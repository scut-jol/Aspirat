/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/24] Train loss=0.7165278196334839
[5/24] Train loss=0.7149661183357239
[10/24] Train loss=0.7115690112113953
[15/24] Train loss=0.6945192813873291
[20/24] Train loss=0.685495913028717
Test set avg_accuracy=60.46% avg_sensitivity=47.20%, avg_specificity=65.19% avg_auc=60.56%
Best model saved!! Metric=-92.59611619025407!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.701962 Test loss=0.681628 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6816918849945068
[5/24] Train loss=0.6720871925354004
[10/24] Train loss=0.6790123581886292
[15/24] Train loss=0.6631985306739807
[20/24] Train loss=0.6557760238647461
Test set avg_accuracy=64.82% avg_sensitivity=69.17%, avg_specificity=63.26% avg_auc=71.97%
Best model saved!! Metric=-56.7747276535683!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.669912 Test loss=0.632341 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6559951901435852
[5/24] Train loss=0.642707884311676
[10/24] Train loss=0.6512869596481323
[15/24] Train loss=0.6311715841293335
[20/24] Train loss=0.6189916133880615
Test set avg_accuracy=67.81% avg_sensitivity=74.86%, avg_specificity=65.29% avg_auc=77.19%
Best model saved!! Metric=-40.84104614155187!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.642026 Test loss=0.604100 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.617819607257843
[5/24] Train loss=0.6136439442634583
[10/24] Train loss=0.6209508776664734
[15/24] Train loss=0.6027255058288574
[20/24] Train loss=0.5980498194694519
Test set avg_accuracy=70.34% avg_sensitivity=78.97%, avg_specificity=67.26% avg_auc=79.87%
Best model saved!! Metric=-29.56306698586397!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.614572 Test loss=0.578149 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5951679944992065
[5/24] Train loss=0.5823485851287842
[10/24] Train loss=0.593421220779419
[15/24] Train loss=0.575050950050354
[20/24] Train loss=0.576551079750061
Test set avg_accuracy=72.21% avg_sensitivity=80.70%, avg_specificity=69.18% avg_auc=81.74%
Best model saved!! Metric=-22.159813068850724!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.588813 Test loss=0.553721 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5709663033485413
[5/24] Train loss=0.5620014667510986
[10/24] Train loss=0.5766337513923645
[15/24] Train loss=0.5536366701126099
[20/24] Train loss=0.5476834774017334
Test set avg_accuracy=73.96% avg_sensitivity=80.90%, avg_specificity=71.48% avg_auc=83.15%
Best model saved!! Metric=-16.517060610745077!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.564577 Test loss=0.530595 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5448296070098877
[5/24] Train loss=0.5363199710845947
[10/24] Train loss=0.5491123199462891
[15/24] Train loss=0.5277923345565796
[20/24] Train loss=0.5231721997261047
Test set avg_accuracy=75.70% avg_sensitivity=79.02%, avg_specificity=74.52% avg_auc=84.11%
Best model saved!! Metric=-12.647656540249002!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.538980 Test loss=0.507533 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5157204866409302
[5/24] Train loss=0.5042757987976074
[10/24] Train loss=0.5241102576255798
[15/24] Train loss=0.5007157325744629
[20/24] Train loss=0.4930810034275055
Test set avg_accuracy=78.10% avg_sensitivity=74.62%, avg_specificity=79.34% avg_auc=84.84%
Best model saved!! Metric=-9.101352346916684!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.514139 Test loss=0.475086 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.49176493287086487
[5/24] Train loss=0.48602285981178284
[10/24] Train loss=0.4992166757583618
[15/24] Train loss=0.4806210994720459
[20/24] Train loss=0.47281306982040405
Test set avg_accuracy=79.31% avg_sensitivity=75.80%, avg_specificity=80.56% avg_auc=86.32%
Best model saved!! Metric=-4.003571637879645!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.489785 Test loss=0.457460 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.46830764412879944
[5/24] Train loss=0.45971566438674927
[10/24] Train loss=0.4727003872394562
[15/24] Train loss=0.45959779620170593
[20/24] Train loss=0.44212064146995544
Test set avg_accuracy=80.70% avg_sensitivity=75.90%, avg_specificity=82.42% avg_auc=87.59%
Best model saved!! Metric=0.611644827899994!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.464607 Test loss=0.433819 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4426790475845337
[5/24] Train loss=0.43781110644340515
[10/24] Train loss=0.4546843469142914
[15/24] Train loss=0.44505128264427185
[20/24] Train loss=0.42692625522613525
Test set avg_accuracy=82.40% avg_sensitivity=73.18%, avg_specificity=85.69% avg_auc=88.34%
Best model saved!! Metric=3.6035714155079432!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.442692 Test loss=0.409701 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.41613513231277466
[5/24] Train loss=0.4082598090171814
[10/24] Train loss=0.4314713478088379
[15/24] Train loss=0.42847940325737
[20/24] Train loss=0.401726096868515
Test set avg_accuracy=83.52% avg_sensitivity=72.69%, avg_specificity=87.38% avg_auc=89.14%
Best model saved!! Metric=6.7277412149786215!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.421934 Test loss=0.390493 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3997574746608734
[5/24] Train loss=0.3903566002845764
[10/24] Train loss=0.4028443694114685
[15/24] Train loss=0.41118350625038147
[20/24] Train loss=0.38450124859809875
Test set avg_accuracy=84.08% avg_sensitivity=75.11%, avg_specificity=87.28% avg_auc=89.99%
Best model saved!! Metric=10.452930360563712!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.403496 Test loss=0.378578 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.37963953614234924
[5/24] Train loss=0.36913052201271057
[10/24] Train loss=0.3950817883014679
[15/24] Train loss=0.39260098338127136
[20/24] Train loss=0.3639577627182007
Test set avg_accuracy=84.28% avg_sensitivity=76.30%, avg_specificity=87.14% avg_auc=90.52%
Best model saved!! Metric=12.243164951753357!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.386485 Test loss=0.370358 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3637433350086212
[5/24] Train loss=0.35757675766944885
[10/24] Train loss=0.3821209669113159
[15/24] Train loss=0.3789479732513428
[20/24] Train loss=0.34605351090431213
Test set avg_accuracy=85.31% avg_sensitivity=72.79%, avg_specificity=89.79% avg_auc=90.71%
Best model saved!! Metric=12.59744612890853!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.372230 Test loss=0.355932 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3549547493457794
[5/24] Train loss=0.3414671719074249
[10/24] Train loss=0.36635565757751465
[15/24] Train loss=0.368741512298584
[20/24] Train loss=0.3388144373893738
Test set avg_accuracy=85.03% avg_sensitivity=76.00%, avg_specificity=88.25% avg_auc=91.20%
Best model saved!! Metric=14.475681204304621!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.359057 Test loss=0.354091 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3388657569885254
[5/24] Train loss=0.3302181363105774
[10/24] Train loss=0.35478919744491577
[15/24] Train loss=0.36085519194602966
[20/24] Train loss=0.33043035864830017
Test set avg_accuracy=84.04% avg_sensitivity=78.92%, avg_specificity=85.86% avg_auc=91.40%
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.348296 Test loss=0.360570 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.32667821645736694
[5/24] Train loss=0.3282935619354248
[10/24] Train loss=0.34642940759658813
[15/24] Train loss=0.3457784950733185
[20/24] Train loss=0.3208528161048889
Test set avg_accuracy=84.74% avg_sensitivity=78.03%, avg_specificity=87.14% avg_auc=91.45%
Best model saved!! Metric=15.35608374922623!!
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.338012 Test loss=0.352802 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.31931787729263306
[5/24] Train loss=0.3186618983745575
[10/24] Train loss=0.3365427255630493
[15/24] Train loss=0.3434036374092102
[20/24] Train loss=0.310261607170105
Test set avg_accuracy=83.20% avg_sensitivity=80.85%, avg_specificity=84.04% avg_auc=91.02%
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.330852 Test loss=0.367610 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.31554245948791504
[5/24] Train loss=0.31350526213645935
[10/24] Train loss=0.3270552456378937
[15/24] Train loss=0.3370436429977417
[20/24] Train loss=0.3030149042606354
Test set avg_accuracy=83.71% avg_sensitivity=80.70%, avg_specificity=84.79% avg_auc=91.32%
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.322736 Test loss=0.362743 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3090443015098572
[5/24] Train loss=0.3110327422618866
[10/24] Train loss=0.32138925790786743
[15/24] Train loss=0.32932522892951965
[20/24] Train loss=0.2957853376865387
Test set avg_accuracy=83.95% avg_sensitivity=80.06%, avg_specificity=85.33% avg_auc=91.14%
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.315466 Test loss=0.363680 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2993195950984955
[5/24] Train loss=0.299063116312027
[10/24] Train loss=0.31554892659187317
[15/24] Train loss=0.3207577168941498
[20/24] Train loss=0.2917558252811432
Test set avg_accuracy=84.70% avg_sensitivity=77.63%, avg_specificity=87.22% avg_auc=91.59%
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.309183 Test loss=0.344297 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2886873483657837
[5/24] Train loss=0.3001510798931122
[10/24] Train loss=0.31351715326309204
[15/24] Train loss=0.3197111189365387
[20/24] Train loss=0.28025132417678833
Test set avg_accuracy=85.96% avg_sensitivity=72.79%, avg_specificity=90.67% avg_auc=91.47%
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.302715 Test loss=0.331551 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.28559044003486633
[5/24] Train loss=0.28848278522491455
[10/24] Train loss=0.3042590916156769
[15/24] Train loss=0.3133501708507538
[20/24] Train loss=0.2731657922267914
Test set avg_accuracy=84.53% avg_sensitivity=77.63%, avg_specificity=86.99% avg_auc=91.07%
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.296727 Test loss=0.350234 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.27907395362854004
[5/24] Train loss=0.27551737427711487
[10/24] Train loss=0.30584368109703064
[15/24] Train loss=0.31944039463996887
[20/24] Train loss=0.26533615589141846
Test set avg_accuracy=85.73% avg_sensitivity=77.14%, avg_specificity=88.80% avg_auc=92.06%
Best model saved!! Metric=17.721501786536763!!
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.289775 Test loss=0.324547 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2706614136695862
[5/24] Train loss=0.28354066610336304
[10/24] Train loss=0.29791393876075745
[15/24] Train loss=0.30150306224823
[20/24] Train loss=0.2724400460720062
Test set avg_accuracy=86.47% avg_sensitivity=65.26%, avg_specificity=94.04% avg_auc=91.78%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.283960 Test loss=0.317407 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2735891044139862
[5/24] Train loss=0.28829771280288696
[10/24] Train loss=0.29502972960472107
[15/24] Train loss=0.2992275655269623
[20/24] Train loss=0.25370660424232483
Test set avg_accuracy=85.48% avg_sensitivity=53.74%, avg_specificity=96.82% avg_auc=90.62%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.285768 Test loss=0.349484 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.26713666319847107
[5/24] Train loss=0.26394888758659363
[10/24] Train loss=0.282843679189682
[15/24] Train loss=0.28932300209999084
[20/24] Train loss=0.24621151387691498
Test set avg_accuracy=83.29% avg_sensitivity=43.20%, avg_specificity=97.61% avg_auc=89.25%
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.272702 Test loss=0.395318 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2604733407497406
[5/24] Train loss=0.2604178488254547
[10/24] Train loss=0.2864272892475128
[15/24] Train loss=0.29608356952667236
[20/24] Train loss=0.24570965766906738
Test set avg_accuracy=84.87% avg_sensitivity=50.67%, avg_specificity=97.08% avg_auc=89.91%
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.268001 Test loss=0.360668 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.25698575377464294
[5/24] Train loss=0.25267425179481506
[10/24] Train loss=0.27606406807899475
[15/24] Train loss=0.2820049524307251
[20/24] Train loss=0.24082350730895996
Test set avg_accuracy=84.61% avg_sensitivity=48.99%, avg_specificity=97.33% avg_auc=91.29%
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.262343 Test loss=0.350573 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.249945268034935
[5/24] Train loss=0.252504825592041
[10/24] Train loss=0.2824056148529053
[15/24] Train loss=0.28506210446357727
[20/24] Train loss=0.24812304973602295
Test set avg_accuracy=81.86% avg_sensitivity=36.07%, avg_specificity=98.22% avg_auc=87.18%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.262097 Test loss=0.439023 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2418442666530609
[5/24] Train loss=0.24884475767612457
[10/24] Train loss=0.25715166330337524
[15/24] Train loss=0.2755567729473114
[20/24] Train loss=0.24489101767539978
Test set avg_accuracy=86.00% avg_sensitivity=56.75%, avg_specificity=96.45% avg_auc=90.90%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.252148 Test loss=0.334178 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.24544815719127655
[5/24] Train loss=0.2440558820962906
[10/24] Train loss=0.2610369920730591
[15/24] Train loss=0.27268847823143005
[20/24] Train loss=0.24183987081050873
Test set avg_accuracy=83.55% avg_sensitivity=43.84%, avg_specificity=97.74% avg_auc=89.18%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.249955 Test loss=0.400489 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.24069641530513763
[5/24] Train loss=0.23943746089935303
[10/24] Train loss=0.2620989680290222
[15/24] Train loss=0.2636285722255707
[20/24] Train loss=0.23915952444076538
Test set avg_accuracy=85.14% avg_sensitivity=53.59%, avg_specificity=96.41% avg_auc=90.72%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.248289 Test loss=0.342329 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.23196646571159363
[5/24] Train loss=0.23217082023620605
[10/24] Train loss=0.2467012256383896
[15/24] Train loss=0.2671854496002197
[20/24] Train loss=0.23472821712493896
Test set avg_accuracy=75.09% avg_sensitivity=5.99%, avg_specificity=99.77% avg_auc=81.62%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.246048 Test loss=0.706256 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.23656630516052246
[5/24] Train loss=0.22277431190013885
[10/24] Train loss=0.24492153525352478
[15/24] Train loss=0.2567055821418762
[20/24] Train loss=0.2228754311800003
Test set avg_accuracy=79.54% avg_sensitivity=25.28%, avg_specificity=98.92% avg_auc=86.12%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.237254 Test loss=0.494583 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2288893163204193
[5/24] Train loss=0.22857633233070374
[10/24] Train loss=0.23748591542243958
[15/24] Train loss=0.25472840666770935
[20/24] Train loss=0.23181185126304626
Test set avg_accuracy=84.09% avg_sensitivity=45.97%, avg_specificity=97.70% avg_auc=89.12%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.236227 Test loss=0.391148 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.23409834504127502
[5/24] Train loss=0.22033491730690002
[10/24] Train loss=0.23634448647499084
[15/24] Train loss=0.26036500930786133
[20/24] Train loss=0.22089990973472595
Test set avg_accuracy=80.82% avg_sensitivity=31.07%, avg_specificity=98.59% avg_auc=84.76%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.234001 Test loss=0.495319 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.22996029257774353
[5/24] Train loss=0.2151494175195694
[10/24] Train loss=0.2611028254032135
[15/24] Train loss=0.2695348262786865
[20/24] Train loss=0.21637356281280518
Test set avg_accuracy=86.78% avg_sensitivity=67.84%, avg_specificity=93.55% avg_auc=90.85%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.236914 Test loss=0.322918 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2282145470380783
[5/24] Train loss=0.21647998690605164
[10/24] Train loss=0.25237345695495605
[15/24] Train loss=0.2438017874956131
[20/24] Train loss=0.21788012981414795
Test set avg_accuracy=84.15% avg_sensitivity=46.31%, avg_specificity=97.67% avg_auc=88.92%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.229590 Test loss=0.394648 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2083776891231537
[5/24] Train loss=0.19696468114852905
[10/24] Train loss=0.2398384064435959
[15/24] Train loss=0.2480112910270691
[20/24] Train loss=0.21865028142929077
Test set avg_accuracy=83.57% avg_sensitivity=79.76%, avg_specificity=84.93% avg_auc=90.94%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.227915 Test loss=0.363122 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.19951757788658142
[5/24] Train loss=0.20168322324752808
[10/24] Train loss=0.22906067967414856
[15/24] Train loss=0.241976797580719
[20/24] Train loss=0.22097255289554596
Test set avg_accuracy=87.01% avg_sensitivity=68.43%, avg_specificity=93.64% avg_auc=91.42%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.223837 Test loss=0.315408 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2072492092847824
[5/24] Train loss=0.2302917093038559
[10/24] Train loss=0.251777321100235
[15/24] Train loss=0.26564374566078186
[20/24] Train loss=0.2136133313179016
Test set avg_accuracy=84.75% avg_sensitivity=69.82%, avg_specificity=90.09% avg_auc=89.75%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.227359 Test loss=0.350821 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2113344371318817
[5/24] Train loss=0.2018628865480423
[10/24] Train loss=0.24026073515415192
[15/24] Train loss=0.24459674954414368
[20/24] Train loss=0.21134600043296814
Test set avg_accuracy=84.79% avg_sensitivity=57.30%, avg_specificity=94.61% avg_auc=88.80%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.221113 Test loss=0.367285 Current lr=[0.00029967723776099]

[0/24] Train loss=0.20891956984996796
[5/24] Train loss=0.19772538542747498
[10/24] Train loss=0.23716434836387634
[15/24] Train loss=0.24817010760307312
[20/24] Train loss=0.20818454027175903
Test set avg_accuracy=84.99% avg_sensitivity=70.51%, avg_specificity=90.16% avg_auc=90.17%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.219125 Test loss=0.343824 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2046879529953003
[5/24] Train loss=0.19884636998176575
[10/24] Train loss=0.22002016007900238
[15/24] Train loss=0.23352602124214172
[20/24] Train loss=0.2051302194595337
Test set avg_accuracy=84.92% avg_sensitivity=71.05%, avg_specificity=89.87% avg_auc=90.09%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.215065 Test loss=0.350231 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2067829966545105
[5/24] Train loss=0.19698727130889893
[10/24] Train loss=0.2371497005224228
[15/24] Train loss=0.23361261188983917
[20/24] Train loss=0.2105012983083725
Test set avg_accuracy=83.62% avg_sensitivity=49.88%, avg_specificity=95.67% avg_auc=86.56%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.217975 Test loss=0.407341 Current lr=[0.000299720220882401]

[0/24] Train loss=0.19747239351272583
[5/24] Train loss=0.19750164449214935
[10/24] Train loss=0.23888443410396576
[15/24] Train loss=0.22880056500434875
[20/24] Train loss=0.2085529863834381
Test set avg_accuracy=84.31% avg_sensitivity=66.70%, avg_specificity=90.60% avg_auc=89.49%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.213965 Test loss=0.371866 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19439643621444702
[5/24] Train loss=0.20245613157749176
[10/24] Train loss=0.22029007971286774
[15/24] Train loss=0.2268819957971573
[20/24] Train loss=0.1968674510717392
Test set avg_accuracy=81.58% avg_sensitivity=34.04%, avg_specificity=98.55% avg_auc=85.24%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.209830 Test loss=0.478298 Current lr=[0.000298904600941902]

[0/24] Train loss=0.19846506416797638
[5/24] Train loss=0.19626665115356445
[10/24] Train loss=0.22047081589698792
[15/24] Train loss=0.2455248236656189
[20/24] Train loss=0.2079489529132843
Test set avg_accuracy=79.51% avg_sensitivity=25.58%, avg_specificity=98.76% avg_auc=80.60%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.210753 Test loss=0.566859 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.19516386091709137
[5/24] Train loss=0.17853011190891266
[10/24] Train loss=0.22270818054676056
[15/24] Train loss=0.2289433628320694
[20/24] Train loss=0.18956302106380463
Test set avg_accuracy=84.87% avg_sensitivity=55.52%, avg_specificity=95.35% avg_auc=88.86%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.206746 Test loss=0.366319 Current lr=[0.000297555943323901]

[0/24] Train loss=0.1871568262577057
[5/24] Train loss=0.18849436938762665
[10/24] Train loss=0.22373095154762268
[15/24] Train loss=0.2197691947221756
[20/24] Train loss=0.2151937186717987
Test set avg_accuracy=79.00% avg_sensitivity=22.12%, avg_specificity=99.31% avg_auc=80.06%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.206355 Test loss=0.619125 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.1854122430086136
[5/24] Train loss=0.1671162098646164
[10/24] Train loss=0.20993004739284515
[15/24] Train loss=0.2229199856519699
[20/24] Train loss=0.19626715779304504
Test set avg_accuracy=84.51% avg_sensitivity=60.66%, avg_specificity=93.02% avg_auc=89.21%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.200461 Test loss=0.364018 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.18347229063510895
[5/24] Train loss=0.18388262391090393
[10/24] Train loss=0.20590783655643463
[15/24] Train loss=0.21944721043109894
[20/24] Train loss=0.20022332668304443
Test set avg_accuracy=83.26% avg_sensitivity=43.69%, avg_specificity=97.38% avg_auc=82.47%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.200762 Test loss=0.475678 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.19825275242328644
[5/24] Train loss=0.18285755813121796
[10/24] Train loss=0.20753279328346252
[15/24] Train loss=0.21562354266643524
[20/24] Train loss=0.19222676753997803
Test set avg_accuracy=84.54% avg_sensitivity=64.87%, avg_specificity=91.57% avg_auc=88.56%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.204727 Test loss=0.370448 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.17748646438121796
[5/24] Train loss=0.19410307705402374
[10/24] Train loss=0.20913803577423096
[15/24] Train loss=0.214798241853714
[20/24] Train loss=0.2033643126487732
Test set avg_accuracy=76.21% avg_sensitivity=10.74%, avg_specificity=99.59% avg_auc=80.44%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.199438 Test loss=0.645637 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.19269685447216034
[5/24] Train loss=0.17800608277320862
[10/24] Train loss=0.19960492849349976
[15/24] Train loss=0.20369242131710052
[20/24] Train loss=0.18767736852169037
Test set avg_accuracy=84.23% avg_sensitivity=70.21%, avg_specificity=89.24% avg_auc=89.15%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.192000 Test loss=0.363418 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.1771451234817505
[5/24] Train loss=0.17637769877910614
[10/24] Train loss=0.20669661462306976
[15/24] Train loss=0.2114492505788803
[20/24] Train loss=0.1912747174501419
Test set avg_accuracy=84.52% avg_sensitivity=56.95%, avg_specificity=94.36% avg_auc=87.45%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.194725 Test loss=0.382914 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.18359214067459106
[5/24] Train loss=0.17886607348918915
[10/24] Train loss=0.19131045043468475
[15/24] Train loss=0.21019190549850464
[20/24] Train loss=0.1805742084980011
Test set avg_accuracy=83.03% avg_sensitivity=58.24%, avg_specificity=91.89% avg_auc=86.33%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.188712 Test loss=0.403913 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18366606533527374
[5/24] Train loss=0.1672554612159729
[10/24] Train loss=0.18505652248859406
[15/24] Train loss=0.2070518583059311
[20/24] Train loss=0.18517327308654785
Test set avg_accuracy=80.91% avg_sensitivity=37.61%, avg_specificity=96.38% avg_auc=81.19%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.189032 Test loss=0.536951 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.17791421711444855
[5/24] Train loss=0.17114567756652832
[10/24] Train loss=0.19397605955600739
[15/24] Train loss=0.19700375199317932
[20/24] Train loss=0.17779789865016937
Test set avg_accuracy=82.85% avg_sensitivity=46.36%, avg_specificity=95.88% avg_auc=83.41%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.189889 Test loss=0.475209 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.1847076565027237
[5/24] Train loss=0.17304424941539764
[10/24] Train loss=0.19062189757823944
[15/24] Train loss=0.1990542709827423
[20/24] Train loss=0.1826428771018982
Test set avg_accuracy=79.23% avg_sensitivity=25.33%, avg_specificity=98.48% avg_auc=79.43%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.194884 Test loss=0.568435 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.19473132491111755
[5/24] Train loss=0.1762756109237671
[10/24] Train loss=0.18486277759075165
[15/24] Train loss=0.19834044575691223
[20/24] Train loss=0.16996680200099945
Test set avg_accuracy=81.74% avg_sensitivity=76.74%, avg_specificity=83.53% avg_auc=88.06%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.191975 Test loss=0.414902 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.17895027995109558
[5/24] Train loss=0.1691790372133255
[10/24] Train loss=0.18183116614818573
[15/24] Train loss=0.20834404230117798
[20/24] Train loss=0.1806769073009491
Test set avg_accuracy=80.62% avg_sensitivity=73.82%, avg_specificity=83.05% avg_auc=86.64%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.187685 Test loss=0.447394 Current lr=[0.000276307469034998]

[0/24] Train loss=0.1724577695131302
[5/24] Train loss=0.16860415041446686
[10/24] Train loss=0.175031378865242
[15/24] Train loss=0.19990023970603943
[20/24] Train loss=0.18239012360572815
Test set avg_accuracy=83.84% avg_sensitivity=46.46%, avg_specificity=97.19% avg_auc=85.37%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.185473 Test loss=0.437193 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.17957207560539246
[5/24] Train loss=0.177006796002388
[10/24] Train loss=0.18841932713985443
[15/24] Train loss=0.19184409081935883
[20/24] Train loss=0.1865551769733429
Test set avg_accuracy=74.83% avg_sensitivity=87.73%, avg_specificity=70.22% avg_auc=87.58%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.185142 Test loss=0.529504 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.17187710106372833
[5/24] Train loss=0.15508858859539032
[10/24] Train loss=0.1808886080980301
[15/24] Train loss=0.20092551410198212
[20/24] Train loss=0.18460910022258759
Test set avg_accuracy=83.89% avg_sensitivity=80.65%, avg_specificity=85.05% avg_auc=90.17%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.182822 Test loss=0.376370 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.17642921209335327
[5/24] Train loss=0.16494067013263702
[10/24] Train loss=0.18107080459594727
[15/24] Train loss=0.19920803606510162
[20/24] Train loss=0.18511095643043518
Test set avg_accuracy=85.03% avg_sensitivity=62.05%, avg_specificity=93.23% avg_auc=87.13%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.185416 Test loss=0.393880 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.17628270387649536
[5/24] Train loss=0.15835481882095337
[10/24] Train loss=0.18441738188266754
[15/24] Train loss=0.19190096855163574
[20/24] Train loss=0.18827004730701447
Test set avg_accuracy=80.82% avg_sensitivity=81.49%, avg_specificity=80.58% avg_auc=88.52%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.183163 Test loss=0.438581 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.18370431661605835
[5/24] Train loss=0.16393586993217468
[10/24] Train loss=0.18372683227062225
[15/24] Train loss=0.1976204663515091
[20/24] Train loss=0.16927914321422577
Test set avg_accuracy=83.14% avg_sensitivity=82.43%, avg_specificity=83.39% avg_auc=90.04%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.179686 Test loss=0.387380 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.16398955881595612
[5/24] Train loss=0.149992436170578
[10/24] Train loss=0.1803719401359558
[15/24] Train loss=0.19065530598163605
[20/24] Train loss=0.17363421618938446
Test set avg_accuracy=84.31% avg_sensitivity=79.27%, avg_specificity=86.11% avg_auc=90.32%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.176912 Test loss=0.382910 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.17002026736736298
[5/24] Train loss=0.1604136824607849
[10/24] Train loss=0.1829236000776291
[15/24] Train loss=0.19134990870952606
[20/24] Train loss=0.1619286984205246
Test set avg_accuracy=84.54% avg_sensitivity=74.62%, avg_specificity=88.09% avg_auc=89.86%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.176662 Test loss=0.373337 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.16390039026737213
[5/24] Train loss=0.148018941283226
[10/24] Train loss=0.17028291523456573
[15/24] Train loss=0.1860671490430832
[20/24] Train loss=0.1698167324066162
Test set avg_accuracy=84.65% avg_sensitivity=67.29%, avg_specificity=90.85% avg_auc=88.55%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.170267 Test loss=0.377455 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.16710059344768524
[5/24] Train loss=0.16814379394054413
[10/24] Train loss=0.1650679111480713
[15/24] Train loss=0.18719948828220367
[20/24] Train loss=0.16610778868198395
Test set avg_accuracy=84.57% avg_sensitivity=52.75%, avg_specificity=95.94% avg_auc=87.25%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.171370 Test loss=0.405731 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.16332803666591644
[5/24] Train loss=0.1455778181552887
[10/24] Train loss=0.17547370493412018
[15/24] Train loss=0.18025720119476318
[20/24] Train loss=0.17198315262794495
Test set avg_accuracy=85.00% avg_sensitivity=71.15%, avg_specificity=89.95% avg_auc=89.71%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.171733 Test loss=0.361845 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.16391249001026154
[5/24] Train loss=0.15638403594493866
[10/24] Train loss=0.16982373595237732
[15/24] Train loss=0.189358651638031
[20/24] Train loss=0.16229942440986633
Test set avg_accuracy=85.49% avg_sensitivity=63.93%, avg_specificity=93.20% avg_auc=89.42%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.171262 Test loss=0.365142 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.16323590278625488
[5/24] Train loss=0.15017393231391907
[10/24] Train loss=0.1659848988056183
[15/24] Train loss=0.178821861743927
[20/24] Train loss=0.1829715222120285
Test set avg_accuracy=84.40% avg_sensitivity=76.00%, avg_specificity=87.40% avg_auc=89.48%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.171263 Test loss=0.386452 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.16864752769470215
[5/24] Train loss=0.1504213511943817
[10/24] Train loss=0.1670275777578354
[15/24] Train loss=0.1938277930021286
[20/24] Train loss=0.1675434112548828
Test set avg_accuracy=79.10% avg_sensitivity=84.27%, avg_specificity=77.26% avg_auc=88.15%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.172022 Test loss=0.478233 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.1606745421886444
[5/24] Train loss=0.1617293804883957
[10/24] Train loss=0.1794613003730774
[15/24] Train loss=0.18351463973522186
[20/24] Train loss=0.16959534585475922
Test set avg_accuracy=82.98% avg_sensitivity=77.34%, avg_specificity=85.00% avg_auc=89.09%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.175020 Test loss=0.406878 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.1662142276763916
[5/24] Train loss=0.15264663100242615
[10/24] Train loss=0.16512537002563477
[15/24] Train loss=0.18222194910049438
[20/24] Train loss=0.1652439385652542
Test set avg_accuracy=83.16% avg_sensitivity=71.05%, avg_specificity=87.49% avg_auc=87.23%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.170476 Test loss=0.400699 Current lr=[0.000224838296036774]

[0/24] Train loss=0.165469229221344
[5/24] Train loss=0.15288721024990082
[10/24] Train loss=0.16284164786338806
[15/24] Train loss=0.16944848001003265
[20/24] Train loss=0.1607784777879715
Test set avg_accuracy=82.01% avg_sensitivity=79.27%, avg_specificity=82.98% avg_auc=89.20%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.166858 Test loss=0.407295 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.15097182989120483
[5/24] Train loss=0.14723800122737885
[10/24] Train loss=0.15969614684581757
[15/24] Train loss=0.17192155122756958
[20/24] Train loss=0.15834349393844604
Test set avg_accuracy=83.42% avg_sensitivity=79.91%, avg_specificity=84.68% avg_auc=90.19%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.163701 Test loss=0.387993 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.15289676189422607
[5/24] Train loss=0.15479303896427155
[10/24] Train loss=0.1627517193555832
[15/24] Train loss=0.1853659301996231
[20/24] Train loss=0.1619446575641632
Test set avg_accuracy=82.50% avg_sensitivity=80.31%, avg_specificity=83.28% avg_auc=88.95%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.166588 Test loss=0.421233 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.15586453676223755
[5/24] Train loss=0.1416129320859909
[10/24] Train loss=0.1606263965368271
[15/24] Train loss=0.17725001275539398
[20/24] Train loss=0.16028936207294464
Test set avg_accuracy=85.30% avg_sensitivity=72.49%, avg_specificity=89.87% avg_auc=89.84%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.168865 Test loss=0.359523 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.15949958562850952
[5/24] Train loss=0.14860109984874725
[10/24] Train loss=0.15912564098834991
[15/24] Train loss=0.18667080998420715
[20/24] Train loss=0.16332264244556427
Test set avg_accuracy=81.69% avg_sensitivity=79.66%, avg_specificity=82.42% avg_auc=88.43%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.166307 Test loss=0.425636 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.16004253923892975
[5/24] Train loss=0.14336176216602325
[10/24] Train loss=0.1568891853094101
[15/24] Train loss=0.1759030818939209
[20/24] Train loss=0.15950916707515717
Test set avg_accuracy=85.43% avg_sensitivity=57.79%, avg_specificity=95.30% avg_auc=87.40%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.163505 Test loss=0.382635 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.147831991314888
[5/24] Train loss=0.14593365788459778
[10/24] Train loss=0.15201658010482788
[15/24] Train loss=0.17082667350769043
[20/24] Train loss=0.16565421223640442
Test set avg_accuracy=85.35% avg_sensitivity=56.16%, avg_specificity=95.78% avg_auc=87.12%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.162638 Test loss=0.397815 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.15907348692417145
[5/24] Train loss=0.14780119061470032
[10/24] Train loss=0.1629948765039444
[15/24] Train loss=0.1676386296749115
[20/24] Train loss=0.15958067774772644
Test set avg_accuracy=83.97% avg_sensitivity=73.97%, avg_specificity=87.54% avg_auc=88.94%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.161819 Test loss=0.391573 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.14800362288951874
[5/24] Train loss=0.14414244890213013
[10/24] Train loss=0.14745181798934937
[15/24] Train loss=0.17148473858833313
[20/24] Train loss=0.15274173021316528
Test set avg_accuracy=84.19% avg_sensitivity=47.60%, avg_specificity=97.26% avg_auc=85.21%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.161007 Test loss=0.429827 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.15298309922218323
[5/24] Train loss=0.14683260023593903
[10/24] Train loss=0.15745757520198822
[15/24] Train loss=0.170101135969162
[20/24] Train loss=0.15393635630607605
Test set avg_accuracy=84.58% avg_sensitivity=57.30%, avg_specificity=94.33% avg_auc=85.40%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.158957 Test loss=0.410191 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1454116553068161
[5/24] Train loss=0.15636616945266724
[10/24] Train loss=0.14501671493053436
[15/24] Train loss=0.17111028730869293
[20/24] Train loss=0.15587326884269714
Test set avg_accuracy=83.50% avg_sensitivity=48.84%, avg_specificity=95.88% avg_auc=84.30%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.159144 Test loss=0.432575 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.14529956877231598
[5/24] Train loss=0.14159440994262695
[10/24] Train loss=0.14567722380161285
[15/24] Train loss=0.16444626450538635
[20/24] Train loss=0.14773395657539368
Test set avg_accuracy=85.56% avg_sensitivity=62.05%, avg_specificity=93.96% avg_auc=88.85%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.153651 Test loss=0.368970 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.14615070819854736
[5/24] Train loss=0.13906380534172058
[10/24] Train loss=0.1462029069662094
[15/24] Train loss=0.159527987241745
[20/24] Train loss=0.1547621339559555
Test set avg_accuracy=84.69% avg_sensitivity=69.17%, avg_specificity=90.23% avg_auc=88.06%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.155337 Test loss=0.377344 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.14581960439682007
[5/24] Train loss=0.14487208425998688
[10/24] Train loss=0.14673052728176117
[15/24] Train loss=0.16114290058612823
[20/24] Train loss=0.14572082459926605
Test set avg_accuracy=84.18% avg_sensitivity=65.66%, avg_specificity=90.79% avg_auc=87.96%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.153942 Test loss=0.389260 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.14332647621631622
[5/24] Train loss=0.14280161261558533
[10/24] Train loss=0.149258553981781
[15/24] Train loss=0.16154032945632935
[20/24] Train loss=0.15504740178585052
Test set avg_accuracy=85.12% avg_sensitivity=69.97%, avg_specificity=90.53% avg_auc=89.94%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.157485 Test loss=0.355126 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.14618133008480072
[5/24] Train loss=0.1435268521308899
[10/24] Train loss=0.15338614583015442
[15/24] Train loss=0.1648309826850891
[20/24] Train loss=0.1465982049703598
Test set avg_accuracy=83.93% avg_sensitivity=67.10%, avg_specificity=89.95% avg_auc=88.77%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.156125 Test loss=0.384060 Current lr=[0.000156543481933168]

[0/24] Train loss=0.1452881246805191
[5/24] Train loss=0.14454512298107147
[10/24] Train loss=0.1508697271347046
[15/24] Train loss=0.15837739408016205
[20/24] Train loss=0.15744982659816742
Test set avg_accuracy=83.61% avg_sensitivity=76.10%, avg_specificity=86.29% avg_auc=88.86%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.155774 Test loss=0.393695 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1410762518644333
[5/24] Train loss=0.13420000672340393
[10/24] Train loss=0.14934280514717102
[15/24] Train loss=0.15623952448368073
[20/24] Train loss=0.1532491147518158
Test set avg_accuracy=84.93% avg_sensitivity=59.03%, avg_specificity=94.19% avg_auc=87.74%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.155290 Test loss=0.395502 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.1436891257762909
[5/24] Train loss=0.14899574220180511
[10/24] Train loss=0.155561625957489
[15/24] Train loss=0.15981753170490265
[20/24] Train loss=0.14958027005195618
Test set avg_accuracy=80.10% avg_sensitivity=83.72%, avg_specificity=78.81% avg_auc=88.68%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.156670 Test loss=0.463947 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.14518767595291138
[5/24] Train loss=0.14901098608970642
[10/24] Train loss=0.15453492105007172
[15/24] Train loss=0.15547938644886017
[20/24] Train loss=0.1506248116493225
Test set avg_accuracy=82.33% avg_sensitivity=39.78%, avg_specificity=97.53% avg_auc=83.32%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.157250 Test loss=0.483379 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15028579533100128
[5/24] Train loss=0.14318779110908508
[10/24] Train loss=0.1450749933719635
[15/24] Train loss=0.16490879654884338
[20/24] Train loss=0.1544675976037979
Test set avg_accuracy=83.31% avg_sensitivity=69.62%, avg_specificity=88.20% avg_auc=87.77%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.153948 Test loss=0.401323 Current lr=[0.000134135431043539]

[0/24] Train loss=0.14573141932487488
[5/24] Train loss=0.1378951072692871
[10/24] Train loss=0.15979863703250885
[15/24] Train loss=0.16257105767726898
[20/24] Train loss=0.1577923595905304
Test set avg_accuracy=84.14% avg_sensitivity=50.47%, avg_specificity=96.17% avg_auc=85.51%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.155280 Test loss=0.421240 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.14989611506462097
[5/24] Train loss=0.14698727428913116
[10/24] Train loss=0.15301504731178284
[15/24] Train loss=0.16624440252780914
[20/24] Train loss=0.1491069197654724
Test set avg_accuracy=85.79% avg_sensitivity=65.31%, avg_specificity=93.11% avg_auc=89.20%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.156097 Test loss=0.358227 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.14555278420448303
[5/24] Train loss=0.14172062277793884
[10/24] Train loss=0.1460578292608261
[15/24] Train loss=0.16280893981456757
[20/24] Train loss=0.1527900993824005
Test set avg_accuracy=85.00% avg_sensitivity=64.37%, avg_specificity=92.37% avg_auc=88.50%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.150641 Test loss=0.375804 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.14263659715652466
[5/24] Train loss=0.13912007212638855
[10/24] Train loss=0.14559616148471832
[15/24] Train loss=0.15557703375816345
[20/24] Train loss=0.15412481129169464
Test set avg_accuracy=85.43% avg_sensitivity=67.99%, avg_specificity=91.66% avg_auc=88.89%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.150520 Test loss=0.364415 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.13955514132976532
[5/24] Train loss=0.13726739585399628
[10/24] Train loss=0.14349639415740967
[15/24] Train loss=0.15336613357067108
[20/24] Train loss=0.14607639610767365
Test set avg_accuracy=85.69% avg_sensitivity=65.81%, avg_specificity=92.79% avg_auc=88.34%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.146372 Test loss=0.368402 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1314534991979599
[5/24] Train loss=0.13467246294021606
[10/24] Train loss=0.13724559545516968
[15/24] Train loss=0.15348178148269653
[20/24] Train loss=0.1427377164363861
Test set avg_accuracy=84.58% avg_sensitivity=77.88%, avg_specificity=86.98% avg_auc=89.70%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.143797 Test loss=0.374797 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.13762278854846954
[5/24] Train loss=0.13194778561592102
[10/24] Train loss=0.14580950140953064
[15/24] Train loss=0.15166541934013367
[20/24] Train loss=0.13866858184337616
Test set avg_accuracy=84.17% avg_sensitivity=79.56%, avg_specificity=85.81% avg_auc=90.02%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.144271 Test loss=0.390423 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.13870379328727722
[5/24] Train loss=0.13547919690608978
[10/24] Train loss=0.1435984969139099
[15/24] Train loss=0.15495285391807556
[20/24] Train loss=0.14807729423046112
Test set avg_accuracy=85.07% avg_sensitivity=70.01%, avg_specificity=90.44% avg_auc=89.43%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.146330 Test loss=0.360948 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1398603320121765
[5/24] Train loss=0.13537487387657166
[10/24] Train loss=0.1398547887802124
[15/24] Train loss=0.15416549146175385
[20/24] Train loss=0.14065463840961456
Test set avg_accuracy=84.86% avg_sensitivity=73.68%, avg_specificity=88.85% avg_auc=90.03%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.143385 Test loss=0.365903 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.13004526495933533
[5/24] Train loss=0.13896523416042328
[10/24] Train loss=0.14405173063278198
[15/24] Train loss=0.1550450176000595
[20/24] Train loss=0.14245939254760742
Test set avg_accuracy=85.05% avg_sensitivity=75.01%, avg_specificity=88.64% avg_auc=89.51%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.144060 Test loss=0.375500 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.13891252875328064
[5/24] Train loss=0.13566064834594727
[10/24] Train loss=0.1352112889289856
[15/24] Train loss=0.1570567786693573
[20/24] Train loss=0.13979394733905792
Test set avg_accuracy=85.22% avg_sensitivity=67.00%, avg_specificity=91.73% avg_auc=89.55%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.142871 Test loss=0.359404 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.13126491010189056
[5/24] Train loss=0.12928356230258942
[10/24] Train loss=0.13126245141029358
[15/24] Train loss=0.1437961310148239
[20/24] Train loss=0.13899771869182587
Test set avg_accuracy=84.49% avg_sensitivity=70.31%, avg_specificity=89.56% avg_auc=89.13%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.139274 Test loss=0.375820 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1282593458890915
[5/24] Train loss=0.12997281551361084
[10/24] Train loss=0.13308623433113098
[15/24] Train loss=0.1435406506061554
[20/24] Train loss=0.14018426835536957
Test set avg_accuracy=84.43% avg_sensitivity=78.08%, avg_specificity=86.69% avg_auc=90.14%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.139152 Test loss=0.372725 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.12815316021442413
[5/24] Train loss=0.1308501958847046
[10/24] Train loss=0.13203242421150208
[15/24] Train loss=0.1407880187034607
[20/24] Train loss=0.1366087794303894
Test set avg_accuracy=84.87% avg_sensitivity=70.81%, avg_specificity=89.89% avg_auc=89.48%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.136939 Test loss=0.367375 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.12640155851840973
[5/24] Train loss=0.1264307051897049
[10/24] Train loss=0.133976548910141
[15/24] Train loss=0.14699646830558777
[20/24] Train loss=0.13883371651172638
Test set avg_accuracy=84.73% avg_sensitivity=76.30%, avg_specificity=87.74% avg_auc=89.86%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.136415 Test loss=0.373344 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1286252737045288
[5/24] Train loss=0.13039639592170715
[10/24] Train loss=0.13014130294322968
[15/24] Train loss=0.13806219398975372
[20/24] Train loss=0.13293594121932983
Test set avg_accuracy=85.26% avg_sensitivity=76.99%, avg_specificity=88.21% avg_auc=90.15%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.134983 Test loss=0.364718 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.12781557440757751
[5/24] Train loss=0.1262126863002777
[10/24] Train loss=0.13085614144802094
[15/24] Train loss=0.1455213725566864
[20/24] Train loss=0.13716506958007812
Test set avg_accuracy=84.41% avg_sensitivity=74.27%, avg_specificity=88.04% avg_auc=89.27%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.134899 Test loss=0.377187 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1298854500055313
[5/24] Train loss=0.12105950713157654
[10/24] Train loss=0.12939020991325378
[15/24] Train loss=0.14457032084465027
[20/24] Train loss=0.13125517964363098
Test set avg_accuracy=83.58% avg_sensitivity=71.30%, avg_specificity=87.97% avg_auc=88.89%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.133580 Test loss=0.383131 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.12390680611133575
[5/24] Train loss=0.1247561052441597
[10/24] Train loss=0.12842236459255219
[15/24] Train loss=0.13996586203575134
[20/24] Train loss=0.13487094640731812
Test set avg_accuracy=84.99% avg_sensitivity=72.44%, avg_specificity=89.47% avg_auc=89.24%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.133467 Test loss=0.375204 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.12416644394397736
[5/24] Train loss=0.12413481622934341
[10/24] Train loss=0.13078638911247253
[15/24] Train loss=0.14032945036888123
[20/24] Train loss=0.1333448439836502
Test set avg_accuracy=84.74% avg_sensitivity=71.55%, avg_specificity=89.45% avg_auc=89.02%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.133390 Test loss=0.375240 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1255761682987213
[5/24] Train loss=0.12320491671562195
[10/24] Train loss=0.12720684707164764
[15/24] Train loss=0.1386067420244217
[20/24] Train loss=0.1317431777715683
Test set avg_accuracy=84.92% avg_sensitivity=66.65%, avg_specificity=91.45% avg_auc=88.71%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.132118 Test loss=0.376538 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.12697739899158478
[5/24] Train loss=0.12334233522415161
[10/24] Train loss=0.12625516951084137
[15/24] Train loss=0.14390680193901062
[20/24] Train loss=0.1316498965024948
Test set avg_accuracy=84.84% avg_sensitivity=66.90%, avg_specificity=91.25% avg_auc=88.93%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.133230 Test loss=0.372533 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12459566444158554
[5/24] Train loss=0.12254849076271057
[10/24] Train loss=0.1274600476026535
[15/24] Train loss=0.14052808284759521
[20/24] Train loss=0.12881559133529663
Test set avg_accuracy=84.87% avg_sensitivity=67.49%, avg_specificity=91.08% avg_auc=88.90%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.132070 Test loss=0.377540 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12316016107797623
[5/24] Train loss=0.1216164231300354
[10/24] Train loss=0.1264621615409851
[15/24] Train loss=0.138238325715065
[20/24] Train loss=0.13061073422431946
Test set avg_accuracy=84.44% avg_sensitivity=67.00%, avg_specificity=90.67% avg_auc=88.33%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.131147 Test loss=0.383097 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12360305339097977
[5/24] Train loss=0.12111413478851318
[10/24] Train loss=0.12148323655128479
[15/24] Train loss=0.136725053191185
[20/24] Train loss=0.12984764575958252
Test set avg_accuracy=83.75% avg_sensitivity=77.83%, avg_specificity=85.86% avg_auc=89.48%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.130033 Test loss=0.389526 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12277574092149734
[5/24] Train loss=0.12162873893976212
[10/24] Train loss=0.12148794531822205
[15/24] Train loss=0.1325703263282776
[20/24] Train loss=0.13038603961467743
Test set avg_accuracy=84.87% avg_sensitivity=71.90%, avg_specificity=89.50% avg_auc=88.85%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.129825 Test loss=0.375951 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12119144201278687
[5/24] Train loss=0.12194468080997467
[10/24] Train loss=0.12375245243310928
[15/24] Train loss=0.1367853283882141
[20/24] Train loss=0.1276259869337082
Test set avg_accuracy=85.10% avg_sensitivity=71.25%, avg_specificity=90.05% avg_auc=89.41%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.128398 Test loss=0.365723 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12244786322116852
[5/24] Train loss=0.12119775265455246
[10/24] Train loss=0.11922048032283783
[15/24] Train loss=0.1337587535381317
[20/24] Train loss=0.12720224261283875
Test set avg_accuracy=83.72% avg_sensitivity=77.73%, avg_specificity=85.86% avg_auc=89.34%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.127905 Test loss=0.392492 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12063497304916382
[5/24] Train loss=0.11760000139474869
[10/24] Train loss=0.1215369924902916
[15/24] Train loss=0.1343492567539215
[20/24] Train loss=0.1263905167579651
Test set avg_accuracy=84.40% avg_sensitivity=75.51%, avg_specificity=87.58% avg_auc=89.68%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.126750 Test loss=0.375332 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12024421989917755
[5/24] Train loss=0.11728911101818085
[10/24] Train loss=0.12169748544692993
[15/24] Train loss=0.12875407934188843
[20/24] Train loss=0.12475505471229553
Test set avg_accuracy=85.53% avg_sensitivity=70.16%, avg_specificity=91.02% avg_auc=89.60%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.126191 Test loss=0.358450 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.11788550764322281
[5/24] Train loss=0.11703570187091827
[10/24] Train loss=0.11892448365688324
[15/24] Train loss=0.13167977333068848
[20/24] Train loss=0.1250186562538147
Test set avg_accuracy=85.47% avg_sensitivity=72.14%, avg_specificity=90.23% avg_auc=89.90%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.125161 Test loss=0.359692 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.11976258456707001
[5/24] Train loss=0.11441110074520111
[10/24] Train loss=0.1226080134510994
[15/24] Train loss=0.12938424944877625
[20/24] Train loss=0.12344478815793991
Test set avg_accuracy=85.42% avg_sensitivity=73.53%, avg_specificity=89.66% avg_auc=89.87%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.124755 Test loss=0.361802 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12091145664453506
[5/24] Train loss=0.11630545556545258
[10/24] Train loss=0.11869057267904282
[15/24] Train loss=0.12907588481903076
[20/24] Train loss=0.12619826197624207
Test set avg_accuracy=85.17% avg_sensitivity=74.07%, avg_specificity=89.13% avg_auc=89.79%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.124497 Test loss=0.365586 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.11932483315467834
[5/24] Train loss=0.11595583707094193
[10/24] Train loss=0.1221957728266716
[15/24] Train loss=0.1283482313156128
[20/24] Train loss=0.1268572360277176
Test set avg_accuracy=85.10% avg_sensitivity=72.54%, avg_specificity=89.59% avg_auc=89.83%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.123500 Test loss=0.363262 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.11755171418190002
[5/24] Train loss=0.11932253837585449
[10/24] Train loss=0.11987931281328201
[15/24] Train loss=0.12704713642597198
[20/24] Train loss=0.12253186851739883
Test set avg_accuracy=85.27% avg_sensitivity=71.94%, avg_specificity=90.03% avg_auc=89.59%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.123022 Test loss=0.365696 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1175091490149498
[5/24] Train loss=0.11316806823015213
[10/24] Train loss=0.11808913946151733
[15/24] Train loss=0.12376416474580765
[20/24] Train loss=0.12971194088459015
Test set avg_accuracy=85.48% avg_sensitivity=72.04%, avg_specificity=90.28% avg_auc=89.77%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.122459 Test loss=0.362032 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.11885187774896622
[5/24] Train loss=0.11563217639923096
[10/24] Train loss=0.11595994979143143
[15/24] Train loss=0.12619102001190186
[20/24] Train loss=0.1252843290567398
Test set avg_accuracy=85.01% avg_sensitivity=72.29%, avg_specificity=89.56% avg_auc=89.83%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.122550 Test loss=0.362475 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.11657161265611649
[5/24] Train loss=0.11442282050848007
[10/24] Train loss=0.11910425871610641
[15/24] Train loss=0.1281164586544037
[20/24] Train loss=0.12499117106199265
Test set avg_accuracy=85.44% avg_sensitivity=71.80%, avg_specificity=90.32% avg_auc=89.60%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.122561 Test loss=0.363102 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.11709477752447128
[5/24] Train loss=0.11555454879999161
[10/24] Train loss=0.11601881682872772
[15/24] Train loss=0.12725183367729187
[20/24] Train loss=0.1240352913737297
Test set avg_accuracy=85.52% avg_sensitivity=71.00%, avg_specificity=90.71% avg_auc=89.42%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.121944 Test loss=0.363944 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1143360286951065
[5/24] Train loss=0.11356692761182785
[10/24] Train loss=0.1167786493897438
[15/24] Train loss=0.12699222564697266
[20/24] Train loss=0.12263654917478561
Test set avg_accuracy=85.03% avg_sensitivity=72.44%, avg_specificity=89.52% avg_auc=89.58%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.121404 Test loss=0.367436 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.11530816555023193
[5/24] Train loss=0.11248145997524261
[10/24] Train loss=0.11764779686927795
[15/24] Train loss=0.1262720674276352
[20/24] Train loss=0.12414556741714478
Test set avg_accuracy=85.13% avg_sensitivity=72.59%, avg_specificity=89.61% avg_auc=89.71%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.121481 Test loss=0.363266 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11625075340270996
[5/24] Train loss=0.11262838542461395
[10/24] Train loss=0.11610222607851028
[15/24] Train loss=0.1250867247581482
[20/24] Train loss=0.12180204689502716
Test set avg_accuracy=85.33% avg_sensitivity=72.34%, avg_specificity=89.96% avg_auc=89.76%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.121880 Test loss=0.362843 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.11578391492366791
[5/24] Train loss=0.11213613301515579
[10/24] Train loss=0.11527647078037262
[15/24] Train loss=0.1285068392753601
[20/24] Train loss=0.12204252928495407
Test set avg_accuracy=85.39% avg_sensitivity=71.99%, avg_specificity=90.17% avg_auc=89.67%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.121544 Test loss=0.364007 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11768616735935211
[5/24] Train loss=0.11266864091157913
[10/24] Train loss=0.11822783201932907
[15/24] Train loss=0.12470702081918716
[20/24] Train loss=0.12191534042358398
Test set avg_accuracy=85.46% avg_sensitivity=71.70%, avg_specificity=90.37% avg_auc=89.56%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.121024 Test loss=0.364527 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11567838490009308
[5/24] Train loss=0.11379368603229523
[10/24] Train loss=0.11669804900884628
[15/24] Train loss=0.12370879203081131
[20/24] Train loss=0.12326005101203918
Test set avg_accuracy=85.34% avg_sensitivity=71.65%, avg_specificity=90.23% avg_auc=89.60%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.121380 Test loss=0.364313 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11799021810293198
[5/24] Train loss=0.11473406106233597
[10/24] Train loss=0.11596065014600754
[15/24] Train loss=0.12448415905237198
[20/24] Train loss=0.12182815372943878
Test set avg_accuracy=85.26% avg_sensitivity=71.75%, avg_specificity=90.09% avg_auc=89.63%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.121433 Test loss=0.364342 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11592091619968414
[5/24] Train loss=0.11313110589981079
[10/24] Train loss=0.11577003449201584
[15/24] Train loss=0.12422619760036469
[20/24] Train loss=0.12416671961545944
Test set avg_accuracy=85.20% avg_sensitivity=71.90%, avg_specificity=89.95% avg_auc=89.65%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.121283 Test loss=0.364145 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11391190439462662
[5/24] Train loss=0.11273066699504852
[10/24] Train loss=0.11562460660934448
[15/24] Train loss=0.12469042837619781
[20/24] Train loss=0.12193300575017929
Test set avg_accuracy=85.36% avg_sensitivity=71.75%, avg_specificity=90.23% avg_auc=89.62%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.120721 Test loss=0.364062 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11854865401983261
[5/24] Train loss=0.11189521849155426
[10/24] Train loss=0.11891813576221466
[15/24] Train loss=0.12548941373825073
[20/24] Train loss=0.12307817488908768
Test set avg_accuracy=85.29% avg_sensitivity=71.80%, avg_specificity=90.10% avg_auc=89.63%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.120813 Test loss=0.363852 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=85.73% sen=77.14%, spe=88.80%, auc=92.06%!
Fold[1] Avg_overlap=0.65%(±0.19107496954028014)
[0/24] Train loss=0.7162091135978699
[5/24] Train loss=0.7114078998565674
[10/24] Train loss=0.7003840208053589
[15/24] Train loss=0.7005170583724976
[20/24] Train loss=0.6902494430541992
Test set avg_accuracy=53.53% avg_sensitivity=57.02%, avg_specificity=52.37% avg_auc=57.73%
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.702545 Test loss=0.694510 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6799288988113403
[5/24] Train loss=0.6802595853805542
[10/24] Train loss=0.6729816794395447
[15/24] Train loss=0.6764448881149292
[20/24] Train loss=0.6670826077461243
Test set avg_accuracy=64.84% avg_sensitivity=69.38%, avg_specificity=63.34% avg_auc=72.24%
Best model saved!! Metric=-56.197245518421944!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.672303 Test loss=0.630597 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6555891633033752
[5/24] Train loss=0.6472435593605042
[10/24] Train loss=0.6417641043663025
[15/24] Train loss=0.6436694860458374
[20/24] Train loss=0.6347439289093018
Test set avg_accuracy=69.48% avg_sensitivity=73.66%, avg_specificity=68.09% avg_auc=76.30%
Best model saved!! Metric=-38.47764576918517!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.648557 Test loss=0.600889 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6314519643783569
[5/24] Train loss=0.620493471622467
[10/24] Train loss=0.6163883805274963
[15/24] Train loss=0.6082002520561218
[20/24] Train loss=0.6117612719535828
Test set avg_accuracy=71.05% avg_sensitivity=75.22%, avg_specificity=69.67% avg_auc=78.35%
Best model saved!! Metric=-31.70982693928771!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.622745 Test loss=0.579790 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6021900773048401
[5/24] Train loss=0.5989115834236145
[10/24] Train loss=0.5899716019630432
[15/24] Train loss=0.5832203030586243
[20/24] Train loss=0.5898727774620056
Test set avg_accuracy=72.16% avg_sensitivity=75.90%, avg_specificity=70.92% avg_auc=80.36%
Best model saved!! Metric=-26.665416217872988!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.597535 Test loss=0.557771 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5814594626426697
[5/24] Train loss=0.5701830387115479
[10/24] Train loss=0.561988353729248
[15/24] Train loss=0.5640522241592407
[20/24] Train loss=0.5590646266937256
Test set avg_accuracy=74.04% avg_sensitivity=75.80%, avg_specificity=73.45% avg_auc=82.19%
Best model saved!! Metric=-20.525888427354957!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.573354 Test loss=0.529543 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5560013651847839
[5/24] Train loss=0.5392270684242249
[10/24] Train loss=0.5373805165290833
[15/24] Train loss=0.5317137837409973
[20/24] Train loss=0.538999080657959
Test set avg_accuracy=76.34% avg_sensitivity=74.18%, avg_specificity=77.06% avg_auc=83.54%
Best model saved!! Metric=-14.875568169102095!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.545876 Test loss=0.501692 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5222724080085754
[5/24] Train loss=0.5055378675460815
[10/24] Train loss=0.5099496245384216
[15/24] Train loss=0.5071762800216675
[20/24] Train loss=0.5088606476783752
Test set avg_accuracy=77.93% avg_sensitivity=73.55%, avg_specificity=79.39% avg_auc=84.58%
Best model saved!! Metric=-10.55666822149098!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.519854 Test loss=0.477935 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.49021488428115845
[5/24] Train loss=0.48261207342147827
[10/24] Train loss=0.48223885893821716
[15/24] Train loss=0.4776013195514679
[20/24] Train loss=0.47602325677871704
Test set avg_accuracy=79.51% avg_sensitivity=71.88%, avg_specificity=82.04% avg_auc=85.37%
Best model saved!! Metric=-7.196861813397149!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.493742 Test loss=0.456921 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.47010338306427
[5/24] Train loss=0.4577415883541107
[10/24] Train loss=0.4565381407737732
[15/24] Train loss=0.449954092502594
[20/24] Train loss=0.4504725933074951
Test set avg_accuracy=80.86% avg_sensitivity=70.79%, avg_specificity=84.21% avg_auc=86.21%
Best model saved!! Metric=-3.9331342990187608!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.469216 Test loss=0.438764 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4466277062892914
[5/24] Train loss=0.43574970960617065
[10/24] Train loss=0.43794137239456177
[15/24] Train loss=0.42693421244621277
[20/24] Train loss=0.42150747776031494
Test set avg_accuracy=81.76% avg_sensitivity=69.17%, avg_specificity=85.94% avg_auc=86.85%
Best model saved!! Metric=-2.2779671679499103!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.447037 Test loss=0.417963 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4178454875946045
[5/24] Train loss=0.4125853478908539
[10/24] Train loss=0.41958320140838623
[15/24] Train loss=0.4047561287879944
[20/24] Train loss=0.4041846692562103
Test set avg_accuracy=82.43% avg_sensitivity=68.75%, avg_specificity=86.99% avg_auc=87.71%
Best model saved!! Metric=-0.11892442434815109!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.425644 Test loss=0.402878 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.402899831533432
[5/24] Train loss=0.39609846472740173
[10/24] Train loss=0.3967128396034241
[15/24] Train loss=0.39152243733406067
[20/24] Train loss=0.3821727931499481
Test set avg_accuracy=83.12% avg_sensitivity=66.61%, avg_specificity=88.62% avg_auc=88.11%
Best model saved!! Metric=0.46792268479032373!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.407926 Test loss=0.386961 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.38411328196525574
[5/24] Train loss=0.37416765093803406
[10/24] Train loss=0.3875763714313507
[15/24] Train loss=0.37365463376045227
[20/24] Train loss=0.36670470237731934
Test set avg_accuracy=83.45% avg_sensitivity=68.70%, avg_specificity=88.36% avg_auc=88.58%
Best model saved!! Metric=3.085596316663711!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.391799 Test loss=0.382071 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.36946743726730347
[5/24] Train loss=0.3684704005718231
[10/24] Train loss=0.374407559633255
[15/24] Train loss=0.35462477803230286
[20/24] Train loss=0.34519878029823303
Test set avg_accuracy=82.94% avg_sensitivity=71.47%, avg_specificity=86.76% avg_auc=89.16%
Best model saved!! Metric=4.32474025662286!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.377253 Test loss=0.380503 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.35669630765914917
[5/24] Train loss=0.349704384803772
[10/24] Train loss=0.36445531249046326
[15/24] Train loss=0.34137392044067383
[20/24] Train loss=0.3318325877189636
Test set avg_accuracy=82.51% avg_sensitivity=73.55%, avg_specificity=85.49% avg_auc=89.38%
Best model saved!! Metric=4.94033641867253!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.364969 Test loss=0.381341 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.34334805607795715
[5/24] Train loss=0.3469073176383972
[10/24] Train loss=0.34815534949302673
[15/24] Train loss=0.3325994908809662
[20/24] Train loss=0.32123973965644836
Test set avg_accuracy=84.08% avg_sensitivity=71.31%, avg_specificity=88.32% avg_auc=89.89%
Best model saved!! Metric=7.6010090561451875!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.353443 Test loss=0.359604 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3337089717388153
[5/24] Train loss=0.33339110016822815
[10/24] Train loss=0.34172746539115906
[15/24] Train loss=0.32519182562828064
[20/24] Train loss=0.31431514024734497
Test set avg_accuracy=83.85% avg_sensitivity=72.67%, avg_specificity=87.58% avg_auc=89.98%
Best model saved!! Metric=8.077621003784401!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.345808 Test loss=0.361555 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.31969359517097473
[5/24] Train loss=0.33637747168540955
[10/24] Train loss=0.3339017331600189
[15/24] Train loss=0.31375420093536377
[20/24] Train loss=0.30469566583633423
Test set avg_accuracy=82.41% avg_sensitivity=78.09%, avg_specificity=83.85% avg_auc=89.59%
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.337686 Test loss=0.386229 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3173982799053192
[5/24] Train loss=0.3309227228164673
[10/24] Train loss=0.321406751871109
[15/24] Train loss=0.31101933121681213
[20/24] Train loss=0.2954229414463043
Test set avg_accuracy=83.15% avg_sensitivity=77.26%, avg_specificity=85.11% avg_auc=89.80%
Best model saved!! Metric=9.3158373054941!!
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.329828 Test loss=0.379170 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.306314617395401
[5/24] Train loss=0.326538622379303
[10/24] Train loss=0.31652578711509705
[15/24] Train loss=0.3023410439491272
[20/24] Train loss=0.2930292785167694
Test set avg_accuracy=84.66% avg_sensitivity=72.20%, avg_specificity=88.81% avg_auc=90.41%
Best model saved!! Metric=10.074602334453559!!
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.321743 Test loss=0.346363 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3018174469470978
[5/24] Train loss=0.326941579580307
[10/24] Train loss=0.3115496039390564
[15/24] Train loss=0.2892484962940216
[20/24] Train loss=0.2785782217979431
Test set avg_accuracy=85.16% avg_sensitivity=72.35%, avg_specificity=89.42% avg_auc=90.86%
Best model saved!! Metric=11.783686135634383!!
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.314420 Test loss=0.338908 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2889194190502167
[5/24] Train loss=0.31551751494407654
[10/24] Train loss=0.30273279547691345
[15/24] Train loss=0.2814522385597229
[20/24] Train loss=0.27877411246299744
Test set avg_accuracy=85.49% avg_sensitivity=63.38%, avg_specificity=92.85% avg_auc=90.86%
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.307057 Test loss=0.327669 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2868465185165405
[5/24] Train loss=0.31336697936058044
[10/24] Train loss=0.29058584570884705
[15/24] Train loss=0.27763456106185913
[20/24] Train loss=0.269302636384964
Test set avg_accuracy=83.72% avg_sensitivity=44.97%, avg_specificity=96.62% avg_auc=89.44%
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.302017 Test loss=0.370166 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.26987001299858093
[5/24] Train loss=0.2904939353466034
[10/24] Train loss=0.2854008376598358
[15/24] Train loss=0.2706259787082672
[20/24] Train loss=0.26804104447364807
Test set avg_accuracy=85.07% avg_sensitivity=53.83%, avg_specificity=95.45% avg_auc=90.41%
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.296120 Test loss=0.341464 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.27078571915626526
[5/24] Train loss=0.29080480337142944
[10/24] Train loss=0.27399593591690063
[15/24] Train loss=0.26423653960227966
[20/24] Train loss=0.25619056820869446
Test set avg_accuracy=85.03% avg_sensitivity=56.55%, avg_specificity=94.50% avg_auc=90.44%
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.287339 Test loss=0.338926 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.25743597745895386
[5/24] Train loss=0.2785010039806366
[10/24] Train loss=0.2824056148529053
[15/24] Train loss=0.24829664826393127
[20/24] Train loss=0.26185715198516846
Test set avg_accuracy=84.04% avg_sensitivity=49.87%, avg_specificity=95.40% avg_auc=89.68%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.282396 Test loss=0.359015 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2571389377117157
[5/24] Train loss=0.27669966220855713
[10/24] Train loss=0.2713574171066284
[15/24] Train loss=0.24215379357337952
[20/24] Train loss=0.25378745794296265
Test set avg_accuracy=83.10% avg_sensitivity=40.38%, avg_specificity=97.31% avg_auc=87.41%
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.275905 Test loss=0.420866 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2471083104610443
[5/24] Train loss=0.2677296996116638
[10/24] Train loss=0.26290053129196167
[15/24] Train loss=0.24264146387577057
[20/24] Train loss=0.2502908408641815
Test set avg_accuracy=83.53% avg_sensitivity=45.33%, avg_specificity=96.23% avg_auc=88.91%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.272021 Test loss=0.382407 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2495262622833252
[5/24] Train loss=0.2564034163951874
[10/24] Train loss=0.26851600408554077
[15/24] Train loss=0.24598722159862518
[20/24] Train loss=0.24542854726314545
Test set avg_accuracy=84.21% avg_sensitivity=50.86%, avg_specificity=95.30% avg_auc=88.50%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.269322 Test loss=0.367987 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.23557311296463013
[5/24] Train loss=0.25346601009368896
[10/24] Train loss=0.25733682513237
[15/24] Train loss=0.2286658138036728
[20/24] Train loss=0.233794704079628
Test set avg_accuracy=84.64% avg_sensitivity=54.67%, avg_specificity=94.60% avg_auc=88.81%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.261355 Test loss=0.366068 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.22783328592777252
[5/24] Train loss=0.26775985956192017
[10/24] Train loss=0.25800788402557373
[15/24] Train loss=0.2272060215473175
[20/24] Train loss=0.2414640486240387
Test set avg_accuracy=80.90% avg_sensitivity=28.17%, avg_specificity=98.44% avg_auc=82.35%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.256372 Test loss=0.509868 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.23086099326610565
[5/24] Train loss=0.26607662439346313
[10/24] Train loss=0.24614907801151276
[15/24] Train loss=0.22244355082511902
[20/24] Train loss=0.2330044060945511
Test set avg_accuracy=83.02% avg_sensitivity=43.19%, avg_specificity=96.27% avg_auc=87.21%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.251469 Test loss=0.401452 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.22508814930915833
[5/24] Train loss=0.24870489537715912
[10/24] Train loss=0.2297564148902893
[15/24] Train loss=0.22840987145900726
[20/24] Train loss=0.21785250306129456
Test set avg_accuracy=84.00% avg_sensitivity=54.46%, avg_specificity=93.82% avg_auc=88.75%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.245031 Test loss=0.368230 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.22093413770198822
[5/24] Train loss=0.23707257211208344
[10/24] Train loss=0.23441576957702637
[15/24] Train loss=0.23033690452575684
[20/24] Train loss=0.2296847552061081
Test set avg_accuracy=83.18% avg_sensitivity=43.87%, avg_specificity=96.25% avg_auc=87.36%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.245001 Test loss=0.394351 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2372225821018219
[5/24] Train loss=0.2469099909067154
[10/24] Train loss=0.2325877994298935
[15/24] Train loss=0.22077929973602295
[20/24] Train loss=0.22038698196411133
Test set avg_accuracy=84.11% avg_sensitivity=47.84%, avg_specificity=96.18% avg_auc=88.53%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.243348 Test loss=0.371412 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.22302556037902832
[5/24] Train loss=0.23291416466236115
[10/24] Train loss=0.22427387535572052
[15/24] Train loss=0.21339498460292816
[20/24] Train loss=0.21840150654315948
Test set avg_accuracy=78.85% avg_sensitivity=33.18%, avg_specificity=94.05% avg_auc=77.77%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.233238 Test loss=0.524336 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.24346190690994263
[5/24] Train loss=0.26844069361686707
[10/24] Train loss=0.23984071612358093
[15/24] Train loss=0.21292881667613983
[20/24] Train loss=0.2129140943288803
Test set avg_accuracy=81.48% avg_sensitivity=30.78%, avg_specificity=98.35% avg_auc=84.90%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.237637 Test loss=0.480973 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.20870375633239746
[5/24] Train loss=0.23101754486560822
[10/24] Train loss=0.24048377573490143
[15/24] Train loss=0.2169838696718216
[20/24] Train loss=0.20416082441806793
Test set avg_accuracy=83.31% avg_sensitivity=42.83%, avg_specificity=96.77% avg_auc=85.03%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.233010 Test loss=0.449842 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2035711407661438
[5/24] Train loss=0.23452603816986084
[10/24] Train loss=0.23750343918800354
[15/24] Train loss=0.21616989374160767
[20/24] Train loss=0.20926393568515778
Test set avg_accuracy=76.50% avg_sensitivity=7.30%, avg_specificity=99.51% avg_auc=65.68%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.231282 Test loss=0.786147 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.23478960990905762
[5/24] Train loss=0.22524552047252655
[10/24] Train loss=0.23043903708457947
[15/24] Train loss=0.21793346107006073
[20/24] Train loss=0.21020565927028656
Test set avg_accuracy=77.11% avg_sensitivity=9.96%, avg_specificity=99.44% avg_auc=74.85%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.231314 Test loss=0.672572 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.20760577917099
[5/24] Train loss=0.21208001673221588
[10/24] Train loss=0.233291894197464
[15/24] Train loss=0.21548724174499512
[20/24] Train loss=0.21050149202346802
Test set avg_accuracy=77.40% avg_sensitivity=12.05%, avg_specificity=99.13% avg_auc=75.10%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.225567 Test loss=0.664740 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2051263302564621
[5/24] Train loss=0.22482256591320038
[10/24] Train loss=0.22162874042987823
[15/24] Train loss=0.21579158306121826
[20/24] Train loss=0.2215181440114975
Test set avg_accuracy=78.58% avg_sensitivity=17.06%, avg_specificity=99.05% avg_auc=78.03%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.223976 Test loss=0.648409 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.21067455410957336
[5/24] Train loss=0.21172603964805603
[10/24] Train loss=0.21823590993881226
[15/24] Train loss=0.20258504152297974
[20/24] Train loss=0.21320326626300812
Test set avg_accuracy=78.85% avg_sensitivity=18.31%, avg_specificity=98.99% avg_auc=72.73%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.225132 Test loss=0.712582 Current lr=[0.00029967723776099]

[0/24] Train loss=0.19079679250717163
[5/24] Train loss=0.21595856547355652
[10/24] Train loss=0.2128574252128601
[15/24] Train loss=0.21724021434783936
[20/24] Train loss=0.19673332571983337
Test set avg_accuracy=82.89% avg_sensitivity=38.97%, avg_specificity=97.50% avg_auc=81.32%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.219192 Test loss=0.517191 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.19007903337478638
[5/24] Train loss=0.2060636281967163
[10/24] Train loss=0.21592101454734802
[15/24] Train loss=0.21336258947849274
[20/24] Train loss=0.21122071146965027
Test set avg_accuracy=78.02% avg_sensitivity=13.93%, avg_specificity=99.34% avg_auc=72.15%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.219568 Test loss=0.718657 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2027696967124939
[5/24] Train loss=0.2039511799812317
[10/24] Train loss=0.21065805852413177
[15/24] Train loss=0.195053368806839
[20/24] Train loss=0.1884327083826065
Test set avg_accuracy=79.88% avg_sensitivity=22.59%, avg_specificity=98.94% avg_auc=77.07%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.215711 Test loss=0.642977 Current lr=[0.000299720220882401]

[0/24] Train loss=0.20250204205513
[5/24] Train loss=0.2047213912010193
[10/24] Train loss=0.21384325623512268
[15/24] Train loss=0.20649297535419464
[20/24] Train loss=0.20339129865169525
Test set avg_accuracy=78.97% avg_sensitivity=18.41%, avg_specificity=99.12% avg_auc=70.59%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.214722 Test loss=0.747844 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19324201345443726
[5/24] Train loss=0.22952808439731598
[10/24] Train loss=0.21900705993175507
[15/24] Train loss=0.20310500264167786
[20/24] Train loss=0.18757162988185883
Test set avg_accuracy=82.43% avg_sensitivity=35.58%, avg_specificity=98.02% avg_auc=86.07%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.213546 Test loss=0.430327 Current lr=[0.000298904600941902]

[0/24] Train loss=0.17853492498397827
[5/24] Train loss=0.20610244572162628
[10/24] Train loss=0.20527760684490204
[15/24] Train loss=0.19777871668338776
[20/24] Train loss=0.18700560927391052
Test set avg_accuracy=83.74% avg_sensitivity=44.71%, avg_specificity=96.72% avg_auc=87.78%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.207907 Test loss=0.402389 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.18331976234912872
[5/24] Train loss=0.21376678347587585
[10/24] Train loss=0.20821532607078552
[15/24] Train loss=0.2050783932209015
[20/24] Train loss=0.1888437718153
Test set avg_accuracy=84.73% avg_sensitivity=53.47%, avg_specificity=95.12% avg_auc=87.36%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.206666 Test loss=0.393441 Current lr=[0.000297555943323901]

[0/24] Train loss=0.18414095044136047
[5/24] Train loss=0.19570431113243103
[10/24] Train loss=0.21505989134311676
[15/24] Train loss=0.2022687792778015
[20/24] Train loss=0.19535663723945618
Test set avg_accuracy=80.92% avg_sensitivity=28.01%, avg_specificity=98.53% avg_auc=76.88%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.207620 Test loss=0.585396 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.18831804394721985
[5/24] Train loss=0.19715586304664612
[10/24] Train loss=0.2098369002342224
[15/24] Train loss=0.20483149588108063
[20/24] Train loss=0.17482782900333405
Test set avg_accuracy=83.61% avg_sensitivity=53.05%, avg_specificity=93.77% avg_auc=87.41%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.210076 Test loss=0.405032 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.1892552226781845
[5/24] Train loss=0.21993260085582733
[10/24] Train loss=0.19923456013202667
[15/24] Train loss=0.19812947511672974
[20/24] Train loss=0.19221343100070953
Test set avg_accuracy=81.16% avg_sensitivity=35.42%, avg_specificity=96.37% avg_auc=78.68%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.209508 Test loss=0.520552 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.18670858442783356
[5/24] Train loss=0.20752409100532532
[10/24] Train loss=0.2179637998342514
[15/24] Train loss=0.19958297908306122
[20/24] Train loss=0.18083198368549347
Test set avg_accuracy=84.19% avg_sensitivity=51.07%, avg_specificity=95.21% avg_auc=88.72%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.208101 Test loss=0.384095 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.18781475722789764
[5/24] Train loss=0.23483823239803314
[10/24] Train loss=0.21503548324108124
[15/24] Train loss=0.20424045622348785
[20/24] Train loss=0.18750938773155212
Test set avg_accuracy=85.49% avg_sensitivity=65.15%, avg_specificity=92.26% avg_auc=90.02%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.210703 Test loss=0.357780 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.18374624848365784
[5/24] Train loss=0.20577622950077057
[10/24] Train loss=0.21305133402347565
[15/24] Train loss=0.18887124955654144
[20/24] Train loss=0.19791115820407867
Test set avg_accuracy=85.34% avg_sensitivity=66.41%, avg_specificity=91.64% avg_auc=89.65%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.206174 Test loss=0.351681 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.18300305306911469
[5/24] Train loss=0.21053797006607056
[10/24] Train loss=0.19976848363876343
[15/24] Train loss=0.20040103793144226
[20/24] Train loss=0.17811007797718048
Test set avg_accuracy=83.58% avg_sensitivity=76.00%, avg_specificity=86.10% avg_auc=89.76%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.204765 Test loss=0.385623 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.1853986382484436
[5/24] Train loss=0.20861420035362244
[10/24] Train loss=0.20724907517433167
[15/24] Train loss=0.19909490644931793
[20/24] Train loss=0.18248824775218964
Test set avg_accuracy=81.69% avg_sensitivity=78.30%, avg_specificity=82.82% avg_auc=88.90%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.205702 Test loss=0.423344 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.1874234676361084
[5/24] Train loss=0.21622787415981293
[10/24] Train loss=0.197027787566185
[15/24] Train loss=0.19840849936008453
[20/24] Train loss=0.18348659574985504
Test set avg_accuracy=82.99% avg_sensitivity=75.53%, avg_specificity=85.48% avg_auc=88.40%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.202452 Test loss=0.412893 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.18190482258796692
[5/24] Train loss=0.1993294209241867
[10/24] Train loss=0.20872028172016144
[15/24] Train loss=0.19442349672317505
[20/24] Train loss=0.1829993575811386
Test set avg_accuracy=85.90% avg_sensitivity=65.83%, avg_specificity=92.57% avg_auc=90.04%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.200259 Test loss=0.348556 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.17579810321331024
[5/24] Train loss=0.19845208525657654
[10/24] Train loss=0.19366854429244995
[15/24] Train loss=0.1948881894350052
[20/24] Train loss=0.1858319491147995
Test set avg_accuracy=84.95% avg_sensitivity=62.02%, avg_specificity=92.57% avg_auc=87.47%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.199398 Test loss=0.382526 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.1791403889656067
[5/24] Train loss=0.2071787565946579
[10/24] Train loss=0.18097306787967682
[15/24] Train loss=0.1780211180448532
[20/24] Train loss=0.18654440343379974
Test set avg_accuracy=80.49% avg_sensitivity=83.31%, avg_specificity=79.56% avg_auc=89.20%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.192887 Test loss=0.429986 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.1746087521314621
[5/24] Train loss=0.2069397270679474
[10/24] Train loss=0.19298961758613586
[15/24] Train loss=0.19819295406341553
[20/24] Train loss=0.18967467546463013
Test set avg_accuracy=84.23% avg_sensitivity=68.08%, avg_specificity=89.61% avg_auc=89.53%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.195653 Test loss=0.355520 Current lr=[0.000276307469034998]

[0/24] Train loss=0.16682381927967072
[5/24] Train loss=0.19850683212280273
[10/24] Train loss=0.19638562202453613
[15/24] Train loss=0.19543969631195068
[20/24] Train loss=0.17321661114692688
Test set avg_accuracy=80.98% avg_sensitivity=81.90%, avg_specificity=80.67% avg_auc=88.40%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.191744 Test loss=0.432774 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.17499709129333496
[5/24] Train loss=0.19751887023448944
[10/24] Train loss=0.17606116831302643
[15/24] Train loss=0.18367479741573334
[20/24] Train loss=0.1725805550813675
Test set avg_accuracy=74.26% avg_sensitivity=89.15%, avg_specificity=69.30% avg_auc=87.52%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.188433 Test loss=0.558231 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.1659976840019226
[5/24] Train loss=0.2039291262626648
[10/24] Train loss=0.1799880415201187
[15/24] Train loss=0.1772869974374771
[20/24] Train loss=0.17653115093708038
Test set avg_accuracy=84.01% avg_sensitivity=77.05%, avg_specificity=86.33% avg_auc=89.13%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.188764 Test loss=0.371655 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.17765700817108154
[5/24] Train loss=0.20613694190979004
[10/24] Train loss=0.18569305539131165
[15/24] Train loss=0.18276149034500122
[20/24] Train loss=0.17271560430526733
Test set avg_accuracy=79.56% avg_sensitivity=82.37%, avg_specificity=78.62% avg_auc=88.47%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.191362 Test loss=0.452651 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.17203634977340698
[5/24] Train loss=0.18532820045948029
[10/24] Train loss=0.1887444704771042
[15/24] Train loss=0.17140047252178192
[20/24] Train loss=0.16749964654445648
Test set avg_accuracy=84.51% avg_sensitivity=73.08%, avg_specificity=88.30% avg_auc=89.14%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.183889 Test loss=0.371689 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.16115723550319672
[5/24] Train loss=0.18866842985153198
[10/24] Train loss=0.1943412572145462
[15/24] Train loss=0.18158181011676788
[20/24] Train loss=0.16388851404190063
Test set avg_accuracy=84.60% avg_sensitivity=69.07%, avg_specificity=89.76% avg_auc=88.97%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.185491 Test loss=0.364552 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.168001189827919
[5/24] Train loss=0.18034903705120087
[10/24] Train loss=0.17598995566368103
[15/24] Train loss=0.1780708134174347
[20/24] Train loss=0.16288290917873383
Test set avg_accuracy=84.71% avg_sensitivity=60.09%, avg_specificity=92.90% avg_auc=85.73%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.180752 Test loss=0.418071 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.1680832952260971
[5/24] Train loss=0.1840253621339798
[10/24] Train loss=0.1741843968629837
[15/24] Train loss=0.17542363703250885
[20/24] Train loss=0.16101469099521637
Test set avg_accuracy=84.48% avg_sensitivity=69.48%, avg_specificity=89.47% avg_auc=88.95%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.178857 Test loss=0.370931 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.1611478179693222
[5/24] Train loss=0.18523378670215607
[10/24] Train loss=0.17382584512233734
[15/24] Train loss=0.1850195974111557
[20/24] Train loss=0.1705387979745865
Test set avg_accuracy=78.71% avg_sensitivity=86.54%, avg_specificity=76.11% avg_auc=88.94%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.179580 Test loss=0.478339 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.16373294591903687
[5/24] Train loss=0.1847897320985794
[10/24] Train loss=0.17759406566619873
[15/24] Train loss=0.172514408826828
[20/24] Train loss=0.16433502733707428
Test set avg_accuracy=83.97% avg_sensitivity=48.72%, avg_specificity=95.70% avg_auc=82.03%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.178237 Test loss=0.465131 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.15256604552268982
[5/24] Train loss=0.18332301080226898
[10/24] Train loss=0.1786486655473709
[15/24] Train loss=0.17625343799591064
[20/24] Train loss=0.16024009883403778
Test set avg_accuracy=84.01% avg_sensitivity=47.78%, avg_specificity=96.06% avg_auc=84.00%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.179076 Test loss=0.447050 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.16545292735099792
[5/24] Train loss=0.18236590921878815
[10/24] Train loss=0.1842222958803177
[15/24] Train loss=0.172784686088562
[20/24] Train loss=0.16739661991596222
Test set avg_accuracy=82.12% avg_sensitivity=80.28%, avg_specificity=82.73% avg_auc=88.73%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.180097 Test loss=0.432703 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.15673401951789856
[5/24] Train loss=0.1816694289445877
[10/24] Train loss=0.17174173891544342
[15/24] Train loss=0.17597384750843048
[20/24] Train loss=0.15741132199764252
Test set avg_accuracy=83.41% avg_sensitivity=42.20%, avg_specificity=97.12% avg_auc=80.17%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.178091 Test loss=0.495220 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.1591283231973648
[5/24] Train loss=0.18153613805770874
[10/24] Train loss=0.19029761850833893
[15/24] Train loss=0.1645793318748474
[20/24] Train loss=0.15452751517295837
Test set avg_accuracy=84.47% avg_sensitivity=51.75%, avg_specificity=95.35% avg_auc=83.51%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.176896 Test loss=0.445210 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.1556927114725113
[5/24] Train loss=0.17147187888622284
[10/24] Train loss=0.16641660034656525
[15/24] Train loss=0.16027338802814484
[20/24] Train loss=0.16034524142742157
Test set avg_accuracy=80.95% avg_sensitivity=29.00%, avg_specificity=98.23% avg_auc=77.12%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.172888 Test loss=0.592696 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.15451101958751678
[5/24] Train loss=0.17787890136241913
[10/24] Train loss=0.17070692777633667
[15/24] Train loss=0.1766166388988495
[20/24] Train loss=0.16902050375938416
Test set avg_accuracy=83.27% avg_sensitivity=42.93%, avg_specificity=96.69% avg_auc=83.07%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.173280 Test loss=0.476241 Current lr=[0.000224838296036774]

[0/24] Train loss=0.16106395423412323
[5/24] Train loss=0.1881897747516632
[10/24] Train loss=0.16870278120040894
[15/24] Train loss=0.16629476845264435
[20/24] Train loss=0.1511835902929306
Test set avg_accuracy=81.02% avg_sensitivity=29.63%, avg_specificity=98.11% avg_auc=75.93%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.173097 Test loss=0.602569 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.1618821918964386
[5/24] Train loss=0.17503412067890167
[10/24] Train loss=0.1695718914270401
[15/24] Train loss=0.17862431704998016
[20/24] Train loss=0.16696195304393768
Test set avg_accuracy=83.87% avg_sensitivity=64.53%, avg_specificity=90.30% avg_auc=87.09%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.173694 Test loss=0.389889 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.1655898243188858
[5/24] Train loss=0.1791457086801529
[10/24] Train loss=0.17265845835208893
[15/24] Train loss=0.169650599360466
[20/24] Train loss=0.16401876509189606
Test set avg_accuracy=82.72% avg_sensitivity=40.38%, avg_specificity=96.81% avg_auc=81.09%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.175924 Test loss=0.491202 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.17542140185832977
[5/24] Train loss=0.17943835258483887
[10/24] Train loss=0.17086532711982727
[15/24] Train loss=0.16753210127353668
[20/24] Train loss=0.16045115888118744
Test set avg_accuracy=84.30% avg_sensitivity=53.99%, avg_specificity=94.38% avg_auc=84.01%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.174454 Test loss=0.410474 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.16654440760612488
[5/24] Train loss=0.17846421897411346
[10/24] Train loss=0.17480811476707458
[15/24] Train loss=0.16295157372951508
[20/24] Train loss=0.1585269421339035
Test set avg_accuracy=83.72% avg_sensitivity=44.81%, avg_specificity=96.67% avg_auc=82.21%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.170429 Test loss=0.460467 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.15254075825214386
[5/24] Train loss=0.172703817486763
[10/24] Train loss=0.16152484714984894
[15/24] Train loss=0.16668002307415009
[20/24] Train loss=0.15935364365577698
Test set avg_accuracy=80.57% avg_sensitivity=25.51%, avg_specificity=98.89% avg_auc=75.81%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.171168 Test loss=0.612566 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.15347954630851746
[5/24] Train loss=0.17188620567321777
[10/24] Train loss=0.16638892889022827
[15/24] Train loss=0.16037549078464508
[20/24] Train loss=0.1563590168952942
Test set avg_accuracy=83.72% avg_sensitivity=45.02%, avg_specificity=96.60% avg_auc=82.55%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.170612 Test loss=0.449087 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.15524014830589294
[5/24] Train loss=0.16870982944965363
[10/24] Train loss=0.17244254052639008
[15/24] Train loss=0.173687145113945
[20/24] Train loss=0.15535937249660492
Test set avg_accuracy=82.16% avg_sensitivity=35.58%, avg_specificity=97.66% avg_auc=75.93%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.168555 Test loss=0.524376 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.14558866620063782
[5/24] Train loss=0.17838211357593536
[10/24] Train loss=0.16287140548229218
[15/24] Train loss=0.15796861052513123
[20/24] Train loss=0.15890134871006012
Test set avg_accuracy=84.34% avg_sensitivity=61.40%, avg_specificity=91.97% avg_auc=87.46%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.169835 Test loss=0.380818 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.15193066000938416
[5/24] Train loss=0.1723528951406479
[10/24] Train loss=0.16493993997573853
[15/24] Train loss=0.15477056801319122
[20/24] Train loss=0.1498112976551056
Test set avg_accuracy=85.05% avg_sensitivity=64.48%, avg_specificity=91.90% avg_auc=88.48%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.165092 Test loss=0.369980 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.14758345484733582
[5/24] Train loss=0.17460158467292786
[10/24] Train loss=0.1672462522983551
[15/24] Train loss=0.1605408638715744
[20/24] Train loss=0.15886491537094116
Test set avg_accuracy=83.55% avg_sensitivity=44.08%, avg_specificity=96.69% avg_auc=81.61%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.168110 Test loss=0.481212 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.1457083523273468
[5/24] Train loss=0.17452849447727203
[10/24] Train loss=0.17527590692043304
[15/24] Train loss=0.16488711535930634
[20/24] Train loss=0.1466463804244995
Test set avg_accuracy=83.67% avg_sensitivity=50.97%, avg_specificity=94.55% avg_auc=82.61%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.169421 Test loss=0.456329 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.15560214221477509
[5/24] Train loss=0.16902518272399902
[10/24] Train loss=0.17240241169929504
[15/24] Train loss=0.15720203518867493
[20/24] Train loss=0.14641229808330536
Test set avg_accuracy=83.65% avg_sensitivity=45.96%, avg_specificity=96.18% avg_auc=82.62%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.166567 Test loss=0.471447 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15072238445281982
[5/24] Train loss=0.17617085576057434
[10/24] Train loss=0.15616104006767273
[15/24] Train loss=0.1568523794412613
[20/24] Train loss=0.14989244937896729
Test set avg_accuracy=84.77% avg_sensitivity=60.25%, avg_specificity=92.92% avg_auc=86.41%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.161747 Test loss=0.395288 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1431787759065628
[5/24] Train loss=0.17003369331359863
[10/24] Train loss=0.15638355910778046
[15/24] Train loss=0.15422113239765167
[20/24] Train loss=0.14563606679439545
Test set avg_accuracy=85.03% avg_sensitivity=66.20%, avg_specificity=91.29% avg_auc=87.63%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.161632 Test loss=0.381000 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.14528824388980865
[5/24] Train loss=0.17224226891994476
[10/24] Train loss=0.15849970281124115
[15/24] Train loss=0.15419356524944305
[20/24] Train loss=0.14962835609912872
Test set avg_accuracy=82.67% avg_sensitivity=38.60%, avg_specificity=97.33% avg_auc=82.40%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.160680 Test loss=0.483699 Current lr=[0.000156543481933168]

[0/24] Train loss=0.14079514145851135
[5/24] Train loss=0.16600079834461212
[10/24] Train loss=0.15745225548744202
[15/24] Train loss=0.15536844730377197
[20/24] Train loss=0.14829401671886444
Test set avg_accuracy=82.97% avg_sensitivity=39.70%, avg_specificity=97.36% avg_auc=81.02%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.160812 Test loss=0.492283 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.14134441316127777
[5/24] Train loss=0.1666468232870102
[10/24] Train loss=0.16282793879508972
[15/24] Train loss=0.15195348858833313
[20/24] Train loss=0.15000449120998383
Test set avg_accuracy=84.38% avg_sensitivity=54.20%, avg_specificity=94.41% avg_auc=85.80%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.160636 Test loss=0.416538 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.14584024250507355
[5/24] Train loss=0.16380129754543304
[10/24] Train loss=0.15144819021224976
[15/24] Train loss=0.1553761214017868
[20/24] Train loss=0.1454204022884369
Test set avg_accuracy=84.09% avg_sensitivity=46.84%, avg_specificity=96.48% avg_auc=82.71%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.158265 Test loss=0.461735 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.14812180399894714
[5/24] Train loss=0.17075316607952118
[10/24] Train loss=0.1495576798915863
[15/24] Train loss=0.15197497606277466
[20/24] Train loss=0.13261379301548004
Test set avg_accuracy=84.88% avg_sensitivity=59.15%, avg_specificity=93.44% avg_auc=86.88%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.156916 Test loss=0.393276 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.14214427769184113
[5/24] Train loss=0.16392499208450317
[10/24] Train loss=0.14916124939918518
[15/24] Train loss=0.14860455691814423
[20/24] Train loss=0.14024582505226135
Test set avg_accuracy=84.34% avg_sensitivity=54.25%, avg_specificity=94.34% avg_auc=85.31%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.154975 Test loss=0.410672 Current lr=[0.000134135431043539]

[0/24] Train loss=0.14476962387561798
[5/24] Train loss=0.15751810371875763
[10/24] Train loss=0.15682780742645264
[15/24] Train loss=0.14634883403778076
[20/24] Train loss=0.1395891308784485
Test set avg_accuracy=85.70% avg_sensitivity=64.53%, avg_specificity=92.75% avg_auc=88.06%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.155630 Test loss=0.369451 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1457643359899521
[5/24] Train loss=0.16053709387779236
[10/24] Train loss=0.15779820084571838
[15/24] Train loss=0.1540154218673706
[20/24] Train loss=0.14178673923015594
Test set avg_accuracy=84.39% avg_sensitivity=48.72%, avg_specificity=96.25% avg_auc=84.47%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.154114 Test loss=0.432001 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.13509859144687653
[5/24] Train loss=0.1587175875902176
[10/24] Train loss=0.14966125786304474
[15/24] Train loss=0.1478295773267746
[20/24] Train loss=0.13642236590385437
Test set avg_accuracy=85.00% avg_sensitivity=57.54%, avg_specificity=94.13% avg_auc=86.65%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.152630 Test loss=0.391547 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.13753436505794525
[5/24] Train loss=0.16589491069316864
[10/24] Train loss=0.15245726704597473
[15/24] Train loss=0.14267410337924957
[20/24] Train loss=0.14171238243579865
Test set avg_accuracy=84.96% avg_sensitivity=63.59%, avg_specificity=92.07% avg_auc=87.79%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.153821 Test loss=0.379628 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14567053318023682
[5/24] Train loss=0.1545158177614212
[10/24] Train loss=0.1504150778055191
[15/24] Train loss=0.15087983012199402
[20/24] Train loss=0.14448051154613495
Test set avg_accuracy=85.00% avg_sensitivity=53.10%, avg_specificity=95.61% avg_auc=86.20%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.153878 Test loss=0.404643 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14022500813007355
[5/24] Train loss=0.15905767679214478
[10/24] Train loss=0.14714019000530243
[15/24] Train loss=0.14039558172225952
[20/24] Train loss=0.13683748245239258
Test set avg_accuracy=85.25% avg_sensitivity=57.38%, avg_specificity=94.52% avg_auc=87.70%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.151550 Test loss=0.379423 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1438540816307068
[5/24] Train loss=0.16077427566051483
[10/24] Train loss=0.14503292739391327
[15/24] Train loss=0.14683182537555695
[20/24] Train loss=0.13692030310630798
Test set avg_accuracy=84.66% avg_sensitivity=68.75%, avg_specificity=89.95% avg_auc=89.39%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.150736 Test loss=0.365297 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.13942229747772217
[5/24] Train loss=0.15031211078166962
[10/24] Train loss=0.14945633709430695
[15/24] Train loss=0.14914686977863312
[20/24] Train loss=0.13915152847766876
Test set avg_accuracy=84.51% avg_sensitivity=61.55%, avg_specificity=92.14% avg_auc=88.32%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.151019 Test loss=0.374357 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.13720403611660004
[5/24] Train loss=0.15463531017303467
[10/24] Train loss=0.14414025843143463
[15/24] Train loss=0.1431148648262024
[20/24] Train loss=0.13650290668010712
Test set avg_accuracy=85.14% avg_sensitivity=63.85%, avg_specificity=92.23% avg_auc=88.26%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.149484 Test loss=0.378383 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.13853485882282257
[5/24] Train loss=0.1544215828180313
[10/24] Train loss=0.1472625434398651
[15/24] Train loss=0.14115947484970093
[20/24] Train loss=0.13172724843025208
Test set avg_accuracy=85.61% avg_sensitivity=69.01%, avg_specificity=91.13% avg_auc=89.62%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.148992 Test loss=0.356839 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1386609673500061
[5/24] Train loss=0.15912343561649323
[10/24] Train loss=0.14282183349132538
[15/24] Train loss=0.15197734534740448
[20/24] Train loss=0.13239863514900208
Test set avg_accuracy=85.74% avg_sensitivity=63.48%, avg_specificity=93.15% avg_auc=88.76%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.150249 Test loss=0.366297 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14093367755413055
[5/24] Train loss=0.16227209568023682
[10/24] Train loss=0.15308931469917297
[15/24] Train loss=0.14523936808109283
[20/24] Train loss=0.1359003335237503
Test set avg_accuracy=84.96% avg_sensitivity=69.33%, avg_specificity=90.16% avg_auc=89.02%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.149661 Test loss=0.375745 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13895611464977264
[5/24] Train loss=0.15078102052211761
[10/24] Train loss=0.14744730293750763
[15/24] Train loss=0.14712932705879211
[20/24] Train loss=0.1269380748271942
Test set avg_accuracy=85.17% avg_sensitivity=69.22%, avg_specificity=90.47% avg_auc=89.48%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.147797 Test loss=0.363807 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13850978016853333
[5/24] Train loss=0.15103036165237427
[10/24] Train loss=0.14031076431274414
[15/24] Train loss=0.1378677487373352
[20/24] Train loss=0.13238881528377533
Test set avg_accuracy=85.61% avg_sensitivity=65.73%, avg_specificity=92.23% avg_auc=88.10%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.145536 Test loss=0.378586 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1339990198612213
[5/24] Train loss=0.14657597243785858
[10/24] Train loss=0.147112637758255
[15/24] Train loss=0.13953456282615662
[20/24] Train loss=0.1352040320634842
Test set avg_accuracy=85.22% avg_sensitivity=64.79%, avg_specificity=92.02% avg_auc=88.01%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.144661 Test loss=0.377709 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13320519030094147
[5/24] Train loss=0.1422870010137558
[10/24] Train loss=0.1422559767961502
[15/24] Train loss=0.1340065449476242
[20/24] Train loss=0.12625651061534882
Test set avg_accuracy=85.13% avg_sensitivity=70.37%, avg_specificity=90.04% avg_auc=89.49%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.142827 Test loss=0.368072 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.13065192103385925
[5/24] Train loss=0.14618711173534393
[10/24] Train loss=0.13613231480121613
[15/24] Train loss=0.13675324618816376
[20/24] Train loss=0.126841738820076
Test set avg_accuracy=84.27% avg_sensitivity=62.75%, avg_specificity=91.43% avg_auc=86.63%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.141683 Test loss=0.401354 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13159948587417603
[5/24] Train loss=0.14554375410079956
[10/24] Train loss=0.1387162059545517
[15/24] Train loss=0.13614502549171448
[20/24] Train loss=0.1295708268880844
Test set avg_accuracy=84.01% avg_sensitivity=71.00%, avg_specificity=88.34% avg_auc=88.07%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.141530 Test loss=0.396818 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13056619465351105
[5/24] Train loss=0.1475316882133484
[10/24] Train loss=0.13859961926937103
[15/24] Train loss=0.13479913771152496
[20/24] Train loss=0.12854483723640442
Test set avg_accuracy=85.22% avg_sensitivity=67.03%, avg_specificity=91.27% avg_auc=88.92%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.141390 Test loss=0.369197 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1289980113506317
[5/24] Train loss=0.14447788894176483
[10/24] Train loss=0.13558219373226166
[15/24] Train loss=0.135767862200737
[20/24] Train loss=0.1287890374660492
Test set avg_accuracy=84.84% avg_sensitivity=72.35%, avg_specificity=89.00% avg_auc=88.95%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.140798 Test loss=0.380657 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1285334825515747
[5/24] Train loss=0.14067795872688293
[10/24] Train loss=0.13708122074604034
[15/24] Train loss=0.13552622497081757
[20/24] Train loss=0.12172411382198334
Test set avg_accuracy=84.71% avg_sensitivity=70.94%, avg_specificity=89.29% avg_auc=88.69%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.139086 Test loss=0.388041 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13011246919631958
[5/24] Train loss=0.14728081226348877
[10/24] Train loss=0.13133099675178528
[15/24] Train loss=0.1311010718345642
[20/24] Train loss=0.12093627452850342
Test set avg_accuracy=85.23% avg_sensitivity=65.26%, avg_specificity=91.88% avg_auc=88.23%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.138018 Test loss=0.380152 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1290951818227768
[5/24] Train loss=0.14218145608901978
[10/24] Train loss=0.13205358386039734
[15/24] Train loss=0.13067924976348877
[20/24] Train loss=0.12135530263185501
Test set avg_accuracy=85.05% avg_sensitivity=70.53%, avg_specificity=89.88% avg_auc=89.17%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.135538 Test loss=0.371772 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12863117456436157
[5/24] Train loss=0.1403777301311493
[10/24] Train loss=0.13596025109291077
[15/24] Train loss=0.1275288611650467
[20/24] Train loss=0.12169691920280457
Test set avg_accuracy=85.18% avg_sensitivity=65.78%, avg_specificity=91.64% avg_auc=87.87%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.135079 Test loss=0.382208 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12755048274993896
[5/24] Train loss=0.1398826688528061
[10/24] Train loss=0.13132677972316742
[15/24] Train loss=0.13075031340122223
[20/24] Train loss=0.1191067099571228
Test set avg_accuracy=85.22% avg_sensitivity=66.61%, avg_specificity=91.41% avg_auc=88.02%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.134438 Test loss=0.381235 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12203516066074371
[5/24] Train loss=0.13707861304283142
[10/24] Train loss=0.12952430546283722
[15/24] Train loss=0.13115131855010986
[20/24] Train loss=0.12141364067792892
Test set avg_accuracy=85.04% avg_sensitivity=71.00%, avg_specificity=89.71% avg_auc=89.33%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.133577 Test loss=0.372099 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12276427447795868
[5/24] Train loss=0.13649843633174896
[10/24] Train loss=0.1302461326122284
[15/24] Train loss=0.1273745894432068
[20/24] Train loss=0.12201164662837982
Test set avg_accuracy=85.26% avg_sensitivity=68.02%, avg_specificity=90.99% avg_auc=88.08%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.133299 Test loss=0.382376 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12124094367027283
[5/24] Train loss=0.13975916802883148
[10/24] Train loss=0.12748025357723236
[15/24] Train loss=0.12597566843032837
[20/24] Train loss=0.11901666969060898
Test set avg_accuracy=85.31% avg_sensitivity=67.66%, avg_specificity=91.19% avg_auc=88.31%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.132073 Test loss=0.379089 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12253806740045547
[5/24] Train loss=0.13555818796157837
[10/24] Train loss=0.1290283501148224
[15/24] Train loss=0.12938199937343597
[20/24] Train loss=0.11885381489992142
Test set avg_accuracy=85.36% avg_sensitivity=68.18%, avg_specificity=91.08% avg_auc=88.55%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.132207 Test loss=0.375506 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.11986658722162247
[5/24] Train loss=0.1375768780708313
[10/24] Train loss=0.12816989421844482
[15/24] Train loss=0.12445428222417831
[20/24] Train loss=0.11799175292253494
Test set avg_accuracy=84.99% avg_sensitivity=67.92%, avg_specificity=90.66% avg_auc=88.61%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.131308 Test loss=0.375542 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12046287208795547
[5/24] Train loss=0.13554510474205017
[10/24] Train loss=0.12465642392635345
[15/24] Train loss=0.12479085475206375
[20/24] Train loss=0.1169157400727272
Test set avg_accuracy=85.00% avg_sensitivity=66.88%, avg_specificity=91.03% avg_auc=88.24%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.131019 Test loss=0.380778 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1218266487121582
[5/24] Train loss=0.13578176498413086
[10/24] Train loss=0.12852081656455994
[15/24] Train loss=0.1267441213130951
[20/24] Train loss=0.1196213886141777
Test set avg_accuracy=85.31% avg_sensitivity=67.34%, avg_specificity=91.29% avg_auc=88.27%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.130726 Test loss=0.376723 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12225736677646637
[5/24] Train loss=0.13632452487945557
[10/24] Train loss=0.127963125705719
[15/24] Train loss=0.12352359294891357
[20/24] Train loss=0.1188684031367302
Test set avg_accuracy=85.70% avg_sensitivity=68.81%, avg_specificity=91.32% avg_auc=88.97%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.130932 Test loss=0.369087 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.11946173012256622
[5/24] Train loss=0.13647451996803284
[10/24] Train loss=0.12813487648963928
[15/24] Train loss=0.12489244341850281
[20/24] Train loss=0.11923998594284058
Test set avg_accuracy=85.26% avg_sensitivity=70.06%, avg_specificity=90.32% avg_auc=88.68%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.129964 Test loss=0.375341 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.11971568316221237
[5/24] Train loss=0.13659727573394775
[10/24] Train loss=0.12731344997882843
[15/24] Train loss=0.1225380152463913
[20/24] Train loss=0.11744049936532974
Test set avg_accuracy=85.22% avg_sensitivity=70.42%, avg_specificity=90.14% avg_auc=88.84%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.129057 Test loss=0.374478 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.11804096400737762
[5/24] Train loss=0.13398562371730804
[10/24] Train loss=0.12328383326530457
[15/24] Train loss=0.12359271943569183
[20/24] Train loss=0.113876111805439
Test set avg_accuracy=85.18% avg_sensitivity=68.18%, avg_specificity=90.84% avg_auc=88.07%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.128378 Test loss=0.380868 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.11881684511899948
[5/24] Train loss=0.13340400159358978
[10/24] Train loss=0.12093658745288849
[15/24] Train loss=0.12221422791481018
[20/24] Train loss=0.11503855884075165
Test set avg_accuracy=85.29% avg_sensitivity=68.18%, avg_specificity=90.98% avg_auc=88.39%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.127887 Test loss=0.376675 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.11837107688188553
[5/24] Train loss=0.13260841369628906
[10/24] Train loss=0.1275256723165512
[15/24] Train loss=0.12289480119943619
[20/24] Train loss=0.11550174653530121
Test set avg_accuracy=85.34% avg_sensitivity=67.29%, avg_specificity=91.34% avg_auc=88.41%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.127405 Test loss=0.377014 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.11829233914613724
[5/24] Train loss=0.13255441188812256
[10/24] Train loss=0.12367837876081467
[15/24] Train loss=0.12312254309654236
[20/24] Train loss=0.11282621324062347
Test set avg_accuracy=85.29% avg_sensitivity=68.13%, avg_specificity=90.99% avg_auc=88.47%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.127441 Test loss=0.377987 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11835465580224991
[5/24] Train loss=0.12874950468540192
[10/24] Train loss=0.12133168429136276
[15/24] Train loss=0.12154284119606018
[20/24] Train loss=0.11612894386053085
Test set avg_accuracy=85.35% avg_sensitivity=68.96%, avg_specificity=90.80% avg_auc=88.91%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.126982 Test loss=0.372582 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1198306679725647
[5/24] Train loss=0.1336182951927185
[10/24] Train loss=0.12259278446435928
[15/24] Train loss=0.12207353115081787
[20/24] Train loss=0.11495617777109146
Test set avg_accuracy=85.22% avg_sensitivity=68.49%, avg_specificity=90.79% avg_auc=88.66%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.126455 Test loss=0.375404 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11822107434272766
[5/24] Train loss=0.13146349787712097
[10/24] Train loss=0.1261354386806488
[15/24] Train loss=0.12356309592723846
[20/24] Train loss=0.117890365421772
Test set avg_accuracy=85.20% avg_sensitivity=67.24%, avg_specificity=91.17% avg_auc=88.66%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.126672 Test loss=0.374961 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1166006475687027
[5/24] Train loss=0.13017255067825317
[10/24] Train loss=0.12252181768417358
[15/24] Train loss=0.11965585500001907
[20/24] Train loss=0.11346333473920822
Test set avg_accuracy=85.12% avg_sensitivity=68.18%, avg_specificity=90.75% avg_auc=88.71%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.126256 Test loss=0.375495 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11581027507781982
[5/24] Train loss=0.13664090633392334
[10/24] Train loss=0.12368445098400116
[15/24] Train loss=0.1209784671664238
[20/24] Train loss=0.11435579508543015
Test set avg_accuracy=85.22% avg_sensitivity=67.50%, avg_specificity=91.12% avg_auc=88.57%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.126440 Test loss=0.375953 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11851851642131805
[5/24] Train loss=0.13267652690410614
[10/24] Train loss=0.12843607366085052
[15/24] Train loss=0.12278768420219421
[20/24] Train loss=0.11605338007211685
Test set avg_accuracy=85.23% avg_sensitivity=67.87%, avg_specificity=91.01% avg_auc=88.65%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.126974 Test loss=0.375584 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1159668043255806
[5/24] Train loss=0.13055668771266937
[10/24] Train loss=0.12158248573541641
[15/24] Train loss=0.12013131380081177
[20/24] Train loss=0.11364622414112091
Test set avg_accuracy=85.21% avg_sensitivity=67.92%, avg_specificity=90.96% avg_auc=88.62%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.126260 Test loss=0.375694 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11637867242097855
[5/24] Train loss=0.13171173632144928
[10/24] Train loss=0.1216416135430336
[15/24] Train loss=0.11832144111394882
[20/24] Train loss=0.11760033667087555
Test set avg_accuracy=85.18% avg_sensitivity=67.55%, avg_specificity=91.05% avg_auc=88.57%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.126257 Test loss=0.376431 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11802811175584793
[5/24] Train loss=0.13049384951591492
[10/24] Train loss=0.12238563597202301
[15/24] Train loss=0.12146562337875366
[20/24] Train loss=0.11196714639663696
Test set avg_accuracy=85.22% avg_sensitivity=67.81%, avg_specificity=91.01% avg_auc=88.57%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.126101 Test loss=0.376568 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1177823469042778
[5/24] Train loss=0.13080139458179474
[10/24] Train loss=0.1221824362874031
[15/24] Train loss=0.12072978913784027
[20/24] Train loss=0.11385414749383926
Test set avg_accuracy=85.20% avg_sensitivity=67.61%, avg_specificity=91.05% avg_auc=88.57%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.125778 Test loss=0.376340 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=85.16% sen=72.35%, spe=89.42%, auc=90.86%!
Fold[2] Avg_overlap=0.21%(±0.26298120028383004)
[0/24] Train loss=0.7521153688430786
[5/24] Train loss=0.7389206886291504
[10/24] Train loss=0.7306894659996033
[15/24] Train loss=0.7242279648780823
[20/24] Train loss=0.7156522274017334
Test set avg_accuracy=60.10% avg_sensitivity=48.01%, avg_specificity=64.69% avg_auc=59.84%
Best model saved!! Metric=-93.35818241056664!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.732702 Test loss=0.649137 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7177643775939941
[5/24] Train loss=0.7121375799179077
[10/24] Train loss=0.704349160194397
[15/24] Train loss=0.6977912187576294
[20/24] Train loss=0.6902788877487183
Test set avg_accuracy=67.10% avg_sensitivity=65.40%, avg_specificity=67.74% avg_auc=71.92%
Best model saved!! Metric=-53.840826225923976!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.702237 Test loss=0.614269 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.686002254486084
[5/24] Train loss=0.6864469051361084
[10/24] Train loss=0.6709778308868408
[15/24] Train loss=0.6680996417999268
[20/24] Train loss=0.654641330242157
Test set avg_accuracy=70.35% avg_sensitivity=72.27%, avg_specificity=69.62% avg_auc=76.86%
Best model saved!! Metric=-36.88813986626478!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.673590 Test loss=0.593264 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6601814031600952
[5/24] Train loss=0.6557097434997559
[10/24] Train loss=0.652823805809021
[15/24] Train loss=0.6434950828552246
[20/24] Train loss=0.6311028599739075
Test set avg_accuracy=72.40% avg_sensitivity=75.88%, avg_specificity=71.08% avg_auc=80.11%
Best model saved!! Metric=-26.54486539972376!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.648602 Test loss=0.567889 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6308530569076538
[5/24] Train loss=0.6299722194671631
[10/24] Train loss=0.6311327815055847
[15/24] Train loss=0.6142228841781616
[20/24] Train loss=0.5997707843780518
Test set avg_accuracy=73.83% avg_sensitivity=78.10%, avg_specificity=72.21% avg_auc=82.11%
Best model saved!! Metric=-19.744547662452035!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.622432 Test loss=0.548268 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6051551103591919
[5/24] Train loss=0.5971850752830505
[10/24] Train loss=0.6016539335250854
[15/24] Train loss=0.5885024070739746
[20/24] Train loss=0.5732571482658386
Test set avg_accuracy=75.46% avg_sensitivity=78.25%, avg_specificity=74.40% avg_auc=83.56%
Best model saved!! Metric=-14.341551458211015!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.596360 Test loss=0.525688 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5749533176422119
[5/24] Train loss=0.572153627872467
[10/24] Train loss=0.5715298056602478
[15/24] Train loss=0.562436580657959
[20/24] Train loss=0.5404860377311707
Test set avg_accuracy=77.58% avg_sensitivity=77.87%, avg_specificity=77.47% avg_auc=84.76%
Best model saved!! Metric=-8.322833928586633!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.569754 Test loss=0.498506 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5439079403877258
[5/24] Train loss=0.5372991561889648
[10/24] Train loss=0.5517285466194153
[15/24] Train loss=0.5347819924354553
[20/24] Train loss=0.5095392465591431
Test set avg_accuracy=78.88% avg_sensitivity=76.97%, avg_specificity=79.61% avg_auc=85.88%
Best model saved!! Metric=-4.667716824290039!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.542552 Test loss=0.475609 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5171729326248169
[5/24] Train loss=0.515516459941864
[10/24] Train loss=0.5161725282669067
[15/24] Train loss=0.511448860168457
[20/24] Train loss=0.4805692732334137
Test set avg_accuracy=80.23% avg_sensitivity=75.21%, avg_specificity=82.14% avg_auc=86.72%
Best model saved!! Metric=-1.6965855452364167!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.516556 Test loss=0.453355 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4916045069694519
[5/24] Train loss=0.4994245171546936
[10/24] Train loss=0.4959627389907837
[15/24] Train loss=0.4852551519870758
[20/24] Train loss=0.4630736708641052
Test set avg_accuracy=81.50% avg_sensitivity=75.12%, avg_specificity=83.91% avg_auc=87.39%
Best model saved!! Metric=1.9241871238453!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.492479 Test loss=0.436693 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.46383047103881836
[5/24] Train loss=0.47323790192604065
[10/24] Train loss=0.4664217233657837
[15/24] Train loss=0.4683789312839508
[20/24] Train loss=0.4356975853443146
Test set avg_accuracy=82.32% avg_sensitivity=73.93%, avg_specificity=85.49% avg_auc=88.00%
Best model saved!! Metric=3.7466821010632856!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.466091 Test loss=0.420156 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4428965449333191
[5/24] Train loss=0.44421857595443726
[10/24] Train loss=0.4534297585487366
[15/24] Train loss=0.4411483407020569
[20/24] Train loss=0.40714120864868164
Test set avg_accuracy=82.90% avg_sensitivity=74.60%, avg_specificity=86.05% avg_auc=88.79%
Best model saved!! Metric=6.345663412272657!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.443542 Test loss=0.408645 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.41830936074256897
[5/24] Train loss=0.42347773909568787
[10/24] Train loss=0.43075162172317505
[15/24] Train loss=0.419486403465271
[20/24] Train loss=0.39075949788093567
Test set avg_accuracy=83.62% avg_sensitivity=76.30%, avg_specificity=86.39% avg_auc=89.46%
Best model saved!! Metric=9.777831946772494!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.421909 Test loss=0.399802 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.39738014340400696
[5/24] Train loss=0.40497979521751404
[10/24] Train loss=0.4168405830860138
[15/24] Train loss=0.4088650047779083
[20/24] Train loss=0.3723062574863434
Test set avg_accuracy=84.43% avg_sensitivity=75.26%, avg_specificity=87.90% avg_auc=89.88%
Best model saved!! Metric=11.462364587853571!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.403513 Test loss=0.385437 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3761073648929596
[5/24] Train loss=0.3906250298023224
[10/24] Train loss=0.40271732211112976
[15/24] Train loss=0.3952253758907318
[20/24] Train loss=0.357562780380249
Test set avg_accuracy=84.83% avg_sensitivity=74.98%, avg_specificity=88.56% avg_auc=90.33%
Best model saved!! Metric=12.700350615355049!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.387494 Test loss=0.371734 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3637884259223938
[5/24] Train loss=0.3704521358013153
[10/24] Train loss=0.3861788511276245
[15/24] Train loss=0.37888002395629883
[20/24] Train loss=0.3453448712825775
Test set avg_accuracy=83.35% avg_sensitivity=78.96%, avg_specificity=85.01% avg_auc=90.20%
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.371994 Test loss=0.388324 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.35452893376350403
[5/24] Train loss=0.35951438546180725
[10/24] Train loss=0.37745505571365356
[15/24] Train loss=0.36850571632385254
[20/24] Train loss=0.33509930968284607
Test set avg_accuracy=85.16% avg_sensitivity=78.25%, avg_specificity=87.77% avg_auc=90.74%
Best model saved!! Metric=15.919712863852567!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.360844 Test loss=0.367578 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3409958779811859
[5/24] Train loss=0.3474698066711426
[10/24] Train loss=0.3612762689590454
[15/24] Train loss=0.36335667967796326
[20/24] Train loss=0.32772335410118103
Test set avg_accuracy=85.26% avg_sensitivity=76.92%, avg_specificity=88.42% avg_auc=90.82%
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.349897 Test loss=0.362873 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.33346661925315857
[5/24] Train loss=0.33550694584846497
[10/24] Train loss=0.3588293194770813
[15/24] Train loss=0.35070234537124634
[20/24] Train loss=0.32231172919273376
Test set avg_accuracy=84.26% avg_sensitivity=79.81%, avg_specificity=85.94% avg_auc=90.72%
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.340830 Test loss=0.373282 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3198077082633972
[5/24] Train loss=0.33440065383911133
[10/24] Train loss=0.34935468435287476
[15/24] Train loss=0.3507325053215027
[20/24] Train loss=0.3099265694618225
Test set avg_accuracy=84.95% avg_sensitivity=78.67%, avg_specificity=87.32% avg_auc=90.90%
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.331886 Test loss=0.363206 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.31267422437667847
[5/24] Train loss=0.3275768458843231
[10/24] Train loss=0.3390635848045349
[15/24] Train loss=0.3375917971134186
[20/24] Train loss=0.3110446631908417
Test set avg_accuracy=84.88% avg_sensitivity=76.64%, avg_specificity=88.01% avg_auc=90.82%
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.323330 Test loss=0.357360 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3101828396320343
[5/24] Train loss=0.3232981562614441
[10/24] Train loss=0.3408385217189789
[15/24] Train loss=0.33535268902778625
[20/24] Train loss=0.2966606318950653
Test set avg_accuracy=84.87% avg_sensitivity=78.39%, avg_specificity=87.32% avg_auc=91.11%
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.318300 Test loss=0.356541 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3001807630062103
[5/24] Train loss=0.31973180174827576
[10/24] Train loss=0.33292123675346375
[15/24] Train loss=0.3246384859085083
[20/24] Train loss=0.29300087690353394
Test set avg_accuracy=83.67% avg_sensitivity=80.66%, avg_specificity=84.81% avg_auc=90.32%
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.310999 Test loss=0.385705 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3033031225204468
[5/24] Train loss=0.31461432576179504
[10/24] Train loss=0.3303525447845459
[15/24] Train loss=0.32818782329559326
[20/24] Train loss=0.28185349702835083
Test set avg_accuracy=85.16% avg_sensitivity=75.97%, avg_specificity=88.64% avg_auc=91.00%
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.303628 Test loss=0.351059 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2995343804359436
[5/24] Train loss=0.3070397973060608
[10/24] Train loss=0.3192117512226105
[15/24] Train loss=0.32464322447776794
[20/24] Train loss=0.2772335112094879
Test set avg_accuracy=84.62% avg_sensitivity=74.93%, avg_specificity=88.29% avg_auc=89.99%
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.300293 Test loss=0.372712 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3004363477230072
[5/24] Train loss=0.3025263547897339
[10/24] Train loss=0.3120797574520111
[15/24] Train loss=0.31431275606155396
[20/24] Train loss=0.2632080614566803
Test set avg_accuracy=84.36% avg_sensitivity=64.55%, avg_specificity=91.87% avg_auc=89.33%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.292753 Test loss=0.359777 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2901005148887634
[5/24] Train loss=0.30032598972320557
[10/24] Train loss=0.30778273940086365
[15/24] Train loss=0.31217366456985474
[20/24] Train loss=0.26723524928092957
Test set avg_accuracy=85.07% avg_sensitivity=56.78%, avg_specificity=95.78% avg_auc=90.70%
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.287047 Test loss=0.346487 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.27848920226097107
[5/24] Train loss=0.2936306893825531
[10/24] Train loss=0.2955339252948761
[15/24] Train loss=0.30554115772247314
[20/24] Train loss=0.25590020418167114
Test set avg_accuracy=84.66% avg_sensitivity=59.81%, avg_specificity=94.08% avg_auc=90.04%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.280886 Test loss=0.351432 Current lr=[0.000210185142098938]

[0/24] Train loss=0.26800736784935
[5/24] Train loss=0.2838476300239563
[10/24] Train loss=0.29630333185195923
[15/24] Train loss=0.30092886090278625
[20/24] Train loss=0.2623453736305237
Test set avg_accuracy=82.86% avg_sensitivity=46.30%, avg_specificity=96.71% avg_auc=88.46%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.273537 Test loss=0.387314 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.269298255443573
[5/24] Train loss=0.2712271809577942
[10/24] Train loss=0.3026847243309021
[15/24] Train loss=0.2958546578884125
[20/24] Train loss=0.24920715391635895
Test set avg_accuracy=85.46% avg_sensitivity=59.10%, avg_specificity=95.44% avg_auc=90.90%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.269988 Test loss=0.340109 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.25784504413604736
[5/24] Train loss=0.2568327784538269
[10/24] Train loss=0.2814626097679138
[15/24] Train loss=0.27830320596694946
[20/24] Train loss=0.235347181558609
Test set avg_accuracy=80.78% avg_sensitivity=62.61%, avg_specificity=87.67% avg_auc=85.66%
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.260456 Test loss=0.415658 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2528168857097626
[5/24] Train loss=0.24481311440467834
[10/24] Train loss=0.29434311389923096
[15/24] Train loss=0.28029119968414307
[20/24] Train loss=0.22649982571601868
Test set avg_accuracy=83.58% avg_sensitivity=62.42%, avg_specificity=91.60% avg_auc=87.66%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.257842 Test loss=0.378442 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2453199177980423
[5/24] Train loss=0.2412944883108139
[10/24] Train loss=0.29336100816726685
[15/24] Train loss=0.27480456233024597
[20/24] Train loss=0.24143001437187195
Test set avg_accuracy=81.30% avg_sensitivity=76.16%, avg_specificity=83.25% avg_auc=87.85%
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.253172 Test loss=0.414665 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.24265119433403015
[5/24] Train loss=0.24216605722904205
[10/24] Train loss=0.2923639118671417
[15/24] Train loss=0.27681198716163635
[20/24] Train loss=0.2303009331226349
Test set avg_accuracy=79.62% avg_sensitivity=80.71%, avg_specificity=79.21% avg_auc=87.48%
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.251714 Test loss=0.449444 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2303209751844406
[5/24] Train loss=0.24247117340564728
[10/24] Train loss=0.28023645281791687
[15/24] Train loss=0.2809533476829529
[20/24] Train loss=0.23404987156391144
Test set avg_accuracy=83.78% avg_sensitivity=55.02%, avg_specificity=94.67% avg_auc=88.50%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.245040 Test loss=0.375635 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.21541863679885864
[5/24] Train loss=0.23559455573558807
[10/24] Train loss=0.29361847043037415
[15/24] Train loss=0.265298992395401
[20/24] Train loss=0.22639214992523193
Test set avg_accuracy=82.20% avg_sensitivity=52.80%, avg_specificity=93.34% avg_auc=87.34%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.241064 Test loss=0.389704 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.22163793444633484
[5/24] Train loss=0.23406697809696198
[10/24] Train loss=0.2773682475090027
[15/24] Train loss=0.26555585861206055
[20/24] Train loss=0.22303706407546997
Test set avg_accuracy=83.41% avg_sensitivity=47.30%, avg_specificity=97.09% avg_auc=86.52%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.237429 Test loss=0.419255 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.21890723705291748
[5/24] Train loss=0.224603533744812
[10/24] Train loss=0.28016582131385803
[15/24] Train loss=0.2682103216648102
[20/24] Train loss=0.22409000992774963
Test set avg_accuracy=83.93% avg_sensitivity=58.53%, avg_specificity=93.55% avg_auc=89.62%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.234775 Test loss=0.363644 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2251150906085968
[5/24] Train loss=0.2273131161928177
[10/24] Train loss=0.27615681290626526
[15/24] Train loss=0.27989503741264343
[20/24] Train loss=0.2208726704120636
Test set avg_accuracy=80.07% avg_sensitivity=32.27%, avg_specificity=98.17% avg_auc=82.89%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.234273 Test loss=0.500465 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.21465212106704712
[5/24] Train loss=0.20422273874282837
[10/24] Train loss=0.26721706986427307
[15/24] Train loss=0.2631503641605377
[20/24] Train loss=0.22037634253501892
Test set avg_accuracy=76.41% avg_sensitivity=15.21%, avg_specificity=99.59% avg_auc=75.13%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.228649 Test loss=0.747224 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2392793446779251
[5/24] Train loss=0.2157054990530014
[10/24] Train loss=0.2601865231990814
[15/24] Train loss=0.25930255651474
[20/24] Train loss=0.2121751308441162
Test set avg_accuracy=74.09% avg_sensitivity=5.88%, avg_specificity=99.93% avg_auc=76.44%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.229819 Test loss=0.780191 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2087281495332718
[5/24] Train loss=0.22638235986232758
[10/24] Train loss=0.26256102323532104
[15/24] Train loss=0.2709048390388489
[20/24] Train loss=0.2224961817264557
Test set avg_accuracy=77.16% avg_sensitivity=19.48%, avg_specificity=99.01% avg_auc=76.06%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.230131 Test loss=0.628367 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.208008274435997
[5/24] Train loss=0.2118934988975525
[10/24] Train loss=0.27609992027282715
[15/24] Train loss=0.2741195261478424
[20/24] Train loss=0.21275651454925537
Test set avg_accuracy=74.65% avg_sensitivity=8.34%, avg_specificity=99.77% avg_auc=64.87%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.228481 Test loss=0.913386 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2409697324037552
[5/24] Train loss=0.19927935302257538
[10/24] Train loss=0.2521568536758423
[15/24] Train loss=0.2570560574531555
[20/24] Train loss=0.22304175794124603
Test set avg_accuracy=73.50% avg_sensitivity=3.79%, avg_specificity=99.91% avg_auc=61.74%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.228278 Test loss=0.987411 Current lr=[0.00029967723776099]

[0/24] Train loss=0.22507436573505402
[5/24] Train loss=0.19544090330600739
[10/24] Train loss=0.2558985650539398
[15/24] Train loss=0.26699432730674744
[20/24] Train loss=0.19766464829444885
Test set avg_accuracy=76.64% avg_sensitivity=16.45%, avg_specificity=99.44% avg_auc=73.64%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.225076 Test loss=0.733788 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.21639256179332733
[5/24] Train loss=0.2050328105688095
[10/24] Train loss=0.24265706539154053
[15/24] Train loss=0.26863113045692444
[20/24] Train loss=0.21512484550476074
Test set avg_accuracy=79.09% avg_sensitivity=27.01%, avg_specificity=98.82% avg_auc=80.96%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.222613 Test loss=0.589198 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.20615801215171814
[5/24] Train loss=0.20945635437965393
[10/24] Train loss=0.24141837656497955
[15/24] Train loss=0.2565237581729889
[20/24] Train loss=0.20657560229301453
Test set avg_accuracy=80.78% avg_sensitivity=35.73%, avg_specificity=97.85% avg_auc=84.52%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.220914 Test loss=0.467510 Current lr=[0.000299720220882401]

[0/24] Train loss=0.21010980010032654
[5/24] Train loss=0.2075515240430832
[10/24] Train loss=0.23751308023929596
[15/24] Train loss=0.25160202383995056
[20/24] Train loss=0.19481094181537628
Test set avg_accuracy=81.67% avg_sensitivity=39.10%, avg_specificity=97.79% avg_auc=85.87%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.218390 Test loss=0.466629 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19797366857528687
[5/24] Train loss=0.20461033284664154
[10/24] Train loss=0.22482337057590485
[15/24] Train loss=0.25547975301742554
[20/24] Train loss=0.20685312151908875
Test set avg_accuracy=80.20% avg_sensitivity=32.46%, avg_specificity=98.28% avg_auc=83.93%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.217797 Test loss=0.543065 Current lr=[0.000298904600941902]

[0/24] Train loss=0.21058690547943115
[5/24] Train loss=0.19651532173156738
[10/24] Train loss=0.24250248074531555
[15/24] Train loss=0.24682360887527466
[20/24] Train loss=0.19281919300556183
Test set avg_accuracy=84.64% avg_sensitivity=59.43%, avg_specificity=94.18% avg_auc=89.14%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.215960 Test loss=0.391381 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.1911676526069641
[5/24] Train loss=0.18761762976646423
[10/24] Train loss=0.23716485500335693
[15/24] Train loss=0.23828710615634918
[20/24] Train loss=0.19670258462429047
Test set avg_accuracy=84.77% avg_sensitivity=59.05%, avg_specificity=94.51% avg_auc=89.22%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.210099 Test loss=0.380834 Current lr=[0.000297555943323901]

[0/24] Train loss=0.19028137624263763
[5/24] Train loss=0.18131409585475922
[10/24] Train loss=0.22841037809848785
[15/24] Train loss=0.24931778013706207
[20/24] Train loss=0.19595949351787567
Test set avg_accuracy=85.51% avg_sensitivity=73.22%, avg_specificity=90.16% avg_auc=90.93%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.209913 Test loss=0.346058 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.1942594349384308
[5/24] Train loss=0.2016962766647339
[10/24] Train loss=0.22173292934894562
[15/24] Train loss=0.22841915488243103
[20/24] Train loss=0.2031591385602951
Test set avg_accuracy=85.05% avg_sensitivity=72.94%, avg_specificity=89.64% avg_auc=91.04%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.206051 Test loss=0.349764 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.20361244678497314
[5/24] Train loss=0.18315662443637848
[10/24] Train loss=0.21726465225219727
[15/24] Train loss=0.23600353300571442
[20/24] Train loss=0.1918807476758957
Test set avg_accuracy=85.01% avg_sensitivity=62.37%, avg_specificity=93.59% avg_auc=89.06%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.203086 Test loss=0.384225 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.1841181218624115
[5/24] Train loss=0.1778937131166458
[10/24] Train loss=0.2119774967432022
[15/24] Train loss=0.22638718783855438
[20/24] Train loss=0.18691149353981018
Test set avg_accuracy=80.78% avg_sensitivity=34.83%, avg_specificity=98.19% avg_auc=85.60%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.199589 Test loss=0.490621 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.19886966049671173
[5/24] Train loss=0.17688822746276855
[10/24] Train loss=0.21173137426376343
[15/24] Train loss=0.2319914549589157
[20/24] Train loss=0.1890820562839508
Test set avg_accuracy=86.00% avg_sensitivity=63.70%, avg_specificity=94.45% avg_auc=90.56%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.199070 Test loss=0.341815 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.1853903830051422
[5/24] Train loss=0.1779564619064331
[10/24] Train loss=0.20833928883075714
[15/24] Train loss=0.23675121366977692
[20/24] Train loss=0.1905221790075302
Test set avg_accuracy=84.41% avg_sensitivity=56.97%, avg_specificity=94.81% avg_auc=89.59%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.196905 Test loss=0.372595 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.1956581473350525
[5/24] Train loss=0.17214561998844147
[10/24] Train loss=0.22224141657352448
[15/24] Train loss=0.23001587390899658
[20/24] Train loss=0.19394555687904358
Test set avg_accuracy=82.94% avg_sensitivity=52.89%, avg_specificity=94.33% avg_auc=87.16%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.199459 Test loss=0.432196 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.18647944927215576
[5/24] Train loss=0.1797325611114502
[10/24] Train loss=0.2150181531906128
[15/24] Train loss=0.22434376180171967
[20/24] Train loss=0.19700711965560913
Test set avg_accuracy=78.97% avg_sensitivity=79.15%, avg_specificity=78.90% avg_auc=86.66%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.196206 Test loss=0.470378 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.17817574739456177
[5/24] Train loss=0.17693860828876495
[10/24] Train loss=0.2157953977584839
[15/24] Train loss=0.22766318917274475
[20/24] Train loss=0.18739621341228485
Test set avg_accuracy=84.62% avg_sensitivity=71.23%, avg_specificity=89.69% avg_auc=88.96%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.197476 Test loss=0.369705 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.18099218606948853
[5/24] Train loss=0.1736082136631012
[10/24] Train loss=0.20884093642234802
[15/24] Train loss=0.22170914709568024
[20/24] Train loss=0.1821073442697525
Test set avg_accuracy=81.71% avg_sensitivity=73.93%, avg_specificity=84.65% avg_auc=88.37%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.189380 Test loss=0.401480 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.1912565678358078
[5/24] Train loss=0.17464511096477509
[10/24] Train loss=0.20928120613098145
[15/24] Train loss=0.23785224556922913
[20/24] Train loss=0.1818561553955078
Test set avg_accuracy=84.45% avg_sensitivity=59.10%, avg_specificity=94.06% avg_auc=88.67%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.193939 Test loss=0.385145 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.17386943101882935
[5/24] Train loss=0.17024724185466766
[10/24] Train loss=0.2184898555278778
[15/24] Train loss=0.22423624992370605
[20/24] Train loss=0.18365079164505005
Test set avg_accuracy=83.58% avg_sensitivity=57.54%, avg_specificity=93.45% avg_auc=87.14%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.188507 Test loss=0.413445 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.17318183183670044
[5/24] Train loss=0.18675178289413452
[10/24] Train loss=0.20653937757015228
[15/24] Train loss=0.2237909585237503
[20/24] Train loss=0.17992176115512848
Test set avg_accuracy=79.75% avg_sensitivity=36.16%, avg_specificity=96.27% avg_auc=80.90%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.191360 Test loss=0.547004 Current lr=[0.000276307469034998]

[0/24] Train loss=0.18652354180812836
[5/24] Train loss=0.1784277707338333
[10/24] Train loss=0.20924027264118195
[15/24] Train loss=0.22796544432640076
[20/24] Train loss=0.1797279566526413
Test set avg_accuracy=85.68% avg_sensitivity=70.43%, avg_specificity=91.45% avg_auc=89.90%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.189658 Test loss=0.360539 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.17553848028182983
[5/24] Train loss=0.18999971449375153
[10/24] Train loss=0.19394710659980774
[15/24] Train loss=0.22891846299171448
[20/24] Train loss=0.18243737518787384
Test set avg_accuracy=80.08% avg_sensitivity=31.85%, avg_specificity=98.35% avg_auc=85.64%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.189919 Test loss=0.511093 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.1767107993364334
[5/24] Train loss=0.16623377799987793
[10/24] Train loss=0.20376156270503998
[15/24] Train loss=0.21848733723163605
[20/24] Train loss=0.18184860050678253
Test set avg_accuracy=84.45% avg_sensitivity=67.06%, avg_specificity=91.04% avg_auc=89.13%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.186128 Test loss=0.378277 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.18296486139297485
[5/24] Train loss=0.1654329001903534
[10/24] Train loss=0.2028760015964508
[15/24] Train loss=0.22026482224464417
[20/24] Train loss=0.1688026487827301
Test set avg_accuracy=85.47% avg_sensitivity=65.17%, avg_specificity=93.16% avg_auc=89.92%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.184750 Test loss=0.361167 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.18237102031707764
[5/24] Train loss=0.16177095472812653
[10/24] Train loss=0.18823903799057007
[15/24] Train loss=0.23024700582027435
[20/24] Train loss=0.16793036460876465
Test set avg_accuracy=79.57% avg_sensitivity=85.17%, avg_specificity=77.45% avg_auc=89.09%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.186085 Test loss=0.467299 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.179584801197052
[5/24] Train loss=0.1662481725215912
[10/24] Train loss=0.21039585769176483
[15/24] Train loss=0.21825425326824188
[20/24] Train loss=0.18606962263584137
Test set avg_accuracy=84.47% avg_sensitivity=79.38%, avg_specificity=86.39% avg_auc=91.06%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.188853 Test loss=0.365958 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.16770246624946594
[5/24] Train loss=0.17009475827217102
[10/24] Train loss=0.20710282027721405
[15/24] Train loss=0.21673479676246643
[20/24] Train loss=0.17993120849132538
Test set avg_accuracy=82.77% avg_sensitivity=71.90%, avg_specificity=86.89% avg_auc=87.88%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.183918 Test loss=0.407465 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.17706625163555145
[5/24] Train loss=0.16355000436306
[10/24] Train loss=0.20432977378368378
[15/24] Train loss=0.21197152137756348
[20/24] Train loss=0.1704123318195343
Test set avg_accuracy=78.07% avg_sensitivity=89.38%, avg_specificity=73.79% avg_auc=89.67%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.181096 Test loss=0.483894 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.16975323855876923
[5/24] Train loss=0.16519716382026672
[10/24] Train loss=0.1908574402332306
[15/24] Train loss=0.2149810642004013
[20/24] Train loss=0.1723605990409851
Test set avg_accuracy=84.90% avg_sensitivity=67.16%, avg_specificity=91.62% avg_auc=89.04%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.181733 Test loss=0.372300 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1682029813528061
[5/24] Train loss=0.15777060389518738
[10/24] Train loss=0.19136160612106323
[15/24] Train loss=0.21818362176418304
[20/24] Train loss=0.16593463718891144
Test set avg_accuracy=78.74% avg_sensitivity=85.78%, avg_specificity=76.07% avg_auc=89.31%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.179438 Test loss=0.455717 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.16310784220695496
[5/24] Train loss=0.16619497537612915
[10/24] Train loss=0.20031462609767914
[15/24] Train loss=0.21198977530002594
[20/24] Train loss=0.17944185435771942
Test set avg_accuracy=83.42% avg_sensitivity=63.84%, avg_specificity=90.84% avg_auc=86.87%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.182153 Test loss=0.418927 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.16756965219974518
[5/24] Train loss=0.1577753722667694
[10/24] Train loss=0.18634511530399323
[15/24] Train loss=0.20877352356910706
[20/24] Train loss=0.18805459141731262
Test set avg_accuracy=82.97% avg_sensitivity=57.16%, avg_specificity=92.75% avg_auc=85.62%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.180252 Test loss=0.418715 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.186009481549263
[5/24] Train loss=0.1565578728914261
[10/24] Train loss=0.18868383765220642
[15/24] Train loss=0.20703046023845673
[20/24] Train loss=0.16978004574775696
Test set avg_accuracy=84.60% avg_sensitivity=80.14%, avg_specificity=86.28% avg_auc=91.17%
Best model saved!! Metric=16.195305896907385!!
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.179866 Test loss=0.350546 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.16741283237934113
[5/24] Train loss=0.15847909450531006
[10/24] Train loss=0.1937922239303589
[15/24] Train loss=0.1955885887145996
[20/24] Train loss=0.17454786598682404
Test set avg_accuracy=85.51% avg_sensitivity=71.37%, avg_specificity=90.86% avg_auc=90.86%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.175411 Test loss=0.341574 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.1659727841615677
[5/24] Train loss=0.15067888796329498
[10/24] Train loss=0.18948720395565033
[15/24] Train loss=0.19156703352928162
[20/24] Train loss=0.16399292647838593
Test set avg_accuracy=83.54% avg_sensitivity=73.03%, avg_specificity=87.52% avg_auc=89.33%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.173583 Test loss=0.378178 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.15628154575824738
[5/24] Train loss=0.15534831583499908
[10/24] Train loss=0.18814097344875336
[15/24] Train loss=0.20426057279109955
[20/24] Train loss=0.16494102776050568
Test set avg_accuracy=83.36% avg_sensitivity=80.47%, avg_specificity=84.45% avg_auc=90.09%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.173007 Test loss=0.387895 Current lr=[0.000224838296036774]

[0/24] Train loss=0.17543034255504608
[5/24] Train loss=0.15588033199310303
[10/24] Train loss=0.19321668148040771
[15/24] Train loss=0.20564474165439606
[20/24] Train loss=0.1815434694290161
Test set avg_accuracy=80.49% avg_sensitivity=83.51%, avg_specificity=79.35% avg_auc=88.61%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.177431 Test loss=0.445413 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.16478125751018524
[5/24] Train loss=0.14876674115657806
[10/24] Train loss=0.1865251362323761
[15/24] Train loss=0.19856654107570648
[20/24] Train loss=0.17032179236412048
Test set avg_accuracy=84.35% avg_sensitivity=64.12%, avg_specificity=92.01% avg_auc=88.07%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.173793 Test loss=0.378974 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.1619676947593689
[5/24] Train loss=0.15368394553661346
[10/24] Train loss=0.1819794476032257
[15/24] Train loss=0.19420766830444336
[20/24] Train loss=0.1680230051279068
Test set avg_accuracy=83.72% avg_sensitivity=50.38%, avg_specificity=96.36% avg_auc=85.77%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.170019 Test loss=0.428016 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.17226891219615936
[5/24] Train loss=0.15624378621578217
[10/24] Train loss=0.19403484463691711
[15/24] Train loss=0.19906826317310333
[20/24] Train loss=0.17217710614204407
Test set avg_accuracy=83.79% avg_sensitivity=80.24%, avg_specificity=85.13% avg_auc=89.59%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.174629 Test loss=0.393183 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.16284634172916412
[5/24] Train loss=0.15395206212997437
[10/24] Train loss=0.1945101022720337
[15/24] Train loss=0.19874799251556396
[20/24] Train loss=0.16468048095703125
Test set avg_accuracy=84.77% avg_sensitivity=58.82%, avg_specificity=94.60% avg_auc=88.42%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.174844 Test loss=0.389091 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.16307835280895233
[5/24] Train loss=0.16640593111515045
[10/24] Train loss=0.184096097946167
[15/24] Train loss=0.18693438172340393
[20/24] Train loss=0.16769957542419434
Test set avg_accuracy=82.16% avg_sensitivity=58.39%, avg_specificity=91.17% avg_auc=85.77%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.171018 Test loss=0.427213 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1614394336938858
[5/24] Train loss=0.143617644906044
[10/24] Train loss=0.1885693520307541
[15/24] Train loss=0.18633802235126495
[20/24] Train loss=0.16727741062641144
Test set avg_accuracy=83.37% avg_sensitivity=84.69%, avg_specificity=82.87% avg_auc=90.79%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.170793 Test loss=0.397590 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.16135506331920624
[5/24] Train loss=0.15607088804244995
[10/24] Train loss=0.19556525349617004
[15/24] Train loss=0.19862957298755646
[20/24] Train loss=0.163234680891037
Test set avg_accuracy=83.45% avg_sensitivity=58.77%, avg_specificity=92.80% avg_auc=86.63%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.169432 Test loss=0.421573 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1564241349697113
[5/24] Train loss=0.15535612404346466
[10/24] Train loss=0.18658362329006195
[15/24] Train loss=0.1858767569065094
[20/24] Train loss=0.1773877888917923
Test set avg_accuracy=84.54% avg_sensitivity=59.62%, avg_specificity=93.99% avg_auc=87.53%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.166007 Test loss=0.393962 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.16131147742271423
[5/24] Train loss=0.15157432854175568
[10/24] Train loss=0.19086545705795288
[15/24] Train loss=0.19308428466320038
[20/24] Train loss=0.1756037324666977
Test set avg_accuracy=85.56% avg_sensitivity=74.74%, avg_specificity=89.66% avg_auc=90.46%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.170950 Test loss=0.355116 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1606367528438568
[5/24] Train loss=0.14645026624202728
[10/24] Train loss=0.18407607078552246
[15/24] Train loss=0.18382810056209564
[20/24] Train loss=0.1621481031179428
Test set avg_accuracy=83.06% avg_sensitivity=50.24%, avg_specificity=95.49% avg_auc=86.65%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.166703 Test loss=0.440062 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.15430104732513428
[5/24] Train loss=0.14928410947322845
[10/24] Train loss=0.17851556837558746
[15/24] Train loss=0.18099404871463776
[20/24] Train loss=0.16156962513923645
Test set avg_accuracy=85.18% avg_sensitivity=74.74%, avg_specificity=89.14% avg_auc=90.93%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.163125 Test loss=0.354156 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.15207365155220032
[5/24] Train loss=0.14484988152980804
[10/24] Train loss=0.1746964156627655
[15/24] Train loss=0.18186846375465393
[20/24] Train loss=0.1540112942457199
Test set avg_accuracy=85.44% avg_sensitivity=71.71%, avg_specificity=90.65% avg_auc=90.24%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.161979 Test loss=0.354709 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.14969003200531006
[5/24] Train loss=0.1468416303396225
[10/24] Train loss=0.1702309101819992
[15/24] Train loss=0.18564677238464355
[20/24] Train loss=0.15753191709518433
Test set avg_accuracy=85.07% avg_sensitivity=62.13%, avg_specificity=93.75% avg_auc=90.02%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.163030 Test loss=0.362213 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.15715977549552917
[5/24] Train loss=0.1459815800189972
[10/24] Train loss=0.17059116065502167
[15/24] Train loss=0.1808953583240509
[20/24] Train loss=0.16433185338974
Test set avg_accuracy=86.37% avg_sensitivity=69.67%, avg_specificity=92.69% avg_auc=90.74%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.160277 Test loss=0.343261 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15185926854610443
[5/24] Train loss=0.14477714896202087
[10/24] Train loss=0.16534973680973053
[15/24] Train loss=0.17770597338676453
[20/24] Train loss=0.15758365392684937
Test set avg_accuracy=83.96% avg_sensitivity=57.58%, avg_specificity=93.95% avg_auc=86.85%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.159219 Test loss=0.413199 Current lr=[0.000156543481933168]

[0/24] Train loss=0.15350571274757385
[5/24] Train loss=0.1397152841091156
[10/24] Train loss=0.16045626997947693
[15/24] Train loss=0.170514777302742
[20/24] Train loss=0.15951001644134521
Test set avg_accuracy=84.24% avg_sensitivity=57.39%, avg_specificity=94.42% avg_auc=86.82%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.158705 Test loss=0.407246 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1477666050195694
[5/24] Train loss=0.1526576727628708
[10/24] Train loss=0.16426634788513184
[15/24] Train loss=0.17012259364128113
[20/24] Train loss=0.15426020324230194
Test set avg_accuracy=85.66% avg_sensitivity=63.22%, avg_specificity=94.17% avg_auc=89.06%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.156115 Test loss=0.371112 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15099923312664032
[5/24] Train loss=0.1418236345052719
[10/24] Train loss=0.17096075415611267
[15/24] Train loss=0.16944892704486847
[20/24] Train loss=0.15680141746997833
Test set avg_accuracy=84.38% avg_sensitivity=53.46%, avg_specificity=96.09% avg_auc=86.89%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.155413 Test loss=0.419276 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.1433417648077011
[5/24] Train loss=0.145218625664711
[10/24] Train loss=0.16745604574680328
[15/24] Train loss=0.17464140057563782
[20/24] Train loss=0.15589381754398346
Test set avg_accuracy=85.81% avg_sensitivity=64.17%, avg_specificity=94.00% avg_auc=90.51%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.154837 Test loss=0.352661 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1488179862499237
[5/24] Train loss=0.14504487812519073
[10/24] Train loss=0.16169503331184387
[15/24] Train loss=0.16827882826328278
[20/24] Train loss=0.1517297774553299
Test set avg_accuracy=83.48% avg_sensitivity=49.91%, avg_specificity=96.19% avg_auc=86.31%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.153510 Test loss=0.442786 Current lr=[0.000134135431043539]

[0/24] Train loss=0.14741623401641846
[5/24] Train loss=0.13654477894306183
[10/24] Train loss=0.1605040282011032
[15/24] Train loss=0.17352086305618286
[20/24] Train loss=0.1528000384569168
Test set avg_accuracy=85.90% avg_sensitivity=68.39%, avg_specificity=92.53% avg_auc=90.55%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.153005 Test loss=0.343326 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.146927148103714
[5/24] Train loss=0.13950161635875702
[10/24] Train loss=0.16344958543777466
[15/24] Train loss=0.17477567493915558
[20/24] Train loss=0.14722606539726257
Test set avg_accuracy=83.62% avg_sensitivity=49.48%, avg_specificity=96.55% avg_auc=85.57%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.152691 Test loss=0.453047 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.14997941255569458
[5/24] Train loss=0.1448633074760437
[10/24] Train loss=0.16016484797000885
[15/24] Train loss=0.1667739599943161
[20/24] Train loss=0.15630735456943512
Test set avg_accuracy=85.03% avg_sensitivity=62.61%, avg_specificity=93.52% avg_auc=88.80%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.151907 Test loss=0.388732 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.1420033872127533
[5/24] Train loss=0.13735240697860718
[10/24] Train loss=0.15577541291713715
[15/24] Train loss=0.16871647536754608
[20/24] Train loss=0.1532662808895111
Test set avg_accuracy=85.62% avg_sensitivity=75.69%, avg_specificity=89.39% avg_auc=91.12%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.151631 Test loss=0.346014 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.142620250582695
[5/24] Train loss=0.14476929605007172
[10/24] Train loss=0.16165517270565033
[15/24] Train loss=0.15993672609329224
[20/24] Train loss=0.15055912733078003
Test set avg_accuracy=85.85% avg_sensitivity=66.68%, avg_specificity=93.11% avg_auc=90.67%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.150950 Test loss=0.347350 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14299063384532928
[5/24] Train loss=0.14704445004463196
[10/24] Train loss=0.1574636846780777
[15/24] Train loss=0.16448791325092316
[20/24] Train loss=0.15424805879592896
Test set avg_accuracy=85.89% avg_sensitivity=67.39%, avg_specificity=92.89% avg_auc=90.22%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.150116 Test loss=0.357042 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.13890340924263
[5/24] Train loss=0.13997995853424072
[10/24] Train loss=0.15661555528640747
[15/24] Train loss=0.16266365349292755
[20/24] Train loss=0.14994844794273376
Test set avg_accuracy=84.51% avg_sensitivity=74.12%, avg_specificity=88.44% avg_auc=90.17%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.148643 Test loss=0.373255 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1402302086353302
[5/24] Train loss=0.13487444818019867
[10/24] Train loss=0.15920524299144745
[15/24] Train loss=0.15945664048194885
[20/24] Train loss=0.1491953581571579
Test set avg_accuracy=85.35% avg_sensitivity=67.39%, avg_specificity=92.15% avg_auc=90.19%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.147308 Test loss=0.361191 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14176766574382782
[5/24] Train loss=0.13257792592048645
[10/24] Train loss=0.15426820516586304
[15/24] Train loss=0.15416501462459564
[20/24] Train loss=0.14497484266757965
Test set avg_accuracy=85.77% avg_sensitivity=76.87%, avg_specificity=89.14% avg_auc=91.41%
Best model saved!! Metric=17.187681717995304!!
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.145875 Test loss=0.350795 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14124158024787903
[5/24] Train loss=0.13150112330913544
[10/24] Train loss=0.16154661774635315
[15/24] Train loss=0.15613751113414764
[20/24] Train loss=0.14759662747383118
Test set avg_accuracy=85.52% avg_sensitivity=75.50%, avg_specificity=89.32% avg_auc=90.84%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.145385 Test loss=0.358087 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.13854138553142548
[5/24] Train loss=0.1281375139951706
[10/24] Train loss=0.15917254984378815
[15/24] Train loss=0.15384678542613983
[20/24] Train loss=0.1438109576702118
Test set avg_accuracy=84.49% avg_sensitivity=72.18%, avg_specificity=89.16% avg_auc=90.27%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.143149 Test loss=0.368169 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1331457942724228
[5/24] Train loss=0.13290899991989136
[10/24] Train loss=0.15944121778011322
[15/24] Train loss=0.15659670531749725
[20/24] Train loss=0.14805103838443756
Test set avg_accuracy=85.44% avg_sensitivity=76.45%, avg_specificity=88.85% avg_auc=91.35%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.142702 Test loss=0.357315 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13599750399589539
[5/24] Train loss=0.12894800305366516
[10/24] Train loss=0.15268880128860474
[15/24] Train loss=0.15353532135486603
[20/24] Train loss=0.14432841539382935
Test set avg_accuracy=83.98% avg_sensitivity=79.43%, avg_specificity=85.71% avg_auc=90.90%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.141476 Test loss=0.371541 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13052847981452942
[5/24] Train loss=0.12869368493556976
[10/24] Train loss=0.14350789785385132
[15/24] Train loss=0.15022145211696625
[20/24] Train loss=0.147169291973114
Test set avg_accuracy=85.59% avg_sensitivity=73.89%, avg_specificity=90.02% avg_auc=90.98%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.140612 Test loss=0.353838 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13322292268276215
[5/24] Train loss=0.1288418173789978
[10/24] Train loss=0.14921781420707703
[15/24] Train loss=0.15128964185714722
[20/24] Train loss=0.14307765662670135
Test set avg_accuracy=83.76% avg_sensitivity=75.73%, avg_specificity=86.80% avg_auc=89.77%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.140339 Test loss=0.390395 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1348690688610077
[5/24] Train loss=0.12429626286029816
[10/24] Train loss=0.14742520451545715
[15/24] Train loss=0.1553109586238861
[20/24] Train loss=0.13771019876003265
Test set avg_accuracy=86.15% avg_sensitivity=72.80%, avg_specificity=91.20% avg_auc=90.66%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.140426 Test loss=0.354844 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1330239176750183
[5/24] Train loss=0.12580738961696625
[10/24] Train loss=0.14624890685081482
[15/24] Train loss=0.15729886293411255
[20/24] Train loss=0.1408941000699997
Test set avg_accuracy=85.20% avg_sensitivity=77.39%, avg_specificity=88.15% avg_auc=90.85%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.138819 Test loss=0.356509 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13241028785705566
[5/24] Train loss=0.12381280958652496
[10/24] Train loss=0.1479676067829132
[15/24] Train loss=0.14737273752689362
[20/24] Train loss=0.13487228751182556
Test set avg_accuracy=85.39% avg_sensitivity=77.16%, avg_specificity=88.51% avg_auc=91.40%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.136718 Test loss=0.352403 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.12934507429599762
[5/24] Train loss=0.12319433689117432
[10/24] Train loss=0.1494712233543396
[15/24] Train loss=0.14523659646511078
[20/24] Train loss=0.14440390467643738
Test set avg_accuracy=85.59% avg_sensitivity=75.26%, avg_specificity=89.50% avg_auc=91.11%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.135721 Test loss=0.351418 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.12746061384677887
[5/24] Train loss=0.12303300201892853
[10/24] Train loss=0.14468251168727875
[15/24] Train loss=0.14373347163200378
[20/24] Train loss=0.13556033372879028
Test set avg_accuracy=83.88% avg_sensitivity=82.94%, avg_specificity=84.24% avg_auc=91.14%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.134321 Test loss=0.374571 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1274605542421341
[5/24] Train loss=0.12251259386539459
[10/24] Train loss=0.1457204967737198
[15/24] Train loss=0.14707902073860168
[20/24] Train loss=0.13974574208259583
Test set avg_accuracy=84.64% avg_sensitivity=75.21%, avg_specificity=88.20% avg_auc=90.79%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.134755 Test loss=0.361406 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1294049471616745
[5/24] Train loss=0.12505199015140533
[10/24] Train loss=0.1407281905412674
[15/24] Train loss=0.13936832547187805
[20/24] Train loss=0.13721643388271332
Test set avg_accuracy=85.74% avg_sensitivity=70.90%, avg_specificity=91.36% avg_auc=90.64%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.133074 Test loss=0.354605 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12448132783174515
[5/24] Train loss=0.12010349333286285
[10/24] Train loss=0.14080242812633514
[15/24] Train loss=0.14408321678638458
[20/24] Train loss=0.13647043704986572
Test set avg_accuracy=85.42% avg_sensitivity=72.80%, avg_specificity=90.20% avg_auc=90.60%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.132143 Test loss=0.357115 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12484218925237656
[5/24] Train loss=0.12058216333389282
[10/24] Train loss=0.1416509747505188
[15/24] Train loss=0.14262007176876068
[20/24] Train loss=0.13619139790534973
Test set avg_accuracy=85.10% avg_sensitivity=74.45%, avg_specificity=89.14% avg_auc=90.23%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.131050 Test loss=0.365763 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12542065978050232
[5/24] Train loss=0.12014037370681763
[10/24] Train loss=0.13973942399024963
[15/24] Train loss=0.14012189209461212
[20/24] Train loss=0.1324993222951889
Test set avg_accuracy=85.39% avg_sensitivity=72.51%, avg_specificity=90.27% avg_auc=90.80%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.130898 Test loss=0.354098 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12675854563713074
[5/24] Train loss=0.12220799922943115
[10/24] Train loss=0.13752146065235138
[15/24] Train loss=0.1398618072271347
[20/24] Train loss=0.12902437150478363
Test set avg_accuracy=85.23% avg_sensitivity=72.65%, avg_specificity=90.00% avg_auc=90.73%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.129581 Test loss=0.361457 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12362458556890488
[5/24] Train loss=0.11867530643939972
[10/24] Train loss=0.13464897871017456
[15/24] Train loss=0.13681243360042572
[20/24] Train loss=0.1333266943693161
Test set avg_accuracy=85.38% avg_sensitivity=73.74%, avg_specificity=89.78% avg_auc=90.82%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.129054 Test loss=0.360453 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12269023805856705
[5/24] Train loss=0.12188351154327393
[10/24] Train loss=0.1379254162311554
[15/24] Train loss=0.13802729547023773
[20/24] Train loss=0.13380976021289825
Test set avg_accuracy=85.69% avg_sensitivity=68.72%, avg_specificity=92.12% avg_auc=90.43%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.129203 Test loss=0.359551 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12501636147499084
[5/24] Train loss=0.12071883678436279
[10/24] Train loss=0.1378880888223648
[15/24] Train loss=0.13651177287101746
[20/24] Train loss=0.13475185632705688
Test set avg_accuracy=85.51% avg_sensitivity=72.75%, avg_specificity=90.34% avg_auc=90.67%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.129369 Test loss=0.358809 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12199842929840088
[5/24] Train loss=0.1185118556022644
[10/24] Train loss=0.13778817653656006
[15/24] Train loss=0.1393791139125824
[20/24] Train loss=0.13122200965881348
Test set avg_accuracy=85.81% avg_sensitivity=69.81%, avg_specificity=91.87% avg_auc=91.27%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.129138 Test loss=0.349866 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12322226166725159
[5/24] Train loss=0.11859778314828873
[10/24] Train loss=0.13524122536182404
[15/24] Train loss=0.1355481594800949
[20/24] Train loss=0.12974494695663452
Test set avg_accuracy=85.89% avg_sensitivity=68.67%, avg_specificity=92.41% avg_auc=90.72%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.128338 Test loss=0.353184 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1220109835267067
[5/24] Train loss=0.11976921558380127
[10/24] Train loss=0.13612894713878632
[15/24] Train loss=0.13915742933750153
[20/24] Train loss=0.13530385494232178
Test set avg_accuracy=86.12% avg_sensitivity=76.21%, avg_specificity=89.87% avg_auc=91.29%
Best model saved!! Metric=17.496075414231058!!
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.128290 Test loss=0.348277 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12134287506341934
[5/24] Train loss=0.11668795347213745
[10/24] Train loss=0.13332177698612213
[15/24] Train loss=0.13281291723251343
[20/24] Train loss=0.13026131689548492
Test set avg_accuracy=85.49% avg_sensitivity=72.09%, avg_specificity=90.57% avg_auc=90.93%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.126952 Test loss=0.354693 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.11913500726222992
[5/24] Train loss=0.11606096476316452
[10/24] Train loss=0.13175715506076813
[15/24] Train loss=0.1384187936782837
[20/24] Train loss=0.12810686230659485
Test set avg_accuracy=85.94% avg_sensitivity=72.51%, avg_specificity=91.02% avg_auc=91.01%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.125184 Test loss=0.350962 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12084048241376877
[5/24] Train loss=0.11568796634674072
[10/24] Train loss=0.13404817879199982
[15/24] Train loss=0.13621360063552856
[20/24] Train loss=0.13015246391296387
Test set avg_accuracy=85.64% avg_sensitivity=72.23%, avg_specificity=90.72% avg_auc=91.07%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.125774 Test loss=0.351727 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.11955778300762177
[5/24] Train loss=0.11645566672086716
[10/24] Train loss=0.1319447010755539
[15/24] Train loss=0.1374066174030304
[20/24] Train loss=0.12687233090400696
Test set avg_accuracy=85.99% avg_sensitivity=73.36%, avg_specificity=90.77% avg_auc=91.24%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.125053 Test loss=0.348502 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12027277052402496
[5/24] Train loss=0.1181497573852539
[10/24] Train loss=0.13358476758003235
[15/24] Train loss=0.13333813846111298
[20/24] Train loss=0.12744803726673126
Test set avg_accuracy=85.69% avg_sensitivity=72.75%, avg_specificity=90.59% avg_auc=91.16%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.124581 Test loss=0.348906 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.11803227663040161
[5/24] Train loss=0.11524975299835205
[10/24] Train loss=0.13126468658447266
[15/24] Train loss=0.1333325207233429
[20/24] Train loss=0.12954559922218323
Test set avg_accuracy=85.90% avg_sensitivity=72.65%, avg_specificity=90.92% avg_auc=91.07%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.124188 Test loss=0.350438 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.11947525292634964
[5/24] Train loss=0.11598727852106094
[10/24] Train loss=0.13248683512210846
[15/24] Train loss=0.13295041024684906
[20/24] Train loss=0.12951616942882538
Test set avg_accuracy=85.79% avg_sensitivity=72.94%, avg_specificity=90.66% avg_auc=91.20%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.124613 Test loss=0.350140 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11723709851503372
[5/24] Train loss=0.11450575292110443
[10/24] Train loss=0.130971297621727
[15/24] Train loss=0.13342046737670898
[20/24] Train loss=0.12922914326190948
Test set avg_accuracy=85.55% avg_sensitivity=72.32%, avg_specificity=90.56% avg_auc=91.00%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.123775 Test loss=0.354471 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.11901997029781342
[5/24] Train loss=0.1144651547074318
[10/24] Train loss=0.12876492738723755
[15/24] Train loss=0.1309356987476349
[20/24] Train loss=0.12752577662467957
Test set avg_accuracy=85.61% avg_sensitivity=72.61%, avg_specificity=90.54% avg_auc=90.98%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.123381 Test loss=0.355232 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11930396407842636
[5/24] Train loss=0.11523328721523285
[10/24] Train loss=0.13380086421966553
[15/24] Train loss=0.13272224366664886
[20/24] Train loss=0.12377437949180603
Test set avg_accuracy=85.77% avg_sensitivity=73.65%, avg_specificity=90.36% avg_auc=91.10%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.122800 Test loss=0.352489 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.11827930063009262
[5/24] Train loss=0.1156989112496376
[10/24] Train loss=0.13092517852783203
[15/24] Train loss=0.1333046555519104
[20/24] Train loss=0.12622889876365662
Test set avg_accuracy=85.66% avg_sensitivity=72.27%, avg_specificity=90.74% avg_auc=91.06%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.123681 Test loss=0.352630 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11778703331947327
[5/24] Train loss=0.11485346406698227
[10/24] Train loss=0.1309552639722824
[15/24] Train loss=0.13222098350524902
[20/24] Train loss=0.12541748583316803
Test set avg_accuracy=85.69% avg_sensitivity=72.37%, avg_specificity=90.74% avg_auc=91.02%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.122522 Test loss=0.352778 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1178271695971489
[5/24] Train loss=0.1157727912068367
[10/24] Train loss=0.13042081892490387
[15/24] Train loss=0.13319897651672363
[20/24] Train loss=0.1292613446712494
Test set avg_accuracy=85.70% avg_sensitivity=72.32%, avg_specificity=90.77% avg_auc=91.02%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.123312 Test loss=0.352229 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11975406855344772
[5/24] Train loss=0.11303115636110306
[10/24] Train loss=0.12851738929748535
[15/24] Train loss=0.13234439492225647
[20/24] Train loss=0.12585943937301636
Test set avg_accuracy=85.68% avg_sensitivity=72.18%, avg_specificity=90.79% avg_auc=91.02%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.122792 Test loss=0.352249 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11925353854894638
[5/24] Train loss=0.11284381151199341
[10/24] Train loss=0.12952139973640442
[15/24] Train loss=0.1329660415649414
[20/24] Train loss=0.1258813440799713
Test set avg_accuracy=85.68% avg_sensitivity=72.18%, avg_specificity=90.79% avg_auc=91.01%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.122641 Test loss=0.352714 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11621548235416412
[5/24] Train loss=0.11457128822803497
[10/24] Train loss=0.13081637024879456
[15/24] Train loss=0.13167861104011536
[20/24] Train loss=0.13052324950695038
Test set avg_accuracy=85.73% avg_sensitivity=72.27%, avg_specificity=90.83% avg_auc=91.02%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.122968 Test loss=0.352494 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11809459328651428
[5/24] Train loss=0.11519788205623627
[10/24] Train loss=0.1306069940328598
[15/24] Train loss=0.13377907872200012
[20/24] Train loss=0.12358688563108444
Test set avg_accuracy=85.69% avg_sensitivity=72.32%, avg_specificity=90.75% avg_auc=91.02%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.122872 Test loss=0.352691 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=86.12% sen=76.21%, spe=89.87%, auc=91.29%!
Fold[3] Avg_overlap=0.64%(±0.24428861396243698)
[0/24] Train loss=0.7539449334144592
[5/24] Train loss=0.743016242980957
[10/24] Train loss=0.7395040392875671
[15/24] Train loss=0.729809045791626
[20/24] Train loss=0.7114256620407104
Test set avg_accuracy=61.72% avg_sensitivity=49.23%, avg_specificity=66.12% avg_auc=61.23%
Best model saved!! Metric=-87.70750570468861!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.732974 Test loss=0.670200 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.71098393201828
[5/24] Train loss=0.7141483426094055
[10/24] Train loss=0.7028377652168274
[15/24] Train loss=0.6983908414840698
[20/24] Train loss=0.6844033002853394
Test set avg_accuracy=66.63% avg_sensitivity=65.82%, avg_specificity=66.91% avg_auc=72.68%
Best model saved!! Metric=-53.962589730925814!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.701815 Test loss=0.620540 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6801577210426331
[5/24] Train loss=0.685967206954956
[10/24] Train loss=0.6882202625274658
[15/24] Train loss=0.6607391238212585
[20/24] Train loss=0.652906596660614
Test set avg_accuracy=70.17% avg_sensitivity=75.46%, avg_specificity=68.30% avg_auc=78.39%
Best model saved!! Metric=-33.67615669062259!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.673936 Test loss=0.585974 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6460669040679932
[5/24] Train loss=0.6490587592124939
[10/24] Train loss=0.6587422490119934
[15/24] Train loss=0.6359074115753174
[20/24] Train loss=0.6238566637039185
Test set avg_accuracy=72.88% avg_sensitivity=77.41%, avg_specificity=71.28% avg_auc=80.89%
Best model saved!! Metric=-23.53796283412595!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.645031 Test loss=0.561255 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6089635491371155
[5/24] Train loss=0.6271116733551025
[10/24] Train loss=0.6335716843605042
[15/24] Train loss=0.609973669052124
[20/24] Train loss=0.5981155037879944
Test set avg_accuracy=74.90% avg_sensitivity=77.06%, avg_specificity=74.13% avg_auc=82.71%
Best model saved!! Metric=-17.19958347666278!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.618432 Test loss=0.536444 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.590688943862915
[5/24] Train loss=0.600785493850708
[10/24] Train loss=0.6122544407844543
[15/24] Train loss=0.5894376635551453
[20/24] Train loss=0.5750013589859009
Test set avg_accuracy=77.45% avg_sensitivity=76.06%, avg_specificity=77.94% avg_auc=83.81%
Best model saved!! Metric=-10.748155573670275!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.593468 Test loss=0.511648 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.564382791519165
[5/24] Train loss=0.5680782794952393
[10/24] Train loss=0.5784904956817627
[15/24] Train loss=0.5539703369140625
[20/24] Train loss=0.5506196618080139
Test set avg_accuracy=78.55% avg_sensitivity=75.31%, avg_specificity=79.70% avg_auc=84.69%
Best model saved!! Metric=-7.749840637410429!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.565782 Test loss=0.493784 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5354720950126648
[5/24] Train loss=0.5388311147689819
[10/24] Train loss=0.5577239990234375
[15/24] Train loss=0.5303514003753662
[20/24] Train loss=0.5262464880943298
Test set avg_accuracy=79.38% avg_sensitivity=75.21%, avg_specificity=80.84% avg_auc=85.45%
Best model saved!! Metric=-5.125561305893967!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.539574 Test loss=0.476035 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5073005557060242
[5/24] Train loss=0.5132827758789062
[10/24] Train loss=0.5297192931175232
[15/24] Train loss=0.5047063827514648
[20/24] Train loss=0.4977298974990845
Test set avg_accuracy=80.42% avg_sensitivity=72.41%, avg_specificity=83.24% avg_auc=86.09%
Best model saved!! Metric=-3.840830751203029!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.514899 Test loss=0.454081 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.48580801486968994
[5/24] Train loss=0.4904390573501587
[10/24] Train loss=0.5058174133300781
[15/24] Train loss=0.4790968596935272
[20/24] Train loss=0.4749371409416199
Test set avg_accuracy=81.39% avg_sensitivity=71.76%, avg_specificity=84.79% avg_auc=86.92%
Best model saved!! Metric=-1.1366411332599569!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.490393 Test loss=0.437569 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4585351049900055
[5/24] Train loss=0.4630335867404938
[10/24] Train loss=0.4788624048233032
[15/24] Train loss=0.46344661712646484
[20/24] Train loss=0.44777193665504456
Test set avg_accuracy=82.19% avg_sensitivity=71.11%, avg_specificity=86.09% avg_auc=87.68%
Best model saved!! Metric=1.0664252142725985!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.466625 Test loss=0.421567 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4381157457828522
[5/24] Train loss=0.4446147084236145
[10/24] Train loss=0.45446500182151794
[15/24] Train loss=0.44465893507003784
[20/24] Train loss=0.42434972524642944
Test set avg_accuracy=83.06% avg_sensitivity=70.91%, avg_specificity=87.34% avg_auc=88.54%
Best model saved!! Metric=3.854661859371177!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.445108 Test loss=0.400736 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4130200147628784
[5/24] Train loss=0.42155566811561584
[10/24] Train loss=0.44162338972091675
[15/24] Train loss=0.42636966705322266
[20/24] Train loss=0.402210533618927
Test set avg_accuracy=83.82% avg_sensitivity=70.96%, avg_specificity=88.34% avg_auc=89.20%
Best model saved!! Metric=6.321428570937513!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.424348 Test loss=0.389195 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3978803753852844
[5/24] Train loss=0.4006367623806
[10/24] Train loss=0.4193747341632843
[15/24] Train loss=0.4101698696613312
[20/24] Train loss=0.38511601090431213
Test set avg_accuracy=84.00% avg_sensitivity=74.11%, avg_specificity=87.48% avg_auc=89.90%
Best model saved!! Metric=9.491837026189984!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.406535 Test loss=0.381024 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.38332095742225647
[5/24] Train loss=0.38493242859840393
[10/24] Train loss=0.4047998785972595
[15/24] Train loss=0.3937353193759918
[20/24] Train loss=0.36492595076560974
Test set avg_accuracy=84.73% avg_sensitivity=76.06%, avg_specificity=87.78% avg_auc=90.41%
Best model saved!! Metric=12.974926960136543!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.389875 Test loss=0.371971 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.36294466257095337
[5/24] Train loss=0.36925509572029114
[10/24] Train loss=0.38601580262184143
[15/24] Train loss=0.3796561658382416
[20/24] Train loss=0.3517557382583618
Test set avg_accuracy=85.09% avg_sensitivity=73.41%, avg_specificity=89.21% avg_auc=90.67%
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.374402 Test loss=0.357791 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3519041836261749
[5/24] Train loss=0.3525559902191162
[10/24] Train loss=0.37973466515541077
[15/24] Train loss=0.3689546287059784
[20/24] Train loss=0.3422884941101074
Test set avg_accuracy=85.42% avg_sensitivity=74.81%, avg_specificity=89.15% avg_auc=91.04%
Best model saved!! Metric=14.426237070758503!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.361283 Test loss=0.348897 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.33918604254722595
[5/24] Train loss=0.3406761884689331
[10/24] Train loss=0.36268898844718933
[15/24] Train loss=0.36005422472953796
[20/24] Train loss=0.323942095041275
Test set avg_accuracy=85.57% avg_sensitivity=76.56%, avg_specificity=88.75% avg_auc=91.35%
Best model saved!! Metric=16.235367269151993!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.350128 Test loss=0.347092 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.323803186416626
[5/24] Train loss=0.3269508481025696
[10/24] Train loss=0.3554314374923706
[15/24] Train loss=0.3473135828971863
[20/24] Train loss=0.31644129753112793
Test set avg_accuracy=85.86% avg_sensitivity=76.61%, avg_specificity=89.12% avg_auc=91.53%
Best model saved!! Metric=17.114982976958856!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.338912 Test loss=0.339132 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3212532699108124
[5/24] Train loss=0.3189445734024048
[10/24] Train loss=0.33825793862342834
[15/24] Train loss=0.33695298433303833
[20/24] Train loss=0.31010791659355164
Test set avg_accuracy=85.81% avg_sensitivity=76.76%, avg_specificity=88.99% avg_auc=91.55%
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.330148 Test loss=0.338460 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3103235960006714
[5/24] Train loss=0.31381091475486755
[10/24] Train loss=0.33732715249061584
[15/24] Train loss=0.33159950375556946
[20/24] Train loss=0.3038465678691864
Test set avg_accuracy=86.47% avg_sensitivity=71.11%, avg_specificity=91.88% avg_auc=92.00%
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.320896 Test loss=0.316962 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.300020307302475
[5/24] Train loss=0.3099147081375122
[10/24] Train loss=0.32810088992118835
[15/24] Train loss=0.3241022229194641
[20/24] Train loss=0.29370659589767456
Test set avg_accuracy=85.83% avg_sensitivity=62.72%, avg_specificity=93.98% avg_auc=91.34%
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.311759 Test loss=0.323804 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.29740214347839355
[5/24] Train loss=0.29806891083717346
[10/24] Train loss=0.30959832668304443
[15/24] Train loss=0.32778942584991455
[20/24] Train loss=0.2829436957836151
Test set avg_accuracy=85.57% avg_sensitivity=58.07%, avg_specificity=95.26% avg_auc=90.90%
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.305858 Test loss=0.335098 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2913875877857208
[5/24] Train loss=0.2864600718021393
[10/24] Train loss=0.3096947968006134
[15/24] Train loss=0.31221169233322144
[20/24] Train loss=0.2733255624771118
Test set avg_accuracy=85.64% avg_sensitivity=60.27%, avg_specificity=94.58% avg_auc=91.20%
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.296144 Test loss=0.326170 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2822868227958679
[5/24] Train loss=0.2743906080722809
[10/24] Train loss=0.3029671907424927
[15/24] Train loss=0.3073149621486664
[20/24] Train loss=0.2690213620662689
Test set avg_accuracy=86.41% avg_sensitivity=70.66%, avg_specificity=91.95% avg_auc=91.44%
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.286826 Test loss=0.321356 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2748450040817261
[5/24] Train loss=0.2726706862449646
[10/24] Train loss=0.29494187235832214
[15/24] Train loss=0.2942965030670166
[20/24] Train loss=0.26877060532569885
Test set avg_accuracy=84.58% avg_sensitivity=51.77%, avg_specificity=96.14% avg_auc=90.07%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.281634 Test loss=0.356297 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.28628218173980713
[5/24] Train loss=0.28473028540611267
[10/24] Train loss=0.2878889739513397
[15/24] Train loss=0.2929815351963043
[20/24] Train loss=0.2604098320007324
Test set avg_accuracy=83.92% avg_sensitivity=45.13%, avg_specificity=97.59% avg_auc=89.45%
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.279652 Test loss=0.382075 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.26819249987602234
[5/24] Train loss=0.2761533856391907
[10/24] Train loss=0.2821716070175171
[15/24] Train loss=0.2829605042934418
[20/24] Train loss=0.24768351018428802
Test set avg_accuracy=87.07% avg_sensitivity=68.47%, avg_specificity=93.63% avg_auc=91.99%
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.273220 Test loss=0.309659 Current lr=[0.000210185142098938]

[0/24] Train loss=0.25452956557273865
[5/24] Train loss=0.26578888297080994
[10/24] Train loss=0.27549922466278076
[15/24] Train loss=0.2770741879940033
[20/24] Train loss=0.2547743022441864
Test set avg_accuracy=85.14% avg_sensitivity=54.67%, avg_specificity=95.88% avg_auc=89.63%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.263285 Test loss=0.357126 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2513792812824249
[5/24] Train loss=0.2384301722049713
[10/24] Train loss=0.2719692885875702
[15/24] Train loss=0.27864450216293335
[20/24] Train loss=0.24268348515033722
Test set avg_accuracy=85.34% avg_sensitivity=61.02%, avg_specificity=93.91% avg_auc=90.64%
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.259607 Test loss=0.333719 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2584783732891083
[5/24] Train loss=0.24528340995311737
[10/24] Train loss=0.2731829881668091
[15/24] Train loss=0.25457441806793213
[20/24] Train loss=0.23893602192401886
Test set avg_accuracy=86.34% avg_sensitivity=74.81%, avg_specificity=90.40% avg_auc=91.70%
Best model saved!! Metric=17.25322069922842!!
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.253773 Test loss=0.333673 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.23628544807434082
[5/24] Train loss=0.24436414241790771
[10/24] Train loss=0.2779405117034912
[15/24] Train loss=0.25689202547073364
[20/24] Train loss=0.23510026931762695
Test set avg_accuracy=86.56% avg_sensitivity=66.22%, avg_specificity=93.73% avg_auc=91.36%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.249371 Test loss=0.318024 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.23191729187965393
[5/24] Train loss=0.22660043835639954
[10/24] Train loss=0.26676538586616516
[15/24] Train loss=0.2652799189090729
[20/24] Train loss=0.24342496693134308
Test set avg_accuracy=84.62% avg_sensitivity=51.12%, avg_specificity=96.43% avg_auc=89.06%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.244856 Test loss=0.369225 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.23412175476551056
[5/24] Train loss=0.23537524044513702
[10/24] Train loss=0.2610417306423187
[15/24] Train loss=0.2626909911632538
[20/24] Train loss=0.22275348007678986
Test set avg_accuracy=84.28% avg_sensitivity=58.87%, avg_specificity=93.24% avg_auc=87.54%
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.240254 Test loss=0.381972 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.23341967165470123
[5/24] Train loss=0.21686170995235443
[10/24] Train loss=0.2599998712539673
[15/24] Train loss=0.2622703015804291
[20/24] Train loss=0.22360248863697052
Test set avg_accuracy=82.33% avg_sensitivity=40.78%, avg_specificity=96.97% avg_auc=85.93%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.233608 Test loss=0.413951 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.23121891915798187
[5/24] Train loss=0.1965380758047104
[10/24] Train loss=0.24546362459659576
[15/24] Train loss=0.23619551956653595
[20/24] Train loss=0.2205178588628769
Test set avg_accuracy=86.18% avg_sensitivity=65.67%, avg_specificity=93.41% avg_auc=90.22%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.228053 Test loss=0.331797 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.22101786732673645
[5/24] Train loss=0.21487952768802643
[10/24] Train loss=0.25510865449905396
[15/24] Train loss=0.2509186863899231
[20/24] Train loss=0.23242226243019104
Test set avg_accuracy=80.91% avg_sensitivity=31.33%, avg_specificity=98.38% avg_auc=82.67%
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.231040 Test loss=0.496361 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.21629010140895844
[5/24] Train loss=0.19362667202949524
[10/24] Train loss=0.24918681383132935
[15/24] Train loss=0.25232186913490295
[20/24] Train loss=0.22495707869529724
Test set avg_accuracy=85.34% avg_sensitivity=56.17%, avg_specificity=95.62% avg_auc=89.51%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.228049 Test loss=0.357245 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.22234933078289032
[5/24] Train loss=0.20142459869384766
[10/24] Train loss=0.24811455607414246
[15/24] Train loss=0.23930373787879944
[20/24] Train loss=0.21716156601905823
Test set avg_accuracy=82.71% avg_sensitivity=40.28%, avg_specificity=97.66% avg_auc=84.65%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.223447 Test loss=0.449038 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.20437732338905334
[5/24] Train loss=0.2080366015434265
[10/24] Train loss=0.246131032705307
[15/24] Train loss=0.25486013293266296
[20/24] Train loss=0.2142130434513092
Test set avg_accuracy=84.74% avg_sensitivity=56.72%, avg_specificity=94.61% avg_auc=88.84%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.223348 Test loss=0.374608 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.20124682784080505
[5/24] Train loss=0.1917525976896286
[10/24] Train loss=0.24625283479690552
[15/24] Train loss=0.23960569500923157
[20/24] Train loss=0.21088258922100067
Test set avg_accuracy=85.36% avg_sensitivity=64.12%, avg_specificity=92.85% avg_auc=90.13%
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.219361 Test loss=0.342572 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.20535412430763245
[5/24] Train loss=0.18749085068702698
[10/24] Train loss=0.23508913815021515
[15/24] Train loss=0.2475438266992569
[20/24] Train loss=0.21097132563591003
Test set avg_accuracy=84.21% avg_sensitivity=55.52%, avg_specificity=94.31% avg_auc=88.81%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.217787 Test loss=0.361408 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.21229182183742523
[5/24] Train loss=0.18045316636562347
[10/24] Train loss=0.24195635318756104
[15/24] Train loss=0.2334475964307785
[20/24] Train loss=0.2127692997455597
Test set avg_accuracy=84.23% avg_sensitivity=48.88%, avg_specificity=96.69% avg_auc=88.06%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.215369 Test loss=0.378761 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.20369505882263184
[5/24] Train loss=0.18869130313396454
[10/24] Train loss=0.24087877571582794
[15/24] Train loss=0.23820671439170837
[20/24] Train loss=0.21408593654632568
Test set avg_accuracy=85.14% avg_sensitivity=53.87%, avg_specificity=96.16% avg_auc=87.23%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.215802 Test loss=0.380070 Current lr=[0.00029967723776099]

[0/24] Train loss=0.1980384737253189
[5/24] Train loss=0.1864955574274063
[10/24] Train loss=0.22704768180847168
[15/24] Train loss=0.22341465950012207
[20/24] Train loss=0.20730865001678467
Test set avg_accuracy=84.13% avg_sensitivity=51.42%, avg_specificity=95.65% avg_auc=87.03%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.212113 Test loss=0.385802 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.20009343326091766
[5/24] Train loss=0.17851640284061432
[10/24] Train loss=0.21680592000484467
[15/24] Train loss=0.23706264793872833
[20/24] Train loss=0.20539726316928864
Test set avg_accuracy=79.38% avg_sensitivity=23.84%, avg_specificity=98.94% avg_auc=80.61%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.209478 Test loss=0.613358 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.195848286151886
[5/24] Train loss=0.18082210421562195
[10/24] Train loss=0.21741575002670288
[15/24] Train loss=0.24511539936065674
[20/24] Train loss=0.20962795615196228
Test set avg_accuracy=78.02% avg_sensitivity=18.44%, avg_specificity=99.01% avg_auc=82.26%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.209456 Test loss=0.561196 Current lr=[0.000299720220882401]

[0/24] Train loss=0.21120689809322357
[5/24] Train loss=0.1920827329158783
[10/24] Train loss=0.21651659905910492
[15/24] Train loss=0.25129231810569763
[20/24] Train loss=0.20685887336730957
Test set avg_accuracy=80.39% avg_sensitivity=29.89%, avg_specificity=98.19% avg_auc=84.50%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.211561 Test loss=0.503733 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19505806267261505
[5/24] Train loss=0.1821230798959732
[10/24] Train loss=0.2047169953584671
[15/24] Train loss=0.22236551344394684
[20/24] Train loss=0.19822882115840912
Test set avg_accuracy=85.92% avg_sensitivity=61.02%, avg_specificity=94.70% avg_auc=90.07%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.204180 Test loss=0.343382 Current lr=[0.000298904600941902]

[0/24] Train loss=0.18862681090831757
[5/24] Train loss=0.1836019605398178
[10/24] Train loss=0.20915229618549347
[15/24] Train loss=0.22833658754825592
[20/24] Train loss=0.20174160599708557
Test set avg_accuracy=80.87% avg_sensitivity=34.33%, avg_specificity=97.27% avg_auc=81.78%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.206228 Test loss=0.488364 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.21011337637901306
[5/24] Train loss=0.1929454803466797
[10/24] Train loss=0.20905862748622894
[15/24] Train loss=0.22258193790912628
[20/24] Train loss=0.2035108059644699
Test set avg_accuracy=83.02% avg_sensitivity=40.43%, avg_specificity=98.03% avg_auc=85.89%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.204591 Test loss=0.440616 Current lr=[0.000297555943323901]

[0/24] Train loss=0.1885758340358734
[5/24] Train loss=0.1887497752904892
[10/24] Train loss=0.20960722863674164
[15/24] Train loss=0.226848766207695
[20/24] Train loss=0.18731346726417542
Test set avg_accuracy=86.04% avg_sensitivity=60.72%, avg_specificity=94.96% avg_auc=91.11%
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.200827 Test loss=0.337601 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.19470804929733276
[5/24] Train loss=0.18899108469486237
[10/24] Train loss=0.20877443253993988
[15/24] Train loss=0.20838604867458344
[20/24] Train loss=0.20364205539226532
Test set avg_accuracy=86.21% avg_sensitivity=76.41%, avg_specificity=89.66% avg_auc=91.47%
Best model saved!! Metric=17.752355204600775!!
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.199784 Test loss=0.337641 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.19492916762828827
[5/24] Train loss=0.17931021749973297
[10/24] Train loss=0.22203856706619263
[15/24] Train loss=0.21922263503074646
[20/24] Train loss=0.19721023738384247
Test set avg_accuracy=86.30% avg_sensitivity=62.37%, avg_specificity=94.73% avg_auc=88.66%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.198555 Test loss=0.366702 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.18877427279949188
[5/24] Train loss=0.19023720920085907
[10/24] Train loss=0.21416977047920227
[15/24] Train loss=0.2143174111843109
[20/24] Train loss=0.19773326814174652
Test set avg_accuracy=85.56% avg_sensitivity=61.42%, avg_specificity=94.07% avg_auc=88.95%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.198110 Test loss=0.371034 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.18974146246910095
[5/24] Train loss=0.17105303704738617
[10/24] Train loss=0.21710817515850067
[15/24] Train loss=0.21283653378486633
[20/24] Train loss=0.19065771996974945
Test set avg_accuracy=83.72% avg_sensitivity=48.48%, avg_specificity=96.14% avg_auc=86.18%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.193404 Test loss=0.427463 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.18586331605911255
[5/24] Train loss=0.16436180472373962
[10/24] Train loss=0.20284609496593475
[15/24] Train loss=0.205791637301445
[20/24] Train loss=0.1876075565814972
Test set avg_accuracy=83.52% avg_sensitivity=44.13%, avg_specificity=97.39% avg_auc=85.07%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.193461 Test loss=0.443590 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.1937425434589386
[5/24] Train loss=0.17265614867210388
[10/24] Train loss=0.21184061467647552
[15/24] Train loss=0.22890739142894745
[20/24] Train loss=0.19934417307376862
Test set avg_accuracy=84.21% avg_sensitivity=59.27%, avg_specificity=92.99% avg_auc=88.42%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.200416 Test loss=0.382058 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.18492503464221954
[5/24] Train loss=0.1730533242225647
[10/24] Train loss=0.204159677028656
[15/24] Train loss=0.22223159670829773
[20/24] Train loss=0.20576928555965424
Test set avg_accuracy=85.83% avg_sensitivity=61.67%, avg_specificity=94.35% avg_auc=88.10%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.194998 Test loss=0.376652 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18499678373336792
[5/24] Train loss=0.18006382882595062
[10/24] Train loss=0.1948675960302353
[15/24] Train loss=0.20790912210941315
[20/24] Train loss=0.18055354058742523
Test set avg_accuracy=86.84% avg_sensitivity=62.27%, avg_specificity=95.49% avg_auc=89.33%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.192336 Test loss=0.347974 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.1855027973651886
[5/24] Train loss=0.16123490035533905
[10/24] Train loss=0.22318218648433685
[15/24] Train loss=0.207071453332901
[20/24] Train loss=0.19101528823375702
Test set avg_accuracy=86.41% avg_sensitivity=76.51%, avg_specificity=89.89% avg_auc=91.27%
Best model saved!! Metric=18.083600794579823!!
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.191251 Test loss=0.329465 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.18586353957653046
[5/24] Train loss=0.1592741161584854
[10/24] Train loss=0.1847575604915619
[15/24] Train loss=0.19997750222682953
[20/24] Train loss=0.1940140724182129
Test set avg_accuracy=84.80% avg_sensitivity=56.87%, avg_specificity=94.65% avg_auc=87.08%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.186615 Test loss=0.389507 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.18644645810127258
[5/24] Train loss=0.16223788261413574
[10/24] Train loss=0.18057960271835327
[15/24] Train loss=0.20147690176963806
[20/24] Train loss=0.18073327839374542
Test set avg_accuracy=86.81% avg_sensitivity=65.37%, avg_specificity=94.37% avg_auc=90.10%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.184207 Test loss=0.333888 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.17847850918769836
[5/24] Train loss=0.16718271374702454
[10/24] Train loss=0.183785542845726
[15/24] Train loss=0.19028419256210327
[20/24] Train loss=0.18272855877876282
Test set avg_accuracy=85.33% avg_sensitivity=56.67%, avg_specificity=95.42% avg_auc=88.47%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.182217 Test loss=0.380647 Current lr=[0.000276307469034998]

[0/24] Train loss=0.19515545666217804
[5/24] Train loss=0.16236472129821777
[10/24] Train loss=0.18969844281673431
[15/24] Train loss=0.19928677380084991
[20/24] Train loss=0.18340909481048584
Test set avg_accuracy=84.77% avg_sensitivity=82.06%, avg_specificity=85.72% avg_auc=90.72%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.181949 Test loss=0.371001 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.1725877970457077
[5/24] Train loss=0.16719980537891388
[10/24] Train loss=0.19164343178272247
[15/24] Train loss=0.20665410161018372
[20/24] Train loss=0.18443039059638977
Test set avg_accuracy=83.53% avg_sensitivity=79.66%, avg_specificity=84.89% avg_auc=89.51%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.181669 Test loss=0.400247 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.17892135679721832
[5/24] Train loss=0.16250494122505188
[10/24] Train loss=0.20821166038513184
[15/24] Train loss=0.20115074515342712
[20/24] Train loss=0.18586213886737823
Test set avg_accuracy=85.52% avg_sensitivity=67.92%, avg_specificity=91.72% avg_auc=90.39%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.185621 Test loss=0.340939 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.18368583917617798
[5/24] Train loss=0.162928968667984
[10/24] Train loss=0.1852138489484787
[15/24] Train loss=0.1841825544834137
[20/24] Train loss=0.16832968592643738
Test set avg_accuracy=85.74% avg_sensitivity=73.41%, avg_specificity=90.09% avg_auc=90.27%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.178159 Test loss=0.349100 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.17414911091327667
[5/24] Train loss=0.15114371478557587
[10/24] Train loss=0.18923744559288025
[15/24] Train loss=0.18175968527793884
[20/24] Train loss=0.18194393813610077
Test set avg_accuracy=86.21% avg_sensitivity=67.52%, avg_specificity=92.80% avg_auc=89.86%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.177514 Test loss=0.353570 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.16650086641311646
[5/24] Train loss=0.16733509302139282
[10/24] Train loss=0.18278205394744873
[15/24] Train loss=0.195126473903656
[20/24] Train loss=0.16594725847244263
Test set avg_accuracy=85.55% avg_sensitivity=58.92%, avg_specificity=94.93% avg_auc=88.34%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.177227 Test loss=0.368334 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.16918551921844482
[5/24] Train loss=0.16278663277626038
[10/24] Train loss=0.17685705423355103
[15/24] Train loss=0.1954878717660904
[20/24] Train loss=0.17855460941791534
Test set avg_accuracy=84.96% avg_sensitivity=58.02%, avg_specificity=94.45% avg_auc=86.58%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.174746 Test loss=0.395812 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.16659104824066162
[5/24] Train loss=0.155026376247406
[10/24] Train loss=0.17817123234272003
[15/24] Train loss=0.1906200498342514
[20/24] Train loss=0.17792123556137085
Test set avg_accuracy=86.03% avg_sensitivity=66.42%, avg_specificity=92.94% avg_auc=88.19%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.174726 Test loss=0.360539 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.17216019332408905
[5/24] Train loss=0.15889482200145721
[10/24] Train loss=0.17513762414455414
[15/24] Train loss=0.20005838572978973
[20/24] Train loss=0.1702444851398468
Test set avg_accuracy=83.49% avg_sensitivity=49.63%, avg_specificity=95.42% avg_auc=83.55%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.173454 Test loss=0.467379 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1653064787387848
[5/24] Train loss=0.15674111247062683
[10/24] Train loss=0.17667439579963684
[15/24] Train loss=0.18766874074935913
[20/24] Train loss=0.1690087467432022
Test set avg_accuracy=85.22% avg_sensitivity=73.01%, avg_specificity=89.52% avg_auc=88.99%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.171513 Test loss=0.365705 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.1740640252828598
[5/24] Train loss=0.15355424582958221
[10/24] Train loss=0.16919317841529846
[15/24] Train loss=0.1897612065076828
[20/24] Train loss=0.1725122630596161
Test set avg_accuracy=85.53% avg_sensitivity=76.96%, avg_specificity=88.55% avg_auc=90.07%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.170673 Test loss=0.363591 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1609921157360077
[5/24] Train loss=0.15269237756729126
[10/24] Train loss=0.17856767773628235
[15/24] Train loss=0.20304527878761292
[20/24] Train loss=0.17206895351409912
Test set avg_accuracy=84.87% avg_sensitivity=68.92%, avg_specificity=90.49% avg_auc=87.87%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.171873 Test loss=0.375682 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.1750282347202301
[5/24] Train loss=0.15660430490970612
[10/24] Train loss=0.18418563902378082
[15/24] Train loss=0.18958401679992676
[20/24] Train loss=0.1782776266336441
Test set avg_accuracy=83.74% avg_sensitivity=49.73%, avg_specificity=95.72% avg_auc=84.29%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.172269 Test loss=0.460717 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.1575251966714859
[5/24] Train loss=0.14680688083171844
[10/24] Train loss=0.18534643948078156
[15/24] Train loss=0.18461929261684418
[20/24] Train loss=0.1727851778268814
Test set avg_accuracy=86.22% avg_sensitivity=75.66%, avg_specificity=89.95% avg_auc=90.88%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.170981 Test loss=0.338248 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.17536139488220215
[5/24] Train loss=0.1540766805410385
[10/24] Train loss=0.17327018082141876
[15/24] Train loss=0.1808224320411682
[20/24] Train loss=0.16398656368255615
Test set avg_accuracy=85.79% avg_sensitivity=70.96%, avg_specificity=91.02% avg_auc=89.52%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.170245 Test loss=0.365034 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.16072700917720795
[5/24] Train loss=0.1498057246208191
[10/24] Train loss=0.1719038486480713
[15/24] Train loss=0.1786828339099884
[20/24] Train loss=0.15865753591060638
Test set avg_accuracy=85.65% avg_sensitivity=59.82%, avg_specificity=94.75% avg_auc=87.76%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.166948 Test loss=0.364340 Current lr=[0.000224838296036774]

[0/24] Train loss=0.15597334504127502
[5/24] Train loss=0.1535574346780777
[10/24] Train loss=0.16870291531085968
[15/24] Train loss=0.18358875811100006
[20/24] Train loss=0.15954147279262543
Test set avg_accuracy=85.82% avg_sensitivity=65.32%, avg_specificity=93.04% avg_auc=89.30%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.163850 Test loss=0.357598 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.16032445430755615
[5/24] Train loss=0.15383018553256989
[10/24] Train loss=0.1626245528459549
[15/24] Train loss=0.17245063185691833
[20/24] Train loss=0.15897153317928314
Test set avg_accuracy=85.68% avg_sensitivity=63.32%, avg_specificity=93.56% avg_auc=88.77%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.161729 Test loss=0.360277 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.15355591475963593
[5/24] Train loss=0.14713770151138306
[10/24] Train loss=0.16633422672748566
[15/24] Train loss=0.17635327577590942
[20/24] Train loss=0.15813319385051727
Test set avg_accuracy=85.49% avg_sensitivity=73.71%, avg_specificity=89.65% avg_auc=89.56%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.159854 Test loss=0.359324 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.15946193039417267
[5/24] Train loss=0.15829862654209137
[10/24] Train loss=0.16479606926441193
[15/24] Train loss=0.1827794462442398
[20/24] Train loss=0.1588434875011444
Test set avg_accuracy=85.56% avg_sensitivity=57.77%, avg_specificity=95.35% avg_auc=89.35%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.160701 Test loss=0.366148 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.153583824634552
[5/24] Train loss=0.14187820255756378
[10/24] Train loss=0.1646145135164261
[15/24] Train loss=0.16512531042099
[20/24] Train loss=0.15872108936309814
Test set avg_accuracy=84.77% avg_sensitivity=66.67%, avg_specificity=91.14% avg_auc=87.07%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.157178 Test loss=0.388010 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.15411044657230377
[5/24] Train loss=0.14449188113212585
[10/24] Train loss=0.16096585988998413
[15/24] Train loss=0.17211338877677917
[20/24] Train loss=0.15802350640296936
Test set avg_accuracy=82.03% avg_sensitivity=38.58%, avg_specificity=97.34% avg_auc=80.57%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.159332 Test loss=0.508862 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1562374234199524
[5/24] Train loss=0.14426551759243011
[10/24] Train loss=0.15525870025157928
[15/24] Train loss=0.17465214431285858
[20/24] Train loss=0.15446075797080994
Test set avg_accuracy=84.39% avg_sensitivity=59.92%, avg_specificity=93.01% avg_auc=84.75%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.159494 Test loss=0.430185 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.15046146512031555
[5/24] Train loss=0.14399684965610504
[10/24] Train loss=0.15782374143600464
[15/24] Train loss=0.17428302764892578
[20/24] Train loss=0.16387128829956055
Test set avg_accuracy=86.04% avg_sensitivity=70.21%, avg_specificity=91.62% avg_auc=88.73%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.160966 Test loss=0.365014 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.15519224107265472
[5/24] Train loss=0.14393602311611176
[10/24] Train loss=0.16373637318611145
[15/24] Train loss=0.17207203805446625
[20/24] Train loss=0.16365846991539001
Test set avg_accuracy=85.86% avg_sensitivity=64.47%, avg_specificity=93.40% avg_auc=88.92%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.157332 Test loss=0.362359 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.1535104513168335
[5/24] Train loss=0.13963541388511658
[10/24] Train loss=0.16927750408649445
[15/24] Train loss=0.16931578516960144
[20/24] Train loss=0.16101014614105225
Test set avg_accuracy=85.31% avg_sensitivity=71.61%, avg_specificity=90.14% avg_auc=89.81%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.157495 Test loss=0.347532 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.150799959897995
[5/24] Train loss=0.1444874256849289
[10/24] Train loss=0.16746403276920319
[15/24] Train loss=0.1757819652557373
[20/24] Train loss=0.16628225147724152
Test set avg_accuracy=86.50% avg_sensitivity=71.61%, avg_specificity=91.74% avg_auc=89.52%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.159696 Test loss=0.349577 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.14575795829296112
[5/24] Train loss=0.14134453237056732
[10/24] Train loss=0.1593015044927597
[15/24] Train loss=0.17083856463432312
[20/24] Train loss=0.16459307074546814
Test set avg_accuracy=85.70% avg_sensitivity=67.62%, avg_specificity=92.08% avg_auc=88.58%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.157562 Test loss=0.359788 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.15464970469474792
[5/24] Train loss=0.1467096507549286
[10/24] Train loss=0.16485868394374847
[15/24] Train loss=0.16523391008377075
[20/24] Train loss=0.1597955971956253
Test set avg_accuracy=85.25% avg_sensitivity=56.17%, avg_specificity=95.49% avg_auc=85.64%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.156902 Test loss=0.403221 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.1460479199886322
[5/24] Train loss=0.13873590528964996
[10/24] Train loss=0.15614208579063416
[15/24] Train loss=0.17120209336280823
[20/24] Train loss=0.14877602458000183
Test set avg_accuracy=84.82% avg_sensitivity=55.57%, avg_specificity=95.12% avg_auc=86.25%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.153006 Test loss=0.397822 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1441589742898941
[5/24] Train loss=0.15098890662193298
[10/24] Train loss=0.16813045740127563
[15/24] Train loss=0.17343349754810333
[20/24] Train loss=0.15570499002933502
Test set avg_accuracy=83.32% avg_sensitivity=43.43%, avg_specificity=97.38% avg_auc=84.34%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.155525 Test loss=0.436329 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15295231342315674
[5/24] Train loss=0.14239731431007385
[10/24] Train loss=0.15843775868415833
[15/24] Train loss=0.16263043880462646
[20/24] Train loss=0.15204888582229614
Test set avg_accuracy=86.21% avg_sensitivity=73.96%, avg_specificity=90.53% avg_auc=90.02%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.154062 Test loss=0.345818 Current lr=[0.000156543481933168]

[0/24] Train loss=0.14704614877700806
[5/24] Train loss=0.1396314650774002
[10/24] Train loss=0.15987804532051086
[15/24] Train loss=0.16140756011009216
[20/24] Train loss=0.15370528399944305
Test set avg_accuracy=86.12% avg_sensitivity=78.31%, avg_specificity=88.87% avg_auc=91.25%
Best model saved!! Metric=18.54967603774051!!
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.152899 Test loss=0.344326 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1496117264032364
[5/24] Train loss=0.13489359617233276
[10/24] Train loss=0.1535148322582245
[15/24] Train loss=0.16958263516426086
[20/24] Train loss=0.15556660294532776
Test set avg_accuracy=85.96% avg_sensitivity=75.16%, avg_specificity=89.77% avg_auc=90.58%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.153452 Test loss=0.351064 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.14523440599441528
[5/24] Train loss=0.14438709616661072
[10/24] Train loss=0.15306822955608368
[15/24] Train loss=0.15988251566886902
[20/24] Train loss=0.15854410827159882
Test set avg_accuracy=86.12% avg_sensitivity=71.06%, avg_specificity=91.42% avg_auc=89.12%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.149568 Test loss=0.355173 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.14343704283237457
[5/24] Train loss=0.13963168859481812
[10/24] Train loss=0.14997749030590057
[15/24] Train loss=0.15860708057880402
[20/24] Train loss=0.14480501413345337
Test set avg_accuracy=85.94% avg_sensitivity=62.92%, avg_specificity=94.05% avg_auc=89.19%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.147862 Test loss=0.357597 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.14369593560695648
[5/24] Train loss=0.1403588354587555
[10/24] Train loss=0.1492636799812317
[15/24] Train loss=0.1597326695919037
[20/24] Train loss=0.1465812474489212
Test set avg_accuracy=87.01% avg_sensitivity=67.67%, avg_specificity=93.82% avg_auc=89.96%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.148012 Test loss=0.346389 Current lr=[0.000134135431043539]

[0/24] Train loss=0.14720401167869568
[5/24] Train loss=0.13446421921253204
[10/24] Train loss=0.1463906466960907
[15/24] Train loss=0.15989509224891663
[20/24] Train loss=0.14784100651741028
Test set avg_accuracy=85.34% avg_sensitivity=60.82%, avg_specificity=93.98% avg_auc=86.78%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.146842 Test loss=0.391405 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.13794724643230438
[5/24] Train loss=0.13121183216571808
[10/24] Train loss=0.14866194128990173
[15/24] Train loss=0.16108541190624237
[20/24] Train loss=0.14644409716129303
Test set avg_accuracy=86.21% avg_sensitivity=67.07%, avg_specificity=92.96% avg_auc=89.06%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.145826 Test loss=0.354677 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1394062638282776
[5/24] Train loss=0.13067153096199036
[10/24] Train loss=0.15983429551124573
[15/24] Train loss=0.1627555936574936
[20/24] Train loss=0.1457306295633316
Test set avg_accuracy=86.07% avg_sensitivity=76.36%, avg_specificity=89.49% avg_auc=90.12%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.147602 Test loss=0.356844 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.14260874688625336
[5/24] Train loss=0.1337888240814209
[10/24] Train loss=0.15724776685237885
[15/24] Train loss=0.15844254195690155
[20/24] Train loss=0.14807119965553284
Test set avg_accuracy=86.45% avg_sensitivity=69.92%, avg_specificity=92.27% avg_auc=88.99%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.147412 Test loss=0.359077 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14319545030593872
[5/24] Train loss=0.1355462521314621
[10/24] Train loss=0.15286870300769806
[15/24] Train loss=0.1587994247674942
[20/24] Train loss=0.1450570821762085
Test set avg_accuracy=85.04% avg_sensitivity=75.16%, avg_specificity=88.52% avg_auc=90.22%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.144986 Test loss=0.362619 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1440826803445816
[5/24] Train loss=0.13132628798484802
[10/24] Train loss=0.14440925419330597
[15/24] Train loss=0.16095110774040222
[20/24] Train loss=0.1400350034236908
Test set avg_accuracy=85.52% avg_sensitivity=73.21%, avg_specificity=89.86% avg_auc=89.76%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.145109 Test loss=0.355005 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.13636291027069092
[5/24] Train loss=0.1274443417787552
[10/24] Train loss=0.1506403386592865
[15/24] Train loss=0.15431712567806244
[20/24] Train loss=0.1400691568851471
Test set avg_accuracy=86.00% avg_sensitivity=70.86%, avg_specificity=91.34% avg_auc=89.21%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.143003 Test loss=0.355444 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.13273534178733826
[5/24] Train loss=0.13068541884422302
[10/24] Train loss=0.14260241389274597
[15/24] Train loss=0.1520722508430481
[20/24] Train loss=0.1451091319322586
Test set avg_accuracy=84.71% avg_sensitivity=80.06%, avg_specificity=86.35% avg_auc=90.50%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.141331 Test loss=0.370210 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.13512369990348816
[5/24] Train loss=0.13559047877788544
[10/24] Train loss=0.1432669311761856
[15/24] Train loss=0.1583416759967804
[20/24] Train loss=0.1429067701101303
Test set avg_accuracy=86.82% avg_sensitivity=69.62%, avg_specificity=92.89% avg_auc=89.25%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.140291 Test loss=0.347320 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.13391774892807007
[5/24] Train loss=0.1263795793056488
[10/24] Train loss=0.14404745399951935
[15/24] Train loss=0.1529923379421234
[20/24] Train loss=0.13959737122058868
Test set avg_accuracy=86.65% avg_sensitivity=74.61%, avg_specificity=90.90% avg_auc=90.44%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.139947 Test loss=0.338154 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.13486088812351227
[5/24] Train loss=0.1311074048280716
[10/24] Train loss=0.14261452853679657
[15/24] Train loss=0.15148021280765533
[20/24] Train loss=0.14273357391357422
Test set avg_accuracy=87.03% avg_sensitivity=72.46%, avg_specificity=92.16% avg_auc=90.90%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.139962 Test loss=0.327123 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.13005590438842773
[5/24] Train loss=0.12526211142539978
[10/24] Train loss=0.14007949829101562
[15/24] Train loss=0.15075452625751495
[20/24] Train loss=0.1328074336051941
Test set avg_accuracy=86.50% avg_sensitivity=73.61%, avg_specificity=91.04% avg_auc=90.56%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.136636 Test loss=0.338654 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13268792629241943
[5/24] Train loss=0.12386143207550049
[10/24] Train loss=0.1412001997232437
[15/24] Train loss=0.1493547111749649
[20/24] Train loss=0.14294087886810303
Test set avg_accuracy=86.41% avg_sensitivity=65.07%, avg_specificity=93.92% avg_auc=88.39%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.137585 Test loss=0.360130 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13298794627189636
[5/24] Train loss=0.12622769176959991
[10/24] Train loss=0.13685856759548187
[15/24] Train loss=0.14749270677566528
[20/24] Train loss=0.1374601423740387
Test set avg_accuracy=86.34% avg_sensitivity=75.06%, avg_specificity=90.32% avg_auc=90.97%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.136415 Test loss=0.336027 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1330212950706482
[5/24] Train loss=0.12318144738674164
[10/24] Train loss=0.13724736869335175
[15/24] Train loss=0.1480584591627121
[20/24] Train loss=0.13456891477108002
Test set avg_accuracy=86.55% avg_sensitivity=71.36%, avg_specificity=91.90% avg_auc=90.64%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.135145 Test loss=0.338181 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13225997984409332
[5/24] Train loss=0.12432961165904999
[10/24] Train loss=0.138168066740036
[15/24] Train loss=0.14318028092384338
[20/24] Train loss=0.13688123226165771
Test set avg_accuracy=86.48% avg_sensitivity=75.26%, avg_specificity=90.44% avg_auc=90.86%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.134758 Test loss=0.336296 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.12967556715011597
[5/24] Train loss=0.11919204890727997
[10/24] Train loss=0.13974247872829437
[15/24] Train loss=0.14797571301460266
[20/24] Train loss=0.1336299329996109
Test set avg_accuracy=86.38% avg_sensitivity=75.31%, avg_specificity=90.28% avg_auc=90.62%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.133424 Test loss=0.347032 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13291320204734802
[5/24] Train loss=0.12076953053474426
[10/24] Train loss=0.14135591685771942
[15/24] Train loss=0.14971788227558136
[20/24] Train loss=0.13173705339431763
Test set avg_accuracy=86.18% avg_sensitivity=73.66%, avg_specificity=90.60% avg_auc=90.52%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.134164 Test loss=0.343494 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1298634558916092
[5/24] Train loss=0.12147239595651627
[10/24] Train loss=0.13458102941513062
[15/24] Train loss=0.1491573601961136
[20/24] Train loss=0.1329508125782013
Test set avg_accuracy=86.61% avg_sensitivity=70.76%, avg_specificity=92.20% avg_auc=89.82%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.131936 Test loss=0.342001 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.12451675534248352
[5/24] Train loss=0.11644692718982697
[10/24] Train loss=0.12982571125030518
[15/24] Train loss=0.1451554000377655
[20/24] Train loss=0.13376280665397644
Test set avg_accuracy=86.05% avg_sensitivity=70.16%, avg_specificity=91.65% avg_auc=89.36%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.131128 Test loss=0.354000 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.12458999454975128
[5/24] Train loss=0.12135005742311478
[10/24] Train loss=0.13447017967700958
[15/24] Train loss=0.14034786820411682
[20/24] Train loss=0.13157662749290466
Test set avg_accuracy=86.58% avg_sensitivity=69.62%, avg_specificity=92.55% avg_auc=88.17%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.130379 Test loss=0.356473 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1278647929430008
[5/24] Train loss=0.12061566114425659
[10/24] Train loss=0.1322586089372635
[15/24] Train loss=0.14186440408229828
[20/24] Train loss=0.13355259597301483
Test set avg_accuracy=86.26% avg_sensitivity=69.37%, avg_specificity=92.22% avg_auc=89.31%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.130169 Test loss=0.351239 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12451903522014618
[5/24] Train loss=0.11933055520057678
[10/24] Train loss=0.13190162181854248
[15/24] Train loss=0.1426938772201538
[20/24] Train loss=0.12798228859901428
Test set avg_accuracy=86.33% avg_sensitivity=72.11%, avg_specificity=91.34% avg_auc=89.63%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.129203 Test loss=0.347933 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12528632581233978
[5/24] Train loss=0.11700683832168579
[10/24] Train loss=0.13109543919563293
[15/24] Train loss=0.14118051528930664
[20/24] Train loss=0.13100777566432953
Test set avg_accuracy=86.55% avg_sensitivity=68.52%, avg_specificity=92.90% avg_auc=89.24%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.129338 Test loss=0.349669 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12194167077541351
[5/24] Train loss=0.11526840180158615
[10/24] Train loss=0.12976984679698944
[15/24] Train loss=0.13995978236198425
[20/24] Train loss=0.12995412945747375
Test set avg_accuracy=86.56% avg_sensitivity=74.46%, avg_specificity=90.83% avg_auc=90.65%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.128250 Test loss=0.339425 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12356124073266983
[5/24] Train loss=0.11674872040748596
[10/24] Train loss=0.13105575740337372
[15/24] Train loss=0.13713325560092926
[20/24] Train loss=0.1296161264181137
Test set avg_accuracy=86.18% avg_sensitivity=75.76%, avg_specificity=89.86% avg_auc=90.38%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.127439 Test loss=0.350801 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12279824167490005
[5/24] Train loss=0.1168765276670456
[10/24] Train loss=0.1287272423505783
[15/24] Train loss=0.13907013833522797
[20/24] Train loss=0.1282709687948227
Test set avg_accuracy=86.15% avg_sensitivity=77.21%, avg_specificity=89.29% avg_auc=90.85%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.126800 Test loss=0.343349 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12337838858366013
[5/24] Train loss=0.11795885115861893
[10/24] Train loss=0.12780636548995972
[15/24] Train loss=0.13881148397922516
[20/24] Train loss=0.12856212258338928
Test set avg_accuracy=86.34% avg_sensitivity=75.76%, avg_specificity=90.07% avg_auc=90.51%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.126874 Test loss=0.348197 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.11860795319080353
[5/24] Train loss=0.1125016063451767
[10/24] Train loss=0.1298198401927948
[15/24] Train loss=0.13227978348731995
[20/24] Train loss=0.1273767054080963
Test set avg_accuracy=86.12% avg_sensitivity=73.96%, avg_specificity=90.40% avg_auc=90.40%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.125218 Test loss=0.348092 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12110629677772522
[5/24] Train loss=0.11166207492351532
[10/24] Train loss=0.12802329659461975
[15/24] Train loss=0.1329352706670761
[20/24] Train loss=0.1267242282629013
Test set avg_accuracy=86.22% avg_sensitivity=74.16%, avg_specificity=90.47% avg_auc=90.20%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.125345 Test loss=0.348077 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.11930162459611893
[5/24] Train loss=0.10862427204847336
[10/24] Train loss=0.1306459605693817
[15/24] Train loss=0.13594746589660645
[20/24] Train loss=0.1259012073278427
Test set avg_accuracy=86.20% avg_sensitivity=74.06%, avg_specificity=90.47% avg_auc=90.72%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.124972 Test loss=0.343084 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1206287145614624
[5/24] Train loss=0.11001186817884445
[10/24] Train loss=0.12469857931137085
[15/24] Train loss=0.13517794013023376
[20/24] Train loss=0.12580609321594238
Test set avg_accuracy=86.54% avg_sensitivity=74.41%, avg_specificity=90.81% avg_auc=90.63%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.124157 Test loss=0.341781 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.11880797147750854
[5/24] Train loss=0.10892687737941742
[10/24] Train loss=0.12687532603740692
[15/24] Train loss=0.13655513525009155
[20/24] Train loss=0.1266251653432846
Test set avg_accuracy=86.55% avg_sensitivity=73.06%, avg_specificity=91.30% avg_auc=90.27%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.124163 Test loss=0.342378 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.11969821155071259
[5/24] Train loss=0.1085025817155838
[10/24] Train loss=0.12602177262306213
[15/24] Train loss=0.13336996734142303
[20/24] Train loss=0.12534253299236298
Test set avg_accuracy=86.80% avg_sensitivity=75.81%, avg_specificity=90.67% avg_auc=90.70%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.122394 Test loss=0.339883 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.116163469851017
[5/24] Train loss=0.10807979106903076
[10/24] Train loss=0.12694546580314636
[15/24] Train loss=0.13452206552028656
[20/24] Train loss=0.12331680208444595
Test set avg_accuracy=86.50% avg_sensitivity=74.16%, avg_specificity=90.84% avg_auc=90.52%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.121810 Test loss=0.339833 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.11956685781478882
[5/24] Train loss=0.1091238409280777
[10/24] Train loss=0.12511248886585236
[15/24] Train loss=0.1324092149734497
[20/24] Train loss=0.12204523384571075
Test set avg_accuracy=86.63% avg_sensitivity=72.56%, avg_specificity=91.58% avg_auc=90.54%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.121497 Test loss=0.339494 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.11645761132240295
[5/24] Train loss=0.10704829543828964
[10/24] Train loss=0.12693117558956146
[15/24] Train loss=0.13236026465892792
[20/24] Train loss=0.1245722845196724
Test set avg_accuracy=86.54% avg_sensitivity=73.81%, avg_specificity=91.02% avg_auc=90.68%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.121734 Test loss=0.339798 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.11588104814291
[5/24] Train loss=0.10940172523260117
[10/24] Train loss=0.12208263576030731
[15/24] Train loss=0.13016043603420258
[20/24] Train loss=0.1277555525302887
Test set avg_accuracy=86.59% avg_sensitivity=74.76%, avg_specificity=90.76% avg_auc=90.80%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.120996 Test loss=0.338604 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1163174957036972
[5/24] Train loss=0.10951296985149384
[10/24] Train loss=0.12395026534795761
[15/24] Train loss=0.1313861608505249
[20/24] Train loss=0.12320847064256668
Test set avg_accuracy=86.84% avg_sensitivity=73.91%, avg_specificity=91.39% avg_auc=90.66%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.120860 Test loss=0.338523 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11513561755418777
[5/24] Train loss=0.11081807315349579
[10/24] Train loss=0.12387502938508987
[15/24] Train loss=0.12973928451538086
[20/24] Train loss=0.12185864895582199
Test set avg_accuracy=86.76% avg_sensitivity=74.11%, avg_specificity=91.21% avg_auc=90.61%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.120572 Test loss=0.340458 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.11459661275148392
[5/24] Train loss=0.11030864715576172
[10/24] Train loss=0.12488415837287903
[15/24] Train loss=0.13111627101898193
[20/24] Train loss=0.12401393055915833
Test set avg_accuracy=86.72% avg_sensitivity=73.06%, avg_specificity=91.53% avg_auc=90.49%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.120475 Test loss=0.340926 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11456156522035599
[5/24] Train loss=0.10498308390378952
[10/24] Train loss=0.12234044820070267
[15/24] Train loss=0.13060972094535828
[20/24] Train loss=0.12263264507055283
Test set avg_accuracy=86.63% avg_sensitivity=73.96%, avg_specificity=91.09% avg_auc=90.57%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.120551 Test loss=0.342029 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.11546521633863449
[5/24] Train loss=0.1070425733923912
[10/24] Train loss=0.12416498363018036
[15/24] Train loss=0.13030003011226654
[20/24] Train loss=0.12386611849069595
Test set avg_accuracy=86.59% avg_sensitivity=73.66%, avg_specificity=91.14% avg_auc=90.57%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.120955 Test loss=0.341751 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11411213874816895
[5/24] Train loss=0.10894758254289627
[10/24] Train loss=0.123581163585186
[15/24] Train loss=0.12785837054252625
[20/24] Train loss=0.12284522503614426
Test set avg_accuracy=86.72% avg_sensitivity=73.31%, avg_specificity=91.44% avg_auc=90.42%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.120076 Test loss=0.342146 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11663035303354263
[5/24] Train loss=0.10679320245981216
[10/24] Train loss=0.11988543719053268
[15/24] Train loss=0.13133561611175537
[20/24] Train loss=0.12451506406068802
Test set avg_accuracy=86.65% avg_sensitivity=73.61%, avg_specificity=91.25% avg_auc=90.51%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.119976 Test loss=0.341335 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11548356711864471
[5/24] Train loss=0.10978659242391586
[10/24] Train loss=0.12330092489719391
[15/24] Train loss=0.12703293561935425
[20/24] Train loss=0.12465798109769821
Test set avg_accuracy=86.63% avg_sensitivity=73.81%, avg_specificity=91.14% avg_auc=90.58%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.119555 Test loss=0.341253 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11625363677740097
[5/24] Train loss=0.10700181871652603
[10/24] Train loss=0.12094294279813766
[15/24] Train loss=0.12727436423301697
[20/24] Train loss=0.1223456859588623
Test set avg_accuracy=86.60% avg_sensitivity=73.91%, avg_specificity=91.07% avg_auc=90.59%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.119855 Test loss=0.341134 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11525468528270721
[5/24] Train loss=0.10806059837341309
[10/24] Train loss=0.1215609535574913
[15/24] Train loss=0.1299218237400055
[20/24] Train loss=0.12088221311569214
Test set avg_accuracy=86.59% avg_sensitivity=73.66%, avg_specificity=91.14% avg_auc=90.58%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.120179 Test loss=0.341157 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11600882560014725
[5/24] Train loss=0.10779128968715668
[10/24] Train loss=0.1224985420703888
[15/24] Train loss=0.13193468749523163
[20/24] Train loss=0.1213291585445404
Test set avg_accuracy=86.56% avg_sensitivity=73.71%, avg_specificity=91.09% avg_auc=90.59%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.120274 Test loss=0.341035 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=86.12% sen=78.31%, spe=88.87%, auc=91.25%!
Fold[4] Avg_overlap=0.70%(±0.23068715324559513)
[0/24] Train loss=0.7362322807312012
[5/24] Train loss=0.7274458408355713
[10/24] Train loss=0.7188259959220886
[15/24] Train loss=0.7084504961967468
[20/24] Train loss=0.701944887638092
Test set avg_accuracy=57.58% avg_sensitivity=51.10%, avg_specificity=59.79% avg_auc=58.68%
Best model saved!! Metric=-98.85550426091598!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.717204 Test loss=0.665233 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7048636674880981
[5/24] Train loss=0.6895214319229126
[10/24] Train loss=0.692995548248291
[15/24] Train loss=0.6766286492347717
[20/24] Train loss=0.6716328859329224
Test set avg_accuracy=68.27% avg_sensitivity=62.88%, avg_specificity=70.11% avg_auc=73.39%
Best model saved!! Metric=-51.35382466677972!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.686264 Test loss=0.601734 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6655105948448181
[5/24] Train loss=0.6577314138412476
[10/24] Train loss=0.6635197401046753
[15/24] Train loss=0.6496652960777283
[20/24] Train loss=0.6424995064735413
Test set avg_accuracy=71.39% avg_sensitivity=71.17%, avg_specificity=71.47% avg_auc=78.51%
Best model saved!! Metric=-33.45549907965193!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.658366 Test loss=0.569050 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6373612880706787
[5/24] Train loss=0.6346247792243958
[10/24] Train loss=0.639324963092804
[15/24] Train loss=0.615696370601654
[20/24] Train loss=0.6108992695808411
Test set avg_accuracy=73.95% avg_sensitivity=75.99%, avg_specificity=73.25% avg_auc=81.50%
Best model saved!! Metric=-21.323458749203482!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.630283 Test loss=0.544746 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6142138242721558
[5/24] Train loss=0.6056435108184814
[10/24] Train loss=0.6103864908218384
[15/24] Train loss=0.5869977474212646
[20/24] Train loss=0.5845474600791931
Test set avg_accuracy=75.43% avg_sensitivity=78.44%, avg_specificity=74.40% avg_auc=83.41%
Best model saved!! Metric=-14.318316381328216!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.603839 Test loss=0.522636 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5831847190856934
[5/24] Train loss=0.5729014277458191
[10/24] Train loss=0.5927984118461609
[15/24] Train loss=0.5574247241020203
[20/24] Train loss=0.5605391263961792
Test set avg_accuracy=77.33% avg_sensitivity=78.65%, avg_specificity=76.88% avg_auc=84.64%
Best model saved!! Metric=-8.49907514597784!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.576881 Test loss=0.497051 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5584152340888977
[5/24] Train loss=0.5563048720359802
[10/24] Train loss=0.5605872869491577
[15/24] Train loss=0.5268502831459045
[20/24] Train loss=0.5343897938728333
Test set avg_accuracy=78.84% avg_sensitivity=78.60%, avg_specificity=78.92% avg_auc=85.75%
Best model saved!! Metric=-3.8827599637234016!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.552722 Test loss=0.476111 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5345429182052612
[5/24] Train loss=0.5245473980903625
[10/24] Train loss=0.5335050225257874
[15/24] Train loss=0.5125777125358582
[20/24] Train loss=0.5179345607757568
Test set avg_accuracy=79.92% avg_sensitivity=78.75%, avg_specificity=80.32% avg_auc=87.08%
Best model saved!! Metric=0.07698454077001315!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.528642 Test loss=0.455841 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5066683888435364
[5/24] Train loss=0.5028896331787109
[10/24] Train loss=0.5150253176689148
[15/24] Train loss=0.48261523246765137
[20/24] Train loss=0.4856089651584625
Test set avg_accuracy=81.95% avg_sensitivity=76.29%, avg_specificity=83.88% avg_auc=87.98%
Best model saved!! Metric=4.106744844591304!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.503684 Test loss=0.430591 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4846837520599365
[5/24] Train loss=0.4826734662055969
[10/24] Train loss=0.4900311529636383
[15/24] Train loss=0.4590182602405548
[20/24] Train loss=0.46046900749206543
Test set avg_accuracy=83.05% avg_sensitivity=76.29%, avg_specificity=85.35% avg_auc=88.99%
Best model saved!! Metric=7.6764687775009435!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.480217 Test loss=0.411004 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4642443060874939
[5/24] Train loss=0.4590986669063568
[10/24] Train loss=0.46787434816360474
[15/24] Train loss=0.43722638487815857
[20/24] Train loss=0.4338971674442291
Test set avg_accuracy=84.32% avg_sensitivity=75.63%, avg_specificity=87.29% avg_auc=89.54%
Best model saved!! Metric=10.78311029855972!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.458388 Test loss=0.393990 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4399740397930145
[5/24] Train loss=0.4335796535015106
[10/24] Train loss=0.4462103247642517
[15/24] Train loss=0.4203202724456787
[20/24] Train loss=0.4164893925189972
Test set avg_accuracy=85.69% avg_sensitivity=72.50%, avg_specificity=90.19% avg_auc=90.06%
Best model saved!! Metric=12.437333874473609!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.436848 Test loss=0.373642 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.42399585247039795
[5/24] Train loss=0.422163724899292
[10/24] Train loss=0.4267513155937195
[15/24] Train loss=0.39995673298835754
[20/24] Train loss=0.39490002393722534
Test set avg_accuracy=86.43% avg_sensitivity=71.43%, avg_specificity=91.55% avg_auc=90.48%
Best model saved!! Metric=13.88508411386593!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.416704 Test loss=0.358061 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.40079939365386963
[5/24] Train loss=0.3987846374511719
[10/24] Train loss=0.4068309962749481
[15/24] Train loss=0.38305044174194336
[20/24] Train loss=0.3702983856201172
Test set avg_accuracy=85.99% avg_sensitivity=77.01%, avg_specificity=89.05% avg_auc=91.14%
Best model saved!! Metric=17.189812822719418!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.396648 Test loss=0.356743 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3839337229728699
[5/24] Train loss=0.3889246881008148
[10/24] Train loss=0.3882370889186859
[15/24] Train loss=0.3637668788433075
[20/24] Train loss=0.357483446598053
Test set avg_accuracy=86.58% avg_sensitivity=76.40%, avg_specificity=90.05% avg_auc=91.42%
Best model saved!! Metric=18.433422307213434!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.381183 Test loss=0.344921 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.36812353134155273
[5/24] Train loss=0.38016942143440247
[10/24] Train loss=0.3756360113620758
[15/24] Train loss=0.35730400681495667
[20/24] Train loss=0.3439237177371979
Test set avg_accuracy=85.25% avg_sensitivity=81.11%, avg_specificity=86.66% avg_auc=91.68%
Best model saved!! Metric=18.691834466335493!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.368121 Test loss=0.358801 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.35744720697402954
[5/24] Train loss=0.36464497447013855
[10/24] Train loss=0.3625314235687256
[15/24] Train loss=0.3370175361633301
[20/24] Train loss=0.3291250467300415
Test set avg_accuracy=86.97% avg_sensitivity=73.73%, avg_specificity=91.48% avg_auc=91.73%
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.355548 Test loss=0.326817 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.34488993883132935
[5/24] Train loss=0.35924646258354187
[10/24] Train loss=0.35816705226898193
[15/24] Train loss=0.3235727548599243
[20/24] Train loss=0.32249191403388977
Test set avg_accuracy=84.93% avg_sensitivity=81.52%, avg_specificity=86.10% avg_auc=91.66%
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.345275 Test loss=0.356992 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.34101882576942444
[5/24] Train loss=0.35633254051208496
[10/24] Train loss=0.3558213710784912
[15/24] Train loss=0.31642964482307434
[20/24] Train loss=0.31556740403175354
Test set avg_accuracy=85.86% avg_sensitivity=79.57%, avg_specificity=88.00% avg_auc=92.05%
Best model saved!! Metric=19.48547931932319!!
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.337703 Test loss=0.338641 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3344176113605499
[5/24] Train loss=0.3460497260093689
[10/24] Train loss=0.33985623717308044
[15/24] Train loss=0.3077715039253235
[20/24] Train loss=0.3082118332386017
Test set avg_accuracy=86.52% avg_sensitivity=78.96%, avg_specificity=89.10% avg_auc=92.14%
Best model saved!! Metric=20.723296576994542!!
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.328120 Test loss=0.327639 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3253748118877411
[5/24] Train loss=0.3409862518310547
[10/24] Train loss=0.3380385935306549
[15/24] Train loss=0.29730531573295593
[20/24] Train loss=0.30704715847969055
Test set avg_accuracy=86.99% avg_sensitivity=74.35%, avg_specificity=91.30% avg_auc=91.93%
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.321519 Test loss=0.318590 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.32555660605430603
[5/24] Train loss=0.3333780765533447
[10/24] Train loss=0.33261919021606445
[15/24] Train loss=0.2903881371021271
[20/24] Train loss=0.2939264476299286
Test set avg_accuracy=87.36% avg_sensitivity=73.99%, avg_specificity=91.92% avg_auc=92.41%
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.313812 Test loss=0.309743 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3127378523349762
[5/24] Train loss=0.3354553282260895
[10/24] Train loss=0.3212426006793976
[15/24] Train loss=0.29168078303337097
[20/24] Train loss=0.28444457054138184
Test set avg_accuracy=87.51% avg_sensitivity=68.31%, avg_specificity=94.06% avg_auc=92.50%
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.308200 Test loss=0.303923 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.307116836309433
[5/24] Train loss=0.3300934433937073
[10/24] Train loss=0.3258555233478546
[15/24] Train loss=0.28374138474464417
[20/24] Train loss=0.2783040404319763
Test set avg_accuracy=87.54% avg_sensitivity=65.75%, avg_specificity=94.97% avg_auc=92.48%
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.302777 Test loss=0.301098 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2992776334285736
[5/24] Train loss=0.31871911883354187
[10/24] Train loss=0.31644219160079956
[15/24] Train loss=0.27890536189079285
[20/24] Train loss=0.26725858449935913
Test set avg_accuracy=86.97% avg_sensitivity=60.98%, avg_specificity=95.83% avg_auc=91.99%
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.295832 Test loss=0.309039 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.29956334829330444
[5/24] Train loss=0.3110325038433075
[10/24] Train loss=0.3060768246650696
[15/24] Train loss=0.2674943208694458
[20/24] Train loss=0.264911413192749
Test set avg_accuracy=87.53% avg_sensitivity=71.12%, avg_specificity=93.12% avg_auc=92.31%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.287167 Test loss=0.303608 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.28050899505615234
[5/24] Train loss=0.2984512448310852
[10/24] Train loss=0.30308547616004944
[15/24] Train loss=0.25522005558013916
[20/24] Train loss=0.2559400200843811
Test set avg_accuracy=85.27% avg_sensitivity=50.79%, avg_specificity=97.03% avg_auc=89.86%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.280218 Test loss=0.350960 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2860800623893738
[5/24] Train loss=0.29080793261528015
[10/24] Train loss=0.3002757430076599
[15/24] Train loss=0.2552829384803772
[20/24] Train loss=0.256040096282959
Test set avg_accuracy=83.26% avg_sensitivity=40.35%, avg_specificity=97.89% avg_auc=89.27%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.275968 Test loss=0.392780 Current lr=[0.000210185142098938]

[0/24] Train loss=0.26928648352622986
[5/24] Train loss=0.2818683683872223
[10/24] Train loss=0.30236467719078064
[15/24] Train loss=0.24033688008785248
[20/24] Train loss=0.2475593090057373
Test set avg_accuracy=81.89% avg_sensitivity=30.77%, avg_specificity=99.32% avg_auc=86.75%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.270107 Test loss=0.458927 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2653696537017822
[5/24] Train loss=0.2752644717693329
[10/24] Train loss=0.29627877473831177
[15/24] Train loss=0.23877978324890137
[20/24] Train loss=0.24495342373847961
Test set avg_accuracy=86.41% avg_sensitivity=58.63%, avg_specificity=95.88% avg_auc=90.91%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.266785 Test loss=0.327945 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2605988681316376
[5/24] Train loss=0.2603638172149658
[10/24] Train loss=0.295139878988266
[15/24] Train loss=0.23839052021503448
[20/24] Train loss=0.2452547550201416
Test set avg_accuracy=86.12% avg_sensitivity=77.21%, avg_specificity=89.16% avg_auc=92.07%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.261548 Test loss=0.316746 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2506023347377777
[5/24] Train loss=0.2612450122833252
[10/24] Train loss=0.28232449293136597
[15/24] Train loss=0.23031699657440186
[20/24] Train loss=0.2475433349609375
Test set avg_accuracy=82.45% avg_sensitivity=35.18%, avg_specificity=98.57% avg_auc=86.21%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.258983 Test loss=0.465905 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.25600144267082214
[5/24] Train loss=0.2514954209327698
[10/24] Train loss=0.26409634947776794
[15/24] Train loss=0.22356924414634705
[20/24] Train loss=0.23418490588665009
Test set avg_accuracy=84.45% avg_sensitivity=46.49%, avg_specificity=97.40% avg_auc=88.43%
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.250996 Test loss=0.381644 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2473137229681015
[5/24] Train loss=0.23417244851589203
[10/24] Train loss=0.2689536511898041
[15/24] Train loss=0.22247754037380219
[20/24] Train loss=0.22975648939609528
Test set avg_accuracy=85.43% avg_sensitivity=62.57%, avg_specificity=93.23% avg_auc=88.08%
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.249035 Test loss=0.359610 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.25135013461112976
[5/24] Train loss=0.24595464766025543
[10/24] Train loss=0.27200236916542053
[15/24] Train loss=0.21420003473758698
[20/24] Train loss=0.23938368260860443
Test set avg_accuracy=85.86% avg_sensitivity=52.18%, avg_specificity=97.35% avg_auc=87.97%
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.245477 Test loss=0.380279 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2498985081911087
[5/24] Train loss=0.24323363602161407
[10/24] Train loss=0.2766968607902527
[15/24] Train loss=0.21621540188789368
[20/24] Train loss=0.23164714872837067
Test set avg_accuracy=81.89% avg_sensitivity=36.97%, avg_specificity=97.21% avg_auc=87.06%
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.242364 Test loss=0.404535 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2571635842323303
[5/24] Train loss=0.2372627556324005
[10/24] Train loss=0.25811702013015747
[15/24] Train loss=0.23050716519355774
[20/24] Train loss=0.22145876288414001
Test set avg_accuracy=78.59% avg_sensitivity=79.11%, avg_specificity=78.42% avg_auc=87.27%
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.242294 Test loss=0.449978 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2516869306564331
[5/24] Train loss=0.23609919846057892
[10/24] Train loss=0.2824038565158844
[15/24] Train loss=0.22419968247413635
[20/24] Train loss=0.22224551439285278
Test set avg_accuracy=85.18% avg_sensitivity=52.79%, avg_specificity=96.23% avg_auc=90.90%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.246129 Test loss=0.334339 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.23676753044128418
[5/24] Train loss=0.23139643669128418
[10/24] Train loss=0.28040504455566406
[15/24] Train loss=0.2298944592475891
[20/24] Train loss=0.22398070991039276
Test set avg_accuracy=85.07% avg_sensitivity=58.58%, avg_specificity=94.10% avg_auc=89.97%
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.244299 Test loss=0.340514 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2354154735803604
[5/24] Train loss=0.2307533323764801
[10/24] Train loss=0.2543562650680542
[15/24] Train loss=0.21134911477565765
[20/24] Train loss=0.22401656210422516
Test set avg_accuracy=85.62% avg_sensitivity=53.66%, avg_specificity=96.53% avg_auc=91.23%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.237411 Test loss=0.326364 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.24397310614585876
[5/24] Train loss=0.20767968893051147
[10/24] Train loss=0.24380455911159515
[15/24] Train loss=0.21456703543663025
[20/24] Train loss=0.21586094796657562
Test set avg_accuracy=84.41% avg_sensitivity=43.11%, avg_specificity=98.50% avg_auc=88.42%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.227399 Test loss=0.403617 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.22615349292755127
[5/24] Train loss=0.21931664645671844
[10/24] Train loss=0.2602837085723877
[15/24] Train loss=0.1991165727376938
[20/24] Train loss=0.2085772603750229
Test set avg_accuracy=81.78% avg_sensitivity=31.85%, avg_specificity=98.81% avg_auc=83.66%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.226108 Test loss=0.495004 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.23357383906841278
[5/24] Train loss=0.21096250414848328
[10/24] Train loss=0.24347251653671265
[15/24] Train loss=0.2083941549062729
[20/24] Train loss=0.2121467888355255
Test set avg_accuracy=79.30% avg_sensitivity=19.97%, avg_specificity=99.53% avg_auc=78.51%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.222980 Test loss=0.626391 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2423202395439148
[5/24] Train loss=0.20711003243923187
[10/24] Train loss=0.23479841649532318
[15/24] Train loss=0.20256473124027252
[20/24] Train loss=0.20990237593650818
Test set avg_accuracy=84.24% avg_sensitivity=43.52%, avg_specificity=98.13% avg_auc=86.36%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.222729 Test loss=0.409558 Current lr=[0.00029967723776099]

[0/24] Train loss=0.22283048927783966
[5/24] Train loss=0.1903039515018463
[10/24] Train loss=0.25112786889076233
[15/24] Train loss=0.19685517251491547
[20/24] Train loss=0.2241266369819641
Test set avg_accuracy=83.98% avg_sensitivity=42.91%, avg_specificity=97.99% avg_auc=87.48%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.221594 Test loss=0.396145 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.22961045801639557
[5/24] Train loss=0.19079171121120453
[10/24] Train loss=0.22782783210277557
[15/24] Train loss=0.19821493327617645
[20/24] Train loss=0.2125333547592163
Test set avg_accuracy=83.40% avg_sensitivity=38.81%, avg_specificity=98.60% avg_auc=88.20%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.215801 Test loss=0.404790 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.22499199211597443
[5/24] Train loss=0.2175004929304123
[10/24] Train loss=0.2417813390493393
[15/24] Train loss=0.20122691988945007
[20/24] Train loss=0.21278969943523407
Test set avg_accuracy=79.61% avg_sensitivity=21.30%, avg_specificity=99.49% avg_auc=82.40%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.218517 Test loss=0.551671 Current lr=[0.000299720220882401]

[0/24] Train loss=0.22189201414585114
[5/24] Train loss=0.18427670001983643
[10/24] Train loss=0.2299567312002182
[15/24] Train loss=0.20178689062595367
[20/24] Train loss=0.19739775359630585
Test set avg_accuracy=85.77% avg_sensitivity=52.74%, avg_specificity=97.03% avg_auc=88.71%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.214258 Test loss=0.363610 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.20763404667377472
[5/24] Train loss=0.19229060411453247
[10/24] Train loss=0.2428242564201355
[15/24] Train loss=0.19543257355690002
[20/24] Train loss=0.21027347445487976
Test set avg_accuracy=81.81% avg_sensitivity=31.23%, avg_specificity=99.06% avg_auc=88.94%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.215861 Test loss=0.425049 Current lr=[0.000298904600941902]

[0/24] Train loss=0.21812817454338074
[5/24] Train loss=0.18365396559238434
[10/24] Train loss=0.2437886893749237
[15/24] Train loss=0.1993331015110016
[20/24] Train loss=0.19116531312465668
Test set avg_accuracy=81.90% avg_sensitivity=32.26%, avg_specificity=98.83% avg_auc=85.60%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.214604 Test loss=0.482513 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.21041032671928406
[5/24] Train loss=0.18700550496578217
[10/24] Train loss=0.2277073711156845
[15/24] Train loss=0.20738647878170013
[20/24] Train loss=0.21148282289505005
Test set avg_accuracy=83.83% avg_sensitivity=73.43%, avg_specificity=87.38% avg_auc=89.65%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.213118 Test loss=0.362070 Current lr=[0.000297555943323901]

[0/24] Train loss=0.21074216067790985
[5/24] Train loss=0.18396992981433868
[10/24] Train loss=0.22886361181735992
[15/24] Train loss=0.20816388726234436
[20/24] Train loss=0.20065127313137054
Test set avg_accuracy=80.26% avg_sensitivity=23.45%, avg_specificity=99.63% avg_auc=78.92%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.207754 Test loss=0.558195 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.23130212724208832
[5/24] Train loss=0.19759909808635712
[10/24] Train loss=0.21698972582817078
[15/24] Train loss=0.1944141685962677
[20/24] Train loss=0.19934064149856567
Test set avg_accuracy=85.44% avg_sensitivity=50.74%, avg_specificity=97.28% avg_auc=88.96%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.208532 Test loss=0.373611 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.22037674486637115
[5/24] Train loss=0.18550947308540344
[10/24] Train loss=0.22145986557006836
[15/24] Train loss=0.20342104136943817
[20/24] Train loss=0.20119118690490723
Test set avg_accuracy=83.58% avg_sensitivity=41.27%, avg_specificity=98.01% avg_auc=86.79%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.205218 Test loss=0.422079 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2325495481491089
[5/24] Train loss=0.17590183019638062
[10/24] Train loss=0.20458509027957916
[15/24] Train loss=0.18523330986499786
[20/24] Train loss=0.20000366866588593
Test set avg_accuracy=85.78% avg_sensitivity=55.71%, avg_specificity=96.04% avg_auc=89.73%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.204242 Test loss=0.347450 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.21963651478290558
[5/24] Train loss=0.1699889451265335
[10/24] Train loss=0.20742210745811462
[15/24] Train loss=0.187026247382164
[20/24] Train loss=0.20202796161174774
Test set avg_accuracy=83.68% avg_sensitivity=40.86%, avg_specificity=98.29% avg_auc=87.30%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.199682 Test loss=0.423773 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.21914604306221008
[5/24] Train loss=0.2027411311864853
[10/24] Train loss=0.2089187055826187
[15/24] Train loss=0.18830378353595734
[20/24] Train loss=0.20084211230278015
Test set avg_accuracy=84.22% avg_sensitivity=46.34%, avg_specificity=97.14% avg_auc=88.17%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.201725 Test loss=0.395628 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.22065214812755585
[5/24] Train loss=0.17911340296268463
[10/24] Train loss=0.2012030929327011
[15/24] Train loss=0.18735232949256897
[20/24] Train loss=0.18169091641902924
Test set avg_accuracy=85.94% avg_sensitivity=63.90%, avg_specificity=93.45% avg_auc=90.14%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.196039 Test loss=0.336799 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.19951166212558746
[5/24] Train loss=0.18852002918720245
[10/24] Train loss=0.20331904292106628
[15/24] Train loss=0.18515034019947052
[20/24] Train loss=0.18532373011112213
Test set avg_accuracy=85.04% avg_sensitivity=75.17%, avg_specificity=88.41% avg_auc=91.19%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.193454 Test loss=0.334545 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.20208188891410828
[5/24] Train loss=0.17541973292827606
[10/24] Train loss=0.20022405683994293
[15/24] Train loss=0.18524819612503052
[20/24] Train loss=0.19138076901435852
Test set avg_accuracy=86.54% avg_sensitivity=58.58%, avg_specificity=96.07% avg_auc=90.85%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.194180 Test loss=0.326244 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.20375408232212067
[5/24] Train loss=0.16585566103458405
[10/24] Train loss=0.19674384593963623
[15/24] Train loss=0.18054084479808807
[20/24] Train loss=0.1783382147550583
Test set avg_accuracy=83.06% avg_sensitivity=38.71%, avg_specificity=98.18% avg_auc=84.21%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.188221 Test loss=0.464369 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.20165689289569855
[5/24] Train loss=0.16343626379966736
[10/24] Train loss=0.1935415118932724
[15/24] Train loss=0.1940583437681198
[20/24] Train loss=0.1844392865896225
Test set avg_accuracy=86.41% avg_sensitivity=61.96%, avg_specificity=94.74% avg_auc=90.19%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.191730 Test loss=0.330523 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.19684404134750366
[5/24] Train loss=0.179742693901062
[10/24] Train loss=0.20221902430057526
[15/24] Train loss=0.18395839631557465
[20/24] Train loss=0.19637547433376312
Test set avg_accuracy=85.76% avg_sensitivity=67.74%, avg_specificity=91.90% avg_auc=90.72%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.195348 Test loss=0.326575 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.19683422148227692
[5/24] Train loss=0.16371117532253265
[10/24] Train loss=0.20704226195812225
[15/24] Train loss=0.18771885335445404
[20/24] Train loss=0.1919781118631363
Test set avg_accuracy=84.08% avg_sensitivity=78.60%, avg_specificity=85.94% avg_auc=91.26%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.194778 Test loss=0.351942 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2027679830789566
[5/24] Train loss=0.17719903588294983
[10/24] Train loss=0.19573193788528442
[15/24] Train loss=0.16951338946819305
[20/24] Train loss=0.17688219249248505
Test set avg_accuracy=86.22% avg_sensitivity=60.32%, avg_specificity=95.06% avg_auc=90.51%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.187968 Test loss=0.333594 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.19077491760253906
[5/24] Train loss=0.17003905773162842
[10/24] Train loss=0.19527335464954376
[15/24] Train loss=0.17659235000610352
[20/24] Train loss=0.1931954026222229
Test set avg_accuracy=86.32% avg_sensitivity=60.93%, avg_specificity=94.97% avg_auc=89.91%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.187185 Test loss=0.342350 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.20343317091464996
[5/24] Train loss=0.1597723364830017
[10/24] Train loss=0.19148407876491547
[15/24] Train loss=0.1708076000213623
[20/24] Train loss=0.192351296544075
Test set avg_accuracy=83.06% avg_sensitivity=84.33%, avg_specificity=82.63% avg_auc=91.14%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.187126 Test loss=0.385514 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.1937323659658432
[5/24] Train loss=0.16594728827476501
[10/24] Train loss=0.1884375959634781
[15/24] Train loss=0.17286646366119385
[20/24] Train loss=0.17593227326869965
Test set avg_accuracy=80.30% avg_sensitivity=83.51%, avg_specificity=79.20% avg_auc=89.51%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.189407 Test loss=0.439053 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.189899742603302
[5/24] Train loss=0.17133094370365143
[10/24] Train loss=0.18824532628059387
[15/24] Train loss=0.1776537299156189
[20/24] Train loss=0.1769333928823471
Test set avg_accuracy=84.18% avg_sensitivity=47.82%, avg_specificity=96.58% avg_auc=85.36%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.186368 Test loss=0.425726 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.1927267462015152
[5/24] Train loss=0.16018803417682648
[10/24] Train loss=0.20045793056488037
[15/24] Train loss=0.18100275099277496
[20/24] Train loss=0.17367365956306458
Test set avg_accuracy=85.31% avg_sensitivity=56.22%, avg_specificity=95.23% avg_auc=89.03%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.185896 Test loss=0.358101 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.1880568563938141
[5/24] Train loss=0.16693255305290222
[10/24] Train loss=0.18108616769313812
[15/24] Train loss=0.16771134734153748
[20/24] Train loss=0.17030246555805206
Test set avg_accuracy=85.90% avg_sensitivity=61.39%, avg_specificity=94.26% avg_auc=89.89%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.181077 Test loss=0.343183 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.1821039617061615
[5/24] Train loss=0.1629476100206375
[10/24] Train loss=0.17964233458042145
[15/24] Train loss=0.16462068259716034
[20/24] Train loss=0.16417059302330017
Test set avg_accuracy=84.71% avg_sensitivity=54.99%, avg_specificity=94.85% avg_auc=86.87%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.174988 Test loss=0.394476 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.18017864227294922
[5/24] Train loss=0.16444148123264313
[10/24] Train loss=0.1846575140953064
[15/24] Train loss=0.17148274183273315
[20/24] Train loss=0.17698055505752563
Test set avg_accuracy=85.21% avg_sensitivity=68.97%, avg_specificity=90.75% avg_auc=89.04%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.176734 Test loss=0.354187 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1912572681903839
[5/24] Train loss=0.17074376344680786
[10/24] Train loss=0.17588363587856293
[15/24] Train loss=0.16420705616474152
[20/24] Train loss=0.17358025908470154
Test set avg_accuracy=80.30% avg_sensitivity=83.77%, avg_specificity=79.12% avg_auc=89.78%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.176749 Test loss=0.433481 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.18642927706241608
[5/24] Train loss=0.1759583204984665
[10/24] Train loss=0.18998175859451294
[15/24] Train loss=0.17042094469070435
[20/24] Train loss=0.1662667989730835
Test set avg_accuracy=84.47% avg_sensitivity=53.15%, avg_specificity=95.15% avg_auc=86.52%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.184626 Test loss=0.393530 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1906922161579132
[5/24] Train loss=0.1596636176109314
[10/24] Train loss=0.1823420375585556
[15/24] Train loss=0.1627490520477295
[20/24] Train loss=0.1683693379163742
Test set avg_accuracy=84.23% avg_sensitivity=46.75%, avg_specificity=97.01% avg_auc=85.84%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.178138 Test loss=0.436358 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.1838584989309311
[5/24] Train loss=0.1576663702726364
[10/24] Train loss=0.17987099289894104
[15/24] Train loss=0.15887074172496796
[20/24] Train loss=0.16767209768295288
Test set avg_accuracy=85.40% avg_sensitivity=69.64%, avg_specificity=90.78% avg_auc=89.30%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.173159 Test loss=0.351593 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.18119463324546814
[5/24] Train loss=0.1655314564704895
[10/24] Train loss=0.1852777600288391
[15/24] Train loss=0.1665492206811905
[20/24] Train loss=0.184381365776062
Test set avg_accuracy=85.40% avg_sensitivity=69.12%, avg_specificity=90.96% avg_auc=88.17%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.180266 Test loss=0.368142 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.17672327160835266
[5/24] Train loss=0.16676612198352814
[10/24] Train loss=0.18211595714092255
[15/24] Train loss=0.17033898830413818
[20/24] Train loss=0.17624716460704803
Test set avg_accuracy=84.26% avg_sensitivity=67.79%, avg_specificity=89.87% avg_auc=88.36%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.179608 Test loss=0.365579 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.18099898099899292
[5/24] Train loss=0.16441121697425842
[10/24] Train loss=0.17756974697113037
[15/24] Train loss=0.15633685886859894
[20/24] Train loss=0.16338159143924713
Test set avg_accuracy=85.42% avg_sensitivity=57.96%, avg_specificity=94.78% avg_auc=86.49%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.174482 Test loss=0.385281 Current lr=[0.000224838296036774]

[0/24] Train loss=0.17749415338039398
[5/24] Train loss=0.17187842726707458
[10/24] Train loss=0.18147289752960205
[15/24] Train loss=0.16277197003364563
[20/24] Train loss=0.16685247421264648
Test set avg_accuracy=85.52% avg_sensitivity=54.63%, avg_specificity=96.05% avg_auc=87.35%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.175957 Test loss=0.390226 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.182634174823761
[5/24] Train loss=0.16233736276626587
[10/24] Train loss=0.17170585691928864
[15/24] Train loss=0.16591539978981018
[20/24] Train loss=0.17125847935676575
Test set avg_accuracy=82.21% avg_sensitivity=80.80%, avg_specificity=82.70% avg_auc=89.41%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.172392 Test loss=0.402485 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.17756907641887665
[5/24] Train loss=0.1545199155807495
[10/24] Train loss=0.17250856757164001
[15/24] Train loss=0.15647417306900024
[20/24] Train loss=0.1666431874036789
Test set avg_accuracy=84.82% avg_sensitivity=73.22%, avg_specificity=88.77% avg_auc=89.18%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.170893 Test loss=0.367429 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.17128019034862518
[5/24] Train loss=0.1547909826040268
[10/24] Train loss=0.1683477759361267
[15/24] Train loss=0.1570289582014084
[20/24] Train loss=0.1673479974269867
Test set avg_accuracy=85.43% avg_sensitivity=64.57%, avg_specificity=92.54% avg_auc=88.35%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.170768 Test loss=0.365208 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.1761946678161621
[5/24] Train loss=0.1574057936668396
[10/24] Train loss=0.17016707360744476
[15/24] Train loss=0.16689938306808472
[20/24] Train loss=0.16547518968582153
Test set avg_accuracy=82.80% avg_sensitivity=39.38%, avg_specificity=97.61% avg_auc=83.57%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.173833 Test loss=0.467920 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.19042496383190155
[5/24] Train loss=0.15479709208011627
[10/24] Train loss=0.17250920832157135
[15/24] Train loss=0.15637287497520447
[20/24] Train loss=0.1623554527759552
Test set avg_accuracy=84.38% avg_sensitivity=48.59%, avg_specificity=96.58% avg_auc=84.26%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.171576 Test loss=0.427991 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1721484214067459
[5/24] Train loss=0.15884169936180115
[10/24] Train loss=0.17619509994983673
[15/24] Train loss=0.17207223176956177
[20/24] Train loss=0.1736328899860382
Test set avg_accuracy=86.52% avg_sensitivity=66.56%, avg_specificity=93.33% avg_auc=89.69%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.175186 Test loss=0.339426 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.18016721308231354
[5/24] Train loss=0.1653926968574524
[10/24] Train loss=0.18015745282173157
[15/24] Train loss=0.16312304139137268
[20/24] Train loss=0.16941897571086884
Test set avg_accuracy=78.01% avg_sensitivity=14.59%, avg_specificity=99.63% avg_auc=68.99%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.174685 Test loss=0.714216 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1809111088514328
[5/24] Train loss=0.16428425908088684
[10/24] Train loss=0.17561961710453033
[15/24] Train loss=0.15497292578220367
[20/24] Train loss=0.16524221003055573
Test set avg_accuracy=82.08% avg_sensitivity=35.07%, avg_specificity=98.11% avg_auc=80.35%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.170091 Test loss=0.492267 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.17665788531303406
[5/24] Train loss=0.14877234399318695
[10/24] Train loss=0.1704801470041275
[15/24] Train loss=0.1581985354423523
[20/24] Train loss=0.15837226808071136
Test set avg_accuracy=86.73% avg_sensitivity=64.21%, avg_specificity=94.41% avg_auc=89.63%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.167884 Test loss=0.340142 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.17135289311408997
[5/24] Train loss=0.15456806123256683
[10/24] Train loss=0.17819815874099731
[15/24] Train loss=0.16501864790916443
[20/24] Train loss=0.16535943746566772
Test set avg_accuracy=84.90% avg_sensitivity=55.86%, avg_specificity=94.80% avg_auc=86.37%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.168704 Test loss=0.395047 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.1751546561717987
[5/24] Train loss=0.15453001856803894
[10/24] Train loss=0.178882896900177
[15/24] Train loss=0.1588154286146164
[20/24] Train loss=0.16030649840831757
Test set avg_accuracy=85.12% avg_sensitivity=54.07%, avg_specificity=95.70% avg_auc=86.50%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.168433 Test loss=0.400851 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.17410196363925934
[5/24] Train loss=0.15809352695941925
[10/24] Train loss=0.18915019929409027
[15/24] Train loss=0.1630912721157074
[20/24] Train loss=0.16380037367343903
Test set avg_accuracy=86.33% avg_sensitivity=72.15%, avg_specificity=91.16% avg_auc=89.95%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.167140 Test loss=0.342878 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.1750040054321289
[5/24] Train loss=0.15599709749221802
[10/24] Train loss=0.18242064118385315
[15/24] Train loss=0.1521753966808319
[20/24] Train loss=0.1602884978055954
Test set avg_accuracy=85.47% avg_sensitivity=55.20%, avg_specificity=95.79% avg_auc=85.72%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.167346 Test loss=0.398002 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.17733483016490936
[5/24] Train loss=0.14932836592197418
[10/24] Train loss=0.1711866557598114
[15/24] Train loss=0.15853892266750336
[20/24] Train loss=0.16305942833423615
Test set avg_accuracy=85.01% avg_sensitivity=59.14%, avg_specificity=93.84% avg_auc=87.44%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.167089 Test loss=0.380364 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.18820121884346008
[5/24] Train loss=0.1559654176235199
[10/24] Train loss=0.1563105285167694
[15/24] Train loss=0.15239140391349792
[20/24] Train loss=0.15737299621105194
Test set avg_accuracy=84.58% avg_sensitivity=50.18%, avg_specificity=96.32% avg_auc=85.33%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.163003 Test loss=0.419828 Current lr=[0.000156543481933168]

[0/24] Train loss=0.16012030839920044
[5/24] Train loss=0.15662826597690582
[10/24] Train loss=0.16167375445365906
[15/24] Train loss=0.1529296338558197
[20/24] Train loss=0.15860258042812347
Test set avg_accuracy=85.23% avg_sensitivity=73.78%, avg_specificity=89.14% avg_auc=90.44%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.163679 Test loss=0.346285 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.16237378120422363
[5/24] Train loss=0.14748461544513702
[10/24] Train loss=0.17266923189163208
[15/24] Train loss=0.16372711956501007
[20/24] Train loss=0.1571948379278183
Test set avg_accuracy=84.53% avg_sensitivity=48.13%, avg_specificity=96.94% avg_auc=85.54%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.163345 Test loss=0.421249 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.17977705597877502
[5/24] Train loss=0.15109524130821228
[10/24] Train loss=0.17072425782680511
[15/24] Train loss=0.15310685336589813
[20/24] Train loss=0.15391801297664642
Test set avg_accuracy=86.18% avg_sensitivity=56.48%, avg_specificity=96.32% avg_auc=89.70%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.163178 Test loss=0.353783 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.16878004372119904
[5/24] Train loss=0.1510591059923172
[10/24] Train loss=0.15767541527748108
[15/24] Train loss=0.1458238661289215
[20/24] Train loss=0.14693216979503632
Test set avg_accuracy=85.96% avg_sensitivity=61.55%, avg_specificity=94.29% avg_auc=88.85%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.158298 Test loss=0.361534 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.16154389083385468
[5/24] Train loss=0.1419941633939743
[10/24] Train loss=0.16011567413806915
[15/24] Train loss=0.14609089493751526
[20/24] Train loss=0.14952637255191803
Test set avg_accuracy=86.56% avg_sensitivity=60.16%, avg_specificity=95.56% avg_auc=89.27%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.156346 Test loss=0.350658 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16608493030071259
[5/24] Train loss=0.146530419588089
[10/24] Train loss=0.15550515055656433
[15/24] Train loss=0.14871038496494293
[20/24] Train loss=0.14478515088558197
Test set avg_accuracy=86.84% avg_sensitivity=63.24%, avg_specificity=94.88% avg_auc=89.66%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.155114 Test loss=0.337276 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.16127756237983704
[5/24] Train loss=0.14102323353290558
[10/24] Train loss=0.15439610183238983
[15/24] Train loss=0.14497897028923035
[20/24] Train loss=0.15045735239982605
Test set avg_accuracy=85.83% avg_sensitivity=58.53%, avg_specificity=95.15% avg_auc=87.23%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.155419 Test loss=0.376871 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.16182063519954681
[5/24] Train loss=0.15397393703460693
[10/24] Train loss=0.15648253262043
[15/24] Train loss=0.14613357186317444
[20/24] Train loss=0.14475415647029877
Test set avg_accuracy=86.76% avg_sensitivity=70.71%, avg_specificity=92.23% avg_auc=90.99%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.155247 Test loss=0.326716 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15821903944015503
[5/24] Train loss=0.14200560748577118
[10/24] Train loss=0.15762227773666382
[15/24] Train loss=0.14632593095302582
[20/24] Train loss=0.14470486342906952
Test set avg_accuracy=86.38% avg_sensitivity=63.44%, avg_specificity=94.20% avg_auc=89.26%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.154711 Test loss=0.347520 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.16689558327198029
[5/24] Train loss=0.13847675919532776
[10/24] Train loss=0.15161152184009552
[15/24] Train loss=0.14113831520080566
[20/24] Train loss=0.1440650373697281
Test set avg_accuracy=86.85% avg_sensitivity=66.67%, avg_specificity=93.73% avg_auc=88.95%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.152993 Test loss=0.346631 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16336247324943542
[5/24] Train loss=0.14424630999565125
[10/24] Train loss=0.15268580615520477
[15/24] Train loss=0.1474953144788742
[20/24] Train loss=0.14374084770679474
Test set avg_accuracy=86.20% avg_sensitivity=59.75%, avg_specificity=95.22% avg_auc=88.76%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.151614 Test loss=0.363581 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15729127824306488
[5/24] Train loss=0.14787353575229645
[10/24] Train loss=0.14922942221164703
[15/24] Train loss=0.1416252702474594
[20/24] Train loss=0.1422749012708664
Test set avg_accuracy=86.13% avg_sensitivity=74.19%, avg_specificity=90.20% avg_auc=90.94%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.151337 Test loss=0.334282 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1561223566532135
[5/24] Train loss=0.14641036093235016
[10/24] Train loss=0.1506844013929367
[15/24] Train loss=0.14443160593509674
[20/24] Train loss=0.13898567855358124
Test set avg_accuracy=86.94% avg_sensitivity=72.61%, avg_specificity=91.83% avg_auc=90.74%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.149775 Test loss=0.326527 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.16197100281715393
[5/24] Train loss=0.14461460709571838
[10/24] Train loss=0.14737489819526672
[15/24] Train loss=0.1363193243741989
[20/24] Train loss=0.14246141910552979
Test set avg_accuracy=87.40% avg_sensitivity=70.10%, avg_specificity=93.29% avg_auc=90.92%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.147684 Test loss=0.320960 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15044356882572174
[5/24] Train loss=0.13620993494987488
[10/24] Train loss=0.1426606923341751
[15/24] Train loss=0.13639171421527863
[20/24] Train loss=0.14434875547885895
Test set avg_accuracy=85.79% avg_sensitivity=73.37%, avg_specificity=90.03% avg_auc=90.39%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.145886 Test loss=0.345317 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.15219195187091827
[5/24] Train loss=0.13965129852294922
[10/24] Train loss=0.1484801024198532
[15/24] Train loss=0.1351502239704132
[20/24] Train loss=0.1407824605703354
Test set avg_accuracy=85.99% avg_sensitivity=74.14%, avg_specificity=90.03% avg_auc=91.10%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.146671 Test loss=0.337409 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1554342657327652
[5/24] Train loss=0.13550937175750732
[10/24] Train loss=0.13939455151557922
[15/24] Train loss=0.1321299970149994
[20/24] Train loss=0.13388513028621674
Test set avg_accuracy=84.84% avg_sensitivity=79.52%, avg_specificity=86.66% avg_auc=90.65%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.143781 Test loss=0.361189 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1558849960565567
[5/24] Train loss=0.13322874903678894
[10/24] Train loss=0.14163613319396973
[15/24] Train loss=0.1352841705083847
[20/24] Train loss=0.14389175176620483
Test set avg_accuracy=86.48% avg_sensitivity=74.71%, avg_specificity=90.50% avg_auc=90.77%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.143994 Test loss=0.336033 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14780281484127045
[5/24] Train loss=0.13552729785442352
[10/24] Train loss=0.13738861680030823
[15/24] Train loss=0.1343434453010559
[20/24] Train loss=0.13486932218074799
Test set avg_accuracy=84.61% avg_sensitivity=77.83%, avg_specificity=86.92% avg_auc=90.37%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.142095 Test loss=0.368984 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14830249547958374
[5/24] Train loss=0.13549207150936127
[10/24] Train loss=0.13530823588371277
[15/24] Train loss=0.13694678246974945
[20/24] Train loss=0.1376941055059433
Test set avg_accuracy=86.64% avg_sensitivity=72.81%, avg_specificity=91.36% avg_auc=90.39%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.141224 Test loss=0.335605 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14974671602249146
[5/24] Train loss=0.1292010396718979
[10/24] Train loss=0.13666248321533203
[15/24] Train loss=0.13295872509479523
[20/24] Train loss=0.13533173501491547
Test set avg_accuracy=86.16% avg_sensitivity=65.85%, avg_specificity=93.09% avg_auc=89.56%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.140064 Test loss=0.352878 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14598695933818817
[5/24] Train loss=0.13357730209827423
[10/24] Train loss=0.1389046162366867
[15/24] Train loss=0.12939795851707458
[20/24] Train loss=0.13228720426559448
Test set avg_accuracy=85.61% avg_sensitivity=77.32%, avg_specificity=88.44% avg_auc=90.41%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.139698 Test loss=0.346726 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.15152782201766968
[5/24] Train loss=0.131117045879364
[10/24] Train loss=0.13888099789619446
[15/24] Train loss=0.13343952596187592
[20/24] Train loss=0.1354556530714035
Test set avg_accuracy=86.56% avg_sensitivity=69.74%, avg_specificity=92.30% avg_auc=89.67%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.139591 Test loss=0.348456 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.15426267683506012
[5/24] Train loss=0.12912847101688385
[10/24] Train loss=0.1357213407754898
[15/24] Train loss=0.1300128996372223
[20/24] Train loss=0.13196833431720734
Test set avg_accuracy=85.90% avg_sensitivity=73.48%, avg_specificity=90.13% avg_auc=90.23%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.139373 Test loss=0.348866 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14825141429901123
[5/24] Train loss=0.12867559492588043
[10/24] Train loss=0.13672909140586853
[15/24] Train loss=0.12831874191761017
[20/24] Train loss=0.13157112896442413
Test set avg_accuracy=86.45% avg_sensitivity=76.04%, avg_specificity=89.99% avg_auc=90.99%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.137692 Test loss=0.335043 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.14865829050540924
[5/24] Train loss=0.1282278597354889
[10/24] Train loss=0.1365332454442978
[15/24] Train loss=0.13154880702495575
[20/24] Train loss=0.1299736350774765
Test set avg_accuracy=86.56% avg_sensitivity=68.97%, avg_specificity=92.56% avg_auc=90.03%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.136817 Test loss=0.340050 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1429564654827118
[5/24] Train loss=0.12624803185462952
[10/24] Train loss=0.13235056400299072
[15/24] Train loss=0.12978467345237732
[20/24] Train loss=0.1317676454782486
Test set avg_accuracy=85.59% avg_sensitivity=71.48%, avg_specificity=90.40% avg_auc=89.76%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.135410 Test loss=0.354667 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1432281881570816
[5/24] Train loss=0.12931352853775024
[10/24] Train loss=0.12924611568450928
[15/24] Train loss=0.12748397886753082
[20/24] Train loss=0.12782536447048187
Test set avg_accuracy=87.49% avg_sensitivity=69.23%, avg_specificity=93.71% avg_auc=90.12%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.134432 Test loss=0.330501 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.14017494022846222
[5/24] Train loss=0.1313769370317459
[10/24] Train loss=0.1283928006887436
[15/24] Train loss=0.12629447877407074
[20/24] Train loss=0.12876909971237183
Test set avg_accuracy=87.04% avg_sensitivity=67.79%, avg_specificity=93.61% avg_auc=89.29%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.133705 Test loss=0.340395 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1407478153705597
[5/24] Train loss=0.12665951251983643
[10/24] Train loss=0.13057011365890503
[15/24] Train loss=0.1261845976114273
[20/24] Train loss=0.1277904361486435
Test set avg_accuracy=86.59% avg_sensitivity=71.89%, avg_specificity=91.60% avg_auc=90.35%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.132706 Test loss=0.334121 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.14085137844085693
[5/24] Train loss=0.1238659992814064
[10/24] Train loss=0.13045459985733032
[15/24] Train loss=0.12507615983486176
[20/24] Train loss=0.1299508512020111
Test set avg_accuracy=86.97% avg_sensitivity=67.08%, avg_specificity=93.75% avg_auc=89.48%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.132550 Test loss=0.339999 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1379069983959198
[5/24] Train loss=0.1222851499915123
[10/24] Train loss=0.1262870728969574
[15/24] Train loss=0.12644729018211365
[20/24] Train loss=0.12877236306667328
Test set avg_accuracy=87.15% avg_sensitivity=71.33%, avg_specificity=92.54% avg_auc=90.40%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.131688 Test loss=0.331501 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.14159707725048065
[5/24] Train loss=0.12349338829517365
[10/24] Train loss=0.12960806488990784
[15/24] Train loss=0.1239345446228981
[20/24] Train loss=0.12561637163162231
Test set avg_accuracy=87.21% avg_sensitivity=71.48%, avg_specificity=92.58% avg_auc=89.81%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.130415 Test loss=0.332095 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13638797402381897
[5/24] Train loss=0.12426929920911789
[10/24] Train loss=0.12566807866096497
[15/24] Train loss=0.1243758499622345
[20/24] Train loss=0.1262819766998291
Test set avg_accuracy=87.25% avg_sensitivity=71.33%, avg_specificity=92.68% avg_auc=89.87%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.129611 Test loss=0.334138 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.14286893606185913
[5/24] Train loss=0.1250501573085785
[10/24] Train loss=0.12958088517189026
[15/24] Train loss=0.12194710224866867
[20/24] Train loss=0.12492109090089798
Test set avg_accuracy=87.37% avg_sensitivity=70.15%, avg_specificity=93.24% avg_auc=89.80%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.129902 Test loss=0.331420 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.14055487513542175
[5/24] Train loss=0.12373553216457367
[10/24] Train loss=0.12437333166599274
[15/24] Train loss=0.12259076535701752
[20/24] Train loss=0.12448690086603165
Test set avg_accuracy=86.97% avg_sensitivity=68.66%, avg_specificity=93.21% avg_auc=89.60%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.129814 Test loss=0.337653 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1376667022705078
[5/24] Train loss=0.12343677878379822
[10/24] Train loss=0.12677419185638428
[15/24] Train loss=0.12086445838212967
[20/24] Train loss=0.12351579964160919
Test set avg_accuracy=87.07% avg_sensitivity=70.76%, avg_specificity=92.63% avg_auc=89.77%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.128586 Test loss=0.334715 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13448047637939453
[5/24] Train loss=0.12169055640697479
[10/24] Train loss=0.12580174207687378
[15/24] Train loss=0.12379904091358185
[20/24] Train loss=0.12645907700061798
Test set avg_accuracy=87.11% avg_sensitivity=71.48%, avg_specificity=92.44% avg_auc=89.92%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.127882 Test loss=0.333717 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13569845259189606
[5/24] Train loss=0.12043775618076324
[10/24] Train loss=0.12367360293865204
[15/24] Train loss=0.11940214037895203
[20/24] Train loss=0.12638233602046967
Test set avg_accuracy=87.10% avg_sensitivity=71.68%, avg_specificity=92.35% avg_auc=90.10%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.127448 Test loss=0.332468 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13632801175117493
[5/24] Train loss=0.12060511857271194
[10/24] Train loss=0.12585601210594177
[15/24] Train loss=0.11911255121231079
[20/24] Train loss=0.1255866289138794
Test set avg_accuracy=87.14% avg_sensitivity=72.76%, avg_specificity=92.04% avg_auc=89.89%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.126731 Test loss=0.337542 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1345883309841156
[5/24] Train loss=0.12338488548994064
[10/24] Train loss=0.12144804745912552
[15/24] Train loss=0.12086088210344315
[20/24] Train loss=0.12122000008821487
Test set avg_accuracy=87.01% avg_sensitivity=71.02%, avg_specificity=92.46% avg_auc=89.82%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.126605 Test loss=0.337329 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13497444987297058
[5/24] Train loss=0.1204531118273735
[10/24] Train loss=0.12088340520858765
[15/24] Train loss=0.11998798698186874
[20/24] Train loss=0.12316470593214035
Test set avg_accuracy=87.17% avg_sensitivity=70.40%, avg_specificity=92.89% avg_auc=89.87%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.126457 Test loss=0.334455 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1348973661661148
[5/24] Train loss=0.12091922014951706
[10/24] Train loss=0.12405529618263245
[15/24] Train loss=0.11770308762788773
[20/24] Train loss=0.1244874894618988
Test set avg_accuracy=86.93% avg_sensitivity=70.66%, avg_specificity=92.47% avg_auc=89.99%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.125919 Test loss=0.335127 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13374575972557068
[5/24] Train loss=0.11839838325977325
[10/24] Train loss=0.11929032951593399
[15/24] Train loss=0.12003868818283081
[20/24] Train loss=0.12273891270160675
Test set avg_accuracy=86.93% avg_sensitivity=71.94%, avg_specificity=92.04% avg_auc=89.89%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.125209 Test loss=0.337889 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13117925822734833
[5/24] Train loss=0.12046877294778824
[10/24] Train loss=0.12109380960464478
[15/24] Train loss=0.11837837845087051
[20/24] Train loss=0.12036631256341934
Test set avg_accuracy=87.23% avg_sensitivity=71.48%, avg_specificity=92.60% avg_auc=89.78%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.125143 Test loss=0.336749 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.132487490773201
[5/24] Train loss=0.12080670148134232
[10/24] Train loss=0.11970873177051544
[15/24] Train loss=0.11872342973947525
[20/24] Train loss=0.12147556245326996
Test set avg_accuracy=87.16% avg_sensitivity=71.17%, avg_specificity=92.61% avg_auc=89.88%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.124586 Test loss=0.335062 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13179415464401245
[5/24] Train loss=0.12178479135036469
[10/24] Train loss=0.11892133206129074
[15/24] Train loss=0.11796847730875015
[20/24] Train loss=0.12377969920635223
Test set avg_accuracy=87.23% avg_sensitivity=70.81%, avg_specificity=92.82% avg_auc=90.00%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.125245 Test loss=0.334226 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13318082690238953
[5/24] Train loss=0.11890339106321335
[10/24] Train loss=0.12142530083656311
[15/24] Train loss=0.11778100579977036
[20/24] Train loss=0.12277869880199432
Test set avg_accuracy=87.07% avg_sensitivity=70.25%, avg_specificity=92.81% avg_auc=89.88%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.123983 Test loss=0.335368 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13517747819423676
[5/24] Train loss=0.11935139447450638
[10/24] Train loss=0.12214372307062149
[15/24] Train loss=0.11816727370023727
[20/24] Train loss=0.12149138003587723
Test set avg_accuracy=87.30% avg_sensitivity=71.17%, avg_specificity=92.81% avg_auc=89.93%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.124499 Test loss=0.335252 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13333652913570404
[5/24] Train loss=0.12005198001861572
[10/24] Train loss=0.1263529509305954
[15/24] Train loss=0.11777809262275696
[20/24] Train loss=0.12383122742176056
Test set avg_accuracy=87.20% avg_sensitivity=70.76%, avg_specificity=92.81% avg_auc=89.92%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.125429 Test loss=0.335132 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.13464640080928802
[5/24] Train loss=0.11821828037500381
[10/24] Train loss=0.1248546689748764
[15/24] Train loss=0.11781521141529083
[20/24] Train loss=0.11925122141838074
Test set avg_accuracy=87.24% avg_sensitivity=70.71%, avg_specificity=92.88% avg_auc=89.90%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.124019 Test loss=0.334879 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.13372240960597992
[5/24] Train loss=0.1205681711435318
[10/24] Train loss=0.12221353501081467
[15/24] Train loss=0.11614717543125153
[20/24] Train loss=0.11991212517023087
Test set avg_accuracy=87.27% avg_sensitivity=70.81%, avg_specificity=92.88% avg_auc=89.90%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.124627 Test loss=0.334936 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13126739859580994
[5/24] Train loss=0.12059932202100754
[10/24] Train loss=0.12311188876628876
[15/24] Train loss=0.11915035545825958
[20/24] Train loss=0.1221655085682869
Test set avg_accuracy=87.27% avg_sensitivity=70.87%, avg_specificity=92.86% avg_auc=89.90%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.124383 Test loss=0.334946 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.13289466500282288
[5/24] Train loss=0.11722549051046371
[10/24] Train loss=0.1208387166261673
[15/24] Train loss=0.11839193105697632
[20/24] Train loss=0.12214063107967377
Test set avg_accuracy=87.28% avg_sensitivity=70.97%, avg_specificity=92.84% avg_auc=89.90%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.124029 Test loss=0.334994 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=86.52% sen=78.96%, spe=89.10%, auc=92.14%!
Fold[5] Avg_overlap=0.65%(±0.2194921277810574)
[0/24] Train loss=0.7437722086906433
[5/24] Train loss=0.7399731874465942
[10/24] Train loss=0.7353937029838562
[15/24] Train loss=0.7240790724754333
[20/24] Train loss=0.7147237658500671
Test set avg_accuracy=56.17% avg_sensitivity=45.83%, avg_specificity=60.03% avg_auc=55.20%
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.727716 Test loss=0.698151 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7007116079330444
[5/24] Train loss=0.7027861475944519
[10/24] Train loss=0.6954500675201416
[15/24] Train loss=0.6849772930145264
[20/24] Train loss=0.6747671365737915
Test set avg_accuracy=67.08% avg_sensitivity=63.92%, avg_specificity=68.26% avg_auc=71.57%
Best model saved!! Metric=-55.1703143914605!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.693709 Test loss=0.624828 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6775237321853638
[5/24] Train loss=0.6626263856887817
[10/24] Train loss=0.6672770380973816
[15/24] Train loss=0.6541018486022949
[20/24] Train loss=0.651921808719635
Test set avg_accuracy=71.00% avg_sensitivity=70.63%, avg_specificity=71.14% avg_auc=77.18%
Best model saved!! Metric=-36.04334961990146!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.662581 Test loss=0.584117 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6388174295425415
[5/24] Train loss=0.6349751949310303
[10/24] Train loss=0.6353901624679565
[15/24] Train loss=0.627084493637085
[20/24] Train loss=0.6165565252304077
Test set avg_accuracy=72.66% avg_sensitivity=75.96%, avg_specificity=71.43% avg_auc=80.26%
Best model saved!! Metric=-25.70059009280004!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.635525 Test loss=0.560159 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6168202757835388
[5/24] Train loss=0.5965040326118469
[10/24] Train loss=0.6121490597724915
[15/24] Train loss=0.594351053237915
[20/24] Train loss=0.5893948078155518
Test set avg_accuracy=74.41% avg_sensitivity=77.78%, avg_specificity=73.16% avg_auc=82.57%
Best model saved!! Metric=-18.069357587559125!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.605545 Test loss=0.534980 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5807985067367554
[5/24] Train loss=0.5783184170722961
[10/24] Train loss=0.5830563306808472
[15/24] Train loss=0.5743793845176697
[20/24] Train loss=0.5607364773750305
Test set avg_accuracy=76.25% avg_sensitivity=77.83%, avg_specificity=75.66% avg_auc=84.19%
Best model saved!! Metric=-12.071781118676768!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.580237 Test loss=0.508389 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.553399384021759
[5/24] Train loss=0.5524804592132568
[10/24] Train loss=0.5553399920463562
[15/24] Train loss=0.5468656420707703
[20/24] Train loss=0.5342346429824829
Test set avg_accuracy=77.58% avg_sensitivity=78.21%, avg_specificity=77.34% avg_auc=85.77%
Best model saved!! Metric=-7.099892887742698!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.553714 Test loss=0.484179 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5265768766403198
[5/24] Train loss=0.5219411849975586
[10/24] Train loss=0.5370614528656006
[15/24] Train loss=0.5207564234733582
[20/24] Train loss=0.5009438991546631
Test set avg_accuracy=79.69% avg_sensitivity=75.72%, avg_specificity=81.17% avg_auc=87.06%
Best model saved!! Metric=-2.3666041448580586!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.527679 Test loss=0.455283 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5106323957443237
[5/24] Train loss=0.4961077868938446
[10/24] Train loss=0.4987396001815796
[15/24] Train loss=0.5028313398361206
[20/24] Train loss=0.4765050411224365
Test set avg_accuracy=80.72% avg_sensitivity=76.06%, avg_specificity=82.45% avg_auc=88.06%
Best model saved!! Metric=1.2856381633359746!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.500885 Test loss=0.440537 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.48220089077949524
[5/24] Train loss=0.4744625687599182
[10/24] Train loss=0.4763995110988617
[15/24] Train loss=0.47183623909950256
[20/24] Train loss=0.4481092095375061
Test set avg_accuracy=81.89% avg_sensitivity=75.77%, avg_specificity=84.17% avg_auc=88.84%
Best model saved!! Metric=4.667194914353644!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.476586 Test loss=0.421456 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.45631030201911926
[5/24] Train loss=0.45071420073509216
[10/24] Train loss=0.4510635733604431
[15/24] Train loss=0.4495072066783905
[20/24] Train loss=0.42550772428512573
Test set avg_accuracy=83.35% avg_sensitivity=73.32%, avg_specificity=87.08% avg_auc=89.42%
Best model saved!! Metric=7.169841672823381!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.453324 Test loss=0.400320 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4338906705379486
[5/24] Train loss=0.43201443552970886
[10/24] Train loss=0.4338098168373108
[15/24] Train loss=0.4369107484817505
[20/24] Train loss=0.4038263261318207
Test set avg_accuracy=84.27% avg_sensitivity=72.17%, avg_specificity=88.78% avg_auc=90.16%
Best model saved!! Metric=9.380066656011024!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.433212 Test loss=0.380425 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4174335300922394
[5/24] Train loss=0.4117368459701538
[10/24] Train loss=0.41655105352401733
[15/24] Train loss=0.41615062952041626
[20/24] Train loss=0.38227006793022156
Test set avg_accuracy=84.86% avg_sensitivity=72.79%, avg_specificity=89.35% avg_auc=90.61%
Best model saved!! Metric=11.61365846488809!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.413429 Test loss=0.370201 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.39626675844192505
[5/24] Train loss=0.39375388622283936
[10/24] Train loss=0.39854714274406433
[15/24] Train loss=0.3940936028957367
[20/24] Train loss=0.36149606108665466
Test set avg_accuracy=85.07% avg_sensitivity=73.56%, avg_specificity=89.35% avg_auc=91.08%
Best model saved!! Metric=13.053716302563018!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.396393 Test loss=0.360284 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3847742974758148
[5/24] Train loss=0.37511059641838074
[10/24] Train loss=0.37834692001342773
[15/24] Train loss=0.3805156946182251
[20/24] Train loss=0.343165785074234
Test set avg_accuracy=85.08% avg_sensitivity=76.54%, avg_specificity=88.26% avg_auc=91.49%
Best model saved!! Metric=15.360640685045112!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.380608 Test loss=0.356635 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3681972026824951
[5/24] Train loss=0.3704977333545685
[10/24] Train loss=0.3658347725868225
[15/24] Train loss=0.3722591996192932
[20/24] Train loss=0.33524972200393677
Test set avg_accuracy=85.94% avg_sensitivity=75.10%, avg_specificity=89.97% avg_auc=91.87%
Best model saved!! Metric=16.877763747480728!!
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.368386 Test loss=0.341806 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3587697446346283
[5/24] Train loss=0.3528183102607727
[10/24] Train loss=0.35502567887306213
[15/24] Train loss=0.36362725496292114
[20/24] Train loss=0.320417582988739
Test set avg_accuracy=85.94% avg_sensitivity=76.15%, avg_specificity=89.58% avg_auc=91.87%
Best model saved!! Metric=17.5438808258984!!
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.357224 Test loss=0.338581 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.35108041763305664
[5/24] Train loss=0.3530596196651459
[10/24] Train loss=0.3430703580379486
[15/24] Train loss=0.3534242808818817
[20/24] Train loss=0.31610843539237976
Test set avg_accuracy=85.04% avg_sensitivity=78.84%, avg_specificity=87.35% avg_auc=91.77%
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.347822 Test loss=0.349204 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3379807472229004
[5/24] Train loss=0.3417212963104248
[10/24] Train loss=0.3373829126358032
[15/24] Train loss=0.34144070744514465
[20/24] Train loss=0.2990798354148865
Test set avg_accuracy=85.20% avg_sensitivity=77.93%, avg_specificity=87.90% avg_auc=91.78%
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.338620 Test loss=0.340267 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3306816816329956
[5/24] Train loss=0.3370240032672882
[10/24] Train loss=0.3291480541229248
[15/24] Train loss=0.3365902006626129
[20/24] Train loss=0.2929985821247101
Test set avg_accuracy=86.09% avg_sensitivity=76.92%, avg_specificity=89.51% avg_auc=92.18%
Best model saved!! Metric=18.708194235600132!!
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.329789 Test loss=0.328106 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.325704962015152
[5/24] Train loss=0.3251986801624298
[10/24] Train loss=0.32743537425994873
[15/24] Train loss=0.3253106474876404
[20/24] Train loss=0.2851969301700592
Test set avg_accuracy=85.47% avg_sensitivity=79.41%, avg_specificity=87.72% avg_auc=92.00%
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.323061 Test loss=0.334776 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3205498158931732
[5/24] Train loss=0.3245019316673279
[10/24] Train loss=0.3155444264411926
[15/24] Train loss=0.32185474038124084
[20/24] Train loss=0.2823675274848938
Test set avg_accuracy=85.90% avg_sensitivity=79.13%, avg_specificity=88.42% avg_auc=92.31%
Best model saved!! Metric=19.75709116542322!!
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.316563 Test loss=0.323222 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3095393478870392
[5/24] Train loss=0.3248394727706909
[10/24] Train loss=0.31124168634414673
[15/24] Train loss=0.31352105736732483
[20/24] Train loss=0.26901018619537354
Test set avg_accuracy=86.02% avg_sensitivity=78.26%, avg_specificity=88.90% avg_auc=92.60%
Best model saved!! Metric=19.78598811925572!!
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.309935 Test loss=0.319230 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.29839587211608887
[5/24] Train loss=0.3175852596759796
[10/24] Train loss=0.30966389179229736
[15/24] Train loss=0.30785951018333435
[20/24] Train loss=0.26472824811935425
Test set avg_accuracy=87.45% avg_sensitivity=72.46%, avg_specificity=93.03% avg_auc=92.60%
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.304330 Test loss=0.301569 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.29958346486091614
[5/24] Train loss=0.3057485818862915
[10/24] Train loss=0.3030613362789154
[15/24] Train loss=0.2976297438144684
[20/24] Train loss=0.26083484292030334
Test set avg_accuracy=86.42% avg_sensitivity=60.08%, avg_specificity=96.23% avg_auc=91.89%
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.298450 Test loss=0.325139 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.30011820793151855
[5/24] Train loss=0.2914198338985443
[10/24] Train loss=0.2943972945213318
[15/24] Train loss=0.29874899983406067
[20/24] Train loss=0.2623503804206848
Test set avg_accuracy=86.74% avg_sensitivity=62.57%, avg_specificity=95.75% avg_auc=92.53%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.293080 Test loss=0.310608 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2827138900756836
[5/24] Train loss=0.28405851125717163
[10/24] Train loss=0.2791200876235962
[15/24] Train loss=0.29443684220314026
[20/24] Train loss=0.2486466020345688
Test set avg_accuracy=86.46% avg_sensitivity=60.94%, avg_specificity=95.96% avg_auc=92.23%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.286361 Test loss=0.316221 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2903675138950348
[5/24] Train loss=0.29361242055892944
[10/24] Train loss=0.2875531017780304
[15/24] Train loss=0.2827082574367523
[20/24] Train loss=0.2447054237127304
Test set avg_accuracy=84.77% avg_sensitivity=50.14%, avg_specificity=97.66% avg_auc=91.12%
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.283690 Test loss=0.356233 Current lr=[0.000210185142098938]

[0/24] Train loss=0.26712489128112793
[5/24] Train loss=0.2735219895839691
[10/24] Train loss=0.27700603008270264
[15/24] Train loss=0.2757246792316437
[20/24] Train loss=0.23695141077041626
Test set avg_accuracy=82.45% avg_sensitivity=38.96%, avg_specificity=98.64% avg_auc=89.78%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.277734 Test loss=0.411180 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2616158127784729
[5/24] Train loss=0.2641616463661194
[10/24] Train loss=0.26506078243255615
[15/24] Train loss=0.2887497544288635
[20/24] Train loss=0.23521621525287628
Test set avg_accuracy=82.34% avg_sensitivity=39.64%, avg_specificity=98.25% avg_auc=88.83%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.269389 Test loss=0.423829 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2588559687137604
[5/24] Train loss=0.2649134397506714
[10/24] Train loss=0.2692837417125702
[15/24] Train loss=0.2824987471103668
[20/24] Train loss=0.23479440808296204
Test set avg_accuracy=81.26% avg_sensitivity=33.97%, avg_specificity=98.87% avg_auc=87.06%
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.264814 Test loss=0.465936 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2557118237018585
[5/24] Train loss=0.24975822865962982
[10/24] Train loss=0.26247724890708923
[15/24] Train loss=0.27499860525131226
[20/24] Train loss=0.23452508449554443
Test set avg_accuracy=78.70% avg_sensitivity=23.75%, avg_specificity=99.16% avg_auc=86.95%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.259328 Test loss=0.500478 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2502628564834595
[5/24] Train loss=0.25491344928741455
[10/24] Train loss=0.25466227531433105
[15/24] Train loss=0.27785393595695496
[20/24] Train loss=0.22834725677967072
Test set avg_accuracy=81.13% avg_sensitivity=33.59%, avg_specificity=98.84% avg_auc=87.35%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.253553 Test loss=0.450225 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.25235339999198914
[5/24] Train loss=0.2512311637401581
[10/24] Train loss=0.2541176378726959
[15/24] Train loss=0.27000632882118225
[20/24] Train loss=0.22892704606056213
Test set avg_accuracy=82.99% avg_sensitivity=42.56%, avg_specificity=98.05% avg_auc=89.19%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.257996 Test loss=0.402070 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2473480999469757
[5/24] Train loss=0.2306826412677765
[10/24] Train loss=0.2614888846874237
[15/24] Train loss=0.2553187906742096
[20/24] Train loss=0.23757091164588928
Test set avg_accuracy=86.74% avg_sensitivity=62.33%, avg_specificity=95.84% avg_auc=91.39%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.252525 Test loss=0.325964 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.24775533378124237
[5/24] Train loss=0.22788839042186737
[10/24] Train loss=0.252958744764328
[15/24] Train loss=0.2576124370098114
[20/24] Train loss=0.21695879101753235
Test set avg_accuracy=85.55% avg_sensitivity=55.81%, avg_specificity=96.62% avg_auc=90.55%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.243390 Test loss=0.345083 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2249027043581009
[5/24] Train loss=0.21317076683044434
[10/24] Train loss=0.22963722050189972
[15/24] Train loss=0.2601550221443176
[20/24] Train loss=0.2315794676542282
Test set avg_accuracy=75.78% avg_sensitivity=11.04%, avg_specificity=99.89% avg_auc=83.95%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.238966 Test loss=0.578615 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.241360604763031
[5/24] Train loss=0.2180670201778412
[10/24] Train loss=0.24736759066581726
[15/24] Train loss=0.2441641092300415
[20/24] Train loss=0.21770618855953217
Test set avg_accuracy=84.27% avg_sensitivity=56.86%, avg_specificity=94.48% avg_auc=89.69%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.242146 Test loss=0.359061 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.23051394522190094
[5/24] Train loss=0.22592008113861084
[10/24] Train loss=0.23958851397037506
[15/24] Train loss=0.24889886379241943
[20/24] Train loss=0.2060248851776123
Test set avg_accuracy=84.54% avg_sensitivity=55.57%, avg_specificity=95.34% avg_auc=87.88%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.233945 Test loss=0.368950 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.23264920711517334
[5/24] Train loss=0.21764720976352692
[10/24] Train loss=0.23428231477737427
[15/24] Train loss=0.2396967113018036
[20/24] Train loss=0.2153913825750351
Test set avg_accuracy=75.07% avg_sensitivity=8.73%, avg_specificity=99.77% avg_auc=79.51%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.232245 Test loss=0.711506 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2308271825313568
[5/24] Train loss=0.23536168038845062
[10/24] Train loss=0.23145641386508942
[15/24] Train loss=0.23709851503372192
[20/24] Train loss=0.20419302582740784
Test set avg_accuracy=80.89% avg_sensitivity=33.64%, avg_specificity=98.48% avg_auc=83.96%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.228393 Test loss=0.512706 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.20939767360687256
[5/24] Train loss=0.22017665207386017
[10/24] Train loss=0.22191490232944489
[15/24] Train loss=0.2315811812877655
[20/24] Train loss=0.19538171589374542
Test set avg_accuracy=77.71% avg_sensitivity=18.71%, avg_specificity=99.68% avg_auc=82.47%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.223343 Test loss=0.617565 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.23174938559532166
[5/24] Train loss=0.2185155749320984
[10/24] Train loss=0.2212718278169632
[15/24] Train loss=0.22921700775623322
[20/24] Train loss=0.20119889080524445
Test set avg_accuracy=83.57% avg_sensitivity=49.23%, avg_specificity=96.35% avg_auc=87.76%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.229466 Test loss=0.394165 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2001204639673233
[5/24] Train loss=0.21384486556053162
[10/24] Train loss=0.21642479300498962
[15/24] Train loss=0.2362002432346344
[20/24] Train loss=0.20681321620941162
Test set avg_accuracy=77.12% avg_sensitivity=17.23%, avg_specificity=99.43% avg_auc=82.28%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.225633 Test loss=0.582192 Current lr=[0.00029967723776099]

[0/24] Train loss=0.21892386674880981
[5/24] Train loss=0.213792085647583
[10/24] Train loss=0.22144170105457306
[15/24] Train loss=0.2266760915517807
[20/24] Train loss=0.1899745613336563
Test set avg_accuracy=78.82% avg_sensitivity=24.47%, avg_specificity=99.05% avg_auc=81.55%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.221459 Test loss=0.575193 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.205305814743042
[5/24] Train loss=0.21228937804698944
[10/24] Train loss=0.21009770035743713
[15/24] Train loss=0.21838237345218658
[20/24] Train loss=0.2037927359342575
Test set avg_accuracy=82.04% avg_sensitivity=36.52%, avg_specificity=99.00% avg_auc=86.18%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.220058 Test loss=0.463328 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.22457265853881836
[5/24] Train loss=0.20216728746891022
[10/24] Train loss=0.22613421082496643
[15/24] Train loss=0.21843600273132324
[20/24] Train loss=0.1919214278459549
Test set avg_accuracy=82.11% avg_sensitivity=43.04%, avg_specificity=96.66% avg_auc=85.22%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.219622 Test loss=0.428902 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2035568356513977
[5/24] Train loss=0.20028312504291534
[10/24] Train loss=0.20900657773017883
[15/24] Train loss=0.22835424542427063
[20/24] Train loss=0.20192910730838776
Test set avg_accuracy=78.74% avg_sensitivity=25.82%, avg_specificity=98.45% avg_auc=81.79%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.217392 Test loss=0.489729 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.20081974565982819
[5/24] Train loss=0.19827285408973694
[10/24] Train loss=0.20628631114959717
[15/24] Train loss=0.21556179225444794
[20/24] Train loss=0.1994192898273468
Test set avg_accuracy=84.38% avg_sensitivity=53.31%, avg_specificity=95.94% avg_auc=87.86%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.215197 Test loss=0.380443 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2079651951789856
[5/24] Train loss=0.20085908472537994
[10/24] Train loss=0.2046956717967987
[15/24] Train loss=0.2037450224161148
[20/24] Train loss=0.18646825850009918
Test set avg_accuracy=80.05% avg_sensitivity=29.56%, avg_specificity=98.86% avg_auc=84.80%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.213677 Test loss=0.541322 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.20772536098957062
[5/24] Train loss=0.2121318131685257
[10/24] Train loss=0.20990458130836487
[15/24] Train loss=0.22642375528812408
[20/24] Train loss=0.19251583516597748
Test set avg_accuracy=84.08% avg_sensitivity=50.82%, avg_specificity=96.46% avg_auc=85.24%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.214678 Test loss=0.422371 Current lr=[0.000297555943323901]

[0/24] Train loss=0.19488248229026794
[5/24] Train loss=0.20858219265937805
[10/24] Train loss=0.2065480351448059
[15/24] Train loss=0.21591560542583466
[20/24] Train loss=0.19722099602222443
Test set avg_accuracy=85.18% avg_sensitivity=54.32%, avg_specificity=96.68% avg_auc=89.67%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.216012 Test loss=0.372791 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2007722705602646
[5/24] Train loss=0.18858633935451508
[10/24] Train loss=0.20623528957366943
[15/24] Train loss=0.2071290761232376
[20/24] Train loss=0.1812335103750229
Test set avg_accuracy=83.15% avg_sensitivity=48.27%, avg_specificity=96.14% avg_auc=86.43%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.205075 Test loss=0.446608 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.18155257403850555
[5/24] Train loss=0.20289403200149536
[10/24] Train loss=0.20606639981269836
[15/24] Train loss=0.20194675028324127
[20/24] Train loss=0.18264570832252502
Test set avg_accuracy=82.63% avg_sensitivity=40.98%, avg_specificity=98.14% avg_auc=87.36%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.204660 Test loss=0.436148 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.19113945960998535
[5/24] Train loss=0.19450172781944275
[10/24] Train loss=0.20399050414562225
[15/24] Train loss=0.20595620572566986
[20/24] Train loss=0.18951745331287384
Test set avg_accuracy=85.26% avg_sensitivity=58.21%, avg_specificity=95.34% avg_auc=88.89%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.205531 Test loss=0.372298 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.1941898763179779
[5/24] Train loss=0.1891428828239441
[10/24] Train loss=0.20089055597782135
[15/24] Train loss=0.18976585566997528
[20/24] Train loss=0.17610573768615723
Test set avg_accuracy=86.90% avg_sensitivity=69.29%, avg_specificity=93.46% avg_auc=91.79%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.200526 Test loss=0.318129 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.1899295300245285
[5/24] Train loss=0.19549143314361572
[10/24] Train loss=0.1928759068250656
[15/24] Train loss=0.2093203067779541
[20/24] Train loss=0.17482812702655792
Test set avg_accuracy=85.00% avg_sensitivity=59.21%, avg_specificity=94.60% avg_auc=88.57%
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.199448 Test loss=0.380353 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.1755463033914566
[5/24] Train loss=0.18681909143924713
[10/24] Train loss=0.2074340581893921
[15/24] Train loss=0.19015096127986908
[20/24] Train loss=0.1771448403596878
Test set avg_accuracy=86.80% avg_sensitivity=72.41%, avg_specificity=92.16% avg_auc=91.78%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.199334 Test loss=0.324343 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.19084715843200684
[5/24] Train loss=0.1903424710035324
[10/24] Train loss=0.19095218181610107
[15/24] Train loss=0.18901465833187103
[20/24] Train loss=0.17997044324874878
Test set avg_accuracy=84.06% avg_sensitivity=83.78%, avg_specificity=84.17% avg_auc=91.12%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.192794 Test loss=0.381330 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.17849881947040558
[5/24] Train loss=0.18495169281959534
[10/24] Train loss=0.18878231942653656
[15/24] Train loss=0.1849842220544815
[20/24] Train loss=0.1779252588748932
Test set avg_accuracy=86.12% avg_sensitivity=68.14%, avg_specificity=92.82% avg_auc=90.18%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.194352 Test loss=0.340811 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.1818002611398697
[5/24] Train loss=0.1783370077610016
[10/24] Train loss=0.19130481779575348
[15/24] Train loss=0.18991559743881226
[20/24] Train loss=0.1814454197883606
Test set avg_accuracy=85.52% avg_sensitivity=81.05%, avg_specificity=87.19% avg_auc=92.31%
Best model saved!! Metric=20.059868276033015!!
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.190716 Test loss=0.340893 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.1756829023361206
[5/24] Train loss=0.1792140156030655
[10/24] Train loss=0.19130386412143707
[15/24] Train loss=0.18401984870433807
[20/24] Train loss=0.17134228348731995
Test set avg_accuracy=85.90% avg_sensitivity=82.05%, avg_specificity=87.33% avg_auc=92.01%
Best model saved!! Metric=21.295150809067763!!
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.189801 Test loss=0.344305 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.16446705162525177
[5/24] Train loss=0.18539009988307953
[10/24] Train loss=0.20194527506828308
[15/24] Train loss=0.1869218945503235
[20/24] Train loss=0.17440955340862274
Test set avg_accuracy=87.55% avg_sensitivity=77.88%, avg_specificity=91.15% avg_auc=92.38%
Best model saved!! Metric=22.96394404683997!!
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.189277 Test loss=0.316079 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.17544616758823395
[5/24] Train loss=0.18366260826587677
[10/24] Train loss=0.19645504653453827
[15/24] Train loss=0.18148885667324066
[20/24] Train loss=0.17903617024421692
Test set avg_accuracy=82.70% avg_sensitivity=77.35%, avg_specificity=84.69% avg_auc=89.56%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.189877 Test loss=0.398587 Current lr=[0.000276307469034998]

[0/24] Train loss=0.16934014856815338
[5/24] Train loss=0.17912118136882782
[10/24] Train loss=0.1957215666770935
[15/24] Train loss=0.18681637942790985
[20/24] Train loss=0.18179449439048767
Test set avg_accuracy=85.94% avg_sensitivity=80.57%, avg_specificity=87.94% avg_auc=92.29%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.193100 Test loss=0.329237 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.17370633780956268
[5/24] Train loss=0.1828155666589737
[10/24] Train loss=0.18180222809314728
[15/24] Train loss=0.1750066578388214
[20/24] Train loss=0.17408590018749237
Test set avg_accuracy=80.51% avg_sensitivity=84.17%, avg_specificity=79.15% avg_auc=90.02%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.187284 Test loss=0.434480 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.17711172997951508
[5/24] Train loss=0.17811372876167297
[10/24] Train loss=0.17938020825386047
[15/24] Train loss=0.18644516170024872
[20/24] Train loss=0.16696172952651978
Test set avg_accuracy=82.79% avg_sensitivity=82.34%, avg_specificity=82.95% avg_auc=90.68%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.188109 Test loss=0.396199 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.17882515490055084
[5/24] Train loss=0.1718544065952301
[10/24] Train loss=0.170454204082489
[15/24] Train loss=0.1652621030807495
[20/24] Train loss=0.1610478311777115
Test set avg_accuracy=87.73% avg_sensitivity=74.57%, avg_specificity=92.64% avg_auc=91.89%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.182569 Test loss=0.310041 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.16310985386371613
[5/24] Train loss=0.16621752083301544
[10/24] Train loss=0.17680369317531586
[15/24] Train loss=0.17059746384620667
[20/24] Train loss=0.17230384051799774
Test set avg_accuracy=86.61% avg_sensitivity=63.77%, avg_specificity=95.12% avg_auc=91.13%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.180461 Test loss=0.334797 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.17274975776672363
[5/24] Train loss=0.16931286454200745
[10/24] Train loss=0.19147075712680817
[15/24] Train loss=0.17582149803638458
[20/24] Train loss=0.15509149432182312
Test set avg_accuracy=87.08% avg_sensitivity=75.29%, avg_specificity=91.48% avg_auc=92.10%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.181680 Test loss=0.312533 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.16668559610843658
[5/24] Train loss=0.15961018204689026
[10/24] Train loss=0.17395801842212677
[15/24] Train loss=0.1815497726202011
[20/24] Train loss=0.16918429732322693
Test set avg_accuracy=86.91% avg_sensitivity=75.82%, avg_specificity=91.05% avg_auc=91.66%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.181404 Test loss=0.323372 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.1665722280740738
[5/24] Train loss=0.16982021927833557
[10/24] Train loss=0.18358027935028076
[15/24] Train loss=0.17776741087436676
[20/24] Train loss=0.15922203660011292
Test set avg_accuracy=86.42% avg_sensitivity=74.52%, avg_specificity=90.85% avg_auc=91.55%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.182112 Test loss=0.332205 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.16091834008693695
[5/24] Train loss=0.1699136197566986
[10/24] Train loss=0.18233121931552887
[15/24] Train loss=0.1691216081380844
[20/24] Train loss=0.16475869715213776
Test set avg_accuracy=87.41% avg_sensitivity=71.11%, avg_specificity=93.48% avg_auc=92.19%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.177020 Test loss=0.307953 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.15887229144573212
[5/24] Train loss=0.1729753017425537
[10/24] Train loss=0.17061252892017365
[15/24] Train loss=0.17153842747211456
[20/24] Train loss=0.15725736320018768
Test set avg_accuracy=79.67% avg_sensitivity=88.34%, avg_specificity=76.45% avg_auc=90.77%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.175565 Test loss=0.444551 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.16702811419963837
[5/24] Train loss=0.16433875262737274
[10/24] Train loss=0.1690356284379959
[15/24] Train loss=0.17241819202899933
[20/24] Train loss=0.15922881662845612
Test set avg_accuracy=84.83% avg_sensitivity=55.61%, avg_specificity=95.71% avg_auc=87.99%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.176561 Test loss=0.397371 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.16213960945606232
[5/24] Train loss=0.16281656920909882
[10/24] Train loss=0.16988135874271393
[15/24] Train loss=0.1797885298728943
[20/24] Train loss=0.15612593293190002
Test set avg_accuracy=85.62% avg_sensitivity=76.82%, avg_specificity=88.90% avg_auc=91.48%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.177739 Test loss=0.339370 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.15965397655963898
[5/24] Train loss=0.17040729522705078
[10/24] Train loss=0.16890457272529602
[15/24] Train loss=0.16580165922641754
[20/24] Train loss=0.1641797125339508
Test set avg_accuracy=86.12% avg_sensitivity=66.46%, avg_specificity=93.44% avg_auc=90.04%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.171360 Test loss=0.342534 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.15704356133937836
[5/24] Train loss=0.16283440589904785
[10/24] Train loss=0.17257674038410187
[15/24] Train loss=0.16855904459953308
[20/24] Train loss=0.1571549028158188
Test set avg_accuracy=86.80% avg_sensitivity=70.97%, avg_specificity=92.69% avg_auc=91.01%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.175789 Test loss=0.329065 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.16262444853782654
[5/24] Train loss=0.16863994300365448
[10/24] Train loss=0.16549232602119446
[15/24] Train loss=0.18771260976791382
[20/24] Train loss=0.16363921761512756
Test set avg_accuracy=84.93% avg_sensitivity=56.91%, avg_specificity=95.37% avg_auc=88.26%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.175391 Test loss=0.371599 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.16794617474079132
[5/24] Train loss=0.16110660135746002
[10/24] Train loss=0.16821248829364777
[15/24] Train loss=0.16116280853748322
[20/24] Train loss=0.1575004756450653
Test set avg_accuracy=81.47% avg_sensitivity=36.61%, avg_specificity=98.18% avg_auc=83.08%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.171910 Test loss=0.514566 Current lr=[0.000224838296036774]

[0/24] Train loss=0.1695648431777954
[5/24] Train loss=0.1634569615125656
[10/24] Train loss=0.15850770473480225
[15/24] Train loss=0.16257210075855255
[20/24] Train loss=0.1557818204164505
Test set avg_accuracy=86.05% avg_sensitivity=63.29%, avg_specificity=94.53% avg_auc=90.12%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.169556 Test loss=0.346039 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.16240590810775757
[5/24] Train loss=0.16626828908920288
[10/24] Train loss=0.16184289753437042
[15/24] Train loss=0.1619490683078766
[20/24] Train loss=0.1538878232240677
Test set avg_accuracy=87.20% avg_sensitivity=67.37%, avg_specificity=94.59% avg_auc=90.41%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.171317 Test loss=0.341297 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.15712083876132965
[5/24] Train loss=0.1695311963558197
[10/24] Train loss=0.15968261659145355
[15/24] Train loss=0.1631043553352356
[20/24] Train loss=0.16180212795734406
Test set avg_accuracy=86.74% avg_sensitivity=67.85%, avg_specificity=93.78% avg_auc=90.29%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.168151 Test loss=0.336249 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.15446822345256805
[5/24] Train loss=0.15716418623924255
[10/24] Train loss=0.15889190137386322
[15/24] Train loss=0.1570129096508026
[20/24] Train loss=0.15100879967212677
Test set avg_accuracy=86.18% avg_sensitivity=74.04%, avg_specificity=90.71% avg_auc=90.40%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.166513 Test loss=0.341647 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.14791330695152283
[5/24] Train loss=0.1558430939912796
[10/24] Train loss=0.1617807000875473
[15/24] Train loss=0.15532808005809784
[20/24] Train loss=0.15126372873783112
Test set avg_accuracy=86.97% avg_sensitivity=79.56%, avg_specificity=89.72% avg_auc=91.59%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.165558 Test loss=0.330329 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.1475147008895874
[5/24] Train loss=0.15291132032871246
[10/24] Train loss=0.16756685078144073
[15/24] Train loss=0.15802784264087677
[20/24] Train loss=0.15507419407367706
Test set avg_accuracy=86.18% avg_sensitivity=62.28%, avg_specificity=95.09% avg_auc=87.99%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.164915 Test loss=0.373748 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.15565915405750275
[5/24] Train loss=0.15660855174064636
[10/24] Train loss=0.17073507606983185
[15/24] Train loss=0.17447389662265778
[20/24] Train loss=0.1569957435131073
Test set avg_accuracy=84.17% avg_sensitivity=48.42%, avg_specificity=97.48% avg_auc=86.90%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.164597 Test loss=0.431283 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.15992432832717896
[5/24] Train loss=0.15797041356563568
[10/24] Train loss=0.15291747450828552
[15/24] Train loss=0.16264405846595764
[20/24] Train loss=0.1560797393321991
Test set avg_accuracy=84.27% avg_sensitivity=50.14%, avg_specificity=96.98% avg_auc=86.07%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.165976 Test loss=0.435848 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.15042947232723236
[5/24] Train loss=0.15278413891792297
[10/24] Train loss=0.14951996505260468
[15/24] Train loss=0.15449722111225128
[20/24] Train loss=0.1481885015964508
Test set avg_accuracy=84.91% avg_sensitivity=52.54%, avg_specificity=96.96% avg_auc=86.38%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.161783 Test loss=0.412412 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.16017870604991913
[5/24] Train loss=0.1510433405637741
[10/24] Train loss=0.15639597177505493
[15/24] Train loss=0.16171973943710327
[20/24] Train loss=0.14698483049869537
Test set avg_accuracy=84.35% avg_sensitivity=62.52%, avg_specificity=92.48% avg_auc=87.85%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.163887 Test loss=0.377059 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.16048501431941986
[5/24] Train loss=0.1560768485069275
[10/24] Train loss=0.15990468859672546
[15/24] Train loss=0.16273318231105804
[20/24] Train loss=0.15309733152389526
Test set avg_accuracy=83.59% avg_sensitivity=47.79%, avg_specificity=96.93% avg_auc=86.19%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.162524 Test loss=0.425727 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.15575601160526276
[5/24] Train loss=0.1638689786195755
[10/24] Train loss=0.15810003876686096
[15/24] Train loss=0.1558576375246048
[20/24] Train loss=0.1466914266347885
Test set avg_accuracy=82.64% avg_sensitivity=41.94%, avg_specificity=97.80% avg_auc=85.63%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.162636 Test loss=0.482914 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1521083265542984
[5/24] Train loss=0.16908201575279236
[10/24] Train loss=0.15462914109230042
[15/24] Train loss=0.16171687841415405
[20/24] Train loss=0.1441371738910675
Test set avg_accuracy=85.16% avg_sensitivity=56.43%, avg_specificity=95.85% avg_auc=88.25%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.160645 Test loss=0.394919 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15075525641441345
[5/24] Train loss=0.16349495947360992
[10/24] Train loss=0.14938463270664215
[15/24] Train loss=0.15160371363162994
[20/24] Train loss=0.15782687067985535
Test set avg_accuracy=87.59% avg_sensitivity=74.57%, avg_specificity=92.44% avg_auc=91.33%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.160307 Test loss=0.321865 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.14699341356754303
[5/24] Train loss=0.15555809438228607
[10/24] Train loss=0.14334063231945038
[15/24] Train loss=0.15458925068378448
[20/24] Train loss=0.15126647055149078
Test set avg_accuracy=87.15% avg_sensitivity=69.53%, avg_specificity=93.71% avg_auc=90.45%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.157050 Test loss=0.335542 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.14621876180171967
[5/24] Train loss=0.148079052567482
[10/24] Train loss=0.1507493257522583
[15/24] Train loss=0.1451357752084732
[20/24] Train loss=0.14551380276679993
Test set avg_accuracy=82.45% avg_sensitivity=42.85%, avg_specificity=97.19% avg_auc=84.08%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.157538 Test loss=0.495925 Current lr=[0.000156543481933168]

[0/24] Train loss=0.1517602652311325
[5/24] Train loss=0.15391120314598083
[10/24] Train loss=0.14767391979694366
[15/24] Train loss=0.1515953093767166
[20/24] Train loss=0.1467251479625702
Test set avg_accuracy=86.71% avg_sensitivity=68.38%, avg_specificity=93.53% avg_auc=89.50%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.157687 Test loss=0.352649 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.14610034227371216
[5/24] Train loss=0.14989791810512543
[10/24] Train loss=0.15039239823818207
[15/24] Train loss=0.15146209299564362
[20/24] Train loss=0.1556951105594635
Test set avg_accuracy=86.99% avg_sensitivity=65.07%, avg_specificity=95.16% avg_auc=89.75%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.156699 Test loss=0.345260 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.14487183094024658
[5/24] Train loss=0.15560898184776306
[10/24] Train loss=0.15336300432682037
[15/24] Train loss=0.15614083409309387
[20/24] Train loss=0.14698122441768646
Test set avg_accuracy=86.85% avg_sensitivity=64.20%, avg_specificity=95.28% avg_auc=90.65%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.155567 Test loss=0.336133 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.1437721848487854
[5/24] Train loss=0.1547241061925888
[10/24] Train loss=0.15483234822750092
[15/24] Train loss=0.14456304907798767
[20/24] Train loss=0.140803724527359
Test set avg_accuracy=84.21% avg_sensitivity=52.30%, avg_specificity=96.09% avg_auc=87.78%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.154887 Test loss=0.406899 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.14512784779071808
[5/24] Train loss=0.14763876795768738
[10/24] Train loss=0.14380104839801788
[15/24] Train loss=0.14357014000415802
[20/24] Train loss=0.14683200418949127
Test set avg_accuracy=83.92% avg_sensitivity=50.34%, avg_specificity=96.43% avg_auc=85.07%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.153523 Test loss=0.449145 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15425029397010803
[5/24] Train loss=0.14646883308887482
[10/24] Train loss=0.14243754744529724
[15/24] Train loss=0.14291535317897797
[20/24] Train loss=0.1432477980852127
Test set avg_accuracy=80.82% avg_sensitivity=33.06%, avg_specificity=98.61% avg_auc=80.26%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.151788 Test loss=0.551998 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.14703518152236938
[5/24] Train loss=0.1466044783592224
[10/24] Train loss=0.14522363245487213
[15/24] Train loss=0.1452743113040924
[20/24] Train loss=0.1427554041147232
Test set avg_accuracy=86.88% avg_sensitivity=68.86%, avg_specificity=93.58% avg_auc=89.83%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.153432 Test loss=0.341374 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1473313719034195
[5/24] Train loss=0.15016525983810425
[10/24] Train loss=0.14033344388008118
[15/24] Train loss=0.14241856336593628
[20/24] Train loss=0.1424630582332611
Test set avg_accuracy=84.64% avg_sensitivity=56.91%, avg_specificity=94.96% avg_auc=88.79%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.152247 Test loss=0.375376 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.13890735805034637
[5/24] Train loss=0.14987125992774963
[10/24] Train loss=0.14883534610271454
[15/24] Train loss=0.14712171256542206
[20/24] Train loss=0.14271926879882812
Test set avg_accuracy=86.12% avg_sensitivity=62.38%, avg_specificity=94.96% avg_auc=89.83%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.151367 Test loss=0.354778 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14313775300979614
[5/24] Train loss=0.15069077908992767
[10/24] Train loss=0.14306949079036713
[15/24] Train loss=0.14260223507881165
[20/24] Train loss=0.1400337815284729
Test set avg_accuracy=86.45% avg_sensitivity=67.56%, avg_specificity=93.48% avg_auc=89.41%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.151027 Test loss=0.351327 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1420336812734604
[5/24] Train loss=0.14507867395877838
[10/24] Train loss=0.14968907833099365
[15/24] Train loss=0.14498861134052277
[20/24] Train loss=0.13756494224071503
Test set avg_accuracy=87.25% avg_sensitivity=76.97%, avg_specificity=91.08% avg_auc=91.83%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.149969 Test loss=0.323858 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1478864699602127
[5/24] Train loss=0.1485024094581604
[10/24] Train loss=0.14087417721748352
[15/24] Train loss=0.13940173387527466
[20/24] Train loss=0.14377722144126892
Test set avg_accuracy=86.90% avg_sensitivity=67.03%, avg_specificity=94.30% avg_auc=91.31%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.148535 Test loss=0.332128 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.13804160058498383
[5/24] Train loss=0.14608603715896606
[10/24] Train loss=0.1368284821510315
[15/24] Train loss=0.1419038623571396
[20/24] Train loss=0.13679945468902588
Test set avg_accuracy=87.15% avg_sensitivity=68.57%, avg_specificity=94.07% avg_auc=90.53%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.146157 Test loss=0.336360 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14253534376621246
[5/24] Train loss=0.14069393277168274
[10/24] Train loss=0.13853280246257782
[15/24] Train loss=0.1357806771993637
[20/24] Train loss=0.14517700672149658
Test set avg_accuracy=85.01% avg_sensitivity=56.14%, avg_specificity=95.76% avg_auc=88.84%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.146657 Test loss=0.375158 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.13817918300628662
[5/24] Train loss=0.1355535238981247
[10/24] Train loss=0.13790282607078552
[15/24] Train loss=0.1411074995994568
[20/24] Train loss=0.13613007962703705
Test set avg_accuracy=86.91% avg_sensitivity=69.43%, avg_specificity=93.42% avg_auc=91.72%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.146834 Test loss=0.323578 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.13885635137557983
[5/24] Train loss=0.14253626763820648
[10/24] Train loss=0.13956598937511444
[15/24] Train loss=0.13931243121623993
[20/24] Train loss=0.13656486570835114
Test set avg_accuracy=86.86% avg_sensitivity=73.22%, avg_specificity=91.94% avg_auc=91.74%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.144581 Test loss=0.326702 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1369106024503708
[5/24] Train loss=0.13620232045650482
[10/24] Train loss=0.1365053355693817
[15/24] Train loss=0.13925157487392426
[20/24] Train loss=0.13588568568229675
Test set avg_accuracy=86.84% avg_sensitivity=79.08%, avg_specificity=89.72% avg_auc=92.10%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.143388 Test loss=0.325374 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14149361848831177
[5/24] Train loss=0.13668519258499146
[10/24] Train loss=0.13231340050697327
[15/24] Train loss=0.13579848408699036
[20/24] Train loss=0.1394886076450348
Test set avg_accuracy=86.13% avg_sensitivity=69.10%, avg_specificity=92.48% avg_auc=90.85%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.143103 Test loss=0.338828 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13653521239757538
[5/24] Train loss=0.13480660319328308
[10/24] Train loss=0.1336193084716797
[15/24] Train loss=0.1311790496110916
[20/24] Train loss=0.1345488578081131
Test set avg_accuracy=86.78% avg_sensitivity=73.13%, avg_specificity=91.87% avg_auc=91.20%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.141072 Test loss=0.333846 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13122281432151794
[5/24] Train loss=0.1300843507051468
[10/24] Train loss=0.1304413378238678
[15/24] Train loss=0.13092640042304993
[20/24] Train loss=0.1409997045993805
Test set avg_accuracy=87.01% avg_sensitivity=78.26%, avg_specificity=90.26% avg_auc=91.28%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.140074 Test loss=0.334117 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13690342009067535
[5/24] Train loss=0.13641034066677094
[10/24] Train loss=0.1368955820798874
[15/24] Train loss=0.13374800980091095
[20/24] Train loss=0.13705940544605255
Test set avg_accuracy=87.17% avg_sensitivity=75.53%, avg_specificity=91.51% avg_auc=91.73%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.141465 Test loss=0.325792 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.13211634755134583
[5/24] Train loss=0.1346629559993744
[10/24] Train loss=0.12978194653987885
[15/24] Train loss=0.13485929369926453
[20/24] Train loss=0.1357969045639038
Test set avg_accuracy=87.17% avg_sensitivity=78.12%, avg_specificity=90.55% avg_auc=92.04%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.139102 Test loss=0.321655 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13333474099636078
[5/24] Train loss=0.12954671680927277
[10/24] Train loss=0.13114987313747406
[15/24] Train loss=0.128619983792305
[20/24] Train loss=0.13468094170093536
Test set avg_accuracy=87.21% avg_sensitivity=74.38%, avg_specificity=91.99% avg_auc=92.22%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.138195 Test loss=0.316232 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1348785161972046
[5/24] Train loss=0.130320742726326
[10/24] Train loss=0.12580008804798126
[15/24] Train loss=0.13314634561538696
[20/24] Train loss=0.13037854433059692
Test set avg_accuracy=87.12% avg_sensitivity=79.51%, avg_specificity=89.96% avg_auc=91.94%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.136857 Test loss=0.328678 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13386689126491547
[5/24] Train loss=0.13242843747138977
[10/24] Train loss=0.1269083023071289
[15/24] Train loss=0.12929116189479828
[20/24] Train loss=0.12989406287670135
Test set avg_accuracy=87.92% avg_sensitivity=73.66%, avg_specificity=93.23% avg_auc=91.27%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.136998 Test loss=0.322735 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1288835108280182
[5/24] Train loss=0.13092394173145294
[10/24] Train loss=0.1276896744966507
[15/24] Train loss=0.12664026021957397
[20/24] Train loss=0.13011574745178223
Test set avg_accuracy=87.36% avg_sensitivity=74.57%, avg_specificity=92.12% avg_auc=91.62%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.134841 Test loss=0.324933 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.12534168362617493
[5/24] Train loss=0.12913107872009277
[10/24] Train loss=0.12518852949142456
[15/24] Train loss=0.12371166050434113
[20/24] Train loss=0.13070416450500488
Test set avg_accuracy=87.79% avg_sensitivity=73.03%, avg_specificity=93.28% avg_auc=91.69%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.133946 Test loss=0.320426 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1321982592344284
[5/24] Train loss=0.1291678249835968
[10/24] Train loss=0.12374714016914368
[15/24] Train loss=0.1242770105600357
[20/24] Train loss=0.12528002262115479
Test set avg_accuracy=87.58% avg_sensitivity=73.46%, avg_specificity=92.83% avg_auc=90.84%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.131908 Test loss=0.329304 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12798956036567688
[5/24] Train loss=0.13100594282150269
[10/24] Train loss=0.1246849000453949
[15/24] Train loss=0.12810856103897095
[20/24] Train loss=0.1275377869606018
Test set avg_accuracy=87.12% avg_sensitivity=75.14%, avg_specificity=91.58% avg_auc=90.90%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.132778 Test loss=0.332975 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13174240291118622
[5/24] Train loss=0.1296587586402893
[10/24] Train loss=0.12283746153116226
[15/24] Train loss=0.12441273033618927
[20/24] Train loss=0.1252215951681137
Test set avg_accuracy=87.28% avg_sensitivity=69.96%, avg_specificity=93.73% avg_auc=90.22%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.131995 Test loss=0.336427 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12857119739055634
[5/24] Train loss=0.13002580404281616
[10/24] Train loss=0.12166611850261688
[15/24] Train loss=0.12673287093639374
[20/24] Train loss=0.1255759298801422
Test set avg_accuracy=87.72% avg_sensitivity=73.85%, avg_specificity=92.89% avg_auc=91.39%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.131115 Test loss=0.321478 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12645523250102997
[5/24] Train loss=0.1278313845396042
[10/24] Train loss=0.12446262687444687
[15/24] Train loss=0.12442535907030106
[20/24] Train loss=0.12275911867618561
Test set avg_accuracy=87.46% avg_sensitivity=74.62%, avg_specificity=92.24% avg_auc=90.98%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.130569 Test loss=0.328264 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12521500885486603
[5/24] Train loss=0.12642104923725128
[10/24] Train loss=0.12131139636039734
[15/24] Train loss=0.12412386387586594
[20/24] Train loss=0.12682154774665833
Test set avg_accuracy=87.71% avg_sensitivity=72.22%, avg_specificity=93.48% avg_auc=91.08%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.129812 Test loss=0.326401 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12591198086738586
[5/24] Train loss=0.1261281818151474
[10/24] Train loss=0.12225205451250076
[15/24] Train loss=0.12559911608695984
[20/24] Train loss=0.12216915935277939
Test set avg_accuracy=87.94% avg_sensitivity=75.91%, avg_specificity=92.42% avg_auc=91.20%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.130211 Test loss=0.324244 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12756268680095673
[5/24] Train loss=0.12717515230178833
[10/24] Train loss=0.12238609790802002
[15/24] Train loss=0.12166934460401535
[20/24] Train loss=0.12449538707733154
Test set avg_accuracy=87.84% avg_sensitivity=71.16%, avg_specificity=94.05% avg_auc=90.99%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.130241 Test loss=0.325849 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12377889454364777
[5/24] Train loss=0.12425310164690018
[10/24] Train loss=0.12025441229343414
[15/24] Train loss=0.12494412064552307
[20/24] Train loss=0.12025117129087448
Test set avg_accuracy=87.80% avg_sensitivity=76.73%, avg_specificity=91.92% avg_auc=91.52%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.129235 Test loss=0.322138 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12181828171014786
[5/24] Train loss=0.12298840284347534
[10/24] Train loss=0.1253441572189331
[15/24] Train loss=0.1212727427482605
[20/24] Train loss=0.12132120877504349
Test set avg_accuracy=87.45% avg_sensitivity=75.05%, avg_specificity=92.07% avg_auc=91.30%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.128480 Test loss=0.325360 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12588471174240112
[5/24] Train loss=0.12471991032361984
[10/24] Train loss=0.11802928149700165
[15/24] Train loss=0.11953738331794739
[20/24] Train loss=0.12184391170740128
Test set avg_accuracy=87.72% avg_sensitivity=75.29%, avg_specificity=92.35% avg_auc=91.39%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.128631 Test loss=0.322962 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12221760302782059
[5/24] Train loss=0.12744258344173431
[10/24] Train loss=0.11744260042905807
[15/24] Train loss=0.12221060693264008
[20/24] Train loss=0.11992745101451874
Test set avg_accuracy=87.84% avg_sensitivity=75.19%, avg_specificity=92.55% avg_auc=91.52%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.127905 Test loss=0.320333 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1221340224146843
[5/24] Train loss=0.1222967654466629
[10/24] Train loss=0.11900483071804047
[15/24] Train loss=0.11792983114719391
[20/24] Train loss=0.12078365683555603
Test set avg_accuracy=87.85% avg_sensitivity=74.52%, avg_specificity=92.82% avg_auc=91.60%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.126670 Test loss=0.319379 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1228727400302887
[5/24] Train loss=0.12364918738603592
[10/24] Train loss=0.1202605664730072
[15/24] Train loss=0.12144242227077484
[20/24] Train loss=0.12015283107757568
Test set avg_accuracy=87.93% avg_sensitivity=74.81%, avg_specificity=92.82% avg_auc=91.30%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.126373 Test loss=0.321948 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.11942169815301895
[5/24] Train loss=0.12003064155578613
[10/24] Train loss=0.11863579601049423
[15/24] Train loss=0.12089104950428009
[20/24] Train loss=0.12070230394601822
Test set avg_accuracy=87.92% avg_sensitivity=74.52%, avg_specificity=92.91% avg_auc=91.26%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.126365 Test loss=0.322105 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12003263831138611
[5/24] Train loss=0.1239127442240715
[10/24] Train loss=0.1198723241686821
[15/24] Train loss=0.11645691841840744
[20/24] Train loss=0.119510717689991
Test set avg_accuracy=87.93% avg_sensitivity=74.90%, avg_specificity=92.78% avg_auc=91.53%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.125492 Test loss=0.321031 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12174312770366669
[5/24] Train loss=0.12054348737001419
[10/24] Train loss=0.1176527589559555
[15/24] Train loss=0.11941806972026825
[20/24] Train loss=0.12086675316095352
Test set avg_accuracy=87.84% avg_sensitivity=74.18%, avg_specificity=92.92% avg_auc=91.24%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.125460 Test loss=0.323221 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12094523757696152
[5/24] Train loss=0.12015802413225174
[10/24] Train loss=0.11978916078805923
[15/24] Train loss=0.11681724339723587
[20/24] Train loss=0.12005817145109177
Test set avg_accuracy=87.85% avg_sensitivity=74.66%, avg_specificity=92.76% avg_auc=91.26%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.125445 Test loss=0.323471 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12191201746463776
[5/24] Train loss=0.1241622045636177
[10/24] Train loss=0.11527812480926514
[15/24] Train loss=0.11870042979717255
[20/24] Train loss=0.12030167877674103
Test set avg_accuracy=87.86% avg_sensitivity=74.47%, avg_specificity=92.85% avg_auc=91.27%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.124892 Test loss=0.322877 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1226544976234436
[5/24] Train loss=0.12092961370944977
[10/24] Train loss=0.11737819015979767
[15/24] Train loss=0.11777568608522415
[20/24] Train loss=0.11966889351606369
Test set avg_accuracy=87.85% avg_sensitivity=74.09%, avg_specificity=92.98% avg_auc=91.27%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.124811 Test loss=0.323163 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12163350731134415
[5/24] Train loss=0.1198575422167778
[10/24] Train loss=0.12092547863721848
[15/24] Train loss=0.11665705591440201
[20/24] Train loss=0.11960112303495407
Test set avg_accuracy=87.93% avg_sensitivity=74.62%, avg_specificity=92.89% avg_auc=91.39%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.124460 Test loss=0.322224 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11713331937789917
[5/24] Train loss=0.11950037628412247
[10/24] Train loss=0.1169215589761734
[15/24] Train loss=0.12032847106456757
[20/24] Train loss=0.11992086470127106
Test set avg_accuracy=87.94% avg_sensitivity=74.42%, avg_specificity=92.98% avg_auc=91.36%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.124697 Test loss=0.322277 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11934194713830948
[5/24] Train loss=0.12033390998840332
[10/24] Train loss=0.1174391359090805
[15/24] Train loss=0.11836846172809601
[20/24] Train loss=0.11949677020311356
Test set avg_accuracy=88.03% avg_sensitivity=74.62%, avg_specificity=93.03% avg_auc=91.39%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.124023 Test loss=0.321387 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1221141517162323
[5/24] Train loss=0.12154446542263031
[10/24] Train loss=0.11700277030467987
[15/24] Train loss=0.11681247502565384
[20/24] Train loss=0.11892541497945786
Test set avg_accuracy=87.99% avg_sensitivity=74.62%, avg_specificity=92.98% avg_auc=91.38%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.124346 Test loss=0.321427 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11976316571235657
[5/24] Train loss=0.11998751014471054
[10/24] Train loss=0.11712459474802017
[15/24] Train loss=0.12021368741989136
[20/24] Train loss=0.12011650204658508
Test set avg_accuracy=87.97% avg_sensitivity=74.62%, avg_specificity=92.94% avg_auc=91.37%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.124456 Test loss=0.321397 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12145496159791946
[5/24] Train loss=0.12160101532936096
[10/24] Train loss=0.11612044274806976
[15/24] Train loss=0.11804881691932678
[20/24] Train loss=0.11911530792713165
Test set avg_accuracy=87.94% avg_sensitivity=74.57%, avg_specificity=92.92% avg_auc=91.39%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.124665 Test loss=0.321269 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12060436606407166
[5/24] Train loss=0.12295380979776382
[10/24] Train loss=0.11741889268159866
[15/24] Train loss=0.11837909370660782
[20/24] Train loss=0.11824948340654373
Test set avg_accuracy=87.97% avg_sensitivity=74.62%, avg_specificity=92.94% avg_auc=91.40%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.124639 Test loss=0.321225 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=87.55% sen=77.88%, spe=91.15%, auc=92.38%!
Fold[6] Avg_overlap=0.70%(±0.2292164169666806)
[0/24] Train loss=0.7350286245346069
[5/24] Train loss=0.7231033444404602
[10/24] Train loss=0.7155238389968872
[15/24] Train loss=0.6992093920707703
[20/24] Train loss=0.6994082927703857
Test set avg_accuracy=56.00% avg_sensitivity=44.55%, avg_specificity=60.37% avg_auc=56.31%
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.712328 Test loss=0.677076 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6946516633033752
[5/24] Train loss=0.6889232397079468
[10/24] Train loss=0.6901535391807556
[15/24] Train loss=0.6755264401435852
[20/24] Train loss=0.6700634360313416
Test set avg_accuracy=66.08% avg_sensitivity=58.04%, avg_specificity=69.15% avg_auc=69.66%
Best model saved!! Metric=-63.06956658914438!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.684649 Test loss=0.623973 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6660208702087402
[5/24] Train loss=0.6612448692321777
[10/24] Train loss=0.66872239112854
[15/24] Train loss=0.6470391154289246
[20/24] Train loss=0.6435259580612183
Test set avg_accuracy=69.14% avg_sensitivity=63.93%, avg_specificity=71.13% avg_auc=75.00%
Best model saved!! Metric=-46.795170676553255!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.658882 Test loss=0.593118 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6442751288414001
[5/24] Train loss=0.6338295936584473
[10/24] Train loss=0.6382408738136292
[15/24] Train loss=0.6228455901145935
[20/24] Train loss=0.6135227680206299
Test set avg_accuracy=71.47% avg_sensitivity=68.79%, avg_specificity=72.50% avg_auc=77.82%
Best model saved!! Metric=-35.425202839276764!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.634072 Test loss=0.567445 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6115880608558655
[5/24] Train loss=0.6145406365394592
[10/24] Train loss=0.6129400134086609
[15/24] Train loss=0.5939152240753174
[20/24] Train loss=0.5909215807914734
Test set avg_accuracy=74.22% avg_sensitivity=70.86%, avg_specificity=75.50% avg_auc=80.39%
Best model saved!! Metric=-25.03095258185327!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.610076 Test loss=0.537480 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5897133350372314
[5/24] Train loss=0.5885769724845886
[10/24] Train loss=0.5916704535484314
[15/24] Train loss=0.5716338157653809
[20/24] Train loss=0.5593137145042419
Test set avg_accuracy=75.95% avg_sensitivity=72.89%, avg_specificity=77.12% avg_auc=82.47%
Best model saved!! Metric=-17.574284226002305!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.584754 Test loss=0.510170 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5621101260185242
[5/24] Train loss=0.5585312247276306
[10/24] Train loss=0.5678819417953491
[15/24] Train loss=0.5386313199996948
[20/24] Train loss=0.5326796770095825
Test set avg_accuracy=77.47% avg_sensitivity=72.75%, avg_specificity=79.28% avg_auc=83.66%
Best model saved!! Metric=-12.841037656281799!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.559269 Test loss=0.487766 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5395683646202087
[5/24] Train loss=0.5325611233711243
[10/24] Train loss=0.5453752279281616
[15/24] Train loss=0.5162844061851501
[20/24] Train loss=0.5153652429580688
Test set avg_accuracy=78.96% avg_sensitivity=71.71%, avg_specificity=81.72% avg_auc=84.97%
Best model saved!! Metric=-8.636882159228179!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.534425 Test loss=0.463817 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.517056941986084
[5/24] Train loss=0.5021141171455383
[10/24] Train loss=0.521896243095398
[15/24] Train loss=0.49354079365730286
[20/24] Train loss=0.48534390330314636
Test set avg_accuracy=80.08% avg_sensitivity=71.95%, avg_specificity=83.18% avg_auc=86.11%
Best model saved!! Metric=-4.687595840066422!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.510188 Test loss=0.446116 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.48924633860588074
[5/24] Train loss=0.4819892644882202
[10/24] Train loss=0.49790969491004944
[15/24] Train loss=0.46973779797554016
[20/24] Train loss=0.4650670289993286
Test set avg_accuracy=81.67% avg_sensitivity=70.63%, avg_specificity=85.88% avg_auc=87.32%
Best model saved!! Metric=-0.5100681142048415!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.484398 Test loss=0.423466 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.46338582038879395
[5/24] Train loss=0.4510543942451477
[10/24] Train loss=0.4722210168838501
[15/24] Train loss=0.4446048140525818
[20/24] Train loss=0.43719154596328735
Test set avg_accuracy=82.72% avg_sensitivity=69.50%, avg_specificity=87.77% avg_auc=88.27%
Best model saved!! Metric=2.2559600518947747!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.461032 Test loss=0.405560 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4418528974056244
[5/24] Train loss=0.43160825967788696
[10/24] Train loss=0.45274069905281067
[15/24] Train loss=0.42046689987182617
[20/24] Train loss=0.4146055579185486
Test set avg_accuracy=83.82% avg_sensitivity=69.31%, avg_specificity=89.35% avg_auc=89.31%
Best model saved!! Metric=5.78616833036466!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.439098 Test loss=0.386864 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.42445191740989685
[5/24] Train loss=0.40729424357414246
[10/24] Train loss=0.42838868498802185
[15/24] Train loss=0.40372979640960693
[20/24] Train loss=0.3868032693862915
Test set avg_accuracy=85.04% avg_sensitivity=70.01%, avg_specificity=90.77% avg_auc=90.08%
Best model saved!! Metric=9.90359155563472!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.418270 Test loss=0.370845 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.40633806586265564
[5/24] Train loss=0.38482779264450073
[10/24] Train loss=0.4073135256767273
[15/24] Train loss=0.3798825740814209
[20/24] Train loss=0.3646845519542694
Test set avg_accuracy=85.59% avg_sensitivity=71.81%, avg_specificity=90.84% avg_auc=90.87%
Best model saved!! Metric=13.10296910447876!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.398762 Test loss=0.358431 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3831075131893158
[5/24] Train loss=0.36692360043525696
[10/24] Train loss=0.3950401544570923
[15/24] Train loss=0.36396875977516174
[20/24] Train loss=0.35082191228866577
Test set avg_accuracy=86.26% avg_sensitivity=73.27%, avg_specificity=91.22% avg_auc=91.45%
Best model saved!! Metric=16.206222893883236!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.383027 Test loss=0.347114 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.36944010853767395
[5/24] Train loss=0.3535023629665375
[10/24] Train loss=0.3832167685031891
[15/24] Train loss=0.34472203254699707
[20/24] Train loss=0.33344775438308716
Test set avg_accuracy=85.96% avg_sensitivity=75.25%, avg_specificity=90.05% avg_auc=92.02%
Best model saved!! Metric=17.279565844830373!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.367792 Test loss=0.342282 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.35439199209213257
[5/24] Train loss=0.3454912304878235
[10/24] Train loss=0.3674633204936981
[15/24] Train loss=0.34140023589134216
[20/24] Train loss=0.31913235783576965
Test set avg_accuracy=86.11% avg_sensitivity=72.89%, avg_specificity=91.15% avg_auc=92.16%
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.355319 Test loss=0.330572 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3437533378601074
[5/24] Train loss=0.3288229703903198
[10/24] Train loss=0.35720813274383545
[15/24] Train loss=0.3271022140979767
[20/24] Train loss=0.3093675673007965
Test set avg_accuracy=85.85% avg_sensitivity=75.39%, avg_specificity=89.84% avg_auc=92.25%
Best model saved!! Metric=17.32302697464594!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.344441 Test loss=0.329123 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.33594810962677
[5/24] Train loss=0.3245297372341156
[10/24] Train loss=0.35138610005378723
[15/24] Train loss=0.32022249698638916
[20/24] Train loss=0.29947754740715027
Test set avg_accuracy=85.38% avg_sensitivity=80.76%, avg_specificity=87.14% avg_auc=92.51%
Best model saved!! Metric=19.792188142988905!!
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.337132 Test loss=0.337922 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3275996744632721
[5/24] Train loss=0.31695857644081116
[10/24] Train loss=0.33874621987342834
[15/24] Train loss=0.31350570917129517
[20/24] Train loss=0.29453691840171814
Test set avg_accuracy=86.54% avg_sensitivity=76.14%, avg_specificity=90.50% avg_auc=92.76%
Best model saved!! Metric=19.940957105622104!!
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.328307 Test loss=0.317561 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3178664445877075
[5/24] Train loss=0.30760258436203003
[10/24] Train loss=0.3422021269798279
[15/24] Train loss=0.29442867636680603
[20/24] Train loss=0.290554940700531
Test set avg_accuracy=86.56% avg_sensitivity=78.31%, avg_specificity=89.71% avg_auc=92.82%
Best model saved!! Metric=21.409516009904138!!
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.320239 Test loss=0.317352 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.31686070561408997
[5/24] Train loss=0.2944287061691284
[10/24] Train loss=0.3277156352996826
[15/24] Train loss=0.29043442010879517
[20/24] Train loss=0.279593288898468
Test set avg_accuracy=86.90% avg_sensitivity=68.03%, avg_specificity=94.10% avg_auc=92.95%
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.313690 Test loss=0.305976 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.30979564785957336
[5/24] Train loss=0.2876269817352295
[10/24] Train loss=0.32612407207489014
[15/24] Train loss=0.2928439676761627
[20/24] Train loss=0.27406421303749084
Test set avg_accuracy=86.50% avg_sensitivity=64.55%, avg_specificity=94.87% avg_auc=92.61%
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.306806 Test loss=0.311624 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3078771233558655
[5/24] Train loss=0.2924169600009918
[10/24] Train loss=0.315021276473999
[15/24] Train loss=0.2822214663028717
[20/24] Train loss=0.26871511340141296
Test set avg_accuracy=86.07% avg_sensitivity=61.06%, avg_specificity=95.61% avg_auc=92.32%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.301332 Test loss=0.322056 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.28371497988700867
[5/24] Train loss=0.28291723132133484
[10/24] Train loss=0.3145116865634918
[15/24] Train loss=0.2770446836948395
[20/24] Train loss=0.2652786672115326
Test set avg_accuracy=83.36% avg_sensitivity=44.51%, avg_specificity=98.18% avg_auc=90.61%
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.292618 Test loss=0.385400 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2901065945625305
[5/24] Train loss=0.2806413173675537
[10/24] Train loss=0.29451027512550354
[15/24] Train loss=0.27250221371650696
[20/24] Train loss=0.260056734085083
Test set avg_accuracy=83.36% avg_sensitivity=45.36%, avg_specificity=97.86% avg_auc=90.57%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.288558 Test loss=0.386019 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2854357659816742
[5/24] Train loss=0.26876014471054077
[10/24] Train loss=0.2909336984157562
[15/24] Train loss=0.26765039563179016
[20/24] Train loss=0.25078797340393066
Test set avg_accuracy=82.77% avg_sensitivity=41.87%, avg_specificity=98.38% avg_auc=88.93%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.280573 Test loss=0.418947 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.272344172000885
[5/24] Train loss=0.26233720779418945
[10/24] Train loss=0.2852592468261719
[15/24] Train loss=0.2621648609638214
[20/24] Train loss=0.2447943240404129
Test set avg_accuracy=85.12% avg_sensitivity=54.55%, avg_specificity=96.78% avg_auc=90.99%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.275855 Test loss=0.353515 Current lr=[0.000210185142098938]

[0/24] Train loss=0.26767730712890625
[5/24] Train loss=0.2564281225204468
[10/24] Train loss=0.2910792827606201
[15/24] Train loss=0.25990232825279236
[20/24] Train loss=0.2417321652173996
Test set avg_accuracy=81.86% avg_sensitivity=37.39%, avg_specificity=98.83% avg_auc=88.61%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.271513 Test loss=0.450568 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2601408362388611
[5/24] Train loss=0.25208020210266113
[10/24] Train loss=0.2721380293369293
[15/24] Train loss=0.25090181827545166
[20/24] Train loss=0.23805366456508636
Test set avg_accuracy=81.04% avg_sensitivity=33.95%, avg_specificity=99.01% avg_auc=86.83%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.262782 Test loss=0.471461 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.26589176058769226
[5/24] Train loss=0.2425149828195572
[10/24] Train loss=0.27677199244499207
[15/24] Train loss=0.24492526054382324
[20/24] Train loss=0.2359037548303604
Test set avg_accuracy=80.40% avg_sensitivity=32.01%, avg_specificity=98.87% avg_auc=85.90%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.260550 Test loss=0.501993 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.238727867603302
[5/24] Train loss=0.23507682979106903
[10/24] Train loss=0.2670671045780182
[15/24] Train loss=0.23870520293712616
[20/24] Train loss=0.22849082946777344
Test set avg_accuracy=80.66% avg_sensitivity=33.19%, avg_specificity=98.78% avg_auc=86.87%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.255611 Test loss=0.474202 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.25297847390174866
[5/24] Train loss=0.2396271973848343
[10/24] Train loss=0.26073718070983887
[15/24] Train loss=0.2381521463394165
[20/24] Train loss=0.23613673448562622
Test set avg_accuracy=82.84% avg_sensitivity=42.39%, avg_specificity=98.27% avg_auc=90.88%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.252558 Test loss=0.395167 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.22522978484630585
[5/24] Train loss=0.2261788547039032
[10/24] Train loss=0.2646234631538391
[15/24] Train loss=0.22989048063755035
[20/24] Train loss=0.23832184076309204
Test set avg_accuracy=82.06% avg_sensitivity=39.23%, avg_specificity=98.40% avg_auc=88.49%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.247315 Test loss=0.435053 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.22852720320224762
[5/24] Train loss=0.2216220200061798
[10/24] Train loss=0.2477736920118332
[15/24] Train loss=0.23324887454509735
[20/24] Train loss=0.2236645221710205
Test set avg_accuracy=81.65% avg_sensitivity=37.48%, avg_specificity=98.51% avg_auc=87.22%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.240918 Test loss=0.477056 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.23094823956489563
[5/24] Train loss=0.22028453648090363
[10/24] Train loss=0.2387695014476776
[15/24] Train loss=0.23275963962078094
[20/24] Train loss=0.2171257734298706
Test set avg_accuracy=73.36% avg_sensitivity=4.24%, avg_specificity=99.73% avg_auc=65.61%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.238811 Test loss=0.829288 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.25563594698905945
[5/24] Train loss=0.21694199740886688
[10/24] Train loss=0.27211272716522217
[15/24] Train loss=0.23219668865203857
[20/24] Train loss=0.21972964704036713
Test set avg_accuracy=82.34% avg_sensitivity=40.88%, avg_specificity=98.17% avg_auc=88.21%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.240719 Test loss=0.450186 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2179669439792633
[5/24] Train loss=0.21307246387004852
[10/24] Train loss=0.24270270764827728
[15/24] Train loss=0.2283085286617279
[20/24] Train loss=0.21726231276988983
Test set avg_accuracy=80.53% avg_sensitivity=33.24%, avg_specificity=98.58% avg_auc=87.39%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.232846 Test loss=0.499103 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.23724262416362762
[5/24] Train loss=0.21628053486347198
[10/24] Train loss=0.23874792456626892
[15/24] Train loss=0.22859425842761993
[20/24] Train loss=0.21516181528568268
Test set avg_accuracy=86.12% avg_sensitivity=59.97%, avg_specificity=96.10% avg_auc=91.27%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.234817 Test loss=0.331499 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.21392099559307098
[5/24] Train loss=0.1984085887670517
[10/24] Train loss=0.24023178219795227
[15/24] Train loss=0.21596932411193848
[20/24] Train loss=0.211305171251297
Test set avg_accuracy=78.87% avg_sensitivity=25.79%, avg_specificity=99.12% avg_auc=82.87%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.226439 Test loss=0.571593 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2207297831773758
[5/24] Train loss=0.19873936474323273
[10/24] Train loss=0.24429871141910553
[15/24] Train loss=0.21698331832885742
[20/24] Train loss=0.21479398012161255
Test set avg_accuracy=78.24% avg_sensitivity=23.24%, avg_specificity=99.23% avg_auc=83.74%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.229386 Test loss=0.568376 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.21443673968315125
[5/24] Train loss=0.18581916391849518
[10/24] Train loss=0.23143832385540009
[15/24] Train loss=0.22316057980060577
[20/24] Train loss=0.2258007526397705
Test set avg_accuracy=84.52% avg_sensitivity=52.76%, avg_specificity=96.64% avg_auc=90.86%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.226557 Test loss=0.353066 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.21001389622688293
[5/24] Train loss=0.21079865097999573
[10/24] Train loss=0.23634371161460876
[15/24] Train loss=0.2079104781150818
[20/24] Train loss=0.21612413227558136
Test set avg_accuracy=78.78% avg_sensitivity=25.93%, avg_specificity=98.94% avg_auc=83.97%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.220648 Test loss=0.526885 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2184705138206482
[5/24] Train loss=0.18654851615428925
[10/24] Train loss=0.22661979496479034
[15/24] Train loss=0.2068321406841278
[20/24] Train loss=0.20728930830955505
Test set avg_accuracy=79.34% avg_sensitivity=28.34%, avg_specificity=98.79% avg_auc=82.52%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.215409 Test loss=0.558623 Current lr=[0.00029967723776099]

[0/24] Train loss=0.219704732298851
[5/24] Train loss=0.19250023365020752
[10/24] Train loss=0.22567839920520782
[15/24] Train loss=0.20767393708229065
[20/24] Train loss=0.19445310533046722
Test set avg_accuracy=77.15% avg_sensitivity=18.76%, avg_specificity=99.42% avg_auc=80.97%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.218777 Test loss=0.665166 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.20893727242946625
[5/24] Train loss=0.19251111149787903
[10/24] Train loss=0.21761836111545563
[15/24] Train loss=0.20170466601848602
[20/24] Train loss=0.18722128868103027
Test set avg_accuracy=79.83% avg_sensitivity=32.01%, avg_specificity=98.08% avg_auc=85.17%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.212509 Test loss=0.483313 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2055090367794037
[5/24] Train loss=0.18942630290985107
[10/24] Train loss=0.21539229154586792
[15/24] Train loss=0.19480541348457336
[20/24] Train loss=0.19088222086429596
Test set avg_accuracy=75.20% avg_sensitivity=10.99%, avg_specificity=99.69% avg_auc=73.11%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.207456 Test loss=0.757468 Current lr=[0.000299720220882401]

[0/24] Train loss=0.21027204394340515
[5/24] Train loss=0.1829841583967209
[10/24] Train loss=0.2130601704120636
[15/24] Train loss=0.20556527376174927
[20/24] Train loss=0.19710782170295715
Test set avg_accuracy=77.97% avg_sensitivity=22.82%, avg_specificity=99.01% avg_auc=80.70%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.205236 Test loss=0.606803 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19612541794776917
[5/24] Train loss=0.19283470511436462
[10/24] Train loss=0.20939487218856812
[15/24] Train loss=0.20849868655204773
[20/24] Train loss=0.20055899024009705
Test set avg_accuracy=75.25% avg_sensitivity=10.75%, avg_specificity=99.86% avg_auc=74.27%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.214514 Test loss=0.873336 Current lr=[0.000298904600941902]

[0/24] Train loss=0.20820176601409912
[5/24] Train loss=0.19657959043979645
[10/24] Train loss=0.2334408313035965
[15/24] Train loss=0.20279277861118317
[20/24] Train loss=0.19411371648311615
Test set avg_accuracy=84.95% avg_sensitivity=54.60%, avg_specificity=96.53% avg_auc=90.45%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.214334 Test loss=0.355455 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.20638687908649445
[5/24] Train loss=0.187735915184021
[10/24] Train loss=0.21644197404384613
[15/24] Train loss=0.21516773104667664
[20/24] Train loss=0.20169377326965332
Test set avg_accuracy=82.38% avg_sensitivity=39.93%, avg_specificity=98.58% avg_auc=85.53%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.206959 Test loss=0.445421 Current lr=[0.000297555943323901]

[0/24] Train loss=0.19734686613082886
[5/24] Train loss=0.18067097663879395
[10/24] Train loss=0.20556700229644775
[15/24] Train loss=0.1875494122505188
[20/24] Train loss=0.2006736695766449
Test set avg_accuracy=86.18% avg_sensitivity=65.82%, avg_specificity=93.96% avg_auc=91.16%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.201605 Test loss=0.335521 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.18921612203121185
[5/24] Train loss=0.17456547915935516
[10/24] Train loss=0.20182190835475922
[15/24] Train loss=0.18911007046699524
[20/24] Train loss=0.20259369909763336
Test set avg_accuracy=82.80% avg_sensitivity=42.20%, avg_specificity=98.29% avg_auc=86.86%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.201772 Test loss=0.439087 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.18993264436721802
[5/24] Train loss=0.17239893972873688
[10/24] Train loss=0.21964313089847565
[15/24] Train loss=0.18884991109371185
[20/24] Train loss=0.19765347242355347
Test set avg_accuracy=86.72% avg_sensitivity=69.87%, avg_specificity=93.15% avg_auc=92.27%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.201665 Test loss=0.312455 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.18436582386493683
[5/24] Train loss=0.18247030675411224
[10/24] Train loss=0.20294585824012756
[15/24] Train loss=0.20168031752109528
[20/24] Train loss=0.19549742341041565
Test set avg_accuracy=85.92% avg_sensitivity=61.72%, avg_specificity=95.16% avg_auc=89.89%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.198922 Test loss=0.353347 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2154289036989212
[5/24] Train loss=0.17875422537326813
[10/24] Train loss=0.2003919780254364
[15/24] Train loss=0.18588033318519592
[20/24] Train loss=0.19020508229732513
Test set avg_accuracy=86.03% avg_sensitivity=65.68%, avg_specificity=93.79% avg_auc=91.20%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.196972 Test loss=0.338647 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.18742813169956207
[5/24] Train loss=0.17027613520622253
[10/24] Train loss=0.2037370353937149
[15/24] Train loss=0.19442413747310638
[20/24] Train loss=0.19688187539577484
Test set avg_accuracy=86.97% avg_sensitivity=70.82%, avg_specificity=93.13% avg_auc=92.77%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.195022 Test loss=0.307463 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.20084059238433838
[5/24] Train loss=0.1934245526790619
[10/24] Train loss=0.20754064619541168
[15/24] Train loss=0.18840211629867554
[20/24] Train loss=0.19165419042110443
Test set avg_accuracy=85.31% avg_sensitivity=63.22%, avg_specificity=93.74% avg_auc=90.37%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.197916 Test loss=0.355815 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.18903282284736633
[5/24] Train loss=0.17252373695373535
[10/24] Train loss=0.20364460349082947
[15/24] Train loss=0.1946229338645935
[20/24] Train loss=0.19823746383190155
Test set avg_accuracy=84.41% avg_sensitivity=81.00%, avg_specificity=85.72% avg_auc=91.77%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.197835 Test loss=0.349121 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18006163835525513
[5/24] Train loss=0.16614462435245514
[10/24] Train loss=0.1993422657251358
[15/24] Train loss=0.18081355094909668
[20/24] Train loss=0.19421696662902832
Test set avg_accuracy=78.93% avg_sensitivity=88.68%, avg_specificity=75.21% avg_auc=89.44%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.192506 Test loss=0.458938 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.1876707822084427
[5/24] Train loss=0.1761976033449173
[10/24] Train loss=0.2038344442844391
[15/24] Train loss=0.21071133017539978
[20/24] Train loss=0.19611477851867676
Test set avg_accuracy=81.52% avg_sensitivity=83.40%, avg_specificity=80.81% avg_auc=90.39%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.198216 Test loss=0.412283 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.18851156532764435
[5/24] Train loss=0.16867545247077942
[10/24] Train loss=0.1964220553636551
[15/24] Train loss=0.19626736640930176
[20/24] Train loss=0.19792437553405762
Test set avg_accuracy=84.08% avg_sensitivity=82.70%, avg_specificity=84.60% avg_auc=91.54%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.194094 Test loss=0.367815 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.180705264210701
[5/24] Train loss=0.17366841435432434
[10/24] Train loss=0.1946132630109787
[15/24] Train loss=0.17896535992622375
[20/24] Train loss=0.19515451788902283
Test set avg_accuracy=78.29% avg_sensitivity=85.57%, avg_specificity=75.52% avg_auc=88.79%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.190375 Test loss=0.489705 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.18033435940742493
[5/24] Train loss=0.16170130670070648
[10/24] Train loss=0.21565508842468262
[15/24] Train loss=0.19307933747768402
[20/24] Train loss=0.18958407640457153
Test set avg_accuracy=86.65% avg_sensitivity=68.41%, avg_specificity=93.61% avg_auc=91.53%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.189348 Test loss=0.333961 Current lr=[0.000276307469034998]

[0/24] Train loss=0.18605756759643555
[5/24] Train loss=0.1613331288099289
[10/24] Train loss=0.2031051516532898
[15/24] Train loss=0.20045003294944763
[20/24] Train loss=0.19775593280792236
Test set avg_accuracy=85.38% avg_sensitivity=57.61%, avg_specificity=95.97% avg_auc=88.83%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.194353 Test loss=0.379116 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.18539918959140778
[5/24] Train loss=0.17949022352695465
[10/24] Train loss=0.20462903380393982
[15/24] Train loss=0.18711069226264954
[20/24] Train loss=0.18825364112854004
Test set avg_accuracy=86.41% avg_sensitivity=73.27%, avg_specificity=91.42% avg_auc=92.16%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.192441 Test loss=0.312874 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.19565488398075104
[5/24] Train loss=0.16687896847724915
[10/24] Train loss=0.20656444132328033
[15/24] Train loss=0.1811579465866089
[20/24] Train loss=0.1896207630634308
Test set avg_accuracy=83.76% avg_sensitivity=81.52%, avg_specificity=84.62% avg_auc=91.61%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.189985 Test loss=0.363540 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.18582430481910706
[5/24] Train loss=0.16778290271759033
[10/24] Train loss=0.17978103458881378
[15/24] Train loss=0.1678014099597931
[20/24] Train loss=0.1830529272556305
Test set avg_accuracy=86.59% avg_sensitivity=75.25%, avg_specificity=90.92% avg_auc=92.09%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.184175 Test loss=0.320313 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.17888669669628143
[5/24] Train loss=0.15204881131649017
[10/24] Train loss=0.18958646059036255
[15/24] Train loss=0.1655491590499878
[20/24] Train loss=0.17442521452903748
Test set avg_accuracy=85.81% avg_sensitivity=72.37%, avg_specificity=90.93% avg_auc=90.76%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.182327 Test loss=0.335131 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.18230725824832916
[5/24] Train loss=0.16666899621486664
[10/24] Train loss=0.1972266584634781
[15/24] Train loss=0.1667766273021698
[20/24] Train loss=0.17943742871284485
Test set avg_accuracy=86.97% avg_sensitivity=71.19%, avg_specificity=92.98% avg_auc=92.35%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.179066 Test loss=0.312154 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.1777094304561615
[5/24] Train loss=0.1537894904613495
[10/24] Train loss=0.17961327731609344
[15/24] Train loss=0.1677882969379425
[20/24] Train loss=0.17308351397514343
Test set avg_accuracy=82.55% avg_sensitivity=42.15%, avg_specificity=97.97% avg_auc=83.99%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.175550 Test loss=0.489174 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.17168760299682617
[5/24] Train loss=0.1476646214723587
[10/24] Train loss=0.18056221306324005
[15/24] Train loss=0.1728263795375824
[20/24] Train loss=0.17590945959091187
Test set avg_accuracy=86.03% avg_sensitivity=66.62%, avg_specificity=93.43% avg_auc=90.51%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.175554 Test loss=0.342954 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.16840071976184845
[5/24] Train loss=0.1542843133211136
[10/24] Train loss=0.1739233434200287
[15/24] Train loss=0.16025173664093018
[20/24] Train loss=0.18408530950546265
Test set avg_accuracy=85.94% avg_sensitivity=72.75%, avg_specificity=90.97% avg_auc=91.30%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.171997 Test loss=0.333171 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1681099385023117
[5/24] Train loss=0.16064497828483582
[10/24] Train loss=0.18294809758663177
[15/24] Train loss=0.1690688282251358
[20/24] Train loss=0.18304720520973206
Test set avg_accuracy=87.04% avg_sensitivity=73.97%, avg_specificity=92.03% avg_auc=92.39%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.175625 Test loss=0.317208 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.1654525250196457
[5/24] Train loss=0.1473742574453354
[10/24] Train loss=0.17533916234970093
[15/24] Train loss=0.16497187316417694
[20/24] Train loss=0.16897283494472504
Test set avg_accuracy=86.72% avg_sensitivity=64.92%, avg_specificity=95.04% avg_auc=92.03%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.173585 Test loss=0.322079 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.17059768736362457
[5/24] Train loss=0.15406551957130432
[10/24] Train loss=0.18081164360046387
[15/24] Train loss=0.17293532192707062
[20/24] Train loss=0.17707450687885284
Test set avg_accuracy=84.02% avg_sensitivity=50.54%, avg_specificity=96.80% avg_auc=86.98%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.175060 Test loss=0.432377 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.17756988108158112
[5/24] Train loss=0.14829950034618378
[10/24] Train loss=0.17845144867897034
[15/24] Train loss=0.16216164827346802
[20/24] Train loss=0.16738013923168182
Test set avg_accuracy=85.57% avg_sensitivity=62.33%, avg_specificity=94.44% avg_auc=90.33%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.171063 Test loss=0.355516 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.1669674664735794
[5/24] Train loss=0.14947116374969482
[10/24] Train loss=0.18064618110656738
[15/24] Train loss=0.1634487360715866
[20/24] Train loss=0.17444327473640442
Test set avg_accuracy=83.92% avg_sensitivity=51.58%, avg_specificity=96.26% avg_auc=88.65%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.170537 Test loss=0.405681 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.16779763996601105
[5/24] Train loss=0.15224161744117737
[10/24] Train loss=0.17477048933506012
[15/24] Train loss=0.16636744141578674
[20/24] Train loss=0.16520275175571442
Test set avg_accuracy=86.05% avg_sensitivity=60.96%, avg_specificity=95.63% avg_auc=89.17%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.170324 Test loss=0.364413 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.16980132460594177
[5/24] Train loss=0.14470262825489044
[10/24] Train loss=0.16955852508544922
[15/24] Train loss=0.16412509977817535
[20/24] Train loss=0.16709275543689728
Test set avg_accuracy=85.86% avg_sensitivity=62.71%, avg_specificity=94.69% avg_auc=89.44%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.167376 Test loss=0.367588 Current lr=[0.000224838296036774]

[0/24] Train loss=0.170909583568573
[5/24] Train loss=0.14030127227306366
[10/24] Train loss=0.16778743267059326
[15/24] Train loss=0.16051514446735382
[20/24] Train loss=0.16805697977542877
Test set avg_accuracy=84.38% avg_sensitivity=54.08%, avg_specificity=95.93% avg_auc=87.72%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.167771 Test loss=0.394516 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.16274134814739227
[5/24] Train loss=0.15915699303150177
[10/24] Train loss=0.1689932942390442
[15/24] Train loss=0.1642451286315918
[20/24] Train loss=0.16118066012859344
Test set avg_accuracy=85.68% avg_sensitivity=71.71%, avg_specificity=91.01% avg_auc=91.21%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.168263 Test loss=0.336718 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.1641603708267212
[5/24] Train loss=0.14534851908683777
[10/24] Train loss=0.1715649664402008
[15/24] Train loss=0.1553143560886383
[20/24] Train loss=0.16635143756866455
Test set avg_accuracy=85.55% avg_sensitivity=59.78%, avg_specificity=95.38% avg_auc=89.86%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.168013 Test loss=0.359278 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1632133424282074
[5/24] Train loss=0.14811167120933533
[10/24] Train loss=0.17141352593898773
[15/24] Train loss=0.15825577080249786
[20/24] Train loss=0.1631513386964798
Test set avg_accuracy=85.21% avg_sensitivity=56.81%, avg_specificity=96.04% avg_auc=88.06%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.166000 Test loss=0.385995 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.16354608535766602
[5/24] Train loss=0.15172962844371796
[10/24] Train loss=0.16899408400058746
[15/24] Train loss=0.1564951092004776
[20/24] Train loss=0.15976779162883759
Test set avg_accuracy=84.56% avg_sensitivity=52.00%, avg_specificity=96.98% avg_auc=85.59%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.166336 Test loss=0.435365 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.1579776555299759
[5/24] Train loss=0.14289464056491852
[10/24] Train loss=0.17467203736305237
[15/24] Train loss=0.15060599148273468
[20/24] Train loss=0.15584276616573334
Test set avg_accuracy=85.70% avg_sensitivity=74.40%, avg_specificity=90.02% avg_auc=91.35%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.161810 Test loss=0.335424 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.16364626586437225
[5/24] Train loss=0.14391569793224335
[10/24] Train loss=0.157173290848732
[15/24] Train loss=0.15148156881332397
[20/24] Train loss=0.15413860976696014
Test set avg_accuracy=86.50% avg_sensitivity=72.94%, avg_specificity=91.67% avg_auc=91.62%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.159842 Test loss=0.331032 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.15533626079559326
[5/24] Train loss=0.1423577070236206
[10/24] Train loss=0.15574759244918823
[15/24] Train loss=0.14591334760189056
[20/24] Train loss=0.15630346536636353
Test set avg_accuracy=85.85% avg_sensitivity=75.44%, avg_specificity=89.82% avg_auc=91.25%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.159996 Test loss=0.341180 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.16587908565998077
[5/24] Train loss=0.13158774375915527
[10/24] Train loss=0.16688960790634155
[15/24] Train loss=0.15293723344802856
[20/24] Train loss=0.1545574963092804
Test set avg_accuracy=85.96% avg_sensitivity=68.32%, avg_specificity=92.70% avg_auc=90.91%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.158924 Test loss=0.339677 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.1603832095861435
[5/24] Train loss=0.13425026834011078
[10/24] Train loss=0.16104313731193542
[15/24] Train loss=0.15053826570510864
[20/24] Train loss=0.16074928641319275
Test set avg_accuracy=85.18% avg_sensitivity=60.07%, avg_specificity=94.77% avg_auc=88.06%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.157063 Test loss=0.385148 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.16710148751735687
[5/24] Train loss=0.14329135417938232
[10/24] Train loss=0.1536712795495987
[15/24] Train loss=0.1498742252588272
[20/24] Train loss=0.1599244475364685
Test set avg_accuracy=86.47% avg_sensitivity=74.73%, avg_specificity=90.95% avg_auc=91.37%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.158241 Test loss=0.336180 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.1599874347448349
[5/24] Train loss=0.1402084082365036
[10/24] Train loss=0.15460342168807983
[15/24] Train loss=0.14955171942710876
[20/24] Train loss=0.15240289270877838
Test set avg_accuracy=86.05% avg_sensitivity=68.69%, avg_specificity=92.68% avg_auc=90.69%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.156719 Test loss=0.345755 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.16493095457553864
[5/24] Train loss=0.14026111364364624
[10/24] Train loss=0.15337695181369781
[15/24] Train loss=0.1497282087802887
[20/24] Train loss=0.14920876920223236
Test set avg_accuracy=86.25% avg_sensitivity=61.57%, avg_specificity=95.66% avg_auc=88.83%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.154398 Test loss=0.362339 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15697325766086578
[5/24] Train loss=0.1409425139427185
[10/24] Train loss=0.16112983226776123
[15/24] Train loss=0.1459176391363144
[20/24] Train loss=0.15913984179496765
Test set avg_accuracy=85.25% avg_sensitivity=64.73%, avg_specificity=93.07% avg_auc=89.70%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.158636 Test loss=0.368134 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.15685346722602844
[5/24] Train loss=0.14060723781585693
[10/24] Train loss=0.15221256017684937
[15/24] Train loss=0.14694181084632874
[20/24] Train loss=0.14501693844795227
Test set avg_accuracy=86.42% avg_sensitivity=76.24%, avg_specificity=90.30% avg_auc=92.03%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.155038 Test loss=0.329364 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15215104818344116
[5/24] Train loss=0.13209426403045654
[10/24] Train loss=0.15554888546466827
[15/24] Train loss=0.15471990406513214
[20/24] Train loss=0.15262912213802338
Test set avg_accuracy=86.30% avg_sensitivity=65.87%, avg_specificity=94.10% avg_auc=90.39%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.155186 Test loss=0.350274 Current lr=[0.000156543481933168]

[0/24] Train loss=0.15179987251758575
[5/24] Train loss=0.1358203887939453
[10/24] Train loss=0.1634441614151001
[15/24] Train loss=0.14307184517383575
[20/24] Train loss=0.15651534497737885
Test set avg_accuracy=85.70% avg_sensitivity=67.80%, avg_specificity=92.53% avg_auc=90.53%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.154179 Test loss=0.352265 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.16712906956672668
[5/24] Train loss=0.13416694104671478
[10/24] Train loss=0.1551118940114975
[15/24] Train loss=0.14397688210010529
[20/24] Train loss=0.15794935822486877
Test set avg_accuracy=86.16% avg_sensitivity=75.39%, avg_specificity=90.27% avg_auc=91.59%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.154500 Test loss=0.334008 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15325133502483368
[5/24] Train loss=0.132542684674263
[10/24] Train loss=0.14276641607284546
[15/24] Train loss=0.1476593315601349
[20/24] Train loss=0.14722341299057007
Test set avg_accuracy=81.26% avg_sensitivity=41.82%, avg_specificity=96.31% avg_auc=83.20%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.152659 Test loss=0.511946 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15264979004859924
[5/24] Train loss=0.13972008228302002
[10/24] Train loss=0.14495733380317688
[15/24] Train loss=0.14960375428199768
[20/24] Train loss=0.15336759388446808
Test set avg_accuracy=86.22% avg_sensitivity=67.75%, avg_specificity=93.27% avg_auc=90.56%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.152893 Test loss=0.346601 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15098996460437775
[5/24] Train loss=0.13220222294330597
[10/24] Train loss=0.14976809918880463
[15/24] Train loss=0.1570771038532257
[20/24] Train loss=0.1525619924068451
Test set avg_accuracy=86.29% avg_sensitivity=64.21%, avg_specificity=94.71% avg_auc=90.12%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.151911 Test loss=0.359185 Current lr=[0.000134135431043539]

[0/24] Train loss=0.14480474591255188
[5/24] Train loss=0.141301229596138
[10/24] Train loss=0.151101216673851
[15/24] Train loss=0.1408018320798874
[20/24] Train loss=0.14461031556129456
Test set avg_accuracy=84.88% avg_sensitivity=54.13%, avg_specificity=96.62% avg_auc=87.14%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.150839 Test loss=0.413320 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.14673611521720886
[5/24] Train loss=0.13002371788024902
[10/24] Train loss=0.1519642025232315
[15/24] Train loss=0.14409062266349792
[20/24] Train loss=0.1472344845533371
Test set avg_accuracy=85.81% avg_sensitivity=63.08%, avg_specificity=94.48% avg_auc=88.58%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.149489 Test loss=0.380137 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.14999781548976898
[5/24] Train loss=0.13143253326416016
[10/24] Train loss=0.1438048779964447
[15/24] Train loss=0.1421998292207718
[20/24] Train loss=0.1456250697374344
Test set avg_accuracy=83.14% avg_sensitivity=44.51%, avg_specificity=97.88% avg_auc=82.70%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.148841 Test loss=0.489320 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.1573871523141861
[5/24] Train loss=0.1361314207315445
[10/24] Train loss=0.1492258459329605
[15/24] Train loss=0.13953089714050293
[20/24] Train loss=0.14635735750198364
Test set avg_accuracy=86.47% avg_sensitivity=69.97%, avg_specificity=92.77% avg_auc=91.22%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.150090 Test loss=0.334104 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14890095591545105
[5/24] Train loss=0.13419140875339508
[10/24] Train loss=0.14238427579402924
[15/24] Train loss=0.13686667382717133
[20/24] Train loss=0.14823958277702332
Test set avg_accuracy=85.34% avg_sensitivity=59.97%, avg_specificity=95.02% avg_auc=89.39%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.148962 Test loss=0.373087 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1468057930469513
[5/24] Train loss=0.12854015827178955
[10/24] Train loss=0.14256684482097626
[15/24] Train loss=0.1366179883480072
[20/24] Train loss=0.14499610662460327
Test set avg_accuracy=86.37% avg_sensitivity=63.70%, avg_specificity=95.02% avg_auc=89.48%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.148548 Test loss=0.358154 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15080802142620087
[5/24] Train loss=0.1329745352268219
[10/24] Train loss=0.1433185338973999
[15/24] Train loss=0.14008156955242157
[20/24] Train loss=0.15036550164222717
Test set avg_accuracy=86.15% avg_sensitivity=63.60%, avg_specificity=94.75% avg_auc=90.11%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.148195 Test loss=0.349570 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.14412041008472443
[5/24] Train loss=0.1290515959262848
[10/24] Train loss=0.14787311851978302
[15/24] Train loss=0.13344405591487885
[20/24] Train loss=0.13981644809246063
Test set avg_accuracy=86.24% avg_sensitivity=66.86%, avg_specificity=93.63% avg_auc=90.19%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.143447 Test loss=0.350976 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1474500447511673
[5/24] Train loss=0.1331629455089569
[10/24] Train loss=0.13592492043972015
[15/24] Train loss=0.1348714679479599
[20/24] Train loss=0.139103963971138
Test set avg_accuracy=85.86% avg_sensitivity=59.26%, avg_specificity=96.01% avg_auc=89.05%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.142158 Test loss=0.377663 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14323243498802185
[5/24] Train loss=0.12616129219532013
[10/24] Train loss=0.13767831027507782
[15/24] Train loss=0.1309202015399933
[20/24] Train loss=0.1353289932012558
Test set avg_accuracy=85.90% avg_sensitivity=74.21%, avg_specificity=90.36% avg_auc=91.24%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.141953 Test loss=0.338248 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1377783864736557
[5/24] Train loss=0.12598757445812225
[10/24] Train loss=0.13766992092132568
[15/24] Train loss=0.12961797416210175
[20/24] Train loss=0.13885578513145447
Test set avg_accuracy=86.24% avg_sensitivity=65.77%, avg_specificity=94.05% avg_auc=90.46%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.141445 Test loss=0.347641 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14572134613990784
[5/24] Train loss=0.12896186113357544
[10/24] Train loss=0.13937994837760925
[15/24] Train loss=0.1301754117012024
[20/24] Train loss=0.1363765448331833
Test set avg_accuracy=86.47% avg_sensitivity=67.00%, avg_specificity=93.90% avg_auc=90.68%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.139279 Test loss=0.344820 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13550527393817902
[5/24] Train loss=0.12315268069505692
[10/24] Train loss=0.12918145954608917
[15/24] Train loss=0.12823306024074554
[20/24] Train loss=0.13711339235305786
Test set avg_accuracy=86.52% avg_sensitivity=68.13%, avg_specificity=93.54% avg_auc=90.46%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.137594 Test loss=0.345085 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1420222520828247
[5/24] Train loss=0.12328563630580902
[10/24] Train loss=0.12972413003444672
[15/24] Train loss=0.1298469752073288
[20/24] Train loss=0.13019639253616333
Test set avg_accuracy=85.69% avg_sensitivity=65.72%, avg_specificity=93.31% avg_auc=89.26%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.137777 Test loss=0.367175 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13959404826164246
[5/24] Train loss=0.12164966762065887
[10/24] Train loss=0.13245217502117157
[15/24] Train loss=0.12664540112018585
[20/24] Train loss=0.1295522302389145
Test set avg_accuracy=86.04% avg_sensitivity=74.21%, avg_specificity=90.56% avg_auc=91.08%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.136596 Test loss=0.342772 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1381291300058365
[5/24] Train loss=0.11868880689144135
[10/24] Train loss=0.12790411710739136
[15/24] Train loss=0.12790682911872864
[20/24] Train loss=0.13596998155117035
Test set avg_accuracy=86.48% avg_sensitivity=69.64%, avg_specificity=92.91% avg_auc=90.58%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.136067 Test loss=0.343614 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1347312480211258
[5/24] Train loss=0.11934179067611694
[10/24] Train loss=0.13105708360671997
[15/24] Train loss=0.13019636273384094
[20/24] Train loss=0.13041231036186218
Test set avg_accuracy=85.52% avg_sensitivity=66.01%, avg_specificity=92.97% avg_auc=89.80%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.135892 Test loss=0.363823 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14079618453979492
[5/24] Train loss=0.12082590162754059
[10/24] Train loss=0.12894466519355774
[15/24] Train loss=0.12896768748760223
[20/24] Train loss=0.13195650279521942
Test set avg_accuracy=86.43% avg_sensitivity=71.10%, avg_specificity=92.28% avg_auc=91.10%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.135606 Test loss=0.337981 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1345265507698059
[5/24] Train loss=0.11951933801174164
[10/24] Train loss=0.1310214251279831
[15/24] Train loss=0.12593311071395874
[20/24] Train loss=0.1314808875322342
Test set avg_accuracy=85.62% avg_sensitivity=75.67%, avg_specificity=89.42% avg_auc=91.57%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.134988 Test loss=0.339923 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13691769540309906
[5/24] Train loss=0.11875775456428528
[10/24] Train loss=0.13062676787376404
[15/24] Train loss=0.12736129760742188
[20/24] Train loss=0.12956736981868744
Test set avg_accuracy=86.33% avg_sensitivity=72.18%, avg_specificity=91.73% avg_auc=90.73%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.134531 Test loss=0.344939 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1345139592885971
[5/24] Train loss=0.12086647748947144
[10/24] Train loss=0.12730681896209717
[15/24] Train loss=0.12655295431613922
[20/24] Train loss=0.13608308136463165
Test set avg_accuracy=86.21% avg_sensitivity=69.54%, avg_specificity=92.57% avg_auc=90.54%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.132776 Test loss=0.346782 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.12952850759029388
[5/24] Train loss=0.11907722800970078
[10/24] Train loss=0.1295723021030426
[15/24] Train loss=0.12299312651157379
[20/24] Train loss=0.129707470536232
Test set avg_accuracy=86.12% avg_sensitivity=67.99%, avg_specificity=93.04% avg_auc=90.07%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.131669 Test loss=0.349588 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1332186460494995
[5/24] Train loss=0.11799576133489609
[10/24] Train loss=0.13491612672805786
[15/24] Train loss=0.1256350725889206
[20/24] Train loss=0.12881453335285187
Test set avg_accuracy=85.72% avg_sensitivity=64.97%, avg_specificity=93.63% avg_auc=87.82%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.132230 Test loss=0.379906 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12892833352088928
[5/24] Train loss=0.11788061261177063
[10/24] Train loss=0.12626880407333374
[15/24] Train loss=0.12295784056186676
[20/24] Train loss=0.127921923995018
Test set avg_accuracy=85.39% avg_sensitivity=72.94%, avg_specificity=90.14% avg_auc=90.41%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.130028 Test loss=0.354694 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12954895198345184
[5/24] Train loss=0.11795564740896225
[10/24] Train loss=0.126103937625885
[15/24] Train loss=0.12376956641674042
[20/24] Train loss=0.12594753503799438
Test set avg_accuracy=85.56% avg_sensitivity=70.11%, avg_specificity=91.46% avg_auc=90.11%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.129696 Test loss=0.360134 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12817099690437317
[5/24] Train loss=0.11396787315607071
[10/24] Train loss=0.12639963626861572
[15/24] Train loss=0.12256714701652527
[20/24] Train loss=0.13046570122241974
Test set avg_accuracy=86.22% avg_sensitivity=73.13%, avg_specificity=91.22% avg_auc=90.79%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.129045 Test loss=0.345697 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12738394737243652
[5/24] Train loss=0.11698325723409653
[10/24] Train loss=0.1225229948759079
[15/24] Train loss=0.12008991837501526
[20/24] Train loss=0.12367371469736099
Test set avg_accuracy=85.85% avg_sensitivity=75.67%, avg_specificity=89.73% avg_auc=91.22%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.128846 Test loss=0.342205 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1250993013381958
[5/24] Train loss=0.11866872012615204
[10/24] Train loss=0.12469432502985
[15/24] Train loss=0.12239420413970947
[20/24] Train loss=0.1271655410528183
Test set avg_accuracy=85.62% avg_sensitivity=74.54%, avg_specificity=89.85% avg_auc=90.56%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.128444 Test loss=0.351890 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.129096120595932
[5/24] Train loss=0.11576337367296219
[10/24] Train loss=0.11994241923093796
[15/24] Train loss=0.12274664640426636
[20/24] Train loss=0.12572935223579407
Test set avg_accuracy=86.46% avg_sensitivity=70.72%, avg_specificity=92.46% avg_auc=90.07%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.127553 Test loss=0.347699 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12329034507274628
[5/24] Train loss=0.11483477801084518
[10/24] Train loss=0.12902000546455383
[15/24] Train loss=0.11829844117164612
[20/24] Train loss=0.12764772772789001
Test set avg_accuracy=86.61% avg_sensitivity=74.59%, avg_specificity=91.20% avg_auc=90.93%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.127360 Test loss=0.339068 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12419939786195755
[5/24] Train loss=0.11187387257814407
[10/24] Train loss=0.12385833263397217
[15/24] Train loss=0.11663931608200073
[20/24] Train loss=0.12432369589805603
Test set avg_accuracy=86.39% avg_sensitivity=72.23%, avg_specificity=91.80% avg_auc=90.14%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.125933 Test loss=0.349814 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12525314092636108
[5/24] Train loss=0.1115940734744072
[10/24] Train loss=0.12114673852920532
[15/24] Train loss=0.11857182532548904
[20/24] Train loss=0.12843941152095795
Test set avg_accuracy=86.54% avg_sensitivity=71.66%, avg_specificity=92.21% avg_auc=89.93%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.125437 Test loss=0.350627 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12853653728961945
[5/24] Train loss=0.11115245521068573
[10/24] Train loss=0.12021653354167938
[15/24] Train loss=0.11837659031152725
[20/24] Train loss=0.12186694890260696
Test set avg_accuracy=86.50% avg_sensitivity=71.95%, avg_specificity=92.05% avg_auc=90.36%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.124772 Test loss=0.343365 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12327505648136139
[5/24] Train loss=0.11077550798654556
[10/24] Train loss=0.11727502197027206
[15/24] Train loss=0.11831752210855484
[20/24] Train loss=0.12351454049348831
Test set avg_accuracy=86.63% avg_sensitivity=72.80%, avg_specificity=91.91% avg_auc=90.46%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.123816 Test loss=0.341250 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1255025714635849
[5/24] Train loss=0.11258591711521149
[10/24] Train loss=0.1174115464091301
[15/24] Train loss=0.11565390229225159
[20/24] Train loss=0.12083751708269119
Test set avg_accuracy=86.95% avg_sensitivity=73.46%, avg_specificity=92.10% avg_auc=90.74%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.123792 Test loss=0.339087 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12295518815517426
[5/24] Train loss=0.10948508232831955
[10/24] Train loss=0.118665911257267
[15/24] Train loss=0.11676204949617386
[20/24] Train loss=0.12154702097177505
Test set avg_accuracy=86.76% avg_sensitivity=71.38%, avg_specificity=92.62% avg_auc=90.29%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.123262 Test loss=0.341565 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1218501627445221
[5/24] Train loss=0.11131180822849274
[10/24] Train loss=0.1198672205209732
[15/24] Train loss=0.11440576612949371
[20/24] Train loss=0.12001578509807587
Test set avg_accuracy=86.67% avg_sensitivity=72.84%, avg_specificity=91.94% avg_auc=90.52%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.122856 Test loss=0.343042 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12060074508190155
[5/24] Train loss=0.11090458184480667
[10/24] Train loss=0.11886423081159592
[15/24] Train loss=0.11733577400445938
[20/24] Train loss=0.12318386137485504
Test set avg_accuracy=86.65% avg_sensitivity=72.28%, avg_specificity=92.14% avg_auc=90.21%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.122432 Test loss=0.344974 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12477481365203857
[5/24] Train loss=0.10852717608213425
[10/24] Train loss=0.11945998668670654
[15/24] Train loss=0.1159055307507515
[20/24] Train loss=0.12122909724712372
Test set avg_accuracy=86.54% avg_sensitivity=72.32%, avg_specificity=91.96% avg_auc=90.30%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.122577 Test loss=0.344481 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12388977408409119
[5/24] Train loss=0.11125019937753677
[10/24] Train loss=0.1202615350484848
[15/24] Train loss=0.11528236418962479
[20/24] Train loss=0.1236027330160141
Test set avg_accuracy=86.71% avg_sensitivity=72.23%, avg_specificity=92.23% avg_auc=90.31%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.121962 Test loss=0.343394 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12093652784824371
[5/24] Train loss=0.1115872785449028
[10/24] Train loss=0.11532091349363327
[15/24] Train loss=0.11340463161468506
[20/24] Train loss=0.11916941404342651
Test set avg_accuracy=86.73% avg_sensitivity=72.84%, avg_specificity=92.03% avg_auc=90.36%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.121442 Test loss=0.343381 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12216916680335999
[5/24] Train loss=0.10817070305347443
[10/24] Train loss=0.1177547425031662
[15/24] Train loss=0.11320863664150238
[20/24] Train loss=0.12286488711833954
Test set avg_accuracy=86.76% avg_sensitivity=71.81%, avg_specificity=92.46% avg_auc=90.39%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.121796 Test loss=0.341851 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12102118879556656
[5/24] Train loss=0.1096167340874672
[10/24] Train loss=0.1153235211968422
[15/24] Train loss=0.11466222256422043
[20/24] Train loss=0.11913834512233734
Test set avg_accuracy=86.67% avg_sensitivity=72.42%, avg_specificity=92.10% avg_auc=90.55%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.121611 Test loss=0.341011 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12118525803089142
[5/24] Train loss=0.11123333126306534
[10/24] Train loss=0.11647641658782959
[15/24] Train loss=0.11230078339576721
[20/24] Train loss=0.12336855381727219
Test set avg_accuracy=86.76% avg_sensitivity=72.75%, avg_specificity=92.10% avg_auc=90.50%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.121344 Test loss=0.341009 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11999709159135818
[5/24] Train loss=0.10973849892616272
[10/24] Train loss=0.11785384267568588
[15/24] Train loss=0.11595719307661057
[20/24] Train loss=0.1207551434636116
Test set avg_accuracy=86.72% avg_sensitivity=72.61%, avg_specificity=92.10% avg_auc=90.52%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.121403 Test loss=0.340843 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12146154046058655
[5/24] Train loss=0.10899843275547028
[10/24] Train loss=0.11663119494915009
[15/24] Train loss=0.11504188925027847
[20/24] Train loss=0.11885403841733932
Test set avg_accuracy=86.65% avg_sensitivity=72.28%, avg_specificity=92.14% avg_auc=90.42%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.121071 Test loss=0.342153 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1196448802947998
[5/24] Train loss=0.10811594873666763
[10/24] Train loss=0.11590349674224854
[15/24] Train loss=0.11511903256177902
[20/24] Train loss=0.11995112150907516
Test set avg_accuracy=86.71% avg_sensitivity=72.47%, avg_specificity=92.14% avg_auc=90.44%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.121792 Test loss=0.342258 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12115072458982468
[5/24] Train loss=0.11029069125652313
[10/24] Train loss=0.11321566998958588
[15/24] Train loss=0.11254684627056122
[20/24] Train loss=0.12035816162824631
Test set avg_accuracy=86.71% avg_sensitivity=72.47%, avg_specificity=92.14% avg_auc=90.42%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.121504 Test loss=0.342278 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12310919910669327
[5/24] Train loss=0.1080327257514
[10/24] Train loss=0.11605692654848099
[15/24] Train loss=0.11322633922100067
[20/24] Train loss=0.12178342044353485
Test set avg_accuracy=86.71% avg_sensitivity=72.37%, avg_specificity=92.17% avg_auc=90.41%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.121224 Test loss=0.342330 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=86.56% sen=78.31%, spe=89.71%, auc=92.82%!
Fold[7] Avg_overlap=0.58%(±0.31544825948802635)
[0/24] Train loss=0.7620642781257629
[5/24] Train loss=0.7569224238395691
[10/24] Train loss=0.7522196769714355
[15/24] Train loss=0.7393203973770142
[20/24] Train loss=0.7345602512359619
Test set avg_accuracy=59.75% avg_sensitivity=54.43%, avg_specificity=61.54% avg_auc=59.66%
Best model saved!! Metric=-90.61865297854283!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.742293 Test loss=0.683980 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7097079753875732
[5/24] Train loss=0.7163410782814026
[10/24] Train loss=0.709128737449646
[15/24] Train loss=0.6987961530685425
[20/24] Train loss=0.6938220262527466
Test set avg_accuracy=60.65% avg_sensitivity=71.57%, avg_specificity=56.98% avg_auc=69.37%
Best model saved!! Metric=-67.42789598029222!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.709717 Test loss=0.667785 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6911724805831909
[5/24] Train loss=0.6852955222129822
[10/24] Train loss=0.6816373467445374
[15/24] Train loss=0.6701825857162476
[20/24] Train loss=0.6670281291007996
Test set avg_accuracy=64.21% avg_sensitivity=78.77%, avg_specificity=59.31% avg_auc=75.45%
Best model saved!! Metric=-48.26011331565459!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.680690 Test loss=0.643804 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6596836447715759
[5/24] Train loss=0.6516425609588623
[10/24] Train loss=0.6583042740821838
[15/24] Train loss=0.6454646587371826
[20/24] Train loss=0.6360594630241394
Test set avg_accuracy=67.27% avg_sensitivity=81.25%, avg_specificity=62.57% avg_auc=78.28%
Best model saved!! Metric=-36.63327602248211!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.652289 Test loss=0.621377 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6212391257286072
[5/24] Train loss=0.6267279982566833
[10/24] Train loss=0.6245847344398499
[15/24] Train loss=0.6125062108039856
[20/24] Train loss=0.6111962199211121
Test set avg_accuracy=70.64% avg_sensitivity=81.36%, avg_specificity=67.04% avg_auc=80.53%
Best model saved!! Metric=-26.43413734895111!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.623232 Test loss=0.589957 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5906701683998108
[5/24] Train loss=0.595536470413208
[10/24] Train loss=0.5936325192451477
[15/24] Train loss=0.5851544737815857
[20/24] Train loss=0.5833778977394104
Test set avg_accuracy=72.46% avg_sensitivity=81.87%, avg_specificity=69.30% avg_auc=82.59%
Best model saved!! Metric=-19.77216957493407!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.596119 Test loss=0.562380 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5649668574333191
[5/24] Train loss=0.5752520561218262
[10/24] Train loss=0.5800780057907104
[15/24] Train loss=0.5529342889785767
[20/24] Train loss=0.5462830066680908
Test set avg_accuracy=75.52% avg_sensitivity=82.34%, avg_specificity=73.23% avg_auc=84.54%
Best model saved!! Metric=-10.372995499078371!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.568048 Test loss=0.526236 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5330418944358826
[5/24] Train loss=0.5460759997367859
[10/24] Train loss=0.548102080821991
[15/24] Train loss=0.5315626859664917
[20/24] Train loss=0.5193054676055908
Test set avg_accuracy=77.73% avg_sensitivity=81.72%, avg_specificity=76.40% avg_auc=86.32%
Best model saved!! Metric=-3.832472507039469!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.539635 Test loss=0.496325 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5079663395881653
[5/24] Train loss=0.5096505284309387
[10/24] Train loss=0.5149161219596863
[15/24] Train loss=0.5001540780067444
[20/24] Train loss=0.49266380071640015
Test set avg_accuracy=79.56% avg_sensitivity=81.93%, avg_specificity=78.76% avg_auc=87.68%
Best model saved!! Metric=1.9289311087906071!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.512963 Test loss=0.469869 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4856860935688019
[5/24] Train loss=0.4823170006275177
[10/24] Train loss=0.49143239855766296
[15/24] Train loss=0.48387518525123596
[20/24] Train loss=0.46620097756385803
Test set avg_accuracy=81.32% avg_sensitivity=80.42%, avg_specificity=81.61% avg_auc=88.78%
Best model saved!! Metric=6.131056757525457!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.488133 Test loss=0.443400 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4576718807220459
[5/24] Train loss=0.46451184153556824
[10/24] Train loss=0.4611513614654541
[15/24] Train loss=0.45991140604019165
[20/24] Train loss=0.43827739357948303
Test set avg_accuracy=83.18% avg_sensitivity=78.82%, avg_specificity=84.64% avg_auc=89.67%
Best model saved!! Metric=10.311805432572172!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.463314 Test loss=0.413252 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4389466643333435
[5/24] Train loss=0.4354875683784485
[10/24] Train loss=0.4437465965747833
[15/24] Train loss=0.44104641675949097
[20/24] Train loss=0.41603848338127136
Test set avg_accuracy=84.95% avg_sensitivity=76.54%, avg_specificity=87.77% avg_auc=90.43%
Best model saved!! Metric=13.691285450141862!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.440544 Test loss=0.386919 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4197441041469574
[5/24] Train loss=0.4173819422721863
[10/24] Train loss=0.4243159890174866
[15/24] Train loss=0.42012709379196167
[20/24] Train loss=0.3896758258342743
Test set avg_accuracy=85.89% avg_sensitivity=74.78%, avg_specificity=89.62% avg_auc=90.94%
Best model saved!! Metric=15.218580230383736!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.419168 Test loss=0.366705 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4038005471229553
[5/24] Train loss=0.40100163221359253
[10/24] Train loss=0.4031692147254944
[15/24] Train loss=0.40295201539993286
[20/24] Train loss=0.3751991391181946
Test set avg_accuracy=85.01% avg_sensitivity=78.25%, avg_specificity=87.28% avg_auc=91.37%
Best model saved!! Metric=15.920168533530045!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.403130 Test loss=0.368164 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.38075047731399536
[5/24] Train loss=0.3793492019176483
[10/24] Train loss=0.3922649919986725
[15/24] Train loss=0.38970547914505005
[20/24] Train loss=0.35849660634994507
Test set avg_accuracy=85.46% avg_sensitivity=78.35%, avg_specificity=87.84% avg_auc=91.77%
Best model saved!! Metric=17.415305862012502!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.386598 Test loss=0.356333 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.36976829171180725
[5/24] Train loss=0.3677254021167755
[10/24] Train loss=0.3761134743690491
[15/24] Train loss=0.3715503215789795
[20/24] Train loss=0.343869686126709
Test set avg_accuracy=85.13% avg_sensitivity=79.44%, avg_specificity=87.04% avg_auc=91.75%
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.374241 Test loss=0.356967 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.35170644521713257
[5/24] Train loss=0.3508892357349396
[10/24] Train loss=0.36239364743232727
[15/24] Train loss=0.3612782657146454
[20/24] Train loss=0.330753892660141
Test set avg_accuracy=86.43% avg_sensitivity=78.04%, avg_specificity=89.25% avg_auc=92.35%
Best model saved!! Metric=20.07655555999321!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.359781 Test loss=0.332794 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.34305131435394287
[5/24] Train loss=0.3470122814178467
[10/24] Train loss=0.3492996096611023
[15/24] Train loss=0.3597627878189087
[20/24] Train loss=0.3188909888267517
Test set avg_accuracy=85.46% avg_sensitivity=80.74%, avg_specificity=87.04% avg_auc=92.15%
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.350339 Test loss=0.346965 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.33060887455940247
[5/24] Train loss=0.33806490898132324
[10/24] Train loss=0.33791711926460266
[15/24] Train loss=0.3454015552997589
[20/24] Train loss=0.3152754604816437
Test set avg_accuracy=86.03% avg_sensitivity=79.18%, avg_specificity=88.33% avg_auc=92.62%
Best model saved!! Metric=20.15758186336724!!
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.339852 Test loss=0.329873 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.32784003019332886
[5/24] Train loss=0.3226412236690521
[10/24] Train loss=0.33091267943382263
[15/24] Train loss=0.339854896068573
[20/24] Train loss=0.3015354871749878
Test set avg_accuracy=86.90% avg_sensitivity=72.09%, avg_specificity=91.88% avg_auc=92.99%
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.332938 Test loss=0.309694 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.328472375869751
[5/24] Train loss=0.3151593804359436
[10/24] Train loss=0.32641056180000305
[15/24] Train loss=0.3305041193962097
[20/24] Train loss=0.2921072244644165
Test set avg_accuracy=86.99% avg_sensitivity=74.99%, avg_specificity=91.02% avg_auc=93.00%
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.323768 Test loss=0.309043 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3145090937614441
[5/24] Train loss=0.3133009672164917
[10/24] Train loss=0.32067182660102844
[15/24] Train loss=0.3185865879058838
[20/24] Train loss=0.2852131128311157
Test set avg_accuracy=84.80% avg_sensitivity=82.03%, avg_specificity=85.74% avg_auc=92.19%
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.317869 Test loss=0.353159 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.31234613060951233
[5/24] Train loss=0.3003931939601898
[10/24] Train loss=0.31411686539649963
[15/24] Train loss=0.3143669366836548
[20/24] Train loss=0.28414642810821533
Test set avg_accuracy=86.43% avg_sensitivity=75.19%, avg_specificity=90.21% avg_auc=92.70%
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.310382 Test loss=0.313828 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3032500743865967
[5/24] Train loss=0.29823920130729675
[10/24] Train loss=0.3072216212749481
[15/24] Train loss=0.3012158274650574
[20/24] Train loss=0.27532657980918884
Test set avg_accuracy=84.65% avg_sensitivity=80.84%, avg_specificity=85.93% avg_auc=91.93%
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.304182 Test loss=0.348409 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.30657345056533813
[5/24] Train loss=0.29512473940849304
[10/24] Train loss=0.29876914620399475
[15/24] Train loss=0.299786776304245
[20/24] Train loss=0.2681894302368164
Test set avg_accuracy=84.21% avg_sensitivity=78.51%, avg_specificity=86.12% avg_auc=91.46%
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.297168 Test loss=0.360450 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.29000481963157654
[5/24] Train loss=0.28241845965385437
[10/24] Train loss=0.29973161220550537
[15/24] Train loss=0.2907527983188629
[20/24] Train loss=0.2687247097492218
Test set avg_accuracy=85.85% avg_sensitivity=74.11%, avg_specificity=89.79% avg_auc=91.82%
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.291488 Test loss=0.327295 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2852078378200531
[5/24] Train loss=0.27047184109687805
[10/24] Train loss=0.29102715849876404
[15/24] Train loss=0.28618866205215454
[20/24] Train loss=0.2588565945625305
Test set avg_accuracy=86.94% avg_sensitivity=60.07%, avg_specificity=95.96% avg_auc=91.71%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.282926 Test loss=0.313229 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.28089213371276855
[5/24] Train loss=0.25914400815963745
[10/24] Train loss=0.28632843494415283
[15/24] Train loss=0.29008087515830994
[20/24] Train loss=0.24593430757522583
Test set avg_accuracy=86.72% avg_sensitivity=63.28%, avg_specificity=94.59% avg_auc=91.64%
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.277681 Test loss=0.310106 Current lr=[0.000210185142098938]

[0/24] Train loss=0.26608070731163025
[5/24] Train loss=0.26017990708351135
[10/24] Train loss=0.2751529812812805
[15/24] Train loss=0.27978700399398804
[20/24] Train loss=0.24461650848388672
Test set avg_accuracy=85.60% avg_sensitivity=49.46%, avg_specificity=97.74% avg_auc=91.32%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.270541 Test loss=0.331817 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.26079127192497253
[5/24] Train loss=0.24854473769664764
[10/24] Train loss=0.2737693190574646
[15/24] Train loss=0.27203115820884705
[20/24] Train loss=0.2397974580526352
Test set avg_accuracy=86.46% avg_sensitivity=53.60%, avg_specificity=97.50% avg_auc=91.46%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.264573 Test loss=0.322910 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.25184640288352966
[5/24] Train loss=0.236883282661438
[10/24] Train loss=0.2561188340187073
[15/24] Train loss=0.2544565796852112
[20/24] Train loss=0.23556241393089294
Test set avg_accuracy=86.90% avg_sensitivity=61.57%, avg_specificity=95.41% avg_auc=91.91%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.256363 Test loss=0.307531 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.25292739272117615
[5/24] Train loss=0.23170848190784454
[10/24] Train loss=0.2599666118621826
[15/24] Train loss=0.2570732533931732
[20/24] Train loss=0.2229887694120407
Test set avg_accuracy=86.26% avg_sensitivity=76.59%, avg_specificity=89.51% avg_auc=92.41%
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.252420 Test loss=0.315032 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.24587345123291016
[5/24] Train loss=0.22148777544498444
[10/24] Train loss=0.25326865911483765
[15/24] Train loss=0.2463928759098053
[20/24] Train loss=0.22079332172870636
Test set avg_accuracy=74.70% avg_sensitivity=80.84%, avg_specificity=72.64% avg_auc=84.81%
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.248030 Test loss=0.505897 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.24428388476371765
[5/24] Train loss=0.22268825769424438
[10/24] Train loss=0.26081961393356323
[15/24] Train loss=0.24378889799118042
[20/24] Train loss=0.22062495350837708
Test set avg_accuracy=86.46% avg_sensitivity=55.46%, avg_specificity=96.87% avg_auc=90.77%
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.245240 Test loss=0.332171 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.24532221257686615
[5/24] Train loss=0.21461907029151917
[10/24] Train loss=0.252490758895874
[15/24] Train loss=0.24229057133197784
[20/24] Train loss=0.21528975665569305
Test set avg_accuracy=85.52% avg_sensitivity=75.61%, avg_specificity=88.85% avg_auc=92.08%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.243493 Test loss=0.321068 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.23054292798042297
[5/24] Train loss=0.2343200445175171
[10/24] Train loss=0.243514746427536
[15/24] Train loss=0.24966490268707275
[20/24] Train loss=0.21251539885997772
Test set avg_accuracy=82.98% avg_sensitivity=79.65%, avg_specificity=84.10% avg_auc=90.49%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.240739 Test loss=0.376266 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.22504922747612
[5/24] Train loss=0.22496135532855988
[10/24] Train loss=0.2503007650375366
[15/24] Train loss=0.27613407373428345
[20/24] Train loss=0.21404078602790833
Test set avg_accuracy=84.14% avg_sensitivity=76.80%, avg_specificity=86.61% avg_auc=90.46%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.241268 Test loss=0.358553 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2241903692483902
[5/24] Train loss=0.2087317258119583
[10/24] Train loss=0.24046316742897034
[15/24] Train loss=0.24258166551589966
[20/24] Train loss=0.22700785100460052
Test set avg_accuracy=84.23% avg_sensitivity=46.30%, avg_specificity=96.97% avg_auc=88.38%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.231897 Test loss=0.375404 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2278313934803009
[5/24] Train loss=0.20991957187652588
[10/24] Train loss=0.22203786671161652
[15/24] Train loss=0.2322312593460083
[20/24] Train loss=0.19550639390945435
Test set avg_accuracy=77.84% avg_sensitivity=12.89%, avg_specificity=99.65% avg_auc=73.73%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.227480 Test loss=0.675089 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.22676385939121246
[5/24] Train loss=0.2132427990436554
[10/24] Train loss=0.224302276968956
[15/24] Train loss=0.2285010814666748
[20/24] Train loss=0.20091482996940613
Test set avg_accuracy=85.76% avg_sensitivity=71.41%, avg_specificity=90.57% avg_auc=90.95%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.225639 Test loss=0.325435 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2169513702392578
[5/24] Train loss=0.187997967004776
[10/24] Train loss=0.22461581230163574
[15/24] Train loss=0.220881849527359
[20/24] Train loss=0.20351681113243103
Test set avg_accuracy=86.69% avg_sensitivity=62.51%, avg_specificity=94.82% avg_auc=90.30%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.226528 Test loss=0.323171 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.22611044347286224
[5/24] Train loss=0.19874556362628937
[10/24] Train loss=0.21836209297180176
[15/24] Train loss=0.2262914478778839
[20/24] Train loss=0.19096188247203827
Test set avg_accuracy=84.09% avg_sensitivity=48.01%, avg_specificity=96.21% avg_auc=86.37%
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.219954 Test loss=0.387192 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.216082364320755
[5/24] Train loss=0.18699847161769867
[10/24] Train loss=0.22028592228889465
[15/24] Train loss=0.22039198875427246
[20/24] Train loss=0.20452167093753815
Test set avg_accuracy=79.71% avg_sensitivity=21.44%, avg_specificity=99.29% avg_auc=82.27%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.218418 Test loss=0.525055 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.22295796871185303
[5/24] Train loss=0.1924767941236496
[10/24] Train loss=0.22196131944656372
[15/24] Train loss=0.21791112422943115
[20/24] Train loss=0.19504095613956451
Test set avg_accuracy=82.27% avg_sensitivity=34.65%, avg_specificity=98.26% avg_auc=84.12%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.216832 Test loss=0.470200 Current lr=[0.00029967723776099]

[0/24] Train loss=0.21688269078731537
[5/24] Train loss=0.19209802150726318
[10/24] Train loss=0.20692209899425507
[15/24] Train loss=0.20817497372627258
[20/24] Train loss=0.19324029982089996
Test set avg_accuracy=81.26% avg_sensitivity=31.02%, avg_specificity=98.14% avg_auc=81.08%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.212064 Test loss=0.487576 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.20520955324172974
[5/24] Train loss=0.17973442375659943
[10/24] Train loss=0.21420319378376007
[15/24] Train loss=0.2109259068965912
[20/24] Train loss=0.19768226146697998
Test set avg_accuracy=78.92% avg_sensitivity=17.66%, avg_specificity=99.50% avg_auc=78.04%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.211060 Test loss=0.593076 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2096642404794693
[5/24] Train loss=0.19690664112567902
[10/24] Train loss=0.21144387125968933
[15/24] Train loss=0.2248479276895523
[20/24] Train loss=0.18135173618793488
Test set avg_accuracy=81.04% avg_sensitivity=28.85%, avg_specificity=98.57% avg_auc=85.87%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.211812 Test loss=0.475453 Current lr=[0.000299720220882401]

[0/24] Train loss=0.20110392570495605
[5/24] Train loss=0.18182817101478577
[10/24] Train loss=0.21977511048316956
[15/24] Train loss=0.21020790934562683
[20/24] Train loss=0.18428434431552887
Test set avg_accuracy=84.75% avg_sensitivity=72.81%, avg_specificity=88.76% avg_auc=90.71%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.207140 Test loss=0.337747 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19438767433166504
[5/24] Train loss=0.18301542103290558
[10/24] Train loss=0.20878061652183533
[15/24] Train loss=0.20351669192314148
[20/24] Train loss=0.183252215385437
Test set avg_accuracy=81.89% avg_sensitivity=34.59%, avg_specificity=97.77% avg_auc=82.41%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.204020 Test loss=0.448576 Current lr=[0.000298904600941902]

[0/24] Train loss=0.19791248440742493
[5/24] Train loss=0.19566617906093597
[10/24] Train loss=0.20311135053634644
[15/24] Train loss=0.19953003525733948
[20/24] Train loss=0.17865486443042755
Test set avg_accuracy=81.69% avg_sensitivity=67.37%, avg_specificity=86.50% avg_auc=86.57%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.205389 Test loss=0.397927 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.1918325275182724
[5/24] Train loss=0.18651194870471954
[10/24] Train loss=0.20748454332351685
[15/24] Train loss=0.20788680016994476
[20/24] Train loss=0.1775076985359192
Test set avg_accuracy=85.85% avg_sensitivity=68.93%, avg_specificity=91.53% avg_auc=89.24%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.203994 Test loss=0.340037 Current lr=[0.000297555943323901]

[0/24] Train loss=0.1907329112291336
[5/24] Train loss=0.1886649876832962
[10/24] Train loss=0.22638855874538422
[15/24] Train loss=0.21324633061885834
[20/24] Train loss=0.1809522658586502
Test set avg_accuracy=80.17% avg_sensitivity=23.77%, avg_specificity=99.11% avg_auc=82.65%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.206579 Test loss=0.567454 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.19875679910182953
[5/24] Train loss=0.16706939041614532
[10/24] Train loss=0.19721220433712006
[15/24] Train loss=0.21608833968639374
[20/24] Train loss=0.17462119460105896
Test set avg_accuracy=80.61% avg_sensitivity=27.55%, avg_specificity=98.43% avg_auc=81.63%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.198563 Test loss=0.506845 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.20843589305877686
[5/24] Train loss=0.16960974037647247
[10/24] Train loss=0.19315408170223236
[15/24] Train loss=0.1970157027244568
[20/24] Train loss=0.17070135474205017
Test set avg_accuracy=85.26% avg_sensitivity=75.61%, avg_specificity=88.50% avg_auc=90.28%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.196144 Test loss=0.340883 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.18670208752155304
[5/24] Train loss=0.17762085795402527
[10/24] Train loss=0.18381880223751068
[15/24] Train loss=0.20263825356960297
[20/24] Train loss=0.17263153195381165
Test set avg_accuracy=84.96% avg_sensitivity=50.75%, avg_specificity=96.45% avg_auc=89.75%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.194573 Test loss=0.350051 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.18709076941013336
[5/24] Train loss=0.1767938733100891
[10/24] Train loss=0.1912764310836792
[15/24] Train loss=0.19508731365203857
[20/24] Train loss=0.17649556696414948
Test set avg_accuracy=84.61% avg_sensitivity=45.21%, avg_specificity=97.84% avg_auc=84.88%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.193112 Test loss=0.435314 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.19224123656749725
[5/24] Train loss=0.18435031175613403
[10/24] Train loss=0.19725993275642395
[15/24] Train loss=0.19871290028095245
[20/24] Train loss=0.16742955148220062
Test set avg_accuracy=82.76% avg_sensitivity=37.03%, avg_specificity=98.12% avg_auc=81.37%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.191401 Test loss=0.462789 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.18712416291236877
[5/24] Train loss=0.16712605953216553
[10/24] Train loss=0.19505642354488373
[15/24] Train loss=0.20169001817703247
[20/24] Train loss=0.1716858595609665
Test set avg_accuracy=86.48% avg_sensitivity=64.73%, avg_specificity=93.79% avg_auc=90.05%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.194155 Test loss=0.339224 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.17715321481227875
[5/24] Train loss=0.17000894248485565
[10/24] Train loss=0.19477400183677673
[15/24] Train loss=0.19001848995685577
[20/24] Train loss=0.1737762689590454
Test set avg_accuracy=86.56% avg_sensitivity=61.94%, avg_specificity=94.83% avg_auc=89.37%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.189969 Test loss=0.349872 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.1774718016386032
[5/24] Train loss=0.17094403505325317
[10/24] Train loss=0.18334169685840607
[15/24] Train loss=0.19014622271060944
[20/24] Train loss=0.17408940196037292
Test set avg_accuracy=83.19% avg_sensitivity=39.67%, avg_specificity=97.81% avg_auc=84.20%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.190069 Test loss=0.474408 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.1790219098329544
[5/24] Train loss=0.17846649885177612
[10/24] Train loss=0.19375552237033844
[15/24] Train loss=0.19090715050697327
[20/24] Train loss=0.16677166521549225
Test set avg_accuracy=86.34% avg_sensitivity=68.62%, avg_specificity=92.29% avg_auc=89.52%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.188023 Test loss=0.331188 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.19161425530910492
[5/24] Train loss=0.1728615164756775
[10/24] Train loss=0.18674622476100922
[15/24] Train loss=0.19925294816493988
[20/24] Train loss=0.164335697889328
Test set avg_accuracy=84.97% avg_sensitivity=61.37%, avg_specificity=92.90% avg_auc=88.06%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.188136 Test loss=0.351436 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.16872042417526245
[5/24] Train loss=0.17539387941360474
[10/24] Train loss=0.19491492211818695
[15/24] Train loss=0.19244277477264404
[20/24] Train loss=0.1558438390493393
Test set avg_accuracy=86.58% avg_sensitivity=67.53%, avg_specificity=92.97% avg_auc=89.84%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.184957 Test loss=0.328823 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.1720571666955948
[5/24] Train loss=0.16599220037460327
[10/24] Train loss=0.19519947469234467
[15/24] Train loss=0.19160640239715576
[20/24] Train loss=0.16287745535373688
Test set avg_accuracy=85.74% avg_sensitivity=76.59%, avg_specificity=88.82% avg_auc=90.80%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.183622 Test loss=0.335113 Current lr=[0.000276307469034998]

[0/24] Train loss=0.1746807098388672
[5/24] Train loss=0.17958566546440125
[10/24] Train loss=0.17755743861198425
[15/24] Train loss=0.18780779838562012
[20/24] Train loss=0.16255103051662445
Test set avg_accuracy=80.96% avg_sensitivity=27.34%, avg_specificity=98.97% avg_auc=84.10%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.181976 Test loss=0.505855 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.17042867839336395
[5/24] Train loss=0.1762094497680664
[10/24] Train loss=0.1862630844116211
[15/24] Train loss=0.1879023313522339
[20/24] Train loss=0.1586681455373764
Test set avg_accuracy=85.22% avg_sensitivity=58.73%, avg_specificity=94.12% avg_auc=85.97%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.180709 Test loss=0.383237 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.16922548413276672
[5/24] Train loss=0.16525357961654663
[10/24] Train loss=0.18076258897781372
[15/24] Train loss=0.1999368667602539
[20/24] Train loss=0.15422362089157104
Test set avg_accuracy=85.23% avg_sensitivity=51.11%, avg_specificity=96.70% avg_auc=86.33%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.178734 Test loss=0.400738 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.17666278779506683
[5/24] Train loss=0.15384827554225922
[10/24] Train loss=0.17328143119812012
[15/24] Train loss=0.1884443610906601
[20/24] Train loss=0.1683497130870819
Test set avg_accuracy=83.75% avg_sensitivity=44.17%, avg_specificity=97.04% avg_auc=84.69%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.181026 Test loss=0.439844 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.16729696094989777
[5/24] Train loss=0.167598694562912
[10/24] Train loss=0.1751471906900406
[15/24] Train loss=0.19565501809120178
[20/24] Train loss=0.15186373889446259
Test set avg_accuracy=82.37% avg_sensitivity=36.15%, avg_specificity=97.90% avg_auc=82.99%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.179629 Test loss=0.489151 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.16528171300888062
[5/24] Train loss=0.16600851714611053
[10/24] Train loss=0.17537809908390045
[15/24] Train loss=0.18126584589481354
[20/24] Train loss=0.15575416386127472
Test set avg_accuracy=82.64% avg_sensitivity=70.38%, avg_specificity=86.76% avg_auc=88.05%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.176633 Test loss=0.398686 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.17523065209388733
[5/24] Train loss=0.16218367218971252
[10/24] Train loss=0.1771397888660431
[15/24] Train loss=0.1820606291294098
[20/24] Train loss=0.14638735353946686
Test set avg_accuracy=86.61% avg_sensitivity=59.09%, avg_specificity=95.86% avg_auc=89.12%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.174502 Test loss=0.347219 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.15889792144298553
[5/24] Train loss=0.14990083873271942
[10/24] Train loss=0.17836403846740723
[15/24] Train loss=0.18423739075660706
[20/24] Train loss=0.14898903667926788
Test set avg_accuracy=83.36% avg_sensitivity=81.46%, avg_specificity=84.00% avg_auc=90.00%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.170299 Test loss=0.396151 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.15919886529445648
[5/24] Train loss=0.16395391523838043
[10/24] Train loss=0.17321771383285522
[15/24] Train loss=0.183587908744812
[20/24] Train loss=0.15502998232841492
Test set avg_accuracy=84.82% avg_sensitivity=74.88%, avg_specificity=88.15% avg_auc=90.10%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.172001 Test loss=0.359850 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1626727133989334
[5/24] Train loss=0.16423852741718292
[10/24] Train loss=0.17922258377075195
[15/24] Train loss=0.18938803672790527
[20/24] Train loss=0.15919791162014008
Test set avg_accuracy=85.51% avg_sensitivity=69.29%, avg_specificity=90.95% avg_auc=88.94%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.173887 Test loss=0.359342 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.17517901957035065
[5/24] Train loss=0.14688776433467865
[10/24] Train loss=0.1746838539838791
[15/24] Train loss=0.1780446320772171
[20/24] Train loss=0.1470586210489273
Test set avg_accuracy=85.49% avg_sensitivity=74.42%, avg_specificity=89.22% avg_auc=88.93%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.171079 Test loss=0.358799 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1664106398820877
[5/24] Train loss=0.1584552824497223
[10/24] Train loss=0.16396118700504303
[15/24] Train loss=0.19000983238220215
[20/24] Train loss=0.15002639591693878
Test set avg_accuracy=85.90% avg_sensitivity=70.38%, avg_specificity=91.11% avg_auc=87.97%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.172280 Test loss=0.363390 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.16646721959114075
[5/24] Train loss=0.1699703186750412
[10/24] Train loss=0.17853225767612457
[15/24] Train loss=0.17003190517425537
[20/24] Train loss=0.14880351722240448
Test set avg_accuracy=86.47% avg_sensitivity=70.33%, avg_specificity=91.89% avg_auc=90.19%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.171455 Test loss=0.329947 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.1629859060049057
[5/24] Train loss=0.15084350109100342
[10/24] Train loss=0.1710028350353241
[15/24] Train loss=0.17489773035049438
[20/24] Train loss=0.14412152767181396
Test set avg_accuracy=84.91% avg_sensitivity=48.89%, avg_specificity=97.01% avg_auc=83.94%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.166846 Test loss=0.424318 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.15494593977928162
[5/24] Train loss=0.15125177800655365
[10/24] Train loss=0.16443663835525513
[15/24] Train loss=0.17242449522018433
[20/24] Train loss=0.13945849239826202
Test set avg_accuracy=85.77% avg_sensitivity=76.23%, avg_specificity=88.97% avg_auc=90.24%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.162933 Test loss=0.345776 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.1548546850681305
[5/24] Train loss=0.1541767567396164
[10/24] Train loss=0.162711501121521
[15/24] Train loss=0.17139175534248352
[20/24] Train loss=0.13921184837818146
Test set avg_accuracy=83.95% avg_sensitivity=69.39%, avg_specificity=88.83% avg_auc=88.23%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.166279 Test loss=0.370693 Current lr=[0.000224838296036774]

[0/24] Train loss=0.16858312487602234
[5/24] Train loss=0.14905396103858948
[10/24] Train loss=0.16706813871860504
[15/24] Train loss=0.18097667396068573
[20/24] Train loss=0.14605531096458435
Test set avg_accuracy=83.01% avg_sensitivity=79.85%, avg_specificity=84.07% avg_auc=89.24%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.165070 Test loss=0.399559 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.15739092230796814
[5/24] Train loss=0.15072320401668549
[10/24] Train loss=0.16804558038711548
[15/24] Train loss=0.17016495764255524
[20/24] Train loss=0.1468302458524704
Test set avg_accuracy=84.17% avg_sensitivity=66.29%, avg_specificity=90.17% avg_auc=86.96%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.165919 Test loss=0.381347 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.15834078192710876
[5/24] Train loss=0.1494501531124115
[10/24] Train loss=0.16590824723243713
[15/24] Train loss=0.16742192208766937
[20/24] Train loss=0.14553220570087433
Test set avg_accuracy=84.82% avg_sensitivity=52.36%, avg_specificity=95.72% avg_auc=86.07%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.163389 Test loss=0.399142 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.15822729468345642
[5/24] Train loss=0.14593186974525452
[10/24] Train loss=0.15606458485126495
[15/24] Train loss=0.17100168764591217
[20/24] Train loss=0.15241973102092743
Test set avg_accuracy=86.24% avg_sensitivity=61.26%, avg_specificity=94.63% avg_auc=87.62%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.159746 Test loss=0.361070 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.1584058254957199
[5/24] Train loss=0.14959116280078888
[10/24] Train loss=0.15087920427322388
[15/24] Train loss=0.15967696905136108
[20/24] Train loss=0.1476564258337021
Test set avg_accuracy=86.76% avg_sensitivity=67.32%, avg_specificity=93.29% avg_auc=88.93%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.159329 Test loss=0.344805 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.15616121888160706
[5/24] Train loss=0.15478667616844177
[10/24] Train loss=0.16762518882751465
[15/24] Train loss=0.16491743922233582
[20/24] Train loss=0.14161011576652527
Test set avg_accuracy=86.20% avg_sensitivity=64.73%, avg_specificity=93.41% avg_auc=89.30%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.160543 Test loss=0.340200 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1553729772567749
[5/24] Train loss=0.14391903579235077
[10/24] Train loss=0.15752118825912476
[15/24] Train loss=0.1644950956106186
[20/24] Train loss=0.14265239238739014
Test set avg_accuracy=87.14% avg_sensitivity=73.12%, avg_specificity=91.84% avg_auc=90.04%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.160622 Test loss=0.331297 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1582583338022232
[5/24] Train loss=0.1466904729604721
[10/24] Train loss=0.1514519900083542
[15/24] Train loss=0.16971281170845032
[20/24] Train loss=0.143515482544899
Test set avg_accuracy=86.78% avg_sensitivity=73.59%, avg_specificity=91.22% avg_auc=90.99%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.158605 Test loss=0.320385 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.15479639172554016
[5/24] Train loss=0.14356276392936707
[10/24] Train loss=0.15687136352062225
[15/24] Train loss=0.16201725602149963
[20/24] Train loss=0.13549475371837616
Test set avg_accuracy=86.67% avg_sensitivity=65.30%, avg_specificity=93.84% avg_auc=88.58%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.155297 Test loss=0.347921 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.1550418585538864
[5/24] Train loss=0.13794060051441193
[10/24] Train loss=0.14785802364349365
[15/24] Train loss=0.1535084843635559
[20/24] Train loss=0.13618984818458557
Test set avg_accuracy=84.34% avg_sensitivity=45.47%, avg_specificity=97.39% avg_auc=83.00%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.153149 Test loss=0.438376 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.15326806902885437
[5/24] Train loss=0.13858093321323395
[10/24] Train loss=0.15097875893115997
[15/24] Train loss=0.15850140154361725
[20/24] Train loss=0.13669097423553467
Test set avg_accuracy=86.11% avg_sensitivity=61.99%, avg_specificity=94.21% avg_auc=88.30%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.154629 Test loss=0.356384 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.1506676971912384
[5/24] Train loss=0.14793355762958527
[10/24] Train loss=0.15338613092899323
[15/24] Train loss=0.15564118325710297
[20/24] Train loss=0.1391952633857727
Test set avg_accuracy=86.28% avg_sensitivity=59.24%, avg_specificity=95.36% avg_auc=87.61%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.154000 Test loss=0.363331 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1516873687505722
[5/24] Train loss=0.1395484060049057
[10/24] Train loss=0.14719751477241516
[15/24] Train loss=0.1609097570180893
[20/24] Train loss=0.135329470038414
Test set avg_accuracy=85.98% avg_sensitivity=52.98%, avg_specificity=97.06% avg_auc=85.55%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.150264 Test loss=0.406286 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15112470090389252
[5/24] Train loss=0.1400151252746582
[10/24] Train loss=0.14405779540538788
[15/24] Train loss=0.16408507525920868
[20/24] Train loss=0.1348140835762024
Test set avg_accuracy=86.00% avg_sensitivity=59.40%, avg_specificity=94.94% avg_auc=88.24%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.150222 Test loss=0.362988 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.14590094983577728
[5/24] Train loss=0.13671106100082397
[10/24] Train loss=0.14451849460601807
[15/24] Train loss=0.15191784501075745
[20/24] Train loss=0.12936362624168396
Test set avg_accuracy=84.19% avg_sensitivity=75.50%, avg_specificity=87.11% avg_auc=89.74%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.148199 Test loss=0.379719 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.14744451642036438
[5/24] Train loss=0.12861502170562744
[10/24] Train loss=0.15208859741687775
[15/24] Train loss=0.15889880061149597
[20/24] Train loss=0.13655182719230652
Test set avg_accuracy=83.89% avg_sensitivity=42.41%, avg_specificity=97.83% avg_auc=82.49%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.151979 Test loss=0.482269 Current lr=[0.000156543481933168]

[0/24] Train loss=0.15190058946609497
[5/24] Train loss=0.1384802758693695
[10/24] Train loss=0.13927122950553894
[15/24] Train loss=0.15752729773521423
[20/24] Train loss=0.12839388847351074
Test set avg_accuracy=86.30% avg_sensitivity=62.45%, avg_specificity=94.31% avg_auc=88.35%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.150286 Test loss=0.360160 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.15646111965179443
[5/24] Train loss=0.13282637298107147
[10/24] Train loss=0.1484163999557495
[15/24] Train loss=0.16351500153541565
[20/24] Train loss=0.13786710798740387
Test set avg_accuracy=80.76% avg_sensitivity=26.31%, avg_specificity=99.04% avg_auc=74.67%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.150402 Test loss=0.599421 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.14738729596138
[5/24] Train loss=0.1415308266878128
[10/24] Train loss=0.14442294836044312
[15/24] Train loss=0.1506405621767044
[20/24] Train loss=0.1362450122833252
Test set avg_accuracy=87.04% avg_sensitivity=65.20%, avg_specificity=94.38% avg_auc=89.70%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.150335 Test loss=0.335682 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.14552761614322662
[5/24] Train loss=0.13858948647975922
[10/24] Train loss=0.1404908001422882
[15/24] Train loss=0.1601284146308899
[20/24] Train loss=0.13333991169929504
Test set avg_accuracy=85.36% avg_sensitivity=51.73%, avg_specificity=96.66% avg_auc=87.11%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.149099 Test loss=0.387819 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.14518480002880096
[5/24] Train loss=0.14061172306537628
[10/24] Train loss=0.14564771950244904
[15/24] Train loss=0.1517535001039505
[20/24] Train loss=0.1355368047952652
Test set avg_accuracy=86.39% avg_sensitivity=66.91%, avg_specificity=92.94% avg_auc=88.98%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.148404 Test loss=0.350107 Current lr=[0.000134135431043539]

[0/24] Train loss=0.14858151972293854
[5/24] Train loss=0.13286462426185608
[10/24] Train loss=0.13803508877754211
[15/24] Train loss=0.14824919402599335
[20/24] Train loss=0.12764893472194672
Test set avg_accuracy=86.42% avg_sensitivity=71.83%, avg_specificity=91.32% avg_auc=91.05%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.146129 Test loss=0.335648 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.13823378086090088
[5/24] Train loss=0.13077393174171448
[10/24] Train loss=0.14329126477241516
[15/24] Train loss=0.14996536076068878
[20/24] Train loss=0.13450148701667786
Test set avg_accuracy=85.68% avg_sensitivity=61.52%, avg_specificity=93.79% avg_auc=87.23%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.146570 Test loss=0.371026 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1579936146736145
[5/24] Train loss=0.13679549098014832
[10/24] Train loss=0.13923175632953644
[15/24] Train loss=0.1536233276128769
[20/24] Train loss=0.13097773492336273
Test set avg_accuracy=86.95% avg_sensitivity=70.64%, avg_specificity=92.43% avg_auc=89.40%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.146608 Test loss=0.339623 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.14705424010753632
[5/24] Train loss=0.13225947320461273
[10/24] Train loss=0.14930470287799835
[15/24] Train loss=0.1480027139186859
[20/24] Train loss=0.12854449450969696
Test set avg_accuracy=85.59% avg_sensitivity=78.15%, avg_specificity=88.08% avg_auc=90.01%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.145271 Test loss=0.359997 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14569801092147827
[5/24] Train loss=0.13251452147960663
[10/24] Train loss=0.1391831636428833
[15/24] Train loss=0.15150275826454163
[20/24] Train loss=0.12499500066041946
Test set avg_accuracy=84.40% avg_sensitivity=80.53%, avg_specificity=85.70% avg_auc=89.82%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.144386 Test loss=0.383000 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14153799414634705
[5/24] Train loss=0.1350117176771164
[10/24] Train loss=0.14273856580257416
[15/24] Train loss=0.14474037289619446
[20/24] Train loss=0.13244977593421936
Test set avg_accuracy=84.70% avg_sensitivity=78.04%, avg_specificity=86.94% avg_auc=90.28%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.143182 Test loss=0.365496 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.14106976985931396
[5/24] Train loss=0.13106513023376465
[10/24] Train loss=0.1359623819589615
[15/24] Train loss=0.14690250158309937
[20/24] Train loss=0.12589433789253235
Test set avg_accuracy=86.15% avg_sensitivity=77.37%, avg_specificity=89.09% avg_auc=90.06%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.140609 Test loss=0.343338 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.13857464492321014
[5/24] Train loss=0.1301158368587494
[10/24] Train loss=0.13362163305282593
[15/24] Train loss=0.14103752374649048
[20/24] Train loss=0.12339922785758972
Test set avg_accuracy=84.74% avg_sensitivity=78.72%, avg_specificity=86.76% avg_auc=90.17%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.138582 Test loss=0.373078 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14019839465618134
[5/24] Train loss=0.12743394076824188
[10/24] Train loss=0.14550136029720306
[15/24] Train loss=0.14256152510643005
[20/24] Train loss=0.12562771141529083
Test set avg_accuracy=86.37% avg_sensitivity=73.02%, avg_specificity=90.85% avg_auc=90.61%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.139381 Test loss=0.333804 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.13781628012657166
[5/24] Train loss=0.129014790058136
[10/24] Train loss=0.13821002840995789
[15/24] Train loss=0.1417187750339508
[20/24] Train loss=0.1260247528553009
Test set avg_accuracy=83.76% avg_sensitivity=82.60%, avg_specificity=84.15% avg_auc=90.18%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.139653 Test loss=0.394163 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1388838142156601
[5/24] Train loss=0.1285325288772583
[10/24] Train loss=0.13429908454418182
[15/24] Train loss=0.14019230008125305
[20/24] Train loss=0.12411490082740784
Test set avg_accuracy=86.18% avg_sensitivity=78.87%, avg_specificity=88.64% avg_auc=90.64%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.138365 Test loss=0.347412 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.13272374868392944
[5/24] Train loss=0.1312279999256134
[10/24] Train loss=0.13409201800823212
[15/24] Train loss=0.1386823058128357
[20/24] Train loss=0.12452969700098038
Test set avg_accuracy=86.94% avg_sensitivity=77.32%, avg_specificity=90.17% avg_auc=90.44%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.139383 Test loss=0.333709 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13685297966003418
[5/24] Train loss=0.13103841245174408
[10/24] Train loss=0.13151127099990845
[15/24] Train loss=0.13886824250221252
[20/24] Train loss=0.12241654098033905
Test set avg_accuracy=84.41% avg_sensitivity=78.87%, avg_specificity=86.28% avg_auc=89.75%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.137419 Test loss=0.383265 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13839510083198547
[5/24] Train loss=0.12484709173440933
[10/24] Train loss=0.13485611975193024
[15/24] Train loss=0.13501518964767456
[20/24] Train loss=0.11881042271852493
Test set avg_accuracy=86.52% avg_sensitivity=75.61%, avg_specificity=90.19% avg_auc=91.11%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.135751 Test loss=0.328981 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13377726078033447
[5/24] Train loss=0.12330503016710281
[10/24] Train loss=0.13352139294147491
[15/24] Train loss=0.13398155570030212
[20/24] Train loss=0.1167815551161766
Test set avg_accuracy=79.51% avg_sensitivity=86.02%, avg_specificity=77.32% avg_auc=88.27%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.134517 Test loss=0.484190 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1331324726343155
[5/24] Train loss=0.12579356133937836
[10/24] Train loss=0.13139033317565918
[15/24] Train loss=0.14681686460971832
[20/24] Train loss=0.1201648935675621
Test set avg_accuracy=85.82% avg_sensitivity=76.80%, avg_specificity=88.85% avg_auc=90.02%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.135549 Test loss=0.358422 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.13017885386943817
[5/24] Train loss=0.12395425140857697
[10/24] Train loss=0.12760749459266663
[15/24] Train loss=0.13747872412204742
[20/24] Train loss=0.11728334426879883
Test set avg_accuracy=86.55% avg_sensitivity=73.90%, avg_specificity=90.80% avg_auc=89.40%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.133975 Test loss=0.344875 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1307494044303894
[5/24] Train loss=0.12389083206653595
[10/24] Train loss=0.13037872314453125
[15/24] Train loss=0.13440150022506714
[20/24] Train loss=0.11522307246923447
Test set avg_accuracy=87.01% avg_sensitivity=67.58%, avg_specificity=93.53% avg_auc=89.66%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.133106 Test loss=0.338088 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.12912386655807495
[5/24] Train loss=0.12255024909973145
[10/24] Train loss=0.13140611350536346
[15/24] Train loss=0.1368611454963684
[20/24] Train loss=0.12011802196502686
Test set avg_accuracy=86.32% avg_sensitivity=75.14%, avg_specificity=90.07% avg_auc=90.96%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.132641 Test loss=0.335171 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1339666098356247
[5/24] Train loss=0.11927737295627594
[10/24] Train loss=0.1262422651052475
[15/24] Train loss=0.13557948172092438
[20/24] Train loss=0.11694592982530594
Test set avg_accuracy=86.67% avg_sensitivity=66.08%, avg_specificity=93.58% avg_auc=89.64%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.131635 Test loss=0.337455 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.13115070760250092
[5/24] Train loss=0.12137338519096375
[10/24] Train loss=0.1299155205488205
[15/24] Train loss=0.1327471137046814
[20/24] Train loss=0.11805803328752518
Test set avg_accuracy=86.15% avg_sensitivity=73.59%, avg_specificity=90.36% avg_auc=89.89%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.132191 Test loss=0.346548 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13023343682289124
[5/24] Train loss=0.1203853189945221
[10/24] Train loss=0.12922032177448273
[15/24] Train loss=0.13590091466903687
[20/24] Train loss=0.11354942619800568
Test set avg_accuracy=87.24% avg_sensitivity=65.56%, avg_specificity=94.52% avg_auc=90.19%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.129907 Test loss=0.323657 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12837804853916168
[5/24] Train loss=0.11809737235307693
[10/24] Train loss=0.12717188894748688
[15/24] Train loss=0.13747826218605042
[20/24] Train loss=0.1114497035741806
Test set avg_accuracy=86.94% avg_sensitivity=73.28%, avg_specificity=91.53% avg_auc=90.04%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.129856 Test loss=0.335483 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13011936843395233
[5/24] Train loss=0.11855949461460114
[10/24] Train loss=0.1247330904006958
[15/24] Train loss=0.131321981549263
[20/24] Train loss=0.11385273188352585
Test set avg_accuracy=86.37% avg_sensitivity=66.55%, avg_specificity=93.02% avg_auc=89.00%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.128547 Test loss=0.343550 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1263328194618225
[5/24] Train loss=0.12069550156593323
[10/24] Train loss=0.12071505188941956
[15/24] Train loss=0.13101014494895935
[20/24] Train loss=0.11549495905637741
Test set avg_accuracy=86.72% avg_sensitivity=69.86%, avg_specificity=92.38% avg_auc=90.23%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.128150 Test loss=0.331447 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12468929588794708
[5/24] Train loss=0.11697569489479065
[10/24] Train loss=0.12367015331983566
[15/24] Train loss=0.12941411137580872
[20/24] Train loss=0.11494790017604828
Test set avg_accuracy=86.26% avg_sensitivity=74.88%, avg_specificity=90.09% avg_auc=90.13%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.127198 Test loss=0.339368 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12685345113277435
[5/24] Train loss=0.11711372435092926
[10/24] Train loss=0.12676388025283813
[15/24] Train loss=0.13268497586250305
[20/24] Train loss=0.11570415645837784
Test set avg_accuracy=86.82% avg_sensitivity=75.09%, avg_specificity=90.76% avg_auc=90.63%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.126422 Test loss=0.330250 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12433475255966187
[5/24] Train loss=0.1152867004275322
[10/24] Train loss=0.12032651156187057
[15/24] Train loss=0.1309453547000885
[20/24] Train loss=0.11161071807146072
Test set avg_accuracy=86.95% avg_sensitivity=73.54%, avg_specificity=91.46% avg_auc=90.00%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.126046 Test loss=0.334181 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12423501908779144
[5/24] Train loss=0.11482888460159302
[10/24] Train loss=0.12094787508249283
[15/24] Train loss=0.1282191276550293
[20/24] Train loss=0.11318134516477585
Test set avg_accuracy=86.65% avg_sensitivity=72.86%, avg_specificity=91.29% avg_auc=89.72%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.126039 Test loss=0.340185 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1266324520111084
[5/24] Train loss=0.1162121593952179
[10/24] Train loss=0.12260273844003677
[15/24] Train loss=0.12903203070163727
[20/24] Train loss=0.11450012773275375
Test set avg_accuracy=86.51% avg_sensitivity=72.50%, avg_specificity=91.22% avg_auc=89.80%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.126216 Test loss=0.339056 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12732870876789093
[5/24] Train loss=0.11806860566139221
[10/24] Train loss=0.1223757416009903
[15/24] Train loss=0.1252404898405075
[20/24] Train loss=0.11306796967983246
Test set avg_accuracy=86.88% avg_sensitivity=73.80%, avg_specificity=91.27% avg_auc=90.49%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.125678 Test loss=0.328470 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12718139588832855
[5/24] Train loss=0.11366786062717438
[10/24] Train loss=0.1198284924030304
[15/24] Train loss=0.12889552116394043
[20/24] Train loss=0.1084476187825203
Test set avg_accuracy=86.59% avg_sensitivity=73.80%, avg_specificity=90.89% avg_auc=90.16%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.124286 Test loss=0.336086 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12371841073036194
[5/24] Train loss=0.11451099067926407
[10/24] Train loss=0.11877644062042236
[15/24] Train loss=0.12637145817279816
[20/24] Train loss=0.11061171442270279
Test set avg_accuracy=87.17% avg_sensitivity=73.59%, avg_specificity=91.74% avg_auc=90.07%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.123154 Test loss=0.329304 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.11851945519447327
[5/24] Train loss=0.11570145934820175
[10/24] Train loss=0.12006691843271255
[15/24] Train loss=0.12673155963420868
[20/24] Train loss=0.1098826453089714
Test set avg_accuracy=86.78% avg_sensitivity=73.07%, avg_specificity=91.39% avg_auc=90.03%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.122851 Test loss=0.333877 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12162656337022781
[5/24] Train loss=0.11371958255767822
[10/24] Train loss=0.1167350485920906
[15/24] Train loss=0.12575975060462952
[20/24] Train loss=0.10915011167526245
Test set avg_accuracy=86.77% avg_sensitivity=72.81%, avg_specificity=91.46% avg_auc=89.93%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.121585 Test loss=0.334789 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12153539806604385
[5/24] Train loss=0.11051903665065765
[10/24] Train loss=0.12114982306957245
[15/24] Train loss=0.12494300305843353
[20/24] Train loss=0.10781172662973404
Test set avg_accuracy=86.95% avg_sensitivity=73.38%, avg_specificity=91.51% avg_auc=90.25%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.121360 Test loss=0.330458 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1237882599234581
[5/24] Train loss=0.112205371260643
[10/24] Train loss=0.11794756352901459
[15/24] Train loss=0.12478329241275787
[20/24] Train loss=0.10536996275186539
Test set avg_accuracy=86.76% avg_sensitivity=72.92%, avg_specificity=91.41% avg_auc=89.87%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.121324 Test loss=0.334248 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12427560240030289
[5/24] Train loss=0.11105265468358994
[10/24] Train loss=0.11682227998971939
[15/24] Train loss=0.1254645138978958
[20/24] Train loss=0.1069340929389
Test set avg_accuracy=86.81% avg_sensitivity=72.71%, avg_specificity=91.55% avg_auc=90.12%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.120817 Test loss=0.331679 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1205965131521225
[5/24] Train loss=0.11162958294153214
[10/24] Train loss=0.11648339033126831
[15/24] Train loss=0.1245737075805664
[20/24] Train loss=0.10845287889242172
Test set avg_accuracy=86.71% avg_sensitivity=71.62%, avg_specificity=91.77% avg_auc=89.85%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.120326 Test loss=0.333396 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12085424363613129
[5/24] Train loss=0.11091196537017822
[10/24] Train loss=0.11679298430681229
[15/24] Train loss=0.12322449684143066
[20/24] Train loss=0.10911210626363754
Test set avg_accuracy=86.97% avg_sensitivity=73.43%, avg_specificity=91.51% avg_auc=90.14%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.121018 Test loss=0.331117 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12056615203619003
[5/24] Train loss=0.10985337197780609
[10/24] Train loss=0.11677525192499161
[15/24] Train loss=0.12320418655872345
[20/24] Train loss=0.10680574178695679
Test set avg_accuracy=86.76% avg_sensitivity=72.81%, avg_specificity=91.44% avg_auc=90.25%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.119986 Test loss=0.331069 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12169893085956573
[5/24] Train loss=0.11086957156658173
[10/24] Train loss=0.11784792691469193
[15/24] Train loss=0.12298636883497238
[20/24] Train loss=0.1056424006819725
Test set avg_accuracy=86.90% avg_sensitivity=73.69%, avg_specificity=91.34% avg_auc=90.23%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.120065 Test loss=0.331981 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12011361122131348
[5/24] Train loss=0.11087282747030258
[10/24] Train loss=0.11527025699615479
[15/24] Train loss=0.1233680322766304
[20/24] Train loss=0.10943954437971115
Test set avg_accuracy=86.86% avg_sensitivity=72.76%, avg_specificity=91.60% avg_auc=90.01%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.119976 Test loss=0.330913 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12065041065216064
[5/24] Train loss=0.11044720560312271
[10/24] Train loss=0.11575235426425934
[15/24] Train loss=0.12207291275262833
[20/24] Train loss=0.1078653410077095
Test set avg_accuracy=86.86% avg_sensitivity=72.66%, avg_specificity=91.63% avg_auc=90.10%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.120227 Test loss=0.330500 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12162937223911285
[5/24] Train loss=0.11040099710226059
[10/24] Train loss=0.1174374595284462
[15/24] Train loss=0.12078128755092621
[20/24] Train loss=0.1087198331952095
Test set avg_accuracy=86.88% avg_sensitivity=73.33%, avg_specificity=91.42% avg_auc=90.10%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.119943 Test loss=0.332301 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12070593237876892
[5/24] Train loss=0.11175443232059479
[10/24] Train loss=0.11519370973110199
[15/24] Train loss=0.1229880079627037
[20/24] Train loss=0.10739655792713165
Test set avg_accuracy=86.82% avg_sensitivity=73.02%, avg_specificity=91.46% avg_auc=90.08%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.119775 Test loss=0.331888 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11983632296323776
[5/24] Train loss=0.11004184931516647
[10/24] Train loss=0.11355956643819809
[15/24] Train loss=0.1225958913564682
[20/24] Train loss=0.10825280100107193
Test set avg_accuracy=86.85% avg_sensitivity=72.86%, avg_specificity=91.55% avg_auc=90.06%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.120124 Test loss=0.331823 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11930828541517258
[5/24] Train loss=0.10957329720258713
[10/24] Train loss=0.11453244835138321
[15/24] Train loss=0.12210734188556671
[20/24] Train loss=0.10672985762357712
Test set avg_accuracy=86.86% avg_sensitivity=72.92%, avg_specificity=91.55% avg_auc=90.06%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.119216 Test loss=0.331715 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12044377624988556
[5/24] Train loss=0.11017467826604843
[10/24] Train loss=0.11729692667722702
[15/24] Train loss=0.12292411178350449
[20/24] Train loss=0.10806241631507874
Test set avg_accuracy=86.84% avg_sensitivity=72.92%, avg_specificity=91.51% avg_auc=90.06%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.120265 Test loss=0.332113 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=86.03% sen=79.18%, spe=88.33%, auc=92.62%!
Fold[8] Avg_overlap=0.50%(±0.306192160436703)
[0/23] Train loss=0.7322067022323608
[5/23] Train loss=0.7176839709281921
[10/23] Train loss=0.7230435609817505
[15/23] Train loss=0.7039702534675598
[20/23] Train loss=0.6937304735183716
Test set avg_accuracy=62.45% avg_sensitivity=49.38%, avg_specificity=66.61% avg_auc=62.70%
Best model saved!! Metric=-84.86684566226685!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.712869 Test loss=0.648119 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.6871694326400757
[5/23] Train loss=0.6912839412689209
[10/23] Train loss=0.6838220357894897
[15/23] Train loss=0.6665752530097961
[20/23] Train loss=0.66547030210495
Test set avg_accuracy=66.56% avg_sensitivity=69.38%, avg_specificity=65.67% avg_auc=73.54%
Best model saved!! Metric=-50.853702584361955!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.679685 Test loss=0.622188 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.6575307846069336
[5/23] Train loss=0.6569141149520874
[10/23] Train loss=0.6557313799858093
[15/23] Train loss=0.6450761556625366
[20/23] Train loss=0.6343280076980591
Test set avg_accuracy=69.74% avg_sensitivity=72.24%, avg_specificity=68.94% avg_auc=76.85%
Best model saved!! Metric=-38.23069534741583!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.652413 Test loss=0.594974 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.6428250670433044
[5/23] Train loss=0.6311672925949097
[10/23] Train loss=0.6317628026008606
[15/23] Train loss=0.6081324815750122
[20/23] Train loss=0.6149532794952393
Test set avg_accuracy=72.25% avg_sensitivity=74.02%, avg_specificity=71.69% avg_auc=79.48%
Best model saved!! Metric=-28.555683375413082!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.628037 Test loss=0.563999 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.6102051138877869
[5/23] Train loss=0.60849928855896
[10/23] Train loss=0.6088514924049377
[15/23] Train loss=0.590332567691803
[20/23] Train loss=0.5893588066101074
Test set avg_accuracy=73.63% avg_sensitivity=76.28%, avg_specificity=72.79% avg_auc=81.26%
Best model saved!! Metric=-22.04022985160742!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.601920 Test loss=0.541793 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.582388162612915
[5/23] Train loss=0.5889981985092163
[10/23] Train loss=0.5873262286186218
[15/23] Train loss=0.5624442100524902
[20/23] Train loss=0.5647532939910889
Test set avg_accuracy=74.62% avg_sensitivity=78.54%, avg_specificity=73.37% avg_auc=82.60%
Best model saved!! Metric=-16.863642365248424!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.577669 Test loss=0.525589 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.5614897608757019
[5/23] Train loss=0.5629124641418457
[10/23] Train loss=0.5623744130134583
[15/23] Train loss=0.5391731262207031
[20/23] Train loss=0.5432162880897522
Test set avg_accuracy=77.30% avg_sensitivity=76.28%, avg_specificity=77.63% avg_auc=84.06%
Best model saved!! Metric=-10.728980928906907!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.554677 Test loss=0.492056 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.536241888999939
[5/23] Train loss=0.5335071086883545
[10/23] Train loss=0.5358750820159912
[15/23] Train loss=0.520812451839447
[20/23] Train loss=0.5190376043319702
Test set avg_accuracy=78.52% avg_sensitivity=76.55%, avg_specificity=79.14% avg_auc=85.53%
Best model saved!! Metric=-6.261173584038033!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.531956 Test loss=0.475201 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.5161443948745728
[5/23] Train loss=0.5160475969314575
[10/23] Train loss=0.5143301486968994
[15/23] Train loss=0.4919719398021698
[20/23] Train loss=0.4934835731983185
Test set avg_accuracy=80.55% avg_sensitivity=74.29%, avg_specificity=82.54% avg_auc=86.81%
Best model saved!! Metric=-1.8142785925407452!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.508216 Test loss=0.446430 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.4921151101589203
[5/23] Train loss=0.49063634872436523
[10/23] Train loss=0.48604050278663635
[15/23] Train loss=0.470401406288147
[20/23] Train loss=0.4631054103374481
Test set avg_accuracy=82.32% avg_sensitivity=72.51%, avg_specificity=85.44% avg_auc=87.88%
Best model saved!! Metric=2.143864297379011!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.483138 Test loss=0.421764 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.46044600009918213
[5/23] Train loss=0.4714288115501404
[10/23] Train loss=0.4632514417171478
[15/23] Train loss=0.4414226710796356
[20/23] Train loss=0.4394352436065674
Test set avg_accuracy=83.18% avg_sensitivity=74.12%, avg_specificity=86.06% avg_auc=88.55%
Best model saved!! Metric=5.910551630361439!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.460471 Test loss=0.410407 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.4448348581790924
[5/23] Train loss=0.4486633837223053
[10/23] Train loss=0.4395979046821594
[15/23] Train loss=0.41870996356010437
[20/23] Train loss=0.4180866479873657
Test set avg_accuracy=84.19% avg_sensitivity=71.32%, avg_specificity=88.29% avg_auc=89.24%
Best model saved!! Metric=7.045297901025322!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.437551 Test loss=0.388811 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.4199068546295166
[5/23] Train loss=0.42819833755493164
[10/23] Train loss=0.421611487865448
[15/23] Train loss=0.40408003330230713
[20/23] Train loss=0.40170711278915405
Test set avg_accuracy=85.01% avg_sensitivity=66.52%, avg_specificity=90.90% avg_auc=89.58%
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.418545 Test loss=0.368775 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.4057679772377014
[5/23] Train loss=0.41018784046173096
[10/23] Train loss=0.4042243957519531
[15/23] Train loss=0.3859224021434784
[20/23] Train loss=0.3786681294441223
Test set avg_accuracy=85.48% avg_sensitivity=66.15%, avg_specificity=91.64% avg_auc=90.06%
Best model saved!! Metric=7.32406691283083!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.400035 Test loss=0.356011 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.3828824758529663
[5/23] Train loss=0.3890332281589508
[10/23] Train loss=0.389679491519928
[15/23] Train loss=0.3661109507083893
[20/23] Train loss=0.3605390191078186
Test set avg_accuracy=85.83% avg_sensitivity=68.46%, avg_specificity=91.36% avg_auc=90.62%
Best model saved!! Metric=10.285807217858391!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.383290 Test loss=0.348133 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.3720620572566986
[5/23] Train loss=0.374655544757843
[10/23] Train loss=0.3735281825065613
[15/23] Train loss=0.357892781496048
[20/23] Train loss=0.3508135974407196
Test set avg_accuracy=85.18% avg_sensitivity=72.83%, avg_specificity=89.12% avg_auc=91.03%
Best model saved!! Metric=12.160378961184449!!
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.369834 Test loss=0.347266 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.3496280014514923
[5/23] Train loss=0.3597679138183594
[10/23] Train loss=0.3601747155189514
[15/23] Train loss=0.3432143032550812
[20/23] Train loss=0.3389194905757904
Test set avg_accuracy=86.09% avg_sensitivity=66.42%, avg_specificity=92.36% avg_auc=91.17%
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.356230 Test loss=0.331393 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.3367181122303009
[5/23] Train loss=0.34689441323280334
[10/23] Train loss=0.3481011986732483
[15/23] Train loss=0.32646694779396057
[20/23] Train loss=0.32254117727279663
Test set avg_accuracy=85.42% avg_sensitivity=73.42%, avg_specificity=89.24% avg_auc=91.47%
Best model saved!! Metric=13.544838988312122!!
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.344684 Test loss=0.336740 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.331898957490921
[5/23] Train loss=0.33932435512542725
[10/23] Train loss=0.33853253722190857
[15/23] Train loss=0.3164101839065552
[20/23] Train loss=0.32102492451667786
Test set avg_accuracy=86.45% avg_sensitivity=70.62%, avg_specificity=91.48% avg_auc=91.75%
Best model saved!! Metric=14.299343479952114!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.335384 Test loss=0.321759 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.31998786330223083
[5/23] Train loss=0.3311583995819092
[10/23] Train loss=0.3328312635421753
[15/23] Train loss=0.3052965998649597
[20/23] Train loss=0.3067055344581604
Test set avg_accuracy=85.91% avg_sensitivity=70.46%, avg_specificity=90.83% avg_auc=91.85%
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.326677 Test loss=0.322311 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.3174339234828949
[5/23] Train loss=0.3263905346393585
[10/23] Train loss=0.3209167420864105
[15/23] Train loss=0.2922971844673157
[20/23] Train loss=0.3022304177284241
Test set avg_accuracy=86.33% avg_sensitivity=63.07%, avg_specificity=93.73% avg_auc=91.75%
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.319589 Test loss=0.313743 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.3172917068004608
[5/23] Train loss=0.32808953523635864
[10/23] Train loss=0.315362811088562
[15/23] Train loss=0.2916141152381897
[20/23] Train loss=0.2931146025657654
Test set avg_accuracy=85.87% avg_sensitivity=57.41%, avg_specificity=94.94% avg_auc=91.38%
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.313166 Test loss=0.320610 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.30131182074546814
[5/23] Train loss=0.3103199899196625
[10/23] Train loss=0.31019720435142517
[15/23] Train loss=0.27696990966796875
[20/23] Train loss=0.2876867651939392
Test set avg_accuracy=86.22% avg_sensitivity=59.35%, avg_specificity=94.78% avg_auc=90.98%
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.305357 Test loss=0.322262 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.2936433255672455
[5/23] Train loss=0.3112882077693939
[10/23] Train loss=0.2960617244243622
[15/23] Train loss=0.27305883169174194
[20/23] Train loss=0.2785802483558655
Test set avg_accuracy=85.92% avg_sensitivity=54.77%, avg_specificity=95.85% avg_auc=91.35%
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.299026 Test loss=0.324576 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.28605854511260986
[5/23] Train loss=0.30402839183807373
[10/23] Train loss=0.2929868996143341
[15/23] Train loss=0.2666011452674866
[20/23] Train loss=0.2740209698677063
Test set avg_accuracy=84.39% avg_sensitivity=43.83%, avg_specificity=97.30% avg_auc=89.56%
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.293012 Test loss=0.365698 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.2765829563140869
[5/23] Train loss=0.29335346817970276
[10/23] Train loss=0.29096388816833496
[15/23] Train loss=0.26019272208213806
[20/23] Train loss=0.26574721932411194
Test set avg_accuracy=85.74% avg_sensitivity=52.72%, avg_specificity=96.26% avg_auc=90.31%
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.287507 Test loss=0.343503 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.26995858550071716
[5/23] Train loss=0.29141685366630554
[10/23] Train loss=0.2860683500766754
[15/23] Train loss=0.26977279782295227
[20/23] Train loss=0.2675665020942688
Test set avg_accuracy=86.07% avg_sensitivity=64.04%, avg_specificity=93.08% avg_auc=91.71%
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.283143 Test loss=0.310988 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.27029791474342346
[5/23] Train loss=0.2837206721305847
[10/23] Train loss=0.27221742272377014
[15/23] Train loss=0.25142598152160645
[20/23] Train loss=0.26006460189819336
Test set avg_accuracy=85.85% avg_sensitivity=53.10%, avg_specificity=96.27% avg_auc=90.76%
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.277742 Test loss=0.337001 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.26394644379615784
[5/23] Train loss=0.2722699046134949
[10/23] Train loss=0.2509821057319641
[15/23] Train loss=0.24751126766204834
[20/23] Train loss=0.2557850480079651
Test set avg_accuracy=85.73% avg_sensitivity=58.65%, avg_specificity=94.35% avg_auc=91.07%
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.269569 Test loss=0.320199 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.2558867633342743
[5/23] Train loss=0.26158374547958374
[10/23] Train loss=0.2517210841178894
[15/23] Train loss=0.2430759221315384
[20/23] Train loss=0.24714063107967377
Test set avg_accuracy=84.84% avg_sensitivity=45.82%, avg_specificity=97.27% avg_auc=89.34%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.265579 Test loss=0.365381 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.2529315650463104
[5/23] Train loss=0.2677392363548279
[10/23] Train loss=0.27217233180999756
[15/23] Train loss=0.22681665420532227
[20/23] Train loss=0.24124334752559662
Test set avg_accuracy=86.65% avg_sensitivity=58.17%, avg_specificity=95.73% avg_auc=91.25%
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.264735 Test loss=0.316298 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.24165377020835876
[5/23] Train loss=0.24603544175624847
[10/23] Train loss=0.257245272397995
[15/23] Train loss=0.2281586080789566
[20/23] Train loss=0.24262899160385132
Test set avg_accuracy=84.99% avg_sensitivity=45.50%, avg_specificity=97.56% avg_auc=88.81%
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.253632 Test loss=0.364861 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.24239510297775269
[5/23] Train loss=0.23320873081684113
[10/23] Train loss=0.2542356550693512
[15/23] Train loss=0.23691843450069427
[20/23] Train loss=0.23270894587039948
Test set avg_accuracy=85.55% avg_sensitivity=48.89%, avg_specificity=97.22% avg_auc=88.50%
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.250294 Test loss=0.370236 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.22732806205749512
[5/23] Train loss=0.23443175852298737
[10/23] Train loss=0.25539660453796387
[15/23] Train loss=0.22362108528614044
[20/23] Train loss=0.22122767567634583
Test set avg_accuracy=75.78% avg_sensitivity=78.06%, avg_specificity=75.06% avg_auc=84.78%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.246138 Test loss=0.485231 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.23636004328727722
[5/23] Train loss=0.21970917284488678
[10/23] Train loss=0.24752692878246307
[15/23] Train loss=0.23061828315258026
[20/23] Train loss=0.2240804135799408
Test set avg_accuracy=85.00% avg_sensitivity=64.74%, avg_specificity=91.45% avg_auc=90.16%
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.243660 Test loss=0.329434 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.24031896889209747
[5/23] Train loss=0.2464430332183838
[10/23] Train loss=0.2561730742454529
[15/23] Train loss=0.22040463984012604
[20/23] Train loss=0.22465920448303223
Test set avg_accuracy=84.82% avg_sensitivity=45.07%, avg_specificity=97.48% avg_auc=88.79%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.242404 Test loss=0.370431 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.22258922457695007
[5/23] Train loss=0.22310028970241547
[10/23] Train loss=0.2400282919406891
[15/23] Train loss=0.21937061846256256
[20/23] Train loss=0.22096943855285645
Test set avg_accuracy=84.44% avg_sensitivity=41.78%, avg_specificity=98.03% avg_auc=88.12%
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.236651 Test loss=0.388466 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.20852158963680267
[5/23] Train loss=0.22531361877918243
[10/23] Train loss=0.24538931250572205
[15/23] Train loss=0.22018633782863617
[20/23] Train loss=0.2126278281211853
Test set avg_accuracy=82.96% avg_sensitivity=32.72%, avg_specificity=98.95% avg_auc=84.95%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.240453 Test loss=0.450588 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.21611618995666504
[5/23] Train loss=0.218263640999794
[10/23] Train loss=0.24978087842464447
[15/23] Train loss=0.20788782835006714
[20/23] Train loss=0.20771406590938568
Test set avg_accuracy=84.83% avg_sensitivity=43.02%, avg_specificity=98.15% avg_auc=85.81%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.233770 Test loss=0.379172 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.20876261591911316
[5/23] Train loss=0.22550226747989655
[10/23] Train loss=0.22371123731136322
[15/23] Train loss=0.20883403718471527
[20/23] Train loss=0.2100435048341751
Test set avg_accuracy=85.79% avg_sensitivity=55.15%, avg_specificity=95.55% avg_auc=89.51%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.227405 Test loss=0.347858 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.2106054723262787
[5/23] Train loss=0.21085409820079803
[10/23] Train loss=0.23613806068897247
[15/23] Train loss=0.2080116868019104
[20/23] Train loss=0.21127817034721375
Test set avg_accuracy=85.83% avg_sensitivity=56.33%, avg_specificity=95.23% avg_auc=89.37%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.226829 Test loss=0.334219 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.20704501867294312
[5/23] Train loss=0.19586943089962006
[10/23] Train loss=0.2179621458053589
[15/23] Train loss=0.21091444790363312
[20/23] Train loss=0.20092657208442688
Test set avg_accuracy=85.62% avg_sensitivity=69.22%, avg_specificity=90.85% avg_auc=90.83%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.221011 Test loss=0.323191 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.20566590130329132
[5/23] Train loss=0.1942848414182663
[10/23] Train loss=0.2159278243780136
[15/23] Train loss=0.19381792843341827
[20/23] Train loss=0.20020714402198792
Test set avg_accuracy=86.51% avg_sensitivity=56.82%, avg_specificity=95.97% avg_auc=89.57%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.217616 Test loss=0.337209 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.205526202917099
[5/23] Train loss=0.19756373763084412
[10/23] Train loss=0.2045721411705017
[15/23] Train loss=0.19238081574440002
[20/23] Train loss=0.20899802446365356
Test set avg_accuracy=85.04% avg_sensitivity=63.23%, avg_specificity=91.98% avg_auc=87.72%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.215592 Test loss=0.363848 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.20587000250816345
[5/23] Train loss=0.19942033290863037
[10/23] Train loss=0.20509372651576996
[15/23] Train loss=0.19635280966758728
[20/23] Train loss=0.1970171332359314
Test set avg_accuracy=83.32% avg_sensitivity=71.59%, avg_specificity=87.06% avg_auc=89.30%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.213763 Test loss=0.369565 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.19280923902988434
[5/23] Train loss=0.18360574543476105
[10/23] Train loss=0.21557222306728363
[15/23] Train loss=0.19725888967514038
[20/23] Train loss=0.19176657497882843
Test set avg_accuracy=85.08% avg_sensitivity=59.03%, avg_specificity=93.37% avg_auc=87.77%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.207739 Test loss=0.362405 Current lr=[0.000299926900870094]

[0/23] Train loss=0.196422278881073
[5/23] Train loss=0.19845612347126007
[10/23] Train loss=0.20686109364032745
[15/23] Train loss=0.18942798674106598
[20/23] Train loss=0.20048314332962036
Test set avg_accuracy=80.31% avg_sensitivity=64.15%, avg_specificity=85.46% avg_auc=84.00%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.210454 Test loss=0.438558 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.19667744636535645
[5/23] Train loss=0.1824135184288025
[10/23] Train loss=0.192547008395195
[15/23] Train loss=0.1951322704553604
[20/23] Train loss=0.19819730520248413
Test set avg_accuracy=81.47% avg_sensitivity=61.29%, avg_specificity=87.90% avg_auc=83.96%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.203549 Test loss=0.428597 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.19630067050457
[5/23] Train loss=0.17332309484481812
[10/23] Train loss=0.19576144218444824
[15/23] Train loss=0.19369573891162872
[20/23] Train loss=0.17727822065353394
Test set avg_accuracy=84.93% avg_sensitivity=59.35%, avg_specificity=93.08% avg_auc=88.71%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.204129 Test loss=0.350307 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.17607149481773376
[5/23] Train loss=0.17304062843322754
[10/23] Train loss=0.2052772492170334
[15/23] Train loss=0.18857532739639282
[20/23] Train loss=0.1787824183702469
Test set avg_accuracy=84.04% avg_sensitivity=40.75%, avg_specificity=97.82% avg_auc=86.69%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.197752 Test loss=0.408029 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.18449273705482483
[5/23] Train loss=0.1735181361436844
[10/23] Train loss=0.1977192759513855
[15/23] Train loss=0.1935783177614212
[20/23] Train loss=0.19536375999450684
Test set avg_accuracy=80.22% avg_sensitivity=20.11%, avg_specificity=99.36% avg_auc=80.14%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.196859 Test loss=0.556394 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.19855469465255737
[5/23] Train loss=0.16960522532463074
[10/23] Train loss=0.20750193297863007
[15/23] Train loss=0.17913874983787537
[20/23] Train loss=0.17927542328834534
Test set avg_accuracy=84.24% avg_sensitivity=44.20%, avg_specificity=97.00% avg_auc=86.44%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.197577 Test loss=0.412220 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.18707899749279022
[5/23] Train loss=0.17274650931358337
[10/23] Train loss=0.19141533970832825
[15/23] Train loss=0.18180280923843384
[20/23] Train loss=0.18612176179885864
Test set avg_accuracy=81.28% avg_sensitivity=68.57%, avg_specificity=85.32% avg_auc=87.12%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.199092 Test loss=0.406190 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.19531379640102386
[5/23] Train loss=0.1716579794883728
[10/23] Train loss=0.18349391222000122
[15/23] Train loss=0.18746596574783325
[20/23] Train loss=0.17484408617019653
Test set avg_accuracy=84.43% avg_sensitivity=67.98%, avg_specificity=89.67% avg_auc=89.21%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.197181 Test loss=0.357282 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.1761617809534073
[5/23] Train loss=0.1708613783121109
[10/23] Train loss=0.18134768307209015
[15/23] Train loss=0.18233084678649902
[20/23] Train loss=0.18233461678028107
Test set avg_accuracy=83.74% avg_sensitivity=39.68%, avg_specificity=97.77% avg_auc=85.14%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.193281 Test loss=0.440353 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.18845808506011963
[5/23] Train loss=0.1646471470594406
[10/23] Train loss=0.17912718653678894
[15/23] Train loss=0.1761389523744583
[20/23] Train loss=0.18848910927772522
Test set avg_accuracy=84.08% avg_sensitivity=48.52%, avg_specificity=95.40% avg_auc=86.67%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.192054 Test loss=0.400591 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.18883445858955383
[5/23] Train loss=0.16778558492660522
[10/23] Train loss=0.1839100867509842
[15/23] Train loss=0.18860004842281342
[20/23] Train loss=0.1756671667098999
Test set avg_accuracy=85.12% avg_sensitivity=45.34%, avg_specificity=97.79% avg_auc=85.00%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.194675 Test loss=0.414259 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.17484083771705627
[5/23] Train loss=0.16995227336883545
[10/23] Train loss=0.1893264353275299
[15/23] Train loss=0.18014101684093475
[20/23] Train loss=0.17658783495426178
Test set avg_accuracy=80.55% avg_sensitivity=24.04%, avg_specificity=98.54% avg_auc=82.44%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.191926 Test loss=0.524094 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.1783037930727005
[5/23] Train loss=0.1645422875881195
[10/23] Train loss=0.17874200642108917
[15/23] Train loss=0.17777973413467407
[20/23] Train loss=0.18380485475063324
Test set avg_accuracy=83.91% avg_sensitivity=80.16%, avg_specificity=85.10% avg_auc=90.55%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.188319 Test loss=0.360157 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.16780924797058105
[5/23] Train loss=0.17143386602401733
[10/23] Train loss=0.1843774914741516
[15/23] Train loss=0.18000955879688263
[20/23] Train loss=0.17534255981445312
Test set avg_accuracy=85.68% avg_sensitivity=64.80%, avg_specificity=92.33% avg_auc=88.90%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.190353 Test loss=0.357671 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.172862246632576
[5/23] Train loss=0.16855938732624054
[10/23] Train loss=0.17463725805282593
[15/23] Train loss=0.18174763023853302
[20/23] Train loss=0.1851779967546463
Test set avg_accuracy=69.78% avg_sensitivity=80.43%, avg_specificity=66.39% avg_auc=82.43%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.188650 Test loss=0.608702 Current lr=[0.000283047938381597]

[0/23] Train loss=0.174797922372818
[5/23] Train loss=0.16929055750370026
[10/23] Train loss=0.170082688331604
[15/23] Train loss=0.1732238382101059
[20/23] Train loss=0.1813730001449585
Test set avg_accuracy=85.00% avg_sensitivity=68.52%, avg_specificity=90.25% avg_auc=89.68%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.188802 Test loss=0.358602 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.17747445404529572
[5/23] Train loss=0.16487538814544678
[10/23] Train loss=0.18147851526737213
[15/23] Train loss=0.1692497432231903
[20/23] Train loss=0.1794249266386032
Test set avg_accuracy=82.80% avg_sensitivity=36.93%, avg_specificity=97.41% avg_auc=80.11%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.185959 Test loss=0.505802 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.17288154363632202
[5/23] Train loss=0.1843760907649994
[10/23] Train loss=0.17048586905002594
[15/23] Train loss=0.17465253174304962
[20/23] Train loss=0.17151178419589996
Test set avg_accuracy=85.05% avg_sensitivity=70.84%, avg_specificity=89.58% avg_auc=89.48%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.190463 Test loss=0.359000 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.17514890432357788
[5/23] Train loss=0.16072213649749756
[10/23] Train loss=0.17942818999290466
[15/23] Train loss=0.17765051126480103
[20/23] Train loss=0.17767885327339172
Test set avg_accuracy=85.03% avg_sensitivity=68.52%, avg_specificity=90.28% avg_auc=89.71%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.188159 Test loss=0.357569 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.17581947147846222
[5/23] Train loss=0.16366368532180786
[10/23] Train loss=0.17331689596176147
[15/23] Train loss=0.17508812248706818
[20/23] Train loss=0.17308254539966583
Test set avg_accuracy=77.23% avg_sensitivity=84.26%, avg_specificity=74.99% avg_auc=87.52%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.181413 Test loss=0.516240 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.16851839423179626
[5/23] Train loss=0.16162177920341492
[10/23] Train loss=0.17812688648700714
[15/23] Train loss=0.17289035022258759
[20/23] Train loss=0.1642305850982666
Test set avg_accuracy=82.92% avg_sensitivity=79.84%, avg_specificity=83.90% avg_auc=90.04%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.183245 Test loss=0.392547 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.17043785750865936
[5/23] Train loss=0.1602572798728943
[10/23] Train loss=0.17840662598609924
[15/23] Train loss=0.17252413928508759
[20/23] Train loss=0.1672087460756302
Test set avg_accuracy=83.98% avg_sensitivity=61.51%, avg_specificity=91.14% avg_auc=86.46%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.184109 Test loss=0.401052 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.17128624022006989
[5/23] Train loss=0.16183708608150482
[10/23] Train loss=0.17871513962745667
[15/23] Train loss=0.15962877869606018
[20/23] Train loss=0.16621114313602448
Test set avg_accuracy=84.79% avg_sensitivity=50.30%, avg_specificity=95.78% avg_auc=85.28%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.179512 Test loss=0.422598 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.1651625633239746
[5/23] Train loss=0.15927685797214508
[10/23] Train loss=0.17304660379886627
[15/23] Train loss=0.16499650478363037
[20/23] Train loss=0.17420105636119843
Test set avg_accuracy=84.02% avg_sensitivity=55.36%, avg_specificity=93.15% avg_auc=84.85%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.179855 Test loss=0.413546 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.16748440265655518
[5/23] Train loss=0.15430407226085663
[10/23] Train loss=0.17230015993118286
[15/23] Train loss=0.16570474207401276
[20/23] Train loss=0.16067303717136383
Test set avg_accuracy=84.49% avg_sensitivity=53.48%, avg_specificity=94.37% avg_auc=86.12%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.175470 Test loss=0.396448 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.16745302081108093
[5/23] Train loss=0.15094386041164398
[10/23] Train loss=0.1666334718465805
[15/23] Train loss=0.16985774040222168
[20/23] Train loss=0.16376365721225739
Test set avg_accuracy=82.28% avg_sensitivity=30.57%, avg_specificity=98.75% avg_auc=81.83%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.175554 Test loss=0.505435 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.15474478900432587
[5/23] Train loss=0.14782199263572693
[10/23] Train loss=0.16016118228435516
[15/23] Train loss=0.16328567266464233
[20/23] Train loss=0.1654379665851593
Test set avg_accuracy=82.02% avg_sensitivity=31.11%, avg_specificity=98.23% avg_auc=80.29%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.172946 Test loss=0.535434 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.1569729894399643
[5/23] Train loss=0.14670519530773163
[10/23] Train loss=0.15698367357254028
[15/23] Train loss=0.17588235437870026
[20/23] Train loss=0.1545744240283966
Test set avg_accuracy=82.99% avg_sensitivity=81.08%, avg_specificity=83.61% avg_auc=89.85%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.171979 Test loss=0.387213 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.15634314715862274
[5/23] Train loss=0.15906092524528503
[10/23] Train loss=0.1568259745836258
[15/23] Train loss=0.16755788028240204
[20/23] Train loss=0.16316449642181396
Test set avg_accuracy=83.36% avg_sensitivity=41.46%, avg_specificity=96.70% avg_auc=84.81%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.176141 Test loss=0.446675 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.170785054564476
[5/23] Train loss=0.1609986573457718
[10/23] Train loss=0.1627703160047531
[15/23] Train loss=0.17313918471336365
[20/23] Train loss=0.15995140373706818
Test set avg_accuracy=80.76% avg_sensitivity=23.23%, avg_specificity=99.07% avg_auc=72.35%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.173190 Test loss=0.636272 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.15393494069576263
[5/23] Train loss=0.14966905117034912
[10/23] Train loss=0.1712513267993927
[15/23] Train loss=0.17648401856422424
[20/23] Train loss=0.16883501410484314
Test set avg_accuracy=81.47% avg_sensitivity=26.63%, avg_specificity=98.94% avg_auc=81.42%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.171810 Test loss=0.516195 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.16187290847301483
[5/23] Train loss=0.14721931517124176
[10/23] Train loss=0.16476301848888397
[15/23] Train loss=0.1576474905014038
[20/23] Train loss=0.16593964397907257
Test set avg_accuracy=84.56% avg_sensitivity=75.26%, avg_specificity=87.52% avg_auc=90.27%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.169638 Test loss=0.365354 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.1662622094154358
[5/23] Train loss=0.16500069200992584
[10/23] Train loss=0.16284118592739105
[15/23] Train loss=0.17472636699676514
[20/23] Train loss=0.1608716994524002
Test set avg_accuracy=83.78% avg_sensitivity=43.72%, avg_specificity=96.53% avg_auc=83.48%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.171840 Test loss=0.446791 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.16111142933368683
[5/23] Train loss=0.1619967520236969
[10/23] Train loss=0.16658005118370056
[15/23] Train loss=0.17666928470134735
[20/23] Train loss=0.15709811449050903
Test set avg_accuracy=83.93% avg_sensitivity=47.12%, avg_specificity=95.66% avg_auc=84.76%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.174717 Test loss=0.445708 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.15935179591178894
[5/23] Train loss=0.15688636898994446
[10/23] Train loss=0.17869693040847778
[15/23] Train loss=0.16513276100158691
[20/23] Train loss=0.15510539710521698
Test set avg_accuracy=84.11% avg_sensitivity=68.57%, avg_specificity=89.06% avg_auc=88.83%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.171587 Test loss=0.364861 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.16514497995376587
[5/23] Train loss=0.14791494607925415
[10/23] Train loss=0.14989206194877625
[15/23] Train loss=0.1477927416563034
[20/23] Train loss=0.1546507328748703
Test set avg_accuracy=84.02% avg_sensitivity=65.01%, avg_specificity=90.08% avg_auc=87.34%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.163540 Test loss=0.382305 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.16074039041996002
[5/23] Train loss=0.14540351927280426
[10/23] Train loss=0.1549968421459198
[15/23] Train loss=0.15723533928394318
[20/23] Train loss=0.149281844496727
Test set avg_accuracy=84.90% avg_sensitivity=51.70%, avg_specificity=95.47% avg_auc=87.41%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.163268 Test loss=0.390187 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.1613706350326538
[5/23] Train loss=0.1460384577512741
[10/23] Train loss=0.1575690358877182
[15/23] Train loss=0.15095289051532745
[20/23] Train loss=0.15406206250190735
Test set avg_accuracy=82.99% avg_sensitivity=74.66%, avg_specificity=85.65% avg_auc=88.95%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.164702 Test loss=0.385770 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.16285140812397003
[5/23] Train loss=0.14806295931339264
[10/23] Train loss=0.16398783028125763
[15/23] Train loss=0.15958140790462494
[20/23] Train loss=0.14846520125865936
Test set avg_accuracy=85.49% avg_sensitivity=56.12%, avg_specificity=94.85% avg_auc=87.41%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.165123 Test loss=0.384270 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.1499730795621872
[5/23] Train loss=0.15388624370098114
[10/23] Train loss=0.15243756771087646
[15/23] Train loss=0.14404095709323883
[20/23] Train loss=0.15005476772785187
Test set avg_accuracy=84.99% avg_sensitivity=71.48%, avg_specificity=89.29% avg_auc=88.80%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.159647 Test loss=0.378276 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.15174642205238342
[5/23] Train loss=0.14571623504161835
[10/23] Train loss=0.15601930022239685
[15/23] Train loss=0.15136291086673737
[20/23] Train loss=0.14131884276866913
Test set avg_accuracy=84.43% avg_sensitivity=72.35%, avg_specificity=88.27% avg_auc=89.70%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.160081 Test loss=0.369067 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.15507641434669495
[5/23] Train loss=0.13737249374389648
[10/23] Train loss=0.1472516506910324
[15/23] Train loss=0.1508055031299591
[20/23] Train loss=0.14637912809848785
Test set avg_accuracy=83.09% avg_sensitivity=76.28%, avg_specificity=85.25% avg_auc=88.68%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.159467 Test loss=0.413055 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.1508932262659073
[5/23] Train loss=0.145114466547966
[10/23] Train loss=0.14809496700763702
[15/23] Train loss=0.14901286363601685
[20/23] Train loss=0.14343561232089996
Test set avg_accuracy=85.04% avg_sensitivity=64.53%, avg_specificity=91.57% avg_auc=88.57%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.158228 Test loss=0.372950 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.14448381960391998
[5/23] Train loss=0.1434149146080017
[10/23] Train loss=0.1432834416627884
[15/23] Train loss=0.15885093808174133
[20/23] Train loss=0.14857454597949982
Test set avg_accuracy=79.36% avg_sensitivity=82.91%, avg_specificity=78.23% avg_auc=88.53%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.157431 Test loss=0.468774 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.14564527571201324
[5/23] Train loss=0.13694709539413452
[10/23] Train loss=0.1572052389383316
[15/23] Train loss=0.1475517302751541
[20/23] Train loss=0.14534765481948853
Test set avg_accuracy=86.24% avg_sensitivity=64.58%, avg_specificity=93.13% avg_auc=87.83%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.155354 Test loss=0.370801 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.13784152269363403
[5/23] Train loss=0.1367592066526413
[10/23] Train loss=0.1409856677055359
[15/23] Train loss=0.14263717830181122
[20/23] Train loss=0.14348939061164856
Test set avg_accuracy=84.01% avg_sensitivity=68.79%, avg_specificity=88.86% avg_auc=88.34%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.153066 Test loss=0.399983 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.14526577293872833
[5/23] Train loss=0.13883385062217712
[10/23] Train loss=0.141472727060318
[15/23] Train loss=0.14984920620918274
[20/23] Train loss=0.14505086839199066
Test set avg_accuracy=83.41% avg_sensitivity=58.98%, avg_specificity=91.19% avg_auc=86.19%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.154083 Test loss=0.410608 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.14575590193271637
[5/23] Train loss=0.13353097438812256
[10/23] Train loss=0.14465883374214172
[15/23] Train loss=0.1487947255373001
[20/23] Train loss=0.1372368335723877
Test set avg_accuracy=84.04% avg_sensitivity=58.76%, avg_specificity=92.09% avg_auc=86.91%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.150868 Test loss=0.404289 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.1386057287454605
[5/23] Train loss=0.14040040969848633
[10/23] Train loss=0.14187419414520264
[15/23] Train loss=0.1422455757856369
[20/23] Train loss=0.1431262046098709
Test set avg_accuracy=84.27% avg_sensitivity=61.13%, avg_specificity=91.64% avg_auc=86.24%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.149433 Test loss=0.408578 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.14217153191566467
[5/23] Train loss=0.1419895887374878
[10/23] Train loss=0.14112530648708344
[15/23] Train loss=0.14579640328884125
[20/23] Train loss=0.13975366950035095
Test set avg_accuracy=85.79% avg_sensitivity=62.37%, avg_specificity=93.25% avg_auc=87.21%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.150473 Test loss=0.382746 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.14160576462745667
[5/23] Train loss=0.13823410868644714
[10/23] Train loss=0.1411280483007431
[15/23] Train loss=0.14564979076385498
[20/23] Train loss=0.13914847373962402
Test set avg_accuracy=84.47% avg_sensitivity=69.38%, avg_specificity=89.27% avg_auc=88.89%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.151675 Test loss=0.384407 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.13906554877758026
[5/23] Train loss=0.13996298611164093
[10/23] Train loss=0.145895853638649
[15/23] Train loss=0.14695101976394653
[20/23] Train loss=0.14424990117549896
Test set avg_accuracy=85.59% avg_sensitivity=60.75%, avg_specificity=93.49% avg_auc=86.45%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.149656 Test loss=0.404247 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.13691446185112
[5/23] Train loss=0.138121098279953
[10/23] Train loss=0.14034301042556763
[15/23] Train loss=0.1443137228488922
[20/23] Train loss=0.13866864144802094
Test set avg_accuracy=84.83% avg_sensitivity=60.65%, avg_specificity=92.53% avg_auc=87.66%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.148984 Test loss=0.392674 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.15039557218551636
[5/23] Train loss=0.1344664841890335
[10/23] Train loss=0.14451093971729279
[15/23] Train loss=0.13939553499221802
[20/23] Train loss=0.13704358041286469
Test set avg_accuracy=84.53% avg_sensitivity=72.51%, avg_specificity=88.36% avg_auc=90.05%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.147796 Test loss=0.373359 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.1374165266752243
[5/23] Train loss=0.136391744017601
[10/23] Train loss=0.13982200622558594
[15/23] Train loss=0.1406930834054947
[20/23] Train loss=0.13222180306911469
Test set avg_accuracy=85.87% avg_sensitivity=59.84%, avg_specificity=94.16% avg_auc=86.83%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.146309 Test loss=0.387507 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.14386457204818726
[5/23] Train loss=0.137596994638443
[10/23] Train loss=0.13960182666778564
[15/23] Train loss=0.13588224351406097
[20/23] Train loss=0.13653762638568878
Test set avg_accuracy=84.60% avg_sensitivity=61.99%, avg_specificity=91.79% avg_auc=86.02%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.148395 Test loss=0.417490 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.1418697088956833
[5/23] Train loss=0.1345539093017578
[10/23] Train loss=0.1338091343641281
[15/23] Train loss=0.13087689876556396
[20/23] Train loss=0.13422973453998566
Test set avg_accuracy=85.26% avg_sensitivity=64.91%, avg_specificity=91.74% avg_auc=88.37%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.145533 Test loss=0.380109 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.1292574405670166
[5/23] Train loss=0.13220760226249695
[10/23] Train loss=0.13632769882678986
[15/23] Train loss=0.126667320728302
[20/23] Train loss=0.1250440925359726
Test set avg_accuracy=84.84% avg_sensitivity=70.08%, avg_specificity=89.55% avg_auc=89.62%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.141190 Test loss=0.375790 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.13195322453975677
[5/23] Train loss=0.1338181495666504
[10/23] Train loss=0.14134037494659424
[15/23] Train loss=0.1374162882566452
[20/23] Train loss=0.13147693872451782
Test set avg_accuracy=84.13% avg_sensitivity=68.41%, avg_specificity=89.13% avg_auc=88.76%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.144488 Test loss=0.395001 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.13232001662254333
[5/23] Train loss=0.13391828536987305
[10/23] Train loss=0.13885994255542755
[15/23] Train loss=0.1382778435945511
[20/23] Train loss=0.13297851383686066
Test set avg_accuracy=85.49% avg_sensitivity=60.70%, avg_specificity=93.39% avg_auc=87.86%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.142945 Test loss=0.391705 Current lr=[0.000112073915556435]

[0/23] Train loss=0.13934263586997986
[5/23] Train loss=0.12882618606090546
[10/23] Train loss=0.13102054595947266
[15/23] Train loss=0.1334851235151291
[20/23] Train loss=0.12802401185035706
Test set avg_accuracy=83.88% avg_sensitivity=76.98%, avg_specificity=86.08% avg_auc=90.14%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.141961 Test loss=0.386913 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.1367431879043579
[5/23] Train loss=0.13126841187477112
[10/23] Train loss=0.13018089532852173
[15/23] Train loss=0.13658036291599274
[20/23] Train loss=0.13193626701831818
Test set avg_accuracy=83.33% avg_sensitivity=71.86%, avg_specificity=86.99% avg_auc=88.81%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.141020 Test loss=0.394506 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.13357630372047424
[5/23] Train loss=0.12438881397247314
[10/23] Train loss=0.13823069632053375
[15/23] Train loss=0.13163438439369202
[20/23] Train loss=0.13072973489761353
Test set avg_accuracy=85.81% avg_sensitivity=67.44%, avg_specificity=91.66% avg_auc=90.50%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.140567 Test loss=0.354445 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.1326700896024704
[5/23] Train loss=0.1324479728937149
[10/23] Train loss=0.13592837750911713
[15/23] Train loss=0.13610844314098358
[20/23] Train loss=0.12688755989074707
Test set avg_accuracy=84.18% avg_sensitivity=73.64%, avg_specificity=87.54% avg_auc=88.98%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.139377 Test loss=0.384732 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.13075944781303406
[5/23] Train loss=0.12673728168010712
[10/23] Train loss=0.13004668056964874
[15/23] Train loss=0.13138310611248016
[20/23] Train loss=0.1286541074514389
Test set avg_accuracy=81.82% avg_sensitivity=79.51%, avg_specificity=82.56% avg_auc=89.13%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.138200 Test loss=0.428377 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.13276740908622742
[5/23] Train loss=0.12433440238237381
[10/23] Train loss=0.12901896238327026
[15/23] Train loss=0.12924669682979584
[20/23] Train loss=0.1301814615726471
Test set avg_accuracy=84.35% avg_sensitivity=70.24%, avg_specificity=88.84% avg_auc=89.07%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.137506 Test loss=0.389183 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.12999753654003143
[5/23] Train loss=0.13021767139434814
[10/23] Train loss=0.12917467951774597
[15/23] Train loss=0.1305168867111206
[20/23] Train loss=0.12278269231319427
Test set avg_accuracy=82.40% avg_sensitivity=81.83%, avg_specificity=82.58% avg_auc=89.30%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.136143 Test loss=0.422451 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.13211143016815186
[5/23] Train loss=0.12428570538759232
[10/23] Train loss=0.12957952916622162
[15/23] Train loss=0.1264735609292984
[20/23] Train loss=0.12456822395324707
Test set avg_accuracy=85.52% avg_sensitivity=68.73%, avg_specificity=90.87% avg_auc=88.96%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.135542 Test loss=0.373295 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.12990382313728333
[5/23] Train loss=0.12241796404123306
[10/23] Train loss=0.12690384685993195
[15/23] Train loss=0.12151575833559036
[20/23] Train loss=0.12422442436218262
Test set avg_accuracy=85.96% avg_sensitivity=65.18%, avg_specificity=92.58% avg_auc=88.59%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.134146 Test loss=0.376093 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.12629398703575134
[5/23] Train loss=0.12399953603744507
[10/23] Train loss=0.1260591745376587
[15/23] Train loss=0.12601777911186218
[20/23] Train loss=0.11986774206161499
Test set avg_accuracy=85.49% avg_sensitivity=70.13%, avg_specificity=90.39% avg_auc=89.15%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.133636 Test loss=0.366676 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.12778958678245544
[5/23] Train loss=0.13098999857902527
[10/23] Train loss=0.1290673166513443
[15/23] Train loss=0.12727856636047363
[20/23] Train loss=0.12528707087039948
Test set avg_accuracy=85.39% avg_sensitivity=64.69%, avg_specificity=91.98% avg_auc=89.17%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.133592 Test loss=0.367468 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.12465254962444305
[5/23] Train loss=0.12341625988483429
[10/23] Train loss=0.1286865919828415
[15/23] Train loss=0.122116319835186
[20/23] Train loss=0.12681245803833008
Test set avg_accuracy=85.08% avg_sensitivity=64.85%, avg_specificity=91.52% avg_auc=87.83%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.131772 Test loss=0.389285 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.12651677429676056
[5/23] Train loss=0.12290897220373154
[10/23] Train loss=0.128451406955719
[15/23] Train loss=0.12150309234857559
[20/23] Train loss=0.1203496977686882
Test set avg_accuracy=83.88% avg_sensitivity=62.80%, avg_specificity=90.59% avg_auc=86.41%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.132117 Test loss=0.405751 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.1278783679008484
[5/23] Train loss=0.11975392699241638
[10/23] Train loss=0.12874461710453033
[15/23] Train loss=0.12283352762460709
[20/23] Train loss=0.1243768110871315
Test set avg_accuracy=84.91% avg_sensitivity=63.13%, avg_specificity=91.85% avg_auc=89.42%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.131268 Test loss=0.373750 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.12277383357286453
[5/23] Train loss=0.11876589804887772
[10/23] Train loss=0.12199102342128754
[15/23] Train loss=0.12355662137269974
[20/23] Train loss=0.12219883501529694
Test set avg_accuracy=84.13% avg_sensitivity=58.87%, avg_specificity=92.17% avg_auc=86.98%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.129997 Test loss=0.403245 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.12556862831115723
[5/23] Train loss=0.11897731572389603
[10/23] Train loss=0.12302830070257187
[15/23] Train loss=0.12222447246313095
[20/23] Train loss=0.11923874914646149
Test set avg_accuracy=85.00% avg_sensitivity=67.65%, avg_specificity=90.52% avg_auc=88.96%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.129583 Test loss=0.381200 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.11914639919996262
[5/23] Train loss=0.12203004956245422
[10/23] Train loss=0.11855243146419525
[15/23] Train loss=0.12641321122646332
[20/23] Train loss=0.11666304618120193
Test set avg_accuracy=85.03% avg_sensitivity=68.73%, avg_specificity=90.21% avg_auc=88.76%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.128648 Test loss=0.385746 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.119549460709095
[5/23] Train loss=0.12241677194833755
[10/23] Train loss=0.11866012960672379
[15/23] Train loss=0.1288117915391922
[20/23] Train loss=0.11778067797422409
Test set avg_accuracy=85.35% avg_sensitivity=62.43%, avg_specificity=92.65% avg_auc=87.61%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.127739 Test loss=0.391918 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.12357904762029648
[5/23] Train loss=0.1192820742726326
[10/23] Train loss=0.11873283982276917
[15/23] Train loss=0.12023667991161346
[20/23] Train loss=0.11921492218971252
Test set avg_accuracy=84.10% avg_sensitivity=71.59%, avg_specificity=88.09% avg_auc=89.02%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.127928 Test loss=0.386515 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.11657460033893585
[5/23] Train loss=0.11864281445741653
[10/23] Train loss=0.11687139421701431
[15/23] Train loss=0.1202235147356987
[20/23] Train loss=0.11495290696620941
Test set avg_accuracy=84.97% avg_sensitivity=70.08%, avg_specificity=89.72% avg_auc=89.14%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.127016 Test loss=0.385508 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.11920606344938278
[5/23] Train loss=0.1229676604270935
[10/23] Train loss=0.119486004114151
[15/23] Train loss=0.1198066771030426
[20/23] Train loss=0.11722617596387863
Test set avg_accuracy=84.56% avg_sensitivity=70.40%, avg_specificity=89.06% avg_auc=89.09%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.125901 Test loss=0.388754 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.12097642570734024
[5/23] Train loss=0.11895129829645157
[10/23] Train loss=0.11806285381317139
[15/23] Train loss=0.12120138108730316
[20/23] Train loss=0.11742264777421951
Test set avg_accuracy=85.31% avg_sensitivity=65.82%, avg_specificity=91.52% avg_auc=87.70%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.125182 Test loss=0.386039 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.11725588887929916
[5/23] Train loss=0.11717981100082397
[10/23] Train loss=0.11705894023180008
[15/23] Train loss=0.11647410690784454
[20/23] Train loss=0.11115656793117523
Test set avg_accuracy=85.00% avg_sensitivity=66.04%, avg_specificity=91.04% avg_auc=88.88%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.123917 Test loss=0.379748 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.11697116494178772
[5/23] Train loss=0.11657417565584183
[10/23] Train loss=0.11654921621084213
[15/23] Train loss=0.1156536266207695
[20/23] Train loss=0.11185367405414581
Test set avg_accuracy=85.60% avg_sensitivity=63.34%, avg_specificity=92.69% avg_auc=87.94%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.122612 Test loss=0.384965 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.11633450537919998
[5/23] Train loss=0.11662974953651428
[10/23] Train loss=0.11417896300554276
[15/23] Train loss=0.11407589167356491
[20/23] Train loss=0.11061055213212967
Test set avg_accuracy=85.36% avg_sensitivity=67.12%, avg_specificity=91.18% avg_auc=88.87%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.122940 Test loss=0.376947 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.11742059886455536
[5/23] Train loss=0.11347287148237228
[10/23] Train loss=0.11549892276525497
[15/23] Train loss=0.1171017438173294
[20/23] Train loss=0.11401701718568802
Test set avg_accuracy=85.82% avg_sensitivity=64.80%, avg_specificity=92.52% avg_auc=88.11%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.122550 Test loss=0.379892 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.11485223472118378
[5/23] Train loss=0.11656367778778076
[10/23] Train loss=0.11247940361499786
[15/23] Train loss=0.11687387526035309
[20/23] Train loss=0.11297037452459335
Test set avg_accuracy=85.16% avg_sensitivity=66.52%, avg_specificity=91.09% avg_auc=88.44%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.121783 Test loss=0.384713 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.11591053754091263
[5/23] Train loss=0.11618857085704803
[10/23] Train loss=0.11348563432693481
[15/23] Train loss=0.11272039264440536
[20/23] Train loss=0.11343823373317719
Test set avg_accuracy=85.94% avg_sensitivity=65.44%, avg_specificity=92.46% avg_auc=88.42%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.121364 Test loss=0.379385 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.11699103564023972
[5/23] Train loss=0.11214336007833481
[10/23] Train loss=0.11521615833044052
[15/23] Train loss=0.11382167041301727
[20/23] Train loss=0.10962055623531342
Test set avg_accuracy=85.65% avg_sensitivity=65.55%, avg_specificity=92.05% avg_auc=88.48%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.120881 Test loss=0.379459 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.1134956032037735
[5/23] Train loss=0.11442337930202484
[10/23] Train loss=0.11610514670610428
[15/23] Train loss=0.11496134102344513
[20/23] Train loss=0.11239197105169296
Test set avg_accuracy=85.60% avg_sensitivity=66.15%, avg_specificity=91.79% avg_auc=88.38%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.120011 Test loss=0.379827 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.11251968145370483
[5/23] Train loss=0.11413253098726273
[10/23] Train loss=0.11348327249288559
[15/23] Train loss=0.11565401405096054
[20/23] Train loss=0.11082111299037933
Test set avg_accuracy=85.13% avg_sensitivity=66.47%, avg_specificity=91.07% avg_auc=88.38%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.119737 Test loss=0.386216 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.11490219831466675
[5/23] Train loss=0.11230970174074173
[10/23] Train loss=0.1111830323934555
[15/23] Train loss=0.11502911895513535
[20/23] Train loss=0.10845652222633362
Test set avg_accuracy=85.56% avg_sensitivity=66.09%, avg_specificity=91.76% avg_auc=88.29%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.119524 Test loss=0.382273 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.11354922503232956
[5/23] Train loss=0.10992885380983353
[10/23] Train loss=0.11109621077775955
[15/23] Train loss=0.11520608514547348
[20/23] Train loss=0.11037331074476242
Test set avg_accuracy=85.64% avg_sensitivity=66.79%, avg_specificity=91.64% avg_auc=88.30%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.119101 Test loss=0.381838 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.11407378315925598
[5/23] Train loss=0.11615557223558426
[10/23] Train loss=0.11310341209173203
[15/23] Train loss=0.11202538013458252
[20/23] Train loss=0.10796383768320084
Test set avg_accuracy=85.55% avg_sensitivity=65.01%, avg_specificity=92.09% avg_auc=88.23%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.119487 Test loss=0.382429 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.1136828064918518
[5/23] Train loss=0.11063941568136215
[10/23] Train loss=0.11079936474561691
[15/23] Train loss=0.11426527053117752
[20/23] Train loss=0.11076100170612335
Test set avg_accuracy=85.27% avg_sensitivity=66.79%, avg_specificity=91.16% avg_auc=88.69%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.118589 Test loss=0.380295 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.11309392750263214
[5/23] Train loss=0.1121736541390419
[10/23] Train loss=0.112004853785038
[15/23] Train loss=0.11226045340299606
[20/23] Train loss=0.11038970202207565
Test set avg_accuracy=85.53% avg_sensitivity=66.36%, avg_specificity=91.64% avg_auc=88.64%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.118932 Test loss=0.378898 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.11198752373456955
[5/23] Train loss=0.11217495054006577
[10/23] Train loss=0.11151580512523651
[15/23] Train loss=0.11267101019620895
[20/23] Train loss=0.11008265614509583
Test set avg_accuracy=85.64% avg_sensitivity=66.15%, avg_specificity=91.85% avg_auc=88.56%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.118400 Test loss=0.379058 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.11271592229604721
[5/23] Train loss=0.1104680746793747
[10/23] Train loss=0.11327431350946426
[15/23] Train loss=0.11303211003541946
[20/23] Train loss=0.10892250388860703
Test set avg_accuracy=85.56% avg_sensitivity=66.52%, avg_specificity=91.62% avg_auc=88.55%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.118473 Test loss=0.380314 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.11055496335029602
[5/23] Train loss=0.11068128049373627
[10/23] Train loss=0.11041263490915298
[15/23] Train loss=0.11497662216424942
[20/23] Train loss=0.10899663716554642
Test set avg_accuracy=85.62% avg_sensitivity=65.66%, avg_specificity=91.98% avg_auc=88.50%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.118096 Test loss=0.379974 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.11135084182024002
[5/23] Train loss=0.11085012555122375
[10/23] Train loss=0.11167358607053757
[15/23] Train loss=0.11349885165691376
[20/23] Train loss=0.10912852734327316
Test set avg_accuracy=85.65% avg_sensitivity=65.82%, avg_specificity=91.97% avg_auc=88.50%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.118460 Test loss=0.379793 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.11181603372097015
[5/23] Train loss=0.11113866418600082
[10/23] Train loss=0.11179164052009583
[15/23] Train loss=0.11288531869649887
[20/23] Train loss=0.10757441818714142
Test set avg_accuracy=85.61% avg_sensitivity=66.25%, avg_specificity=91.78% avg_auc=88.52%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.118236 Test loss=0.379780 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.11285915225744247
[5/23] Train loss=0.1132000982761383
[10/23] Train loss=0.11203873157501221
[15/23] Train loss=0.11268066614866257
[20/23] Train loss=0.10853839665651321
Test set avg_accuracy=85.59% avg_sensitivity=66.31%, avg_specificity=91.73% avg_auc=88.50%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.118810 Test loss=0.380376 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.11411125957965851
[5/23] Train loss=0.1103072240948677
[10/23] Train loss=0.11367189139127731
[15/23] Train loss=0.11339464783668518
[20/23] Train loss=0.11032263934612274
Test set avg_accuracy=85.47% avg_sensitivity=66.36%, avg_specificity=91.55% avg_auc=88.52%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.118352 Test loss=0.380496 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.1099848523736
[5/23] Train loss=0.11245114356279373
[10/23] Train loss=0.11195434629917145
[15/23] Train loss=0.11383707076311111
[20/23] Train loss=0.10844377428293228
Test set avg_accuracy=85.60% avg_sensitivity=66.31%, avg_specificity=91.74% avg_auc=88.49%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.118237 Test loss=0.380277 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=86.45% sen=70.62%, spe=91.48%, auc=91.75%!
Fold[9] Avg_overlap=0.00%(±0.0)
[0/24] Train loss=0.727369487285614
[5/24] Train loss=0.7197174429893494
[10/24] Train loss=0.7119391560554504
[15/24] Train loss=0.7074511051177979
[20/24] Train loss=0.6958927512168884
Test set avg_accuracy=59.58% avg_sensitivity=43.92%, avg_specificity=64.12% avg_auc=57.51%
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.711392 Test loss=0.658946 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6919050216674805
[5/24] Train loss=0.6778898239135742
[10/24] Train loss=0.6794418096542358
[15/24] Train loss=0.6764887571334839
[20/24] Train loss=0.669009268283844
Test set avg_accuracy=70.27% avg_sensitivity=52.90%, avg_specificity=75.31% avg_auc=71.35%
Best model saved!! Metric=-56.16523854512152!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.678779 Test loss=0.589182 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6580843925476074
[5/24] Train loss=0.6545880436897278
[10/24] Train loss=0.6526923775672913
[15/24] Train loss=0.6486692428588867
[20/24] Train loss=0.6411766409873962
Test set avg_accuracy=74.69% avg_sensitivity=58.63%, avg_specificity=79.34% avg_auc=76.55%
Best model saved!! Metric=-36.78457813009043!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.651513 Test loss=0.548116 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6290972828865051
[5/24] Train loss=0.6308982968330383
[10/24] Train loss=0.6377078294754028
[15/24] Train loss=0.6218284368515015
[20/24] Train loss=0.6105273365974426
Test set avg_accuracy=76.22% avg_sensitivity=66.45%, avg_specificity=79.06% avg_auc=79.42%
Best model saved!! Metric=-24.8421384044606!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.626267 Test loss=0.517825 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.597288191318512
[5/24] Train loss=0.5975749492645264
[10/24] Train loss=0.6075624823570251
[15/24] Train loss=0.5909581780433655
[20/24] Train loss=0.5876603722572327
Test set avg_accuracy=77.07% avg_sensitivity=69.64%, avg_specificity=79.22% avg_auc=81.70%
Best model saved!! Metric=-18.365183895501872!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.600822 Test loss=0.492101 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5751370787620544
[5/24] Train loss=0.5764893293380737
[10/24] Train loss=0.5877240300178528
[15/24] Train loss=0.5725003480911255
[20/24] Train loss=0.5627624988555908
Test set avg_accuracy=78.24% avg_sensitivity=70.22%, avg_specificity=80.57% avg_auc=83.30%
Best model saved!! Metric=-13.670666590709345!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.576447 Test loss=0.466275 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5482305884361267
[5/24] Train loss=0.5519384145736694
[10/24] Train loss=0.5580732226371765
[15/24] Train loss=0.5460932850837708
[20/24] Train loss=0.5339246988296509
Test set avg_accuracy=80.61% avg_sensitivity=69.47%, avg_specificity=83.84% avg_auc=84.79%
Best model saved!! Metric=-7.286922454919605!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.551772 Test loss=0.439666 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5128000974655151
[5/24] Train loss=0.5231488347053528
[10/24] Train loss=0.5344969630241394
[15/24] Train loss=0.5160983800888062
[20/24] Train loss=0.5035154223442078
Test set avg_accuracy=82.15% avg_sensitivity=70.68%, avg_specificity=85.47% avg_auc=86.02%
Best model saved!! Metric=-1.6716069426971956!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.524583 Test loss=0.423285 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.4959748089313507
[5/24] Train loss=0.49458569288253784
[10/24] Train loss=0.5057605504989624
[15/24] Train loss=0.485990971326828
[20/24] Train loss=0.4794837534427643
Test set avg_accuracy=84.11% avg_sensitivity=66.98%, avg_specificity=89.08% avg_auc=86.61%
Best model saved!! Metric=0.7877562998113632!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.500306 Test loss=0.399852 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.47096171975135803
[5/24] Train loss=0.4682820737361908
[10/24] Train loss=0.4786217510700226
[15/24] Train loss=0.4631180465221405
[20/24] Train loss=0.4568236172199249
Test set avg_accuracy=84.74% avg_sensitivity=65.99%, avg_specificity=90.17% avg_auc=87.40%
Best model saved!! Metric=2.3023205955651065!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.475026 Test loss=0.386474 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.448241263628006
[5/24] Train loss=0.44404536485671997
[10/24] Train loss=0.4577331840991974
[15/24] Train loss=0.44247978925704956
[20/24] Train loss=0.4313032627105713
Test set avg_accuracy=85.34% avg_sensitivity=65.12%, avg_specificity=91.20% avg_auc=87.97%
Best model saved!! Metric=3.6312768932064756!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.452553 Test loss=0.369504 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.43028050661087036
[5/24] Train loss=0.4265105426311493
[10/24] Train loss=0.43343719840049744
[15/24] Train loss=0.41604459285736084
[20/24] Train loss=0.41014909744262695
Test set avg_accuracy=85.87% avg_sensitivity=64.72%, avg_specificity=92.01% avg_auc=88.54%
Best model saved!! Metric=5.137558332540252!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.432378 Test loss=0.357190 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4148615598678589
[5/24] Train loss=0.4073886573314667
[10/24] Train loss=0.4168754518032074
[15/24] Train loss=0.40016329288482666
[20/24] Train loss=0.3872936964035034
Test set avg_accuracy=86.15% avg_sensitivity=64.83%, avg_specificity=92.32% avg_auc=89.17%
Best model saved!! Metric=6.469774588635204!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.413782 Test loss=0.346051 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3984939754009247
[5/24] Train loss=0.39117667078971863
[10/24] Train loss=0.39940357208251953
[15/24] Train loss=0.3845883905887604
[20/24] Train loss=0.37397927045822144
Test set avg_accuracy=86.48% avg_sensitivity=64.66%, avg_specificity=92.81% avg_auc=89.56%
Best model saved!! Metric=7.517139909497331!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.397100 Test loss=0.335856 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.38423916697502136
[5/24] Train loss=0.38287800550460815
[10/24] Train loss=0.37887686491012573
[15/24] Train loss=0.37237560749053955
[20/24] Train loss=0.35564354062080383
Test set avg_accuracy=87.11% avg_sensitivity=63.50%, avg_specificity=93.95% avg_auc=89.59%
Best model saved!! Metric=8.150109468312692!!
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.383005 Test loss=0.327917 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.35951074957847595
[5/24] Train loss=0.3658476769924164
[10/24] Train loss=0.3734853267669678
[15/24] Train loss=0.3493921458721161
[20/24] Train loss=0.3365512788295746
Test set avg_accuracy=87.02% avg_sensitivity=64.60%, avg_specificity=93.52% avg_auc=89.84%
Best model saved!! Metric=8.97229550998398!!
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.368158 Test loss=0.323811 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.35368940234184265
[5/24] Train loss=0.3616737127304077
[10/24] Train loss=0.35696253180503845
[15/24] Train loss=0.34329670667648315
[20/24] Train loss=0.32854005694389343
Test set avg_accuracy=87.36% avg_sensitivity=64.72%, avg_specificity=93.92% avg_auc=90.17%
Best model saved!! Metric=10.157975005450893!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.356154 Test loss=0.315496 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.34137365221977234
[5/24] Train loss=0.355332612991333
[10/24] Train loss=0.3451436758041382
[15/24] Train loss=0.33640387654304504
[20/24] Train loss=0.3193305730819702
Test set avg_accuracy=87.63% avg_sensitivity=62.69%, avg_specificity=94.86% avg_auc=89.73%
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.347331 Test loss=0.312836 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.33400729298591614
[5/24] Train loss=0.3406156003475189
[10/24] Train loss=0.3438815474510193
[15/24] Train loss=0.3216087818145752
[20/24] Train loss=0.31157368421554565
Test set avg_accuracy=87.23% avg_sensitivity=66.69%, avg_specificity=93.18% avg_auc=90.19%
Best model saved!! Metric=11.283312764970802!!
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.337437 Test loss=0.313905 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3215794861316681
[5/24] Train loss=0.3459571301937103
[10/24] Train loss=0.33091649413108826
[15/24] Train loss=0.3161777853965759
[20/24] Train loss=0.30605778098106384
Test set avg_accuracy=87.72% avg_sensitivity=65.41%, avg_specificity=94.19% avg_auc=90.46%
Best model saved!! Metric=11.780546872739606!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.329666 Test loss=0.307095 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.31945154070854187
[5/24] Train loss=0.3317217230796814
[10/24] Train loss=0.3243354856967926
[15/24] Train loss=0.3049330413341522
[20/24] Train loss=0.3000200390815735
Test set avg_accuracy=87.38% avg_sensitivity=69.47%, avg_specificity=92.58% avg_auc=90.54%
Best model saved!! Metric=13.963032580485745!!
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.322415 Test loss=0.307515 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3045094311237335
[5/24] Train loss=0.3244377076625824
[10/24] Train loss=0.3171357810497284
[15/24] Train loss=0.29537782073020935
[20/24] Train loss=0.28746962547302246
Test set avg_accuracy=86.20% avg_sensitivity=75.38%, avg_specificity=89.33% avg_auc=91.20%
Best model saved!! Metric=16.10739804787002!!
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.314279 Test loss=0.324057 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3097688853740692
[5/24] Train loss=0.33158692717552185
[10/24] Train loss=0.3091496229171753
[15/24] Train loss=0.2955879271030426
[20/24] Train loss=0.2910171151161194
Test set avg_accuracy=86.76% avg_sensitivity=75.43%, avg_specificity=90.04% avg_auc=91.29%
Best model saved!! Metric=17.51843108567286!!
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.310505 Test loss=0.313912 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2960645854473114
[5/24] Train loss=0.3222769498825073
[10/24] Train loss=0.3031614422798157
[15/24] Train loss=0.2906580865383148
[20/24] Train loss=0.2861620783805847
Test set avg_accuracy=84.69% avg_sensitivity=82.50%, avg_specificity=85.32% avg_auc=90.91%
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.303845 Test loss=0.358182 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.29016655683517456
[5/24] Train loss=0.3098650276660919
[10/24] Train loss=0.29556897282600403
[15/24] Train loss=0.278499037027359
[20/24] Train loss=0.2685384750366211
Test set avg_accuracy=87.23% avg_sensitivity=71.15%, avg_specificity=91.89% avg_auc=90.39%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.295690 Test loss=0.312853 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.28035202622413635
[5/24] Train loss=0.30902042984962463
[10/24] Train loss=0.28571414947509766
[15/24] Train loss=0.2733150124549866
[20/24] Train loss=0.25970038771629333
Test set avg_accuracy=86.08% avg_sensitivity=78.56%, avg_specificity=88.26% avg_auc=91.67%
Best model saved!! Metric=18.578546149786774!!
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.289525 Test loss=0.323335 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2692907750606537
[5/24] Train loss=0.29433512687683105
[10/24] Train loss=0.28475135564804077
[15/24] Train loss=0.271500825881958
[20/24] Train loss=0.258769690990448
Test set avg_accuracy=88.67% avg_sensitivity=64.95%, avg_specificity=95.55% avg_auc=91.34%
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.284268 Test loss=0.289323 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2720199525356293
[5/24] Train loss=0.298184335231781
[10/24] Train loss=0.28583285212516785
[15/24] Train loss=0.26810115575790405
[20/24] Train loss=0.25573939085006714
Test set avg_accuracy=87.90% avg_sensitivity=67.15%, avg_specificity=93.92% avg_auc=90.54%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.282308 Test loss=0.300961 Current lr=[0.000210185142098938]

[0/24] Train loss=0.26519447565078735
[5/24] Train loss=0.28229087591171265
[10/24] Train loss=0.2736856937408447
[15/24] Train loss=0.26356446743011475
[20/24] Train loss=0.2639526128768921
Test set avg_accuracy=87.23% avg_sensitivity=75.20%, avg_specificity=90.71% avg_auc=91.53%
Best model saved!! Metric=18.671064594271613!!
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.274501 Test loss=0.306600 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.26537391543388367
[5/24] Train loss=0.2684307098388672
[10/24] Train loss=0.2667609453201294
[15/24] Train loss=0.25262734293937683
[20/24] Train loss=0.25193583965301514
Test set avg_accuracy=86.46% avg_sensitivity=75.20%, avg_specificity=89.72% avg_auc=91.02%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.269391 Test loss=0.318417 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2565644681453705
[5/24] Train loss=0.26569512486457825
[10/24] Train loss=0.2557380795478821
[15/24] Train loss=0.27009618282318115
[20/24] Train loss=0.2468036413192749
Test set avg_accuracy=87.93% avg_sensitivity=69.76%, avg_specificity=93.20% avg_auc=90.73%
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.263657 Test loss=0.302629 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2523215413093567
[5/24] Train loss=0.2681594789028168
[10/24] Train loss=0.27358171343803406
[15/24] Train loss=0.25074732303619385
[20/24] Train loss=0.2401522696018219
Test set avg_accuracy=81.20% avg_sensitivity=74.68%, avg_specificity=83.09% avg_auc=86.93%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.263346 Test loss=0.408397 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2601563632488251
[5/24] Train loss=0.27378374338150024
[10/24] Train loss=0.26855719089508057
[15/24] Train loss=0.24648350477218628
[20/24] Train loss=0.22450368106365204
Test set avg_accuracy=86.71% avg_sensitivity=64.08%, avg_specificity=93.27% avg_auc=89.35%
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.260336 Test loss=0.324483 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2554625868797302
[5/24] Train loss=0.26045989990234375
[10/24] Train loss=0.2576027810573578
[15/24] Train loss=0.24176032841205597
[20/24] Train loss=0.22914063930511475
Test set avg_accuracy=87.12% avg_sensitivity=61.70%, avg_specificity=94.49% avg_auc=90.44%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.254301 Test loss=0.311094 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.24619024991989136
[5/24] Train loss=0.2285957783460617
[10/24] Train loss=0.2551449239253998
[15/24] Train loss=0.23818469047546387
[20/24] Train loss=0.21708424389362335
Test set avg_accuracy=87.01% avg_sensitivity=51.04%, avg_specificity=97.43% avg_auc=88.48%
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.246778 Test loss=0.334839 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.24243804812431335
[5/24] Train loss=0.2359999567270279
[10/24] Train loss=0.235293909907341
[15/24] Train loss=0.2436630129814148
[20/24] Train loss=0.22340260446071625
Test set avg_accuracy=87.54% avg_sensitivity=55.16%, avg_specificity=96.93% avg_auc=90.04%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.243808 Test loss=0.309798 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.24022558331489563
[5/24] Train loss=0.2319943606853485
[10/24] Train loss=0.2364388257265091
[15/24] Train loss=0.22890283167362213
[20/24] Train loss=0.22303950786590576
Test set avg_accuracy=87.06% avg_sensitivity=50.06%, avg_specificity=97.78% avg_auc=86.67%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.241647 Test loss=0.357169 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.24704594910144806
[5/24] Train loss=0.2297917902469635
[10/24] Train loss=0.22347474098205566
[15/24] Train loss=0.2307877391576767
[20/24] Train loss=0.23011848330497742
Test set avg_accuracy=85.35% avg_sensitivity=39.69%, avg_specificity=98.59% avg_auc=85.16%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.238840 Test loss=0.398072 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.22662946581840515
[5/24] Train loss=0.22899362444877625
[10/24] Train loss=0.22651028633117676
[15/24] Train loss=0.22760100662708282
[20/24] Train loss=0.23708942532539368
Test set avg_accuracy=80.94% avg_sensitivity=16.34%, avg_specificity=99.66% avg_auc=75.70%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.241089 Test loss=0.519962 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.26803359389305115
[5/24] Train loss=0.2327442318201065
[10/24] Train loss=0.23018446564674377
[15/24] Train loss=0.2130131870508194
[20/24] Train loss=0.21570703387260437
Test set avg_accuracy=83.59% avg_sensitivity=29.49%, avg_specificity=99.28% avg_auc=82.73%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.238709 Test loss=0.471898 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.24723292887210846
[5/24] Train loss=0.23397497832775116
[10/24] Train loss=0.219913512468338
[15/24] Train loss=0.22456078231334686
[20/24] Train loss=0.2156985104084015
Test set avg_accuracy=82.25% avg_sensitivity=23.17%, avg_specificity=99.38% avg_auc=83.23%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.234647 Test loss=0.469240 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.22682467103004456
[5/24] Train loss=0.21081258356571198
[10/24] Train loss=0.23074690997600555
[15/24] Train loss=0.22863881289958954
[20/24] Train loss=0.20896640419960022
Test set avg_accuracy=88.45% avg_sensitivity=68.66%, avg_specificity=94.19% avg_auc=89.99%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.233133 Test loss=0.304049 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.22901149094104767
[5/24] Train loss=0.20742179453372955
[10/24] Train loss=0.2274109274148941
[15/24] Train loss=0.22984246909618378
[20/24] Train loss=0.22309814393520355
Test set avg_accuracy=88.10% avg_sensitivity=71.90%, avg_specificity=92.79% avg_auc=90.36%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.234184 Test loss=0.305775 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.22992220520973206
[5/24] Train loss=0.22071906924247742
[10/24] Train loss=0.22220812737941742
[15/24] Train loss=0.21948596835136414
[20/24] Train loss=0.20826394855976105
Test set avg_accuracy=87.41% avg_sensitivity=68.42%, avg_specificity=92.91% avg_auc=89.38%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.228753 Test loss=0.316860 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2292969822883606
[5/24] Train loss=0.20556917786598206
[10/24] Train loss=0.22386771440505981
[15/24] Train loss=0.22363980114459991
[20/24] Train loss=0.2128293216228485
Test set avg_accuracy=86.32% avg_sensitivity=63.38%, avg_specificity=92.96% avg_auc=88.85%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.224319 Test loss=0.333765 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2162095606327057
[5/24] Train loss=0.23162807524204254
[10/24] Train loss=0.2154635488986969
[15/24] Train loss=0.21959151327610016
[20/24] Train loss=0.21920087933540344
Test set avg_accuracy=85.51% avg_sensitivity=64.89%, avg_specificity=91.48% avg_auc=87.23%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.224387 Test loss=0.370046 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.22300957143306732
[5/24] Train loss=0.19656099379062653
[10/24] Train loss=0.21227028965950012
[15/24] Train loss=0.21878542006015778
[20/24] Train loss=0.21680039167404175
Test set avg_accuracy=85.60% avg_sensitivity=45.94%, avg_specificity=97.09% avg_auc=86.59%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.219278 Test loss=0.376126 Current lr=[0.000299720220882401]

[0/24] Train loss=0.20833303034305573
[5/24] Train loss=0.204459086060524
[10/24] Train loss=0.21468330919742584
[15/24] Train loss=0.21423271298408508
[20/24] Train loss=0.207429900765419
Test set avg_accuracy=87.53% avg_sensitivity=65.64%, avg_specificity=93.87% avg_auc=89.76%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.216282 Test loss=0.316145 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.22547297179698944
[5/24] Train loss=0.2073456197977066
[10/24] Train loss=0.21564042568206787
[15/24] Train loss=0.21326884627342224
[20/24] Train loss=0.1973310261964798
Test set avg_accuracy=87.03% avg_sensitivity=55.10%, avg_specificity=96.29% avg_auc=88.76%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.216900 Test loss=0.338479 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2101888507604599
[5/24] Train loss=0.2137787640094757
[10/24] Train loss=0.21882979571819305
[15/24] Train loss=0.21047458052635193
[20/24] Train loss=0.19989389181137085
Test set avg_accuracy=84.84% avg_sensitivity=37.54%, avg_specificity=98.56% avg_auc=83.49%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.214663 Test loss=0.418899 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.21477974951267242
[5/24] Train loss=0.2000950574874878
[10/24] Train loss=0.22180597484111786
[15/24] Train loss=0.19779762625694275
[20/24] Train loss=0.1940237432718277
Test set avg_accuracy=86.47% avg_sensitivity=52.09%, avg_specificity=96.44% avg_auc=87.67%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.214148 Test loss=0.355911 Current lr=[0.000297555943323901]

[0/24] Train loss=0.22324809432029724
[5/24] Train loss=0.18887116014957428
[10/24] Train loss=0.20699670910835266
[15/24] Train loss=0.20288096368312836
[20/24] Train loss=0.22067692875862122
Test set avg_accuracy=83.82% avg_sensitivity=80.48%, avg_specificity=84.78% avg_auc=89.68%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.214067 Test loss=0.386099 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.20837879180908203
[5/24] Train loss=0.20461612939834595
[10/24] Train loss=0.21642456948757172
[15/24] Train loss=0.2146540731191635
[20/24] Train loss=0.1967618465423584
Test set avg_accuracy=87.84% avg_sensitivity=69.87%, avg_specificity=93.05% avg_auc=90.20%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.212210 Test loss=0.313375 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2057386189699173
[5/24] Train loss=0.19330288469791412
[10/24] Train loss=0.21513937413692474
[15/24] Train loss=0.21075107157230377
[20/24] Train loss=0.2081419676542282
Test set avg_accuracy=85.44% avg_sensitivity=42.64%, avg_specificity=97.85% avg_auc=86.23%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.212164 Test loss=0.393159 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2106321156024933
[5/24] Train loss=0.19086231291294098
[10/24] Train loss=0.20363427698612213
[15/24] Train loss=0.21410410106182098
[20/24] Train loss=0.19481784105300903
Test set avg_accuracy=87.50% avg_sensitivity=58.98%, avg_specificity=95.77% avg_auc=89.48%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.207080 Test loss=0.340513 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.20575197041034698
[5/24] Train loss=0.1820693165063858
[10/24] Train loss=0.20743250846862793
[15/24] Train loss=0.20149554312229156
[20/24] Train loss=0.19980794191360474
Test set avg_accuracy=87.29% avg_sensitivity=73.29%, avg_specificity=91.35% avg_auc=90.13%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.205195 Test loss=0.318462 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.198432058095932
[5/24] Train loss=0.1914689540863037
[10/24] Train loss=0.19572515785694122
[15/24] Train loss=0.1987553834915161
[20/24] Train loss=0.20046721398830414
Test set avg_accuracy=87.90% avg_sensitivity=60.08%, avg_specificity=95.97% avg_auc=88.90%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.202480 Test loss=0.319725 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.19971372187137604
[5/24] Train loss=0.1832660436630249
[10/24] Train loss=0.19107845425605774
[15/24] Train loss=0.19690848886966705
[20/24] Train loss=0.19223588705062866
Test set avg_accuracy=88.07% avg_sensitivity=61.59%, avg_specificity=95.75% avg_auc=89.77%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.199818 Test loss=0.311719 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.1883254200220108
[5/24] Train loss=0.18863259255886078
[10/24] Train loss=0.21360625326633453
[15/24] Train loss=0.20743520557880402
[20/24] Train loss=0.1879768818616867
Test set avg_accuracy=86.67% avg_sensitivity=51.80%, avg_specificity=96.78% avg_auc=88.34%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.200952 Test loss=0.352144 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.20431385934352875
[5/24] Train loss=0.1859227567911148
[10/24] Train loss=0.18866856396198273
[15/24] Train loss=0.20130126178264618
[20/24] Train loss=0.20136091113090515
Test set avg_accuracy=85.26% avg_sensitivity=44.90%, avg_specificity=96.96% avg_auc=85.57%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.202187 Test loss=0.413398 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.20379281044006348
[5/24] Train loss=0.1759263426065445
[10/24] Train loss=0.2163182497024536
[15/24] Train loss=0.21273808181285858
[20/24] Train loss=0.19546113908290863
Test set avg_accuracy=87.19% avg_sensitivity=63.62%, avg_specificity=94.02% avg_auc=88.73%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.203782 Test loss=0.330070 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2095503956079483
[5/24] Train loss=0.18354569375514984
[10/24] Train loss=0.19291630387306213
[15/24] Train loss=0.20512153208255768
[20/24] Train loss=0.20018355548381805
Test set avg_accuracy=83.20% avg_sensitivity=29.55%, avg_specificity=98.76% avg_auc=83.66%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.199222 Test loss=0.442636 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.19343161582946777
[5/24] Train loss=0.1824023276567459
[10/24] Train loss=0.18311215937137604
[15/24] Train loss=0.19740168750286102
[20/24] Train loss=0.1869218945503235
Test set avg_accuracy=86.67% avg_sensitivity=49.42%, avg_specificity=97.46% avg_auc=87.03%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.193359 Test loss=0.382348 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.20403949916362762
[5/24] Train loss=0.1767364889383316
[10/24] Train loss=0.18944723904132843
[15/24] Train loss=0.20054221153259277
[20/24] Train loss=0.19189059734344482
Test set avg_accuracy=85.29% avg_sensitivity=79.37%, avg_specificity=87.00% avg_auc=90.04%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.195067 Test loss=0.353748 Current lr=[0.000276307469034998]

[0/24] Train loss=0.19010178744792938
[5/24] Train loss=0.16711080074310303
[10/24] Train loss=0.18949003517627716
[15/24] Train loss=0.19527140259742737
[20/24] Train loss=0.18017856776714325
Test set avg_accuracy=87.21% avg_sensitivity=55.74%, avg_specificity=96.34% avg_auc=87.87%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.192169 Test loss=0.349506 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.18497347831726074
[5/24] Train loss=0.1757270246744156
[10/24] Train loss=0.17712460458278656
[15/24] Train loss=0.2000417858362198
[20/24] Train loss=0.18143954873085022
Test set avg_accuracy=81.43% avg_sensitivity=20.68%, avg_specificity=99.04% avg_auc=75.79%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.189652 Test loss=0.552417 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.18916729092597961
[5/24] Train loss=0.16993889212608337
[10/24] Train loss=0.19000345468521118
[15/24] Train loss=0.1866556853055954
[20/24] Train loss=0.17940740287303925
Test set avg_accuracy=83.68% avg_sensitivity=34.53%, avg_specificity=97.93% avg_auc=79.95%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.185942 Test loss=0.475676 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.179857075214386
[5/24] Train loss=0.17196373641490936
[10/24] Train loss=0.1882360577583313
[15/24] Train loss=0.19937317073345184
[20/24] Train loss=0.17400698363780975
Test set avg_accuracy=86.58% avg_sensitivity=64.25%, avg_specificity=93.05% avg_auc=88.23%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.187467 Test loss=0.345870 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.18035270273685455
[5/24] Train loss=0.18216614425182343
[10/24] Train loss=0.1887677013874054
[15/24] Train loss=0.19131359457969666
[20/24] Train loss=0.18681035935878754
Test set avg_accuracy=86.69% avg_sensitivity=75.14%, avg_specificity=90.04% avg_auc=91.10%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.187882 Test loss=0.328574 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.18578164279460907
[5/24] Train loss=0.1676691770553589
[10/24] Train loss=0.18990930914878845
[15/24] Train loss=0.19282332062721252
[20/24] Train loss=0.18398672342300415
Test set avg_accuracy=83.37% avg_sensitivity=32.04%, avg_specificity=98.25% avg_auc=80.89%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.187563 Test loss=0.491017 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.18444287776947021
[5/24] Train loss=0.17019622027873993
[10/24] Train loss=0.17559261620044708
[15/24] Train loss=0.17684732377529144
[20/24] Train loss=0.17396876215934753
Test set avg_accuracy=87.64% avg_sensitivity=58.29%, avg_specificity=96.15% avg_auc=88.09%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.185237 Test loss=0.336283 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.19035854935646057
[5/24] Train loss=0.16564656794071198
[10/24] Train loss=0.19077222049236298
[15/24] Train loss=0.18507084250450134
[20/24] Train loss=0.17837423086166382
Test set avg_accuracy=85.49% avg_sensitivity=45.83%, avg_specificity=96.99% avg_auc=85.28%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.184121 Test loss=0.394897 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.18230202794075012
[5/24] Train loss=0.1705244928598404
[10/24] Train loss=0.17675499618053436
[15/24] Train loss=0.1890009492635727
[20/24] Train loss=0.18142640590667725
Test set avg_accuracy=87.99% avg_sensitivity=62.75%, avg_specificity=95.31% avg_auc=87.72%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.186385 Test loss=0.335879 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.18454056978225708
[5/24] Train loss=0.16523759067058563
[10/24] Train loss=0.19183829426765442
[15/24] Train loss=0.17903900146484375
[20/24] Train loss=0.17079417407512665
Test set avg_accuracy=84.30% avg_sensitivity=68.42%, avg_specificity=88.90% avg_auc=87.23%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.185322 Test loss=0.377898 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.17569176852703094
[5/24] Train loss=0.1703529804944992
[10/24] Train loss=0.1796611249446869
[15/24] Train loss=0.18940846621990204
[20/24] Train loss=0.16657431423664093
Test set avg_accuracy=87.90% avg_sensitivity=60.31%, avg_specificity=95.90% avg_auc=88.50%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.183880 Test loss=0.335506 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1842089146375656
[5/24] Train loss=0.16839587688446045
[10/24] Train loss=0.1793028712272644
[15/24] Train loss=0.18040326237678528
[20/24] Train loss=0.17867469787597656
Test set avg_accuracy=86.94% avg_sensitivity=51.56%, avg_specificity=97.20% avg_auc=84.98%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.180197 Test loss=0.377064 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.18349991738796234
[5/24] Train loss=0.16887515783309937
[10/24] Train loss=0.17700150609016418
[15/24] Train loss=0.1825154721736908
[20/24] Train loss=0.17591629922389984
Test set avg_accuracy=85.57% avg_sensitivity=54.69%, avg_specificity=94.52% avg_auc=84.62%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.180729 Test loss=0.380365 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.17624056339263916
[5/24] Train loss=0.16033393144607544
[10/24] Train loss=0.17376358807086945
[15/24] Train loss=0.18087950348854065
[20/24] Train loss=0.1705627143383026
Test set avg_accuracy=85.22% avg_sensitivity=60.54%, avg_specificity=92.37% avg_auc=85.00%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.179810 Test loss=0.384773 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.1779194325208664
[5/24] Train loss=0.16886760294437408
[10/24] Train loss=0.17483438551425934
[15/24] Train loss=0.1821187138557434
[20/24] Train loss=0.18610115349292755
Test set avg_accuracy=86.82% avg_sensitivity=67.56%, avg_specificity=92.41% avg_auc=89.58%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.180903 Test loss=0.334686 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.18813878297805786
[5/24] Train loss=0.1623595654964447
[10/24] Train loss=0.1701010912656784
[15/24] Train loss=0.18337680399417877
[20/24] Train loss=0.17266052961349487
Test set avg_accuracy=86.35% avg_sensitivity=56.26%, avg_specificity=95.08% avg_auc=86.53%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.185792 Test loss=0.363421 Current lr=[0.000224838296036774]

[0/24] Train loss=0.17917980253696442
[5/24] Train loss=0.15904833376407623
[10/24] Train loss=0.17818504571914673
[15/24] Train loss=0.18257218599319458
[20/24] Train loss=0.16492144763469696
Test set avg_accuracy=87.83% avg_sensitivity=70.97%, avg_specificity=92.71% avg_auc=90.16%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.177600 Test loss=0.312648 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.1732938289642334
[5/24] Train loss=0.1726287305355072
[10/24] Train loss=0.19234435260295868
[15/24] Train loss=0.17401307821273804
[20/24] Train loss=0.17248034477233887
Test set avg_accuracy=87.62% avg_sensitivity=70.80%, avg_specificity=92.49% avg_auc=90.24%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.180658 Test loss=0.309300 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.17886221408843994
[5/24] Train loss=0.15907974541187286
[10/24] Train loss=0.17296552658081055
[15/24] Train loss=0.1811295598745346
[20/24] Train loss=0.16347552835941315
Test set avg_accuracy=87.99% avg_sensitivity=64.37%, avg_specificity=94.84% avg_auc=88.58%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.180048 Test loss=0.323840 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.175650954246521
[5/24] Train loss=0.16092413663864136
[10/24] Train loss=0.164659321308136
[15/24] Train loss=0.17069754004478455
[20/24] Train loss=0.16801723837852478
Test set avg_accuracy=83.55% avg_sensitivity=80.36%, avg_specificity=84.48% avg_auc=90.43%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.174023 Test loss=0.384310 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.17055779695510864
[5/24] Train loss=0.1606369912624359
[10/24] Train loss=0.15931664407253265
[15/24] Train loss=0.162825345993042
[20/24] Train loss=0.1653478443622589
Test set avg_accuracy=87.72% avg_sensitivity=73.00%, avg_specificity=91.99% avg_auc=90.46%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.174050 Test loss=0.309356 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.17804116010665894
[5/24] Train loss=0.1566905528306961
[10/24] Train loss=0.16676968336105347
[15/24] Train loss=0.16824473440647125
[20/24] Train loss=0.16490615904331207
Test set avg_accuracy=87.88% avg_sensitivity=71.44%, avg_specificity=92.64% avg_auc=89.56%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.172776 Test loss=0.320763 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.18273894488811493
[5/24] Train loss=0.16264140605926514
[10/24] Train loss=0.16775186359882355
[15/24] Train loss=0.17552930116653442
[20/24] Train loss=0.16618411242961884
Test set avg_accuracy=86.78% avg_sensitivity=57.42%, avg_specificity=95.30% avg_auc=87.53%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.175336 Test loss=0.357414 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1728399693965912
[5/24] Train loss=0.15097370743751526
[10/24] Train loss=0.16310393810272217
[15/24] Train loss=0.17569002509117126
[20/24] Train loss=0.17136195302009583
Test set avg_accuracy=85.69% avg_sensitivity=78.68%, avg_specificity=87.72% avg_auc=90.85%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.172609 Test loss=0.344248 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.17631757259368896
[5/24] Train loss=0.157315194606781
[10/24] Train loss=0.1581306904554367
[15/24] Train loss=0.17782989144325256
[20/24] Train loss=0.1621350198984146
Test set avg_accuracy=87.34% avg_sensitivity=58.98%, avg_specificity=95.57% avg_auc=87.77%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.172522 Test loss=0.339856 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.16439715027809143
[5/24] Train loss=0.15201786160469055
[10/24] Train loss=0.16270187497138977
[15/24] Train loss=0.17195779085159302
[20/24] Train loss=0.16123810410499573
Test set avg_accuracy=87.63% avg_sensitivity=57.47%, avg_specificity=96.37% avg_auc=87.42%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.169257 Test loss=0.341388 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.16677305102348328
[5/24] Train loss=0.1562252640724182
[10/24] Train loss=0.16252140700817108
[15/24] Train loss=0.16343766450881958
[20/24] Train loss=0.16006667912006378
Test set avg_accuracy=87.76% avg_sensitivity=64.83%, avg_specificity=94.41% avg_auc=90.12%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.168275 Test loss=0.312982 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.15918582677841187
[5/24] Train loss=0.15653492510318756
[10/24] Train loss=0.15936900675296783
[15/24] Train loss=0.1642446666955948
[20/24] Train loss=0.1550695151090622
Test set avg_accuracy=85.51% avg_sensitivity=45.25%, avg_specificity=97.18% avg_auc=83.84%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.164652 Test loss=0.416130 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.16905899345874786
[5/24] Train loss=0.15534164011478424
[10/24] Train loss=0.1602959781885147
[15/24] Train loss=0.1590386927127838
[20/24] Train loss=0.1532878279685974
Test set avg_accuracy=87.72% avg_sensitivity=60.02%, avg_specificity=95.75% avg_auc=88.36%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.165401 Test loss=0.341895 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.17051303386688232
[5/24] Train loss=0.15568006038665771
[10/24] Train loss=0.15605990588665009
[15/24] Train loss=0.1664385050535202
[20/24] Train loss=0.1576901227235794
Test set avg_accuracy=86.97% avg_sensitivity=54.63%, avg_specificity=96.34% avg_auc=87.01%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.166088 Test loss=0.360599 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.16012679040431976
[5/24] Train loss=0.14790059626102448
[10/24] Train loss=0.15921813249588013
[15/24] Train loss=0.16000786423683167
[20/24] Train loss=0.1645822674036026
Test set avg_accuracy=87.03% avg_sensitivity=53.59%, avg_specificity=96.72% avg_auc=85.65%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.163189 Test loss=0.373713 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15703217685222626
[5/24] Train loss=0.15655775368213654
[10/24] Train loss=0.1608744114637375
[15/24] Train loss=0.16278213262557983
[20/24] Train loss=0.16056525707244873
Test set avg_accuracy=87.12% avg_sensitivity=55.39%, avg_specificity=96.32% avg_auc=87.04%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.162385 Test loss=0.364287 Current lr=[0.000156543481933168]

[0/24] Train loss=0.15785996615886688
[5/24] Train loss=0.1547170728445053
[10/24] Train loss=0.15540501475334167
[15/24] Train loss=0.1620149314403534
[20/24] Train loss=0.1572425812482834
Test set avg_accuracy=87.04% avg_sensitivity=55.33%, avg_specificity=96.24% avg_auc=86.89%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.163608 Test loss=0.363180 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.163883239030838
[5/24] Train loss=0.17258940637111664
[10/24] Train loss=0.15624727308750153
[15/24] Train loss=0.1624242514371872
[20/24] Train loss=0.1494174748659134
Test set avg_accuracy=87.47% avg_sensitivity=67.73%, avg_specificity=93.20% avg_auc=89.63%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.166171 Test loss=0.322686 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15754979848861694
[5/24] Train loss=0.15100426971912384
[10/24] Train loss=0.1580590307712555
[15/24] Train loss=0.1637120246887207
[20/24] Train loss=0.1607169508934021
Test set avg_accuracy=87.14% avg_sensitivity=53.48%, avg_specificity=96.89% avg_auc=85.60%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.162265 Test loss=0.368788 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.1580890417098999
[5/24] Train loss=0.16084182262420654
[10/24] Train loss=0.14721328020095825
[15/24] Train loss=0.16465838253498077
[20/24] Train loss=0.15309292078018188
Test set avg_accuracy=88.54% avg_sensitivity=67.03%, avg_specificity=94.78% avg_auc=89.66%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.161890 Test loss=0.316477 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1505090594291687
[5/24] Train loss=0.15047647058963776
[10/24] Train loss=0.15875110030174255
[15/24] Train loss=0.15918023884296417
[20/24] Train loss=0.15693563222885132
Test set avg_accuracy=86.72% avg_sensitivity=49.54%, avg_specificity=97.50% avg_auc=85.38%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.162364 Test loss=0.384500 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15665508806705475
[5/24] Train loss=0.1537470668554306
[10/24] Train loss=0.14823196828365326
[15/24] Train loss=0.1643465757369995
[20/24] Train loss=0.16486941277980804
Test set avg_accuracy=86.85% avg_sensitivity=55.79%, avg_specificity=95.85% avg_auc=85.77%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.164382 Test loss=0.371513 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.16396895051002502
[5/24] Train loss=0.14826025068759918
[10/24] Train loss=0.15270434319972992
[15/24] Train loss=0.15952864289283752
[20/24] Train loss=0.14735151827335358
Test set avg_accuracy=87.81% avg_sensitivity=71.84%, avg_specificity=92.44% avg_auc=90.23%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.160386 Test loss=0.313649 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1580774039030075
[5/24] Train loss=0.14407339692115784
[10/24] Train loss=0.15440325438976288
[15/24] Train loss=0.15888075530529022
[20/24] Train loss=0.14479230344295502
Test set avg_accuracy=87.63% avg_sensitivity=74.33%, avg_specificity=91.48% avg_auc=90.69%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.156790 Test loss=0.316534 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15006810426712036
[5/24] Train loss=0.15094676613807678
[10/24] Train loss=0.14854785799980164
[15/24] Train loss=0.15648309886455536
[20/24] Train loss=0.15107890963554382
Test set avg_accuracy=87.37% avg_sensitivity=69.64%, avg_specificity=92.51% avg_auc=90.20%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.156397 Test loss=0.317753 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.15341733396053314
[5/24] Train loss=0.1494743376970291
[10/24] Train loss=0.14354369044303894
[15/24] Train loss=0.15778742730617523
[20/24] Train loss=0.14659184217453003
Test set avg_accuracy=88.23% avg_sensitivity=66.80%, avg_specificity=94.44% avg_auc=89.92%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.155025 Test loss=0.310967 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15086641907691956
[5/24] Train loss=0.14188432693481445
[10/24] Train loss=0.14133508503437042
[15/24] Train loss=0.15118519961833954
[20/24] Train loss=0.14782944321632385
Test set avg_accuracy=88.49% avg_sensitivity=66.05%, avg_specificity=94.99% avg_auc=90.21%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.153263 Test loss=0.311330 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15121805667877197
[5/24] Train loss=0.14469395577907562
[10/24] Train loss=0.15163101255893707
[15/24] Train loss=0.15244503319263458
[20/24] Train loss=0.14075806736946106
Test set avg_accuracy=87.27% avg_sensitivity=75.67%, avg_specificity=90.63% avg_auc=90.99%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.151330 Test loss=0.319471 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15023408830165863
[5/24] Train loss=0.14383579790592194
[10/24] Train loss=0.144145205616951
[15/24] Train loss=0.15088345110416412
[20/24] Train loss=0.14046123623847961
Test set avg_accuracy=87.66% avg_sensitivity=75.49%, avg_specificity=91.18% avg_auc=90.32%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.148717 Test loss=0.321597 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14681661128997803
[5/24] Train loss=0.1417873203754425
[10/24] Train loss=0.13797882199287415
[15/24] Train loss=0.1465086191892624
[20/24] Train loss=0.13949380815029144
Test set avg_accuracy=87.51% avg_sensitivity=69.87%, avg_specificity=92.63% avg_auc=90.23%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.147905 Test loss=0.320218 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14852651953697205
[5/24] Train loss=0.14339260756969452
[10/24] Train loss=0.13824160397052765
[15/24] Train loss=0.14998437464237213
[20/24] Train loss=0.14229588210582733
Test set avg_accuracy=87.73% avg_sensitivity=75.43%, avg_specificity=91.30% avg_auc=90.15%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.147535 Test loss=0.323276 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.14552421867847443
[5/24] Train loss=0.13903413712978363
[10/24] Train loss=0.13495253026485443
[15/24] Train loss=0.14547809958457947
[20/24] Train loss=0.1410139799118042
Test set avg_accuracy=88.26% avg_sensitivity=69.06%, avg_specificity=93.82% avg_auc=90.29%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.145740 Test loss=0.311262 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1462041288614273
[5/24] Train loss=0.1428542137145996
[10/24] Train loss=0.13661882281303406
[15/24] Train loss=0.1432834267616272
[20/24] Train loss=0.13575050234794617
Test set avg_accuracy=87.55% avg_sensitivity=70.22%, avg_specificity=92.58% avg_auc=90.04%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.145967 Test loss=0.321484 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1512298732995987
[5/24] Train loss=0.13599996268749237
[10/24] Train loss=0.13578090071678162
[15/24] Train loss=0.1434422880411148
[20/24] Train loss=0.13596658408641815
Test set avg_accuracy=88.22% avg_sensitivity=68.71%, avg_specificity=93.87% avg_auc=90.34%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.144700 Test loss=0.310850 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14488881826400757
[5/24] Train loss=0.1393173187971115
[10/24] Train loss=0.1329423189163208
[15/24] Train loss=0.1446198672056198
[20/24] Train loss=0.13618993759155273
Test set avg_accuracy=88.09% avg_sensitivity=70.57%, avg_specificity=93.16% avg_auc=90.48%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.143281 Test loss=0.313397 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14702706038951874
[5/24] Train loss=0.13851889967918396
[10/24] Train loss=0.13574139773845673
[15/24] Train loss=0.1405307948589325
[20/24] Train loss=0.13916918635368347
Test set avg_accuracy=87.92% avg_sensitivity=68.02%, avg_specificity=93.68% avg_auc=89.14%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.143516 Test loss=0.321335 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14189599454402924
[5/24] Train loss=0.13729844987392426
[10/24] Train loss=0.13297836482524872
[15/24] Train loss=0.14447063207626343
[20/24] Train loss=0.13436299562454224
Test set avg_accuracy=87.83% avg_sensitivity=68.48%, avg_specificity=93.43% avg_auc=89.91%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.141748 Test loss=0.320064 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14252622425556183
[5/24] Train loss=0.1341502070426941
[10/24] Train loss=0.1296021044254303
[15/24] Train loss=0.13974934816360474
[20/24] Train loss=0.13343532383441925
Test set avg_accuracy=87.83% avg_sensitivity=74.74%, avg_specificity=91.62% avg_auc=90.44%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.140805 Test loss=0.316212 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14114971458911896
[5/24] Train loss=0.13032782077789307
[10/24] Train loss=0.13264812529087067
[15/24] Train loss=0.14031784236431122
[20/24] Train loss=0.13198864459991455
Test set avg_accuracy=87.16% avg_sensitivity=63.27%, avg_specificity=94.09% avg_auc=88.84%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.139530 Test loss=0.337384 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14496569335460663
[5/24] Train loss=0.13530153036117554
[10/24] Train loss=0.1298515349626541
[15/24] Train loss=0.1422872543334961
[20/24] Train loss=0.1309652030467987
Test set avg_accuracy=87.75% avg_sensitivity=70.34%, avg_specificity=92.79% avg_auc=90.16%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.139209 Test loss=0.318288 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14009875059127808
[5/24] Train loss=0.13446828722953796
[10/24] Train loss=0.14103621244430542
[15/24] Train loss=0.1373695433139801
[20/24] Train loss=0.13523997366428375
Test set avg_accuracy=87.14% avg_sensitivity=69.41%, avg_specificity=92.27% avg_auc=90.24%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.139518 Test loss=0.324431 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.13519757986068726
[5/24] Train loss=0.13456161320209503
[10/24] Train loss=0.12804535031318665
[15/24] Train loss=0.1393272876739502
[20/24] Train loss=0.13309445977210999
Test set avg_accuracy=87.46% avg_sensitivity=68.48%, avg_specificity=92.96% avg_auc=89.67%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.137629 Test loss=0.322088 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13746821880340576
[5/24] Train loss=0.1325826346874237
[10/24] Train loss=0.1290568858385086
[15/24] Train loss=0.14447441697120667
[20/24] Train loss=0.1326015144586563
Test set avg_accuracy=87.10% avg_sensitivity=64.02%, avg_specificity=93.79% avg_auc=89.22%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.137522 Test loss=0.332280 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1376940757036209
[5/24] Train loss=0.13233806192874908
[10/24] Train loss=0.1275804340839386
[15/24] Train loss=0.14161832630634308
[20/24] Train loss=0.12780562043190002
Test set avg_accuracy=87.28% avg_sensitivity=67.32%, avg_specificity=93.06% avg_auc=89.84%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.136028 Test loss=0.324451 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1349964588880539
[5/24] Train loss=0.12817011773586273
[10/24] Train loss=0.126018688082695
[15/24] Train loss=0.13806046545505524
[20/24] Train loss=0.134090393781662
Test set avg_accuracy=87.98% avg_sensitivity=68.42%, avg_specificity=93.65% avg_auc=89.89%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.135613 Test loss=0.319207 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1367684155702591
[5/24] Train loss=0.13213275372982025
[10/24] Train loss=0.1253213882446289
[15/24] Train loss=0.1344997137784958
[20/24] Train loss=0.13025613129138947
Test set avg_accuracy=87.85% avg_sensitivity=64.83%, avg_specificity=94.52% avg_auc=89.23%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.134211 Test loss=0.328972 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13884073495864868
[5/24] Train loss=0.12859976291656494
[10/24] Train loss=0.12237861007452011
[15/24] Train loss=0.13637180626392365
[20/24] Train loss=0.1274600625038147
Test set avg_accuracy=87.76% avg_sensitivity=64.77%, avg_specificity=94.42% avg_auc=89.09%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.133799 Test loss=0.332018 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13419552147388458
[5/24] Train loss=0.13096483051776886
[10/24] Train loss=0.1224978044629097
[15/24] Train loss=0.1361325979232788
[20/24] Train loss=0.1267032027244568
Test set avg_accuracy=87.59% avg_sensitivity=64.77%, avg_specificity=94.21% avg_auc=89.41%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.133266 Test loss=0.330747 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13221941888332367
[5/24] Train loss=0.13177871704101562
[10/24] Train loss=0.11978611350059509
[15/24] Train loss=0.13573452830314636
[20/24] Train loss=0.13381223380565643
Test set avg_accuracy=87.66% avg_sensitivity=62.92%, avg_specificity=94.83% avg_auc=89.47%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.132936 Test loss=0.327765 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13073104619979858
[5/24] Train loss=0.1284569650888443
[10/24] Train loss=0.1250735968351364
[15/24] Train loss=0.13361963629722595
[20/24] Train loss=0.12850195169448853
Test set avg_accuracy=88.33% avg_sensitivity=68.02%, avg_specificity=94.22% avg_auc=89.91%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.132679 Test loss=0.319909 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13104553520679474
[5/24] Train loss=0.13089625537395477
[10/24] Train loss=0.1218964233994484
[15/24] Train loss=0.13069842755794525
[20/24] Train loss=0.12817108631134033
Test set avg_accuracy=87.85% avg_sensitivity=65.47%, avg_specificity=94.34% avg_auc=89.76%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.131928 Test loss=0.324028 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13097457587718964
[5/24] Train loss=0.12906770408153534
[10/24] Train loss=0.12091090530157089
[15/24] Train loss=0.1305258572101593
[20/24] Train loss=0.12814271450042725
Test set avg_accuracy=87.97% avg_sensitivity=66.05%, avg_specificity=94.32% avg_auc=89.53%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.130957 Test loss=0.326658 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1316552460193634
[5/24] Train loss=0.1237921491265297
[10/24] Train loss=0.11899230629205704
[15/24] Train loss=0.1294994205236435
[20/24] Train loss=0.12563765048980713
Test set avg_accuracy=88.18% avg_sensitivity=68.25%, avg_specificity=93.95% avg_auc=89.87%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.130354 Test loss=0.317668 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12865443527698517
[5/24] Train loss=0.12420346587896347
[10/24] Train loss=0.11846461147069931
[15/24] Train loss=0.12961691617965698
[20/24] Train loss=0.12884537875652313
Test set avg_accuracy=88.15% avg_sensitivity=66.98%, avg_specificity=94.29% avg_auc=89.54%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.129045 Test loss=0.322606 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13090498745441437
[5/24] Train loss=0.12629449367523193
[10/24] Train loss=0.1180247813463211
[15/24] Train loss=0.12997281551361084
[20/24] Train loss=0.1290816068649292
Test set avg_accuracy=88.06% avg_sensitivity=68.02%, avg_specificity=93.87% avg_auc=89.83%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.129211 Test loss=0.322827 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1292034089565277
[5/24] Train loss=0.12444215267896652
[10/24] Train loss=0.11904992163181305
[15/24] Train loss=0.12722665071487427
[20/24] Train loss=0.12826162576675415
Test set avg_accuracy=88.26% avg_sensitivity=68.25%, avg_specificity=94.05% avg_auc=90.07%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.127983 Test loss=0.316916 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12689551711082458
[5/24] Train loss=0.12388385832309723
[10/24] Train loss=0.11930099874734879
[15/24] Train loss=0.1301102638244629
[20/24] Train loss=0.1247575581073761
Test set avg_accuracy=88.14% avg_sensitivity=65.93%, avg_specificity=94.58% avg_auc=89.72%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.127747 Test loss=0.320961 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12770810723304749
[5/24] Train loss=0.1249765083193779
[10/24] Train loss=0.1183597594499588
[15/24] Train loss=0.12863337993621826
[20/24] Train loss=0.12463153898715973
Test set avg_accuracy=88.20% avg_sensitivity=68.54%, avg_specificity=93.90% avg_auc=89.88%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.127911 Test loss=0.319466 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12865155935287476
[5/24] Train loss=0.12259363383054733
[10/24] Train loss=0.11697569489479065
[15/24] Train loss=0.12702398002147675
[20/24] Train loss=0.12225763499736786
Test set avg_accuracy=88.29% avg_sensitivity=68.60%, avg_specificity=94.00% avg_auc=90.23%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.127533 Test loss=0.313273 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12604838609695435
[5/24] Train loss=0.12135081738233566
[10/24] Train loss=0.11895249783992767
[15/24] Train loss=0.12577460706233978
[20/24] Train loss=0.12143651396036148
Test set avg_accuracy=88.22% avg_sensitivity=67.27%, avg_specificity=94.29% avg_auc=89.84%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.126490 Test loss=0.317724 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12589681148529053
[5/24] Train loss=0.12257394939661026
[10/24] Train loss=0.11558368057012558
[15/24] Train loss=0.1272205412387848
[20/24] Train loss=0.1287362277507782
Test set avg_accuracy=88.24% avg_sensitivity=68.08%, avg_specificity=94.09% avg_auc=90.00%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.127009 Test loss=0.316362 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12489831447601318
[5/24] Train loss=0.1213940754532814
[10/24] Train loss=0.11822276562452316
[15/24] Train loss=0.12989017367362976
[20/24] Train loss=0.1221950426697731
Test set avg_accuracy=88.26% avg_sensitivity=69.18%, avg_specificity=93.79% avg_auc=90.14%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.126420 Test loss=0.314521 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12675298750400543
[5/24] Train loss=0.12310627847909927
[10/24] Train loss=0.11557253450155258
[15/24] Train loss=0.12700238823890686
[20/24] Train loss=0.12454482913017273
Test set avg_accuracy=88.22% avg_sensitivity=67.73%, avg_specificity=94.16% avg_auc=90.03%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.125810 Test loss=0.316382 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12785020470619202
[5/24] Train loss=0.12262609601020813
[10/24] Train loss=0.11299179494380951
[15/24] Train loss=0.12676851451396942
[20/24] Train loss=0.1221950501203537
Test set avg_accuracy=88.31% avg_sensitivity=67.84%, avg_specificity=94.24% avg_auc=90.03%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.125309 Test loss=0.316804 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12742780148983002
[5/24] Train loss=0.1199505478143692
[10/24] Train loss=0.1172146275639534
[15/24] Train loss=0.1255386918783188
[20/24] Train loss=0.12451308965682983
Test set avg_accuracy=88.27% avg_sensitivity=67.73%, avg_specificity=94.22% avg_auc=90.04%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.125768 Test loss=0.316359 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13090626895427704
[5/24] Train loss=0.12122359126806259
[10/24] Train loss=0.11900025606155396
[15/24] Train loss=0.12415952980518341
[20/24] Train loss=0.12366515398025513
Test set avg_accuracy=88.33% avg_sensitivity=68.19%, avg_specificity=94.17% avg_auc=90.06%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.126153 Test loss=0.315815 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12513631582260132
[5/24] Train loss=0.12092160433530807
[10/24] Train loss=0.11609447002410889
[15/24] Train loss=0.12705098092556
[20/24] Train loss=0.12351392954587936
Test set avg_accuracy=88.32% avg_sensitivity=68.13%, avg_specificity=94.17% avg_auc=90.07%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.125419 Test loss=0.315801 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12633904814720154
[5/24] Train loss=0.12247612327337265
[10/24] Train loss=0.11676979809999466
[15/24] Train loss=0.12575024366378784
[20/24] Train loss=0.12369909882545471
Test set avg_accuracy=88.31% avg_sensitivity=68.19%, avg_specificity=94.14% avg_auc=90.09%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.126307 Test loss=0.315648 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1256052553653717
[5/24] Train loss=0.12362558394670486
[10/24] Train loss=0.11630502343177795
[15/24] Train loss=0.12541955709457397
[20/24] Train loss=0.12367576360702515
Test set avg_accuracy=88.31% avg_sensitivity=68.19%, avg_specificity=94.14% avg_auc=90.08%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.126032 Test loss=0.315765 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12901805341243744
[5/24] Train loss=0.12220007926225662
[10/24] Train loss=0.11965575814247131
[15/24] Train loss=0.1263614147901535
[20/24] Train loss=0.12696297466754913
Test set avg_accuracy=88.32% avg_sensitivity=68.19%, avg_specificity=94.16% avg_auc=90.07%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.126200 Test loss=0.315853 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=87.23% sen=75.20%, spe=90.71%, auc=91.53%!
Fold[10] Avg_overlap=0.62%(±0.29609386478317734)
Final Avg Result: avg_acc=86.35%(±0.6926028097709548) avg_sen=76.42% (±2.897680107358693) avg_spe=89.75% (±1.0622863440317494) avg_auc=91.87% (±0.6419383112789736) avg_overlap=0.52% (±0.2341185128564625)
