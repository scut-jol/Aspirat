/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/24] Train loss=0.724866509437561
[5/24] Train loss=0.7084258198738098
[10/24] Train loss=0.7030438184738159
[15/24] Train loss=0.6915863752365112
[20/24] Train loss=0.699049174785614
Test set avg_accuracy=62.37% avg_sensitivity=46.96%, avg_specificity=67.87% avg_auc=61.36%
Best model saved!! Metric=-87.44235607800299!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.702083 Test loss=0.671754 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6891613006591797
[5/24] Train loss=0.678253710269928
[10/24] Train loss=0.6839450001716614
[15/24] Train loss=0.6708183288574219
[20/24] Train loss=0.6661360859870911
Test set avg_accuracy=65.09% avg_sensitivity=69.72%, avg_specificity=63.44% avg_auc=71.20%
Best model saved!! Metric=-56.55335436466719!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.675826 Test loss=0.639681 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6542393565177917
[5/24] Train loss=0.6519799828529358
[10/24] Train loss=0.6518527269363403
[15/24] Train loss=0.6399480700492859
[20/24] Train loss=0.6400189995765686
Test set avg_accuracy=66.42% avg_sensitivity=75.11%, avg_specificity=63.32% avg_auc=75.63%
Best model saved!! Metric=-45.52792576530729!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.648040 Test loss=0.616542 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6335337162017822
[5/24] Train loss=0.6263009905815125
[10/24] Train loss=0.6291490793228149
[15/24] Train loss=0.6173033714294434
[20/24] Train loss=0.6046023964881897
Test set avg_accuracy=68.89% avg_sensitivity=78.72%, avg_specificity=65.38% avg_auc=78.99%
Best model saved!! Metric=-34.01215526691675!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.624587 Test loss=0.590918 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6045474410057068
[5/24] Train loss=0.5975430011749268
[10/24] Train loss=0.605973482131958
[15/24] Train loss=0.5877034664154053
[20/24] Train loss=0.5796193480491638
Test set avg_accuracy=72.50% avg_sensitivity=80.06%, avg_specificity=69.80% avg_auc=81.23%
Best model saved!! Metric=-22.410780330124425!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.597196 Test loss=0.558418 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5773520469665527
[5/24] Train loss=0.571528971195221
[10/24] Train loss=0.5840431451797485
[15/24] Train loss=0.5564124584197998
[20/24] Train loss=0.5543652772903442
Test set avg_accuracy=74.23% avg_sensitivity=80.70%, avg_specificity=71.92% avg_auc=82.77%
Best model saved!! Metric=-16.37595862757803!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.572404 Test loss=0.530653 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5500874519348145
[5/24] Train loss=0.5453258156776428
[10/24] Train loss=0.5590624213218689
[15/24] Train loss=0.5348604917526245
[20/24] Train loss=0.5297380089759827
Test set avg_accuracy=76.16% avg_sensitivity=78.92%, avg_specificity=75.17% avg_auc=83.99%
Best model saved!! Metric=-11.75966632662697!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.546539 Test loss=0.500927 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5263094305992126
[5/24] Train loss=0.5239962339401245
[10/24] Train loss=0.5269259810447693
[15/24] Train loss=0.5100758671760559
[20/24] Train loss=0.501788318157196
Test set avg_accuracy=77.47% avg_sensitivity=77.78%, avg_specificity=77.36% avg_auc=85.04%
Best model saved!! Metric=-8.337139820623364!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.520975 Test loss=0.478227 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.49918583035469055
[5/24] Train loss=0.499601274728775
[10/24] Train loss=0.505220890045166
[15/24] Train loss=0.4873177409172058
[20/24] Train loss=0.48073071241378784
Test set avg_accuracy=79.09% avg_sensitivity=77.04%, avg_specificity=79.82% avg_auc=86.16%
Best model saved!! Metric=-3.8899206514616367!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.496684 Test loss=0.453484 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4737832844257355
[5/24] Train loss=0.4696267545223236
[10/24] Train loss=0.47602713108062744
[15/24] Train loss=0.4679471552371979
[20/24] Train loss=0.45367422699928284
Test set avg_accuracy=80.35% avg_sensitivity=77.34%, avg_specificity=81.43% avg_auc=87.26%
Best model saved!! Metric=0.3738156767737735!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.473078 Test loss=0.435611 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.44750669598579407
[5/24] Train loss=0.45330438017845154
[10/24] Train loss=0.4627074599266052
[15/24] Train loss=0.44029393792152405
[20/24] Train loss=0.4335763156414032
Test set avg_accuracy=82.42% avg_sensitivity=74.57%, avg_specificity=85.23% avg_auc=88.15%
Best model saved!! Metric=4.366031597815208!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.450824 Test loss=0.412196 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4310377538204193
[5/24] Train loss=0.4265228509902954
[10/24] Train loss=0.43547818064689636
[15/24] Train loss=0.4231663644313812
[20/24] Train loss=0.4079970121383667
Test set avg_accuracy=82.28% avg_sensitivity=77.19%, avg_specificity=84.10% avg_auc=88.97%
Best model saved!! Metric=6.532986215321756!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.431402 Test loss=0.404284 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.406899094581604
[5/24] Train loss=0.4108331501483917
[10/24] Train loss=0.41466817259788513
[15/24] Train loss=0.41119301319122314
[20/24] Train loss=0.3951258659362793
Test set avg_accuracy=84.01% avg_sensitivity=73.78%, avg_specificity=87.67% avg_auc=89.41%
Best model saved!! Metric=8.86046360708437!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.412933 Test loss=0.384963 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3947279751300812
[5/24] Train loss=0.39396220445632935
[10/24] Train loss=0.40411216020584106
[15/24] Train loss=0.3910248279571533
[20/24] Train loss=0.379756897687912
Test set avg_accuracy=84.65% avg_sensitivity=72.24%, avg_specificity=89.08% avg_auc=89.92%
Best model saved!! Metric=9.890594533075316!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.397385 Test loss=0.370074 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3774729073047638
[5/24] Train loss=0.374956876039505
[10/24] Train loss=0.3901894986629486
[15/24] Train loss=0.38207805156707764
[20/24] Train loss=0.37631645798683167
Test set avg_accuracy=83.28% avg_sensitivity=77.73%, avg_specificity=85.26% avg_auc=90.16%
Best model saved!! Metric=10.439775708021244!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.385247 Test loss=0.382387 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3683334290981293
[5/24] Train loss=0.3652084171772003
[10/24] Train loss=0.3858523964881897
[15/24] Train loss=0.37384793162345886
[20/24] Train loss=0.3530004024505615
Test set avg_accuracy=83.96% avg_sensitivity=76.40%, avg_specificity=86.66% avg_auc=90.40%
Best model saved!! Metric=11.417934364702205!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.373093 Test loss=0.369322 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.35028204321861267
[5/24] Train loss=0.35349610447883606
[10/24] Train loss=0.3685399293899536
[15/24] Train loss=0.3632102310657501
[20/24] Train loss=0.3404300808906555
Test set avg_accuracy=83.85% avg_sensitivity=77.24%, avg_specificity=86.22% avg_auc=90.54%
Best model saved!! Metric=11.848342854685058!!
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.361916 Test loss=0.367501 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.338977187871933
[5/24] Train loss=0.3454636335372925
[10/24] Train loss=0.36748647689819336
[15/24] Train loss=0.34940147399902344
[20/24] Train loss=0.33661526441574097
Test set avg_accuracy=83.31% avg_sensitivity=78.67%, avg_specificity=84.96% avg_auc=90.47%
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.353299 Test loss=0.375784 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3300550580024719
[5/24] Train loss=0.3436753749847412
[10/24] Train loss=0.35871487855911255
[15/24] Train loss=0.3483070433139801
[20/24] Train loss=0.3261965215206146
Test set avg_accuracy=83.42% avg_sensitivity=78.23%, avg_specificity=85.28% avg_auc=90.59%
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.346208 Test loss=0.370697 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.32981061935424805
[5/24] Train loss=0.33505135774612427
[10/24] Train loss=0.35037556290626526
[15/24] Train loss=0.33796223998069763
[20/24] Train loss=0.3151039183139801
Test set avg_accuracy=84.32% avg_sensitivity=76.20%, avg_specificity=87.22% avg_auc=90.75%
Best model saved!! Metric=12.49550316543612!!
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.339418 Test loss=0.358438 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3283487856388092
[5/24] Train loss=0.32769638299942017
[10/24] Train loss=0.3460467755794525
[15/24] Train loss=0.34253937005996704
[20/24] Train loss=0.313880056142807
Test set avg_accuracy=84.22% avg_sensitivity=75.75%, avg_specificity=87.24% avg_auc=90.78%
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.335210 Test loss=0.352205 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3214649260044098
[5/24] Train loss=0.32462161779403687
[10/24] Train loss=0.34062692523002625
[15/24] Train loss=0.33231309056282043
[20/24] Train loss=0.30170002579689026
Test set avg_accuracy=83.07% avg_sensitivity=78.53%, avg_specificity=84.70% avg_auc=90.47%
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.328483 Test loss=0.370674 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.31251195073127747
[5/24] Train loss=0.3203217387199402
[10/24] Train loss=0.33702147006988525
[15/24] Train loss=0.3219604790210724
[20/24] Train loss=0.3006545305252075
Test set avg_accuracy=82.96% avg_sensitivity=78.38%, avg_specificity=84.59% avg_auc=90.43%
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.321951 Test loss=0.369679 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3129998743534088
[5/24] Train loss=0.30851832032203674
[10/24] Train loss=0.3275134563446045
[15/24] Train loss=0.3191753029823303
[20/24] Train loss=0.2981984317302704
Test set avg_accuracy=85.66% avg_sensitivity=67.69%, avg_specificity=92.08% avg_auc=90.93%
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.319134 Test loss=0.332629 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.30451858043670654
[5/24] Train loss=0.3171330988407135
[10/24] Train loss=0.32223790884017944
[15/24] Train loss=0.32081612944602966
[20/24] Train loss=0.2960335612297058
Test set avg_accuracy=84.75% avg_sensitivity=72.44%, avg_specificity=89.15% avg_auc=90.71%
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.314126 Test loss=0.340257 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.29514068365097046
[5/24] Train loss=0.2971736490726471
[10/24] Train loss=0.3299100995063782
[15/24] Train loss=0.31561246514320374
[20/24] Train loss=0.29647961258888245
Test set avg_accuracy=84.61% avg_sensitivity=73.43%, avg_specificity=88.60% avg_auc=90.58%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.307485 Test loss=0.345359 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.29027634859085083
[5/24] Train loss=0.2944381833076477
[10/24] Train loss=0.311200886964798
[15/24] Train loss=0.3034968674182892
[20/24] Train loss=0.2874065339565277
Test set avg_accuracy=81.63% avg_sensitivity=79.17%, avg_specificity=82.51% avg_auc=89.09%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.301234 Test loss=0.400932 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2849158048629761
[5/24] Train loss=0.2854132354259491
[10/24] Train loss=0.31229230761528015
[15/24] Train loss=0.3047720193862915
[20/24] Train loss=0.28495070338249207
Test set avg_accuracy=84.01% avg_sensitivity=51.90%, avg_specificity=95.48% avg_auc=89.48%
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.294831 Test loss=0.357771 Current lr=[0.000210185142098938]

[0/24] Train loss=0.296782910823822
[5/24] Train loss=0.277706503868103
[10/24] Train loss=0.31815415620803833
[15/24] Train loss=0.2986491620540619
[20/24] Train loss=0.27837443351745605
Test set avg_accuracy=84.02% avg_sensitivity=73.73%, avg_specificity=87.70% avg_auc=90.23%
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.292965 Test loss=0.356985 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2818152904510498
[5/24] Train loss=0.27983367443084717
[10/24] Train loss=0.31171557307243347
[15/24] Train loss=0.29636403918266296
[20/24] Train loss=0.2854083180427551
Test set avg_accuracy=84.79% avg_sensitivity=65.71%, avg_specificity=91.61% avg_auc=89.61%
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.288732 Test loss=0.347513 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.27659475803375244
[5/24] Train loss=0.26506173610687256
[10/24] Train loss=0.3053692579269409
[15/24] Train loss=0.28823766112327576
[20/24] Train loss=0.2666437327861786
Test set avg_accuracy=82.76% avg_sensitivity=42.16%, avg_specificity=97.26% avg_auc=88.34%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.282894 Test loss=0.398117 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.27410051226615906
[5/24] Train loss=0.26196181774139404
[10/24] Train loss=0.2868540585041046
[15/24] Train loss=0.2859002649784088
[20/24] Train loss=0.2692670226097107
Test set avg_accuracy=83.18% avg_sensitivity=57.84%, avg_specificity=92.22% avg_auc=87.70%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.275997 Test loss=0.375111 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2686804533004761
[5/24] Train loss=0.24973763525485992
[10/24] Train loss=0.2821786403656006
[15/24] Train loss=0.28034457564353943
[20/24] Train loss=0.26872316002845764
Test set avg_accuracy=83.98% avg_sensitivity=57.25%, avg_specificity=93.53% avg_auc=88.05%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.275423 Test loss=0.372699 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.25824040174484253
[5/24] Train loss=0.25736549496650696
[10/24] Train loss=0.29951146245002747
[15/24] Train loss=0.27654361724853516
[20/24] Train loss=0.27518412470817566
Test set avg_accuracy=85.57% avg_sensitivity=60.02%, avg_specificity=94.70% avg_auc=89.46%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.273676 Test loss=0.350833 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.253618985414505
[5/24] Train loss=0.24922116100788116
[10/24] Train loss=0.2855112552642822
[15/24] Train loss=0.2742863595485687
[20/24] Train loss=0.26206737756729126
Test set avg_accuracy=83.19% avg_sensitivity=70.31%, avg_specificity=87.79% avg_auc=88.22%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.268178 Test loss=0.378768 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.24929845333099365
[5/24] Train loss=0.23930706083774567
[10/24] Train loss=0.2943992018699646
[15/24] Train loss=0.2750948667526245
[20/24] Train loss=0.25984734296798706
Test set avg_accuracy=84.91% avg_sensitivity=56.41%, avg_specificity=95.09% avg_auc=88.31%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.264677 Test loss=0.362573 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.24964118003845215
[5/24] Train loss=0.23008909821510315
[10/24] Train loss=0.29281675815582275
[15/24] Train loss=0.2683432996273041
[20/24] Train loss=0.2641519606113434
Test set avg_accuracy=83.44% avg_sensitivity=56.66%, avg_specificity=93.00% avg_auc=87.42%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.263704 Test loss=0.377316 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.25808942317962646
[5/24] Train loss=0.2389557957649231
[10/24] Train loss=0.28932833671569824
[15/24] Train loss=0.2845568358898163
[20/24] Train loss=0.26080185174942017
Test set avg_accuracy=71.99% avg_sensitivity=72.54%, avg_specificity=71.80% avg_auc=79.16%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.269106 Test loss=0.560573 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2669127881526947
[5/24] Train loss=0.23814994096755981
[10/24] Train loss=0.2812263071537018
[15/24] Train loss=0.25740474462509155
[20/24] Train loss=0.25528454780578613
Test set avg_accuracy=83.87% avg_sensitivity=61.55%, avg_specificity=91.84% avg_auc=88.98%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.260875 Test loss=0.357169 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2561846375465393
[5/24] Train loss=0.22453773021697998
[10/24] Train loss=0.28141945600509644
[15/24] Train loss=0.26665371656417847
[20/24] Train loss=0.25460511445999146
Test set avg_accuracy=83.46% avg_sensitivity=47.35%, avg_specificity=96.36% avg_auc=86.59%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.256547 Test loss=0.422344 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.23765288293361664
[5/24] Train loss=0.21627551317214966
[10/24] Train loss=0.27347221970558167
[15/24] Train loss=0.27196210622787476
[20/24] Train loss=0.25155705213546753
Test set avg_accuracy=80.14% avg_sensitivity=28.40%, avg_specificity=98.62% avg_auc=82.14%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.254712 Test loss=0.516192 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.23450560867786407
[5/24] Train loss=0.20024876296520233
[10/24] Train loss=0.2587435245513916
[15/24] Train loss=0.24966596066951752
[20/24] Train loss=0.25453677773475647
Test set avg_accuracy=84.22% avg_sensitivity=53.79%, avg_specificity=95.09% avg_auc=89.00%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.247416 Test loss=0.360575 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2420247495174408
[5/24] Train loss=0.22534480690956116
[10/24] Train loss=0.28674957156181335
[15/24] Train loss=0.26337215304374695
[20/24] Train loss=0.24905499815940857
Test set avg_accuracy=83.54% avg_sensitivity=50.52%, avg_specificity=95.33% avg_auc=85.50%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.252295 Test loss=0.416640 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.23234526813030243
[5/24] Train loss=0.20402716100215912
[10/24] Train loss=0.26033082604408264
[15/24] Train loss=0.2629854381084442
[20/24] Train loss=0.24496477842330933
Test set avg_accuracy=81.45% avg_sensitivity=47.35%, avg_specificity=93.62% avg_auc=82.49%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.248531 Test loss=0.440449 Current lr=[0.00029967723776099]

[0/24] Train loss=0.22567619383335114
[5/24] Train loss=0.21434661746025085
[10/24] Train loss=0.25510579347610474
[15/24] Train loss=0.26270830631256104
[20/24] Train loss=0.23946994543075562
Test set avg_accuracy=83.66% avg_sensitivity=54.63%, avg_specificity=94.03% avg_auc=86.59%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.243037 Test loss=0.396748 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.23267537355422974
[5/24] Train loss=0.2148529440164566
[10/24] Train loss=0.2678910195827484
[15/24] Train loss=0.26191118359565735
[20/24] Train loss=0.24372616410255432
Test set avg_accuracy=80.55% avg_sensitivity=37.75%, avg_specificity=95.83% avg_auc=85.68%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.247312 Test loss=0.425706 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.24886953830718994
[5/24] Train loss=0.21702973544597626
[10/24] Train loss=0.25907108187675476
[15/24] Train loss=0.2685946226119995
[20/24] Train loss=0.24135500192642212
Test set avg_accuracy=81.69% avg_sensitivity=54.13%, avg_specificity=91.54% avg_auc=83.50%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.249711 Test loss=0.423491 Current lr=[0.000299720220882401]

[0/24] Train loss=0.23927702009677887
[5/24] Train loss=0.21072903275489807
[10/24] Train loss=0.26251277327537537
[15/24] Train loss=0.2549055218696594
[20/24] Train loss=0.23912246525287628
Test set avg_accuracy=82.45% avg_sensitivity=70.86%, avg_specificity=86.59% avg_auc=88.63%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.247981 Test loss=0.376308 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.24336332082748413
[5/24] Train loss=0.21955972909927368
[10/24] Train loss=0.25569501519203186
[15/24] Train loss=0.2500719428062439
[20/24] Train loss=0.23246316611766815
Test set avg_accuracy=83.78% avg_sensitivity=57.94%, avg_specificity=93.00% avg_auc=87.29%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.248698 Test loss=0.375966 Current lr=[0.000298904600941902]

[0/24] Train loss=0.22783975303173065
[5/24] Train loss=0.21108056604862213
[10/24] Train loss=0.25443631410598755
[15/24] Train loss=0.2398364543914795
[20/24] Train loss=0.23563554883003235
Test set avg_accuracy=84.44% avg_sensitivity=56.80%, avg_specificity=94.31% avg_auc=87.82%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.241447 Test loss=0.366069 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.22553750872612
[5/24] Train loss=0.21015937626361847
[10/24] Train loss=0.253797709941864
[15/24] Train loss=0.25385943055152893
[20/24] Train loss=0.22016102075576782
Test set avg_accuracy=80.31% avg_sensitivity=28.90%, avg_specificity=98.67% avg_auc=80.92%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.244092 Test loss=0.536617 Current lr=[0.000297555943323901]

[0/24] Train loss=0.22833256423473358
[5/24] Train loss=0.19718144834041595
[10/24] Train loss=0.25189924240112305
[15/24] Train loss=0.25307440757751465
[20/24] Train loss=0.22307854890823364
Test set avg_accuracy=82.96% avg_sensitivity=43.54%, avg_specificity=97.03% avg_auc=85.64%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.237313 Test loss=0.425577 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.21727138757705688
[5/24] Train loss=0.20858550071716309
[10/24] Train loss=0.2554328441619873
[15/24] Train loss=0.2612107992172241
[20/24] Train loss=0.2231694757938385
Test set avg_accuracy=83.65% avg_sensitivity=58.34%, avg_specificity=92.68% avg_auc=88.24%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.234142 Test loss=0.367359 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.21250700950622559
[5/24] Train loss=0.2246222048997879
[10/24] Train loss=0.2551090717315674
[15/24] Train loss=0.24763864278793335
[20/24] Train loss=0.22334076464176178
Test set avg_accuracy=79.52% avg_sensitivity=25.43%, avg_specificity=98.83% avg_auc=81.23%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.234897 Test loss=0.554417 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.21827974915504456
[5/24] Train loss=0.2060444951057434
[10/24] Train loss=0.23908129334449768
[15/24] Train loss=0.2527313232421875
[20/24] Train loss=0.22682133316993713
Test set avg_accuracy=80.79% avg_sensitivity=76.15%, avg_specificity=82.45% avg_auc=88.37%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.232452 Test loss=0.402956 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.21674244105815887
[5/24] Train loss=0.19370034337043762
[10/24] Train loss=0.2366025298833847
[15/24] Train loss=0.23611925542354584
[20/24] Train loss=0.21178577840328217
Test set avg_accuracy=84.45% avg_sensitivity=63.48%, avg_specificity=91.94% avg_auc=88.42%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.228191 Test loss=0.365092 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.21473023295402527
[5/24] Train loss=0.196793332695961
[10/24] Train loss=0.24404403567314148
[15/24] Train loss=0.235868439078331
[20/24] Train loss=0.2325906604528427
Test set avg_accuracy=82.96% avg_sensitivity=45.47%, avg_specificity=96.34% avg_auc=85.60%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.227309 Test loss=0.432391 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.21858921647071838
[5/24] Train loss=0.22330136597156525
[10/24] Train loss=0.23243500292301178
[15/24] Train loss=0.2474408596754074
[20/24] Train loss=0.22269447147846222
Test set avg_accuracy=85.04% avg_sensitivity=66.30%, avg_specificity=91.73% avg_auc=89.53%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.229353 Test loss=0.348257 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.21988248825073242
[5/24] Train loss=0.2016805112361908
[10/24] Train loss=0.2311943769454956
[15/24] Train loss=0.23794080317020416
[20/24] Train loss=0.21646077930927277
Test set avg_accuracy=83.80% avg_sensitivity=69.27%, avg_specificity=88.99% avg_auc=89.37%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.225771 Test loss=0.358214 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.21981483697891235
[5/24] Train loss=0.19249942898750305
[10/24] Train loss=0.23926357924938202
[15/24] Train loss=0.23232610523700714
[20/24] Train loss=0.23630879819393158
Test set avg_accuracy=81.61% avg_sensitivity=74.96%, avg_specificity=83.99% avg_auc=87.50%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.223480 Test loss=0.407028 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.1975509077310562
[5/24] Train loss=0.18237146735191345
[10/24] Train loss=0.23017153143882751
[15/24] Train loss=0.23052215576171875
[20/24] Train loss=0.23100686073303223
Test set avg_accuracy=83.05% avg_sensitivity=58.04%, avg_specificity=91.98% avg_auc=86.94%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.221087 Test loss=0.402689 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.20654813945293427
[5/24] Train loss=0.19841217994689941
[10/24] Train loss=0.2369745820760727
[15/24] Train loss=0.23843172192573547
[20/24] Train loss=0.223414808511734
Test set avg_accuracy=84.21% avg_sensitivity=67.29%, avg_specificity=90.25% avg_auc=88.40%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.221058 Test loss=0.367604 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.20128077268600464
[5/24] Train loss=0.1944485753774643
[10/24] Train loss=0.23914173245429993
[15/24] Train loss=0.23139245808124542
[20/24] Train loss=0.22837820649147034
Test set avg_accuracy=83.65% avg_sensitivity=58.49%, avg_specificity=92.63% avg_auc=87.13%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.220124 Test loss=0.380121 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.20173142850399017
[5/24] Train loss=0.196422278881073
[10/24] Train loss=0.2157798409461975
[15/24] Train loss=0.22772465646266937
[20/24] Train loss=0.22359253466129303
Test set avg_accuracy=83.40% avg_sensitivity=73.68%, avg_specificity=86.87% avg_auc=88.93%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.216673 Test loss=0.380349 Current lr=[0.000276307469034998]

[0/24] Train loss=0.19391316175460815
[5/24] Train loss=0.18473221361637115
[10/24] Train loss=0.22104518115520477
[15/24] Train loss=0.2312910407781601
[20/24] Train loss=0.21418486535549164
Test set avg_accuracy=83.01% avg_sensitivity=67.00%, avg_specificity=88.73% avg_auc=87.26%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.213719 Test loss=0.386273 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.19676490128040314
[5/24] Train loss=0.18917661905288696
[10/24] Train loss=0.22192959487438202
[15/24] Train loss=0.22441579401493073
[20/24] Train loss=0.2133152186870575
Test set avg_accuracy=83.59% avg_sensitivity=52.25%, avg_specificity=94.79% avg_auc=86.54%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.211867 Test loss=0.404532 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.1969916820526123
[5/24] Train loss=0.1811976283788681
[10/24] Train loss=0.22146032750606537
[15/24] Train loss=0.233383908867836
[20/24] Train loss=0.2233850657939911
Test set avg_accuracy=82.14% avg_sensitivity=47.85%, avg_specificity=94.38% avg_auc=83.63%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.215864 Test loss=0.451444 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.20036102831363678
[5/24] Train loss=0.18066298961639404
[10/24] Train loss=0.21123483777046204
[15/24] Train loss=0.22130407392978668
[20/24] Train loss=0.21377304196357727
Test set avg_accuracy=80.89% avg_sensitivity=75.90%, avg_specificity=82.66% avg_auc=86.28%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.209156 Test loss=0.438316 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.19565211236476898
[5/24] Train loss=0.17859701812267303
[10/24] Train loss=0.21099621057510376
[15/24] Train loss=0.21073897182941437
[20/24] Train loss=0.20633646845817566
Test set avg_accuracy=79.47% avg_sensitivity=32.66%, avg_specificity=96.18% avg_auc=74.92%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.206968 Test loss=0.535890 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.19095902144908905
[5/24] Train loss=0.1833881139755249
[10/24] Train loss=0.22758731245994568
[15/24] Train loss=0.2213008999824524
[20/24] Train loss=0.2117694467306137
Test set avg_accuracy=82.73% avg_sensitivity=50.02%, avg_specificity=94.42% avg_auc=85.74%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.209756 Test loss=0.417145 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.18887481093406677
[5/24] Train loss=0.17808854579925537
[10/24] Train loss=0.2111247181892395
[15/24] Train loss=0.21690236032009125
[20/24] Train loss=0.1972718983888626
Test set avg_accuracy=79.95% avg_sensitivity=67.44%, avg_specificity=84.41% avg_auc=85.55%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.205197 Test loss=0.427176 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.20524652302265167
[5/24] Train loss=0.18044066429138184
[10/24] Train loss=0.2274853140115738
[15/24] Train loss=0.22840356826782227
[20/24] Train loss=0.1995648592710495
Test set avg_accuracy=80.00% avg_sensitivity=54.73%, avg_specificity=89.03% avg_auc=84.33%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.209319 Test loss=0.438188 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.19375519454479218
[5/24] Train loss=0.1751125454902649
[10/24] Train loss=0.23488953709602356
[15/24] Train loss=0.21874095499515533
[20/24] Train loss=0.20918263494968414
Test set avg_accuracy=81.51% avg_sensitivity=40.97%, avg_specificity=95.99% avg_auc=83.95%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.207695 Test loss=0.470332 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.18735533952713013
[5/24] Train loss=0.17265072464942932
[10/24] Train loss=0.2124302238225937
[15/24] Train loss=0.21249991655349731
[20/24] Train loss=0.21078060567378998
Test set avg_accuracy=80.12% avg_sensitivity=82.04%, avg_specificity=79.43% avg_auc=87.75%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.203897 Test loss=0.455757 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.18454407155513763
[5/24] Train loss=0.16867078840732574
[10/24] Train loss=0.21246889233589172
[15/24] Train loss=0.20824436843395233
[20/24] Train loss=0.20164859294891357
Test set avg_accuracy=81.43% avg_sensitivity=70.01%, avg_specificity=85.51% avg_auc=86.47%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.202548 Test loss=0.410703 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1802939921617508
[5/24] Train loss=0.1720319241285324
[10/24] Train loss=0.205366313457489
[15/24] Train loss=0.20833387970924377
[20/24] Train loss=0.20344820618629456
Test set avg_accuracy=81.86% avg_sensitivity=41.07%, avg_specificity=96.43% avg_auc=84.64%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.203966 Test loss=0.458343 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.19506895542144775
[5/24] Train loss=0.17934532463550568
[10/24] Train loss=0.21393230557441711
[15/24] Train loss=0.21782220900058746
[20/24] Train loss=0.2101653665304184
Test set avg_accuracy=80.13% avg_sensitivity=75.75%, avg_specificity=81.69% avg_auc=86.57%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.205766 Test loss=0.433685 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.19196230173110962
[5/24] Train loss=0.17678385972976685
[10/24] Train loss=0.21812182664871216
[15/24] Train loss=0.2136908918619156
[20/24] Train loss=0.21139079332351685
Test set avg_accuracy=71.69% avg_sensitivity=82.53%, avg_specificity=67.82% avg_auc=82.41%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.205301 Test loss=0.609746 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.19069889187812805
[5/24] Train loss=0.1928805708885193
[10/24] Train loss=0.20584923028945923
[15/24] Train loss=0.22248171269893646
[20/24] Train loss=0.20328201353549957
Test set avg_accuracy=81.88% avg_sensitivity=70.36%, avg_specificity=85.99% avg_auc=86.64%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.206506 Test loss=0.408523 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.1920265257358551
[5/24] Train loss=0.17608481645584106
[10/24] Train loss=0.2035168558359146
[15/24] Train loss=0.21596674621105194
[20/24] Train loss=0.20680688321590424
Test set avg_accuracy=80.31% avg_sensitivity=78.77%, avg_specificity=80.86% avg_auc=87.34%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.203152 Test loss=0.441643 Current lr=[0.000224838296036774]

[0/24] Train loss=0.17772939801216125
[5/24] Train loss=0.18879160284996033
[10/24] Train loss=0.22664985060691833
[15/24] Train loss=0.2130988985300064
[20/24] Train loss=0.19702793657779694
Test set avg_accuracy=83.28% avg_sensitivity=61.16%, avg_specificity=91.18% avg_auc=86.63%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.201035 Test loss=0.394104 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.17804279923439026
[5/24] Train loss=0.17313668131828308
[10/24] Train loss=0.22878624498844147
[15/24] Train loss=0.21920135617256165
[20/24] Train loss=0.2041168361902237
Test set avg_accuracy=82.54% avg_sensitivity=75.80%, avg_specificity=84.94% avg_auc=88.80%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.204764 Test loss=0.388075 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.18994219601154327
[5/24] Train loss=0.18138638138771057
[10/24] Train loss=0.20046097040176392
[15/24] Train loss=0.22117023169994354
[20/24] Train loss=0.19869236648082733
Test set avg_accuracy=83.92% avg_sensitivity=60.02%, avg_specificity=92.45% avg_auc=86.45%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.201080 Test loss=0.386873 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.18382000923156738
[5/24] Train loss=0.17868821322917938
[10/24] Train loss=0.2024882286787033
[15/24] Train loss=0.2070876806974411
[20/24] Train loss=0.2097112387418747
Test set avg_accuracy=80.01% avg_sensitivity=80.06%, avg_specificity=80.00% avg_auc=88.04%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.199114 Test loss=0.436087 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.18671825528144836
[5/24] Train loss=0.167476624250412
[10/24] Train loss=0.20835337042808533
[15/24] Train loss=0.21175958216190338
[20/24] Train loss=0.20051100850105286
Test set avg_accuracy=81.74% avg_sensitivity=77.09%, avg_specificity=83.41% avg_auc=88.31%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.198616 Test loss=0.408438 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.18380336463451385
[5/24] Train loss=0.17192164063453674
[10/24] Train loss=0.20486781001091003
[15/24] Train loss=0.20136910676956177
[20/24] Train loss=0.20634649693965912
Test set avg_accuracy=77.96% avg_sensitivity=77.44%, avg_specificity=78.14% avg_auc=86.08%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.197646 Test loss=0.490376 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1810576468706131
[5/24] Train loss=0.17334821820259094
[10/24] Train loss=0.1916690468788147
[15/24] Train loss=0.20002585649490356
[20/24] Train loss=0.1998158097267151
Test set avg_accuracy=84.70% avg_sensitivity=62.84%, avg_specificity=92.51% avg_auc=87.82%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.197012 Test loss=0.376605 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.17996849119663239
[5/24] Train loss=0.1691272258758545
[10/24] Train loss=0.20577751100063324
[15/24] Train loss=0.2017638385295868
[20/24] Train loss=0.2097248136997223
Test set avg_accuracy=84.13% avg_sensitivity=59.97%, avg_specificity=92.75% avg_auc=86.19%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.194423 Test loss=0.397521 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.18408280611038208
[5/24] Train loss=0.16388995945453644
[10/24] Train loss=0.19374795258045197
[15/24] Train loss=0.20950016379356384
[20/24] Train loss=0.18206699192523956
Test set avg_accuracy=83.71% avg_sensitivity=53.88%, avg_specificity=94.36% avg_auc=85.97%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.193863 Test loss=0.400514 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.1807878315448761
[5/24] Train loss=0.16901274025440216
[10/24] Train loss=0.18871437013149261
[15/24] Train loss=0.19423994421958923
[20/24] Train loss=0.19267773628234863
Test set avg_accuracy=83.12% avg_sensitivity=49.08%, avg_specificity=95.28% avg_auc=84.90%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.188926 Test loss=0.420436 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.17315272986888885
[5/24] Train loss=0.1701086312532425
[10/24] Train loss=0.2051401138305664
[15/24] Train loss=0.2070758044719696
[20/24] Train loss=0.17848245799541473
Test set avg_accuracy=80.56% avg_sensitivity=47.25%, avg_specificity=92.45% avg_auc=77.89%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.188411 Test loss=0.498012 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.16860061883926392
[5/24] Train loss=0.1665271520614624
[10/24] Train loss=0.19692884385585785
[15/24] Train loss=0.19149421155452728
[20/24] Train loss=0.17947420477867126
Test set avg_accuracy=83.80% avg_sensitivity=54.53%, avg_specificity=94.26% avg_auc=85.90%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.183609 Test loss=0.409907 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.16151440143585205
[5/24] Train loss=0.15852810442447662
[10/24] Train loss=0.19292043149471283
[15/24] Train loss=0.187196746468544
[20/24] Train loss=0.18221335113048553
Test set avg_accuracy=82.76% avg_sensitivity=54.23%, avg_specificity=92.95% avg_auc=84.58%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.184407 Test loss=0.436925 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.16898387670516968
[5/24] Train loss=0.16096527874469757
[10/24] Train loss=0.18748068809509277
[15/24] Train loss=0.1815781146287918
[20/24] Train loss=0.1912696361541748
Test set avg_accuracy=83.65% avg_sensitivity=59.28%, avg_specificity=92.35% avg_auc=85.61%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.181569 Test loss=0.408235 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.16393563151359558
[5/24] Train loss=0.15920887887477875
[10/24] Train loss=0.17974142730236053
[15/24] Train loss=0.189545139670372
[20/24] Train loss=0.17768731713294983
Test set avg_accuracy=81.78% avg_sensitivity=74.37%, avg_specificity=84.43% avg_auc=88.00%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.181036 Test loss=0.403719 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.16822926700115204
[5/24] Train loss=0.15967166423797607
[10/24] Train loss=0.19080518186092377
[15/24] Train loss=0.19842921197414398
[20/24] Train loss=0.18092027306556702
Test set avg_accuracy=79.83% avg_sensitivity=34.98%, avg_specificity=95.85% avg_auc=78.58%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.181579 Test loss=0.520425 Current lr=[0.000156543481933168]

[0/24] Train loss=0.177653506398201
[5/24] Train loss=0.15960560739040375
[10/24] Train loss=0.18614795804023743
[15/24] Train loss=0.18353287875652313
[20/24] Train loss=0.1732940971851349
Test set avg_accuracy=83.41% avg_sensitivity=59.67%, avg_specificity=91.89% avg_auc=85.83%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.178913 Test loss=0.418794 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.15687072277069092
[5/24] Train loss=0.15170854330062866
[10/24] Train loss=0.17648513615131378
[15/24] Train loss=0.18255940079689026
[20/24] Train loss=0.18059417605400085
Test set avg_accuracy=84.82% avg_sensitivity=70.51%, avg_specificity=89.93% avg_auc=88.38%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.175144 Test loss=0.373282 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15497516095638275
[5/24] Train loss=0.15851959586143494
[10/24] Train loss=0.1730162799358368
[15/24] Train loss=0.18391680717468262
[20/24] Train loss=0.17091818153858185
Test set avg_accuracy=83.80% avg_sensitivity=55.32%, avg_specificity=93.97% avg_auc=85.31%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.174662 Test loss=0.422988 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.162143737077713
[5/24] Train loss=0.1651145964860916
[10/24] Train loss=0.17169751226902008
[15/24] Train loss=0.18170857429504395
[20/24] Train loss=0.17692480981349945
Test set avg_accuracy=84.78% avg_sensitivity=69.67%, avg_specificity=90.17% avg_auc=86.87%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.175133 Test loss=0.381804 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1594034731388092
[5/24] Train loss=0.14871810376644135
[10/24] Train loss=0.17343534529209137
[15/24] Train loss=0.17694029211997986
[20/24] Train loss=0.17138078808784485
Test set avg_accuracy=85.12% avg_sensitivity=62.15%, avg_specificity=93.32% avg_auc=87.02%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.170687 Test loss=0.378165 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15348772704601288
[5/24] Train loss=0.1541341245174408
[10/24] Train loss=0.18143944442272186
[15/24] Train loss=0.1744982898235321
[20/24] Train loss=0.17426517605781555
Test set avg_accuracy=84.78% avg_sensitivity=58.09%, avg_specificity=94.31% avg_auc=87.31%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.172391 Test loss=0.392583 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1525421440601349
[5/24] Train loss=0.1522074192762375
[10/24] Train loss=0.17935670912265778
[15/24] Train loss=0.1738482564687729
[20/24] Train loss=0.18224573135375977
Test set avg_accuracy=84.11% avg_sensitivity=60.02%, avg_specificity=92.72% avg_auc=86.94%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.171620 Test loss=0.396449 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.16027581691741943
[5/24] Train loss=0.14782223105430603
[10/24] Train loss=0.17197291553020477
[15/24] Train loss=0.17628532648086548
[20/24] Train loss=0.16724419593811035
Test set avg_accuracy=83.41% avg_sensitivity=69.47%, avg_specificity=88.39% avg_auc=87.18%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.168094 Test loss=0.406878 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15241894125938416
[5/24] Train loss=0.14865653216838837
[10/24] Train loss=0.17042718827724457
[15/24] Train loss=0.16901831328868866
[20/24] Train loss=0.17189376056194305
Test set avg_accuracy=83.59% avg_sensitivity=60.61%, avg_specificity=91.80% avg_auc=86.81%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.166584 Test loss=0.394801 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1471685916185379
[5/24] Train loss=0.15660983324050903
[10/24] Train loss=0.1675269901752472
[15/24] Train loss=0.18056552112102509
[20/24] Train loss=0.16274042427539825
Test set avg_accuracy=83.23% avg_sensitivity=47.15%, avg_specificity=96.11% avg_auc=83.12%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.164924 Test loss=0.450153 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14760152995586395
[5/24] Train loss=0.14540275931358337
[10/24] Train loss=0.1623549610376358
[15/24] Train loss=0.17394110560417175
[20/24] Train loss=0.16600532829761505
Test set avg_accuracy=84.32% avg_sensitivity=65.66%, avg_specificity=90.99% avg_auc=87.91%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.165492 Test loss=0.377507 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15197345614433289
[5/24] Train loss=0.15129239857196808
[10/24] Train loss=0.16379192471504211
[15/24] Train loss=0.166438028216362
[20/24] Train loss=0.16633673012256622
Test set avg_accuracy=83.01% avg_sensitivity=53.88%, avg_specificity=93.41% avg_auc=84.83%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.164579 Test loss=0.422092 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15200482308864594
[5/24] Train loss=0.14348946511745453
[10/24] Train loss=0.1587487906217575
[15/24] Train loss=0.16709719598293304
[20/24] Train loss=0.170303612947464
Test set avg_accuracy=84.13% avg_sensitivity=55.17%, avg_specificity=94.47% avg_auc=86.14%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.164487 Test loss=0.413699 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14715991914272308
[5/24] Train loss=0.14660553634166718
[10/24] Train loss=0.16769210994243622
[15/24] Train loss=0.16454602777957916
[20/24] Train loss=0.1674884855747223
Test set avg_accuracy=84.31% avg_sensitivity=71.90%, avg_specificity=88.74% avg_auc=88.63%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.162637 Test loss=0.381111 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15152627229690552
[5/24] Train loss=0.14418216049671173
[10/24] Train loss=0.16130052506923676
[15/24] Train loss=0.1641094833612442
[20/24] Train loss=0.1653893142938614
Test set avg_accuracy=83.57% avg_sensitivity=67.39%, avg_specificity=89.34% avg_auc=87.17%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.162028 Test loss=0.393781 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1486714482307434
[5/24] Train loss=0.1428525745868683
[10/24] Train loss=0.17334426939487457
[15/24] Train loss=0.16250556707382202
[20/24] Train loss=0.16665950417518616
Test set avg_accuracy=83.67% avg_sensitivity=60.12%, avg_specificity=92.08% avg_auc=87.51%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.162835 Test loss=0.394942 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1547735333442688
[5/24] Train loss=0.1438181847333908
[10/24] Train loss=0.15838246047496796
[15/24] Train loss=0.16765837371349335
[20/24] Train loss=0.164885014295578
Test set avg_accuracy=84.21% avg_sensitivity=71.75%, avg_specificity=88.66% avg_auc=89.27%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.159838 Test loss=0.374359 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14395400881767273
[5/24] Train loss=0.14145717024803162
[10/24] Train loss=0.15676727890968323
[15/24] Train loss=0.16370658576488495
[20/24] Train loss=0.16623681783676147
Test set avg_accuracy=85.03% avg_sensitivity=65.17%, avg_specificity=92.12% avg_auc=88.73%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.157737 Test loss=0.375386 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14481885731220245
[5/24] Train loss=0.14264708757400513
[10/24] Train loss=0.1542372852563858
[15/24] Train loss=0.1650717705488205
[20/24] Train loss=0.1593761146068573
Test set avg_accuracy=83.55% avg_sensitivity=68.68%, avg_specificity=88.87% avg_auc=87.21%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.157839 Test loss=0.402683 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14287276566028595
[5/24] Train loss=0.14574435353279114
[10/24] Train loss=0.15455514192581177
[15/24] Train loss=0.16270749270915985
[20/24] Train loss=0.16030126810073853
Test set avg_accuracy=84.44% avg_sensitivity=69.72%, avg_specificity=89.70% avg_auc=88.68%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.156004 Test loss=0.380080 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1353052854537964
[5/24] Train loss=0.14281359314918518
[10/24] Train loss=0.15491534769535065
[15/24] Train loss=0.16354931890964508
[20/24] Train loss=0.158162921667099
Test set avg_accuracy=85.08% avg_sensitivity=71.25%, avg_specificity=90.02% avg_auc=88.59%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.154157 Test loss=0.375638 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1367451548576355
[5/24] Train loss=0.14390382170677185
[10/24] Train loss=0.1468825489282608
[15/24] Train loss=0.15902179479599
[20/24] Train loss=0.15589024126529694
Test set avg_accuracy=82.96% avg_sensitivity=77.19%, avg_specificity=85.02% avg_auc=88.92%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.152628 Test loss=0.404193 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14239619672298431
[5/24] Train loss=0.13870303332805634
[10/24] Train loss=0.14881551265716553
[15/24] Train loss=0.15600255131721497
[20/24] Train loss=0.15796618163585663
Test set avg_accuracy=84.88% avg_sensitivity=66.90%, avg_specificity=91.31% avg_auc=87.95%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.153087 Test loss=0.384556 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14083485305309296
[5/24] Train loss=0.1416349858045578
[10/24] Train loss=0.1469399780035019
[15/24] Train loss=0.15510056912899017
[20/24] Train loss=0.15198981761932373
Test set avg_accuracy=84.00% avg_sensitivity=73.38%, avg_specificity=87.79% avg_auc=88.48%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.150721 Test loss=0.387366 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1358652114868164
[5/24] Train loss=0.14223945140838623
[10/24] Train loss=0.14614418148994446
[15/24] Train loss=0.15825212001800537
[20/24] Train loss=0.15567666292190552
Test set avg_accuracy=83.14% avg_sensitivity=74.27%, avg_specificity=86.31% avg_auc=88.67%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.151544 Test loss=0.398660 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.13438400626182556
[5/24] Train loss=0.13497856259346008
[10/24] Train loss=0.14363901317119598
[15/24] Train loss=0.15178853273391724
[20/24] Train loss=0.15271100401878357
Test set avg_accuracy=84.52% avg_sensitivity=73.23%, avg_specificity=88.55% avg_auc=88.80%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.148906 Test loss=0.382969 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1346053183078766
[5/24] Train loss=0.1379014402627945
[10/24] Train loss=0.14609919488430023
[15/24] Train loss=0.15746363997459412
[20/24] Train loss=0.15500129759311676
Test set avg_accuracy=84.84% avg_sensitivity=66.90%, avg_specificity=91.25% avg_auc=88.31%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.149290 Test loss=0.380112 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1390034258365631
[5/24] Train loss=0.13585376739501953
[10/24] Train loss=0.1398247927427292
[15/24] Train loss=0.15578319132328033
[20/24] Train loss=0.15287619829177856
Test set avg_accuracy=85.17% avg_sensitivity=67.84%, avg_specificity=91.36% avg_auc=88.69%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.147670 Test loss=0.369679 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13320592045783997
[5/24] Train loss=0.13274097442626953
[10/24] Train loss=0.1419845074415207
[15/24] Train loss=0.15635506808757782
[20/24] Train loss=0.1568121612071991
Test set avg_accuracy=84.60% avg_sensitivity=76.00%, avg_specificity=87.67% avg_auc=88.61%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.146824 Test loss=0.382776 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12968572974205017
[5/24] Train loss=0.13809755444526672
[10/24] Train loss=0.14403383433818817
[15/24] Train loss=0.14886897802352905
[20/24] Train loss=0.15079458057880402
Test set avg_accuracy=84.47% avg_sensitivity=70.16%, avg_specificity=89.57% avg_auc=88.12%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.146007 Test loss=0.387373 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13606902956962585
[5/24] Train loss=0.13556058704853058
[10/24] Train loss=0.1409389227628708
[15/24] Train loss=0.14990505576133728
[20/24] Train loss=0.14815333485603333
Test set avg_accuracy=83.71% avg_sensitivity=73.43%, avg_specificity=87.38% avg_auc=88.18%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.144900 Test loss=0.397500 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13501706719398499
[5/24] Train loss=0.13515982031822205
[10/24] Train loss=0.13842259347438812
[15/24] Train loss=0.14914685487747192
[20/24] Train loss=0.14741933345794678
Test set avg_accuracy=83.05% avg_sensitivity=74.32%, avg_specificity=86.16% avg_auc=88.43%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.144123 Test loss=0.404178 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13348501920700073
[5/24] Train loss=0.133969247341156
[10/24] Train loss=0.1410709172487259
[15/24] Train loss=0.15107207000255585
[20/24] Train loss=0.14796766638755798
Test set avg_accuracy=85.20% avg_sensitivity=69.57%, avg_specificity=90.78% avg_auc=87.99%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.144382 Test loss=0.383552 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13232295215129852
[5/24] Train loss=0.1320757120847702
[10/24] Train loss=0.13658425211906433
[15/24] Train loss=0.14841948449611664
[20/24] Train loss=0.1474096029996872
Test set avg_accuracy=84.26% avg_sensitivity=75.95%, avg_specificity=87.22% avg_auc=88.76%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.142669 Test loss=0.380855 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13413849472999573
[5/24] Train loss=0.13245420157909393
[10/24] Train loss=0.13488933444023132
[15/24] Train loss=0.1439724713563919
[20/24] Train loss=0.14150625467300415
Test set avg_accuracy=84.38% avg_sensitivity=72.04%, avg_specificity=88.78% avg_auc=88.29%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.141756 Test loss=0.391586 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1323283314704895
[5/24] Train loss=0.13186882436275482
[10/24] Train loss=0.13492801785469055
[15/24] Train loss=0.1456434577703476
[20/24] Train loss=0.1437259018421173
Test set avg_accuracy=84.80% avg_sensitivity=70.86%, avg_specificity=89.79% avg_auc=88.65%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.141255 Test loss=0.378837 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13260412216186523
[5/24] Train loss=0.13153205811977386
[10/24] Train loss=0.13553661108016968
[15/24] Train loss=0.15105395019054413
[20/24] Train loss=0.1417783796787262
Test set avg_accuracy=84.78% avg_sensitivity=72.24%, avg_specificity=89.26% avg_auc=88.74%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.140229 Test loss=0.380099 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13013947010040283
[5/24] Train loss=0.13023442029953003
[10/24] Train loss=0.1341364085674286
[15/24] Train loss=0.14462846517562866
[20/24] Train loss=0.14444215595722198
Test set avg_accuracy=84.79% avg_sensitivity=72.88%, avg_specificity=89.04% avg_auc=88.76%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.139114 Test loss=0.380331 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1282411366701126
[5/24] Train loss=0.12794692814350128
[10/24] Train loss=0.13501524925231934
[15/24] Train loss=0.14455947279930115
[20/24] Train loss=0.14708681404590607
Test set avg_accuracy=84.93% avg_sensitivity=71.00%, avg_specificity=89.91% avg_auc=88.41%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.138471 Test loss=0.384003 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12798838317394257
[5/24] Train loss=0.12816517055034637
[10/24] Train loss=0.13375255465507507
[15/24] Train loss=0.14539197087287903
[20/24] Train loss=0.1447167694568634
Test set avg_accuracy=84.73% avg_sensitivity=73.58%, avg_specificity=88.71% avg_auc=89.02%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.138321 Test loss=0.379526 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1272217482328415
[5/24] Train loss=0.1285502165555954
[10/24] Train loss=0.1349031627178192
[15/24] Train loss=0.14134716987609863
[20/24] Train loss=0.1406625509262085
Test set avg_accuracy=84.73% avg_sensitivity=72.44%, avg_specificity=89.11% avg_auc=88.52%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.137439 Test loss=0.383796 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12534740567207336
[5/24] Train loss=0.13023656606674194
[10/24] Train loss=0.13294826447963715
[15/24] Train loss=0.14529120922088623
[20/24] Train loss=0.14339175820350647
Test set avg_accuracy=84.90% avg_sensitivity=71.35%, avg_specificity=89.73% avg_auc=88.54%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.137323 Test loss=0.382610 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1271664798259735
[5/24] Train loss=0.12741254270076752
[10/24] Train loss=0.13261739909648895
[15/24] Train loss=0.14282885193824768
[20/24] Train loss=0.14324723184108734
Test set avg_accuracy=84.86% avg_sensitivity=71.80%, avg_specificity=89.52% avg_auc=88.76%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.136576 Test loss=0.381559 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12678208947181702
[5/24] Train loss=0.13077692687511444
[10/24] Train loss=0.13040226697921753
[15/24] Train loss=0.14324189722537994
[20/24] Train loss=0.14132271707057953
Test set avg_accuracy=85.04% avg_sensitivity=72.14%, avg_specificity=89.64% avg_auc=88.62%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.136428 Test loss=0.379506 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12685400247573853
[5/24] Train loss=0.1278698891401291
[10/24] Train loss=0.12769147753715515
[15/24] Train loss=0.14179933071136475
[20/24] Train loss=0.13930897414684296
Test set avg_accuracy=84.80% avg_sensitivity=72.19%, avg_specificity=89.31% avg_auc=88.77%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.135540 Test loss=0.379580 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1284017413854599
[5/24] Train loss=0.12587179243564606
[10/24] Train loss=0.13108792901039124
[15/24] Train loss=0.14117245376110077
[20/24] Train loss=0.13569000363349915
Test set avg_accuracy=84.83% avg_sensitivity=71.94%, avg_specificity=89.43% avg_auc=88.80%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.135145 Test loss=0.377710 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12356394529342651
[5/24] Train loss=0.12375569343566895
[10/24] Train loss=0.12826715409755707
[15/24] Train loss=0.14056642353534698
[20/24] Train loss=0.14119915664196014
Test set avg_accuracy=84.95% avg_sensitivity=71.65%, avg_specificity=89.70% avg_auc=88.76%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.135426 Test loss=0.378167 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1236351877450943
[5/24] Train loss=0.12624678015708923
[10/24] Train loss=0.13066735863685608
[15/24] Train loss=0.14310042560100555
[20/24] Train loss=0.13890095055103302
Test set avg_accuracy=84.97% avg_sensitivity=72.34%, avg_specificity=89.49% avg_auc=88.79%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.135122 Test loss=0.378263 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12595832347869873
[5/24] Train loss=0.12628252804279327
[10/24] Train loss=0.13161268830299377
[15/24] Train loss=0.14589883387088776
[20/24] Train loss=0.14059334993362427
Test set avg_accuracy=85.04% avg_sensitivity=72.14%, avg_specificity=89.64% avg_auc=88.81%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.135595 Test loss=0.377605 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12815463542938232
[5/24] Train loss=0.1264839917421341
[10/24] Train loss=0.1301719695329666
[15/24] Train loss=0.14285148680210114
[20/24] Train loss=0.1387767791748047
Test set avg_accuracy=84.91% avg_sensitivity=72.14%, avg_specificity=89.47% avg_auc=88.81%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.135413 Test loss=0.378032 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12420623004436493
[5/24] Train loss=0.12812615931034088
[10/24] Train loss=0.13121655583381653
[15/24] Train loss=0.14370006322860718
[20/24] Train loss=0.13645528256893158
Test set avg_accuracy=84.91% avg_sensitivity=71.99%, avg_specificity=89.52% avg_auc=88.83%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.134839 Test loss=0.377604 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12404971569776535
[5/24] Train loss=0.12737902998924255
[10/24] Train loss=0.12954989075660706
[15/24] Train loss=0.14178693294525146
[20/24] Train loss=0.1407395303249359
Test set avg_accuracy=84.93% avg_sensitivity=71.99%, avg_specificity=89.56% avg_auc=88.82%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.134809 Test loss=0.377440 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12396817654371262
[5/24] Train loss=0.12529802322387695
[10/24] Train loss=0.13083592057228088
[15/24] Train loss=0.14207763969898224
[20/24] Train loss=0.14067290723323822
Test set avg_accuracy=85.00% avg_sensitivity=72.04%, avg_specificity=89.63% avg_auc=88.83%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.135314 Test loss=0.376900 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12476036697626114
[5/24] Train loss=0.12312865257263184
[10/24] Train loss=0.13204732537269592
[15/24] Train loss=0.14352114498615265
[20/24] Train loss=0.14189569652080536
Test set avg_accuracy=84.99% avg_sensitivity=72.19%, avg_specificity=89.56% avg_auc=88.84%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.135105 Test loss=0.377275 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=84.32% sen=76.20%, spe=87.22%, auc=90.75%!
Fold[1] Avg_overlap=0.66%(±0.21641372907134274)
[0/24] Train loss=0.712380588054657
[5/24] Train loss=0.7131363749504089
[10/24] Train loss=0.709104597568512
[15/24] Train loss=0.6997926235198975
[20/24] Train loss=0.6875978112220764
Test set avg_accuracy=52.99% avg_sensitivity=57.07%, avg_specificity=51.64% avg_auc=58.31%
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.702373 Test loss=0.687942 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6848686337471008
[5/24] Train loss=0.6752801537513733
[10/24] Train loss=0.669953465461731
[15/24] Train loss=0.6600269079208374
[20/24] Train loss=0.667817234992981
Test set avg_accuracy=63.37% avg_sensitivity=69.64%, avg_specificity=61.29% avg_auc=71.64%
Best model saved!! Metric=-60.05794038866313!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.670622 Test loss=0.631179 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6512899994850159
[5/24] Train loss=0.6449304223060608
[10/24] Train loss=0.6411667466163635
[15/24] Train loss=0.6346129179000854
[20/24] Train loss=0.6354506611824036
Test set avg_accuracy=66.99% avg_sensitivity=75.43%, avg_specificity=64.19% avg_auc=76.56%
Best model saved!! Metric=-42.83582023122227!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.645498 Test loss=0.606406 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6314261555671692
[5/24] Train loss=0.615770697593689
[10/24] Train loss=0.6130815744400024
[15/24] Train loss=0.609474241733551
[20/24] Train loss=0.6059841513633728
Test set avg_accuracy=70.03% avg_sensitivity=77.73%, avg_specificity=67.46% avg_auc=79.35%
Best model saved!! Metric=-31.432523310512693!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.619603 Test loss=0.580055 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6010470390319824
[5/24] Train loss=0.5809075236320496
[10/24] Train loss=0.5869329571723938
[15/24] Train loss=0.583121120929718
[20/24] Train loss=0.5862494111061096
Test set avg_accuracy=71.93% avg_sensitivity=77.57%, avg_specificity=70.05% avg_auc=81.01%
Best model saved!! Metric=-25.44197264235602!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.593682 Test loss=0.557028 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5739230513572693
[5/24] Train loss=0.5616535544395447
[10/24] Train loss=0.5583150386810303
[15/24] Train loss=0.5597047209739685
[20/24] Train loss=0.5553680062294006
Test set avg_accuracy=73.61% avg_sensitivity=77.00%, avg_specificity=72.48% avg_auc=82.12%
Best model saved!! Metric=-20.79724391330423!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.567449 Test loss=0.536879 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5462478995323181
[5/24] Train loss=0.5274239182472229
[10/24] Train loss=0.5321902632713318
[15/24] Train loss=0.5261296629905701
[20/24] Train loss=0.5306270122528076
Test set avg_accuracy=76.41% avg_sensitivity=75.59%, avg_specificity=76.68% avg_auc=83.55%
Best model saved!! Metric=-13.779092774961342!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.541514 Test loss=0.506480 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5221885442733765
[5/24] Train loss=0.5029961466789246
[10/24] Train loss=0.5028971433639526
[15/24] Train loss=0.5018430948257446
[20/24] Train loss=0.4988729655742645
Test set avg_accuracy=77.98% avg_sensitivity=75.38%, avg_specificity=78.85% avg_auc=84.66%
Best model saved!! Metric=-9.12921808007657!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.515572 Test loss=0.486937 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.49660059809684753
[5/24] Train loss=0.47714465856552124
[10/24] Train loss=0.48307305574417114
[15/24] Train loss=0.47701922059059143
[20/24] Train loss=0.4679916203022003
Test set avg_accuracy=79.71% avg_sensitivity=73.03%, avg_specificity=81.94% avg_auc=85.33%
Best model saved!! Metric=-5.993640055164107!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.490156 Test loss=0.462059 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.47017166018486023
[5/24] Train loss=0.44808992743492126
[10/24] Train loss=0.4638541340827942
[15/24] Train loss=0.45152848958969116
[20/24] Train loss=0.443096399307251
Test set avg_accuracy=80.43% avg_sensitivity=72.87%, avg_specificity=82.94% avg_auc=86.11%
Best model saved!! Metric=-3.640357308539265!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.467530 Test loss=0.446557 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.45103150606155396
[5/24] Train loss=0.4323170483112335
[10/24] Train loss=0.4398292005062103
[15/24] Train loss=0.4282233715057373
[20/24] Train loss=0.4262235164642334
Test set avg_accuracy=81.81% avg_sensitivity=69.69%, avg_specificity=85.84% avg_auc=86.65%
Best model saved!! Metric=-2.007502965019725!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.446609 Test loss=0.422213 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.42344146966934204
[5/24] Train loss=0.41196587681770325
[10/24] Train loss=0.42456793785095215
[15/24] Train loss=0.40565988421440125
[20/24] Train loss=0.39770469069480896
Test set avg_accuracy=82.93% avg_sensitivity=67.61%, avg_specificity=88.03% avg_auc=87.14%
Best model saved!! Metric=-0.2952515844459356!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.427261 Test loss=0.405760 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4087905287742615
[5/24] Train loss=0.3962192237377167
[10/24] Train loss=0.4087873101234436
[15/24] Train loss=0.3916766941547394
[20/24] Train loss=0.38251709938049316
Test set avg_accuracy=83.27% avg_sensitivity=64.63%, avg_specificity=89.47% avg_auc=87.52%
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.410541 Test loss=0.390946 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3866870403289795
[5/24] Train loss=0.3834402561187744
[10/24] Train loss=0.38948169350624084
[15/24] Train loss=0.3732026517391205
[20/24] Train loss=0.3630165159702301
Test set avg_accuracy=83.52% avg_sensitivity=67.08%, avg_specificity=88.98% avg_auc=87.97%
Best model saved!! Metric=1.5475164276139992!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.394067 Test loss=0.386289 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.37915995717048645
[5/24] Train loss=0.3697763979434967
[10/24] Train loss=0.37977924942970276
[15/24] Train loss=0.3603559136390686
[20/24] Train loss=0.35302212834358215
Test set avg_accuracy=83.11% avg_sensitivity=71.78%, avg_specificity=86.88% avg_auc=88.33%
Best model saved!! Metric=4.105286624863055!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.382941 Test loss=0.388317 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3599000573158264
[5/24] Train loss=0.36164578795433044
[10/24] Train loss=0.36146706342697144
[15/24] Train loss=0.34444665908813477
[20/24] Train loss=0.3399643301963806
Test set avg_accuracy=83.85% avg_sensitivity=69.54%, avg_specificity=88.62% avg_auc=88.72%
Best model saved!! Metric=4.728901622115643!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.370507 Test loss=0.374504 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3509488105773926
[5/24] Train loss=0.3564755320549011
[10/24] Train loss=0.35943928360939026
[15/24] Train loss=0.33391132950782776
[20/24] Train loss=0.32972246408462524
Test set avg_accuracy=83.45% avg_sensitivity=72.04%, avg_specificity=87.25% avg_auc=88.91%
Best model saved!! Metric=5.642103475502893!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.362005 Test loss=0.377718 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.338232159614563
[5/24] Train loss=0.34165334701538086
[10/24] Train loss=0.34573087096214294
[15/24] Train loss=0.3265326917171478
[20/24] Train loss=0.32195401191711426
Test set avg_accuracy=83.46% avg_sensitivity=72.30%, avg_specificity=87.18% avg_auc=88.98%
Best model saved!! Metric=5.920949567390707!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.351691 Test loss=0.375147 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3308744728565216
[5/24] Train loss=0.3514432907104492
[10/24] Train loss=0.3441755473613739
[15/24] Train loss=0.31548428535461426
[20/24] Train loss=0.3094783127307892
Test set avg_accuracy=82.40% avg_sensitivity=74.91%, avg_specificity=84.89% avg_auc=88.57%
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.344757 Test loss=0.390316 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.32621777057647705
[5/24] Train loss=0.3340465724468231
[10/24] Train loss=0.3314911127090454
[15/24] Train loss=0.31033846735954285
[20/24] Train loss=0.3001432716846466
Test set avg_accuracy=83.36% avg_sensitivity=71.00%, avg_specificity=87.47% avg_auc=89.19%
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.337947 Test loss=0.367154 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3148038983345032
[5/24] Train loss=0.33087801933288574
[10/24] Train loss=0.3308303654193878
[15/24] Train loss=0.3043442666530609
[20/24] Train loss=0.2906324565410614
Test set avg_accuracy=83.62% avg_sensitivity=68.54%, avg_specificity=88.63% avg_auc=89.34%
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.330713 Test loss=0.358220 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3098509609699249
[5/24] Train loss=0.33060628175735474
[10/24] Train loss=0.31869572401046753
[15/24] Train loss=0.29602912068367004
[20/24] Train loss=0.28790754079818726
Test set avg_accuracy=83.28% avg_sensitivity=71.73%, avg_specificity=87.12% avg_auc=89.37%
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.323932 Test loss=0.366303 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3069087266921997
[5/24] Train loss=0.3322153389453888
[10/24] Train loss=0.3252779245376587
[15/24] Train loss=0.29284948110580444
[20/24] Train loss=0.27892836928367615
Test set avg_accuracy=83.65% avg_sensitivity=69.90%, avg_specificity=88.22% avg_auc=89.28%
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.320185 Test loss=0.360082 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.29758456349372864
[5/24] Train loss=0.3314744532108307
[10/24] Train loss=0.31566840410232544
[15/24] Train loss=0.2797602415084839
[20/24] Train loss=0.2822333574295044
Test set avg_accuracy=83.67% avg_sensitivity=67.55%, avg_specificity=89.03% avg_auc=89.08%
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.314296 Test loss=0.359108 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2935484051704407
[5/24] Train loss=0.32521796226501465
[10/24] Train loss=0.30372029542922974
[15/24] Train loss=0.2846151292324066
[20/24] Train loss=0.2647940218448639
Test set avg_accuracy=82.75% avg_sensitivity=67.66%, avg_specificity=87.77% avg_auc=87.45%
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.309435 Test loss=0.388389 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2895160913467407
[5/24] Train loss=0.3195726275444031
[10/24] Train loss=0.30356287956237793
[15/24] Train loss=0.2792726159095764
[20/24] Train loss=0.2693166136741638
Test set avg_accuracy=82.58% avg_sensitivity=63.28%, avg_specificity=89.00% avg_auc=86.76%
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.305298 Test loss=0.386739 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.27831926941871643
[5/24] Train loss=0.3128910958766937
[10/24] Train loss=0.2848775386810303
[15/24] Train loss=0.2712108790874481
[20/24] Train loss=0.26866716146469116
Test set avg_accuracy=80.64% avg_sensitivity=28.95%, avg_specificity=97.83% avg_auc=86.99%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.298811 Test loss=0.438063 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2798948287963867
[5/24] Train loss=0.2872733473777771
[10/24] Train loss=0.28535494208335876
[15/24] Train loss=0.2585684359073639
[20/24] Train loss=0.2588365077972412
Test set avg_accuracy=80.44% avg_sensitivity=28.22%, avg_specificity=97.81% avg_auc=87.21%
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.291673 Test loss=0.442860 Current lr=[0.000210185142098938]

[0/24] Train loss=0.26642733812332153
[5/24] Train loss=0.2802054286003113
[10/24] Train loss=0.27982163429260254
[15/24] Train loss=0.2653035819530487
[20/24] Train loss=0.26630085706710815
Test set avg_accuracy=83.53% avg_sensitivity=66.25%, avg_specificity=89.28% avg_auc=89.16%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.290123 Test loss=0.354864 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.26883596181869507
[5/24] Train loss=0.284149706363678
[10/24] Train loss=0.27572643756866455
[15/24] Train loss=0.2533286511898041
[20/24] Train loss=0.2662819027900696
Test set avg_accuracy=80.65% avg_sensitivity=26.97%, avg_specificity=98.51% avg_auc=86.29%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.285917 Test loss=0.470306 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2609928846359253
[5/24] Train loss=0.27434927225112915
[10/24] Train loss=0.27115219831466675
[15/24] Train loss=0.2528664469718933
[20/24] Train loss=0.2529072165489197
Test set avg_accuracy=83.82% avg_sensitivity=63.48%, avg_specificity=90.58% avg_auc=88.61%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.282880 Test loss=0.360517 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.26502344012260437
[5/24] Train loss=0.26866599917411804
[10/24] Train loss=0.27533069252967834
[15/24] Train loss=0.25088468194007874
[20/24] Train loss=0.25297456979751587
Test set avg_accuracy=82.54% avg_sensitivity=41.11%, avg_specificity=96.32% avg_auc=87.72%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.278346 Test loss=0.401891 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2404598891735077
[5/24] Train loss=0.2738994061946869
[10/24] Train loss=0.2676237225532532
[15/24] Train loss=0.25385528802871704
[20/24] Train loss=0.24225492775440216
Test set avg_accuracy=83.20% avg_sensitivity=55.24%, avg_specificity=92.50% avg_auc=88.22%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.274648 Test loss=0.366507 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.24752074480056763
[5/24] Train loss=0.26963990926742554
[10/24] Train loss=0.261855810880661
[15/24] Train loss=0.24008996784687042
[20/24] Train loss=0.24162429571151733
Test set avg_accuracy=82.21% avg_sensitivity=66.61%, avg_specificity=87.40% avg_auc=87.40%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.270074 Test loss=0.393281 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2543558180332184
[5/24] Train loss=0.2882518172264099
[10/24] Train loss=0.2803194224834442
[15/24] Train loss=0.24077092111110687
[20/24] Train loss=0.2497226893901825
Test set avg_accuracy=81.67% avg_sensitivity=35.63%, avg_specificity=96.98% avg_auc=87.26%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.272842 Test loss=0.409612 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.23607487976551056
[5/24] Train loss=0.2890055179595947
[10/24] Train loss=0.2693421244621277
[15/24] Train loss=0.24493969976902008
[20/24] Train loss=0.24025677144527435
Test set avg_accuracy=82.33% avg_sensitivity=40.38%, avg_specificity=96.29% avg_auc=86.26%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.265793 Test loss=0.433713 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.23254135251045227
[5/24] Train loss=0.2643374502658844
[10/24] Train loss=0.2625029385089874
[15/24] Train loss=0.24275654554367065
[20/24] Train loss=0.24919991195201874
Test set avg_accuracy=80.21% avg_sensitivity=27.60%, avg_specificity=97.71% avg_auc=83.75%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.263573 Test loss=0.507018 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2515513002872467
[5/24] Train loss=0.27645769715309143
[10/24] Train loss=0.28634196519851685
[15/24] Train loss=0.237754225730896
[20/24] Train loss=0.23877355456352234
Test set avg_accuracy=82.37% avg_sensitivity=39.38%, avg_specificity=96.67% avg_auc=85.74%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.265951 Test loss=0.454286 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.22509777545928955
[5/24] Train loss=0.2573196291923523
[10/24] Train loss=0.2492266297340393
[15/24] Train loss=0.22174453735351562
[20/24] Train loss=0.23782849311828613
Test set avg_accuracy=77.01% avg_sensitivity=9.96%, avg_specificity=99.31% avg_auc=78.49%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.253462 Test loss=0.704028 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.23107324540615082
[5/24] Train loss=0.2647114396095276
[10/24] Train loss=0.2441287487745285
[15/24] Train loss=0.23364712297916412
[20/24] Train loss=0.2320631444454193
Test set avg_accuracy=75.57% avg_sensitivity=3.39%, avg_specificity=99.58% avg_auc=73.38%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.251368 Test loss=0.741539 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.21269166469573975
[5/24] Train loss=0.25698572397232056
[10/24] Train loss=0.2469523847103119
[15/24] Train loss=0.22979283332824707
[20/24] Train loss=0.22701780498027802
Test set avg_accuracy=80.65% avg_sensitivity=31.72%, avg_specificity=96.93% avg_auc=83.51%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.247041 Test loss=0.482682 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.22510014474391937
[5/24] Train loss=0.25716182589530945
[10/24] Train loss=0.24394720792770386
[15/24] Train loss=0.2225145399570465
[20/24] Train loss=0.22268517315387726
Test set avg_accuracy=76.54% avg_sensitivity=7.67%, avg_specificity=99.44% avg_auc=73.48%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.246824 Test loss=0.769619 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.222886860370636
[5/24] Train loss=0.24343495070934296
[10/24] Train loss=0.23291274905204773
[15/24] Train loss=0.23194155097007751
[20/24] Train loss=0.2324913740158081
Test set avg_accuracy=78.61% avg_sensitivity=18.41%, avg_specificity=98.63% avg_auc=77.64%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.243094 Test loss=0.617760 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.21582669019699097
[5/24] Train loss=0.24081452190876007
[10/24] Train loss=0.23676654696464539
[15/24] Train loss=0.22994364798069
[20/24] Train loss=0.23767602443695068
Test set avg_accuracy=76.04% avg_sensitivity=4.49%, avg_specificity=99.84% avg_auc=72.08%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.245455 Test loss=0.803490 Current lr=[0.00029967723776099]

[0/24] Train loss=0.22730766236782074
[5/24] Train loss=0.24305042624473572
[10/24] Train loss=0.23119540512561798
[15/24] Train loss=0.2398388683795929
[20/24] Train loss=0.23348405957221985
Test set avg_accuracy=82.55% avg_sensitivity=42.15%, avg_specificity=95.99% avg_auc=86.01%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.241021 Test loss=0.429098 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2197485715150833
[5/24] Train loss=0.24005606770515442
[10/24] Train loss=0.23062124848365784
[15/24] Train loss=0.21636150777339935
[20/24] Train loss=0.22152268886566162
Test set avg_accuracy=80.61% avg_sensitivity=35.73%, avg_specificity=95.54% avg_auc=83.38%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.242990 Test loss=0.451601 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.21116897463798523
[5/24] Train loss=0.24409180879592896
[10/24] Train loss=0.2463427186012268
[15/24] Train loss=0.21534797549247742
[20/24] Train loss=0.22631153464317322
Test set avg_accuracy=83.27% avg_sensitivity=63.38%, avg_specificity=89.88% avg_auc=88.66%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.242490 Test loss=0.361689 Current lr=[0.000299720220882401]

[0/24] Train loss=0.20980118215084076
[5/24] Train loss=0.23023326694965363
[10/24] Train loss=0.22435249388217926
[15/24] Train loss=0.2196090966463089
[20/24] Train loss=0.21955110132694244
Test set avg_accuracy=78.22% avg_sensitivity=15.70%, avg_specificity=99.01% avg_auc=79.89%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.238114 Test loss=0.633362 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2048185169696808
[5/24] Train loss=0.23343950510025024
[10/24] Train loss=0.2278355360031128
[15/24] Train loss=0.2156113088130951
[20/24] Train loss=0.21640409529209137
Test set avg_accuracy=78.89% avg_sensitivity=21.49%, avg_specificity=97.99% avg_auc=78.06%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.233558 Test loss=0.575091 Current lr=[0.000298904600941902]

[0/24] Train loss=0.20348581671714783
[5/24] Train loss=0.22183147072792053
[10/24] Train loss=0.22585316002368927
[15/24] Train loss=0.21332868933677673
[20/24] Train loss=0.21486331522464752
Test set avg_accuracy=76.76% avg_sensitivity=7.82%, avg_specificity=99.69% avg_auc=68.68%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.230676 Test loss=0.811499 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.1989554762840271
[5/24] Train loss=0.23860538005828857
[10/24] Train loss=0.22576050460338593
[15/24] Train loss=0.2080504596233368
[20/24] Train loss=0.21536384522914886
Test set avg_accuracy=75.39% avg_sensitivity=1.46%, avg_specificity=99.98% avg_auc=65.98%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.229311 Test loss=0.849496 Current lr=[0.000297555943323901]

[0/24] Train loss=0.21804043650627136
[5/24] Train loss=0.24884743988513947
[10/24] Train loss=0.23024092614650726
[15/24] Train loss=0.21066035330295563
[20/24] Train loss=0.22165538370609283
Test set avg_accuracy=82.64% avg_sensitivity=62.96%, avg_specificity=89.19% avg_auc=87.76%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.233020 Test loss=0.375017 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.21118129789829254
[5/24] Train loss=0.23950761556625366
[10/24] Train loss=0.21557500958442688
[15/24] Train loss=0.2048766016960144
[20/24] Train loss=0.20906434953212738
Test set avg_accuracy=79.78% avg_sensitivity=24.67%, avg_specificity=98.11% avg_auc=76.66%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.232767 Test loss=0.571670 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2074458748102188
[5/24] Train loss=0.23690859973430634
[10/24] Train loss=0.2261999547481537
[15/24] Train loss=0.20817811787128448
[20/24] Train loss=0.20681525766849518
Test set avg_accuracy=76.38% avg_sensitivity=6.62%, avg_specificity=99.58% avg_auc=72.31%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.227964 Test loss=0.788503 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.19290202856063843
[5/24] Train loss=0.23078526556491852
[10/24] Train loss=0.22558297216892242
[15/24] Train loss=0.20121340453624725
[20/24] Train loss=0.21387986838817596
Test set avg_accuracy=79.99% avg_sensitivity=27.70%, avg_specificity=97.38% avg_auc=75.52%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.224083 Test loss=0.639789 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.20127105712890625
[5/24] Train loss=0.2415482997894287
[10/24] Train loss=0.22448833286762238
[15/24] Train loss=0.1989704668521881
[20/24] Train loss=0.20284724235534668
Test set avg_accuracy=83.01% avg_sensitivity=60.82%, avg_specificity=90.39% avg_auc=85.60%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.227494 Test loss=0.423987 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.19909857213497162
[5/24] Train loss=0.24055607616901398
[10/24] Train loss=0.2161249816417694
[15/24] Train loss=0.20431450009346008
[20/24] Train loss=0.20552031695842743
Test set avg_accuracy=82.01% avg_sensitivity=42.98%, avg_specificity=94.99% avg_auc=82.53%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.221800 Test loss=0.443184 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.19696983695030212
[5/24] Train loss=0.23784108459949493
[10/24] Train loss=0.21453572809696198
[15/24] Train loss=0.19545038044452667
[20/24] Train loss=0.21145424246788025
Test set avg_accuracy=80.17% avg_sensitivity=25.67%, avg_specificity=98.30% avg_auc=77.37%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.221251 Test loss=0.603878 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.21629101037979126
[5/24] Train loss=0.23081989586353302
[10/24] Train loss=0.23266546428203583
[15/24] Train loss=0.18998487293720245
[20/24] Train loss=0.20484115183353424
Test set avg_accuracy=82.04% avg_sensitivity=68.49%, avg_specificity=86.55% avg_auc=87.07%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.226462 Test loss=0.403909 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.19369135797023773
[5/24] Train loss=0.22762785851955414
[10/24] Train loss=0.22942166030406952
[15/24] Train loss=0.20967182517051697
[20/24] Train loss=0.21033987402915955
Test set avg_accuracy=80.73% avg_sensitivity=36.93%, avg_specificity=95.30% avg_auc=82.47%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.223578 Test loss=0.478666 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.20438969135284424
[5/24] Train loss=0.22559653222560883
[10/24] Train loss=0.21259461343288422
[15/24] Train loss=0.1953388750553131
[20/24] Train loss=0.21017253398895264
Test set avg_accuracy=82.71% avg_sensitivity=50.08%, avg_specificity=93.56% avg_auc=85.57%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.217717 Test loss=0.440952 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.19413450360298157
[5/24] Train loss=0.22672441601753235
[10/24] Train loss=0.20875991880893707
[15/24] Train loss=0.19448605179786682
[20/24] Train loss=0.19639773666858673
Test set avg_accuracy=79.41% avg_sensitivity=22.12%, avg_specificity=98.47% avg_auc=74.49%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.220392 Test loss=0.621878 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2142910361289978
[5/24] Train loss=0.22091981768608093
[10/24] Train loss=0.2118745893239975
[15/24] Train loss=0.19117730855941772
[20/24] Train loss=0.20317095518112183
Test set avg_accuracy=82.88% avg_sensitivity=70.21%, avg_specificity=87.09% avg_auc=88.53%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.217513 Test loss=0.395592 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.19434574246406555
[5/24] Train loss=0.22410206496715546
[10/24] Train loss=0.20513086020946503
[15/24] Train loss=0.19301849603652954
[20/24] Train loss=0.20769241452217102
Test set avg_accuracy=81.72% avg_sensitivity=41.47%, avg_specificity=95.11% avg_auc=85.21%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.218317 Test loss=0.441272 Current lr=[0.000276307469034998]

[0/24] Train loss=0.20535412430763245
[5/24] Train loss=0.22994261980056763
[10/24] Train loss=0.21295300126075745
[15/24] Train loss=0.20085233449935913
[20/24] Train loss=0.1944878250360489
Test set avg_accuracy=81.63% avg_sensitivity=45.12%, avg_specificity=93.77% avg_auc=83.66%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.215412 Test loss=0.445027 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.1851060390472412
[5/24] Train loss=0.2288818061351776
[10/24] Train loss=0.21484112739562988
[15/24] Train loss=0.20643259584903717
[20/24] Train loss=0.21203744411468506
Test set avg_accuracy=78.28% avg_sensitivity=82.11%, avg_specificity=77.01% avg_auc=87.12%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.212692 Test loss=0.476168 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.19419614970684052
[5/24] Train loss=0.20732878148555756
[10/24] Train loss=0.2141457498073578
[15/24] Train loss=0.19640040397644043
[20/24] Train loss=0.2017320692539215
Test set avg_accuracy=79.04% avg_sensitivity=70.84%, avg_specificity=81.76% avg_auc=85.12%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.210604 Test loss=0.477467 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.18463332951068878
[5/24] Train loss=0.22383545339107513
[10/24] Train loss=0.20620928704738617
[15/24] Train loss=0.186201810836792
[20/24] Train loss=0.20984482765197754
Test set avg_accuracy=80.23% avg_sensitivity=59.00%, avg_specificity=87.30% avg_auc=83.76%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.212137 Test loss=0.457922 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.19908742606639862
[5/24] Train loss=0.2143176645040512
[10/24] Train loss=0.20527157187461853
[15/24] Train loss=0.18320238590240479
[20/24] Train loss=0.19410458207130432
Test set avg_accuracy=83.09% avg_sensitivity=63.48%, avg_specificity=89.61% avg_auc=86.98%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.211743 Test loss=0.391860 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.17942918837070465
[5/24] Train loss=0.21146546304225922
[10/24] Train loss=0.21447037160396576
[15/24] Train loss=0.18625962734222412
[20/24] Train loss=0.20187172293663025
Test set avg_accuracy=79.41% avg_sensitivity=72.98%, avg_specificity=81.55% avg_auc=85.86%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.208791 Test loss=0.454350 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.189461350440979
[5/24] Train loss=0.20706675946712494
[10/24] Train loss=0.201722651720047
[15/24] Train loss=0.18798218667507172
[20/24] Train loss=0.19156530499458313
Test set avg_accuracy=77.76% avg_sensitivity=79.34%, avg_specificity=77.23% avg_auc=85.99%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.207459 Test loss=0.510020 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.1899481564760208
[5/24] Train loss=0.21372751891613007
[10/24] Train loss=0.2103065699338913
[15/24] Train loss=0.1851741373538971
[20/24] Train loss=0.19811156392097473
Test set avg_accuracy=76.05% avg_sensitivity=81.64%, avg_specificity=74.20% avg_auc=86.21%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.208160 Test loss=0.525308 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.18349866569042206
[5/24] Train loss=0.20986320078372955
[10/24] Train loss=0.20726396143436432
[15/24] Train loss=0.18242257833480835
[20/24] Train loss=0.19308209419250488
Test set avg_accuracy=80.26% avg_sensitivity=75.07%, avg_specificity=81.99% avg_auc=86.45%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.206176 Test loss=0.445781 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.18351434171199799
[5/24] Train loss=0.20390714704990387
[10/24] Train loss=0.20979784429073334
[15/24] Train loss=0.1899779587984085
[20/24] Train loss=0.19329094886779785
Test set avg_accuracy=82.25% avg_sensitivity=46.58%, avg_specificity=94.12% avg_auc=83.85%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.210688 Test loss=0.448759 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.1996167004108429
[5/24] Train loss=0.20126935839653015
[10/24] Train loss=0.20422135293483734
[15/24] Train loss=0.18681098520755768
[20/24] Train loss=0.1930181235074997
Test set avg_accuracy=80.60% avg_sensitivity=70.89%, avg_specificity=83.83% avg_auc=85.98%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.204403 Test loss=0.442330 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.18859834969043732
[5/24] Train loss=0.19641533493995667
[10/24] Train loss=0.2024535983800888
[15/24] Train loss=0.17688590288162231
[20/24] Train loss=0.18182936310768127
Test set avg_accuracy=82.30% avg_sensitivity=45.85%, avg_specificity=94.43% avg_auc=83.24%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.200629 Test loss=0.451234 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.18224142491817474
[5/24] Train loss=0.2078561931848526
[10/24] Train loss=0.19421632587909698
[15/24] Train loss=0.17875656485557556
[20/24] Train loss=0.18509942293167114
Test set avg_accuracy=82.43% avg_sensitivity=57.12%, avg_specificity=90.86% avg_auc=84.89%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.195728 Test loss=0.437771 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.1781533658504486
[5/24] Train loss=0.19551657140254974
[10/24] Train loss=0.19539837539196014
[15/24] Train loss=0.18464337289333344
[20/24] Train loss=0.18008996546268463
Test set avg_accuracy=83.37% avg_sensitivity=58.11%, avg_specificity=91.78% avg_auc=85.63%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.198790 Test loss=0.414059 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.17293795943260193
[5/24] Train loss=0.21046331524848938
[10/24] Train loss=0.19128167629241943
[15/24] Train loss=0.18127387762069702
[20/24] Train loss=0.189086452126503
Test set avg_accuracy=82.75% avg_sensitivity=62.28%, avg_specificity=89.55% avg_auc=86.32%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.193838 Test loss=0.398480 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17776401340961456
[5/24] Train loss=0.20107200741767883
[10/24] Train loss=0.18845035135746002
[15/24] Train loss=0.177029550075531
[20/24] Train loss=0.17092524468898773
Test set avg_accuracy=70.18% avg_sensitivity=69.80%, avg_specificity=70.31% avg_auc=77.64%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.194567 Test loss=0.622778 Current lr=[0.000224838296036774]

[0/24] Train loss=0.18223774433135986
[5/24] Train loss=0.19555991888046265
[10/24] Train loss=0.2063763439655304
[15/24] Train loss=0.18877436220645905
[20/24] Train loss=0.18120306730270386
Test set avg_accuracy=82.32% avg_sensitivity=46.22%, avg_specificity=94.33% avg_auc=84.03%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.195816 Test loss=0.458415 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.17759579420089722
[5/24] Train loss=0.187527596950531
[10/24] Train loss=0.1941036432981491
[15/24] Train loss=0.17691217362880707
[20/24] Train loss=0.17765958607196808
Test set avg_accuracy=80.91% avg_sensitivity=69.43%, avg_specificity=84.73% avg_auc=85.60%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.191711 Test loss=0.447393 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.1790037900209427
[5/24] Train loss=0.18998423218727112
[10/24] Train loss=0.18353772163391113
[15/24] Train loss=0.17217382788658142
[20/24] Train loss=0.1732652634382248
Test set avg_accuracy=81.18% avg_sensitivity=68.39%, avg_specificity=85.44% avg_auc=86.13%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.193069 Test loss=0.424229 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.17471866309642792
[5/24] Train loss=0.19426919519901276
[10/24] Train loss=0.18175141513347626
[15/24] Train loss=0.1659865826368332
[20/24] Train loss=0.1742960661649704
Test set avg_accuracy=81.18% avg_sensitivity=47.16%, avg_specificity=92.50% avg_auc=80.31%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.188212 Test loss=0.468324 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.18001870810985565
[5/24] Train loss=0.19444386661052704
[10/24] Train loss=0.19330734014511108
[15/24] Train loss=0.17187631130218506
[20/24] Train loss=0.1795284003019333
Test set avg_accuracy=82.14% avg_sensitivity=61.40%, avg_specificity=89.03% avg_auc=84.73%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.190551 Test loss=0.426749 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.18122854828834534
[5/24] Train loss=0.18592076003551483
[10/24] Train loss=0.19141028821468353
[15/24] Train loss=0.17308937013149261
[20/24] Train loss=0.18050052225589752
Test set avg_accuracy=77.90% avg_sensitivity=68.60%, avg_specificity=81.00% avg_auc=83.68%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.190436 Test loss=0.474356 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.16902849078178406
[5/24] Train loss=0.19109700620174408
[10/24] Train loss=0.18813948333263397
[15/24] Train loss=0.176117941737175
[20/24] Train loss=0.1723601222038269
Test set avg_accuracy=82.32% avg_sensitivity=44.39%, avg_specificity=94.93% avg_auc=80.92%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.188086 Test loss=0.469369 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1738457828760147
[5/24] Train loss=0.19140009582042694
[10/24] Train loss=0.17961184680461884
[15/24] Train loss=0.16423112154006958
[20/24] Train loss=0.17919084429740906
Test set avg_accuracy=80.13% avg_sensitivity=73.03%, avg_specificity=82.49% avg_auc=86.53%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.187948 Test loss=0.440634 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.16825580596923828
[5/24] Train loss=0.18690085411071777
[10/24] Train loss=0.17749956250190735
[15/24] Train loss=0.16492022573947906
[20/24] Train loss=0.1759856641292572
Test set avg_accuracy=78.58% avg_sensitivity=17.58%, avg_specificity=98.87% avg_auc=68.24%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.183533 Test loss=0.659406 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.18140769004821777
[5/24] Train loss=0.18529152870178223
[10/24] Train loss=0.18661880493164062
[15/24] Train loss=0.169178768992424
[20/24] Train loss=0.17078864574432373
Test set avg_accuracy=82.55% avg_sensitivity=54.67%, avg_specificity=91.83% avg_auc=83.73%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.186248 Test loss=0.428569 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.17287535965442657
[5/24] Train loss=0.19994452595710754
[10/24] Train loss=0.17441494762897491
[15/24] Train loss=0.16746969521045685
[20/24] Train loss=0.18214640021324158
Test set avg_accuracy=82.02% avg_sensitivity=55.14%, avg_specificity=90.96% avg_auc=84.10%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.185216 Test loss=0.437221 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.169091135263443
[5/24] Train loss=0.19411633908748627
[10/24] Train loss=0.1828274130821228
[15/24] Train loss=0.17222599685192108
[20/24] Train loss=0.17166975140571594
Test set avg_accuracy=81.94% avg_sensitivity=51.43%, avg_specificity=92.09% avg_auc=82.69%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.188428 Test loss=0.450403 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.17810648679733276
[5/24] Train loss=0.20195573568344116
[10/24] Train loss=0.1781911998987198
[15/24] Train loss=0.167482390999794
[20/24] Train loss=0.1890815943479538
Test set avg_accuracy=79.08% avg_sensitivity=33.91%, avg_specificity=94.10% avg_auc=73.81%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.194501 Test loss=0.546455 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.18880502879619598
[5/24] Train loss=0.18893061578273773
[10/24] Train loss=0.18324212729930878
[15/24] Train loss=0.17865212261676788
[20/24] Train loss=0.1797393262386322
Test set avg_accuracy=81.78% avg_sensitivity=66.15%, avg_specificity=86.99% avg_auc=85.38%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.191831 Test loss=0.434108 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1808905303478241
[5/24] Train loss=0.189788356423378
[10/24] Train loss=0.1900685429573059
[15/24] Train loss=0.18159174919128418
[20/24] Train loss=0.17833663523197174
Test set avg_accuracy=79.69% avg_sensitivity=39.49%, avg_specificity=93.06% avg_auc=73.71%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.189438 Test loss=0.518467 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.17415782809257507
[5/24] Train loss=0.18423421680927277
[10/24] Train loss=0.18397989869117737
[15/24] Train loss=0.18052689731121063
[20/24] Train loss=0.18535590171813965
Test set avg_accuracy=82.84% avg_sensitivity=45.70%, avg_specificity=95.19% avg_auc=82.34%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.189286 Test loss=0.448423 Current lr=[0.000156543481933168]

[0/24] Train loss=0.17053718864917755
[5/24] Train loss=0.19206809997558594
[10/24] Train loss=0.18556106090545654
[15/24] Train loss=0.1729593425989151
[20/24] Train loss=0.16710533201694489
Test set avg_accuracy=82.55% avg_sensitivity=56.44%, avg_specificity=91.24% avg_auc=84.09%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.187037 Test loss=0.424744 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.16063649952411652
[5/24] Train loss=0.19165991246700287
[10/24] Train loss=0.17139333486557007
[15/24] Train loss=0.16713954508304596
[20/24] Train loss=0.1679629534482956
Test set avg_accuracy=83.93% avg_sensitivity=56.70%, avg_specificity=92.99% avg_auc=83.95%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.182993 Test loss=0.424533 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.1585317999124527
[5/24] Train loss=0.1821424961090088
[10/24] Train loss=0.16756513714790344
[15/24] Train loss=0.16452988982200623
[20/24] Train loss=0.17006446421146393
Test set avg_accuracy=83.36% avg_sensitivity=52.48%, avg_specificity=93.63% avg_auc=84.38%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.178355 Test loss=0.421810 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.18083249032497406
[5/24] Train loss=0.18206262588500977
[10/24] Train loss=0.17407475411891937
[15/24] Train loss=0.16360053420066833
[20/24] Train loss=0.16247016191482544
Test set avg_accuracy=83.09% avg_sensitivity=54.09%, avg_specificity=92.73% avg_auc=83.32%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.177298 Test loss=0.429998 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15978702902793884
[5/24] Train loss=0.17654721438884735
[10/24] Train loss=0.17586328089237213
[15/24] Train loss=0.16713638603687286
[20/24] Train loss=0.1603253185749054
Test set avg_accuracy=81.35% avg_sensitivity=53.89%, avg_specificity=90.49% avg_auc=84.59%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.178489 Test loss=0.429257 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16638362407684326
[5/24] Train loss=0.17862170934677124
[10/24] Train loss=0.16272994875907898
[15/24] Train loss=0.16733083128929138
[20/24] Train loss=0.17001433670520782
Test set avg_accuracy=82.77% avg_sensitivity=51.33%, avg_specificity=93.23% avg_auc=83.65%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.176507 Test loss=0.435503 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1510104238986969
[5/24] Train loss=0.1833360195159912
[10/24] Train loss=0.1665489226579666
[15/24] Train loss=0.1613047868013382
[20/24] Train loss=0.1639772206544876
Test set avg_accuracy=81.38% avg_sensitivity=32.55%, avg_specificity=97.62% avg_auc=78.31%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.172867 Test loss=0.519099 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1576131284236908
[5/24] Train loss=0.1835426390171051
[10/24] Train loss=0.16884641349315643
[15/24] Train loss=0.16676467657089233
[20/24] Train loss=0.1597147136926651
Test set avg_accuracy=80.65% avg_sensitivity=29.99%, avg_specificity=97.50% avg_auc=76.12%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.174091 Test loss=0.572685 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15009035170078278
[5/24] Train loss=0.1805243194103241
[10/24] Train loss=0.1629631668329239
[15/24] Train loss=0.15864251554012299
[20/24] Train loss=0.16347679495811462
Test set avg_accuracy=83.46% avg_sensitivity=63.64%, avg_specificity=90.06% avg_auc=87.31%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.173316 Test loss=0.394685 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1486387848854065
[5/24] Train loss=0.175265833735466
[10/24] Train loss=0.16175444424152374
[15/24] Train loss=0.15875163674354553
[20/24] Train loss=0.16074879467487335
Test set avg_accuracy=83.01% avg_sensitivity=66.30%, avg_specificity=88.56% avg_auc=86.64%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.170537 Test loss=0.414450 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15414339303970337
[5/24] Train loss=0.17932213842868805
[10/24] Train loss=0.1646411418914795
[15/24] Train loss=0.15712691843509674
[20/24] Train loss=0.15602977573871613
Test set avg_accuracy=83.16% avg_sensitivity=64.32%, avg_specificity=89.43% avg_auc=85.58%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.168082 Test loss=0.420216 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15463532507419586
[5/24] Train loss=0.1688251495361328
[10/24] Train loss=0.15972070395946503
[15/24] Train loss=0.15338259935379028
[20/24] Train loss=0.151658833026886
Test set avg_accuracy=83.88% avg_sensitivity=54.77%, avg_specificity=93.56% avg_auc=84.20%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.166954 Test loss=0.430343 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15084493160247803
[5/24] Train loss=0.1731305867433548
[10/24] Train loss=0.1588946431875229
[15/24] Train loss=0.15121369063854218
[20/24] Train loss=0.1621333211660385
Test set avg_accuracy=82.47% avg_sensitivity=69.33%, avg_specificity=86.85% avg_auc=86.14%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.165408 Test loss=0.427416 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.15917642414569855
[5/24] Train loss=0.17421355843544006
[10/24] Train loss=0.16508497297763824
[15/24] Train loss=0.15207470953464508
[20/24] Train loss=0.14997512102127075
Test set avg_accuracy=83.71% avg_sensitivity=60.41%, avg_specificity=91.46% avg_auc=85.79%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.165907 Test loss=0.419501 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.151186004281044
[5/24] Train loss=0.16417068243026733
[10/24] Train loss=0.16212217509746552
[15/24] Train loss=0.14877434074878693
[20/24] Train loss=0.14873574674129486
Test set avg_accuracy=83.32% avg_sensitivity=69.64%, avg_specificity=87.87% avg_auc=86.87%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.162415 Test loss=0.412860 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1506347358226776
[5/24] Train loss=0.1649838536977768
[10/24] Train loss=0.15206852555274963
[15/24] Train loss=0.15003664791584015
[20/24] Train loss=0.14989793300628662
Test set avg_accuracy=83.01% avg_sensitivity=54.30%, avg_specificity=92.56% avg_auc=84.31%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.159970 Test loss=0.433484 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1439993530511856
[5/24] Train loss=0.16456404328346252
[10/24] Train loss=0.15288497507572174
[15/24] Train loss=0.1482534110546112
[20/24] Train loss=0.14341796934604645
Test set avg_accuracy=83.53% avg_sensitivity=55.35%, avg_specificity=92.90% avg_auc=84.20%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.158307 Test loss=0.429994 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14384320378303528
[5/24] Train loss=0.1600099503993988
[10/24] Train loss=0.15083441138267517
[15/24] Train loss=0.1511109620332718
[20/24] Train loss=0.14432469010353088
Test set avg_accuracy=83.12% avg_sensitivity=66.09%, avg_specificity=88.79% avg_auc=86.60%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.157326 Test loss=0.417143 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14841553568840027
[5/24] Train loss=0.1676671802997589
[10/24] Train loss=0.1546367108821869
[15/24] Train loss=0.1510971188545227
[20/24] Train loss=0.1454395353794098
Test set avg_accuracy=83.49% avg_sensitivity=59.26%, avg_specificity=91.55% avg_auc=85.68%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.158923 Test loss=0.425154 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14746586978435516
[5/24] Train loss=0.16329701244831085
[10/24] Train loss=0.1518421322107315
[15/24] Train loss=0.1550813913345337
[20/24] Train loss=0.14080283045768738
Test set avg_accuracy=83.52% avg_sensitivity=69.07%, avg_specificity=88.32% avg_auc=86.83%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.156558 Test loss=0.415297 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13883385062217712
[5/24] Train loss=0.1623501181602478
[10/24] Train loss=0.14861281216144562
[15/24] Train loss=0.14840416610240936
[20/24] Train loss=0.14470688998699188
Test set avg_accuracy=83.14% avg_sensitivity=55.09%, avg_specificity=92.47% avg_auc=84.39%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.155417 Test loss=0.443610 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1416764259338379
[5/24] Train loss=0.16117049753665924
[10/24] Train loss=0.14756838977336884
[15/24] Train loss=0.14425508677959442
[20/24] Train loss=0.14473626017570496
Test set avg_accuracy=83.40% avg_sensitivity=64.21%, avg_specificity=89.78% avg_auc=86.35%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.154277 Test loss=0.406915 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13826468586921692
[5/24] Train loss=0.1603771597146988
[10/24] Train loss=0.142275869846344
[15/24] Train loss=0.13823094964027405
[20/24] Train loss=0.14257320761680603
Test set avg_accuracy=83.61% avg_sensitivity=63.69%, avg_specificity=90.23% avg_auc=86.10%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.151624 Test loss=0.415228 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13567817211151123
[5/24] Train loss=0.15707801282405853
[10/24] Train loss=0.14737571775913239
[15/24] Train loss=0.14623934030532837
[20/24] Train loss=0.13775750994682312
Test set avg_accuracy=82.12% avg_sensitivity=68.60%, avg_specificity=86.62% avg_auc=86.61%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.151509 Test loss=0.423353 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.143773153424263
[5/24] Train loss=0.15391671657562256
[10/24] Train loss=0.145131915807724
[15/24] Train loss=0.1436685174703598
[20/24] Train loss=0.1369323581457138
Test set avg_accuracy=81.59% avg_sensitivity=68.39%, avg_specificity=85.98% avg_auc=86.14%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.152196 Test loss=0.442524 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.13928592205047607
[5/24] Train loss=0.15533116459846497
[10/24] Train loss=0.14960667490959167
[15/24] Train loss=0.14708276093006134
[20/24] Train loss=0.13684587180614471
Test set avg_accuracy=82.84% avg_sensitivity=66.20%, avg_specificity=88.37% avg_auc=86.45%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.152509 Test loss=0.415735 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1358087807893753
[5/24] Train loss=0.15677106380462646
[10/24] Train loss=0.14324083924293518
[15/24] Train loss=0.14197973906993866
[20/24] Train loss=0.14077787101268768
Test set avg_accuracy=82.86% avg_sensitivity=60.56%, avg_specificity=90.28% avg_auc=85.07%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.149460 Test loss=0.432503 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1338144987821579
[5/24] Train loss=0.15356966853141785
[10/24] Train loss=0.1421283483505249
[15/24] Train loss=0.14367634057998657
[20/24] Train loss=0.13466809689998627
Test set avg_accuracy=82.62% avg_sensitivity=67.34%, avg_specificity=87.70% avg_auc=86.11%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.148481 Test loss=0.425100 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1344464123249054
[5/24] Train loss=0.15208487212657928
[10/24] Train loss=0.14190417528152466
[15/24] Train loss=0.1425621062517166
[20/24] Train loss=0.13558408617973328
Test set avg_accuracy=82.76% avg_sensitivity=66.30%, avg_specificity=88.24% avg_auc=85.37%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.147648 Test loss=0.430284 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1342100203037262
[5/24] Train loss=0.14776137471199036
[10/24] Train loss=0.14018790423870087
[15/24] Train loss=0.14135503768920898
[20/24] Train loss=0.13564297556877136
Test set avg_accuracy=82.64% avg_sensitivity=63.85%, avg_specificity=88.89% avg_auc=85.40%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.147017 Test loss=0.427108 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13234294950962067
[5/24] Train loss=0.1476074904203415
[10/24] Train loss=0.14198338985443115
[15/24] Train loss=0.14187288284301758
[20/24] Train loss=0.13823890686035156
Test set avg_accuracy=82.86% avg_sensitivity=59.26%, avg_specificity=90.72% avg_auc=85.12%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.146711 Test loss=0.427821 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13203120231628418
[5/24] Train loss=0.1510877013206482
[10/24] Train loss=0.14240039885044098
[15/24] Train loss=0.1390973925590515
[20/24] Train loss=0.13884122669696808
Test set avg_accuracy=83.35% avg_sensitivity=67.08%, avg_specificity=88.76% avg_auc=86.26%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.147204 Test loss=0.415974 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1296602189540863
[5/24] Train loss=0.15298812091350555
[10/24] Train loss=0.14218200743198395
[15/24] Train loss=0.139202281832695
[20/24] Train loss=0.13451233506202698
Test set avg_accuracy=83.26% avg_sensitivity=65.83%, avg_specificity=89.05% avg_auc=85.89%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.146927 Test loss=0.422507 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13087905943393707
[5/24] Train loss=0.14838425815105438
[10/24] Train loss=0.1416240632534027
[15/24] Train loss=0.13701143860816956
[20/24] Train loss=0.13211700320243835
Test set avg_accuracy=83.05% avg_sensitivity=66.09%, avg_specificity=88.69% avg_auc=86.25%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.145181 Test loss=0.420466 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1340998113155365
[5/24] Train loss=0.14552468061447144
[10/24] Train loss=0.14119155704975128
[15/24] Train loss=0.13530567288398743
[20/24] Train loss=0.13070958852767944
Test set avg_accuracy=81.94% avg_sensitivity=70.27%, avg_specificity=85.82% avg_auc=86.45%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.144459 Test loss=0.439011 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13149690628051758
[5/24] Train loss=0.14832589030265808
[10/24] Train loss=0.1376810073852539
[15/24] Train loss=0.13603201508522034
[20/24] Train loss=0.1325131356716156
Test set avg_accuracy=83.40% avg_sensitivity=62.18%, avg_specificity=90.46% avg_auc=84.84%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.142137 Test loss=0.428000 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12872104346752167
[5/24] Train loss=0.14499761164188385
[10/24] Train loss=0.135674387216568
[15/24] Train loss=0.13417311012744904
[20/24] Train loss=0.130837544798851
Test set avg_accuracy=83.29% avg_sensitivity=62.70%, avg_specificity=90.14% avg_auc=85.41%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.140990 Test loss=0.422013 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1248815730214119
[5/24] Train loss=0.14222370088100433
[10/24] Train loss=0.13485699892044067
[15/24] Train loss=0.13112834095954895
[20/24] Train loss=0.12906482815742493
Test set avg_accuracy=83.46% avg_sensitivity=64.63%, avg_specificity=89.73% avg_auc=85.39%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.139606 Test loss=0.421434 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12573201954364777
[5/24] Train loss=0.14343474805355072
[10/24] Train loss=0.13616690039634705
[15/24] Train loss=0.12971538305282593
[20/24] Train loss=0.1278747320175171
Test set avg_accuracy=83.20% avg_sensitivity=64.58%, avg_specificity=89.40% avg_auc=85.45%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.138989 Test loss=0.426454 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1275458186864853
[5/24] Train loss=0.14318260550498962
[10/24] Train loss=0.13374866545200348
[15/24] Train loss=0.12986190617084503
[20/24] Train loss=0.12679946422576904
Test set avg_accuracy=83.33% avg_sensitivity=64.58%, avg_specificity=89.57% avg_auc=85.65%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.138920 Test loss=0.422619 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12337371706962585
[5/24] Train loss=0.13971099257469177
[10/24] Train loss=0.13651911914348602
[15/24] Train loss=0.13040722906589508
[20/24] Train loss=0.1262051910161972
Test set avg_accuracy=83.54% avg_sensitivity=65.52%, avg_specificity=89.54% avg_auc=85.53%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.138011 Test loss=0.423438 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1239451915025711
[5/24] Train loss=0.14191536605358124
[10/24] Train loss=0.1358623057603836
[15/24] Train loss=0.12695904076099396
[20/24] Train loss=0.12291981279850006
Test set avg_accuracy=83.45% avg_sensitivity=65.21%, avg_specificity=89.52% avg_auc=85.60%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.137748 Test loss=0.423647 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12409002333879471
[5/24] Train loss=0.13948620855808258
[10/24] Train loss=0.13379082083702087
[15/24] Train loss=0.12998683750629425
[20/24] Train loss=0.12665624916553497
Test set avg_accuracy=83.36% avg_sensitivity=65.52%, avg_specificity=89.29% avg_auc=85.68%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.136909 Test loss=0.425318 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12548840045928955
[5/24] Train loss=0.14116889238357544
[10/24] Train loss=0.13660553097724915
[15/24] Train loss=0.12744158506393433
[20/24] Train loss=0.12214233726263046
Test set avg_accuracy=83.36% avg_sensitivity=64.68%, avg_specificity=89.57% avg_auc=85.40%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.137288 Test loss=0.427105 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1263950765132904
[5/24] Train loss=0.14218130707740784
[10/24] Train loss=0.13583040237426758
[15/24] Train loss=0.13132448494434357
[20/24] Train loss=0.12730661034584045
Test set avg_accuracy=83.42% avg_sensitivity=65.15%, avg_specificity=89.50% avg_auc=85.50%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.137949 Test loss=0.426189 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1258396953344345
[5/24] Train loss=0.13859246671199799
[10/24] Train loss=0.13230594992637634
[15/24] Train loss=0.12632368505001068
[20/24] Train loss=0.12759357690811157
Test set avg_accuracy=83.61% avg_sensitivity=66.20%, avg_specificity=89.40% avg_auc=85.80%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.136803 Test loss=0.422972 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12245295941829681
[5/24] Train loss=0.13930542767047882
[10/24] Train loss=0.13246525824069977
[15/24] Train loss=0.1268874853849411
[20/24] Train loss=0.12438683956861496
Test set avg_accuracy=83.59% avg_sensitivity=65.78%, avg_specificity=89.52% avg_auc=85.72%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.136246 Test loss=0.422343 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12381044030189514
[5/24] Train loss=0.14057978987693787
[10/24] Train loss=0.13045722246170044
[15/24] Train loss=0.1283452957868576
[20/24] Train loss=0.12612071633338928
Test set avg_accuracy=83.55% avg_sensitivity=65.31%, avg_specificity=89.62% avg_auc=85.64%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.136081 Test loss=0.424138 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12289191782474518
[5/24] Train loss=0.1391439139842987
[10/24] Train loss=0.13076399266719818
[15/24] Train loss=0.12355057150125504
[20/24] Train loss=0.12327868491411209
Test set avg_accuracy=83.48% avg_sensitivity=65.47%, avg_specificity=89.47% avg_auc=85.62%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.135445 Test loss=0.424728 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12707722187042236
[5/24] Train loss=0.13869518041610718
[10/24] Train loss=0.1351865530014038
[15/24] Train loss=0.12799784541130066
[20/24] Train loss=0.12382093071937561
Test set avg_accuracy=83.50% avg_sensitivity=65.31%, avg_specificity=89.55% avg_auc=85.69%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.136264 Test loss=0.423224 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12380814552307129
[5/24] Train loss=0.13828113675117493
[10/24] Train loss=0.13111035525798798
[15/24] Train loss=0.128315269947052
[20/24] Train loss=0.12065969407558441
Test set avg_accuracy=83.58% avg_sensitivity=65.31%, avg_specificity=89.66% avg_auc=85.67%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.135631 Test loss=0.423229 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12319149076938629
[5/24] Train loss=0.1391727477312088
[10/24] Train loss=0.1304825246334076
[15/24] Train loss=0.12937162816524506
[20/24] Train loss=0.12549802660942078
Test set avg_accuracy=83.61% avg_sensitivity=65.41%, avg_specificity=89.66% avg_auc=85.67%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.135993 Test loss=0.423473 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12447751313447952
[5/24] Train loss=0.14133906364440918
[10/24] Train loss=0.1332746148109436
[15/24] Train loss=0.12760251760482788
[20/24] Train loss=0.12554390728473663
Test set avg_accuracy=83.53% avg_sensitivity=65.47%, avg_specificity=89.54% avg_auc=85.69%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.135391 Test loss=0.423624 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1240861788392067
[5/24] Train loss=0.1388205885887146
[10/24] Train loss=0.12934446334838867
[15/24] Train loss=0.1269926279783249
[20/24] Train loss=0.12297593802213669
Test set avg_accuracy=83.54% avg_sensitivity=65.47%, avg_specificity=89.55% avg_auc=85.67%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.135693 Test loss=0.423908 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=83.46% sen=72.30%, spe=87.18%, auc=88.98%!
Fold[2] Avg_overlap=0.32%(±0.3076865764162736)
[0/24] Train loss=0.7618889212608337
[5/24] Train loss=0.7496206164360046
[10/24] Train loss=0.7389432787895203
[15/24] Train loss=0.7231287956237793
[20/24] Train loss=0.7175637483596802
Test set avg_accuracy=57.70% avg_sensitivity=48.48%, avg_specificity=61.18% avg_auc=58.47%
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.735682 Test loss=0.657387 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7261908054351807
[5/24] Train loss=0.713575541973114
[10/24] Train loss=0.7110535502433777
[15/24] Train loss=0.6935878992080688
[20/24] Train loss=0.6961773037910461
Test set avg_accuracy=65.57% avg_sensitivity=63.79%, avg_specificity=66.25% avg_auc=70.39%
Best model saved!! Metric=-59.99838609780447!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.705750 Test loss=0.620179 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6934934854507446
[5/24] Train loss=0.6831305027008057
[10/24] Train loss=0.684179961681366
[15/24] Train loss=0.6704543232917786
[20/24] Train loss=0.6694103479385376
Test set avg_accuracy=69.02% avg_sensitivity=71.09%, avg_specificity=68.24% avg_auc=75.69%
Best model saved!! Metric=-41.95231700747489!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.680005 Test loss=0.596637 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.664975643157959
[5/24] Train loss=0.6569854021072388
[10/24] Train loss=0.6629372239112854
[15/24] Train loss=0.6461223363876343
[20/24] Train loss=0.6279779672622681
Test set avg_accuracy=71.50% avg_sensitivity=75.07%, avg_specificity=70.14% avg_auc=78.98%
Best model saved!! Metric=-30.308457289778815!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.653216 Test loss=0.573013 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6302322745323181
[5/24] Train loss=0.6330286860466003
[10/24] Train loss=0.6313564777374268
[15/24] Train loss=0.6160715818405151
[20/24] Train loss=0.6079563498497009
Test set avg_accuracy=73.95% avg_sensitivity=77.49%, avg_specificity=72.60% avg_auc=81.43%
Best model saved!! Metric=-20.532505363129346!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.627060 Test loss=0.550123 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6049607396125793
[5/24] Train loss=0.6069910526275635
[10/24] Train loss=0.6054832935333252
[15/24] Train loss=0.5964627265930176
[20/24] Train loss=0.577892005443573
Test set avg_accuracy=75.98% avg_sensitivity=78.20%, avg_specificity=75.13% avg_auc=83.09%
Best model saved!! Metric=-13.599194560079823!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.600702 Test loss=0.528520 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5773268938064575
[5/24] Train loss=0.578510582447052
[10/24] Train loss=0.574609637260437
[15/24] Train loss=0.5636322498321533
[20/24] Train loss=0.5451933741569519
Test set avg_accuracy=77.89% avg_sensitivity=78.15%, avg_specificity=77.79% avg_auc=84.59%
Best model saved!! Metric=-7.577182397449093!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.572936 Test loss=0.505573 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5511995553970337
[5/24] Train loss=0.5529646873474121
[10/24] Train loss=0.5551099181175232
[15/24] Train loss=0.542496919631958
[20/24] Train loss=0.5197420120239258
Test set avg_accuracy=78.98% avg_sensitivity=77.77%, avg_specificity=79.44% avg_auc=85.67%
Best model saved!! Metric=-4.131619622512289!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.547036 Test loss=0.482873 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5228362083435059
[5/24] Train loss=0.5267817378044128
[10/24] Train loss=0.519817590713501
[15/24] Train loss=0.5142296552658081
[20/24] Train loss=0.49263426661491394
Test set avg_accuracy=80.26% avg_sensitivity=74.79%, avg_specificity=82.33% avg_auc=86.07%
Best model saved!! Metric=-2.5468191174510224!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.520107 Test loss=0.459582 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5015454292297363
[5/24] Train loss=0.49932926893234253
[10/24] Train loss=0.5012075901031494
[15/24] Train loss=0.4900423586368561
[20/24] Train loss=0.4625294804573059
Test set avg_accuracy=81.08% avg_sensitivity=76.21%, avg_specificity=82.93% avg_auc=86.89%
Best model saved!! Metric=1.1014010122851232!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.496286 Test loss=0.448032 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.47551366686820984
[5/24] Train loss=0.4753901958465576
[10/24] Train loss=0.4778563380241394
[15/24] Train loss=0.4719657599925995
[20/24] Train loss=0.447190523147583
Test set avg_accuracy=81.88% avg_sensitivity=76.87%, avg_specificity=83.77% avg_auc=87.59%
Best model saved!! Metric=4.109380184978775!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.471792 Test loss=0.435233 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.44850125908851624
[5/24] Train loss=0.45176392793655396
[10/24] Train loss=0.4569593071937561
[15/24] Train loss=0.4542827308177948
[20/24] Train loss=0.42268291115760803
Test set avg_accuracy=82.38% avg_sensitivity=74.36%, avg_specificity=85.42% avg_auc=87.92%
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.450630 Test loss=0.417928 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.42775437235832214
[5/24] Train loss=0.43553832173347473
[10/24] Train loss=0.44247788190841675
[15/24] Train loss=0.4362807273864746
[20/24] Train loss=0.4058660864830017
Test set avg_accuracy=82.92% avg_sensitivity=75.02%, avg_specificity=85.91% avg_auc=88.46%
Best model saved!! Metric=6.302322728677964!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.429932 Test loss=0.407641 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.41057252883911133
[5/24] Train loss=0.4184097647666931
[10/24] Train loss=0.42726272344589233
[15/24] Train loss=0.4122266471385956
[20/24] Train loss=0.38315755128860474
Test set avg_accuracy=83.27% avg_sensitivity=74.17%, avg_specificity=86.71% avg_auc=88.91%
Best model saved!! Metric=7.0683857264359204!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.413180 Test loss=0.397432 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3916206657886505
[5/24] Train loss=0.3972145915031433
[10/24] Train loss=0.41173675656318665
[15/24] Train loss=0.3939869999885559
[20/24] Train loss=0.3701876401901245
Test set avg_accuracy=83.74% avg_sensitivity=74.22%, avg_specificity=87.34% avg_auc=89.31%
Best model saved!! Metric=8.612122750694184!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.396485 Test loss=0.386648 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3786119520664215
[5/24] Train loss=0.3888530731201172
[10/24] Train loss=0.40645527839660645
[15/24] Train loss=0.3871954679489136
[20/24] Train loss=0.36514678597450256
Test set avg_accuracy=83.74% avg_sensitivity=76.11%, avg_specificity=86.62% avg_auc=89.70%
Best model saved!! Metric=10.176733435898427!!
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.384261 Test loss=0.384614 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3674662709236145
[5/24] Train loss=0.3752039670944214
[10/24] Train loss=0.3916643261909485
[15/24] Train loss=0.377705454826355
[20/24] Train loss=0.3504028916358948
Test set avg_accuracy=84.30% avg_sensitivity=74.64%, avg_specificity=87.95% avg_auc=89.95%
Best model saved!! Metric=10.839992751665562!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.371847 Test loss=0.373875 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.34735020995140076
[5/24] Train loss=0.3645229637622833
[10/24] Train loss=0.3894979953765869
[15/24] Train loss=0.3707405924797058
[20/24] Train loss=0.34849002957344055
Test set avg_accuracy=83.46% avg_sensitivity=76.68%, avg_specificity=86.03% avg_auc=89.99%
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.362339 Test loss=0.382020 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.34549134969711304
[5/24] Train loss=0.35621243715286255
[10/24] Train loss=0.37867891788482666
[15/24] Train loss=0.35990220308303833
[20/24] Train loss=0.34057626128196716
Test set avg_accuracy=84.41% avg_sensitivity=73.41%, avg_specificity=88.58% avg_auc=90.42%
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.352673 Test loss=0.361014 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3357033133506775
[5/24] Train loss=0.35335469245910645
[10/24] Train loss=0.3721626400947571
[15/24] Train loss=0.34873950481414795
[20/24] Train loss=0.33504050970077515
Test set avg_accuracy=83.49% avg_sensitivity=76.73%, avg_specificity=86.05% avg_auc=90.31%
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.345620 Test loss=0.371145 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.32838505506515503
[5/24] Train loss=0.3452034592628479
[10/24] Train loss=0.3656749427318573
[15/24] Train loss=0.35043662786483765
[20/24] Train loss=0.3216550350189209
Test set avg_accuracy=84.88% avg_sensitivity=70.81%, avg_specificity=90.22% avg_auc=90.67%
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.336996 Test loss=0.350997 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3217568099498749
[5/24] Train loss=0.34228795766830444
[10/24] Train loss=0.36140456795692444
[15/24] Train loss=0.34006643295288086
[20/24] Train loss=0.313403457403183
Test set avg_accuracy=84.61% avg_sensitivity=62.65%, avg_specificity=92.93% avg_auc=90.63%
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.330659 Test loss=0.349744 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.31403547525405884
[5/24] Train loss=0.33955118060112
[10/24] Train loss=0.3526032269001007
[15/24] Train loss=0.3410041630268097
[20/24] Train loss=0.3196186423301697
Test set avg_accuracy=83.59% avg_sensitivity=74.17%, avg_specificity=87.16% avg_auc=90.39%
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.326997 Test loss=0.364152 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.30429598689079285
[5/24] Train loss=0.33371517062187195
[10/24] Train loss=0.34886234998703003
[15/24] Train loss=0.3304845988750458
[20/24] Train loss=0.3051741123199463
Test set avg_accuracy=84.80% avg_sensitivity=61.75%, avg_specificity=93.54% avg_auc=90.90%
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.320794 Test loss=0.343142 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3089268207550049
[5/24] Train loss=0.33160802721977234
[10/24] Train loss=0.34132370352745056
[15/24] Train loss=0.3281674385070801
[20/24] Train loss=0.2989368736743927
Test set avg_accuracy=82.53% avg_sensitivity=45.17%, avg_specificity=96.68% avg_auc=89.35%
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.317058 Test loss=0.387172 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.306494802236557
[5/24] Train loss=0.32252782583236694
[10/24] Train loss=0.34314754605293274
[15/24] Train loss=0.31664201617240906
[20/24] Train loss=0.30209994316101074
Test set avg_accuracy=84.90% avg_sensitivity=62.51%, avg_specificity=93.38% avg_auc=90.61%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.312021 Test loss=0.347306 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.292593389749527
[5/24] Train loss=0.3245660960674286
[10/24] Train loss=0.3354220390319824
[15/24] Train loss=0.32452592253685
[20/24] Train loss=0.29973769187927246
Test set avg_accuracy=84.19% avg_sensitivity=72.94%, avg_specificity=88.46% avg_auc=90.83%
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.307116 Test loss=0.349113 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.27958089113235474
[5/24] Train loss=0.321615993976593
[10/24] Train loss=0.321890652179718
[15/24] Train loss=0.3135486841201782
[20/24] Train loss=0.2900626063346863
Test set avg_accuracy=84.77% avg_sensitivity=67.35%, avg_specificity=91.36% avg_auc=90.88%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.301214 Test loss=0.342527 Current lr=[0.000210185142098938]

[0/24] Train loss=0.27658146619796753
[5/24] Train loss=0.30534878373146057
[10/24] Train loss=0.3260934352874756
[15/24] Train loss=0.3083783686161041
[20/24] Train loss=0.2913098633289337
Test set avg_accuracy=83.31% avg_sensitivity=48.72%, avg_specificity=96.41% avg_auc=89.80%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.295597 Test loss=0.382596 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2811954617500305
[5/24] Train loss=0.30853548645973206
[10/24] Train loss=0.32155221700668335
[15/24] Train loss=0.30513399839401245
[20/24] Train loss=0.2852807641029358
Test set avg_accuracy=82.71% avg_sensitivity=45.36%, avg_specificity=96.86% avg_auc=88.13%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.293377 Test loss=0.421593 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2761366665363312
[5/24] Train loss=0.2984534204006195
[10/24] Train loss=0.3251950442790985
[15/24] Train loss=0.303424596786499
[20/24] Train loss=0.29295241832733154
Test set avg_accuracy=83.92% avg_sensitivity=70.14%, avg_specificity=89.14% avg_auc=90.03%
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.288883 Test loss=0.361425 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.27016958594322205
[5/24] Train loss=0.3013335168361664
[10/24] Train loss=0.3156495690345764
[15/24] Train loss=0.29872927069664
[20/24] Train loss=0.28199538588523865
Test set avg_accuracy=80.34% avg_sensitivity=34.55%, avg_specificity=97.68% avg_auc=86.85%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.284870 Test loss=0.465199 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.25930342078208923
[5/24] Train loss=0.28279852867126465
[10/24] Train loss=0.31536367535591125
[15/24] Train loss=0.29170557856559753
[20/24] Train loss=0.27657440304756165
Test set avg_accuracy=84.87% avg_sensitivity=63.32%, avg_specificity=93.03% avg_auc=90.80%
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.279566 Test loss=0.343422 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2606753706932068
[5/24] Train loss=0.28502118587493896
[10/24] Train loss=0.3121444284915924
[15/24] Train loss=0.28080567717552185
[20/24] Train loss=0.26254183053970337
Test set avg_accuracy=83.88% avg_sensitivity=77.77%, avg_specificity=86.19% avg_auc=90.53%
Best model saved!! Metric=12.376732536282447!!
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.275039 Test loss=0.360473 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.26148685812950134
[5/24] Train loss=0.2809435725212097
[10/24] Train loss=0.3084118366241455
[15/24] Train loss=0.28343331813812256
[20/24] Train loss=0.25971972942352295
Test set avg_accuracy=82.11% avg_sensitivity=44.74%, avg_specificity=96.27% avg_auc=87.74%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.270723 Test loss=0.431918 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2655905485153198
[5/24] Train loss=0.25992247462272644
[10/24] Train loss=0.3209824860095978
[15/24] Train loss=0.2902612090110779
[20/24] Train loss=0.26697778701782227
Test set avg_accuracy=84.09% avg_sensitivity=67.49%, avg_specificity=90.38% avg_auc=90.17%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.269212 Test loss=0.354836 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.25479984283447266
[5/24] Train loss=0.2681139409542084
[10/24] Train loss=0.30893415212631226
[15/24] Train loss=0.2707693576812744
[20/24] Train loss=0.25699540972709656
Test set avg_accuracy=82.80% avg_sensitivity=56.97%, avg_specificity=92.59% avg_auc=86.12%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.262775 Test loss=0.412205 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2548163831233978
[5/24] Train loss=0.2666963040828705
[10/24] Train loss=0.3035375475883484
[15/24] Train loss=0.2730197310447693
[20/24] Train loss=0.268659383058548
Test set avg_accuracy=82.21% avg_sensitivity=70.19%, avg_specificity=86.77% avg_auc=88.81%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.262577 Test loss=0.402486 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.24593979120254517
[5/24] Train loss=0.2716106176376343
[10/24] Train loss=0.2965829372406006
[15/24] Train loss=0.2742997705936432
[20/24] Train loss=0.2577798068523407
Test set avg_accuracy=77.84% avg_sensitivity=22.09%, avg_specificity=98.96% avg_auc=83.82%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.260325 Test loss=0.546905 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2334343045949936
[5/24] Train loss=0.25804567337036133
[10/24] Train loss=0.2941569983959198
[15/24] Train loss=0.2832573652267456
[20/24] Train loss=0.2651596665382385
Test set avg_accuracy=81.84% avg_sensitivity=76.16%, avg_specificity=83.99% avg_auc=88.57%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.255069 Test loss=0.404292 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.23981527984142303
[5/24] Train loss=0.23868905007839203
[10/24] Train loss=0.29957374930381775
[15/24] Train loss=0.2710753381252289
[20/24] Train loss=0.2603241205215454
Test set avg_accuracy=79.71% avg_sensitivity=32.99%, avg_specificity=97.41% avg_auc=85.86%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.250805 Test loss=0.448594 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.24712927639484406
[5/24] Train loss=0.23319600522518158
[10/24] Train loss=0.2868269085884094
[15/24] Train loss=0.2669503390789032
[20/24] Train loss=0.25817063450813293
Test set avg_accuracy=82.60% avg_sensitivity=62.13%, avg_specificity=90.36% avg_auc=88.03%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.250285 Test loss=0.379784 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.24366742372512817
[5/24] Train loss=0.2439415454864502
[10/24] Train loss=0.29318130016326904
[15/24] Train loss=0.2707182765007019
[20/24] Train loss=0.24135451018810272
Test set avg_accuracy=78.42% avg_sensitivity=25.21%, avg_specificity=98.58% avg_auc=81.22%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.249838 Test loss=0.563037 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.23449397087097168
[5/24] Train loss=0.23717276751995087
[10/24] Train loss=0.28881844878196716
[15/24] Train loss=0.26081350445747375
[20/24] Train loss=0.23370854556560516
Test set avg_accuracy=82.96% avg_sensitivity=50.66%, avg_specificity=95.19% avg_auc=87.26%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.244032 Test loss=0.410567 Current lr=[0.00029967723776099]

[0/24] Train loss=0.23363660275936127
[5/24] Train loss=0.22454267740249634
[10/24] Train loss=0.2934492826461792
[15/24] Train loss=0.26285797357559204
[20/24] Train loss=0.2441634237766266
Test set avg_accuracy=80.90% avg_sensitivity=42.61%, avg_specificity=95.40% avg_auc=82.82%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.241807 Test loss=0.455049 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.24304498732089996
[5/24] Train loss=0.23357567191123962
[10/24] Train loss=0.287980854511261
[15/24] Train loss=0.24457046389579773
[20/24] Train loss=0.22450241446495056
Test set avg_accuracy=78.24% avg_sensitivity=31.04%, avg_specificity=96.12% avg_auc=78.04%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.238960 Test loss=0.536336 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.24618305265903473
[5/24] Train loss=0.2226828783750534
[10/24] Train loss=0.2713317275047302
[15/24] Train loss=0.2527388632297516
[20/24] Train loss=0.22788077592849731
Test set avg_accuracy=72.62% avg_sensitivity=0.33%, avg_specificity=100.00% avg_auc=64.97%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.236512 Test loss=0.958035 Current lr=[0.000299720220882401]

[0/24] Train loss=0.24441154301166534
[5/24] Train loss=0.22915028035640717
[10/24] Train loss=0.29255369305610657
[15/24] Train loss=0.2616209387779236
[20/24] Train loss=0.2408040165901184
Test set avg_accuracy=83.15% avg_sensitivity=60.28%, avg_specificity=91.81% avg_auc=87.29%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.242146 Test loss=0.386996 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.22173680365085602
[5/24] Train loss=0.22062824666500092
[10/24] Train loss=0.270364910364151
[15/24] Train loss=0.2665688097476959
[20/24] Train loss=0.23468081653118134
Test set avg_accuracy=80.70% avg_sensitivity=54.69%, avg_specificity=90.56% avg_auc=81.42%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.234197 Test loss=0.452096 Current lr=[0.000298904600941902]

[0/24] Train loss=0.21560999751091003
[5/24] Train loss=0.20898638665676117
[10/24] Train loss=0.25925812125205994
[15/24] Train loss=0.24942012131214142
[20/24] Train loss=0.22746042907238007
Test set avg_accuracy=73.37% avg_sensitivity=3.65%, avg_specificity=99.78% avg_auc=53.88%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.226517 Test loss=0.757597 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.23043593764305115
[5/24] Train loss=0.2034628987312317
[10/24] Train loss=0.26224127411842346
[15/24] Train loss=0.27258723974227905
[20/24] Train loss=0.21847064793109894
Test set avg_accuracy=77.66% avg_sensitivity=32.51%, avg_specificity=94.76% avg_auc=78.76%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.230144 Test loss=0.548304 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2202121466398239
[5/24] Train loss=0.2196117490530014
[10/24] Train loss=0.25844937562942505
[15/24] Train loss=0.25074899196624756
[20/24] Train loss=0.23829646408557892
Test set avg_accuracy=78.37% avg_sensitivity=37.01%, avg_specificity=94.04% avg_auc=79.40%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.230351 Test loss=0.497477 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.22536601126194
[5/24] Train loss=0.2074459344148636
[10/24] Train loss=0.26577088236808777
[15/24] Train loss=0.24424491822719574
[20/24] Train loss=0.22175313532352448
Test set avg_accuracy=82.96% avg_sensitivity=52.56%, avg_specificity=94.47% avg_auc=86.18%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.227001 Test loss=0.412088 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.21348418295383453
[5/24] Train loss=0.22667111456394196
[10/24] Train loss=0.25565582513809204
[15/24] Train loss=0.24717029929161072
[20/24] Train loss=0.2206471562385559
Test set avg_accuracy=83.39% avg_sensitivity=66.21%, avg_specificity=89.89% avg_auc=87.31%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.227076 Test loss=0.397541 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2042931765317917
[5/24] Train loss=0.2271483838558197
[10/24] Train loss=0.24245746433734894
[15/24] Train loss=0.24052776396274567
[20/24] Train loss=0.2245202511548996
Test set avg_accuracy=82.77% avg_sensitivity=55.12%, avg_specificity=93.25% avg_auc=86.90%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.222238 Test loss=0.426230 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2000671923160553
[5/24] Train loss=0.20901474356651306
[10/24] Train loss=0.25695863366127014
[15/24] Train loss=0.24367836117744446
[20/24] Train loss=0.21009820699691772
Test set avg_accuracy=80.57% avg_sensitivity=51.00%, avg_specificity=91.78% avg_auc=82.09%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.224574 Test loss=0.452452 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.20551662147045135
[5/24] Train loss=0.22679606080055237
[10/24] Train loss=0.25624242424964905
[15/24] Train loss=0.24719195067882538
[20/24] Train loss=0.2283557951450348
Test set avg_accuracy=74.80% avg_sensitivity=10.33%, avg_specificity=99.23% avg_auc=66.52%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.224579 Test loss=0.845727 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.1974801868200302
[5/24] Train loss=0.21096698939800262
[10/24] Train loss=0.24958910048007965
[15/24] Train loss=0.24083395302295685
[20/24] Train loss=0.22321994602680206
Test set avg_accuracy=80.14% avg_sensitivity=62.09%, avg_specificity=86.98% avg_auc=83.34%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.222230 Test loss=0.444193 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.20080074667930603
[5/24] Train loss=0.1963605284690857
[10/24] Train loss=0.24432775378227234
[15/24] Train loss=0.24891753494739532
[20/24] Train loss=0.22303910553455353
Test set avg_accuracy=83.59% avg_sensitivity=67.20%, avg_specificity=89.80% avg_auc=88.88%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.220877 Test loss=0.376746 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.20821677148342133
[5/24] Train loss=0.21001163125038147
[10/24] Train loss=0.25753679871559143
[15/24] Train loss=0.24405866861343384
[20/24] Train loss=0.21058490872383118
Test set avg_accuracy=82.37% avg_sensitivity=56.16%, avg_specificity=92.30% avg_auc=84.17%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.220980 Test loss=0.418677 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.19558019936084747
[5/24] Train loss=0.2048598974943161
[10/24] Train loss=0.23738618195056915
[15/24] Train loss=0.2324611097574234
[20/24] Train loss=0.22187209129333496
Test set avg_accuracy=81.38% avg_sensitivity=46.21%, avg_specificity=94.70% avg_auc=84.13%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.221924 Test loss=0.450182 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2094545066356659
[5/24] Train loss=0.1977595090866089
[10/24] Train loss=0.2486414760351181
[15/24] Train loss=0.23649057745933533
[20/24] Train loss=0.23099316656589508
Test set avg_accuracy=81.91% avg_sensitivity=51.33%, avg_specificity=93.50% avg_auc=85.77%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.218150 Test loss=0.467308 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2038571536540985
[5/24] Train loss=0.20815083384513855
[10/24] Train loss=0.24284453690052032
[15/24] Train loss=0.2539232671260834
[20/24] Train loss=0.21797502040863037
Test set avg_accuracy=69.56% avg_sensitivity=63.98%, avg_specificity=71.67% avg_auc=76.90%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.225491 Test loss=0.601375 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2114720493555069
[5/24] Train loss=0.18728215992450714
[10/24] Train loss=0.24586263298988342
[15/24] Train loss=0.23180709779262543
[20/24] Train loss=0.2095666080713272
Test set avg_accuracy=80.08% avg_sensitivity=54.17%, avg_specificity=89.89% avg_auc=84.42%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.214599 Test loss=0.470476 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2061276137828827
[5/24] Train loss=0.20439466834068298
[10/24] Train loss=0.2388046681880951
[15/24] Train loss=0.2334837019443512
[20/24] Train loss=0.21735677123069763
Test set avg_accuracy=74.90% avg_sensitivity=77.20%, avg_specificity=74.02% avg_auc=84.09%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.215861 Test loss=0.540699 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.2070194035768509
[5/24] Train loss=0.2095678448677063
[10/24] Train loss=0.24135422706604004
[15/24] Train loss=0.2411024421453476
[20/24] Train loss=0.21471844613552094
Test set avg_accuracy=78.88% avg_sensitivity=83.36%, avg_specificity=77.18% avg_auc=87.99%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.214795 Test loss=0.461988 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.19927476346492767
[5/24] Train loss=0.1856568455696106
[10/24] Train loss=0.2327907681465149
[15/24] Train loss=0.2260056883096695
[20/24] Train loss=0.2141447514295578
Test set avg_accuracy=84.00% avg_sensitivity=73.13%, avg_specificity=88.11% avg_auc=89.98%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.210705 Test loss=0.372985 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2089213728904724
[5/24] Train loss=0.20425069332122803
[10/24] Train loss=0.23716679215431213
[15/24] Train loss=0.22227534651756287
[20/24] Train loss=0.2105662077665329
Test set avg_accuracy=75.77% avg_sensitivity=64.12%, avg_specificity=80.18% avg_auc=80.34%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.209370 Test loss=0.514743 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.21110154688358307
[5/24] Train loss=0.19117581844329834
[10/24] Train loss=0.23561227321624756
[15/24] Train loss=0.21958263218402863
[20/24] Train loss=0.20567233860492706
Test set avg_accuracy=82.03% avg_sensitivity=81.37%, avg_specificity=82.28% avg_auc=89.31%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.207205 Test loss=0.413024 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.19495421648025513
[5/24] Train loss=0.18997430801391602
[10/24] Train loss=0.23186522722244263
[15/24] Train loss=0.23159466683864594
[20/24] Train loss=0.20209446549415588
Test set avg_accuracy=84.40% avg_sensitivity=68.34%, avg_specificity=90.48% avg_auc=88.98%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.208122 Test loss=0.378770 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.19693461060523987
[5/24] Train loss=0.19030314683914185
[10/24] Train loss=0.2203233242034912
[15/24] Train loss=0.22367562353610992
[20/24] Train loss=0.2070118635892868
Test set avg_accuracy=81.00% avg_sensitivity=83.32%, avg_specificity=80.13% avg_auc=88.94%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.203812 Test loss=0.417454 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.18932375311851501
[5/24] Train loss=0.18628814816474915
[10/24] Train loss=0.22332648932933807
[15/24] Train loss=0.21953167021274567
[20/24] Train loss=0.19757051765918732
Test set avg_accuracy=80.70% avg_sensitivity=74.64%, avg_specificity=83.00% avg_auc=87.46%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.200318 Test loss=0.417013 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.1844085156917572
[5/24] Train loss=0.18546998500823975
[10/24] Train loss=0.21862256526947021
[15/24] Train loss=0.21063286066055298
[20/24] Train loss=0.19157131016254425
Test set avg_accuracy=80.64% avg_sensitivity=81.18%, avg_specificity=80.43% avg_auc=88.97%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.199588 Test loss=0.418562 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1909831166267395
[5/24] Train loss=0.17576295137405396
[10/24] Train loss=0.22522440552711487
[15/24] Train loss=0.20246297121047974
[20/24] Train loss=0.20234054327011108
Test set avg_accuracy=82.27% avg_sensitivity=74.45%, avg_specificity=85.22% avg_auc=88.07%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.197287 Test loss=0.412707 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.18389153480529785
[5/24] Train loss=0.17030106484889984
[10/24] Train loss=0.2301453799009323
[15/24] Train loss=0.2132451832294464
[20/24] Train loss=0.2118566334247589
Test set avg_accuracy=82.76% avg_sensitivity=74.12%, avg_specificity=86.03% avg_auc=89.13%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.198760 Test loss=0.388222 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.18228735029697418
[5/24] Train loss=0.18388846516609192
[10/24] Train loss=0.24161893129348755
[15/24] Train loss=0.2022978961467743
[20/24] Train loss=0.19993093609809875
Test set avg_accuracy=82.51% avg_sensitivity=63.79%, avg_specificity=89.61% avg_auc=85.33%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.195332 Test loss=0.432164 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.19631735980510712
[5/24] Train loss=0.19113825261592865
[10/24] Train loss=0.22322194278240204
[15/24] Train loss=0.19410470128059387
[20/24] Train loss=0.20355626940727234
Test set avg_accuracy=81.39% avg_sensitivity=54.55%, avg_specificity=91.56% avg_auc=84.06%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.195491 Test loss=0.466383 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.19363780319690704
[5/24] Train loss=0.1796330362558365
[10/24] Train loss=0.21441051363945007
[15/24] Train loss=0.20743635296821594
[20/24] Train loss=0.1863706260919571
Test set avg_accuracy=79.99% avg_sensitivity=44.12%, avg_specificity=93.57% avg_auc=82.48%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.195134 Test loss=0.492430 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.18517830967903137
[5/24] Train loss=0.1852099895477295
[10/24] Train loss=0.2124570608139038
[15/24] Train loss=0.20569702982902527
[20/24] Train loss=0.18632817268371582
Test set avg_accuracy=79.53% avg_sensitivity=34.88%, avg_specificity=96.45% avg_auc=80.09%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.193480 Test loss=0.535104 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.18017582595348358
[5/24] Train loss=0.17363959550857544
[10/24] Train loss=0.20947696268558502
[15/24] Train loss=0.20852090418338776
[20/24] Train loss=0.20004594326019287
Test set avg_accuracy=75.82% avg_sensitivity=83.79%, avg_specificity=72.80% avg_auc=85.95%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.195055 Test loss=0.502325 Current lr=[0.000224838296036774]

[0/24] Train loss=0.18238656222820282
[5/24] Train loss=0.1730264127254486
[10/24] Train loss=0.21331720054149628
[15/24] Train loss=0.20488832890987396
[20/24] Train loss=0.19709521532058716
Test set avg_accuracy=83.89% avg_sensitivity=63.13%, avg_specificity=91.76% avg_auc=87.98%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.195253 Test loss=0.392377 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.18346554040908813
[5/24] Train loss=0.18823418021202087
[10/24] Train loss=0.21597212553024292
[15/24] Train loss=0.19357076287269592
[20/24] Train loss=0.18533886969089508
Test set avg_accuracy=82.17% avg_sensitivity=62.37%, avg_specificity=89.68% avg_auc=86.54%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.191845 Test loss=0.425786 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.18865668773651123
[5/24] Train loss=0.18208618462085724
[10/24] Train loss=0.2226533442735672
[15/24] Train loss=0.20526669919490814
[20/24] Train loss=0.20175300538539886
Test set avg_accuracy=80.34% avg_sensitivity=41.66%, avg_specificity=94.99% avg_auc=80.14%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.194554 Test loss=0.524761 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1874522715806961
[5/24] Train loss=0.18714696168899536
[10/24] Train loss=0.21774230897426605
[15/24] Train loss=0.20861703157424927
[20/24] Train loss=0.18954811990261078
Test set avg_accuracy=83.06% avg_sensitivity=72.84%, avg_specificity=86.93% avg_auc=88.44%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.191940 Test loss=0.398399 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.1797417402267456
[5/24] Train loss=0.18642348051071167
[10/24] Train loss=0.22754105925559998
[15/24] Train loss=0.19925740361213684
[20/24] Train loss=0.20099374651908875
Test set avg_accuracy=81.77% avg_sensitivity=74.93%, avg_specificity=84.36% avg_auc=87.90%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.196783 Test loss=0.414899 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.189548522233963
[5/24] Train loss=0.18347595632076263
[10/24] Train loss=0.21278557181358337
[15/24] Train loss=0.20721188187599182
[20/24] Train loss=0.19510900974273682
Test set avg_accuracy=79.44% avg_sensitivity=76.16%, avg_specificity=80.68% avg_auc=85.82%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.194333 Test loss=0.461586 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.18431158363819122
[5/24] Train loss=0.17946720123291016
[10/24] Train loss=0.22086696326732635
[15/24] Train loss=0.195350781083107
[20/24] Train loss=0.19550316035747528
Test set avg_accuracy=79.97% avg_sensitivity=41.71%, avg_specificity=94.47% avg_auc=76.14%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.194696 Test loss=0.522758 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1773199588060379
[5/24] Train loss=0.17720676958560944
[10/24] Train loss=0.2444685697555542
[15/24] Train loss=0.20532360672950745
[20/24] Train loss=0.19988931715488434
Test set avg_accuracy=81.42% avg_sensitivity=61.56%, avg_specificity=88.94% avg_auc=83.27%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.197755 Test loss=0.450203 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1755022406578064
[5/24] Train loss=0.18592308461666107
[10/24] Train loss=0.22638438642024994
[15/24] Train loss=0.19447235763072968
[20/24] Train loss=0.18783149123191833
Test set avg_accuracy=81.78% avg_sensitivity=55.17%, avg_specificity=91.87% avg_auc=85.09%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.192282 Test loss=0.447422 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.17984706163406372
[5/24] Train loss=0.16573822498321533
[10/24] Train loss=0.21882003545761108
[15/24] Train loss=0.19630111753940582
[20/24] Train loss=0.17749688029289246
Test set avg_accuracy=81.78% avg_sensitivity=53.79%, avg_specificity=92.39% avg_auc=84.49%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.183352 Test loss=0.457480 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.17291179299354553
[5/24] Train loss=0.1686413288116455
[10/24] Train loss=0.21602672338485718
[15/24] Train loss=0.2049310803413391
[20/24] Train loss=0.1844199150800705
Test set avg_accuracy=80.96% avg_sensitivity=72.51%, avg_specificity=84.17% avg_auc=86.70%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.185324 Test loss=0.446657 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.174277663230896
[5/24] Train loss=0.16993804275989532
[10/24] Train loss=0.19912166893482208
[15/24] Train loss=0.18195198476314545
[20/24] Train loss=0.1820174902677536
Test set avg_accuracy=82.17% avg_sensitivity=61.42%, avg_specificity=90.04% avg_auc=87.04%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.181610 Test loss=0.410611 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1731366068124771
[5/24] Train loss=0.18096479773521423
[10/24] Train loss=0.21604418754577637
[15/24] Train loss=0.18899860978126526
[20/24] Train loss=0.18709947168827057
Test set avg_accuracy=82.98% avg_sensitivity=64.22%, avg_specificity=90.09% avg_auc=87.53%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.180707 Test loss=0.409157 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.17222526669502258
[5/24] Train loss=0.15870735049247742
[10/24] Train loss=0.2025199681520462
[15/24] Train loss=0.1827094703912735
[20/24] Train loss=0.18133069574832916
Test set avg_accuracy=83.58% avg_sensitivity=76.16%, avg_specificity=86.39% avg_auc=89.23%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.176933 Test loss=0.390240 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.16711513698101044
[5/24] Train loss=0.17718186974525452
[10/24] Train loss=0.20231807231903076
[15/24] Train loss=0.186187282204628
[20/24] Train loss=0.17669682204723358
Test set avg_accuracy=82.07% avg_sensitivity=59.76%, avg_specificity=90.52% avg_auc=86.06%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.176840 Test loss=0.436416 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.16284364461898804
[5/24] Train loss=0.17100191116333008
[10/24] Train loss=0.20573922991752625
[15/24] Train loss=0.1929025501012802
[20/24] Train loss=0.17967070639133453
Test set avg_accuracy=82.51% avg_sensitivity=62.61%, avg_specificity=90.05% avg_auc=86.09%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.174849 Test loss=0.424221 Current lr=[0.000156543481933168]

[0/24] Train loss=0.16253212094306946
[5/24] Train loss=0.15549679100513458
[10/24] Train loss=0.1945970356464386
[15/24] Train loss=0.18413113057613373
[20/24] Train loss=0.18228591978549957
Test set avg_accuracy=82.25% avg_sensitivity=54.88%, avg_specificity=92.62% avg_auc=84.45%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.172934 Test loss=0.462786 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.17376141250133514
[5/24] Train loss=0.1615588515996933
[10/24] Train loss=0.1973455846309662
[15/24] Train loss=0.19544929265975952
[20/24] Train loss=0.17688383162021637
Test set avg_accuracy=82.06% avg_sensitivity=51.80%, avg_specificity=93.52% avg_auc=84.63%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.176052 Test loss=0.451892 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.16293758153915405
[5/24] Train loss=0.1607280671596527
[10/24] Train loss=0.198887437582016
[15/24] Train loss=0.1858292669057846
[20/24] Train loss=0.17161308228969574
Test set avg_accuracy=81.54% avg_sensitivity=45.69%, avg_specificity=95.12% avg_auc=84.27%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.172347 Test loss=0.471343 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.16511036455631256
[5/24] Train loss=0.15875191986560822
[10/24] Train loss=0.19776713848114014
[15/24] Train loss=0.18319305777549744
[20/24] Train loss=0.1770433485507965
Test set avg_accuracy=84.01% avg_sensitivity=62.61%, avg_specificity=92.12% avg_auc=87.29%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.170992 Test loss=0.410440 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.161738321185112
[5/24] Train loss=0.157950758934021
[10/24] Train loss=0.1854022890329361
[15/24] Train loss=0.1797151267528534
[20/24] Train loss=0.17182907462120056
Test set avg_accuracy=83.01% avg_sensitivity=55.73%, avg_specificity=93.34% avg_auc=85.91%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.171286 Test loss=0.444145 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16191990673542023
[5/24] Train loss=0.1524745225906372
[10/24] Train loss=0.20363973081111908
[15/24] Train loss=0.18166886270046234
[20/24] Train loss=0.18178775906562805
Test set avg_accuracy=83.93% avg_sensitivity=62.46%, avg_specificity=92.06% avg_auc=86.83%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.172341 Test loss=0.418943 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15727563202381134
[5/24] Train loss=0.14948351681232452
[10/24] Train loss=0.1841902881860733
[15/24] Train loss=0.18920235335826874
[20/24] Train loss=0.17514149844646454
Test set avg_accuracy=82.08% avg_sensitivity=47.11%, avg_specificity=95.33% avg_auc=83.50%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.171070 Test loss=0.476613 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.16697125136852264
[5/24] Train loss=0.16969755291938782
[10/24] Train loss=0.1925680935382843
[15/24] Train loss=0.17657862603664398
[20/24] Train loss=0.1658477932214737
Test set avg_accuracy=81.48% avg_sensitivity=47.68%, avg_specificity=94.29% avg_auc=83.37%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.168337 Test loss=0.471033 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.16142669320106506
[5/24] Train loss=0.15288743376731873
[10/24] Train loss=0.18425744771957397
[15/24] Train loss=0.17923599481582642
[20/24] Train loss=0.16787227988243103
Test set avg_accuracy=84.40% avg_sensitivity=67.49%, avg_specificity=90.81% avg_auc=88.20%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.165528 Test loss=0.388129 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.15619711577892303
[5/24] Train loss=0.1492391973733902
[10/24] Train loss=0.18387897312641144
[15/24] Train loss=0.17164833843708038
[20/24] Train loss=0.1652652472257614
Test set avg_accuracy=83.32% avg_sensitivity=55.78%, avg_specificity=93.75% avg_auc=86.86%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.164278 Test loss=0.429978 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16027435660362244
[5/24] Train loss=0.15265770256519318
[10/24] Train loss=0.17549660801887512
[15/24] Train loss=0.16967202723026276
[20/24] Train loss=0.16668319702148438
Test set avg_accuracy=83.44% avg_sensitivity=64.50%, avg_specificity=90.61% avg_auc=87.22%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.162214 Test loss=0.409590 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1617744266986847
[5/24] Train loss=0.15092933177947998
[10/24] Train loss=0.17981134355068207
[15/24] Train loss=0.1668519377708435
[20/24] Train loss=0.16847674548625946
Test set avg_accuracy=83.65% avg_sensitivity=66.68%, avg_specificity=90.07% avg_auc=88.93%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.162727 Test loss=0.384405 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.16262835264205933
[5/24] Train loss=0.15494607388973236
[10/24] Train loss=0.18978911638259888
[15/24] Train loss=0.1698029786348343
[20/24] Train loss=0.16807709634304047
Test set avg_accuracy=83.62% avg_sensitivity=72.09%, avg_specificity=87.99% avg_auc=88.77%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.160447 Test loss=0.400921 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1528187245130539
[5/24] Train loss=0.14895299077033997
[10/24] Train loss=0.18359553813934326
[15/24] Train loss=0.16974973678588867
[20/24] Train loss=0.16024179756641388
Test set avg_accuracy=82.03% avg_sensitivity=64.93%, avg_specificity=88.51% avg_auc=86.93%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.159315 Test loss=0.423379 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15423400700092316
[5/24] Train loss=0.14973847568035126
[10/24] Train loss=0.17890337109565735
[15/24] Train loss=0.18109659850597382
[20/24] Train loss=0.1643923968076706
Test set avg_accuracy=83.76% avg_sensitivity=72.09%, avg_specificity=88.19% avg_auc=89.19%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.158969 Test loss=0.385835 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.15213844180107117
[5/24] Train loss=0.1478254348039627
[10/24] Train loss=0.18083560466766357
[15/24] Train loss=0.168438121676445
[20/24] Train loss=0.15650507807731628
Test set avg_accuracy=81.81% avg_sensitivity=54.79%, avg_specificity=92.05% avg_auc=85.08%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.157695 Test loss=0.451032 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.15345564484596252
[5/24] Train loss=0.1474384218454361
[10/24] Train loss=0.17404669523239136
[15/24] Train loss=0.17358212172985077
[20/24] Train loss=0.1718066930770874
Test set avg_accuracy=83.09% avg_sensitivity=60.43%, avg_specificity=91.67% avg_auc=87.01%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.158567 Test loss=0.423011 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.15283353626728058
[5/24] Train loss=0.14607366919517517
[10/24] Train loss=0.17639510333538055
[15/24] Train loss=0.16939420998096466
[20/24] Train loss=0.16186197102069855
Test set avg_accuracy=81.84% avg_sensitivity=50.38%, avg_specificity=93.75% avg_auc=84.53%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.157245 Test loss=0.459381 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.15719525516033173
[5/24] Train loss=0.1477450728416443
[10/24] Train loss=0.18607452511787415
[15/24] Train loss=0.16356922686100006
[20/24] Train loss=0.1593463271856308
Test set avg_accuracy=83.49% avg_sensitivity=65.88%, avg_specificity=90.16% avg_auc=88.40%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.157186 Test loss=0.401965 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15473228693008423
[5/24] Train loss=0.1420135200023651
[10/24] Train loss=0.1740214079618454
[15/24] Train loss=0.16978001594543457
[20/24] Train loss=0.161282479763031
Test set avg_accuracy=80.38% avg_sensitivity=74.69%, avg_specificity=82.53% avg_auc=86.65%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.155601 Test loss=0.446255 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14505450427532196
[5/24] Train loss=0.14705480635166168
[10/24] Train loss=0.1714022159576416
[15/24] Train loss=0.1679886132478714
[20/24] Train loss=0.15955178439617157
Test set avg_accuracy=83.96% avg_sensitivity=67.87%, avg_specificity=90.05% avg_auc=88.58%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.154679 Test loss=0.391562 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1470227986574173
[5/24] Train loss=0.145077183842659
[10/24] Train loss=0.17442694306373596
[15/24] Train loss=0.16224171221256256
[20/24] Train loss=0.16326749324798584
Test set avg_accuracy=83.07% avg_sensitivity=71.71%, avg_specificity=87.38% avg_auc=88.70%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.151735 Test loss=0.403036 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1432306319475174
[5/24] Train loss=0.14242926239967346
[10/24] Train loss=0.17019835114479065
[15/24] Train loss=0.16199499368667603
[20/24] Train loss=0.15576311945915222
Test set avg_accuracy=82.34% avg_sensitivity=71.56%, avg_specificity=86.43% avg_auc=88.00%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.151545 Test loss=0.414662 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14428205788135529
[5/24] Train loss=0.13883231580257416
[10/24] Train loss=0.1719697266817093
[15/24] Train loss=0.15642210841178894
[20/24] Train loss=0.15202312171459198
Test set avg_accuracy=83.68% avg_sensitivity=67.35%, avg_specificity=89.87% avg_auc=88.30%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.149918 Test loss=0.401117 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1443459838628769
[5/24] Train loss=0.13630816340446472
[10/24] Train loss=0.1669672280550003
[15/24] Train loss=0.16078950464725494
[20/24] Train loss=0.15122541785240173
Test set avg_accuracy=83.09% avg_sensitivity=73.51%, avg_specificity=86.71% avg_auc=89.14%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.149882 Test loss=0.396698 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.14460976421833038
[5/24] Train loss=0.13781295716762543
[10/24] Train loss=0.16203899681568146
[15/24] Train loss=0.15707647800445557
[20/24] Train loss=0.15016214549541473
Test set avg_accuracy=84.08% avg_sensitivity=68.72%, avg_specificity=89.89% avg_auc=88.79%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.148126 Test loss=0.392557 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14385266602039337
[5/24] Train loss=0.13580580055713654
[10/24] Train loss=0.16967074573040009
[15/24] Train loss=0.15973766148090363
[20/24] Train loss=0.1560686230659485
Test set avg_accuracy=83.58% avg_sensitivity=66.82%, avg_specificity=89.93% avg_auc=88.54%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.148439 Test loss=0.399128 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.14666599035263062
[5/24] Train loss=0.13750195503234863
[10/24] Train loss=0.16276611387729645
[15/24] Train loss=0.1551811546087265
[20/24] Train loss=0.15215878188610077
Test set avg_accuracy=83.45% avg_sensitivity=70.81%, avg_specificity=88.24% avg_auc=88.81%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.145935 Test loss=0.397330 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13972654938697815
[5/24] Train loss=0.14097043871879578
[10/24] Train loss=0.15858307480812073
[15/24] Train loss=0.14747674763202667
[20/24] Train loss=0.15358412265777588
Test set avg_accuracy=83.67% avg_sensitivity=68.67%, avg_specificity=89.35% avg_auc=88.60%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.144701 Test loss=0.398786 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13806363940238953
[5/24] Train loss=0.13361942768096924
[10/24] Train loss=0.16000878810882568
[15/24] Train loss=0.15599416196346283
[20/24] Train loss=0.15388134121894836
Test set avg_accuracy=83.19% avg_sensitivity=72.89%, avg_specificity=87.09% avg_auc=88.68%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.144372 Test loss=0.401070 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1365748792886734
[5/24] Train loss=0.12819981575012207
[10/24] Train loss=0.15807031095027924
[15/24] Train loss=0.15243421494960785
[20/24] Train loss=0.14812378585338593
Test set avg_accuracy=83.53% avg_sensitivity=70.05%, avg_specificity=88.64% avg_auc=88.47%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.143599 Test loss=0.402611 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.14004357159137726
[5/24] Train loss=0.12795086205005646
[10/24] Train loss=0.15501545369625092
[15/24] Train loss=0.15798866748809814
[20/24] Train loss=0.14473210275173187
Test set avg_accuracy=83.11% avg_sensitivity=72.51%, avg_specificity=87.13% avg_auc=89.20%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.142445 Test loss=0.395650 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13326036930084229
[5/24] Train loss=0.12900441884994507
[10/24] Train loss=0.15797720849514008
[15/24] Train loss=0.1500881463289261
[20/24] Train loss=0.14469142258167267
Test set avg_accuracy=83.66% avg_sensitivity=71.09%, avg_specificity=88.42% avg_auc=88.93%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.141034 Test loss=0.393289 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13580957055091858
[5/24] Train loss=0.13020382821559906
[10/24] Train loss=0.1545640379190445
[15/24] Train loss=0.1484864354133606
[20/24] Train loss=0.14742013812065125
Test set avg_accuracy=83.54% avg_sensitivity=69.10%, avg_specificity=89.01% avg_auc=88.74%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.141038 Test loss=0.399071 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1390911191701889
[5/24] Train loss=0.13125285506248474
[10/24] Train loss=0.15544620156288147
[15/24] Train loss=0.14615701138973236
[20/24] Train loss=0.1443752497434616
Test set avg_accuracy=83.70% avg_sensitivity=68.58%, avg_specificity=89.43% avg_auc=88.89%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.140683 Test loss=0.394030 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1378631293773651
[5/24] Train loss=0.1310112178325653
[10/24] Train loss=0.15243318676948547
[15/24] Train loss=0.15083205699920654
[20/24] Train loss=0.14718876779079437
Test set avg_accuracy=83.62% avg_sensitivity=73.55%, avg_specificity=87.43% avg_auc=89.38%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.140851 Test loss=0.388319 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13401655852794647
[5/24] Train loss=0.1303745061159134
[10/24] Train loss=0.15551191568374634
[15/24] Train loss=0.14767099916934967
[20/24] Train loss=0.14521396160125732
Test set avg_accuracy=83.89% avg_sensitivity=70.24%, avg_specificity=89.07% avg_auc=89.02%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.139898 Test loss=0.394298 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1345899999141693
[5/24] Train loss=0.1328675001859665
[10/24] Train loss=0.15687032043933868
[15/24] Train loss=0.14951010048389435
[20/24] Train loss=0.14288191497325897
Test set avg_accuracy=84.26% avg_sensitivity=67.58%, avg_specificity=90.57% avg_auc=88.73%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.139860 Test loss=0.393322 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13585858047008514
[5/24] Train loss=0.12586715817451477
[10/24] Train loss=0.15296503901481628
[15/24] Train loss=0.14742404222488403
[20/24] Train loss=0.141798198223114
Test set avg_accuracy=84.05% avg_sensitivity=71.04%, avg_specificity=88.98% avg_auc=89.24%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.138171 Test loss=0.389426 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1332460194826126
[5/24] Train loss=0.12744030356407166
[10/24] Train loss=0.1490279883146286
[15/24] Train loss=0.14510826766490936
[20/24] Train loss=0.143240287899971
Test set avg_accuracy=83.75% avg_sensitivity=69.67%, avg_specificity=89.08% avg_auc=88.85%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.137205 Test loss=0.395588 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1322367936372757
[5/24] Train loss=0.12734153866767883
[10/24] Train loss=0.1507013887166977
[15/24] Train loss=0.14572730660438538
[20/24] Train loss=0.1401330679655075
Test set avg_accuracy=83.71% avg_sensitivity=70.33%, avg_specificity=88.78% avg_auc=88.94%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.136883 Test loss=0.393400 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1337815672159195
[5/24] Train loss=0.12782810628414154
[10/24] Train loss=0.15054932236671448
[15/24] Train loss=0.14584162831306458
[20/24] Train loss=0.1438296139240265
Test set avg_accuracy=83.82% avg_sensitivity=70.14%, avg_specificity=88.99% avg_auc=88.92%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.136721 Test loss=0.394950 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.13604845106601715
[5/24] Train loss=0.12684059143066406
[10/24] Train loss=0.1495492160320282
[15/24] Train loss=0.14518854022026062
[20/24] Train loss=0.1434195637702942
Test set avg_accuracy=83.97% avg_sensitivity=69.38%, avg_specificity=89.50% avg_auc=88.88%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.136445 Test loss=0.393946 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13139525055885315
[5/24] Train loss=0.12576797604560852
[10/24] Train loss=0.15319126844406128
[15/24] Train loss=0.14683328568935394
[20/24] Train loss=0.14440499246120453
Test set avg_accuracy=84.00% avg_sensitivity=70.43%, avg_specificity=89.14% avg_auc=89.15%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.136380 Test loss=0.390000 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13195201754570007
[5/24] Train loss=0.12844090163707733
[10/24] Train loss=0.1502271294593811
[15/24] Train loss=0.14487619698047638
[20/24] Train loss=0.1449945867061615
Test set avg_accuracy=84.05% avg_sensitivity=70.00%, avg_specificity=89.37% avg_auc=89.03%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.136000 Test loss=0.392359 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.13096289336681366
[5/24] Train loss=0.12741266191005707
[10/24] Train loss=0.15296709537506104
[15/24] Train loss=0.14631043374538422
[20/24] Train loss=0.14653007686138153
Test set avg_accuracy=83.96% avg_sensitivity=69.67%, avg_specificity=89.37% avg_auc=89.06%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.136177 Test loss=0.391832 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1313648521900177
[5/24] Train loss=0.12770695984363556
[10/24] Train loss=0.14349089562892914
[15/24] Train loss=0.1416327804327011
[20/24] Train loss=0.14315165579319
Test set avg_accuracy=84.08% avg_sensitivity=69.29%, avg_specificity=89.68% avg_auc=89.07%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.135434 Test loss=0.391049 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13092981278896332
[5/24] Train loss=0.12686388194561005
[10/24] Train loss=0.1456194669008255
[15/24] Train loss=0.14569750428199768
[20/24] Train loss=0.1414462774991989
Test set avg_accuracy=84.22% avg_sensitivity=70.05%, avg_specificity=89.59% avg_auc=89.09%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.135451 Test loss=0.391481 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13221560418605804
[5/24] Train loss=0.12560635805130005
[10/24] Train loss=0.14795252680778503
[15/24] Train loss=0.14627115428447723
[20/24] Train loss=0.13836969435214996
Test set avg_accuracy=84.26% avg_sensitivity=70.52%, avg_specificity=89.46% avg_auc=89.14%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.135589 Test loss=0.390114 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13361142575740814
[5/24] Train loss=0.1239302009344101
[10/24] Train loss=0.14824120700359344
[15/24] Train loss=0.14420807361602783
[20/24] Train loss=0.13888102769851685
Test set avg_accuracy=84.24% avg_sensitivity=70.05%, avg_specificity=89.62% avg_auc=89.13%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.135332 Test loss=0.390110 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1297234147787094
[5/24] Train loss=0.1249336302280426
[10/24] Train loss=0.1508609503507614
[15/24] Train loss=0.1442466527223587
[20/24] Train loss=0.14256787300109863
Test set avg_accuracy=84.21% avg_sensitivity=70.00%, avg_specificity=89.59% avg_auc=89.12%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.135287 Test loss=0.390638 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1297406405210495
[5/24] Train loss=0.12452436238527298
[10/24] Train loss=0.14585962891578674
[15/24] Train loss=0.144422709941864
[20/24] Train loss=0.13873191177845
Test set avg_accuracy=84.19% avg_sensitivity=70.09%, avg_specificity=89.53% avg_auc=89.12%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.134615 Test loss=0.390547 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13262833654880524
[5/24] Train loss=0.12346436828374863
[10/24] Train loss=0.14629746973514557
[15/24] Train loss=0.1411566436290741
[20/24] Train loss=0.13847500085830688
Test set avg_accuracy=84.24% avg_sensitivity=70.24%, avg_specificity=89.55% avg_auc=89.13%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.134645 Test loss=0.390759 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.13383670151233673
[5/24] Train loss=0.12429691106081009
[10/24] Train loss=0.14783401787281036
[15/24] Train loss=0.14143173396587372
[20/24] Train loss=0.14075559377670288
Test set avg_accuracy=84.22% avg_sensitivity=70.19%, avg_specificity=89.53% avg_auc=89.12%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.134253 Test loss=0.390547 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=83.88% sen=77.77%, spe=86.19%, auc=90.53%!
Fold[3] Avg_overlap=0.63%(±0.2681350533275235)
[0/24] Train loss=0.749021053314209
[5/24] Train loss=0.7441495656967163
[10/24] Train loss=0.7368267178535461
[15/24] Train loss=0.7258560061454773
[20/24] Train loss=0.7142985463142395
Test set avg_accuracy=61.03% avg_sensitivity=52.82%, avg_specificity=63.92% avg_auc=61.01%
Best model saved!! Metric=-87.21563790611407!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.733560 Test loss=0.671318 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7141852378845215
[5/24] Train loss=0.7098469138145447
[10/24] Train loss=0.70374596118927
[15/24] Train loss=0.6885973811149597
[20/24] Train loss=0.6873809695243835
Test set avg_accuracy=67.68% avg_sensitivity=68.82%, avg_specificity=67.28% avg_auc=73.75%
Best model saved!! Metric=-48.46735969184144!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.700087 Test loss=0.612268 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6798298358917236
[5/24] Train loss=0.6822705268859863
[10/24] Train loss=0.6801362633705139
[15/24] Train loss=0.6634147763252258
[20/24] Train loss=0.6600680351257324
Test set avg_accuracy=70.36% avg_sensitivity=75.81%, avg_specificity=68.45% avg_auc=78.26%
Best model saved!! Metric=-33.117955552180774!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.673316 Test loss=0.586252 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6547945141792297
[5/24] Train loss=0.656398594379425
[10/24] Train loss=0.6588513255119324
[15/24] Train loss=0.6379233002662659
[20/24] Train loss=0.6344524621963501
Test set avg_accuracy=72.49% avg_sensitivity=78.26%, avg_specificity=70.45% avg_auc=80.51%
Best model saved!! Metric=-24.28895088204378!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.648580 Test loss=0.564285 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6246550679206848
[5/24] Train loss=0.626837432384491
[10/24] Train loss=0.6387225389480591
[15/24] Train loss=0.6136810183525085
[20/24] Train loss=0.602581799030304
Test set avg_accuracy=74.21% avg_sensitivity=79.86%, avg_specificity=72.21% avg_auc=82.17%
Best model saved!! Metric=-17.548807722310926!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.621724 Test loss=0.544519 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5967113971710205
[5/24] Train loss=0.5932943224906921
[10/24] Train loss=0.6140576004981995
[15/24] Train loss=0.5909451246261597
[20/24] Train loss=0.5808417797088623
Test set avg_accuracy=76.54% avg_sensitivity=79.31%, avg_specificity=75.56% avg_auc=83.43%
Best model saved!! Metric=-11.161443376139445!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.595880 Test loss=0.520352 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5710371136665344
[5/24] Train loss=0.574489951133728
[10/24] Train loss=0.5962970852851868
[15/24] Train loss=0.5675728917121887
[20/24] Train loss=0.5546618700027466
Test set avg_accuracy=78.16% avg_sensitivity=76.06%, avg_specificity=78.90% avg_auc=84.20%
Best model saved!! Metric=-8.668573655949146!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.570708 Test loss=0.497185 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5430306792259216
[5/24] Train loss=0.5426848530769348
[10/24] Train loss=0.5621098875999451
[15/24] Train loss=0.5403531789779663
[20/24] Train loss=0.5331214666366577
Test set avg_accuracy=79.10% avg_sensitivity=76.71%, avg_specificity=79.94% avg_auc=85.51%
Best model saved!! Metric=-4.729466517979148!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.545217 Test loss=0.478669 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5219376683235168
[5/24] Train loss=0.5119055509567261
[10/24] Train loss=0.5374377369880676
[15/24] Train loss=0.509351372718811
[20/24] Train loss=0.5003538131713867
Test set avg_accuracy=80.33% avg_sensitivity=72.91%, avg_specificity=82.94% avg_auc=86.10%
Best model saved!! Metric=-3.7216661736210312!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.519102 Test loss=0.455150 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4896182119846344
[5/24] Train loss=0.4845028221607208
[10/24] Train loss=0.5110712051391602
[15/24] Train loss=0.49134689569473267
[20/24] Train loss=0.47060728073120117
Test set avg_accuracy=81.15% avg_sensitivity=71.81%, avg_specificity=84.43% avg_auc=86.60%
Best model saved!! Metric=-2.0101502174163812!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.494355 Test loss=0.438100 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.47062885761260986
[5/24] Train loss=0.4650248885154724
[10/24] Train loss=0.4877632260322571
[15/24] Train loss=0.4733186364173889
[20/24] Train loss=0.4537924826145172
Test set avg_accuracy=81.89% avg_sensitivity=69.87%, avg_specificity=86.12% avg_auc=87.15%
Best model saved!! Metric=-0.9698946357678295!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.472390 Test loss=0.422010 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4483601152896881
[5/24] Train loss=0.4466409683227539
[10/24] Train loss=0.463487833738327
[15/24] Train loss=0.45148900151252747
[20/24] Train loss=0.42939284443855286
Test set avg_accuracy=82.40% avg_sensitivity=70.91%, avg_specificity=86.44% avg_auc=87.84%
Best model saved!! Metric=1.5869021764430187!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.451563 Test loss=0.409966 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4278005063533783
[5/24] Train loss=0.4183768630027771
[10/24] Train loss=0.45239973068237305
[15/24] Train loss=0.43256205320358276
[20/24] Train loss=0.41308698058128357
Test set avg_accuracy=83.06% avg_sensitivity=66.62%, avg_specificity=88.85% avg_auc=88.04%
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.431885 Test loss=0.392886 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.40960943698883057
[5/24] Train loss=0.4024531841278076
[10/24] Train loss=0.43096333742141724
[15/24] Train loss=0.4150491952896118
[20/24] Train loss=0.39502596855163574
Test set avg_accuracy=83.80% avg_sensitivity=67.12%, avg_specificity=89.68% avg_auc=88.75%
Best model saved!! Metric=3.3454852544893043!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.413915 Test loss=0.381531 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3866586685180664
[5/24] Train loss=0.38610732555389404
[10/24] Train loss=0.41970932483673096
[15/24] Train loss=0.39667975902557373
[20/24] Train loss=0.38285818696022034
Test set avg_accuracy=84.06% avg_sensitivity=68.47%, avg_specificity=89.56% avg_auc=89.34%
Best model saved!! Metric=5.424344698358681!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.398389 Test loss=0.371041 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3742622137069702
[5/24] Train loss=0.3717647194862366
[10/24] Train loss=0.4017375111579895
[15/24] Train loss=0.3837868571281433
[20/24] Train loss=0.3639158308506012
Test set avg_accuracy=84.66% avg_sensitivity=68.92%, avg_specificity=90.21% avg_auc=89.84%
Best model saved!! Metric=7.628777807950655!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.382033 Test loss=0.360429 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3645460903644562
[5/24] Train loss=0.3641078472137451
[10/24] Train loss=0.4003165662288666
[15/24] Train loss=0.37226468324661255
[20/24] Train loss=0.35490551590919495
Test set avg_accuracy=85.00% avg_sensitivity=69.42%, avg_specificity=90.49% avg_auc=90.17%
Best model saved!! Metric=9.079925700118778!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.372106 Test loss=0.354081 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.348283588886261
[5/24] Train loss=0.3523155450820923
[10/24] Train loss=0.38398197293281555
[15/24] Train loss=0.36704814434051514
[20/24] Train loss=0.34791693091392517
Test set avg_accuracy=85.25% avg_sensitivity=72.61%, avg_specificity=89.70% avg_auc=90.69%
Best model saved!! Metric=12.252536158046823!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.361660 Test loss=0.349420 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3350470960140228
[5/24] Train loss=0.3418126106262207
[10/24] Train loss=0.371433287858963
[15/24] Train loss=0.3573679029941559
[20/24] Train loss=0.33698204159736633
Test set avg_accuracy=85.29% avg_sensitivity=72.76%, avg_specificity=89.70% avg_auc=90.80%
Best model saved!! Metric=12.551914881340352!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.350099 Test loss=0.344636 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3244205713272095
[5/24] Train loss=0.3294614851474762
[10/24] Train loss=0.3663583993911743
[15/24] Train loss=0.3518027365207672
[20/24] Train loss=0.3327118158340454
Test set avg_accuracy=85.69% avg_sensitivity=69.82%, avg_specificity=91.28% avg_auc=91.01%
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.342522 Test loss=0.332410 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3214905858039856
[5/24] Train loss=0.32822728157043457
[10/24] Train loss=0.36098361015319824
[15/24] Train loss=0.34450045228004456
[20/24] Train loss=0.3236803114414215
Test set avg_accuracy=85.98% avg_sensitivity=68.67%, avg_specificity=92.08% avg_auc=91.01%
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.334771 Test loss=0.333157 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3113804757595062
[5/24] Train loss=0.3186682164669037
[10/24] Train loss=0.34818148612976074
[15/24] Train loss=0.33399614691734314
[20/24] Train loss=0.3134060800075531
Test set avg_accuracy=85.23% avg_sensitivity=59.52%, avg_specificity=94.29% avg_auc=90.47%
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.325616 Test loss=0.338368 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.30259472131729126
[5/24] Train loss=0.3160836100578308
[10/24] Train loss=0.33906498551368713
[15/24] Train loss=0.32778188586235046
[20/24] Train loss=0.30594688653945923
Test set avg_accuracy=84.66% avg_sensitivity=56.27%, avg_specificity=94.66% avg_auc=89.78%
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.318858 Test loss=0.349824 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.31270214915275574
[5/24] Train loss=0.31294363737106323
[10/24] Train loss=0.32892894744873047
[15/24] Train loss=0.32974424958229065
[20/24] Train loss=0.3038863241672516
Test set avg_accuracy=85.64% avg_sensitivity=63.87%, avg_specificity=93.31% avg_auc=90.64%
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.315061 Test loss=0.332748 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2910759747028351
[5/24] Train loss=0.3058550953865051
[10/24] Train loss=0.32366254925727844
[15/24] Train loss=0.3258326053619385
[20/24] Train loss=0.29762694239616394
Test set avg_accuracy=84.56% avg_sensitivity=51.52%, avg_specificity=96.20% avg_auc=89.40%
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.307639 Test loss=0.363665 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2863234877586365
[5/24] Train loss=0.2958575487136841
[10/24] Train loss=0.31854167580604553
[15/24] Train loss=0.3155803978443146
[20/24] Train loss=0.2927238643169403
Test set avg_accuracy=84.27% avg_sensitivity=50.02%, avg_specificity=96.34% avg_auc=88.75%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.300636 Test loss=0.377186 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2780817747116089
[5/24] Train loss=0.2843477725982666
[10/24] Train loss=0.3198220133781433
[15/24] Train loss=0.3076014220714569
[20/24] Train loss=0.28411805629730225
Test set avg_accuracy=83.46% avg_sensitivity=47.93%, avg_specificity=95.99% avg_auc=88.10%
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.294940 Test loss=0.383669 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2782714366912842
[5/24] Train loss=0.2911578118801117
[10/24] Train loss=0.3133408725261688
[15/24] Train loss=0.29314348101615906
[20/24] Train loss=0.2874951660633087
Test set avg_accuracy=84.17% avg_sensitivity=49.38%, avg_specificity=96.43% avg_auc=88.01%
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.290501 Test loss=0.383467 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2645241916179657
[5/24] Train loss=0.2812250554561615
[10/24] Train loss=0.30563852190971375
[15/24] Train loss=0.28884464502334595
[20/24] Train loss=0.27912816405296326
Test set avg_accuracy=80.18% avg_sensitivity=27.84%, avg_specificity=98.63% avg_auc=83.17%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.283259 Test loss=0.475066 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.264855295419693
[5/24] Train loss=0.2706444263458252
[10/24] Train loss=0.31382688879966736
[15/24] Train loss=0.2811073958873749
[20/24] Train loss=0.2707826793193817
Test set avg_accuracy=77.72% avg_sensitivity=16.44%, avg_specificity=99.31% avg_auc=79.07%
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.276395 Test loss=0.575323 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2549605667591095
[5/24] Train loss=0.2637561857700348
[10/24] Train loss=0.2980909049510956
[15/24] Train loss=0.2770097553730011
[20/24] Train loss=0.2758439779281616
Test set avg_accuracy=82.25% avg_sensitivity=41.78%, avg_specificity=96.51% avg_auc=84.78%
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.271544 Test loss=0.452623 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.25513535737991333
[5/24] Train loss=0.24380911886692047
[10/24] Train loss=0.29050078988075256
[15/24] Train loss=0.2722800374031067
[20/24] Train loss=0.27225637435913086
Test set avg_accuracy=82.50% avg_sensitivity=42.83%, avg_specificity=96.48% avg_auc=84.07%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.264738 Test loss=0.458614 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.24920907616615295
[5/24] Train loss=0.24456408619880676
[10/24] Train loss=0.2982669174671173
[15/24] Train loss=0.28162068128585815
[20/24] Train loss=0.26506197452545166
Test set avg_accuracy=79.28% avg_sensitivity=25.64%, avg_specificity=98.19% avg_auc=80.15%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.264649 Test loss=0.524159 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2616375982761383
[5/24] Train loss=0.2411946803331375
[10/24] Train loss=0.3084598183631897
[15/24] Train loss=0.2761915326118469
[20/24] Train loss=0.256963849067688
Test set avg_accuracy=84.47% avg_sensitivity=56.07%, avg_specificity=94.47% avg_auc=88.85%
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.262979 Test loss=0.362691 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.23616287112236023
[5/24] Train loss=0.2620798349380493
[10/24] Train loss=0.30493953824043274
[15/24] Train loss=0.27670446038246155
[20/24] Train loss=0.26178109645843506
Test set avg_accuracy=83.42% avg_sensitivity=46.88%, avg_specificity=96.30% avg_auc=86.44%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.258810 Test loss=0.405609 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.24987520277500153
[5/24] Train loss=0.2395162135362625
[10/24] Train loss=0.28043875098228455
[15/24] Train loss=0.26471731066703796
[20/24] Train loss=0.25445544719696045
Test set avg_accuracy=80.51% avg_sensitivity=31.78%, avg_specificity=97.68% avg_auc=80.95%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.251888 Test loss=0.513044 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2533824145793915
[5/24] Train loss=0.23506906628608704
[10/24] Train loss=0.30251339077949524
[15/24] Train loss=0.27274757623672485
[20/24] Train loss=0.25361573696136475
Test set avg_accuracy=76.00% avg_sensitivity=8.80%, avg_specificity=99.68% avg_auc=72.40%
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.254418 Test loss=0.704436 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2382536381483078
[5/24] Train loss=0.24167636036872864
[10/24] Train loss=0.2774454653263092
[15/24] Train loss=0.2655738592147827
[20/24] Train loss=0.24908889830112457
Test set avg_accuracy=75.72% avg_sensitivity=7.35%, avg_specificity=99.81% avg_auc=78.76%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.250200 Test loss=0.675636 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.22503486275672913
[5/24] Train loss=0.25475022196769714
[10/24] Train loss=0.27857667207717896
[15/24] Train loss=0.2674511671066284
[20/24] Train loss=0.2626365125179291
Test set avg_accuracy=81.82% avg_sensitivity=37.78%, avg_specificity=97.34% avg_auc=83.38%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.254921 Test loss=0.462806 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.23443874716758728
[5/24] Train loss=0.22226697206497192
[10/24] Train loss=0.2653295397758484
[15/24] Train loss=0.23789682984352112
[20/24] Train loss=0.23837825655937195
Test set avg_accuracy=80.48% avg_sensitivity=34.83%, avg_specificity=96.57% avg_auc=81.11%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.241126 Test loss=0.570089 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.235920712351799
[5/24] Train loss=0.2170877754688263
[10/24] Train loss=0.26745161414146423
[15/24] Train loss=0.24824918806552887
[20/24] Train loss=0.2580840289592743
Test set avg_accuracy=82.28% avg_sensitivity=41.98%, avg_specificity=96.48% avg_auc=83.92%
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.241228 Test loss=0.448976 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2310503125190735
[5/24] Train loss=0.21577370166778564
[10/24] Train loss=0.2573568522930145
[15/24] Train loss=0.23572193086147308
[20/24] Train loss=0.24124497175216675
Test set avg_accuracy=83.84% avg_sensitivity=53.52%, avg_specificity=94.52% avg_auc=87.62%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.237371 Test loss=0.380684 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2359992116689682
[5/24] Train loss=0.21336328983306885
[10/24] Train loss=0.26815709471702576
[15/24] Train loss=0.23943841457366943
[20/24] Train loss=0.2375948131084442
Test set avg_accuracy=82.33% avg_sensitivity=39.98%, avg_specificity=97.25% avg_auc=86.03%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.235785 Test loss=0.445965 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.22117950022220612
[5/24] Train loss=0.21825413405895233
[10/24] Train loss=0.2747329771518707
[15/24] Train loss=0.23974855244159698
[20/24] Train loss=0.24562953412532806
Test set avg_accuracy=80.92% avg_sensitivity=32.78%, avg_specificity=97.89% avg_auc=85.43%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.239364 Test loss=0.468894 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2104693502187729
[5/24] Train loss=0.23955947160720825
[10/24] Train loss=0.2684037387371063
[15/24] Train loss=0.235129714012146
[20/24] Train loss=0.24499279260635376
Test set avg_accuracy=78.11% avg_sensitivity=22.69%, avg_specificity=97.64% avg_auc=76.29%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.233683 Test loss=0.626197 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.22474883496761322
[5/24] Train loss=0.20328901708126068
[10/24] Train loss=0.27210181951522827
[15/24] Train loss=0.2415880262851715
[20/24] Train loss=0.23718562722206116
Test set avg_accuracy=79.32% avg_sensitivity=23.59%, avg_specificity=98.96% avg_auc=82.02%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.230923 Test loss=0.547164 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.22192241251468658
[5/24] Train loss=0.20897537469863892
[10/24] Train loss=0.24806106090545654
[15/24] Train loss=0.23532140254974365
[20/24] Train loss=0.2281116545200348
Test set avg_accuracy=79.01% avg_sensitivity=22.94%, avg_specificity=98.77% avg_auc=80.08%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.228450 Test loss=0.550013 Current lr=[0.000299720220882401]

[0/24] Train loss=0.22482654452323914
[5/24] Train loss=0.19598807394504547
[10/24] Train loss=0.2562260329723358
[15/24] Train loss=0.2356104999780655
[20/24] Train loss=0.24482178688049316
Test set avg_accuracy=77.06% avg_sensitivity=14.24%, avg_specificity=99.19% avg_auc=78.10%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.227645 Test loss=0.630690 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.20825448632240295
[5/24] Train loss=0.2133329212665558
[10/24] Train loss=0.23945365846157074
[15/24] Train loss=0.23700357973575592
[20/24] Train loss=0.22008833289146423
Test set avg_accuracy=78.10% avg_sensitivity=20.84%, avg_specificity=98.27% avg_auc=77.80%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.224249 Test loss=0.591526 Current lr=[0.000298904600941902]

[0/24] Train loss=0.22631120681762695
[5/24] Train loss=0.20566681027412415
[10/24] Train loss=0.24322758615016937
[15/24] Train loss=0.24264203011989594
[20/24] Train loss=0.23464913666248322
Test set avg_accuracy=75.00% avg_sensitivity=4.55%, avg_specificity=99.82% avg_auc=69.60%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.226347 Test loss=0.716528 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.21769601106643677
[5/24] Train loss=0.21837875247001648
[10/24] Train loss=0.255331814289093
[15/24] Train loss=0.23232796788215637
[20/24] Train loss=0.22317568957805634
Test set avg_accuracy=83.49% avg_sensitivity=46.68%, avg_specificity=96.46% avg_auc=85.78%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.227090 Test loss=0.451765 Current lr=[0.000297555943323901]

[0/24] Train loss=0.21808649599552155
[5/24] Train loss=0.213850736618042
[10/24] Train loss=0.24999698996543884
[15/24] Train loss=0.23614293336868286
[20/24] Train loss=0.22545622289180756
Test set avg_accuracy=85.31% avg_sensitivity=66.32%, avg_specificity=92.01% avg_auc=89.92%
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.226618 Test loss=0.347915 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.21704137325286865
[5/24] Train loss=0.2041761577129364
[10/24] Train loss=0.26688119769096375
[15/24] Train loss=0.23565351963043213
[20/24] Train loss=0.22721923887729645
Test set avg_accuracy=80.65% avg_sensitivity=32.53%, avg_specificity=97.61% avg_auc=82.63%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.228924 Test loss=0.546777 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.20945312082767487
[5/24] Train loss=0.20481961965560913
[10/24] Train loss=0.24615100026130676
[15/24] Train loss=0.21541443467140198
[20/24] Train loss=0.2264786660671234
Test set avg_accuracy=85.20% avg_sensitivity=66.82%, avg_specificity=91.67% avg_auc=88.98%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.219262 Test loss=0.360458 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.20932769775390625
[5/24] Train loss=0.20022138953208923
[10/24] Train loss=0.23635391891002655
[15/24] Train loss=0.2275151014328003
[20/24] Train loss=0.23731836676597595
Test set avg_accuracy=83.82% avg_sensitivity=47.88%, avg_specificity=96.48% avg_auc=87.16%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.217877 Test loss=0.421741 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.20230327546596527
[5/24] Train loss=0.19878125190734863
[10/24] Train loss=0.2373969852924347
[15/24] Train loss=0.22545012831687927
[20/24] Train loss=0.22295857965946198
Test set avg_accuracy=84.40% avg_sensitivity=65.52%, avg_specificity=91.05% avg_auc=88.43%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.216312 Test loss=0.367042 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.21306797862052917
[5/24] Train loss=0.20292061567306519
[10/24] Train loss=0.2432328313589096
[15/24] Train loss=0.22435402870178223
[20/24] Train loss=0.21641643345355988
Test set avg_accuracy=83.18% avg_sensitivity=44.38%, avg_specificity=96.85% avg_auc=85.22%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.215756 Test loss=0.454565 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.20352940261363983
[5/24] Train loss=0.19314752519130707
[10/24] Train loss=0.23959840834140778
[15/24] Train loss=0.21805280447006226
[20/24] Train loss=0.210219144821167
Test set avg_accuracy=85.47% avg_sensitivity=60.47%, avg_specificity=94.28% avg_auc=87.71%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.211901 Test loss=0.385987 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.20023107528686523
[5/24] Train loss=0.1822470873594284
[10/24] Train loss=0.24768279492855072
[15/24] Train loss=0.224274680018425
[20/24] Train loss=0.22049549221992493
Test set avg_accuracy=84.15% avg_sensitivity=65.42%, avg_specificity=90.76% avg_auc=88.20%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.211486 Test loss=0.384049 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.20794205367565155
[5/24] Train loss=0.2015901803970337
[10/24] Train loss=0.24034558236598969
[15/24] Train loss=0.20616446435451508
[20/24] Train loss=0.20892907679080963
Test set avg_accuracy=79.79% avg_sensitivity=27.74%, avg_specificity=98.13% avg_auc=83.30%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.208787 Test loss=0.527922 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.20966124534606934
[5/24] Train loss=0.17498299479484558
[10/24] Train loss=0.2428404688835144
[15/24] Train loss=0.23375557363033295
[20/24] Train loss=0.22966714203357697
Test set avg_accuracy=84.65% avg_sensitivity=63.52%, avg_specificity=92.09% avg_auc=87.58%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.209798 Test loss=0.385553 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.21036359667778015
[5/24] Train loss=0.1834850162267685
[10/24] Train loss=0.22830452024936676
[15/24] Train loss=0.21298131346702576
[20/24] Train loss=0.20444108545780182
Test set avg_accuracy=84.82% avg_sensitivity=70.31%, avg_specificity=89.93% avg_auc=89.39%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.205543 Test loss=0.357808 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.201386496424675
[5/24] Train loss=0.17918701469898224
[10/24] Train loss=0.23773226141929626
[15/24] Train loss=0.21111701428890228
[20/24] Train loss=0.2130434811115265
Test set avg_accuracy=80.30% avg_sensitivity=32.28%, avg_specificity=97.22% avg_auc=82.43%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.203359 Test loss=0.529503 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.1900118589401245
[5/24] Train loss=0.19264714419841766
[10/24] Train loss=0.23240546882152557
[15/24] Train loss=0.20964430272579193
[20/24] Train loss=0.2325277477502823
Test set avg_accuracy=84.66% avg_sensitivity=64.32%, avg_specificity=91.83% avg_auc=88.16%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.205744 Test loss=0.374476 Current lr=[0.000276307469034998]

[0/24] Train loss=0.19456015527248383
[5/24] Train loss=0.1903439313173294
[10/24] Train loss=0.23418296873569489
[15/24] Train loss=0.2136572301387787
[20/24] Train loss=0.21573202311992645
Test set avg_accuracy=85.23% avg_sensitivity=65.52%, avg_specificity=92.18% avg_auc=89.20%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.202938 Test loss=0.356134 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.19224558770656586
[5/24] Train loss=0.18644219636917114
[10/24] Train loss=0.24426554143428802
[15/24] Train loss=0.2305365949869156
[20/24] Train loss=0.21092665195465088
Test set avg_accuracy=84.62% avg_sensitivity=60.62%, avg_specificity=93.08% avg_auc=87.18%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.204727 Test loss=0.390700 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.19973783195018768
[5/24] Train loss=0.16885872185230255
[10/24] Train loss=0.22651396691799164
[15/24] Train loss=0.22030863165855408
[20/24] Train loss=0.20458298921585083
Test set avg_accuracy=84.62% avg_sensitivity=62.82%, avg_specificity=92.30% avg_auc=87.83%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.202625 Test loss=0.388065 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.20246560871601105
[5/24] Train loss=0.17973944544792175
[10/24] Train loss=0.21738021075725555
[15/24] Train loss=0.21284958720207214
[20/24] Train loss=0.2044748067855835
Test set avg_accuracy=81.63% avg_sensitivity=41.38%, avg_specificity=95.81% avg_auc=83.39%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.200607 Test loss=0.466371 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.18080496788024902
[5/24] Train loss=0.17321670055389404
[10/24] Train loss=0.22786618769168854
[15/24] Train loss=0.21412526071071625
[20/24] Train loss=0.20401491224765778
Test set avg_accuracy=83.03% avg_sensitivity=50.02%, avg_specificity=94.66% avg_auc=85.91%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.200864 Test loss=0.431038 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.19857457280158997
[5/24] Train loss=0.16914460062980652
[10/24] Train loss=0.2252189666032791
[15/24] Train loss=0.2109985500574112
[20/24] Train loss=0.21181713044643402
Test set avg_accuracy=84.40% avg_sensitivity=64.97%, avg_specificity=91.25% avg_auc=88.43%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.199021 Test loss=0.373694 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.19419002532958984
[5/24] Train loss=0.17497718334197998
[10/24] Train loss=0.24587960541248322
[15/24] Train loss=0.20053531229496002
[20/24] Train loss=0.20769932866096497
Test set avg_accuracy=83.39% avg_sensitivity=54.92%, avg_specificity=93.41% avg_auc=84.79%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.199552 Test loss=0.442692 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.18776772916316986
[5/24] Train loss=0.16532374918460846
[10/24] Train loss=0.22093477845191956
[15/24] Train loss=0.2042379081249237
[20/24] Train loss=0.2019575536251068
Test set avg_accuracy=84.64% avg_sensitivity=55.72%, avg_specificity=94.82% avg_auc=87.05%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.196620 Test loss=0.402802 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.18426458537578583
[5/24] Train loss=0.1691429615020752
[10/24] Train loss=0.20950967073440552
[15/24] Train loss=0.2183760106563568
[20/24] Train loss=0.2015330046415329
Test set avg_accuracy=82.47% avg_sensitivity=45.38%, avg_specificity=95.54% avg_auc=82.85%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.195698 Test loss=0.467914 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.18648679554462433
[5/24] Train loss=0.17033880949020386
[10/24] Train loss=0.22244231402873993
[15/24] Train loss=0.20104169845581055
[20/24] Train loss=0.20470254123210907
Test set avg_accuracy=84.08% avg_sensitivity=60.87%, avg_specificity=92.25% avg_auc=87.77%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.194524 Test loss=0.378779 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.19357186555862427
[5/24] Train loss=0.17045927047729492
[10/24] Train loss=0.21545174717903137
[15/24] Train loss=0.20782402157783508
[20/24] Train loss=0.2021094262599945
Test set avg_accuracy=84.13% avg_sensitivity=64.67%, avg_specificity=90.98% avg_auc=87.27%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.193519 Test loss=0.386148 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.19763082265853882
[5/24] Train loss=0.17296817898750305
[10/24] Train loss=0.2288416624069214
[15/24] Train loss=0.19412794709205627
[20/24] Train loss=0.19839417934417725
Test set avg_accuracy=84.74% avg_sensitivity=64.77%, avg_specificity=91.78% avg_auc=87.69%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.191700 Test loss=0.380762 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.1860998272895813
[5/24] Train loss=0.17166239023208618
[10/24] Train loss=0.21300244331359863
[15/24] Train loss=0.21362823247909546
[20/24] Train loss=0.1867070198059082
Test set avg_accuracy=85.05% avg_sensitivity=70.66%, avg_specificity=90.12% avg_auc=89.05%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.190660 Test loss=0.374842 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.18005099892616272
[5/24] Train loss=0.16373403370380402
[10/24] Train loss=0.22400832176208496
[15/24] Train loss=0.2018577754497528
[20/24] Train loss=0.18964117765426636
Test set avg_accuracy=79.04% avg_sensitivity=28.49%, avg_specificity=96.85% avg_auc=80.76%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.190107 Test loss=0.540346 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.18973508477210999
[5/24] Train loss=0.1642766147851944
[10/24] Train loss=0.20121686160564423
[15/24] Train loss=0.19734367728233337
[20/24] Train loss=0.18435479700565338
Test set avg_accuracy=85.51% avg_sensitivity=61.77%, avg_specificity=93.87% avg_auc=88.81%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.186646 Test loss=0.356956 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.1813449114561081
[5/24] Train loss=0.1709974855184555
[10/24] Train loss=0.21459877490997314
[15/24] Train loss=0.19808506965637207
[20/24] Train loss=0.1888515204191208
Test set avg_accuracy=81.60% avg_sensitivity=44.98%, avg_specificity=94.51% avg_auc=81.50%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.186947 Test loss=0.484835 Current lr=[0.000224838296036774]

[0/24] Train loss=0.18233121931552887
[5/24] Train loss=0.16586793959140778
[10/24] Train loss=0.19929155707359314
[15/24] Train loss=0.19939617812633514
[20/24] Train loss=0.18362414836883545
Test set avg_accuracy=83.31% avg_sensitivity=71.86%, avg_specificity=87.34% avg_auc=88.15%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.186331 Test loss=0.389894 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.18354669213294983
[5/24] Train loss=0.15582618117332458
[10/24] Train loss=0.20287083089351654
[15/24] Train loss=0.1825600415468216
[20/24] Train loss=0.1959594041109085
Test set avg_accuracy=81.35% avg_sensitivity=78.16%, avg_specificity=82.48% avg_auc=87.85%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.184068 Test loss=0.433821 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.18324004113674164
[5/24] Train loss=0.15747162699699402
[10/24] Train loss=0.1973562091588974
[15/24] Train loss=0.19118638336658478
[20/24] Train loss=0.17944756150245667
Test set avg_accuracy=84.60% avg_sensitivity=80.26%, avg_specificity=86.12% avg_auc=89.84%
Best model saved!! Metric=14.817935223294555!!
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.182536 Test loss=0.369395 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.17745375633239746
[5/24] Train loss=0.16091781854629517
[10/24] Train loss=0.20973050594329834
[15/24] Train loss=0.18331193923950195
[20/24] Train loss=0.18311689794063568
Test set avg_accuracy=84.19% avg_sensitivity=66.22%, avg_specificity=90.53% avg_auc=87.07%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.183572 Test loss=0.385855 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.18276919424533844
[5/24] Train loss=0.16992101073265076
[10/24] Train loss=0.22271881997585297
[15/24] Train loss=0.19281747937202454
[20/24] Train loss=0.18170589208602905
Test set avg_accuracy=83.45% avg_sensitivity=63.32%, avg_specificity=90.54% avg_auc=86.64%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.183016 Test loss=0.396334 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.17638540267944336
[5/24] Train loss=0.1665797233581543
[10/24] Train loss=0.21374833583831787
[15/24] Train loss=0.19317249953746796
[20/24] Train loss=0.18197064101696014
Test set avg_accuracy=85.26% avg_sensitivity=68.77%, avg_specificity=91.07% avg_auc=87.50%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.184193 Test loss=0.381581 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.17445975542068481
[5/24] Train loss=0.1577584147453308
[10/24] Train loss=0.20014944672584534
[15/24] Train loss=0.19215524196624756
[20/24] Train loss=0.19063575565814972
Test set avg_accuracy=84.18% avg_sensitivity=71.81%, avg_specificity=88.54% avg_auc=88.57%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.179954 Test loss=0.377123 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.16912449896335602
[5/24] Train loss=0.16112563014030457
[10/24] Train loss=0.1968887895345688
[15/24] Train loss=0.18192975223064423
[20/24] Train loss=0.1856105923652649
Test set avg_accuracy=84.64% avg_sensitivity=73.31%, avg_specificity=88.62% avg_auc=89.51%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.179018 Test loss=0.358799 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.185620978474617
[5/24] Train loss=0.16119816899299622
[10/24] Train loss=0.20835334062576294
[15/24] Train loss=0.1844089925289154
[20/24] Train loss=0.1866948902606964
Test set avg_accuracy=84.05% avg_sensitivity=73.16%, avg_specificity=87.89% avg_auc=88.92%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.180424 Test loss=0.378987 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.17893341183662415
[5/24] Train loss=0.16353736817836761
[10/24] Train loss=0.2055378407239914
[15/24] Train loss=0.18614381551742554
[20/24] Train loss=0.18176418542861938
Test set avg_accuracy=82.45% avg_sensitivity=74.51%, avg_specificity=85.24% avg_auc=88.67%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.178270 Test loss=0.396287 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1750248670578003
[5/24] Train loss=0.14945922791957855
[10/24] Train loss=0.1967105120420456
[15/24] Train loss=0.17171578109264374
[20/24] Train loss=0.1809789389371872
Test set avg_accuracy=84.40% avg_sensitivity=64.07%, avg_specificity=91.57% avg_auc=88.21%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.176279 Test loss=0.374914 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.1787429302930832
[5/24] Train loss=0.16260507702827454
[10/24] Train loss=0.19695012271404266
[15/24] Train loss=0.18620313704013824
[20/24] Train loss=0.17876355350017548
Test set avg_accuracy=83.10% avg_sensitivity=73.16%, avg_specificity=86.60% avg_auc=87.52%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.174980 Test loss=0.400295 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1688971221446991
[5/24] Train loss=0.15545186400413513
[10/24] Train loss=0.19750942289829254
[15/24] Train loss=0.17917734384536743
[20/24] Train loss=0.17396196722984314
Test set avg_accuracy=84.36% avg_sensitivity=60.27%, avg_specificity=92.85% avg_auc=85.51%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.174105 Test loss=0.413523 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.1666206270456314
[5/24] Train loss=0.14881780743598938
[10/24] Train loss=0.18024498224258423
[15/24] Train loss=0.1854875087738037
[20/24] Train loss=0.18466006219387054
Test set avg_accuracy=85.46% avg_sensitivity=70.36%, avg_specificity=90.77% avg_auc=89.06%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.173353 Test loss=0.359434 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1758839339017868
[5/24] Train loss=0.14553885161876678
[10/24] Train loss=0.1943260282278061
[15/24] Train loss=0.1680523008108139
[20/24] Train loss=0.16945557296276093
Test set avg_accuracy=82.37% avg_sensitivity=73.41%, avg_specificity=85.53% avg_auc=87.74%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.169773 Test loss=0.398437 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.16260221600532532
[5/24] Train loss=0.15304502844810486
[10/24] Train loss=0.19436925649642944
[15/24] Train loss=0.18847686052322388
[20/24] Train loss=0.1729384958744049
Test set avg_accuracy=82.93% avg_sensitivity=63.92%, avg_specificity=89.63% avg_auc=85.85%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.172173 Test loss=0.405137 Current lr=[0.000156543481933168]

[0/24] Train loss=0.15715165436267853
[5/24] Train loss=0.14917822182178497
[10/24] Train loss=0.1831739842891693
[15/24] Train loss=0.16634292900562286
[20/24] Train loss=0.1751512587070465
Test set avg_accuracy=84.23% avg_sensitivity=78.31%, avg_specificity=86.32% avg_auc=89.44%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.166450 Test loss=0.380509 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.16376671195030212
[5/24] Train loss=0.1427857130765915
[10/24] Train loss=0.18663109838962555
[15/24] Train loss=0.17008620500564575
[20/24] Train loss=0.17769309878349304
Test set avg_accuracy=83.68% avg_sensitivity=65.77%, avg_specificity=90.00% avg_auc=85.46%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.167189 Test loss=0.413061 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.16124480962753296
[5/24] Train loss=0.1458195447921753
[10/24] Train loss=0.18743057548999786
[15/24] Train loss=0.17031069099903107
[20/24] Train loss=0.17657305300235748
Test set avg_accuracy=80.60% avg_sensitivity=81.56%, avg_specificity=80.26% avg_auc=88.32%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.165882 Test loss=0.433096 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15486688911914825
[5/24] Train loss=0.148236945271492
[10/24] Train loss=0.19307909905910492
[15/24] Train loss=0.18638354539871216
[20/24] Train loss=0.1764490306377411
Test set avg_accuracy=83.32% avg_sensitivity=78.61%, avg_specificity=84.98% avg_auc=88.89%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.169208 Test loss=0.394046 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15371352434158325
[5/24] Train loss=0.15156546235084534
[10/24] Train loss=0.18230761587619781
[15/24] Train loss=0.17223091423511505
[20/24] Train loss=0.17241127789020538
Test set avg_accuracy=84.14% avg_sensitivity=65.22%, avg_specificity=90.81% avg_auc=88.13%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.165812 Test loss=0.381601 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16147534549236298
[5/24] Train loss=0.1531304121017456
[10/24] Train loss=0.18118467926979065
[15/24] Train loss=0.16503740847110748
[20/24] Train loss=0.16718223690986633
Test set avg_accuracy=84.71% avg_sensitivity=68.32%, avg_specificity=90.49% avg_auc=87.69%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.163172 Test loss=0.393200 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15525846183300018
[5/24] Train loss=0.14351437985897064
[10/24] Train loss=0.16902019083499908
[15/24] Train loss=0.16408506035804749
[20/24] Train loss=0.17276687920093536
Test set avg_accuracy=84.61% avg_sensitivity=68.37%, avg_specificity=90.33% avg_auc=87.06%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.160861 Test loss=0.397183 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.15609252452850342
[5/24] Train loss=0.1418345868587494
[10/24] Train loss=0.18193574249744415
[15/24] Train loss=0.16507191956043243
[20/24] Train loss=0.1716645359992981
Test set avg_accuracy=84.90% avg_sensitivity=70.81%, avg_specificity=89.86% avg_auc=87.84%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.161630 Test loss=0.381784 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.1535632163286209
[5/24] Train loss=0.14385446906089783
[10/24] Train loss=0.16650547087192535
[15/24] Train loss=0.174993097782135
[20/24] Train loss=0.15833038091659546
Test set avg_accuracy=83.07% avg_sensitivity=54.82%, avg_specificity=93.03% avg_auc=84.46%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.159461 Test loss=0.443302 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1509421467781067
[5/24] Train loss=0.1398470252752304
[10/24] Train loss=0.1603885442018509
[15/24] Train loss=0.17564497888088226
[20/24] Train loss=0.15602616965770721
Test set avg_accuracy=84.11% avg_sensitivity=56.62%, avg_specificity=93.80% avg_auc=84.00%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.158695 Test loss=0.436695 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15836378931999207
[5/24] Train loss=0.13235530257225037
[10/24] Train loss=0.1630489081144333
[15/24] Train loss=0.16464591026306152
[20/24] Train loss=0.16035160422325134
Test set avg_accuracy=84.21% avg_sensitivity=75.71%, avg_specificity=87.20% avg_auc=88.46%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.156106 Test loss=0.388532 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15456193685531616
[5/24] Train loss=0.13562822341918945
[10/24] Train loss=0.16549979150295258
[15/24] Train loss=0.15933579206466675
[20/24] Train loss=0.1601475030183792
Test set avg_accuracy=84.69% avg_sensitivity=73.46%, avg_specificity=88.64% avg_auc=88.15%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.154823 Test loss=0.385566 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15220263600349426
[5/24] Train loss=0.13387541472911835
[10/24] Train loss=0.16456103324890137
[15/24] Train loss=0.1618383824825287
[20/24] Train loss=0.16384439170360565
Test set avg_accuracy=85.00% avg_sensitivity=67.77%, avg_specificity=91.07% avg_auc=87.37%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.153576 Test loss=0.395896 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14769186079502106
[5/24] Train loss=0.1313553750514984
[10/24] Train loss=0.1584852635860443
[15/24] Train loss=0.16534759104251862
[20/24] Train loss=0.1557791829109192
Test set avg_accuracy=84.92% avg_sensitivity=65.17%, avg_specificity=91.88% avg_auc=87.01%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.151413 Test loss=0.391787 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14681467413902283
[5/24] Train loss=0.1431449055671692
[10/24] Train loss=0.16286277770996094
[15/24] Train loss=0.15676824748516083
[20/24] Train loss=0.15488295257091522
Test set avg_accuracy=85.08% avg_sensitivity=70.36%, avg_specificity=90.26% avg_auc=88.81%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.151934 Test loss=0.373000 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.14906136691570282
[5/24] Train loss=0.1319447010755539
[10/24] Train loss=0.15887311100959778
[15/24] Train loss=0.15448547899723053
[20/24] Train loss=0.15278743207454681
Test set avg_accuracy=85.07% avg_sensitivity=68.17%, avg_specificity=91.02% avg_auc=87.23%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.150153 Test loss=0.390805 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1447032392024994
[5/24] Train loss=0.13492043316364288
[10/24] Train loss=0.15693192183971405
[15/24] Train loss=0.1544084995985031
[20/24] Train loss=0.15228542685508728
Test set avg_accuracy=84.22% avg_sensitivity=72.11%, avg_specificity=88.48% avg_auc=87.63%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.149634 Test loss=0.394266 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14086775481700897
[5/24] Train loss=0.13173407316207886
[10/24] Train loss=0.16227465867996216
[15/24] Train loss=0.1534411460161209
[20/24] Train loss=0.15319138765335083
Test set avg_accuracy=85.49% avg_sensitivity=70.51%, avg_specificity=90.77% avg_auc=88.64%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.147423 Test loss=0.369143 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1390361487865448
[5/24] Train loss=0.13370442390441895
[10/24] Train loss=0.1492457091808319
[15/24] Train loss=0.15110595524311066
[20/24] Train loss=0.1566246747970581
Test set avg_accuracy=83.96% avg_sensitivity=72.91%, avg_specificity=87.85% avg_auc=87.90%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.146119 Test loss=0.391746 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.143649160861969
[5/24] Train loss=0.13571734726428986
[10/24] Train loss=0.15376253426074982
[15/24] Train loss=0.1529950052499771
[20/24] Train loss=0.15631921589374542
Test set avg_accuracy=85.03% avg_sensitivity=73.76%, avg_specificity=88.99% avg_auc=89.13%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.147629 Test loss=0.375056 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14906731247901917
[5/24] Train loss=0.1278674155473709
[10/24] Train loss=0.15010850131511688
[15/24] Train loss=0.15370045602321625
[20/24] Train loss=0.14966528117656708
Test set avg_accuracy=85.52% avg_sensitivity=72.31%, avg_specificity=90.17% avg_auc=89.58%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.147599 Test loss=0.362595 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1404319852590561
[5/24] Train loss=0.12676522135734558
[10/24] Train loss=0.15731723606586456
[15/24] Train loss=0.1538463681936264
[20/24] Train loss=0.15481412410736084
Test set avg_accuracy=83.26% avg_sensitivity=79.31%, avg_specificity=84.65% avg_auc=88.66%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.145360 Test loss=0.412510 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13849489390850067
[5/24] Train loss=0.12671108543872833
[10/24] Train loss=0.14988642930984497
[15/24] Train loss=0.15110071003437042
[20/24] Train loss=0.15082862973213196
Test set avg_accuracy=85.38% avg_sensitivity=75.81%, avg_specificity=88.75% avg_auc=89.50%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.143870 Test loss=0.370181 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13753996789455414
[5/24] Train loss=0.12705908715724945
[10/24] Train loss=0.15187686681747437
[15/24] Train loss=0.14956408739089966
[20/24] Train loss=0.1527327001094818
Test set avg_accuracy=84.10% avg_sensitivity=78.81%, avg_specificity=85.97% avg_auc=88.80%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.142913 Test loss=0.402012 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1344318389892578
[5/24] Train loss=0.12403995543718338
[10/24] Train loss=0.14795927703380585
[15/24] Train loss=0.14878712594509125
[20/24] Train loss=0.1502714902162552
Test set avg_accuracy=83.84% avg_sensitivity=63.52%, avg_specificity=91.00% avg_auc=87.48%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.141890 Test loss=0.385539 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1383836269378662
[5/24] Train loss=0.12653416395187378
[10/24] Train loss=0.14168082177639008
[15/24] Train loss=0.1513638198375702
[20/24] Train loss=0.14463095366954803
Test set avg_accuracy=84.71% avg_sensitivity=74.31%, avg_specificity=88.38% avg_auc=88.04%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.142186 Test loss=0.392107 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13342703878879547
[5/24] Train loss=0.12653596699237823
[10/24] Train loss=0.1470717489719391
[15/24] Train loss=0.15128403902053833
[20/24] Train loss=0.1448388248682022
Test set avg_accuracy=83.59% avg_sensitivity=65.62%, avg_specificity=89.93% avg_auc=87.83%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.140359 Test loss=0.395505 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13318824768066406
[5/24] Train loss=0.1235220655798912
[10/24] Train loss=0.14364619553089142
[15/24] Train loss=0.14616000652313232
[20/24] Train loss=0.1489780992269516
Test set avg_accuracy=84.36% avg_sensitivity=62.17%, avg_specificity=92.18% avg_auc=87.33%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.139480 Test loss=0.391726 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.136937215924263
[5/24] Train loss=0.12363194674253464
[10/24] Train loss=0.14330275356769562
[15/24] Train loss=0.14938612282276154
[20/24] Train loss=0.14063531160354614
Test set avg_accuracy=84.65% avg_sensitivity=68.12%, avg_specificity=90.47% avg_auc=87.26%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.138708 Test loss=0.393008 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1353052854537964
[5/24] Train loss=0.12258150428533554
[10/24] Train loss=0.14065800607204437
[15/24] Train loss=0.14387942850589752
[20/24] Train loss=0.14263159036636353
Test set avg_accuracy=84.71% avg_sensitivity=73.96%, avg_specificity=88.50% avg_auc=88.75%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.137796 Test loss=0.379842 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1326504647731781
[5/24] Train loss=0.12260806560516357
[10/24] Train loss=0.13766175508499146
[15/24] Train loss=0.13999707996845245
[20/24] Train loss=0.14038856327533722
Test set avg_accuracy=84.83% avg_sensitivity=75.36%, avg_specificity=88.17% avg_auc=88.43%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.136108 Test loss=0.388357 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13048017024993896
[5/24] Train loss=0.12391357123851776
[10/24] Train loss=0.13667668402194977
[15/24] Train loss=0.14234088361263275
[20/24] Train loss=0.139479860663414
Test set avg_accuracy=84.97% avg_sensitivity=74.91%, avg_specificity=88.52% avg_auc=88.63%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.135882 Test loss=0.383107 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13287757337093353
[5/24] Train loss=0.1203957125544548
[10/24] Train loss=0.1380406767129898
[15/24] Train loss=0.1386808156967163
[20/24] Train loss=0.1390165090560913
Test set avg_accuracy=85.56% avg_sensitivity=72.31%, avg_specificity=90.23% avg_auc=88.26%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.134548 Test loss=0.381418 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1270691603422165
[5/24] Train loss=0.1224910318851471
[10/24] Train loss=0.13317644596099854
[15/24] Train loss=0.14135012030601501
[20/24] Train loss=0.13954639434814453
Test set avg_accuracy=85.27% avg_sensitivity=73.76%, avg_specificity=89.33% avg_auc=88.53%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.134222 Test loss=0.380771 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1281544268131256
[5/24] Train loss=0.12200090289115906
[10/24] Train loss=0.13295790553092957
[15/24] Train loss=0.13903215527534485
[20/24] Train loss=0.14064423739910126
Test set avg_accuracy=85.18% avg_sensitivity=75.21%, avg_specificity=88.70% avg_auc=88.71%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.133907 Test loss=0.376043 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12742812931537628
[5/24] Train loss=0.11962811648845673
[10/24] Train loss=0.13709425926208496
[15/24] Train loss=0.1408415287733078
[20/24] Train loss=0.13963931798934937
Test set avg_accuracy=85.49% avg_sensitivity=73.46%, avg_specificity=89.73% avg_auc=88.84%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.133369 Test loss=0.372357 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12993976473808289
[5/24] Train loss=0.1217029020190239
[10/24] Train loss=0.13591834902763367
[15/24] Train loss=0.13685792684555054
[20/24] Train loss=0.13689583539962769
Test set avg_accuracy=85.68% avg_sensitivity=74.31%, avg_specificity=89.68% avg_auc=89.00%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.132808 Test loss=0.372758 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1271582692861557
[5/24] Train loss=0.11828044801950455
[10/24] Train loss=0.13232596218585968
[15/24] Train loss=0.14016148447990417
[20/24] Train loss=0.13895836472511292
Test set avg_accuracy=84.99% avg_sensitivity=74.16%, avg_specificity=88.80% avg_auc=88.54%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.132216 Test loss=0.383796 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1279810667037964
[5/24] Train loss=0.12314482033252716
[10/24] Train loss=0.13311976194381714
[15/24] Train loss=0.1391063779592514
[20/24] Train loss=0.13875579833984375
Test set avg_accuracy=85.34% avg_sensitivity=75.46%, avg_specificity=88.82% avg_auc=88.93%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.131675 Test loss=0.376768 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1280941516160965
[5/24] Train loss=0.11509803682565689
[10/24] Train loss=0.1303430199623108
[15/24] Train loss=0.13636216521263123
[20/24] Train loss=0.13685260713100433
Test set avg_accuracy=85.64% avg_sensitivity=73.86%, avg_specificity=89.79% avg_auc=88.77%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.130595 Test loss=0.373833 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12970849871635437
[5/24] Train loss=0.12092854827642441
[10/24] Train loss=0.13310079276561737
[15/24] Train loss=0.13840092718601227
[20/24] Train loss=0.13472093641757965
Test set avg_accuracy=85.66% avg_sensitivity=73.16%, avg_specificity=90.07% avg_auc=88.82%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.130036 Test loss=0.373247 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12652647495269775
[5/24] Train loss=0.1151597648859024
[10/24] Train loss=0.13018083572387695
[15/24] Train loss=0.13600632548332214
[20/24] Train loss=0.13490568101406097
Test set avg_accuracy=85.53% avg_sensitivity=74.46%, avg_specificity=89.43% avg_auc=88.80%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.129287 Test loss=0.374929 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12466573715209961
[5/24] Train loss=0.11916369199752808
[10/24] Train loss=0.13308827579021454
[15/24] Train loss=0.13482680916786194
[20/24] Train loss=0.1319294571876526
Test set avg_accuracy=85.69% avg_sensitivity=72.36%, avg_specificity=90.39% avg_auc=88.55%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.128906 Test loss=0.374423 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12444598227739334
[5/24] Train loss=0.11602365970611572
[10/24] Train loss=0.1316533386707306
[15/24] Train loss=0.13674457371234894
[20/24] Train loss=0.1350260227918625
Test set avg_accuracy=85.49% avg_sensitivity=74.16%, avg_specificity=89.49% avg_auc=88.73%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.129248 Test loss=0.377226 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12608909606933594
[5/24] Train loss=0.11623977869749069
[10/24] Train loss=0.13150779902935028
[15/24] Train loss=0.13751982152462006
[20/24] Train loss=0.13580873608589172
Test set avg_accuracy=85.56% avg_sensitivity=74.06%, avg_specificity=89.61% avg_auc=88.85%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.129059 Test loss=0.375195 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12462028861045837
[5/24] Train loss=0.11757413297891617
[10/24] Train loss=0.1323121041059494
[15/24] Train loss=0.13514293730258942
[20/24] Train loss=0.13569432497024536
Test set avg_accuracy=85.74% avg_sensitivity=73.46%, avg_specificity=90.07% avg_auc=88.66%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.128845 Test loss=0.374958 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12730544805526733
[5/24] Train loss=0.11250030249357224
[10/24] Train loss=0.12949629127979279
[15/24] Train loss=0.13603192567825317
[20/24] Train loss=0.13422664999961853
Test set avg_accuracy=85.72% avg_sensitivity=74.11%, avg_specificity=89.80% avg_auc=88.85%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.128373 Test loss=0.374010 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1230960488319397
[5/24] Train loss=0.11639770120382309
[10/24] Train loss=0.1323050856590271
[15/24] Train loss=0.13548079133033752
[20/24] Train loss=0.13183791935443878
Test set avg_accuracy=85.57% avg_sensitivity=73.96%, avg_specificity=89.66% avg_auc=88.80%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.128304 Test loss=0.374544 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12263023853302002
[5/24] Train loss=0.11689653992652893
[10/24] Train loss=0.12929120659828186
[15/24] Train loss=0.13358476758003235
[20/24] Train loss=0.1331089735031128
Test set avg_accuracy=85.60% avg_sensitivity=73.66%, avg_specificity=89.80% avg_auc=88.77%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.128138 Test loss=0.374687 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12377788871526718
[5/24] Train loss=0.11416272073984146
[10/24] Train loss=0.1299644112586975
[15/24] Train loss=0.13539692759513855
[20/24] Train loss=0.13373766839504242
Test set avg_accuracy=85.70% avg_sensitivity=73.71%, avg_specificity=89.93% avg_auc=88.77%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.128246 Test loss=0.374835 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12456471472978592
[5/24] Train loss=0.1134738028049469
[10/24] Train loss=0.12933757901191711
[15/24] Train loss=0.1348511278629303
[20/24] Train loss=0.1341841071844101
Test set avg_accuracy=85.68% avg_sensitivity=73.56%, avg_specificity=89.95% avg_auc=88.72%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.127698 Test loss=0.374858 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12255559861660004
[5/24] Train loss=0.11598306894302368
[10/24] Train loss=0.13117201626300812
[15/24] Train loss=0.13449476659297943
[20/24] Train loss=0.1366882175207138
Test set avg_accuracy=85.66% avg_sensitivity=73.61%, avg_specificity=89.91% avg_auc=88.76%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.127677 Test loss=0.374932 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12445665150880814
[5/24] Train loss=0.11439194530248642
[10/24] Train loss=0.12855903804302216
[15/24] Train loss=0.13403353095054626
[20/24] Train loss=0.13456600904464722
Test set avg_accuracy=85.66% avg_sensitivity=73.61%, avg_specificity=89.91% avg_auc=88.77%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.127484 Test loss=0.374814 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12151968479156494
[5/24] Train loss=0.11708100885152817
[10/24] Train loss=0.1311168223619461
[15/24] Train loss=0.1332665979862213
[20/24] Train loss=0.13140812516212463
Test set avg_accuracy=85.62% avg_sensitivity=73.41%, avg_specificity=89.93% avg_auc=88.74%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.127416 Test loss=0.374872 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=84.60% sen=80.26%, spe=86.12%, auc=89.84%!
Fold[4] Avg_overlap=0.65%(±0.23910989716840536)
[0/24] Train loss=0.7313258647918701
[5/24] Train loss=0.7300095558166504
[10/24] Train loss=0.7189207077026367
[15/24] Train loss=0.7124277353286743
[20/24] Train loss=0.7037792205810547
Test set avg_accuracy=60.76% avg_sensitivity=47.52%, avg_specificity=65.27% avg_auc=59.41%
Best model saved!! Metric=-93.04576603990483!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.718809 Test loss=0.656376 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6989261507987976
[5/24] Train loss=0.6906663775444031
[10/24] Train loss=0.696980357170105
[15/24] Train loss=0.685016393661499
[20/24] Train loss=0.6757543683052063
Test set avg_accuracy=68.10% avg_sensitivity=64.72%, avg_specificity=69.25% avg_auc=72.86%
Best model saved!! Metric=-51.06883740716556!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.689580 Test loss=0.611611 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6699047684669495
[5/24] Train loss=0.6692089438438416
[10/24] Train loss=0.6760553121566772
[15/24] Train loss=0.6559564471244812
[20/24] Train loss=0.6519749760627747
Test set avg_accuracy=69.44% avg_sensitivity=72.30%, avg_specificity=68.47% avg_auc=77.63%
Best model saved!! Metric=-38.166077455567944!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.662959 Test loss=0.585285 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.639916718006134
[5/24] Train loss=0.6374724507331848
[10/24] Train loss=0.6460623741149902
[15/24] Train loss=0.6241772174835205
[20/24] Train loss=0.6154547929763794
Test set avg_accuracy=71.74% avg_sensitivity=75.27%, avg_specificity=70.54% avg_auc=80.60%
Best model saved!! Metric=-27.839865088540492!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.634597 Test loss=0.559184 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6216729283332825
[5/24] Train loss=0.6091448664665222
[10/24] Train loss=0.6195206642150879
[15/24] Train loss=0.5958443284034729
[20/24] Train loss=0.5908836722373962
Test set avg_accuracy=73.68% avg_sensitivity=77.47%, avg_specificity=72.39% avg_auc=82.71%
Best model saved!! Metric=-19.736994582355564!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.610701 Test loss=0.532350 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5945649743080139
[5/24] Train loss=0.5886651277542114
[10/24] Train loss=0.5916294455528259
[15/24] Train loss=0.5688385963439941
[20/24] Train loss=0.5674845576286316
Test set avg_accuracy=75.78% avg_sensitivity=77.52%, avg_specificity=75.19% avg_auc=84.36%
Best model saved!! Metric=-13.150469755086164!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.583587 Test loss=0.504520 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5683137774467468
[5/24] Train loss=0.5640504360198975
[10/24] Train loss=0.5706725716590881
[15/24] Train loss=0.5362818837165833
[20/24] Train loss=0.5457081198692322
Test set avg_accuracy=77.71% avg_sensitivity=78.08%, avg_specificity=77.58% avg_auc=85.75%
Best model saved!! Metric=-6.879065081537675!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.559705 Test loss=0.482533 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5425547957420349
[5/24] Train loss=0.5378202199935913
[10/24] Train loss=0.5436380505561829
[15/24] Train loss=0.5137783885002136
[20/24] Train loss=0.519869863986969
Test set avg_accuracy=79.21% avg_sensitivity=77.06%, avg_specificity=79.94% avg_auc=86.77%
Best model saved!! Metric=-3.0295952651463836!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.534345 Test loss=0.460203 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5223947763442993
[5/24] Train loss=0.5090826153755188
[10/24] Train loss=0.5128482580184937
[15/24] Train loss=0.4901773929595947
[20/24] Train loss=0.49680787324905396
Test set avg_accuracy=81.02% avg_sensitivity=75.73%, avg_specificity=82.82% avg_auc=87.64%
Best model saved!! Metric=1.1994520064161094!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.509976 Test loss=0.436878 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4932328760623932
[5/24] Train loss=0.48743924498558044
[10/24] Train loss=0.49500250816345215
[15/24] Train loss=0.45733967423439026
[20/24] Train loss=0.4729677140712738
Test set avg_accuracy=82.83% avg_sensitivity=73.17%, avg_specificity=86.12% avg_auc=88.23%
Best model saved!! Metric=4.347544188000029!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.487348 Test loss=0.413407 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.47266823053359985
[5/24] Train loss=0.4738786518573761
[10/24] Train loss=0.46927353739738464
[15/24] Train loss=0.443162739276886
[20/24] Train loss=0.4503531754016876
Test set avg_accuracy=83.84% avg_sensitivity=72.50%, avg_specificity=87.71% avg_auc=89.01%
Best model saved!! Metric=7.059252034490953!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.465665 Test loss=0.395291 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4513130486011505
[5/24] Train loss=0.4493671655654907
[10/24] Train loss=0.4580481946468353
[15/24] Train loss=0.4190031886100769
[20/24] Train loss=0.425739049911499
Test set avg_accuracy=84.90% avg_sensitivity=70.76%, avg_specificity=89.72% avg_auc=89.55%
Best model saved!! Metric=8.927832028709261!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.445204 Test loss=0.379070 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.43684667348861694
[5/24] Train loss=0.43370795249938965
[10/24] Train loss=0.441132128238678
[15/24] Train loss=0.4039326608181
[20/24] Train loss=0.4021480679512024
Test set avg_accuracy=85.53% avg_sensitivity=68.15%, avg_specificity=91.46% avg_auc=89.81%
Best model saved!! Metric=8.95847667549134!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.425782 Test loss=0.362423 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4126220941543579
[5/24] Train loss=0.41538113355636597
[10/24] Train loss=0.4151800870895386
[15/24] Train loss=0.3870040476322174
[20/24] Train loss=0.38507211208343506
Test set avg_accuracy=85.95% avg_sensitivity=66.77%, avg_specificity=92.49% avg_auc=89.93%
Best model saved!! Metric=9.136717745919682!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.407533 Test loss=0.354898 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.40565356612205505
[5/24] Train loss=0.398973673582077
[10/24] Train loss=0.40610620379447937
[15/24] Train loss=0.3654164969921112
[20/24] Train loss=0.37213894724845886
Test set avg_accuracy=85.96% avg_sensitivity=70.66%, avg_specificity=91.18% avg_auc=90.76%
Best model saved!! Metric=12.568484915250394!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.393641 Test loss=0.346768 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3876282572746277
[5/24] Train loss=0.3869550824165344
[10/24] Train loss=0.39416491985321045
[15/24] Train loss=0.3589262068271637
[20/24] Train loss=0.35292789340019226
Test set avg_accuracy=85.89% avg_sensitivity=73.63%, avg_specificity=90.06% avg_auc=91.19%
Best model saved!! Metric=14.769786399208897!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.380205 Test loss=0.343316 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.37364766001701355
[5/24] Train loss=0.38154318928718567
[10/24] Train loss=0.3881784677505493
[15/24] Train loss=0.34180748462677
[20/24] Train loss=0.34782129526138306
Test set avg_accuracy=86.04% avg_sensitivity=74.86%, avg_specificity=89.86% avg_auc=91.36%
Best model saved!! Metric=16.11741783358194!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.368669 Test loss=0.339792 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.36425089836120605
[5/24] Train loss=0.36880195140838623
[10/24] Train loss=0.3730114698410034
[15/24] Train loss=0.32725924253463745
[20/24] Train loss=0.33773505687713623
Test set avg_accuracy=85.96% avg_sensitivity=76.96%, avg_specificity=89.03% avg_auc=91.43%
Best model saved!! Metric=17.383649310671316!!
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.357909 Test loss=0.339794 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3526347875595093
[5/24] Train loss=0.3618322014808655
[10/24] Train loss=0.36567214131355286
[15/24] Train loss=0.3227289915084839
[20/24] Train loss=0.31924495100975037
Test set avg_accuracy=85.73% avg_sensitivity=75.22%, avg_specificity=89.31% avg_auc=91.29%
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.349942 Test loss=0.337430 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.34339049458503723
[5/24] Train loss=0.3587260842323303
[10/24] Train loss=0.3648306727409363
[15/24] Train loss=0.3143029808998108
[20/24] Train loss=0.3117868900299072
Test set avg_accuracy=86.35% avg_sensitivity=69.84%, avg_specificity=91.99% avg_auc=91.41%
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.341801 Test loss=0.320267 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3360513150691986
[5/24] Train loss=0.3531656563282013
[10/24] Train loss=0.35924461483955383
[15/24] Train loss=0.30698361992836
[20/24] Train loss=0.3090648055076599
Test set avg_accuracy=86.38% avg_sensitivity=71.53%, avg_specificity=91.44% avg_auc=91.50%
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.335177 Test loss=0.322704 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.32808220386505127
[5/24] Train loss=0.3445008099079132
[10/24] Train loss=0.3461204767227173
[15/24] Train loss=0.2980944514274597
[20/24] Train loss=0.30580422282218933
Test set avg_accuracy=86.15% avg_sensitivity=71.07%, avg_specificity=91.29% avg_auc=91.34%
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.327163 Test loss=0.329995 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3232177197933197
[5/24] Train loss=0.34063249826431274
[10/24] Train loss=0.3497677147388458
[15/24] Train loss=0.2868477702140808
[20/24] Train loss=0.3000653088092804
Test set avg_accuracy=85.95% avg_sensitivity=71.94%, avg_specificity=90.73% avg_auc=91.00%
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.322222 Test loss=0.328419 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3226166069507599
[5/24] Train loss=0.3450855016708374
[10/24] Train loss=0.3416586220264435
[15/24] Train loss=0.2885379195213318
[20/24] Train loss=0.2988356351852417
Test set avg_accuracy=86.05% avg_sensitivity=56.94%, avg_specificity=95.98% avg_auc=90.21%
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.318154 Test loss=0.335596 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3216458857059479
[5/24] Train loss=0.3341347277164459
[10/24] Train loss=0.3245643973350525
[15/24] Train loss=0.2762908339500427
[20/24] Train loss=0.2923142910003662
Test set avg_accuracy=86.15% avg_sensitivity=61.34%, avg_specificity=94.60% avg_auc=90.65%
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.311908 Test loss=0.328239 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3146092891693115
[5/24] Train loss=0.3240962624549866
[10/24] Train loss=0.3209798336029053
[15/24] Train loss=0.27825021743774414
[20/24] Train loss=0.27434197068214417
Test set avg_accuracy=85.18% avg_sensitivity=54.07%, avg_specificity=95.79% avg_auc=89.72%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.306437 Test loss=0.345558 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.304729163646698
[5/24] Train loss=0.3243250846862793
[10/24] Train loss=0.3112858533859253
[15/24] Train loss=0.2656727731227875
[20/24] Train loss=0.2839694023132324
Test set avg_accuracy=82.85% avg_sensitivity=37.94%, avg_specificity=98.17% avg_auc=87.57%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.301815 Test loss=0.400774 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3046404719352722
[5/24] Train loss=0.32237303256988525
[10/24] Train loss=0.32187381386756897
[15/24] Train loss=0.264362096786499
[20/24] Train loss=0.2754611670970917
Test set avg_accuracy=84.65% avg_sensitivity=50.49%, avg_specificity=96.30% avg_auc=88.71%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.298968 Test loss=0.356051 Current lr=[0.000210185142098938]

[0/24] Train loss=0.30424609780311584
[5/24] Train loss=0.31002727150917053
[10/24] Train loss=0.30944353342056274
[15/24] Train loss=0.2519938051700592
[20/24] Train loss=0.2771509289741516
Test set avg_accuracy=82.97% avg_sensitivity=39.89%, avg_specificity=97.66% avg_auc=87.09%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.293414 Test loss=0.396707 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2980341613292694
[5/24] Train loss=0.3050396740436554
[10/24] Train loss=0.3094860315322876
[15/24] Train loss=0.2622394561767578
[20/24] Train loss=0.268002450466156
Test set avg_accuracy=85.04% avg_sensitivity=52.89%, avg_specificity=96.00% avg_auc=89.55%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.290252 Test loss=0.347627 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2877291142940521
[5/24] Train loss=0.30145055055618286
[10/24] Train loss=0.29898330569267273
[15/24] Train loss=0.24795468151569366
[20/24] Train loss=0.26249709725379944
Test set avg_accuracy=85.83% avg_sensitivity=58.32%, avg_specificity=95.22% avg_auc=89.90%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.286883 Test loss=0.336732 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.29370373487472534
[5/24] Train loss=0.30671483278274536
[10/24] Train loss=0.30090874433517456
[15/24] Train loss=0.24502766132354736
[20/24] Train loss=0.26401859521865845
Test set avg_accuracy=85.46% avg_sensitivity=58.27%, avg_specificity=94.73% avg_auc=89.39%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.283043 Test loss=0.341242 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.27690252661705017
[5/24] Train loss=0.2938600182533264
[10/24] Train loss=0.3047303855419159
[15/24] Train loss=0.23817972838878632
[20/24] Train loss=0.26271528005599976
Test set avg_accuracy=83.62% avg_sensitivity=44.14%, avg_specificity=97.08% avg_auc=87.07%
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.280644 Test loss=0.398543 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2778322994709015
[5/24] Train loss=0.29747849702835083
[10/24] Train loss=0.3163469135761261
[15/24] Train loss=0.24195824563503265
[20/24] Train loss=0.2632497549057007
Test set avg_accuracy=81.42% avg_sensitivity=30.77%, avg_specificity=98.69% avg_auc=85.93%
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.274472 Test loss=0.458746 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.26812443137168884
[5/24] Train loss=0.2818388044834137
[10/24] Train loss=0.30413249135017395
[15/24] Train loss=0.23246850073337555
[20/24] Train loss=0.26960352063179016
Test set avg_accuracy=83.78% avg_sensitivity=52.79%, avg_specificity=94.34% avg_auc=87.56%
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.272290 Test loss=0.372581 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2741808593273163
[5/24] Train loss=0.2759636640548706
[10/24] Train loss=0.2948140501976013
[15/24] Train loss=0.24242328107357025
[20/24] Train loss=0.2505418360233307
Test set avg_accuracy=83.24% avg_sensitivity=52.28%, avg_specificity=93.80% avg_auc=87.76%
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.269276 Test loss=0.369141 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2819332182407379
[5/24] Train loss=0.2931728959083557
[10/24] Train loss=0.3088177442550659
[15/24] Train loss=0.2330217808485031
[20/24] Train loss=0.24010834097862244
Test set avg_accuracy=83.39% avg_sensitivity=45.88%, avg_specificity=96.18% avg_auc=87.04%
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.267626 Test loss=0.390184 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.280119389295578
[5/24] Train loss=0.2765246033668518
[10/24] Train loss=0.2918786108493805
[15/24] Train loss=0.23132704198360443
[20/24] Train loss=0.24310602247714996
Test set avg_accuracy=79.90% avg_sensitivity=24.42%, avg_specificity=98.81% avg_auc=83.97%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.263204 Test loss=0.511657 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2672062814235687
[5/24] Train loss=0.26239293813705444
[10/24] Train loss=0.2996980845928192
[15/24] Train loss=0.22439977526664734
[20/24] Train loss=0.24607914686203003
Test set avg_accuracy=83.52% avg_sensitivity=43.63%, avg_specificity=97.12% avg_auc=89.02%
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.261351 Test loss=0.368034 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2598491907119751
[5/24] Train loss=0.2613660991191864
[10/24] Train loss=0.282824844121933
[15/24] Train loss=0.21270346641540527
[20/24] Train loss=0.23603878915309906
Test set avg_accuracy=84.21% avg_sensitivity=54.99%, avg_specificity=94.17% avg_auc=87.51%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.253618 Test loss=0.376658 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.25810277462005615
[5/24] Train loss=0.2666212022304535
[10/24] Train loss=0.2953272759914398
[15/24] Train loss=0.2257165014743805
[20/24] Train loss=0.23262207210063934
Test set avg_accuracy=84.61% avg_sensitivity=65.54%, avg_specificity=91.11% avg_auc=89.79%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.254716 Test loss=0.341389 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.24842756986618042
[5/24] Train loss=0.24870266020298004
[10/24] Train loss=0.29713577032089233
[15/24] Train loss=0.20875892043113708
[20/24] Train loss=0.23848862946033478
Test set avg_accuracy=84.05% avg_sensitivity=50.79%, avg_specificity=95.39% avg_auc=87.75%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.249402 Test loss=0.393285 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.24996517598628998
[5/24] Train loss=0.2530035674571991
[10/24] Train loss=0.27685412764549255
[15/24] Train loss=0.21390117704868317
[20/24] Train loss=0.22501467168331146
Test set avg_accuracy=84.15% avg_sensitivity=67.95%, avg_specificity=89.68% avg_auc=90.12%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.249295 Test loss=0.344015 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2506292760372162
[5/24] Train loss=0.24084573984146118
[10/24] Train loss=0.2690693736076355
[15/24] Train loss=0.21105656027793884
[20/24] Train loss=0.2259780317544937
Test set avg_accuracy=76.80% avg_sensitivity=9.83%, avg_specificity=99.63% avg_auc=77.17%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.245038 Test loss=0.698057 Current lr=[0.00029967723776099]

[0/24] Train loss=0.26130253076553345
[5/24] Train loss=0.2526390254497528
[10/24] Train loss=0.2725850045681
[15/24] Train loss=0.2446594089269638
[20/24] Train loss=0.23014093935489655
Test set avg_accuracy=82.38% avg_sensitivity=62.62%, avg_specificity=89.12% avg_auc=86.96%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.249784 Test loss=0.390152 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2484518140554428
[5/24] Train loss=0.2185751348733902
[10/24] Train loss=0.2649784982204437
[15/24] Train loss=0.1998526155948639
[20/24] Train loss=0.2280791848897934
Test set avg_accuracy=84.08% avg_sensitivity=62.21%, avg_specificity=91.53% avg_auc=88.37%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.237895 Test loss=0.359553 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.24200502038002014
[5/24] Train loss=0.2556704580783844
[10/24] Train loss=0.2745046019554138
[15/24] Train loss=0.22044119238853455
[20/24] Train loss=0.23631910979747772
Test set avg_accuracy=83.01% avg_sensitivity=49.82%, avg_specificity=94.33% avg_auc=85.59%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.245105 Test loss=0.392400 Current lr=[0.000299720220882401]

[0/24] Train loss=0.24350132048130035
[5/24] Train loss=0.2412867397069931
[10/24] Train loss=0.2569900453090668
[15/24] Train loss=0.20933206379413605
[20/24] Train loss=0.22712571918964386
Test set avg_accuracy=83.49% avg_sensitivity=49.16%, avg_specificity=95.20% avg_auc=84.15%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.241927 Test loss=0.406114 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2517358660697937
[5/24] Train loss=0.24002216756343842
[10/24] Train loss=0.2493239790201187
[15/24] Train loss=0.2105157971382141
[20/24] Train loss=0.22390016913414001
Test set avg_accuracy=77.94% avg_sensitivity=54.53%, avg_specificity=85.93% avg_auc=79.04%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.235070 Test loss=0.471268 Current lr=[0.000298904600941902]

[0/24] Train loss=0.24747627973556519
[5/24] Train loss=0.22265832126140594
[10/24] Train loss=0.2503729462623596
[15/24] Train loss=0.20770016312599182
[20/24] Train loss=0.22272588312625885
Test set avg_accuracy=79.08% avg_sensitivity=65.95%, avg_specificity=83.55% avg_auc=82.88%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.232186 Test loss=0.454853 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.23152169585227966
[5/24] Train loss=0.22508135437965393
[10/24] Train loss=0.2658214271068573
[15/24] Train loss=0.20771390199661255
[20/24] Train loss=0.23305952548980713
Test set avg_accuracy=80.13% avg_sensitivity=24.83%, avg_specificity=98.99% avg_auc=84.55%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.232986 Test loss=0.491258 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2510546147823334
[5/24] Train loss=0.2149941772222519
[10/24] Train loss=0.2596891522407532
[15/24] Train loss=0.191592276096344
[20/24] Train loss=0.2270263433456421
Test set avg_accuracy=79.56% avg_sensitivity=22.22%, avg_specificity=99.11% avg_auc=81.80%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.231309 Test loss=0.521298 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.25880810618400574
[5/24] Train loss=0.21850542724132538
[10/24] Train loss=0.2552603781223297
[15/24] Train loss=0.19780917465686798
[20/24] Train loss=0.21696819365024567
Test set avg_accuracy=83.97% avg_sensitivity=46.49%, avg_specificity=96.75% avg_auc=87.19%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.230178 Test loss=0.420417 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.22723184525966644
[5/24] Train loss=0.2055588811635971
[10/24] Train loss=0.24136613309383392
[15/24] Train loss=0.19520528614521027
[20/24] Train loss=0.21413613855838776
Test set avg_accuracy=84.18% avg_sensitivity=46.44%, avg_specificity=97.05% avg_auc=84.58%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.224405 Test loss=0.407490 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2257745862007141
[5/24] Train loss=0.20788709819316864
[10/24] Train loss=0.24127459526062012
[15/24] Train loss=0.19970805943012238
[20/24] Train loss=0.21048787236213684
Test set avg_accuracy=85.07% avg_sensitivity=60.83%, avg_specificity=93.33% avg_auc=89.03%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.220972 Test loss=0.348504 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2317506968975067
[5/24] Train loss=0.1994178295135498
[10/24] Train loss=0.23142437636852264
[15/24] Train loss=0.20531047880649567
[20/24] Train loss=0.21092580258846283
Test set avg_accuracy=84.10% avg_sensitivity=46.39%, avg_specificity=96.96% avg_auc=87.39%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.217909 Test loss=0.375877 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.23287534713745117
[5/24] Train loss=0.20464052259922028
[10/24] Train loss=0.22981320321559906
[15/24] Train loss=0.19080989062786102
[20/24] Train loss=0.2219032347202301
Test set avg_accuracy=81.77% avg_sensitivity=35.48%, avg_specificity=97.56% avg_auc=83.27%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.218995 Test loss=0.471409 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.23051126301288605
[5/24] Train loss=0.2104083150625229
[10/24] Train loss=0.24311408400535583
[15/24] Train loss=0.19865243136882782
[20/24] Train loss=0.21957840025424957
Test set avg_accuracy=80.51% avg_sensitivity=26.98%, avg_specificity=98.76% avg_auc=81.46%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.220300 Test loss=0.500240 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.23584918677806854
[5/24] Train loss=0.2295585721731186
[10/24] Train loss=0.23098112642765045
[15/24] Train loss=0.1917736530303955
[20/24] Train loss=0.21357101202011108
Test set avg_accuracy=84.35% avg_sensitivity=53.76%, avg_specificity=94.78% avg_auc=86.15%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.222709 Test loss=0.392973 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.23777872323989868
[5/24] Train loss=0.2051354944705963
[10/24] Train loss=0.2343808114528656
[15/24] Train loss=0.19072221219539642
[20/24] Train loss=0.20888595283031464
Test set avg_accuracy=82.57% avg_sensitivity=39.17%, avg_specificity=97.36% avg_auc=80.78%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.214387 Test loss=0.503846 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.22702062129974365
[5/24] Train loss=0.20635384321212769
[10/24] Train loss=0.23779402673244476
[15/24] Train loss=0.20781047642230988
[20/24] Train loss=0.2154858112335205
Test set avg_accuracy=84.05% avg_sensitivity=62.26%, avg_specificity=91.48% avg_auc=88.01%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.221157 Test loss=0.367861 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2453891634941101
[5/24] Train loss=0.20800000429153442
[10/24] Train loss=0.23116062581539154
[15/24] Train loss=0.1866406351327896
[20/24] Train loss=0.2170906513929367
Test set avg_accuracy=84.95% avg_sensitivity=71.84%, avg_specificity=89.42% avg_auc=89.97%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.220155 Test loss=0.345492 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.23086832463741302
[5/24] Train loss=0.20469027757644653
[10/24] Train loss=0.22380362451076508
[15/24] Train loss=0.18516260385513306
[20/24] Train loss=0.21451067924499512
Test set avg_accuracy=85.12% avg_sensitivity=53.46%, avg_specificity=95.91% avg_auc=88.91%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.212091 Test loss=0.361143 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.22131362557411194
[5/24] Train loss=0.20549117028713226
[10/24] Train loss=0.2108772099018097
[15/24] Train loss=0.1824980080127716
[20/24] Train loss=0.20768509805202484
Test set avg_accuracy=84.78% avg_sensitivity=60.83%, avg_specificity=92.95% avg_auc=88.60%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.213548 Test loss=0.359203 Current lr=[0.000276307469034998]

[0/24] Train loss=0.21146148443222046
[5/24] Train loss=0.20554232597351074
[10/24] Train loss=0.22550947964191437
[15/24] Train loss=0.18335576355457306
[20/24] Train loss=0.2212153822183609
Test set avg_accuracy=85.03% avg_sensitivity=59.86%, avg_specificity=93.61% avg_auc=88.27%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.211423 Test loss=0.362258 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.2156805694103241
[5/24] Train loss=0.1996181607246399
[10/24] Train loss=0.20728102326393127
[15/24] Train loss=0.1807788908481598
[20/24] Train loss=0.1960904896259308
Test set avg_accuracy=83.63% avg_sensitivity=50.95%, avg_specificity=94.78% avg_auc=88.35%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.208659 Test loss=0.370309 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2095564752817154
[5/24] Train loss=0.19856368005275726
[10/24] Train loss=0.22420211136341095
[15/24] Train loss=0.1780073046684265
[20/24] Train loss=0.2248939573764801
Test set avg_accuracy=85.13% avg_sensitivity=56.48%, avg_specificity=94.90% avg_auc=88.06%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.211956 Test loss=0.376569 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.22612063586711884
[5/24] Train loss=0.19962972402572632
[10/24] Train loss=0.2276318520307541
[15/24] Train loss=0.21021723747253418
[20/24] Train loss=0.210294708609581
Test set avg_accuracy=82.55% avg_sensitivity=57.09%, avg_specificity=91.23% avg_auc=86.20%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.213309 Test loss=0.386312 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.21090847253799438
[5/24] Train loss=0.1978677213191986
[10/24] Train loss=0.23150020837783813
[15/24] Train loss=0.19669069349765778
[20/24] Train loss=0.1994156688451767
Test set avg_accuracy=84.10% avg_sensitivity=49.56%, avg_specificity=95.88% avg_auc=84.92%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.209393 Test loss=0.420866 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.22069363296031952
[5/24] Train loss=0.19150632619857788
[10/24] Train loss=0.2248092144727707
[15/24] Train loss=0.18072837591171265
[20/24] Train loss=0.21067175269126892
Test set avg_accuracy=85.86% avg_sensitivity=68.51%, avg_specificity=91.78% avg_auc=90.42%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.208391 Test loss=0.333153 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.2170412391424179
[5/24] Train loss=0.178849458694458
[10/24] Train loss=0.22397547960281372
[15/24] Train loss=0.19026099145412445
[20/24] Train loss=0.19639897346496582
Test set avg_accuracy=83.32% avg_sensitivity=48.85%, avg_specificity=95.08% avg_auc=82.56%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.204438 Test loss=0.438982 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.20907974243164062
[5/24] Train loss=0.17793774604797363
[10/24] Train loss=0.20983321964740753
[15/24] Train loss=0.19265735149383545
[20/24] Train loss=0.1938609927892685
Test set avg_accuracy=81.55% avg_sensitivity=64.41%, avg_specificity=87.39% avg_auc=84.87%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.201615 Test loss=0.413271 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.22215460240840912
[5/24] Train loss=0.197938472032547
[10/24] Train loss=0.20308278501033783
[15/24] Train loss=0.17855384945869446
[20/24] Train loss=0.20245686173439026
Test set avg_accuracy=83.09% avg_sensitivity=67.08%, avg_specificity=88.55% avg_auc=86.53%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.201228 Test loss=0.392541 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.21202486753463745
[5/24] Train loss=0.18895722925662994
[10/24] Train loss=0.20714989304542542
[15/24] Train loss=0.16851092875003815
[20/24] Train loss=0.1842145472764969
Test set avg_accuracy=81.82% avg_sensitivity=73.48%, avg_specificity=84.67% avg_auc=88.09%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.194674 Test loss=0.402089 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.20310518145561218
[5/24] Train loss=0.18720033764839172
[10/24] Train loss=0.20308735966682434
[15/24] Train loss=0.17958620190620422
[20/24] Train loss=0.19220095872879028
Test set avg_accuracy=85.18% avg_sensitivity=54.94%, avg_specificity=95.50% avg_auc=86.86%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.196785 Test loss=0.381799 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.19959108531475067
[5/24] Train loss=0.18139991164207458
[10/24] Train loss=0.20602943003177643
[15/24] Train loss=0.17463573813438416
[20/24] Train loss=0.18902724981307983
Test set avg_accuracy=83.01% avg_sensitivity=49.56%, avg_specificity=94.41% avg_auc=83.65%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.196896 Test loss=0.411643 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.19606530666351318
[5/24] Train loss=0.1852797567844391
[10/24] Train loss=0.201679527759552
[15/24] Train loss=0.1809072196483612
[20/24] Train loss=0.19144649803638458
Test set avg_accuracy=84.58% avg_sensitivity=61.24%, avg_specificity=92.54% avg_auc=86.68%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.196154 Test loss=0.386051 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.20878173410892487
[5/24] Train loss=0.19191431999206543
[10/24] Train loss=0.20112769305706024
[15/24] Train loss=0.17020283639431
[20/24] Train loss=0.18949472904205322
Test set avg_accuracy=84.49% avg_sensitivity=61.80%, avg_specificity=92.23% avg_auc=87.37%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.194802 Test loss=0.370838 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.20637725293636322
[5/24] Train loss=0.1844317466020584
[10/24] Train loss=0.1948907971382141
[15/24] Train loss=0.17388251423835754
[20/24] Train loss=0.19477781653404236
Test set avg_accuracy=76.04% avg_sensitivity=76.19%, avg_specificity=75.99% avg_auc=83.50%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.198035 Test loss=0.533717 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.20279544591903687
[5/24] Train loss=0.18235637247562408
[10/24] Train loss=0.1979815512895584
[15/24] Train loss=0.18599212169647217
[20/24] Train loss=0.1918969750404358
Test set avg_accuracy=82.33% avg_sensitivity=74.24%, avg_specificity=85.09% avg_auc=89.36%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.192968 Test loss=0.386153 Current lr=[0.000224838296036774]

[0/24] Train loss=0.20003993809223175
[5/24] Train loss=0.1699593961238861
[10/24] Train loss=0.1956343799829483
[15/24] Train loss=0.1800479143857956
[20/24] Train loss=0.18656238913536072
Test set avg_accuracy=80.36% avg_sensitivity=27.19%, avg_specificity=98.50% avg_auc=81.21%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.195941 Test loss=0.532014 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.20026318728923798
[5/24] Train loss=0.18339337408542633
[10/24] Train loss=0.19660718739032745
[15/24] Train loss=0.17498867213726044
[20/24] Train loss=0.1784931868314743
Test set avg_accuracy=83.68% avg_sensitivity=55.30%, avg_specificity=93.36% avg_auc=86.46%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.190491 Test loss=0.392288 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.20209901034832
[5/24] Train loss=0.17494052648544312
[10/24] Train loss=0.1952560991048813
[15/24] Train loss=0.1759244203567505
[20/24] Train loss=0.18776234984397888
Test set avg_accuracy=84.15% avg_sensitivity=57.86%, avg_specificity=93.12% avg_auc=86.91%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.189861 Test loss=0.382443 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.19109708070755005
[5/24] Train loss=0.17439477145671844
[10/24] Train loss=0.1948411464691162
[15/24] Train loss=0.1697009801864624
[20/24] Train loss=0.17753995954990387
Test set avg_accuracy=83.89% avg_sensitivity=47.93%, avg_specificity=96.16% avg_auc=84.30%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.187934 Test loss=0.426357 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.19232165813446045
[5/24] Train loss=0.16900107264518738
[10/24] Train loss=0.19541579484939575
[15/24] Train loss=0.18383827805519104
[20/24] Train loss=0.2016148716211319
Test set avg_accuracy=82.50% avg_sensitivity=47.21%, avg_specificity=94.53% avg_auc=83.03%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.188612 Test loss=0.436788 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.19969402253627777
[5/24] Train loss=0.18997816741466522
[10/24] Train loss=0.1936664879322052
[15/24] Train loss=0.16583740711212158
[20/24] Train loss=0.176028773188591
Test set avg_accuracy=83.41% avg_sensitivity=49.46%, avg_specificity=94.99% avg_auc=85.38%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.188594 Test loss=0.413028 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1982143372297287
[5/24] Train loss=0.17163491249084473
[10/24] Train loss=0.18954208493232727
[15/24] Train loss=0.17032134532928467
[20/24] Train loss=0.19141271710395813
Test set avg_accuracy=82.17% avg_sensitivity=35.69%, avg_specificity=98.03% avg_auc=79.03%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.184841 Test loss=0.518746 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.20606987178325653
[5/24] Train loss=0.16820040345191956
[10/24] Train loss=0.18512772023677826
[15/24] Train loss=0.16168849170207977
[20/24] Train loss=0.1807679533958435
Test set avg_accuracy=78.11% avg_sensitivity=17.20%, avg_specificity=98.88% avg_auc=72.87%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.183264 Test loss=0.668616 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.19800250232219696
[5/24] Train loss=0.18573683500289917
[10/24] Train loss=0.1981865018606186
[15/24] Train loss=0.1645766943693161
[20/24] Train loss=0.1733950823545456
Test set avg_accuracy=79.74% avg_sensitivity=26.37%, avg_specificity=97.94% avg_auc=78.44%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.188308 Test loss=0.558464 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.20348334312438965
[5/24] Train loss=0.18282732367515564
[10/24] Train loss=0.18246540427207947
[15/24] Train loss=0.17192496359348297
[20/24] Train loss=0.17849060893058777
Test set avg_accuracy=83.18% avg_sensitivity=60.06%, avg_specificity=91.06% avg_auc=84.10%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.185260 Test loss=0.410971 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.183444082736969
[5/24] Train loss=0.1651216745376587
[10/24] Train loss=0.19116847217082977
[15/24] Train loss=0.16497041285037994
[20/24] Train loss=0.18229618668556213
Test set avg_accuracy=83.03% avg_sensitivity=61.65%, avg_specificity=90.33% avg_auc=87.42%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.182381 Test loss=0.384010 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.19939342141151428
[5/24] Train loss=0.17841072380542755
[10/24] Train loss=0.18458214402198792
[15/24] Train loss=0.1608501672744751
[20/24] Train loss=0.1785249412059784
Test set avg_accuracy=81.58% avg_sensitivity=36.82%, avg_specificity=96.84% avg_auc=79.29%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.180305 Test loss=0.502649 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.18335598707199097
[5/24] Train loss=0.16367268562316895
[10/24] Train loss=0.19125287234783173
[15/24] Train loss=0.1720794141292572
[20/24] Train loss=0.17475932836532593
Test set avg_accuracy=83.09% avg_sensitivity=50.54%, avg_specificity=94.19% avg_auc=81.51%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.181767 Test loss=0.436142 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.19162042438983917
[5/24] Train loss=0.16924919188022614
[10/24] Train loss=0.1874047964811325
[15/24] Train loss=0.15481653809547424
[20/24] Train loss=0.17280493676662445
Test set avg_accuracy=79.60% avg_sensitivity=23.40%, avg_specificity=98.76% avg_auc=73.46%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.181166 Test loss=0.591961 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.18694880604743958
[5/24] Train loss=0.17797185480594635
[10/24] Train loss=0.18441924452781677
[15/24] Train loss=0.16244980692863464
[20/24] Train loss=0.17431919276714325
Test set avg_accuracy=81.85% avg_sensitivity=38.86%, avg_specificity=96.51% avg_auc=79.33%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.178858 Test loss=0.489834 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.18089891970157623
[5/24] Train loss=0.16995443403720856
[10/24] Train loss=0.18199317157268524
[15/24] Train loss=0.15854205191135406
[20/24] Train loss=0.17956583201885223
Test set avg_accuracy=82.54% avg_sensitivity=40.60%, avg_specificity=96.84% avg_auc=80.38%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.176183 Test loss=0.476292 Current lr=[0.000156543481933168]

[0/24] Train loss=0.19066615402698517
[5/24] Train loss=0.16570183634757996
[10/24] Train loss=0.18990951776504517
[15/24] Train loss=0.16634847223758698
[20/24] Train loss=0.19001850485801697
Test set avg_accuracy=79.17% avg_sensitivity=21.76%, avg_specificity=98.74% avg_auc=71.34%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.183481 Test loss=0.625704 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1821766495704651
[5/24] Train loss=0.17224682867527008
[10/24] Train loss=0.19731302559375763
[15/24] Train loss=0.16701285541057587
[20/24] Train loss=0.1888781636953354
Test set avg_accuracy=83.28% avg_sensitivity=44.60%, avg_specificity=96.47% avg_auc=82.76%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.181631 Test loss=0.443696 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.19118160009384155
[5/24] Train loss=0.1702708750963211
[10/24] Train loss=0.19121356308460236
[15/24] Train loss=0.17427311837673187
[20/24] Train loss=0.18571574985980988
Test set avg_accuracy=83.11% avg_sensitivity=71.89%, avg_specificity=86.94% avg_auc=88.49%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.181126 Test loss=0.391303 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.17930690944194794
[5/24] Train loss=0.16941238939762115
[10/24] Train loss=0.18404024839401245
[15/24] Train loss=0.17565752565860748
[20/24] Train loss=0.18049314618110657
Test set avg_accuracy=85.18% avg_sensitivity=60.68%, avg_specificity=93.54% avg_auc=87.71%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.180094 Test loss=0.376829 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.19776856899261475
[5/24] Train loss=0.15557615458965302
[10/24] Train loss=0.18291887640953064
[15/24] Train loss=0.17511677742004395
[20/24] Train loss=0.1721956878900528
Test set avg_accuracy=83.98% avg_sensitivity=63.90%, avg_specificity=90.83% avg_auc=87.38%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.177527 Test loss=0.386739 Current lr=[0.000134135431043539]

[0/24] Train loss=0.18973182141780853
[5/24] Train loss=0.16466526687145233
[10/24] Train loss=0.17134946584701538
[15/24] Train loss=0.16695867478847504
[20/24] Train loss=0.16702066361904144
Test set avg_accuracy=84.87% avg_sensitivity=52.74%, avg_specificity=95.83% avg_auc=86.07%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.171292 Test loss=0.394505 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.17548701167106628
[5/24] Train loss=0.1648680567741394
[10/24] Train loss=0.17505471408367157
[15/24] Train loss=0.1564520299434662
[20/24] Train loss=0.17979495227336884
Test set avg_accuracy=85.13% avg_sensitivity=62.31%, avg_specificity=92.91% avg_auc=88.85%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.169927 Test loss=0.359264 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.17119595408439636
[5/24] Train loss=0.15896283090114594
[10/24] Train loss=0.1712101697921753
[15/24] Train loss=0.1534716635942459
[20/24] Train loss=0.1610325574874878
Test set avg_accuracy=85.29% avg_sensitivity=71.38%, avg_specificity=90.03% avg_auc=89.61%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.165062 Test loss=0.351105 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.17896834015846252
[5/24] Train loss=0.15564092993736267
[10/24] Train loss=0.17224504053592682
[15/24] Train loss=0.15812323987483978
[20/24] Train loss=0.16481216251850128
Test set avg_accuracy=84.00% avg_sensitivity=76.50%, avg_specificity=86.55% avg_auc=90.40%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.166145 Test loss=0.361110 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.17480666935443878
[5/24] Train loss=0.15735407173633575
[10/24] Train loss=0.16839896142482758
[15/24] Train loss=0.14982783794403076
[20/24] Train loss=0.16046883165836334
Test set avg_accuracy=84.91% avg_sensitivity=66.26%, avg_specificity=91.27% avg_auc=87.52%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.163854 Test loss=0.366945 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1744580715894699
[5/24] Train loss=0.15230657160282135
[10/24] Train loss=0.16625015437602997
[15/24] Train loss=0.14597128331661224
[20/24] Train loss=0.1589190661907196
Test set avg_accuracy=84.41% avg_sensitivity=76.24%, avg_specificity=87.20% avg_auc=89.82%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.162920 Test loss=0.366387 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.17570658028125763
[5/24] Train loss=0.15610063076019287
[10/24] Train loss=0.16140593588352203
[15/24] Train loss=0.1496199667453766
[20/24] Train loss=0.16089247167110443
Test set avg_accuracy=85.64% avg_sensitivity=65.59%, avg_specificity=92.47% avg_auc=88.03%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.162230 Test loss=0.366511 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.16911129653453827
[5/24] Train loss=0.15550333261489868
[10/24] Train loss=0.15908318758010864
[15/24] Train loss=0.1573254019021988
[20/24] Train loss=0.1577274352312088
Test set avg_accuracy=85.85% avg_sensitivity=65.39%, avg_specificity=92.82% avg_auc=88.57%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.161282 Test loss=0.358494 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.17415012419223785
[5/24] Train loss=0.14614547789096832
[10/24] Train loss=0.16018089652061462
[15/24] Train loss=0.14657430350780487
[20/24] Train loss=0.15698830783367157
Test set avg_accuracy=85.73% avg_sensitivity=65.80%, avg_specificity=92.53% avg_auc=89.66%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.160850 Test loss=0.351639 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.17067036032676697
[5/24] Train loss=0.14975520968437195
[10/24] Train loss=0.15540054440498352
[15/24] Train loss=0.14292435348033905
[20/24] Train loss=0.1502145677804947
Test set avg_accuracy=85.57% avg_sensitivity=70.40%, avg_specificity=90.75% avg_auc=89.80%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.156814 Test loss=0.351047 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.17146700620651245
[5/24] Train loss=0.1482994705438614
[10/24] Train loss=0.15313780307769775
[15/24] Train loss=0.1471647173166275
[20/24] Train loss=0.15249857306480408
Test set avg_accuracy=84.35% avg_sensitivity=73.94%, avg_specificity=87.90% avg_auc=89.20%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.155749 Test loss=0.371905 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.16934294998645782
[5/24] Train loss=0.14717155694961548
[10/24] Train loss=0.15859372913837433
[15/24] Train loss=0.14633497595787048
[20/24] Train loss=0.14491665363311768
Test set avg_accuracy=86.17% avg_sensitivity=69.33%, avg_specificity=91.92% avg_auc=89.69%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.152495 Test loss=0.347523 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1636999249458313
[5/24] Train loss=0.1406676024198532
[10/24] Train loss=0.15365402400493622
[15/24] Train loss=0.15066209435462952
[20/24] Train loss=0.14486064016819
Test set avg_accuracy=86.21% avg_sensitivity=66.62%, avg_specificity=92.89% avg_auc=88.93%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.152692 Test loss=0.350996 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.16470949351787567
[5/24] Train loss=0.14185065031051636
[10/24] Train loss=0.1523643285036087
[15/24] Train loss=0.14307458698749542
[20/24] Train loss=0.14620573818683624
Test set avg_accuracy=85.98% avg_sensitivity=65.64%, avg_specificity=92.91% avg_auc=88.26%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.151625 Test loss=0.355010 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15780964493751526
[5/24] Train loss=0.14081326127052307
[10/24] Train loss=0.16029472649097443
[15/24] Train loss=0.14343269169330597
[20/24] Train loss=0.14634807407855988
Test set avg_accuracy=85.12% avg_sensitivity=55.35%, avg_specificity=95.27% avg_auc=86.69%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.150567 Test loss=0.390284 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.16909609735012054
[5/24] Train loss=0.1404314488172531
[10/24] Train loss=0.14888907968997955
[15/24] Train loss=0.14372463524341583
[20/24] Train loss=0.14589516818523407
Test set avg_accuracy=84.19% avg_sensitivity=74.40%, avg_specificity=87.53% avg_auc=89.48%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.149103 Test loss=0.375559 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.16537047922611237
[5/24] Train loss=0.13908225297927856
[10/24] Train loss=0.14873920381069183
[15/24] Train loss=0.13851965963840485
[20/24] Train loss=0.1429809331893921
Test set avg_accuracy=86.17% avg_sensitivity=68.82%, avg_specificity=92.09% avg_auc=88.55%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.148126 Test loss=0.352753 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.15494553744792938
[5/24] Train loss=0.1406390517950058
[10/24] Train loss=0.14367584884166718
[15/24] Train loss=0.13967688381671906
[20/24] Train loss=0.14494328200817108
Test set avg_accuracy=85.90% avg_sensitivity=70.40%, avg_specificity=91.18% avg_auc=89.06%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.146476 Test loss=0.355937 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.15689131617546082
[5/24] Train loss=0.13975070416927338
[10/24] Train loss=0.1479814350605011
[15/24] Train loss=0.13791869580745697
[20/24] Train loss=0.14268045127391815
Test set avg_accuracy=84.86% avg_sensitivity=61.44%, avg_specificity=92.84% avg_auc=87.94%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.146356 Test loss=0.378708 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1591624617576599
[5/24] Train loss=0.1349819153547287
[10/24] Train loss=0.14621983468532562
[15/24] Train loss=0.14329583942890167
[20/24] Train loss=0.14022283256053925
Test set avg_accuracy=85.61% avg_sensitivity=67.74%, avg_specificity=91.71% avg_auc=88.93%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.146235 Test loss=0.361013 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.15742436051368713
[5/24] Train loss=0.13874737918376923
[10/24] Train loss=0.1445300430059433
[15/24] Train loss=0.1376398801803589
[20/24] Train loss=0.1405625343322754
Test set avg_accuracy=85.69% avg_sensitivity=65.90%, avg_specificity=92.44% avg_auc=88.20%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.144394 Test loss=0.368478 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.15768687427043915
[5/24] Train loss=0.135522723197937
[10/24] Train loss=0.14486882090568542
[15/24] Train loss=0.1400831937789917
[20/24] Train loss=0.14718808233737946
Test set avg_accuracy=84.79% avg_sensitivity=65.34%, avg_specificity=91.43% avg_auc=88.10%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.145137 Test loss=0.372440 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.14804679155349731
[5/24] Train loss=0.13748979568481445
[10/24] Train loss=0.14979125559329987
[15/24] Train loss=0.13605670630931854
[20/24] Train loss=0.1410301774740219
Test set avg_accuracy=86.11% avg_sensitivity=65.34%, avg_specificity=93.19% avg_auc=88.91%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.142494 Test loss=0.360363 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1491568237543106
[5/24] Train loss=0.13654518127441406
[10/24] Train loss=0.14041128754615784
[15/24] Train loss=0.1385035365819931
[20/24] Train loss=0.1399153769016266
Test set avg_accuracy=84.05% avg_sensitivity=71.38%, avg_specificity=88.37% avg_auc=88.18%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.141426 Test loss=0.382308 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.15342767536640167
[5/24] Train loss=0.13670668005943298
[10/24] Train loss=0.1379454880952835
[15/24] Train loss=0.1323287934064865
[20/24] Train loss=0.1413985937833786
Test set avg_accuracy=85.20% avg_sensitivity=67.18%, avg_specificity=91.34% avg_auc=87.98%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.141168 Test loss=0.368454 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.15011365711688995
[5/24] Train loss=0.13272354006767273
[10/24] Train loss=0.1411391645669937
[15/24] Train loss=0.13673661649227142
[20/24] Train loss=0.1368904709815979
Test set avg_accuracy=85.78% avg_sensitivity=66.67%, avg_specificity=92.30% avg_auc=88.31%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.140533 Test loss=0.361204 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.14858601987361908
[5/24] Train loss=0.13246698677539825
[10/24] Train loss=0.13829626142978668
[15/24] Train loss=0.1346319615840912
[20/24] Train loss=0.13769513368606567
Test set avg_accuracy=84.56% avg_sensitivity=69.99%, avg_specificity=89.52% avg_auc=87.38%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.139927 Test loss=0.382126 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.14837856590747833
[5/24] Train loss=0.13178274035453796
[10/24] Train loss=0.13446441292762756
[15/24] Train loss=0.13345779478549957
[20/24] Train loss=0.13759970664978027
Test set avg_accuracy=85.29% avg_sensitivity=70.46%, avg_specificity=90.34% avg_auc=88.43%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.138866 Test loss=0.366390 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.14915019273757935
[5/24] Train loss=0.13026349246501923
[10/24] Train loss=0.13213108479976654
[15/24] Train loss=0.13102754950523376
[20/24] Train loss=0.13503053784370422
Test set avg_accuracy=85.52% avg_sensitivity=70.51%, avg_specificity=90.64% avg_auc=88.86%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.137148 Test loss=0.359425 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1494259536266327
[5/24] Train loss=0.12983591854572296
[10/24] Train loss=0.13592156767845154
[15/24] Train loss=0.12953872978687286
[20/24] Train loss=0.13990937173366547
Test set avg_accuracy=85.29% avg_sensitivity=70.15%, avg_specificity=90.45% avg_auc=88.63%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.137433 Test loss=0.362897 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1535981297492981
[5/24] Train loss=0.12766419351100922
[10/24] Train loss=0.13282199203968048
[15/24] Train loss=0.12852393090724945
[20/24] Train loss=0.1335885226726532
Test set avg_accuracy=85.29% avg_sensitivity=70.10%, avg_specificity=90.47% avg_auc=88.49%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.136715 Test loss=0.365296 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.150172159075737
[5/24] Train loss=0.13111554086208344
[10/24] Train loss=0.13103704154491425
[15/24] Train loss=0.13274437189102173
[20/24] Train loss=0.1351948082447052
Test set avg_accuracy=85.38% avg_sensitivity=69.69%, avg_specificity=90.73% avg_auc=88.61%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.135875 Test loss=0.366857 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.14767254889011383
[5/24] Train loss=0.1289367526769638
[10/24] Train loss=0.12963947653770447
[15/24] Train loss=0.1252385526895523
[20/24] Train loss=0.132298082113266
Test set avg_accuracy=85.29% avg_sensitivity=70.46%, avg_specificity=90.34% avg_auc=88.55%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.134629 Test loss=0.365713 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.14287322759628296
[5/24] Train loss=0.12569458782672882
[10/24] Train loss=0.1302003264427185
[15/24] Train loss=0.12671299278736115
[20/24] Train loss=0.13373301923274994
Test set avg_accuracy=85.72% avg_sensitivity=68.51%, avg_specificity=91.58% avg_auc=88.35%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.133834 Test loss=0.362585 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1419352889060974
[5/24] Train loss=0.1258600503206253
[10/24] Train loss=0.13138744235038757
[15/24] Train loss=0.12929771840572357
[20/24] Train loss=0.13250543177127838
Test set avg_accuracy=85.21% avg_sensitivity=67.28%, avg_specificity=91.32% avg_auc=88.02%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.134038 Test loss=0.366990 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.14454972743988037
[5/24] Train loss=0.1271301805973053
[10/24] Train loss=0.13473671674728394
[15/24] Train loss=0.13094991445541382
[20/24] Train loss=0.13357026875019073
Test set avg_accuracy=85.52% avg_sensitivity=68.92%, avg_specificity=91.18% avg_auc=88.41%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.133842 Test loss=0.365281 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.14098893105983734
[5/24] Train loss=0.1293533444404602
[10/24] Train loss=0.13014072179794312
[15/24] Train loss=0.12589819729328156
[20/24] Train loss=0.1315188705921173
Test set avg_accuracy=85.52% avg_sensitivity=68.46%, avg_specificity=91.34% avg_auc=88.77%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.132621 Test loss=0.359610 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.14528487622737885
[5/24] Train loss=0.12647700309753418
[10/24] Train loss=0.12623322010040283
[15/24] Train loss=0.12232435494661331
[20/24] Train loss=0.13228721916675568
Test set avg_accuracy=85.66% avg_sensitivity=68.36%, avg_specificity=91.57% avg_auc=88.56%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.132455 Test loss=0.360871 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.14302416145801544
[5/24] Train loss=0.1261748969554901
[10/24] Train loss=0.13433177769184113
[15/24] Train loss=0.12610836327075958
[20/24] Train loss=0.13326483964920044
Test set avg_accuracy=85.39% avg_sensitivity=68.61%, avg_specificity=91.11% avg_auc=88.46%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.132362 Test loss=0.363141 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.14011119306087494
[5/24] Train loss=0.12571130692958832
[10/24] Train loss=0.1295522004365921
[15/24] Train loss=0.12561893463134766
[20/24] Train loss=0.13317957520484924
Test set avg_accuracy=85.55% avg_sensitivity=68.82%, avg_specificity=91.25% avg_auc=88.57%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.131152 Test loss=0.361126 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.14081886410713196
[5/24] Train loss=0.12448827922344208
[10/24] Train loss=0.12842842936515808
[15/24] Train loss=0.1272243708372116
[20/24] Train loss=0.13043220341205597
Test set avg_accuracy=85.55% avg_sensitivity=67.95%, avg_specificity=91.55% avg_auc=88.34%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.131147 Test loss=0.362360 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.14307360351085663
[5/24] Train loss=0.12615999579429626
[10/24] Train loss=0.1302425116300583
[15/24] Train loss=0.12372123450040817
[20/24] Train loss=0.1312742531299591
Test set avg_accuracy=85.65% avg_sensitivity=68.41%, avg_specificity=91.53% avg_auc=88.31%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.130953 Test loss=0.364075 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.14367243647575378
[5/24] Train loss=0.12333493679761887
[10/24] Train loss=0.12890511751174927
[15/24] Train loss=0.12698303163051605
[20/24] Train loss=0.12995551526546478
Test set avg_accuracy=85.68% avg_sensitivity=68.41%, avg_specificity=91.57% avg_auc=88.48%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.131038 Test loss=0.361209 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13966040313243866
[5/24] Train loss=0.12801173329353333
[10/24] Train loss=0.13157880306243896
[15/24] Train loss=0.12396223098039627
[20/24] Train loss=0.12996424734592438
Test set avg_accuracy=85.59% avg_sensitivity=68.71%, avg_specificity=91.34% avg_auc=88.45%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.130790 Test loss=0.361167 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13903748989105225
[5/24] Train loss=0.12365444004535675
[10/24] Train loss=0.12913601100444794
[15/24] Train loss=0.12534278631210327
[20/24] Train loss=0.12881383299827576
Test set avg_accuracy=85.57% avg_sensitivity=68.56%, avg_specificity=91.37% avg_auc=88.49%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.130788 Test loss=0.360721 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.13756726682186127
[5/24] Train loss=0.12635266780853271
[10/24] Train loss=0.12627223134040833
[15/24] Train loss=0.12369217723608017
[20/24] Train loss=0.13262586295604706
Test set avg_accuracy=85.68% avg_sensitivity=68.41%, avg_specificity=91.57% avg_auc=88.45%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.130902 Test loss=0.360836 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1450306922197342
[5/24] Train loss=0.12680572271347046
[10/24] Train loss=0.12782111763954163
[15/24] Train loss=0.12423162907361984
[20/24] Train loss=0.13286815583705902
Test set avg_accuracy=85.59% avg_sensitivity=68.41%, avg_specificity=91.44% avg_auc=88.48%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.130617 Test loss=0.360858 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13852423429489136
[5/24] Train loss=0.1253705471754074
[10/24] Train loss=0.12668922543525696
[15/24] Train loss=0.12481715530157089
[20/24] Train loss=0.13059452176094055
Test set avg_accuracy=85.64% avg_sensitivity=68.31%, avg_specificity=91.55% avg_auc=88.44%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.130485 Test loss=0.361275 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.14035964012145996
[5/24] Train loss=0.12682999670505524
[10/24] Train loss=0.127949520945549
[15/24] Train loss=0.12591908872127533
[20/24] Train loss=0.1312750279903412
Test set avg_accuracy=85.61% avg_sensitivity=68.36%, avg_specificity=91.50% avg_auc=88.45%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.130703 Test loss=0.361125 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=85.96% sen=76.96%, spe=89.03%, auc=91.43%!
Fold[5] Avg_overlap=0.58%(±0.2626273564103877)
[0/24] Train loss=0.7344738841056824
[5/24] Train loss=0.7376880049705505
[10/24] Train loss=0.7238864302635193
[15/24] Train loss=0.7188887000083923
[20/24] Train loss=0.7128268480300903
Test set avg_accuracy=57.24% avg_sensitivity=49.14%, avg_specificity=60.26% avg_auc=57.63%
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.724885 Test loss=0.695030 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.705237627029419
[5/24] Train loss=0.6910560131072998
[10/24] Train loss=0.6915220022201538
[15/24] Train loss=0.6822782754898071
[20/24] Train loss=0.6764464378356934
Test set avg_accuracy=67.01% avg_sensitivity=63.48%, avg_specificity=68.32% avg_auc=71.62%
Best model saved!! Metric=-55.57449230970893!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.692193 Test loss=0.621153 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6725536584854126
[5/24] Train loss=0.6674967408180237
[10/24] Train loss=0.6697229743003845
[15/24] Train loss=0.6501628160476685
[20/24] Train loss=0.6525365710258484
Test set avg_accuracy=70.94% avg_sensitivity=70.68%, avg_specificity=71.03% avg_auc=77.21%
Best model saved!! Metric=-36.14106808194501!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.664078 Test loss=0.583813 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6453900337219238
[5/24] Train loss=0.6449758410453796
[10/24] Train loss=0.6420691609382629
[15/24] Train loss=0.6301445960998535
[20/24] Train loss=0.6231525540351868
Test set avg_accuracy=72.38% avg_sensitivity=75.48%, avg_specificity=71.23% avg_auc=79.95%
Best model saved!! Metric=-26.95817585334808!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.639034 Test loss=0.564062 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6130030155181885
[5/24] Train loss=0.6113752126693726
[10/24] Train loss=0.6160812973976135
[15/24] Train loss=0.6033071279525757
[20/24] Train loss=0.6019125580787659
Test set avg_accuracy=74.41% avg_sensitivity=76.44%, avg_specificity=73.66% avg_auc=81.85%
Best model saved!! Metric=-19.63640866873996!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.611678 Test loss=0.537749 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5877057909965515
[5/24] Train loss=0.5798546075820923
[10/24] Train loss=0.5924750566482544
[15/24] Train loss=0.5772017240524292
[20/24] Train loss=0.570183515548706
Test set avg_accuracy=75.95% avg_sensitivity=76.68%, avg_specificity=75.68% avg_auc=83.32%
Best model saved!! Metric=-14.369354276252778!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.586971 Test loss=0.516829 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5680432915687561
[5/24] Train loss=0.5564894676208496
[10/24] Train loss=0.5639662742614746
[15/24] Train loss=0.5494133234024048
[20/24] Train loss=0.5439934730529785
Test set avg_accuracy=77.32% avg_sensitivity=77.16%, avg_specificity=77.38% avg_auc=84.83%
Best model saved!! Metric=-9.319319554697458!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.561282 Test loss=0.493953 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5395220518112183
[5/24] Train loss=0.5350538492202759
[10/24] Train loss=0.5394424796104431
[15/24] Train loss=0.5308839082717896
[20/24] Train loss=0.5114144086837769
Test set avg_accuracy=79.28% avg_sensitivity=75.53%, avg_specificity=80.68% avg_auc=86.11%
Best model saved!! Metric=-4.392527132561327!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.534836 Test loss=0.466558 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5110381245613098
[5/24] Train loss=0.5088489055633545
[10/24] Train loss=0.5146862864494324
[15/24] Train loss=0.5010764002799988
[20/24] Train loss=0.4863947927951813
Test set avg_accuracy=80.72% avg_sensitivity=75.62%, avg_specificity=82.61% avg_auc=87.27%
Best model saved!! Metric=0.22728777184438798!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.509693 Test loss=0.443018 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4923434853553772
[5/24] Train loss=0.4797236919403076
[10/24] Train loss=0.4892793297767639
[15/24] Train loss=0.474045068025589
[20/24] Train loss=0.464013010263443
Test set avg_accuracy=81.95% avg_sensitivity=74.81%, avg_specificity=84.61% avg_auc=88.22%
Best model saved!! Metric=3.5921278386055775!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.485292 Test loss=0.423462 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.47260382771492004
[5/24] Train loss=0.45785874128341675
[10/24] Train loss=0.46952658891677856
[15/24] Train loss=0.4503011107444763
[20/24] Train loss=0.4427020251750946
Test set avg_accuracy=82.99% avg_sensitivity=73.42%, avg_specificity=86.56% avg_auc=88.89%
Best model saved!! Metric=5.859863921457929!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.462829 Test loss=0.402821 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4458056688308716
[5/24] Train loss=0.43645310401916504
[10/24] Train loss=0.445986270904541
[15/24] Train loss=0.4305035173892975
[20/24] Train loss=0.41356369853019714
Test set avg_accuracy=84.10% avg_sensitivity=72.65%, avg_specificity=88.37% avg_auc=89.69%
Best model saved!! Metric=8.809953398900902!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.440739 Test loss=0.384566 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4235134720802307
[5/24] Train loss=0.418828547000885
[10/24] Train loss=0.42671144008636475
[15/24] Train loss=0.4119350016117096
[20/24] Train loss=0.3969866931438446
Test set avg_accuracy=84.57% avg_sensitivity=72.65%, avg_specificity=89.01% avg_auc=90.00%
Best model saved!! Metric=10.22911835117695!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.422258 Test loss=0.373137 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4023433327674866
[5/24] Train loss=0.39739924669265747
[10/24] Train loss=0.40508970618247986
[15/24] Train loss=0.400834858417511
[20/24] Train loss=0.3704560101032257
Test set avg_accuracy=85.21% avg_sensitivity=72.65%, avg_specificity=89.89% avg_auc=90.46%
Best model saved!! Metric=12.204681149637523!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.404018 Test loss=0.362165 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3950260877609253
[5/24] Train loss=0.38592177629470825
[10/24] Train loss=0.39426058530807495
[15/24] Train loss=0.3855029344558716
[20/24] Train loss=0.3578775227069855
Test set avg_accuracy=85.78% avg_sensitivity=69.67%, avg_specificity=91.78% avg_auc=90.94%
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.390097 Test loss=0.349403 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.37888675928115845
[5/24] Train loss=0.36873894929885864
[10/24] Train loss=0.3761526346206665
[15/24] Train loss=0.3683682382106781
[20/24] Train loss=0.3483407497406006
Test set avg_accuracy=85.65% avg_sensitivity=72.07%, avg_specificity=90.71% avg_auc=91.07%
Best model saved!! Metric=13.497860720309319!!
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.376830 Test loss=0.344495 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3709287941455841
[5/24] Train loss=0.36215460300445557
[10/24] Train loss=0.3717890679836273
[15/24] Train loss=0.3619922697544098
[20/24] Train loss=0.3382011651992798
Test set avg_accuracy=85.70% avg_sensitivity=74.66%, avg_specificity=89.81% avg_auc=91.37%
Best model saved!! Metric=15.552141091834159!!
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.367890 Test loss=0.342920 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3603702187538147
[5/24] Train loss=0.35026270151138306
[10/24] Train loss=0.36579880118370056
[15/24] Train loss=0.3515316843986511
[20/24] Train loss=0.3257525861263275
Test set avg_accuracy=85.12% avg_sensitivity=78.21%, avg_specificity=87.69% avg_auc=91.35%
Best model saved!! Metric=16.365149781805357!!
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.357886 Test loss=0.349438 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3499573767185211
[5/24] Train loss=0.35196027159690857
[10/24] Train loss=0.3531445264816284
[15/24] Train loss=0.34081950783729553
[20/24] Train loss=0.32036274671554565
Test set avg_accuracy=85.03% avg_sensitivity=78.45%, avg_specificity=87.47% avg_auc=91.47%
Best model saved!! Metric=16.428895055226334!!
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.349735 Test loss=0.345127 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.34413638710975647
[5/24] Train loss=0.3390134274959564
[10/24] Train loss=0.34189581871032715
[15/24] Train loss=0.33497893810272217
[20/24] Train loss=0.3144631087779999
Test set avg_accuracy=84.57% avg_sensitivity=79.89%, avg_specificity=86.31% avg_auc=91.48%
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.343291 Test loss=0.352142 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3284927308559418
[5/24] Train loss=0.33241093158721924
[10/24] Train loss=0.3306938111782074
[15/24] Train loss=0.32979679107666016
[20/24] Train loss=0.3081618547439575
Test set avg_accuracy=86.63% avg_sensitivity=71.79%, avg_specificity=92.16% avg_auc=92.07%
Best model saved!! Metric=16.638392651449465!!
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.336866 Test loss=0.318633 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3205706477165222
[5/24] Train loss=0.3268240988254547
[10/24] Train loss=0.329233318567276
[15/24] Train loss=0.32207486033439636
[20/24] Train loss=0.295989066362381
Test set avg_accuracy=86.61% avg_sensitivity=70.63%, avg_specificity=92.57% avg_auc=92.15%
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.329248 Test loss=0.314485 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3262830674648285
[5/24] Train loss=0.3295266032218933
[10/24] Train loss=0.3252624571323395
[15/24] Train loss=0.3205692172050476
[20/24] Train loss=0.2893885374069214
Test set avg_accuracy=86.39% avg_sensitivity=64.16%, avg_specificity=94.67% avg_auc=91.75%
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.324620 Test loss=0.323469 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3215404152870178
[5/24] Train loss=0.32927337288856506
[10/24] Train loss=0.32076555490493774
[15/24] Train loss=0.3109667897224426
[20/24] Train loss=0.2793375551700592
Test set avg_accuracy=86.73% avg_sensitivity=68.33%, avg_specificity=93.58% avg_auc=92.25%
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.319137 Test loss=0.310249 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3074023127555847
[5/24] Train loss=0.3214859068393707
[10/24] Train loss=0.31213968992233276
[15/24] Train loss=0.3104967176914215
[20/24] Train loss=0.2806694209575653
Test set avg_accuracy=86.42% avg_sensitivity=62.62%, avg_specificity=95.28% avg_auc=91.95%
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.315732 Test loss=0.319994 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.30408045649528503
[5/24] Train loss=0.3212226331233978
[10/24] Train loss=0.312195748090744
[15/24] Train loss=0.30068013072013855
[20/24] Train loss=0.2790277302265167
Test set avg_accuracy=84.66% avg_sensitivity=49.86%, avg_specificity=97.62% avg_auc=91.63%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.310202 Test loss=0.348876 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.29329580068588257
[5/24] Train loss=0.3169589638710022
[10/24] Train loss=0.30184727907180786
[15/24] Train loss=0.30360502004623413
[20/24] Train loss=0.27634620666503906
Test set avg_accuracy=83.32% avg_sensitivity=43.76%, avg_specificity=98.05% avg_auc=91.00%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.305212 Test loss=0.371496 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2960474193096161
[5/24] Train loss=0.30068013072013855
[10/24] Train loss=0.29539528489112854
[15/24] Train loss=0.2896083891391754
[20/24] Train loss=0.2636367678642273
Test set avg_accuracy=83.20% avg_sensitivity=44.24%, avg_specificity=97.71% avg_auc=90.69%
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.298218 Test loss=0.381794 Current lr=[0.000210185142098938]

[0/24] Train loss=0.28318578004837036
[5/24] Train loss=0.2984158396720886
[10/24] Train loss=0.2908022701740265
[15/24] Train loss=0.2894901931285858
[20/24] Train loss=0.2681824564933777
Test set avg_accuracy=85.82% avg_sensitivity=75.00%, avg_specificity=89.85% avg_auc=91.72%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.294254 Test loss=0.321400 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.27704310417175293
[5/24] Train loss=0.30504539608955383
[10/24] Train loss=0.2928336262702942
[15/24] Train loss=0.28096768260002136
[20/24] Train loss=0.25973448157310486
Test set avg_accuracy=83.48% avg_sensitivity=47.31%, avg_specificity=96.94% avg_auc=89.18%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.291485 Test loss=0.376106 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.27792325615882874
[5/24] Train loss=0.28683802485466003
[10/24] Train loss=0.2773520350456238
[15/24] Train loss=0.2759077847003937
[20/24] Train loss=0.2547134757041931
Test set avg_accuracy=86.02% avg_sensitivity=59.07%, avg_specificity=96.05% avg_auc=91.58%
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.283316 Test loss=0.328611 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.27306219935417175
[5/24] Train loss=0.2823808789253235
[10/24] Train loss=0.2804649770259857
[15/24] Train loss=0.26455312967300415
[20/24] Train loss=0.2481120228767395
Test set avg_accuracy=84.23% avg_sensitivity=51.68%, avg_specificity=96.35% avg_auc=90.86%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.277384 Test loss=0.352934 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.27739977836608887
[5/24] Train loss=0.2703022062778473
[10/24] Train loss=0.278665155172348
[15/24] Train loss=0.2687450051307678
[20/24] Train loss=0.24935510754585266
Test set avg_accuracy=85.14% avg_sensitivity=58.49%, avg_specificity=95.07% avg_auc=90.30%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.274908 Test loss=0.345192 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.24900466203689575
[5/24] Train loss=0.2575690746307373
[10/24] Train loss=0.26953601837158203
[15/24] Train loss=0.26130211353302
[20/24] Train loss=0.2477971464395523
Test set avg_accuracy=79.84% avg_sensitivity=28.55%, avg_specificity=98.95% avg_auc=84.43%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.267234 Test loss=0.497670 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.26636776328086853
[5/24] Train loss=0.24982675909996033
[10/24] Train loss=0.27751532196998596
[15/24] Train loss=0.2532975673675537
[20/24] Train loss=0.2385382205247879
Test set avg_accuracy=80.16% avg_sensitivity=29.99%, avg_specificity=98.84% avg_auc=82.61%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.265582 Test loss=0.456186 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.265134334564209
[5/24] Train loss=0.26005858182907104
[10/24] Train loss=0.26882728934288025
[15/24] Train loss=0.2683732807636261
[20/24] Train loss=0.2352788895368576
Test set avg_accuracy=83.82% avg_sensitivity=48.70%, avg_specificity=96.89% avg_auc=89.89%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.262522 Test loss=0.366575 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.25255656242370605
[5/24] Train loss=0.2655376195907593
[10/24] Train loss=0.2670198678970337
[15/24] Train loss=0.2654419541358948
[20/24] Train loss=0.24418814480304718
Test set avg_accuracy=85.66% avg_sensitivity=56.09%, avg_specificity=96.68% avg_auc=91.40%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.260974 Test loss=0.334973 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.24409432709217072
[5/24] Train loss=0.24386867880821228
[10/24] Train loss=0.256095290184021
[15/24] Train loss=0.2424999475479126
[20/24] Train loss=0.23270860314369202
Test set avg_accuracy=78.05% avg_sensitivity=21.11%, avg_specificity=99.25% avg_auc=81.41%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.252277 Test loss=0.581473 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.25585728883743286
[5/24] Train loss=0.24447891116142273
[10/24] Train loss=0.24771857261657715
[15/24] Train loss=0.25506335496902466
[20/24] Train loss=0.23917506635189056
Test set avg_accuracy=86.48% avg_sensitivity=65.26%, avg_specificity=94.39% avg_auc=91.55%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.253910 Test loss=0.321672 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.23522330820560455
[5/24] Train loss=0.23346377909183502
[10/24] Train loss=0.2504105865955353
[15/24] Train loss=0.2356342077255249
[20/24] Train loss=0.22259865701198578
Test set avg_accuracy=79.21% avg_sensitivity=24.81%, avg_specificity=99.46% avg_auc=83.20%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.248923 Test loss=0.527430 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2501579225063324
[5/24] Train loss=0.23468153178691864
[10/24] Train loss=0.2488747388124466
[15/24] Train loss=0.2520601451396942
[20/24] Train loss=0.2384568303823471
Test set avg_accuracy=83.76% avg_sensitivity=65.79%, avg_specificity=90.46% avg_auc=87.72%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.248298 Test loss=0.381054 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.23820802569389343
[5/24] Train loss=0.22564205527305603
[10/24] Train loss=0.2557108998298645
[15/24] Train loss=0.2505846619606018
[20/24] Train loss=0.22691002488136292
Test set avg_accuracy=85.59% avg_sensitivity=57.63%, avg_specificity=96.00% avg_auc=90.82%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.245031 Test loss=0.340644 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2358892261981964
[5/24] Train loss=0.23640264570713043
[10/24] Train loss=0.25374507904052734
[15/24] Train loss=0.2372617870569229
[20/24] Train loss=0.228165864944458
Test set avg_accuracy=81.33% avg_sensitivity=35.22%, avg_specificity=98.50% avg_auc=86.17%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.242642 Test loss=0.461928 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.23246324062347412
[5/24] Train loss=0.21814490854740143
[10/24] Train loss=0.2548390030860901
[15/24] Train loss=0.23235821723937988
[20/24] Train loss=0.22519253194332123
Test set avg_accuracy=84.91% avg_sensitivity=54.13%, avg_specificity=96.37% avg_auc=88.79%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.234595 Test loss=0.368609 Current lr=[0.00029967723776099]

[0/24] Train loss=0.23579296469688416
[5/24] Train loss=0.21965160965919495
[10/24] Train loss=0.24645504355430603
[15/24] Train loss=0.2507953345775604
[20/24] Train loss=0.2176361232995987
Test set avg_accuracy=85.95% avg_sensitivity=65.31%, avg_specificity=93.64% avg_auc=90.51%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.233103 Test loss=0.336050 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2412276715040207
[5/24] Train loss=0.23756606876850128
[10/24] Train loss=0.24598947167396545
[15/24] Train loss=0.22860270738601685
[20/24] Train loss=0.22043712437152863
Test set avg_accuracy=78.01% avg_sensitivity=22.26%, avg_specificity=98.77% avg_auc=78.62%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.239483 Test loss=0.630289 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2528739869594574
[5/24] Train loss=0.22363366186618805
[10/24] Train loss=0.23725654184818268
[15/24] Train loss=0.23737600445747375
[20/24] Train loss=0.23188082873821259
Test set avg_accuracy=82.21% avg_sensitivity=46.79%, avg_specificity=95.41% avg_auc=85.65%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.240597 Test loss=0.435879 Current lr=[0.000299720220882401]

[0/24] Train loss=0.24443817138671875
[5/24] Train loss=0.23659011721611023
[10/24] Train loss=0.2699417769908905
[15/24] Train loss=0.2152678221464157
[20/24] Train loss=0.21321222186088562
Test set avg_accuracy=83.33% avg_sensitivity=50.72%, avg_specificity=95.48% avg_auc=85.64%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.240864 Test loss=0.439159 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2299012392759323
[5/24] Train loss=0.2210122048854828
[10/24] Train loss=0.23612681031227112
[15/24] Train loss=0.21719740331172943
[20/24] Train loss=0.22032633423805237
Test set avg_accuracy=86.77% avg_sensitivity=68.57%, avg_specificity=93.55% avg_auc=91.31%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.228532 Test loss=0.324274 Current lr=[0.000298904600941902]

[0/24] Train loss=0.22594311833381653
[5/24] Train loss=0.22650602459907532
[10/24] Train loss=0.23045586049556732
[15/24] Train loss=0.21103715896606445
[20/24] Train loss=0.21206863224506378
Test set avg_accuracy=77.20% avg_sensitivity=17.61%, avg_specificity=99.39% avg_auc=81.09%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.227764 Test loss=0.643872 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.23015017807483673
[5/24] Train loss=0.21298354864120483
[10/24] Train loss=0.23384985327720642
[15/24] Train loss=0.21436932682991028
[20/24] Train loss=0.20508739352226257
Test set avg_accuracy=81.64% avg_sensitivity=48.94%, avg_specificity=93.82% avg_auc=83.30%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.225146 Test loss=0.440105 Current lr=[0.000297555943323901]

[0/24] Train loss=0.20812614262104034
[5/24] Train loss=0.2277754843235016
[10/24] Train loss=0.21957656741142273
[15/24] Train loss=0.21742121875286102
[20/24] Train loss=0.21514223515987396
Test set avg_accuracy=81.80% avg_sensitivity=40.45%, avg_specificity=97.19% avg_auc=85.69%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.225663 Test loss=0.468451 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2324790507555008
[5/24] Train loss=0.2241562008857727
[10/24] Train loss=0.23520570993423462
[15/24] Train loss=0.21848924458026886
[20/24] Train loss=0.21027182042598724
Test set avg_accuracy=75.57% avg_sensitivity=11.66%, avg_specificity=99.37% avg_auc=76.69%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.226125 Test loss=0.655026 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.21836453676223755
[5/24] Train loss=0.22702810168266296
[10/24] Train loss=0.2325422465801239
[15/24] Train loss=0.23291440308094025
[20/24] Train loss=0.21981418132781982
Test set avg_accuracy=85.95% avg_sensitivity=59.26%, avg_specificity=95.89% avg_auc=89.62%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.230812 Test loss=0.350917 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.21255674958229065
[5/24] Train loss=0.21536728739738464
[10/24] Train loss=0.23221999406814575
[15/24] Train loss=0.22411033511161804
[20/24] Train loss=0.2235570102930069
Test set avg_accuracy=83.24% avg_sensitivity=49.81%, avg_specificity=95.69% avg_auc=88.36%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.226345 Test loss=0.394476 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.22298076748847961
[5/24] Train loss=0.2076023519039154
[10/24] Train loss=0.21848338842391968
[15/24] Train loss=0.2234414964914322
[20/24] Train loss=0.21237000823020935
Test set avg_accuracy=85.74% avg_sensitivity=71.83%, avg_specificity=90.92% avg_auc=91.32%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.219954 Test loss=0.324942 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.21328678727149963
[5/24] Train loss=0.2014891356229782
[10/24] Train loss=0.21703648567199707
[15/24] Train loss=0.21126486361026764
[20/24] Train loss=0.20860114693641663
Test set avg_accuracy=79.80% avg_sensitivity=32.92%, avg_specificity=97.27% avg_auc=82.45%
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.218521 Test loss=0.527130 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2198752462863922
[5/24] Train loss=0.20760175585746765
[10/24] Train loss=0.21427638828754425
[15/24] Train loss=0.20896053314208984
[20/24] Train loss=0.22286537289619446
Test set avg_accuracy=84.43% avg_sensitivity=79.51%, avg_specificity=86.26% avg_auc=90.98%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.217975 Test loss=0.355476 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2099800854921341
[5/24] Train loss=0.21230778098106384
[10/24] Train loss=0.21519236266613007
[15/24] Train loss=0.21450315415859222
[20/24] Train loss=0.20281438529491425
Test set avg_accuracy=83.67% avg_sensitivity=55.81%, avg_specificity=94.05% avg_auc=86.83%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.214982 Test loss=0.394258 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.201524019241333
[5/24] Train loss=0.20825865864753723
[10/24] Train loss=0.22192679345607758
[15/24] Train loss=0.22002005577087402
[20/24] Train loss=0.21412166953086853
Test set avg_accuracy=83.66% avg_sensitivity=52.40%, avg_specificity=95.30% avg_auc=87.58%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.217137 Test loss=0.401119 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.1998041868209839
[5/24] Train loss=0.19915488362312317
[10/24] Train loss=0.2199186384677887
[15/24] Train loss=0.20752552151679993
[20/24] Train loss=0.19915546476840973
Test set avg_accuracy=85.56% avg_sensitivity=72.70%, avg_specificity=90.35% avg_auc=90.33%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.212984 Test loss=0.342343 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.21696661412715912
[5/24] Train loss=0.20683377981185913
[10/24] Train loss=0.22572028636932373
[15/24] Train loss=0.21679839491844177
[20/24] Train loss=0.1968705952167511
Test set avg_accuracy=81.60% avg_sensitivity=36.13%, avg_specificity=98.53% avg_auc=82.62%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.216491 Test loss=0.515299 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2027549147605896
[5/24] Train loss=0.20317918062210083
[10/24] Train loss=0.22412334382534027
[15/24] Train loss=0.20631766319274902
[20/24] Train loss=0.21653300523757935
Test set avg_accuracy=84.01% avg_sensitivity=50.96%, avg_specificity=96.32% avg_auc=87.54%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.212876 Test loss=0.399971 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2139514833688736
[5/24] Train loss=0.2030285745859146
[10/24] Train loss=0.21460860967636108
[15/24] Train loss=0.20284542441368103
[20/24] Train loss=0.19803106784820557
Test set avg_accuracy=85.00% avg_sensitivity=79.85%, avg_specificity=86.92% avg_auc=90.94%
Best model saved!! Metric=16.70229437945116!!
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.209726 Test loss=0.353490 Current lr=[0.000276307469034998]

[0/24] Train loss=0.20053718984127045
[5/24] Train loss=0.19651272892951965
[10/24] Train loss=0.2228853404521942
[15/24] Train loss=0.19799739122390747
[20/24] Train loss=0.19591011106967926
Test set avg_accuracy=84.05% avg_sensitivity=79.65%, avg_specificity=85.69% avg_auc=90.34%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.205171 Test loss=0.371867 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.19401627779006958
[5/24] Train loss=0.20245110988616943
[10/24] Train loss=0.21244317293167114
[15/24] Train loss=0.2007398009300232
[20/24] Train loss=0.18963894248008728
Test set avg_accuracy=74.74% avg_sensitivity=81.00%, avg_specificity=72.41% avg_auc=85.26%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.208472 Test loss=0.541632 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.20571282505989075
[5/24] Train loss=0.19606228172779083
[10/24] Train loss=0.22376687824726105
[15/24] Train loss=0.19750119745731354
[20/24] Train loss=0.18921160697937012
Test set avg_accuracy=84.56% avg_sensitivity=62.43%, avg_specificity=92.80% avg_auc=88.51%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.206542 Test loss=0.374008 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2018018364906311
[5/24] Train loss=0.1973370909690857
[10/24] Train loss=0.21039363741874695
[15/24] Train loss=0.20184466242790222
[20/24] Train loss=0.18409189581871033
Test set avg_accuracy=81.64% avg_sensitivity=66.60%, avg_specificity=87.24% avg_auc=86.42%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.202853 Test loss=0.419058 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.20122773945331573
[5/24] Train loss=0.1904078871011734
[10/24] Train loss=0.2177148312330246
[15/24] Train loss=0.20296229422092438
[20/24] Train loss=0.1973820924758911
Test set avg_accuracy=82.25% avg_sensitivity=84.07%, avg_specificity=81.58% avg_auc=90.27%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.202960 Test loss=0.395712 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.19403663277626038
[5/24] Train loss=0.19744698703289032
[10/24] Train loss=0.21065783500671387
[15/24] Train loss=0.19197385013103485
[20/24] Train loss=0.18285275995731354
Test set avg_accuracy=86.09% avg_sensitivity=69.15%, avg_specificity=92.41% avg_auc=90.57%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.198590 Test loss=0.337900 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.19077721238136292
[5/24] Train loss=0.19187313318252563
[10/24] Train loss=0.20279176533222198
[15/24] Train loss=0.18768012523651123
[20/24] Train loss=0.18062108755111694
Test set avg_accuracy=82.70% avg_sensitivity=81.72%, avg_specificity=83.06% avg_auc=90.09%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.196893 Test loss=0.392038 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.18788252770900726
[5/24] Train loss=0.1815812885761261
[10/24] Train loss=0.20017750561237335
[15/24] Train loss=0.19056206941604614
[20/24] Train loss=0.19235621392726898
Test set avg_accuracy=85.59% avg_sensitivity=73.18%, avg_specificity=90.21% avg_auc=90.53%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.196700 Test loss=0.346404 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.19780968129634857
[5/24] Train loss=0.19401584565639496
[10/24] Train loss=0.20067821443080902
[15/24] Train loss=0.18471811711788177
[20/24] Train loss=0.18185685575008392
Test set avg_accuracy=86.07% avg_sensitivity=70.01%, avg_specificity=92.05% avg_auc=90.79%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.198080 Test loss=0.333753 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.18533873558044434
[5/24] Train loss=0.18399293720722198
[10/24] Train loss=0.19824282824993134
[15/24] Train loss=0.2022310495376587
[20/24] Train loss=0.18547523021697998
Test set avg_accuracy=85.33% avg_sensitivity=69.24%, avg_specificity=91.32% avg_auc=89.98%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.197641 Test loss=0.344999 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.20961609482765198
[5/24] Train loss=0.19656029343605042
[10/24] Train loss=0.19802945852279663
[15/24] Train loss=0.1905737668275833
[20/24] Train loss=0.21196924149990082
Test set avg_accuracy=78.40% avg_sensitivity=85.89%, avg_specificity=75.61% avg_auc=87.97%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.200205 Test loss=0.493592 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.19739121198654175
[5/24] Train loss=0.1883026361465454
[10/24] Train loss=0.20448213815689087
[15/24] Train loss=0.18862640857696533
[20/24] Train loss=0.17815499007701874
Test set avg_accuracy=86.16% avg_sensitivity=77.11%, avg_specificity=89.53% avg_auc=91.60%
Best model saved!! Metric=18.395277839182953!!
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.194951 Test loss=0.331253 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.18959186971187592
[5/24] Train loss=0.19076021015644073
[10/24] Train loss=0.20444944500923157
[15/24] Train loss=0.18695679306983948
[20/24] Train loss=0.1920117735862732
Test set avg_accuracy=61.30% avg_sensitivity=92.13%, avg_specificity=49.82% avg_auc=82.31%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.194962 Test loss=0.773045 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.1897459328174591
[5/24] Train loss=0.19218643009662628
[10/24] Train loss=0.19890640676021576
[15/24] Train loss=0.2029949575662613
[20/24] Train loss=0.1895616054534912
Test set avg_accuracy=83.55% avg_sensitivity=83.01%, avg_specificity=83.76% avg_auc=91.00%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.197297 Test loss=0.379429 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.1812400221824646
[5/24] Train loss=0.1813160926103592
[10/24] Train loss=0.2001960277557373
[15/24] Train loss=0.1967744678258896
[20/24] Train loss=0.19425660371780396
Test set avg_accuracy=85.10% avg_sensitivity=75.82%, avg_specificity=88.56% avg_auc=90.08%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.193516 Test loss=0.361770 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.1841331273317337
[5/24] Train loss=0.17875659465789795
[10/24] Train loss=0.2154315710067749
[15/24] Train loss=0.19638113677501678
[20/24] Train loss=0.20041728019714355
Test set avg_accuracy=84.08% avg_sensitivity=80.47%, avg_specificity=85.42% avg_auc=90.09%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.196967 Test loss=0.377486 Current lr=[0.000224838296036774]

[0/24] Train loss=0.18721280992031097
[5/24] Train loss=0.18784648180007935
[10/24] Train loss=0.19902577996253967
[15/24] Train loss=0.18790145218372345
[20/24] Train loss=0.1852487027645111
Test set avg_accuracy=85.74% avg_sensitivity=66.07%, avg_specificity=93.07% avg_auc=88.59%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.192482 Test loss=0.358464 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.18631917238235474
[5/24] Train loss=0.17865204811096191
[10/24] Train loss=0.19992899894714355
[15/24] Train loss=0.20102337002754211
[20/24] Train loss=0.1835254728794098
Test set avg_accuracy=86.08% avg_sensitivity=68.71%, avg_specificity=92.55% avg_auc=89.88%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.188769 Test loss=0.344384 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.1767880916595459
[5/24] Train loss=0.17784422636032104
[10/24] Train loss=0.20333604514598846
[15/24] Train loss=0.18902188539505005
[20/24] Train loss=0.1860823780298233
Test set avg_accuracy=85.34% avg_sensitivity=73.61%, avg_specificity=89.71% avg_auc=90.10%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.188445 Test loss=0.350832 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.18052570521831512
[5/24] Train loss=0.18751280009746552
[10/24] Train loss=0.19723279774188995
[15/24] Train loss=0.1871497631072998
[20/24] Train loss=0.17756284773349762
Test set avg_accuracy=81.37% avg_sensitivity=36.42%, avg_specificity=98.11% avg_auc=80.86%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.187947 Test loss=0.520020 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.1788150519132614
[5/24] Train loss=0.1752997189760208
[10/24] Train loss=0.19105024635791779
[15/24] Train loss=0.17971250414848328
[20/24] Train loss=0.16875706613063812
Test set avg_accuracy=84.52% avg_sensitivity=54.70%, avg_specificity=95.62% avg_auc=87.57%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.186226 Test loss=0.382156 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.17234723269939423
[5/24] Train loss=0.18141627311706543
[10/24] Train loss=0.17964328825473785
[15/24] Train loss=0.18533740937709808
[20/24] Train loss=0.17398007214069366
Test set avg_accuracy=85.10% avg_sensitivity=71.98%, avg_specificity=89.99% avg_auc=89.60%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.186846 Test loss=0.358378 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.18877385556697845
[5/24] Train loss=0.17922323942184448
[10/24] Train loss=0.20472770929336548
[15/24] Train loss=0.16829627752304077
[20/24] Train loss=0.17782293260097504
Test set avg_accuracy=84.99% avg_sensitivity=56.96%, avg_specificity=95.43% avg_auc=88.10%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.187256 Test loss=0.393417 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.17195086181163788
[5/24] Train loss=0.17408619821071625
[10/24] Train loss=0.19448964297771454
[15/24] Train loss=0.17536450922489166
[20/24] Train loss=0.17613324522972107
Test set avg_accuracy=85.23% avg_sensitivity=56.14%, avg_specificity=96.07% avg_auc=87.89%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.185281 Test loss=0.375728 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.17265816032886505
[5/24] Train loss=0.19147013127803802
[10/24] Train loss=0.19872742891311646
[15/24] Train loss=0.17538020014762878
[20/24] Train loss=0.16589276492595673
Test set avg_accuracy=84.99% avg_sensitivity=57.01%, avg_specificity=95.41% avg_auc=86.60%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.183823 Test loss=0.388531 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.17669503390789032
[5/24] Train loss=0.17765593528747559
[10/24] Train loss=0.19664272665977478
[15/24] Train loss=0.17340174317359924
[20/24] Train loss=0.1614263355731964
Test set avg_accuracy=86.00% avg_sensitivity=68.57%, avg_specificity=92.49% avg_auc=89.11%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.179533 Test loss=0.356980 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.17635710537433624
[5/24] Train loss=0.16732223331928253
[10/24] Train loss=0.188863143324852
[15/24] Train loss=0.16177713871002197
[20/24] Train loss=0.16954131424427032
Test set avg_accuracy=86.54% avg_sensitivity=67.03%, avg_specificity=93.80% avg_auc=89.79%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.175769 Test loss=0.341702 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.16895225644111633
[5/24] Train loss=0.16812685132026672
[10/24] Train loss=0.18254698812961578
[15/24] Train loss=0.16456545889377594
[20/24] Train loss=0.16753722727298737
Test set avg_accuracy=85.64% avg_sensitivity=69.96%, avg_specificity=91.48% avg_auc=89.84%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.173673 Test loss=0.342530 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.16515567898750305
[5/24] Train loss=0.1660517454147339
[10/24] Train loss=0.18837086856365204
[15/24] Train loss=0.16026021540164948
[20/24] Train loss=0.16150681674480438
Test set avg_accuracy=86.54% avg_sensitivity=71.07%, avg_specificity=92.30% avg_auc=90.04%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.171941 Test loss=0.337853 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.16654139757156372
[5/24] Train loss=0.16740605235099792
[10/24] Train loss=0.1936381757259369
[15/24] Train loss=0.16490304470062256
[20/24] Train loss=0.16746674478054047
Test set avg_accuracy=81.61% avg_sensitivity=37.76%, avg_specificity=97.94% avg_auc=79.66%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.173156 Test loss=0.561133 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.17050346732139587
[5/24] Train loss=0.15538519620895386
[10/24] Train loss=0.18084943294525146
[15/24] Train loss=0.1738141030073166
[20/24] Train loss=0.1666926145553589
Test set avg_accuracy=84.66% avg_sensitivity=55.13%, avg_specificity=95.66% avg_auc=86.13%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.174187 Test loss=0.398457 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.1678592413663864
[5/24] Train loss=0.16231946647167206
[10/24] Train loss=0.1827346831560135
[15/24] Train loss=0.16811636090278625
[20/24] Train loss=0.16423673927783966
Test set avg_accuracy=82.70% avg_sensitivity=45.35%, avg_specificity=96.60% avg_auc=84.54%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.173373 Test loss=0.451281 Current lr=[0.000156543481933168]

[0/24] Train loss=0.16473716497421265
[5/24] Train loss=0.17743948101997375
[10/24] Train loss=0.17717014253139496
[15/24] Train loss=0.16176989674568176
[20/24] Train loss=0.16651521623134613
Test set avg_accuracy=83.79% avg_sensitivity=51.68%, avg_specificity=95.75% avg_auc=87.39%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.171429 Test loss=0.408927 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1629236340522766
[5/24] Train loss=0.1666586697101593
[10/24] Train loss=0.18482902646064758
[15/24] Train loss=0.17283688485622406
[20/24] Train loss=0.1688167303800583
Test set avg_accuracy=84.80% avg_sensitivity=54.94%, avg_specificity=95.93% avg_auc=86.52%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.172549 Test loss=0.396385 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.16100147366523743
[5/24] Train loss=0.17446203529834747
[10/24] Train loss=0.18267160654067993
[15/24] Train loss=0.1661924570798874
[20/24] Train loss=0.16089488565921783
Test set avg_accuracy=85.60% avg_sensitivity=65.12%, avg_specificity=93.23% avg_auc=88.53%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.173870 Test loss=0.371123 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.16830410063266754
[5/24] Train loss=0.1641303300857544
[10/24] Train loss=0.1883898675441742
[15/24] Train loss=0.16779562830924988
[20/24] Train loss=0.16530466079711914
Test set avg_accuracy=83.65% avg_sensitivity=75.96%, avg_specificity=86.51% avg_auc=89.76%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.176846 Test loss=0.375575 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1647794246673584
[5/24] Train loss=0.17739123106002808
[10/24] Train loss=0.18310779333114624
[15/24] Train loss=0.16029611229896545
[20/24] Train loss=0.15965552628040314
Test set avg_accuracy=85.70% avg_sensitivity=69.77%, avg_specificity=91.64% avg_auc=90.18%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.175800 Test loss=0.348322 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16885945200920105
[5/24] Train loss=0.17321152985095978
[10/24] Train loss=0.17759399116039276
[15/24] Train loss=0.16538859903812408
[20/24] Train loss=0.16992531716823578
Test set avg_accuracy=85.49% avg_sensitivity=59.02%, avg_specificity=95.35% avg_auc=87.96%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.172572 Test loss=0.388734 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.16365768015384674
[5/24] Train loss=0.16726651787757874
[10/24] Train loss=0.17154532670974731
[15/24] Train loss=0.16378386318683624
[20/24] Train loss=0.1707373410463333
Test set avg_accuracy=84.91% avg_sensitivity=53.02%, avg_specificity=96.78% avg_auc=86.36%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.171174 Test loss=0.404328 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1610751748085022
[5/24] Train loss=0.16100268065929413
[10/24] Train loss=0.17859898507595062
[15/24] Train loss=0.1615045666694641
[20/24] Train loss=0.16055928170681
Test set avg_accuracy=85.17% avg_sensitivity=57.29%, avg_specificity=95.55% avg_auc=87.91%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.166100 Test loss=0.384713 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15581545233726501
[5/24] Train loss=0.15963895618915558
[10/24] Train loss=0.1694948673248291
[15/24] Train loss=0.15989768505096436
[20/24] Train loss=0.15845854580402374
Test set avg_accuracy=85.87% avg_sensitivity=71.55%, avg_specificity=91.21% avg_auc=90.62%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.164940 Test loss=0.337863 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.15962575376033783
[5/24] Train loss=0.15817807614803314
[10/24] Train loss=0.16251720488071442
[15/24] Train loss=0.15594632923603058
[20/24] Train loss=0.1620715856552124
Test set avg_accuracy=84.71% avg_sensitivity=55.37%, avg_specificity=95.64% avg_auc=87.24%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.165132 Test loss=0.382736 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15645119547843933
[5/24] Train loss=0.1523553878068924
[10/24] Train loss=0.1823427975177765
[15/24] Train loss=0.14970315992832184
[20/24] Train loss=0.1658453494310379
Test set avg_accuracy=86.11% avg_sensitivity=63.10%, avg_specificity=94.67% avg_auc=90.23%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.164891 Test loss=0.340831 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15718857944011688
[5/24] Train loss=0.1557401865720749
[10/24] Train loss=0.1796892136335373
[15/24] Train loss=0.1614474356174469
[20/24] Train loss=0.15901325643062592
Test set avg_accuracy=85.20% avg_sensitivity=63.39%, avg_specificity=93.32% avg_auc=89.40%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.162535 Test loss=0.357856 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15509377419948578
[5/24] Train loss=0.1538122296333313
[10/24] Train loss=0.16570715606212616
[15/24] Train loss=0.15039989352226257
[20/24] Train loss=0.16104047000408173
Test set avg_accuracy=84.75% avg_sensitivity=69.39%, avg_specificity=90.48% avg_auc=89.74%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.164174 Test loss=0.364116 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.15987184643745422
[5/24] Train loss=0.15620413422584534
[10/24] Train loss=0.1678396612405777
[15/24] Train loss=0.1634284108877182
[20/24] Train loss=0.1563768982887268
Test set avg_accuracy=84.62% avg_sensitivity=72.98%, avg_specificity=88.96% avg_auc=89.68%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.163189 Test loss=0.366313 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15828503668308258
[5/24] Train loss=0.1551673859357834
[10/24] Train loss=0.17766037583351135
[15/24] Train loss=0.16072379052639008
[20/24] Train loss=0.16326835751533508
Test set avg_accuracy=82.62% avg_sensitivity=55.42%, avg_specificity=92.74% avg_auc=87.03%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.163648 Test loss=0.412363 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.14883308112621307
[5/24] Train loss=0.1601846069097519
[10/24] Train loss=0.1617918759584427
[15/24] Train loss=0.1512620747089386
[20/24] Train loss=0.15715231001377106
Test set avg_accuracy=85.55% avg_sensitivity=78.07%, avg_specificity=88.33% avg_auc=90.82%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.159403 Test loss=0.353465 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.15745215117931366
[5/24] Train loss=0.14874491095542908
[10/24] Train loss=0.1600712239742279
[15/24] Train loss=0.15562893450260162
[20/24] Train loss=0.1577444225549698
Test set avg_accuracy=84.97% avg_sensitivity=78.60%, avg_specificity=87.35% avg_auc=90.29%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.157279 Test loss=0.363897 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1492803692817688
[5/24] Train loss=0.14670251309871674
[10/24] Train loss=0.15754328668117523
[15/24] Train loss=0.1485593467950821
[20/24] Train loss=0.15213866531848907
Test set avg_accuracy=85.98% avg_sensitivity=72.84%, avg_specificity=90.87% avg_auc=91.04%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.155261 Test loss=0.338252 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.15009938180446625
[5/24] Train loss=0.14436973631381989
[10/24] Train loss=0.16667307913303375
[15/24] Train loss=0.14646810293197632
[20/24] Train loss=0.1555667370557785
Test set avg_accuracy=85.99% avg_sensitivity=71.11%, avg_specificity=91.53% avg_auc=90.02%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.155775 Test loss=0.346857 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14471283555030823
[5/24] Train loss=0.14866219460964203
[10/24] Train loss=0.1607258915901184
[15/24] Train loss=0.14557085931301117
[20/24] Train loss=0.15196478366851807
Test set avg_accuracy=86.05% avg_sensitivity=71.21%, avg_specificity=91.58% avg_auc=89.41%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.154377 Test loss=0.357454 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14572420716285706
[5/24] Train loss=0.14750762283802032
[10/24] Train loss=0.15853020548820496
[15/24] Train loss=0.1396479606628418
[20/24] Train loss=0.1490253061056137
Test set avg_accuracy=85.08% avg_sensitivity=63.96%, avg_specificity=92.94% avg_auc=89.01%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.152597 Test loss=0.372781 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14039047062397003
[5/24] Train loss=0.14478808641433716
[10/24] Train loss=0.15634915232658386
[15/24] Train loss=0.1401871293783188
[20/24] Train loss=0.1482919156551361
Test set avg_accuracy=86.25% avg_sensitivity=68.86%, avg_specificity=92.73% avg_auc=90.10%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.152440 Test loss=0.350771 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14851020276546478
[5/24] Train loss=0.1404414027929306
[10/24] Train loss=0.1530291736125946
[15/24] Train loss=0.1421154886484146
[20/24] Train loss=0.15122681856155396
Test set avg_accuracy=86.07% avg_sensitivity=75.05%, avg_specificity=90.17% avg_auc=91.22%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.151250 Test loss=0.336764 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14592601358890533
[5/24] Train loss=0.14228279888629913
[10/24] Train loss=0.15274770557880402
[15/24] Train loss=0.14577892422676086
[20/24] Train loss=0.14307983219623566
Test set avg_accuracy=86.03% avg_sensitivity=76.54%, avg_specificity=89.56% avg_auc=91.35%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.150651 Test loss=0.340748 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14407320320606232
[5/24] Train loss=0.14584538340568542
[10/24] Train loss=0.14999409019947052
[15/24] Train loss=0.14302785694599152
[20/24] Train loss=0.14497032761573792
Test set avg_accuracy=86.26% avg_sensitivity=68.86%, avg_specificity=92.74% avg_auc=89.67%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.149374 Test loss=0.352384 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.14223194122314453
[5/24] Train loss=0.14240339398384094
[10/24] Train loss=0.15275566279888153
[15/24] Train loss=0.14028635621070862
[20/24] Train loss=0.14456532895565033
Test set avg_accuracy=86.50% avg_sensitivity=73.85%, avg_specificity=91.21% avg_auc=90.77%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.147722 Test loss=0.340983 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13792040944099426
[5/24] Train loss=0.14318174123764038
[10/24] Train loss=0.14633461833000183
[15/24] Train loss=0.13500985503196716
[20/24] Train loss=0.14174789190292358
Test set avg_accuracy=85.96% avg_sensitivity=70.01%, avg_specificity=91.90% avg_auc=89.81%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.146304 Test loss=0.352259 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13621290028095245
[5/24] Train loss=0.14076083898544312
[10/24] Train loss=0.14645537734031677
[15/24] Train loss=0.13345187902450562
[20/24] Train loss=0.145194411277771
Test set avg_accuracy=85.74% avg_sensitivity=75.43%, avg_specificity=89.58% avg_auc=90.39%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.145821 Test loss=0.356251 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1394316405057907
[5/24] Train loss=0.14007878303527832
[10/24] Train loss=0.14515076577663422
[15/24] Train loss=0.13679073750972748
[20/24] Train loss=0.13967353105545044
Test set avg_accuracy=85.65% avg_sensitivity=74.66%, avg_specificity=89.74% avg_auc=90.41%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.144458 Test loss=0.351058 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13625860214233398
[5/24] Train loss=0.1368028223514557
[10/24] Train loss=0.14566443860530853
[15/24] Train loss=0.1364007443189621
[20/24] Train loss=0.14061684906482697
Test set avg_accuracy=85.21% avg_sensitivity=73.46%, avg_specificity=89.58% avg_auc=90.18%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.143490 Test loss=0.361663 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13972197473049164
[5/24] Train loss=0.1370103806257248
[10/24] Train loss=0.142560213804245
[15/24] Train loss=0.13456055521965027
[20/24] Train loss=0.13949400186538696
Test set avg_accuracy=85.14% avg_sensitivity=74.86%, avg_specificity=88.97% avg_auc=90.28%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.143609 Test loss=0.359652 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.139631986618042
[5/24] Train loss=0.13854177296161652
[10/24] Train loss=0.13902120292186737
[15/24] Train loss=0.13735431432724
[20/24] Train loss=0.14163382351398468
Test set avg_accuracy=85.64% avg_sensitivity=76.01%, avg_specificity=89.22% avg_auc=90.43%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.144601 Test loss=0.356821 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13895022869110107
[5/24] Train loss=0.137690007686615
[10/24] Train loss=0.14836566150188446
[15/24] Train loss=0.1358220875263214
[20/24] Train loss=0.1434098482131958
Test set avg_accuracy=86.26% avg_sensitivity=72.98%, avg_specificity=91.21% avg_auc=90.21%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.144185 Test loss=0.348397 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13759823143482208
[5/24] Train loss=0.13819298148155212
[10/24] Train loss=0.14546963572502136
[15/24] Train loss=0.13752561807632446
[20/24] Train loss=0.1400667279958725
Test set avg_accuracy=85.82% avg_sensitivity=73.08%, avg_specificity=90.56% avg_auc=89.59%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.142780 Test loss=0.358110 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.14006488025188446
[5/24] Train loss=0.13448843359947205
[10/24] Train loss=0.14134395122528076
[15/24] Train loss=0.13128267228603363
[20/24] Train loss=0.1385427713394165
Test set avg_accuracy=86.30% avg_sensitivity=72.55%, avg_specificity=91.42% avg_auc=89.88%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.141485 Test loss=0.350847 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13765475153923035
[5/24] Train loss=0.13582949340343475
[10/24] Train loss=0.13682299852371216
[15/24] Train loss=0.13573496043682098
[20/24] Train loss=0.14059583842754364
Test set avg_accuracy=86.17% avg_sensitivity=71.31%, avg_specificity=91.71% avg_auc=89.62%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.141224 Test loss=0.352575 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1317022740840912
[5/24] Train loss=0.1346098929643631
[10/24] Train loss=0.13945800065994263
[15/24] Train loss=0.13045762479305267
[20/24] Train loss=0.1391671895980835
Test set avg_accuracy=86.11% avg_sensitivity=70.44%, avg_specificity=91.94% avg_auc=89.63%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.139656 Test loss=0.352544 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13395123183727264
[5/24] Train loss=0.13137581944465637
[10/24] Train loss=0.14140670001506805
[15/24] Train loss=0.13082095980644226
[20/24] Train loss=0.13463209569454193
Test set avg_accuracy=86.16% avg_sensitivity=70.68%, avg_specificity=91.92% avg_auc=89.65%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.138101 Test loss=0.350654 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13099677860736847
[5/24] Train loss=0.13299907743930817
[10/24] Train loss=0.13822562992572784
[15/24] Train loss=0.12900026142597198
[20/24] Train loss=0.1331770420074463
Test set avg_accuracy=86.37% avg_sensitivity=74.42%, avg_specificity=90.81% avg_auc=90.38%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.137116 Test loss=0.343978 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1331373006105423
[5/24] Train loss=0.13127782940864563
[10/24] Train loss=0.13391292095184326
[15/24] Train loss=0.12794850766658783
[20/24] Train loss=0.13253295421600342
Test set avg_accuracy=86.41% avg_sensitivity=74.33%, avg_specificity=90.90% avg_auc=90.45%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.136803 Test loss=0.343582 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.128339484333992
[5/24] Train loss=0.13034114241600037
[10/24] Train loss=0.13620075583457947
[15/24] Train loss=0.1277812421321869
[20/24] Train loss=0.13309939205646515
Test set avg_accuracy=86.54% avg_sensitivity=70.73%, avg_specificity=92.42% avg_auc=89.81%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.136330 Test loss=0.349606 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13035684823989868
[5/24] Train loss=0.13084661960601807
[10/24] Train loss=0.13437499105930328
[15/24] Train loss=0.12879520654678345
[20/24] Train loss=0.13589514791965485
Test set avg_accuracy=86.37% avg_sensitivity=72.89%, avg_specificity=91.39% avg_auc=89.92%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.135795 Test loss=0.350218 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1325160562992096
[5/24] Train loss=0.13389261066913605
[10/24] Train loss=0.1337113082408905
[15/24] Train loss=0.13209855556488037
[20/24] Train loss=0.13319750130176544
Test set avg_accuracy=86.41% avg_sensitivity=72.12%, avg_specificity=91.73% avg_auc=90.01%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.135789 Test loss=0.349626 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13040296733379364
[5/24] Train loss=0.12894794344902039
[10/24] Train loss=0.13403216004371643
[15/24] Train loss=0.12655015289783478
[20/24] Train loss=0.13454237580299377
Test set avg_accuracy=86.50% avg_sensitivity=73.61%, avg_specificity=91.30% avg_auc=90.44%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.135427 Test loss=0.344438 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1300797313451767
[5/24] Train loss=0.12935316562652588
[10/24] Train loss=0.134320929646492
[15/24] Train loss=0.1283792406320572
[20/24] Train loss=0.13336391746997833
Test set avg_accuracy=86.48% avg_sensitivity=72.50%, avg_specificity=91.69% avg_auc=90.09%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.135100 Test loss=0.347597 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.13099293410778046
[5/24] Train loss=0.1310727447271347
[10/24] Train loss=0.13590440154075623
[15/24] Train loss=0.12564362585544586
[20/24] Train loss=0.13694052398204803
Test set avg_accuracy=86.52% avg_sensitivity=71.98%, avg_specificity=91.94% avg_auc=89.97%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.135155 Test loss=0.347655 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1300445795059204
[5/24] Train loss=0.13059529662132263
[10/24] Train loss=0.1330656260251999
[15/24] Train loss=0.12675902247428894
[20/24] Train loss=0.13488303124904633
Test set avg_accuracy=86.55% avg_sensitivity=73.37%, avg_specificity=91.46% avg_auc=90.10%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.134142 Test loss=0.346367 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12839864194393158
[5/24] Train loss=0.12882056832313538
[10/24] Train loss=0.1353694647550583
[15/24] Train loss=0.12984542548656464
[20/24] Train loss=0.13243669271469116
Test set avg_accuracy=86.42% avg_sensitivity=72.22%, avg_specificity=91.71% avg_auc=89.99%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.134387 Test loss=0.347648 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12945520877838135
[5/24] Train loss=0.12996962666511536
[10/24] Train loss=0.13460056483745575
[15/24] Train loss=0.12599413096904755
[20/24] Train loss=0.13168403506278992
Test set avg_accuracy=86.59% avg_sensitivity=72.41%, avg_specificity=91.87% avg_auc=90.02%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.133917 Test loss=0.347521 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13299693167209625
[5/24] Train loss=0.128677099943161
[10/24] Train loss=0.13366630673408508
[15/24] Train loss=0.12666907906532288
[20/24] Train loss=0.1364912986755371
Test set avg_accuracy=86.55% avg_sensitivity=72.50%, avg_specificity=91.78% avg_auc=90.07%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.134255 Test loss=0.346889 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12909506261348724
[5/24] Train loss=0.1287381947040558
[10/24] Train loss=0.13026414811611176
[15/24] Train loss=0.12545645236968994
[20/24] Train loss=0.13292156159877777
Test set avg_accuracy=86.51% avg_sensitivity=72.46%, avg_specificity=91.74% avg_auc=90.01%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.133413 Test loss=0.347572 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.13154567778110504
[5/24] Train loss=0.12914171814918518
[10/24] Train loss=0.13188590109348297
[15/24] Train loss=0.1272379457950592
[20/24] Train loss=0.13372977077960968
Test set avg_accuracy=86.51% avg_sensitivity=72.46%, avg_specificity=91.74% avg_auc=90.02%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.133762 Test loss=0.347633 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12740713357925415
[5/24] Train loss=0.13139617443084717
[10/24] Train loss=0.13379640877246857
[15/24] Train loss=0.12607698142528534
[20/24] Train loss=0.13243037462234497
Test set avg_accuracy=86.48% avg_sensitivity=72.22%, avg_specificity=91.80% avg_auc=90.00%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.134023 Test loss=0.347596 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12688316404819489
[5/24] Train loss=0.12777940928936005
[10/24] Train loss=0.1388733685016632
[15/24] Train loss=0.12873630225658417
[20/24] Train loss=0.13289175927639008
Test set avg_accuracy=86.50% avg_sensitivity=72.60%, avg_specificity=91.67% avg_auc=90.06%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.133387 Test loss=0.347207 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=86.16% sen=77.11%, spe=89.53%, auc=91.60%!
Fold[6] Avg_overlap=0.67%(±0.2434608441729175)
[0/24] Train loss=0.7240879535675049
[5/24] Train loss=0.7218014001846313
[10/24] Train loss=0.7129453420639038
[15/24] Train loss=0.7005003690719604
[20/24] Train loss=0.6857449412345886
Test set avg_accuracy=58.26% avg_sensitivity=45.12%, avg_specificity=63.27% avg_auc=57.63%
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.710289 Test loss=0.669172 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6947821378707886
[5/24] Train loss=0.682607114315033
[10/24] Train loss=0.6754641532897949
[15/24] Train loss=0.6668625473976135
[20/24] Train loss=0.6565015316009521
Test set avg_accuracy=64.80% avg_sensitivity=62.00%, avg_specificity=65.88% avg_auc=69.71%
Best model saved!! Metric=-63.60965153624732!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.678131 Test loss=0.623895 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.656275749206543
[5/24] Train loss=0.6495233178138733
[10/24] Train loss=0.654554009437561
[15/24] Train loss=0.6388906240463257
[20/24] Train loss=0.6320632100105286
Test set avg_accuracy=68.28% avg_sensitivity=66.86%, avg_specificity=68.83% avg_auc=74.81%
Best model saved!! Metric=-47.22773250722459!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.650695 Test loss=0.595105 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6382113695144653
[5/24] Train loss=0.6295399069786072
[10/24] Train loss=0.6329267024993896
[15/24] Train loss=0.6171253323554993
[20/24] Train loss=0.6041553616523743
Test set avg_accuracy=71.63% avg_sensitivity=67.09%, avg_specificity=73.36% avg_auc=77.50%
Best model saved!! Metric=-36.42422525496177!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.627396 Test loss=0.566381 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6092075705528259
[5/24] Train loss=0.6070609092712402
[10/24] Train loss=0.6148614287376404
[15/24] Train loss=0.5898104906082153
[20/24] Train loss=0.5837540030479431
Test set avg_accuracy=73.57% avg_sensitivity=68.60%, avg_specificity=75.46% avg_auc=79.54%
Best model saved!! Metric=-28.827133371174796!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.603711 Test loss=0.542754 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.583677351474762
[5/24] Train loss=0.5792738795280457
[10/24] Train loss=0.5902084708213806
[15/24] Train loss=0.5620958805084229
[20/24] Train loss=0.5576399564743042
Test set avg_accuracy=75.60% avg_sensitivity=70.11%, avg_specificity=77.69% avg_auc=81.31%
Best model saved!! Metric=-21.293314765690397!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.579496 Test loss=0.520799 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5620264410972595
[5/24] Train loss=0.5576425790786743
[10/24] Train loss=0.5639337301254272
[15/24] Train loss=0.5400463342666626
[20/24] Train loss=0.5310564637184143
Test set avg_accuracy=77.59% avg_sensitivity=70.72%, avg_specificity=80.21% avg_auc=82.93%
Best model saved!! Metric=-14.549315256180137!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.556340 Test loss=0.495935 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5331185460090637
[5/24] Train loss=0.5315467715263367
[10/24] Train loss=0.5403695702552795
[15/24] Train loss=0.513591468334198
[20/24] Train loss=0.5055549740791321
Test set avg_accuracy=78.97% avg_sensitivity=70.30%, avg_specificity=82.28% avg_auc=84.49%
Best model saved!! Metric=-9.960175668145524!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.531586 Test loss=0.470232 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.519080638885498
[5/24] Train loss=0.5066649317741394
[10/24] Train loss=0.5120593309402466
[15/24] Train loss=0.4912196695804596
[20/24] Train loss=0.4799339473247528
Test set avg_accuracy=79.87% avg_sensitivity=72.04%, avg_specificity=82.86% avg_auc=85.89%
Best model saved!! Metric=-5.341579320096628!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.507645 Test loss=0.454178 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.49512726068496704
[5/24] Train loss=0.4814683496952057
[10/24] Train loss=0.49372732639312744
[15/24] Train loss=0.46681177616119385
[20/24] Train loss=0.45705512166023254
Test set avg_accuracy=81.00% avg_sensitivity=67.89%, avg_specificity=86.00% avg_auc=86.48%
Best model saved!! Metric=-4.61613235813067!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.484763 Test loss=0.431376 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4665464758872986
[5/24] Train loss=0.4583572447299957
[10/24] Train loss=0.474456250667572
[15/24] Train loss=0.44072651863098145
[20/24] Train loss=0.4323810935020447
Test set avg_accuracy=82.30% avg_sensitivity=68.32%, avg_specificity=87.64% avg_auc=87.83%
Best model saved!! Metric=0.0882856578267166!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.462140 Test loss=0.410763 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4443903863430023
[5/24] Train loss=0.43968161940574646
[10/24] Train loss=0.45799773931503296
[15/24] Train loss=0.4233444333076477
[20/24] Train loss=0.407575398683548
Test set avg_accuracy=83.24% avg_sensitivity=67.61%, avg_specificity=89.21% avg_auc=88.63%
Best model saved!! Metric=2.6857677843255487!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.441444 Test loss=0.395483 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.42542845010757446
[5/24] Train loss=0.4073876142501831
[10/24] Train loss=0.4400176405906677
[15/24] Train loss=0.4003477096557617
[20/24] Train loss=0.3885660469532013
Test set avg_accuracy=84.05% avg_sensitivity=67.66%, avg_specificity=90.30% avg_auc=89.40%
Best model saved!! Metric=5.407709708709362!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.421514 Test loss=0.379000 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.40843284130096436
[5/24] Train loss=0.39439883828163147
[10/24] Train loss=0.42748743295669556
[15/24] Train loss=0.39203155040740967
[20/24] Train loss=0.3735312223434448
Test set avg_accuracy=84.78% avg_sensitivity=68.55%, avg_specificity=90.97% avg_auc=89.93%
Best model saved!! Metric=8.235600626029466!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.406098 Test loss=0.369853 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.39231500029563904
[5/24] Train loss=0.3854568600654602
[10/24] Train loss=0.41344785690307617
[15/24] Train loss=0.3692609965801239
[20/24] Train loss=0.3619750440120697
Test set avg_accuracy=85.13% avg_sensitivity=66.81%, avg_specificity=92.12% avg_auc=90.14%
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.391808 Test loss=0.359404 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.37638404965400696
[5/24] Train loss=0.36547166109085083
[10/24] Train loss=0.4045320749282837
[15/24] Train loss=0.35426610708236694
[20/24] Train loss=0.3500787913799286
Test set avg_accuracy=85.74% avg_sensitivity=69.64%, avg_specificity=91.89% avg_auc=90.90%
Best model saved!! Metric=12.166267314503685!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.378619 Test loss=0.349609 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3648243844509125
[5/24] Train loss=0.34995126724243164
[10/24] Train loss=0.3809601366519928
[15/24] Train loss=0.34905174374580383
[20/24] Train loss=0.33289551734924316
Test set avg_accuracy=85.59% avg_sensitivity=70.20%, avg_specificity=91.46% avg_auc=91.15%
Best model saved!! Metric=12.392956695482098!!
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.366856 Test loss=0.342451 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.34217530488967896
[5/24] Train loss=0.3500278890132904
[10/24] Train loss=0.3786658048629761
[15/24] Train loss=0.3367714285850525
[20/24] Train loss=0.3258250057697296
Test set avg_accuracy=85.91% avg_sensitivity=70.34%, avg_specificity=91.85% avg_auc=91.43%
Best model saved!! Metric=13.54086298222471!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.356990 Test loss=0.336702 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3460279107093811
[5/24] Train loss=0.33736854791641235
[10/24] Train loss=0.3753128945827484
[15/24] Train loss=0.3231118619441986
[20/24] Train loss=0.31443390250205994
Test set avg_accuracy=85.21% avg_sensitivity=76.90%, avg_specificity=88.38% avg_auc=91.81%
Best model saved!! Metric=16.292559217952473!!
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.349118 Test loss=0.340699 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3396545350551605
[5/24] Train loss=0.32931455969810486
[10/24] Train loss=0.3696956932544708
[15/24] Train loss=0.311294823884964
[20/24] Train loss=0.3129802942276001
Test set avg_accuracy=86.02% avg_sensitivity=72.89%, avg_specificity=91.02% avg_auc=91.92%
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.342218 Test loss=0.331905 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.33415815234184265
[5/24] Train loss=0.320050448179245
[10/24] Train loss=0.36008894443511963
[15/24] Train loss=0.30858296155929565
[20/24] Train loss=0.3074784576892853
Test set avg_accuracy=85.46% avg_sensitivity=76.14%, avg_specificity=89.01% avg_auc=92.10%
Best model saved!! Metric=16.70343219616322!!
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.335442 Test loss=0.332054 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3310854732990265
[5/24] Train loss=0.3133166432380676
[10/24] Train loss=0.358569860458374
[15/24] Train loss=0.30316677689552307
[20/24] Train loss=0.2917661964893341
Test set avg_accuracy=85.83% avg_sensitivity=74.92%, avg_specificity=90.00% avg_auc=92.20%
Best model saved!! Metric=16.94710808294613!!
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.328125 Test loss=0.325723 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3190481960773468
[5/24] Train loss=0.3099122941493988
[10/24] Train loss=0.345235139131546
[15/24] Train loss=0.29550760984420776
[20/24] Train loss=0.2902636229991913
Test set avg_accuracy=85.20% avg_sensitivity=74.45%, avg_specificity=89.30% avg_auc=91.79%
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.322786 Test loss=0.333819 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3105740249156952
[5/24] Train loss=0.3100952208042145
[10/24] Train loss=0.34839382767677307
[15/24] Train loss=0.2848876416683197
[20/24] Train loss=0.28818514943122864
Test set avg_accuracy=86.17% avg_sensitivity=70.25%, avg_specificity=92.25% avg_auc=92.10%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.316967 Test loss=0.320556 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.30482903122901917
[5/24] Train loss=0.3118065893650055
[10/24] Train loss=0.33781442046165466
[15/24] Train loss=0.2906200587749481
[20/24] Train loss=0.2852080166339874
Test set avg_accuracy=85.95% avg_sensitivity=63.60%, avg_specificity=94.48% avg_auc=91.87%
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.313110 Test loss=0.325581 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.30184975266456604
[5/24] Train loss=0.29846465587615967
[10/24] Train loss=0.32785093784332275
[15/24] Train loss=0.2791910767555237
[20/24] Train loss=0.2726052701473236
Test set avg_accuracy=85.95% avg_sensitivity=62.05%, avg_specificity=95.07% avg_auc=91.47%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.306425 Test loss=0.329786 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.29603323340415955
[5/24] Train loss=0.3013748824596405
[10/24] Train loss=0.3274405896663666
[15/24] Train loss=0.2782040536403656
[20/24] Train loss=0.2747732102870941
Test set avg_accuracy=81.32% avg_sensitivity=36.87%, avg_specificity=98.27% avg_auc=87.90%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.302932 Test loss=0.441521 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3021688759326935
[5/24] Train loss=0.2836986780166626
[10/24] Train loss=0.3237869143486023
[15/24] Train loss=0.2748667895793915
[20/24] Train loss=0.2716223895549774
Test set avg_accuracy=86.15% avg_sensitivity=71.15%, avg_specificity=91.87% avg_auc=91.40%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.299028 Test loss=0.326586 Current lr=[0.000210185142098938]

[0/24] Train loss=0.29279130697250366
[5/24] Train loss=0.27599266171455383
[10/24] Train loss=0.31267455220222473
[15/24] Train loss=0.26196131110191345
[20/24] Train loss=0.26465317606925964
Test set avg_accuracy=84.30% avg_sensitivity=50.97%, avg_specificity=97.01% avg_auc=90.53%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.290535 Test loss=0.363349 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2858273386955261
[5/24] Train loss=0.286253958940506
[10/24] Train loss=0.31536033749580383
[15/24] Train loss=0.25971341133117676
[20/24] Train loss=0.2683599889278412
Test set avg_accuracy=83.78% avg_sensitivity=47.24%, avg_specificity=97.72% avg_auc=90.27%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.291268 Test loss=0.376291 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.28195661306381226
[5/24] Train loss=0.26943933963775635
[10/24] Train loss=0.30961304903030396
[15/24] Train loss=0.25805696845054626
[20/24] Train loss=0.2649098038673401
Test set avg_accuracy=85.57% avg_sensitivity=68.60%, avg_specificity=92.05% avg_auc=91.32%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.284305 Test loss=0.326687 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2662186026573181
[5/24] Train loss=0.2555936574935913
[10/24] Train loss=0.2984125316143036
[15/24] Train loss=0.2533940076828003
[20/24] Train loss=0.25666993856430054
Test set avg_accuracy=83.24% avg_sensitivity=45.31%, avg_specificity=97.72% avg_auc=89.65%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.276194 Test loss=0.393151 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.27745941281318665
[5/24] Train loss=0.258714884519577
[10/24] Train loss=0.29856523871421814
[15/24] Train loss=0.24926002323627472
[20/24] Train loss=0.25025632977485657
Test set avg_accuracy=80.64% avg_sensitivity=33.00%, avg_specificity=98.81% avg_auc=86.55%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.274186 Test loss=0.477140 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2756969630718231
[5/24] Train loss=0.2603670060634613
[10/24] Train loss=0.30378979444503784
[15/24] Train loss=0.24556612968444824
[20/24] Train loss=0.25388115644454956
Test set avg_accuracy=82.86% avg_sensitivity=79.21%, avg_specificity=84.26% avg_auc=90.69%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.273219 Test loss=0.369028 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.26129621267318726
[5/24] Train loss=0.24518035352230072
[10/24] Train loss=0.29454365372657776
[15/24] Train loss=0.24615693092346191
[20/24] Train loss=0.24897073209285736
Test set avg_accuracy=80.51% avg_sensitivity=81.42%, avg_specificity=80.16% avg_auc=89.35%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.265100 Test loss=0.409134 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2560351490974426
[5/24] Train loss=0.24830055236816406
[10/24] Train loss=0.282929003238678
[15/24] Train loss=0.23200079798698425
[20/24] Train loss=0.25070059299468994
Test set avg_accuracy=85.78% avg_sensitivity=60.96%, avg_specificity=95.25% avg_auc=91.07%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.261913 Test loss=0.333195 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.25139081478118896
[5/24] Train loss=0.2620685398578644
[10/24] Train loss=0.28348636627197266
[15/24] Train loss=0.24162480235099792
[20/24] Train loss=0.2550485134124756
Test set avg_accuracy=85.72% avg_sensitivity=70.44%, avg_specificity=91.55% avg_auc=91.21%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.262795 Test loss=0.333977 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2530626952648163
[5/24] Train loss=0.22659188508987427
[10/24] Train loss=0.27587491273880005
[15/24] Train loss=0.2309693992137909
[20/24] Train loss=0.24703554809093475
Test set avg_accuracy=80.57% avg_sensitivity=34.18%, avg_specificity=98.27% avg_auc=86.24%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.256355 Test loss=0.501978 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.24766072630882263
[5/24] Train loss=0.24396014213562012
[10/24] Train loss=0.2756637930870056
[15/24] Train loss=0.23131762444972992
[20/24] Train loss=0.24301038682460785
Test set avg_accuracy=82.06% avg_sensitivity=42.67%, avg_specificity=97.09% avg_auc=89.36%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.257138 Test loss=0.396499 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2494317889213562
[5/24] Train loss=0.23075032234191895
[10/24] Train loss=0.30008867383003235
[15/24] Train loss=0.23927953839302063
[20/24] Train loss=0.2645455002784729
Test set avg_accuracy=84.31% avg_sensitivity=55.07%, avg_specificity=95.47% avg_auc=89.06%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.258872 Test loss=0.370113 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2340591549873352
[5/24] Train loss=0.21541248261928558
[10/24] Train loss=0.3011787235736847
[15/24] Train loss=0.2233142852783203
[20/24] Train loss=0.24039016664028168
Test set avg_accuracy=78.03% avg_sensitivity=21.97%, avg_specificity=99.42% avg_auc=83.38%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.249705 Test loss=0.540756 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.26505300402641296
[5/24] Train loss=0.22796180844306946
[10/24] Train loss=0.3038189709186554
[15/24] Train loss=0.2241089791059494
[20/24] Train loss=0.23831450939178467
Test set avg_accuracy=83.59% avg_sensitivity=45.31%, avg_specificity=98.20% avg_auc=88.04%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.258031 Test loss=0.402663 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.23921331763267517
[5/24] Train loss=0.22403083741664886
[10/24] Train loss=0.27899956703186035
[15/24] Train loss=0.23295943439006805
[20/24] Train loss=0.23374995589256287
Test set avg_accuracy=80.27% avg_sensitivity=32.30%, avg_specificity=98.58% avg_auc=83.69%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.251269 Test loss=0.537442 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2427404373884201
[5/24] Train loss=0.21845921874046326
[10/24] Train loss=0.28123006224632263
[15/24] Train loss=0.2201080322265625
[20/24] Train loss=0.23479819297790527
Test set avg_accuracy=80.99% avg_sensitivity=33.95%, avg_specificity=98.94% avg_auc=84.45%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.243092 Test loss=0.489424 Current lr=[0.00029967723776099]

[0/24] Train loss=0.24044708907604218
[5/24] Train loss=0.20802265405654907
[10/24] Train loss=0.25679242610931396
[15/24] Train loss=0.21710927784442902
[20/24] Train loss=0.2274198830127716
Test set avg_accuracy=84.08% avg_sensitivity=50.78%, avg_specificity=96.78% avg_auc=89.28%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.239730 Test loss=0.366566 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.24944570660591125
[5/24] Train loss=0.21730491518974304
[10/24] Train loss=0.26977381110191345
[15/24] Train loss=0.22053471207618713
[20/24] Train loss=0.22539903223514557
Test set avg_accuracy=84.87% avg_sensitivity=53.32%, avg_specificity=96.91% avg_auc=87.82%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.241779 Test loss=0.382714 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.23153181374073029
[5/24] Train loss=0.21641090512275696
[10/24] Train loss=0.27031752467155457
[15/24] Train loss=0.2195589244365692
[20/24] Train loss=0.22472640872001648
Test set avg_accuracy=78.24% avg_sensitivity=23.53%, avg_specificity=99.12% avg_auc=79.70%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.237617 Test loss=0.597940 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2352040559053421
[5/24] Train loss=0.2214086353778839
[10/24] Train loss=0.24348090589046478
[15/24] Train loss=0.2138734608888626
[20/24] Train loss=0.2239225059747696
Test set avg_accuracy=83.55% avg_sensitivity=48.28%, avg_specificity=97.01% avg_auc=87.97%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.234262 Test loss=0.389785 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.232040673494339
[5/24] Train loss=0.20855583250522614
[10/24] Train loss=0.26596203446388245
[15/24] Train loss=0.21921303868293762
[20/24] Train loss=0.22813792526721954
Test set avg_accuracy=78.83% avg_sensitivity=26.50%, avg_specificity=98.79% avg_auc=83.21%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.238829 Test loss=0.590659 Current lr=[0.000298904600941902]

[0/24] Train loss=0.23596958816051483
[5/24] Train loss=0.19987554848194122
[10/24] Train loss=0.24649980664253235
[15/24] Train loss=0.21450628340244293
[20/24] Train loss=0.22616435587406158
Test set avg_accuracy=80.57% avg_sensitivity=33.29%, avg_specificity=98.61% avg_auc=84.62%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.231601 Test loss=0.489325 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.23117855191230774
[5/24] Train loss=0.2094169706106186
[10/24] Train loss=0.24927055835723877
[15/24] Train loss=0.20983706414699554
[20/24] Train loss=0.21304701268672943
Test set avg_accuracy=79.44% avg_sensitivity=29.51%, avg_specificity=98.49% avg_auc=78.34%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.226492 Test loss=0.530084 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2378435730934143
[5/24] Train loss=0.19786737859249115
[10/24] Train loss=0.24183571338653564
[15/24] Train loss=0.2102339267730713
[20/24] Train loss=0.22693221271038055
Test set avg_accuracy=76.38% avg_sensitivity=16.69%, avg_specificity=99.15% avg_auc=75.19%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.227220 Test loss=0.652757 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.23264667391777039
[5/24] Train loss=0.20830947160720825
[10/24] Train loss=0.23892953991889954
[15/24] Train loss=0.21306627988815308
[20/24] Train loss=0.22149844467639923
Test set avg_accuracy=82.96% avg_sensitivity=80.67%, avg_specificity=83.83% avg_auc=90.11%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.227665 Test loss=0.391114 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.22917631268501282
[5/24] Train loss=0.20533064007759094
[10/24] Train loss=0.23930850625038147
[15/24] Train loss=0.2075190395116806
[20/24] Train loss=0.2134944647550583
Test set avg_accuracy=75.17% avg_sensitivity=10.75%, avg_specificity=99.75% avg_auc=73.73%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.224661 Test loss=0.791383 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.23591093719005585
[5/24] Train loss=0.2025468647480011
[10/24] Train loss=0.2288927137851715
[15/24] Train loss=0.1965547651052475
[20/24] Train loss=0.2339797168970108
Test set avg_accuracy=85.07% avg_sensitivity=64.26%, avg_specificity=93.00% avg_auc=90.16%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.222431 Test loss=0.347251 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.23752735555171967
[5/24] Train loss=0.20742648839950562
[10/24] Train loss=0.23591820895671844
[15/24] Train loss=0.20191054046154022
[20/24] Train loss=0.22176848351955414
Test set avg_accuracy=84.35% avg_sensitivity=51.20%, avg_specificity=97.00% avg_auc=86.70%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.224091 Test loss=0.396835 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.22148321568965912
[5/24] Train loss=0.18653635680675507
[10/24] Train loss=0.24280951917171478
[15/24] Train loss=0.21218901872634888
[20/24] Train loss=0.22552621364593506
Test set avg_accuracy=85.77% avg_sensitivity=65.54%, avg_specificity=93.49% avg_auc=90.30%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.223738 Test loss=0.342104 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.23196113109588623
[5/24] Train loss=0.19559043645858765
[10/24] Train loss=0.2231096476316452
[15/24] Train loss=0.20197176933288574
[20/24] Train loss=0.21480081975460052
Test set avg_accuracy=84.21% avg_sensitivity=56.62%, avg_specificity=94.73% avg_auc=88.02%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.217723 Test loss=0.385778 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.22394683957099915
[5/24] Train loss=0.19608710706233978
[10/24] Train loss=0.23536792397499084
[15/24] Train loss=0.1959303915500641
[20/24] Train loss=0.20820431411266327
Test set avg_accuracy=82.33% avg_sensitivity=45.59%, avg_specificity=96.35% avg_auc=85.08%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.215912 Test loss=0.427469 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.21370002627372742
[5/24] Train loss=0.191957488656044
[10/24] Train loss=0.22559824585914612
[15/24] Train loss=0.20678606629371643
[20/24] Train loss=0.22407403588294983
Test set avg_accuracy=84.84% avg_sensitivity=74.63%, avg_specificity=88.74% avg_auc=90.99%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.215348 Test loss=0.345807 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.20641808211803436
[5/24] Train loss=0.19449442625045776
[10/24] Train loss=0.22909638285636902
[15/24] Train loss=0.18147209286689758
[20/24] Train loss=0.20773252844810486
Test set avg_accuracy=85.23% avg_sensitivity=67.52%, avg_specificity=91.99% avg_auc=90.53%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.209784 Test loss=0.348639 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2116357982158661
[5/24] Train loss=0.18612776696681976
[10/24] Train loss=0.2277330905199051
[15/24] Train loss=0.2043566107749939
[20/24] Train loss=0.20362375676631927
Test set avg_accuracy=83.79% avg_sensitivity=47.48%, avg_specificity=97.64% avg_auc=87.14%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.210961 Test loss=0.431470 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.21097229421138763
[5/24] Train loss=0.1961454153060913
[10/24] Train loss=0.2136770486831665
[15/24] Train loss=0.19089649617671967
[20/24] Train loss=0.20604513585567474
Test set avg_accuracy=82.06% avg_sensitivity=40.17%, avg_specificity=98.04% avg_auc=85.42%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.210441 Test loss=0.461415 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.21541012823581696
[5/24] Train loss=0.19075971841812134
[10/24] Train loss=0.22326748073101044
[15/24] Train loss=0.1837320178747177
[20/24] Train loss=0.1980884075164795
Test set avg_accuracy=84.40% avg_sensitivity=53.32%, avg_specificity=96.26% avg_auc=87.57%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.207731 Test loss=0.415550 Current lr=[0.000276307469034998]

[0/24] Train loss=0.19746097922325134
[5/24] Train loss=0.18787139654159546
[10/24] Train loss=0.21946434676647186
[15/24] Train loss=0.18606965243816376
[20/24] Train loss=0.19282390177249908
Test set avg_accuracy=85.82% avg_sensitivity=68.18%, avg_specificity=92.55% avg_auc=90.95%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.205891 Test loss=0.339168 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.215368390083313
[5/24] Train loss=0.18657293915748596
[10/24] Train loss=0.21357353031635284
[15/24] Train loss=0.19842730462551117
[20/24] Train loss=0.2122703343629837
Test set avg_accuracy=82.93% avg_sensitivity=54.69%, avg_specificity=93.70% avg_auc=85.32%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.209629 Test loss=0.415963 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2114291936159134
[5/24] Train loss=0.1872742474079132
[10/24] Train loss=0.21667662262916565
[15/24] Train loss=0.19659322500228882
[20/24] Train loss=0.20134834945201874
Test set avg_accuracy=79.13% avg_sensitivity=72.42%, avg_specificity=81.69% avg_auc=85.82%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.205610 Test loss=0.447680 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.19661761820316315
[5/24] Train loss=0.18486438691616058
[10/24] Train loss=0.2239677608013153
[15/24] Train loss=0.17962488532066345
[20/24] Train loss=0.20268934965133667
Test set avg_accuracy=81.09% avg_sensitivity=83.03%, avg_specificity=80.36% avg_auc=89.48%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.203151 Test loss=0.415886 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.1934579461812973
[5/24] Train loss=0.1759650707244873
[10/24] Train loss=0.21274980902671814
[15/24] Train loss=0.18973487615585327
[20/24] Train loss=0.20517690479755402
Test set avg_accuracy=84.02% avg_sensitivity=78.08%, avg_specificity=86.29% avg_auc=90.33%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.201097 Test loss=0.363185 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2150150090456009
[5/24] Train loss=0.18177691102027893
[10/24] Train loss=0.21530747413635254
[15/24] Train loss=0.16964778304100037
[20/24] Train loss=0.19942350685596466
Test set avg_accuracy=85.27% avg_sensitivity=61.01%, avg_specificity=94.53% avg_auc=89.43%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.199343 Test loss=0.372992 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.20025470852851868
[5/24] Train loss=0.18153220415115356
[10/24] Train loss=0.2180866301059723
[15/24] Train loss=0.18173182010650635
[20/24] Train loss=0.19710220396518707
Test set avg_accuracy=85.16% avg_sensitivity=66.20%, avg_specificity=92.39% avg_auc=90.13%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.202405 Test loss=0.353568 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.2192813903093338
[5/24] Train loss=0.1798049807548523
[10/24] Train loss=0.21054567396640778
[15/24] Train loss=0.1858229786157608
[20/24] Train loss=0.1830746978521347
Test set avg_accuracy=82.84% avg_sensitivity=45.26%, avg_specificity=97.18% avg_auc=84.48%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.200211 Test loss=0.452101 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.19469153881072998
[5/24] Train loss=0.1717624068260193
[10/24] Train loss=0.20359084010124207
[15/24] Train loss=0.1852843016386032
[20/24] Train loss=0.1933058798313141
Test set avg_accuracy=82.41% avg_sensitivity=70.77%, avg_specificity=86.85% avg_auc=87.29%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.196639 Test loss=0.403328 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.19130557775497437
[5/24] Train loss=0.1821395456790924
[10/24] Train loss=0.20867349207401276
[15/24] Train loss=0.17362350225448608
[20/24] Train loss=0.187931090593338
Test set avg_accuracy=82.80% avg_sensitivity=78.97%, avg_specificity=84.26% avg_auc=89.91%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.195272 Test loss=0.384348 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.1929391473531723
[5/24] Train loss=0.17139209806919098
[10/24] Train loss=0.20663806796073914
[15/24] Train loss=0.18519563972949982
[20/24] Train loss=0.18551968038082123
Test set avg_accuracy=84.30% avg_sensitivity=51.39%, avg_specificity=96.85% avg_auc=86.59%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.194934 Test loss=0.402468 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.20939387381076813
[5/24] Train loss=0.17074677348136902
[10/24] Train loss=0.22052831947803497
[15/24] Train loss=0.1765127331018448
[20/24] Train loss=0.18538838624954224
Test set avg_accuracy=84.40% avg_sensitivity=52.99%, avg_specificity=96.38% avg_auc=86.17%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.197043 Test loss=0.429396 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.18901972472667694
[5/24] Train loss=0.18331865966320038
[10/24] Train loss=0.21201547980308533
[15/24] Train loss=0.1778535395860672
[20/24] Train loss=0.1992722898721695
Test set avg_accuracy=82.88% avg_sensitivity=69.40%, avg_specificity=88.02% avg_auc=86.73%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.198665 Test loss=0.398727 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.1913757175207138
[5/24] Train loss=0.16022644937038422
[10/24] Train loss=0.19885273277759552
[15/24] Train loss=0.18388332426548004
[20/24] Train loss=0.18980427086353302
Test set avg_accuracy=84.56% avg_sensitivity=66.05%, avg_specificity=91.62% avg_auc=89.23%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.193021 Test loss=0.365186 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.19529515504837036
[5/24] Train loss=0.16305716335773468
[10/24] Train loss=0.2057448923587799
[15/24] Train loss=0.16590704023838043
[20/24] Train loss=0.1876651793718338
Test set avg_accuracy=83.23% avg_sensitivity=48.28%, avg_specificity=96.56% avg_auc=85.10%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.187028 Test loss=0.437649 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.19844679534435272
[5/24] Train loss=0.1675540655851364
[10/24] Train loss=0.2024991661310196
[15/24] Train loss=0.17782676219940186
[20/24] Train loss=0.18829140067100525
Test set avg_accuracy=82.20% avg_sensitivity=44.70%, avg_specificity=96.51% avg_auc=83.51%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.190621 Test loss=0.476664 Current lr=[0.000224838296036774]

[0/24] Train loss=0.1912609487771988
[5/24] Train loss=0.16915713250637054
[10/24] Train loss=0.1964685171842575
[15/24] Train loss=0.1668296754360199
[20/24] Train loss=0.1868167370557785
Test set avg_accuracy=84.41% avg_sensitivity=61.39%, avg_specificity=93.20% avg_auc=88.79%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.189267 Test loss=0.375525 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.18739666044712067
[5/24] Train loss=0.17397311329841614
[10/24] Train loss=0.2102651298046112
[15/24] Train loss=0.18407271802425385
[20/24] Train loss=0.19177652895450592
Test set avg_accuracy=84.04% avg_sensitivity=56.11%, avg_specificity=94.69% avg_auc=87.39%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.191236 Test loss=0.401114 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2018752247095108
[5/24] Train loss=0.16737566888332367
[10/24] Train loss=0.19582735002040863
[15/24] Train loss=0.17599020898342133
[20/24] Train loss=0.17864088714122772
Test set avg_accuracy=78.97% avg_sensitivity=27.82%, avg_specificity=98.49% avg_auc=76.41%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.186724 Test loss=0.629546 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1893434375524521
[5/24] Train loss=0.17263086140155792
[10/24] Train loss=0.21792437136173248
[15/24] Train loss=0.18394389748573303
[20/24] Train loss=0.196949765086174
Test set avg_accuracy=79.18% avg_sensitivity=29.09%, avg_specificity=98.29% avg_auc=80.23%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.192737 Test loss=0.593158 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.18512694537639618
[5/24] Train loss=0.17018258571624756
[10/24] Train loss=0.20340143144130707
[15/24] Train loss=0.1729857623577118
[20/24] Train loss=0.18352700769901276
Test set avg_accuracy=78.53% avg_sensitivity=52.19%, avg_specificity=88.58% avg_auc=81.08%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.189842 Test loss=0.495664 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.19829219579696655
[5/24] Train loss=0.1728098839521408
[10/24] Train loss=0.19996874034404755
[15/24] Train loss=0.1866864562034607
[20/24] Train loss=0.186382457613945
Test set avg_accuracy=81.61% avg_sensitivity=45.83%, avg_specificity=95.27% avg_auc=84.02%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.189302 Test loss=0.453734 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.18684683740139008
[5/24] Train loss=0.17085038125514984
[10/24] Train loss=0.2025856077671051
[15/24] Train loss=0.18956755101680756
[20/24] Train loss=0.17357198894023895
Test set avg_accuracy=84.06% avg_sensitivity=55.73%, avg_specificity=94.87% avg_auc=86.48%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.186668 Test loss=0.420964 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.18450547754764557
[5/24] Train loss=0.17353960871696472
[10/24] Train loss=0.18795549869537354
[15/24] Train loss=0.1670709252357483
[20/24] Train loss=0.174590066075325
Test set avg_accuracy=83.20% avg_sensitivity=54.36%, avg_specificity=94.21% avg_auc=84.96%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.185058 Test loss=0.440762 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.18837124109268188
[5/24] Train loss=0.17706401646137238
[10/24] Train loss=0.22137166559696198
[15/24] Train loss=0.16930317878723145
[20/24] Train loss=0.16880328953266144
Test set avg_accuracy=82.58% avg_sensitivity=50.92%, avg_specificity=94.66% avg_auc=85.20%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.183509 Test loss=0.445777 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.1864386647939682
[5/24] Train loss=0.17018818855285645
[10/24] Train loss=0.18185940384864807
[15/24] Train loss=0.16654916107654572
[20/24] Train loss=0.1734282225370407
Test set avg_accuracy=80.91% avg_sensitivity=50.87%, avg_specificity=92.37% avg_auc=81.60%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.182663 Test loss=0.483127 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.18348067998886108
[5/24] Train loss=0.1646057814359665
[10/24] Train loss=0.1789073944091797
[15/24] Train loss=0.16586190462112427
[20/24] Train loss=0.19107049703598022
Test set avg_accuracy=83.12% avg_sensitivity=62.09%, avg_specificity=91.15% avg_auc=87.22%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.183144 Test loss=0.414842 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.1816152036190033
[5/24] Train loss=0.1532837450504303
[10/24] Train loss=0.18768616020679474
[15/24] Train loss=0.1621403694152832
[20/24] Train loss=0.16743962466716766
Test set avg_accuracy=84.69% avg_sensitivity=62.00%, avg_specificity=93.34% avg_auc=87.62%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.177440 Test loss=0.391780 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.17411407828330994
[5/24] Train loss=0.15758591890335083
[10/24] Train loss=0.17436091601848602
[15/24] Train loss=0.154086172580719
[20/24] Train loss=0.16346518695354462
Test set avg_accuracy=85.38% avg_sensitivity=63.65%, avg_specificity=93.67% avg_auc=88.41%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.172462 Test loss=0.378005 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.17320820689201355
[5/24] Train loss=0.15011359751224518
[10/24] Train loss=0.17681141197681427
[15/24] Train loss=0.15619643032550812
[20/24] Train loss=0.175019308924675
Test set avg_accuracy=84.84% avg_sensitivity=65.72%, avg_specificity=92.14% avg_auc=88.84%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.171547 Test loss=0.370526 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1702221930027008
[5/24] Train loss=0.1641308218240738
[10/24] Train loss=0.1668168157339096
[15/24] Train loss=0.15586693584918976
[20/24] Train loss=0.16734997928142548
Test set avg_accuracy=84.51% avg_sensitivity=71.62%, avg_specificity=89.42% avg_auc=90.16%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.171002 Test loss=0.359892 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.17287464439868927
[5/24] Train loss=0.1574726402759552
[10/24] Train loss=0.16983376443386078
[15/24] Train loss=0.15465670824050903
[20/24] Train loss=0.1820717602968216
Test set avg_accuracy=85.22% avg_sensitivity=65.35%, avg_specificity=92.80% avg_auc=89.38%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.171440 Test loss=0.363871 Current lr=[0.000156543481933168]

[0/24] Train loss=0.1706392765045166
[5/24] Train loss=0.16437847912311554
[10/24] Train loss=0.17167720198631287
[15/24] Train loss=0.1668137013912201
[20/24] Train loss=0.1643887311220169
Test set avg_accuracy=84.93% avg_sensitivity=61.39%, avg_specificity=93.92% avg_auc=88.64%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.171399 Test loss=0.377544 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.165155291557312
[5/24] Train loss=0.15997737646102905
[10/24] Train loss=0.18684571981430054
[15/24] Train loss=0.16593609750270844
[20/24] Train loss=0.1749677211046219
Test set avg_accuracy=84.18% avg_sensitivity=58.32%, avg_specificity=94.05% avg_auc=86.67%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.174768 Test loss=0.396826 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.1814836859703064
[5/24] Train loss=0.15479150414466858
[10/24] Train loss=0.18552327156066895
[15/24] Train loss=0.15801389515399933
[20/24] Train loss=0.17232713103294373
Test set avg_accuracy=81.43% avg_sensitivity=42.81%, avg_specificity=96.17% avg_auc=82.11%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.169263 Test loss=0.484630 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.17700383067131042
[5/24] Train loss=0.1526717096567154
[10/24] Train loss=0.17661933600902557
[15/24] Train loss=0.16460728645324707
[20/24] Train loss=0.17084920406341553
Test set avg_accuracy=81.94% avg_sensitivity=40.36%, avg_specificity=97.81% avg_auc=81.01%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.169368 Test loss=0.519643 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1745145469903946
[5/24] Train loss=0.15627481043338776
[10/24] Train loss=0.171636700630188
[15/24] Train loss=0.1553228795528412
[20/24] Train loss=0.1699790060520172
Test set avg_accuracy=84.36% avg_sensitivity=53.84%, avg_specificity=96.01% avg_auc=85.81%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.169997 Test loss=0.434402 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16632217168807983
[5/24] Train loss=0.15440836548805237
[10/24] Train loss=0.16663134098052979
[15/24] Train loss=0.14731675386428833
[20/24] Train loss=0.1612197309732437
Test set avg_accuracy=85.05% avg_sensitivity=60.44%, avg_specificity=94.44% avg_auc=87.92%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.163383 Test loss=0.383648 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.16370300948619843
[5/24] Train loss=0.14637865126132965
[10/24] Train loss=0.16562046110630035
[15/24] Train loss=0.16000424325466156
[20/24] Train loss=0.1570674031972885
Test set avg_accuracy=84.64% avg_sensitivity=57.99%, avg_specificity=94.80% avg_auc=87.99%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.162806 Test loss=0.399249 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.17261163890361786
[5/24] Train loss=0.14694955945014954
[10/24] Train loss=0.16437983512878418
[15/24] Train loss=0.14792500436306
[20/24] Train loss=0.16626329720020294
Test set avg_accuracy=85.33% avg_sensitivity=63.46%, avg_specificity=93.67% avg_auc=88.43%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.161333 Test loss=0.378786 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.16397888958454132
[5/24] Train loss=0.14320586621761322
[10/24] Train loss=0.16060484945774078
[15/24] Train loss=0.15296582877635956
[20/24] Train loss=0.1616416722536087
Test set avg_accuracy=84.83% avg_sensitivity=58.09%, avg_specificity=95.04% avg_auc=87.62%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.160439 Test loss=0.399209 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.16303040087223053
[5/24] Train loss=0.14965903759002686
[10/24] Train loss=0.163190558552742
[15/24] Train loss=0.1427779644727707
[20/24] Train loss=0.15957146883010864
Test set avg_accuracy=84.54% avg_sensitivity=59.69%, avg_specificity=94.03% avg_auc=86.96%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.160478 Test loss=0.406100 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16601206362247467
[5/24] Train loss=0.140360027551651
[10/24] Train loss=0.15595406293869019
[15/24] Train loss=0.14576111733913422
[20/24] Train loss=0.16280893981456757
Test set avg_accuracy=83.41% avg_sensitivity=48.80%, avg_specificity=96.62% avg_auc=85.82%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.159302 Test loss=0.440684 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1630820333957672
[5/24] Train loss=0.1455588936805725
[10/24] Train loss=0.1595207303762436
[15/24] Train loss=0.1515074223279953
[20/24] Train loss=0.15430647134780884
Test set avg_accuracy=84.43% avg_sensitivity=62.00%, avg_specificity=92.98% avg_auc=86.65%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.158637 Test loss=0.388988 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1605774164199829
[5/24] Train loss=0.13737082481384277
[10/24] Train loss=0.15706667304039001
[15/24] Train loss=0.13738764822483063
[20/24] Train loss=0.1556178331375122
Test set avg_accuracy=85.57% avg_sensitivity=66.62%, avg_specificity=92.80% avg_auc=89.74%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.156866 Test loss=0.366327 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.16107456386089325
[5/24] Train loss=0.13854274153709412
[10/24] Train loss=0.15494923293590546
[15/24] Train loss=0.14469726383686066
[20/24] Train loss=0.15544329583644867
Test set avg_accuracy=85.36% avg_sensitivity=66.43%, avg_specificity=92.59% avg_auc=89.63%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.155678 Test loss=0.367341 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.1628793179988861
[5/24] Train loss=0.145280659198761
[10/24] Train loss=0.15525583922863007
[15/24] Train loss=0.1459285467863083
[20/24] Train loss=0.1518034040927887
Test set avg_accuracy=85.70% avg_sensitivity=69.59%, avg_specificity=91.85% avg_auc=90.59%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.155674 Test loss=0.348122 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.15696987509727478
[5/24] Train loss=0.14606794714927673
[10/24] Train loss=0.14872685074806213
[15/24] Train loss=0.14200827479362488
[20/24] Train loss=0.148451030254364
Test set avg_accuracy=84.14% avg_sensitivity=58.56%, avg_specificity=93.90% avg_auc=87.56%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.153545 Test loss=0.393352 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.15337537229061127
[5/24] Train loss=0.139628067612648
[10/24] Train loss=0.14280708134174347
[15/24] Train loss=0.13920804858207703
[20/24] Train loss=0.1484871655702591
Test set avg_accuracy=85.46% avg_sensitivity=64.83%, avg_specificity=93.33% avg_auc=89.74%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.150575 Test loss=0.366026 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.15123103559017181
[5/24] Train loss=0.13373783230781555
[10/24] Train loss=0.14596642553806305
[15/24] Train loss=0.1392575055360794
[20/24] Train loss=0.14446528255939484
Test set avg_accuracy=85.77% avg_sensitivity=69.12%, avg_specificity=92.12% avg_auc=89.98%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.150562 Test loss=0.359127 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.15592394769191742
[5/24] Train loss=0.13110536336898804
[10/24] Train loss=0.14467647671699524
[15/24] Train loss=0.133940652012825
[20/24] Train loss=0.1545092761516571
Test set avg_accuracy=85.66% avg_sensitivity=66.53%, avg_specificity=92.97% avg_auc=89.85%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.148523 Test loss=0.358133 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15213696658611298
[5/24] Train loss=0.13489170372486115
[10/24] Train loss=0.14240625500679016
[15/24] Train loss=0.1396780014038086
[20/24] Train loss=0.14457042515277863
Test set avg_accuracy=85.35% avg_sensitivity=70.25%, avg_specificity=91.11% avg_auc=89.89%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.147928 Test loss=0.362372 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1519380360841751
[5/24] Train loss=0.1276692897081375
[10/24] Train loss=0.1468474119901657
[15/24] Train loss=0.1346002072095871
[20/24] Train loss=0.14560681581497192
Test set avg_accuracy=85.57% avg_sensitivity=70.30%, avg_specificity=91.40% avg_auc=89.77%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.147309 Test loss=0.358019 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14582166075706482
[5/24] Train loss=0.13222041726112366
[10/24] Train loss=0.1420493870973587
[15/24] Train loss=0.13572995364665985
[20/24] Train loss=0.1430773288011551
Test set avg_accuracy=85.12% avg_sensitivity=64.88%, avg_specificity=92.84% avg_auc=88.18%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.146019 Test loss=0.379148 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1454225778579712
[5/24] Train loss=0.13137952983379364
[10/24] Train loss=0.13781067728996277
[15/24] Train loss=0.1325925588607788
[20/24] Train loss=0.14412103593349457
Test set avg_accuracy=85.23% avg_sensitivity=72.37%, avg_specificity=90.14% avg_auc=90.40%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.145061 Test loss=0.355931 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1532260924577713
[5/24] Train loss=0.13062061369419098
[10/24] Train loss=0.13688507676124573
[15/24] Train loss=0.13994911313056946
[20/24] Train loss=0.14403174817562103
Test set avg_accuracy=85.65% avg_sensitivity=72.51%, avg_specificity=90.66% avg_auc=90.16%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.144704 Test loss=0.356625 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14930659532546997
[5/24] Train loss=0.12740856409072876
[10/24] Train loss=0.13875192403793335
[15/24] Train loss=0.13733816146850586
[20/24] Train loss=0.14523106813430786
Test set avg_accuracy=85.20% avg_sensitivity=68.41%, avg_specificity=91.60% avg_auc=89.10%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.144152 Test loss=0.369613 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.15401987731456757
[5/24] Train loss=0.12805286049842834
[10/24] Train loss=0.13985656201839447
[15/24] Train loss=0.1364576369524002
[20/24] Train loss=0.14504291117191315
Test set avg_accuracy=85.60% avg_sensitivity=67.94%, avg_specificity=92.34% avg_auc=89.12%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.143744 Test loss=0.369548 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.15154165029525757
[5/24] Train loss=0.12755991518497467
[10/24] Train loss=0.1360132098197937
[15/24] Train loss=0.13368940353393555
[20/24] Train loss=0.14691998064517975
Test set avg_accuracy=84.70% avg_sensitivity=63.51%, avg_specificity=92.79% avg_auc=88.22%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.142976 Test loss=0.390211 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.14575564861297607
[5/24] Train loss=0.12716273963451385
[10/24] Train loss=0.1392660140991211
[15/24] Train loss=0.13154521584510803
[20/24] Train loss=0.14287014305591583
Test set avg_accuracy=84.70% avg_sensitivity=64.55%, avg_specificity=92.39% avg_auc=88.69%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.140898 Test loss=0.383676 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.14638139307498932
[5/24] Train loss=0.1278505027294159
[10/24] Train loss=0.13395634293556213
[15/24] Train loss=0.12624433636665344
[20/24] Train loss=0.1416665017604828
Test set avg_accuracy=84.99% avg_sensitivity=64.83%, avg_specificity=92.68% avg_auc=89.12%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.139500 Test loss=0.380610 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.14271429181098938
[5/24] Train loss=0.12397625297307968
[10/24] Train loss=0.13327151536941528
[15/24] Train loss=0.13098719716072083
[20/24] Train loss=0.1372460424900055
Test set avg_accuracy=85.57% avg_sensitivity=69.50%, avg_specificity=91.71% avg_auc=89.50%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.139474 Test loss=0.369220 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.14147816598415375
[5/24] Train loss=0.12386233359575272
[10/24] Train loss=0.12781336903572083
[15/24] Train loss=0.13352718949317932
[20/24] Train loss=0.13983039557933807
Test set avg_accuracy=85.27% avg_sensitivity=68.79%, avg_specificity=91.56% avg_auc=88.52%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.138971 Test loss=0.377096 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.14377616345882416
[5/24] Train loss=0.12167249619960785
[10/24] Train loss=0.13235032558441162
[15/24] Train loss=0.12545958161354065
[20/24] Train loss=0.13720417022705078
Test set avg_accuracy=85.70% avg_sensitivity=67.09%, avg_specificity=92.80% avg_auc=88.91%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.137408 Test loss=0.369470 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.14343062043190002
[5/24] Train loss=0.12064506858587265
[10/24] Train loss=0.13512052595615387
[15/24] Train loss=0.1282254308462143
[20/24] Train loss=0.1352669894695282
Test set avg_accuracy=84.41% avg_sensitivity=75.15%, avg_specificity=87.95% avg_auc=89.87%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.137338 Test loss=0.375954 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.14024080336093903
[5/24] Train loss=0.12159715592861176
[10/24] Train loss=0.1286916732788086
[15/24] Train loss=0.12722623348236084
[20/24] Train loss=0.1342574506998062
Test set avg_accuracy=85.66% avg_sensitivity=67.99%, avg_specificity=92.41% avg_auc=89.00%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.136677 Test loss=0.367627 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13857023417949677
[5/24] Train loss=0.12383226305246353
[10/24] Train loss=0.128409743309021
[15/24] Train loss=0.1280180662870407
[20/24] Train loss=0.13643427193164825
Test set avg_accuracy=85.66% avg_sensitivity=68.60%, avg_specificity=92.17% avg_auc=89.36%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.136568 Test loss=0.368006 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13941022753715515
[5/24] Train loss=0.12684163451194763
[10/24] Train loss=0.12726789712905884
[15/24] Train loss=0.12598060071468353
[20/24] Train loss=0.1394025683403015
Test set avg_accuracy=85.62% avg_sensitivity=67.89%, avg_specificity=92.39% avg_auc=88.86%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.135550 Test loss=0.372158 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13960790634155273
[5/24] Train loss=0.12212992459535599
[10/24] Train loss=0.1274949610233307
[15/24] Train loss=0.12255499511957169
[20/24] Train loss=0.13411003351211548
Test set avg_accuracy=85.68% avg_sensitivity=66.57%, avg_specificity=92.97% avg_auc=89.14%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.134461 Test loss=0.368342 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13941679894924164
[5/24] Train loss=0.12206068634986877
[10/24] Train loss=0.12842532992362976
[15/24] Train loss=0.12617143988609314
[20/24] Train loss=0.13593235611915588
Test set avg_accuracy=85.40% avg_sensitivity=70.44%, avg_specificity=91.11% avg_auc=89.31%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.134233 Test loss=0.367559 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13931620121002197
[5/24] Train loss=0.11813563108444214
[10/24] Train loss=0.1266801655292511
[15/24] Train loss=0.12382739037275314
[20/24] Train loss=0.13043396174907684
Test set avg_accuracy=85.72% avg_sensitivity=67.28%, avg_specificity=92.75% avg_auc=88.79%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.133154 Test loss=0.371343 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13921573758125305
[5/24] Train loss=0.11669981479644775
[10/24] Train loss=0.126657634973526
[15/24] Train loss=0.1261226087808609
[20/24] Train loss=0.13371804356575012
Test set avg_accuracy=85.69% avg_sensitivity=66.38%, avg_specificity=93.06% avg_auc=88.65%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.132548 Test loss=0.372410 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1365407109260559
[5/24] Train loss=0.11881296336650848
[10/24] Train loss=0.12840232253074646
[15/24] Train loss=0.11926806718111038
[20/24] Train loss=0.13198216259479523
Test set avg_accuracy=85.52% avg_sensitivity=66.76%, avg_specificity=92.68% avg_auc=88.89%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.131283 Test loss=0.370497 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13493351638317108
[5/24] Train loss=0.11798388510942459
[10/24] Train loss=0.12365006655454636
[15/24] Train loss=0.12509340047836304
[20/24] Train loss=0.13254901766777039
Test set avg_accuracy=85.81% avg_sensitivity=69.21%, avg_specificity=92.14% avg_auc=89.10%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.130595 Test loss=0.366969 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1360982060432434
[5/24] Train loss=0.116268090903759
[10/24] Train loss=0.1268566995859146
[15/24] Train loss=0.12144479155540466
[20/24] Train loss=0.13077490031719208
Test set avg_accuracy=85.72% avg_sensitivity=69.26%, avg_specificity=91.99% avg_auc=89.28%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.130915 Test loss=0.367152 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13506662845611572
[5/24] Train loss=0.11995863914489746
[10/24] Train loss=0.12278468161821365
[15/24] Train loss=0.12328237295150757
[20/24] Train loss=0.13096818327903748
Test set avg_accuracy=85.68% avg_sensitivity=66.81%, avg_specificity=92.88% avg_auc=88.74%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.130201 Test loss=0.372023 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13248348236083984
[5/24] Train loss=0.1172972097992897
[10/24] Train loss=0.12576942145824432
[15/24] Train loss=0.1213301494717598
[20/24] Train loss=0.13015499711036682
Test set avg_accuracy=85.69% avg_sensitivity=67.09%, avg_specificity=92.79% avg_auc=88.81%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.129682 Test loss=0.372968 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1323014348745346
[5/24] Train loss=0.11677782237529755
[10/24] Train loss=0.12197471410036087
[15/24] Train loss=0.12082300335168839
[20/24] Train loss=0.13306492567062378
Test set avg_accuracy=85.64% avg_sensitivity=67.94%, avg_specificity=92.39% avg_auc=88.84%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.129883 Test loss=0.371478 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13255755603313446
[5/24] Train loss=0.11677398532629013
[10/24] Train loss=0.12372413277626038
[15/24] Train loss=0.11913694441318512
[20/24] Train loss=0.13203299045562744
Test set avg_accuracy=85.74% avg_sensitivity=68.18%, avg_specificity=92.44% avg_auc=88.82%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.129614 Test loss=0.372079 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13281388580799103
[5/24] Train loss=0.11816228926181793
[10/24] Train loss=0.12153173238039017
[15/24] Train loss=0.11974179744720459
[20/24] Train loss=0.1285514086484909
Test set avg_accuracy=85.68% avg_sensitivity=67.00%, avg_specificity=92.80% avg_auc=88.69%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.129610 Test loss=0.373490 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13174264132976532
[5/24] Train loss=0.116150863468647
[10/24] Train loss=0.12325895577669144
[15/24] Train loss=0.12062281370162964
[20/24] Train loss=0.1321883648633957
Test set avg_accuracy=85.66% avg_sensitivity=67.23%, avg_specificity=92.70% avg_auc=88.73%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.130070 Test loss=0.373791 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13577233254909515
[5/24] Train loss=0.11632280051708221
[10/24] Train loss=0.12263481318950653
[15/24] Train loss=0.1210281103849411
[20/24] Train loss=0.12929175794124603
Test set avg_accuracy=85.81% avg_sensitivity=67.56%, avg_specificity=92.77% avg_auc=88.78%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.129461 Test loss=0.372604 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.13232861459255219
[5/24] Train loss=0.11440523713827133
[10/24] Train loss=0.12308571487665176
[15/24] Train loss=0.12016943842172623
[20/24] Train loss=0.1278783231973648
Test set avg_accuracy=85.78% avg_sensitivity=67.33%, avg_specificity=92.82% avg_auc=88.71%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.129240 Test loss=0.373195 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.13335222005844116
[5/24] Train loss=0.11660116910934448
[10/24] Train loss=0.12323109060525894
[15/24] Train loss=0.12057626247406006
[20/24] Train loss=0.12823063135147095
Test set avg_accuracy=85.85% avg_sensitivity=67.75%, avg_specificity=92.75% avg_auc=88.78%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.129375 Test loss=0.372280 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13537640869617462
[5/24] Train loss=0.11576520651578903
[10/24] Train loss=0.1217736005783081
[15/24] Train loss=0.11767016351222992
[20/24] Train loss=0.13083510100841522
Test set avg_accuracy=85.83% avg_sensitivity=67.61%, avg_specificity=92.79% avg_auc=88.81%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.129789 Test loss=0.372187 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.13289380073547363
[5/24] Train loss=0.11632317304611206
[10/24] Train loss=0.12479857355356216
[15/24] Train loss=0.11781136691570282
[20/24] Train loss=0.12981942296028137
Test set avg_accuracy=85.83% avg_sensitivity=67.61%, avg_specificity=92.79% avg_auc=88.79%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.128786 Test loss=0.372295 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=85.83% sen=74.92%, spe=90.00%, auc=92.20%!
Fold[7] Avg_overlap=0.57%(±0.2439882182184697)
[0/24] Train loss=0.7627080678939819
[5/24] Train loss=0.7582070231437683
[10/24] Train loss=0.7547067403793335
[15/24] Train loss=0.7289270162582397
[20/24] Train loss=0.7248541712760925
Test set avg_accuracy=56.98% avg_sensitivity=52.05%, avg_specificity=58.64% avg_auc=57.62%
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.742625 Test loss=0.685089 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.717921793460846
[5/24] Train loss=0.7115910649299622
[10/24] Train loss=0.7130539417266846
[15/24] Train loss=0.7120059728622437
[20/24] Train loss=0.691783607006073
Test set avg_accuracy=59.51% avg_sensitivity=71.57%, avg_specificity=55.45% avg_auc=68.61%
Best model saved!! Metric=-70.86214657287195!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.708901 Test loss=0.670379 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.688029944896698
[5/24] Train loss=0.6808885335922241
[10/24] Train loss=0.6807199120521545
[15/24] Train loss=0.6707921624183655
[20/24] Train loss=0.6660588383674622
Test set avg_accuracy=63.67% avg_sensitivity=81.05%, avg_specificity=57.84% avg_auc=75.17%
Best model saved!! Metric=-48.275938948955066!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.679104 Test loss=0.646223 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6531381607055664
[5/24] Train loss=0.6475605368614197
[10/24] Train loss=0.6546044945716858
[15/24] Train loss=0.6376417875289917
[20/24] Train loss=0.6333107948303223
Test set avg_accuracy=67.60% avg_sensitivity=81.98%, avg_specificity=62.78% avg_auc=77.97%
Best model saved!! Metric=-35.671821889287806!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.650342 Test loss=0.617360 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.621722936630249
[5/24] Train loss=0.616878092288971
[10/24] Train loss=0.6261205077171326
[15/24] Train loss=0.6096231341362
[20/24] Train loss=0.6065706014633179
Test set avg_accuracy=70.52% avg_sensitivity=81.72%, avg_specificity=66.76% avg_auc=80.17%
Best model saved!! Metric=-26.834399319651425!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.623119 Test loss=0.587570 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5945471525192261
[5/24] Train loss=0.5965650081634521
[10/24] Train loss=0.5973143577575684
[15/24] Train loss=0.5837644338607788
[20/24] Train loss=0.5777550935745239
Test set avg_accuracy=73.67% avg_sensitivity=80.42%, avg_specificity=71.40% avg_auc=82.11%
Best model saved!! Metric=-18.386878919241497!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.594785 Test loss=0.553553 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5642640590667725
[5/24] Train loss=0.5673149228096008
[10/24] Train loss=0.5676566362380981
[15/24] Train loss=0.5611085295677185
[20/24] Train loss=0.5505709648132324
Test set avg_accuracy=75.82% avg_sensitivity=79.91%, avg_specificity=74.45% avg_auc=83.90%
Best model saved!! Metric=-11.92816981998378!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.567615 Test loss=0.525099 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5431899428367615
[5/24] Train loss=0.5429869890213013
[10/24] Train loss=0.5443432331085205
[15/24] Train loss=0.527805745601654
[20/24] Train loss=0.5283740162849426
Test set avg_accuracy=77.93% avg_sensitivity=77.99%, avg_specificity=77.91% avg_auc=85.20%
Best model saved!! Metric=-6.968867707718999!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.541383 Test loss=0.495454 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5088592767715454
[5/24] Train loss=0.5227828025817871
[10/24] Train loss=0.5103490948677063
[15/24] Train loss=0.5093106031417847
[20/24] Train loss=0.49451133608818054
Test set avg_accuracy=79.38% avg_sensitivity=78.66%, avg_specificity=79.61% avg_auc=86.55%
Best model saved!! Metric=-1.797993407359968!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.516138 Test loss=0.476017 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.48996707797050476
[5/24] Train loss=0.48877274990081787
[10/24] Train loss=0.49270910024642944
[15/24] Train loss=0.4877049922943115
[20/24] Train loss=0.4691154956817627
Test set avg_accuracy=80.85% avg_sensitivity=76.85%, avg_specificity=82.19% avg_auc=87.66%
Best model saved!! Metric=1.548480283392081!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.491322 Test loss=0.446575 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4663711190223694
[5/24] Train loss=0.46765702962875366
[10/24] Train loss=0.4686451852321625
[15/24] Train loss=0.4627074897289276
[20/24] Train loss=0.4399137794971466
Test set avg_accuracy=81.90% avg_sensitivity=74.73%, avg_specificity=84.31% avg_auc=88.50%
Best model saved!! Metric=3.440527740348543!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.467622 Test loss=0.422472 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4440227150917053
[5/24] Train loss=0.4458361566066742
[10/24] Train loss=0.44939538836479187
[15/24] Train loss=0.4389185905456543
[20/24] Train loss=0.42191946506500244
Test set avg_accuracy=83.76% avg_sensitivity=71.72%, avg_specificity=87.81% avg_auc=89.24%
Best model saved!! Metric=6.532180606149524!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.446612 Test loss=0.394337 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.42304715514183044
[5/24] Train loss=0.41959160566329956
[10/24] Train loss=0.4309747815132141
[15/24] Train loss=0.4252530038356781
[20/24] Train loss=0.4032486379146576
Test set avg_accuracy=84.78% avg_sensitivity=71.57%, avg_specificity=89.22% avg_auc=89.81%
Best model saved!! Metric=9.371084443556114!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.427811 Test loss=0.377905 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4019012153148651
[5/24] Train loss=0.40595006942749023
[10/24] Train loss=0.41042983531951904
[15/24] Train loss=0.4088340401649475
[20/24] Train loss=0.3837774395942688
Test set avg_accuracy=85.03% avg_sensitivity=72.04%, avg_specificity=89.39% avg_auc=90.33%
Best model saved!! Metric=10.776504832349929!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.410704 Test loss=0.364792 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.38295304775238037
[5/24] Train loss=0.3896941840648651
[10/24] Train loss=0.4021133780479431
[15/24] Train loss=0.38924694061279297
[20/24] Train loss=0.36117830872535706
Test set avg_accuracy=86.17% avg_sensitivity=71.15%, avg_specificity=91.22% avg_auc=90.79%
Best model saved!! Metric=13.333638930934711!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.395773 Test loss=0.347502 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3744410574436188
[5/24] Train loss=0.3691636323928833
[10/24] Train loss=0.38710400462150574
[15/24] Train loss=0.3789564371109009
[20/24] Train loss=0.3536115288734436
Test set avg_accuracy=85.82% avg_sensitivity=76.02%, avg_specificity=89.11% avg_auc=91.22%
Best model saved!! Metric=16.17353953545407!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.382021 Test loss=0.350432 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3617604076862335
[5/24] Train loss=0.3627258539199829
[10/24] Train loss=0.37153202295303345
[15/24] Train loss=0.36860373616218567
[20/24] Train loss=0.3457067310810089
Test set avg_accuracy=86.68% avg_sensitivity=73.33%, avg_specificity=91.16% avg_auc=91.36%
Best model saved!! Metric=16.531257930504694!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.371979 Test loss=0.335275 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3484041094779968
[5/24] Train loss=0.35318177938461304
[10/24] Train loss=0.3580949306488037
[15/24] Train loss=0.35569891333580017
[20/24] Train loss=0.3278626501560211
Test set avg_accuracy=85.62% avg_sensitivity=77.06%, avg_specificity=88.50% avg_auc=91.43%
Best model saved!! Metric=16.62065069700276!!
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.359768 Test loss=0.345430 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.34148159623146057
[5/24] Train loss=0.3440101146697998
[10/24] Train loss=0.3547244071960449
[15/24] Train loss=0.3503971993923187
[20/24] Train loss=0.32211342453956604
Test set avg_accuracy=86.78% avg_sensitivity=72.76%, avg_specificity=91.49% avg_auc=91.63%
Best model saved!! Metric=16.663574405315785!!
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.351617 Test loss=0.324849 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.33500468730926514
[5/24] Train loss=0.3357292413711548
[10/24] Train loss=0.3466984033584595
[15/24] Train loss=0.34254807233810425
[20/24] Train loss=0.318413108587265
Test set avg_accuracy=87.06% avg_sensitivity=73.90%, avg_specificity=91.48% avg_auc=92.20%
Best model saved!! Metric=18.63101781578463!!
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.345343 Test loss=0.317723 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3265419900417328
[5/24] Train loss=0.3239228129386902
[10/24] Train loss=0.3358123004436493
[15/24] Train loss=0.33745864033699036
[20/24] Train loss=0.30606672167778015
Test set avg_accuracy=86.43% avg_sensitivity=78.09%, avg_specificity=89.23% avg_auc=92.29%
Best model saved!! Metric=20.045392596385028!!
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.338381 Test loss=0.328294 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.31939831376075745
[5/24] Train loss=0.3182081878185272
[10/24] Train loss=0.33252260088920593
[15/24] Train loss=0.33139824867248535
[20/24] Train loss=0.30009472370147705
Test set avg_accuracy=86.64% avg_sensitivity=79.18%, avg_specificity=89.15% avg_auc=92.42%
Best model saved!! Metric=21.39248700846946!!
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.332390 Test loss=0.328463 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.32265880703926086
[5/24] Train loss=0.31842753291130066
[10/24] Train loss=0.3271336555480957
[15/24] Train loss=0.32309648394584656
[20/24] Train loss=0.2907364070415497
Test set avg_accuracy=87.30% avg_sensitivity=71.83%, avg_specificity=92.50% avg_auc=92.14%
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.327244 Test loss=0.314315 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3148520588874817
[5/24] Train loss=0.3109632134437561
[10/24] Train loss=0.31823286414146423
[15/24] Train loss=0.3159289062023163
[20/24] Train loss=0.2902510464191437
Test set avg_accuracy=85.56% avg_sensitivity=80.79%, avg_specificity=87.16% avg_auc=92.24%
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.322576 Test loss=0.335831 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.31005436182022095
[5/24] Train loss=0.3098810315132141
[10/24] Train loss=0.31333687901496887
[15/24] Train loss=0.311046302318573
[20/24] Train loss=0.28654617071151733
Test set avg_accuracy=86.16% avg_sensitivity=74.68%, avg_specificity=90.02% avg_auc=91.56%
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.316665 Test loss=0.332646 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.30167925357818604
[5/24] Train loss=0.3007253408432007
[10/24] Train loss=0.3085424602031708
[15/24] Train loss=0.3078007996082306
[20/24] Train loss=0.2731052041053772
Test set avg_accuracy=87.36% avg_sensitivity=65.61%, avg_specificity=94.66% avg_auc=92.28%
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.310129 Test loss=0.300950 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.30048519372940063
[5/24] Train loss=0.2924555242061615
[10/24] Train loss=0.31158772110939026
[15/24] Train loss=0.30214813351631165
[20/24] Train loss=0.27735191583633423
Test set avg_accuracy=86.07% avg_sensitivity=70.53%, avg_specificity=91.29% avg_auc=90.51%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.305419 Test loss=0.340007 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.30566829442977905
[5/24] Train loss=0.2819198668003082
[10/24] Train loss=0.2978309094905853
[15/24] Train loss=0.29864415526390076
[20/24] Train loss=0.26547980308532715
Test set avg_accuracy=86.64% avg_sensitivity=68.82%, avg_specificity=92.62% avg_auc=91.13%
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.298691 Test loss=0.319515 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2836148738861084
[5/24] Train loss=0.2707482874393463
[10/24] Train loss=0.2980231046676636
[15/24] Train loss=0.2903665602207184
[20/24] Train loss=0.2630193829536438
Test set avg_accuracy=80.65% avg_sensitivity=83.89%, avg_specificity=79.56% avg_auc=89.96%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.290965 Test loss=0.420247 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2770577073097229
[5/24] Train loss=0.26501214504241943
[10/24] Train loss=0.2932353913784027
[15/24] Train loss=0.29145902395248413
[20/24] Train loss=0.25988084077835083
Test set avg_accuracy=77.10% avg_sensitivity=82.70%, avg_specificity=75.21% avg_auc=87.72%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.287213 Test loss=0.470351 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2825687527656555
[5/24] Train loss=0.2767283618450165
[10/24] Train loss=0.29829224944114685
[15/24] Train loss=0.2970750331878662
[20/24] Train loss=0.2485005259513855
Test set avg_accuracy=85.91% avg_sensitivity=65.30%, avg_specificity=92.83% avg_auc=90.25%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.286211 Test loss=0.334307 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.28937867283821106
[5/24] Train loss=0.27261728048324585
[10/24] Train loss=0.29907792806625366
[15/24] Train loss=0.28060489892959595
[20/24] Train loss=0.2512718439102173
Test set avg_accuracy=83.24% avg_sensitivity=38.68%, avg_specificity=98.21% avg_auc=88.83%
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.281634 Test loss=0.388263 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2841104567050934
[5/24] Train loss=0.24961695075035095
[10/24] Train loss=0.3040247857570648
[15/24] Train loss=0.27890679240226746
[20/24] Train loss=0.2506245970726013
Test set avg_accuracy=85.38% avg_sensitivity=49.66%, avg_specificity=97.37% avg_auc=89.97%
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.279486 Test loss=0.343168 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.27779218554496765
[5/24] Train loss=0.24965718388557434
[10/24] Train loss=0.2877857983112335
[15/24] Train loss=0.2862536907196045
[20/24] Train loss=0.24587951600551605
Test set avg_accuracy=83.63% avg_sensitivity=39.88%, avg_specificity=98.33% avg_auc=88.82%
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.271910 Test loss=0.373145 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2626916468143463
[5/24] Train loss=0.2496393918991089
[10/24] Train loss=0.2788887619972229
[15/24] Train loss=0.27106305956840515
[20/24] Train loss=0.23934920132160187
Test set avg_accuracy=84.73% avg_sensitivity=49.09%, avg_specificity=96.70% avg_auc=88.17%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.271672 Test loss=0.373161 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.272725373506546
[5/24] Train loss=0.24522541463375092
[10/24] Train loss=0.2820121645927429
[15/24] Train loss=0.2831682860851288
[20/24] Train loss=0.24104773998260498
Test set avg_accuracy=80.85% avg_sensitivity=27.76%, avg_specificity=98.68% avg_auc=85.32%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.271686 Test loss=0.472242 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.25863441824913025
[5/24] Train loss=0.23761610686779022
[10/24] Train loss=0.2866695523262024
[15/24] Train loss=0.25903448462486267
[20/24] Train loss=0.23916183412075043
Test set avg_accuracy=85.98% avg_sensitivity=62.35%, avg_specificity=93.91% avg_auc=90.28%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.262998 Test loss=0.333109 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.25999441742897034
[5/24] Train loss=0.24202942848205566
[10/24] Train loss=0.27383920550346375
[15/24] Train loss=0.27088701725006104
[20/24] Train loss=0.23401419818401337
Test set avg_accuracy=84.65% avg_sensitivity=52.82%, avg_specificity=95.34% avg_auc=88.70%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.261453 Test loss=0.356639 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2515115439891815
[5/24] Train loss=0.23524798452854156
[10/24] Train loss=0.25630539655685425
[15/24] Train loss=0.26590579748153687
[20/24] Train loss=0.23307916522026062
Test set avg_accuracy=82.42% avg_sensitivity=33.97%, avg_specificity=98.70% avg_auc=86.76%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.254265 Test loss=0.433983 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.24764956533908844
[5/24] Train loss=0.2268930971622467
[10/24] Train loss=0.2578960359096527
[15/24] Train loss=0.24690696597099304
[20/24] Train loss=0.2218889445066452
Test set avg_accuracy=83.20% avg_sensitivity=39.10%, avg_specificity=98.02% avg_auc=83.73%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.251693 Test loss=0.443407 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2557520866394043
[5/24] Train loss=0.22091536223888397
[10/24] Train loss=0.2567563056945801
[15/24] Train loss=0.2504223585128784
[20/24] Train loss=0.23048119246959686
Test set avg_accuracy=77.96% avg_sensitivity=13.26%, avg_specificity=99.69% avg_auc=82.38%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.254323 Test loss=0.608836 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.26458144187927246
[5/24] Train loss=0.23414866626262665
[10/24] Train loss=0.24686206877231598
[15/24] Train loss=0.25752127170562744
[20/24] Train loss=0.21568891406059265
Test set avg_accuracy=85.29% avg_sensitivity=58.57%, avg_specificity=94.26% avg_auc=88.57%
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.248803 Test loss=0.354750 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.23339292407035828
[5/24] Train loss=0.211909681558609
[10/24] Train loss=0.25013989210128784
[15/24] Train loss=0.2571291923522949
[20/24] Train loss=0.2171873152256012
Test set avg_accuracy=83.89% avg_sensitivity=44.64%, avg_specificity=97.08% avg_auc=86.87%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.245510 Test loss=0.389317 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.23882915079593658
[5/24] Train loss=0.2081182301044464
[10/24] Train loss=0.24745093286037445
[15/24] Train loss=0.24484403431415558
[20/24] Train loss=0.2243855744600296
Test set avg_accuracy=83.37% avg_sensitivity=41.12%, avg_specificity=97.56% avg_auc=84.79%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.241868 Test loss=0.442478 Current lr=[0.00029967723776099]

[0/24] Train loss=0.22836387157440186
[5/24] Train loss=0.2101668119430542
[10/24] Train loss=0.248246967792511
[15/24] Train loss=0.2454216182231903
[20/24] Train loss=0.21599790453910828
Test set avg_accuracy=83.06% avg_sensitivity=52.77%, avg_specificity=93.23% avg_auc=87.54%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.244003 Test loss=0.375159 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.23864181339740753
[5/24] Train loss=0.23868438601493835
[10/24] Train loss=0.2486000806093216
[15/24] Train loss=0.23189406096935272
[20/24] Train loss=0.21441857516765594
Test set avg_accuracy=84.91% avg_sensitivity=59.81%, avg_specificity=93.34% avg_auc=89.00%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.246617 Test loss=0.349891 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.23047959804534912
[5/24] Train loss=0.20370736718177795
[10/24] Train loss=0.2337721884250641
[15/24] Train loss=0.2430158108472824
[20/24] Train loss=0.2138892412185669
Test set avg_accuracy=82.30% avg_sensitivity=70.53%, avg_specificity=86.26% avg_auc=87.26%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.235610 Test loss=0.400090 Current lr=[0.000299720220882401]

[0/24] Train loss=0.24468129873275757
[5/24] Train loss=0.2113216519355774
[10/24] Train loss=0.245963454246521
[15/24] Train loss=0.23967508971691132
[20/24] Train loss=0.21480268239974976
Test set avg_accuracy=76.72% avg_sensitivity=43.55%, avg_specificity=87.86% avg_auc=79.24%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.240035 Test loss=0.477253 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.23932243883609772
[5/24] Train loss=0.21958380937576294
[10/24] Train loss=0.23952855169773102
[15/24] Train loss=0.236525759100914
[20/24] Train loss=0.2283039391040802
Test set avg_accuracy=81.30% avg_sensitivity=34.70%, avg_specificity=96.96% avg_auc=82.65%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.242748 Test loss=0.482313 Current lr=[0.000298904600941902]

[0/24] Train loss=0.23577457666397095
[5/24] Train loss=0.23060354590415955
[10/24] Train loss=0.24175816774368286
[15/24] Train loss=0.234216570854187
[20/24] Train loss=0.20475898683071136
Test set avg_accuracy=82.17% avg_sensitivity=33.56%, avg_specificity=98.50% avg_auc=84.47%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.232894 Test loss=0.464666 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.21955829858779907
[5/24] Train loss=0.20592093467712402
[10/24] Train loss=0.23654131591320038
[15/24] Train loss=0.23346225917339325
[20/24] Train loss=0.22334502637386322
Test set avg_accuracy=79.23% avg_sensitivity=20.09%, avg_specificity=99.10% avg_auc=83.69%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.231012 Test loss=0.527099 Current lr=[0.000297555943323901]

[0/24] Train loss=0.23983563482761383
[5/24] Train loss=0.21410340070724487
[10/24] Train loss=0.24026185274124146
[15/24] Train loss=0.24127599596977234
[20/24] Train loss=0.21714378893375397
Test set avg_accuracy=78.78% avg_sensitivity=18.18%, avg_specificity=99.13% avg_auc=82.80%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.234135 Test loss=0.546897 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.23223373293876648
[5/24] Train loss=0.21540988981723785
[10/24] Train loss=0.233509361743927
[15/24] Train loss=0.22915127873420715
[20/24] Train loss=0.2039048969745636
Test set avg_accuracy=85.90% avg_sensitivity=55.57%, avg_specificity=96.09% avg_auc=89.51%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.228030 Test loss=0.345385 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.21086782217025757
[5/24] Train loss=0.20044247806072235
[10/24] Train loss=0.23541243374347687
[15/24] Train loss=0.23363317549228668
[20/24] Train loss=0.20761463046073914
Test set avg_accuracy=84.23% avg_sensitivity=53.65%, avg_specificity=94.50% avg_auc=87.78%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.223476 Test loss=0.372012 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.21912655234336853
[5/24] Train loss=0.19299937784671783
[10/24] Train loss=0.22766244411468506
[15/24] Train loss=0.2233116179704666
[20/24] Train loss=0.20335352420806885
Test set avg_accuracy=82.66% avg_sensitivity=35.58%, avg_specificity=98.47% avg_auc=89.41%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.224797 Test loss=0.401582 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.24196529388427734
[5/24] Train loss=0.19347544014453888
[10/24] Train loss=0.22522075474262238
[15/24] Train loss=0.2220214307308197
[20/24] Train loss=0.1964491307735443
Test set avg_accuracy=83.23% avg_sensitivity=40.81%, avg_specificity=97.48% avg_auc=85.97%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.221888 Test loss=0.409606 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.22066248953342438
[5/24] Train loss=0.19943396747112274
[10/24] Train loss=0.21776612102985382
[15/24] Train loss=0.21571481227874756
[20/24] Train loss=0.1928521692752838
Test set avg_accuracy=84.26% avg_sensitivity=47.49%, avg_specificity=96.61% avg_auc=88.36%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.218907 Test loss=0.371455 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2067958116531372
[5/24] Train loss=0.20446732640266418
[10/24] Train loss=0.22005979716777802
[15/24] Train loss=0.22300906479358673
[20/24] Train loss=0.194147527217865
Test set avg_accuracy=82.36% avg_sensitivity=53.91%, avg_specificity=91.91% avg_auc=83.63%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.222093 Test loss=0.416834 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.21787117421627045
[5/24] Train loss=0.19847065210342407
[10/24] Train loss=0.22343407571315765
[15/24] Train loss=0.21803703904151917
[20/24] Train loss=0.18433517217636108
Test set avg_accuracy=84.99% avg_sensitivity=51.01%, avg_specificity=96.40% avg_auc=87.69%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.216703 Test loss=0.379021 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2059342861175537
[5/24] Train loss=0.19079940021038055
[10/24] Train loss=0.23601405322551727
[15/24] Train loss=0.2167208194732666
[20/24] Train loss=0.19452054798603058
Test set avg_accuracy=80.55% avg_sensitivity=27.24%, avg_specificity=98.45% avg_auc=79.78%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.214525 Test loss=0.547710 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2080649733543396
[5/24] Train loss=0.20138822495937347
[10/24] Train loss=0.22867652773857117
[15/24] Train loss=0.2135525792837143
[20/24] Train loss=0.20269429683685303
Test set avg_accuracy=85.05% avg_sensitivity=51.73%, avg_specificity=96.24% avg_auc=87.13%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.216127 Test loss=0.379587 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.21276700496673584
[5/24] Train loss=0.1846633106470108
[10/24] Train loss=0.20914286375045776
[15/24] Train loss=0.2199348509311676
[20/24] Train loss=0.19277507066726685
Test set avg_accuracy=75.60% avg_sensitivity=3.16%, avg_specificity=99.93% avg_auc=61.74%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.211321 Test loss=0.787715 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.22013145685195923
[5/24] Train loss=0.18586182594299316
[10/24] Train loss=0.23099926114082336
[15/24] Train loss=0.21800105273723602
[20/24] Train loss=0.1882869154214859
Test set avg_accuracy=80.26% avg_sensitivity=23.87%, avg_specificity=99.20% avg_auc=82.26%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.211549 Test loss=0.542385 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.19475889205932617
[5/24] Train loss=0.17365999519824982
[10/24] Train loss=0.21581313014030457
[15/24] Train loss=0.21000412106513977
[20/24] Train loss=0.18386419117450714
Test set avg_accuracy=83.53% avg_sensitivity=59.92%, avg_specificity=91.46% avg_auc=88.01%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.207029 Test loss=0.366158 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2034684419631958
[5/24] Train loss=0.1810176968574524
[10/24] Train loss=0.21558116376399994
[15/24] Train loss=0.21391870081424713
[20/24] Train loss=0.18015746772289276
Test set avg_accuracy=83.02% avg_sensitivity=44.12%, avg_specificity=96.09% avg_auc=86.55%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.208769 Test loss=0.411518 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.20443037152290344
[5/24] Train loss=0.18794192373752594
[10/24] Train loss=0.2083360105752945
[15/24] Train loss=0.20345669984817505
[20/24] Train loss=0.19415776431560516
Test set avg_accuracy=81.29% avg_sensitivity=36.87%, avg_specificity=96.21% avg_auc=84.50%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.203083 Test loss=0.424591 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.20202212035655975
[5/24] Train loss=0.18431788682937622
[10/24] Train loss=0.22736594080924988
[15/24] Train loss=0.21317830681800842
[20/24] Train loss=0.1765785962343216
Test set avg_accuracy=80.66% avg_sensitivity=28.33%, avg_specificity=98.24% avg_auc=80.89%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.205768 Test loss=0.530304 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.19687941670417786
[5/24] Train loss=0.17884650826454163
[10/24] Train loss=0.2214658260345459
[15/24] Train loss=0.20261944830417633
[20/24] Train loss=0.1734628826379776
Test set avg_accuracy=85.35% avg_sensitivity=72.45%, avg_specificity=89.69% avg_auc=88.54%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.203876 Test loss=0.356822 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.19146724045276642
[5/24] Train loss=0.17123931646347046
[10/24] Train loss=0.21442493796348572
[15/24] Train loss=0.2122337967157364
[20/24] Train loss=0.17554831504821777
Test set avg_accuracy=78.55% avg_sensitivity=16.78%, avg_specificity=99.30% avg_auc=77.66%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.201153 Test loss=0.587051 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.1925467848777771
[5/24] Train loss=0.18075892329216003
[10/24] Train loss=0.2113720327615738
[15/24] Train loss=0.21094012260437012
[20/24] Train loss=0.1919945478439331
Test set avg_accuracy=79.57% avg_sensitivity=21.54%, avg_specificity=99.06% avg_auc=79.88%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.201895 Test loss=0.596621 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.1965625286102295
[5/24] Train loss=0.1836075335741043
[10/24] Train loss=0.20756982266902924
[15/24] Train loss=0.19856682419776917
[20/24] Train loss=0.1740691363811493
Test set avg_accuracy=84.44% avg_sensitivity=51.68%, avg_specificity=95.44% avg_auc=86.73%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.204803 Test loss=0.409090 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.19074104726314545
[5/24] Train loss=0.1730557233095169
[10/24] Train loss=0.21350055932998657
[15/24] Train loss=0.20631222426891327
[20/24] Train loss=0.18151922523975372
Test set avg_accuracy=80.39% avg_sensitivity=47.85%, avg_specificity=91.32% avg_auc=82.88%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.202233 Test loss=0.431298 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.18989761173725128
[5/24] Train loss=0.17768050730228424
[10/24] Train loss=0.20403850078582764
[15/24] Train loss=0.19725559651851654
[20/24] Train loss=0.1729912906885147
Test set avg_accuracy=86.48% avg_sensitivity=63.75%, avg_specificity=94.12% avg_auc=88.55%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.198942 Test loss=0.347853 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.19454948604106903
[5/24] Train loss=0.17139627039432526
[10/24] Train loss=0.20828275382518768
[15/24] Train loss=0.1972595602273941
[20/24] Train loss=0.16541798412799835
Test set avg_accuracy=78.18% avg_sensitivity=86.54%, avg_specificity=75.37% avg_auc=88.98%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.197044 Test loss=0.462126 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.18477733433246613
[5/24] Train loss=0.18075305223464966
[10/24] Train loss=0.21480967104434967
[15/24] Train loss=0.19181960821151733
[20/24] Train loss=0.16819129884243011
Test set avg_accuracy=86.78% avg_sensitivity=69.45%, avg_specificity=92.61% avg_auc=90.53%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.197404 Test loss=0.323343 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.18848541378974915
[5/24] Train loss=0.18487326800823212
[10/24] Train loss=0.20794358849525452
[15/24] Train loss=0.19039735198020935
[20/24] Train loss=0.17006441950798035
Test set avg_accuracy=78.01% avg_sensitivity=14.19%, avg_specificity=99.44% avg_auc=76.88%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.197214 Test loss=0.635854 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.18593312799930573
[5/24] Train loss=0.17355382442474365
[10/24] Train loss=0.19777095317840576
[15/24] Train loss=0.1895986944437027
[20/24] Train loss=0.16470490396022797
Test set avg_accuracy=84.57% avg_sensitivity=61.11%, avg_specificity=92.45% avg_auc=87.74%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.192528 Test loss=0.361917 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.19742518663406372
[5/24] Train loss=0.17200151085853577
[10/24] Train loss=0.2035236805677414
[15/24] Train loss=0.1898181438446045
[20/24] Train loss=0.1592228263616562
Test set avg_accuracy=86.38% avg_sensitivity=66.70%, avg_specificity=92.99% avg_auc=89.37%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.186787 Test loss=0.338477 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.19016684591770172
[5/24] Train loss=0.17082028090953827
[10/24] Train loss=0.20276029407978058
[15/24] Train loss=0.1867443472146988
[20/24] Train loss=0.17761924862861633
Test set avg_accuracy=75.98% avg_sensitivity=5.18%, avg_specificity=99.76% avg_auc=73.78%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.196577 Test loss=0.689509 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.1885882467031479
[5/24] Train loss=0.18005280196666718
[10/24] Train loss=0.19616176187992096
[15/24] Train loss=0.19857889413833618
[20/24] Train loss=0.1765892058610916
Test set avg_accuracy=84.60% avg_sensitivity=53.03%, avg_specificity=95.20% avg_auc=83.82%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.193987 Test loss=0.431887 Current lr=[0.000224838296036774]

[0/24] Train loss=0.19769468903541565
[5/24] Train loss=0.17357131838798523
[10/24] Train loss=0.19626417756080627
[15/24] Train loss=0.18496574461460114
[20/24] Train loss=0.16829058527946472
Test set avg_accuracy=74.65% avg_sensitivity=87.36%, avg_specificity=70.38% avg_auc=87.34%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.187415 Test loss=0.550417 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.1853722333908081
[5/24] Train loss=0.16468453407287598
[10/24] Train loss=0.1992393285036087
[15/24] Train loss=0.1874154657125473
[20/24] Train loss=0.16459433734416962
Test set avg_accuracy=81.02% avg_sensitivity=79.60%, avg_specificity=81.49% avg_auc=88.00%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.187552 Test loss=0.413630 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.18735449016094208
[5/24] Train loss=0.16693080961704254
[10/24] Train loss=0.19753670692443848
[15/24] Train loss=0.17526684701442719
[20/24] Train loss=0.16067810356616974
Test set avg_accuracy=81.86% avg_sensitivity=64.73%, avg_specificity=87.62% avg_auc=85.22%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.185947 Test loss=0.416104 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1784294694662094
[5/24] Train loss=0.16473878920078278
[10/24] Train loss=0.20639806985855103
[15/24] Train loss=0.19146376848220825
[20/24] Train loss=0.16606414318084717
Test set avg_accuracy=84.34% avg_sensitivity=55.77%, avg_specificity=93.93% avg_auc=87.51%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.189049 Test loss=0.375608 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.17591911554336548
[5/24] Train loss=0.15962092578411102
[10/24] Train loss=0.18263350427150726
[15/24] Train loss=0.17838259041309357
[20/24] Train loss=0.15888743102550507
Test set avg_accuracy=86.61% avg_sensitivity=63.65%, avg_specificity=94.33% avg_auc=88.89%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.181706 Test loss=0.341457 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.17174884676933289
[5/24] Train loss=0.15994513034820557
[10/24] Train loss=0.2026340216398239
[15/24] Train loss=0.18657831847667694
[20/24] Train loss=0.16633817553520203
Test set avg_accuracy=86.08% avg_sensitivity=73.07%, avg_specificity=90.45% avg_auc=90.30%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.185486 Test loss=0.333821 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.17637839913368225
[5/24] Train loss=0.15880657732486725
[10/24] Train loss=0.1932794451713562
[15/24] Train loss=0.17801542580127716
[20/24] Train loss=0.17004309594631195
Test set avg_accuracy=83.68% avg_sensitivity=71.72%, avg_specificity=87.70% avg_auc=87.81%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.183615 Test loss=0.375978 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.18003156781196594
[5/24] Train loss=0.16706988215446472
[10/24] Train loss=0.1941312700510025
[15/24] Train loss=0.17920434474945068
[20/24] Train loss=0.16101685166358948
Test set avg_accuracy=86.54% avg_sensitivity=62.97%, avg_specificity=94.45% avg_auc=86.63%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.182834 Test loss=0.355208 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1738489866256714
[5/24] Train loss=0.1712392419576645
[10/24] Train loss=0.20178429782390594
[15/24] Train loss=0.17385101318359375
[20/24] Train loss=0.17229703068733215
Test set avg_accuracy=79.02% avg_sensitivity=23.82%, avg_specificity=97.56% avg_auc=77.75%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.185095 Test loss=0.587639 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.18130846321582794
[5/24] Train loss=0.16342270374298096
[10/24] Train loss=0.18940891325473785
[15/24] Train loss=0.18384088575839996
[20/24] Train loss=0.15339383482933044
Test set avg_accuracy=85.39% avg_sensitivity=53.29%, avg_specificity=96.17% avg_auc=87.28%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.181243 Test loss=0.378508 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.17510159313678741
[5/24] Train loss=0.16367511451244354
[10/24] Train loss=0.18641485273838043
[15/24] Train loss=0.1732177883386612
[20/24] Train loss=0.15775413811206818
Test set avg_accuracy=83.48% avg_sensitivity=48.32%, avg_specificity=95.29% avg_auc=84.24%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.176843 Test loss=0.413747 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.17266765236854553
[5/24] Train loss=0.1690957099199295
[10/24] Train loss=0.18317341804504395
[15/24] Train loss=0.17285463213920593
[20/24] Train loss=0.1574113667011261
Test set avg_accuracy=85.72% avg_sensitivity=70.59%, avg_specificity=90.80% avg_auc=87.91%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.178257 Test loss=0.362124 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.17883282899856567
[5/24] Train loss=0.16487233340740204
[10/24] Train loss=0.19777517020702362
[15/24] Train loss=0.16977055370807648
[20/24] Train loss=0.15528616309165955
Test set avg_accuracy=83.29% avg_sensitivity=67.74%, avg_specificity=88.52% avg_auc=86.62%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.177572 Test loss=0.392691 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.17047956585884094
[5/24] Train loss=0.1557510793209076
[10/24] Train loss=0.17561665177345276
[15/24] Train loss=0.16943205893039703
[20/24] Train loss=0.1527463048696518
Test set avg_accuracy=84.05% avg_sensitivity=48.27%, avg_specificity=96.07% avg_auc=85.15%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.176848 Test loss=0.416147 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.17730006575584412
[5/24] Train loss=0.1618773341178894
[10/24] Train loss=0.1787012666463852
[15/24] Train loss=0.1680341511964798
[20/24] Train loss=0.15138033032417297
Test set avg_accuracy=80.26% avg_sensitivity=71.00%, avg_specificity=83.37% avg_auc=85.95%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.176844 Test loss=0.441058 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.16929401457309723
[5/24] Train loss=0.15550890564918518
[10/24] Train loss=0.19021305441856384
[15/24] Train loss=0.15963712334632874
[20/24] Train loss=0.15828244388103485
Test set avg_accuracy=86.02% avg_sensitivity=61.42%, avg_specificity=94.28% avg_auc=87.81%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.172785 Test loss=0.357060 Current lr=[0.000156543481933168]

[0/24] Train loss=0.17065401375293732
[5/24] Train loss=0.1559704840183258
[10/24] Train loss=0.1743565946817398
[15/24] Train loss=0.17438572645187378
[20/24] Train loss=0.15063610672950745
Test set avg_accuracy=86.20% avg_sensitivity=65.35%, avg_specificity=93.20% avg_auc=88.17%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.170316 Test loss=0.346219 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.15999308228492737
[5/24] Train loss=0.14595788717269897
[10/24] Train loss=0.18841108679771423
[15/24] Train loss=0.16047625243663788
[20/24] Train loss=0.15184015035629272
Test set avg_accuracy=85.99% avg_sensitivity=61.52%, avg_specificity=94.21% avg_auc=88.11%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.168744 Test loss=0.355758 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.16726185381412506
[5/24] Train loss=0.14932069182395935
[10/24] Train loss=0.1800764501094818
[15/24] Train loss=0.1656942069530487
[20/24] Train loss=0.1435256451368332
Test set avg_accuracy=81.85% avg_sensitivity=33.66%, avg_specificity=98.03% avg_auc=79.18%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.169196 Test loss=0.528823 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.162077397108078
[5/24] Train loss=0.1498968005180359
[10/24] Train loss=0.17151671648025513
[15/24] Train loss=0.1618952602148056
[20/24] Train loss=0.14980266988277435
Test set avg_accuracy=85.86% avg_sensitivity=75.14%, avg_specificity=89.46% avg_auc=88.75%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.166918 Test loss=0.356062 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15537439286708832
[5/24] Train loss=0.15512962639331818
[10/24] Train loss=0.18154065310955048
[15/24] Train loss=0.17132261395454407
[20/24] Train loss=0.142948716878891
Test set avg_accuracy=85.38% avg_sensitivity=61.68%, avg_specificity=93.34% avg_auc=85.78%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.166665 Test loss=0.396370 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16636262834072113
[5/24] Train loss=0.14841677248477936
[10/24] Train loss=0.16567930579185486
[15/24] Train loss=0.1602398306131363
[20/24] Train loss=0.14753325283527374
Test set avg_accuracy=83.89% avg_sensitivity=47.28%, avg_specificity=96.19% avg_auc=84.30%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.165645 Test loss=0.435826 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.16243116557598114
[5/24] Train loss=0.15494398772716522
[10/24] Train loss=0.16435521841049194
[15/24] Train loss=0.15659615397453308
[20/24] Train loss=0.14251413941383362
Test set avg_accuracy=85.92% avg_sensitivity=67.84%, avg_specificity=92.00% avg_auc=88.79%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.162180 Test loss=0.349970 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.15605272352695465
[5/24] Train loss=0.1507948637008667
[10/24] Train loss=0.16883322596549988
[15/24] Train loss=0.16331781446933746
[20/24] Train loss=0.14312013983726501
Test set avg_accuracy=85.42% avg_sensitivity=73.90%, avg_specificity=89.29% avg_auc=88.50%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.163864 Test loss=0.356651 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.1617719978094101
[5/24] Train loss=0.14609795808792114
[10/24] Train loss=0.17086298763751984
[15/24] Train loss=0.15624748170375824
[20/24] Train loss=0.14093896746635437
Test set avg_accuracy=85.13% avg_sensitivity=70.84%, avg_specificity=89.93% avg_auc=87.63%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.163764 Test loss=0.370005 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.16056957840919495
[5/24] Train loss=0.15947271883487701
[10/24] Train loss=0.16062472760677338
[15/24] Train loss=0.16036660969257355
[20/24] Train loss=0.1511266827583313
Test set avg_accuracy=85.82% avg_sensitivity=74.47%, avg_specificity=89.63% avg_auc=90.02%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.164123 Test loss=0.344890 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1597580462694168
[5/24] Train loss=0.14335861802101135
[10/24] Train loss=0.18147748708724976
[15/24] Train loss=0.1625206619501114
[20/24] Train loss=0.14692817628383636
Test set avg_accuracy=84.54% avg_sensitivity=79.18%, avg_specificity=86.35% avg_auc=90.13%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.163446 Test loss=0.370876 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1704750955104828
[5/24] Train loss=0.15064188838005066
[10/24] Train loss=0.17117895185947418
[15/24] Train loss=0.1530076116323471
[20/24] Train loss=0.13388869166374207
Test set avg_accuracy=85.44% avg_sensitivity=77.99%, avg_specificity=87.95% avg_auc=90.30%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.163282 Test loss=0.356984 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.16150891780853271
[5/24] Train loss=0.14715924859046936
[10/24] Train loss=0.1656082719564438
[15/24] Train loss=0.1552022397518158
[20/24] Train loss=0.1388079971075058
Test set avg_accuracy=86.17% avg_sensitivity=69.81%, avg_specificity=91.67% avg_auc=89.38%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.159430 Test loss=0.344041 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.15731586515903473
[5/24] Train loss=0.15423567593097687
[10/24] Train loss=0.15703429281711578
[15/24] Train loss=0.15530206263065338
[20/24] Train loss=0.14416828751564026
Test set avg_accuracy=87.08% avg_sensitivity=61.42%, avg_specificity=95.70% avg_auc=88.15%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.160191 Test loss=0.357157 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15567007660865784
[5/24] Train loss=0.14795997738838196
[10/24] Train loss=0.15837983787059784
[15/24] Train loss=0.15923739969730377
[20/24] Train loss=0.13714343309402466
Test set avg_accuracy=86.51% avg_sensitivity=76.80%, avg_specificity=89.77% avg_auc=90.69%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.157451 Test loss=0.342630 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.16437526047229767
[5/24] Train loss=0.1451393961906433
[10/24] Train loss=0.1666875034570694
[15/24] Train loss=0.15672916173934937
[20/24] Train loss=0.1389988362789154
Test set avg_accuracy=81.65% avg_sensitivity=83.38%, avg_specificity=81.07% avg_auc=89.05%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.158106 Test loss=0.428210 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.15442457795143127
[5/24] Train loss=0.14130041003227234
[10/24] Train loss=0.15856540203094482
[15/24] Train loss=0.15079572796821594
[20/24] Train loss=0.13396041095256805
Test set avg_accuracy=86.80% avg_sensitivity=64.32%, avg_specificity=94.35% avg_auc=89.61%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.155225 Test loss=0.342001 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14959993958473206
[5/24] Train loss=0.14090649783611298
[10/24] Train loss=0.1543697565793991
[15/24] Train loss=0.157663494348526
[20/24] Train loss=0.1321086883544922
Test set avg_accuracy=86.71% avg_sensitivity=67.37%, avg_specificity=93.20% avg_auc=90.17%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.154116 Test loss=0.334826 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14573152363300323
[5/24] Train loss=0.1337650865316391
[10/24] Train loss=0.15781070291996002
[15/24] Train loss=0.1482383906841278
[20/24] Train loss=0.13784858584403992
Test set avg_accuracy=85.89% avg_sensitivity=75.76%, avg_specificity=89.29% avg_auc=90.03%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.151997 Test loss=0.351691 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15171308815479279
[5/24] Train loss=0.13380713760852814
[10/24] Train loss=0.1486676037311554
[15/24] Train loss=0.14893631637096405
[20/24] Train loss=0.1332852840423584
Test set avg_accuracy=86.50% avg_sensitivity=70.84%, avg_specificity=91.76% avg_auc=90.05%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.150178 Test loss=0.336055 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.15024758875370026
[5/24] Train loss=0.13984714448451996
[10/24] Train loss=0.15417611598968506
[15/24] Train loss=0.14803281426429749
[20/24] Train loss=0.1277085840702057
Test set avg_accuracy=86.04% avg_sensitivity=71.78%, avg_specificity=90.83% avg_auc=89.90%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.149370 Test loss=0.342665 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14761866629123688
[5/24] Train loss=0.1359797716140747
[10/24] Train loss=0.1535337269306183
[15/24] Train loss=0.14711183309555054
[20/24] Train loss=0.12635920941829681
Test set avg_accuracy=86.69% avg_sensitivity=64.47%, avg_specificity=94.16% avg_auc=88.89%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.147736 Test loss=0.344895 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14636369049549103
[5/24] Train loss=0.13946349918842316
[10/24] Train loss=0.14462141692638397
[15/24] Train loss=0.14164696633815765
[20/24] Train loss=0.1285240352153778
Test set avg_accuracy=86.55% avg_sensitivity=71.62%, avg_specificity=91.56% avg_auc=90.09%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.145965 Test loss=0.338981 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14252154529094696
[5/24] Train loss=0.13513396680355072
[10/24] Train loss=0.14591912925243378
[15/24] Train loss=0.14030781388282776
[20/24] Train loss=0.12447866797447205
Test set avg_accuracy=86.67% avg_sensitivity=66.44%, avg_specificity=93.46% avg_auc=89.31%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.144564 Test loss=0.338843 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14305144548416138
[5/24] Train loss=0.13330620527267456
[10/24] Train loss=0.14308322966098785
[15/24] Train loss=0.1441696584224701
[20/24] Train loss=0.12665358185768127
Test set avg_accuracy=86.32% avg_sensitivity=70.38%, avg_specificity=91.67% avg_auc=89.49%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.144109 Test loss=0.345384 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.13863815367221832
[5/24] Train loss=0.13188019394874573
[10/24] Train loss=0.14207905530929565
[15/24] Train loss=0.1421026885509491
[20/24] Train loss=0.1263129562139511
Test set avg_accuracy=86.07% avg_sensitivity=68.67%, avg_specificity=91.91% avg_auc=89.48%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.143735 Test loss=0.344904 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14429952204227448
[5/24] Train loss=0.1297045350074768
[10/24] Train loss=0.14324359595775604
[15/24] Train loss=0.14308208227157593
[20/24] Train loss=0.1261683851480484
Test set avg_accuracy=87.29% avg_sensitivity=70.53%, avg_specificity=92.92% avg_auc=89.55%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.142592 Test loss=0.333106 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13650374114513397
[5/24] Train loss=0.12878260016441345
[10/24] Train loss=0.14513953030109406
[15/24] Train loss=0.13981086015701294
[20/24] Train loss=0.12427389621734619
Test set avg_accuracy=86.09% avg_sensitivity=70.90%, avg_specificity=91.20% avg_auc=89.36%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.140903 Test loss=0.346154 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13933666050434113
[5/24] Train loss=0.13553890585899353
[10/24] Train loss=0.14164766669273376
[15/24] Train loss=0.14200487732887268
[20/24] Train loss=0.12411083281040192
Test set avg_accuracy=85.21% avg_sensitivity=74.73%, avg_specificity=88.73% avg_auc=89.18%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.141152 Test loss=0.359600 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13613665103912354
[5/24] Train loss=0.1313299685716629
[10/24] Train loss=0.1421925574541092
[15/24] Train loss=0.13762153685092926
[20/24] Train loss=0.12588992714881897
Test set avg_accuracy=86.71% avg_sensitivity=67.94%, avg_specificity=93.01% avg_auc=87.93%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.140297 Test loss=0.355301 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13719436526298523
[5/24] Train loss=0.12581667304039001
[10/24] Train loss=0.1399899125099182
[15/24] Train loss=0.13822513818740845
[20/24] Train loss=0.12625858187675476
Test set avg_accuracy=86.13% avg_sensitivity=75.04%, avg_specificity=89.86% avg_auc=89.86%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.140465 Test loss=0.348843 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13767772912979126
[5/24] Train loss=0.13178393244743347
[10/24] Train loss=0.14099328219890594
[15/24] Train loss=0.13914942741394043
[20/24] Train loss=0.12375867366790771
Test set avg_accuracy=85.86% avg_sensitivity=76.44%, avg_specificity=89.02% avg_auc=89.72%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.140779 Test loss=0.354153 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13797467947006226
[5/24] Train loss=0.1269731968641281
[10/24] Train loss=0.13625364005565643
[15/24] Train loss=0.13478843867778778
[20/24] Train loss=0.12137502431869507
Test set avg_accuracy=86.35% avg_sensitivity=71.67%, avg_specificity=91.29% avg_auc=89.02%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.139707 Test loss=0.355441 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1367141157388687
[5/24] Train loss=0.12526337802410126
[10/24] Train loss=0.13792359828948975
[15/24] Train loss=0.1399713158607483
[20/24] Train loss=0.12241113185882568
Test set avg_accuracy=86.86% avg_sensitivity=68.25%, avg_specificity=93.11% avg_auc=89.31%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.139472 Test loss=0.343223 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13751761615276337
[5/24] Train loss=0.1275758594274521
[10/24] Train loss=0.1395387351512909
[15/24] Train loss=0.13440924882888794
[20/24] Train loss=0.11785636842250824
Test set avg_accuracy=86.00% avg_sensitivity=71.31%, avg_specificity=90.94% avg_auc=89.17%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.138311 Test loss=0.351743 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13983139395713806
[5/24] Train loss=0.12836870551109314
[10/24] Train loss=0.1362762153148651
[15/24] Train loss=0.13575950264930725
[20/24] Train loss=0.12026514112949371
Test set avg_accuracy=86.98% avg_sensitivity=71.62%, avg_specificity=92.14% avg_auc=89.65%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.137557 Test loss=0.339355 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1345682591199875
[5/24] Train loss=0.12416191399097443
[10/24] Train loss=0.13516400754451752
[15/24] Train loss=0.13657408952713013
[20/24] Train loss=0.12206633388996124
Test set avg_accuracy=86.95% avg_sensitivity=71.83%, avg_specificity=92.03% avg_auc=90.08%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.136532 Test loss=0.334899 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1326046586036682
[5/24] Train loss=0.12340150773525238
[10/24] Train loss=0.1386227011680603
[15/24] Train loss=0.13643617928028107
[20/24] Train loss=0.11827097833156586
Test set avg_accuracy=87.17% avg_sensitivity=71.31%, avg_specificity=92.50% avg_auc=89.30%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.135931 Test loss=0.339884 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13486485183238983
[5/24] Train loss=0.12238314002752304
[10/24] Train loss=0.1340094357728958
[15/24] Train loss=0.13306307792663574
[20/24] Train loss=0.11732520908117294
Test set avg_accuracy=87.15% avg_sensitivity=70.84%, avg_specificity=92.62% avg_auc=89.59%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.133909 Test loss=0.338249 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13575777411460876
[5/24] Train loss=0.12439275532960892
[10/24] Train loss=0.13051266968250275
[15/24] Train loss=0.13199594616889954
[20/24] Train loss=0.11823852360248566
Test set avg_accuracy=87.07% avg_sensitivity=72.45%, avg_specificity=91.98% avg_auc=89.50%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.133677 Test loss=0.340681 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.13544118404388428
[5/24] Train loss=0.12270750850439072
[10/24] Train loss=0.12810510396957397
[15/24] Train loss=0.13503125309944153
[20/24] Train loss=0.11684286594390869
Test set avg_accuracy=86.91% avg_sensitivity=71.72%, avg_specificity=92.02% avg_auc=89.75%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.133350 Test loss=0.340421 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13154172897338867
[5/24] Train loss=0.12760882079601288
[10/24] Train loss=0.13442404568195343
[15/24] Train loss=0.13269898295402527
[20/24] Train loss=0.11839654296636581
Test set avg_accuracy=87.29% avg_sensitivity=71.72%, avg_specificity=92.52% avg_auc=89.72%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.133352 Test loss=0.336151 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.13232338428497314
[5/24] Train loss=0.11997221410274506
[10/24] Train loss=0.13117162883281708
[15/24] Train loss=0.13071246445178986
[20/24] Train loss=0.11735943704843521
Test set avg_accuracy=87.16% avg_sensitivity=71.47%, avg_specificity=92.43% avg_auc=89.56%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.132898 Test loss=0.338776 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13167107105255127
[5/24] Train loss=0.12636594474315643
[10/24] Train loss=0.13296137750148773
[15/24] Train loss=0.13113318383693695
[20/24] Train loss=0.11615597456693649
Test set avg_accuracy=87.29% avg_sensitivity=70.74%, avg_specificity=92.85% avg_auc=89.43%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.132431 Test loss=0.339160 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1329677850008011
[5/24] Train loss=0.1212017610669136
[10/24] Train loss=0.13136214017868042
[15/24] Train loss=0.1309329718351364
[20/24] Train loss=0.11603820323944092
Test set avg_accuracy=87.24% avg_sensitivity=72.55%, avg_specificity=92.17% avg_auc=89.75%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.132202 Test loss=0.338608 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1307065188884735
[5/24] Train loss=0.1217186376452446
[10/24] Train loss=0.13329824805259705
[15/24] Train loss=0.12757807970046997
[20/24] Train loss=0.11781549453735352
Test set avg_accuracy=87.02% avg_sensitivity=71.36%, avg_specificity=92.28% avg_auc=89.30%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.132555 Test loss=0.341826 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13009542226791382
[5/24] Train loss=0.12123017013072968
[10/24] Train loss=0.12894143164157867
[15/24] Train loss=0.13411810994148254
[20/24] Train loss=0.1176786720752716
Test set avg_accuracy=86.98% avg_sensitivity=70.79%, avg_specificity=92.42% avg_auc=89.43%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.132661 Test loss=0.341871 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1309029757976532
[5/24] Train loss=0.12562835216522217
[10/24] Train loss=0.13018126785755157
[15/24] Train loss=0.12964919209480286
[20/24] Train loss=0.1156274601817131
Test set avg_accuracy=87.15% avg_sensitivity=71.10%, avg_specificity=92.54% avg_auc=89.40%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.131648 Test loss=0.340948 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13140152394771576
[5/24] Train loss=0.12053140997886658
[10/24] Train loss=0.1311195343732834
[15/24] Train loss=0.1288333535194397
[20/24] Train loss=0.11749671399593353
Test set avg_accuracy=87.12% avg_sensitivity=71.52%, avg_specificity=92.36% avg_auc=89.40%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.131792 Test loss=0.340710 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12987112998962402
[5/24] Train loss=0.1224520355463028
[10/24] Train loss=0.13167347013950348
[15/24] Train loss=0.13081204891204834
[20/24] Train loss=0.1168787032365799
Test set avg_accuracy=87.12% avg_sensitivity=71.10%, avg_specificity=92.50% avg_auc=89.31%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.131382 Test loss=0.341516 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1329767107963562
[5/24] Train loss=0.12033027410507202
[10/24] Train loss=0.12899518013000488
[15/24] Train loss=0.13022761046886444
[20/24] Train loss=0.1155480444431305
Test set avg_accuracy=87.11% avg_sensitivity=71.21%, avg_specificity=92.45% avg_auc=89.30%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.130900 Test loss=0.341671 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.13484148681163788
[5/24] Train loss=0.12100973725318909
[10/24] Train loss=0.1314803659915924
[15/24] Train loss=0.12866272032260895
[20/24] Train loss=0.11526302248239517
Test set avg_accuracy=87.12% avg_sensitivity=71.26%, avg_specificity=92.45% avg_auc=89.34%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.131429 Test loss=0.341517 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12987452745437622
[5/24] Train loss=0.12051501870155334
[10/24] Train loss=0.12943610548973083
[15/24] Train loss=0.13312691450119019
[20/24] Train loss=0.11450286954641342
Test set avg_accuracy=87.10% avg_sensitivity=71.36%, avg_specificity=92.38% avg_auc=89.37%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.130972 Test loss=0.341524 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12965364754199982
[5/24] Train loss=0.11849527806043625
[10/24] Train loss=0.13109488785266876
[15/24] Train loss=0.13038590550422668
[20/24] Train loss=0.11513621360063553
Test set avg_accuracy=87.08% avg_sensitivity=71.15%, avg_specificity=92.43% avg_auc=89.34%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.131098 Test loss=0.341677 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=86.64% sen=79.18%, spe=89.15%, auc=92.42%!
Fold[8] Avg_overlap=0.68%(±0.2134698514539268)
[0/23] Train loss=0.7224543690681458
[5/23] Train loss=0.7233883142471313
[10/23] Train loss=0.7224822044372559
[15/23] Train loss=0.7132893800735474
[20/23] Train loss=0.6965811848640442
Test set avg_accuracy=62.08% avg_sensitivity=48.84%, avg_specificity=66.30% avg_auc=60.96%
Best model saved!! Metric=-87.81162172375632!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.716976 Test loss=0.655568 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.6994047164916992
[5/23] Train loss=0.6916678547859192
[10/23] Train loss=0.6916739344596863
[15/23] Train loss=0.6780820488929749
[20/23] Train loss=0.6706914901733398
Test set avg_accuracy=66.20% avg_sensitivity=64.96%, avg_specificity=66.59% avg_auc=71.28%
Best model saved!! Metric=-56.96707297968989!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.686899 Test loss=0.622335 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.6689541339874268
[5/23] Train loss=0.6680410504341125
[10/23] Train loss=0.668461799621582
[15/23] Train loss=0.6530035734176636
[20/23] Train loss=0.6506282091140747
Test set avg_accuracy=69.90% avg_sensitivity=66.36%, avg_specificity=71.02% avg_auc=75.16%
Best model saved!! Metric=-43.56088612341851!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.661768 Test loss=0.590550 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.6426444053649902
[5/23] Train loss=0.6402579545974731
[10/23] Train loss=0.6468740105628967
[15/23] Train loss=0.6345250010490417
[20/23] Train loss=0.6259188652038574
Test set avg_accuracy=72.20% avg_sensitivity=67.65%, avg_specificity=73.65% avg_auc=77.99%
Best model saved!! Metric=-34.50307344266355!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.637216 Test loss=0.562701 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.6218003034591675
[5/23] Train loss=0.6145433187484741
[10/23] Train loss=0.6171087622642517
[15/23] Train loss=0.6006222367286682
[20/23] Train loss=0.5989164113998413
Test set avg_accuracy=73.48% avg_sensitivity=71.37%, avg_specificity=74.15% avg_auc=80.17%
Best model saved!! Metric=-26.8364715224194!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.611835 Test loss=0.543018 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.595939040184021
[5/23] Train loss=0.5950481295585632
[10/23] Train loss=0.598090410232544
[15/23] Train loss=0.5729318261146545
[20/23] Train loss=0.5736802816390991
Test set avg_accuracy=74.92% avg_sensitivity=73.48%, avg_specificity=75.38% avg_auc=82.01%
Best model saved!! Metric=-20.20946935408304!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.586599 Test loss=0.518483 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.5670803189277649
[5/23] Train loss=0.5739094018936157
[10/23] Train loss=0.565960168838501
[15/23] Train loss=0.5475173592567444
[20/23] Train loss=0.5414751768112183
Test set avg_accuracy=76.93% avg_sensitivity=72.83%, avg_specificity=78.23% avg_auc=83.65%
Best model saved!! Metric=-14.363385530542288!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.559638 Test loss=0.490655 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.5492650866508484
[5/23] Train loss=0.5373760461807251
[10/23] Train loss=0.5384351015090942
[15/23] Train loss=0.516270101070404
[20/23] Train loss=0.5206568837165833
Test set avg_accuracy=78.62% avg_sensitivity=73.10%, avg_specificity=80.38% avg_auc=85.25%
Best model saved!! Metric=-8.651094350708945!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.535876 Test loss=0.470607 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.5146411061286926
[5/23] Train loss=0.5173647999763489
[10/23] Train loss=0.5140329599380493
[15/23] Train loss=0.49417802691459656
[20/23] Train loss=0.49390819668769836
Test set avg_accuracy=80.26% avg_sensitivity=73.69%, avg_specificity=82.35% avg_auc=86.74%
Best model saved!! Metric=-2.9559409331389617!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.508937 Test loss=0.447105 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.48412400484085083
[5/23] Train loss=0.49706584215164185
[10/23] Train loss=0.4852568507194519
[15/23] Train loss=0.47384199500083923
[20/23] Train loss=0.4624249339103699
Test set avg_accuracy=82.28% avg_sensitivity=71.48%, avg_specificity=85.72% avg_auc=87.68%
Best model saved!! Metric=1.1605587701818791!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.484605 Test loss=0.423037 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.4627476632595062
[5/23] Train loss=0.46647849678993225
[10/23] Train loss=0.4683164954185486
[15/23] Train loss=0.44095543026924133
[20/23] Train loss=0.44131115078926086
Test set avg_accuracy=82.73% avg_sensitivity=72.94%, avg_specificity=85.85% avg_auc=88.33%
Best model saved!! Metric=3.8519438025635395!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.461002 Test loss=0.413038 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.4424820840358734
[5/23] Train loss=0.44604435563087463
[10/23] Train loss=0.4402381479740143
[15/23] Train loss=0.42823272943496704
[20/23] Train loss=0.4204447567462921
Test set avg_accuracy=83.36% avg_sensitivity=70.84%, avg_specificity=87.35% avg_auc=88.91%
Best model saved!! Metric=4.454394839663124!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.440051 Test loss=0.395263 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.42521733045578003
[5/23] Train loss=0.4323534369468689
[10/23] Train loss=0.42096155881881714
[15/23] Train loss=0.4087088406085968
[20/23] Train loss=0.4037224054336548
Test set avg_accuracy=83.87% avg_sensitivity=68.63%, avg_specificity=88.72% avg_auc=89.10%
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.422600 Test loss=0.382042 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.4046843349933624
[5/23] Train loss=0.4213268756866455
[10/23] Train loss=0.40891212224960327
[15/23] Train loss=0.38709262013435364
[20/23] Train loss=0.38785624504089355
Test set avg_accuracy=84.40% avg_sensitivity=65.55%, avg_specificity=90.40% avg_auc=89.37%
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.406455 Test loss=0.368647 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.3872176706790924
[5/23] Train loss=0.4023423194885254
[10/23] Train loss=0.39537400007247925
[15/23] Train loss=0.3744492530822754
[20/23] Train loss=0.37101665139198303
Test set avg_accuracy=84.41% avg_sensitivity=60.92%, avg_specificity=91.90% avg_auc=89.45%
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.392106 Test loss=0.359437 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.3757685422897339
[5/23] Train loss=0.3963399827480316
[10/23] Train loss=0.38071343302726746
[15/23] Train loss=0.35619306564331055
[20/23] Train loss=0.35294872522354126
Test set avg_accuracy=84.52% avg_sensitivity=66.47%, avg_specificity=90.27% avg_auc=89.79%
Best model saved!! Metric=5.045406613076452!!
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.378842 Test loss=0.357981 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.3602731227874756
[5/23] Train loss=0.3904561698436737
[10/23] Train loss=0.37101295590400696
[15/23] Train loss=0.34615328907966614
[20/23] Train loss=0.34218305349349976
Test set avg_accuracy=84.62% avg_sensitivity=67.49%, avg_specificity=90.08% avg_auc=90.11%
Best model saved!! Metric=6.302656814557963!!
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.368686 Test loss=0.351765 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.3500427305698395
[5/23] Train loss=0.365842342376709
[10/23] Train loss=0.3601917326450348
[15/23] Train loss=0.3384893834590912
[20/23] Train loss=0.3302121162414551
Test set avg_accuracy=84.56% avg_sensitivity=66.79%, avg_specificity=90.21% avg_auc=90.43%
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.358671 Test loss=0.345058 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.3371000587940216
[5/23] Train loss=0.36315518617630005
[10/23] Train loss=0.3508721888065338
[15/23] Train loss=0.32575494050979614
[20/23] Train loss=0.32863911986351013
Test set avg_accuracy=84.02% avg_sensitivity=75.36%, avg_specificity=86.78% avg_auc=90.55%
Best model saved!! Metric=10.717240352746884!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.350893 Test loss=0.357470 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.33364272117614746
[5/23] Train loss=0.3570721447467804
[10/23] Train loss=0.34557801485061646
[15/23] Train loss=0.314465194940567
[20/23] Train loss=0.31784799695014954
Test set avg_accuracy=84.40% avg_sensitivity=74.29%, avg_specificity=87.62% avg_auc=90.76%
Best model saved!! Metric=11.070921240489866!!
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.342694 Test loss=0.347941 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.32298749685287476
[5/23] Train loss=0.34969839453697205
[10/23] Train loss=0.3347052335739136
[15/23] Train loss=0.3064344525337219
[20/23] Train loss=0.3072107136249542
Test set avg_accuracy=84.49% avg_sensitivity=71.81%, avg_specificity=88.53% avg_auc=90.56%
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.334832 Test loss=0.345445 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.3234594464302063
[5/23] Train loss=0.3421556055545807
[10/23] Train loss=0.33646273612976074
[15/23] Train loss=0.30095145106315613
[20/23] Train loss=0.29966750741004944
Test set avg_accuracy=85.03% avg_sensitivity=68.30%, avg_specificity=90.35% avg_auc=90.96%
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.328756 Test loss=0.332350 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.30668026208877563
[5/23] Train loss=0.33882230520248413
[10/23] Train loss=0.3203418254852295
[15/23] Train loss=0.2902023494243622
[20/23] Train loss=0.2948192358016968
Test set avg_accuracy=84.80% avg_sensitivity=71.43%, avg_specificity=89.06% avg_auc=90.79%
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.321597 Test loss=0.338280 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.3067316710948944
[5/23] Train loss=0.3334518074989319
[10/23] Train loss=0.32081955671310425
[15/23] Train loss=0.2922367751598358
[20/23] Train loss=0.28756919503211975
Test set avg_accuracy=85.81% avg_sensitivity=66.47%, avg_specificity=91.97% avg_auc=90.69%
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.317170 Test loss=0.329089 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.30014219880104065
[5/23] Train loss=0.3261570930480957
[10/23] Train loss=0.3205093443393707
[15/23] Train loss=0.2818571925163269
[20/23] Train loss=0.28607454895973206
Test set avg_accuracy=85.72% avg_sensitivity=69.70%, avg_specificity=90.82% avg_auc=91.20%
Best model saved!! Metric=11.436146296065985!!
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.314450 Test loss=0.325177 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.3004719614982605
[5/23] Train loss=0.3182193338871002
[10/23] Train loss=0.3091362714767456
[15/23] Train loss=0.2747516632080078
[20/23] Train loss=0.2822740077972412
Test set avg_accuracy=85.70% avg_sensitivity=62.80%, avg_specificity=93.00% avg_auc=90.51%
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.306251 Test loss=0.329494 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.2906332314014435
[5/23] Train loss=0.32368141412734985
[10/23] Train loss=0.3092506527900696
[15/23] Train loss=0.26705101132392883
[20/23] Train loss=0.2735344469547272
Test set avg_accuracy=85.31% avg_sensitivity=73.48%, avg_specificity=89.08% avg_auc=91.04%
Best model saved!! Metric=12.909279380632327!!
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.301298 Test loss=0.329406 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.2791271209716797
[5/23] Train loss=0.29637229442596436
[10/23] Train loss=0.30570724606513977
[15/23] Train loss=0.27287694811820984
[20/23] Train loss=0.2696272134780884
Test set avg_accuracy=85.78% avg_sensitivity=69.43%, avg_specificity=90.99% avg_auc=91.24%
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.294037 Test loss=0.324168 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.2828582227230072
[5/23] Train loss=0.29748281836509705
[10/23] Train loss=0.29853060841560364
[15/23] Train loss=0.2628270089626312
[20/23] Train loss=0.2582680881023407
Test set avg_accuracy=86.09% avg_sensitivity=69.81%, avg_specificity=91.28% avg_auc=91.06%
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.288134 Test loss=0.323494 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.26500287652015686
[5/23] Train loss=0.28619998693466187
[10/23] Train loss=0.2956005334854126
[15/23] Train loss=0.2586459815502167
[20/23] Train loss=0.26104581356048584
Test set avg_accuracy=84.84% avg_sensitivity=62.43%, avg_specificity=91.98% avg_auc=89.89%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.280747 Test loss=0.334799 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.2593480348587036
[5/23] Train loss=0.2829333543777466
[10/23] Train loss=0.2964172661304474
[15/23] Train loss=0.2526857852935791
[20/23] Train loss=0.24611277878284454
Test set avg_accuracy=86.02% avg_sensitivity=66.04%, avg_specificity=92.38% avg_auc=90.14%
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.279260 Test loss=0.329023 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.2530248761177063
[5/23] Train loss=0.2670935392379761
[10/23] Train loss=0.2984074354171753
[15/23] Train loss=0.2591245174407959
[20/23] Train loss=0.2537643313407898
Test set avg_accuracy=80.60% avg_sensitivity=78.98%, avg_specificity=81.12% avg_auc=88.84%
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.277823 Test loss=0.403022 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.25931277871131897
[5/23] Train loss=0.2595290243625641
[10/23] Train loss=0.279002845287323
[15/23] Train loss=0.24687252938747406
[20/23] Train loss=0.23794221878051758
Test set avg_accuracy=84.05% avg_sensitivity=66.36%, avg_specificity=89.68% avg_auc=89.71%
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.268429 Test loss=0.343678 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.24432584643363953
[5/23] Train loss=0.255098432302475
[10/23] Train loss=0.2645048201084137
[15/23] Train loss=0.2463243156671524
[20/23] Train loss=0.24037976562976837
Test set avg_accuracy=83.20% avg_sensitivity=77.41%, avg_specificity=85.05% avg_auc=89.21%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.267962 Test loss=0.382686 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.25193220376968384
[5/23] Train loss=0.2575478255748749
[10/23] Train loss=0.28082576394081116
[15/23] Train loss=0.23735330998897552
[20/23] Train loss=0.24467897415161133
Test set avg_accuracy=85.85% avg_sensitivity=64.20%, avg_specificity=92.74% avg_auc=90.39%
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.263723 Test loss=0.330471 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.2538851499557495
[5/23] Train loss=0.2511049807071686
[10/23] Train loss=0.26330336928367615
[15/23] Train loss=0.23579347133636475
[20/23] Train loss=0.23261132836341858
Test set avg_accuracy=85.27% avg_sensitivity=56.17%, avg_specificity=94.54% avg_auc=89.11%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.259898 Test loss=0.350156 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.23261767625808716
[5/23] Train loss=0.22977419197559357
[10/23] Train loss=0.25790172815322876
[15/23] Train loss=0.22240793704986572
[20/23] Train loss=0.24076227843761444
Test set avg_accuracy=85.65% avg_sensitivity=57.14%, avg_specificity=94.73% avg_auc=89.96%
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.248814 Test loss=0.337567 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.2251538783311844
[5/23] Train loss=0.2312355488538742
[10/23] Train loss=0.24710579216480255
[15/23] Train loss=0.2319374531507492
[20/23] Train loss=0.23718930780887604
Test set avg_accuracy=83.58% avg_sensitivity=75.09%, avg_specificity=86.28% avg_auc=89.70%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.250496 Test loss=0.367396 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.2254086583852768
[5/23] Train loss=0.23061475157737732
[10/23] Train loss=0.24118870496749878
[15/23] Train loss=0.22729864716529846
[20/23] Train loss=0.23852622509002686
Test set avg_accuracy=83.22% avg_sensitivity=38.06%, avg_specificity=97.60% avg_auc=86.63%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.248257 Test loss=0.408488 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.23923060297966003
[5/23] Train loss=0.23218588531017303
[10/23] Train loss=0.2721080780029297
[15/23] Train loss=0.23252663016319275
[20/23] Train loss=0.22649873793125153
Test set avg_accuracy=85.03% avg_sensitivity=51.64%, avg_specificity=95.66% avg_auc=88.87%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.250160 Test loss=0.361432 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.23581203818321228
[5/23] Train loss=0.23084308207035065
[10/23] Train loss=0.27473288774490356
[15/23] Train loss=0.22434476017951965
[20/23] Train loss=0.22025467455387115
Test set avg_accuracy=84.87% avg_sensitivity=64.58%, avg_specificity=91.33% avg_auc=89.37%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.245532 Test loss=0.346544 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.21353277564048767
[5/23] Train loss=0.22355417907238007
[10/23] Train loss=0.2338796854019165
[15/23] Train loss=0.23488090932369232
[20/23] Train loss=0.21990129351615906
Test set avg_accuracy=85.65% avg_sensitivity=70.03%, avg_specificity=90.63% avg_auc=90.08%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.241102 Test loss=0.335100 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.21876923739910126
[5/23] Train loss=0.21316024661064148
[10/23] Train loss=0.2785264551639557
[15/23] Train loss=0.2237573117017746
[20/23] Train loss=0.24379213154315948
Test set avg_accuracy=77.03% avg_sensitivity=85.88%, avg_specificity=74.21% avg_auc=88.38%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.243824 Test loss=0.470596 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.21362504363059998
[5/23] Train loss=0.22360177338123322
[10/23] Train loss=0.24427317082881927
[15/23] Train loss=0.21463754773139954
[20/23] Train loss=0.22202907502651215
Test set avg_accuracy=84.44% avg_sensitivity=53.64%, avg_specificity=94.25% avg_auc=88.71%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.237389 Test loss=0.379593 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.2202901691198349
[5/23] Train loss=0.22096505761146545
[10/23] Train loss=0.23864851891994476
[15/23] Train loss=0.21239301562309265
[20/23] Train loss=0.21850281953811646
Test set avg_accuracy=81.60% avg_sensitivity=75.63%, avg_specificity=83.50% avg_auc=88.34%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.231490 Test loss=0.402823 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.20364409685134888
[5/23] Train loss=0.20458464324474335
[10/23] Train loss=0.24713946878910065
[15/23] Train loss=0.20965468883514404
[20/23] Train loss=0.21696384251117706
Test set avg_accuracy=82.03% avg_sensitivity=68.25%, avg_specificity=86.42% avg_auc=86.52%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.229934 Test loss=0.394047 Current lr=[0.000299926900870094]

[0/23] Train loss=0.21435654163360596
[5/23] Train loss=0.21026551723480225
[10/23] Train loss=0.22733652591705322
[15/23] Train loss=0.1972801834344864
[20/23] Train loss=0.20661598443984985
Test set avg_accuracy=82.53% avg_sensitivity=45.77%, avg_specificity=94.23% avg_auc=84.12%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.226890 Test loss=0.420427 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.21612152457237244
[5/23] Train loss=0.19744020700454712
[10/23] Train loss=0.23818138241767883
[15/23] Train loss=0.2142421007156372
[20/23] Train loss=0.23588521778583527
Test set avg_accuracy=82.23% avg_sensitivity=33.69%, avg_specificity=97.68% avg_auc=84.49%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.231022 Test loss=0.459294 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.2033187747001648
[5/23] Train loss=0.20901530981063843
[10/23] Train loss=0.2508975565433502
[15/23] Train loss=0.2140820026397705
[20/23] Train loss=0.2120732069015503
Test set avg_accuracy=84.15% avg_sensitivity=61.99%, avg_specificity=91.21% avg_auc=89.28%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.229215 Test loss=0.344754 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.22013740241527557
[5/23] Train loss=0.20195059478282928
[10/23] Train loss=0.23518583178520203
[15/23] Train loss=0.20814572274684906
[20/23] Train loss=0.1913309395313263
Test set avg_accuracy=78.49% avg_sensitivity=11.81%, avg_specificity=99.73% avg_auc=80.01%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.223419 Test loss=0.604894 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.20198753476142883
[5/23] Train loss=0.19152696430683136
[10/23] Train loss=0.2331259548664093
[15/23] Train loss=0.20709097385406494
[20/23] Train loss=0.20902250707149506
Test set avg_accuracy=80.78% avg_sensitivity=28.95%, avg_specificity=97.29% avg_auc=74.59%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.220324 Test loss=0.540673 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.19086219370365143
[5/23] Train loss=0.1974734514951706
[10/23] Train loss=0.22995254397392273
[15/23] Train loss=0.18981361389160156
[20/23] Train loss=0.21519413590431213
Test set avg_accuracy=80.22% avg_sensitivity=23.34%, avg_specificity=98.33% avg_auc=81.39%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.216325 Test loss=0.543391 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.21502865850925446
[5/23] Train loss=0.20077836513519287
[10/23] Train loss=0.24592836201190948
[15/23] Train loss=0.20892173051834106
[20/23] Train loss=0.1992367058992386
Test set avg_accuracy=82.60% avg_sensitivity=38.01%, avg_specificity=96.81% avg_auc=83.52%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.221107 Test loss=0.469224 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.1978563815355301
[5/23] Train loss=0.20003341138362885
[10/23] Train loss=0.22233352065086365
[15/23] Train loss=0.1973603516817093
[20/23] Train loss=0.18650783598423004
Test set avg_accuracy=82.98% avg_sensitivity=42.05%, avg_specificity=96.02% avg_auc=85.93%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.217028 Test loss=0.415454 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.20480388402938843
[5/23] Train loss=0.20551520586013794
[10/23] Train loss=0.21810771524906158
[15/23] Train loss=0.20578722655773163
[20/23] Train loss=0.21180187165737152
Test set avg_accuracy=84.21% avg_sensitivity=49.00%, avg_specificity=95.42% avg_auc=86.52%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.216258 Test loss=0.404506 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.20060697197914124
[5/23] Train loss=0.19240203499794006
[10/23] Train loss=0.21721361577510834
[15/23] Train loss=0.19234488904476166
[20/23] Train loss=0.20691858232021332
Test set avg_accuracy=78.84% avg_sensitivity=74.18%, avg_specificity=80.33% avg_auc=85.72%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.212909 Test loss=0.434925 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.19918906688690186
[5/23] Train loss=0.1901443898677826
[10/23] Train loss=0.22968903183937073
[15/23] Train loss=0.19964034855365753
[20/23] Train loss=0.19919711351394653
Test set avg_accuracy=79.17% avg_sensitivity=18.06%, avg_specificity=98.63% avg_auc=73.34%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.215976 Test loss=0.589186 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.19602198898792267
[5/23] Train loss=0.19010086357593536
[10/23] Train loss=0.21062466502189636
[15/23] Train loss=0.19679664075374603
[20/23] Train loss=0.2032727301120758
Test set avg_accuracy=82.67% avg_sensitivity=33.80%, avg_specificity=98.23% avg_auc=81.74%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.209978 Test loss=0.501659 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.20405328273773193
[5/23] Train loss=0.18432891368865967
[10/23] Train loss=0.21440555155277252
[15/23] Train loss=0.20454604923725128
[20/23] Train loss=0.18641869723796844
Test set avg_accuracy=82.57% avg_sensitivity=37.14%, avg_specificity=97.03% avg_auc=81.84%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.211909 Test loss=0.471326 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.20424984395503998
[5/23] Train loss=0.18792735040187836
[10/23] Train loss=0.21039187908172607
[15/23] Train loss=0.19566653668880463
[20/23] Train loss=0.18918591737747192
Test set avg_accuracy=84.14% avg_sensitivity=51.32%, avg_specificity=94.59% avg_auc=85.43%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.209028 Test loss=0.419534 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.20164433121681213
[5/23] Train loss=0.19268719851970673
[10/23] Train loss=0.20855122804641724
[15/23] Train loss=0.18467684090137482
[20/23] Train loss=0.1783715933561325
Test set avg_accuracy=83.01% avg_sensitivity=43.23%, avg_specificity=95.67% avg_auc=85.11%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.204154 Test loss=0.440917 Current lr=[0.000283047938381597]

[0/23] Train loss=0.19310227036476135
[5/23] Train loss=0.18166013062000275
[10/23] Train loss=0.199445441365242
[15/23] Train loss=0.18847189843654633
[20/23] Train loss=0.1802644431591034
Test set avg_accuracy=82.57% avg_sensitivity=45.34%, avg_specificity=94.42% avg_auc=84.09%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.203465 Test loss=0.426663 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.18440277874469757
[5/23] Train loss=0.18233329057693481
[10/23] Train loss=0.2030438482761383
[15/23] Train loss=0.17142058908939362
[20/23] Train loss=0.17826059460639954
Test set avg_accuracy=83.46% avg_sensitivity=56.28%, avg_specificity=92.12% avg_auc=85.31%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.199506 Test loss=0.429720 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.18891984224319458
[5/23] Train loss=0.19137266278266907
[10/23] Train loss=0.19798976182937622
[15/23] Train loss=0.18486452102661133
[20/23] Train loss=0.19124168157577515
Test set avg_accuracy=81.91% avg_sensitivity=38.49%, avg_specificity=95.74% avg_auc=81.01%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.201895 Test loss=0.485734 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.1844342052936554
[5/23] Train loss=0.19533784687519073
[10/23] Train loss=0.20016604661941528
[15/23] Train loss=0.1796092391014099
[20/23] Train loss=0.18695366382598877
Test set avg_accuracy=84.86% avg_sensitivity=58.27%, avg_specificity=93.32% avg_auc=87.17%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.198990 Test loss=0.364133 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.18324264883995056
[5/23] Train loss=0.1755203902721405
[10/23] Train loss=0.20632077753543854
[15/23] Train loss=0.18026584386825562
[20/23] Train loss=0.1800597459077835
Test set avg_accuracy=82.28% avg_sensitivity=37.04%, avg_specificity=96.69% avg_auc=83.97%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.200956 Test loss=0.430443 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.17692351341247559
[5/23] Train loss=0.1895815134048462
[10/23] Train loss=0.20370686054229736
[15/23] Train loss=0.1852627843618393
[20/23] Train loss=0.18778663873672485
Test set avg_accuracy=83.39% avg_sensitivity=44.58%, avg_specificity=95.74% avg_auc=85.86%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.200060 Test loss=0.417763 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.18279877305030823
[5/23] Train loss=0.1796322762966156
[10/23] Train loss=0.2143334150314331
[15/23] Train loss=0.18335215747356415
[20/23] Train loss=0.16994595527648926
Test set avg_accuracy=84.27% avg_sensitivity=51.75%, avg_specificity=94.63% avg_auc=83.58%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.197489 Test loss=0.421993 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.18919312953948975
[5/23] Train loss=0.17925170063972473
[10/23] Train loss=0.19277718663215637
[15/23] Train loss=0.18290092051029205
[20/23] Train loss=0.1720675528049469
Test set avg_accuracy=83.93% avg_sensitivity=66.36%, avg_specificity=89.53% avg_auc=87.77%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.195554 Test loss=0.374313 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.1765032857656479
[5/23] Train loss=0.1812097132205963
[10/23] Train loss=0.19842278957366943
[15/23] Train loss=0.17579524219036102
[20/23] Train loss=0.16709716618061066
Test set avg_accuracy=82.07% avg_sensitivity=35.15%, avg_specificity=97.01% avg_auc=81.92%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.193945 Test loss=0.495237 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.18112027645111084
[5/23] Train loss=0.17025624215602875
[10/23] Train loss=0.19630607962608337
[15/23] Train loss=0.1835060864686966
[20/23] Train loss=0.1809161901473999
Test set avg_accuracy=81.29% avg_sensitivity=26.52%, avg_specificity=98.73% avg_auc=76.74%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.194824 Test loss=0.572698 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.17781436443328857
[5/23] Train loss=0.1829749345779419
[10/23] Train loss=0.1917971521615982
[15/23] Train loss=0.17367056012153625
[20/23] Train loss=0.16577164828777313
Test set avg_accuracy=84.23% avg_sensitivity=65.98%, avg_specificity=90.04% avg_auc=87.71%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.189912 Test loss=0.384900 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.17879453301429749
[5/23] Train loss=0.18320943415164948
[10/23] Train loss=0.1925627738237381
[15/23] Train loss=0.1764518916606903
[20/23] Train loss=0.18114332854747772
Test set avg_accuracy=82.42% avg_sensitivity=40.54%, avg_specificity=95.76% avg_auc=81.19%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.190750 Test loss=0.467922 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.16493594646453857
[5/23] Train loss=0.1779772788286209
[10/23] Train loss=0.1916603446006775
[15/23] Train loss=0.16959598660469055
[20/23] Train loss=0.1765301376581192
Test set avg_accuracy=73.97% avg_sensitivity=51.64%, avg_specificity=81.08% avg_auc=78.26%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.189279 Test loss=0.531621 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.16654756665229797
[5/23] Train loss=0.17280761897563934
[10/23] Train loss=0.1992076337337494
[15/23] Train loss=0.16869020462036133
[20/23] Train loss=0.17941366136074066
Test set avg_accuracy=83.37% avg_sensitivity=50.78%, avg_specificity=93.75% avg_auc=84.22%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.190014 Test loss=0.424200 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.16815325617790222
[5/23] Train loss=0.1702854335308075
[10/23] Train loss=0.19067105650901794
[15/23] Train loss=0.16107235848903656
[20/23] Train loss=0.1699824035167694
Test set avg_accuracy=84.61% avg_sensitivity=56.66%, avg_specificity=93.51% avg_auc=86.41%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.185824 Test loss=0.414762 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.16763728857040405
[5/23] Train loss=0.16751599311828613
[10/23] Train loss=0.18798322975635529
[15/23] Train loss=0.17039722204208374
[20/23] Train loss=0.1597006767988205
Test set avg_accuracy=82.33% avg_sensitivity=57.68%, avg_specificity=90.18% avg_auc=84.60%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.186145 Test loss=0.410701 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.17061540484428406
[5/23] Train loss=0.16621895134449005
[10/23] Train loss=0.1889716535806656
[15/23] Train loss=0.16711847484111786
[20/23] Train loss=0.1682867705821991
Test set avg_accuracy=82.17% avg_sensitivity=34.02%, avg_specificity=97.51% avg_auc=79.08%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.182384 Test loss=0.529313 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.17587605118751526
[5/23] Train loss=0.17245948314666748
[10/23] Train loss=0.17847780883312225
[15/23] Train loss=0.16427470743656158
[20/23] Train loss=0.17515546083450317
Test set avg_accuracy=80.31% avg_sensitivity=36.82%, avg_specificity=94.16% avg_auc=81.00%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.184297 Test loss=0.507220 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.17891409993171692
[5/23] Train loss=0.16865034401416779
[10/23] Train loss=0.17677345871925354
[15/23] Train loss=0.15896956622600555
[20/23] Train loss=0.1668112576007843
Test set avg_accuracy=83.91% avg_sensitivity=53.53%, avg_specificity=93.58% avg_auc=83.48%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.184343 Test loss=0.429503 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.17318817973136902
[5/23] Train loss=0.16337572038173676
[10/23] Train loss=0.1869305670261383
[15/23] Train loss=0.16445502638816833
[20/23] Train loss=0.1560049206018448
Test set avg_accuracy=82.94% avg_sensitivity=54.88%, avg_specificity=91.88% avg_auc=83.66%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.182025 Test loss=0.430647 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.16159957647323608
[5/23] Train loss=0.16608287394046783
[10/23] Train loss=0.18510980904102325
[15/23] Train loss=0.1692814975976944
[20/23] Train loss=0.16454418003559113
Test set avg_accuracy=79.84% avg_sensitivity=21.67%, avg_specificity=98.37% avg_auc=78.03%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.181154 Test loss=0.576234 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.1749955415725708
[5/23] Train loss=0.16010938584804535
[10/23] Train loss=0.17839019000530243
[15/23] Train loss=0.164832204580307
[20/23] Train loss=0.16470277309417725
Test set avg_accuracy=83.05% avg_sensitivity=73.21%, avg_specificity=86.18% avg_auc=87.71%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.180959 Test loss=0.395472 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.1674545407295227
[5/23] Train loss=0.15828867256641388
[10/23] Train loss=0.18528230488300323
[15/23] Train loss=0.1743754744529724
[20/23] Train loss=0.16560494899749756
Test set avg_accuracy=80.99% avg_sensitivity=36.55%, avg_specificity=95.14% avg_auc=81.07%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.180351 Test loss=0.520229 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.1657678782939911
[5/23] Train loss=0.15649768710136414
[10/23] Train loss=0.1920316219329834
[15/23] Train loss=0.16963912546634674
[20/23] Train loss=0.16120867431163788
Test set avg_accuracy=84.02% avg_sensitivity=61.67%, avg_specificity=91.14% avg_auc=87.50%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.179240 Test loss=0.380901 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.18025575578212738
[5/23] Train loss=0.16551616787910461
[10/23] Train loss=0.17703773081302643
[15/23] Train loss=0.17166316509246826
[20/23] Train loss=0.1635560393333435
Test set avg_accuracy=85.01% avg_sensitivity=66.09%, avg_specificity=91.04% avg_auc=86.90%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.180410 Test loss=0.407052 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.16773085296154022
[5/23] Train loss=0.16752436757087708
[10/23] Train loss=0.1794215589761734
[15/23] Train loss=0.16438281536102295
[20/23] Train loss=0.16326358914375305
Test set avg_accuracy=83.27% avg_sensitivity=41.78%, avg_specificity=96.48% avg_auc=83.89%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.184007 Test loss=0.445974 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.17217318713665009
[5/23] Train loss=0.1616588681936264
[10/23] Train loss=0.1796501874923706
[15/23] Train loss=0.1732722371816635
[20/23] Train loss=0.170565664768219
Test set avg_accuracy=81.08% avg_sensitivity=27.39%, avg_specificity=98.18% avg_auc=79.64%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.182818 Test loss=0.534431 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.17559140920639038
[5/23] Train loss=0.16604386270046234
[10/23] Train loss=0.17730964720249176
[15/23] Train loss=0.16764792799949646
[20/23] Train loss=0.17059282958507538
Test set avg_accuracy=79.99% avg_sensitivity=36.12%, avg_specificity=93.96% avg_auc=78.00%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.182789 Test loss=0.540780 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.1670423001050949
[5/23] Train loss=0.16497235000133514
[10/23] Train loss=0.18026848137378693
[15/23] Train loss=0.16256488859653473
[20/23] Train loss=0.16305693984031677
Test set avg_accuracy=82.15% avg_sensitivity=44.58%, avg_specificity=94.11% avg_auc=84.12%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.176988 Test loss=0.447211 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.16632837057113647
[5/23] Train loss=0.18045584857463837
[10/23] Train loss=0.18709905445575714
[15/23] Train loss=0.18184177577495575
[20/23] Train loss=0.16067549586296082
Test set avg_accuracy=83.84% avg_sensitivity=66.15%, avg_specificity=89.48% avg_auc=87.28%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.180321 Test loss=0.404689 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.17397403717041016
[5/23] Train loss=0.15292254090309143
[10/23] Train loss=0.19938038289546967
[15/23] Train loss=0.16581545770168304
[20/23] Train loss=0.16683311760425568
Test set avg_accuracy=82.71% avg_sensitivity=37.95%, avg_specificity=96.96% avg_auc=83.73%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.178752 Test loss=0.442096 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.16882193088531494
[5/23] Train loss=0.16597169637680054
[10/23] Train loss=0.1868341863155365
[15/23] Train loss=0.15899039804935455
[20/23] Train loss=0.16293275356292725
Test set avg_accuracy=81.39% avg_sensitivity=53.53%, avg_specificity=90.27% avg_auc=84.61%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.176921 Test loss=0.461352 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.15832644701004028
[5/23] Train loss=0.1563899964094162
[10/23] Train loss=0.18012139201164246
[15/23] Train loss=0.16119322180747986
[20/23] Train loss=0.15769575536251068
Test set avg_accuracy=84.71% avg_sensitivity=62.16%, avg_specificity=91.90% avg_auc=86.12%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.172808 Test loss=0.400839 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.15388892590999603
[5/23] Train loss=0.15749630331993103
[10/23] Train loss=0.1711045205593109
[15/23] Train loss=0.15753969550132751
[20/23] Train loss=0.1544891744852066
Test set avg_accuracy=82.67% avg_sensitivity=39.19%, avg_specificity=96.52% avg_auc=82.15%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.168645 Test loss=0.473708 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.15998056530952454
[5/23] Train loss=0.15394368767738342
[10/23] Train loss=0.17843417823314667
[15/23] Train loss=0.1585792601108551
[20/23] Train loss=0.1624368131160736
Test set avg_accuracy=81.28% avg_sensitivity=59.95%, avg_specificity=88.07% avg_auc=81.71%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.167797 Test loss=0.458939 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.15136779844760895
[5/23] Train loss=0.15394358336925507
[10/23] Train loss=0.15798312425613403
[15/23] Train loss=0.15276676416397095
[20/23] Train loss=0.1592998206615448
Test set avg_accuracy=83.80% avg_sensitivity=53.96%, avg_specificity=93.30% avg_auc=84.89%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.166025 Test loss=0.421229 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.1527460217475891
[5/23] Train loss=0.14951317012310028
[10/23] Train loss=0.16001886129379272
[15/23] Train loss=0.1480342000722885
[20/23] Train loss=0.15192337334156036
Test set avg_accuracy=80.48% avg_sensitivity=62.75%, avg_specificity=86.13% avg_auc=83.73%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.164906 Test loss=0.470692 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.15258553624153137
[5/23] Train loss=0.1560686081647873
[10/23] Train loss=0.15306133031845093
[15/23] Train loss=0.1504555195569992
[20/23] Train loss=0.1523953080177307
Test set avg_accuracy=83.96% avg_sensitivity=59.95%, avg_specificity=91.61% avg_auc=85.35%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.163884 Test loss=0.426133 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.15273228287696838
[5/23] Train loss=0.14945225417613983
[10/23] Train loss=0.16088588535785675
[15/23] Train loss=0.15443943440914154
[20/23] Train loss=0.14527490735054016
Test set avg_accuracy=83.03% avg_sensitivity=65.88%, avg_specificity=88.50% avg_auc=87.55%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.162892 Test loss=0.406212 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.1493394523859024
[5/23] Train loss=0.14501948654651642
[10/23] Train loss=0.1545591950416565
[15/23] Train loss=0.15694771707057953
[20/23] Train loss=0.15458247065544128
Test set avg_accuracy=85.16% avg_sensitivity=56.71%, avg_specificity=94.21% avg_auc=86.58%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.162114 Test loss=0.396874 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.15137721598148346
[5/23] Train loss=0.1498294174671173
[10/23] Train loss=0.15042133629322052
[15/23] Train loss=0.15306906402111053
[20/23] Train loss=0.14329980313777924
Test set avg_accuracy=84.86% avg_sensitivity=53.69%, avg_specificity=94.78% avg_auc=85.37%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.159338 Test loss=0.415490 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.14700940251350403
[5/23] Train loss=0.14728868007659912
[10/23] Train loss=0.16055335104465485
[15/23] Train loss=0.15142971277236938
[20/23] Train loss=0.15857070684432983
Test set avg_accuracy=82.97% avg_sensitivity=66.20%, avg_specificity=88.31% avg_auc=86.40%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.160230 Test loss=0.403007 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.15041978657245636
[5/23] Train loss=0.14099770784378052
[10/23] Train loss=0.15895523130893707
[15/23] Train loss=0.14493678510189056
[20/23] Train loss=0.15655702352523804
Test set avg_accuracy=83.02% avg_sensitivity=52.99%, avg_specificity=92.58% avg_auc=84.63%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.158487 Test loss=0.434016 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.1545248180627823
[5/23] Train loss=0.14617764949798584
[10/23] Train loss=0.16095159947872162
[15/23] Train loss=0.14914315938949585
[20/23] Train loss=0.143490731716156
Test set avg_accuracy=84.18% avg_sensitivity=64.42%, avg_specificity=90.47% avg_auc=88.29%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.158437 Test loss=0.389596 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.15115725994110107
[5/23] Train loss=0.14936892688274384
[10/23] Train loss=0.14903847873210907
[15/23] Train loss=0.1547747701406479
[20/23] Train loss=0.1478813886642456
Test set avg_accuracy=84.73% avg_sensitivity=56.01%, avg_specificity=93.87% avg_auc=85.45%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.158980 Test loss=0.413250 Current lr=[0.000112073915556435]

[0/23] Train loss=0.14897817373275757
[5/23] Train loss=0.14076021313667297
[10/23] Train loss=0.16002123057842255
[15/23] Train loss=0.14880838990211487
[20/23] Train loss=0.14136439561843872
Test set avg_accuracy=84.83% avg_sensitivity=61.29%, avg_specificity=92.33% avg_auc=87.06%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.156711 Test loss=0.398381 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.1448480486869812
[5/23] Train loss=0.1489737331867218
[10/23] Train loss=0.15579940378665924
[15/23] Train loss=0.14058078825473785
[20/23] Train loss=0.14224863052368164
Test set avg_accuracy=84.01% avg_sensitivity=47.06%, avg_specificity=95.78% avg_auc=83.21%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.154483 Test loss=0.444614 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.14987894892692566
[5/23] Train loss=0.14008088409900665
[10/23] Train loss=0.15093931555747986
[15/23] Train loss=0.14746467769145966
[20/23] Train loss=0.14050062000751495
Test set avg_accuracy=83.01% avg_sensitivity=69.54%, avg_specificity=87.30% avg_auc=87.95%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.153980 Test loss=0.402993 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.14067697525024414
[5/23] Train loss=0.140104278922081
[10/23] Train loss=0.15424419939517975
[15/23] Train loss=0.1556604504585266
[20/23] Train loss=0.1490788608789444
Test set avg_accuracy=84.88% avg_sensitivity=60.49%, avg_specificity=92.65% avg_auc=88.14%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.154085 Test loss=0.384054 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.14780829846858978
[5/23] Train loss=0.14602868258953094
[10/23] Train loss=0.15443360805511475
[15/23] Train loss=0.14088469743728638
[20/23] Train loss=0.1301681101322174
Test set avg_accuracy=83.68% avg_sensitivity=67.49%, avg_specificity=88.84% avg_auc=87.31%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.151669 Test loss=0.407408 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.14747513830661774
[5/23] Train loss=0.1387403905391693
[10/23] Train loss=0.14123868942260742
[15/23] Train loss=0.14725656807422638
[20/23] Train loss=0.1355089247226715
Test set avg_accuracy=84.19% avg_sensitivity=68.57%, avg_specificity=89.17% avg_auc=88.86%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.149055 Test loss=0.386837 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.13711249828338623
[5/23] Train loss=0.13438428938388824
[10/23] Train loss=0.14196661114692688
[15/23] Train loss=0.13759584724903107
[20/23] Train loss=0.13381797075271606
Test set avg_accuracy=84.80% avg_sensitivity=65.23%, avg_specificity=91.04% avg_auc=88.01%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.146106 Test loss=0.384944 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.14040271937847137
[5/23] Train loss=0.13013991713523865
[10/23] Train loss=0.14818090200424194
[15/23] Train loss=0.1369534581899643
[20/23] Train loss=0.1334330141544342
Test set avg_accuracy=83.05% avg_sensitivity=74.12%, avg_specificity=85.89% avg_auc=88.30%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.145729 Test loss=0.418699 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.1425480842590332
[5/23] Train loss=0.13285957276821136
[10/23] Train loss=0.144737109541893
[15/23] Train loss=0.134882390499115
[20/23] Train loss=0.12654843926429749
Test set avg_accuracy=84.14% avg_sensitivity=67.65%, avg_specificity=89.39% avg_auc=87.65%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.144047 Test loss=0.400354 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.14031095802783966
[5/23] Train loss=0.13253267109394073
[10/23] Train loss=0.13696333765983582
[15/23] Train loss=0.13437703251838684
[20/23] Train loss=0.13422007858753204
Test set avg_accuracy=84.82% avg_sensitivity=65.23%, avg_specificity=91.06% avg_auc=87.67%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.143389 Test loss=0.389659 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.13367897272109985
[5/23] Train loss=0.1315607875585556
[10/23] Train loss=0.13979247212409973
[15/23] Train loss=0.13744209706783295
[20/23] Train loss=0.13178811967372894
Test set avg_accuracy=83.39% avg_sensitivity=70.84%, avg_specificity=87.38% avg_auc=87.54%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.142543 Test loss=0.416900 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.13988152146339417
[5/23] Train loss=0.12900669872760773
[10/23] Train loss=0.14187966287136078
[15/23] Train loss=0.13525819778442383
[20/23] Train loss=0.13091808557510376
Test set avg_accuracy=82.72% avg_sensitivity=62.53%, avg_specificity=89.15% avg_auc=86.08%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.143018 Test loss=0.413400 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.13504716753959656
[5/23] Train loss=0.13040059804916382
[10/23] Train loss=0.1426163613796234
[15/23] Train loss=0.13436508178710938
[20/23] Train loss=0.1248093694448471
Test set avg_accuracy=82.73% avg_sensitivity=68.46%, avg_specificity=87.28% avg_auc=86.74%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.141281 Test loss=0.415843 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.13579750061035156
[5/23] Train loss=0.12464925646781921
[10/23] Train loss=0.13629870116710663
[15/23] Train loss=0.13511908054351807
[20/23] Train loss=0.12560801208019257
Test set avg_accuracy=82.88% avg_sensitivity=63.13%, avg_specificity=89.17% avg_auc=85.69%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.139494 Test loss=0.432142 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.1318562626838684
[5/23] Train loss=0.13020281493663788
[10/23] Train loss=0.13496704399585724
[15/23] Train loss=0.1319652646780014
[20/23] Train loss=0.12329497933387756
Test set avg_accuracy=84.22% avg_sensitivity=70.40%, avg_specificity=88.62% avg_auc=88.39%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.138722 Test loss=0.390732 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.13147041201591492
[5/23] Train loss=0.1254919320344925
[10/23] Train loss=0.13388162851333618
[15/23] Train loss=0.12904059886932373
[20/23] Train loss=0.12153523415327072
Test set avg_accuracy=83.05% avg_sensitivity=75.31%, avg_specificity=85.51% avg_auc=87.77%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.137361 Test loss=0.420230 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.1327972412109375
[5/23] Train loss=0.1290547251701355
[10/23] Train loss=0.13135480880737305
[15/23] Train loss=0.12564067542552948
[20/23] Train loss=0.12580722570419312
Test set avg_accuracy=84.18% avg_sensitivity=68.25%, avg_specificity=89.25% avg_auc=87.61%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.136603 Test loss=0.396901 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.1262587606906891
[5/23] Train loss=0.12629421055316925
[10/23] Train loss=0.13226255774497986
[15/23] Train loss=0.1298997849225998
[20/23] Train loss=0.12283463776111603
Test set avg_accuracy=83.48% avg_sensitivity=62.91%, avg_specificity=90.03% avg_auc=86.53%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.135124 Test loss=0.417626 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.12782081961631775
[5/23] Train loss=0.12549813091754913
[10/23] Train loss=0.12903104722499847
[15/23] Train loss=0.1264372318983078
[20/23] Train loss=0.12457112222909927
Test set avg_accuracy=83.39% avg_sensitivity=67.65%, avg_specificity=88.39% avg_auc=87.91%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.134204 Test loss=0.401734 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.12922005355358124
[5/23] Train loss=0.12121985107660294
[10/23] Train loss=0.12906132638454437
[15/23] Train loss=0.12544216215610504
[20/23] Train loss=0.12010671943426132
Test set avg_accuracy=83.40% avg_sensitivity=66.36%, avg_specificity=88.82% avg_auc=87.45%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.134735 Test loss=0.413946 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.12778565287590027
[5/23] Train loss=0.1250072866678238
[10/23] Train loss=0.1293458342552185
[15/23] Train loss=0.12877734005451202
[20/23] Train loss=0.12029682844877243
Test set avg_accuracy=83.61% avg_sensitivity=72.29%, avg_specificity=87.21% avg_auc=87.94%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.133949 Test loss=0.404469 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.1316649466753006
[5/23] Train loss=0.1256455034017563
[10/23] Train loss=0.1309937685728073
[15/23] Train loss=0.12796230614185333
[20/23] Train loss=0.12339765578508377
Test set avg_accuracy=83.80% avg_sensitivity=68.14%, avg_specificity=88.79% avg_auc=87.52%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.134164 Test loss=0.405897 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.1275055706501007
[5/23] Train loss=0.12084745615720749
[10/23] Train loss=0.13052712380886078
[15/23] Train loss=0.13038109242916107
[20/23] Train loss=0.12089286744594574
Test set avg_accuracy=83.85% avg_sensitivity=64.53%, avg_specificity=90.01% avg_auc=86.97%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.132936 Test loss=0.409774 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.12748032808303833
[5/23] Train loss=0.12293817102909088
[10/23] Train loss=0.12732945382595062
[15/23] Train loss=0.1315011978149414
[20/23] Train loss=0.11767621338367462
Test set avg_accuracy=83.95% avg_sensitivity=59.46%, avg_specificity=91.74% avg_auc=85.84%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.132915 Test loss=0.419752 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.12571772933006287
[5/23] Train loss=0.12498874962329865
[10/23] Train loss=0.12598392367362976
[15/23] Train loss=0.1277652084827423
[20/23] Train loss=0.11949309706687927
Test set avg_accuracy=83.80% avg_sensitivity=64.80%, avg_specificity=89.85% avg_auc=87.16%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.132974 Test loss=0.406148 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.12317122519016266
[5/23] Train loss=0.12397326529026031
[10/23] Train loss=0.12442490458488464
[15/23] Train loss=0.1245746985077858
[20/23] Train loss=0.11868511885404587
Test set avg_accuracy=84.43% avg_sensitivity=65.77%, avg_specificity=90.37% avg_auc=87.68%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.131160 Test loss=0.392779 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.1301247626543045
[5/23] Train loss=0.12089768052101135
[10/23] Train loss=0.12703435122966766
[15/23] Train loss=0.12302257865667343
[20/23] Train loss=0.1144414097070694
Test set avg_accuracy=83.98% avg_sensitivity=61.67%, avg_specificity=91.09% avg_auc=86.60%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.129992 Test loss=0.408237 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.12148623168468475
[5/23] Train loss=0.12021887302398682
[10/23] Train loss=0.12413377314805984
[15/23] Train loss=0.12213591486215591
[20/23] Train loss=0.11830873787403107
Test set avg_accuracy=84.04% avg_sensitivity=69.11%, avg_specificity=88.79% avg_auc=87.60%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.129491 Test loss=0.401698 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.12123003602027893
[5/23] Train loss=0.12084882706403732
[10/23] Train loss=0.12246062606573105
[15/23] Train loss=0.12478554248809814
[20/23] Train loss=0.11843305081129074
Test set avg_accuracy=84.32% avg_sensitivity=64.47%, avg_specificity=90.64% avg_auc=87.27%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.128670 Test loss=0.397446 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.1214512288570404
[5/23] Train loss=0.1187528669834137
[10/23] Train loss=0.12361083179712296
[15/23] Train loss=0.12164811044931412
[20/23] Train loss=0.11465605348348618
Test set avg_accuracy=84.48% avg_sensitivity=64.64%, avg_specificity=90.80% avg_auc=86.71%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.128516 Test loss=0.399476 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.12401837855577469
[5/23] Train loss=0.11694909632205963
[10/23] Train loss=0.12237297743558884
[15/23] Train loss=0.12088638544082642
[20/23] Train loss=0.11432722955942154
Test set avg_accuracy=84.23% avg_sensitivity=64.42%, avg_specificity=90.54% avg_auc=87.12%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.127733 Test loss=0.401894 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.11975359171628952
[5/23] Train loss=0.11843212693929672
[10/23] Train loss=0.12114860862493515
[15/23] Train loss=0.12132082879543304
[20/23] Train loss=0.11557620763778687
Test set avg_accuracy=84.23% avg_sensitivity=64.58%, avg_specificity=90.49% avg_auc=87.25%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.127288 Test loss=0.402014 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.12267082929611206
[5/23] Train loss=0.1210300400853157
[10/23] Train loss=0.12138521671295166
[15/23] Train loss=0.1221671998500824
[20/23] Train loss=0.11543843895196915
Test set avg_accuracy=84.15% avg_sensitivity=64.04%, avg_specificity=90.56% avg_auc=87.01%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.127397 Test loss=0.404391 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.12469397485256195
[5/23] Train loss=0.11667824536561966
[10/23] Train loss=0.12243460863828659
[15/23] Train loss=0.12348213791847229
[20/23] Train loss=0.11520133912563324
Test set avg_accuracy=84.35% avg_sensitivity=65.61%, avg_specificity=90.32% avg_auc=87.69%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.127700 Test loss=0.396426 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.12189638614654541
[5/23] Train loss=0.11887843906879425
[10/23] Train loss=0.12164777517318726
[15/23] Train loss=0.11895257979631424
[20/23] Train loss=0.11469566076993942
Test set avg_accuracy=84.22% avg_sensitivity=64.69%, avg_specificity=90.44% avg_auc=87.04%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.126855 Test loss=0.404861 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.11923026293516159
[5/23] Train loss=0.11727484315633774
[10/23] Train loss=0.11982225626707077
[15/23] Train loss=0.12271691113710403
[20/23] Train loss=0.11285419762134552
Test set avg_accuracy=84.15% avg_sensitivity=65.18%, avg_specificity=90.20% avg_auc=87.37%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.126663 Test loss=0.400599 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.1233539804816246
[5/23] Train loss=0.11735180765390396
[10/23] Train loss=0.1217515617609024
[15/23] Train loss=0.11936114728450775
[20/23] Train loss=0.11394790560007095
Test set avg_accuracy=84.32% avg_sensitivity=64.26%, avg_specificity=90.71% avg_auc=87.05%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.125854 Test loss=0.403607 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.11988693475723267
[5/23] Train loss=0.11628863960504532
[10/23] Train loss=0.12301332503557205
[15/23] Train loss=0.12220118194818497
[20/23] Train loss=0.11389833688735962
Test set avg_accuracy=84.34% avg_sensitivity=64.42%, avg_specificity=90.68% avg_auc=87.06%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.126091 Test loss=0.403792 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.12322182953357697
[5/23] Train loss=0.11736626923084259
[10/23] Train loss=0.12097232788801193
[15/23] Train loss=0.1204623132944107
[20/23] Train loss=0.11219141632318497
Test set avg_accuracy=84.26% avg_sensitivity=64.37%, avg_specificity=90.59% avg_auc=86.93%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.125937 Test loss=0.404383 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.11898259073495865
[5/23] Train loss=0.1152314618229866
[10/23] Train loss=0.1210813894867897
[15/23] Train loss=0.11928568035364151
[20/23] Train loss=0.11486484110355377
Test set avg_accuracy=84.18% avg_sensitivity=64.64%, avg_specificity=90.40% avg_auc=86.98%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.125422 Test loss=0.404862 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.12099913507699966
[5/23] Train loss=0.11489574611186981
[10/23] Train loss=0.12092408537864685
[15/23] Train loss=0.1256464272737503
[20/23] Train loss=0.11397440731525421
Test set avg_accuracy=84.17% avg_sensitivity=64.42%, avg_specificity=90.45% avg_auc=87.03%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.126592 Test loss=0.404032 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.12503871321678162
[5/23] Train loss=0.11863637715578079
[10/23] Train loss=0.12094871699810028
[15/23] Train loss=0.12350687384605408
[20/23] Train loss=0.11263382434844971
Test set avg_accuracy=84.26% avg_sensitivity=64.91%, avg_specificity=90.42% avg_auc=87.08%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.126212 Test loss=0.403728 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.121162548661232
[5/23] Train loss=0.11996474117040634
[10/23] Train loss=0.12064781785011292
[15/23] Train loss=0.11812962591648102
[20/23] Train loss=0.11332307010889053
Test set avg_accuracy=84.23% avg_sensitivity=64.53%, avg_specificity=90.51% avg_auc=87.01%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.125821 Test loss=0.404228 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.12001599371433258
[5/23] Train loss=0.11745857447385788
[10/23] Train loss=0.1220039427280426
[15/23] Train loss=0.12122312933206558
[20/23] Train loss=0.11265735328197479
Test set avg_accuracy=84.27% avg_sensitivity=64.85%, avg_specificity=90.45% avg_auc=87.04%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.126202 Test loss=0.403988 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=85.31% sen=73.48%, spe=89.08%, auc=91.04%!
Fold[9] Avg_overlap=0.59%(±0.28119203643977125)
[0/24] Train loss=0.7289767265319824
[5/24] Train loss=0.7178813219070435
[10/24] Train loss=0.7131942510604858
[15/24] Train loss=0.6996849179267883
[20/24] Train loss=0.6910185813903809
Test set avg_accuracy=61.26% avg_sensitivity=46.47%, avg_specificity=65.55% avg_auc=59.00%
Best model saved!! Metric=-93.71446530897593!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.708132 Test loss=0.652597 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6886864304542542
[5/24] Train loss=0.6798755526542664
[10/24] Train loss=0.6787799596786499
[15/24] Train loss=0.6687785983085632
[20/24] Train loss=0.6562009453773499
Test set avg_accuracy=70.70% avg_sensitivity=54.29%, avg_specificity=75.46% avg_auc=72.21%
Best model saved!! Metric=-53.336387858527964!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.674826 Test loss=0.579582 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6597388386726379
[5/24] Train loss=0.6505305171012878
[10/24] Train loss=0.6517608165740967
[15/24] Train loss=0.6475992798805237
[20/24] Train loss=0.6357977986335754
Test set avg_accuracy=73.19% avg_sensitivity=63.44%, avg_specificity=76.02% avg_auc=76.39%
Best model saved!! Metric=-36.96147450659934!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.649971 Test loss=0.552138 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6251813769340515
[5/24] Train loss=0.6220548152923584
[10/24] Train loss=0.6256921291351318
[15/24] Train loss=0.6207506656646729
[20/24] Train loss=0.6087945103645325
Test set avg_accuracy=74.11% avg_sensitivity=68.89%, avg_specificity=75.63% avg_auc=79.02%
Best model saved!! Metric=-28.348156692457266!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.623387 Test loss=0.526093 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.596927285194397
[5/24] Train loss=0.5979894399642944
[10/24] Train loss=0.6063273549079895
[15/24] Train loss=0.5958302021026611
[20/24] Train loss=0.5837011933326721
Test set avg_accuracy=75.86% avg_sensitivity=70.63%, avg_specificity=77.38% avg_auc=81.20%
Best model saved!! Metric=-20.941835205239002!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.599924 Test loss=0.500424 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5748000144958496
[5/24] Train loss=0.5756101012229919
[10/24] Train loss=0.5797649621963501
[15/24] Train loss=0.5675808787345886
[20/24] Train loss=0.5636506080627441
Test set avg_accuracy=77.45% avg_sensitivity=71.44%, avg_specificity=79.19% avg_auc=83.01%
Best model saved!! Metric=-14.917095549431167!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.577047 Test loss=0.477929 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5503620505332947
[5/24] Train loss=0.559079647064209
[10/24] Train loss=0.569390058517456
[15/24] Train loss=0.5400074124336243
[20/24] Train loss=0.5398958325386047
Test set avg_accuracy=79.41% avg_sensitivity=70.28%, avg_specificity=82.06% avg_auc=84.23%
Best model saved!! Metric=-10.01935383092021!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.553910 Test loss=0.452779 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5297409296035767
[5/24] Train loss=0.5369847416877747
[10/24] Train loss=0.5346816182136536
[15/24] Train loss=0.5165356397628784
[20/24] Train loss=0.507511556148529
Test set avg_accuracy=82.19% avg_sensitivity=67.15%, avg_specificity=86.55% avg_auc=85.21%
Best model saved!! Metric=-4.907201128894329!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.529095 Test loss=0.427664 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.4956652522087097
[5/24] Train loss=0.49894851446151733
[10/24] Train loss=0.5039801001548767
[15/24] Train loss=0.4923997223377228
[20/24] Train loss=0.483553409576416
Test set avg_accuracy=83.52% avg_sensitivity=67.27%, avg_specificity=88.23% avg_auc=86.07%
Best model saved!! Metric=-0.9211309555666389!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.502941 Test loss=0.411192 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.47847869992256165
[5/24] Train loss=0.4843139946460724
[10/24] Train loss=0.48779532313346863
[15/24] Train loss=0.46277374029159546
[20/24] Train loss=0.4527207911014557
Test set avg_accuracy=84.22% avg_sensitivity=66.16%, avg_specificity=89.45% avg_auc=86.63%
Best model saved!! Metric=0.4644325231370061!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.480648 Test loss=0.396325 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4546060264110565
[5/24] Train loss=0.4522865414619446
[10/24] Train loss=0.45557838678359985
[15/24] Train loss=0.4434090554714203
[20/24] Train loss=0.43450185656547546
Test set avg_accuracy=85.08% avg_sensitivity=63.96%, avg_specificity=91.20% avg_auc=86.99%
Best model saved!! Metric=1.2316418621852279!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.458513 Test loss=0.379502 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4344305396080017
[5/24] Train loss=0.43627631664276123
[10/24] Train loss=0.4398016631603241
[15/24] Train loss=0.4172271192073822
[20/24] Train loss=0.4094558358192444
Test set avg_accuracy=85.60% avg_sensitivity=59.33%, avg_specificity=93.21% avg_auc=87.07%
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.438095 Test loss=0.365388 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4195666015148163
[5/24] Train loss=0.40947800874710083
[10/24] Train loss=0.41986140608787537
[15/24] Train loss=0.398236483335495
[20/24] Train loss=0.38807666301727295
Test set avg_accuracy=86.04% avg_sensitivity=58.63%, avg_specificity=93.99% avg_auc=87.52%
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.419051 Test loss=0.354630 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.39840418100357056
[5/24] Train loss=0.40704983472824097
[10/24] Train loss=0.4078516364097595
[15/24] Train loss=0.38525390625
[20/24] Train loss=0.3776710033416748
Test set avg_accuracy=86.13% avg_sensitivity=56.20%, avg_specificity=94.81% avg_auc=87.62%
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.404870 Test loss=0.348224 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.38805538415908813
[5/24] Train loss=0.380440354347229
[10/24] Train loss=0.39800384640693665
[15/24] Train loss=0.3695355951786041
[20/24] Train loss=0.3566199541091919
Test set avg_accuracy=86.33% avg_sensitivity=61.70%, avg_specificity=93.47% avg_auc=88.76%
Best model saved!! Metric=4.259169730340872!!
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.388672 Test loss=0.339735 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.37106725573539734
[5/24] Train loss=0.38792550563812256
[10/24] Train loss=0.38409486413002014
[15/24] Train loss=0.35356077551841736
[20/24] Train loss=0.34636029601097107
Test set avg_accuracy=86.38% avg_sensitivity=59.68%, avg_specificity=94.12% avg_auc=88.74%
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.376912 Test loss=0.334619 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3546929359436035
[5/24] Train loss=0.369270920753479
[10/24] Train loss=0.37240496277809143
[15/24] Train loss=0.3434256315231323
[20/24] Train loss=0.33739736676216125
Test set avg_accuracy=86.33% avg_sensitivity=65.99%, avg_specificity=92.22% avg_auc=89.81%
Best model saved!! Metric=8.35694366422021!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.365679 Test loss=0.329943 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.34750691056251526
[5/24] Train loss=0.3642219007015228
[10/24] Train loss=0.3595200479030609
[15/24] Train loss=0.33113163709640503
[20/24] Train loss=0.33319342136383057
Test set avg_accuracy=86.60% avg_sensitivity=66.11%, avg_specificity=92.54% avg_auc=90.08%
Best model saved!! Metric=9.331337433431301!!
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.356954 Test loss=0.324618 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3423144817352295
[5/24] Train loss=0.3572552502155304
[10/24] Train loss=0.3449065387248993
[15/24] Train loss=0.3215472996234894
[20/24] Train loss=0.3227907717227936
Test set avg_accuracy=87.02% avg_sensitivity=62.34%, avg_specificity=94.17% avg_auc=89.92%
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.347738 Test loss=0.318441 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.34538060426712036
[5/24] Train loss=0.3531370460987091
[10/24] Train loss=0.3474200665950775
[15/24] Train loss=0.31747549772262573
[20/24] Train loss=0.31401169300079346
Test set avg_accuracy=86.74% avg_sensitivity=65.82%, avg_specificity=92.81% avg_auc=90.42%
Best model saved!! Metric=9.791553612539062!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.344289 Test loss=0.316533 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3227437436580658
[5/24] Train loss=0.34548741579055786
[10/24] Train loss=0.34210097789764404
[15/24] Train loss=0.3156593143939972
[20/24] Train loss=0.30887675285339355
Test set avg_accuracy=87.06% avg_sensitivity=66.05%, avg_specificity=93.15% avg_auc=90.82%
Best model saved!! Metric=11.07625707586216!!
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.334546 Test loss=0.312702 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.32530152797698975
[5/24] Train loss=0.34966808557510376
[10/24] Train loss=0.3329905867576599
[15/24] Train loss=0.3001202642917633
[20/24] Train loss=0.29764696955680847
Test set avg_accuracy=87.01% avg_sensitivity=58.81%, avg_specificity=95.18% avg_auc=89.92%
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.328310 Test loss=0.315396 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.32260504364967346
[5/24] Train loss=0.35066384077072144
[10/24] Train loss=0.33238959312438965
[15/24] Train loss=0.2981446087360382
[20/24] Train loss=0.29317131638526917
Test set avg_accuracy=86.97% avg_sensitivity=60.49%, avg_specificity=94.64% avg_auc=90.07%
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.326626 Test loss=0.314785 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3189246952533722
[5/24] Train loss=0.3457295596599579
[10/24] Train loss=0.32491424679756165
[15/24] Train loss=0.2973296046257019
[20/24] Train loss=0.29429978132247925
Test set avg_accuracy=86.97% avg_sensitivity=59.04%, avg_specificity=95.06% avg_auc=90.05%
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.319844 Test loss=0.315308 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.31303244829177856
[5/24] Train loss=0.33167868852615356
[10/24] Train loss=0.30482161045074463
[15/24] Train loss=0.2888565957546234
[20/24] Train loss=0.28735268115997314
Test set avg_accuracy=87.02% avg_sensitivity=60.72%, avg_specificity=94.64% avg_auc=90.02%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.314833 Test loss=0.314426 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3045596778392792
[5/24] Train loss=0.328326940536499
[10/24] Train loss=0.3111302852630615
[15/24] Train loss=0.2826932370662689
[20/24] Train loss=0.2845093011856079
Test set avg_accuracy=84.96% avg_sensitivity=37.72%, avg_specificity=98.66% avg_auc=86.86%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.307974 Test loss=0.378106 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3003102242946625
[5/24] Train loss=0.32045692205429077
[10/24] Train loss=0.3004783093929291
[15/24] Train loss=0.2736126482486725
[20/24] Train loss=0.29656440019607544
Test set avg_accuracy=84.05% avg_sensitivity=32.79%, avg_specificity=98.91% avg_auc=86.62%
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.302809 Test loss=0.402167 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3002506196498871
[5/24] Train loss=0.32460612058639526
[10/24] Train loss=0.3028219938278198
[15/24] Train loss=0.2690196931362152
[20/24] Train loss=0.2806699872016907
Test set avg_accuracy=86.04% avg_sensitivity=47.80%, avg_specificity=97.13% avg_auc=88.93%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.300796 Test loss=0.339688 Current lr=[0.000210185142098938]

[0/24] Train loss=0.28160178661346436
[5/24] Train loss=0.3029528856277466
[10/24] Train loss=0.28152939677238464
[15/24] Train loss=0.26367348432540894
[20/24] Train loss=0.28480684757232666
Test set avg_accuracy=85.72% avg_sensitivity=44.03%, avg_specificity=97.80% avg_auc=86.94%
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.292324 Test loss=0.362627 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2845782935619354
[5/24] Train loss=0.2912226915359497
[10/24] Train loss=0.2892237901687622
[15/24] Train loss=0.2700810432434082
[20/24] Train loss=0.270405113697052
Test set avg_accuracy=87.08% avg_sensitivity=62.98%, avg_specificity=94.07% avg_auc=90.91%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.289017 Test loss=0.303503 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2789943814277649
[5/24] Train loss=0.2660079896450043
[10/24] Train loss=0.2926984429359436
[15/24] Train loss=0.270837664604187
[20/24] Train loss=0.27601224184036255
Test set avg_accuracy=85.55% avg_sensitivity=40.79%, avg_specificity=98.52% avg_auc=87.70%
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.285043 Test loss=0.366920 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.27288737893104553
[5/24] Train loss=0.27279937267303467
[10/24] Train loss=0.2760915458202362
[15/24] Train loss=0.2605801224708557
[20/24] Train loss=0.27215394377708435
Test set avg_accuracy=87.42% avg_sensitivity=61.47%, avg_specificity=94.94% avg_auc=90.75%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.280421 Test loss=0.305618 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2702573239803314
[5/24] Train loss=0.2569734454154968
[10/24] Train loss=0.2796081304550171
[15/24] Train loss=0.2616384029388428
[20/24] Train loss=0.27396464347839355
Test set avg_accuracy=87.30% avg_sensitivity=56.95%, avg_specificity=96.10% avg_auc=90.44%
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.276530 Test loss=0.309164 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.27061137557029724
[5/24] Train loss=0.2584789991378784
[10/24] Train loss=0.27627837657928467
[15/24] Train loss=0.25835686922073364
[20/24] Train loss=0.2685183584690094
Test set avg_accuracy=86.98% avg_sensitivity=50.46%, avg_specificity=97.56% avg_auc=89.09%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.272248 Test loss=0.337015 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.26623064279556274
[5/24] Train loss=0.24438604712486267
[10/24] Train loss=0.28924503922462463
[15/24] Train loss=0.24657490849494934
[20/24] Train loss=0.26249492168426514
Test set avg_accuracy=86.09% avg_sensitivity=72.65%, avg_specificity=89.99% avg_auc=90.44%
Best model saved!! Metric=13.175711706415854!!
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.269801 Test loss=0.323329 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2707071900367737
[5/24] Train loss=0.25567346811294556
[10/24] Train loss=0.27832356095314026
[15/24] Train loss=0.2501026690006256
[20/24] Train loss=0.26293203234672546
Test set avg_accuracy=86.71% avg_sensitivity=68.19%, avg_specificity=92.07% avg_auc=91.03%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.265880 Test loss=0.308635 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2690277695655823
[5/24] Train loss=0.24726159870624542
[10/24] Train loss=0.2688688337802887
[15/24] Train loss=0.2577071487903595
[20/24] Train loss=0.26227912306785583
Test set avg_accuracy=84.09% avg_sensitivity=79.26%, avg_specificity=85.49% avg_auc=89.74%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.264368 Test loss=0.369777 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.25544068217277527
[5/24] Train loss=0.23148047924041748
[10/24] Train loss=0.2734932005405426
[15/24] Train loss=0.24953770637512207
[20/24] Train loss=0.24625784158706665
Test set avg_accuracy=81.28% avg_sensitivity=18.25%, avg_specificity=99.55% avg_auc=77.07%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.258401 Test loss=0.522500 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2658233344554901
[5/24] Train loss=0.2500210404396057
[10/24] Train loss=0.2785685062408447
[15/24] Train loss=0.24972161650657654
[20/24] Train loss=0.2553005814552307
Test set avg_accuracy=86.98% avg_sensitivity=57.71%, avg_specificity=95.47% avg_auc=88.87%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.261940 Test loss=0.320613 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.24553054571151733
[5/24] Train loss=0.2311987578868866
[10/24] Train loss=0.2579391300678253
[15/24] Train loss=0.2454826831817627
[20/24] Train loss=0.2625144422054291
Test set avg_accuracy=86.11% avg_sensitivity=51.80%, avg_specificity=96.05% avg_auc=87.58%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.256056 Test loss=0.352914 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.27896949648857117
[5/24] Train loss=0.22691132128238678
[10/24] Train loss=0.26933926343917847
[15/24] Train loss=0.24121496081352234
[20/24] Train loss=0.248628631234169
Test set avg_accuracy=86.51% avg_sensitivity=63.21%, avg_specificity=93.27% avg_auc=89.42%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.255133 Test loss=0.325727 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2744808793067932
[5/24] Train loss=0.2356647551059723
[10/24] Train loss=0.27076688408851624
[15/24] Train loss=0.2277025282382965
[20/24] Train loss=0.24712517857551575
Test set avg_accuracy=85.55% avg_sensitivity=53.30%, avg_specificity=94.89% avg_auc=87.73%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.257037 Test loss=0.345891 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2370661348104477
[5/24] Train loss=0.22149789333343506
[10/24] Train loss=0.26093998551368713
[15/24] Train loss=0.22861900925636292
[20/24] Train loss=0.25373852252960205
Test set avg_accuracy=83.95% avg_sensitivity=78.45%, avg_specificity=85.54% avg_auc=89.69%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.247682 Test loss=0.363741 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2538626492023468
[5/24] Train loss=0.22701820731163025
[10/24] Train loss=0.24930638074874878
[15/24] Train loss=0.22576385736465454
[20/24] Train loss=0.24321897327899933
Test set avg_accuracy=85.27% avg_sensitivity=47.05%, avg_specificity=96.36% avg_auc=87.08%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.245344 Test loss=0.358217 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2462455928325653
[5/24] Train loss=0.21710525453090668
[10/24] Train loss=0.2622033655643463
[15/24] Train loss=0.22075071930885315
[20/24] Train loss=0.2525688111782074
Test set avg_accuracy=85.99% avg_sensitivity=56.26%, avg_specificity=94.61% avg_auc=88.77%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.246143 Test loss=0.336188 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.26155781745910645
[5/24] Train loss=0.21819233894348145
[10/24] Train loss=0.2828700840473175
[15/24] Train loss=0.2265394777059555
[20/24] Train loss=0.23051977157592773
Test set avg_accuracy=85.31% avg_sensitivity=50.98%, avg_specificity=95.26% avg_auc=84.04%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.244584 Test loss=0.384660 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2418672889471054
[5/24] Train loss=0.22064711153507233
[10/24] Train loss=0.2620455324649811
[15/24] Train loss=0.2345426380634308
[20/24] Train loss=0.22785724699497223
Test set avg_accuracy=84.22% avg_sensitivity=40.03%, avg_specificity=97.03% avg_auc=85.38%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.244978 Test loss=0.383607 Current lr=[0.000299720220882401]

[0/24] Train loss=0.23600280284881592
[5/24] Train loss=0.2261204868555069
[10/24] Train loss=0.24868938326835632
[15/24] Train loss=0.2399994283914566
[20/24] Train loss=0.2507748603820801
Test set avg_accuracy=85.94% avg_sensitivity=51.56%, avg_specificity=95.90% avg_auc=88.45%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.246027 Test loss=0.350969 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.24977102875709534
[5/24] Train loss=0.24477612972259521
[10/24] Train loss=0.24995721876621246
[15/24] Train loss=0.22166234254837036
[20/24] Train loss=0.2356729656457901
Test set avg_accuracy=85.14% avg_sensitivity=43.22%, avg_specificity=97.30% avg_auc=86.57%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.247541 Test loss=0.404457 Current lr=[0.000298904600941902]

[0/24] Train loss=0.23962903022766113
[5/24] Train loss=0.23125959932804108
[10/24] Train loss=0.2601451575756073
[15/24] Train loss=0.2159961462020874
[20/24] Train loss=0.24237027764320374
Test set avg_accuracy=83.48% avg_sensitivity=31.17%, avg_specificity=98.64% avg_auc=81.21%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.245512 Test loss=0.425074 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.23099006712436676
[5/24] Train loss=0.2376154512166977
[10/24] Train loss=0.2467697560787201
[15/24] Train loss=0.22679933905601501
[20/24] Train loss=0.22362039983272552
Test set avg_accuracy=80.76% avg_sensitivity=16.28%, avg_specificity=99.45% avg_auc=75.83%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.238443 Test loss=0.577248 Current lr=[0.000297555943323901]

[0/24] Train loss=0.23365098237991333
[5/24] Train loss=0.22460715472698212
[10/24] Train loss=0.23642785847187042
[15/24] Train loss=0.21702277660369873
[20/24] Train loss=0.2280304729938507
Test set avg_accuracy=84.67% avg_sensitivity=40.61%, avg_specificity=97.45% avg_auc=84.57%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.237302 Test loss=0.418162 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.22686949372291565
[5/24] Train loss=0.2040938138961792
[10/24] Train loss=0.2369161993265152
[15/24] Train loss=0.23091520369052887
[20/24] Train loss=0.22631387412548065
Test set avg_accuracy=86.51% avg_sensitivity=57.07%, avg_specificity=95.05% avg_auc=88.89%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.234107 Test loss=0.329758 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2345304936170578
[5/24] Train loss=0.20134560763835907
[10/24] Train loss=0.23852282762527466
[15/24] Train loss=0.22767949104309082
[20/24] Train loss=0.22976338863372803
Test set avg_accuracy=86.65% avg_sensitivity=74.86%, avg_specificity=90.07% avg_auc=90.65%
Best model saved!! Metric=16.228824170457145!!
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.234829 Test loss=0.318712 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2274225652217865
[5/24] Train loss=0.2062787115573883
[10/24] Train loss=0.23047824203968048
[15/24] Train loss=0.23193992674350739
[20/24] Train loss=0.23177728056907654
Test set avg_accuracy=85.60% avg_sensitivity=46.47%, avg_specificity=96.94% avg_auc=86.15%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.231117 Test loss=0.389242 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.213432177901268
[5/24] Train loss=0.20438097417354584
[10/24] Train loss=0.25052937865257263
[15/24] Train loss=0.222483292222023
[20/24] Train loss=0.223687082529068
Test set avg_accuracy=80.85% avg_sensitivity=79.84%, avg_specificity=81.14% avg_auc=88.77%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.231334 Test loss=0.398817 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.227337047457695
[5/24] Train loss=0.20129893720149994
[10/24] Train loss=0.22652986645698547
[15/24] Train loss=0.22239693999290466
[20/24] Train loss=0.22593744099140167
Test set avg_accuracy=86.58% avg_sensitivity=70.05%, avg_specificity=91.37% avg_auc=89.17%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.226153 Test loss=0.332363 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2209768146276474
[5/24] Train loss=0.19983994960784912
[10/24] Train loss=0.22196955978870392
[15/24] Train loss=0.22041064500808716
[20/24] Train loss=0.22079233825206757
Test set avg_accuracy=85.48% avg_sensitivity=76.71%, avg_specificity=88.02% avg_auc=90.57%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.221905 Test loss=0.336907 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2108679860830307
[5/24] Train loss=0.19528500735759735
[10/24] Train loss=0.22061358392238617
[15/24] Train loss=0.19905950129032135
[20/24] Train loss=0.21738503873348236
Test set avg_accuracy=83.74% avg_sensitivity=81.00%, avg_specificity=84.53% avg_auc=89.93%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.216233 Test loss=0.377302 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.22596904635429382
[5/24] Train loss=0.19909468293190002
[10/24] Train loss=0.2260294109582901
[15/24] Train loss=0.21629582345485687
[20/24] Train loss=0.21158374845981598
Test set avg_accuracy=86.35% avg_sensitivity=72.31%, avg_specificity=90.43% avg_auc=89.65%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.217780 Test loss=0.337332 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2051714062690735
[5/24] Train loss=0.18960174918174744
[10/24] Train loss=0.21601782739162445
[15/24] Train loss=0.19925299286842346
[20/24] Train loss=0.20724429190158844
Test set avg_accuracy=85.51% avg_sensitivity=73.12%, avg_specificity=89.10% avg_auc=89.82%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.214737 Test loss=0.333659 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2033713161945343
[5/24] Train loss=0.18627196550369263
[10/24] Train loss=0.22764229774475098
[15/24] Train loss=0.21226146817207336
[20/24] Train loss=0.20878329873085022
Test set avg_accuracy=85.48% avg_sensitivity=52.67%, avg_specificity=94.99% avg_auc=86.95%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.217286 Test loss=0.363554 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.21014277637004852
[5/24] Train loss=0.1937805563211441
[10/24] Train loss=0.21633581817150116
[15/24] Train loss=0.20623712241649628
[20/24] Train loss=0.2186351716518402
Test set avg_accuracy=86.32% avg_sensitivity=50.75%, avg_specificity=96.62% avg_auc=87.02%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.214919 Test loss=0.361666 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2087094932794571
[5/24] Train loss=0.18521636724472046
[10/24] Train loss=0.2271815985441208
[15/24] Train loss=0.2153780311346054
[20/24] Train loss=0.19814364612102509
Test set avg_accuracy=86.08% avg_sensitivity=68.25%, avg_specificity=91.25% avg_auc=89.29%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.210717 Test loss=0.334125 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2104337066411972
[5/24] Train loss=0.1928918957710266
[10/24] Train loss=0.21282173693180084
[15/24] Train loss=0.19671308994293213
[20/24] Train loss=0.20529086887836456
Test set avg_accuracy=85.00% avg_sensitivity=42.82%, avg_specificity=97.23% avg_auc=82.50%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.211759 Test loss=0.403077 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.20498989522457123
[5/24] Train loss=0.1868329793214798
[10/24] Train loss=0.2118559330701828
[15/24] Train loss=0.20365121960639954
[20/24] Train loss=0.2006077617406845
Test set avg_accuracy=85.34% avg_sensitivity=43.57%, avg_specificity=97.45% avg_auc=83.02%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.208853 Test loss=0.435199 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.190322145819664
[5/24] Train loss=0.18126453459262848
[10/24] Train loss=0.22023187577724457
[15/24] Train loss=0.19891341030597687
[20/24] Train loss=0.20887289941310883
Test set avg_accuracy=85.44% avg_sensitivity=47.45%, avg_specificity=96.46% avg_auc=86.23%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.205710 Test loss=0.383185 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2016502171754837
[5/24] Train loss=0.1727295070886612
[10/24] Train loss=0.21703028678894043
[15/24] Train loss=0.19580373167991638
[20/24] Train loss=0.2071763426065445
Test set avg_accuracy=86.60% avg_sensitivity=52.67%, avg_specificity=96.44% avg_auc=85.50%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.205850 Test loss=0.370828 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2105298936367035
[5/24] Train loss=0.18291562795639038
[10/24] Train loss=0.2238076627254486
[15/24] Train loss=0.19108717143535614
[20/24] Train loss=0.19494129717350006
Test set avg_accuracy=83.42% avg_sensitivity=31.46%, avg_specificity=98.49% avg_auc=77.73%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.204662 Test loss=0.517881 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.20376470685005188
[5/24] Train loss=0.18761056661605835
[10/24] Train loss=0.20874793827533722
[15/24] Train loss=0.2005612552165985
[20/24] Train loss=0.19646909832954407
Test set avg_accuracy=82.59% avg_sensitivity=26.07%, avg_specificity=98.98% avg_auc=76.49%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.204609 Test loss=0.517575 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.19857467710971832
[5/24] Train loss=0.17753544449806213
[10/24] Train loss=0.21416716277599335
[15/24] Train loss=0.20485647022724152
[20/24] Train loss=0.19812269508838654
Test set avg_accuracy=85.91% avg_sensitivity=48.32%, avg_specificity=96.81% avg_auc=84.50%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.204637 Test loss=0.391957 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.2011946737766266
[5/24] Train loss=0.17648836970329285
[10/24] Train loss=0.21082831919193268
[15/24] Train loss=0.19768062233924866
[20/24] Train loss=0.19456961750984192
Test set avg_accuracy=84.82% avg_sensitivity=50.58%, avg_specificity=94.74% avg_auc=83.34%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.202205 Test loss=0.392476 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.1990257054567337
[5/24] Train loss=0.1792561560869217
[10/24] Train loss=0.20919668674468994
[15/24] Train loss=0.19532421231269836
[20/24] Train loss=0.19212056696414948
Test set avg_accuracy=86.81% avg_sensitivity=62.63%, avg_specificity=93.82% avg_auc=87.99%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.202529 Test loss=0.341123 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.19663700461387634
[5/24] Train loss=0.18221761286258698
[10/24] Train loss=0.1928660124540329
[15/24] Train loss=0.1854541301727295
[20/24] Train loss=0.19727659225463867
Test set avg_accuracy=84.14% avg_sensitivity=78.10%, avg_specificity=85.89% avg_auc=89.55%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.199535 Test loss=0.369745 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.2075076550245285
[5/24] Train loss=0.18747559189796448
[10/24] Train loss=0.20777307450771332
[15/24] Train loss=0.19425301253795624
[20/24] Train loss=0.1851961761713028
Test set avg_accuracy=85.12% avg_sensitivity=66.11%, avg_specificity=90.63% avg_auc=87.31%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.200198 Test loss=0.365964 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.18024280667304993
[5/24] Train loss=0.1677822470664978
[10/24] Train loss=0.20689548552036285
[15/24] Train loss=0.1791326105594635
[20/24] Train loss=0.2004871368408203
Test set avg_accuracy=85.23% avg_sensitivity=53.19%, avg_specificity=94.52% avg_auc=84.55%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.194417 Test loss=0.386508 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.20082150399684906
[5/24] Train loss=0.17979271709918976
[10/24] Train loss=0.19155649840831757
[15/24] Train loss=0.18844017386436462
[20/24] Train loss=0.1900644749403
Test set avg_accuracy=85.90% avg_sensitivity=58.98%, avg_specificity=93.70% avg_auc=86.92%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.197127 Test loss=0.358135 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.20128652453422546
[5/24] Train loss=0.17702603340148926
[10/24] Train loss=0.19407762587070465
[15/24] Train loss=0.1883831024169922
[20/24] Train loss=0.189724862575531
Test set avg_accuracy=83.92% avg_sensitivity=35.92%, avg_specificity=97.83% avg_auc=81.46%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.196503 Test loss=0.455876 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.20603609085083008
[5/24] Train loss=0.1829390674829483
[10/24] Train loss=0.21050044894218445
[15/24] Train loss=0.18900121748447418
[20/24] Train loss=0.2015661597251892
Test set avg_accuracy=85.23% avg_sensitivity=69.81%, avg_specificity=89.70% avg_auc=88.36%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.195457 Test loss=0.348784 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.1893828809261322
[5/24] Train loss=0.17457664012908936
[10/24] Train loss=0.1991652548313141
[15/24] Train loss=0.18942955136299133
[20/24] Train loss=0.19676759839057922
Test set avg_accuracy=86.09% avg_sensitivity=51.74%, avg_specificity=96.05% avg_auc=85.72%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.195010 Test loss=0.380580 Current lr=[0.000224838296036774]

[0/24] Train loss=0.1911003589630127
[5/24] Train loss=0.17861834168434143
[10/24] Train loss=0.19491484761238098
[15/24] Train loss=0.17866557836532593
[20/24] Train loss=0.18436744809150696
Test set avg_accuracy=85.20% avg_sensitivity=41.60%, avg_specificity=97.83% avg_auc=82.60%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.192304 Test loss=0.425914 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.19392207264900208
[5/24] Train loss=0.1731778234243393
[10/24] Train loss=0.18839821219444275
[15/24] Train loss=0.18274980783462524
[20/24] Train loss=0.18784721195697784
Test set avg_accuracy=84.28% avg_sensitivity=38.12%, avg_specificity=97.67% avg_auc=81.61%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.190471 Test loss=0.451075 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.18598294258117676
[5/24] Train loss=0.16680598258972168
[10/24] Train loss=0.19683820009231567
[15/24] Train loss=0.1816471666097641
[20/24] Train loss=0.18317921459674835
Test set avg_accuracy=81.03% avg_sensitivity=20.22%, avg_specificity=98.66% avg_auc=77.34%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.188874 Test loss=0.574281 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.19586795568466187
[5/24] Train loss=0.17251339554786682
[10/24] Train loss=0.20065028965473175
[15/24] Train loss=0.18888120353221893
[20/24] Train loss=0.18782950937747955
Test set avg_accuracy=83.48% avg_sensitivity=32.62%, avg_specificity=98.22% avg_auc=80.08%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.190442 Test loss=0.473466 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.18969638645648956
[5/24] Train loss=0.1640927791595459
[10/24] Train loss=0.1872188299894333
[15/24] Train loss=0.1859508454799652
[20/24] Train loss=0.19229967892169952
Test set avg_accuracy=84.27% avg_sensitivity=44.55%, avg_specificity=95.78% avg_auc=79.79%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.189916 Test loss=0.417983 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2048177868127823
[5/24] Train loss=0.1661888211965561
[10/24] Train loss=0.18414431810379028
[15/24] Train loss=0.17917141318321228
[20/24] Train loss=0.19117452204227448
Test set avg_accuracy=85.23% avg_sensitivity=43.28%, avg_specificity=97.40% avg_auc=83.14%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.188998 Test loss=0.441684 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.19201438128948212
[5/24] Train loss=0.17308993637561798
[10/24] Train loss=0.1809922605752945
[15/24] Train loss=0.18288038671016693
[20/24] Train loss=0.19622552394866943
Test set avg_accuracy=81.84% avg_sensitivity=24.97%, avg_specificity=98.32% avg_auc=76.86%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.189482 Test loss=0.506395 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.19129331409931183
[5/24] Train loss=0.17425169050693512
[10/24] Train loss=0.20468291640281677
[15/24] Train loss=0.18139152228832245
[20/24] Train loss=0.18622110784053802
Test set avg_accuracy=81.20% avg_sensitivity=19.29%, avg_specificity=99.14% avg_auc=73.14%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.188719 Test loss=0.595944 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.18750600516796112
[5/24] Train loss=0.17831899225711823
[10/24] Train loss=0.19225652515888214
[15/24] Train loss=0.191162571310997
[20/24] Train loss=0.18315210938453674
Test set avg_accuracy=79.78% avg_sensitivity=12.69%, avg_specificity=99.23% avg_auc=69.38%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.193559 Test loss=0.642294 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.20760272443294525
[5/24] Train loss=0.17299866676330566
[10/24] Train loss=0.19807133078575134
[15/24] Train loss=0.17870144546031952
[20/24] Train loss=0.19324035942554474
Test set avg_accuracy=84.17% avg_sensitivity=38.01%, avg_specificity=97.55% avg_auc=81.93%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.196921 Test loss=0.458475 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.19486139714717865
[5/24] Train loss=0.17271608114242554
[10/24] Train loss=0.19473408162593842
[15/24] Train loss=0.1896732747554779
[20/24] Train loss=0.1898709386587143
Test set avg_accuracy=81.54% avg_sensitivity=20.80%, avg_specificity=99.14% avg_auc=74.72%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.195828 Test loss=0.579110 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.20452502369880676
[5/24] Train loss=0.1788332760334015
[10/24] Train loss=0.21256589889526367
[15/24] Train loss=0.19445295631885529
[20/24] Train loss=0.19044075906276703
Test set avg_accuracy=85.92% avg_sensitivity=54.06%, avg_specificity=95.16% avg_auc=84.92%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.200999 Test loss=0.381224 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1901290863752365
[5/24] Train loss=0.19653162360191345
[10/24] Train loss=0.2087828367948532
[15/24] Train loss=0.1819860339164734
[20/24] Train loss=0.18470259010791779
Test set avg_accuracy=85.72% avg_sensitivity=48.90%, avg_specificity=96.39% avg_auc=84.03%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.193490 Test loss=0.393009 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.1963546872138977
[5/24] Train loss=0.17850112915039062
[10/24] Train loss=0.19332104921340942
[15/24] Train loss=0.18383939564228058
[20/24] Train loss=0.19148865342140198
Test set avg_accuracy=87.34% avg_sensitivity=69.93%, avg_specificity=92.39% avg_auc=89.53%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.190294 Test loss=0.323005 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.18682219088077545
[5/24] Train loss=0.16325801610946655
[10/24] Train loss=0.1799233853816986
[15/24] Train loss=0.18222835659980774
[20/24] Train loss=0.18747249245643616
Test set avg_accuracy=81.61% avg_sensitivity=23.70%, avg_specificity=98.40% avg_auc=75.14%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.185740 Test loss=0.564639 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.1938098669052124
[5/24] Train loss=0.16516199707984924
[10/24] Train loss=0.18816721439361572
[15/24] Train loss=0.18849927186965942
[20/24] Train loss=0.1787215620279312
Test set avg_accuracy=82.96% avg_sensitivity=30.19%, avg_specificity=98.25% avg_auc=77.35%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.185164 Test loss=0.489224 Current lr=[0.000156543481933168]

[0/24] Train loss=0.18334737420082092
[5/24] Train loss=0.15786559879779816
[10/24] Train loss=0.1866239607334137
[15/24] Train loss=0.1733456254005432
[20/24] Train loss=0.1737678050994873
Test set avg_accuracy=87.29% avg_sensitivity=70.39%, avg_specificity=92.19% avg_auc=89.83%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.180381 Test loss=0.324049 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.17477074265480042
[5/24] Train loss=0.1623985767364502
[10/24] Train loss=0.16967637836933136
[15/24] Train loss=0.16670644283294678
[20/24] Train loss=0.1736956685781479
Test set avg_accuracy=86.22% avg_sensitivity=50.64%, avg_specificity=96.54% avg_auc=85.87%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.175003 Test loss=0.374372 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.1821402609348297
[5/24] Train loss=0.16019245982170105
[10/24] Train loss=0.1805158108472824
[15/24] Train loss=0.16809232532978058
[20/24] Train loss=0.17676173150539398
Test set avg_accuracy=87.46% avg_sensitivity=65.70%, avg_specificity=93.77% avg_auc=88.89%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.175754 Test loss=0.329208 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.17041856050491333
[5/24] Train loss=0.16522860527038574
[10/24] Train loss=0.1731850653886795
[15/24] Train loss=0.1718035191297531
[20/24] Train loss=0.16785602271556854
Test set avg_accuracy=86.03% avg_sensitivity=56.55%, avg_specificity=94.58% avg_auc=85.96%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.175204 Test loss=0.369294 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.17135633528232574
[5/24] Train loss=0.15901127457618713
[10/24] Train loss=0.1838478446006775
[15/24] Train loss=0.17037852108478546
[20/24] Train loss=0.17752450704574585
Test set avg_accuracy=87.01% avg_sensitivity=60.08%, avg_specificity=94.81% avg_auc=86.93%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.174947 Test loss=0.358544 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16618230938911438
[5/24] Train loss=0.1591838002204895
[10/24] Train loss=0.175461083650589
[15/24] Train loss=0.17492905259132385
[20/24] Train loss=0.17406299710273743
Test set avg_accuracy=86.81% avg_sensitivity=58.00%, avg_specificity=95.16% avg_auc=87.82%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.174453 Test loss=0.343644 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.17232432961463928
[5/24] Train loss=0.1583928018808365
[10/24] Train loss=0.1753651350736618
[15/24] Train loss=0.16574089229106903
[20/24] Train loss=0.1732947826385498
Test set avg_accuracy=86.18% avg_sensitivity=68.19%, avg_specificity=91.40% avg_auc=88.93%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.175288 Test loss=0.339181 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.17039191722869873
[5/24] Train loss=0.16118688881397247
[10/24] Train loss=0.16942648589611053
[15/24] Train loss=0.17214620113372803
[20/24] Train loss=0.17091326415538788
Test set avg_accuracy=86.61% avg_sensitivity=51.62%, avg_specificity=96.76% avg_auc=85.52%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.170799 Test loss=0.381209 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.17134253680706024
[5/24] Train loss=0.15301945805549622
[10/24] Train loss=0.16510607302188873
[15/24] Train loss=0.17283417284488678
[20/24] Train loss=0.16807621717453003
Test set avg_accuracy=87.14% avg_sensitivity=70.45%, avg_specificity=91.97% avg_auc=89.82%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.169644 Test loss=0.325452 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.17598563432693481
[5/24] Train loss=0.15294921398162842
[10/24] Train loss=0.17064771056175232
[15/24] Train loss=0.15979121625423431
[20/24] Train loss=0.1687699407339096
Test set avg_accuracy=87.30% avg_sensitivity=62.86%, avg_specificity=94.39% avg_auc=88.09%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.167969 Test loss=0.338501 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16458100080490112
[5/24] Train loss=0.16154208779335022
[10/24] Train loss=0.16185687482357025
[15/24] Train loss=0.15875652432441711
[20/24] Train loss=0.16694821417331696
Test set avg_accuracy=86.95% avg_sensitivity=64.66%, avg_specificity=93.42% avg_auc=88.83%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.167950 Test loss=0.336482 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.17157885432243347
[5/24] Train loss=0.14649230241775513
[10/24] Train loss=0.16641545295715332
[15/24] Train loss=0.15740828216075897
[20/24] Train loss=0.17088866233825684
Test set avg_accuracy=86.86% avg_sensitivity=66.16%, avg_specificity=92.86% avg_auc=88.17%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.166039 Test loss=0.340893 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1613951176404953
[5/24] Train loss=0.1526796668767929
[10/24] Train loss=0.16105644404888153
[15/24] Train loss=0.16496410965919495
[20/24] Train loss=0.16506516933441162
Test set avg_accuracy=87.21% avg_sensitivity=60.43%, avg_specificity=94.98% avg_auc=86.53%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.163787 Test loss=0.353206 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.16657871007919312
[5/24] Train loss=0.15000519156455994
[10/24] Train loss=0.1605810523033142
[15/24] Train loss=0.1545352041721344
[20/24] Train loss=0.1637030988931656
Test set avg_accuracy=86.33% avg_sensitivity=67.38%, avg_specificity=91.82% avg_auc=88.90%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.162381 Test loss=0.347023 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.1623392403125763
[5/24] Train loss=0.14565934240818024
[10/24] Train loss=0.1568313091993332
[15/24] Train loss=0.15743745863437653
[20/24] Train loss=0.1660292148590088
Test set avg_accuracy=87.02% avg_sensitivity=66.28%, avg_specificity=93.03% avg_auc=88.72%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.161311 Test loss=0.338331 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.16139313578605652
[5/24] Train loss=0.14940319955348969
[10/24] Train loss=0.17070405185222626
[15/24] Train loss=0.15016356110572815
[20/24] Train loss=0.16579680144786835
Test set avg_accuracy=86.89% avg_sensitivity=63.73%, avg_specificity=93.60% avg_auc=88.26%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.162810 Test loss=0.341260 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.15812264382839203
[5/24] Train loss=0.15114332735538483
[10/24] Train loss=0.1593119353055954
[15/24] Train loss=0.1576714962720871
[20/24] Train loss=0.16175322234630585
Test set avg_accuracy=86.45% avg_sensitivity=73.64%, avg_specificity=90.16% avg_auc=89.58%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.159859 Test loss=0.343669 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.15887416899204254
[5/24] Train loss=0.1521899253129959
[10/24] Train loss=0.16121621429920197
[15/24] Train loss=0.15457822382450104
[20/24] Train loss=0.16199487447738647
Test set avg_accuracy=86.33% avg_sensitivity=70.97%, avg_specificity=90.78% avg_auc=89.58%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.158389 Test loss=0.343203 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.15913525223731995
[5/24] Train loss=0.1423780620098114
[10/24] Train loss=0.15165358781814575
[15/24] Train loss=0.15280647575855255
[20/24] Train loss=0.15724246203899384
Test set avg_accuracy=86.42% avg_sensitivity=58.63%, avg_specificity=94.47% avg_auc=86.36%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.156229 Test loss=0.367361 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15846049785614014
[5/24] Train loss=0.14465218782424927
[10/24] Train loss=0.1564834713935852
[15/24] Train loss=0.1532704085111618
[20/24] Train loss=0.15248140692710876
Test set avg_accuracy=86.85% avg_sensitivity=71.32%, avg_specificity=91.35% avg_auc=89.43%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.155082 Test loss=0.339545 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.15854234993457794
[5/24] Train loss=0.14386799931526184
[10/24] Train loss=0.1506783813238144
[15/24] Train loss=0.14559869468212128
[20/24] Train loss=0.15234233438968658
Test set avg_accuracy=86.47% avg_sensitivity=66.57%, avg_specificity=92.24% avg_auc=88.16%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.153588 Test loss=0.355583 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.15297384560108185
[5/24] Train loss=0.14125758409500122
[10/24] Train loss=0.15290914475917816
[15/24] Train loss=0.15294915437698364
[20/24] Train loss=0.15004020929336548
Test set avg_accuracy=86.16% avg_sensitivity=70.05%, avg_specificity=90.83% avg_auc=88.98%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.152863 Test loss=0.349794 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.15411053597927094
[5/24] Train loss=0.1417735517024994
[10/24] Train loss=0.14838120341300964
[15/24] Train loss=0.15085463225841522
[20/24] Train loss=0.14969000220298767
Test set avg_accuracy=86.32% avg_sensitivity=62.11%, avg_specificity=93.33% avg_auc=87.56%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.151257 Test loss=0.359631 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14978019893169403
[5/24] Train loss=0.13356441259384155
[10/24] Train loss=0.1473352313041687
[15/24] Train loss=0.15109504759311676
[20/24] Train loss=0.15004082024097443
Test set avg_accuracy=86.60% avg_sensitivity=63.67%, avg_specificity=93.25% avg_auc=87.24%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.151647 Test loss=0.358424 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.15288706123828888
[5/24] Train loss=0.1434508115053177
[10/24] Train loss=0.15136469900608063
[15/24] Train loss=0.15111427009105682
[20/24] Train loss=0.15159089863300323
Test set avg_accuracy=85.96% avg_sensitivity=55.10%, avg_specificity=94.91% avg_auc=84.89%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.150785 Test loss=0.381983 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1506734937429428
[5/24] Train loss=0.13852623105049133
[10/24] Train loss=0.14565105736255646
[15/24] Train loss=0.14946657419204712
[20/24] Train loss=0.1473591923713684
Test set avg_accuracy=86.50% avg_sensitivity=58.05%, avg_specificity=94.74% avg_auc=85.60%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.148419 Test loss=0.375453 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14442546665668488
[5/24] Train loss=0.13421127200126648
[10/24] Train loss=0.15053346753120422
[15/24] Train loss=0.14643320441246033
[20/24] Train loss=0.14900299906730652
Test set avg_accuracy=86.86% avg_sensitivity=65.41%, avg_specificity=93.08% avg_auc=87.77%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.147719 Test loss=0.351834 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.14678075909614563
[5/24] Train loss=0.13559959828853607
[10/24] Train loss=0.14676718413829803
[15/24] Train loss=0.14579321444034576
[20/24] Train loss=0.14265528321266174
Test set avg_accuracy=86.73% avg_sensitivity=66.69%, avg_specificity=92.54% avg_auc=88.46%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.146187 Test loss=0.348623 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.14756721258163452
[5/24] Train loss=0.13879211246967316
[10/24] Train loss=0.14341670274734497
[15/24] Train loss=0.14130167663097382
[20/24] Train loss=0.14559930562973022
Test set avg_accuracy=85.91% avg_sensitivity=65.64%, avg_specificity=91.79% avg_auc=87.65%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.145095 Test loss=0.361765 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1441432684659958
[5/24] Train loss=0.13771596550941467
[10/24] Train loss=0.1412431001663208
[15/24] Train loss=0.1422935277223587
[20/24] Train loss=0.14651808142662048
Test set avg_accuracy=86.58% avg_sensitivity=63.15%, avg_specificity=93.37% avg_auc=87.84%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.145772 Test loss=0.352436 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.14460697770118713
[5/24] Train loss=0.13239817321300507
[10/24] Train loss=0.1403108835220337
[15/24] Train loss=0.1400173306465149
[20/24] Train loss=0.1464066356420517
Test set avg_accuracy=86.72% avg_sensitivity=68.13%, avg_specificity=92.11% avg_auc=88.05%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.143604 Test loss=0.351959 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.14327608048915863
[5/24] Train loss=0.13886506855487823
[10/24] Train loss=0.1370200365781784
[15/24] Train loss=0.1427849680185318
[20/24] Train loss=0.14662091434001923
Test set avg_accuracy=86.60% avg_sensitivity=68.66%, avg_specificity=91.80% avg_auc=88.99%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.143713 Test loss=0.342446 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.14303487539291382
[5/24] Train loss=0.13405629992485046
[10/24] Train loss=0.1366250067949295
[15/24] Train loss=0.14152531325817108
[20/24] Train loss=0.1398109495639801
Test set avg_accuracy=86.64% avg_sensitivity=66.40%, avg_specificity=92.51% avg_auc=87.85%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.143067 Test loss=0.354443 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1416551023721695
[5/24] Train loss=0.13361698389053345
[10/24] Train loss=0.1346924751996994
[15/24] Train loss=0.13951890170574188
[20/24] Train loss=0.14246514439582825
Test set avg_accuracy=86.32% avg_sensitivity=67.67%, avg_specificity=91.72% avg_auc=88.39%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.141800 Test loss=0.355916 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13945336639881134
[5/24] Train loss=0.13337139785289764
[10/24] Train loss=0.13990283012390137
[15/24] Train loss=0.1403367966413498
[20/24] Train loss=0.14335158467292786
Test set avg_accuracy=86.33% avg_sensitivity=67.03%, avg_specificity=91.92% avg_auc=88.51%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.141003 Test loss=0.350721 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1399894505739212
[5/24] Train loss=0.13342230021953583
[10/24] Train loss=0.13849321007728577
[15/24] Train loss=0.13767583668231964
[20/24] Train loss=0.14253684878349304
Test set avg_accuracy=86.91% avg_sensitivity=62.98%, avg_specificity=93.85% avg_auc=87.30%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.140358 Test loss=0.355716 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.14138543605804443
[5/24] Train loss=0.13041716814041138
[10/24] Train loss=0.1382410079240799
[15/24] Train loss=0.13519777357578278
[20/24] Train loss=0.1390102356672287
Test set avg_accuracy=86.32% avg_sensitivity=67.09%, avg_specificity=91.89% avg_auc=88.46%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.139349 Test loss=0.352939 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1384795755147934
[5/24] Train loss=0.12982363998889923
[10/24] Train loss=0.13669374585151672
[15/24] Train loss=0.13852785527706146
[20/24] Train loss=0.13644175231456757
Test set avg_accuracy=86.72% avg_sensitivity=65.47%, avg_specificity=92.88% avg_auc=88.20%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.138279 Test loss=0.352185 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13725809752941132
[5/24] Train loss=0.13167397677898407
[10/24] Train loss=0.13817772269248962
[15/24] Train loss=0.1394232213497162
[20/24] Train loss=0.13832879066467285
Test set avg_accuracy=86.90% avg_sensitivity=66.40%, avg_specificity=92.85% avg_auc=88.70%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.138540 Test loss=0.343165 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.138635516166687
[5/24] Train loss=0.13119542598724365
[10/24] Train loss=0.13461211323738098
[15/24] Train loss=0.13618777692317963
[20/24] Train loss=0.13746589422225952
Test set avg_accuracy=86.68% avg_sensitivity=67.61%, avg_specificity=92.21% avg_auc=88.68%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.137532 Test loss=0.346922 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1384640783071518
[5/24] Train loss=0.13021451234817505
[10/24] Train loss=0.13342402875423431
[15/24] Train loss=0.13429521024227142
[20/24] Train loss=0.1434912532567978
Test set avg_accuracy=86.81% avg_sensitivity=64.14%, avg_specificity=93.38% avg_auc=88.08%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.137455 Test loss=0.352285 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1393214613199234
[5/24] Train loss=0.1280299872159958
[10/24] Train loss=0.13094089925289154
[15/24] Train loss=0.13444001972675323
[20/24] Train loss=0.13676130771636963
Test set avg_accuracy=86.84% avg_sensitivity=65.76%, avg_specificity=92.95% avg_auc=88.42%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.136586 Test loss=0.347261 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1384335458278656
[5/24] Train loss=0.12781652808189392
[10/24] Train loss=0.13404010236263275
[15/24] Train loss=0.13249845802783966
[20/24] Train loss=0.1368008553981781
Test set avg_accuracy=87.04% avg_sensitivity=65.24%, avg_specificity=93.37% avg_auc=88.21%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.136135 Test loss=0.348470 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13592374324798584
[5/24] Train loss=0.12851163744926453
[10/24] Train loss=0.13196662068367004
[15/24] Train loss=0.13291999697685242
[20/24] Train loss=0.13482819497585297
Test set avg_accuracy=86.82% avg_sensitivity=66.74%, avg_specificity=92.64% avg_auc=88.48%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.136258 Test loss=0.348171 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1341651827096939
[5/24] Train loss=0.12766990065574646
[10/24] Train loss=0.13015709817409515
[15/24] Train loss=0.13440456986427307
[20/24] Train loss=0.1342964917421341
Test set avg_accuracy=86.88% avg_sensitivity=65.41%, avg_specificity=93.10% avg_auc=88.18%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.135189 Test loss=0.350179 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.13401100039482117
[5/24] Train loss=0.12916691601276398
[10/24] Train loss=0.13340409100055695
[15/24] Train loss=0.1328267753124237
[20/24] Train loss=0.13361534476280212
Test set avg_accuracy=86.81% avg_sensitivity=65.82%, avg_specificity=92.90% avg_auc=88.30%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.135493 Test loss=0.350632 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13785739243030548
[5/24] Train loss=0.12731605768203735
[10/24] Train loss=0.13380488753318787
[15/24] Train loss=0.13388249278068542
[20/24] Train loss=0.1371135115623474
Test set avg_accuracy=86.85% avg_sensitivity=66.16%, avg_specificity=92.85% avg_auc=88.36%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.134927 Test loss=0.349978 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13203978538513184
[5/24] Train loss=0.12631984055042267
[10/24] Train loss=0.13405412435531616
[15/24] Train loss=0.13313701748847961
[20/24] Train loss=0.13709132373332977
Test set avg_accuracy=86.89% avg_sensitivity=66.98%, avg_specificity=92.66% avg_auc=88.77%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.135087 Test loss=0.346564 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.14289818704128265
[5/24] Train loss=0.1236373782157898
[10/24] Train loss=0.1273394525051117
[15/24] Train loss=0.13371598720550537
[20/24] Train loss=0.13612160086631775
Test set avg_accuracy=87.01% avg_sensitivity=66.40%, avg_specificity=92.98% avg_auc=88.81%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.134707 Test loss=0.344977 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13518927991390228
[5/24] Train loss=0.1280491054058075
[10/24] Train loss=0.13156309723854065
[15/24] Train loss=0.13178075850009918
[20/24] Train loss=0.1388658583164215
Test set avg_accuracy=86.93% avg_sensitivity=65.93%, avg_specificity=93.01% avg_auc=88.62%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.134800 Test loss=0.346903 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1367536038160324
[5/24] Train loss=0.12995046377182007
[10/24] Train loss=0.12942294776439667
[15/24] Train loss=0.13162021338939667
[20/24] Train loss=0.13679613173007965
Test set avg_accuracy=86.93% avg_sensitivity=66.16%, avg_specificity=92.95% avg_auc=88.62%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.134148 Test loss=0.347404 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.13556794822216034
[5/24] Train loss=0.12480335682630539
[10/24] Train loss=0.1279403120279312
[15/24] Train loss=0.13202671706676483
[20/24] Train loss=0.13545583188533783
Test set avg_accuracy=86.86% avg_sensitivity=66.05%, avg_specificity=92.90% avg_auc=88.63%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.134444 Test loss=0.347389 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1347285360097885
[5/24] Train loss=0.12682299315929413
[10/24] Train loss=0.13037163019180298
[15/24] Train loss=0.13121813535690308
[20/24] Train loss=0.13438639044761658
Test set avg_accuracy=86.84% avg_sensitivity=66.11%, avg_specificity=92.85% avg_auc=88.65%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.134104 Test loss=0.347382 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.13828304409980774
[5/24] Train loss=0.12803421914577484
[10/24] Train loss=0.1317187398672104
[15/24] Train loss=0.13142047822475433
[20/24] Train loss=0.13374380767345428
Test set avg_accuracy=86.85% avg_sensitivity=66.05%, avg_specificity=92.88% avg_auc=88.63%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.134475 Test loss=0.347495 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=86.65% sen=74.86%, spe=90.07%, auc=90.65%!
Fold[10] Avg_overlap=0.64%(±0.26368652860422453)
Final Avg Result: avg_acc=85.28%(±1.1511976246049302) avg_sen=76.30% (±2.476988454800564) avg_spe=88.36% (±1.5260689573768575) avg_auc=90.94% (±1.0441186744921613) avg_overlap=0.60% (±0.10547200390505684)
