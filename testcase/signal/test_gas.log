/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/24] Train loss=0.7343041896820068
[5/24] Train loss=0.7156659960746765
[10/24] Train loss=0.7136808037757874
[15/24] Train loss=0.7029354572296143
[20/24] Train loss=0.707660973072052
Test set avg_accuracy=56.67% avg_sensitivity=46.12%, avg_specificity=60.43% avg_auc=54.47%
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.710748 Test loss=0.692071 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7018910050392151
[5/24] Train loss=0.7005913853645325
[10/24] Train loss=0.6993004679679871
[15/24] Train loss=0.6819501519203186
[20/24] Train loss=0.6840797066688538
Test set avg_accuracy=63.92% avg_sensitivity=51.41%, avg_specificity=68.39% avg_auc=63.88%
Best model saved!! Metric=-78.4064158358591!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.693477 Test loss=0.648414 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6766651272773743
[5/24] Train loss=0.6840673089027405
[10/24] Train loss=0.6759318113327026
[15/24] Train loss=0.6666066646575928
[20/24] Train loss=0.6662088632583618
Test set avg_accuracy=65.43% avg_sensitivity=56.70%, avg_specificity=68.55% avg_auc=68.13%
Best model saved!! Metric=-67.19306027147776!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.675409 Test loss=0.632823 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.663641631603241
[5/24] Train loss=0.6691918969154358
[10/24] Train loss=0.661169171333313
[15/24] Train loss=0.6497163772583008
[20/24] Train loss=0.6368829011917114
Test set avg_accuracy=67.25% avg_sensitivity=61.26%, avg_specificity=69.39% avg_auc=71.82%
Best model saved!! Metric=-56.276551398083356!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.658312 Test loss=0.615575 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6342288255691528
[5/24] Train loss=0.6436112523078918
[10/24] Train loss=0.6458136439323425
[15/24] Train loss=0.6241165399551392
[20/24] Train loss=0.6175268888473511
Test set avg_accuracy=69.04% avg_sensitivity=63.78%, avg_specificity=70.91% avg_auc=74.59%
Best model saved!! Metric=-47.68385345911212!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.636693 Test loss=0.591863 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6127963662147522
[5/24] Train loss=0.6255984306335449
[10/24] Train loss=0.6239163875579834
[15/24] Train loss=0.5976875424385071
[20/24] Train loss=0.5850895643234253
Test set avg_accuracy=70.25% avg_sensitivity=72.93%, avg_specificity=69.29% avg_auc=77.85%
Best model saved!! Metric=-35.68228578586232!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.611771 Test loss=0.579822 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5901740193367004
[5/24] Train loss=0.5988698601722717
[10/24] Train loss=0.6039432883262634
[15/24] Train loss=0.5694552659988403
[20/24] Train loss=0.5553618669509888
Test set avg_accuracy=72.14% avg_sensitivity=76.50%, avg_specificity=70.58% avg_auc=80.11%
Best model saved!! Metric=-26.68264521214445!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.584985 Test loss=0.556418 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5550203323364258
[5/24] Train loss=0.5685656666755676
[10/24] Train loss=0.5719899535179138
[15/24] Train loss=0.5409600138664246
[20/24] Train loss=0.5262656807899475
Test set avg_accuracy=73.11% avg_sensitivity=77.29%, avg_specificity=71.62% avg_auc=81.49%
Best model saved!! Metric=-22.490246588194452!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.554283 Test loss=0.531527 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5213111042976379
[5/24] Train loss=0.5303095579147339
[10/24] Train loss=0.5391726493835449
[15/24] Train loss=0.516660213470459
[20/24] Train loss=0.5046526193618774
Test set avg_accuracy=74.14% avg_sensitivity=77.68%, avg_specificity=72.88% avg_auc=82.82%
Best model saved!! Metric=-18.484934737266556!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.526281 Test loss=0.511543 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.49716904759407043
[5/24] Train loss=0.49778902530670166
[10/24] Train loss=0.5280817151069641
[15/24] Train loss=0.48719531297683716
[20/24] Train loss=0.4735576808452606
Test set avg_accuracy=76.00% avg_sensitivity=75.46%, avg_specificity=76.20% avg_auc=83.67%
Best model saved!! Metric=-14.667878647684375!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.501489 Test loss=0.482551 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.473907470703125
[5/24] Train loss=0.4711934030056
[10/24] Train loss=0.5087026953697205
[15/24] Train loss=0.46536314487457275
[20/24] Train loss=0.4540330469608307
Test set avg_accuracy=76.64% avg_sensitivity=76.55%, avg_specificity=76.67% avg_auc=84.56%
Best model saved!! Metric=-11.579867043299743!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.481244 Test loss=0.472831 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4561443626880646
[5/24] Train loss=0.45129454135894775
[10/24] Train loss=0.49311235547065735
[15/24] Train loss=0.4469873011112213
[20/24] Train loss=0.4310729503631592
Test set avg_accuracy=78.46% avg_sensitivity=72.69%, avg_specificity=80.53% avg_auc=84.80%
Best model saved!! Metric=-9.524486668785102!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.463328 Test loss=0.450867 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4309130012989044
[5/24] Train loss=0.42668765783309937
[10/24] Train loss=0.4714018702507019
[15/24] Train loss=0.4359916150569916
[20/24] Train loss=0.41817507147789
Test set avg_accuracy=78.80% avg_sensitivity=69.97%, avg_specificity=81.96% avg_auc=85.13%
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.446790 Test loss=0.436384 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4163314998149872
[5/24] Train loss=0.40851032733917236
[10/24] Train loss=0.4639241695404053
[15/24] Train loss=0.4191065728664398
[20/24] Train loss=0.4034495949745178
Test set avg_accuracy=79.47% avg_sensitivity=66.75%, avg_specificity=84.01% avg_auc=85.38%
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.433169 Test loss=0.426094 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4086158275604248
[5/24] Train loss=0.3950485289096832
[10/24] Train loss=0.4463343024253845
[15/24] Train loss=0.4071398079395294
[20/24] Train loss=0.39520522952079773
Test set avg_accuracy=80.23% avg_sensitivity=62.54%, avg_specificity=86.55% avg_auc=85.55%
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.422611 Test loss=0.412946 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.39644911885261536
[5/24] Train loss=0.38593918085098267
[10/24] Train loss=0.4368540942668915
[15/24] Train loss=0.39945656061172485
[20/24] Train loss=0.38328203558921814
Test set avg_accuracy=80.22% avg_sensitivity=61.50%, avg_specificity=86.91% avg_auc=85.61%
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.413564 Test loss=0.410527 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3849687874317169
[5/24] Train loss=0.3789759576320648
[10/24] Train loss=0.43377435207366943
[15/24] Train loss=0.39135825634002686
[20/24] Train loss=0.3782499432563782
Test set avg_accuracy=80.72% avg_sensitivity=61.01%, avg_specificity=87.75% avg_auc=86.00%
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.403826 Test loss=0.403661 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3768930733203888
[5/24] Train loss=0.3656412363052368
[10/24] Train loss=0.43078505992889404
[15/24] Train loss=0.38482367992401123
[20/24] Train loss=0.37159445881843567
Test set avg_accuracy=80.44% avg_sensitivity=57.20%, avg_specificity=88.74% avg_auc=85.64%
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.398353 Test loss=0.405696 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3658246099948883
[5/24] Train loss=0.36454078555107117
[10/24] Train loss=0.4218771755695343
[15/24] Train loss=0.37845996022224426
[20/24] Train loss=0.3613305985927582
Test set avg_accuracy=80.73% avg_sensitivity=62.15%, avg_specificity=87.37% avg_auc=86.33%
Best model saved!! Metric=-9.430781724667703!!
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.391710 Test loss=0.400111 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.36036860942840576
[5/24] Train loss=0.3529195189476013
[10/24] Train loss=0.42012637853622437
[15/24] Train loss=0.3713970482349396
[20/24] Train loss=0.3602144718170166
Test set avg_accuracy=80.57% avg_sensitivity=64.67%, avg_specificity=86.25% avg_auc=86.48%
Best model saved!! Metric=-8.027518645922768!!
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.386923 Test loss=0.401416 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3546420633792877
[5/24] Train loss=0.34444525837898254
[10/24] Train loss=0.411334365606308
[15/24] Train loss=0.3626925051212311
[20/24] Train loss=0.35529622435569763
Test set avg_accuracy=80.27% avg_sensitivity=69.62%, avg_specificity=84.08% avg_auc=86.65%
Best model saved!! Metric=-5.3781148214062995!!
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.382019 Test loss=0.406470 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.351570188999176
[5/24] Train loss=0.34169772267341614
[10/24] Train loss=0.4126639664173126
[15/24] Train loss=0.36167585849761963
[20/24] Train loss=0.3462539315223694
Test set avg_accuracy=79.61% avg_sensitivity=71.45%, avg_specificity=82.52% avg_auc=86.11%
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.378944 Test loss=0.420995 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.34974321722984314
[5/24] Train loss=0.3339013457298279
[10/24] Train loss=0.4102327525615692
[15/24] Train loss=0.36088743805885315
[20/24] Train loss=0.35110634565353394
Test set avg_accuracy=80.51% avg_sensitivity=68.04%, avg_specificity=84.96% avg_auc=86.01%
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.375232 Test loss=0.416134 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.34495437145233154
[5/24] Train loss=0.3322754204273224
[10/24] Train loss=0.4095689356327057
[15/24] Train loss=0.3595392405986786
[20/24] Train loss=0.34602490067481995
Test set avg_accuracy=76.71% avg_sensitivity=74.17%, avg_specificity=77.61% avg_auc=83.98%
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.372036 Test loss=0.480404 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.34391242265701294
[5/24] Train loss=0.330702543258667
[10/24] Train loss=0.4003273546695709
[15/24] Train loss=0.3521686792373657
[20/24] Train loss=0.34296533465385437
Test set avg_accuracy=81.28% avg_sensitivity=64.82%, avg_specificity=87.15% avg_auc=86.51%
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.369724 Test loss=0.404497 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3440455198287964
[5/24] Train loss=0.3276115655899048
[10/24] Train loss=0.4008532166481018
[15/24] Train loss=0.34974220395088196
[20/24] Train loss=0.3425324261188507
Test set avg_accuracy=77.55% avg_sensitivity=70.81%, avg_specificity=79.96% avg_auc=84.07%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.366567 Test loss=0.459888 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3387278616428375
[5/24] Train loss=0.32329216599464417
[10/24] Train loss=0.4056299328804016
[15/24] Train loss=0.35227376222610474
[20/24] Train loss=0.3340833783149719
Test set avg_accuracy=80.48% avg_sensitivity=62.39%, avg_specificity=86.94% avg_auc=85.87%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.365066 Test loss=0.415943 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.34366661310195923
[5/24] Train loss=0.3232021927833557
[10/24] Train loss=0.3992377817630768
[15/24] Train loss=0.3445037603378296
[20/24] Train loss=0.33473697304725647
Test set avg_accuracy=74.30% avg_sensitivity=73.68%, avg_specificity=74.52% avg_auc=82.06%
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.363964 Test loss=0.499253 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3376418650150299
[5/24] Train loss=0.3212066888809204
[10/24] Train loss=0.40834617614746094
[15/24] Train loss=0.34425103664398193
[20/24] Train loss=0.3345949947834015
Test set avg_accuracy=67.01% avg_sensitivity=76.74%, avg_specificity=63.53% avg_auc=78.16%
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.362928 Test loss=0.579368 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.34164106845855713
[5/24] Train loss=0.32422497868537903
[10/24] Train loss=0.40778449177742004
[15/24] Train loss=0.34234845638275146
[20/24] Train loss=0.3407343029975891
Test set avg_accuracy=66.74% avg_sensitivity=75.06%, avg_specificity=63.77% avg_auc=77.02%
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.361606 Test loss=0.586391 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.33526137471199036
[5/24] Train loss=0.32077446579933167
[10/24] Train loss=0.4086386263370514
[15/24] Train loss=0.336652010679245
[20/24] Train loss=0.33218511939048767
Test set avg_accuracy=77.33% avg_sensitivity=72.98%, avg_specificity=78.88% avg_auc=83.71%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.359814 Test loss=0.467027 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.32399582862854004
[5/24] Train loss=0.31742745637893677
[10/24] Train loss=0.39739418029785156
[15/24] Train loss=0.3405669927597046
[20/24] Train loss=0.33758974075317383
Test set avg_accuracy=78.15% avg_sensitivity=63.58%, avg_specificity=83.35% avg_auc=82.98%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.357008 Test loss=0.446871 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.332096666097641
[5/24] Train loss=0.31332579255104065
[10/24] Train loss=0.40103060007095337
[15/24] Train loss=0.3422320783138275
[20/24] Train loss=0.3348533511161804
Test set avg_accuracy=75.96% avg_sensitivity=67.74%, avg_specificity=78.90% avg_auc=81.73%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.357550 Test loss=0.477526 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.32842573523521423
[5/24] Train loss=0.3208235204219818
[10/24] Train loss=0.39412227272987366
[15/24] Train loss=0.33610567450523376
[20/24] Train loss=0.3298225700855255
Test set avg_accuracy=81.09% avg_sensitivity=61.26%, avg_specificity=88.18% avg_auc=86.38%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.354713 Test loss=0.399262 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3271249532699585
[5/24] Train loss=0.3166922330856323
[10/24] Train loss=0.3900097608566284
[15/24] Train loss=0.3402676582336426
[20/24] Train loss=0.33344507217407227
Test set avg_accuracy=80.46% avg_sensitivity=49.53%, avg_specificity=91.50% avg_auc=84.31%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.353122 Test loss=0.419262 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.33378660678863525
[5/24] Train loss=0.31630250811576843
[10/24] Train loss=0.3940334618091583
[15/24] Train loss=0.3405913710594177
[20/24] Train loss=0.3333512246608734
Test set avg_accuracy=73.15% avg_sensitivity=68.04%, avg_specificity=74.98% avg_auc=79.11%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.357911 Test loss=0.519711 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.32691606879234314
[5/24] Train loss=0.31584301590919495
[10/24] Train loss=0.38543492555618286
[15/24] Train loss=0.34417498111724854
[20/24] Train loss=0.33419573307037354
Test set avg_accuracy=79.91% avg_sensitivity=48.29%, avg_specificity=91.20% avg_auc=84.99%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.351642 Test loss=0.422568 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3208082318305969
[5/24] Train loss=0.315460741519928
[10/24] Train loss=0.38432765007019043
[15/24] Train loss=0.3408389985561371
[20/24] Train loss=0.33027029037475586
Test set avg_accuracy=79.14% avg_sensitivity=47.40%, avg_specificity=90.48% avg_auc=82.98%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.352678 Test loss=0.431976 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3288411498069763
[5/24] Train loss=0.3147122859954834
[10/24] Train loss=0.3758445978164673
[15/24] Train loss=0.33716142177581787
[20/24] Train loss=0.324916273355484
Test set avg_accuracy=80.25% avg_sensitivity=52.05%, avg_specificity=90.32% avg_auc=84.51%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.349004 Test loss=0.417035 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3284514844417572
[5/24] Train loss=0.3176904320716858
[10/24] Train loss=0.3898191750049591
[15/24] Train loss=0.33309391140937805
[20/24] Train loss=0.32234084606170654
Test set avg_accuracy=80.51% avg_sensitivity=46.66%, avg_specificity=92.60% avg_auc=85.72%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.351838 Test loss=0.403750 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.32116347551345825
[5/24] Train loss=0.31535813212394714
[10/24] Train loss=0.3856580853462219
[15/24] Train loss=0.3302500247955322
[20/24] Train loss=0.3395250141620636
Test set avg_accuracy=78.91% avg_sensitivity=36.71%, avg_specificity=93.97% avg_auc=83.81%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.351271 Test loss=0.425911 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.31931784749031067
[5/24] Train loss=0.3198961913585663
[10/24] Train loss=0.38601425290107727
[15/24] Train loss=0.3353789746761322
[20/24] Train loss=0.3226901888847351
Test set avg_accuracy=78.10% avg_sensitivity=29.94%, avg_specificity=95.30% avg_auc=85.42%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.349255 Test loss=0.416599 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3243061900138855
[5/24] Train loss=0.3098806142807007
[10/24] Train loss=0.3802946209907532
[15/24] Train loss=0.3399254083633423
[20/24] Train loss=0.32293492555618286
Test set avg_accuracy=79.26% avg_sensitivity=44.43%, avg_specificity=91.69% avg_auc=84.02%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.346230 Test loss=0.427397 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.32162368297576904
[5/24] Train loss=0.3008456826210022
[10/24] Train loss=0.3732644319534302
[15/24] Train loss=0.33100011944770813
[20/24] Train loss=0.3246053159236908
Test set avg_accuracy=76.84% avg_sensitivity=28.06%, avg_specificity=94.26% avg_auc=80.75%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.345977 Test loss=0.455086 Current lr=[0.00029967723776099]

[0/24] Train loss=0.32244932651519775
[5/24] Train loss=0.3070893883705139
[10/24] Train loss=0.3824484348297119
[15/24] Train loss=0.33707308769226074
[20/24] Train loss=0.3248683512210846
Test set avg_accuracy=79.87% avg_sensitivity=60.42%, avg_specificity=86.82% avg_auc=83.63%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.348296 Test loss=0.447040 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3243895471096039
[5/24] Train loss=0.31500154733657837
[10/24] Train loss=0.38841375708580017
[15/24] Train loss=0.328984797000885
[20/24] Train loss=0.32489797472953796
Test set avg_accuracy=80.38% avg_sensitivity=64.32%, avg_specificity=86.11% avg_auc=85.74%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.347721 Test loss=0.423512 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.31815704703330994
[5/24] Train loss=0.30993565917015076
[10/24] Train loss=0.3775273859500885
[15/24] Train loss=0.3215978145599365
[20/24] Train loss=0.3176968991756439
Test set avg_accuracy=74.83% avg_sensitivity=66.16%, avg_specificity=77.93% avg_auc=79.29%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.346032 Test loss=0.535195 Current lr=[0.000299720220882401]

[0/24] Train loss=0.32664477825164795
[5/24] Train loss=0.3060969114303589
[10/24] Train loss=0.38231539726257324
[15/24] Train loss=0.32685160636901855
[20/24] Train loss=0.32001280784606934
Test set avg_accuracy=81.22% avg_sensitivity=58.63%, avg_specificity=89.29% avg_auc=84.47%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.344359 Test loss=0.422334 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.31893637776374817
[5/24] Train loss=0.31244415044784546
[10/24] Train loss=0.3756524622440338
[15/24] Train loss=0.32674938440322876
[20/24] Train loss=0.32720494270324707
Test set avg_accuracy=81.22% avg_sensitivity=51.66%, avg_specificity=91.78% avg_auc=86.68%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.343380 Test loss=0.396394 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3127787411212921
[5/24] Train loss=0.3056931793689728
[10/24] Train loss=0.37617480754852295
[15/24] Train loss=0.32379576563835144
[20/24] Train loss=0.31686079502105713
Test set avg_accuracy=80.52% avg_sensitivity=60.81%, avg_specificity=87.56% avg_auc=86.08%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.342011 Test loss=0.408665 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.31203576922416687
[5/24] Train loss=0.3038928508758545
[10/24] Train loss=0.3695290982723236
[15/24] Train loss=0.3192056119441986
[20/24] Train loss=0.3189759850502014
Test set avg_accuracy=79.93% avg_sensitivity=49.28%, avg_specificity=90.88% avg_auc=84.37%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.339195 Test loss=0.424137 Current lr=[0.000297555943323901]

[0/24] Train loss=0.31851962208747864
[5/24] Train loss=0.3056517243385315
[10/24] Train loss=0.36339783668518066
[15/24] Train loss=0.3235064148902893
[20/24] Train loss=0.3166998326778412
Test set avg_accuracy=78.41% avg_sensitivity=31.87%, avg_specificity=95.03% avg_auc=83.58%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.339309 Test loss=0.438126 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3204993009567261
[5/24] Train loss=0.3092022240161896
[10/24] Train loss=0.36857762932777405
[15/24] Train loss=0.3163219392299652
[20/24] Train loss=0.32598400115966797
Test set avg_accuracy=79.41% avg_sensitivity=45.13%, avg_specificity=91.66% avg_auc=84.53%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.342618 Test loss=0.423961 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3039087951183319
[5/24] Train loss=0.3020123839378357
[10/24] Train loss=0.36456888914108276
[15/24] Train loss=0.3195759654045105
[20/24] Train loss=0.31749045848846436
Test set avg_accuracy=78.72% avg_sensitivity=40.52%, avg_specificity=92.37% avg_auc=82.82%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.337162 Test loss=0.441458 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.31345587968826294
[5/24] Train loss=0.3077987730503082
[10/24] Train loss=0.38017022609710693
[15/24] Train loss=0.31206169724464417
[20/24] Train loss=0.31920114159584045
Test set avg_accuracy=79.45% avg_sensitivity=38.45%, avg_specificity=94.10% avg_auc=85.76%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.340743 Test loss=0.412284 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3137105405330658
[5/24] Train loss=0.30249589681625366
[10/24] Train loss=0.3603331446647644
[15/24] Train loss=0.3135850131511688
[20/24] Train loss=0.3136996030807495
Test set avg_accuracy=79.62% avg_sensitivity=41.32%, avg_specificity=93.30% avg_auc=84.41%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.339241 Test loss=0.423774 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3052774965763092
[5/24] Train loss=0.30147427320480347
[10/24] Train loss=0.37289753556251526
[15/24] Train loss=0.3104407787322998
[20/24] Train loss=0.31642836332321167
Test set avg_accuracy=79.96% avg_sensitivity=44.88%, avg_specificity=92.49% avg_auc=84.68%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.337330 Test loss=0.418191 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.308391273021698
[5/24] Train loss=0.2989708483219147
[10/24] Train loss=0.37104859948158264
[15/24] Train loss=0.3141704797744751
[20/24] Train loss=0.31692537665367126
Test set avg_accuracy=79.54% avg_sensitivity=44.63%, avg_specificity=92.01% avg_auc=80.03%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.334901 Test loss=0.453296 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.31966567039489746
[5/24] Train loss=0.3003374934196472
[10/24] Train loss=0.351502001285553
[15/24] Train loss=0.3133613169193268
[20/24] Train loss=0.31156209111213684
Test set avg_accuracy=75.20% avg_sensitivity=67.44%, avg_specificity=77.96% avg_auc=80.31%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.333491 Test loss=0.506857 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3112317621707916
[5/24] Train loss=0.30752265453338623
[10/24] Train loss=0.36385759711265564
[15/24] Train loss=0.3061883747577667
[20/24] Train loss=0.31460878252983093
Test set avg_accuracy=79.99% avg_sensitivity=58.44%, avg_specificity=87.68% avg_auc=83.69%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.335284 Test loss=0.429210 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.30075332522392273
[5/24] Train loss=0.3068826198577881
[10/24] Train loss=0.3545137643814087
[15/24] Train loss=0.3079264163970947
[20/24] Train loss=0.321045458316803
Test set avg_accuracy=80.16% avg_sensitivity=47.85%, avg_specificity=91.69% avg_auc=83.98%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.332926 Test loss=0.425426 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3065189719200134
[5/24] Train loss=0.2989646792411804
[10/24] Train loss=0.36264973878860474
[15/24] Train loss=0.30893099308013916
[20/24] Train loss=0.3169492781162262
Test set avg_accuracy=80.72% avg_sensitivity=59.87%, avg_specificity=88.16% avg_auc=85.04%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.331846 Test loss=0.412666 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.29564082622528076
[5/24] Train loss=0.3016919791698456
[10/24] Train loss=0.3606266975402832
[15/24] Train loss=0.3147182762622833
[20/24] Train loss=0.31454208493232727
Test set avg_accuracy=78.12% avg_sensitivity=32.46%, avg_specificity=94.43% avg_auc=83.57%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.334397 Test loss=0.432522 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3001028299331665
[5/24] Train loss=0.30208805203437805
[10/24] Train loss=0.36369091272354126
[15/24] Train loss=0.30382010340690613
[20/24] Train loss=0.30690798163414
Test set avg_accuracy=79.61% avg_sensitivity=39.24%, avg_specificity=94.03% avg_auc=81.90%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.329539 Test loss=0.440358 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2984845042228699
[5/24] Train loss=0.29639938473701477
[10/24] Train loss=0.36143583059310913
[15/24] Train loss=0.3112988770008087
[20/24] Train loss=0.3143453896045685
Test set avg_accuracy=80.04% avg_sensitivity=61.85%, avg_specificity=86.53% avg_auc=84.70%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.332689 Test loss=0.426762 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.30836188793182373
[5/24] Train loss=0.29591861367225647
[10/24] Train loss=0.35335689783096313
[15/24] Train loss=0.30856719613075256
[20/24] Train loss=0.3152696192264557
Test set avg_accuracy=80.82% avg_sensitivity=56.16%, avg_specificity=89.63% avg_auc=86.24%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.332119 Test loss=0.398762 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.29855626821517944
[5/24] Train loss=0.2945985198020935
[10/24] Train loss=0.3669910728931427
[15/24] Train loss=0.30351701378822327
[20/24] Train loss=0.30577388405799866
Test set avg_accuracy=78.36% avg_sensitivity=46.71%, avg_specificity=89.66% avg_auc=79.43%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.331693 Test loss=0.465394 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2978862226009369
[5/24] Train loss=0.2905600965023041
[10/24] Train loss=0.35434311628341675
[15/24] Train loss=0.2968937158584595
[20/24] Train loss=0.3132729232311249
Test set avg_accuracy=79.08% avg_sensitivity=46.46%, avg_specificity=90.72% avg_auc=84.46%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.327305 Test loss=0.418420 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.29171672463417053
[5/24] Train loss=0.29227423667907715
[10/24] Train loss=0.3542291224002838
[15/24] Train loss=0.30215898156166077
[20/24] Train loss=0.30526381731033325
Test set avg_accuracy=79.47% avg_sensitivity=67.94%, avg_specificity=83.58% avg_auc=85.17%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.323418 Test loss=0.432461 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2934320271015167
[5/24] Train loss=0.29434624314308167
[10/24] Train loss=0.36059609055519104
[15/24] Train loss=0.29958415031433105
[20/24] Train loss=0.3112085461616516
Test set avg_accuracy=80.18% avg_sensitivity=58.09%, avg_specificity=88.07% avg_auc=85.62%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.325763 Test loss=0.407779 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.29411470890045166
[5/24] Train loss=0.28903061151504517
[10/24] Train loss=0.3517354428768158
[15/24] Train loss=0.29003870487213135
[20/24] Train loss=0.30611154437065125
Test set avg_accuracy=80.64% avg_sensitivity=50.42%, avg_specificity=91.43% avg_auc=84.92%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.324198 Test loss=0.416224 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.29477158188819885
[5/24] Train loss=0.2837110757827759
[10/24] Train loss=0.3615961968898773
[15/24] Train loss=0.30663302540779114
[20/24] Train loss=0.3086654245853424
Test set avg_accuracy=80.23% avg_sensitivity=50.82%, avg_specificity=90.74% avg_auc=85.52%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.322941 Test loss=0.407166 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2972637116909027
[5/24] Train loss=0.28041428327560425
[10/24] Train loss=0.33740800619125366
[15/24] Train loss=0.3003210723400116
[20/24] Train loss=0.30185309052467346
Test set avg_accuracy=79.78% avg_sensitivity=43.54%, avg_specificity=92.72% avg_auc=84.20%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.318267 Test loss=0.422398 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.29393908381462097
[5/24] Train loss=0.27923449873924255
[10/24] Train loss=0.3418307602405548
[15/24] Train loss=0.29666104912757874
[20/24] Train loss=0.2987957298755646
Test set avg_accuracy=80.29% avg_sensitivity=53.79%, avg_specificity=89.75% avg_auc=85.37%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.315887 Test loss=0.408483 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.28773370385169983
[5/24] Train loss=0.27940309047698975
[10/24] Train loss=0.3394516110420227
[15/24] Train loss=0.29328373074531555
[20/24] Train loss=0.31299710273742676
Test set avg_accuracy=79.70% avg_sensitivity=56.66%, avg_specificity=87.93% avg_auc=85.07%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.319365 Test loss=0.414978 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.292405903339386
[5/24] Train loss=0.27478963136672974
[10/24] Train loss=0.34098634123802185
[15/24] Train loss=0.29212355613708496
[20/24] Train loss=0.3078716993331909
Test set avg_accuracy=81.00% avg_sensitivity=55.57%, avg_specificity=90.09% avg_auc=85.74%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.315544 Test loss=0.405395 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2896817624568939
[5/24] Train loss=0.28139397501945496
[10/24] Train loss=0.32714977860450745
[15/24] Train loss=0.28655532002449036
[20/24] Train loss=0.306938499212265
Test set avg_accuracy=78.71% avg_sensitivity=40.23%, avg_specificity=92.45% avg_auc=80.08%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.312930 Test loss=0.456714 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.28736791014671326
[5/24] Train loss=0.2829345166683197
[10/24] Train loss=0.33951494097709656
[15/24] Train loss=0.30589479207992554
[20/24] Train loss=0.3022778332233429
Test set avg_accuracy=78.85% avg_sensitivity=35.48%, avg_specificity=94.35% avg_auc=82.06%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.316926 Test loss=0.447610 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.28759023547172546
[5/24] Train loss=0.27620723843574524
[10/24] Train loss=0.3395792543888092
[15/24] Train loss=0.28786367177963257
[20/24] Train loss=0.31007203459739685
Test set avg_accuracy=79.27% avg_sensitivity=44.19%, avg_specificity=91.80% avg_auc=81.00%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.314701 Test loss=0.448518 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2842734754085541
[5/24] Train loss=0.27145472168922424
[10/24] Train loss=0.3303583860397339
[15/24] Train loss=0.28763359785079956
[20/24] Train loss=0.30229973793029785
Test set avg_accuracy=79.67% avg_sensitivity=49.88%, avg_specificity=90.32% avg_auc=82.49%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.311669 Test loss=0.441978 Current lr=[0.000224838296036774]

[0/24] Train loss=0.28881391882896423
[5/24] Train loss=0.27914953231811523
[10/24] Train loss=0.33494532108306885
[15/24] Train loss=0.29411107301712036
[20/24] Train loss=0.3028913140296936
Test set avg_accuracy=80.10% avg_sensitivity=56.11%, avg_specificity=88.67% avg_auc=82.39%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.313496 Test loss=0.440607 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.28363147377967834
[5/24] Train loss=0.2754006087779999
[10/24] Train loss=0.34104108810424805
[15/24] Train loss=0.290321946144104
[20/24] Train loss=0.29776132106781006
Test set avg_accuracy=79.04% avg_sensitivity=66.40%, avg_specificity=83.55% avg_auc=85.54%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.311232 Test loss=0.424434 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.28048238158226013
[5/24] Train loss=0.278228759765625
[10/24] Train loss=0.33550015091896057
[15/24] Train loss=0.3029530644416809
[20/24] Train loss=0.303317129611969
Test set avg_accuracy=79.92% avg_sensitivity=58.63%, avg_specificity=87.52% avg_auc=84.93%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.310366 Test loss=0.416176 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.28498122096061707
[5/24] Train loss=0.2599508464336395
[10/24] Train loss=0.32638415694236755
[15/24] Train loss=0.2913733422756195
[20/24] Train loss=0.3069121837615967
Test set avg_accuracy=80.34% avg_sensitivity=41.22%, avg_specificity=94.31% avg_auc=84.42%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.309176 Test loss=0.426315 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.28131794929504395
[5/24] Train loss=0.2706480622291565
[10/24] Train loss=0.32714933156967163
[15/24] Train loss=0.2839428782463074
[20/24] Train loss=0.30142727494239807
Test set avg_accuracy=79.67% avg_sensitivity=51.21%, avg_specificity=89.84% avg_auc=84.23%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.306388 Test loss=0.434299 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2786950170993805
[5/24] Train loss=0.26781007647514343
[10/24] Train loss=0.32149627804756165
[15/24] Train loss=0.28940320014953613
[20/24] Train loss=0.3075683116912842
Test set avg_accuracy=77.93% avg_sensitivity=37.06%, avg_specificity=92.53% avg_auc=82.03%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.309311 Test loss=0.464234 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2730480432510376
[5/24] Train loss=0.26153865456581116
[10/24] Train loss=0.3223024606704712
[15/24] Train loss=0.2841203808784485
[20/24] Train loss=0.30287784337997437
Test set avg_accuracy=79.90% avg_sensitivity=41.96%, avg_specificity=93.44% avg_auc=83.71%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.306396 Test loss=0.432234 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.281250536441803
[5/24] Train loss=0.2729671001434326
[10/24] Train loss=0.31075435876846313
[15/24] Train loss=0.28394389152526855
[20/24] Train loss=0.28901317715644836
Test set avg_accuracy=80.79% avg_sensitivity=61.21%, avg_specificity=87.79% avg_auc=86.19%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.302635 Test loss=0.404327 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2845304012298584
[5/24] Train loss=0.2612147331237793
[10/24] Train loss=0.3187881112098694
[15/24] Train loss=0.2870999276638031
[20/24] Train loss=0.29772576689720154
Test set avg_accuracy=79.66% avg_sensitivity=55.52%, avg_specificity=88.28% avg_auc=84.63%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.302026 Test loss=0.424081 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2711712121963501
[5/24] Train loss=0.26068487763404846
[10/24] Train loss=0.31081622838974
[15/24] Train loss=0.2808414697647095
[20/24] Train loss=0.3047502040863037
Test set avg_accuracy=77.68% avg_sensitivity=49.88%, avg_specificity=87.61% avg_auc=82.29%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.301126 Test loss=0.444908 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2759266495704651
[5/24] Train loss=0.25970885157585144
[10/24] Train loss=0.31313204765319824
[15/24] Train loss=0.28652745485305786
[20/24] Train loss=0.2979181408882141
Test set avg_accuracy=79.44% avg_sensitivity=61.65%, avg_specificity=85.79% avg_auc=85.68%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.300177 Test loss=0.409268 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.276596337556839
[5/24] Train loss=0.2651059031486511
[10/24] Train loss=0.30485740303993225
[15/24] Train loss=0.2835966944694519
[20/24] Train loss=0.2904815077781677
Test set avg_accuracy=79.43% avg_sensitivity=69.27%, avg_specificity=83.05% avg_auc=85.51%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.297041 Test loss=0.430235 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.265337198972702
[5/24] Train loss=0.25182056427001953
[10/24] Train loss=0.29408493638038635
[15/24] Train loss=0.28815627098083496
[20/24] Train loss=0.2927292585372925
Test set avg_accuracy=79.99% avg_sensitivity=57.10%, avg_specificity=88.16% avg_auc=85.53%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.290400 Test loss=0.414844 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2635955512523651
[5/24] Train loss=0.25884270668029785
[10/24] Train loss=0.29733890295028687
[15/24] Train loss=0.2719760835170746
[20/24] Train loss=0.28546398878097534
Test set avg_accuracy=80.13% avg_sensitivity=56.36%, avg_specificity=88.62% avg_auc=86.13%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.291204 Test loss=0.399284 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2637510597705841
[5/24] Train loss=0.24502712488174438
[10/24] Train loss=0.30942779779434204
[15/24] Train loss=0.2752065360546112
[20/24] Train loss=0.28609535098075867
Test set avg_accuracy=77.19% avg_sensitivity=34.19%, avg_specificity=92.54% avg_auc=80.25%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.289778 Test loss=0.491613 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.26775437593460083
[5/24] Train loss=0.24157603085041046
[10/24] Train loss=0.3048844039440155
[15/24] Train loss=0.28106698393821716
[20/24] Train loss=0.28481408953666687
Test set avg_accuracy=80.39% avg_sensitivity=50.72%, avg_specificity=90.99% avg_auc=84.41%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.286902 Test loss=0.424711 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2614439129829407
[5/24] Train loss=0.2525199055671692
[10/24] Train loss=0.28279557824134827
[15/24] Train loss=0.27452823519706726
[20/24] Train loss=0.2851956784725189
Test set avg_accuracy=79.14% avg_sensitivity=48.05%, avg_specificity=90.25% avg_auc=82.36%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.284219 Test loss=0.442922 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2575131356716156
[5/24] Train loss=0.24666081368923187
[10/24] Train loss=0.27576470375061035
[15/24] Train loss=0.2736348509788513
[20/24] Train loss=0.27563416957855225
Test set avg_accuracy=77.57% avg_sensitivity=39.04%, avg_specificity=91.32% avg_auc=80.24%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.279365 Test loss=0.487303 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2570904493331909
[5/24] Train loss=0.25087130069732666
[10/24] Train loss=0.28640466928482056
[15/24] Train loss=0.2695014178752899
[20/24] Train loss=0.2836299538612366
Test set avg_accuracy=78.88% avg_sensitivity=44.83%, avg_specificity=91.04% avg_auc=82.19%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.278197 Test loss=0.454103 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.26010042428970337
[5/24] Train loss=0.24369458854198456
[10/24] Train loss=0.26277169585227966
[15/24] Train loss=0.25709640979766846
[20/24] Train loss=0.28003203868865967
Test set avg_accuracy=79.32% avg_sensitivity=49.43%, avg_specificity=90.00% avg_auc=81.98%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.273798 Test loss=0.446483 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.24863117933273315
[5/24] Train loss=0.2472262680530548
[10/24] Train loss=0.2697783410549164
[15/24] Train loss=0.2607032060623169
[20/24] Train loss=0.27637210488319397
Test set avg_accuracy=78.93% avg_sensitivity=38.15%, avg_specificity=93.50% avg_auc=79.69%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.271456 Test loss=0.485222 Current lr=[0.000134135431043539]

[0/24] Train loss=0.2468818724155426
[5/24] Train loss=0.24343249201774597
[10/24] Train loss=0.28143349289894104
[15/24] Train loss=0.25597310066223145
[20/24] Train loss=0.27788013219833374
Test set avg_accuracy=77.96% avg_sensitivity=33.94%, avg_specificity=93.67% avg_auc=76.04%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.272782 Test loss=0.506420 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.24695423245429993
[5/24] Train loss=0.24403414130210876
[10/24] Train loss=0.26487791538238525
[15/24] Train loss=0.26142093539237976
[20/24] Train loss=0.27484411001205444
Test set avg_accuracy=77.47% avg_sensitivity=38.64%, avg_specificity=91.34% avg_auc=80.43%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.270255 Test loss=0.482178 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2513854205608368
[5/24] Train loss=0.23737694323062897
[10/24] Train loss=0.2788328230381012
[15/24] Train loss=0.2479258030653
[20/24] Train loss=0.2714890241622925
Test set avg_accuracy=78.53% avg_sensitivity=48.64%, avg_specificity=89.20% avg_auc=81.11%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.268135 Test loss=0.463593 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.24368742108345032
[5/24] Train loss=0.23302875459194183
[10/24] Train loss=0.2687090039253235
[15/24] Train loss=0.25796958804130554
[20/24] Train loss=0.2758330702781677
Test set avg_accuracy=77.66% avg_sensitivity=35.43%, avg_specificity=92.74% avg_auc=79.80%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.268039 Test loss=0.493155 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.24094648659229279
[5/24] Train loss=0.2444768100976944
[10/24] Train loss=0.2629148066043854
[15/24] Train loss=0.25649505853652954
[20/24] Train loss=0.26900923252105713
Test set avg_accuracy=79.08% avg_sensitivity=46.71%, avg_specificity=90.63% avg_auc=83.36%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.266179 Test loss=0.438642 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.23733016848564148
[5/24] Train loss=0.2411390095949173
[10/24] Train loss=0.27408161759376526
[15/24] Train loss=0.24761973321437836
[20/24] Train loss=0.26221030950546265
Test set avg_accuracy=78.80% avg_sensitivity=58.19%, avg_specificity=86.16% avg_auc=83.28%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.262848 Test loss=0.445198 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.2348618358373642
[5/24] Train loss=0.24206925928592682
[10/24] Train loss=0.2621418237686157
[15/24] Train loss=0.2548818290233612
[20/24] Train loss=0.2666405737400055
Test set avg_accuracy=79.49% avg_sensitivity=54.68%, avg_specificity=88.35% avg_auc=84.19%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.262521 Test loss=0.432172 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.24120977520942688
[5/24] Train loss=0.21694013476371765
[10/24] Train loss=0.2622794210910797
[15/24] Train loss=0.24090838432312012
[20/24] Train loss=0.2651212215423584
Test set avg_accuracy=79.70% avg_sensitivity=58.44%, avg_specificity=87.29% avg_auc=83.88%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.259016 Test loss=0.438987 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.2372836321592331
[5/24] Train loss=0.22855406999588013
[10/24] Train loss=0.25880861282348633
[15/24] Train loss=0.24304772913455963
[20/24] Train loss=0.2604166865348816
Test set avg_accuracy=79.69% avg_sensitivity=58.44%, avg_specificity=87.28% avg_auc=83.97%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.255492 Test loss=0.438662 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.23880785703659058
[5/24] Train loss=0.21753647923469543
[10/24] Train loss=0.24668915569782257
[15/24] Train loss=0.24018265306949615
[20/24] Train loss=0.2543392479419708
Test set avg_accuracy=80.82% avg_sensitivity=56.61%, avg_specificity=89.47% avg_auc=84.10%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.251902 Test loss=0.435893 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.22535325586795807
[5/24] Train loss=0.21810244023799896
[10/24] Train loss=0.25027960538864136
[15/24] Train loss=0.23017148673534393
[20/24] Train loss=0.25803273916244507
Test set avg_accuracy=79.96% avg_sensitivity=58.98%, avg_specificity=87.45% avg_auc=84.31%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.248325 Test loss=0.433171 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.2211446911096573
[5/24] Train loss=0.22185181081295013
[10/24] Train loss=0.24598729610443115
[15/24] Train loss=0.23556411266326904
[20/24] Train loss=0.2577635943889618
Test set avg_accuracy=79.45% avg_sensitivity=53.69%, avg_specificity=88.66% avg_auc=82.03%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.245514 Test loss=0.456285 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.23109674453735352
[5/24] Train loss=0.22480443120002747
[10/24] Train loss=0.23967839777469635
[15/24] Train loss=0.24043326079845428
[20/24] Train loss=0.2532712519168854
Test set avg_accuracy=79.91% avg_sensitivity=64.18%, avg_specificity=85.53% avg_auc=84.86%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.244783 Test loss=0.427432 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.22822745144367218
[5/24] Train loss=0.21028707921504974
[10/24] Train loss=0.245042622089386
[15/24] Train loss=0.22976626455783844
[20/24] Train loss=0.2462034374475479
Test set avg_accuracy=79.28% avg_sensitivity=58.58%, avg_specificity=86.68% avg_auc=83.83%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.241270 Test loss=0.440254 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.2210920751094818
[5/24] Train loss=0.20990590751171112
[10/24] Train loss=0.25351881980895996
[15/24] Train loss=0.22402796149253845
[20/24] Train loss=0.24641764163970947
Test set avg_accuracy=79.15% avg_sensitivity=61.95%, avg_specificity=85.30% avg_auc=84.44%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.238441 Test loss=0.437703 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.2262546718120575
[5/24] Train loss=0.21115891635417938
[10/24] Train loss=0.23738977313041687
[15/24] Train loss=0.22210955619812012
[20/24] Train loss=0.24677282571792603
Test set avg_accuracy=78.83% avg_sensitivity=68.48%, avg_specificity=82.52% avg_auc=84.02%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.236442 Test loss=0.454675 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.2207992970943451
[5/24] Train loss=0.20308594405651093
[10/24] Train loss=0.23297934234142303
[15/24] Train loss=0.22570213675498962
[20/24] Train loss=0.24002206325531006
Test set avg_accuracy=80.00% avg_sensitivity=64.57%, avg_specificity=85.51% avg_auc=82.92%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.232937 Test loss=0.453557 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.20880663394927979
[5/24] Train loss=0.2059582620859146
[10/24] Train loss=0.23938703536987305
[15/24] Train loss=0.22403034567832947
[20/24] Train loss=0.23567913472652435
Test set avg_accuracy=79.86% avg_sensitivity=60.47%, avg_specificity=86.78% avg_auc=84.00%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.230253 Test loss=0.440701 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.21128025650978088
[5/24] Train loss=0.20159800350666046
[10/24] Train loss=0.22989331185817719
[15/24] Train loss=0.21995103359222412
[20/24] Train loss=0.23299407958984375
Test set avg_accuracy=79.05% avg_sensitivity=51.56%, avg_specificity=88.87% avg_auc=81.68%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.227151 Test loss=0.465427 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.212143212556839
[5/24] Train loss=0.19811506569385529
[10/24] Train loss=0.23249037563800812
[15/24] Train loss=0.21696875989437103
[20/24] Train loss=0.230920672416687
Test set avg_accuracy=80.61% avg_sensitivity=58.63%, avg_specificity=88.46% avg_auc=84.40%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.223670 Test loss=0.436568 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1980465054512024
[5/24] Train loss=0.20257258415222168
[10/24] Train loss=0.21809089183807373
[15/24] Train loss=0.21194805204868317
[20/24] Train loss=0.22620928287506104
Test set avg_accuracy=80.13% avg_sensitivity=57.60%, avg_specificity=88.18% avg_auc=84.05%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.221871 Test loss=0.437110 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.20351694524288177
[5/24] Train loss=0.20008496940135956
[10/24] Train loss=0.22274470329284668
[15/24] Train loss=0.21273115277290344
[20/24] Train loss=0.23057939112186432
Test set avg_accuracy=79.90% avg_sensitivity=56.36%, avg_specificity=88.30% avg_auc=84.38%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.219683 Test loss=0.430236 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1956901103258133
[5/24] Train loss=0.2002808302640915
[10/24] Train loss=0.21707019209861755
[15/24] Train loss=0.21063996851444244
[20/24] Train loss=0.2259272038936615
Test set avg_accuracy=79.93% avg_sensitivity=57.45%, avg_specificity=87.97% avg_auc=84.76%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.217880 Test loss=0.432338 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1981673389673233
[5/24] Train loss=0.19589729607105255
[10/24] Train loss=0.21571777760982513
[15/24] Train loss=0.2089853286743164
[20/24] Train loss=0.2231329083442688
Test set avg_accuracy=79.54% avg_sensitivity=59.57%, avg_specificity=86.68% avg_auc=84.50%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.216290 Test loss=0.437157 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.19449235498905182
[5/24] Train loss=0.1870911419391632
[10/24] Train loss=0.21213430166244507
[15/24] Train loss=0.2057471126317978
[20/24] Train loss=0.21637603640556335
Test set avg_accuracy=79.26% avg_sensitivity=56.80%, avg_specificity=87.28% avg_auc=82.99%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.212594 Test loss=0.457857 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.19421763718128204
[5/24] Train loss=0.1954808086156845
[10/24] Train loss=0.21264605224132538
[15/24] Train loss=0.20505231618881226
[20/24] Train loss=0.2173682004213333
Test set avg_accuracy=79.04% avg_sensitivity=60.42%, avg_specificity=85.69% avg_auc=84.42%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.210422 Test loss=0.443231 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1849011778831482
[5/24] Train loss=0.1856442093849182
[10/24] Train loss=0.21059344708919525
[15/24] Train loss=0.2001151442527771
[20/24] Train loss=0.21475951373577118
Test set avg_accuracy=79.47% avg_sensitivity=61.80%, avg_specificity=85.77% avg_auc=84.68%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.209685 Test loss=0.439228 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1899465173482895
[5/24] Train loss=0.18677718937397003
[10/24] Train loss=0.20866884291172028
[15/24] Train loss=0.20114096999168396
[20/24] Train loss=0.210529625415802
Test set avg_accuracy=80.49% avg_sensitivity=60.96%, avg_specificity=87.47% avg_auc=85.19%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.206126 Test loss=0.429088 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.18906202912330627
[5/24] Train loss=0.1841978132724762
[10/24] Train loss=0.20247432589530945
[15/24] Train loss=0.19473852217197418
[20/24] Train loss=0.2136664241552353
Test set avg_accuracy=80.26% avg_sensitivity=62.89%, avg_specificity=86.46% avg_auc=84.79%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.204916 Test loss=0.436022 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.18686321377754211
[5/24] Train loss=0.18719089031219482
[10/24] Train loss=0.19854095578193665
[15/24] Train loss=0.19848623871803284
[20/24] Train loss=0.21106642484664917
Test set avg_accuracy=80.18% avg_sensitivity=59.23%, avg_specificity=87.67% avg_auc=84.94%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.202080 Test loss=0.430926 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.18046298623085022
[5/24] Train loss=0.18094448745250702
[10/24] Train loss=0.20186351239681244
[15/24] Train loss=0.19367298483848572
[20/24] Train loss=0.20642688870429993
Test set avg_accuracy=79.88% avg_sensitivity=60.56%, avg_specificity=86.78% avg_auc=84.76%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.200412 Test loss=0.436613 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.18064597249031067
[5/24] Train loss=0.17787234485149384
[10/24] Train loss=0.19805292785167694
[15/24] Train loss=0.19542430341243744
[20/24] Train loss=0.2116638869047165
Test set avg_accuracy=80.35% avg_sensitivity=62.30%, avg_specificity=86.80% avg_auc=84.67%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.199544 Test loss=0.437312 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.19020682573318481
[5/24] Train loss=0.18261544406414032
[10/24] Train loss=0.200609028339386
[15/24] Train loss=0.19099177420139313
[20/24] Train loss=0.2048981785774231
Test set avg_accuracy=79.95% avg_sensitivity=57.40%, avg_specificity=88.00% avg_auc=84.16%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.199275 Test loss=0.440637 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.18253257870674133
[5/24] Train loss=0.18181470036506653
[10/24] Train loss=0.19614841043949127
[15/24] Train loss=0.18514220416545868
[20/24] Train loss=0.20462065935134888
Test set avg_accuracy=79.84% avg_sensitivity=58.39%, avg_specificity=87.51% avg_auc=84.62%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.196595 Test loss=0.433786 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.17930574715137482
[5/24] Train loss=0.18174201250076294
[10/24] Train loss=0.19402895867824554
[15/24] Train loss=0.19387187063694
[20/24] Train loss=0.20271219313144684
Test set avg_accuracy=79.93% avg_sensitivity=60.37%, avg_specificity=86.92% avg_auc=84.58%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.196374 Test loss=0.437901 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.18162603676319122
[5/24] Train loss=0.17971055209636688
[10/24] Train loss=0.1939728558063507
[15/24] Train loss=0.18804602324962616
[20/24] Train loss=0.2041131556034088
Test set avg_accuracy=79.96% avg_sensitivity=58.44%, avg_specificity=87.65% avg_auc=84.25%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.195110 Test loss=0.441066 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.17829832434654236
[5/24] Train loss=0.17198337614536285
[10/24] Train loss=0.19002939760684967
[15/24] Train loss=0.1908036321401596
[20/24] Train loss=0.20230072736740112
Test set avg_accuracy=79.88% avg_sensitivity=58.83%, avg_specificity=87.40% avg_auc=84.39%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.193646 Test loss=0.437611 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.17791606485843658
[5/24] Train loss=0.17410720884799957
[10/24] Train loss=0.19304229319095612
[15/24] Train loss=0.18675516545772552
[20/24] Train loss=0.2018490433692932
Test set avg_accuracy=79.87% avg_sensitivity=58.58%, avg_specificity=87.47% avg_auc=84.37%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.193286 Test loss=0.441364 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1790088415145874
[5/24] Train loss=0.1732647716999054
[10/24] Train loss=0.1906464695930481
[15/24] Train loss=0.1853412687778473
[20/24] Train loss=0.20263464748859406
Test set avg_accuracy=79.90% avg_sensitivity=57.94%, avg_specificity=87.74% avg_auc=84.29%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.192458 Test loss=0.440208 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.17707262933254242
[5/24] Train loss=0.17467623949050903
[10/24] Train loss=0.19064192473888397
[15/24] Train loss=0.18703395128250122
[20/24] Train loss=0.20546773076057434
Test set avg_accuracy=79.99% avg_sensitivity=59.28%, avg_specificity=87.38% avg_auc=84.38%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.191943 Test loss=0.440519 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.17773546278476715
[5/24] Train loss=0.17325659096240997
[10/24] Train loss=0.18875963985919952
[15/24] Train loss=0.18383271992206573
[20/24] Train loss=0.19735324382781982
Test set avg_accuracy=80.03% avg_sensitivity=58.78%, avg_specificity=87.61% avg_auc=84.34%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.190875 Test loss=0.439646 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1749958097934723
[5/24] Train loss=0.1721755564212799
[10/24] Train loss=0.19525647163391113
[15/24] Train loss=0.1875409185886383
[20/24] Train loss=0.20550081133842468
Test set avg_accuracy=79.99% avg_sensitivity=59.72%, avg_specificity=87.22% avg_auc=84.56%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.191844 Test loss=0.438162 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.17828144133090973
[5/24] Train loss=0.17132680118083954
[10/24] Train loss=0.18953554332256317
[15/24] Train loss=0.18685434758663177
[20/24] Train loss=0.2047925889492035
Test set avg_accuracy=79.84% avg_sensitivity=58.39%, avg_specificity=87.51% avg_auc=84.47%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.190714 Test loss=0.438860 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.17436549067497253
[5/24] Train loss=0.17638178169727325
[10/24] Train loss=0.19132192432880402
[15/24] Train loss=0.18736840784549713
[20/24] Train loss=0.19968587160110474
Test set avg_accuracy=80.05% avg_sensitivity=57.74%, avg_specificity=88.02% avg_auc=84.45%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.190463 Test loss=0.438386 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1763557344675064
[5/24] Train loss=0.16930122673511505
[10/24] Train loss=0.19169887900352478
[15/24] Train loss=0.18615926802158356
[20/24] Train loss=0.19762524962425232
Test set avg_accuracy=80.09% avg_sensitivity=58.09%, avg_specificity=87.95% avg_auc=84.40%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.190355 Test loss=0.438745 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.17472398281097412
[5/24] Train loss=0.1734417974948883
[10/24] Train loss=0.18602676689624786
[15/24] Train loss=0.18755605816841125
[20/24] Train loss=0.19828298687934875
Test set avg_accuracy=79.99% avg_sensitivity=58.19%, avg_specificity=87.77% avg_auc=84.43%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.190712 Test loss=0.438834 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.17470408976078033
[5/24] Train loss=0.17377451062202454
[10/24] Train loss=0.19365839660167694
[15/24] Train loss=0.18212038278579712
[20/24] Train loss=0.19646786153316498
Test set avg_accuracy=80.03% avg_sensitivity=58.44%, avg_specificity=87.74% avg_auc=84.45%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.190708 Test loss=0.439048 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.17485401034355164
[5/24] Train loss=0.1709885150194168
[10/24] Train loss=0.19233377277851105
[15/24] Train loss=0.1847163289785385
[20/24] Train loss=0.19939997792243958
Test set avg_accuracy=80.00% avg_sensitivity=58.39%, avg_specificity=87.72% avg_auc=84.47%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.190169 Test loss=0.438758 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.17633290588855743
[5/24] Train loss=0.17147164046764374
[10/24] Train loss=0.18780086934566498
[15/24] Train loss=0.186361625790596
[20/24] Train loss=0.19823314249515533
Test set avg_accuracy=79.99% avg_sensitivity=58.19%, avg_specificity=87.77% avg_auc=84.46%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.190545 Test loss=0.438720 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=80.27% sen=69.62%, spe=84.08%, auc=86.65%!
Fold[1] Avg_overlap=0.00%(0.0)
[0/24] Train loss=0.7220157384872437
[5/24] Train loss=0.7207064628601074
[10/24] Train loss=0.7112849950790405
[15/24] Train loss=0.7064750790596008
[20/24] Train loss=0.6994312405586243
Test set avg_accuracy=50.14% avg_sensitivity=57.54%, avg_specificity=47.68% avg_auc=53.80%
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.712389 Test loss=0.711255 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7069705724716187
[5/24] Train loss=0.6987782716751099
[10/24] Train loss=0.691813588142395
[15/24] Train loss=0.686850905418396
[20/24] Train loss=0.6904986500740051
Test set avg_accuracy=60.94% avg_sensitivity=52.63%, avg_specificity=63.70% avg_auc=61.09%
Best model saved!! Metric=-87.63816775838998!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.694864 Test loss=0.655235 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6813192367553711
[5/24] Train loss=0.6784945130348206
[10/24] Train loss=0.6861270666122437
[15/24] Train loss=0.6648545265197754
[20/24] Train loss=0.6585646271705627
Test set avg_accuracy=64.93% avg_sensitivity=53.16%, avg_specificity=68.85% avg_auc=65.62%
Best model saved!! Metric=-73.436019267234!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.676666 Test loss=0.626625 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6647205948829651
[5/24] Train loss=0.6566717028617859
[10/24] Train loss=0.6634093523025513
[15/24] Train loss=0.6500576138496399
[20/24] Train loss=0.6402695178985596
Test set avg_accuracy=68.31% avg_sensitivity=54.88%, avg_specificity=72.77% avg_auc=68.95%
Best model saved!! Metric=-61.092633077652756!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.658599 Test loss=0.608038 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6443296074867249
[5/24] Train loss=0.6406797766685486
[10/24] Train loss=0.6412843465805054
[15/24] Train loss=0.639420211315155
[20/24] Train loss=0.6210963129997253
Test set avg_accuracy=70.78% avg_sensitivity=58.89%, avg_specificity=74.74% avg_auc=71.81%
Best model saved!! Metric=-49.777331623221755!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.639824 Test loss=0.592552 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6130867600440979
[5/24] Train loss=0.6214683651924133
[10/24] Train loss=0.6170941591262817
[15/24] Train loss=0.6055218577384949
[20/24] Train loss=0.5967332720756531
Test set avg_accuracy=71.33% avg_sensitivity=62.34%, avg_specificity=74.32% avg_auc=74.09%
Best model saved!! Metric=-43.92152318376651!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.616514 Test loss=0.579079 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5951983332633972
[5/24] Train loss=0.5922549366950989
[10/24] Train loss=0.5996278524398804
[15/24] Train loss=0.5854662656784058
[20/24] Train loss=0.5674763917922974
Test set avg_accuracy=72.86% avg_sensitivity=64.06%, avg_specificity=75.79% avg_auc=76.34%
Best model saved!! Metric=-36.947597532660964!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.593745 Test loss=0.557716 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5710939764976501
[5/24] Train loss=0.5648837089538574
[10/24] Train loss=0.5625631213188171
[15/24] Train loss=0.5674142241477966
[20/24] Train loss=0.5278386473655701
Test set avg_accuracy=74.56% avg_sensitivity=65.10%, avg_specificity=77.70% avg_auc=78.43%
Best model saved!! Metric=-30.20352135899276!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.567336 Test loss=0.532571 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5412852764129639
[5/24] Train loss=0.5348996520042419
[10/24] Train loss=0.5475239157676697
[15/24] Train loss=0.5320593118667603
[20/24] Train loss=0.5018900632858276
Test set avg_accuracy=75.66% avg_sensitivity=65.99%, avg_specificity=78.88% avg_auc=80.28%
Best model saved!! Metric=-25.184134011282794!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.539321 Test loss=0.511012 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5146088600158691
[5/24] Train loss=0.5021107196807861
[10/24] Train loss=0.5130220055580139
[15/24] Train loss=0.5100942850112915
[20/24] Train loss=0.47084227204322815
Test set avg_accuracy=76.94% avg_sensitivity=66.72%, avg_specificity=80.34% avg_auc=81.69%
Best model saved!! Metric=-20.30949676732203!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.512206 Test loss=0.487125 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.49144887924194336
[5/24] Train loss=0.4702020287513733
[10/24] Train loss=0.4927106499671936
[15/24] Train loss=0.4780074954032898
[20/24] Train loss=0.4443364441394806
Test set avg_accuracy=78.15% avg_sensitivity=67.29%, avg_specificity=81.76% avg_auc=82.93%
Best model saved!! Metric=-15.864569949573522!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.488194 Test loss=0.465430 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.46244877576828003
[5/24] Train loss=0.4474192261695862
[10/24] Train loss=0.46505263447761536
[15/24] Train loss=0.4598625600337982
[20/24] Train loss=0.41849538683891296
Test set avg_accuracy=78.40% avg_sensitivity=67.92%, avg_specificity=81.88% avg_auc=83.87%
Best model saved!! Metric=-13.924428197213459!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.466955 Test loss=0.452303 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.45158451795578003
[5/24] Train loss=0.42615655064582825
[10/24] Train loss=0.4505942165851593
[15/24] Train loss=0.43895164132118225
[20/24] Train loss=0.39935237169265747
Test set avg_accuracy=79.30% avg_sensitivity=64.16%, avg_specificity=84.33% avg_auc=84.32%
Best model saved!! Metric=-13.88587329147245!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.450454 Test loss=0.434532 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.43193116784095764
[5/24] Train loss=0.40959566831588745
[10/24] Train loss=0.43337130546569824
[15/24] Train loss=0.42626863718032837
[20/24] Train loss=0.3825053870677948
Test set avg_accuracy=79.70% avg_sensitivity=64.32%, avg_specificity=84.82% avg_auc=85.09%
Best model saved!! Metric=-12.07395778754524!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.435822 Test loss=0.422019 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.41834235191345215
[5/24] Train loss=0.3975270092487335
[10/24] Train loss=0.4209210276603699
[15/24] Train loss=0.4147743880748749
[20/24] Train loss=0.37008383870124817
Test set avg_accuracy=79.84% avg_sensitivity=61.87%, avg_specificity=85.82% avg_auc=85.18%
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.424516 Test loss=0.414592 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.40678882598876953
[5/24] Train loss=0.38401511311531067
[10/24] Train loss=0.4124792814254761
[15/24] Train loss=0.3955151438713074
[20/24] Train loss=0.35692262649536133
Test set avg_accuracy=80.52% avg_sensitivity=59.89%, avg_specificity=87.39% avg_auc=85.58%
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.414011 Test loss=0.404045 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3978172540664673
[5/24] Train loss=0.38016751408576965
[10/24] Train loss=0.4031479060649872
[15/24] Train loss=0.39157789945602417
[20/24] Train loss=0.34602636098861694
Test set avg_accuracy=80.40% avg_sensitivity=63.59%, avg_specificity=86.00% avg_auc=85.78%
Best model saved!! Metric=-10.229148716757805!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.405849 Test loss=0.405184 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3920772671699524
[5/24] Train loss=0.36557072401046753
[10/24] Train loss=0.395004540681839
[15/24] Train loss=0.3848605453968048
[20/24] Train loss=0.34459188580513
Test set avg_accuracy=80.55% avg_sensitivity=63.64%, avg_specificity=86.17% avg_auc=85.79%
Best model saved!! Metric=-9.846787700491355!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.399397 Test loss=0.405700 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.38041484355926514
[5/24] Train loss=0.36358481645584106
[10/24] Train loss=0.3920070230960846
[15/24] Train loss=0.37928125262260437
[20/24] Train loss=0.33318281173706055
Test set avg_accuracy=80.18% avg_sensitivity=65.88%, avg_specificity=84.94% avg_auc=86.07%
Best model saved!! Metric=-8.92700983226463!!
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.393397 Test loss=0.405003 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3747611939907074
[5/24] Train loss=0.36035633087158203
[10/24] Train loss=0.3783681392669678
[15/24] Train loss=0.3741872310638428
[20/24] Train loss=0.32672494649887085
Test set avg_accuracy=80.25% avg_sensitivity=67.76%, avg_specificity=84.40% avg_auc=85.93%
Best model saved!! Metric=-7.6576608976283325!!
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.387004 Test loss=0.413421 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.37925341725349426
[5/24] Train loss=0.34800010919570923
[10/24] Train loss=0.3785822093486786
[15/24] Train loss=0.36849093437194824
[20/24] Train loss=0.3208845257759094
Test set avg_accuracy=80.04% avg_sensitivity=68.23%, avg_specificity=83.97% avg_auc=86.01%
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.382635 Test loss=0.413741 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3673297166824341
[5/24] Train loss=0.34718751907348633
[10/24] Train loss=0.3756243586540222
[15/24] Train loss=0.3650496304035187
[20/24] Train loss=0.3166644275188446
Test set avg_accuracy=79.09% avg_sensitivity=70.11%, avg_specificity=82.08% avg_auc=85.22%
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.379286 Test loss=0.434889 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.37170398235321045
[5/24] Train loss=0.35007986426353455
[10/24] Train loss=0.36854591965675354
[15/24] Train loss=0.3566034436225891
[20/24] Train loss=0.31520456075668335
Test set avg_accuracy=79.30% avg_sensitivity=71.52%, avg_specificity=81.88% avg_auc=85.34%
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.375752 Test loss=0.440139 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.35935449600219727
[5/24] Train loss=0.3427380621433258
[10/24] Train loss=0.36495038866996765
[15/24] Train loss=0.35283076763153076
[20/24] Train loss=0.31326889991760254
Test set avg_accuracy=80.66% avg_sensitivity=69.17%, avg_specificity=84.49% avg_auc=86.37%
Best model saved!! Metric=-5.307604831512677!!
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.371939 Test loss=0.408243 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.36083224415779114
[5/24] Train loss=0.3344208002090454
[10/24] Train loss=0.36632564663887024
[15/24] Train loss=0.3507890999317169
[20/24] Train loss=0.306872695684433
Test set avg_accuracy=78.89% avg_sensitivity=71.83%, avg_specificity=81.24% avg_auc=84.73%
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.370120 Test loss=0.452974 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3570461571216583
[5/24] Train loss=0.33351606130599976
[10/24] Train loss=0.36032187938690186
[15/24] Train loss=0.3527659773826599
[20/24] Train loss=0.31053799390792847
Test set avg_accuracy=80.03% avg_sensitivity=69.01%, avg_specificity=83.69% avg_auc=85.36%
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.367125 Test loss=0.429433 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3519236147403717
[5/24] Train loss=0.3396736681461334
[10/24] Train loss=0.3615233302116394
[15/24] Train loss=0.34338510036468506
[20/24] Train loss=0.3075675368309021
Test set avg_accuracy=81.38% avg_sensitivity=57.22%, avg_specificity=89.42% avg_auc=86.07%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.363570 Test loss=0.399126 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3495134711265564
[5/24] Train loss=0.3385024666786194
[10/24] Train loss=0.3632890284061432
[15/24] Train loss=0.3462786078453064
[20/24] Train loss=0.30069804191589355
Test set avg_accuracy=81.60% avg_sensitivity=59.21%, avg_specificity=89.05% avg_auc=86.63%
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.361900 Test loss=0.387437 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3529931902885437
[5/24] Train loss=0.33179622888565063
[10/24] Train loss=0.35759153962135315
[15/24] Train loss=0.33438435196876526
[20/24] Train loss=0.3052455484867096
Test set avg_accuracy=81.48% avg_sensitivity=57.90%, avg_specificity=89.33% avg_auc=86.24%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.360200 Test loss=0.393945 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.35335856676101685
[5/24] Train loss=0.3256119191646576
[10/24] Train loss=0.35166463255882263
[15/24] Train loss=0.3323512673377991
[20/24] Train loss=0.302022248506546
Test set avg_accuracy=81.90% avg_sensitivity=56.81%, avg_specificity=90.25% avg_auc=86.37%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.356375 Test loss=0.388037 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.34326088428497314
[5/24] Train loss=0.3318924903869629
[10/24] Train loss=0.35630422830581665
[15/24] Train loss=0.33168333768844604
[20/24] Train loss=0.2988043427467346
Test set avg_accuracy=79.91% avg_sensitivity=41.58%, avg_specificity=92.66% avg_auc=82.71%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.356352 Test loss=0.430041 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.34470120072364807
[5/24] Train loss=0.336626797914505
[10/24] Train loss=0.35723939538002014
[15/24] Train loss=0.3326956629753113
[20/24] Train loss=0.29692837595939636
Test set avg_accuracy=80.49% avg_sensitivity=49.03%, avg_specificity=90.96% avg_auc=84.98%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.356099 Test loss=0.402388 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.33300599455833435
[5/24] Train loss=0.32763272523880005
[10/24] Train loss=0.35714733600616455
[15/24] Train loss=0.33525538444519043
[20/24] Train loss=0.29904285073280334
Test set avg_accuracy=80.21% avg_sensitivity=62.70%, avg_specificity=86.03% avg_auc=85.33%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.353299 Test loss=0.413156 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.33928701281547546
[5/24] Train loss=0.3233889937400818
[10/24] Train loss=0.34897592663764954
[15/24] Train loss=0.32712671160697937
[20/24] Train loss=0.29114845395088196
Test set avg_accuracy=81.45% avg_sensitivity=47.37%, avg_specificity=92.78% avg_auc=85.45%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.352498 Test loss=0.398581 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.33645492792129517
[5/24] Train loss=0.33016911149024963
[10/24] Train loss=0.3489207625389099
[15/24] Train loss=0.3345557749271393
[20/24] Train loss=0.2942615747451782
Test set avg_accuracy=80.77% avg_sensitivity=44.60%, avg_specificity=92.80% avg_auc=85.41%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.351000 Test loss=0.398058 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3321692943572998
[5/24] Train loss=0.3268599510192871
[10/24] Train loss=0.34434962272644043
[15/24] Train loss=0.34586456418037415
[20/24] Train loss=0.2944427728652954
Test set avg_accuracy=80.90% avg_sensitivity=41.47%, avg_specificity=94.01% avg_auc=85.38%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.350590 Test loss=0.399202 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3398296535015106
[5/24] Train loss=0.3234398066997528
[10/24] Train loss=0.34057381749153137
[15/24] Train loss=0.3292265236377716
[20/24] Train loss=0.2964722812175751
Test set avg_accuracy=80.43% avg_sensitivity=46.53%, avg_specificity=91.71% avg_auc=84.92%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.349323 Test loss=0.402355 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3333342373371124
[5/24] Train loss=0.32565996050834656
[10/24] Train loss=0.35507863759994507
[15/24] Train loss=0.33581164479255676
[20/24] Train loss=0.2900589108467102
Test set avg_accuracy=80.86% avg_sensitivity=42.20%, avg_specificity=93.72% avg_auc=85.12%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.350030 Test loss=0.401248 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3344849944114685
[5/24] Train loss=0.3173166513442993
[10/24] Train loss=0.3474251627922058
[15/24] Train loss=0.3192366361618042
[20/24] Train loss=0.29077354073524475
Test set avg_accuracy=81.50% avg_sensitivity=59.73%, avg_specificity=88.74% avg_auc=86.40%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.347409 Test loss=0.399765 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3316102921962738
[5/24] Train loss=0.3249889016151428
[10/24] Train loss=0.34261202812194824
[15/24] Train loss=0.32556185126304626
[20/24] Train loss=0.286903440952301
Test set avg_accuracy=81.46% avg_sensitivity=55.45%, avg_specificity=90.11% avg_auc=85.44%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.347864 Test loss=0.405389 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3300459682941437
[5/24] Train loss=0.3247819244861603
[10/24] Train loss=0.3446446359157562
[15/24] Train loss=0.31909239292144775
[20/24] Train loss=0.2932279109954834
Test set avg_accuracy=80.95% avg_sensitivity=53.05%, avg_specificity=90.23% avg_auc=85.06%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.345496 Test loss=0.409178 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.345393568277359
[5/24] Train loss=0.3281419575214386
[10/24] Train loss=0.34635958075523376
[15/24] Train loss=0.3217974901199341
[20/24] Train loss=0.27953773736953735
Test set avg_accuracy=80.47% avg_sensitivity=36.98%, avg_specificity=94.93% avg_auc=83.59%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.345318 Test loss=0.418943 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.33030179142951965
[5/24] Train loss=0.3226970434188843
[10/24] Train loss=0.3463193476200104
[15/24] Train loss=0.3220565915107727
[20/24] Train loss=0.2933785617351532
Test set avg_accuracy=80.96% avg_sensitivity=43.14%, avg_specificity=93.55% avg_auc=85.65%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.345634 Test loss=0.403144 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3255354166030884
[5/24] Train loss=0.3240376114845276
[10/24] Train loss=0.3397577404975891
[15/24] Train loss=0.32676705718040466
[20/24] Train loss=0.29086342453956604
Test set avg_accuracy=80.79% avg_sensitivity=56.70%, avg_specificity=88.81% avg_auc=84.63%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.343440 Test loss=0.411148 Current lr=[0.00029967723776099]

[0/24] Train loss=0.32639560103416443
[5/24] Train loss=0.31904318928718567
[10/24] Train loss=0.3494698405265808
[15/24] Train loss=0.32595306634902954
[20/24] Train loss=0.2849194407463074
Test set avg_accuracy=77.37% avg_sensitivity=35.32%, avg_specificity=91.36% avg_auc=75.50%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.343450 Test loss=0.486366 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3295901119709015
[5/24] Train loss=0.31728070974349976
[10/24] Train loss=0.3410850167274475
[15/24] Train loss=0.3360506296157837
[20/24] Train loss=0.28722676634788513
Test set avg_accuracy=79.62% avg_sensitivity=62.23%, avg_specificity=85.41% avg_auc=83.75%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.341612 Test loss=0.473299 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.33545738458633423
[5/24] Train loss=0.3205614984035492
[10/24] Train loss=0.34492507576942444
[15/24] Train loss=0.31467851996421814
[20/24] Train loss=0.2895490229129791
Test set avg_accuracy=80.96% avg_sensitivity=48.30%, avg_specificity=91.83% avg_auc=84.81%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.340770 Test loss=0.402538 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3257242441177368
[5/24] Train loss=0.32319357991218567
[10/24] Train loss=0.3433333933353424
[15/24] Train loss=0.32553309202194214
[20/24] Train loss=0.28732672333717346
Test set avg_accuracy=81.73% avg_sensitivity=53.52%, avg_specificity=91.12% avg_auc=85.27%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.342276 Test loss=0.397737 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3251967430114746
[5/24] Train loss=0.31547337770462036
[10/24] Train loss=0.33897116780281067
[15/24] Train loss=0.31857830286026
[20/24] Train loss=0.28777605295181274
Test set avg_accuracy=81.68% avg_sensitivity=51.49%, avg_specificity=91.72% avg_auc=86.37%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.338259 Test loss=0.386265 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3209223449230194
[5/24] Train loss=0.3178460896015167
[10/24] Train loss=0.338539183139801
[15/24] Train loss=0.3172644376754761
[20/24] Train loss=0.29121798276901245
Test set avg_accuracy=81.18% avg_sensitivity=48.83%, avg_specificity=91.95% avg_auc=85.51%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.340068 Test loss=0.400709 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3229660093784332
[5/24] Train loss=0.31663185358047485
[10/24] Train loss=0.33407142758369446
[15/24] Train loss=0.3171333968639374
[20/24] Train loss=0.279687762260437
Test set avg_accuracy=81.93% avg_sensitivity=54.04%, avg_specificity=91.20% avg_auc=86.77%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.336193 Test loss=0.385628 Current lr=[0.000297555943323901]

[0/24] Train loss=0.31710949540138245
[5/24] Train loss=0.3242430090904236
[10/24] Train loss=0.3445121943950653
[15/24] Train loss=0.31303802132606506
[20/24] Train loss=0.28890103101730347
Test set avg_accuracy=81.34% avg_sensitivity=43.45%, avg_specificity=93.94% avg_auc=84.51%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.339274 Test loss=0.417355 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.32073351740837097
[5/24] Train loss=0.32117751240730286
[10/24] Train loss=0.34636378288269043
[15/24] Train loss=0.3214258849620819
[20/24] Train loss=0.28647127747535706
Test set avg_accuracy=81.69% avg_sensitivity=46.22%, avg_specificity=93.49% avg_auc=84.75%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.340676 Test loss=0.406348 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3353007733821869
[5/24] Train loss=0.31703469157218933
[10/24] Train loss=0.34510505199432373
[15/24] Train loss=0.31892773509025574
[20/24] Train loss=0.2850814759731293
Test set avg_accuracy=81.59% avg_sensitivity=57.75%, avg_specificity=89.52% avg_auc=86.15%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.338655 Test loss=0.389099 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.31597286462783813
[5/24] Train loss=0.3224853575229645
[10/24] Train loss=0.34172236919403076
[15/24] Train loss=0.32541435956954956
[20/24] Train loss=0.2840133309364319
Test set avg_accuracy=81.30% avg_sensitivity=59.26%, avg_specificity=88.63% avg_auc=86.61%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.337409 Test loss=0.389814 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.32141003012657166
[5/24] Train loss=0.3267204165458679
[10/24] Train loss=0.33599692583084106
[15/24] Train loss=0.32565245032310486
[20/24] Train loss=0.2786862850189209
Test set avg_accuracy=80.29% avg_sensitivity=60.35%, avg_specificity=86.92% avg_auc=84.19%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.336519 Test loss=0.427623 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.32438573241233826
[5/24] Train loss=0.3133400082588196
[10/24] Train loss=0.33674418926239014
[15/24] Train loss=0.3209705650806427
[20/24] Train loss=0.2865836024284363
Test set avg_accuracy=77.77% avg_sensitivity=56.86%, avg_specificity=84.73% avg_auc=80.72%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.336023 Test loss=0.464843 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3257731795310974
[5/24] Train loss=0.31333985924720764
[10/24] Train loss=0.3350507915019989
[15/24] Train loss=0.3093581795692444
[20/24] Train loss=0.28768065571784973
Test set avg_accuracy=80.44% avg_sensitivity=59.52%, avg_specificity=87.40% avg_auc=85.88%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.334474 Test loss=0.400719 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.32187962532043457
[5/24] Train loss=0.3237897455692291
[10/24] Train loss=0.33924010396003723
[15/24] Train loss=0.3079935908317566
[20/24] Train loss=0.2898695468902588
Test set avg_accuracy=81.11% avg_sensitivity=56.70%, avg_specificity=89.22% avg_auc=85.45%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.336163 Test loss=0.402194 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3176012635231018
[5/24] Train loss=0.3294333815574646
[10/24] Train loss=0.3425399959087372
[15/24] Train loss=0.30936259031295776
[20/24] Train loss=0.28378137946128845
Test set avg_accuracy=79.53% avg_sensitivity=69.43%, avg_specificity=82.89% avg_auc=84.22%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.336265 Test loss=0.454850 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.33036375045776367
[5/24] Train loss=0.3192598223686218
[10/24] Train loss=0.3320906460285187
[15/24] Train loss=0.3090747594833374
[20/24] Train loss=0.28885963559150696
Test set avg_accuracy=77.38% avg_sensitivity=71.31%, avg_specificity=79.40% avg_auc=83.33%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.334830 Test loss=0.479252 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3364056348800659
[5/24] Train loss=0.313892126083374
[10/24] Train loss=0.3315187692642212
[15/24] Train loss=0.3132970333099365
[20/24] Train loss=0.2787272036075592
Test set avg_accuracy=79.83% avg_sensitivity=46.11%, avg_specificity=91.05% avg_auc=77.58%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.332683 Test loss=0.473096 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3339727520942688
[5/24] Train loss=0.3199782073497772
[10/24] Train loss=0.33534878492355347
[15/24] Train loss=0.30789047479629517
[20/24] Train loss=0.2801302969455719
Test set avg_accuracy=80.20% avg_sensitivity=60.25%, avg_specificity=86.83% avg_auc=84.91%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.335027 Test loss=0.424765 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.32482269406318665
[5/24] Train loss=0.3103264570236206
[10/24] Train loss=0.3312777280807495
[15/24] Train loss=0.2988462746143341
[20/24] Train loss=0.28504693508148193
Test set avg_accuracy=80.12% avg_sensitivity=58.95%, avg_specificity=87.16% avg_auc=84.58%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.330281 Test loss=0.422044 Current lr=[0.000276307469034998]

[0/24] Train loss=0.31633880734443665
[5/24] Train loss=0.31607919931411743
[10/24] Train loss=0.33608362078666687
[15/24] Train loss=0.30358925461769104
[20/24] Train loss=0.28409069776535034
Test set avg_accuracy=80.43% avg_sensitivity=47.89%, avg_specificity=91.25% avg_auc=83.79%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.331484 Test loss=0.415345 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.32344546914100647
[5/24] Train loss=0.31050217151641846
[10/24] Train loss=0.33483895659446716
[15/24] Train loss=0.30513662099838257
[20/24] Train loss=0.27781516313552856
Test set avg_accuracy=79.04% avg_sensitivity=55.71%, avg_specificity=86.80% avg_auc=80.53%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.331985 Test loss=0.459551 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.32533207535743713
[5/24] Train loss=0.31504026055336
[10/24] Train loss=0.329102098941803
[15/24] Train loss=0.29427745938301086
[20/24] Train loss=0.27158433198928833
Test set avg_accuracy=81.08% avg_sensitivity=42.57%, avg_specificity=93.89% avg_auc=84.35%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.329974 Test loss=0.409353 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3105989396572113
[5/24] Train loss=0.31215739250183105
[10/24] Train loss=0.3288910686969757
[15/24] Train loss=0.2955489754676819
[20/24] Train loss=0.27613744139671326
Test set avg_accuracy=78.22% avg_sensitivity=65.26%, avg_specificity=82.53% avg_auc=81.24%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.326777 Test loss=0.500073 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3075776696205139
[5/24] Train loss=0.30813145637512207
[10/24] Train loss=0.33034658432006836
[15/24] Train loss=0.30618032813072205
[20/24] Train loss=0.2728409469127655
Test set avg_accuracy=80.65% avg_sensitivity=57.43%, avg_specificity=88.37% avg_auc=85.17%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.327204 Test loss=0.406001 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.31035494804382324
[5/24] Train loss=0.3033219277858734
[10/24] Train loss=0.3360573649406433
[15/24] Train loss=0.29855024814605713
[20/24] Train loss=0.2756211757659912
Test set avg_accuracy=80.60% avg_sensitivity=58.22%, avg_specificity=88.04% avg_auc=85.57%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.327140 Test loss=0.402878 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3149062693119049
[5/24] Train loss=0.3131276071071625
[10/24] Train loss=0.32972750067710876
[15/24] Train loss=0.3038066625595093
[20/24] Train loss=0.27321964502334595
Test set avg_accuracy=80.27% avg_sensitivity=54.88%, avg_specificity=88.72% avg_auc=85.21%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.325232 Test loss=0.406145 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3100448250770569
[5/24] Train loss=0.3069750964641571
[10/24] Train loss=0.31927961111068726
[15/24] Train loss=0.2947767376899719
[20/24] Train loss=0.27819982171058655
Test set avg_accuracy=79.30% avg_sensitivity=59.42%, avg_specificity=85.91% avg_auc=83.72%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.323136 Test loss=0.443061 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.30799204111099243
[5/24] Train loss=0.3032214641571045
[10/24] Train loss=0.33139193058013916
[15/24] Train loss=0.30240634083747864
[20/24] Train loss=0.27653250098228455
Test set avg_accuracy=81.42% avg_sensitivity=44.44%, avg_specificity=93.72% avg_auc=84.89%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.324441 Test loss=0.407429 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.314471960067749
[5/24] Train loss=0.3057318329811096
[10/24] Train loss=0.3144918382167816
[15/24] Train loss=0.29255959391593933
[20/24] Train loss=0.26391392946243286
Test set avg_accuracy=81.02% avg_sensitivity=46.84%, avg_specificity=92.38% avg_auc=84.25%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.320283 Test loss=0.411260 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3001379370689392
[5/24] Train loss=0.3047109842300415
[10/24] Train loss=0.3241961896419525
[15/24] Train loss=0.30061471462249756
[20/24] Train loss=0.2725255489349365
Test set avg_accuracy=80.20% avg_sensitivity=57.02%, avg_specificity=87.91% avg_auc=85.07%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.320602 Test loss=0.410373 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.30118754506111145
[5/24] Train loss=0.2981540858745575
[10/24] Train loss=0.31403911113739014
[15/24] Train loss=0.2975384593009949
[20/24] Train loss=0.2736313045024872
Test set avg_accuracy=80.17% avg_sensitivity=46.22%, avg_specificity=91.46% avg_auc=82.74%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.319891 Test loss=0.426557 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2967064082622528
[5/24] Train loss=0.30390238761901855
[10/24] Train loss=0.30953386425971985
[15/24] Train loss=0.29637375473976135
[20/24] Train loss=0.26437994837760925
Test set avg_accuracy=78.97% avg_sensitivity=60.35%, avg_specificity=85.16% avg_auc=83.25%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.314498 Test loss=0.439902 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.30475538969039917
[5/24] Train loss=0.2947852611541748
[10/24] Train loss=0.3179764151573181
[15/24] Train loss=0.2910095453262329
[20/24] Train loss=0.26396289467811584
Test set avg_accuracy=80.52% avg_sensitivity=58.84%, avg_specificity=87.73% avg_auc=84.64%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.318727 Test loss=0.421546 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.29335296154022217
[5/24] Train loss=0.29755619168281555
[10/24] Train loss=0.3193688988685608
[15/24] Train loss=0.28749188780784607
[20/24] Train loss=0.265328973531723
Test set avg_accuracy=79.24% avg_sensitivity=32.13%, avg_specificity=94.92% avg_auc=82.76%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.314399 Test loss=0.446416 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2949879467487335
[5/24] Train loss=0.2968892455101013
[10/24] Train loss=0.3073914647102356
[15/24] Train loss=0.30468741059303284
[20/24] Train loss=0.263336718082428
Test set avg_accuracy=79.02% avg_sensitivity=34.85%, avg_specificity=93.72% avg_auc=83.58%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.313396 Test loss=0.441534 Current lr=[0.000224838296036774]

[0/24] Train loss=0.30234038829803467
[5/24] Train loss=0.3012952506542206
[10/24] Train loss=0.31456369161605835
[15/24] Train loss=0.28588348627090454
[20/24] Train loss=0.2704232931137085
Test set avg_accuracy=80.55% avg_sensitivity=52.90%, avg_specificity=89.74% avg_auc=84.47%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.313550 Test loss=0.416896 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2928283214569092
[5/24] Train loss=0.3047788441181183
[10/24] Train loss=0.30984315276145935
[15/24] Train loss=0.2854384183883667
[20/24] Train loss=0.2588499188423157
Test set avg_accuracy=79.93% avg_sensitivity=39.18%, avg_specificity=93.49% avg_auc=83.59%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.312674 Test loss=0.427269 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.29304373264312744
[5/24] Train loss=0.2985273599624634
[10/24] Train loss=0.31839555501937866
[15/24] Train loss=0.2756385803222656
[20/24] Train loss=0.2712475061416626
Test set avg_accuracy=80.42% avg_sensitivity=54.83%, avg_specificity=88.93% avg_auc=84.20%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.308720 Test loss=0.419755 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.29361483454704285
[5/24] Train loss=0.29103198647499084
[10/24] Train loss=0.30602553486824036
[15/24] Train loss=0.2817494571208954
[20/24] Train loss=0.25977623462677
Test set avg_accuracy=79.56% avg_sensitivity=62.02%, avg_specificity=85.39% avg_auc=81.64%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.308326 Test loss=0.466260 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.28866317868232727
[5/24] Train loss=0.2911301851272583
[10/24] Train loss=0.3162305951118469
[15/24] Train loss=0.297964870929718
[20/24] Train loss=0.26161059737205505
Test set avg_accuracy=80.01% avg_sensitivity=50.23%, avg_specificity=89.92% avg_auc=85.14%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.306291 Test loss=0.407429 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2929770350456238
[5/24] Train loss=0.28426051139831543
[10/24] Train loss=0.31332722306251526
[15/24] Train loss=0.2876409590244293
[20/24] Train loss=0.2550327479839325
Test set avg_accuracy=80.43% avg_sensitivity=57.28%, avg_specificity=88.13% avg_auc=85.31%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.306496 Test loss=0.408704 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2791762948036194
[5/24] Train loss=0.2961583733558655
[10/24] Train loss=0.302903950214386
[15/24] Train loss=0.2854537069797516
[20/24] Train loss=0.2576707899570465
Test set avg_accuracy=80.34% avg_sensitivity=57.80%, avg_specificity=87.84% avg_auc=84.68%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.302975 Test loss=0.419465 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2785942852497101
[5/24] Train loss=0.2968328595161438
[10/24] Train loss=0.3032529354095459
[15/24] Train loss=0.2800385355949402
[20/24] Train loss=0.25892531871795654
Test set avg_accuracy=79.23% avg_sensitivity=37.77%, avg_specificity=93.02% avg_auc=82.89%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.301527 Test loss=0.440848 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.27274951338768005
[5/24] Train loss=0.28851523995399475
[10/24] Train loss=0.3037090599536896
[15/24] Train loss=0.28276526927948
[20/24] Train loss=0.2673904001712799
Test set avg_accuracy=80.22% avg_sensitivity=52.27%, avg_specificity=89.52% avg_auc=84.34%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.301179 Test loss=0.417219 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2790752649307251
[5/24] Train loss=0.28935638070106506
[10/24] Train loss=0.29677480459213257
[15/24] Train loss=0.2842613458633423
[20/24] Train loss=0.2521686255931854
Test set avg_accuracy=79.17% avg_sensitivity=40.27%, avg_specificity=92.10% avg_auc=82.37%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.297940 Test loss=0.448168 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2772827744483948
[5/24] Train loss=0.287955641746521
[10/24] Train loss=0.28919246792793274
[15/24] Train loss=0.27960145473480225
[20/24] Train loss=0.27037161588668823
Test set avg_accuracy=80.55% avg_sensitivity=56.29%, avg_specificity=88.62% avg_auc=84.48%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.297927 Test loss=0.422717 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.27773886919021606
[5/24] Train loss=0.2796175181865692
[10/24] Train loss=0.2916931211948395
[15/24] Train loss=0.2783363461494446
[20/24] Train loss=0.2566477060317993
Test set avg_accuracy=81.45% avg_sensitivity=62.75%, avg_specificity=87.66% avg_auc=85.73%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.295342 Test loss=0.418170 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.27457988262176514
[5/24] Train loss=0.27979493141174316
[10/24] Train loss=0.29489073157310486
[15/24] Train loss=0.27515289187431335
[20/24] Train loss=0.2496419996023178
Test set avg_accuracy=79.22% avg_sensitivity=34.48%, avg_specificity=94.10% avg_auc=82.32%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.293068 Test loss=0.471180 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.26681050658226013
[5/24] Train loss=0.28215137124061584
[10/24] Train loss=0.2991792559623718
[15/24] Train loss=0.2706175744533539
[20/24] Train loss=0.24963799118995667
Test set avg_accuracy=79.87% avg_sensitivity=49.40%, avg_specificity=90.01% avg_auc=83.68%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.291465 Test loss=0.440736 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.265938937664032
[5/24] Train loss=0.2753760814666748
[10/24] Train loss=0.29634037613868713
[15/24] Train loss=0.27240997552871704
[20/24] Train loss=0.2574901580810547
Test set avg_accuracy=80.86% avg_sensitivity=62.34%, avg_specificity=87.02% avg_auc=85.22%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.291703 Test loss=0.419104 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.25681453943252563
[5/24] Train loss=0.27456676959991455
[10/24] Train loss=0.2836464047431946
[15/24] Train loss=0.2636162340641022
[20/24] Train loss=0.25284847617149353
Test set avg_accuracy=78.35% avg_sensitivity=52.58%, avg_specificity=86.92% avg_auc=81.11%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.285402 Test loss=0.462762 Current lr=[0.000156543481933168]

[0/24] Train loss=0.25777551531791687
[5/24] Train loss=0.271923303604126
[10/24] Train loss=0.28842219710350037
[15/24] Train loss=0.27149704098701477
[20/24] Train loss=0.2541540265083313
Test set avg_accuracy=80.87% avg_sensitivity=56.49%, avg_specificity=88.98% avg_auc=84.98%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.285953 Test loss=0.418224 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2628733515739441
[5/24] Train loss=0.2791885435581207
[10/24] Train loss=0.2806430757045746
[15/24] Train loss=0.2669787108898163
[20/24] Train loss=0.24985164403915405
Test set avg_accuracy=79.73% avg_sensitivity=41.73%, avg_specificity=92.37% avg_auc=82.25%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.283513 Test loss=0.465674 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2575072944164276
[5/24] Train loss=0.27976566553115845
[10/24] Train loss=0.2825138568878174
[15/24] Train loss=0.26376813650131226
[20/24] Train loss=0.24849648773670197
Test set avg_accuracy=80.40% avg_sensitivity=47.21%, avg_specificity=91.45% avg_auc=82.58%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.283856 Test loss=0.432019 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.2501780688762665
[5/24] Train loss=0.2644997239112854
[10/24] Train loss=0.28358593583106995
[15/24] Train loss=0.25694653391838074
[20/24] Train loss=0.2502255439758301
Test set avg_accuracy=78.63% avg_sensitivity=30.78%, avg_specificity=94.55% avg_auc=80.66%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.281297 Test loss=0.497083 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.2540087103843689
[5/24] Train loss=0.2670837342739105
[10/24] Train loss=0.27196618914604187
[15/24] Train loss=0.2564804255962372
[20/24] Train loss=0.23905116319656372
Test set avg_accuracy=80.09% avg_sensitivity=42.04%, avg_specificity=92.75% avg_auc=81.78%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.278245 Test loss=0.465360 Current lr=[0.000134135431043539]

[0/24] Train loss=0.25676870346069336
[5/24] Train loss=0.2584482431411743
[10/24] Train loss=0.2713721692562103
[15/24] Train loss=0.26454418897628784
[20/24] Train loss=0.24628211557865143
Test set avg_accuracy=80.42% avg_sensitivity=60.62%, avg_specificity=87.00% avg_auc=85.18%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.276609 Test loss=0.418260 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.24610121548175812
[5/24] Train loss=0.26622480154037476
[10/24] Train loss=0.27323827147483826
[15/24] Train loss=0.24868883192539215
[20/24] Train loss=0.23793721199035645
Test set avg_accuracy=80.26% avg_sensitivity=50.97%, avg_specificity=90.01% avg_auc=84.74%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.273105 Test loss=0.417431 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2506006360054016
[5/24] Train loss=0.25762656331062317
[10/24] Train loss=0.27557680010795593
[15/24] Train loss=0.26733869314193726
[20/24] Train loss=0.24254928529262543
Test set avg_accuracy=80.70% avg_sensitivity=48.62%, avg_specificity=91.38% avg_auc=83.99%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.271245 Test loss=0.432600 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.24604013562202454
[5/24] Train loss=0.26002615690231323
[10/24] Train loss=0.2686860263347626
[15/24] Train loss=0.2563255727291107
[20/24] Train loss=0.2419515699148178
Test set avg_accuracy=79.47% avg_sensitivity=29.79%, avg_specificity=95.99% avg_auc=80.20%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.271647 Test loss=0.486048 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.25136798620224
[5/24] Train loss=0.2545624375343323
[10/24] Train loss=0.2598680555820465
[15/24] Train loss=0.2540952265262604
[20/24] Train loss=0.24030810594558716
Test set avg_accuracy=78.16% avg_sensitivity=22.17%, avg_specificity=96.79% avg_auc=75.82%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.268660 Test loss=0.546213 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.2483016401529312
[5/24] Train loss=0.24683907628059387
[10/24] Train loss=0.2596453130245209
[15/24] Train loss=0.23834696412086487
[20/24] Train loss=0.22202534973621368
Test set avg_accuracy=78.41% avg_sensitivity=25.82%, avg_specificity=95.90% avg_auc=74.41%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.265667 Test loss=0.559465 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.2386694699525833
[5/24] Train loss=0.2504739761352539
[10/24] Train loss=0.25410768389701843
[15/24] Train loss=0.24126780033111572
[20/24] Train loss=0.2278871238231659
Test set avg_accuracy=80.34% avg_sensitivity=52.58%, avg_specificity=89.57% avg_auc=82.53%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.264769 Test loss=0.438529 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.23177631199359894
[5/24] Train loss=0.24889196455478668
[10/24] Train loss=0.25170740485191345
[15/24] Train loss=0.24883323907852173
[20/24] Train loss=0.22380588948726654
Test set avg_accuracy=79.99% avg_sensitivity=42.72%, avg_specificity=92.38% avg_auc=81.19%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.259342 Test loss=0.449097 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.24454659223556519
[5/24] Train loss=0.24681192636489868
[10/24] Train loss=0.25001418590545654
[15/24] Train loss=0.24788135290145874
[20/24] Train loss=0.2283542901277542
Test set avg_accuracy=79.71% avg_sensitivity=42.15%, avg_specificity=92.21% avg_auc=81.98%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.255858 Test loss=0.451460 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.23578228056430817
[5/24] Train loss=0.24476046860218048
[10/24] Train loss=0.24244239926338196
[15/24] Train loss=0.23668703436851501
[20/24] Train loss=0.21846714615821838
Test set avg_accuracy=80.86% avg_sensitivity=46.17%, avg_specificity=92.40% avg_auc=83.33%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.251894 Test loss=0.436283 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.22600585222244263
[5/24] Train loss=0.2369813621044159
[10/24] Train loss=0.2343214601278305
[15/24] Train loss=0.23804421722888947
[20/24] Train loss=0.2278418093919754
Test set avg_accuracy=79.92% avg_sensitivity=44.50%, avg_specificity=91.71% avg_auc=81.98%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.249618 Test loss=0.448793 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.23217053711414337
[5/24] Train loss=0.24555277824401855
[10/24] Train loss=0.23890525102615356
[15/24] Train loss=0.23527000844478607
[20/24] Train loss=0.22308357059955597
Test set avg_accuracy=78.05% avg_sensitivity=43.97%, avg_specificity=89.38% avg_auc=79.27%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.248629 Test loss=0.487600 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.2178526669740677
[5/24] Train loss=0.23884062469005585
[10/24] Train loss=0.2345139980316162
[15/24] Train loss=0.23087455332279205
[20/24] Train loss=0.22307263314723969
Test set avg_accuracy=80.09% avg_sensitivity=55.24%, avg_specificity=88.36% avg_auc=83.59%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.243432 Test loss=0.432938 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.21492743492126465
[5/24] Train loss=0.2333565205335617
[10/24] Train loss=0.23640528321266174
[15/24] Train loss=0.22638611495494843
[20/24] Train loss=0.2108834981918335
Test set avg_accuracy=78.50% avg_sensitivity=34.06%, avg_specificity=93.28% avg_auc=79.52%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.240311 Test loss=0.497990 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.21845722198486328
[5/24] Train loss=0.23207953572273254
[10/24] Train loss=0.23089151084423065
[15/24] Train loss=0.221824511885643
[20/24] Train loss=0.21469536423683167
Test set avg_accuracy=79.79% avg_sensitivity=50.29%, avg_specificity=89.61% avg_auc=81.83%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.236212 Test loss=0.450102 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.22313110530376434
[5/24] Train loss=0.233724445104599
[10/24] Train loss=0.22507727146148682
[15/24] Train loss=0.22739297151565552
[20/24] Train loss=0.20877183973789215
Test set avg_accuracy=80.52% avg_sensitivity=55.76%, avg_specificity=88.76% avg_auc=83.71%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.234950 Test loss=0.427665 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.2204718440771103
[5/24] Train loss=0.23439577221870422
[10/24] Train loss=0.2169753611087799
[15/24] Train loss=0.21293160319328308
[20/24] Train loss=0.19888560473918915
Test set avg_accuracy=80.35% avg_sensitivity=50.65%, avg_specificity=90.23% avg_auc=83.60%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.231434 Test loss=0.436670 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.20711681246757507
[5/24] Train loss=0.22505740821361542
[10/24] Train loss=0.21740040183067322
[15/24] Train loss=0.20686249434947968
[20/24] Train loss=0.20287470519542694
Test set avg_accuracy=80.76% avg_sensitivity=56.13%, avg_specificity=88.95% avg_auc=84.30%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.227550 Test loss=0.432721 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.21581867337226868
[5/24] Train loss=0.21680191159248352
[10/24] Train loss=0.2191268354654312
[15/24] Train loss=0.20951616764068604
[20/24] Train loss=0.19628427922725677
Test set avg_accuracy=79.91% avg_sensitivity=60.67%, avg_specificity=86.31% avg_auc=84.12%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.227304 Test loss=0.440737 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.20514991879463196
[5/24] Train loss=0.22175006568431854
[10/24] Train loss=0.2174229770898819
[15/24] Train loss=0.20937539637088776
[20/24] Train loss=0.20347504317760468
Test set avg_accuracy=80.48% avg_sensitivity=47.68%, avg_specificity=91.39% avg_auc=84.12%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.224627 Test loss=0.440168 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.2062624990940094
[5/24] Train loss=0.22016417980194092
[10/24] Train loss=0.2217838615179062
[15/24] Train loss=0.2068420946598053
[20/24] Train loss=0.19753772020339966
Test set avg_accuracy=80.25% avg_sensitivity=51.02%, avg_specificity=89.97% avg_auc=82.89%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.224161 Test loss=0.454632 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.20212504267692566
[5/24] Train loss=0.21902325749397278
[10/24] Train loss=0.2133503556251526
[15/24] Train loss=0.20461933314800262
[20/24] Train loss=0.19407576322555542
Test set avg_accuracy=79.23% avg_sensitivity=58.58%, avg_specificity=86.10% avg_auc=82.45%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.219761 Test loss=0.460542 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.20408622920513153
[5/24] Train loss=0.21681058406829834
[10/24] Train loss=0.2172015905380249
[15/24] Train loss=0.197032168507576
[20/24] Train loss=0.1945057362318039
Test set avg_accuracy=80.23% avg_sensitivity=60.04%, avg_specificity=86.95% avg_auc=83.69%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.217788 Test loss=0.444817 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.20505954325199127
[5/24] Train loss=0.20725443959236145
[10/24] Train loss=0.2174396812915802
[15/24] Train loss=0.20112404227256775
[20/24] Train loss=0.19730180501937866
Test set avg_accuracy=80.38% avg_sensitivity=62.23%, avg_specificity=86.41% avg_auc=83.73%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.215809 Test loss=0.454951 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1923513561487198
[5/24] Train loss=0.20998863875865936
[10/24] Train loss=0.2123972624540329
[15/24] Train loss=0.19375279545783997
[20/24] Train loss=0.18715570867061615
Test set avg_accuracy=79.84% avg_sensitivity=55.82%, avg_specificity=87.84% avg_auc=83.62%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.213306 Test loss=0.441386 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1974514275789261
[5/24] Train loss=0.2070145457983017
[10/24] Train loss=0.20710939168930054
[15/24] Train loss=0.20289930701255798
[20/24] Train loss=0.1857321560382843
Test set avg_accuracy=80.30% avg_sensitivity=57.90%, avg_specificity=87.75% avg_auc=84.47%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.209534 Test loss=0.434963 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.19627662003040314
[5/24] Train loss=0.2027316391468048
[10/24] Train loss=0.19796572625637054
[15/24] Train loss=0.18967664241790771
[20/24] Train loss=0.18393613398075104
Test set avg_accuracy=80.08% avg_sensitivity=62.39%, avg_specificity=85.96% avg_auc=83.97%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.206155 Test loss=0.454459 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.19318972527980804
[5/24] Train loss=0.20055750012397766
[10/24] Train loss=0.19576598703861237
[15/24] Train loss=0.19389976561069489
[20/24] Train loss=0.17777517437934875
Test set avg_accuracy=80.33% avg_sensitivity=61.19%, avg_specificity=86.69% avg_auc=84.59%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.204242 Test loss=0.446767 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.18491490185260773
[5/24] Train loss=0.20132295787334442
[10/24] Train loss=0.2011103630065918
[15/24] Train loss=0.19547946751117706
[20/24] Train loss=0.18104396760463715
Test set avg_accuracy=80.74% avg_sensitivity=59.47%, avg_specificity=87.82% avg_auc=84.37%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.203193 Test loss=0.440586 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.18584108352661133
[5/24] Train loss=0.19906534254550934
[10/24] Train loss=0.19400130212306976
[15/24] Train loss=0.19070203602313995
[20/24] Train loss=0.1837797909975052
Test set avg_accuracy=79.75% avg_sensitivity=54.72%, avg_specificity=88.08% avg_auc=83.47%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.201580 Test loss=0.448136 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1804308444261551
[5/24] Train loss=0.19927352666854858
[10/24] Train loss=0.1965627521276474
[15/24] Train loss=0.18298834562301636
[20/24] Train loss=0.17900855839252472
Test set avg_accuracy=79.67% avg_sensitivity=58.32%, avg_specificity=86.78% avg_auc=83.58%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.199966 Test loss=0.450362 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1871727705001831
[5/24] Train loss=0.19245480000972748
[10/24] Train loss=0.18889398872852325
[15/24] Train loss=0.18334613740444183
[20/24] Train loss=0.18178457021713257
Test set avg_accuracy=79.99% avg_sensitivity=56.34%, avg_specificity=87.85% avg_auc=83.30%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.196823 Test loss=0.449168 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.17466644942760468
[5/24] Train loss=0.19220291078090668
[10/24] Train loss=0.18743902444839478
[15/24] Train loss=0.18324214220046997
[20/24] Train loss=0.17714710533618927
Test set avg_accuracy=79.84% avg_sensitivity=55.03%, avg_specificity=88.10% avg_auc=83.30%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.195809 Test loss=0.450906 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.17954717576503754
[5/24] Train loss=0.1915728896856308
[10/24] Train loss=0.19390930235385895
[15/24] Train loss=0.177730530500412
[20/24] Train loss=0.17608006298542023
Test set avg_accuracy=79.95% avg_sensitivity=57.90%, avg_specificity=87.28% avg_auc=83.19%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.194649 Test loss=0.449594 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.17429225146770477
[5/24] Train loss=0.19418291747570038
[10/24] Train loss=0.1853247433900833
[15/24] Train loss=0.17734326422214508
[20/24] Train loss=0.17417621612548828
Test set avg_accuracy=80.23% avg_sensitivity=59.31%, avg_specificity=87.19% avg_auc=83.93%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.192958 Test loss=0.445286 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.17736604809761047
[5/24] Train loss=0.1909996122121811
[10/24] Train loss=0.18636344373226166
[15/24] Train loss=0.179320827126503
[20/24] Train loss=0.17231588065624237
Test set avg_accuracy=79.83% avg_sensitivity=57.17%, avg_specificity=87.37% avg_auc=83.24%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.191614 Test loss=0.454697 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1754566878080368
[5/24] Train loss=0.19066663086414337
[10/24] Train loss=0.18679732084274292
[15/24] Train loss=0.18060296773910522
[20/24] Train loss=0.17611584067344666
Test set avg_accuracy=79.96% avg_sensitivity=57.22%, avg_specificity=87.52% avg_auc=83.62%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.192261 Test loss=0.450054 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.17856350541114807
[5/24] Train loss=0.18879055976867676
[10/24] Train loss=0.1820034384727478
[15/24] Train loss=0.17804957926273346
[20/24] Train loss=0.17328345775604248
Test set avg_accuracy=80.07% avg_sensitivity=56.65%, avg_specificity=87.85% avg_auc=83.67%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.190917 Test loss=0.447927 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.17373308539390564
[5/24] Train loss=0.18992571532726288
[10/24] Train loss=0.18187128007411957
[15/24] Train loss=0.17545203864574432
[20/24] Train loss=0.17044323682785034
Test set avg_accuracy=80.03% avg_sensitivity=58.01%, avg_specificity=87.35% avg_auc=83.66%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.189679 Test loss=0.446928 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.17485463619232178
[5/24] Train loss=0.1910359114408493
[10/24] Train loss=0.1865059733390808
[15/24] Train loss=0.1771557331085205
[20/24] Train loss=0.17179171741008759
Test set avg_accuracy=80.05% avg_sensitivity=56.91%, avg_specificity=87.75% avg_auc=83.31%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.190152 Test loss=0.452079 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.16929112374782562
[5/24] Train loss=0.186619371175766
[10/24] Train loss=0.1809094250202179
[15/24] Train loss=0.1760113686323166
[20/24] Train loss=0.16971172392368317
Test set avg_accuracy=80.04% avg_sensitivity=56.76%, avg_specificity=87.78% avg_auc=83.57%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.188707 Test loss=0.448529 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.17450731992721558
[5/24] Train loss=0.18515005707740784
[10/24] Train loss=0.18565742671489716
[15/24] Train loss=0.1798173040151596
[20/24] Train loss=0.1695508360862732
Test set avg_accuracy=79.93% avg_sensitivity=57.22%, avg_specificity=87.49% avg_auc=83.49%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.188546 Test loss=0.450036 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.16824379563331604
[5/24] Train loss=0.1902262419462204
[10/24] Train loss=0.1796451061964035
[15/24] Train loss=0.17658811807632446
[20/24] Train loss=0.1711607426404953
Test set avg_accuracy=79.82% avg_sensitivity=57.38%, avg_specificity=87.28% avg_auc=83.48%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.188438 Test loss=0.450172 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.16965945065021515
[5/24] Train loss=0.18783815205097198
[10/24] Train loss=0.18179067969322205
[15/24] Train loss=0.17412790656089783
[20/24] Train loss=0.16907842457294464
Test set avg_accuracy=79.82% avg_sensitivity=57.38%, avg_specificity=87.28% avg_auc=83.49%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.188430 Test loss=0.449870 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.17396968603134155
[5/24] Train loss=0.18796537816524506
[10/24] Train loss=0.18109561502933502
[15/24] Train loss=0.17594751715660095
[20/24] Train loss=0.17641206085681915
Test set avg_accuracy=79.93% avg_sensitivity=57.17%, avg_specificity=87.51% avg_auc=83.51%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.188662 Test loss=0.449458 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.16949298977851868
[5/24] Train loss=0.18706464767456055
[10/24] Train loss=0.18111519515514374
[15/24] Train loss=0.1727384626865387
[20/24] Train loss=0.16910065710544586
Test set avg_accuracy=79.91% avg_sensitivity=57.17%, avg_specificity=87.47% avg_auc=83.48%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.187374 Test loss=0.449940 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.16878020763397217
[5/24] Train loss=0.18692649900913239
[10/24] Train loss=0.17897093296051025
[15/24] Train loss=0.17228178679943085
[20/24] Train loss=0.17007656395435333
Test set avg_accuracy=79.92% avg_sensitivity=57.12%, avg_specificity=87.51% avg_auc=83.48%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.188036 Test loss=0.449844 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.17187047004699707
[5/24] Train loss=0.18785499036312103
[10/24] Train loss=0.185527965426445
[15/24] Train loss=0.1711815595626831
[20/24] Train loss=0.17264533042907715
Test set avg_accuracy=80.09% avg_sensitivity=57.17%, avg_specificity=87.71% avg_auc=83.47%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.188897 Test loss=0.450049 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.17511391639709473
[5/24] Train loss=0.18317373096942902
[10/24] Train loss=0.18021616339683533
[15/24] Train loss=0.1765264868736267
[20/24] Train loss=0.17551836371421814
Test set avg_accuracy=79.99% avg_sensitivity=57.17%, avg_specificity=87.58% avg_auc=83.47%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.188471 Test loss=0.450113 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=80.66% sen=69.17%, spe=84.49%, auc=86.37%!
Fold[2] Avg_overlap=0.13%(0.22864490309325008)
[0/24] Train loss=0.7665298581123352
[5/24] Train loss=0.7586814761161804
[10/24] Train loss=0.7532587051391602
[15/24] Train loss=0.7393814325332642
[20/24] Train loss=0.7339717149734497
Test set avg_accuracy=54.60% avg_sensitivity=44.50%, avg_specificity=58.42% avg_auc=52.77%
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.749373 Test loss=0.687407 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7402265071868896
[5/24] Train loss=0.7331429123878479
[10/24] Train loss=0.7283822298049927
[15/24] Train loss=0.7204070091247559
[20/24] Train loss=0.7154027819633484
Test set avg_accuracy=61.74% avg_sensitivity=50.14%, avg_specificity=66.14% avg_auc=61.01%
Best model saved!! Metric=-86.95891471569655!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.728120 Test loss=0.646051 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7162885665893555
[5/24] Train loss=0.7275448441505432
[10/24] Train loss=0.7146382331848145
[15/24] Train loss=0.6978790760040283
[20/24] Train loss=0.6968386173248291
Test set avg_accuracy=64.02% avg_sensitivity=56.21%, avg_specificity=66.98% avg_auc=64.67%
Best model saved!! Metric=-74.11579859043027!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.713099 Test loss=0.637181 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6936248540878296
[5/24] Train loss=0.7109886407852173
[10/24] Train loss=0.7031625509262085
[15/24] Train loss=0.6867384910583496
[20/24] Train loss=0.6818214654922485
Test set avg_accuracy=65.65% avg_sensitivity=59.29%, avg_specificity=68.06% avg_auc=67.69%
Best model saved!! Metric=-65.30923129188756!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.694833 Test loss=0.627215 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6705633997917175
[5/24] Train loss=0.6892171502113342
[10/24] Train loss=0.6878616809844971
[15/24] Train loss=0.663969099521637
[20/24] Train loss=0.6531286835670471
Test set avg_accuracy=66.37% avg_sensitivity=61.90%, avg_specificity=68.06% avg_auc=70.14%
Best model saved!! Metric=-59.539965749891536!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.675367 Test loss=0.614114 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6579229235649109
[5/24] Train loss=0.6741665005683899
[10/24] Train loss=0.6671828031539917
[15/24] Train loss=0.6458237171173096
[20/24] Train loss=0.6312271952629089
Test set avg_accuracy=67.94% avg_sensitivity=62.32%, avg_specificity=70.07% avg_auc=71.95%
Best model saved!! Metric=-53.717165567982974!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.654639 Test loss=0.593682 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6320432424545288
[5/24] Train loss=0.654438316822052
[10/24] Train loss=0.6487348079681396
[15/24] Train loss=0.6193892359733582
[20/24] Train loss=0.6040642261505127
Test set avg_accuracy=70.10% avg_sensitivity=63.70%, avg_specificity=72.53% avg_auc=74.40%
Best model saved!! Metric=-45.26750962899304!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.631521 Test loss=0.569806 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6100327968597412
[5/24] Train loss=0.6292736530303955
[10/24] Train loss=0.6282403469085693
[15/24] Train loss=0.6013940572738647
[20/24] Train loss=0.5721914768218994
Test set avg_accuracy=73.36% avg_sensitivity=63.51%, avg_specificity=77.09% avg_auc=77.23%
Best model saved!! Metric=-34.81196860615009!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.606835 Test loss=0.536436 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5806918144226074
[5/24] Train loss=0.5999857783317566
[10/24] Train loss=0.5911683440208435
[15/24] Train loss=0.5669018030166626
[20/24] Train loss=0.5440775752067566
Test set avg_accuracy=75.10% avg_sensitivity=64.41%, avg_specificity=79.16% avg_auc=79.11%
Best model saved!! Metric=-28.22631909405213!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.577609 Test loss=0.514396 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5515705347061157
[5/24] Train loss=0.5723825097084045
[10/24] Train loss=0.5727149844169617
[15/24] Train loss=0.5418872833251953
[20/24] Train loss=0.5063838958740234
Test set avg_accuracy=76.95% avg_sensitivity=65.64%, avg_specificity=81.24% avg_auc=81.12%
Best model saved!! Metric=-21.04743657308535!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.550064 Test loss=0.494824 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5213081240653992
[5/24] Train loss=0.5361061096191406
[10/24] Train loss=0.5433744192123413
[15/24] Train loss=0.5065601468086243
[20/24] Train loss=0.47817403078079224
Test set avg_accuracy=78.32% avg_sensitivity=67.39%, avg_specificity=82.46% avg_auc=82.90%
Best model saved!! Metric=-14.926600975201453!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.520638 Test loss=0.473732 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.49693214893341064
[5/24] Train loss=0.5108809471130371
[10/24] Train loss=0.5275614261627197
[15/24] Train loss=0.47990965843200684
[20/24] Train loss=0.4500230848789215
Test set avg_accuracy=79.26% avg_sensitivity=64.12%, avg_specificity=84.99% avg_auc=84.03%
Best model saved!! Metric=-13.594834125881704!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.495600 Test loss=0.451771 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4740927517414093
[5/24] Train loss=0.4782320261001587
[10/24] Train loss=0.5070358514785767
[15/24] Train loss=0.45428723096847534
[20/24] Train loss=0.4255644977092743
Test set avg_accuracy=80.01% avg_sensitivity=64.12%, avg_specificity=86.03% avg_auc=84.50%
Best model saved!! Metric=-11.327785959999233!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.471251 Test loss=0.440772 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.451953262090683
[5/24] Train loss=0.45940324664115906
[10/24] Train loss=0.5011229515075684
[15/24] Train loss=0.4407373070716858
[20/24] Train loss=0.40692922472953796
Test set avg_accuracy=80.25% avg_sensitivity=63.93%, avg_specificity=86.43% avg_auc=85.58%
Best model saved!! Metric=-9.80886357939736!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.454513 Test loss=0.428284 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4395937919616699
[5/24] Train loss=0.436612606048584
[10/24] Train loss=0.4810423254966736
[15/24] Train loss=0.4203968942165375
[20/24] Train loss=0.3931031823158264
Test set avg_accuracy=80.43% avg_sensitivity=64.98%, avg_specificity=86.28% avg_auc=86.21%
Best model saved!! Metric=-8.097829581181358!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.439207 Test loss=0.420699 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4238353669643402
[5/24] Train loss=0.41863012313842773
[10/24] Train loss=0.4679252505302429
[15/24] Train loss=0.40886738896369934
[20/24] Train loss=0.38657528162002563
Test set avg_accuracy=80.92% avg_sensitivity=64.12%, avg_specificity=87.29% avg_auc=86.60%
Best model saved!! Metric=-7.060970985213359!!
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.426520 Test loss=0.410836 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.40928223729133606
[5/24] Train loss=0.40158969163894653
[10/24] Train loss=0.4622608721256256
[15/24] Train loss=0.39989861845970154
[20/24] Train loss=0.374294638633728
Test set avg_accuracy=80.95% avg_sensitivity=61.61%, avg_specificity=88.28% avg_auc=86.70%
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.414906 Test loss=0.404074 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3976017236709595
[5/24] Train loss=0.39590367674827576
[10/24] Train loss=0.458488792181015
[15/24] Train loss=0.39043569564819336
[20/24] Train loss=0.3610469400882721
Test set avg_accuracy=81.45% avg_sensitivity=63.36%, avg_specificity=88.29% avg_auc=87.13%
Best model saved!! Metric=-5.76882552785743!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.407232 Test loss=0.398009 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.39256203174591064
[5/24] Train loss=0.3890551030635834
[10/24] Train loss=0.4472280740737915
[15/24] Train loss=0.38725194334983826
[20/24] Train loss=0.3604884147644043
Test set avg_accuracy=81.29% avg_sensitivity=66.26%, avg_specificity=86.98% avg_auc=87.40%
Best model saved!! Metric=-4.0683021906668415!!
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.399707 Test loss=0.398122 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3810153007507324
[5/24] Train loss=0.3750550448894501
[10/24] Train loss=0.44066283106803894
[15/24] Train loss=0.3804534077644348
[20/24] Train loss=0.3482932448387146
Test set avg_accuracy=81.41% avg_sensitivity=69.24%, avg_specificity=86.01% avg_auc=87.64%
Best model saved!! Metric=-1.6933186097662798!!
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.392583 Test loss=0.405054 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.37999022006988525
[5/24] Train loss=0.36777764558792114
[10/24] Train loss=0.4339396059513092
[15/24] Train loss=0.3789147138595581
[20/24] Train loss=0.34102895855903625
Test set avg_accuracy=81.02% avg_sensitivity=70.81%, avg_specificity=84.88% avg_auc=87.55%
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.386825 Test loss=0.412592 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3706583082675934
[5/24] Train loss=0.35770246386528015
[10/24] Train loss=0.43476584553718567
[15/24] Train loss=0.3671634793281555
[20/24] Train loss=0.3366190195083618
Test set avg_accuracy=79.79% avg_sensitivity=73.32%, avg_specificity=82.24% avg_auc=86.49%
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.381283 Test loss=0.439727 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3717060387134552
[5/24] Train loss=0.3602709174156189
[10/24] Train loss=0.4359247386455536
[15/24] Train loss=0.3636817932128906
[20/24] Train loss=0.3347134590148926
Test set avg_accuracy=80.34% avg_sensitivity=72.99%, avg_specificity=83.12% avg_auc=87.01%
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.378590 Test loss=0.422172 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3696521818637848
[5/24] Train loss=0.3546535074710846
[10/24] Train loss=0.431262731552124
[15/24] Train loss=0.35366594791412354
[20/24] Train loss=0.326829731464386
Test set avg_accuracy=79.36% avg_sensitivity=74.50%, avg_specificity=81.20% avg_auc=86.00%
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.375673 Test loss=0.446509 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3624190092086792
[5/24] Train loss=0.3488360345363617
[10/24] Train loss=0.4266066551208496
[15/24] Train loss=0.35579437017440796
[20/24] Train loss=0.3255620002746582
Test set avg_accuracy=78.83% avg_sensitivity=73.65%, avg_specificity=80.79% avg_auc=85.41%
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.372214 Test loss=0.451311 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3613533079624176
[5/24] Train loss=0.34766829013824463
[10/24] Train loss=0.4280005991458893
[15/24] Train loss=0.3565289378166199
[20/24] Train loss=0.3257389962673187
Test set avg_accuracy=75.62% avg_sensitivity=75.97%, avg_specificity=75.49% avg_auc=83.70%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.369894 Test loss=0.491477 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.36490726470947266
[5/24] Train loss=0.34373196959495544
[10/24] Train loss=0.431143581867218
[15/24] Train loss=0.3460284173488617
[20/24] Train loss=0.3228089213371277
Test set avg_accuracy=79.52% avg_sensitivity=74.36%, avg_specificity=81.47% avg_auc=85.44%
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.367578 Test loss=0.452830 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3599538207054138
[5/24] Train loss=0.34960436820983887
[10/24] Train loss=0.413398802280426
[15/24] Train loss=0.3453359007835388
[20/24] Train loss=0.31861695647239685
Test set avg_accuracy=79.65% avg_sensitivity=72.61%, avg_specificity=82.32% avg_auc=85.88%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.365971 Test loss=0.435612 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3579927682876587
[5/24] Train loss=0.3431823253631592
[10/24] Train loss=0.4197401702404022
[15/24] Train loss=0.3501927852630615
[20/24] Train loss=0.32174307107925415
Test set avg_accuracy=80.12% avg_sensitivity=74.41%, avg_specificity=82.28% avg_auc=86.53%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.365447 Test loss=0.433837 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.35414940118789673
[5/24] Train loss=0.33919990062713623
[10/24] Train loss=0.42367422580718994
[15/24] Train loss=0.3441784679889679
[20/24] Train loss=0.31242042779922485
Test set avg_accuracy=82.08% avg_sensitivity=59.48%, avg_specificity=90.65% avg_auc=88.26%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.363123 Test loss=0.377871 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3532446026802063
[5/24] Train loss=0.3350605070590973
[10/24] Train loss=0.4114091992378235
[15/24] Train loss=0.34739264845848083
[20/24] Train loss=0.31293627619743347
Test set avg_accuracy=81.34% avg_sensitivity=65.31%, avg_specificity=87.41% avg_auc=87.48%
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.361283 Test loss=0.398199 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.35670414566993713
[5/24] Train loss=0.33469295501708984
[10/24] Train loss=0.41494232416152954
[15/24] Train loss=0.34592726826667786
[20/24] Train loss=0.3133436441421509
Test set avg_accuracy=80.69% avg_sensitivity=63.13%, avg_specificity=87.34% avg_auc=85.79%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.360591 Test loss=0.418079 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3525291085243225
[5/24] Train loss=0.33707576990127563
[10/24] Train loss=0.41885411739349365
[15/24] Train loss=0.3404756784439087
[20/24] Train loss=0.31004106998443604
Test set avg_accuracy=81.85% avg_sensitivity=59.86%, avg_specificity=90.18% avg_auc=87.86%
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.357559 Test loss=0.392335 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3488772213459015
[5/24] Train loss=0.34088441729545593
[10/24] Train loss=0.41735419631004333
[15/24] Train loss=0.3345484137535095
[20/24] Train loss=0.31087496876716614
Test set avg_accuracy=81.50% avg_sensitivity=62.89%, avg_specificity=88.55% avg_auc=87.06%
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.357725 Test loss=0.402130 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.34979012608528137
[5/24] Train loss=0.32694658637046814
[10/24] Train loss=0.408110648393631
[15/24] Train loss=0.33328598737716675
[20/24] Train loss=0.3062167763710022
Test set avg_accuracy=81.84% avg_sensitivity=51.42%, avg_specificity=93.36% avg_auc=88.12%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.355408 Test loss=0.386902 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3489043414592743
[5/24] Train loss=0.32673174142837524
[10/24] Train loss=0.4122729003429413
[15/24] Train loss=0.3310477137565613
[20/24] Train loss=0.30657416582107544
Test set avg_accuracy=80.59% avg_sensitivity=58.10%, avg_specificity=89.10% avg_auc=86.19%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.356441 Test loss=0.403615 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.34390512108802795
[5/24] Train loss=0.32789212465286255
[10/24] Train loss=0.41576674580574036
[15/24] Train loss=0.3332161009311676
[20/24] Train loss=0.30577030777931213
Test set avg_accuracy=80.09% avg_sensitivity=38.34%, avg_specificity=95.91% avg_auc=86.28%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.353069 Test loss=0.413041 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.34638240933418274
[5/24] Train loss=0.33018845319747925
[10/24] Train loss=0.40043801069259644
[15/24] Train loss=0.32227104902267456
[20/24] Train loss=0.30495861172676086
Test set avg_accuracy=78.01% avg_sensitivity=31.52%, avg_specificity=95.62% avg_auc=83.26%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.351536 Test loss=0.459131 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.34607914090156555
[5/24] Train loss=0.3304312527179718
[10/24] Train loss=0.41721293330192566
[15/24] Train loss=0.3309069573879242
[20/24] Train loss=0.3074435889720917
Test set avg_accuracy=81.64% avg_sensitivity=55.59%, avg_specificity=91.51% avg_auc=87.99%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.353885 Test loss=0.382894 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.34205108880996704
[5/24] Train loss=0.3242557644844055
[10/24] Train loss=0.40049490332603455
[15/24] Train loss=0.3334330916404724
[20/24] Train loss=0.310983806848526
Test set avg_accuracy=81.69% avg_sensitivity=56.82%, avg_specificity=91.11% avg_auc=87.25%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.350445 Test loss=0.392651 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.34018993377685547
[5/24] Train loss=0.3250855505466461
[10/24] Train loss=0.4006025195121765
[15/24] Train loss=0.3326408267021179
[20/24] Train loss=0.30884087085723877
Test set avg_accuracy=81.03% avg_sensitivity=50.76%, avg_specificity=92.50% avg_auc=87.65%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.350869 Test loss=0.389818 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3374534547328949
[5/24] Train loss=0.3358084559440613
[10/24] Train loss=0.40923500061035156
[15/24] Train loss=0.33388105034828186
[20/24] Train loss=0.30882906913757324
Test set avg_accuracy=78.07% avg_sensitivity=54.93%, avg_specificity=86.84% avg_auc=82.17%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.351485 Test loss=0.448794 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3489535450935364
[5/24] Train loss=0.32695603370666504
[10/24] Train loss=0.40839624404907227
[15/24] Train loss=0.3257718086242676
[20/24] Train loss=0.30421483516693115
Test set avg_accuracy=80.81% avg_sensitivity=46.02%, avg_specificity=93.99% avg_auc=86.21%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.349232 Test loss=0.410076 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3357747793197632
[5/24] Train loss=0.32698461413383484
[10/24] Train loss=0.4106166660785675
[15/24] Train loss=0.3279607892036438
[20/24] Train loss=0.3013922870159149
Test set avg_accuracy=80.48% avg_sensitivity=53.03%, avg_specificity=90.88% avg_auc=83.87%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.349179 Test loss=0.432134 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3321944773197174
[5/24] Train loss=0.3228212893009186
[10/24] Train loss=0.41197776794433594
[15/24] Train loss=0.32465028762817383
[20/24] Train loss=0.3044262230396271
Test set avg_accuracy=78.57% avg_sensitivity=62.09%, avg_specificity=84.81% avg_auc=83.23%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.347882 Test loss=0.449965 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.33365780115127563
[5/24] Train loss=0.3138158917427063
[10/24] Train loss=0.4004526734352112
[15/24] Train loss=0.32096800208091736
[20/24] Train loss=0.3026593327522278
Test set avg_accuracy=80.98% avg_sensitivity=46.02%, avg_specificity=94.22% avg_auc=87.69%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.344738 Test loss=0.393581 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3371393382549286
[5/24] Train loss=0.3256273567676544
[10/24] Train loss=0.4114353358745575
[15/24] Train loss=0.3213485777378082
[20/24] Train loss=0.3019126355648041
Test set avg_accuracy=76.89% avg_sensitivity=20.90%, avg_specificity=98.10% avg_auc=83.94%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.347258 Test loss=0.470006 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3339024484157562
[5/24] Train loss=0.3289168179035187
[10/24] Train loss=0.40057826042175293
[15/24] Train loss=0.320891410112381
[20/24] Train loss=0.29969170689582825
Test set avg_accuracy=78.66% avg_sensitivity=46.78%, avg_specificity=90.74% avg_auc=83.13%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.345613 Test loss=0.450469 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.32909730076789856
[5/24] Train loss=0.32208412885665894
[10/24] Train loss=0.3981369137763977
[15/24] Train loss=0.3230765759944916
[20/24] Train loss=0.29774802923202515
Test set avg_accuracy=79.18% avg_sensitivity=30.76%, avg_specificity=97.52% avg_auc=86.64%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.346642 Test loss=0.418112 Current lr=[0.000298904600941902]

[0/24] Train loss=0.34021493792533875
[5/24] Train loss=0.3289855420589447
[10/24] Train loss=0.3977225124835968
[15/24] Train loss=0.3171813488006592
[20/24] Train loss=0.3014109432697296
Test set avg_accuracy=79.91% avg_sensitivity=43.55%, avg_specificity=93.68% avg_auc=85.58%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.344300 Test loss=0.416882 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.33549341559410095
[5/24] Train loss=0.32319173216819763
[10/24] Train loss=0.4082910716533661
[15/24] Train loss=0.31977227330207825
[20/24] Train loss=0.3007484972476959
Test set avg_accuracy=80.13% avg_sensitivity=57.58%, avg_specificity=88.67% avg_auc=85.82%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.345762 Test loss=0.415671 Current lr=[0.000297555943323901]

[0/24] Train loss=0.33728575706481934
[5/24] Train loss=0.3167491555213928
[10/24] Train loss=0.4018228054046631
[15/24] Train loss=0.3152548670768738
[20/24] Train loss=0.29724013805389404
Test set avg_accuracy=81.61% avg_sensitivity=56.11%, avg_specificity=91.27% avg_auc=86.90%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.341977 Test loss=0.416874 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.32168713212013245
[5/24] Train loss=0.32397812604904175
[10/24] Train loss=0.3974042534828186
[15/24] Train loss=0.3269115686416626
[20/24] Train loss=0.3021007180213928
Test set avg_accuracy=79.51% avg_sensitivity=35.83%, avg_specificity=96.05% avg_auc=85.71%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.343276 Test loss=0.423050 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.32058849930763245
[5/24] Train loss=0.3193712532520294
[10/24] Train loss=0.41179484128952026
[15/24] Train loss=0.31664761900901794
[20/24] Train loss=0.30086594820022583
Test set avg_accuracy=81.46% avg_sensitivity=61.33%, avg_specificity=89.08% avg_auc=87.15%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.341724 Test loss=0.410101 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3329268991947174
[5/24] Train loss=0.32141804695129395
[10/24] Train loss=0.39435404539108276
[15/24] Train loss=0.32140082120895386
[20/24] Train loss=0.2992171049118042
Test set avg_accuracy=81.56% avg_sensitivity=62.42%, avg_specificity=88.82% avg_auc=87.17%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.340001 Test loss=0.404573 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3185461759567261
[5/24] Train loss=0.3218185603618622
[10/24] Train loss=0.38962459564208984
[15/24] Train loss=0.3164099454879761
[20/24] Train loss=0.2953367531299591
Test set avg_accuracy=81.08% avg_sensitivity=54.88%, avg_specificity=91.01% avg_auc=82.91%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.336162 Test loss=0.442183 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.33251631259918213
[5/24] Train loss=0.323234885931015
[10/24] Train loss=0.39191073179244995
[15/24] Train loss=0.3350217938423157
[20/24] Train loss=0.30583110451698303
Test set avg_accuracy=80.05% avg_sensitivity=37.16%, avg_specificity=96.30% avg_auc=87.09%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.341120 Test loss=0.405584 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3252621591091156
[5/24] Train loss=0.3163319528102875
[10/24] Train loss=0.3908417224884033
[15/24] Train loss=0.32686567306518555
[20/24] Train loss=0.3018638789653778
Test set avg_accuracy=77.76% avg_sensitivity=25.26%, avg_specificity=97.65% avg_auc=84.76%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.339682 Test loss=0.449347 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3328651189804077
[5/24] Train loss=0.31763097643852234
[10/24] Train loss=0.40084314346313477
[15/24] Train loss=0.31941884756088257
[20/24] Train loss=0.2991192042827606
Test set avg_accuracy=81.35% avg_sensitivity=50.33%, avg_specificity=93.11% avg_auc=87.66%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.340061 Test loss=0.388274 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.32263967394828796
[5/24] Train loss=0.31221017241477966
[10/24] Train loss=0.3963282108306885
[15/24] Train loss=0.3131393790245056
[20/24] Train loss=0.28990569710731506
Test set avg_accuracy=82.14% avg_sensitivity=55.45%, avg_specificity=92.24% avg_auc=87.41%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.335261 Test loss=0.390327 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.31732457876205444
[5/24] Train loss=0.31422001123428345
[10/24] Train loss=0.4018144905567169
[15/24] Train loss=0.3112303614616394
[20/24] Train loss=0.2935400903224945
Test set avg_accuracy=79.31% avg_sensitivity=39.81%, avg_specificity=94.27% avg_auc=83.94%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.337729 Test loss=0.436219 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.31076517701148987
[5/24] Train loss=0.31366991996765137
[10/24] Train loss=0.39580652117729187
[15/24] Train loss=0.31683549284935
[20/24] Train loss=0.299178808927536
Test set avg_accuracy=81.43% avg_sensitivity=57.77%, avg_specificity=90.39% avg_auc=86.82%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.335010 Test loss=0.406225 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3233042061328888
[5/24] Train loss=0.3175761103630066
[10/24] Train loss=0.3944395184516907
[15/24] Train loss=0.30823200941085815
[20/24] Train loss=0.2910667657852173
Test set avg_accuracy=81.98% avg_sensitivity=59.19%, avg_specificity=90.61% avg_auc=86.82%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.337054 Test loss=0.395602 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.31699392199516296
[5/24] Train loss=0.3141759932041168
[10/24] Train loss=0.3909098505973816
[15/24] Train loss=0.31995877623558044
[20/24] Train loss=0.29978203773498535
Test set avg_accuracy=81.07% avg_sensitivity=66.54%, avg_specificity=86.57% avg_auc=86.66%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.334344 Test loss=0.408380 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3239384591579437
[5/24] Train loss=0.32026681303977966
[10/24] Train loss=0.39577943086624146
[15/24] Train loss=0.3180682063102722
[20/24] Train loss=0.28575387597084045
Test set avg_accuracy=81.54% avg_sensitivity=65.07%, avg_specificity=87.77% avg_auc=87.59%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.335615 Test loss=0.387709 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3181181848049164
[5/24] Train loss=0.3133460581302643
[10/24] Train loss=0.3896205723285675
[15/24] Train loss=0.3116530179977417
[20/24] Train loss=0.28967735171318054
Test set avg_accuracy=80.12% avg_sensitivity=59.05%, avg_specificity=88.10% avg_auc=84.65%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.331880 Test loss=0.422385 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3186688721179962
[5/24] Train loss=0.31189045310020447
[10/24] Train loss=0.3979721665382385
[15/24] Train loss=0.3122961223125458
[20/24] Train loss=0.29620128870010376
Test set avg_accuracy=81.58% avg_sensitivity=63.32%, avg_specificity=88.49% avg_auc=86.92%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.331909 Test loss=0.399609 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.31003832817077637
[5/24] Train loss=0.3059661388397217
[10/24] Train loss=0.3841423988342285
[15/24] Train loss=0.30998125672340393
[20/24] Train loss=0.28963595628738403
Test set avg_accuracy=80.74% avg_sensitivity=57.11%, avg_specificity=89.69% avg_auc=87.08%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.329921 Test loss=0.393723 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.31049883365631104
[5/24] Train loss=0.30700618028640747
[10/24] Train loss=0.39216265082359314
[15/24] Train loss=0.30650800466537476
[20/24] Train loss=0.2921834886074066
Test set avg_accuracy=80.26% avg_sensitivity=66.68%, avg_specificity=85.40% avg_auc=84.73%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.331077 Test loss=0.430520 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3167252242565155
[5/24] Train loss=0.3149683177471161
[10/24] Train loss=0.38228127360343933
[15/24] Train loss=0.30156129598617554
[20/24] Train loss=0.2927369177341461
Test set avg_accuracy=81.56% avg_sensitivity=63.08%, avg_specificity=88.56% avg_auc=87.45%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.328844 Test loss=0.395649 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.31695571541786194
[5/24] Train loss=0.31767427921295166
[10/24] Train loss=0.3813416361808777
[15/24] Train loss=0.3054172098636627
[20/24] Train loss=0.2904597818851471
Test set avg_accuracy=81.84% avg_sensitivity=60.28%, avg_specificity=90.00% avg_auc=87.19%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.327998 Test loss=0.399942 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3102342188358307
[5/24] Train loss=0.3067708909511566
[10/24] Train loss=0.3890460729598999
[15/24] Train loss=0.31178393959999084
[20/24] Train loss=0.30168744921684265
Test set avg_accuracy=55.66% avg_sensitivity=74.17%, avg_specificity=48.65% avg_auc=70.30%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.329391 Test loss=0.687598 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3265637159347534
[5/24] Train loss=0.316302090883255
[10/24] Train loss=0.37790295481681824
[15/24] Train loss=0.30090248584747314
[20/24] Train loss=0.29735127091407776
Test set avg_accuracy=79.56% avg_sensitivity=64.08%, avg_specificity=85.42% avg_auc=84.40%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.327495 Test loss=0.440133 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3133547008037567
[5/24] Train loss=0.316501647233963
[10/24] Train loss=0.39197617769241333
[15/24] Train loss=0.31166312098503113
[20/24] Train loss=0.31124624609947205
Test set avg_accuracy=82.37% avg_sensitivity=65.26%, avg_specificity=88.85% avg_auc=86.11%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.330583 Test loss=0.422680 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.30894821882247925
[5/24] Train loss=0.3030165433883667
[10/24] Train loss=0.38758915662765503
[15/24] Train loss=0.30703169107437134
[20/24] Train loss=0.30146023631095886
Test set avg_accuracy=81.55% avg_sensitivity=62.80%, avg_specificity=88.65% avg_auc=86.57%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.324109 Test loss=0.405641 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3050990402698517
[5/24] Train loss=0.30882957577705383
[10/24] Train loss=0.3887232542037964
[15/24] Train loss=0.3022220730781555
[20/24] Train loss=0.29792729020118713
Test set avg_accuracy=79.35% avg_sensitivity=63.51%, avg_specificity=85.35% avg_auc=82.78%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.323814 Test loss=0.468855 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.31185704469680786
[5/24] Train loss=0.3034927546977997
[10/24] Train loss=0.3808492124080658
[15/24] Train loss=0.3015822470188141
[20/24] Train loss=0.2975400388240814
Test set avg_accuracy=81.46% avg_sensitivity=62.75%, avg_specificity=88.55% avg_auc=87.50%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.321892 Test loss=0.389784 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3148801028728485
[5/24] Train loss=0.2999507486820221
[10/24] Train loss=0.3829801678657532
[15/24] Train loss=0.3117614984512329
[20/24] Train loss=0.2958470582962036
Test set avg_accuracy=80.46% avg_sensitivity=44.31%, avg_specificity=94.15% avg_auc=84.86%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.321608 Test loss=0.421440 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3065560758113861
[5/24] Train loss=0.2989007532596588
[10/24] Train loss=0.38268187642097473
[15/24] Train loss=0.2960856258869171
[20/24] Train loss=0.3132878839969635
Test set avg_accuracy=80.65% avg_sensitivity=51.28%, avg_specificity=91.78% avg_auc=86.96%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.319001 Test loss=0.405384 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3096272349357605
[5/24] Train loss=0.29325708746910095
[10/24] Train loss=0.37470898032188416
[15/24] Train loss=0.2959265410900116
[20/24] Train loss=0.2966485321521759
Test set avg_accuracy=80.14% avg_sensitivity=41.90%, avg_specificity=94.63% avg_auc=84.89%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.316801 Test loss=0.440135 Current lr=[0.000224838296036774]

[0/24] Train loss=0.30062583088874817
[5/24] Train loss=0.30054527521133423
[10/24] Train loss=0.36927106976509094
[15/24] Train loss=0.29577192664146423
[20/24] Train loss=0.29958784580230713
Test set avg_accuracy=81.42% avg_sensitivity=57.58%, avg_specificity=90.45% avg_auc=87.67%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.317871 Test loss=0.385706 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2986415922641754
[5/24] Train loss=0.30375176668167114
[10/24] Train loss=0.375063419342041
[15/24] Train loss=0.307428240776062
[20/24] Train loss=0.3015771806240082
Test set avg_accuracy=79.38% avg_sensitivity=45.50%, avg_specificity=92.21% avg_auc=84.77%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.319024 Test loss=0.430609 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.29320231080055237
[5/24] Train loss=0.2870818078517914
[10/24] Train loss=0.36727359890937805
[15/24] Train loss=0.30253881216049194
[20/24] Train loss=0.3014758825302124
Test set avg_accuracy=81.77% avg_sensitivity=60.62%, avg_specificity=89.78% avg_auc=87.48%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.317841 Test loss=0.391123 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.29051268100738525
[5/24] Train loss=0.2885531783103943
[10/24] Train loss=0.3767644762992859
[15/24] Train loss=0.299431174993515
[20/24] Train loss=0.28741148114204407
Test set avg_accuracy=80.53% avg_sensitivity=46.68%, avg_specificity=93.36% avg_auc=85.93%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.311865 Test loss=0.410239 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.29360753297805786
[5/24] Train loss=0.2976669371128082
[10/24] Train loss=0.37502264976501465
[15/24] Train loss=0.30384162068367004
[20/24] Train loss=0.27984729409217834
Test set avg_accuracy=81.09% avg_sensitivity=53.03%, avg_specificity=91.72% avg_auc=86.35%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.312812 Test loss=0.410603 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.28756090998649597
[5/24] Train loss=0.288301557302475
[10/24] Train loss=0.35879746079444885
[15/24] Train loss=0.3004485070705414
[20/24] Train loss=0.2892872989177704
Test set avg_accuracy=80.44% avg_sensitivity=45.88%, avg_specificity=93.54% avg_auc=85.18%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.307837 Test loss=0.426260 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2919846475124359
[5/24] Train loss=0.28725868463516235
[10/24] Train loss=0.3691977262496948
[15/24] Train loss=0.2959483563899994
[20/24] Train loss=0.28079548478126526
Test set avg_accuracy=80.64% avg_sensitivity=51.75%, avg_specificity=91.58% avg_auc=85.96%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.305094 Test loss=0.407690 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2818167507648468
[5/24] Train loss=0.2769950330257416
[10/24] Train loss=0.349319726228714
[15/24] Train loss=0.2856317460536957
[20/24] Train loss=0.2873099744319916
Test set avg_accuracy=81.35% avg_sensitivity=64.36%, avg_specificity=87.79% avg_auc=87.40%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.301333 Test loss=0.389763 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.28581932187080383
[5/24] Train loss=0.28393784165382385
[10/24] Train loss=0.36394309997558594
[15/24] Train loss=0.293599009513855
[20/24] Train loss=0.2841666638851166
Test set avg_accuracy=79.91% avg_sensitivity=67.91%, avg_specificity=84.45% avg_auc=86.24%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.301339 Test loss=0.410664 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.28987109661102295
[5/24] Train loss=0.2904873192310333
[10/24] Train loss=0.3494024872779846
[15/24] Train loss=0.2912820875644684
[20/24] Train loss=0.2733097970485687
Test set avg_accuracy=80.94% avg_sensitivity=54.17%, avg_specificity=91.08% avg_auc=85.71%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.301311 Test loss=0.412224 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.29362723231315613
[5/24] Train loss=0.27809980511665344
[10/24] Train loss=0.3492453694343567
[15/24] Train loss=0.2919595539569855
[20/24] Train loss=0.28073397278785706
Test set avg_accuracy=79.56% avg_sensitivity=37.63%, avg_specificity=95.44% avg_auc=84.38%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.300015 Test loss=0.444215 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2831123471260071
[5/24] Train loss=0.2874731719493866
[10/24] Train loss=0.3402974307537079
[15/24] Train loss=0.28016844391822815
[20/24] Train loss=0.2849852442741394
Test set avg_accuracy=79.62% avg_sensitivity=41.28%, avg_specificity=94.15% avg_auc=82.44%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.296968 Test loss=0.454060 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.28186535835266113
[5/24] Train loss=0.28610503673553467
[10/24] Train loss=0.34816184639930725
[15/24] Train loss=0.2918294370174408
[20/24] Train loss=0.28361883759498596
Test set avg_accuracy=81.08% avg_sensitivity=61.18%, avg_specificity=88.62% avg_auc=86.77%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.298554 Test loss=0.400441 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.28768566250801086
[5/24] Train loss=0.27552568912506104
[10/24] Train loss=0.33662378787994385
[15/24] Train loss=0.2752930521965027
[20/24] Train loss=0.2828245162963867
Test set avg_accuracy=80.79% avg_sensitivity=46.35%, avg_specificity=93.84% avg_auc=84.72%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.293557 Test loss=0.437972 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2926771938800812
[5/24] Train loss=0.2735253572463989
[10/24] Train loss=0.33819612860679626
[15/24] Train loss=0.28128403425216675
[20/24] Train loss=0.2761818766593933
Test set avg_accuracy=80.30% avg_sensitivity=47.35%, avg_specificity=92.78% avg_auc=84.65%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.293303 Test loss=0.445025 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2754298150539398
[5/24] Train loss=0.2742808759212494
[10/24] Train loss=0.33999818563461304
[15/24] Train loss=0.2729729413986206
[20/24] Train loss=0.2796797454357147
Test set avg_accuracy=77.57% avg_sensitivity=30.95%, avg_specificity=95.22% avg_auc=80.81%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.290822 Test loss=0.507377 Current lr=[0.000156543481933168]

[0/24] Train loss=0.27401816844940186
[5/24] Train loss=0.27586591243743896
[10/24] Train loss=0.34677189588546753
[15/24] Train loss=0.275389164686203
[20/24] Train loss=0.2795054316520691
Test set avg_accuracy=80.53% avg_sensitivity=48.72%, avg_specificity=92.59% avg_auc=85.38%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.290642 Test loss=0.428797 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2660311460494995
[5/24] Train loss=0.2769545018672943
[10/24] Train loss=0.32021674513816833
[15/24] Train loss=0.2796423137187958
[20/24] Train loss=0.27277132868766785
Test set avg_accuracy=77.98% avg_sensitivity=29.15%, avg_specificity=96.48% avg_auc=79.09%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.285476 Test loss=0.520552 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2775404751300812
[5/24] Train loss=0.268547385931015
[10/24] Train loss=0.3219681680202484
[15/24] Train loss=0.2664410173892975
[20/24] Train loss=0.269113689661026
Test set avg_accuracy=80.53% avg_sensitivity=47.30%, avg_specificity=93.12% avg_auc=84.39%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.281544 Test loss=0.427970 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.26880156993865967
[5/24] Train loss=0.2702960968017578
[10/24] Train loss=0.3096429407596588
[15/24] Train loss=0.28442904353141785
[20/24] Train loss=0.2662104666233063
Test set avg_accuracy=80.77% avg_sensitivity=60.47%, avg_specificity=88.46% avg_auc=86.55%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.279546 Test loss=0.405839 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.26856163144111633
[5/24] Train loss=0.25874266028404236
[10/24] Train loss=0.31508713960647583
[15/24] Train loss=0.2649999260902405
[20/24] Train loss=0.266215443611145
Test set avg_accuracy=80.66% avg_sensitivity=47.87%, avg_specificity=93.09% avg_auc=85.21%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.276488 Test loss=0.434126 Current lr=[0.000134135431043539]

[0/24] Train loss=0.2655079662799835
[5/24] Train loss=0.25511789321899414
[10/24] Train loss=0.32791444659233093
[15/24] Train loss=0.2643197178840637
[20/24] Train loss=0.26344531774520874
Test set avg_accuracy=79.93% avg_sensitivity=48.58%, avg_specificity=91.81% avg_auc=84.91%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.279075 Test loss=0.425841 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.2577448785305023
[5/24] Train loss=0.2640379071235657
[10/24] Train loss=0.3214738368988037
[15/24] Train loss=0.26679497957229614
[20/24] Train loss=0.2570103406906128
Test set avg_accuracy=81.08% avg_sensitivity=56.11%, avg_specificity=90.54% avg_auc=86.15%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.274272 Test loss=0.409876 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2506990432739258
[5/24] Train loss=0.2594892084598541
[10/24] Train loss=0.3162618577480316
[15/24] Train loss=0.25891372561454773
[20/24] Train loss=0.2529868185520172
Test set avg_accuracy=80.43% avg_sensitivity=43.74%, avg_specificity=94.33% avg_auc=84.03%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.268821 Test loss=0.458714 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.2511187195777893
[5/24] Train loss=0.25515854358673096
[10/24] Train loss=0.3032076358795166
[15/24] Train loss=0.25759178400039673
[20/24] Train loss=0.2603597044944763
Test set avg_accuracy=80.86% avg_sensitivity=56.11%, avg_specificity=90.23% avg_auc=86.22%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.264919 Test loss=0.414700 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.2423456460237503
[5/24] Train loss=0.24311012029647827
[10/24] Train loss=0.3158046007156372
[15/24] Train loss=0.2611747086048126
[20/24] Train loss=0.25087636709213257
Test set avg_accuracy=80.48% avg_sensitivity=47.39%, avg_specificity=93.02% avg_auc=84.70%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.262547 Test loss=0.442655 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.2506677806377411
[5/24] Train loss=0.25426816940307617
[10/24] Train loss=0.28660935163497925
[15/24] Train loss=0.26132962107658386
[20/24] Train loss=0.24845203757286072
Test set avg_accuracy=80.81% avg_sensitivity=59.34%, avg_specificity=88.94% avg_auc=86.62%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.259851 Test loss=0.403219 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.246331125497818
[5/24] Train loss=0.23780417442321777
[10/24] Train loss=0.29707953333854675
[15/24] Train loss=0.25475916266441345
[20/24] Train loss=0.2504834532737732
Test set avg_accuracy=80.21% avg_sensitivity=47.96%, avg_specificity=92.42% avg_auc=85.77%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.256677 Test loss=0.433115 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.2411583960056305
[5/24] Train loss=0.23928532004356384
[10/24] Train loss=0.29306158423423767
[15/24] Train loss=0.25206005573272705
[20/24] Train loss=0.2505306303501129
Test set avg_accuracy=79.77% avg_sensitivity=42.84%, avg_specificity=93.75% avg_auc=84.43%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.252867 Test loss=0.455175 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.24538813531398773
[5/24] Train loss=0.2426702380180359
[10/24] Train loss=0.28838613629341125
[15/24] Train loss=0.24718213081359863
[20/24] Train loss=0.2435821145772934
Test set avg_accuracy=80.49% avg_sensitivity=58.53%, avg_specificity=88.82% avg_auc=86.31%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.251349 Test loss=0.408764 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.2378881871700287
[5/24] Train loss=0.2287287563085556
[10/24] Train loss=0.2860165536403656
[15/24] Train loss=0.24911291897296906
[20/24] Train loss=0.2512548267841339
Test set avg_accuracy=80.48% avg_sensitivity=53.55%, avg_specificity=90.68% avg_auc=85.72%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.246090 Test loss=0.421473 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.23191122710704803
[5/24] Train loss=0.23279355466365814
[10/24] Train loss=0.2896466553211212
[15/24] Train loss=0.24087530374526978
[20/24] Train loss=0.23862573504447937
Test set avg_accuracy=80.16% avg_sensitivity=57.30%, avg_specificity=88.82% avg_auc=85.90%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.244104 Test loss=0.420862 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.23033437132835388
[5/24] Train loss=0.22874568402767181
[10/24] Train loss=0.2845507860183716
[15/24] Train loss=0.24774384498596191
[20/24] Train loss=0.24112963676452637
Test set avg_accuracy=80.76% avg_sensitivity=54.83%, avg_specificity=90.57% avg_auc=86.15%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.240661 Test loss=0.418680 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.2253429889678955
[5/24] Train loss=0.21556247770786285
[10/24] Train loss=0.28009721636772156
[15/24] Train loss=0.23913684487342834
[20/24] Train loss=0.23035995662212372
Test set avg_accuracy=80.91% avg_sensitivity=55.31%, avg_specificity=90.61% avg_auc=84.78%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.238487 Test loss=0.427810 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.2312229424715042
[5/24] Train loss=0.21749922633171082
[10/24] Train loss=0.2763165533542633
[15/24] Train loss=0.23960022628307343
[20/24] Train loss=0.23512865602970123
Test set avg_accuracy=80.78% avg_sensitivity=49.57%, avg_specificity=92.60% avg_auc=84.06%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.235542 Test loss=0.449771 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.22173993289470673
[5/24] Train loss=0.21607190370559692
[10/24] Train loss=0.2641882300376892
[15/24] Train loss=0.22873756289482117
[20/24] Train loss=0.22924509644508362
Test set avg_accuracy=79.52% avg_sensitivity=40.47%, avg_specificity=94.31% avg_auc=80.78%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.232753 Test loss=0.500645 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.2185893952846527
[5/24] Train loss=0.22259196639060974
[10/24] Train loss=0.25450703501701355
[15/24] Train loss=0.22992876172065735
[20/24] Train loss=0.22203433513641357
Test set avg_accuracy=79.74% avg_sensitivity=44.83%, avg_specificity=92.96% avg_auc=83.26%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.230515 Test loss=0.459694 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.2215641438961029
[5/24] Train loss=0.2211153209209442
[10/24] Train loss=0.25946587324142456
[15/24] Train loss=0.23577657341957092
[20/24] Train loss=0.22515957057476044
Test set avg_accuracy=80.17% avg_sensitivity=48.67%, avg_specificity=92.10% avg_auc=84.64%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.229041 Test loss=0.445005 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.21333329379558563
[5/24] Train loss=0.21746830642223358
[10/24] Train loss=0.2526701092720032
[15/24] Train loss=0.22307813167572021
[20/24] Train loss=0.2246677428483963
Test set avg_accuracy=81.13% avg_sensitivity=57.91%, avg_specificity=89.93% avg_auc=86.16%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.226167 Test loss=0.418472 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.21103888750076294
[5/24] Train loss=0.20515130460262299
[10/24] Train loss=0.25168997049331665
[15/24] Train loss=0.2236694097518921
[20/24] Train loss=0.22317804396152496
Test set avg_accuracy=80.22% avg_sensitivity=54.69%, avg_specificity=89.89% avg_auc=85.68%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.221638 Test loss=0.423743 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.21258869767189026
[5/24] Train loss=0.21569044888019562
[10/24] Train loss=0.25612351298332214
[15/24] Train loss=0.2232445925474167
[20/24] Train loss=0.21935616433620453
Test set avg_accuracy=80.36% avg_sensitivity=61.85%, avg_specificity=87.38% avg_auc=86.07%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.220316 Test loss=0.419235 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.21694545447826385
[5/24] Train loss=0.20782750844955444
[10/24] Train loss=0.2504667639732361
[15/24] Train loss=0.2142331898212433
[20/24] Train loss=0.21858417987823486
Test set avg_accuracy=80.91% avg_sensitivity=59.95%, avg_specificity=88.85% avg_auc=86.10%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.218230 Test loss=0.418680 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.20962415635585785
[5/24] Train loss=0.20033028721809387
[10/24] Train loss=0.2456216961145401
[15/24] Train loss=0.21944411098957062
[20/24] Train loss=0.21284419298171997
Test set avg_accuracy=80.72% avg_sensitivity=56.97%, avg_specificity=89.71% avg_auc=85.07%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.213883 Test loss=0.433265 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.20563380420207977
[5/24] Train loss=0.19428542256355286
[10/24] Train loss=0.24367745220661163
[15/24] Train loss=0.2090815007686615
[20/24] Train loss=0.2133282870054245
Test set avg_accuracy=80.90% avg_sensitivity=61.47%, avg_specificity=88.26% avg_auc=85.62%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.210332 Test loss=0.427553 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.20279961824417114
[5/24] Train loss=0.1946174055337906
[10/24] Train loss=0.23647122085094452
[15/24] Train loss=0.20582729578018188
[20/24] Train loss=0.21360339224338531
Test set avg_accuracy=80.79% avg_sensitivity=57.30%, avg_specificity=89.69% avg_auc=85.08%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.207140 Test loss=0.437133 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.20076386630535126
[5/24] Train loss=0.1948290765285492
[10/24] Train loss=0.23006786406040192
[15/24] Train loss=0.21208104491233826
[20/24] Train loss=0.20624086260795593
Test set avg_accuracy=80.09% avg_sensitivity=57.25%, avg_specificity=88.74% avg_auc=84.32%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.207024 Test loss=0.447086 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.20009490847587585
[5/24] Train loss=0.19074809551239014
[10/24] Train loss=0.2245848923921585
[15/24] Train loss=0.20451559126377106
[20/24] Train loss=0.20873010158538818
Test set avg_accuracy=79.67% avg_sensitivity=49.05%, avg_specificity=91.27% avg_auc=82.84%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.204935 Test loss=0.471784 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.19868235290050507
[5/24] Train loss=0.18531015515327454
[10/24] Train loss=0.22121722996234894
[15/24] Train loss=0.20782367885112762
[20/24] Train loss=0.20713400840759277
Test set avg_accuracy=79.83% avg_sensitivity=52.51%, avg_specificity=90.18% avg_auc=84.07%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.201768 Test loss=0.458509 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.19351238012313843
[5/24] Train loss=0.1913272589445114
[10/24] Train loss=0.23169554769992828
[15/24] Train loss=0.20511820912361145
[20/24] Train loss=0.19810369610786438
Test set avg_accuracy=79.92% avg_sensitivity=54.31%, avg_specificity=89.62% avg_auc=84.28%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.200563 Test loss=0.446920 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.19501081109046936
[5/24] Train loss=0.1807360202074051
[10/24] Train loss=0.22162173688411713
[15/24] Train loss=0.20462626218795776
[20/24] Train loss=0.1970389187335968
Test set avg_accuracy=80.09% avg_sensitivity=53.36%, avg_specificity=90.22% avg_auc=83.72%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.198048 Test loss=0.449623 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.19012436270713806
[5/24] Train loss=0.19376784563064575
[10/24] Train loss=0.2278273105621338
[15/24] Train loss=0.21083775162696838
[20/24] Train loss=0.1958998739719391
Test set avg_accuracy=79.67% avg_sensitivity=53.32%, avg_specificity=89.66% avg_auc=83.69%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.197568 Test loss=0.451687 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.18456211686134338
[5/24] Train loss=0.18578340113162994
[10/24] Train loss=0.21938496828079224
[15/24] Train loss=0.19490042328834534
[20/24] Train loss=0.19958817958831787
Test set avg_accuracy=80.51% avg_sensitivity=56.26%, avg_specificity=89.69% avg_auc=84.34%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.194010 Test loss=0.444598 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1859273761510849
[5/24] Train loss=0.1776454746723175
[10/24] Train loss=0.2190103381872177
[15/24] Train loss=0.19908450543880463
[20/24] Train loss=0.19417494535446167
Test set avg_accuracy=80.20% avg_sensitivity=54.79%, avg_specificity=89.82% avg_auc=84.15%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.192522 Test loss=0.447575 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1876271814107895
[5/24] Train loss=0.17827504873275757
[10/24] Train loss=0.21654340624809265
[15/24] Train loss=0.19394223392009735
[20/24] Train loss=0.19374069571495056
Test set avg_accuracy=79.95% avg_sensitivity=55.31%, avg_specificity=89.28% avg_auc=83.86%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.190899 Test loss=0.447618 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.18875344097614288
[5/24] Train loss=0.1748977154493332
[10/24] Train loss=0.21676819026470184
[15/24] Train loss=0.19499710202217102
[20/24] Train loss=0.19436535239219666
Test set avg_accuracy=80.20% avg_sensitivity=54.93%, avg_specificity=89.77% avg_auc=84.19%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.190339 Test loss=0.447881 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.18783418834209442
[5/24] Train loss=0.1747182458639145
[10/24] Train loss=0.21111178398132324
[15/24] Train loss=0.1950412392616272
[20/24] Train loss=0.19498680531978607
Test set avg_accuracy=80.25% avg_sensitivity=54.27%, avg_specificity=90.09% avg_auc=84.32%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.188641 Test loss=0.448482 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.182271808385849
[5/24] Train loss=0.18052034080028534
[10/24] Train loss=0.20868150889873505
[15/24] Train loss=0.19173160195350647
[20/24] Train loss=0.19445517659187317
Test set avg_accuracy=80.16% avg_sensitivity=54.69%, avg_specificity=89.80% avg_auc=84.14%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.187481 Test loss=0.448899 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.17893612384796143
[5/24] Train loss=0.17686128616333008
[10/24] Train loss=0.2109738141298294
[15/24] Train loss=0.18807253241539001
[20/24] Train loss=0.1918104588985443
Test set avg_accuracy=80.16% avg_sensitivity=53.98%, avg_specificity=90.07% avg_auc=83.98%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.185619 Test loss=0.451517 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.18044984340667725
[5/24] Train loss=0.1775679588317871
[10/24] Train loss=0.20660315454006195
[15/24] Train loss=0.19141420722007751
[20/24] Train loss=0.18736256659030914
Test set avg_accuracy=80.33% avg_sensitivity=55.21%, avg_specificity=89.84% avg_auc=84.13%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.185733 Test loss=0.448393 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.17583373188972473
[5/24] Train loss=0.1729249209165573
[10/24] Train loss=0.2067376673221588
[15/24] Train loss=0.1922377347946167
[20/24] Train loss=0.18856209516525269
Test set avg_accuracy=79.96% avg_sensitivity=54.36%, avg_specificity=89.66% avg_auc=83.89%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.184910 Test loss=0.452826 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.17419686913490295
[5/24] Train loss=0.1772223263978958
[10/24] Train loss=0.2095106691122055
[15/24] Train loss=0.1949625313282013
[20/24] Train loss=0.1847108155488968
Test set avg_accuracy=79.88% avg_sensitivity=53.98%, avg_specificity=89.69% avg_auc=83.75%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.184359 Test loss=0.454297 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.17660856246948242
[5/24] Train loss=0.1746767908334732
[10/24] Train loss=0.20854957401752472
[15/24] Train loss=0.19328957796096802
[20/24] Train loss=0.18946237862110138
Test set avg_accuracy=79.97% avg_sensitivity=53.65%, avg_specificity=89.95% avg_auc=83.78%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.184150 Test loss=0.452156 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1765931099653244
[5/24] Train loss=0.1756506711244583
[10/24] Train loss=0.20325849950313568
[15/24] Train loss=0.18877583742141724
[20/24] Train loss=0.18418501317501068
Test set avg_accuracy=80.08% avg_sensitivity=54.60%, avg_specificity=89.73% avg_auc=84.17%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.183717 Test loss=0.448569 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.17910055816173553
[5/24] Train loss=0.17174431681632996
[10/24] Train loss=0.20855167508125305
[15/24] Train loss=0.1899227499961853
[20/24] Train loss=0.18553133308887482
Test set avg_accuracy=80.05% avg_sensitivity=54.03%, avg_specificity=89.91% avg_auc=84.07%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.184150 Test loss=0.449784 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.17853781580924988
[5/24] Train loss=0.1737063080072403
[10/24] Train loss=0.20790542662143707
[15/24] Train loss=0.1886288970708847
[20/24] Train loss=0.1854182779788971
Test set avg_accuracy=80.03% avg_sensitivity=53.98%, avg_specificity=89.89% avg_auc=84.04%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.183605 Test loss=0.450844 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.17367851734161377
[5/24] Train loss=0.17501839995384216
[10/24] Train loss=0.20075325667858124
[15/24] Train loss=0.18909019231796265
[20/24] Train loss=0.18435923755168915
Test set avg_accuracy=79.99% avg_sensitivity=54.08%, avg_specificity=89.80% avg_auc=84.09%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.182276 Test loss=0.450128 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.17410221695899963
[5/24] Train loss=0.16958512365818024
[10/24] Train loss=0.20191895961761475
[15/24] Train loss=0.19158533215522766
[20/24] Train loss=0.18468323349952698
Test set avg_accuracy=79.99% avg_sensitivity=54.08%, avg_specificity=89.80% avg_auc=84.07%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.182074 Test loss=0.450149 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.17478443682193756
[5/24] Train loss=0.16933341324329376
[10/24] Train loss=0.20051409304141998
[15/24] Train loss=0.18718929588794708
[20/24] Train loss=0.18772578239440918
Test set avg_accuracy=80.01% avg_sensitivity=54.03%, avg_specificity=89.86% avg_auc=84.02%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.182799 Test loss=0.451196 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.17958012223243713
[5/24] Train loss=0.17416752874851227
[10/24] Train loss=0.20395493507385254
[15/24] Train loss=0.19064007699489594
[20/24] Train loss=0.18135160207748413
Test set avg_accuracy=80.05% avg_sensitivity=54.27%, avg_specificity=89.82% avg_auc=84.05%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.182518 Test loss=0.450446 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1739521026611328
[5/24] Train loss=0.17084170877933502
[10/24] Train loss=0.20445510745048523
[15/24] Train loss=0.18906059861183167
[20/24] Train loss=0.1805242896080017
Test set avg_accuracy=80.00% avg_sensitivity=54.03%, avg_specificity=89.84% avg_auc=84.06%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.181646 Test loss=0.450354 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=81.41% sen=69.24%, spe=86.01%, auc=87.64%!
Fold[3] Avg_overlap=0.45%(0.28338041774005834)
[0/24] Train loss=0.7543492913246155
[5/24] Train loss=0.746878981590271
[10/24] Train loss=0.749279260635376
[15/24] Train loss=0.7449649572372437
[20/24] Train loss=0.7336120009422302
Test set avg_accuracy=56.80% avg_sensitivity=46.73%, avg_specificity=60.35% avg_auc=54.18%
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.744929 Test loss=0.706218 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7317039966583252
[5/24] Train loss=0.7332704067230225
[10/24] Train loss=0.7262519001960754
[15/24] Train loss=0.7220510244369507
[20/24] Train loss=0.7172649502754211
Test set avg_accuracy=57.08% avg_sensitivity=58.72%, avg_specificity=56.51% avg_auc=60.60%
Best model saved!! Metric=-93.09412715283493!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.725152 Test loss=0.677320 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7081103324890137
[5/24] Train loss=0.7181321978569031
[10/24] Train loss=0.7140748500823975
[15/24] Train loss=0.6984701156616211
[20/24] Train loss=0.6970590353012085
Test set avg_accuracy=60.22% avg_sensitivity=63.22%, avg_specificity=59.17% avg_auc=65.77%
Best model saved!! Metric=-77.62407898926813!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.705777 Test loss=0.656655 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6933349370956421
[5/24] Train loss=0.698553740978241
[10/24] Train loss=0.6930659413337708
[15/24] Train loss=0.672348141670227
[20/24] Train loss=0.6681239008903503
Test set avg_accuracy=64.86% avg_sensitivity=67.37%, avg_specificity=63.97% avg_auc=70.17%
Best model saved!! Metric=-59.63740081653464!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.686281 Test loss=0.637884 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6682141423225403
[5/24] Train loss=0.6766707897186279
[10/24] Train loss=0.6728936433792114
[15/24] Train loss=0.6536074280738831
[20/24] Train loss=0.6392453908920288
Test set avg_accuracy=67.12% avg_sensitivity=71.56%, avg_specificity=65.56% avg_auc=73.65%
Best model saved!! Metric=-48.10754017594675!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.663690 Test loss=0.619394 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.639221727848053
[5/24] Train loss=0.6507784724235535
[10/24] Train loss=0.6553070545196533
[15/24] Train loss=0.6320645809173584
[20/24] Train loss=0.6154913902282715
Test set avg_accuracy=67.93% avg_sensitivity=75.36%, avg_specificity=65.31% avg_auc=76.43%
Best model saved!! Metric=-40.96701787156144!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.639295 Test loss=0.606987 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.617384135723114
[5/24] Train loss=0.6317028999328613
[10/24] Train loss=0.6280803084373474
[15/24] Train loss=0.602634608745575
[20/24] Train loss=0.5845381617546082
Test set avg_accuracy=68.98% avg_sensitivity=79.01%, avg_specificity=65.45% avg_auc=78.39%
Best model saved!! Metric=-34.164108338890514!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.612365 Test loss=0.589335 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5874882936477661
[5/24] Train loss=0.5961794853210449
[10/24] Train loss=0.5998725295066833
[15/24] Train loss=0.5738678574562073
[20/24] Train loss=0.5531571507453918
Test set avg_accuracy=71.00% avg_sensitivity=78.46%, avg_specificity=68.37% avg_auc=79.78%
Best model saved!! Metric=-28.37833610804543!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.582178 Test loss=0.566681 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5598563551902771
[5/24] Train loss=0.5559649467468262
[10/24] Train loss=0.5726513862609863
[15/24] Train loss=0.5378221273422241
[20/24] Train loss=0.5177249312400818
Test set avg_accuracy=72.54% avg_sensitivity=78.76%, avg_specificity=70.35% avg_auc=81.00%
Best model saved!! Metric=-23.352387267280477!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.552638 Test loss=0.551880 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5314377546310425
[5/24] Train loss=0.527126669883728
[10/24] Train loss=0.5504391193389893
[15/24] Train loss=0.5168558359146118
[20/24] Train loss=0.49225857853889465
Test set avg_accuracy=74.71% avg_sensitivity=76.31%, avg_specificity=74.15% avg_auc=82.09%
Best model saved!! Metric=-18.738478053355323!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.527207 Test loss=0.518685 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5121590495109558
[5/24] Train loss=0.4887097179889679
[10/24] Train loss=0.5294458270072937
[15/24] Train loss=0.48826339840888977
[20/24] Train loss=0.4756619930267334
Test set avg_accuracy=76.55% avg_sensitivity=75.16%, avg_specificity=77.04% avg_auc=83.20%
Best model saved!! Metric=-14.051720849630868!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.501813 Test loss=0.489416 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.48254916071891785
[5/24] Train loss=0.46417054533958435
[10/24] Train loss=0.5101775527000427
[15/24] Train loss=0.47105368971824646
[20/24] Train loss=0.44695228338241577
Test set avg_accuracy=77.57% avg_sensitivity=73.31%, avg_specificity=79.06% avg_auc=83.87%
Best model saved!! Metric=-12.186877035899869!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.479732 Test loss=0.471081 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.46564117074012756
[5/24] Train loss=0.4459918439388275
[10/24] Train loss=0.49619466066360474
[15/24] Train loss=0.45551177859306335
[20/24] Train loss=0.43511849641799927
Test set avg_accuracy=79.28% avg_sensitivity=70.61%, avg_specificity=82.34% avg_auc=84.38%
Best model saved!! Metric=-9.382285909975778!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.461788 Test loss=0.447747 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.45050209760665894
[5/24] Train loss=0.42016419768333435
[10/24] Train loss=0.4795243740081787
[15/24] Train loss=0.43333908915519714
[20/24] Train loss=0.418901652097702
Test set avg_accuracy=79.74% avg_sensitivity=69.52%, avg_specificity=83.34% avg_auc=84.93%
Best model saved!! Metric=-8.470674453779466!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.445999 Test loss=0.436615 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.43350398540496826
[5/24] Train loss=0.40827152132987976
[10/24] Train loss=0.4633679986000061
[15/24] Train loss=0.4244897961616516
[20/24] Train loss=0.40839478373527527
Test set avg_accuracy=80.23% avg_sensitivity=66.52%, avg_specificity=85.07% avg_auc=85.25%
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.431804 Test loss=0.423060 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.42120125889778137
[5/24] Train loss=0.39089667797088623
[10/24] Train loss=0.4559909403324127
[15/24] Train loss=0.4090842008590698
[20/24] Train loss=0.39288845658302307
Test set avg_accuracy=80.81% avg_sensitivity=65.37%, avg_specificity=86.25% avg_auc=85.63%
Best model saved!! Metric=-7.951934460716885!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.418488 Test loss=0.412911 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.40940141677856445
[5/24] Train loss=0.38587865233421326
[10/24] Train loss=0.44769060611724854
[15/24] Train loss=0.40626800060272217
[20/24] Train loss=0.389571875333786
Test set avg_accuracy=81.20% avg_sensitivity=64.82%, avg_specificity=86.97% avg_auc=85.93%
Best model saved!! Metric=-7.087862437090138!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.410634 Test loss=0.406516 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.40265601873397827
[5/24] Train loss=0.3726101815700531
[10/24] Train loss=0.4365045130252838
[15/24] Train loss=0.3942517042160034
[20/24] Train loss=0.38513103127479553
Test set avg_accuracy=81.25% avg_sensitivity=61.92%, avg_specificity=88.06% avg_auc=85.83%
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.402117 Test loss=0.401954 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.389644056558609
[5/24] Train loss=0.35936519503593445
[10/24] Train loss=0.42944860458374023
[15/24] Train loss=0.3920462429523468
[20/24] Train loss=0.3753984570503235
Test set avg_accuracy=81.21% avg_sensitivity=68.07%, avg_specificity=85.84% avg_auc=86.26%
Best model saved!! Metric=-4.621234809689511!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.394587 Test loss=0.404650 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.38775545358657837
[5/24] Train loss=0.35238197445869446
[10/24] Train loss=0.42488497495651245
[15/24] Train loss=0.3834654688835144
[20/24] Train loss=0.3715798556804657
Test set avg_accuracy=80.65% avg_sensitivity=71.81%, avg_specificity=83.76% avg_auc=86.22%
Best model saved!! Metric=-3.5532775507276284!!
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.388604 Test loss=0.412473 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3817377984523773
[5/24] Train loss=0.3448092043399811
[10/24] Train loss=0.4218689799308777
[15/24] Train loss=0.3786028027534485
[20/24] Train loss=0.36219683289527893
Test set avg_accuracy=80.69% avg_sensitivity=71.36%, avg_specificity=83.98% avg_auc=86.47%
Best model saved!! Metric=-3.5033866913556437!!
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.383533 Test loss=0.408246 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.37273457646369934
[5/24] Train loss=0.3445378839969635
[10/24] Train loss=0.4136640727519989
[15/24] Train loss=0.38279154896736145
[20/24] Train loss=0.3582395613193512
Test set avg_accuracy=80.27% avg_sensitivity=71.86%, avg_specificity=83.24% avg_auc=86.40%
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.379169 Test loss=0.418503 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.37042346596717834
[5/24] Train loss=0.33484041690826416
[10/24] Train loss=0.41604238748550415
[15/24] Train loss=0.37567079067230225
[20/24] Train loss=0.3542638421058655
Test set avg_accuracy=81.13% avg_sensitivity=71.51%, avg_specificity=84.52% avg_auc=86.62%
Best model saved!! Metric=-2.206760361922605!!
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.374686 Test loss=0.405216 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.36994174122810364
[5/24] Train loss=0.32597723603248596
[10/24] Train loss=0.40627190470695496
[15/24] Train loss=0.36971962451934814
[20/24] Train loss=0.3555954694747925
Test set avg_accuracy=81.03% avg_sensitivity=70.16%, avg_specificity=84.86% avg_auc=86.74%
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.372028 Test loss=0.403970 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3680802881717682
[5/24] Train loss=0.3285910487174988
[10/24] Train loss=0.40387722849845886
[15/24] Train loss=0.3617054224014282
[20/24] Train loss=0.35021793842315674
Test set avg_accuracy=80.87% avg_sensitivity=71.66%, avg_specificity=84.12% avg_auc=86.48%
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.368892 Test loss=0.413080 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3623653054237366
[5/24] Train loss=0.3256821632385254
[10/24] Train loss=0.4054710566997528
[15/24] Train loss=0.3674600124359131
[20/24] Train loss=0.3470677137374878
Test set avg_accuracy=81.84% avg_sensitivity=65.07%, avg_specificity=87.74% avg_auc=86.63%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.366063 Test loss=0.393366 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3640427589416504
[5/24] Train loss=0.32367613911628723
[10/24] Train loss=0.4173835217952728
[15/24] Train loss=0.36141255497932434
[20/24] Train loss=0.3449283838272095
Test set avg_accuracy=81.91% avg_sensitivity=65.17%, avg_specificity=87.81% avg_auc=86.94%
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.363918 Test loss=0.390053 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3639799952507019
[5/24] Train loss=0.32217809557914734
[10/24] Train loss=0.399556040763855
[15/24] Train loss=0.3528197705745697
[20/24] Train loss=0.34684500098228455
Test set avg_accuracy=81.41% avg_sensitivity=68.37%, avg_specificity=86.00% avg_auc=86.60%
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.362744 Test loss=0.404193 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3603838086128235
[5/24] Train loss=0.3175424635410309
[10/24] Train loss=0.4003121554851532
[15/24] Train loss=0.3624999225139618
[20/24] Train loss=0.34283214807510376
Test set avg_accuracy=81.42% avg_sensitivity=68.27%, avg_specificity=86.05% avg_auc=86.97%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.360950 Test loss=0.399002 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3548371195793152
[5/24] Train loss=0.3200428783893585
[10/24] Train loss=0.3940938413143158
[15/24] Train loss=0.3587437570095062
[20/24] Train loss=0.3416062593460083
Test set avg_accuracy=80.27% avg_sensitivity=64.42%, avg_specificity=85.86% avg_auc=84.75%
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.359174 Test loss=0.431198 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3549841046333313
[5/24] Train loss=0.3213905394077301
[10/24] Train loss=0.40595829486846924
[15/24] Train loss=0.3507407009601593
[20/24] Train loss=0.33544886112213135
Test set avg_accuracy=81.35% avg_sensitivity=48.78%, avg_specificity=92.83% avg_auc=86.77%
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.355732 Test loss=0.393230 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3603690266609192
[5/24] Train loss=0.31418901681900024
[10/24] Train loss=0.3974856436252594
[15/24] Train loss=0.359046071767807
[20/24] Train loss=0.3413902521133423
Test set avg_accuracy=82.14% avg_sensitivity=63.17%, avg_specificity=88.82% avg_auc=87.04%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.356970 Test loss=0.389837 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.35082530975341797
[5/24] Train loss=0.30836933851242065
[10/24] Train loss=0.3951971232891083
[15/24] Train loss=0.34736061096191406
[20/24] Train loss=0.3394501209259033
Test set avg_accuracy=80.00% avg_sensitivity=41.48%, avg_specificity=93.57% avg_auc=84.70%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.354273 Test loss=0.418908 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3531167209148407
[5/24] Train loss=0.3106309175491333
[10/24] Train loss=0.40358126163482666
[15/24] Train loss=0.34373483061790466
[20/24] Train loss=0.32995277643203735
Test set avg_accuracy=81.71% avg_sensitivity=62.82%, avg_specificity=88.36% avg_auc=86.52%
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.352778 Test loss=0.399756 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.348375141620636
[5/24] Train loss=0.3152830898761749
[10/24] Train loss=0.38901597261428833
[15/24] Train loss=0.35396844148635864
[20/24] Train loss=0.3307843804359436
Test set avg_accuracy=81.68% avg_sensitivity=68.02%, avg_specificity=86.49% avg_auc=86.85%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.352783 Test loss=0.398911 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3514147698879242
[5/24] Train loss=0.31024882197380066
[10/24] Train loss=0.39061006903648376
[15/24] Train loss=0.33788231015205383
[20/24] Train loss=0.3297819197177887
Test set avg_accuracy=80.51% avg_sensitivity=43.43%, avg_specificity=93.57% avg_auc=86.27%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.349744 Test loss=0.402742 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3528726100921631
[5/24] Train loss=0.3164326250553131
[10/24] Train loss=0.3902256190776825
[15/24] Train loss=0.35202109813690186
[20/24] Train loss=0.33557453751564026
Test set avg_accuracy=80.23% avg_sensitivity=36.83%, avg_specificity=95.53% avg_auc=86.71%
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.351287 Test loss=0.403999 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3475537896156311
[5/24] Train loss=0.30577293038368225
[10/24] Train loss=0.4025505781173706
[15/24] Train loss=0.3434942066669464
[20/24] Train loss=0.3321605622768402
Test set avg_accuracy=81.61% avg_sensitivity=58.37%, avg_specificity=89.80% avg_auc=85.73%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.351037 Test loss=0.408572 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3569859564304352
[5/24] Train loss=0.30313384532928467
[10/24] Train loss=0.3860201835632324
[15/24] Train loss=0.3475003242492676
[20/24] Train loss=0.3324666917324066
Test set avg_accuracy=80.61% avg_sensitivity=43.08%, avg_specificity=93.84% avg_auc=85.44%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.347966 Test loss=0.411717 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3519221842288971
[5/24] Train loss=0.31170111894607544
[10/24] Train loss=0.3927140533924103
[15/24] Train loss=0.33987247943878174
[20/24] Train loss=0.327528715133667
Test set avg_accuracy=80.26% avg_sensitivity=36.28%, avg_specificity=95.76% avg_auc=86.61%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.346978 Test loss=0.405497 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.34424057602882385
[5/24] Train loss=0.302916944026947
[10/24] Train loss=0.3862961530685425
[15/24] Train loss=0.3369063138961792
[20/24] Train loss=0.3309900164604187
Test set avg_accuracy=80.59% avg_sensitivity=49.78%, avg_specificity=91.44% avg_auc=83.98%
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.346523 Test loss=0.421410 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.35467061400413513
[5/24] Train loss=0.3065480589866638
[10/24] Train loss=0.39248213171958923
[15/24] Train loss=0.33790773153305054
[20/24] Train loss=0.3277090787887573
Test set avg_accuracy=74.27% avg_sensitivity=23.59%, avg_specificity=92.13% avg_auc=78.25%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.347596 Test loss=0.470562 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.35473811626434326
[5/24] Train loss=0.30164968967437744
[10/24] Train loss=0.39129266142845154
[15/24] Train loss=0.34393414855003357
[20/24] Train loss=0.3347990810871124
Test set avg_accuracy=77.02% avg_sensitivity=28.79%, avg_specificity=94.01% avg_auc=80.56%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.348083 Test loss=0.459919 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.34863200783729553
[5/24] Train loss=0.30362847447395325
[10/24] Train loss=0.3937661349773407
[15/24] Train loss=0.33644384145736694
[20/24] Train loss=0.325151264667511
Test set avg_accuracy=80.94% avg_sensitivity=49.48%, avg_specificity=92.02% avg_auc=85.90%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.344869 Test loss=0.401920 Current lr=[0.00029967723776099]

[0/24] Train loss=0.34977102279663086
[5/24] Train loss=0.3061824440956116
[10/24] Train loss=0.3813750147819519
[15/24] Train loss=0.33142274618148804
[20/24] Train loss=0.3279808461666107
Test set avg_accuracy=80.66% avg_sensitivity=42.18%, avg_specificity=94.22% avg_auc=86.22%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.341140 Test loss=0.403116 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3403502404689789
[5/24] Train loss=0.2959613502025604
[10/24] Train loss=0.39062750339508057
[15/24] Train loss=0.34107106924057007
[20/24] Train loss=0.3212006688117981
Test set avg_accuracy=79.15% avg_sensitivity=33.63%, avg_specificity=95.19% avg_auc=84.15%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.342657 Test loss=0.453705 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3546057939529419
[5/24] Train loss=0.29797884821891785
[10/24] Train loss=0.3784944415092468
[15/24] Train loss=0.3309837281703949
[20/24] Train loss=0.3242315351963043
Test set avg_accuracy=75.81% avg_sensitivity=16.79%, avg_specificity=96.60% avg_auc=81.85%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.343158 Test loss=0.491386 Current lr=[0.000299720220882401]

[0/24] Train loss=0.330862432718277
[5/24] Train loss=0.28934386372566223
[10/24] Train loss=0.3823121190071106
[15/24] Train loss=0.335208922624588
[20/24] Train loss=0.3255026340484619
Test set avg_accuracy=80.79% avg_sensitivity=49.33%, avg_specificity=91.88% avg_auc=85.41%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.341023 Test loss=0.408100 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3403957486152649
[5/24] Train loss=0.29857107996940613
[10/24] Train loss=0.3782319724559784
[15/24] Train loss=0.3295220136642456
[20/24] Train loss=0.32185813784599304
Test set avg_accuracy=80.21% avg_sensitivity=50.17%, avg_specificity=90.79% avg_auc=84.49%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.340883 Test loss=0.421539 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3331812620162964
[5/24] Train loss=0.29833152890205383
[10/24] Train loss=0.3722623586654663
[15/24] Train loss=0.3366314172744751
[20/24] Train loss=0.33396485447883606
Test set avg_accuracy=82.34% avg_sensitivity=56.52%, avg_specificity=91.44% avg_auc=86.48%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.340357 Test loss=0.392695 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3384508192539215
[5/24] Train loss=0.29530951380729675
[10/24] Train loss=0.37968307733535767
[15/24] Train loss=0.3368685841560364
[20/24] Train loss=0.31860029697418213
Test set avg_accuracy=81.13% avg_sensitivity=53.97%, avg_specificity=90.70% avg_auc=85.66%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.338935 Test loss=0.405505 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3421003818511963
[5/24] Train loss=0.29812273383140564
[10/24] Train loss=0.3830576539039612
[15/24] Train loss=0.333041787147522
[20/24] Train loss=0.32307949662208557
Test set avg_accuracy=77.30% avg_sensitivity=27.44%, avg_specificity=94.88% avg_auc=82.66%
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.338557 Test loss=0.448560 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3298516571521759
[5/24] Train loss=0.2945959270000458
[10/24] Train loss=0.3833809792995453
[15/24] Train loss=0.32928526401519775
[20/24] Train loss=0.3206796944141388
Test set avg_accuracy=74.97% avg_sensitivity=8.85%, avg_specificity=98.27% avg_auc=79.54%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.338922 Test loss=0.533131 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.33704033493995667
[5/24] Train loss=0.29867804050445557
[10/24] Train loss=0.37580645084381104
[15/24] Train loss=0.3333960473537445
[20/24] Train loss=0.32318854331970215
Test set avg_accuracy=81.39% avg_sensitivity=51.32%, avg_specificity=91.99% avg_auc=86.21%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.336989 Test loss=0.397794 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3260318636894226
[5/24] Train loss=0.28815725445747375
[10/24] Train loss=0.3784499168395996
[15/24] Train loss=0.35400447249412537
[20/24] Train loss=0.3265105187892914
Test set avg_accuracy=75.96% avg_sensitivity=20.49%, avg_specificity=95.51% avg_auc=75.42%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.337110 Test loss=0.535147 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3374502956867218
[5/24] Train loss=0.29183903336524963
[10/24] Train loss=0.370981365442276
[15/24] Train loss=0.3390386700630188
[20/24] Train loss=0.32327979803085327
Test set avg_accuracy=79.47% avg_sensitivity=54.07%, avg_specificity=88.41% avg_auc=82.50%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.338933 Test loss=0.437151 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3429401218891144
[5/24] Train loss=0.29690441489219666
[10/24] Train loss=0.37728434801101685
[15/24] Train loss=0.3293796181678772
[20/24] Train loss=0.31739941239356995
Test set avg_accuracy=80.31% avg_sensitivity=43.38%, avg_specificity=93.33% avg_auc=85.44%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.337105 Test loss=0.411326 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3429854214191437
[5/24] Train loss=0.29658663272857666
[10/24] Train loss=0.3845440447330475
[15/24] Train loss=0.3234279155731201
[20/24] Train loss=0.32919415831565857
Test set avg_accuracy=81.41% avg_sensitivity=60.12%, avg_specificity=88.91% avg_auc=85.51%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.337193 Test loss=0.406410 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3287678360939026
[5/24] Train loss=0.2865292429924011
[10/24] Train loss=0.37811222672462463
[15/24] Train loss=0.32391804456710815
[20/24] Train loss=0.3263494372367859
Test set avg_accuracy=80.46% avg_sensitivity=43.13%, avg_specificity=93.61% avg_auc=85.20%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.335378 Test loss=0.417923 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3382415175437927
[5/24] Train loss=0.29399770498275757
[10/24] Train loss=0.3727225065231323
[15/24] Train loss=0.31565895676612854
[20/24] Train loss=0.32553789019584656
Test set avg_accuracy=79.56% avg_sensitivity=46.83%, avg_specificity=91.09% avg_auc=82.18%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.334417 Test loss=0.437790 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3477168083190918
[5/24] Train loss=0.29330974817276
[10/24] Train loss=0.3677866756916046
[15/24] Train loss=0.3195502460002899
[20/24] Train loss=0.3249192237854004
Test set avg_accuracy=80.65% avg_sensitivity=57.37%, avg_specificity=88.85% avg_auc=84.44%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.334894 Test loss=0.419518 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.339158833026886
[5/24] Train loss=0.28851625323295593
[10/24] Train loss=0.3627448081970215
[15/24] Train loss=0.3167732059955597
[20/24] Train loss=0.326655775308609
Test set avg_accuracy=80.66% avg_sensitivity=67.02%, avg_specificity=85.47% avg_auc=86.15%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.333900 Test loss=0.409188 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3303527235984802
[5/24] Train loss=0.2842475473880768
[10/24] Train loss=0.36658382415771484
[15/24] Train loss=0.3167703151702881
[20/24] Train loss=0.3179224133491516
Test set avg_accuracy=80.30% avg_sensitivity=54.07%, avg_specificity=89.54% avg_auc=84.78%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.330953 Test loss=0.419000 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3290454149246216
[5/24] Train loss=0.2960120737552643
[10/24] Train loss=0.3705730438232422
[15/24] Train loss=0.30566611886024475
[20/24] Train loss=0.32104045152664185
Test set avg_accuracy=79.74% avg_sensitivity=61.12%, avg_specificity=86.30% avg_auc=83.64%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.330977 Test loss=0.441839 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3365551233291626
[5/24] Train loss=0.2917953133583069
[10/24] Train loss=0.37815314531326294
[15/24] Train loss=0.3109629452228546
[20/24] Train loss=0.3161267638206482
Test set avg_accuracy=81.21% avg_sensitivity=53.12%, avg_specificity=91.11% avg_auc=83.97%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.330168 Test loss=0.420663 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.32786932587623596
[5/24] Train loss=0.2902194559574127
[10/24] Train loss=0.374230295419693
[15/24] Train loss=0.31685397028923035
[20/24] Train loss=0.329131543636322
Test set avg_accuracy=78.42% avg_sensitivity=70.66%, avg_specificity=81.16% avg_auc=84.31%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.330692 Test loss=0.455676 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.33247703313827515
[5/24] Train loss=0.29191306233406067
[10/24] Train loss=0.36291494965553284
[15/24] Train loss=0.3177717328071594
[20/24] Train loss=0.3193661868572235
Test set avg_accuracy=78.33% avg_sensitivity=66.07%, avg_specificity=82.66% avg_auc=81.63%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.329121 Test loss=0.468897 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.32912343740463257
[5/24] Train loss=0.2852575480937958
[10/24] Train loss=0.3642306923866272
[15/24] Train loss=0.3125501871109009
[20/24] Train loss=0.32579970359802246
Test set avg_accuracy=80.59% avg_sensitivity=48.18%, avg_specificity=92.01% avg_auc=81.44%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.328622 Test loss=0.437732 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3389012813568115
[5/24] Train loss=0.2963101267814636
[10/24] Train loss=0.3658086955547333
[15/24] Train loss=0.3143784999847412
[20/24] Train loss=0.33154845237731934
Test set avg_accuracy=78.58% avg_sensitivity=67.77%, avg_specificity=82.39% avg_auc=83.20%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.330363 Test loss=0.469917 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3262624144554138
[5/24] Train loss=0.28304508328437805
[10/24] Train loss=0.36592504382133484
[15/24] Train loss=0.3245607614517212
[20/24] Train loss=0.31932342052459717
Test set avg_accuracy=79.87% avg_sensitivity=67.82%, avg_specificity=84.12% avg_auc=84.04%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.327932 Test loss=0.435665 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.32222074270248413
[5/24] Train loss=0.28932955861091614
[10/24] Train loss=0.37281203269958496
[15/24] Train loss=0.31049033999443054
[20/24] Train loss=0.3198259472846985
Test set avg_accuracy=81.46% avg_sensitivity=59.17%, avg_specificity=89.31% avg_auc=86.10%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.328881 Test loss=0.401596 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3161502182483673
[5/24] Train loss=0.28782758116722107
[10/24] Train loss=0.35952648520469666
[15/24] Train loss=0.31141796708106995
[20/24] Train loss=0.3148682117462158
Test set avg_accuracy=82.20% avg_sensitivity=59.32%, avg_specificity=90.26% avg_auc=86.25%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.321498 Test loss=0.395998 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3119041919708252
[5/24] Train loss=0.279430091381073
[10/24] Train loss=0.35992148518562317
[15/24] Train loss=0.3096282482147217
[20/24] Train loss=0.32309091091156006
Test set avg_accuracy=81.52% avg_sensitivity=55.72%, avg_specificity=90.61% avg_auc=85.22%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.322855 Test loss=0.407325 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.32351502776145935
[5/24] Train loss=0.2880839705467224
[10/24] Train loss=0.35190439224243164
[15/24] Train loss=0.3090747892856598
[20/24] Train loss=0.313913494348526
Test set avg_accuracy=82.11% avg_sensitivity=61.32%, avg_specificity=89.43% avg_auc=86.68%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.321998 Test loss=0.393268 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.31717589497566223
[5/24] Train loss=0.28271740674972534
[10/24] Train loss=0.3483715057373047
[15/24] Train loss=0.3113724887371063
[20/24] Train loss=0.3137516677379608
Test set avg_accuracy=80.07% avg_sensitivity=64.17%, avg_specificity=85.67% avg_auc=84.65%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.320855 Test loss=0.426654 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.32233181595802307
[5/24] Train loss=0.2798382341861725
[10/24] Train loss=0.35808876156806946
[15/24] Train loss=0.30920445919036865
[20/24] Train loss=0.32972195744514465
Test set avg_accuracy=81.21% avg_sensitivity=64.32%, avg_specificity=87.16% avg_auc=85.89%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.321920 Test loss=0.410722 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3142334222793579
[5/24] Train loss=0.2780124545097351
[10/24] Train loss=0.3603896498680115
[15/24] Train loss=0.3026975691318512
[20/24] Train loss=0.3113304376602173
Test set avg_accuracy=80.99% avg_sensitivity=68.27%, avg_specificity=85.47% avg_auc=86.36%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.318463 Test loss=0.411454 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3097590506076813
[5/24] Train loss=0.27468645572662354
[10/24] Train loss=0.34081995487213135
[15/24] Train loss=0.3083241879940033
[20/24] Train loss=0.31615328788757324
Test set avg_accuracy=81.47% avg_sensitivity=59.77%, avg_specificity=89.12% avg_auc=86.09%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.315403 Test loss=0.401943 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3155801296234131
[5/24] Train loss=0.28034543991088867
[10/24] Train loss=0.3493995666503906
[15/24] Train loss=0.29693955183029175
[20/24] Train loss=0.3209875822067261
Test set avg_accuracy=81.69% avg_sensitivity=65.87%, avg_specificity=87.27% avg_auc=86.07%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.312812 Test loss=0.405819 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3152885138988495
[5/24] Train loss=0.2710106074810028
[10/24] Train loss=0.35017672181129456
[15/24] Train loss=0.3137736916542053
[20/24] Train loss=0.3087516725063324
Test set avg_accuracy=79.99% avg_sensitivity=70.31%, avg_specificity=83.39% avg_auc=85.10%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.316386 Test loss=0.438703 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3123292028903961
[5/24] Train loss=0.27445393800735474
[10/24] Train loss=0.3636428713798523
[15/24] Train loss=0.3044457733631134
[20/24] Train loss=0.32624468207359314
Test set avg_accuracy=81.02% avg_sensitivity=59.57%, avg_specificity=88.57% avg_auc=85.01%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.317499 Test loss=0.424029 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3046909272670746
[5/24] Train loss=0.2723674774169922
[10/24] Train loss=0.34296342730522156
[15/24] Train loss=0.29795560240745544
[20/24] Train loss=0.31091177463531494
Test set avg_accuracy=81.18% avg_sensitivity=60.87%, avg_specificity=88.34% avg_auc=85.60%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.313186 Test loss=0.406772 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.30810174345970154
[5/24] Train loss=0.27175769209861755
[10/24] Train loss=0.34514474868774414
[15/24] Train loss=0.30476441979408264
[20/24] Train loss=0.30216220021247864
Test set avg_accuracy=78.39% avg_sensitivity=35.58%, avg_specificity=93.47% avg_auc=81.43%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.310876 Test loss=0.459049 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.313113808631897
[5/24] Train loss=0.27556291222572327
[10/24] Train loss=0.35750001668930054
[15/24] Train loss=0.2925248444080353
[20/24] Train loss=0.31619536876678467
Test set avg_accuracy=80.83% avg_sensitivity=50.72%, avg_specificity=91.44% avg_auc=84.41%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.313515 Test loss=0.428222 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.30150511860847473
[5/24] Train loss=0.28076645731925964
[10/24] Train loss=0.3387204110622406
[15/24] Train loss=0.30271437764167786
[20/24] Train loss=0.30070871114730835
Test set avg_accuracy=80.72% avg_sensitivity=48.03%, avg_specificity=92.23% avg_auc=84.76%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.309366 Test loss=0.424817 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.30513420701026917
[5/24] Train loss=0.2665756046772003
[10/24] Train loss=0.34386423230171204
[15/24] Train loss=0.297539085149765
[20/24] Train loss=0.3017260432243347
Test set avg_accuracy=80.68% avg_sensitivity=60.02%, avg_specificity=87.96% avg_auc=84.66%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.306907 Test loss=0.424482 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.29835379123687744
[5/24] Train loss=0.2683829665184021
[10/24] Train loss=0.34426721930503845
[15/24] Train loss=0.29823413491249084
[20/24] Train loss=0.29940199851989746
Test set avg_accuracy=78.12% avg_sensitivity=36.73%, avg_specificity=92.71% avg_auc=80.62%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.305762 Test loss=0.480574 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.29773566126823425
[5/24] Train loss=0.27191200852394104
[10/24] Train loss=0.33854538202285767
[15/24] Train loss=0.29726213216781616
[20/24] Train loss=0.29398253560066223
Test set avg_accuracy=77.67% avg_sensitivity=27.59%, avg_specificity=95.32% avg_auc=78.32%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.305897 Test loss=0.527789 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.29358401894569397
[5/24] Train loss=0.2656976580619812
[10/24] Train loss=0.33126240968704224
[15/24] Train loss=0.2941194176673889
[20/24] Train loss=0.29668113589286804
Test set avg_accuracy=78.16% avg_sensitivity=38.28%, avg_specificity=92.22% avg_auc=75.47%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.301905 Test loss=0.501989 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.301961213350296
[5/24] Train loss=0.2760699689388275
[10/24] Train loss=0.32534804940223694
[15/24] Train loss=0.30261093378067017
[20/24] Train loss=0.3079957365989685
Test set avg_accuracy=81.47% avg_sensitivity=53.77%, avg_specificity=91.23% avg_auc=84.96%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.302863 Test loss=0.426148 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.30585741996765137
[5/24] Train loss=0.2726406753063202
[10/24] Train loss=0.33278658986091614
[15/24] Train loss=0.29331329464912415
[20/24] Train loss=0.29616841673851013
Test set avg_accuracy=79.30% avg_sensitivity=47.23%, avg_specificity=90.60% avg_auc=82.81%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.303368 Test loss=0.443210 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.29241424798965454
[5/24] Train loss=0.2703825533390045
[10/24] Train loss=0.33085161447525024
[15/24] Train loss=0.28692275285720825
[20/24] Train loss=0.3006906807422638
Test set avg_accuracy=80.64% avg_sensitivity=50.02%, avg_specificity=91.42% avg_auc=83.99%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.300426 Test loss=0.437175 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2960977852344513
[5/24] Train loss=0.26257672905921936
[10/24] Train loss=0.32778024673461914
[15/24] Train loss=0.28820356726646423
[20/24] Train loss=0.29951298236846924
Test set avg_accuracy=81.13% avg_sensitivity=59.27%, avg_specificity=88.84% avg_auc=85.50%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.296645 Test loss=0.413942 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.29298079013824463
[5/24] Train loss=0.2666122019290924
[10/24] Train loss=0.31778484582901
[15/24] Train loss=0.29036465287208557
[20/24] Train loss=0.3033553659915924
Test set avg_accuracy=80.99% avg_sensitivity=57.67%, avg_specificity=89.21% avg_auc=84.57%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.295401 Test loss=0.426133 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2965375781059265
[5/24] Train loss=0.2573346793651581
[10/24] Train loss=0.32087475061416626
[15/24] Train loss=0.28444430232048035
[20/24] Train loss=0.30224254727363586
Test set avg_accuracy=79.27% avg_sensitivity=44.18%, avg_specificity=91.64% avg_auc=79.01%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.294397 Test loss=0.488593 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.29408055543899536
[5/24] Train loss=0.2659175992012024
[10/24] Train loss=0.3319280743598938
[15/24] Train loss=0.2864619195461273
[20/24] Train loss=0.2974287271499634
Test set avg_accuracy=80.17% avg_sensitivity=48.03%, avg_specificity=91.49% avg_auc=81.42%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.295996 Test loss=0.468319 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2959926724433899
[5/24] Train loss=0.25774481892585754
[10/24] Train loss=0.3191811442375183
[15/24] Train loss=0.2826879322528839
[20/24] Train loss=0.29036787152290344
Test set avg_accuracy=81.18% avg_sensitivity=60.52%, avg_specificity=88.47% avg_auc=85.09%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.289943 Test loss=0.420282 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.29297181963920593
[5/24] Train loss=0.2608523964881897
[10/24] Train loss=0.3082968592643738
[15/24] Train loss=0.28695008158683777
[20/24] Train loss=0.29859036207199097
Test set avg_accuracy=80.08% avg_sensitivity=58.57%, avg_specificity=87.66% avg_auc=83.83%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.287163 Test loss=0.439983 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2889808118343353
[5/24] Train loss=0.25677940249443054
[10/24] Train loss=0.3099653422832489
[15/24] Train loss=0.28039973974227905
[20/24] Train loss=0.30447617173194885
Test set avg_accuracy=79.57% avg_sensitivity=45.18%, avg_specificity=91.69% avg_auc=82.71%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.289671 Test loss=0.456240 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.28600865602493286
[5/24] Train loss=0.25056061148643494
[10/24] Train loss=0.3027455508708954
[15/24] Train loss=0.2788182199001312
[20/24] Train loss=0.29196810722351074
Test set avg_accuracy=80.08% avg_sensitivity=44.68%, avg_specificity=92.55% avg_auc=82.03%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.283479 Test loss=0.457952 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.2817913889884949
[5/24] Train loss=0.25179651379585266
[10/24] Train loss=0.29791808128356934
[15/24] Train loss=0.2864125072956085
[20/24] Train loss=0.28650936484336853
Test set avg_accuracy=80.52% avg_sensitivity=54.77%, avg_specificity=89.59% avg_auc=83.97%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.281382 Test loss=0.431817 Current lr=[0.000134135431043539]

[0/24] Train loss=0.27799397706985474
[5/24] Train loss=0.24863643944263458
[10/24] Train loss=0.2890847623348236
[15/24] Train loss=0.2771953344345093
[20/24] Train loss=0.2894304394721985
Test set avg_accuracy=80.74% avg_sensitivity=46.98%, avg_specificity=92.64% avg_auc=82.16%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.278054 Test loss=0.460832 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.27686938643455505
[5/24] Train loss=0.24234481155872345
[10/24] Train loss=0.28590935468673706
[15/24] Train loss=0.2801254093647003
[20/24] Train loss=0.2914978265762329
Test set avg_accuracy=80.31% avg_sensitivity=46.73%, avg_specificity=92.15% avg_auc=81.17%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.278325 Test loss=0.458434 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2753412425518036
[5/24] Train loss=0.24653731286525726
[10/24] Train loss=0.3021297752857208
[15/24] Train loss=0.27892494201660156
[20/24] Train loss=0.29520800709724426
Test set avg_accuracy=79.71% avg_sensitivity=47.48%, avg_specificity=91.07% avg_auc=83.06%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.275394 Test loss=0.437492 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.2796628177165985
[5/24] Train loss=0.23745399713516235
[10/24] Train loss=0.29573482275009155
[15/24] Train loss=0.2719305455684662
[20/24] Train loss=0.2822633385658264
Test set avg_accuracy=79.14% avg_sensitivity=45.13%, avg_specificity=91.13% avg_auc=81.64%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.271953 Test loss=0.468600 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.2696227431297302
[5/24] Train loss=0.24139316380023956
[10/24] Train loss=0.2923020124435425
[15/24] Train loss=0.27135762572288513
[20/24] Train loss=0.2785961925983429
Test set avg_accuracy=79.70% avg_sensitivity=48.28%, avg_specificity=90.77% avg_auc=83.48%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.271151 Test loss=0.444641 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.2695993483066559
[5/24] Train loss=0.23960520327091217
[10/24] Train loss=0.2855885624885559
[15/24] Train loss=0.2629806399345398
[20/24] Train loss=0.2760389447212219
Test set avg_accuracy=81.80% avg_sensitivity=57.37%, avg_specificity=90.40% avg_auc=85.54%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.267391 Test loss=0.412925 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.2597023844718933
[5/24] Train loss=0.2481435090303421
[10/24] Train loss=0.29143422842025757
[15/24] Train loss=0.2704712748527527
[20/24] Train loss=0.28623366355895996
Test set avg_accuracy=81.69% avg_sensitivity=56.22%, avg_specificity=90.67% avg_auc=85.74%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.267689 Test loss=0.410509 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.25820863246917725
[5/24] Train loss=0.2287544161081314
[10/24] Train loss=0.28159308433532715
[15/24] Train loss=0.27060046792030334
[20/24] Train loss=0.2756699323654175
Test set avg_accuracy=81.03% avg_sensitivity=51.37%, avg_specificity=91.48% avg_auc=84.19%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.263019 Test loss=0.436985 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.25537240505218506
[5/24] Train loss=0.22761033475399017
[10/24] Train loss=0.28081199526786804
[15/24] Train loss=0.2571018934249878
[20/24] Train loss=0.28069332242012024
Test set avg_accuracy=81.04% avg_sensitivity=48.93%, avg_specificity=92.36% avg_auc=84.11%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.259798 Test loss=0.438753 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.24952080845832825
[5/24] Train loss=0.23344393074512482
[10/24] Train loss=0.2667613625526428
[15/24] Train loss=0.25843727588653564
[20/24] Train loss=0.2719355523586273
Test set avg_accuracy=81.26% avg_sensitivity=51.37%, avg_specificity=91.79% avg_auc=84.27%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.257040 Test loss=0.430154 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2554386258125305
[5/24] Train loss=0.2343944013118744
[10/24] Train loss=0.2762819826602936
[15/24] Train loss=0.2596650719642639
[20/24] Train loss=0.25709640979766846
Test set avg_accuracy=80.82% avg_sensitivity=54.42%, avg_specificity=90.12% avg_auc=84.33%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.254661 Test loss=0.432359 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.24936246871948242
[5/24] Train loss=0.23064322769641876
[10/24] Train loss=0.2687414884567261
[15/24] Train loss=0.25351911783218384
[20/24] Train loss=0.26920053362846375
Test set avg_accuracy=81.04% avg_sensitivity=59.37%, avg_specificity=88.68% avg_auc=84.93%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.253457 Test loss=0.420719 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.2449032962322235
[5/24] Train loss=0.2268063724040985
[10/24] Train loss=0.2651098668575287
[15/24] Train loss=0.24916134774684906
[20/24] Train loss=0.26025986671447754
Test set avg_accuracy=81.84% avg_sensitivity=61.07%, avg_specificity=89.15% avg_auc=85.18%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.250937 Test loss=0.418750 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.2481871098279953
[5/24] Train loss=0.22181010246276855
[10/24] Train loss=0.26249682903289795
[15/24] Train loss=0.25349846482276917
[20/24] Train loss=0.2608705759048462
Test set avg_accuracy=81.47% avg_sensitivity=63.72%, avg_specificity=87.73% avg_auc=85.71%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.248766 Test loss=0.413618 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.24048066139221191
[5/24] Train loss=0.21857084333896637
[10/24] Train loss=0.2580925226211548
[15/24] Train loss=0.25272274017333984
[20/24] Train loss=0.2518814206123352
Test set avg_accuracy=80.52% avg_sensitivity=58.77%, avg_specificity=88.18% avg_auc=83.80%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.247296 Test loss=0.438590 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.24603718519210815
[5/24] Train loss=0.2126203328371048
[10/24] Train loss=0.2532269358634949
[15/24] Train loss=0.24626760184764862
[20/24] Train loss=0.24794766306877136
Test set avg_accuracy=81.07% avg_sensitivity=63.87%, avg_specificity=87.13% avg_auc=85.69%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.239882 Test loss=0.416363 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.23449543118476868
[5/24] Train loss=0.2144373059272766
[10/24] Train loss=0.2525917887687683
[15/24] Train loss=0.24258145689964294
[20/24] Train loss=0.2496219128370285
Test set avg_accuracy=80.90% avg_sensitivity=57.77%, avg_specificity=89.05% avg_auc=84.57%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.238968 Test loss=0.424878 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.24947255849838257
[5/24] Train loss=0.2105608731508255
[10/24] Train loss=0.24358516931533813
[15/24] Train loss=0.2400936782360077
[20/24] Train loss=0.24460847675800323
Test set avg_accuracy=81.59% avg_sensitivity=60.22%, avg_specificity=89.12% avg_auc=85.27%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.236735 Test loss=0.421576 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.22607891261577606
[5/24] Train loss=0.21348951756954193
[10/24] Train loss=0.25338438153266907
[15/24] Train loss=0.23318347334861755
[20/24] Train loss=0.24305576086044312
Test set avg_accuracy=80.96% avg_sensitivity=65.42%, avg_specificity=86.44% avg_auc=85.79%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.233721 Test loss=0.421636 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.23278260231018066
[5/24] Train loss=0.20288363099098206
[10/24] Train loss=0.23755119740962982
[15/24] Train loss=0.2367790937423706
[20/24] Train loss=0.23994071781635284
Test set avg_accuracy=80.07% avg_sensitivity=61.47%, avg_specificity=86.62% avg_auc=85.14%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.231358 Test loss=0.430200 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.24020466208457947
[5/24] Train loss=0.21001698076725006
[10/24] Train loss=0.24414871633052826
[15/24] Train loss=0.22827015817165375
[20/24] Train loss=0.23669472336769104
Test set avg_accuracy=81.54% avg_sensitivity=59.42%, avg_specificity=89.33% avg_auc=85.06%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.232630 Test loss=0.427399 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.2260526716709137
[5/24] Train loss=0.21056434512138367
[10/24] Train loss=0.23276016116142273
[15/24] Train loss=0.23514825105667114
[20/24] Train loss=0.23082180321216583
Test set avg_accuracy=81.11% avg_sensitivity=57.32%, avg_specificity=89.49% avg_auc=85.02%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.227248 Test loss=0.424731 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.21730342507362366
[5/24] Train loss=0.20744240283966064
[10/24] Train loss=0.23821181058883667
[15/24] Train loss=0.22573043406009674
[20/24] Train loss=0.24213403463363647
Test set avg_accuracy=80.89% avg_sensitivity=61.92%, avg_specificity=87.57% avg_auc=84.32%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.225972 Test loss=0.432874 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.21953676640987396
[5/24] Train loss=0.20017987489700317
[10/24] Train loss=0.23708704113960266
[15/24] Train loss=0.23633845150470734
[20/24] Train loss=0.23152562975883484
Test set avg_accuracy=81.43% avg_sensitivity=60.72%, avg_specificity=88.73% avg_auc=85.56%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.224842 Test loss=0.416058 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.21357344090938568
[5/24] Train loss=0.19924740493297577
[10/24] Train loss=0.23500432074069977
[15/24] Train loss=0.23119740188121796
[20/24] Train loss=0.23176386952400208
Test set avg_accuracy=81.02% avg_sensitivity=62.77%, avg_specificity=87.44% avg_auc=85.16%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.222662 Test loss=0.422715 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.2137034386396408
[5/24] Train loss=0.19199435412883759
[10/24] Train loss=0.22816407680511475
[15/24] Train loss=0.22789321839809418
[20/24] Train loss=0.23153838515281677
Test set avg_accuracy=80.90% avg_sensitivity=60.57%, avg_specificity=88.06% avg_auc=85.36%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.218525 Test loss=0.418160 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.2120705395936966
[5/24] Train loss=0.19119893014431
[10/24] Train loss=0.22676154971122742
[15/24] Train loss=0.22423560917377472
[20/24] Train loss=0.22732234001159668
Test set avg_accuracy=81.05% avg_sensitivity=59.37%, avg_specificity=88.70% avg_auc=84.96%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.215298 Test loss=0.424623 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.21152448654174805
[5/24] Train loss=0.19228486716747284
[10/24] Train loss=0.2319868505001068
[15/24] Train loss=0.22107569873332977
[20/24] Train loss=0.22349153459072113
Test set avg_accuracy=81.09% avg_sensitivity=61.47%, avg_specificity=88.01% avg_auc=85.22%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.213342 Test loss=0.422773 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.20330166816711426
[5/24] Train loss=0.18558397889137268
[10/24] Train loss=0.22708627581596375
[15/24] Train loss=0.22077062726020813
[20/24] Train loss=0.220926433801651
Test set avg_accuracy=81.34% avg_sensitivity=59.62%, avg_specificity=88.99% avg_auc=85.22%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.210251 Test loss=0.420912 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.2099538892507553
[5/24] Train loss=0.1869274228811264
[10/24] Train loss=0.22639454901218414
[15/24] Train loss=0.2204190343618393
[20/24] Train loss=0.2198948711156845
Test set avg_accuracy=80.91% avg_sensitivity=61.47%, avg_specificity=87.76% avg_auc=85.47%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.209462 Test loss=0.419787 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.20453473925590515
[5/24] Train loss=0.18052935600280762
[10/24] Train loss=0.2157655507326126
[15/24] Train loss=0.21766310930252075
[20/24] Train loss=0.21729367971420288
Test set avg_accuracy=81.03% avg_sensitivity=60.82%, avg_specificity=88.15% avg_auc=84.84%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.207037 Test loss=0.427313 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.2008167803287506
[5/24] Train loss=0.18065860867500305
[10/24] Train loss=0.21902945637702942
[15/24] Train loss=0.21367941796779633
[20/24] Train loss=0.21136826276779175
Test set avg_accuracy=80.78% avg_sensitivity=59.52%, avg_specificity=88.27% avg_auc=85.01%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.204909 Test loss=0.428418 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.20426732301712036
[5/24] Train loss=0.18798820674419403
[10/24] Train loss=0.2161419689655304
[15/24] Train loss=0.2181483954191208
[20/24] Train loss=0.21722260117530823
Test set avg_accuracy=81.05% avg_sensitivity=61.72%, avg_specificity=87.87% avg_auc=84.99%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.203995 Test loss=0.425622 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.19752252101898193
[5/24] Train loss=0.18081490695476532
[10/24] Train loss=0.21391502022743225
[15/24] Train loss=0.2110372632741928
[20/24] Train loss=0.21240362524986267
Test set avg_accuracy=81.09% avg_sensitivity=59.27%, avg_specificity=88.78% avg_auc=85.13%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.202847 Test loss=0.423426 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.20515641570091248
[5/24] Train loss=0.18099713325500488
[10/24] Train loss=0.2116784155368805
[15/24] Train loss=0.221498504281044
[20/24] Train loss=0.21413788199424744
Test set avg_accuracy=81.05% avg_sensitivity=61.22%, avg_specificity=88.04% avg_auc=85.27%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.203437 Test loss=0.422468 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.203342005610466
[5/24] Train loss=0.18247824907302856
[10/24] Train loss=0.2155311107635498
[15/24] Train loss=0.2140817791223526
[20/24] Train loss=0.2074347287416458
Test set avg_accuracy=81.18% avg_sensitivity=60.02%, avg_specificity=88.64% avg_auc=84.83%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.201316 Test loss=0.428145 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1969461292028427
[5/24] Train loss=0.17928285896778107
[10/24] Train loss=0.21379271149635315
[15/24] Train loss=0.21123680472373962
[20/24] Train loss=0.2127944678068161
Test set avg_accuracy=81.09% avg_sensitivity=60.22%, avg_specificity=88.45% avg_auc=84.76%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.199577 Test loss=0.428084 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1970614790916443
[5/24] Train loss=0.18107253313064575
[10/24] Train loss=0.21472302079200745
[15/24] Train loss=0.20830175280570984
[20/24] Train loss=0.20937331020832062
Test set avg_accuracy=80.81% avg_sensitivity=60.67%, avg_specificity=87.90% avg_auc=84.96%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.199728 Test loss=0.428552 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.19354063272476196
[5/24] Train loss=0.17804165184497833
[10/24] Train loss=0.20932219922542572
[15/24] Train loss=0.20885470509529114
[20/24] Train loss=0.20734566450119019
Test set avg_accuracy=80.95% avg_sensitivity=59.82%, avg_specificity=88.40% avg_auc=84.75%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.198412 Test loss=0.429541 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.19576773047447205
[5/24] Train loss=0.17970746755599976
[10/24] Train loss=0.20903998613357544
[15/24] Train loss=0.21029719710350037
[20/24] Train loss=0.2101454883813858
Test set avg_accuracy=81.41% avg_sensitivity=61.07%, avg_specificity=88.57% avg_auc=85.05%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.198724 Test loss=0.425386 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1938340961933136
[5/24] Train loss=0.17998816072940826
[10/24] Train loss=0.20598344504833221
[15/24] Train loss=0.20753562450408936
[20/24] Train loss=0.2113640308380127
Test set avg_accuracy=80.95% avg_sensitivity=59.97%, avg_specificity=88.34% avg_auc=84.98%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.198428 Test loss=0.427458 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1971013844013214
[5/24] Train loss=0.17688946425914764
[10/24] Train loss=0.21294645965099335
[15/24] Train loss=0.20566585659980774
[20/24] Train loss=0.20840030908584595
Test set avg_accuracy=81.18% avg_sensitivity=59.57%, avg_specificity=88.80% avg_auc=84.89%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.197298 Test loss=0.428398 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.19433264434337616
[5/24] Train loss=0.1736522763967514
[10/24] Train loss=0.2061891406774521
[15/24] Train loss=0.20631669461727142
[20/24] Train loss=0.20995678007602692
Test set avg_accuracy=81.15% avg_sensitivity=60.17%, avg_specificity=88.54% avg_auc=85.02%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.196065 Test loss=0.426766 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.19409635663032532
[5/24] Train loss=0.1743887960910797
[10/24] Train loss=0.21019808948040009
[15/24] Train loss=0.20304785668849945
[20/24] Train loss=0.207239031791687
Test set avg_accuracy=81.09% avg_sensitivity=60.12%, avg_specificity=88.48% avg_auc=84.94%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.196235 Test loss=0.427402 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.19392478466033936
[5/24] Train loss=0.1707954853773117
[10/24] Train loss=0.2052554339170456
[15/24] Train loss=0.20377160608768463
[20/24] Train loss=0.20656345784664154
Test set avg_accuracy=81.11% avg_sensitivity=60.07%, avg_specificity=88.52% avg_auc=84.90%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.195976 Test loss=0.427566 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1922968178987503
[5/24] Train loss=0.1788577437400818
[10/24] Train loss=0.20904500782489777
[15/24] Train loss=0.2068466991186142
[20/24] Train loss=0.20538276433944702
Test set avg_accuracy=81.20% avg_sensitivity=60.12%, avg_specificity=88.62% avg_auc=84.89%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.195690 Test loss=0.428272 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.19566334784030914
[5/24] Train loss=0.1756533831357956
[10/24] Train loss=0.20840921998023987
[15/24] Train loss=0.20394782721996307
[20/24] Train loss=0.20478351414203644
Test set avg_accuracy=81.22% avg_sensitivity=60.22%, avg_specificity=88.62% avg_auc=84.90%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.196473 Test loss=0.427945 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.19271472096443176
[5/24] Train loss=0.1771622896194458
[10/24] Train loss=0.2051062434911728
[15/24] Train loss=0.20996364951133728
[20/24] Train loss=0.20606495440006256
Test set avg_accuracy=81.18% avg_sensitivity=60.22%, avg_specificity=88.57% avg_auc=84.92%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.196150 Test loss=0.427649 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.197927325963974
[5/24] Train loss=0.18068499863147736
[10/24] Train loss=0.20496439933776855
[15/24] Train loss=0.20809543132781982
[20/24] Train loss=0.2022567242383957
Test set avg_accuracy=81.17% avg_sensitivity=60.12%, avg_specificity=88.59% avg_auc=84.92%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.196270 Test loss=0.427461 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=81.13% sen=71.51%, spe=84.52%, auc=86.62%!
Fold[4] Avg_overlap=0.25%(0.28294960420784515)
[0/24] Train loss=0.7365760207176208
[5/24] Train loss=0.7253985404968262
[10/24] Train loss=0.7228608727455139
[15/24] Train loss=0.7242721319198608
[20/24] Train loss=0.7148433923721313
Test set avg_accuracy=59.19% avg_sensitivity=46.19%, avg_specificity=63.63% avg_auc=56.76%
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.724807 Test loss=0.661857 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7108434438705444
[5/24] Train loss=0.7033994197845459
[10/24] Train loss=0.706973135471344
[15/24] Train loss=0.7017229795455933
[20/24] Train loss=0.6946007013320923
Test set avg_accuracy=64.87% avg_sensitivity=53.56%, avg_specificity=68.73% avg_auc=64.52%
Best model saved!! Metric=-74.32186049151078!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.704543 Test loss=0.642658 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6919910907745361
[5/24] Train loss=0.6890780329704285
[10/24] Train loss=0.697864294052124
[15/24] Train loss=0.6838844418525696
[20/24] Train loss=0.6748256683349609
Test set avg_accuracy=65.60% avg_sensitivity=57.50%, avg_specificity=68.36% avg_auc=67.62%
Best model saved!! Metric=-66.92261092417266!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.687729 Test loss=0.624856 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6703436374664307
[5/24] Train loss=0.66538405418396
[10/24] Train loss=0.6676068902015686
[15/24] Train loss=0.6546452641487122
[20/24] Train loss=0.63974928855896
Test set avg_accuracy=67.76% avg_sensitivity=60.16%, avg_specificity=70.35% avg_auc=70.86%
Best model saved!! Metric=-56.862226804656224!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.666782 Test loss=0.603639 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.658930778503418
[5/24] Train loss=0.6482057571411133
[10/24] Train loss=0.6516006588935852
[15/24] Train loss=0.6367921233177185
[20/24] Train loss=0.6280362606048584
Test set avg_accuracy=69.27% avg_sensitivity=64.98%, avg_specificity=70.74% avg_auc=73.87%
Best model saved!! Metric=-47.14920519921131!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.647066 Test loss=0.586749 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6280521750450134
[5/24] Train loss=0.6279683709144592
[10/24] Train loss=0.632221519947052
[15/24] Train loss=0.6128790378570557
[20/24] Train loss=0.5985036492347717
Test set avg_accuracy=70.91% avg_sensitivity=67.84%, avg_specificity=71.96% avg_auc=76.68%
Best model saved!! Metric=-38.60417994497412!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.621901 Test loss=0.566003 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6068112850189209
[5/24] Train loss=0.6037280559539795
[10/24] Train loss=0.6146185994148254
[15/24] Train loss=0.5806633830070496
[20/24] Train loss=0.5661331415176392
Test set avg_accuracy=72.77% avg_sensitivity=69.53%, avg_specificity=73.88% avg_auc=78.51%
Best model saved!! Metric=-31.302686314476944!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.597725 Test loss=0.547679 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5797972679138184
[5/24] Train loss=0.5675778985023499
[10/24] Train loss=0.5868624448776245
[15/24] Train loss=0.5513464212417603
[20/24] Train loss=0.5408133268356323
Test set avg_accuracy=73.74% avg_sensitivity=73.02%, avg_specificity=73.98% avg_auc=80.78%
Best model saved!! Metric=-24.4884885225635!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.567200 Test loss=0.534905 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5622435808181763
[5/24] Train loss=0.543376088142395
[10/24] Train loss=0.5551979541778564
[15/24] Train loss=0.5253586173057556
[20/24] Train loss=0.5105485916137695
Test set avg_accuracy=76.54% avg_sensitivity=73.84%, avg_specificity=77.46% avg_auc=82.66%
Best model saved!! Metric=-15.505916379346715!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.540307 Test loss=0.509716 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5372693538665771
[5/24] Train loss=0.5036802291870117
[10/24] Train loss=0.5384825468063354
[15/24] Train loss=0.4938929080963135
[20/24] Train loss=0.4874327480792999
Test set avg_accuracy=78.02% avg_sensitivity=71.58%, avg_specificity=80.22% avg_auc=83.69%
Best model saved!! Metric=-12.486238789616039!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.515646 Test loss=0.481804 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5139849185943604
[5/24] Train loss=0.4782118797302246
[10/24] Train loss=0.5179016590118408
[15/24] Train loss=0.474998414516449
[20/24] Train loss=0.4623588025569916
Test set avg_accuracy=78.88% avg_sensitivity=71.79%, avg_specificity=81.30% avg_auc=84.66%
Best model saved!! Metric=-9.374044770714463!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.493010 Test loss=0.464847 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4941859841346741
[5/24] Train loss=0.45983240008354187
[10/24] Train loss=0.4931993782520294
[15/24] Train loss=0.4558413326740265
[20/24] Train loss=0.44846275448799133
Test set avg_accuracy=79.87% avg_sensitivity=70.35%, avg_specificity=83.12% avg_auc=85.33%
Best model saved!! Metric=-7.335156356240404!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.473061 Test loss=0.445077 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.47989416122436523
[5/24] Train loss=0.432819128036499
[10/24] Train loss=0.47949445247650146
[15/24] Train loss=0.4376470148563385
[20/24] Train loss=0.42810964584350586
Test set avg_accuracy=80.33% avg_sensitivity=70.76%, avg_specificity=83.59% avg_auc=85.89%
Best model saved!! Metric=-5.434273480948207!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.455964 Test loss=0.438441 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4689955711364746
[5/24] Train loss=0.4202311933040619
[10/24] Train loss=0.46579453349113464
[15/24] Train loss=0.41987869143486023
[20/24] Train loss=0.41396617889404297
Test set avg_accuracy=81.46% avg_sensitivity=68.51%, avg_specificity=85.87% avg_auc=86.43%
Best model saved!! Metric=-3.7313093175033316!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.440755 Test loss=0.415562 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.45745256543159485
[5/24] Train loss=0.4040369987487793
[10/24] Train loss=0.45296987891197205
[15/24] Train loss=0.4069806635379791
[20/24] Train loss=0.3994119167327881
Test set avg_accuracy=81.71% avg_sensitivity=68.05%, avg_specificity=86.36% avg_auc=86.84%
Best model saved!! Metric=-3.045207704887332!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.427714 Test loss=0.406268 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4414309561252594
[5/24] Train loss=0.38988566398620605
[10/24] Train loss=0.44487980008125305
[15/24] Train loss=0.39528128504753113
[20/24] Train loss=0.39120426774024963
Test set avg_accuracy=82.38% avg_sensitivity=65.85%, avg_specificity=88.02% avg_auc=87.19%
Best model saved!! Metric=-2.561444234858129!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.418053 Test loss=0.392126 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.43653351068496704
[5/24] Train loss=0.3815174698829651
[10/24] Train loss=0.4341728389263153
[15/24] Train loss=0.3859114348888397
[20/24] Train loss=0.38444629311561584
Test set avg_accuracy=82.34% avg_sensitivity=64.31%, avg_specificity=88.49% avg_auc=87.34%
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.408677 Test loss=0.385342 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4341099262237549
[5/24] Train loss=0.3724246919155121
[10/24] Train loss=0.43207883834838867
[15/24] Train loss=0.38071906566619873
[20/24] Train loss=0.38073959946632385
Test set avg_accuracy=82.67% avg_sensitivity=63.75%, avg_specificity=89.12% avg_auc=87.51%
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.400912 Test loss=0.380723 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.42430371046066284
[5/24] Train loss=0.3672063648700714
[10/24] Train loss=0.4200914800167084
[15/24] Train loss=0.37354663014411926
[20/24] Train loss=0.3704094886779785
Test set avg_accuracy=83.03% avg_sensitivity=62.31%, avg_specificity=90.10% avg_auc=87.59%
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.394023 Test loss=0.376541 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4115806221961975
[5/24] Train loss=0.3582708537578583
[10/24] Train loss=0.41765594482421875
[15/24] Train loss=0.36254510283470154
[20/24] Train loss=0.3630125820636749
Test set avg_accuracy=82.94% avg_sensitivity=61.90%, avg_specificity=90.12% avg_auc=87.77%
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.389580 Test loss=0.374012 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.4114329218864441
[5/24] Train loss=0.36027514934539795
[10/24] Train loss=0.4152451753616333
[15/24] Train loss=0.35882461071014404
[20/24] Train loss=0.3585658669471741
Test set avg_accuracy=83.18% avg_sensitivity=60.11%, avg_specificity=91.04% avg_auc=87.89%
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.384241 Test loss=0.371345 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.40678662061691284
[5/24] Train loss=0.3442394435405731
[10/24] Train loss=0.4099341928958893
[15/24] Train loss=0.3556292653083801
[20/24] Train loss=0.3507913053035736
Test set avg_accuracy=82.96% avg_sensitivity=64.00%, avg_specificity=89.42% avg_auc=88.23%
Best model saved!! Metric=-1.394817211727414!!
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.379180 Test loss=0.370600 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.4055432081222534
[5/24] Train loss=0.3485826253890991
[10/24] Train loss=0.4067724347114563
[15/24] Train loss=0.34819236397743225
[20/24] Train loss=0.35318681597709656
Test set avg_accuracy=82.99% avg_sensitivity=65.28%, avg_specificity=89.03% avg_auc=88.40%
Best model saved!! Metric=-0.28644038771126645!!
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.376151 Test loss=0.368990 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.39928993582725525
[5/24] Train loss=0.3442710340023041
[10/24] Train loss=0.411404550075531
[15/24] Train loss=0.3436765968799591
[20/24] Train loss=0.3447819650173187
Test set avg_accuracy=82.34% avg_sensitivity=68.10%, avg_specificity=87.20% avg_auc=88.24%
Best model saved!! Metric=-0.11671864722408998!!
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.373590 Test loss=0.382248 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3946886658668518
[5/24] Train loss=0.33504819869995117
[10/24] Train loss=0.4121253192424774
[15/24] Train loss=0.3439396321773529
[20/24] Train loss=0.34837156534194946
Test set avg_accuracy=82.40% avg_sensitivity=70.81%, avg_specificity=86.35% avg_auc=88.35%
Best model saved!! Metric=1.9085996862625763!!
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.370939 Test loss=0.381863 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3927060067653656
[5/24] Train loss=0.3383180499076843
[10/24] Train loss=0.40533822774887085
[15/24] Train loss=0.33495819568634033
[20/24] Train loss=0.343071311712265
Test set avg_accuracy=82.88% avg_sensitivity=60.83%, avg_specificity=90.40% avg_auc=88.20%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.369132 Test loss=0.369670 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3952127695083618
[5/24] Train loss=0.33480384945869446
[10/24] Train loss=0.3984704613685608
[15/24] Train loss=0.3343321681022644
[20/24] Train loss=0.3393681049346924
Test set avg_accuracy=81.97% avg_sensitivity=42.50%, avg_specificity=95.43% avg_auc=86.97%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.364741 Test loss=0.393036 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.39666813611984253
[5/24] Train loss=0.3442642390727997
[10/24] Train loss=0.40081194043159485
[15/24] Train loss=0.33063966035842896
[20/24] Train loss=0.33880674839019775
Test set avg_accuracy=80.33% avg_sensitivity=32.05%, avg_specificity=96.79% avg_auc=87.25%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.364869 Test loss=0.405458 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3857775032520294
[5/24] Train loss=0.3327137231826782
[10/24] Train loss=0.40123113989830017
[15/24] Train loss=0.3335425853729248
[20/24] Train loss=0.3362361192703247
Test set avg_accuracy=81.84% avg_sensitivity=41.73%, avg_specificity=95.51% avg_auc=87.56%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.362700 Test loss=0.386291 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3918911814689636
[5/24] Train loss=0.3307381868362427
[10/24] Train loss=0.39740443229675293
[15/24] Train loss=0.32741764187812805
[20/24] Train loss=0.3369138538837433
Test set avg_accuracy=82.41% avg_sensitivity=53.00%, avg_specificity=92.44% avg_auc=87.45%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.361288 Test loss=0.378820 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3797077238559723
[5/24] Train loss=0.33475515246391296
[10/24] Train loss=0.39826059341430664
[15/24] Train loss=0.32850950956344604
[20/24] Train loss=0.33344465494155884
Test set avg_accuracy=80.91% avg_sensitivity=39.53%, avg_specificity=95.02% avg_auc=86.06%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.359643 Test loss=0.400091 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.38212886452674866
[5/24] Train loss=0.3323267698287964
[10/24] Train loss=0.39249396324157715
[15/24] Train loss=0.3227008879184723
[20/24] Train loss=0.3353431820869446
Test set avg_accuracy=81.78% avg_sensitivity=41.32%, avg_specificity=95.58% avg_auc=86.45%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.356789 Test loss=0.394799 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.37674766778945923
[5/24] Train loss=0.33159029483795166
[10/24] Train loss=0.39497318863868713
[15/24] Train loss=0.3251901865005493
[20/24] Train loss=0.33440670371055603
Test set avg_accuracy=81.48% avg_sensitivity=48.80%, avg_specificity=92.63% avg_auc=86.35%
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.358466 Test loss=0.401858 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3835180103778839
[5/24] Train loss=0.326260507106781
[10/24] Train loss=0.38760194182395935
[15/24] Train loss=0.33326053619384766
[20/24] Train loss=0.33688557147979736
Test set avg_accuracy=80.94% avg_sensitivity=53.35%, avg_specificity=90.34% avg_auc=85.15%
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.357749 Test loss=0.406943 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3804822862148285
[5/24] Train loss=0.325222909450531
[10/24] Train loss=0.3868370056152344
[15/24] Train loss=0.327876478433609
[20/24] Train loss=0.33638542890548706
Test set avg_accuracy=81.88% avg_sensitivity=67.84%, avg_specificity=86.66% avg_auc=86.46%
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.357078 Test loss=0.404251 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.37891343235969543
[5/24] Train loss=0.32954341173171997
[10/24] Train loss=0.39518511295318604
[15/24] Train loss=0.3209918439388275
[20/24] Train loss=0.33573758602142334
Test set avg_accuracy=81.12% avg_sensitivity=48.23%, avg_specificity=92.33% avg_auc=85.46%
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.355021 Test loss=0.403033 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3776508569717407
[5/24] Train loss=0.32944968342781067
[10/24] Train loss=0.3913757801055908
[15/24] Train loss=0.3247479796409607
[20/24] Train loss=0.3329278826713562
Test set avg_accuracy=81.82% avg_sensitivity=45.72%, avg_specificity=94.13% avg_auc=87.70%
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.354716 Test loss=0.379562 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.38437899947166443
[5/24] Train loss=0.33047181367874146
[10/24] Train loss=0.3852345049381256
[15/24] Train loss=0.3255663216114044
[20/24] Train loss=0.338672935962677
Test set avg_accuracy=80.87% avg_sensitivity=44.24%, avg_specificity=93.36% avg_auc=86.03%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.355965 Test loss=0.396324 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.37498894333839417
[5/24] Train loss=0.3289412260055542
[10/24] Train loss=0.3913351893424988
[15/24] Train loss=0.32219263911247253
[20/24] Train loss=0.33324626088142395
Test set avg_accuracy=81.93% avg_sensitivity=59.40%, avg_specificity=89.61% avg_auc=86.77%
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.352777 Test loss=0.397741 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.38385286927223206
[5/24] Train loss=0.3240267038345337
[10/24] Train loss=0.39484938979148865
[15/24] Train loss=0.31750890612602234
[20/24] Train loss=0.32818803191185
Test set avg_accuracy=82.60% avg_sensitivity=53.10%, avg_specificity=92.67% avg_auc=87.81%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.352645 Test loss=0.379027 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3887860178947449
[5/24] Train loss=0.324910968542099
[10/24] Train loss=0.38910913467407227
[15/24] Train loss=0.3226414620876312
[20/24] Train loss=0.33347028493881226
Test set avg_accuracy=77.92% avg_sensitivity=24.42%, avg_specificity=96.16% avg_auc=82.39%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.352559 Test loss=0.446767 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.37312382459640503
[5/24] Train loss=0.3303733468055725
[10/24] Train loss=0.3950742781162262
[15/24] Train loss=0.32343682646751404
[20/24] Train loss=0.331440269947052
Test set avg_accuracy=82.99% avg_sensitivity=53.10%, avg_specificity=93.19% avg_auc=88.04%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.351876 Test loss=0.370660 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3769162893295288
[5/24] Train loss=0.3184099495410919
[10/24] Train loss=0.39070257544517517
[15/24] Train loss=0.319697767496109
[20/24] Train loss=0.32598695158958435
Test set avg_accuracy=82.43% avg_sensitivity=47.77%, avg_specificity=94.26% avg_auc=87.59%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.347806 Test loss=0.380187 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3830755054950714
[5/24] Train loss=0.32213294506073
[10/24] Train loss=0.3916480541229248
[15/24] Train loss=0.3169276714324951
[20/24] Train loss=0.33228379487991333
Test set avg_accuracy=82.36% avg_sensitivity=45.11%, avg_specificity=95.06% avg_auc=87.61%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.350660 Test loss=0.383084 Current lr=[0.00029967723776099]

[0/24] Train loss=0.37509676814079285
[5/24] Train loss=0.316405713558197
[10/24] Train loss=0.397908478975296
[15/24] Train loss=0.32415634393692017
[20/24] Train loss=0.33063191175460815
Test set avg_accuracy=79.26% avg_sensitivity=25.50%, avg_specificity=97.59% avg_auc=84.59%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.348868 Test loss=0.439505 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.37921014428138733
[5/24] Train loss=0.3255033791065216
[10/24] Train loss=0.389430969953537
[15/24] Train loss=0.30987659096717834
[20/24] Train loss=0.32847699522972107
Test set avg_accuracy=82.63% avg_sensitivity=55.04%, avg_specificity=92.04% avg_auc=87.41%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.348999 Test loss=0.377242 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3720000088214874
[5/24] Train loss=0.3233581781387329
[10/24] Train loss=0.37833070755004883
[15/24] Train loss=0.32350829243659973
[20/24] Train loss=0.33266502618789673
Test set avg_accuracy=82.59% avg_sensitivity=68.36%, avg_specificity=87.45% avg_auc=87.12%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.347102 Test loss=0.412021 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3810591697692871
[5/24] Train loss=0.3142569959163666
[10/24] Train loss=0.37960848212242126
[15/24] Train loss=0.3193424344062805
[20/24] Train loss=0.3401172161102295
Test set avg_accuracy=80.33% avg_sensitivity=32.57%, avg_specificity=96.61% avg_auc=85.68%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.347766 Test loss=0.417939 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.37804871797561646
[5/24] Train loss=0.3255893290042877
[10/24] Train loss=0.38653668761253357
[15/24] Train loss=0.31242257356643677
[20/24] Train loss=0.327499121427536
Test set avg_accuracy=78.93% avg_sensitivity=24.83%, avg_specificity=97.38% avg_auc=83.47%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.345843 Test loss=0.445593 Current lr=[0.000298904600941902]

[0/24] Train loss=0.36464744806289673
[5/24] Train loss=0.31859132647514343
[10/24] Train loss=0.3881854712963104
[15/24] Train loss=0.32586342096328735
[20/24] Train loss=0.3232485055923462
Test set avg_accuracy=83.36% avg_sensitivity=58.83%, avg_specificity=91.72% avg_auc=88.44%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.346327 Test loss=0.367900 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3742431402206421
[5/24] Train loss=0.3167983293533325
[10/24] Train loss=0.3830370008945465
[15/24] Train loss=0.31506308913230896
[20/24] Train loss=0.33426469564437866
Test set avg_accuracy=82.38% avg_sensitivity=51.66%, avg_specificity=92.86% avg_auc=87.29%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.345325 Test loss=0.381885 Current lr=[0.000297555943323901]

[0/24] Train loss=0.36846300959587097
[5/24] Train loss=0.3242136240005493
[10/24] Train loss=0.37339910864830017
[15/24] Train loss=0.31816527247428894
[20/24] Train loss=0.3283021152019501
Test set avg_accuracy=82.15% avg_sensitivity=45.72%, avg_specificity=94.57% avg_auc=87.06%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.343128 Test loss=0.385393 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.37800300121307373
[5/24] Train loss=0.3181855082511902
[10/24] Train loss=0.3870883584022522
[15/24] Train loss=0.3147338628768921
[20/24] Train loss=0.33198320865631104
Test set avg_accuracy=82.29% avg_sensitivity=64.21%, avg_specificity=88.46% avg_auc=86.68%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.346596 Test loss=0.389378 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.37751248478889465
[5/24] Train loss=0.3226029872894287
[10/24] Train loss=0.39426401257514954
[15/24] Train loss=0.31870710849761963
[20/24] Train loss=0.33219894766807556
Test set avg_accuracy=82.53% avg_sensitivity=48.85%, avg_specificity=94.01% avg_auc=87.27%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.344177 Test loss=0.384554 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.368762344121933
[5/24] Train loss=0.31516700983047485
[10/24] Train loss=0.3798491656780243
[15/24] Train loss=0.3116518259048462
[20/24] Train loss=0.32711777091026306
Test set avg_accuracy=81.43% avg_sensitivity=58.06%, avg_specificity=89.40% avg_auc=84.60%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.338828 Test loss=0.421537 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.37360143661499023
[5/24] Train loss=0.3135965168476105
[10/24] Train loss=0.37702563405036926
[15/24] Train loss=0.3130094110965729
[20/24] Train loss=0.3283481001853943
Test set avg_accuracy=79.02% avg_sensitivity=25.14%, avg_specificity=97.40% avg_auc=82.26%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.340959 Test loss=0.463568 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.37243354320526123
[5/24] Train loss=0.31059443950653076
[10/24] Train loss=0.38136863708496094
[15/24] Train loss=0.3168562650680542
[20/24] Train loss=0.32429856061935425
Test set avg_accuracy=80.70% avg_sensitivity=34.72%, avg_specificity=96.39% avg_auc=84.91%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.340835 Test loss=0.430699 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3693445324897766
[5/24] Train loss=0.31729656457901
[10/24] Train loss=0.37379905581474304
[15/24] Train loss=0.31313207745552063
[20/24] Train loss=0.3256419003009796
Test set avg_accuracy=80.95% avg_sensitivity=35.18%, avg_specificity=96.56% avg_auc=84.14%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.339296 Test loss=0.434654 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3664316236972809
[5/24] Train loss=0.3220110535621643
[10/24] Train loss=0.38674598932266235
[15/24] Train loss=0.3026586174964905
[20/24] Train loss=0.3168337643146515
Test set avg_accuracy=79.05% avg_sensitivity=27.60%, avg_specificity=96.60% avg_auc=81.96%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.339830 Test loss=0.446836 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3719658851623535
[5/24] Train loss=0.30950868129730225
[10/24] Train loss=0.3829590082168579
[15/24] Train loss=0.31466180086135864
[20/24] Train loss=0.3282754123210907
Test set avg_accuracy=81.26% avg_sensitivity=50.69%, avg_specificity=91.69% avg_auc=84.26%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.339888 Test loss=0.412016 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.365926593542099
[5/24] Train loss=0.30932432413101196
[10/24] Train loss=0.3767884373664856
[15/24] Train loss=0.3145475685596466
[20/24] Train loss=0.3252739906311035
Test set avg_accuracy=81.15% avg_sensitivity=45.72%, avg_specificity=93.23% avg_auc=85.21%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.337338 Test loss=0.405369 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3753807246685028
[5/24] Train loss=0.3085566461086273
[10/24] Train loss=0.379666805267334
[15/24] Train loss=0.3129638135433197
[20/24] Train loss=0.32361724972724915
Test set avg_accuracy=80.22% avg_sensitivity=34.61%, avg_specificity=95.77% avg_auc=83.89%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.338934 Test loss=0.434235 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.34672749042510986
[5/24] Train loss=0.312721848487854
[10/24] Train loss=0.3732588589191437
[15/24] Train loss=0.2989303171634674
[20/24] Train loss=0.3269542157649994
Test set avg_accuracy=80.43% avg_sensitivity=65.34%, avg_specificity=85.58% avg_auc=85.99%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.336802 Test loss=0.413800 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3543488681316376
[5/24] Train loss=0.3176860213279724
[10/24] Train loss=0.3855174481868744
[15/24] Train loss=0.30926287174224854
[20/24] Train loss=0.3241634964942932
Test set avg_accuracy=78.45% avg_sensitivity=27.91%, avg_specificity=95.69% avg_auc=81.84%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.338869 Test loss=0.476304 Current lr=[0.000276307469034998]

[0/24] Train loss=0.35212182998657227
[5/24] Train loss=0.30584344267845154
[10/24] Train loss=0.38081488013267517
[15/24] Train loss=0.3029460310935974
[20/24] Train loss=0.32852086424827576
Test set avg_accuracy=82.76% avg_sensitivity=57.19%, avg_specificity=91.48% avg_auc=87.11%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.336226 Test loss=0.381478 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3586243987083435
[5/24] Train loss=0.3012501001358032
[10/24] Train loss=0.374102920293808
[15/24] Train loss=0.3061813414096832
[20/24] Train loss=0.314904123544693
Test set avg_accuracy=80.64% avg_sensitivity=46.49%, avg_specificity=92.28% avg_auc=83.97%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.334406 Test loss=0.418010 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.34724166989326477
[5/24] Train loss=0.30195143818855286
[10/24] Train loss=0.37904155254364014
[15/24] Train loss=0.304053395986557
[20/24] Train loss=0.32356271147727966
Test set avg_accuracy=81.21% avg_sensitivity=66.46%, avg_specificity=86.24% avg_auc=86.45%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.332980 Test loss=0.401500 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3475693464279175
[5/24] Train loss=0.30738717317581177
[10/24] Train loss=0.382144957780838
[15/24] Train loss=0.30453893542289734
[20/24] Train loss=0.3156616985797882
Test set avg_accuracy=83.26% avg_sensitivity=60.62%, avg_specificity=90.97% avg_auc=86.60%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.332837 Test loss=0.388335 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3495519161224365
[5/24] Train loss=0.31039711833000183
[10/24] Train loss=0.3754018247127533
[15/24] Train loss=0.295441597700119
[20/24] Train loss=0.33272773027420044
Test set avg_accuracy=79.75% avg_sensitivity=67.69%, avg_specificity=83.87% avg_auc=84.02%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.333203 Test loss=0.436612 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3611639738082886
[5/24] Train loss=0.30979233980178833
[10/24] Train loss=0.3629101812839508
[15/24] Train loss=0.29642266035079956
[20/24] Train loss=0.32411086559295654
Test set avg_accuracy=81.04% avg_sensitivity=65.85%, avg_specificity=86.22% avg_auc=86.19%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.330858 Test loss=0.402240 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3594096601009369
[5/24] Train loss=0.30025941133499146
[10/24] Train loss=0.3649504482746124
[15/24] Train loss=0.30048689246177673
[20/24] Train loss=0.3259015679359436
Test set avg_accuracy=80.62% avg_sensitivity=43.42%, avg_specificity=93.31% avg_auc=83.46%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.329961 Test loss=0.423262 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3495948910713196
[5/24] Train loss=0.30552536249160767
[10/24] Train loss=0.3714733421802521
[15/24] Train loss=0.29728367924690247
[20/24] Train loss=0.3222976624965668
Test set avg_accuracy=80.77% avg_sensitivity=62.11%, avg_specificity=87.13% avg_auc=84.72%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.328690 Test loss=0.428453 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3546626567840576
[5/24] Train loss=0.3059992492198944
[10/24] Train loss=0.36359408497810364
[15/24] Train loss=0.29163500666618347
[20/24] Train loss=0.31690123677253723
Test set avg_accuracy=81.08% avg_sensitivity=62.72%, avg_specificity=87.34% avg_auc=85.41%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.329143 Test loss=0.406923 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3540884256362915
[5/24] Train loss=0.2997439205646515
[10/24] Train loss=0.3708551526069641
[15/24] Train loss=0.2932686507701874
[20/24] Train loss=0.31292930245399475
Test set avg_accuracy=81.84% avg_sensitivity=64.52%, avg_specificity=87.74% avg_auc=86.35%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.329373 Test loss=0.395937 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.35702982544898987
[5/24] Train loss=0.29809898138046265
[10/24] Train loss=0.36327216029167175
[15/24] Train loss=0.2914755046367645
[20/24] Train loss=0.31392329931259155
Test set avg_accuracy=81.69% avg_sensitivity=66.36%, avg_specificity=86.92% avg_auc=86.53%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.326369 Test loss=0.396565 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.35500726103782654
[5/24] Train loss=0.30429473519325256
[10/24] Train loss=0.34824565052986145
[15/24] Train loss=0.29182618856430054
[20/24] Train loss=0.3187904953956604
Test set avg_accuracy=80.65% avg_sensitivity=65.75%, avg_specificity=85.73% avg_auc=86.33%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.325737 Test loss=0.405124 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3445781171321869
[5/24] Train loss=0.3065935969352722
[10/24] Train loss=0.3474922478199005
[15/24] Train loss=0.2961600720882416
[20/24] Train loss=0.31288474798202515
Test set avg_accuracy=81.51% avg_sensitivity=56.48%, avg_specificity=90.05% avg_auc=86.09%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.323193 Test loss=0.397298 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3489453196525574
[5/24] Train loss=0.28953248262405396
[10/24] Train loss=0.3574598431587219
[15/24] Train loss=0.2935161292552948
[20/24] Train loss=0.30703312158584595
Test set avg_accuracy=82.72% avg_sensitivity=53.51%, avg_specificity=92.68% avg_auc=86.39%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.319416 Test loss=0.388763 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.345566064119339
[5/24] Train loss=0.29653483629226685
[10/24] Train loss=0.36044254899024963
[15/24] Train loss=0.29034262895584106
[20/24] Train loss=0.30982285737991333
Test set avg_accuracy=81.90% avg_sensitivity=64.87%, avg_specificity=87.71% avg_auc=86.50%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.320276 Test loss=0.393020 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3327193260192871
[5/24] Train loss=0.3009437620639801
[10/24] Train loss=0.35067683458328247
[15/24] Train loss=0.2951867878437042
[20/24] Train loss=0.30940529704093933
Test set avg_accuracy=81.16% avg_sensitivity=57.96%, avg_specificity=89.07% avg_auc=86.14%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.319913 Test loss=0.401015 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3390827775001526
[5/24] Train loss=0.28841355443000793
[10/24] Train loss=0.3460790514945984
[15/24] Train loss=0.2947029173374176
[20/24] Train loss=0.3044356107711792
Test set avg_accuracy=81.55% avg_sensitivity=66.87%, avg_specificity=86.55% avg_auc=86.73%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.318074 Test loss=0.401619 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.33487117290496826
[5/24] Train loss=0.2852230668067932
[10/24] Train loss=0.3391289710998535
[15/24] Train loss=0.29108938574790955
[20/24] Train loss=0.30816391110420227
Test set avg_accuracy=80.98% avg_sensitivity=69.79%, avg_specificity=84.79% avg_auc=86.69%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.317231 Test loss=0.405357 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3431485593318939
[5/24] Train loss=0.28480005264282227
[10/24] Train loss=0.35929790139198303
[15/24] Train loss=0.2832680642604828
[20/24] Train loss=0.3027920126914978
Test set avg_accuracy=82.14% avg_sensitivity=53.66%, avg_specificity=91.85% avg_auc=87.33%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.315380 Test loss=0.378754 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.34230780601501465
[5/24] Train loss=0.2853386104106903
[10/24] Train loss=0.340248703956604
[15/24] Train loss=0.29669061303138733
[20/24] Train loss=0.29985275864601135
Test set avg_accuracy=80.73% avg_sensitivity=65.03%, avg_specificity=86.08% avg_auc=87.25%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.314495 Test loss=0.391084 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3352101147174835
[5/24] Train loss=0.2890760004520416
[10/24] Train loss=0.34560197591781616
[15/24] Train loss=0.2838854193687439
[20/24] Train loss=0.29962146282196045
Test set avg_accuracy=81.76% avg_sensitivity=59.86%, avg_specificity=89.23% avg_auc=86.63%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.312680 Test loss=0.392368 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.33892473578453064
[5/24] Train loss=0.2825315296649933
[10/24] Train loss=0.3408268988132477
[15/24] Train loss=0.28548312187194824
[20/24] Train loss=0.30522385239601135
Test set avg_accuracy=81.26% avg_sensitivity=67.79%, avg_specificity=85.86% avg_auc=87.12%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.310944 Test loss=0.400768 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.347694993019104
[5/24] Train loss=0.29428502917289734
[10/24] Train loss=0.3393109142780304
[15/24] Train loss=0.27646511793136597
[20/24] Train loss=0.3059408366680145
Test set avg_accuracy=82.20% avg_sensitivity=59.96%, avg_specificity=89.79% avg_auc=86.62%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.313003 Test loss=0.389483 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.33163753151893616
[5/24] Train loss=0.2938674986362457
[10/24] Train loss=0.3419249951839447
[15/24] Train loss=0.2803213596343994
[20/24] Train loss=0.30562183260917664
Test set avg_accuracy=81.33% avg_sensitivity=60.98%, avg_specificity=88.27% avg_auc=85.63%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.311203 Test loss=0.407107 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.3260708153247833
[5/24] Train loss=0.2876646816730499
[10/24] Train loss=0.3370344638824463
[15/24] Train loss=0.2862871289253235
[20/24] Train loss=0.29459279775619507
Test set avg_accuracy=81.02% avg_sensitivity=52.43%, avg_specificity=90.76% avg_auc=86.29%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.308150 Test loss=0.394193 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3313308656215668
[5/24] Train loss=0.2815851867198944
[10/24] Train loss=0.3346979320049286
[15/24] Train loss=0.2757819592952728
[20/24] Train loss=0.2973056137561798
Test set avg_accuracy=81.76% avg_sensitivity=58.73%, avg_specificity=89.61% avg_auc=86.48%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.305287 Test loss=0.397291 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.32964155077934265
[5/24] Train loss=0.27600252628326416
[10/24] Train loss=0.33680763840675354
[15/24] Train loss=0.27955886721611023
[20/24] Train loss=0.29873254895210266
Test set avg_accuracy=81.85% avg_sensitivity=65.75%, avg_specificity=87.34% avg_auc=86.13%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.305371 Test loss=0.414429 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3148799240589142
[5/24] Train loss=0.28454503417015076
[10/24] Train loss=0.33494651317596436
[15/24] Train loss=0.2794512212276459
[20/24] Train loss=0.29464319348335266
Test set avg_accuracy=79.45% avg_sensitivity=65.23%, avg_specificity=84.30% avg_auc=85.80%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.303572 Test loss=0.421587 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.32132488489151
[5/24] Train loss=0.2777542769908905
[10/24] Train loss=0.33542871475219727
[15/24] Train loss=0.28927892446517944
[20/24] Train loss=0.2910400629043579
Test set avg_accuracy=81.20% avg_sensitivity=58.01%, avg_specificity=89.10% avg_auc=86.10%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.302966 Test loss=0.400352 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3319902718067169
[5/24] Train loss=0.2858556807041168
[10/24] Train loss=0.32360807061195374
[15/24] Train loss=0.28378593921661377
[20/24] Train loss=0.29482728242874146
Test set avg_accuracy=76.58% avg_sensitivity=67.74%, avg_specificity=79.59% avg_auc=83.10%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.299648 Test loss=0.473493 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3172071874141693
[5/24] Train loss=0.2719587981700897
[10/24] Train loss=0.3291606307029724
[15/24] Train loss=0.28085213899612427
[20/24] Train loss=0.290253221988678
Test set avg_accuracy=81.50% avg_sensitivity=47.16%, avg_specificity=93.21% avg_auc=83.58%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.299349 Test loss=0.427095 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.32813864946365356
[5/24] Train loss=0.274576336145401
[10/24] Train loss=0.32033419609069824
[15/24] Train loss=0.2730472981929779
[20/24] Train loss=0.28938785195350647
Test set avg_accuracy=81.60% avg_sensitivity=54.79%, avg_specificity=90.75% avg_auc=85.58%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.298437 Test loss=0.412567 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3090856969356537
[5/24] Train loss=0.28745919466018677
[10/24] Train loss=0.31576406955718994
[15/24] Train loss=0.2698531150817871
[20/24] Train loss=0.28598514199256897
Test set avg_accuracy=81.45% avg_sensitivity=49.05%, avg_specificity=92.49% avg_auc=84.43%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.294776 Test loss=0.419886 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3146952986717224
[5/24] Train loss=0.2707904875278473
[10/24] Train loss=0.3258001208305359
[15/24] Train loss=0.28396719694137573
[20/24] Train loss=0.28311261534690857
Test set avg_accuracy=80.99% avg_sensitivity=48.28%, avg_specificity=92.14% avg_auc=84.23%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.296080 Test loss=0.435710 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3129011392593384
[5/24] Train loss=0.27010437846183777
[10/24] Train loss=0.3150009214878082
[15/24] Train loss=0.2730399966239929
[20/24] Train loss=0.2812076210975647
Test set avg_accuracy=80.53% avg_sensitivity=46.59%, avg_specificity=92.11% avg_auc=83.44%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.291116 Test loss=0.436445 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3019695580005646
[5/24] Train loss=0.27040570974349976
[10/24] Train loss=0.3038098216056824
[15/24] Train loss=0.2720799446105957
[20/24] Train loss=0.2873976528644562
Test set avg_accuracy=80.49% avg_sensitivity=50.90%, avg_specificity=90.59% avg_auc=84.28%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.286769 Test loss=0.428608 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3064817190170288
[5/24] Train loss=0.2750087380409241
[10/24] Train loss=0.29799655079841614
[15/24] Train loss=0.25991445779800415
[20/24] Train loss=0.27912822365760803
Test set avg_accuracy=81.60% avg_sensitivity=50.79%, avg_specificity=92.11% avg_auc=84.84%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.285879 Test loss=0.420717 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3028899133205414
[5/24] Train loss=0.2733747661113739
[10/24] Train loss=0.30111104249954224
[15/24] Train loss=0.2704760432243347
[20/24] Train loss=0.27986612915992737
Test set avg_accuracy=80.59% avg_sensitivity=46.54%, avg_specificity=92.19% avg_auc=83.04%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.288546 Test loss=0.439252 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.29855626821517944
[5/24] Train loss=0.2748781442642212
[10/24] Train loss=0.3013651371002197
[15/24] Train loss=0.2749241590499878
[20/24] Train loss=0.2832249402999878
Test set avg_accuracy=81.84% avg_sensitivity=64.98%, avg_specificity=87.59% avg_auc=87.03%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.287828 Test loss=0.397322 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.32151666283607483
[5/24] Train loss=0.26288720965385437
[10/24] Train loss=0.2983984351158142
[15/24] Train loss=0.27420708537101746
[20/24] Train loss=0.27581673860549927
Test set avg_accuracy=80.55% avg_sensitivity=53.35%, avg_specificity=89.82% avg_auc=84.72%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.285815 Test loss=0.416167 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3027891218662262
[5/24] Train loss=0.2658092975616455
[10/24] Train loss=0.29849371314048767
[15/24] Train loss=0.2649542987346649
[20/24] Train loss=0.2703399658203125
Test set avg_accuracy=80.49% avg_sensitivity=55.04%, avg_specificity=89.17% avg_auc=85.65%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.283295 Test loss=0.407051 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3007464110851288
[5/24] Train loss=0.2611292600631714
[10/24] Train loss=0.29549703001976013
[15/24] Train loss=0.27537107467651367
[20/24] Train loss=0.2788434624671936
Test set avg_accuracy=79.62% avg_sensitivity=31.80%, avg_specificity=95.93% avg_auc=81.20%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.280963 Test loss=0.486608 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.31109124422073364
[5/24] Train loss=0.2513376772403717
[10/24] Train loss=0.29299208521842957
[15/24] Train loss=0.2569316625595093
[20/24] Train loss=0.2680808901786804
Test set avg_accuracy=80.89% avg_sensitivity=39.89%, avg_specificity=94.87% avg_auc=81.29%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.276189 Test loss=0.452105 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.2848440408706665
[5/24] Train loss=0.25915995240211487
[10/24] Train loss=0.28346946835517883
[15/24] Train loss=0.2505725026130676
[20/24] Train loss=0.274505615234375
Test set avg_accuracy=80.36% avg_sensitivity=50.28%, avg_specificity=90.62% avg_auc=84.67%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.275097 Test loss=0.421058 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.2943706810474396
[5/24] Train loss=0.25479671359062195
[10/24] Train loss=0.2905561625957489
[15/24] Train loss=0.25395795702934265
[20/24] Train loss=0.2781822979450226
Test set avg_accuracy=81.68% avg_sensitivity=52.48%, avg_specificity=91.64% avg_auc=86.68%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.274081 Test loss=0.403979 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.2887698709964752
[5/24] Train loss=0.25117170810699463
[10/24] Train loss=0.2819073498249054
[15/24] Train loss=0.2485833317041397
[20/24] Train loss=0.26524195075035095
Test set avg_accuracy=81.28% avg_sensitivity=44.39%, avg_specificity=93.85% avg_auc=82.70%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.267947 Test loss=0.452191 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.2782233953475952
[5/24] Train loss=0.24298052489757538
[10/24] Train loss=0.27005887031555176
[15/24] Train loss=0.2577398121356964
[20/24] Train loss=0.2654835879802704
Test set avg_accuracy=82.36% avg_sensitivity=59.04%, avg_specificity=90.31% avg_auc=85.77%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.267284 Test loss=0.406068 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2827010750770569
[5/24] Train loss=0.23976311087608337
[10/24] Train loss=0.2766345739364624
[15/24] Train loss=0.2558119595050812
[20/24] Train loss=0.2605493664741516
Test set avg_accuracy=81.02% avg_sensitivity=44.14%, avg_specificity=93.59% avg_auc=82.82%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.266580 Test loss=0.448853 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.28766492009162903
[5/24] Train loss=0.24699681997299194
[10/24] Train loss=0.2782818078994751
[15/24] Train loss=0.2388601452112198
[20/24] Train loss=0.26257169246673584
Test set avg_accuracy=82.45% avg_sensitivity=59.96%, avg_specificity=90.12% avg_auc=85.48%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.261438 Test loss=0.406162 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.29118233919143677
[5/24] Train loss=0.23867052793502808
[10/24] Train loss=0.26114511489868164
[15/24] Train loss=0.24635601043701172
[20/24] Train loss=0.25944745540618896
Test set avg_accuracy=81.98% avg_sensitivity=53.00%, avg_specificity=91.86% avg_auc=84.54%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.258690 Test loss=0.422542 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.28506529331207275
[5/24] Train loss=0.23227550089359283
[10/24] Train loss=0.2625417411327362
[15/24] Train loss=0.23583416640758514
[20/24] Train loss=0.259677916765213
Test set avg_accuracy=81.68% avg_sensitivity=57.76%, avg_specificity=89.84% avg_auc=84.90%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.257068 Test loss=0.416768 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.2797183692455292
[5/24] Train loss=0.23580928146839142
[10/24] Train loss=0.2585371136665344
[15/24] Train loss=0.24509847164154053
[20/24] Train loss=0.2688029408454895
Test set avg_accuracy=80.87% avg_sensitivity=52.79%, avg_specificity=90.45% avg_auc=84.71%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.255589 Test loss=0.421340 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.2731075882911682
[5/24] Train loss=0.23466376960277557
[10/24] Train loss=0.26644212007522583
[15/24] Train loss=0.23461030423641205
[20/24] Train loss=0.2562377154827118
Test set avg_accuracy=80.56% avg_sensitivity=58.58%, avg_specificity=88.06% avg_auc=86.33%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.250981 Test loss=0.401799 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.27298659086227417
[5/24] Train loss=0.23278439044952393
[10/24] Train loss=0.2578682005405426
[15/24] Train loss=0.2328440248966217
[20/24] Train loss=0.24600011110305786
Test set avg_accuracy=81.50% avg_sensitivity=60.42%, avg_specificity=88.69% avg_auc=86.19%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.248570 Test loss=0.406260 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.2739756405353546
[5/24] Train loss=0.23009520769119263
[10/24] Train loss=0.2656243145465851
[15/24] Train loss=0.2368924915790558
[20/24] Train loss=0.247897669672966
Test set avg_accuracy=80.94% avg_sensitivity=60.27%, avg_specificity=87.99% avg_auc=85.60%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.245510 Test loss=0.419916 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.27168703079223633
[5/24] Train loss=0.22270557284355164
[10/24] Train loss=0.24408964812755585
[15/24] Train loss=0.23449189960956573
[20/24] Train loss=0.24316124618053436
Test set avg_accuracy=81.05% avg_sensitivity=62.98%, avg_specificity=87.22% avg_auc=86.72%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.242768 Test loss=0.409411 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.2546239495277405
[5/24] Train loss=0.2217167615890503
[10/24] Train loss=0.23915539681911469
[15/24] Train loss=0.2286248803138733
[20/24] Train loss=0.2381468266248703
Test set avg_accuracy=82.49% avg_sensitivity=62.88%, avg_specificity=89.17% avg_auc=87.03%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.239202 Test loss=0.394386 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.2544533312320709
[5/24] Train loss=0.2157573699951172
[10/24] Train loss=0.2360166311264038
[15/24] Train loss=0.23182852566242218
[20/24] Train loss=0.24805501103401184
Test set avg_accuracy=81.61% avg_sensitivity=63.49%, avg_specificity=87.79% avg_auc=86.56%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.236877 Test loss=0.404139 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.25876080989837646
[5/24] Train loss=0.2096763253211975
[10/24] Train loss=0.24584093689918518
[15/24] Train loss=0.219198077917099
[20/24] Train loss=0.23582765460014343
Test set avg_accuracy=81.85% avg_sensitivity=64.57%, avg_specificity=87.74% avg_auc=86.60%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.235198 Test loss=0.404815 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.24973580241203308
[5/24] Train loss=0.2147245556116104
[10/24] Train loss=0.23293454945087433
[15/24] Train loss=0.21156089007854462
[20/24] Train loss=0.22994129359722137
Test set avg_accuracy=81.42% avg_sensitivity=59.19%, avg_specificity=89.00% avg_auc=85.57%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.231595 Test loss=0.417847 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.24774031341075897
[5/24] Train loss=0.21089749038219452
[10/24] Train loss=0.2365971803665161
[15/24] Train loss=0.2152201533317566
[20/24] Train loss=0.23130731284618378
Test set avg_accuracy=81.72% avg_sensitivity=65.08%, avg_specificity=87.39% avg_auc=86.10%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.230181 Test loss=0.410391 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.2455773502588272
[5/24] Train loss=0.20909346640110016
[10/24] Train loss=0.23221857845783234
[15/24] Train loss=0.21342378854751587
[20/24] Train loss=0.22329655289649963
Test set avg_accuracy=81.80% avg_sensitivity=63.13%, avg_specificity=88.16% avg_auc=86.05%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.226674 Test loss=0.413923 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.2361057847738266
[5/24] Train loss=0.2074345052242279
[10/24] Train loss=0.22831694781780243
[15/24] Train loss=0.21099090576171875
[20/24] Train loss=0.22591057419776917
Test set avg_accuracy=82.41% avg_sensitivity=64.31%, avg_specificity=88.58% avg_auc=86.83%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.224539 Test loss=0.403542 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.23975993692874908
[5/24] Train loss=0.2029571384191513
[10/24] Train loss=0.2283703237771988
[15/24] Train loss=0.20786526799201965
[20/24] Train loss=0.2266315519809723
Test set avg_accuracy=81.81% avg_sensitivity=60.01%, avg_specificity=89.24% avg_auc=85.68%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.222932 Test loss=0.418420 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.23543865978717804
[5/24] Train loss=0.1966489553451538
[10/24] Train loss=0.22067345678806305
[15/24] Train loss=0.20572437345981598
[20/24] Train loss=0.228749617934227
Test set avg_accuracy=81.34% avg_sensitivity=60.16%, avg_specificity=88.56% avg_auc=85.61%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.221150 Test loss=0.414289 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.23185276985168457
[5/24] Train loss=0.19803015887737274
[10/24] Train loss=0.23169131577014923
[15/24] Train loss=0.20653687417507172
[20/24] Train loss=0.22160591185092926
Test set avg_accuracy=80.39% avg_sensitivity=59.70%, avg_specificity=87.45% avg_auc=84.79%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.218230 Test loss=0.431249 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.22843366861343384
[5/24] Train loss=0.19984304904937744
[10/24] Train loss=0.2220347821712494
[15/24] Train loss=0.20454691350460052
[20/24] Train loss=0.21913039684295654
Test set avg_accuracy=80.65% avg_sensitivity=59.81%, avg_specificity=87.76% avg_auc=85.14%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.217020 Test loss=0.424328 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.2285437285900116
[5/24] Train loss=0.19481290876865387
[10/24] Train loss=0.21325837075710297
[15/24] Train loss=0.20099294185638428
[20/24] Train loss=0.22104480862617493
Test set avg_accuracy=82.19% avg_sensitivity=61.50%, avg_specificity=89.24% avg_auc=85.98%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.214350 Test loss=0.410623 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.22451025247573853
[5/24] Train loss=0.19739988446235657
[10/24] Train loss=0.22423644363880157
[15/24] Train loss=0.1984678953886032
[20/24] Train loss=0.21246477961540222
Test set avg_accuracy=80.95% avg_sensitivity=61.14%, avg_specificity=87.71% avg_auc=85.56%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.211247 Test loss=0.423233 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.2232174426317215
[5/24] Train loss=0.19373662769794464
[10/24] Train loss=0.21449948847293854
[15/24] Train loss=0.1979578137397766
[20/24] Train loss=0.21727846562862396
Test set avg_accuracy=81.77% avg_sensitivity=60.88%, avg_specificity=88.89% avg_auc=85.86%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.209606 Test loss=0.416295 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.2231934666633606
[5/24] Train loss=0.1936892867088318
[10/24] Train loss=0.2161795198917389
[15/24] Train loss=0.1984826773405075
[20/24] Train loss=0.21100357174873352
Test set avg_accuracy=81.35% avg_sensitivity=58.93%, avg_specificity=89.00% avg_auc=84.87%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.210043 Test loss=0.424587 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.21852999925613403
[5/24] Train loss=0.19253861904144287
[10/24] Train loss=0.21334467828273773
[15/24] Train loss=0.2025400847196579
[20/24] Train loss=0.21023499965667725
Test set avg_accuracy=81.61% avg_sensitivity=59.96%, avg_specificity=89.00% avg_auc=85.67%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.208357 Test loss=0.417916 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.2269277274608612
[5/24] Train loss=0.18702097237110138
[10/24] Train loss=0.21389561891555786
[15/24] Train loss=0.19391082227230072
[20/24] Train loss=0.2112630307674408
Test set avg_accuracy=81.08% avg_sensitivity=59.04%, avg_specificity=88.60% avg_auc=85.20%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.207039 Test loss=0.422812 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.22440412640571594
[5/24] Train loss=0.19284965097904205
[10/24] Train loss=0.21496745944023132
[15/24] Train loss=0.19281627237796783
[20/24] Train loss=0.206507608294487
Test set avg_accuracy=81.37% avg_sensitivity=60.01%, avg_specificity=88.65% avg_auc=85.47%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.207351 Test loss=0.419129 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.22333107888698578
[5/24] Train loss=0.19321876764297485
[10/24] Train loss=0.21022269129753113
[15/24] Train loss=0.19694243371486664
[20/24] Train loss=0.20972926914691925
Test set avg_accuracy=81.29% avg_sensitivity=59.24%, avg_specificity=88.81% avg_auc=85.34%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.205659 Test loss=0.424627 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.2236078679561615
[5/24] Train loss=0.19072279334068298
[10/24] Train loss=0.20760361850261688
[15/24] Train loss=0.19424808025360107
[20/24] Train loss=0.20493435859680176
Test set avg_accuracy=81.47% avg_sensitivity=60.27%, avg_specificity=88.70% avg_auc=85.52%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.206023 Test loss=0.419334 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.21949875354766846
[5/24] Train loss=0.1895390897989273
[10/24] Train loss=0.20786985754966736
[15/24] Train loss=0.19301491975784302
[20/24] Train loss=0.2063327580690384
Test set avg_accuracy=81.28% avg_sensitivity=60.42%, avg_specificity=88.39% avg_auc=85.38%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.204472 Test loss=0.420963 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.21346405148506165
[5/24] Train loss=0.18854255974292755
[10/24] Train loss=0.2018398940563202
[15/24] Train loss=0.19609598815441132
[20/24] Train loss=0.203330859541893
Test set avg_accuracy=81.56% avg_sensitivity=60.37%, avg_specificity=88.79% avg_auc=85.44%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.203026 Test loss=0.421378 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.21829108893871307
[5/24] Train loss=0.18745359778404236
[10/24] Train loss=0.21022801101207733
[15/24] Train loss=0.19232472777366638
[20/24] Train loss=0.20643210411071777
Test set avg_accuracy=81.58% avg_sensitivity=60.27%, avg_specificity=88.84% avg_auc=85.50%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.203268 Test loss=0.420030 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.2142457216978073
[5/24] Train loss=0.18746459484100342
[10/24] Train loss=0.20495951175689697
[15/24] Train loss=0.19279895722866058
[20/24] Train loss=0.19953440129756927
Test set avg_accuracy=81.42% avg_sensitivity=60.37%, avg_specificity=88.60% avg_auc=85.42%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.200722 Test loss=0.421279 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.2152077853679657
[5/24] Train loss=0.18351604044437408
[10/24] Train loss=0.20893718302249908
[15/24] Train loss=0.18915273249149323
[20/24] Train loss=0.2027537077665329
Test set avg_accuracy=81.50% avg_sensitivity=60.22%, avg_specificity=88.76% avg_auc=85.32%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.202533 Test loss=0.421599 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.21498632431030273
[5/24] Train loss=0.1876061111688614
[10/24] Train loss=0.20825564861297607
[15/24] Train loss=0.19718559086322784
[20/24] Train loss=0.2077336460351944
Test set avg_accuracy=81.61% avg_sensitivity=59.96%, avg_specificity=89.00% avg_auc=85.26%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.202516 Test loss=0.421792 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.21150518953800201
[5/24] Train loss=0.1859586089849472
[10/24] Train loss=0.20196816325187683
[15/24] Train loss=0.18787845969200134
[20/24] Train loss=0.20343948900699615
Test set avg_accuracy=81.55% avg_sensitivity=60.06%, avg_specificity=88.88% avg_auc=85.26%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.200474 Test loss=0.422336 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.21683277189731598
[5/24] Train loss=0.182806596159935
[10/24] Train loss=0.20609697699546814
[15/24] Train loss=0.19130049645900726
[20/24] Train loss=0.2046624720096588
Test set avg_accuracy=81.47% avg_sensitivity=60.32%, avg_specificity=88.69% avg_auc=85.29%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.201327 Test loss=0.422346 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.21283408999443054
[5/24] Train loss=0.18782244622707367
[10/24] Train loss=0.20677804946899414
[15/24] Train loss=0.19172044098377228
[20/24] Train loss=0.20700933039188385
Test set avg_accuracy=81.48% avg_sensitivity=60.16%, avg_specificity=88.76% avg_auc=85.28%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.201402 Test loss=0.422104 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.21957705914974213
[5/24] Train loss=0.18491192162036896
[10/24] Train loss=0.20405268669128418
[15/24] Train loss=0.1899070143699646
[20/24] Train loss=0.2079675793647766
Test set avg_accuracy=81.52% avg_sensitivity=60.11%, avg_specificity=88.82% avg_auc=85.27%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.202037 Test loss=0.422191 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=82.40% sen=70.81%, spe=86.35%, auc=88.35%!
Fold[5] Avg_overlap=0.47%(0.2965896859945675)
[0/24] Train loss=0.7340720891952515
[5/24] Train loss=0.7364231944084167
[10/24] Train loss=0.7224201560020447
[15/24] Train loss=0.7274373173713684
[20/24] Train loss=0.7181954979896545
Test set avg_accuracy=57.07% avg_sensitivity=43.57%, avg_specificity=62.10% avg_auc=54.72%
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.725726 Test loss=0.689227 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7189706563949585
[5/24] Train loss=0.707126796245575
[10/24] Train loss=0.7124896049499512
[15/24] Train loss=0.6909327507019043
[20/24] Train loss=0.6872367858886719
Test set avg_accuracy=64.66% avg_sensitivity=48.18%, avg_specificity=70.80% avg_auc=63.83%
Best model saved!! Metric=-78.53267213962583!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.706568 Test loss=0.636300 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6861478686332703
[5/24] Train loss=0.6989195942878723
[10/24] Train loss=0.6948525905609131
[15/24] Train loss=0.6734408140182495
[20/24] Train loss=0.6750707626342773
Test set avg_accuracy=68.11% avg_sensitivity=55.33%, avg_specificity=72.87% avg_auc=69.04%
Best model saved!! Metric=-60.651163789845995!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.685996 Test loss=0.614287 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6724026203155518
[5/24] Train loss=0.6810063123703003
[10/24] Train loss=0.6769245266914368
[15/24] Train loss=0.661919355392456
[20/24] Train loss=0.6514257788658142
Test set avg_accuracy=69.60% avg_sensitivity=60.36%, avg_specificity=73.03% avg_auc=72.18%
Best model saved!! Metric=-50.82397314417643!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.669738 Test loss=0.602842 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6475691795349121
[5/24] Train loss=0.6634700298309326
[10/24] Train loss=0.6540489792823792
[15/24] Train loss=0.643360435962677
[20/24] Train loss=0.6298337578773499
Test set avg_accuracy=71.76% avg_sensitivity=63.92%, avg_specificity=74.68% avg_auc=75.52%
Best model saved!! Metric=-40.12729325829458!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.648705 Test loss=0.580863 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.625616192817688
[5/24] Train loss=0.632219135761261
[10/24] Train loss=0.6291266679763794
[15/24] Train loss=0.6091811060905457
[20/24] Train loss=0.6007619500160217
Test set avg_accuracy=73.27% avg_sensitivity=70.01%, avg_specificity=74.48% avg_auc=78.32%
Best model saved!! Metric=-29.925087556685213!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.625720 Test loss=0.564171 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6027615070343018
[5/24] Train loss=0.6118491291999817
[10/24] Train loss=0.5993567705154419
[15/24] Train loss=0.5862259268760681
[20/24] Train loss=0.569031834602356
Test set avg_accuracy=74.45% avg_sensitivity=73.27%, avg_specificity=74.89% avg_auc=80.66%
Best model saved!! Metric=-22.721355778016658!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.599499 Test loss=0.540537 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5737981200218201
[5/24] Train loss=0.590391218662262
[10/24] Train loss=0.5816625356674194
[15/24] Train loss=0.5610746145248413
[20/24] Train loss=0.5354030728340149
Test set avg_accuracy=76.52% avg_sensitivity=72.84%, avg_specificity=77.89% avg_auc=82.39%
Best model saved!! Metric=-16.350775332308245!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.573245 Test loss=0.505296 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.547827959060669
[5/24] Train loss=0.5565102100372314
[10/24] Train loss=0.5561304092407227
[15/24] Train loss=0.535003125667572
[20/24] Train loss=0.5104144215583801
Test set avg_accuracy=77.43% avg_sensitivity=73.90%, avg_specificity=78.75% avg_auc=83.68%
Best model saved!! Metric=-12.240273502043337!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.546213 Test loss=0.487273 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5265270471572876
[5/24] Train loss=0.525822103023529
[10/24] Train loss=0.5247004628181458
[15/24] Train loss=0.5076202750205994
[20/24] Train loss=0.47791793942451477
Test set avg_accuracy=79.02% avg_sensitivity=72.84%, avg_specificity=81.33% avg_auc=85.03%
Best model saved!! Metric=-7.781480908954023!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.521347 Test loss=0.461442 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5064109563827515
[5/24] Train loss=0.5016443729400635
[10/24] Train loss=0.5110695362091064
[15/24] Train loss=0.48166459798812866
[20/24] Train loss=0.4609525799751282
Test set avg_accuracy=80.16% avg_sensitivity=71.50%, avg_specificity=83.38% avg_auc=85.80%
Best model saved!! Metric=-5.16999790946096!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.498656 Test loss=0.441328 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4843440055847168
[5/24] Train loss=0.47260379791259766
[10/24] Train loss=0.482819527387619
[15/24] Train loss=0.4549497067928314
[20/24] Train loss=0.43230199813842773
Test set avg_accuracy=81.34% avg_sensitivity=70.83%, avg_specificity=85.26% avg_auc=86.67%
Best model saved!! Metric=-1.9029492085048787!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.476492 Test loss=0.422360 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.46716493368148804
[5/24] Train loss=0.4579368829727173
[10/24] Train loss=0.4665248990058899
[15/24] Train loss=0.44048357009887695
[20/24] Train loss=0.4217436611652374
Test set avg_accuracy=81.37% avg_sensitivity=69.19%, avg_specificity=85.90% avg_auc=86.95%
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.460399 Test loss=0.411808 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.444583922624588
[5/24] Train loss=0.4342420697212219
[10/24] Train loss=0.4519661068916321
[15/24] Train loss=0.4269726574420929
[20/24] Train loss=0.4060570001602173
Test set avg_accuracy=82.25% avg_sensitivity=66.36%, avg_specificity=88.17% avg_auc=87.28%
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.443188 Test loss=0.397183 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4358404874801636
[5/24] Train loss=0.42335912585258484
[10/24] Train loss=0.4392143487930298
[15/24] Train loss=0.41088584065437317
[20/24] Train loss=0.3922768533229828
Test set avg_accuracy=82.71% avg_sensitivity=67.03%, avg_specificity=88.55% avg_auc=87.67%
Best model saved!! Metric=-0.04529106797335203!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.430867 Test loss=0.389732 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4245300590991974
[5/24] Train loss=0.41196268796920776
[10/24] Train loss=0.4184258282184601
[15/24] Train loss=0.4007028043270111
[20/24] Train loss=0.3779251277446747
Test set avg_accuracy=82.66% avg_sensitivity=63.96%, avg_specificity=89.62% avg_auc=87.75%
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.419429 Test loss=0.382478 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.40771156549453735
[5/24] Train loss=0.39498838782310486
[10/24] Train loss=0.41146358847618103
[15/24] Train loss=0.3862352967262268
[20/24] Train loss=0.37051787972450256
Test set avg_accuracy=82.88% avg_sensitivity=64.49%, avg_specificity=89.72% avg_auc=87.85%
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.409914 Test loss=0.380601 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3976588547229767
[5/24] Train loss=0.3904445469379425
[10/24] Train loss=0.4090312719345093
[15/24] Train loss=0.38164204359054565
[20/24] Train loss=0.3564866781234741
Test set avg_accuracy=82.92% avg_sensitivity=65.60%, avg_specificity=89.37% avg_auc=88.07%
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.400984 Test loss=0.377656 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.39521411061286926
[5/24] Train loss=0.3898269534111023
[10/24] Train loss=0.3938803970813751
[15/24] Train loss=0.3712935149669647
[20/24] Train loss=0.3551943302154541
Test set avg_accuracy=83.01% avg_sensitivity=67.61%, avg_specificity=88.74% avg_auc=88.27%
Best model saved!! Metric=1.6256091438874023!!
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.395245 Test loss=0.374181 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3854290544986725
[5/24] Train loss=0.373531311750412
[10/24] Train loss=0.3926309645175934
[15/24] Train loss=0.36501529812812805
[20/24] Train loss=0.35005584359169006
Test set avg_accuracy=82.97% avg_sensitivity=67.66%, avg_specificity=88.67% avg_auc=88.48%
Best model saved!! Metric=1.7771990018233481!!
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.388837 Test loss=0.371761 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3796389400959015
[5/24] Train loss=0.36569198966026306
[10/24] Train loss=0.38526615500450134
[15/24] Train loss=0.35731378197669983
[20/24] Train loss=0.3394065797328949
Test set avg_accuracy=82.96% avg_sensitivity=71.88%, avg_specificity=87.08% avg_auc=88.40%
Best model saved!! Metric=4.313692559767574!!
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.382765 Test loss=0.380280 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.38207685947418213
[5/24] Train loss=0.36488446593284607
[10/24] Train loss=0.3789142668247223
[15/24] Train loss=0.3527778685092926
[20/24] Train loss=0.3393250107765198
Test set avg_accuracy=83.37% avg_sensitivity=66.46%, avg_specificity=89.67% avg_auc=88.83%
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.378845 Test loss=0.365213 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3736155331134796
[5/24] Train loss=0.3602452874183655
[10/24] Train loss=0.37371498346328735
[15/24] Train loss=0.3437693417072296
[20/24] Train loss=0.3350302577018738
Test set avg_accuracy=83.24% avg_sensitivity=71.50%, avg_specificity=87.62% avg_auc=88.61%
Best model saved!! Metric=4.966796968786994!!
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.375644 Test loss=0.374871 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.37609800696372986
[5/24] Train loss=0.36263132095336914
[10/24] Train loss=0.3714630603790283
[15/24] Train loss=0.33740222454071045
[20/24] Train loss=0.33216392993927
Test set avg_accuracy=83.61% avg_sensitivity=67.66%, avg_specificity=89.55% avg_auc=89.00%
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.373381 Test loss=0.365926 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.36743980646133423
[5/24] Train loss=0.3578755855560303
[10/24] Train loss=0.3650006353855133
[15/24] Train loss=0.3374341130256653
[20/24] Train loss=0.3327542245388031
Test set avg_accuracy=84.06% avg_sensitivity=66.27%, avg_specificity=90.69% avg_auc=89.05%
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.370774 Test loss=0.361455 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3706190884113312
[5/24] Train loss=0.3565537929534912
[10/24] Train loss=0.3658139109611511
[15/24] Train loss=0.33378830552101135
[20/24] Train loss=0.33013415336608887
Test set avg_accuracy=84.31% avg_sensitivity=61.04%, avg_specificity=92.98% avg_auc=89.33%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.367451 Test loss=0.358169 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.36847352981567383
[5/24] Train loss=0.3464111089706421
[10/24] Train loss=0.3684912919998169
[15/24] Train loss=0.3314021825790405
[20/24] Train loss=0.32449743151664734
Test set avg_accuracy=83.96% avg_sensitivity=60.65%, avg_specificity=92.64% avg_auc=89.09%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.367238 Test loss=0.362225 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.36470556259155273
[5/24] Train loss=0.34806278347969055
[10/24] Train loss=0.36374446749687195
[15/24] Train loss=0.32519349455833435
[20/24] Train loss=0.3222920298576355
Test set avg_accuracy=83.87% avg_sensitivity=67.51%, avg_specificity=89.96% avg_auc=89.14%
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.365254 Test loss=0.362470 Current lr=[0.000210185142098938]

[0/24] Train loss=0.35676833987236023
[5/24] Train loss=0.3549479842185974
[10/24] Train loss=0.3596697747707367
[15/24] Train loss=0.3245874047279358
[20/24] Train loss=0.32395416498184204
Test set avg_accuracy=83.50% avg_sensitivity=63.58%, avg_specificity=90.92% avg_auc=88.99%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.362243 Test loss=0.366518 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.36154818534851074
[5/24] Train loss=0.3500101864337921
[10/24] Train loss=0.35843318700790405
[15/24] Train loss=0.3232203423976898
[20/24] Train loss=0.3224755823612213
Test set avg_accuracy=82.41% avg_sensitivity=70.01%, avg_specificity=87.03% avg_auc=88.08%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.361651 Test loss=0.400153 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.367096483707428
[5/24] Train loss=0.3459927439689636
[10/24] Train loss=0.3587687909603119
[15/24] Train loss=0.31742027401924133
[20/24] Train loss=0.32054588198661804
Test set avg_accuracy=81.08% avg_sensitivity=73.61%, avg_specificity=83.86% avg_auc=87.50%
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.360822 Test loss=0.418270 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.36813637614250183
[5/24] Train loss=0.347057580947876
[10/24] Train loss=0.3587419092655182
[15/24] Train loss=0.31091195344924927
[20/24] Train loss=0.31746381521224976
Test set avg_accuracy=83.72% avg_sensitivity=61.18%, avg_specificity=92.12% avg_auc=89.13%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.359656 Test loss=0.367300 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3538009226322174
[5/24] Train loss=0.34622612595558167
[10/24] Train loss=0.35305556654930115
[15/24] Train loss=0.3142775297164917
[20/24] Train loss=0.3177722692489624
Test set avg_accuracy=83.44% avg_sensitivity=66.94%, avg_specificity=89.58% avg_auc=88.86%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.358995 Test loss=0.367255 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.35668304562568665
[5/24] Train loss=0.34130626916885376
[10/24] Train loss=0.3559879660606384
[15/24] Train loss=0.3108600378036499
[20/24] Train loss=0.32098114490509033
Test set avg_accuracy=83.78% avg_sensitivity=62.19%, avg_specificity=91.82% avg_auc=89.08%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.356409 Test loss=0.369439 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3607428967952728
[5/24] Train loss=0.3420192301273346
[10/24] Train loss=0.34743526577949524
[15/24] Train loss=0.3102315366268158
[20/24] Train loss=0.32230740785598755
Test set avg_accuracy=83.89% avg_sensitivity=61.08%, avg_specificity=92.39% avg_auc=88.76%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.355760 Test loss=0.378279 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.35735267400741577
[5/24] Train loss=0.33836451172828674
[10/24] Train loss=0.35822850465774536
[15/24] Train loss=0.30727770924568176
[20/24] Train loss=0.3129161298274994
Test set avg_accuracy=82.67% avg_sensitivity=50.96%, avg_specificity=94.48% avg_auc=88.11%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.354996 Test loss=0.385885 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3537597954273224
[5/24] Train loss=0.34728357195854187
[10/24] Train loss=0.35708582401275635
[15/24] Train loss=0.31163260340690613
[20/24] Train loss=0.3136647641658783
Test set avg_accuracy=81.54% avg_sensitivity=38.72%, avg_specificity=97.48% avg_auc=88.45%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.355317 Test loss=0.396536 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3547641634941101
[5/24] Train loss=0.3446844220161438
[10/24] Train loss=0.34967857599258423
[15/24] Train loss=0.3134270906448364
[20/24] Train loss=0.3221643269062042
Test set avg_accuracy=83.23% avg_sensitivity=50.24%, avg_specificity=95.51% avg_auc=88.63%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.355562 Test loss=0.377384 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3483896553516388
[5/24] Train loss=0.3336147665977478
[10/24] Train loss=0.35364821553230286
[15/24] Train loss=0.3080100417137146
[20/24] Train loss=0.3143830895423889
Test set avg_accuracy=83.66% avg_sensitivity=57.34%, avg_specificity=93.46% avg_auc=88.82%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.352095 Test loss=0.366302 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3492162227630615
[5/24] Train loss=0.33393073081970215
[10/24] Train loss=0.3463052213191986
[15/24] Train loss=0.31117889285087585
[20/24] Train loss=0.31708571314811707
Test set avg_accuracy=84.40% avg_sensitivity=58.49%, avg_specificity=94.05% avg_auc=89.69%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.351641 Test loss=0.354673 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3503286838531494
[5/24] Train loss=0.3338475227355957
[10/24] Train loss=0.3558952510356903
[15/24] Train loss=0.3154539167881012
[20/24] Train loss=0.3135553002357483
Test set avg_accuracy=83.45% avg_sensitivity=58.06%, avg_specificity=92.91% avg_auc=89.20%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.353505 Test loss=0.361797 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3451911211013794
[5/24] Train loss=0.33247649669647217
[10/24] Train loss=0.34432750940322876
[15/24] Train loss=0.30659982562065125
[20/24] Train loss=0.32026156783103943
Test set avg_accuracy=79.83% avg_sensitivity=34.50%, avg_specificity=96.71% avg_auc=86.63%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.350384 Test loss=0.412048 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.35374465584754944
[5/24] Train loss=0.3321579694747925
[10/24] Train loss=0.3465067744255066
[15/24] Train loss=0.30476370453834534
[20/24] Train loss=0.31466570496559143
Test set avg_accuracy=81.47% avg_sensitivity=43.47%, avg_specificity=95.62% avg_auc=87.73%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.352071 Test loss=0.391885 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3579062223434448
[5/24] Train loss=0.33081892132759094
[10/24] Train loss=0.3491850793361664
[15/24] Train loss=0.311808317899704
[20/24] Train loss=0.31380417943000793
Test set avg_accuracy=83.20% avg_sensitivity=49.90%, avg_specificity=95.60% avg_auc=89.50%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.348778 Test loss=0.367413 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3364221751689911
[5/24] Train loss=0.33553576469421387
[10/24] Train loss=0.34222155809402466
[15/24] Train loss=0.31057900190353394
[20/24] Train loss=0.31865254044532776
Test set avg_accuracy=82.43% avg_sensitivity=49.04%, avg_specificity=94.87% avg_auc=87.36%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.348114 Test loss=0.398106 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.34669896960258484
[5/24] Train loss=0.3341134488582611
[10/24] Train loss=0.34997695684432983
[15/24] Train loss=0.3123680353164673
[20/24] Train loss=0.310600608587265
Test set avg_accuracy=83.59% avg_sensitivity=53.07%, avg_specificity=94.96% avg_auc=89.48%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.349800 Test loss=0.365364 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3464724123477936
[5/24] Train loss=0.33450570702552795
[10/24] Train loss=0.34592679142951965
[15/24] Train loss=0.3038976490497589
[20/24] Train loss=0.31258803606033325
Test set avg_accuracy=83.85% avg_sensitivity=67.18%, avg_specificity=90.06% avg_auc=89.04%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.349990 Test loss=0.362355 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3428274393081665
[5/24] Train loss=0.3245898187160492
[10/24] Train loss=0.3499729335308075
[15/24] Train loss=0.3036297559738159
[20/24] Train loss=0.3083608150482178
Test set avg_accuracy=83.75% avg_sensitivity=56.48%, avg_specificity=93.91% avg_auc=89.44%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.346985 Test loss=0.362513 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.34531474113464355
[5/24] Train loss=0.3260602056980133
[10/24] Train loss=0.35284990072250366
[15/24] Train loss=0.3078240156173706
[20/24] Train loss=0.308274507522583
Test set avg_accuracy=82.34% avg_sensitivity=46.21%, avg_specificity=95.80% avg_auc=87.25%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.347828 Test loss=0.395528 Current lr=[0.000298904600941902]

[0/24] Train loss=0.34806036949157715
[5/24] Train loss=0.33213233947753906
[10/24] Train loss=0.342145174741745
[15/24] Train loss=0.3029317557811737
[20/24] Train loss=0.3022810220718384
Test set avg_accuracy=83.96% avg_sensitivity=63.82%, avg_specificity=91.46% avg_auc=89.23%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.347922 Test loss=0.363576 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3394691050052643
[5/24] Train loss=0.3312903344631195
[10/24] Train loss=0.3443444073200226
[15/24] Train loss=0.302382230758667
[20/24] Train loss=0.310878187417984
Test set avg_accuracy=80.44% avg_sensitivity=35.70%, avg_specificity=97.11% avg_auc=85.76%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.344595 Test loss=0.420232 Current lr=[0.000297555943323901]

[0/24] Train loss=0.34483709931373596
[5/24] Train loss=0.32443201541900635
[10/24] Train loss=0.34140217304229736
[15/24] Train loss=0.30336180329322815
[20/24] Train loss=0.30705615878105164
Test set avg_accuracy=83.11% avg_sensitivity=56.09%, avg_specificity=93.17% avg_auc=87.79%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.343210 Test loss=0.377444 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.33341702818870544
[5/24] Train loss=0.3334713578224182
[10/24] Train loss=0.33517107367515564
[15/24] Train loss=0.29812943935394287
[20/24] Train loss=0.31210988759994507
Test set avg_accuracy=81.99% avg_sensitivity=50.38%, avg_specificity=93.76% avg_auc=85.86%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.343941 Test loss=0.410063 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3363192677497864
[5/24] Train loss=0.3201233446598053
[10/24] Train loss=0.3345085382461548
[15/24] Train loss=0.3044872581958771
[20/24] Train loss=0.3119732737541199
Test set avg_accuracy=83.66% avg_sensitivity=67.90%, avg_specificity=89.53% avg_auc=88.45%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.341374 Test loss=0.367066 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3351640999317169
[5/24] Train loss=0.33189576864242554
[10/24] Train loss=0.343050092458725
[15/24] Train loss=0.29766541719436646
[20/24] Train loss=0.30742812156677246
Test set avg_accuracy=83.65% avg_sensitivity=58.93%, avg_specificity=92.85% avg_auc=88.40%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.342067 Test loss=0.370287 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.33297979831695557
[5/24] Train loss=0.32112762331962585
[10/24] Train loss=0.3321187496185303
[15/24] Train loss=0.3005082309246063
[20/24] Train loss=0.3092939555644989
Test set avg_accuracy=82.06% avg_sensitivity=45.73%, avg_specificity=95.59% avg_auc=87.66%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.341763 Test loss=0.393652 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3373492956161499
[5/24] Train loss=0.3241878151893616
[10/24] Train loss=0.3380550444126129
[15/24] Train loss=0.2892763614654541
[20/24] Train loss=0.3059738874435425
Test set avg_accuracy=83.70% avg_sensitivity=59.60%, avg_specificity=92.67% avg_auc=88.96%
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.338606 Test loss=0.366573 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3337157070636749
[5/24] Train loss=0.3283384442329407
[10/24] Train loss=0.3317077159881592
[15/24] Train loss=0.3041551411151886
[20/24] Train loss=0.3101919889450073
Test set avg_accuracy=82.58% avg_sensitivity=47.84%, avg_specificity=95.51% avg_auc=88.08%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.339535 Test loss=0.390663 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3373714089393616
[5/24] Train loss=0.31911614537239075
[10/24] Train loss=0.3446994423866272
[15/24] Train loss=0.29412245750427246
[20/24] Train loss=0.30995404720306396
Test set avg_accuracy=82.92% avg_sensitivity=60.99%, avg_specificity=91.08% avg_auc=86.91%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.339335 Test loss=0.389566 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3404279947280884
[5/24] Train loss=0.3203941881656647
[10/24] Train loss=0.34133780002593994
[15/24] Train loss=0.292173832654953
[20/24] Train loss=0.315994530916214
Test set avg_accuracy=84.39% avg_sensitivity=63.77%, avg_specificity=92.07% avg_auc=89.53%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.337970 Test loss=0.381273 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3436267375946045
[5/24] Train loss=0.32957831025123596
[10/24] Train loss=0.3339928388595581
[15/24] Train loss=0.29774197936058044
[20/24] Train loss=0.30649060010910034
Test set avg_accuracy=80.29% avg_sensitivity=46.59%, avg_specificity=92.83% avg_auc=84.98%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.339788 Test loss=0.421074 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.33815017342567444
[5/24] Train loss=0.3202086389064789
[10/24] Train loss=0.33274316787719727
[15/24] Train loss=0.3017006516456604
[20/24] Train loss=0.3112965524196625
Test set avg_accuracy=78.14% avg_sensitivity=26.15%, avg_specificity=97.50% avg_auc=86.09%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.338841 Test loss=0.433889 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.33452463150024414
[5/24] Train loss=0.3293845057487488
[10/24] Train loss=0.3340999186038971
[15/24] Train loss=0.29197680950164795
[20/24] Train loss=0.30532678961753845
Test set avg_accuracy=82.06% avg_sensitivity=43.81%, avg_specificity=96.30% avg_auc=86.05%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.335575 Test loss=0.422007 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3318946361541748
[5/24] Train loss=0.3246367871761322
[10/24] Train loss=0.33467888832092285
[15/24] Train loss=0.2821897268295288
[20/24] Train loss=0.30172795057296753
Test set avg_accuracy=78.50% avg_sensitivity=32.01%, avg_specificity=95.82% avg_auc=82.14%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.335176 Test loss=0.463397 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3319060206413269
[5/24] Train loss=0.3180534541606903
[10/24] Train loss=0.32425451278686523
[15/24] Train loss=0.2951580882072449
[20/24] Train loss=0.30685368180274963
Test set avg_accuracy=80.91% avg_sensitivity=49.38%, avg_specificity=92.66% avg_auc=84.89%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.333318 Test loss=0.416469 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3260708153247833
[5/24] Train loss=0.31987160444259644
[10/24] Train loss=0.31854644417762756
[15/24] Train loss=0.2894228994846344
[20/24] Train loss=0.3043654263019562
Test set avg_accuracy=82.79% avg_sensitivity=56.05%, avg_specificity=92.74% avg_auc=88.04%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.332677 Test loss=0.376330 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.33291471004486084
[5/24] Train loss=0.3191588521003723
[10/24] Train loss=0.3231576979160309
[15/24] Train loss=0.2959519624710083
[20/24] Train loss=0.3068956136703491
Test set avg_accuracy=83.23% avg_sensitivity=64.01%, avg_specificity=90.39% avg_auc=87.57%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.334118 Test loss=0.378788 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3282213509082794
[5/24] Train loss=0.31656038761138916
[10/24] Train loss=0.32177218794822693
[15/24] Train loss=0.2962416410446167
[20/24] Train loss=0.30564501881599426
Test set avg_accuracy=79.83% avg_sensitivity=31.67%, avg_specificity=97.77% avg_auc=85.80%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.330313 Test loss=0.435108 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3336549401283264
[5/24] Train loss=0.3179398477077484
[10/24] Train loss=0.3332309126853943
[15/24] Train loss=0.29604947566986084
[20/24] Train loss=0.3061760663986206
Test set avg_accuracy=79.83% avg_sensitivity=48.56%, avg_specificity=91.48% avg_auc=83.46%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.330382 Test loss=0.431395 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3329184353351593
[5/24] Train loss=0.3194243013858795
[10/24] Train loss=0.3161459267139435
[15/24] Train loss=0.28824105858802795
[20/24] Train loss=0.3023514449596405
Test set avg_accuracy=81.55% avg_sensitivity=66.70%, avg_specificity=87.08% avg_auc=86.67%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.329490 Test loss=0.399389 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3273299038410187
[5/24] Train loss=0.31786468625068665
[10/24] Train loss=0.31700462102890015
[15/24] Train loss=0.2961180806159973
[20/24] Train loss=0.29727086424827576
Test set avg_accuracy=83.28% avg_sensitivity=66.41%, avg_specificity=89.56% avg_auc=86.07%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.329297 Test loss=0.413259 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3229316771030426
[5/24] Train loss=0.3170017898082733
[10/24] Train loss=0.3129827082157135
[15/24] Train loss=0.2915359437465668
[20/24] Train loss=0.296353280544281
Test set avg_accuracy=83.31% avg_sensitivity=66.27%, avg_specificity=89.65% avg_auc=88.55%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.329234 Test loss=0.368145 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.31723931431770325
[5/24] Train loss=0.3109595775604248
[10/24] Train loss=0.3182356655597687
[15/24] Train loss=0.28953391313552856
[20/24] Train loss=0.3067425489425659
Test set avg_accuracy=83.80% avg_sensitivity=64.59%, avg_specificity=90.96% avg_auc=88.06%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.325305 Test loss=0.373265 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3305467367172241
[5/24] Train loss=0.31084030866622925
[10/24] Train loss=0.32189929485321045
[15/24] Train loss=0.2839202880859375
[20/24] Train loss=0.3045820891857147
Test set avg_accuracy=83.12% avg_sensitivity=70.54%, avg_specificity=87.81% avg_auc=88.74%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.327054 Test loss=0.374415 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3284892439842224
[5/24] Train loss=0.30485770106315613
[10/24] Train loss=0.3199065625667572
[15/24] Train loss=0.2689070701599121
[20/24] Train loss=0.30488237738609314
Test set avg_accuracy=83.61% avg_sensitivity=53.45%, avg_specificity=94.84% avg_auc=87.75%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.322696 Test loss=0.382450 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.326704204082489
[5/24] Train loss=0.3075636625289917
[10/24] Train loss=0.3186403512954712
[15/24] Train loss=0.28153640031814575
[20/24] Train loss=0.29406747221946716
Test set avg_accuracy=82.34% avg_sensitivity=54.89%, avg_specificity=92.57% avg_auc=85.83%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.323824 Test loss=0.400872 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3166431188583374
[5/24] Train loss=0.2989575266838074
[10/24] Train loss=0.31175240874290466
[15/24] Train loss=0.270027220249176
[20/24] Train loss=0.29722559452056885
Test set avg_accuracy=80.07% avg_sensitivity=68.95%, avg_specificity=84.20% avg_auc=86.45%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.319054 Test loss=0.412887 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.32304397225379944
[5/24] Train loss=0.30526962876319885
[10/24] Train loss=0.31322887539863586
[15/24] Train loss=0.2770993709564209
[20/24] Train loss=0.2972806394100189
Test set avg_accuracy=82.94% avg_sensitivity=62.76%, avg_specificity=90.46% avg_auc=88.06%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.319218 Test loss=0.373881 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.31342780590057373
[5/24] Train loss=0.299215167760849
[10/24] Train loss=0.3096085488796234
[15/24] Train loss=0.28038814663887024
[20/24] Train loss=0.2992349863052368
Test set avg_accuracy=81.80% avg_sensitivity=43.19%, avg_specificity=96.18% avg_auc=87.10%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.319647 Test loss=0.409917 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.32412993907928467
[5/24] Train loss=0.3041132688522339
[10/24] Train loss=0.3097287714481354
[15/24] Train loss=0.28255602717399597
[20/24] Train loss=0.3001513183116913
Test set avg_accuracy=84.01% avg_sensitivity=66.41%, avg_specificity=90.56% avg_auc=88.75%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.317470 Test loss=0.364807 Current lr=[0.000224838296036774]

[0/24] Train loss=0.30980685353279114
[5/24] Train loss=0.29622453451156616
[10/24] Train loss=0.30327990651130676
[15/24] Train loss=0.2805570662021637
[20/24] Train loss=0.2873486876487732
Test set avg_accuracy=83.22% avg_sensitivity=53.89%, avg_specificity=94.14% avg_auc=88.76%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.315198 Test loss=0.367328 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3084559142589569
[5/24] Train loss=0.30374014377593994
[10/24] Train loss=0.30680856108665466
[15/24] Train loss=0.282810777425766
[20/24] Train loss=0.288991779088974
Test set avg_accuracy=80.23% avg_sensitivity=34.31%, avg_specificity=97.34% avg_auc=86.27%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.315794 Test loss=0.416173 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3160381615161896
[5/24] Train loss=0.303188681602478
[10/24] Train loss=0.30447617173194885
[15/24] Train loss=0.2796953320503235
[20/24] Train loss=0.28864943981170654
Test set avg_accuracy=82.45% avg_sensitivity=71.50%, avg_specificity=86.53% avg_auc=88.47%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.314338 Test loss=0.378861 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3104669749736786
[5/24] Train loss=0.2963389456272125
[10/24] Train loss=0.30406972765922546
[15/24] Train loss=0.2655019760131836
[20/24] Train loss=0.2871646583080292
Test set avg_accuracy=82.84% avg_sensitivity=70.73%, avg_specificity=87.35% avg_auc=87.53%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.309517 Test loss=0.398329 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3081547021865845
[5/24] Train loss=0.30026569962501526
[10/24] Train loss=0.289268434047699
[15/24] Train loss=0.2605980336666107
[20/24] Train loss=0.2844988703727722
Test set avg_accuracy=82.79% avg_sensitivity=67.75%, avg_specificity=88.38% avg_auc=88.81%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.309121 Test loss=0.369204 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3010982275009155
[5/24] Train loss=0.2973916232585907
[10/24] Train loss=0.29652854800224304
[15/24] Train loss=0.26325446367263794
[20/24] Train loss=0.292029470205307
Test set avg_accuracy=83.72% avg_sensitivity=63.53%, avg_specificity=91.24% avg_auc=88.57%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.308685 Test loss=0.366836 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3037346303462982
[5/24] Train loss=0.29970768094062805
[10/24] Train loss=0.29434847831726074
[15/24] Train loss=0.25867775082588196
[20/24] Train loss=0.2868431806564331
Test set avg_accuracy=82.34% avg_sensitivity=60.70%, avg_specificity=90.40% avg_auc=87.09%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.305961 Test loss=0.387750 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.298531174659729
[5/24] Train loss=0.2915978729724884
[10/24] Train loss=0.2848602533340454
[15/24] Train loss=0.2707405984401703
[20/24] Train loss=0.28213006258010864
Test set avg_accuracy=83.49% avg_sensitivity=58.73%, avg_specificity=92.71% avg_auc=88.32%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.306121 Test loss=0.369167 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.30212417244911194
[5/24] Train loss=0.2937673032283783
[10/24] Train loss=0.290800005197525
[15/24] Train loss=0.27113068103790283
[20/24] Train loss=0.28564557433128357
Test set avg_accuracy=82.57% avg_sensitivity=68.43%, avg_specificity=87.83% avg_auc=87.19%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.303013 Test loss=0.393243 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.29927965998649597
[5/24] Train loss=0.2785835266113281
[10/24] Train loss=0.2860911190509796
[15/24] Train loss=0.2688583731651306
[20/24] Train loss=0.2847563624382019
Test set avg_accuracy=82.79% avg_sensitivity=65.31%, avg_specificity=89.30% avg_auc=87.79%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.300441 Test loss=0.377925 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3103673756122589
[5/24] Train loss=0.2870275378227234
[10/24] Train loss=0.3032669425010681
[15/24] Train loss=0.2694253921508789
[20/24] Train loss=0.28294387459754944
Test set avg_accuracy=82.73% avg_sensitivity=60.41%, avg_specificity=91.05% avg_auc=87.80%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.303878 Test loss=0.374613 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2858865559101105
[5/24] Train loss=0.28614914417266846
[10/24] Train loss=0.28511950373649597
[15/24] Train loss=0.2635737657546997
[20/24] Train loss=0.27314481139183044
Test set avg_accuracy=80.60% avg_sensitivity=46.35%, avg_specificity=93.35% avg_auc=83.89%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.296113 Test loss=0.442912 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.30027666687965393
[5/24] Train loss=0.28818774223327637
[10/24] Train loss=0.2883274555206299
[15/24] Train loss=0.27136120200157166
[20/24] Train loss=0.28588852286338806
Test set avg_accuracy=83.27% avg_sensitivity=62.48%, avg_specificity=91.01% avg_auc=87.79%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.300451 Test loss=0.375141 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2895577847957611
[5/24] Train loss=0.28163084387779236
[10/24] Train loss=0.2911376357078552
[15/24] Train loss=0.27231547236442566
[20/24] Train loss=0.281469464302063
Test set avg_accuracy=82.72% avg_sensitivity=60.70%, avg_specificity=90.92% avg_auc=88.15%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.296666 Test loss=0.371908 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.27918121218681335
[5/24] Train loss=0.2880486845970154
[10/24] Train loss=0.28278109431266785
[15/24] Train loss=0.27152881026268005
[20/24] Train loss=0.2797086834907532
Test set avg_accuracy=82.73% avg_sensitivity=57.10%, avg_specificity=92.28% avg_auc=87.65%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.292362 Test loss=0.379812 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2855963110923767
[5/24] Train loss=0.2716836631298065
[10/24] Train loss=0.2828923165798187
[15/24] Train loss=0.26623085141181946
[20/24] Train loss=0.27038735151290894
Test set avg_accuracy=81.95% avg_sensitivity=57.20%, avg_specificity=91.17% avg_auc=86.95%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.291262 Test loss=0.389962 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2690873146057129
[5/24] Train loss=0.27622926235198975
[10/24] Train loss=0.2764684557914734
[15/24] Train loss=0.2637064754962921
[20/24] Train loss=0.27738475799560547
Test set avg_accuracy=81.42% avg_sensitivity=49.14%, avg_specificity=93.44% avg_auc=86.18%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.289608 Test loss=0.403209 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2785707414150238
[5/24] Train loss=0.2771705090999603
[10/24] Train loss=0.2727568447589874
[15/24] Train loss=0.25612011551856995
[20/24] Train loss=0.2709358036518097
Test set avg_accuracy=79.24% avg_sensitivity=30.37%, avg_specificity=97.44% avg_auc=81.45%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.284652 Test loss=0.470895 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2874232828617096
[5/24] Train loss=0.2744514048099518
[10/24] Train loss=0.2735823392868042
[15/24] Train loss=0.2558174133300781
[20/24] Train loss=0.27788597345352173
Test set avg_accuracy=81.93% avg_sensitivity=52.74%, avg_specificity=92.80% avg_auc=85.93%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.283820 Test loss=0.412021 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.26758497953414917
[5/24] Train loss=0.2762870788574219
[10/24] Train loss=0.25661271810531616
[15/24] Train loss=0.2541162669658661
[20/24] Train loss=0.27668723464012146
Test set avg_accuracy=83.53% avg_sensitivity=66.27%, avg_specificity=89.96% avg_auc=88.36%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.283687 Test loss=0.371314 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.26312413811683655
[5/24] Train loss=0.2640198767185211
[10/24] Train loss=0.27143868803977966
[15/24] Train loss=0.2519056797027588
[20/24] Train loss=0.26897215843200684
Test set avg_accuracy=80.77% avg_sensitivity=46.64%, avg_specificity=93.48% avg_auc=84.42%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.279802 Test loss=0.436622 Current lr=[0.000134135431043539]

[0/24] Train loss=0.2642468512058258
[5/24] Train loss=0.27098408341407776
[10/24] Train loss=0.26553162932395935
[15/24] Train loss=0.25262007117271423
[20/24] Train loss=0.25493311882019043
Test set avg_accuracy=80.85% avg_sensitivity=45.54%, avg_specificity=94.00% avg_auc=85.12%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.277134 Test loss=0.430530 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.2564609944820404
[5/24] Train loss=0.2683579623699188
[10/24] Train loss=0.2729059159755707
[15/24] Train loss=0.26332440972328186
[20/24] Train loss=0.2691141963005066
Test set avg_accuracy=82.75% avg_sensitivity=54.13%, avg_specificity=93.41% avg_auc=87.15%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.278308 Test loss=0.398693 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2668669521808624
[5/24] Train loss=0.260372519493103
[10/24] Train loss=0.25107476115226746
[15/24] Train loss=0.24955610930919647
[20/24] Train loss=0.26853683590888977
Test set avg_accuracy=82.77% avg_sensitivity=57.92%, avg_specificity=92.03% avg_auc=86.20%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.275837 Test loss=0.400917 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.26270443201065063
[5/24] Train loss=0.2643360495567322
[10/24] Train loss=0.2550131678581238
[15/24] Train loss=0.24374830722808838
[20/24] Train loss=0.26683345437049866
Test set avg_accuracy=81.04% avg_sensitivity=45.15%, avg_specificity=94.41% avg_auc=85.26%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.272884 Test loss=0.437455 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.25126907229423523
[5/24] Train loss=0.2645011842250824
[10/24] Train loss=0.2517952620983124
[15/24] Train loss=0.24772383272647858
[20/24] Train loss=0.26876315474510193
Test set avg_accuracy=82.98% avg_sensitivity=58.06%, avg_specificity=92.26% avg_auc=87.51%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.269485 Test loss=0.381611 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.2705918252468109
[5/24] Train loss=0.24729523062705994
[10/24] Train loss=0.2511228024959564
[15/24] Train loss=0.24364683032035828
[20/24] Train loss=0.2551738917827606
Test set avg_accuracy=81.02% avg_sensitivity=59.60%, avg_specificity=88.99% avg_auc=83.28%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.264837 Test loss=0.435182 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.2511674463748932
[5/24] Train loss=0.25693878531455994
[10/24] Train loss=0.242147296667099
[15/24] Train loss=0.2390880137681961
[20/24] Train loss=0.26372748613357544
Test set avg_accuracy=82.08% avg_sensitivity=61.23%, avg_specificity=89.85% avg_auc=86.86%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.263471 Test loss=0.398694 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.24230314791202545
[5/24] Train loss=0.24301746487617493
[10/24] Train loss=0.2446211278438568
[15/24] Train loss=0.2415890246629715
[20/24] Train loss=0.2650192379951477
Test set avg_accuracy=83.31% avg_sensitivity=59.36%, avg_specificity=92.23% avg_auc=87.24%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.262595 Test loss=0.389118 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.24532176554203033
[5/24] Train loss=0.2452860176563263
[10/24] Train loss=0.2662671208381653
[15/24] Train loss=0.23114895820617676
[20/24] Train loss=0.25937873125076294
Test set avg_accuracy=83.28% avg_sensitivity=62.24%, avg_specificity=91.12% avg_auc=86.81%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.262296 Test loss=0.392503 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.25626301765441895
[5/24] Train loss=0.2478567212820053
[10/24] Train loss=0.24196404218673706
[15/24] Train loss=0.2430567741394043
[20/24] Train loss=0.2449956089258194
Test set avg_accuracy=82.94% avg_sensitivity=61.80%, avg_specificity=90.81% avg_auc=87.44%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.257555 Test loss=0.386330 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.24156193435192108
[5/24] Train loss=0.23742501437664032
[10/24] Train loss=0.24150815606117249
[15/24] Train loss=0.23568673431873322
[20/24] Train loss=0.25540870428085327
Test set avg_accuracy=83.55% avg_sensitivity=66.31%, avg_specificity=89.97% avg_auc=87.85%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.253941 Test loss=0.382871 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.2467724084854126
[5/24] Train loss=0.23879863321781158
[10/24] Train loss=0.2360076904296875
[15/24] Train loss=0.2265821248292923
[20/24] Train loss=0.25966981053352356
Test set avg_accuracy=82.43% avg_sensitivity=57.39%, avg_specificity=91.76% avg_auc=85.69%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.251706 Test loss=0.411808 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.24839439988136292
[5/24] Train loss=0.23821666836738586
[10/24] Train loss=0.23413477838039398
[15/24] Train loss=0.22434063255786896
[20/24] Train loss=0.2424258142709732
Test set avg_accuracy=82.55% avg_sensitivity=63.48%, avg_specificity=89.65% avg_auc=87.67%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.248302 Test loss=0.386957 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.23501050472259521
[5/24] Train loss=0.2325095236301422
[10/24] Train loss=0.23898042738437653
[15/24] Train loss=0.2269565761089325
[20/24] Train loss=0.2380058765411377
Test set avg_accuracy=81.54% avg_sensitivity=65.12%, avg_specificity=87.65% avg_auc=86.39%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.242774 Test loss=0.407337 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.22792638838291168
[5/24] Train loss=0.22330328822135925
[10/24] Train loss=0.22841140627861023
[15/24] Train loss=0.2109273374080658
[20/24] Train loss=0.23583902418613434
Test set avg_accuracy=82.53% avg_sensitivity=65.36%, avg_specificity=88.92% avg_auc=87.35%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.239303 Test loss=0.391923 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.22938859462738037
[5/24] Train loss=0.2314409762620926
[10/24] Train loss=0.22646667063236237
[15/24] Train loss=0.2254723161458969
[20/24] Train loss=0.23116570711135864
Test set avg_accuracy=82.63% avg_sensitivity=61.71%, avg_specificity=90.42% avg_auc=86.81%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.239586 Test loss=0.393726 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.22830751538276672
[5/24] Train loss=0.23150503635406494
[10/24] Train loss=0.2197561413049698
[15/24] Train loss=0.21517090499401093
[20/24] Train loss=0.2384551465511322
Test set avg_accuracy=82.68% avg_sensitivity=67.23%, avg_specificity=88.44% avg_auc=87.66%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.236776 Test loss=0.389127 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.21916960179805756
[5/24] Train loss=0.22499944269657135
[10/24] Train loss=0.2200191617012024
[15/24] Train loss=0.2222442924976349
[20/24] Train loss=0.22496981918811798
Test set avg_accuracy=83.19% avg_sensitivity=64.88%, avg_specificity=90.01% avg_auc=87.50%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.233304 Test loss=0.387531 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.21560604870319366
[5/24] Train loss=0.22762738168239594
[10/24] Train loss=0.20792047679424286
[15/24] Train loss=0.21461650729179382
[20/24] Train loss=0.2279207557439804
Test set avg_accuracy=82.25% avg_sensitivity=67.13%, avg_specificity=87.88% avg_auc=86.70%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.228780 Test loss=0.405973 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.21775434911251068
[5/24] Train loss=0.2193945199251175
[10/24] Train loss=0.21300861239433289
[15/24] Train loss=0.2133309543132782
[20/24] Train loss=0.23141691088676453
Test set avg_accuracy=81.85% avg_sensitivity=63.92%, avg_specificity=88.53% avg_auc=86.49%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.229075 Test loss=0.404380 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.21723392605781555
[5/24] Train loss=0.21447357535362244
[10/24] Train loss=0.21825996041297913
[15/24] Train loss=0.20321878790855408
[20/24] Train loss=0.22859406471252441
Test set avg_accuracy=82.03% avg_sensitivity=67.03%, avg_specificity=87.62% avg_auc=87.17%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.226612 Test loss=0.397135 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.21970674395561218
[5/24] Train loss=0.20471026003360748
[10/24] Train loss=0.20540206134319305
[15/24] Train loss=0.2024683803319931
[20/24] Train loss=0.2172618955373764
Test set avg_accuracy=82.34% avg_sensitivity=67.32%, avg_specificity=87.94% avg_auc=86.84%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.221641 Test loss=0.399014 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.2095033973455429
[5/24] Train loss=0.2159472405910492
[10/24] Train loss=0.20583239197731018
[15/24] Train loss=0.20399999618530273
[20/24] Train loss=0.2177301049232483
Test set avg_accuracy=82.03% avg_sensitivity=63.87%, avg_specificity=88.80% avg_auc=86.79%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.219699 Test loss=0.400419 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.20921866595745087
[5/24] Train loss=0.20792651176452637
[10/24] Train loss=0.21601517498493195
[15/24] Train loss=0.20370471477508545
[20/24] Train loss=0.21078655123710632
Test set avg_accuracy=82.32% avg_sensitivity=65.40%, avg_specificity=88.62% avg_auc=87.18%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.218098 Test loss=0.393775 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1997535079717636
[5/24] Train loss=0.20566336810588837
[10/24] Train loss=0.20597074925899506
[15/24] Train loss=0.19517894089221954
[20/24] Train loss=0.21640485525131226
Test set avg_accuracy=81.74% avg_sensitivity=66.65%, avg_specificity=87.37% avg_auc=86.66%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.216057 Test loss=0.402670 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.20537115633487701
[5/24] Train loss=0.2099902331829071
[10/24] Train loss=0.20390239357948303
[15/24] Train loss=0.19553834199905396
[20/24] Train loss=0.21065355837345123
Test set avg_accuracy=82.99% avg_sensitivity=61.85%, avg_specificity=90.87% avg_auc=86.67%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.213830 Test loss=0.395476 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.20599406957626343
[5/24] Train loss=0.1941056102514267
[10/24] Train loss=0.19910231232643127
[15/24] Train loss=0.18847157061100006
[20/24] Train loss=0.207414910197258
Test set avg_accuracy=82.86% avg_sensitivity=64.25%, avg_specificity=89.80% avg_auc=86.72%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.210105 Test loss=0.395420 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.20163175463676453
[5/24] Train loss=0.19617365300655365
[10/24] Train loss=0.198222815990448
[15/24] Train loss=0.1906518042087555
[20/24] Train loss=0.20233413577079773
Test set avg_accuracy=82.73% avg_sensitivity=60.84%, avg_specificity=90.89% avg_auc=86.26%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.209728 Test loss=0.400254 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.20199273526668549
[5/24] Train loss=0.1993512660264969
[10/24] Train loss=0.1969628632068634
[15/24] Train loss=0.190204456448555
[20/24] Train loss=0.20957782864570618
Test set avg_accuracy=81.90% avg_sensitivity=63.34%, avg_specificity=88.81% avg_auc=86.60%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.207362 Test loss=0.398535 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.20379722118377686
[5/24] Train loss=0.1961900144815445
[10/24] Train loss=0.19716352224349976
[15/24] Train loss=0.1894608736038208
[20/24] Train loss=0.20069700479507446
Test set avg_accuracy=82.86% avg_sensitivity=62.67%, avg_specificity=90.39% avg_auc=87.17%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.204911 Test loss=0.387496 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.19057071208953857
[5/24] Train loss=0.19774894416332245
[10/24] Train loss=0.19595851004123688
[15/24] Train loss=0.18389658629894257
[20/24] Train loss=0.19797269999980927
Test set avg_accuracy=83.07% avg_sensitivity=63.87%, avg_specificity=90.23% avg_auc=87.58%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.202176 Test loss=0.387606 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1905452311038971
[5/24] Train loss=0.18897461891174316
[10/24] Train loss=0.18711210787296295
[15/24] Train loss=0.1851087361574173
[20/24] Train loss=0.19441093504428864
Test set avg_accuracy=82.60% avg_sensitivity=61.71%, avg_specificity=90.39% avg_auc=86.31%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.200748 Test loss=0.400447 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.18836922943592072
[5/24] Train loss=0.1919112652540207
[10/24] Train loss=0.18875329196453094
[15/24] Train loss=0.18663178384304047
[20/24] Train loss=0.1978662759065628
Test set avg_accuracy=83.01% avg_sensitivity=62.19%, avg_specificity=90.76% avg_auc=86.76%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.199151 Test loss=0.392054 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.18492165207862854
[5/24] Train loss=0.1836564540863037
[10/24] Train loss=0.1865054816007614
[15/24] Train loss=0.18013820052146912
[20/24] Train loss=0.19536636769771576
Test set avg_accuracy=82.99% avg_sensitivity=64.40%, avg_specificity=89.92% avg_auc=87.21%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.198842 Test loss=0.391268 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.18558445572853088
[5/24] Train loss=0.18600384891033173
[10/24] Train loss=0.19097548723220825
[15/24] Train loss=0.17929084599018097
[20/24] Train loss=0.19699084758758545
Test set avg_accuracy=82.84% avg_sensitivity=63.48%, avg_specificity=90.05% avg_auc=86.91%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.197478 Test loss=0.393425 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.18739956617355347
[5/24] Train loss=0.18716338276863098
[10/24] Train loss=0.18876288831233978
[15/24] Train loss=0.1821730136871338
[20/24] Train loss=0.19590461254119873
Test set avg_accuracy=82.81% avg_sensitivity=63.48%, avg_specificity=90.01% avg_auc=86.76%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.196060 Test loss=0.395469 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.18820728361606598
[5/24] Train loss=0.18754063546657562
[10/24] Train loss=0.18062138557434082
[15/24] Train loss=0.17932897806167603
[20/24] Train loss=0.19146870076656342
Test set avg_accuracy=82.88% avg_sensitivity=64.59%, avg_specificity=89.69% avg_auc=87.05%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.195802 Test loss=0.394773 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.18663538992404938
[5/24] Train loss=0.18670855462551117
[10/24] Train loss=0.18712200224399567
[15/24] Train loss=0.17987868189811707
[20/24] Train loss=0.19414839148521423
Test set avg_accuracy=82.92% avg_sensitivity=63.96%, avg_specificity=89.97% avg_auc=86.89%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.195506 Test loss=0.394007 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1840134710073471
[5/24] Train loss=0.18562164902687073
[10/24] Train loss=0.18442663550376892
[15/24] Train loss=0.17811965942382812
[20/24] Train loss=0.1897733509540558
Test set avg_accuracy=83.05% avg_sensitivity=63.05%, avg_specificity=90.49% avg_auc=86.84%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.194792 Test loss=0.394547 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.18281394243240356
[5/24] Train loss=0.1872960329055786
[10/24] Train loss=0.18408095836639404
[15/24] Train loss=0.1815415471792221
[20/24] Train loss=0.1914031058549881
Test set avg_accuracy=82.76% avg_sensitivity=63.96%, avg_specificity=89.76% avg_auc=87.01%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.194555 Test loss=0.394028 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.18246956169605255
[5/24] Train loss=0.1847933530807495
[10/24] Train loss=0.1837083250284195
[15/24] Train loss=0.17840692400932312
[20/24] Train loss=0.19544602930545807
Test set avg_accuracy=82.75% avg_sensitivity=63.05%, avg_specificity=90.08% avg_auc=86.87%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.193691 Test loss=0.395750 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.18251441419124603
[5/24] Train loss=0.18478018045425415
[10/24] Train loss=0.18291378021240234
[15/24] Train loss=0.1734824925661087
[20/24] Train loss=0.1886768490076065
Test set avg_accuracy=82.92% avg_sensitivity=63.15%, avg_specificity=90.28% avg_auc=86.67%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.193298 Test loss=0.396637 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.17752259969711304
[5/24] Train loss=0.18602539598941803
[10/24] Train loss=0.18329639732837677
[15/24] Train loss=0.1823493242263794
[20/24] Train loss=0.1897812932729721
Test set avg_accuracy=82.84% avg_sensitivity=63.44%, avg_specificity=90.06% avg_auc=86.70%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.192688 Test loss=0.395964 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.18004156649112701
[5/24] Train loss=0.186065211892128
[10/24] Train loss=0.18571867048740387
[15/24] Train loss=0.17740878462791443
[20/24] Train loss=0.1911332607269287
Test set avg_accuracy=82.97% avg_sensitivity=63.68%, avg_specificity=90.15% avg_auc=86.83%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.192756 Test loss=0.394884 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.18419568240642548
[5/24] Train loss=0.1806253045797348
[10/24] Train loss=0.18553364276885986
[15/24] Train loss=0.1740395724773407
[20/24] Train loss=0.1891031712293625
Test set avg_accuracy=83.07% avg_sensitivity=63.96%, avg_specificity=90.19% avg_auc=86.91%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.193366 Test loss=0.394523 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.18036319315433502
[5/24] Train loss=0.18702559173107147
[10/24] Train loss=0.1797056794166565
[15/24] Train loss=0.17394430935382843
[20/24] Train loss=0.18987125158309937
Test set avg_accuracy=83.07% avg_sensitivity=63.63%, avg_specificity=90.31% avg_auc=86.87%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.191921 Test loss=0.394706 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.18405361473560333
[5/24] Train loss=0.18626871705055237
[10/24] Train loss=0.18297643959522247
[15/24] Train loss=0.17473077774047852
[20/24] Train loss=0.18489740788936615
Test set avg_accuracy=83.02% avg_sensitivity=63.44%, avg_specificity=90.31% avg_auc=86.84%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.192523 Test loss=0.395083 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.17990197241306305
[5/24] Train loss=0.18515537679195404
[10/24] Train loss=0.1839989870786667
[15/24] Train loss=0.17204894125461578
[20/24] Train loss=0.1891508251428604
Test set avg_accuracy=83.01% avg_sensitivity=63.53%, avg_specificity=90.26% avg_auc=86.84%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.191880 Test loss=0.394988 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.17896226048469543
[5/24] Train loss=0.18558353185653687
[10/24] Train loss=0.18079820275306702
[15/24] Train loss=0.17867816984653473
[20/24] Train loss=0.19060416519641876
Test set avg_accuracy=83.05% avg_sensitivity=63.58%, avg_specificity=90.30% avg_auc=86.87%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.192335 Test loss=0.394844 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=83.24% sen=71.50%, spe=87.62%, auc=88.61%!
Fold[6] Avg_overlap=0.36%(0.30817292811029007)
[0/24] Train loss=0.7338870167732239
[5/24] Train loss=0.7275958061218262
[10/24] Train loss=0.7212324142456055
[15/24] Train loss=0.7166104912757874
[20/24] Train loss=0.7157847285270691
Test set avg_accuracy=55.72% avg_sensitivity=42.10%, avg_specificity=60.91% avg_auc=52.36%
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.722422 Test loss=0.691534 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7115229368209839
[5/24] Train loss=0.7101927995681763
[10/24] Train loss=0.704992949962616
[15/24] Train loss=0.6941266655921936
[20/24] Train loss=0.6955112218856812
Test set avg_accuracy=59.51% avg_sensitivity=48.42%, avg_specificity=63.73% avg_auc=59.42%
Best model saved!! Metric=-94.92099061992101!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.704711 Test loss=0.658198 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6945846676826477
[5/24] Train loss=0.6932262778282166
[10/24] Train loss=0.683209240436554
[15/24] Train loss=0.6769034266471863
[20/24] Train loss=0.6714255213737488
Test set avg_accuracy=62.88% avg_sensitivity=50.83%, avg_specificity=67.48% avg_auc=63.92%
Best model saved!! Metric=-80.9052954709187!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.687730 Test loss=0.636694 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6762980222702026
[5/24] Train loss=0.6787142753601074
[10/24] Train loss=0.6681901812553406
[15/24] Train loss=0.6607154011726379
[20/24] Train loss=0.6484060883522034
Test set avg_accuracy=66.95% avg_sensitivity=54.13%, avg_specificity=71.85% avg_auc=68.27%
Best model saved!! Metric=-64.80699113959173!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.668751 Test loss=0.614383 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.652944803237915
[5/24] Train loss=0.6578630208969116
[10/24] Train loss=0.6516045331954956
[15/24] Train loss=0.6372760534286499
[20/24] Train loss=0.6326302886009216
Test set avg_accuracy=69.18% avg_sensitivity=56.25%, avg_specificity=74.11% avg_auc=71.37%
Best model saved!! Metric=-55.09296761224626!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.651143 Test loss=0.594495 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6318982243537903
[5/24] Train loss=0.633023738861084
[10/24] Train loss=0.6301276087760925
[15/24] Train loss=0.614919900894165
[20/24] Train loss=0.6061955690383911
Test set avg_accuracy=71.82% avg_sensitivity=60.21%, avg_specificity=76.25% avg_auc=74.72%
Best model saved!! Metric=-42.994551156748166!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.628364 Test loss=0.571377 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6147881746292114
[5/24] Train loss=0.6171928644180298
[10/24] Train loss=0.6041770577430725
[15/24] Train loss=0.5841377377510071
[20/24] Train loss=0.5686587691307068
Test set avg_accuracy=73.92% avg_sensitivity=65.91%, avg_specificity=76.97% avg_auc=78.26%
Best model saved!! Metric=-30.93173970137984!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.603284 Test loss=0.546747 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5830395817756653
[5/24] Train loss=0.5865023732185364
[10/24] Train loss=0.582923412322998
[15/24] Train loss=0.5617464184761047
[20/24] Train loss=0.5420634746551514
Test set avg_accuracy=76.26% avg_sensitivity=69.78%, avg_specificity=78.74% avg_auc=80.93%
Best model saved!! Metric=-20.292977022253623!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.574157 Test loss=0.517955 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5584471821784973
[5/24] Train loss=0.5514237880706787
[10/24] Train loss=0.5464210510253906
[15/24] Train loss=0.5297830700874329
[20/24] Train loss=0.5049483180046082
Test set avg_accuracy=77.54% avg_sensitivity=71.29%, avg_specificity=79.92% avg_auc=82.92%
Best model saved!! Metric=-14.33169734601006!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.546212 Test loss=0.493395 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5265962481498718
[5/24] Train loss=0.5219280123710632
[10/24] Train loss=0.5267271399497986
[15/24] Train loss=0.501573383808136
[20/24] Train loss=0.47899648547172546
Test set avg_accuracy=78.54% avg_sensitivity=72.47%, avg_specificity=80.86% avg_auc=84.19%
Best model saved!! Metric=-9.944904247768093!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.518495 Test loss=0.476240 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5078690648078918
[5/24] Train loss=0.48917466402053833
[10/24] Train loss=0.5030228495597839
[15/24] Train loss=0.48163509368896484
[20/24] Train loss=0.45390769839286804
Test set avg_accuracy=79.75% avg_sensitivity=71.48%, avg_specificity=82.91% avg_auc=85.15%
Best model saved!! Metric=-6.71128163290706!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.495624 Test loss=0.453749 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.47790780663490295
[5/24] Train loss=0.46173548698425293
[10/24] Train loss=0.47751015424728394
[15/24] Train loss=0.45700564980506897
[20/24] Train loss=0.4319048821926117
Test set avg_accuracy=80.57% avg_sensitivity=70.39%, avg_specificity=84.46% avg_auc=86.08%
Best model saved!! Metric=-4.4963967098178586!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.473889 Test loss=0.432923 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4659039378166199
[5/24] Train loss=0.43964216113090515
[10/24] Train loss=0.46616196632385254
[15/24] Train loss=0.4424385130405426
[20/24] Train loss=0.41443389654159546
Test set avg_accuracy=81.18% avg_sensitivity=67.85%, avg_specificity=86.27% avg_auc=86.50%
Best model saved!! Metric=-4.195248872988344!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.456819 Test loss=0.420133 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4498772621154785
[5/24] Train loss=0.42537519335746765
[10/24] Train loss=0.4477611780166626
[15/24] Train loss=0.41927188634872437
[20/24] Train loss=0.39502766728401184
Test set avg_accuracy=81.56% avg_sensitivity=66.90%, avg_specificity=87.16% avg_auc=87.07%
Best model saved!! Metric=-3.3089615043340785!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.441241 Test loss=0.407140 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4361855983734131
[5/24] Train loss=0.4099055230617523
[10/24] Train loss=0.4377250075340271
[15/24] Train loss=0.4067858159542084
[20/24] Train loss=0.38578835129737854
Test set avg_accuracy=81.80% avg_sensitivity=62.47%, avg_specificity=89.17% avg_auc=87.19%
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.429146 Test loss=0.399512 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4190254211425781
[5/24] Train loss=0.3865039348602295
[10/24] Train loss=0.42544564604759216
[15/24] Train loss=0.3945441246032715
[20/24] Train loss=0.3805738091468811
Test set avg_accuracy=81.72% avg_sensitivity=59.41%, avg_specificity=90.23% avg_auc=87.42%
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.416049 Test loss=0.394667 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4090825021266937
[5/24] Train loss=0.37889349460601807
[10/24] Train loss=0.4106962978839874
[15/24] Train loss=0.3859488070011139
[20/24] Train loss=0.36526405811309814
Test set avg_accuracy=82.01% avg_sensitivity=60.91%, avg_specificity=90.05% avg_auc=87.75%
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.407481 Test loss=0.390786 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.39965391159057617
[5/24] Train loss=0.37021780014038086
[10/24] Train loss=0.4004379212856293
[15/24] Train loss=0.3757644593715668
[20/24] Train loss=0.3521115779876709
Test set avg_accuracy=82.01% avg_sensitivity=60.02%, avg_specificity=90.39% avg_auc=87.86%
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.399052 Test loss=0.387446 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.39557433128356934
[5/24] Train loss=0.3587080240249634
[10/24] Train loss=0.39589011669158936
[15/24] Train loss=0.3726349472999573
[20/24] Train loss=0.3490387201309204
Test set avg_accuracy=82.30% avg_sensitivity=61.29%, avg_specificity=90.32% avg_auc=87.99%
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.392195 Test loss=0.385416 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.38576194643974304
[5/24] Train loss=0.352812796831131
[10/24] Train loss=0.38760578632354736
[15/24] Train loss=0.3621588349342346
[20/24] Train loss=0.34543076157569885
Test set avg_accuracy=82.15% avg_sensitivity=65.16%, avg_specificity=88.63% avg_auc=88.25%
Best model saved!! Metric=-1.8105119683027766!!
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.385862 Test loss=0.382690 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3812216520309448
[5/24] Train loss=0.34700432419776917
[10/24] Train loss=0.3831057548522949
[15/24] Train loss=0.36143994331359863
[20/24] Train loss=0.3376803696155548
Test set avg_accuracy=81.93% avg_sensitivity=67.23%, avg_specificity=87.53% avg_auc=88.43%
Best model saved!! Metric=-0.8737864074839337!!
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.380740 Test loss=0.382408 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.37392789125442505
[5/24] Train loss=0.3406887948513031
[10/24] Train loss=0.38332951068878174
[15/24] Train loss=0.35839343070983887
[20/24] Train loss=0.33286479115486145
Test set avg_accuracy=82.34% avg_sensitivity=64.59%, avg_specificity=89.12% avg_auc=88.51%
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.376978 Test loss=0.378418 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3724830746650696
[5/24] Train loss=0.33448803424835205
[10/24] Train loss=0.38698703050613403
[15/24] Train loss=0.34314003586769104
[20/24] Train loss=0.3308562636375427
Test set avg_accuracy=82.20% avg_sensitivity=67.14%, avg_specificity=87.95% avg_auc=88.66%
Best model saved!! Metric=-0.0586225430349856!!
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.373429 Test loss=0.377329 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.37037646770477295
[5/24] Train loss=0.3344396650791168
[10/24] Train loss=0.37983953952789307
[15/24] Train loss=0.3408544957637787
[20/24] Train loss=0.32673215866088867
Test set avg_accuracy=82.32% avg_sensitivity=63.70%, avg_specificity=89.42% avg_auc=88.84%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.369804 Test loss=0.371882 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.36672693490982056
[5/24] Train loss=0.33136293292045593
[10/24] Train loss=0.37241455912590027
[15/24] Train loss=0.34207218885421753
[20/24] Train loss=0.3248898386955261
Test set avg_accuracy=82.94% avg_sensitivity=63.98%, avg_specificity=90.18% avg_auc=88.93%
Best model saved!! Metric=0.032361913601548054!!
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.368355 Test loss=0.371305 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3703095018863678
[5/24] Train loss=0.33174070715904236
[10/24] Train loss=0.3723265528678894
[15/24] Train loss=0.3338782787322998
[20/24] Train loss=0.3241051733493805
Test set avg_accuracy=82.03% avg_sensitivity=70.44%, avg_specificity=86.45% avg_auc=88.39%
Best model saved!! Metric=1.3184774352560424!!
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.366255 Test loss=0.390753 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3604288697242737
[5/24] Train loss=0.32633674144744873
[10/24] Train loss=0.37497493624687195
[15/24] Train loss=0.3354227542877197
[20/24] Train loss=0.32004812359809875
Test set avg_accuracy=82.03% avg_sensitivity=66.71%, avg_specificity=87.88% avg_auc=88.52%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.364323 Test loss=0.378758 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.358638197183609
[5/24] Train loss=0.31817731261253357
[10/24] Train loss=0.366720050573349
[15/24] Train loss=0.32996731996536255
[20/24] Train loss=0.3251996636390686
Test set avg_accuracy=82.27% avg_sensitivity=53.47%, avg_specificity=93.25% avg_auc=88.91%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.361192 Test loss=0.374929 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3592860698699951
[5/24] Train loss=0.3224891126155853
[10/24] Train loss=0.3663083016872406
[15/24] Train loss=0.3327338993549347
[20/24] Train loss=0.3132869303226471
Test set avg_accuracy=79.52% avg_sensitivity=35.79%, avg_specificity=96.20% avg_auc=87.81%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.359427 Test loss=0.416429 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.35787010192871094
[5/24] Train loss=0.32697272300720215
[10/24] Train loss=0.3670780062675476
[15/24] Train loss=0.3376098573207855
[20/24] Train loss=0.31676697731018066
Test set avg_accuracy=80.36% avg_sensitivity=42.06%, avg_specificity=94.98% avg_auc=87.85%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.360651 Test loss=0.397320 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.36299052834510803
[5/24] Train loss=0.32033801078796387
[10/24] Train loss=0.36062321066856384
[15/24] Train loss=0.3194398283958435
[20/24] Train loss=0.3224756121635437
Test set avg_accuracy=79.93% avg_sensitivity=36.92%, avg_specificity=96.35% avg_auc=88.55%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.356816 Test loss=0.395185 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3569508492946625
[5/24] Train loss=0.32001936435699463
[10/24] Train loss=0.3613657057285309
[15/24] Train loss=0.32748711109161377
[20/24] Train loss=0.3143596053123474
Test set avg_accuracy=80.25% avg_sensitivity=39.98%, avg_specificity=95.61% avg_auc=88.21%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.357553 Test loss=0.395888 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3556945323944092
[5/24] Train loss=0.3161914348602295
[10/24] Train loss=0.3619830012321472
[15/24] Train loss=0.3295193016529083
[20/24] Train loss=0.31183549761772156
Test set avg_accuracy=77.73% avg_sensitivity=27.63%, avg_specificity=96.85% avg_auc=85.58%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.353834 Test loss=0.439299 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3470815122127533
[5/24] Train loss=0.32242387533187866
[10/24] Train loss=0.3670186698436737
[15/24] Train loss=0.32614666223526
[20/24] Train loss=0.31613078713417053
Test set avg_accuracy=77.70% avg_sensitivity=29.37%, avg_specificity=96.13% avg_auc=85.20%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.354447 Test loss=0.452887 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3535991907119751
[5/24] Train loss=0.31897246837615967
[10/24] Train loss=0.36116960644721985
[15/24] Train loss=0.32576388120651245
[20/24] Train loss=0.31242576241493225
Test set avg_accuracy=78.03% avg_sensitivity=27.58%, avg_specificity=97.28% avg_auc=86.78%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.355662 Test loss=0.425252 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.34808892011642456
[5/24] Train loss=0.317770779132843
[10/24] Train loss=0.35729870200157166
[15/24] Train loss=0.3228697180747986
[20/24] Train loss=0.3160378038883209
Test set avg_accuracy=76.30% avg_sensitivity=19.47%, avg_specificity=97.99% avg_auc=85.49%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.352631 Test loss=0.471396 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3456118702888489
[5/24] Train loss=0.31773802638053894
[10/24] Train loss=0.36339929699897766
[15/24] Train loss=0.32090577483177185
[20/24] Train loss=0.30665215849876404
Test set avg_accuracy=79.65% avg_sensitivity=37.58%, avg_specificity=95.70% avg_auc=87.89%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.353482 Test loss=0.406994 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.34181907773017883
[5/24] Train loss=0.31516438722610474
[10/24] Train loss=0.3585844933986664
[15/24] Train loss=0.32537561655044556
[20/24] Train loss=0.31497421860694885
Test set avg_accuracy=79.24% avg_sensitivity=35.36%, avg_specificity=95.99% avg_auc=87.60%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.351903 Test loss=0.407743 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3460504710674286
[5/24] Train loss=0.3121219575405121
[10/24] Train loss=0.36017274856567383
[15/24] Train loss=0.31665346026420593
[20/24] Train loss=0.31170904636383057
Test set avg_accuracy=81.99% avg_sensitivity=49.69%, avg_specificity=94.32% avg_auc=88.81%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.350981 Test loss=0.380194 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.34160885214805603
[5/24] Train loss=0.31095245480537415
[10/24] Train loss=0.36471134424209595
[15/24] Train loss=0.3112567961215973
[20/24] Train loss=0.3156779706478119
Test set avg_accuracy=77.79% avg_sensitivity=30.93%, avg_specificity=95.66% avg_auc=85.02%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.350132 Test loss=0.434768 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3477610945701599
[5/24] Train loss=0.30374449491500854
[10/24] Train loss=0.35637786984443665
[15/24] Train loss=0.3089960217475891
[20/24] Train loss=0.317505419254303
Test set avg_accuracy=80.04% avg_sensitivity=41.87%, avg_specificity=94.60% avg_auc=87.91%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.347879 Test loss=0.394896 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.33386099338531494
[5/24] Train loss=0.3205186724662781
[10/24] Train loss=0.3673665225505829
[15/24] Train loss=0.31265419721603394
[20/24] Train loss=0.3094111979007721
Test set avg_accuracy=79.00% avg_sensitivity=33.95%, avg_specificity=96.19% avg_auc=87.38%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.347934 Test loss=0.416665 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.33570361137390137
[5/24] Train loss=0.31465399265289307
[10/24] Train loss=0.3579098582267761
[15/24] Train loss=0.3298976421356201
[20/24] Train loss=0.3158610165119171
Test set avg_accuracy=80.13% avg_sensitivity=39.56%, avg_specificity=95.61% avg_auc=88.69%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.349479 Test loss=0.393704 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.34485647082328796
[5/24] Train loss=0.30617719888687134
[10/24] Train loss=0.3580588698387146
[15/24] Train loss=0.32111164927482605
[20/24] Train loss=0.3147936165332794
Test set avg_accuracy=82.15% avg_sensitivity=49.41%, avg_specificity=94.64% avg_auc=88.33%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.347906 Test loss=0.386276 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3494536280632019
[5/24] Train loss=0.3064403831958771
[10/24] Train loss=0.36050161719322205
[15/24] Train loss=0.32780253887176514
[20/24] Train loss=0.30788445472717285
Test set avg_accuracy=81.29% avg_sensitivity=49.55%, avg_specificity=93.40% avg_auc=87.64%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.347181 Test loss=0.398316 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3357771337032318
[5/24] Train loss=0.31066009402275085
[10/24] Train loss=0.3584507703781128
[15/24] Train loss=0.31279343366622925
[20/24] Train loss=0.31332772970199585
Test set avg_accuracy=82.16% avg_sensitivity=61.10%, avg_specificity=90.20% avg_auc=87.45%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.347649 Test loss=0.400403 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.337504506111145
[5/24] Train loss=0.314382940530777
[10/24] Train loss=0.3515389859676361
[15/24] Train loss=0.31184443831443787
[20/24] Train loss=0.3109291195869446
Test set avg_accuracy=82.75% avg_sensitivity=57.28%, avg_specificity=92.46% avg_auc=88.72%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.345109 Test loss=0.374299 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3503319025039673
[5/24] Train loss=0.2971537411212921
[10/24] Train loss=0.3616470396518707
[15/24] Train loss=0.314997136592865
[20/24] Train loss=0.31141796708106995
Test set avg_accuracy=82.90% avg_sensitivity=60.21%, avg_specificity=91.56% avg_auc=88.57%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.345432 Test loss=0.374052 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.34074220061302185
[5/24] Train loss=0.3046436011791229
[10/24] Train loss=0.35092952847480774
[15/24] Train loss=0.31874385476112366
[20/24] Train loss=0.31130653619766235
Test set avg_accuracy=78.70% avg_sensitivity=38.52%, avg_specificity=94.03% avg_auc=83.32%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.347090 Test loss=0.448025 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3384109139442444
[5/24] Train loss=0.30116382241249084
[10/24] Train loss=0.35125842690467834
[15/24] Train loss=0.30821317434310913
[20/24] Train loss=0.3032923638820648
Test set avg_accuracy=79.27% avg_sensitivity=35.22%, avg_specificity=96.08% avg_auc=86.40%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.344025 Test loss=0.435606 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3342200219631195
[5/24] Train loss=0.2990416884422302
[10/24] Train loss=0.35304903984069824
[15/24] Train loss=0.3068426251411438
[20/24] Train loss=0.3121281862258911
Test set avg_accuracy=80.56% avg_sensitivity=46.82%, avg_specificity=93.43% avg_auc=86.15%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.342328 Test loss=0.408370 Current lr=[0.000297555943323901]

[0/24] Train loss=0.33490681648254395
[5/24] Train loss=0.3035966455936432
[10/24] Train loss=0.3445223569869995
[15/24] Train loss=0.30681750178337097
[20/24] Train loss=0.3158326745033264
Test set avg_accuracy=82.54% avg_sensitivity=58.89%, avg_specificity=91.56% avg_auc=87.53%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.340792 Test loss=0.391017 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3393344283103943
[5/24] Train loss=0.2941877543926239
[10/24] Train loss=0.35121139883995056
[15/24] Train loss=0.3057557940483093
[20/24] Train loss=0.3075205087661743
Test set avg_accuracy=82.79% avg_sensitivity=58.98%, avg_specificity=91.87% avg_auc=88.59%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.340224 Test loss=0.374734 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3292955160140991
[5/24] Train loss=0.29549935460090637
[10/24] Train loss=0.35160091519355774
[15/24] Train loss=0.31240755319595337
[20/24] Train loss=0.30660831928253174
Test set avg_accuracy=82.20% avg_sensitivity=52.52%, avg_specificity=93.52% avg_auc=87.21%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.338685 Test loss=0.395475 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.33622241020202637
[5/24] Train loss=0.3080618381500244
[10/24] Train loss=0.3556270897388458
[15/24] Train loss=0.3269907832145691
[20/24] Train loss=0.31544458866119385
Test set avg_accuracy=82.16% avg_sensitivity=55.07%, avg_specificity=92.50% avg_auc=87.59%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.339886 Test loss=0.388625 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.33085325360298157
[5/24] Train loss=0.3065377175807953
[10/24] Train loss=0.35485604405403137
[15/24] Train loss=0.31213462352752686
[20/24] Train loss=0.3099191188812256
Test set avg_accuracy=81.97% avg_sensitivity=52.38%, avg_specificity=93.25% avg_auc=87.57%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.341803 Test loss=0.401453 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3327893316745758
[5/24] Train loss=0.2965443432331085
[10/24] Train loss=0.35660889744758606
[15/24] Train loss=0.30544352531433105
[20/24] Train loss=0.31082913279533386
Test set avg_accuracy=82.49% avg_sensitivity=56.58%, avg_specificity=92.37% avg_auc=87.05%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.335489 Test loss=0.392541 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3361476957798004
[5/24] Train loss=0.30489760637283325
[10/24] Train loss=0.35138216614723206
[15/24] Train loss=0.3094661235809326
[20/24] Train loss=0.30413463711738586
Test set avg_accuracy=80.94% avg_sensitivity=42.86%, avg_specificity=95.47% avg_auc=88.70%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.337769 Test loss=0.393975 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3294055461883545
[5/24] Train loss=0.2979062497615814
[10/24] Train loss=0.34033897519111633
[15/24] Train loss=0.3154972791671753
[20/24] Train loss=0.30580228567123413
Test set avg_accuracy=79.83% avg_sensitivity=39.60%, avg_specificity=95.18% avg_auc=82.89%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.333654 Test loss=0.447258 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3360992670059204
[5/24] Train loss=0.2954908609390259
[10/24] Train loss=0.35603898763656616
[15/24] Train loss=0.30806514620780945
[20/24] Train loss=0.3029116094112396
Test set avg_accuracy=80.74% avg_sensitivity=54.31%, avg_specificity=90.83% avg_auc=86.42%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.337462 Test loss=0.431567 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.334488183259964
[5/24] Train loss=0.30558377504348755
[10/24] Train loss=0.348555326461792
[15/24] Train loss=0.30501776933670044
[20/24] Train loss=0.30336394906044006
Test set avg_accuracy=82.24% avg_sensitivity=64.64%, avg_specificity=88.95% avg_auc=87.41%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.335879 Test loss=0.394437 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3323989510536194
[5/24] Train loss=0.2988578975200653
[10/24] Train loss=0.3441552519798279
[15/24] Train loss=0.3033224046230316
[20/24] Train loss=0.2998804450035095
Test set avg_accuracy=79.92% avg_sensitivity=43.61%, avg_specificity=93.78% avg_auc=83.70%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.333028 Test loss=0.447811 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.32334935665130615
[5/24] Train loss=0.2996707558631897
[10/24] Train loss=0.33581018447875977
[15/24] Train loss=0.3039787709712982
[20/24] Train loss=0.3055479824542999
Test set avg_accuracy=82.40% avg_sensitivity=53.47%, avg_specificity=93.43% avg_auc=87.89%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.331069 Test loss=0.385786 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.33173438906669617
[5/24] Train loss=0.29018619656562805
[10/24] Train loss=0.33663123846054077
[15/24] Train loss=0.3033343255519867
[20/24] Train loss=0.30039718747138977
Test set avg_accuracy=81.26% avg_sensitivity=54.83%, avg_specificity=91.35% avg_auc=87.14%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.330811 Test loss=0.402352 Current lr=[0.000276307469034998]

[0/24] Train loss=0.33314618468284607
[5/24] Train loss=0.28760796785354614
[10/24] Train loss=0.34999123215675354
[15/24] Train loss=0.3032384514808655
[20/24] Train loss=0.3030488193035126
Test set avg_accuracy=80.90% avg_sensitivity=47.95%, avg_specificity=93.47% avg_auc=86.49%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.331662 Test loss=0.404996 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.33410322666168213
[5/24] Train loss=0.29618963599205017
[10/24] Train loss=0.3496547043323517
[15/24] Train loss=0.3164868652820587
[20/24] Train loss=0.3030327558517456
Test set avg_accuracy=82.02% avg_sensitivity=59.92%, avg_specificity=90.45% avg_auc=87.13%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.333674 Test loss=0.390954 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.32643723487854004
[5/24] Train loss=0.29531699419021606
[10/24] Train loss=0.3512526750564575
[15/24] Train loss=0.30545201897621155
[20/24] Train loss=0.2984524667263031
Test set avg_accuracy=82.53% avg_sensitivity=65.30%, avg_specificity=89.10% avg_auc=87.20%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.329425 Test loss=0.401618 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3273279666900635
[5/24] Train loss=0.2920202314853668
[10/24] Train loss=0.3487677574157715
[15/24] Train loss=0.3047355115413666
[20/24] Train loss=0.301427960395813
Test set avg_accuracy=79.70% avg_sensitivity=66.43%, avg_specificity=84.76% avg_auc=85.10%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.330371 Test loss=0.428456 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.34545060992240906
[5/24] Train loss=0.28731468319892883
[10/24] Train loss=0.3385607898235321
[15/24] Train loss=0.3017103970050812
[20/24] Train loss=0.3011859059333801
Test set avg_accuracy=81.97% avg_sensitivity=60.16%, avg_specificity=90.29% avg_auc=86.76%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.331679 Test loss=0.396695 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.32540610432624817
[5/24] Train loss=0.2900988459587097
[10/24] Train loss=0.35190558433532715
[15/24] Train loss=0.298878937959671
[20/24] Train loss=0.30064767599105835
Test set avg_accuracy=80.10% avg_sensitivity=62.14%, avg_specificity=86.96% avg_auc=84.32%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.330691 Test loss=0.430638 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.32532304525375366
[5/24] Train loss=0.29688361287117004
[10/24] Train loss=0.3478599190711975
[15/24] Train loss=0.2973766028881073
[20/24] Train loss=0.2996208369731903
Test set avg_accuracy=81.18% avg_sensitivity=67.85%, avg_specificity=86.27% avg_auc=87.19%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.327892 Test loss=0.404085 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3200676441192627
[5/24] Train loss=0.2916875183582306
[10/24] Train loss=0.34061160683631897
[15/24] Train loss=0.2937832474708557
[20/24] Train loss=0.29732024669647217
Test set avg_accuracy=81.69% avg_sensitivity=65.91%, avg_specificity=87.71% avg_auc=88.38%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.328614 Test loss=0.380924 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.33205848932266235
[5/24] Train loss=0.3042643964290619
[10/24] Train loss=0.34681910276412964
[15/24] Train loss=0.3014513850212097
[20/24] Train loss=0.30412518978118896
Test set avg_accuracy=81.39% avg_sensitivity=64.40%, avg_specificity=87.88% avg_auc=87.24%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.329848 Test loss=0.400622 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3170272707939148
[5/24] Train loss=0.291456937789917
[10/24] Train loss=0.33847397565841675
[15/24] Train loss=0.2957780361175537
[20/24] Train loss=0.29433271288871765
Test set avg_accuracy=81.22% avg_sensitivity=63.79%, avg_specificity=87.88% avg_auc=86.58%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.325530 Test loss=0.403601 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3246747851371765
[5/24] Train loss=0.287874311208725
[10/24] Train loss=0.340621680021286
[15/24] Train loss=0.29721179604530334
[20/24] Train loss=0.2938683331012726
Test set avg_accuracy=81.09% avg_sensitivity=62.05%, avg_specificity=88.36% avg_auc=86.81%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.321644 Test loss=0.403952 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.31923753023147583
[5/24] Train loss=0.28987792134284973
[10/24] Train loss=0.3381028473377228
[15/24] Train loss=0.2924322187900543
[20/24] Train loss=0.29191771149635315
Test set avg_accuracy=81.74% avg_sensitivity=50.35%, avg_specificity=93.72% avg_auc=87.37%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.321003 Test loss=0.396980 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3230799436569214
[5/24] Train loss=0.28779879212379456
[10/24] Train loss=0.3417184352874756
[15/24] Train loss=0.2869916558265686
[20/24] Train loss=0.29057514667510986
Test set avg_accuracy=81.63% avg_sensitivity=59.03%, avg_specificity=90.25% avg_auc=87.84%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.320607 Test loss=0.383764 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.31357645988464355
[5/24] Train loss=0.2832256555557251
[10/24] Train loss=0.32922160625457764
[15/24] Train loss=0.2930683195590973
[20/24] Train loss=0.29590728878974915
Test set avg_accuracy=83.07% avg_sensitivity=66.05%, avg_specificity=89.57% avg_auc=88.07%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.318008 Test loss=0.381312 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.31773144006729126
[5/24] Train loss=0.28728416562080383
[10/24] Train loss=0.346792995929718
[15/24] Train loss=0.28724217414855957
[20/24] Train loss=0.29489919543266296
Test set avg_accuracy=81.78% avg_sensitivity=63.70%, avg_specificity=88.69% avg_auc=87.01%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.320346 Test loss=0.400126 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.31690269708633423
[5/24] Train loss=0.2872435450553894
[10/24] Train loss=0.33101093769073486
[15/24] Train loss=0.28860190510749817
[20/24] Train loss=0.2938593029975891
Test set avg_accuracy=80.12% avg_sensitivity=63.32%, avg_specificity=86.53% avg_auc=84.80%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.317942 Test loss=0.433760 Current lr=[0.000224838296036774]

[0/24] Train loss=0.30764371156692505
[5/24] Train loss=0.2828516364097595
[10/24] Train loss=0.3329642117023468
[15/24] Train loss=0.28317803144454956
[20/24] Train loss=0.28429973125457764
Test set avg_accuracy=82.46% avg_sensitivity=58.75%, avg_specificity=91.51% avg_auc=87.16%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.317149 Test loss=0.390201 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3136194348335266
[5/24] Train loss=0.2804385721683502
[10/24] Train loss=0.33259573578834534
[15/24] Train loss=0.3050871789455414
[20/24] Train loss=0.28324005007743835
Test set avg_accuracy=81.68% avg_sensitivity=49.22%, avg_specificity=94.06% avg_auc=87.22%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.315977 Test loss=0.398970 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3024294674396515
[5/24] Train loss=0.2770345211029053
[10/24] Train loss=0.3266642391681671
[15/24] Train loss=0.2815014719963074
[20/24] Train loss=0.2807655334472656
Test set avg_accuracy=82.19% avg_sensitivity=54.93%, avg_specificity=92.59% avg_auc=86.04%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.311118 Test loss=0.404246 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3072955012321472
[5/24] Train loss=0.2743372619152069
[10/24] Train loss=0.3178372085094452
[15/24] Train loss=0.2944676876068115
[20/24] Train loss=0.2880703806877136
Test set avg_accuracy=81.64% avg_sensitivity=57.10%, avg_specificity=91.01% avg_auc=87.43%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.312309 Test loss=0.391618 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2992717921733856
[5/24] Train loss=0.2802870571613312
[10/24] Train loss=0.3190135657787323
[15/24] Train loss=0.29055798053741455
[20/24] Train loss=0.28386440873146057
Test set avg_accuracy=81.42% avg_sensitivity=57.28%, avg_specificity=90.63% avg_auc=84.64%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.309500 Test loss=0.421935 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3034396767616272
[5/24] Train loss=0.2795291841030121
[10/24] Train loss=0.3193739056587219
[15/24] Train loss=0.28687772154808044
[20/24] Train loss=0.2885817587375641
Test set avg_accuracy=81.32% avg_sensitivity=51.91%, avg_specificity=92.53% avg_auc=86.22%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.305967 Test loss=0.406821 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.297348290681839
[5/24] Train loss=0.2763063311576843
[10/24] Train loss=0.3286917209625244
[15/24] Train loss=0.30926287174224854
[20/24] Train loss=0.2803284823894501
Test set avg_accuracy=81.51% avg_sensitivity=51.72%, avg_specificity=92.88% avg_auc=86.73%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.310303 Test loss=0.406414 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3076440989971161
[5/24] Train loss=0.27675139904022217
[10/24] Train loss=0.31573882699012756
[15/24] Train loss=0.2831558287143707
[20/24] Train loss=0.2806989848613739
Test set avg_accuracy=81.16% avg_sensitivity=49.74%, avg_specificity=93.15% avg_auc=85.94%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.308133 Test loss=0.414243 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2988680601119995
[5/24] Train loss=0.2652456760406494
[10/24] Train loss=0.3006434738636017
[15/24] Train loss=0.27490851283073425
[20/24] Train loss=0.2780633866786957
Test set avg_accuracy=79.74% avg_sensitivity=47.48%, avg_specificity=92.05% avg_auc=84.73%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.299725 Test loss=0.427662 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.28569549322128296
[5/24] Train loss=0.2714794874191284
[10/24] Train loss=0.3125394284725189
[15/24] Train loss=0.27693596482276917
[20/24] Train loss=0.2795601785182953
Test set avg_accuracy=80.87% avg_sensitivity=58.89%, avg_specificity=89.26% avg_auc=84.40%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.302029 Test loss=0.428251 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.31101056933403015
[5/24] Train loss=0.2688918709754944
[10/24] Train loss=0.3046162724494934
[15/24] Train loss=0.2743094861507416
[20/24] Train loss=0.2766067683696747
Test set avg_accuracy=79.75% avg_sensitivity=35.97%, avg_specificity=96.46% avg_auc=80.97%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.300910 Test loss=0.460787 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2837768495082855
[5/24] Train loss=0.2675425708293915
[10/24] Train loss=0.30046388506889343
[15/24] Train loss=0.27636057138442993
[20/24] Train loss=0.28149041533470154
Test set avg_accuracy=81.20% avg_sensitivity=58.13%, avg_specificity=90.00% avg_auc=85.11%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.298304 Test loss=0.415862 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2922913134098053
[5/24] Train loss=0.27288633584976196
[10/24] Train loss=0.3059033155441284
[15/24] Train loss=0.2870824933052063
[20/24] Train loss=0.287150502204895
Test set avg_accuracy=81.13% avg_sensitivity=50.87%, avg_specificity=92.68% avg_auc=84.53%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.297847 Test loss=0.420315 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2842637598514557
[5/24] Train loss=0.2760999798774719
[10/24] Train loss=0.3080575466156006
[15/24] Train loss=0.27694258093833923
[20/24] Train loss=0.28061434626579285
Test set avg_accuracy=81.71% avg_sensitivity=52.90%, avg_specificity=92.70% avg_auc=87.09%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.299375 Test loss=0.401426 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2790795564651489
[5/24] Train loss=0.26287034153938293
[10/24] Train loss=0.30764296650886536
[15/24] Train loss=0.2721446454524994
[20/24] Train loss=0.27622485160827637
Test set avg_accuracy=82.08% avg_sensitivity=62.14%, avg_specificity=89.69% avg_auc=86.90%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.294094 Test loss=0.397946 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.28388655185699463
[5/24] Train loss=0.2679674029350281
[10/24] Train loss=0.30181336402893066
[15/24] Train loss=0.279254287481308
[20/24] Train loss=0.2776622176170349
Test set avg_accuracy=78.85% avg_sensitivity=34.04%, avg_specificity=95.95% avg_auc=81.55%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.292572 Test loss=0.480292 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2940678000450134
[5/24] Train loss=0.26329219341278076
[10/24] Train loss=0.2965588867664337
[15/24] Train loss=0.27629733085632324
[20/24] Train loss=0.27322274446487427
Test set avg_accuracy=81.99% avg_sensitivity=56.81%, avg_specificity=91.60% avg_auc=87.34%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.291363 Test loss=0.397812 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2721439599990845
[5/24] Train loss=0.25741851329803467
[10/24] Train loss=0.29204726219177246
[15/24] Train loss=0.2788136899471283
[20/24] Train loss=0.2788112163543701
Test set avg_accuracy=80.99% avg_sensitivity=48.70%, avg_specificity=93.31% avg_auc=85.81%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.292773 Test loss=0.412319 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2794244885444641
[5/24] Train loss=0.2568167746067047
[10/24] Train loss=0.2978951334953308
[15/24] Train loss=0.28038114309310913
[20/24] Train loss=0.27526819705963135
Test set avg_accuracy=81.69% avg_sensitivity=58.89%, avg_specificity=90.39% avg_auc=87.07%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.292945 Test loss=0.406653 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.28867223858833313
[5/24] Train loss=0.26285380125045776
[10/24] Train loss=0.30243608355522156
[15/24] Train loss=0.26085662841796875
[20/24] Train loss=0.26743584871292114
Test set avg_accuracy=78.98% avg_sensitivity=64.83%, avg_specificity=84.39% avg_auc=85.04%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.287317 Test loss=0.433470 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.27118435502052307
[5/24] Train loss=0.25918471813201904
[10/24] Train loss=0.2818189263343811
[15/24] Train loss=0.2677728235721588
[20/24] Train loss=0.2740618586540222
Test set avg_accuracy=80.89% avg_sensitivity=50.35%, avg_specificity=92.53% avg_auc=85.97%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.283744 Test loss=0.414673 Current lr=[0.000134135431043539]

[0/24] Train loss=0.27553874254226685
[5/24] Train loss=0.2518382966518402
[10/24] Train loss=0.27400386333465576
[15/24] Train loss=0.2596657872200012
[20/24] Train loss=0.27157869935035706
Test set avg_accuracy=82.37% avg_sensitivity=58.09%, avg_specificity=91.64% avg_auc=87.40%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.278890 Test loss=0.396164 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.27584147453308105
[5/24] Train loss=0.252707839012146
[10/24] Train loss=0.2716335952281952
[15/24] Train loss=0.25736233592033386
[20/24] Train loss=0.26110586524009705
Test set avg_accuracy=80.90% avg_sensitivity=50.92%, avg_specificity=92.34% avg_auc=85.35%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.276190 Test loss=0.427890 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2560359835624695
[5/24] Train loss=0.24617619812488556
[10/24] Train loss=0.26537472009658813
[15/24] Train loss=0.25780439376831055
[20/24] Train loss=0.2653478980064392
Test set avg_accuracy=79.75% avg_sensitivity=60.63%, avg_specificity=87.05% avg_auc=85.06%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.275540 Test loss=0.424458 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.26661059260368347
[5/24] Train loss=0.24979496002197266
[10/24] Train loss=0.2615264058113098
[15/24] Train loss=0.25825098156929016
[20/24] Train loss=0.273389607667923
Test set avg_accuracy=82.37% avg_sensitivity=62.14%, avg_specificity=90.09% avg_auc=87.81%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.272473 Test loss=0.389679 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.2637683153152466
[5/24] Train loss=0.2464376837015152
[10/24] Train loss=0.2694851756095886
[15/24] Train loss=0.2625209391117096
[20/24] Train loss=0.254048615694046
Test set avg_accuracy=79.71% avg_sensitivity=44.22%, avg_specificity=93.25% avg_auc=83.57%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.270893 Test loss=0.452823 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.26188990473747253
[5/24] Train loss=0.2441888302564621
[10/24] Train loss=0.25994038581848145
[15/24] Train loss=0.2574474513530731
[20/24] Train loss=0.25651034712791443
Test set avg_accuracy=80.21% avg_sensitivity=47.95%, avg_specificity=92.52% avg_auc=85.47%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.266840 Test loss=0.427000 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.2603662312030792
[5/24] Train loss=0.2289658784866333
[10/24] Train loss=0.2486993968486786
[15/24] Train loss=0.25567346811294556
[20/24] Train loss=0.2613978981971741
Test set avg_accuracy=81.13% avg_sensitivity=56.77%, avg_specificity=90.43% avg_auc=86.25%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.263153 Test loss=0.419331 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.2532714605331421
[5/24] Train loss=0.23562856018543243
[10/24] Train loss=0.24992211163043976
[15/24] Train loss=0.2512184977531433
[20/24] Train loss=0.2620950937271118
Test set avg_accuracy=80.92% avg_sensitivity=58.37%, avg_specificity=89.53% avg_auc=86.72%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.262207 Test loss=0.404487 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.24904432892799377
[5/24] Train loss=0.23548975586891174
[10/24] Train loss=0.2516247034072876
[15/24] Train loss=0.2433997243642807
[20/24] Train loss=0.2659889757633209
Test set avg_accuracy=80.60% avg_sensitivity=49.60%, avg_specificity=92.43% avg_auc=84.94%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.259218 Test loss=0.439243 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.24946357309818268
[5/24] Train loss=0.2378857433795929
[10/24] Train loss=0.2549915313720703
[15/24] Train loss=0.24623550474643707
[20/24] Train loss=0.24954606592655182
Test set avg_accuracy=81.25% avg_sensitivity=55.16%, avg_specificity=91.20% avg_auc=86.10%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.258199 Test loss=0.419964 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2592673897743225
[5/24] Train loss=0.23032651841640472
[10/24] Train loss=0.24855802953243256
[15/24] Train loss=0.2593611478805542
[20/24] Train loss=0.2527048587799072
Test set avg_accuracy=80.40% avg_sensitivity=59.59%, avg_specificity=88.34% avg_auc=86.45%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.258651 Test loss=0.413947 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.2610643208026886
[5/24] Train loss=0.21779170632362366
[10/24] Train loss=0.25670701265335083
[15/24] Train loss=0.24007631838321686
[20/24] Train loss=0.25511103868484497
Test set avg_accuracy=81.20% avg_sensitivity=57.52%, avg_specificity=90.23% avg_auc=86.23%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.255511 Test loss=0.421452 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.25473934412002563
[5/24] Train loss=0.22265088558197021
[10/24] Train loss=0.26368898153305054
[15/24] Train loss=0.23802787065505981
[20/24] Train loss=0.25461602210998535
Test set avg_accuracy=81.46% avg_sensitivity=52.81%, avg_specificity=92.39% avg_auc=85.43%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.252698 Test loss=0.427740 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.24850593507289886
[5/24] Train loss=0.22666475176811218
[10/24] Train loss=0.24535609781742096
[15/24] Train loss=0.2365594059228897
[20/24] Train loss=0.2510039806365967
Test set avg_accuracy=82.34% avg_sensitivity=64.03%, avg_specificity=89.33% avg_auc=86.50%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.250493 Test loss=0.413776 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.24950860440731049
[5/24] Train loss=0.21762269735336304
[10/24] Train loss=0.23843926191329956
[15/24] Train loss=0.2317383736371994
[20/24] Train loss=0.24026146531105042
Test set avg_accuracy=81.65% avg_sensitivity=61.67%, avg_specificity=89.28% avg_auc=86.19%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.243747 Test loss=0.423484 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.2426399141550064
[5/24] Train loss=0.21709613502025604
[10/24] Train loss=0.23615054786205292
[15/24] Train loss=0.23198364675045013
[20/24] Train loss=0.2504958212375641
Test set avg_accuracy=81.84% avg_sensitivity=59.31%, avg_specificity=90.43% avg_auc=87.13%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.243457 Test loss=0.407297 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.23769941926002502
[5/24] Train loss=0.21485908329486847
[10/24] Train loss=0.23661190271377563
[15/24] Train loss=0.22120387852191925
[20/24] Train loss=0.23503318428993225
Test set avg_accuracy=81.26% avg_sensitivity=63.27%, avg_specificity=88.13% avg_auc=86.98%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.238036 Test loss=0.410319 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.22851720452308655
[5/24] Train loss=0.20507517457008362
[10/24] Train loss=0.22796450555324554
[15/24] Train loss=0.2185615450143814
[20/24] Train loss=0.23915253579616547
Test set avg_accuracy=81.47% avg_sensitivity=59.12%, avg_specificity=90.00% avg_auc=86.07%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.233817 Test loss=0.419808 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.23342134058475494
[5/24] Train loss=0.2023741453886032
[10/24] Train loss=0.2341478168964386
[15/24] Train loss=0.2189023792743683
[20/24] Train loss=0.23654572665691376
Test set avg_accuracy=81.11% avg_sensitivity=62.09%, avg_specificity=88.36% avg_auc=86.29%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.230139 Test loss=0.417403 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.22398485243320465
[5/24] Train loss=0.206425741314888
[10/24] Train loss=0.21989715099334717
[15/24] Train loss=0.2188219279050827
[20/24] Train loss=0.2325284779071808
Test set avg_accuracy=80.77% avg_sensitivity=63.79%, avg_specificity=87.25% avg_auc=86.20%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.228955 Test loss=0.418491 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.22209607064723969
[5/24] Train loss=0.2047678679227829
[10/24] Train loss=0.22936345636844635
[15/24] Train loss=0.21166455745697021
[20/24] Train loss=0.22102351486682892
Test set avg_accuracy=81.94% avg_sensitivity=63.79%, avg_specificity=88.86% avg_auc=86.03%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.226242 Test loss=0.420372 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.22511234879493713
[5/24] Train loss=0.20105798542499542
[10/24] Train loss=0.21256215870380402
[15/24] Train loss=0.20688283443450928
[20/24] Train loss=0.22734060883522034
Test set avg_accuracy=82.06% avg_sensitivity=66.81%, avg_specificity=87.88% avg_auc=87.27%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.222661 Test loss=0.405749 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.215538889169693
[5/24] Train loss=0.20207302272319794
[10/24] Train loss=0.21739162504673004
[15/24] Train loss=0.20904143154621124
[20/24] Train loss=0.22640076279640198
Test set avg_accuracy=81.61% avg_sensitivity=63.32%, avg_specificity=88.60% avg_auc=87.07%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.221093 Test loss=0.409307 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.21866925060749054
[5/24] Train loss=0.19664980471134186
[10/24] Train loss=0.21372804045677185
[15/24] Train loss=0.20360468327999115
[20/24] Train loss=0.22189028561115265
Test set avg_accuracy=81.67% avg_sensitivity=63.41%, avg_specificity=88.63% avg_auc=86.64%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.217744 Test loss=0.413393 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.21875910460948944
[5/24] Train loss=0.19917330145835876
[10/24] Train loss=0.21044224500656128
[15/24] Train loss=0.20355112850666046
[20/24] Train loss=0.2155425250530243
Test set avg_accuracy=81.78% avg_sensitivity=61.10%, avg_specificity=89.67% avg_auc=86.11%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.217036 Test loss=0.418965 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.21094536781311035
[5/24] Train loss=0.19283929467201233
[10/24] Train loss=0.21771039068698883
[15/24] Train loss=0.20096255838871002
[20/24] Train loss=0.2208583950996399
Test set avg_accuracy=81.25% avg_sensitivity=57.24%, avg_specificity=90.41% avg_auc=85.57%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.214439 Test loss=0.428740 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.21666550636291504
[5/24] Train loss=0.1946452409029007
[10/24] Train loss=0.21384242177009583
[15/24] Train loss=0.19907374680042267
[20/24] Train loss=0.21797801554203033
Test set avg_accuracy=81.71% avg_sensitivity=57.71%, avg_specificity=90.86% avg_auc=85.43%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.214033 Test loss=0.428561 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.21759310364723206
[5/24] Train loss=0.19117163121700287
[10/24] Train loss=0.2089509218931198
[15/24] Train loss=0.20218227803707123
[20/24] Train loss=0.21812058985233307
Test set avg_accuracy=81.15% avg_sensitivity=62.38%, avg_specificity=88.31% avg_auc=85.78%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.210390 Test loss=0.426893 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.20256608724594116
[5/24] Train loss=0.18183264136314392
[10/24] Train loss=0.2012590616941452
[15/24] Train loss=0.19167862832546234
[20/24] Train loss=0.21412014961242676
Test set avg_accuracy=81.48% avg_sensitivity=61.06%, avg_specificity=89.28% avg_auc=86.24%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.208490 Test loss=0.418389 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.20421436429023743
[5/24] Train loss=0.18278752267360687
[10/24] Train loss=0.20326153934001923
[15/24] Train loss=0.19046396017074585
[20/24] Train loss=0.21080510318279266
Test set avg_accuracy=81.78% avg_sensitivity=63.79%, avg_specificity=88.65% avg_auc=86.46%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.206199 Test loss=0.418285 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.2048277109861374
[5/24] Train loss=0.1850549578666687
[10/24] Train loss=0.20190100371837616
[15/24] Train loss=0.1890927255153656
[20/24] Train loss=0.21548083424568176
Test set avg_accuracy=81.42% avg_sensitivity=63.74%, avg_specificity=88.16% avg_auc=86.30%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.205542 Test loss=0.422301 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.20703479647636414
[5/24] Train loss=0.18295921385288239
[10/24] Train loss=0.19893084466457367
[15/24] Train loss=0.18778270483016968
[20/24] Train loss=0.20897004008293152
Test set avg_accuracy=81.28% avg_sensitivity=61.39%, avg_specificity=88.86% avg_auc=85.78%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.203593 Test loss=0.427657 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.2020982950925827
[5/24] Train loss=0.17532727122306824
[10/24] Train loss=0.19807450473308563
[15/24] Train loss=0.19010035693645477
[20/24] Train loss=0.20814630389213562
Test set avg_accuracy=81.42% avg_sensitivity=59.59%, avg_specificity=89.75% avg_auc=85.86%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.200814 Test loss=0.425304 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.19973371922969818
[5/24] Train loss=0.18051224946975708
[10/24] Train loss=0.19657698273658752
[15/24] Train loss=0.18921001255512238
[20/24] Train loss=0.20782741904258728
Test set avg_accuracy=81.65% avg_sensitivity=62.71%, avg_specificity=88.88% avg_auc=86.30%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.200259 Test loss=0.421203 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.20062939822673798
[5/24] Train loss=0.17532016336917877
[10/24] Train loss=0.19649893045425415
[15/24] Train loss=0.18660877645015717
[20/24] Train loss=0.20424066483974457
Test set avg_accuracy=81.54% avg_sensitivity=60.44%, avg_specificity=89.58% avg_auc=85.46%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.199466 Test loss=0.430448 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.20151357352733612
[5/24] Train loss=0.1797703206539154
[10/24] Train loss=0.19309096038341522
[15/24] Train loss=0.18504977226257324
[20/24] Train loss=0.2042437493801117
Test set avg_accuracy=81.61% avg_sensitivity=61.86%, avg_specificity=89.15% avg_auc=85.94%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.199320 Test loss=0.424993 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1940610408782959
[5/24] Train loss=0.17591184377670288
[10/24] Train loss=0.1962260752916336
[15/24] Train loss=0.18558821082115173
[20/24] Train loss=0.20109739899635315
Test set avg_accuracy=81.67% avg_sensitivity=62.00%, avg_specificity=89.17% avg_auc=85.89%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.197284 Test loss=0.424483 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1932026892900467
[5/24] Train loss=0.17495036125183105
[10/24] Train loss=0.19359242916107178
[15/24] Train loss=0.18587704002857208
[20/24] Train loss=0.20556654036045074
Test set avg_accuracy=81.84% avg_sensitivity=62.33%, avg_specificity=89.28% avg_auc=86.07%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.196378 Test loss=0.422375 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.194560244679451
[5/24] Train loss=0.16998329758644104
[10/24] Train loss=0.19346509873867035
[15/24] Train loss=0.1840287297964096
[20/24] Train loss=0.20280377566814423
Test set avg_accuracy=81.52% avg_sensitivity=61.86%, avg_specificity=89.03% avg_auc=86.14%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.195815 Test loss=0.422787 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1946086436510086
[5/24] Train loss=0.17021016776561737
[10/24] Train loss=0.1945108324289322
[15/24] Train loss=0.1789897084236145
[20/24] Train loss=0.19892005622386932
Test set avg_accuracy=81.69% avg_sensitivity=61.86%, avg_specificity=89.26% avg_auc=86.07%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.194004 Test loss=0.423312 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.19318370521068573
[5/24] Train loss=0.17685675621032715
[10/24] Train loss=0.19135387241840363
[15/24] Train loss=0.1827116310596466
[20/24] Train loss=0.20607155561447144
Test set avg_accuracy=81.52% avg_sensitivity=60.49%, avg_specificity=89.55% avg_auc=85.96%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.195439 Test loss=0.425163 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.190948948264122
[5/24] Train loss=0.17307323217391968
[10/24] Train loss=0.19280274212360382
[15/24] Train loss=0.18076401948928833
[20/24] Train loss=0.20028620958328247
Test set avg_accuracy=81.46% avg_sensitivity=61.06%, avg_specificity=89.24% avg_auc=86.07%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.194920 Test loss=0.423483 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.19299542903900146
[5/24] Train loss=0.1751226782798767
[10/24] Train loss=0.19093099236488342
[15/24] Train loss=0.17991110682487488
[20/24] Train loss=0.20351284742355347
Test set avg_accuracy=81.43% avg_sensitivity=60.96%, avg_specificity=89.24% avg_auc=85.97%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.194117 Test loss=0.424681 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1893625110387802
[5/24] Train loss=0.17149753868579865
[10/24] Train loss=0.19084404408931732
[15/24] Train loss=0.18588262796401978
[20/24] Train loss=0.20075395703315735
Test set avg_accuracy=81.42% avg_sensitivity=61.06%, avg_specificity=89.19% avg_auc=85.94%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.193503 Test loss=0.425519 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.19423651695251465
[5/24] Train loss=0.1742260754108429
[10/24] Train loss=0.1887611299753189
[15/24] Train loss=0.18423984944820404
[20/24] Train loss=0.2056429237127304
Test set avg_accuracy=81.41% avg_sensitivity=61.10%, avg_specificity=89.15% avg_auc=85.97%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.193264 Test loss=0.425343 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.19096976518630981
[5/24] Train loss=0.17506620287895203
[10/24] Train loss=0.18888334929943085
[15/24] Train loss=0.18079569935798645
[20/24] Train loss=0.19651544094085693
Test set avg_accuracy=81.42% avg_sensitivity=61.15%, avg_specificity=89.15% avg_auc=85.98%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.192913 Test loss=0.425336 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.19229750335216522
[5/24] Train loss=0.1751687228679657
[10/24] Train loss=0.18788208067417145
[15/24] Train loss=0.1791110336780548
[20/24] Train loss=0.2005614936351776
Test set avg_accuracy=81.41% avg_sensitivity=61.20%, avg_specificity=89.12% avg_auc=86.00%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.193488 Test loss=0.425044 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1890515685081482
[5/24] Train loss=0.17513790726661682
[10/24] Train loss=0.18794578313827515
[15/24] Train loss=0.17884597182273865
[20/24] Train loss=0.20275583863258362
Test set avg_accuracy=81.38% avg_sensitivity=61.10%, avg_specificity=89.12% avg_auc=85.98%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.194235 Test loss=0.425168 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1909348964691162
[5/24] Train loss=0.17532072961330414
[10/24] Train loss=0.18913641571998596
[15/24] Train loss=0.1761282980442047
[20/24] Train loss=0.20645058155059814
Test set avg_accuracy=81.41% avg_sensitivity=61.10%, avg_specificity=89.15% avg_auc=85.98%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.194442 Test loss=0.425234 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=82.03% sen=70.44%, spe=86.45%, auc=88.39%!
Fold[7] Avg_overlap=0.41%(0.3239668738444172)
[0/24] Train loss=0.7622976303100586
[5/24] Train loss=0.7644228935241699
[10/24] Train loss=0.7485155463218689
[15/24] Train loss=0.7422670125961304
[20/24] Train loss=0.7393798232078552
Test set avg_accuracy=52.62% avg_sensitivity=46.09%, avg_specificity=54.81% avg_auc=51.99%
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.750765 Test loss=0.708861 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7310091853141785
[5/24] Train loss=0.7301995754241943
[10/24] Train loss=0.7322921752929688
[15/24] Train loss=0.7269808650016785
[20/24] Train loss=0.7183871269226074
Test set avg_accuracy=58.22% avg_sensitivity=53.08%, avg_specificity=59.94% avg_auc=58.81%
Best model saved!! Metric=-95.95406529202933!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.729511 Test loss=0.672158 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7184765338897705
[5/24] Train loss=0.7189271450042725
[10/24] Train loss=0.7096178531646729
[15/24] Train loss=0.7032262682914734
[20/24] Train loss=0.7018212080001831
Test set avg_accuracy=62.67% avg_sensitivity=57.90%, avg_specificity=64.27% avg_auc=64.92%
Best model saved!! Metric=-76.2407896738911!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.710120 Test loss=0.649882 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6963151693344116
[5/24] Train loss=0.7006170153617859
[10/24] Train loss=0.6903789639472961
[15/24] Train loss=0.6828346848487854
[20/24] Train loss=0.670001745223999
Test set avg_accuracy=65.53% avg_sensitivity=60.95%, avg_specificity=67.07% avg_auc=69.09%
Best model saved!! Metric=-63.34748362751795!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.691828 Test loss=0.630019 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6705478429794312
[5/24] Train loss=0.6806931495666504
[10/24] Train loss=0.6687649488449097
[15/24] Train loss=0.6544643640518188
[20/24] Train loss=0.6356696486473083
Test set avg_accuracy=69.19% avg_sensitivity=63.85%, avg_specificity=70.99% avg_auc=73.22%
Best model saved!! Metric=-48.743587705002284!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.667556 Test loss=0.605500 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6491913199424744
[5/24] Train loss=0.6548088788986206
[10/24] Train loss=0.6436532735824585
[15/24] Train loss=0.6333222985267639
[20/24] Train loss=0.605168879032135
Test set avg_accuracy=72.77% avg_sensitivity=70.48%, avg_specificity=73.54% avg_auc=77.40%
Best model saved!! Metric=-31.801374195799383!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.641373 Test loss=0.584420 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6170606017112732
[5/24] Train loss=0.6279907822608948
[10/24] Train loss=0.6167587637901306
[15/24] Train loss=0.6030605435371399
[20/24] Train loss=0.56525719165802
Test set avg_accuracy=74.77% avg_sensitivity=74.31%, avg_specificity=74.92% avg_auc=80.18%
Best model saved!! Metric=-21.824968784396248!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.612267 Test loss=0.557789 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5855726599693298
[5/24] Train loss=0.6002716422080994
[10/24] Train loss=0.5881525874137878
[15/24] Train loss=0.5706992149353027
[20/24] Train loss=0.5369777679443359
Test set avg_accuracy=76.74% avg_sensitivity=73.90%, avg_specificity=77.70% avg_auc=82.64%
Best model saved!! Metric=-15.011439642423724!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.583086 Test loss=0.518783 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5545402765274048
[5/24] Train loss=0.5692267417907715
[10/24] Train loss=0.562556266784668
[15/24] Train loss=0.5483086109161377
[20/24] Train loss=0.4974120855331421
Test set avg_accuracy=78.39% avg_sensitivity=75.82%, avg_specificity=79.25% avg_auc=84.21%
Best model saved!! Metric=-8.34179962177619!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.553970 Test loss=0.493888 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5303711295127869
[5/24] Train loss=0.5284631848335266
[10/24] Train loss=0.5306313633918762
[15/24] Train loss=0.513272762298584
[20/24] Train loss=0.4693567752838135
Test set avg_accuracy=79.65% avg_sensitivity=73.64%, avg_specificity=81.67% avg_auc=85.05%
Best model saved!! Metric=-5.992385360778982!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.526028 Test loss=0.467980 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5191554427146912
[5/24] Train loss=0.5135506391525269
[10/24] Train loss=0.5078357458114624
[15/24] Train loss=0.4912358522415161
[20/24] Train loss=0.4423823058605194
Test set avg_accuracy=80.81% avg_sensitivity=73.17%, avg_specificity=83.37% avg_auc=85.76%
Best model saved!! Metric=-2.8911043527612748!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.502893 Test loss=0.447172 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4921395778656006
[5/24] Train loss=0.4795425534248352
[10/24] Train loss=0.49075305461883545
[15/24] Train loss=0.4672240912914276
[20/24] Train loss=0.4250117540359497
Test set avg_accuracy=81.25% avg_sensitivity=71.05%, avg_specificity=84.68% avg_auc=86.37%
Best model saved!! Metric=-2.652813170218792!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.482085 Test loss=0.429035 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4699702858924866
[5/24] Train loss=0.45809704065322876
[10/24] Train loss=0.4743936359882355
[15/24] Train loss=0.4434095621109009
[20/24] Train loss=0.40241238474845886
Test set avg_accuracy=81.68% avg_sensitivity=71.21%, avg_specificity=85.20% avg_auc=86.73%
Best model saved!! Metric=-1.1884738419090155!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.463468 Test loss=0.418078 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.45944687724113464
[5/24] Train loss=0.44734200835227966
[10/24] Train loss=0.453583300113678
[15/24] Train loss=0.4340836703777313
[20/24] Train loss=0.3902740180492401
Test set avg_accuracy=82.25% avg_sensitivity=69.70%, avg_specificity=86.47% avg_auc=87.16%
Best model saved!! Metric=-0.4200578836716886!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.448035 Test loss=0.403188 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.44173407554626465
[5/24] Train loss=0.4271577000617981
[10/24] Train loss=0.43649259209632874
[15/24] Train loss=0.4179486036300659
[20/24] Train loss=0.3710848391056061
Test set avg_accuracy=82.75% avg_sensitivity=66.49%, avg_specificity=88.21% avg_auc=87.11%
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.433958 Test loss=0.390316 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.430226594209671
[5/24] Train loss=0.4143749475479126
[10/24] Train loss=0.42983192205429077
[15/24] Train loss=0.4034620523452759
[20/24] Train loss=0.3576385974884033
Test set avg_accuracy=82.89% avg_sensitivity=63.85%, avg_specificity=89.29% avg_auc=87.11%
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.423090 Test loss=0.384199 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4253643751144409
[5/24] Train loss=0.39905214309692383
[10/24] Train loss=0.4137266278266907
[15/24] Train loss=0.3922630548477173
[20/24] Train loss=0.3467199504375458
Test set avg_accuracy=82.94% avg_sensitivity=60.54%, avg_specificity=90.47% avg_auc=87.14%
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.413701 Test loss=0.381061 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.41010719537734985
[5/24] Train loss=0.3913792073726654
[10/24] Train loss=0.4055896997451782
[15/24] Train loss=0.38511359691619873
[20/24] Train loss=0.3360048532485962
Test set avg_accuracy=82.80% avg_sensitivity=55.20%, avg_specificity=92.07% avg_auc=86.63%
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.405399 Test loss=0.384420 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.40050679445266724
[5/24] Train loss=0.3896847665309906
[10/24] Train loss=0.4068208336830139
[15/24] Train loss=0.37827834486961365
[20/24] Train loss=0.32620206475257874
Test set avg_accuracy=83.44% avg_sensitivity=59.24%, avg_specificity=91.56% avg_auc=87.23%
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.398178 Test loss=0.376128 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3938288688659668
[5/24] Train loss=0.3790634274482727
[10/24] Train loss=0.3933333158493042
[15/24] Train loss=0.37514936923980713
[20/24] Train loss=0.32175421714782715
Test set avg_accuracy=83.39% avg_sensitivity=58.52%, avg_specificity=91.74% avg_auc=87.31%
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.393296 Test loss=0.374795 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3908125162124634
[5/24] Train loss=0.3728814423084259
[10/24] Train loss=0.3895491361618042
[15/24] Train loss=0.36452677845954895
[20/24] Train loss=0.312611848115921
Test set avg_accuracy=83.65% avg_sensitivity=65.30%, avg_specificity=89.81% avg_auc=87.88%
Best model saved!! Metric=0.639147911537961!!
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.387249 Test loss=0.368588 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3844049572944641
[5/24] Train loss=0.3646967113018036
[10/24] Train loss=0.38522499799728394
[15/24] Train loss=0.3687504529953003
[20/24] Train loss=0.30489662289619446
Test set avg_accuracy=82.76% avg_sensitivity=73.80%, avg_specificity=85.77% avg_auc=88.19%
Best model saved!! Metric=4.516800390078274!!
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.382558 Test loss=0.386168 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.380414217710495
[5/24] Train loss=0.3603907823562622
[10/24] Train loss=0.38005417585372925
[15/24] Train loss=0.35563814640045166
[20/24] Train loss=0.2966116964817047
Test set avg_accuracy=83.46% avg_sensitivity=70.48%, avg_specificity=87.82% avg_auc=88.52%
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.377390 Test loss=0.369178 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3726341724395752
[5/24] Train loss=0.35238510370254517
[10/24] Train loss=0.3784358501434326
[15/24] Train loss=0.3479433059692383
[20/24] Train loss=0.3004239499568939
Test set avg_accuracy=83.11% avg_sensitivity=70.95%, avg_specificity=87.20% avg_auc=88.15%
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.373835 Test loss=0.382532 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3714025318622589
[5/24] Train loss=0.3536613881587982
[10/24] Train loss=0.378734290599823
[15/24] Train loss=0.3498479723930359
[20/24] Train loss=0.2932562232017517
Test set avg_accuracy=81.91% avg_sensitivity=74.73%, avg_specificity=84.33% avg_auc=87.65%
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.371045 Test loss=0.408796 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3725338578224182
[5/24] Train loss=0.34713441133499146
[10/24] Train loss=0.37626028060913086
[15/24] Train loss=0.34544190764427185
[20/24] Train loss=0.2866658568382263
Test set avg_accuracy=79.58% avg_sensitivity=77.42%, avg_specificity=80.31% avg_auc=86.63%
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.369334 Test loss=0.443059 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.37220194935798645
[5/24] Train loss=0.34304866194725037
[10/24] Train loss=0.3681635558605194
[15/24] Train loss=0.3413461148738861
[20/24] Train loss=0.28809621930122375
Test set avg_accuracy=82.59% avg_sensitivity=69.08%, avg_specificity=87.13% avg_auc=87.36%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.364425 Test loss=0.398582 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3698645532131195
[5/24] Train loss=0.34163933992385864
[10/24] Train loss=0.3663620948791504
[15/24] Train loss=0.3406771421432495
[20/24] Train loss=0.28305086493492126
Test set avg_accuracy=82.88% avg_sensitivity=63.49%, avg_specificity=89.39% avg_auc=87.28%
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.363127 Test loss=0.380020 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3696824908256531
[5/24] Train loss=0.3366084098815918
[10/24] Train loss=0.3737667202949524
[15/24] Train loss=0.34079307317733765
[20/24] Train loss=0.28661254048347473
Test set avg_accuracy=82.70% avg_sensitivity=68.00%, avg_specificity=87.63% avg_auc=87.75%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.364404 Test loss=0.384253 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.36118048429489136
[5/24] Train loss=0.33663713932037354
[10/24] Train loss=0.36858847737312317
[15/24] Train loss=0.33968430757522583
[20/24] Train loss=0.2775767147541046
Test set avg_accuracy=78.72% avg_sensitivity=75.14%, avg_specificity=79.93% avg_auc=85.33%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.361983 Test loss=0.459371 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3589921295642853
[5/24] Train loss=0.3393111824989319
[10/24] Train loss=0.3690703809261322
[15/24] Train loss=0.32679152488708496
[20/24] Train loss=0.2801150679588318
Test set avg_accuracy=79.09% avg_sensitivity=75.35%, avg_specificity=80.34% avg_auc=85.45%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.359581 Test loss=0.448356 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.36470192670822144
[5/24] Train loss=0.32758641242980957
[10/24] Train loss=0.36882421374320984
[15/24] Train loss=0.33157452940940857
[20/24] Train loss=0.28381168842315674
Test set avg_accuracy=82.58% avg_sensitivity=72.60%, avg_specificity=85.93% avg_auc=87.59%
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.358508 Test loss=0.394215 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3628528416156769
[5/24] Train loss=0.3260563611984253
[10/24] Train loss=0.3709869086742401
[15/24] Train loss=0.32563671469688416
[20/24] Train loss=0.2785223126411438
Test set avg_accuracy=81.48% avg_sensitivity=71.98%, avg_specificity=84.68% avg_auc=86.21%
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.355905 Test loss=0.426668 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.35433870553970337
[5/24] Train loss=0.32674551010131836
[10/24] Train loss=0.3630136549472809
[15/24] Train loss=0.33141741156578064
[20/24] Train loss=0.2744717001914978
Test set avg_accuracy=82.70% avg_sensitivity=65.30%, avg_specificity=88.54% avg_auc=87.65%
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.355005 Test loss=0.383906 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3509652614593506
[5/24] Train loss=0.3289351761341095
[10/24] Train loss=0.3608933389186859
[15/24] Train loss=0.3238886892795563
[20/24] Train loss=0.2785279154777527
Test set avg_accuracy=81.07% avg_sensitivity=57.90%, avg_specificity=88.85% avg_auc=83.99%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.355259 Test loss=0.415139 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3570812940597534
[5/24] Train loss=0.32101649045944214
[10/24] Train loss=0.363322377204895
[15/24] Train loss=0.33640679717063904
[20/24] Train loss=0.2700398564338684
Test set avg_accuracy=81.86% avg_sensitivity=56.50%, avg_specificity=90.38% avg_auc=86.49%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.354510 Test loss=0.387736 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.351205974817276
[5/24] Train loss=0.3193770945072174
[10/24] Train loss=0.36175215244293213
[15/24] Train loss=0.3263947367668152
[20/24] Train loss=0.2767980992794037
Test set avg_accuracy=82.70% avg_sensitivity=66.24%, avg_specificity=88.22% avg_auc=87.31%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.352736 Test loss=0.379292 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3567304015159607
[5/24] Train loss=0.31567099690437317
[10/24] Train loss=0.3627674877643585
[15/24] Train loss=0.3249354362487793
[20/24] Train loss=0.2833556532859802
Test set avg_accuracy=81.46% avg_sensitivity=64.42%, avg_specificity=87.18% avg_auc=85.97%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.352634 Test loss=0.396029 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.348180890083313
[5/24] Train loss=0.3135432004928589
[10/24] Train loss=0.3640316128730774
[15/24] Train loss=0.3290380537509918
[20/24] Train loss=0.26857733726501465
Test set avg_accuracy=81.21% avg_sensitivity=73.64%, avg_specificity=83.75% avg_auc=86.66%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.351595 Test loss=0.415809 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3495975732803345
[5/24] Train loss=0.31552714109420776
[10/24] Train loss=0.3482426702976227
[15/24] Train loss=0.3309020400047302
[20/24] Train loss=0.2772033214569092
Test set avg_accuracy=83.27% avg_sensitivity=51.37%, avg_specificity=93.98% avg_auc=87.95%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.350003 Test loss=0.373821 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.34601008892059326
[5/24] Train loss=0.3131653666496277
[10/24] Train loss=0.3598465323448181
[15/24] Train loss=0.3243103325366974
[20/24] Train loss=0.2739664316177368
Test set avg_accuracy=82.33% avg_sensitivity=61.32%, avg_specificity=89.39% avg_auc=85.56%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.350060 Test loss=0.407317 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.34820127487182617
[5/24] Train loss=0.3186013996601105
[10/24] Train loss=0.35866299271583557
[15/24] Train loss=0.3377377390861511
[20/24] Train loss=0.27295586466789246
Test set avg_accuracy=83.09% avg_sensitivity=59.35%, avg_specificity=91.06% avg_auc=87.16%
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.350437 Test loss=0.382131 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.35194480419158936
[5/24] Train loss=0.3172239363193512
[10/24] Train loss=0.35288161039352417
[15/24] Train loss=0.32884472608566284
[20/24] Train loss=0.2738018035888672
Test set avg_accuracy=80.44% avg_sensitivity=48.99%, avg_specificity=91.01% avg_auc=84.84%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.348972 Test loss=0.406081 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.33945485949516296
[5/24] Train loss=0.3119080364704132
[10/24] Train loss=0.3571140170097351
[15/24] Train loss=0.3205766975879669
[20/24] Train loss=0.26736685633659363
Test set avg_accuracy=79.83% avg_sensitivity=69.76%, avg_specificity=83.21% avg_auc=85.36%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.346172 Test loss=0.431515 Current lr=[0.00029967723776099]

[0/24] Train loss=0.34572070837020874
[5/24] Train loss=0.3150756061077118
[10/24] Train loss=0.35672545433044434
[15/24] Train loss=0.32356026768684387
[20/24] Train loss=0.2680412232875824
Test set avg_accuracy=69.54% avg_sensitivity=74.26%, avg_specificity=67.96% avg_auc=79.36%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.350143 Test loss=0.559957 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.34494566917419434
[5/24] Train loss=0.3271285593509674
[10/24] Train loss=0.3577582836151123
[15/24] Train loss=0.3213653862476349
[20/24] Train loss=0.26621732115745544
Test set avg_accuracy=77.70% avg_sensitivity=63.49%, avg_specificity=82.47% avg_auc=81.69%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.346075 Test loss=0.458573 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3416241407394409
[5/24] Train loss=0.3153027296066284
[10/24] Train loss=0.36316153407096863
[15/24] Train loss=0.32576417922973633
[20/24] Train loss=0.2712385356426239
Test set avg_accuracy=81.42% avg_sensitivity=71.93%, avg_specificity=84.61% avg_auc=86.19%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.345468 Test loss=0.430361 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3463149666786194
[5/24] Train loss=0.32235589623451233
[10/24] Train loss=0.3530844449996948
[15/24] Train loss=0.3174504041671753
[20/24] Train loss=0.26820868253707886
Test set avg_accuracy=83.01% avg_sensitivity=62.25%, avg_specificity=89.98% avg_auc=87.36%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.344744 Test loss=0.396035 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.34880515933036804
[5/24] Train loss=0.31564611196517944
[10/24] Train loss=0.35178765654563904
[15/24] Train loss=0.3199100196361542
[20/24] Train loss=0.26912280917167664
Test set avg_accuracy=81.91% avg_sensitivity=52.98%, avg_specificity=91.63% avg_auc=84.49%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.344423 Test loss=0.415319 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3508213460445404
[5/24] Train loss=0.3158324062824249
[10/24] Train loss=0.35694223642349243
[15/24] Train loss=0.32040074467658997
[20/24] Train loss=0.261756956577301
Test set avg_accuracy=82.37% avg_sensitivity=48.01%, avg_specificity=93.91% avg_auc=86.92%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.345872 Test loss=0.391086 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.34116384387016296
[5/24] Train loss=0.32129916548728943
[10/24] Train loss=0.3552216589450836
[15/24] Train loss=0.31421881914138794
[20/24] Train loss=0.2723866105079651
Test set avg_accuracy=76.43% avg_sensitivity=71.21%, avg_specificity=78.19% avg_auc=83.31%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.344026 Test loss=0.484855 Current lr=[0.000297555943323901]

[0/24] Train loss=0.349904328584671
[5/24] Train loss=0.32138592004776
[10/24] Train loss=0.3523845076560974
[15/24] Train loss=0.31238609552383423
[20/24] Train loss=0.26731187105178833
Test set avg_accuracy=80.90% avg_sensitivity=73.64%, avg_specificity=83.34% avg_auc=86.51%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.345287 Test loss=0.430980 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.35192638635635376
[5/24] Train loss=0.31985729932785034
[10/24] Train loss=0.35551559925079346
[15/24] Train loss=0.30949822068214417
[20/24] Train loss=0.2708956003189087
Test set avg_accuracy=83.88% avg_sensitivity=66.44%, avg_specificity=89.74% avg_auc=88.26%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.342446 Test loss=0.383118 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3378308117389679
[5/24] Train loss=0.31174683570861816
[10/24] Train loss=0.3404754102230072
[15/24] Train loss=0.3120340406894684
[20/24] Train loss=0.2661726176738739
Test set avg_accuracy=83.89% avg_sensitivity=69.34%, avg_specificity=88.78% avg_auc=88.67%
Best model saved!! Metric=4.686452566516721!!
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.342395 Test loss=0.370062 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.34597450494766235
[5/24] Train loss=0.3160358667373657
[10/24] Train loss=0.33791372179985046
[15/24] Train loss=0.30696699023246765
[20/24] Train loss=0.2683104872703552
Test set avg_accuracy=64.10% avg_sensitivity=79.03%, avg_specificity=59.09% avg_auc=76.12%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.340093 Test loss=0.627215 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3516395092010498
[5/24] Train loss=0.3152257204055786
[10/24] Train loss=0.3549667298793793
[15/24] Train loss=0.3032369017601013
[20/24] Train loss=0.2739220857620239
Test set avg_accuracy=82.80% avg_sensitivity=66.70%, avg_specificity=88.21% avg_auc=85.71%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.340840 Test loss=0.439960 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.34242191910743713
[5/24] Train loss=0.3090711534023285
[10/24] Train loss=0.3458990454673767
[15/24] Train loss=0.3121163845062256
[20/24] Train loss=0.26041296124458313
Test set avg_accuracy=82.17% avg_sensitivity=57.28%, avg_specificity=90.54% avg_auc=86.42%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.342334 Test loss=0.400116 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3452262282371521
[5/24] Train loss=0.31106704473495483
[10/24] Train loss=0.3421764671802521
[15/24] Train loss=0.3127093017101288
[20/24] Train loss=0.26676541566848755
Test set avg_accuracy=83.40% avg_sensitivity=67.27%, avg_specificity=88.82% avg_auc=88.70%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.338348 Test loss=0.374158 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3452291786670685
[5/24] Train loss=0.31173044443130493
[10/24] Train loss=0.3439508378505707
[15/24] Train loss=0.3110758066177368
[20/24] Train loss=0.257058709859848
Test set avg_accuracy=76.98% avg_sensitivity=72.76%, avg_specificity=78.40% avg_auc=83.53%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.335586 Test loss=0.482092 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3483518064022064
[5/24] Train loss=0.31182539463043213
[10/24] Train loss=0.33762407302856445
[15/24] Train loss=0.3124469816684723
[20/24] Train loss=0.2668774425983429
Test set avg_accuracy=82.20% avg_sensitivity=71.83%, avg_specificity=85.68% avg_auc=87.48%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.340223 Test loss=0.411285 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3327912390232086
[5/24] Train loss=0.30191007256507874
[10/24] Train loss=0.3498537242412567
[15/24] Train loss=0.3048919141292572
[20/24] Train loss=0.25947847962379456
Test set avg_accuracy=84.04% avg_sensitivity=65.72%, avg_specificity=90.19% avg_auc=88.32%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.335479 Test loss=0.365800 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3408724069595337
[5/24] Train loss=0.31030020117759705
[10/24] Train loss=0.34213781356811523
[15/24] Train loss=0.2986368238925934
[20/24] Train loss=0.2688286602497101
Test set avg_accuracy=82.50% avg_sensitivity=70.48%, avg_specificity=86.54% avg_auc=87.14%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.335781 Test loss=0.413775 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3387562930583954
[5/24] Train loss=0.30763137340545654
[10/24] Train loss=0.3485153913497925
[15/24] Train loss=0.30881771445274353
[20/24] Train loss=0.26343274116516113
Test set avg_accuracy=83.12% avg_sensitivity=72.81%, avg_specificity=86.59% avg_auc=88.25%
Best model saved!! Metric=4.774058638887851!!
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.336378 Test loss=0.374784 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3402048945426941
[5/24] Train loss=0.3165974020957947
[10/24] Train loss=0.3426288664340973
[15/24] Train loss=0.2970500588417053
[20/24] Train loss=0.25857606530189514
Test set avg_accuracy=82.25% avg_sensitivity=68.98%, avg_specificity=86.71% avg_auc=88.10%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.335523 Test loss=0.397934 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3404904305934906
[5/24] Train loss=0.3089454770088196
[10/24] Train loss=0.34573569893836975
[15/24] Train loss=0.3141966164112091
[20/24] Train loss=0.2538979649543762
Test set avg_accuracy=83.78% avg_sensitivity=62.87%, avg_specificity=90.80% avg_auc=89.02%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.336800 Test loss=0.358199 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.33512282371520996
[5/24] Train loss=0.30734336376190186
[10/24] Train loss=0.3420761227607727
[15/24] Train loss=0.2997509837150574
[20/24] Train loss=0.2597430944442749
Test set avg_accuracy=82.75% avg_sensitivity=72.24%, avg_specificity=86.28% avg_auc=88.55%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.333361 Test loss=0.377960 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3401404321193695
[5/24] Train loss=0.3072923421859741
[10/24] Train loss=0.3461335599422455
[15/24] Train loss=0.2998826801776886
[20/24] Train loss=0.2542077302932739
Test set avg_accuracy=81.80% avg_sensitivity=70.48%, avg_specificity=85.60% avg_auc=86.82%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.333467 Test loss=0.397319 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.335065633058548
[5/24] Train loss=0.3002336621284485
[10/24] Train loss=0.33349230885505676
[15/24] Train loss=0.29372233152389526
[20/24] Train loss=0.258655846118927
Test set avg_accuracy=80.17% avg_sensitivity=75.04%, avg_specificity=81.89% avg_auc=86.80%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.330144 Test loss=0.420135 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3344824016094208
[5/24] Train loss=0.3020816445350647
[10/24] Train loss=0.33414557576179504
[15/24] Train loss=0.29050523042678833
[20/24] Train loss=0.2598348557949066
Test set avg_accuracy=84.18% avg_sensitivity=65.56%, avg_specificity=90.43% avg_auc=88.81%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.326952 Test loss=0.355346 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3345714807510376
[5/24] Train loss=0.30004847049713135
[10/24] Train loss=0.33827516436576843
[15/24] Train loss=0.29188576340675354
[20/24] Train loss=0.2657930552959442
Test set avg_accuracy=83.59% avg_sensitivity=67.17%, avg_specificity=89.11% avg_auc=88.60%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.330239 Test loss=0.360135 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.33798715472221375
[5/24] Train loss=0.29853543639183044
[10/24] Train loss=0.3364514112472534
[15/24] Train loss=0.2946048080921173
[20/24] Train loss=0.2650568187236786
Test set avg_accuracy=83.22% avg_sensitivity=70.64%, avg_specificity=87.44% avg_auc=88.63%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.327423 Test loss=0.373345 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.33603134751319885
[5/24] Train loss=0.29083964228630066
[10/24] Train loss=0.33946871757507324
[15/24] Train loss=0.3000597059726715
[20/24] Train loss=0.2603413462638855
Test set avg_accuracy=81.43% avg_sensitivity=68.77%, avg_specificity=85.68% avg_auc=86.49%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.327496 Test loss=0.406671 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3377498686313629
[5/24] Train loss=0.29397469758987427
[10/24] Train loss=0.33698952198028564
[15/24] Train loss=0.2919110655784607
[20/24] Train loss=0.24431392550468445
Test set avg_accuracy=81.34% avg_sensitivity=70.84%, avg_specificity=84.87% avg_auc=86.58%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.325287 Test loss=0.413698 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3351520299911499
[5/24] Train loss=0.2935382127761841
[10/24] Train loss=0.331869900226593
[15/24] Train loss=0.29844582080841064
[20/24] Train loss=0.25741279125213623
Test set avg_accuracy=80.53% avg_sensitivity=67.43%, avg_specificity=84.94% avg_auc=84.55%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.327435 Test loss=0.437005 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.33309459686279297
[5/24] Train loss=0.296312153339386
[10/24] Train loss=0.3267802596092224
[15/24] Train loss=0.2983931303024292
[20/24] Train loss=0.2563866972923279
Test set avg_accuracy=83.24% avg_sensitivity=61.83%, avg_specificity=90.43% avg_auc=88.65%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.326323 Test loss=0.368215 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3263101875782013
[5/24] Train loss=0.2951467037200928
[10/24] Train loss=0.3258143961429596
[15/24] Train loss=0.29440054297447205
[20/24] Train loss=0.25923022627830505
Test set avg_accuracy=83.71% avg_sensitivity=68.31%, avg_specificity=88.89% avg_auc=88.17%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.323210 Test loss=0.367264 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3378841280937195
[5/24] Train loss=0.30112138390541077
[10/24] Train loss=0.3403915464878082
[15/24] Train loss=0.2920301854610443
[20/24] Train loss=0.2493758350610733
Test set avg_accuracy=83.50% avg_sensitivity=55.98%, avg_specificity=92.75% avg_auc=87.72%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.323411 Test loss=0.367986 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.32406529784202576
[5/24] Train loss=0.29739534854888916
[10/24] Train loss=0.31937822699546814
[15/24] Train loss=0.28424444794654846
[20/24] Train loss=0.2483544796705246
Test set avg_accuracy=83.05% avg_sensitivity=65.72%, avg_specificity=88.87% avg_auc=87.43%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.319210 Test loss=0.376294 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.320762038230896
[5/24] Train loss=0.29587721824645996
[10/24] Train loss=0.3307953178882599
[15/24] Train loss=0.30009230971336365
[20/24] Train loss=0.2551436722278595
Test set avg_accuracy=83.42% avg_sensitivity=63.75%, avg_specificity=90.03% avg_auc=87.70%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.322403 Test loss=0.389358 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3186841607093811
[5/24] Train loss=0.29227426648139954
[10/24] Train loss=0.3227722644805908
[15/24] Train loss=0.2948134243488312
[20/24] Train loss=0.2622508406639099
Test set avg_accuracy=82.16% avg_sensitivity=66.55%, avg_specificity=87.41% avg_auc=87.70%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.321680 Test loss=0.382992 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3224927484989166
[5/24] Train loss=0.2909228503704071
[10/24] Train loss=0.332392156124115
[15/24] Train loss=0.2915101647377014
[20/24] Train loss=0.2560856342315674
Test set avg_accuracy=83.46% avg_sensitivity=61.00%, avg_specificity=91.01% avg_auc=88.19%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.319719 Test loss=0.363195 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.32467854022979736
[5/24] Train loss=0.3017313480377197
[10/24] Train loss=0.32642602920532227
[15/24] Train loss=0.285180002450943
[20/24] Train loss=0.24508319795131683
Test set avg_accuracy=81.24% avg_sensitivity=37.08%, avg_specificity=96.07% avg_auc=84.57%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.319043 Test loss=0.430715 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3318363130092621
[5/24] Train loss=0.29156866669654846
[10/24] Train loss=0.32089439034461975
[15/24] Train loss=0.29309409856796265
[20/24] Train loss=0.26066768169403076
Test set avg_accuracy=83.75% avg_sensitivity=63.23%, avg_specificity=90.64% avg_auc=88.22%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.316408 Test loss=0.362261 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.32767894864082336
[5/24] Train loss=0.2921992838382721
[10/24] Train loss=0.3174477517604828
[15/24] Train loss=0.28969502449035645
[20/24] Train loss=0.24277377128601074
Test set avg_accuracy=83.55% avg_sensitivity=56.65%, avg_specificity=92.59% avg_auc=88.40%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.317282 Test loss=0.358435 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.31040331721305847
[5/24] Train loss=0.28677526116371155
[10/24] Train loss=0.32212474942207336
[15/24] Train loss=0.28783324360847473
[20/24] Train loss=0.25535744428634644
Test set avg_accuracy=84.18% avg_sensitivity=69.24%, avg_specificity=89.20% avg_auc=88.90%
Best model saved!! Metric=5.512576501748342!!
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.314543 Test loss=0.359978 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3250795304775238
[5/24] Train loss=0.2946999967098236
[10/24] Train loss=0.31397685408592224
[15/24] Train loss=0.2882806062698364
[20/24] Train loss=0.2489696592092514
Test set avg_accuracy=82.58% avg_sensitivity=58.67%, avg_specificity=90.61% avg_auc=87.21%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.313569 Test loss=0.376608 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3224985897541046
[5/24] Train loss=0.29094603657722473
[10/24] Train loss=0.32752761244773865
[15/24] Train loss=0.2890077233314514
[20/24] Train loss=0.24220266938209534
Test set avg_accuracy=82.17% avg_sensitivity=45.68%, avg_specificity=94.43% avg_auc=84.38%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.312079 Test loss=0.408475 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3108154535293579
[5/24] Train loss=0.295919805765152
[10/24] Train loss=0.31532132625579834
[15/24] Train loss=0.28535380959510803
[20/24] Train loss=0.2514127194881439
Test set avg_accuracy=79.93% avg_sensitivity=32.63%, avg_specificity=95.83% avg_auc=83.79%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.310067 Test loss=0.455190 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.31980639696121216
[5/24] Train loss=0.27937236428260803
[10/24] Train loss=0.30539900064468384
[15/24] Train loss=0.2844911813735962
[20/24] Train loss=0.2434423267841339
Test set avg_accuracy=83.92% avg_sensitivity=58.10%, avg_specificity=92.59% avg_auc=87.68%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.309230 Test loss=0.365428 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.32500866055488586
[5/24] Train loss=0.28025394678115845
[10/24] Train loss=0.3089437186717987
[15/24] Train loss=0.2861465513706207
[20/24] Train loss=0.24600732326507568
Test set avg_accuracy=83.62% avg_sensitivity=50.18%, avg_specificity=94.85% avg_auc=88.17%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.309675 Test loss=0.365760 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3129511773586273
[5/24] Train loss=0.29044997692108154
[10/24] Train loss=0.31154581904411316
[15/24] Train loss=0.2880343794822693
[20/24] Train loss=0.23783652484416962
Test set avg_accuracy=83.48% avg_sensitivity=62.20%, avg_specificity=90.62% avg_auc=87.82%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.307376 Test loss=0.368891 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3118506073951721
[5/24] Train loss=0.27896615862846375
[10/24] Train loss=0.3107346296310425
[15/24] Train loss=0.2885466516017914
[20/24] Train loss=0.2415076345205307
Test set avg_accuracy=83.83% avg_sensitivity=68.77%, avg_specificity=88.89% avg_auc=88.31%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.305456 Test loss=0.365395 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.30818164348602295
[5/24] Train loss=0.27614879608154297
[10/24] Train loss=0.306841105222702
[15/24] Train loss=0.27868106961250305
[20/24] Train loss=0.23781178891658783
Test set avg_accuracy=83.55% avg_sensitivity=64.11%, avg_specificity=90.09% avg_auc=88.49%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.300733 Test loss=0.358931 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3033044636249542
[5/24] Train loss=0.2716697156429291
[10/24] Train loss=0.298511266708374
[15/24] Train loss=0.28285136818885803
[20/24] Train loss=0.24398331344127655
Test set avg_accuracy=83.35% avg_sensitivity=58.26%, avg_specificity=91.77% avg_auc=87.55%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.302305 Test loss=0.372390 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.30048897862434387
[5/24] Train loss=0.27846965193748474
[10/24] Train loss=0.3040253221988678
[15/24] Train loss=0.28410348296165466
[20/24] Train loss=0.24648508429527283
Test set avg_accuracy=84.09% avg_sensitivity=59.14%, avg_specificity=92.47% avg_auc=86.88%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.299687 Test loss=0.375297 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.30565664172172546
[5/24] Train loss=0.27313223481178284
[10/24] Train loss=0.2963210940361023
[15/24] Train loss=0.2715376317501068
[20/24] Train loss=0.2386733889579773
Test set avg_accuracy=82.36% avg_sensitivity=45.00%, avg_specificity=94.90% avg_auc=86.05%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.296671 Test loss=0.394225 Current lr=[0.000156543481933168]

[0/24] Train loss=0.29924309253692627
[5/24] Train loss=0.2705104947090149
[10/24] Train loss=0.2947569191455841
[15/24] Train loss=0.2775898873806
[20/24] Train loss=0.24048419296741486
Test set avg_accuracy=83.76% avg_sensitivity=59.92%, avg_specificity=91.77% avg_auc=87.37%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.297413 Test loss=0.373677 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3092663884162903
[5/24] Train loss=0.26666054129600525
[10/24] Train loss=0.29251834750175476
[15/24] Train loss=0.27766454219818115
[20/24] Train loss=0.23910380899906158
Test set avg_accuracy=83.33% avg_sensitivity=58.36%, avg_specificity=91.72% avg_auc=87.07%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.294936 Test loss=0.374413 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3018885552883148
[5/24] Train loss=0.2639084756374359
[10/24] Train loss=0.3078930377960205
[15/24] Train loss=0.26855286955833435
[20/24] Train loss=0.2340545803308487
Test set avg_accuracy=82.45% avg_sensitivity=48.63%, avg_specificity=93.81% avg_auc=86.46%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.291038 Test loss=0.388587 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.28791823983192444
[5/24] Train loss=0.27660036087036133
[10/24] Train loss=0.28949761390686035
[15/24] Train loss=0.26854783296585083
[20/24] Train loss=0.2425338178873062
Test set avg_accuracy=81.82% avg_sensitivity=49.77%, avg_specificity=92.59% avg_auc=85.17%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.290071 Test loss=0.407277 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.2924751341342926
[5/24] Train loss=0.2514755427837372
[10/24] Train loss=0.2873374819755554
[15/24] Train loss=0.2634808421134949
[20/24] Train loss=0.23725420236587524
Test set avg_accuracy=84.38% avg_sensitivity=62.71%, avg_specificity=91.65% avg_auc=88.47%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.287279 Test loss=0.359466 Current lr=[0.000134135431043539]

[0/24] Train loss=0.28960585594177246
[5/24] Train loss=0.25557637214660645
[10/24] Train loss=0.2817399501800537
[15/24] Train loss=0.27374202013015747
[20/24] Train loss=0.23470768332481384
Test set avg_accuracy=82.62% avg_sensitivity=59.97%, avg_specificity=90.22% avg_auc=86.60%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.283223 Test loss=0.391048 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.2979198098182678
[5/24] Train loss=0.2591155171394348
[10/24] Train loss=0.2784278094768524
[15/24] Train loss=0.25901609659194946
[20/24] Train loss=0.22925813496112823
Test set avg_accuracy=82.89% avg_sensitivity=62.92%, avg_specificity=89.60% avg_auc=87.30%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.285145 Test loss=0.377959 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2907331585884094
[5/24] Train loss=0.2642230689525604
[10/24] Train loss=0.2792188227176666
[15/24] Train loss=0.2746753692626953
[20/24] Train loss=0.22873418033123016
Test set avg_accuracy=82.94% avg_sensitivity=56.19%, avg_specificity=91.93% avg_auc=86.90%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.286402 Test loss=0.378628 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.2840316891670227
[5/24] Train loss=0.24933409690856934
[10/24] Train loss=0.26809999346733093
[15/24] Train loss=0.26996633410453796
[20/24] Train loss=0.23832036554813385
Test set avg_accuracy=83.46% avg_sensitivity=57.43%, avg_specificity=92.21% avg_auc=86.55%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.278326 Test loss=0.383209 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.2827228009700775
[5/24] Train loss=0.255662202835083
[10/24] Train loss=0.2798277735710144
[15/24] Train loss=0.26461249589920044
[20/24] Train loss=0.23038436472415924
Test set avg_accuracy=81.81% avg_sensitivity=50.34%, avg_specificity=92.38% avg_auc=85.84%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.280420 Test loss=0.396584 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.28032147884368896
[5/24] Train loss=0.2464161068201065
[10/24] Train loss=0.2678276598453522
[15/24] Train loss=0.2596750855445862
[20/24] Train loss=0.223658487200737
Test set avg_accuracy=82.41% avg_sensitivity=59.50%, avg_specificity=90.10% avg_auc=86.22%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.274695 Test loss=0.393344 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.27598807215690613
[5/24] Train loss=0.24805837869644165
[10/24] Train loss=0.26333948969841003
[15/24] Train loss=0.26105204224586487
[20/24] Train loss=0.2274055927991867
Test set avg_accuracy=82.47% avg_sensitivity=55.93%, avg_specificity=91.39% avg_auc=87.16%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.270411 Test loss=0.382647 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.2800773084163666
[5/24] Train loss=0.24509888887405396
[10/24] Train loss=0.27393239736557007
[15/24] Train loss=0.2569970488548279
[20/24] Train loss=0.2234734147787094
Test set avg_accuracy=82.41% avg_sensitivity=56.97%, avg_specificity=90.95% avg_auc=86.17%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.271776 Test loss=0.394977 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.27099698781967163
[5/24] Train loss=0.24084241688251495
[10/24] Train loss=0.26718875765800476
[15/24] Train loss=0.26029911637306213
[20/24] Train loss=0.22126184403896332
Test set avg_accuracy=81.81% avg_sensitivity=60.90%, avg_specificity=88.83% avg_auc=86.32%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.269578 Test loss=0.393972 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.27000248432159424
[5/24] Train loss=0.2369188368320465
[10/24] Train loss=0.26102423667907715
[15/24] Train loss=0.2545355260372162
[20/24] Train loss=0.22604604065418243
Test set avg_accuracy=82.90% avg_sensitivity=60.90%, avg_specificity=90.29% avg_auc=87.13%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.265036 Test loss=0.385047 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2744244635105133
[5/24] Train loss=0.23144888877868652
[10/24] Train loss=0.2524125874042511
[15/24] Train loss=0.24571487307548523
[20/24] Train loss=0.21908850967884064
Test set avg_accuracy=82.54% avg_sensitivity=63.54%, avg_specificity=88.92% avg_auc=87.07%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.261292 Test loss=0.392344 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.2688738703727722
[5/24] Train loss=0.22387342154979706
[10/24] Train loss=0.25881773233413696
[15/24] Train loss=0.24368776381015778
[20/24] Train loss=0.21672624349594116
Test set avg_accuracy=83.06% avg_sensitivity=64.47%, avg_specificity=89.30% avg_auc=87.70%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.259454 Test loss=0.376686 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.2679723799228668
[5/24] Train loss=0.23060640692710876
[10/24] Train loss=0.2622402310371399
[15/24] Train loss=0.25300610065460205
[20/24] Train loss=0.21327707171440125
Test set avg_accuracy=82.55% avg_sensitivity=64.06%, avg_specificity=88.76% avg_auc=86.95%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.259945 Test loss=0.387169 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.2628129720687866
[5/24] Train loss=0.23594221472740173
[10/24] Train loss=0.25122198462486267
[15/24] Train loss=0.25950515270233154
[20/24] Train loss=0.21681955456733704
Test set avg_accuracy=82.32% avg_sensitivity=62.30%, avg_specificity=89.04% avg_auc=87.15%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.257129 Test loss=0.386409 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.25693896412849426
[5/24] Train loss=0.22582918405532837
[10/24] Train loss=0.24161690473556519
[15/24] Train loss=0.23814569413661957
[20/24] Train loss=0.20837542414665222
Test set avg_accuracy=82.85% avg_sensitivity=61.37%, avg_specificity=90.07% avg_auc=86.78%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.251647 Test loss=0.385186 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.2603641450405121
[5/24] Train loss=0.22582639753818512
[10/24] Train loss=0.25016874074935913
[15/24] Train loss=0.23572704195976257
[20/24] Train loss=0.213810533285141
Test set avg_accuracy=82.88% avg_sensitivity=65.46%, avg_specificity=88.73% avg_auc=87.18%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.249628 Test loss=0.382092 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.2538885176181793
[5/24] Train loss=0.21066395938396454
[10/24] Train loss=0.2548004388809204
[15/24] Train loss=0.22422756254673004
[20/24] Train loss=0.20603050291538239
Test set avg_accuracy=83.19% avg_sensitivity=66.65%, avg_specificity=88.75% avg_auc=87.03%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.245101 Test loss=0.384573 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.2514575123786926
[5/24] Train loss=0.21736060082912445
[10/24] Train loss=0.24052304029464722
[15/24] Train loss=0.23308220505714417
[20/24] Train loss=0.20918065309524536
Test set avg_accuracy=82.15% avg_sensitivity=67.58%, avg_specificity=87.04% avg_auc=86.84%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.243427 Test loss=0.392106 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.24894572794437408
[5/24] Train loss=0.21097826957702637
[10/24] Train loss=0.22740647196769714
[15/24] Train loss=0.22944097220897675
[20/24] Train loss=0.2008434534072876
Test set avg_accuracy=83.61% avg_sensitivity=64.32%, avg_specificity=90.09% avg_auc=87.04%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.239464 Test loss=0.378013 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.2456381618976593
[5/24] Train loss=0.20431780815124512
[10/24] Train loss=0.2295522838830948
[15/24] Train loss=0.22349880635738373
[20/24] Train loss=0.20410598814487457
Test set avg_accuracy=83.02% avg_sensitivity=67.58%, avg_specificity=88.21% avg_auc=87.15%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.234043 Test loss=0.385531 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.23708046972751617
[5/24] Train loss=0.2096042037010193
[10/24] Train loss=0.22750353813171387
[15/24] Train loss=0.22178485989570618
[20/24] Train loss=0.19570936262607574
Test set avg_accuracy=82.85% avg_sensitivity=70.53%, avg_specificity=86.99% avg_auc=87.78%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.231157 Test loss=0.386349 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.2522001564502716
[5/24] Train loss=0.20508180558681488
[10/24] Train loss=0.22908326983451843
[15/24] Train loss=0.2169899046421051
[20/24] Train loss=0.19164074957370758
Test set avg_accuracy=83.14% avg_sensitivity=64.01%, avg_specificity=89.56% avg_auc=86.93%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.229697 Test loss=0.384193 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.232824444770813
[5/24] Train loss=0.20859457552433014
[10/24] Train loss=0.21805083751678467
[15/24] Train loss=0.22981734573841095
[20/24] Train loss=0.19655485451221466
Test set avg_accuracy=82.84% avg_sensitivity=65.10%, avg_specificity=88.80% avg_auc=87.20%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.226998 Test loss=0.384602 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.23088563978672028
[5/24] Train loss=0.19449664652347565
[10/24] Train loss=0.2206200361251831
[15/24] Train loss=0.21887147426605225
[20/24] Train loss=0.19327177107334137
Test set avg_accuracy=83.41% avg_sensitivity=58.78%, avg_specificity=91.69% avg_auc=85.66%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.224665 Test loss=0.393145 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.23344098031520844
[5/24] Train loss=0.1992112249135971
[10/24] Train loss=0.22148963809013367
[15/24] Train loss=0.2130730152130127
[20/24] Train loss=0.19249612092971802
Test set avg_accuracy=83.12% avg_sensitivity=60.54%, avg_specificity=90.71% avg_auc=86.40%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.222787 Test loss=0.387736 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.21926920115947723
[5/24] Train loss=0.1970454305410385
[10/24] Train loss=0.21888504922389984
[15/24] Train loss=0.21187373995780945
[20/24] Train loss=0.19332395493984222
Test set avg_accuracy=82.86% avg_sensitivity=55.05%, avg_specificity=92.21% avg_auc=84.78%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.218184 Test loss=0.403919 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.226401686668396
[5/24] Train loss=0.19111910462379456
[10/24] Train loss=0.21415077149868011
[15/24] Train loss=0.20328287780284882
[20/24] Train loss=0.18697531521320343
Test set avg_accuracy=82.54% avg_sensitivity=56.08%, avg_specificity=91.42% avg_auc=84.11%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.216423 Test loss=0.411277 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.22057022154331207
[5/24] Train loss=0.19200856983661652
[10/24] Train loss=0.21781450510025024
[15/24] Train loss=0.20585186779499054
[20/24] Train loss=0.18560673296451569
Test set avg_accuracy=83.07% avg_sensitivity=61.63%, avg_specificity=90.28% avg_auc=84.48%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.216174 Test loss=0.405415 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.22019006311893463
[5/24] Train loss=0.18691474199295044
[10/24] Train loss=0.21124553680419922
[15/24] Train loss=0.20813439786434174
[20/24] Train loss=0.1819244772195816
Test set avg_accuracy=82.97% avg_sensitivity=63.08%, avg_specificity=89.65% avg_auc=85.78%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.212476 Test loss=0.394949 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.21356621384620667
[5/24] Train loss=0.1861373782157898
[10/24] Train loss=0.2070842832326889
[15/24] Train loss=0.1999383419752121
[20/24] Train loss=0.18120279908180237
Test set avg_accuracy=83.29% avg_sensitivity=59.87%, avg_specificity=91.16% avg_auc=85.64%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.210436 Test loss=0.396566 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.21190033853054047
[5/24] Train loss=0.1874336302280426
[10/24] Train loss=0.20583698153495789
[15/24] Train loss=0.195262148976326
[20/24] Train loss=0.18194293975830078
Test set avg_accuracy=83.14% avg_sensitivity=61.37%, avg_specificity=90.45% avg_auc=85.56%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.208229 Test loss=0.395587 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.20837000012397766
[5/24] Train loss=0.18361619114875793
[10/24] Train loss=0.1999121755361557
[15/24] Train loss=0.2028999775648117
[20/24] Train loss=0.17818526923656464
Test set avg_accuracy=82.94% avg_sensitivity=62.09%, avg_specificity=89.95% avg_auc=85.66%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.207610 Test loss=0.397641 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.2133217453956604
[5/24] Train loss=0.18063338100910187
[10/24] Train loss=0.19979986548423767
[15/24] Train loss=0.19586582481861115
[20/24] Train loss=0.1800929754972458
Test set avg_accuracy=82.83% avg_sensitivity=62.61%, avg_specificity=89.62% avg_auc=86.20%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.205623 Test loss=0.394849 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.20814339816570282
[5/24] Train loss=0.1841762363910675
[10/24] Train loss=0.20589150488376617
[15/24] Train loss=0.20255811512470245
[20/24] Train loss=0.17765790224075317
Test set avg_accuracy=82.90% avg_sensitivity=62.51%, avg_specificity=89.75% avg_auc=86.11%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.205314 Test loss=0.392598 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.20631304383277893
[5/24] Train loss=0.1833817958831787
[10/24] Train loss=0.20069491863250732
[15/24] Train loss=0.19573356211185455
[20/24] Train loss=0.1800515353679657
Test set avg_accuracy=83.09% avg_sensitivity=60.59%, avg_specificity=90.64% avg_auc=85.66%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.202904 Test loss=0.395225 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.2089567929506302
[5/24] Train loss=0.1780942678451538
[10/24] Train loss=0.20117393136024475
[15/24] Train loss=0.1968860775232315
[20/24] Train loss=0.17803974449634552
Test set avg_accuracy=82.94% avg_sensitivity=62.66%, avg_specificity=89.75% avg_auc=85.48%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.202635 Test loss=0.399135 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.20145733654499054
[5/24] Train loss=0.17857177555561066
[10/24] Train loss=0.19914363324642181
[15/24] Train loss=0.19143818318843842
[20/24] Train loss=0.17702218890190125
Test set avg_accuracy=83.09% avg_sensitivity=61.47%, avg_specificity=90.35% avg_auc=85.49%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.202082 Test loss=0.398075 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.2047479748725891
[5/24] Train loss=0.18164706230163574
[10/24] Train loss=0.2020030915737152
[15/24] Train loss=0.18970099091529846
[20/24] Train loss=0.1713847517967224
Test set avg_accuracy=82.55% avg_sensitivity=62.09%, avg_specificity=89.42% avg_auc=85.34%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.200786 Test loss=0.402504 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.20147044956684113
[5/24] Train loss=0.18366602063179016
[10/24] Train loss=0.1971634030342102
[15/24] Train loss=0.19109046459197998
[20/24] Train loss=0.17415215075016022
Test set avg_accuracy=83.09% avg_sensitivity=61.42%, avg_specificity=90.36% avg_auc=85.29%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.199314 Test loss=0.401530 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.19505752623081207
[5/24] Train loss=0.17987674474716187
[10/24] Train loss=0.19334012269973755
[15/24] Train loss=0.1965974122285843
[20/24] Train loss=0.18450774252414703
Test set avg_accuracy=82.84% avg_sensitivity=61.06%, avg_specificity=90.15% avg_auc=85.69%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.199645 Test loss=0.396885 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.2005482167005539
[5/24] Train loss=0.17760595679283142
[10/24] Train loss=0.19584274291992188
[15/24] Train loss=0.19253134727478027
[20/24] Train loss=0.17051085829734802
Test set avg_accuracy=82.80% avg_sensitivity=62.09%, avg_specificity=89.75% avg_auc=85.64%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.198029 Test loss=0.399479 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.20017673075199127
[5/24] Train loss=0.17887133359909058
[10/24] Train loss=0.1980685293674469
[15/24] Train loss=0.19301781058311462
[20/24] Train loss=0.17312867939472198
Test set avg_accuracy=82.80% avg_sensitivity=61.99%, avg_specificity=89.79% avg_auc=85.59%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.198704 Test loss=0.398555 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1997109204530716
[5/24] Train loss=0.17405599355697632
[10/24] Train loss=0.19870933890342712
[15/24] Train loss=0.1864147037267685
[20/24] Train loss=0.16964992880821228
Test set avg_accuracy=82.94% avg_sensitivity=62.20%, avg_specificity=89.91% avg_auc=85.54%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.197339 Test loss=0.399644 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1944347769021988
[5/24] Train loss=0.1793859899044037
[10/24] Train loss=0.19297918677330017
[15/24] Train loss=0.18582561612129211
[20/24] Train loss=0.17662443220615387
Test set avg_accuracy=82.93% avg_sensitivity=61.57%, avg_specificity=90.10% avg_auc=85.47%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.198271 Test loss=0.400553 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.19709844887256622
[5/24] Train loss=0.17294251918792725
[10/24] Train loss=0.19153322279453278
[15/24] Train loss=0.19056442379951477
[20/24] Train loss=0.1709609031677246
Test set avg_accuracy=82.90% avg_sensitivity=61.68%, avg_specificity=90.03% avg_auc=85.46%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.197892 Test loss=0.400632 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.19859038293361664
[5/24] Train loss=0.17556317150592804
[10/24] Train loss=0.19522348046302795
[15/24] Train loss=0.1894504576921463
[20/24] Train loss=0.17108920216560364
Test set avg_accuracy=82.80% avg_sensitivity=61.52%, avg_specificity=89.95% avg_auc=85.47%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.196688 Test loss=0.400279 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.19239483773708344
[5/24] Train loss=0.17627650499343872
[10/24] Train loss=0.19582262635231018
[15/24] Train loss=0.18992342054843903
[20/24] Train loss=0.17657136917114258
Test set avg_accuracy=82.77% avg_sensitivity=61.52%, avg_specificity=89.91% avg_auc=85.47%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.197014 Test loss=0.400417 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.19311174750328064
[5/24] Train loss=0.1746627241373062
[10/24] Train loss=0.19804708659648895
[15/24] Train loss=0.1902337223291397
[20/24] Train loss=0.16988787055015564
Test set avg_accuracy=82.79% avg_sensitivity=61.42%, avg_specificity=89.96% avg_auc=85.49%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.196591 Test loss=0.400417 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1947394460439682
[5/24] Train loss=0.17522434890270233
[10/24] Train loss=0.19217433035373688
[15/24] Train loss=0.1922219842672348
[20/24] Train loss=0.1781231313943863
Test set avg_accuracy=82.90% avg_sensitivity=61.42%, avg_specificity=90.12% avg_auc=85.48%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.196450 Test loss=0.400377 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=84.18% sen=69.24%, spe=89.20%, auc=88.90%!
Fold[8] Avg_overlap=0.61%(0.2688628700132592)
[0/23] Train loss=0.7227256894111633
[5/23] Train loss=0.7214349508285522
[10/23] Train loss=0.7186524868011475
[15/23] Train loss=0.7205713987350464
[20/23] Train loss=0.7088680863380432
Test set avg_accuracy=55.39% avg_sensitivity=46.31%, avg_specificity=58.28% avg_auc=54.20%
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.719788 Test loss=0.690615 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.7083005905151367
[5/23] Train loss=0.6996610164642334
[10/23] Train loss=0.7067042589187622
[15/23] Train loss=0.6999529600143433
[20/23] Train loss=0.6923331022262573
Test set avg_accuracy=61.56% avg_sensitivity=49.97%, avg_specificity=65.25% avg_auc=60.02%
Best model saved!! Metric=-89.19441958863067!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.703140 Test loss=0.671454 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.6887317895889282
[5/23] Train loss=0.6873937249183655
[10/23] Train loss=0.6906281113624573
[15/23] Train loss=0.684056282043457
[20/23] Train loss=0.6703813076019287
Test set avg_accuracy=62.14% avg_sensitivity=52.18%, avg_specificity=65.30% avg_auc=63.13%
Best model saved!! Metric=-83.24269839181116!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.686963 Test loss=0.656099 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.6721968650817871
[5/23] Train loss=0.6761038303375244
[10/23] Train loss=0.6785503625869751
[15/23] Train loss=0.6641562581062317
[20/23] Train loss=0.6559635996818542
Test set avg_accuracy=63.16% avg_sensitivity=55.36%, avg_specificity=65.65% avg_auc=65.63%
Best model saved!! Metric=-76.19688980383029!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.671125 Test loss=0.642416 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.6576074361801147
[5/23] Train loss=0.6561623215675354
[10/23] Train loss=0.6646520495414734
[15/23] Train loss=0.6390812397003174
[20/23] Train loss=0.6360352635383606
Test set avg_accuracy=64.05% avg_sensitivity=57.68%, avg_specificity=66.08% avg_auc=67.97%
Best model saved!! Metric=-70.218628141039!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.653963 Test loss=0.626637 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.6312178373336792
[5/23] Train loss=0.6316039562225342
[10/23] Train loss=0.6484085321426392
[15/23] Train loss=0.6231801509857178
[20/23] Train loss=0.6071425676345825
Test set avg_accuracy=66.32% avg_sensitivity=57.36%, avg_specificity=69.17% avg_auc=70.50%
Best model saved!! Metric=-62.66216409102915!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.631483 Test loss=0.596039 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.610176146030426
[5/23] Train loss=0.6135032773017883
[10/23] Train loss=0.6221509575843811
[15/23] Train loss=0.596860408782959
[20/23] Train loss=0.5807651877403259
Test set avg_accuracy=71.09% avg_sensitivity=60.97%, avg_specificity=74.32% avg_auc=74.36%
Best model saved!! Metric=-45.262299651215244!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.607750 Test loss=0.569840 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.5800340175628662
[5/23] Train loss=0.5849481225013733
[10/23] Train loss=0.5937342643737793
[15/23] Train loss=0.5739648342132568
[20/23] Train loss=0.5583732724189758
Test set avg_accuracy=74.18% avg_sensitivity=61.83%, avg_specificity=78.11% avg_auc=77.45%
Best model saved!! Metric=-34.424868103114164!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.580441 Test loss=0.534038 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.5579737424850464
[5/23] Train loss=0.5500133037567139
[10/23] Train loss=0.5753605365753174
[15/23] Train loss=0.5452355742454529
[20/23] Train loss=0.5220677852630615
Test set avg_accuracy=76.33% avg_sensitivity=67.33%, avg_specificity=79.19% avg_auc=80.29%
Best model saved!! Metric=-22.857780162939747!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.552867 Test loss=0.514401 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.5297940969467163
[5/23] Train loss=0.5272110104560852
[10/23] Train loss=0.5440871715545654
[15/23] Train loss=0.5243142247200012
[20/23] Train loss=0.49242010712623596
Test set avg_accuracy=78.97% avg_sensitivity=67.28%, avg_specificity=82.70% avg_auc=82.08%
Best model saved!! Metric=-14.9763940604888!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.525790 Test loss=0.480223 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.5070928931236267
[5/23] Train loss=0.4874587059020996
[10/23] Train loss=0.5275124907493591
[15/23] Train loss=0.4960414171218872
[20/23] Train loss=0.47063836455345154
Test set avg_accuracy=80.36% avg_sensitivity=67.33%, avg_specificity=84.52% avg_auc=83.79%
Best model saved!! Metric=-9.997472587909584!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.499626 Test loss=0.452561 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.47382888197898865
[5/23] Train loss=0.4749097526073456
[10/23] Train loss=0.502129852771759
[15/23] Train loss=0.4739992320537567
[20/23] Train loss=0.4475153088569641
Test set avg_accuracy=80.78% avg_sensitivity=69.22%, avg_specificity=84.46% avg_auc=85.14%
Best model saved!! Metric=-6.400458177643046!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.478322 Test loss=0.441307 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.4646669924259186
[5/23] Train loss=0.4484440088272095
[10/23] Train loss=0.4842170774936676
[15/23] Train loss=0.45324990153312683
[20/23] Train loss=0.4314747154712677
Test set avg_accuracy=81.94% avg_sensitivity=67.55%, avg_specificity=86.52% avg_auc=85.79%
Best model saved!! Metric=-4.197790168328638!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.460343 Test loss=0.416311 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.4431862235069275
[5/23] Train loss=0.4325125515460968
[10/23] Train loss=0.4766363799571991
[15/23] Train loss=0.4361298084259033
[20/23] Train loss=0.4082498252391815
Test set avg_accuracy=82.80% avg_sensitivity=63.13%, avg_specificity=89.06% avg_auc=86.22%
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.444269 Test loss=0.396024 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.4377055764198303
[5/23] Train loss=0.4115743339061737
[10/23] Train loss=0.4600085914134979
[15/23] Train loss=0.4258725643157959
[20/23] Train loss=0.39637961983680725
Test set avg_accuracy=82.57% avg_sensitivity=64.47%, avg_specificity=88.33% avg_auc=86.80%
Best model saved!! Metric=-3.8297641280477706!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.431582 Test loss=0.392746 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.4224359393119812
[5/23] Train loss=0.39554670453071594
[10/23] Train loss=0.4465288519859314
[15/23] Train loss=0.4100862741470337
[20/23] Train loss=0.3864904046058655
Test set avg_accuracy=82.89% avg_sensitivity=62.80%, avg_specificity=89.29% avg_auc=87.04%
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.420180 Test loss=0.382775 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.40609094500541687
[5/23] Train loss=0.38823574781417847
[10/23] Train loss=0.44347524642944336
[15/23] Train loss=0.40085822343826294
[20/23] Train loss=0.37333357334136963
Test set avg_accuracy=83.15% avg_sensitivity=61.99%, avg_specificity=89.89% avg_auc=87.12%
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.411676 Test loss=0.378039 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.3998397886753082
[5/23] Train loss=0.3790328800678253
[10/23] Train loss=0.43626126646995544
[15/23] Train loss=0.39425143599510193
[20/23] Train loss=0.37018021941185
Test set avg_accuracy=83.23% avg_sensitivity=65.98%, avg_specificity=88.72% avg_auc=87.65%
Best model saved!! Metric=-0.41571377478028637!!
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.403572 Test loss=0.379255 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.39140868186950684
[5/23] Train loss=0.37504029273986816
[10/23] Train loss=0.43125852942466736
[15/23] Train loss=0.38316643238067627
[20/23] Train loss=0.36326614022254944
Test set avg_accuracy=83.52% avg_sensitivity=66.63%, avg_specificity=88.89% avg_auc=87.95%
Best model saved!! Metric=0.9867446973728278!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.398023 Test loss=0.373793 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.3805862069129944
[5/23] Train loss=0.36631250381469727
[10/23] Train loss=0.43014323711395264
[15/23] Train loss=0.37593814730644226
[20/23] Train loss=0.3571942150592804
Test set avg_accuracy=82.54% avg_sensitivity=70.84%, avg_specificity=86.27% avg_auc=87.99%
Best model saved!! Metric=1.629075572197877!!
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.391493 Test loss=0.389228 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.37796512246131897
[5/23] Train loss=0.3574281930923462
[10/23] Train loss=0.4174387753009796
[15/23] Train loss=0.3753345310688019
[20/23] Train loss=0.34833043813705444
Test set avg_accuracy=82.71% avg_sensitivity=70.30%, avg_specificity=86.66% avg_auc=88.11%
Best model saved!! Metric=1.7759825356978922!!
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.386831 Test loss=0.382624 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.37734952569007874
[5/23] Train loss=0.3553198575973511
[10/23] Train loss=0.4219999313354492
[15/23] Train loss=0.36822211742401123
[20/23] Train loss=0.34165313839912415
Test set avg_accuracy=83.74% avg_sensitivity=69.11%, avg_specificity=88.39% avg_auc=88.51%
Best model saved!! Metric=3.7527583506376203!!
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.383659 Test loss=0.372259 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.3677857220172882
[5/23] Train loss=0.34667763113975525
[10/23] Train loss=0.41295385360717773
[15/23] Train loss=0.3676702082157135
[20/23] Train loss=0.33808109164237976
Test set avg_accuracy=82.90% avg_sensitivity=69.76%, avg_specificity=87.09% avg_auc=88.43%
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.379611 Test loss=0.377343 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.37169337272644043
[5/23] Train loss=0.3435727059841156
[10/23] Train loss=0.407626748085022
[15/23] Train loss=0.365607351064682
[20/23] Train loss=0.33471405506134033
Test set avg_accuracy=83.98% avg_sensitivity=68.46%, avg_specificity=88.93% avg_auc=88.65%
Best model saved!! Metric=4.029903267181865!!
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.374090 Test loss=0.363571 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.3630136549472809
[5/23] Train loss=0.34636425971984863
[10/23] Train loss=0.4117922782897949
[15/23] Train loss=0.3597995638847351
[20/23] Train loss=0.33349958062171936
Test set avg_accuracy=84.22% avg_sensitivity=66.52%, avg_specificity=89.85% avg_auc=88.43%
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.372863 Test loss=0.358523 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.36351609230041504
[5/23] Train loss=0.33758217096328735
[10/23] Train loss=0.3969948887825012
[15/23] Train loss=0.36418694257736206
[20/23] Train loss=0.3349914848804474
Test set avg_accuracy=83.68% avg_sensitivity=70.24%, avg_specificity=87.97% avg_auc=88.77%
Best model saved!! Metric=4.667420734135021!!
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.372198 Test loss=0.370176 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.3632237911224365
[5/23] Train loss=0.3426441550254822
[10/23] Train loss=0.40165793895721436
[15/23] Train loss=0.3563043773174286
[20/23] Train loss=0.33338382840156555
Test set avg_accuracy=82.96% avg_sensitivity=74.02%, avg_specificity=85.80% avg_auc=88.17%
Best model saved!! Metric=4.940981876544868!!
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.368393 Test loss=0.405669 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.3566646873950958
[5/23] Train loss=0.3322860598564148
[10/23] Train loss=0.40437549352645874
[15/23] Train loss=0.3497896194458008
[20/23] Train loss=0.3254278898239136
Test set avg_accuracy=83.48% avg_sensitivity=66.25%, avg_specificity=88.96% avg_auc=88.41%
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.365217 Test loss=0.377875 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.3627629280090332
[5/23] Train loss=0.33645108342170715
[10/23] Train loss=0.3953511118888855
[15/23] Train loss=0.3499876856803894
[20/23] Train loss=0.3218967318534851
Test set avg_accuracy=83.55% avg_sensitivity=51.43%, avg_specificity=93.79% avg_auc=88.23%
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.361613 Test loss=0.360834 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.3610997796058655
[5/23] Train loss=0.3388485014438629
[10/23] Train loss=0.39951378107070923
[15/23] Train loss=0.3382606506347656
[20/23] Train loss=0.32915106415748596
Test set avg_accuracy=82.86% avg_sensitivity=48.36%, avg_specificity=93.85% avg_auc=87.74%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.363300 Test loss=0.367917 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.35551828145980835
[5/23] Train loss=0.33566775918006897
[10/23] Train loss=0.39194783568382263
[15/23] Train loss=0.3479306697845459
[20/23] Train loss=0.32220104336738586
Test set avg_accuracy=82.02% avg_sensitivity=38.22%, avg_specificity=95.97% avg_auc=86.25%
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.360097 Test loss=0.390571 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.35065850615501404
[5/23] Train loss=0.33724507689476013
[10/23] Train loss=0.3922177851200104
[15/23] Train loss=0.3479701578617096
[20/23] Train loss=0.3197571635246277
Test set avg_accuracy=80.73% avg_sensitivity=35.04%, avg_specificity=95.28% avg_auc=85.03%
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.360322 Test loss=0.408681 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.341426283121109
[5/23] Train loss=0.3347460925579071
[10/23] Train loss=0.39733433723449707
[15/23] Train loss=0.3432222306728363
[20/23] Train loss=0.31583094596862793
Test set avg_accuracy=83.87% avg_sensitivity=57.57%, avg_specificity=92.24% avg_auc=88.82%
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.359506 Test loss=0.353123 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.3512483537197113
[5/23] Train loss=0.33050405979156494
[10/23] Train loss=0.3944239616394043
[15/23] Train loss=0.3466847240924835
[20/23] Train loss=0.311911404132843
Test set avg_accuracy=83.39% avg_sensitivity=67.98%, avg_specificity=88.29% avg_auc=88.84%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.357551 Test loss=0.367529 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.3482482433319092
[5/23] Train loss=0.3284125328063965
[10/23] Train loss=0.39196455478668213
[15/23] Train loss=0.33675020933151245
[20/23] Train loss=0.3178076446056366
Test set avg_accuracy=83.65% avg_sensitivity=58.49%, avg_specificity=91.66% avg_auc=88.93%
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.355401 Test loss=0.358426 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.34990257024765015
[5/23] Train loss=0.32737836241722107
[10/23] Train loss=0.38263043761253357
[15/23] Train loss=0.33465802669525146
[20/23] Train loss=0.31389182806015015
Test set avg_accuracy=84.32% avg_sensitivity=64.58%, avg_specificity=90.61% avg_auc=89.37%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.354543 Test loss=0.354384 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.34248003363609314
[5/23] Train loss=0.3208903968334198
[10/23] Train loss=0.38399824500083923
[15/23] Train loss=0.32855620980262756
[20/23] Train loss=0.3170417249202728
Test set avg_accuracy=82.68% avg_sensitivity=48.95%, avg_specificity=93.42% avg_auc=87.91%
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.352640 Test loss=0.365848 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.3480360209941864
[5/23] Train loss=0.32843515276908875
[10/23] Train loss=0.38968855142593384
[15/23] Train loss=0.3328603208065033
[20/23] Train loss=0.3135402798652649
Test set avg_accuracy=83.15% avg_sensitivity=45.01%, avg_specificity=95.30% avg_auc=88.39%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.351520 Test loss=0.364748 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.3415193557739258
[5/23] Train loss=0.3327060341835022
[10/23] Train loss=0.378869891166687
[15/23] Train loss=0.33034440875053406
[20/23] Train loss=0.3111099302768707
Test set avg_accuracy=83.10% avg_sensitivity=52.61%, avg_specificity=92.81% avg_auc=87.17%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.348993 Test loss=0.385525 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.3507460951805115
[5/23] Train loss=0.3315865397453308
[10/23] Train loss=0.3926432132720947
[15/23] Train loss=0.34653112292289734
[20/23] Train loss=0.3108692467212677
Test set avg_accuracy=80.87% avg_sensitivity=49.38%, avg_specificity=90.90% avg_auc=82.70%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.354164 Test loss=0.417977 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.34793055057525635
[5/23] Train loss=0.3212994337081909
[10/23] Train loss=0.37926098704338074
[15/23] Train loss=0.34216079115867615
[20/23] Train loss=0.3064022958278656
Test set avg_accuracy=83.11% avg_sensitivity=61.83%, avg_specificity=89.89% avg_auc=87.34%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.348921 Test loss=0.383256 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.3361554443836212
[5/23] Train loss=0.3323028087615967
[10/23] Train loss=0.37968239188194275
[15/23] Train loss=0.32470348477363586
[20/23] Train loss=0.30807679891586304
Test set avg_accuracy=80.95% avg_sensitivity=71.32%, avg_specificity=84.02% avg_auc=86.12%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.348809 Test loss=0.419832 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.33768558502197266
[5/23] Train loss=0.3265436291694641
[10/23] Train loss=0.3820882737636566
[15/23] Train loss=0.3265095055103302
[20/23] Train loss=0.31291282176971436
Test set avg_accuracy=78.75% avg_sensitivity=17.74%, avg_specificity=98.18% avg_auc=79.03%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.348897 Test loss=0.506891 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.34019216895103455
[5/23] Train loss=0.32041633129119873
[10/23] Train loss=0.3764722943305969
[15/23] Train loss=0.329624742269516
[20/23] Train loss=0.3045833706855774
Test set avg_accuracy=80.78% avg_sensitivity=35.15%, avg_specificity=95.31% avg_auc=82.02%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.346313 Test loss=0.427689 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.3354642987251282
[5/23] Train loss=0.3273981809616089
[10/23] Train loss=0.3815721571445465
[15/23] Train loss=0.3422197103500366
[20/23] Train loss=0.3132239580154419
Test set avg_accuracy=83.72% avg_sensitivity=59.25%, avg_specificity=91.52% avg_auc=87.72%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.349485 Test loss=0.365080 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.330769419670105
[5/23] Train loss=0.3258916437625885
[10/23] Train loss=0.3869246244430542
[15/23] Train loss=0.3202402889728546
[20/23] Train loss=0.3110322058200836
Test set avg_accuracy=82.38% avg_sensitivity=42.21%, avg_specificity=95.18% avg_auc=86.26%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.346310 Test loss=0.387324 Current lr=[0.000299926900870094]

[0/23] Train loss=0.3258397579193115
[5/23] Train loss=0.3231247365474701
[10/23] Train loss=0.3881598711013794
[15/23] Train loss=0.32848185300827026
[20/23] Train loss=0.29699811339378357
Test set avg_accuracy=82.47% avg_sensitivity=47.65%, avg_specificity=93.56% avg_auc=85.70%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.343235 Test loss=0.389310 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.330279678106308
[5/23] Train loss=0.3232281506061554
[10/23] Train loss=0.38750898838043213
[15/23] Train loss=0.3362460732460022
[20/23] Train loss=0.30460110306739807
Test set avg_accuracy=82.19% avg_sensitivity=38.60%, avg_specificity=96.07% avg_auc=86.61%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.345763 Test loss=0.391843 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.3393429219722748
[5/23] Train loss=0.31162765622138977
[10/23] Train loss=0.3829796612262726
[15/23] Train loss=0.3323522210121155
[20/23] Train loss=0.30129721760749817
Test set avg_accuracy=82.81% avg_sensitivity=63.99%, avg_specificity=88.81% avg_auc=88.09%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.342542 Test loss=0.385022 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.32509151101112366
[5/23] Train loss=0.3168583810329437
[10/23] Train loss=0.3808884620666504
[15/23] Train loss=0.3328447639942169
[20/23] Train loss=0.3058004677295685
Test set avg_accuracy=82.23% avg_sensitivity=41.83%, avg_specificity=95.09% avg_auc=85.21%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.342088 Test loss=0.394722 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.3317629098892212
[5/23] Train loss=0.32169362902641296
[10/23] Train loss=0.3694538176059723
[15/23] Train loss=0.33702051639556885
[20/23] Train loss=0.30894526839256287
Test set avg_accuracy=83.12% avg_sensitivity=54.99%, avg_specificity=92.09% avg_auc=88.03%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.343261 Test loss=0.361887 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.32982146739959717
[5/23] Train loss=0.31655749678611755
[10/23] Train loss=0.3738020360469818
[15/23] Train loss=0.3210756480693817
[20/23] Train loss=0.30170735716819763
Test set avg_accuracy=81.89% avg_sensitivity=66.58%, avg_specificity=86.76% avg_auc=86.67%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.340347 Test loss=0.408656 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.3349141478538513
[5/23] Train loss=0.31514379382133484
[10/23] Train loss=0.3834908604621887
[15/23] Train loss=0.3205137848854065
[20/23] Train loss=0.3071516156196594
Test set avg_accuracy=82.29% avg_sensitivity=57.84%, avg_specificity=90.08% avg_auc=86.99%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.342250 Test loss=0.386487 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.3261396586894989
[5/23] Train loss=0.3143509328365326
[10/23] Train loss=0.37795716524124146
[15/23] Train loss=0.3301904797554016
[20/23] Train loss=0.294586718082428
Test set avg_accuracy=84.13% avg_sensitivity=63.94%, avg_specificity=90.56% avg_auc=88.28%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.340259 Test loss=0.360763 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.33798250555992126
[5/23] Train loss=0.31382471323013306
[10/23] Train loss=0.3785335123538971
[15/23] Train loss=0.33211851119995117
[20/23] Train loss=0.30023685097694397
Test set avg_accuracy=84.15% avg_sensitivity=60.54%, avg_specificity=91.67% avg_auc=88.49%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.341439 Test loss=0.362544 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.3221258819103241
[5/23] Train loss=0.3172687888145447
[10/23] Train loss=0.38097140192985535
[15/23] Train loss=0.3209240138530731
[20/23] Train loss=0.2960507273674011
Test set avg_accuracy=81.55% avg_sensitivity=39.84%, avg_specificity=94.83% avg_auc=83.80%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.338151 Test loss=0.410017 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.32635799050331116
[5/23] Train loss=0.3222450315952301
[10/23] Train loss=0.3819579780101776
[15/23] Train loss=0.3284570872783661
[20/23] Train loss=0.300149530172348
Test set avg_accuracy=83.20% avg_sensitivity=62.32%, avg_specificity=89.85% avg_auc=87.35%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.341870 Test loss=0.372090 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.30950772762298584
[5/23] Train loss=0.3101818263530731
[10/23] Train loss=0.37387752532958984
[15/23] Train loss=0.32100558280944824
[20/23] Train loss=0.30150070786476135
Test set avg_accuracy=83.11% avg_sensitivity=50.57%, avg_specificity=93.48% avg_auc=86.48%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.335959 Test loss=0.380410 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.3243456780910492
[5/23] Train loss=0.3133464753627777
[10/23] Train loss=0.3661630153656006
[15/23] Train loss=0.312736839056015
[20/23] Train loss=0.2990638315677643
Test set avg_accuracy=83.88% avg_sensitivity=61.83%, avg_specificity=90.90% avg_auc=88.70%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.335917 Test loss=0.353214 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.3327842056751251
[5/23] Train loss=0.3152802586555481
[10/23] Train loss=0.3767315149307251
[15/23] Train loss=0.3194100558757782
[20/23] Train loss=0.2991129755973816
Test set avg_accuracy=82.29% avg_sensitivity=50.40%, avg_specificity=92.45% avg_auc=86.74%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.338814 Test loss=0.376219 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.31817835569381714
[5/23] Train loss=0.30735328793525696
[10/23] Train loss=0.37526941299438477
[15/23] Train loss=0.32647520303726196
[20/23] Train loss=0.29525524377822876
Test set avg_accuracy=81.03% avg_sensitivity=42.59%, avg_specificity=93.27% avg_auc=82.14%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.338672 Test loss=0.423494 Current lr=[0.000283047938381597]

[0/23] Train loss=0.3225174844264984
[5/23] Train loss=0.3103763461112976
[10/23] Train loss=0.36702316999435425
[15/23] Train loss=0.3132968842983246
[20/23] Train loss=0.2889293134212494
Test set avg_accuracy=82.47% avg_sensitivity=56.55%, avg_specificity=90.73% avg_auc=85.76%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.332495 Test loss=0.394734 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.32043007016181946
[5/23] Train loss=0.2994285821914673
[10/23] Train loss=0.36180195212364197
[15/23] Train loss=0.3264138102531433
[20/23] Train loss=0.29886847734451294
Test set avg_accuracy=83.07% avg_sensitivity=57.41%, avg_specificity=91.24% avg_auc=86.47%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.335093 Test loss=0.379785 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.3221341371536255
[5/23] Train loss=0.3092280924320221
[10/23] Train loss=0.37039071321487427
[15/23] Train loss=0.31394779682159424
[20/23] Train loss=0.29708823561668396
Test set avg_accuracy=83.87% avg_sensitivity=61.78%, avg_specificity=90.90% avg_auc=88.29%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.334671 Test loss=0.363625 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.3191100060939789
[5/23] Train loss=0.3097091317176819
[10/23] Train loss=0.36214423179626465
[15/23] Train loss=0.31634244322776794
[20/23] Train loss=0.29157310724258423
Test set avg_accuracy=82.83% avg_sensitivity=71.86%, avg_specificity=86.32% avg_auc=88.26%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.329582 Test loss=0.388204 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.3091396391391754
[5/23] Train loss=0.3086181879043579
[10/23] Train loss=0.38089630007743835
[15/23] Train loss=0.3150618374347687
[20/23] Train loss=0.30200183391571045
Test set avg_accuracy=82.75% avg_sensitivity=55.80%, avg_specificity=91.33% avg_auc=85.81%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.333395 Test loss=0.383839 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.32635608315467834
[5/23] Train loss=0.3032960593700409
[10/23] Train loss=0.3591836094856262
[15/23] Train loss=0.3094651699066162
[20/23] Train loss=0.2904817759990692
Test set avg_accuracy=81.43% avg_sensitivity=63.29%, avg_specificity=87.21% avg_auc=85.63%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.332234 Test loss=0.399301 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.31155821681022644
[5/23] Train loss=0.3011245131492615
[10/23] Train loss=0.36381059885025024
[15/23] Train loss=0.3052016794681549
[20/23] Train loss=0.28990575671195984
Test set avg_accuracy=82.60% avg_sensitivity=67.82%, avg_specificity=87.31% avg_auc=86.86%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.328170 Test loss=0.391326 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.3121507167816162
[5/23] Train loss=0.30130133032798767
[10/23] Train loss=0.36607107520103455
[15/23] Train loss=0.31279999017715454
[20/23] Train loss=0.29044896364212036
Test set avg_accuracy=82.40% avg_sensitivity=72.13%, avg_specificity=85.67% avg_auc=87.54%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.328948 Test loss=0.400216 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.31579893827438354
[5/23] Train loss=0.30438339710235596
[10/23] Train loss=0.3619290888309479
[15/23] Train loss=0.30878719687461853
[20/23] Train loss=0.2913164496421814
Test set avg_accuracy=81.97% avg_sensitivity=64.47%, avg_specificity=87.54% avg_auc=87.15%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.327770 Test loss=0.382015 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.3067531883716583
[5/23] Train loss=0.291403204202652
[10/23] Train loss=0.3646404445171356
[15/23] Train loss=0.3059660494327545
[20/23] Train loss=0.28990256786346436
Test set avg_accuracy=81.48% avg_sensitivity=65.93%, avg_specificity=86.44% avg_auc=84.57%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.325404 Test loss=0.419082 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.3039322793483734
[5/23] Train loss=0.2952820658683777
[10/23] Train loss=0.3616936206817627
[15/23] Train loss=0.302374005317688
[20/23] Train loss=0.28597530722618103
Test set avg_accuracy=82.01% avg_sensitivity=70.51%, avg_specificity=85.67% avg_auc=87.31%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.325247 Test loss=0.420010 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.3079339265823364
[5/23] Train loss=0.29653674364089966
[10/23] Train loss=0.3657212257385254
[15/23] Train loss=0.30698132514953613
[20/23] Train loss=0.2884218692779541
Test set avg_accuracy=84.05% avg_sensitivity=62.91%, avg_specificity=90.78% avg_auc=87.59%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.325832 Test loss=0.367150 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.3069848418235779
[5/23] Train loss=0.29890644550323486
[10/23] Train loss=0.3531375825405121
[15/23] Train loss=0.3054710030555725
[20/23] Train loss=0.28463777899742126
Test set avg_accuracy=83.97% avg_sensitivity=71.37%, avg_specificity=87.98% avg_auc=87.86%
Best model saved!! Metric=5.1854212397668675!!
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.322779 Test loss=0.373096 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.3094533383846283
[5/23] Train loss=0.2959407866001129
[10/23] Train loss=0.3581392168998718
[15/23] Train loss=0.3052617609500885
[20/23] Train loss=0.2831611633300781
Test set avg_accuracy=83.28% avg_sensitivity=70.13%, avg_specificity=87.47% avg_auc=87.61%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.322784 Test loss=0.380671 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.30118221044540405
[5/23] Train loss=0.2982458472251892
[10/23] Train loss=0.35488200187683105
[15/23] Train loss=0.31385329365730286
[20/23] Train loss=0.28679877519607544
Test set avg_accuracy=82.77% avg_sensitivity=58.01%, avg_specificity=90.66% avg_auc=85.91%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.320290 Test loss=0.388563 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.2984996438026428
[5/23] Train loss=0.2901793420314789
[10/23] Train loss=0.35122689604759216
[15/23] Train loss=0.2943513095378876
[20/23] Train loss=0.2813971936702728
Test set avg_accuracy=83.67% avg_sensitivity=56.44%, avg_specificity=92.34% avg_auc=87.66%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.316831 Test loss=0.368497 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.3067378103733063
[5/23] Train loss=0.28972551226615906
[10/23] Train loss=0.34644821286201477
[15/23] Train loss=0.3011171817779541
[20/23] Train loss=0.2913307249546051
Test set avg_accuracy=83.10% avg_sensitivity=48.79%, avg_specificity=94.03% avg_auc=86.24%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.314826 Test loss=0.380948 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.30127400159835815
[5/23] Train loss=0.2869040369987488
[10/23] Train loss=0.34639227390289307
[15/23] Train loss=0.2914205491542816
[20/23] Train loss=0.2828599810600281
Test set avg_accuracy=83.63% avg_sensitivity=60.86%, avg_specificity=90.88% avg_auc=86.06%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.314156 Test loss=0.385706 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.2964265048503876
[5/23] Train loss=0.28953102231025696
[10/23] Train loss=0.34396985173225403
[15/23] Train loss=0.3003070056438446
[20/23] Train loss=0.2866590619087219
Test set avg_accuracy=81.03% avg_sensitivity=72.35%, avg_specificity=83.79% avg_auc=86.42%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.314828 Test loss=0.418924 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.29985594749450684
[5/23] Train loss=0.28950944542884827
[10/23] Train loss=0.3372915983200073
[15/23] Train loss=0.30283254384994507
[20/23] Train loss=0.2793256938457489
Test set avg_accuracy=82.85% avg_sensitivity=62.96%, avg_specificity=89.18% avg_auc=87.49%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.314233 Test loss=0.371671 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.2974407970905304
[5/23] Train loss=0.2950695753097534
[10/23] Train loss=0.34609416127204895
[15/23] Train loss=0.3002775311470032
[20/23] Train loss=0.28591597080230713
Test set avg_accuracy=83.27% avg_sensitivity=55.96%, avg_specificity=91.97% avg_auc=86.27%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.315764 Test loss=0.382911 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.2965189218521118
[5/23] Train loss=0.27966827154159546
[10/23] Train loss=0.33590757846832275
[15/23] Train loss=0.30491867661476135
[20/23] Train loss=0.27263712882995605
Test set avg_accuracy=83.50% avg_sensitivity=47.12%, avg_specificity=95.09% avg_auc=85.53%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.309993 Test loss=0.396435 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.29078397154808044
[5/23] Train loss=0.2860432267189026
[10/23] Train loss=0.33959564566612244
[15/23] Train loss=0.2947681248188019
[20/23] Train loss=0.2801651656627655
Test set avg_accuracy=83.68% avg_sensitivity=55.15%, avg_specificity=92.77% avg_auc=87.02%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.308245 Test loss=0.370321 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.2883084714412689
[5/23] Train loss=0.2862280011177063
[10/23] Train loss=0.3522026836872101
[15/23] Train loss=0.2905522584915161
[20/23] Train loss=0.27525588870048523
Test set avg_accuracy=83.12% avg_sensitivity=59.84%, avg_specificity=90.54% avg_auc=86.92%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.306723 Test loss=0.383927 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.29350581765174866
[5/23] Train loss=0.2741192579269409
[10/23] Train loss=0.3343927562236786
[15/23] Train loss=0.2886120080947876
[20/23] Train loss=0.2786567211151123
Test set avg_accuracy=84.06% avg_sensitivity=64.31%, avg_specificity=90.35% avg_auc=87.63%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.305587 Test loss=0.371512 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.2855900526046753
[5/23] Train loss=0.2746500074863434
[10/23] Train loss=0.31857213377952576
[15/23] Train loss=0.29315295815467834
[20/23] Train loss=0.26691189408302307
Test set avg_accuracy=79.40% avg_sensitivity=67.22%, avg_specificity=83.28% avg_auc=82.76%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.302696 Test loss=0.449805 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.3015843331813812
[5/23] Train loss=0.27820631861686707
[10/23] Train loss=0.32145240902900696
[15/23] Train loss=0.3059152662754059
[20/23] Train loss=0.2673327326774597
Test set avg_accuracy=82.85% avg_sensitivity=47.22%, avg_specificity=94.20% avg_auc=84.69%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.303071 Test loss=0.397925 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.289163738489151
[5/23] Train loss=0.2739933729171753
[10/23] Train loss=0.3223794996738434
[15/23] Train loss=0.3031686246395111
[20/23] Train loss=0.2755836546421051
Test set avg_accuracy=81.88% avg_sensitivity=73.80%, avg_specificity=84.45% avg_auc=87.36%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.300898 Test loss=0.400404 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.29222384095191956
[5/23] Train loss=0.27366992831230164
[10/23] Train loss=0.32122188806533813
[15/23] Train loss=0.3012220561504364
[20/23] Train loss=0.27598217129707336
Test set avg_accuracy=83.58% avg_sensitivity=58.49%, avg_specificity=91.57% avg_auc=87.48%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.301646 Test loss=0.371874 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.2857327163219452
[5/23] Train loss=0.26995736360549927
[10/23] Train loss=0.3101804852485657
[15/23] Train loss=0.28102946281433105
[20/23] Train loss=0.266973614692688
Test set avg_accuracy=83.22% avg_sensitivity=46.95%, avg_specificity=94.76% avg_auc=85.86%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.296137 Test loss=0.394311 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.2700478732585907
[5/23] Train loss=0.2725105285644531
[10/23] Train loss=0.31468266248703003
[15/23] Train loss=0.283917635679245
[20/23] Train loss=0.2697448134422302
Test set avg_accuracy=83.49% avg_sensitivity=55.15%, avg_specificity=92.52% avg_auc=86.15%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.292984 Test loss=0.384157 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.2876074016094208
[5/23] Train loss=0.26466986536979675
[10/23] Train loss=0.34215572476387024
[15/23] Train loss=0.2883845269680023
[20/23] Train loss=0.2721426784992218
Test set avg_accuracy=78.76% avg_sensitivity=18.65%, avg_specificity=97.91% avg_auc=75.97%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.295962 Test loss=0.548195 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.2839374542236328
[5/23] Train loss=0.2884618937969208
[10/23] Train loss=0.3153432011604309
[15/23] Train loss=0.2860969603061676
[20/23] Train loss=0.252188503742218
Test set avg_accuracy=81.86% avg_sensitivity=65.61%, avg_specificity=87.04% avg_auc=85.46%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.293943 Test loss=0.402018 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.28182774782180786
[5/23] Train loss=0.26038047671318054
[10/23] Train loss=0.3121078908443451
[15/23] Train loss=0.2916701138019562
[20/23] Train loss=0.26288101077079773
Test set avg_accuracy=81.94% avg_sensitivity=50.19%, avg_specificity=92.05% avg_auc=83.81%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.292873 Test loss=0.409232 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.2654534876346588
[5/23] Train loss=0.2741994559764862
[10/23] Train loss=0.31399157643318176
[15/23] Train loss=0.27451464533805847
[20/23] Train loss=0.26542648673057556
Test set avg_accuracy=81.77% avg_sensitivity=48.89%, avg_specificity=92.24% avg_auc=82.60%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.291012 Test loss=0.415302 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.27461135387420654
[5/23] Train loss=0.2525571882724762
[10/23] Train loss=0.29971176385879517
[15/23] Train loss=0.2759246230125427
[20/23] Train loss=0.25411084294319153
Test set avg_accuracy=80.95% avg_sensitivity=38.38%, avg_specificity=94.51% avg_auc=82.55%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.287592 Test loss=0.434446 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.2626245319843292
[5/23] Train loss=0.2644985020160675
[10/23] Train loss=0.30871450901031494
[15/23] Train loss=0.28493207693099976
[20/23] Train loss=0.2553449273109436
Test set avg_accuracy=80.91% avg_sensitivity=40.16%, avg_specificity=93.89% avg_auc=80.58%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.286682 Test loss=0.444768 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.26976847648620605
[5/23] Train loss=0.2664817273616791
[10/23] Train loss=0.2987850308418274
[15/23] Train loss=0.2841397225856781
[20/23] Train loss=0.254146546125412
Test set avg_accuracy=81.54% avg_sensitivity=64.37%, avg_specificity=87.00% avg_auc=85.82%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.282727 Test loss=0.403861 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.25868046283721924
[5/23] Train loss=0.25142309069633484
[10/23] Train loss=0.2883799970149994
[15/23] Train loss=0.2875927686691284
[20/23] Train loss=0.26171451807022095
Test set avg_accuracy=81.02% avg_sensitivity=61.83%, avg_specificity=87.12% avg_auc=85.81%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.282123 Test loss=0.393341 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.2726820111274719
[5/23] Train loss=0.25888869166374207
[10/23] Train loss=0.29074186086654663
[15/23] Train loss=0.28693702816963196
[20/23] Train loss=0.25260424613952637
Test set avg_accuracy=81.04% avg_sensitivity=35.85%, avg_specificity=95.43% avg_auc=78.70%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.281422 Test loss=0.489011 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.2646762430667877
[5/23] Train loss=0.2532925605773926
[10/23] Train loss=0.27533194422721863
[15/23] Train loss=0.27408498525619507
[20/23] Train loss=0.25176700949668884
Test set avg_accuracy=82.76% avg_sensitivity=53.37%, avg_specificity=92.12% avg_auc=86.43%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.275981 Test loss=0.386579 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.26537981629371643
[5/23] Train loss=0.2444498986005783
[10/23] Train loss=0.2754994034767151
[15/23] Train loss=0.279879093170166
[20/23] Train loss=0.24540910124778748
Test set avg_accuracy=81.56% avg_sensitivity=42.64%, avg_specificity=93.96% avg_auc=83.27%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.273475 Test loss=0.434386 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.2635885179042816
[5/23] Train loss=0.24468787014484406
[10/23] Train loss=0.28246456384658813
[15/23] Train loss=0.2698207497596741
[20/23] Train loss=0.2471269965171814
Test set avg_accuracy=82.83% avg_sensitivity=57.74%, avg_specificity=90.82% avg_auc=86.45%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.270676 Test loss=0.383638 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.26040953397750854
[5/23] Train loss=0.24680033326148987
[10/23] Train loss=0.2816345989704132
[15/23] Train loss=0.2686540484428406
[20/23] Train loss=0.24830211699008942
Test set avg_accuracy=82.41% avg_sensitivity=58.76%, avg_specificity=89.94% avg_auc=85.59%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.268399 Test loss=0.394506 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.24408473074436188
[5/23] Train loss=0.2408372312784195
[10/23] Train loss=0.26775285601615906
[15/23] Train loss=0.2530929744243622
[20/23] Train loss=0.2357373684644699
Test set avg_accuracy=83.03% avg_sensitivity=65.01%, avg_specificity=88.77% avg_auc=87.05%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.264449 Test loss=0.382634 Current lr=[0.000112073915556435]

[0/23] Train loss=0.24442657828330994
[5/23] Train loss=0.24568688869476318
[10/23] Train loss=0.25704461336135864
[15/23] Train loss=0.25824838876724243
[20/23] Train loss=0.2498159259557724
Test set avg_accuracy=82.24% avg_sensitivity=51.27%, avg_specificity=92.10% avg_auc=83.64%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.261680 Test loss=0.412429 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.2500249743461609
[5/23] Train loss=0.22965334355831146
[10/23] Train loss=0.257768452167511
[15/23] Train loss=0.2510347366333008
[20/23] Train loss=0.23872631788253784
Test set avg_accuracy=82.40% avg_sensitivity=65.55%, avg_specificity=87.76% avg_auc=85.54%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.255990 Test loss=0.401595 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.23688434064388275
[5/23] Train loss=0.22470419108867645
[10/23] Train loss=0.2599228024482727
[15/23] Train loss=0.24966250360012054
[20/23] Train loss=0.23383790254592896
Test set avg_accuracy=82.79% avg_sensitivity=62.32%, avg_specificity=89.30% avg_auc=86.39%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.254738 Test loss=0.390326 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.23797135055065155
[5/23] Train loss=0.23186461627483368
[10/23] Train loss=0.24958686530590057
[15/23] Train loss=0.24295639991760254
[20/23] Train loss=0.2400461584329605
Test set avg_accuracy=81.65% avg_sensitivity=67.22%, avg_specificity=86.25% avg_auc=86.14%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.252160 Test loss=0.399233 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.24408020079135895
[5/23] Train loss=0.22213028371334076
[10/23] Train loss=0.2601723074913025
[15/23] Train loss=0.2430892437696457
[20/23] Train loss=0.2361157089471817
Test set avg_accuracy=81.99% avg_sensitivity=63.94%, avg_specificity=87.74% avg_auc=86.38%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.251844 Test loss=0.396298 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.23634129762649536
[5/23] Train loss=0.21714556217193604
[10/23] Train loss=0.2501707673072815
[15/23] Train loss=0.24425047636032104
[20/23] Train loss=0.2308933436870575
Test set avg_accuracy=79.83% avg_sensitivity=68.63%, avg_specificity=83.40% avg_auc=85.17%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.247847 Test loss=0.435777 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.2270815074443817
[5/23] Train loss=0.2226664274930954
[10/23] Train loss=0.2516898810863495
[15/23] Train loss=0.24285270273685455
[20/23] Train loss=0.2192455381155014
Test set avg_accuracy=81.24% avg_sensitivity=67.87%, avg_specificity=85.49% avg_auc=86.38%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.244489 Test loss=0.418407 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.23440469801425934
[5/23] Train loss=0.22217419743537903
[10/23] Train loss=0.252304345369339
[15/23] Train loss=0.2246178686618805
[20/23] Train loss=0.21313811838626862
Test set avg_accuracy=83.32% avg_sensitivity=62.43%, avg_specificity=89.97% avg_auc=86.44%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.239566 Test loss=0.389608 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.22224439680576324
[5/23] Train loss=0.2172696739435196
[10/23] Train loss=0.22958211600780487
[15/23] Train loss=0.23177333176136017
[20/23] Train loss=0.20502151548862457
Test set avg_accuracy=81.50% avg_sensitivity=64.91%, avg_specificity=86.78% avg_auc=85.97%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.235417 Test loss=0.411012 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.2242548167705536
[5/23] Train loss=0.20985175669193268
[10/23] Train loss=0.23034358024597168
[15/23] Train loss=0.22606231272220612
[20/23] Train loss=0.2129373401403427
Test set avg_accuracy=80.66% avg_sensitivity=69.33%, avg_specificity=84.27% avg_auc=85.71%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.231986 Test loss=0.424678 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.22216913104057312
[5/23] Train loss=0.21404807269573212
[10/23] Train loss=0.23275183141231537
[15/23] Train loss=0.22514355182647705
[20/23] Train loss=0.209181010723114
Test set avg_accuracy=81.81% avg_sensitivity=59.95%, avg_specificity=88.77% avg_auc=85.38%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.232953 Test loss=0.411885 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.21681934595108032
[5/23] Train loss=0.2026384174823761
[10/23] Train loss=0.22630493342876434
[15/23] Train loss=0.23203712701797485
[20/23] Train loss=0.21064619719982147
Test set avg_accuracy=81.97% avg_sensitivity=63.88%, avg_specificity=87.73% avg_auc=86.43%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.230284 Test loss=0.399479 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.21558928489685059
[5/23] Train loss=0.21219858527183533
[10/23] Train loss=0.22704479098320007
[15/23] Train loss=0.22887147963047028
[20/23] Train loss=0.21303795278072357
Test set avg_accuracy=82.30% avg_sensitivity=63.77%, avg_specificity=88.21% avg_auc=85.81%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.228312 Test loss=0.403444 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.21131448447704315
[5/23] Train loss=0.2125227153301239
[10/23] Train loss=0.22073253989219666
[15/23] Train loss=0.22423265874385834
[20/23] Train loss=0.20239309966564178
Test set avg_accuracy=81.16% avg_sensitivity=64.85%, avg_specificity=86.35% avg_auc=84.64%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.225685 Test loss=0.420428 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.21627674996852875
[5/23] Train loss=0.20373940467834473
[10/23] Train loss=0.23051297664642334
[15/23] Train loss=0.2126990109682083
[20/23] Train loss=0.20784948766231537
Test set avg_accuracy=81.54% avg_sensitivity=70.78%, avg_specificity=84.96% avg_auc=86.62%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.223514 Test loss=0.407797 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.20709238946437836
[5/23] Train loss=0.20269323885440826
[10/23] Train loss=0.21076753735542297
[15/23] Train loss=0.20865820348262787
[20/23] Train loss=0.20071029663085938
Test set avg_accuracy=81.98% avg_sensitivity=61.62%, avg_specificity=88.46% avg_auc=85.28%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.220068 Test loss=0.412069 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.2099982053041458
[5/23] Train loss=0.1962091475725174
[10/23] Train loss=0.22333283722400665
[15/23] Train loss=0.20708338916301727
[20/23] Train loss=0.19789230823516846
Test set avg_accuracy=82.10% avg_sensitivity=64.53%, avg_specificity=87.69% avg_auc=85.81%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.217852 Test loss=0.408006 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.20552624762058258
[5/23] Train loss=0.1920902132987976
[10/23] Train loss=0.21196642518043518
[15/23] Train loss=0.2109646499156952
[20/23] Train loss=0.19480092823505402
Test set avg_accuracy=82.71% avg_sensitivity=69.11%, avg_specificity=87.04% avg_auc=86.78%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.216007 Test loss=0.402228 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.19704946875572205
[5/23] Train loss=0.19935227930545807
[10/23] Train loss=0.20613029599189758
[15/23] Train loss=0.21655704081058502
[20/23] Train loss=0.19090932607650757
Test set avg_accuracy=82.21% avg_sensitivity=64.20%, avg_specificity=87.95% avg_auc=84.37%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.213264 Test loss=0.421510 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.19683372974395752
[5/23] Train loss=0.19798506796360016
[10/23] Train loss=0.2049449384212494
[15/23] Train loss=0.20728568732738495
[20/23] Train loss=0.18693633377552032
Test set avg_accuracy=82.79% avg_sensitivity=58.11%, avg_specificity=90.64% avg_auc=85.12%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.210994 Test loss=0.405586 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.1989368200302124
[5/23] Train loss=0.19199423491954803
[10/23] Train loss=0.20201659202575684
[15/23] Train loss=0.19491349160671234
[20/23] Train loss=0.1883857399225235
Test set avg_accuracy=82.62% avg_sensitivity=60.22%, avg_specificity=89.75% avg_auc=85.10%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.206984 Test loss=0.406252 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.18855230510234833
[5/23] Train loss=0.19304417073726654
[10/23] Train loss=0.20052479207515717
[15/23] Train loss=0.19950896501541138
[20/23] Train loss=0.18478699028491974
Test set avg_accuracy=83.01% avg_sensitivity=61.94%, avg_specificity=89.72% avg_auc=86.09%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.203853 Test loss=0.395518 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.200307235121727
[5/23] Train loss=0.18204930424690247
[10/23] Train loss=0.1938716024160385
[15/23] Train loss=0.19542935490608215
[20/23] Train loss=0.18211007118225098
Test set avg_accuracy=82.68% avg_sensitivity=60.00%, avg_specificity=89.91% avg_auc=85.02%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.202149 Test loss=0.410562 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.18772359192371368
[5/23] Train loss=0.18379704654216766
[10/23] Train loss=0.1913347691297531
[15/23] Train loss=0.193804532289505
[20/23] Train loss=0.18149656057357788
Test set avg_accuracy=82.76% avg_sensitivity=63.56%, avg_specificity=88.88% avg_auc=85.44%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.199172 Test loss=0.407544 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.19315336644649506
[5/23] Train loss=0.18266595900058746
[10/23] Train loss=0.1900213360786438
[15/23] Train loss=0.18805497884750366
[20/23] Train loss=0.18066848814487457
Test set avg_accuracy=82.96% avg_sensitivity=63.13%, avg_specificity=89.27% avg_auc=85.92%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.198453 Test loss=0.401982 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.18390487134456635
[5/23] Train loss=0.17440688610076904
[10/23] Train loss=0.18709419667720795
[15/23] Train loss=0.18559391796588898
[20/23] Train loss=0.17504136264324188
Test set avg_accuracy=82.02% avg_sensitivity=61.78%, avg_specificity=88.46% avg_auc=85.32%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.196546 Test loss=0.414029 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.18688510358333588
[5/23] Train loss=0.18244415521621704
[10/23] Train loss=0.19124311208724976
[15/23] Train loss=0.18652042746543884
[20/23] Train loss=0.17935383319854736
Test set avg_accuracy=82.17% avg_sensitivity=63.67%, avg_specificity=88.07% avg_auc=85.93%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.195723 Test loss=0.408111 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.17774419486522675
[5/23] Train loss=0.17779415845870972
[10/23] Train loss=0.18726766109466553
[15/23] Train loss=0.18560661375522614
[20/23] Train loss=0.16770634055137634
Test set avg_accuracy=83.22% avg_sensitivity=62.05%, avg_specificity=89.96% avg_auc=85.57%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.194097 Test loss=0.403311 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.17882707715034485
[5/23] Train loss=0.17537569999694824
[10/23] Train loss=0.18955574929714203
[15/23] Train loss=0.18761104345321655
[20/23] Train loss=0.17380857467651367
Test set avg_accuracy=83.35% avg_sensitivity=63.07%, avg_specificity=89.80% avg_auc=85.83%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.193673 Test loss=0.402973 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.18147209286689758
[5/23] Train loss=0.1757136434316635
[10/23] Train loss=0.18808512389659882
[15/23] Train loss=0.18510335683822632
[20/23] Train loss=0.17578494548797607
Test set avg_accuracy=82.59% avg_sensitivity=62.75%, avg_specificity=88.91% avg_auc=85.81%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.191556 Test loss=0.405234 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.1804332137107849
[5/23] Train loss=0.17765380442142487
[10/23] Train loss=0.1865728795528412
[15/23] Train loss=0.1803288608789444
[20/23] Train loss=0.16875188052654266
Test set avg_accuracy=82.66% avg_sensitivity=61.94%, avg_specificity=89.25% avg_auc=85.48%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.190638 Test loss=0.405355 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.17557795345783234
[5/23] Train loss=0.17720791697502136
[10/23] Train loss=0.18791794776916504
[15/23] Train loss=0.1820066273212433
[20/23] Train loss=0.17413200438022614
Test set avg_accuracy=82.85% avg_sensitivity=62.91%, avg_specificity=89.20% avg_auc=85.83%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.190810 Test loss=0.405785 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.1761777549982071
[5/23] Train loss=0.17290551960468292
[10/23] Train loss=0.1871347874403
[15/23] Train loss=0.17813734710216522
[20/23] Train loss=0.16783255338668823
Test set avg_accuracy=82.99% avg_sensitivity=61.78%, avg_specificity=89.75% avg_auc=85.68%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.188704 Test loss=0.405283 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.1774214655160904
[5/23] Train loss=0.17509852349758148
[10/23] Train loss=0.18276138603687286
[15/23] Train loss=0.1804298311471939
[20/23] Train loss=0.1731754094362259
Test set avg_accuracy=82.84% avg_sensitivity=61.99%, avg_specificity=89.48% avg_auc=85.97%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.188431 Test loss=0.402598 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.17675335705280304
[5/23] Train loss=0.16911135613918304
[10/23] Train loss=0.19114063680171967
[15/23] Train loss=0.18521691858768463
[20/23] Train loss=0.16809344291687012
Test set avg_accuracy=82.97% avg_sensitivity=61.94%, avg_specificity=89.67% avg_auc=85.94%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.188973 Test loss=0.402084 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.17920061945915222
[5/23] Train loss=0.1778964102268219
[10/23] Train loss=0.18203513324260712
[15/23] Train loss=0.18011562526226044
[20/23] Train loss=0.16970603168010712
Test set avg_accuracy=83.02% avg_sensitivity=62.75%, avg_specificity=89.48% avg_auc=85.97%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.188443 Test loss=0.403622 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.17347435653209686
[5/23] Train loss=0.17375952005386353
[10/23] Train loss=0.17690981924533844
[15/23] Train loss=0.17582182586193085
[20/23] Train loss=0.16867147386074066
Test set avg_accuracy=82.81% avg_sensitivity=62.32%, avg_specificity=89.34% avg_auc=85.91%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.187177 Test loss=0.404214 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.17242956161499023
[5/23] Train loss=0.17514795064926147
[10/23] Train loss=0.18207526206970215
[15/23] Train loss=0.17807255685329437
[20/23] Train loss=0.1685759574174881
Test set avg_accuracy=82.84% avg_sensitivity=62.32%, avg_specificity=89.37% avg_auc=85.78%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.187422 Test loss=0.405463 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.18181073665618896
[5/23] Train loss=0.16925425827503204
[10/23] Train loss=0.18603718280792236
[15/23] Train loss=0.18111729621887207
[20/23] Train loss=0.16665399074554443
Test set avg_accuracy=82.81% avg_sensitivity=62.32%, avg_specificity=89.34% avg_auc=85.84%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.188241 Test loss=0.405564 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.16806085407733917
[5/23] Train loss=0.16790740191936493
[10/23] Train loss=0.18001466989517212
[15/23] Train loss=0.17482532560825348
[20/23] Train loss=0.1679467409849167
Test set avg_accuracy=82.77% avg_sensitivity=62.21%, avg_specificity=89.32% avg_auc=85.83%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.185173 Test loss=0.404577 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.1740141659975052
[5/23] Train loss=0.1704634726047516
[10/23] Train loss=0.18139322102069855
[15/23] Train loss=0.1752217710018158
[20/23] Train loss=0.16879861056804657
Test set avg_accuracy=82.76% avg_sensitivity=62.32%, avg_specificity=89.27% avg_auc=85.86%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.186000 Test loss=0.404474 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.1723492592573166
[5/23] Train loss=0.1735883206129074
[10/23] Train loss=0.17885953187942505
[15/23] Train loss=0.18079419434070587
[20/23] Train loss=0.16833512485027313
Test set avg_accuracy=82.81% avg_sensitivity=62.32%, avg_specificity=89.34% avg_auc=85.87%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.186260 Test loss=0.404210 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.17669539153575897
[5/23] Train loss=0.17082011699676514
[10/23] Train loss=0.18336239457130432
[15/23] Train loss=0.17427140474319458
[20/23] Train loss=0.16969457268714905
Test set avg_accuracy=82.81% avg_sensitivity=62.53%, avg_specificity=89.27% avg_auc=85.88%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.186216 Test loss=0.404067 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.17170487344264984
[5/23] Train loss=0.16751885414123535
[10/23] Train loss=0.17824772000312805
[15/23] Train loss=0.180870920419693
[20/23] Train loss=0.16817142069339752
Test set avg_accuracy=82.76% avg_sensitivity=62.37%, avg_specificity=89.25% avg_auc=85.88%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.186443 Test loss=0.403960 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=83.97% sen=71.37%, spe=87.98%, auc=87.86%!
Fold[9] Avg_overlap=0.60%(0.2677091943757404)
[0/24] Train loss=0.7353751063346863
[5/24] Train loss=0.7199137806892395
[10/24] Train loss=0.7157037258148193
[15/24] Train loss=0.7124703526496887
[20/24] Train loss=0.7159086465835571
Test set avg_accuracy=59.91% avg_sensitivity=42.18%, avg_specificity=65.05% avg_auc=54.89%
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.716461 Test loss=0.675293 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7019413113594055
[5/24] Train loss=0.7002913951873779
[10/24] Train loss=0.7039896845817566
[15/24] Train loss=0.6925055980682373
[20/24] Train loss=0.683918833732605
Test set avg_accuracy=65.23% avg_sensitivity=46.52%, avg_specificity=70.66% avg_auc=62.46%
Best model saved!! Metric=-81.1240381489352!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.697033 Test loss=0.633624 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6879506707191467
[5/24] Train loss=0.683840274810791
[10/24] Train loss=0.6812863945960999
[15/24] Train loss=0.6709921956062317
[20/24] Train loss=0.6654601693153381
Test set avg_accuracy=66.54% avg_sensitivity=50.17%, avg_specificity=71.28% avg_auc=67.24%
Best model saved!! Metric=-70.7685603284736!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.679483 Test loss=0.615530 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6695952415466309
[5/24] Train loss=0.6691687107086182
[10/24] Train loss=0.6585374474525452
[15/24] Train loss=0.6576496958732605
[20/24] Train loss=0.6498790979385376
Test set avg_accuracy=68.06% avg_sensitivity=54.81%, avg_specificity=71.90% avg_auc=70.41%
Best model saved!! Metric=-60.81965464851845!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.661578 Test loss=0.599246 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6413373351097107
[5/24] Train loss=0.6449905633926392
[10/24] Train loss=0.6423240900039673
[15/24] Train loss=0.6391212344169617
[20/24] Train loss=0.6309161186218262
Test set avg_accuracy=69.92% avg_sensitivity=61.18%, avg_specificity=72.46% avg_auc=73.37%
Best model saved!! Metric=-49.067589223784424!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.642225 Test loss=0.581586 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6256009936332703
[5/24] Train loss=0.6327477097511292
[10/24] Train loss=0.6248126029968262
[15/24] Train loss=0.6173619031906128
[20/24] Train loss=0.6069855093955994
Test set avg_accuracy=71.84% avg_sensitivity=63.62%, avg_specificity=74.22% avg_auc=76.18%
Best model saved!! Metric=-40.152609883941246!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.621209 Test loss=0.560853 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6075053215026855
[5/24] Train loss=0.6074210405349731
[10/24] Train loss=0.6037918329238892
[15/24] Train loss=0.5916927456855774
[20/24] Train loss=0.5765706896781921
Test set avg_accuracy=73.41% avg_sensitivity=68.08%, avg_specificity=74.96% avg_auc=78.63%
Best model saved!! Metric=-30.925553582276137!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.598086 Test loss=0.548133 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5760461091995239
[5/24] Train loss=0.5861964225769043
[10/24] Train loss=0.5785182118415833
[15/24] Train loss=0.5683492422103882
[20/24] Train loss=0.5514426231384277
Test set avg_accuracy=74.93% avg_sensitivity=71.32%, avg_specificity=75.98% avg_auc=81.13%
Best model saved!! Metric=-22.633308993864446!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.571672 Test loss=0.522760 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5518114566802979
[5/24] Train loss=0.5628029108047485
[10/24] Train loss=0.5508332252502441
[15/24] Train loss=0.536753237247467
[20/24] Train loss=0.5236693620681763
Test set avg_accuracy=78.11% avg_sensitivity=71.15%, avg_specificity=80.13% avg_auc=83.60%
Best model saved!! Metric=-13.006449061179794!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.544045 Test loss=0.480112 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.530870795249939
[5/24] Train loss=0.528688371181488
[10/24] Train loss=0.52078777551651
[15/24] Train loss=0.5078229904174805
[20/24] Train loss=0.4916323721408844
Test set avg_accuracy=79.79% avg_sensitivity=70.86%, avg_specificity=82.38% avg_auc=85.21%
Best model saved!! Metric=-7.76401846044341!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.518691 Test loss=0.450217 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.505623996257782
[5/24] Train loss=0.49814921617507935
[10/24] Train loss=0.49823319911956787
[15/24] Train loss=0.48638492822647095
[20/24] Train loss=0.46532097458839417
Test set avg_accuracy=81.17% avg_sensitivity=71.03%, avg_specificity=84.11% avg_auc=86.28%
Best model saved!! Metric=-3.401842543266241!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.495220 Test loss=0.425436 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.48485809564590454
[5/24] Train loss=0.484126478433609
[10/24] Train loss=0.47630536556243896
[15/24] Train loss=0.4646835923194885
[20/24] Train loss=0.45108193159103394
Test set avg_accuracy=82.12% avg_sensitivity=71.03%, avg_specificity=85.34% avg_auc=87.24%
Best model saved!! Metric=-0.2657942730480869!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.475274 Test loss=0.409971 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.471145898103714
[5/24] Train loss=0.4605146050453186
[10/24] Train loss=0.4577086567878723
[15/24] Train loss=0.44651415944099426
[20/24] Train loss=0.43082836270332336
Test set avg_accuracy=82.53% avg_sensitivity=71.32%, avg_specificity=85.77% avg_auc=87.88%
Best model saved!! Metric=1.5061926971043533!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.456862 Test loss=0.392206 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4573209285736084
[5/24] Train loss=0.4471326172351837
[10/24] Train loss=0.4408246576786041
[15/24] Train loss=0.4282517433166504
[20/24] Train loss=0.41815900802612305
Test set avg_accuracy=83.36% avg_sensitivity=69.87%, avg_specificity=87.27% avg_auc=88.52%
Best model saved!! Metric=3.0176196886150564!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.443078 Test loss=0.374604 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4407540261745453
[5/24] Train loss=0.4294608533382416
[10/24] Train loss=0.43571925163269043
[15/24] Train loss=0.4113507568836212
[20/24] Train loss=0.4091908931732178
Test set avg_accuracy=83.53% avg_sensitivity=69.18%, avg_specificity=87.69% avg_auc=88.57%
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.429758 Test loss=0.368897 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4366776943206787
[5/24] Train loss=0.4144846498966217
[10/24] Train loss=0.4217832386493683
[15/24] Train loss=0.40856510400772095
[20/24] Train loss=0.39707693457603455
Test set avg_accuracy=83.92% avg_sensitivity=66.80%, avg_specificity=88.88% avg_auc=89.00%
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.421261 Test loss=0.351405 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.423721045255661
[5/24] Train loss=0.4070379436016083
[10/24] Train loss=0.40846556425094604
[15/24] Train loss=0.3948175311088562
[20/24] Train loss=0.3849658668041229
Test set avg_accuracy=84.32% avg_sensitivity=64.54%, avg_specificity=90.06% avg_auc=89.22%
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.411677 Test loss=0.342223 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.41639789938926697
[5/24] Train loss=0.39837515354156494
[10/24] Train loss=0.40457847714424133
[15/24] Train loss=0.390291303396225
[20/24] Train loss=0.3825628459453583
Test set avg_accuracy=84.40% avg_sensitivity=69.64%, avg_specificity=88.68% avg_auc=89.66%
Best model saved!! Metric=6.377231077098372!!
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.405575 Test loss=0.342543 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4087129235267639
[5/24] Train loss=0.3890586495399475
[10/24] Train loss=0.39662379026412964
[15/24] Train loss=0.3817387819290161
[20/24] Train loss=0.3741012215614319
Test set avg_accuracy=84.38% avg_sensitivity=69.81%, avg_specificity=88.60% avg_auc=89.66%
Best model saved!! Metric=6.4481183180747195!!
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.398073 Test loss=0.341171 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4041706919670105
[5/24] Train loss=0.39121198654174805
[10/24] Train loss=0.3894014060497284
[15/24] Train loss=0.3717186450958252
[20/24] Train loss=0.36892402172088623
Test set avg_accuracy=84.27% avg_sensitivity=71.67%, avg_specificity=87.92% avg_auc=89.97%
Best model saved!! Metric=7.82932074804738!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.393814 Test loss=0.344811 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.40679335594177246
[5/24] Train loss=0.3782504200935364
[10/24] Train loss=0.3921348750591278
[15/24] Train loss=0.36893826723098755
[20/24] Train loss=0.36646685004234314
Test set avg_accuracy=84.62% avg_sensitivity=70.97%, avg_specificity=88.58% avg_auc=90.12%
Best model saved!! Metric=8.297322491984374!!
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.388324 Test loss=0.339851 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.4023267328739166
[5/24] Train loss=0.375613272190094
[10/24] Train loss=0.3815420866012573
[15/24] Train loss=0.3695013225078583
[20/24] Train loss=0.3605461120605469
Test set avg_accuracy=84.77% avg_sensitivity=68.71%, avg_specificity=89.42% avg_auc=90.10%
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.385053 Test loss=0.337551 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.39861103892326355
[5/24] Train loss=0.37151050567626953
[10/24] Train loss=0.38611143827438354
[15/24] Train loss=0.3602808713912964
[20/24] Train loss=0.3570004105567932
Test set avg_accuracy=84.71% avg_sensitivity=69.58%, avg_specificity=89.10% avg_auc=90.22%
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.381468 Test loss=0.337450 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.39815524220466614
[5/24] Train loss=0.367009699344635
[10/24] Train loss=0.3793421685695648
[15/24] Train loss=0.3587523102760315
[20/24] Train loss=0.35542020201683044
Test set avg_accuracy=84.95% avg_sensitivity=65.99%, avg_specificity=90.44% avg_auc=90.02%
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.377845 Test loss=0.334034 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.38482406735420227
[5/24] Train loss=0.36842086911201477
[10/24] Train loss=0.3790092170238495
[15/24] Train loss=0.3495774567127228
[20/24] Train loss=0.35559776425361633
Test set avg_accuracy=85.64% avg_sensitivity=57.18%, avg_specificity=93.89% avg_auc=90.47%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.374449 Test loss=0.321339 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3877195417881012
[5/24] Train loss=0.3567516803741455
[10/24] Train loss=0.3702295422554016
[15/24] Train loss=0.35558271408081055
[20/24] Train loss=0.35125377774238586
Test set avg_accuracy=85.74% avg_sensitivity=65.18%, avg_specificity=91.70% avg_auc=90.54%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.372808 Test loss=0.320244 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.38745221495628357
[5/24] Train loss=0.35589152574539185
[10/24] Train loss=0.3714160621166229
[15/24] Train loss=0.3533192574977875
[20/24] Train loss=0.35090959072113037
Test set avg_accuracy=85.68% avg_sensitivity=65.87%, avg_specificity=91.42% avg_auc=90.07%
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.370177 Test loss=0.335039 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.38814789056777954
[5/24] Train loss=0.35977625846862793
[10/24] Train loss=0.3710159361362457
[15/24] Train loss=0.3487946093082428
[20/24] Train loss=0.34044745564460754
Test set avg_accuracy=85.66% avg_sensitivity=63.79%, avg_specificity=92.01% avg_auc=90.03%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.368180 Test loss=0.334216 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3908231556415558
[5/24] Train loss=0.3563082814216614
[10/24] Train loss=0.3623455762863159
[15/24] Train loss=0.3480406105518341
[20/24] Train loss=0.3424973487854004
Test set avg_accuracy=85.01% avg_sensitivity=46.35%, avg_specificity=96.22% avg_auc=90.09%
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.367420 Test loss=0.333722 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.38559025526046753
[5/24] Train loss=0.3498421311378479
[10/24] Train loss=0.3624330759048462
[15/24] Train loss=0.34321218729019165
[20/24] Train loss=0.3418899178504944
Test set avg_accuracy=85.10% avg_sensitivity=48.67%, avg_specificity=95.67% avg_auc=90.03%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.366602 Test loss=0.332295 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.38079628348350525
[5/24] Train loss=0.3528563976287842
[10/24] Train loss=0.3633519113063812
[15/24] Train loss=0.3367331326007843
[20/24] Train loss=0.3382449448108673
Test set avg_accuracy=85.23% avg_sensitivity=49.94%, avg_specificity=95.47% avg_auc=90.28%
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.363573 Test loss=0.325116 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.37256738543510437
[5/24] Train loss=0.34456050395965576
[10/24] Train loss=0.35511869192123413
[15/24] Train loss=0.3376907408237457
[20/24] Train loss=0.3387547433376312
Test set avg_accuracy=83.83% avg_sensitivity=41.25%, avg_specificity=96.17% avg_auc=89.80%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.360975 Test loss=0.339551 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.37592577934265137
[5/24] Train loss=0.3538159430027008
[10/24] Train loss=0.3617194592952728
[15/24] Train loss=0.338641494512558
[20/24] Train loss=0.3364422619342804
Test set avg_accuracy=83.92% avg_sensitivity=39.51%, avg_specificity=96.79% avg_auc=89.82%
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.362395 Test loss=0.344404 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3762575387954712
[5/24] Train loss=0.3516135811805725
[10/24] Train loss=0.3490714430809021
[15/24] Train loss=0.3433323800563812
[20/24] Train loss=0.33795472979545593
Test set avg_accuracy=80.48% avg_sensitivity=16.98%, avg_specificity=98.89% avg_auc=87.90%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.359965 Test loss=0.399153 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3832170367240906
[5/24] Train loss=0.35655099153518677
[10/24] Train loss=0.35774892568588257
[15/24] Train loss=0.33666878938674927
[20/24] Train loss=0.33733758330345154
Test set avg_accuracy=84.48% avg_sensitivity=44.79%, avg_specificity=95.99% avg_auc=89.85%
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.361653 Test loss=0.337058 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3686656653881073
[5/24] Train loss=0.352733314037323
[10/24] Train loss=0.35743463039398193
[15/24] Train loss=0.338052898645401
[20/24] Train loss=0.33429989218711853
Test set avg_accuracy=83.09% avg_sensitivity=32.79%, avg_specificity=97.67% avg_auc=89.02%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.361970 Test loss=0.357414 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.360629141330719
[5/24] Train loss=0.34970152378082275
[10/24] Train loss=0.35286659002304077
[15/24] Train loss=0.33937615156173706
[20/24] Train loss=0.3353917598724365
Test set avg_accuracy=83.52% avg_sensitivity=41.19%, avg_specificity=95.78% avg_auc=88.03%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.359166 Test loss=0.357664 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.37511909008026123
[5/24] Train loss=0.355104923248291
[10/24] Train loss=0.3464227318763733
[15/24] Train loss=0.33639439940452576
[20/24] Train loss=0.32971271872520447
Test set avg_accuracy=85.01% avg_sensitivity=50.00%, avg_specificity=95.16% avg_auc=90.13%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.358045 Test loss=0.340828 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3579855263233185
[5/24] Train loss=0.3522173762321472
[10/24] Train loss=0.3541751503944397
[15/24] Train loss=0.3344549536705017
[20/24] Train loss=0.3314547538757324
Test set avg_accuracy=85.57% avg_sensitivity=55.56%, avg_specificity=94.27% avg_auc=90.44%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.356638 Test loss=0.317731 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.36812523007392883
[5/24] Train loss=0.3421507775783539
[10/24] Train loss=0.3439142405986786
[15/24] Train loss=0.3471992015838623
[20/24] Train loss=0.33286064863204956
Test set avg_accuracy=79.84% avg_sensitivity=14.02%, avg_specificity=98.93% avg_auc=85.74%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.356159 Test loss=0.434924 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3602924644947052
[5/24] Train loss=0.34641948342323303
[10/24] Train loss=0.3516358733177185
[15/24] Train loss=0.3405087888240814
[20/24] Train loss=0.33319035172462463
Test set avg_accuracy=84.70% avg_sensitivity=47.57%, avg_specificity=95.47% avg_auc=89.12%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.356109 Test loss=0.343916 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.36241015791893005
[5/24] Train loss=0.3469628095626831
[10/24] Train loss=0.3587108254432678
[15/24] Train loss=0.33827847242355347
[20/24] Train loss=0.33371612429618835
Test set avg_accuracy=85.07% avg_sensitivity=52.78%, avg_specificity=94.42% avg_auc=89.80%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.356560 Test loss=0.334248 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3544512689113617
[5/24] Train loss=0.3452719748020172
[10/24] Train loss=0.3547213077545166
[15/24] Train loss=0.3307555019855499
[20/24] Train loss=0.33080244064331055
Test set avg_accuracy=84.58% avg_sensitivity=51.68%, avg_specificity=94.12% avg_auc=89.41%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.352703 Test loss=0.336806 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.35136422514915466
[5/24] Train loss=0.3435252010822296
[10/24] Train loss=0.3541296124458313
[15/24] Train loss=0.33716559410095215
[20/24] Train loss=0.3295780122280121
Test set avg_accuracy=83.91% avg_sensitivity=37.95%, avg_specificity=97.23% avg_auc=87.58%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.352648 Test loss=0.367753 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3535328805446625
[5/24] Train loss=0.3391439616680145
[10/24] Train loss=0.35687005519866943
[15/24] Train loss=0.33346521854400635
[20/24] Train loss=0.32796740531921387
Test set avg_accuracy=85.39% avg_sensitivity=53.24%, avg_specificity=94.71% avg_auc=90.48%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.353553 Test loss=0.328042 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3545607328414917
[5/24] Train loss=0.3300290107727051
[10/24] Train loss=0.3464123606681824
[15/24] Train loss=0.3259788155555725
[20/24] Train loss=0.3306732177734375
Test set avg_accuracy=80.98% avg_sensitivity=22.65%, avg_specificity=97.88% avg_auc=86.14%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.348574 Test loss=0.407110 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3549293577671051
[5/24] Train loss=0.34324750304222107
[10/24] Train loss=0.355465829372406
[15/24] Train loss=0.3408564627170563
[20/24] Train loss=0.32742658257484436
Test set avg_accuracy=84.74% avg_sensitivity=46.87%, avg_specificity=95.72% avg_auc=88.73%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.351708 Test loss=0.340910 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3536630868911743
[5/24] Train loss=0.3415146470069885
[10/24] Train loss=0.34349873661994934
[15/24] Train loss=0.33398962020874023
[20/24] Train loss=0.32607150077819824
Test set avg_accuracy=84.05% avg_sensitivity=45.94%, avg_specificity=95.10% avg_auc=87.14%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.348815 Test loss=0.358945 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.35703176259994507
[5/24] Train loss=0.33798107504844666
[10/24] Train loss=0.3458130657672882
[15/24] Train loss=0.325813353061676
[20/24] Train loss=0.3295919895172119
Test set avg_accuracy=84.23% avg_sensitivity=42.06%, avg_specificity=96.46% avg_auc=90.20%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.350518 Test loss=0.334914 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3510505259037018
[5/24] Train loss=0.3401434123516083
[10/24] Train loss=0.34475091099739075
[15/24] Train loss=0.3272259831428528
[20/24] Train loss=0.3290315270423889
Test set avg_accuracy=85.60% avg_sensitivity=61.01%, avg_specificity=92.73% avg_auc=90.19%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.346689 Test loss=0.324204 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3522685468196869
[5/24] Train loss=0.33248820900917053
[10/24] Train loss=0.34632551670074463
[15/24] Train loss=0.32926052808761597
[20/24] Train loss=0.3252013027667999
Test set avg_accuracy=84.04% avg_sensitivity=40.56%, avg_specificity=96.64% avg_auc=88.33%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.349090 Test loss=0.356860 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3598926067352295
[5/24] Train loss=0.34055233001708984
[10/24] Train loss=0.340136855840683
[15/24] Train loss=0.3217381238937378
[20/24] Train loss=0.327696830034256
Test set avg_accuracy=85.42% avg_sensitivity=62.40%, avg_specificity=92.09% avg_auc=89.70%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.347778 Test loss=0.338052 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.34784290194511414
[5/24] Train loss=0.33409571647644043
[10/24] Train loss=0.329880028963089
[15/24] Train loss=0.31885018944740295
[20/24] Train loss=0.32069915533065796
Test set avg_accuracy=84.87% avg_sensitivity=50.64%, avg_specificity=94.79% avg_auc=89.34%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.344527 Test loss=0.340190 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3499476909637451
[5/24] Train loss=0.3410569429397583
[10/24] Train loss=0.3376065492630005
[15/24] Train loss=0.3177408277988434
[20/24] Train loss=0.3296579420566559
Test set avg_accuracy=82.57% avg_sensitivity=64.77%, avg_specificity=87.72% avg_auc=85.47%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.345236 Test loss=0.443300 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.360334575176239
[5/24] Train loss=0.3347066342830658
[10/24] Train loss=0.3310019373893738
[15/24] Train loss=0.31806495785713196
[20/24] Train loss=0.33463403582572937
Test set avg_accuracy=84.58% avg_sensitivity=67.32%, avg_specificity=89.59% avg_auc=88.44%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.344671 Test loss=0.371097 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3472411632537842
[5/24] Train loss=0.3308555483818054
[10/24] Train loss=0.3328315317630768
[15/24] Train loss=0.3225766718387604
[20/24] Train loss=0.3202972114086151
Test set avg_accuracy=80.91% avg_sensitivity=75.61%, avg_specificity=82.45% avg_auc=86.30%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.344111 Test loss=0.449384 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3458850681781769
[5/24] Train loss=0.32572951912879944
[10/24] Train loss=0.3386956453323364
[15/24] Train loss=0.31208544969558716
[20/24] Train loss=0.3211017847061157
Test set avg_accuracy=85.62% avg_sensitivity=68.89%, avg_specificity=90.48% avg_auc=89.80%
Best model saved!! Metric=8.784722414136027!!
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.341348 Test loss=0.340722 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3462030589580536
[5/24] Train loss=0.32983437180519104
[10/24] Train loss=0.3386073410511017
[15/24] Train loss=0.31729671359062195
[20/24] Train loss=0.3127279579639435
Test set avg_accuracy=84.28% avg_sensitivity=63.73%, avg_specificity=90.24% avg_auc=88.92%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.339798 Test loss=0.363189 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3446333110332489
[5/24] Train loss=0.32073092460632324
[10/24] Train loss=0.33137479424476624
[15/24] Train loss=0.31791722774505615
[20/24] Train loss=0.32584333419799805
Test set avg_accuracy=85.23% avg_sensitivity=52.26%, avg_specificity=94.79% avg_auc=89.46%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.337445 Test loss=0.337072 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3385336697101593
[5/24] Train loss=0.32462769746780396
[10/24] Train loss=0.32877588272094727
[15/24] Train loss=0.32005801796913147
[20/24] Train loss=0.32726460695266724
Test set avg_accuracy=85.64% avg_sensitivity=60.20%, avg_specificity=93.01% avg_auc=89.59%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.338269 Test loss=0.330907 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.33982139825820923
[5/24] Train loss=0.32186728715896606
[10/24] Train loss=0.3418675363063812
[15/24] Train loss=0.3204561471939087
[20/24] Train loss=0.3149425685405731
Test set avg_accuracy=84.57% avg_sensitivity=46.99%, avg_specificity=95.47% avg_auc=89.00%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.337682 Test loss=0.345436 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3405376970767975
[5/24] Train loss=0.3178025782108307
[10/24] Train loss=0.3241384029388428
[15/24] Train loss=0.31635260581970215
[20/24] Train loss=0.31554847955703735
Test set avg_accuracy=83.84% avg_sensitivity=44.67%, avg_specificity=95.20% avg_auc=88.10%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.334749 Test loss=0.354625 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.33704835176467896
[5/24] Train loss=0.32185131311416626
[10/24] Train loss=0.322177529335022
[15/24] Train loss=0.31096187233924866
[20/24] Train loss=0.3183920681476593
Test set avg_accuracy=84.62% avg_sensitivity=65.41%, avg_specificity=90.19% avg_auc=88.59%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.332378 Test loss=0.356000 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3412974774837494
[5/24] Train loss=0.32662758231163025
[10/24] Train loss=0.3356090188026428
[15/24] Train loss=0.31699976325035095
[20/24] Train loss=0.32857316732406616
Test set avg_accuracy=82.85% avg_sensitivity=32.16%, avg_specificity=97.55% avg_auc=86.66%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.338705 Test loss=0.376857 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3460569977760315
[5/24] Train loss=0.3190052807331085
[10/24] Train loss=0.33888792991638184
[15/24] Train loss=0.304839164018631
[20/24] Train loss=0.3211963176727295
Test set avg_accuracy=83.09% avg_sensitivity=35.81%, avg_specificity=96.79% avg_auc=87.53%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.334881 Test loss=0.364924 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3319609463214874
[5/24] Train loss=0.3251040279865265
[10/24] Train loss=0.3345749080181122
[15/24] Train loss=0.3112935423851013
[20/24] Train loss=0.3283822536468506
Test set avg_accuracy=86.21% avg_sensitivity=64.89%, avg_specificity=92.39% avg_auc=89.26%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.334568 Test loss=0.354695 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.34445032477378845
[5/24] Train loss=0.3101647198200226
[10/24] Train loss=0.3301869034767151
[15/24] Train loss=0.30792292952537537
[20/24] Train loss=0.32062476873397827
Test set avg_accuracy=84.06% avg_sensitivity=47.51%, avg_specificity=94.66% avg_auc=88.52%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.331604 Test loss=0.352831 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3461001217365265
[5/24] Train loss=0.31444185972213745
[10/24] Train loss=0.3230731189250946
[15/24] Train loss=0.3113783597946167
[20/24] Train loss=0.3164139986038208
Test set avg_accuracy=84.69% avg_sensitivity=46.12%, avg_specificity=95.87% avg_auc=90.41%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.332270 Test loss=0.327905 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3358360528945923
[5/24] Train loss=0.31621870398521423
[10/24] Train loss=0.3195137083530426
[15/24] Train loss=0.30993467569351196
[20/24] Train loss=0.3271588683128357
Test set avg_accuracy=83.50% avg_sensitivity=56.95%, avg_specificity=91.20% avg_auc=88.01%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.329207 Test loss=0.355067 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3337962031364441
[5/24] Train loss=0.31336042284965515
[10/24] Train loss=0.32152310013771057
[15/24] Train loss=0.3069952726364136
[20/24] Train loss=0.31808364391326904
Test set avg_accuracy=81.51% avg_sensitivity=29.43%, avg_specificity=96.61% avg_auc=81.79%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.325051 Test loss=0.438617 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3289578855037689
[5/24] Train loss=0.304590106010437
[10/24] Train loss=0.3275212347507477
[15/24] Train loss=0.30852076411247253
[20/24] Train loss=0.30920401215553284
Test set avg_accuracy=85.82% avg_sensitivity=57.42%, avg_specificity=94.05% avg_auc=90.21%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.329051 Test loss=0.326454 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.33440256118774414
[5/24] Train loss=0.30632779002189636
[10/24] Train loss=0.3212926387786865
[15/24] Train loss=0.3158773183822632
[20/24] Train loss=0.3109639883041382
Test set avg_accuracy=84.67% avg_sensitivity=46.41%, avg_specificity=95.77% avg_auc=89.16%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.326872 Test loss=0.343777 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3167601525783539
[5/24] Train loss=0.31623420119285583
[10/24] Train loss=0.3293667137622833
[15/24] Train loss=0.31050705909729004
[20/24] Train loss=0.3183301091194153
Test set avg_accuracy=83.79% avg_sensitivity=44.90%, avg_specificity=95.06% avg_auc=87.11%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.324325 Test loss=0.360873 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3254844844341278
[5/24] Train loss=0.31915900111198425
[10/24] Train loss=0.32046568393707275
[15/24] Train loss=0.3101038634777069
[20/24] Train loss=0.3155193030834198
Test set avg_accuracy=81.38% avg_sensitivity=24.10%, avg_specificity=97.98% avg_auc=85.42%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.324076 Test loss=0.436642 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3182932436466217
[5/24] Train loss=0.3064762055873871
[10/24] Train loss=0.3198896050453186
[15/24] Train loss=0.30368131399154663
[20/24] Train loss=0.30806294083595276
Test set avg_accuracy=81.25% avg_sensitivity=22.13%, avg_specificity=98.39% avg_auc=80.57%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.321590 Test loss=0.470193 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.32593590021133423
[5/24] Train loss=0.29849591851234436
[10/24] Train loss=0.32382968068122864
[15/24] Train loss=0.3001604378223419
[20/24] Train loss=0.30844858288764954
Test set avg_accuracy=84.39% avg_sensitivity=47.16%, avg_specificity=95.18% avg_auc=88.22%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.319488 Test loss=0.353551 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.31949102878570557
[5/24] Train loss=0.3044215738773346
[10/24] Train loss=0.32399916648864746
[15/24] Train loss=0.30702292919158936
[20/24] Train loss=0.3153879940509796
Test set avg_accuracy=85.86% avg_sensitivity=56.14%, avg_specificity=94.47% avg_auc=88.23%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.320358 Test loss=0.347388 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3248121440410614
[5/24] Train loss=0.30678898096084595
[10/24] Train loss=0.3241068124771118
[15/24] Train loss=0.3094949424266815
[20/24] Train loss=0.31696563959121704
Test set avg_accuracy=80.53% avg_sensitivity=18.95%, avg_specificity=98.39% avg_auc=79.81%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.321375 Test loss=0.533476 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3136119544506073
[5/24] Train loss=0.2987237870693207
[10/24] Train loss=0.317428857088089
[15/24] Train loss=0.3083629906177521
[20/24] Train loss=0.31863006949424744
Test set avg_accuracy=82.57% avg_sensitivity=30.76%, avg_specificity=97.58% avg_auc=82.89%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.318111 Test loss=0.415277 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.33499422669410706
[5/24] Train loss=0.3061676323413849
[10/24] Train loss=0.3305874764919281
[15/24] Train loss=0.3011883497238159
[20/24] Train loss=0.30769017338752747
Test set avg_accuracy=84.00% avg_sensitivity=44.15%, avg_specificity=95.55% avg_auc=88.11%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.318852 Test loss=0.350362 Current lr=[0.000224838296036774]

[0/24] Train loss=0.316109299659729
[5/24] Train loss=0.30547013878822327
[10/24] Train loss=0.31273144483566284
[15/24] Train loss=0.2990032136440277
[20/24] Train loss=0.3061828017234802
Test set avg_accuracy=84.90% avg_sensitivity=71.38%, avg_specificity=88.81% avg_auc=89.66%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.313830 Test loss=0.344657 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3303161859512329
[5/24] Train loss=0.30526110529899597
[10/24] Train loss=0.3132016658782959
[15/24] Train loss=0.3013257682323456
[20/24] Train loss=0.3114221692085266
Test set avg_accuracy=84.91% avg_sensitivity=52.95%, avg_specificity=94.17% avg_auc=87.86%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.315390 Test loss=0.347580 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3271152079105377
[5/24] Train loss=0.3018910884857178
[10/24] Train loss=0.31148311495780945
[15/24] Train loss=0.2911989986896515
[20/24] Train loss=0.30509302020072937
Test set avg_accuracy=85.43% avg_sensitivity=53.30%, avg_specificity=94.74% avg_auc=89.69%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.314612 Test loss=0.329660 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3150579631328583
[5/24] Train loss=0.29146817326545715
[10/24] Train loss=0.3215253949165344
[15/24] Train loss=0.3022117018699646
[20/24] Train loss=0.30685412883758545
Test set avg_accuracy=84.73% avg_sensitivity=52.09%, avg_specificity=94.19% avg_auc=89.01%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.310988 Test loss=0.340115 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3038037121295929
[5/24] Train loss=0.2821926474571228
[10/24] Train loss=0.3009113371372223
[15/24] Train loss=0.2974681258201599
[20/24] Train loss=0.30514857172966003
Test set avg_accuracy=84.45% avg_sensitivity=52.72%, avg_specificity=93.65% avg_auc=88.57%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.308570 Test loss=0.346122 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.30973729491233826
[5/24] Train loss=0.2958894968032837
[10/24] Train loss=0.3096218705177307
[15/24] Train loss=0.2897410988807678
[20/24] Train loss=0.2976558208465576
Test set avg_accuracy=84.78% avg_sensitivity=62.57%, avg_specificity=91.22% avg_auc=88.15%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.308558 Test loss=0.361148 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3068416118621826
[5/24] Train loss=0.28978168964385986
[10/24] Train loss=0.31019410490989685
[15/24] Train loss=0.3016781508922577
[20/24] Train loss=0.31215226650238037
Test set avg_accuracy=85.27% avg_sensitivity=50.12%, avg_specificity=95.47% avg_auc=88.78%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.306861 Test loss=0.338136 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.30332398414611816
[5/24] Train loss=0.28376540541648865
[10/24] Train loss=0.305279016494751
[15/24] Train loss=0.2893471419811249
[20/24] Train loss=0.30072513222694397
Test set avg_accuracy=85.29% avg_sensitivity=59.62%, avg_specificity=92.73% avg_auc=90.23%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.305426 Test loss=0.325548 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.30405256152153015
[5/24] Train loss=0.28837713599205017
[10/24] Train loss=0.3001954257488251
[15/24] Train loss=0.29090723395347595
[20/24] Train loss=0.28561994433403015
Test set avg_accuracy=84.69% avg_sensitivity=49.25%, avg_specificity=94.96% avg_auc=88.09%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.301319 Test loss=0.352395 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.29595181345939636
[5/24] Train loss=0.2865797281265259
[10/24] Train loss=0.30011942982673645
[15/24] Train loss=0.2971095144748688
[20/24] Train loss=0.3014753460884094
Test set avg_accuracy=82.92% avg_sensitivity=34.36%, avg_specificity=96.99% avg_auc=83.00%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.297757 Test loss=0.415852 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3029644191265106
[5/24] Train loss=0.2781047523021698
[10/24] Train loss=0.2994057834148407
[15/24] Train loss=0.2816540598869324
[20/24] Train loss=0.29430776834487915
Test set avg_accuracy=82.24% avg_sensitivity=28.16%, avg_specificity=97.92% avg_auc=80.05%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.298316 Test loss=0.452430 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.29477736353874207
[5/24] Train loss=0.2739156186580658
[10/24] Train loss=0.2999112010002136
[15/24] Train loss=0.28774601221084595
[20/24] Train loss=0.28698477149009705
Test set avg_accuracy=84.34% avg_sensitivity=43.86%, avg_specificity=96.07% avg_auc=85.98%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.296929 Test loss=0.380731 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2982810437679291
[5/24] Train loss=0.2823205888271332
[10/24] Train loss=0.29608041048049927
[15/24] Train loss=0.29135018587112427
[20/24] Train loss=0.28173285722732544
Test set avg_accuracy=85.22% avg_sensitivity=56.03%, avg_specificity=93.68% avg_auc=87.95%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.295626 Test loss=0.347700 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3005499541759491
[5/24] Train loss=0.2845407724380493
[10/24] Train loss=0.2903505861759186
[15/24] Train loss=0.29312121868133545
[20/24] Train loss=0.2799535393714905
Test set avg_accuracy=82.43% avg_sensitivity=34.07%, avg_specificity=96.46% avg_auc=83.47%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.292483 Test loss=0.418137 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2903602719306946
[5/24] Train loss=0.28264936804771423
[10/24] Train loss=0.2852863371372223
[15/24] Train loss=0.2805606722831726
[20/24] Train loss=0.28157198429107666
Test set avg_accuracy=83.45% avg_sensitivity=65.35%, avg_specificity=88.70% avg_auc=87.99%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.288906 Test loss=0.358862 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2919231057167053
[5/24] Train loss=0.2738480567932129
[10/24] Train loss=0.28541481494903564
[15/24] Train loss=0.2851308584213257
[20/24] Train loss=0.291945219039917
Test set avg_accuracy=85.70% avg_sensitivity=59.56%, avg_specificity=93.28% avg_auc=88.87%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.289877 Test loss=0.341244 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2926757335662842
[5/24] Train loss=0.27936720848083496
[10/24] Train loss=0.2872817814350128
[15/24] Train loss=0.28096339106559753
[20/24] Train loss=0.28513476252555847
Test set avg_accuracy=85.52% avg_sensitivity=58.23%, avg_specificity=93.43% avg_auc=89.51%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.288596 Test loss=0.334346 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2889828383922577
[5/24] Train loss=0.27275505661964417
[10/24] Train loss=0.29565584659576416
[15/24] Train loss=0.2786799371242523
[20/24] Train loss=0.28249821066856384
Test set avg_accuracy=85.01% avg_sensitivity=48.44%, avg_specificity=95.62% avg_auc=87.48%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.287776 Test loss=0.352937 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2851371169090271
[5/24] Train loss=0.2606942057609558
[10/24] Train loss=0.26341456174850464
[15/24] Train loss=0.2875381112098694
[20/24] Train loss=0.2814443111419678
Test set avg_accuracy=84.15% avg_sensitivity=43.92%, avg_specificity=95.82% avg_auc=85.41%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.281634 Test loss=0.382138 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.26354166865348816
[5/24] Train loss=0.2707763910293579
[10/24] Train loss=0.27382132411003113
[15/24] Train loss=0.27385005354881287
[20/24] Train loss=0.2687615156173706
Test set avg_accuracy=84.67% avg_sensitivity=50.52%, avg_specificity=94.58% avg_auc=87.90%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.278493 Test loss=0.349306 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.27574658393859863
[5/24] Train loss=0.2675555646419525
[10/24] Train loss=0.2722175419330597
[15/24] Train loss=0.2732870578765869
[20/24] Train loss=0.2723727822303772
Test set avg_accuracy=84.15% avg_sensitivity=50.06%, avg_specificity=94.04% avg_auc=86.19%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.276279 Test loss=0.362688 Current lr=[0.000134135431043539]

[0/24] Train loss=0.2667691111564636
[5/24] Train loss=0.2654176950454712
[10/24] Train loss=0.278392493724823
[15/24] Train loss=0.27177494764328003
[20/24] Train loss=0.28723832964897156
Test set avg_accuracy=84.30% avg_sensitivity=57.42%, avg_specificity=92.09% avg_auc=86.53%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.275502 Test loss=0.363768 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.27591606974601746
[5/24] Train loss=0.255491703748703
[10/24] Train loss=0.2608461380004883
[15/24] Train loss=0.26278477907180786
[20/24] Train loss=0.2654081881046295
Test set avg_accuracy=84.77% avg_sensitivity=59.62%, avg_specificity=92.06% avg_auc=87.76%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.271859 Test loss=0.349238 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2656680941581726
[5/24] Train loss=0.25354889035224915
[10/24] Train loss=0.2622583508491516
[15/24] Train loss=0.2591288089752197
[20/24] Train loss=0.263678640127182
Test set avg_accuracy=84.36% avg_sensitivity=59.50%, avg_specificity=91.57% avg_auc=87.52%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.270699 Test loss=0.356349 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.26284876465797424
[5/24] Train loss=0.24951781332492828
[10/24] Train loss=0.2571699321269989
[15/24] Train loss=0.2564503848552704
[20/24] Train loss=0.27175015211105347
Test set avg_accuracy=82.10% avg_sensitivity=57.47%, avg_specificity=89.23% avg_auc=85.47%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.266540 Test loss=0.384938 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.26460781693458557
[5/24] Train loss=0.24989552795886993
[10/24] Train loss=0.26120510697364807
[15/24] Train loss=0.26759564876556396
[20/24] Train loss=0.25424033403396606
Test set avg_accuracy=84.04% avg_sensitivity=57.88%, avg_specificity=91.62% avg_auc=87.23%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.266370 Test loss=0.357164 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.26291266083717346
[5/24] Train loss=0.25077906250953674
[10/24] Train loss=0.257111132144928
[15/24] Train loss=0.25379204750061035
[20/24] Train loss=0.25995737314224243
Test set avg_accuracy=82.79% avg_sensitivity=63.38%, avg_specificity=88.41% avg_auc=87.26%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.260781 Test loss=0.370828 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.25412866473197937
[5/24] Train loss=0.23627819120883942
[10/24] Train loss=0.24742566049098969
[15/24] Train loss=0.2548932731151581
[20/24] Train loss=0.25571414828300476
Test set avg_accuracy=84.39% avg_sensitivity=59.97%, avg_specificity=91.47% avg_auc=88.22%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.256276 Test loss=0.352083 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.25239959359169006
[5/24] Train loss=0.23465952277183533
[10/24] Train loss=0.2437940537929535
[15/24] Train loss=0.24856658279895782
[20/24] Train loss=0.25915804505348206
Test set avg_accuracy=84.09% avg_sensitivity=69.93%, avg_specificity=88.19% avg_auc=89.16%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.253930 Test loss=0.347142 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.26167210936546326
[5/24] Train loss=0.23752856254577637
[10/24] Train loss=0.23914609849452972
[15/24] Train loss=0.25275102257728577
[20/24] Train loss=0.25496405363082886
Test set avg_accuracy=83.26% avg_sensitivity=64.48%, avg_specificity=88.70% avg_auc=87.23%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.252784 Test loss=0.370172 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.24487337470054626
[5/24] Train loss=0.24511539936065674
[10/24] Train loss=0.23509427905082703
[15/24] Train loss=0.24371886253356934
[20/24] Train loss=0.2442413568496704
Test set avg_accuracy=84.15% avg_sensitivity=64.95%, avg_specificity=89.72% avg_auc=88.27%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.249060 Test loss=0.351568 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2529865503311157
[5/24] Train loss=0.23225037753582
[10/24] Train loss=0.23783954977989197
[15/24] Train loss=0.24083669483661652
[20/24] Train loss=0.2483525425195694
Test set avg_accuracy=83.41% avg_sensitivity=65.35%, avg_specificity=88.65% avg_auc=87.07%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.245398 Test loss=0.369692 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.23583611845970154
[5/24] Train loss=0.227865070104599
[10/24] Train loss=0.2295600026845932
[15/24] Train loss=0.234768345952034
[20/24] Train loss=0.24059037864208221
Test set avg_accuracy=84.77% avg_sensitivity=60.43%, avg_specificity=91.82% avg_auc=87.57%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.242403 Test loss=0.356381 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.23938892781734467
[5/24] Train loss=0.22990623116493225
[10/24] Train loss=0.2249813824892044
[15/24] Train loss=0.23520822823047638
[20/24] Train loss=0.2335222065448761
Test set avg_accuracy=83.53% avg_sensitivity=62.22%, avg_specificity=89.70% avg_auc=86.47%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.238236 Test loss=0.372682 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.24124865233898163
[5/24] Train loss=0.22585070133209229
[10/24] Train loss=0.2302057445049286
[15/24] Train loss=0.22708652913570404
[20/24] Train loss=0.23953823745250702
Test set avg_accuracy=84.14% avg_sensitivity=65.64%, avg_specificity=89.50% avg_auc=88.25%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.236017 Test loss=0.356036 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.24300530552864075
[5/24] Train loss=0.22815127670764923
[10/24] Train loss=0.22066593170166016
[15/24] Train loss=0.2272806018590927
[20/24] Train loss=0.23610493540763855
Test set avg_accuracy=84.51% avg_sensitivity=64.95%, avg_specificity=90.17% avg_auc=88.32%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.233717 Test loss=0.355912 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.237260103225708
[5/24] Train loss=0.22061681747436523
[10/24] Train loss=0.2197946012020111
[15/24] Train loss=0.23159770667552948
[20/24] Train loss=0.2292395681142807
Test set avg_accuracy=84.61% avg_sensitivity=63.79%, avg_specificity=90.64% avg_auc=87.59%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.230070 Test loss=0.362059 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.23044158518314362
[5/24] Train loss=0.21468506753444672
[10/24] Train loss=0.22146615386009216
[15/24] Train loss=0.2242993414402008
[20/24] Train loss=0.2231825292110443
Test set avg_accuracy=84.57% avg_sensitivity=59.62%, avg_specificity=91.80% avg_auc=87.39%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.229078 Test loss=0.362661 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.23276154696941376
[5/24] Train loss=0.21289613842964172
[10/24] Train loss=0.21463802456855774
[15/24] Train loss=0.22365495562553406
[20/24] Train loss=0.219328373670578
Test set avg_accuracy=84.48% avg_sensitivity=64.72%, avg_specificity=90.21% avg_auc=87.65%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.225067 Test loss=0.361525 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.23132987320423126
[5/24] Train loss=0.2080342024564743
[10/24] Train loss=0.20998619496822357
[15/24] Train loss=0.21667106449604034
[20/24] Train loss=0.21992230415344238
Test set avg_accuracy=84.14% avg_sensitivity=61.70%, avg_specificity=90.64% avg_auc=87.13%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.221269 Test loss=0.365540 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.21716700494289398
[5/24] Train loss=0.2010258138179779
[10/24] Train loss=0.20668062567710876
[15/24] Train loss=0.21188218891620636
[20/24] Train loss=0.22297823429107666
Test set avg_accuracy=83.95% avg_sensitivity=59.85%, avg_specificity=90.93% avg_auc=85.78%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.219363 Test loss=0.374923 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.220613494515419
[5/24] Train loss=0.2038542926311493
[10/24] Train loss=0.2068183273077011
[15/24] Train loss=0.21291030943393707
[20/24] Train loss=0.21628504991531372
Test set avg_accuracy=84.56% avg_sensitivity=60.60%, avg_specificity=91.50% avg_auc=86.78%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.218201 Test loss=0.365371 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.2169693410396576
[5/24] Train loss=0.2024839073419571
[10/24] Train loss=0.20687323808670044
[15/24] Train loss=0.21055087447166443
[20/24] Train loss=0.2116577923297882
Test set avg_accuracy=84.24% avg_sensitivity=57.30%, avg_specificity=92.06% avg_auc=85.48%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.215291 Test loss=0.384316 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.22104232013225555
[5/24] Train loss=0.20152869820594788
[10/24] Train loss=0.2032179832458496
[15/24] Train loss=0.21098832786083221
[20/24] Train loss=0.20371533930301666
Test set avg_accuracy=84.57% avg_sensitivity=56.20%, avg_specificity=92.79% avg_auc=86.49%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.212352 Test loss=0.376429 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.2132139652967453
[5/24] Train loss=0.19774916768074036
[10/24] Train loss=0.20311792194843292
[15/24] Train loss=0.21109050512313843
[20/24] Train loss=0.20786680281162262
Test set avg_accuracy=84.97% avg_sensitivity=58.69%, avg_specificity=92.59% avg_auc=85.98%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.209461 Test loss=0.372265 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.20570549368858337
[5/24] Train loss=0.18876878917217255
[10/24] Train loss=0.19306683540344238
[15/24] Train loss=0.20702867209911346
[20/24] Train loss=0.20807212591171265
Test set avg_accuracy=84.44% avg_sensitivity=59.56%, avg_specificity=91.65% avg_auc=86.64%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.207676 Test loss=0.370824 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.20396265387535095
[5/24] Train loss=0.19049222767353058
[10/24] Train loss=0.1953781396150589
[15/24] Train loss=0.20240965485572815
[20/24] Train loss=0.20326249301433563
Test set avg_accuracy=84.38% avg_sensitivity=58.17%, avg_specificity=91.97% avg_auc=85.74%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.204991 Test loss=0.382118 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.20599645376205444
[5/24] Train loss=0.19425298273563385
[10/24] Train loss=0.18882425129413605
[15/24] Train loss=0.19789987802505493
[20/24] Train loss=0.1972850263118744
Test set avg_accuracy=84.43% avg_sensitivity=60.72%, avg_specificity=91.30% avg_auc=86.50%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.203646 Test loss=0.371850 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.20007458329200745
[5/24] Train loss=0.18910959362983704
[10/24] Train loss=0.18530073761940002
[15/24] Train loss=0.1998930424451828
[20/24] Train loss=0.20807267725467682
Test set avg_accuracy=84.26% avg_sensitivity=58.23%, avg_specificity=91.80% avg_auc=85.58%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.200955 Test loss=0.381354 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.20289981365203857
[5/24] Train loss=0.19264544546604156
[10/24] Train loss=0.186759352684021
[15/24] Train loss=0.18671001493930817
[20/24] Train loss=0.19782677292823792
Test set avg_accuracy=84.53% avg_sensitivity=57.65%, avg_specificity=92.32% avg_auc=86.05%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.199200 Test loss=0.376398 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.20410071313381195
[5/24] Train loss=0.19062121212482452
[10/24] Train loss=0.1839362233877182
[15/24] Train loss=0.19082127511501312
[20/24] Train loss=0.19246245920658112
Test set avg_accuracy=84.53% avg_sensitivity=59.85%, avg_specificity=91.69% avg_auc=86.81%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.197236 Test loss=0.367954 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1947891265153885
[5/24] Train loss=0.18845438957214355
[10/24] Train loss=0.18339279294013977
[15/24] Train loss=0.18925891816616058
[20/24] Train loss=0.19810307025909424
Test set avg_accuracy=84.32% avg_sensitivity=59.91%, avg_specificity=91.40% avg_auc=85.61%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.196075 Test loss=0.379823 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.19231854379177094
[5/24] Train loss=0.18545334041118622
[10/24] Train loss=0.18438972532749176
[15/24] Train loss=0.18928317725658417
[20/24] Train loss=0.18940643966197968
Test set avg_accuracy=84.66% avg_sensitivity=59.27%, avg_specificity=92.02% avg_auc=86.04%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.194242 Test loss=0.376414 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.19554905593395233
[5/24] Train loss=0.185954287648201
[10/24] Train loss=0.18126502633094788
[15/24] Train loss=0.19356563687324524
[20/24] Train loss=0.1918502300977707
Test set avg_accuracy=84.27% avg_sensitivity=60.60%, avg_specificity=91.13% avg_auc=86.22%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.193485 Test loss=0.376549 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1970304548740387
[5/24] Train loss=0.18454861640930176
[10/24] Train loss=0.18078604340553284
[15/24] Train loss=0.1826627254486084
[20/24] Train loss=0.19675593078136444
Test set avg_accuracy=84.77% avg_sensitivity=59.04%, avg_specificity=92.22% avg_auc=86.13%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.191726 Test loss=0.376639 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.19252601265907288
[5/24] Train loss=0.1821489781141281
[10/24] Train loss=0.1792362928390503
[15/24] Train loss=0.19319090247154236
[20/24] Train loss=0.1877281665802002
Test set avg_accuracy=84.58% avg_sensitivity=61.07%, avg_specificity=91.40% avg_auc=86.15%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.190795 Test loss=0.376554 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.20046283304691315
[5/24] Train loss=0.17921778559684753
[10/24] Train loss=0.17437060177326202
[15/24] Train loss=0.1879010647535324
[20/24] Train loss=0.18888328969478607
Test set avg_accuracy=84.57% avg_sensitivity=59.85%, avg_specificity=91.74% avg_auc=86.26%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.190424 Test loss=0.374874 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.19027937948703766
[5/24] Train loss=0.17807945609092712
[10/24] Train loss=0.17489303648471832
[15/24] Train loss=0.18917985260486603
[20/24] Train loss=0.18971943855285645
Test set avg_accuracy=84.53% avg_sensitivity=59.68%, avg_specificity=91.74% avg_auc=85.99%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.190074 Test loss=0.379873 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.19033698737621307
[5/24] Train loss=0.17680467665195465
[10/24] Train loss=0.18015964329242706
[15/24] Train loss=0.18371430039405823
[20/24] Train loss=0.19185788929462433
Test set avg_accuracy=84.77% avg_sensitivity=59.44%, avg_specificity=92.11% avg_auc=86.12%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.188829 Test loss=0.375712 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.18984250724315643
[5/24] Train loss=0.17599265277385712
[10/24] Train loss=0.17680096626281738
[15/24] Train loss=0.17926108837127686
[20/24] Train loss=0.19177736341953278
Test set avg_accuracy=84.60% avg_sensitivity=59.27%, avg_specificity=91.94% avg_auc=86.10%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.187263 Test loss=0.378168 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.18193627893924713
[5/24] Train loss=0.17986585199832916
[10/24] Train loss=0.1756446659564972
[15/24] Train loss=0.17889873683452606
[20/24] Train loss=0.1868681162595749
Test set avg_accuracy=84.84% avg_sensitivity=61.18%, avg_specificity=91.70% avg_auc=86.56%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.186832 Test loss=0.372538 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.18622508645057678
[5/24] Train loss=0.17366164922714233
[10/24] Train loss=0.1748340129852295
[15/24] Train loss=0.18096695840358734
[20/24] Train loss=0.18977688252925873
Test set avg_accuracy=84.57% avg_sensitivity=59.50%, avg_specificity=91.84% avg_auc=86.26%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.186171 Test loss=0.374770 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.19065645337104797
[5/24] Train loss=0.1794629544019699
[10/24] Train loss=0.17206914722919464
[15/24] Train loss=0.18457336723804474
[20/24] Train loss=0.1888231486082077
Test set avg_accuracy=84.79% avg_sensitivity=60.37%, avg_specificity=91.87% avg_auc=86.34%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.186887 Test loss=0.374911 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.18747800588607788
[5/24] Train loss=0.17578387260437012
[10/24] Train loss=0.17680911719799042
[15/24] Train loss=0.18436649441719055
[20/24] Train loss=0.1834924817085266
Test set avg_accuracy=84.70% avg_sensitivity=59.85%, avg_specificity=91.90% avg_auc=86.11%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.186989 Test loss=0.377719 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.18834900856018066
[5/24] Train loss=0.17569537460803986
[10/24] Train loss=0.17147302627563477
[15/24] Train loss=0.17941345274448395
[20/24] Train loss=0.18620365858078003
Test set avg_accuracy=84.52% avg_sensitivity=59.68%, avg_specificity=91.72% avg_auc=86.25%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.185774 Test loss=0.376772 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.19105897843837738
[5/24] Train loss=0.17094852030277252
[10/24] Train loss=0.17210286855697632
[15/24] Train loss=0.17905576527118683
[20/24] Train loss=0.18557871878147125
Test set avg_accuracy=84.58% avg_sensitivity=59.68%, avg_specificity=91.80% avg_auc=86.22%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.185337 Test loss=0.377112 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.18980678915977478
[5/24] Train loss=0.17568114399909973
[10/24] Train loss=0.17256833612918854
[15/24] Train loss=0.18208633363246918
[20/24] Train loss=0.18440546095371246
Test set avg_accuracy=84.58% avg_sensitivity=59.73%, avg_specificity=91.79% avg_auc=86.18%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.185814 Test loss=0.377384 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1888219565153122
[5/24] Train loss=0.17626908421516418
[10/24] Train loss=0.17402350902557373
[15/24] Train loss=0.17798052728176117
[20/24] Train loss=0.1904463917016983
Test set avg_accuracy=84.67% avg_sensitivity=59.97%, avg_specificity=91.84% avg_auc=86.17%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.185509 Test loss=0.377288 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.192261204123497
[5/24] Train loss=0.17325326800346375
[10/24] Train loss=0.17318664491176605
[15/24] Train loss=0.18257659673690796
[20/24] Train loss=0.18562857806682587
Test set avg_accuracy=84.64% avg_sensitivity=59.73%, avg_specificity=91.85% avg_auc=86.14%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.185655 Test loss=0.377849 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.19349195063114166
[5/24] Train loss=0.17403483390808105
[10/24] Train loss=0.17118319869041443
[15/24] Train loss=0.17852532863616943
[20/24] Train loss=0.1904521882534027
Test set avg_accuracy=84.65% avg_sensitivity=59.79%, avg_specificity=91.85% avg_auc=86.16%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.185608 Test loss=0.377748 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=85.62% sen=68.89%, spe=90.48%, auc=89.80%!
Fold[10] Avg_overlap=0.62%(0.26868481629677093)
Final Avg Result: avg_acc=82.49%(1.7296886413754924) avg_sen=70.18% (1.0636143484267115) avg_spe=86.72% (2.1123215350992237) avg_auc=87.92% (1.112038799218056) avg_overlap=0.39% (0.2080374106830994)
