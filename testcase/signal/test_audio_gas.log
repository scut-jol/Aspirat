/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/24] Train loss=0.7208883762359619
[5/24] Train loss=0.7190126776695251
[10/24] Train loss=0.7160095572471619
[15/24] Train loss=0.7086580991744995
[20/24] Train loss=0.6947086453437805
Test set avg_accuracy=57.94% avg_sensitivity=47.80%, avg_specificity=61.57% avg_auc=56.25%
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.710512 Test loss=0.687419 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6953508257865906
[5/24] Train loss=0.6910132169723511
[10/24] Train loss=0.6965206265449524
[15/24] Train loss=0.6772818565368652
[20/24] Train loss=0.669929027557373
Test set avg_accuracy=61.94% avg_sensitivity=54.92%, avg_specificity=64.45% avg_auc=64.94%
Best model saved!! Metric=-79.74565043738082!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.686238 Test loss=0.643353 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6719284057617188
[5/24] Train loss=0.6687948107719421
[10/24] Train loss=0.6745036244392395
[15/24] Train loss=0.6573778986930847
[20/24] Train loss=0.6462365984916687
Test set avg_accuracy=65.87% avg_sensitivity=60.96%, avg_specificity=67.63% avg_auc=70.04%
Best model saved!! Metric=-61.503570025764624!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.665385 Test loss=0.621692 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6449599266052246
[5/24] Train loss=0.6466086506843567
[10/24] Train loss=0.6467753648757935
[15/24] Train loss=0.6283375024795532
[20/24] Train loss=0.623555064201355
Test set avg_accuracy=68.68% avg_sensitivity=64.87%, avg_specificity=70.05% avg_auc=73.98%
Best model saved!! Metric=-48.41752328789414!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.641787 Test loss=0.599552 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6175653338432312
[5/24] Train loss=0.6191559433937073
[10/24] Train loss=0.6214823722839355
[15/24] Train loss=0.5991598963737488
[20/24] Train loss=0.5944275259971619
Test set avg_accuracy=70.82% avg_sensitivity=71.45%, avg_specificity=70.60% avg_auc=77.68%
Best model saved!! Metric=-35.45789199339191!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.617398 Test loss=0.578215 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5879777669906616
[5/24] Train loss=0.5927944779396057
[10/24] Train loss=0.5959413051605225
[15/24] Train loss=0.5722005367279053
[20/24] Train loss=0.5695152282714844
Test set avg_accuracy=72.20% avg_sensitivity=77.29%, avg_specificity=70.38% avg_auc=80.31%
Best model saved!! Metric=-25.813433372020086!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.589519 Test loss=0.557832 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5535461902618408
[5/24] Train loss=0.5619297027587891
[10/24] Train loss=0.5661933422088623
[15/24] Train loss=0.5430494546890259
[20/24] Train loss=0.5371334552764893
Test set avg_accuracy=73.93% avg_sensitivity=80.01%, avg_specificity=71.76% avg_auc=82.60%
Best model saved!! Metric=-17.693079119789275!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.560593 Test loss=0.533993 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5224393010139465
[5/24] Train loss=0.5211610198020935
[10/24] Train loss=0.5452815294265747
[15/24] Train loss=0.5050186514854431
[20/24] Train loss=0.49581053853034973
Test set avg_accuracy=76.93% avg_sensitivity=79.12%, avg_specificity=76.14% avg_auc=84.75%
Best model saved!! Metric=-9.05619089130164!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.527298 Test loss=0.494593 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.4870016872882843
[5/24] Train loss=0.48752614855766296
[10/24] Train loss=0.512191116809845
[15/24] Train loss=0.47578051686286926
[20/24] Train loss=0.47052204608917236
Test set avg_accuracy=78.20% avg_sensitivity=78.77%, avg_specificity=78.00% avg_auc=86.15%
Best model saved!! Metric=-4.879203430084587!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.495570 Test loss=0.473860 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.46398597955703735
[5/24] Train loss=0.456302672624588
[10/24] Train loss=0.48808208107948303
[15/24] Train loss=0.44360512495040894
[20/24] Train loss=0.4397032558917999
Test set avg_accuracy=80.27% avg_sensitivity=78.23%, avg_specificity=81.00% avg_auc=87.12%
Best model saved!! Metric=0.6256725887338774!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.468606 Test loss=0.446797 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.43477386236190796
[5/24] Train loss=0.4251781105995178
[10/24] Train loss=0.46893343329429626
[15/24] Train loss=0.4264204502105713
[20/24] Train loss=0.41521576046943665
Test set avg_accuracy=81.50% avg_sensitivity=77.29%, avg_specificity=83.00% avg_auc=87.84%
Best model saved!! Metric=3.6234820709729405!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.444513 Test loss=0.428167 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4059346914291382
[5/24] Train loss=0.3935769498348236
[10/24] Train loss=0.44411230087280273
[15/24] Train loss=0.40190762281417847
[20/24] Train loss=0.3937360942363739
Test set avg_accuracy=82.79% avg_sensitivity=74.42%, avg_specificity=85.77% avg_auc=88.55%
Best model saved!! Metric=5.530556243603812!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.420631 Test loss=0.402384 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3887377083301544
[5/24] Train loss=0.37316909432411194
[10/24] Train loss=0.4227820336818695
[15/24] Train loss=0.38790610432624817
[20/24] Train loss=0.37881073355674744
Test set avg_accuracy=84.05% avg_sensitivity=74.27%, avg_specificity=87.54% avg_auc=89.22%
Best model saved!! Metric=9.081210924016744!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.402156 Test loss=0.387030 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.368852436542511
[5/24] Train loss=0.35538366436958313
[10/24] Train loss=0.4083564877510071
[15/24] Train loss=0.36793386936187744
[20/24] Train loss=0.354850709438324
Test set avg_accuracy=84.69% avg_sensitivity=68.48%, avg_specificity=90.48% avg_auc=89.48%
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.384852 Test loss=0.364549 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.34857332706451416
[5/24] Train loss=0.3432031273841858
[10/24] Train loss=0.38989564776420593
[15/24] Train loss=0.3551495373249054
[20/24] Train loss=0.3381543755531311
Test set avg_accuracy=84.74% avg_sensitivity=62.59%, avg_specificity=92.65% avg_auc=89.44%
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.368940 Test loss=0.360370 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3343259394168854
[5/24] Train loss=0.3248863220214844
[10/24] Train loss=0.38210687041282654
[15/24] Train loss=0.34004268050193787
[20/24] Train loss=0.3272351026535034
Test set avg_accuracy=83.97% avg_sensitivity=54.43%, avg_specificity=94.52% avg_auc=88.90%
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.356468 Test loss=0.368457 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.31970635056495667
[5/24] Train loss=0.3172628581523895
[10/24] Train loss=0.37337425351142883
[15/24] Train loss=0.335930198431015
[20/24] Train loss=0.3188589811325073
Test set avg_accuracy=83.82% avg_sensitivity=51.66%, avg_specificity=95.30% avg_auc=88.72%
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.345421 Test loss=0.374054 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3106011152267456
[5/24] Train loss=0.31036290526390076
[10/24] Train loss=0.3589339256286621
[15/24] Train loss=0.323723167181015
[20/24] Train loss=0.31335487961769104
Test set avg_accuracy=82.07% avg_sensitivity=42.01%, avg_specificity=96.38% avg_auc=87.43%
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.336279 Test loss=0.403614 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.2998380959033966
[5/24] Train loss=0.30199071764945984
[10/24] Train loss=0.3519139587879181
[15/24] Train loss=0.31528347730636597
[20/24] Train loss=0.30075541138648987
Test set avg_accuracy=82.20% avg_sensitivity=41.66%, avg_specificity=96.68% avg_auc=87.79%
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.326852 Test loss=0.402854 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.29371389746665955
[5/24] Train loss=0.2960387170314789
[10/24] Train loss=0.3469429314136505
[15/24] Train loss=0.3110436797142029
[20/24] Train loss=0.29240038990974426
Test set avg_accuracy=82.51% avg_sensitivity=41.32%, avg_specificity=97.23% avg_auc=87.95%
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.319247 Test loss=0.402214 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.28797417879104614
[5/24] Train loss=0.28125524520874023
[10/24] Train loss=0.3327184319496155
[15/24] Train loss=0.30241045355796814
[20/24] Train loss=0.29461270570755005
Test set avg_accuracy=83.75% avg_sensitivity=48.79%, avg_specificity=96.24% avg_auc=89.13%
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.310823 Test loss=0.372718 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2801017165184021
[5/24] Train loss=0.276750385761261
[10/24] Train loss=0.340289831161499
[15/24] Train loss=0.2926395535469055
[20/24] Train loss=0.284812867641449
Test set avg_accuracy=86.30% avg_sensitivity=66.75%, avg_specificity=93.29% avg_auc=90.96%
Best model saved!! Metric=11.29563583503419!!
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.304616 Test loss=0.326457 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2756418287754059
[5/24] Train loss=0.27387821674346924
[10/24] Train loss=0.33494600653648376
[15/24] Train loss=0.2969277799129486
[20/24] Train loss=0.2832450568675995
Test set avg_accuracy=85.53% avg_sensitivity=58.09%, avg_specificity=95.33% avg_auc=90.55%
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.299815 Test loss=0.339223 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2706414759159088
[5/24] Train loss=0.2664572298526764
[10/24] Train loss=0.33214476704597473
[15/24] Train loss=0.28989312052726746
[20/24] Train loss=0.2753368020057678
Test set avg_accuracy=85.05% avg_sensitivity=54.77%, avg_specificity=95.86% avg_auc=90.58%
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.295864 Test loss=0.343793 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.26404815912246704
[5/24] Train loss=0.26160570979118347
[10/24] Train loss=0.3203158974647522
[15/24] Train loss=0.2896043062210083
[20/24] Train loss=0.27636194229125977
Test set avg_accuracy=85.85% avg_sensitivity=58.83%, avg_specificity=95.49% avg_auc=90.96%
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.291875 Test loss=0.332558 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.26560142636299133
[5/24] Train loss=0.2592235207557678
[10/24] Train loss=0.3190377652645111
[15/24] Train loss=0.28226909041404724
[20/24] Train loss=0.27215778827667236
Test set avg_accuracy=84.27% avg_sensitivity=51.56%, avg_specificity=95.95% avg_auc=90.06%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.288592 Test loss=0.359118 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2659144103527069
[5/24] Train loss=0.2558421194553375
[10/24] Train loss=0.3149663209915161
[15/24] Train loss=0.28136199712753296
[20/24] Train loss=0.266591876745224
Test set avg_accuracy=86.30% avg_sensitivity=61.16%, avg_specificity=95.28% avg_auc=91.04%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.285620 Test loss=0.331224 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2529434263706207
[5/24] Train loss=0.25530487298965454
[10/24] Train loss=0.31837016344070435
[15/24] Train loss=0.2784426212310791
[20/24] Train loss=0.2684800624847412
Test set avg_accuracy=84.92% avg_sensitivity=53.54%, avg_specificity=96.13% avg_auc=91.21%
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.281713 Test loss=0.337790 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2535604238510132
[5/24] Train loss=0.25249677896499634
[10/24] Train loss=0.31453850865364075
[15/24] Train loss=0.273639976978302
[20/24] Train loss=0.2590751647949219
Test set avg_accuracy=85.74% avg_sensitivity=58.88%, avg_specificity=95.33% avg_auc=91.30%
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.279462 Test loss=0.329952 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.24683766067028046
[5/24] Train loss=0.24554593861103058
[10/24] Train loss=0.3098694682121277
[15/24] Train loss=0.28257423639297485
[20/24] Train loss=0.2616404592990875
Test set avg_accuracy=86.85% avg_sensitivity=64.87%, avg_specificity=94.70% avg_auc=91.93%
Best model saved!! Metric=12.34192767564899!!
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.278541 Test loss=0.312154 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.24503283202648163
[5/24] Train loss=0.2366461604833603
[10/24] Train loss=0.3016411066055298
[15/24] Train loss=0.27490466833114624
[20/24] Train loss=0.26648539304733276
Test set avg_accuracy=85.59% avg_sensitivity=57.00%, avg_specificity=95.79% avg_auc=91.17%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.274234 Test loss=0.334511 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.24843649566173553
[5/24] Train loss=0.23921450972557068
[10/24] Train loss=0.30843451619148254
[15/24] Train loss=0.27807649970054626
[20/24] Train loss=0.2623811662197113
Test set avg_accuracy=86.61% avg_sensitivity=65.31%, avg_specificity=94.22% avg_auc=91.96%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.275711 Test loss=0.311305 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.24595747888088226
[5/24] Train loss=0.23685882985591888
[10/24] Train loss=0.3024473488330841
[15/24] Train loss=0.27709606289863586
[20/24] Train loss=0.2594624161720276
Test set avg_accuracy=86.61% avg_sensitivity=68.88%, avg_specificity=92.95% avg_auc=92.02%
Best model saved!! Metric=14.462066890634446!!
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.275304 Test loss=0.309467 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2515551745891571
[5/24] Train loss=0.23855100572109222
[10/24] Train loss=0.29516470432281494
[15/24] Train loss=0.2636600434780121
[20/24] Train loss=0.25778698921203613
Test set avg_accuracy=85.83% avg_sensitivity=57.15%, avg_specificity=96.08% avg_auc=91.13%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.271194 Test loss=0.330877 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.24413646757602692
[5/24] Train loss=0.23546573519706726
[10/24] Train loss=0.2998061776161194
[15/24] Train loss=0.26198136806488037
[20/24] Train loss=0.24864313006401062
Test set avg_accuracy=85.76% avg_sensitivity=56.70%, avg_specificity=96.13% avg_auc=91.11%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.267945 Test loss=0.335981 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.25771328806877136
[5/24] Train loss=0.23345303535461426
[10/24] Train loss=0.294913649559021
[15/24] Train loss=0.2632082998752594
[20/24] Train loss=0.2552129924297333
Test set avg_accuracy=86.74% avg_sensitivity=64.08%, avg_specificity=94.84% avg_auc=92.03%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.267258 Test loss=0.312413 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2424474060535431
[5/24] Train loss=0.23878808319568634
[10/24] Train loss=0.2856318950653076
[15/24] Train loss=0.2525427043437958
[20/24] Train loss=0.24908283352851868
Test set avg_accuracy=83.37% avg_sensitivity=47.30%, avg_specificity=96.25% avg_auc=89.50%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.265964 Test loss=0.377863 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.24122773110866547
[5/24] Train loss=0.23880603909492493
[10/24] Train loss=0.29919689893722534
[15/24] Train loss=0.2690114676952362
[20/24] Train loss=0.24419251084327698
Test set avg_accuracy=85.40% avg_sensitivity=59.48%, avg_specificity=94.66% avg_auc=90.19%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.265368 Test loss=0.341880 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.25372013449668884
[5/24] Train loss=0.23260454833507538
[10/24] Train loss=0.2900400459766388
[15/24] Train loss=0.2668170928955078
[20/24] Train loss=0.24352377653121948
Test set avg_accuracy=83.15% avg_sensitivity=45.62%, avg_specificity=96.55% avg_auc=89.45%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.262398 Test loss=0.380154 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2402416616678238
[5/24] Train loss=0.23398302495479584
[10/24] Train loss=0.2922915816307068
[15/24] Train loss=0.2553517520427704
[20/24] Train loss=0.2525743842124939
Test set avg_accuracy=85.00% avg_sensitivity=60.17%, avg_specificity=93.87% avg_auc=89.81%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.262903 Test loss=0.344736 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2453256994485855
[5/24] Train loss=0.23183730244636536
[10/24] Train loss=0.28447604179382324
[15/24] Train loss=0.26033711433410645
[20/24] Train loss=0.24691134691238403
Test set avg_accuracy=86.46% avg_sensitivity=65.17%, avg_specificity=94.06% avg_auc=91.96%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.262782 Test loss=0.314330 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.23908717930316925
[5/24] Train loss=0.22800491750240326
[10/24] Train loss=0.28850263357162476
[15/24] Train loss=0.2623697817325592
[20/24] Train loss=0.2488294392824173
Test set avg_accuracy=86.47% avg_sensitivity=71.15%, avg_specificity=91.94% avg_auc=91.37%
Best model saved!! Metric=14.93428749990673!!
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.259172 Test loss=0.322521 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.236000195145607
[5/24] Train loss=0.2321648746728897
[10/24] Train loss=0.2780734896659851
[15/24] Train loss=0.2661932706832886
[20/24] Train loss=0.2424830198287964
Test set avg_accuracy=82.85% avg_sensitivity=77.73%, avg_specificity=84.68% avg_auc=90.00%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.258656 Test loss=0.384340 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.24375663697719574
[5/24] Train loss=0.22780153155326843
[10/24] Train loss=0.27759280800819397
[15/24] Train loss=0.264821320772171
[20/24] Train loss=0.24444156885147095
Test set avg_accuracy=86.30% avg_sensitivity=66.90%, avg_specificity=93.23% avg_auc=90.72%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.261111 Test loss=0.330381 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2348339855670929
[5/24] Train loss=0.2303772121667862
[10/24] Train loss=0.2842690944671631
[15/24] Train loss=0.2594261169433594
[20/24] Train loss=0.24638697504997253
Test set avg_accuracy=83.59% avg_sensitivity=48.05%, avg_specificity=96.29% avg_auc=89.61%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.255242 Test loss=0.369975 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.23680396378040314
[5/24] Train loss=0.22880379855632782
[10/24] Train loss=0.27649518847465515
[15/24] Train loss=0.26053765416145325
[20/24] Train loss=0.24856168031692505
Test set avg_accuracy=86.26% avg_sensitivity=66.85%, avg_specificity=93.20% avg_auc=91.24%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.255237 Test loss=0.325130 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.23966600000858307
[5/24] Train loss=0.22449007630348206
[10/24] Train loss=0.28460249304771423
[15/24] Train loss=0.2701566815376282
[20/24] Train loss=0.24111808836460114
Test set avg_accuracy=86.24% avg_sensitivity=65.56%, avg_specificity=93.62% avg_auc=90.95%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.251963 Test loss=0.326529 Current lr=[0.000299720220882401]

[0/24] Train loss=0.23079578578472137
[5/24] Train loss=0.2212839424610138
[10/24] Train loss=0.2639606297016144
[15/24] Train loss=0.25093507766723633
[20/24] Train loss=0.23950539529323578
Test set avg_accuracy=86.15% avg_sensitivity=63.43%, avg_specificity=94.26% avg_auc=90.60%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.249614 Test loss=0.331897 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.23592248558998108
[5/24] Train loss=0.22298482060432434
[10/24] Train loss=0.2673436105251312
[15/24] Train loss=0.2440662533044815
[20/24] Train loss=0.23074615001678467
Test set avg_accuracy=83.83% avg_sensitivity=73.92%, avg_specificity=87.37% avg_auc=89.89%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.249557 Test loss=0.357181 Current lr=[0.000298904600941902]

[0/24] Train loss=0.24037085473537445
[5/24] Train loss=0.2212868183851242
[10/24] Train loss=0.2678786814212799
[15/24] Train loss=0.25540709495544434
[20/24] Train loss=0.24888670444488525
Test set avg_accuracy=85.16% avg_sensitivity=58.58%, avg_specificity=94.65% avg_auc=89.52%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.252470 Test loss=0.353954 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.23174835741519928
[5/24] Train loss=0.22412577271461487
[10/24] Train loss=0.2659918963909149
[15/24] Train loss=0.2459859699010849
[20/24] Train loss=0.24804005026817322
Test set avg_accuracy=80.36% avg_sensitivity=31.22%, avg_specificity=97.91% avg_auc=85.22%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.249415 Test loss=0.481367 Current lr=[0.000297555943323901]

[0/24] Train loss=0.23318524658679962
[5/24] Train loss=0.2200237214565277
[10/24] Train loss=0.27963200211524963
[15/24] Train loss=0.2532911002635956
[20/24] Train loss=0.24193011224269867
Test set avg_accuracy=86.76% avg_sensitivity=68.33%, avg_specificity=93.34% avg_auc=91.39%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.250542 Test loss=0.318091 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2346908301115036
[5/24] Train loss=0.21316289901733398
[10/24] Train loss=0.27488040924072266
[15/24] Train loss=0.2512107789516449
[20/24] Train loss=0.23474034667015076
Test set avg_accuracy=85.07% avg_sensitivity=55.71%, avg_specificity=95.55% avg_auc=89.07%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.248411 Test loss=0.363573 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.22112955152988434
[5/24] Train loss=0.2104332447052002
[10/24] Train loss=0.2508939206600189
[15/24] Train loss=0.24186542630195618
[20/24] Train loss=0.2311069220304489
Test set avg_accuracy=86.12% avg_sensitivity=62.00%, avg_specificity=94.73% avg_auc=91.29%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.245714 Test loss=0.326165 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2237231731414795
[5/24] Train loss=0.21892096102237701
[10/24] Train loss=0.2648757994174957
[15/24] Train loss=0.2481197863817215
[20/24] Train loss=0.23287628591060638
Test set avg_accuracy=83.66% avg_sensitivity=48.79%, avg_specificity=96.11% avg_auc=87.84%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.245844 Test loss=0.396724 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2264144867658615
[5/24] Train loss=0.21804405748844147
[10/24] Train loss=0.25995686650276184
[15/24] Train loss=0.2494102567434311
[20/24] Train loss=0.24605777859687805
Test set avg_accuracy=83.88% avg_sensitivity=48.29%, avg_specificity=96.59% avg_auc=88.70%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.243283 Test loss=0.388937 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.2196187525987625
[5/24] Train loss=0.21847856044769287
[10/24] Train loss=0.24989546835422516
[15/24] Train loss=0.2370537668466568
[20/24] Train loss=0.2378578633069992
Test set avg_accuracy=86.37% avg_sensitivity=71.10%, avg_specificity=91.82% avg_auc=90.99%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.238701 Test loss=0.327232 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.23289774358272552
[5/24] Train loss=0.20985083281993866
[10/24] Train loss=0.24419911205768585
[15/24] Train loss=0.23836761713027954
[20/24] Train loss=0.23452596366405487
Test set avg_accuracy=86.84% avg_sensitivity=72.69%, avg_specificity=91.89% avg_auc=91.51%
Best model saved!! Metric=16.922225852926914!!
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.237802 Test loss=0.320603 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.21625038981437683
[5/24] Train loss=0.21292056143283844
[10/24] Train loss=0.2681487500667572
[15/24] Train loss=0.24208107590675354
[20/24] Train loss=0.2272292524576187
Test set avg_accuracy=85.76% avg_sensitivity=72.34%, avg_specificity=90.55% avg_auc=91.17%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.237090 Test loss=0.330311 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.23951099812984467
[5/24] Train loss=0.22496314346790314
[10/24] Train loss=0.24515827000141144
[15/24] Train loss=0.23580805957317352
[20/24] Train loss=0.23192191123962402
Test set avg_accuracy=85.33% avg_sensitivity=66.70%, avg_specificity=91.98% avg_auc=89.94%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.237243 Test loss=0.347152 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2300732582807541
[5/24] Train loss=0.20532800257205963
[10/24] Train loss=0.26519399881362915
[15/24] Train loss=0.2504468858242035
[20/24] Train loss=0.23469583690166473
Test set avg_accuracy=85.01% avg_sensitivity=77.04%, avg_specificity=87.86% avg_auc=90.43%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.237918 Test loss=0.353583 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.20842795073986053
[5/24] Train loss=0.21309249103069305
[10/24] Train loss=0.2502613067626953
[15/24] Train loss=0.24223661422729492
[20/24] Train loss=0.22458218038082123
Test set avg_accuracy=84.02% avg_sensitivity=50.02%, avg_specificity=96.17% avg_auc=86.68%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.236349 Test loss=0.395177 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.23446941375732422
[5/24] Train loss=0.21761482954025269
[10/24] Train loss=0.24891215562820435
[15/24] Train loss=0.23776037991046906
[20/24] Train loss=0.22466155886650085
Test set avg_accuracy=86.50% avg_sensitivity=67.24%, avg_specificity=93.37% avg_auc=91.35%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.236598 Test loss=0.322915 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.22158582508563995
[5/24] Train loss=0.2102883756160736
[10/24] Train loss=0.25788819789886475
[15/24] Train loss=0.2374720722436905
[20/24] Train loss=0.22394903004169464
Test set avg_accuracy=81.13% avg_sensitivity=36.86%, avg_specificity=96.94% avg_auc=85.13%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.238062 Test loss=0.473926 Current lr=[0.000276307469034998]

[0/24] Train loss=0.22876515984535217
[5/24] Train loss=0.21299678087234497
[10/24] Train loss=0.2418229579925537
[15/24] Train loss=0.24012139439582825
[20/24] Train loss=0.22731947898864746
Test set avg_accuracy=85.60% avg_sensitivity=74.02%, avg_specificity=89.73% avg_auc=91.08%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.235493 Test loss=0.334562 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.21682047843933105
[5/24] Train loss=0.21628154814243317
[10/24] Train loss=0.24390673637390137
[15/24] Train loss=0.23181277513504028
[20/24] Train loss=0.22235597670078278
Test set avg_accuracy=85.59% avg_sensitivity=64.13%, avg_specificity=93.25% avg_auc=90.22%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.233838 Test loss=0.340310 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.20956037938594818
[5/24] Train loss=0.20579227805137634
[10/24] Train loss=0.23133501410484314
[15/24] Train loss=0.23093779385089874
[20/24] Train loss=0.223563089966774
Test set avg_accuracy=84.18% avg_sensitivity=50.22%, avg_specificity=96.31% avg_auc=88.56%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.229957 Test loss=0.375914 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.21797677874565125
[5/24] Train loss=0.21170036494731903
[10/24] Train loss=0.24047791957855225
[15/24] Train loss=0.2288486659526825
[20/24] Train loss=0.22292457520961761
Test set avg_accuracy=85.76% avg_sensitivity=61.55%, avg_specificity=94.40% avg_auc=89.31%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.228741 Test loss=0.353816 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.21106816828250885
[5/24] Train loss=0.21058256924152374
[10/24] Train loss=0.2559719681739807
[15/24] Train loss=0.2319408655166626
[20/24] Train loss=0.21696418523788452
Test set avg_accuracy=84.01% avg_sensitivity=52.25%, avg_specificity=95.35% avg_auc=88.41%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.229064 Test loss=0.376487 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.21138054132461548
[5/24] Train loss=0.2220311313867569
[10/24] Train loss=0.23628175258636475
[15/24] Train loss=0.23092932999134064
[20/24] Train loss=0.22620347142219543
Test set avg_accuracy=86.15% avg_sensitivity=62.30%, avg_specificity=94.66% avg_auc=91.25%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.231608 Test loss=0.329384 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.2157219648361206
[5/24] Train loss=0.2058047652244568
[10/24] Train loss=0.2372562140226364
[15/24] Train loss=0.2315385341644287
[20/24] Train loss=0.2248283475637436
Test set avg_accuracy=83.59% avg_sensitivity=64.77%, avg_specificity=90.32% avg_auc=88.26%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.227142 Test loss=0.373585 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.21838371455669403
[5/24] Train loss=0.2138729840517044
[10/24] Train loss=0.25381919741630554
[15/24] Train loss=0.23161061108112335
[20/24] Train loss=0.2291765809059143
Test set avg_accuracy=85.17% avg_sensitivity=57.60%, avg_specificity=95.02% avg_auc=89.52%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.230629 Test loss=0.351202 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.21370339393615723
[5/24] Train loss=0.20095086097717285
[10/24] Train loss=0.2366233915090561
[15/24] Train loss=0.23549367487430573
[20/24] Train loss=0.2225828915834427
Test set avg_accuracy=84.10% avg_sensitivity=61.95%, avg_specificity=92.01% avg_auc=87.92%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.225878 Test loss=0.380174 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.21837228536605835
[5/24] Train loss=0.2023973912000656
[10/24] Train loss=0.24608944356441498
[15/24] Train loss=0.22367851436138153
[20/24] Train loss=0.22254741191864014
Test set avg_accuracy=86.32% avg_sensitivity=64.82%, avg_specificity=93.99% avg_auc=90.35%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.226669 Test loss=0.342736 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.20640425384044647
[5/24] Train loss=0.20789435505867004
[10/24] Train loss=0.22827103734016418
[15/24] Train loss=0.2133937031030655
[20/24] Train loss=0.22291480004787445
Test set avg_accuracy=85.26% avg_sensitivity=60.91%, avg_specificity=93.96% avg_auc=89.19%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.220427 Test loss=0.358063 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.21380922198295593
[5/24] Train loss=0.20379045605659485
[10/24] Train loss=0.23845690488815308
[15/24] Train loss=0.22698521614074707
[20/24] Train loss=0.2215486615896225
Test set avg_accuracy=85.53% avg_sensitivity=69.07%, avg_specificity=91.41% avg_auc=89.90%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.221329 Test loss=0.346180 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.20822086930274963
[5/24] Train loss=0.20021401345729828
[10/24] Train loss=0.23459015786647797
[15/24] Train loss=0.22093622386455536
[20/24] Train loss=0.21985608339309692
Test set avg_accuracy=84.36% avg_sensitivity=53.09%, avg_specificity=95.53% avg_auc=87.10%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.222891 Test loss=0.387685 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.20976297557353973
[5/24] Train loss=0.20173928141593933
[10/24] Train loss=0.23895199596881866
[15/24] Train loss=0.22301287949085236
[20/24] Train loss=0.21697334945201874
Test set avg_accuracy=85.91% avg_sensitivity=66.50%, avg_specificity=92.84% avg_auc=89.78%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.219199 Test loss=0.347234 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.21231597661972046
[5/24] Train loss=0.19736261665821075
[10/24] Train loss=0.23038455843925476
[15/24] Train loss=0.2194882333278656
[20/24] Train loss=0.223969504237175
Test set avg_accuracy=85.27% avg_sensitivity=75.21%, avg_specificity=88.87% avg_auc=90.82%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.223346 Test loss=0.344248 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2050575315952301
[5/24] Train loss=0.19192178547382355
[10/24] Train loss=0.24004697799682617
[15/24] Train loss=0.22712403535842896
[20/24] Train loss=0.22858130931854248
Test set avg_accuracy=85.10% avg_sensitivity=72.54%, avg_specificity=89.59% avg_auc=90.62%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.224330 Test loss=0.344131 Current lr=[0.000224838296036774]

[0/24] Train loss=0.21624647080898285
[5/24] Train loss=0.2046249508857727
[10/24] Train loss=0.22601808607578278
[15/24] Train loss=0.22047801315784454
[20/24] Train loss=0.21505723893642426
Test set avg_accuracy=85.95% avg_sensitivity=63.14%, avg_specificity=94.10% avg_auc=89.83%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.222742 Test loss=0.347510 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.20766164362430573
[5/24] Train loss=0.1897948533296585
[10/24] Train loss=0.2274715006351471
[15/24] Train loss=0.21209479868412018
[20/24] Train loss=0.21570324897766113
Test set avg_accuracy=85.70% avg_sensitivity=71.15%, avg_specificity=90.90% avg_auc=89.89%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.215786 Test loss=0.345338 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.19733792543411255
[5/24] Train loss=0.1883278787136078
[10/24] Train loss=0.23034434020519257
[15/24] Train loss=0.21847106516361237
[20/24] Train loss=0.21507073938846588
Test set avg_accuracy=85.30% avg_sensitivity=66.90%, avg_specificity=91.87% avg_auc=89.28%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.215207 Test loss=0.355215 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.19892019033432007
[5/24] Train loss=0.18927553296089172
[10/24] Train loss=0.22046688199043274
[15/24] Train loss=0.20372632145881653
[20/24] Train loss=0.21493227779865265
Test set avg_accuracy=85.22% avg_sensitivity=62.79%, avg_specificity=93.23% avg_auc=89.22%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.212716 Test loss=0.354743 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2045620083808899
[5/24] Train loss=0.20020975172519684
[10/24] Train loss=0.2407495677471161
[15/24] Train loss=0.21275003254413605
[20/24] Train loss=0.21515808999538422
Test set avg_accuracy=84.77% avg_sensitivity=73.53%, avg_specificity=88.78% avg_auc=89.94%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.212880 Test loss=0.353100 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.19729822874069214
[5/24] Train loss=0.1956688016653061
[10/24] Train loss=0.21401269733905792
[15/24] Train loss=0.20235666632652283
[20/24] Train loss=0.20500460267066956
Test set avg_accuracy=85.31% avg_sensitivity=61.60%, avg_specificity=93.78% avg_auc=89.28%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.212886 Test loss=0.353074 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.19631825387477875
[5/24] Train loss=0.1770021915435791
[10/24] Train loss=0.21791234612464905
[15/24] Train loss=0.20892292261123657
[20/24] Train loss=0.20566675066947937
Test set avg_accuracy=85.76% avg_sensitivity=69.12%, avg_specificity=91.69% avg_auc=89.91%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.209813 Test loss=0.341147 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.19746939837932587
[5/24] Train loss=0.18765996396541595
[10/24] Train loss=0.21897707879543304
[15/24] Train loss=0.19922758638858795
[20/24] Train loss=0.2195509970188141
Test set avg_accuracy=85.20% avg_sensitivity=56.75%, avg_specificity=95.35% avg_auc=88.58%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.211064 Test loss=0.379851 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.19457274675369263
[5/24] Train loss=0.18852530419826508
[10/24] Train loss=0.22076131403446198
[15/24] Train loss=0.2070288509130478
[20/24] Train loss=0.20424869656562805
Test set avg_accuracy=84.82% avg_sensitivity=56.61%, avg_specificity=94.89% avg_auc=87.94%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.209752 Test loss=0.382325 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.20579193532466888
[5/24] Train loss=0.1891322135925293
[10/24] Train loss=0.21779663860797882
[15/24] Train loss=0.2131151407957077
[20/24] Train loss=0.19741666316986084
Test set avg_accuracy=86.32% avg_sensitivity=65.56%, avg_specificity=93.73% avg_auc=90.26%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.206219 Test loss=0.336463 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.18519847095012665
[5/24] Train loss=0.1848464161157608
[10/24] Train loss=0.21216683089733124
[15/24] Train loss=0.2032327651977539
[20/24] Train loss=0.20500101149082184
Test set avg_accuracy=85.57% avg_sensitivity=59.77%, avg_specificity=94.79% avg_auc=87.86%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.203680 Test loss=0.370960 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.18371468782424927
[5/24] Train loss=0.18762922286987305
[10/24] Train loss=0.20769767463207245
[15/24] Train loss=0.1988181471824646
[20/24] Train loss=0.20119985938072205
Test set avg_accuracy=85.60% avg_sensitivity=58.29%, avg_specificity=95.35% avg_auc=89.04%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.202369 Test loss=0.358079 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.18987742066383362
[5/24] Train loss=0.18208163976669312
[10/24] Train loss=0.20539633929729462
[15/24] Train loss=0.2066648304462433
[20/24] Train loss=0.19515395164489746
Test set avg_accuracy=86.48% avg_sensitivity=68.63%, avg_specificity=92.86% avg_auc=90.33%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.199065 Test loss=0.336138 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.19525401294231415
[5/24] Train loss=0.17936787009239197
[10/24] Train loss=0.22969236969947815
[15/24] Train loss=0.192654088139534
[20/24] Train loss=0.19852353632450104
Test set avg_accuracy=85.36% avg_sensitivity=58.49%, avg_specificity=94.96% avg_auc=87.81%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.199881 Test loss=0.380589 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1844775676727295
[5/24] Train loss=0.18298913538455963
[10/24] Train loss=0.20726704597473145
[15/24] Train loss=0.20178565382957458
[20/24] Train loss=0.18917647004127502
Test set avg_accuracy=85.65% avg_sensitivity=68.04%, avg_specificity=91.94% avg_auc=89.50%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.200308 Test loss=0.351508 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.17708754539489746
[5/24] Train loss=0.18028336763381958
[10/24] Train loss=0.20782598853111267
[15/24] Train loss=0.19568447768688202
[20/24] Train loss=0.19324946403503418
Test set avg_accuracy=84.84% avg_sensitivity=57.10%, avg_specificity=94.75% avg_auc=88.06%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.196787 Test loss=0.375332 Current lr=[0.000156543481933168]

[0/24] Train loss=0.18595504760742188
[5/24] Train loss=0.18254660069942474
[10/24] Train loss=0.202012300491333
[15/24] Train loss=0.18027034401893616
[20/24] Train loss=0.18970222771167755
Test set avg_accuracy=84.96% avg_sensitivity=57.35%, avg_specificity=94.82% avg_auc=87.24%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.191551 Test loss=0.386541 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1795850545167923
[5/24] Train loss=0.17331919074058533
[10/24] Train loss=0.18862217664718628
[15/24] Train loss=0.1921699345111847
[20/24] Train loss=0.19390609860420227
Test set avg_accuracy=86.34% avg_sensitivity=67.64%, avg_specificity=93.02% avg_auc=90.78%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.193642 Test loss=0.332073 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.17789043486118317
[5/24] Train loss=0.18630094826221466
[10/24] Train loss=0.20248445868492126
[15/24] Train loss=0.1979905664920807
[20/24] Train loss=0.18935516476631165
Test set avg_accuracy=86.34% avg_sensitivity=73.82%, avg_specificity=90.81% avg_auc=91.24%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.195666 Test loss=0.329168 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.17773476243019104
[5/24] Train loss=0.17551982402801514
[10/24] Train loss=0.19707630574703217
[15/24] Train loss=0.18424920737743378
[20/24] Train loss=0.19108343124389648
Test set avg_accuracy=86.45% avg_sensitivity=64.67%, avg_specificity=94.22% avg_auc=89.01%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.191308 Test loss=0.348845 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.17309299111366272
[5/24] Train loss=0.16822628676891327
[10/24] Train loss=0.19263723492622375
[15/24] Train loss=0.1922307014465332
[20/24] Train loss=0.1895550936460495
Test set avg_accuracy=86.73% avg_sensitivity=70.61%, avg_specificity=92.49% avg_auc=91.21%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.188811 Test loss=0.324026 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1717018336057663
[5/24] Train loss=0.16962681710720062
[10/24] Train loss=0.18802396953105927
[15/24] Train loss=0.1898675262928009
[20/24] Train loss=0.1825990080833435
Test set avg_accuracy=86.20% avg_sensitivity=71.35%, avg_specificity=91.50% avg_auc=91.02%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.185735 Test loss=0.326980 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.18191580474376678
[5/24] Train loss=0.1687970757484436
[10/24] Train loss=0.18735960125923157
[15/24] Train loss=0.1862981617450714
[20/24] Train loss=0.1850617378950119
Test set avg_accuracy=85.52% avg_sensitivity=68.98%, avg_specificity=91.43% avg_auc=90.47%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.184024 Test loss=0.341023 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.17704933881759644
[5/24] Train loss=0.16425547003746033
[10/24] Train loss=0.18496279418468475
[15/24] Train loss=0.17827780544757843
[20/24] Train loss=0.19384758174419403
Test set avg_accuracy=85.98% avg_sensitivity=72.93%, avg_specificity=90.63% avg_auc=91.35%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.185729 Test loss=0.336497 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.17038044333457947
[5/24] Train loss=0.16524004936218262
[10/24] Train loss=0.18942169845104218
[15/24] Train loss=0.1847861111164093
[20/24] Train loss=0.1827803999185562
Test set avg_accuracy=86.13% avg_sensitivity=73.68%, avg_specificity=90.58% avg_auc=91.64%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.184835 Test loss=0.328686 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.17101339995861053
[5/24] Train loss=0.16253754496574402
[10/24] Train loss=0.17676055431365967
[15/24] Train loss=0.17965929210186005
[20/24] Train loss=0.17608553171157837
Test set avg_accuracy=84.64% avg_sensitivity=76.35%, avg_specificity=87.59% avg_auc=90.99%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.177925 Test loss=0.351630 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1706710159778595
[5/24] Train loss=0.1682366132736206
[10/24] Train loss=0.17251718044281006
[15/24] Train loss=0.1771949678659439
[20/24] Train loss=0.1838090568780899
Test set avg_accuracy=86.08% avg_sensitivity=77.73%, avg_specificity=89.06% avg_auc=91.66%
Best model saved!! Metric=18.535259303883777!!
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.178879 Test loss=0.334853 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.17351795732975006
[5/24] Train loss=0.16247272491455078
[10/24] Train loss=0.1691965013742447
[15/24] Train loss=0.17671093344688416
[20/24] Train loss=0.1788259893655777
Test set avg_accuracy=84.91% avg_sensitivity=78.67%, avg_specificity=87.14% avg_auc=90.25%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.173832 Test loss=0.368029 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.166595458984375
[5/24] Train loss=0.1656733751296997
[10/24] Train loss=0.1657947599887848
[15/24] Train loss=0.18010301887989044
[20/24] Train loss=0.17956338822841644
Test set avg_accuracy=83.62% avg_sensitivity=80.95%, avg_specificity=84.57% avg_auc=90.54%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.173728 Test loss=0.383456 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.16508157551288605
[5/24] Train loss=0.16324439644813538
[10/24] Train loss=0.16756649315357208
[15/24] Train loss=0.17320509254932404
[20/24] Train loss=0.17529456317424774
Test set avg_accuracy=85.23% avg_sensitivity=73.13%, avg_specificity=89.56% avg_auc=91.01%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.171642 Test loss=0.343956 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15928295254707336
[5/24] Train loss=0.15035726130008698
[10/24] Train loss=0.1665038764476776
[15/24] Train loss=0.16666212677955627
[20/24] Train loss=0.1681193858385086
Test set avg_accuracy=85.34% avg_sensitivity=72.24%, avg_specificity=90.02% avg_auc=90.57%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.168383 Test loss=0.342758 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1583966314792633
[5/24] Train loss=0.15233203768730164
[10/24] Train loss=0.16453330218791962
[15/24] Train loss=0.16622523963451385
[20/24] Train loss=0.1698542982339859
Test set avg_accuracy=85.87% avg_sensitivity=69.27%, avg_specificity=91.80% avg_auc=90.79%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.165935 Test loss=0.341042 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.15565218031406403
[5/24] Train loss=0.15126794576644897
[10/24] Train loss=0.15930882096290588
[15/24] Train loss=0.16604188084602356
[20/24] Train loss=0.16355936229228973
Test set avg_accuracy=86.13% avg_sensitivity=72.74%, avg_specificity=90.92% avg_auc=90.64%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.162624 Test loss=0.340279 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.16279208660125732
[5/24] Train loss=0.1448298543691635
[10/24] Train loss=0.16080312430858612
[15/24] Train loss=0.15597067773342133
[20/24] Train loss=0.16394393146038055
Test set avg_accuracy=85.07% avg_sensitivity=73.68%, avg_specificity=89.13% avg_auc=90.86%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.160800 Test loss=0.347135 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1499767154455185
[5/24] Train loss=0.14462615549564362
[10/24] Train loss=0.1511596441268921
[15/24] Train loss=0.15821509063243866
[20/24] Train loss=0.1596069484949112
Test set avg_accuracy=84.45% avg_sensitivity=75.71%, avg_specificity=87.58% avg_auc=89.97%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.157845 Test loss=0.371285 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15245547890663147
[5/24] Train loss=0.14426782727241516
[10/24] Train loss=0.15211454033851624
[15/24] Train loss=0.15545395016670227
[20/24] Train loss=0.1596270501613617
Test set avg_accuracy=86.41% avg_sensitivity=71.00%, avg_specificity=91.91% avg_auc=90.80%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.156414 Test loss=0.336757 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.15404826402664185
[5/24] Train loss=0.1457962691783905
[10/24] Train loss=0.15101927518844604
[15/24] Train loss=0.15604433417320251
[20/24] Train loss=0.15766936540603638
Test set avg_accuracy=85.86% avg_sensitivity=69.62%, avg_specificity=91.66% avg_auc=90.72%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.155955 Test loss=0.341316 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14453637599945068
[5/24] Train loss=0.13934116065502167
[10/24] Train loss=0.1498742550611496
[15/24] Train loss=0.15424610674381256
[20/24] Train loss=0.15726354718208313
Test set avg_accuracy=85.59% avg_sensitivity=73.82%, avg_specificity=89.79% avg_auc=91.07%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.154103 Test loss=0.340729 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13877137005329132
[5/24] Train loss=0.13795652985572815
[10/24] Train loss=0.14684359729290009
[15/24] Train loss=0.1520647406578064
[20/24] Train loss=0.1567680984735489
Test set avg_accuracy=85.70% avg_sensitivity=75.85%, avg_specificity=89.22% avg_auc=91.16%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.152625 Test loss=0.339394 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14511102437973022
[5/24] Train loss=0.14117823541164398
[10/24] Train loss=0.1467261016368866
[15/24] Train loss=0.15157392621040344
[20/24] Train loss=0.15376955270767212
Test set avg_accuracy=85.08% avg_sensitivity=72.54%, avg_specificity=89.56% avg_auc=90.93%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.151269 Test loss=0.345142 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14211998879909515
[5/24] Train loss=0.13810458779335022
[10/24] Train loss=0.1499483287334442
[15/24] Train loss=0.14894969761371613
[20/24] Train loss=0.15706267952919006
Test set avg_accuracy=85.21% avg_sensitivity=73.68%, avg_specificity=89.33% avg_auc=91.11%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.148828 Test loss=0.343282 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1437710076570511
[5/24] Train loss=0.1362883597612381
[10/24] Train loss=0.14177966117858887
[15/24] Train loss=0.1444828063249588
[20/24] Train loss=0.15314780175685883
Test set avg_accuracy=85.60% avg_sensitivity=72.84%, avg_specificity=90.16% avg_auc=91.05%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.147856 Test loss=0.343660 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13953645527362823
[5/24] Train loss=0.13475485146045685
[10/24] Train loss=0.14144685864448547
[15/24] Train loss=0.1457858681678772
[20/24] Train loss=0.1494108885526657
Test set avg_accuracy=86.24% avg_sensitivity=74.62%, avg_specificity=90.39% avg_auc=91.42%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.145826 Test loss=0.332996 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.14193406701087952
[5/24] Train loss=0.13605457544326782
[10/24] Train loss=0.14302274584770203
[15/24] Train loss=0.14074380695819855
[20/24] Train loss=0.14892953634262085
Test set avg_accuracy=86.33% avg_sensitivity=74.12%, avg_specificity=90.69% avg_auc=91.33%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.144686 Test loss=0.333630 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13677988946437836
[5/24] Train loss=0.12875336408615112
[10/24] Train loss=0.1390296220779419
[15/24] Train loss=0.14681880176067352
[20/24] Train loss=0.14890606701374054
Test set avg_accuracy=86.03% avg_sensitivity=73.33%, avg_specificity=90.56% avg_auc=91.01%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.143348 Test loss=0.338090 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13470560312271118
[5/24] Train loss=0.13145579397678375
[10/24] Train loss=0.14178581535816193
[15/24] Train loss=0.14600490033626556
[20/24] Train loss=0.14552031457424164
Test set avg_accuracy=86.05% avg_sensitivity=73.97%, avg_specificity=90.37% avg_auc=91.44%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.142105 Test loss=0.332517 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13466109335422516
[5/24] Train loss=0.13071763515472412
[10/24] Train loss=0.1356954574584961
[15/24] Train loss=0.1414232701063156
[20/24] Train loss=0.14448201656341553
Test set avg_accuracy=86.16% avg_sensitivity=73.38%, avg_specificity=90.72% avg_auc=91.03%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.140920 Test loss=0.338005 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13303954899311066
[5/24] Train loss=0.1284056156873703
[10/24] Train loss=0.13615375757217407
[15/24] Train loss=0.13840895891189575
[20/24] Train loss=0.14194700121879578
Test set avg_accuracy=85.62% avg_sensitivity=71.75%, avg_specificity=90.58% avg_auc=90.53%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.139416 Test loss=0.341658 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13059908151626587
[5/24] Train loss=0.1328389197587967
[10/24] Train loss=0.1370301991701126
[15/24] Train loss=0.13782095909118652
[20/24] Train loss=0.14183726906776428
Test set avg_accuracy=85.90% avg_sensitivity=73.82%, avg_specificity=90.21% avg_auc=91.49%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.139706 Test loss=0.334138 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13120228052139282
[5/24] Train loss=0.12999959290027618
[10/24] Train loss=0.13345660269260406
[15/24] Train loss=0.13515536487102509
[20/24] Train loss=0.14216001331806183
Test set avg_accuracy=86.38% avg_sensitivity=74.76%, avg_specificity=90.53% avg_auc=91.54%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.138978 Test loss=0.330971 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12955279648303986
[5/24] Train loss=0.12702472507953644
[10/24] Train loss=0.134028360247612
[15/24] Train loss=0.13782930374145508
[20/24] Train loss=0.14274118840694427
Test set avg_accuracy=85.78% avg_sensitivity=73.48%, avg_specificity=90.17% avg_auc=91.24%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.138112 Test loss=0.335995 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12846872210502625
[5/24] Train loss=0.12771198153495789
[10/24] Train loss=0.13629133999347687
[15/24] Train loss=0.13575077056884766
[20/24] Train loss=0.14321988821029663
Test set avg_accuracy=85.91% avg_sensitivity=73.63%, avg_specificity=90.30% avg_auc=91.56%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.137871 Test loss=0.332323 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13077916204929352
[5/24] Train loss=0.12705397605895996
[10/24] Train loss=0.13250166177749634
[15/24] Train loss=0.1357678920030594
[20/24] Train loss=0.13921496272087097
Test set avg_accuracy=85.90% avg_sensitivity=76.50%, avg_specificity=89.26% avg_auc=91.51%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.136823 Test loss=0.336453 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12987230718135834
[5/24] Train loss=0.12413564324378967
[10/24] Train loss=0.13496634364128113
[15/24] Train loss=0.13624711334705353
[20/24] Train loss=0.13902652263641357
Test set avg_accuracy=85.92% avg_sensitivity=74.37%, avg_specificity=90.05% avg_auc=91.35%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.135915 Test loss=0.334112 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1281178593635559
[5/24] Train loss=0.12636332213878632
[10/24] Train loss=0.12833403050899506
[15/24] Train loss=0.13415947556495667
[20/24] Train loss=0.1391044557094574
Test set avg_accuracy=86.17% avg_sensitivity=75.80%, avg_specificity=89.87% avg_auc=91.68%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.134644 Test loss=0.331472 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1275370717048645
[5/24] Train loss=0.12182354927062988
[10/24] Train loss=0.1304616928100586
[15/24] Train loss=0.13247200846672058
[20/24] Train loss=0.13691477477550507
Test set avg_accuracy=86.12% avg_sensitivity=73.87%, avg_specificity=90.49% avg_auc=91.61%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.133373 Test loss=0.330021 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12881843745708466
[5/24] Train loss=0.12252690643072128
[10/24] Train loss=0.12870429456233978
[15/24] Train loss=0.13425670564174652
[20/24] Train loss=0.140728160738945
Test set avg_accuracy=86.09% avg_sensitivity=74.22%, avg_specificity=90.33% avg_auc=91.56%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.133222 Test loss=0.330197 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12682513892650604
[5/24] Train loss=0.12315372377634048
[10/24] Train loss=0.12923792004585266
[15/24] Train loss=0.13365644216537476
[20/24] Train loss=0.13857285678386688
Test set avg_accuracy=85.78% avg_sensitivity=73.68%, avg_specificity=90.10% avg_auc=91.54%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.132948 Test loss=0.332689 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12429820746183395
[5/24] Train loss=0.12254127860069275
[10/24] Train loss=0.12664775550365448
[15/24] Train loss=0.13366034626960754
[20/24] Train loss=0.134796604514122
Test set avg_accuracy=85.79% avg_sensitivity=73.73%, avg_specificity=90.10% avg_auc=91.26%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.132316 Test loss=0.335723 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1254645437002182
[5/24] Train loss=0.1234297975897789
[10/24] Train loss=0.12873782217502594
[15/24] Train loss=0.13355785608291626
[20/24] Train loss=0.13719578087329865
Test set avg_accuracy=86.00% avg_sensitivity=73.82%, avg_specificity=90.35% avg_auc=91.43%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.132359 Test loss=0.334070 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12474877387285233
[5/24] Train loss=0.12254823744297028
[10/24] Train loss=0.13119977712631226
[15/24] Train loss=0.1302241086959839
[20/24] Train loss=0.1359599083662033
Test set avg_accuracy=86.02% avg_sensitivity=73.82%, avg_specificity=90.37% avg_auc=91.45%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.131721 Test loss=0.332590 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12316686660051346
[5/24] Train loss=0.11967282742261887
[10/24] Train loss=0.12678390741348267
[15/24] Train loss=0.1305847465991974
[20/24] Train loss=0.1361159086227417
Test set avg_accuracy=85.94% avg_sensitivity=73.73%, avg_specificity=90.30% avg_auc=91.55%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.131206 Test loss=0.331949 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1231018528342247
[5/24] Train loss=0.12014078348875046
[10/24] Train loss=0.12754929065704346
[15/24] Train loss=0.13168545067310333
[20/24] Train loss=0.13633111119270325
Test set avg_accuracy=85.87% avg_sensitivity=73.97%, avg_specificity=90.12% avg_auc=91.47%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.131193 Test loss=0.333307 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12294752895832062
[5/24] Train loss=0.12007543444633484
[10/24] Train loss=0.12662287056446075
[15/24] Train loss=0.13238398730754852
[20/24] Train loss=0.13687996566295624
Test set avg_accuracy=85.90% avg_sensitivity=73.78%, avg_specificity=90.23% avg_auc=91.42%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.130900 Test loss=0.333482 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12559664249420166
[5/24] Train loss=0.12347935885190964
[10/24] Train loss=0.12700200080871582
[15/24] Train loss=0.13302740454673767
[20/24] Train loss=0.1346883475780487
Test set avg_accuracy=85.96% avg_sensitivity=73.92%, avg_specificity=90.26% avg_auc=91.50%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.131255 Test loss=0.332476 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12493477761745453
[5/24] Train loss=0.12321966886520386
[10/24] Train loss=0.13033926486968994
[15/24] Train loss=0.1326778382062912
[20/24] Train loss=0.13571850955486298
Test set avg_accuracy=85.85% avg_sensitivity=73.63%, avg_specificity=90.21% avg_auc=91.48%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.131235 Test loss=0.332714 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12456244230270386
[5/24] Train loss=0.12066565454006195
[10/24] Train loss=0.13058319687843323
[15/24] Train loss=0.1306472271680832
[20/24] Train loss=0.135877326130867
Test set avg_accuracy=85.91% avg_sensitivity=74.02%, avg_specificity=90.16% avg_auc=91.47%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.131025 Test loss=0.333231 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12457574158906937
[5/24] Train loss=0.12334277480840683
[10/24] Train loss=0.12726306915283203
[15/24] Train loss=0.13287624716758728
[20/24] Train loss=0.13560143113136292
Test set avg_accuracy=85.87% avg_sensitivity=73.78%, avg_specificity=90.19% avg_auc=91.46%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.130977 Test loss=0.333128 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12293662130832672
[5/24] Train loss=0.12247253209352493
[10/24] Train loss=0.13047756254673004
[15/24] Train loss=0.13093987107276917
[20/24] Train loss=0.13321106135845184
Test set avg_accuracy=85.86% avg_sensitivity=73.92%, avg_specificity=90.12% avg_auc=91.47%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.130613 Test loss=0.333272 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1250419020652771
[5/24] Train loss=0.12159380316734314
[10/24] Train loss=0.1283760815858841
[15/24] Train loss=0.1325952112674713
[20/24] Train loss=0.1362013816833496
Test set avg_accuracy=85.87% avg_sensitivity=73.92%, avg_specificity=90.14% avg_auc=91.47%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.131043 Test loss=0.333359 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=86.08% sen=77.73%, spe=89.06%, auc=91.66%!
Fold[1] Avg_overlap=0.68%(±0.22180039017426298)
[0/24] Train loss=0.7252023220062256
[5/24] Train loss=0.7161533832550049
[10/24] Train loss=0.7155381441116333
[15/24] Train loss=0.7024967670440674
[20/24] Train loss=0.699571430683136
Test set avg_accuracy=50.08% avg_sensitivity=61.76%, avg_specificity=46.19% avg_auc=55.74%
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.708994 Test loss=0.707308 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6898453235626221
[5/24] Train loss=0.6921035647392273
[10/24] Train loss=0.6853403449058533
[15/24] Train loss=0.6806034445762634
[20/24] Train loss=0.6729578971862793
Test set avg_accuracy=60.44% avg_sensitivity=58.84%, avg_specificity=60.98% avg_auc=64.27%
Best model saved!! Metric=-81.46817007714793!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.683816 Test loss=0.645434 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6679404973983765
[5/24] Train loss=0.6644114255905151
[10/24] Train loss=0.6669800877571106
[15/24] Train loss=0.6613138914108276
[20/24] Train loss=0.6455082297325134
Test set avg_accuracy=68.32% avg_sensitivity=58.42%, avg_specificity=71.61% avg_auc=70.91%
Best model saved!! Metric=-56.72999864702818!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.664703 Test loss=0.604381 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6432827115058899
[5/24] Train loss=0.6425681710243225
[10/24] Train loss=0.6359935998916626
[15/24] Train loss=0.6332151293754578
[20/24] Train loss=0.6227261424064636
Test set avg_accuracy=71.90% avg_sensitivity=59.83%, avg_specificity=75.92% avg_auc=74.27%
Best model saved!! Metric=-44.08018152508118!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.641524 Test loss=0.577870 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6156100630760193
[5/24] Train loss=0.6180446743965149
[10/24] Train loss=0.608002781867981
[15/24] Train loss=0.6036121845245361
[20/24] Train loss=0.5956345200538635
Test set avg_accuracy=73.16% avg_sensitivity=62.70%, avg_specificity=76.64% avg_auc=76.64%
Best model saved!! Metric=-36.8482691489059!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.617067 Test loss=0.555069 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5937351584434509
[5/24] Train loss=0.5960411429405212
[10/24] Train loss=0.5846672654151917
[15/24] Train loss=0.5811821818351746
[20/24] Train loss=0.5704904198646545
Test set avg_accuracy=74.49% avg_sensitivity=65.41%, avg_specificity=77.51% avg_auc=78.67%
Best model saved!! Metric=-29.90963583452907!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.594532 Test loss=0.534852 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5655612945556641
[5/24] Train loss=0.5604261159896851
[10/24] Train loss=0.5558802485466003
[15/24] Train loss=0.5537638664245605
[20/24] Train loss=0.5435447692871094
Test set avg_accuracy=75.49% avg_sensitivity=68.18%, avg_specificity=77.93% avg_auc=80.47%
Best model saved!! Metric=-23.929163481889077!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.567707 Test loss=0.515552 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5357404351234436
[5/24] Train loss=0.529621422290802
[10/24] Train loss=0.526610255241394
[15/24] Train loss=0.5277812480926514
[20/24] Train loss=0.510348379611969
Test set avg_accuracy=77.11% avg_sensitivity=68.49%, avg_specificity=79.98% avg_auc=82.25%
Best model saved!! Metric=-18.170073129836595!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.541336 Test loss=0.489962 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5092700123786926
[5/24] Train loss=0.5016195774078369
[10/24] Train loss=0.5002715587615967
[15/24] Train loss=0.4989408552646637
[20/24] Train loss=0.4769257605075836
Test set avg_accuracy=78.67% avg_sensitivity=70.11%, avg_specificity=81.52% avg_auc=84.02%
Best model saved!! Metric=-11.676646964493699!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.513000 Test loss=0.469008 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.48020800948143005
[5/24] Train loss=0.4666502773761749
[10/24] Train loss=0.4677387475967407
[15/24] Train loss=0.47312912344932556
[20/24] Train loss=0.4481520652770996
Test set avg_accuracy=80.17% avg_sensitivity=70.58%, avg_specificity=83.36% avg_auc=85.65%
Best model saved!! Metric=-6.238692075772136!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.483303 Test loss=0.440810 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.451415479183197
[5/24] Train loss=0.4421985149383545
[10/24] Train loss=0.4465186595916748
[15/24] Train loss=0.4441034495830536
[20/24] Train loss=0.41971921920776367
Test set avg_accuracy=81.60% avg_sensitivity=71.78%, avg_specificity=84.87% avg_auc=86.70%
Best model saved!! Metric=-1.0539715035017139!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.455826 Test loss=0.423384 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4351470172405243
[5/24] Train loss=0.41134417057037354
[10/24] Train loss=0.4178531765937805
[15/24] Train loss=0.42015179991722107
[20/24] Train loss=0.3934595286846161
Test set avg_accuracy=82.80% avg_sensitivity=72.56%, avg_specificity=86.21% avg_auc=87.71%
Best model saved!! Metric=3.2715726966061567!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.432173 Test loss=0.403424 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4148542582988739
[5/24] Train loss=0.39525851607322693
[10/24] Train loss=0.40613043308258057
[15/24] Train loss=0.4028557240962982
[20/24] Train loss=0.37372729182243347
Test set avg_accuracy=83.70% avg_sensitivity=69.85%, avg_specificity=88.30% avg_auc=88.28%
Best model saved!! Metric=4.13192072055277!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.411482 Test loss=0.383515 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.39109495282173157
[5/24] Train loss=0.3706991374492645
[10/24] Train loss=0.3799450993537903
[15/24] Train loss=0.38638415932655334
[20/24] Train loss=0.354875385761261
Test set avg_accuracy=84.11% avg_sensitivity=66.88%, avg_specificity=89.85% avg_auc=88.73%
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.394679 Test loss=0.369236 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3711005449295044
[5/24] Train loss=0.352287232875824
[10/24] Train loss=0.36633309721946716
[15/24] Train loss=0.3687448501586914
[20/24] Train loss=0.3367721140384674
Test set avg_accuracy=84.23% avg_sensitivity=68.70%, avg_specificity=89.40% avg_auc=89.07%
Best model saved!! Metric=5.402201596523156!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.377711 Test loss=0.362759 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.361303448677063
[5/24] Train loss=0.3406310975551605
[10/24] Train loss=0.35684844851493835
[15/24] Train loss=0.3554636538028717
[20/24] Train loss=0.315311461687088
Test set avg_accuracy=84.56% avg_sensitivity=65.47%, avg_specificity=90.91% avg_auc=89.57%
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.363928 Test loss=0.350832 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3457920253276825
[5/24] Train loss=0.3286343514919281
[10/24] Train loss=0.34802940487861633
[15/24] Train loss=0.34389528632164
[20/24] Train loss=0.3056514263153076
Test set avg_accuracy=84.48% avg_sensitivity=67.61%, avg_specificity=90.09% avg_auc=89.87%
Best model saved!! Metric=6.045689963748941!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.354094 Test loss=0.348000 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3348091244697571
[5/24] Train loss=0.3170510232448578
[10/24] Train loss=0.3421836495399475
[15/24] Train loss=0.3352124094963074
[20/24] Train loss=0.29613831639289856
Test set avg_accuracy=84.64% avg_sensitivity=64.32%, avg_specificity=91.39% avg_auc=90.00%
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.343329 Test loss=0.342406 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3275662362575531
[5/24] Train loss=0.30623000860214233
[10/24] Train loss=0.3292444348335266
[15/24] Train loss=0.327894926071167
[20/24] Train loss=0.2901184856891632
Test set avg_accuracy=84.91% avg_sensitivity=60.15%, avg_specificity=93.15% avg_auc=90.29%
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.333741 Test loss=0.336055 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.31794866919517517
[5/24] Train loss=0.2974579334259033
[10/24] Train loss=0.3267008662223816
[15/24] Train loss=0.32532280683517456
[20/24] Train loss=0.2883531153202057
Test set avg_accuracy=85.04% avg_sensitivity=57.17%, avg_specificity=94.31% avg_auc=90.58%
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.325798 Test loss=0.334667 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3132413923740387
[5/24] Train loss=0.3004573583602905
[10/24] Train loss=0.310854971408844
[15/24] Train loss=0.31183016300201416
[20/24] Train loss=0.27597975730895996
Test set avg_accuracy=85.57% avg_sensitivity=57.75%, avg_specificity=94.83% avg_auc=91.15%
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.316926 Test loss=0.328037 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.30285897850990295
[5/24] Train loss=0.28719761967658997
[10/24] Train loss=0.31523460149765015
[15/24] Train loss=0.3092314600944519
[20/24] Train loss=0.2732667028903961
Test set avg_accuracy=85.81% avg_sensitivity=57.64%, avg_specificity=95.18% avg_auc=91.20%
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.311198 Test loss=0.326115 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2966354489326477
[5/24] Train loss=0.2784021496772766
[10/24] Train loss=0.3064830005168915
[15/24] Train loss=0.30193522572517395
[20/24] Train loss=0.2673019468784332
Test set avg_accuracy=85.22% avg_sensitivity=51.38%, avg_specificity=96.48% avg_auc=90.11%
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.305464 Test loss=0.350044 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2981778085231781
[5/24] Train loss=0.2711791396141052
[10/24] Train loss=0.3094087243080139
[15/24] Train loss=0.29433420300483704
[20/24] Train loss=0.26132726669311523
Test set avg_accuracy=85.79% avg_sensitivity=57.85%, avg_specificity=95.09% avg_auc=91.86%
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.300438 Test loss=0.316925 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.29094040393829346
[5/24] Train loss=0.27246034145355225
[10/24] Train loss=0.3006044924259186
[15/24] Train loss=0.2898372709751129
[20/24] Train loss=0.26499873399734497
Test set avg_accuracy=85.77% avg_sensitivity=56.39%, avg_specificity=95.54% avg_auc=91.60%
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.295962 Test loss=0.320970 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2798336148262024
[5/24] Train loss=0.26539409160614014
[10/24] Train loss=0.29698240756988525
[15/24] Train loss=0.28915107250213623
[20/24] Train loss=0.2525580823421478
Test set avg_accuracy=85.10% avg_sensitivity=49.45%, avg_specificity=96.96% avg_auc=90.71%
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.290485 Test loss=0.342037 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.27934277057647705
[5/24] Train loss=0.26916149258613586
[10/24] Train loss=0.2979227304458618
[15/24] Train loss=0.2844429612159729
[20/24] Train loss=0.2484801560640335
Test set avg_accuracy=86.05% avg_sensitivity=56.39%, avg_specificity=95.92% avg_auc=91.50%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.289295 Test loss=0.322056 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.27048659324645996
[5/24] Train loss=0.2511262893676758
[10/24] Train loss=0.29671376943588257
[15/24] Train loss=0.2738029658794403
[20/24] Train loss=0.2456202656030655
Test set avg_accuracy=85.14% avg_sensitivity=48.41%, avg_specificity=97.36% avg_auc=91.56%
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.283865 Test loss=0.338259 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2774117887020111
[5/24] Train loss=0.2573317289352417
[10/24] Train loss=0.292499303817749
[15/24] Train loss=0.2779810130596161
[20/24] Train loss=0.23976446688175201
Test set avg_accuracy=85.94% avg_sensitivity=56.23%, avg_specificity=95.82% avg_auc=91.25%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.281261 Test loss=0.324928 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.26008614897727966
[5/24] Train loss=0.24924731254577637
[10/24] Train loss=0.29228416085243225
[15/24] Train loss=0.2656577527523041
[20/24] Train loss=0.24411247670650482
Test set avg_accuracy=83.61% avg_sensitivity=40.58%, avg_specificity=97.92% avg_auc=89.45%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.278646 Test loss=0.378264 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2794646620750427
[5/24] Train loss=0.25210148096084595
[10/24] Train loss=0.2853904962539673
[15/24] Train loss=0.27392059564590454
[20/24] Train loss=0.24760888516902924
Test set avg_accuracy=84.93% avg_sensitivity=48.51%, avg_specificity=97.05% avg_auc=90.70%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.278377 Test loss=0.346642 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.26545998454093933
[5/24] Train loss=0.24657458066940308
[10/24] Train loss=0.2919030785560608
[15/24] Train loss=0.26581016182899475
[20/24] Train loss=0.24383677542209625
Test set avg_accuracy=83.76% avg_sensitivity=40.38%, avg_specificity=98.20% avg_auc=89.98%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.274211 Test loss=0.373521 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.27595198154449463
[5/24] Train loss=0.23728206753730774
[10/24] Train loss=0.2772149443626404
[15/24] Train loss=0.2665964663028717
[20/24] Train loss=0.24150805175304413
Test set avg_accuracy=83.97% avg_sensitivity=41.84%, avg_specificity=97.99% avg_auc=89.78%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.272433 Test loss=0.365660 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.26312822103500366
[5/24] Train loss=0.23769629001617432
[10/24] Train loss=0.273334264755249
[15/24] Train loss=0.26311469078063965
[20/24] Train loss=0.24411094188690186
Test set avg_accuracy=83.18% avg_sensitivity=36.98%, avg_specificity=98.54% avg_auc=89.52%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.272191 Test loss=0.387007 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2560339570045471
[5/24] Train loss=0.23525725305080414
[10/24] Train loss=0.28489044308662415
[15/24] Train loss=0.2605694830417633
[20/24] Train loss=0.23355881869792938
Test set avg_accuracy=86.39% avg_sensitivity=65.05%, avg_specificity=93.49% avg_auc=91.01%
Best model saved!! Metric=9.943274601582331!!
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.270191 Test loss=0.320908 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.25791648030281067
[5/24] Train loss=0.24391846358776093
[10/24] Train loss=0.2779689431190491
[15/24] Train loss=0.2589723765850067
[20/24] Train loss=0.23579466342926025
Test set avg_accuracy=85.36% avg_sensitivity=51.85%, avg_specificity=96.51% avg_auc=90.85%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.267066 Test loss=0.333901 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.25045275688171387
[5/24] Train loss=0.22644445300102234
[10/24] Train loss=0.2737652063369751
[15/24] Train loss=0.25480106472969055
[20/24] Train loss=0.2380453199148178
Test set avg_accuracy=86.00% avg_sensitivity=61.45%, avg_specificity=94.17% avg_auc=91.35%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.261569 Test loss=0.316657 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2582509219646454
[5/24] Train loss=0.23233985900878906
[10/24] Train loss=0.26897382736206055
[15/24] Train loss=0.2541322410106659
[20/24] Train loss=0.23979592323303223
Test set avg_accuracy=83.83% avg_sensitivity=41.89%, avg_specificity=97.78% avg_auc=88.44%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.263470 Test loss=0.380821 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2519441545009613
[5/24] Train loss=0.22474436461925507
[10/24] Train loss=0.2688837945461273
[15/24] Train loss=0.25501638650894165
[20/24] Train loss=0.23130764067173004
Test set avg_accuracy=85.10% avg_sensitivity=55.76%, avg_specificity=94.86% avg_auc=90.55%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.262710 Test loss=0.333233 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.25187551975250244
[5/24] Train loss=0.238548144698143
[10/24] Train loss=0.2649591267108917
[15/24] Train loss=0.25415635108947754
[20/24] Train loss=0.23181191086769104
Test set avg_accuracy=84.30% avg_sensitivity=45.54%, avg_specificity=97.19% avg_auc=89.79%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.261440 Test loss=0.357891 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.25111207365989685
[5/24] Train loss=0.23061268031597137
[10/24] Train loss=0.27926138043403625
[15/24] Train loss=0.2516341805458069
[20/24] Train loss=0.23720963299274445
Test set avg_accuracy=85.52% avg_sensitivity=55.76%, avg_specificity=95.42% avg_auc=90.89%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.262794 Test loss=0.327416 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2561630308628082
[5/24] Train loss=0.2328599989414215
[10/24] Train loss=0.27435094118118286
[15/24] Train loss=0.24870207905769348
[20/24] Train loss=0.22139722108840942
Test set avg_accuracy=86.02% avg_sensitivity=63.75%, avg_specificity=93.42% avg_auc=91.48%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.258017 Test loss=0.314070 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.23918230831623077
[5/24] Train loss=0.23578672111034393
[10/24] Train loss=0.25316962599754333
[15/24] Train loss=0.25546905398368835
[20/24] Train loss=0.23223933577537537
Test set avg_accuracy=84.19% avg_sensitivity=49.50%, avg_specificity=95.73% avg_auc=87.30%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.255006 Test loss=0.382833 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.24062895774841309
[5/24] Train loss=0.2313631922006607
[10/24] Train loss=0.261087566614151
[15/24] Train loss=0.23127876222133636
[20/24] Train loss=0.23238138854503632
Test set avg_accuracy=85.01% avg_sensitivity=68.75%, avg_specificity=90.42% avg_auc=90.36%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.253818 Test loss=0.333912 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2513757646083832
[5/24] Train loss=0.2280893474817276
[10/24] Train loss=0.25968414545059204
[15/24] Train loss=0.23865261673927307
[20/24] Train loss=0.22457550466060638
Test set avg_accuracy=85.69% avg_sensitivity=62.02%, avg_specificity=93.56% avg_auc=90.77%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.255040 Test loss=0.322687 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.25152215361595154
[5/24] Train loss=0.24477319419384003
[10/24] Train loss=0.2574338912963867
[15/24] Train loss=0.25239312648773193
[20/24] Train loss=0.23579031229019165
Test set avg_accuracy=84.83% avg_sensitivity=49.19%, avg_specificity=96.69% avg_auc=89.35%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.256913 Test loss=0.360375 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.23721912503242493
[5/24] Train loss=0.22325871884822845
[10/24] Train loss=0.253134161233902
[15/24] Train loss=0.24519497156143188
[20/24] Train loss=0.22687199711799622
Test set avg_accuracy=85.33% avg_sensitivity=64.48%, avg_specificity=92.26% avg_auc=89.70%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.252214 Test loss=0.338303 Current lr=[0.000299720220882401]

[0/24] Train loss=0.24037791788578033
[5/24] Train loss=0.2348109632730484
[10/24] Train loss=0.26420143246650696
[15/24] Train loss=0.240584135055542
[20/24] Train loss=0.22307726740837097
Test set avg_accuracy=84.32% avg_sensitivity=49.40%, avg_specificity=95.94% avg_auc=88.84%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.252276 Test loss=0.360532 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2460794299840927
[5/24] Train loss=0.23374730348587036
[10/24] Train loss=0.27079254388809204
[15/24] Train loss=0.23514755070209503
[20/24] Train loss=0.2272121161222458
Test set avg_accuracy=84.78% avg_sensitivity=54.30%, avg_specificity=94.92% avg_auc=90.33%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.251620 Test loss=0.339960 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2375885546207428
[5/24] Train loss=0.23374876379966736
[10/24] Train loss=0.2593100666999817
[15/24] Train loss=0.23593813180923462
[20/24] Train loss=0.22351571917533875
Test set avg_accuracy=85.44% avg_sensitivity=64.58%, avg_specificity=92.38% avg_auc=90.21%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.248860 Test loss=0.331824 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.24030819535255432
[5/24] Train loss=0.2308986783027649
[10/24] Train loss=0.2517664134502411
[15/24] Train loss=0.23862655460834503
[20/24] Train loss=0.22293011844158173
Test set avg_accuracy=85.66% avg_sensitivity=57.75%, avg_specificity=94.95% avg_auc=90.53%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.247797 Test loss=0.331529 Current lr=[0.000297555943323901]

[0/24] Train loss=0.22367849946022034
[5/24] Train loss=0.2214708775281906
[10/24] Train loss=0.2572612762451172
[15/24] Train loss=0.22827096283435822
[20/24] Train loss=0.21395789086818695
Test set avg_accuracy=85.30% avg_sensitivity=57.12%, avg_specificity=94.67% avg_auc=90.31%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.242348 Test loss=0.330476 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2227649986743927
[5/24] Train loss=0.21194426715373993
[10/24] Train loss=0.24004516005516052
[15/24] Train loss=0.2295069396495819
[20/24] Train loss=0.21866141259670258
Test set avg_accuracy=85.61% avg_sensitivity=57.43%, avg_specificity=94.99% avg_auc=90.98%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.241381 Test loss=0.324149 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.22727157175540924
[5/24] Train loss=0.21877801418304443
[10/24] Train loss=0.25214752554893494
[15/24] Train loss=0.21790200471878052
[20/24] Train loss=0.2178565263748169
Test set avg_accuracy=85.01% avg_sensitivity=51.43%, avg_specificity=96.18% avg_auc=89.01%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.240470 Test loss=0.354002 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.23078925907611847
[5/24] Train loss=0.2205187827348709
[10/24] Train loss=0.2415332794189453
[15/24] Train loss=0.23269467055797577
[20/24] Train loss=0.21239009499549866
Test set avg_accuracy=85.82% avg_sensitivity=69.12%, avg_specificity=91.38% avg_auc=91.06%
Best model saved!! Metric=11.378355819718706!!
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.242464 Test loss=0.328023 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.23863591253757477
[5/24] Train loss=0.2248828113079071
[10/24] Train loss=0.2513766288757324
[15/24] Train loss=0.23241868615150452
[20/24] Train loss=0.22143463790416718
Test set avg_accuracy=82.62% avg_sensitivity=37.61%, avg_specificity=97.59% avg_auc=86.77%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.242276 Test loss=0.409365 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.245303675532341
[5/24] Train loss=0.21985916793346405
[10/24] Train loss=0.24375906586647034
[15/24] Train loss=0.22158583998680115
[20/24] Train loss=0.2158171832561493
Test set avg_accuracy=85.65% avg_sensitivity=66.46%, avg_specificity=92.04% avg_auc=91.19%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.237905 Test loss=0.321673 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2301885336637497
[5/24] Train loss=0.21732665598392487
[10/24] Train loss=0.2501205503940582
[15/24] Train loss=0.21418599784374237
[20/24] Train loss=0.22450445592403412
Test set avg_accuracy=85.68% avg_sensitivity=57.28%, avg_specificity=95.12% avg_auc=88.10%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.232744 Test loss=0.351321 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2263370007276535
[5/24] Train loss=0.2185295820236206
[10/24] Train loss=0.23600150644779205
[15/24] Train loss=0.23775672912597656
[20/24] Train loss=0.2139144092798233
Test set avg_accuracy=85.62% avg_sensitivity=59.73%, avg_specificity=94.24% avg_auc=90.28%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.238062 Test loss=0.337180 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.24632206559181213
[5/24] Train loss=0.21670380234718323
[10/24] Train loss=0.24983930587768555
[15/24] Train loss=0.2224743366241455
[20/24] Train loss=0.205707386136055
Test set avg_accuracy=86.20% avg_sensitivity=56.49%, avg_specificity=96.08% avg_auc=90.26%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.235758 Test loss=0.332985 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.21630685031414032
[5/24] Train loss=0.2164054661989212
[10/24] Train loss=0.2366667538881302
[15/24] Train loss=0.2367802858352661
[20/24] Train loss=0.21345552802085876
Test set avg_accuracy=85.77% avg_sensitivity=56.96%, avg_specificity=95.35% avg_auc=90.55%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.233839 Test loss=0.330299 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.22511011362075806
[5/24] Train loss=0.21815761923789978
[10/24] Train loss=0.22788439691066742
[15/24] Train loss=0.22719331085681915
[20/24] Train loss=0.21101485192775726
Test set avg_accuracy=84.93% avg_sensitivity=50.81%, avg_specificity=96.29% avg_auc=89.73%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.229862 Test loss=0.355718 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.21994709968566895
[5/24] Train loss=0.21248143911361694
[10/24] Train loss=0.22738057374954224
[15/24] Train loss=0.22057422995567322
[20/24] Train loss=0.20430517196655273
Test set avg_accuracy=85.59% avg_sensitivity=55.35%, avg_specificity=95.64% avg_auc=89.04%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.230101 Test loss=0.347394 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2158641666173935
[5/24] Train loss=0.2206527441740036
[10/24] Train loss=0.23583753407001495
[15/24] Train loss=0.21403230726718903
[20/24] Train loss=0.20765182375907898
Test set avg_accuracy=86.81% avg_sensitivity=68.28%, avg_specificity=92.97% avg_auc=91.68%
Best model saved!! Metric=13.743351219540983!!
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.226603 Test loss=0.308137 Current lr=[0.000276307469034998]

[0/24] Train loss=0.21727193892002106
[5/24] Train loss=0.20607990026474
[10/24] Train loss=0.21765929460525513
[15/24] Train loss=0.2096022069454193
[20/24] Train loss=0.2113395482301712
Test set avg_accuracy=86.73% avg_sensitivity=65.26%, avg_specificity=93.87% avg_auc=90.81%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.223446 Test loss=0.320069 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.2172204554080963
[5/24] Train loss=0.2286817729473114
[10/24] Train loss=0.22989186644554138
[15/24] Train loss=0.220075324177742
[20/24] Train loss=0.2124645709991455
Test set avg_accuracy=85.18% avg_sensitivity=52.37%, avg_specificity=96.10% avg_auc=89.20%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.228634 Test loss=0.356237 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.21419893205165863
[5/24] Train loss=0.20991817116737366
[10/24] Train loss=0.2264462262392044
[15/24] Train loss=0.2172890156507492
[20/24] Train loss=0.2127845287322998
Test set avg_accuracy=84.70% avg_sensitivity=52.63%, avg_specificity=95.37% avg_auc=88.99%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.225895 Test loss=0.364957 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2049490362405777
[5/24] Train loss=0.211874857544899
[10/24] Train loss=0.23595838248729706
[15/24] Train loss=0.2154090404510498
[20/24] Train loss=0.20548614859580994
Test set avg_accuracy=86.05% avg_sensitivity=67.03%, avg_specificity=92.38% avg_auc=90.86%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.226908 Test loss=0.331885 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.22039182484149933
[5/24] Train loss=0.21194544434547424
[10/24] Train loss=0.22944559156894684
[15/24] Train loss=0.21012167632579803
[20/24] Train loss=0.20242081582546234
Test set avg_accuracy=86.12% avg_sensitivity=58.27%, avg_specificity=95.38% avg_auc=90.77%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.227179 Test loss=0.331049 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.21382659673690796
[5/24] Train loss=0.2142820954322815
[10/24] Train loss=0.22481314837932587
[15/24] Train loss=0.2115611881017685
[20/24] Train loss=0.20065230131149292
Test set avg_accuracy=86.04% avg_sensitivity=70.37%, avg_specificity=91.25% avg_auc=91.13%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.222465 Test loss=0.325149 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.2231956571340561
[5/24] Train loss=0.21401850879192352
[10/24] Train loss=0.23232807219028473
[15/24] Train loss=0.22702917456626892
[20/24] Train loss=0.2084341198205948
Test set avg_accuracy=86.34% avg_sensitivity=60.51%, avg_specificity=94.93% avg_auc=91.01%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.223659 Test loss=0.321957 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.2056387960910797
[5/24] Train loss=0.2125752568244934
[10/24] Train loss=0.2274596393108368
[15/24] Train loss=0.21388229727745056
[20/24] Train loss=0.2032938152551651
Test set avg_accuracy=86.35% avg_sensitivity=72.04%, avg_specificity=91.12% avg_auc=92.06%
Best model saved!! Metric=15.564672120712146!!
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.221029 Test loss=0.310179 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2044268697500229
[5/24] Train loss=0.20977237820625305
[10/24] Train loss=0.23592880368232727
[15/24] Train loss=0.20387062430381775
[20/24] Train loss=0.19579605758190155
Test set avg_accuracy=85.83% avg_sensitivity=65.31%, avg_specificity=92.66% avg_auc=90.99%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.218724 Test loss=0.322044 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.21108482778072357
[5/24] Train loss=0.21174514293670654
[10/24] Train loss=0.22558048367500305
[15/24] Train loss=0.20178765058517456
[20/24] Train loss=0.20160259306430817
Test set avg_accuracy=84.34% avg_sensitivity=73.24%, avg_specificity=88.03% avg_auc=90.70%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.219208 Test loss=0.347560 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.21633653342723846
[5/24] Train loss=0.2264045774936676
[10/24] Train loss=0.22154046595096588
[15/24] Train loss=0.20151439309120178
[20/24] Train loss=0.19202971458435059
Test set avg_accuracy=86.13% avg_sensitivity=71.47%, avg_specificity=91.01% avg_auc=91.52%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.221452 Test loss=0.320399 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.21043552458286285
[5/24] Train loss=0.21132567524909973
[10/24] Train loss=0.2287181168794632
[15/24] Train loss=0.2013188898563385
[20/24] Train loss=0.17964325845241547
Test set avg_accuracy=84.58% avg_sensitivity=75.48%, avg_specificity=87.61% avg_auc=90.71%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.213750 Test loss=0.347556 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2077227681875229
[5/24] Train loss=0.20170600712299347
[10/24] Train loss=0.2146030217409134
[15/24] Train loss=0.19314266741275787
[20/24] Train loss=0.1965603232383728
Test set avg_accuracy=72.75% avg_sensitivity=79.34%, avg_specificity=70.55% avg_auc=83.30%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.218313 Test loss=0.572044 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.21284835040569305
[5/24] Train loss=0.2050679326057434
[10/24] Train loss=0.23426242172718048
[15/24] Train loss=0.20311057567596436
[20/24] Train loss=0.18938316404819489
Test set avg_accuracy=84.40% avg_sensitivity=68.08%, avg_specificity=89.83% avg_auc=89.06%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.216635 Test loss=0.360594 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.20628952980041504
[5/24] Train loss=0.20800939202308655
[10/24] Train loss=0.2152377814054489
[15/24] Train loss=0.20062121748924255
[20/24] Train loss=0.2005923092365265
Test set avg_accuracy=85.52% avg_sensitivity=70.74%, avg_specificity=90.44% avg_auc=90.37%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.213321 Test loss=0.340778 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.20420698821544647
[5/24] Train loss=0.20075516402721405
[10/24] Train loss=0.21433040499687195
[15/24] Train loss=0.20202377438545227
[20/24] Train loss=0.19489896297454834
Test set avg_accuracy=85.85% avg_sensitivity=67.81%, avg_specificity=91.84% avg_auc=90.45%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.212010 Test loss=0.336086 Current lr=[0.000224838296036774]

[0/24] Train loss=0.19907428324222565
[5/24] Train loss=0.20505791902542114
[10/24] Train loss=0.21290498971939087
[15/24] Train loss=0.1980336308479309
[20/24] Train loss=0.18861155211925507
Test set avg_accuracy=82.32% avg_sensitivity=75.07%, avg_specificity=84.73% avg_auc=89.02%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.209295 Test loss=0.387321 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.20270885527133942
[5/24] Train loss=0.20346587896347046
[10/24] Train loss=0.2150491625070572
[15/24] Train loss=0.19802135229110718
[20/24] Train loss=0.19393354654312134
Test set avg_accuracy=86.09% avg_sensitivity=65.10%, avg_specificity=93.08% avg_auc=90.99%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.208860 Test loss=0.331584 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.19747427105903625
[5/24] Train loss=0.1926054060459137
[10/24] Train loss=0.2033475935459137
[15/24] Train loss=0.19098825752735138
[20/24] Train loss=0.18170058727264404
Test set avg_accuracy=86.11% avg_sensitivity=68.70%, avg_specificity=91.90% avg_auc=90.61%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.202222 Test loss=0.327058 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.19168265163898468
[5/24] Train loss=0.20249783992767334
[10/24] Train loss=0.2079775035381317
[15/24] Train loss=0.1872951239347458
[20/24] Train loss=0.1800353080034256
Test set avg_accuracy=85.69% avg_sensitivity=66.82%, avg_specificity=91.97% avg_auc=89.85%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.201140 Test loss=0.338827 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.1866012066602707
[5/24] Train loss=0.1882452815771103
[10/24] Train loss=0.19961294531822205
[15/24] Train loss=0.19596078991889954
[20/24] Train loss=0.18313470482826233
Test set avg_accuracy=85.78% avg_sensitivity=69.22%, avg_specificity=91.29% avg_auc=90.14%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.199772 Test loss=0.339347 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.20136211812496185
[5/24] Train loss=0.19545453786849976
[10/24] Train loss=0.2018350511789322
[15/24] Train loss=0.1889568716287613
[20/24] Train loss=0.18017418682575226
Test set avg_accuracy=85.39% avg_sensitivity=72.77%, avg_specificity=89.59% avg_auc=90.96%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.200237 Test loss=0.338629 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.18785911798477173
[5/24] Train loss=0.19818846881389618
[10/24] Train loss=0.19848869740962982
[15/24] Train loss=0.19278156757354736
[20/24] Train loss=0.17615832388401031
Test set avg_accuracy=85.35% avg_sensitivity=58.42%, avg_specificity=94.31% avg_auc=88.40%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.201064 Test loss=0.360502 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.18992027640342712
[5/24] Train loss=0.1950283944606781
[10/24] Train loss=0.21090441942214966
[15/24] Train loss=0.1990060955286026
[20/24] Train loss=0.18132835626602173
Test set avg_accuracy=86.54% avg_sensitivity=69.64%, avg_specificity=92.16% avg_auc=91.01%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.204570 Test loss=0.329037 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.18843138217926025
[5/24] Train loss=0.1938696950674057
[10/24] Train loss=0.19055047631263733
[15/24] Train loss=0.17953819036483765
[20/24] Train loss=0.17196045815944672
Test set avg_accuracy=85.60% avg_sensitivity=65.26%, avg_specificity=92.37% avg_auc=88.87%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.195844 Test loss=0.352830 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.18368200957775116
[5/24] Train loss=0.18157461285591125
[10/24] Train loss=0.19319474697113037
[15/24] Train loss=0.18699665367603302
[20/24] Train loss=0.18919309973716736
Test set avg_accuracy=84.06% avg_sensitivity=73.55%, avg_specificity=87.56% avg_auc=89.16%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.196820 Test loss=0.379967 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.19123128056526184
[5/24] Train loss=0.19608207046985626
[10/24] Train loss=0.19742773473262787
[15/24] Train loss=0.1753460317850113
[20/24] Train loss=0.17194034159183502
Test set avg_accuracy=85.61% avg_sensitivity=65.83%, avg_specificity=92.19% avg_auc=88.88%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.194343 Test loss=0.348642 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.17992669343948364
[5/24] Train loss=0.18641327321529388
[10/24] Train loss=0.20651370286941528
[15/24] Train loss=0.17857065796852112
[20/24] Train loss=0.16828042268753052
Test set avg_accuracy=86.16% avg_sensitivity=66.77%, avg_specificity=92.61% avg_auc=90.48%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.192254 Test loss=0.330764 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.17374007403850555
[5/24] Train loss=0.19501082599163055
[10/24] Train loss=0.20199783146381378
[15/24] Train loss=0.17399072647094727
[20/24] Train loss=0.17892666161060333
Test set avg_accuracy=84.66% avg_sensitivity=49.87%, avg_specificity=96.23% avg_auc=85.01%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.191011 Test loss=0.414519 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.18412819504737854
[5/24] Train loss=0.18028777837753296
[10/24] Train loss=0.19540095329284668
[15/24] Train loss=0.17438550293445587
[20/24] Train loss=0.17313654720783234
Test set avg_accuracy=85.89% avg_sensitivity=62.39%, avg_specificity=93.70% avg_auc=89.49%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.191538 Test loss=0.356632 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.17871038615703583
[5/24] Train loss=0.18486246466636658
[10/24] Train loss=0.19109104573726654
[15/24] Train loss=0.17745280265808105
[20/24] Train loss=0.17428246140480042
Test set avg_accuracy=86.81% avg_sensitivity=62.44%, avg_specificity=94.92% avg_auc=89.44%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.189694 Test loss=0.342162 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.18191373348236084
[5/24] Train loss=0.19436633586883545
[10/24] Train loss=0.19960980117321014
[15/24] Train loss=0.18436077237129211
[20/24] Train loss=0.16375963389873505
Test set avg_accuracy=86.46% avg_sensitivity=66.56%, avg_specificity=93.08% avg_auc=90.20%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.190229 Test loss=0.336232 Current lr=[0.000156543481933168]

[0/24] Train loss=0.17277175188064575
[5/24] Train loss=0.18783560395240784
[10/24] Train loss=0.19465260207653046
[15/24] Train loss=0.17454294860363007
[20/24] Train loss=0.17197147011756897
Test set avg_accuracy=86.60% avg_sensitivity=69.12%, avg_specificity=92.42% avg_auc=90.77%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.186892 Test loss=0.321246 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.17046985030174255
[5/24] Train loss=0.1959870457649231
[10/24] Train loss=0.1878836452960968
[15/24] Train loss=0.17876788973808289
[20/24] Train loss=0.17339946329593658
Test set avg_accuracy=86.28% avg_sensitivity=62.86%, avg_specificity=94.07% avg_auc=89.74%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.187469 Test loss=0.350001 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.179986834526062
[5/24] Train loss=0.19232986867427826
[10/24] Train loss=0.185520201921463
[15/24] Train loss=0.1737162321805954
[20/24] Train loss=0.16602513194084167
Test set avg_accuracy=86.76% avg_sensitivity=66.15%, avg_specificity=93.61% avg_auc=90.93%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.187738 Test loss=0.322501 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.17650766670703888
[5/24] Train loss=0.18926367163658142
[10/24] Train loss=0.1843608021736145
[15/24] Train loss=0.17043647170066833
[20/24] Train loss=0.16191549599170685
Test set avg_accuracy=87.06% avg_sensitivity=71.99%, avg_specificity=92.07% avg_auc=91.40%
Best model saved!! Metric=16.51047270364724!!
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.184866 Test loss=0.316606 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1816791296005249
[5/24] Train loss=0.19248859584331512
[10/24] Train loss=0.19350185990333557
[15/24] Train loss=0.1860426366329193
[20/24] Train loss=0.17119771242141724
Test set avg_accuracy=86.60% avg_sensitivity=61.87%, avg_specificity=94.83% avg_auc=90.00%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.190220 Test loss=0.339006 Current lr=[0.000134135431043539]

[0/24] Train loss=0.17546600103378296
[5/24] Train loss=0.18962937593460083
[10/24] Train loss=0.1858656257390976
[15/24] Train loss=0.18329058587551117
[20/24] Train loss=0.17376868426799774
Test set avg_accuracy=87.24% avg_sensitivity=68.18%, avg_specificity=93.58% avg_auc=90.82%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.187912 Test loss=0.325424 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.18522104620933533
[5/24] Train loss=0.17870792746543884
[10/24] Train loss=0.1813979297876358
[15/24] Train loss=0.17696452140808105
[20/24] Train loss=0.17451544106006622
Test set avg_accuracy=86.60% avg_sensitivity=62.39%, avg_specificity=94.66% avg_auc=89.36%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.187685 Test loss=0.342444 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1773337423801422
[5/24] Train loss=0.1799245923757553
[10/24] Train loss=0.18345926702022552
[15/24] Train loss=0.17468295991420746
[20/24] Train loss=0.1649995744228363
Test set avg_accuracy=86.22% avg_sensitivity=69.38%, avg_specificity=91.83% avg_auc=90.83%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.183409 Test loss=0.333580 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.16895174980163574
[5/24] Train loss=0.16949787735939026
[10/24] Train loss=0.1839192807674408
[15/24] Train loss=0.1707342267036438
[20/24] Train loss=0.1566268652677536
Test set avg_accuracy=86.18% avg_sensitivity=69.80%, avg_specificity=91.64% avg_auc=90.85%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.176386 Test loss=0.336577 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1751841902732849
[5/24] Train loss=0.1738746613264084
[10/24] Train loss=0.1744670271873474
[15/24] Train loss=0.17009395360946655
[20/24] Train loss=0.15787428617477417
Test set avg_accuracy=86.13% avg_sensitivity=68.96%, avg_specificity=91.84% avg_auc=90.94%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.175305 Test loss=0.338767 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16965632140636444
[5/24] Train loss=0.1708768755197525
[10/24] Train loss=0.1739814281463623
[15/24] Train loss=0.16651436686515808
[20/24] Train loss=0.1593543142080307
Test set avg_accuracy=86.73% avg_sensitivity=65.78%, avg_specificity=93.70% avg_auc=90.83%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.172409 Test loss=0.332772 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1613716334104538
[5/24] Train loss=0.17494849860668182
[10/24] Train loss=0.17337484657764435
[15/24] Train loss=0.160334050655365
[20/24] Train loss=0.15142734348773956
Test set avg_accuracy=85.91% avg_sensitivity=63.17%, avg_specificity=93.48% avg_auc=89.48%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.170944 Test loss=0.353925 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15739184617996216
[5/24] Train loss=0.16486626863479614
[10/24] Train loss=0.16384495794773102
[15/24] Train loss=0.15418186783790588
[20/24] Train loss=0.15334491431713104
Test set avg_accuracy=86.56% avg_sensitivity=71.36%, avg_specificity=91.62% avg_auc=91.24%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.167749 Test loss=0.325907 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.16258037090301514
[5/24] Train loss=0.16504934430122375
[10/24] Train loss=0.166788712143898
[15/24] Train loss=0.15721674263477325
[20/24] Train loss=0.1476663202047348
Test set avg_accuracy=86.67% avg_sensitivity=67.24%, avg_specificity=93.13% avg_auc=90.24%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.163551 Test loss=0.338802 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15329374372959137
[5/24] Train loss=0.1615447849035263
[10/24] Train loss=0.16575604677200317
[15/24] Train loss=0.1516585797071457
[20/24] Train loss=0.15508754551410675
Test set avg_accuracy=86.13% avg_sensitivity=70.27%, avg_specificity=91.41% avg_auc=90.74%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.163746 Test loss=0.342916 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1555287390947342
[5/24] Train loss=0.16339021921157837
[10/24] Train loss=0.16415797173976898
[15/24] Train loss=0.15540437400341034
[20/24] Train loss=0.14872907102108002
Test set avg_accuracy=86.20% avg_sensitivity=73.24%, avg_specificity=90.51% avg_auc=91.01%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.162031 Test loss=0.335001 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.15500730276107788
[5/24] Train loss=0.16378113627433777
[10/24] Train loss=0.16263532638549805
[15/24] Train loss=0.1507561057806015
[20/24] Train loss=0.14502766728401184
Test set avg_accuracy=86.64% avg_sensitivity=72.46%, avg_specificity=91.36% avg_auc=91.18%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.158312 Test loss=0.331635 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14729195833206177
[5/24] Train loss=0.1573873609304428
[10/24] Train loss=0.15771444141864777
[15/24] Train loss=0.14722923934459686
[20/24] Train loss=0.1437244564294815
Test set avg_accuracy=86.61% avg_sensitivity=74.70%, avg_specificity=90.58% avg_auc=91.15%
Best model saved!! Metric=17.045264514914493!!
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.157851 Test loss=0.330485 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.15128257870674133
[5/24] Train loss=0.1579149067401886
[10/24] Train loss=0.1574726551771164
[15/24] Train loss=0.14384503662586212
[20/24] Train loss=0.13933376967906952
Test set avg_accuracy=85.96% avg_sensitivity=74.65%, avg_specificity=89.73% avg_auc=90.49%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.156395 Test loss=0.347112 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14816251397132874
[5/24] Train loss=0.15852493047714233
[10/24] Train loss=0.1612541824579239
[15/24] Train loss=0.14381854236125946
[20/24] Train loss=0.14156383275985718
Test set avg_accuracy=86.51% avg_sensitivity=72.30%, avg_specificity=91.24% avg_auc=91.23%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.155299 Test loss=0.326441 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1440477818250656
[5/24] Train loss=0.1606377810239792
[10/24] Train loss=0.15694037079811096
[15/24] Train loss=0.1417020857334137
[20/24] Train loss=0.14060671627521515
Test set avg_accuracy=86.77% avg_sensitivity=70.37%, avg_specificity=92.23% avg_auc=91.21%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.154918 Test loss=0.323392 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14337852597236633
[5/24] Train loss=0.15642936527729034
[10/24] Train loss=0.15652842819690704
[15/24] Train loss=0.14232830703258514
[20/24] Train loss=0.13733775913715363
Test set avg_accuracy=87.20% avg_sensitivity=68.44%, avg_specificity=93.44% avg_auc=90.88%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.153202 Test loss=0.327586 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14412681758403778
[5/24] Train loss=0.15313416719436646
[10/24] Train loss=0.15304842591285706
[15/24] Train loss=0.14015884697437286
[20/24] Train loss=0.13850507140159607
Test set avg_accuracy=87.16% avg_sensitivity=70.27%, avg_specificity=92.78% avg_auc=90.83%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.150807 Test loss=0.323210 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14301976561546326
[5/24] Train loss=0.14967308938503265
[10/24] Train loss=0.1487218290567398
[15/24] Train loss=0.13971979916095734
[20/24] Train loss=0.1377129852771759
Test set avg_accuracy=86.47% avg_sensitivity=65.73%, avg_specificity=93.37% avg_auc=90.28%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.148678 Test loss=0.335317 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13979220390319824
[5/24] Train loss=0.1515185683965683
[10/24] Train loss=0.15075820684432983
[15/24] Train loss=0.14101289212703705
[20/24] Train loss=0.13310079276561737
Test set avg_accuracy=86.61% avg_sensitivity=69.43%, avg_specificity=92.33% avg_auc=90.42%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.147843 Test loss=0.335343 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.13620784878730774
[5/24] Train loss=0.15006031095981598
[10/24] Train loss=0.14276903867721558
[15/24] Train loss=0.13534151017665863
[20/24] Train loss=0.13270807266235352
Test set avg_accuracy=86.99% avg_sensitivity=68.86%, avg_specificity=93.02% avg_auc=90.72%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.145629 Test loss=0.324460 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13291525840759277
[5/24] Train loss=0.1490894854068756
[10/24] Train loss=0.145115926861763
[15/24] Train loss=0.13812342286109924
[20/24] Train loss=0.13015025854110718
Test set avg_accuracy=86.74% avg_sensitivity=69.85%, avg_specificity=92.37% avg_auc=90.70%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.144188 Test loss=0.331515 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1359938085079193
[5/24] Train loss=0.15259087085723877
[10/24] Train loss=0.14701224863529205
[15/24] Train loss=0.1343068778514862
[20/24] Train loss=0.13384093344211578
Test set avg_accuracy=86.81% avg_sensitivity=70.47%, avg_specificity=92.24% avg_auc=90.87%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.143121 Test loss=0.327190 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1338764876127243
[5/24] Train loss=0.14517372846603394
[10/24] Train loss=0.14238081872463226
[15/24] Train loss=0.13411922752857208
[20/24] Train loss=0.1328044831752777
Test set avg_accuracy=87.07% avg_sensitivity=68.44%, avg_specificity=93.27% avg_auc=90.74%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.141844 Test loss=0.326964 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12860578298568726
[5/24] Train loss=0.14758826792240143
[10/24] Train loss=0.1410539597272873
[15/24] Train loss=0.13508500158786774
[20/24] Train loss=0.12811055779457092
Test set avg_accuracy=86.91% avg_sensitivity=71.15%, avg_specificity=92.16% avg_auc=91.07%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.141367 Test loss=0.324895 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1313098967075348
[5/24] Train loss=0.14060288667678833
[10/24] Train loss=0.1415896862745285
[15/24] Train loss=0.13167019188404083
[20/24] Train loss=0.12899072468280792
Test set avg_accuracy=86.77% avg_sensitivity=69.59%, avg_specificity=92.49% avg_auc=90.90%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.139624 Test loss=0.328190 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1287078559398651
[5/24] Train loss=0.14156582951545715
[10/24] Train loss=0.14006160199642181
[15/24] Train loss=0.12854838371276855
[20/24] Train loss=0.12709994614124298
Test set avg_accuracy=87.17% avg_sensitivity=68.96%, avg_specificity=93.23% avg_auc=90.68%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.138159 Test loss=0.328605 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1264447569847107
[5/24] Train loss=0.1438908725976944
[10/24] Train loss=0.13839541375637054
[15/24] Train loss=0.1280079334974289
[20/24] Train loss=0.12655320763587952
Test set avg_accuracy=86.76% avg_sensitivity=67.97%, avg_specificity=93.01% avg_auc=91.00%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.137413 Test loss=0.326757 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12551479041576385
[5/24] Train loss=0.14470428228378296
[10/24] Train loss=0.13697221875190735
[15/24] Train loss=0.13095539808273315
[20/24] Train loss=0.12451568245887756
Test set avg_accuracy=86.88% avg_sensitivity=69.54%, avg_specificity=92.64% avg_auc=91.13%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.137444 Test loss=0.323963 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12582889199256897
[5/24] Train loss=0.1439950317144394
[10/24] Train loss=0.14014479517936707
[15/24] Train loss=0.12814374268054962
[20/24] Train loss=0.12643735110759735
Test set avg_accuracy=87.08% avg_sensitivity=68.70%, avg_specificity=93.20% avg_auc=91.09%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.137086 Test loss=0.322511 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12380341440439224
[5/24] Train loss=0.14143966138362885
[10/24] Train loss=0.14217792451381683
[15/24] Train loss=0.12547104060649872
[20/24] Train loss=0.12735779583454132
Test set avg_accuracy=87.23% avg_sensitivity=69.33%, avg_specificity=93.18% avg_auc=91.16%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.137239 Test loss=0.322618 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12569376826286316
[5/24] Train loss=0.1381778120994568
[10/24] Train loss=0.14159196615219116
[15/24] Train loss=0.12749707698822021
[20/24] Train loss=0.12459465861320496
Test set avg_accuracy=86.99% avg_sensitivity=70.37%, avg_specificity=92.52% avg_auc=91.22%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.136279 Test loss=0.324724 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1282227337360382
[5/24] Train loss=0.1397465020418167
[10/24] Train loss=0.13731533288955688
[15/24] Train loss=0.12768758833408356
[20/24] Train loss=0.12385429441928864
Test set avg_accuracy=87.27% avg_sensitivity=70.47%, avg_specificity=92.85% avg_auc=91.33%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.136242 Test loss=0.321321 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12370239198207855
[5/24] Train loss=0.14026665687561035
[10/24] Train loss=0.13697947561740875
[15/24] Train loss=0.1271284520626068
[20/24] Train loss=0.12292329221963882
Test set avg_accuracy=87.38% avg_sensitivity=70.16%, avg_specificity=93.11% avg_auc=91.03%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.133881 Test loss=0.324154 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12189645320177078
[5/24] Train loss=0.13813188672065735
[10/24] Train loss=0.1345595419406891
[15/24] Train loss=0.12469842284917831
[20/24] Train loss=0.12200953811407089
Test set avg_accuracy=87.42% avg_sensitivity=70.89%, avg_specificity=92.92% avg_auc=91.03%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.132394 Test loss=0.323950 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12028715759515762
[5/24] Train loss=0.1386578381061554
[10/24] Train loss=0.13456586003303528
[15/24] Train loss=0.12391915172338486
[20/24] Train loss=0.11943749338388443
Test set avg_accuracy=87.19% avg_sensitivity=69.85%, avg_specificity=92.96% avg_auc=91.27%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.132058 Test loss=0.320640 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.11994673311710358
[5/24] Train loss=0.13589106500148773
[10/24] Train loss=0.1349424421787262
[15/24] Train loss=0.12399111688137054
[20/24] Train loss=0.11897563189268112
Test set avg_accuracy=87.50% avg_sensitivity=70.16%, avg_specificity=93.27% avg_auc=91.23%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.131311 Test loss=0.320947 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12051674723625183
[5/24] Train loss=0.13626916706562042
[10/24] Train loss=0.13161253929138184
[15/24] Train loss=0.12306514382362366
[20/24] Train loss=0.12075060606002808
Test set avg_accuracy=87.57% avg_sensitivity=70.74%, avg_specificity=93.16% avg_auc=91.08%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.131589 Test loss=0.321675 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12000108510255814
[5/24] Train loss=0.13387668132781982
[10/24] Train loss=0.1313052475452423
[15/24] Train loss=0.12239034473896027
[20/24] Train loss=0.12074041366577148
Test set avg_accuracy=87.43% avg_sensitivity=70.58%, avg_specificity=93.04% avg_auc=91.18%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.130660 Test loss=0.322050 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11910697817802429
[5/24] Train loss=0.13492268323898315
[10/24] Train loss=0.13287264108657837
[15/24] Train loss=0.12135506421327591
[20/24] Train loss=0.1232214868068695
Test set avg_accuracy=87.43% avg_sensitivity=70.74%, avg_specificity=92.99% avg_auc=91.22%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.130410 Test loss=0.322027 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12165975570678711
[5/24] Train loss=0.13685236871242523
[10/24] Train loss=0.13045915961265564
[15/24] Train loss=0.12403417378664017
[20/24] Train loss=0.12121135741472244
Test set avg_accuracy=87.76% avg_sensitivity=70.53%, avg_specificity=93.49% avg_auc=91.17%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.130623 Test loss=0.321011 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11759653687477112
[5/24] Train loss=0.13712938129901886
[10/24] Train loss=0.12925253808498383
[15/24] Train loss=0.12181469798088074
[20/24] Train loss=0.12283580005168915
Test set avg_accuracy=87.54% avg_sensitivity=70.16%, avg_specificity=93.32% avg_auc=91.17%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.129816 Test loss=0.321655 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1189287081360817
[5/24] Train loss=0.1329098492860794
[10/24] Train loss=0.13200967013835907
[15/24] Train loss=0.12170539796352386
[20/24] Train loss=0.11963046342134476
Test set avg_accuracy=87.37% avg_sensitivity=70.63%, avg_specificity=92.94% avg_auc=91.20%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.130050 Test loss=0.322720 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11900410801172256
[5/24] Train loss=0.13399308919906616
[10/24] Train loss=0.13001321256160736
[15/24] Train loss=0.12202563881874084
[20/24] Train loss=0.12021415680646896
Test set avg_accuracy=87.40% avg_sensitivity=70.58%, avg_specificity=92.99% avg_auc=91.16%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.129683 Test loss=0.323065 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1182728260755539
[5/24] Train loss=0.1358296275138855
[10/24] Train loss=0.13012883067131042
[15/24] Train loss=0.12238644808530807
[20/24] Train loss=0.11972901970148087
Test set avg_accuracy=87.43% avg_sensitivity=70.63%, avg_specificity=93.02% avg_auc=91.16%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.129940 Test loss=0.322724 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11821510642766953
[5/24] Train loss=0.13374793529510498
[10/24] Train loss=0.13131022453308105
[15/24] Train loss=0.12422726303339005
[20/24] Train loss=0.11987263709306717
Test set avg_accuracy=87.46% avg_sensitivity=70.68%, avg_specificity=93.04% avg_auc=91.15%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.129826 Test loss=0.322866 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1200128123164177
[5/24] Train loss=0.13809247314929962
[10/24] Train loss=0.13013499975204468
[15/24] Train loss=0.12080617249011993
[20/24] Train loss=0.11816380172967911
Test set avg_accuracy=87.46% avg_sensitivity=70.63%, avg_specificity=93.06% avg_auc=91.14%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.129748 Test loss=0.323014 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12067072093486786
[5/24] Train loss=0.1347985565662384
[10/24] Train loss=0.1292913258075714
[15/24] Train loss=0.12148486822843552
[20/24] Train loss=0.11903290450572968
Test set avg_accuracy=87.41% avg_sensitivity=70.63%, avg_specificity=92.99% avg_auc=91.15%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.129522 Test loss=0.322934 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11628458648920059
[5/24] Train loss=0.13588681817054749
[10/24] Train loss=0.12922273576259613
[15/24] Train loss=0.1234554648399353
[20/24] Train loss=0.11876175552606583
Test set avg_accuracy=87.49% avg_sensitivity=70.63%, avg_specificity=93.09% avg_auc=91.14%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.129556 Test loss=0.322895 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=86.61% sen=74.70%, spe=90.58%, auc=91.15%!
Fold[2] Avg_overlap=0.72%(±0.2137609095809858)
[0/24] Train loss=0.7654604911804199
[5/24] Train loss=0.7502766847610474
[10/24] Train loss=0.7465537190437317
[15/24] Train loss=0.740100622177124
[20/24] Train loss=0.7305748462677002
Test set avg_accuracy=55.47% avg_sensitivity=46.45%, avg_specificity=58.89% avg_auc=54.56%
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.746614 Test loss=0.679914 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7443555593490601
[5/24] Train loss=0.7351089715957642
[10/24] Train loss=0.7260749340057373
[15/24] Train loss=0.7194831967353821
[20/24] Train loss=0.7103332877159119
Test set avg_accuracy=62.88% avg_sensitivity=57.87%, avg_specificity=64.78% avg_auc=64.41%
Best model saved!! Metric=-76.0725732393762!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.724134 Test loss=0.641041 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7138416171073914
[5/24] Train loss=0.7131302356719971
[10/24] Train loss=0.697794497013092
[15/24] Train loss=0.6964190006256104
[20/24] Train loss=0.677558183670044
Test set avg_accuracy=66.37% avg_sensitivity=62.70%, avg_specificity=67.76% avg_auc=68.71%
Best model saved!! Metric=-60.46312383271505!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.700848 Test loss=0.624943 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6918480396270752
[5/24] Train loss=0.6921208500862122
[10/24] Train loss=0.686738133430481
[15/24] Train loss=0.6753638386726379
[20/24] Train loss=0.6632043719291687
Test set avg_accuracy=68.36% avg_sensitivity=65.31%, avg_specificity=69.52% avg_auc=71.98%
Best model saved!! Metric=-50.840072786466095!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.680631 Test loss=0.603944 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6636645793914795
[5/24] Train loss=0.6654952764511108
[10/24] Train loss=0.6693904399871826
[15/24] Train loss=0.6446815729141235
[20/24] Train loss=0.6310295462608337
Test set avg_accuracy=70.66% avg_sensitivity=65.55%, avg_specificity=72.60% avg_auc=74.81%
Best model saved!! Metric=-42.37291623680092!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.656306 Test loss=0.577018 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.630172848701477
[5/24] Train loss=0.6491817235946655
[10/24] Train loss=0.642788827419281
[15/24] Train loss=0.6211689114570618
[20/24] Train loss=0.6007252335548401
Test set avg_accuracy=72.25% avg_sensitivity=66.49%, avg_specificity=74.43% avg_auc=77.10%
Best model saved!! Metric=-35.7220782467362!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.631147 Test loss=0.551134 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5974838137626648
[5/24] Train loss=0.6177037954330444
[10/24] Train loss=0.6186144351959229
[15/24] Train loss=0.592780351638794
[20/24] Train loss=0.5691325664520264
Test set avg_accuracy=73.95% avg_sensitivity=69.05%, avg_specificity=75.80% avg_auc=79.22%
Best model saved!! Metric=-27.982333913164624!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.604678 Test loss=0.529799 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5731609463691711
[5/24] Train loss=0.5797320604324341
[10/24] Train loss=0.5927144289016724
[15/24] Train loss=0.5648720264434814
[20/24] Train loss=0.5384950041770935
Test set avg_accuracy=75.76% avg_sensitivity=71.18%, avg_specificity=77.49% avg_auc=81.38%
Best model saved!! Metric=-20.18964689142352!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.575141 Test loss=0.504622 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.54250568151474
[5/24] Train loss=0.5537457466125488
[10/24] Train loss=0.5574249625205994
[15/24] Train loss=0.5262709856033325
[20/24] Train loss=0.5009264945983887
Test set avg_accuracy=78.20% avg_sensitivity=67.49%, avg_specificity=82.26% avg_auc=82.57%
Best model saved!! Metric=-15.479543663370961!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.544142 Test loss=0.474050 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5138475894927979
[5/24] Train loss=0.5122430920600891
[10/24] Train loss=0.5350546836853027
[15/24] Train loss=0.4915778636932373
[20/24] Train loss=0.4698711037635803
Test set avg_accuracy=79.69% avg_sensitivity=71.28%, avg_specificity=82.87% avg_auc=85.00%
Best model saved!! Metric=-7.1561572021748105!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.514500 Test loss=0.452190 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4897036552429199
[5/24] Train loss=0.4845525324344635
[10/24] Train loss=0.5083190202713013
[15/24] Train loss=0.46594488620758057
[20/24] Train loss=0.4375331997871399
Test set avg_accuracy=81.47% avg_sensitivity=70.47%, avg_specificity=85.64% avg_auc=86.21%
Best model saved!! Metric=-2.2106848541540813!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.484058 Test loss=0.431856 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.46290484070777893
[5/24] Train loss=0.4591701030731201
[10/24] Train loss=0.4843040406703949
[15/24] Train loss=0.44447487592697144
[20/24] Train loss=0.40801137685775757
Test set avg_accuracy=82.43% avg_sensitivity=68.82%, avg_specificity=87.59% avg_auc=87.27%
Best model saved!! Metric=0.11154885774475076!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.456636 Test loss=0.409405 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.43350890278816223
[5/24] Train loss=0.43300527334213257
[10/24] Train loss=0.46719178557395935
[15/24] Train loss=0.4181250333786011
[20/24] Train loss=0.389064222574234
Test set avg_accuracy=83.23% avg_sensitivity=66.59%, avg_specificity=89.53% avg_auc=88.01%
Best model saved!! Metric=1.3605066991698465!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.432909 Test loss=0.393262 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4138663113117218
[5/24] Train loss=0.4062240719795227
[10/24] Train loss=0.44481849670410156
[15/24] Train loss=0.40204712748527527
[20/24] Train loss=0.3688059151172638
Test set avg_accuracy=83.68% avg_sensitivity=63.03%, avg_specificity=91.51% avg_auc=88.51%
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.410292 Test loss=0.377678 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.39156368374824524
[5/24] Train loss=0.3863530457019806
[10/24] Train loss=0.4299003779888153
[15/24] Train loss=0.37760427594184875
[20/24] Train loss=0.35350167751312256
Test set avg_accuracy=84.35% avg_sensitivity=66.73%, avg_specificity=91.02% avg_auc=89.35%
Best model saved!! Metric=5.4559294974062595!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.392309 Test loss=0.370346 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.37612757086753845
[5/24] Train loss=0.3676741421222687
[10/24] Train loss=0.40710267424583435
[15/24] Train loss=0.3659871518611908
[20/24] Train loss=0.34216418862342834
Test set avg_accuracy=84.51% avg_sensitivity=65.78%, avg_specificity=91.60% avg_auc=89.56%
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.376759 Test loss=0.361250 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3590349555015564
[5/24] Train loss=0.35456207394599915
[10/24] Train loss=0.39947307109832764
[15/24] Train loss=0.35506704449653625
[20/24] Train loss=0.3294505476951599
Test set avg_accuracy=84.48% avg_sensitivity=68.58%, avg_specificity=90.50% avg_auc=90.02%
Best model saved!! Metric=7.579296849518258!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.363289 Test loss=0.356042 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.355620414018631
[5/24] Train loss=0.3374980390071869
[10/24] Train loss=0.38598474860191345
[15/24] Train loss=0.3386061191558838
[20/24] Train loss=0.31985440850257874
Test set avg_accuracy=85.10% avg_sensitivity=67.58%, avg_specificity=91.74% avg_auc=90.77%
Best model saved!! Metric=9.199119315845167!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.352044 Test loss=0.345797 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.341299444437027
[5/24] Train loss=0.32907843589782715
[10/24] Train loss=0.3749268054962158
[15/24] Train loss=0.3380410373210907
[20/24] Train loss=0.30653825402259827
Test set avg_accuracy=84.79% avg_sensitivity=61.71%, avg_specificity=93.54% avg_auc=90.60%
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.340937 Test loss=0.343260 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.33186107873916626
[5/24] Train loss=0.31195035576820374
[10/24] Train loss=0.36483505368232727
[15/24] Train loss=0.32880234718322754
[20/24] Train loss=0.29517003893852234
Test set avg_accuracy=84.86% avg_sensitivity=58.53%, avg_specificity=94.83% avg_auc=90.74%
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.331482 Test loss=0.344805 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3232360780239105
[5/24] Train loss=0.31021586060523987
[10/24] Train loss=0.35935544967651367
[15/24] Train loss=0.3189351558685303
[20/24] Train loss=0.28751298785209656
Test set avg_accuracy=85.60% avg_sensitivity=66.64%, avg_specificity=92.78% avg_auc=91.28%
Best model saved!! Metric=10.295981145112734!!
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.324913 Test loss=0.332653 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.31362611055374146
[5/24] Train loss=0.29915985465049744
[10/24] Train loss=0.3537251353263855
[15/24] Train loss=0.314558744430542
[20/24] Train loss=0.2800549566745758
Test set avg_accuracy=85.99% avg_sensitivity=66.07%, avg_specificity=93.54% avg_auc=91.61%
Best model saved!! Metric=11.200794374200527!!
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.317680 Test loss=0.325421 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.31129327416419983
[5/24] Train loss=0.2925370931625366
[10/24] Train loss=0.3500349223613739
[15/24] Train loss=0.31269705295562744
[20/24] Train loss=0.2751138210296631
Test set avg_accuracy=86.25% avg_sensitivity=65.40%, avg_specificity=94.15% avg_auc=91.73%
Best model saved!! Metric=11.530127119725677!!
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.311509 Test loss=0.322634 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2972879707813263
[5/24] Train loss=0.2861637771129608
[10/24] Train loss=0.34113767743110657
[15/24] Train loss=0.30031073093414307
[20/24] Train loss=0.2711504101753235
Test set avg_accuracy=86.12% avg_sensitivity=66.87%, avg_specificity=93.41% avg_auc=92.05%
Best model saved!! Metric=12.452430124212597!!
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.304064 Test loss=0.316810 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2918558418750763
[5/24] Train loss=0.2777455151081085
[10/24] Train loss=0.34595808386802673
[15/24] Train loss=0.29836782813072205
[20/24] Train loss=0.26546379923820496
Test set avg_accuracy=86.28% avg_sensitivity=67.06%, avg_specificity=93.55% avg_auc=91.81%
Best model saved!! Metric=12.706002441637523!!
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.299473 Test loss=0.319572 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2898215353488922
[5/24] Train loss=0.26964670419692993
[10/24] Train loss=0.3390069305896759
[15/24] Train loss=0.29597049951553345
[20/24] Train loss=0.26254916191101074
Test set avg_accuracy=85.77% avg_sensitivity=59.38%, avg_specificity=95.76% avg_auc=91.84%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.293346 Test loss=0.327482 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.28611406683921814
[5/24] Train loss=0.25838932394981384
[10/24] Train loss=0.3380706310272217
[15/24] Train loss=0.29318150877952576
[20/24] Train loss=0.25302669405937195
Test set avg_accuracy=83.68% avg_sensitivity=48.91%, avg_specificity=96.86% avg_auc=91.11%
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.290811 Test loss=0.360672 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2834738790988922
[5/24] Train loss=0.2583570182323456
[10/24] Train loss=0.3300739526748657
[15/24] Train loss=0.29079097509384155
[20/24] Train loss=0.24716076254844666
Test set avg_accuracy=83.23% avg_sensitivity=46.35%, avg_specificity=97.20% avg_auc=90.84%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.286128 Test loss=0.375216 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2825293242931366
[5/24] Train loss=0.2588801980018616
[10/24] Train loss=0.3257821500301361
[15/24] Train loss=0.28892162442207336
[20/24] Train loss=0.24901075661182404
Test set avg_accuracy=85.86% avg_sensitivity=61.94%, avg_specificity=94.92% avg_auc=91.96%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.285345 Test loss=0.322777 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.27710840106010437
[5/24] Train loss=0.24705122411251068
[10/24] Train loss=0.3221094012260437
[15/24] Train loss=0.280132919549942
[20/24] Train loss=0.24618683755397797
Test set avg_accuracy=81.90% avg_sensitivity=39.10%, avg_specificity=98.11% avg_auc=90.00%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.279405 Test loss=0.405283 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.27904176712036133
[5/24] Train loss=0.2523128390312195
[10/24] Train loss=0.3207578957080841
[15/24] Train loss=0.27237382531166077
[20/24] Train loss=0.24942560493946075
Test set avg_accuracy=81.09% avg_sensitivity=36.49%, avg_specificity=97.99% avg_auc=89.55%
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.277587 Test loss=0.413809 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2743552327156067
[5/24] Train loss=0.24216032028198242
[10/24] Train loss=0.3114813566207886
[15/24] Train loss=0.28284454345703125
[20/24] Train loss=0.24398191273212433
Test set avg_accuracy=84.60% avg_sensitivity=52.18%, avg_specificity=96.88% avg_auc=91.42%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.275168 Test loss=0.354476 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.26782476902008057
[5/24] Train loss=0.242460697889328
[10/24] Train loss=0.31256556510925293
[15/24] Train loss=0.27473124861717224
[20/24] Train loss=0.2389773428440094
Test set avg_accuracy=82.51% avg_sensitivity=43.93%, avg_specificity=97.13% avg_auc=90.18%
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.272898 Test loss=0.385010 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2797444760799408
[5/24] Train loss=0.24431805312633514
[10/24] Train loss=0.30148160457611084
[15/24] Train loss=0.2777569591999054
[20/24] Train loss=0.24537691473960876
Test set avg_accuracy=78.20% avg_sensitivity=23.70%, avg_specificity=98.85% avg_auc=85.58%
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.272710 Test loss=0.526199 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.27728113532066345
[5/24] Train loss=0.2377508282661438
[10/24] Train loss=0.3041204512119293
[15/24] Train loss=0.27575165033340454
[20/24] Train loss=0.23950381577014923
Test set avg_accuracy=84.87% avg_sensitivity=54.88%, avg_specificity=96.23% avg_auc=91.23%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.270670 Test loss=0.344767 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2611178755760193
[5/24] Train loss=0.23923636972904205
[10/24] Train loss=0.30170851945877075
[15/24] Train loss=0.28130054473876953
[20/24] Train loss=0.23275883495807648
Test set avg_accuracy=83.39% avg_sensitivity=48.82%, avg_specificity=96.48% avg_auc=89.76%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.265250 Test loss=0.380142 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2526242733001709
[5/24] Train loss=0.22809474170207977
[10/24] Train loss=0.30342650413513184
[15/24] Train loss=0.27494171261787415
[20/24] Train loss=0.23640449345111847
Test set avg_accuracy=81.88% avg_sensitivity=39.95%, avg_specificity=97.76% avg_auc=87.86%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.262818 Test loss=0.426400 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.26327380537986755
[5/24] Train loss=0.24421045184135437
[10/24] Train loss=0.2985098361968994
[15/24] Train loss=0.2728174328804016
[20/24] Train loss=0.23150505125522614
Test set avg_accuracy=80.64% avg_sensitivity=34.79%, avg_specificity=98.01% avg_auc=88.38%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.265882 Test loss=0.459582 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2536059617996216
[5/24] Train loss=0.232808917760849
[10/24] Train loss=0.30278944969177246
[15/24] Train loss=0.2704734802246094
[20/24] Train loss=0.22965851426124573
Test set avg_accuracy=86.25% avg_sensitivity=66.35%, avg_specificity=93.79% avg_auc=92.02%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.266268 Test loss=0.317049 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.25437411665916443
[5/24] Train loss=0.23073966801166534
[10/24] Train loss=0.29749736189842224
[15/24] Train loss=0.26957422494888306
[20/24] Train loss=0.23105910420417786
Test set avg_accuracy=84.23% avg_sensitivity=52.46%, avg_specificity=96.27% avg_auc=90.21%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.262017 Test loss=0.368429 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2495046854019165
[5/24] Train loss=0.22771665453910828
[10/24] Train loss=0.29944008588790894
[15/24] Train loss=0.2653082609176636
[20/24] Train loss=0.22975219786167145
Test set avg_accuracy=79.36% avg_sensitivity=28.29%, avg_specificity=98.71% avg_auc=86.62%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.259276 Test loss=0.491260 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.25322839617729187
[5/24] Train loss=0.22431392967700958
[10/24] Train loss=0.291801780462265
[15/24] Train loss=0.27010148763656616
[20/24] Train loss=0.23290157318115234
Test set avg_accuracy=81.63% avg_sensitivity=39.38%, avg_specificity=97.63% avg_auc=88.04%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.255715 Test loss=0.439721 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.24959200620651245
[5/24] Train loss=0.2363150417804718
[10/24] Train loss=0.3032131791114807
[15/24] Train loss=0.2790115475654602
[20/24] Train loss=0.23099994659423828
Test set avg_accuracy=82.71% avg_sensitivity=44.08%, avg_specificity=97.34% avg_auc=88.79%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.257158 Test loss=0.405385 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2562487721443176
[5/24] Train loss=0.2361995428800583
[10/24] Train loss=0.29409298300743103
[15/24] Train loss=0.2531394064426422
[20/24] Train loss=0.23007534444332123
Test set avg_accuracy=82.96% avg_sensitivity=47.49%, avg_specificity=96.39% avg_auc=89.70%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.256919 Test loss=0.398172 Current lr=[0.00029967723776099]

[0/24] Train loss=0.24881277978420258
[5/24] Train loss=0.2421785593032837
[10/24] Train loss=0.2913984954357147
[15/24] Train loss=0.2651804983615875
[20/24] Train loss=0.2229057103395462
Test set avg_accuracy=83.23% avg_sensitivity=60.14%, avg_specificity=91.97% avg_auc=89.09%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.256943 Test loss=0.364970 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2582244277000427
[5/24] Train loss=0.23552481830120087
[10/24] Train loss=0.2835104763507843
[15/24] Train loss=0.26212820410728455
[20/24] Train loss=0.22880111634731293
Test set avg_accuracy=85.25% avg_sensitivity=61.00%, avg_specificity=94.43% avg_auc=91.14%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.256070 Test loss=0.336896 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2425900399684906
[5/24] Train loss=0.23016415536403656
[10/24] Train loss=0.2898663878440857
[15/24] Train loss=0.2633129358291626
[20/24] Train loss=0.22606593370437622
Test set avg_accuracy=85.23% avg_sensitivity=63.13%, avg_specificity=93.61% avg_auc=89.84%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.252567 Test loss=0.346593 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2565002143383026
[5/24] Train loss=0.23315134644508362
[10/24] Train loss=0.26910585165023804
[15/24] Train loss=0.2725643217563629
[20/24] Train loss=0.22815461456775665
Test set avg_accuracy=82.80% avg_sensitivity=46.26%, avg_specificity=96.64% avg_auc=88.45%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.252836 Test loss=0.404626 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2377421110868454
[5/24] Train loss=0.20955297350883484
[10/24] Train loss=0.28933507204055786
[15/24] Train loss=0.26994654536247253
[20/24] Train loss=0.22803431749343872
Test set avg_accuracy=86.42% avg_sensitivity=65.83%, avg_specificity=94.22% avg_auc=91.88%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.249109 Test loss=0.322202 Current lr=[0.000298904600941902]

[0/24] Train loss=0.23574170470237732
[5/24] Train loss=0.2246728092432022
[10/24] Train loss=0.2673450708389282
[15/24] Train loss=0.2586633265018463
[20/24] Train loss=0.22279848158359528
Test set avg_accuracy=79.41% avg_sensitivity=29.00%, avg_specificity=98.51% avg_auc=83.71%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.246087 Test loss=0.516300 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.24241001904010773
[5/24] Train loss=0.21937012672424316
[10/24] Train loss=0.28321629762649536
[15/24] Train loss=0.2840005159378052
[20/24] Train loss=0.22807450592517853
Test set avg_accuracy=85.95% avg_sensitivity=68.34%, avg_specificity=92.62% avg_auc=91.80%
Best model saved!! Metric=12.708661515899905!!
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.248972 Test loss=0.320645 Current lr=[0.000297555943323901]

[0/24] Train loss=0.241141676902771
[5/24] Train loss=0.22707784175872803
[10/24] Train loss=0.28392380475997925
[15/24] Train loss=0.2530623972415924
[20/24] Train loss=0.2265787273645401
Test set avg_accuracy=84.87% avg_sensitivity=56.78%, avg_specificity=95.51% avg_auc=90.72%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.247856 Test loss=0.347867 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.24943816661834717
[5/24] Train loss=0.2209022343158722
[10/24] Train loss=0.2799300253391266
[15/24] Train loss=0.2569749653339386
[20/24] Train loss=0.222479909658432
Test set avg_accuracy=82.45% avg_sensitivity=45.12%, avg_specificity=96.59% avg_auc=88.85%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.245221 Test loss=0.390928 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.23022623360157013
[5/24] Train loss=0.2217264622449875
[10/24] Train loss=0.2680671215057373
[15/24] Train loss=0.25412309169769287
[20/24] Train loss=0.22513604164123535
Test set avg_accuracy=84.53% avg_sensitivity=53.41%, avg_specificity=96.32% avg_auc=89.98%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.242920 Test loss=0.356014 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2488633692264557
[5/24] Train loss=0.22353695333003998
[10/24] Train loss=0.26647093892097473
[15/24] Train loss=0.2557879388332367
[20/24] Train loss=0.2152702510356903
Test set avg_accuracy=82.66% avg_sensitivity=44.83%, avg_specificity=96.98% avg_auc=87.75%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.243134 Test loss=0.418254 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2324979603290558
[5/24] Train loss=0.22638840973377228
[10/24] Train loss=0.26851674914360046
[15/24] Train loss=0.24256227910518646
[20/24] Train loss=0.2209666669368744
Test set avg_accuracy=84.97% avg_sensitivity=58.91%, avg_specificity=94.85% avg_auc=90.57%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.241969 Test loss=0.348173 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.236806720495224
[5/24] Train loss=0.21418946981430054
[10/24] Train loss=0.25326791405677795
[15/24] Train loss=0.2594335973262787
[20/24] Train loss=0.22303085029125214
Test set avg_accuracy=83.74% avg_sensitivity=54.12%, avg_specificity=94.96% avg_auc=87.59%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.238429 Test loss=0.390050 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2540764808654785
[5/24] Train loss=0.2114930897951126
[10/24] Train loss=0.25996121764183044
[15/24] Train loss=0.24923516809940338
[20/24] Train loss=0.2230333834886551
Test set avg_accuracy=84.54% avg_sensitivity=56.26%, avg_specificity=95.26% avg_auc=89.70%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.239929 Test loss=0.360340 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2391364723443985
[5/24] Train loss=0.21209841966629028
[10/24] Train loss=0.23985296487808228
[15/24] Train loss=0.24630846083164215
[20/24] Train loss=0.2204957753419876
Test set avg_accuracy=84.75% avg_sensitivity=75.50%, avg_specificity=88.26% avg_auc=90.67%
Best model saved!! Metric=13.181756616741964!!
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.236106 Test loss=0.344879 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2318754643201828
[5/24] Train loss=0.21903516352176666
[10/24] Train loss=0.24828210473060608
[15/24] Train loss=0.23126529157161713
[20/24] Train loss=0.21715006232261658
Test set avg_accuracy=84.97% avg_sensitivity=63.41%, avg_specificity=93.14% avg_auc=89.81%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.234120 Test loss=0.348620 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.23967957496643066
[5/24] Train loss=0.2162455916404724
[10/24] Train loss=0.25639015436172485
[15/24] Train loss=0.25649672746658325
[20/24] Train loss=0.22286581993103027
Test set avg_accuracy=83.29% avg_sensitivity=72.27%, avg_specificity=87.47% avg_auc=90.03%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.236887 Test loss=0.363362 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2334507703781128
[5/24] Train loss=0.20659683644771576
[10/24] Train loss=0.2610134482383728
[15/24] Train loss=0.24044200778007507
[20/24] Train loss=0.21952229738235474
Test set avg_accuracy=86.38% avg_sensitivity=67.44%, avg_specificity=93.55% avg_auc=91.59%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.234603 Test loss=0.323058 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.22899974882602692
[5/24] Train loss=0.20828312635421753
[10/24] Train loss=0.25116172432899475
[15/24] Train loss=0.24191386997699738
[20/24] Train loss=0.21372367441654205
Test set avg_accuracy=84.73% avg_sensitivity=60.33%, avg_specificity=93.97% avg_auc=88.96%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.231606 Test loss=0.363729 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.23070763051509857
[5/24] Train loss=0.20865562558174133
[10/24] Train loss=0.2621111571788788
[15/24] Train loss=0.24667240679264069
[20/24] Train loss=0.21586905419826508
Test set avg_accuracy=78.18% avg_sensitivity=80.43%, avg_specificity=77.32% avg_auc=87.03%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.235228 Test loss=0.456901 Current lr=[0.000276307469034998]

[0/24] Train loss=0.23749281466007233
[5/24] Train loss=0.210176482796669
[10/24] Train loss=0.2642046809196472
[15/24] Train loss=0.24008342623710632
[20/24] Train loss=0.2145279347896576
Test set avg_accuracy=85.83% avg_sensitivity=66.59%, avg_specificity=93.12% avg_auc=91.18%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.236093 Test loss=0.327513 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.22439947724342346
[5/24] Train loss=0.21067796647548676
[10/24] Train loss=0.24551333487033844
[15/24] Train loss=0.2514141798019409
[20/24] Train loss=0.21218203008174896
Test set avg_accuracy=85.86% avg_sensitivity=71.85%, avg_specificity=91.17% avg_auc=91.60%
Best model saved!! Metric=14.47434007185582!!
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.229265 Test loss=0.328159 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2263120710849762
[5/24] Train loss=0.19316613674163818
[10/24] Train loss=0.23928171396255493
[15/24] Train loss=0.2273566722869873
[20/24] Train loss=0.20733091235160828
Test set avg_accuracy=86.21% avg_sensitivity=65.88%, avg_specificity=93.91% avg_auc=90.75%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.224721 Test loss=0.335705 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.21656924486160278
[5/24] Train loss=0.19968141615390778
[10/24] Train loss=0.25252997875213623
[15/24] Train loss=0.253799170255661
[20/24] Train loss=0.2096596509218216
Test set avg_accuracy=85.74% avg_sensitivity=66.97%, avg_specificity=92.85% avg_auc=90.75%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.226118 Test loss=0.333504 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.22254861891269684
[5/24] Train loss=0.2024725079536438
[10/24] Train loss=0.24863660335540771
[15/24] Train loss=0.2314932942390442
[20/24] Train loss=0.2155148983001709
Test set avg_accuracy=84.24% avg_sensitivity=56.30%, avg_specificity=94.83% avg_auc=89.48%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.227421 Test loss=0.372131 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.21268083155155182
[5/24] Train loss=0.2019403874874115
[10/24] Train loss=0.24025380611419678
[15/24] Train loss=0.2433760166168213
[20/24] Train loss=0.20888307690620422
Test set avg_accuracy=85.65% avg_sensitivity=70.52%, avg_specificity=91.38% avg_auc=89.54%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.226245 Test loss=0.346879 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.22059117257595062
[5/24] Train loss=0.19810765981674194
[10/24] Train loss=0.24169465899467468
[15/24] Train loss=0.2514452636241913
[20/24] Train loss=0.20700789988040924
Test set avg_accuracy=85.38% avg_sensitivity=67.58%, avg_specificity=92.12% avg_auc=90.00%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.225401 Test loss=0.348110 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.2159772664308548
[5/24] Train loss=0.19553464651107788
[10/24] Train loss=0.23852461576461792
[15/24] Train loss=0.2529657483100891
[20/24] Train loss=0.20528680086135864
Test set avg_accuracy=85.95% avg_sensitivity=68.67%, avg_specificity=92.50% avg_auc=90.80%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.223885 Test loss=0.338149 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.21358442306518555
[5/24] Train loss=0.19438622891902924
[10/24] Train loss=0.23979544639587402
[15/24] Train loss=0.2325352281332016
[20/24] Train loss=0.19819079339504242
Test set avg_accuracy=84.90% avg_sensitivity=70.09%, avg_specificity=90.50% avg_auc=90.20%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.218734 Test loss=0.347543 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2107567936182022
[5/24] Train loss=0.19762493669986725
[10/24] Train loss=0.2424682378768921
[15/24] Train loss=0.24096731841564178
[20/24] Train loss=0.21248465776443481
Test set avg_accuracy=85.46% avg_sensitivity=65.36%, avg_specificity=93.07% avg_auc=89.96%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.221784 Test loss=0.342918 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.21381519734859467
[5/24] Train loss=0.19748584926128387
[10/24] Train loss=0.2436610609292984
[15/24] Train loss=0.24022677540779114
[20/24] Train loss=0.21005065739154816
Test set avg_accuracy=86.03% avg_sensitivity=73.93%, avg_specificity=90.61% avg_auc=91.40%
Best model saved!! Metric=15.977619260715969!!
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.223745 Test loss=0.327129 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2079002559185028
[5/24] Train loss=0.20391058921813965
[10/24] Train loss=0.23962000012397766
[15/24] Train loss=0.23875905573368073
[20/24] Train loss=0.21645015478134155
Test set avg_accuracy=83.39% avg_sensitivity=51.00%, avg_specificity=95.66% avg_auc=86.29%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.224213 Test loss=0.415700 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.20853941142559052
[5/24] Train loss=0.19892965257167816
[10/24] Train loss=0.24478818476200104
[15/24] Train loss=0.23052836954593658
[20/24] Train loss=0.2071104198694229
Test set avg_accuracy=85.14% avg_sensitivity=71.04%, avg_specificity=90.48% avg_auc=89.80%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.218259 Test loss=0.353146 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.21438702940940857
[5/24] Train loss=0.19816440343856812
[10/24] Train loss=0.2226426899433136
[15/24] Train loss=0.23687539994716644
[20/24] Train loss=0.20686785876750946
Test set avg_accuracy=81.41% avg_sensitivity=79.38%, avg_specificity=82.17% avg_auc=89.01%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.218759 Test loss=0.409833 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.20938442647457123
[5/24] Train loss=0.19592797756195068
[10/24] Train loss=0.22326849400997162
[15/24] Train loss=0.230738565325737
[20/24] Train loss=0.2082834094762802
Test set avg_accuracy=84.49% avg_sensitivity=59.81%, avg_specificity=93.84% avg_auc=88.30%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.216484 Test loss=0.373156 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.210740864276886
[5/24] Train loss=0.18950290977954865
[10/24] Train loss=0.22841769456863403
[15/24] Train loss=0.22168229520320892
[20/24] Train loss=0.20373445749282837
Test set avg_accuracy=85.42% avg_sensitivity=70.52%, avg_specificity=91.06% avg_auc=90.44%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.214235 Test loss=0.343952 Current lr=[0.000224838296036774]

[0/24] Train loss=0.20206357538700104
[5/24] Train loss=0.19355449080467224
[10/24] Train loss=0.23806531727313995
[15/24] Train loss=0.22726556658744812
[20/24] Train loss=0.20952866971492767
Test set avg_accuracy=83.62% avg_sensitivity=80.66%, avg_specificity=84.74% avg_auc=90.75%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.215640 Test loss=0.369075 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.20276769995689392
[5/24] Train loss=0.19125515222549438
[10/24] Train loss=0.23573064804077148
[15/24] Train loss=0.23448094725608826
[20/24] Train loss=0.20569927990436554
Test set avg_accuracy=85.40% avg_sensitivity=75.45%, avg_specificity=89.17% avg_auc=91.21%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.220593 Test loss=0.340400 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2115287184715271
[5/24] Train loss=0.18955038487911224
[10/24] Train loss=0.23848366737365723
[15/24] Train loss=0.2223343402147293
[20/24] Train loss=0.20287010073661804
Test set avg_accuracy=84.56% avg_sensitivity=66.82%, avg_specificity=91.27% avg_auc=89.75%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.213894 Test loss=0.356474 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.21285223960876465
[5/24] Train loss=0.1877623349428177
[10/24] Train loss=0.2272692769765854
[15/24] Train loss=0.22553010284900665
[20/24] Train loss=0.20096153020858765
Test set avg_accuracy=85.01% avg_sensitivity=64.64%, avg_specificity=92.73% avg_auc=89.54%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.212834 Test loss=0.352624 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.20172609388828278
[5/24] Train loss=0.1927727460861206
[10/24] Train loss=0.21789908409118652
[15/24] Train loss=0.21473586559295654
[20/24] Train loss=0.19953563809394836
Test set avg_accuracy=85.87% avg_sensitivity=65.21%, avg_specificity=93.70% avg_auc=90.19%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.208140 Test loss=0.342502 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.19688375294208527
[5/24] Train loss=0.18457818031311035
[10/24] Train loss=0.22751329839229584
[15/24] Train loss=0.22157350182533264
[20/24] Train loss=0.20231938362121582
Test set avg_accuracy=84.97% avg_sensitivity=65.02%, avg_specificity=92.53% avg_auc=90.55%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.210652 Test loss=0.343826 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1901339441537857
[5/24] Train loss=0.19114771485328674
[10/24] Train loss=0.22758561372756958
[15/24] Train loss=0.2085474282503128
[20/24] Train loss=0.19805943965911865
Test set avg_accuracy=85.94% avg_sensitivity=65.50%, avg_specificity=93.68% avg_auc=90.04%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.206191 Test loss=0.343547 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.18940341472625732
[5/24] Train loss=0.17361730337142944
[10/24] Train loss=0.21717748045921326
[15/24] Train loss=0.20481480658054352
[20/24] Train loss=0.19078916311264038
Test set avg_accuracy=85.36% avg_sensitivity=61.75%, avg_specificity=94.31% avg_auc=88.36%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.199530 Test loss=0.367296 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.18986308574676514
[5/24] Train loss=0.17213159799575806
[10/24] Train loss=0.22900792956352234
[15/24] Train loss=0.2132064700126648
[20/24] Train loss=0.201072096824646
Test set avg_accuracy=84.41% avg_sensitivity=56.92%, avg_specificity=94.83% avg_auc=87.74%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.202055 Test loss=0.381906 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.18798664212226868
[5/24] Train loss=0.17957672476768494
[10/24] Train loss=0.21970368921756744
[15/24] Train loss=0.2157902866601944
[20/24] Train loss=0.1927393674850464
Test set avg_accuracy=85.68% avg_sensitivity=70.47%, avg_specificity=91.44% avg_auc=90.36%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.201581 Test loss=0.338617 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.18979071080684662
[5/24] Train loss=0.1852526068687439
[10/24] Train loss=0.22082120180130005
[15/24] Train loss=0.21169444918632507
[20/24] Train loss=0.1917797327041626
Test set avg_accuracy=86.67% avg_sensitivity=71.47%, avg_specificity=92.42% avg_auc=90.98%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.201069 Test loss=0.330321 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.1890963464975357
[5/24] Train loss=0.1820431798696518
[10/24] Train loss=0.21548467874526978
[15/24] Train loss=0.21409425139427185
[20/24] Train loss=0.18751533329486847
Test set avg_accuracy=85.34% avg_sensitivity=64.74%, avg_specificity=93.14% avg_auc=89.11%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.196257 Test loss=0.357858 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.18474294245243073
[5/24] Train loss=0.1802825629711151
[10/24] Train loss=0.21230927109718323
[15/24] Train loss=0.20311878621578217
[20/24] Train loss=0.19061432778835297
Test set avg_accuracy=84.15% avg_sensitivity=59.81%, avg_specificity=93.38% avg_auc=87.60%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.196640 Test loss=0.386083 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.18895597755908966
[5/24] Train loss=0.17698682844638824
[10/24] Train loss=0.2102723866701126
[15/24] Train loss=0.20021021366119385
[20/24] Train loss=0.1891496479511261
Test set avg_accuracy=84.86% avg_sensitivity=68.44%, avg_specificity=91.08% avg_auc=88.57%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.196344 Test loss=0.369914 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.19328565895557404
[5/24] Train loss=0.17892515659332275
[10/24] Train loss=0.213479682803154
[15/24] Train loss=0.19845791161060333
[20/24] Train loss=0.18641367554664612
Test set avg_accuracy=84.35% avg_sensitivity=58.34%, avg_specificity=94.20% avg_auc=87.69%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.195568 Test loss=0.388700 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.18617583811283112
[5/24] Train loss=0.19187402725219727
[10/24] Train loss=0.21258103847503662
[15/24] Train loss=0.20880672335624695
[20/24] Train loss=0.18881040811538696
Test set avg_accuracy=84.78% avg_sensitivity=64.93%, avg_specificity=92.30% avg_auc=88.54%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.193788 Test loss=0.368196 Current lr=[0.000156543481933168]

[0/24] Train loss=0.1852492094039917
[5/24] Train loss=0.1793869435787201
[10/24] Train loss=0.1999448835849762
[15/24] Train loss=0.20643948018550873
[20/24] Train loss=0.1870606690645218
Test set avg_accuracy=85.23% avg_sensitivity=63.41%, avg_specificity=93.50% avg_auc=90.29%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.192694 Test loss=0.344550 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1925259828567505
[5/24] Train loss=0.18006747961044312
[10/24] Train loss=0.20398347079753876
[15/24] Train loss=0.19347280263900757
[20/24] Train loss=0.19123266637325287
Test set avg_accuracy=85.26% avg_sensitivity=64.36%, avg_specificity=93.18% avg_auc=90.01%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.191724 Test loss=0.353219 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.17654147744178772
[5/24] Train loss=0.175058051943779
[10/24] Train loss=0.20330189168453217
[15/24] Train loss=0.1971544325351715
[20/24] Train loss=0.1858317106962204
Test set avg_accuracy=86.08% avg_sensitivity=69.29%, avg_specificity=92.44% avg_auc=90.69%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.190197 Test loss=0.340118 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.17699815332889557
[5/24] Train loss=0.17563225328922272
[10/24] Train loss=0.20908914506435394
[15/24] Train loss=0.199525386095047
[20/24] Train loss=0.1926833838224411
Test set avg_accuracy=85.99% avg_sensitivity=68.86%, avg_specificity=92.48% avg_auc=91.40%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.191296 Test loss=0.338950 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.17718201875686646
[5/24] Train loss=0.17435967922210693
[10/24] Train loss=0.20776522159576416
[15/24] Train loss=0.19939611852169037
[20/24] Train loss=0.18990376591682434
Test set avg_accuracy=83.50% avg_sensitivity=52.32%, avg_specificity=95.31% avg_auc=87.62%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.188016 Test loss=0.399374 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1704641431570053
[5/24] Train loss=0.17096514999866486
[10/24] Train loss=0.20126521587371826
[15/24] Train loss=0.19649061560630798
[20/24] Train loss=0.1819458305835724
Test set avg_accuracy=84.19% avg_sensitivity=55.36%, avg_specificity=95.12% avg_auc=88.28%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.185534 Test loss=0.396842 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1785418540239334
[5/24] Train loss=0.16860586404800415
[10/24] Train loss=0.1990981101989746
[15/24] Train loss=0.2039615362882614
[20/24] Train loss=0.17933079600334167
Test set avg_accuracy=86.00% avg_sensitivity=66.07%, avg_specificity=93.55% avg_auc=90.71%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.182879 Test loss=0.343597 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.16801056265830994
[5/24] Train loss=0.1740298718214035
[10/24] Train loss=0.18858183920383453
[15/24] Train loss=0.19413983821868896
[20/24] Train loss=0.17742571234703064
Test set avg_accuracy=85.60% avg_sensitivity=63.79%, avg_specificity=93.86% avg_auc=89.52%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.181288 Test loss=0.360044 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.16560018062591553
[5/24] Train loss=0.16525164246559143
[10/24] Train loss=0.1926940530538559
[15/24] Train loss=0.1785251647233963
[20/24] Train loss=0.17565178871154785
Test set avg_accuracy=86.00% avg_sensitivity=69.10%, avg_specificity=92.41% avg_auc=90.79%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.178292 Test loss=0.337549 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.16312719881534576
[5/24] Train loss=0.16842137277126312
[10/24] Train loss=0.18983639776706696
[15/24] Train loss=0.18743504583835602
[20/24] Train loss=0.17308269441127777
Test set avg_accuracy=86.18% avg_sensitivity=67.39%, avg_specificity=93.30% avg_auc=90.35%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.177419 Test loss=0.347023 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16326533257961273
[5/24] Train loss=0.16282327473163605
[10/24] Train loss=0.1981600821018219
[15/24] Train loss=0.17757952213287354
[20/24] Train loss=0.1690015345811844
Test set avg_accuracy=85.85% avg_sensitivity=70.43%, avg_specificity=91.69% avg_auc=90.64%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.175104 Test loss=0.341412 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15522564947605133
[5/24] Train loss=0.16639591753482819
[10/24] Train loss=0.17801636457443237
[15/24] Train loss=0.18535958230495453
[20/24] Train loss=0.17440301179885864
Test set avg_accuracy=85.52% avg_sensitivity=74.79%, avg_specificity=89.59% avg_auc=90.69%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.170553 Test loss=0.348672 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.16202859580516815
[5/24] Train loss=0.15311181545257568
[10/24] Train loss=0.17965784668922424
[15/24] Train loss=0.17554086446762085
[20/24] Train loss=0.16808374226093292
Test set avg_accuracy=85.78% avg_sensitivity=71.80%, avg_specificity=91.08% avg_auc=90.47%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.169096 Test loss=0.347325 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.16046836972236633
[5/24] Train loss=0.15693257749080658
[10/24] Train loss=0.18091727793216705
[15/24] Train loss=0.17534852027893066
[20/24] Train loss=0.17755353450775146
Test set avg_accuracy=85.38% avg_sensitivity=74.88%, avg_specificity=89.35% avg_auc=91.15%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.168890 Test loss=0.345378 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15750421583652496
[5/24] Train loss=0.15386159718036652
[10/24] Train loss=0.18165171146392822
[15/24] Train loss=0.17797662317752838
[20/24] Train loss=0.1695699244737625
Test set avg_accuracy=86.48% avg_sensitivity=73.46%, avg_specificity=91.42% avg_auc=91.13%
Best model saved!! Metric=16.487974172956!!
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.166492 Test loss=0.335245 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.16189806163311005
[5/24] Train loss=0.14655901491641998
[10/24] Train loss=0.1807578206062317
[15/24] Train loss=0.17422232031822205
[20/24] Train loss=0.16610731184482574
Test set avg_accuracy=85.30% avg_sensitivity=74.45%, avg_specificity=89.41% avg_auc=90.79%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.165244 Test loss=0.345272 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.15145348012447357
[5/24] Train loss=0.15167981386184692
[10/24] Train loss=0.176677867770195
[15/24] Train loss=0.17343458533287048
[20/24] Train loss=0.16540983319282532
Test set avg_accuracy=85.59% avg_sensitivity=70.81%, avg_specificity=91.18% avg_auc=89.93%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.163568 Test loss=0.354730 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.15122157335281372
[5/24] Train loss=0.14635172486305237
[10/24] Train loss=0.17323535680770874
[15/24] Train loss=0.16518399119377136
[20/24] Train loss=0.1618468314409256
Test set avg_accuracy=85.68% avg_sensitivity=71.94%, avg_specificity=90.88% avg_auc=90.41%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.160511 Test loss=0.349969 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1501217633485794
[5/24] Train loss=0.1473575085401535
[10/24] Train loss=0.1708705723285675
[15/24] Train loss=0.16329753398895264
[20/24] Train loss=0.15820449590682983
Test set avg_accuracy=85.35% avg_sensitivity=74.12%, avg_specificity=89.61% avg_auc=90.57%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.158805 Test loss=0.355175 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14878903329372406
[5/24] Train loss=0.14857925474643707
[10/24] Train loss=0.17404253780841827
[15/24] Train loss=0.1646961122751236
[20/24] Train loss=0.15709537267684937
Test set avg_accuracy=85.52% avg_sensitivity=67.96%, avg_specificity=92.17% avg_auc=89.80%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.158184 Test loss=0.355095 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14628921449184418
[5/24] Train loss=0.1517854481935501
[10/24] Train loss=0.16814880073070526
[15/24] Train loss=0.15918901562690735
[20/24] Train loss=0.15289437770843506
Test set avg_accuracy=85.36% avg_sensitivity=66.68%, avg_specificity=92.44% avg_auc=89.05%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.155619 Test loss=0.363710 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14818935096263885
[5/24] Train loss=0.14209702610969543
[10/24] Train loss=0.16143350303173065
[15/24] Train loss=0.1571771651506424
[20/24] Train loss=0.15627656877040863
Test set avg_accuracy=84.95% avg_sensitivity=69.53%, avg_specificity=90.79% avg_auc=88.98%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.152982 Test loss=0.368739 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14730988442897797
[5/24] Train loss=0.14056842029094696
[10/24] Train loss=0.16089674830436707
[15/24] Train loss=0.16005538403987885
[20/24] Train loss=0.15002769231796265
Test set avg_accuracy=86.12% avg_sensitivity=69.29%, avg_specificity=92.50% avg_auc=89.38%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.151901 Test loss=0.356821 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14028801023960114
[5/24] Train loss=0.13751459121704102
[10/24] Train loss=0.15880067646503448
[15/24] Train loss=0.16026628017425537
[20/24] Train loss=0.1486097127199173
Test set avg_accuracy=85.62% avg_sensitivity=69.10%, avg_specificity=91.89% avg_auc=89.54%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.149602 Test loss=0.357080 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14101777970790863
[5/24] Train loss=0.1340986043214798
[10/24] Train loss=0.16085074841976166
[15/24] Train loss=0.1551540195941925
[20/24] Train loss=0.14761605858802795
Test set avg_accuracy=85.96% avg_sensitivity=68.20%, avg_specificity=92.69% avg_auc=89.15%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.148113 Test loss=0.356466 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.141347736120224
[5/24] Train loss=0.13560929894447327
[10/24] Train loss=0.1606624722480774
[15/24] Train loss=0.15362200140953064
[20/24] Train loss=0.14983858168125153
Test set avg_accuracy=86.05% avg_sensitivity=70.14%, avg_specificity=92.08% avg_auc=89.28%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.147295 Test loss=0.353370 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13825197517871857
[5/24] Train loss=0.13310606777668
[10/24] Train loss=0.1559595912694931
[15/24] Train loss=0.15005801618099213
[20/24] Train loss=0.1515399068593979
Test set avg_accuracy=86.03% avg_sensitivity=71.23%, avg_specificity=91.63% avg_auc=90.04%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.145351 Test loss=0.350232 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1385222226381302
[5/24] Train loss=0.13239820301532745
[10/24] Train loss=0.15689486265182495
[15/24] Train loss=0.1498372107744217
[20/24] Train loss=0.1444806158542633
Test set avg_accuracy=86.04% avg_sensitivity=70.00%, avg_specificity=92.12% avg_auc=89.51%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.143966 Test loss=0.354834 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1372600942850113
[5/24] Train loss=0.1289047747850418
[10/24] Train loss=0.15239863097667694
[15/24] Train loss=0.149835005402565
[20/24] Train loss=0.14230214059352875
Test set avg_accuracy=86.24% avg_sensitivity=68.91%, avg_specificity=92.80% avg_auc=89.48%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.142566 Test loss=0.356309 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13413624465465546
[5/24] Train loss=0.12965992093086243
[10/24] Train loss=0.15094603598117828
[15/24] Train loss=0.1473819762468338
[20/24] Train loss=0.14260993897914886
Test set avg_accuracy=86.07% avg_sensitivity=69.15%, avg_specificity=92.48% avg_auc=89.86%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.141618 Test loss=0.350665 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1326446831226349
[5/24] Train loss=0.1295984834432602
[10/24] Train loss=0.15283390879631042
[15/24] Train loss=0.15044425427913666
[20/24] Train loss=0.14098593592643738
Test set avg_accuracy=85.89% avg_sensitivity=70.85%, avg_specificity=91.58% avg_auc=90.37%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.141367 Test loss=0.346009 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13634860515594482
[5/24] Train loss=0.1253320574760437
[10/24] Train loss=0.15183432400226593
[15/24] Train loss=0.1463925987482071
[20/24] Train loss=0.1414404958486557
Test set avg_accuracy=86.13% avg_sensitivity=67.82%, avg_specificity=93.07% avg_auc=89.40%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.140102 Test loss=0.352432 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13434337079524994
[5/24] Train loss=0.12653446197509766
[10/24] Train loss=0.148236945271492
[15/24] Train loss=0.14635248482227325
[20/24] Train loss=0.14051800966262817
Test set avg_accuracy=85.90% avg_sensitivity=68.25%, avg_specificity=92.59% avg_auc=89.71%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.138598 Test loss=0.352142 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13086211681365967
[5/24] Train loss=0.12640348076820374
[10/24] Train loss=0.14995308220386505
[15/24] Train loss=0.1459326148033142
[20/24] Train loss=0.14051859080791473
Test set avg_accuracy=86.05% avg_sensitivity=68.91%, avg_specificity=92.55% avg_auc=89.58%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.138137 Test loss=0.354641 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12898604571819305
[5/24] Train loss=0.12561483681201935
[10/24] Train loss=0.14721953868865967
[15/24] Train loss=0.1449512243270874
[20/24] Train loss=0.14168404042720795
Test set avg_accuracy=86.00% avg_sensitivity=70.66%, avg_specificity=91.81% avg_auc=90.13%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.136858 Test loss=0.348643 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13209128379821777
[5/24] Train loss=0.12553641200065613
[10/24] Train loss=0.147568479180336
[15/24] Train loss=0.1462676078081131
[20/24] Train loss=0.1404542326927185
Test set avg_accuracy=85.91% avg_sensitivity=69.43%, avg_specificity=92.15% avg_auc=89.83%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.137190 Test loss=0.355270 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13150542974472046
[5/24] Train loss=0.12477573752403259
[10/24] Train loss=0.14648407697677612
[15/24] Train loss=0.14589323103427887
[20/24] Train loss=0.13813839852809906
Test set avg_accuracy=85.79% avg_sensitivity=69.76%, avg_specificity=91.87% avg_auc=89.75%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.137274 Test loss=0.357955 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12964724004268646
[5/24] Train loss=0.12600255012512207
[10/24] Train loss=0.14252455532550812
[15/24] Train loss=0.14773637056350708
[20/24] Train loss=0.1373719871044159
Test set avg_accuracy=85.90% avg_sensitivity=70.81%, avg_specificity=91.62% avg_auc=90.24%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.136773 Test loss=0.349105 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1283535361289978
[5/24] Train loss=0.1271650791168213
[10/24] Train loss=0.1430477499961853
[15/24] Train loss=0.14762486517429352
[20/24] Train loss=0.1372717022895813
Test set avg_accuracy=86.22% avg_sensitivity=71.47%, avg_specificity=91.81% avg_auc=90.10%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.135962 Test loss=0.349351 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12634654343128204
[5/24] Train loss=0.12315327674150467
[10/24] Train loss=0.14677827060222626
[15/24] Train loss=0.14271968603134155
[20/24] Train loss=0.13556532561779022
Test set avg_accuracy=85.96% avg_sensitivity=71.85%, avg_specificity=91.31% avg_auc=90.00%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.135282 Test loss=0.354263 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12986771762371063
[5/24] Train loss=0.12362650781869888
[10/24] Train loss=0.14113010466098785
[15/24] Train loss=0.14232000708580017
[20/24] Train loss=0.1364918202161789
Test set avg_accuracy=86.12% avg_sensitivity=70.05%, avg_specificity=92.21% avg_auc=89.87%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.133940 Test loss=0.355848 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12856601178646088
[5/24] Train loss=0.12341533601284027
[10/24] Train loss=0.14470015466213226
[15/24] Train loss=0.14058874547481537
[20/24] Train loss=0.1374189704656601
Test set avg_accuracy=86.12% avg_sensitivity=70.81%, avg_specificity=91.92% avg_auc=90.17%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.133035 Test loss=0.349934 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12677381932735443
[5/24] Train loss=0.11993599683046341
[10/24] Train loss=0.141865536570549
[15/24] Train loss=0.14107882976531982
[20/24] Train loss=0.1355392336845398
Test set avg_accuracy=86.28% avg_sensitivity=71.37%, avg_specificity=91.92% avg_auc=89.96%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.132806 Test loss=0.352968 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12700264155864716
[5/24] Train loss=0.12315583974123001
[10/24] Train loss=0.1397620290517807
[15/24] Train loss=0.13915377855300903
[20/24] Train loss=0.1348777860403061
Test set avg_accuracy=86.05% avg_sensitivity=71.04%, avg_specificity=91.74% avg_auc=90.02%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.132106 Test loss=0.351705 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1250608265399933
[5/24] Train loss=0.12035100162029266
[10/24] Train loss=0.13952703773975372
[15/24] Train loss=0.14018169045448303
[20/24] Train loss=0.13257341086864471
Test set avg_accuracy=86.04% avg_sensitivity=71.00%, avg_specificity=91.74% avg_auc=89.98%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.131232 Test loss=0.353906 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12599679827690125
[5/24] Train loss=0.12448723614215851
[10/24] Train loss=0.14176718890666962
[15/24] Train loss=0.14083394408226013
[20/24] Train loss=0.13359807431697845
Test set avg_accuracy=86.35% avg_sensitivity=71.00%, avg_specificity=92.17% avg_auc=89.99%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.132072 Test loss=0.352579 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12722884118556976
[5/24] Train loss=0.12379360944032669
[10/24] Train loss=0.14020265638828278
[15/24] Train loss=0.1408054381608963
[20/24] Train loss=0.13361534476280212
Test set avg_accuracy=86.35% avg_sensitivity=71.14%, avg_specificity=92.12% avg_auc=90.04%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.131805 Test loss=0.351719 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12745784223079681
[5/24] Train loss=0.12076089531183243
[10/24] Train loss=0.14127472043037415
[15/24] Train loss=0.13979318737983704
[20/24] Train loss=0.134658545255661
Test set avg_accuracy=86.15% avg_sensitivity=70.38%, avg_specificity=92.12% avg_auc=89.90%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.131826 Test loss=0.354110 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12673765420913696
[5/24] Train loss=0.12122383713722229
[10/24] Train loss=0.13835562765598297
[15/24] Train loss=0.1392781138420105
[20/24] Train loss=0.13400690257549286
Test set avg_accuracy=86.09% avg_sensitivity=71.00%, avg_specificity=91.81% avg_auc=89.95%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.131173 Test loss=0.353682 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12544406950473785
[5/24] Train loss=0.12027294933795929
[10/24] Train loss=0.13950616121292114
[15/24] Train loss=0.14071890711784363
[20/24] Train loss=0.13484852015972137
Test set avg_accuracy=86.16% avg_sensitivity=70.76%, avg_specificity=91.99% avg_auc=89.96%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.131432 Test loss=0.353195 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12541507184505463
[5/24] Train loss=0.12215707451105118
[10/24] Train loss=0.14124581217765808
[15/24] Train loss=0.13937155902385712
[20/24] Train loss=0.13360396027565002
Test set avg_accuracy=86.21% avg_sensitivity=70.81%, avg_specificity=92.05% avg_auc=90.00%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.131180 Test loss=0.352625 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1251339465379715
[5/24] Train loss=0.11871557682752609
[10/24] Train loss=0.13989655673503876
[15/24] Train loss=0.13826504349708557
[20/24] Train loss=0.13180823624134064
Test set avg_accuracy=86.21% avg_sensitivity=70.95%, avg_specificity=91.99% avg_auc=90.00%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.130684 Test loss=0.352626 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12529316544532776
[5/24] Train loss=0.11929355561733246
[10/24] Train loss=0.14023511111736298
[15/24] Train loss=0.13773463666439056
[20/24] Train loss=0.13329903781414032
Test set avg_accuracy=86.20% avg_sensitivity=70.90%, avg_specificity=91.99% avg_auc=90.00%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.130645 Test loss=0.352761 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12360595911741257
[5/24] Train loss=0.12187287956476212
[10/24] Train loss=0.13947761058807373
[15/24] Train loss=0.13869360089302063
[20/24] Train loss=0.1341690570116043
Test set avg_accuracy=86.22% avg_sensitivity=71.00%, avg_specificity=91.99% avg_auc=90.00%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.131090 Test loss=0.352875 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=86.48% sen=73.46%, spe=91.42%, auc=91.13%!
Fold[3] Avg_overlap=0.65%(±0.25029244974995074)
[0/24] Train loss=0.7549853920936584
[5/24] Train loss=0.7493078112602234
[10/24] Train loss=0.7467688918113708
[15/24] Train loss=0.7348284721374512
[20/24] Train loss=0.7262052297592163
Test set avg_accuracy=56.18% avg_sensitivity=50.07%, avg_specificity=58.34% avg_auc=56.50%
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.740305 Test loss=0.696831 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7265288233757019
[5/24] Train loss=0.7279887795448303
[10/24] Train loss=0.7220133543014526
[15/24] Train loss=0.7107784152030945
[20/24] Train loss=0.7092716097831726
Test set avg_accuracy=59.23% avg_sensitivity=60.82%, avg_specificity=58.67% avg_auc=64.33%
Best model saved!! Metric=-82.95097684899736!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.718786 Test loss=0.657806 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6950798630714417
[5/24] Train loss=0.7154116630554199
[10/24] Train loss=0.6995010375976562
[15/24] Train loss=0.6815099716186523
[20/24] Train loss=0.6724832057952881
Test set avg_accuracy=63.61% avg_sensitivity=65.52%, avg_specificity=62.93% avg_auc=69.99%
Best model saved!! Metric=-63.9549989069066!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.695200 Test loss=0.633002 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6731962561607361
[5/24] Train loss=0.6849411725997925
[10/24] Train loss=0.6833984851837158
[15/24] Train loss=0.6580232381820679
[20/24] Train loss=0.6481531262397766
Test set avg_accuracy=66.32% avg_sensitivity=71.11%, avg_specificity=64.62% avg_auc=73.87%
Best model saved!! Metric=-50.0753098884998!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.671662 Test loss=0.616506 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6413346529006958
[5/24] Train loss=0.6566490530967712
[10/24] Train loss=0.6539768576622009
[15/24] Train loss=0.6317479610443115
[20/24] Train loss=0.621768057346344
Test set avg_accuracy=68.05% avg_sensitivity=75.96%, avg_specificity=65.26% avg_auc=77.25%
Best model saved!! Metric=-39.48243870201499!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.646268 Test loss=0.595956 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6124328970909119
[5/24] Train loss=0.6285585165023804
[10/24] Train loss=0.6314619779586792
[15/24] Train loss=0.6081138849258423
[20/24] Train loss=0.5916880965232849
Test set avg_accuracy=69.60% avg_sensitivity=78.01%, avg_specificity=66.63% avg_auc=79.69%
Best model saved!! Metric=-32.069867133671025!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.619634 Test loss=0.574356 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5846984386444092
[5/24] Train loss=0.5905842185020447
[10/24] Train loss=0.6014931797981262
[15/24] Train loss=0.5645617246627808
[20/24] Train loss=0.5606876611709595
Test set avg_accuracy=71.58% avg_sensitivity=79.91%, avg_specificity=68.64% avg_auc=81.67%
Best model saved!! Metric=-24.203368556273674!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.587438 Test loss=0.554178 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5543227195739746
[5/24] Train loss=0.5619149804115295
[10/24] Train loss=0.5747761130332947
[15/24] Train loss=0.5374118089675903
[20/24] Train loss=0.53316330909729
Test set avg_accuracy=74.15% avg_sensitivity=78.71%, avg_specificity=72.55% avg_auc=83.33%
Best model saved!! Metric=-17.253331959685994!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.558209 Test loss=0.525754 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5221586227416992
[5/24] Train loss=0.5209732055664062
[10/24] Train loss=0.5422090291976929
[15/24] Train loss=0.508192777633667
[20/24] Train loss=0.4961133599281311
Test set avg_accuracy=76.84% avg_sensitivity=79.16%, avg_specificity=76.02% avg_auc=85.26%
Best model saved!! Metric=-8.72578102443208!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.527044 Test loss=0.493780 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.49358418583869934
[5/24] Train loss=0.4877254068851471
[10/24] Train loss=0.5216730833053589
[15/24] Train loss=0.47751760482788086
[20/24] Train loss=0.4673193395137787
Test set avg_accuracy=78.74% avg_sensitivity=78.86%, avg_specificity=78.69% avg_auc=86.51%
Best model saved!! Metric=-3.203082146223295!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.497655 Test loss=0.466337 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4765467047691345
[5/24] Train loss=0.453911691904068
[10/24] Train loss=0.4921882152557373
[15/24] Train loss=0.45889177918434143
[20/24] Train loss=0.4425804316997528
Test set avg_accuracy=80.78% avg_sensitivity=75.36%, avg_specificity=82.69% avg_auc=87.40%
Best model saved!! Metric=0.23159227031581509!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.471433 Test loss=0.436307 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.45097604393959045
[5/24] Train loss=0.42827361822128296
[10/24] Train loss=0.47512930631637573
[15/24] Train loss=0.432460755109787
[20/24] Train loss=0.4205291271209717
Test set avg_accuracy=82.29% avg_sensitivity=73.91%, avg_specificity=85.24% avg_auc=88.29%
Best model saved!! Metric=3.738307846868935!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.447417 Test loss=0.412318 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4258164167404175
[5/24] Train loss=0.39897972345352173
[10/24] Train loss=0.4561024308204651
[15/24] Train loss=0.41107818484306335
[20/24] Train loss=0.3905608057975769
Test set avg_accuracy=83.27% avg_sensitivity=72.01%, avg_specificity=87.23% avg_auc=88.84%
Best model saved!! Metric=5.35411754841347!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.423827 Test loss=0.394396 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.40304484963417053
[5/24] Train loss=0.3832918107509613
[10/24] Train loss=0.43400320410728455
[15/24] Train loss=0.3980267643928528
[20/24] Train loss=0.3800235688686371
Test set avg_accuracy=83.88% avg_sensitivity=65.37%, avg_specificity=90.40% avg_auc=88.75%
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.404759 Test loss=0.375617 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3839305341243744
[5/24] Train loss=0.35873299837112427
[10/24] Train loss=0.41802212595939636
[15/24] Train loss=0.37844571471214294
[20/24] Train loss=0.3626030683517456
Test set avg_accuracy=83.59% avg_sensitivity=58.62%, avg_specificity=92.39% avg_auc=88.31%
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.388672 Test loss=0.372755 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.37312179803848267
[5/24] Train loss=0.34549859166145325
[10/24] Train loss=0.4077880382537842
[15/24] Train loss=0.36751604080200195
[20/24] Train loss=0.35368454456329346
Test set avg_accuracy=84.26% avg_sensitivity=63.32%, avg_specificity=91.64% avg_auc=89.35%
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.373131 Test loss=0.361087 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.35756608843803406
[5/24] Train loss=0.3307341933250427
[10/24] Train loss=0.39730316400527954
[15/24] Train loss=0.3505658209323883
[20/24] Train loss=0.342520534992218
Test set avg_accuracy=84.47% avg_sensitivity=60.37%, avg_specificity=92.96% avg_auc=89.19%
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.360028 Test loss=0.358119 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3491392433643341
[5/24] Train loss=0.30959779024124146
[10/24] Train loss=0.3852521479129791
[15/24] Train loss=0.34720563888549805
[20/24] Train loss=0.3292846083641052
Test set avg_accuracy=84.74% avg_sensitivity=63.22%, avg_specificity=92.32% avg_auc=89.72%
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.348053 Test loss=0.350080 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3332422375679016
[5/24] Train loss=0.2985175549983978
[10/24] Train loss=0.36950936913490295
[15/24] Train loss=0.3344818949699402
[20/24] Train loss=0.32418203353881836
Test set avg_accuracy=84.49% avg_sensitivity=58.07%, avg_specificity=93.80% avg_auc=89.24%
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.337863 Test loss=0.355448 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3279193937778473
[5/24] Train loss=0.29070761799812317
[10/24] Train loss=0.3561556935310364
[15/24] Train loss=0.32826635241508484
[20/24] Train loss=0.3115236163139343
Test set avg_accuracy=85.20% avg_sensitivity=59.02%, avg_specificity=94.42% avg_auc=89.86%
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.328248 Test loss=0.345778 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.322684645652771
[5/24] Train loss=0.2834523618221283
[10/24] Train loss=0.3489304482936859
[15/24] Train loss=0.3299139142036438
[20/24] Train loss=0.30629831552505493
Test set avg_accuracy=85.23% avg_sensitivity=62.87%, avg_specificity=93.11% avg_auc=90.32%
Best model saved!! Metric=5.5399332615454!!
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.321979 Test loss=0.338012 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3150211572647095
[5/24] Train loss=0.28168147802352905
[10/24] Train loss=0.34144327044487
[15/24] Train loss=0.31874459981918335
[20/24] Train loss=0.30516812205314636
Test set avg_accuracy=85.77% avg_sensitivity=60.52%, avg_specificity=94.66% avg_auc=90.57%
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.313617 Test loss=0.335034 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.30527612566947937
[5/24] Train loss=0.26780691742897034
[10/24] Train loss=0.3336668014526367
[15/24] Train loss=0.3149917423725128
[20/24] Train loss=0.2982741594314575
Test set avg_accuracy=85.83% avg_sensitivity=65.47%, avg_specificity=93.01% avg_auc=91.28%
Best model saved!! Metric=9.588571051681384!!
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.308484 Test loss=0.324153 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.30148807168006897
[5/24] Train loss=0.2680317759513855
[10/24] Train loss=0.33593443036079407
[15/24] Train loss=0.3037899136543274
[20/24] Train loss=0.29430240392684937
Test set avg_accuracy=85.64% avg_sensitivity=57.52%, avg_specificity=95.54% avg_auc=91.03%
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.302936 Test loss=0.331699 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2987237572669983
[5/24] Train loss=0.26208120584487915
[10/24] Train loss=0.3310651183128357
[15/24] Train loss=0.30127254128456116
[20/24] Train loss=0.2884885370731354
Test set avg_accuracy=85.44% avg_sensitivity=54.57%, avg_specificity=96.32% avg_auc=90.74%
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.297520 Test loss=0.338867 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.28739455342292786
[5/24] Train loss=0.2583702802658081
[10/24] Train loss=0.32129061222076416
[15/24] Train loss=0.3020137846469879
[20/24] Train loss=0.28633275628089905
Test set avg_accuracy=85.76% avg_sensitivity=58.42%, avg_specificity=95.39% avg_auc=91.54%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.292102 Test loss=0.324294 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.28293296694755554
[5/24] Train loss=0.25282806158065796
[10/24] Train loss=0.32552552223205566
[15/24] Train loss=0.2983616590499878
[20/24] Train loss=0.2802603542804718
Test set avg_accuracy=85.30% avg_sensitivity=54.72%, avg_specificity=96.07% avg_auc=91.26%
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.289487 Test loss=0.332920 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2806369364261627
[5/24] Train loss=0.2462252378463745
[10/24] Train loss=0.3246940076351166
[15/24] Train loss=0.2999010980129242
[20/24] Train loss=0.2763265073299408
Test set avg_accuracy=85.64% avg_sensitivity=56.37%, avg_specificity=95.95% avg_auc=91.52%
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.285067 Test loss=0.325683 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2741106152534485
[5/24] Train loss=0.23319962620735168
[10/24] Train loss=0.3198486566543579
[15/24] Train loss=0.2927296459674835
[20/24] Train loss=0.2756411135196686
Test set avg_accuracy=84.04% avg_sensitivity=46.03%, avg_specificity=97.43% avg_auc=90.28%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.283248 Test loss=0.368061 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2755647301673889
[5/24] Train loss=0.2383953034877777
[10/24] Train loss=0.31465333700180054
[15/24] Train loss=0.28537434339523315
[20/24] Train loss=0.27270743250846863
Test set avg_accuracy=83.98% avg_sensitivity=46.23%, avg_specificity=97.29% avg_auc=90.02%
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.277695 Test loss=0.366930 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2707824110984802
[5/24] Train loss=0.23240885138511658
[10/24] Train loss=0.31128180027008057
[15/24] Train loss=0.28492799401283264
[20/24] Train loss=0.2687374949455261
Test set avg_accuracy=85.26% avg_sensitivity=53.07%, avg_specificity=96.60% avg_auc=91.07%
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.273706 Test loss=0.337519 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2698109745979309
[5/24] Train loss=0.23049673438072205
[10/24] Train loss=0.3028380274772644
[15/24] Train loss=0.2857443690299988
[20/24] Train loss=0.26719358563423157
Test set avg_accuracy=85.87% avg_sensitivity=56.47%, avg_specificity=96.23% avg_auc=91.30%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.272165 Test loss=0.328599 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2564595937728882
[5/24] Train loss=0.2318122684955597
[10/24] Train loss=0.30471041798591614
[15/24] Train loss=0.2795332968235016
[20/24] Train loss=0.26359400153160095
Test set avg_accuracy=85.00% avg_sensitivity=51.67%, avg_specificity=96.74% avg_auc=91.53%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.269319 Test loss=0.331684 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2690136134624481
[5/24] Train loss=0.22822104394435883
[10/24] Train loss=0.2947614789009094
[15/24] Train loss=0.2825993299484253
[20/24] Train loss=0.2652820944786072
Test set avg_accuracy=86.24% avg_sensitivity=59.67%, avg_specificity=95.60% avg_auc=91.23%
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.268009 Test loss=0.324061 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2567836046218872
[5/24] Train loss=0.22248093783855438
[10/24] Train loss=0.2981918454170227
[15/24] Train loss=0.274053156375885
[20/24] Train loss=0.26183608174324036
Test set avg_accuracy=85.56% avg_sensitivity=55.87%, avg_specificity=96.02% avg_auc=90.86%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.264547 Test loss=0.333714 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.25469356775283813
[5/24] Train loss=0.22423063218593597
[10/24] Train loss=0.2859145700931549
[15/24] Train loss=0.27572187781333923
[20/24] Train loss=0.26767581701278687
Test set avg_accuracy=84.18% avg_sensitivity=46.88%, avg_specificity=97.32% avg_auc=89.59%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.265153 Test loss=0.377674 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2628120481967926
[5/24] Train loss=0.22901175916194916
[10/24] Train loss=0.30331313610076904
[15/24] Train loss=0.28230413794517517
[20/24] Train loss=0.26301515102386475
Test set avg_accuracy=82.24% avg_sensitivity=36.58%, avg_specificity=98.33% avg_auc=87.45%
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.263344 Test loss=0.422593 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2554100751876831
[5/24] Train loss=0.22119252383708954
[10/24] Train loss=0.3062274754047394
[15/24] Train loss=0.2638823091983795
[20/24] Train loss=0.2626909613609314
Test set avg_accuracy=81.37% avg_sensitivity=31.73%, avg_specificity=98.86% avg_auc=87.47%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.261534 Test loss=0.439148 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2593638300895691
[5/24] Train loss=0.21858899295330048
[10/24] Train loss=0.295846551656723
[15/24] Train loss=0.2770300507545471
[20/24] Train loss=0.26001375913619995
Test set avg_accuracy=80.55% avg_sensitivity=27.94%, avg_specificity=99.08% avg_auc=85.53%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.259409 Test loss=0.471458 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2534627616405487
[5/24] Train loss=0.2200382649898529
[10/24] Train loss=0.28280743956565857
[15/24] Train loss=0.27685579657554626
[20/24] Train loss=0.26513609290122986
Test set avg_accuracy=82.16% avg_sensitivity=35.93%, avg_specificity=98.45% avg_auc=86.59%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.259577 Test loss=0.430541 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2504064440727234
[5/24] Train loss=0.21900978684425354
[10/24] Train loss=0.2833216190338135
[15/24] Train loss=0.26945415139198303
[20/24] Train loss=0.2569507956504822
Test set avg_accuracy=78.97% avg_sensitivity=20.89%, avg_specificity=99.44% avg_auc=86.30%
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.261826 Test loss=0.552949 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2545190751552582
[5/24] Train loss=0.21982349455356598
[10/24] Train loss=0.2809464931488037
[15/24] Train loss=0.27268531918525696
[20/24] Train loss=0.2525154948234558
Test set avg_accuracy=83.74% avg_sensitivity=43.93%, avg_specificity=97.76% avg_auc=89.99%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.257762 Test loss=0.383202 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.24607478082180023
[5/24] Train loss=0.21187354624271393
[10/24] Train loss=0.27064090967178345
[15/24] Train loss=0.2622006833553314
[20/24] Train loss=0.25819289684295654
Test set avg_accuracy=84.11% avg_sensitivity=47.33%, avg_specificity=97.08% avg_auc=90.34%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.254432 Test loss=0.364933 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2517072260379791
[5/24] Train loss=0.2107255607843399
[10/24] Train loss=0.27073734998703003
[15/24] Train loss=0.26130959391593933
[20/24] Train loss=0.25196489691734314
Test set avg_accuracy=82.32% avg_sensitivity=37.43%, avg_specificity=98.13% avg_auc=87.02%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.253037 Test loss=0.447495 Current lr=[0.00029967723776099]

[0/24] Train loss=0.23928993940353394
[5/24] Train loss=0.2146548479795456
[10/24] Train loss=0.26115453243255615
[15/24] Train loss=0.2750152051448822
[20/24] Train loss=0.2536570727825165
Test set avg_accuracy=82.99% avg_sensitivity=40.78%, avg_specificity=97.87% avg_auc=88.46%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.251480 Test loss=0.409312 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2582579553127289
[5/24] Train loss=0.22178059816360474
[10/24] Train loss=0.2775813043117523
[15/24] Train loss=0.26556098461151123
[20/24] Train loss=0.2527829110622406
Test set avg_accuracy=86.91% avg_sensitivity=65.27%, avg_specificity=94.54% avg_auc=91.99%
Best model saved!! Metric=12.71460174437675!!
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.254726 Test loss=0.307090 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.24538548290729523
[5/24] Train loss=0.21733908355236053
[10/24] Train loss=0.28781047463417053
[15/24] Train loss=0.26903581619262695
[20/24] Train loss=0.24998240172863007
Test set avg_accuracy=85.59% avg_sensitivity=57.47%, avg_specificity=95.49% avg_auc=90.76%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.254258 Test loss=0.340304 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2521251440048218
[5/24] Train loss=0.2051457166671753
[10/24] Train loss=0.27525579929351807
[15/24] Train loss=0.26200470328330994
[20/24] Train loss=0.2593156695365906
Test set avg_accuracy=83.03% avg_sensitivity=41.18%, avg_specificity=97.78% avg_auc=88.79%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.249998 Test loss=0.402191 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.25544679164886475
[5/24] Train loss=0.21021561324596405
[10/24] Train loss=0.25596868991851807
[15/24] Train loss=0.2511660158634186
[20/24] Train loss=0.24371011555194855
Test set avg_accuracy=83.41% avg_sensitivity=42.48%, avg_specificity=97.83% avg_auc=88.26%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.244645 Test loss=0.423581 Current lr=[0.000298904600941902]

[0/24] Train loss=0.24968796968460083
[5/24] Train loss=0.21452151238918304
[10/24] Train loss=0.2512335479259491
[15/24] Train loss=0.25916656851768494
[20/24] Train loss=0.2536331117153168
Test set avg_accuracy=82.34% avg_sensitivity=37.93%, avg_specificity=97.99% avg_auc=83.73%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.243401 Test loss=0.468090 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.24338145554065704
[5/24] Train loss=0.20834586024284363
[10/24] Train loss=0.2713463008403778
[15/24] Train loss=0.250454306602478
[20/24] Train loss=0.250696063041687
Test set avg_accuracy=82.62% avg_sensitivity=38.18%, avg_specificity=98.27% avg_auc=86.70%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.242646 Test loss=0.420239 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2457408308982849
[5/24] Train loss=0.20523667335510254
[10/24] Train loss=0.25838589668273926
[15/24] Train loss=0.25854477286338806
[20/24] Train loss=0.24843865633010864
Test set avg_accuracy=86.91% avg_sensitivity=63.82%, avg_specificity=95.05% avg_auc=90.75%
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.245338 Test loss=0.328718 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.24504926800727844
[5/24] Train loss=0.2045488953590393
[10/24] Train loss=0.2696913480758667
[15/24] Train loss=0.26659971475601196
[20/24] Train loss=0.25126349925994873
Test set avg_accuracy=84.84% avg_sensitivity=58.72%, avg_specificity=94.05% avg_auc=89.93%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.243296 Test loss=0.346337 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2430272251367569
[5/24] Train loss=0.19704042375087738
[10/24] Train loss=0.26506343483924866
[15/24] Train loss=0.2574175000190735
[20/24] Train loss=0.24253639578819275
Test set avg_accuracy=85.21% avg_sensitivity=52.67%, avg_specificity=96.67% avg_auc=89.51%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.241632 Test loss=0.366122 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.24707280099391937
[5/24] Train loss=0.21116459369659424
[10/24] Train loss=0.24478211998939514
[15/24] Train loss=0.2696518003940582
[20/24] Train loss=0.24566343426704407
Test set avg_accuracy=86.43% avg_sensitivity=64.27%, avg_specificity=94.24% avg_auc=91.54%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.241111 Test loss=0.318039 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2358648031949997
[5/24] Train loss=0.20062650740146637
[10/24] Train loss=0.24486403167247772
[15/24] Train loss=0.25246742367744446
[20/24] Train loss=0.2509128451347351
Test set avg_accuracy=86.26% avg_sensitivity=64.77%, avg_specificity=93.84% avg_auc=89.99%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.238417 Test loss=0.338231 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.22776789963245392
[5/24] Train loss=0.20094996690750122
[10/24] Train loss=0.24246691167354584
[15/24] Train loss=0.25437504053115845
[20/24] Train loss=0.23400196433067322
Test set avg_accuracy=84.73% avg_sensitivity=51.27%, avg_specificity=96.51% avg_auc=89.50%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.237555 Test loss=0.369408 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.23302330076694489
[5/24] Train loss=0.20426376163959503
[10/24] Train loss=0.27093052864074707
[15/24] Train loss=0.25296175479888916
[20/24] Train loss=0.24090087413787842
Test set avg_accuracy=83.87% avg_sensitivity=50.67%, avg_specificity=95.56% avg_auc=88.76%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.237532 Test loss=0.376488 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.24579085409641266
[5/24] Train loss=0.21130800247192383
[10/24] Train loss=0.2451319545507431
[15/24] Train loss=0.238145112991333
[20/24] Train loss=0.24378331005573273
Test set avg_accuracy=86.37% avg_sensitivity=69.47%, avg_specificity=92.32% avg_auc=91.01%
Best model saved!! Metric=13.160407019840363!!
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.237801 Test loss=0.324333 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.23542247712612152
[5/24] Train loss=0.19281752407550812
[10/24] Train loss=0.25226280093193054
[15/24] Train loss=0.2407871037721634
[20/24] Train loss=0.24132928252220154
Test set avg_accuracy=82.85% avg_sensitivity=57.97%, avg_specificity=91.62% avg_auc=87.54%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.232003 Test loss=0.395961 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2213955968618393
[5/24] Train loss=0.19540247321128845
[10/24] Train loss=0.24300070106983185
[15/24] Train loss=0.24066981673240662
[20/24] Train loss=0.23902101814746857
Test set avg_accuracy=82.12% avg_sensitivity=38.73%, avg_specificity=97.41% avg_auc=84.97%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.234007 Test loss=0.462796 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.24591079354286194
[5/24] Train loss=0.19229383766651154
[10/24] Train loss=0.2556358873844147
[15/24] Train loss=0.2564540505409241
[20/24] Train loss=0.23752181231975555
Test set avg_accuracy=85.09% avg_sensitivity=52.72%, avg_specificity=96.50% avg_auc=88.99%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.235629 Test loss=0.375685 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.22450749576091766
[5/24] Train loss=0.19512911140918732
[10/24] Train loss=0.2553313076496124
[15/24] Train loss=0.2420770823955536
[20/24] Train loss=0.2394704669713974
Test set avg_accuracy=81.02% avg_sensitivity=30.18%, avg_specificity=98.93% avg_auc=84.01%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.234332 Test loss=0.492825 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.23124895989894867
[5/24] Train loss=0.19528351724147797
[10/24] Train loss=0.24915288388729095
[15/24] Train loss=0.261135995388031
[20/24] Train loss=0.23315902054309845
Test set avg_accuracy=86.71% avg_sensitivity=63.97%, avg_specificity=94.72% avg_auc=90.83%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.229910 Test loss=0.326727 Current lr=[0.000276307469034998]

[0/24] Train loss=0.22655893862247467
[5/24] Train loss=0.19044403731822968
[10/24] Train loss=0.23921123147010803
[15/24] Train loss=0.25374990701675415
[20/24] Train loss=0.23219233751296997
Test set avg_accuracy=81.90% avg_sensitivity=35.93%, avg_specificity=98.10% avg_auc=84.39%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.231135 Test loss=0.514626 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.2300785779953003
[5/24] Train loss=0.20450711250305176
[10/24] Train loss=0.25736281275749207
[15/24] Train loss=0.24265894293785095
[20/24] Train loss=0.23850153386592865
Test set avg_accuracy=83.49% avg_sensitivity=44.13%, avg_specificity=97.36% avg_auc=88.79%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.231243 Test loss=0.397785 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.22688007354736328
[5/24] Train loss=0.18858815729618073
[10/24] Train loss=0.23574721813201904
[15/24] Train loss=0.24647746980190277
[20/24] Train loss=0.23353375494480133
Test set avg_accuracy=85.79% avg_sensitivity=64.02%, avg_specificity=93.47% avg_auc=90.67%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.227253 Test loss=0.330703 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.21350659430027008
[5/24] Train loss=0.19321483373641968
[10/24] Train loss=0.2450898140668869
[15/24] Train loss=0.24110077321529388
[20/24] Train loss=0.2385081648826599
Test set avg_accuracy=83.79% avg_sensitivity=44.78%, avg_specificity=97.53% avg_auc=87.76%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.227300 Test loss=0.414005 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2162417769432068
[5/24] Train loss=0.19244354963302612
[10/24] Train loss=0.24109698832035065
[15/24] Train loss=0.25373178720474243
[20/24] Train loss=0.2264738827943802
Test set avg_accuracy=84.78% avg_sensitivity=51.87%, avg_specificity=96.37% avg_auc=90.45%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.228740 Test loss=0.362722 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.21723856031894684
[5/24] Train loss=0.19564327597618103
[10/24] Train loss=0.24425660073757172
[15/24] Train loss=0.24549828469753265
[20/24] Train loss=0.23597340285778046
Test set avg_accuracy=84.36% avg_sensitivity=52.02%, avg_specificity=95.76% avg_auc=89.02%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.227514 Test loss=0.366107 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.22505789995193481
[5/24] Train loss=0.20605793595314026
[10/24] Train loss=0.23782490193843842
[15/24] Train loss=0.23950710892677307
[20/24] Train loss=0.22839988768100739
Test set avg_accuracy=83.61% avg_sensitivity=48.88%, avg_specificity=95.84% avg_auc=86.39%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.228614 Test loss=0.399410 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.22443081438541412
[5/24] Train loss=0.19817288219928741
[10/24] Train loss=0.2515672743320465
[15/24] Train loss=0.22991874814033508
[20/24] Train loss=0.22558528184890747
Test set avg_accuracy=86.85% avg_sensitivity=62.87%, avg_specificity=95.30% avg_auc=90.80%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.225371 Test loss=0.337128 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.21602976322174072
[5/24] Train loss=0.1822287142276764
[10/24] Train loss=0.22832156717777252
[15/24] Train loss=0.24104391038417816
[20/24] Train loss=0.2319057583808899
Test set avg_accuracy=85.78% avg_sensitivity=58.97%, avg_specificity=95.23% avg_auc=88.56%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.219993 Test loss=0.365114 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.21539044380187988
[5/24] Train loss=0.19822537899017334
[10/24] Train loss=0.24183011054992676
[15/24] Train loss=0.24958786368370056
[20/24] Train loss=0.22432652115821838
Test set avg_accuracy=84.78% avg_sensitivity=52.57%, avg_specificity=96.13% avg_auc=88.33%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.226857 Test loss=0.371042 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.22275865077972412
[5/24] Train loss=0.18798662722110748
[10/24] Train loss=0.22595129907131195
[15/24] Train loss=0.22961768507957458
[20/24] Train loss=0.22291655838489532
Test set avg_accuracy=86.02% avg_sensitivity=74.36%, avg_specificity=90.12% avg_auc=90.44%
Best model saved!! Metric=14.944165308116737!!
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.220673 Test loss=0.338180 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.21141976118087769
[5/24] Train loss=0.19430069625377655
[10/24] Train loss=0.24254067242145538
[15/24] Train loss=0.23439638316631317
[20/24] Train loss=0.22791770100593567
Test set avg_accuracy=85.73% avg_sensitivity=59.27%, avg_specificity=95.05% avg_auc=88.80%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.221551 Test loss=0.359573 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2111108899116516
[5/24] Train loss=0.18409770727157593
[10/24] Train loss=0.2418520748615265
[15/24] Train loss=0.22656622529029846
[20/24] Train loss=0.22871337831020355
Test set avg_accuracy=86.13% avg_sensitivity=67.67%, avg_specificity=92.64% avg_auc=89.95%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.218273 Test loss=0.334858 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2023225724697113
[5/24] Train loss=0.18148474395275116
[10/24] Train loss=0.2403760701417923
[15/24] Train loss=0.2291107028722763
[20/24] Train loss=0.2159682810306549
Test set avg_accuracy=83.32% avg_sensitivity=48.08%, avg_specificity=95.74% avg_auc=87.04%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.214817 Test loss=0.398669 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2059275358915329
[5/24] Train loss=0.1880294382572174
[10/24] Train loss=0.22817330062389374
[15/24] Train loss=0.22198402881622314
[20/24] Train loss=0.21583291888237
Test set avg_accuracy=86.64% avg_sensitivity=69.72%, avg_specificity=92.60% avg_auc=90.90%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.214366 Test loss=0.325252 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.20165473222732544
[5/24] Train loss=0.18390052020549774
[10/24] Train loss=0.21842001378536224
[15/24] Train loss=0.22226211428642273
[20/24] Train loss=0.2166503220796585
Test set avg_accuracy=85.65% avg_sensitivity=76.31%, avg_specificity=88.94% avg_auc=90.46%
Best model saved!! Metric=15.363417033834295!!
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.214070 Test loss=0.341847 Current lr=[0.000224838296036774]

[0/24] Train loss=0.20966540277004242
[5/24] Train loss=0.17924967408180237
[10/24] Train loss=0.23616251349449158
[15/24] Train loss=0.2196037471294403
[20/24] Train loss=0.22353386878967285
Test set avg_accuracy=86.76% avg_sensitivity=65.77%, avg_specificity=94.15% avg_auc=89.77%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.210986 Test loss=0.347492 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2073296159505844
[5/24] Train loss=0.18501965701580048
[10/24] Train loss=0.2174968421459198
[15/24] Train loss=0.2228253185749054
[20/24] Train loss=0.21236640214920044
Test set avg_accuracy=86.35% avg_sensitivity=74.81%, avg_specificity=90.42% avg_auc=91.21%
Best model saved!! Metric=16.799588083445514!!
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.212091 Test loss=0.328873 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2133333384990692
[5/24] Train loss=0.1848643273115158
[10/24] Train loss=0.22350478172302246
[15/24] Train loss=0.22326204180717468
[20/24] Train loss=0.21184852719306946
Test set avg_accuracy=82.27% avg_sensitivity=42.88%, avg_specificity=96.14% avg_auc=83.89%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.212304 Test loss=0.450228 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.21309703588485718
[5/24] Train loss=0.18137580156326294
[10/24] Train loss=0.23683568835258484
[15/24] Train loss=0.2317894548177719
[20/24] Train loss=0.20747357606887817
Test set avg_accuracy=85.77% avg_sensitivity=62.82%, avg_specificity=93.85% avg_auc=88.90%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.211273 Test loss=0.363712 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.201115682721138
[5/24] Train loss=0.1844135969877243
[10/24] Train loss=0.22536110877990723
[15/24] Train loss=0.2157776653766632
[20/24] Train loss=0.21747371554374695
Test set avg_accuracy=85.57% avg_sensitivity=72.81%, avg_specificity=90.07% avg_auc=90.41%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.208737 Test loss=0.340616 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.1935814619064331
[5/24] Train loss=0.1704314947128296
[10/24] Train loss=0.2172979712486267
[15/24] Train loss=0.214841827750206
[20/24] Train loss=0.2139662206172943
Test set avg_accuracy=84.05% avg_sensitivity=81.76%, avg_specificity=84.86% avg_auc=90.38%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.205258 Test loss=0.378249 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.20926533639431
[5/24] Train loss=0.18529728055000305
[10/24] Train loss=0.2130957394838333
[15/24] Train loss=0.22167563438415527
[20/24] Train loss=0.2145422399044037
Test set avg_accuracy=85.27% avg_sensitivity=60.17%, avg_specificity=94.12% avg_auc=87.25%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.205062 Test loss=0.376814 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.19702333211898804
[5/24] Train loss=0.17357522249221802
[10/24] Train loss=0.21719519793987274
[15/24] Train loss=0.2118152379989624
[20/24] Train loss=0.20876111090183258
Test set avg_accuracy=86.15% avg_sensitivity=60.82%, avg_specificity=95.07% avg_auc=89.24%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.203201 Test loss=0.356144 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.18969133496284485
[5/24] Train loss=0.17608658969402313
[10/24] Train loss=0.21110282838344574
[15/24] Train loss=0.21258576214313507
[20/24] Train loss=0.2199496328830719
Test set avg_accuracy=85.73% avg_sensitivity=63.42%, avg_specificity=93.59% avg_auc=89.53%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.202786 Test loss=0.351722 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.19845201075077057
[5/24] Train loss=0.1709379255771637
[10/24] Train loss=0.21182741224765778
[15/24] Train loss=0.2043309062719345
[20/24] Train loss=0.2102634161710739
Test set avg_accuracy=86.98% avg_sensitivity=73.26%, avg_specificity=91.81% avg_auc=91.00%
Best model saved!! Metric=17.055530668148933!!
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.200194 Test loss=0.326635 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.18805085122585297
[5/24] Train loss=0.17785386741161346
[10/24] Train loss=0.21726587414741516
[15/24] Train loss=0.20970404148101807
[20/24] Train loss=0.20511557161808014
Test set avg_accuracy=85.69% avg_sensitivity=67.97%, avg_specificity=91.94% avg_auc=89.56%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.201177 Test loss=0.351734 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.19038502871990204
[5/24] Train loss=0.17270424962043762
[10/24] Train loss=0.21177639067173004
[15/24] Train loss=0.2107084095478058
[20/24] Train loss=0.21009375154972076
Test set avg_accuracy=84.95% avg_sensitivity=54.52%, avg_specificity=95.67% avg_auc=88.30%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.200527 Test loss=0.383670 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.20165741443634033
[5/24] Train loss=0.17766906321048737
[10/24] Train loss=0.21717879176139832
[15/24] Train loss=0.208670973777771
[20/24] Train loss=0.20214463770389557
Test set avg_accuracy=86.00% avg_sensitivity=63.12%, avg_specificity=94.07% avg_auc=89.06%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.198802 Test loss=0.360235 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.19228123128414154
[5/24] Train loss=0.17478667199611664
[10/24] Train loss=0.21729421615600586
[15/24] Train loss=0.21010276675224304
[20/24] Train loss=0.20752418041229248
Test set avg_accuracy=86.42% avg_sensitivity=64.27%, avg_specificity=94.22% avg_auc=89.27%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.196487 Test loss=0.343694 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.19103245437145233
[5/24] Train loss=0.17050214111804962
[10/24] Train loss=0.22566042840480804
[15/24] Train loss=0.2085488736629486
[20/24] Train loss=0.20174726843833923
Test set avg_accuracy=86.63% avg_sensitivity=69.02%, avg_specificity=92.83% avg_auc=89.40%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.199065 Test loss=0.337738 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.18627066910266876
[5/24] Train loss=0.17837385833263397
[10/24] Train loss=0.21608111262321472
[15/24] Train loss=0.20266292989253998
[20/24] Train loss=0.20543882250785828
Test set avg_accuracy=84.82% avg_sensitivity=56.52%, avg_specificity=94.79% avg_auc=87.03%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.195843 Test loss=0.381784 Current lr=[0.000156543481933168]

[0/24] Train loss=0.18746337294578552
[5/24] Train loss=0.17372888326644897
[10/24] Train loss=0.22727012634277344
[15/24] Train loss=0.21548841893672943
[20/24] Train loss=0.21633322536945343
Test set avg_accuracy=85.64% avg_sensitivity=65.77%, avg_specificity=92.64% avg_auc=88.96%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.199493 Test loss=0.358625 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1891120970249176
[5/24] Train loss=0.18296055495738983
[10/24] Train loss=0.21096238493919373
[15/24] Train loss=0.20866374671459198
[20/24] Train loss=0.2066834270954132
Test set avg_accuracy=85.83% avg_sensitivity=64.97%, avg_specificity=93.19% avg_auc=88.70%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.199337 Test loss=0.362749 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.18677712976932526
[5/24] Train loss=0.1771237552165985
[10/24] Train loss=0.20436114072799683
[15/24] Train loss=0.20182092487812042
[20/24] Train loss=0.19497278332710266
Test set avg_accuracy=86.77% avg_sensitivity=69.22%, avg_specificity=92.96% avg_auc=89.59%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.194768 Test loss=0.344886 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.1854674369096756
[5/24] Train loss=0.17703743278980255
[10/24] Train loss=0.21455849707126617
[15/24] Train loss=0.19859619438648224
[20/24] Train loss=0.19934801757335663
Test set avg_accuracy=86.29% avg_sensitivity=73.91%, avg_specificity=90.65% avg_auc=90.63%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.192053 Test loss=0.339343 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.18566203117370605
[5/24] Train loss=0.16279208660125732
[10/24] Train loss=0.1907363086938858
[15/24] Train loss=0.19273844361305237
[20/24] Train loss=0.19217057526111603
Test set avg_accuracy=86.05% avg_sensitivity=63.87%, avg_specificity=93.87% avg_auc=89.78%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.187485 Test loss=0.344437 Current lr=[0.000134135431043539]

[0/24] Train loss=0.17842985689640045
[5/24] Train loss=0.1597994863986969
[10/24] Train loss=0.1946372091770172
[15/24] Train loss=0.1908901333808899
[20/24] Train loss=0.19688016176223755
Test set avg_accuracy=85.70% avg_sensitivity=64.32%, avg_specificity=93.24% avg_auc=89.50%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.187429 Test loss=0.357661 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.17898161709308624
[5/24] Train loss=0.173513263463974
[10/24] Train loss=0.19222815334796906
[15/24] Train loss=0.1977168470621109
[20/24] Train loss=0.19211426377296448
Test set avg_accuracy=84.22% avg_sensitivity=50.87%, avg_specificity=95.97% avg_auc=88.24%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.186788 Test loss=0.393397 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.18459902703762054
[5/24] Train loss=0.16687490046024323
[10/24] Train loss=0.1913916915655136
[15/24] Train loss=0.1953132450580597
[20/24] Train loss=0.19266657531261444
Test set avg_accuracy=85.70% avg_sensitivity=67.27%, avg_specificity=92.20% avg_auc=89.04%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.185282 Test loss=0.359391 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.17903819680213928
[5/24] Train loss=0.16300635039806366
[10/24] Train loss=0.1886182427406311
[15/24] Train loss=0.19355078041553497
[20/24] Train loss=0.1873665153980255
Test set avg_accuracy=85.89% avg_sensitivity=66.82%, avg_specificity=92.60% avg_auc=90.20%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.183919 Test loss=0.345066 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.18010875582695007
[5/24] Train loss=0.167934387922287
[10/24] Train loss=0.1886553317308426
[15/24] Train loss=0.19429610669612885
[20/24] Train loss=0.18414002656936646
Test set avg_accuracy=86.94% avg_sensitivity=72.16%, avg_specificity=92.15% avg_auc=91.25%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.180183 Test loss=0.323125 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.17300179600715637
[5/24] Train loss=0.16081270575523376
[10/24] Train loss=0.1868675947189331
[15/24] Train loss=0.18933935463428497
[20/24] Train loss=0.17887648940086365
Test set avg_accuracy=86.32% avg_sensitivity=70.31%, avg_specificity=91.95% avg_auc=90.84%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.178350 Test loss=0.335029 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.17153432965278625
[5/24] Train loss=0.1552514135837555
[10/24] Train loss=0.18953639268875122
[15/24] Train loss=0.1867941915988922
[20/24] Train loss=0.18612734973430634
Test set avg_accuracy=86.46% avg_sensitivity=72.91%, avg_specificity=91.23% avg_auc=90.35%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.177160 Test loss=0.339423 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.16648156940937042
[5/24] Train loss=0.15360848605632782
[10/24] Train loss=0.1792091727256775
[15/24] Train loss=0.1847640722990036
[20/24] Train loss=0.1800915151834488
Test set avg_accuracy=86.32% avg_sensitivity=69.07%, avg_specificity=92.39% avg_auc=90.50%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.173921 Test loss=0.338579 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.16688582301139832
[5/24] Train loss=0.15271110832691193
[10/24] Train loss=0.1819608211517334
[15/24] Train loss=0.17300565540790558
[20/24] Train loss=0.1788778454065323
Test set avg_accuracy=86.94% avg_sensitivity=71.96%, avg_specificity=92.22% avg_auc=90.57%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.171855 Test loss=0.327370 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.16541443765163422
[5/24] Train loss=0.15418711304664612
[10/24] Train loss=0.1783687174320221
[15/24] Train loss=0.17773772776126862
[20/24] Train loss=0.17284435033798218
Test set avg_accuracy=86.63% avg_sensitivity=66.02%, avg_specificity=93.89% avg_auc=90.60%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.170613 Test loss=0.335677 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1602376103401184
[5/24] Train loss=0.15077388286590576
[10/24] Train loss=0.17613212764263153
[15/24] Train loss=0.17966023087501526
[20/24] Train loss=0.17362694442272186
Test set avg_accuracy=86.95% avg_sensitivity=70.56%, avg_specificity=92.73% avg_auc=91.13%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.171071 Test loss=0.331026 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.16495145857334137
[5/24] Train loss=0.15388762950897217
[10/24] Train loss=0.17972758412361145
[15/24] Train loss=0.17758138477802277
[20/24] Train loss=0.17767386138439178
Test set avg_accuracy=86.33% avg_sensitivity=68.92%, avg_specificity=92.46% avg_auc=90.32%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.169986 Test loss=0.335488 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.16677793860435486
[5/24] Train loss=0.1499113142490387
[10/24] Train loss=0.18029074370861053
[15/24] Train loss=0.1731969267129898
[20/24] Train loss=0.17415311932563782
Test set avg_accuracy=86.54% avg_sensitivity=70.21%, avg_specificity=92.29% avg_auc=90.42%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.168867 Test loss=0.334161 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.162637397646904
[5/24] Train loss=0.14178387820720673
[10/24] Train loss=0.1773807257413864
[15/24] Train loss=0.17354030907154083
[20/24] Train loss=0.16520878672599792
Test set avg_accuracy=86.98% avg_sensitivity=74.86%, avg_specificity=91.25% avg_auc=91.43%
Best model saved!! Metric=18.518129180479292!!
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.166053 Test loss=0.322943 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.16430944204330444
[5/24] Train loss=0.14524447917938232
[10/24] Train loss=0.17156866192817688
[15/24] Train loss=0.1731933057308197
[20/24] Train loss=0.1667909324169159
Test set avg_accuracy=86.41% avg_sensitivity=77.51%, avg_specificity=89.54% avg_auc=91.14%
Best model saved!! Metric=18.597056868092622!!
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.164500 Test loss=0.338304 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1612236350774765
[5/24] Train loss=0.1468982845544815
[10/24] Train loss=0.17614570260047913
[15/24] Train loss=0.16946853697299957
[20/24] Train loss=0.16891701519489288
Test set avg_accuracy=86.86% avg_sensitivity=71.96%, avg_specificity=92.11% avg_auc=91.75%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.163817 Test loss=0.320633 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1579025834798813
[5/24] Train loss=0.14596949517726898
[10/24] Train loss=0.17252342402935028
[15/24] Train loss=0.172041118144989
[20/24] Train loss=0.1675337553024292
Test set avg_accuracy=87.51% avg_sensitivity=75.71%, avg_specificity=91.67% avg_auc=91.77%
Best model saved!! Metric=20.666284490288078!!
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.160924 Test loss=0.319450 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.15478265285491943
[5/24] Train loss=0.14184816181659698
[10/24] Train loss=0.16476957499980927
[15/24] Train loss=0.16167862713336945
[20/24] Train loss=0.16162285208702087
Test set avg_accuracy=86.78% avg_sensitivity=70.86%, avg_specificity=92.39% avg_auc=90.55%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.158159 Test loss=0.334623 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.15470890700817108
[5/24] Train loss=0.14055541157722473
[10/24] Train loss=0.16169415414333344
[15/24] Train loss=0.16230255365371704
[20/24] Train loss=0.1595803201198578
Test set avg_accuracy=86.71% avg_sensitivity=68.62%, avg_specificity=93.08% avg_auc=90.53%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.156233 Test loss=0.332252 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1549045294523239
[5/24] Train loss=0.13509248197078705
[10/24] Train loss=0.16037467122077942
[15/24] Train loss=0.1600629836320877
[20/24] Train loss=0.15986689925193787
Test set avg_accuracy=86.95% avg_sensitivity=74.11%, avg_specificity=91.48% avg_auc=90.73%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.154238 Test loss=0.330909 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.14628136157989502
[5/24] Train loss=0.13377965986728668
[10/24] Train loss=0.16218440234661102
[15/24] Train loss=0.16189607977867126
[20/24] Train loss=0.1549348533153534
Test set avg_accuracy=87.20% avg_sensitivity=73.21%, avg_specificity=92.13% avg_auc=91.46%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.152411 Test loss=0.324142 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14833737909793854
[5/24] Train loss=0.13739430904388428
[10/24] Train loss=0.1575181931257248
[15/24] Train loss=0.1614139825105667
[20/24] Train loss=0.15509046614170074
Test set avg_accuracy=87.07% avg_sensitivity=71.21%, avg_specificity=92.66% avg_auc=90.87%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.152288 Test loss=0.331060 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.14720161259174347
[5/24] Train loss=0.1339339017868042
[10/24] Train loss=0.1585930585861206
[15/24] Train loss=0.15696020424365997
[20/24] Train loss=0.15389050543308258
Test set avg_accuracy=86.39% avg_sensitivity=73.31%, avg_specificity=91.00% avg_auc=90.96%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.151133 Test loss=0.336578 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1503666639328003
[5/24] Train loss=0.13338786363601685
[10/24] Train loss=0.15235687792301178
[15/24] Train loss=0.15589985251426697
[20/24] Train loss=0.15095320343971252
Test set avg_accuracy=86.43% avg_sensitivity=71.26%, avg_specificity=91.78% avg_auc=90.54%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.148914 Test loss=0.338567 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.14389990270137787
[5/24] Train loss=0.1319693922996521
[10/24] Train loss=0.1559947431087494
[15/24] Train loss=0.15590457618236542
[20/24] Train loss=0.15217597782611847
Test set avg_accuracy=86.88% avg_sensitivity=71.06%, avg_specificity=92.45% avg_auc=90.75%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.148947 Test loss=0.333841 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.14387644827365875
[5/24] Train loss=0.13348662853240967
[10/24] Train loss=0.1575608104467392
[15/24] Train loss=0.15399068593978882
[20/24] Train loss=0.14977321028709412
Test set avg_accuracy=86.59% avg_sensitivity=72.31%, avg_specificity=91.62% avg_auc=90.55%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.147614 Test loss=0.338337 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1462583690881729
[5/24] Train loss=0.13278934359550476
[10/24] Train loss=0.15135620534420013
[15/24] Train loss=0.15547028183937073
[20/24] Train loss=0.15508808195590973
Test set avg_accuracy=86.69% avg_sensitivity=75.76%, avg_specificity=90.54% avg_auc=91.08%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.147453 Test loss=0.333661 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.14458663761615753
[5/24] Train loss=0.12989625334739685
[10/24] Train loss=0.15109236538410187
[15/24] Train loss=0.15838667750358582
[20/24] Train loss=0.1483292132616043
Test set avg_accuracy=86.80% avg_sensitivity=74.11%, avg_specificity=91.27% avg_auc=91.17%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.145947 Test loss=0.330321 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.14035086333751678
[5/24] Train loss=0.12911006808280945
[10/24] Train loss=0.15047456324100494
[15/24] Train loss=0.156557098031044
[20/24] Train loss=0.1502838283777237
Test set avg_accuracy=86.65% avg_sensitivity=74.56%, avg_specificity=90.91% avg_auc=91.01%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.144760 Test loss=0.333002 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.14443427324295044
[5/24] Train loss=0.12845875322818756
[10/24] Train loss=0.1484285444021225
[15/24] Train loss=0.1531779021024704
[20/24] Train loss=0.15149225294589996
Test set avg_accuracy=86.97% avg_sensitivity=74.46%, avg_specificity=91.37% avg_auc=91.10%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.143867 Test loss=0.329976 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.14115893840789795
[5/24] Train loss=0.1307830810546875
[10/24] Train loss=0.15118303894996643
[15/24] Train loss=0.1513843983411789
[20/24] Train loss=0.1493329554796219
Test set avg_accuracy=86.93% avg_sensitivity=72.86%, avg_specificity=91.88% avg_auc=91.19%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.143726 Test loss=0.328075 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13871660828590393
[5/24] Train loss=0.1308533251285553
[10/24] Train loss=0.14929746091365814
[15/24] Train loss=0.15242163836956024
[20/24] Train loss=0.14574572443962097
Test set avg_accuracy=86.98% avg_sensitivity=73.66%, avg_specificity=91.67% avg_auc=90.91%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.142401 Test loss=0.329439 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13958251476287842
[5/24] Train loss=0.12959128618240356
[10/24] Train loss=0.1450645476579666
[15/24] Train loss=0.15391309559345245
[20/24] Train loss=0.14639006555080414
Test set avg_accuracy=87.11% avg_sensitivity=73.96%, avg_specificity=91.74% avg_auc=90.89%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.142206 Test loss=0.329891 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1343792974948883
[5/24] Train loss=0.1264222264289856
[10/24] Train loss=0.14914551377296448
[15/24] Train loss=0.14781895279884338
[20/24] Train loss=0.14784370362758636
Test set avg_accuracy=86.80% avg_sensitivity=73.81%, avg_specificity=91.37% avg_auc=91.04%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.141167 Test loss=0.332394 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13675807416439056
[5/24] Train loss=0.12727710604667664
[10/24] Train loss=0.14376260340213776
[15/24] Train loss=0.14908646047115326
[20/24] Train loss=0.1434512585401535
Test set avg_accuracy=86.39% avg_sensitivity=73.36%, avg_specificity=90.98% avg_auc=90.58%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.140510 Test loss=0.338295 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.13838940858840942
[5/24] Train loss=0.12574262917041779
[10/24] Train loss=0.1438649594783783
[15/24] Train loss=0.1491403728723526
[20/24] Train loss=0.14266885817050934
Test set avg_accuracy=86.74% avg_sensitivity=73.81%, avg_specificity=91.30% avg_auc=90.77%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.140473 Test loss=0.334664 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13495054841041565
[5/24] Train loss=0.12349386513233185
[10/24] Train loss=0.14381997287273407
[15/24] Train loss=0.14803379774093628
[20/24] Train loss=0.14171858131885529
Test set avg_accuracy=86.97% avg_sensitivity=72.91%, avg_specificity=91.92% avg_auc=90.88%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.138932 Test loss=0.331314 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.13383705914020538
[5/24] Train loss=0.12343738228082657
[10/24] Train loss=0.14747072756290436
[15/24] Train loss=0.14499464631080627
[20/24] Train loss=0.14154860377311707
Test set avg_accuracy=86.88% avg_sensitivity=74.01%, avg_specificity=91.41% avg_auc=90.97%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.138615 Test loss=0.331222 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13307371735572815
[5/24] Train loss=0.12376391887664795
[10/24] Train loss=0.14512161910533905
[15/24] Train loss=0.14990006387233734
[20/24] Train loss=0.14217790961265564
Test set avg_accuracy=86.71% avg_sensitivity=73.51%, avg_specificity=91.35% avg_auc=90.88%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.138703 Test loss=0.332852 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.134027898311615
[5/24] Train loss=0.12481769919395447
[10/24] Train loss=0.1400797963142395
[15/24] Train loss=0.14460407197475433
[20/24] Train loss=0.14247487485408783
Test set avg_accuracy=86.85% avg_sensitivity=74.06%, avg_specificity=91.35% avg_auc=90.69%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.137810 Test loss=0.335766 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.13335630297660828
[5/24] Train loss=0.1225079894065857
[10/24] Train loss=0.14332152903079987
[15/24] Train loss=0.14495518803596497
[20/24] Train loss=0.14135701954364777
Test set avg_accuracy=86.91% avg_sensitivity=73.61%, avg_specificity=91.60% avg_auc=90.69%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.138068 Test loss=0.334534 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1322990506887436
[5/24] Train loss=0.12210738658905029
[10/24] Train loss=0.14320190250873566
[15/24] Train loss=0.14490050077438354
[20/24] Train loss=0.14432337880134583
Test set avg_accuracy=86.74% avg_sensitivity=73.56%, avg_specificity=91.39% avg_auc=90.71%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.137486 Test loss=0.334196 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1379508674144745
[5/24] Train loss=0.12416555732488632
[10/24] Train loss=0.1417989581823349
[15/24] Train loss=0.14585496485233307
[20/24] Train loss=0.14263252913951874
Test set avg_accuracy=86.72% avg_sensitivity=73.56%, avg_specificity=91.35% avg_auc=90.69%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.137113 Test loss=0.334558 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13116547465324402
[5/24] Train loss=0.1250331848859787
[10/24] Train loss=0.14198894798755646
[15/24] Train loss=0.14557798206806183
[20/24] Train loss=0.1413097381591797
Test set avg_accuracy=86.81% avg_sensitivity=73.46%, avg_specificity=91.51% avg_auc=90.65%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.137593 Test loss=0.334888 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.135407492518425
[5/24] Train loss=0.12131151556968689
[10/24] Train loss=0.14013253152370453
[15/24] Train loss=0.14348845183849335
[20/24] Train loss=0.13967019319534302
Test set avg_accuracy=86.88% avg_sensitivity=73.61%, avg_specificity=91.55% avg_auc=90.65%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.136476 Test loss=0.335100 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1353345364332199
[5/24] Train loss=0.12182970345020294
[10/24] Train loss=0.140654519200325
[15/24] Train loss=0.1443278044462204
[20/24] Train loss=0.1417105793952942
Test set avg_accuracy=86.82% avg_sensitivity=73.61%, avg_specificity=91.48% avg_auc=90.67%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.136873 Test loss=0.335371 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.13360987603664398
[5/24] Train loss=0.12002020329236984
[10/24] Train loss=0.13893932104110718
[15/24] Train loss=0.14529390633106232
[20/24] Train loss=0.1399129033088684
Test set avg_accuracy=86.81% avg_sensitivity=73.41%, avg_specificity=91.53% avg_auc=90.67%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.136673 Test loss=0.335119 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13286487758159637
[5/24] Train loss=0.12067411839962006
[10/24] Train loss=0.14322330057621002
[15/24] Train loss=0.14441050589084625
[20/24] Train loss=0.1394021362066269
Test set avg_accuracy=86.80% avg_sensitivity=73.36%, avg_specificity=91.53% avg_auc=90.68%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.136984 Test loss=0.335046 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.13257750868797302
[5/24] Train loss=0.12030964344739914
[10/24] Train loss=0.1388627290725708
[15/24] Train loss=0.145021453499794
[20/24] Train loss=0.14175449311733246
Test set avg_accuracy=86.80% avg_sensitivity=73.51%, avg_specificity=91.48% avg_auc=90.69%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.136404 Test loss=0.334948 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=87.51% sen=75.71%, spe=91.67%, auc=91.77%!
Fold[4] Avg_overlap=0.70%(±0.22278750170885847)
[0/24] Train loss=0.7383748888969421
[5/24] Train loss=0.7279630303382874
[10/24] Train loss=0.7292275428771973
[15/24] Train loss=0.7220801115036011
[20/24] Train loss=0.7183101773262024
Test set avg_accuracy=59.41% avg_sensitivity=46.70%, avg_specificity=63.75% avg_auc=57.21%
Best model saved!! Metric=-98.93251922304972!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.724824 Test loss=0.661780 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7161327004432678
[5/24] Train loss=0.7030425071716309
[10/24] Train loss=0.712132453918457
[15/24] Train loss=0.7004342675209045
[20/24] Train loss=0.6931632161140442
Test set avg_accuracy=65.60% avg_sensitivity=53.51%, avg_specificity=69.72% avg_auc=66.50%
Best model saved!! Metric=-70.67561353994756!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.702406 Test loss=0.623531 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6858398914337158
[5/24] Train loss=0.6805849075317383
[10/24] Train loss=0.691688060760498
[15/24] Train loss=0.6706697344779968
[20/24] Train loss=0.6681340932846069
Test set avg_accuracy=67.15% avg_sensitivity=57.91%, avg_specificity=70.30% avg_auc=70.39%
Best model saved!! Metric=-60.24822195779602!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.680596 Test loss=0.600703 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6663016080856323
[5/24] Train loss=0.6671229600906372
[10/24] Train loss=0.6577932238578796
[15/24] Train loss=0.6488847732543945
[20/24] Train loss=0.6382367610931396
Test set avg_accuracy=68.97% avg_sensitivity=63.13%, avg_specificity=70.96% avg_auc=73.72%
Best model saved!! Metric=-49.21786621583173!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.658455 Test loss=0.579796 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6445920467376709
[5/24] Train loss=0.6307345628738403
[10/24] Train loss=0.6398234367370605
[15/24] Train loss=0.6204822063446045
[20/24] Train loss=0.612541913986206
Test set avg_accuracy=70.56% avg_sensitivity=67.18%, avg_specificity=71.71% avg_auc=76.60%
Best model saved!! Metric=-39.947366726109905!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.633736 Test loss=0.559930 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6220604181289673
[5/24] Train loss=0.60552579164505
[10/24] Train loss=0.622745931148529
[15/24] Train loss=0.589339017868042
[20/24] Train loss=0.5804681181907654
Test set avg_accuracy=72.81% avg_sensitivity=69.33%, avg_specificity=74.00% avg_auc=79.28%
Best model saved!! Metric=-30.576693453168843!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.607272 Test loss=0.534583 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5911880135536194
[5/24] Train loss=0.5849425196647644
[10/24] Train loss=0.5906919240951538
[15/24] Train loss=0.5537704229354858
[20/24] Train loss=0.5462853312492371
Test set avg_accuracy=74.97% avg_sensitivity=71.79%, avg_specificity=76.06% avg_auc=81.97%
Best model saved!! Metric=-21.207996136966642!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.578334 Test loss=0.509129 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5623984932899475
[5/24] Train loss=0.5401467084884644
[10/24] Train loss=0.5570697784423828
[15/24] Train loss=0.528713583946228
[20/24] Train loss=0.5239256024360657
Test set avg_accuracy=78.24% avg_sensitivity=74.65%, avg_specificity=79.47% avg_auc=84.95%
Best model saved!! Metric=-8.687915064804088!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.548007 Test loss=0.474815 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5319288372993469
[5/24] Train loss=0.5025774240493774
[10/24] Train loss=0.5335172414779663
[15/24] Train loss=0.4989766776561737
[20/24] Train loss=0.48621106147766113
Test set avg_accuracy=80.47% avg_sensitivity=75.01%, avg_specificity=82.33% avg_auc=86.99%
Best model saved!! Metric=-1.2035976644394282!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.516738 Test loss=0.447153 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5071598887443542
[5/24] Train loss=0.4740833342075348
[10/24] Train loss=0.506885290145874
[15/24] Train loss=0.46819785237312317
[20/24] Train loss=0.4538191854953766
Test set avg_accuracy=81.98% avg_sensitivity=76.14%, avg_specificity=83.97% avg_auc=88.44%
Best model saved!! Metric=4.532595860187769!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.487778 Test loss=0.424084 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.48405149579048157
[5/24] Train loss=0.43942496180534363
[10/24] Train loss=0.4815654754638672
[15/24] Train loss=0.4408464729785919
[20/24] Train loss=0.4241602420806885
Test set avg_accuracy=83.03% avg_sensitivity=75.06%, avg_specificity=85.75% avg_auc=89.29%
Best model saved!! Metric=7.140860700784188!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.461166 Test loss=0.403949 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4618852138519287
[5/24] Train loss=0.41163256764411926
[10/24] Train loss=0.4592610001564026
[15/24] Train loss=0.41471022367477417
[20/24] Train loss=0.405955970287323
Test set avg_accuracy=83.49% avg_sensitivity=77.01%, avg_specificity=85.70% avg_auc=90.09%
Best model saved!! Metric=10.286098542190743!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.437932 Test loss=0.394916 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4421917796134949
[5/24] Train loss=0.39378806948661804
[10/24] Train loss=0.4449068307876587
[15/24] Train loss=0.3975154161453247
[20/24] Train loss=0.3948957026004791
Test set avg_accuracy=84.75% avg_sensitivity=74.50%, avg_specificity=88.25% avg_auc=90.54%
Best model saved!! Metric=12.038746800381915!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.417934 Test loss=0.372706 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.42389923334121704
[5/24] Train loss=0.37362000346183777
[10/24] Train loss=0.420801043510437
[15/24] Train loss=0.37579646706581116
[20/24] Train loss=0.37072673439979553
Test set avg_accuracy=85.34% avg_sensitivity=72.15%, avg_specificity=89.84% avg_auc=90.81%
Best model saved!! Metric=12.126876152900735!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.400126 Test loss=0.353752 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4068467319011688
[5/24] Train loss=0.36343005299568176
[10/24] Train loss=0.4071469306945801
[15/24] Train loss=0.36097413301467896
[20/24] Train loss=0.36264094710350037
Test set avg_accuracy=86.05% avg_sensitivity=68.15%, avg_specificity=92.16% avg_auc=90.79%
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.385938 Test loss=0.339942 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.39154213666915894
[5/24] Train loss=0.3513794243335724
[10/24] Train loss=0.39783844351768494
[15/24] Train loss=0.35417309403419495
[20/24] Train loss=0.34618157148361206
Test set avg_accuracy=86.47% avg_sensitivity=67.03%, avg_specificity=93.10% avg_auc=91.06%
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.371493 Test loss=0.330675 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3807483911514282
[5/24] Train loss=0.3392932415008545
[10/24] Train loss=0.38831430673599243
[15/24] Train loss=0.3387051224708557
[20/24] Train loss=0.330570250749588
Test set avg_accuracy=86.38% avg_sensitivity=64.62%, avg_specificity=93.80% avg_auc=91.35%
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.360619 Test loss=0.322512 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3673270046710968
[5/24] Train loss=0.3283868730068207
[10/24] Train loss=0.3784577250480652
[15/24] Train loss=0.3254076838493347
[20/24] Train loss=0.3262443542480469
Test set avg_accuracy=86.41% avg_sensitivity=62.57%, avg_specificity=94.53% avg_auc=91.28%
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.349035 Test loss=0.322139 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3589116632938385
[5/24] Train loss=0.3182905316352844
[10/24] Train loss=0.37191343307495117
[15/24] Train loss=0.32233646512031555
[20/24] Train loss=0.3126698434352875
Test set avg_accuracy=86.38% avg_sensitivity=58.58%, avg_specificity=95.86% avg_auc=91.22%
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.340493 Test loss=0.324555 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.35060739517211914
[5/24] Train loss=0.3080829679965973
[10/24] Train loss=0.3645894527435303
[15/24] Train loss=0.30981746315956116
[20/24] Train loss=0.3076551854610443
Test set avg_accuracy=86.42% avg_sensitivity=59.40%, avg_specificity=95.63% avg_auc=91.41%
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.330311 Test loss=0.321639 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.33802279829978943
[5/24] Train loss=0.2979658246040344
[10/24] Train loss=0.3503977656364441
[15/24] Train loss=0.30071303248405457
[20/24] Train loss=0.301906019449234
Test set avg_accuracy=86.95% avg_sensitivity=61.29%, avg_specificity=95.70% avg_auc=91.91%
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.322788 Test loss=0.311103 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.33355283737182617
[5/24] Train loss=0.2874729335308075
[10/24] Train loss=0.3503493070602417
[15/24] Train loss=0.29886385798454285
[20/24] Train loss=0.29321107268333435
Test set avg_accuracy=87.54% avg_sensitivity=66.92%, avg_specificity=94.57% avg_auc=92.62%
Best model saved!! Metric=15.654703585681133!!
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.315585 Test loss=0.298619 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.32603514194488525
[5/24] Train loss=0.2854990065097809
[10/24] Train loss=0.3410607874393463
[15/24] Train loss=0.2859727144241333
[20/24] Train loss=0.28578928112983704
Test set avg_accuracy=88.14% avg_sensitivity=71.38%, avg_specificity=93.85% avg_auc=93.32%
Best model saved!! Metric=20.69345184521005!!
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.309482 Test loss=0.287583 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3175295293331146
[5/24] Train loss=0.28197798132896423
[10/24] Train loss=0.3430039584636688
[15/24] Train loss=0.2853311002254486
[20/24] Train loss=0.28566914796829224
Test set avg_accuracy=87.90% avg_sensitivity=73.43%, avg_specificity=92.84% avg_auc=93.07%
Best model saved!! Metric=21.240706893978768!!
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.305232 Test loss=0.293276 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3109673261642456
[5/24] Train loss=0.27174443006515503
[10/24] Train loss=0.3310742974281311
[15/24] Train loss=0.2827797532081604
[20/24] Train loss=0.2731243669986725
Test set avg_accuracy=88.15% avg_sensitivity=70.20%, avg_specificity=94.27% avg_auc=93.24%
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.299277 Test loss=0.288754 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3094836473464966
[5/24] Train loss=0.2704406678676605
[10/24] Train loss=0.3367030918598175
[15/24] Train loss=0.2750382125377655
[20/24] Train loss=0.2737826406955719
Test set avg_accuracy=87.73% avg_sensitivity=66.87%, avg_specificity=94.85% avg_auc=93.17%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.294553 Test loss=0.289617 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.30054858326911926
[5/24] Train loss=0.2604040503501892
[10/24] Train loss=0.33222833275794983
[15/24] Train loss=0.2693875730037689
[20/24] Train loss=0.26676928997039795
Test set avg_accuracy=88.14% avg_sensitivity=68.20%, avg_specificity=94.94% avg_auc=92.89%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.291818 Test loss=0.291805 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.29466140270233154
[5/24] Train loss=0.25839826464653015
[10/24] Train loss=0.3214065134525299
[15/24] Train loss=0.26874569058418274
[20/24] Train loss=0.2644623816013336
Test set avg_accuracy=86.90% avg_sensitivity=56.43%, avg_specificity=97.29% avg_auc=92.59%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.286482 Test loss=0.307433 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2960973083972931
[5/24] Train loss=0.25566989183425903
[10/24] Train loss=0.3284810781478882
[15/24] Train loss=0.261488139629364
[20/24] Train loss=0.26103755831718445
Test set avg_accuracy=87.04% avg_sensitivity=58.32%, avg_specificity=96.84% avg_auc=92.36%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.283627 Test loss=0.310201 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.295803964138031
[5/24] Train loss=0.25705692172050476
[10/24] Train loss=0.3245300352573395
[15/24] Train loss=0.251898854970932
[20/24] Train loss=0.25824159383773804
Test set avg_accuracy=85.26% avg_sensitivity=47.67%, avg_specificity=98.08% avg_auc=91.40%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.281794 Test loss=0.345465 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.29512202739715576
[5/24] Train loss=0.2554134726524353
[10/24] Train loss=0.3204458951950073
[15/24] Train loss=0.2522033452987671
[20/24] Train loss=0.2545211613178253
Test set avg_accuracy=87.79% avg_sensitivity=64.00%, avg_specificity=95.90% avg_auc=93.09%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.278327 Test loss=0.294351 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.28684625029563904
[5/24] Train loss=0.2475445568561554
[10/24] Train loss=0.31481269001960754
[15/24] Train loss=0.2533787190914154
[20/24] Train loss=0.25238940119743347
Test set avg_accuracy=86.41% avg_sensitivity=54.12%, avg_specificity=97.42% avg_auc=92.32%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.274695 Test loss=0.318586 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.28951582312583923
[5/24] Train loss=0.24635252356529236
[10/24] Train loss=0.31979867815971375
[15/24] Train loss=0.24999544024467468
[20/24] Train loss=0.2498590648174286
Test set avg_accuracy=88.06% avg_sensitivity=73.78%, avg_specificity=92.93% avg_auc=92.98%
Best model saved!! Metric=21.753922502131445!!
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.274382 Test loss=0.288129 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2662304937839508
[5/24] Train loss=0.24845346808433533
[10/24] Train loss=0.308683842420578
[15/24] Train loss=0.2390211522579193
[20/24] Train loss=0.24968895316123962
Test set avg_accuracy=87.97% avg_sensitivity=62.47%, avg_specificity=96.66% avg_auc=92.94%
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.270590 Test loss=0.297712 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.285336971282959
[5/24] Train loss=0.2400144338607788
[10/24] Train loss=0.3096332252025604
[15/24] Train loss=0.24084143340587616
[20/24] Train loss=0.24917693436145782
Test set avg_accuracy=87.33% avg_sensitivity=63.08%, avg_specificity=95.60% avg_auc=91.85%
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.270402 Test loss=0.304202 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.270059734582901
[5/24] Train loss=0.24026590585708618
[10/24] Train loss=0.3074791729450226
[15/24] Train loss=0.23800396919250488
[20/24] Train loss=0.24335408210754395
Test set avg_accuracy=87.77% avg_sensitivity=66.67%, avg_specificity=94.97% avg_auc=92.59%
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.265936 Test loss=0.295322 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2831628918647766
[5/24] Train loss=0.23583699762821198
[10/24] Train loss=0.3157581388950348
[15/24] Train loss=0.25022023916244507
[20/24] Train loss=0.25028565526008606
Test set avg_accuracy=87.37% avg_sensitivity=67.03%, avg_specificity=94.31% avg_auc=92.40%
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.268521 Test loss=0.298358 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.27290552854537964
[5/24] Train loss=0.24318435788154602
[10/24] Train loss=0.2990039885044098
[15/24] Train loss=0.23681798577308655
[20/24] Train loss=0.24327927827835083
Test set avg_accuracy=86.39% avg_sensitivity=56.53%, avg_specificity=96.58% avg_auc=90.29%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.262652 Test loss=0.334865 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2639559507369995
[5/24] Train loss=0.24056099355220795
[10/24] Train loss=0.3013654947280884
[15/24] Train loss=0.2416904866695404
[20/24] Train loss=0.24829649925231934
Test set avg_accuracy=85.48% avg_sensitivity=56.07%, avg_specificity=95.51% avg_auc=91.22%
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.260780 Test loss=0.325460 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.28181248903274536
[5/24] Train loss=0.24150948226451874
[10/24] Train loss=0.29844388365745544
[15/24] Train loss=0.24811111390590668
[20/24] Train loss=0.2475983053445816
Test set avg_accuracy=86.71% avg_sensitivity=58.12%, avg_specificity=96.46% avg_auc=92.34%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.261353 Test loss=0.306336 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.273912250995636
[5/24] Train loss=0.22883200645446777
[10/24] Train loss=0.2899705469608307
[15/24] Train loss=0.24702514708042145
[20/24] Train loss=0.23664624989032745
Test set avg_accuracy=86.88% avg_sensitivity=67.33%, avg_specificity=93.54% avg_auc=91.73%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.261147 Test loss=0.307490 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2703759968280792
[5/24] Train loss=0.24296952784061432
[10/24] Train loss=0.2964650094509125
[15/24] Train loss=0.24300989508628845
[20/24] Train loss=0.24318157136440277
Test set avg_accuracy=87.83% avg_sensitivity=67.33%, avg_specificity=94.81% avg_auc=92.76%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.262141 Test loss=0.289963 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.26924312114715576
[5/24] Train loss=0.23463205993175507
[10/24] Train loss=0.2965776026248932
[15/24] Train loss=0.23247316479682922
[20/24] Train loss=0.23585940897464752
Test set avg_accuracy=87.98% avg_sensitivity=70.10%, avg_specificity=94.08% avg_auc=92.40%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.256125 Test loss=0.294163 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.264751672744751
[5/24] Train loss=0.22827158868312836
[10/24] Train loss=0.2877751886844635
[15/24] Train loss=0.2446882575750351
[20/24] Train loss=0.2389703243970871
Test set avg_accuracy=87.64% avg_sensitivity=67.90%, avg_specificity=94.38% avg_auc=92.57%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.254786 Test loss=0.296919 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2649722099304199
[5/24] Train loss=0.2278817892074585
[10/24] Train loss=0.2925913631916046
[15/24] Train loss=0.24453020095825195
[20/24] Train loss=0.23903495073318481
Test set avg_accuracy=87.46% avg_sensitivity=61.55%, avg_specificity=96.30% avg_auc=92.37%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.255787 Test loss=0.304663 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2647739350795746
[5/24] Train loss=0.22580698132514954
[10/24] Train loss=0.2915499806404114
[15/24] Train loss=0.2281562238931656
[20/24] Train loss=0.23847438395023346
Test set avg_accuracy=88.07% avg_sensitivity=68.66%, avg_specificity=94.69% avg_auc=93.10%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.255515 Test loss=0.286282 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.26236698031425476
[5/24] Train loss=0.22458294034004211
[10/24] Train loss=0.27410921454429626
[15/24] Train loss=0.23258210718631744
[20/24] Train loss=0.23477432131767273
Test set avg_accuracy=87.47% avg_sensitivity=75.93%, avg_specificity=91.41% avg_auc=92.78%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.247893 Test loss=0.300396 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2663068473339081
[5/24] Train loss=0.21846753358840942
[10/24] Train loss=0.27583950757980347
[15/24] Train loss=0.2297971546649933
[20/24] Train loss=0.24674519896507263
Test set avg_accuracy=87.17% avg_sensitivity=70.71%, avg_specificity=92.79% avg_auc=92.01%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.251839 Test loss=0.300710 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2516810894012451
[5/24] Train loss=0.24319632351398468
[10/24] Train loss=0.2825295925140381
[15/24] Train loss=0.21770983934402466
[20/24] Train loss=0.23529085516929626
Test set avg_accuracy=87.76% avg_sensitivity=64.26%, avg_specificity=95.77% avg_auc=92.61%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.249048 Test loss=0.297476 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2622901499271393
[5/24] Train loss=0.23320060968399048
[10/24] Train loss=0.2861267924308777
[15/24] Train loss=0.22628174722194672
[20/24] Train loss=0.24249674379825592
Test set avg_accuracy=87.45% avg_sensitivity=68.10%, avg_specificity=94.05% avg_auc=93.25%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.249737 Test loss=0.286828 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.252986341714859
[5/24] Train loss=0.23076091706752777
[10/24] Train loss=0.26452213525772095
[15/24] Train loss=0.21972638368606567
[20/24] Train loss=0.22687454521656036
Test set avg_accuracy=87.99% avg_sensitivity=71.84%, avg_specificity=93.50% avg_auc=93.29%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.244359 Test loss=0.282195 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2582190930843353
[5/24] Train loss=0.2244943231344223
[10/24] Train loss=0.27731674909591675
[15/24] Train loss=0.21899642050266266
[20/24] Train loss=0.2373809963464737
Test set avg_accuracy=87.99% avg_sensitivity=67.38%, avg_specificity=95.02% avg_auc=92.21%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.247149 Test loss=0.296075 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.25694894790649414
[5/24] Train loss=0.22071287035942078
[10/24] Train loss=0.2716960310935974
[15/24] Train loss=0.22864139080047607
[20/24] Train loss=0.224701389670372
Test set avg_accuracy=86.37% avg_sensitivity=73.73%, avg_specificity=90.68% avg_auc=92.17%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.242667 Test loss=0.305775 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.25147518515586853
[5/24] Train loss=0.2105194330215454
[10/24] Train loss=0.2644214928150177
[15/24] Train loss=0.21489927172660828
[20/24] Train loss=0.23205189406871796
Test set avg_accuracy=86.67% avg_sensitivity=62.78%, avg_specificity=94.81% avg_auc=91.06%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.239856 Test loss=0.323428 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.24898579716682434
[5/24] Train loss=0.22629043459892273
[10/24] Train loss=0.2689874768257141
[15/24] Train loss=0.2224421352148056
[20/24] Train loss=0.23262643814086914
Test set avg_accuracy=87.94% avg_sensitivity=67.13%, avg_specificity=95.04% avg_auc=92.95%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.247736 Test loss=0.288244 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2520391047000885
[5/24] Train loss=0.21203413605690002
[10/24] Train loss=0.2636701464653015
[15/24] Train loss=0.22381150722503662
[20/24] Train loss=0.23539073765277863
Test set avg_accuracy=87.53% avg_sensitivity=68.46%, avg_specificity=94.03% avg_auc=92.66%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.242414 Test loss=0.295534 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.25893375277519226
[5/24] Train loss=0.21116754412651062
[10/24] Train loss=0.2598329782485962
[15/24] Train loss=0.2165321558713913
[20/24] Train loss=0.23646652698516846
Test set avg_accuracy=85.25% avg_sensitivity=50.49%, avg_specificity=97.10% avg_auc=88.33%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.240804 Test loss=0.367291 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2611565589904785
[5/24] Train loss=0.20984284579753876
[10/24] Train loss=0.24112237989902496
[15/24] Train loss=0.22052724659442902
[20/24] Train loss=0.23058554530143738
Test set avg_accuracy=85.89% avg_sensitivity=57.86%, avg_specificity=95.44% avg_auc=89.83%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.237767 Test loss=0.340984 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2638533115386963
[5/24] Train loss=0.21081387996673584
[10/24] Train loss=0.2454918622970581
[15/24] Train loss=0.21852748095989227
[20/24] Train loss=0.22365330159664154
Test set avg_accuracy=86.74% avg_sensitivity=64.72%, avg_specificity=94.26% avg_auc=91.17%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.236625 Test loss=0.321091 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2379286289215088
[5/24] Train loss=0.21099750697612762
[10/24] Train loss=0.23702578246593475
[15/24] Train loss=0.21618357300758362
[20/24] Train loss=0.235535129904747
Test set avg_accuracy=86.67% avg_sensitivity=74.60%, avg_specificity=90.78% avg_auc=92.20%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.235806 Test loss=0.305521 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.24356511235237122
[5/24] Train loss=0.20533522963523865
[10/24] Train loss=0.2451714277267456
[15/24] Train loss=0.20937074720859528
[20/24] Train loss=0.22889453172683716
Test set avg_accuracy=85.40% avg_sensitivity=48.85%, avg_specificity=97.87% avg_auc=89.19%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.234441 Test loss=0.363401 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.25186672806739807
[5/24] Train loss=0.2267029583454132
[10/24] Train loss=0.24546697735786438
[15/24] Train loss=0.21664875745773315
[20/24] Train loss=0.22375333309173584
Test set avg_accuracy=86.39% avg_sensitivity=53.15%, avg_specificity=97.73% avg_auc=89.83%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.236049 Test loss=0.353429 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.23944668471813202
[5/24] Train loss=0.21503527462482452
[10/24] Train loss=0.2429855465888977
[15/24] Train loss=0.22293145954608917
[20/24] Train loss=0.21727630496025085
Test set avg_accuracy=87.50% avg_sensitivity=62.21%, avg_specificity=96.12% avg_auc=92.02%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.234660 Test loss=0.302488 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.23797550797462463
[5/24] Train loss=0.2046130895614624
[10/24] Train loss=0.2272048145532608
[15/24] Train loss=0.21533486247062683
[20/24] Train loss=0.22756873071193695
Test set avg_accuracy=84.32% avg_sensitivity=70.97%, avg_specificity=88.88% avg_auc=88.85%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.230502 Test loss=0.364070 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2610212564468384
[5/24] Train loss=0.2128559798002243
[10/24] Train loss=0.24791064858436584
[15/24] Train loss=0.2097243070602417
[20/24] Train loss=0.22679616510868073
Test set avg_accuracy=87.53% avg_sensitivity=72.40%, avg_specificity=92.68% avg_auc=92.86%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.232237 Test loss=0.293091 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.23165249824523926
[5/24] Train loss=0.2149435132741928
[10/24] Train loss=0.26443415880203247
[15/24] Train loss=0.22108714282512665
[20/24] Train loss=0.22567206621170044
Test set avg_accuracy=86.41% avg_sensitivity=60.01%, avg_specificity=95.41% avg_auc=91.44%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.232094 Test loss=0.321885 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.24684318900108337
[5/24] Train loss=0.2125857174396515
[10/24] Train loss=0.2599714398384094
[15/24] Train loss=0.2102266103029251
[20/24] Train loss=0.21709029376506805
Test set avg_accuracy=86.63% avg_sensitivity=60.57%, avg_specificity=95.51% avg_auc=90.42%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.231647 Test loss=0.331332 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.23954719305038452
[5/24] Train loss=0.20027194917201996
[10/24] Train loss=0.24291743338108063
[15/24] Train loss=0.2053232491016388
[20/24] Train loss=0.21938279271125793
Test set avg_accuracy=86.71% avg_sensitivity=68.05%, avg_specificity=93.07% avg_auc=91.46%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.223233 Test loss=0.314698 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.23420189321041107
[5/24] Train loss=0.19865086674690247
[10/24] Train loss=0.2439887523651123
[15/24] Train loss=0.20641830563545227
[20/24] Train loss=0.2352597862482071
Test set avg_accuracy=86.63% avg_sensitivity=73.17%, avg_specificity=91.22% avg_auc=91.99%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.229339 Test loss=0.310490 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.23064608871936798
[5/24] Train loss=0.19809259474277496
[10/24] Train loss=0.22686342895030975
[15/24] Train loss=0.2152871936559677
[20/24] Train loss=0.2174699306488037
Test set avg_accuracy=87.04% avg_sensitivity=72.40%, avg_specificity=92.04% avg_auc=91.54%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.227004 Test loss=0.314971 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.24090662598609924
[5/24] Train loss=0.19572144746780396
[10/24] Train loss=0.2551072835922241
[15/24] Train loss=0.2008449286222458
[20/24] Train loss=0.2223120480775833
Test set avg_accuracy=86.90% avg_sensitivity=75.17%, avg_specificity=90.90% avg_auc=92.81%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.225414 Test loss=0.298011 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.24575383961200714
[5/24] Train loss=0.20373758673667908
[10/24] Train loss=0.23817327618598938
[15/24] Train loss=0.21347633004188538
[20/24] Train loss=0.2133122831583023
Test set avg_accuracy=87.10% avg_sensitivity=70.10%, avg_specificity=92.89% avg_auc=91.18%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.220873 Test loss=0.320007 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.22597768902778625
[5/24] Train loss=0.20421355962753296
[10/24] Train loss=0.22129011154174805
[15/24] Train loss=0.19576843082904816
[20/24] Train loss=0.21052247285842896
Test set avg_accuracy=86.32% avg_sensitivity=68.31%, avg_specificity=92.46% avg_auc=89.96%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.216990 Test loss=0.335782 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.22149118781089783
[5/24] Train loss=0.19632849097251892
[10/24] Train loss=0.2261597365140915
[15/24] Train loss=0.20851479470729828
[20/24] Train loss=0.22118479013442993
Test set avg_accuracy=86.72% avg_sensitivity=70.81%, avg_specificity=92.14% avg_auc=91.62%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.218786 Test loss=0.313611 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.22478105127811432
[5/24] Train loss=0.21086125075817108
[10/24] Train loss=0.227852925658226
[15/24] Train loss=0.2094922810792923
[20/24] Train loss=0.20696313679218292
Test set avg_accuracy=87.60% avg_sensitivity=67.74%, avg_specificity=94.38% avg_auc=92.09%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.215867 Test loss=0.303633 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.22839407622814178
[5/24] Train loss=0.1877698302268982
[10/24] Train loss=0.22578109800815582
[15/24] Train loss=0.20581907033920288
[20/24] Train loss=0.2071840465068817
Test set avg_accuracy=87.49% avg_sensitivity=74.91%, avg_specificity=91.78% avg_auc=92.70%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.217588 Test loss=0.296010 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.21933944523334503
[5/24] Train loss=0.1904037892818451
[10/24] Train loss=0.21700656414031982
[15/24] Train loss=0.19408217072486877
[20/24] Train loss=0.20582057535648346
Test set avg_accuracy=86.76% avg_sensitivity=67.18%, avg_specificity=93.43% avg_auc=91.67%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.212192 Test loss=0.315906 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.23046386241912842
[5/24] Train loss=0.1959526687860489
[10/24] Train loss=0.22310195863246918
[15/24] Train loss=0.19828812777996063
[20/24] Train loss=0.21855027973651886
Test set avg_accuracy=85.90% avg_sensitivity=75.78%, avg_specificity=89.35% avg_auc=91.83%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.216137 Test loss=0.322627 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.22585786879062653
[5/24] Train loss=0.19630150496959686
[10/24] Train loss=0.22034810483455658
[15/24] Train loss=0.19823218882083893
[20/24] Train loss=0.2023135870695114
Test set avg_accuracy=87.25% avg_sensitivity=72.30%, avg_specificity=92.35% avg_auc=91.05%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.213894 Test loss=0.315532 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.21453727781772614
[5/24] Train loss=0.1843079924583435
[10/24] Train loss=0.20722827315330505
[15/24] Train loss=0.19344563782215118
[20/24] Train loss=0.19715876877307892
Test set avg_accuracy=86.78% avg_sensitivity=62.06%, avg_specificity=95.22% avg_auc=87.98%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.208483 Test loss=0.359465 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2162301391363144
[5/24] Train loss=0.18394847214221954
[10/24] Train loss=0.2162143439054489
[15/24] Train loss=0.19033557176589966
[20/24] Train loss=0.20431138575077057
Test set avg_accuracy=85.55% avg_sensitivity=72.86%, avg_specificity=89.87% avg_auc=90.81%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.207055 Test loss=0.333749 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.21179388463497162
[5/24] Train loss=0.1815883219242096
[10/24] Train loss=0.22402754426002502
[15/24] Train loss=0.18707378208637238
[20/24] Train loss=0.199320986866951
Test set avg_accuracy=86.90% avg_sensitivity=68.97%, avg_specificity=93.02% avg_auc=91.52%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.205149 Test loss=0.315439 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2145307958126068
[5/24] Train loss=0.1849154531955719
[10/24] Train loss=0.21108318865299225
[15/24] Train loss=0.1867767721414566
[20/24] Train loss=0.21735221147537231
Test set avg_accuracy=86.97% avg_sensitivity=62.42%, avg_specificity=95.34% avg_auc=90.23%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.205730 Test loss=0.334532 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.23996502161026
[5/24] Train loss=0.18538551032543182
[10/24] Train loss=0.2158999890089035
[15/24] Train loss=0.20525185763835907
[20/24] Train loss=0.20388391613960266
Test set avg_accuracy=88.12% avg_sensitivity=73.73%, avg_specificity=93.03% avg_auc=92.26%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.212829 Test loss=0.296286 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.21237459778785706
[5/24] Train loss=0.18680238723754883
[10/24] Train loss=0.2122892141342163
[15/24] Train loss=0.18052281439304352
[20/24] Train loss=0.2012397050857544
Test set avg_accuracy=87.30% avg_sensitivity=70.92%, avg_specificity=92.89% avg_auc=92.30%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.205295 Test loss=0.304477 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.20640899240970612
[5/24] Train loss=0.18621157109737396
[10/24] Train loss=0.198604017496109
[15/24] Train loss=0.1831262707710266
[20/24] Train loss=0.19344846904277802
Test set avg_accuracy=87.32% avg_sensitivity=67.74%, avg_specificity=93.99% avg_auc=91.66%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.198142 Test loss=0.310223 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.20728932321071625
[5/24] Train loss=0.17951099574565887
[10/24] Train loss=0.206809401512146
[15/24] Train loss=0.18179462850093842
[20/24] Train loss=0.19194941222667694
Test set avg_accuracy=87.66% avg_sensitivity=74.60%, avg_specificity=92.11% avg_auc=92.67%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.198105 Test loss=0.295035 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2011226862668991
[5/24] Train loss=0.18403896689414978
[10/24] Train loss=0.20004740357398987
[15/24] Train loss=0.18413498997688293
[20/24] Train loss=0.19857889413833618
Test set avg_accuracy=88.01% avg_sensitivity=69.33%, avg_specificity=94.38% avg_auc=92.01%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.199189 Test loss=0.296646 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.19915629923343658
[5/24] Train loss=0.18709829449653625
[10/24] Train loss=0.19463856518268585
[15/24] Train loss=0.18057005107402802
[20/24] Train loss=0.19807104766368866
Test set avg_accuracy=86.93% avg_sensitivity=70.71%, avg_specificity=92.46% avg_auc=90.97%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.196229 Test loss=0.318116 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2054964005947113
[5/24] Train loss=0.18392765522003174
[10/24] Train loss=0.20178955793380737
[15/24] Train loss=0.17717747390270233
[20/24] Train loss=0.20702245831489563
Test set avg_accuracy=87.73% avg_sensitivity=73.37%, avg_specificity=92.63% avg_auc=92.78%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.197247 Test loss=0.295772 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.21078038215637207
[5/24] Train loss=0.17732474207878113
[10/24] Train loss=0.1854964941740036
[15/24] Train loss=0.1745481938123703
[20/24] Train loss=0.19591759145259857
Test set avg_accuracy=86.82% avg_sensitivity=73.73%, avg_specificity=91.29% avg_auc=91.83%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.194333 Test loss=0.313059 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.20199231803417206
[5/24] Train loss=0.17143575847148895
[10/24] Train loss=0.20299486815929413
[15/24] Train loss=0.1776299923658371
[20/24] Train loss=0.19724565744400024
Test set avg_accuracy=87.72% avg_sensitivity=74.55%, avg_specificity=92.21% avg_auc=91.75%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.191316 Test loss=0.308128 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1999232918024063
[5/24] Train loss=0.17365674674510956
[10/24] Train loss=0.19561924040317535
[15/24] Train loss=0.1780257523059845
[20/24] Train loss=0.19259367883205414
Test set avg_accuracy=86.02% avg_sensitivity=64.93%, avg_specificity=93.21% avg_auc=89.25%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.191339 Test loss=0.345058 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.19710379838943481
[5/24] Train loss=0.16812993586063385
[10/24] Train loss=0.19841213524341583
[15/24] Train loss=0.18561485409736633
[20/24] Train loss=0.18920746445655823
Test set avg_accuracy=86.21% avg_sensitivity=77.27%, avg_specificity=89.26% avg_auc=91.57%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.193163 Test loss=0.327926 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.19682735204696655
[5/24] Train loss=0.17230042815208435
[10/24] Train loss=0.18677918612957
[15/24] Train loss=0.18260525166988373
[20/24] Train loss=0.18127673864364624
Test set avg_accuracy=87.03% avg_sensitivity=73.27%, avg_specificity=91.72% avg_auc=90.65%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.189397 Test loss=0.331857 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.19440913200378418
[5/24] Train loss=0.18039560317993164
[10/24] Train loss=0.216879740357399
[15/24] Train loss=0.16957926750183105
[20/24] Train loss=0.18848897516727448
Test set avg_accuracy=87.07% avg_sensitivity=72.50%, avg_specificity=92.04% avg_auc=91.86%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.190088 Test loss=0.313430 Current lr=[0.000156543481933168]

[0/24] Train loss=0.19768832623958588
[5/24] Train loss=0.17249219119548798
[10/24] Train loss=0.19130630791187286
[15/24] Train loss=0.16841627657413483
[20/24] Train loss=0.19927679002285004
Test set avg_accuracy=86.95% avg_sensitivity=66.10%, avg_specificity=94.06% avg_auc=90.45%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.187309 Test loss=0.326582 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.20247626304626465
[5/24] Train loss=0.17796361446380615
[10/24] Train loss=0.1989290714263916
[15/24] Train loss=0.17815393209457397
[20/24] Train loss=0.1848471760749817
Test set avg_accuracy=87.08% avg_sensitivity=66.62%, avg_specificity=94.06% avg_auc=90.83%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.187819 Test loss=0.324610 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.19085818529129028
[5/24] Train loss=0.17153345048427582
[10/24] Train loss=0.18207097053527832
[15/24] Train loss=0.17592847347259521
[20/24] Train loss=0.18759916722774506
Test set avg_accuracy=86.54% avg_sensitivity=62.01%, avg_specificity=94.90% avg_auc=88.89%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.183455 Test loss=0.352857 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.19489315152168274
[5/24] Train loss=0.1783122420310974
[10/24] Train loss=0.17501355707645416
[15/24] Train loss=0.17173075675964355
[20/24] Train loss=0.1803460717201233
Test set avg_accuracy=86.58% avg_sensitivity=59.70%, avg_specificity=95.74% avg_auc=88.60%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.182133 Test loss=0.357730 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.18902063369750977
[5/24] Train loss=0.16404692828655243
[10/24] Train loss=0.1888800710439682
[15/24] Train loss=0.1686190366744995
[20/24] Train loss=0.18421460688114166
Test set avg_accuracy=86.38% avg_sensitivity=65.64%, avg_specificity=93.45% avg_auc=89.67%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.179736 Test loss=0.339859 Current lr=[0.000134135431043539]

[0/24] Train loss=0.18413065373897552
[5/24] Train loss=0.17063701152801514
[10/24] Train loss=0.18436460196971893
[15/24] Train loss=0.1641024649143219
[20/24] Train loss=0.1856696456670761
Test set avg_accuracy=86.56% avg_sensitivity=68.61%, avg_specificity=92.68% avg_auc=90.66%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.180490 Test loss=0.332079 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.19611702859401703
[5/24] Train loss=0.16316893696784973
[10/24] Train loss=0.18944576382637024
[15/24] Train loss=0.17118121683597565
[20/24] Train loss=0.18876388669013977
Test set avg_accuracy=86.38% avg_sensitivity=59.70%, avg_specificity=95.48% avg_auc=89.66%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.182277 Test loss=0.346407 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.18616002798080444
[5/24] Train loss=0.16913701593875885
[10/24] Train loss=0.17135000228881836
[15/24] Train loss=0.16252446174621582
[20/24] Train loss=0.1754864603281021
Test set avg_accuracy=84.70% avg_sensitivity=77.06%, avg_specificity=87.31% avg_auc=90.75%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.177509 Test loss=0.349823 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.18973612785339355
[5/24] Train loss=0.15832652151584625
[10/24] Train loss=0.17577897012233734
[15/24] Train loss=0.16479544341564178
[20/24] Train loss=0.17263436317443848
Test set avg_accuracy=87.38% avg_sensitivity=68.05%, avg_specificity=93.98% avg_auc=91.45%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.177175 Test loss=0.311839 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.17788617312908173
[5/24] Train loss=0.1666383147239685
[10/24] Train loss=0.17339643836021423
[15/24] Train loss=0.1642003059387207
[20/24] Train loss=0.1746765524148941
Test set avg_accuracy=87.29% avg_sensitivity=67.95%, avg_specificity=93.89% avg_auc=91.09%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.172303 Test loss=0.324274 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.18591633439064026
[5/24] Train loss=0.16297760605812073
[10/24] Train loss=0.1763816922903061
[15/24] Train loss=0.1635332852602005
[20/24] Train loss=0.17063790559768677
Test set avg_accuracy=87.92% avg_sensitivity=69.84%, avg_specificity=94.08% avg_auc=91.89%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.171873 Test loss=0.302086 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.17138786613941193
[5/24] Train loss=0.158765509724617
[10/24] Train loss=0.16342371702194214
[15/24] Train loss=0.15806610882282257
[20/24] Train loss=0.17045696079730988
Test set avg_accuracy=87.37% avg_sensitivity=65.59%, avg_specificity=94.80% avg_auc=90.57%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.170674 Test loss=0.324529 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.17518295347690582
[5/24] Train loss=0.16226667165756226
[10/24] Train loss=0.1804693639278412
[15/24] Train loss=0.1586465984582901
[20/24] Train loss=0.16965194046497345
Test set avg_accuracy=88.03% avg_sensitivity=71.89%, avg_specificity=93.54% avg_auc=92.42%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.170322 Test loss=0.298704 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1752120554447174
[5/24] Train loss=0.15468138456344604
[10/24] Train loss=0.17352235317230225
[15/24] Train loss=0.16283100843429565
[20/24] Train loss=0.16462498903274536
Test set avg_accuracy=86.45% avg_sensitivity=79.77%, avg_specificity=88.72% avg_auc=92.91%
Best model saved!! Metric=21.84696443376636!!
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.167170 Test loss=0.310505 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.17079849541187286
[5/24] Train loss=0.1514318585395813
[10/24] Train loss=0.16619892418384552
[15/24] Train loss=0.15192238986492157
[20/24] Train loss=0.16571451723575592
Test set avg_accuracy=87.29% avg_sensitivity=74.50%, avg_specificity=91.65% avg_auc=92.08%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.163920 Test loss=0.313205 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.17058005928993225
[5/24] Train loss=0.15803305804729462
[10/24] Train loss=0.15978626906871796
[15/24] Train loss=0.15235458314418793
[20/24] Train loss=0.16463759541511536
Test set avg_accuracy=86.80% avg_sensitivity=77.27%, avg_specificity=90.05% avg_auc=92.13%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.162876 Test loss=0.320186 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1710982769727707
[5/24] Train loss=0.15901696681976318
[10/24] Train loss=0.16677239537239075
[15/24] Train loss=0.14808353781700134
[20/24] Train loss=0.15633635222911835
Test set avg_accuracy=88.35% avg_sensitivity=75.83%, avg_specificity=92.61% avg_auc=92.91%
Best model saved!! Metric=23.706199478589568!!
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.161817 Test loss=0.293643 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.16740794479846954
[5/24] Train loss=0.14861012995243073
[10/24] Train loss=0.1621454507112503
[15/24] Train loss=0.14844892919063568
[20/24] Train loss=0.15532754361629486
Test set avg_accuracy=88.07% avg_sensitivity=73.63%, avg_specificity=93.00% avg_auc=92.68%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.159465 Test loss=0.295461 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.16383613646030426
[5/24] Train loss=0.14933623373508453
[10/24] Train loss=0.1548357456922531
[15/24] Train loss=0.1456907093524933
[20/24] Train loss=0.15541453659534454
Test set avg_accuracy=87.67% avg_sensitivity=76.29%, avg_specificity=91.55% avg_auc=92.96%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.155232 Test loss=0.296790 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1590472012758255
[5/24] Train loss=0.1470324546098709
[10/24] Train loss=0.14929930865764618
[15/24] Train loss=0.1489250510931015
[20/24] Train loss=0.15544314682483673
Test set avg_accuracy=87.63% avg_sensitivity=75.78%, avg_specificity=91.67% avg_auc=92.93%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.154037 Test loss=0.299108 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.16315847635269165
[5/24] Train loss=0.15064534544944763
[10/24] Train loss=0.15146401524543762
[15/24] Train loss=0.14190661907196045
[20/24] Train loss=0.154552161693573
Test set avg_accuracy=87.60% avg_sensitivity=73.73%, avg_specificity=92.33% avg_auc=92.44%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.153109 Test loss=0.302181 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.15727408230304718
[5/24] Train loss=0.14721189439296722
[10/24] Train loss=0.14740429818630219
[15/24] Train loss=0.13836686313152313
[20/24] Train loss=0.1479441374540329
Test set avg_accuracy=87.67% avg_sensitivity=74.24%, avg_specificity=92.25% avg_auc=92.48%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.149027 Test loss=0.302909 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.15633711218833923
[5/24] Train loss=0.14163851737976074
[10/24] Train loss=0.1441497504711151
[15/24] Train loss=0.1375737190246582
[20/24] Train loss=0.1521131694316864
Test set avg_accuracy=88.12% avg_sensitivity=74.91%, avg_specificity=92.63% avg_auc=92.46%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.148247 Test loss=0.298356 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.15382204949855804
[5/24] Train loss=0.1431284099817276
[10/24] Train loss=0.1464817076921463
[15/24] Train loss=0.1385442465543747
[20/24] Train loss=0.14653003215789795
Test set avg_accuracy=87.62% avg_sensitivity=76.65%, avg_specificity=91.36% avg_auc=92.85%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.147706 Test loss=0.299416 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.155862495303154
[5/24] Train loss=0.13929347693920135
[10/24] Train loss=0.1425028294324875
[15/24] Train loss=0.13491462171077728
[20/24] Train loss=0.15018512308597565
Test set avg_accuracy=87.77% avg_sensitivity=75.06%, avg_specificity=92.11% avg_auc=92.57%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.145751 Test loss=0.300319 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.15196342766284943
[5/24] Train loss=0.14171423017978668
[10/24] Train loss=0.14078448712825775
[15/24] Train loss=0.13484087586402893
[20/24] Train loss=0.14413566887378693
Test set avg_accuracy=87.34% avg_sensitivity=74.60%, avg_specificity=91.69% avg_auc=92.47%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.143894 Test loss=0.303050 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1482626497745514
[5/24] Train loss=0.1337604969739914
[10/24] Train loss=0.14008843898773193
[15/24] Train loss=0.13387565314769745
[20/24] Train loss=0.14567504823207855
Test set avg_accuracy=87.19% avg_sensitivity=74.35%, avg_specificity=91.57% avg_auc=92.46%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.142840 Test loss=0.304841 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.14962133765220642
[5/24] Train loss=0.13324163854122162
[10/24] Train loss=0.13558101654052734
[15/24] Train loss=0.13372105360031128
[20/24] Train loss=0.1424904465675354
Test set avg_accuracy=87.41% avg_sensitivity=74.96%, avg_specificity=91.65% avg_auc=92.34%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.140722 Test loss=0.303980 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.14858141541481018
[5/24] Train loss=0.13340811431407928
[10/24] Train loss=0.13473403453826904
[15/24] Train loss=0.1324395388364792
[20/24] Train loss=0.14457574486732483
Test set avg_accuracy=87.54% avg_sensitivity=74.09%, avg_specificity=92.13% avg_auc=92.42%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.140106 Test loss=0.302358 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.14435206353664398
[5/24] Train loss=0.13303843140602112
[10/24] Train loss=0.13482028245925903
[15/24] Train loss=0.13037529587745667
[20/24] Train loss=0.14056852459907532
Test set avg_accuracy=87.23% avg_sensitivity=73.58%, avg_specificity=91.88% avg_auc=91.92%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.138645 Test loss=0.310573 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.14393667876720428
[5/24] Train loss=0.1316440999507904
[10/24] Train loss=0.13812516629695892
[15/24] Train loss=0.13453051447868347
[20/24] Train loss=0.14387138187885284
Test set avg_accuracy=87.59% avg_sensitivity=74.09%, avg_specificity=92.19% avg_auc=92.27%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.138687 Test loss=0.305178 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.14463752508163452
[5/24] Train loss=0.13002046942710876
[10/24] Train loss=0.13397347927093506
[15/24] Train loss=0.1292591392993927
[20/24] Train loss=0.13736926019191742
Test set avg_accuracy=87.27% avg_sensitivity=75.06%, avg_specificity=91.43% avg_auc=92.32%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.137157 Test loss=0.306377 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.14673224091529846
[5/24] Train loss=0.13059905171394348
[10/24] Train loss=0.1339966505765915
[15/24] Train loss=0.1294327676296234
[20/24] Train loss=0.13924449682235718
Test set avg_accuracy=87.77% avg_sensitivity=72.45%, avg_specificity=93.00% avg_auc=92.20%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.137059 Test loss=0.303952 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1445063054561615
[5/24] Train loss=0.13026642799377441
[10/24] Train loss=0.1307123750448227
[15/24] Train loss=0.12717829644680023
[20/24] Train loss=0.13720297813415527
Test set avg_accuracy=87.32% avg_sensitivity=73.73%, avg_specificity=91.95% avg_auc=92.43%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.136414 Test loss=0.305538 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.14531244337558746
[5/24] Train loss=0.1271519660949707
[10/24] Train loss=0.13135001063346863
[15/24] Train loss=0.13001121580600739
[20/24] Train loss=0.14035969972610474
Test set avg_accuracy=87.67% avg_sensitivity=73.58%, avg_specificity=92.47% avg_auc=92.18%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.135624 Test loss=0.306014 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1454860270023346
[5/24] Train loss=0.13153479993343353
[10/24] Train loss=0.12990204989910126
[15/24] Train loss=0.12800636887550354
[20/24] Train loss=0.13652992248535156
Test set avg_accuracy=87.19% avg_sensitivity=73.73%, avg_specificity=91.78% avg_auc=92.23%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.136134 Test loss=0.306868 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13950224220752716
[5/24] Train loss=0.1290942281484604
[10/24] Train loss=0.13059578835964203
[15/24] Train loss=0.12504464387893677
[20/24] Train loss=0.13753178715705872
Test set avg_accuracy=87.60% avg_sensitivity=74.35%, avg_specificity=92.13% avg_auc=92.27%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.135223 Test loss=0.302547 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1401316374540329
[5/24] Train loss=0.1304735392332077
[10/24] Train loss=0.1339963674545288
[15/24] Train loss=0.12472202628850937
[20/24] Train loss=0.13495363295078278
Test set avg_accuracy=87.25% avg_sensitivity=74.45%, avg_specificity=91.62% avg_auc=92.02%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.134331 Test loss=0.309989 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.14218929409980774
[5/24] Train loss=0.1258702576160431
[10/24] Train loss=0.13269372284412384
[15/24] Train loss=0.12517672777175903
[20/24] Train loss=0.13339030742645264
Test set avg_accuracy=87.42% avg_sensitivity=74.60%, avg_specificity=91.79% avg_auc=92.36%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.133459 Test loss=0.303418 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.14104516804218292
[5/24] Train loss=0.12925098836421967
[10/24] Train loss=0.1297411471605301
[15/24] Train loss=0.12468186020851135
[20/24] Train loss=0.13427966833114624
Test set avg_accuracy=87.32% avg_sensitivity=73.48%, avg_specificity=92.04% avg_auc=92.22%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.132522 Test loss=0.305561 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1409829705953598
[5/24] Train loss=0.1260499656200409
[10/24] Train loss=0.13156910240650177
[15/24] Train loss=0.12436121702194214
[20/24] Train loss=0.13253535330295563
Test set avg_accuracy=87.38% avg_sensitivity=73.73%, avg_specificity=92.04% avg_auc=92.28%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.132439 Test loss=0.305206 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13859133422374725
[5/24] Train loss=0.12575051188468933
[10/24] Train loss=0.12648752331733704
[15/24] Train loss=0.1258562058210373
[20/24] Train loss=0.13096579909324646
Test set avg_accuracy=87.43% avg_sensitivity=74.45%, avg_specificity=91.86% avg_auc=92.37%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.131698 Test loss=0.303339 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.14025163650512695
[5/24] Train loss=0.12406633049249649
[10/24] Train loss=0.12791761755943298
[15/24] Train loss=0.12311547994613647
[20/24] Train loss=0.13586674630641937
Test set avg_accuracy=87.57% avg_sensitivity=73.94%, avg_specificity=92.21% avg_auc=92.25%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.131407 Test loss=0.305031 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13659004867076874
[5/24] Train loss=0.12481848895549774
[10/24] Train loss=0.12732592225074768
[15/24] Train loss=0.12452127784490585
[20/24] Train loss=0.13116377592086792
Test set avg_accuracy=87.37% avg_sensitivity=74.24%, avg_specificity=91.85% avg_auc=92.19%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.131072 Test loss=0.306918 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13912615180015564
[5/24] Train loss=0.1252492517232895
[10/24] Train loss=0.12691372632980347
[15/24] Train loss=0.1235346570611
[20/24] Train loss=0.13081447780132294
Test set avg_accuracy=87.47% avg_sensitivity=74.04%, avg_specificity=92.06% avg_auc=92.20%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.130257 Test loss=0.305612 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.139317587018013
[5/24] Train loss=0.12423700839281082
[10/24] Train loss=0.1277136653661728
[15/24] Train loss=0.12436694651842117
[20/24] Train loss=0.1316964328289032
Test set avg_accuracy=87.45% avg_sensitivity=73.78%, avg_specificity=92.11% avg_auc=92.16%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.130760 Test loss=0.305872 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13776347041130066
[5/24] Train loss=0.12386439740657806
[10/24] Train loss=0.12736588716506958
[15/24] Train loss=0.1240672618150711
[20/24] Train loss=0.13134801387786865
Test set avg_accuracy=87.51% avg_sensitivity=73.89%, avg_specificity=92.16% avg_auc=92.16%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.130625 Test loss=0.306619 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13727805018424988
[5/24] Train loss=0.12425542622804642
[10/24] Train loss=0.12748926877975464
[15/24] Train loss=0.12293590605258942
[20/24] Train loss=0.1302112191915512
Test set avg_accuracy=87.60% avg_sensitivity=74.60%, avg_specificity=92.04% avg_auc=92.19%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.129520 Test loss=0.306179 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13511918485164642
[5/24] Train loss=0.12518402934074402
[10/24] Train loss=0.12716138362884521
[15/24] Train loss=0.12467019259929657
[20/24] Train loss=0.13254939019680023
Test set avg_accuracy=87.60% avg_sensitivity=74.35%, avg_specificity=92.13% avg_auc=92.20%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.130231 Test loss=0.305362 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13846823573112488
[5/24] Train loss=0.12354010343551636
[10/24] Train loss=0.12961867451667786
[15/24] Train loss=0.12192708998918533
[20/24] Train loss=0.13205046951770782
Test set avg_accuracy=87.57% avg_sensitivity=74.24%, avg_specificity=92.11% avg_auc=92.21%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.130252 Test loss=0.305154 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.13802026212215424
[5/24] Train loss=0.1231752336025238
[10/24] Train loss=0.127515509724617
[15/24] Train loss=0.12371211498975754
[20/24] Train loss=0.13083048164844513
Test set avg_accuracy=87.59% avg_sensitivity=74.40%, avg_specificity=92.09% avg_auc=92.23%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.129551 Test loss=0.304892 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1382444202899933
[5/24] Train loss=0.12384139001369476
[10/24] Train loss=0.12889082729816437
[15/24] Train loss=0.12076353281736374
[20/24] Train loss=0.13074891269207
Test set avg_accuracy=87.63% avg_sensitivity=74.45%, avg_specificity=92.13% avg_auc=92.20%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.130070 Test loss=0.305471 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1370345801115036
[5/24] Train loss=0.12455200403928757
[10/24] Train loss=0.128507599234581
[15/24] Train loss=0.12314092367887497
[20/24] Train loss=0.13083766400814056
Test set avg_accuracy=87.62% avg_sensitivity=74.40%, avg_specificity=92.13% avg_auc=92.20%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.129625 Test loss=0.305389 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1373496800661087
[5/24] Train loss=0.12372204661369324
[10/24] Train loss=0.12469100207090378
[15/24] Train loss=0.12375965714454651
[20/24] Train loss=0.12935097515583038
Test set avg_accuracy=87.60% avg_sensitivity=74.45%, avg_specificity=92.09% avg_auc=92.21%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.129444 Test loss=0.305178 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=88.35% sen=75.83%, spe=92.61%, auc=92.91%!
Fold[5] Avg_overlap=0.68%(±0.22049675867610793)
[0/24] Train loss=0.7352268695831299
[5/24] Train loss=0.7363935112953186
[10/24] Train loss=0.724964439868927
[15/24] Train loss=0.7228071093559265
[20/24] Train loss=0.7087708711624146
Test set avg_accuracy=60.33% avg_sensitivity=41.75%, avg_specificity=67.24% avg_auc=56.39%
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.723324 Test loss=0.689896 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7003551721572876
[5/24] Train loss=0.7063377499580383
[10/24] Train loss=0.7031302452087402
[15/24] Train loss=0.6899922490119934
[20/24] Train loss=0.6815981864929199
Test set avg_accuracy=65.30% avg_sensitivity=51.63%, avg_specificity=70.39% avg_auc=65.89%
Best model saved!! Metric=-72.7942462664985!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.698735 Test loss=0.628550 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.682523787021637
[5/24] Train loss=0.6860931515693665
[10/24] Train loss=0.6846402883529663
[15/24] Train loss=0.6677594184875488
[20/24] Train loss=0.6596586108207703
Test set avg_accuracy=68.58% avg_sensitivity=57.63%, avg_specificity=72.66% avg_auc=70.38%
Best model saved!! Metric=-56.75293938462923!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.676914 Test loss=0.603524 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6544052362442017
[5/24] Train loss=0.6653033494949341
[10/24] Train loss=0.655137836933136
[15/24] Train loss=0.6432108879089355
[20/24] Train loss=0.6371071338653564
Test set avg_accuracy=70.65% avg_sensitivity=60.12%, avg_specificity=74.57% avg_auc=74.21%
Best model saved!! Metric=-46.43860592916201!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.656872 Test loss=0.578813 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6356393694877625
[5/24] Train loss=0.6321837902069092
[10/24] Train loss=0.6314360499382019
[15/24] Train loss=0.6143981218338013
[20/24] Train loss=0.6145417094230652
Test set avg_accuracy=73.12% avg_sensitivity=63.82%, avg_specificity=76.59% avg_auc=77.41%
Best model saved!! Metric=-35.05344199791736!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.631734 Test loss=0.556100 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6029191613197327
[5/24] Train loss=0.6103327870368958
[10/24] Train loss=0.6115174889564514
[15/24] Train loss=0.5866337418556213
[20/24] Train loss=0.5872501730918884
Test set avg_accuracy=75.03% avg_sensitivity=67.27%, avg_specificity=77.91% avg_auc=80.29%
Best model saved!! Metric=-25.495299495583836!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.607768 Test loss=0.529102 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5711023211479187
[5/24] Train loss=0.5840716361999512
[10/24] Train loss=0.5830212235450745
[15/24] Train loss=0.563051164150238
[20/24] Train loss=0.5500138998031616
Test set avg_accuracy=76.68% avg_sensitivity=68.57%, avg_specificity=79.70% avg_auc=82.69%
Best model saved!! Metric=-18.357937400703705!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.581087 Test loss=0.499845 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5491065979003906
[5/24] Train loss=0.556323766708374
[10/24] Train loss=0.5644657611846924
[15/24] Train loss=0.5286409854888916
[20/24] Train loss=0.5115887522697449
Test set avg_accuracy=78.24% avg_sensitivity=71.98%, avg_specificity=80.58% avg_auc=84.83%
Best model saved!! Metric=-10.378014207004853!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.552011 Test loss=0.477451 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5241689682006836
[5/24] Train loss=0.5158602595329285
[10/24] Train loss=0.5205843448638916
[15/24] Train loss=0.5049595832824707
[20/24] Train loss=0.4845331311225891
Test set avg_accuracy=80.39% avg_sensitivity=73.32%, avg_specificity=83.02% avg_auc=86.72%
Best model saved!! Metric=-2.5417970824032636!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.521870 Test loss=0.449406 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.49404725432395935
[5/24] Train loss=0.4902683198451996
[10/24] Train loss=0.4985949695110321
[15/24] Train loss=0.47730985283851624
[20/24] Train loss=0.4468686878681183
Test set avg_accuracy=82.47% avg_sensitivity=71.69%, avg_specificity=86.49% avg_auc=88.09%
Best model saved!! Metric=2.740639771541865!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.492829 Test loss=0.416417 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4731161594390869
[5/24] Train loss=0.4599778652191162
[10/24] Train loss=0.46804243326187134
[15/24] Train loss=0.4484858810901642
[20/24] Train loss=0.4252597391605377
Test set avg_accuracy=83.20% avg_sensitivity=73.13%, avg_specificity=86.95% avg_auc=89.07%
Best model saved!! Metric=6.35590361620379!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.465799 Test loss=0.398471 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.44792360067367554
[5/24] Train loss=0.4338775873184204
[10/24] Train loss=0.4488682448863983
[15/24] Train loss=0.42368680238723755
[20/24] Train loss=0.3979651927947998
Test set avg_accuracy=84.18% avg_sensitivity=74.52%, avg_specificity=87.78% avg_auc=89.95%
Best model saved!! Metric=10.431668795935266!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.441766 Test loss=0.384085 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4291864037513733
[5/24] Train loss=0.408945232629776
[10/24] Train loss=0.42786356806755066
[15/24] Train loss=0.4047240912914276
[20/24] Train loss=0.3788908123970032
Test set avg_accuracy=84.99% avg_sensitivity=73.94%, avg_specificity=89.10% avg_auc=90.68%
Best model saved!! Metric=12.710646778163252!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.420236 Test loss=0.364238 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.40778225660324097
[5/24] Train loss=0.3926105797290802
[10/24] Train loss=0.40659716725349426
[15/24] Train loss=0.3917876183986664
[20/24] Train loss=0.35950008034706116
Test set avg_accuracy=85.64% avg_sensitivity=67.85%, avg_specificity=92.26% avg_auc=90.84%
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.400956 Test loss=0.346064 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.39621320366859436
[5/24] Train loss=0.3776032328605652
[10/24] Train loss=0.38739892840385437
[15/24] Train loss=0.3703606128692627
[20/24] Train loss=0.34821900725364685
Test set avg_accuracy=86.07% avg_sensitivity=65.98%, avg_specificity=93.55% avg_auc=91.10%
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.383492 Test loss=0.337868 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.37491118907928467
[5/24] Train loss=0.356023907661438
[10/24] Train loss=0.3682686686515808
[15/24] Train loss=0.3584451973438263
[20/24] Train loss=0.3316211700439453
Test set avg_accuracy=85.64% avg_sensitivity=59.36%, avg_specificity=95.43% avg_auc=91.09%
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.368184 Test loss=0.342362 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3635399639606476
[5/24] Train loss=0.3480434715747833
[10/24] Train loss=0.3569519519805908
[15/24] Train loss=0.35057148337364197
[20/24] Train loss=0.3181588351726532
Test set avg_accuracy=86.26% avg_sensitivity=65.55%, avg_specificity=93.98% avg_auc=91.32%
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.356000 Test loss=0.331908 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3468964099884033
[5/24] Train loss=0.3272141218185425
[10/24] Train loss=0.347400963306427
[15/24] Train loss=0.33832985162734985
[20/24] Train loss=0.30960240960121155
Test set avg_accuracy=85.77% avg_sensitivity=58.83%, avg_specificity=95.80% avg_auc=91.36%
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.343751 Test loss=0.338480 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.33896222710609436
[5/24] Train loss=0.3173181712627411
[10/24] Train loss=0.3367101848125458
[15/24] Train loss=0.32389768958091736
[20/24] Train loss=0.30088183283805847
Test set avg_accuracy=86.33% avg_sensitivity=64.06%, avg_specificity=94.62% avg_auc=91.63%
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.334335 Test loss=0.325938 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3321278989315033
[5/24] Train loss=0.30598184466362
[10/24] Train loss=0.3277132213115692
[15/24] Train loss=0.31182438135147095
[20/24] Train loss=0.2946943938732147
Test set avg_accuracy=85.08% avg_sensitivity=54.37%, avg_specificity=96.52% avg_auc=91.44%
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.326154 Test loss=0.341643 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3222106993198395
[5/24] Train loss=0.30275461077690125
[10/24] Train loss=0.32425442337989807
[15/24] Train loss=0.30108940601348877
[20/24] Train loss=0.2807137370109558
Test set avg_accuracy=85.85% avg_sensitivity=57.49%, avg_specificity=96.41% avg_auc=91.94%
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.316620 Test loss=0.333834 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3096087872982025
[5/24] Train loss=0.2903880774974823
[10/24] Train loss=0.31241080164909363
[15/24] Train loss=0.2975574731826782
[20/24] Train loss=0.27174872159957886
Test set avg_accuracy=84.91% avg_sensitivity=51.82%, avg_specificity=97.23% avg_auc=91.51%
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.308878 Test loss=0.349753 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.31894251704216003
[5/24] Train loss=0.2844698131084442
[10/24] Train loss=0.309552401304245
[15/24] Train loss=0.29109010100364685
[20/24] Train loss=0.2710282802581787
Test set avg_accuracy=83.82% avg_sensitivity=46.45%, avg_specificity=97.73% avg_auc=91.11%
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.305005 Test loss=0.368621 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.30538833141326904
[5/24] Train loss=0.28051069378852844
[10/24] Train loss=0.30308476090431213
[15/24] Train loss=0.2873505651950836
[20/24] Train loss=0.2702227234840393
Test set avg_accuracy=85.23% avg_sensitivity=53.79%, avg_specificity=96.94% avg_auc=91.57%
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.299279 Test loss=0.346209 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.29772135615348816
[5/24] Train loss=0.2780154049396515
[10/24] Train loss=0.30413925647735596
[15/24] Train loss=0.28295668959617615
[20/24] Train loss=0.2642732858657837
Test set avg_accuracy=86.25% avg_sensitivity=58.78%, avg_specificity=96.48% avg_auc=92.33%
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.296194 Test loss=0.323644 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2942905128002167
[5/24] Train loss=0.27028000354766846
[10/24] Train loss=0.29567888379096985
[15/24] Train loss=0.27745649218559265
[20/24] Train loss=0.2541879713535309
Test set avg_accuracy=84.36% avg_sensitivity=47.98%, avg_specificity=97.91% avg_auc=90.77%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.290504 Test loss=0.372582 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2875359356403351
[5/24] Train loss=0.26181474328041077
[10/24] Train loss=0.27817419171333313
[15/24] Train loss=0.2843281924724579
[20/24] Train loss=0.2525905668735504
Test set avg_accuracy=81.76% avg_sensitivity=36.18%, avg_specificity=98.73% avg_auc=90.94%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.286399 Test loss=0.410962 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.29115232825279236
[5/24] Train loss=0.2695535719394684
[10/24] Train loss=0.29095256328582764
[15/24] Train loss=0.2807045876979828
[20/24] Train loss=0.25134384632110596
Test set avg_accuracy=83.79% avg_sensitivity=46.02%, avg_specificity=97.86% avg_auc=91.05%
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.284806 Test loss=0.379955 Current lr=[0.000210185142098938]

[0/24] Train loss=0.287208616733551
[5/24] Train loss=0.26297134160995483
[10/24] Train loss=0.28020212054252625
[15/24] Train loss=0.2751927971839905
[20/24] Train loss=0.2466462254524231
Test set avg_accuracy=81.72% avg_sensitivity=36.42%, avg_specificity=98.59% avg_auc=90.18%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.282301 Test loss=0.429268 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2808389365673065
[5/24] Train loss=0.25740182399749756
[10/24] Train loss=0.27767273783683777
[15/24] Train loss=0.2715868651866913
[20/24] Train loss=0.249470055103302
Test set avg_accuracy=85.94% avg_sensitivity=56.19%, avg_specificity=97.02% avg_auc=92.44%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.279173 Test loss=0.326926 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2688235640525818
[5/24] Train loss=0.25609540939331055
[10/24] Train loss=0.26821380853652954
[15/24] Train loss=0.2644362151622772
[20/24] Train loss=0.24155239760875702
Test set avg_accuracy=85.39% avg_sensitivity=53.21%, avg_specificity=97.37% avg_auc=92.36%
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.275139 Test loss=0.335857 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2800794243812561
[5/24] Train loss=0.24288159608840942
[10/24] Train loss=0.2678071856498718
[15/24] Train loss=0.26041898131370544
[20/24] Train loss=0.24388982355594635
Test set avg_accuracy=84.54% avg_sensitivity=49.14%, avg_specificity=97.73% avg_auc=91.54%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.273019 Test loss=0.355618 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2742677927017212
[5/24] Train loss=0.24425768852233887
[10/24] Train loss=0.26276668906211853
[15/24] Train loss=0.2651757001876831
[20/24] Train loss=0.2408907115459442
Test set avg_accuracy=82.21% avg_sensitivity=38.58%, avg_specificity=98.46% avg_auc=90.03%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.271000 Test loss=0.424071 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.27100831270217896
[5/24] Train loss=0.25065192580223083
[10/24] Train loss=0.2628483176231384
[15/24] Train loss=0.2639901638031006
[20/24] Train loss=0.2424429953098297
Test set avg_accuracy=86.60% avg_sensitivity=59.69%, avg_specificity=96.62% avg_auc=92.45%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.270908 Test loss=0.318689 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.26451557874679565
[5/24] Train loss=0.24215063452720642
[10/24] Train loss=0.2566073536872864
[15/24] Train loss=0.27130573987960815
[20/24] Train loss=0.24346619844436646
Test set avg_accuracy=85.78% avg_sensitivity=57.77%, avg_specificity=96.21% avg_auc=92.03%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.267867 Test loss=0.331842 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.27381134033203125
[5/24] Train loss=0.2438022494316101
[10/24] Train loss=0.25386595726013184
[15/24] Train loss=0.26144862174987793
[20/24] Train loss=0.23307417333126068
Test set avg_accuracy=87.68% avg_sensitivity=69.34%, avg_specificity=94.51% avg_auc=92.94%
Best model saved!! Metric=18.476732170508868!!
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.265537 Test loss=0.297074 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.25844427943229675
[5/24] Train loss=0.23567356169223785
[10/24] Train loss=0.2567152678966522
[15/24] Train loss=0.2503430247306824
[20/24] Train loss=0.24042578041553497
Test set avg_accuracy=84.64% avg_sensitivity=50.67%, avg_specificity=97.28% avg_auc=90.46%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.263762 Test loss=0.354934 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.25087374448776245
[5/24] Train loss=0.23511579632759094
[10/24] Train loss=0.2638327479362488
[15/24] Train loss=0.2678738236427307
[20/24] Train loss=0.2382972240447998
Test set avg_accuracy=86.65% avg_sensitivity=61.18%, avg_specificity=96.14% avg_auc=92.60%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.265839 Test loss=0.313390 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2507215738296509
[5/24] Train loss=0.2535221576690674
[10/24] Train loss=0.2641797959804535
[15/24] Train loss=0.2551957368850708
[20/24] Train loss=0.239021435379982
Test set avg_accuracy=83.65% avg_sensitivity=45.15%, avg_specificity=97.98% avg_auc=90.09%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.264232 Test loss=0.375389 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.26331672072410583
[5/24] Train loss=0.2391825020313263
[10/24] Train loss=0.25193890929222107
[15/24] Train loss=0.2538680136203766
[20/24] Train loss=0.23253345489501953
Test set avg_accuracy=86.72% avg_sensitivity=61.23%, avg_specificity=96.21% avg_auc=92.47%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.261223 Test loss=0.311336 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.266812801361084
[5/24] Train loss=0.23397646844387054
[10/24] Train loss=0.2395821362733841
[15/24] Train loss=0.24859152734279633
[20/24] Train loss=0.23661881685256958
Test set avg_accuracy=82.32% avg_sensitivity=38.82%, avg_specificity=98.52% avg_auc=89.09%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.257437 Test loss=0.444826 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.24874316155910492
[5/24] Train loss=0.23475250601768494
[10/24] Train loss=0.24831447005271912
[15/24] Train loss=0.2489626258611679
[20/24] Train loss=0.2400977611541748
Test set avg_accuracy=82.81% avg_sensitivity=43.09%, avg_specificity=97.61% avg_auc=89.45%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.258947 Test loss=0.378326 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2594750225543976
[5/24] Train loss=0.2352251559495926
[10/24] Train loss=0.251287579536438
[15/24] Train loss=0.2520917057991028
[20/24] Train loss=0.23342537879943848
Test set avg_accuracy=83.96% avg_sensitivity=46.55%, avg_specificity=97.89% avg_auc=90.47%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.261125 Test loss=0.380859 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.25269246101379395
[5/24] Train loss=0.2241652011871338
[10/24] Train loss=0.24935895204544067
[15/24] Train loss=0.2434571087360382
[20/24] Train loss=0.22682328522205353
Test set avg_accuracy=84.67% avg_sensitivity=51.10%, avg_specificity=97.18% avg_auc=89.47%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.252413 Test loss=0.367466 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2561473846435547
[5/24] Train loss=0.22945551574230194
[10/24] Train loss=0.24968741834163666
[15/24] Train loss=0.2585050165653229
[20/24] Train loss=0.23632939159870148
Test set avg_accuracy=85.10% avg_sensitivity=53.60%, avg_specificity=96.84% avg_auc=90.55%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.255052 Test loss=0.354220 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2473733127117157
[5/24] Train loss=0.22845463454723358
[10/24] Train loss=0.23941832780838013
[15/24] Train loss=0.24819600582122803
[20/24] Train loss=0.23171819746494293
Test set avg_accuracy=84.21% avg_sensitivity=50.48%, avg_specificity=96.77% avg_auc=90.34%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.253345 Test loss=0.354639 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2546103000640869
[5/24] Train loss=0.2263224720954895
[10/24] Train loss=0.24704045057296753
[15/24] Train loss=0.2483874410390854
[20/24] Train loss=0.2283119112253189
Test set avg_accuracy=82.24% avg_sensitivity=40.55%, avg_specificity=97.77% avg_auc=85.69%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.250188 Test loss=0.432898 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2547132670879364
[5/24] Train loss=0.2330274134874344
[10/24] Train loss=0.23772746324539185
[15/24] Train loss=0.23996053636074066
[20/24] Train loss=0.23256255686283112
Test set avg_accuracy=84.31% avg_sensitivity=50.10%, avg_specificity=97.05% avg_auc=88.69%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.250232 Test loss=0.388601 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2535952925682068
[5/24] Train loss=0.2270965874195099
[10/24] Train loss=0.24058380722999573
[15/24] Train loss=0.23765890300273895
[20/24] Train loss=0.23304127156734467
Test set avg_accuracy=80.38% avg_sensitivity=30.33%, avg_specificity=99.02% avg_auc=86.19%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.249135 Test loss=0.479124 Current lr=[0.000298904600941902]

[0/24] Train loss=0.24013027548789978
[5/24] Train loss=0.2278369963169098
[10/24] Train loss=0.22684074938297272
[15/24] Train loss=0.25232815742492676
[20/24] Train loss=0.23031650483608246
Test set avg_accuracy=84.06% avg_sensitivity=46.45%, avg_specificity=98.07% avg_auc=88.85%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.249468 Test loss=0.397030 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2648839056491852
[5/24] Train loss=0.23849952220916748
[10/24] Train loss=0.23242755234241486
[15/24] Train loss=0.23967808485031128
[20/24] Train loss=0.22679303586483002
Test set avg_accuracy=82.84% avg_sensitivity=41.75%, avg_specificity=98.14% avg_auc=88.09%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.248563 Test loss=0.427892 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2553323209285736
[5/24] Train loss=0.2280968874692917
[10/24] Train loss=0.23028557002544403
[15/24] Train loss=0.2493308186531067
[20/24] Train loss=0.22127188742160797
Test set avg_accuracy=81.63% avg_sensitivity=37.28%, avg_specificity=98.14% avg_auc=86.73%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.242118 Test loss=0.450760 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.23932550847530365
[5/24] Train loss=0.2117225080728531
[10/24] Train loss=0.21964864432811737
[15/24] Train loss=0.2477051168680191
[20/24] Train loss=0.2315431386232376
Test set avg_accuracy=85.62% avg_sensitivity=58.01%, avg_specificity=95.91% avg_auc=89.68%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.239144 Test loss=0.346420 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.24261945486068726
[5/24] Train loss=0.22536173462867737
[10/24] Train loss=0.23898185789585114
[15/24] Train loss=0.23200026154518127
[20/24] Train loss=0.22817650437355042
Test set avg_accuracy=86.00% avg_sensitivity=58.69%, avg_specificity=96.18% avg_auc=90.87%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.242685 Test loss=0.334591 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.23937763273715973
[5/24] Train loss=0.21961139142513275
[10/24] Train loss=0.2373836189508438
[15/24] Train loss=0.22873272001743317
[20/24] Train loss=0.22362366318702698
Test set avg_accuracy=80.55% avg_sensitivity=32.15%, avg_specificity=98.57% avg_auc=83.55%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.240039 Test loss=0.474043 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.23666299879550934
[5/24] Train loss=0.21868668496608734
[10/24] Train loss=0.22162280976772308
[15/24] Train loss=0.23172475397586823
[20/24] Train loss=0.22590447962284088
Test set avg_accuracy=87.03% avg_sensitivity=80.28%, avg_specificity=89.55% avg_auc=92.68%
Best model saved!! Metric=23.532767741627893!!
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.238808 Test loss=0.307598 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.23687995970249176
[5/24] Train loss=0.22311994433403015
[10/24] Train loss=0.22015582025051117
[15/24] Train loss=0.23792603611946106
[20/24] Train loss=0.2231762707233429
Test set avg_accuracy=86.74% avg_sensitivity=63.68%, avg_specificity=95.34% avg_auc=91.65%
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.240373 Test loss=0.316714 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2372061163187027
[5/24] Train loss=0.22098150849342346
[10/24] Train loss=0.22118717432022095
[15/24] Train loss=0.2280329167842865
[20/24] Train loss=0.22716739773750305
Test set avg_accuracy=84.92% avg_sensitivity=52.83%, avg_specificity=96.87% avg_auc=89.61%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.236858 Test loss=0.365362 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2406086027622223
[5/24] Train loss=0.21657505631446838
[10/24] Train loss=0.223626047372818
[15/24] Train loss=0.21957305073738098
[20/24] Train loss=0.2273276448249817
Test set avg_accuracy=87.79% avg_sensitivity=69.05%, avg_specificity=94.76% avg_auc=92.14%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.235603 Test loss=0.303282 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2374354600906372
[5/24] Train loss=0.20556406676769257
[10/24] Train loss=0.22162361443042755
[15/24] Train loss=0.23705308139324188
[20/24] Train loss=0.22676099836826324
Test set avg_accuracy=86.47% avg_sensitivity=63.96%, avg_specificity=94.85% avg_auc=91.49%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.236371 Test loss=0.322844 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.23484055697917938
[5/24] Train loss=0.21416762471199036
[10/24] Train loss=0.223809614777565
[15/24] Train loss=0.21966229379177094
[20/24] Train loss=0.21777096390724182
Test set avg_accuracy=85.47% avg_sensitivity=55.23%, avg_specificity=96.73% avg_auc=89.58%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.233262 Test loss=0.364214 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.23798175156116486
[5/24] Train loss=0.22622540593147278
[10/24] Train loss=0.21820677816867828
[15/24] Train loss=0.2246801108121872
[20/24] Train loss=0.21846352517604828
Test set avg_accuracy=86.46% avg_sensitivity=65.21%, avg_specificity=94.37% avg_auc=91.17%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.233326 Test loss=0.322636 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.23137374222278595
[5/24] Train loss=0.20552174746990204
[10/24] Train loss=0.2410779595375061
[15/24] Train loss=0.23100492358207703
[20/24] Train loss=0.2170584797859192
Test set avg_accuracy=87.68% avg_sensitivity=73.42%, avg_specificity=92.99% avg_auc=92.79%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.235303 Test loss=0.296976 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.24013826251029968
[5/24] Train loss=0.23387105762958527
[10/24] Train loss=0.2415364533662796
[15/24] Train loss=0.2399742752313614
[20/24] Train loss=0.224839448928833
Test set avg_accuracy=86.47% avg_sensitivity=61.56%, avg_specificity=95.75% avg_auc=89.46%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.236604 Test loss=0.348437 Current lr=[0.000276307469034998]

[0/24] Train loss=0.22343064844608307
[5/24] Train loss=0.21649996936321259
[10/24] Train loss=0.24072404205799103
[15/24] Train loss=0.23051829636096954
[20/24] Train loss=0.218924418091774
Test set avg_accuracy=85.18% avg_sensitivity=52.11%, avg_specificity=97.50% avg_auc=87.76%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.233659 Test loss=0.394149 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.23558764159679413
[5/24] Train loss=0.2130018025636673
[10/24] Train loss=0.22132942080497742
[15/24] Train loss=0.2201201170682907
[20/24] Train loss=0.22080931067466736
Test set avg_accuracy=86.15% avg_sensitivity=59.98%, avg_specificity=95.89% avg_auc=90.23%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.227578 Test loss=0.341388 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2126254290342331
[5/24] Train loss=0.21166358888149261
[10/24] Train loss=0.22733336687088013
[15/24] Train loss=0.21084043383598328
[20/24] Train loss=0.21107268333435059
Test set avg_accuracy=86.98% avg_sensitivity=63.24%, avg_specificity=95.82% avg_auc=89.53%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.225107 Test loss=0.342311 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.21575166285037994
[5/24] Train loss=0.20261982083320618
[10/24] Train loss=0.21182163059711456
[15/24] Train loss=0.22506214678287506
[20/24] Train loss=0.22262521088123322
Test set avg_accuracy=86.68% avg_sensitivity=62.67%, avg_specificity=95.62% avg_auc=91.63%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.230274 Test loss=0.321558 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.22839483618736267
[5/24] Train loss=0.20679378509521484
[10/24] Train loss=0.221151202917099
[15/24] Train loss=0.21350590884685516
[20/24] Train loss=0.21348898112773895
Test set avg_accuracy=87.16% avg_sensitivity=62.62%, avg_specificity=96.30% avg_auc=89.96%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.223963 Test loss=0.332386 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.22498802840709686
[5/24] Train loss=0.21107925474643707
[10/24] Train loss=0.20873945951461792
[15/24] Train loss=0.21939954161643982
[20/24] Train loss=0.21169641613960266
Test set avg_accuracy=86.93% avg_sensitivity=67.23%, avg_specificity=94.26% avg_auc=90.74%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.222034 Test loss=0.326869 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.21448978781700134
[5/24] Train loss=0.20124638080596924
[10/24] Train loss=0.21951989829540253
[15/24] Train loss=0.24000287055969238
[20/24] Train loss=0.21338613331317902
Test set avg_accuracy=87.17% avg_sensitivity=67.18%, avg_specificity=94.62% avg_auc=91.46%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.225098 Test loss=0.313300 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.2186007797718048
[5/24] Train loss=0.21420490741729736
[10/24] Train loss=0.22715875506401062
[15/24] Train loss=0.21289557218551636
[20/24] Train loss=0.20773790776729584
Test set avg_accuracy=87.19% avg_sensitivity=68.43%, avg_specificity=94.17% avg_auc=91.04%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.222867 Test loss=0.317894 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.21820658445358276
[5/24] Train loss=0.20310047268867493
[10/24] Train loss=0.2276708036661148
[15/24] Train loss=0.21364174783229828
[20/24] Train loss=0.21079783141613007
Test set avg_accuracy=88.39% avg_sensitivity=76.68%, avg_specificity=92.74% avg_auc=92.81%
Best model saved!! Metric=24.618139793550554!!
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.222598 Test loss=0.291726 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2271619588136673
[5/24] Train loss=0.21178185939788818
[10/24] Train loss=0.21481028199195862
[15/24] Train loss=0.22098323702812195
[20/24] Train loss=0.21358561515808105
Test set avg_accuracy=87.54% avg_sensitivity=74.09%, avg_specificity=92.55% avg_auc=91.98%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.223294 Test loss=0.307285 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.21395651996135712
[5/24] Train loss=0.1965649574995041
[10/24] Train loss=0.2031494826078415
[15/24] Train loss=0.2112615704536438
[20/24] Train loss=0.2057734876871109
Test set avg_accuracy=87.51% avg_sensitivity=77.69%, avg_specificity=91.17% avg_auc=92.30%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.218595 Test loss=0.307408 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.21430054306983948
[5/24] Train loss=0.20900200307369232
[10/24] Train loss=0.20550309121608734
[15/24] Train loss=0.20507575571537018
[20/24] Train loss=0.20910176634788513
Test set avg_accuracy=86.72% avg_sensitivity=71.79%, avg_specificity=92.28% avg_auc=91.39%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.215050 Test loss=0.315916 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2148221731185913
[5/24] Train loss=0.20686951279640198
[10/24] Train loss=0.2022441178560257
[15/24] Train loss=0.20643915235996246
[20/24] Train loss=0.20557598769664764
Test set avg_accuracy=86.80% avg_sensitivity=72.55%, avg_specificity=92.10% avg_auc=91.59%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.213883 Test loss=0.317422 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.21354940533638
[5/24] Train loss=0.20053601264953613
[10/24] Train loss=0.20498031377792358
[15/24] Train loss=0.2052946835756302
[20/24] Train loss=0.2072039097547531
Test set avg_accuracy=86.99% avg_sensitivity=74.18%, avg_specificity=91.76% avg_auc=91.13%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.215439 Test loss=0.328110 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2117612212896347
[5/24] Train loss=0.1918591558933258
[10/24] Train loss=0.21880899369716644
[15/24] Train loss=0.2174573689699173
[20/24] Train loss=0.21138638257980347
Test set avg_accuracy=87.06% avg_sensitivity=69.87%, avg_specificity=93.46% avg_auc=91.91%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.217703 Test loss=0.312787 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.21177221834659576
[5/24] Train loss=0.19931358098983765
[10/24] Train loss=0.20254284143447876
[15/24] Train loss=0.20943884551525116
[20/24] Train loss=0.20224003493785858
Test set avg_accuracy=87.67% avg_sensitivity=72.02%, avg_specificity=93.50% avg_auc=91.22%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.214104 Test loss=0.313450 Current lr=[0.000224838296036774]

[0/24] Train loss=0.20188546180725098
[5/24] Train loss=0.18705779314041138
[10/24] Train loss=0.20168732106685638
[15/24] Train loss=0.20322170853614807
[20/24] Train loss=0.2027062475681305
Test set avg_accuracy=87.06% avg_sensitivity=77.26%, avg_specificity=90.71% avg_auc=92.13%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.210850 Test loss=0.314162 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.207467183470726
[5/24] Train loss=0.18142230808734894
[10/24] Train loss=0.2020539939403534
[15/24] Train loss=0.19426167011260986
[20/24] Train loss=0.20161136984825134
Test set avg_accuracy=87.08% avg_sensitivity=70.35%, avg_specificity=93.32% avg_auc=91.66%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.207967 Test loss=0.314339 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.21081499755382538
[5/24] Train loss=0.19307342171669006
[10/24] Train loss=0.19861049950122833
[15/24] Train loss=0.19988727569580078
[20/24] Train loss=0.20013581216335297
Test set avg_accuracy=86.04% avg_sensitivity=82.01%, avg_specificity=87.54% avg_auc=91.74%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.211329 Test loss=0.336409 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2036506086587906
[5/24] Train loss=0.19426794350147247
[10/24] Train loss=0.19814443588256836
[15/24] Train loss=0.199117511510849
[20/24] Train loss=0.2013123482465744
Test set avg_accuracy=87.11% avg_sensitivity=75.77%, avg_specificity=91.33% avg_auc=91.71%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.207596 Test loss=0.315788 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.21033672988414764
[5/24] Train loss=0.1933279186487198
[10/24] Train loss=0.20283812284469604
[15/24] Train loss=0.18873348832130432
[20/24] Train loss=0.20158420503139496
Test set avg_accuracy=86.73% avg_sensitivity=75.86%, avg_specificity=90.78% avg_auc=91.46%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.207645 Test loss=0.323328 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.20138655602931976
[5/24] Train loss=0.19653789699077606
[10/24] Train loss=0.20097240805625916
[15/24] Train loss=0.20587687194347382
[20/24] Train loss=0.20414377748966217
Test set avg_accuracy=87.38% avg_sensitivity=74.86%, avg_specificity=92.05% avg_auc=91.53%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.209963 Test loss=0.314723 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.20131248235702515
[5/24] Train loss=0.18906250596046448
[10/24] Train loss=0.1860836148262024
[15/24] Train loss=0.190684512257576
[20/24] Train loss=0.19404743611812592
Test set avg_accuracy=86.51% avg_sensitivity=72.02%, avg_specificity=91.90% avg_auc=91.15%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.207472 Test loss=0.327120 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.20364625751972198
[5/24] Train loss=0.1893729269504547
[10/24] Train loss=0.18720202147960663
[15/24] Train loss=0.20737774670124054
[20/24] Train loss=0.20381705462932587
Test set avg_accuracy=86.59% avg_sensitivity=68.43%, avg_specificity=93.35% avg_auc=90.52%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.205339 Test loss=0.333507 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2015339583158493
[5/24] Train loss=0.1945449262857437
[10/24] Train loss=0.1988898068666458
[15/24] Train loss=0.20224197208881378
[20/24] Train loss=0.1981102079153061
Test set avg_accuracy=86.77% avg_sensitivity=70.11%, avg_specificity=92.98% avg_auc=90.33%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.205458 Test loss=0.334396 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.19597089290618896
[5/24] Train loss=0.18605788052082062
[10/24] Train loss=0.1916208416223526
[15/24] Train loss=0.20528477430343628
[20/24] Train loss=0.19581235945224762
Test set avg_accuracy=85.81% avg_sensitivity=60.80%, avg_specificity=95.12% avg_auc=89.38%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.202094 Test loss=0.351640 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.19701561331748962
[5/24] Train loss=0.18961988389492035
[10/24] Train loss=0.2006174921989441
[15/24] Train loss=0.19218769669532776
[20/24] Train loss=0.19337229430675507
Test set avg_accuracy=84.95% avg_sensitivity=54.32%, avg_specificity=96.35% avg_auc=87.15%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.199049 Test loss=0.390301 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.19163358211517334
[5/24] Train loss=0.1858867108821869
[10/24] Train loss=0.1996070295572281
[15/24] Train loss=0.19200848042964935
[20/24] Train loss=0.19499477744102478
Test set avg_accuracy=86.35% avg_sensitivity=65.26%, avg_specificity=94.21% avg_auc=89.63%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.198022 Test loss=0.342152 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.19300836324691772
[5/24] Train loss=0.18467988073825836
[10/24] Train loss=0.18307223916053772
[15/24] Train loss=0.18080492317676544
[20/24] Train loss=0.19363410770893097
Test set avg_accuracy=85.57% avg_sensitivity=76.58%, avg_specificity=88.92% avg_auc=90.80%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.196825 Test loss=0.344578 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.19539618492126465
[5/24] Train loss=0.18341290950775146
[10/24] Train loss=0.18553954362869263
[15/24] Train loss=0.19694119691848755
[20/24] Train loss=0.1913411170244217
Test set avg_accuracy=86.61% avg_sensitivity=64.49%, avg_specificity=94.85% avg_auc=90.27%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.196892 Test loss=0.339542 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.19001227617263794
[5/24] Train loss=0.18584541976451874
[10/24] Train loss=0.1860051304101944
[15/24] Train loss=0.1757688969373703
[20/24] Train loss=0.18298344314098358
Test set avg_accuracy=86.15% avg_sensitivity=62.48%, avg_specificity=94.96% avg_auc=88.37%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.192380 Test loss=0.357570 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.20269830524921417
[5/24] Train loss=0.17860355973243713
[10/24] Train loss=0.1945299208164215
[15/24] Train loss=0.17800571024417877
[20/24] Train loss=0.1879148930311203
Test set avg_accuracy=86.30% avg_sensitivity=63.44%, avg_specificity=94.82% avg_auc=89.12%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.191653 Test loss=0.353567 Current lr=[0.000156543481933168]

[0/24] Train loss=0.19389185309410095
[5/24] Train loss=0.17455092072486877
[10/24] Train loss=0.17933757603168488
[15/24] Train loss=0.1840798407793045
[20/24] Train loss=0.18186181783676147
Test set avg_accuracy=85.01% avg_sensitivity=56.33%, avg_specificity=95.69% avg_auc=85.54%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.190691 Test loss=0.404675 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.18303073942661285
[5/24] Train loss=0.1800348311662674
[10/24] Train loss=0.1798456311225891
[15/24] Train loss=0.1827784776687622
[20/24] Train loss=0.18183808028697968
Test set avg_accuracy=87.37% avg_sensitivity=65.45%, avg_specificity=95.53% avg_auc=89.83%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.189395 Test loss=0.338905 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.17974084615707397
[5/24] Train loss=0.18188965320587158
[10/24] Train loss=0.18076221644878387
[15/24] Train loss=0.1731511354446411
[20/24] Train loss=0.18879950046539307
Test set avg_accuracy=85.35% avg_sensitivity=55.61%, avg_specificity=96.43% avg_auc=86.09%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.190093 Test loss=0.401905 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.17706596851348877
[5/24] Train loss=0.17107215523719788
[10/24] Train loss=0.18583834171295166
[15/24] Train loss=0.18506862223148346
[20/24] Train loss=0.1802927553653717
Test set avg_accuracy=85.20% avg_sensitivity=55.23%, avg_specificity=96.35% avg_auc=88.21%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.188236 Test loss=0.391411 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.18293283879756927
[5/24] Train loss=0.18104808032512665
[10/24] Train loss=0.189527690410614
[15/24] Train loss=0.17689257860183716
[20/24] Train loss=0.18356819450855255
Test set avg_accuracy=86.90% avg_sensitivity=67.51%, avg_specificity=94.12% avg_auc=90.76%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.188266 Test loss=0.327903 Current lr=[0.000134135431043539]

[0/24] Train loss=0.18007786571979523
[5/24] Train loss=0.17565491795539856
[10/24] Train loss=0.17754332721233368
[15/24] Train loss=0.16892218589782715
[20/24] Train loss=0.17798082530498505
Test set avg_accuracy=87.07% avg_sensitivity=64.35%, avg_specificity=95.53% avg_auc=90.33%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.183672 Test loss=0.333858 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.18030968308448792
[5/24] Train loss=0.1726446896791458
[10/24] Train loss=0.176591694355011
[15/24] Train loss=0.17859825491905212
[20/24] Train loss=0.18185235559940338
Test set avg_accuracy=87.42% avg_sensitivity=68.76%, avg_specificity=94.37% avg_auc=90.71%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.182022 Test loss=0.325537 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1700049489736557
[5/24] Train loss=0.17522434890270233
[10/24] Train loss=0.17179915308952332
[15/24] Train loss=0.1709197759628296
[20/24] Train loss=0.17905573546886444
Test set avg_accuracy=86.93% avg_sensitivity=72.41%, avg_specificity=92.33% avg_auc=90.21%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.181426 Test loss=0.334670 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.1729366034269333
[5/24] Train loss=0.16482596099376678
[10/24] Train loss=0.17350247502326965
[15/24] Train loss=0.16964232921600342
[20/24] Train loss=0.17462272942066193
Test set avg_accuracy=87.64% avg_sensitivity=72.89%, avg_specificity=93.14% avg_auc=91.63%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.177818 Test loss=0.312921 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1672179102897644
[5/24] Train loss=0.17145831882953644
[10/24] Train loss=0.1781885027885437
[15/24] Train loss=0.16437740623950958
[20/24] Train loss=0.1676725149154663
Test set avg_accuracy=87.53% avg_sensitivity=76.73%, avg_specificity=91.55% avg_auc=92.14%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.174147 Test loss=0.313527 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.171281099319458
[5/24] Train loss=0.1657678633928299
[10/24] Train loss=0.17396819591522217
[15/24] Train loss=0.17642895877361298
[20/24] Train loss=0.16838735342025757
Test set avg_accuracy=87.83% avg_sensitivity=71.59%, avg_specificity=93.87% avg_auc=90.95%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.175873 Test loss=0.318659 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.16446353495121002
[5/24] Train loss=0.1606702208518982
[10/24] Train loss=0.1668611466884613
[15/24] Train loss=0.1712779700756073
[20/24] Train loss=0.15748199820518494
Test set avg_accuracy=87.46% avg_sensitivity=70.97%, avg_specificity=93.60% avg_auc=90.26%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.169571 Test loss=0.326786 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.16959239542484283
[5/24] Train loss=0.16246095299720764
[10/24] Train loss=0.17142735421657562
[15/24] Train loss=0.1603555828332901
[20/24] Train loss=0.15560689568519592
Test set avg_accuracy=87.93% avg_sensitivity=76.20%, avg_specificity=92.30% avg_auc=91.75%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.170252 Test loss=0.311079 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.16646064817905426
[5/24] Train loss=0.1706913560628891
[10/24] Train loss=0.16020676493644714
[15/24] Train loss=0.16564401984214783
[20/24] Train loss=0.16447147727012634
Test set avg_accuracy=88.09% avg_sensitivity=74.86%, avg_specificity=93.01% avg_auc=91.23%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.170008 Test loss=0.318801 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15968552231788635
[5/24] Train loss=0.16957969963550568
[10/24] Train loss=0.15830448269844055
[15/24] Train loss=0.17995861172676086
[20/24] Train loss=0.1629655957221985
Test set avg_accuracy=87.12% avg_sensitivity=78.45%, avg_specificity=90.35% avg_auc=92.21%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.169930 Test loss=0.318353 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1606743186712265
[5/24] Train loss=0.1562930792570114
[10/24] Train loss=0.15980581939220428
[15/24] Train loss=0.16101615130901337
[20/24] Train loss=0.1573612242937088
Test set avg_accuracy=87.94% avg_sensitivity=72.17%, avg_specificity=93.82% avg_auc=90.97%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.165362 Test loss=0.318656 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.16279517114162445
[5/24] Train loss=0.1546955704689026
[10/24] Train loss=0.15531209111213684
[15/24] Train loss=0.15379928052425385
[20/24] Train loss=0.1558021903038025
Test set avg_accuracy=87.27% avg_sensitivity=75.24%, avg_specificity=91.74% avg_auc=91.60%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.163806 Test loss=0.323660 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.16475309431552887
[5/24] Train loss=0.15206481516361237
[10/24] Train loss=0.15464048087596893
[15/24] Train loss=0.15087857842445374
[20/24] Train loss=0.15531156957149506
Test set avg_accuracy=87.03% avg_sensitivity=75.34%, avg_specificity=91.39% avg_auc=91.88%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.161550 Test loss=0.321531 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.16238223016262054
[5/24] Train loss=0.15338245034217834
[10/24] Train loss=0.15711165964603424
[15/24] Train loss=0.15618425607681274
[20/24] Train loss=0.16187162697315216
Test set avg_accuracy=87.10% avg_sensitivity=74.42%, avg_specificity=91.82% avg_auc=91.35%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.162139 Test loss=0.324235 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15444518625736237
[5/24] Train loss=0.14743967354297638
[10/24] Train loss=0.1580178588628769
[15/24] Train loss=0.15345646440982819
[20/24] Train loss=0.15001104772090912
Test set avg_accuracy=87.70% avg_sensitivity=74.14%, avg_specificity=92.74% avg_auc=91.75%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.158386 Test loss=0.311986 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.159981831908226
[5/24] Train loss=0.1467500776052475
[10/24] Train loss=0.1505451798439026
[15/24] Train loss=0.14644593000411987
[20/24] Train loss=0.14773432910442352
Test set avg_accuracy=87.86% avg_sensitivity=73.70%, avg_specificity=93.14% avg_auc=91.65%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.155564 Test loss=0.312327 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.15434768795967102
[5/24] Train loss=0.14387787878513336
[10/24] Train loss=0.1451776921749115
[15/24] Train loss=0.14600226283073425
[20/24] Train loss=0.14937691390514374
Test set avg_accuracy=87.38% avg_sensitivity=75.67%, avg_specificity=91.74% avg_auc=90.84%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.152735 Test loss=0.327139 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14718984067440033
[5/24] Train loss=0.1405998170375824
[10/24] Train loss=0.14332886040210724
[15/24] Train loss=0.14407047629356384
[20/24] Train loss=0.14180418848991394
Test set avg_accuracy=87.19% avg_sensitivity=70.35%, avg_specificity=93.46% avg_auc=90.37%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.150745 Test loss=0.328469 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.15025505423545837
[5/24] Train loss=0.14369730651378632
[10/24] Train loss=0.13915345072746277
[15/24] Train loss=0.1428690403699875
[20/24] Train loss=0.1426752805709839
Test set avg_accuracy=87.32% avg_sensitivity=72.41%, avg_specificity=92.87% avg_auc=91.07%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.149034 Test loss=0.322232 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14200156927108765
[5/24] Train loss=0.1384647935628891
[10/24] Train loss=0.14026962220668793
[15/24] Train loss=0.14504700899124146
[20/24] Train loss=0.14163361489772797
Test set avg_accuracy=87.16% avg_sensitivity=70.97%, avg_specificity=93.19% avg_auc=91.39%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.147782 Test loss=0.321579 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1469874083995819
[5/24] Train loss=0.14216108620166779
[10/24] Train loss=0.14037948846817017
[15/24] Train loss=0.14229434728622437
[20/24] Train loss=0.13955196738243103
Test set avg_accuracy=87.94% avg_sensitivity=75.62%, avg_specificity=92.53% avg_auc=91.47%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.147190 Test loss=0.316594 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14219336211681366
[5/24] Train loss=0.14379781484603882
[10/24] Train loss=0.1393769383430481
[15/24] Train loss=0.14069609344005585
[20/24] Train loss=0.14026376605033875
Test set avg_accuracy=87.15% avg_sensitivity=71.64%, avg_specificity=92.92% avg_auc=90.90%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.146465 Test loss=0.326787 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1412293165922165
[5/24] Train loss=0.13603946566581726
[10/24] Train loss=0.13863319158554077
[15/24] Train loss=0.13629919290542603
[20/24] Train loss=0.1410282701253891
Test set avg_accuracy=87.73% avg_sensitivity=75.14%, avg_specificity=92.42% avg_auc=91.86%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.144764 Test loss=0.313296 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.14239616692066193
[5/24] Train loss=0.1347755491733551
[10/24] Train loss=0.13656240701675415
[15/24] Train loss=0.13475224375724792
[20/24] Train loss=0.13938671350479126
Test set avg_accuracy=87.41% avg_sensitivity=74.81%, avg_specificity=92.10% avg_auc=91.67%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.143025 Test loss=0.319663 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13675811886787415
[5/24] Train loss=0.1338493376970291
[10/24] Train loss=0.1343977302312851
[15/24] Train loss=0.13778455555438995
[20/24] Train loss=0.1362440139055252
Test set avg_accuracy=87.45% avg_sensitivity=75.53%, avg_specificity=91.89% avg_auc=91.05%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.141752 Test loss=0.323892 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.14011485874652863
[5/24] Train loss=0.13369782269001007
[10/24] Train loss=0.13482744991779327
[15/24] Train loss=0.1353009045124054
[20/24] Train loss=0.13373231887817383
Test set avg_accuracy=87.24% avg_sensitivity=74.33%, avg_specificity=92.05% avg_auc=91.07%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.140846 Test loss=0.323882 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13766388595104218
[5/24] Train loss=0.135520339012146
[10/24] Train loss=0.1327490657567978
[15/24] Train loss=0.139185830950737
[20/24] Train loss=0.13387402892112732
Test set avg_accuracy=87.47% avg_sensitivity=77.06%, avg_specificity=91.35% avg_auc=91.87%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.140639 Test loss=0.315832 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1335178166627884
[5/24] Train loss=0.13488928973674774
[10/24] Train loss=0.129855215549469
[15/24] Train loss=0.13397188484668732
[20/24] Train loss=0.13248774409294128
Test set avg_accuracy=87.20% avg_sensitivity=74.04%, avg_specificity=92.10% avg_auc=91.17%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.139007 Test loss=0.325338 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13713723421096802
[5/24] Train loss=0.13336355984210968
[10/24] Train loss=0.13505201041698456
[15/24] Train loss=0.12994129955768585
[20/24] Train loss=0.13608407974243164
Test set avg_accuracy=87.07% avg_sensitivity=73.99%, avg_specificity=91.94% avg_auc=91.32%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.138432 Test loss=0.322688 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1331672966480255
[5/24] Train loss=0.1321059614419937
[10/24] Train loss=0.13457082211971283
[15/24] Train loss=0.12916889786720276
[20/24] Train loss=0.13256745040416718
Test set avg_accuracy=87.20% avg_sensitivity=73.61%, avg_specificity=92.26% avg_auc=91.09%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.137945 Test loss=0.324234 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1358707845211029
[5/24] Train loss=0.13340812921524048
[10/24] Train loss=0.13076132535934448
[15/24] Train loss=0.13082163035869598
[20/24] Train loss=0.13340869545936584
Test set avg_accuracy=87.24% avg_sensitivity=73.46%, avg_specificity=92.37% avg_auc=91.41%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.137365 Test loss=0.322865 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13776367902755737
[5/24] Train loss=0.12695729732513428
[10/24] Train loss=0.13326862454414368
[15/24] Train loss=0.13179731369018555
[20/24] Train loss=0.1309666931629181
Test set avg_accuracy=86.98% avg_sensitivity=73.90%, avg_specificity=91.85% avg_auc=91.22%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.137039 Test loss=0.322977 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13254569470882416
[5/24] Train loss=0.13212384283542633
[10/24] Train loss=0.12729011476039886
[15/24] Train loss=0.12967680394649506
[20/24] Train loss=0.1289728432893753
Test set avg_accuracy=87.04% avg_sensitivity=73.22%, avg_specificity=92.19% avg_auc=91.32%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.136018 Test loss=0.322500 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12927529215812683
[5/24] Train loss=0.13198284804821014
[10/24] Train loss=0.1278124302625656
[15/24] Train loss=0.12850479781627655
[20/24] Train loss=0.13123905658721924
Test set avg_accuracy=87.43% avg_sensitivity=74.38%, avg_specificity=92.30% avg_auc=91.64%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.135148 Test loss=0.317999 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13361848890781403
[5/24] Train loss=0.130076065659523
[10/24] Train loss=0.13104477524757385
[15/24] Train loss=0.12600556015968323
[20/24] Train loss=0.13170897960662842
Test set avg_accuracy=87.29% avg_sensitivity=71.02%, avg_specificity=93.35% avg_auc=90.88%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.134717 Test loss=0.326667 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.13241009414196014
[5/24] Train loss=0.12909863889217377
[10/24] Train loss=0.12824663519859314
[15/24] Train loss=0.13003641366958618
[20/24] Train loss=0.12917762994766235
Test set avg_accuracy=87.24% avg_sensitivity=72.94%, avg_specificity=92.57% avg_auc=91.48%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.133508 Test loss=0.319767 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13032549619674683
[5/24] Train loss=0.12579043209552765
[10/24] Train loss=0.1266469806432724
[15/24] Train loss=0.12569880485534668
[20/24] Train loss=0.12911328673362732
Test set avg_accuracy=87.33% avg_sensitivity=72.98%, avg_specificity=92.67% avg_auc=91.38%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.133038 Test loss=0.322093 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.13031169772148132
[5/24] Train loss=0.12705986201763153
[10/24] Train loss=0.12698876857757568
[15/24] Train loss=0.1272088587284088
[20/24] Train loss=0.12524692714214325
Test set avg_accuracy=87.24% avg_sensitivity=72.89%, avg_specificity=92.58% avg_auc=91.29%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.132257 Test loss=0.322860 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1282651722431183
[5/24] Train loss=0.1253882497549057
[10/24] Train loss=0.12673422694206238
[15/24] Train loss=0.12801015377044678
[20/24] Train loss=0.12606781721115112
Test set avg_accuracy=87.29% avg_sensitivity=72.55%, avg_specificity=92.78% avg_auc=91.11%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.132612 Test loss=0.324338 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13035224378108978
[5/24] Train loss=0.12519466876983643
[10/24] Train loss=0.12795691192150116
[15/24] Train loss=0.12626796960830688
[20/24] Train loss=0.1279841512441635
Test set avg_accuracy=87.23% avg_sensitivity=72.98%, avg_specificity=92.53% avg_auc=91.19%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.132614 Test loss=0.323444 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12911415100097656
[5/24] Train loss=0.12704998254776
[10/24] Train loss=0.12595868110656738
[15/24] Train loss=0.12927405536174774
[20/24] Train loss=0.12927286326885223
Test set avg_accuracy=87.20% avg_sensitivity=73.13%, avg_specificity=92.44% avg_auc=91.18%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.131569 Test loss=0.323865 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12753595411777496
[5/24] Train loss=0.12671354413032532
[10/24] Train loss=0.1286490261554718
[15/24] Train loss=0.1256536841392517
[20/24] Train loss=0.12806858122348785
Test set avg_accuracy=87.36% avg_sensitivity=73.13%, avg_specificity=92.66% avg_auc=91.19%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.131661 Test loss=0.323315 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12988366186618805
[5/24] Train loss=0.1237950250506401
[10/24] Train loss=0.12555845081806183
[15/24] Train loss=0.12717099487781525
[20/24] Train loss=0.12685279548168182
Test set avg_accuracy=87.41% avg_sensitivity=73.13%, avg_specificity=92.73% avg_auc=91.18%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.131237 Test loss=0.322762 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1284007728099823
[5/24] Train loss=0.1239771917462349
[10/24] Train loss=0.1284084916114807
[15/24] Train loss=0.12526577711105347
[20/24] Train loss=0.12821350991725922
Test set avg_accuracy=87.36% avg_sensitivity=72.79%, avg_specificity=92.78% avg_auc=91.20%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.131339 Test loss=0.322757 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12653379142284393
[5/24] Train loss=0.12621086835861206
[10/24] Train loss=0.1258876472711563
[15/24] Train loss=0.1231650561094284
[20/24] Train loss=0.12458817660808563
Test set avg_accuracy=87.33% avg_sensitivity=72.74%, avg_specificity=92.76% avg_auc=91.20%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.130773 Test loss=0.322903 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1260504424571991
[5/24] Train loss=0.12621788680553436
[10/24] Train loss=0.13000446557998657
[15/24] Train loss=0.12633375823497772
[20/24] Train loss=0.125994011759758
Test set avg_accuracy=87.37% avg_sensitivity=72.94%, avg_specificity=92.74% avg_auc=91.22%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.131536 Test loss=0.322864 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12714460492134094
[5/24] Train loss=0.12163843214511871
[10/24] Train loss=0.12392789125442505
[15/24] Train loss=0.1260780543088913
[20/24] Train loss=0.12645302712917328
Test set avg_accuracy=87.41% avg_sensitivity=72.74%, avg_specificity=92.87% avg_auc=91.20%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.130813 Test loss=0.322921 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12930579483509064
[5/24] Train loss=0.1256009340286255
[10/24] Train loss=0.12450046837329865
[15/24] Train loss=0.1246180459856987
[20/24] Train loss=0.12467561662197113
Test set avg_accuracy=87.37% avg_sensitivity=72.65%, avg_specificity=92.85% avg_auc=91.20%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.131164 Test loss=0.322958 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12800510227680206
[5/24] Train loss=0.12561896443367004
[10/24] Train loss=0.12536615133285522
[15/24] Train loss=0.12418868392705917
[20/24] Train loss=0.12400669604539871
Test set avg_accuracy=87.36% avg_sensitivity=72.60%, avg_specificity=92.85% avg_auc=91.19%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.130612 Test loss=0.323057 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=88.39% sen=76.68%, spe=92.74%, auc=92.81%!
Fold[6] Avg_overlap=0.71%(±0.2417264835163197)
[0/24] Train loss=0.7389193773269653
[5/24] Train loss=0.7247711420059204
[10/24] Train loss=0.7205137014389038
[15/24] Train loss=0.7141374945640564
[20/24] Train loss=0.7160298824310303
Test set avg_accuracy=56.35% avg_sensitivity=43.56%, avg_specificity=61.23% avg_auc=53.07%
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.723710 Test loss=0.687105 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7134451270103455
[5/24] Train loss=0.7140893936157227
[10/24] Train loss=0.7013862729072571
[15/24] Train loss=0.6904770731925964
[20/24] Train loss=0.6876327991485596
Test set avg_accuracy=61.34% avg_sensitivity=55.30%, avg_specificity=63.64% avg_auc=62.67%
Best model saved!! Metric=-83.03548328744628!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.702655 Test loss=0.657350 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6911612749099731
[5/24] Train loss=0.6883400082588196
[10/24] Train loss=0.6877267956733704
[15/24] Train loss=0.6768487691879272
[20/24] Train loss=0.6639854907989502
Test set avg_accuracy=65.60% avg_sensitivity=57.28%, avg_specificity=68.77% avg_auc=67.70%
Best model saved!! Metric=-66.64230645307902!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.682692 Test loss=0.634989 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6659932136535645
[5/24] Train loss=0.6658266186714172
[10/24] Train loss=0.6639245748519897
[15/24] Train loss=0.6510564684867859
[20/24] Train loss=0.6397765278816223
Test set avg_accuracy=68.31% avg_sensitivity=59.64%, avg_specificity=71.61% avg_auc=71.24%
Best model saved!! Metric=-55.195931017023334!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.662166 Test loss=0.610066 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6431306600570679
[5/24] Train loss=0.6522581577301025
[10/24] Train loss=0.6400468349456787
[15/24] Train loss=0.6239777207374573
[20/24] Train loss=0.6141422390937805
Test set avg_accuracy=70.22% avg_sensitivity=63.79%, avg_specificity=72.67% avg_auc=75.01%
Best model saved!! Metric=-44.300039796798735!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.639928 Test loss=0.581916 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6229640245437622
[5/24] Train loss=0.6221897006034851
[10/24] Train loss=0.6218876242637634
[15/24] Train loss=0.5953488945960999
[20/24] Train loss=0.577643871307373
Test set avg_accuracy=71.99% avg_sensitivity=68.69%, avg_specificity=73.25% avg_auc=78.56%
Best model saved!! Metric=-33.50782093889801!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.613582 Test loss=0.553709 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5849699378013611
[5/24] Train loss=0.5923959612846375
[10/24] Train loss=0.5902542471885681
[15/24] Train loss=0.5676504969596863
[20/24] Train loss=0.5511950254440308
Test set avg_accuracy=74.53% avg_sensitivity=72.56%, avg_specificity=75.28% avg_auc=82.09%
Best model saved!! Metric=-21.530402298912733!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.585105 Test loss=0.515440 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5604791641235352
[5/24] Train loss=0.5591747760772705
[10/24] Train loss=0.5627028942108154
[15/24] Train loss=0.5363934636116028
[20/24] Train loss=0.5159683227539062
Test set avg_accuracy=77.45% avg_sensitivity=77.23%, avg_specificity=77.53% avg_auc=84.97%
Best model saved!! Metric=-8.821446172785869!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.554737 Test loss=0.486650 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5309408903121948
[5/24] Train loss=0.526833176612854
[10/24] Train loss=0.5291972160339355
[15/24] Train loss=0.5037597417831421
[20/24] Train loss=0.4788964092731476
Test set avg_accuracy=80.34% avg_sensitivity=74.82%, avg_specificity=82.44% avg_auc=86.79%
Best model saved!! Metric=-1.6044526019221763!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.525376 Test loss=0.451639 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5010554790496826
[5/24] Train loss=0.48738953471183777
[10/24] Train loss=0.5079665184020996
[15/24] Train loss=0.4815627336502075
[20/24] Train loss=0.4525175988674164
Test set avg_accuracy=81.68% avg_sensitivity=75.72%, avg_specificity=83.95% avg_auc=88.26%
Best model saved!! Metric=3.609854813238911!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.494595 Test loss=0.427666 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4745095372200012
[5/24] Train loss=0.45289182662963867
[10/24] Train loss=0.4765511155128479
[15/24] Train loss=0.4546905755996704
[20/24] Train loss=0.4191543459892273
Test set avg_accuracy=83.26% avg_sensitivity=74.45%, avg_specificity=86.62% avg_auc=89.31%
Best model saved!! Metric=7.630417005229731!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.467221 Test loss=0.403256 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.45051103830337524
[5/24] Train loss=0.42915213108062744
[10/24] Train loss=0.4526921212673187
[15/24] Train loss=0.4246736168861389
[20/24] Train loss=0.3963986933231354
Test set avg_accuracy=84.24% avg_sensitivity=76.05%, avg_specificity=87.37% avg_auc=90.35%
Best model saved!! Metric=12.018370011317856!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.443866 Test loss=0.385840 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4306853115558624
[5/24] Train loss=0.40172210335731506
[10/24] Train loss=0.43325456976890564
[15/24] Train loss=0.4080851376056671
[20/24] Train loss=0.37359580397605896
Test set avg_accuracy=85.04% avg_sensitivity=73.64%, avg_specificity=89.39% avg_auc=90.99%
Best model saved!! Metric=13.064480460807715!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.421152 Test loss=0.368396 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4087553322315216
[5/24] Train loss=0.378696084022522
[10/24] Train loss=0.40778467059135437
[15/24] Train loss=0.39306360483169556
[20/24] Train loss=0.35913270711898804
Test set avg_accuracy=85.76% avg_sensitivity=66.71%, avg_specificity=93.02% avg_auc=91.16%
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.401670 Test loss=0.350693 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3969860374927521
[5/24] Train loss=0.36572590470314026
[10/24] Train loss=0.3942005932331085
[15/24] Train loss=0.37551674246788025
[20/24] Train loss=0.342306524515152
Test set avg_accuracy=85.69% avg_sensitivity=62.80%, avg_specificity=94.42% avg_auc=91.37%
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.386245 Test loss=0.345734 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.38102877140045166
[5/24] Train loss=0.35091572999954224
[10/24] Train loss=0.377729594707489
[15/24] Train loss=0.35869473218917847
[20/24] Train loss=0.32608795166015625
Test set avg_accuracy=85.12% avg_sensitivity=57.24%, avg_specificity=95.75% avg_auc=91.10%
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.369690 Test loss=0.348031 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.36462754011154175
[5/24] Train loss=0.3316783905029297
[10/24] Train loss=0.36842137575149536
[15/24] Train loss=0.35590842366218567
[20/24] Train loss=0.31716424226760864
Test set avg_accuracy=85.07% avg_sensitivity=55.78%, avg_specificity=96.24% avg_auc=91.31%
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.357413 Test loss=0.346875 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.356601357460022
[5/24] Train loss=0.31965121626853943
[10/24] Train loss=0.3561103343963623
[15/24] Train loss=0.34130820631980896
[20/24] Train loss=0.3035193979740143
Test set avg_accuracy=84.21% avg_sensitivity=51.49%, avg_specificity=96.69% avg_auc=90.87%
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.345261 Test loss=0.355206 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3420563042163849
[5/24] Train loss=0.3078235685825348
[10/24] Train loss=0.3415719270706177
[15/24] Train loss=0.32838138937950134
[20/24] Train loss=0.29654988646507263
Test set avg_accuracy=84.96% avg_sensitivity=54.17%, avg_specificity=96.71% avg_auc=91.45%
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.335054 Test loss=0.344908 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.33711597323417664
[5/24] Train loss=0.29619327187538147
[10/24] Train loss=0.33283060789108276
[15/24] Train loss=0.3191434442996979
[20/24] Train loss=0.2835196256637573
Test set avg_accuracy=85.38% avg_sensitivity=56.53%, avg_specificity=96.38% avg_auc=91.65%
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.327895 Test loss=0.337642 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3316023051738739
[5/24] Train loss=0.28859221935272217
[10/24] Train loss=0.3298328220844269
[15/24] Train loss=0.313894122838974
[20/24] Train loss=0.282853364944458
Test set avg_accuracy=85.81% avg_sensitivity=57.76%, avg_specificity=96.51% avg_auc=92.13%
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.319857 Test loss=0.330775 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.31698065996170044
[5/24] Train loss=0.27575403451919556
[10/24] Train loss=0.3201374411582947
[15/24] Train loss=0.3085402250289917
[20/24] Train loss=0.2753027677536011
Test set avg_accuracy=84.69% avg_sensitivity=51.11%, avg_specificity=97.50% avg_auc=91.42%
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.311013 Test loss=0.352685 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.31867697834968567
[5/24] Train loss=0.2699294686317444
[10/24] Train loss=0.31901654601097107
[15/24] Train loss=0.3029915392398834
[20/24] Train loss=0.2693648040294647
Test set avg_accuracy=85.33% avg_sensitivity=54.31%, avg_specificity=97.16% avg_auc=92.65%
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.305114 Test loss=0.332509 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3097669780254364
[5/24] Train loss=0.26765814423561096
[10/24] Train loss=0.30954813957214355
[15/24] Train loss=0.29770687222480774
[20/24] Train loss=0.2658316493034363
Test set avg_accuracy=85.92% avg_sensitivity=57.90%, avg_specificity=96.62% avg_auc=93.20%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.300908 Test loss=0.318072 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3044096827507019
[5/24] Train loss=0.26121312379837036
[10/24] Train loss=0.30157849192619324
[15/24] Train loss=0.2895672619342804
[20/24] Train loss=0.26032620668411255
Test set avg_accuracy=84.93% avg_sensitivity=52.19%, avg_specificity=97.43% avg_auc=92.42%
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.294966 Test loss=0.339183 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3017675280570984
[5/24] Train loss=0.2567443251609802
[10/24] Train loss=0.3031342923641205
[15/24] Train loss=0.2876080870628357
[20/24] Train loss=0.25604167580604553
Test set avg_accuracy=85.92% avg_sensitivity=56.77%, avg_specificity=97.05% avg_auc=93.12%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.291580 Test loss=0.318722 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3027942180633545
[5/24] Train loss=0.2515425980091095
[10/24] Train loss=0.29303690791130066
[15/24] Train loss=0.27791449427604675
[20/24] Train loss=0.25532296299934387
Test set avg_accuracy=86.12% avg_sensitivity=57.71%, avg_specificity=96.96% avg_auc=92.98%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.286221 Test loss=0.318606 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.293356716632843
[5/24] Train loss=0.24345241487026215
[10/24] Train loss=0.2922297418117523
[15/24] Train loss=0.28169137239456177
[20/24] Train loss=0.24646900594234467
Test set avg_accuracy=83.85% avg_sensitivity=48.09%, avg_specificity=97.50% avg_auc=90.74%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.281618 Test loss=0.369376 Current lr=[0.000210185142098938]

[0/24] Train loss=0.28712722659111023
[5/24] Train loss=0.24110451340675354
[10/24] Train loss=0.2910729944705963
[15/24] Train loss=0.27151262760162354
[20/24] Train loss=0.25085243582725525
Test set avg_accuracy=86.02% avg_sensitivity=57.85%, avg_specificity=96.76% avg_auc=92.83%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.279601 Test loss=0.318767 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2815670669078827
[5/24] Train loss=0.23351727426052094
[10/24] Train loss=0.2904265224933624
[15/24] Train loss=0.2706223130226135
[20/24] Train loss=0.2426750361919403
Test set avg_accuracy=84.80% avg_sensitivity=51.25%, avg_specificity=97.61% avg_auc=91.26%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.275920 Test loss=0.358402 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.27930983901023865
[5/24] Train loss=0.23022237420082092
[10/24] Train loss=0.2914588153362274
[15/24] Train loss=0.26465579867362976
[20/24] Train loss=0.24065737426280975
Test set avg_accuracy=84.88% avg_sensitivity=51.16%, avg_specificity=97.75% avg_auc=90.41%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.272631 Test loss=0.362363 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2794096767902374
[5/24] Train loss=0.2355889081954956
[10/24] Train loss=0.28780311346054077
[15/24] Train loss=0.2694947123527527
[20/24] Train loss=0.24095475673675537
Test set avg_accuracy=85.22% avg_sensitivity=53.04%, avg_specificity=97.50% avg_auc=91.14%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.272640 Test loss=0.349179 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2724325656890869
[5/24] Train loss=0.2229817807674408
[10/24] Train loss=0.268130362033844
[15/24] Train loss=0.25684890151023865
[20/24] Train loss=0.2292128950357437
Test set avg_accuracy=79.24% avg_sensitivity=27.20%, avg_specificity=99.10% avg_auc=86.74%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.266150 Test loss=0.518150 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2683413326740265
[5/24] Train loss=0.22480285167694092
[10/24] Train loss=0.28620457649230957
[15/24] Train loss=0.2615584135055542
[20/24] Train loss=0.23427459597587585
Test set avg_accuracy=82.02% avg_sensitivity=38.57%, avg_specificity=98.60% avg_auc=88.38%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.268154 Test loss=0.433910 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2777523696422577
[5/24] Train loss=0.22116272151470184
[10/24] Train loss=0.276856005191803
[15/24] Train loss=0.25892359018325806
[20/24] Train loss=0.23228658735752106
Test set avg_accuracy=82.11% avg_sensitivity=38.66%, avg_specificity=98.69% avg_auc=86.84%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.268060 Test loss=0.438550 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.27012699842453003
[5/24] Train loss=0.2285919189453125
[10/24] Train loss=0.2765340209007263
[15/24] Train loss=0.273511677980423
[20/24] Train loss=0.23836593329906464
Test set avg_accuracy=82.86% avg_sensitivity=42.29%, avg_specificity=98.35% avg_auc=89.80%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.266131 Test loss=0.418288 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.27564945816993713
[5/24] Train loss=0.2295704036951065
[10/24] Train loss=0.2735615670681
[15/24] Train loss=0.25549328327178955
[20/24] Train loss=0.23040546476840973
Test set avg_accuracy=82.89% avg_sensitivity=42.53%, avg_specificity=98.29% avg_auc=88.88%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.261837 Test loss=0.422114 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2726846933364868
[5/24] Train loss=0.22891700267791748
[10/24] Train loss=0.2668747305870056
[15/24] Train loss=0.25247207283973694
[20/24] Train loss=0.23249313235282898
Test set avg_accuracy=84.57% avg_sensitivity=50.83%, avg_specificity=97.45% avg_auc=92.59%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.262548 Test loss=0.346931 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2643560469150543
[5/24] Train loss=0.22457604110240936
[10/24] Train loss=0.2776666283607483
[15/24] Train loss=0.25118136405944824
[20/24] Train loss=0.2367103099822998
Test set avg_accuracy=84.39% avg_sensitivity=50.07%, avg_specificity=97.48% avg_auc=89.70%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.259391 Test loss=0.385817 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2789093255996704
[5/24] Train loss=0.22131624817848206
[10/24] Train loss=0.27525943517684937
[15/24] Train loss=0.24437052011489868
[20/24] Train loss=0.22678551077842712
Test set avg_accuracy=80.94% avg_sensitivity=34.23%, avg_specificity=98.76% avg_auc=86.56%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.256162 Test loss=0.478407 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2818000614643097
[5/24] Train loss=0.21657872200012207
[10/24] Train loss=0.2857549786567688
[15/24] Train loss=0.24697133898735046
[20/24] Train loss=0.23013430833816528
Test set avg_accuracy=82.98% avg_sensitivity=42.15%, avg_specificity=98.56% avg_auc=90.46%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.256647 Test loss=0.393917 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2738718092441559
[5/24] Train loss=0.21623890101909637
[10/24] Train loss=0.26890480518341064
[15/24] Train loss=0.25387731194496155
[20/24] Train loss=0.22956804931163788
Test set avg_accuracy=79.96% avg_sensitivity=29.75%, avg_specificity=99.12% avg_auc=86.19%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.260009 Test loss=0.489445 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.254761666059494
[5/24] Train loss=0.20638436079025269
[10/24] Train loss=0.2609785199165344
[15/24] Train loss=0.24642103910446167
[20/24] Train loss=0.2316056191921234
Test set avg_accuracy=83.10% avg_sensitivity=43.99%, avg_specificity=98.02% avg_auc=90.10%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.253355 Test loss=0.398424 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2671176791191101
[5/24] Train loss=0.22128689289093018
[10/24] Train loss=0.26181524991989136
[15/24] Train loss=0.24673816561698914
[20/24] Train loss=0.22668345272541046
Test set avg_accuracy=87.17% avg_sensitivity=64.78%, avg_specificity=95.72% avg_auc=92.95%
Best model saved!! Metric=14.626166560369427!!
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.254074 Test loss=0.305440 Current lr=[0.00029967723776099]

[0/24] Train loss=0.261455774307251
[5/24] Train loss=0.22005662322044373
[10/24] Train loss=0.25737592577934265
[15/24] Train loss=0.24610279500484467
[20/24] Train loss=0.22161410748958588
Test set avg_accuracy=84.27% avg_sensitivity=49.50%, avg_specificity=97.54% avg_auc=91.25%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.250888 Test loss=0.361962 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.252622127532959
[5/24] Train loss=0.21696877479553223
[10/24] Train loss=0.2544644773006439
[15/24] Train loss=0.2518352270126343
[20/24] Train loss=0.22195565700531006
Test set avg_accuracy=83.16% avg_sensitivity=44.32%, avg_specificity=97.99% avg_auc=88.91%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.249429 Test loss=0.425306 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.25649508833885193
[5/24] Train loss=0.22639207541942596
[10/24] Train loss=0.25505730509757996
[15/24] Train loss=0.2539653778076172
[20/24] Train loss=0.2268182933330536
Test set avg_accuracy=86.00% avg_sensitivity=60.07%, avg_specificity=95.90% avg_auc=91.99%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.256290 Test loss=0.326617 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2531477212905884
[5/24] Train loss=0.21604150533676147
[10/24] Train loss=0.24815945327281952
[15/24] Train loss=0.2436116337776184
[20/24] Train loss=0.22518892586231232
Test set avg_accuracy=87.01% avg_sensitivity=68.93%, avg_specificity=93.90% avg_auc=92.26%
Best model saved!! Metric=16.09268917300622!!
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.247532 Test loss=0.308530 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.24855831265449524
[5/24] Train loss=0.22345224022865295
[10/24] Train loss=0.2650589048862457
[15/24] Train loss=0.246285542845726
[20/24] Train loss=0.22300979495048523
Test set avg_accuracy=88.28% avg_sensitivity=74.40%, avg_specificity=93.58% avg_auc=93.11%
Best model saved!! Metric=23.37268872524635!!
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.244952 Test loss=0.291450 Current lr=[0.000298904600941902]

[0/24] Train loss=0.24063241481781006
[5/24] Train loss=0.20779407024383545
[10/24] Train loss=0.24685978889465332
[15/24] Train loss=0.24242770671844482
[20/24] Train loss=0.22711296379566193
Test set avg_accuracy=84.75% avg_sensitivity=53.42%, avg_specificity=96.71% avg_auc=90.21%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.245493 Test loss=0.364991 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.25471261143684387
[5/24] Train loss=0.20725658535957336
[10/24] Train loss=0.2562836706638336
[15/24] Train loss=0.2541746199131012
[20/24] Train loss=0.22382760047912598
Test set avg_accuracy=84.96% avg_sensitivity=54.27%, avg_specificity=96.67% avg_auc=91.19%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.246943 Test loss=0.361528 Current lr=[0.000297555943323901]

[0/24] Train loss=0.25320616364479065
[5/24] Train loss=0.21304726600646973
[10/24] Train loss=0.24709591269493103
[15/24] Train loss=0.253265917301178
[20/24] Train loss=0.22645816206932068
Test set avg_accuracy=86.22% avg_sensitivity=60.07%, avg_specificity=96.20% avg_auc=91.64%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.246802 Test loss=0.329725 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.24866139888763428
[5/24] Train loss=0.20835570991039276
[10/24] Train loss=0.25434765219688416
[15/24] Train loss=0.24319282174110413
[20/24] Train loss=0.21932174265384674
Test set avg_accuracy=85.96% avg_sensitivity=59.59%, avg_specificity=96.02% avg_auc=90.53%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.242027 Test loss=0.334863 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.24438446760177612
[5/24] Train loss=0.21341930329799652
[10/24] Train loss=0.240483358502388
[15/24] Train loss=0.25040435791015625
[20/24] Train loss=0.2242293357849121
Test set avg_accuracy=85.99% avg_sensitivity=60.58%, avg_specificity=95.68% avg_auc=91.68%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.241606 Test loss=0.329682 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2444804310798645
[5/24] Train loss=0.20299483835697174
[10/24] Train loss=0.2374245822429657
[15/24] Train loss=0.2335207760334015
[20/24] Train loss=0.22000108659267426
Test set avg_accuracy=84.39% avg_sensitivity=51.25%, avg_specificity=97.03% avg_auc=87.77%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.236940 Test loss=0.401900 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.24771633744239807
[5/24] Train loss=0.20961320400238037
[10/24] Train loss=0.24798902869224548
[15/24] Train loss=0.24835512042045593
[20/24] Train loss=0.2215684950351715
Test set avg_accuracy=85.83% avg_sensitivity=57.19%, avg_specificity=96.76% avg_auc=91.07%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.239063 Test loss=0.342432 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.24922743439674377
[5/24] Train loss=0.19520719349384308
[10/24] Train loss=0.24053801596164703
[15/24] Train loss=0.23555245995521545
[20/24] Train loss=0.21422457695007324
Test set avg_accuracy=82.38% avg_sensitivity=41.96%, avg_specificity=97.81% avg_auc=87.29%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.233587 Test loss=0.437663 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.24162344634532928
[5/24] Train loss=0.21784058213233948
[10/24] Train loss=0.23087289929389954
[15/24] Train loss=0.23470869660377502
[20/24] Train loss=0.22519002854824066
Test set avg_accuracy=87.70% avg_sensitivity=67.09%, avg_specificity=95.56% avg_auc=93.28%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.238203 Test loss=0.295340 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2381436675786972
[5/24] Train loss=0.20294907689094543
[10/24] Train loss=0.2376721203327179
[15/24] Train loss=0.2224370539188385
[20/24] Train loss=0.21396861970424652
Test set avg_accuracy=87.24% avg_sensitivity=69.21%, avg_specificity=94.12% avg_auc=93.10%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.229904 Test loss=0.296282 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.23739370703697205
[5/24] Train loss=0.20405100286006927
[10/24] Train loss=0.22854697704315186
[15/24] Train loss=0.23175685107707977
[20/24] Train loss=0.21802863478660583
Test set avg_accuracy=86.64% avg_sensitivity=69.31%, avg_specificity=93.25% avg_auc=92.43%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.233221 Test loss=0.305403 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.22843915224075317
[5/24] Train loss=0.20154894888401031
[10/24] Train loss=0.22155839204788208
[15/24] Train loss=0.2353696972131729
[20/24] Train loss=0.21505402028560638
Test set avg_accuracy=86.71% avg_sensitivity=69.68%, avg_specificity=93.20% avg_auc=91.52%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.230484 Test loss=0.318764 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.24730053544044495
[5/24] Train loss=0.19062186777591705
[10/24] Train loss=0.2140226662158966
[15/24] Train loss=0.23941534757614136
[20/24] Train loss=0.21575264632701874
Test set avg_accuracy=86.42% avg_sensitivity=70.49%, avg_specificity=92.50% avg_auc=91.10%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.232220 Test loss=0.324188 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2506267726421356
[5/24] Train loss=0.20165427029132843
[10/24] Train loss=0.23529136180877686
[15/24] Train loss=0.23470669984817505
[20/24] Train loss=0.2165164351463318
Test set avg_accuracy=81.77% avg_sensitivity=40.12%, avg_specificity=97.66% avg_auc=86.23%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.232700 Test loss=0.470587 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.23909814655780792
[5/24] Train loss=0.2017512023448944
[10/24] Train loss=0.22970671951770782
[15/24] Train loss=0.22774191200733185
[20/24] Train loss=0.20897912979125977
Test set avg_accuracy=83.45% avg_sensitivity=50.12%, avg_specificity=96.17% avg_auc=86.80%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.225074 Test loss=0.409304 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2380313128232956
[5/24] Train loss=0.2093215137720108
[10/24] Train loss=0.22472365200519562
[15/24] Train loss=0.22416718304157257
[20/24] Train loss=0.20926308631896973
Test set avg_accuracy=80.95% avg_sensitivity=34.04%, avg_specificity=98.85% avg_auc=79.84%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.227829 Test loss=0.574140 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.23723697662353516
[5/24] Train loss=0.20707768201828003
[10/24] Train loss=0.22942915558815002
[15/24] Train loss=0.22130601108074188
[20/24] Train loss=0.21295230090618134
Test set avg_accuracy=83.62% avg_sensitivity=48.33%, avg_specificity=97.09% avg_auc=87.07%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.225877 Test loss=0.418343 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.23420347273349762
[5/24] Train loss=0.1984660029411316
[10/24] Train loss=0.22177064418792725
[15/24] Train loss=0.2124590277671814
[20/24] Train loss=0.20579107105731964
Test set avg_accuracy=83.50% avg_sensitivity=46.06%, avg_specificity=97.79% avg_auc=88.33%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.222084 Test loss=0.404930 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.22547081112861633
[5/24] Train loss=0.21000856161117554
[10/24] Train loss=0.22463153302669525
[15/24] Train loss=0.22120603919029236
[20/24] Train loss=0.21127226948738098
Test set avg_accuracy=85.47% avg_sensitivity=54.36%, avg_specificity=97.34% avg_auc=89.27%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.223090 Test loss=0.381669 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.21594032645225525
[5/24] Train loss=0.19096626341342926
[10/24] Train loss=0.22558610141277313
[15/24] Train loss=0.2249756008386612
[20/24] Train loss=0.2102125585079193
Test set avg_accuracy=84.22% avg_sensitivity=51.67%, avg_specificity=96.64% avg_auc=89.31%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.222026 Test loss=0.388253 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.24487973749637604
[5/24] Train loss=0.19536300003528595
[10/24] Train loss=0.2214903086423874
[15/24] Train loss=0.2142120897769928
[20/24] Train loss=0.20445752143859863
Test set avg_accuracy=86.50% avg_sensitivity=68.46%, avg_specificity=93.38% avg_auc=91.60%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.219510 Test loss=0.319754 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.22781899571418762
[5/24] Train loss=0.1951296627521515
[10/24] Train loss=0.21350237727165222
[15/24] Train loss=0.20870257914066315
[20/24] Train loss=0.21151955425739288
Test set avg_accuracy=85.14% avg_sensitivity=55.16%, avg_specificity=96.58% avg_auc=90.00%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.216343 Test loss=0.364010 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.2238205373287201
[5/24] Train loss=0.1892857402563095
[10/24] Train loss=0.21443825960159302
[15/24] Train loss=0.2054360806941986
[20/24] Train loss=0.2054768204689026
Test set avg_accuracy=87.04% avg_sensitivity=68.60%, avg_specificity=94.08% avg_auc=92.56%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.215398 Test loss=0.308340 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.22393961250782013
[5/24] Train loss=0.1913783848285675
[10/24] Train loss=0.2138415426015854
[15/24] Train loss=0.2043391913175583
[20/24] Train loss=0.20944368839263916
Test set avg_accuracy=86.00% avg_sensitivity=58.56%, avg_specificity=96.47% avg_auc=90.15%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.216541 Test loss=0.350887 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.21838726103305817
[5/24] Train loss=0.19759182631969452
[10/24] Train loss=0.21691858768463135
[15/24] Train loss=0.19814735651016235
[20/24] Train loss=0.20919515192508698
Test set avg_accuracy=86.03% avg_sensitivity=58.89%, avg_specificity=96.38% avg_auc=91.15%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.212411 Test loss=0.342251 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.2300119400024414
[5/24] Train loss=0.1811893880367279
[10/24] Train loss=0.20534390211105347
[15/24] Train loss=0.20045360922813416
[20/24] Train loss=0.204001322388649
Test set avg_accuracy=86.37% avg_sensitivity=60.87%, avg_specificity=96.10% avg_auc=90.17%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.209662 Test loss=0.345613 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.21746493875980377
[5/24] Train loss=0.18010935187339783
[10/24] Train loss=0.2097148895263672
[15/24] Train loss=0.20552414655685425
[20/24] Train loss=0.20633363723754883
Test set avg_accuracy=86.39% avg_sensitivity=60.02%, avg_specificity=96.46% avg_auc=90.45%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.208587 Test loss=0.347051 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.21323959529399872
[5/24] Train loss=0.18646924197673798
[10/24] Train loss=0.1999911516904831
[15/24] Train loss=0.2019408941268921
[20/24] Train loss=0.19825243949890137
Test set avg_accuracy=86.11% avg_sensitivity=61.62%, avg_specificity=95.45% avg_auc=90.31%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.206630 Test loss=0.342977 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.21703216433525085
[5/24] Train loss=0.18336056172847748
[10/24] Train loss=0.21714286506175995
[15/24] Train loss=0.20398996770381927
[20/24] Train loss=0.19671986997127533
Test set avg_accuracy=86.09% avg_sensitivity=61.34%, avg_specificity=95.54% avg_auc=90.53%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.209206 Test loss=0.341932 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.21073171496391296
[5/24] Train loss=0.18299634754657745
[10/24] Train loss=0.21340064704418182
[15/24] Train loss=0.19756849110126495
[20/24] Train loss=0.20095133781433105
Test set avg_accuracy=86.47% avg_sensitivity=66.05%, avg_specificity=94.26% avg_auc=91.29%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.208793 Test loss=0.324076 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.21361958980560303
[5/24] Train loss=0.1859455555677414
[10/24] Train loss=0.2050682008266449
[15/24] Train loss=0.19394385814666748
[20/24] Train loss=0.19936715066432953
Test set avg_accuracy=87.53% avg_sensitivity=71.19%, avg_specificity=93.76% avg_auc=92.27%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.205449 Test loss=0.305119 Current lr=[0.000224838296036774]

[0/24] Train loss=0.20896972715854645
[5/24] Train loss=0.18226376175880432
[10/24] Train loss=0.19806352257728577
[15/24] Train loss=0.20051105320453644
[20/24] Train loss=0.20172476768493652
Test set avg_accuracy=86.16% avg_sensitivity=62.56%, avg_specificity=95.16% avg_auc=90.50%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.207642 Test loss=0.336369 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.21878354251384735
[5/24] Train loss=0.18559719622135162
[10/24] Train loss=0.20391161739826202
[15/24] Train loss=0.19930920004844666
[20/24] Train loss=0.19950130581855774
Test set avg_accuracy=87.47% avg_sensitivity=69.26%, avg_specificity=94.42% avg_auc=92.26%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.206851 Test loss=0.309159 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.21267816424369812
[5/24] Train loss=0.17528238892555237
[10/24] Train loss=0.19802984595298767
[15/24] Train loss=0.19230425357818604
[20/24] Train loss=0.19094885885715485
Test set avg_accuracy=84.71% avg_sensitivity=69.83%, avg_specificity=90.39% avg_auc=89.15%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.202466 Test loss=0.359765 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.20896804332733154
[5/24] Train loss=0.17205549776554108
[10/24] Train loss=0.20165395736694336
[15/24] Train loss=0.20671652257442474
[20/24] Train loss=0.1957184225320816
Test set avg_accuracy=87.23% avg_sensitivity=67.09%, avg_specificity=94.91% avg_auc=91.62%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.207733 Test loss=0.317105 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.21277675032615662
[5/24] Train loss=0.1805250197649002
[10/24] Train loss=0.20905648171901703
[15/24] Train loss=0.18960826098918915
[20/24] Train loss=0.203696608543396
Test set avg_accuracy=87.03% avg_sensitivity=72.80%, avg_specificity=92.46% avg_auc=91.87%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.204912 Test loss=0.313485 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.21682678163051605
[5/24] Train loss=0.18693886697292328
[10/24] Train loss=0.21686583757400513
[15/24] Train loss=0.19033722579479218
[20/24] Train loss=0.19903162121772766
Test set avg_accuracy=87.83% avg_sensitivity=71.38%, avg_specificity=94.10% avg_auc=92.31%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.204845 Test loss=0.305617 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.20639106631278992
[5/24] Train loss=0.17558804154396057
[10/24] Train loss=0.20136770606040955
[15/24] Train loss=0.1926461011171341
[20/24] Train loss=0.20725226402282715
Test set avg_accuracy=87.55% avg_sensitivity=79.73%, avg_specificity=90.54% avg_auc=93.36%
Best model saved!! Metric=25.181416739266623!!
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.204513 Test loss=0.301684 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.21819058060646057
[5/24] Train loss=0.1767755001783371
[10/24] Train loss=0.2002839893102646
[15/24] Train loss=0.18767611682415009
[20/24] Train loss=0.1968744993209839
Test set avg_accuracy=88.09% avg_sensitivity=74.73%, avg_specificity=93.18% avg_auc=93.15%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.204567 Test loss=0.294250 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.21292687952518463
[5/24] Train loss=0.1764003038406372
[10/24] Train loss=0.19204045832157135
[15/24] Train loss=0.19706258177757263
[20/24] Train loss=0.19372861087322235
Test set avg_accuracy=87.68% avg_sensitivity=72.65%, avg_specificity=93.42% avg_auc=92.46%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.199096 Test loss=0.301252 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.19645097851753235
[5/24] Train loss=0.17349807918071747
[10/24] Train loss=0.1950618177652359
[15/24] Train loss=0.19579802453517914
[20/24] Train loss=0.19056743383407593
Test set avg_accuracy=87.04% avg_sensitivity=69.31%, avg_specificity=93.81% avg_auc=92.45%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.201287 Test loss=0.310847 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.21226096153259277
[5/24] Train loss=0.1834719181060791
[10/24] Train loss=0.1954507678747177
[15/24] Train loss=0.19503697752952576
[20/24] Train loss=0.18836693465709686
Test set avg_accuracy=85.09% avg_sensitivity=54.79%, avg_specificity=96.65% avg_auc=89.22%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.194962 Test loss=0.374032 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.19645299017429352
[5/24] Train loss=0.17208105325698853
[10/24] Train loss=0.19054989516735077
[15/24] Train loss=0.1853959560394287
[20/24] Train loss=0.18207873404026031
Test set avg_accuracy=85.18% avg_sensitivity=66.05%, avg_specificity=92.48% avg_auc=88.45%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.191686 Test loss=0.370220 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2028118222951889
[5/24] Train loss=0.17351564764976501
[10/24] Train loss=0.18139584362506866
[15/24] Train loss=0.18137413263320923
[20/24] Train loss=0.20079128444194794
Test set avg_accuracy=86.50% avg_sensitivity=63.32%, avg_specificity=95.34% avg_auc=89.84%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.191745 Test loss=0.344978 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.19825387001037598
[5/24] Train loss=0.1655767261981964
[10/24] Train loss=0.19177885353565216
[15/24] Train loss=0.1903865933418274
[20/24] Train loss=0.18369264900684357
Test set avg_accuracy=86.91% avg_sensitivity=63.13%, avg_specificity=95.99% avg_auc=90.35%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.191343 Test loss=0.339902 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.19185146689414978
[5/24] Train loss=0.16346077620983124
[10/24] Train loss=0.18458330631256104
[15/24] Train loss=0.1841084212064743
[20/24] Train loss=0.18452785909175873
Test set avg_accuracy=86.86% avg_sensitivity=65.91%, avg_specificity=94.86% avg_auc=90.63%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.188755 Test loss=0.332919 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.18982134759426117
[5/24] Train loss=0.16557863354682922
[10/24] Train loss=0.18415366113185883
[15/24] Train loss=0.1797737181186676
[20/24] Train loss=0.18308770656585693
Test set avg_accuracy=85.01% avg_sensitivity=53.70%, avg_specificity=96.96% avg_auc=88.69%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.188760 Test loss=0.376171 Current lr=[0.000156543481933168]

[0/24] Train loss=0.19527567923069
[5/24] Train loss=0.1662185788154602
[10/24] Train loss=0.1771712601184845
[15/24] Train loss=0.1718345284461975
[20/24] Train loss=0.18010535836219788
Test set avg_accuracy=81.46% avg_sensitivity=37.20%, avg_specificity=98.35% avg_auc=81.87%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.184693 Test loss=0.517850 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.187988743185997
[5/24] Train loss=0.1733406037092209
[10/24] Train loss=0.1841116100549698
[15/24] Train loss=0.1742950975894928
[20/24] Train loss=0.1810556948184967
Test set avg_accuracy=86.45% avg_sensitivity=64.69%, avg_specificity=94.75% avg_auc=90.86%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.183849 Test loss=0.334479 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.18710924685001373
[5/24] Train loss=0.170741468667984
[10/24] Train loss=0.17712822556495667
[15/24] Train loss=0.1771964579820633
[20/24] Train loss=0.17580609023571014
Test set avg_accuracy=87.15% avg_sensitivity=69.68%, avg_specificity=93.81% avg_auc=92.94%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.182562 Test loss=0.302940 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.18807944655418396
[5/24] Train loss=0.18682600557804108
[10/24] Train loss=0.18142341077327728
[15/24] Train loss=0.1798848807811737
[20/24] Train loss=0.1734032779932022
Test set avg_accuracy=86.51% avg_sensitivity=66.62%, avg_specificity=94.10% avg_auc=91.44%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.180675 Test loss=0.324511 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.18433040380477905
[5/24] Train loss=0.16779989004135132
[10/24] Train loss=0.1784193068742752
[15/24] Train loss=0.16667866706848145
[20/24] Train loss=0.1727927178144455
Test set avg_accuracy=85.55% avg_sensitivity=59.26%, avg_specificity=95.57% avg_auc=89.94%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.178155 Test loss=0.361492 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1798953115940094
[5/24] Train loss=0.15936800837516785
[10/24] Train loss=0.17647092044353485
[15/24] Train loss=0.16527584195137024
[20/24] Train loss=0.1747530847787857
Test set avg_accuracy=86.86% avg_sensitivity=64.97%, avg_specificity=95.21% avg_auc=92.36%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.176989 Test loss=0.316144 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.18538396060466766
[5/24] Train loss=0.15835349261760712
[10/24] Train loss=0.17217500507831573
[15/24] Train loss=0.16535387933254242
[20/24] Train loss=0.18142631649971008
Test set avg_accuracy=87.86% avg_sensitivity=74.87%, avg_specificity=92.82% avg_auc=92.71%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.177562 Test loss=0.298231 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.17976561188697815
[5/24] Train loss=0.16120360791683197
[10/24] Train loss=0.1714310348033905
[15/24] Train loss=0.17167483270168304
[20/24] Train loss=0.1715564727783203
Test set avg_accuracy=87.07% avg_sensitivity=66.71%, avg_specificity=94.84% avg_auc=91.53%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.173838 Test loss=0.320043 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.1803492158651352
[5/24] Train loss=0.15300707519054413
[10/24] Train loss=0.1705564260482788
[15/24] Train loss=0.16442172229290009
[20/24] Train loss=0.17364701628684998
Test set avg_accuracy=87.72% avg_sensitivity=71.33%, avg_specificity=93.97% avg_auc=92.73%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.170933 Test loss=0.304122 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.18226639926433563
[5/24] Train loss=0.14862515032291412
[10/24] Train loss=0.16155996918678284
[15/24] Train loss=0.15805351734161377
[20/24] Train loss=0.1677357405424118
Test set avg_accuracy=87.55% avg_sensitivity=75.62%, avg_specificity=92.10% avg_auc=92.65%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.167628 Test loss=0.302216 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.17255602777004242
[5/24] Train loss=0.1553395837545395
[10/24] Train loss=0.16102556884288788
[15/24] Train loss=0.1544298529624939
[20/24] Train loss=0.16580522060394287
Test set avg_accuracy=87.51% avg_sensitivity=69.68%, avg_specificity=94.32% avg_auc=92.08%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.165375 Test loss=0.308606 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1699128895998001
[5/24] Train loss=0.15162576735019684
[10/24] Train loss=0.1614173799753189
[15/24] Train loss=0.16546808183193207
[20/24] Train loss=0.16349349915981293
Test set avg_accuracy=87.53% avg_sensitivity=65.63%, avg_specificity=95.88% avg_auc=91.52%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.164754 Test loss=0.320156 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1713320016860962
[5/24] Train loss=0.1473083794116974
[10/24] Train loss=0.1621326059103012
[15/24] Train loss=0.15918470919132233
[20/24] Train loss=0.16213029623031616
Test set avg_accuracy=88.16% avg_sensitivity=70.82%, avg_specificity=94.78% avg_auc=92.66%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.162484 Test loss=0.296221 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1676359474658966
[5/24] Train loss=0.14334450662136078
[10/24] Train loss=0.15891224145889282
[15/24] Train loss=0.15391434729099274
[20/24] Train loss=0.16107149422168732
Test set avg_accuracy=87.28% avg_sensitivity=75.01%, avg_specificity=91.96% avg_auc=91.85%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.161118 Test loss=0.315069 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.1707450896501541
[5/24] Train loss=0.14457279443740845
[10/24] Train loss=0.15718933939933777
[15/24] Train loss=0.1530837118625641
[20/24] Train loss=0.16359005868434906
Test set avg_accuracy=87.45% avg_sensitivity=73.83%, avg_specificity=92.64% avg_auc=92.13%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.161407 Test loss=0.309528 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.16718044877052307
[5/24] Train loss=0.14390327036380768
[10/24] Train loss=0.15065912902355194
[15/24] Train loss=0.15503109991550446
[20/24] Train loss=0.1597999781370163
Test set avg_accuracy=87.12% avg_sensitivity=74.82%, avg_specificity=91.82% avg_auc=91.95%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.159583 Test loss=0.314617 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.15902218222618103
[5/24] Train loss=0.13973766565322876
[10/24] Train loss=0.1553773581981659
[15/24] Train loss=0.15094426274299622
[20/24] Train loss=0.15918022394180298
Test set avg_accuracy=87.80% avg_sensitivity=71.00%, avg_specificity=94.21% avg_auc=92.12%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.158081 Test loss=0.305671 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.16509738564491272
[5/24] Train loss=0.14240185916423798
[10/24] Train loss=0.15747442841529846
[15/24] Train loss=0.14580285549163818
[20/24] Train loss=0.15373662114143372
Test set avg_accuracy=87.85% avg_sensitivity=74.96%, avg_specificity=92.77% avg_auc=92.11%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.158471 Test loss=0.305853 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.16036823391914368
[5/24] Train loss=0.14475685358047485
[10/24] Train loss=0.14864251017570496
[15/24] Train loss=0.1447913944721222
[20/24] Train loss=0.1617971956729889
Test set avg_accuracy=87.37% avg_sensitivity=73.27%, avg_specificity=92.75% avg_auc=92.76%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.157335 Test loss=0.300422 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15875470638275146
[5/24] Train loss=0.1389520764350891
[10/24] Train loss=0.1556171178817749
[15/24] Train loss=0.14624011516571045
[20/24] Train loss=0.1565345674753189
Test set avg_accuracy=87.58% avg_sensitivity=77.27%, avg_specificity=91.51% avg_auc=93.15%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.155327 Test loss=0.300523 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.16142353415489197
[5/24] Train loss=0.13472147285938263
[10/24] Train loss=0.16065947711467743
[15/24] Train loss=0.14176687598228455
[20/24] Train loss=0.15243390202522278
Test set avg_accuracy=86.88% avg_sensitivity=73.46%, avg_specificity=91.99% avg_auc=92.42%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.154462 Test loss=0.311709 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.16038236021995544
[5/24] Train loss=0.14540335536003113
[10/24] Train loss=0.14578759670257568
[15/24] Train loss=0.1425308734178543
[20/24] Train loss=0.15024243295192719
Test set avg_accuracy=87.21% avg_sensitivity=75.77%, avg_specificity=91.58% avg_auc=92.53%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.152852 Test loss=0.306121 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.15062054991722107
[5/24] Train loss=0.1337115615606308
[10/24] Train loss=0.14750780165195465
[15/24] Train loss=0.13853386044502258
[20/24] Train loss=0.15024922788143158
Test set avg_accuracy=86.85% avg_sensitivity=68.51%, avg_specificity=93.85% avg_auc=91.80%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.147892 Test loss=0.317417 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.15355266630649567
[5/24] Train loss=0.13487060368061066
[10/24] Train loss=0.14943593740463257
[15/24] Train loss=0.14150086045265198
[20/24] Train loss=0.1518157422542572
Test set avg_accuracy=87.43% avg_sensitivity=68.79%, avg_specificity=94.55% avg_auc=91.86%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.147810 Test loss=0.309061 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14916487038135529
[5/24] Train loss=0.1295345276594162
[10/24] Train loss=0.14325116574764252
[15/24] Train loss=0.1354333907365799
[20/24] Train loss=0.1518533080816269
Test set avg_accuracy=86.82% avg_sensitivity=71.38%, avg_specificity=92.71% avg_auc=91.84%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.145865 Test loss=0.314270 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.14943674206733704
[5/24] Train loss=0.12692853808403015
[10/24] Train loss=0.14416596293449402
[15/24] Train loss=0.1341671645641327
[20/24] Train loss=0.1465662121772766
Test set avg_accuracy=87.19% avg_sensitivity=69.45%, avg_specificity=93.96% avg_auc=91.30%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.144400 Test loss=0.317266 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14690908789634705
[5/24] Train loss=0.1274643987417221
[10/24] Train loss=0.14041750133037567
[15/24] Train loss=0.1318926215171814
[20/24] Train loss=0.145141139626503
Test set avg_accuracy=87.28% avg_sensitivity=72.65%, avg_specificity=92.86% avg_auc=92.39%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.142321 Test loss=0.306433 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1438780277967453
[5/24] Train loss=0.12922069430351257
[10/24] Train loss=0.13913755118846893
[15/24] Train loss=0.13162629306316376
[20/24] Train loss=0.14695791900157928
Test set avg_accuracy=87.54% avg_sensitivity=70.39%, avg_specificity=94.08% avg_auc=92.31%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.141483 Test loss=0.306923 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.14477333426475525
[5/24] Train loss=0.12450096756219864
[10/24] Train loss=0.1374443620443344
[15/24] Train loss=0.13036833703517914
[20/24] Train loss=0.1410200446844101
Test set avg_accuracy=87.28% avg_sensitivity=72.98%, avg_specificity=92.73% avg_auc=92.29%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.139618 Test loss=0.306433 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13943059742450714
[5/24] Train loss=0.1259986013174057
[10/24] Train loss=0.14011250436306
[15/24] Train loss=0.12846289575099945
[20/24] Train loss=0.14003650844097137
Test set avg_accuracy=87.37% avg_sensitivity=71.05%, avg_specificity=93.60% avg_auc=92.39%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.137999 Test loss=0.306402 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13971656560897827
[5/24] Train loss=0.12314257770776749
[10/24] Train loss=0.13577575981616974
[15/24] Train loss=0.12845683097839355
[20/24] Train loss=0.1416487991809845
Test set avg_accuracy=87.06% avg_sensitivity=72.18%, avg_specificity=92.73% avg_auc=92.08%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.137311 Test loss=0.311048 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1402295082807541
[5/24] Train loss=0.12015169858932495
[10/24] Train loss=0.13380849361419678
[15/24] Train loss=0.12854012846946716
[20/24] Train loss=0.14013294875621796
Test set avg_accuracy=87.19% avg_sensitivity=73.93%, avg_specificity=92.25% avg_auc=92.19%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.136843 Test loss=0.308196 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1399560421705246
[5/24] Train loss=0.12540291249752045
[10/24] Train loss=0.1358390897512436
[15/24] Train loss=0.13382644951343536
[20/24] Train loss=0.13822858035564423
Test set avg_accuracy=87.23% avg_sensitivity=73.31%, avg_specificity=92.53% avg_auc=91.85%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.137002 Test loss=0.312563 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13821172714233398
[5/24] Train loss=0.1235194280743599
[10/24] Train loss=0.13050222396850586
[15/24] Train loss=0.12857751548290253
[20/24] Train loss=0.13945680856704712
Test set avg_accuracy=87.54% avg_sensitivity=72.98%, avg_specificity=93.09% avg_auc=92.02%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.136222 Test loss=0.308551 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13581021130084991
[5/24] Train loss=0.1275419443845749
[10/24] Train loss=0.13502143323421478
[15/24] Train loss=0.1266518384218216
[20/24] Train loss=0.13977527618408203
Test set avg_accuracy=87.64% avg_sensitivity=71.90%, avg_specificity=93.65% avg_auc=92.11%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.136030 Test loss=0.304415 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1385165899991989
[5/24] Train loss=0.12098832428455353
[10/24] Train loss=0.13401277363300323
[15/24] Train loss=0.12321311235427856
[20/24] Train loss=0.1395941525697708
Test set avg_accuracy=87.85% avg_sensitivity=71.52%, avg_specificity=94.08% avg_auc=92.11%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.135802 Test loss=0.306688 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.14007388055324554
[5/24] Train loss=0.12242060899734497
[10/24] Train loss=0.1356302946805954
[15/24] Train loss=0.12499552220106125
[20/24] Train loss=0.13494299352169037
Test set avg_accuracy=87.80% avg_sensitivity=73.79%, avg_specificity=93.15% avg_auc=92.30%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.135009 Test loss=0.302854 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1360844522714615
[5/24] Train loss=0.11953681707382202
[10/24] Train loss=0.1292511373758316
[15/24] Train loss=0.1275387853384018
[20/24] Train loss=0.13428588211536407
Test set avg_accuracy=87.64% avg_sensitivity=71.99%, avg_specificity=93.61% avg_auc=92.23%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.132588 Test loss=0.303061 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13634374737739563
[5/24] Train loss=0.11968369036912918
[10/24] Train loss=0.13119810819625854
[15/24] Train loss=0.12353506684303284
[20/24] Train loss=0.1342504918575287
Test set avg_accuracy=87.66% avg_sensitivity=73.03%, avg_specificity=93.24% avg_auc=92.18%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.131800 Test loss=0.304988 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13351041078567505
[5/24] Train loss=0.11897378414869308
[10/24] Train loss=0.13145530223846436
[15/24] Train loss=0.12417308241128922
[20/24] Train loss=0.1334557831287384
Test set avg_accuracy=87.77% avg_sensitivity=72.98%, avg_specificity=93.42% avg_auc=92.47%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.131417 Test loss=0.303502 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.13339853286743164
[5/24] Train loss=0.11903050541877747
[10/24] Train loss=0.1282261610031128
[15/24] Train loss=0.12430964410305023
[20/24] Train loss=0.13209830224514008
Test set avg_accuracy=87.68% avg_sensitivity=71.90%, avg_specificity=93.70% avg_auc=91.99%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.130665 Test loss=0.307973 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13257724046707153
[5/24] Train loss=0.11943710595369339
[10/24] Train loss=0.12920817732810974
[15/24] Train loss=0.12067658454179764
[20/24] Train loss=0.1327584683895111
Test set avg_accuracy=87.80% avg_sensitivity=73.08%, avg_specificity=93.42% avg_auc=92.50%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.129699 Test loss=0.302474 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1334744244813919
[5/24] Train loss=0.11973915249109268
[10/24] Train loss=0.13011640310287476
[15/24] Train loss=0.12256906926631927
[20/24] Train loss=0.13066449761390686
Test set avg_accuracy=87.84% avg_sensitivity=72.65%, avg_specificity=93.63% avg_auc=92.29%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.129468 Test loss=0.304639 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13049200177192688
[5/24] Train loss=0.11646295338869095
[10/24] Train loss=0.12869583070278168
[15/24] Train loss=0.12207775563001633
[20/24] Train loss=0.13163572549819946
Test set avg_accuracy=87.77% avg_sensitivity=72.28%, avg_specificity=93.69% avg_auc=92.09%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.129029 Test loss=0.307050 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12990707159042358
[5/24] Train loss=0.11769735813140869
[10/24] Train loss=0.12901639938354492
[15/24] Train loss=0.123149573802948
[20/24] Train loss=0.1311936229467392
Test set avg_accuracy=87.57% avg_sensitivity=71.66%, avg_specificity=93.63% avg_auc=92.28%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.129532 Test loss=0.305831 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.130637988448143
[5/24] Train loss=0.11688163131475449
[10/24] Train loss=0.12714806199073792
[15/24] Train loss=0.1202041506767273
[20/24] Train loss=0.1306101381778717
Test set avg_accuracy=87.50% avg_sensitivity=71.85%, avg_specificity=93.47% avg_auc=92.31%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.128441 Test loss=0.304886 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13032902777194977
[5/24] Train loss=0.11610681563615799
[10/24] Train loss=0.12729614973068237
[15/24] Train loss=0.12200668454170227
[20/24] Train loss=0.13118135929107666
Test set avg_accuracy=87.57% avg_sensitivity=72.32%, avg_specificity=93.38% avg_auc=92.23%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.128810 Test loss=0.304674 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12996207177639008
[5/24] Train loss=0.11760969460010529
[10/24] Train loss=0.13039249181747437
[15/24] Train loss=0.11978399753570557
[20/24] Train loss=0.13205048441886902
Test set avg_accuracy=87.64% avg_sensitivity=72.18%, avg_specificity=93.54% avg_auc=92.22%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.128552 Test loss=0.304621 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1310497522354126
[5/24] Train loss=0.11694975197315216
[10/24] Train loss=0.1270422339439392
[15/24] Train loss=0.11962071061134338
[20/24] Train loss=0.13035693764686584
Test set avg_accuracy=87.63% avg_sensitivity=71.81%, avg_specificity=93.67% avg_auc=92.16%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.127867 Test loss=0.305827 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13141527771949768
[5/24] Train loss=0.11701594293117523
[10/24] Train loss=0.12703973054885864
[15/24] Train loss=0.12045743316411972
[20/24] Train loss=0.1297132968902588
Test set avg_accuracy=87.67% avg_sensitivity=71.76%, avg_specificity=93.74% avg_auc=92.17%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.127979 Test loss=0.305993 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12906448543071747
[5/24] Train loss=0.11654647439718246
[10/24] Train loss=0.12763521075248718
[15/24] Train loss=0.12126284092664719
[20/24] Train loss=0.13111340999603271
Test set avg_accuracy=87.66% avg_sensitivity=71.85%, avg_specificity=93.69% avg_auc=92.17%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.128183 Test loss=0.306037 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1295180320739746
[5/24] Train loss=0.11776268482208252
[10/24] Train loss=0.12978748977184296
[15/24] Train loss=0.11957214027643204
[20/24] Train loss=0.13074132800102234
Test set avg_accuracy=87.68% avg_sensitivity=71.85%, avg_specificity=93.72% avg_auc=92.17%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.128322 Test loss=0.306172 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12903791666030884
[5/24] Train loss=0.11863193660974503
[10/24] Train loss=0.12782058119773865
[15/24] Train loss=0.11787505447864532
[20/24] Train loss=0.13062234222888947
Test set avg_accuracy=87.66% avg_sensitivity=71.85%, avg_specificity=93.69% avg_auc=92.18%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.127729 Test loss=0.305957 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1303827464580536
[5/24] Train loss=0.11529531329870224
[10/24] Train loss=0.12819726765155792
[15/24] Train loss=0.12003074586391449
[20/24] Train loss=0.1311212033033371
Test set avg_accuracy=87.67% avg_sensitivity=71.90%, avg_specificity=93.69% avg_auc=92.17%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.128123 Test loss=0.306178 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=87.55% sen=79.73%, spe=90.54%, auc=93.36%!
Fold[7] Avg_overlap=0.69%(±0.24170362790897387)
[0/24] Train loss=0.7584508657455444
[5/24] Train loss=0.7541435360908508
[10/24] Train loss=0.7509168386459351
[15/24] Train loss=0.7408994436264038
[20/24] Train loss=0.7346523404121399
Test set avg_accuracy=52.36% avg_sensitivity=51.27%, avg_specificity=52.72% avg_auc=53.95%
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.745235 Test loss=0.702640 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7231314182281494
[5/24] Train loss=0.7322766184806824
[10/24] Train loss=0.726423978805542
[15/24] Train loss=0.7130827307701111
[20/24] Train loss=0.7100802659988403
Test set avg_accuracy=57.75% avg_sensitivity=62.09%, avg_specificity=56.29% avg_auc=62.65%
Best model saved!! Metric=-87.22177350591366!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.721466 Test loss=0.668861 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6973745226860046
[5/24] Train loss=0.7083826661109924
[10/24] Train loss=0.7077882289886475
[15/24] Train loss=0.6887050867080688
[20/24] Train loss=0.6901316046714783
Test set avg_accuracy=62.38% avg_sensitivity=66.29%, avg_specificity=61.07% avg_auc=67.75%
Best model saved!! Metric=-68.50385457082285!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.699555 Test loss=0.651025 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6790245175361633
[5/24] Train loss=0.68731290102005
[10/24] Train loss=0.6763215065002441
[15/24] Train loss=0.6664205193519592
[20/24] Train loss=0.6573354601860046
Test set avg_accuracy=65.70% avg_sensitivity=68.10%, avg_specificity=64.90% avg_auc=71.71%
Best model saved!! Metric=-55.5859347955072!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.676925 Test loss=0.630310 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6496273875236511
[5/24] Train loss=0.6699627637863159
[10/24] Train loss=0.6499109268188477
[15/24] Train loss=0.6393572092056274
[20/24] Train loss=0.6278318166732788
Test set avg_accuracy=69.19% avg_sensitivity=69.86%, avg_specificity=68.97% avg_auc=75.23%
Best model saved!! Metric=-42.7503944637307!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.652470 Test loss=0.603632 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6132552027702332
[5/24] Train loss=0.6338666677474976
[10/24] Train loss=0.6229222416877747
[15/24] Train loss=0.6134591698646545
[20/24] Train loss=0.5991908311843872
Test set avg_accuracy=72.58% avg_sensitivity=71.83%, avg_specificity=72.83% avg_auc=78.61%
Best model saved!! Metric=-30.150721365013027!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.625672 Test loss=0.566643 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5981471538543701
[5/24] Train loss=0.6148228049278259
[10/24] Train loss=0.6039880514144897
[15/24] Train loss=0.5781504511833191
[20/24] Train loss=0.5568702816963196
Test set avg_accuracy=74.36% avg_sensitivity=73.54%, avg_specificity=74.64% avg_auc=80.95%
Best model saved!! Metric=-22.5122926203165!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.598293 Test loss=0.540962 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5596302151679993
[5/24] Train loss=0.577275812625885
[10/24] Train loss=0.5738349556922913
[15/24] Train loss=0.546867311000824
[20/24] Train loss=0.5277978181838989
Test set avg_accuracy=76.73% avg_sensitivity=75.45%, avg_specificity=77.16% avg_auc=84.03%
Best model saved!! Metric=-12.626087813913898!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.567072 Test loss=0.508043 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5326839685440063
[5/24] Train loss=0.536607563495636
[10/24] Train loss=0.5431416630744934
[15/24] Train loss=0.5150631070137024
[20/24] Train loss=0.4873095452785492
Test set avg_accuracy=79.47% avg_sensitivity=75.82%, avg_specificity=80.69% avg_auc=86.20%
Best model saved!! Metric=-3.824965249953266!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.533624 Test loss=0.469829 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5048943758010864
[5/24] Train loss=0.4998021721839905
[10/24] Train loss=0.5120524168014526
[15/24] Train loss=0.48222237825393677
[20/24] Train loss=0.4578339457511902
Test set avg_accuracy=81.29% avg_sensitivity=76.28%, avg_specificity=82.97% avg_auc=87.86%
Best model saved!! Metric=2.4060942689276317!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.501247 Test loss=0.443044 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.47123977541923523
[5/24] Train loss=0.47020021080970764
[10/24] Train loss=0.485516756772995
[15/24] Train loss=0.458548367023468
[20/24] Train loss=0.41859954595565796
Test set avg_accuracy=82.50% avg_sensitivity=79.18%, avg_specificity=83.61% avg_auc=89.38%
Best model saved!! Metric=8.673039077608706!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.472051 Test loss=0.422913 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.448629230260849
[5/24] Train loss=0.4374634623527527
[10/24] Train loss=0.46442121267318726
[15/24] Train loss=0.4317105710506439
[20/24] Train loss=0.3928629755973816
Test set avg_accuracy=84.47% avg_sensitivity=78.46%, avg_specificity=86.48% avg_auc=90.22%
Best model saved!! Metric=13.627645111031782!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.444923 Test loss=0.393181 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4267185628414154
[5/24] Train loss=0.4121856987476349
[10/24] Train loss=0.43893805146217346
[15/24] Train loss=0.4121928811073303
[20/24] Train loss=0.3690694272518158
Test set avg_accuracy=85.98% avg_sensitivity=75.97%, avg_specificity=89.34% avg_auc=90.88%
Best model saved!! Metric=16.16657919981739!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.421803 Test loss=0.366889 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.40887153148651123
[5/24] Train loss=0.38902634382247925
[10/24] Train loss=0.4188195765018463
[15/24] Train loss=0.39101508259773254
[20/24] Train loss=0.3491581678390503
Test set avg_accuracy=86.71% avg_sensitivity=76.07%, avg_specificity=90.28% avg_auc=91.20%
Best model saved!! Metric=18.254395230582148!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.403353 Test loss=0.349531 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3864562511444092
[5/24] Train loss=0.37604084610939026
[10/24] Train loss=0.40402284264564514
[15/24] Train loss=0.3808862864971161
[20/24] Train loss=0.33419543504714966
Test set avg_accuracy=86.97% avg_sensitivity=67.37%, avg_specificity=93.55% avg_auc=91.45%
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.386829 Test loss=0.327522 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.37358006834983826
[5/24] Train loss=0.3604732155799866
[10/24] Train loss=0.38417214155197144
[15/24] Train loss=0.3633282482624054
[20/24] Train loss=0.3182726204395294
Test set avg_accuracy=87.03% avg_sensitivity=63.96%, avg_specificity=94.78% avg_auc=91.70%
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.372480 Test loss=0.318575 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3620989918708801
[5/24] Train loss=0.3477139472961426
[10/24] Train loss=0.37119951844215393
[15/24] Train loss=0.3556213974952698
[20/24] Train loss=0.30103036761283875
Test set avg_accuracy=86.18% avg_sensitivity=56.24%, avg_specificity=96.24% avg_auc=91.14%
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.358524 Test loss=0.329486 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3521159589290619
[5/24] Train loss=0.33114930987358093
[10/24] Train loss=0.3635782301425934
[15/24] Train loss=0.3454872965812683
[20/24] Train loss=0.2901308536529541
Test set avg_accuracy=86.07% avg_sensitivity=54.89%, avg_specificity=96.54% avg_auc=91.19%
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.348659 Test loss=0.330236 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3415631651878357
[5/24] Train loss=0.3263120949268341
[10/24] Train loss=0.3479040861129761
[15/24] Train loss=0.3402860164642334
[20/24] Train loss=0.28054946660995483
Test set avg_accuracy=84.79% avg_sensitivity=46.30%, avg_specificity=97.72% avg_auc=91.18%
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.339026 Test loss=0.344963 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.329267293214798
[5/24] Train loss=0.3142540752887726
[10/24] Train loss=0.3383362591266632
[15/24] Train loss=0.3303702771663666
[20/24] Train loss=0.27465516328811646
Test set avg_accuracy=86.39% avg_sensitivity=55.20%, avg_specificity=96.87% avg_auc=92.07%
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.329966 Test loss=0.318813 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.32718920707702637
[5/24] Train loss=0.3053956925868988
[10/24] Train loss=0.33364975452423096
[15/24] Train loss=0.3173205554485321
[20/24] Train loss=0.26598748564720154
Test set avg_accuracy=86.07% avg_sensitivity=52.51%, avg_specificity=97.34% avg_auc=92.16%
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.321987 Test loss=0.322465 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.32270658016204834
[5/24] Train loss=0.29773014783859253
[10/24] Train loss=0.3334895074367523
[15/24] Train loss=0.31129661202430725
[20/24] Train loss=0.2530995011329651
Test set avg_accuracy=87.62% avg_sensitivity=62.61%, avg_specificity=96.02% avg_auc=92.92%
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.315268 Test loss=0.294562 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.30399516224861145
[5/24] Train loss=0.28630608320236206
[10/24] Train loss=0.32079559564590454
[15/24] Train loss=0.3072153329849243
[20/24] Train loss=0.252348929643631
Test set avg_accuracy=88.42% avg_sensitivity=69.34%, avg_specificity=94.83% avg_auc=93.31%
Best model saved!! Metric=19.90959422371529!!
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.308655 Test loss=0.283855 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.30782172083854675
[5/24] Train loss=0.28200238943099976
[10/24] Train loss=0.31560903787612915
[15/24] Train loss=0.3009529709815979
[20/24] Train loss=0.2518511414527893
Test set avg_accuracy=88.29% avg_sensitivity=68.46%, avg_specificity=94.96% avg_auc=93.18%
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.303893 Test loss=0.285144 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.30778664350509644
[5/24] Train loss=0.27689775824546814
[10/24] Train loss=0.3171239495277405
[15/24] Train loss=0.29133474826812744
[20/24] Train loss=0.24009235203266144
Test set avg_accuracy=88.67% avg_sensitivity=69.65%, avg_specificity=95.06% avg_auc=93.19%
Best model saved!! Metric=20.570143665191935!!
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.299720 Test loss=0.285287 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2952302396297455
[5/24] Train loss=0.27398768067359924
[10/24] Train loss=0.3091431260108948
[15/24] Train loss=0.29680654406547546
[20/24] Train loss=0.23699311912059784
Test set avg_accuracy=86.47% avg_sensitivity=54.53%, avg_specificity=97.20% avg_auc=92.23%
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.292776 Test loss=0.313198 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.29639732837677
[5/24] Train loss=0.26135528087615967
[10/24] Train loss=0.29392144083976746
[15/24] Train loss=0.28739026188850403
[20/24] Train loss=0.2398601770401001
Test set avg_accuracy=86.84% avg_sensitivity=56.40%, avg_specificity=97.06% avg_auc=92.19%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.287747 Test loss=0.309233 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2892862558364868
[5/24] Train loss=0.25751549005508423
[10/24] Train loss=0.29461154341697693
[15/24] Train loss=0.27704036235809326
[20/24] Train loss=0.22552445530891418
Test set avg_accuracy=86.88% avg_sensitivity=57.43%, avg_specificity=96.76% avg_auc=91.81%
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.285916 Test loss=0.313047 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2925489842891693
[5/24] Train loss=0.25606638193130493
[10/24] Train loss=0.2963058650493622
[15/24] Train loss=0.2792893350124359
[20/24] Train loss=0.22656558454036713
Test set avg_accuracy=86.28% avg_sensitivity=53.03%, avg_specificity=97.44% avg_auc=91.97%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.282534 Test loss=0.319769 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2790992259979248
[5/24] Train loss=0.25366872549057007
[10/24] Train loss=0.29071351885795593
[15/24] Train loss=0.2749812602996826
[20/24] Train loss=0.22308696806430817
Test set avg_accuracy=87.89% avg_sensitivity=62.14%, avg_specificity=96.54% avg_auc=92.88%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.277408 Test loss=0.292896 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.27460357546806335
[5/24] Train loss=0.23969727754592896
[10/24] Train loss=0.28967317938804626
[15/24] Train loss=0.2738482356071472
[20/24] Train loss=0.22132645547389984
Test set avg_accuracy=85.96% avg_sensitivity=50.49%, avg_specificity=97.88% avg_auc=90.92%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.273359 Test loss=0.339137 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.27298209071159363
[5/24] Train loss=0.24266915023326874
[10/24] Train loss=0.28383657336235046
[15/24] Train loss=0.27380937337875366
[20/24] Train loss=0.21738068759441376
Test set avg_accuracy=87.86% avg_sensitivity=64.27%, avg_specificity=95.79% avg_auc=92.91%
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.272099 Test loss=0.288719 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.27577731013298035
[5/24] Train loss=0.2467660754919052
[10/24] Train loss=0.2730971872806549
[15/24] Train loss=0.2868848443031311
[20/24] Train loss=0.22246237099170685
Test set avg_accuracy=82.42% avg_sensitivity=33.61%, avg_specificity=98.82% avg_auc=89.93%
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.271181 Test loss=0.397920 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.27809983491897583
[5/24] Train loss=0.240895614027977
[10/24] Train loss=0.2836436629295349
[15/24] Train loss=0.27821487188339233
[20/24] Train loss=0.21900826692581177
Test set avg_accuracy=85.43% avg_sensitivity=47.95%, avg_specificity=98.02% avg_auc=91.12%
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.269304 Test loss=0.336178 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2751412093639374
[5/24] Train loss=0.24364806711673737
[10/24] Train loss=0.2805964946746826
[15/24] Train loss=0.2800754904747009
[20/24] Train loss=0.21346955001354218
Test set avg_accuracy=86.41% avg_sensitivity=54.63%, avg_specificity=97.08% avg_auc=91.52%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.270392 Test loss=0.321501 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2736548185348511
[5/24] Train loss=0.23410354554653168
[10/24] Train loss=0.27815911173820496
[15/24] Train loss=0.263744980096817
[20/24] Train loss=0.209885835647583
Test set avg_accuracy=87.08% avg_sensitivity=59.87%, avg_specificity=96.23% avg_auc=92.28%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.266419 Test loss=0.301772 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.27007830142974854
[5/24] Train loss=0.23398330807685852
[10/24] Train loss=0.2774891257286072
[15/24] Train loss=0.268143892288208
[20/24] Train loss=0.21255670487880707
Test set avg_accuracy=86.91% avg_sensitivity=60.07%, avg_specificity=95.93% avg_auc=91.73%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.267242 Test loss=0.309504 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2756264805793762
[5/24] Train loss=0.2392708957195282
[10/24] Train loss=0.26481860876083374
[15/24] Train loss=0.2698988616466522
[20/24] Train loss=0.2120133489370346
Test set avg_accuracy=87.79% avg_sensitivity=63.39%, avg_specificity=95.98% avg_auc=92.93%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.265253 Test loss=0.287448 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.26196926832199097
[5/24] Train loss=0.24985486268997192
[10/24] Train loss=0.26606351137161255
[15/24] Train loss=0.2684483230113983
[20/24] Train loss=0.21004259586334229
Test set avg_accuracy=84.77% avg_sensitivity=45.47%, avg_specificity=97.96% avg_auc=88.66%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.260855 Test loss=0.388726 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2685888409614563
[5/24] Train loss=0.21851478517055511
[10/24] Train loss=0.2601143419742584
[15/24] Train loss=0.2719973921775818
[20/24] Train loss=0.20370984077453613
Test set avg_accuracy=87.30% avg_sensitivity=58.88%, avg_specificity=96.85% avg_auc=92.31%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.259459 Test loss=0.305497 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.25590580701828003
[5/24] Train loss=0.23564410209655762
[10/24] Train loss=0.26169365644454956
[15/24] Train loss=0.2608414590358734
[20/24] Train loss=0.20572686195373535
Test set avg_accuracy=86.89% avg_sensitivity=56.55%, avg_specificity=97.08% avg_auc=89.61%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.258701 Test loss=0.338083 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2593942880630493
[5/24] Train loss=0.22674861550331116
[10/24] Train loss=0.26748284697532654
[15/24] Train loss=0.2762617766857147
[20/24] Train loss=0.2132135033607483
Test set avg_accuracy=86.58% avg_sensitivity=54.95%, avg_specificity=97.20% avg_auc=90.60%
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.259028 Test loss=0.326809 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2721012830734253
[5/24] Train loss=0.2426297962665558
[10/24] Train loss=0.2692955732345581
[15/24] Train loss=0.2609093487262726
[20/24] Train loss=0.2050056904554367
Test set avg_accuracy=84.32% avg_sensitivity=42.78%, avg_specificity=98.28% avg_auc=88.73%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.262403 Test loss=0.388173 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.26796483993530273
[5/24] Train loss=0.23546013236045837
[10/24] Train loss=0.26279217004776
[15/24] Train loss=0.270818293094635
[20/24] Train loss=0.20473849773406982
Test set avg_accuracy=87.15% avg_sensitivity=59.30%, avg_specificity=96.50% avg_auc=92.00%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.254429 Test loss=0.305502 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2626681923866272
[5/24] Train loss=0.22232237458229065
[10/24] Train loss=0.2624211609363556
[15/24] Train loss=0.2670120596885681
[20/24] Train loss=0.21057340502738953
Test set avg_accuracy=87.54% avg_sensitivity=63.28%, avg_specificity=95.69% avg_auc=91.90%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.254722 Test loss=0.303395 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.25700512528419495
[5/24] Train loss=0.22006238996982574
[10/24] Train loss=0.2462044656276703
[15/24] Train loss=0.26037439703941345
[20/24] Train loss=0.20567871630191803
Test set avg_accuracy=87.49% avg_sensitivity=65.82%, avg_specificity=94.76% avg_auc=92.14%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.250952 Test loss=0.296033 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2706187963485718
[5/24] Train loss=0.2280230075120926
[10/24] Train loss=0.24142953753471375
[15/24] Train loss=0.253479540348053
[20/24] Train loss=0.2079433798789978
Test set avg_accuracy=87.12% avg_sensitivity=61.89%, avg_specificity=95.60% avg_auc=91.69%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.251014 Test loss=0.310071 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2615382671356201
[5/24] Train loss=0.21949231624603271
[10/24] Train loss=0.24939016997814178
[15/24] Train loss=0.2599217891693115
[20/24] Train loss=0.19848623871803284
Test set avg_accuracy=85.26% avg_sensitivity=49.72%, avg_specificity=97.20% avg_auc=90.84%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.252776 Test loss=0.351154 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.24808523058891296
[5/24] Train loss=0.21391737461090088
[10/24] Train loss=0.2426833212375641
[15/24] Train loss=0.2530617117881775
[20/24] Train loss=0.20220938324928284
Test set avg_accuracy=79.51% avg_sensitivity=20.04%, avg_specificity=99.48% avg_auc=83.62%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.248477 Test loss=0.533456 Current lr=[0.000298904600941902]

[0/24] Train loss=0.27054500579833984
[5/24] Train loss=0.21370819211006165
[10/24] Train loss=0.24850846827030182
[15/24] Train loss=0.24399909377098083
[20/24] Train loss=0.20343022048473358
Test set avg_accuracy=85.22% avg_sensitivity=48.99%, avg_specificity=97.39% avg_auc=89.97%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.249950 Test loss=0.358489 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2507025897502899
[5/24] Train loss=0.22866378724575043
[10/24] Train loss=0.2508796751499176
[15/24] Train loss=0.2584793269634247
[20/24] Train loss=0.20008669793605804
Test set avg_accuracy=87.98% avg_sensitivity=67.06%, avg_specificity=95.01% avg_auc=91.89%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.249953 Test loss=0.294792 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2535712718963623
[5/24] Train loss=0.2140708714723587
[10/24] Train loss=0.2469504177570343
[15/24] Train loss=0.26130953431129456
[20/24] Train loss=0.20285047590732574
Test set avg_accuracy=88.18% avg_sensitivity=76.54%, avg_specificity=92.09% avg_auc=92.78%
Best model saved!! Metric=23.585876288476783!!
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.249438 Test loss=0.291483 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.25550228357315063
[5/24] Train loss=0.2198779582977295
[10/24] Train loss=0.2598094940185547
[15/24] Train loss=0.2414938062429428
[20/24] Train loss=0.20947450399398804
Test set avg_accuracy=87.51% avg_sensitivity=65.87%, avg_specificity=94.78% avg_auc=92.08%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.248213 Test loss=0.296581 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2534320652484894
[5/24] Train loss=0.2090741991996765
[10/24] Train loss=0.24900731444358826
[15/24] Train loss=0.24523015320301056
[20/24] Train loss=0.2041412740945816
Test set avg_accuracy=85.52% avg_sensitivity=52.05%, avg_specificity=96.76% avg_auc=87.75%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.241412 Test loss=0.374774 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.23833885788917542
[5/24] Train loss=0.2180345505475998
[10/24] Train loss=0.23999649286270142
[15/24] Train loss=0.2523402273654938
[20/24] Train loss=0.20865470170974731
Test set avg_accuracy=87.75% avg_sensitivity=68.10%, avg_specificity=94.35% avg_auc=91.83%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.244195 Test loss=0.299988 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2484399825334549
[5/24] Train loss=0.2156665325164795
[10/24] Train loss=0.24477919936180115
[15/24] Train loss=0.23490563035011292
[20/24] Train loss=0.19577902555465698
Test set avg_accuracy=87.81% avg_sensitivity=67.01%, avg_specificity=94.80% avg_auc=91.59%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.241627 Test loss=0.298210 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.24535104632377625
[5/24] Train loss=0.2196309119462967
[10/24] Train loss=0.23315782845020294
[15/24] Train loss=0.24023666977882385
[20/24] Train loss=0.19310176372528076
Test set avg_accuracy=86.90% avg_sensitivity=68.72%, avg_specificity=93.01% avg_auc=91.01%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.238406 Test loss=0.317607 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.24360762536525726
[5/24] Train loss=0.21191416680812836
[10/24] Train loss=0.2444320023059845
[15/24] Train loss=0.24046200513839722
[20/24] Train loss=0.20692887902259827
Test set avg_accuracy=85.85% avg_sensitivity=67.58%, avg_specificity=91.98% avg_auc=90.11%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.241339 Test loss=0.328887 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.24551793932914734
[5/24] Train loss=0.21631118655204773
[10/24] Train loss=0.2353372573852539
[15/24] Train loss=0.23743624985218048
[20/24] Train loss=0.18929997086524963
Test set avg_accuracy=86.32% avg_sensitivity=58.47%, avg_specificity=95.67% avg_auc=90.44%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.240430 Test loss=0.326345 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.22810129821300507
[5/24] Train loss=0.20629584789276123
[10/24] Train loss=0.2365448772907257
[15/24] Train loss=0.2377886027097702
[20/24] Train loss=0.19538617134094238
Test set avg_accuracy=87.70% avg_sensitivity=71.00%, avg_specificity=93.30% avg_auc=92.21%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.240265 Test loss=0.296585 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.23835301399230957
[5/24] Train loss=0.20807693898677826
[10/24] Train loss=0.2428683042526245
[15/24] Train loss=0.24577803909778595
[20/24] Train loss=0.1980811506509781
Test set avg_accuracy=85.77% avg_sensitivity=74.00%, avg_specificity=89.72% avg_auc=90.34%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.235362 Test loss=0.336234 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.23156744241714478
[5/24] Train loss=0.2143278568983078
[10/24] Train loss=0.2339586764574051
[15/24] Train loss=0.2312719076871872
[20/24] Train loss=0.18876484036445618
Test set avg_accuracy=88.66% avg_sensitivity=75.35%, avg_specificity=93.13% avg_auc=92.94%
Best model saved!! Metric=24.07711446528525!!
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.233660 Test loss=0.283748 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.22980855405330658
[5/24] Train loss=0.2023138403892517
[10/24] Train loss=0.21938252449035645
[15/24] Train loss=0.24053171277046204
[20/24] Train loss=0.19600720703601837
Test set avg_accuracy=87.68% avg_sensitivity=68.67%, avg_specificity=94.07% avg_auc=91.42%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.232265 Test loss=0.305774 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2336970418691635
[5/24] Train loss=0.19955432415008545
[10/24] Train loss=0.22342126071453094
[15/24] Train loss=0.237811878323555
[20/24] Train loss=0.18717657029628754
Test set avg_accuracy=86.95% avg_sensitivity=63.13%, avg_specificity=94.96% avg_auc=90.69%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.231188 Test loss=0.319235 Current lr=[0.000276307469034998]

[0/24] Train loss=0.25179147720336914
[5/24] Train loss=0.20300686359405518
[10/24] Train loss=0.22123834490776062
[15/24] Train loss=0.24233774840831757
[20/24] Train loss=0.18353500962257385
Test set avg_accuracy=86.78% avg_sensitivity=77.01%, avg_specificity=90.07% avg_auc=91.93%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.231539 Test loss=0.313770 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.2242797613143921
[5/24] Train loss=0.19999460875988007
[10/24] Train loss=0.23138873279094696
[15/24] Train loss=0.23461784422397614
[20/24] Train loss=0.18903136253356934
Test set avg_accuracy=86.86% avg_sensitivity=71.62%, avg_specificity=91.98% avg_auc=91.81%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.227375 Test loss=0.307294 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.22641988098621368
[5/24] Train loss=0.1943110078573227
[10/24] Train loss=0.2256951481103897
[15/24] Train loss=0.22684286534786224
[20/24] Train loss=0.1866319626569748
Test set avg_accuracy=87.70% avg_sensitivity=69.81%, avg_specificity=93.70% avg_auc=91.40%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.224926 Test loss=0.308429 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.22724203765392303
[5/24] Train loss=0.21122634410858154
[10/24] Train loss=0.22110256552696228
[15/24] Train loss=0.24058851599693298
[20/24] Train loss=0.19484440982341766
Test set avg_accuracy=87.92% avg_sensitivity=69.55%, avg_specificity=94.09% avg_auc=91.67%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.228423 Test loss=0.306507 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.22817641496658325
[5/24] Train loss=0.20655710995197296
[10/24] Train loss=0.2166389375925064
[15/24] Train loss=0.22341668605804443
[20/24] Train loss=0.18939822912216187
Test set avg_accuracy=87.81% avg_sensitivity=65.35%, avg_specificity=95.36% avg_auc=91.05%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.224519 Test loss=0.309049 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.22136810421943665
[5/24] Train loss=0.19834807515144348
[10/24] Train loss=0.2178170382976532
[15/24] Train loss=0.2306566685438156
[20/24] Train loss=0.1936137080192566
Test set avg_accuracy=88.54% avg_sensitivity=76.59%, avg_specificity=92.56% avg_auc=93.30%
Best model saved!! Metric=24.991137761047426!!
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.227555 Test loss=0.276169 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.22355127334594727
[5/24] Train loss=0.20133021473884583
[10/24] Train loss=0.23268990218639374
[15/24] Train loss=0.2392938882112503
[20/24] Train loss=0.18656735122203827
Test set avg_accuracy=87.30% avg_sensitivity=66.60%, avg_specificity=94.26% avg_auc=91.49%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.228258 Test loss=0.307014 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.23101197183132172
[5/24] Train loss=0.1986074596643448
[10/24] Train loss=0.21718372404575348
[15/24] Train loss=0.22212234139442444
[20/24] Train loss=0.1855943500995636
Test set avg_accuracy=86.20% avg_sensitivity=78.51%, avg_specificity=88.78% avg_auc=91.63%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.226365 Test loss=0.318982 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2355746328830719
[5/24] Train loss=0.20012420415878296
[10/24] Train loss=0.22341585159301758
[15/24] Train loss=0.22145168483257294
[20/24] Train loss=0.18575136363506317
Test set avg_accuracy=87.66% avg_sensitivity=68.51%, avg_specificity=94.09% avg_auc=92.15%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.224973 Test loss=0.298643 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.21387314796447754
[5/24] Train loss=0.1978648602962494
[10/24] Train loss=0.22324207425117493
[15/24] Train loss=0.2270384579896927
[20/24] Train loss=0.1860083043575287
Test set avg_accuracy=87.64% avg_sensitivity=65.04%, avg_specificity=95.23% avg_auc=92.23%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.222082 Test loss=0.297494 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.2199942171573639
[5/24] Train loss=0.20529592037200928
[10/24] Train loss=0.22445783019065857
[15/24] Train loss=0.22881175577640533
[20/24] Train loss=0.18462862074375153
Test set avg_accuracy=86.97% avg_sensitivity=79.13%, avg_specificity=89.60% avg_auc=92.59%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.229684 Test loss=0.307365 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.22594977915287018
[5/24] Train loss=0.2015552818775177
[10/24] Train loss=0.2150573581457138
[15/24] Train loss=0.2073390632867813
[20/24] Train loss=0.18013417720794678
Test set avg_accuracy=86.02% avg_sensitivity=80.48%, avg_specificity=87.88% avg_auc=91.76%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.220890 Test loss=0.325971 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.22354121506214142
[5/24] Train loss=0.20343482494354248
[10/24] Train loss=0.23401007056236267
[15/24] Train loss=0.21300722658634186
[20/24] Train loss=0.18592065572738647
Test set avg_accuracy=88.15% avg_sensitivity=76.85%, avg_specificity=91.95% avg_auc=92.23%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.220398 Test loss=0.298549 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.22147415578365326
[5/24] Train loss=0.19605496525764465
[10/24] Train loss=0.21433700621128082
[15/24] Train loss=0.2217726856470108
[20/24] Train loss=0.18828311562538147
Test set avg_accuracy=87.43% avg_sensitivity=76.44%, avg_specificity=91.13% avg_auc=92.29%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.217966 Test loss=0.304764 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.22353647649288177
[5/24] Train loss=0.1840866208076477
[10/24] Train loss=0.20836231112480164
[15/24] Train loss=0.2104208767414093
[20/24] Train loss=0.1787126064300537
Test set avg_accuracy=86.80% avg_sensitivity=79.85%, avg_specificity=89.13% avg_auc=92.12%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.215766 Test loss=0.318711 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.21341802179813385
[5/24] Train loss=0.18295007944107056
[10/24] Train loss=0.20239169895648956
[15/24] Train loss=0.21987062692642212
[20/24] Train loss=0.18863095343112946
Test set avg_accuracy=84.34% avg_sensitivity=81.77%, avg_specificity=85.20% avg_auc=91.11%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.215688 Test loss=0.358315 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2178965061903
[5/24] Train loss=0.17892631888389587
[10/24] Train loss=0.2080327421426773
[15/24] Train loss=0.21334613859653473
[20/24] Train loss=0.1733127385377884
Test set avg_accuracy=86.97% avg_sensitivity=71.05%, avg_specificity=92.31% avg_auc=91.20%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.215106 Test loss=0.318222 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.21392518281936646
[5/24] Train loss=0.1981019228696823
[10/24] Train loss=0.22642847895622253
[15/24] Train loss=0.21139158308506012
[20/24] Train loss=0.17791922390460968
Test set avg_accuracy=86.15% avg_sensitivity=71.05%, avg_specificity=91.22% avg_auc=90.61%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.217239 Test loss=0.326174 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2131049484014511
[5/24] Train loss=0.19183222949504852
[10/24] Train loss=0.20704351365566254
[15/24] Train loss=0.20297221839427948
[20/24] Train loss=0.183241605758667
Test set avg_accuracy=87.84% avg_sensitivity=76.75%, avg_specificity=91.56% avg_auc=92.48%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.215265 Test loss=0.295475 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.20577411353588104
[5/24] Train loss=0.18789266049861908
[10/24] Train loss=0.207168847322464
[15/24] Train loss=0.21022865176200867
[20/24] Train loss=0.17337456345558167
Test set avg_accuracy=87.47% avg_sensitivity=68.93%, avg_specificity=93.70% avg_auc=91.59%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.212289 Test loss=0.302903 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.20382216572761536
[5/24] Train loss=0.18574760854244232
[10/24] Train loss=0.1950886845588684
[15/24] Train loss=0.19975554943084717
[20/24] Train loss=0.1727725714445114
Test set avg_accuracy=87.53% avg_sensitivity=73.74%, avg_specificity=92.16% avg_auc=91.45%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.205665 Test loss=0.308628 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.20675262808799744
[5/24] Train loss=0.1766434609889984
[10/24] Train loss=0.20806884765625
[15/24] Train loss=0.20647311210632324
[20/24] Train loss=0.18031074106693268
Test set avg_accuracy=87.45% avg_sensitivity=70.59%, avg_specificity=93.11% avg_auc=90.69%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.207927 Test loss=0.316723 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.20309773087501526
[5/24] Train loss=0.19068658351898193
[10/24] Train loss=0.20040066540241241
[15/24] Train loss=0.19613498449325562
[20/24] Train loss=0.17703425884246826
Test set avg_accuracy=86.03% avg_sensitivity=57.48%, avg_specificity=95.62% avg_auc=88.40%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.206614 Test loss=0.347035 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2080485075712204
[5/24] Train loss=0.18315544724464417
[10/24] Train loss=0.2138424664735794
[15/24] Train loss=0.20387135446071625
[20/24] Train loss=0.1614924967288971
Test set avg_accuracy=87.43% avg_sensitivity=68.10%, avg_specificity=93.93% avg_auc=89.96%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.206256 Test loss=0.320666 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.20334914326667786
[5/24] Train loss=0.17822858691215515
[10/24] Train loss=0.20100592076778412
[15/24] Train loss=0.1952887773513794
[20/24] Train loss=0.1678100973367691
Test set avg_accuracy=86.37% avg_sensitivity=58.57%, avg_specificity=95.70% avg_auc=86.98%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.201954 Test loss=0.360016 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.20603397488594055
[5/24] Train loss=0.18057219684123993
[10/24] Train loss=0.19015629589557648
[15/24] Train loss=0.19616557657718658
[20/24] Train loss=0.16794434189796448
Test set avg_accuracy=88.15% avg_sensitivity=67.12%, avg_specificity=95.22% avg_auc=90.79%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.198905 Test loss=0.308646 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.20121438801288605
[5/24] Train loss=0.17084892094135284
[10/24] Train loss=0.19976744055747986
[15/24] Train loss=0.19170863926410675
[20/24] Train loss=0.17187845706939697
Test set avg_accuracy=88.32% avg_sensitivity=75.04%, avg_specificity=92.78% avg_auc=91.71%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.200648 Test loss=0.301296 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.20173627138137817
[5/24] Train loss=0.18384991586208344
[10/24] Train loss=0.19567649066448212
[15/24] Train loss=0.19627390801906586
[20/24] Train loss=0.1725391149520874
Test set avg_accuracy=87.15% avg_sensitivity=67.32%, avg_specificity=93.81% avg_auc=91.43%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.201793 Test loss=0.311638 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.19532513618469238
[5/24] Train loss=0.1820213794708252
[10/24] Train loss=0.20559605956077576
[15/24] Train loss=0.20540474355220795
[20/24] Train loss=0.16666002571582794
Test set avg_accuracy=86.90% avg_sensitivity=62.82%, avg_specificity=94.99% avg_auc=89.57%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.202210 Test loss=0.330335 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2146475911140442
[5/24] Train loss=0.17705179750919342
[10/24] Train loss=0.19695651531219482
[15/24] Train loss=0.19946442544460297
[20/24] Train loss=0.17028746008872986
Test set avg_accuracy=86.51% avg_sensitivity=58.10%, avg_specificity=96.05% avg_auc=88.21%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.200966 Test loss=0.365426 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.19836610555648804
[5/24] Train loss=0.1826358586549759
[10/24] Train loss=0.1929616928100586
[15/24] Train loss=0.20051071047782898
[20/24] Train loss=0.16250266134738922
Test set avg_accuracy=85.90% avg_sensitivity=57.59%, avg_specificity=95.41% avg_auc=86.74%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.199643 Test loss=0.368809 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.200632706284523
[5/24] Train loss=0.17260362207889557
[10/24] Train loss=0.18450522422790527
[15/24] Train loss=0.18791702389717102
[20/24] Train loss=0.1654895544052124
Test set avg_accuracy=86.29% avg_sensitivity=63.96%, avg_specificity=93.79% avg_auc=88.88%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.191221 Test loss=0.338506 Current lr=[0.000156543481933168]

[0/24] Train loss=0.1963178962469101
[5/24] Train loss=0.18271663784980774
[10/24] Train loss=0.18300223350524902
[15/24] Train loss=0.18466386198997498
[20/24] Train loss=0.1591005176305771
Test set avg_accuracy=88.07% avg_sensitivity=73.02%, avg_specificity=93.13% avg_auc=92.30%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.191906 Test loss=0.293984 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.19129492342472076
[5/24] Train loss=0.18038906157016754
[10/24] Train loss=0.19445912539958954
[15/24] Train loss=0.18176035583019257
[20/24] Train loss=0.1630999594926834
Test set avg_accuracy=87.34% avg_sensitivity=67.58%, avg_specificity=93.98% avg_auc=90.24%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.189040 Test loss=0.321164 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.18217672407627106
[5/24] Train loss=0.17732620239257812
[10/24] Train loss=0.1757224202156067
[15/24] Train loss=0.1875089704990387
[20/24] Train loss=0.1661473959684372
Test set avg_accuracy=85.51% avg_sensitivity=71.31%, avg_specificity=90.28% avg_auc=89.11%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.190037 Test loss=0.352307 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.19233161211013794
[5/24] Train loss=0.16671591997146606
[10/24] Train loss=0.18028849363327026
[15/24] Train loss=0.18208058178424835
[20/24] Train loss=0.1573355793952942
Test set avg_accuracy=86.54% avg_sensitivity=68.77%, avg_specificity=92.50% avg_auc=89.69%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.186784 Test loss=0.333772 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.18032917380332947
[5/24] Train loss=0.18458977341651917
[10/24] Train loss=0.18298117816448212
[15/24] Train loss=0.19585688412189484
[20/24] Train loss=0.1558387130498886
Test set avg_accuracy=86.58% avg_sensitivity=67.63%, avg_specificity=92.94% avg_auc=89.48%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.185327 Test loss=0.336670 Current lr=[0.000134135431043539]

[0/24] Train loss=0.19504527747631073
[5/24] Train loss=0.16808795928955078
[10/24] Train loss=0.17894291877746582
[15/24] Train loss=0.1748102903366089
[20/24] Train loss=0.1564309149980545
Test set avg_accuracy=86.99% avg_sensitivity=67.43%, avg_specificity=93.56% avg_auc=89.61%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.184693 Test loss=0.333035 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.18772126734256744
[5/24] Train loss=0.16937842965126038
[10/24] Train loss=0.18314911425113678
[15/24] Train loss=0.18966524302959442
[20/24] Train loss=0.1570833921432495
Test set avg_accuracy=87.97% avg_sensitivity=71.21%, avg_specificity=93.60% avg_auc=90.89%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.180597 Test loss=0.314065 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1789391189813614
[5/24] Train loss=0.1635245531797409
[10/24] Train loss=0.17227959632873535
[15/24] Train loss=0.17264194786548615
[20/24] Train loss=0.15856806933879852
Test set avg_accuracy=87.41% avg_sensitivity=67.79%, avg_specificity=94.00% avg_auc=88.35%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.177813 Test loss=0.337842 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.17592743039131165
[5/24] Train loss=0.15772460401058197
[10/24] Train loss=0.1678847074508667
[15/24] Train loss=0.17186236381530762
[20/24] Train loss=0.15155623853206635
Test set avg_accuracy=87.90% avg_sensitivity=71.57%, avg_specificity=93.39% avg_auc=90.75%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.174422 Test loss=0.314905 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1762300729751587
[5/24] Train loss=0.15732938051223755
[10/24] Train loss=0.16603980958461761
[15/24] Train loss=0.17088583111763
[20/24] Train loss=0.15404708683490753
Test set avg_accuracy=87.94% avg_sensitivity=71.21%, avg_specificity=93.56% avg_auc=90.61%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.174177 Test loss=0.318384 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16815240681171417
[5/24] Train loss=0.15941770374774933
[10/24] Train loss=0.16630516946315765
[15/24] Train loss=0.16599136590957642
[20/24] Train loss=0.153667613863945
Test set avg_accuracy=86.98% avg_sensitivity=72.92%, avg_specificity=91.70% avg_auc=90.78%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.171397 Test loss=0.323758 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.16946345567703247
[5/24] Train loss=0.15561875700950623
[10/24] Train loss=0.16770963370800018
[15/24] Train loss=0.16322746872901917
[20/24] Train loss=0.1520189344882965
Test set avg_accuracy=87.62% avg_sensitivity=70.95%, avg_specificity=93.22% avg_auc=91.46%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.170187 Test loss=0.313385 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.17274892330169678
[5/24] Train loss=0.15872058272361755
[10/24] Train loss=0.16030451655387878
[15/24] Train loss=0.17452304065227509
[20/24] Train loss=0.14901190996170044
Test set avg_accuracy=87.89% avg_sensitivity=70.74%, avg_specificity=93.65% avg_auc=91.12%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.168940 Test loss=0.310281 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.16504618525505066
[5/24] Train loss=0.15353423357009888
[10/24] Train loss=0.161490797996521
[15/24] Train loss=0.16231705248355865
[20/24] Train loss=0.15509004890918732
Test set avg_accuracy=87.67% avg_sensitivity=74.05%, avg_specificity=92.24% avg_auc=91.65%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.167248 Test loss=0.308219 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.16639494895935059
[5/24] Train loss=0.15841935575008392
[10/24] Train loss=0.15832418203353882
[15/24] Train loss=0.1631929874420166
[20/24] Train loss=0.15685123205184937
Test set avg_accuracy=88.33% avg_sensitivity=75.87%, avg_specificity=92.52% avg_auc=92.14%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.166859 Test loss=0.301355 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1696808934211731
[5/24] Train loss=0.15428341925144196
[10/24] Train loss=0.15713901817798615
[15/24] Train loss=0.1622290313243866
[20/24] Train loss=0.1469910442829132
Test set avg_accuracy=87.98% avg_sensitivity=74.94%, avg_specificity=92.36% avg_auc=91.78%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.166217 Test loss=0.305305 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.17387127876281738
[5/24] Train loss=0.15314239263534546
[10/24] Train loss=0.15887993574142456
[15/24] Train loss=0.16317154467105865
[20/24] Train loss=0.14751282334327698
Test set avg_accuracy=87.67% avg_sensitivity=76.64%, avg_specificity=91.37% avg_auc=91.86%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.164379 Test loss=0.310930 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.16837748885154724
[5/24] Train loss=0.1566232442855835
[10/24] Train loss=0.1566108912229538
[15/24] Train loss=0.1632853001356125
[20/24] Train loss=0.14967992901802063
Test set avg_accuracy=88.12% avg_sensitivity=72.97%, avg_specificity=93.22% avg_auc=90.94%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.165256 Test loss=0.312894 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.16534027457237244
[5/24] Train loss=0.15289942920207977
[10/24] Train loss=0.1612912118434906
[15/24] Train loss=0.16039861738681793
[20/24] Train loss=0.1423606276512146
Test set avg_accuracy=86.46% avg_sensitivity=76.75%, avg_specificity=89.72% avg_auc=91.19%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.162580 Test loss=0.334003 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1624893844127655
[5/24] Train loss=0.1526375561952591
[10/24] Train loss=0.1536148339509964
[15/24] Train loss=0.1592966765165329
[20/24] Train loss=0.1426478773355484
Test set avg_accuracy=86.82% avg_sensitivity=73.69%, avg_specificity=91.23% avg_auc=91.14%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.160886 Test loss=0.324719 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.15925371646881104
[5/24] Train loss=0.15431179106235504
[10/24] Train loss=0.1502663642168045
[15/24] Train loss=0.16249942779541016
[20/24] Train loss=0.14043134450912476
Test set avg_accuracy=87.25% avg_sensitivity=73.95%, avg_specificity=91.72% avg_auc=90.87%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.159337 Test loss=0.321438 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.16451026499271393
[5/24] Train loss=0.15090411901474
[10/24] Train loss=0.15155185759067535
[15/24] Train loss=0.15523475408554077
[20/24] Train loss=0.14003680646419525
Test set avg_accuracy=87.76% avg_sensitivity=71.15%, avg_specificity=93.34% avg_auc=90.71%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.157493 Test loss=0.315296 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.15823404490947723
[5/24] Train loss=0.14467497169971466
[10/24] Train loss=0.14533282816410065
[15/24] Train loss=0.15192817151546478
[20/24] Train loss=0.13614098727703094
Test set avg_accuracy=87.96% avg_sensitivity=70.27%, avg_specificity=93.89% avg_auc=90.64%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.153975 Test loss=0.314953 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1514352411031723
[5/24] Train loss=0.14109987020492554
[10/24] Train loss=0.14691582322120667
[15/24] Train loss=0.1461986005306244
[20/24] Train loss=0.13468880951404572
Test set avg_accuracy=87.90% avg_sensitivity=72.40%, avg_specificity=93.11% avg_auc=91.63%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.151652 Test loss=0.302768 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1544664204120636
[5/24] Train loss=0.14234456419944763
[10/24] Train loss=0.14504636824131012
[15/24] Train loss=0.14616864919662476
[20/24] Train loss=0.13092873990535736
Test set avg_accuracy=88.02% avg_sensitivity=71.47%, avg_specificity=93.58% avg_auc=91.20%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.149378 Test loss=0.306432 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.14997167885303497
[5/24] Train loss=0.1373465657234192
[10/24] Train loss=0.14182019233703613
[15/24] Train loss=0.14183171093463898
[20/24] Train loss=0.1291416585445404
Test set avg_accuracy=87.93% avg_sensitivity=71.62%, avg_specificity=93.41% avg_auc=91.51%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.147506 Test loss=0.305527 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14814554154872894
[5/24] Train loss=0.13819876313209534
[10/24] Train loss=0.14731580018997192
[15/24] Train loss=0.14357134699821472
[20/24] Train loss=0.12756067514419556
Test set avg_accuracy=88.15% avg_sensitivity=73.54%, avg_specificity=93.06% avg_auc=91.51%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.146399 Test loss=0.301890 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1485186219215393
[5/24] Train loss=0.13605204224586487
[10/24] Train loss=0.14305706322193146
[15/24] Train loss=0.1427127867937088
[20/24] Train loss=0.12819525599479675
Test set avg_accuracy=88.10% avg_sensitivity=71.26%, avg_specificity=93.76% avg_auc=90.58%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.145184 Test loss=0.314089 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1463286429643631
[5/24] Train loss=0.13894732296466827
[10/24] Train loss=0.1389293521642685
[15/24] Train loss=0.142544686794281
[20/24] Train loss=0.12993676960468292
Test set avg_accuracy=88.59% avg_sensitivity=75.40%, avg_specificity=93.02% avg_auc=91.39%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.143585 Test loss=0.304071 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1432162970304489
[5/24] Train loss=0.13546371459960938
[10/24] Train loss=0.13892976939678192
[15/24] Train loss=0.13970598578453064
[20/24] Train loss=0.12650126218795776
Test set avg_accuracy=87.81% avg_sensitivity=71.36%, avg_specificity=93.34% avg_auc=90.41%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.142636 Test loss=0.317146 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1472354382276535
[5/24] Train loss=0.13622818887233734
[10/24] Train loss=0.13790014386177063
[15/24] Train loss=0.13819822669029236
[20/24] Train loss=0.12896989285945892
Test set avg_accuracy=87.99% avg_sensitivity=73.54%, avg_specificity=92.85% avg_auc=91.32%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.142845 Test loss=0.309303 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.14526237547397614
[5/24] Train loss=0.135732501745224
[10/24] Train loss=0.13826094567775726
[15/24] Train loss=0.13776977360248566
[20/24] Train loss=0.1306144744157791
Test set avg_accuracy=87.58% avg_sensitivity=74.73%, avg_specificity=91.89% avg_auc=91.01%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.142320 Test loss=0.314169 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1423499882221222
[5/24] Train loss=0.13421383500099182
[10/24] Train loss=0.13635671138763428
[15/24] Train loss=0.1367388814687729
[20/24] Train loss=0.1266586035490036
Test set avg_accuracy=87.76% avg_sensitivity=75.14%, avg_specificity=92.00% avg_auc=91.15%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.140885 Test loss=0.312018 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.14321225881576538
[5/24] Train loss=0.13207049667835236
[10/24] Train loss=0.138994038105011
[15/24] Train loss=0.1359909474849701
[20/24] Train loss=0.12537211179733276
Test set avg_accuracy=87.79% avg_sensitivity=73.95%, avg_specificity=92.43% avg_auc=90.64%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.140153 Test loss=0.316397 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.14227339625358582
[5/24] Train loss=0.13462768495082855
[10/24] Train loss=0.1360585242509842
[15/24] Train loss=0.13647913932800293
[20/24] Train loss=0.1228499636054039
Test set avg_accuracy=88.01% avg_sensitivity=73.43%, avg_specificity=92.90% avg_auc=91.00%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.139107 Test loss=0.310803 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.14171536266803741
[5/24] Train loss=0.1281587928533554
[10/24] Train loss=0.1360846310853958
[15/24] Train loss=0.13467086851596832
[20/24] Train loss=0.12117002159357071
Test set avg_accuracy=87.73% avg_sensitivity=73.28%, avg_specificity=92.59% avg_auc=91.17%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.138236 Test loss=0.310318 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13961033523082733
[5/24] Train loss=0.13054253160953522
[10/24] Train loss=0.13249169290065765
[15/24] Train loss=0.13612961769104004
[20/24] Train loss=0.12155488133430481
Test set avg_accuracy=87.77% avg_sensitivity=73.59%, avg_specificity=92.54% avg_auc=90.97%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.137538 Test loss=0.315302 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.14447136223316193
[5/24] Train loss=0.12752097845077515
[10/24] Train loss=0.13305193185806274
[15/24] Train loss=0.1331874579191208
[20/24] Train loss=0.1202603280544281
Test set avg_accuracy=87.96% avg_sensitivity=74.57%, avg_specificity=92.45% avg_auc=91.39%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.136954 Test loss=0.308070 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13860222697257996
[5/24] Train loss=0.12843163311481476
[10/24] Train loss=0.12949241697788239
[15/24] Train loss=0.13340482115745544
[20/24] Train loss=0.11904192715883255
Test set avg_accuracy=87.72% avg_sensitivity=72.97%, avg_specificity=92.68% avg_auc=90.83%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.135939 Test loss=0.316225 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13829760253429413
[5/24] Train loss=0.12714655697345734
[10/24] Train loss=0.1331002563238144
[15/24] Train loss=0.1321427822113037
[20/24] Train loss=0.11996807157993317
Test set avg_accuracy=87.76% avg_sensitivity=73.28%, avg_specificity=92.62% avg_auc=91.20%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.135449 Test loss=0.311182 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.13802500069141388
[5/24] Train loss=0.1271863877773285
[10/24] Train loss=0.1298677921295166
[15/24] Train loss=0.13180725276470184
[20/24] Train loss=0.12044277787208557
Test set avg_accuracy=87.66% avg_sensitivity=73.07%, avg_specificity=92.56% avg_auc=91.26%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.134366 Test loss=0.310317 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13819752633571625
[5/24] Train loss=0.12615962326526642
[10/24] Train loss=0.12951776385307312
[15/24] Train loss=0.13054358959197998
[20/24] Train loss=0.1195615604519844
Test set avg_accuracy=87.72% avg_sensitivity=72.92%, avg_specificity=92.69% avg_auc=91.31%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.134426 Test loss=0.310972 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.136842280626297
[5/24] Train loss=0.12775784730911255
[10/24] Train loss=0.13042649626731873
[15/24] Train loss=0.13322265446186066
[20/24] Train loss=0.11866253614425659
Test set avg_accuracy=87.90% avg_sensitivity=73.69%, avg_specificity=92.68% avg_auc=91.40%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.134139 Test loss=0.308382 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13414034247398376
[5/24] Train loss=0.1263720542192459
[10/24] Train loss=0.13155597448349
[15/24] Train loss=0.1304241269826889
[20/24] Train loss=0.12013234198093414
Test set avg_accuracy=87.83% avg_sensitivity=73.07%, avg_specificity=92.78% avg_auc=91.36%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.133782 Test loss=0.310986 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1355828195810318
[5/24] Train loss=0.12283439189195633
[10/24] Train loss=0.13164997100830078
[15/24] Train loss=0.1273273527622223
[20/24] Train loss=0.11822329461574554
Test set avg_accuracy=87.89% avg_sensitivity=74.16%, avg_specificity=92.50% avg_auc=91.66%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.133370 Test loss=0.306829 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1347462236881256
[5/24] Train loss=0.12396593391895294
[10/24] Train loss=0.13026392459869385
[15/24] Train loss=0.13020212948322296
[20/24] Train loss=0.12055429816246033
Test set avg_accuracy=87.92% avg_sensitivity=73.95%, avg_specificity=92.61% avg_auc=91.52%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.133523 Test loss=0.307416 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13644929230213165
[5/24] Train loss=0.12319230288267136
[10/24] Train loss=0.12856929004192352
[15/24] Train loss=0.1279338151216507
[20/24] Train loss=0.11867547035217285
Test set avg_accuracy=87.81% avg_sensitivity=73.64%, avg_specificity=92.57% avg_auc=91.33%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.132811 Test loss=0.310826 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13300921022891998
[5/24] Train loss=0.12491525709629059
[10/24] Train loss=0.1289263665676117
[15/24] Train loss=0.13002660870552063
[20/24] Train loss=0.1184445470571518
Test set avg_accuracy=87.88% avg_sensitivity=73.59%, avg_specificity=92.68% avg_auc=91.30%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.132510 Test loss=0.311033 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13950161635875702
[5/24] Train loss=0.1242181807756424
[10/24] Train loss=0.12918567657470703
[15/24] Train loss=0.13002978265285492
[20/24] Train loss=0.12005572766065598
Test set avg_accuracy=87.81% avg_sensitivity=73.49%, avg_specificity=92.62% avg_auc=91.23%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.132679 Test loss=0.311831 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13665589690208435
[5/24] Train loss=0.12351460754871368
[10/24] Train loss=0.12703382968902588
[15/24] Train loss=0.12730039656162262
[20/24] Train loss=0.1180189996957779
Test set avg_accuracy=87.89% avg_sensitivity=73.64%, avg_specificity=92.68% avg_auc=91.29%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.132424 Test loss=0.310957 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1374792456626892
[5/24] Train loss=0.12365030497312546
[10/24] Train loss=0.13019707798957825
[15/24] Train loss=0.12927031517028809
[20/24] Train loss=0.11931385099887848
Test set avg_accuracy=87.85% avg_sensitivity=73.64%, avg_specificity=92.62% avg_auc=91.37%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.132501 Test loss=0.309859 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.13697734475135803
[5/24] Train loss=0.12322736531496048
[10/24] Train loss=0.1302681416273117
[15/24] Train loss=0.12909728288650513
[20/24] Train loss=0.11913635581731796
Test set avg_accuracy=87.88% avg_sensitivity=73.59%, avg_specificity=92.68% avg_auc=91.38%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.132601 Test loss=0.309506 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13454563915729523
[5/24] Train loss=0.12431806325912476
[10/24] Train loss=0.12710268795490265
[15/24] Train loss=0.12858298420906067
[20/24] Train loss=0.11978902667760849
Test set avg_accuracy=87.90% avg_sensitivity=73.80%, avg_specificity=92.64% avg_auc=91.39%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.132570 Test loss=0.309499 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.13550877571105957
[5/24] Train loss=0.1235661655664444
[10/24] Train loss=0.13003675639629364
[15/24] Train loss=0.12774313986301422
[20/24] Train loss=0.12019162625074387
Test set avg_accuracy=87.86% avg_sensitivity=73.64%, avg_specificity=92.64% avg_auc=91.38%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.132499 Test loss=0.309531 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=88.54% sen=76.59%, spe=92.56%, auc=93.30%!
Fold[8] Avg_overlap=0.68%(±0.25040393211413975)
[0/23] Train loss=0.7320722341537476
[5/23] Train loss=0.7226839661598206
[10/23] Train loss=0.728399395942688
[15/23] Train loss=0.7133361101150513
[20/23] Train loss=0.7051627039909363
Test set avg_accuracy=54.78% avg_sensitivity=47.76%, avg_specificity=57.01% avg_auc=53.83%
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.720431 Test loss=0.694089 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.7046859860420227
[5/23] Train loss=0.7023040056228638
[10/23] Train loss=0.697804868221283
[15/23] Train loss=0.6977432370185852
[20/23] Train loss=0.6875391006469727
Test set avg_accuracy=58.41% avg_sensitivity=57.68%, avg_specificity=58.64% avg_auc=61.46%
Best model saved!! Metric=-89.80131540196047!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.699723 Test loss=0.669037 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.6755510568618774
[5/23] Train loss=0.6826940178871155
[10/23] Train loss=0.6784124374389648
[15/23] Train loss=0.6762768030166626
[20/23] Train loss=0.6631964445114136
Test set avg_accuracy=61.29% avg_sensitivity=59.57%, avg_specificity=61.84% avg_auc=65.56%
Best model saved!! Metric=-77.74043439390697!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.678974 Test loss=0.647827 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.6694921255111694
[5/23] Train loss=0.6586720943450928
[10/23] Train loss=0.6618929505348206
[15/23] Train loss=0.6459550261497498
[20/23] Train loss=0.6472381949424744
Test set avg_accuracy=63.52% avg_sensitivity=62.43%, avg_specificity=63.86% avg_auc=69.06%
Best model saved!! Metric=-67.13857719103919!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.661894 Test loss=0.628352 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.6401245594024658
[5/23] Train loss=0.6370241045951843
[10/23] Train loss=0.6446413993835449
[15/23] Train loss=0.6252260804176331
[20/23] Train loss=0.6297860741615295
Test set avg_accuracy=67.47% avg_sensitivity=62.80%, avg_specificity=68.96% avg_auc=72.67%
Best model saved!! Metric=-54.090119729667705!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.639062 Test loss=0.596543 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.620219349861145
[5/23] Train loss=0.613983690738678
[10/23] Train loss=0.6234762072563171
[15/23] Train loss=0.6047190427780151
[20/23] Train loss=0.6021116971969604
Test set avg_accuracy=69.01% avg_sensitivity=66.85%, avg_specificity=69.70% avg_auc=75.55%
Best model saved!! Metric=-44.89685170671234!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.617693 Test loss=0.580077 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.5950678586959839
[5/23] Train loss=0.5937701463699341
[10/23] Train loss=0.5987929701805115
[15/23] Train loss=0.5807318687438965
[20/23] Train loss=0.573664128780365
Test set avg_accuracy=72.20% avg_sensitivity=67.28%, avg_specificity=73.77% avg_auc=78.25%
Best model saved!! Metric=-34.50063021417775!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.592636 Test loss=0.546516 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.5631569027900696
[5/23] Train loss=0.5627325773239136
[10/23] Train loss=0.5685698390007019
[15/23] Train loss=0.5601583123207092
[20/23] Train loss=0.540381133556366
Test set avg_accuracy=75.10% avg_sensitivity=69.11%, avg_specificity=77.01% avg_auc=81.07%
Best model saved!! Metric=-23.701723920194013!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.566639 Test loss=0.514370 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.5351807475090027
[5/23] Train loss=0.5295320749282837
[10/23] Train loss=0.5419507026672363
[15/23] Train loss=0.5306946039199829
[20/23] Train loss=0.5158977508544922
Test set avg_accuracy=79.26% avg_sensitivity=69.81%, avg_specificity=82.27% avg_auc=84.26%
Best model saved!! Metric=-10.409066252472726!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.535464 Test loss=0.476042 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.51067715883255
[5/23] Train loss=0.4994922876358032
[10/23] Train loss=0.5140328407287598
[15/23] Train loss=0.49989473819732666
[20/23] Train loss=0.47885674238204956
Test set avg_accuracy=81.67% avg_sensitivity=67.98%, avg_specificity=86.03% avg_auc=86.46%
Best model saved!! Metric=-3.8739045768116966!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.503791 Test loss=0.436357 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.47077813744544983
[5/23] Train loss=0.46125921607017517
[10/23] Train loss=0.4880484640598297
[15/23] Train loss=0.46569037437438965
[20/23] Train loss=0.4538157880306244
Test set avg_accuracy=83.50% avg_sensitivity=67.28%, avg_specificity=88.67% avg_auc=88.18%
Best model saved!! Metric=1.633242853431355!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.473939 Test loss=0.405901 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.4498092830181122
[5/23] Train loss=0.43473830819129944
[10/23] Train loss=0.46677613258361816
[15/23] Train loss=0.43968749046325684
[20/23] Train loss=0.42253631353378296
Test set avg_accuracy=84.53% avg_sensitivity=69.70%, avg_specificity=89.25% avg_auc=89.23%
Best model saved!! Metric=6.718508655992977!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.448062 Test loss=0.390231 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.43175846338272095
[5/23] Train loss=0.4009580910205841
[10/23] Train loss=0.44465234875679016
[15/23] Train loss=0.4188265800476074
[20/23] Train loss=0.40020889043807983
Test set avg_accuracy=85.52% avg_sensitivity=65.23%, avg_specificity=91.98% avg_auc=89.92%
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.425342 Test loss=0.364531 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.41541892290115356
[5/23] Train loss=0.3879013955593109
[10/23] Train loss=0.4315638244152069
[15/23] Train loss=0.4002961814403534
[20/23] Train loss=0.3730562925338745
Test set avg_accuracy=85.60% avg_sensitivity=59.41%, avg_specificity=93.94% avg_auc=90.17%
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.406219 Test loss=0.349919 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.39510372281074524
[5/23] Train loss=0.363977313041687
[10/23] Train loss=0.4096353352069855
[15/23] Train loss=0.3811033368110657
[20/23] Train loss=0.3586357831954956
Test set avg_accuracy=85.92% avg_sensitivity=59.68%, avg_specificity=94.28% avg_auc=90.37%
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.389015 Test loss=0.341894 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.38719573616981506
[5/23] Train loss=0.3433144986629486
[10/23] Train loss=0.39488685131073
[15/23] Train loss=0.3717000484466553
[20/23] Train loss=0.33817923069000244
Test set avg_accuracy=86.29% avg_sensitivity=60.05%, avg_specificity=94.64% avg_auc=90.49%
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.373461 Test loss=0.333580 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.36249199509620667
[5/23] Train loss=0.3298318386077881
[10/23] Train loss=0.38494977355003357
[15/23] Train loss=0.36082568764686584
[20/23] Train loss=0.32593730092048645
Test set avg_accuracy=86.09% avg_sensitivity=57.41%, avg_specificity=95.23% avg_auc=90.43%
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.361222 Test loss=0.331644 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.3496720790863037
[5/23] Train loss=0.3230774700641632
[10/23] Train loss=0.37418118119239807
[15/23] Train loss=0.34127092361450195
[20/23] Train loss=0.3142938017845154
Test set avg_accuracy=85.55% avg_sensitivity=51.43%, avg_specificity=96.41% avg_auc=90.15%
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.350216 Test loss=0.338324 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.33693742752075195
[5/23] Train loss=0.310939759016037
[10/23] Train loss=0.3680676519870758
[15/23] Train loss=0.3343020975589752
[20/23] Train loss=0.30563223361968994
Test set avg_accuracy=85.43% avg_sensitivity=49.06%, avg_specificity=97.01% avg_auc=90.52%
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.340504 Test loss=0.338606 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.3332836329936981
[5/23] Train loss=0.30284127593040466
[10/23] Train loss=0.35368990898132324
[15/23] Train loss=0.33057788014411926
[20/23] Train loss=0.29673343896865845
Test set avg_accuracy=86.28% avg_sensitivity=55.04%, avg_specificity=96.22% avg_auc=91.29%
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.331948 Test loss=0.322555 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.324297696352005
[5/23] Train loss=0.28489023447036743
[10/23] Train loss=0.35463085770606995
[15/23] Train loss=0.31124556064605713
[20/23] Train loss=0.2821104824542999
Test set avg_accuracy=86.50% avg_sensitivity=55.96%, avg_specificity=96.22% avg_auc=91.41%
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.323171 Test loss=0.316299 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.3197613060474396
[5/23] Train loss=0.27546972036361694
[10/23] Train loss=0.34185081720352173
[15/23] Train loss=0.30366963148117065
[20/23] Train loss=0.27830931544303894
Test set avg_accuracy=87.21% avg_sensitivity=60.00%, avg_specificity=95.88% avg_auc=92.18%
Best model saved!! Metric=9.274428031091787!!
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.315034 Test loss=0.304498 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.31839072704315186
[5/23] Train loss=0.27388522028923035
[10/23] Train loss=0.3419898450374603
[15/23] Train loss=0.2983056902885437
[20/23] Train loss=0.27213695645332336
Test set avg_accuracy=87.75% avg_sensitivity=62.64%, avg_specificity=95.74% avg_auc=92.32%
Best model saved!! Metric=12.447107782247649!!
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.310388 Test loss=0.299758 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.3013884127140045
[5/23] Train loss=0.26460355520248413
[10/23] Train loss=0.33761319518089294
[15/23] Train loss=0.29578229784965515
[20/23] Train loss=0.26577121019363403
Test set avg_accuracy=87.71% avg_sensitivity=62.26%, avg_specificity=95.81% avg_auc=92.77%
Best model saved!! Metric=12.549622969278396!!
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.303972 Test loss=0.293933 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.29563257098197937
[5/23] Train loss=0.2659536898136139
[10/23] Train loss=0.33378517627716064
[15/23] Train loss=0.28007298707962036
[20/23] Train loss=0.2630409896373749
Test set avg_accuracy=88.14% avg_sensitivity=63.72%, avg_specificity=95.91% avg_auc=93.09%
Best model saved!! Metric=14.86571422666767!!
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.298114 Test loss=0.286361 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.2879793643951416
[5/23] Train loss=0.2582864463329315
[10/23] Train loss=0.32762911915779114
[15/23] Train loss=0.28134799003601074
[20/23] Train loss=0.2564055919647217
Test set avg_accuracy=88.18% avg_sensitivity=66.90%, avg_specificity=94.95% avg_auc=92.80%
Best model saved!! Metric=16.828499873712545!!
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.291576 Test loss=0.288990 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.2878621816635132
[5/23] Train loss=0.2544170618057251
[10/23] Train loss=0.32352912425994873
[15/23] Train loss=0.27260157465934753
[20/23] Train loss=0.25047382712364197
Test set avg_accuracy=87.64% avg_sensitivity=58.54%, avg_specificity=96.91% avg_auc=92.56%
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.289179 Test loss=0.296405 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.2813701629638672
[5/23] Train loss=0.2498604655265808
[10/23] Train loss=0.3160833418369293
[15/23] Train loss=0.26240795850753784
[20/23] Train loss=0.2523345649242401
Test set avg_accuracy=87.84% avg_sensitivity=60.75%, avg_specificity=96.46% avg_auc=92.75%
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.286024 Test loss=0.291011 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.2786067724227905
[5/23] Train loss=0.24382896721363068
[10/23] Train loss=0.31599122285842896
[15/23] Train loss=0.2668375074863434
[20/23] Train loss=0.2416602373123169
Test set avg_accuracy=88.09% avg_sensitivity=64.04%, avg_specificity=95.74% avg_auc=92.74%
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.280840 Test loss=0.290675 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.27961769700050354
[5/23] Train loss=0.2421954721212387
[10/23] Train loss=0.31197020411491394
[15/23] Train loss=0.2665640115737915
[20/23] Train loss=0.24267420172691345
Test set avg_accuracy=85.66% avg_sensitivity=45.66%, avg_specificity=98.40% avg_auc=91.92%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.278399 Test loss=0.333630 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.2672030031681061
[5/23] Train loss=0.2510739862918854
[10/23] Train loss=0.3145502507686615
[15/23] Train loss=0.25410178303718567
[20/23] Train loss=0.2380884885787964
Test set avg_accuracy=86.33% avg_sensitivity=49.65%, avg_specificity=98.01% avg_auc=90.60%
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.275589 Test loss=0.328880 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.27205002307891846
[5/23] Train loss=0.23696503043174744
[10/23] Train loss=0.2980373501777649
[15/23] Train loss=0.26106569170951843
[20/23] Train loss=0.23769359290599823
Test set avg_accuracy=85.09% avg_sensitivity=42.43%, avg_specificity=98.68% avg_auc=90.22%
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.272876 Test loss=0.356760 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.2696254551410675
[5/23] Train loss=0.2366219013929367
[10/23] Train loss=0.2999063730239868
[15/23] Train loss=0.2508951723575592
[20/23] Train loss=0.23129282891750336
Test set avg_accuracy=87.79% avg_sensitivity=56.93%, avg_specificity=97.61% avg_auc=92.38%
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.269087 Test loss=0.297487 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.25390446186065674
[5/23] Train loss=0.23649197816848755
[10/23] Train loss=0.292529821395874
[15/23] Train loss=0.2571067810058594
[20/23] Train loss=0.23576803505420685
Test set avg_accuracy=85.65% avg_sensitivity=45.07%, avg_specificity=98.58% avg_auc=90.09%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.268155 Test loss=0.344663 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.26140114665031433
[5/23] Train loss=0.23109617829322815
[10/23] Train loss=0.3092460036277771
[15/23] Train loss=0.2526915371417999
[20/23] Train loss=0.22379107773303986
Test set avg_accuracy=87.42% avg_sensitivity=55.04%, avg_specificity=97.73% avg_auc=91.06%
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.265525 Test loss=0.317016 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.24907286465168
[5/23] Train loss=0.2301333099603653
[10/23] Train loss=0.2854681611061096
[15/23] Train loss=0.2556913495063782
[20/23] Train loss=0.23719623684883118
Test set avg_accuracy=84.44% avg_sensitivity=39.41%, avg_specificity=98.78% avg_auc=89.38%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.264331 Test loss=0.393103 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.2651788890361786
[5/23] Train loss=0.23183833062648773
[10/23] Train loss=0.2925979495048523
[15/23] Train loss=0.2607981264591217
[20/23] Train loss=0.2310791164636612
Test set avg_accuracy=87.42% avg_sensitivity=55.26%, avg_specificity=97.67% avg_auc=91.89%
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.265123 Test loss=0.309779 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.2572126090526581
[5/23] Train loss=0.2234942615032196
[10/23] Train loss=0.2829812467098236
[15/23] Train loss=0.24996545910835266
[20/23] Train loss=0.22481314837932587
Test set avg_accuracy=86.55% avg_sensitivity=50.51%, avg_specificity=98.03% avg_auc=90.73%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.257349 Test loss=0.333476 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.2541210651397705
[5/23] Train loss=0.2213054597377777
[10/23] Train loss=0.30764076113700867
[15/23] Train loss=0.24680618941783905
[20/23] Train loss=0.2203516811132431
Test set avg_accuracy=87.62% avg_sensitivity=58.33%, avg_specificity=96.94% avg_auc=91.68%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.260306 Test loss=0.304878 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.24836090207099915
[5/23] Train loss=0.2223714292049408
[10/23] Train loss=0.28329554200172424
[15/23] Train loss=0.23828820884227753
[20/23] Train loss=0.22249098122119904
Test set avg_accuracy=88.01% avg_sensitivity=60.16%, avg_specificity=96.88% avg_auc=91.32%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.255503 Test loss=0.304164 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.2397986799478531
[5/23] Train loss=0.21294280886650085
[10/23] Train loss=0.28616297245025635
[15/23] Train loss=0.2396724671125412
[20/23] Train loss=0.215961292386055
Test set avg_accuracy=86.65% avg_sensitivity=53.42%, avg_specificity=97.24% avg_auc=92.05%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.255622 Test loss=0.308117 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.257352739572525
[5/23] Train loss=0.21344199776649475
[10/23] Train loss=0.27496659755706787
[15/23] Train loss=0.2490757554769516
[20/23] Train loss=0.23018032312393188
Test set avg_accuracy=85.94% avg_sensitivity=47.76%, avg_specificity=98.09% avg_auc=90.13%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.256759 Test loss=0.341197 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.24661917984485626
[5/23] Train loss=0.2086644023656845
[10/23] Train loss=0.27942952513694763
[15/23] Train loss=0.2500772178173065
[20/23] Train loss=0.21246199309825897
Test set avg_accuracy=88.48% avg_sensitivity=68.57%, avg_specificity=94.82% avg_auc=92.07%
Best model saved!! Metric=17.92958472273638!!
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.251217 Test loss=0.292150 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.2340487539768219
[5/23] Train loss=0.22101683914661407
[10/23] Train loss=0.27793967723846436
[15/23] Train loss=0.23623113334178925
[20/23] Train loss=0.2276666760444641
Test set avg_accuracy=85.40% avg_sensitivity=43.67%, avg_specificity=98.70% avg_auc=89.64%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.251407 Test loss=0.362514 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.24635285139083862
[5/23] Train loss=0.2174360603094101
[10/23] Train loss=0.28596174716949463
[15/23] Train loss=0.23381564021110535
[20/23] Train loss=0.22556133568286896
Test set avg_accuracy=87.63% avg_sensitivity=57.68%, avg_specificity=97.17% avg_auc=91.80%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.251604 Test loss=0.306453 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.2429811954498291
[5/23] Train loss=0.2153913974761963
[10/23] Train loss=0.27820587158203125
[15/23] Train loss=0.23447981476783752
[20/23] Train loss=0.22290834784507751
Test set avg_accuracy=87.04% avg_sensitivity=52.94%, avg_specificity=97.91% avg_auc=92.07%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.250106 Test loss=0.312661 Current lr=[0.000299926900870094]

[0/23] Train loss=0.23372754454612732
[5/23] Train loss=0.20446738600730896
[10/23] Train loss=0.24597755074501038
[15/23] Train loss=0.23372431099414825
[20/23] Train loss=0.22828808426856995
Test set avg_accuracy=87.62% avg_sensitivity=58.60%, avg_specificity=96.86% avg_auc=91.83%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.246414 Test loss=0.302666 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.24016466736793518
[5/23] Train loss=0.20987528562545776
[10/23] Train loss=0.25986579060554504
[15/23] Train loss=0.22474227845668793
[20/23] Train loss=0.22352969646453857
Test set avg_accuracy=86.56% avg_sensitivity=51.81%, avg_specificity=97.63% avg_auc=90.52%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.246345 Test loss=0.329473 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.23535586893558502
[5/23] Train loss=0.20748603343963623
[10/23] Train loss=0.2585832476615906
[15/23] Train loss=0.23756040632724762
[20/23] Train loss=0.21434712409973145
Test set avg_accuracy=84.74% avg_sensitivity=40.32%, avg_specificity=98.88% avg_auc=87.24%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.242622 Test loss=0.416945 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.22567212581634521
[5/23] Train loss=0.21903394162654877
[10/23] Train loss=0.2422872632741928
[15/23] Train loss=0.2299468219280243
[20/23] Train loss=0.21200424432754517
Test set avg_accuracy=86.91% avg_sensitivity=58.71%, avg_specificity=95.90% avg_auc=90.52%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.240993 Test loss=0.311049 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.23095612227916718
[5/23] Train loss=0.2060685008764267
[10/23] Train loss=0.2526516914367676
[15/23] Train loss=0.23064398765563965
[20/23] Train loss=0.21599917113780975
Test set avg_accuracy=87.14% avg_sensitivity=53.10%, avg_specificity=97.97% avg_auc=90.40%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.243456 Test loss=0.332903 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.23388127982616425
[5/23] Train loss=0.20898662507534027
[10/23] Train loss=0.2508598566055298
[15/23] Train loss=0.23282280564308167
[20/23] Train loss=0.21281300485134125
Test set avg_accuracy=87.97% avg_sensitivity=68.03%, avg_specificity=94.32% avg_auc=91.56%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.238483 Test loss=0.297725 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.2207711637020111
[5/23] Train loss=0.21145831048488617
[10/23] Train loss=0.23581553995609283
[15/23] Train loss=0.23172526061534882
[20/23] Train loss=0.2122974544763565
Test set avg_accuracy=88.39% avg_sensitivity=67.22%, avg_specificity=95.12% avg_auc=90.85%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.236548 Test loss=0.302856 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.22143825888633728
[5/23] Train loss=0.21618542075157166
[10/23] Train loss=0.2637621760368347
[15/23] Train loss=0.22967937588691711
[20/23] Train loss=0.21624413132667542
Test set avg_accuracy=87.94% avg_sensitivity=67.17%, avg_specificity=94.56% avg_auc=91.29%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.246602 Test loss=0.297142 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.23206709325313568
[5/23] Train loss=0.21256543695926666
[10/23] Train loss=0.2580505907535553
[15/23] Train loss=0.2300095409154892
[20/23] Train loss=0.22711682319641113
Test set avg_accuracy=88.31% avg_sensitivity=62.10%, avg_specificity=96.65% avg_auc=92.59%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.244886 Test loss=0.286794 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.2235831767320633
[5/23] Train loss=0.20618890225887299
[10/23] Train loss=0.2521686255931854
[15/23] Train loss=0.21899521350860596
[20/23] Train loss=0.2197616994380951
Test set avg_accuracy=85.61% avg_sensitivity=72.40%, avg_specificity=89.82% avg_auc=90.95%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.239339 Test loss=0.328864 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.2293332815170288
[5/23] Train loss=0.21055150032043457
[10/23] Train loss=0.25855734944343567
[15/23] Train loss=0.22935092449188232
[20/23] Train loss=0.2172302007675171
Test set avg_accuracy=86.38% avg_sensitivity=51.32%, avg_specificity=97.55% avg_auc=89.17%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.238658 Test loss=0.358116 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.23098838329315186
[5/23] Train loss=0.21430104970932007
[10/23] Train loss=0.24584974348545074
[15/23] Train loss=0.21550606191158295
[20/23] Train loss=0.22186370193958282
Test set avg_accuracy=87.49% avg_sensitivity=58.71%, avg_specificity=96.65% avg_auc=89.92%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.235479 Test loss=0.317529 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.22249235212802887
[5/23] Train loss=0.20843996107578278
[10/23] Train loss=0.24336260557174683
[15/23] Train loss=0.22260965406894684
[20/23] Train loss=0.2130250334739685
Test set avg_accuracy=87.46% avg_sensitivity=65.39%, avg_specificity=94.49% avg_auc=91.62%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.232283 Test loss=0.299956 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.22508761286735535
[5/23] Train loss=0.19572824239730835
[10/23] Train loss=0.24229182302951813
[15/23] Train loss=0.22145475447177887
[20/23] Train loss=0.20846310257911682
Test set avg_accuracy=86.47% avg_sensitivity=54.72%, avg_specificity=96.58% avg_auc=89.98%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.233544 Test loss=0.344252 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.21216733753681183
[5/23] Train loss=0.2084825336933136
[10/23] Train loss=0.24385200440883636
[15/23] Train loss=0.21347291767597198
[20/23] Train loss=0.20924542844295502
Test set avg_accuracy=85.40% avg_sensitivity=48.52%, avg_specificity=97.15% avg_auc=87.83%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.230694 Test loss=0.367334 Current lr=[0.000283047938381597]

[0/23] Train loss=0.2316894382238388
[5/23] Train loss=0.203367680311203
[10/23] Train loss=0.23993179202079773
[15/23] Train loss=0.21527475118637085
[20/23] Train loss=0.2093203365802765
Test set avg_accuracy=87.28% avg_sensitivity=59.41%, avg_specificity=96.15% avg_auc=91.29%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.229134 Test loss=0.306857 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.21090373396873474
[5/23] Train loss=0.20147058367729187
[10/23] Train loss=0.22754372656345367
[15/23] Train loss=0.22206096351146698
[20/23] Train loss=0.21728767454624176
Test set avg_accuracy=87.70% avg_sensitivity=63.94%, avg_specificity=95.26% avg_auc=91.60%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.225526 Test loss=0.297034 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.20805661380290985
[5/23] Train loss=0.1961708664894104
[10/23] Train loss=0.23206254839897156
[15/23] Train loss=0.20808735489845276
[20/23] Train loss=0.20812535285949707
Test set avg_accuracy=87.29% avg_sensitivity=60.00%, avg_specificity=95.98% avg_auc=88.33%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.224490 Test loss=0.334478 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.22214607894420624
[5/23] Train loss=0.20336377620697021
[10/23] Train loss=0.2466498613357544
[15/23] Train loss=0.2140282839536667
[20/23] Train loss=0.213290736079216
Test set avg_accuracy=87.25% avg_sensitivity=57.25%, avg_specificity=96.81% avg_auc=90.61%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.229387 Test loss=0.312043 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.21328599750995636
[5/23] Train loss=0.19416320323944092
[10/23] Train loss=0.2433229237794876
[15/23] Train loss=0.20456267893314362
[20/23] Train loss=0.20339976251125336
Test set avg_accuracy=88.07% avg_sensitivity=59.84%, avg_specificity=97.06% avg_auc=91.47%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.227168 Test loss=0.308931 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.21107016503810883
[5/23] Train loss=0.20475217700004578
[10/23] Train loss=0.2298087179660797
[15/23] Train loss=0.2153499722480774
[20/23] Train loss=0.201827272772789
Test set avg_accuracy=88.09% avg_sensitivity=61.94%, avg_specificity=96.41% avg_auc=90.78%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.223512 Test loss=0.308211 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.2144288867712021
[5/23] Train loss=0.19552788138389587
[10/23] Train loss=0.22776591777801514
[15/23] Train loss=0.20906051993370056
[20/23] Train loss=0.21340177953243256
Test set avg_accuracy=88.12% avg_sensitivity=68.73%, avg_specificity=94.30% avg_auc=91.81%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.224682 Test loss=0.297195 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.22115164995193481
[5/23] Train loss=0.20215243101119995
[10/23] Train loss=0.24103601276874542
[15/23] Train loss=0.21085716784000397
[20/23] Train loss=0.20725959539413452
Test set avg_accuracy=87.29% avg_sensitivity=57.95%, avg_specificity=96.64% avg_auc=90.95%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.226041 Test loss=0.311580 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.21392254531383514
[5/23] Train loss=0.19976109266281128
[10/23] Train loss=0.2270512729883194
[15/23] Train loss=0.20991212129592896
[20/23] Train loss=0.20830556750297546
Test set avg_accuracy=88.12% avg_sensitivity=68.63%, avg_specificity=94.33% avg_auc=91.50%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.219985 Test loss=0.297913 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.2032831460237503
[5/23] Train loss=0.2047429233789444
[10/23] Train loss=0.23259936273097992
[15/23] Train loss=0.20664292573928833
[20/23] Train loss=0.19508153200149536
Test set avg_accuracy=88.11% avg_sensitivity=69.70%, avg_specificity=93.97% avg_auc=91.76%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.220980 Test loss=0.297732 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.21356621384620667
[5/23] Train loss=0.19924576580524445
[10/23] Train loss=0.2344612181186676
[15/23] Train loss=0.18901006877422333
[20/23] Train loss=0.20670540630817413
Test set avg_accuracy=87.43% avg_sensitivity=64.10%, avg_specificity=94.87% avg_auc=91.11%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.219931 Test loss=0.307023 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.2206895798444748
[5/23] Train loss=0.19482861459255219
[10/23] Train loss=0.21746794879436493
[15/23] Train loss=0.21180598437786102
[20/23] Train loss=0.19656284153461456
Test set avg_accuracy=88.10% avg_sensitivity=64.15%, avg_specificity=95.73% avg_auc=91.63%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.220291 Test loss=0.297771 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.20936283469200134
[5/23] Train loss=0.1845298856496811
[10/23] Train loss=0.2245459407567978
[15/23] Train loss=0.2061101198196411
[20/23] Train loss=0.19899535179138184
Test set avg_accuracy=87.14% avg_sensitivity=73.26%, avg_specificity=91.55% avg_auc=91.98%
Best model saved!! Metric=17.932917910260727!!
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.215699 Test loss=0.300482 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.20908576250076294
[5/23] Train loss=0.18777817487716675
[10/23] Train loss=0.21646036207675934
[15/23] Train loss=0.18851104378700256
[20/23] Train loss=0.20464371144771576
Test set avg_accuracy=86.97% avg_sensitivity=71.70%, avg_specificity=91.83% avg_auc=91.25%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.212477 Test loss=0.310575 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.21167266368865967
[5/23] Train loss=0.1832091361284256
[10/23] Train loss=0.208542138338089
[15/23] Train loss=0.19016088545322418
[20/23] Train loss=0.1888992041349411
Test set avg_accuracy=88.03% avg_sensitivity=70.89%, avg_specificity=93.49% avg_auc=91.39%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.212134 Test loss=0.297814 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.20613569021224976
[5/23] Train loss=0.18290238082408905
[10/23] Train loss=0.21656197309494019
[15/23] Train loss=0.19426684081554413
[20/23] Train loss=0.19163016974925995
Test set avg_accuracy=86.69% avg_sensitivity=66.15%, avg_specificity=93.24% avg_auc=90.52%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.214264 Test loss=0.319705 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.2028186023235321
[5/23] Train loss=0.19684255123138428
[10/23] Train loss=0.20015552639961243
[15/23] Train loss=0.1957688182592392
[20/23] Train loss=0.19061709940433502
Test set avg_accuracy=87.38% avg_sensitivity=75.20%, avg_specificity=91.26% avg_auc=92.48%
Best model saved!! Metric=20.32787456401907!!
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.210657 Test loss=0.301203 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.21277418732643127
[5/23] Train loss=0.19657157361507416
[10/23] Train loss=0.2076425552368164
[15/23] Train loss=0.2031521201133728
[20/23] Train loss=0.19524803757667542
Test set avg_accuracy=87.88% avg_sensitivity=63.45%, avg_specificity=95.66% avg_auc=91.06%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.212356 Test loss=0.304858 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.1960785984992981
[5/23] Train loss=0.18500767648220062
[10/23] Train loss=0.20884327590465546
[15/23] Train loss=0.1981005072593689
[20/23] Train loss=0.19474130868911743
Test set avg_accuracy=88.48% avg_sensitivity=64.58%, avg_specificity=96.09% avg_auc=91.68%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.210614 Test loss=0.294932 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.20569570362567902
[5/23] Train loss=0.18389104306697845
[10/23] Train loss=0.208465114235878
[15/23] Train loss=0.18950119614601135
[20/23] Train loss=0.18566596508026123
Test set avg_accuracy=86.52% avg_sensitivity=72.40%, avg_specificity=91.02% avg_auc=91.40%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.205804 Test loss=0.318216 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.20297470688819885
[5/23] Train loss=0.1875927448272705
[10/23] Train loss=0.19289304316043854
[15/23] Train loss=0.19500380754470825
[20/23] Train loss=0.20200298726558685
Test set avg_accuracy=87.19% avg_sensitivity=70.84%, avg_specificity=92.39% avg_auc=92.37%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.208680 Test loss=0.296230 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.19438274204730988
[5/23] Train loss=0.18833643198013306
[10/23] Train loss=0.20393016934394836
[15/23] Train loss=0.20682652294635773
[20/23] Train loss=0.1916716992855072
Test set avg_accuracy=87.50% avg_sensitivity=71.37%, avg_specificity=92.64% avg_auc=91.73%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.207978 Test loss=0.300537 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.19074711203575134
[5/23] Train loss=0.1849091351032257
[10/23] Train loss=0.2063833624124527
[15/23] Train loss=0.19198189675807953
[20/23] Train loss=0.18217773735523224
Test set avg_accuracy=87.11% avg_sensitivity=60.65%, avg_specificity=95.54% avg_auc=90.47%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.203164 Test loss=0.320853 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.1854211837053299
[5/23] Train loss=0.19272518157958984
[10/23] Train loss=0.18424572050571442
[15/23] Train loss=0.18716329336166382
[20/23] Train loss=0.18423065543174744
Test set avg_accuracy=88.16% avg_sensitivity=68.46%, avg_specificity=94.44% avg_auc=92.21%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.200011 Test loss=0.290989 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.18777304887771606
[5/23] Train loss=0.16986587643623352
[10/23] Train loss=0.18611682951450348
[15/23] Train loss=0.18490448594093323
[20/23] Train loss=0.18192684650421143
Test set avg_accuracy=87.57% avg_sensitivity=58.71%, avg_specificity=96.76% avg_auc=89.56%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.197457 Test loss=0.334938 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.18766778707504272
[5/23] Train loss=0.1695941984653473
[10/23] Train loss=0.19327597320079803
[15/23] Train loss=0.18764886260032654
[20/23] Train loss=0.1715727001428604
Test set avg_accuracy=87.80% avg_sensitivity=66.85%, avg_specificity=94.47% avg_auc=91.83%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.195622 Test loss=0.299429 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.17666445672512054
[5/23] Train loss=0.1741829663515091
[10/23] Train loss=0.18263821303844452
[15/23] Train loss=0.19157235324382782
[20/23] Train loss=0.16670618951320648
Test set avg_accuracy=87.19% avg_sensitivity=70.89%, avg_specificity=92.38% avg_auc=92.04%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.193123 Test loss=0.302392 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.182495579123497
[5/23] Train loss=0.16934163868427277
[10/23] Train loss=0.18184837698936462
[15/23] Train loss=0.17243720591068268
[20/23] Train loss=0.17671699821949005
Test set avg_accuracy=88.54% avg_sensitivity=64.20%, avg_specificity=96.29% avg_auc=91.07%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.194096 Test loss=0.298735 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.18033109605312347
[5/23] Train loss=0.1821252852678299
[10/23] Train loss=0.17931658029556274
[15/23] Train loss=0.1795729100704193
[20/23] Train loss=0.16449551284313202
Test set avg_accuracy=87.67% avg_sensitivity=64.91%, avg_specificity=94.92% avg_auc=90.92%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.190474 Test loss=0.306848 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.18854771554470062
[5/23] Train loss=0.1715945303440094
[10/23] Train loss=0.19313199818134308
[15/23] Train loss=0.16868862509727478
[20/23] Train loss=0.16973115503787994
Test set avg_accuracy=87.41% avg_sensitivity=61.29%, avg_specificity=95.73% avg_auc=89.80%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.187673 Test loss=0.324786 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.18075788021087646
[5/23] Train loss=0.1753971129655838
[10/23] Train loss=0.17769956588745117
[15/23] Train loss=0.1674765646457672
[20/23] Train loss=0.1708110272884369
Test set avg_accuracy=86.95% avg_sensitivity=72.08%, avg_specificity=91.69% avg_auc=91.29%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.189217 Test loss=0.317370 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.17856158316135406
[5/23] Train loss=0.16059869527816772
[10/23] Train loss=0.17939072847366333
[15/23] Train loss=0.17360666394233704
[20/23] Train loss=0.16818320751190186
Test set avg_accuracy=87.53% avg_sensitivity=65.66%, avg_specificity=94.49% avg_auc=91.14%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.185008 Test loss=0.305667 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.17451122403144836
[5/23] Train loss=0.17639881372451782
[10/23] Train loss=0.1757696270942688
[15/23] Train loss=0.1656620055437088
[20/23] Train loss=0.15870754420757294
Test set avg_accuracy=87.64% avg_sensitivity=69.92%, avg_specificity=93.29% avg_auc=91.06%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.183742 Test loss=0.310336 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.17178641259670258
[5/23] Train loss=0.16376587748527527
[10/23] Train loss=0.17501524090766907
[15/23] Train loss=0.18295755982398987
[20/23] Train loss=0.15903013944625854
Test set avg_accuracy=86.98% avg_sensitivity=59.08%, avg_specificity=95.86% avg_auc=86.89%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.184340 Test loss=0.350253 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.17967480421066284
[5/23] Train loss=0.16591015458106995
[10/23] Train loss=0.17772014439105988
[15/23] Train loss=0.17060375213623047
[20/23] Train loss=0.1675427258014679
Test set avg_accuracy=87.08% avg_sensitivity=58.17%, avg_specificity=96.29% avg_auc=88.76%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.184750 Test loss=0.346341 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.17223496735095978
[5/23] Train loss=0.17047415673732758
[10/23] Train loss=0.18227028846740723
[15/23] Train loss=0.16926273703575134
[20/23] Train loss=0.1665298491716385
Test set avg_accuracy=87.46% avg_sensitivity=70.51%, avg_specificity=92.86% avg_auc=91.38%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.183751 Test loss=0.305182 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.17087312042713165
[5/23] Train loss=0.1689690351486206
[10/23] Train loss=0.17547161877155304
[15/23] Train loss=0.17154553532600403
[20/23] Train loss=0.16579170525074005
Test set avg_accuracy=87.90% avg_sensitivity=68.84%, avg_specificity=93.97% avg_auc=91.17%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.183158 Test loss=0.310228 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.1664295643568039
[5/23] Train loss=0.1658775359392166
[10/23] Train loss=0.1653745472431183
[15/23] Train loss=0.16390836238861084
[20/23] Train loss=0.1644047200679779
Test set avg_accuracy=87.73% avg_sensitivity=61.73%, avg_specificity=96.02% avg_auc=89.91%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.180283 Test loss=0.325248 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.17100639641284943
[5/23] Train loss=0.1649077832698822
[10/23] Train loss=0.17514696717262268
[15/23] Train loss=0.16597500443458557
[20/23] Train loss=0.164424866437912
Test set avg_accuracy=87.27% avg_sensitivity=67.28%, avg_specificity=93.63% avg_auc=90.91%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.180315 Test loss=0.316415 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.1615609973669052
[5/23] Train loss=0.15225845575332642
[10/23] Train loss=0.1679585874080658
[15/23] Train loss=0.1728391945362091
[20/23] Train loss=0.16539031267166138
Test set avg_accuracy=87.81% avg_sensitivity=59.08%, avg_specificity=96.96% avg_auc=89.16%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.179288 Test loss=0.329751 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.15929213166236877
[5/23] Train loss=0.16037006676197052
[10/23] Train loss=0.1661710888147354
[15/23] Train loss=0.17313551902770996
[20/23] Train loss=0.15588079392910004
Test set avg_accuracy=87.11% avg_sensitivity=55.15%, avg_specificity=97.29% avg_auc=87.75%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.177741 Test loss=0.364492 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.16278253495693207
[5/23] Train loss=0.1523793339729309
[10/23] Train loss=0.15967990458011627
[15/23] Train loss=0.16281332075595856
[20/23] Train loss=0.15212854743003845
Test set avg_accuracy=86.95% avg_sensitivity=56.01%, avg_specificity=96.81% avg_auc=88.11%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.173261 Test loss=0.352982 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.15343454480171204
[5/23] Train loss=0.1533827930688858
[10/23] Train loss=0.15781868994235992
[15/23] Train loss=0.15835025906562805
[20/23] Train loss=0.14730270206928253
Test set avg_accuracy=87.70% avg_sensitivity=64.37%, avg_specificity=95.12% avg_auc=90.51%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.168715 Test loss=0.308886 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.15717752277851105
[5/23] Train loss=0.15544524788856506
[10/23] Train loss=0.16315515339374542
[15/23] Train loss=0.15780290961265564
[20/23] Train loss=0.15678595006465912
Test set avg_accuracy=87.83% avg_sensitivity=66.63%, avg_specificity=94.58% avg_auc=91.01%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.168806 Test loss=0.310428 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.16259604692459106
[5/23] Train loss=0.1532989889383316
[10/23] Train loss=0.16097547113895416
[15/23] Train loss=0.15731927752494812
[20/23] Train loss=0.15070362389087677
Test set avg_accuracy=87.99% avg_sensitivity=70.62%, avg_specificity=93.53% avg_auc=90.65%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.168458 Test loss=0.312243 Current lr=[0.000112073915556435]

[0/23] Train loss=0.15934649109840393
[5/23] Train loss=0.15147247910499573
[10/23] Train loss=0.16217009723186493
[15/23] Train loss=0.1503058671951294
[20/23] Train loss=0.14564324915409088
Test set avg_accuracy=87.79% avg_sensitivity=70.67%, avg_specificity=93.24% avg_auc=91.12%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.165045 Test loss=0.308113 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.15171948075294495
[5/23] Train loss=0.15141500532627106
[10/23] Train loss=0.1460149884223938
[15/23] Train loss=0.16084659099578857
[20/23] Train loss=0.14318297803401947
Test set avg_accuracy=87.27% avg_sensitivity=67.28%, avg_specificity=93.63% avg_auc=89.92%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.161914 Test loss=0.321323 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.15033452212810516
[5/23] Train loss=0.15129674971103668
[10/23] Train loss=0.15232782065868378
[15/23] Train loss=0.1540885716676712
[20/23] Train loss=0.14545762538909912
Test set avg_accuracy=87.45% avg_sensitivity=67.44%, avg_specificity=93.82% avg_auc=90.65%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.161451 Test loss=0.315229 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.1558416187763214
[5/23] Train loss=0.14782612025737762
[10/23] Train loss=0.15419448912143707
[15/23] Train loss=0.14911608397960663
[20/23] Train loss=0.14478956162929535
Test set avg_accuracy=87.62% avg_sensitivity=67.12%, avg_specificity=94.15% avg_auc=91.28%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.160058 Test loss=0.307959 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.14749674499034882
[5/23] Train loss=0.15086454153060913
[10/23] Train loss=0.15250621736049652
[15/23] Train loss=0.14724522829055786
[20/23] Train loss=0.1487172245979309
Test set avg_accuracy=87.85% avg_sensitivity=68.09%, avg_specificity=94.15% avg_auc=91.39%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.158712 Test loss=0.308210 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.15222686529159546
[5/23] Train loss=0.14081044495105743
[10/23] Train loss=0.14591239392757416
[15/23] Train loss=0.14607925713062286
[20/23] Train loss=0.14185360074043274
Test set avg_accuracy=86.77% avg_sensitivity=74.77%, avg_specificity=90.59% avg_auc=91.23%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.156616 Test loss=0.323566 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.15218354761600494
[5/23] Train loss=0.14030610024929047
[10/23] Train loss=0.1472329944372177
[15/23] Train loss=0.14467185735702515
[20/23] Train loss=0.14407917857170105
Test set avg_accuracy=84.87% avg_sensitivity=75.36%, avg_specificity=87.90% avg_auc=89.88%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.157085 Test loss=0.365405 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.15292635560035706
[5/23] Train loss=0.1459978073835373
[10/23] Train loss=0.15433593094348907
[15/23] Train loss=0.14939121901988983
[20/23] Train loss=0.14986860752105713
Test set avg_accuracy=87.83% avg_sensitivity=70.03%, avg_specificity=93.49% avg_auc=91.19%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.158461 Test loss=0.310002 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.14972171187400818
[5/23] Train loss=0.140989288687706
[10/23] Train loss=0.14685453474521637
[15/23] Train loss=0.1453305035829544
[20/23] Train loss=0.13528107106685638
Test set avg_accuracy=87.51% avg_sensitivity=68.36%, avg_specificity=93.61% avg_auc=90.74%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.156291 Test loss=0.315317 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.14675770699977875
[5/23] Train loss=0.14093507826328278
[10/23] Train loss=0.14465142786502838
[15/23] Train loss=0.14031833410263062
[20/23] Train loss=0.1354628950357437
Test set avg_accuracy=87.57% avg_sensitivity=73.15%, avg_specificity=92.15% avg_auc=91.45%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.151923 Test loss=0.311615 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.144089013338089
[5/23] Train loss=0.13813722133636475
[10/23] Train loss=0.1402691900730133
[15/23] Train loss=0.14213593304157257
[20/23] Train loss=0.13272333145141602
Test set avg_accuracy=87.99% avg_sensitivity=69.11%, avg_specificity=94.01% avg_auc=91.29%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.149611 Test loss=0.304279 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.14393317699432373
[5/23] Train loss=0.13471317291259766
[10/23] Train loss=0.13758403062820435
[15/23] Train loss=0.13673090934753418
[20/23] Train loss=0.13261164724826813
Test set avg_accuracy=87.42% avg_sensitivity=69.27%, avg_specificity=93.20% avg_auc=90.98%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.146828 Test loss=0.314649 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.13538780808448792
[5/23] Train loss=0.1353902667760849
[10/23] Train loss=0.13499827682971954
[15/23] Train loss=0.13571453094482422
[20/23] Train loss=0.12981250882148743
Test set avg_accuracy=87.32% avg_sensitivity=72.61%, avg_specificity=92.00% avg_auc=91.05%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.144602 Test loss=0.313533 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.1377454698085785
[5/23] Train loss=0.1337190717458725
[10/23] Train loss=0.13725851476192474
[15/23] Train loss=0.13437828421592712
[20/23] Train loss=0.13131491839885712
Test set avg_accuracy=87.60% avg_sensitivity=71.05%, avg_specificity=92.88% avg_auc=91.44%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.143866 Test loss=0.304747 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.1383996605873108
[5/23] Train loss=0.13096486032009125
[10/23] Train loss=0.13180793821811676
[15/23] Train loss=0.13202893733978271
[20/23] Train loss=0.1333504468202591
Test set avg_accuracy=87.67% avg_sensitivity=70.89%, avg_specificity=93.01% avg_auc=91.08%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.141650 Test loss=0.308495 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.13544045388698578
[5/23] Train loss=0.13091906905174255
[10/23] Train loss=0.1321345865726471
[15/23] Train loss=0.1337604969739914
[20/23] Train loss=0.12639620900154114
Test set avg_accuracy=87.77% avg_sensitivity=72.56%, avg_specificity=92.62% avg_auc=91.22%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.140491 Test loss=0.307513 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.13637390732765198
[5/23] Train loss=0.12826180458068848
[10/23] Train loss=0.12999805808067322
[15/23] Train loss=0.13065938651561737
[20/23] Train loss=0.12512604892253876
Test set avg_accuracy=87.97% avg_sensitivity=70.78%, avg_specificity=93.44% avg_auc=90.64%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.139184 Test loss=0.313038 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.1342308223247528
[5/23] Train loss=0.12967506051063538
[10/23] Train loss=0.1281019151210785
[15/23] Train loss=0.13125376403331757
[20/23] Train loss=0.12690778076648712
Test set avg_accuracy=87.75% avg_sensitivity=72.13%, avg_specificity=92.72% avg_auc=91.38%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.139094 Test loss=0.309295 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.1339006870985031
[5/23] Train loss=0.1335401087999344
[10/23] Train loss=0.12885631620883942
[15/23] Train loss=0.13081592321395874
[20/23] Train loss=0.12809693813323975
Test set avg_accuracy=88.18% avg_sensitivity=67.71%, avg_specificity=94.70% avg_auc=90.82%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.139308 Test loss=0.311775 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.13028976321220398
[5/23] Train loss=0.13362793624401093
[10/23] Train loss=0.13124315440654755
[15/23] Train loss=0.13189665973186493
[20/23] Train loss=0.12358003109693527
Test set avg_accuracy=88.31% avg_sensitivity=69.65%, avg_specificity=94.25% avg_auc=91.19%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.137821 Test loss=0.305664 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.13048730790615082
[5/23] Train loss=0.1283697783946991
[10/23] Train loss=0.12979301810264587
[15/23] Train loss=0.1300358772277832
[20/23] Train loss=0.1225883886218071
Test set avg_accuracy=87.94% avg_sensitivity=65.55%, avg_specificity=95.07% avg_auc=90.44%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.136767 Test loss=0.318037 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.13128992915153503
[5/23] Train loss=0.12985043227672577
[10/23] Train loss=0.12685626745224
[15/23] Train loss=0.1294008195400238
[20/23] Train loss=0.12043649703264236
Test set avg_accuracy=87.99% avg_sensitivity=67.55%, avg_specificity=94.51% avg_auc=90.82%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.135254 Test loss=0.310760 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.1278715580701828
[5/23] Train loss=0.1297546923160553
[10/23] Train loss=0.12488238513469696
[15/23] Train loss=0.1275586038827896
[20/23] Train loss=0.12537017464637756
Test set avg_accuracy=88.41% avg_sensitivity=69.00%, avg_specificity=94.59% avg_auc=91.35%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.135282 Test loss=0.303550 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.12523627281188965
[5/23] Train loss=0.12672221660614014
[10/23] Train loss=0.1264076977968216
[15/23] Train loss=0.12645018100738525
[20/23] Train loss=0.1190737783908844
Test set avg_accuracy=88.18% avg_sensitivity=68.89%, avg_specificity=94.32% avg_auc=91.19%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.133999 Test loss=0.306403 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.12798896431922913
[5/23] Train loss=0.12413714081048965
[10/23] Train loss=0.126026451587677
[15/23] Train loss=0.124189592897892
[20/23] Train loss=0.11973095685243607
Test set avg_accuracy=87.83% avg_sensitivity=70.89%, avg_specificity=93.22% avg_auc=91.45%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.133945 Test loss=0.305389 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.1285504847764969
[5/23] Train loss=0.12325425446033478
[10/23] Train loss=0.12510250508785248
[15/23] Train loss=0.12337400764226913
[20/23] Train loss=0.11858504265546799
Test set avg_accuracy=87.94% avg_sensitivity=69.76%, avg_specificity=93.73% avg_auc=91.09%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.132237 Test loss=0.307516 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.1265828013420105
[5/23] Train loss=0.12349666655063629
[10/23] Train loss=0.1211625188589096
[15/23] Train loss=0.12331454455852509
[20/23] Train loss=0.12034377455711365
Test set avg_accuracy=88.26% avg_sensitivity=69.27%, avg_specificity=94.30% avg_auc=90.98%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.130518 Test loss=0.309928 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.12651821970939636
[5/23] Train loss=0.12267493456602097
[10/23] Train loss=0.12292010337114334
[15/23] Train loss=0.12377358227968216
[20/23] Train loss=0.1167021095752716
Test set avg_accuracy=88.36% avg_sensitivity=69.49%, avg_specificity=94.37% avg_auc=90.88%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.129697 Test loss=0.306751 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.1252538114786148
[5/23] Train loss=0.12771470844745636
[10/23] Train loss=0.12259256839752197
[15/23] Train loss=0.12469685077667236
[20/23] Train loss=0.1143937036395073
Test set avg_accuracy=88.05% avg_sensitivity=68.89%, avg_specificity=94.15% avg_auc=90.63%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.129789 Test loss=0.313228 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.12278918921947479
[5/23] Train loss=0.12079374492168427
[10/23] Train loss=0.12326506525278091
[15/23] Train loss=0.12228957563638687
[20/23] Train loss=0.11770258843898773
Test set avg_accuracy=88.10% avg_sensitivity=70.30%, avg_specificity=93.77% avg_auc=91.13%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.129070 Test loss=0.307014 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.1241985633969307
[5/23] Train loss=0.12226130813360214
[10/23] Train loss=0.11975212395191193
[15/23] Train loss=0.12079379707574844
[20/23] Train loss=0.11514666676521301
Test set avg_accuracy=88.07% avg_sensitivity=68.73%, avg_specificity=94.23% avg_auc=91.04%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.128574 Test loss=0.307171 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.12287808209657669
[5/23] Train loss=0.12283299118280411
[10/23] Train loss=0.12221851944923401
[15/23] Train loss=0.11951667070388794
[20/23] Train loss=0.1176338717341423
Test set avg_accuracy=88.05% avg_sensitivity=69.22%, avg_specificity=94.04% avg_auc=91.06%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.128234 Test loss=0.308129 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.12495815753936768
[5/23] Train loss=0.12117695063352585
[10/23] Train loss=0.12031741440296173
[15/23] Train loss=0.12168790400028229
[20/23] Train loss=0.11466215550899506
Test set avg_accuracy=87.92% avg_sensitivity=68.25%, avg_specificity=94.18% avg_auc=90.82%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.127608 Test loss=0.309437 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.12369417399168015
[5/23] Train loss=0.1234574243426323
[10/23] Train loss=0.12035265564918518
[15/23] Train loss=0.12148474901914597
[20/23] Train loss=0.11534824967384338
Test set avg_accuracy=88.05% avg_sensitivity=68.89%, avg_specificity=94.15% avg_auc=90.90%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.127836 Test loss=0.309511 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.12299120426177979
[5/23] Train loss=0.12015797942876816
[10/23] Train loss=0.11971350014209747
[15/23] Train loss=0.12348377704620361
[20/23] Train loss=0.1135677844285965
Test set avg_accuracy=87.99% avg_sensitivity=69.65%, avg_specificity=93.84% avg_auc=91.17%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.127116 Test loss=0.307068 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.12164155393838882
[5/23] Train loss=0.1208445131778717
[10/23] Train loss=0.12184631079435349
[15/23] Train loss=0.12369585782289505
[20/23] Train loss=0.11644687503576279
Test set avg_accuracy=88.15% avg_sensitivity=69.65%, avg_specificity=94.04% avg_auc=91.06%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.127467 Test loss=0.306991 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.12123410403728485
[5/23] Train loss=0.12013489007949829
[10/23] Train loss=0.1233423501253128
[15/23] Train loss=0.12101143598556519
[20/23] Train loss=0.1130404993891716
Test set avg_accuracy=88.29% avg_sensitivity=69.65%, avg_specificity=94.23% avg_auc=91.01%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.126932 Test loss=0.307186 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.1221417635679245
[5/23] Train loss=0.11999762058258057
[10/23] Train loss=0.12119220197200775
[15/23] Train loss=0.12018989026546478
[20/23] Train loss=0.11494386196136475
Test set avg_accuracy=88.32% avg_sensitivity=69.33%, avg_specificity=94.37% avg_auc=90.94%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.126672 Test loss=0.307837 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.12143252044916153
[5/23] Train loss=0.11930051445960999
[10/23] Train loss=0.1205856055021286
[15/23] Train loss=0.1199464276432991
[20/23] Train loss=0.11544758826494217
Test set avg_accuracy=88.33% avg_sensitivity=69.38%, avg_specificity=94.37% avg_auc=91.00%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.126587 Test loss=0.307309 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.12051861733198166
[5/23] Train loss=0.12200985103845596
[10/23] Train loss=0.12353697419166565
[15/23] Train loss=0.11939598619937897
[20/23] Train loss=0.1140344962477684
Test set avg_accuracy=88.32% avg_sensitivity=69.49%, avg_specificity=94.32% avg_auc=90.99%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.127100 Test loss=0.307464 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.12283438444137573
[5/23] Train loss=0.12195010483264923
[10/23] Train loss=0.11995487660169601
[15/23] Train loss=0.12049074470996857
[20/23] Train loss=0.11373961716890335
Test set avg_accuracy=88.32% avg_sensitivity=69.60%, avg_specificity=94.28% avg_auc=91.02%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.126641 Test loss=0.307081 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.12298814207315445
[5/23] Train loss=0.11884879320859909
[10/23] Train loss=0.11995407938957214
[15/23] Train loss=0.11996443569660187
[20/23] Train loss=0.11418384313583374
Test set avg_accuracy=88.32% avg_sensitivity=69.60%, avg_specificity=94.28% avg_auc=91.02%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.127075 Test loss=0.307040 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.12368471175432205
[5/23] Train loss=0.1201363205909729
[10/23] Train loss=0.11943347752094269
[15/23] Train loss=0.11910004913806915
[20/23] Train loss=0.11473441869020462
Test set avg_accuracy=88.35% avg_sensitivity=69.60%, avg_specificity=94.32% avg_auc=91.01%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.126782 Test loss=0.307263 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.12120691686868668
[5/23] Train loss=0.11918498575687408
[10/23] Train loss=0.11967527866363525
[15/23] Train loss=0.12063354253768921
[20/23] Train loss=0.11496792733669281
Test set avg_accuracy=88.33% avg_sensitivity=69.60%, avg_specificity=94.30% avg_auc=91.02%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.126392 Test loss=0.307218 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=87.38% sen=75.20%, spe=91.26%, auc=92.48%!
Fold[9] Avg_overlap=0.68%(±0.2642378714981276)
[0/24] Train loss=0.7188123464584351
[5/24] Train loss=0.7219334244728088
[10/24] Train loss=0.7139862179756165
[15/24] Train loss=0.7162184715270996
[20/24] Train loss=0.7040954828262329
Test set avg_accuracy=61.38% avg_sensitivity=40.32%, avg_specificity=67.48% avg_auc=56.06%
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.713822 Test loss=0.657500 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6982896327972412
[5/24] Train loss=0.6911786794662476
[10/24] Train loss=0.6966097950935364
[15/24] Train loss=0.6885016560554504
[20/24] Train loss=0.6815623044967651
Test set avg_accuracy=69.53% avg_sensitivity=47.10%, avg_specificity=76.03% avg_auc=67.47%
Best model saved!! Metric=-65.85833044894986!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.688318 Test loss=0.604428 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.671788215637207
[5/24] Train loss=0.6698991656303406
[10/24] Train loss=0.6634544730186462
[15/24] Train loss=0.66115403175354
[20/24] Train loss=0.6536941528320312
Test set avg_accuracy=71.29% avg_sensitivity=54.23%, avg_specificity=76.23% avg_auc=73.05%
Best model saved!! Metric=-51.19881909979697!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.665599 Test loss=0.570429 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6373760104179382
[5/24] Train loss=0.6439639925956726
[10/24] Train loss=0.6475622653961182
[15/24] Train loss=0.6372523903846741
[20/24] Train loss=0.6281450986862183
Test set avg_accuracy=74.01% avg_sensitivity=58.23%, avg_specificity=78.59% avg_auc=76.19%
Best model saved!! Metric=-38.983331462579144!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.643233 Test loss=0.541321 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.610084593296051
[5/24] Train loss=0.6167525053024292
[10/24] Train loss=0.6277868151664734
[15/24] Train loss=0.6100239157676697
[20/24] Train loss=0.6101344227790833
Test set avg_accuracy=75.23% avg_sensitivity=60.83%, avg_specificity=79.41% avg_auc=79.01%
Best model saved!! Metric=-31.516843982457623!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.619341 Test loss=0.514767 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5884369015693665
[5/24] Train loss=0.5959545969963074
[10/24] Train loss=0.6024647951126099
[15/24] Train loss=0.5876333117485046
[20/24] Train loss=0.5835797786712646
Test set avg_accuracy=75.92% avg_sensitivity=65.99%, avg_specificity=78.80% avg_auc=81.51%
Best model saved!! Metric=-23.775037716537142!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.594816 Test loss=0.497047 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5686586499214172
[5/24] Train loss=0.5725439190864563
[10/24] Train loss=0.5766879916191101
[15/24] Train loss=0.5610644817352295
[20/24] Train loss=0.5518264174461365
Test set avg_accuracy=78.52% avg_sensitivity=68.37%, avg_specificity=81.46% avg_auc=83.46%
Best model saved!! Metric=-14.19893848809393!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.570908 Test loss=0.473332 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5370743870735168
[5/24] Train loss=0.5412077307701111
[10/24] Train loss=0.5493211150169373
[15/24] Train loss=0.5322105288505554
[20/24] Train loss=0.5239202380180359
Test set avg_accuracy=80.08% avg_sensitivity=69.76%, avg_specificity=83.07% avg_auc=85.16%
Best model saved!! Metric=-7.933926841250269!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.544001 Test loss=0.444859 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5164600610733032
[5/24] Train loss=0.5112931132316589
[10/24] Train loss=0.5238082408905029
[15/24] Train loss=0.5064982771873474
[20/24] Train loss=0.4920286238193512
Test set avg_accuracy=82.07% avg_sensitivity=70.28%, avg_specificity=85.49% avg_auc=86.66%
Best model saved!! Metric=-1.498593531603447!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.516565 Test loss=0.419088 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4938349723815918
[5/24] Train loss=0.48230186104774475
[10/24] Train loss=0.49231401085853577
[15/24] Train loss=0.4750625193119049
[20/24] Train loss=0.4669904410839081
Test set avg_accuracy=83.70% avg_sensitivity=72.65%, avg_specificity=86.90% avg_auc=88.17%
Best model saved!! Metric=5.424753275336229!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.486641 Test loss=0.401296 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.47204700112342834
[5/24] Train loss=0.45158037543296814
[10/24] Train loss=0.467278391122818
[15/24] Train loss=0.458182156085968
[20/24] Train loss=0.43999192118644714
Test set avg_accuracy=84.93% avg_sensitivity=71.73%, avg_specificity=88.76% avg_auc=89.22%
Best model saved!! Metric=8.6472813645847!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.461315 Test loss=0.375666 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4505191147327423
[5/24] Train loss=0.4295068383216858
[10/24] Train loss=0.44831517338752747
[15/24] Train loss=0.4294167757034302
[20/24] Train loss=0.4120844602584839
Test set avg_accuracy=85.52% avg_sensitivity=72.94%, avg_specificity=89.17% avg_auc=90.23%
Best model saved!! Metric=11.862496980195658!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.438765 Test loss=0.364116 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.44168615341186523
[5/24] Train loss=0.40182429552078247
[10/24] Train loss=0.4249141216278076
[15/24] Train loss=0.4090636670589447
[20/24] Train loss=0.391911119222641
Test set avg_accuracy=86.38% avg_sensitivity=71.26%, avg_specificity=90.76% avg_auc=91.01%
Best model saved!! Metric=13.420346884940443!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.418055 Test loss=0.340452 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.42390045523643494
[5/24] Train loss=0.3858450651168823
[10/24] Train loss=0.4079524874687195
[15/24] Train loss=0.3915018141269684
[20/24] Train loss=0.37466827034950256
Test set avg_accuracy=87.20% avg_sensitivity=70.10%, avg_specificity=92.16% avg_auc=91.46%
Best model saved!! Metric=14.916758220703684!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.399868 Test loss=0.325871 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.40514159202575684
[5/24] Train loss=0.3736596703529358
[10/24] Train loss=0.38635802268981934
[15/24] Train loss=0.38268446922302246
[20/24] Train loss=0.362859308719635
Test set avg_accuracy=87.53% avg_sensitivity=65.35%, avg_specificity=93.95% avg_auc=91.61%
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.384690 Test loss=0.310510 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.38889065384864807
[5/24] Train loss=0.35899385809898376
[10/24] Train loss=0.37717902660369873
[15/24] Train loss=0.3657839000225067
[20/24] Train loss=0.34521207213401794
Test set avg_accuracy=87.38% avg_sensitivity=61.12%, avg_specificity=94.99% avg_auc=91.77%
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.369552 Test loss=0.304087 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.372774213552475
[5/24] Train loss=0.3466392755508423
[10/24] Train loss=0.35794392228126526
[15/24] Train loss=0.3498534560203552
[20/24] Train loss=0.33883947134017944
Test set avg_accuracy=87.25% avg_sensitivity=56.89%, avg_specificity=96.05% avg_auc=91.64%
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.357387 Test loss=0.303459 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3599146902561188
[5/24] Train loss=0.33868277072906494
[10/24] Train loss=0.3551400899887085
[15/24] Train loss=0.3385554850101471
[20/24] Train loss=0.3238791227340698
Test set avg_accuracy=86.78% avg_sensitivity=51.45%, avg_specificity=97.03% avg_auc=91.72%
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.347467 Test loss=0.308421 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3560441732406616
[5/24] Train loss=0.3200375437736511
[10/24] Train loss=0.34228065609931946
[15/24] Train loss=0.3244464695453644
[20/24] Train loss=0.313802033662796
Test set avg_accuracy=87.84% avg_sensitivity=59.27%, avg_specificity=96.12% avg_auc=92.64%
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.336900 Test loss=0.290323 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.34677475690841675
[5/24] Train loss=0.3071140646934509
[10/24] Train loss=0.3359053432941437
[15/24] Train loss=0.32271409034729004
[20/24] Train loss=0.30923134088516235
Test set avg_accuracy=87.43% avg_sensitivity=54.06%, avg_specificity=97.11% avg_auc=92.52%
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.328728 Test loss=0.293308 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.334398090839386
[5/24] Train loss=0.29797011613845825
[10/24] Train loss=0.32986825704574585
[15/24] Train loss=0.30888840556144714
[20/24] Train loss=0.30310502648353577
Test set avg_accuracy=87.99% avg_sensitivity=57.82%, avg_specificity=96.74% avg_auc=93.12%
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.320159 Test loss=0.280592 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3281741738319397
[5/24] Train loss=0.2959336042404175
[10/24] Train loss=0.32467448711395264
[15/24] Train loss=0.3050001859664917
[20/24] Train loss=0.29111239314079285
Test set avg_accuracy=88.92% avg_sensitivity=62.05%, avg_specificity=96.71% avg_auc=93.24%
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.313555 Test loss=0.274443 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3220643401145935
[5/24] Train loss=0.29787570238113403
[10/24] Train loss=0.3167631924152374
[15/24] Train loss=0.30639827251434326
[20/24] Train loss=0.28584951162338257
Test set avg_accuracy=88.75% avg_sensitivity=60.95%, avg_specificity=96.81% avg_auc=93.43%
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.307331 Test loss=0.270822 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3153392970561981
[5/24] Train loss=0.29197344183921814
[10/24] Train loss=0.30956313014030457
[15/24] Train loss=0.2919466197490692
[20/24] Train loss=0.28158625960350037
Test set avg_accuracy=88.96% avg_sensitivity=61.12%, avg_specificity=97.03% avg_auc=93.17%
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.302843 Test loss=0.274354 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3147957921028137
[5/24] Train loss=0.28186556696891785
[10/24] Train loss=0.307388573884964
[15/24] Train loss=0.2905907928943634
[20/24] Train loss=0.27588802576065063
Test set avg_accuracy=89.60% avg_sensitivity=64.37%, avg_specificity=96.91% avg_auc=93.58%
Best model saved!! Metric=18.451985462764085!!
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.298797 Test loss=0.265105 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2986871898174286
[5/24] Train loss=0.27400732040405273
[10/24] Train loss=0.30136874318122864
[15/24] Train loss=0.2866256535053253
[20/24] Train loss=0.2754257917404175
Test set avg_accuracy=88.36% avg_sensitivity=55.56%, avg_specificity=97.87% avg_auc=93.06%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.294030 Test loss=0.283124 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.31051263213157654
[5/24] Train loss=0.27128350734710693
[10/24] Train loss=0.29718706011772156
[15/24] Train loss=0.28141462802886963
[20/24] Train loss=0.2638511657714844
Test set avg_accuracy=89.54% avg_sensitivity=65.24%, avg_specificity=96.59% avg_auc=93.50%
Best model saved!! Metric=18.87632410696341!!
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.289971 Test loss=0.261646 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.29695266485214233
[5/24] Train loss=0.26297298073768616
[10/24] Train loss=0.28985077142715454
[15/24] Train loss=0.2761993408203125
[20/24] Train loss=0.2650163769721985
Test set avg_accuracy=89.34% avg_sensitivity=64.25%, avg_specificity=96.61% avg_auc=92.96%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.285368 Test loss=0.271062 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2972261607646942
[5/24] Train loss=0.26267117261886597
[10/24] Train loss=0.2858348786830902
[15/24] Train loss=0.28213584423065186
[20/24] Train loss=0.2630639672279358
Test set avg_accuracy=89.69% avg_sensitivity=66.51%, avg_specificity=96.41% avg_auc=93.34%
Best model saved!! Metric=19.947943625150884!!
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.282701 Test loss=0.262571 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2915627062320709
[5/24] Train loss=0.26314684748649597
[10/24] Train loss=0.2849023938179016
[15/24] Train loss=0.2716066837310791
[20/24] Train loss=0.2575892210006714
Test set avg_accuracy=89.04% avg_sensitivity=58.81%, avg_specificity=97.80% avg_auc=93.55%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.281704 Test loss=0.270717 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.289518803358078
[5/24] Train loss=0.2641626000404358
[10/24] Train loss=0.27854692935943604
[15/24] Train loss=0.26961013674736023
[20/24] Train loss=0.2633070647716522
Test set avg_accuracy=89.83% avg_sensitivity=66.28%, avg_specificity=96.66% avg_auc=94.02%
Best model saved!! Metric=20.78731716013222!!
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.279653 Test loss=0.253744 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.28663402795791626
[5/24] Train loss=0.25641193985939026
[10/24] Train loss=0.2892360985279083
[15/24] Train loss=0.2675743103027344
[20/24] Train loss=0.26062747836112976
Test set avg_accuracy=89.79% avg_sensitivity=66.57%, avg_specificity=96.52% avg_auc=93.66%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.277622 Test loss=0.256860 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.28821301460266113
[5/24] Train loss=0.25511226058006287
[10/24] Train loss=0.27303147315979004
[15/24] Train loss=0.26543760299682617
[20/24] Train loss=0.25433677434921265
Test set avg_accuracy=89.62% avg_sensitivity=76.25%, avg_specificity=93.50% avg_auc=93.45%
Best model saved!! Metric=26.822379018440003!!
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.273574 Test loss=0.264552 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.28553444147109985
[5/24] Train loss=0.24386227130889893
[10/24] Train loss=0.2756216526031494
[15/24] Train loss=0.26272493600845337
[20/24] Train loss=0.255410760641098
Test set avg_accuracy=88.63% avg_sensitivity=56.43%, avg_specificity=97.97% avg_auc=93.15%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.273044 Test loss=0.279697 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.27550050616264343
[5/24] Train loss=0.24828040599822998
[10/24] Train loss=0.2798152565956116
[15/24] Train loss=0.2608807682991028
[20/24] Train loss=0.2531214952468872
Test set avg_accuracy=89.86% avg_sensitivity=74.62%, avg_specificity=94.27% avg_auc=93.85%
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.271514 Test loss=0.255637 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.28483062982559204
[5/24] Train loss=0.24692842364311218
[10/24] Train loss=0.2621435821056366
[15/24] Train loss=0.2678090035915375
[20/24] Train loss=0.2575173079967499
Test set avg_accuracy=89.79% avg_sensitivity=71.96%, avg_specificity=94.96% avg_auc=93.97%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.270138 Test loss=0.251078 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2826153635978699
[5/24] Train loss=0.2420186549425125
[10/24] Train loss=0.24970898032188416
[15/24] Train loss=0.26335954666137695
[20/24] Train loss=0.24362988770008087
Test set avg_accuracy=88.28% avg_sensitivity=56.20%, avg_specificity=97.58% avg_auc=91.87%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.265622 Test loss=0.293545 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2778118848800659
[5/24] Train loss=0.2459225207567215
[10/24] Train loss=0.26017138361930847
[15/24] Train loss=0.26100847125053406
[20/24] Train loss=0.25495457649230957
Test set avg_accuracy=89.53% avg_sensitivity=74.97%, avg_specificity=93.75% avg_auc=93.57%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.267436 Test loss=0.262442 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.27765530347824097
[5/24] Train loss=0.24740156531333923
[10/24] Train loss=0.24788020551204681
[15/24] Train loss=0.2551136016845703
[20/24] Train loss=0.2569226622581482
Test set avg_accuracy=89.84% avg_sensitivity=68.25%, avg_specificity=96.10% avg_auc=94.04%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.265357 Test loss=0.256114 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.28401345014572144
[5/24] Train loss=0.24071910977363586
[10/24] Train loss=0.2683432400226593
[15/24] Train loss=0.2690030634403229
[20/24] Train loss=0.24951773881912231
Test set avg_accuracy=88.52% avg_sensitivity=56.37%, avg_specificity=97.83% avg_auc=92.95%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.269610 Test loss=0.284319 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2839354872703552
[5/24] Train loss=0.24064435064792633
[10/24] Train loss=0.26051104068756104
[15/24] Train loss=0.2582941949367523
[20/24] Train loss=0.24450547993183136
Test set avg_accuracy=89.67% avg_sensitivity=67.15%, avg_specificity=96.20% avg_auc=93.41%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.262010 Test loss=0.260094 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.28492456674575806
[5/24] Train loss=0.23336392641067505
[10/24] Train loss=0.25895223021507263
[15/24] Train loss=0.24434514343738556
[20/24] Train loss=0.24332767724990845
Test set avg_accuracy=88.78% avg_sensitivity=58.75%, avg_specificity=97.48% avg_auc=93.23%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.258928 Test loss=0.275625 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.27141469717025757
[5/24] Train loss=0.2280164361000061
[10/24] Train loss=0.249431312084198
[15/24] Train loss=0.25425735116004944
[20/24] Train loss=0.24736274778842926
Test set avg_accuracy=89.69% avg_sensitivity=71.67%, avg_specificity=94.91% avg_auc=93.28%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.257872 Test loss=0.263040 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.27238646149635315
[5/24] Train loss=0.23154614865779877
[10/24] Train loss=0.2552003562450409
[15/24] Train loss=0.2444167584180832
[20/24] Train loss=0.23696105182170868
Test set avg_accuracy=88.23% avg_sensitivity=55.79%, avg_specificity=97.63% avg_auc=92.45%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.255178 Test loss=0.288069 Current lr=[0.00029967723776099]

[0/24] Train loss=0.27497953176498413
[5/24] Train loss=0.22088634967803955
[10/24] Train loss=0.24678611755371094
[15/24] Train loss=0.24937951564788818
[20/24] Train loss=0.23728717863559723
Test set avg_accuracy=89.30% avg_sensitivity=76.19%, avg_specificity=93.10% avg_auc=93.53%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.253223 Test loss=0.267047 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2626922130584717
[5/24] Train loss=0.224213644862175
[10/24] Train loss=0.24753056466579437
[15/24] Train loss=0.2514556646347046
[20/24] Train loss=0.2434304803609848
Test set avg_accuracy=88.41% avg_sensitivity=60.25%, avg_specificity=96.57% avg_auc=92.61%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.253865 Test loss=0.282983 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.27000442147254944
[5/24] Train loss=0.22775492072105408
[10/24] Train loss=0.2416083812713623
[15/24] Train loss=0.24390143156051636
[20/24] Train loss=0.24042417109012604
Test set avg_accuracy=89.60% avg_sensitivity=67.44%, avg_specificity=96.02% avg_auc=93.08%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.253426 Test loss=0.266702 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2761915326118469
[5/24] Train loss=0.228676438331604
[10/24] Train loss=0.25511571764945984
[15/24] Train loss=0.2456277459859848
[20/24] Train loss=0.25743594765663147
Test set avg_accuracy=88.97% avg_sensitivity=66.69%, avg_specificity=95.43% avg_auc=93.27%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.254585 Test loss=0.265863 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2527417838573456
[5/24] Train loss=0.2361978441476822
[10/24] Train loss=0.24479679763317108
[15/24] Train loss=0.23983511328697205
[20/24] Train loss=0.2463718056678772
Test set avg_accuracy=88.58% avg_sensitivity=62.57%, avg_specificity=96.12% avg_auc=92.62%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.254638 Test loss=0.278379 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2649391293525696
[5/24] Train loss=0.23575100302696228
[10/24] Train loss=0.23359684646129608
[15/24] Train loss=0.2517620623111725
[20/24] Train loss=0.24208663403987885
Test set avg_accuracy=87.92% avg_sensitivity=56.60%, avg_specificity=96.99% avg_auc=92.26%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.255041 Test loss=0.290924 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.26111260056495667
[5/24] Train loss=0.231793612241745
[10/24] Train loss=0.2448277324438095
[15/24] Train loss=0.23331385850906372
[20/24] Train loss=0.2396671175956726
Test set avg_accuracy=88.74% avg_sensitivity=62.80%, avg_specificity=96.25% avg_auc=92.95%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.248007 Test loss=0.273794 Current lr=[0.000297555943323901]

[0/24] Train loss=0.24820291996002197
[5/24] Train loss=0.22108179330825806
[10/24] Train loss=0.23462210595607758
[15/24] Train loss=0.23851606249809265
[20/24] Train loss=0.24032928049564362
Test set avg_accuracy=89.05% avg_sensitivity=65.99%, avg_specificity=95.73% avg_auc=93.16%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.245967 Test loss=0.267342 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2480519413948059
[5/24] Train loss=0.2155729979276657
[10/24] Train loss=0.2365141659975052
[15/24] Train loss=0.22959810495376587
[20/24] Train loss=0.23745553195476532
Test set avg_accuracy=86.48% avg_sensitivity=45.02%, avg_specificity=98.51% avg_auc=91.23%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.240714 Test loss=0.329601 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.25534987449645996
[5/24] Train loss=0.21899816393852234
[10/24] Train loss=0.24152877926826477
[15/24] Train loss=0.2410978078842163
[20/24] Train loss=0.231382817029953
Test set avg_accuracy=88.58% avg_sensitivity=61.88%, avg_specificity=96.32% avg_auc=91.59%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.241894 Test loss=0.289719 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.25686123967170715
[5/24] Train loss=0.21993085741996765
[10/24] Train loss=0.2332315593957901
[15/24] Train loss=0.2390449494123459
[20/24] Train loss=0.23843197524547577
Test set avg_accuracy=87.07% avg_sensitivity=49.02%, avg_specificity=98.10% avg_auc=91.23%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.242343 Test loss=0.322196 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2515113353729248
[5/24] Train loss=0.2055671513080597
[10/24] Train loss=0.21162284910678864
[15/24] Train loss=0.23179487884044647
[20/24] Train loss=0.22475488483905792
Test set avg_accuracy=88.40% avg_sensitivity=56.49%, avg_specificity=97.65% avg_auc=92.02%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.236841 Test loss=0.288352 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.23731985688209534
[5/24] Train loss=0.20963715016841888
[10/24] Train loss=0.22356702387332916
[15/24] Train loss=0.23549440503120422
[20/24] Train loss=0.22959166765213013
Test set avg_accuracy=87.96% avg_sensitivity=56.55%, avg_specificity=97.06% avg_auc=91.26%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.235145 Test loss=0.299439 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2452823966741562
[5/24] Train loss=0.20889034867286682
[10/24] Train loss=0.2267143428325653
[15/24] Train loss=0.23683051764965057
[20/24] Train loss=0.22203519940376282
Test set avg_accuracy=88.16% avg_sensitivity=63.21%, avg_specificity=95.40% avg_auc=91.78%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.238140 Test loss=0.287674 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.24291008710861206
[5/24] Train loss=0.21212343871593475
[10/24] Train loss=0.2253616750240326
[15/24] Train loss=0.2396536022424698
[20/24] Train loss=0.2276759296655655
Test set avg_accuracy=86.94% avg_sensitivity=50.35%, avg_specificity=97.55% avg_auc=90.36%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.236696 Test loss=0.326489 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.24107667803764343
[5/24] Train loss=0.23295782506465912
[10/24] Train loss=0.2232373058795929
[15/24] Train loss=0.2320166677236557
[20/24] Train loss=0.23578521609306335
Test set avg_accuracy=86.52% avg_sensitivity=70.16%, avg_specificity=91.27% avg_auc=89.99%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.238568 Test loss=0.322668 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.23462939262390137
[5/24] Train loss=0.21706882119178772
[10/24] Train loss=0.2298191338777542
[15/24] Train loss=0.23251484334468842
[20/24] Train loss=0.22827616333961487
Test set avg_accuracy=88.59% avg_sensitivity=70.57%, avg_specificity=93.82% avg_auc=92.31%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.237982 Test loss=0.278349 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2409583479166031
[5/24] Train loss=0.22833678126335144
[10/24] Train loss=0.225568026304245
[15/24] Train loss=0.2235458791255951
[20/24] Train loss=0.23400656878948212
Test set avg_accuracy=87.99% avg_sensitivity=55.39%, avg_specificity=97.45% avg_auc=89.50%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.236182 Test loss=0.327854 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.23421542346477509
[5/24] Train loss=0.20109394192695618
[10/24] Train loss=0.22072796523571014
[15/24] Train loss=0.22918960452079773
[20/24] Train loss=0.21848873794078827
Test set avg_accuracy=88.83% avg_sensitivity=73.75%, avg_specificity=93.20% avg_auc=93.66%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.229817 Test loss=0.261983 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2245224416255951
[5/24] Train loss=0.22447657585144043
[10/24] Train loss=0.2252202332019806
[15/24] Train loss=0.21716926991939545
[20/24] Train loss=0.22165267169475555
Test set avg_accuracy=89.40% avg_sensitivity=73.00%, avg_specificity=94.16% avg_auc=93.64%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.230146 Test loss=0.256865 Current lr=[0.000276307469034998]

[0/24] Train loss=0.23010332882404327
[5/24] Train loss=0.20941978693008423
[10/24] Train loss=0.2280256748199463
[15/24] Train loss=0.23243628442287445
[20/24] Train loss=0.22843191027641296
Test set avg_accuracy=86.65% avg_sensitivity=51.39%, avg_specificity=96.88% avg_auc=89.56%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.233267 Test loss=0.327063 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.24452532827854156
[5/24] Train loss=0.21628634631633759
[10/24] Train loss=0.2216108739376068
[15/24] Train loss=0.22687239944934845
[20/24] Train loss=0.23008042573928833
Test set avg_accuracy=87.90% avg_sensitivity=76.36%, avg_specificity=91.25% avg_auc=92.84%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.233164 Test loss=0.283241 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.24269136786460876
[5/24] Train loss=0.2078533172607422
[10/24] Train loss=0.20882293581962585
[15/24] Train loss=0.22334910929203033
[20/24] Train loss=0.21248012781143188
Test set avg_accuracy=88.37% avg_sensitivity=78.16%, avg_specificity=91.33% avg_auc=93.17%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.226390 Test loss=0.275616 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2433970868587494
[5/24] Train loss=0.21406197547912598
[10/24] Train loss=0.23292605578899384
[15/24] Train loss=0.22907496988773346
[20/24] Train loss=0.22422908246517181
Test set avg_accuracy=88.95% avg_sensitivity=71.84%, avg_specificity=93.90% avg_auc=92.76%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.229410 Test loss=0.270719 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.23189517855644226
[5/24] Train loss=0.19495101273059845
[10/24] Train loss=0.21561801433563232
[15/24] Train loss=0.218460351228714
[20/24] Train loss=0.22054289281368256
Test set avg_accuracy=89.24% avg_sensitivity=68.48%, avg_specificity=95.26% avg_auc=92.82%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.224288 Test loss=0.268688 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.22402647137641907
[5/24] Train loss=0.1958189755678177
[10/24] Train loss=0.2175012230873108
[15/24] Train loss=0.2272869497537613
[20/24] Train loss=0.2241724729537964
Test set avg_accuracy=89.22% avg_sensitivity=65.53%, avg_specificity=96.09% avg_auc=92.34%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.220086 Test loss=0.272789 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.22391700744628906
[5/24] Train loss=0.2041245847940445
[10/24] Train loss=0.22435863316059113
[15/24] Train loss=0.22997869551181793
[20/24] Train loss=0.21997608244419098
Test set avg_accuracy=86.33% avg_sensitivity=78.74%, avg_specificity=88.53% avg_auc=91.42%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.222623 Test loss=0.327774 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.22269999980926514
[5/24] Train loss=0.1974673867225647
[10/24] Train loss=0.21079474687576294
[15/24] Train loss=0.21753111481666565
[20/24] Train loss=0.21306942403316498
Test set avg_accuracy=89.43% avg_sensitivity=69.47%, avg_specificity=95.21% avg_auc=92.94%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.221016 Test loss=0.265997 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.22184357047080994
[5/24] Train loss=0.19786357879638672
[10/24] Train loss=0.23031874001026154
[15/24] Train loss=0.2086561620235443
[20/24] Train loss=0.22358594834804535
Test set avg_accuracy=89.09% avg_sensitivity=73.87%, avg_specificity=93.50% avg_auc=92.56%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.221680 Test loss=0.270147 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.22349928319454193
[5/24] Train loss=0.20108339190483093
[10/24] Train loss=0.2088596224784851
[15/24] Train loss=0.21717222034931183
[20/24] Train loss=0.21550452709197998
Test set avg_accuracy=88.87% avg_sensitivity=68.71%, avg_specificity=94.71% avg_auc=92.66%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.221468 Test loss=0.272489 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.21653802692890167
[5/24] Train loss=0.1846500039100647
[10/24] Train loss=0.22887997329235077
[15/24] Train loss=0.21713198721408844
[20/24] Train loss=0.2135939598083496
Test set avg_accuracy=88.65% avg_sensitivity=71.67%, avg_specificity=93.57% avg_auc=91.86%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.218788 Test loss=0.287956 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.21789857745170593
[5/24] Train loss=0.20212966203689575
[10/24] Train loss=0.2071877419948578
[15/24] Train loss=0.21262329816818237
[20/24] Train loss=0.2254289835691452
Test set avg_accuracy=86.30% avg_sensitivity=49.02%, avg_specificity=97.11% avg_auc=87.71%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.219872 Test loss=0.338995 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.24610669910907745
[5/24] Train loss=0.1947064995765686
[10/24] Train loss=0.221078023314476
[15/24] Train loss=0.2170889973640442
[20/24] Train loss=0.21933801472187042
Test set avg_accuracy=88.11% avg_sensitivity=74.39%, avg_specificity=92.09% avg_auc=91.28%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.221634 Test loss=0.299181 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2216206192970276
[5/24] Train loss=0.22160185873508453
[10/24] Train loss=0.21878215670585632
[15/24] Train loss=0.20677055418491364
[20/24] Train loss=0.21600405871868134
Test set avg_accuracy=88.70% avg_sensitivity=71.96%, avg_specificity=93.55% avg_auc=91.82%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.218711 Test loss=0.282917 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.22678948938846588
[5/24] Train loss=0.20393361151218414
[10/24] Train loss=0.2099875807762146
[15/24] Train loss=0.20652025938034058
[20/24] Train loss=0.2104191929101944
Test set avg_accuracy=87.20% avg_sensitivity=79.32%, avg_specificity=89.49% avg_auc=92.28%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.216983 Test loss=0.311795 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.21446450054645538
[5/24] Train loss=0.21060965955257416
[10/24] Train loss=0.21158957481384277
[15/24] Train loss=0.21383343636989594
[20/24] Train loss=0.21944160759449005
Test set avg_accuracy=89.93% avg_sensitivity=74.39%, avg_specificity=94.44% avg_auc=93.48%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.218464 Test loss=0.259312 Current lr=[0.000224838296036774]

[0/24] Train loss=0.21813710033893585
[5/24] Train loss=0.1929454207420349
[10/24] Train loss=0.2159852385520935
[15/24] Train loss=0.20583035051822662
[20/24] Train loss=0.21333357691764832
Test set avg_accuracy=88.23% avg_sensitivity=78.33%, avg_specificity=91.10% avg_auc=92.63%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.219124 Test loss=0.287729 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.21991947293281555
[5/24] Train loss=0.19538289308547974
[10/24] Train loss=0.20727810263633728
[15/24] Train loss=0.20502829551696777
[20/24] Train loss=0.21686208248138428
Test set avg_accuracy=89.83% avg_sensitivity=74.33%, avg_specificity=94.32% avg_auc=93.16%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.214455 Test loss=0.263500 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.21007172763347626
[5/24] Train loss=0.19447410106658936
[10/24] Train loss=0.20221789181232452
[15/24] Train loss=0.20473159849643707
[20/24] Train loss=0.20118768513202667
Test set avg_accuracy=88.82% avg_sensitivity=76.01%, avg_specificity=92.53% avg_auc=92.43%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.209923 Test loss=0.285871 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.21183018386363983
[5/24] Train loss=0.1812615841627121
[10/24] Train loss=0.2135094404220581
[15/24] Train loss=0.20307102799415588
[20/24] Train loss=0.20696613192558289
Test set avg_accuracy=88.20% avg_sensitivity=73.58%, avg_specificity=92.44% avg_auc=91.61%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.209213 Test loss=0.292056 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.20542654395103455
[5/24] Train loss=0.18817077577114105
[10/24] Train loss=0.1887608766555786
[15/24] Train loss=0.20483221113681793
[20/24] Train loss=0.20354023575782776
Test set avg_accuracy=89.31% avg_sensitivity=72.02%, avg_specificity=94.32% avg_auc=92.26%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.205062 Test loss=0.274545 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2002672404050827
[5/24] Train loss=0.18119987845420837
[10/24] Train loss=0.18751774728298187
[15/24] Train loss=0.19934070110321045
[20/24] Train loss=0.20079797506332397
Test set avg_accuracy=88.87% avg_sensitivity=74.86%, avg_specificity=92.93% avg_auc=93.10%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.200607 Test loss=0.274387 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.20564433932304382
[5/24] Train loss=0.18116503953933716
[10/24] Train loss=0.1924566626548767
[15/24] Train loss=0.19648227095603943
[20/24] Train loss=0.19115585088729858
Test set avg_accuracy=89.49% avg_sensitivity=69.12%, avg_specificity=95.40% avg_auc=92.32%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.201784 Test loss=0.274392 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.19836445152759552
[5/24] Train loss=0.17980389297008514
[10/24] Train loss=0.19118493795394897
[15/24] Train loss=0.1992899626493454
[20/24] Train loss=0.1970020979642868
Test set avg_accuracy=88.89% avg_sensitivity=69.93%, avg_specificity=94.39% avg_auc=91.05%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.198363 Test loss=0.284529 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.20358146727085114
[5/24] Train loss=0.17671479284763336
[10/24] Train loss=0.19435183703899384
[15/24] Train loss=0.1983042061328888
[20/24] Train loss=0.2087477594614029
Test set avg_accuracy=88.89% avg_sensitivity=72.07%, avg_specificity=93.77% avg_auc=91.87%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.201379 Test loss=0.282948 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.20022018253803253
[5/24] Train loss=0.19288168847560883
[10/24] Train loss=0.181289941072464
[15/24] Train loss=0.19021159410476685
[20/24] Train loss=0.19160528481006622
Test set avg_accuracy=88.70% avg_sensitivity=70.51%, avg_specificity=93.97% avg_auc=92.19%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.199142 Test loss=0.282505 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2008347362279892
[5/24] Train loss=0.18669798970222473
[10/24] Train loss=0.1852155178785324
[15/24] Train loss=0.2029116451740265
[20/24] Train loss=0.19776853919029236
Test set avg_accuracy=88.46% avg_sensitivity=72.13%, avg_specificity=93.20% avg_auc=91.58%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.201701 Test loss=0.290155 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.20492704212665558
[5/24] Train loss=0.18725071847438812
[10/24] Train loss=0.21198725700378418
[15/24] Train loss=0.19593121111392975
[20/24] Train loss=0.194247305393219
Test set avg_accuracy=88.84% avg_sensitivity=67.44%, avg_specificity=95.05% avg_auc=91.46%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.201883 Test loss=0.289129 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.20787103474140167
[5/24] Train loss=0.18663257360458374
[10/24] Train loss=0.19943661987781525
[15/24] Train loss=0.2006710320711136
[20/24] Train loss=0.19247379899024963
Test set avg_accuracy=89.67% avg_sensitivity=68.77%, avg_specificity=95.73% avg_auc=91.21%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.203740 Test loss=0.279514 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.20281372964382172
[5/24] Train loss=0.18434451520442963
[10/24] Train loss=0.18998491764068604
[15/24] Train loss=0.1965106874704361
[20/24] Train loss=0.20036867260932922
Test set avg_accuracy=89.06% avg_sensitivity=62.11%, avg_specificity=96.88% avg_auc=91.01%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.199955 Test loss=0.290125 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.20358644425868988
[5/24] Train loss=0.1860276460647583
[10/24] Train loss=0.18926496803760529
[15/24] Train loss=0.1993338018655777
[20/24] Train loss=0.19367177784442902
Test set avg_accuracy=86.98% avg_sensitivity=51.27%, avg_specificity=97.33% avg_auc=88.37%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.198927 Test loss=0.348150 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.21383331716060638
[5/24] Train loss=0.1851097196340561
[10/24] Train loss=0.1874261051416397
[15/24] Train loss=0.19120214879512787
[20/24] Train loss=0.19960728287696838
Test set avg_accuracy=88.54% avg_sensitivity=60.37%, avg_specificity=96.71% avg_auc=89.25%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.198342 Test loss=0.309411 Current lr=[0.000156543481933168]

[0/24] Train loss=0.19421403110027313
[5/24] Train loss=0.18045896291732788
[10/24] Train loss=0.18487469851970673
[15/24] Train loss=0.19263838231563568
[20/24] Train loss=0.21041375398635864
Test set avg_accuracy=89.96% avg_sensitivity=69.64%, avg_specificity=95.85% avg_auc=91.90%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.195467 Test loss=0.272386 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.19750678539276123
[5/24] Train loss=0.17848610877990723
[10/24] Train loss=0.188877135515213
[15/24] Train loss=0.1863206923007965
[20/24] Train loss=0.191945418715477
Test set avg_accuracy=88.88% avg_sensitivity=60.66%, avg_specificity=97.06% avg_auc=90.50%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.193474 Test loss=0.301682 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.19531504809856415
[5/24] Train loss=0.17121462523937225
[10/24] Train loss=0.184634730219841
[15/24] Train loss=0.19129925966262817
[20/24] Train loss=0.1913803219795227
Test set avg_accuracy=88.37% avg_sensitivity=57.59%, avg_specificity=97.30% avg_auc=88.48%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.193089 Test loss=0.316916 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.19546449184417725
[5/24] Train loss=0.16689841449260712
[10/24] Train loss=0.17562295496463776
[15/24] Train loss=0.17964354157447815
[20/24] Train loss=0.1921306550502777
Test set avg_accuracy=89.65% avg_sensitivity=67.32%, avg_specificity=96.12% avg_auc=92.09%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.191454 Test loss=0.279264 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1917964369058609
[5/24] Train loss=0.17496010661125183
[10/24] Train loss=0.17051927745342255
[15/24] Train loss=0.1774199903011322
[20/24] Train loss=0.18368111550807953
Test set avg_accuracy=89.39% avg_sensitivity=66.11%, avg_specificity=96.14% avg_auc=90.71%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.187627 Test loss=0.286145 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1908530294895172
[5/24] Train loss=0.16576316952705383
[10/24] Train loss=0.17527970671653748
[15/24] Train loss=0.17784886062145233
[20/24] Train loss=0.18516603112220764
Test set avg_accuracy=89.13% avg_sensitivity=72.83%, avg_specificity=93.85% avg_auc=91.89%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.182754 Test loss=0.279715 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.184060737490654
[5/24] Train loss=0.1682320386171341
[10/24] Train loss=0.16706730425357819
[15/24] Train loss=0.1868947148323059
[20/24] Train loss=0.17269718647003174
Test set avg_accuracy=88.44% avg_sensitivity=71.26%, avg_specificity=93.42% avg_auc=91.23%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.179935 Test loss=0.290927 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1893935203552246
[5/24] Train loss=0.1645534634590149
[10/24] Train loss=0.16957665979862213
[15/24] Train loss=0.17362581193447113
[20/24] Train loss=0.18478548526763916
Test set avg_accuracy=89.86% avg_sensitivity=71.32%, avg_specificity=95.23% avg_auc=91.05%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.175898 Test loss=0.282442 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.1782972812652588
[5/24] Train loss=0.16195526719093323
[10/24] Train loss=0.16378876566886902
[15/24] Train loss=0.17543792724609375
[20/24] Train loss=0.17795556783676147
Test set avg_accuracy=89.28% avg_sensitivity=71.84%, avg_specificity=94.34% avg_auc=92.34%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.175903 Test loss=0.276760 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1791001260280609
[5/24] Train loss=0.16693156957626343
[10/24] Train loss=0.16526684165000916
[15/24] Train loss=0.1678217351436615
[20/24] Train loss=0.16768580675125122
Test set avg_accuracy=89.27% avg_sensitivity=70.74%, avg_specificity=94.64% avg_auc=91.60%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.172629 Test loss=0.282373 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.17933320999145508
[5/24] Train loss=0.16500960290431976
[10/24] Train loss=0.15954452753067017
[15/24] Train loss=0.16468015313148499
[20/24] Train loss=0.16301019489765167
Test set avg_accuracy=89.49% avg_sensitivity=69.76%, avg_specificity=95.21% avg_auc=91.42%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.169673 Test loss=0.280362 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1729588657617569
[5/24] Train loss=0.16106466948986053
[10/24] Train loss=0.15745215117931366
[15/24] Train loss=0.16725385189056396
[20/24] Train loss=0.16927418112754822
Test set avg_accuracy=89.21% avg_sensitivity=71.21%, avg_specificity=94.42% avg_auc=91.08%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.168259 Test loss=0.283259 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.17461997270584106
[5/24] Train loss=0.15214091539382935
[10/24] Train loss=0.16106770932674408
[15/24] Train loss=0.1610742062330246
[20/24] Train loss=0.16819868981838226
Test set avg_accuracy=88.61% avg_sensitivity=75.55%, avg_specificity=92.39% avg_auc=91.46%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.167897 Test loss=0.292223 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1686137318611145
[5/24] Train loss=0.15384961664676666
[10/24] Train loss=0.1543169766664505
[15/24] Train loss=0.17133641242980957
[20/24] Train loss=0.16572873294353485
Test set avg_accuracy=88.62% avg_sensitivity=76.25%, avg_specificity=92.21% avg_auc=91.59%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.166185 Test loss=0.295908 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.16548746824264526
[5/24] Train loss=0.1567370444536209
[10/24] Train loss=0.15842066705226898
[15/24] Train loss=0.15748560428619385
[20/24] Train loss=0.1606321632862091
Test set avg_accuracy=88.63% avg_sensitivity=73.99%, avg_specificity=92.88% avg_auc=91.54%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.164116 Test loss=0.291264 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.17084971070289612
[5/24] Train loss=0.1482250988483429
[10/24] Train loss=0.1502913236618042
[15/24] Train loss=0.15388260781764984
[20/24] Train loss=0.16004639863967896
Test set avg_accuracy=88.83% avg_sensitivity=73.75%, avg_specificity=93.20% avg_auc=92.12%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.160610 Test loss=0.288870 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.16609103977680206
[5/24] Train loss=0.14829809963703156
[10/24] Train loss=0.148472398519516
[15/24] Train loss=0.15384528040885925
[20/24] Train loss=0.15198592841625214
Test set avg_accuracy=88.76% avg_sensitivity=75.67%, avg_specificity=92.56% avg_auc=91.89%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.159544 Test loss=0.288664 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.16372054815292358
[5/24] Train loss=0.14493219554424286
[10/24] Train loss=0.14803549647331238
[15/24] Train loss=0.1492391675710678
[20/24] Train loss=0.1497301161289215
Test set avg_accuracy=88.54% avg_sensitivity=74.51%, avg_specificity=92.61% avg_auc=91.89%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.156706 Test loss=0.293357 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.160163015127182
[5/24] Train loss=0.15040379762649536
[10/24] Train loss=0.1446746289730072
[15/24] Train loss=0.15327826142311096
[20/24] Train loss=0.1562710553407669
Test set avg_accuracy=88.79% avg_sensitivity=74.28%, avg_specificity=93.00% avg_auc=92.52%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.156887 Test loss=0.282263 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15834449231624603
[5/24] Train loss=0.14672143757343292
[10/24] Train loss=0.1559198796749115
[15/24] Train loss=0.15075823664665222
[20/24] Train loss=0.1509680300951004
Test set avg_accuracy=89.04% avg_sensitivity=73.75%, avg_specificity=93.47% avg_auc=91.84%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.155599 Test loss=0.281941 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.15968507528305054
[5/24] Train loss=0.14513419568538666
[10/24] Train loss=0.15019309520721436
[15/24] Train loss=0.14960990846157074
[20/24] Train loss=0.1531650871038437
Test set avg_accuracy=88.95% avg_sensitivity=70.97%, avg_specificity=94.16% avg_auc=91.39%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.154858 Test loss=0.289532 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1621866673231125
[5/24] Train loss=0.14459480345249176
[10/24] Train loss=0.14198368787765503
[15/24] Train loss=0.14752604067325592
[20/24] Train loss=0.1470256894826889
Test set avg_accuracy=88.97% avg_sensitivity=72.07%, avg_specificity=93.87% avg_auc=91.91%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.152130 Test loss=0.281400 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1558583825826645
[5/24] Train loss=0.14174887537956238
[10/24] Train loss=0.14109590649604797
[15/24] Train loss=0.14611609280109406
[20/24] Train loss=0.1468876302242279
Test set avg_accuracy=88.50% avg_sensitivity=73.52%, avg_specificity=92.85% avg_auc=91.37%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.150765 Test loss=0.291788 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.15496155619621277
[5/24] Train loss=0.144736185669899
[10/24] Train loss=0.1450079381465912
[15/24] Train loss=0.14188741147518158
[20/24] Train loss=0.15029196441173553
Test set avg_accuracy=89.05% avg_sensitivity=71.49%, avg_specificity=94.14% avg_auc=91.24%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.148441 Test loss=0.286892 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1527300626039505
[5/24] Train loss=0.1397591084241867
[10/24] Train loss=0.13691028952598572
[15/24] Train loss=0.14019158482551575
[20/24] Train loss=0.14715546369552612
Test set avg_accuracy=88.88% avg_sensitivity=70.10%, avg_specificity=94.32% avg_auc=91.01%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.147166 Test loss=0.289579 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.14844916760921478
[5/24] Train loss=0.13826735317707062
[10/24] Train loss=0.13766422867774963
[15/24] Train loss=0.1404150128364563
[20/24] Train loss=0.1487172544002533
Test set avg_accuracy=88.96% avg_sensitivity=72.19%, avg_specificity=93.82% avg_auc=91.30%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.146167 Test loss=0.285895 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.15017497539520264
[5/24] Train loss=0.1431364268064499
[10/24] Train loss=0.1377563327550888
[15/24] Train loss=0.14829537272453308
[20/24] Train loss=0.1417287141084671
Test set avg_accuracy=88.65% avg_sensitivity=75.14%, avg_specificity=92.56% avg_auc=92.10%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.145674 Test loss=0.287248 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.14962825179100037
[5/24] Train loss=0.13686810433864594
[10/24] Train loss=0.13658805191516876
[15/24] Train loss=0.14220665395259857
[20/24] Train loss=0.14315956830978394
Test set avg_accuracy=88.70% avg_sensitivity=74.97%, avg_specificity=92.68% avg_auc=92.10%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.143740 Test loss=0.285014 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1474202424287796
[5/24] Train loss=0.1368158757686615
[10/24] Train loss=0.1337798833847046
[15/24] Train loss=0.1384791135787964
[20/24] Train loss=0.14178839325904846
Test set avg_accuracy=89.22% avg_sensitivity=71.49%, avg_specificity=94.36% avg_auc=91.23%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.142412 Test loss=0.286264 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.14807777106761932
[5/24] Train loss=0.1331826001405716
[10/24] Train loss=0.1318618804216385
[15/24] Train loss=0.13286922872066498
[20/24] Train loss=0.1378779262304306
Test set avg_accuracy=88.48% avg_sensitivity=72.89%, avg_specificity=93.00% avg_auc=91.62%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.140128 Test loss=0.287915 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.14548909664154053
[5/24] Train loss=0.13347457349300385
[10/24] Train loss=0.12978485226631165
[15/24] Train loss=0.13667303323745728
[20/24] Train loss=0.13896329700946808
Test set avg_accuracy=88.15% avg_sensitivity=71.96%, avg_specificity=92.85% avg_auc=91.27%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.141291 Test loss=0.297529 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1469089537858963
[5/24] Train loss=0.13847842812538147
[10/24] Train loss=0.12859569489955902
[15/24] Train loss=0.13831913471221924
[20/24] Train loss=0.13754984736442566
Test set avg_accuracy=88.54% avg_sensitivity=72.65%, avg_specificity=93.15% avg_auc=91.71%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.139822 Test loss=0.287476 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1448325663805008
[5/24] Train loss=0.13227641582489014
[10/24] Train loss=0.12977127730846405
[15/24] Train loss=0.14083939790725708
[20/24] Train loss=0.13644073903560638
Test set avg_accuracy=88.35% avg_sensitivity=71.49%, avg_specificity=93.23% avg_auc=91.57%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.139401 Test loss=0.293093 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.14439554512500763
[5/24] Train loss=0.13539117574691772
[10/24] Train loss=0.12863914668560028
[15/24] Train loss=0.13733705878257751
[20/24] Train loss=0.1387650966644287
Test set avg_accuracy=89.01% avg_sensitivity=71.73%, avg_specificity=94.02% avg_auc=91.28%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.138880 Test loss=0.287855 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.14190149307250977
[5/24] Train loss=0.13339117169380188
[10/24] Train loss=0.1277996003627777
[15/24] Train loss=0.13617046177387238
[20/24] Train loss=0.1372881531715393
Test set avg_accuracy=88.49% avg_sensitivity=74.04%, avg_specificity=92.68% avg_auc=91.88%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.138799 Test loss=0.284789 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1404922753572464
[5/24] Train loss=0.13287070393562317
[10/24] Train loss=0.12992851436138153
[15/24] Train loss=0.1313798725605011
[20/24] Train loss=0.13641482591629028
Test set avg_accuracy=88.85% avg_sensitivity=73.46%, avg_specificity=93.32% avg_auc=91.87%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.137907 Test loss=0.284442 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.14114508032798767
[5/24] Train loss=0.12962386012077332
[10/24] Train loss=0.12599332630634308
[15/24] Train loss=0.13191571831703186
[20/24] Train loss=0.13199615478515625
Test set avg_accuracy=88.50% avg_sensitivity=72.36%, avg_specificity=93.18% avg_auc=91.42%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.136319 Test loss=0.291029 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13950224220752716
[5/24] Train loss=0.12790964543819427
[10/24] Train loss=0.12649351358413696
[15/24] Train loss=0.13239651918411255
[20/24] Train loss=0.13052594661712646
Test set avg_accuracy=88.36% avg_sensitivity=72.36%, avg_specificity=93.00% avg_auc=91.66%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.134678 Test loss=0.287736 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13777148723602295
[5/24] Train loss=0.12761905789375305
[10/24] Train loss=0.12397848069667816
[15/24] Train loss=0.13059063255786896
[20/24] Train loss=0.13059954345226288
Test set avg_accuracy=88.78% avg_sensitivity=72.13%, avg_specificity=93.60% avg_auc=91.56%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.134119 Test loss=0.288922 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1392568200826645
[5/24] Train loss=0.12749986350536346
[10/24] Train loss=0.12544097006320953
[15/24] Train loss=0.1287621259689331
[20/24] Train loss=0.13021600246429443
Test set avg_accuracy=88.57% avg_sensitivity=72.65%, avg_specificity=93.18% avg_auc=91.61%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.133551 Test loss=0.286872 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1390475630760193
[5/24] Train loss=0.12768469750881195
[10/24] Train loss=0.12005393952131271
[15/24] Train loss=0.12931883335113525
[20/24] Train loss=0.1278597116470337
Test set avg_accuracy=88.95% avg_sensitivity=72.65%, avg_specificity=93.67% avg_auc=91.61%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.132325 Test loss=0.286151 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13796007633209229
[5/24] Train loss=0.12571856379508972
[10/24] Train loss=0.12323223054409027
[15/24] Train loss=0.13078776001930237
[20/24] Train loss=0.1307200938463211
Test set avg_accuracy=88.54% avg_sensitivity=73.23%, avg_specificity=92.98% avg_auc=91.87%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.132874 Test loss=0.286430 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.13625963032245636
[5/24] Train loss=0.12702958285808563
[10/24] Train loss=0.1249290183186531
[15/24] Train loss=0.1287429928779602
[20/24] Train loss=0.12934458255767822
Test set avg_accuracy=88.66% avg_sensitivity=72.77%, avg_specificity=93.27% avg_auc=91.53%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.131955 Test loss=0.288269 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13507080078125
[5/24] Train loss=0.12577323615550995
[10/24] Train loss=0.1216270849108696
[15/24] Train loss=0.12645170092582703
[20/24] Train loss=0.1292053908109665
Test set avg_accuracy=88.85% avg_sensitivity=72.89%, avg_specificity=93.48% avg_auc=91.61%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.131759 Test loss=0.286067 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13620850443840027
[5/24] Train loss=0.12561503052711487
[10/24] Train loss=0.12175071239471436
[15/24] Train loss=0.12810742855072021
[20/24] Train loss=0.1286168396472931
Test set avg_accuracy=88.78% avg_sensitivity=73.00%, avg_specificity=93.35% avg_auc=91.54%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.131733 Test loss=0.288018 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1350359320640564
[5/24] Train loss=0.1252412647008896
[10/24] Train loss=0.12210123240947723
[15/24] Train loss=0.12852922081947327
[20/24] Train loss=0.13058890402317047
Test set avg_accuracy=88.70% avg_sensitivity=72.31%, avg_specificity=93.45% avg_auc=91.42%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.131262 Test loss=0.288933 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1368834227323532
[5/24] Train loss=0.12684111297130585
[10/24] Train loss=0.11856339126825333
[15/24] Train loss=0.1245255246758461
[20/24] Train loss=0.13065263628959656
Test set avg_accuracy=88.58% avg_sensitivity=73.00%, avg_specificity=93.10% avg_auc=91.59%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.131060 Test loss=0.288061 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1361217498779297
[5/24] Train loss=0.12309695035219193
[10/24] Train loss=0.12031526863574982
[15/24] Train loss=0.12952227890491486
[20/24] Train loss=0.1297861486673355
Test set avg_accuracy=88.66% avg_sensitivity=73.00%, avg_specificity=93.20% avg_auc=91.60%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.130763 Test loss=0.287100 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1363830864429474
[5/24] Train loss=0.12414328008890152
[10/24] Train loss=0.12256691604852676
[15/24] Train loss=0.12918902933597565
[20/24] Train loss=0.1288343220949173
Test set avg_accuracy=88.65% avg_sensitivity=72.89%, avg_specificity=93.21% avg_auc=91.59%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.131181 Test loss=0.287256 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13481692969799042
[5/24] Train loss=0.12551526725292206
[10/24] Train loss=0.12118349969387054
[15/24] Train loss=0.12870445847511292
[20/24] Train loss=0.13058333098888397
Test set avg_accuracy=88.68% avg_sensitivity=72.89%, avg_specificity=93.27% avg_auc=91.57%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.131150 Test loss=0.287418 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.13462907075881958
[5/24] Train loss=0.12550130486488342
[10/24] Train loss=0.12245819717645645
[15/24] Train loss=0.1289108395576477
[20/24] Train loss=0.12947313487529755
Test set avg_accuracy=88.67% avg_sensitivity=72.83%, avg_specificity=93.27% avg_auc=91.59%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.130689 Test loss=0.287235 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.13380813598632812
[5/24] Train loss=0.12423419207334518
[10/24] Train loss=0.12231793999671936
[15/24] Train loss=0.12793920934200287
[20/24] Train loss=0.1284053772687912
Test set avg_accuracy=88.65% avg_sensitivity=72.65%, avg_specificity=93.28% avg_auc=91.59%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.130413 Test loss=0.287145 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13327090442180634
[5/24] Train loss=0.12398258596658707
[10/24] Train loss=0.12071314454078674
[15/24] Train loss=0.12722258269786835
[20/24] Train loss=0.1288846880197525
Test set avg_accuracy=88.67% avg_sensitivity=72.65%, avg_specificity=93.32% avg_auc=91.59%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.130693 Test loss=0.287155 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1344490796327591
[5/24] Train loss=0.12446415424346924
[10/24] Train loss=0.12250783294439316
[15/24] Train loss=0.12666556239128113
[20/24] Train loss=0.1290578842163086
Test set avg_accuracy=88.68% avg_sensitivity=72.65%, avg_specificity=93.33% avg_auc=91.59%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.131206 Test loss=0.287196 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=89.62% sen=76.25%, spe=93.50%, auc=93.45%!
Fold[10] Avg_overlap=0.71%(±0.23539038868113815)
Final Avg Result: avg_acc=87.65%(±1.0905771674594282) avg_sen=76.19% (±1.7095078871051987) avg_spe=91.59% (±1.317824756176975) avg_auc=92.40% (±0.9078927005343586) avg_overlap=0.69% (±0.019587723243053336)
