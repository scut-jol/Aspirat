/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/24] Train loss=0.720790445804596
[5/24] Train loss=0.7148216366767883
[10/24] Train loss=0.7061995267868042
[15/24] Train loss=0.7016193270683289
[20/24] Train loss=0.6906653046607971
Test set avg_accuracy=58.75% avg_sensitivity=41.02%, avg_specificity=65.08% avg_auc=55.63%
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.703819 Test loss=0.691927 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6843286752700806
[5/24] Train loss=0.6794202327728271
[10/24] Train loss=0.681577742099762
[15/24] Train loss=0.6715512871742249
[20/24] Train loss=0.66668701171875
Test set avg_accuracy=61.71% avg_sensitivity=59.72%, avg_specificity=62.41% avg_auc=66.14%
Best model saved!! Metric=-76.0151973935481!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.676631 Test loss=0.642816 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6591985821723938
[5/24] Train loss=0.6434158086776733
[10/24] Train loss=0.6521141529083252
[15/24] Train loss=0.6435455679893494
[20/24] Train loss=0.6338241696357727
Test set avg_accuracy=65.31% avg_sensitivity=66.25%, avg_specificity=64.98% avg_auc=70.84%
Best model saved!! Metric=-58.616857928357646!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.652274 Test loss=0.622730 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6202035546302795
[5/24] Train loss=0.618414580821991
[10/24] Train loss=0.6280862092971802
[15/24] Train loss=0.6186241507530212
[20/24] Train loss=0.6203182339668274
Test set avg_accuracy=66.56% avg_sensitivity=69.57%, avg_specificity=65.49% avg_auc=73.26%
Best model saved!! Metric=-51.12035047992718!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.629101 Test loss=0.607370 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6079986691474915
[5/24] Train loss=0.5945742130279541
[10/24] Train loss=0.6053654551506042
[15/24] Train loss=0.5958285331726074
[20/24] Train loss=0.5982245206832886
Test set avg_accuracy=67.90% avg_sensitivity=70.95%, avg_specificity=66.81% avg_auc=74.89%
Best model saved!! Metric=-45.43895818513715!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.609643 Test loss=0.592099 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5859862565994263
[5/24] Train loss=0.5728641748428345
[10/24] Train loss=0.5879270434379578
[15/24] Train loss=0.5740426778793335
[20/24] Train loss=0.5773880481719971
Test set avg_accuracy=69.08% avg_sensitivity=71.99%, avg_specificity=68.03% avg_auc=76.13%
Best model saved!! Metric=-40.76290690006397!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.588970 Test loss=0.576580 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5642002820968628
[5/24] Train loss=0.552036702632904
[10/24] Train loss=0.5712257623672485
[15/24] Train loss=0.5590647459030151
[20/24] Train loss=0.5562751889228821
Test set avg_accuracy=70.03% avg_sensitivity=71.45%, avg_specificity=69.52% avg_auc=77.51%
Best model saved!! Metric=-37.50052786884919!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.570126 Test loss=0.559837 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5360991358757019
[5/24] Train loss=0.5298831462860107
[10/24] Train loss=0.5526191592216492
[15/24] Train loss=0.5371339917182922
[20/24] Train loss=0.5369511842727661
Test set avg_accuracy=72.25% avg_sensitivity=69.03%, avg_specificity=73.41% avg_auc=78.54%
Best model saved!! Metric=-32.77554338354366!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.549523 Test loss=0.535041 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5140445232391357
[5/24] Train loss=0.5115525126457214
[10/24] Train loss=0.5305615663528442
[15/24] Train loss=0.5162927508354187
[20/24] Train loss=0.5164364576339722
Test set avg_accuracy=74.32% avg_sensitivity=66.55%, avg_specificity=77.10% avg_auc=79.68%
Best model saved!! Metric=-28.34819849023988!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.529086 Test loss=0.510027 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5007245540618896
[5/24] Train loss=0.4926340878009796
[10/24] Train loss=0.5128358602523804
[15/24] Train loss=0.5009905695915222
[20/24] Train loss=0.48926830291748047
Test set avg_accuracy=75.65% avg_sensitivity=66.80%, avg_specificity=78.81% avg_auc=80.95%
Best model saved!! Metric=-23.785823187337158!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.507834 Test loss=0.493772 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.47555652260780334
[5/24] Train loss=0.4715481102466583
[10/24] Train loss=0.4986482858657837
[15/24] Train loss=0.4833994209766388
[20/24] Train loss=0.47362327575683594
Test set avg_accuracy=77.42% avg_sensitivity=65.66%, avg_specificity=81.62% avg_auc=82.01%
Best model saved!! Metric=-19.288738308449993!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.487816 Test loss=0.471020 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.44818365573883057
[5/24] Train loss=0.4516301155090332
[10/24] Train loss=0.47785210609436035
[15/24] Train loss=0.46256300806999207
[20/24] Train loss=0.4505385458469391
Test set avg_accuracy=78.20% avg_sensitivity=67.59%, avg_specificity=81.99% avg_auc=83.18%
Best model saved!! Metric=-15.032048110332326!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.468237 Test loss=0.461171 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.44143563508987427
[5/24] Train loss=0.4371033012866974
[10/24] Train loss=0.4629667103290558
[15/24] Train loss=0.446991503238678
[20/24] Train loss=0.43097302317619324
Test set avg_accuracy=79.48% avg_sensitivity=63.58%, avg_specificity=85.16% avg_auc=84.01%
Best model saved!! Metric=-13.771189834810677!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.451743 Test loss=0.439528 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4232562780380249
[5/24] Train loss=0.41757068037986755
[10/24] Train loss=0.4475821554660797
[15/24] Train loss=0.43503591418266296
[20/24] Train loss=0.41345274448394775
Test set avg_accuracy=80.78% avg_sensitivity=62.35%, avg_specificity=87.37% avg_auc=84.67%
Best model saved!! Metric=-10.839372971084927!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.435919 Test loss=0.423807 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4033536911010742
[5/24] Train loss=0.40882033109664917
[10/24] Train loss=0.43357107043266296
[15/24] Train loss=0.4190935492515564
[20/24] Train loss=0.3989613950252533
Test set avg_accuracy=81.98% avg_sensitivity=57.74%, avg_specificity=90.63% avg_auc=85.09%
Best model saved!! Metric=-10.55130997989626!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.422852 Test loss=0.409619 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.39656487107276917
[5/24] Train loss=0.3917883336544037
[10/24] Train loss=0.42500948905944824
[15/24] Train loss=0.41123872995376587
[20/24] Train loss=0.39106452465057373
Test set avg_accuracy=82.85% avg_sensitivity=56.51%, avg_specificity=92.26% avg_auc=85.64%
Best model saved!! Metric=-8.738072887889963!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.412246 Test loss=0.400511 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3923349976539612
[5/24] Train loss=0.3823438286781311
[10/24] Train loss=0.42876410484313965
[15/24] Train loss=0.40934857726097107
[20/24] Train loss=0.38438087701797485
Test set avg_accuracy=82.77% avg_sensitivity=58.14%, avg_specificity=91.57% avg_auc=85.97%
Best model saved!! Metric=-7.548990226752103!!
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.403856 Test loss=0.396957 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3836309313774109
[5/24] Train loss=0.37903666496276855
[10/24] Train loss=0.41657283902168274
[15/24] Train loss=0.39820900559425354
[20/24] Train loss=0.37624233961105347
Test set avg_accuracy=82.83% avg_sensitivity=50.02%, avg_specificity=94.54% avg_auc=86.30%
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.396536 Test loss=0.394708 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3756864368915558
[5/24] Train loss=0.3692801892757416
[10/24] Train loss=0.4092530906200409
[15/24] Train loss=0.39110875129699707
[20/24] Train loss=0.3583557605743408
Test set avg_accuracy=83.09% avg_sensitivity=57.60%, avg_specificity=92.19% avg_auc=86.98%
Best model saved!! Metric=-6.148204381336264!!
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.388743 Test loss=0.385790 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.36700713634490967
[5/24] Train loss=0.35599279403686523
[10/24] Train loss=0.4013434946537018
[15/24] Train loss=0.3885863125324249
[20/24] Train loss=0.35162487626075745
Test set avg_accuracy=82.97% avg_sensitivity=55.22%, avg_specificity=92.88% avg_auc=86.86%
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.382176 Test loss=0.386316 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.35790467262268066
[5/24] Train loss=0.3601837158203125
[10/24] Train loss=0.392101526260376
[15/24] Train loss=0.3801220655441284
[20/24] Train loss=0.34505483508110046
Test set avg_accuracy=82.97% avg_sensitivity=52.94%, avg_specificity=93.69% avg_auc=87.02%
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.374593 Test loss=0.385104 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3523792028427124
[5/24] Train loss=0.3462485074996948
[10/24] Train loss=0.3967154324054718
[15/24] Train loss=0.3784804344177246
[20/24] Train loss=0.33889836072921753
Test set avg_accuracy=83.31% avg_sensitivity=53.09%, avg_specificity=94.10% avg_auc=87.16%
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.370299 Test loss=0.383486 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3429580330848694
[5/24] Train loss=0.35140955448150635
[10/24] Train loss=0.39108970761299133
[15/24] Train loss=0.37493523955345154
[20/24] Train loss=0.3407424986362457
Test set avg_accuracy=83.09% avg_sensitivity=49.04%, avg_specificity=95.25% avg_auc=87.41%
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.366156 Test loss=0.386204 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.35014235973358154
[5/24] Train loss=0.3418927788734436
[10/24] Train loss=0.38757574558258057
[15/24] Train loss=0.3718762993812561
[20/24] Train loss=0.3374573886394501
Test set avg_accuracy=83.49% avg_sensitivity=55.91%, avg_specificity=93.34% avg_auc=87.73%
Best model saved!! Metric=-5.525061709759427!!
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.363357 Test loss=0.377134 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.33638134598731995
[5/24] Train loss=0.34205037355422974
[10/24] Train loss=0.38485878705978394
[15/24] Train loss=0.36458271741867065
[20/24] Train loss=0.3327175974845886
Test set avg_accuracy=82.86% avg_sensitivity=53.79%, avg_specificity=93.25% avg_auc=87.38%
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.358401 Test loss=0.381887 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.33535391092300415
[5/24] Train loss=0.33350875973701477
[10/24] Train loss=0.3864016830921173
[15/24] Train loss=0.35812604427337646
[20/24] Train loss=0.32425567507743835
Test set avg_accuracy=81.77% avg_sensitivity=41.96%, avg_specificity=95.99% avg_auc=86.63%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.357061 Test loss=0.407634 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3334711790084839
[5/24] Train loss=0.33171215653419495
[10/24] Train loss=0.3875434994697571
[15/24] Train loss=0.36497002840042114
[20/24] Train loss=0.3217058777809143
Test set avg_accuracy=82.98% avg_sensitivity=45.37%, avg_specificity=96.41% avg_auc=88.38%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.352572 Test loss=0.382190 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.33787018060684204
[5/24] Train loss=0.3325114846229553
[10/24] Train loss=0.3727620840072632
[15/24] Train loss=0.3480103611946106
[20/24] Train loss=0.3203226923942566
Test set avg_accuracy=79.79% avg_sensitivity=27.31%, avg_specificity=98.53% avg_auc=86.44%
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.349521 Test loss=0.447468 Current lr=[0.000210185142098938]

[0/24] Train loss=0.344074547290802
[5/24] Train loss=0.32908570766448975
[10/24] Train loss=0.3794480860233307
[15/24] Train loss=0.3575778007507324
[20/24] Train loss=0.31973057985305786
Test set avg_accuracy=81.63% avg_sensitivity=38.10%, avg_specificity=97.17% avg_auc=87.08%
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.348774 Test loss=0.410087 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.34898555278778076
[5/24] Train loss=0.31718528270721436
[10/24] Train loss=0.38096264004707336
[15/24] Train loss=0.36262956261634827
[20/24] Train loss=0.31670576333999634
Test set avg_accuracy=82.03% avg_sensitivity=42.36%, avg_specificity=96.20% avg_auc=87.51%
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.349079 Test loss=0.395566 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3316401541233063
[5/24] Train loss=0.3207450211048126
[10/24] Train loss=0.38498979806900024
[15/24] Train loss=0.3378590941429138
[20/24] Train loss=0.31414034962654114
Test set avg_accuracy=83.59% avg_sensitivity=50.07%, avg_specificity=95.56% avg_auc=88.33%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.340989 Test loss=0.370914 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.32693198323249817
[5/24] Train loss=0.3178466856479645
[10/24] Train loss=0.3802652060985565
[15/24] Train loss=0.3291669487953186
[20/24] Train loss=0.3089698255062103
Test set avg_accuracy=80.72% avg_sensitivity=33.20%, avg_specificity=97.69% avg_auc=87.57%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.338629 Test loss=0.419555 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3255743086338043
[5/24] Train loss=0.3272685408592224
[10/24] Train loss=0.37341222167015076
[15/24] Train loss=0.33030351996421814
[20/24] Train loss=0.3008403182029724
Test set avg_accuracy=78.18% avg_sensitivity=19.54%, avg_specificity=99.12% avg_auc=86.23%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.336630 Test loss=0.482275 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3352176249027252
[5/24] Train loss=0.3179763853549957
[10/24] Train loss=0.36715149879455566
[15/24] Train loss=0.3400524854660034
[20/24] Train loss=0.3058163523674011
Test set avg_accuracy=81.25% avg_sensitivity=37.21%, avg_specificity=96.98% avg_auc=87.23%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.338591 Test loss=0.418092 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.31658199429512024
[5/24] Train loss=0.31801870465278625
[10/24] Train loss=0.3683898448944092
[15/24] Train loss=0.3423970639705658
[20/24] Train loss=0.3058495819568634
Test set avg_accuracy=81.54% avg_sensitivity=38.89%, avg_specificity=96.77% avg_auc=86.26%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.337635 Test loss=0.405759 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3221987783908844
[5/24] Train loss=0.3191183805465698
[10/24] Train loss=0.35736098885536194
[15/24] Train loss=0.337442547082901
[20/24] Train loss=0.30198004841804504
Test set avg_accuracy=83.88% avg_sensitivity=57.35%, avg_specificity=93.36% avg_auc=88.01%
Best model saved!! Metric=-3.4029748958788844!!
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.333175 Test loss=0.371071 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3088773787021637
[5/24] Train loss=0.3146982491016388
[10/24] Train loss=0.3794293701648712
[15/24] Train loss=0.3272072374820709
[20/24] Train loss=0.300167977809906
Test set avg_accuracy=82.08% avg_sensitivity=42.95%, avg_specificity=96.06% avg_auc=87.12%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.330958 Test loss=0.396956 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3094717860221863
[5/24] Train loss=0.31551969051361084
[10/24] Train loss=0.3621797263622284
[15/24] Train loss=0.3257301449775696
[20/24] Train loss=0.29762569069862366
Test set avg_accuracy=82.92% avg_sensitivity=49.83%, avg_specificity=94.73% avg_auc=87.97%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.328567 Test loss=0.377426 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3017685115337372
[5/24] Train loss=0.3095253109931946
[10/24] Train loss=0.3587490916252136
[15/24] Train loss=0.3174333870410919
[20/24] Train loss=0.2953535318374634
Test set avg_accuracy=78.50% avg_sensitivity=21.67%, avg_specificity=98.80% avg_auc=85.76%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.323170 Test loss=0.447907 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3123500943183899
[5/24] Train loss=0.3186592757701874
[10/24] Train loss=0.3584699034690857
[15/24] Train loss=0.321050226688385
[20/24] Train loss=0.29597750306129456
Test set avg_accuracy=81.12% avg_sensitivity=37.75%, avg_specificity=96.61% avg_auc=86.58%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.325812 Test loss=0.407863 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3000156581401825
[5/24] Train loss=0.3077429533004761
[10/24] Train loss=0.3612373471260071
[15/24] Train loss=0.3214751183986664
[20/24] Train loss=0.2875893712043762
Test set avg_accuracy=77.75% avg_sensitivity=20.29%, avg_specificity=98.27% avg_auc=81.39%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.320524 Test loss=0.513127 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.29111799597740173
[5/24] Train loss=0.2867472767829895
[10/24] Train loss=0.3612571656703949
[15/24] Train loss=0.32602375745773315
[20/24] Train loss=0.28244563937187195
Test set avg_accuracy=83.16% avg_sensitivity=48.84%, avg_specificity=95.42% avg_auc=86.79%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.316487 Test loss=0.387195 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2767643928527832
[5/24] Train loss=0.2955605983734131
[10/24] Train loss=0.33589625358581543
[15/24] Train loss=0.3128036558628082
[20/24] Train loss=0.28703245520591736
Test set avg_accuracy=78.22% avg_sensitivity=19.99%, avg_specificity=99.01% avg_auc=82.72%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.312050 Test loss=0.511400 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3187808096408844
[5/24] Train loss=0.2981313169002533
[10/24] Train loss=0.3540368378162384
[15/24] Train loss=0.31843870878219604
[20/24] Train loss=0.28719115257263184
Test set avg_accuracy=82.38% avg_sensitivity=42.40%, avg_specificity=96.66% avg_auc=87.21%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.319147 Test loss=0.388014 Current lr=[0.00029967723776099]

[0/24] Train loss=0.300509512424469
[5/24] Train loss=0.2868274450302124
[10/24] Train loss=0.34692683815956116
[15/24] Train loss=0.30761420726776123
[20/24] Train loss=0.2799787223339081
Test set avg_accuracy=81.77% avg_sensitivity=46.36%, avg_specificity=94.42% avg_auc=84.56%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.311204 Test loss=0.409392 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3021302819252014
[5/24] Train loss=0.2957858443260193
[10/24] Train loss=0.34256064891815186
[15/24] Train loss=0.30825164914131165
[20/24] Train loss=0.2886282801628113
Test set avg_accuracy=80.78% avg_sensitivity=39.88%, avg_specificity=95.39% avg_auc=83.67%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.310789 Test loss=0.424404 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.29751133918762207
[5/24] Train loss=0.2975371778011322
[10/24] Train loss=0.35026925802230835
[15/24] Train loss=0.3078870177268982
[20/24] Train loss=0.2752964198589325
Test set avg_accuracy=80.30% avg_sensitivity=31.96%, avg_specificity=97.56% avg_auc=85.58%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.307683 Test loss=0.448983 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2920352518558502
[5/24] Train loss=0.2802915573120117
[10/24] Train loss=0.3507496416568756
[15/24] Train loss=0.29887837171554565
[20/24] Train loss=0.27724185585975647
Test set avg_accuracy=80.76% avg_sensitivity=35.63%, avg_specificity=96.87% avg_auc=83.12%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.308478 Test loss=0.456975 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.308379203081131
[5/24] Train loss=0.27936503291130066
[10/24] Train loss=0.3376956582069397
[15/24] Train loss=0.29196467995643616
[20/24] Train loss=0.2724611461162567
Test set avg_accuracy=81.30% avg_sensitivity=39.24%, avg_specificity=96.32% avg_auc=84.58%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.301607 Test loss=0.427267 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2852226495742798
[5/24] Train loss=0.2848745584487915
[10/24] Train loss=0.3227802515029907
[15/24] Train loss=0.29041728377342224
[20/24] Train loss=0.261186808347702
Test set avg_accuracy=77.42% avg_sensitivity=20.14%, avg_specificity=97.88% avg_auc=79.10%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.297932 Test loss=0.502096 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2925032377243042
[5/24] Train loss=0.28703245520591736
[10/24] Train loss=0.3137687146663666
[15/24] Train loss=0.29667049646377563
[20/24] Train loss=0.27215147018432617
Test set avg_accuracy=80.16% avg_sensitivity=58.54%, avg_specificity=87.88% avg_auc=83.54%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.301366 Test loss=0.431649 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2801903784275055
[5/24] Train loss=0.280917227268219
[10/24] Train loss=0.3106330633163452
[15/24] Train loss=0.30252134799957275
[20/24] Train loss=0.2721574604511261
Test set avg_accuracy=80.65% avg_sensitivity=51.41%, avg_specificity=91.09% avg_auc=83.34%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.298603 Test loss=0.431889 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2795206904411316
[5/24] Train loss=0.27201515436172485
[10/24] Train loss=0.3320721387863159
[15/24] Train loss=0.2874853014945984
[20/24] Train loss=0.27197280526161194
Test set avg_accuracy=81.26% avg_sensitivity=42.75%, avg_specificity=95.02% avg_auc=83.90%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.297153 Test loss=0.428292 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2941935062408447
[5/24] Train loss=0.2678772211074829
[10/24] Train loss=0.30788454413414
[15/24] Train loss=0.28786057233810425
[20/24] Train loss=0.262463241815567
Test set avg_accuracy=82.08% avg_sensitivity=50.32%, avg_specificity=93.43% avg_auc=86.02%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.295742 Test loss=0.402938 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.26826801896095276
[5/24] Train loss=0.27260464429855347
[10/24] Train loss=0.3140508830547333
[15/24] Train loss=0.28805050253868103
[20/24] Train loss=0.25513002276420593
Test set avg_accuracy=82.42% avg_sensitivity=52.45%, avg_specificity=93.13% avg_auc=86.14%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.290364 Test loss=0.395513 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.26486894488334656
[5/24] Train loss=0.27641719579696655
[10/24] Train loss=0.3304787874221802
[15/24] Train loss=0.2927488684654236
[20/24] Train loss=0.26290008425712585
Test set avg_accuracy=82.60% avg_sensitivity=59.13%, avg_specificity=90.99% avg_auc=86.77%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.292159 Test loss=0.395097 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.2633536159992218
[5/24] Train loss=0.272891640663147
[10/24] Train loss=0.30601680278778076
[15/24] Train loss=0.2997923195362091
[20/24] Train loss=0.26453375816345215
Test set avg_accuracy=82.06% avg_sensitivity=51.11%, avg_specificity=93.11% avg_auc=85.41%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.289659 Test loss=0.410235 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.25936612486839294
[5/24] Train loss=0.2647751569747925
[10/24] Train loss=0.31642094254493713
[15/24] Train loss=0.2852884531021118
[20/24] Train loss=0.25186219811439514
Test set avg_accuracy=80.44% avg_sensitivity=40.92%, avg_specificity=94.56% avg_auc=83.25%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.286170 Test loss=0.428060 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.27409884333610535
[5/24] Train loss=0.24879807233810425
[10/24] Train loss=0.30575695633888245
[15/24] Train loss=0.2947937846183777
[20/24] Train loss=0.2599967122077942
Test set avg_accuracy=71.00% avg_sensitivity=64.42%, avg_specificity=73.35% avg_auc=76.40%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.287318 Test loss=0.571140 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2700049877166748
[5/24] Train loss=0.2657145857810974
[10/24] Train loss=0.30404606461524963
[15/24] Train loss=0.2775232493877411
[20/24] Train loss=0.2638351023197174
Test set avg_accuracy=82.42% avg_sensitivity=58.88%, avg_specificity=90.83% avg_auc=86.30%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.287340 Test loss=0.400544 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2842017412185669
[5/24] Train loss=0.27779150009155273
[10/24] Train loss=0.313978910446167
[15/24] Train loss=0.2858937680721283
[20/24] Train loss=0.25472694635391235
Test set avg_accuracy=82.17% avg_sensitivity=54.53%, avg_specificity=92.05% avg_auc=85.84%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.285861 Test loss=0.405750 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.27956265211105347
[5/24] Train loss=0.2633179724216461
[10/24] Train loss=0.3056596517562866
[15/24] Train loss=0.27466732263565063
[20/24] Train loss=0.26426583528518677
Test set avg_accuracy=82.11% avg_sensitivity=50.37%, avg_specificity=93.44% avg_auc=84.88%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.280946 Test loss=0.422891 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.26399028301239014
[5/24] Train loss=0.26700374484062195
[10/24] Train loss=0.28381437063217163
[15/24] Train loss=0.27070340514183044
[20/24] Train loss=0.2546282410621643
Test set avg_accuracy=80.46% avg_sensitivity=57.99%, avg_specificity=88.48% avg_auc=85.32%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.276623 Test loss=0.423296 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.260157972574234
[5/24] Train loss=0.24708831310272217
[10/24] Train loss=0.2930367588996887
[15/24] Train loss=0.27371644973754883
[20/24] Train loss=0.2411442995071411
Test set avg_accuracy=82.83% avg_sensitivity=58.68%, avg_specificity=91.45% avg_auc=87.27%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.270974 Test loss=0.389457 Current lr=[0.000276307469034998]

[0/24] Train loss=0.25612568855285645
[5/24] Train loss=0.2603318691253662
[10/24] Train loss=0.27646204829216003
[15/24] Train loss=0.2696813642978668
[20/24] Train loss=0.2573324739933014
Test set avg_accuracy=79.45% avg_sensitivity=37.41%, avg_specificity=94.47% avg_auc=80.68%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.268894 Test loss=0.517201 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.24574795365333557
[5/24] Train loss=0.25083956122398376
[10/24] Train loss=0.2800103425979614
[15/24] Train loss=0.2733830213546753
[20/24] Train loss=0.2613493502140045
Test set avg_accuracy=80.61% avg_sensitivity=46.66%, avg_specificity=92.74% avg_auc=80.58%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.264942 Test loss=0.470069 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2516445815563202
[5/24] Train loss=0.24649013578891754
[10/24] Train loss=0.29928058385849
[15/24] Train loss=0.2586284279823303
[20/24] Train loss=0.24492183327674866
Test set avg_accuracy=82.43% avg_sensitivity=61.45%, avg_specificity=89.93% avg_auc=86.47%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.268750 Test loss=0.398205 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.24838747084140778
[5/24] Train loss=0.24919360876083374
[10/24] Train loss=0.28060436248779297
[15/24] Train loss=0.2648750841617584
[20/24] Train loss=0.2494526356458664
Test set avg_accuracy=82.53% avg_sensitivity=60.32%, avg_specificity=90.46% avg_auc=86.74%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.267279 Test loss=0.393604 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.24720367789268494
[5/24] Train loss=0.24141868948936462
[10/24] Train loss=0.2767084240913391
[15/24] Train loss=0.2700912654399872
[20/24] Train loss=0.26940104365348816
Test set avg_accuracy=81.16% avg_sensitivity=65.41%, avg_specificity=86.78% avg_auc=86.35%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.266779 Test loss=0.418500 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2474457174539566
[5/24] Train loss=0.24270828068256378
[10/24] Train loss=0.2696019113063812
[15/24] Train loss=0.25611504912376404
[20/24] Train loss=0.24787497520446777
Test set avg_accuracy=76.09% avg_sensitivity=73.43%, avg_specificity=77.05% avg_auc=83.95%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.261022 Test loss=0.488396 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.254442036151886
[5/24] Train loss=0.25260716676712036
[10/24] Train loss=0.28633952140808105
[15/24] Train loss=0.2649610936641693
[20/24] Train loss=0.2413971871137619
Test set avg_accuracy=76.38% avg_sensitivity=74.17%, avg_specificity=77.17% avg_auc=84.32%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.262523 Test loss=0.476824 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.23585903644561768
[5/24] Train loss=0.26284632086753845
[10/24] Train loss=0.28349655866622925
[15/24] Train loss=0.2520846128463745
[20/24] Train loss=0.258359432220459
Test set avg_accuracy=79.78% avg_sensitivity=65.07%, avg_specificity=85.03% avg_auc=85.25%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.262259 Test loss=0.431149 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2494909167289734
[5/24] Train loss=0.24818797409534454
[10/24] Train loss=0.2887142300605774
[15/24] Train loss=0.2503068745136261
[20/24] Train loss=0.2368844598531723
Test set avg_accuracy=82.47% avg_sensitivity=57.55%, avg_specificity=91.38% avg_auc=86.67%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.255611 Test loss=0.407221 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2332473248243332
[5/24] Train loss=0.2238975614309311
[10/24] Train loss=0.2864200174808502
[15/24] Train loss=0.2460477650165558
[20/24] Train loss=0.2362271249294281
Test set avg_accuracy=80.04% avg_sensitivity=64.97%, avg_specificity=85.42% avg_auc=84.81%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.252763 Test loss=0.441733 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.23358584940433502
[5/24] Train loss=0.22990712523460388
[10/24] Train loss=0.2948681712150574
[15/24] Train loss=0.24563664197921753
[20/24] Train loss=0.23641875386238098
Test set avg_accuracy=79.92% avg_sensitivity=71.60%, avg_specificity=82.89% avg_auc=86.08%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.258566 Test loss=0.435364 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2392835021018982
[5/24] Train loss=0.23290854692459106
[10/24] Train loss=0.28119128942489624
[15/24] Train loss=0.258622944355011
[20/24] Train loss=0.24015559256076813
Test set avg_accuracy=82.28% avg_sensitivity=64.28%, avg_specificity=88.71% avg_auc=85.95%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.255043 Test loss=0.417791 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2292119711637497
[5/24] Train loss=0.2362428456544876
[10/24] Train loss=0.24704308807849884
[15/24] Train loss=0.2478853017091751
[20/24] Train loss=0.22861631214618683
Test set avg_accuracy=80.79% avg_sensitivity=67.74%, avg_specificity=85.46% avg_auc=85.12%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.253749 Test loss=0.442260 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.228905588388443
[5/24] Train loss=0.21884307265281677
[10/24] Train loss=0.26157471537590027
[15/24] Train loss=0.24578529596328735
[20/24] Train loss=0.2274673879146576
Test set avg_accuracy=79.71% avg_sensitivity=69.82%, avg_specificity=83.25% avg_auc=85.45%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.246276 Test loss=0.448259 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.23480993509292603
[5/24] Train loss=0.23415827751159668
[10/24] Train loss=0.25136110186576843
[15/24] Train loss=0.24217024445533752
[20/24] Train loss=0.23495423793792725
Test set avg_accuracy=79.84% avg_sensitivity=66.06%, avg_specificity=84.77% avg_auc=84.96%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.247150 Test loss=0.448610 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2323702573776245
[5/24] Train loss=0.23002780973911285
[10/24] Train loss=0.27504274249076843
[15/24] Train loss=0.25571274757385254
[20/24] Train loss=0.22336365282535553
Test set avg_accuracy=79.39% avg_sensitivity=47.80%, avg_specificity=90.67% avg_auc=81.03%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.243736 Test loss=0.500637 Current lr=[0.000224838296036774]

[0/24] Train loss=0.23300616443157196
[5/24] Train loss=0.22765548527240753
[10/24] Train loss=0.24117401242256165
[15/24] Train loss=0.242996484041214
[20/24] Train loss=0.23879805207252502
Test set avg_accuracy=82.37% avg_sensitivity=46.21%, avg_specificity=95.28% avg_auc=84.72%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.240913 Test loss=0.432817 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.21623602509498596
[5/24] Train loss=0.238225057721138
[10/24] Train loss=0.24601130187511444
[15/24] Train loss=0.23551522195339203
[20/24] Train loss=0.22765997052192688
Test set avg_accuracy=80.87% avg_sensitivity=39.14%, avg_specificity=95.78% avg_auc=80.23%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.236948 Test loss=0.477516 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.22242769598960876
[5/24] Train loss=0.2145552784204483
[10/24] Train loss=0.23948954045772552
[15/24] Train loss=0.22935421764850616
[20/24] Train loss=0.23530243337154388
Test set avg_accuracy=80.27% avg_sensitivity=44.33%, avg_specificity=93.11% avg_auc=79.36%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.233656 Test loss=0.513531 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.21094094216823578
[5/24] Train loss=0.21365484595298767
[10/24] Train loss=0.24756816029548645
[15/24] Train loss=0.2391951084136963
[20/24] Train loss=0.22296510636806488
Test set avg_accuracy=79.43% avg_sensitivity=27.71%, avg_specificity=97.90% avg_auc=79.40%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.231758 Test loss=0.552218 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.22895865142345428
[5/24] Train loss=0.21555975079536438
[10/24] Train loss=0.2345033437013626
[15/24] Train loss=0.22726142406463623
[20/24] Train loss=0.22240379452705383
Test set avg_accuracy=81.25% avg_sensitivity=42.95%, avg_specificity=94.93% avg_auc=81.63%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.232229 Test loss=0.463703 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.22175012528896332
[5/24] Train loss=0.2222953885793686
[10/24] Train loss=0.2429138422012329
[15/24] Train loss=0.2372899353504181
[20/24] Train loss=0.24033284187316895
Test set avg_accuracy=81.50% avg_sensitivity=42.95%, avg_specificity=95.26% avg_auc=81.47%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.233423 Test loss=0.487715 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2130151093006134
[5/24] Train loss=0.21562033891677856
[10/24] Train loss=0.23501457273960114
[15/24] Train loss=0.23411233723163605
[20/24] Train loss=0.22086656093597412
Test set avg_accuracy=82.77% avg_sensitivity=52.20%, avg_specificity=93.69% avg_auc=83.73%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.227255 Test loss=0.429697 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.21392863988876343
[5/24] Train loss=0.21173742413520813
[10/24] Train loss=0.2247197926044464
[15/24] Train loss=0.22195206582546234
[20/24] Train loss=0.21926750242710114
Test set avg_accuracy=79.38% avg_sensitivity=34.44%, avg_specificity=95.42% avg_auc=76.84%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.228254 Test loss=0.557855 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.21182410418987274
[5/24] Train loss=0.2054785043001175
[10/24] Train loss=0.23168356716632843
[15/24] Train loss=0.22458398342132568
[20/24] Train loss=0.21002425253391266
Test set avg_accuracy=79.01% avg_sensitivity=26.77%, avg_specificity=97.67% avg_auc=74.17%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.223124 Test loss=0.595075 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.21010515093803406
[5/24] Train loss=0.2042192816734314
[10/24] Train loss=0.2339848130941391
[15/24] Train loss=0.2131890505552292
[20/24] Train loss=0.21157978475093842
Test set avg_accuracy=80.55% avg_sensitivity=39.98%, avg_specificity=95.03% avg_auc=79.02%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.219152 Test loss=0.505760 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2022170126438141
[5/24] Train loss=0.19980375468730927
[10/24] Train loss=0.2167092114686966
[15/24] Train loss=0.2241262048482895
[20/24] Train loss=0.21300479769706726
Test set avg_accuracy=80.36% avg_sensitivity=40.92%, avg_specificity=94.45% avg_auc=79.55%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.217426 Test loss=0.498200 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.20123104751110077
[5/24] Train loss=0.1944185346364975
[10/24] Train loss=0.2195613831281662
[15/24] Train loss=0.22606495022773743
[20/24] Train loss=0.20983944833278656
Test set avg_accuracy=80.65% avg_sensitivity=47.90%, avg_specificity=92.35% avg_auc=81.44%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.214937 Test loss=0.470702 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.20381386578083038
[5/24] Train loss=0.2033413201570511
[10/24] Train loss=0.2162081003189087
[15/24] Train loss=0.20977532863616943
[20/24] Train loss=0.20415669679641724
Test set avg_accuracy=80.77% avg_sensitivity=56.01%, avg_specificity=89.61% avg_auc=83.43%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.210996 Test loss=0.453655 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.20243269205093384
[5/24] Train loss=0.20440009236335754
[10/24] Train loss=0.2151692509651184
[15/24] Train loss=0.2172108143568039
[20/24] Train loss=0.1934056133031845
Test set avg_accuracy=79.70% avg_sensitivity=44.58%, avg_specificity=92.24% avg_auc=78.42%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.209720 Test loss=0.489599 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.19510090351104736
[5/24] Train loss=0.20121833682060242
[10/24] Train loss=0.21958962082862854
[15/24] Train loss=0.20917518436908722
[20/24] Train loss=0.21487191319465637
Test set avg_accuracy=80.03% avg_sensitivity=39.44%, avg_specificity=94.52% avg_auc=80.34%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.213578 Test loss=0.493185 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.19620968401432037
[5/24] Train loss=0.19967418909072876
[10/24] Train loss=0.2149677872657776
[15/24] Train loss=0.20586299896240234
[20/24] Train loss=0.20520547032356262
Test set avg_accuracy=79.88% avg_sensitivity=52.15%, avg_specificity=89.79% avg_auc=81.70%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.209966 Test loss=0.475607 Current lr=[0.000156543481933168]

[0/24] Train loss=0.19210472702980042
[5/24] Train loss=0.18255117535591125
[10/24] Train loss=0.2062751203775406
[15/24] Train loss=0.19990889728069305
[20/24] Train loss=0.20411717891693115
Test set avg_accuracy=81.18% avg_sensitivity=60.22%, avg_specificity=88.67% avg_auc=84.42%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.205697 Test loss=0.442159 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.18728838860988617
[5/24] Train loss=0.1813601553440094
[10/24] Train loss=0.21244505047798157
[15/24] Train loss=0.207613006234169
[20/24] Train loss=0.19670093059539795
Test set avg_accuracy=80.17% avg_sensitivity=38.00%, avg_specificity=95.23% avg_auc=78.99%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.201803 Test loss=0.508658 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.18882416188716888
[5/24] Train loss=0.1820155680179596
[10/24] Train loss=0.1995706707239151
[15/24] Train loss=0.2025427520275116
[20/24] Train loss=0.1996343582868576
Test set avg_accuracy=81.91% avg_sensitivity=60.66%, avg_specificity=89.50% avg_auc=85.20%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.200350 Test loss=0.423357 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.18419069051742554
[5/24] Train loss=0.17570121586322784
[10/24] Train loss=0.20829880237579346
[15/24] Train loss=0.20727266371250153
[20/24] Train loss=0.2009335607290268
Test set avg_accuracy=81.30% avg_sensitivity=49.33%, avg_specificity=92.72% avg_auc=81.73%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.198331 Test loss=0.474612 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.18342575430870056
[5/24] Train loss=0.18078169226646423
[10/24] Train loss=0.2009010761976242
[15/24] Train loss=0.20615766942501068
[20/24] Train loss=0.19182276725769043
Test set avg_accuracy=80.12% avg_sensitivity=61.65%, avg_specificity=86.71% avg_auc=83.25%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.196456 Test loss=0.462709 Current lr=[0.000134135431043539]

[0/24] Train loss=0.17973756790161133
[5/24] Train loss=0.18241365253925323
[10/24] Train loss=0.20775286853313446
[15/24] Train loss=0.20868490636348724
[20/24] Train loss=0.19265151023864746
Test set avg_accuracy=79.32% avg_sensitivity=47.01%, avg_specificity=90.86% avg_auc=79.62%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.198559 Test loss=0.497844 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.18746517598628998
[5/24] Train loss=0.18080778419971466
[10/24] Train loss=0.20261381566524506
[15/24] Train loss=0.19760912656784058
[20/24] Train loss=0.1959189921617508
Test set avg_accuracy=80.17% avg_sensitivity=55.86%, avg_specificity=88.85% avg_auc=82.15%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.196186 Test loss=0.458682 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.18150709569454193
[5/24] Train loss=0.1766161471605301
[10/24] Train loss=0.2075427621603012
[15/24] Train loss=0.199778214097023
[20/24] Train loss=0.19540639221668243
Test set avg_accuracy=79.88% avg_sensitivity=48.49%, avg_specificity=91.09% avg_auc=79.83%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.198135 Test loss=0.494711 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.1786448210477829
[5/24] Train loss=0.17952442169189453
[10/24] Train loss=0.19039936363697052
[15/24] Train loss=0.1969045102596283
[20/24] Train loss=0.18335135281085968
Test set avg_accuracy=80.94% avg_sensitivity=57.00%, avg_specificity=89.49% avg_auc=83.12%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.191667 Test loss=0.452522 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.17115797102451324
[5/24] Train loss=0.16992910206317902
[10/24] Train loss=0.19222016632556915
[15/24] Train loss=0.1991083174943924
[20/24] Train loss=0.1837185025215149
Test set avg_accuracy=81.43% avg_sensitivity=53.14%, avg_specificity=91.54% avg_auc=83.46%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.187575 Test loss=0.443629 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.17209723591804504
[5/24] Train loss=0.17018312215805054
[10/24] Train loss=0.19158059358596802
[15/24] Train loss=0.18338735401630402
[20/24] Train loss=0.18162909150123596
Test set avg_accuracy=81.35% avg_sensitivity=54.08%, avg_specificity=91.09% avg_auc=84.14%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.185024 Test loss=0.448631 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.16445904970169067
[5/24] Train loss=0.17399124801158905
[10/24] Train loss=0.19272394478321075
[15/24] Train loss=0.18564075231552124
[20/24] Train loss=0.18344956636428833
Test set avg_accuracy=81.07% avg_sensitivity=44.14%, avg_specificity=94.26% avg_auc=80.45%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.185474 Test loss=0.500955 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.17131128907203674
[5/24] Train loss=0.17352540791034698
[10/24] Train loss=0.1858304738998413
[15/24] Train loss=0.19099406898021698
[20/24] Train loss=0.17891505360603333
Test set avg_accuracy=82.45% avg_sensitivity=53.74%, avg_specificity=92.70% avg_auc=83.19%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.184919 Test loss=0.441169 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.163683220744133
[5/24] Train loss=0.16447554528713226
[10/24] Train loss=0.18540462851524353
[15/24] Train loss=0.17698276042938232
[20/24] Train loss=0.18645232915878296
Test set avg_accuracy=80.91% avg_sensitivity=61.75%, avg_specificity=87.75% avg_auc=84.68%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.182062 Test loss=0.441871 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.16854602098464966
[5/24] Train loss=0.16233472526073456
[10/24] Train loss=0.18412263691425323
[15/24] Train loss=0.1832902729511261
[20/24] Train loss=0.17320093512535095
Test set avg_accuracy=80.05% avg_sensitivity=57.99%, avg_specificity=87.93% avg_auc=82.93%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.180465 Test loss=0.458996 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.16981574892997742
[5/24] Train loss=0.15890243649482727
[10/24] Train loss=0.18253158032894135
[15/24] Train loss=0.17224738001823425
[20/24] Train loss=0.17949631810188293
Test set avg_accuracy=81.33% avg_sensitivity=59.33%, avg_specificity=89.19% avg_auc=84.50%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.177005 Test loss=0.439815 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.170121431350708
[5/24] Train loss=0.17007187008857727
[10/24] Train loss=0.1786021590232849
[15/24] Train loss=0.17545554041862488
[20/24] Train loss=0.1773456186056137
Test set avg_accuracy=81.47% avg_sensitivity=57.74%, avg_specificity=89.95% avg_auc=83.56%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.176723 Test loss=0.450545 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.16040262579917908
[5/24] Train loss=0.1587056815624237
[10/24] Train loss=0.1839216649532318
[15/24] Train loss=0.1812099814414978
[20/24] Train loss=0.17235219478607178
Test set avg_accuracy=79.80% avg_sensitivity=64.82%, avg_specificity=85.16% avg_auc=83.86%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.176328 Test loss=0.464296 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1644384115934372
[5/24] Train loss=0.16570241749286652
[10/24] Train loss=0.1772913634777069
[15/24] Train loss=0.18255412578582764
[20/24] Train loss=0.1724568009376526
Test set avg_accuracy=80.25% avg_sensitivity=57.35%, avg_specificity=88.43% avg_auc=83.04%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.177986 Test loss=0.460289 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15574362874031067
[5/24] Train loss=0.1648647040128708
[10/24] Train loss=0.1710493564605713
[15/24] Train loss=0.1761239767074585
[20/24] Train loss=0.17199614644050598
Test set avg_accuracy=80.34% avg_sensitivity=69.62%, avg_specificity=84.17% avg_auc=84.87%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.172807 Test loss=0.459083 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.15795686841011047
[5/24] Train loss=0.1566183716058731
[10/24] Train loss=0.18201644718647003
[15/24] Train loss=0.17333394289016724
[20/24] Train loss=0.17590710520744324
Test set avg_accuracy=80.57% avg_sensitivity=68.98%, avg_specificity=84.71% avg_auc=84.47%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.173062 Test loss=0.456053 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.16405029594898224
[5/24] Train loss=0.15432558953762054
[10/24] Train loss=0.16968944668769836
[15/24] Train loss=0.1718912571668625
[20/24] Train loss=0.17319612205028534
Test set avg_accuracy=79.87% avg_sensitivity=70.21%, avg_specificity=83.32% avg_auc=84.62%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.171383 Test loss=0.474909 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.15609095990657806
[5/24] Train loss=0.15172795951366425
[10/24] Train loss=0.16300427913665771
[15/24] Train loss=0.1660650372505188
[20/24] Train loss=0.16502222418785095
Test set avg_accuracy=81.11% avg_sensitivity=68.68%, avg_specificity=85.55% avg_auc=85.07%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.167118 Test loss=0.452959 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.15087831020355225
[5/24] Train loss=0.15220774710178375
[10/24] Train loss=0.1683036983013153
[15/24] Train loss=0.16489802300930023
[20/24] Train loss=0.1723863035440445
Test set avg_accuracy=81.43% avg_sensitivity=64.52%, avg_specificity=87.47% avg_auc=84.97%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.165278 Test loss=0.438697 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.15647943317890167
[5/24] Train loss=0.15093497931957245
[10/24] Train loss=0.17155541479587555
[15/24] Train loss=0.16102713346481323
[20/24] Train loss=0.15852756798267365
Test set avg_accuracy=81.37% avg_sensitivity=56.80%, avg_specificity=90.14% avg_auc=83.53%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.163731 Test loss=0.447490 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1528007537126541
[5/24] Train loss=0.14534232020378113
[10/24] Train loss=0.16112472116947174
[15/24] Train loss=0.15920454263687134
[20/24] Train loss=0.15764500200748444
Test set avg_accuracy=81.78% avg_sensitivity=63.63%, avg_specificity=88.27% avg_auc=85.11%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.159036 Test loss=0.441803 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14398041367530823
[5/24] Train loss=0.14166198670864105
[10/24] Train loss=0.15503711998462677
[15/24] Train loss=0.1582680642604828
[20/24] Train loss=0.1538182944059372
Test set avg_accuracy=81.39% avg_sensitivity=65.91%, avg_specificity=86.92% avg_auc=84.94%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.155840 Test loss=0.444005 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13711637258529663
[5/24] Train loss=0.13929307460784912
[10/24] Train loss=0.15378199517726898
[15/24] Train loss=0.15224654972553253
[20/24] Train loss=0.1502581685781479
Test set avg_accuracy=82.02% avg_sensitivity=62.39%, avg_specificity=89.03% avg_auc=84.43%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.153975 Test loss=0.448103 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13658903539180756
[5/24] Train loss=0.14129586517810822
[10/24] Train loss=0.15175241231918335
[15/24] Train loss=0.1515636146068573
[20/24] Train loss=0.1533311903476715
Test set avg_accuracy=82.30% avg_sensitivity=64.82%, avg_specificity=88.55% avg_auc=84.56%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.152400 Test loss=0.438716 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13898847997188568
[5/24] Train loss=0.13860835134983063
[10/24] Train loss=0.15050621330738068
[15/24] Train loss=0.15264353156089783
[20/24] Train loss=0.1454385370016098
Test set avg_accuracy=82.16% avg_sensitivity=60.86%, avg_specificity=89.77% avg_auc=83.96%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.151595 Test loss=0.443461 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13869711756706238
[5/24] Train loss=0.13608326017856598
[10/24] Train loss=0.14606517553329468
[15/24] Train loss=0.15032818913459778
[20/24] Train loss=0.14495240151882172
Test set avg_accuracy=82.10% avg_sensitivity=62.05%, avg_specificity=89.26% avg_auc=84.15%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.149249 Test loss=0.445387 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13820010423660278
[5/24] Train loss=0.1343400776386261
[10/24] Train loss=0.1459706723690033
[15/24] Train loss=0.14738427102565765
[20/24] Train loss=0.1434914469718933
Test set avg_accuracy=81.55% avg_sensitivity=66.85%, avg_specificity=86.80% avg_auc=85.45%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.149204 Test loss=0.438676 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13617566227912903
[5/24] Train loss=0.13847550749778748
[10/24] Train loss=0.14562073349952698
[15/24] Train loss=0.14477457106113434
[20/24] Train loss=0.14523078501224518
Test set avg_accuracy=81.33% avg_sensitivity=65.51%, avg_specificity=86.98% avg_auc=84.11%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.148136 Test loss=0.451781 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.136723592877388
[5/24] Train loss=0.13343976438045502
[10/24] Train loss=0.14494146406650543
[15/24] Train loss=0.14411748945713043
[20/24] Train loss=0.14674457907676697
Test set avg_accuracy=81.48% avg_sensitivity=63.78%, avg_specificity=87.81% avg_auc=84.36%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.146155 Test loss=0.448634 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1334971785545349
[5/24] Train loss=0.13162080943584442
[10/24] Train loss=0.14060819149017334
[15/24] Train loss=0.14425405859947205
[20/24] Train loss=0.14097008109092712
Test set avg_accuracy=81.95% avg_sensitivity=65.36%, avg_specificity=87.88% avg_auc=84.48%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.145415 Test loss=0.446671 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13509811460971832
[5/24] Train loss=0.13286104798316956
[10/24] Train loss=0.1424773782491684
[15/24] Train loss=0.14625537395477295
[20/24] Train loss=0.14118264615535736
Test set avg_accuracy=81.48% avg_sensitivity=63.19%, avg_specificity=88.02% avg_auc=84.24%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.145070 Test loss=0.449604 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13904884457588196
[5/24] Train loss=0.131099134683609
[10/24] Train loss=0.14048081636428833
[15/24] Train loss=0.1416883021593094
[20/24] Train loss=0.1410781592130661
Test set avg_accuracy=81.73% avg_sensitivity=63.78%, avg_specificity=88.14% avg_auc=84.09%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.144114 Test loss=0.449773 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13373982906341553
[5/24] Train loss=0.12921355664730072
[10/24] Train loss=0.1385575532913208
[15/24] Train loss=0.14344194531440735
[20/24] Train loss=0.14288873970508575
Test set avg_accuracy=81.65% avg_sensitivity=64.77%, avg_specificity=87.68% avg_auc=83.97%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.143632 Test loss=0.453492 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13454119861125946
[5/24] Train loss=0.12933941185474396
[10/24] Train loss=0.1365983933210373
[15/24] Train loss=0.14364328980445862
[20/24] Train loss=0.1450522243976593
Test set avg_accuracy=81.58% avg_sensitivity=62.54%, avg_specificity=88.37% avg_auc=84.17%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.142598 Test loss=0.448699 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12894417345523834
[5/24] Train loss=0.1314220428466797
[10/24] Train loss=0.13857445120811462
[15/24] Train loss=0.14226526021957397
[20/24] Train loss=0.13835707306861877
Test set avg_accuracy=81.68% avg_sensitivity=62.59%, avg_specificity=88.50% avg_auc=83.95%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.141504 Test loss=0.449263 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.13046036660671234
[5/24] Train loss=0.12961049377918243
[10/24] Train loss=0.14000676572322845
[15/24] Train loss=0.14014992117881775
[20/24] Train loss=0.1436750441789627
Test set avg_accuracy=81.91% avg_sensitivity=64.57%, avg_specificity=88.11% avg_auc=84.30%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.142091 Test loss=0.447695 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12788839638233185
[5/24] Train loss=0.12732301652431488
[10/24] Train loss=0.14148478209972382
[15/24] Train loss=0.1420442909002304
[20/24] Train loss=0.1403043568134308
Test set avg_accuracy=81.90% avg_sensitivity=64.42%, avg_specificity=88.14% avg_auc=84.25%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.141064 Test loss=0.446213 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1290591061115265
[5/24] Train loss=0.12856611609458923
[10/24] Train loss=0.1352468580007553
[15/24] Train loss=0.14265090227127075
[20/24] Train loss=0.13984958827495575
Test set avg_accuracy=81.90% avg_sensitivity=64.97%, avg_specificity=87.95% avg_auc=84.45%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.140807 Test loss=0.446324 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12908732891082764
[5/24] Train loss=0.12935784459114075
[10/24] Train loss=0.13956604897975922
[15/24] Train loss=0.14225822687149048
[20/24] Train loss=0.14296966791152954
Test set avg_accuracy=81.74% avg_sensitivity=63.24%, avg_specificity=88.35% avg_auc=84.43%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.140522 Test loss=0.444675 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1344832181930542
[5/24] Train loss=0.12788526713848114
[10/24] Train loss=0.13936612010002136
[15/24] Train loss=0.14074097573757172
[20/24] Train loss=0.1380445808172226
Test set avg_accuracy=81.95% avg_sensitivity=63.88%, avg_specificity=88.41% avg_auc=84.40%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.140057 Test loss=0.446276 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1265949308872223
[5/24] Train loss=0.12863394618034363
[10/24] Train loss=0.1365184187889099
[15/24] Train loss=0.14392226934432983
[20/24] Train loss=0.1409701406955719
Test set avg_accuracy=81.98% avg_sensitivity=64.32%, avg_specificity=88.28% avg_auc=84.45%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.140266 Test loss=0.445899 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13119901716709137
[5/24] Train loss=0.12741844356060028
[10/24] Train loss=0.1351563185453415
[15/24] Train loss=0.14070305228233337
[20/24] Train loss=0.14237132668495178
Test set avg_accuracy=81.94% avg_sensitivity=64.13%, avg_specificity=88.30% avg_auc=84.44%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.140339 Test loss=0.444414 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12967482209205627
[5/24] Train loss=0.1259784698486328
[10/24] Train loss=0.1350407898426056
[15/24] Train loss=0.14543494582176208
[20/24] Train loss=0.13753458857536316
Test set avg_accuracy=82.04% avg_sensitivity=64.52%, avg_specificity=88.30% avg_auc=84.55%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.139242 Test loss=0.443772 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13056838512420654
[5/24] Train loss=0.1277352273464203
[10/24] Train loss=0.13930350542068481
[15/24] Train loss=0.14160332083702087
[20/24] Train loss=0.13823401927947998
Test set avg_accuracy=81.93% avg_sensitivity=64.08%, avg_specificity=88.30% avg_auc=84.56%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.139638 Test loss=0.444078 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1321655958890915
[5/24] Train loss=0.1283324658870697
[10/24] Train loss=0.135606586933136
[15/24] Train loss=0.1381220519542694
[20/24] Train loss=0.1383400708436966
Test set avg_accuracy=81.90% avg_sensitivity=63.78%, avg_specificity=88.37% avg_auc=84.50%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.139577 Test loss=0.444649 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12844441831111908
[5/24] Train loss=0.1300160139799118
[10/24] Train loss=0.14079292118549347
[15/24] Train loss=0.14023154973983765
[20/24] Train loss=0.14150266349315643
Test set avg_accuracy=81.91% avg_sensitivity=63.63%, avg_specificity=88.44% avg_auc=84.46%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.140269 Test loss=0.444748 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1289614737033844
[5/24] Train loss=0.12908601760864258
[10/24] Train loss=0.1364811360836029
[15/24] Train loss=0.13908761739730835
[20/24] Train loss=0.14015229046344757
Test set avg_accuracy=81.89% avg_sensitivity=63.58%, avg_specificity=88.43% avg_auc=84.46%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.139306 Test loss=0.444744 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1295386403799057
[5/24] Train loss=0.12609335780143738
[10/24] Train loss=0.1368960738182068
[15/24] Train loss=0.13982850313186646
[20/24] Train loss=0.13937382400035858
Test set avg_accuracy=81.89% avg_sensitivity=63.63%, avg_specificity=88.41% avg_auc=84.45%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.139321 Test loss=0.444581 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12592348456382751
[5/24] Train loss=0.1266307234764099
[10/24] Train loss=0.13675791025161743
[15/24] Train loss=0.14047890901565552
[20/24] Train loss=0.14132973551750183
Test set avg_accuracy=81.91% avg_sensitivity=63.68%, avg_specificity=88.43% avg_auc=84.46%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.139065 Test loss=0.444842 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=83.88% sen=57.35%, spe=93.36%, auc=88.01%!
Fold[1] Avg_overlap=0.42%(±0.3165466764159143)
[0/24] Train loss=0.7246737480163574
[5/24] Train loss=0.7178541421890259
[10/24] Train loss=0.7088523507118225
[15/24] Train loss=0.7008564472198486
[20/24] Train loss=0.7020032405853271
Test set avg_accuracy=51.41% avg_sensitivity=55.19%, avg_specificity=50.15% avg_auc=55.81%
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.709398 Test loss=0.701751 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6863295435905457
[5/24] Train loss=0.6819239258766174
[10/24] Train loss=0.6868788003921509
[15/24] Train loss=0.6825655698776245
[20/24] Train loss=0.6822693347930908
Test set avg_accuracy=64.80% avg_sensitivity=61.76%, avg_specificity=65.82% avg_auc=68.42%
Best model saved!! Metric=-65.197237430603!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.681897 Test loss=0.630318 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6622499227523804
[5/24] Train loss=0.6526484489440918
[10/24] Train loss=0.6565119624137878
[15/24] Train loss=0.6558245420455933
[20/24] Train loss=0.6488965749740601
Test set avg_accuracy=69.52% avg_sensitivity=63.95%, avg_specificity=71.37% avg_auc=73.73%
Best model saved!! Metric=-47.42485286392603!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.660939 Test loss=0.597838 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6463196873664856
[5/24] Train loss=0.6356090903282166
[10/24] Train loss=0.6295096278190613
[15/24] Train loss=0.629913866519928
[20/24] Train loss=0.6252588629722595
Test set avg_accuracy=71.89% avg_sensitivity=65.31%, avg_specificity=74.08% avg_auc=75.83%
Best model saved!! Metric=-38.89240935869539!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.639473 Test loss=0.576639 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6144740581512451
[5/24] Train loss=0.6175289750099182
[10/24] Train loss=0.6027542352676392
[15/24] Train loss=0.6025243997573853
[20/24] Train loss=0.6049101948738098
Test set avg_accuracy=72.90% avg_sensitivity=65.83%, avg_specificity=75.26% avg_auc=77.13%
Best model saved!! Metric=-34.882922575519544!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.619255 Test loss=0.561284 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5960045456886292
[5/24] Train loss=0.5980896353721619
[10/24] Train loss=0.5810022950172424
[15/24] Train loss=0.5957258939743042
[20/24] Train loss=0.5917821526527405
Test set avg_accuracy=73.65% avg_sensitivity=66.82%, avg_specificity=75.92% avg_auc=78.59%
Best model saved!! Metric=-31.027879886403227!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.601481 Test loss=0.543487 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5734711289405823
[5/24] Train loss=0.5663831233978271
[10/24] Train loss=0.5600470304489136
[15/24] Train loss=0.5744063854217529
[20/24] Train loss=0.5703691244125366
Test set avg_accuracy=74.87% avg_sensitivity=65.73%, avg_specificity=77.91% avg_auc=79.61%
Best model saved!! Metric=-27.881312706372697!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.580529 Test loss=0.525739 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5465030670166016
[5/24] Train loss=0.5426064729690552
[10/24] Train loss=0.5459005236625671
[15/24] Train loss=0.5517975091934204
[20/24] Train loss=0.5459192991256714
Test set avg_accuracy=75.92% avg_sensitivity=66.20%, avg_specificity=79.16% avg_auc=80.31%
Best model saved!! Metric=-24.404254916743298!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.560969 Test loss=0.509127 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5216971039772034
[5/24] Train loss=0.5294539332389832
[10/24] Train loss=0.5220488905906677
[15/24] Train loss=0.5306734442710876
[20/24] Train loss=0.528577983379364
Test set avg_accuracy=77.19% avg_sensitivity=65.57%, avg_specificity=81.05% avg_auc=81.25%
Best model saved!! Metric=-20.936869018592233!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.540650 Test loss=0.489926 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5086643099784851
[5/24] Train loss=0.5012045502662659
[10/24] Train loss=0.4986884593963623
[15/24] Train loss=0.5165182948112488
[20/24] Train loss=0.5059871077537537
Test set avg_accuracy=78.10% avg_sensitivity=64.37%, avg_specificity=82.67% avg_auc=82.02%
Best model saved!! Metric=-18.846392953829366!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.521767 Test loss=0.473138 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.488103449344635
[5/24] Train loss=0.49188119173049927
[10/24] Train loss=0.4787346422672272
[15/24] Train loss=0.5078728795051575
[20/24] Train loss=0.4794010519981384
Test set avg_accuracy=79.23% avg_sensitivity=62.49%, avg_specificity=84.80% avg_auc=82.99%
Best model saved!! Metric=-16.485846572181373!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.503439 Test loss=0.450880 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4733707010746002
[5/24] Train loss=0.4705616533756256
[10/24] Train loss=0.46682456135749817
[15/24] Train loss=0.4817705452442169
[20/24] Train loss=0.46062833070755005
Test set avg_accuracy=80.23% avg_sensitivity=62.96%, avg_specificity=85.98% avg_auc=83.79%
Best model saved!! Metric=-13.03602977581204!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.484665 Test loss=0.438467 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4568994641304016
[5/24] Train loss=0.45249953866004944
[10/24] Train loss=0.4488619863986969
[15/24] Train loss=0.46874409914016724
[20/24] Train loss=0.43533608317375183
Test set avg_accuracy=81.32% avg_sensitivity=61.24%, avg_specificity=87.99% avg_auc=84.93%
Best model saved!! Metric=-10.521984935642777!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.465778 Test loss=0.419959 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.43168219923973083
[5/24] Train loss=0.4391067922115326
[10/24] Train loss=0.4318329095840454
[15/24] Train loss=0.4501543343067169
[20/24] Train loss=0.42413854598999023
Test set avg_accuracy=81.74% avg_sensitivity=61.14%, avg_specificity=88.60% avg_auc=85.64%
Best model saved!! Metric=-8.880422100108248!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.448799 Test loss=0.407927 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4214542508125305
[5/24] Train loss=0.42323172092437744
[10/24] Train loss=0.42166730761528015
[15/24] Train loss=0.43285229802131653
[20/24] Train loss=0.4007106125354767
Test set avg_accuracy=82.30% avg_sensitivity=59.52%, avg_specificity=89.88% avg_auc=86.18%
Best model saved!! Metric=-8.115641454401334!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.432757 Test loss=0.397939 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.41280341148376465
[5/24] Train loss=0.408282071352005
[10/24] Train loss=0.41221538186073303
[15/24] Train loss=0.4203639030456543
[20/24] Train loss=0.38789281249046326
Test set avg_accuracy=82.53% avg_sensitivity=52.74%, avg_specificity=92.43% avg_auc=86.16%
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.421191 Test loss=0.391006 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.397592157125473
[5/24] Train loss=0.39237141609191895
[10/24] Train loss=0.4010971486568451
[15/24] Train loss=0.4142739176750183
[20/24] Train loss=0.37454232573509216
Test set avg_accuracy=82.96% avg_sensitivity=53.63%, avg_specificity=92.71% avg_auc=86.72%
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.410979 Test loss=0.385021 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3880862891674042
[5/24] Train loss=0.38757094740867615
[10/24] Train loss=0.3961641788482666
[15/24] Train loss=0.40423890948295593
[20/24] Train loss=0.3675503730773926
Test set avg_accuracy=83.09% avg_sensitivity=50.70%, avg_specificity=93.86% avg_auc=86.85%
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.402925 Test loss=0.382879 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.38201627135276794
[5/24] Train loss=0.37019288539886475
[10/24] Train loss=0.3846581280231476
[15/24] Train loss=0.39371559023857117
[20/24] Train loss=0.35125720500946045
Test set avg_accuracy=83.09% avg_sensitivity=59.78%, avg_specificity=90.84% avg_auc=87.11%
Best model saved!! Metric=-5.181141235418536!!
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.394095 Test loss=0.380894 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3694058358669281
[5/24] Train loss=0.37339240312576294
[10/24] Train loss=0.3822334408760071
[15/24] Train loss=0.3910806477069855
[20/24] Train loss=0.3526369035243988
Test set avg_accuracy=82.62% avg_sensitivity=45.28%, avg_specificity=95.04% avg_auc=87.01%
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.387674 Test loss=0.385551 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3671799898147583
[5/24] Train loss=0.3688960671424866
[10/24] Train loss=0.3736098110675812
[15/24] Train loss=0.3883230984210968
[20/24] Train loss=0.3455403447151184
Test set avg_accuracy=82.54% avg_sensitivity=45.49%, avg_specificity=94.86% avg_auc=86.82%
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.381893 Test loss=0.387306 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3606375455856323
[5/24] Train loss=0.363806813955307
[10/24] Train loss=0.3684685528278351
[15/24] Train loss=0.37110185623168945
[20/24] Train loss=0.3458971381187439
Test set avg_accuracy=81.82% avg_sensitivity=39.33%, avg_specificity=95.96% avg_auc=86.03%
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.376905 Test loss=0.411418 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.35598069429397583
[5/24] Train loss=0.35744500160217285
[10/24] Train loss=0.3616792857646942
[15/24] Train loss=0.37807929515838623
[20/24] Train loss=0.3330635130405426
Test set avg_accuracy=81.82% avg_sensitivity=38.29%, avg_specificity=96.30% avg_auc=87.14%
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.372260 Test loss=0.393685 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3584361970424652
[5/24] Train loss=0.3526778817176819
[10/24] Train loss=0.360774427652359
[15/24] Train loss=0.3628993034362793
[20/24] Train loss=0.33449938893318176
Test set avg_accuracy=81.48% avg_sensitivity=40.32%, avg_specificity=95.18% avg_auc=86.45%
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.369186 Test loss=0.397304 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3567117750644684
[5/24] Train loss=0.3542505204677582
[10/24] Train loss=0.35657453536987305
[15/24] Train loss=0.36283037066459656
[20/24] Train loss=0.33207565546035767
Test set avg_accuracy=81.78% avg_sensitivity=38.97%, avg_specificity=96.03% avg_auc=86.90%
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.364822 Test loss=0.396792 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3425714373588562
[5/24] Train loss=0.3447158932685852
[10/24] Train loss=0.3560141324996948
[15/24] Train loss=0.370441734790802
[20/24] Train loss=0.3293205499649048
Test set avg_accuracy=82.12% avg_sensitivity=39.23%, avg_specificity=96.39% avg_auc=87.26%
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.362652 Test loss=0.392722 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.33946657180786133
[5/24] Train loss=0.3459183871746063
[10/24] Train loss=0.35478630661964417
[15/24] Train loss=0.3620665371417999
[20/24] Train loss=0.3252091407775879
Test set avg_accuracy=80.99% avg_sensitivity=32.55%, avg_specificity=97.10% avg_auc=86.92%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.357931 Test loss=0.413282 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3442908823490143
[5/24] Train loss=0.3499222993850708
[10/24] Train loss=0.3437650501728058
[15/24] Train loss=0.3453603684902191
[20/24] Train loss=0.3253543972969055
Test set avg_accuracy=82.66% avg_sensitivity=54.36%, avg_specificity=92.07% avg_auc=86.35%
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.354349 Test loss=0.388697 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3448216915130615
[5/24] Train loss=0.342873215675354
[10/24] Train loss=0.3451431393623352
[15/24] Train loss=0.34906744956970215
[20/24] Train loss=0.3175472021102905
Test set avg_accuracy=81.51% avg_sensitivity=36.15%, avg_specificity=96.60% avg_auc=87.27%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.354815 Test loss=0.399854 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.33440572023391724
[5/24] Train loss=0.3389745354652405
[10/24] Train loss=0.3548116981983185
[15/24] Train loss=0.3368661105632782
[20/24] Train loss=0.30837222933769226
Test set avg_accuracy=82.84% avg_sensitivity=49.09%, avg_specificity=94.07% avg_auc=88.25%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.350155 Test loss=0.367912 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3267895579338074
[5/24] Train loss=0.34027379751205444
[10/24] Train loss=0.34171760082244873
[15/24] Train loss=0.3442511558532715
[20/24] Train loss=0.3120870292186737
Test set avg_accuracy=82.77% avg_sensitivity=51.07%, avg_specificity=93.32% avg_auc=87.39%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.346776 Test loss=0.375050 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.33297109603881836
[5/24] Train loss=0.3295627236366272
[10/24] Train loss=0.3491860032081604
[15/24] Train loss=0.3295619487762451
[20/24] Train loss=0.3138106167316437
Test set avg_accuracy=82.59% avg_sensitivity=48.41%, avg_specificity=93.96% avg_auc=87.22%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.342759 Test loss=0.380805 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3319976031780243
[5/24] Train loss=0.32495811581611633
[10/24] Train loss=0.34498000144958496
[15/24] Train loss=0.32594335079193115
[20/24] Train loss=0.3116714656352997
Test set avg_accuracy=83.09% avg_sensitivity=51.33%, avg_specificity=93.65% avg_auc=87.70%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.342187 Test loss=0.373624 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.33096352219581604
[5/24] Train loss=0.33180010318756104
[10/24] Train loss=0.35368216037750244
[15/24] Train loss=0.324974000453949
[20/24] Train loss=0.3071913421154022
Test set avg_accuracy=82.40% avg_sensitivity=42.98%, avg_specificity=95.51% avg_auc=88.08%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.339323 Test loss=0.375998 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3312477469444275
[5/24] Train loss=0.3268209397792816
[10/24] Train loss=0.34486934542655945
[15/24] Train loss=0.3271709084510803
[20/24] Train loss=0.3045670986175537
Test set avg_accuracy=83.22% avg_sensitivity=54.83%, avg_specificity=92.66% avg_auc=87.25%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.337193 Test loss=0.377426 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3243591785430908
[5/24] Train loss=0.3217223584651947
[10/24] Train loss=0.3525736331939697
[15/24] Train loss=0.3173430860042572
[20/24] Train loss=0.30830973386764526
Test set avg_accuracy=83.50% avg_sensitivity=69.27%, avg_specificity=88.24% avg_auc=87.96%
Best model saved!! Metric=2.9713640528001264!!
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.336818 Test loss=0.383399 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.32241711020469666
[5/24] Train loss=0.3287622034549713
[10/24] Train loss=0.3486371636390686
[15/24] Train loss=0.30706655979156494
[20/24] Train loss=0.303123414516449
Test set avg_accuracy=82.27% avg_sensitivity=60.72%, avg_specificity=89.43% avg_auc=86.23%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.333100 Test loss=0.398630 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.31780174374580383
[5/24] Train loss=0.3152881860733032
[10/24] Train loss=0.3387070298194885
[15/24] Train loss=0.31494778394699097
[20/24] Train loss=0.3036341369152069
Test set avg_accuracy=83.31% avg_sensitivity=53.36%, avg_specificity=93.27% avg_auc=87.50%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.329877 Test loss=0.373169 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.32194483280181885
[5/24] Train loss=0.3141886591911316
[10/24] Train loss=0.3293919861316681
[15/24] Train loss=0.3113095760345459
[20/24] Train loss=0.30899760127067566
Test set avg_accuracy=83.66% avg_sensitivity=64.74%, avg_specificity=89.95% avg_auc=88.29%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.326680 Test loss=0.370210 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3086971640586853
[5/24] Train loss=0.31140780448913574
[10/24] Train loss=0.326267272233963
[15/24] Train loss=0.2976098656654358
[20/24] Train loss=0.2959524989128113
Test set avg_accuracy=82.72% avg_sensitivity=55.19%, avg_specificity=91.88% avg_auc=86.73%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.324289 Test loss=0.384449 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.308716356754303
[5/24] Train loss=0.31450915336608887
[10/24] Train loss=0.33047914505004883
[15/24] Train loss=0.29688677191734314
[20/24] Train loss=0.29854846000671387
Test set avg_accuracy=82.96% avg_sensitivity=55.50%, avg_specificity=92.09% avg_auc=87.17%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.322941 Test loss=0.375846 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.30111202597618103
[5/24] Train loss=0.3135773539543152
[10/24] Train loss=0.33582910895347595
[15/24] Train loss=0.2968841791152954
[20/24] Train loss=0.2951792776584625
Test set avg_accuracy=82.47% avg_sensitivity=59.21%, avg_specificity=90.21% avg_auc=85.37%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.320149 Test loss=0.401793 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.31018131971359253
[5/24] Train loss=0.292827308177948
[10/24] Train loss=0.3278730511665344
[15/24] Train loss=0.29919150471687317
[20/24] Train loss=0.30568578839302063
Test set avg_accuracy=82.86% avg_sensitivity=46.58%, avg_specificity=94.93% avg_auc=86.97%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.320728 Test loss=0.385876 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.30941328406333923
[5/24] Train loss=0.3004637062549591
[10/24] Train loss=0.32983115315437317
[15/24] Train loss=0.29359933733940125
[20/24] Train loss=0.28230616450309753
Test set avg_accuracy=82.12% avg_sensitivity=41.00%, avg_specificity=95.80% avg_auc=85.60%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.316236 Test loss=0.398339 Current lr=[0.00029967723776099]

[0/24] Train loss=0.30532678961753845
[5/24] Train loss=0.30920132994651794
[10/24] Train loss=0.3234141170978546
[15/24] Train loss=0.28656384348869324
[20/24] Train loss=0.29955750703811646
Test set avg_accuracy=81.47% avg_sensitivity=36.83%, avg_specificity=96.32% avg_auc=84.00%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.314616 Test loss=0.419733 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.30641621351242065
[5/24] Train loss=0.30034568905830383
[10/24] Train loss=0.31682202219963074
[15/24] Train loss=0.2916054129600525
[20/24] Train loss=0.28812146186828613
Test set avg_accuracy=81.54% avg_sensitivity=50.29%, avg_specificity=91.93% avg_auc=82.69%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.310877 Test loss=0.426892 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.30965209007263184
[5/24] Train loss=0.2950659394264221
[10/24] Train loss=0.31171858310699463
[15/24] Train loss=0.2899407148361206
[20/24] Train loss=0.2821224331855774
Test set avg_accuracy=81.28% avg_sensitivity=58.42%, avg_specificity=88.88% avg_auc=84.34%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.310007 Test loss=0.423588 Current lr=[0.000299720220882401]

[0/24] Train loss=0.29337382316589355
[5/24] Train loss=0.30163052678108215
[10/24] Train loss=0.3129574954509735
[15/24] Train loss=0.28236493468284607
[20/24] Train loss=0.29790619015693665
Test set avg_accuracy=81.90% avg_sensitivity=52.01%, avg_specificity=91.84% avg_auc=83.56%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.309219 Test loss=0.414581 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.29180270433425903
[5/24] Train loss=0.2962566018104553
[10/24] Train loss=0.31581345200538635
[15/24] Train loss=0.2855547368526459
[20/24] Train loss=0.2987437844276428
Test set avg_accuracy=83.09% avg_sensitivity=46.48%, avg_specificity=95.26% avg_auc=85.76%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.306652 Test loss=0.397817 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2841370403766632
[5/24] Train loss=0.30025699734687805
[10/24] Train loss=0.31825268268585205
[15/24] Train loss=0.2859211266040802
[20/24] Train loss=0.29100367426872253
Test set avg_accuracy=81.50% avg_sensitivity=36.31%, avg_specificity=96.53% avg_auc=83.58%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.306156 Test loss=0.445021 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2981167137622833
[5/24] Train loss=0.2899443209171295
[10/24] Train loss=0.31753218173980713
[15/24] Train loss=0.27549242973327637
[20/24] Train loss=0.2775197923183441
Test set avg_accuracy=82.60% avg_sensitivity=48.30%, avg_specificity=94.01% avg_auc=85.22%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.303495 Test loss=0.408614 Current lr=[0.000297555943323901]

[0/24] Train loss=0.28272730112075806
[5/24] Train loss=0.28534725308418274
[10/24] Train loss=0.3178703188896179
[15/24] Train loss=0.2908014953136444
[20/24] Train loss=0.2809840440750122
Test set avg_accuracy=82.77% avg_sensitivity=60.56%, avg_specificity=90.16% avg_auc=85.77%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.304059 Test loss=0.396738 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.28495514392852783
[5/24] Train loss=0.28245508670806885
[10/24] Train loss=0.2958032190799713
[15/24] Train loss=0.27265188097953796
[20/24] Train loss=0.2882145047187805
Test set avg_accuracy=81.54% avg_sensitivity=54.20%, avg_specificity=90.63% avg_auc=84.70%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.298143 Test loss=0.407453 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2828490734100342
[5/24] Train loss=0.2912776470184326
[10/24] Train loss=0.3081192672252655
[15/24] Train loss=0.27978000044822693
[20/24] Train loss=0.28159695863723755
Test set avg_accuracy=81.85% avg_sensitivity=63.90%, avg_specificity=87.82% avg_auc=85.72%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.300639 Test loss=0.403378 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2935353219509125
[5/24] Train loss=0.27420946955680847
[10/24] Train loss=0.3013281226158142
[15/24] Train loss=0.28015708923339844
[20/24] Train loss=0.3050072491168976
Test set avg_accuracy=78.67% avg_sensitivity=52.06%, avg_specificity=87.52% avg_auc=82.06%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.297129 Test loss=0.439622 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.28697484731674194
[5/24] Train loss=0.287875235080719
[10/24] Train loss=0.3037171959877014
[15/24] Train loss=0.266731858253479
[20/24] Train loss=0.2780712842941284
Test set avg_accuracy=82.19% avg_sensitivity=41.26%, avg_specificity=95.80% avg_auc=84.37%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.294749 Test loss=0.417869 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.28209298849105835
[5/24] Train loss=0.26582953333854675
[10/24] Train loss=0.3019872307777405
[15/24] Train loss=0.26868152618408203
[20/24] Train loss=0.2916719615459442
Test set avg_accuracy=81.94% avg_sensitivity=55.92%, avg_specificity=90.60% avg_auc=84.21%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.293794 Test loss=0.411842 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.28394412994384766
[5/24] Train loss=0.2648140788078308
[10/24] Train loss=0.3012469708919525
[15/24] Train loss=0.25453728437423706
[20/24] Train loss=0.27692294120788574
Test set avg_accuracy=79.91% avg_sensitivity=27.86%, avg_specificity=97.22% avg_auc=78.42%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.292805 Test loss=0.507815 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.27695149183273315
[5/24] Train loss=0.27472078800201416
[10/24] Train loss=0.28995680809020996
[15/24] Train loss=0.25850412249565125
[20/24] Train loss=0.27148929238319397
Test set avg_accuracy=80.10% avg_sensitivity=41.99%, avg_specificity=92.78% avg_auc=80.15%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.288116 Test loss=0.449841 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2759248912334442
[5/24] Train loss=0.26314911246299744
[10/24] Train loss=0.2898872196674347
[15/24] Train loss=0.2723958492279053
[20/24] Train loss=0.27336326241493225
Test set avg_accuracy=82.10% avg_sensitivity=42.98%, avg_specificity=95.11% avg_auc=81.80%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.286282 Test loss=0.436966 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2826589047908783
[5/24] Train loss=0.27433905005455017
[10/24] Train loss=0.27838134765625
[15/24] Train loss=0.2512218654155731
[20/24] Train loss=0.2831684648990631
Test set avg_accuracy=79.78% avg_sensitivity=28.27%, avg_specificity=96.91% avg_auc=79.70%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.285887 Test loss=0.466879 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.277339369058609
[5/24] Train loss=0.26623135805130005
[10/24] Train loss=0.28611916303634644
[15/24] Train loss=0.2798484265804291
[20/24] Train loss=0.27579671144485474
Test set avg_accuracy=81.58% avg_sensitivity=36.46%, avg_specificity=96.58% avg_auc=84.24%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.283997 Test loss=0.438668 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2614521086215973
[5/24] Train loss=0.25932320952415466
[10/24] Train loss=0.2757679224014282
[15/24] Train loss=0.25101980566978455
[20/24] Train loss=0.27473193407058716
Test set avg_accuracy=81.91% avg_sensitivity=48.25%, avg_specificity=93.11% avg_auc=83.38%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.279076 Test loss=0.424668 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.26562073826789856
[5/24] Train loss=0.2586049735546112
[10/24] Train loss=0.2714778780937195
[15/24] Train loss=0.24657300114631653
[20/24] Train loss=0.26118555665016174
Test set avg_accuracy=80.79% avg_sensitivity=32.03%, avg_specificity=97.02% avg_auc=81.55%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.274107 Test loss=0.450933 Current lr=[0.000276307469034998]

[0/24] Train loss=0.26297661662101746
[5/24] Train loss=0.25934940576553345
[10/24] Train loss=0.2873604893684387
[15/24] Train loss=0.26190221309661865
[20/24] Train loss=0.2654487192630768
Test set avg_accuracy=81.71% avg_sensitivity=42.57%, avg_specificity=94.72% avg_auc=84.27%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.275774 Test loss=0.425888 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.26093626022338867
[5/24] Train loss=0.26393234729766846
[10/24] Train loss=0.2716006636619568
[15/24] Train loss=0.24427129328250885
[20/24] Train loss=0.2634037733078003
Test set avg_accuracy=81.22% avg_sensitivity=42.51%, avg_specificity=94.10% avg_auc=81.08%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.270946 Test loss=0.432981 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2535181939601898
[5/24] Train loss=0.2691842317581177
[10/24] Train loss=0.2842957675457001
[15/24] Train loss=0.23329530656337738
[20/24] Train loss=0.25390464067459106
Test set avg_accuracy=82.58% avg_sensitivity=45.91%, avg_specificity=94.78% avg_auc=84.12%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.271858 Test loss=0.424456 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2641119360923767
[5/24] Train loss=0.2543870508670807
[10/24] Train loss=0.27446863055229187
[15/24] Train loss=0.24891509115695953
[20/24] Train loss=0.24899782240390778
Test set avg_accuracy=82.29% avg_sensitivity=60.77%, avg_specificity=89.45% avg_auc=85.11%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.268464 Test loss=0.402352 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2627214789390564
[5/24] Train loss=0.2505890429019928
[10/24] Train loss=0.27509474754333496
[15/24] Train loss=0.23256880044937134
[20/24] Train loss=0.24509549140930176
Test set avg_accuracy=82.17% avg_sensitivity=45.44%, avg_specificity=94.40% avg_auc=84.74%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.265263 Test loss=0.423916 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.25098946690559387
[5/24] Train loss=0.2479211688041687
[10/24] Train loss=0.27033451199531555
[15/24] Train loss=0.2531062364578247
[20/24] Train loss=0.2546984851360321
Test set avg_accuracy=82.54% avg_sensitivity=50.39%, avg_specificity=93.23% avg_auc=85.59%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.263312 Test loss=0.403926 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.25269410014152527
[5/24] Train loss=0.24583201110363007
[10/24] Train loss=0.26976972818374634
[15/24] Train loss=0.23425503075122833
[20/24] Train loss=0.2478533387184143
Test set avg_accuracy=83.10% avg_sensitivity=65.73%, avg_specificity=88.88% avg_auc=86.85%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.261845 Test loss=0.391452 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.24812616407871246
[5/24] Train loss=0.2435820996761322
[10/24] Train loss=0.28010454773902893
[15/24] Train loss=0.23728327453136444
[20/24] Train loss=0.2619088292121887
Test set avg_accuracy=84.09% avg_sensitivity=56.23%, avg_specificity=93.35% avg_auc=87.39%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.261357 Test loss=0.372424 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.24308481812477112
[5/24] Train loss=0.2609468400478363
[10/24] Train loss=0.2696077525615692
[15/24] Train loss=0.2354906052350998
[20/24] Train loss=0.2344653606414795
Test set avg_accuracy=83.23% avg_sensitivity=63.02%, avg_specificity=89.95% avg_auc=86.20%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.254430 Test loss=0.394145 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.238887220621109
[5/24] Train loss=0.2389247715473175
[10/24] Train loss=0.2687510550022125
[15/24] Train loss=0.2209361046552658
[20/24] Train loss=0.2310960739850998
Test set avg_accuracy=83.26% avg_sensitivity=62.13%, avg_specificity=90.28% avg_auc=86.78%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.249107 Test loss=0.387969 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.23633889853954315
[5/24] Train loss=0.233648881316185
[10/24] Train loss=0.28046485781669617
[15/24] Train loss=0.22924265265464783
[20/24] Train loss=0.22311504185199738
Test set avg_accuracy=81.55% avg_sensitivity=37.14%, avg_specificity=96.32% avg_auc=81.58%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.251234 Test loss=0.492144 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2343960404396057
[5/24] Train loss=0.23453640937805176
[10/24] Train loss=0.26400983333587646
[15/24] Train loss=0.22968141734600067
[20/24] Train loss=0.23341229557991028
Test set avg_accuracy=82.62% avg_sensitivity=56.49%, avg_specificity=91.31% avg_auc=85.33%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.250324 Test loss=0.409887 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2398511916399002
[5/24] Train loss=0.24380752444267273
[10/24] Train loss=0.25597450137138367
[15/24] Train loss=0.2234109342098236
[20/24] Train loss=0.22731569409370422
Test set avg_accuracy=81.38% avg_sensitivity=57.85%, avg_specificity=89.21% avg_auc=83.51%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.249064 Test loss=0.434384 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.23532597720623016
[5/24] Train loss=0.24365779757499695
[10/24] Train loss=0.25030219554901123
[15/24] Train loss=0.24231263995170593
[20/24] Train loss=0.2315521240234375
Test set avg_accuracy=82.28% avg_sensitivity=61.97%, avg_specificity=89.03% avg_auc=84.90%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.250081 Test loss=0.422011 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2376423329114914
[5/24] Train loss=0.24041227996349335
[10/24] Train loss=0.2530005872249603
[15/24] Train loss=0.22462813556194305
[20/24] Train loss=0.2210197001695633
Test set avg_accuracy=74.53% avg_sensitivity=72.46%, avg_specificity=75.22% avg_auc=81.08%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.244662 Test loss=0.552977 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2271127849817276
[5/24] Train loss=0.226251482963562
[10/24] Train loss=0.26846542954444885
[15/24] Train loss=0.2172243446111679
[20/24] Train loss=0.22671888768672943
Test set avg_accuracy=82.90% avg_sensitivity=50.08%, avg_specificity=93.82% avg_auc=84.16%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.242995 Test loss=0.420881 Current lr=[0.000224838296036774]

[0/24] Train loss=0.22638742625713348
[5/24] Train loss=0.23241959512233734
[10/24] Train loss=0.25556111335754395
[15/24] Train loss=0.21010924875736237
[20/24] Train loss=0.2168632298707962
Test set avg_accuracy=80.85% avg_sensitivity=65.52%, avg_specificity=85.94% avg_auc=84.66%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.240052 Test loss=0.431068 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.22093774378299713
[5/24] Train loss=0.2251240462064743
[10/24] Train loss=0.25408899784088135
[15/24] Train loss=0.21698984503746033
[20/24] Train loss=0.22326688468456268
Test set avg_accuracy=82.85% avg_sensitivity=64.84%, avg_specificity=88.84% avg_auc=86.45%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.236080 Test loss=0.400525 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2197098433971405
[5/24] Train loss=0.23397640883922577
[10/24] Train loss=0.24590207636356354
[15/24] Train loss=0.21755041182041168
[20/24] Train loss=0.22292792797088623
Test set avg_accuracy=82.29% avg_sensitivity=67.92%, avg_specificity=87.07% avg_auc=86.28%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.239133 Test loss=0.413560 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.21751703321933746
[5/24] Train loss=0.21813403069972992
[10/24] Train loss=0.24649208784103394
[15/24] Train loss=0.21448437869548798
[20/24] Train loss=0.21175383031368256
Test set avg_accuracy=82.46% avg_sensitivity=64.74%, avg_specificity=88.36% avg_auc=86.66%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.238043 Test loss=0.400836 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2087659239768982
[5/24] Train loss=0.22013287246227264
[10/24] Train loss=0.2330670803785324
[15/24] Train loss=0.21831519901752472
[20/24] Train loss=0.21994611620903015
Test set avg_accuracy=82.30% avg_sensitivity=42.41%, avg_specificity=95.58% avg_auc=83.07%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.234678 Test loss=0.456312 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2174673229455948
[5/24] Train loss=0.22350706160068512
[10/24] Train loss=0.2307056486606598
[15/24] Train loss=0.2208019196987152
[20/24] Train loss=0.21860244870185852
Test set avg_accuracy=82.77% avg_sensitivity=52.84%, avg_specificity=92.73% avg_auc=84.97%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.233156 Test loss=0.412575 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.22056148946285248
[5/24] Train loss=0.21672096848487854
[10/24] Train loss=0.24485453963279724
[15/24] Train loss=0.21207010746002197
[20/24] Train loss=0.2130267471075058
Test set avg_accuracy=81.28% avg_sensitivity=36.20%, avg_specificity=96.27% avg_auc=82.48%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.229782 Test loss=0.472403 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.21691253781318665
[5/24] Train loss=0.2244342863559723
[10/24] Train loss=0.22759254276752472
[15/24] Train loss=0.20268514752388
[20/24] Train loss=0.20837019383907318
Test set avg_accuracy=82.24% avg_sensitivity=61.14%, avg_specificity=89.26% avg_auc=85.05%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.223655 Test loss=0.416813 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2091701328754425
[5/24] Train loss=0.22871585190296173
[10/24] Train loss=0.2386033982038498
[15/24] Train loss=0.20550891757011414
[20/24] Train loss=0.19277992844581604
Test set avg_accuracy=82.06% avg_sensitivity=51.23%, avg_specificity=92.31% avg_auc=83.28%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.221969 Test loss=0.428401 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.19654202461242676
[5/24] Train loss=0.21725720167160034
[10/24] Train loss=0.2251746654510498
[15/24] Train loss=0.1989336460828781
[20/24] Train loss=0.1952718198299408
Test set avg_accuracy=81.65% avg_sensitivity=60.56%, avg_specificity=88.67% avg_auc=84.81%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.217802 Test loss=0.424219 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.19915562868118286
[5/24] Train loss=0.2146146595478058
[10/24] Train loss=0.21740666031837463
[15/24] Train loss=0.189451202750206
[20/24] Train loss=0.1866542547941208
Test set avg_accuracy=80.68% avg_sensitivity=46.48%, avg_specificity=92.05% avg_auc=81.37%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.212171 Test loss=0.459546 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.19391067326068878
[5/24] Train loss=0.2055007517337799
[10/24] Train loss=0.21640729904174805
[15/24] Train loss=0.20687749981880188
[20/24] Train loss=0.18588827550411224
Test set avg_accuracy=80.83% avg_sensitivity=44.65%, avg_specificity=92.87% avg_auc=80.67%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.210906 Test loss=0.476425 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.19599470496177673
[5/24] Train loss=0.20305155217647552
[10/24] Train loss=0.20410892367362976
[15/24] Train loss=0.19498811662197113
[20/24] Train loss=0.1874360889196396
Test set avg_accuracy=79.47% avg_sensitivity=37.51%, avg_specificity=93.42% avg_auc=73.84%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.205936 Test loss=0.551460 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.1934049129486084
[5/24] Train loss=0.19588595628738403
[10/24] Train loss=0.20453855395317078
[15/24] Train loss=0.18636687099933624
[20/24] Train loss=0.1838330328464508
Test set avg_accuracy=81.68% avg_sensitivity=39.12%, avg_specificity=95.84% avg_auc=82.30%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.201237 Test loss=0.484559 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1820600926876068
[5/24] Train loss=0.19886340200901031
[10/24] Train loss=0.20700004696846008
[15/24] Train loss=0.18908031284809113
[20/24] Train loss=0.18781977891921997
Test set avg_accuracy=83.37% avg_sensitivity=47.89%, avg_specificity=95.18% avg_auc=83.72%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.200298 Test loss=0.444698 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.18778719007968903
[5/24] Train loss=0.20399214327335358
[10/24] Train loss=0.21082551777362823
[15/24] Train loss=0.19754689931869507
[20/24] Train loss=0.17972460389137268
Test set avg_accuracy=82.19% avg_sensitivity=44.65%, avg_specificity=94.67% avg_auc=81.24%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.202126 Test loss=0.474824 Current lr=[0.000156543481933168]

[0/24] Train loss=0.18672692775726318
[5/24] Train loss=0.20322047173976898
[10/24] Train loss=0.20644252002239227
[15/24] Train loss=0.18599794805049896
[20/24] Train loss=0.17422296106815338
Test set avg_accuracy=81.71% avg_sensitivity=49.66%, avg_specificity=92.37% avg_auc=81.85%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.196971 Test loss=0.471332 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.18517981469631195
[5/24] Train loss=0.1958184391260147
[10/24] Train loss=0.19470839202404022
[15/24] Train loss=0.18640153110027313
[20/24] Train loss=0.17589344084262848
Test set avg_accuracy=80.30% avg_sensitivity=42.25%, avg_specificity=92.96% avg_auc=81.39%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.197256 Test loss=0.464875 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.1886688619852066
[5/24] Train loss=0.20032943785190582
[10/24] Train loss=0.19520175457000732
[15/24] Train loss=0.1813165694475174
[20/24] Train loss=0.16909942030906677
Test set avg_accuracy=82.06% avg_sensitivity=51.17%, avg_specificity=92.33% avg_auc=84.29%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.194010 Test loss=0.429674 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.172420471906662
[5/24] Train loss=0.1948513388633728
[10/24] Train loss=0.1851189136505127
[15/24] Train loss=0.17891591787338257
[20/24] Train loss=0.17286911606788635
Test set avg_accuracy=81.56% avg_sensitivity=51.96%, avg_specificity=91.41% avg_auc=82.95%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.189778 Test loss=0.449546 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.188028484582901
[5/24] Train loss=0.18322248756885529
[10/24] Train loss=0.18213796615600586
[15/24] Train loss=0.1777275800704956
[20/24] Train loss=0.17203746736049652
Test set avg_accuracy=81.93% avg_sensitivity=58.27%, avg_specificity=89.80% avg_auc=83.09%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.185557 Test loss=0.437907 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16551126539707184
[5/24] Train loss=0.1961105912923813
[10/24] Train loss=0.18186640739440918
[15/24] Train loss=0.16529645025730133
[20/24] Train loss=0.15857990086078644
Test set avg_accuracy=82.60% avg_sensitivity=53.52%, avg_specificity=92.28% avg_auc=84.43%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.182446 Test loss=0.420769 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.166207954287529
[5/24] Train loss=0.18206849694252014
[10/24] Train loss=0.18089018762111664
[15/24] Train loss=0.16942927241325378
[20/24] Train loss=0.16202044486999512
Test set avg_accuracy=83.05% avg_sensitivity=53.73%, avg_specificity=92.80% avg_auc=84.00%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.176762 Test loss=0.430257 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1667589247226715
[5/24] Train loss=0.1804438978433609
[10/24] Train loss=0.18946629762649536
[15/24] Train loss=0.1648755669593811
[20/24] Train loss=0.16405121982097626
Test set avg_accuracy=84.04% avg_sensitivity=60.51%, avg_specificity=91.86% avg_auc=85.67%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.175937 Test loss=0.399122 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.16050975024700165
[5/24] Train loss=0.183874249458313
[10/24] Train loss=0.17899316549301147
[15/24] Train loss=0.16757996380329132
[20/24] Train loss=0.15539878606796265
Test set avg_accuracy=83.06% avg_sensitivity=54.88%, avg_specificity=92.43% avg_auc=85.19%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.175941 Test loss=0.418714 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.159649059176445
[5/24] Train loss=0.17533688247203827
[10/24] Train loss=0.17120397090911865
[15/24] Train loss=0.16613543033599854
[20/24] Train loss=0.15457889437675476
Test set avg_accuracy=83.68% avg_sensitivity=63.12%, avg_specificity=90.53% avg_auc=86.18%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.169942 Test loss=0.394846 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16306932270526886
[5/24] Train loss=0.17626501619815826
[10/24] Train loss=0.17273809015750885
[15/24] Train loss=0.1668853759765625
[20/24] Train loss=0.15156152844429016
Test set avg_accuracy=81.18% avg_sensitivity=47.21%, avg_specificity=92.49% avg_auc=81.74%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.172560 Test loss=0.456310 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.163089320063591
[5/24] Train loss=0.1737181395292282
[10/24] Train loss=0.1754927933216095
[15/24] Train loss=0.1586637794971466
[20/24] Train loss=0.15472523868083954
Test set avg_accuracy=82.67% avg_sensitivity=47.94%, avg_specificity=94.22% avg_auc=83.84%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.170273 Test loss=0.436464 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15749885141849518
[5/24] Train loss=0.17718788981437683
[10/24] Train loss=0.1656920462846756
[15/24] Train loss=0.15377359092235565
[20/24] Train loss=0.14938901364803314
Test set avg_accuracy=83.49% avg_sensitivity=65.94%, avg_specificity=89.33% avg_auc=86.10%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.167077 Test loss=0.406309 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1673031598329544
[5/24] Train loss=0.1722429096698761
[10/24] Train loss=0.16581904888153076
[15/24] Train loss=0.15974964201450348
[20/24] Train loss=0.1502658873796463
Test set avg_accuracy=83.44% avg_sensitivity=58.74%, avg_specificity=91.65% avg_auc=85.30%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.169854 Test loss=0.408470 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15343670547008514
[5/24] Train loss=0.17024219036102295
[10/24] Train loss=0.17479398846626282
[15/24] Train loss=0.1651807278394699
[20/24] Train loss=0.14833404123783112
Test set avg_accuracy=80.74% avg_sensitivity=66.20%, avg_specificity=85.58% avg_auc=83.84%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.169814 Test loss=0.451982 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.15803399682044983
[5/24] Train loss=0.16920971870422363
[10/24] Train loss=0.16951628029346466
[15/24] Train loss=0.1551341712474823
[20/24] Train loss=0.14547055959701538
Test set avg_accuracy=81.73% avg_sensitivity=67.71%, avg_specificity=86.40% avg_auc=84.80%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.167250 Test loss=0.434885 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.16303761303424835
[5/24] Train loss=0.1682964712381363
[10/24] Train loss=0.17250336706638336
[15/24] Train loss=0.1502329558134079
[20/24] Train loss=0.14997655153274536
Test set avg_accuracy=83.50% avg_sensitivity=56.34%, avg_specificity=92.54% avg_auc=84.73%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.167379 Test loss=0.415053 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.15117976069450378
[5/24] Train loss=0.1607760339975357
[10/24] Train loss=0.16203060746192932
[15/24] Train loss=0.15130546689033508
[20/24] Train loss=0.148018941283226
Test set avg_accuracy=81.95% avg_sensitivity=66.61%, avg_specificity=87.06% avg_auc=84.39%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.163031 Test loss=0.443785 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14992034435272217
[5/24] Train loss=0.16624660789966583
[10/24] Train loss=0.16388453543186188
[15/24] Train loss=0.15646640956401825
[20/24] Train loss=0.14010529220104218
Test set avg_accuracy=82.24% avg_sensitivity=64.21%, avg_specificity=88.24% avg_auc=84.76%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.159813 Test loss=0.436866 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1482757180929184
[5/24] Train loss=0.1573292464017868
[10/24] Train loss=0.16383735835552216
[15/24] Train loss=0.149578258395195
[20/24] Train loss=0.13519971072673798
Test set avg_accuracy=80.96% avg_sensitivity=65.99%, avg_specificity=85.94% avg_auc=83.78%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.157076 Test loss=0.469529 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.15118521451950073
[5/24] Train loss=0.1611386388540268
[10/24] Train loss=0.15956427156925201
[15/24] Train loss=0.14668062329292297
[20/24] Train loss=0.14344438910484314
Test set avg_accuracy=82.36% avg_sensitivity=60.41%, avg_specificity=89.66% avg_auc=84.95%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.156886 Test loss=0.427423 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14625634253025055
[5/24] Train loss=0.1563231498003006
[10/24] Train loss=0.1565575748682022
[15/24] Train loss=0.13682816922664642
[20/24] Train loss=0.13762223720550537
Test set avg_accuracy=83.53% avg_sensitivity=61.09%, avg_specificity=90.99% avg_auc=85.38%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.152362 Test loss=0.416543 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1351054608821869
[5/24] Train loss=0.1591019332408905
[10/24] Train loss=0.14962556958198547
[15/24] Train loss=0.13841408491134644
[20/24] Train loss=0.13724808394908905
Test set avg_accuracy=83.62% avg_sensitivity=58.11%, avg_specificity=92.10% avg_auc=85.32%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.150276 Test loss=0.410381 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13499069213867188
[5/24] Train loss=0.15146039426326752
[10/24] Train loss=0.15011808276176453
[15/24] Train loss=0.1361032873392105
[20/24] Train loss=0.1314079463481903
Test set avg_accuracy=82.88% avg_sensitivity=60.82%, avg_specificity=90.21% avg_auc=85.22%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.147519 Test loss=0.418324 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13317951560020447
[5/24] Train loss=0.14908209443092346
[10/24] Train loss=0.15151040256023407
[15/24] Train loss=0.1366855651140213
[20/24] Train loss=0.13369931280612946
Test set avg_accuracy=83.57% avg_sensitivity=62.23%, avg_specificity=90.66% avg_auc=85.99%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.145973 Test loss=0.409148 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.13536590337753296
[5/24] Train loss=0.151761993765831
[10/24] Train loss=0.1499147117137909
[15/24] Train loss=0.1340424120426178
[20/24] Train loss=0.1305682510137558
Test set avg_accuracy=83.06% avg_sensitivity=62.39%, avg_specificity=89.94% avg_auc=85.65%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.143940 Test loss=0.410601 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13201044499874115
[5/24] Train loss=0.14921490848064423
[10/24] Train loss=0.1434866338968277
[15/24] Train loss=0.13037726283073425
[20/24] Train loss=0.128825381398201
Test set avg_accuracy=83.49% avg_sensitivity=63.22%, avg_specificity=90.23% avg_auc=85.62%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.141531 Test loss=0.411716 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13566049933433533
[5/24] Train loss=0.14289645850658417
[10/24] Train loss=0.13893088698387146
[15/24] Train loss=0.13080894947052002
[20/24] Train loss=0.12430749833583832
Test set avg_accuracy=83.06% avg_sensitivity=64.74%, avg_specificity=89.15% avg_auc=86.32%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.138710 Test loss=0.407700 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12797614932060242
[5/24] Train loss=0.1417180299758911
[10/24] Train loss=0.1386227309703827
[15/24] Train loss=0.1310064047574997
[20/24] Train loss=0.12890702486038208
Test set avg_accuracy=83.40% avg_sensitivity=64.68%, avg_specificity=89.62% avg_auc=85.99%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.137958 Test loss=0.410846 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12674012780189514
[5/24] Train loss=0.14266164600849152
[10/24] Train loss=0.13739800453186035
[15/24] Train loss=0.12980709969997406
[20/24] Train loss=0.12704622745513916
Test set avg_accuracy=83.44% avg_sensitivity=62.02%, avg_specificity=90.56% avg_auc=85.87%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.137462 Test loss=0.407862 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12677940726280212
[5/24] Train loss=0.1361849159002304
[10/24] Train loss=0.13823828101158142
[15/24] Train loss=0.13187795877456665
[20/24] Train loss=0.12147252261638641
Test set avg_accuracy=84.04% avg_sensitivity=60.25%, avg_specificity=91.95% avg_auc=85.80%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.136108 Test loss=0.405554 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.125319704413414
[5/24] Train loss=0.13967645168304443
[10/24] Train loss=0.136973038315773
[15/24] Train loss=0.12599030137062073
[20/24] Train loss=0.12249923497438431
Test set avg_accuracy=83.49% avg_sensitivity=63.22%, avg_specificity=90.23% avg_auc=85.84%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.135510 Test loss=0.406685 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12461085617542267
[5/24] Train loss=0.14060825109481812
[10/24] Train loss=0.13189928233623505
[15/24] Train loss=0.12646040320396423
[20/24] Train loss=0.12373195588588715
Test set avg_accuracy=83.35% avg_sensitivity=64.16%, avg_specificity=89.73% avg_auc=85.84%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.134612 Test loss=0.411224 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12459070235490799
[5/24] Train loss=0.13920235633850098
[10/24] Train loss=0.13622935116291046
[15/24] Train loss=0.12743902206420898
[20/24] Train loss=0.1221388578414917
Test set avg_accuracy=83.49% avg_sensitivity=63.33%, avg_specificity=90.20% avg_auc=85.53%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.134608 Test loss=0.411430 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12355072051286697
[5/24] Train loss=0.1421157568693161
[10/24] Train loss=0.1328149288892746
[15/24] Train loss=0.12556929886341095
[20/24] Train loss=0.12189143896102905
Test set avg_accuracy=83.40% avg_sensitivity=63.02%, avg_specificity=90.18% avg_auc=86.22%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.133611 Test loss=0.407328 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1231946125626564
[5/24] Train loss=0.13525442779064178
[10/24] Train loss=0.1309259533882141
[15/24] Train loss=0.12526977062225342
[20/24] Train loss=0.11889227479696274
Test set avg_accuracy=83.16% avg_sensitivity=62.55%, avg_specificity=90.02% avg_auc=85.75%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.132039 Test loss=0.410388 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12103858590126038
[5/24] Train loss=0.136394664645195
[10/24] Train loss=0.13078194856643677
[15/24] Train loss=0.12455182522535324
[20/24] Train loss=0.11829861253499985
Test set avg_accuracy=83.74% avg_sensitivity=61.71%, avg_specificity=91.06% avg_auc=85.63%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.131200 Test loss=0.408359 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.11983957141637802
[5/24] Train loss=0.13533075153827667
[10/24] Train loss=0.13011442124843597
[15/24] Train loss=0.1262449324131012
[20/24] Train loss=0.11887252330780029
Test set avg_accuracy=83.44% avg_sensitivity=62.96%, avg_specificity=90.25% avg_auc=85.85%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.131155 Test loss=0.405820 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12170106917619705
[5/24] Train loss=0.13472366333007812
[10/24] Train loss=0.13204415142536163
[15/24] Train loss=0.12138213962316513
[20/24] Train loss=0.11925093084573746
Test set avg_accuracy=83.46% avg_sensitivity=63.59%, avg_specificity=90.07% avg_auc=86.08%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.130029 Test loss=0.407490 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12143450230360031
[5/24] Train loss=0.13336455821990967
[10/24] Train loss=0.13389313220977783
[15/24] Train loss=0.12205576151609421
[20/24] Train loss=0.11870574951171875
Test set avg_accuracy=83.49% avg_sensitivity=63.07%, avg_specificity=90.28% avg_auc=86.07%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.129913 Test loss=0.404418 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.119766004383564
[5/24] Train loss=0.1320504993200302
[10/24] Train loss=0.12864258885383606
[15/24] Train loss=0.12244800478219986
[20/24] Train loss=0.11784368008375168
Test set avg_accuracy=83.55% avg_sensitivity=63.17%, avg_specificity=90.33% avg_auc=85.96%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.129521 Test loss=0.407409 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.11913276463747025
[5/24] Train loss=0.13177421689033508
[10/24] Train loss=0.13174670934677124
[15/24] Train loss=0.12079670280218124
[20/24] Train loss=0.11484145373106003
Test set avg_accuracy=83.49% avg_sensitivity=63.33%, avg_specificity=90.20% avg_auc=85.94%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.128926 Test loss=0.408673 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12070964276790619
[5/24] Train loss=0.13310642540454865
[10/24] Train loss=0.13230912387371063
[15/24] Train loss=0.12037519365549088
[20/24] Train loss=0.11715066432952881
Test set avg_accuracy=83.48% avg_sensitivity=63.59%, avg_specificity=90.09% avg_auc=85.98%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.128836 Test loss=0.408407 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12041198462247849
[5/24] Train loss=0.13150055706501007
[10/24] Train loss=0.1302110254764557
[15/24] Train loss=0.12113551050424576
[20/24] Train loss=0.11706249415874481
Test set avg_accuracy=83.42% avg_sensitivity=63.69%, avg_specificity=89.99% avg_auc=85.98%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.128501 Test loss=0.407882 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11941041797399521
[5/24] Train loss=0.13090620934963226
[10/24] Train loss=0.1295163780450821
[15/24] Train loss=0.12117645144462585
[20/24] Train loss=0.11601339280605316
Test set avg_accuracy=83.42% avg_sensitivity=63.54%, avg_specificity=90.04% avg_auc=86.00%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.128279 Test loss=0.406960 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12025623768568039
[5/24] Train loss=0.13146574795246124
[10/24] Train loss=0.12821879982948303
[15/24] Train loss=0.11984723061323166
[20/24] Train loss=0.11684222519397736
Test set avg_accuracy=83.52% avg_sensitivity=63.90%, avg_specificity=90.04% avg_auc=85.88%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.128388 Test loss=0.408698 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11713346093893051
[5/24] Train loss=0.13384482264518738
[10/24] Train loss=0.128073588013649
[15/24] Train loss=0.12297303229570389
[20/24] Train loss=0.1173057109117508
Test set avg_accuracy=83.59% avg_sensitivity=63.59%, avg_specificity=90.25% avg_auc=85.87%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.128266 Test loss=0.408319 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.11752983182668686
[5/24] Train loss=0.13235779106616974
[10/24] Train loss=0.12637540698051453
[15/24] Train loss=0.11999423801898956
[20/24] Train loss=0.11690178513526917
Test set avg_accuracy=83.53% avg_sensitivity=63.12%, avg_specificity=90.32% avg_auc=85.86%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.127357 Test loss=0.408096 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11907139420509338
[5/24] Train loss=0.1315733790397644
[10/24] Train loss=0.1277371346950531
[15/24] Train loss=0.1198497861623764
[20/24] Train loss=0.11838056892156601
Test set avg_accuracy=83.55% avg_sensitivity=63.69%, avg_specificity=90.16% avg_auc=85.91%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.127630 Test loss=0.408571 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11889702826738358
[5/24] Train loss=0.1317349076271057
[10/24] Train loss=0.12717919051647186
[15/24] Train loss=0.12059687823057175
[20/24] Train loss=0.11684003472328186
Test set avg_accuracy=83.50% avg_sensitivity=63.59%, avg_specificity=90.13% avg_auc=85.93%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.127438 Test loss=0.407977 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11703593283891678
[5/24] Train loss=0.12965235114097595
[10/24] Train loss=0.1298154890537262
[15/24] Train loss=0.11930686235427856
[20/24] Train loss=0.11599162966012955
Test set avg_accuracy=83.49% avg_sensitivity=63.69%, avg_specificity=90.07% avg_auc=85.93%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.127677 Test loss=0.408222 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11698367446660995
[5/24] Train loss=0.13012626767158508
[10/24] Train loss=0.12758424878120422
[15/24] Train loss=0.12014632672071457
[20/24] Train loss=0.1158808246254921
Test set avg_accuracy=83.46% avg_sensitivity=63.54%, avg_specificity=90.09% avg_auc=85.92%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.127423 Test loss=0.408359 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11828232556581497
[5/24] Train loss=0.13307541608810425
[10/24] Train loss=0.12682731449604034
[15/24] Train loss=0.1199059709906578
[20/24] Train loss=0.11437609046697617
Test set avg_accuracy=83.48% avg_sensitivity=63.54%, avg_specificity=90.11% avg_auc=85.92%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.127383 Test loss=0.408340 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11826169490814209
[5/24] Train loss=0.13414771854877472
[10/24] Train loss=0.12812171876430511
[15/24] Train loss=0.11879070848226547
[20/24] Train loss=0.11627404391765594
Test set avg_accuracy=83.46% avg_sensitivity=63.54%, avg_specificity=90.09% avg_auc=85.92%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.127687 Test loss=0.408433 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=83.50% sen=69.27%, spe=88.24%, auc=87.96%!
Fold[2] Avg_overlap=0.29%(±0.33268141666342915)
[0/24] Train loss=0.7590201497077942
[5/24] Train loss=0.7485031485557556
[10/24] Train loss=0.7428582906723022
[15/24] Train loss=0.7359731793403625
[20/24] Train loss=0.7281562089920044
Test set avg_accuracy=57.42% avg_sensitivity=51.42%, avg_specificity=59.69% avg_auc=57.48%
Best model saved!! Metric=-99.97807564963794!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.740578 Test loss=0.668035 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.726208508014679
[5/24] Train loss=0.7268140912055969
[10/24] Train loss=0.7133257389068604
[15/24] Train loss=0.7119746208190918
[20/24] Train loss=0.7055001854896545
Test set avg_accuracy=65.92% avg_sensitivity=61.28%, avg_specificity=67.68% avg_auc=69.02%
Best model saved!! Metric=-62.096775523744896!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.712474 Test loss=0.630896 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6939980387687683
[5/24] Train loss=0.692432165145874
[10/24] Train loss=0.6852465867996216
[15/24] Train loss=0.685693621635437
[20/24] Train loss=0.6719980835914612
Test set avg_accuracy=69.15% avg_sensitivity=65.50%, avg_specificity=70.54% avg_auc=73.47%
Best model saved!! Metric=-47.340117301946236!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.688349 Test loss=0.606765 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.667405366897583
[5/24] Train loss=0.6686237454414368
[10/24] Train loss=0.6731716990470886
[15/24] Train loss=0.6611020565032959
[20/24] Train loss=0.6492111682891846
Test set avg_accuracy=71.00% avg_sensitivity=67.77%, avg_specificity=72.23% avg_auc=75.43%
Best model saved!! Metric=-39.56614599287114!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.669054 Test loss=0.589735 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6410540342330933
[5/24] Train loss=0.6450437903404236
[10/24] Train loss=0.6534838676452637
[15/24] Train loss=0.6395394802093506
[20/24] Train loss=0.6292585134506226
Test set avg_accuracy=71.81% avg_sensitivity=68.63%, avg_specificity=73.02% avg_auc=77.06%
Best model saved!! Metric=-35.491630624416786!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.647901 Test loss=0.569815 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6253941059112549
[5/24] Train loss=0.6263774037361145
[10/24] Train loss=0.6276549100875854
[15/24] Train loss=0.6212894916534424
[20/24] Train loss=0.6010991930961609
Test set avg_accuracy=73.55% avg_sensitivity=68.20%, avg_specificity=75.58% avg_auc=78.41%
Best model saved!! Metric=-30.253016261688785!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.627107 Test loss=0.547381 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5961024761199951
[5/24] Train loss=0.5978063941001892
[10/24] Train loss=0.6058743000030518
[15/24] Train loss=0.5988757014274597
[20/24] Train loss=0.5749282240867615
Test set avg_accuracy=75.14% avg_sensitivity=66.68%, avg_specificity=78.35% avg_auc=79.43%
Best model saved!! Metric=-26.394000576286018!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.605086 Test loss=0.525903 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5744296908378601
[5/24] Train loss=0.5771809816360474
[10/24] Train loss=0.5891870260238647
[15/24] Train loss=0.5765265226364136
[20/24] Train loss=0.5504431128501892
Test set avg_accuracy=76.20% avg_sensitivity=65.73%, avg_specificity=80.16% avg_auc=80.48%
Best model saved!! Metric=-23.43067080685006!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.582157 Test loss=0.509693 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5523483753204346
[5/24] Train loss=0.5485143065452576
[10/24] Train loss=0.5589145421981812
[15/24] Train loss=0.5549425482749939
[20/24] Train loss=0.5229880213737488
Test set avg_accuracy=77.24% avg_sensitivity=65.40%, avg_specificity=81.72% avg_auc=81.22%
Best model saved!! Metric=-20.416470169266063!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.559849 Test loss=0.493536 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5265965461730957
[5/24] Train loss=0.5291362404823303
[10/24] Train loss=0.5454864501953125
[15/24] Train loss=0.5378355383872986
[20/24] Train loss=0.5060198307037354
Test set avg_accuracy=78.50% avg_sensitivity=61.37%, avg_specificity=84.99% avg_auc=81.74%
Best model saved!! Metric=-19.396176539043516!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.537395 Test loss=0.473290 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5043333768844604
[5/24] Train loss=0.5101662278175354
[10/24] Train loss=0.5197312831878662
[15/24] Train loss=0.5177725553512573
[20/24] Train loss=0.48252445459365845
Test set avg_accuracy=79.44% avg_sensitivity=61.09%, avg_specificity=86.39% avg_auc=82.56%
Best model saved!! Metric=-16.521245140301083!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.515385 Test loss=0.460849 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4835865795612335
[5/24] Train loss=0.48132264614105225
[10/24] Train loss=0.5039694905281067
[15/24] Train loss=0.49640148878097534
[20/24] Train loss=0.45012184977531433
Test set avg_accuracy=79.93% avg_sensitivity=60.24%, avg_specificity=87.40% avg_auc=83.19%
Best model saved!! Metric=-15.239017395116313!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.492954 Test loss=0.450495 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.46340397000312805
[5/24] Train loss=0.46369001269340515
[10/24] Train loss=0.48143887519836426
[15/24] Train loss=0.48559680581092834
[20/24] Train loss=0.4339831471443176
Test set avg_accuracy=80.76% avg_sensitivity=59.86%, avg_specificity=88.67% avg_auc=84.18%
Best model saved!! Metric=-12.53347426726058!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.473051 Test loss=0.435328 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4492853283882141
[5/24] Train loss=0.4422295093536377
[10/24] Train loss=0.47383782267570496
[15/24] Train loss=0.46126312017440796
[20/24] Train loss=0.42285117506980896
Test set avg_accuracy=81.21% avg_sensitivity=57.16%, avg_specificity=90.32% avg_auc=84.47%
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.454492 Test loss=0.426935 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4337729215621948
[5/24] Train loss=0.4295974373817444
[10/24] Train loss=0.4579170048236847
[15/24] Train loss=0.4489588141441345
[20/24] Train loss=0.40304458141326904
Test set avg_accuracy=81.48% avg_sensitivity=59.00%, avg_specificity=90.00% avg_auc=85.00%
Best model saved!! Metric=-10.509005244539544!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.437360 Test loss=0.419558 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4173492193222046
[5/24] Train loss=0.4121152460575104
[10/24] Train loss=0.4479702413082123
[15/24] Train loss=0.4352947771549225
[20/24] Train loss=0.38607871532440186
Test set avg_accuracy=81.32% avg_sensitivity=55.12%, avg_specificity=91.24% avg_auc=85.36%
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.422271 Test loss=0.412606 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4180922508239746
[5/24] Train loss=0.40131595730781555
[10/24] Train loss=0.442415326833725
[15/24] Train loss=0.41998469829559326
[20/24] Train loss=0.37578240036964417
Test set avg_accuracy=81.63% avg_sensitivity=53.93%, avg_specificity=92.12% avg_auc=85.73%
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.412576 Test loss=0.408131 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.40929633378982544
[5/24] Train loss=0.3970213234424591
[10/24] Train loss=0.4392424523830414
[15/24] Train loss=0.4215027689933777
[20/24] Train loss=0.36559104919433594
Test set avg_accuracy=81.43% avg_sensitivity=53.13%, avg_specificity=92.15% avg_auc=85.95%
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.402934 Test loss=0.406015 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.40297192335128784
[5/24] Train loss=0.3871043622493744
[10/24] Train loss=0.4341120719909668
[15/24] Train loss=0.39861947298049927
[20/24] Train loss=0.35575079917907715
Test set avg_accuracy=81.67% avg_sensitivity=47.82%, avg_specificity=94.49% avg_auc=85.85%
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.393727 Test loss=0.408849 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.38466358184814453
[5/24] Train loss=0.36943188309669495
[10/24] Train loss=0.41717106103897095
[15/24] Train loss=0.3953149914741516
[20/24] Train loss=0.34993988275527954
Test set avg_accuracy=81.58% avg_sensitivity=47.44%, avg_specificity=94.51% avg_auc=85.72%
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.383045 Test loss=0.411521 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3779723048210144
[5/24] Train loss=0.35870394110679626
[10/24] Train loss=0.4198914170265198
[15/24] Train loss=0.39472344517707825
[20/24] Train loss=0.3420453667640686
Test set avg_accuracy=81.47% avg_sensitivity=45.36%, avg_specificity=95.15% avg_auc=85.48%
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.376772 Test loss=0.420189 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3726508617401123
[5/24] Train loss=0.3551146984100342
[10/24] Train loss=0.415798157453537
[15/24] Train loss=0.3892224133014679
[20/24] Train loss=0.3355395197868347
Test set avg_accuracy=82.04% avg_sensitivity=50.81%, avg_specificity=93.88% avg_auc=86.42%
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.371586 Test loss=0.401948 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.37278199195861816
[5/24] Train loss=0.3437940776348114
[10/24] Train loss=0.4118030071258545
[15/24] Train loss=0.3835113048553467
[20/24] Train loss=0.32514211535453796
Test set avg_accuracy=80.46% avg_sensitivity=35.45%, avg_specificity=97.50% avg_auc=84.51%
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.365687 Test loss=0.460083 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3612831234931946
[5/24] Train loss=0.34910348057746887
[10/24] Train loss=0.4097211956977844
[15/24] Train loss=0.3783356547355652
[20/24] Train loss=0.32252973318099976
Test set avg_accuracy=81.39% avg_sensitivity=45.45%, avg_specificity=95.01% avg_auc=85.45%
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.360272 Test loss=0.424681 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3616279661655426
[5/24] Train loss=0.3397931456565857
[10/24] Train loss=0.40683621168136597
[15/24] Train loss=0.3719612956047058
[20/24] Train loss=0.3147510588169098
Test set avg_accuracy=81.05% avg_sensitivity=41.56%, avg_specificity=96.01% avg_auc=85.51%
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.355203 Test loss=0.436380 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3592076301574707
[5/24] Train loss=0.32699650526046753
[10/24] Train loss=0.39971065521240234
[15/24] Train loss=0.3625134229660034
[20/24] Train loss=0.30792948603630066
Test set avg_accuracy=80.79% avg_sensitivity=43.13%, avg_specificity=95.06% avg_auc=85.23%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.348635 Test loss=0.431202 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.361307829618454
[5/24] Train loss=0.32606643438339233
[10/24] Train loss=0.39959052205085754
[15/24] Train loss=0.3710499107837677
[20/24] Train loss=0.30653029680252075
Test set avg_accuracy=80.22% avg_sensitivity=36.40%, avg_specificity=96.82% avg_auc=84.81%
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.346778 Test loss=0.453062 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.355034202337265
[5/24] Train loss=0.32520073652267456
[10/24] Train loss=0.3858168423175812
[15/24] Train loss=0.35854512453079224
[20/24] Train loss=0.3028474748134613
Test set avg_accuracy=80.14% avg_sensitivity=37.39%, avg_specificity=96.34% avg_auc=85.12%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.343193 Test loss=0.440417 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3605864346027374
[5/24] Train loss=0.3277195692062378
[10/24] Train loss=0.38833269476890564
[15/24] Train loss=0.3644779324531555
[20/24] Train loss=0.30260613560676575
Test set avg_accuracy=81.24% avg_sensitivity=46.82%, avg_specificity=94.27% avg_auc=85.21%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.339395 Test loss=0.425324 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.34314653277397156
[5/24] Train loss=0.3204192817211151
[10/24] Train loss=0.3903068006038666
[15/24] Train loss=0.3446691632270813
[20/24] Train loss=0.29392316937446594
Test set avg_accuracy=79.93% avg_sensitivity=34.88%, avg_specificity=97.00% avg_auc=85.27%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.331732 Test loss=0.456577 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.33356836438179016
[5/24] Train loss=0.31943780183792114
[10/24] Train loss=0.3747529089450836
[15/24] Train loss=0.35662174224853516
[20/24] Train loss=0.2953164577484131
Test set avg_accuracy=80.69% avg_sensitivity=47.73%, avg_specificity=93.18% avg_auc=85.23%
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.331535 Test loss=0.416733 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3432845175266266
[5/24] Train loss=0.30756834149360657
[10/24] Train loss=0.3710295557975769
[15/24] Train loss=0.3550894558429718
[20/24] Train loss=0.29180118441581726
Test set avg_accuracy=77.15% avg_sensitivity=24.55%, avg_specificity=97.07% avg_auc=80.53%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.325411 Test loss=0.538011 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3474457263946533
[5/24] Train loss=0.31523433327674866
[10/24] Train loss=0.3853435814380646
[15/24] Train loss=0.3353031277656555
[20/24] Train loss=0.2940823435783386
Test set avg_accuracy=79.84% avg_sensitivity=56.73%, avg_specificity=88.60% avg_auc=82.93%
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.326864 Test loss=0.444808 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3213908076286316
[5/24] Train loss=0.3203141689300537
[10/24] Train loss=0.3662947118282318
[15/24] Train loss=0.34253907203674316
[20/24] Train loss=0.2856413722038269
Test set avg_accuracy=78.20% avg_sensitivity=30.62%, avg_specificity=96.23% avg_auc=80.34%
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.323569 Test loss=0.529646 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.31976449489593506
[5/24] Train loss=0.31086304783821106
[10/24] Train loss=0.3715507984161377
[15/24] Train loss=0.3443625271320343
[20/24] Train loss=0.28255409002304077
Test set avg_accuracy=77.25% avg_sensitivity=25.07%, avg_specificity=97.02% avg_auc=80.88%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.322263 Test loss=0.515046 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3181104362010956
[5/24] Train loss=0.3149803876876831
[10/24] Train loss=0.3697412312030792
[15/24] Train loss=0.3389468789100647
[20/24] Train loss=0.2919357717037201
Test set avg_accuracy=81.02% avg_sensitivity=50.43%, avg_specificity=92.60% avg_auc=85.06%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.318673 Test loss=0.421246 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3124549984931946
[5/24] Train loss=0.3017849028110504
[10/24] Train loss=0.3629554510116577
[15/24] Train loss=0.34097614884376526
[20/24] Train loss=0.2815656363964081
Test set avg_accuracy=81.20% avg_sensitivity=47.06%, avg_specificity=94.13% avg_auc=84.58%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.314441 Test loss=0.440296 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3237692713737488
[5/24] Train loss=0.30238425731658936
[10/24] Train loss=0.37384963035583496
[15/24] Train loss=0.3400067687034607
[20/24] Train loss=0.27671536803245544
Test set avg_accuracy=76.63% avg_sensitivity=19.81%, avg_specificity=98.15% avg_auc=81.15%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.313821 Test loss=0.584494 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3112601041793823
[5/24] Train loss=0.2990144193172455
[10/24] Train loss=0.371524453163147
[15/24] Train loss=0.33244186639785767
[20/24] Train loss=0.275471568107605
Test set avg_accuracy=76.07% avg_sensitivity=16.54%, avg_specificity=98.62% avg_auc=77.75%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.313276 Test loss=0.625726 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.30917513370513916
[5/24] Train loss=0.28939661383628845
[10/24] Train loss=0.36170274019241333
[15/24] Train loss=0.3240744173526764
[20/24] Train loss=0.2811511158943176
Test set avg_accuracy=80.13% avg_sensitivity=46.35%, avg_specificity=92.93% avg_auc=84.47%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.307506 Test loss=0.425538 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.31164324283599854
[5/24] Train loss=0.28849056363105774
[10/24] Train loss=0.34755244851112366
[15/24] Train loss=0.3305041790008545
[20/24] Train loss=0.26533985137939453
Test set avg_accuracy=80.56% avg_sensitivity=55.36%, avg_specificity=90.11% avg_auc=83.50%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.304989 Test loss=0.437010 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.28839972615242004
[5/24] Train loss=0.2809240221977234
[10/24] Train loss=0.35764575004577637
[15/24] Train loss=0.3239818513393402
[20/24] Train loss=0.26991233229637146
Test set avg_accuracy=76.99% avg_sensitivity=64.45%, avg_specificity=81.74% avg_auc=80.39%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.298543 Test loss=0.502095 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.28992190957069397
[5/24] Train loss=0.2783290445804596
[10/24] Train loss=0.36397331953048706
[15/24] Train loss=0.3273797035217285
[20/24] Train loss=0.2673809826374054
Test set avg_accuracy=78.70% avg_sensitivity=36.26%, avg_specificity=94.78% avg_auc=81.52%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.302117 Test loss=0.483920 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.29187020659446716
[5/24] Train loss=0.2849371135234833
[10/24] Train loss=0.3450089395046234
[15/24] Train loss=0.3073747456073761
[20/24] Train loss=0.2564878463745117
Test set avg_accuracy=75.53% avg_sensitivity=14.93%, avg_specificity=98.49% avg_auc=76.52%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.294402 Test loss=0.689541 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2886304259300232
[5/24] Train loss=0.2812809646129608
[10/24] Train loss=0.3419869840145111
[15/24] Train loss=0.3210589587688446
[20/24] Train loss=0.2674340009689331
Test set avg_accuracy=79.73% avg_sensitivity=38.77%, avg_specificity=95.24% avg_auc=82.51%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.296029 Test loss=0.500006 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.278845876455307
[5/24] Train loss=0.26801905035972595
[10/24] Train loss=0.34144529700279236
[15/24] Train loss=0.3267657458782196
[20/24] Train loss=0.2685675621032715
Test set avg_accuracy=78.49% avg_sensitivity=34.22%, avg_specificity=95.26% avg_auc=81.75%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.297486 Test loss=0.511249 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2770116329193115
[5/24] Train loss=0.2681617736816406
[10/24] Train loss=0.3476001024246216
[15/24] Train loss=0.31375035643577576
[20/24] Train loss=0.2595618963241577
Test set avg_accuracy=75.59% avg_sensitivity=13.89%, avg_specificity=98.96% avg_auc=73.16%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.294301 Test loss=0.699356 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2826378047466278
[5/24] Train loss=0.2647395133972168
[10/24] Train loss=0.3450154662132263
[15/24] Train loss=0.316756933927536
[20/24] Train loss=0.2682558000087738
Test set avg_accuracy=74.57% avg_sensitivity=8.86%, avg_specificity=99.46% avg_auc=74.57%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.288849 Test loss=0.745739 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2885708510875702
[5/24] Train loss=0.26698538661003113
[10/24] Train loss=0.3405260145664215
[15/24] Train loss=0.3033105432987213
[20/24] Train loss=0.27182355523109436
Test set avg_accuracy=77.50% avg_sensitivity=24.50%, avg_specificity=97.58% avg_auc=77.10%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.291239 Test loss=0.585248 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2782363295555115
[5/24] Train loss=0.24710392951965332
[10/24] Train loss=0.3389042913913727
[15/24] Train loss=0.30335360765457153
[20/24] Train loss=0.27331990003585815
Test set avg_accuracy=75.13% avg_sensitivity=13.60%, avg_specificity=98.44% avg_auc=76.61%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.287682 Test loss=0.586181 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.31350576877593994
[5/24] Train loss=0.2607499361038208
[10/24] Train loss=0.34537380933761597
[15/24] Train loss=0.31171825528144836
[20/24] Train loss=0.25586462020874023
Test set avg_accuracy=77.11% avg_sensitivity=21.09%, avg_specificity=98.33% avg_auc=81.16%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.290346 Test loss=0.564158 Current lr=[0.000297555943323901]

[0/24] Train loss=0.28075605630874634
[5/24] Train loss=0.24821807444095612
[10/24] Train loss=0.31188657879829407
[15/24] Train loss=0.3098478615283966
[20/24] Train loss=0.2555503845214844
Test set avg_accuracy=77.75% avg_sensitivity=25.07%, avg_specificity=97.70% avg_auc=83.47%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.284364 Test loss=0.487516 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.26938220858573914
[5/24] Train loss=0.25527000427246094
[10/24] Train loss=0.32814255356788635
[15/24] Train loss=0.3159888684749603
[20/24] Train loss=0.24611057341098785
Test set avg_accuracy=79.84% avg_sensitivity=38.34%, avg_specificity=95.57% avg_auc=80.47%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.283102 Test loss=0.504423 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.27012941241264343
[5/24] Train loss=0.2486187070608139
[10/24] Train loss=0.31604012846946716
[15/24] Train loss=0.3002726435661316
[20/24] Train loss=0.26021167635917664
Test set avg_accuracy=77.46% avg_sensitivity=23.93%, avg_specificity=97.74% avg_auc=73.53%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.284588 Test loss=0.653597 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2930792570114136
[5/24] Train loss=0.24316325783729553
[10/24] Train loss=0.30854305624961853
[15/24] Train loss=0.3109535872936249
[20/24] Train loss=0.24762454628944397
Test set avg_accuracy=76.90% avg_sensitivity=22.99%, avg_specificity=97.32% avg_auc=79.39%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.276975 Test loss=0.571043 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.26790785789489746
[5/24] Train loss=0.2412555068731308
[10/24] Train loss=0.3196534514427185
[15/24] Train loss=0.30147555470466614
[20/24] Train loss=0.24893857538700104
Test set avg_accuracy=76.65% avg_sensitivity=20.52%, avg_specificity=97.92% avg_auc=74.98%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.273706 Test loss=0.652284 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.2891762852668762
[5/24] Train loss=0.24992521107196808
[10/24] Train loss=0.297992467880249
[15/24] Train loss=0.3057214319705963
[20/24] Train loss=0.2604573369026184
Test set avg_accuracy=76.50% avg_sensitivity=20.24%, avg_specificity=97.81% avg_auc=77.26%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.276289 Test loss=0.619710 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2667449116706848
[5/24] Train loss=0.2613283693790436
[10/24] Train loss=0.30361369252204895
[15/24] Train loss=0.27685821056365967
[20/24] Train loss=0.2506057024002075
Test set avg_accuracy=79.75% avg_sensitivity=43.32%, avg_specificity=93.55% avg_auc=81.07%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.272964 Test loss=0.499089 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2558652460575104
[5/24] Train loss=0.24618366360664368
[10/24] Train loss=0.29964926838874817
[15/24] Train loss=0.28906771540641785
[20/24] Train loss=0.24124133586883545
Test set avg_accuracy=78.22% avg_sensitivity=30.71%, avg_specificity=96.21% avg_auc=77.95%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.267559 Test loss=0.591198 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2825993299484253
[5/24] Train loss=0.23163561522960663
[10/24] Train loss=0.3147774934768677
[15/24] Train loss=0.27932125329971313
[20/24] Train loss=0.2520792484283447
Test set avg_accuracy=79.38% avg_sensitivity=50.09%, avg_specificity=90.47% avg_auc=81.39%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.270839 Test loss=0.473388 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.27435103058815
[5/24] Train loss=0.24728341400623322
[10/24] Train loss=0.290094256401062
[15/24] Train loss=0.2754252851009369
[20/24] Train loss=0.24529699981212616
Test set avg_accuracy=78.31% avg_sensitivity=35.97%, avg_specificity=94.34% avg_auc=81.21%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.263499 Test loss=0.509809 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2495713084936142
[5/24] Train loss=0.22916018962860107
[10/24] Train loss=0.29112011194229126
[15/24] Train loss=0.2821817398071289
[20/24] Train loss=0.2414924055337906
Test set avg_accuracy=76.84% avg_sensitivity=21.18%, avg_specificity=97.92% avg_auc=74.91%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.261191 Test loss=0.698093 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.24964654445648193
[5/24] Train loss=0.23313172161579132
[10/24] Train loss=0.28533193469047546
[15/24] Train loss=0.2725234627723694
[20/24] Train loss=0.22758443653583527
Test set avg_accuracy=79.51% avg_sensitivity=43.79%, avg_specificity=93.03% avg_auc=81.07%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.258964 Test loss=0.495210 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2432740032672882
[5/24] Train loss=0.23987087607383728
[10/24] Train loss=0.3017553985118866
[15/24] Train loss=0.2710725665092468
[20/24] Train loss=0.2410927563905716
Test set avg_accuracy=80.30% avg_sensitivity=58.20%, avg_specificity=88.67% avg_auc=83.92%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.259547 Test loss=0.450217 Current lr=[0.000276307469034998]

[0/24] Train loss=0.23888224363327026
[5/24] Train loss=0.22584162652492523
[10/24] Train loss=0.29848921298980713
[15/24] Train loss=0.2856971323490143
[20/24] Train loss=0.23870840668678284
Test set avg_accuracy=80.73% avg_sensitivity=50.47%, avg_specificity=92.19% avg_auc=83.15%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.255307 Test loss=0.456531 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.24026185274124146
[5/24] Train loss=0.23137082159519196
[10/24] Train loss=0.28609564900398254
[15/24] Train loss=0.28141462802886963
[20/24] Train loss=0.2365334928035736
Test set avg_accuracy=78.83% avg_sensitivity=36.68%, avg_specificity=94.79% avg_auc=80.37%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.256142 Test loss=0.533651 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.25085464119911194
[5/24] Train loss=0.23130467534065247
[10/24] Train loss=0.28587841987609863
[15/24] Train loss=0.25849926471710205
[20/24] Train loss=0.2409224510192871
Test set avg_accuracy=78.67% avg_sensitivity=37.16%, avg_specificity=94.40% avg_auc=77.81%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.251869 Test loss=0.572713 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.23944105207920074
[5/24] Train loss=0.23764081299304962
[10/24] Train loss=0.27824917435646057
[15/24] Train loss=0.266083300113678
[20/24] Train loss=0.23522540926933289
Test set avg_accuracy=78.98% avg_sensitivity=51.66%, avg_specificity=89.34% avg_auc=81.82%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.253987 Test loss=0.478499 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2483033686876297
[5/24] Train loss=0.21217133104801178
[10/24] Train loss=0.28636661171913147
[15/24] Train loss=0.2764195501804352
[20/24] Train loss=0.23484914004802704
Test set avg_accuracy=79.75% avg_sensitivity=52.51%, avg_specificity=90.07% avg_auc=83.12%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.249570 Test loss=0.444241 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.22971272468566895
[5/24] Train loss=0.21457800269126892
[10/24] Train loss=0.27408525347709656
[15/24] Train loss=0.2686289846897125
[20/24] Train loss=0.2427208125591278
Test set avg_accuracy=79.06% avg_sensitivity=61.09%, avg_specificity=85.87% avg_auc=83.59%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.250707 Test loss=0.471829 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.25195467472076416
[5/24] Train loss=0.23845940828323364
[10/24] Train loss=0.27927693724632263
[15/24] Train loss=0.26889267563819885
[20/24] Train loss=0.22964917123317719
Test set avg_accuracy=79.69% avg_sensitivity=39.53%, avg_specificity=94.90% avg_auc=78.93%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.250397 Test loss=0.552903 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.23088088631629944
[5/24] Train loss=0.2106790691614151
[10/24] Train loss=0.2691594064235687
[15/24] Train loss=0.263763964176178
[20/24] Train loss=0.23124542832374573
Test set avg_accuracy=77.98% avg_sensitivity=62.09%, avg_specificity=84.00% avg_auc=81.79%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.244922 Test loss=0.502222 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.24898195266723633
[5/24] Train loss=0.21842074394226074
[10/24] Train loss=0.2686055600643158
[15/24] Train loss=0.2671041488647461
[20/24] Train loss=0.2215055674314499
Test set avg_accuracy=78.15% avg_sensitivity=59.15%, avg_specificity=85.35% avg_auc=81.27%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.241346 Test loss=0.488254 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.22879619896411896
[5/24] Train loss=0.23225194215774536
[10/24] Train loss=0.2716695964336395
[15/24] Train loss=0.2630106210708618
[20/24] Train loss=0.22439038753509521
Test set avg_accuracy=80.85% avg_sensitivity=58.82%, avg_specificity=89.19% avg_auc=83.60%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.243054 Test loss=0.452020 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.2352164089679718
[5/24] Train loss=0.21624544262886047
[10/24] Train loss=0.2740049362182617
[15/24] Train loss=0.26958486437797546
[20/24] Train loss=0.22822998464107513
Test set avg_accuracy=79.47% avg_sensitivity=37.63%, avg_specificity=95.31% avg_auc=78.21%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.245139 Test loss=0.567446 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2294929474592209
[5/24] Train loss=0.21686097979545593
[10/24] Train loss=0.254659503698349
[15/24] Train loss=0.25336188077926636
[20/24] Train loss=0.22732926905155182
Test set avg_accuracy=78.75% avg_sensitivity=37.20%, avg_specificity=94.49% avg_auc=78.68%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.233821 Test loss=0.541204 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2307419627904892
[5/24] Train loss=0.21537081897258759
[10/24] Train loss=0.267372727394104
[15/24] Train loss=0.2433176189661026
[20/24] Train loss=0.22014164924621582
Test set avg_accuracy=79.13% avg_sensitivity=51.85%, avg_specificity=89.46% avg_auc=79.28%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.235278 Test loss=0.504395 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.22644788026809692
[5/24] Train loss=0.20351041853427887
[10/24] Train loss=0.2523699700832367
[15/24] Train loss=0.2307884395122528
[20/24] Train loss=0.2294771373271942
Test set avg_accuracy=77.19% avg_sensitivity=54.93%, avg_specificity=85.62% avg_auc=79.19%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.233383 Test loss=0.524104 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.22738416492938995
[5/24] Train loss=0.2076309770345688
[10/24] Train loss=0.25428128242492676
[15/24] Train loss=0.24220706522464752
[20/24] Train loss=0.23662380874156952
Test set avg_accuracy=80.26% avg_sensitivity=57.20%, avg_specificity=88.99% avg_auc=83.86%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.234193 Test loss=0.454067 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.20712852478027344
[5/24] Train loss=0.20570197701454163
[10/24] Train loss=0.2591164708137512
[15/24] Train loss=0.24232855439186096
[20/24] Train loss=0.23264004290103912
Test set avg_accuracy=81.13% avg_sensitivity=56.11%, avg_specificity=90.61% avg_auc=84.11%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.231647 Test loss=0.461121 Current lr=[0.000224838296036774]

[0/24] Train loss=0.24280816316604614
[5/24] Train loss=0.21525819599628448
[10/24] Train loss=0.26244229078292847
[15/24] Train loss=0.24633300304412842
[20/24] Train loss=0.2395430952310562
Test set avg_accuracy=81.13% avg_sensitivity=57.16%, avg_specificity=90.22% avg_auc=83.84%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.236426 Test loss=0.447748 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.22599348425865173
[5/24] Train loss=0.21011219918727875
[10/24] Train loss=0.28802648186683655
[15/24] Train loss=0.24310532212257385
[20/24] Train loss=0.22360840439796448
Test set avg_accuracy=79.28% avg_sensitivity=61.66%, avg_specificity=85.96% avg_auc=82.51%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.231669 Test loss=0.481593 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.21764831244945526
[5/24] Train loss=0.2067873626947403
[10/24] Train loss=0.2589905261993408
[15/24] Train loss=0.254869282245636
[20/24] Train loss=0.20910650491714478
Test set avg_accuracy=81.02% avg_sensitivity=53.98%, avg_specificity=91.26% avg_auc=82.01%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.225011 Test loss=0.470383 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.20812836289405823
[5/24] Train loss=0.20070281624794006
[10/24] Train loss=0.2501394748687744
[15/24] Train loss=0.23798343539237976
[20/24] Train loss=0.21272212266921997
Test set avg_accuracy=80.40% avg_sensitivity=57.25%, avg_specificity=89.17% avg_auc=82.74%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.219973 Test loss=0.470017 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.22807355225086212
[5/24] Train loss=0.2038821130990982
[10/24] Train loss=0.23155081272125244
[15/24] Train loss=0.2310522496700287
[20/24] Train loss=0.2156667858362198
Test set avg_accuracy=80.33% avg_sensitivity=46.73%, avg_specificity=93.05% avg_auc=79.70%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.219484 Test loss=0.511762 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2116958498954773
[5/24] Train loss=0.18466530740261078
[10/24] Train loss=0.24719776213169098
[15/24] Train loss=0.23313316702842712
[20/24] Train loss=0.21880391240119934
Test set avg_accuracy=79.10% avg_sensitivity=58.96%, avg_specificity=86.73% avg_auc=81.43%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.214964 Test loss=0.495225 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.19836346805095673
[5/24] Train loss=0.20538777112960815
[10/24] Train loss=0.2348020225763321
[15/24] Train loss=0.23569659888744354
[20/24] Train loss=0.21932396292686462
Test set avg_accuracy=80.68% avg_sensitivity=61.37%, avg_specificity=87.99% avg_auc=82.25%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.214677 Test loss=0.483987 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.20403017103672028
[5/24] Train loss=0.189354807138443
[10/24] Train loss=0.24368013441562653
[15/24] Train loss=0.2283143699169159
[20/24] Train loss=0.2081649899482727
Test set avg_accuracy=80.05% avg_sensitivity=54.22%, avg_specificity=89.84% avg_auc=79.23%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.214864 Test loss=0.500177 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.19649678468704224
[5/24] Train loss=0.18573157489299774
[10/24] Train loss=0.22896495461463928
[15/24] Train loss=0.2441718578338623
[20/24] Train loss=0.221537247300148
Test set avg_accuracy=80.61% avg_sensitivity=63.22%, avg_specificity=87.20% avg_auc=83.68%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.212739 Test loss=0.481317 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.22668345272541046
[5/24] Train loss=0.2094065397977829
[10/24] Train loss=0.24353156983852386
[15/24] Train loss=0.22783805429935455
[20/24] Train loss=0.20853962004184723
Test set avg_accuracy=80.61% avg_sensitivity=51.37%, avg_specificity=91.69% avg_auc=81.74%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.214430 Test loss=0.486659 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2144862860441208
[5/24] Train loss=0.20181383192539215
[10/24] Train loss=0.23578496277332306
[15/24] Train loss=0.23286931216716766
[20/24] Train loss=0.21154646575450897
Test set avg_accuracy=80.08% avg_sensitivity=52.04%, avg_specificity=90.70% avg_auc=79.82%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.218394 Test loss=0.523845 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.21111156046390533
[5/24] Train loss=0.19066943228244781
[10/24] Train loss=0.24129381775856018
[15/24] Train loss=0.2218243032693863
[20/24] Train loss=0.22494293749332428
Test set avg_accuracy=80.96% avg_sensitivity=53.51%, avg_specificity=91.36% avg_auc=81.65%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.212419 Test loss=0.478657 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.21217244863510132
[5/24] Train loss=0.19638708233833313
[10/24] Train loss=0.2508595585823059
[15/24] Train loss=0.22802671790122986
[20/24] Train loss=0.19497136771678925
Test set avg_accuracy=80.61% avg_sensitivity=56.40%, avg_specificity=89.78% avg_auc=82.29%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.211881 Test loss=0.470861 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.21820935606956482
[5/24] Train loss=0.18803821504116058
[10/24] Train loss=0.23399411141872406
[15/24] Train loss=0.22035515308380127
[20/24] Train loss=0.20676706731319427
Test set avg_accuracy=79.86% avg_sensitivity=67.01%, avg_specificity=84.72% avg_auc=83.74%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.210949 Test loss=0.474172 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.20151425898075104
[5/24] Train loss=0.2057504951953888
[10/24] Train loss=0.23046621680259705
[15/24] Train loss=0.22378380596637726
[20/24] Train loss=0.21485841274261475
Test set avg_accuracy=80.51% avg_sensitivity=62.23%, avg_specificity=87.43% avg_auc=82.55%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.212091 Test loss=0.465873 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2018221914768219
[5/24] Train loss=0.1938333660364151
[10/24] Train loss=0.2271149456501007
[15/24] Train loss=0.22451354563236237
[20/24] Train loss=0.1929253339767456
Test set avg_accuracy=80.40% avg_sensitivity=49.53%, avg_specificity=92.10% avg_auc=81.06%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.209729 Test loss=0.497694 Current lr=[0.000156543481933168]

[0/24] Train loss=0.21296574175357819
[5/24] Train loss=0.18936456739902496
[10/24] Train loss=0.21849468350410461
[15/24] Train loss=0.21204069256782532
[20/24] Train loss=0.1868213713169098
Test set avg_accuracy=80.49% avg_sensitivity=58.20%, avg_specificity=88.94% avg_auc=82.64%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.202913 Test loss=0.460807 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1933864951133728
[5/24] Train loss=0.17896725237369537
[10/24] Train loss=0.21482624113559723
[15/24] Train loss=0.20530661940574646
[20/24] Train loss=0.18600954115390778
Test set avg_accuracy=80.04% avg_sensitivity=64.69%, avg_specificity=85.85% avg_auc=83.76%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.197765 Test loss=0.463719 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.18840676546096802
[5/24] Train loss=0.18461209535598755
[10/24] Train loss=0.2145407348871231
[15/24] Train loss=0.2194860577583313
[20/24] Train loss=0.190037801861763
Test set avg_accuracy=80.98% avg_sensitivity=57.01%, avg_specificity=90.05% avg_auc=80.65%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.197186 Test loss=0.486384 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.21506020426750183
[5/24] Train loss=0.1805979609489441
[10/24] Train loss=0.2177087664604187
[15/24] Train loss=0.19845159351825714
[20/24] Train loss=0.18372298777103424
Test set avg_accuracy=81.52% avg_sensitivity=64.79%, avg_specificity=87.86% avg_auc=84.59%
Best model saved!! Metric=-7.233112058824787!!
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.197142 Test loss=0.447913 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1787049025297165
[5/24] Train loss=0.17619280517101288
[10/24] Train loss=0.22122721374034882
[15/24] Train loss=0.19781802594661713
[20/24] Train loss=0.189834862947464
Test set avg_accuracy=80.34% avg_sensitivity=60.90%, avg_specificity=87.70% avg_auc=81.08%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.191950 Test loss=0.485156 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1794961541891098
[5/24] Train loss=0.17052508890628815
[10/24] Train loss=0.20472297072410583
[15/24] Train loss=0.19597865641117096
[20/24] Train loss=0.18704845011234283
Test set avg_accuracy=81.17% avg_sensitivity=62.23%, avg_specificity=88.35% avg_auc=82.45%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.189600 Test loss=0.472428 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.17817291617393494
[5/24] Train loss=0.17476892471313477
[10/24] Train loss=0.19976074993610382
[15/24] Train loss=0.20511965453624725
[20/24] Train loss=0.19067858159542084
Test set avg_accuracy=80.81% avg_sensitivity=65.26%, avg_specificity=86.70% avg_auc=84.95%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.192288 Test loss=0.460940 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.18289728462696075
[5/24] Train loss=0.18029086291790009
[10/24] Train loss=0.2177942991256714
[15/24] Train loss=0.21656844019889832
[20/24] Train loss=0.19328349828720093
Test set avg_accuracy=81.11% avg_sensitivity=59.62%, avg_specificity=89.25% avg_auc=82.76%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.191974 Test loss=0.464610 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.17461377382278442
[5/24] Train loss=0.17673739790916443
[10/24] Train loss=0.20559179782867432
[15/24] Train loss=0.21077188849449158
[20/24] Train loss=0.1849343627691269
Test set avg_accuracy=80.53% avg_sensitivity=49.10%, avg_specificity=92.44% avg_auc=80.37%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.190234 Test loss=0.510237 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1889468878507614
[5/24] Train loss=0.1726107895374298
[10/24] Train loss=0.20301136374473572
[15/24] Train loss=0.20293568074703217
[20/24] Train loss=0.17444385588169098
Test set avg_accuracy=79.34% avg_sensitivity=56.82%, avg_specificity=87.86% avg_auc=80.39%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.189965 Test loss=0.515484 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.17461253702640533
[5/24] Train loss=0.1863851100206375
[10/24] Train loss=0.20548513531684875
[15/24] Train loss=0.19578221440315247
[20/24] Train loss=0.18236468732357025
Test set avg_accuracy=80.64% avg_sensitivity=51.80%, avg_specificity=91.56% avg_auc=80.58%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.190370 Test loss=0.507200 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1791801154613495
[5/24] Train loss=0.173508882522583
[10/24] Train loss=0.20063625276088715
[15/24] Train loss=0.19646801054477692
[20/24] Train loss=0.18480753898620605
Test set avg_accuracy=81.13% avg_sensitivity=59.00%, avg_specificity=89.52% avg_auc=83.27%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.184582 Test loss=0.463796 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.17491289973258972
[5/24] Train loss=0.16332650184631348
[10/24] Train loss=0.2158743292093277
[15/24] Train loss=0.1881909817457199
[20/24] Train loss=0.18081796169281006
Test set avg_accuracy=81.88% avg_sensitivity=59.00%, avg_specificity=90.54% avg_auc=83.85%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.182189 Test loss=0.449959 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.17314839363098145
[5/24] Train loss=0.16682124137878418
[10/24] Train loss=0.1890440732240677
[15/24] Train loss=0.18707333505153656
[20/24] Train loss=0.18046632409095764
Test set avg_accuracy=81.30% avg_sensitivity=56.07%, avg_specificity=90.86% avg_auc=83.10%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.178289 Test loss=0.456649 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.1671321988105774
[5/24] Train loss=0.16910973191261292
[10/24] Train loss=0.2141820341348648
[15/24] Train loss=0.17985904216766357
[20/24] Train loss=0.17443367838859558
Test set avg_accuracy=80.74% avg_sensitivity=59.67%, avg_specificity=88.73% avg_auc=83.37%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.178541 Test loss=0.449402 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.17830802500247955
[5/24] Train loss=0.1592824012041092
[10/24] Train loss=0.1892092227935791
[15/24] Train loss=0.18909551203250885
[20/24] Train loss=0.16975092887878418
Test set avg_accuracy=81.29% avg_sensitivity=60.71%, avg_specificity=89.08% avg_auc=83.50%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.175882 Test loss=0.455549 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.16848543286323547
[5/24] Train loss=0.1543474793434143
[10/24] Train loss=0.18830332159996033
[15/24] Train loss=0.17929460108280182
[20/24] Train loss=0.1741667240858078
Test set avg_accuracy=80.69% avg_sensitivity=53.13%, avg_specificity=91.13% avg_auc=80.97%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.170400 Test loss=0.482266 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.17633503675460815
[5/24] Train loss=0.1580430120229721
[10/24] Train loss=0.18428145349025726
[15/24] Train loss=0.17259196937084198
[20/24] Train loss=0.1776888072490692
Test set avg_accuracy=80.38% avg_sensitivity=63.22%, avg_specificity=86.88% avg_auc=83.48%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.170257 Test loss=0.463955 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1744033694267273
[5/24] Train loss=0.1581757813692093
[10/24] Train loss=0.184928297996521
[15/24] Train loss=0.18057556450366974
[20/24] Train loss=0.1655852496623993
Test set avg_accuracy=80.95% avg_sensitivity=63.41%, avg_specificity=87.59% avg_auc=84.59%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.170355 Test loss=0.452147 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1615000218153
[5/24] Train loss=0.15538083016872406
[10/24] Train loss=0.1822642683982849
[15/24] Train loss=0.17212235927581787
[20/24] Train loss=0.16535843908786774
Test set avg_accuracy=80.52% avg_sensitivity=66.92%, avg_specificity=85.67% avg_auc=84.29%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.167721 Test loss=0.462102 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1631893813610077
[5/24] Train loss=0.1530340313911438
[10/24] Train loss=0.17894630134105682
[15/24] Train loss=0.16962486505508423
[20/24] Train loss=0.16778084635734558
Test set avg_accuracy=81.08% avg_sensitivity=69.00%, avg_specificity=85.66% avg_auc=85.18%
Best model saved!! Metric=-5.083977666656736!!
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.164614 Test loss=0.448801 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.15734848380088806
[5/24] Train loss=0.1510661393404007
[10/24] Train loss=0.17839181423187256
[15/24] Train loss=0.17748786509037018
[20/24] Train loss=0.16237828135490417
Test set avg_accuracy=79.88% avg_sensitivity=72.09%, avg_specificity=82.84% avg_auc=84.49%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.163051 Test loss=0.476346 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1584169715642929
[5/24] Train loss=0.14773230254650116
[10/24] Train loss=0.17186109721660614
[15/24] Train loss=0.17774170637130737
[20/24] Train loss=0.15984952449798584
Test set avg_accuracy=80.05% avg_sensitivity=72.70%, avg_specificity=82.84% avg_auc=85.06%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.162754 Test loss=0.471721 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.15529052913188934
[5/24] Train loss=0.15397308766841888
[10/24] Train loss=0.17542198300361633
[15/24] Train loss=0.166015163064003
[20/24] Train loss=0.16185490787029266
Test set avg_accuracy=80.66% avg_sensitivity=61.14%, avg_specificity=88.06% avg_auc=82.93%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.161902 Test loss=0.475620 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.15213699638843536
[5/24] Train loss=0.15371397137641907
[10/24] Train loss=0.16993780434131622
[15/24] Train loss=0.16862913966178894
[20/24] Train loss=0.16389240324497223
Test set avg_accuracy=81.68% avg_sensitivity=66.87%, avg_specificity=87.29% avg_auc=85.29%
Best model saved!! Metric=-4.868254674989586!!
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.160427 Test loss=0.443860 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.15545111894607544
[5/24] Train loss=0.14960114657878876
[10/24] Train loss=0.17137792706489563
[15/24] Train loss=0.1622585654258728
[20/24] Train loss=0.1591694951057434
Test set avg_accuracy=81.52% avg_sensitivity=67.73%, avg_specificity=86.75% avg_auc=84.90%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.157952 Test loss=0.448793 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.15103228390216827
[5/24] Train loss=0.1445230096578598
[10/24] Train loss=0.16394267976284027
[15/24] Train loss=0.1617434322834015
[20/24] Train loss=0.15238243341445923
Test set avg_accuracy=81.65% avg_sensitivity=67.25%, avg_specificity=87.11% avg_auc=84.85%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.155310 Test loss=0.447758 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1432742029428482
[5/24] Train loss=0.14052027463912964
[10/24] Train loss=0.16974151134490967
[15/24] Train loss=0.15845689177513123
[20/24] Train loss=0.1532205194234848
Test set avg_accuracy=81.94% avg_sensitivity=63.46%, avg_specificity=88.94% avg_auc=84.47%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.152261 Test loss=0.447132 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.14629216492176056
[5/24] Train loss=0.14208641648292542
[10/24] Train loss=0.17161528766155243
[15/24] Train loss=0.16044621169567108
[20/24] Train loss=0.15815779566764832
Test set avg_accuracy=81.74% avg_sensitivity=59.67%, avg_specificity=90.11% avg_auc=83.37%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.150878 Test loss=0.456926 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.14688381552696228
[5/24] Train loss=0.1459200233221054
[10/24] Train loss=0.15970490872859955
[15/24] Train loss=0.15515615046024323
[20/24] Train loss=0.15575836598873138
Test set avg_accuracy=81.88% avg_sensitivity=62.94%, avg_specificity=89.05% avg_auc=84.74%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.150600 Test loss=0.442923 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.152051642537117
[5/24] Train loss=0.1386665254831314
[10/24] Train loss=0.16232521831989288
[15/24] Train loss=0.16272838413715363
[20/24] Train loss=0.15484774112701416
Test set avg_accuracy=81.93% avg_sensitivity=62.61%, avg_specificity=89.25% avg_auc=84.15%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.149808 Test loss=0.446083 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.144464910030365
[5/24] Train loss=0.13586200773715973
[10/24] Train loss=0.16190938651561737
[15/24] Train loss=0.15492020547389984
[20/24] Train loss=0.148768812417984
Test set avg_accuracy=81.94% avg_sensitivity=60.81%, avg_specificity=89.95% avg_auc=84.04%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.148158 Test loss=0.444250 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.14476780593395233
[5/24] Train loss=0.13562679290771484
[10/24] Train loss=0.1585831344127655
[15/24] Train loss=0.15737970173358917
[20/24] Train loss=0.14695623517036438
Test set avg_accuracy=82.32% avg_sensitivity=62.23%, avg_specificity=89.93% avg_auc=83.92%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.148637 Test loss=0.447925 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.14012090861797333
[5/24] Train loss=0.13765905797481537
[10/24] Train loss=0.15579818189144135
[15/24] Train loss=0.15606261789798737
[20/24] Train loss=0.15010057389736176
Test set avg_accuracy=82.27% avg_sensitivity=59.00%, avg_specificity=91.08% avg_auc=83.22%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.146890 Test loss=0.453528 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13860706984996796
[5/24] Train loss=0.1347501575946808
[10/24] Train loss=0.1585163027048111
[15/24] Train loss=0.1579696387052536
[20/24] Train loss=0.15607145428657532
Test set avg_accuracy=81.86% avg_sensitivity=65.12%, avg_specificity=88.20% avg_auc=84.63%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.146837 Test loss=0.446249 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.14726988971233368
[5/24] Train loss=0.135758638381958
[10/24] Train loss=0.16118590533733368
[15/24] Train loss=0.15168212354183197
[20/24] Train loss=0.15238241851329803
Test set avg_accuracy=81.93% avg_sensitivity=61.61%, avg_specificity=89.62% avg_auc=84.01%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.146951 Test loss=0.446666 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13982439041137695
[5/24] Train loss=0.13603660464286804
[10/24] Train loss=0.1574164777994156
[15/24] Train loss=0.16319428384304047
[20/24] Train loss=0.1485583335161209
Test set avg_accuracy=81.98% avg_sensitivity=63.41%, avg_specificity=89.01% avg_auc=84.07%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.145908 Test loss=0.446444 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13598769903182983
[5/24] Train loss=0.13190177083015442
[10/24] Train loss=0.15580445528030396
[15/24] Train loss=0.1496211141347885
[20/24] Train loss=0.14629969000816345
Test set avg_accuracy=81.97% avg_sensitivity=62.65%, avg_specificity=89.28% avg_auc=83.48%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.143425 Test loss=0.453723 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.14157003164291382
[5/24] Train loss=0.13169245421886444
[10/24] Train loss=0.1529959887266159
[15/24] Train loss=0.14778897166252136
[20/24] Train loss=0.15017451345920563
Test set avg_accuracy=82.17% avg_sensitivity=63.70%, avg_specificity=89.17% avg_auc=83.76%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.143278 Test loss=0.450078 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13629236817359924
[5/24] Train loss=0.13376803696155548
[10/24] Train loss=0.15314973890781403
[15/24] Train loss=0.15637251734733582
[20/24] Train loss=0.1460016667842865
Test set avg_accuracy=82.10% avg_sensitivity=63.41%, avg_specificity=89.17% avg_auc=83.40%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.142269 Test loss=0.457899 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1371932476758957
[5/24] Train loss=0.13299305737018585
[10/24] Train loss=0.14860741794109344
[15/24] Train loss=0.15182964503765106
[20/24] Train loss=0.14798091351985931
Test set avg_accuracy=82.04% avg_sensitivity=62.84%, avg_specificity=89.32% avg_auc=83.50%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.142647 Test loss=0.453599 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13672134280204773
[5/24] Train loss=0.1312803477048874
[10/24] Train loss=0.15180827677249908
[15/24] Train loss=0.1493430733680725
[20/24] Train loss=0.14566726982593536
Test set avg_accuracy=82.06% avg_sensitivity=62.75%, avg_specificity=89.37% avg_auc=83.68%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.141373 Test loss=0.452954 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1372523307800293
[5/24] Train loss=0.1291271299123764
[10/24] Train loss=0.15025269985198975
[15/24] Train loss=0.15469354391098022
[20/24] Train loss=0.1468796581029892
Test set avg_accuracy=82.15% avg_sensitivity=62.51%, avg_specificity=89.59% avg_auc=83.71%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.142120 Test loss=0.451369 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13206417858600616
[5/24] Train loss=0.13147714734077454
[10/24] Train loss=0.1505228877067566
[15/24] Train loss=0.1498827040195465
[20/24] Train loss=0.14172999560832977
Test set avg_accuracy=82.03% avg_sensitivity=63.13%, avg_specificity=89.19% avg_auc=83.66%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.140396 Test loss=0.453668 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13586001098155975
[5/24] Train loss=0.12809467315673828
[10/24] Train loss=0.15451034903526306
[15/24] Train loss=0.14566455781459808
[20/24] Train loss=0.1432417631149292
Test set avg_accuracy=81.97% avg_sensitivity=63.74%, avg_specificity=88.87% avg_auc=83.74%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.140133 Test loss=0.454259 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.13424165546894073
[5/24] Train loss=0.1300298422574997
[10/24] Train loss=0.1497313380241394
[15/24] Train loss=0.15048149228096008
[20/24] Train loss=0.14626769721508026
Test set avg_accuracy=81.98% avg_sensitivity=62.51%, avg_specificity=89.35% avg_auc=83.64%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.140850 Test loss=0.452520 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13274379074573517
[5/24] Train loss=0.12997668981552124
[10/24] Train loss=0.15120021998882294
[15/24] Train loss=0.15270432829856873
[20/24] Train loss=0.14054617285728455
Test set avg_accuracy=81.89% avg_sensitivity=62.99%, avg_specificity=89.05% avg_auc=83.69%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.139620 Test loss=0.453354 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13639244437217712
[5/24] Train loss=0.12832674384117126
[10/24] Train loss=0.1500515341758728
[15/24] Train loss=0.1495237946510315
[20/24] Train loss=0.14175038039684296
Test set avg_accuracy=81.86% avg_sensitivity=62.61%, avg_specificity=89.16% avg_auc=83.67%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.140192 Test loss=0.453147 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13590040802955627
[5/24] Train loss=0.12750951945781708
[10/24] Train loss=0.15102797746658325
[15/24] Train loss=0.14431194961071014
[20/24] Train loss=0.14907719194889069
Test set avg_accuracy=81.85% avg_sensitivity=62.75%, avg_specificity=89.08% avg_auc=83.57%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.139403 Test loss=0.454476 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13512949645519257
[5/24] Train loss=0.12896600365638733
[10/24] Train loss=0.15897957980632782
[15/24] Train loss=0.14787623286247253
[20/24] Train loss=0.1451375037431717
Test set avg_accuracy=81.86% avg_sensitivity=62.94%, avg_specificity=89.03% avg_auc=83.53%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.140276 Test loss=0.455058 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1375463604927063
[5/24] Train loss=0.1271357536315918
[10/24] Train loss=0.15215785801410675
[15/24] Train loss=0.14689885079860687
[20/24] Train loss=0.14338575303554535
Test set avg_accuracy=81.93% avg_sensitivity=62.89%, avg_specificity=89.14% avg_auc=83.54%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.139835 Test loss=0.454682 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.13118430972099304
[5/24] Train loss=0.12801630795001984
[10/24] Train loss=0.1495436728000641
[15/24] Train loss=0.14855659008026123
[20/24] Train loss=0.14227628707885742
Test set avg_accuracy=82.02% avg_sensitivity=62.80%, avg_specificity=89.30% avg_auc=83.53%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.139030 Test loss=0.454599 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13643768429756165
[5/24] Train loss=0.13009420037269592
[10/24] Train loss=0.14938631653785706
[15/24] Train loss=0.1463545858860016
[20/24] Train loss=0.1417192667722702
Test set avg_accuracy=81.93% avg_sensitivity=62.99%, avg_specificity=89.10% avg_auc=83.56%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.139150 Test loss=0.454594 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1333678662776947
[5/24] Train loss=0.1299816370010376
[10/24] Train loss=0.15060104429721832
[15/24] Train loss=0.14674749970436096
[20/24] Train loss=0.1421293169260025
Test set avg_accuracy=81.90% avg_sensitivity=62.99%, avg_specificity=89.07% avg_auc=83.56%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.139438 Test loss=0.454488 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=81.68% sen=66.87%, spe=87.29%, auc=85.29%!
Fold[3] Avg_overlap=0.61%(±0.2944079903742647)
[0/24] Train loss=0.7464948892593384
[5/24] Train loss=0.73728346824646
[10/24] Train loss=0.7369366884231567
[15/24] Train loss=0.7262487411499023
[20/24] Train loss=0.7117470502853394
Test set avg_accuracy=58.53% avg_sensitivity=52.37%, avg_specificity=60.70% avg_auc=59.04%
Best model saved!! Metric=-95.3598795289195!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.732465 Test loss=0.684124 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7135547995567322
[5/24] Train loss=0.7122516632080078
[10/24] Train loss=0.7076430320739746
[15/24] Train loss=0.7034875750541687
[20/24] Train loss=0.6930420398712158
Test set avg_accuracy=63.59% avg_sensitivity=65.02%, avg_specificity=63.09% avg_auc=67.84%
Best model saved!! Metric=-66.46113838605876!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.708407 Test loss=0.650599 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.684788167476654
[5/24] Train loss=0.6917182803153992
[10/24] Train loss=0.6957389712333679
[15/24] Train loss=0.6725095510482788
[20/24] Train loss=0.6700059175491333
Test set avg_accuracy=64.90% avg_sensitivity=70.96%, avg_specificity=62.76% avg_auc=72.02%
Best model saved!! Metric=-55.36641219472145!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.687150 Test loss=0.632497 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6563646197319031
[5/24] Train loss=0.6677839159965515
[10/24] Train loss=0.6671667695045471
[15/24] Train loss=0.6527036428451538
[20/24] Train loss=0.6432946920394897
Test set avg_accuracy=66.35% avg_sensitivity=73.96%, avg_specificity=63.67% avg_auc=74.82%
Best model saved!! Metric=-47.18798847516724!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.665366 Test loss=0.612376 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6311602592468262
[5/24] Train loss=0.6431321501731873
[10/24] Train loss=0.6469017267227173
[15/24] Train loss=0.633206307888031
[20/24] Train loss=0.6267786622047424
Test set avg_accuracy=68.49% avg_sensitivity=76.16%, avg_specificity=65.79% avg_auc=77.15%
Best model saved!! Metric=-38.41309791980659!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.644939 Test loss=0.590794 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6090990900993347
[5/24] Train loss=0.6196288466453552
[10/24] Train loss=0.6285675168037415
[15/24] Train loss=0.6139922142028809
[20/24] Train loss=0.6051778197288513
Test set avg_accuracy=71.07% avg_sensitivity=75.91%, avg_specificity=69.36% avg_auc=78.96%
Best model saved!! Metric=-30.698784190786725!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.625926 Test loss=0.567791 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.583358645439148
[5/24] Train loss=0.5949380397796631
[10/24] Train loss=0.6028326749801636
[15/24] Train loss=0.5927428603172302
[20/24] Train loss=0.5888778567314148
Test set avg_accuracy=73.83% avg_sensitivity=74.66%, avg_specificity=73.53% avg_auc=80.32%
Best model saved!! Metric=-23.655515993378998!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.603033 Test loss=0.545876 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5701936483383179
[5/24] Train loss=0.5734772682189941
[10/24] Train loss=0.5856602787971497
[15/24] Train loss=0.5728893876075745
[20/24] Train loss=0.5620768666267395
Test set avg_accuracy=76.11% avg_sensitivity=73.21%, avg_specificity=77.13% avg_auc=81.26%
Best model saved!! Metric=-18.295055723013405!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.581388 Test loss=0.520161 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5492808818817139
[5/24] Train loss=0.5541901588439941
[10/24] Train loss=0.566867470741272
[15/24] Train loss=0.5479848384857178
[20/24] Train loss=0.5357396602630615
Test set avg_accuracy=76.98% avg_sensitivity=69.82%, avg_specificity=79.50% avg_auc=81.89%
Best model saved!! Metric=-17.812172828227546!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.558986 Test loss=0.499335 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5211711525917053
[5/24] Train loss=0.5256978273391724
[10/24] Train loss=0.541745662689209
[15/24] Train loss=0.5237511396408081
[20/24] Train loss=0.518154501914978
Test set avg_accuracy=78.45% avg_sensitivity=69.02%, avg_specificity=81.77% avg_auc=82.77%
Best model saved!! Metric=-13.992776271415948!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.536818 Test loss=0.480374 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.500632643699646
[5/24] Train loss=0.4987426996231079
[10/24] Train loss=0.5189924836158752
[15/24] Train loss=0.5122144818305969
[20/24] Train loss=0.4856833815574646
Test set avg_accuracy=79.22% avg_sensitivity=67.52%, avg_specificity=83.34% avg_auc=83.34%
Best model saved!! Metric=-12.586285499506815!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.512796 Test loss=0.462711 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4819380044937134
[5/24] Train loss=0.4801451563835144
[10/24] Train loss=0.5022774934768677
[15/24] Train loss=0.49515974521636963
[20/24] Train loss=0.4599955379962921
Test set avg_accuracy=80.13% avg_sensitivity=66.97%, avg_specificity=84.77% avg_auc=84.00%
Best model saved!! Metric=-10.133574548953291!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.492155 Test loss=0.448311 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.46535012125968933
[5/24] Train loss=0.4662606120109558
[10/24] Train loss=0.4841611087322235
[15/24] Train loss=0.4700288474559784
[20/24] Train loss=0.44138750433921814
Test set avg_accuracy=80.96% avg_sensitivity=61.07%, avg_specificity=87.97% avg_auc=84.36%
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.472004 Test loss=0.430380 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4480147957801819
[5/24] Train loss=0.44331812858581543
[10/24] Train loss=0.4735557734966278
[15/24] Train loss=0.45661231875419617
[20/24] Train loss=0.42470839619636536
Test set avg_accuracy=81.93% avg_sensitivity=63.17%, avg_specificity=88.54% avg_auc=85.04%
Best model saved!! Metric=-7.329367328463796!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.454486 Test loss=0.421023 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4330347776412964
[5/24] Train loss=0.4267662465572357
[10/24] Train loss=0.45630016922950745
[15/24] Train loss=0.44355127215385437
[20/24] Train loss=0.40732595324516296
Test set avg_accuracy=82.02% avg_sensitivity=61.57%, avg_specificity=89.22% avg_auc=85.29%
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.439069 Test loss=0.413629 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.41739416122436523
[5/24] Train loss=0.4148511588573456
[10/24] Train loss=0.45382335782051086
[15/24] Train loss=0.4287395179271698
[20/24] Train loss=0.39127516746520996
Test set avg_accuracy=82.49% avg_sensitivity=53.92%, avg_specificity=92.55% avg_auc=85.21%
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.425324 Test loss=0.402798 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.41387617588043213
[5/24] Train loss=0.4019635021686554
[10/24] Train loss=0.44265538454055786
[15/24] Train loss=0.4177042841911316
[20/24] Train loss=0.3873237073421478
Test set avg_accuracy=82.79% avg_sensitivity=56.37%, avg_specificity=92.09% avg_auc=86.07%
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.413866 Test loss=0.394800 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.40148571133613586
[5/24] Train loss=0.3895118236541748
[10/24] Train loss=0.4320731461048126
[15/24] Train loss=0.4186721444129944
[20/24] Train loss=0.37509018182754517
Test set avg_accuracy=82.90% avg_sensitivity=55.82%, avg_specificity=92.45% avg_auc=86.42%
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.403264 Test loss=0.390778 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3932468295097351
[5/24] Train loss=0.3785448372364044
[10/24] Train loss=0.4361671209335327
[15/24] Train loss=0.40124982595443726
[20/24] Train loss=0.3694324791431427
Test set avg_accuracy=82.76% avg_sensitivity=55.17%, avg_specificity=92.48% avg_auc=86.49%
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.396064 Test loss=0.388090 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3893120586872101
[5/24] Train loss=0.3672071397304535
[10/24] Train loss=0.43185853958129883
[15/24] Train loss=0.3865954875946045
[20/24] Train loss=0.3618181347846985
Test set avg_accuracy=82.64% avg_sensitivity=58.07%, avg_specificity=91.30% avg_auc=86.37%
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.387963 Test loss=0.388815 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.37789204716682434
[5/24] Train loss=0.3643873333930969
[10/24] Train loss=0.4179285764694214
[15/24] Train loss=0.39654484391212463
[20/24] Train loss=0.34993648529052734
Test set avg_accuracy=82.99% avg_sensitivity=53.07%, avg_specificity=93.54% avg_auc=86.61%
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.382777 Test loss=0.385596 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.36719879508018494
[5/24] Train loss=0.3578711450099945
[10/24] Train loss=0.41115593910217285
[15/24] Train loss=0.38543394207954407
[20/24] Train loss=0.35152944922447205
Test set avg_accuracy=82.51% avg_sensitivity=49.03%, avg_specificity=94.31% avg_auc=86.42%
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.375450 Test loss=0.391390 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.36751267313957214
[5/24] Train loss=0.35499924421310425
[10/24] Train loss=0.41890937089920044
[15/24] Train loss=0.3861701190471649
[20/24] Train loss=0.3451142907142639
Test set avg_accuracy=83.16% avg_sensitivity=50.67%, avg_specificity=94.61% avg_auc=86.80%
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.371875 Test loss=0.385030 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.36139726638793945
[5/24] Train loss=0.34634625911712646
[10/24] Train loss=0.4128943979740143
[15/24] Train loss=0.3775722086429596
[20/24] Train loss=0.3443562388420105
Test set avg_accuracy=82.77% avg_sensitivity=50.17%, avg_specificity=94.26% avg_auc=86.88%
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.367760 Test loss=0.384043 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.35638561844825745
[5/24] Train loss=0.34824690222740173
[10/24] Train loss=0.414537250995636
[15/24] Train loss=0.3692267835140228
[20/24] Train loss=0.3333354592323303
Test set avg_accuracy=82.53% avg_sensitivity=54.92%, avg_specificity=92.25% avg_auc=86.49%
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.363130 Test loss=0.387088 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3558686077594757
[5/24] Train loss=0.34462323784828186
[10/24] Train loss=0.39812833070755005
[15/24] Train loss=0.3578810691833496
[20/24] Train loss=0.32978522777557373
Test set avg_accuracy=82.51% avg_sensitivity=46.18%, avg_specificity=95.32% avg_auc=86.79%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.357311 Test loss=0.391644 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.34796276688575745
[5/24] Train loss=0.33460938930511475
[10/24] Train loss=0.39221957325935364
[15/24] Train loss=0.3628767430782318
[20/24] Train loss=0.3190719485282898
Test set avg_accuracy=82.33% avg_sensitivity=52.67%, avg_specificity=92.78% avg_auc=86.75%
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.353699 Test loss=0.388620 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3462259769439697
[5/24] Train loss=0.3346193730831146
[10/24] Train loss=0.4005797803401947
[15/24] Train loss=0.3550955057144165
[20/24] Train loss=0.31875908374786377
Test set avg_accuracy=83.14% avg_sensitivity=52.32%, avg_specificity=94.00% avg_auc=87.36%
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.348987 Test loss=0.379170 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3415573835372925
[5/24] Train loss=0.33543816208839417
[10/24] Train loss=0.391884446144104
[15/24] Train loss=0.34630146622657776
[20/24] Train loss=0.31751549243927
Test set avg_accuracy=82.30% avg_sensitivity=47.53%, avg_specificity=94.56% avg_auc=86.48%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.345306 Test loss=0.397484 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.34246042370796204
[5/24] Train loss=0.3340569734573364
[10/24] Train loss=0.38473352789878845
[15/24] Train loss=0.34975993633270264
[20/24] Train loss=0.31021803617477417
Test set avg_accuracy=80.70% avg_sensitivity=31.73%, avg_specificity=97.96% avg_auc=86.53%
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.345146 Test loss=0.417051 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3426535427570343
[5/24] Train loss=0.32649022340774536
[10/24] Train loss=0.3883366584777832
[15/24] Train loss=0.345928817987442
[20/24] Train loss=0.31222003698349
Test set avg_accuracy=81.43% avg_sensitivity=39.08%, avg_specificity=96.35% avg_auc=85.39%
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.344139 Test loss=0.428870 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.33179277181625366
[5/24] Train loss=0.32804930210113525
[10/24] Train loss=0.3898168206214905
[15/24] Train loss=0.3434447646141052
[20/24] Train loss=0.3160552382469177
Test set avg_accuracy=80.85% avg_sensitivity=35.58%, avg_specificity=96.80% avg_auc=85.63%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.338445 Test loss=0.426067 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3214789927005768
[5/24] Train loss=0.3157939314842224
[10/24] Train loss=0.37574073672294617
[15/24] Train loss=0.3289719521999359
[20/24] Train loss=0.30712199211120605
Test set avg_accuracy=82.46% avg_sensitivity=50.47%, avg_specificity=93.73% avg_auc=86.58%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.330792 Test loss=0.386355 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3301381468772888
[5/24] Train loss=0.32295793294906616
[10/24] Train loss=0.37800508737564087
[15/24] Train loss=0.32738354802131653
[20/24] Train loss=0.3096565306186676
Test set avg_accuracy=80.35% avg_sensitivity=29.79%, avg_specificity=98.17% avg_auc=85.77%
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.333152 Test loss=0.450917 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.32053273916244507
[5/24] Train loss=0.31991487741470337
[10/24] Train loss=0.36224132776260376
[15/24] Train loss=0.32447531819343567
[20/24] Train loss=0.30610015988349915
Test set avg_accuracy=81.68% avg_sensitivity=39.28%, avg_specificity=96.62% avg_auc=85.89%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.326858 Test loss=0.403946 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3262549936771393
[5/24] Train loss=0.3036556541919708
[10/24] Train loss=0.3707578480243683
[15/24] Train loss=0.32134541869163513
[20/24] Train loss=0.31002911925315857
Test set avg_accuracy=80.14% avg_sensitivity=30.03%, avg_specificity=97.80% avg_auc=85.76%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.325471 Test loss=0.439929 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3304494619369507
[5/24] Train loss=0.32376182079315186
[10/24] Train loss=0.3685835599899292
[15/24] Train loss=0.31792837381362915
[20/24] Train loss=0.3007447123527527
Test set avg_accuracy=78.14% avg_sensitivity=18.54%, avg_specificity=99.14% avg_auc=82.13%
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.324652 Test loss=0.529385 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.30652594566345215
[5/24] Train loss=0.3109012842178345
[10/24] Train loss=0.36339911818504333
[15/24] Train loss=0.31271761655807495
[20/24] Train loss=0.3107055723667145
Test set avg_accuracy=82.01% avg_sensitivity=47.03%, avg_specificity=94.33% avg_auc=85.70%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.320278 Test loss=0.398526 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3054544925689697
[5/24] Train loss=0.30203142762184143
[10/24] Train loss=0.36427193880081177
[15/24] Train loss=0.31527334451675415
[20/24] Train loss=0.29514822363853455
Test set avg_accuracy=81.26% avg_sensitivity=38.98%, avg_specificity=96.16% avg_auc=85.04%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.318800 Test loss=0.420020 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.30663001537323
[5/24] Train loss=0.3007304072380066
[10/24] Train loss=0.3694761395454407
[15/24] Train loss=0.31381461024284363
[20/24] Train loss=0.2964072823524475
Test set avg_accuracy=81.08% avg_sensitivity=34.08%, avg_specificity=97.64% avg_auc=84.18%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.315763 Test loss=0.448742 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3127971589565277
[5/24] Train loss=0.29326674342155457
[10/24] Train loss=0.35162246227264404
[15/24] Train loss=0.30594122409820557
[20/24] Train loss=0.2887488901615143
Test set avg_accuracy=82.70% avg_sensitivity=52.22%, avg_specificity=93.43% avg_auc=86.88%
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.308369 Test loss=0.380467 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3151836097240448
[5/24] Train loss=0.304921418428421
[10/24] Train loss=0.34904080629348755
[15/24] Train loss=0.2981157600879669
[20/24] Train loss=0.28778040409088135
Test set avg_accuracy=76.98% avg_sensitivity=13.99%, avg_specificity=99.17% avg_auc=80.80%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.312467 Test loss=0.538271 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3042340874671936
[5/24] Train loss=0.3039189279079437
[10/24] Train loss=0.34505707025527954
[15/24] Train loss=0.31157955527305603
[20/24] Train loss=0.2861487865447998
Test set avg_accuracy=81.65% avg_sensitivity=45.23%, avg_specificity=94.49% avg_auc=84.56%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.310380 Test loss=0.414289 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.29864051938056946
[5/24] Train loss=0.29015764594078064
[10/24] Train loss=0.32771602272987366
[15/24] Train loss=0.29419800639152527
[20/24] Train loss=0.2775145173072815
Test set avg_accuracy=82.20% avg_sensitivity=54.52%, avg_specificity=91.95% avg_auc=85.93%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.302155 Test loss=0.392173 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2832625210285187
[5/24] Train loss=0.2885149121284485
[10/24] Train loss=0.364499568939209
[15/24] Train loss=0.29673680663108826
[20/24] Train loss=0.292566180229187
Test set avg_accuracy=79.34% avg_sensitivity=27.64%, avg_specificity=97.55% avg_auc=81.79%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.305347 Test loss=0.473907 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3030224144458771
[5/24] Train loss=0.2922899127006531
[10/24] Train loss=0.35759297013282776
[15/24] Train loss=0.28631484508514404
[20/24] Train loss=0.28303807973861694
Test set avg_accuracy=80.64% avg_sensitivity=39.33%, avg_specificity=95.19% avg_auc=83.34%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.304956 Test loss=0.436591 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2979034185409546
[5/24] Train loss=0.2875109314918518
[10/24] Train loss=0.3421871066093445
[15/24] Train loss=0.28327247500419617
[20/24] Train loss=0.26978978514671326
Test set avg_accuracy=76.37% avg_sensitivity=10.74%, avg_specificity=99.49% avg_auc=80.78%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.299259 Test loss=0.556050 Current lr=[0.000299720220882401]

[0/24] Train loss=0.301970511674881
[5/24] Train loss=0.29730746150016785
[10/24] Train loss=0.31423455476760864
[15/24] Train loss=0.27975356578826904
[20/24] Train loss=0.2855822443962097
Test set avg_accuracy=79.82% avg_sensitivity=29.34%, avg_specificity=97.61% avg_auc=80.60%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.295463 Test loss=0.502547 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.28962716460227966
[5/24] Train loss=0.2897090017795563
[10/24] Train loss=0.34861961007118225
[15/24] Train loss=0.2741321921348572
[20/24] Train loss=0.27279791235923767
Test set avg_accuracy=80.91% avg_sensitivity=35.68%, avg_specificity=96.85% avg_auc=82.60%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.299849 Test loss=0.448048 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3021850287914276
[5/24] Train loss=0.2905462682247162
[10/24] Train loss=0.33735665678977966
[15/24] Train loss=0.28046953678131104
[20/24] Train loss=0.26473626494407654
Test set avg_accuracy=76.94% avg_sensitivity=13.44%, avg_specificity=99.31% avg_auc=79.54%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.296193 Test loss=0.562619 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.28332680463790894
[5/24] Train loss=0.29541945457458496
[10/24] Train loss=0.3322547376155853
[15/24] Train loss=0.2749210298061371
[20/24] Train loss=0.27591991424560547
Test set avg_accuracy=80.73% avg_sensitivity=37.03%, avg_specificity=96.13% avg_auc=83.20%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.295559 Test loss=0.454750 Current lr=[0.000297555943323901]

[0/24] Train loss=0.28191491961479187
[5/24] Train loss=0.27690714597702026
[10/24] Train loss=0.33556652069091797
[15/24] Train loss=0.28935930132865906
[20/24] Train loss=0.25316691398620605
Test set avg_accuracy=79.23% avg_sensitivity=26.59%, avg_specificity=97.78% avg_auc=80.79%
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.293462 Test loss=0.477951 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2774088680744171
[5/24] Train loss=0.2791712284088135
[10/24] Train loss=0.31996652483940125
[15/24] Train loss=0.2716931998729706
[20/24] Train loss=0.26239579916000366
Test set avg_accuracy=78.01% avg_sensitivity=20.64%, avg_specificity=98.22% avg_auc=80.27%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.289755 Test loss=0.501441 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.26848214864730835
[5/24] Train loss=0.26188474893569946
[10/24] Train loss=0.30059897899627686
[15/24] Train loss=0.2825574576854706
[20/24] Train loss=0.27256327867507935
Test set avg_accuracy=80.35% avg_sensitivity=35.83%, avg_specificity=96.04% avg_auc=81.77%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.286281 Test loss=0.451320 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2788870930671692
[5/24] Train loss=0.27260103821754456
[10/24] Train loss=0.3079841136932373
[15/24] Train loss=0.27105531096458435
[20/24] Train loss=0.25695979595184326
Test set avg_accuracy=78.03% avg_sensitivity=19.09%, avg_specificity=98.80% avg_auc=79.94%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.284508 Test loss=0.540338 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.27460163831710815
[5/24] Train loss=0.27629801630973816
[10/24] Train loss=0.33680444955825806
[15/24] Train loss=0.2820788025856018
[20/24] Train loss=0.24251528084278107
Test set avg_accuracy=79.30% avg_sensitivity=27.99%, avg_specificity=97.38% avg_auc=81.00%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.284100 Test loss=0.539218 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.277222603559494
[5/24] Train loss=0.2547871470451355
[10/24] Train loss=0.31288740038871765
[15/24] Train loss=0.2694697976112366
[20/24] Train loss=0.2533023953437805
Test set avg_accuracy=80.70% avg_sensitivity=50.82%, avg_specificity=91.23% avg_auc=83.30%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.277732 Test loss=0.439618 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2634120583534241
[5/24] Train loss=0.2586206793785095
[10/24] Train loss=0.31759756803512573
[15/24] Train loss=0.27890127897262573
[20/24] Train loss=0.24961450695991516
Test set avg_accuracy=79.49% avg_sensitivity=38.38%, avg_specificity=93.98% avg_auc=81.31%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.276932 Test loss=0.464015 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.27655550837516785
[5/24] Train loss=0.26562777161598206
[10/24] Train loss=0.30780673027038574
[15/24] Train loss=0.27158206701278687
[20/24] Train loss=0.2516661286354065
Test set avg_accuracy=78.96% avg_sensitivity=36.73%, avg_specificity=93.84% avg_auc=79.29%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.273597 Test loss=0.515164 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.25784364342689514
[5/24] Train loss=0.259250283241272
[10/24] Train loss=0.3291512429714203
[15/24] Train loss=0.27860110998153687
[20/24] Train loss=0.2622627019882202
Test set avg_accuracy=80.44% avg_sensitivity=39.48%, avg_specificity=94.88% avg_auc=82.15%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.279062 Test loss=0.436868 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2716478407382965
[5/24] Train loss=0.27904796600341797
[10/24] Train loss=0.31044548749923706
[15/24] Train loss=0.27473077178001404
[20/24] Train loss=0.2571253180503845
Test set avg_accuracy=80.82% avg_sensitivity=44.43%, avg_specificity=93.64% avg_auc=82.89%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.279522 Test loss=0.440077 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.256011426448822
[5/24] Train loss=0.27481314539909363
[10/24] Train loss=0.30401140451431274
[15/24] Train loss=0.26400595903396606
[20/24] Train loss=0.25509172677993774
Test set avg_accuracy=81.17% avg_sensitivity=41.83%, avg_specificity=95.03% avg_auc=83.00%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.270688 Test loss=0.452258 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.251291424036026
[5/24] Train loss=0.26956647634506226
[10/24] Train loss=0.2998064160346985
[15/24] Train loss=0.2516977787017822
[20/24] Train loss=0.24695372581481934
Test set avg_accuracy=81.39% avg_sensitivity=40.53%, avg_specificity=95.79% avg_auc=82.90%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.264765 Test loss=0.459701 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2596396505832672
[5/24] Train loss=0.25226637721061707
[10/24] Train loss=0.29840537905693054
[15/24] Train loss=0.27068763971328735
[20/24] Train loss=0.24661999940872192
Test set avg_accuracy=78.83% avg_sensitivity=24.94%, avg_specificity=97.82% avg_auc=78.96%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.264874 Test loss=0.575854 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2578276991844177
[5/24] Train loss=0.27706992626190186
[10/24] Train loss=0.3127419948577881
[15/24] Train loss=0.28752726316452026
[20/24] Train loss=0.24271467328071594
Test set avg_accuracy=77.71% avg_sensitivity=18.89%, avg_specificity=98.43% avg_auc=75.71%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.273076 Test loss=0.629238 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.25214147567749023
[5/24] Train loss=0.26770827174186707
[10/24] Train loss=0.2835724651813507
[15/24] Train loss=0.2662222385406494
[20/24] Train loss=0.2492741048336029
Test set avg_accuracy=81.02% avg_sensitivity=40.18%, avg_specificity=95.40% avg_auc=81.64%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.263504 Test loss=0.473253 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2731180191040039
[5/24] Train loss=0.25818943977355957
[10/24] Train loss=0.29657918214797974
[15/24] Train loss=0.24990420043468475
[20/24] Train loss=0.2478814274072647
Test set avg_accuracy=80.92% avg_sensitivity=37.58%, avg_specificity=96.20% avg_auc=80.37%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.264101 Test loss=0.484796 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.24423304200172424
[5/24] Train loss=0.25281640887260437
[10/24] Train loss=0.29067525267601013
[15/24] Train loss=0.2532205581665039
[20/24] Train loss=0.22936846315860748
Test set avg_accuracy=80.99% avg_sensitivity=40.08%, avg_specificity=95.40% avg_auc=80.53%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.261367 Test loss=0.479555 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.24429482221603394
[5/24] Train loss=0.25233370065689087
[10/24] Train loss=0.28069350123405457
[15/24] Train loss=0.2488168478012085
[20/24] Train loss=0.23393431305885315
Test set avg_accuracy=80.74% avg_sensitivity=46.18%, avg_specificity=92.92% avg_auc=80.97%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.255522 Test loss=0.486804 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.24549581110477448
[5/24] Train loss=0.23385711014270782
[10/24] Train loss=0.2971811890602112
[15/24] Train loss=0.2548714280128479
[20/24] Train loss=0.25041478872299194
Test set avg_accuracy=80.76% avg_sensitivity=41.48%, avg_specificity=94.59% avg_auc=81.01%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.258363 Test loss=0.478354 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.25993919372558594
[5/24] Train loss=0.2445274442434311
[10/24] Train loss=0.29168733954429626
[15/24] Train loss=0.2629549205303192
[20/24] Train loss=0.2498808652162552
Test set avg_accuracy=81.38% avg_sensitivity=45.93%, avg_specificity=93.87% avg_auc=80.75%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.255257 Test loss=0.495794 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.24875634908676147
[5/24] Train loss=0.2531670033931732
[10/24] Train loss=0.26964718103408813
[15/24] Train loss=0.2673472464084625
[20/24] Train loss=0.23944903910160065
Test set avg_accuracy=82.62% avg_sensitivity=53.37%, avg_specificity=92.92% avg_auc=84.54%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.255995 Test loss=0.419141 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.23716171085834503
[5/24] Train loss=0.2465173900127411
[10/24] Train loss=0.2829965054988861
[15/24] Train loss=0.2463945895433426
[20/24] Train loss=0.23077186942100525
Test set avg_accuracy=81.54% avg_sensitivity=54.17%, avg_specificity=91.18% avg_auc=83.35%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.251494 Test loss=0.436754 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2434874027967453
[5/24] Train loss=0.24587097764015198
[10/24] Train loss=0.27291393280029297
[15/24] Train loss=0.24283099174499512
[20/24] Train loss=0.26467227935791016
Test set avg_accuracy=81.67% avg_sensitivity=50.32%, avg_specificity=92.71% avg_auc=81.48%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.249989 Test loss=0.479240 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.23535898327827454
[5/24] Train loss=0.2391694039106369
[10/24] Train loss=0.28252577781677246
[15/24] Train loss=0.25066834688186646
[20/24] Train loss=0.23060743510723114
Test set avg_accuracy=81.64% avg_sensitivity=44.78%, avg_specificity=94.63% avg_auc=81.70%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.245650 Test loss=0.479405 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.23393547534942627
[5/24] Train loss=0.2289762794971466
[10/24] Train loss=0.26249179244041443
[15/24] Train loss=0.2488446682691574
[20/24] Train loss=0.22887571156024933
Test set avg_accuracy=81.91% avg_sensitivity=57.62%, avg_specificity=90.47% avg_auc=84.38%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.243260 Test loss=0.422858 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.23198606073856354
[5/24] Train loss=0.22839871048927307
[10/24] Train loss=0.2648756504058838
[15/24] Train loss=0.2403317540884018
[20/24] Train loss=0.24120290577411652
Test set avg_accuracy=82.68% avg_sensitivity=63.12%, avg_specificity=89.58% avg_auc=84.80%
Best model saved!! Metric=-5.822492215384202!!
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.242474 Test loss=0.415424 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2330426722764969
[5/24] Train loss=0.22994111478328705
[10/24] Train loss=0.2552739679813385
[15/24] Train loss=0.2302299439907074
[20/24] Train loss=0.2227495014667511
Test set avg_accuracy=82.46% avg_sensitivity=48.58%, avg_specificity=94.40% avg_auc=83.49%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.239459 Test loss=0.442182 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.22746984660625458
[5/24] Train loss=0.23156914114952087
[10/24] Train loss=0.2646332383155823
[15/24] Train loss=0.24291492998600006
[20/24] Train loss=0.2324175387620926
Test set avg_accuracy=81.15% avg_sensitivity=61.72%, avg_specificity=87.99% avg_auc=84.78%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.238753 Test loss=0.436944 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.24166083335876465
[5/24] Train loss=0.2248094379901886
[10/24] Train loss=0.2752305567264557
[15/24] Train loss=0.24219751358032227
[20/24] Train loss=0.23753464221954346
Test set avg_accuracy=79.53% avg_sensitivity=38.98%, avg_specificity=93.82% avg_auc=78.74%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.240013 Test loss=0.511210 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2361130565404892
[5/24] Train loss=0.22737319767475128
[10/24] Train loss=0.2573781907558441
[15/24] Train loss=0.22968804836273193
[20/24] Train loss=0.23475611209869385
Test set avg_accuracy=81.73% avg_sensitivity=52.02%, avg_specificity=92.20% avg_auc=84.44%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.235103 Test loss=0.425512 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.23817947506904602
[5/24] Train loss=0.22426046431064606
[10/24] Train loss=0.2572135627269745
[15/24] Train loss=0.22424915432929993
[20/24] Train loss=0.22885343432426453
Test set avg_accuracy=79.26% avg_sensitivity=61.22%, avg_specificity=85.61% avg_auc=82.12%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.231282 Test loss=0.479632 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.22793714702129364
[5/24] Train loss=0.2209756076335907
[10/24] Train loss=0.25740763545036316
[15/24] Train loss=0.2269423007965088
[20/24] Train loss=0.23042307794094086
Test set avg_accuracy=80.96% avg_sensitivity=58.02%, avg_specificity=89.05% avg_auc=83.41%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.230472 Test loss=0.438828 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.22648397088050842
[5/24] Train loss=0.2221214324235916
[10/24] Train loss=0.24563123285770416
[15/24] Train loss=0.23675112426280975
[20/24] Train loss=0.2131223827600479
Test set avg_accuracy=80.08% avg_sensitivity=48.48%, avg_specificity=91.21% avg_auc=80.62%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.228307 Test loss=0.482557 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.22970086336135864
[5/24] Train loss=0.20564568042755127
[10/24] Train loss=0.2480488121509552
[15/24] Train loss=0.2250373661518097
[20/24] Train loss=0.21117176115512848
Test set avg_accuracy=81.03% avg_sensitivity=56.22%, avg_specificity=89.77% avg_auc=83.09%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.221719 Test loss=0.458641 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.21196894347667694
[5/24] Train loss=0.226700097322464
[10/24] Train loss=0.24174000322818756
[15/24] Train loss=0.2290559560060501
[20/24] Train loss=0.2236609011888504
Test set avg_accuracy=78.66% avg_sensitivity=65.77%, avg_specificity=83.20% avg_auc=82.93%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.223156 Test loss=0.493998 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2139054834842682
[5/24] Train loss=0.203674778342247
[10/24] Train loss=0.22699306905269623
[15/24] Train loss=0.22315846383571625
[20/24] Train loss=0.21252474188804626
Test set avg_accuracy=81.03% avg_sensitivity=56.77%, avg_specificity=89.58% avg_auc=82.99%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.220385 Test loss=0.437495 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.22790464758872986
[5/24] Train loss=0.19993340969085693
[10/24] Train loss=0.23559977114200592
[15/24] Train loss=0.22696749866008759
[20/24] Train loss=0.2156987339258194
Test set avg_accuracy=80.72% avg_sensitivity=44.53%, avg_specificity=93.47% avg_auc=79.24%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.222316 Test loss=0.499265 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2083105444908142
[5/24] Train loss=0.20952145755290985
[10/24] Train loss=0.24459585547447205
[15/24] Train loss=0.23610639572143555
[20/24] Train loss=0.2173151820898056
Test set avg_accuracy=79.19% avg_sensitivity=61.42%, avg_specificity=85.46% avg_auc=83.29%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.224774 Test loss=0.455693 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2153756469488144
[5/24] Train loss=0.21467047929763794
[10/24] Train loss=0.2333575040102005
[15/24] Train loss=0.22117431461811066
[20/24] Train loss=0.20586681365966797
Test set avg_accuracy=81.99% avg_sensitivity=58.62%, avg_specificity=90.23% avg_auc=83.37%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.221365 Test loss=0.453701 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.23175093531608582
[5/24] Train loss=0.20613372325897217
[10/24] Train loss=0.22896067798137665
[15/24] Train loss=0.22282738983631134
[20/24] Train loss=0.2154344618320465
Test set avg_accuracy=80.49% avg_sensitivity=65.92%, avg_specificity=85.63% avg_auc=84.31%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.218695 Test loss=0.463785 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2190532237291336
[5/24] Train loss=0.23066149652004242
[10/24] Train loss=0.25331345200538635
[15/24] Train loss=0.2049577534198761
[20/24] Train loss=0.21454617381095886
Test set avg_accuracy=80.76% avg_sensitivity=64.32%, avg_specificity=86.55% avg_auc=83.92%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.222278 Test loss=0.448264 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.21506313979625702
[5/24] Train loss=0.20812344551086426
[10/24] Train loss=0.23207755386829376
[15/24] Train loss=0.23032116889953613
[20/24] Train loss=0.21351945400238037
Test set avg_accuracy=80.95% avg_sensitivity=49.28%, avg_specificity=92.11% avg_auc=80.78%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.222108 Test loss=0.461759 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.22246457636356354
[5/24] Train loss=0.19515752792358398
[10/24] Train loss=0.2306903600692749
[15/24] Train loss=0.22694946825504303
[20/24] Train loss=0.2140180766582489
Test set avg_accuracy=80.39% avg_sensitivity=56.02%, avg_specificity=88.98% avg_auc=81.99%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.220451 Test loss=0.460190 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2230767011642456
[5/24] Train loss=0.21566785871982574
[10/24] Train loss=0.22257642447948456
[15/24] Train loss=0.2203366458415985
[20/24] Train loss=0.21355843544006348
Test set avg_accuracy=81.47% avg_sensitivity=59.77%, avg_specificity=89.12% avg_auc=82.67%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.215614 Test loss=0.458649 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.20679955184459686
[5/24] Train loss=0.19704283773899078
[10/24] Train loss=0.21930864453315735
[15/24] Train loss=0.20957912504673004
[20/24] Train loss=0.20074805617332458
Test set avg_accuracy=81.38% avg_sensitivity=49.53%, avg_specificity=92.60% avg_auc=81.31%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.210508 Test loss=0.462443 Current lr=[0.000156543481933168]

[0/24] Train loss=0.20660893619060516
[5/24] Train loss=0.19519120454788208
[10/24] Train loss=0.2246120572090149
[15/24] Train loss=0.2071666121482849
[20/24] Train loss=0.20097017288208008
Test set avg_accuracy=80.94% avg_sensitivity=55.27%, avg_specificity=89.98% avg_auc=82.51%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.203966 Test loss=0.442152 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2171952724456787
[5/24] Train loss=0.18425466120243073
[10/24] Train loss=0.20849791169166565
[15/24] Train loss=0.21767017245292664
[20/24] Train loss=0.2157348394393921
Test set avg_accuracy=80.47% avg_sensitivity=41.68%, avg_specificity=94.14% avg_auc=76.83%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.205874 Test loss=0.513543 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.20978747308254242
[5/24] Train loss=0.1936720460653305
[10/24] Train loss=0.21065875887870789
[15/24] Train loss=0.20717228949069977
[20/24] Train loss=0.1978612095117569
Test set avg_accuracy=80.62% avg_sensitivity=53.42%, avg_specificity=90.21% avg_auc=81.46%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.203247 Test loss=0.459601 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.19542482495307922
[5/24] Train loss=0.18344028294086456
[10/24] Train loss=0.2177351415157318
[15/24] Train loss=0.20635674893856049
[20/24] Train loss=0.1945365071296692
Test set avg_accuracy=80.85% avg_sensitivity=52.92%, avg_specificity=90.68% avg_auc=83.04%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.196271 Test loss=0.445735 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.18656811118125916
[5/24] Train loss=0.19340841472148895
[10/24] Train loss=0.2132783681154251
[15/24] Train loss=0.2009156197309494
[20/24] Train loss=0.1899111419916153
Test set avg_accuracy=80.08% avg_sensitivity=50.67%, avg_specificity=90.44% avg_auc=79.48%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.194920 Test loss=0.487818 Current lr=[0.000134135431043539]

[0/24] Train loss=0.18716581165790558
[5/24] Train loss=0.1818513721227646
[10/24] Train loss=0.20133329927921295
[15/24] Train loss=0.19523240625858307
[20/24] Train loss=0.18871110677719116
Test set avg_accuracy=80.27% avg_sensitivity=53.87%, avg_specificity=89.58% avg_auc=81.86%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.192566 Test loss=0.465218 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.18820439279079437
[5/24] Train loss=0.17614692449569702
[10/24] Train loss=0.19739891588687897
[15/24] Train loss=0.19220811128616333
[20/24] Train loss=0.1916360855102539
Test set avg_accuracy=78.71% avg_sensitivity=45.78%, avg_specificity=90.32% avg_auc=78.15%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.190954 Test loss=0.494991 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.18884052336215973
[5/24] Train loss=0.1760421246290207
[10/24] Train loss=0.21466265618801117
[15/24] Train loss=0.19852636754512787
[20/24] Train loss=0.18962247669696808
Test set avg_accuracy=80.65% avg_sensitivity=59.67%, avg_specificity=88.04% avg_auc=83.14%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.192315 Test loss=0.460031 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.1800854206085205
[5/24] Train loss=0.1757621467113495
[10/24] Train loss=0.20096421241760254
[15/24] Train loss=0.19269731640815735
[20/24] Train loss=0.18461453914642334
Test set avg_accuracy=80.73% avg_sensitivity=57.27%, avg_specificity=88.99% avg_auc=83.04%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.189229 Test loss=0.451320 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.17956118285655975
[5/24] Train loss=0.18013185262680054
[10/24] Train loss=0.20542345941066742
[15/24] Train loss=0.1860245168209076
[20/24] Train loss=0.18366391956806183
Test set avg_accuracy=80.43% avg_sensitivity=58.77%, avg_specificity=88.06% avg_auc=83.33%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.184977 Test loss=0.458177 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.18101359903812408
[5/24] Train loss=0.17031480371952057
[10/24] Train loss=0.19844090938568115
[15/24] Train loss=0.18719641864299774
[20/24] Train loss=0.18363666534423828
Test set avg_accuracy=80.08% avg_sensitivity=55.42%, avg_specificity=88.77% avg_auc=82.27%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.188262 Test loss=0.468083 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.18423666059970856
[5/24] Train loss=0.16783533990383148
[10/24] Train loss=0.20860649645328522
[15/24] Train loss=0.18475103378295898
[20/24] Train loss=0.19353801012039185
Test set avg_accuracy=78.91% avg_sensitivity=60.62%, avg_specificity=85.35% avg_auc=83.09%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.185461 Test loss=0.469049 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1826050877571106
[5/24] Train loss=0.16742374002933502
[10/24] Train loss=0.19273650646209717
[15/24] Train loss=0.18725860118865967
[20/24] Train loss=0.182908296585083
Test set avg_accuracy=80.65% avg_sensitivity=62.62%, avg_specificity=87.00% avg_auc=84.49%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.182150 Test loss=0.446131 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.18011312186717987
[5/24] Train loss=0.176879420876503
[10/24] Train loss=0.18097692728042603
[15/24] Train loss=0.18039464950561523
[20/24] Train loss=0.17588333785533905
Test set avg_accuracy=80.79% avg_sensitivity=54.67%, avg_specificity=90.00% avg_auc=82.36%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.179507 Test loss=0.464281 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.16771872341632843
[5/24] Train loss=0.1687658727169037
[10/24] Train loss=0.18328037858009338
[15/24] Train loss=0.1841660887002945
[20/24] Train loss=0.17116403579711914
Test set avg_accuracy=81.63% avg_sensitivity=60.07%, avg_specificity=89.22% avg_auc=83.75%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.177311 Test loss=0.442532 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.17845885455608368
[5/24] Train loss=0.16183343529701233
[10/24] Train loss=0.19134625792503357
[15/24] Train loss=0.18140405416488647
[20/24] Train loss=0.1716444045305252
Test set avg_accuracy=81.65% avg_sensitivity=62.12%, avg_specificity=88.54% avg_auc=85.06%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.176958 Test loss=0.435276 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.16690292954444885
[5/24] Train loss=0.15368296205997467
[10/24] Train loss=0.18282684683799744
[15/24] Train loss=0.18235079944133759
[20/24] Train loss=0.1696254312992096
Test set avg_accuracy=81.30% avg_sensitivity=59.27%, avg_specificity=89.06% avg_auc=83.38%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.172494 Test loss=0.455529 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.17701587080955505
[5/24] Train loss=0.1619000881910324
[10/24] Train loss=0.17604918777942657
[15/24] Train loss=0.1729373037815094
[20/24] Train loss=0.17100292444229126
Test set avg_accuracy=80.79% avg_sensitivity=65.27%, avg_specificity=86.27% avg_auc=85.05%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.173682 Test loss=0.451453 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.17128820717334747
[5/24] Train loss=0.15499655902385712
[10/24] Train loss=0.17688418924808502
[15/24] Train loss=0.16742713749408722
[20/24] Train loss=0.16843551397323608
Test set avg_accuracy=80.96% avg_sensitivity=58.02%, avg_specificity=89.05% avg_auc=83.59%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.169389 Test loss=0.462393 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.16687136888504028
[5/24] Train loss=0.15815870463848114
[10/24] Train loss=0.17626290023326874
[15/24] Train loss=0.1742495894432068
[20/24] Train loss=0.16777773201465607
Test set avg_accuracy=80.78% avg_sensitivity=66.27%, avg_specificity=85.90% avg_auc=84.66%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.169734 Test loss=0.457484 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1611403077840805
[5/24] Train loss=0.15271557867527008
[10/24] Train loss=0.17319339513778687
[15/24] Train loss=0.17282898724079132
[20/24] Train loss=0.16566096246242523
Test set avg_accuracy=81.09% avg_sensitivity=67.47%, avg_specificity=85.90% avg_auc=85.53%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.166265 Test loss=0.442837 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.15835769474506378
[5/24] Train loss=0.1477682888507843
[10/24] Train loss=0.16858740150928497
[15/24] Train loss=0.1617632359266281
[20/24] Train loss=0.15994416177272797
Test set avg_accuracy=80.23% avg_sensitivity=69.22%, avg_specificity=84.12% avg_auc=85.05%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.163333 Test loss=0.458441 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.16020089387893677
[5/24] Train loss=0.15135802328586578
[10/24] Train loss=0.1750277876853943
[15/24] Train loss=0.17208148539066315
[20/24] Train loss=0.16213800013065338
Test set avg_accuracy=79.65% avg_sensitivity=68.32%, avg_specificity=83.64% avg_auc=84.25%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.162897 Test loss=0.474074 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.16076257824897766
[5/24] Train loss=0.1508590131998062
[10/24] Train loss=0.16489459574222565
[15/24] Train loss=0.16369743645191193
[20/24] Train loss=0.15511032938957214
Test set avg_accuracy=80.26% avg_sensitivity=64.62%, avg_specificity=85.77% avg_auc=83.95%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.160214 Test loss=0.458180 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.150049090385437
[5/24] Train loss=0.14569035172462463
[10/24] Train loss=0.1588798612356186
[15/24] Train loss=0.16212603449821472
[20/24] Train loss=0.16088040173053741
Test set avg_accuracy=82.19% avg_sensitivity=60.97%, avg_specificity=89.66% avg_auc=84.31%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.158267 Test loss=0.442448 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.15492761135101318
[5/24] Train loss=0.14423756301403046
[10/24] Train loss=0.15841415524482727
[15/24] Train loss=0.163053959608078
[20/24] Train loss=0.16049951314926147
Test set avg_accuracy=81.86% avg_sensitivity=56.32%, avg_specificity=90.86% avg_auc=83.72%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.156488 Test loss=0.450483 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.15134650468826294
[5/24] Train loss=0.14261099696159363
[10/24] Train loss=0.1597355306148529
[15/24] Train loss=0.16095194220542908
[20/24] Train loss=0.15794961154460907
Test set avg_accuracy=81.12% avg_sensitivity=56.12%, avg_specificity=89.93% avg_auc=83.20%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.155348 Test loss=0.454807 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.14787296950817108
[5/24] Train loss=0.14066645503044128
[10/24] Train loss=0.16176025569438934
[15/24] Train loss=0.15319664776325226
[20/24] Train loss=0.15580910444259644
Test set avg_accuracy=81.39% avg_sensitivity=58.42%, avg_specificity=89.49% avg_auc=83.59%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.154334 Test loss=0.451287 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.14948102831840515
[5/24] Train loss=0.14084023237228394
[10/24] Train loss=0.1522921919822693
[15/24] Train loss=0.15527604520320892
[20/24] Train loss=0.15251043438911438
Test set avg_accuracy=81.85% avg_sensitivity=62.47%, avg_specificity=88.68% avg_auc=84.69%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.151037 Test loss=0.443496 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.14476381242275238
[5/24] Train loss=0.13568119704723358
[10/24] Train loss=0.15289780497550964
[15/24] Train loss=0.14843222498893738
[20/24] Train loss=0.1514461487531662
Test set avg_accuracy=81.77% avg_sensitivity=57.82%, avg_specificity=90.21% avg_auc=84.12%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.149874 Test loss=0.447418 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.14271385967731476
[5/24] Train loss=0.13285265862941742
[10/24] Train loss=0.15949095785617828
[15/24] Train loss=0.15195447206497192
[20/24] Train loss=0.15062516927719116
Test set avg_accuracy=81.56% avg_sensitivity=59.47%, avg_specificity=89.35% avg_auc=84.49%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.148129 Test loss=0.443066 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1414085030555725
[5/24] Train loss=0.13421882688999176
[10/24] Train loss=0.1513601392507553
[15/24] Train loss=0.14923976361751556
[20/24] Train loss=0.14736135303974152
Test set avg_accuracy=81.84% avg_sensitivity=60.27%, avg_specificity=89.43% avg_auc=83.95%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.146375 Test loss=0.446611 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.14075464010238647
[5/24] Train loss=0.13182269036769867
[10/24] Train loss=0.14816804230213165
[15/24] Train loss=0.15240271389484406
[20/24] Train loss=0.15019461512565613
Test set avg_accuracy=81.38% avg_sensitivity=60.47%, avg_specificity=88.75% avg_auc=83.86%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.145778 Test loss=0.450589 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.142038494348526
[5/24] Train loss=0.12915395200252533
[10/24] Train loss=0.14736643433570862
[15/24] Train loss=0.14986087381839752
[20/24] Train loss=0.14638474583625793
Test set avg_accuracy=81.20% avg_sensitivity=61.07%, avg_specificity=88.29% avg_auc=83.73%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.144318 Test loss=0.451474 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1402398943901062
[5/24] Train loss=0.13028603792190552
[10/24] Train loss=0.14916281402111053
[15/24] Train loss=0.14421136677265167
[20/24] Train loss=0.14580902457237244
Test set avg_accuracy=81.24% avg_sensitivity=59.67%, avg_specificity=88.84% avg_auc=83.43%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.143371 Test loss=0.453371 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13787126541137695
[5/24] Train loss=0.1319345384836197
[10/24] Train loss=0.15009577572345734
[15/24] Train loss=0.15055590867996216
[20/24] Train loss=0.1427968144416809
Test set avg_accuracy=81.60% avg_sensitivity=59.62%, avg_specificity=89.35% avg_auc=83.85%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.142799 Test loss=0.450540 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1385076344013214
[5/24] Train loss=0.12632453441619873
[10/24] Train loss=0.14587536454200745
[15/24] Train loss=0.1540142446756363
[20/24] Train loss=0.14445921778678894
Test set avg_accuracy=81.58% avg_sensitivity=60.87%, avg_specificity=88.87% avg_auc=83.89%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.142257 Test loss=0.452496 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.14039185643196106
[5/24] Train loss=0.13087747991085052
[10/24] Train loss=0.14489352703094482
[15/24] Train loss=0.14725863933563232
[20/24] Train loss=0.1421058028936386
Test set avg_accuracy=81.48% avg_sensitivity=60.67%, avg_specificity=88.82% avg_auc=83.80%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.141684 Test loss=0.450186 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13695120811462402
[5/24] Train loss=0.12773047387599945
[10/24] Train loss=0.14227566123008728
[15/24] Train loss=0.14497077465057373
[20/24] Train loss=0.14036281406879425
Test set avg_accuracy=81.43% avg_sensitivity=59.87%, avg_specificity=89.03% avg_auc=84.06%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.140460 Test loss=0.449859 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13668358325958252
[5/24] Train loss=0.12646472454071045
[10/24] Train loss=0.144064798951149
[15/24] Train loss=0.14476412534713745
[20/24] Train loss=0.14176078140735626
Test set avg_accuracy=81.28% avg_sensitivity=59.82%, avg_specificity=88.84% avg_auc=83.62%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.139913 Test loss=0.452764 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.13480056822299957
[5/24] Train loss=0.12665364146232605
[10/24] Train loss=0.14233942329883575
[15/24] Train loss=0.14409755170345306
[20/24] Train loss=0.14607053995132446
Test set avg_accuracy=81.28% avg_sensitivity=61.12%, avg_specificity=88.38% avg_auc=84.00%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.139539 Test loss=0.450833 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13676588237285614
[5/24] Train loss=0.12439336627721786
[10/24] Train loss=0.14382578432559967
[15/24] Train loss=0.14373987913131714
[20/24] Train loss=0.14055711030960083
Test set avg_accuracy=81.45% avg_sensitivity=61.02%, avg_specificity=88.64% avg_auc=84.12%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.138731 Test loss=0.448200 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.13864079117774963
[5/24] Train loss=0.12449192255735397
[10/24] Train loss=0.1390049308538437
[15/24] Train loss=0.14496003091335297
[20/24] Train loss=0.1381606161594391
Test set avg_accuracy=81.45% avg_sensitivity=60.22%, avg_specificity=88.92% avg_auc=83.94%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.138663 Test loss=0.448525 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1333203911781311
[5/24] Train loss=0.12436909973621368
[10/24] Train loss=0.14274580776691437
[15/24] Train loss=0.14488404989242554
[20/24] Train loss=0.14012284576892853
Test set avg_accuracy=81.45% avg_sensitivity=60.57%, avg_specificity=88.80% avg_auc=83.95%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.138698 Test loss=0.451187 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13717474043369293
[5/24] Train loss=0.12327458709478378
[10/24] Train loss=0.14217326045036316
[15/24] Train loss=0.13947337865829468
[20/24] Train loss=0.1384904980659485
Test set avg_accuracy=81.71% avg_sensitivity=60.77%, avg_specificity=89.08% avg_auc=84.00%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.138124 Test loss=0.448920 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1329822540283203
[5/24] Train loss=0.12477239966392517
[10/24] Train loss=0.14090731739997864
[15/24] Train loss=0.1412086933851242
[20/24] Train loss=0.1408880352973938
Test set avg_accuracy=81.47% avg_sensitivity=61.32%, avg_specificity=88.57% avg_auc=83.99%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.137278 Test loss=0.450465 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13381144404411316
[5/24] Train loss=0.12449683248996735
[10/24] Train loss=0.14592553675174713
[15/24] Train loss=0.1430242955684662
[20/24] Train loss=0.14216646552085876
Test set avg_accuracy=81.37% avg_sensitivity=60.57%, avg_specificity=88.70% avg_auc=83.77%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.138570 Test loss=0.453076 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13626325130462646
[5/24] Train loss=0.12263520061969757
[10/24] Train loss=0.14793196320533752
[15/24] Train loss=0.14387521147727966
[20/24] Train loss=0.13728289306163788
Test set avg_accuracy=81.42% avg_sensitivity=59.97%, avg_specificity=88.98% avg_auc=83.76%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.137258 Test loss=0.452369 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13412584364414215
[5/24] Train loss=0.12258182466030121
[10/24] Train loss=0.1403217911720276
[15/24] Train loss=0.1441906988620758
[20/24] Train loss=0.14151634275913239
Test set avg_accuracy=81.33% avg_sensitivity=60.32%, avg_specificity=88.73% avg_auc=83.86%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.137451 Test loss=0.452101 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13277384638786316
[5/24] Train loss=0.12428444623947144
[10/24] Train loss=0.13850253820419312
[15/24] Train loss=0.1412334144115448
[20/24] Train loss=0.14195844531059265
Test set avg_accuracy=81.43% avg_sensitivity=60.22%, avg_specificity=88.91% avg_auc=83.82%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.137478 Test loss=0.451615 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.13290193676948547
[5/24] Train loss=0.12292110919952393
[10/24] Train loss=0.14051935076713562
[15/24] Train loss=0.14300617575645447
[20/24] Train loss=0.14601139724254608
Test set avg_accuracy=81.45% avg_sensitivity=60.27%, avg_specificity=88.91% avg_auc=83.84%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.137552 Test loss=0.451223 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.13642843067646027
[5/24] Train loss=0.12413625419139862
[10/24] Train loss=0.1390821635723114
[15/24] Train loss=0.1412196159362793
[20/24] Train loss=0.1415134221315384
Test set avg_accuracy=81.47% avg_sensitivity=60.47%, avg_specificity=88.87% avg_auc=83.85%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.136899 Test loss=0.451435 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13198116421699524
[5/24] Train loss=0.12400823831558228
[10/24] Train loss=0.141926109790802
[15/24] Train loss=0.14170251786708832
[20/24] Train loss=0.13930928707122803
Test set avg_accuracy=81.46% avg_sensitivity=60.52%, avg_specificity=88.84% avg_auc=83.85%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.137280 Test loss=0.451785 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.13264775276184082
[5/24] Train loss=0.1252293735742569
[10/24] Train loss=0.14351756870746613
[15/24] Train loss=0.14549440145492554
[20/24] Train loss=0.14334474503993988
Test set avg_accuracy=81.48% avg_sensitivity=60.52%, avg_specificity=88.87% avg_auc=83.85%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.137375 Test loss=0.451637 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=82.68% sen=63.12%, spe=89.58%, auc=84.80%!
Fold[4] Avg_overlap=0.59%(±0.29604711911632386)
[0/24] Train loss=0.7356172204017639
[5/24] Train loss=0.7270984053611755
[10/24] Train loss=0.722632646560669
[15/24] Train loss=0.7142089009284973
[20/24] Train loss=0.7030442953109741
Test set avg_accuracy=55.42% avg_sensitivity=48.34%, avg_specificity=57.83% avg_auc=56.65%
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.720300 Test loss=0.663934 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7046194076538086
[5/24] Train loss=0.691023051738739
[10/24] Train loss=0.6969480514526367
[15/24] Train loss=0.691589891910553
[20/24] Train loss=0.679100513458252
Test set avg_accuracy=66.85% avg_sensitivity=59.45%, avg_specificity=69.37% avg_auc=70.07%
Best model saved!! Metric=-60.25761627651103!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.692719 Test loss=0.618219 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.675568699836731
[5/24] Train loss=0.6611928939819336
[10/24] Train loss=0.6743088364601135
[15/24] Train loss=0.6630632281303406
[20/24] Train loss=0.6573823690414429
Test set avg_accuracy=68.92% avg_sensitivity=67.54%, avg_specificity=69.39% avg_auc=74.71%
Best model saved!! Metric=-45.44104055626211!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.668671 Test loss=0.594744 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6503064632415771
[5/24] Train loss=0.6429880261421204
[10/24] Train loss=0.6424974799156189
[15/24] Train loss=0.6416555643081665
[20/24] Train loss=0.6306235194206238
Test set avg_accuracy=70.66% avg_sensitivity=70.87%, avg_specificity=70.60% avg_auc=76.97%
Best model saved!! Metric=-36.906351930043684!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.648805 Test loss=0.574854 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6330805420875549
[5/24] Train loss=0.6146032214164734
[10/24] Train loss=0.6265859007835388
[15/24] Train loss=0.62241530418396
[20/24] Train loss=0.6114963889122009
Test set avg_accuracy=72.72% avg_sensitivity=73.17%, avg_specificity=72.57% avg_auc=78.91%
Best model saved!! Metric=-28.629127212980478!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.627305 Test loss=0.552715 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6118854880332947
[5/24] Train loss=0.5914292931556702
[10/24] Train loss=0.614444375038147
[15/24] Train loss=0.595982015132904
[20/24] Train loss=0.5917454361915588
Test set avg_accuracy=74.39% avg_sensitivity=72.96%, avg_specificity=74.87% avg_auc=80.23%
Best model saved!! Metric=-23.546029846556266!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.607673 Test loss=0.531992 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.584561288356781
[5/24] Train loss=0.5708029270172119
[10/24] Train loss=0.5921590924263
[15/24] Train loss=0.5748311877250671
[20/24] Train loss=0.5696182250976562
Test set avg_accuracy=75.99% avg_sensitivity=72.56%, avg_specificity=77.16% avg_auc=81.42%
Best model saved!! Metric=-18.873370429669436!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.586835 Test loss=0.511647 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5628863573074341
[5/24] Train loss=0.5449931621551514
[10/24] Train loss=0.5653344988822937
[15/24] Train loss=0.561750590801239
[20/24] Train loss=0.551472008228302
Test set avg_accuracy=77.75% avg_sensitivity=71.84%, avg_specificity=79.76% avg_auc=82.89%
Best model saved!! Metric=-13.759852331614354!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.566157 Test loss=0.489483 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5462663173675537
[5/24] Train loss=0.5263661742210388
[10/24] Train loss=0.543444812297821
[15/24] Train loss=0.5396865010261536
[20/24] Train loss=0.5220376253128052
Test set avg_accuracy=79.64% avg_sensitivity=71.07%, avg_specificity=82.56% avg_auc=83.95%
Best model saved!! Metric=-8.78878983229609!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.545674 Test loss=0.465684 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5271205306053162
[5/24] Train loss=0.5077501535415649
[10/24] Train loss=0.5319312214851379
[15/24] Train loss=0.5161580443382263
[20/24] Train loss=0.505266547203064
Test set avg_accuracy=81.08% avg_sensitivity=69.89%, avg_specificity=84.90% avg_auc=85.09%
Best model saved!! Metric=-5.042718384753641!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.525482 Test loss=0.443347 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5086955428123474
[5/24] Train loss=0.4890950918197632
[10/24] Train loss=0.5068037509918213
[15/24] Train loss=0.49252641201019287
[20/24] Train loss=0.48251694440841675
Test set avg_accuracy=82.33% avg_sensitivity=66.05%, avg_specificity=87.88% avg_auc=85.69%
Best model saved!! Metric=-4.043955976094992!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.503975 Test loss=0.421298 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4886428415775299
[5/24] Train loss=0.46456483006477356
[10/24] Train loss=0.48799562454223633
[15/24] Train loss=0.4784027636051178
[20/24] Train loss=0.46201080083847046
Test set avg_accuracy=82.64% avg_sensitivity=66.82%, avg_specificity=88.04% avg_auc=86.72%
Best model saved!! Metric=-1.7823652835310924!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.483575 Test loss=0.410172 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4728527367115021
[5/24] Train loss=0.45598915219306946
[10/24] Train loss=0.4740963280200958
[15/24] Train loss=0.45582836866378784
[20/24] Train loss=0.44669076800346375
Test set avg_accuracy=83.53% avg_sensitivity=65.03%, avg_specificity=89.84% avg_auc=87.21%
Best model saved!! Metric=-0.40029381716293244!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.466033 Test loss=0.396010 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.45930686593055725
[5/24] Train loss=0.4373752772808075
[10/24] Train loss=0.457507461309433
[15/24] Train loss=0.44217464327812195
[20/24] Train loss=0.4272000789642334
Test set avg_accuracy=83.98% avg_sensitivity=63.59%, avg_specificity=90.94% avg_auc=87.84%
Best model saved!! Metric=0.3540049032144381!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.450065 Test loss=0.385216 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.44448256492614746
[5/24] Train loss=0.4310603737831116
[10/24] Train loss=0.4516544044017792
[15/24] Train loss=0.41999971866607666
[20/24] Train loss=0.41191670298576355
Test set avg_accuracy=84.17% avg_sensitivity=63.03%, avg_specificity=91.37% avg_auc=88.26%
Best model saved!! Metric=0.8330064620556072!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.435223 Test loss=0.375908 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.43606245517730713
[5/24] Train loss=0.41071683168411255
[10/24] Train loss=0.44377437233924866
[15/24] Train loss=0.41648292541503906
[20/24] Train loss=0.4037186801433563
Test set avg_accuracy=84.30% avg_sensitivity=59.65%, avg_specificity=92.70% avg_auc=88.42%
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.422276 Test loss=0.370879 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.42800718545913696
[5/24] Train loss=0.4029139280319214
[10/24] Train loss=0.43090471625328064
[15/24] Train loss=0.4001479744911194
[20/24] Train loss=0.3920935392379761
Test set avg_accuracy=84.26% avg_sensitivity=57.35%, avg_specificity=93.43% avg_auc=88.54%
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.412286 Test loss=0.364810 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4259534478187561
[5/24] Train loss=0.3901820778846741
[10/24] Train loss=0.4279625713825226
[15/24] Train loss=0.3909853398799896
[20/24] Train loss=0.37978193163871765
Test set avg_accuracy=84.45% avg_sensitivity=57.19%, avg_specificity=93.75% avg_auc=88.83%
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.402909 Test loss=0.360583 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.409240186214447
[5/24] Train loss=0.3851827085018158
[10/24] Train loss=0.42622363567352295
[15/24] Train loss=0.3878433406352997
[20/24] Train loss=0.3741026222705841
Test set avg_accuracy=84.57% avg_sensitivity=57.30%, avg_specificity=93.87% avg_auc=88.71%
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.396377 Test loss=0.359663 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4036725163459778
[5/24] Train loss=0.384051650762558
[10/24] Train loss=0.4123486280441284
[15/24] Train loss=0.382000595331192
[20/24] Train loss=0.35908955335617065
Test set avg_accuracy=84.35% avg_sensitivity=52.28%, avg_specificity=95.29% avg_auc=89.02%
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.389508 Test loss=0.358216 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.40132859349250793
[5/24] Train loss=0.36834684014320374
[10/24] Train loss=0.41191381216049194
[15/24] Train loss=0.3800492286682129
[20/24] Train loss=0.36146941781044006
Test set avg_accuracy=84.90% avg_sensitivity=58.99%, avg_specificity=93.73% avg_auc=88.91%
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.384078 Test loss=0.355258 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3940240740776062
[5/24] Train loss=0.37120771408081055
[10/24] Train loss=0.4104287028312683
[15/24] Train loss=0.37158694863319397
[20/24] Train loss=0.35276538133621216
Test set avg_accuracy=84.47% avg_sensitivity=58.42%, avg_specificity=93.35% avg_auc=89.40%
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.378355 Test loss=0.349726 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3836836814880371
[5/24] Train loss=0.3701612055301666
[10/24] Train loss=0.4059477746486664
[15/24] Train loss=0.36526885628700256
[20/24] Train loss=0.35006222128868103
Test set avg_accuracy=84.48% avg_sensitivity=63.80%, avg_specificity=91.53% avg_auc=89.84%
Best model saved!! Metric=3.6480565676405803!!
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.374530 Test loss=0.344321 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3803558349609375
[5/24] Train loss=0.3638612627983093
[10/24] Train loss=0.4004593789577484
[15/24] Train loss=0.36244770884513855
[20/24] Train loss=0.3423936069011688
Test set avg_accuracy=84.88% avg_sensitivity=57.40%, avg_specificity=94.26% avg_auc=89.89%
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.370218 Test loss=0.343960 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3749939203262329
[5/24] Train loss=0.3565117418766022
[10/24] Train loss=0.4058992266654968
[15/24] Train loss=0.3676721155643463
[20/24] Train loss=0.33791837096214294
Test set avg_accuracy=84.84% avg_sensitivity=57.14%, avg_specificity=94.29% avg_auc=90.21%
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.367192 Test loss=0.342274 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.38085341453552246
[5/24] Train loss=0.35629966855049133
[10/24] Train loss=0.39472880959510803
[15/24] Train loss=0.3554695248603821
[20/24] Train loss=0.3321459889411926
Test set avg_accuracy=84.67% avg_sensitivity=60.93%, avg_specificity=92.77% avg_auc=89.68%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.362822 Test loss=0.347996 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3736218214035034
[5/24] Train loss=0.35448604822158813
[10/24] Train loss=0.38997069001197815
[15/24] Train loss=0.3429570198059082
[20/24] Train loss=0.32877781987190247
Test set avg_accuracy=84.67% avg_sensitivity=56.12%, avg_specificity=94.41% avg_auc=89.80%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.359262 Test loss=0.348541 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3782345652580261
[5/24] Train loss=0.3456525206565857
[10/24] Train loss=0.3888888955116272
[15/24] Train loss=0.34621843695640564
[20/24] Train loss=0.32858970761299133
Test set avg_accuracy=85.25% avg_sensitivity=68.46%, avg_specificity=90.97% avg_auc=90.20%
Best model saved!! Metric=8.881324142129415!!
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.356624 Test loss=0.344882 Current lr=[0.000210185142098938]

[0/24] Train loss=0.37479597330093384
[5/24] Train loss=0.34983593225479126
[10/24] Train loss=0.38788652420043945
[15/24] Train loss=0.3377799391746521
[20/24] Train loss=0.3206872344017029
Test set avg_accuracy=83.85% avg_sensitivity=55.50%, avg_specificity=93.52% avg_auc=89.47%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.353819 Test loss=0.349756 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.37094467878341675
[5/24] Train loss=0.34861281514167786
[10/24] Train loss=0.3778347969055176
[15/24] Train loss=0.3392697870731354
[20/24] Train loss=0.32216760516166687
Test set avg_accuracy=83.89% avg_sensitivity=45.52%, avg_specificity=96.98% avg_auc=89.95%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.352040 Test loss=0.359889 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.36692363023757935
[5/24] Train loss=0.3391475975513458
[10/24] Train loss=0.37442028522491455
[15/24] Train loss=0.33462050557136536
[20/24] Train loss=0.31839823722839355
Test set avg_accuracy=81.67% avg_sensitivity=34.05%, avg_specificity=97.90% avg_auc=87.78%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.346688 Test loss=0.406192 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.372477263212204
[5/24] Train loss=0.32872438430786133
[10/24] Train loss=0.37074825167655945
[15/24] Train loss=0.33343201875686646
[20/24] Train loss=0.31741875410079956
Test set avg_accuracy=82.10% avg_sensitivity=36.41%, avg_specificity=97.68% avg_auc=88.35%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.343947 Test loss=0.399141 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3602309226989746
[5/24] Train loss=0.34430181980133057
[10/24] Train loss=0.37590086460113525
[15/24] Train loss=0.3208203911781311
[20/24] Train loss=0.3120473325252533
Test set avg_accuracy=82.40% avg_sensitivity=39.22%, avg_specificity=97.12% avg_auc=89.45%
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.341098 Test loss=0.376787 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3696530759334564
[5/24] Train loss=0.344931036233902
[10/24] Train loss=0.36497756838798523
[15/24] Train loss=0.31758296489715576
[20/24] Train loss=0.32466191053390503
Test set avg_accuracy=82.89% avg_sensitivity=39.78%, avg_specificity=97.59% avg_auc=90.19%
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.343698 Test loss=0.362715 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3508724570274353
[5/24] Train loss=0.33670473098754883
[10/24] Train loss=0.37019917368888855
[15/24] Train loss=0.3240896463394165
[20/24] Train loss=0.315657377243042
Test set avg_accuracy=79.43% avg_sensitivity=21.20%, avg_specificity=99.28% avg_auc=87.05%
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.334221 Test loss=0.478792 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.35810545086860657
[5/24] Train loss=0.3268362283706665
[10/24] Train loss=0.3553371727466583
[15/24] Train loss=0.3130956292152405
[20/24] Train loss=0.3090989589691162
Test set avg_accuracy=83.75% avg_sensitivity=54.43%, avg_specificity=93.75% avg_auc=88.12%
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.330388 Test loss=0.368667 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.34654974937438965
[5/24] Train loss=0.3306422233581543
[10/24] Train loss=0.3672395348548889
[15/24] Train loss=0.3106338083744049
[20/24] Train loss=0.3084496855735779
Test set avg_accuracy=84.04% avg_sensitivity=53.66%, avg_specificity=94.39% avg_auc=89.04%
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.329593 Test loss=0.356625 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3393731713294983
[5/24] Train loss=0.3226005733013153
[10/24] Train loss=0.35275715589523315
[15/24] Train loss=0.309213250875473
[20/24] Train loss=0.3190602660179138
Test set avg_accuracy=83.98% avg_sensitivity=59.81%, avg_specificity=92.23% avg_auc=88.45%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.328279 Test loss=0.363059 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3403586745262146
[5/24] Train loss=0.3235703110694885
[10/24] Train loss=0.3534368574619293
[15/24] Train loss=0.305642306804657
[20/24] Train loss=0.3097880780696869
Test set avg_accuracy=84.14% avg_sensitivity=48.90%, avg_specificity=96.16% avg_auc=89.84%
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.326805 Test loss=0.352986 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3641653060913086
[5/24] Train loss=0.3213123381137848
[10/24] Train loss=0.35364827513694763
[15/24] Train loss=0.31493666768074036
[20/24] Train loss=0.3071324825286865
Test set avg_accuracy=84.08% avg_sensitivity=54.17%, avg_specificity=94.27% avg_auc=89.59%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.327689 Test loss=0.350911 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3455033302307129
[5/24] Train loss=0.3268679976463318
[10/24] Train loss=0.3665626645088196
[15/24] Train loss=0.30651265382766724
[20/24] Train loss=0.29642876982688904
Test set avg_accuracy=82.17% avg_sensitivity=39.07%, avg_specificity=96.87% avg_auc=87.50%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.324277 Test loss=0.426601 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.33774569630622864
[5/24] Train loss=0.3381603956222534
[10/24] Train loss=0.35324257612228394
[15/24] Train loss=0.29755616188049316
[20/24] Train loss=0.29190802574157715
Test set avg_accuracy=83.03% avg_sensitivity=45.78%, avg_specificity=95.74% avg_auc=88.52%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.321112 Test loss=0.374980 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.33421429991722107
[5/24] Train loss=0.33490410447120667
[10/24] Train loss=0.3595728278160095
[15/24] Train loss=0.3059764504432678
[20/24] Train loss=0.2914988398551941
Test set avg_accuracy=80.18% avg_sensitivity=27.19%, avg_specificity=98.25% avg_auc=83.77%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.323097 Test loss=0.495066 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3481237590312958
[5/24] Train loss=0.3254193067550659
[10/24] Train loss=0.3548486828804016
[15/24] Train loss=0.29414501786231995
[20/24] Train loss=0.29313284158706665
Test set avg_accuracy=82.06% avg_sensitivity=38.76%, avg_specificity=96.82% avg_auc=86.74%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.322316 Test loss=0.395076 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3259276747703552
[5/24] Train loss=0.32528477907180786
[10/24] Train loss=0.3441845774650574
[15/24] Train loss=0.2981247007846832
[20/24] Train loss=0.2953856289386749
Test set avg_accuracy=83.31% avg_sensitivity=43.98%, avg_specificity=96.72% avg_auc=85.45%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.318829 Test loss=0.407654 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.33888736367225647
[5/24] Train loss=0.31420642137527466
[10/24] Train loss=0.3394216299057007
[15/24] Train loss=0.29103386402130127
[20/24] Train loss=0.28503328561782837
Test set avg_accuracy=81.82% avg_sensitivity=35.79%, avg_specificity=97.52% avg_auc=83.58%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.315309 Test loss=0.459365 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3356189727783203
[5/24] Train loss=0.32177770137786865
[10/24] Train loss=0.3507270812988281
[15/24] Train loss=0.29378873109817505
[20/24] Train loss=0.28881651163101196
Test set avg_accuracy=78.11% avg_sensitivity=16.79%, avg_specificity=99.02% avg_auc=75.62%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.314221 Test loss=0.617151 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3271629214286804
[5/24] Train loss=0.3049300014972687
[10/24] Train loss=0.342428594827652
[15/24] Train loss=0.28616607189178467
[20/24] Train loss=0.28445112705230713
Test set avg_accuracy=80.01% avg_sensitivity=26.52%, avg_specificity=98.25% avg_auc=82.14%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.308964 Test loss=0.509253 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3181631565093994
[5/24] Train loss=0.30855676531791687
[10/24] Train loss=0.342794269323349
[15/24] Train loss=0.2691657245159149
[20/24] Train loss=0.2755354940891266
Test set avg_accuracy=83.44% avg_sensitivity=44.65%, avg_specificity=96.66% avg_auc=86.34%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.304685 Test loss=0.406841 Current lr=[0.000298904600941902]

[0/24] Train loss=0.32653379440307617
[5/24] Train loss=0.3055103123188019
[10/24] Train loss=0.35622304677963257
[15/24] Train loss=0.271696537733078
[20/24] Train loss=0.2867582440376282
Test set avg_accuracy=81.20% avg_sensitivity=31.64%, avg_specificity=98.10% avg_auc=83.08%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.305348 Test loss=0.493719 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3183184564113617
[5/24] Train loss=0.2949896454811096
[10/24] Train loss=0.336944580078125
[15/24] Train loss=0.28842106461524963
[20/24] Train loss=0.26800164580345154
Test set avg_accuracy=76.51% avg_sensitivity=8.86%, avg_specificity=99.58% avg_auc=80.85%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.305669 Test loss=0.575486 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3344920575618744
[5/24] Train loss=0.3014897108078003
[10/24] Train loss=0.3299928307533264
[15/24] Train loss=0.28239905834198
[20/24] Train loss=0.2687190771102905
Test set avg_accuracy=78.55% avg_sensitivity=18.64%, avg_specificity=98.99% avg_auc=81.14%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.300142 Test loss=0.519318 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.32101431488990784
[5/24] Train loss=0.2830362915992737
[10/24] Train loss=0.3427790403366089
[15/24] Train loss=0.27526628971099854
[20/24] Train loss=0.27918657660484314
Test set avg_accuracy=81.91% avg_sensitivity=37.94%, avg_specificity=96.91% avg_auc=83.40%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.302981 Test loss=0.447870 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.31160128116607666
[5/24] Train loss=0.29971182346343994
[10/24] Train loss=0.3174237310886383
[15/24] Train loss=0.272379606962204
[20/24] Train loss=0.27658843994140625
Test set avg_accuracy=83.03% avg_sensitivity=40.50%, avg_specificity=97.54% avg_auc=85.52%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.295105 Test loss=0.421905 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.30360281467437744
[5/24] Train loss=0.2980011999607086
[10/24] Train loss=0.33144286274909973
[15/24] Train loss=0.26045292615890503
[20/24] Train loss=0.2678896188735962
Test set avg_accuracy=78.18% avg_sensitivity=17.26%, avg_specificity=98.95% avg_auc=69.72%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.290947 Test loss=0.598357 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2947055995464325
[5/24] Train loss=0.2857682704925537
[10/24] Train loss=0.32220014929771423
[15/24] Train loss=0.2698724865913391
[20/24] Train loss=0.2639518678188324
Test set avg_accuracy=80.42% avg_sensitivity=27.96%, avg_specificity=98.31% avg_auc=83.02%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.290780 Test loss=0.484929 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3040376305580139
[5/24] Train loss=0.277647465467453
[10/24] Train loss=0.32130637764930725
[15/24] Train loss=0.24659587442874908
[20/24] Train loss=0.26199424266815186
Test set avg_accuracy=81.50% avg_sensitivity=33.85%, avg_specificity=97.75% avg_auc=85.70%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.287953 Test loss=0.419053 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.28657111525535583
[5/24] Train loss=0.28530845046043396
[10/24] Train loss=0.3326224088668823
[15/24] Train loss=0.25989943742752075
[20/24] Train loss=0.2672358751296997
Test set avg_accuracy=85.09% avg_sensitivity=56.27%, avg_specificity=94.92% avg_auc=89.11%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.287734 Test loss=0.349449 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.29042258858680725
[5/24] Train loss=0.2829750180244446
[10/24] Train loss=0.32053473591804504
[15/24] Train loss=0.2601170241832733
[20/24] Train loss=0.2591449022293091
Test set avg_accuracy=83.91% avg_sensitivity=66.31%, avg_specificity=89.91% avg_auc=87.32%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.285148 Test loss=0.379989 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2865273952484131
[5/24] Train loss=0.28326696157455444
[10/24] Train loss=0.3102967143058777
[15/24] Train loss=0.252097487449646
[20/24] Train loss=0.2701968252658844
Test set avg_accuracy=85.42% avg_sensitivity=57.30%, avg_specificity=95.01% avg_auc=89.19%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.285988 Test loss=0.348679 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2847406268119812
[5/24] Train loss=0.27502453327178955
[10/24] Train loss=0.3221457898616791
[15/24] Train loss=0.24284888803958893
[20/24] Train loss=0.2687654495239258
Test set avg_accuracy=83.41% avg_sensitivity=46.70%, avg_specificity=95.93% avg_auc=86.73%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.280003 Test loss=0.388603 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2861863672733307
[5/24] Train loss=0.2811536192893982
[10/24] Train loss=0.31251782178878784
[15/24] Train loss=0.2544807493686676
[20/24] Train loss=0.27014127373695374
Test set avg_accuracy=83.12% avg_sensitivity=64.67%, avg_specificity=89.42% avg_auc=87.19%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.277711 Test loss=0.380847 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2787724733352661
[5/24] Train loss=0.2660103440284729
[10/24] Train loss=0.3113410174846649
[15/24] Train loss=0.2615329623222351
[20/24] Train loss=0.26598241925239563
Test set avg_accuracy=78.58% avg_sensitivity=17.82%, avg_specificity=99.30% avg_auc=77.56%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.279642 Test loss=0.590709 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2756222188472748
[5/24] Train loss=0.2901543974876404
[10/24] Train loss=0.31036314368247986
[15/24] Train loss=0.2691333591938019
[20/24] Train loss=0.2572418749332428
Test set avg_accuracy=77.94% avg_sensitivity=16.59%, avg_specificity=98.87% avg_auc=80.83%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.281630 Test loss=0.542085 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3020838499069214
[5/24] Train loss=0.2798186242580414
[10/24] Train loss=0.294445276260376
[15/24] Train loss=0.24185122549533844
[20/24] Train loss=0.2695080637931824
Test set avg_accuracy=81.22% avg_sensitivity=32.67%, avg_specificity=97.78% avg_auc=81.83%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.277903 Test loss=0.454775 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.2872444689273834
[5/24] Train loss=0.2782590389251709
[10/24] Train loss=0.303300142288208
[15/24] Train loss=0.2429584413766861
[20/24] Train loss=0.2479526847600937
Test set avg_accuracy=83.74% avg_sensitivity=45.37%, avg_specificity=96.82% avg_auc=88.36%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.272357 Test loss=0.372013 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.269641250371933
[5/24] Train loss=0.2730676531791687
[10/24] Train loss=0.3214119076728821
[15/24] Train loss=0.25671762228012085
[20/24] Train loss=0.2805275619029999
Test set avg_accuracy=82.40% avg_sensitivity=46.29%, avg_specificity=94.71% avg_auc=83.02%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.273618 Test loss=0.427438 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.29262274503707886
[5/24] Train loss=0.26376718282699585
[10/24] Train loss=0.3019820749759674
[15/24] Train loss=0.24297067523002625
[20/24] Train loss=0.25210249423980713
Test set avg_accuracy=84.04% avg_sensitivity=52.94%, avg_specificity=94.64% avg_auc=85.94%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.272085 Test loss=0.386114 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2909621000289917
[5/24] Train loss=0.26722460985183716
[10/24] Train loss=0.30739396810531616
[15/24] Train loss=0.23346419632434845
[20/24] Train loss=0.23817791044712067
Test set avg_accuracy=80.91% avg_sensitivity=68.51%, avg_specificity=85.14% avg_auc=85.23%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.267413 Test loss=0.426129 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2799893319606781
[5/24] Train loss=0.2616230845451355
[10/24] Train loss=0.2909300625324249
[15/24] Train loss=0.2325500249862671
[20/24] Train loss=0.2539161145687103
Test set avg_accuracy=83.71% avg_sensitivity=65.64%, avg_specificity=89.87% avg_auc=87.37%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.264697 Test loss=0.379043 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.2716936767101288
[5/24] Train loss=0.2603486478328705
[10/24] Train loss=0.28832557797431946
[15/24] Train loss=0.23522591590881348
[20/24] Train loss=0.25393128395080566
Test set avg_accuracy=82.80% avg_sensitivity=47.57%, avg_specificity=94.81% avg_auc=83.18%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.265585 Test loss=0.413842 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.2788407802581787
[5/24] Train loss=0.27406957745552063
[10/24] Train loss=0.29106682538986206
[15/24] Train loss=0.23914848268032074
[20/24] Train loss=0.2582436203956604
Test set avg_accuracy=81.64% avg_sensitivity=56.43%, avg_specificity=90.24% avg_auc=83.47%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.268136 Test loss=0.420487 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2685091197490692
[5/24] Train loss=0.2618829011917114
[10/24] Train loss=0.2879476249217987
[15/24] Train loss=0.23249602317810059
[20/24] Train loss=0.23949512839317322
Test set avg_accuracy=80.17% avg_sensitivity=70.40%, avg_specificity=83.50% avg_auc=85.66%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.261237 Test loss=0.427376 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.26074114441871643
[5/24] Train loss=0.26483163237571716
[10/24] Train loss=0.28713303804397583
[15/24] Train loss=0.24534423649311066
[20/24] Train loss=0.24711820483207703
Test set avg_accuracy=82.45% avg_sensitivity=43.22%, avg_specificity=95.83% avg_auc=83.77%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.262197 Test loss=0.419878 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.26874908804893494
[5/24] Train loss=0.245123952627182
[10/24] Train loss=0.28826016187667847
[15/24] Train loss=0.23081074655056
[20/24] Train loss=0.2450515180826187
Test set avg_accuracy=83.89% avg_sensitivity=54.99%, avg_specificity=93.75% avg_auc=86.25%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.259561 Test loss=0.383911 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.26923251152038574
[5/24] Train loss=0.25197017192840576
[10/24] Train loss=0.3018980920314789
[15/24] Train loss=0.23846980929374695
[20/24] Train loss=0.24906492233276367
Test set avg_accuracy=81.35% avg_sensitivity=32.62%, avg_specificity=97.97% avg_auc=80.39%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.260789 Test loss=0.502593 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.28750312328338623
[5/24] Train loss=0.24839624762535095
[10/24] Train loss=0.270372599363327
[15/24] Train loss=0.22475294768810272
[20/24] Train loss=0.23654519021511078
Test set avg_accuracy=85.18% avg_sensitivity=63.44%, avg_specificity=92.60% avg_auc=88.51%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.252077 Test loss=0.352053 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.27148956060409546
[5/24] Train loss=0.24992266297340393
[10/24] Train loss=0.28400954604148865
[15/24] Train loss=0.2370675951242447
[20/24] Train loss=0.24951496720314026
Test set avg_accuracy=83.70% avg_sensitivity=59.34%, avg_specificity=92.00% avg_auc=87.44%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.254095 Test loss=0.370604 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2744848132133484
[5/24] Train loss=0.25447243452072144
[10/24] Train loss=0.27198526263237
[15/24] Train loss=0.22271734476089478
[20/24] Train loss=0.23322461545467377
Test set avg_accuracy=84.79% avg_sensitivity=66.87%, avg_specificity=90.90% avg_auc=88.67%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.246376 Test loss=0.358587 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.24713154137134552
[5/24] Train loss=0.24848532676696777
[10/24] Train loss=0.2638920545578003
[15/24] Train loss=0.22105136513710022
[20/24] Train loss=0.2367018461227417
Test set avg_accuracy=84.06% avg_sensitivity=72.20%, avg_specificity=88.11% avg_auc=89.36%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.241349 Test loss=0.359562 Current lr=[0.000224838296036774]

[0/24] Train loss=0.24138982594013214
[5/24] Train loss=0.24796605110168457
[10/24] Train loss=0.27229180932044983
[15/24] Train loss=0.2225772589445114
[20/24] Train loss=0.23818756639957428
Test set avg_accuracy=84.24% avg_sensitivity=64.21%, avg_specificity=91.08% avg_auc=87.46%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.245263 Test loss=0.373675 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2509356439113617
[5/24] Train loss=0.2288341373205185
[10/24] Train loss=0.2621709108352661
[15/24] Train loss=0.2242063581943512
[20/24] Train loss=0.23966802656650543
Test set avg_accuracy=82.66% avg_sensitivity=72.56%, avg_specificity=86.10% avg_auc=88.33%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.242681 Test loss=0.388044 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.24915668368339539
[5/24] Train loss=0.2405158430337906
[10/24] Train loss=0.2624872326850891
[15/24] Train loss=0.2155607044696808
[20/24] Train loss=0.24425029754638672
Test set avg_accuracy=83.55% avg_sensitivity=69.84%, avg_specificity=88.23% avg_auc=88.68%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.244792 Test loss=0.375145 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.24465347826480865
[5/24] Train loss=0.23108114302158356
[10/24] Train loss=0.254632830619812
[15/24] Train loss=0.21873532235622406
[20/24] Train loss=0.2392471432685852
Test set avg_accuracy=84.83% avg_sensitivity=66.41%, avg_specificity=91.11% avg_auc=88.24%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.241189 Test loss=0.361592 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.23980459570884705
[5/24] Train loss=0.23814739286899567
[10/24] Train loss=0.25960415601730347
[15/24] Train loss=0.20568911731243134
[20/24] Train loss=0.22617462277412415
Test set avg_accuracy=84.95% avg_sensitivity=66.26%, avg_specificity=91.32% avg_auc=87.85%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.235677 Test loss=0.361925 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.23072370886802673
[5/24] Train loss=0.21529605984687805
[10/24] Train loss=0.2497885376214981
[15/24] Train loss=0.20323485136032104
[20/24] Train loss=0.2193569839000702
Test set avg_accuracy=84.41% avg_sensitivity=62.57%, avg_specificity=91.86% avg_auc=88.16%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.228525 Test loss=0.366937 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.23714864253997803
[5/24] Train loss=0.21677473187446594
[10/24] Train loss=0.25069496035575867
[15/24] Train loss=0.22528786957263947
[20/24] Train loss=0.23894886672496796
Test set avg_accuracy=83.62% avg_sensitivity=67.95%, avg_specificity=88.96% avg_auc=87.61%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.230493 Test loss=0.388165 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2371121197938919
[5/24] Train loss=0.22847971320152283
[10/24] Train loss=0.25282934308052063
[15/24] Train loss=0.22220216691493988
[20/24] Train loss=0.23115193843841553
Test set avg_accuracy=83.61% avg_sensitivity=54.89%, avg_specificity=93.40% avg_auc=85.96%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.232789 Test loss=0.407273 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.22612304985523224
[5/24] Train loss=0.21346820890903473
[10/24] Train loss=0.2440970540046692
[15/24] Train loss=0.21219052374362946
[20/24] Train loss=0.21962252259254456
Test set avg_accuracy=83.33% avg_sensitivity=69.02%, avg_specificity=88.21% avg_auc=88.25%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.225868 Test loss=0.377115 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.22558729350566864
[5/24] Train loss=0.2031797617673874
[10/24] Train loss=0.23956306278705597
[15/24] Train loss=0.20349115133285522
[20/24] Train loss=0.2150157243013382
Test set avg_accuracy=83.93% avg_sensitivity=58.63%, avg_specificity=92.56% avg_auc=86.56%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.223461 Test loss=0.383429 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.22801421582698822
[5/24] Train loss=0.2144913673400879
[10/24] Train loss=0.23376774787902832
[15/24] Train loss=0.20896154642105103
[20/24] Train loss=0.21574334800243378
Test set avg_accuracy=85.01% avg_sensitivity=60.57%, avg_specificity=93.35% avg_auc=88.20%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.222385 Test loss=0.362173 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.22797250747680664
[5/24] Train loss=0.22510574758052826
[10/24] Train loss=0.22690770030021667
[15/24] Train loss=0.20258797705173492
[20/24] Train loss=0.2280917912721634
Test set avg_accuracy=83.07% avg_sensitivity=47.00%, avg_specificity=95.37% avg_auc=83.94%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.220351 Test loss=0.427286 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.23278675973415375
[5/24] Train loss=0.21731765568256378
[10/24] Train loss=0.23877765238285065
[15/24] Train loss=0.19653910398483276
[20/24] Train loss=0.20621022582054138
Test set avg_accuracy=83.98% avg_sensitivity=54.33%, avg_specificity=94.10% avg_auc=86.03%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.216993 Test loss=0.397900 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2141847014427185
[5/24] Train loss=0.20315517485141754
[10/24] Train loss=0.2319437712430954
[15/24] Train loss=0.18921621143817902
[20/24] Train loss=0.20175907015800476
Test set avg_accuracy=83.39% avg_sensitivity=45.21%, avg_specificity=96.40% avg_auc=82.77%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.209681 Test loss=0.425517 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.23486186563968658
[5/24] Train loss=0.20643118023872375
[10/24] Train loss=0.2254153937101364
[15/24] Train loss=0.1895703673362732
[20/24] Train loss=0.21577537059783936
Test set avg_accuracy=84.10% avg_sensitivity=52.18%, avg_specificity=94.99% avg_auc=85.23%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.209976 Test loss=0.392674 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.21378636360168457
[5/24] Train loss=0.1900758594274521
[10/24] Train loss=0.21366184949874878
[15/24] Train loss=0.19686925411224365
[20/24] Train loss=0.20407947897911072
Test set avg_accuracy=84.44% avg_sensitivity=57.19%, avg_specificity=93.73% avg_auc=86.27%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.207288 Test loss=0.384386 Current lr=[0.000156543481933168]

[0/24] Train loss=0.21928168833255768
[5/24] Train loss=0.19092828035354614
[10/24] Train loss=0.21505966782569885
[15/24] Train loss=0.1882859617471695
[20/24] Train loss=0.20596273243427277
Test set avg_accuracy=84.40% avg_sensitivity=53.71%, avg_specificity=94.87% avg_auc=85.56%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.204522 Test loss=0.390574 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.21068567037582397
[5/24] Train loss=0.20329943299293518
[10/24] Train loss=0.21549072861671448
[15/24] Train loss=0.18420922756195068
[20/24] Train loss=0.2029414176940918
Test set avg_accuracy=84.38% avg_sensitivity=63.90%, avg_specificity=91.36% avg_auc=86.41%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.203214 Test loss=0.391023 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.21264301240444183
[5/24] Train loss=0.1965320110321045
[10/24] Train loss=0.21174320578575134
[15/24] Train loss=0.18187202513217926
[20/24] Train loss=0.19219695031642914
Test set avg_accuracy=83.05% avg_sensitivity=44.75%, avg_specificity=96.11% avg_auc=82.60%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.200348 Test loss=0.444287 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.21488547325134277
[5/24] Train loss=0.1938244253396988
[10/24] Train loss=0.2035757154226303
[15/24] Train loss=0.1837378740310669
[20/24] Train loss=0.19259628653526306
Test set avg_accuracy=83.62% avg_sensitivity=51.20%, avg_specificity=94.67% avg_auc=85.43%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.196406 Test loss=0.407244 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1918393224477768
[5/24] Train loss=0.20317043364048004
[10/24] Train loss=0.1977372020483017
[15/24] Train loss=0.1798802614212036
[20/24] Train loss=0.19353550672531128
Test set avg_accuracy=82.36% avg_sensitivity=54.99%, avg_specificity=91.69% avg_auc=84.17%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.196810 Test loss=0.423020 Current lr=[0.000134135431043539]

[0/24] Train loss=0.2079082578420639
[5/24] Train loss=0.19166554510593414
[10/24] Train loss=0.20335881412029266
[15/24] Train loss=0.175462543964386
[20/24] Train loss=0.1928006261587143
Test set avg_accuracy=84.66% avg_sensitivity=62.11%, avg_specificity=92.35% avg_auc=86.64%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.195824 Test loss=0.385041 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.19457678496837616
[5/24] Train loss=0.18977861106395721
[10/24] Train loss=0.19100455939769745
[15/24] Train loss=0.17784518003463745
[20/24] Train loss=0.19035904109477997
Test set avg_accuracy=84.48% avg_sensitivity=61.75%, avg_specificity=92.23% avg_auc=86.00%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.190466 Test loss=0.385460 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.18999281525611877
[5/24] Train loss=0.1746395230293274
[10/24] Train loss=0.19449323415756226
[15/24] Train loss=0.17924894392490387
[20/24] Train loss=0.18934060633182526
Test set avg_accuracy=85.25% avg_sensitivity=61.03%, avg_specificity=93.50% avg_auc=86.88%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.187807 Test loss=0.377023 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.19170908629894257
[5/24] Train loss=0.1729326695203781
[10/24] Train loss=0.19251564145088196
[15/24] Train loss=0.17898572981357574
[20/24] Train loss=0.17606577277183533
Test set avg_accuracy=83.03% avg_sensitivity=54.84%, avg_specificity=92.65% avg_auc=82.85%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.183924 Test loss=0.429801 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1896851360797882
[5/24] Train loss=0.17978860437870026
[10/24] Train loss=0.19362293183803558
[15/24] Train loss=0.17286908626556396
[20/24] Train loss=0.1883188933134079
Test set avg_accuracy=83.92% avg_sensitivity=54.69%, avg_specificity=93.89% avg_auc=86.10%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.185232 Test loss=0.394707 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1938219517469406
[5/24] Train loss=0.17648081481456757
[10/24] Train loss=0.1898733377456665
[15/24] Train loss=0.18293122947216034
[20/24] Train loss=0.18335135281085968
Test set avg_accuracy=84.86% avg_sensitivity=56.07%, avg_specificity=94.67% avg_auc=86.17%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.184268 Test loss=0.389730 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.19132257997989655
[5/24] Train loss=0.17105329036712646
[10/24] Train loss=0.18634285032749176
[15/24] Train loss=0.16967618465423584
[20/24] Train loss=0.1785745769739151
Test set avg_accuracy=83.80% avg_sensitivity=47.82%, avg_specificity=96.07% avg_auc=83.63%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.180906 Test loss=0.425550 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.19191597402095795
[5/24] Train loss=0.16882413625717163
[10/24] Train loss=0.18780866265296936
[15/24] Train loss=0.16660411655902863
[20/24] Train loss=0.17358922958374023
Test set avg_accuracy=84.04% avg_sensitivity=56.32%, avg_specificity=93.49% avg_auc=84.67%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.180318 Test loss=0.408777 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.18185339868068695
[5/24] Train loss=0.17213493585586548
[10/24] Train loss=0.18170349299907684
[15/24] Train loss=0.16378194093704224
[20/24] Train loss=0.1768816113471985
Test set avg_accuracy=84.86% avg_sensitivity=66.56%, avg_specificity=91.09% avg_auc=87.66%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.175886 Test loss=0.378731 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.19051478803157806
[5/24] Train loss=0.17502054572105408
[10/24] Train loss=0.17486035823822021
[15/24] Train loss=0.16724145412445068
[20/24] Train loss=0.17375364899635315
Test set avg_accuracy=83.39% avg_sensitivity=63.39%, avg_specificity=90.20% avg_auc=87.05%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.174329 Test loss=0.391173 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1767043173313141
[5/24] Train loss=0.16658617556095123
[10/24] Train loss=0.17721259593963623
[15/24] Train loss=0.16097837686538696
[20/24] Train loss=0.17153896391391754
Test set avg_accuracy=83.91% avg_sensitivity=66.51%, avg_specificity=89.84% avg_auc=87.57%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.173634 Test loss=0.377490 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.18186520040035248
[5/24] Train loss=0.16447938978672028
[10/24] Train loss=0.16938163340091705
[15/24] Train loss=0.15914295613765717
[20/24] Train loss=0.1629614531993866
Test set avg_accuracy=85.21% avg_sensitivity=67.18%, avg_specificity=91.36% avg_auc=88.03%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.168018 Test loss=0.373840 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.17672190070152283
[5/24] Train loss=0.1579938679933548
[10/24] Train loss=0.1721286028623581
[15/24] Train loss=0.15591514110565186
[20/24] Train loss=0.16008491814136505
Test set avg_accuracy=84.41% avg_sensitivity=68.10%, avg_specificity=89.98% avg_auc=87.70%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.165004 Test loss=0.382461 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.17142018675804138
[5/24] Train loss=0.15717606246471405
[10/24] Train loss=0.17167524993419647
[15/24] Train loss=0.15621334314346313
[20/24] Train loss=0.15732130408287048
Test set avg_accuracy=84.92% avg_sensitivity=69.38%, avg_specificity=90.22% avg_auc=88.77%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.164136 Test loss=0.365339 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1725967675447464
[5/24] Train loss=0.14974437654018402
[10/24] Train loss=0.16128259897232056
[15/24] Train loss=0.15405432879924774
[20/24] Train loss=0.16050127148628235
Test set avg_accuracy=84.21% avg_sensitivity=68.36%, avg_specificity=89.61% avg_auc=88.39%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.161054 Test loss=0.376290 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.17504101991653442
[5/24] Train loss=0.15253010392189026
[10/24] Train loss=0.1595955640077591
[15/24] Train loss=0.1490222066640854
[20/24] Train loss=0.1561659872531891
Test set avg_accuracy=83.74% avg_sensitivity=71.63%, avg_specificity=87.86% avg_auc=88.72%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.159394 Test loss=0.380942 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.171167254447937
[5/24] Train loss=0.15703123807907104
[10/24] Train loss=0.1568128615617752
[15/24] Train loss=0.14702099561691284
[20/24] Train loss=0.15458610653877258
Test set avg_accuracy=84.28% avg_sensitivity=66.92%, avg_specificity=90.20% avg_auc=87.33%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.158072 Test loss=0.389342 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1693611592054367
[5/24] Train loss=0.14805381000041962
[10/24] Train loss=0.1540331244468689
[15/24] Train loss=0.14842063188552856
[20/24] Train loss=0.1551494300365448
Test set avg_accuracy=84.26% avg_sensitivity=67.95%, avg_specificity=89.82% avg_auc=87.70%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.156286 Test loss=0.382351 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.16471652686595917
[5/24] Train loss=0.1509259045124054
[10/24] Train loss=0.15519842505455017
[15/24] Train loss=0.14659301936626434
[20/24] Train loss=0.15279105305671692
Test set avg_accuracy=84.04% avg_sensitivity=68.15%, avg_specificity=89.45% avg_auc=87.74%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.154350 Test loss=0.381477 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.16443222761154175
[5/24] Train loss=0.1455727368593216
[10/24] Train loss=0.15439914166927338
[15/24] Train loss=0.14618681371212006
[20/24] Train loss=0.1526317298412323
Test set avg_accuracy=84.60% avg_sensitivity=64.36%, avg_specificity=91.50% avg_auc=87.31%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.151870 Test loss=0.383367 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.16060486435890198
[5/24] Train loss=0.14914259314537048
[10/24] Train loss=0.15086022019386292
[15/24] Train loss=0.14356158673763275
[20/24] Train loss=0.1490430235862732
Test set avg_accuracy=84.91% avg_sensitivity=64.21%, avg_specificity=91.97% avg_auc=87.69%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.150450 Test loss=0.372895 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1596655398607254
[5/24] Train loss=0.14188598096370697
[10/24] Train loss=0.14620821177959442
[15/24] Train loss=0.1415492743253708
[20/24] Train loss=0.14291390776634216
Test set avg_accuracy=85.04% avg_sensitivity=62.01%, avg_specificity=92.89% avg_auc=86.46%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.148048 Test loss=0.382870 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.15781547129154205
[5/24] Train loss=0.14280346035957336
[10/24] Train loss=0.14388376474380493
[15/24] Train loss=0.13822434842586517
[20/24] Train loss=0.14291059970855713
Test set avg_accuracy=84.57% avg_sensitivity=65.39%, avg_specificity=91.11% avg_auc=87.45%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.146123 Test loss=0.377514 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.15096156299114227
[5/24] Train loss=0.14109139144420624
[10/24] Train loss=0.1430787742137909
[15/24] Train loss=0.13694220781326294
[20/24] Train loss=0.14175833761692047
Test set avg_accuracy=84.97% avg_sensitivity=64.36%, avg_specificity=92.00% avg_auc=87.47%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.145479 Test loss=0.373570 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.15156088769435883
[5/24] Train loss=0.13952100276947021
[10/24] Train loss=0.14570151269435883
[15/24] Train loss=0.1367926448583603
[20/24] Train loss=0.1396723836660385
Test set avg_accuracy=84.77% avg_sensitivity=64.06%, avg_specificity=91.83% avg_auc=87.53%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.142873 Test loss=0.373300 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1561499834060669
[5/24] Train loss=0.13615600764751434
[10/24] Train loss=0.14213839173316956
[15/24] Train loss=0.1379292607307434
[20/24] Train loss=0.1391666829586029
Test set avg_accuracy=84.90% avg_sensitivity=63.80%, avg_specificity=92.09% avg_auc=87.71%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.142500 Test loss=0.371921 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.15619681775569916
[5/24] Train loss=0.14020974934101105
[10/24] Train loss=0.14067193865776062
[15/24] Train loss=0.133609801530838
[20/24] Train loss=0.13615980744361877
Test set avg_accuracy=84.38% avg_sensitivity=67.33%, avg_specificity=90.19% avg_auc=87.88%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.142134 Test loss=0.379823 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.15033765137195587
[5/24] Train loss=0.1350957453250885
[10/24] Train loss=0.13767623901367188
[15/24] Train loss=0.1320381760597229
[20/24] Train loss=0.1360069364309311
Test set avg_accuracy=84.93% avg_sensitivity=64.46%, avg_specificity=91.92% avg_auc=87.81%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.140267 Test loss=0.371605 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1482909619808197
[5/24] Train loss=0.13432316482067108
[10/24] Train loss=0.14095740020275116
[15/24] Train loss=0.13375186920166016
[20/24] Train loss=0.1395496428012848
Test set avg_accuracy=84.73% avg_sensitivity=63.95%, avg_specificity=91.81% avg_auc=87.30%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.140160 Test loss=0.376955 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.15403713285923004
[5/24] Train loss=0.1388780176639557
[10/24] Train loss=0.14142437279224396
[15/24] Train loss=0.13164538145065308
[20/24] Train loss=0.13911443948745728
Test set avg_accuracy=84.08% avg_sensitivity=63.70%, avg_specificity=91.02% avg_auc=86.50%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.140330 Test loss=0.388863 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.14808443188667297
[5/24] Train loss=0.1336023211479187
[10/24] Train loss=0.13774046301841736
[15/24] Train loss=0.13218027353286743
[20/24] Train loss=0.13868169486522675
Test set avg_accuracy=84.34% avg_sensitivity=67.28%, avg_specificity=90.15% avg_auc=87.71%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.138678 Test loss=0.379228 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1464810073375702
[5/24] Train loss=0.13318035006523132
[10/24] Train loss=0.13807331025600433
[15/24] Train loss=0.12951724231243134
[20/24] Train loss=0.13297885656356812
Test set avg_accuracy=84.82% avg_sensitivity=66.10%, avg_specificity=91.20% avg_auc=88.03%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.137379 Test loss=0.372795 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1486780047416687
[5/24] Train loss=0.1323121041059494
[10/24] Train loss=0.13632333278656006
[15/24] Train loss=0.12832948565483093
[20/24] Train loss=0.132759228348732
Test set avg_accuracy=84.78% avg_sensitivity=65.54%, avg_specificity=91.34% avg_auc=87.80%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.136401 Test loss=0.376185 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1484321653842926
[5/24] Train loss=0.1313910037279129
[10/24] Train loss=0.13795176148414612
[15/24] Train loss=0.130194291472435
[20/24] Train loss=0.13707444071769714
Test set avg_accuracy=84.53% avg_sensitivity=66.10%, avg_specificity=90.82% avg_auc=87.69%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.136240 Test loss=0.376670 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1462455838918686
[5/24] Train loss=0.13263235986232758
[10/24] Train loss=0.13460318744182587
[15/24] Train loss=0.12853239476680756
[20/24] Train loss=0.1329990029335022
Test set avg_accuracy=84.58% avg_sensitivity=65.44%, avg_specificity=91.11% avg_auc=87.58%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.135648 Test loss=0.379839 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.14511485397815704
[5/24] Train loss=0.12998522818088531
[10/24] Train loss=0.13307051360607147
[15/24] Train loss=0.13011042773723602
[20/24] Train loss=0.13285930454730988
Test set avg_accuracy=84.32% avg_sensitivity=66.00%, avg_specificity=90.57% avg_auc=87.93%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.134773 Test loss=0.376189 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.143506720662117
[5/24] Train loss=0.12889787554740906
[10/24] Train loss=0.13387390971183777
[15/24] Train loss=0.13119617104530334
[20/24] Train loss=0.13023641705513
Test set avg_accuracy=84.58% avg_sensitivity=65.18%, avg_specificity=91.20% avg_auc=87.39%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.134883 Test loss=0.380480 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.14308783411979675
[5/24] Train loss=0.13431581854820251
[10/24] Train loss=0.13412466645240784
[15/24] Train loss=0.1285945475101471
[20/24] Train loss=0.13064539432525635
Test set avg_accuracy=84.66% avg_sensitivity=65.85%, avg_specificity=91.08% avg_auc=87.76%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.134298 Test loss=0.376588 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.14606791734695435
[5/24] Train loss=0.12853586673736572
[10/24] Train loss=0.13217034935951233
[15/24] Train loss=0.1282394379377365
[20/24] Train loss=0.12914641201496124
Test set avg_accuracy=84.36% avg_sensitivity=65.85%, avg_specificity=90.68% avg_auc=87.77%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.133591 Test loss=0.377257 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.14190685749053955
[5/24] Train loss=0.1296190321445465
[10/24] Train loss=0.13101907074451447
[15/24] Train loss=0.1259162724018097
[20/24] Train loss=0.13131459057331085
Test set avg_accuracy=84.30% avg_sensitivity=65.08%, avg_specificity=90.85% avg_auc=87.64%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.133440 Test loss=0.378944 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.14469420909881592
[5/24] Train loss=0.12709520757198334
[10/24] Train loss=0.13072852790355682
[15/24] Train loss=0.1276770830154419
[20/24] Train loss=0.13419124484062195
Test set avg_accuracy=84.40% avg_sensitivity=65.49%, avg_specificity=90.85% avg_auc=87.68%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.133400 Test loss=0.378986 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.14034777879714966
[5/24] Train loss=0.12899696826934814
[10/24] Train loss=0.13108418881893158
[15/24] Train loss=0.12688925862312317
[20/24] Train loss=0.13067811727523804
Test set avg_accuracy=84.44% avg_sensitivity=65.54%, avg_specificity=90.89% avg_auc=87.73%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.132687 Test loss=0.377416 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1431867927312851
[5/24] Train loss=0.12743918597698212
[10/24] Train loss=0.13269926607608795
[15/24] Train loss=0.12653204798698425
[20/24] Train loss=0.1305684596300125
Test set avg_accuracy=84.48% avg_sensitivity=65.44%, avg_specificity=90.97% avg_auc=87.62%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.132661 Test loss=0.379043 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1446227729320526
[5/24] Train loss=0.1278357356786728
[10/24] Train loss=0.12936052680015564
[15/24] Train loss=0.12675929069519043
[20/24] Train loss=0.13069194555282593
Test set avg_accuracy=84.39% avg_sensitivity=65.59%, avg_specificity=90.80% avg_auc=87.72%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.132715 Test loss=0.378152 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13998572528362274
[5/24] Train loss=0.1268846094608307
[10/24] Train loss=0.13036958873271942
[15/24] Train loss=0.12498676776885986
[20/24] Train loss=0.13275273144245148
Test set avg_accuracy=84.60% avg_sensitivity=65.64%, avg_specificity=91.06% avg_auc=87.72%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.132453 Test loss=0.377461 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.14425034821033478
[5/24] Train loss=0.1269824206829071
[10/24] Train loss=0.13188616931438446
[15/24] Train loss=0.1282104104757309
[20/24] Train loss=0.13098256289958954
Test set avg_accuracy=84.49% avg_sensitivity=65.69%, avg_specificity=90.90% avg_auc=87.73%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.133226 Test loss=0.377590 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.14324423670768738
[5/24] Train loss=0.12838131189346313
[10/24] Train loss=0.12992510199546814
[15/24] Train loss=0.12488900870084763
[20/24] Train loss=0.13113422691822052
Test set avg_accuracy=84.51% avg_sensitivity=65.49%, avg_specificity=90.99% avg_auc=87.72%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.132438 Test loss=0.377485 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.14040975272655487
[5/24] Train loss=0.12845949828624725
[10/24] Train loss=0.13319867849349976
[15/24] Train loss=0.12727364897727966
[20/24] Train loss=0.13273130357265472
Test set avg_accuracy=84.53% avg_sensitivity=65.64%, avg_specificity=90.97% avg_auc=87.74%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.131944 Test loss=0.377552 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.14185963571071625
[5/24] Train loss=0.12895484268665314
[10/24] Train loss=0.13105395436286926
[15/24] Train loss=0.1260485053062439
[20/24] Train loss=0.13361215591430664
Test set avg_accuracy=84.57% avg_sensitivity=65.90%, avg_specificity=90.94% avg_auc=87.74%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.132521 Test loss=0.377469 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=85.25% sen=68.46%, spe=90.97%, auc=90.20%!
Fold[5] Avg_overlap=0.08%(±0.1739847910831208)
[0/24] Train loss=0.7383324503898621
[5/24] Train loss=0.7260789275169373
[10/24] Train loss=0.7264711260795593
[15/24] Train loss=0.7176165580749512
[20/24] Train loss=0.704232394695282
Test set avg_accuracy=61.33% avg_sensitivity=41.27%, avg_specificity=68.80% avg_auc=57.98%
Best model saved!! Metric=-96.62576412288597!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.720624 Test loss=0.660683 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.695228099822998
[5/24] Train loss=0.6930314302444458
[10/24] Train loss=0.6927746534347534
[15/24] Train loss=0.6840559840202332
[20/24] Train loss=0.6756188869476318
Test set avg_accuracy=68.06% avg_sensitivity=53.98%, avg_specificity=73.30% avg_auc=69.11%
Best model saved!! Metric=-61.543831602907794!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.691324 Test loss=0.610806 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.676918089389801
[5/24] Train loss=0.6672093868255615
[10/24] Train loss=0.6697617173194885
[15/24] Train loss=0.6644946932792664
[20/24] Train loss=0.6581607460975647
Test set avg_accuracy=70.47% avg_sensitivity=60.17%, avg_specificity=74.30% avg_auc=73.15%
Best model saved!! Metric=-47.906356156165835!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.668376 Test loss=0.586870 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6470229625701904
[5/24] Train loss=0.640008807182312
[10/24] Train loss=0.6520933508872986
[15/24] Train loss=0.6495229601860046
[20/24] Train loss=0.6306741833686829
Test set avg_accuracy=71.82% avg_sensitivity=63.34%, avg_specificity=74.98% avg_auc=75.62%
Best model saved!! Metric=-40.23813564791504!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.648639 Test loss=0.568348 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6251627206802368
[5/24] Train loss=0.613135576248169
[10/24] Train loss=0.62836092710495
[15/24] Train loss=0.6318393349647522
[20/24] Train loss=0.6124141812324524
Test set avg_accuracy=72.75% avg_sensitivity=66.03%, avg_specificity=75.25% avg_auc=77.61%
Best model saved!! Metric=-34.36132128569464!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.626638 Test loss=0.555068 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.598314106464386
[5/24] Train loss=0.5937885642051697
[10/24] Train loss=0.6110308766365051
[15/24] Train loss=0.6058623790740967
[20/24] Train loss=0.5954408049583435
Test set avg_accuracy=73.97% avg_sensitivity=68.81%, avg_specificity=75.89% avg_auc=79.31%
Best model saved!! Metric=-28.01588531341163!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.607788 Test loss=0.539275 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5794046521186829
[5/24] Train loss=0.5768002867698669
[10/24] Train loss=0.584306538105011
[15/24] Train loss=0.5903920531272888
[20/24] Train loss=0.5660536885261536
Test set avg_accuracy=74.66% avg_sensitivity=67.66%, avg_specificity=77.27% avg_auc=80.41%
Best model saved!! Metric=-25.996132295563925!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.587237 Test loss=0.522893 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5527349710464478
[5/24] Train loss=0.5597065091133118
[10/24] Train loss=0.569830596446991
[15/24] Train loss=0.5698679685592651
[20/24] Train loss=0.5431646108627319
Test set avg_accuracy=76.85% avg_sensitivity=66.51%, avg_specificity=80.70% avg_auc=81.84%
Best model saved!! Metric=-20.10773509589154!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.566294 Test loss=0.496229 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.533112645149231
[5/24] Train loss=0.530678927898407
[10/24] Train loss=0.5443811416625977
[15/24] Train loss=0.5518396496772766
[20/24] Train loss=0.5164373517036438
Test set avg_accuracy=77.68% avg_sensitivity=67.51%, avg_specificity=81.47% avg_auc=82.81%
Best model saved!! Metric=-16.521600028662732!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.543291 Test loss=0.483649 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5133575201034546
[5/24] Train loss=0.5128133296966553
[10/24] Train loss=0.5158085227012634
[15/24] Train loss=0.5318734049797058
[20/24] Train loss=0.4982064366340637
Test set avg_accuracy=79.10% avg_sensitivity=63.20%, avg_specificity=85.03% avg_auc=83.74%
Best model saved!! Metric=-14.938768954191993!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.522171 Test loss=0.459228 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.49452877044677734
[5/24] Train loss=0.4940052330493927
[10/24] Train loss=0.4990527629852295
[15/24] Train loss=0.5152102708816528
[20/24] Train loss=0.47142475843429565
Test set avg_accuracy=79.22% avg_sensitivity=66.60%, avg_specificity=83.92% avg_auc=84.41%
Best model saved!! Metric=-11.846584918415829!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.501966 Test loss=0.454920 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.47644510865211487
[5/24] Train loss=0.47302961349487305
[10/24] Train loss=0.47954443097114563
[15/24] Train loss=0.49432387948036194
[20/24] Train loss=0.4485895037651062
Test set avg_accuracy=80.66% avg_sensitivity=61.08%, avg_specificity=87.96% avg_auc=85.06%
Best model saved!! Metric=-11.23960172273106!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.481637 Test loss=0.433430 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.461325466632843
[5/24] Train loss=0.4518865644931793
[10/24] Train loss=0.46466541290283203
[15/24] Train loss=0.4725986123085022
[20/24] Train loss=0.4339328110218048
Test set avg_accuracy=81.47% avg_sensitivity=59.31%, avg_specificity=89.72% avg_auc=85.83%
Best model saved!! Metric=-9.668101421983827!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.463164 Test loss=0.418981 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.44319745898246765
[5/24] Train loss=0.43781813979148865
[10/24] Train loss=0.45048996806144714
[15/24] Train loss=0.45938214659690857
[20/24] Train loss=0.4181576371192932
Test set avg_accuracy=81.80% avg_sensitivity=55.95%, avg_specificity=91.42% avg_auc=86.19%
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.448039 Test loss=0.411268 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4298799932003021
[5/24] Train loss=0.42660823464393616
[10/24] Train loss=0.4321855306625366
[15/24] Train loss=0.4452612102031708
[20/24] Train loss=0.3978680372238159
Test set avg_accuracy=82.41% avg_sensitivity=55.85%, avg_specificity=92.30% avg_auc=86.86%
Best model saved!! Metric=-8.57625481575701!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.432661 Test loss=0.401138 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4181974232196808
[5/24] Train loss=0.4118354320526123
[10/24] Train loss=0.42257845401763916
[15/24] Train loss=0.4364943504333496
[20/24] Train loss=0.3801833987236023
Test set avg_accuracy=82.17% avg_sensitivity=48.61%, avg_specificity=94.67% avg_auc=87.14%
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.421348 Test loss=0.399393 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4226897656917572
[5/24] Train loss=0.39442288875579834
[10/24] Train loss=0.4175777733325958
[15/24] Train loss=0.43282902240753174
[20/24] Train loss=0.37131360173225403
Test set avg_accuracy=82.01% avg_sensitivity=45.49%, avg_specificity=95.60% avg_auc=87.03%
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.411041 Test loss=0.401414 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4132504463195801
[5/24] Train loss=0.38189223408699036
[10/24] Train loss=0.41106507182121277
[15/24] Train loss=0.4171767830848694
[20/24] Train loss=0.3646543323993683
Test set avg_accuracy=82.73% avg_sensitivity=49.47%, avg_specificity=95.12% avg_auc=87.73%
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.401941 Test loss=0.389928 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.400220662355423
[5/24] Train loss=0.37570902705192566
[10/24] Train loss=0.4044385552406311
[15/24] Train loss=0.40841275453567505
[20/24] Train loss=0.3536820411682129
Test set avg_accuracy=82.03% avg_sensitivity=43.91%, avg_specificity=96.23% avg_auc=87.71%
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.393747 Test loss=0.398092 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3965500593185425
[5/24] Train loss=0.37173494696617126
[10/24] Train loss=0.39859411120414734
[15/24] Train loss=0.40047240257263184
[20/24] Train loss=0.3502318859100342
Test set avg_accuracy=83.33% avg_sensitivity=52.78%, avg_specificity=94.71% avg_auc=88.24%
Best model saved!! Metric=-6.93462986769179!!
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.387423 Test loss=0.380441 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.38131117820739746
[5/24] Train loss=0.36353635787963867
[10/24] Train loss=0.3933255672454834
[15/24] Train loss=0.40089020133018494
[20/24] Train loss=0.341598778963089
Test set avg_accuracy=82.97% avg_sensitivity=48.66%, avg_specificity=95.75% avg_auc=88.23%
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.379243 Test loss=0.385417 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.38070693612098694
[5/24] Train loss=0.354934960603714
[10/24] Train loss=0.384869784116745
[15/24] Train loss=0.3961135447025299
[20/24] Train loss=0.33868512511253357
Test set avg_accuracy=82.42% avg_sensitivity=45.97%, avg_specificity=96.00% avg_auc=88.20%
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.374476 Test loss=0.391124 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3808523416519165
[5/24] Train loss=0.3547988831996918
[10/24] Train loss=0.3902967572212219
[15/24] Train loss=0.38680973649024963
[20/24] Train loss=0.32946720719337463
Test set avg_accuracy=82.94% avg_sensitivity=49.04%, avg_specificity=95.57% avg_auc=88.31%
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.370136 Test loss=0.385276 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3715467154979706
[5/24] Train loss=0.35603588819503784
[10/24] Train loss=0.3841751217842102
[15/24] Train loss=0.3904411196708679
[20/24] Train loss=0.33061474561691284
Test set avg_accuracy=81.74% avg_sensitivity=41.79%, avg_specificity=96.62% avg_auc=88.00%
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.366072 Test loss=0.400781 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3719954490661621
[5/24] Train loss=0.346790075302124
[10/24] Train loss=0.3751636743545532
[15/24] Train loss=0.3809574246406555
[20/24] Train loss=0.3235965967178345
Test set avg_accuracy=81.95% avg_sensitivity=41.36%, avg_specificity=97.07% avg_auc=88.28%
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.364369 Test loss=0.400817 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3695070445537567
[5/24] Train loss=0.34600889682769775
[10/24] Train loss=0.37903690338134766
[15/24] Train loss=0.3807777464389801
[20/24] Train loss=0.3166833221912384
Test set avg_accuracy=81.86% avg_sensitivity=41.89%, avg_specificity=96.75% avg_auc=87.65%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.359366 Test loss=0.398040 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3704667389392853
[5/24] Train loss=0.3343678414821625
[10/24] Train loss=0.37116333842277527
[15/24] Train loss=0.3772076368331909
[20/24] Train loss=0.3183892071247101
Test set avg_accuracy=82.77% avg_sensitivity=49.18%, avg_specificity=95.28% avg_auc=88.77%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.356547 Test loss=0.376343 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3615560531616211
[5/24] Train loss=0.33395451307296753
[10/24] Train loss=0.3664136826992035
[15/24] Train loss=0.372224897146225
[20/24] Train loss=0.3124104142189026
Test set avg_accuracy=82.79% avg_sensitivity=47.17%, avg_specificity=96.05% avg_auc=89.13%
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.353050 Test loss=0.375864 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3505781292915344
[5/24] Train loss=0.32854440808296204
[10/24] Train loss=0.3638254404067993
[15/24] Train loss=0.3678804039955139
[20/24] Train loss=0.3063699007034302
Test set avg_accuracy=81.35% avg_sensitivity=37.62%, avg_specificity=97.64% avg_auc=87.49%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.348327 Test loss=0.410425 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3648839592933655
[5/24] Train loss=0.33050280809402466
[10/24] Train loss=0.37069475650787354
[15/24] Train loss=0.3709665536880493
[20/24] Train loss=0.31193530559539795
Test set avg_accuracy=80.64% avg_sensitivity=33.64%, avg_specificity=98.14% avg_auc=87.65%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.347652 Test loss=0.412389 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.354469895362854
[5/24] Train loss=0.3266851603984833
[10/24] Train loss=0.3685363829135895
[15/24] Train loss=0.3564865291118622
[20/24] Train loss=0.3068091571331024
Test set avg_accuracy=79.62% avg_sensitivity=28.45%, avg_specificity=98.68% avg_auc=86.99%
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.344992 Test loss=0.418641 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3489392101764679
[5/24] Train loss=0.3211897611618042
[10/24] Train loss=0.3653111457824707
[15/24] Train loss=0.3605499863624573
[20/24] Train loss=0.31095951795578003
Test set avg_accuracy=79.78% avg_sensitivity=29.61%, avg_specificity=98.46% avg_auc=83.77%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.340172 Test loss=0.491840 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3459993004798889
[5/24] Train loss=0.3185397684574127
[10/24] Train loss=0.3669491708278656
[15/24] Train loss=0.3419286012649536
[20/24] Train loss=0.3063620924949646
Test set avg_accuracy=80.98% avg_sensitivity=36.61%, avg_specificity=97.50% avg_auc=87.35%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.336552 Test loss=0.408637 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3360869884490967
[5/24] Train loss=0.32101428508758545
[10/24] Train loss=0.36715230345726013
[15/24] Train loss=0.3627590835094452
[20/24] Train loss=0.3052915334701538
Test set avg_accuracy=79.35% avg_sensitivity=26.54%, avg_specificity=99.02% avg_auc=86.06%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.336197 Test loss=0.442536 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.33388254046440125
[5/24] Train loss=0.31686416268348694
[10/24] Train loss=0.35020098090171814
[15/24] Train loss=0.34119513630867004
[20/24] Train loss=0.2964118421077728
Test set avg_accuracy=81.43% avg_sensitivity=39.68%, avg_specificity=96.98% avg_auc=85.82%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.328690 Test loss=0.416130 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3264370560646057
[5/24] Train loss=0.3180081248283386
[10/24] Train loss=0.359711229801178
[15/24] Train loss=0.33711233735084534
[20/24] Train loss=0.3025512099266052
Test set avg_accuracy=82.04% avg_sensitivity=40.88%, avg_specificity=97.37% avg_auc=87.58%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.328721 Test loss=0.394682 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.33239978551864624
[5/24] Train loss=0.30380529165267944
[10/24] Train loss=0.35931819677352905
[15/24] Train loss=0.34112173318862915
[20/24] Train loss=0.3032136857509613
Test set avg_accuracy=83.05% avg_sensitivity=52.88%, avg_specificity=94.28% avg_auc=87.73%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.325988 Test loss=0.380600 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.32399454712867737
[5/24] Train loss=0.3093053102493286
[10/24] Train loss=0.3516389727592468
[15/24] Train loss=0.33128899335861206
[20/24] Train loss=0.29382333159446716
Test set avg_accuracy=81.58% avg_sensitivity=41.75%, avg_specificity=96.41% avg_auc=85.70%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.321420 Test loss=0.409162 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3256710469722748
[5/24] Train loss=0.31222715973854065
[10/24] Train loss=0.36097052693367004
[15/24] Train loss=0.34427061676979065
[20/24] Train loss=0.2953561842441559
Test set avg_accuracy=79.48% avg_sensitivity=27.88%, avg_specificity=98.70% avg_auc=84.49%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.325321 Test loss=0.482360 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3254360258579254
[5/24] Train loss=0.3112489879131317
[10/24] Train loss=0.34427741169929504
[15/24] Train loss=0.34813392162323
[20/24] Train loss=0.29161983728408813
Test set avg_accuracy=81.85% avg_sensitivity=45.39%, avg_specificity=95.43% avg_auc=84.90%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.322672 Test loss=0.412519 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3223940134048462
[5/24] Train loss=0.29842740297317505
[10/24] Train loss=0.3468761742115021
[15/24] Train loss=0.3371473550796509
[20/24] Train loss=0.30756548047065735
Test set avg_accuracy=81.58% avg_sensitivity=51.20%, avg_specificity=92.89% avg_auc=84.99%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.320503 Test loss=0.414277 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3312130272388458
[5/24] Train loss=0.3079115152359009
[10/24] Train loss=0.3413781225681305
[15/24] Train loss=0.33272096514701843
[20/24] Train loss=0.29597488045692444
Test set avg_accuracy=80.55% avg_sensitivity=35.36%, avg_specificity=97.37% avg_auc=84.73%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.318830 Test loss=0.450796 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3078940212726593
[5/24] Train loss=0.30419299006462097
[10/24] Train loss=0.34661269187927246
[15/24] Train loss=0.325104296207428
[20/24] Train loss=0.3019687235355377
Test set avg_accuracy=80.98% avg_sensitivity=64.88%, avg_specificity=86.97% avg_auc=85.84%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.315980 Test loss=0.422762 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3075990378856659
[5/24] Train loss=0.28738299012184143
[10/24] Train loss=0.3340268135070801
[15/24] Train loss=0.31683123111724854
[20/24] Train loss=0.29459148645401
Test set avg_accuracy=79.86% avg_sensitivity=58.45%, avg_specificity=87.83% avg_auc=82.70%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.311464 Test loss=0.448160 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3200574815273285
[5/24] Train loss=0.2989073097705841
[10/24] Train loss=0.33104899525642395
[15/24] Train loss=0.31122857332229614
[20/24] Train loss=0.2857408821582794
Test set avg_accuracy=82.16% avg_sensitivity=49.62%, avg_specificity=94.28% avg_auc=86.26%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.309556 Test loss=0.403297 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.31813615560531616
[5/24] Train loss=0.29228752851486206
[10/24] Train loss=0.32801294326782227
[15/24] Train loss=0.32486456632614136
[20/24] Train loss=0.2990191876888275
Test set avg_accuracy=77.53% avg_sensitivity=54.56%, avg_specificity=86.08% avg_auc=79.61%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.311589 Test loss=0.472817 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3382679224014282
[5/24] Train loss=0.30192986130714417
[10/24] Train loss=0.324028342962265
[15/24] Train loss=0.32054659724235535
[20/24] Train loss=0.27560558915138245
Test set avg_accuracy=78.41% avg_sensitivity=24.66%, avg_specificity=98.43% avg_auc=81.24%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.313015 Test loss=0.527205 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3153831362724304
[5/24] Train loss=0.29167038202285767
[10/24] Train loss=0.3385026454925537
[15/24] Train loss=0.32223305106163025
[20/24] Train loss=0.272081583738327
Test set avg_accuracy=77.34% avg_sensitivity=18.62%, avg_specificity=99.21% avg_auc=79.46%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.307008 Test loss=0.554121 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.307119756937027
[5/24] Train loss=0.29227739572525024
[10/24] Train loss=0.33001983165740967
[15/24] Train loss=0.31485942006111145
[20/24] Train loss=0.2809855341911316
Test set avg_accuracy=81.85% avg_sensitivity=51.73%, avg_specificity=93.07% avg_auc=85.32%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.305434 Test loss=0.409048 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3211645781993866
[5/24] Train loss=0.282205730676651
[10/24] Train loss=0.3125477731227875
[15/24] Train loss=0.3167077600955963
[20/24] Train loss=0.2787953317165375
Test set avg_accuracy=78.76% avg_sensitivity=25.34%, avg_specificity=98.66% avg_auc=80.07%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.302144 Test loss=0.542612 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2934742271900177
[5/24] Train loss=0.2836814522743225
[10/24] Train loss=0.32022884488105774
[15/24] Train loss=0.2971426844596863
[20/24] Train loss=0.27870702743530273
Test set avg_accuracy=80.74% avg_sensitivity=41.94%, avg_specificity=95.19% avg_auc=83.36%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.298584 Test loss=0.434896 Current lr=[0.000297555943323901]

[0/24] Train loss=0.28916361927986145
[5/24] Train loss=0.2833566665649414
[10/24] Train loss=0.3086943030357361
[15/24] Train loss=0.29886594414711
[20/24] Train loss=0.2814987301826477
Test set avg_accuracy=77.55% avg_sensitivity=19.96%, avg_specificity=99.00% avg_auc=80.90%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.296982 Test loss=0.541344 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.28933748602867126
[5/24] Train loss=0.2844042181968689
[10/24] Train loss=0.32240670919418335
[15/24] Train loss=0.30325180292129517
[20/24] Train loss=0.27444565296173096
Test set avg_accuracy=81.45% avg_sensitivity=45.11%, avg_specificity=94.98% avg_auc=82.81%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.292481 Test loss=0.430628 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2863485515117645
[5/24] Train loss=0.28010886907577515
[10/24] Train loss=0.31214869022369385
[15/24] Train loss=0.2951074242591858
[20/24] Train loss=0.27995195984840393
Test set avg_accuracy=79.82% avg_sensitivity=32.15%, avg_specificity=97.57% avg_auc=84.01%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.293430 Test loss=0.433778 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.30257174372673035
[5/24] Train loss=0.29113444685935974
[10/24] Train loss=0.2944653332233429
[15/24] Train loss=0.29025229811668396
[20/24] Train loss=0.2618318498134613
Test set avg_accuracy=81.99% avg_sensitivity=43.04%, avg_specificity=96.50% avg_auc=83.86%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.294234 Test loss=0.417800 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.29034847021102905
[5/24] Train loss=0.28798988461494446
[10/24] Train loss=0.291800320148468
[15/24] Train loss=0.3031187951564789
[20/24] Train loss=0.2710755169391632
Test set avg_accuracy=80.35% avg_sensitivity=32.92%, avg_specificity=98.02% avg_auc=83.07%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.292774 Test loss=0.459872 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3097723424434662
[5/24] Train loss=0.270948588848114
[10/24] Train loss=0.3271560072898865
[15/24] Train loss=0.30447518825531006
[20/24] Train loss=0.26552268862724304
Test set avg_accuracy=80.66% avg_sensitivity=36.52%, avg_specificity=97.11% avg_auc=81.90%
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.298849 Test loss=0.443953 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.305031418800354
[5/24] Train loss=0.28391680121421814
[10/24] Train loss=0.3085014522075653
[15/24] Train loss=0.28732743859291077
[20/24] Train loss=0.26746097207069397
Test set avg_accuracy=82.34% avg_sensitivity=45.49%, avg_specificity=96.07% avg_auc=83.47%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.289459 Test loss=0.419176 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2856430113315582
[5/24] Train loss=0.26583239436149597
[10/24] Train loss=0.2996712625026703
[15/24] Train loss=0.2838371992111206
[20/24] Train loss=0.26145029067993164
Test set avg_accuracy=81.24% avg_sensitivity=36.56%, avg_specificity=97.87% avg_auc=83.65%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.282782 Test loss=0.474925 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2803519666194916
[5/24] Train loss=0.2761014997959137
[10/24] Train loss=0.2940642237663269
[15/24] Train loss=0.28327077627182007
[20/24] Train loss=0.2665597200393677
Test set avg_accuracy=79.23% avg_sensitivity=27.88%, avg_specificity=98.36% avg_auc=80.63%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.287389 Test loss=0.522145 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.28481751680374146
[5/24] Train loss=0.2566116750240326
[10/24] Train loss=0.2920995354652405
[15/24] Train loss=0.28753891587257385
[20/24] Train loss=0.26444345712661743
Test set avg_accuracy=80.36% avg_sensitivity=54.46%, avg_specificity=90.01% avg_auc=83.70%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.279370 Test loss=0.433785 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3043939769268036
[5/24] Train loss=0.26607415080070496
[10/24] Train loss=0.2866003215312958
[15/24] Train loss=0.26646167039871216
[20/24] Train loss=0.25732937455177307
Test set avg_accuracy=76.39% avg_sensitivity=14.01%, avg_specificity=99.62% avg_auc=74.47%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.280330 Test loss=0.678208 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2731790244579315
[5/24] Train loss=0.2774321436882019
[10/24] Train loss=0.2971746623516083
[15/24] Train loss=0.2828104496002197
[20/24] Train loss=0.2512529790401459
Test set avg_accuracy=77.36% avg_sensitivity=18.81%, avg_specificity=99.16% avg_auc=78.60%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.280411 Test loss=0.652750 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2855091094970703
[5/24] Train loss=0.25102439522743225
[10/24] Train loss=0.28569045662879944
[15/24] Train loss=0.2786850035190582
[20/24] Train loss=0.2516385614871979
Test set avg_accuracy=82.20% avg_sensitivity=63.00%, avg_specificity=89.35% avg_auc=85.77%
Best model saved!! Metric=-5.677110776302847!!
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.277157 Test loss=0.404914 Current lr=[0.000276307469034998]

[0/24] Train loss=0.27821534872055054
[5/24] Train loss=0.25048884749412537
[10/24] Train loss=0.2848140001296997
[15/24] Train loss=0.2770237624645233
[20/24] Train loss=0.2569482922554016
Test set avg_accuracy=80.05% avg_sensitivity=36.90%, avg_specificity=96.12% avg_auc=82.66%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.274380 Test loss=0.471575 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.2788431644439697
[5/24] Train loss=0.2664933502674103
[10/24] Train loss=0.29574859142303467
[15/24] Train loss=0.27714550495147705
[20/24] Train loss=0.24316002428531647
Test set avg_accuracy=81.74% avg_sensitivity=47.55%, avg_specificity=94.48% avg_auc=83.87%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.274685 Test loss=0.437540 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.25759193301200867
[5/24] Train loss=0.2553441822528839
[10/24] Train loss=0.2755565047264099
[15/24] Train loss=0.2749086022377014
[20/24] Train loss=0.25381073355674744
Test set avg_accuracy=77.70% avg_sensitivity=21.83%, avg_specificity=98.50% avg_auc=76.44%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.272389 Test loss=0.564300 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.25199466943740845
[5/24] Train loss=0.2426050901412964
[10/24] Train loss=0.2768705487251282
[15/24] Train loss=0.26830095052719116
[20/24] Train loss=0.2347429096698761
Test set avg_accuracy=81.85% avg_sensitivity=48.66%, avg_specificity=94.21% avg_auc=85.53%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.266254 Test loss=0.411119 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2639249265193939
[5/24] Train loss=0.24714979529380798
[10/24] Train loss=0.28143492341041565
[15/24] Train loss=0.26205432415008545
[20/24] Train loss=0.23616406321525574
Test set avg_accuracy=82.83% avg_sensitivity=62.86%, avg_specificity=90.26% avg_auc=86.49%
Best model saved!! Metric=-3.5642009174648095!!
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.266637 Test loss=0.398687 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.26558181643486023
[5/24] Train loss=0.2537877857685089
[10/24] Train loss=0.26865679025650024
[15/24] Train loss=0.28119611740112305
[20/24] Train loss=0.2480086237192154
Test set avg_accuracy=81.74% avg_sensitivity=43.38%, avg_specificity=96.03% avg_auc=84.48%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.264901 Test loss=0.447400 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.2557675242424011
[5/24] Train loss=0.2366819530725479
[10/24] Train loss=0.2699369490146637
[15/24] Train loss=0.2720540165901184
[20/24] Train loss=0.23957587778568268
Test set avg_accuracy=81.99% avg_sensitivity=64.16%, avg_specificity=88.63% avg_auc=86.19%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.261256 Test loss=0.401855 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.24376621842384338
[5/24] Train loss=0.2346215397119522
[10/24] Train loss=0.26125550270080566
[15/24] Train loss=0.24604302644729614
[20/24] Train loss=0.24233901500701904
Test set avg_accuracy=82.99% avg_sensitivity=54.89%, avg_specificity=93.46% avg_auc=85.68%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.259573 Test loss=0.403616 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2558042109012604
[5/24] Train loss=0.23642858862876892
[10/24] Train loss=0.2558819055557251
[15/24] Train loss=0.25409626960754395
[20/24] Train loss=0.24108141660690308
Test set avg_accuracy=83.09% avg_sensitivity=54.70%, avg_specificity=93.66% avg_auc=84.57%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.253800 Test loss=0.407982 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2554894685745239
[5/24] Train loss=0.24553513526916504
[10/24] Train loss=0.276174932718277
[15/24] Train loss=0.25089186429977417
[20/24] Train loss=0.25340357422828674
Test set avg_accuracy=79.11% avg_sensitivity=70.73%, avg_specificity=82.24% avg_auc=85.71%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.258343 Test loss=0.455463 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.24458859860897064
[5/24] Train loss=0.24170240759849548
[10/24] Train loss=0.24313175678253174
[15/24] Train loss=0.25837603211402893
[20/24] Train loss=0.23081350326538086
Test set avg_accuracy=82.70% avg_sensitivity=71.79%, avg_specificity=86.76% avg_auc=87.75%
Best model saved!! Metric=2.992095813828513!!
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.250054 Test loss=0.394484 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.23791523277759552
[5/24] Train loss=0.23359517753124237
[10/24] Train loss=0.27022919058799744
[15/24] Train loss=0.24970777332782745
[20/24] Train loss=0.230367973446846
Test set avg_accuracy=82.16% avg_sensitivity=70.54%, avg_specificity=86.49% avg_auc=87.68%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.249995 Test loss=0.399682 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.25432294607162476
[5/24] Train loss=0.22939984500408173
[10/24] Train loss=0.250107079744339
[15/24] Train loss=0.24295568466186523
[20/24] Train loss=0.2250869870185852
Test set avg_accuracy=82.30% avg_sensitivity=53.50%, avg_specificity=93.03% avg_auc=84.83%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.245980 Test loss=0.416200 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.25611695647239685
[5/24] Train loss=0.2246726006269455
[10/24] Train loss=0.25734663009643555
[15/24] Train loss=0.24487878382205963
[20/24] Train loss=0.23152776062488556
Test set avg_accuracy=83.14% avg_sensitivity=57.97%, avg_specificity=92.51% avg_auc=87.09%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.243521 Test loss=0.396096 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.24151349067687988
[5/24] Train loss=0.22586047649383545
[10/24] Train loss=0.24519944190979004
[15/24] Train loss=0.24861454963684082
[20/24] Train loss=0.23058710992336273
Test set avg_accuracy=81.60% avg_sensitivity=64.11%, avg_specificity=88.12% avg_auc=86.40%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.246430 Test loss=0.402009 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.23722700774669647
[5/24] Train loss=0.2266707718372345
[10/24] Train loss=0.24646785855293274
[15/24] Train loss=0.23497004806995392
[20/24] Train loss=0.23243099451065063
Test set avg_accuracy=81.82% avg_sensitivity=47.79%, avg_specificity=94.50% avg_auc=82.88%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.245398 Test loss=0.436766 Current lr=[0.000224838296036774]

[0/24] Train loss=0.24524153769016266
[5/24] Train loss=0.2207585722208023
[10/24] Train loss=0.2599054276943207
[15/24] Train loss=0.25411197543144226
[20/24] Train loss=0.24716290831565857
Test set avg_accuracy=82.66% avg_sensitivity=62.52%, avg_specificity=90.15% avg_auc=86.29%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.245577 Test loss=0.413075 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.24866855144500732
[5/24] Train loss=0.21678362786769867
[10/24] Train loss=0.2428983449935913
[15/24] Train loss=0.24647818505764008
[20/24] Train loss=0.22924275696277618
Test set avg_accuracy=82.77% avg_sensitivity=55.09%, avg_specificity=93.08% avg_auc=86.14%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.238750 Test loss=0.403113 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.23015041649341583
[5/24] Train loss=0.2267129123210907
[10/24] Train loss=0.24304801225662231
[15/24] Train loss=0.23535676300525665
[20/24] Train loss=0.22010958194732666
Test set avg_accuracy=82.81% avg_sensitivity=54.08%, avg_specificity=93.51% avg_auc=84.59%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.236754 Test loss=0.424085 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.22925230860710144
[5/24] Train loss=0.20990687608718872
[10/24] Train loss=0.23394139111042023
[15/24] Train loss=0.2376708984375
[20/24] Train loss=0.22723518311977386
Test set avg_accuracy=82.59% avg_sensitivity=67.99%, avg_specificity=88.03% avg_auc=87.29%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.234737 Test loss=0.395825 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.22725149989128113
[5/24] Train loss=0.2241145223379135
[10/24] Train loss=0.23961903154850006
[15/24] Train loss=0.2300909459590912
[20/24] Train loss=0.22316661477088928
Test set avg_accuracy=81.26% avg_sensitivity=55.18%, avg_specificity=90.98% avg_auc=82.51%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.235192 Test loss=0.447626 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2324768751859665
[5/24] Train loss=0.21996359527111053
[10/24] Train loss=0.24347570538520813
[15/24] Train loss=0.23162582516670227
[20/24] Train loss=0.23414835333824158
Test set avg_accuracy=82.58% avg_sensitivity=48.99%, avg_specificity=95.09% avg_auc=83.58%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.233518 Test loss=0.445158 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.23364123702049255
[5/24] Train loss=0.221772700548172
[10/24] Train loss=0.23890948295593262
[15/24] Train loss=0.22359362244606018
[20/24] Train loss=0.21669520437717438
Test set avg_accuracy=80.74% avg_sensitivity=37.04%, avg_specificity=97.02% avg_auc=82.02%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.231415 Test loss=0.459759 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.22626569867134094
[5/24] Train loss=0.20823000371456146
[10/24] Train loss=0.22979384660720825
[15/24] Train loss=0.23223860561847687
[20/24] Train loss=0.21570001542568207
Test set avg_accuracy=83.75% avg_sensitivity=58.01%, avg_specificity=93.33% avg_auc=86.69%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.225348 Test loss=0.400143 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2215200662612915
[5/24] Train loss=0.21153561770915985
[10/24] Train loss=0.22574006021022797
[15/24] Train loss=0.21960030496120453
[20/24] Train loss=0.20942886173725128
Test set avg_accuracy=83.62% avg_sensitivity=63.24%, avg_specificity=91.21% avg_auc=86.52%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.224165 Test loss=0.396136 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.22805896401405334
[5/24] Train loss=0.21413713693618774
[10/24] Train loss=0.2316509634256363
[15/24] Train loss=0.214981347322464
[20/24] Train loss=0.21589718759059906
Test set avg_accuracy=83.75% avg_sensitivity=55.04%, avg_specificity=94.44% avg_auc=86.44%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.221474 Test loss=0.396615 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.21475981175899506
[5/24] Train loss=0.1937156468629837
[10/24] Train loss=0.21282590925693512
[15/24] Train loss=0.21440720558166504
[20/24] Train loss=0.20363442599773407
Test set avg_accuracy=83.57% avg_sensitivity=57.39%, avg_specificity=93.32% avg_auc=85.59%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.214152 Test loss=0.401562 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2086275815963745
[5/24] Train loss=0.21456344425678253
[10/24] Train loss=0.21117204427719116
[15/24] Train loss=0.22795192897319794
[20/24] Train loss=0.2053743451833725
Test set avg_accuracy=82.21% avg_sensitivity=72.22%, avg_specificity=85.94% avg_auc=87.27%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.220735 Test loss=0.403359 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2223450243473053
[5/24] Train loss=0.22088797390460968
[10/24] Train loss=0.21416416764259338
[15/24] Train loss=0.23619094491004944
[20/24] Train loss=0.20200392603874207
Test set avg_accuracy=82.28% avg_sensitivity=56.67%, avg_specificity=91.82% avg_auc=84.01%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.219523 Test loss=0.427022 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.21161819994449615
[5/24] Train loss=0.2076277881860733
[10/24] Train loss=0.21343670785427094
[15/24] Train loss=0.20974960923194885
[20/24] Train loss=0.20292264223098755
Test set avg_accuracy=83.72% avg_sensitivity=60.36%, avg_specificity=92.42% avg_auc=87.26%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.217057 Test loss=0.385182 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.20989257097244263
[5/24] Train loss=0.213439479470253
[10/24] Train loss=0.2184046506881714
[15/24] Train loss=0.201613187789917
[20/24] Train loss=0.19892528653144836
Test set avg_accuracy=82.49% avg_sensitivity=69.53%, avg_specificity=87.31% avg_auc=86.53%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.213774 Test loss=0.408189 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.20793350040912628
[5/24] Train loss=0.1898951381444931
[10/24] Train loss=0.21244803071022034
[15/24] Train loss=0.19302956759929657
[20/24] Train loss=0.20223325490951538
Test set avg_accuracy=83.57% avg_sensitivity=65.12%, avg_specificity=90.44% avg_auc=86.30%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.210930 Test loss=0.393570 Current lr=[0.000156543481933168]

[0/24] Train loss=0.20731939375400543
[5/24] Train loss=0.1926698088645935
[10/24] Train loss=0.21130219101905823
[15/24] Train loss=0.2031315267086029
[20/24] Train loss=0.19938285648822784
Test set avg_accuracy=79.91% avg_sensitivity=45.63%, avg_specificity=92.67% avg_auc=79.90%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.206880 Test loss=0.468076 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2093299925327301
[5/24] Train loss=0.19193793833255768
[10/24] Train loss=0.2035733312368393
[15/24] Train loss=0.22028358280658722
[20/24] Train loss=0.19873900711536407
Test set avg_accuracy=82.59% avg_sensitivity=70.63%, avg_specificity=87.04% avg_auc=86.91%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.208206 Test loss=0.400147 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.20209412276744843
[5/24] Train loss=0.20163069665431976
[10/24] Train loss=0.20731651782989502
[15/24] Train loss=0.2071060836315155
[20/24] Train loss=0.1958482265472412
Test set avg_accuracy=77.64% avg_sensitivity=71.45%, avg_specificity=79.95% avg_auc=84.20%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.206834 Test loss=0.481701 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.20134004950523376
[5/24] Train loss=0.19672198593616486
[10/24] Train loss=0.20812785625457764
[15/24] Train loss=0.21274498105049133
[20/24] Train loss=0.1968613713979721
Test set avg_accuracy=83.49% avg_sensitivity=59.93%, avg_specificity=92.26% avg_auc=85.99%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.205958 Test loss=0.397927 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.2007589489221573
[5/24] Train loss=0.19695861637592316
[10/24] Train loss=0.21291488409042358
[15/24] Train loss=0.20354987680912018
[20/24] Train loss=0.1835290640592575
Test set avg_accuracy=82.81% avg_sensitivity=64.16%, avg_specificity=89.76% avg_auc=84.80%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.203203 Test loss=0.408203 Current lr=[0.000134135431043539]

[0/24] Train loss=0.20045357942581177
[5/24] Train loss=0.19098776578903198
[10/24] Train loss=0.21274806559085846
[15/24] Train loss=0.204939603805542
[20/24] Train loss=0.1853799670934677
Test set avg_accuracy=83.02% avg_sensitivity=49.42%, avg_specificity=95.53% avg_auc=84.16%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.204078 Test loss=0.437461 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1997869610786438
[5/24] Train loss=0.19313758611679077
[10/24] Train loss=0.19726233184337616
[15/24] Train loss=0.1946415901184082
[20/24] Train loss=0.19407130777835846
Test set avg_accuracy=81.21% avg_sensitivity=47.84%, avg_specificity=93.64% avg_auc=82.44%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.197130 Test loss=0.458194 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2063370794057846
[5/24] Train loss=0.19106614589691162
[10/24] Train loss=0.2046169638633728
[15/24] Train loss=0.19584707915782928
[20/24] Train loss=0.1907982975244522
Test set avg_accuracy=81.21% avg_sensitivity=38.20%, avg_specificity=97.23% avg_auc=81.22%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.198514 Test loss=0.490527 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.19355173408985138
[5/24] Train loss=0.19561688601970673
[10/24] Train loss=0.19486470520496368
[15/24] Train loss=0.20106889307498932
[20/24] Train loss=0.18454234302043915
Test set avg_accuracy=83.31% avg_sensitivity=51.73%, avg_specificity=95.07% avg_auc=83.49%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.196943 Test loss=0.440493 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1918424665927887
[5/24] Train loss=0.19094230234622955
[10/24] Train loss=0.20303994417190552
[15/24] Train loss=0.19358956813812256
[20/24] Train loss=0.180216982960701
Test set avg_accuracy=83.57% avg_sensitivity=59.40%, avg_specificity=92.57% avg_auc=85.23%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.196536 Test loss=0.412138 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.19836410880088806
[5/24] Train loss=0.1791413426399231
[10/24] Train loss=0.1967262178659439
[15/24] Train loss=0.18216337263584137
[20/24] Train loss=0.18799322843551636
Test set avg_accuracy=82.01% avg_sensitivity=45.54%, avg_specificity=95.59% avg_auc=81.96%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.195681 Test loss=0.465217 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1977224200963974
[5/24] Train loss=0.1835496425628662
[10/24] Train loss=0.19424928724765778
[15/24] Train loss=0.1862058788537979
[20/24] Train loss=0.19161517918109894
Test set avg_accuracy=83.26% avg_sensitivity=61.85%, avg_specificity=91.23% avg_auc=86.03%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.194460 Test loss=0.404346 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1791740208864212
[5/24] Train loss=0.1879904419183731
[10/24] Train loss=0.19583016633987427
[15/24] Train loss=0.19709160923957825
[20/24] Train loss=0.18521662056446075
Test set avg_accuracy=82.50% avg_sensitivity=60.65%, avg_specificity=90.64% avg_auc=85.07%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.193693 Test loss=0.416720 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.18054281175136566
[5/24] Train loss=0.1796739548444748
[10/24] Train loss=0.18151429295539856
[15/24] Train loss=0.18627645075321198
[20/24] Train loss=0.18007296323776245
Test set avg_accuracy=81.02% avg_sensitivity=63.20%, avg_specificity=87.65% avg_auc=84.48%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.191474 Test loss=0.433065 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.18390913307666779
[5/24] Train loss=0.18229202926158905
[10/24] Train loss=0.18170469999313354
[15/24] Train loss=0.1821986585855484
[20/24] Train loss=0.18650545179843903
Test set avg_accuracy=81.71% avg_sensitivity=46.74%, avg_specificity=94.73% avg_auc=82.23%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.187893 Test loss=0.473449 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.17861799895763397
[5/24] Train loss=0.17843638360500336
[10/24] Train loss=0.1954212635755539
[15/24] Train loss=0.1810339242219925
[20/24] Train loss=0.17115665972232819
Test set avg_accuracy=81.47% avg_sensitivity=57.15%, avg_specificity=90.53% avg_auc=84.53%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.187440 Test loss=0.426923 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.17375081777572632
[5/24] Train loss=0.17733417451381683
[10/24] Train loss=0.1837451010942459
[15/24] Train loss=0.17875847220420837
[20/24] Train loss=0.17827753722667694
Test set avg_accuracy=82.77% avg_sensitivity=60.60%, avg_specificity=91.03% avg_auc=84.86%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.183565 Test loss=0.417354 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.17239969968795776
[5/24] Train loss=0.17200174927711487
[10/24] Train loss=0.18377061188220978
[15/24] Train loss=0.17544838786125183
[20/24] Train loss=0.17450463771820068
Test set avg_accuracy=81.60% avg_sensitivity=62.96%, avg_specificity=88.55% avg_auc=85.45%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.181226 Test loss=0.420311 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.18040914833545685
[5/24] Train loss=0.1671566665172577
[10/24] Train loss=0.18144391477108002
[15/24] Train loss=0.17058949172496796
[20/24] Train loss=0.17630425095558167
Test set avg_accuracy=81.99% avg_sensitivity=66.65%, avg_specificity=87.71% avg_auc=85.48%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.180044 Test loss=0.419532 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.16479706764221191
[5/24] Train loss=0.17654645442962646
[10/24] Train loss=0.1773776113986969
[15/24] Train loss=0.17612546682357788
[20/24] Train loss=0.16939333081245422
Test set avg_accuracy=82.19% avg_sensitivity=62.00%, avg_specificity=89.71% avg_auc=85.85%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.177597 Test loss=0.414293 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.17635858058929443
[5/24] Train loss=0.16834481060504913
[10/24] Train loss=0.17094165086746216
[15/24] Train loss=0.1734892576932907
[20/24] Train loss=0.1691010594367981
Test set avg_accuracy=83.79% avg_sensitivity=68.14%, avg_specificity=89.62% avg_auc=87.34%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.177359 Test loss=0.397122 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1723005473613739
[5/24] Train loss=0.1694912314414978
[10/24] Train loss=0.1845238208770752
[15/24] Train loss=0.1693008840084076
[20/24] Train loss=0.16423852741718292
Test set avg_accuracy=82.55% avg_sensitivity=74.52%, avg_specificity=85.54% avg_auc=87.44%
Best model saved!! Metric=4.0530317074805!!
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.175902 Test loss=0.409800 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1752977818250656
[5/24] Train loss=0.1703280210494995
[10/24] Train loss=0.16457797586917877
[15/24] Train loss=0.16844840347766876
[20/24] Train loss=0.1731567531824112
Test set avg_accuracy=83.89% avg_sensitivity=72.26%, avg_specificity=88.22% avg_auc=87.45%
Best model saved!! Metric=5.834095380400356!!
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.172804 Test loss=0.399419 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.16519483923912048
[5/24] Train loss=0.169296532869339
[10/24] Train loss=0.16586078703403473
[15/24] Train loss=0.1626899540424347
[20/24] Train loss=0.1618165373802185
Test set avg_accuracy=83.67% avg_sensitivity=72.50%, avg_specificity=87.83% avg_auc=87.92%
Best model saved!! Metric=5.923681026789083!!
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.170564 Test loss=0.395536 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.15927207469940186
[5/24] Train loss=0.16987353563308716
[10/24] Train loss=0.16067159175872803
[15/24] Train loss=0.1631127893924713
[20/24] Train loss=0.1546643078327179
Test set avg_accuracy=83.40% avg_sensitivity=72.36%, avg_specificity=87.51% avg_auc=86.98%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.166476 Test loss=0.407834 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1649242788553238
[5/24] Train loss=0.15959228575229645
[10/24] Train loss=0.16082274913787842
[15/24] Train loss=0.15740236639976501
[20/24] Train loss=0.16185982525348663
Test set avg_accuracy=83.95% avg_sensitivity=63.96%, avg_specificity=91.39% avg_auc=86.04%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.164773 Test loss=0.406120 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.16308239102363586
[5/24] Train loss=0.1559075117111206
[10/24] Train loss=0.1600879430770874
[15/24] Train loss=0.153625026345253
[20/24] Train loss=0.15624238550662994
Test set avg_accuracy=83.91% avg_sensitivity=65.83%, avg_specificity=90.64% avg_auc=86.05%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.161328 Test loss=0.398652 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.15707255899906158
[5/24] Train loss=0.1582721322774887
[10/24] Train loss=0.15217170119285583
[15/24] Train loss=0.15079167485237122
[20/24] Train loss=0.15606194734573364
Test set avg_accuracy=83.11% avg_sensitivity=69.91%, avg_specificity=88.03% avg_auc=86.74%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.160092 Test loss=0.405642 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.15445087850093842
[5/24] Train loss=0.16521048545837402
[10/24] Train loss=0.15114471316337585
[15/24] Train loss=0.15239903330802917
[20/24] Train loss=0.15810994803905487
Test set avg_accuracy=83.24% avg_sensitivity=66.94%, avg_specificity=89.31% avg_auc=86.50%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.159552 Test loss=0.403549 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.15350988507270813
[5/24] Train loss=0.15413504838943481
[10/24] Train loss=0.15529729425907135
[15/24] Train loss=0.1526821255683899
[20/24] Train loss=0.15699927508831024
Test set avg_accuracy=83.33% avg_sensitivity=62.09%, avg_specificity=91.24% avg_auc=85.80%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.157910 Test loss=0.406685 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.15990658104419708
[5/24] Train loss=0.14935846626758575
[10/24] Train loss=0.1585657000541687
[15/24] Train loss=0.14857599139213562
[20/24] Train loss=0.15243472158908844
Test set avg_accuracy=83.55% avg_sensitivity=67.42%, avg_specificity=89.56% avg_auc=86.60%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.156429 Test loss=0.402103 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.15550579130649567
[5/24] Train loss=0.14646783471107483
[10/24] Train loss=0.1480678915977478
[15/24] Train loss=0.1471986472606659
[20/24] Train loss=0.14994797110557556
Test set avg_accuracy=83.75% avg_sensitivity=67.08%, avg_specificity=89.96% avg_auc=86.49%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.154774 Test loss=0.405110 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.15808191895484924
[5/24] Train loss=0.1519012153148651
[10/24] Train loss=0.14439158141613007
[15/24] Train loss=0.1549071967601776
[20/24] Train loss=0.14696547389030457
Test set avg_accuracy=83.29% avg_sensitivity=65.26%, avg_specificity=90.01% avg_auc=85.83%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.155346 Test loss=0.414449 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.15085746347904205
[5/24] Train loss=0.15097372233867645
[10/24] Train loss=0.14633691310882568
[15/24] Train loss=0.14857085049152374
[20/24] Train loss=0.14476560056209564
Test set avg_accuracy=83.23% avg_sensitivity=66.31%, avg_specificity=89.53% avg_auc=86.06%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.153735 Test loss=0.407758 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.14916567504405975
[5/24] Train loss=0.15532538294792175
[10/24] Train loss=0.1477750539779663
[15/24] Train loss=0.14471137523651123
[20/24] Train loss=0.15269938111305237
Test set avg_accuracy=83.96% avg_sensitivity=63.87%, avg_specificity=91.44% avg_auc=86.20%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.152936 Test loss=0.400078 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.14922301471233368
[5/24] Train loss=0.15820446610450745
[10/24] Train loss=0.14324693381786346
[15/24] Train loss=0.142622709274292
[20/24] Train loss=0.14589688181877136
Test set avg_accuracy=83.45% avg_sensitivity=68.62%, avg_specificity=88.97% avg_auc=86.84%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.151030 Test loss=0.399290 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.14740239083766937
[5/24] Train loss=0.14552806317806244
[10/24] Train loss=0.14340558648109436
[15/24] Train loss=0.13814006745815277
[20/24] Train loss=0.14785811305046082
Test set avg_accuracy=83.48% avg_sensitivity=62.96%, avg_specificity=91.12% avg_auc=85.55%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.149156 Test loss=0.410491 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1476822942495346
[5/24] Train loss=0.14516177773475647
[10/24] Train loss=0.14233747124671936
[15/24] Train loss=0.1434510052204132
[20/24] Train loss=0.14325915277004242
Test set avg_accuracy=83.27% avg_sensitivity=64.20%, avg_specificity=90.37% avg_auc=86.05%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.147942 Test loss=0.406416 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.14686790108680725
[5/24] Train loss=0.14419686794281006
[10/24] Train loss=0.14337880909442902
[15/24] Train loss=0.14222778379917145
[20/24] Train loss=0.14070454239845276
Test set avg_accuracy=83.62% avg_sensitivity=64.88%, avg_specificity=90.60% avg_auc=85.84%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.147890 Test loss=0.405748 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.14618931710720062
[5/24] Train loss=0.14459821581840515
[10/24] Train loss=0.14275799691677094
[15/24] Train loss=0.13889732956886292
[20/24] Train loss=0.14476509392261505
Test set avg_accuracy=83.80% avg_sensitivity=66.84%, avg_specificity=90.12% avg_auc=86.52%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.146814 Test loss=0.402275 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.14758414030075073
[5/24] Train loss=0.14573164284229279
[10/24] Train loss=0.14139734208583832
[15/24] Train loss=0.14004378020763397
[20/24] Train loss=0.1436966508626938
Test set avg_accuracy=83.45% avg_sensitivity=64.25%, avg_specificity=90.60% avg_auc=85.95%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.146867 Test loss=0.407110 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.14625705778598785
[5/24] Train loss=0.13853538036346436
[10/24] Train loss=0.14018264412879944
[15/24] Train loss=0.1351003497838974
[20/24] Train loss=0.13793395459651947
Test set avg_accuracy=83.50% avg_sensitivity=65.40%, avg_specificity=90.24% avg_auc=86.20%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.145256 Test loss=0.406207 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.14315026998519897
[5/24] Train loss=0.14427486062049866
[10/24] Train loss=0.13835707306861877
[15/24] Train loss=0.13630294799804688
[20/24] Train loss=0.13870327174663544
Test set avg_accuracy=83.39% avg_sensitivity=65.83%, avg_specificity=89.92% avg_auc=86.31%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.145429 Test loss=0.406670 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.14268751442432404
[5/24] Train loss=0.14100444316864014
[10/24] Train loss=0.1405828893184662
[15/24] Train loss=0.14250534772872925
[20/24] Train loss=0.14500799775123596
Test set avg_accuracy=83.40% avg_sensitivity=65.31%, avg_specificity=90.14% avg_auc=86.11%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.145774 Test loss=0.406144 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.14676006138324738
[5/24] Train loss=0.14261217415332794
[10/24] Train loss=0.13864704966545105
[15/24] Train loss=0.13600121438503265
[20/24] Train loss=0.13928231596946716
Test set avg_accuracy=83.44% avg_sensitivity=64.06%, avg_specificity=90.65% avg_auc=86.02%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.145035 Test loss=0.406656 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.14514075219631195
[5/24] Train loss=0.13873408734798431
[10/24] Train loss=0.13650360703468323
[15/24] Train loss=0.13754427433013916
[20/24] Train loss=0.13765299320220947
Test set avg_accuracy=83.58% avg_sensitivity=64.40%, avg_specificity=90.73% avg_auc=86.20%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.144185 Test loss=0.405340 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1451307088136673
[5/24] Train loss=0.13971088826656342
[10/24] Train loss=0.14091263711452484
[15/24] Train loss=0.13858506083488464
[20/24] Train loss=0.1399122178554535
Test set avg_accuracy=83.45% avg_sensitivity=64.30%, avg_specificity=90.58% avg_auc=86.14%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.144618 Test loss=0.406647 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13929791748523712
[5/24] Train loss=0.1411055326461792
[10/24] Train loss=0.13757914304733276
[15/24] Train loss=0.13640010356903076
[20/24] Train loss=0.13923633098602295
Test set avg_accuracy=83.55% avg_sensitivity=64.35%, avg_specificity=90.71% avg_auc=86.19%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.143817 Test loss=0.406334 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.14220108091831207
[5/24] Train loss=0.139395073056221
[10/24] Train loss=0.13754558563232422
[15/24] Train loss=0.1361387073993683
[20/24] Train loss=0.1417791247367859
Test set avg_accuracy=83.61% avg_sensitivity=64.49%, avg_specificity=90.73% avg_auc=86.27%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.144433 Test loss=0.405057 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.14288482069969177
[5/24] Train loss=0.14067557454109192
[10/24] Train loss=0.13631600141525269
[15/24] Train loss=0.13968849182128906
[20/24] Train loss=0.13775190711021423
Test set avg_accuracy=83.58% avg_sensitivity=64.59%, avg_specificity=90.65% avg_auc=86.25%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.143514 Test loss=0.405636 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.14301560819149017
[5/24] Train loss=0.14071951806545258
[10/24] Train loss=0.13862571120262146
[15/24] Train loss=0.13559246063232422
[20/24] Train loss=0.13956499099731445
Test set avg_accuracy=83.58% avg_sensitivity=64.49%, avg_specificity=90.69% avg_auc=86.19%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.143523 Test loss=0.405719 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.14125077426433563
[5/24] Train loss=0.14079682528972626
[10/24] Train loss=0.13716720044612885
[15/24] Train loss=0.14051604270935059
[20/24] Train loss=0.13687363266944885
Test set avg_accuracy=83.59% avg_sensitivity=64.68%, avg_specificity=90.64% avg_auc=86.19%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.142994 Test loss=0.405870 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.14413781464099884
[5/24] Train loss=0.13906298577785492
[10/24] Train loss=0.13775749504566193
[15/24] Train loss=0.1384873390197754
[20/24] Train loss=0.13911032676696777
Test set avg_accuracy=83.57% avg_sensitivity=64.54%, avg_specificity=90.65% avg_auc=86.18%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.143778 Test loss=0.406285 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1420329064130783
[5/24] Train loss=0.14041632413864136
[10/24] Train loss=0.13616067171096802
[15/24] Train loss=0.13493047654628754
[20/24] Train loss=0.1371314823627472
Test set avg_accuracy=83.65% avg_sensitivity=64.68%, avg_specificity=90.71% avg_auc=86.19%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.142939 Test loss=0.406172 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=83.67% sen=72.50%, spe=87.83%, auc=87.92%!
Fold[6] Avg_overlap=0.64%(±0.24390217964406105)
[0/24] Train loss=0.7339274287223816
[5/24] Train loss=0.7193557024002075
[10/24] Train loss=0.7133212089538574
[15/24] Train loss=0.705451250076294
[20/24] Train loss=0.7023678421974182
Test set avg_accuracy=56.48% avg_sensitivity=46.49%, avg_specificity=60.30% avg_auc=55.14%
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.715925 Test loss=0.688309 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6961355209350586
[5/24] Train loss=0.6884577870368958
[10/24] Train loss=0.6978026628494263
[15/24] Train loss=0.6856917142868042
[20/24] Train loss=0.6696438193321228
Test set avg_accuracy=63.39% avg_sensitivity=59.36%, avg_specificity=64.92% avg_auc=67.07%
Best model saved!! Metric=-71.26334274323469!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.690765 Test loss=0.642908 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6689596772193909
[5/24] Train loss=0.6675458550453186
[10/24] Train loss=0.6733473539352417
[15/24] Train loss=0.664749026298523
[20/24] Train loss=0.6472772359848022
Test set avg_accuracy=67.49% avg_sensitivity=66.67%, avg_specificity=67.80% avg_auc=72.25%
Best model saved!! Metric=-51.793359583421434!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.667908 Test loss=0.616119 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6491827368736267
[5/24] Train loss=0.6435979604721069
[10/24] Train loss=0.6475760340690613
[15/24] Train loss=0.6426053643226624
[20/24] Train loss=0.6255035996437073
Test set avg_accuracy=69.04% avg_sensitivity=70.30%, avg_specificity=68.56% avg_auc=74.81%
Best model saved!! Metric=-43.298446840169134!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.647761 Test loss=0.596524 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6174562573432922
[5/24] Train loss=0.6224225163459778
[10/24] Train loss=0.6252507567405701
[15/24] Train loss=0.618547797203064
[20/24] Train loss=0.6073758006095886
Test set avg_accuracy=70.62% avg_sensitivity=72.89%, avg_specificity=69.76% avg_auc=76.82%
Best model saved!! Metric=-35.90513072489115!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.627385 Test loss=0.578052 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6004094481468201
[5/24] Train loss=0.5970022082328796
[10/24] Train loss=0.6120978593826294
[15/24] Train loss=0.5966057181358337
[20/24] Train loss=0.5744382739067078
Test set avg_accuracy=72.70% avg_sensitivity=72.89%, avg_specificity=72.62% avg_auc=78.63%
Best model saved!! Metric=-29.162692312122587!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.607298 Test loss=0.552889 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.568930983543396
[5/24] Train loss=0.5704675316810608
[10/24] Train loss=0.5901432633399963
[15/24] Train loss=0.5849997401237488
[20/24] Train loss=0.5555139183998108
Test set avg_accuracy=74.71% avg_sensitivity=71.10%, avg_specificity=76.09% avg_auc=79.88%
Best model saved!! Metric=-24.21946052261245!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.585615 Test loss=0.530304 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5544628500938416
[5/24] Train loss=0.5488725304603577
[10/24] Train loss=0.5710426568984985
[15/24] Train loss=0.5628206133842468
[20/24] Train loss=0.5327461957931519
Test set avg_accuracy=76.30% avg_sensitivity=69.54%, avg_specificity=78.88% avg_auc=81.08%
Best model saved!! Metric=-20.193960180508455!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.565477 Test loss=0.507019 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5414989590644836
[5/24] Train loss=0.5272830724716187
[10/24] Train loss=0.549575686454773
[15/24] Train loss=0.5395544767379761
[20/24] Train loss=0.5116822719573975
Test set avg_accuracy=77.57% avg_sensitivity=68.88%, avg_specificity=80.88% avg_auc=82.17%
Best model saved!! Metric=-16.50024835578779!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.545164 Test loss=0.488130 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5120803713798523
[5/24] Train loss=0.5039255023002625
[10/24] Train loss=0.5314801335334778
[15/24] Train loss=0.5220738053321838
[20/24] Train loss=0.4862540066242218
Test set avg_accuracy=78.80% avg_sensitivity=66.43%, avg_specificity=83.52% avg_auc=83.07%
Best model saved!! Metric=-14.170062960010057!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.523102 Test loss=0.467449 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.49446117877960205
[5/24] Train loss=0.4868325889110565
[10/24] Train loss=0.5081750750541687
[15/24] Train loss=0.5004438161849976
[20/24] Train loss=0.46323731541633606
Test set avg_accuracy=79.92% avg_sensitivity=66.86%, avg_specificity=84.91% avg_auc=84.47%
Best model saved!! Metric=-9.846424580709765!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.502140 Test loss=0.448817 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4719955027103424
[5/24] Train loss=0.46562641859054565
[10/24] Train loss=0.49507761001586914
[15/24] Train loss=0.4820254445075989
[20/24] Train loss=0.43430134654045105
Test set avg_accuracy=80.83% avg_sensitivity=66.43%, avg_specificity=86.33% avg_auc=85.60%
Best model saved!! Metric=-6.804343810373638!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.482140 Test loss=0.432189 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.46895551681518555
[5/24] Train loss=0.44867366552352905
[10/24] Train loss=0.4732857644557953
[15/24] Train loss=0.4689491391181946
[20/24] Train loss=0.41471928358078003
Test set avg_accuracy=81.90% avg_sensitivity=63.88%, avg_specificity=88.77% avg_auc=86.19%
Best model saved!! Metric=-5.250402288152074!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.463201 Test loss=0.417678 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4442426562309265
[5/24] Train loss=0.4300094246864319
[10/24] Train loss=0.4639835059642792
[15/24] Train loss=0.44632193446159363
[20/24] Train loss=0.3981873691082001
Test set avg_accuracy=82.15% avg_sensitivity=63.84%, avg_specificity=89.13% avg_auc=86.98%
Best model saved!! Metric=-3.897705885443308!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.447320 Test loss=0.407739 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.43522363901138306
[5/24] Train loss=0.4115327298641205
[10/24] Train loss=0.4529348909854889
[15/24] Train loss=0.43113815784454346
[20/24] Train loss=0.3886599838733673
Test set avg_accuracy=82.54% avg_sensitivity=61.76%, avg_specificity=90.47% avg_auc=87.28%
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.434035 Test loss=0.399304 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4244168996810913
[5/24] Train loss=0.39715373516082764
[10/24] Train loss=0.4446622133255005
[15/24] Train loss=0.4225207269191742
[20/24] Train loss=0.37228477001190186
Test set avg_accuracy=82.53% avg_sensitivity=58.23%, avg_specificity=91.80% avg_auc=87.60%
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.420948 Test loss=0.391477 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.41191986203193665
[5/24] Train loss=0.3889341652393341
[10/24] Train loss=0.43180716037750244
[15/24] Train loss=0.41675519943237305
[20/24] Train loss=0.3660660982131958
Test set avg_accuracy=82.63% avg_sensitivity=60.58%, avg_specificity=91.04% avg_auc=88.14%
Best model saved!! Metric=-3.606798329325102!!
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.410205 Test loss=0.387129 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.40677544474601746
[5/24] Train loss=0.3757733106613159
[10/24] Train loss=0.42914196848869324
[15/24] Train loss=0.4020058810710907
[20/24] Train loss=0.35566431283950806
Test set avg_accuracy=82.40% avg_sensitivity=49.55%, avg_specificity=94.93% avg_auc=87.75%
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.401648 Test loss=0.392256 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4009550213813782
[5/24] Train loss=0.36407187581062317
[10/24] Train loss=0.41926977038383484
[15/24] Train loss=0.38827237486839294
[20/24] Train loss=0.3470580279827118
Test set avg_accuracy=82.54% avg_sensitivity=51.20%, avg_specificity=94.50% avg_auc=87.72%
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.393317 Test loss=0.389773 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3900115489959717
[5/24] Train loss=0.3589950501918793
[10/24] Train loss=0.40837129950523376
[15/24] Train loss=0.38331249356269836
[20/24] Train loss=0.3390028178691864
Test set avg_accuracy=82.55% avg_sensitivity=51.20%, avg_specificity=94.51% avg_auc=87.94%
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.386018 Test loss=0.387108 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3795569837093353
[5/24] Train loss=0.35210585594177246
[10/24] Train loss=0.4075482487678528
[15/24] Train loss=0.3818782866001129
[20/24] Train loss=0.3380013406276703
Test set avg_accuracy=82.29% avg_sensitivity=46.44%, avg_specificity=95.97% avg_auc=87.54%
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.379297 Test loss=0.399692 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3750646412372589
[5/24] Train loss=0.3472228944301605
[10/24] Train loss=0.4086501896381378
[15/24] Train loss=0.38107243180274963
[20/24] Train loss=0.32823407649993896
Test set avg_accuracy=82.81% avg_sensitivity=51.39%, avg_specificity=94.80% avg_auc=88.41%
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.375517 Test loss=0.382081 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.36679020524024963
[5/24] Train loss=0.3393067717552185
[10/24] Train loss=0.403062641620636
[15/24] Train loss=0.36890825629234314
[20/24] Train loss=0.3226642906665802
Test set avg_accuracy=81.95% avg_sensitivity=44.22%, avg_specificity=96.35% avg_auc=87.78%
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.370013 Test loss=0.404514 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.363295316696167
[5/24] Train loss=0.3468998670578003
[10/24] Train loss=0.4059973359107971
[15/24] Train loss=0.37634068727493286
[20/24] Train loss=0.3182472288608551
Test set avg_accuracy=82.77% avg_sensitivity=53.32%, avg_specificity=94.01% avg_auc=88.91%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.365567 Test loss=0.373547 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.355625718832016
[5/24] Train loss=0.3368992805480957
[10/24] Train loss=0.4035353362560272
[15/24] Train loss=0.36286240816116333
[20/24] Train loss=0.31055083870887756
Test set avg_accuracy=83.22% avg_sensitivity=52.90%, avg_specificity=94.78% avg_auc=89.31%
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.360610 Test loss=0.370296 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.36028844118118286
[5/24] Train loss=0.3335617184638977
[10/24] Train loss=0.3940098285675049
[15/24] Train loss=0.36649444699287415
[20/24] Train loss=0.3117178678512573
Test set avg_accuracy=81.90% avg_sensitivity=43.33%, avg_specificity=96.62% avg_auc=88.18%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.358115 Test loss=0.399741 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.35297876596450806
[5/24] Train loss=0.33168402314186096
[10/24] Train loss=0.39366087317466736
[15/24] Train loss=0.34637880325317383
[20/24] Train loss=0.31406453251838684
Test set avg_accuracy=82.50% avg_sensitivity=44.88%, avg_specificity=96.85% avg_auc=88.92%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.355297 Test loss=0.391626 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3501074016094208
[5/24] Train loss=0.3260338604450226
[10/24] Train loss=0.38833338022232056
[15/24] Train loss=0.3532562553882599
[20/24] Train loss=0.30632880330085754
Test set avg_accuracy=82.41% avg_sensitivity=46.02%, avg_specificity=96.29% avg_auc=89.00%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.350255 Test loss=0.386641 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3546505272388458
[5/24] Train loss=0.3354594111442566
[10/24] Train loss=0.3957083225250244
[15/24] Train loss=0.3465183973312378
[20/24] Train loss=0.2987718880176544
Test set avg_accuracy=83.36% avg_sensitivity=52.57%, avg_specificity=95.11% avg_auc=89.23%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.348028 Test loss=0.370362 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3499342203140259
[5/24] Train loss=0.3227059841156006
[10/24] Train loss=0.38902854919433594
[15/24] Train loss=0.34321123361587524
[20/24] Train loss=0.3018590807914734
Test set avg_accuracy=82.98% avg_sensitivity=50.87%, avg_specificity=95.23% avg_auc=89.04%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.345219 Test loss=0.374632 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3421576917171478
[5/24] Train loss=0.3273043632507324
[10/24] Train loss=0.39112335443496704
[15/24] Train loss=0.3421562910079956
[20/24] Train loss=0.30832016468048096
Test set avg_accuracy=83.39% avg_sensitivity=54.74%, avg_specificity=94.32% avg_auc=89.32%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.345102 Test loss=0.365307 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3368413746356964
[5/24] Train loss=0.32006874680519104
[10/24] Train loss=0.3817378282546997
[15/24] Train loss=0.33589842915534973
[20/24] Train loss=0.2958897054195404
Test set avg_accuracy=81.98% avg_sensitivity=43.89%, avg_specificity=96.51% avg_auc=87.79%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.338093 Test loss=0.401031 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3470394015312195
[5/24] Train loss=0.3212164640426636
[10/24] Train loss=0.3850156366825104
[15/24] Train loss=0.332919716835022
[20/24] Train loss=0.29230841994285583
Test set avg_accuracy=79.82% avg_sensitivity=31.40%, avg_specificity=98.29% avg_auc=85.96%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.335680 Test loss=0.447796 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.34358325600624084
[5/24] Train loss=0.32141029834747314
[10/24] Train loss=0.387160986661911
[15/24] Train loss=0.3289930522441864
[20/24] Train loss=0.2915923297405243
Test set avg_accuracy=81.54% avg_sensitivity=40.83%, avg_specificity=97.07% avg_auc=88.46%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.333135 Test loss=0.395342 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3347601294517517
[5/24] Train loss=0.31770461797714233
[10/24] Train loss=0.3784010112285614
[15/24] Train loss=0.31570759415626526
[20/24] Train loss=0.2954752743244171
Test set avg_accuracy=82.53% avg_sensitivity=48.94%, avg_specificity=95.34% avg_auc=88.04%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.331179 Test loss=0.387243 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3245966136455536
[5/24] Train loss=0.3131645619869232
[10/24] Train loss=0.381236732006073
[15/24] Train loss=0.32770660519599915
[20/24] Train loss=0.2903851270675659
Test set avg_accuracy=82.85% avg_sensitivity=48.47%, avg_specificity=95.97% avg_auc=88.43%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.328236 Test loss=0.381368 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.31716176867485046
[5/24] Train loss=0.3089621365070343
[10/24] Train loss=0.36196810007095337
[15/24] Train loss=0.3212471604347229
[20/24] Train loss=0.28568321466445923
Test set avg_accuracy=80.42% avg_sensitivity=37.44%, avg_specificity=96.82% avg_auc=86.22%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.326934 Test loss=0.419313 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3184756934642792
[5/24] Train loss=0.3126755356788635
[10/24] Train loss=0.374850869178772
[15/24] Train loss=0.32400351762771606
[20/24] Train loss=0.2801458537578583
Test set avg_accuracy=79.51% avg_sensitivity=30.32%, avg_specificity=98.27% avg_auc=86.52%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.327469 Test loss=0.448805 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.32832756638526917
[5/24] Train loss=0.32058364152908325
[10/24] Train loss=0.3536236584186554
[15/24] Train loss=0.31373482942581177
[20/24] Train loss=0.2849814295768738
Test set avg_accuracy=78.63% avg_sensitivity=28.71%, avg_specificity=97.68% avg_auc=85.18%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.325420 Test loss=0.450416 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.32956448197364807
[5/24] Train loss=0.30446869134902954
[10/24] Train loss=0.3625442385673523
[15/24] Train loss=0.3067215085029602
[20/24] Train loss=0.27691709995269775
Test set avg_accuracy=81.02% avg_sensitivity=39.18%, avg_specificity=96.98% avg_auc=87.83%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.320575 Test loss=0.400061 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.31296297907829285
[5/24] Train loss=0.30029577016830444
[10/24] Train loss=0.3523501753807068
[15/24] Train loss=0.2987061142921448
[20/24] Train loss=0.28013139963150024
Test set avg_accuracy=80.86% avg_sensitivity=45.40%, avg_specificity=94.39% avg_auc=83.53%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.316202 Test loss=0.433733 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.31781527400016785
[5/24] Train loss=0.3052564859390259
[10/24] Train loss=0.3568684458732605
[15/24] Train loss=0.3196426033973694
[20/24] Train loss=0.2846496105194092
Test set avg_accuracy=80.21% avg_sensitivity=33.71%, avg_specificity=97.95% avg_auc=84.86%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.319483 Test loss=0.434652 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.30371028184890747
[5/24] Train loss=0.3007048964500427
[10/24] Train loss=0.3467403054237366
[15/24] Train loss=0.3004923462867737
[20/24] Train loss=0.2794353663921356
Test set avg_accuracy=77.89% avg_sensitivity=23.62%, avg_specificity=98.60% avg_auc=84.40%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.315071 Test loss=0.536401 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.31938377022743225
[5/24] Train loss=0.2960822880268097
[10/24] Train loss=0.34334567189216614
[15/24] Train loss=0.28196272253990173
[20/24] Train loss=0.28469914197921753
Test set avg_accuracy=77.03% avg_sensitivity=19.66%, avg_specificity=98.92% avg_auc=84.45%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.311354 Test loss=0.540060 Current lr=[0.00029967723776099]

[0/24] Train loss=0.29947447776794434
[5/24] Train loss=0.2920878529548645
[10/24] Train loss=0.3388747572898865
[15/24] Train loss=0.2840394377708435
[20/24] Train loss=0.27451223134994507
Test set avg_accuracy=79.48% avg_sensitivity=32.20%, avg_specificity=97.52% avg_auc=79.97%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.306088 Test loss=0.477146 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.30674389004707336
[5/24] Train loss=0.2978705167770386
[10/24] Train loss=0.3512066602706909
[15/24] Train loss=0.2919049859046936
[20/24] Train loss=0.28390347957611084
Test set avg_accuracy=80.30% avg_sensitivity=37.95%, avg_specificity=96.46% avg_auc=83.08%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.312020 Test loss=0.443883 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.31985360383987427
[5/24] Train loss=0.2979060709476471
[10/24] Train loss=0.34478023648262024
[15/24] Train loss=0.2840602695941925
[20/24] Train loss=0.2707286477088928
Test set avg_accuracy=78.19% avg_sensitivity=24.56%, avg_specificity=98.65% avg_auc=79.85%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.307359 Test loss=0.511386 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3077695965766907
[5/24] Train loss=0.2909751534461975
[10/24] Train loss=0.341727077960968
[15/24] Train loss=0.2870228886604309
[20/24] Train loss=0.270009845495224
Test set avg_accuracy=76.89% avg_sensitivity=18.86%, avg_specificity=99.03% avg_auc=79.84%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.304334 Test loss=0.585838 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.32792365550994873
[5/24] Train loss=0.2833757996559143
[10/24] Train loss=0.31536105275154114
[15/24] Train loss=0.28587767481803894
[20/24] Train loss=0.2657032907009125
Test set avg_accuracy=75.14% avg_sensitivity=11.41%, avg_specificity=99.46% avg_auc=78.98%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.301077 Test loss=0.654116 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3042972981929779
[5/24] Train loss=0.27711987495422363
[10/24] Train loss=0.33611053228378296
[15/24] Train loss=0.27496740221977234
[20/24] Train loss=0.2586511969566345
Test set avg_accuracy=78.16% avg_sensitivity=28.01%, avg_specificity=97.30% avg_auc=81.47%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.299341 Test loss=0.486220 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.28939464688301086
[5/24] Train loss=0.2866170406341553
[10/24] Train loss=0.3217252194881439
[15/24] Train loss=0.27843260765075684
[20/24] Train loss=0.25626227259635925
Test set avg_accuracy=80.30% avg_sensitivity=47.81%, avg_specificity=92.70% avg_auc=83.58%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.296778 Test loss=0.427042 Current lr=[0.000297555943323901]

[0/24] Train loss=0.29283106327056885
[5/24] Train loss=0.2720474302768707
[10/24] Train loss=0.3103206753730774
[15/24] Train loss=0.2776585817337036
[20/24] Train loss=0.2730536162853241
Test set avg_accuracy=78.93% avg_sensitivity=29.51%, avg_specificity=97.79% avg_auc=82.97%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.295823 Test loss=0.493932 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2983076870441437
[5/24] Train loss=0.2806509733200073
[10/24] Train loss=0.3069426417350769
[15/24] Train loss=0.2625144422054291
[20/24] Train loss=0.26870402693748474
Test set avg_accuracy=80.09% avg_sensitivity=38.05%, avg_specificity=96.13% avg_auc=81.97%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.291318 Test loss=0.460197 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3016021251678467
[5/24] Train loss=0.2652541399002075
[10/24] Train loss=0.3187805414199829
[15/24] Train loss=0.25579389929771423
[20/24] Train loss=0.26092544198036194
Test set avg_accuracy=80.44% avg_sensitivity=37.34%, avg_specificity=96.89% avg_auc=84.68%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.290196 Test loss=0.435913 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2804465889930725
[5/24] Train loss=0.2869296669960022
[10/24] Train loss=0.3099280297756195
[15/24] Train loss=0.25320515036582947
[20/24] Train loss=0.2619117200374603
Test set avg_accuracy=82.83% avg_sensitivity=45.26%, avg_specificity=97.16% avg_auc=86.44%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.290155 Test loss=0.421186 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.29365071654319763
[5/24] Train loss=0.2617619037628174
[10/24] Train loss=0.3075854778289795
[15/24] Train loss=0.2673813998699188
[20/24] Train loss=0.26120299100875854
Test set avg_accuracy=78.24% avg_sensitivity=26.03%, avg_specificity=98.17% avg_auc=81.15%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.285181 Test loss=0.567245 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3028959333896637
[5/24] Train loss=0.2618680000305176
[10/24] Train loss=0.301788866519928
[15/24] Train loss=0.25849851965904236
[20/24] Train loss=0.2708868682384491
Test set avg_accuracy=79.35% avg_sensitivity=43.14%, avg_specificity=93.16% avg_auc=82.39%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.283741 Test loss=0.471016 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.28429752588272095
[5/24] Train loss=0.26715242862701416
[10/24] Train loss=0.3162137567996979
[15/24] Train loss=0.2511678636074066
[20/24] Train loss=0.26626601815223694
Test set avg_accuracy=82.12% avg_sensitivity=45.59%, avg_specificity=96.06% avg_auc=86.17%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.281709 Test loss=0.416773 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2676471769809723
[5/24] Train loss=0.26096102595329285
[10/24] Train loss=0.3055507242679596
[15/24] Train loss=0.24874237179756165
[20/24] Train loss=0.24649329483509064
Test set avg_accuracy=82.34% avg_sensitivity=46.91%, avg_specificity=95.86% avg_auc=87.25%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.277939 Test loss=0.413059 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.260843425989151
[5/24] Train loss=0.25329944491386414
[10/24] Train loss=0.30286556482315063
[15/24] Train loss=0.25835782289505005
[20/24] Train loss=0.2510318160057068
Test set avg_accuracy=82.55% avg_sensitivity=46.86%, avg_specificity=96.17% avg_auc=84.95%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.275408 Test loss=0.442407 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.26525864005088806
[5/24] Train loss=0.2517140805721283
[10/24] Train loss=0.2969040274620056
[15/24] Train loss=0.2493181675672531
[20/24] Train loss=0.25067758560180664
Test set avg_accuracy=82.42% avg_sensitivity=55.35%, avg_specificity=92.75% avg_auc=86.04%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.274773 Test loss=0.398641 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2685452997684479
[5/24] Train loss=0.2633061408996582
[10/24] Train loss=0.3085935711860657
[15/24] Train loss=0.247222438454628
[20/24] Train loss=0.25288844108581543
Test set avg_accuracy=82.16% avg_sensitivity=57.00%, avg_specificity=91.76% avg_auc=83.56%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.274039 Test loss=0.426256 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.25701332092285156
[5/24] Train loss=0.24973547458648682
[10/24] Train loss=0.3115900754928589
[15/24] Train loss=0.26150184869766235
[20/24] Train loss=0.24438343942165375
Test set avg_accuracy=74.78% avg_sensitivity=73.27%, avg_specificity=75.36% avg_auc=82.70%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.273191 Test loss=0.500781 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.26041287183761597
[5/24] Train loss=0.24809962511062622
[10/24] Train loss=0.29526159167289734
[15/24] Train loss=0.2524375319480896
[20/24] Train loss=0.2545745372772217
Test set avg_accuracy=82.49% avg_sensitivity=54.97%, avg_specificity=92.98% avg_auc=85.97%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.269024 Test loss=0.404922 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2552137076854706
[5/24] Train loss=0.25285017490386963
[10/24] Train loss=0.29398098587989807
[15/24] Train loss=0.2601250112056732
[20/24] Train loss=0.24842078983783722
Test set avg_accuracy=81.07% avg_sensitivity=71.52%, avg_specificity=84.71% avg_auc=87.22%
Best model saved!! Metric=-1.479332925414397!!
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.271194 Test loss=0.404455 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.2621711194515228
[5/24] Train loss=0.2387116253376007
[10/24] Train loss=0.2965872287750244
[15/24] Train loss=0.2405412495136261
[20/24] Train loss=0.25001150369644165
Test set avg_accuracy=80.48% avg_sensitivity=38.24%, avg_specificity=96.60% avg_auc=84.72%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.268358 Test loss=0.455062 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2575099766254425
[5/24] Train loss=0.24537689983844757
[10/24] Train loss=0.2885277569293976
[15/24] Train loss=0.2525536119937897
[20/24] Train loss=0.2329169064760208
Test set avg_accuracy=83.71% avg_sensitivity=56.25%, avg_specificity=94.19% avg_auc=85.61%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.265777 Test loss=0.417979 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.26095762848854065
[5/24] Train loss=0.24052311480045319
[10/24] Train loss=0.2702874541282654
[15/24] Train loss=0.2393067181110382
[20/24] Train loss=0.25019562244415283
Test set avg_accuracy=82.40% avg_sensitivity=47.62%, avg_specificity=95.66% avg_auc=85.07%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.261755 Test loss=0.446320 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2441159039735794
[5/24] Train loss=0.23658406734466553
[10/24] Train loss=0.26931440830230713
[15/24] Train loss=0.23074914515018463
[20/24] Train loss=0.2427750676870346
Test set avg_accuracy=81.03% avg_sensitivity=44.13%, avg_specificity=95.11% avg_auc=83.96%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.257709 Test loss=0.458790 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.25890490412712097
[5/24] Train loss=0.24542373418807983
[10/24] Train loss=0.2586631178855896
[15/24] Train loss=0.224424809217453
[20/24] Train loss=0.22623102366924286
Test set avg_accuracy=83.05% avg_sensitivity=52.15%, avg_specificity=94.84% avg_auc=86.08%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.252315 Test loss=0.420474 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.24817082285881042
[5/24] Train loss=0.2281634509563446
[10/24] Train loss=0.28107750415802
[15/24] Train loss=0.23720116913318634
[20/24] Train loss=0.24188999831676483
Test set avg_accuracy=82.28% avg_sensitivity=47.29%, avg_specificity=95.63% avg_auc=84.75%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.252993 Test loss=0.425215 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.26321831345558167
[5/24] Train loss=0.2429625391960144
[10/24] Train loss=0.26547443866729736
[15/24] Train loss=0.23812007904052734
[20/24] Train loss=0.2373349666595459
Test set avg_accuracy=81.50% avg_sensitivity=52.43%, avg_specificity=92.59% avg_auc=84.82%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.256947 Test loss=0.422444 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.25007349252700806
[5/24] Train loss=0.22860144078731537
[10/24] Train loss=0.26871734857559204
[15/24] Train loss=0.21580035984516144
[20/24] Train loss=0.2381003201007843
Test set avg_accuracy=79.41% avg_sensitivity=31.73%, avg_specificity=97.61% avg_auc=83.05%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.252948 Test loss=0.471982 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.24906831979751587
[5/24] Train loss=0.23296573758125305
[10/24] Train loss=0.2700101435184479
[15/24] Train loss=0.2147214114665985
[20/24] Train loss=0.2355111837387085
Test set avg_accuracy=82.43% avg_sensitivity=52.52%, avg_specificity=93.85% avg_auc=86.06%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.246922 Test loss=0.414754 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.2629545331001282
[5/24] Train loss=0.21047990024089813
[10/24] Train loss=0.2663772404193878
[15/24] Train loss=0.22913138568401337
[20/24] Train loss=0.22742463648319244
Test set avg_accuracy=82.50% avg_sensitivity=50.87%, avg_specificity=94.57% avg_auc=85.32%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.250477 Test loss=0.410045 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.25553053617477417
[5/24] Train loss=0.22286534309387207
[10/24] Train loss=0.2803739607334137
[15/24] Train loss=0.23454301059246063
[20/24] Train loss=0.23101307451725006
Test set avg_accuracy=80.01% avg_sensitivity=36.30%, avg_specificity=96.69% avg_auc=83.57%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.251140 Test loss=0.473770 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.25774115324020386
[5/24] Train loss=0.21901609003543854
[10/24] Train loss=0.2743369936943054
[15/24] Train loss=0.2209947109222412
[20/24] Train loss=0.23361490666866302
Test set avg_accuracy=81.71% avg_sensitivity=71.05%, avg_specificity=85.77% avg_auc=86.52%
Best model saved!! Metric=-0.9492706174841317!!
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.250148 Test loss=0.414380 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2518441379070282
[5/24] Train loss=0.21170386672019958
[10/24] Train loss=0.26101383566856384
[15/24] Train loss=0.21642467379570007
[20/24] Train loss=0.2194252461194992
Test set avg_accuracy=83.29% avg_sensitivity=67.89%, avg_specificity=89.17% avg_auc=87.99%
Best model saved!! Metric=2.344530619931831!!
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.242350 Test loss=0.386140 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2332056313753128
[5/24] Train loss=0.2060173600912094
[10/24] Train loss=0.2587794065475464
[15/24] Train loss=0.22101594507694244
[20/24] Train loss=0.21416591107845306
Test set avg_accuracy=84.05% avg_sensitivity=59.83%, avg_specificity=93.29% avg_auc=87.25%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.237267 Test loss=0.384936 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.23533742129802704
[5/24] Train loss=0.21827122569084167
[10/24] Train loss=0.2622731924057007
[15/24] Train loss=0.22465863823890686
[20/24] Train loss=0.2340492457151413
Test set avg_accuracy=81.16% avg_sensitivity=55.40%, avg_specificity=90.99% avg_auc=83.91%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.238918 Test loss=0.440115 Current lr=[0.000224838296036774]

[0/24] Train loss=0.23399926722049713
[5/24] Train loss=0.21327592432498932
[10/24] Train loss=0.24565836787223816
[15/24] Train loss=0.22219033539295197
[20/24] Train loss=0.2294086068868637
Test set avg_accuracy=81.59% avg_sensitivity=49.17%, avg_specificity=93.96% avg_auc=86.81%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.236749 Test loss=0.421620 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.23276592791080475
[5/24] Train loss=0.20988468825817108
[10/24] Train loss=0.2501923739910126
[15/24] Train loss=0.21624065935611725
[20/24] Train loss=0.2212572544813156
Test set avg_accuracy=82.21% avg_sensitivity=65.82%, avg_specificity=88.47% avg_auc=86.87%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.234899 Test loss=0.402146 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.22925879061222076
[5/24] Train loss=0.20730233192443848
[10/24] Train loss=0.24080194532871246
[15/24] Train loss=0.21639011800289154
[20/24] Train loss=0.2173098623752594
Test set avg_accuracy=83.18% avg_sensitivity=70.01%, avg_specificity=88.20% avg_auc=87.91%
Best model saved!! Metric=3.2966108669979803!!
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.231101 Test loss=0.387628 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.22809243202209473
[5/24] Train loss=0.20497727394104004
[10/24] Train loss=0.2653370499610901
[15/24] Train loss=0.21581029891967773
[20/24] Train loss=0.22196325659751892
Test set avg_accuracy=83.59% avg_sensitivity=69.45%, avg_specificity=88.99% avg_auc=88.17%
Best model saved!! Metric=4.202776024798155!!
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.233087 Test loss=0.382653 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.21147611737251282
[5/24] Train loss=0.21662147343158722
[10/24] Train loss=0.25236761569976807
[15/24] Train loss=0.20955516397953033
[20/24] Train loss=0.21517397463321686
Test set avg_accuracy=83.01% avg_sensitivity=64.69%, avg_specificity=90.00% avg_auc=86.69%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.227372 Test loss=0.397726 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.22378763556480408
[5/24] Train loss=0.1883627027273178
[10/24] Train loss=0.2297459840774536
[15/24] Train loss=0.21592408418655396
[20/24] Train loss=0.20951008796691895
Test set avg_accuracy=83.16% avg_sensitivity=66.01%, avg_specificity=89.71% avg_auc=86.94%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.222345 Test loss=0.397035 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.21990658342838287
[5/24] Train loss=0.1911892145872116
[10/24] Train loss=0.22978618741035461
[15/24] Train loss=0.21830283105373383
[20/24] Train loss=0.20919153094291687
Test set avg_accuracy=82.32% avg_sensitivity=65.30%, avg_specificity=88.81% avg_auc=86.53%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.223670 Test loss=0.401966 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.23375165462493896
[5/24] Train loss=0.21283592283725739
[10/24] Train loss=0.2500036656856537
[15/24] Train loss=0.20731939375400543
[20/24] Train loss=0.21529631316661835
Test set avg_accuracy=81.55% avg_sensitivity=52.43%, avg_specificity=92.66% avg_auc=84.13%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.224573 Test loss=0.434823 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.21979600191116333
[5/24] Train loss=0.1968420296907425
[10/24] Train loss=0.23526549339294434
[15/24] Train loss=0.2023928016424179
[20/24] Train loss=0.22217957675457
Test set avg_accuracy=79.80% avg_sensitivity=39.18%, avg_specificity=95.30% avg_auc=80.01%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.221016 Test loss=0.533699 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.21758392453193665
[5/24] Train loss=0.1996847242116928
[10/24] Train loss=0.23181436955928802
[15/24] Train loss=0.21884311735630035
[20/24] Train loss=0.20794489979743958
Test set avg_accuracy=81.65% avg_sensitivity=50.83%, avg_specificity=93.42% avg_auc=83.78%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.219834 Test loss=0.450314 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.21822571754455566
[5/24] Train loss=0.19839082658290863
[10/24] Train loss=0.2306966930627823
[15/24] Train loss=0.20330524444580078
[20/24] Train loss=0.21223412454128265
Test set avg_accuracy=81.86% avg_sensitivity=53.42%, avg_specificity=92.71% avg_auc=85.87%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.213403 Test loss=0.420581 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.21101869642734528
[5/24] Train loss=0.18901558220386505
[10/24] Train loss=0.22336441278457642
[15/24] Train loss=0.2028607726097107
[20/24] Train loss=0.20512300729751587
Test set avg_accuracy=79.58% avg_sensitivity=35.45%, avg_specificity=96.42% avg_auc=76.89%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.214293 Test loss=0.540974 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2100333571434021
[5/24] Train loss=0.1826796680688858
[10/24] Train loss=0.21897996962070465
[15/24] Train loss=0.18241077661514282
[20/24] Train loss=0.20000647008419037
Test set avg_accuracy=81.85% avg_sensitivity=50.45%, avg_specificity=93.83% avg_auc=83.54%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.208589 Test loss=0.437998 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.20640374720096588
[5/24] Train loss=0.18225371837615967
[10/24] Train loss=0.2152787446975708
[15/24] Train loss=0.18914173543453217
[20/24] Train loss=0.20290589332580566
Test set avg_accuracy=83.46% avg_sensitivity=57.57%, avg_specificity=93.34% avg_auc=84.99%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.203597 Test loss=0.419389 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1930122673511505
[5/24] Train loss=0.18249209225177765
[10/24] Train loss=0.21791903674602509
[15/24] Train loss=0.1865338683128357
[20/24] Train loss=0.19385316967964172
Test set avg_accuracy=82.53% avg_sensitivity=64.59%, avg_specificity=89.37% avg_auc=85.32%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.200334 Test loss=0.416815 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2156907171010971
[5/24] Train loss=0.17088539898395538
[10/24] Train loss=0.21801206469535828
[15/24] Train loss=0.1889888495206833
[20/24] Train loss=0.1936035305261612
Test set avg_accuracy=82.10% avg_sensitivity=54.36%, avg_specificity=92.68% avg_auc=82.91%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.203216 Test loss=0.450217 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2015780359506607
[5/24] Train loss=0.1801186203956604
[10/24] Train loss=0.2017257809638977
[15/24] Train loss=0.1959892064332962
[20/24] Train loss=0.18493449687957764
Test set avg_accuracy=82.27% avg_sensitivity=55.07%, avg_specificity=92.64% avg_auc=83.10%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.200193 Test loss=0.441097 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1890305131673813
[5/24] Train loss=0.17028893530368805
[10/24] Train loss=0.20356827974319458
[15/24] Train loss=0.17939791083335876
[20/24] Train loss=0.18481974303722382
Test set avg_accuracy=83.06% avg_sensitivity=58.84%, avg_specificity=92.30% avg_auc=85.63%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.193393 Test loss=0.411019 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.18911999464035034
[5/24] Train loss=0.16658324003219604
[10/24] Train loss=0.18481063842773438
[15/24] Train loss=0.18267877399921417
[20/24] Train loss=0.18106630444526672
Test set avg_accuracy=81.02% avg_sensitivity=42.95%, avg_specificity=95.54% avg_auc=78.71%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.187584 Test loss=0.517060 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.18879269063472748
[5/24] Train loss=0.16959166526794434
[10/24] Train loss=0.20037433505058289
[15/24] Train loss=0.17836648225784302
[20/24] Train loss=0.19005191326141357
Test set avg_accuracy=81.50% avg_sensitivity=44.93%, avg_specificity=95.45% avg_auc=79.97%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.187506 Test loss=0.486275 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.19118675589561462
[5/24] Train loss=0.16984893381595612
[10/24] Train loss=0.18809305131435394
[15/24] Train loss=0.17604441940784454
[20/24] Train loss=0.18386505544185638
Test set avg_accuracy=82.10% avg_sensitivity=47.81%, avg_specificity=95.18% avg_auc=82.62%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.184770 Test loss=0.481575 Current lr=[0.000134135431043539]

[0/24] Train loss=0.19191761314868927
[5/24] Train loss=0.15942484140396118
[10/24] Train loss=0.19718939065933228
[15/24] Train loss=0.17380666732788086
[20/24] Train loss=0.18582157790660858
Test set avg_accuracy=82.62% avg_sensitivity=55.02%, avg_specificity=93.15% avg_auc=84.58%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.184298 Test loss=0.429150 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1782522350549698
[5/24] Train loss=0.16357702016830444
[10/24] Train loss=0.18828946352005005
[15/24] Train loss=0.17212572693824768
[20/24] Train loss=0.1797022968530655
Test set avg_accuracy=82.89% avg_sensitivity=53.98%, avg_specificity=93.92% avg_auc=83.63%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.180436 Test loss=0.435445 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1765899807214737
[5/24] Train loss=0.16019362211227417
[10/24] Train loss=0.18489345908164978
[15/24] Train loss=0.1682124137878418
[20/24] Train loss=0.1733095943927765
Test set avg_accuracy=80.21% avg_sensitivity=39.27%, avg_specificity=95.83% avg_auc=79.95%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.181520 Test loss=0.524072 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.18942266702651978
[5/24] Train loss=0.15962302684783936
[10/24] Train loss=0.1952390968799591
[15/24] Train loss=0.1674603819847107
[20/24] Train loss=0.17770317196846008
Test set avg_accuracy=81.91% avg_sensitivity=51.49%, avg_specificity=93.52% avg_auc=83.99%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.179783 Test loss=0.435618 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1767549216747284
[5/24] Train loss=0.15477977693080902
[10/24] Train loss=0.18638910353183746
[15/24] Train loss=0.17056208848953247
[20/24] Train loss=0.18502981960773468
Test set avg_accuracy=82.34% avg_sensitivity=51.72%, avg_specificity=94.03% avg_auc=83.62%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.180368 Test loss=0.444108 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1741582602262497
[5/24] Train loss=0.1605459600687027
[10/24] Train loss=0.17935490608215332
[15/24] Train loss=0.17299772799015045
[20/24] Train loss=0.17996461689472198
Test set avg_accuracy=81.84% avg_sensitivity=64.26%, avg_specificity=88.54% avg_auc=86.26%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.178197 Test loss=0.421926 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1785261183977127
[5/24] Train loss=0.1524149477481842
[10/24] Train loss=0.19140614569187164
[15/24] Train loss=0.16796579957008362
[20/24] Train loss=0.17971818149089813
Test set avg_accuracy=82.60% avg_sensitivity=60.87%, avg_specificity=90.90% avg_auc=85.98%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.176141 Test loss=0.413415 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.18347623944282532
[5/24] Train loss=0.1530112624168396
[10/24] Train loss=0.17182020843029022
[15/24] Train loss=0.16201572120189667
[20/24] Train loss=0.16241538524627686
Test set avg_accuracy=81.85% avg_sensitivity=68.65%, avg_specificity=86.89% avg_auc=85.59%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.171780 Test loss=0.428459 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.17510195076465607
[5/24] Train loss=0.15025396645069122
[10/24] Train loss=0.16943086683750153
[15/24] Train loss=0.16686293482780457
[20/24] Train loss=0.16240480542182922
Test set avg_accuracy=82.84% avg_sensitivity=62.56%, avg_specificity=90.57% avg_auc=85.04%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.168322 Test loss=0.427205 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.1682456135749817
[5/24] Train loss=0.14777491986751556
[10/24] Train loss=0.16231530904769897
[15/24] Train loss=0.15801028907299042
[20/24] Train loss=0.16346319019794464
Test set avg_accuracy=81.25% avg_sensitivity=68.74%, avg_specificity=86.02% avg_auc=85.60%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.165741 Test loss=0.435000 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.16447611153125763
[5/24] Train loss=0.1564382165670395
[10/24] Train loss=0.168642058968544
[15/24] Train loss=0.15642684698104858
[20/24] Train loss=0.16246262192726135
Test set avg_accuracy=82.64% avg_sensitivity=64.92%, avg_specificity=89.40% avg_auc=85.75%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.164092 Test loss=0.420314 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.16429974138736725
[5/24] Train loss=0.1384383738040924
[10/24] Train loss=0.16562801599502563
[15/24] Train loss=0.15311935544013977
[20/24] Train loss=0.16235387325286865
Test set avg_accuracy=82.64% avg_sensitivity=69.40%, avg_specificity=87.70% avg_auc=86.98%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.161782 Test loss=0.403434 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.15577934682369232
[5/24] Train loss=0.14350634813308716
[10/24] Train loss=0.1550692915916443
[15/24] Train loss=0.15205422043800354
[20/24] Train loss=0.1574009358882904
Test set avg_accuracy=80.78% avg_sensitivity=71.95%, avg_specificity=84.15% avg_auc=86.01%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.159342 Test loss=0.441103 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.16569964587688446
[5/24] Train loss=0.1349700391292572
[10/24] Train loss=0.15685370564460754
[15/24] Train loss=0.15403713285923004
[20/24] Train loss=0.15709082782268524
Test set avg_accuracy=83.27% avg_sensitivity=66.15%, avg_specificity=89.80% avg_auc=86.73%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.158276 Test loss=0.406628 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15579307079315186
[5/24] Train loss=0.14299167692661285
[10/24] Train loss=0.1541942059993744
[15/24] Train loss=0.14530621469020844
[20/24] Train loss=0.1468610316514969
Test set avg_accuracy=83.39% avg_sensitivity=58.89%, avg_specificity=92.73% avg_auc=84.50%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.153371 Test loss=0.427291 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.15408605337142944
[5/24] Train loss=0.13330189883708954
[10/24] Train loss=0.1586376428604126
[15/24] Train loss=0.1443844586610794
[20/24] Train loss=0.157770574092865
Test set avg_accuracy=83.22% avg_sensitivity=64.97%, avg_specificity=90.18% avg_auc=85.55%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.153599 Test loss=0.425988 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.160089910030365
[5/24] Train loss=0.13354834914207458
[10/24] Train loss=0.14565719664096832
[15/24] Train loss=0.14970947802066803
[20/24] Train loss=0.15587887167930603
Test set avg_accuracy=83.61% avg_sensitivity=64.07%, avg_specificity=91.06% avg_auc=86.03%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.151698 Test loss=0.411488 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.15514704585075378
[5/24] Train loss=0.1373278945684433
[10/24] Train loss=0.1436951458454132
[15/24] Train loss=0.14454598724842072
[20/24] Train loss=0.14605358242988586
Test set avg_accuracy=83.27% avg_sensitivity=60.25%, avg_specificity=92.05% avg_auc=85.53%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.149230 Test loss=0.425811 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.15216580033302307
[5/24] Train loss=0.13428658246994019
[10/24] Train loss=0.1497942954301834
[15/24] Train loss=0.14066259562969208
[20/24] Train loss=0.14519444108009338
Test set avg_accuracy=81.73% avg_sensitivity=70.06%, avg_specificity=86.18% avg_auc=86.08%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.148276 Test loss=0.429554 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14662592113018036
[5/24] Train loss=0.13310444355010986
[10/24] Train loss=0.1469043493270874
[15/24] Train loss=0.13899071514606476
[20/24] Train loss=0.1451156586408615
Test set avg_accuracy=83.02% avg_sensitivity=63.46%, avg_specificity=90.48% avg_auc=85.78%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.146622 Test loss=0.417525 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1505667120218277
[5/24] Train loss=0.12701386213302612
[10/24] Train loss=0.14028912782669067
[15/24] Train loss=0.1397165060043335
[20/24] Train loss=0.14445380866527557
Test set avg_accuracy=82.51% avg_sensitivity=60.30%, avg_specificity=90.99% avg_auc=85.67%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.145391 Test loss=0.421955 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14382432401180267
[5/24] Train loss=0.12458540499210358
[10/24] Train loss=0.13769102096557617
[15/24] Train loss=0.1356126070022583
[20/24] Train loss=0.1439080387353897
Test set avg_accuracy=82.88% avg_sensitivity=62.71%, avg_specificity=90.57% avg_auc=86.04%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.142393 Test loss=0.414622 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.14524434506893158
[5/24] Train loss=0.12751755118370056
[10/24] Train loss=0.13999316096305847
[15/24] Train loss=0.1336210072040558
[20/24] Train loss=0.13678839802742004
Test set avg_accuracy=82.97% avg_sensitivity=60.44%, avg_specificity=91.56% avg_auc=85.50%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.139941 Test loss=0.423334 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.14269879460334778
[5/24] Train loss=0.12302489578723907
[10/24] Train loss=0.13488474488258362
[15/24] Train loss=0.13360527157783508
[20/24] Train loss=0.13817177712917328
Test set avg_accuracy=82.92% avg_sensitivity=59.12%, avg_specificity=91.99% avg_auc=85.77%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.139974 Test loss=0.418616 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13830316066741943
[5/24] Train loss=0.12459122389554977
[10/24] Train loss=0.13832548260688782
[15/24] Train loss=0.13096454739570618
[20/24] Train loss=0.13415758311748505
Test set avg_accuracy=83.79% avg_sensitivity=62.33%, avg_specificity=91.98% avg_auc=86.38%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.138278 Test loss=0.403250 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1366625875234604
[5/24] Train loss=0.12273874133825302
[10/24] Train loss=0.13650278747081757
[15/24] Train loss=0.1293300986289978
[20/24] Train loss=0.1380888670682907
Test set avg_accuracy=82.98% avg_sensitivity=60.73%, avg_specificity=91.47% avg_auc=85.93%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.137348 Test loss=0.417792 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13777749240398407
[5/24] Train loss=0.12546727061271667
[10/24] Train loss=0.13020777702331543
[15/24] Train loss=0.13046714663505554
[20/24] Train loss=0.1373726725578308
Test set avg_accuracy=82.89% avg_sensitivity=63.88%, avg_specificity=90.14% avg_auc=86.34%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.137330 Test loss=0.408403 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13968870043754578
[5/24] Train loss=0.12529371678829193
[10/24] Train loss=0.13880911469459534
[15/24] Train loss=0.12960824370384216
[20/24] Train loss=0.13715709745883942
Test set avg_accuracy=83.23% avg_sensitivity=64.21%, avg_specificity=90.48% avg_auc=85.99%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.137780 Test loss=0.414686 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.14042514562606812
[5/24] Train loss=0.12155669927597046
[10/24] Train loss=0.13724815845489502
[15/24] Train loss=0.13186267018318176
[20/24] Train loss=0.13613221049308777
Test set avg_accuracy=82.88% avg_sensitivity=62.23%, avg_specificity=90.75% avg_auc=85.97%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.136738 Test loss=0.418674 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.14189812541007996
[5/24] Train loss=0.12471199780702591
[10/24] Train loss=0.1356571912765503
[15/24] Train loss=0.13232193887233734
[20/24] Train loss=0.1380021870136261
Test set avg_accuracy=83.07% avg_sensitivity=62.85%, avg_specificity=90.79% avg_auc=86.27%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.136385 Test loss=0.411532 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13653108477592468
[5/24] Train loss=0.1256520301103592
[10/24] Train loss=0.13046318292617798
[15/24] Train loss=0.1306965947151184
[20/24] Train loss=0.13421790301799774
Test set avg_accuracy=83.01% avg_sensitivity=63.65%, avg_specificity=90.39% avg_auc=86.05%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.135518 Test loss=0.413211 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1350659430027008
[5/24] Train loss=0.12313411384820938
[10/24] Train loss=0.12752465903759003
[15/24] Train loss=0.1259276568889618
[20/24] Train loss=0.1352527141571045
Test set avg_accuracy=83.33% avg_sensitivity=63.65%, avg_specificity=90.84% avg_auc=86.42%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.133676 Test loss=0.408214 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1338430792093277
[5/24] Train loss=0.12029530107975006
[10/24] Train loss=0.12796664237976074
[15/24] Train loss=0.12558358907699585
[20/24] Train loss=0.13142432272434235
Test set avg_accuracy=83.10% avg_sensitivity=62.56%, avg_specificity=90.93% avg_auc=85.81%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.132154 Test loss=0.417411 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.132330521941185
[5/24] Train loss=0.11828882247209549
[10/24] Train loss=0.12966522574424744
[15/24] Train loss=0.12572644650936127
[20/24] Train loss=0.13015912473201752
Test set avg_accuracy=82.89% avg_sensitivity=61.62%, avg_specificity=91.01% avg_auc=85.73%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.131157 Test loss=0.419436 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13288754224777222
[5/24] Train loss=0.11746922880411148
[10/24] Train loss=0.128714457154274
[15/24] Train loss=0.12548677623271942
[20/24] Train loss=0.1312706172466278
Test set avg_accuracy=83.35% avg_sensitivity=63.55%, avg_specificity=90.90% avg_auc=86.30%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.131049 Test loss=0.408485 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1313120573759079
[5/24] Train loss=0.11759863793849945
[10/24] Train loss=0.12696239352226257
[15/24] Train loss=0.12793441116809845
[20/24] Train loss=0.12847061455249786
Test set avg_accuracy=83.23% avg_sensitivity=62.42%, avg_specificity=91.17% avg_auc=86.11%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.130617 Test loss=0.412114 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13120728731155396
[5/24] Train loss=0.12000880390405655
[10/24] Train loss=0.12663446366786957
[15/24] Train loss=0.12358909100294113
[20/24] Train loss=0.13059325516223907
Test set avg_accuracy=83.44% avg_sensitivity=64.26%, avg_specificity=90.75% avg_auc=86.36%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.130560 Test loss=0.408771 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.13091765344142914
[5/24] Train loss=0.12003283947706223
[10/24] Train loss=0.12628579139709473
[15/24] Train loss=0.12476231902837753
[20/24] Train loss=0.13060660660266876
Test set avg_accuracy=83.01% avg_sensitivity=61.29%, avg_specificity=91.29% avg_auc=86.01%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.130097 Test loss=0.413609 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13164371252059937
[5/24] Train loss=0.1148829534649849
[10/24] Train loss=0.12730340659618378
[15/24] Train loss=0.12331588566303253
[20/24] Train loss=0.12887486815452576
Test set avg_accuracy=83.12% avg_sensitivity=61.81%, avg_specificity=91.26% avg_auc=85.81%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.129239 Test loss=0.415228 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13101965188980103
[5/24] Train loss=0.11778344959020615
[10/24] Train loss=0.12650522589683533
[15/24] Train loss=0.12221168726682663
[20/24] Train loss=0.12996380031108856
Test set avg_accuracy=83.23% avg_sensitivity=62.38%, avg_specificity=91.19% avg_auc=85.97%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.129524 Test loss=0.413074 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12998226284980774
[5/24] Train loss=0.11591703444719315
[10/24] Train loss=0.12677517533302307
[15/24] Train loss=0.12226106971502304
[20/24] Train loss=0.12884193658828735
Test set avg_accuracy=83.44% avg_sensitivity=62.75%, avg_specificity=91.33% avg_auc=86.06%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.128979 Test loss=0.412962 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12839314341545105
[5/24] Train loss=0.1170920804142952
[10/24] Train loss=0.12458019703626633
[15/24] Train loss=0.12099184840917587
[20/24] Train loss=0.1290779709815979
Test set avg_accuracy=83.53% avg_sensitivity=63.46%, avg_specificity=91.19% avg_auc=86.06%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.128721 Test loss=0.412499 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12988078594207764
[5/24] Train loss=0.11695754528045654
[10/24] Train loss=0.12532299757003784
[15/24] Train loss=0.12310295552015305
[20/24] Train loss=0.13057658076286316
Test set avg_accuracy=83.28% avg_sensitivity=63.18%, avg_specificity=90.95% avg_auc=85.97%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.128636 Test loss=0.413810 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1297449916601181
[5/24] Train loss=0.11814172565937042
[10/24] Train loss=0.12363218516111374
[15/24] Train loss=0.12260542809963226
[20/24] Train loss=0.13243305683135986
Test set avg_accuracy=83.28% avg_sensitivity=63.04%, avg_specificity=91.01% avg_auc=85.99%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.128780 Test loss=0.413586 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12905971705913544
[5/24] Train loss=0.11775306612253189
[10/24] Train loss=0.12719354033470154
[15/24] Train loss=0.12197794020175934
[20/24] Train loss=0.12823939323425293
Test set avg_accuracy=83.36% avg_sensitivity=63.18%, avg_specificity=91.06% avg_auc=85.99%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.128052 Test loss=0.413658 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12946821749210358
[5/24] Train loss=0.11552789062261581
[10/24] Train loss=0.12422722578048706
[15/24] Train loss=0.12433017790317535
[20/24] Train loss=0.12834049761295319
Test set avg_accuracy=83.26% avg_sensitivity=62.61%, avg_specificity=91.13% avg_auc=85.95%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.128271 Test loss=0.414264 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1305563598871231
[5/24] Train loss=0.11650742590427399
[10/24] Train loss=0.1255614012479782
[15/24] Train loss=0.12194892764091492
[20/24] Train loss=0.12784148752689362
Test set avg_accuracy=83.35% avg_sensitivity=63.04%, avg_specificity=91.10% avg_auc=85.98%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.128960 Test loss=0.413544 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12973393499851227
[5/24] Train loss=0.11743958294391632
[10/24] Train loss=0.12287534773349762
[15/24] Train loss=0.12206779420375824
[20/24] Train loss=0.12821096181869507
Test set avg_accuracy=83.29% avg_sensitivity=62.89%, avg_specificity=91.08% avg_auc=85.96%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.128421 Test loss=0.413876 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12918798625469208
[5/24] Train loss=0.11617284268140793
[10/24] Train loss=0.12758758664131165
[15/24] Train loss=0.12325411289930344
[20/24] Train loss=0.13052982091903687
Test set avg_accuracy=83.27% avg_sensitivity=62.80%, avg_specificity=91.08% avg_auc=85.96%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.128577 Test loss=0.414137 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=83.59% sen=69.45%, spe=88.99%, auc=88.17%!
Fold[7] Avg_overlap=0.62%(±0.2912417788474216)
[0/24] Train loss=0.7649037837982178
[5/24] Train loss=0.7603204250335693
[10/24] Train loss=0.7477681636810303
[15/24] Train loss=0.7379212379455566
[20/24] Train loss=0.7325757145881653
Test set avg_accuracy=56.02% avg_sensitivity=52.87%, avg_specificity=57.07% avg_auc=57.05%
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.743687 Test loss=0.690184 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7158243060112
[5/24] Train loss=0.7158735990524292
[10/24] Train loss=0.7090617418289185
[15/24] Train loss=0.7065825462341309
[20/24] Train loss=0.6970323324203491
Test set avg_accuracy=61.00% avg_sensitivity=67.37%, avg_specificity=58.86% avg_auc=67.67%
Best model saved!! Metric=-71.0944506067346!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.713039 Test loss=0.669001 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6914028525352478
[5/24] Train loss=0.6894281506538391
[10/24] Train loss=0.6864404678344727
[15/24] Train loss=0.6834414601325989
[20/24] Train loss=0.6796611547470093
Test set avg_accuracy=63.54% avg_sensitivity=69.55%, avg_specificity=61.52% avg_auc=71.29%
Best model saved!! Metric=-60.09927581953699!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.688786 Test loss=0.644582 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.662463903427124
[5/24] Train loss=0.6628623604774475
[10/24] Train loss=0.6646620631217957
[15/24] Train loss=0.6626253128051758
[20/24] Train loss=0.6554115414619446
Test set avg_accuracy=65.65% avg_sensitivity=70.53%, avg_specificity=64.01% avg_auc=73.48%
Best model saved!! Metric=-52.32741602831533!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.666944 Test loss=0.620971 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6301767826080322
[5/24] Train loss=0.6412214040756226
[10/24] Train loss=0.6396960020065308
[15/24] Train loss=0.6416359543800354
[20/24] Train loss=0.6351016163825989
Test set avg_accuracy=67.68% avg_sensitivity=70.95%, avg_specificity=66.59% avg_auc=75.39%
Best model saved!! Metric=-45.39467639451598!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.644533 Test loss=0.600635 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6088159680366516
[5/24] Train loss=0.612885057926178
[10/24] Train loss=0.6222693920135498
[15/24] Train loss=0.6178560853004456
[20/24] Train loss=0.6173862218856812
Test set avg_accuracy=70.48% avg_sensitivity=71.41%, avg_specificity=70.17% avg_auc=77.13%
Best model saved!! Metric=-36.809979273118!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.624022 Test loss=0.578659 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5924597978591919
[5/24] Train loss=0.5996306538581848
[10/24] Train loss=0.6037754416465759
[15/24] Train loss=0.5971307158470154
[20/24] Train loss=0.5873705744743347
Test set avg_accuracy=72.76% avg_sensitivity=69.86%, avg_specificity=73.73% avg_auc=78.86%
Best model saved!! Metric=-30.784990325061074!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.603384 Test loss=0.553012 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5659531354904175
[5/24] Train loss=0.5731252431869507
[10/24] Train loss=0.5820473432540894
[15/24] Train loss=0.5774806141853333
[20/24] Train loss=0.5649621486663818
Test set avg_accuracy=74.64% avg_sensitivity=67.53%, avg_specificity=77.02% avg_auc=80.23%
Best model saved!! Metric=-26.58196966373245!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.580750 Test loss=0.527101 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5521823167800903
[5/24] Train loss=0.5511630177497864
[10/24] Train loss=0.5602310299873352
[15/24] Train loss=0.5548515319824219
[20/24] Train loss=0.5344871878623962
Test set avg_accuracy=76.21% avg_sensitivity=64.06%, avg_specificity=80.29% avg_auc=81.16%
Best model saved!! Metric=-24.27710306526977!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.557403 Test loss=0.501537 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5259550213813782
[5/24] Train loss=0.526347815990448
[10/24] Train loss=0.5343316197395325
[15/24] Train loss=0.5338070392608643
[20/24] Train loss=0.5123588442802429
Test set avg_accuracy=78.15% avg_sensitivity=61.00%, avg_specificity=83.91% avg_auc=82.43%
Best model saved!! Metric=-20.500793669296563!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.535089 Test loss=0.475353 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5055575370788574
[5/24] Train loss=0.5037249326705933
[10/24] Train loss=0.5131982564926147
[15/24] Train loss=0.512424886226654
[20/24] Train loss=0.4856629967689514
Test set avg_accuracy=79.27% avg_sensitivity=62.04%, avg_specificity=85.06% avg_auc=83.52%
Best model saved!! Metric=-16.110705923398235!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.511977 Test loss=0.457040 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4862613379955292
[5/24] Train loss=0.4798399806022644
[10/24] Train loss=0.4918792247772217
[15/24] Train loss=0.49263638257980347
[20/24] Train loss=0.4639969766139984
Test set avg_accuracy=80.25% avg_sensitivity=59.35%, avg_specificity=87.27% avg_auc=84.28%
Best model saved!! Metric=-14.860166970690223!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.488627 Test loss=0.440923 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4682556986808777
[5/24] Train loss=0.45843225717544556
[10/24] Train loss=0.47388193011283875
[15/24] Train loss=0.4744108319282532
[20/24] Train loss=0.4357282817363739
Test set avg_accuracy=81.24% avg_sensitivity=57.22%, avg_specificity=89.30% avg_auc=84.83%
Best model saved!! Metric=-13.40981406574111!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.468692 Test loss=0.423972 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.45031383633613586
[5/24] Train loss=0.43830564618110657
[10/24] Train loss=0.4512956738471985
[15/24] Train loss=0.45726415514945984
[20/24] Train loss=0.4160207211971283
Test set avg_accuracy=81.69% avg_sensitivity=57.17%, avg_specificity=89.93% avg_auc=85.52%
Best model saved!! Metric=-11.68351065469863!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.450078 Test loss=0.413046 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4406086802482605
[5/24] Train loss=0.42170342803001404
[10/24] Train loss=0.4437202513217926
[15/24] Train loss=0.44226542115211487
[20/24] Train loss=0.4030030071735382
Test set avg_accuracy=82.55% avg_sensitivity=57.85%, avg_specificity=90.85% avg_auc=86.13%
Best model saved!! Metric=-8.626594984080995!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.435089 Test loss=0.403305 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.43216174840927124
[5/24] Train loss=0.4115506708621979
[10/24] Train loss=0.4304414689540863
[15/24] Train loss=0.4279221296310425
[20/24] Train loss=0.38503968715667725
Test set avg_accuracy=82.66% avg_sensitivity=52.15%, avg_specificity=92.90% avg_auc=85.83%
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.423433 Test loss=0.396689 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.42193713784217834
[5/24] Train loss=0.39697763323783875
[10/24] Train loss=0.41729578375816345
[15/24] Train loss=0.419138640165329
[20/24] Train loss=0.36831367015838623
Test set avg_accuracy=83.12% avg_sensitivity=53.44%, avg_specificity=93.09% avg_auc=86.08%
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.411134 Test loss=0.391646 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.41517043113708496
[5/24] Train loss=0.38754525780677795
[10/24] Train loss=0.41139674186706543
[15/24] Train loss=0.4102715253829956
[20/24] Train loss=0.36309531331062317
Test set avg_accuracy=83.02% avg_sensitivity=53.44%, avg_specificity=92.96% avg_auc=86.28%
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.402701 Test loss=0.388161 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3977642059326172
[5/24] Train loss=0.3810740113258362
[10/24] Train loss=0.40146052837371826
[15/24] Train loss=0.406976580619812
[20/24] Train loss=0.3524763286113739
Test set avg_accuracy=82.85% avg_sensitivity=51.32%, avg_specificity=93.44% avg_auc=85.88%
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.394617 Test loss=0.388737 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.38797858357429504
[5/24] Train loss=0.371417760848999
[10/24] Train loss=0.3939612805843353
[15/24] Train loss=0.3971206247806549
[20/24] Train loss=0.34637656807899475
Test set avg_accuracy=81.89% avg_sensitivity=39.20%, avg_specificity=96.23% avg_auc=85.00%
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.387123 Test loss=0.408134 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3864566385746002
[5/24] Train loss=0.36061957478523254
[10/24] Train loss=0.38970598578453064
[15/24] Train loss=0.3853799104690552
[20/24] Train loss=0.33823707699775696
Test set avg_accuracy=82.60% avg_sensitivity=42.88%, avg_specificity=95.95% avg_auc=85.99%
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.380380 Test loss=0.394162 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.38240846991539
[5/24] Train loss=0.36025893688201904
[10/24] Train loss=0.38974714279174805
[15/24] Train loss=0.38682201504707336
[20/24] Train loss=0.3281090259552002
Test set avg_accuracy=81.97% avg_sensitivity=38.68%, avg_specificity=96.50% avg_auc=85.02%
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.375959 Test loss=0.412159 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.37479856610298157
[5/24] Train loss=0.3497515022754669
[10/24] Train loss=0.39167502522468567
[15/24] Train loss=0.3820285499095917
[20/24] Train loss=0.32519349455833435
Test set avg_accuracy=81.05% avg_sensitivity=32.47%, avg_specificity=97.37% avg_auc=84.25%
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.371851 Test loss=0.431937 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3742486834526062
[5/24] Train loss=0.3473190367221832
[10/24] Train loss=0.3774060904979706
[15/24] Train loss=0.3697572946548462
[20/24] Train loss=0.3257102370262146
Test set avg_accuracy=81.98% avg_sensitivity=40.45%, avg_specificity=95.93% avg_auc=85.49%
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.365857 Test loss=0.408789 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.37289246916770935
[5/24] Train loss=0.35151827335357666
[10/24] Train loss=0.3681536018848419
[15/24] Train loss=0.37225693464279175
[20/24] Train loss=0.31530532240867615
Test set avg_accuracy=80.48% avg_sensitivity=30.61%, avg_specificity=97.23% avg_auc=83.88%
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.361031 Test loss=0.443016 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.36471840739250183
[5/24] Train loss=0.33764219284057617
[10/24] Train loss=0.37423548102378845
[15/24] Train loss=0.36170053482055664
[20/24] Train loss=0.316191703081131
Test set avg_accuracy=81.82% avg_sensitivity=39.98%, avg_specificity=95.88% avg_auc=85.83%
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.357248 Test loss=0.399144 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.36548709869384766
[5/24] Train loss=0.333335816860199
[10/24] Train loss=0.36924540996551514
[15/24] Train loss=0.3562573790550232
[20/24] Train loss=0.3137010633945465
Test set avg_accuracy=81.13% avg_sensitivity=34.54%, avg_specificity=96.78% avg_auc=84.73%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.354224 Test loss=0.421106 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.35467830300331116
[5/24] Train loss=0.32421642541885376
[10/24] Train loss=0.35347750782966614
[15/24] Train loss=0.35236093401908875
[20/24] Train loss=0.30601051449775696
Test set avg_accuracy=80.61% avg_sensitivity=32.52%, avg_specificity=96.76% avg_auc=84.57%
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.347193 Test loss=0.428717 Current lr=[0.000210185142098938]

[0/24] Train loss=0.35028380155563354
[5/24] Train loss=0.31722959876060486
[10/24] Train loss=0.36370977759361267
[15/24] Train loss=0.3532993793487549
[20/24] Train loss=0.30475956201553345
Test set avg_accuracy=79.75% avg_sensitivity=25.22%, avg_specificity=98.07% avg_auc=82.89%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.344525 Test loss=0.485288 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3460274636745453
[5/24] Train loss=0.3240697383880615
[10/24] Train loss=0.36472970247268677
[15/24] Train loss=0.3494001626968384
[20/24] Train loss=0.30800551176071167
Test set avg_accuracy=80.20% avg_sensitivity=28.53%, avg_specificity=97.55% avg_auc=84.20%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.342128 Test loss=0.439125 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3410530984401703
[5/24] Train loss=0.3148229718208313
[10/24] Train loss=0.363215833902359
[15/24] Train loss=0.348131388425827
[20/24] Train loss=0.3019444942474365
Test set avg_accuracy=80.21% avg_sensitivity=31.28%, avg_specificity=96.64% avg_auc=82.24%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.338355 Test loss=0.447964 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.34932079911231995
[5/24] Train loss=0.3231814205646515
[10/24] Train loss=0.354013592004776
[15/24] Train loss=0.34899094700813293
[20/24] Train loss=0.29663699865341187
Test set avg_accuracy=81.34% avg_sensitivity=36.51%, avg_specificity=96.40% avg_auc=85.42%
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.338396 Test loss=0.402684 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3440622389316559
[5/24] Train loss=0.3093508183956146
[10/24] Train loss=0.34671297669410706
[15/24] Train loss=0.340838760137558
[20/24] Train loss=0.2944367527961731
Test set avg_accuracy=77.30% avg_sensitivity=12.64%, avg_specificity=99.03% avg_auc=79.27%
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.331937 Test loss=0.553183 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3465414345264435
[5/24] Train loss=0.3125435411930084
[10/24] Train loss=0.3571798801422119
[15/24] Train loss=0.3231041133403778
[20/24] Train loss=0.2864471673965454
Test set avg_accuracy=77.94% avg_sensitivity=15.43%, avg_specificity=98.94% avg_auc=81.69%
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.330272 Test loss=0.531880 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3271528482437134
[5/24] Train loss=0.31042829155921936
[10/24] Train loss=0.3562565743923187
[15/24] Train loss=0.3326655328273773
[20/24] Train loss=0.2905135452747345
Test set avg_accuracy=78.39% avg_sensitivity=18.80%, avg_specificity=98.40% avg_auc=81.46%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.327017 Test loss=0.490211 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3393299877643585
[5/24] Train loss=0.31695762276649475
[10/24] Train loss=0.35218167304992676
[15/24] Train loss=0.3213190734386444
[20/24] Train loss=0.28526461124420166
Test set avg_accuracy=78.55% avg_sensitivity=19.47%, avg_specificity=98.40% avg_auc=80.50%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.326311 Test loss=0.545644 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.325900673866272
[5/24] Train loss=0.3075152337551117
[10/24] Train loss=0.35124483704566956
[15/24] Train loss=0.32069340348243713
[20/24] Train loss=0.2921367883682251
Test set avg_accuracy=79.41% avg_sensitivity=23.61%, avg_specificity=98.16% avg_auc=80.42%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.324672 Test loss=0.511454 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.32581526041030884
[5/24] Train loss=0.31781286001205444
[10/24] Train loss=0.35598528385162354
[15/24] Train loss=0.31720292568206787
[20/24] Train loss=0.2841870188713074
Test set avg_accuracy=76.78% avg_sensitivity=8.86%, avg_specificity=99.60% avg_auc=76.84%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.323787 Test loss=0.666065 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3306710720062256
[5/24] Train loss=0.301215261220932
[10/24] Train loss=0.34253108501434326
[15/24] Train loss=0.3229181468486786
[20/24] Train loss=0.27532896399497986
Test set avg_accuracy=78.11% avg_sensitivity=15.74%, avg_specificity=99.06% avg_auc=79.28%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.318079 Test loss=0.550498 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.31942102313041687
[5/24] Train loss=0.2994278073310852
[10/24] Train loss=0.3357878029346466
[15/24] Train loss=0.30877670645713806
[20/24] Train loss=0.2794725000858307
Test set avg_accuracy=79.23% avg_sensitivity=24.81%, avg_specificity=97.51% avg_auc=83.33%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.314773 Test loss=0.442879 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3201053738594055
[5/24] Train loss=0.3065907955169678
[10/24] Train loss=0.3392059803009033
[15/24] Train loss=0.2972376048564911
[20/24] Train loss=0.2873614728450775
Test set avg_accuracy=78.18% avg_sensitivity=17.61%, avg_specificity=98.52% avg_auc=80.64%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.315256 Test loss=0.514290 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.31775495409965515
[5/24] Train loss=0.29489433765411377
[10/24] Train loss=0.34640905261039734
[15/24] Train loss=0.3276542127132416
[20/24] Train loss=0.28283724188804626
Test set avg_accuracy=79.65% avg_sensitivity=25.17%, avg_specificity=97.95% avg_auc=82.07%
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.312264 Test loss=0.487250 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.30193522572517395
[5/24] Train loss=0.2919695973396301
[10/24] Train loss=0.3394516110420227
[15/24] Train loss=0.3050873875617981
[20/24] Train loss=0.28669556975364685
Test set avg_accuracy=80.85% avg_sensitivity=33.92%, avg_specificity=96.61% avg_auc=84.92%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.309820 Test loss=0.421937 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.31678280234336853
[5/24] Train loss=0.28403154015541077
[10/24] Train loss=0.3360467255115509
[15/24] Train loss=0.30368572473526
[20/24] Train loss=0.27570590376853943
Test set avg_accuracy=81.58% avg_sensitivity=44.54%, avg_specificity=94.02% avg_auc=84.75%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.304513 Test loss=0.404339 Current lr=[0.00029967723776099]

[0/24] Train loss=0.28796571493148804
[5/24] Train loss=0.290518194437027
[10/24] Train loss=0.3332483768463135
[15/24] Train loss=0.304126501083374
[20/24] Train loss=0.2627658545970917
Test set avg_accuracy=80.21% avg_sensitivity=30.45%, avg_specificity=96.92% avg_auc=81.75%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.302495 Test loss=0.474631 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.29319533705711365
[5/24] Train loss=0.28979867696762085
[10/24] Train loss=0.3136848509311676
[15/24] Train loss=0.29904016852378845
[20/24] Train loss=0.2717234194278717
Test set avg_accuracy=78.06% avg_sensitivity=17.40%, avg_specificity=98.43% avg_auc=75.85%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.299574 Test loss=0.569234 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.33917564153671265
[5/24] Train loss=0.29404446482658386
[10/24] Train loss=0.32554805278778076
[15/24] Train loss=0.3107490837574005
[20/24] Train loss=0.28602954745292664
Test set avg_accuracy=77.55% avg_sensitivity=13.93%, avg_specificity=98.92% avg_auc=78.73%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.312292 Test loss=0.527717 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3094945549964905
[5/24] Train loss=0.28802433609962463
[10/24] Train loss=0.33230629563331604
[15/24] Train loss=0.31197652220726013
[20/24] Train loss=0.28296005725860596
Test set avg_accuracy=77.23% avg_sensitivity=11.03%, avg_specificity=99.46% avg_auc=73.77%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.302495 Test loss=0.682429 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3061456084251404
[5/24] Train loss=0.2821452021598816
[10/24] Train loss=0.31967610120773315
[15/24] Train loss=0.2880614697933197
[20/24] Train loss=0.2789827287197113
Test set avg_accuracy=76.64% avg_sensitivity=9.17%, avg_specificity=99.30% avg_auc=74.46%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.298199 Test loss=0.546189 Current lr=[0.000298904600941902]

[0/24] Train loss=0.29610946774482727
[5/24] Train loss=0.2885403335094452
[10/24] Train loss=0.32690754532814026
[15/24] Train loss=0.2802201211452484
[20/24] Train loss=0.2576746940612793
Test set avg_accuracy=81.26% avg_sensitivity=42.78%, avg_specificity=94.19% avg_auc=82.73%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.296005 Test loss=0.434963 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2818945646286011
[5/24] Train loss=0.2808753550052643
[10/24] Train loss=0.3134840726852417
[15/24] Train loss=0.2720784842967987
[20/24] Train loss=0.2647022008895874
Test set avg_accuracy=76.91% avg_sensitivity=9.84%, avg_specificity=99.44% avg_auc=73.72%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.292091 Test loss=0.614639 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2980204224586487
[5/24] Train loss=0.2726822793483734
[10/24] Train loss=0.300711452960968
[15/24] Train loss=0.28173696994781494
[20/24] Train loss=0.2556576430797577
Test set avg_accuracy=79.14% avg_sensitivity=28.74%, avg_specificity=96.07% avg_auc=78.42%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.289863 Test loss=0.477474 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.30463749170303345
[5/24] Train loss=0.2817375063896179
[10/24] Train loss=0.31900325417518616
[15/24] Train loss=0.28811410069465637
[20/24] Train loss=0.26602575182914734
Test set avg_accuracy=79.82% avg_sensitivity=32.88%, avg_specificity=95.58% avg_auc=80.57%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.291707 Test loss=0.468569 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.29053226113319397
[5/24] Train loss=0.27524635195732117
[10/24] Train loss=0.31766659021377563
[15/24] Train loss=0.27842435240745544
[20/24] Train loss=0.2700293958187103
Test set avg_accuracy=78.62% avg_sensitivity=34.70%, avg_specificity=93.37% avg_auc=76.57%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.287283 Test loss=0.513999 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2705555558204651
[5/24] Train loss=0.27335619926452637
[10/24] Train loss=0.29871243238449097
[15/24] Train loss=0.2837583124637604
[20/24] Train loss=0.25483062863349915
Test set avg_accuracy=79.71% avg_sensitivity=27.03%, avg_specificity=97.41% avg_auc=76.41%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.284954 Test loss=0.546193 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2805507481098175
[5/24] Train loss=0.28865522146224976
[10/24] Train loss=0.30873242020606995
[15/24] Train loss=0.2958991527557373
[20/24] Train loss=0.2614798843860626
Test set avg_accuracy=78.70% avg_sensitivity=22.89%, avg_specificity=97.44% avg_auc=74.99%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.282980 Test loss=0.570808 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.269205242395401
[5/24] Train loss=0.28252485394477844
[10/24] Train loss=0.30534857511520386
[15/24] Train loss=0.2837730050086975
[20/24] Train loss=0.2517661154270172
Test set avg_accuracy=76.77% avg_sensitivity=9.63%, avg_specificity=99.32% avg_auc=77.08%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.285370 Test loss=0.561129 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.27567097544670105
[5/24] Train loss=0.27611586451530457
[10/24] Train loss=0.2907545864582062
[15/24] Train loss=0.2840329110622406
[20/24] Train loss=0.2585996687412262
Test set avg_accuracy=76.76% avg_sensitivity=8.65%, avg_specificity=99.63% avg_auc=66.22%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.286453 Test loss=0.725734 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.31742194294929504
[5/24] Train loss=0.2728552222251892
[10/24] Train loss=0.3104967176914215
[15/24] Train loss=0.2917104959487915
[20/24] Train loss=0.24478958547115326
Test set avg_accuracy=79.92% avg_sensitivity=32.42%, avg_specificity=95.88% avg_auc=80.34%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.285559 Test loss=0.462167 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.26931264996528625
[5/24] Train loss=0.2688390016555786
[10/24] Train loss=0.31150808930397034
[15/24] Train loss=0.2796313166618347
[20/24] Train loss=0.2545371353626251
Test set avg_accuracy=78.65% avg_sensitivity=33.30%, avg_specificity=93.88% avg_auc=74.41%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.280076 Test loss=0.539086 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.295163094997406
[5/24] Train loss=0.28723961114883423
[10/24] Train loss=0.3079436123371124
[15/24] Train loss=0.2748214602470398
[20/24] Train loss=0.24972474575042725
Test set avg_accuracy=78.31% avg_sensitivity=65.92%, avg_specificity=82.47% avg_auc=82.61%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.282775 Test loss=0.470813 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2786630094051361
[5/24] Train loss=0.2789813280105591
[10/24] Train loss=0.29880017042160034
[15/24] Train loss=0.2690797746181488
[20/24] Train loss=0.23763810098171234
Test set avg_accuracy=80.70% avg_sensitivity=46.61%, avg_specificity=92.16% avg_auc=81.36%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.276717 Test loss=0.442624 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2647514343261719
[5/24] Train loss=0.2586047053337097
[10/24] Train loss=0.28648364543914795
[15/24] Train loss=0.2693677842617035
[20/24] Train loss=0.2343522012233734
Test set avg_accuracy=79.71% avg_sensitivity=61.32%, avg_specificity=85.89% avg_auc=83.12%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.266825 Test loss=0.452835 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2785690426826477
[5/24] Train loss=0.2640577554702759
[10/24] Train loss=0.29974809288978577
[15/24] Train loss=0.2786024212837219
[20/24] Train loss=0.249134361743927
Test set avg_accuracy=78.62% avg_sensitivity=59.35%, avg_specificity=85.09% avg_auc=82.29%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.277944 Test loss=0.474796 Current lr=[0.000276307469034998]

[0/24] Train loss=0.27704787254333496
[5/24] Train loss=0.2528758645057678
[10/24] Train loss=0.2749192714691162
[15/24] Train loss=0.2584375739097595
[20/24] Train loss=0.2415645569562912
Test set avg_accuracy=78.65% avg_sensitivity=41.12%, avg_specificity=91.25% avg_auc=76.70%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.269288 Test loss=0.489482 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.26719188690185547
[5/24] Train loss=0.25635895133018494
[10/24] Train loss=0.26993972063064575
[15/24] Train loss=0.2535470128059387
[20/24] Train loss=0.23947177827358246
Test set avg_accuracy=79.87% avg_sensitivity=35.73%, avg_specificity=94.69% avg_auc=78.81%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.268592 Test loss=0.489596 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2548348605632782
[5/24] Train loss=0.24500831961631775
[10/24] Train loss=0.28023046255111694
[15/24] Train loss=0.2597883939743042
[20/24] Train loss=0.2390661984682083
Test set avg_accuracy=80.01% avg_sensitivity=59.76%, avg_specificity=86.82% avg_auc=84.69%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.268644 Test loss=0.421595 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2527177929878235
[5/24] Train loss=0.2502793073654175
[10/24] Train loss=0.25047120451927185
[15/24] Train loss=0.24598227441310883
[20/24] Train loss=0.22269490361213684
Test set avg_accuracy=81.25% avg_sensitivity=64.32%, avg_specificity=86.94% avg_auc=85.21%
Best model saved!! Metric=-8.281522695636426!!
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.259073 Test loss=0.426487 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.254427433013916
[5/24] Train loss=0.2669129967689514
[10/24] Train loss=0.2605098783969879
[15/24] Train loss=0.26025113463401794
[20/24] Train loss=0.22916197776794434
Test set avg_accuracy=79.78% avg_sensitivity=42.88%, avg_specificity=92.17% avg_auc=80.98%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.262014 Test loss=0.441363 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2489473819732666
[5/24] Train loss=0.24555738270282745
[10/24] Train loss=0.27248677611351013
[15/24] Train loss=0.2613086700439453
[20/24] Train loss=0.22494399547576904
Test set avg_accuracy=79.04% avg_sensitivity=39.20%, avg_specificity=92.42% avg_auc=75.06%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.260395 Test loss=0.537387 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.25568968057632446
[5/24] Train loss=0.26665613055229187
[10/24] Train loss=0.29026472568511963
[15/24] Train loss=0.24288532137870789
[20/24] Train loss=0.22201578319072723
Test set avg_accuracy=80.87% avg_sensitivity=52.25%, avg_specificity=90.49% avg_auc=82.26%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.260157 Test loss=0.476248 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.25827282667160034
[5/24] Train loss=0.25182515382766724
[10/24] Train loss=0.27319034934043884
[15/24] Train loss=0.24563224613666534
[20/24] Train loss=0.2180350422859192
Test set avg_accuracy=80.23% avg_sensitivity=40.13%, avg_specificity=93.70% avg_auc=79.50%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.260682 Test loss=0.500226 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2462305724620819
[5/24] Train loss=0.2458747923374176
[10/24] Train loss=0.27376285195350647
[15/24] Train loss=0.2359461784362793
[20/24] Train loss=0.22428648173809052
Test set avg_accuracy=80.35% avg_sensitivity=55.31%, avg_specificity=88.76% avg_auc=82.15%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.253220 Test loss=0.463561 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2501941919326782
[5/24] Train loss=0.24899736046791077
[10/24] Train loss=0.2721947133541107
[15/24] Train loss=0.2331531047821045
[20/24] Train loss=0.21848846971988678
Test set avg_accuracy=81.61% avg_sensitivity=58.73%, avg_specificity=89.30% avg_auc=83.80%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.251916 Test loss=0.439437 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.2464454621076584
[5/24] Train loss=0.23803135752677917
[10/24] Train loss=0.26319044828414917
[15/24] Train loss=0.24198204278945923
[20/24] Train loss=0.22153227031230927
Test set avg_accuracy=82.01% avg_sensitivity=58.62%, avg_specificity=89.86% avg_auc=85.44%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.249350 Test loss=0.404846 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2376175820827484
[5/24] Train loss=0.2416723668575287
[10/24] Train loss=0.2723594605922699
[15/24] Train loss=0.25624918937683105
[20/24] Train loss=0.21888087689876556
Test set avg_accuracy=78.87% avg_sensitivity=52.41%, avg_specificity=87.75% avg_auc=81.70%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.251207 Test loss=0.468979 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.25477632880210876
[5/24] Train loss=0.22925855219364166
[10/24] Train loss=0.2522125542163849
[15/24] Train loss=0.24920959770679474
[20/24] Train loss=0.2193906456232071
Test set avg_accuracy=78.98% avg_sensitivity=37.55%, avg_specificity=92.90% avg_auc=76.14%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.243011 Test loss=0.553641 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.23238374292850494
[5/24] Train loss=0.22591015696525574
[10/24] Train loss=0.2510615587234497
[15/24] Train loss=0.22309866547584534
[20/24] Train loss=0.19729387760162354
Test set avg_accuracy=77.57% avg_sensitivity=71.00%, avg_specificity=79.77% avg_auc=84.01%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.239498 Test loss=0.470545 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.23691003024578094
[5/24] Train loss=0.22697007656097412
[10/24] Train loss=0.24587590992450714
[15/24] Train loss=0.23430074751377106
[20/24] Train loss=0.20477913320064545
Test set avg_accuracy=80.03% avg_sensitivity=41.84%, avg_specificity=92.85% avg_auc=79.60%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.239284 Test loss=0.467107 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.23290811479091644
[5/24] Train loss=0.22846505045890808
[10/24] Train loss=0.24474865198135376
[15/24] Train loss=0.23212632536888123
[20/24] Train loss=0.2138497531414032
Test set avg_accuracy=80.26% avg_sensitivity=59.97%, avg_specificity=87.08% avg_auc=82.10%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.242031 Test loss=0.447013 Current lr=[0.000224838296036774]

[0/24] Train loss=0.23692438006401062
[5/24] Train loss=0.23213224112987518
[10/24] Train loss=0.24713249504566193
[15/24] Train loss=0.22674772143363953
[20/24] Train loss=0.21851219236850739
Test set avg_accuracy=80.56% avg_sensitivity=39.36%, avg_specificity=94.40% avg_auc=77.79%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.240002 Test loss=0.507468 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.24062924087047577
[5/24] Train loss=0.2429383099079132
[10/24] Train loss=0.24434822797775269
[15/24] Train loss=0.23528754711151123
[20/24] Train loss=0.21042320132255554
Test set avg_accuracy=81.08% avg_sensitivity=36.41%, avg_specificity=96.09% avg_auc=79.25%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.243466 Test loss=0.518490 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.233363538980484
[5/24] Train loss=0.21688580513000488
[10/24] Train loss=0.23663316667079926
[15/24] Train loss=0.22470560669898987
[20/24] Train loss=0.20539376139640808
Test set avg_accuracy=77.77% avg_sensitivity=66.80%, avg_specificity=81.46% avg_auc=82.03%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.233781 Test loss=0.494229 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2271847277879715
[5/24] Train loss=0.2131269872188568
[10/24] Train loss=0.23365998268127441
[15/24] Train loss=0.23991400003433228
[20/24] Train loss=0.20509934425354004
Test set avg_accuracy=79.82% avg_sensitivity=62.61%, avg_specificity=85.60% avg_auc=83.33%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.233189 Test loss=0.450953 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.22545656561851501
[5/24] Train loss=0.22504498064517975
[10/24] Train loss=0.2540287375450134
[15/24] Train loss=0.22584624588489532
[20/24] Train loss=0.20815743505954742
Test set avg_accuracy=81.65% avg_sensitivity=52.51%, avg_specificity=91.44% avg_auc=83.70%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.234122 Test loss=0.427075 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.22718748450279236
[5/24] Train loss=0.2122550755739212
[10/24] Train loss=0.22742708027362823
[15/24] Train loss=0.2162853330373764
[20/24] Train loss=0.19930987060070038
Test set avg_accuracy=81.22% avg_sensitivity=45.62%, avg_specificity=93.18% avg_auc=79.03%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.227367 Test loss=0.504387 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.21495485305786133
[5/24] Train loss=0.23400981724262238
[10/24] Train loss=0.24450010061264038
[15/24] Train loss=0.22854934632778168
[20/24] Train loss=0.21466399729251862
Test set avg_accuracy=79.74% avg_sensitivity=48.73%, avg_specificity=90.15% avg_auc=78.40%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.232787 Test loss=0.516151 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.23221461474895477
[5/24] Train loss=0.21764670312404633
[10/24] Train loss=0.22314989566802979
[15/24] Train loss=0.22500815987586975
[20/24] Train loss=0.19727367162704468
Test set avg_accuracy=81.50% avg_sensitivity=46.30%, avg_specificity=93.32% avg_auc=80.53%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.228356 Test loss=0.459126 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.23844128847122192
[5/24] Train loss=0.22194206714630127
[10/24] Train loss=0.230180025100708
[15/24] Train loss=0.21882125735282898
[20/24] Train loss=0.201679065823555
Test set avg_accuracy=78.53% avg_sensitivity=27.08%, avg_specificity=95.81% avg_auc=72.55%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.227134 Test loss=0.585241 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2429448515176773
[5/24] Train loss=0.21589592099189758
[10/24] Train loss=0.2357160747051239
[15/24] Train loss=0.2072502076625824
[20/24] Train loss=0.2091136872768402
Test set avg_accuracy=81.68% avg_sensitivity=48.16%, avg_specificity=92.94% avg_auc=82.67%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.225693 Test loss=0.446692 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.22077596187591553
[5/24] Train loss=0.20775796473026276
[10/24] Train loss=0.21653318405151367
[15/24] Train loss=0.2119395136833191
[20/24] Train loss=0.20098116993904114
Test set avg_accuracy=80.53% avg_sensitivity=53.08%, avg_specificity=89.75% avg_auc=82.69%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.220301 Test loss=0.440769 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.23256167769432068
[5/24] Train loss=0.20833401381969452
[10/24] Train loss=0.21224848926067352
[15/24] Train loss=0.2125508040189743
[20/24] Train loss=0.20994919538497925
Test set avg_accuracy=80.46% avg_sensitivity=38.74%, avg_specificity=94.47% avg_auc=80.13%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.221282 Test loss=0.474875 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.20983397960662842
[5/24] Train loss=0.21343709528446198
[10/24] Train loss=0.20947127044200897
[15/24] Train loss=0.20974433422088623
[20/24] Train loss=0.1866118460893631
Test set avg_accuracy=80.21% avg_sensitivity=43.60%, avg_specificity=92.50% avg_auc=78.09%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.218125 Test loss=0.524183 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.21407699584960938
[5/24] Train loss=0.21117588877677917
[10/24] Train loss=0.21680507063865662
[15/24] Train loss=0.21992357075214386
[20/24] Train loss=0.19886097311973572
Test set avg_accuracy=81.16% avg_sensitivity=50.23%, avg_specificity=91.55% avg_auc=80.16%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.215112 Test loss=0.469370 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.20956270396709442
[5/24] Train loss=0.20631533861160278
[10/24] Train loss=0.20029428601264954
[15/24] Train loss=0.20906203985214233
[20/24] Train loss=0.19421134889125824
Test set avg_accuracy=80.21% avg_sensitivity=50.28%, avg_specificity=90.26% avg_auc=80.79%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.210978 Test loss=0.487874 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.20587213337421417
[5/24] Train loss=0.18927069008350372
[10/24] Train loss=0.2011786699295044
[15/24] Train loss=0.2067582905292511
[20/24] Train loss=0.1869000941514969
Test set avg_accuracy=79.83% avg_sensitivity=41.17%, avg_specificity=92.82% avg_auc=77.65%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.206800 Test loss=0.504773 Current lr=[0.000156543481933168]

[0/24] Train loss=0.20410828292369843
[5/24] Train loss=0.1922173798084259
[10/24] Train loss=0.19643466174602509
[15/24] Train loss=0.20324110984802246
[20/24] Train loss=0.18726462125778198
Test set avg_accuracy=81.37% avg_sensitivity=54.69%, avg_specificity=90.33% avg_auc=83.86%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.205189 Test loss=0.437261 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.19749538600444794
[5/24] Train loss=0.20603713393211365
[10/24] Train loss=0.2072991579771042
[15/24] Train loss=0.20591023564338684
[20/24] Train loss=0.18505564332008362
Test set avg_accuracy=80.89% avg_sensitivity=55.41%, avg_specificity=89.44% avg_auc=81.27%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.209380 Test loss=0.457657 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.202435702085495
[5/24] Train loss=0.18843747675418854
[10/24] Train loss=0.20388290286064148
[15/24] Train loss=0.19745059311389923
[20/24] Train loss=0.18623672425746918
Test set avg_accuracy=81.42% avg_sensitivity=54.17%, avg_specificity=90.57% avg_auc=82.14%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.204957 Test loss=0.449159 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.20571057498455048
[5/24] Train loss=0.1964774876832962
[10/24] Train loss=0.18378736078739166
[15/24] Train loss=0.20106326043605804
[20/24] Train loss=0.17929081618785858
Test set avg_accuracy=81.84% avg_sensitivity=53.81%, avg_specificity=91.25% avg_auc=82.42%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.199273 Test loss=0.442473 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.19836775958538055
[5/24] Train loss=0.17975617945194244
[10/24] Train loss=0.19362924993038177
[15/24] Train loss=0.20925107598304749
[20/24] Train loss=0.17864705622196198
Test set avg_accuracy=81.24% avg_sensitivity=59.92%, avg_specificity=88.40% avg_auc=83.45%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.198571 Test loss=0.430796 Current lr=[0.000134135431043539]

[0/24] Train loss=0.19073161482810974
[5/24] Train loss=0.1796039342880249
[10/24] Train loss=0.18838205933570862
[15/24] Train loss=0.18889930844306946
[20/24] Train loss=0.17159180343151093
Test set avg_accuracy=81.45% avg_sensitivity=58.78%, avg_specificity=89.06% avg_auc=82.95%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.195131 Test loss=0.437089 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.18913590908050537
[5/24] Train loss=0.1707843542098999
[10/24] Train loss=0.19826020300388336
[15/24] Train loss=0.18766410648822784
[20/24] Train loss=0.16888143122196198
Test set avg_accuracy=81.69% avg_sensitivity=60.90%, avg_specificity=88.68% avg_auc=84.07%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.192624 Test loss=0.425759 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1912335753440857
[5/24] Train loss=0.1789812445640564
[10/24] Train loss=0.18865951895713806
[15/24] Train loss=0.1933152824640274
[20/24] Train loss=0.1720510721206665
Test set avg_accuracy=81.16% avg_sensitivity=50.54%, avg_specificity=91.44% avg_auc=82.53%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.191526 Test loss=0.454926 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.18179264664649963
[5/24] Train loss=0.17660577595233917
[10/24] Train loss=0.19075976312160492
[15/24] Train loss=0.18625715374946594
[20/24] Train loss=0.17875881493091583
Test set avg_accuracy=81.28% avg_sensitivity=51.42%, avg_specificity=91.30% avg_auc=79.88%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.191196 Test loss=0.468439 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.18883267045021057
[5/24] Train loss=0.17144395411014557
[10/24] Train loss=0.1800699383020401
[15/24] Train loss=0.1794297695159912
[20/24] Train loss=0.16973522305488586
Test set avg_accuracy=81.82% avg_sensitivity=57.90%, avg_specificity=89.86% avg_auc=83.30%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.188821 Test loss=0.438432 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1900177299976349
[5/24] Train loss=0.17746320366859436
[10/24] Train loss=0.18089739978313446
[15/24] Train loss=0.18615908920764923
[20/24] Train loss=0.16816143691539764
Test set avg_accuracy=80.90% avg_sensitivity=43.40%, avg_specificity=93.49% avg_auc=81.33%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.187526 Test loss=0.461066 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.19481919705867767
[5/24] Train loss=0.18202297389507294
[10/24] Train loss=0.17687149345874786
[15/24] Train loss=0.180860698223114
[20/24] Train loss=0.16810236871242523
Test set avg_accuracy=81.73% avg_sensitivity=51.53%, avg_specificity=91.88% avg_auc=81.31%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.185513 Test loss=0.452820 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.18085336685180664
[5/24] Train loss=0.18114162981510162
[10/24] Train loss=0.18318085372447968
[15/24] Train loss=0.18255119025707245
[20/24] Train loss=0.16744554042816162
Test set avg_accuracy=80.65% avg_sensitivity=60.75%, avg_specificity=87.34% avg_auc=82.66%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.184617 Test loss=0.448632 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1791125386953354
[5/24] Train loss=0.16320458054542542
[10/24] Train loss=0.1780804693698883
[15/24] Train loss=0.18711689114570618
[20/24] Train loss=0.16524197161197662
Test set avg_accuracy=79.19% avg_sensitivity=54.95%, avg_specificity=87.34% avg_auc=81.84%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.183022 Test loss=0.465699 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.17589512467384338
[5/24] Train loss=0.17792761325836182
[10/24] Train loss=0.17794950306415558
[15/24] Train loss=0.179631769657135
[20/24] Train loss=0.16338440775871277
Test set avg_accuracy=81.29% avg_sensitivity=63.13%, avg_specificity=87.39% avg_auc=84.61%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.181477 Test loss=0.431860 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.17812758684158325
[5/24] Train loss=0.16507406532764435
[10/24] Train loss=0.1652902066707611
[15/24] Train loss=0.17500729858875275
[20/24] Train loss=0.15843424201011658
Test set avg_accuracy=82.07% avg_sensitivity=50.80%, avg_specificity=92.57% avg_auc=83.79%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.177882 Test loss=0.441849 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1729598343372345
[5/24] Train loss=0.1659160852432251
[10/24] Train loss=0.17169466614723206
[15/24] Train loss=0.1765708178281784
[20/24] Train loss=0.16953767836093903
Test set avg_accuracy=80.20% avg_sensitivity=54.01%, avg_specificity=88.99% avg_auc=82.54%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.178482 Test loss=0.456476 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.17689642310142517
[5/24] Train loss=0.16194064915180206
[10/24] Train loss=0.1678047925233841
[15/24] Train loss=0.17526566982269287
[20/24] Train loss=0.15488828718662262
Test set avg_accuracy=81.21% avg_sensitivity=59.30%, avg_specificity=88.57% avg_auc=83.77%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.174522 Test loss=0.441022 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.18393297493457794
[5/24] Train loss=0.1617228239774704
[10/24] Train loss=0.17011170089244843
[15/24] Train loss=0.18123626708984375
[20/24] Train loss=0.153089240193367
Test set avg_accuracy=81.22% avg_sensitivity=61.11%, avg_specificity=87.98% avg_auc=84.57%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.172855 Test loss=0.436364 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1740218549966812
[5/24] Train loss=0.15290702879428864
[10/24] Train loss=0.1589217633008957
[15/24] Train loss=0.16810645163059235
[20/24] Train loss=0.15637147426605225
Test set avg_accuracy=81.63% avg_sensitivity=56.97%, avg_specificity=89.91% avg_auc=83.33%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.171334 Test loss=0.444092 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.16717317700386047
[5/24] Train loss=0.15423302352428436
[10/24] Train loss=0.15858881175518036
[15/24] Train loss=0.1745755821466446
[20/24] Train loss=0.14861279726028442
Test set avg_accuracy=80.62% avg_sensitivity=63.54%, avg_specificity=86.36% avg_auc=84.30%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.169727 Test loss=0.443116 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.170274555683136
[5/24] Train loss=0.1566927284002304
[10/24] Train loss=0.16329441964626312
[15/24] Train loss=0.16357405483722687
[20/24] Train loss=0.15265722572803497
Test set avg_accuracy=81.18% avg_sensitivity=63.75%, avg_specificity=87.04% avg_auc=84.46%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.169348 Test loss=0.442275 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.16655108332633972
[5/24] Train loss=0.15573225915431976
[10/24] Train loss=0.15806333720684052
[15/24] Train loss=0.1673320233821869
[20/24] Train loss=0.15744343400001526
Test set avg_accuracy=81.71% avg_sensitivity=59.61%, avg_specificity=89.13% avg_auc=83.08%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.168199 Test loss=0.450253 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.16555406153202057
[5/24] Train loss=0.16239123046398163
[10/24] Train loss=0.15343579649925232
[15/24] Train loss=0.16122163832187653
[20/24] Train loss=0.15225078165531158
Test set avg_accuracy=81.11% avg_sensitivity=61.52%, avg_specificity=87.68% avg_auc=83.33%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.166190 Test loss=0.458485 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.16417519748210907
[5/24] Train loss=0.14965477585792542
[10/24] Train loss=0.15420421957969666
[15/24] Train loss=0.16443493962287903
[20/24] Train loss=0.14675216376781464
Test set avg_accuracy=81.03% avg_sensitivity=65.46%, avg_specificity=86.26% avg_auc=83.44%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.162497 Test loss=0.457136 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1585778295993805
[5/24] Train loss=0.14571569859981537
[10/24] Train loss=0.148153617978096
[15/24] Train loss=0.15898263454437256
[20/24] Train loss=0.1480647623538971
Test set avg_accuracy=81.58% avg_sensitivity=63.39%, avg_specificity=87.68% avg_auc=83.76%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.160072 Test loss=0.450160 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1625729650259018
[5/24] Train loss=0.15504372119903564
[10/24] Train loss=0.1527666300535202
[15/24] Train loss=0.15782365202903748
[20/24] Train loss=0.14363785088062286
Test set avg_accuracy=80.76% avg_sensitivity=64.01%, avg_specificity=86.38% avg_auc=83.86%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.159300 Test loss=0.457085 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1545075625181198
[5/24] Train loss=0.14515581727027893
[10/24] Train loss=0.14555437862873077
[15/24] Train loss=0.15294890105724335
[20/24] Train loss=0.1409033238887787
Test set avg_accuracy=81.32% avg_sensitivity=59.92%, avg_specificity=88.50% avg_auc=82.15%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.156520 Test loss=0.462053 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1540755033493042
[5/24] Train loss=0.14083565771579742
[10/24] Train loss=0.14293378591537476
[15/24] Train loss=0.15204967558383942
[20/24] Train loss=0.13629837334156036
Test set avg_accuracy=81.54% avg_sensitivity=62.14%, avg_specificity=88.05% avg_auc=83.05%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.153698 Test loss=0.458527 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.15679886937141418
[5/24] Train loss=0.1436949521303177
[10/24] Train loss=0.1427985578775406
[15/24] Train loss=0.1454361230134964
[20/24] Train loss=0.1357276737689972
Test set avg_accuracy=81.12% avg_sensitivity=62.14%, avg_specificity=87.49% avg_auc=84.32%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.153287 Test loss=0.446211 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.15135695040225983
[5/24] Train loss=0.1435731053352356
[10/24] Train loss=0.14671851694583893
[15/24] Train loss=0.1505281776189804
[20/24] Train loss=0.139036625623703
Test set avg_accuracy=81.32% avg_sensitivity=62.51%, avg_specificity=87.63% avg_auc=83.58%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.153461 Test loss=0.452106 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1507434993982315
[5/24] Train loss=0.13906535506248474
[10/24] Train loss=0.1503204107284546
[15/24] Train loss=0.15095525979995728
[20/24] Train loss=0.13844506442546844
Test set avg_accuracy=81.76% avg_sensitivity=60.28%, avg_specificity=88.97% avg_auc=83.08%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.152024 Test loss=0.453943 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1538134217262268
[5/24] Train loss=0.13983744382858276
[10/24] Train loss=0.142682746052742
[15/24] Train loss=0.1445237398147583
[20/24] Train loss=0.13683752715587616
Test set avg_accuracy=81.24% avg_sensitivity=65.41%, avg_specificity=86.55% avg_auc=84.08%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.150330 Test loss=0.452341 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.14988794922828674
[5/24] Train loss=0.1395222395658493
[10/24] Train loss=0.14211080968379974
[15/24] Train loss=0.14500240981578827
[20/24] Train loss=0.13183413445949554
Test set avg_accuracy=82.11% avg_sensitivity=63.34%, avg_specificity=88.42% avg_auc=83.86%
Best model saved!! Metric=-8.278802657087425!!
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.149637 Test loss=0.446388 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.14746569097042084
[5/24] Train loss=0.13917186856269836
[10/24] Train loss=0.14099739491939545
[15/24] Train loss=0.15241119265556335
[20/24] Train loss=0.13532251119613647
Test set avg_accuracy=81.97% avg_sensitivity=64.22%, avg_specificity=87.93% avg_auc=84.30%
Best model saved!! Metric=-7.58644643070302!!
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.148880 Test loss=0.445067 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.14914670586585999
[5/24] Train loss=0.13722996413707733
[10/24] Train loss=0.1361132264137268
[15/24] Train loss=0.1441756933927536
[20/24] Train loss=0.13423030078411102
Test set avg_accuracy=81.81% avg_sensitivity=61.89%, avg_specificity=88.50% avg_auc=82.89%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.147967 Test loss=0.453588 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1478804647922516
[5/24] Train loss=0.13407720625400543
[10/24] Train loss=0.13944768905639648
[15/24] Train loss=0.1420672982931137
[20/24] Train loss=0.13183632493019104
Test set avg_accuracy=81.82% avg_sensitivity=60.69%, avg_specificity=88.92% avg_auc=83.09%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.146446 Test loss=0.454629 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1433948576450348
[5/24] Train loss=0.1364382803440094
[10/24] Train loss=0.13908499479293823
[15/24] Train loss=0.1422625035047531
[20/24] Train loss=0.13484376668930054
Test set avg_accuracy=81.90% avg_sensitivity=61.37%, avg_specificity=88.80% avg_auc=83.50%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.145832 Test loss=0.451068 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.14637736976146698
[5/24] Train loss=0.1328970044851303
[10/24] Train loss=0.1403641402721405
[15/24] Train loss=0.14134687185287476
[20/24] Train loss=0.13368071615695953
Test set avg_accuracy=81.86% avg_sensitivity=62.71%, avg_specificity=88.29% avg_auc=83.92%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.145429 Test loss=0.450241 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1456795632839203
[5/24] Train loss=0.13766488432884216
[10/24] Train loss=0.13658374547958374
[15/24] Train loss=0.1498774141073227
[20/24] Train loss=0.12831154465675354
Test set avg_accuracy=81.68% avg_sensitivity=60.38%, avg_specificity=88.83% avg_auc=82.80%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.144787 Test loss=0.456093 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.148572638630867
[5/24] Train loss=0.1334521621465683
[10/24] Train loss=0.13569432497024536
[15/24] Train loss=0.14054018259048462
[20/24] Train loss=0.13044026494026184
Test set avg_accuracy=81.32% avg_sensitivity=64.06%, avg_specificity=87.11% avg_auc=84.16%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.144119 Test loss=0.451240 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.14100676774978638
[5/24] Train loss=0.1382043957710266
[10/24] Train loss=0.1340147703886032
[15/24] Train loss=0.1385554075241089
[20/24] Train loss=0.12738868594169617
Test set avg_accuracy=81.88% avg_sensitivity=62.30%, avg_specificity=88.45% avg_auc=83.52%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.143403 Test loss=0.451117 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.14436672627925873
[5/24] Train loss=0.13210797309875488
[10/24] Train loss=0.1376056969165802
[15/24] Train loss=0.14030514657497406
[20/24] Train loss=0.12927426397800446
Test set avg_accuracy=82.03% avg_sensitivity=60.54%, avg_specificity=89.25% avg_auc=82.98%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.143245 Test loss=0.452127 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.14366205036640167
[5/24] Train loss=0.1341957151889801
[10/24] Train loss=0.13183768093585968
[15/24] Train loss=0.13917993009090424
[20/24] Train loss=0.13072974979877472
Test set avg_accuracy=81.85% avg_sensitivity=61.73%, avg_specificity=88.61% avg_auc=83.25%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.142528 Test loss=0.454160 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.14037510752677917
[5/24] Train loss=0.129688560962677
[10/24] Train loss=0.1363069862127304
[15/24] Train loss=0.136554554104805
[20/24] Train loss=0.13161149621009827
Test set avg_accuracy=81.81% avg_sensitivity=62.45%, avg_specificity=88.31% avg_auc=83.35%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.142723 Test loss=0.456807 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.14451515674591064
[5/24] Train loss=0.12933890521526337
[10/24] Train loss=0.13490404188632965
[15/24] Train loss=0.14178602397441864
[20/24] Train loss=0.12657296657562256
Test set avg_accuracy=81.72% avg_sensitivity=62.82%, avg_specificity=88.07% avg_auc=83.41%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.142439 Test loss=0.456350 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.14247362315654755
[5/24] Train loss=0.1266709268093109
[10/24] Train loss=0.13657373189926147
[15/24] Train loss=0.13844291865825653
[20/24] Train loss=0.1284187287092209
Test set avg_accuracy=82.06% avg_sensitivity=62.09%, avg_specificity=88.76% avg_auc=83.38%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.141587 Test loss=0.452920 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.14272259175777435
[5/24] Train loss=0.13214841485023499
[10/24] Train loss=0.1340610384941101
[15/24] Train loss=0.13996754586696625
[20/24] Train loss=0.12815327942371368
Test set avg_accuracy=81.98% avg_sensitivity=61.52%, avg_specificity=88.85% avg_auc=83.36%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.141858 Test loss=0.452509 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1410955935716629
[5/24] Train loss=0.1334059238433838
[10/24] Train loss=0.13353660702705383
[15/24] Train loss=0.13571524620056152
[20/24] Train loss=0.12946568429470062
Test set avg_accuracy=82.02% avg_sensitivity=61.63%, avg_specificity=88.87% avg_auc=83.31%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.141741 Test loss=0.453689 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.14241927862167358
[5/24] Train loss=0.13040053844451904
[10/24] Train loss=0.1346023678779602
[15/24] Train loss=0.13954605162143707
[20/24] Train loss=0.1291370540857315
Test set avg_accuracy=81.98% avg_sensitivity=62.09%, avg_specificity=88.66% avg_auc=83.35%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.141819 Test loss=0.454597 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.14201806485652924
[5/24] Train loss=0.12749287486076355
[10/24] Train loss=0.13701355457305908
[15/24] Train loss=0.1395275592803955
[20/24] Train loss=0.12788352370262146
Test set avg_accuracy=81.94% avg_sensitivity=62.09%, avg_specificity=88.61% avg_auc=83.40%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.142211 Test loss=0.454104 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.14213654398918152
[5/24] Train loss=0.1302807629108429
[10/24] Train loss=0.13516147434711456
[15/24] Train loss=0.13638047873973846
[20/24] Train loss=0.12774062156677246
Test set avg_accuracy=81.98% avg_sensitivity=62.30%, avg_specificity=88.59% avg_auc=83.44%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.141867 Test loss=0.453981 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.14143535494804382
[5/24] Train loss=0.13065339624881744
[10/24] Train loss=0.13011139631271362
[15/24] Train loss=0.13758035004138947
[20/24] Train loss=0.12729935348033905
Test set avg_accuracy=81.98% avg_sensitivity=62.20%, avg_specificity=88.62% avg_auc=83.41%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.141375 Test loss=0.454039 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1414114087820053
[5/24] Train loss=0.12808027863502502
[10/24] Train loss=0.1345275491476059
[15/24] Train loss=0.13508276641368866
[20/24] Train loss=0.12869024276733398
Test set avg_accuracy=81.94% avg_sensitivity=62.14%, avg_specificity=88.59% avg_auc=83.42%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.141787 Test loss=0.453864 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=81.97% sen=64.22%, spe=87.93%, auc=84.30%!
Fold[8] Avg_overlap=0.61%(±0.2914349636212717)
[0/23] Train loss=0.7348132729530334
[5/23] Train loss=0.7204170227050781
[10/23] Train loss=0.7204059958457947
[15/23] Train loss=0.7102926969528198
[20/23] Train loss=0.697205662727356
Test set avg_accuracy=61.43% avg_sensitivity=40.11%, avg_specificity=68.22% avg_auc=57.83%
Best model saved!! Metric=-98.4076398488985!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.716969 Test loss=0.659149 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.6936275959014893
[5/23] Train loss=0.6853950619697571
[10/23] Train loss=0.6886647343635559
[15/23] Train loss=0.6791905164718628
[20/23] Train loss=0.6756880283355713
Test set avg_accuracy=66.58% avg_sensitivity=53.15%, avg_specificity=70.85% avg_auc=68.43%
Best model saved!! Metric=-66.99007962014468!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.688411 Test loss=0.623069 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.6657154560089111
[5/23] Train loss=0.6564475297927856
[10/23] Train loss=0.6622331142425537
[15/23] Train loss=0.6666480302810669
[20/23] Train loss=0.6485803723335266
Test set avg_accuracy=69.19% avg_sensitivity=60.32%, avg_specificity=72.02% avg_auc=71.88%
Best model saved!! Metric=-52.58961759242121!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.664548 Test loss=0.601264 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.6560747623443604
[5/23] Train loss=0.6356950998306274
[10/23] Train loss=0.639960527420044
[15/23] Train loss=0.6394728422164917
[20/23] Train loss=0.6353017687797546
Test set avg_accuracy=71.03% avg_sensitivity=63.72%, avg_specificity=73.36% avg_auc=74.50%
Best model saved!! Metric=-43.39050204445895!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.646149 Test loss=0.582387 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.6220899820327759
[5/23] Train loss=0.6103934049606323
[10/23] Train loss=0.6245872974395752
[15/23] Train loss=0.6200001239776611
[20/23] Train loss=0.6144117712974548
Test set avg_accuracy=72.46% avg_sensitivity=65.55%, avg_specificity=74.66% avg_auc=76.23%
Best model saved!! Metric=-37.09433013300672!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.625177 Test loss=0.563578 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.6004732251167297
[5/23] Train loss=0.5904759764671326
[10/23] Train loss=0.6011106967926025
[15/23] Train loss=0.601549506187439
[20/23] Train loss=0.600462019443512
Test set avg_accuracy=73.50% avg_sensitivity=64.37%, avg_specificity=76.41% avg_auc=77.27%
Best model saved!! Metric=-34.44920222598516!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.607186 Test loss=0.548683 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.581937849521637
[5/23] Train loss=0.5694126486778259
[10/23] Train loss=0.583807110786438
[15/23] Train loss=0.5852957963943481
[20/23] Train loss=0.5742851495742798
Test set avg_accuracy=75.16% avg_sensitivity=62.64%, avg_specificity=79.14% avg_auc=78.34%
Best model saved!! Metric=-30.72233820263063!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.586215 Test loss=0.530411 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.5612351298332214
[5/23] Train loss=0.5483124256134033
[10/23] Train loss=0.5585616230964661
[15/23] Train loss=0.5680524110794067
[20/23] Train loss=0.5541942715644836
Test set avg_accuracy=76.55% avg_sensitivity=62.53%, avg_specificity=81.01% avg_auc=79.49%
Best model saved!! Metric=-26.417030556503505!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.567867 Test loss=0.512446 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.5343130826950073
[5/23] Train loss=0.5293610095977783
[10/23] Train loss=0.5452951192855835
[15/23] Train loss=0.5469440221786499
[20/23] Train loss=0.5354408025741577
Test set avg_accuracy=77.88% avg_sensitivity=60.32%, avg_specificity=83.47% avg_auc=80.47%
Best model saved!! Metric=-23.857069548960972!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.547833 Test loss=0.491674 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.5260276198387146
[5/23] Train loss=0.5091649889945984
[10/23] Train loss=0.5184014439582825
[15/23] Train loss=0.5306419730186462
[20/23] Train loss=0.5138015747070312
Test set avg_accuracy=79.02% avg_sensitivity=57.63%, avg_specificity=85.84% avg_auc=81.26%
Best model saved!! Metric=-22.250062956948497!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.527162 Test loss=0.472380 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.4957410991191864
[5/23] Train loss=0.48792019486427307
[10/23] Train loss=0.5002013444900513
[15/23] Train loss=0.5055181384086609
[20/23] Train loss=0.493364155292511
Test set avg_accuracy=80.43% avg_sensitivity=56.12%, avg_specificity=88.17% avg_auc=82.50%
Best model saved!! Metric=-18.778979482867328!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.507115 Test loss=0.453126 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.4810154438018799
[5/23] Train loss=0.46819183230400085
[10/23] Train loss=0.48064976930618286
[15/23] Train loss=0.48166120052337646
[20/23] Train loss=0.47044795751571655
Test set avg_accuracy=81.22% avg_sensitivity=56.28%, avg_specificity=89.17% avg_auc=83.72%
Best model saved!! Metric=-15.60975174151369!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.485917 Test loss=0.437277 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.46204817295074463
[5/23] Train loss=0.4465482532978058
[10/23] Train loss=0.4651971161365509
[15/23] Train loss=0.46292757987976074
[20/23] Train loss=0.4549500644207001
Test set avg_accuracy=81.71% avg_sensitivity=56.33%, avg_specificity=89.79% avg_auc=84.49%
Best model saved!! Metric=-13.686152188677333!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.468188 Test loss=0.423775 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.45083922147750854
[5/23] Train loss=0.42805618047714233
[10/23] Train loss=0.4553851783275604
[15/23] Train loss=0.4483199715614319
[20/23] Train loss=0.430510014295578
Test set avg_accuracy=81.77% avg_sensitivity=57.20%, avg_specificity=89.60% avg_auc=85.31%
Best model saved!! Metric=-12.129267311021884!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.451357 Test loss=0.415371 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.4335891306400299
[5/23] Train loss=0.4150269329547882
[10/23] Train loss=0.4399354159832001
[15/23] Train loss=0.437142938375473
[20/23] Train loss=0.41822218894958496
Test set avg_accuracy=82.43% avg_sensitivity=54.34%, avg_specificity=91.38% avg_auc=85.66%
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.436560 Test loss=0.404596 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.42788541316986084
[5/23] Train loss=0.40410980582237244
[10/23] Train loss=0.4299734830856323
[15/23] Train loss=0.4244726300239563
[20/23] Train loss=0.40386471152305603
Test set avg_accuracy=82.20% avg_sensitivity=47.55%, avg_specificity=93.24% avg_auc=85.61%
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.423268 Test loss=0.398193 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.4146963357925415
[5/23] Train loss=0.3892894983291626
[10/23] Train loss=0.41643282771110535
[15/23] Train loss=0.40780341625213623
[20/23] Train loss=0.38822710514068604
Test set avg_accuracy=82.11% avg_sensitivity=44.04%, avg_specificity=94.23% avg_auc=85.69%
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.412371 Test loss=0.394567 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.40091025829315186
[5/23] Train loss=0.3733130395412445
[10/23] Train loss=0.40850749611854553
[15/23] Train loss=0.3942195773124695
[20/23] Train loss=0.3800138533115387
Test set avg_accuracy=82.29% avg_sensitivity=44.20%, avg_specificity=94.42% avg_auc=85.61%
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.401763 Test loss=0.393949 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.40392935276031494
[5/23] Train loss=0.3689877986907959
[10/23] Train loss=0.40174245834350586
[15/23] Train loss=0.3861914277076721
[20/23] Train loss=0.37152740359306335
Test set avg_accuracy=82.24% avg_sensitivity=43.56%, avg_specificity=94.56% avg_auc=85.76%
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.394348 Test loss=0.393703 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.39107319712638855
[5/23] Train loss=0.36714431643486023
[10/23] Train loss=0.399603933095932
[15/23] Train loss=0.3837195336818695
[20/23] Train loss=0.3586694896221161
Test set avg_accuracy=81.60% avg_sensitivity=37.14%, avg_specificity=95.76% avg_auc=85.29%
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.387676 Test loss=0.407705 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.3848094642162323
[5/23] Train loss=0.3570233881473541
[10/23] Train loss=0.3922327160835266
[15/23] Train loss=0.37768232822418213
[20/23] Train loss=0.35197094082832336
Test set avg_accuracy=81.93% avg_sensitivity=38.38%, avg_specificity=95.79% avg_auc=85.51%
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.381201 Test loss=0.401841 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.3821990489959717
[5/23] Train loss=0.3550527095794678
[10/23] Train loss=0.38741374015808105
[15/23] Train loss=0.365800678730011
[20/23] Train loss=0.34806862473487854
Test set avg_accuracy=81.45% avg_sensitivity=34.82%, avg_specificity=96.29% avg_auc=84.62%
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.375825 Test loss=0.418251 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.3766529858112335
[5/23] Train loss=0.3441155254840851
[10/23] Train loss=0.3797491788864136
[15/23] Train loss=0.36336153745651245
[20/23] Train loss=0.3350631296634674
Test set avg_accuracy=79.27% avg_sensitivity=18.98%, avg_specificity=98.47% avg_auc=83.87%
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.370972 Test loss=0.459806 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.37692880630493164
[5/23] Train loss=0.34229591488838196
[10/23] Train loss=0.38510772585868835
[15/23] Train loss=0.35703811049461365
[20/23] Train loss=0.3294779062271118
Test set avg_accuracy=78.76% avg_sensitivity=16.93%, avg_specificity=98.45% avg_auc=82.72%
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.366668 Test loss=0.489259 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.3737246096134186
[5/23] Train loss=0.3379009962081909
[10/23] Train loss=0.3889105021953583
[15/23] Train loss=0.3555959463119507
[20/23] Train loss=0.32695525884628296
Test set avg_accuracy=78.20% avg_sensitivity=13.26%, avg_specificity=98.88% avg_auc=82.59%
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.362678 Test loss=0.517054 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.364118754863739
[5/23] Train loss=0.32647207379341125
[10/23] Train loss=0.37799227237701416
[15/23] Train loss=0.3500288128852844
[20/23] Train loss=0.322661817073822
Test set avg_accuracy=79.44% avg_sensitivity=19.78%, avg_specificity=98.44% avg_auc=83.74%
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.357814 Test loss=0.460088 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.3648265302181244
[5/23] Train loss=0.3315678536891937
[10/23] Train loss=0.3834109306335449
[15/23] Train loss=0.35159891843795776
[20/23] Train loss=0.31886008381843567
Test set avg_accuracy=79.79% avg_sensitivity=23.07%, avg_specificity=97.85% avg_auc=83.28%
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.355354 Test loss=0.462457 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.35738247632980347
[5/23] Train loss=0.32333651185035706
[10/23] Train loss=0.37971433997154236
[15/23] Train loss=0.34469008445739746
[20/23] Train loss=0.31706559658050537
Test set avg_accuracy=78.27% avg_sensitivity=12.67%, avg_specificity=99.16% avg_auc=82.27%
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.349401 Test loss=0.507555 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.357505738735199
[5/23] Train loss=0.331062912940979
[10/23] Train loss=0.36718428134918213
[15/23] Train loss=0.3465151786804199
[20/23] Train loss=0.3069222867488861
Test set avg_accuracy=79.80% avg_sensitivity=21.56%, avg_specificity=98.35% avg_auc=84.28%
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.348722 Test loss=0.467596 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.3493579030036926
[5/23] Train loss=0.3235780894756317
[10/23] Train loss=0.37925371527671814
[15/23] Train loss=0.3372526466846466
[20/23] Train loss=0.3032473027706146
Test set avg_accuracy=78.06% avg_sensitivity=11.43%, avg_specificity=99.28% avg_auc=81.41%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.343225 Test loss=0.540045 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.3438296616077423
[5/23] Train loss=0.32639363408088684
[10/23] Train loss=0.37979868054389954
[15/23] Train loss=0.33611777424812317
[20/23] Train loss=0.3083566427230835
Test set avg_accuracy=78.71% avg_sensitivity=15.31%, avg_specificity=98.90% avg_auc=82.84%
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.342188 Test loss=0.484297 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.34895697236061096
[5/23] Train loss=0.32391515374183655
[10/23] Train loss=0.3736630380153656
[15/23] Train loss=0.3344002068042755
[20/23] Train loss=0.3102552592754364
Test set avg_accuracy=79.69% avg_sensitivity=21.24%, avg_specificity=98.30% avg_auc=85.19%
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.338445 Test loss=0.462834 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.3461865484714508
[5/23] Train loss=0.31045326590538025
[10/23] Train loss=0.3804459869861603
[15/23] Train loss=0.31879475712776184
[20/23] Train loss=0.30286115407943726
Test set avg_accuracy=77.94% avg_sensitivity=10.84%, avg_specificity=99.31% avg_auc=82.36%
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.335481 Test loss=0.517413 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.3378656208515167
[5/23] Train loss=0.3088758587837219
[10/23] Train loss=0.36121535301208496
[15/23] Train loss=0.3289841115474701
[20/23] Train loss=0.28795236349105835
Test set avg_accuracy=77.97% avg_sensitivity=11.11%, avg_specificity=99.26% avg_auc=83.70%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.332975 Test loss=0.574678 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.32965579628944397
[5/23] Train loss=0.3115764856338501
[10/23] Train loss=0.3753100335597992
[15/23] Train loss=0.3236803710460663
[20/23] Train loss=0.3034549057483673
Test set avg_accuracy=78.07% avg_sensitivity=12.29%, avg_specificity=99.02% avg_auc=81.57%
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.331338 Test loss=0.555934 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.33123546838760376
[5/23] Train loss=0.29517415165901184
[10/23] Train loss=0.36356574296951294
[15/23] Train loss=0.32494521141052246
[20/23] Train loss=0.29541295766830444
Test set avg_accuracy=78.26% avg_sensitivity=12.29%, avg_specificity=99.26% avg_auc=81.60%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.326158 Test loss=0.530556 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.33424943685531616
[5/23] Train loss=0.2954569160938263
[10/23] Train loss=0.36383721232414246
[15/23] Train loss=0.3172326982021332
[20/23] Train loss=0.29254764318466187
Test set avg_accuracy=77.66% avg_sensitivity=9.54%, avg_specificity=99.35% avg_auc=80.24%
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.326398 Test loss=0.571283 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.32409486174583435
[5/23] Train loss=0.29840248823165894
[10/23] Train loss=0.348869651556015
[15/23] Train loss=0.3146739602088928
[20/23] Train loss=0.28187212347984314
Test set avg_accuracy=78.36% avg_sensitivity=14.93%, avg_specificity=98.56% avg_auc=81.35%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.319757 Test loss=0.520638 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.31898024678230286
[5/23] Train loss=0.2883583903312683
[10/23] Train loss=0.348158597946167
[15/23] Train loss=0.3033314645290375
[20/23] Train loss=0.28173714876174927
Test set avg_accuracy=79.47% avg_sensitivity=19.25%, avg_specificity=98.64% avg_auc=81.94%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.317911 Test loss=0.480558 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.3178904354572296
[5/23] Train loss=0.28807488083839417
[10/23] Train loss=0.3549506962299347
[15/23] Train loss=0.31557098031044006
[20/23] Train loss=0.276238352060318
Test set avg_accuracy=77.41% avg_sensitivity=8.52%, avg_specificity=99.35% avg_auc=74.33%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.319554 Test loss=0.678965 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.31991609930992126
[5/23] Train loss=0.2884785830974579
[10/23] Train loss=0.34554457664489746
[15/23] Train loss=0.30792880058288574
[20/23] Train loss=0.27162429690361023
Test set avg_accuracy=78.54% avg_sensitivity=14.18%, avg_specificity=99.04% avg_auc=79.34%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.314426 Test loss=0.513474 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.3180692791938782
[5/23] Train loss=0.28349801898002625
[10/23] Train loss=0.3461591601371765
[15/23] Train loss=0.3210650384426117
[20/23] Train loss=0.2753596007823944
Test set avg_accuracy=80.33% avg_sensitivity=26.47%, avg_specificity=97.48% avg_auc=80.01%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.315406 Test loss=0.512523 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.3099272549152374
[5/23] Train loss=0.2864706814289093
[10/23] Train loss=0.33390721678733826
[15/23] Train loss=0.30418264865875244
[20/23] Train loss=0.2648966610431671
Test set avg_accuracy=80.73% avg_sensitivity=29.22%, avg_specificity=97.13% avg_auc=82.67%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.308067 Test loss=0.480249 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.2997218072414398
[5/23] Train loss=0.27212992310523987
[10/23] Train loss=0.33211269974708557
[15/23] Train loss=0.3040551543235779
[20/23] Train loss=0.27690690755844116
Test set avg_accuracy=79.64% avg_sensitivity=23.61%, avg_specificity=97.48% avg_auc=79.64%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.306913 Test loss=0.513684 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.3249017298221588
[5/23] Train loss=0.2950717508792877
[10/23] Train loss=0.3407552242279053
[15/23] Train loss=0.28808632493019104
[20/23] Train loss=0.2743490934371948
Test set avg_accuracy=80.31% avg_sensitivity=30.94%, avg_specificity=96.03% avg_auc=81.22%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.306644 Test loss=0.478229 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.3139656186103821
[5/23] Train loss=0.2767494022846222
[10/23] Train loss=0.3507341742515564
[15/23] Train loss=0.2907954752445221
[20/23] Train loss=0.2670539915561676
Test set avg_accuracy=81.03% avg_sensitivity=33.64%, avg_specificity=96.12% avg_auc=83.58%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.306137 Test loss=0.446407 Current lr=[0.000299926900870094]

[0/23] Train loss=0.29775145649909973
[5/23] Train loss=0.27425679564476013
[10/23] Train loss=0.34549009799957275
[15/23] Train loss=0.2897520661354065
[20/23] Train loss=0.274261474609375
Test set avg_accuracy=81.71% avg_sensitivity=51.43%, avg_specificity=91.35% avg_auc=81.95%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.303786 Test loss=0.430994 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.3000318109989166
[5/23] Train loss=0.27332237362861633
[10/23] Train loss=0.3389075696468353
[15/23] Train loss=0.288690447807312
[20/23] Train loss=0.2600306272506714
Test set avg_accuracy=80.73% avg_sensitivity=30.19%, avg_specificity=96.82% avg_auc=81.00%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.301330 Test loss=0.459223 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.3071402907371521
[5/23] Train loss=0.28050440549850464
[10/23] Train loss=0.33290234208106995
[15/23] Train loss=0.27054813504219055
[20/23] Train loss=0.27447912096977234
Test set avg_accuracy=80.35% avg_sensitivity=26.85%, avg_specificity=97.39% avg_auc=81.11%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.301841 Test loss=0.461056 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.2887974679470062
[5/23] Train loss=0.27391111850738525
[10/23] Train loss=0.3235000669956207
[15/23] Train loss=0.2756481170654297
[20/23] Train loss=0.284897118806839
Test set avg_accuracy=83.05% avg_sensitivity=47.82%, avg_specificity=94.27% avg_auc=85.96%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.296622 Test loss=0.386333 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.2975504398345947
[5/23] Train loss=0.27409735321998596
[10/23] Train loss=0.3088989555835724
[15/23] Train loss=0.260993629693985
[20/23] Train loss=0.27494722604751587
Test set avg_accuracy=81.43% avg_sensitivity=46.25%, avg_specificity=92.64% avg_auc=85.07%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.293220 Test loss=0.400535 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.3078555762767792
[5/23] Train loss=0.2833822965621948
[10/23] Train loss=0.3156808018684387
[15/23] Train loss=0.27763891220092773
[20/23] Train loss=0.26059749722480774
Test set avg_accuracy=77.75% avg_sensitivity=9.33%, avg_specificity=99.54% avg_auc=73.66%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.292444 Test loss=0.562474 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.29202255606651306
[5/23] Train loss=0.2817225456237793
[10/23] Train loss=0.3267666697502136
[15/23] Train loss=0.28852057456970215
[20/23] Train loss=0.25326162576675415
Test set avg_accuracy=80.14% avg_sensitivity=29.27%, avg_specificity=96.34% avg_auc=80.74%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.296527 Test loss=0.445385 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.2835468351840973
[5/23] Train loss=0.25903239846229553
[10/23] Train loss=0.33524972200393677
[15/23] Train loss=0.2845294773578644
[20/23] Train loss=0.27042141556739807
Test set avg_accuracy=77.77% avg_sensitivity=9.92%, avg_specificity=99.38% avg_auc=74.81%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.290902 Test loss=0.515794 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.2887941002845764
[5/23] Train loss=0.2587791383266449
[10/23] Train loss=0.31764456629753113
[15/23] Train loss=0.2595950663089752
[20/23] Train loss=0.2556583285331726
Test set avg_accuracy=80.05% avg_sensitivity=21.94%, avg_specificity=98.56% avg_auc=80.59%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.285582 Test loss=0.505068 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.28031623363494873
[5/23] Train loss=0.26158344745635986
[10/23] Train loss=0.3128567934036255
[15/23] Train loss=0.2523042857646942
[20/23] Train loss=0.25286850333213806
Test set avg_accuracy=80.13% avg_sensitivity=23.45%, avg_specificity=98.18% avg_auc=79.33%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.282121 Test loss=0.470038 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.2744271755218506
[5/23] Train loss=0.2542180120944977
[10/23] Train loss=0.3047333061695099
[15/23] Train loss=0.25969159603118896
[20/23] Train loss=0.2573893368244171
Test set avg_accuracy=82.10% avg_sensitivity=41.08%, avg_specificity=95.16% avg_auc=84.07%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.281067 Test loss=0.425235 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.2676054537296295
[5/23] Train loss=0.25080859661102295
[10/23] Train loss=0.3050415813922882
[15/23] Train loss=0.26196613907814026
[20/23] Train loss=0.24599528312683105
Test set avg_accuracy=79.77% avg_sensitivity=20.81%, avg_specificity=98.54% avg_auc=78.70%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.278853 Test loss=0.597123 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.2639791667461395
[5/23] Train loss=0.24836976826190948
[10/23] Train loss=0.2918945252895355
[15/23] Train loss=0.26463401317596436
[20/23] Train loss=0.2523130774497986
Test set avg_accuracy=78.53% avg_sensitivity=13.85%, avg_specificity=99.12% avg_auc=75.02%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.276970 Test loss=0.512386 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.2810799479484558
[5/23] Train loss=0.26765888929367065
[10/23] Train loss=0.2973298728466034
[15/23] Train loss=0.26390570402145386
[20/23] Train loss=0.23874981701374054
Test set avg_accuracy=80.51% avg_sensitivity=27.98%, avg_specificity=97.24% avg_auc=78.00%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.279581 Test loss=0.489812 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.2699085772037506
[5/23] Train loss=0.24696575105190277
[10/23] Train loss=0.29602935910224915
[15/23] Train loss=0.24607881903648376
[20/23] Train loss=0.2470451146364212
Test set avg_accuracy=78.58% avg_sensitivity=14.88%, avg_specificity=98.87% avg_auc=74.06%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.271718 Test loss=0.599778 Current lr=[0.000283047938381597]

[0/23] Train loss=0.27046510577201843
[5/23] Train loss=0.2409067004919052
[10/23] Train loss=0.2731344401836395
[15/23] Train loss=0.24446512758731842
[20/23] Train loss=0.24547821283340454
Test set avg_accuracy=78.88% avg_sensitivity=17.04%, avg_specificity=98.58% avg_auc=76.92%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.270100 Test loss=0.573417 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.2598300278186798
[5/23] Train loss=0.24982553720474243
[10/23] Train loss=0.2669447362422943
[15/23] Train loss=0.24451209604740143
[20/23] Train loss=0.23368871212005615
Test set avg_accuracy=82.33% avg_sensitivity=49.27%, avg_specificity=92.86% avg_auc=84.96%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.268807 Test loss=0.404553 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.26114189624786377
[5/23] Train loss=0.23512157797813416
[10/23] Train loss=0.2983505427837372
[15/23] Train loss=0.23732765018939972
[20/23] Train loss=0.2459198534488678
Test set avg_accuracy=78.41% avg_sensitivity=14.66%, avg_specificity=98.71% avg_auc=75.34%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.266136 Test loss=0.655642 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.27774906158447266
[5/23] Train loss=0.2632111608982086
[10/23] Train loss=0.2875305414199829
[15/23] Train loss=0.25374430418014526
[20/23] Train loss=0.24238450825214386
Test set avg_accuracy=80.05% avg_sensitivity=24.91%, avg_specificity=97.61% avg_auc=78.06%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.272206 Test loss=0.495269 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.2679816782474518
[5/23] Train loss=0.23938129842281342
[10/23] Train loss=0.2658577561378479
[15/23] Train loss=0.2635936439037323
[20/23] Train loss=0.22894325852394104
Test set avg_accuracy=80.61% avg_sensitivity=27.65%, avg_specificity=97.48% avg_auc=78.11%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.265459 Test loss=0.505233 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.263577938079834
[5/23] Train loss=0.23873330652713776
[10/23] Train loss=0.27180343866348267
[15/23] Train loss=0.256746381521225
[20/23] Train loss=0.24536235630512238
Test set avg_accuracy=81.35% avg_sensitivity=35.69%, avg_specificity=95.90% avg_auc=78.68%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.264483 Test loss=0.491898 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.26726850867271423
[5/23] Train loss=0.23752129077911377
[10/23] Train loss=0.2634514570236206
[15/23] Train loss=0.25441479682922363
[20/23] Train loss=0.21565943956375122
Test set avg_accuracy=81.65% avg_sensitivity=38.60%, avg_specificity=95.36% avg_auc=79.05%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.262410 Test loss=0.453797 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.25403937697410583
[5/23] Train loss=0.23107953369617462
[10/23] Train loss=0.2766692638397217
[15/23] Train loss=0.23611603677272797
[20/23] Train loss=0.23406438529491425
Test set avg_accuracy=80.31% avg_sensitivity=28.46%, avg_specificity=96.82% avg_auc=75.18%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.256596 Test loss=0.541018 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.26152318716049194
[5/23] Train loss=0.22714807093143463
[10/23] Train loss=0.26450878381729126
[15/23] Train loss=0.2542710602283478
[20/23] Train loss=0.22250081598758698
Test set avg_accuracy=81.61% avg_sensitivity=35.85%, avg_specificity=96.19% avg_auc=78.74%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.254842 Test loss=0.476718 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.23787465691566467
[5/23] Train loss=0.22239205241203308
[10/23] Train loss=0.2575037479400635
[15/23] Train loss=0.23133544623851776
[20/23] Train loss=0.21578960120677948
Test set avg_accuracy=80.46% avg_sensitivity=30.73%, avg_specificity=96.29% avg_auc=77.53%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.252602 Test loss=0.551335 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.24373507499694824
[5/23] Train loss=0.22135652601718903
[10/23] Train loss=0.2440560907125473
[15/23] Train loss=0.23586097359657288
[20/23] Train loss=0.22821660339832306
Test set avg_accuracy=82.55% avg_sensitivity=43.40%, avg_specificity=95.02% avg_auc=81.59%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.250309 Test loss=0.431753 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.24238917231559753
[5/23] Train loss=0.21278737485408783
[10/23] Train loss=0.2564074397087097
[15/23] Train loss=0.23709355294704437
[20/23] Train loss=0.22499454021453857
Test set avg_accuracy=80.61% avg_sensitivity=27.87%, avg_specificity=97.41% avg_auc=78.33%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.249833 Test loss=0.488256 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.23446716368198395
[5/23] Train loss=0.21391135454177856
[10/23] Train loss=0.2561163902282715
[15/23] Train loss=0.22964350879192352
[20/23] Train loss=0.23335248231887817
Test set avg_accuracy=82.01% avg_sensitivity=43.45%, avg_specificity=94.28% avg_auc=81.39%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.247437 Test loss=0.446334 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.23479166626930237
[5/23] Train loss=0.22681453824043274
[10/23] Train loss=0.25611376762390137
[15/23] Train loss=0.22155387699604034
[20/23] Train loss=0.21880808472633362
Test set avg_accuracy=81.11% avg_sensitivity=52.24%, avg_specificity=90.30% avg_auc=82.59%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.243064 Test loss=0.443728 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.2370952069759369
[5/23] Train loss=0.21460513770580292
[10/23] Train loss=0.26076242327690125
[15/23] Train loss=0.230399489402771
[20/23] Train loss=0.21156318485736847
Test set avg_accuracy=80.68% avg_sensitivity=49.65%, avg_specificity=90.56% avg_auc=81.15%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.242223 Test loss=0.439531 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.24495670199394226
[5/23] Train loss=0.21950724720954895
[10/23] Train loss=0.2637298107147217
[15/23] Train loss=0.21676622331142426
[20/23] Train loss=0.2118971198797226
Test set avg_accuracy=81.93% avg_sensitivity=42.21%, avg_specificity=94.58% avg_auc=81.05%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.241534 Test loss=0.458641 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.23267649114131927
[5/23] Train loss=0.21776069700717926
[10/23] Train loss=0.2596322000026703
[15/23] Train loss=0.2136799693107605
[20/23] Train loss=0.2062101811170578
Test set avg_accuracy=81.20% avg_sensitivity=38.65%, avg_specificity=94.75% avg_auc=79.30%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.238957 Test loss=0.484607 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.23609934747219086
[5/23] Train loss=0.21869224309921265
[10/23] Train loss=0.24274380505084991
[15/23] Train loss=0.21086204051971436
[20/23] Train loss=0.20452938973903656
Test set avg_accuracy=79.86% avg_sensitivity=51.97%, avg_specificity=88.74% avg_auc=79.09%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.234876 Test loss=0.468602 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.2283177226781845
[5/23] Train loss=0.21466776728630066
[10/23] Train loss=0.23430217802524567
[15/23] Train loss=0.22321172058582306
[20/23] Train loss=0.21653102338314056
Test set avg_accuracy=80.66% avg_sensitivity=57.79%, avg_specificity=87.95% avg_auc=82.10%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.235876 Test loss=0.458396 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.24754929542541504
[5/23] Train loss=0.22124351561069489
[10/23] Train loss=0.2323177605867386
[15/23] Train loss=0.2179928719997406
[20/23] Train loss=0.2056925743818283
Test set avg_accuracy=82.21% avg_sensitivity=52.40%, avg_specificity=91.71% avg_auc=82.73%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.232246 Test loss=0.429818 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.22532112896442413
[5/23] Train loss=0.20790444314479828
[10/23] Train loss=0.25924667716026306
[15/23] Train loss=0.22221872210502625
[20/23] Train loss=0.20175053179264069
Test set avg_accuracy=81.09% avg_sensitivity=46.25%, avg_specificity=92.19% avg_auc=80.94%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.236781 Test loss=0.447891 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.2376808226108551
[5/23] Train loss=0.21277132630348206
[10/23] Train loss=0.23323051631450653
[15/23] Train loss=0.21734149754047394
[20/23] Train loss=0.20608878135681152
Test set avg_accuracy=81.78% avg_sensitivity=54.45%, avg_specificity=90.49% avg_auc=82.34%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.235709 Test loss=0.429480 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.211885005235672
[5/23] Train loss=0.20181290805339813
[10/23] Train loss=0.22762028872966766
[15/23] Train loss=0.21893444657325745
[20/23] Train loss=0.21059158444404602
Test set avg_accuracy=81.28% avg_sensitivity=45.82%, avg_specificity=92.57% avg_auc=81.02%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.229406 Test loss=0.466830 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.21726350486278534
[5/23] Train loss=0.21478524804115295
[10/23] Train loss=0.23368477821350098
[15/23] Train loss=0.21487271785736084
[20/23] Train loss=0.21469056606292725
Test set avg_accuracy=81.60% avg_sensitivity=45.77%, avg_specificity=93.01% avg_auc=79.16%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.230398 Test loss=0.451126 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.22221755981445312
[5/23] Train loss=0.20976607501506805
[10/23] Train loss=0.22253111004829407
[15/23] Train loss=0.2127114087343216
[20/23] Train loss=0.19872310757637024
Test set avg_accuracy=81.32% avg_sensitivity=59.73%, avg_specificity=88.19% avg_auc=83.71%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.226065 Test loss=0.454007 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.21786588430404663
[5/23] Train loss=0.2092224806547165
[10/23] Train loss=0.23070502281188965
[15/23] Train loss=0.20163223147392273
[20/23] Train loss=0.18481439352035522
Test set avg_accuracy=81.41% avg_sensitivity=46.09%, avg_specificity=92.65% avg_auc=78.91%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.221840 Test loss=0.478246 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.2184762805700302
[5/23] Train loss=0.2075236737728119
[10/23] Train loss=0.2296144664287567
[15/23] Train loss=0.20863108336925507
[20/23] Train loss=0.20105551183223724
Test set avg_accuracy=82.25% avg_sensitivity=47.06%, avg_specificity=93.46% avg_auc=78.48%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.222105 Test loss=0.488447 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.2077644318342209
[5/23] Train loss=0.20354725420475006
[10/23] Train loss=0.21889559924602509
[15/23] Train loss=0.21180331707000732
[20/23] Train loss=0.19028425216674805
Test set avg_accuracy=81.58% avg_sensitivity=44.26%, avg_specificity=93.46% avg_auc=81.19%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.216859 Test loss=0.474479 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.22249148786067963
[5/23] Train loss=0.190598726272583
[10/23] Train loss=0.2218986600637436
[15/23] Train loss=0.20909203588962555
[20/23] Train loss=0.1969502866268158
Test set avg_accuracy=81.39% avg_sensitivity=54.88%, avg_specificity=89.84% avg_auc=83.35%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.220030 Test loss=0.436436 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.20629578828811646
[5/23] Train loss=0.19483837485313416
[10/23] Train loss=0.21660679578781128
[15/23] Train loss=0.2048751562833786
[20/23] Train loss=0.1927822381258011
Test set avg_accuracy=82.79% avg_sensitivity=55.53%, avg_specificity=91.47% avg_auc=84.78%
Best model saved!! Metric=-11.44377893284208!!
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.214231 Test loss=0.421170 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.20963454246520996
[5/23] Train loss=0.19151392579078674
[10/23] Train loss=0.22666087746620178
[15/23] Train loss=0.2052994817495346
[20/23] Train loss=0.18671217560768127
Test set avg_accuracy=81.52% avg_sensitivity=60.59%, avg_specificity=88.19% avg_auc=84.31%
Best model saved!! Metric=-11.38584144682045!!
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.212536 Test loss=0.426826 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.19553878903388977
[5/23] Train loss=0.1956809014081955
[10/23] Train loss=0.20723725855350494
[15/23] Train loss=0.2094978541135788
[20/23] Train loss=0.19138038158416748
Test set avg_accuracy=81.61% avg_sensitivity=48.89%, avg_specificity=92.03% avg_auc=80.36%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.214699 Test loss=0.478898 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.20643159747123718
[5/23] Train loss=0.20619647204875946
[10/23] Train loss=0.22538161277770996
[15/23] Train loss=0.205104261636734
[20/23] Train loss=0.1805032193660736
Test set avg_accuracy=82.17% avg_sensitivity=49.87%, avg_specificity=92.46% avg_auc=83.00%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.212791 Test loss=0.435212 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.18848732113838196
[5/23] Train loss=0.18867677450180054
[10/23] Train loss=0.21249540150165558
[15/23] Train loss=0.1974126547574997
[20/23] Train loss=0.1760747730731964
Test set avg_accuracy=80.89% avg_sensitivity=63.13%, avg_specificity=86.54% avg_auc=84.84%
Best model saved!! Metric=-10.602962959213961!!
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.205114 Test loss=0.431424 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.1973021924495697
[5/23] Train loss=0.1807047724723816
[10/23] Train loss=0.19881585240364075
[15/23] Train loss=0.1908140331506729
[20/23] Train loss=0.18137572705745697
Test set avg_accuracy=82.20% avg_sensitivity=61.89%, avg_specificity=88.67% avg_auc=85.31%
Best model saved!! Metric=-7.93613337811238!!
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.205123 Test loss=0.424430 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.18691714107990265
[5/23] Train loss=0.1885080337524414
[10/23] Train loss=0.21107134222984314
[15/23] Train loss=0.1992521584033966
[20/23] Train loss=0.17574334144592285
Test set avg_accuracy=81.81% avg_sensitivity=56.82%, avg_specificity=89.77% avg_auc=83.78%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.206032 Test loss=0.430270 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.19117359817028046
[5/23] Train loss=0.18771561980247498
[10/23] Train loss=0.20025163888931274
[15/23] Train loss=0.18892371654510498
[20/23] Train loss=0.18349094688892365
Test set avg_accuracy=83.05% avg_sensitivity=53.58%, avg_specificity=92.43% avg_auc=84.55%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.202277 Test loss=0.424574 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.1844581961631775
[5/23] Train loss=0.1876414716243744
[10/23] Train loss=0.20894457399845123
[15/23] Train loss=0.18597206473350525
[20/23] Train loss=0.16964218020439148
Test set avg_accuracy=82.47% avg_sensitivity=41.78%, avg_specificity=95.43% avg_auc=80.88%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.196392 Test loss=0.473439 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.18486368656158447
[5/23] Train loss=0.1771443486213684
[10/23] Train loss=0.19074296951293945
[15/23] Train loss=0.18110035359859467
[20/23] Train loss=0.17603498697280884
Test set avg_accuracy=82.38% avg_sensitivity=44.69%, avg_specificity=94.39% avg_auc=82.64%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.193138 Test loss=0.452520 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.1827467828989029
[5/23] Train loss=0.17417466640472412
[10/23] Train loss=0.18326811492443085
[15/23] Train loss=0.17865599691867828
[20/23] Train loss=0.1785511076450348
Test set avg_accuracy=81.76% avg_sensitivity=41.78%, avg_specificity=94.49% avg_auc=80.53%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.191253 Test loss=0.472692 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.17784370481967926
[5/23] Train loss=0.17186599969863892
[10/23] Train loss=0.18997421860694885
[15/23] Train loss=0.18174032866954803
[20/23] Train loss=0.1729491651058197
Test set avg_accuracy=81.33% avg_sensitivity=49.92%, avg_specificity=91.33% avg_auc=79.38%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.192682 Test loss=0.458549 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.17279571294784546
[5/23] Train loss=0.17619311809539795
[10/23] Train loss=0.18742933869361877
[15/23] Train loss=0.18021167814731598
[20/23] Train loss=0.17042453587055206
Test set avg_accuracy=82.25% avg_sensitivity=51.11%, avg_specificity=92.17% avg_auc=82.94%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.189206 Test loss=0.442576 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.1745687574148178
[5/23] Train loss=0.16718193888664246
[10/23] Train loss=0.1944410800933838
[15/23] Train loss=0.1828944981098175
[20/23] Train loss=0.16228295862674713
Test set avg_accuracy=82.37% avg_sensitivity=53.96%, avg_specificity=91.42% avg_auc=83.31%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.187084 Test loss=0.428938 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.1772748976945877
[5/23] Train loss=0.16777640581130981
[10/23] Train loss=0.1737031638622284
[15/23] Train loss=0.17265304923057556
[20/23] Train loss=0.16244646906852722
Test set avg_accuracy=82.75% avg_sensitivity=48.95%, avg_specificity=93.51% avg_auc=83.28%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.183092 Test loss=0.439581 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.17857113480567932
[5/23] Train loss=0.16387157142162323
[10/23] Train loss=0.1966848373413086
[15/23] Train loss=0.17232026159763336
[20/23] Train loss=0.17340320348739624
Test set avg_accuracy=81.67% avg_sensitivity=45.34%, avg_specificity=93.24% avg_auc=77.38%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.184713 Test loss=0.490675 Current lr=[0.000112073915556435]

[0/23] Train loss=0.1814851611852646
[5/23] Train loss=0.16286809742450714
[10/23] Train loss=0.18109923601150513
[15/23] Train loss=0.178298681974411
[20/23] Train loss=0.15850380063056946
Test set avg_accuracy=81.73% avg_sensitivity=58.60%, avg_specificity=89.10% avg_auc=82.31%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.183371 Test loss=0.449389 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.1669359654188156
[5/23] Train loss=0.16371190547943115
[10/23] Train loss=0.17258910834789276
[15/23] Train loss=0.1717153787612915
[20/23] Train loss=0.16313917934894562
Test set avg_accuracy=81.64% avg_sensitivity=63.88%, avg_specificity=87.30% avg_auc=83.41%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.178545 Test loss=0.448206 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.1707867980003357
[5/23] Train loss=0.16122904419898987
[10/23] Train loss=0.1735071837902069
[15/23] Train loss=0.16755127906799316
[20/23] Train loss=0.16766679286956787
Test set avg_accuracy=81.91% avg_sensitivity=51.86%, avg_specificity=91.48% avg_auc=81.88%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.178757 Test loss=0.441926 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.16908450424671173
[5/23] Train loss=0.16614501178264618
[10/23] Train loss=0.18190157413482666
[15/23] Train loss=0.16749662160873413
[20/23] Train loss=0.16701683402061462
Test set avg_accuracy=82.90% avg_sensitivity=50.46%, avg_specificity=93.24% avg_auc=82.19%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.179433 Test loss=0.445143 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.16616500914096832
[5/23] Train loss=0.16714367270469666
[10/23] Train loss=0.1740911453962326
[15/23] Train loss=0.15717513859272003
[20/23] Train loss=0.15972170233726501
Test set avg_accuracy=79.23% avg_sensitivity=67.98%, avg_specificity=82.82% avg_auc=83.66%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.174070 Test loss=0.477021 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.16524620354175568
[5/23] Train loss=0.1553410291671753
[10/23] Train loss=0.16814520955085754
[15/23] Train loss=0.1615077704191208
[20/23] Train loss=0.1635923981666565
Test set avg_accuracy=81.28% avg_sensitivity=58.11%, avg_specificity=88.65% avg_auc=83.54%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.171529 Test loss=0.440289 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.16274166107177734
[5/23] Train loss=0.15258467197418213
[10/23] Train loss=0.1626414954662323
[15/23] Train loss=0.1667250543832779
[20/23] Train loss=0.15164874494075775
Test set avg_accuracy=81.25% avg_sensitivity=60.92%, avg_specificity=87.73% avg_auc=83.67%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.170759 Test loss=0.446228 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.1651013195514679
[5/23] Train loss=0.15034164488315582
[10/23] Train loss=0.16431987285614014
[15/23] Train loss=0.15429440140724182
[20/23] Train loss=0.15878351032733917
Test set avg_accuracy=81.02% avg_sensitivity=55.69%, avg_specificity=89.08% avg_auc=82.48%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.168140 Test loss=0.456495 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.16148339211940765
[5/23] Train loss=0.16141360998153687
[10/23] Train loss=0.157989040017128
[15/23] Train loss=0.1545787900686264
[20/23] Train loss=0.1481519490480423
Test set avg_accuracy=81.52% avg_sensitivity=51.64%, avg_specificity=91.04% avg_auc=80.78%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.166737 Test loss=0.477018 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.16418102383613586
[5/23] Train loss=0.15437868237495422
[10/23] Train loss=0.15783783793449402
[15/23] Train loss=0.15693166851997375
[20/23] Train loss=0.14896829426288605
Test set avg_accuracy=81.64% avg_sensitivity=54.34%, avg_specificity=90.33% avg_auc=82.37%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.164685 Test loss=0.460402 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.1515340954065323
[5/23] Train loss=0.14881138503551483
[10/23] Train loss=0.1557338535785675
[15/23] Train loss=0.150578573346138
[20/23] Train loss=0.1402997225522995
Test set avg_accuracy=82.84% avg_sensitivity=62.37%, avg_specificity=89.36% avg_auc=85.03%
Best model saved!! Metric=-6.403409676993299!!
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.159372 Test loss=0.417154 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.14906461536884308
[5/23] Train loss=0.14528223872184753
[10/23] Train loss=0.15692943334579468
[15/23] Train loss=0.1492687314748764
[20/23] Train loss=0.14322850108146667
Test set avg_accuracy=82.42% avg_sensitivity=59.08%, avg_specificity=89.85% avg_auc=84.09%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.157989 Test loss=0.427714 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.14827968180179596
[5/23] Train loss=0.1490393877029419
[10/23] Train loss=0.1529218852519989
[15/23] Train loss=0.14657795429229736
[20/23] Train loss=0.14169709384441376
Test set avg_accuracy=82.70% avg_sensitivity=54.72%, avg_specificity=91.61% avg_auc=83.92%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.156512 Test loss=0.438530 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.14886288344860077
[5/23] Train loss=0.14764027297496796
[10/23] Train loss=0.1541135162115097
[15/23] Train loss=0.14707572758197784
[20/23] Train loss=0.14074736833572388
Test set avg_accuracy=82.92% avg_sensitivity=60.75%, avg_specificity=89.97% avg_auc=83.99%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.154945 Test loss=0.433373 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.14393529295921326
[5/23] Train loss=0.14543965458869934
[10/23] Train loss=0.14897239208221436
[15/23] Train loss=0.14123116433620453
[20/23] Train loss=0.13550518453121185
Test set avg_accuracy=82.80% avg_sensitivity=56.82%, avg_specificity=91.07% avg_auc=83.40%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.152643 Test loss=0.436027 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.14519856870174408
[5/23] Train loss=0.1386766880750656
[10/23] Train loss=0.15131191909313202
[15/23] Train loss=0.14267674088478088
[20/23] Train loss=0.13717159628868103
Test set avg_accuracy=82.42% avg_sensitivity=55.63%, avg_specificity=90.95% avg_auc=84.48%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.150937 Test loss=0.429781 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.14247703552246094
[5/23] Train loss=0.14169494807720184
[10/23] Train loss=0.14698323607444763
[15/23] Train loss=0.13911095261573792
[20/23] Train loss=0.13242734968662262
Test set avg_accuracy=82.51% avg_sensitivity=56.12%, avg_specificity=90.92% avg_auc=83.73%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.150367 Test loss=0.438893 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.14159880578517914
[5/23] Train loss=0.14500653743743896
[10/23] Train loss=0.14341886341571808
[15/23] Train loss=0.1388283371925354
[20/23] Train loss=0.13212479650974274
Test set avg_accuracy=82.71% avg_sensitivity=59.78%, avg_specificity=90.01% avg_auc=84.02%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.147663 Test loss=0.430566 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.14611072838306427
[5/23] Train loss=0.136673241853714
[10/23] Train loss=0.1415419578552246
[15/23] Train loss=0.13966907560825348
[20/23] Train loss=0.1300644874572754
Test set avg_accuracy=83.03% avg_sensitivity=53.42%, avg_specificity=92.46% avg_auc=83.49%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.145774 Test loss=0.437165 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.1429908573627472
[5/23] Train loss=0.13725431263446808
[10/23] Train loss=0.14380869269371033
[15/23] Train loss=0.13601866364479065
[20/23] Train loss=0.13315632939338684
Test set avg_accuracy=82.42% avg_sensitivity=53.80%, avg_specificity=91.54% avg_auc=83.16%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.145312 Test loss=0.439482 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.13543479144573212
[5/23] Train loss=0.1375596523284912
[10/23] Train loss=0.13804808259010315
[15/23] Train loss=0.13819673657417297
[20/23] Train loss=0.13202780485153198
Test set avg_accuracy=82.92% avg_sensitivity=55.90%, avg_specificity=91.52% avg_auc=83.45%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.143555 Test loss=0.434241 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.13793188333511353
[5/23] Train loss=0.1356799453496933
[10/23] Train loss=0.13908590376377106
[15/23] Train loss=0.13627202808856964
[20/23] Train loss=0.13015007972717285
Test set avg_accuracy=82.97% avg_sensitivity=56.39%, avg_specificity=91.43% avg_auc=83.50%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.143147 Test loss=0.434990 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.13240520656108856
[5/23] Train loss=0.1308949887752533
[10/23] Train loss=0.13737010955810547
[15/23] Train loss=0.13430850207805634
[20/23] Train loss=0.13054996728897095
Test set avg_accuracy=82.73% avg_sensitivity=54.34%, avg_specificity=91.78% avg_auc=83.21%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.141155 Test loss=0.439740 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.13508577644824982
[5/23] Train loss=0.13188356161117554
[10/23] Train loss=0.14045773446559906
[15/23] Train loss=0.13222569227218628
[20/23] Train loss=0.1263408213853836
Test set avg_accuracy=82.43% avg_sensitivity=53.53%, avg_specificity=91.64% avg_auc=83.04%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.140623 Test loss=0.447129 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.13897350430488586
[5/23] Train loss=0.13172751665115356
[10/23] Train loss=0.13944290578365326
[15/23] Train loss=0.13752484321594238
[20/23] Train loss=0.12372918426990509
Test set avg_accuracy=82.47% avg_sensitivity=55.47%, avg_specificity=91.07% avg_auc=83.38%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.140449 Test loss=0.442539 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.13285008072853088
[5/23] Train loss=0.13174748420715332
[10/23] Train loss=0.1361023336648941
[15/23] Train loss=0.13079363107681274
[20/23] Train loss=0.12976810336112976
Test set avg_accuracy=82.73% avg_sensitivity=54.88%, avg_specificity=91.61% avg_auc=83.35%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.138921 Test loss=0.441029 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.1306396722793579
[5/23] Train loss=0.1317487508058548
[10/23] Train loss=0.13411782681941986
[15/23] Train loss=0.13335950672626495
[20/23] Train loss=0.12491598725318909
Test set avg_accuracy=82.88% avg_sensitivity=56.01%, avg_specificity=91.43% avg_auc=83.40%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.138324 Test loss=0.439284 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.13345472514629364
[5/23] Train loss=0.1297360360622406
[10/23] Train loss=0.1362198442220688
[15/23] Train loss=0.13134543597698212
[20/23] Train loss=0.12628550827503204
Test set avg_accuracy=82.66% avg_sensitivity=54.66%, avg_specificity=91.57% avg_auc=82.95%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.137556 Test loss=0.442229 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.1306886523962021
[5/23] Train loss=0.13092052936553955
[10/23] Train loss=0.13685691356658936
[15/23] Train loss=0.1382228583097458
[20/23] Train loss=0.1226353645324707
Test set avg_accuracy=82.51% avg_sensitivity=55.69%, avg_specificity=91.06% avg_auc=83.51%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.138067 Test loss=0.438173 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.1338503211736679
[5/23] Train loss=0.13083672523498535
[10/23] Train loss=0.13032957911491394
[15/23] Train loss=0.13011986017227173
[20/23] Train loss=0.12500083446502686
Test set avg_accuracy=82.83% avg_sensitivity=54.29%, avg_specificity=91.91% avg_auc=83.03%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.136442 Test loss=0.442039 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.13092663884162903
[5/23] Train loss=0.1274455338716507
[10/23] Train loss=0.1343226283788681
[15/23] Train loss=0.1322895735502243
[20/23] Train loss=0.12453782558441162
Test set avg_accuracy=82.37% avg_sensitivity=56.28%, avg_specificity=90.68% avg_auc=83.59%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.136013 Test loss=0.439610 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.12920284271240234
[5/23] Train loss=0.12839263677597046
[10/23] Train loss=0.13202707469463348
[15/23] Train loss=0.13088853657245636
[20/23] Train loss=0.12288931757211685
Test set avg_accuracy=82.89% avg_sensitivity=53.96%, avg_specificity=92.10% avg_auc=83.02%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.135673 Test loss=0.444345 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.13379845023155212
[5/23] Train loss=0.12548945844173431
[10/23] Train loss=0.13016830384731293
[15/23] Train loss=0.12843380868434906
[20/23] Train loss=0.12336329370737076
Test set avg_accuracy=82.58% avg_sensitivity=54.02%, avg_specificity=91.67% avg_auc=83.10%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.135169 Test loss=0.443202 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.12698715925216675
[5/23] Train loss=0.1287515014410019
[10/23] Train loss=0.1289621740579605
[15/23] Train loss=0.12907521426677704
[20/23] Train loss=0.12354635447263718
Test set avg_accuracy=82.73% avg_sensitivity=55.20%, avg_specificity=91.50% avg_auc=83.53%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.134864 Test loss=0.438171 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.12926948070526123
[5/23] Train loss=0.12400317192077637
[10/23] Train loss=0.12885339558124542
[15/23] Train loss=0.12556706368923187
[20/23] Train loss=0.12355601787567139
Test set avg_accuracy=82.96% avg_sensitivity=55.36%, avg_specificity=91.74% avg_auc=83.44%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.133701 Test loss=0.438859 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.12632738053798676
[5/23] Train loss=0.12725485861301422
[10/23] Train loss=0.13106343150138855
[15/23] Train loss=0.12673461437225342
[20/23] Train loss=0.12156248837709427
Test set avg_accuracy=82.83% avg_sensitivity=55.42%, avg_specificity=91.55% avg_auc=83.47%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.134050 Test loss=0.438726 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.13089501857757568
[5/23] Train loss=0.1282535344362259
[10/23] Train loss=0.13197758793830872
[15/23] Train loss=0.12647764384746552
[20/23] Train loss=0.12129973620176315
Test set avg_accuracy=82.73% avg_sensitivity=53.69%, avg_specificity=91.98% avg_auc=83.14%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.134177 Test loss=0.441808 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.12928542494773865
[5/23] Train loss=0.1265932023525238
[10/23] Train loss=0.13230445981025696
[15/23] Train loss=0.12761327624320984
[20/23] Train loss=0.12338779121637344
Test set avg_accuracy=82.86% avg_sensitivity=54.72%, avg_specificity=91.83% avg_auc=83.23%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.134332 Test loss=0.440023 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.12701855599880219
[5/23] Train loss=0.13023437559604645
[10/23] Train loss=0.13174813985824585
[15/23] Train loss=0.1262013167142868
[20/23] Train loss=0.12227236479520798
Test set avg_accuracy=82.79% avg_sensitivity=55.15%, avg_specificity=91.59% avg_auc=83.34%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.134210 Test loss=0.439721 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.12913987040519714
[5/23] Train loss=0.12560336291790009
[10/23] Train loss=0.12916958332061768
[15/23] Train loss=0.12689675390720367
[20/23] Train loss=0.12013820558786392
Test set avg_accuracy=82.75% avg_sensitivity=55.09%, avg_specificity=91.55% avg_auc=83.40%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.133866 Test loss=0.439424 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.12670806050300598
[5/23] Train loss=0.12428012490272522
[10/23] Train loss=0.1293167769908905
[15/23] Train loss=0.12598878145217896
[20/23] Train loss=0.12440335750579834
Test set avg_accuracy=82.80% avg_sensitivity=54.88%, avg_specificity=91.69% avg_auc=83.33%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.133255 Test loss=0.440036 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.127061665058136
[5/23] Train loss=0.12715765833854675
[10/23] Train loss=0.13381902873516083
[15/23] Train loss=0.1269126981496811
[20/23] Train loss=0.12301291525363922
Test set avg_accuracy=82.76% avg_sensitivity=54.72%, avg_specificity=91.69% avg_auc=83.36%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.134280 Test loss=0.439757 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.12979000806808472
[5/23] Train loss=0.1264784187078476
[10/23] Train loss=0.13281351327896118
[15/23] Train loss=0.12569361925125122
[20/23] Train loss=0.12396799027919769
Test set avg_accuracy=82.75% avg_sensitivity=54.72%, avg_specificity=91.67% avg_auc=83.36%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.134397 Test loss=0.440065 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.12719058990478516
[5/23] Train loss=0.12468940764665604
[10/23] Train loss=0.12758834660053253
[15/23] Train loss=0.12842720746994019
[20/23] Train loss=0.12306933850049973
Test set avg_accuracy=82.72% avg_sensitivity=54.77%, avg_specificity=91.62% avg_auc=83.36%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.133283 Test loss=0.439723 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=82.84% sen=62.37%, spe=89.36%, auc=85.03%!
Fold[9] Avg_overlap=0.59%(±0.2885975093350457)
[0/24] Train loss=0.7338700294494629
[5/24] Train loss=0.7143155932426453
[10/24] Train loss=0.7036846876144409
[15/24] Train loss=0.7100369930267334
[20/24] Train loss=0.6969414353370667
Test set avg_accuracy=62.11% avg_sensitivity=42.35%, avg_specificity=67.84% avg_auc=58.15%
Best model saved!! Metric=-95.54931302573301!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.710176 Test loss=0.660035 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6874733567237854
[5/24] Train loss=0.6811896562576294
[10/24] Train loss=0.684476375579834
[15/24] Train loss=0.6872352957725525
[20/24] Train loss=0.6774889826774597
Test set avg_accuracy=69.95% avg_sensitivity=55.50%, avg_specificity=74.14% avg_auc=70.15%
Best model saved!! Metric=-56.265573120426424!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.682070 Test loss=0.600913 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6582666039466858
[5/24] Train loss=0.6577470302581787
[10/24] Train loss=0.6577240824699402
[15/24] Train loss=0.6598650813102722
[20/24] Train loss=0.6562738418579102
Test set avg_accuracy=71.73% avg_sensitivity=60.25%, avg_specificity=75.06% avg_auc=73.53%
Best model saved!! Metric=-45.42450024610109!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.659440 Test loss=0.571895 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6293767690658569
[5/24] Train loss=0.6298865079879761
[10/24] Train loss=0.6392778158187866
[15/24] Train loss=0.6419540643692017
[20/24] Train loss=0.6332910060882568
Test set avg_accuracy=73.39% avg_sensitivity=62.46%, avg_specificity=76.55% avg_auc=75.65%
Best model saved!! Metric=-37.95511508876539!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.640689 Test loss=0.547788 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6071040630340576
[5/24] Train loss=0.6100499033927917
[10/24] Train loss=0.6257820725440979
[15/24] Train loss=0.6223520040512085
[20/24] Train loss=0.6119576692581177
Test set avg_accuracy=74.52% avg_sensitivity=62.51%, avg_specificity=78.00% avg_auc=77.29%
Best model saved!! Metric=-33.682466705238106!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.621560 Test loss=0.527051 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5828585028648376
[5/24] Train loss=0.586049497127533
[10/24] Train loss=0.6069144606590271
[15/24] Train loss=0.6087485551834106
[20/24] Train loss=0.5981149077415466
Test set avg_accuracy=75.60% avg_sensitivity=64.14%, avg_specificity=78.92% avg_auc=78.83%
Best model saved!! Metric=-28.509704800908295!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.602939 Test loss=0.510357 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5726149678230286
[5/24] Train loss=0.5738739967346191
[10/24] Train loss=0.5846942067146301
[15/24] Train loss=0.5875132083892822
[20/24] Train loss=0.5715997815132141
Test set avg_accuracy=77.64% avg_sensitivity=62.80%, avg_specificity=81.94% avg_auc=80.02%
Best model saved!! Metric=-23.591235448297567!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.583356 Test loss=0.488884 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5482295155525208
[5/24] Train loss=0.5565091967582703
[10/24] Train loss=0.5636067986488342
[15/24] Train loss=0.567478597164154
[20/24] Train loss=0.5493276119232178
Test set avg_accuracy=79.24% avg_sensitivity=62.57%, avg_specificity=84.08% avg_auc=80.77%
Best model saved!! Metric=-19.337420316980854!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.564430 Test loss=0.471174 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.534515380859375
[5/24] Train loss=0.5370370149612427
[10/24] Train loss=0.5485839247703552
[15/24] Train loss=0.5470258593559265
[20/24] Train loss=0.5326583981513977
Test set avg_accuracy=79.58% avg_sensitivity=62.05%, avg_specificity=84.67% avg_auc=81.51%
Best model saved!! Metric=-18.1898467950437!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.544741 Test loss=0.456596 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5139126181602478
[5/24] Train loss=0.5181654095649719
[10/24] Train loss=0.52395099401474
[15/24] Train loss=0.5305361747741699
[20/24] Train loss=0.5153617262840271
Test set avg_accuracy=81.29% avg_sensitivity=58.11%, avg_specificity=88.01% avg_auc=82.15%
Best model saved!! Metric=-16.437424187625602!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.524770 Test loss=0.433748 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4895947277545929
[5/24] Train loss=0.49712079763412476
[10/24] Train loss=0.5026851892471313
[15/24] Train loss=0.5025087594985962
[20/24] Train loss=0.4895024299621582
Test set avg_accuracy=81.91% avg_sensitivity=59.21%, avg_specificity=88.50% avg_auc=83.21%
Best model saved!! Metric=-13.166141427289588!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.503931 Test loss=0.423503 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.47808364033699036
[5/24] Train loss=0.4772568941116333
[10/24] Train loss=0.4879215359687805
[15/24] Train loss=0.4852750897407532
[20/24] Train loss=0.4666609764099121
Test set avg_accuracy=83.31% avg_sensitivity=56.14%, avg_specificity=91.18% avg_auc=84.01%
Best model saved!! Metric=-11.360412177910789!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.485646 Test loss=0.405874 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4586249887943268
[5/24] Train loss=0.46200743317604065
[10/24] Train loss=0.4711515009403229
[15/24] Train loss=0.47127625346183777
[20/24] Train loss=0.44930994510650635
Test set avg_accuracy=83.98% avg_sensitivity=55.04%, avg_specificity=92.37% avg_auc=84.65%
Best model saved!! Metric=-9.95320437933583!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.468054 Test loss=0.389708 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4406871795654297
[5/24] Train loss=0.44772496819496155
[10/24] Train loss=0.45745354890823364
[15/24] Train loss=0.4534148573875427
[20/24] Train loss=0.4320724904537201
Test set avg_accuracy=84.41% avg_sensitivity=57.01%, avg_specificity=92.36% avg_auc=85.54%
Best model saved!! Metric=-6.680603014016121!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.451308 Test loss=0.383370 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4281708002090454
[5/24] Train loss=0.42979586124420166
[10/24] Train loss=0.44456377625465393
[15/24] Train loss=0.44139501452445984
[20/24] Train loss=0.42531177401542664
Test set avg_accuracy=84.82% avg_sensitivity=56.72%, avg_specificity=92.96% avg_auc=86.05%
Best model saved!! Metric=-5.44498973307072!!
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.437522 Test loss=0.373621 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.42778512835502625
[5/24] Train loss=0.42722266912460327
[10/24] Train loss=0.435535728931427
[15/24] Train loss=0.4313652813434601
[20/24] Train loss=0.4055541455745697
Test set avg_accuracy=84.87% avg_sensitivity=50.98%, avg_specificity=94.69% avg_auc=85.93%
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.425805 Test loss=0.367062 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4129658043384552
[5/24] Train loss=0.41103681921958923
[10/24] Train loss=0.42396077513694763
[15/24] Train loss=0.4145481288433075
[20/24] Train loss=0.3963215947151184
Test set avg_accuracy=84.87% avg_sensitivity=48.84%, avg_specificity=95.31% avg_auc=86.13%
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.414713 Test loss=0.363576 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4042312800884247
[5/24] Train loss=0.4018326699733734
[10/24] Train loss=0.4184369742870331
[15/24] Train loss=0.40805259346961975
[20/24] Train loss=0.3801794648170471
Test set avg_accuracy=85.03% avg_sensitivity=49.02%, avg_specificity=95.47% avg_auc=86.71%
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.405176 Test loss=0.357460 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4007438123226166
[5/24] Train loss=0.3975852429866791
[10/24] Train loss=0.41977593302726746
[15/24] Train loss=0.39297404885292053
[20/24] Train loss=0.37382274866104126
Test set avg_accuracy=84.34% avg_sensitivity=41.77%, avg_specificity=96.67% avg_auc=85.52%
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.397894 Test loss=0.372249 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.38862383365631104
[5/24] Train loss=0.38431867957115173
[10/24] Train loss=0.40646424889564514
[15/24] Train loss=0.3891231119632721
[20/24] Train loss=0.36909350752830505
Test set avg_accuracy=84.83% avg_sensitivity=45.02%, avg_specificity=96.37% avg_auc=86.34%
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.389906 Test loss=0.362564 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3797767758369446
[5/24] Train loss=0.37968993186950684
[10/24] Train loss=0.41293102502822876
[15/24] Train loss=0.37814855575561523
[20/24] Train loss=0.356363445520401
Test set avg_accuracy=85.05% avg_sensitivity=45.94%, avg_specificity=96.39% avg_auc=86.33%
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.382151 Test loss=0.361789 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.37663233280181885
[5/24] Train loss=0.3749200105667114
[10/24] Train loss=0.4011349380016327
[15/24] Train loss=0.3771497905254364
[20/24] Train loss=0.35198360681533813
Test set avg_accuracy=85.33% avg_sensitivity=50.23%, avg_specificity=95.50% avg_auc=86.63%
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.377182 Test loss=0.355089 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3762039244174957
[5/24] Train loss=0.37439876794815063
[10/24] Train loss=0.39819222688674927
[15/24] Train loss=0.3712611198425293
[20/24] Train loss=0.3542877733707428
Test set avg_accuracy=85.70% avg_sensitivity=51.33%, avg_specificity=95.67% avg_auc=87.21%
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.373749 Test loss=0.349915 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.36559250950813293
[5/24] Train loss=0.3735635280609131
[10/24] Train loss=0.39124375581741333
[15/24] Train loss=0.36596331000328064
[20/24] Train loss=0.34281280636787415
Test set avg_accuracy=84.45% avg_sensitivity=39.57%, avg_specificity=97.46% avg_auc=85.95%
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.367161 Test loss=0.375658 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3691089153289795
[5/24] Train loss=0.36778178811073303
[10/24] Train loss=0.38915279507637024
[15/24] Train loss=0.35552215576171875
[20/24] Train loss=0.34422996640205383
Test set avg_accuracy=84.14% avg_sensitivity=38.93%, avg_specificity=97.25% avg_auc=85.64%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.365256 Test loss=0.381923 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.36439254879951477
[5/24] Train loss=0.3607538342475891
[10/24] Train loss=0.38716715574264526
[15/24] Train loss=0.35933738946914673
[20/24] Train loss=0.3392704427242279
Test set avg_accuracy=84.30% avg_sensitivity=40.38%, avg_specificity=97.03% avg_auc=86.82%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.359334 Test loss=0.366236 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3550029993057251
[5/24] Train loss=0.3620913326740265
[10/24] Train loss=0.3814011514186859
[15/24] Train loss=0.3510375916957855
[20/24] Train loss=0.32775741815567017
Test set avg_accuracy=83.12% avg_sensitivity=30.82%, avg_specificity=98.29% avg_auc=83.44%
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.358128 Test loss=0.423208 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.35465267300605774
[5/24] Train loss=0.3624957501888275
[10/24] Train loss=0.39285188913345337
[15/24] Train loss=0.3487582206726074
[20/24] Train loss=0.33314502239227295
Test set avg_accuracy=84.53% avg_sensitivity=41.48%, avg_specificity=97.01% avg_auc=86.43%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.354254 Test loss=0.365328 Current lr=[0.000210185142098938]

[0/24] Train loss=0.35741814970970154
[5/24] Train loss=0.34307950735092163
[10/24] Train loss=0.3858707547187805
[15/24] Train loss=0.348976194858551
[20/24] Train loss=0.3346896171569824
Test set avg_accuracy=84.48% avg_sensitivity=40.56%, avg_specificity=97.21% avg_auc=86.54%
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.351805 Test loss=0.366409 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3475803732872009
[5/24] Train loss=0.34676888585090637
[10/24] Train loss=0.38847771286964417
[15/24] Train loss=0.34494566917419434
[20/24] Train loss=0.32704952359199524
Test set avg_accuracy=84.05% avg_sensitivity=40.61%, avg_specificity=96.64% avg_auc=84.61%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.348197 Test loss=0.380529 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.34398481249809265
[5/24] Train loss=0.34661829471588135
[10/24] Train loss=0.385470986366272
[15/24] Train loss=0.3432910442352295
[20/24] Train loss=0.3269409239292145
Test set avg_accuracy=82.85% avg_sensitivity=28.45%, avg_specificity=98.62% avg_auc=84.16%
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.345231 Test loss=0.418776 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3426000475883484
[5/24] Train loss=0.3375316262245178
[10/24] Train loss=0.380669504404068
[15/24] Train loss=0.34208211302757263
[20/24] Train loss=0.3195740878582001
Test set avg_accuracy=83.88% avg_sensitivity=34.53%, avg_specificity=98.19% avg_auc=83.71%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.339432 Test loss=0.405248 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3440272808074951
[5/24] Train loss=0.33750224113464355
[10/24] Train loss=0.38279375433921814
[15/24] Train loss=0.33399656414985657
[20/24] Train loss=0.3216712772846222
Test set avg_accuracy=83.10% avg_sensitivity=29.55%, avg_specificity=98.62% avg_auc=85.66%
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.340827 Test loss=0.394180 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3467424511909485
[5/24] Train loss=0.3345693349838257
[10/24] Train loss=0.38624152541160583
[15/24] Train loss=0.33160263299942017
[20/24] Train loss=0.3119073808193207
Test set avg_accuracy=83.33% avg_sensitivity=30.88%, avg_specificity=98.54% avg_auc=85.82%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.336714 Test loss=0.401807 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3373691439628601
[5/24] Train loss=0.33496159315109253
[10/24] Train loss=0.3743695914745331
[15/24] Train loss=0.31520622968673706
[20/24] Train loss=0.3166722059249878
Test set avg_accuracy=83.12% avg_sensitivity=31.40%, avg_specificity=98.12% avg_auc=83.73%
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.331882 Test loss=0.410353 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3383081257343292
[5/24] Train loss=0.33469057083129883
[10/24] Train loss=0.3683992624282837
[15/24] Train loss=0.32511651515960693
[20/24] Train loss=0.30720850825309753
Test set avg_accuracy=84.90% avg_sensitivity=45.71%, avg_specificity=96.25% avg_auc=87.52%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.328526 Test loss=0.350235 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.32290732860565186
[5/24] Train loss=0.331659734249115
[10/24] Train loss=0.3713108003139496
[15/24] Train loss=0.3244233727455139
[20/24] Train loss=0.3214031457901001
Test set avg_accuracy=81.35% avg_sensitivity=70.97%, avg_specificity=84.36% avg_auc=85.92%
Best model saved!! Metric=-3.3923560172861187!!
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.329115 Test loss=0.424939 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3219134211540222
[5/24] Train loss=0.3157190978527069
[10/24] Train loss=0.35967496037483215
[15/24] Train loss=0.3195893168449402
[20/24] Train loss=0.31172722578048706
Test set avg_accuracy=84.75% avg_sensitivity=41.02%, avg_specificity=97.43% avg_auc=85.25%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.324502 Test loss=0.381991 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.32012906670570374
[5/24] Train loss=0.31609222292900085
[10/24] Train loss=0.367488831281662
[15/24] Train loss=0.3149058222770691
[20/24] Train loss=0.3038126528263092
Test set avg_accuracy=84.88% avg_sensitivity=49.54%, avg_specificity=95.13% avg_auc=85.02%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.321938 Test loss=0.371770 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.31477034091949463
[5/24] Train loss=0.30426397919654846
[10/24] Train loss=0.35986191034317017
[15/24] Train loss=0.3229728937149048
[20/24] Train loss=0.31954818964004517
Test set avg_accuracy=82.42% avg_sensitivity=29.32%, avg_specificity=97.82% avg_auc=81.74%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.322661 Test loss=0.413608 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.34436264634132385
[5/24] Train loss=0.3258677124977112
[10/24] Train loss=0.34983524680137634
[15/24] Train loss=0.3180229961872101
[20/24] Train loss=0.297707200050354
Test set avg_accuracy=85.12% avg_sensitivity=58.98%, avg_specificity=92.69% avg_auc=86.15%
Best model saved!! Metric=-3.0622737305777434!!
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.320050 Test loss=0.362077 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3108619451522827
[5/24] Train loss=0.32042792439460754
[10/24] Train loss=0.36341604590415955
[15/24] Train loss=0.30359575152397156
[20/24] Train loss=0.298868864774704
Test set avg_accuracy=83.06% avg_sensitivity=32.44%, avg_specificity=97.73% avg_auc=82.32%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.316416 Test loss=0.422312 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.32623159885406494
[5/24] Train loss=0.31251260638237
[10/24] Train loss=0.36353355646133423
[15/24] Train loss=0.30278918147087097
[20/24] Train loss=0.3051181733608246
Test set avg_accuracy=83.06% avg_sensitivity=32.16%, avg_specificity=97.82% avg_auc=82.62%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.314748 Test loss=0.407730 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3400189280509949
[5/24] Train loss=0.29479023814201355
[10/24] Train loss=0.3675910532474518
[15/24] Train loss=0.306339830160141
[20/24] Train loss=0.2926160395145416
Test set avg_accuracy=84.19% avg_sensitivity=50.81%, avg_specificity=93.87% avg_auc=83.37%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.312121 Test loss=0.390492 Current lr=[0.00029967723776099]

[0/24] Train loss=0.32469379901885986
[5/24] Train loss=0.3099239468574524
[10/24] Train loss=0.3669314980506897
[15/24] Train loss=0.2817448377609253
[20/24] Train loss=0.2919765114784241
Test set avg_accuracy=83.15% avg_sensitivity=38.82%, avg_specificity=96.00% avg_auc=83.01%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.309989 Test loss=0.418513 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.31348922848701477
[5/24] Train loss=0.3044876158237457
[10/24] Train loss=0.3685165345668793
[15/24] Train loss=0.3054731488227844
[20/24] Train loss=0.2878451943397522
Test set avg_accuracy=85.05% avg_sensitivity=63.09%, avg_specificity=91.42% avg_auc=87.40%
Best model saved!! Metric=0.9601008068099901!!
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.309412 Test loss=0.359195 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.29638999700546265
[5/24] Train loss=0.30084750056266785
[10/24] Train loss=0.3457978367805481
[15/24] Train loss=0.29584288597106934
[20/24] Train loss=0.2911044955253601
Test set avg_accuracy=82.27% avg_sensitivity=60.66%, avg_specificity=88.53% avg_auc=84.74%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.304221 Test loss=0.397520 Current lr=[0.000299720220882401]

[0/24] Train loss=0.29868197441101074
[5/24] Train loss=0.30150943994522095
[10/24] Train loss=0.34114566445350647
[15/24] Train loss=0.2889484763145447
[20/24] Train loss=0.29484039545059204
Test set avg_accuracy=82.08% avg_sensitivity=27.29%, avg_specificity=97.97% avg_auc=79.25%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.303534 Test loss=0.448123 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3215482831001282
[5/24] Train loss=0.30615338683128357
[10/24] Train loss=0.3661395013332367
[15/24] Train loss=0.2759796977043152
[20/24] Train loss=0.2807600796222687
Test set avg_accuracy=80.79% avg_sensitivity=33.31%, avg_specificity=94.56% avg_auc=76.35%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.305199 Test loss=0.489690 Current lr=[0.000298904600941902]

[0/24] Train loss=0.30808907747268677
[5/24] Train loss=0.3023793697357178
[10/24] Train loss=0.3422743082046509
[15/24] Train loss=0.2763662040233612
[20/24] Train loss=0.2727609872817993
Test set avg_accuracy=80.10% avg_sensitivity=14.48%, avg_specificity=99.13% avg_auc=72.76%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.298640 Test loss=0.565936 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3002364933490753
[5/24] Train loss=0.2905336022377014
[10/24] Train loss=0.3231657147407532
[15/24] Train loss=0.27480971813201904
[20/24] Train loss=0.2835004925727844
Test set avg_accuracy=78.61% avg_sensitivity=5.21%, avg_specificity=99.88% avg_auc=70.63%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.296791 Test loss=0.615884 Current lr=[0.000297555943323901]

[0/24] Train loss=0.30516842007637024
[5/24] Train loss=0.2848741412162781
[10/24] Train loss=0.3448682129383087
[15/24] Train loss=0.28237083554267883
[20/24] Train loss=0.297412633895874
Test set avg_accuracy=82.72% avg_sensitivity=34.47%, avg_specificity=96.71% avg_auc=82.02%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.300756 Test loss=0.412069 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2879554033279419
[5/24] Train loss=0.2820270359516144
[10/24] Train loss=0.3244783580303192
[15/24] Train loss=0.28218919038772583
[20/24] Train loss=0.27974507212638855
Test set avg_accuracy=82.33% avg_sensitivity=27.87%, avg_specificity=98.12% avg_auc=79.54%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.295392 Test loss=0.483694 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.28868550062179565
[5/24] Train loss=0.27013030648231506
[10/24] Train loss=0.32443326711654663
[15/24] Train loss=0.2740659713745117
[20/24] Train loss=0.29185840487480164
Test set avg_accuracy=83.15% avg_sensitivity=61.65%, avg_specificity=89.39% avg_auc=86.07%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.293059 Test loss=0.381559 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2804158329963684
[5/24] Train loss=0.26361411809921265
[10/24] Train loss=0.29395121335983276
[15/24] Train loss=0.27258792519569397
[20/24] Train loss=0.26571032404899597
Test set avg_accuracy=81.26% avg_sensitivity=63.90%, avg_specificity=86.29% avg_auc=84.02%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.283639 Test loss=0.418270 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2782697081565857
[5/24] Train loss=0.2524377405643463
[10/24] Train loss=0.3179251551628113
[15/24] Train loss=0.2714496850967407
[20/24] Train loss=0.2627127468585968
Test set avg_accuracy=81.74% avg_sensitivity=23.29%, avg_specificity=98.69% avg_auc=74.89%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.279605 Test loss=0.494998 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.27885591983795166
[5/24] Train loss=0.2625482678413391
[10/24] Train loss=0.3213564157485962
[15/24] Train loss=0.258063405752182
[20/24] Train loss=0.27170512080192566
Test set avg_accuracy=79.54% avg_sensitivity=12.57%, avg_specificity=98.96% avg_auc=73.71%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.275960 Test loss=0.542509 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2759579122066498
[5/24] Train loss=0.26144149899482727
[10/24] Train loss=0.3240462839603424
[15/24] Train loss=0.2580907940864563
[20/24] Train loss=0.26433491706848145
Test set avg_accuracy=83.39% avg_sensitivity=40.85%, avg_specificity=95.72% avg_auc=82.76%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.281407 Test loss=0.409708 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.27572575211524963
[5/24] Train loss=0.25232067704200745
[10/24] Train loss=0.2889600694179535
[15/24] Train loss=0.27119511365890503
[20/24] Train loss=0.2713741660118103
Test set avg_accuracy=80.62% avg_sensitivity=37.02%, avg_specificity=93.27% avg_auc=80.45%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.276156 Test loss=0.434570 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.27640974521636963
[5/24] Train loss=0.2567545175552368
[10/24] Train loss=0.2953486144542694
[15/24] Train loss=0.2676618695259094
[20/24] Train loss=0.2638462781906128
Test set avg_accuracy=84.22% avg_sensitivity=49.19%, avg_specificity=94.37% avg_auc=83.70%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.271716 Test loss=0.387584 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2794059216976166
[5/24] Train loss=0.2507829964160919
[10/24] Train loss=0.3083328902721405
[15/24] Train loss=0.2747715711593628
[20/24] Train loss=0.26887309551239014
Test set avg_accuracy=83.02% avg_sensitivity=66.28%, avg_specificity=87.87% avg_auc=85.67%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.271503 Test loss=0.391050 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2678881585597992
[5/24] Train loss=0.24249285459518433
[10/24] Train loss=0.30294811725616455
[15/24] Train loss=0.26146912574768066
[20/24] Train loss=0.25759270787239075
Test set avg_accuracy=82.21% avg_sensitivity=28.39%, avg_specificity=97.82% avg_auc=81.18%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.270960 Test loss=0.454436 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2569617033004761
[5/24] Train loss=0.24419663846492767
[10/24] Train loss=0.28247612714767456
[15/24] Train loss=0.25104090571403503
[20/24] Train loss=0.2725890874862671
Test set avg_accuracy=82.93% avg_sensitivity=34.88%, avg_specificity=96.86% avg_auc=81.87%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.263068 Test loss=0.455564 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.25785723328590393
[5/24] Train loss=0.24845314025878906
[10/24] Train loss=0.2882942259311676
[15/24] Train loss=0.25446179509162903
[20/24] Train loss=0.26241087913513184
Test set avg_accuracy=81.94% avg_sensitivity=25.84%, avg_specificity=98.20% avg_auc=79.15%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.262144 Test loss=0.498771 Current lr=[0.000276307469034998]

[0/24] Train loss=0.25756606459617615
[5/24] Train loss=0.24863025546073914
[10/24] Train loss=0.2807994782924652
[15/24] Train loss=0.23645122349262238
[20/24] Train loss=0.2598591148853302
Test set avg_accuracy=83.27% avg_sensitivity=39.46%, avg_specificity=95.97% avg_auc=81.60%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.260644 Test loss=0.437672 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.26787447929382324
[5/24] Train loss=0.2368406504392624
[10/24] Train loss=0.30189448595046997
[15/24] Train loss=0.2566045820713043
[20/24] Train loss=0.24876834452152252
Test set avg_accuracy=83.58% avg_sensitivity=57.13%, avg_specificity=91.25% avg_auc=83.72%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.261371 Test loss=0.407474 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.262215793132782
[5/24] Train loss=0.24009542167186737
[10/24] Train loss=0.2776738703250885
[15/24] Train loss=0.2665591835975647
[20/24] Train loss=0.25251278281211853
Test set avg_accuracy=83.33% avg_sensitivity=47.86%, avg_specificity=93.62% avg_auc=83.23%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.262169 Test loss=0.409308 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2508925199508667
[5/24] Train loss=0.23050594329833984
[10/24] Train loss=0.2800101935863495
[15/24] Train loss=0.24928097426891327
[20/24] Train loss=0.251474529504776
Test set avg_accuracy=83.16% avg_sensitivity=36.73%, avg_specificity=96.62% avg_auc=82.35%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.253615 Test loss=0.451437 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2507299780845642
[5/24] Train loss=0.23306962847709656
[10/24] Train loss=0.26858198642730713
[15/24] Train loss=0.246311217546463
[20/24] Train loss=0.24465572834014893
Test set avg_accuracy=83.50% avg_sensitivity=60.08%, avg_specificity=90.29% avg_auc=85.32%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.251662 Test loss=0.387718 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.26434528827667236
[5/24] Train loss=0.23684705793857574
[10/24] Train loss=0.26785165071487427
[15/24] Train loss=0.24778856337070465
[20/24] Train loss=0.24090342223644257
Test set avg_accuracy=84.24% avg_sensitivity=58.23%, avg_specificity=91.79% avg_auc=84.80%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.250175 Test loss=0.378229 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.26575466990470886
[5/24] Train loss=0.22832489013671875
[10/24] Train loss=0.2709459066390991
[15/24] Train loss=0.24627768993377686
[20/24] Train loss=0.23517513275146484
Test set avg_accuracy=84.05% avg_sensitivity=55.91%, avg_specificity=92.21% avg_auc=85.03%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.252298 Test loss=0.374599 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.24895571172237396
[5/24] Train loss=0.2363547831773758
[10/24] Train loss=0.26068466901779175
[15/24] Train loss=0.2429862767457962
[20/24] Train loss=0.23359166085720062
Test set avg_accuracy=79.75% avg_sensitivity=69.12%, avg_specificity=82.84% avg_auc=84.29%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.248592 Test loss=0.446119 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.24247154593467712
[5/24] Train loss=0.2272392064332962
[10/24] Train loss=0.2557562589645386
[15/24] Train loss=0.2247185856103897
[20/24] Train loss=0.2623240351676941
Test set avg_accuracy=83.24% avg_sensitivity=64.89%, avg_specificity=88.56% avg_auc=85.36%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.242892 Test loss=0.392262 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.23681263625621796
[5/24] Train loss=0.21949626505374908
[10/24] Train loss=0.2513905167579651
[15/24] Train loss=0.22477492690086365
[20/24] Train loss=0.23635922372341156
Test set avg_accuracy=83.96% avg_sensitivity=63.85%, avg_specificity=89.79% avg_auc=85.93%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.236933 Test loss=0.380721 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.25159385800361633
[5/24] Train loss=0.21278028190135956
[10/24] Train loss=0.26867902278900146
[15/24] Train loss=0.23842176795005798
[20/24] Train loss=0.2486332356929779
Test set avg_accuracy=80.96% avg_sensitivity=70.51%, avg_specificity=83.99% avg_auc=86.21%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.238645 Test loss=0.420725 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.24820686876773834
[5/24] Train loss=0.21517610549926758
[10/24] Train loss=0.25472506880760193
[15/24] Train loss=0.22185784578323364
[20/24] Train loss=0.2297966629266739
Test set avg_accuracy=83.53% avg_sensitivity=66.40%, avg_specificity=88.50% avg_auc=86.16%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.236805 Test loss=0.392183 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.234782412648201
[5/24] Train loss=0.2048262506723404
[10/24] Train loss=0.24461767077445984
[15/24] Train loss=0.21955253183841705
[20/24] Train loss=0.23026403784751892
Test set avg_accuracy=84.67% avg_sensitivity=53.65%, avg_specificity=93.67% avg_auc=84.44%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.229340 Test loss=0.395585 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.23648521304130554
[5/24] Train loss=0.22853252291679382
[10/24] Train loss=0.24970752000808716
[15/24] Train loss=0.23029354214668274
[20/24] Train loss=0.23182997107505798
Test set avg_accuracy=79.27% avg_sensitivity=74.51%, avg_specificity=80.65% avg_auc=85.47%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.232676 Test loss=0.466184 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2313736081123352
[5/24] Train loss=0.21703515946865082
[10/24] Train loss=0.23669734597206116
[15/24] Train loss=0.20870020985603333
[20/24] Train loss=0.2445036768913269
Test set avg_accuracy=83.23% avg_sensitivity=61.99%, avg_specificity=89.39% avg_auc=83.95%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.230592 Test loss=0.413050 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.23849469423294067
[5/24] Train loss=0.20976099371910095
[10/24] Train loss=0.23341216146945953
[15/24] Train loss=0.2177283763885498
[20/24] Train loss=0.2227264791727066
Test set avg_accuracy=83.74% avg_sensitivity=58.92%, avg_specificity=90.93% avg_auc=84.62%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.228387 Test loss=0.410867 Current lr=[0.000224838296036774]

[0/24] Train loss=0.22248099744319916
[5/24] Train loss=0.20593249797821045
[10/24] Train loss=0.23740887641906738
[15/24] Train loss=0.22906801104545593
[20/24] Train loss=0.2075861543416977
Test set avg_accuracy=84.05% avg_sensitivity=58.52%, avg_specificity=91.45% avg_auc=84.57%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.224867 Test loss=0.407291 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.22722958028316498
[5/24] Train loss=0.20036858320236206
[10/24] Train loss=0.2255241572856903
[15/24] Train loss=0.20114003121852875
[20/24] Train loss=0.2239302396774292
Test set avg_accuracy=83.46% avg_sensitivity=41.48%, avg_specificity=95.63% avg_auc=80.91%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.222795 Test loss=0.464648 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.24585366249084473
[5/24] Train loss=0.20042684674263
[10/24] Train loss=0.2330259084701538
[15/24] Train loss=0.22303371131420135
[20/24] Train loss=0.23682467639446259
Test set avg_accuracy=82.30% avg_sensitivity=65.47%, avg_specificity=87.19% avg_auc=84.00%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.223987 Test loss=0.447558 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.23364247381687164
[5/24] Train loss=0.20012357831001282
[10/24] Train loss=0.2209307998418808
[15/24] Train loss=0.2127116620540619
[20/24] Train loss=0.20602892339229584
Test set avg_accuracy=81.82% avg_sensitivity=67.79%, avg_specificity=85.89% avg_auc=85.76%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.220317 Test loss=0.426579 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.21782691776752472
[5/24] Train loss=0.20245219767093658
[10/24] Train loss=0.22262077033519745
[15/24] Train loss=0.21174217760562897
[20/24] Train loss=0.2103194296360016
Test set avg_accuracy=83.03% avg_sensitivity=60.08%, avg_specificity=89.69% avg_auc=84.00%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.214380 Test loss=0.416271 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2004999965429306
[5/24] Train loss=0.1981697678565979
[10/24] Train loss=0.213022843003273
[15/24] Train loss=0.19501854479312897
[20/24] Train loss=0.1975867748260498
Test set avg_accuracy=82.41% avg_sensitivity=65.99%, avg_specificity=87.17% avg_auc=84.46%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.206019 Test loss=0.432561 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.20680496096611023
[5/24] Train loss=0.18852931261062622
[10/24] Train loss=0.2242775410413742
[15/24] Train loss=0.20018862187862396
[20/24] Train loss=0.19464054703712463
Test set avg_accuracy=81.29% avg_sensitivity=67.21%, avg_specificity=85.37% avg_auc=84.80%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.205592 Test loss=0.439581 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.21163956820964813
[5/24] Train loss=0.18313716351985931
[10/24] Train loss=0.20120751857757568
[15/24] Train loss=0.20566147565841675
[20/24] Train loss=0.19599580764770508
Test set avg_accuracy=78.82% avg_sensitivity=69.93%, avg_specificity=81.39% avg_auc=83.07%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.206984 Test loss=0.491641 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.20490257441997528
[5/24] Train loss=0.18115085363388062
[10/24] Train loss=0.2189692109823227
[15/24] Train loss=0.1988619863986969
[20/24] Train loss=0.19992366433143616
Test set avg_accuracy=80.91% avg_sensitivity=69.64%, avg_specificity=84.18% avg_auc=85.93%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.206794 Test loss=0.437460 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.21056488156318665
[5/24] Train loss=0.19163942337036133
[10/24] Train loss=0.1973012089729309
[15/24] Train loss=0.1952676922082901
[20/24] Train loss=0.19530025124549866
Test set avg_accuracy=79.57% avg_sensitivity=70.34%, avg_specificity=82.25% avg_auc=84.69%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.205274 Test loss=0.470640 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.20994813740253448
[5/24] Train loss=0.19031159579753876
[10/24] Train loss=0.201893150806427
[15/24] Train loss=0.1975049376487732
[20/24] Train loss=0.19818514585494995
Test set avg_accuracy=80.90% avg_sensitivity=67.27%, avg_specificity=84.85% avg_auc=84.48%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.202241 Test loss=0.437838 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.21662048995494843
[5/24] Train loss=0.18157362937927246
[10/24] Train loss=0.19824448227882385
[15/24] Train loss=0.19025146961212158
[20/24] Train loss=0.19284339249134064
Test set avg_accuracy=82.83% avg_sensitivity=61.82%, avg_specificity=88.92% avg_auc=84.15%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.195495 Test loss=0.413363 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1985117495059967
[5/24] Train loss=0.17645414173603058
[10/24] Train loss=0.18992453813552856
[15/24] Train loss=0.18665571510791779
[20/24] Train loss=0.18877829611301422
Test set avg_accuracy=82.41% avg_sensitivity=44.79%, avg_specificity=93.32% avg_auc=79.91%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.192297 Test loss=0.437022 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2049972265958786
[5/24] Train loss=0.17675569653511047
[10/24] Train loss=0.18898774683475494
[15/24] Train loss=0.19314901530742645
[20/24] Train loss=0.20040267705917358
Test set avg_accuracy=83.42% avg_sensitivity=54.58%, avg_specificity=91.79% avg_auc=83.21%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.193956 Test loss=0.419674 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.19541454315185547
[5/24] Train loss=0.17097260057926178
[10/24] Train loss=0.1875586360692978
[15/24] Train loss=0.17862997949123383
[20/24] Train loss=0.17946431040763855
Test set avg_accuracy=84.26% avg_sensitivity=54.81%, avg_specificity=92.79% avg_auc=84.22%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.188184 Test loss=0.393241 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.18436503410339355
[5/24] Train loss=0.1731289029121399
[10/24] Train loss=0.1818377524614334
[15/24] Train loss=0.17660774290561676
[20/24] Train loss=0.1868334859609604
Test set avg_accuracy=83.50% avg_sensitivity=53.07%, avg_specificity=92.32% avg_auc=81.90%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.186170 Test loss=0.421409 Current lr=[0.000156543481933168]

[0/24] Train loss=0.18697603046894073
[5/24] Train loss=0.17790167033672333
[10/24] Train loss=0.18056966364383698
[15/24] Train loss=0.1816464364528656
[20/24] Train loss=0.18324677646160126
Test set avg_accuracy=83.75% avg_sensitivity=55.33%, avg_specificity=91.99% avg_auc=83.05%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.183798 Test loss=0.417766 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.18895097076892853
[5/24] Train loss=0.17882800102233887
[10/24] Train loss=0.17712187767028809
[15/24] Train loss=0.1793076992034912
[20/24] Train loss=0.18889692425727844
Test set avg_accuracy=82.12% avg_sensitivity=36.56%, avg_specificity=95.33% avg_auc=78.61%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.183668 Test loss=0.479463 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.1933450698852539
[5/24] Train loss=0.16725172102451324
[10/24] Train loss=0.17801816761493683
[15/24] Train loss=0.17256700992584229
[20/24] Train loss=0.19167834520339966
Test set avg_accuracy=84.13% avg_sensitivity=53.19%, avg_specificity=93.10% avg_auc=84.52%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.183148 Test loss=0.392612 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.18719062209129333
[5/24] Train loss=0.16998787224292755
[10/24] Train loss=0.17666925489902496
[15/24] Train loss=0.18318969011306763
[20/24] Train loss=0.17051300406455994
Test set avg_accuracy=83.68% avg_sensitivity=55.21%, avg_specificity=91.94% avg_auc=83.34%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.181980 Test loss=0.429689 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.18769876658916473
[5/24] Train loss=0.17483200132846832
[10/24] Train loss=0.17643842101097107
[15/24] Train loss=0.1723954677581787
[20/24] Train loss=0.1757896989583969
Test set avg_accuracy=84.44% avg_sensitivity=54.11%, avg_specificity=93.23% avg_auc=83.54%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.181490 Test loss=0.406519 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1789156049489975
[5/24] Train loss=0.16553092002868652
[10/24] Train loss=0.1747315675020218
[15/24] Train loss=0.1695828139781952
[20/24] Train loss=0.1691545993089676
Test set avg_accuracy=84.40% avg_sensitivity=59.44%, avg_specificity=91.64% avg_auc=84.27%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.175498 Test loss=0.407941 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.17854176461696625
[5/24] Train loss=0.1619780957698822
[10/24] Train loss=0.16459618508815765
[15/24] Train loss=0.1734190732240677
[20/24] Train loss=0.1759863942861557
Test set avg_accuracy=84.19% avg_sensitivity=56.03%, avg_specificity=92.36% avg_auc=84.26%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.171476 Test loss=0.407477 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.17375265061855316
[5/24] Train loss=0.15991348028182983
[10/24] Train loss=0.1627764105796814
[15/24] Train loss=0.16803421080112457
[20/24] Train loss=0.17231668531894684
Test set avg_accuracy=81.51% avg_sensitivity=67.61%, avg_specificity=85.54% avg_auc=85.01%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.168835 Test loss=0.439057 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.17085301876068115
[5/24] Train loss=0.15619361400604248
[10/24] Train loss=0.16056805849075317
[15/24] Train loss=0.16190755367279053
[20/24] Train loss=0.16520044207572937
Test set avg_accuracy=83.02% avg_sensitivity=53.53%, avg_specificity=91.57% avg_auc=82.91%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.168212 Test loss=0.423567 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.16848447918891907
[5/24] Train loss=0.15802887082099915
[10/24] Train loss=0.16668950021266937
[15/24] Train loss=0.16663020849227905
[20/24] Train loss=0.16149088740348816
Test set avg_accuracy=83.87% avg_sensitivity=49.71%, avg_specificity=93.77% avg_auc=82.83%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.165878 Test loss=0.422259 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16599515080451965
[5/24] Train loss=0.15612508356571198
[10/24] Train loss=0.1544429212808609
[15/24] Train loss=0.15486584603786469
[20/24] Train loss=0.16456595063209534
Test set avg_accuracy=82.06% avg_sensitivity=56.84%, avg_specificity=89.37% avg_auc=83.47%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.164291 Test loss=0.423156 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.16974593698978424
[5/24] Train loss=0.15546755492687225
[10/24] Train loss=0.1517254263162613
[15/24] Train loss=0.1589326560497284
[20/24] Train loss=0.14867937564849854
Test set avg_accuracy=83.24% avg_sensitivity=56.49%, avg_specificity=91.00% avg_auc=83.90%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.159544 Test loss=0.419472 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1744648665189743
[5/24] Train loss=0.15611769258975983
[10/24] Train loss=0.1487196832895279
[15/24] Train loss=0.17024298012256622
[20/24] Train loss=0.16500604152679443
Test set avg_accuracy=83.80% avg_sensitivity=47.86%, avg_specificity=94.22% avg_auc=81.84%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.162276 Test loss=0.429867 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.15648595988750458
[5/24] Train loss=0.1476481854915619
[10/24] Train loss=0.1476210206747055
[15/24] Train loss=0.16643494367599487
[20/24] Train loss=0.16003431379795074
Test set avg_accuracy=82.96% avg_sensitivity=64.25%, avg_specificity=88.38% avg_auc=84.61%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.159741 Test loss=0.422065 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.16672183573246002
[5/24] Train loss=0.1506209522485733
[10/24] Train loss=0.14759640395641327
[15/24] Train loss=0.15208719670772552
[20/24] Train loss=0.14952298998832703
Test set avg_accuracy=82.57% avg_sensitivity=57.13%, avg_specificity=89.94% avg_auc=83.66%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.156773 Test loss=0.416765 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.15244723856449127
[5/24] Train loss=0.1460157036781311
[10/24] Train loss=0.14870859682559967
[15/24] Train loss=0.14327065646648407
[20/24] Train loss=0.15560711920261383
Test set avg_accuracy=82.42% avg_sensitivity=62.17%, avg_specificity=88.29% avg_auc=84.66%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.154224 Test loss=0.422719 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1521957814693451
[5/24] Train loss=0.13930268585681915
[10/24] Train loss=0.1463700383901596
[15/24] Train loss=0.14307712018489838
[20/24] Train loss=0.14755578339099884
Test set avg_accuracy=82.03% avg_sensitivity=65.18%, avg_specificity=86.92% avg_auc=85.10%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.151360 Test loss=0.424526 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.15632186830043793
[5/24] Train loss=0.14340344071388245
[10/24] Train loss=0.14425525069236755
[15/24] Train loss=0.14560312032699585
[20/24] Train loss=0.14725622534751892
Test set avg_accuracy=82.86% avg_sensitivity=63.96%, avg_specificity=88.34% avg_auc=85.02%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.150387 Test loss=0.420340 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1547904759645462
[5/24] Train loss=0.14337971806526184
[10/24] Train loss=0.14082655310630798
[15/24] Train loss=0.14698375761508942
[20/24] Train loss=0.15567992627620697
Test set avg_accuracy=82.98% avg_sensitivity=65.64%, avg_specificity=88.01% avg_auc=84.87%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.148898 Test loss=0.426431 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15615086257457733
[5/24] Train loss=0.13816580176353455
[10/24] Train loss=0.1399054229259491
[15/24] Train loss=0.1430617719888687
[20/24] Train loss=0.1416429877281189
Test set avg_accuracy=83.76% avg_sensitivity=64.43%, avg_specificity=89.37% avg_auc=85.89%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.146657 Test loss=0.399771 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1465734839439392
[5/24] Train loss=0.1349143087863922
[10/24] Train loss=0.1381205916404724
[15/24] Train loss=0.14120681583881378
[20/24] Train loss=0.1401272863149643
Test set avg_accuracy=82.83% avg_sensitivity=66.57%, avg_specificity=87.54% avg_auc=85.66%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.145083 Test loss=0.420982 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14730726182460785
[5/24] Train loss=0.13739116489887238
[10/24] Train loss=0.1377430409193039
[15/24] Train loss=0.1391925811767578
[20/24] Train loss=0.14570052921772003
Test set avg_accuracy=83.10% avg_sensitivity=67.56%, avg_specificity=87.60% avg_auc=86.00%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.143668 Test loss=0.424671 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14732912182807922
[5/24] Train loss=0.13484004139900208
[10/24] Train loss=0.13196836411952972
[15/24] Train loss=0.13976460695266724
[20/24] Train loss=0.14655062556266785
Test set avg_accuracy=81.68% avg_sensitivity=68.42%, avg_specificity=85.52% avg_auc=85.72%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.141765 Test loss=0.433714 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14064322412014008
[5/24] Train loss=0.1370357722043991
[10/24] Train loss=0.1366800218820572
[15/24] Train loss=0.13130661845207214
[20/24] Train loss=0.14343707263469696
Test set avg_accuracy=83.96% avg_sensitivity=61.01%, avg_specificity=90.61% avg_auc=84.70%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.140091 Test loss=0.410912 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14594291150569916
[5/24] Train loss=0.13111847639083862
[10/24] Train loss=0.1304895430803299
[15/24] Train loss=0.1320147067308426
[20/24] Train loss=0.13280072808265686
Test set avg_accuracy=83.52% avg_sensitivity=62.28%, avg_specificity=89.67% avg_auc=85.57%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.137436 Test loss=0.400341 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1392190307378769
[5/24] Train loss=0.13177040219306946
[10/24] Train loss=0.12805379927158356
[15/24] Train loss=0.13355652987957
[20/24] Train loss=0.13289664685726166
Test set avg_accuracy=83.27% avg_sensitivity=63.50%, avg_specificity=89.00% avg_auc=85.18%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.135546 Test loss=0.407518 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13807392120361328
[5/24] Train loss=0.13114576041698456
[10/24] Train loss=0.12524482607841492
[15/24] Train loss=0.13322782516479492
[20/24] Train loss=0.13332347571849823
Test set avg_accuracy=83.54% avg_sensitivity=63.56%, avg_specificity=89.33% avg_auc=85.27%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.135735 Test loss=0.406936 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13540342450141907
[5/24] Train loss=0.12780852615833282
[10/24] Train loss=0.12622836232185364
[15/24] Train loss=0.13163577020168304
[20/24] Train loss=0.1358121633529663
Test set avg_accuracy=84.43% avg_sensitivity=60.66%, avg_specificity=91.32% avg_auc=84.88%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.133311 Test loss=0.399868 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13377061486244202
[5/24] Train loss=0.12640048563480377
[10/24] Train loss=0.12497732788324356
[15/24] Train loss=0.12792253494262695
[20/24] Train loss=0.13207338750362396
Test set avg_accuracy=84.49% avg_sensitivity=58.98%, avg_specificity=91.89% avg_auc=84.65%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.131824 Test loss=0.398001 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13431763648986816
[5/24] Train loss=0.1267091929912567
[10/24] Train loss=0.12403116375207901
[15/24] Train loss=0.12759070098400116
[20/24] Train loss=0.1307111233472824
Test set avg_accuracy=84.38% avg_sensitivity=61.47%, avg_specificity=91.01% avg_auc=85.14%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.131203 Test loss=0.395769 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13123753666877747
[5/24] Train loss=0.1254727989435196
[10/24] Train loss=0.12208575755357742
[15/24] Train loss=0.12901577353477478
[20/24] Train loss=0.12769797444343567
Test set avg_accuracy=84.23% avg_sensitivity=64.25%, avg_specificity=90.02% avg_auc=85.49%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.130132 Test loss=0.400033 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1343432366847992
[5/24] Train loss=0.1259922981262207
[10/24] Train loss=0.12177567929029465
[15/24] Train loss=0.12882237136363983
[20/24] Train loss=0.1279851496219635
Test set avg_accuracy=83.98% avg_sensitivity=62.80%, avg_specificity=90.12% avg_auc=85.16%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.129744 Test loss=0.403479 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13077899813652039
[5/24] Train loss=0.12362722307443619
[10/24] Train loss=0.12065263092517853
[15/24] Train loss=0.123627208173275
[20/24] Train loss=0.1321120709180832
Test set avg_accuracy=83.62% avg_sensitivity=63.44%, avg_specificity=89.47% avg_auc=85.19%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.129269 Test loss=0.406751 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13216657936573029
[5/24] Train loss=0.12233252823352814
[10/24] Train loss=0.12155254185199738
[15/24] Train loss=0.125380739569664
[20/24] Train loss=0.1266506165266037
Test set avg_accuracy=83.92% avg_sensitivity=61.94%, avg_specificity=90.29% avg_auc=85.03%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.128182 Test loss=0.404844 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13035325706005096
[5/24] Train loss=0.12238962948322296
[10/24] Train loss=0.1180877834558487
[15/24] Train loss=0.1261506825685501
[20/24] Train loss=0.1266879141330719
Test set avg_accuracy=83.84% avg_sensitivity=63.56%, avg_specificity=89.72% avg_auc=85.33%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.127480 Test loss=0.401435 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1284865438938141
[5/24] Train loss=0.12047135084867477
[10/24] Train loss=0.12005250155925751
[15/24] Train loss=0.12411666661500931
[20/24] Train loss=0.12608113884925842
Test set avg_accuracy=83.70% avg_sensitivity=62.75%, avg_specificity=89.77% avg_auc=85.12%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.126853 Test loss=0.403330 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12711471319198608
[5/24] Train loss=0.12020733952522278
[10/24] Train loss=0.11636100709438324
[15/24] Train loss=0.12561307847499847
[20/24] Train loss=0.1249484270811081
Test set avg_accuracy=83.63% avg_sensitivity=63.21%, avg_specificity=89.55% avg_auc=85.23%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.125732 Test loss=0.403927 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1265253722667694
[5/24] Train loss=0.12151319533586502
[10/24] Train loss=0.11793520301580429
[15/24] Train loss=0.12198701500892639
[20/24] Train loss=0.127772256731987
Test set avg_accuracy=83.57% avg_sensitivity=61.53%, avg_specificity=89.96% avg_auc=84.95%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.125560 Test loss=0.405256 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1274319738149643
[5/24] Train loss=0.12012830376625061
[10/24] Train loss=0.11554747074842453
[15/24] Train loss=0.12238864600658417
[20/24] Train loss=0.12733882665634155
Test set avg_accuracy=83.70% avg_sensitivity=63.15%, avg_specificity=89.65% avg_auc=85.20%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.125189 Test loss=0.403802 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1270863264799118
[5/24] Train loss=0.11860423535108566
[10/24] Train loss=0.11584916710853577
[15/24] Train loss=0.12252119183540344
[20/24] Train loss=0.12407230585813522
Test set avg_accuracy=83.85% avg_sensitivity=61.12%, avg_specificity=90.44% avg_auc=84.86%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.124531 Test loss=0.403605 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12761583924293518
[5/24] Train loss=0.11842582374811172
[10/24] Train loss=0.11506454646587372
[15/24] Train loss=0.1219787672162056
[20/24] Train loss=0.1264721006155014
Test set avg_accuracy=83.58% avg_sensitivity=63.50%, avg_specificity=89.40% avg_auc=85.01%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.124437 Test loss=0.407354 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12642712891101837
[5/24] Train loss=0.11836564540863037
[10/24] Train loss=0.11632653325796127
[15/24] Train loss=0.12262454628944397
[20/24] Train loss=0.12424776703119278
Test set avg_accuracy=83.78% avg_sensitivity=63.21%, avg_specificity=89.74% avg_auc=85.19%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.123873 Test loss=0.404368 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12450339645147324
[5/24] Train loss=0.12076929956674576
[10/24] Train loss=0.11635904759168625
[15/24] Train loss=0.12242330610752106
[20/24] Train loss=0.1215190663933754
Test set avg_accuracy=83.92% avg_sensitivity=62.63%, avg_specificity=90.09% avg_auc=85.12%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.123863 Test loss=0.403679 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12548401951789856
[5/24] Train loss=0.1181664690375328
[10/24] Train loss=0.11541001498699188
[15/24] Train loss=0.12030927836894989
[20/24] Train loss=0.12238290905952454
Test set avg_accuracy=84.15% avg_sensitivity=61.99%, avg_specificity=90.58% avg_auc=84.99%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.123413 Test loss=0.402848 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.126738041639328
[5/24] Train loss=0.11863792687654495
[10/24] Train loss=0.1154746264219284
[15/24] Train loss=0.12151992321014404
[20/24] Train loss=0.12644237279891968
Test set avg_accuracy=83.89% avg_sensitivity=62.46%, avg_specificity=90.11% avg_auc=85.03%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.123316 Test loss=0.403930 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12417132407426834
[5/24] Train loss=0.1189352348446846
[10/24] Train loss=0.1164446696639061
[15/24] Train loss=0.1219804435968399
[20/24] Train loss=0.12182959914207458
Test set avg_accuracy=84.00% avg_sensitivity=63.09%, avg_specificity=90.06% avg_auc=85.26%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.123155 Test loss=0.402177 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12529917061328888
[5/24] Train loss=0.1178557276725769
[10/24] Train loss=0.11543324589729309
[15/24] Train loss=0.11958849430084229
[20/24] Train loss=0.12204384058713913
Test set avg_accuracy=84.15% avg_sensitivity=62.40%, avg_specificity=90.46% avg_auc=85.14%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.123137 Test loss=0.401862 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12618395686149597
[5/24] Train loss=0.11804158240556717
[10/24] Train loss=0.1143324226140976
[15/24] Train loss=0.12017521262168884
[20/24] Train loss=0.12318816781044006
Test set avg_accuracy=84.22% avg_sensitivity=62.22%, avg_specificity=90.59% avg_auc=85.07%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.122781 Test loss=0.401406 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12498431652784348
[5/24] Train loss=0.1191585436463356
[10/24] Train loss=0.1151411384344101
[15/24] Train loss=0.12097375839948654
[20/24] Train loss=0.12266385555267334
Test set avg_accuracy=84.13% avg_sensitivity=62.75%, avg_specificity=90.33% avg_auc=85.10%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.122827 Test loss=0.402291 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12729601562023163
[5/24] Train loss=0.11788871139287949
[10/24] Train loss=0.11525971442461014
[15/24] Train loss=0.12166821956634521
[20/24] Train loss=0.12223916500806808
Test set avg_accuracy=84.10% avg_sensitivity=62.86%, avg_specificity=90.26% avg_auc=85.11%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.122863 Test loss=0.402734 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12412919104099274
[5/24] Train loss=0.11735653877258301
[10/24] Train loss=0.11396270245313644
[15/24] Train loss=0.1212800145149231
[20/24] Train loss=0.12239746004343033
Test set avg_accuracy=84.13% avg_sensitivity=63.15%, avg_specificity=90.21% avg_auc=85.14%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.122753 Test loss=0.402873 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1241723969578743
[5/24] Train loss=0.11820102483034134
[10/24] Train loss=0.11513494700193405
[15/24] Train loss=0.12092279642820358
[20/24] Train loss=0.1227506771683693
Test set avg_accuracy=84.15% avg_sensitivity=62.98%, avg_specificity=90.29% avg_auc=85.10%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.122749 Test loss=0.402989 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12456484138965607
[5/24] Train loss=0.1189207136631012
[10/24] Train loss=0.1132306456565857
[15/24] Train loss=0.1203087568283081
[20/24] Train loss=0.12371858954429626
Test set avg_accuracy=84.14% avg_sensitivity=63.04%, avg_specificity=90.26% avg_auc=85.11%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.122989 Test loss=0.402911 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12449563294649124
[5/24] Train loss=0.11860388517379761
[10/24] Train loss=0.11462573707103729
[15/24] Train loss=0.12102755904197693
[20/24] Train loss=0.12244772166013718
Test set avg_accuracy=84.10% avg_sensitivity=62.75%, avg_specificity=90.29% avg_auc=85.10%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.122873 Test loss=0.402854 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=85.05% sen=63.09%, spe=91.42%, auc=87.40%!
Fold[10] Avg_overlap=0.58%(±0.31215016217534447)
Final Avg Result: avg_acc=83.41%(±1.170910096584021) avg_sen=65.67% (±4.454786421181645) avg_spe=89.50% (±1.9073615211788222) avg_auc=86.91% (±1.926164007221023) avg_overlap=0.50% (±0.1862710830708656)
