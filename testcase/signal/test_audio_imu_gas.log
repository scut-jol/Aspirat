/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/24] Train loss=0.7289053797721863
[5/24] Train loss=0.7179115414619446
[10/24] Train loss=0.7064447999000549
[15/24] Train loss=0.6974030137062073
[20/24] Train loss=0.6973227262496948
Test set avg_accuracy=60.04% avg_sensitivity=47.75%, avg_specificity=64.43% avg_auc=58.81%
Best model saved!! Metric=-94.97458803753054!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.706061 Test loss=0.684999 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.690925121307373
[5/24] Train loss=0.687739372253418
[10/24] Train loss=0.6863216757774353
[15/24] Train loss=0.6704133749008179
[20/24] Train loss=0.6626789569854736
Test set avg_accuracy=63.84% avg_sensitivity=67.10%, avg_specificity=62.68% avg_auc=70.45%
Best model saved!! Metric=-61.932659673590386!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.679145 Test loss=0.637812 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6637377142906189
[5/24] Train loss=0.6576501727104187
[10/24] Train loss=0.6582366228103638
[15/24] Train loss=0.6385579705238342
[20/24] Train loss=0.6415126323699951
Test set avg_accuracy=67.25% avg_sensitivity=72.14%, avg_specificity=65.51% avg_auc=75.69%
Best model saved!! Metric=-45.40658549229417!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.651570 Test loss=0.604855 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6310929656028748
[5/24] Train loss=0.625537633895874
[10/24] Train loss=0.6291929483413696
[15/24] Train loss=0.6114295125007629
[20/24] Train loss=0.5982820987701416
Test set avg_accuracy=70.62% avg_sensitivity=76.89%, avg_specificity=68.39% avg_auc=79.43%
Best model saved!! Metric=-30.661243865109952!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.623241 Test loss=0.573642 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5985778570175171
[5/24] Train loss=0.5945277810096741
[10/24] Train loss=0.6035851836204529
[15/24] Train loss=0.5774973034858704
[20/24] Train loss=0.5706554651260376
Test set avg_accuracy=72.42% avg_sensitivity=78.92%, avg_specificity=70.10% avg_auc=81.58%
Best model saved!! Metric=-22.980194925090316!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.594731 Test loss=0.551430 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5641529560089111
[5/24] Train loss=0.5674726963043213
[10/24] Train loss=0.5765194296836853
[15/24] Train loss=0.5469449758529663
[20/24] Train loss=0.544061541557312
Test set avg_accuracy=73.48% avg_sensitivity=82.19%, avg_specificity=70.37% avg_auc=83.59%
Best model saved!! Metric=-16.381073338014318!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.566921 Test loss=0.533662 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5379437804222107
[5/24] Train loss=0.5362355709075928
[10/24] Train loss=0.5537264943122864
[15/24] Train loss=0.5199074149131775
[20/24] Train loss=0.5154498219490051
Test set avg_accuracy=76.37% avg_sensitivity=80.90%, avg_specificity=74.75% avg_auc=85.17%
Best model saved!! Metric=-8.809928659456304!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.537615 Test loss=0.497708 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5079981684684753
[5/24] Train loss=0.5057350993156433
[10/24] Train loss=0.5215954184532166
[15/24] Train loss=0.4921644330024719
[20/24] Train loss=0.4826425313949585
Test set avg_accuracy=78.46% avg_sensitivity=79.42%, avg_specificity=78.12% avg_auc=86.85%
Best model saved!! Metric=-3.1449442095443914!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.507120 Test loss=0.470316 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.4755493998527527
[5/24] Train loss=0.4768385887145996
[10/24] Train loss=0.48637640476226807
[15/24] Train loss=0.46334993839263916
[20/24] Train loss=0.4553597867488861
Test set avg_accuracy=80.26% avg_sensitivity=79.81%, avg_specificity=80.42% avg_auc=88.44%
Best model saved!! Metric=2.934683218814513!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.476866 Test loss=0.441460 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.44066014885902405
[5/24] Train loss=0.4434974789619446
[10/24] Train loss=0.4646278917789459
[15/24] Train loss=0.4346036911010742
[20/24] Train loss=0.4286258816719055
Test set avg_accuracy=82.06% avg_sensitivity=79.61%, avg_specificity=82.93% avg_auc=89.39%
Best model saved!! Metric=7.987296102332863!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.448072 Test loss=0.416520 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4147331714630127
[5/24] Train loss=0.4120676815509796
[10/24] Train loss=0.4363850951194763
[15/24] Train loss=0.4121514558792114
[20/24] Train loss=0.3918643891811371
Test set avg_accuracy=83.57% avg_sensitivity=79.96%, avg_specificity=84.86% avg_auc=90.43%
Best model saved!! Metric=12.818857711233989!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.420668 Test loss=0.394559 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.38988399505615234
[5/24] Train loss=0.3911319673061371
[10/24] Train loss=0.41290733218193054
[15/24] Train loss=0.38883042335510254
[20/24] Train loss=0.3595927357673645
Test set avg_accuracy=84.71% avg_sensitivity=79.17%, avg_specificity=86.69% avg_auc=91.06%
Best model saved!! Metric=15.63622808377896!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.396044 Test loss=0.374185 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3702007234096527
[5/24] Train loss=0.3683616816997528
[10/24] Train loss=0.39098671078681946
[15/24] Train loss=0.37176239490509033
[20/24] Train loss=0.3500443696975708
Test set avg_accuracy=85.79% avg_sensitivity=73.33%, avg_specificity=90.25% avg_auc=91.10%
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.375926 Test loss=0.350641 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3493225872516632
[5/24] Train loss=0.3480430543422699
[10/24] Train loss=0.37349238991737366
[15/24] Train loss=0.35520240664482117
[20/24] Train loss=0.3384535610675812
Test set avg_accuracy=86.12% avg_sensitivity=70.26%, avg_specificity=91.78% avg_auc=91.30%
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.358237 Test loss=0.338146 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3301953077316284
[5/24] Train loss=0.3268758952617645
[10/24] Train loss=0.35550904273986816
[15/24] Train loss=0.345268189907074
[20/24] Train loss=0.32088503241539
Test set avg_accuracy=86.32% avg_sensitivity=69.32%, avg_specificity=92.38% avg_auc=91.73%
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.342831 Test loss=0.330055 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.31688371300697327
[5/24] Train loss=0.316992849111557
[10/24] Train loss=0.3556297719478607
[15/24] Train loss=0.3342178165912628
[20/24] Train loss=0.31063392758369446
Test set avg_accuracy=86.74% avg_sensitivity=71.65%, avg_specificity=92.14% avg_auc=92.15%
Best model saved!! Metric=16.68159378480439!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.330438 Test loss=0.321512 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.30095353722572327
[5/24] Train loss=0.30093926191329956
[10/24] Train loss=0.3393361568450928
[15/24] Train loss=0.32062774896621704
[20/24] Train loss=0.2935525178909302
Test set avg_accuracy=86.52% avg_sensitivity=68.73%, avg_specificity=92.88% avg_auc=92.13%
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.318059 Test loss=0.317198 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.2955428659915924
[5/24] Train loss=0.29139798879623413
[10/24] Train loss=0.3347591459751129
[15/24] Train loss=0.31137773394584656
[20/24] Train loss=0.2919856607913971
Test set avg_accuracy=87.19% avg_sensitivity=75.71%, avg_specificity=91.29% avg_auc=92.87%
Best model saved!! Metric=21.04976613839716!!
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.309674 Test loss=0.311796 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.27615657448768616
[5/24] Train loss=0.2844352722167969
[10/24] Train loss=0.31999120116233826
[15/24] Train loss=0.3076467216014862
[20/24] Train loss=0.28572264313697815
Test set avg_accuracy=87.03% avg_sensitivity=76.84%, avg_specificity=90.67% avg_auc=93.15%
Best model saved!! Metric=21.68933918006104!!
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.300118 Test loss=0.306621 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2761814594268799
[5/24] Train loss=0.2752041518688202
[10/24] Train loss=0.31366679072380066
[15/24] Train loss=0.2922530770301819
[20/24] Train loss=0.27155613899230957
Test set avg_accuracy=87.36% avg_sensitivity=75.90%, avg_specificity=91.45% avg_auc=93.10%
Best model saved!! Metric=21.809357426534476!!
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.293553 Test loss=0.305691 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.26852473616600037
[5/24] Train loss=0.26605460047721863
[10/24] Train loss=0.30761611461639404
[15/24] Train loss=0.2916395366191864
[20/24] Train loss=0.262973427772522
Test set avg_accuracy=87.59% avg_sensitivity=76.10%, avg_specificity=91.69% avg_auc=93.54%
Best model saved!! Metric=22.929951949254004!!
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.286116 Test loss=0.293324 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.26056262850761414
[5/24] Train loss=0.2630339562892914
[10/24] Train loss=0.30719608068466187
[15/24] Train loss=0.2817995846271515
[20/24] Train loss=0.2571874260902405
Test set avg_accuracy=87.75% avg_sensitivity=76.89%, avg_specificity=91.62% avg_auc=93.57%
Best model saved!! Metric=23.829820881023508!!
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.280632 Test loss=0.297214 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.25516995787620544
[5/24] Train loss=0.2504497766494751
[10/24] Train loss=0.30406126379966736
[15/24] Train loss=0.2768211364746094
[20/24] Train loss=0.2529299557209015
Test set avg_accuracy=88.01% avg_sensitivity=74.07%, avg_specificity=92.98% avg_auc=93.71%
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.273695 Test loss=0.286105 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2538291811943054
[5/24] Train loss=0.2413628101348877
[10/24] Train loss=0.29327094554901123
[15/24] Train loss=0.2734796106815338
[20/24] Train loss=0.24274836480617523
Test set avg_accuracy=87.90% avg_sensitivity=80.95%, avg_specificity=90.39% avg_auc=93.82%
Best model saved!! Metric=27.06390558692435!!
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.269379 Test loss=0.294916 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2486850917339325
[5/24] Train loss=0.24273155629634857
[10/24] Train loss=0.2856738865375519
[15/24] Train loss=0.2729707956314087
[20/24] Train loss=0.23950642347335815
Test set avg_accuracy=88.16% avg_sensitivity=74.67%, avg_specificity=92.98% avg_auc=93.93%
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.263951 Test loss=0.280644 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.23886626958847046
[5/24] Train loss=0.22929619252681732
[10/24] Train loss=0.28789451718330383
[15/24] Train loss=0.2673514783382416
[20/24] Train loss=0.23888204991817474
Test set avg_accuracy=86.56% avg_sensitivity=82.83%, avg_specificity=87.90% avg_auc=93.65%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.259336 Test loss=0.308245 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2399957776069641
[5/24] Train loss=0.2272549718618393
[10/24] Train loss=0.2782106101512909
[15/24] Train loss=0.2629254162311554
[20/24] Train loss=0.24476836621761322
Test set avg_accuracy=87.01% avg_sensitivity=80.80%, avg_specificity=89.22% avg_auc=93.48%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.255081 Test loss=0.310274 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.23573116958141327
[5/24] Train loss=0.22175103425979614
[10/24] Train loss=0.27906274795532227
[15/24] Train loss=0.2536298334598541
[20/24] Train loss=0.23454461991786957
Test set avg_accuracy=87.84% avg_sensitivity=71.65%, avg_specificity=93.62% avg_auc=93.79%
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.251267 Test loss=0.282306 Current lr=[0.000210185142098938]

[0/24] Train loss=0.23604217171669006
[5/24] Train loss=0.21240045130252838
[10/24] Train loss=0.2756088674068451
[15/24] Train loss=0.2549343705177307
[20/24] Train loss=0.2269672155380249
Test set avg_accuracy=87.60% avg_sensitivity=66.35%, avg_specificity=95.19% avg_auc=93.19%
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.247538 Test loss=0.293661 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.23151253163814545
[5/24] Train loss=0.2162470668554306
[10/24] Train loss=0.26906436681747437
[15/24] Train loss=0.24953660368919373
[20/24] Train loss=0.22593139111995697
Test set avg_accuracy=85.76% avg_sensitivity=81.49%, avg_specificity=87.28% avg_auc=92.88%
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.244086 Test loss=0.328228 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.22398412227630615
[5/24] Train loss=0.21304939687252045
[10/24] Train loss=0.2645649313926697
[15/24] Train loss=0.2538702189922333
[20/24] Train loss=0.23227538168430328
Test set avg_accuracy=87.79% avg_sensitivity=70.91%, avg_specificity=93.82% avg_auc=93.55%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.240831 Test loss=0.284975 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.22961963713169098
[5/24] Train loss=0.19767023622989655
[10/24] Train loss=0.2547977566719055
[15/24] Train loss=0.24521905183792114
[20/24] Train loss=0.2275206297636032
Test set avg_accuracy=87.34% avg_sensitivity=72.79%, avg_specificity=92.54% avg_auc=93.64%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.234828 Test loss=0.284392 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2291133999824524
[5/24] Train loss=0.20669686794281006
[10/24] Train loss=0.2626902759075165
[15/24] Train loss=0.2509896457195282
[20/24] Train loss=0.21550926566123962
Test set avg_accuracy=86.46% avg_sensitivity=80.26%, avg_specificity=88.67% avg_auc=93.41%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.233667 Test loss=0.302965 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.21486328542232513
[5/24] Train loss=0.21120263636112213
[10/24] Train loss=0.25935307145118713
[15/24] Train loss=0.2362285703420639
[20/24] Train loss=0.21801361441612244
Test set avg_accuracy=85.40% avg_sensitivity=53.19%, avg_specificity=96.91% avg_auc=90.97%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.233017 Test loss=0.348615 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2177896350622177
[5/24] Train loss=0.19601021707057953
[10/24] Train loss=0.2588690221309662
[15/24] Train loss=0.2438938021659851
[20/24] Train loss=0.21375760436058044
Test set avg_accuracy=87.59% avg_sensitivity=76.65%, avg_specificity=91.50% avg_auc=93.06%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.231273 Test loss=0.298769 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.21378736197948456
[5/24] Train loss=0.19371184706687927
[10/24] Train loss=0.24997055530548096
[15/24] Train loss=0.24500098824501038
[20/24] Train loss=0.22253695130348206
Test set avg_accuracy=84.35% avg_sensitivity=50.57%, avg_specificity=96.41% avg_auc=88.03%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.227698 Test loss=0.398895 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.22390301525592804
[5/24] Train loss=0.19950784742832184
[10/24] Train loss=0.24394680559635162
[15/24] Train loss=0.2280057966709137
[20/24] Train loss=0.21632687747478485
Test set avg_accuracy=87.57% avg_sensitivity=69.03%, avg_specificity=94.19% avg_auc=92.32%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.229485 Test loss=0.299753 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.21122907102108002
[5/24] Train loss=0.18867436051368713
[10/24] Train loss=0.24627041816711426
[15/24] Train loss=0.2242620587348938
[20/24] Train loss=0.19996336102485657
Test set avg_accuracy=82.32% avg_sensitivity=38.10%, avg_specificity=98.11% avg_auc=85.67%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.219934 Test loss=0.454776 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.23290643095970154
[5/24] Train loss=0.20873050391674042
[10/24] Train loss=0.2500671446323395
[15/24] Train loss=0.23296284675598145
[20/24] Train loss=0.20901070535182953
Test set avg_accuracy=86.67% avg_sensitivity=74.86%, avg_specificity=90.88% avg_auc=92.80%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.226303 Test loss=0.303088 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.21089819073677063
[5/24] Train loss=0.1973688155412674
[10/24] Train loss=0.2371755987405777
[15/24] Train loss=0.23404641449451447
[20/24] Train loss=0.209132581949234
Test set avg_accuracy=86.41% avg_sensitivity=72.98%, avg_specificity=91.20% avg_auc=92.15%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.219826 Test loss=0.311941 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.20889215171337128
[5/24] Train loss=0.1835285872220993
[10/24] Train loss=0.22944901883602142
[15/24] Train loss=0.23428969085216522
[20/24] Train loss=0.2112138569355011
Test set avg_accuracy=85.23% avg_sensitivity=74.72%, avg_specificity=88.99% avg_auc=91.39%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.217962 Test loss=0.332190 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.20723561942577362
[5/24] Train loss=0.1790429800748825
[10/24] Train loss=0.23575280606746674
[15/24] Train loss=0.23211289942264557
[20/24] Train loss=0.2030625343322754
Test set avg_accuracy=85.74% avg_sensitivity=65.17%, avg_specificity=93.09% avg_auc=90.27%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.216725 Test loss=0.344873 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.20476959645748138
[5/24] Train loss=0.18017373979091644
[10/24] Train loss=0.243626207113266
[15/24] Train loss=0.22537854313850403
[20/24] Train loss=0.2012607753276825
Test set avg_accuracy=84.43% avg_sensitivity=81.35%, avg_specificity=85.53% avg_auc=91.71%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.213838 Test loss=0.354450 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.19331371784210205
[5/24] Train loss=0.18560054898262024
[10/24] Train loss=0.23881010711193085
[15/24] Train loss=0.21773481369018555
[20/24] Train loss=0.19106446206569672
Test set avg_accuracy=86.56% avg_sensitivity=76.15%, avg_specificity=90.28% avg_auc=92.69%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.209293 Test loss=0.305938 Current lr=[0.00029967723776099]

[0/24] Train loss=0.20975925028324127
[5/24] Train loss=0.1768684834241867
[10/24] Train loss=0.24263319373130798
[15/24] Train loss=0.2267889678478241
[20/24] Train loss=0.19798368215560913
Test set avg_accuracy=86.65% avg_sensitivity=71.40%, avg_specificity=92.10% avg_auc=92.34%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.214512 Test loss=0.307804 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.1956014484167099
[5/24] Train loss=0.17671434581279755
[10/24] Train loss=0.2347252517938614
[15/24] Train loss=0.23187588155269623
[20/24] Train loss=0.1903742253780365
Test set avg_accuracy=86.04% avg_sensitivity=77.93%, avg_specificity=88.94% avg_auc=92.09%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.208210 Test loss=0.322545 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.1979335993528366
[5/24] Train loss=0.16843195259571075
[10/24] Train loss=0.20824900269508362
[15/24] Train loss=0.22721123695373535
[20/24] Train loss=0.18703141808509827
Test set avg_accuracy=86.52% avg_sensitivity=76.99%, avg_specificity=89.93% avg_auc=91.95%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.201804 Test loss=0.318531 Current lr=[0.000299720220882401]

[0/24] Train loss=0.19523119926452637
[5/24] Train loss=0.1829894334077835
[10/24] Train loss=0.23085598647594452
[15/24] Train loss=0.229430690407753
[20/24] Train loss=0.19217269122600555
Test set avg_accuracy=84.73% avg_sensitivity=78.92%, avg_specificity=86.80% avg_auc=91.16%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.209723 Test loss=0.349635 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19885776937007904
[5/24] Train loss=0.18524660170078278
[10/24] Train loss=0.224552720785141
[15/24] Train loss=0.21658460795879364
[20/24] Train loss=0.20226743817329407
Test set avg_accuracy=86.09% avg_sensitivity=55.81%, avg_specificity=96.91% avg_auc=92.13%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.209631 Test loss=0.328200 Current lr=[0.000298904600941902]

[0/24] Train loss=0.20443342626094818
[5/24] Train loss=0.17664295434951782
[10/24] Train loss=0.2063775360584259
[15/24] Train loss=0.21701954305171967
[20/24] Train loss=0.185396209359169
Test set avg_accuracy=87.57% avg_sensitivity=66.80%, avg_specificity=94.98% avg_auc=92.58%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.202414 Test loss=0.303248 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.19991101324558258
[5/24] Train loss=0.18050998449325562
[10/24] Train loss=0.21814671158790588
[15/24] Train loss=0.210336372256279
[20/24] Train loss=0.19440607726573944
Test set avg_accuracy=86.72% avg_sensitivity=77.39%, avg_specificity=90.05% avg_auc=92.53%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.203634 Test loss=0.312972 Current lr=[0.000297555943323901]

[0/24] Train loss=0.18614332377910614
[5/24] Train loss=0.1704815924167633
[10/24] Train loss=0.20945845544338226
[15/24] Train loss=0.21519050002098083
[20/24] Train loss=0.19060908257961273
Test set avg_accuracy=85.87% avg_sensitivity=67.84%, avg_specificity=92.31% avg_auc=90.61%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.198993 Test loss=0.333224 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.18824081122875214
[5/24] Train loss=0.16103234887123108
[10/24] Train loss=0.20692552626132965
[15/24] Train loss=0.21276096999645233
[20/24] Train loss=0.17218807339668274
Test set avg_accuracy=84.74% avg_sensitivity=83.77%, avg_specificity=85.09% avg_auc=92.43%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.193234 Test loss=0.345922 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.1836860477924347
[5/24] Train loss=0.16138261556625366
[10/24] Train loss=0.19581376016139984
[15/24] Train loss=0.20460860431194305
[20/24] Train loss=0.17813414335250854
Test set avg_accuracy=86.21% avg_sensitivity=78.97%, avg_specificity=88.80% avg_auc=92.22%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.191637 Test loss=0.326151 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.17606516182422638
[5/24] Train loss=0.17581941187381744
[10/24] Train loss=0.21435284614562988
[15/24] Train loss=0.20555409789085388
[20/24] Train loss=0.18481548130512238
Test set avg_accuracy=87.03% avg_sensitivity=73.18%, avg_specificity=91.98% avg_auc=91.83%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.196470 Test loss=0.316658 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.18285387754440308
[5/24] Train loss=0.16983678936958313
[10/24] Train loss=0.18956537544727325
[15/24] Train loss=0.22081229090690613
[20/24] Train loss=0.1841387152671814
Test set avg_accuracy=82.07% avg_sensitivity=84.41%, avg_specificity=81.23% avg_auc=90.63%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.196667 Test loss=0.400522 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.1986270397901535
[5/24] Train loss=0.18339693546295166
[10/24] Train loss=0.18731366097927094
[15/24] Train loss=0.20455177128314972
[20/24] Train loss=0.18868198990821838
Test set avg_accuracy=82.14% avg_sensitivity=87.18%, avg_specificity=80.33% avg_auc=92.30%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.195667 Test loss=0.384138 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.18144558370113373
[5/24] Train loss=0.16557754576206207
[10/24] Train loss=0.19969002902507782
[15/24] Train loss=0.20255045592784882
[20/24] Train loss=0.1787194311618805
Test set avg_accuracy=72.34% avg_sensitivity=89.16%, avg_specificity=66.34% avg_auc=85.78%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.189768 Test loss=0.637983 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.1788794994354248
[5/24] Train loss=0.16356703639030457
[10/24] Train loss=0.20606058835983276
[15/24] Train loss=0.21921181678771973
[20/24] Train loss=0.18163155019283295
Test set avg_accuracy=86.98% avg_sensitivity=72.79%, avg_specificity=92.05% avg_auc=91.85%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.196079 Test loss=0.310633 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18116170167922974
[5/24] Train loss=0.1674685776233673
[10/24] Train loss=0.18703964352607727
[15/24] Train loss=0.197435662150383
[20/24] Train loss=0.18679778277873993
Test set avg_accuracy=85.08% avg_sensitivity=75.41%, avg_specificity=88.53% avg_auc=91.30%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.189990 Test loss=0.337896 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.18152053654193878
[5/24] Train loss=0.1648627668619156
[10/24] Train loss=0.19565202295780182
[15/24] Train loss=0.208681121468544
[20/24] Train loss=0.185637965798378
Test set avg_accuracy=86.41% avg_sensitivity=63.48%, avg_specificity=94.59% avg_auc=89.92%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.188618 Test loss=0.349694 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.1765952855348587
[5/24] Train loss=0.16336274147033691
[10/24] Train loss=0.1933632344007492
[15/24] Train loss=0.2005002498626709
[20/24] Train loss=0.1733003705739975
Test set avg_accuracy=83.48% avg_sensitivity=84.41%, avg_specificity=83.14% avg_auc=91.90%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.186790 Test loss=0.371463 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.17608585953712463
[5/24] Train loss=0.15175488591194153
[10/24] Train loss=0.18700988590717316
[15/24] Train loss=0.20724456012248993
[20/24] Train loss=0.18053781986236572
Test set avg_accuracy=85.39% avg_sensitivity=83.42%, avg_specificity=86.09% avg_auc=92.75%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.179644 Test loss=0.336953 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.17582115530967712
[5/24] Train loss=0.16310887038707733
[10/24] Train loss=0.19104547798633575
[15/24] Train loss=0.20086054503917694
[20/24] Train loss=0.17285218834877014
Test set avg_accuracy=83.28% avg_sensitivity=83.37%, avg_specificity=83.25% avg_auc=91.55%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.189277 Test loss=0.371086 Current lr=[0.000276307469034998]

[0/24] Train loss=0.16817207634449005
[5/24] Train loss=0.16141019761562347
[10/24] Train loss=0.1996450424194336
[15/24] Train loss=0.19627000391483307
[20/24] Train loss=0.19148501753807068
Test set avg_accuracy=87.57% avg_sensitivity=69.37%, avg_specificity=94.06% avg_auc=91.97%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.184326 Test loss=0.306974 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.17458942532539368
[5/24] Train loss=0.15451882779598236
[10/24] Train loss=0.18909747898578644
[15/24] Train loss=0.19488684833049774
[20/24] Train loss=0.1869668811559677
Test set avg_accuracy=84.39% avg_sensitivity=85.21%, avg_specificity=84.10% avg_auc=92.42%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.183424 Test loss=0.359901 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.17604820430278778
[5/24] Train loss=0.1601669043302536
[10/24] Train loss=0.18732410669326782
[15/24] Train loss=0.196035236120224
[20/24] Train loss=0.17746178805828094
Test set avg_accuracy=86.55% avg_sensitivity=75.11%, avg_specificity=90.63% avg_auc=92.13%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.181690 Test loss=0.326519 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.17383098602294922
[5/24] Train loss=0.15617355704307556
[10/24] Train loss=0.1830359250307083
[15/24] Train loss=0.195771262049675
[20/24] Train loss=0.18758974969387054
Test set avg_accuracy=87.29% avg_sensitivity=76.25%, avg_specificity=91.24% avg_auc=92.72%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.185342 Test loss=0.299666 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.18131709098815918
[5/24] Train loss=0.1752714365720749
[10/24] Train loss=0.203501358628273
[15/24] Train loss=0.20344504714012146
[20/24] Train loss=0.17846639454364777
Test set avg_accuracy=85.96% avg_sensitivity=58.88%, avg_specificity=95.64% avg_auc=89.91%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.189432 Test loss=0.365881 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.1816318780183792
[5/24] Train loss=0.16617009043693542
[10/24] Train loss=0.18807056546211243
[15/24] Train loss=0.19432106614112854
[20/24] Train loss=0.17568880319595337
Test set avg_accuracy=86.20% avg_sensitivity=75.56%, avg_specificity=90.00% avg_auc=92.21%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.181201 Test loss=0.323219 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.1713864803314209
[5/24] Train loss=0.1637747585773468
[10/24] Train loss=0.17905862629413605
[15/24] Train loss=0.19243256747722626
[20/24] Train loss=0.17485982179641724
Test set avg_accuracy=86.81% avg_sensitivity=74.57%, avg_specificity=91.18% avg_auc=92.41%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.179384 Test loss=0.316677 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.17432431876659393
[5/24] Train loss=0.16075484454631805
[10/24] Train loss=0.18054035305976868
[15/24] Train loss=0.19968166947364807
[20/24] Train loss=0.1796162873506546
Test set avg_accuracy=78.54% avg_sensitivity=87.88%, avg_specificity=75.21% avg_auc=89.14%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.181248 Test loss=0.488498 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.18060116469860077
[5/24] Train loss=0.16932889819145203
[10/24] Train loss=0.1854812353849411
[15/24] Train loss=0.18786154687404633
[20/24] Train loss=0.15984374284744263
Test set avg_accuracy=85.83% avg_sensitivity=78.43%, avg_specificity=88.48% avg_auc=92.25%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.177122 Test loss=0.334731 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.16284921765327454
[5/24] Train loss=0.1587212234735489
[10/24] Train loss=0.1691800206899643
[15/24] Train loss=0.19245538115501404
[20/24] Train loss=0.17847242951393127
Test set avg_accuracy=78.52% avg_sensitivity=85.30%, avg_specificity=76.09% avg_auc=89.05%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.174810 Test loss=0.478903 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.1666097193956375
[5/24] Train loss=0.14844439923763275
[10/24] Train loss=0.18173889815807343
[15/24] Train loss=0.18634209036827087
[20/24] Train loss=0.1660173535346985
Test set avg_accuracy=86.84% avg_sensitivity=77.98%, avg_specificity=90.00% avg_auc=92.61%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.173240 Test loss=0.319717 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.17089444398880005
[5/24] Train loss=0.15766213834285736
[10/24] Train loss=0.171122744679451
[15/24] Train loss=0.1764504462480545
[20/24] Train loss=0.1720684915781021
Test set avg_accuracy=80.60% avg_sensitivity=88.57%, avg_specificity=77.75% avg_auc=90.93%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.175237 Test loss=0.437915 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.16975697875022888
[5/24] Train loss=0.16522517800331116
[10/24] Train loss=0.17641595005989075
[15/24] Train loss=0.1879962533712387
[20/24] Train loss=0.16531039774417877
Test set avg_accuracy=85.61% avg_sensitivity=80.65%, avg_specificity=87.38% avg_auc=92.34%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.177913 Test loss=0.332770 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.17121490836143494
[5/24] Train loss=0.14654377102851868
[10/24] Train loss=0.19341212511062622
[15/24] Train loss=0.19292180240154266
[20/24] Train loss=0.17533177137374878
Test set avg_accuracy=75.52% avg_sensitivity=88.52%, avg_specificity=70.88% avg_auc=87.85%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.182662 Test loss=0.544581 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.1737203299999237
[5/24] Train loss=0.15279504656791687
[10/24] Train loss=0.1818891018629074
[15/24] Train loss=0.1854236125946045
[20/24] Train loss=0.1677560955286026
Test set avg_accuracy=86.02% avg_sensitivity=76.35%, avg_specificity=89.47% avg_auc=91.80%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.177374 Test loss=0.331560 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.16764770448207855
[5/24] Train loss=0.1480824202299118
[10/24] Train loss=0.17261967062950134
[15/24] Train loss=0.19384489953517914
[20/24] Train loss=0.17757347226142883
Test set avg_accuracy=87.54% avg_sensitivity=72.59%, avg_specificity=92.88% avg_auc=92.40%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.175055 Test loss=0.305008 Current lr=[0.000224838296036774]

[0/24] Train loss=0.16892950236797333
[5/24] Train loss=0.15932932496070862
[10/24] Train loss=0.1651832014322281
[15/24] Train loss=0.17755557596683502
[20/24] Train loss=0.16443590819835663
Test set avg_accuracy=87.53% avg_sensitivity=73.53%, avg_specificity=92.53% avg_auc=92.31%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.174009 Test loss=0.312634 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.1592891812324524
[5/24] Train loss=0.14865656197071075
[10/24] Train loss=0.16469907760620117
[15/24] Train loss=0.17948828637599945
[20/24] Train loss=0.16165350377559662
Test set avg_accuracy=86.38% avg_sensitivity=76.94%, avg_specificity=89.75% avg_auc=92.44%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.170195 Test loss=0.320081 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.15213517844676971
[5/24] Train loss=0.15421529114246368
[10/24] Train loss=0.1629916876554489
[15/24] Train loss=0.1749449521303177
[20/24] Train loss=0.17012126743793488
Test set avg_accuracy=85.10% avg_sensitivity=80.85%, avg_specificity=86.62% avg_auc=91.06%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.167814 Test loss=0.357964 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.16077405214309692
[5/24] Train loss=0.15067598223686218
[10/24] Train loss=0.15940186381340027
[15/24] Train loss=0.18157991766929626
[20/24] Train loss=0.16890698671340942
Test set avg_accuracy=84.93% avg_sensitivity=50.62%, avg_specificity=97.19% avg_auc=87.30%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.166341 Test loss=0.400855 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.15765297412872314
[5/24] Train loss=0.14962022006511688
[10/24] Train loss=0.1684015989303589
[15/24] Train loss=0.18262940645217896
[20/24] Train loss=0.1617039442062378
Test set avg_accuracy=86.21% avg_sensitivity=61.60%, avg_specificity=95.00% avg_auc=89.84%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.168620 Test loss=0.347932 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.16076253354549408
[5/24] Train loss=0.14453063905239105
[10/24] Train loss=0.1684955656528473
[15/24] Train loss=0.1904091238975525
[20/24] Train loss=0.16142070293426514
Test set avg_accuracy=87.02% avg_sensitivity=66.16%, avg_specificity=94.47% avg_auc=91.26%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.168088 Test loss=0.328961 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.16416731476783752
[5/24] Train loss=0.14664839208126068
[10/24] Train loss=0.1614239513874054
[15/24] Train loss=0.17557300627231598
[20/24] Train loss=0.1567349135875702
Test set avg_accuracy=87.29% avg_sensitivity=76.69%, avg_specificity=91.08% avg_auc=91.71%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.164626 Test loss=0.318742 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.16574519872665405
[5/24] Train loss=0.14720885455608368
[10/24] Train loss=0.1666356772184372
[15/24] Train loss=0.180278480052948
[20/24] Train loss=0.15430405735969543
Test set avg_accuracy=87.21% avg_sensitivity=69.17%, avg_specificity=93.66% avg_auc=91.05%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.166599 Test loss=0.322843 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.15433722734451294
[5/24] Train loss=0.144684836268425
[10/24] Train loss=0.16576874256134033
[15/24] Train loss=0.18117310106754303
[20/24] Train loss=0.1560884267091751
Test set avg_accuracy=85.51% avg_sensitivity=83.13%, avg_specificity=86.36% avg_auc=92.74%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.168502 Test loss=0.332882 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.15842881798744202
[5/24] Train loss=0.15076984465122223
[10/24] Train loss=0.1702847182750702
[15/24] Train loss=0.1778152734041214
[20/24] Train loss=0.16514261066913605
Test set avg_accuracy=87.68% avg_sensitivity=77.54%, avg_specificity=91.31% avg_auc=92.52%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.163432 Test loss=0.303382 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.15759332478046417
[5/24] Train loss=0.14631448686122894
[10/24] Train loss=0.16314731538295746
[15/24] Train loss=0.16945840418338776
[20/24] Train loss=0.1568850874900818
Test set avg_accuracy=87.36% avg_sensitivity=72.34%, avg_specificity=92.72% avg_auc=91.41%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.163010 Test loss=0.323462 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.1541142612695694
[5/24] Train loss=0.14536091685295105
[10/24] Train loss=0.15489614009857178
[15/24] Train loss=0.17317061126232147
[20/24] Train loss=0.15755543112754822
Test set avg_accuracy=87.23% avg_sensitivity=77.29%, avg_specificity=90.78% avg_auc=92.53%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.162025 Test loss=0.309694 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1537923961877823
[5/24] Train loss=0.14483395218849182
[10/24] Train loss=0.1554604470729828
[15/24] Train loss=0.17583081126213074
[20/24] Train loss=0.1674841046333313
Test set avg_accuracy=87.15% avg_sensitivity=68.38%, avg_specificity=93.85% avg_auc=91.31%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.160509 Test loss=0.323723 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.150334432721138
[5/24] Train loss=0.15345366299152374
[10/24] Train loss=0.15842308104038239
[15/24] Train loss=0.17429658770561218
[20/24] Train loss=0.16252347826957703
Test set avg_accuracy=86.52% avg_sensitivity=67.94%, avg_specificity=93.16% avg_auc=90.34%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.162250 Test loss=0.336141 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.15705834329128265
[5/24] Train loss=0.1482018381357193
[10/24] Train loss=0.1523289829492569
[15/24] Train loss=0.16495577991008759
[20/24] Train loss=0.15731199085712433
Test set avg_accuracy=87.28% avg_sensitivity=72.39%, avg_specificity=92.60% avg_auc=91.29%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.159795 Test loss=0.320938 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15315847098827362
[5/24] Train loss=0.14615142345428467
[10/24] Train loss=0.15665395557880402
[15/24] Train loss=0.17085933685302734
[20/24] Train loss=0.1524190753698349
Test set avg_accuracy=87.43% avg_sensitivity=64.92%, avg_specificity=95.48% avg_auc=90.98%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.157895 Test loss=0.324768 Current lr=[0.000156543481933168]

[0/24] Train loss=0.14763742685317993
[5/24] Train loss=0.13962525129318237
[10/24] Train loss=0.16065914928913116
[15/24] Train loss=0.16292023658752441
[20/24] Train loss=0.14955414831638336
Test set avg_accuracy=86.56% avg_sensitivity=58.49%, avg_specificity=96.59% avg_auc=88.53%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.155201 Test loss=0.363798 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1503002941608429
[5/24] Train loss=0.1429663896560669
[10/24] Train loss=0.15273252129554749
[15/24] Train loss=0.1679612547159195
[20/24] Train loss=0.1509118527173996
Test set avg_accuracy=87.16% avg_sensitivity=63.58%, avg_specificity=95.58% avg_auc=89.97%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.155985 Test loss=0.338443 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15001796185970306
[5/24] Train loss=0.13802793622016907
[10/24] Train loss=0.1582876592874527
[15/24] Train loss=0.16267085075378418
[20/24] Train loss=0.14955350756645203
Test set avg_accuracy=86.74% avg_sensitivity=63.88%, avg_specificity=94.91% avg_auc=89.54%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.154576 Test loss=0.339344 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.14650675654411316
[5/24] Train loss=0.14074192941188812
[10/24] Train loss=0.14755526185035706
[15/24] Train loss=0.16848880052566528
[20/24] Train loss=0.14875324070453644
Test set avg_accuracy=87.58% avg_sensitivity=71.05%, avg_specificity=93.48% avg_auc=91.20%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.153775 Test loss=0.316673 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.14772358536720276
[5/24] Train loss=0.14014282822608948
[10/24] Train loss=0.15099084377288818
[15/24] Train loss=0.16402588784694672
[20/24] Train loss=0.14797481894493103
Test set avg_accuracy=87.38% avg_sensitivity=76.55%, avg_specificity=91.25% avg_auc=91.11%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.153848 Test loss=0.319248 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1487383395433426
[5/24] Train loss=0.14108330011367798
[10/24] Train loss=0.1589411199092865
[15/24] Train loss=0.17243322730064392
[20/24] Train loss=0.15478864312171936
Test set avg_accuracy=87.92% avg_sensitivity=70.11%, avg_specificity=94.27% avg_auc=92.50%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.156244 Test loss=0.304408 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1455957293510437
[5/24] Train loss=0.14834843575954437
[10/24] Train loss=0.15863686800003052
[15/24] Train loss=0.16160552203655243
[20/24] Train loss=0.1543492078781128
Test set avg_accuracy=87.54% avg_sensitivity=69.07%, avg_specificity=94.13% avg_auc=90.04%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.153411 Test loss=0.325773 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.149511456489563
[5/24] Train loss=0.14165087044239044
[10/24] Train loss=0.15385551750659943
[15/24] Train loss=0.1658274233341217
[20/24] Train loss=0.14915134012699127
Test set avg_accuracy=86.59% avg_sensitivity=60.96%, avg_specificity=95.74% avg_auc=89.10%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.152721 Test loss=0.357412 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.1430167853832245
[5/24] Train loss=0.1409514844417572
[10/24] Train loss=0.14743398129940033
[15/24] Train loss=0.16381299495697021
[20/24] Train loss=0.15421515703201294
Test set avg_accuracy=87.29% avg_sensitivity=72.59%, avg_specificity=92.54% avg_auc=91.96%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.154177 Test loss=0.313877 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1485225111246109
[5/24] Train loss=0.1382736712694168
[10/24] Train loss=0.14412826299667358
[15/24] Train loss=0.15828491747379303
[20/24] Train loss=0.1507522463798523
Test set avg_accuracy=87.84% avg_sensitivity=69.32%, avg_specificity=94.45% avg_auc=91.26%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.149441 Test loss=0.312261 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14276613295078278
[5/24] Train loss=0.13854581117630005
[10/24] Train loss=0.1456504762172699
[15/24] Train loss=0.1576327383518219
[20/24] Train loss=0.14517763257026672
Test set avg_accuracy=87.94% avg_sensitivity=72.98%, avg_specificity=93.29% avg_auc=92.23%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.148298 Test loss=0.302797 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.14137715101242065
[5/24] Train loss=0.1323181390762329
[10/24] Train loss=0.1443869024515152
[15/24] Train loss=0.15840081870555878
[20/24] Train loss=0.14606963098049164
Test set avg_accuracy=88.05% avg_sensitivity=70.86%, avg_specificity=94.19% avg_auc=92.04%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.147515 Test loss=0.307212 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.13803613185882568
[5/24] Train loss=0.13649967312812805
[10/24] Train loss=0.13857311010360718
[15/24] Train loss=0.15236060321331024
[20/24] Train loss=0.14751173555850983
Test set avg_accuracy=87.19% avg_sensitivity=65.81%, avg_specificity=94.82% avg_auc=91.27%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.145367 Test loss=0.320731 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14050862193107605
[5/24] Train loss=0.13159066438674927
[10/24] Train loss=0.13527081906795502
[15/24] Train loss=0.15045085549354553
[20/24] Train loss=0.14431804418563843
Test set avg_accuracy=88.20% avg_sensitivity=72.04%, avg_specificity=93.97% avg_auc=92.29%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.144319 Test loss=0.300668 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.13834649324417114
[5/24] Train loss=0.13206210732460022
[10/24] Train loss=0.14168769121170044
[15/24] Train loss=0.15033112466335297
[20/24] Train loss=0.1491548717021942
Test set avg_accuracy=88.06% avg_sensitivity=74.07%, avg_specificity=93.06% avg_auc=93.10%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.143898 Test loss=0.296004 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.13534323871135712
[5/24] Train loss=0.13180150091648102
[10/24] Train loss=0.1416541039943695
[15/24] Train loss=0.15425799787044525
[20/24] Train loss=0.13855423033237457
Test set avg_accuracy=87.64% avg_sensitivity=72.44%, avg_specificity=93.07% avg_auc=92.27%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.142731 Test loss=0.305558 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1364716738462448
[5/24] Train loss=0.12907946109771729
[10/24] Train loss=0.1367202252149582
[15/24] Train loss=0.14955578744411469
[20/24] Train loss=0.1425798386335373
Test set avg_accuracy=88.18% avg_sensitivity=74.72%, avg_specificity=92.98% avg_auc=92.96%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.140342 Test loss=0.293354 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13966861367225647
[5/24] Train loss=0.13444304466247559
[10/24] Train loss=0.13969571888446808
[15/24] Train loss=0.1438019871711731
[20/24] Train loss=0.14313705265522003
Test set avg_accuracy=87.80% avg_sensitivity=74.67%, avg_specificity=92.49% avg_auc=92.86%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.140215 Test loss=0.306831 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1336165815591812
[5/24] Train loss=0.12746195495128632
[10/24] Train loss=0.13653434813022614
[15/24] Train loss=0.14824073016643524
[20/24] Train loss=0.14082764089107513
Test set avg_accuracy=88.14% avg_sensitivity=71.35%, avg_specificity=94.13% avg_auc=92.53%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.138608 Test loss=0.302867 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13203725218772888
[5/24] Train loss=0.12876251339912415
[10/24] Train loss=0.134239062666893
[15/24] Train loss=0.14112898707389832
[20/24] Train loss=0.1390821784734726
Test set avg_accuracy=87.28% avg_sensitivity=65.81%, avg_specificity=94.95% avg_auc=91.13%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.136938 Test loss=0.328662 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13405810296535492
[5/24] Train loss=0.12865248322486877
[10/24] Train loss=0.13045935332775116
[15/24] Train loss=0.14067929983139038
[20/24] Train loss=0.14268676936626434
Test set avg_accuracy=88.07% avg_sensitivity=69.37%, avg_specificity=94.75% avg_auc=92.40%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.137147 Test loss=0.305393 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.13043563067913055
[5/24] Train loss=0.12549541890621185
[10/24] Train loss=0.13257165253162384
[15/24] Train loss=0.14424742758274078
[20/24] Train loss=0.1343584805727005
Test set avg_accuracy=87.77% avg_sensitivity=74.02%, avg_specificity=92.68% avg_auc=92.70%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.135556 Test loss=0.301609 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1300601065158844
[5/24] Train loss=0.12268156558275223
[10/24] Train loss=0.12821424007415771
[15/24] Train loss=0.14501352608203888
[20/24] Train loss=0.1343093365430832
Test set avg_accuracy=87.62% avg_sensitivity=74.47%, avg_specificity=92.31% avg_auc=92.55%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.134832 Test loss=0.305580 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13125920295715332
[5/24] Train loss=0.12392347306013107
[10/24] Train loss=0.12803904712200165
[15/24] Train loss=0.1418384611606598
[20/24] Train loss=0.1370960772037506
Test set avg_accuracy=88.50% avg_sensitivity=73.82%, avg_specificity=93.74% avg_auc=92.89%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.134202 Test loss=0.296076 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.12914429605007172
[5/24] Train loss=0.12286536395549774
[10/24] Train loss=0.13192760944366455
[15/24] Train loss=0.14229747653007507
[20/24] Train loss=0.13372285664081573
Test set avg_accuracy=87.77% avg_sensitivity=72.24%, avg_specificity=93.32% avg_auc=92.79%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.133539 Test loss=0.301877 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1289292871952057
[5/24] Train loss=0.12284265458583832
[10/24] Train loss=0.1275557577610016
[15/24] Train loss=0.13832740485668182
[20/24] Train loss=0.13221198320388794
Test set avg_accuracy=87.97% avg_sensitivity=72.69%, avg_specificity=93.43% avg_auc=92.71%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.132572 Test loss=0.300331 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.12875068187713623
[5/24] Train loss=0.12115360051393509
[10/24] Train loss=0.13026869297027588
[15/24] Train loss=0.136499285697937
[20/24] Train loss=0.1342068463563919
Test set avg_accuracy=87.77% avg_sensitivity=73.48%, avg_specificity=92.88% avg_auc=92.73%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.132059 Test loss=0.301765 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12551607191562653
[5/24] Train loss=0.12262845784425735
[10/24] Train loss=0.12341852486133575
[15/24] Train loss=0.1386527419090271
[20/24] Train loss=0.13317105174064636
Test set avg_accuracy=87.55% avg_sensitivity=77.14%, avg_specificity=91.27% avg_auc=92.61%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.131078 Test loss=0.311118 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1266920566558838
[5/24] Train loss=0.1210285872220993
[10/24] Train loss=0.12483767420053482
[15/24] Train loss=0.1379103660583496
[20/24] Train loss=0.13352468609809875
Test set avg_accuracy=87.47% avg_sensitivity=77.14%, avg_specificity=91.16% avg_auc=92.70%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.130886 Test loss=0.309132 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.128291055560112
[5/24] Train loss=0.12244075536727905
[10/24] Train loss=0.1243608221411705
[15/24] Train loss=0.1368148922920227
[20/24] Train loss=0.1291714906692505
Test set avg_accuracy=87.12% avg_sensitivity=73.58%, avg_specificity=91.96% avg_auc=91.58%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.130476 Test loss=0.321018 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12484733760356903
[5/24] Train loss=0.12044657766819
[10/24] Train loss=0.12109670042991638
[15/24] Train loss=0.13521428406238556
[20/24] Train loss=0.13230833411216736
Test set avg_accuracy=86.98% avg_sensitivity=78.08%, avg_specificity=90.16% avg_auc=92.17%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.128985 Test loss=0.321284 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12454834580421448
[5/24] Train loss=0.1220763623714447
[10/24] Train loss=0.12340281158685684
[15/24] Train loss=0.13606059551239014
[20/24] Train loss=0.1330157369375229
Test set avg_accuracy=87.85% avg_sensitivity=78.03%, avg_specificity=91.36% avg_auc=92.86%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.129535 Test loss=0.303058 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12345093488693237
[5/24] Train loss=0.11940276622772217
[10/24] Train loss=0.12545043230056763
[15/24] Train loss=0.13701343536376953
[20/24] Train loss=0.13329185545444489
Test set avg_accuracy=87.42% avg_sensitivity=79.22%, avg_specificity=90.35% avg_auc=92.72%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.129105 Test loss=0.310191 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12361758947372437
[5/24] Train loss=0.11894126981496811
[10/24] Train loss=0.12467728555202484
[15/24] Train loss=0.13470086455345154
[20/24] Train loss=0.131675586104393
Test set avg_accuracy=87.59% avg_sensitivity=79.76%, avg_specificity=90.39% avg_auc=92.97%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.128899 Test loss=0.307469 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12453542649745941
[5/24] Train loss=0.11756487935781479
[10/24] Train loss=0.12031430006027222
[15/24] Train loss=0.13476264476776123
[20/24] Train loss=0.13167482614517212
Test set avg_accuracy=87.75% avg_sensitivity=78.97%, avg_specificity=90.88% avg_auc=93.10%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.127936 Test loss=0.305038 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.124595046043396
[5/24] Train loss=0.11965647339820862
[10/24] Train loss=0.1215658113360405
[15/24] Train loss=0.13095098733901978
[20/24] Train loss=0.13104911148548126
Test set avg_accuracy=87.86% avg_sensitivity=77.68%, avg_specificity=91.50% avg_auc=92.95%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.127209 Test loss=0.304444 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12149803340435028
[5/24] Train loss=0.11700310558080673
[10/24] Train loss=0.12137351930141449
[15/24] Train loss=0.13408499956130981
[20/24] Train loss=0.12840788066387177
Test set avg_accuracy=88.01% avg_sensitivity=77.44%, avg_specificity=91.78% avg_auc=93.14%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.126655 Test loss=0.300005 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12175766378641129
[5/24] Train loss=0.11675246059894562
[10/24] Train loss=0.11794448643922806
[15/24] Train loss=0.13056735694408417
[20/24] Train loss=0.12602415680885315
Test set avg_accuracy=87.88% avg_sensitivity=78.48%, avg_specificity=91.24% avg_auc=92.91%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.125434 Test loss=0.304982 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12047534435987473
[5/24] Train loss=0.11625340580940247
[10/24] Train loss=0.1203264445066452
[15/24] Train loss=0.1285117119550705
[20/24] Train loss=0.12669721245765686
Test set avg_accuracy=87.88% avg_sensitivity=77.19%, avg_specificity=91.69% avg_auc=92.96%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.124228 Test loss=0.300263 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.11674366891384125
[5/24] Train loss=0.11490156501531601
[10/24] Train loss=0.11950457096099854
[15/24] Train loss=0.13077116012573242
[20/24] Train loss=0.1267327517271042
Test set avg_accuracy=87.93% avg_sensitivity=78.72%, avg_specificity=91.22% avg_auc=93.21%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.123904 Test loss=0.300516 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.11842259019613266
[5/24] Train loss=0.11458610743284225
[10/24] Train loss=0.12032528221607208
[15/24] Train loss=0.12765267491340637
[20/24] Train loss=0.1248716190457344
Test set avg_accuracy=87.81% avg_sensitivity=76.30%, avg_specificity=91.92% avg_auc=92.86%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.123462 Test loss=0.301431 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1185421496629715
[5/24] Train loss=0.11401156336069107
[10/24] Train loss=0.11752064526081085
[15/24] Train loss=0.12835024297237396
[20/24] Train loss=0.12611186504364014
Test set avg_accuracy=87.85% avg_sensitivity=78.13%, avg_specificity=91.32% avg_auc=93.14%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.123062 Test loss=0.300101 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.11801543831825256
[5/24] Train loss=0.11248864233493805
[10/24] Train loss=0.11682317405939102
[15/24] Train loss=0.12871405482292175
[20/24] Train loss=0.12643657624721527
Test set avg_accuracy=87.89% avg_sensitivity=77.24%, avg_specificity=91.69% avg_auc=92.93%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.122055 Test loss=0.300303 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.11737711727619171
[5/24] Train loss=0.11344088613986969
[10/24] Train loss=0.11633233726024628
[15/24] Train loss=0.12762770056724548
[20/24] Train loss=0.12354125827550888
Test set avg_accuracy=88.01% avg_sensitivity=76.89%, avg_specificity=91.98% avg_auc=92.92%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.122053 Test loss=0.300771 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11679426580667496
[5/24] Train loss=0.11316611617803574
[10/24] Train loss=0.1169552206993103
[15/24] Train loss=0.12711243331432343
[20/24] Train loss=0.1245412603020668
Test set avg_accuracy=87.94% avg_sensitivity=77.34%, avg_specificity=91.73% avg_auc=92.97%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.122260 Test loss=0.300253 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1173568144440651
[5/24] Train loss=0.11432819813489914
[10/24] Train loss=0.11536325514316559
[15/24] Train loss=0.12685811519622803
[20/24] Train loss=0.12186229228973389
Test set avg_accuracy=88.01% avg_sensitivity=77.44%, avg_specificity=91.78% avg_auc=93.10%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.121726 Test loss=0.298201 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11745423078536987
[5/24] Train loss=0.1106802374124527
[10/24] Train loss=0.11639855057001114
[15/24] Train loss=0.1259828358888626
[20/24] Train loss=0.12668068706989288
Test set avg_accuracy=87.92% avg_sensitivity=77.59%, avg_specificity=91.61% avg_auc=93.01%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.121773 Test loss=0.299931 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.11844845116138458
[5/24] Train loss=0.1114673987030983
[10/24] Train loss=0.11564125120639801
[15/24] Train loss=0.12760627269744873
[20/24] Train loss=0.12393493950366974
Test set avg_accuracy=87.90% avg_sensitivity=76.99%, avg_specificity=91.80% avg_auc=92.93%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.121589 Test loss=0.300223 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11382359266281128
[5/24] Train loss=0.11205635219812393
[10/24] Train loss=0.11646042764186859
[15/24] Train loss=0.12747009098529816
[20/24] Train loss=0.12287041544914246
Test set avg_accuracy=87.99% avg_sensitivity=77.39%, avg_specificity=91.78% avg_auc=92.96%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.121214 Test loss=0.300260 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11676142364740372
[5/24] Train loss=0.11280927807092667
[10/24] Train loss=0.11532505601644516
[15/24] Train loss=0.12657928466796875
[20/24] Train loss=0.12435384094715118
Test set avg_accuracy=87.94% avg_sensitivity=77.29%, avg_specificity=91.75% avg_auc=92.96%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.121527 Test loss=0.300799 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12177830934524536
[5/24] Train loss=0.11267482489347458
[10/24] Train loss=0.11736573278903961
[15/24] Train loss=0.12695053219795227
[20/24] Train loss=0.1259460747241974
Test set avg_accuracy=87.92% avg_sensitivity=77.29%, avg_specificity=91.71% avg_auc=92.95%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.121740 Test loss=0.300850 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11527017503976822
[5/24] Train loss=0.1110609620809555
[10/24] Train loss=0.1151907816529274
[15/24] Train loss=0.12814347445964813
[20/24] Train loss=0.12554608285427094
Test set avg_accuracy=87.92% avg_sensitivity=77.24%, avg_specificity=91.73% avg_auc=92.95%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.121584 Test loss=0.300667 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11639788001775742
[5/24] Train loss=0.11237312853336334
[10/24] Train loss=0.1183004155755043
[15/24] Train loss=0.1266942024230957
[20/24] Train loss=0.1234295517206192
Test set avg_accuracy=87.90% avg_sensitivity=77.29%, avg_specificity=91.69% avg_auc=92.95%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.121308 Test loss=0.300789 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11692444235086441
[5/24] Train loss=0.11269402503967285
[10/24] Train loss=0.11611034721136093
[15/24] Train loss=0.12776826322078705
[20/24] Train loss=0.12648534774780273
Test set avg_accuracy=87.90% avg_sensitivity=77.24%, avg_specificity=91.71% avg_auc=92.95%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.121354 Test loss=0.300730 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=87.90% sen=80.95%, spe=90.39%, auc=93.82%!
Fold[1] Avg_overlap=0.72%(0.22060373434716307)
[0/24] Train loss=0.7188782691955566
[5/24] Train loss=0.7172929644584656
[10/24] Train loss=0.7060985565185547
[15/24] Train loss=0.7015687823295593
[20/24] Train loss=0.6827689409255981
Test set avg_accuracy=51.59% avg_sensitivity=58.32%, avg_specificity=49.35% avg_auc=55.95%
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.705259 Test loss=0.702649 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6873329877853394
[5/24] Train loss=0.683442234992981
[10/24] Train loss=0.6736482381820679
[15/24] Train loss=0.6682266592979431
[20/24] Train loss=0.6705537438392639
Test set avg_accuracy=65.62% avg_sensitivity=65.88%, avg_specificity=65.54% avg_auc=70.76%
Best model saved!! Metric=-58.19097406367369!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.676978 Test loss=0.627032 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6578486561775208
[5/24] Train loss=0.6538180112838745
[10/24] Train loss=0.6427275538444519
[15/24] Train loss=0.6366941928863525
[20/24] Train loss=0.6357910633087158
Test set avg_accuracy=69.97% avg_sensitivity=71.21%, avg_specificity=69.56% avg_auc=76.47%
Best model saved!! Metric=-38.78726799210668!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.649231 Test loss=0.591675 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6287122368812561
[5/24] Train loss=0.6166409850120544
[10/24] Train loss=0.6182129383087158
[15/24] Train loss=0.6044005155563354
[20/24] Train loss=0.6082797050476074
Test set avg_accuracy=71.73% avg_sensitivity=73.14%, avg_specificity=71.26% avg_auc=78.99%
Best model saved!! Metric=-30.878217824004494!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.621120 Test loss=0.568207 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6015747785568237
[5/24] Train loss=0.5875617265701294
[10/24] Train loss=0.5893364548683167
[15/24] Train loss=0.5837370753288269
[20/24] Train loss=0.5776053071022034
Test set avg_accuracy=74.06% avg_sensitivity=74.70%, avg_specificity=73.85% avg_auc=81.13%
Best model saved!! Metric=-22.253424505717078!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.594074 Test loss=0.541675 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5710403919219971
[5/24] Train loss=0.5560799837112427
[10/24] Train loss=0.5569917559623718
[15/24] Train loss=0.5515534281730652
[20/24] Train loss=0.54543137550354
Test set avg_accuracy=76.20% avg_sensitivity=74.23%, avg_specificity=76.85% avg_auc=82.99%
Best model saved!! Metric=-15.726199828113081!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.563560 Test loss=0.510557 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.534213662147522
[5/24] Train loss=0.522969663143158
[10/24] Train loss=0.5240269303321838
[15/24] Train loss=0.5137608051300049
[20/24] Train loss=0.5202214121818542
Test set avg_accuracy=77.98% avg_sensitivity=76.00%, avg_specificity=78.64% avg_auc=84.50%
Best model saved!! Metric=-8.871272310330127!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.534786 Test loss=0.487336 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5096985697746277
[5/24] Train loss=0.4901808798313141
[10/24] Train loss=0.4936337471008301
[15/24] Train loss=0.4859812259674072
[20/24] Train loss=0.485131174325943
Test set avg_accuracy=79.78% avg_sensitivity=75.07%, avg_specificity=81.35% avg_auc=85.73%
Best model saved!! Metric=-4.081141989819628!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.504691 Test loss=0.461917 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.4771627187728882
[5/24] Train loss=0.464169979095459
[10/24] Train loss=0.4617600440979004
[15/24] Train loss=0.45538607239723206
[20/24] Train loss=0.44981011748313904
Test set avg_accuracy=81.68% avg_sensitivity=74.96%, avg_specificity=83.91% avg_auc=87.11%
Best model saved!! Metric=1.6632527238376866!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.475237 Test loss=0.435217 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.44852715730667114
[5/24] Train loss=0.42804235219955444
[10/24] Train loss=0.4310813248157501
[15/24] Train loss=0.42939117550849915
[20/24] Train loss=0.41919827461242676
Test set avg_accuracy=82.73% avg_sensitivity=75.95%, avg_specificity=84.99% avg_auc=88.12%
Best model saved!! Metric=5.798702675941811!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.446080 Test loss=0.415176 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.419166624546051
[5/24] Train loss=0.4023262858390808
[10/24] Train loss=0.41378068923950195
[15/24] Train loss=0.4004862904548645
[20/24] Train loss=0.3919166028499603
Test set avg_accuracy=83.20% avg_sensitivity=76.47%, avg_specificity=85.44% avg_auc=88.96%
Best model saved!! Metric=8.074381032153738!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.418927 Test loss=0.400767 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.39149191975593567
[5/24] Train loss=0.3782527446746826
[10/24] Train loss=0.38409292697906494
[15/24] Train loss=0.38007107377052307
[20/24] Train loss=0.36339041590690613
Test set avg_accuracy=84.69% avg_sensitivity=74.54%, avg_specificity=88.06% avg_auc=89.73%
Best model saved!! Metric=11.023924573106854!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.395431 Test loss=0.373464 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3710969388484955
[5/24] Train loss=0.3577853739261627
[10/24] Train loss=0.3706608712673187
[15/24] Train loss=0.35692098736763
[20/24] Train loss=0.34355428814888
Test set avg_accuracy=84.86% avg_sensitivity=74.91%, avg_specificity=88.17% avg_auc=90.24%
Best model saved!! Metric=12.173759545252793!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.375045 Test loss=0.363586 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.34846240282058716
[5/24] Train loss=0.337356835603714
[10/24] Train loss=0.3506554663181305
[15/24] Train loss=0.3398805558681488
[20/24] Train loss=0.32930421829223633
Test set avg_accuracy=85.26% avg_sensitivity=75.80%, avg_specificity=88.41% avg_auc=90.76%
Best model saved!! Metric=14.228011194056208!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.357162 Test loss=0.356002 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3353229761123657
[5/24] Train loss=0.324332594871521
[10/24] Train loss=0.3405742943286896
[15/24] Train loss=0.32929566502571106
[20/24] Train loss=0.31323257088661194
Test set avg_accuracy=85.66% avg_sensitivity=76.00%, avg_specificity=88.88% avg_auc=91.11%
Best model saved!! Metric=15.651976151664684!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.343753 Test loss=0.344448 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.31326574087142944
[5/24] Train loss=0.31893759965896606
[10/24] Train loss=0.3266461491584778
[15/24] Train loss=0.3151192367076874
[20/24] Train loss=0.297014445066452
Test set avg_accuracy=86.04% avg_sensitivity=74.02%, avg_specificity=90.04% avg_auc=91.39%
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.331480 Test loss=0.332614 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3049589991569519
[5/24] Train loss=0.3028891384601593
[10/24] Train loss=0.3139301538467407
[15/24] Train loss=0.3003787398338318
[20/24] Train loss=0.2837110161781311
Test set avg_accuracy=86.09% avg_sensitivity=74.91%, avg_specificity=89.81% avg_auc=91.67%
Best model saved!! Metric=16.484422749034607!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.319171 Test loss=0.327836 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.29325413703918457
[5/24] Train loss=0.28536760807037354
[10/24] Train loss=0.30338218808174133
[15/24] Train loss=0.29615867137908936
[20/24] Train loss=0.27199769020080566
Test set avg_accuracy=86.03% avg_sensitivity=76.11%, avg_specificity=89.33% avg_auc=91.86%
Best model saved!! Metric=17.328134567203136!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.309614 Test loss=0.325198 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.2838671803474426
[5/24] Train loss=0.2898286283016205
[10/24] Train loss=0.3016040623188019
[15/24] Train loss=0.2869666516780853
[20/24] Train loss=0.2633742392063141
Test set avg_accuracy=85.55% avg_sensitivity=77.88%, avg_specificity=88.10% avg_auc=91.80%
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.302610 Test loss=0.330313 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2733374834060669
[5/24] Train loss=0.2751343548297882
[10/24] Train loss=0.29260358214378357
[15/24] Train loss=0.2806861400604248
[20/24] Train loss=0.2571570873260498
Test set avg_accuracy=86.20% avg_sensitivity=76.42%, avg_specificity=89.45% avg_auc=92.23%
Best model saved!! Metric=18.300018005491836!!
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.293796 Test loss=0.315990 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2683473825454712
[5/24] Train loss=0.2612689733505249
[10/24] Train loss=0.2878919243812561
[15/24] Train loss=0.26855456829071045
[20/24] Train loss=0.24975590407848358
Test set avg_accuracy=86.59% avg_sensitivity=71.94%, avg_specificity=91.46% avg_auc=92.37%
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.286789 Test loss=0.302954 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.25664353370666504
[5/24] Train loss=0.25602370500564575
[10/24] Train loss=0.28103700280189514
[15/24] Train loss=0.2622374892234802
[20/24] Train loss=0.2442680150270462
Test set avg_accuracy=87.30% avg_sensitivity=71.52%, avg_specificity=92.56% avg_auc=92.64%
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.279315 Test loss=0.294771 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.25400322675704956
[5/24] Train loss=0.2545514702796936
[10/24] Train loss=0.2746647894382477
[15/24] Train loss=0.25161996483802795
[20/24] Train loss=0.23334603011608124
Test set avg_accuracy=87.76% avg_sensitivity=68.96%, avg_specificity=94.01% avg_auc=92.79%
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.273576 Test loss=0.290306 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.24763000011444092
[5/24] Train loss=0.24567246437072754
[10/24] Train loss=0.2686218321323395
[15/24] Train loss=0.24872705340385437
[20/24] Train loss=0.23634037375450134
Test set avg_accuracy=88.02% avg_sensitivity=71.36%, avg_specificity=93.56% avg_auc=92.78%
Best model saved!! Metric=19.725022750270185!!
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.267410 Test loss=0.290814 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.24683864414691925
[5/24] Train loss=0.24396522343158722
[10/24] Train loss=0.2599029541015625
[15/24] Train loss=0.24411176145076752
[20/24] Train loss=0.22800211608409882
Test set avg_accuracy=87.63% avg_sensitivity=69.43%, avg_specificity=93.68% avg_auc=93.02%
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.262421 Test loss=0.286589 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.23872464895248413
[5/24] Train loss=0.2421478033065796
[10/24] Train loss=0.25731781125068665
[15/24] Train loss=0.2468324452638626
[20/24] Train loss=0.23021775484085083
Test set avg_accuracy=87.12% avg_sensitivity=77.00%, avg_specificity=90.49% avg_auc=92.60%
Best model saved!! Metric=21.21133222544711!!
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.259818 Test loss=0.307402 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2399444729089737
[5/24] Train loss=0.24427753686904907
[10/24] Train loss=0.25628772377967834
[15/24] Train loss=0.2371366322040558
[20/24] Train loss=0.23124484717845917
Test set avg_accuracy=87.15% avg_sensitivity=70.68%, avg_specificity=92.63% avg_auc=91.90%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.256759 Test loss=0.307614 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.23797613382339478
[5/24] Train loss=0.24567903578281403
[10/24] Train loss=0.2511918544769287
[15/24] Train loss=0.235248863697052
[20/24] Train loss=0.21790432929992676
Test set avg_accuracy=86.18% avg_sensitivity=57.28%, avg_specificity=95.80% avg_auc=91.40%
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.251264 Test loss=0.317104 Current lr=[0.000210185142098938]

[0/24] Train loss=0.23634091019630432
[5/24] Train loss=0.22650791704654694
[10/24] Train loss=0.24221329391002655
[15/24] Train loss=0.2360912412405014
[20/24] Train loss=0.2191171497106552
Test set avg_accuracy=87.21% avg_sensitivity=62.49%, avg_specificity=95.44% avg_auc=92.70%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.247484 Test loss=0.294371 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.22627630829811096
[5/24] Train loss=0.22120197117328644
[10/24] Train loss=0.23936578631401062
[15/24] Train loss=0.23484455049037933
[20/24] Train loss=0.2150830626487732
Test set avg_accuracy=87.47% avg_sensitivity=70.16%, avg_specificity=93.23% avg_auc=92.42%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.242174 Test loss=0.295016 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.22000348567962646
[5/24] Train loss=0.22318129241466522
[10/24] Train loss=0.23568540811538696
[15/24] Train loss=0.23355241119861603
[20/24] Train loss=0.21131417155265808
Test set avg_accuracy=86.85% avg_sensitivity=66.67%, avg_specificity=93.56% avg_auc=91.73%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.240825 Test loss=0.304624 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.22746706008911133
[5/24] Train loss=0.2115698754787445
[10/24] Train loss=0.23765696585178375
[15/24] Train loss=0.23749597370624542
[20/24] Train loss=0.21245098114013672
Test set avg_accuracy=86.76% avg_sensitivity=68.34%, avg_specificity=92.89% avg_auc=91.75%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.238645 Test loss=0.307877 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.21724142134189606
[5/24] Train loss=0.2095032036304474
[10/24] Train loss=0.2456488460302353
[15/24] Train loss=0.2298145592212677
[20/24] Train loss=0.21468986570835114
Test set avg_accuracy=85.91% avg_sensitivity=80.23%, avg_specificity=87.80% avg_auc=91.81%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.237680 Test loss=0.333632 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.22565551102161407
[5/24] Train loss=0.20522785186767578
[10/24] Train loss=0.2228848785161972
[15/24] Train loss=0.2235679179430008
[20/24] Train loss=0.20289085805416107
Test set avg_accuracy=84.90% avg_sensitivity=80.86%, avg_specificity=86.24% avg_auc=91.38%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.233434 Test loss=0.343803 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.21600425243377686
[5/24] Train loss=0.20980989933013916
[10/24] Train loss=0.2257177084684372
[15/24] Train loss=0.219289168715477
[20/24] Train loss=0.21404846012592316
Test set avg_accuracy=86.73% avg_sensitivity=71.05%, avg_specificity=91.95% avg_auc=92.11%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.229516 Test loss=0.305268 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.20885954797267914
[5/24] Train loss=0.2090783566236496
[10/24] Train loss=0.22792883217334747
[15/24] Train loss=0.22939419746398926
[20/24] Train loss=0.20140334963798523
Test set avg_accuracy=87.32% avg_sensitivity=69.48%, avg_specificity=93.25% avg_auc=91.98%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.229788 Test loss=0.300743 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.20553341507911682
[5/24] Train loss=0.21110783517360687
[10/24] Train loss=0.22767341136932373
[15/24] Train loss=0.22707034647464752
[20/24] Train loss=0.20004630088806152
Test set avg_accuracy=87.02% avg_sensitivity=66.51%, avg_specificity=93.84% avg_auc=91.90%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.225302 Test loss=0.302748 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.20173077285289764
[5/24] Train loss=0.20570389926433563
[10/24] Train loss=0.22990265488624573
[15/24] Train loss=0.22295507788658142
[20/24] Train loss=0.19158624112606049
Test set avg_accuracy=86.21% avg_sensitivity=62.23%, avg_specificity=94.19% avg_auc=90.80%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.225638 Test loss=0.329261 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.19708210229873657
[5/24] Train loss=0.20067530870437622
[10/24] Train loss=0.21510225534439087
[15/24] Train loss=0.20993547141551971
[20/24] Train loss=0.18794459104537964
Test set avg_accuracy=85.03% avg_sensitivity=75.01%, avg_specificity=88.36% avg_auc=90.63%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.216572 Test loss=0.342565 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.1961301565170288
[5/24] Train loss=0.19686615467071533
[10/24] Train loss=0.21323910355567932
[15/24] Train loss=0.21357358992099762
[20/24] Train loss=0.18775062263011932
Test set avg_accuracy=84.27% avg_sensitivity=80.02%, avg_specificity=85.68% avg_auc=91.03%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.217640 Test loss=0.350943 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.19746850430965424
[5/24] Train loss=0.1955203413963318
[10/24] Train loss=0.2192562222480774
[15/24] Train loss=0.21617448329925537
[20/24] Train loss=0.2161916047334671
Test set avg_accuracy=85.59% avg_sensitivity=60.82%, avg_specificity=93.82% avg_auc=89.51%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.215499 Test loss=0.354149 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.20691396296024323
[5/24] Train loss=0.20263555645942688
[10/24] Train loss=0.21745768189430237
[15/24] Train loss=0.20604561269283295
[20/24] Train loss=0.19839635491371155
Test set avg_accuracy=84.78% avg_sensitivity=76.89%, avg_specificity=87.40% avg_auc=90.15%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.219751 Test loss=0.358363 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.1970096230506897
[5/24] Train loss=0.19268806278705597
[10/24] Train loss=0.21464689075946808
[15/24] Train loss=0.22391822934150696
[20/24] Train loss=0.19980640709400177
Test set avg_accuracy=86.54% avg_sensitivity=70.84%, avg_specificity=91.76% avg_auc=91.60%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.216487 Test loss=0.312260 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.19595132768154144
[5/24] Train loss=0.20088088512420654
[10/24] Train loss=0.21871189773082733
[15/24] Train loss=0.20845910906791687
[20/24] Train loss=0.18613384664058685
Test set avg_accuracy=87.06% avg_sensitivity=69.90%, avg_specificity=92.76% avg_auc=92.29%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.210633 Test loss=0.295972 Current lr=[0.00029967723776099]

[0/24] Train loss=0.19199000298976898
[5/24] Train loss=0.19965268671512604
[10/24] Train loss=0.214077889919281
[15/24] Train loss=0.2136676162481308
[20/24] Train loss=0.19545134902000427
Test set avg_accuracy=84.18% avg_sensitivity=44.44%, avg_specificity=97.40% avg_auc=87.96%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.212523 Test loss=0.397125 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.20731300115585327
[5/24] Train loss=0.19364167749881744
[10/24] Train loss=0.213265523314476
[15/24] Train loss=0.2175450474023819
[20/24] Train loss=0.18396171927452087
Test set avg_accuracy=85.59% avg_sensitivity=78.20%, avg_specificity=88.04% avg_auc=90.68%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.213630 Test loss=0.348076 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.19001440703868866
[5/24] Train loss=0.1966274082660675
[10/24] Train loss=0.21487364172935486
[15/24] Train loss=0.1970800757408142
[20/24] Train loss=0.1821506917476654
Test set avg_accuracy=86.17% avg_sensitivity=68.65%, avg_specificity=92.00% avg_auc=90.12%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.206913 Test loss=0.334720 Current lr=[0.000299720220882401]

[0/24] Train loss=0.19273242354393005
[5/24] Train loss=0.18826396763324738
[10/24] Train loss=0.2137944996356964
[15/24] Train loss=0.19490274786949158
[20/24] Train loss=0.1774413138628006
Test set avg_accuracy=86.71% avg_sensitivity=67.08%, avg_specificity=93.23% avg_auc=91.00%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.207127 Test loss=0.324543 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.18593601882457733
[5/24] Train loss=0.19174420833587646
[10/24] Train loss=0.20403505861759186
[15/24] Train loss=0.19050167500972748
[20/24] Train loss=0.18037149310112
Test set avg_accuracy=86.33% avg_sensitivity=73.34%, avg_specificity=90.65% avg_auc=91.97%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.200309 Test loss=0.312985 Current lr=[0.000298904600941902]

[0/24] Train loss=0.18004174530506134
[5/24] Train loss=0.18178077042102814
[10/24] Train loss=0.19028960168361664
[15/24] Train loss=0.19671273231506348
[20/24] Train loss=0.18102259933948517
Test set avg_accuracy=82.73% avg_sensitivity=82.21%, avg_specificity=82.91% avg_auc=89.83%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.195640 Test loss=0.407703 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.19220276176929474
[5/24] Train loss=0.18576139211654663
[10/24] Train loss=0.19994334876537323
[15/24] Train loss=0.19523583352565765
[20/24] Train loss=0.177743598818779
Test set avg_accuracy=86.30% avg_sensitivity=69.64%, avg_specificity=91.84% avg_auc=90.19%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.199212 Test loss=0.349296 Current lr=[0.000297555943323901]

[0/24] Train loss=0.18167757987976074
[5/24] Train loss=0.18273717164993286
[10/24] Train loss=0.2191847264766693
[15/24] Train loss=0.20684684813022614
[20/24] Train loss=0.18658272922039032
Test set avg_accuracy=84.11% avg_sensitivity=42.83%, avg_specificity=97.85% avg_auc=88.83%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.204875 Test loss=0.403854 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.18836401402950287
[5/24] Train loss=0.1776823252439499
[10/24] Train loss=0.20758157968521118
[15/24] Train loss=0.19584983587265015
[20/24] Train loss=0.17600183188915253
Test set avg_accuracy=83.06% avg_sensitivity=76.32%, avg_specificity=85.30% avg_auc=90.23%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.199166 Test loss=0.367414 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.18594034016132355
[5/24] Train loss=0.20082546770572662
[10/24] Train loss=0.2126634120941162
[15/24] Train loss=0.20620569586753845
[20/24] Train loss=0.17851296067237854
Test set avg_accuracy=85.85% avg_sensitivity=66.30%, avg_specificity=92.35% avg_auc=90.14%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.205185 Test loss=0.332826 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.1794021725654602
[5/24] Train loss=0.18480390310287476
[10/24] Train loss=0.2015153467655182
[15/24] Train loss=0.19292864203453064
[20/24] Train loss=0.18071392178535461
Test set avg_accuracy=86.03% avg_sensitivity=77.57%, avg_specificity=88.84% avg_auc=91.69%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.198876 Test loss=0.324628 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.18078376352787018
[5/24] Train loss=0.17815834283828735
[10/24] Train loss=0.19395023584365845
[15/24] Train loss=0.18482889235019684
[20/24] Train loss=0.17214302718639374
Test set avg_accuracy=85.16% avg_sensitivity=75.17%, avg_specificity=88.48% avg_auc=89.77%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.192220 Test loss=0.358467 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.18415576219558716
[5/24] Train loss=0.18879249691963196
[10/24] Train loss=0.19937357306480408
[15/24] Train loss=0.18748077750205994
[20/24] Train loss=0.17715001106262207
Test set avg_accuracy=85.62% avg_sensitivity=70.89%, avg_specificity=90.53% avg_auc=89.31%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.195544 Test loss=0.366589 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.18108518421649933
[5/24] Train loss=0.19287516176700592
[10/24] Train loss=0.19288571178913116
[15/24] Train loss=0.18996278941631317
[20/24] Train loss=0.16568966209888458
Test set avg_accuracy=84.23% avg_sensitivity=73.29%, avg_specificity=87.87% avg_auc=88.39%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.195916 Test loss=0.379910 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.20424723625183105
[5/24] Train loss=0.17763829231262207
[10/24] Train loss=0.19280990958213806
[15/24] Train loss=0.1884162724018097
[20/24] Train loss=0.16406235098838806
Test set avg_accuracy=86.33% avg_sensitivity=74.13%, avg_specificity=90.39% avg_auc=91.00%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.192504 Test loss=0.327719 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18601085245609283
[5/24] Train loss=0.1794281154870987
[10/24] Train loss=0.18937721848487854
[15/24] Train loss=0.18615756928920746
[20/24] Train loss=0.16664546728134155
Test set avg_accuracy=86.89% avg_sensitivity=72.82%, avg_specificity=91.57% avg_auc=90.41%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.190314 Test loss=0.333717 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.17405559122562408
[5/24] Train loss=0.1945493072271347
[10/24] Train loss=0.19317741692066193
[15/24] Train loss=0.19465956091880798
[20/24] Train loss=0.1701226383447647
Test set avg_accuracy=84.65% avg_sensitivity=77.26%, avg_specificity=87.11% avg_auc=90.35%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.194863 Test loss=0.365092 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.18122820556163788
[5/24] Train loss=0.17526495456695557
[10/24] Train loss=0.1903725415468216
[15/24] Train loss=0.19039063155651093
[20/24] Train loss=0.1627357304096222
Test set avg_accuracy=86.04% avg_sensitivity=60.62%, avg_specificity=94.50% avg_auc=88.75%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.187445 Test loss=0.352286 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.173888698220253
[5/24] Train loss=0.17760425806045532
[10/24] Train loss=0.19834832847118378
[15/24] Train loss=0.18700037896633148
[20/24] Train loss=0.16787856817245483
Test set avg_accuracy=84.09% avg_sensitivity=59.68%, avg_specificity=92.21% avg_auc=85.80%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.190306 Test loss=0.393970 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.19014768302440643
[5/24] Train loss=0.18733127415180206
[10/24] Train loss=0.19773785769939423
[15/24] Train loss=0.19631078839302063
[20/24] Train loss=0.16758592426776886
Test set avg_accuracy=86.51% avg_sensitivity=61.87%, avg_specificity=94.71% avg_auc=90.36%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.195444 Test loss=0.339793 Current lr=[0.000276307469034998]

[0/24] Train loss=0.17461170256137848
[5/24] Train loss=0.1970110684633255
[10/24] Train loss=0.18830840289592743
[15/24] Train loss=0.1894427388906479
[20/24] Train loss=0.16153405606746674
Test set avg_accuracy=86.00% avg_sensitivity=73.40%, avg_specificity=90.20% avg_auc=90.52%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.192829 Test loss=0.337183 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.17731022834777832
[5/24] Train loss=0.18321698904037476
[10/24] Train loss=0.18896104395389557
[15/24] Train loss=0.1750708669424057
[20/24] Train loss=0.1569574773311615
Test set avg_accuracy=85.70% avg_sensitivity=62.44%, avg_specificity=93.44% avg_auc=89.35%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.186577 Test loss=0.353722 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.17606624960899353
[5/24] Train loss=0.18110108375549316
[10/24] Train loss=0.18027465045452118
[15/24] Train loss=0.1895454376935959
[20/24] Train loss=0.1541406661272049
Test set avg_accuracy=87.30% avg_sensitivity=66.04%, avg_specificity=94.38% avg_auc=90.69%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.186728 Test loss=0.335626 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.1780165433883667
[5/24] Train loss=0.17135955393314362
[10/24] Train loss=0.17989550530910492
[15/24] Train loss=0.17338553071022034
[20/24] Train loss=0.15276078879833221
Test set avg_accuracy=86.51% avg_sensitivity=64.89%, avg_specificity=93.70% avg_auc=89.68%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.181734 Test loss=0.348012 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.17394213378429413
[5/24] Train loss=0.18857988715171814
[10/24] Train loss=0.1751910001039505
[15/24] Train loss=0.1828489452600479
[20/24] Train loss=0.14841146767139435
Test set avg_accuracy=86.11% avg_sensitivity=76.00%, avg_specificity=89.47% avg_auc=90.61%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.184398 Test loss=0.341905 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.17877604067325592
[5/24] Train loss=0.18512454628944397
[10/24] Train loss=0.1770353764295578
[15/24] Train loss=0.17807993292808533
[20/24] Train loss=0.15206950902938843
Test set avg_accuracy=85.25% avg_sensitivity=55.56%, avg_specificity=95.12% avg_auc=87.08%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.183158 Test loss=0.417203 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.16618309915065765
[5/24] Train loss=0.18285800516605377
[10/24] Train loss=0.1834898591041565
[15/24] Train loss=0.17976662516593933
[20/24] Train loss=0.15269342064857483
Test set avg_accuracy=84.65% avg_sensitivity=80.54%, avg_specificity=86.01% avg_auc=90.74%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.182581 Test loss=0.362419 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.16883952915668488
[5/24] Train loss=0.17736978828907013
[10/24] Train loss=0.1879013478755951
[15/24] Train loss=0.17330341041088104
[20/24] Train loss=0.1568901389837265
Test set avg_accuracy=85.64% avg_sensitivity=80.70%, avg_specificity=87.28% avg_auc=91.65%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.179920 Test loss=0.347453 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.16422949731349945
[5/24] Train loss=0.16718748211860657
[10/24] Train loss=0.1782650351524353
[15/24] Train loss=0.18276001513004303
[20/24] Train loss=0.15095359086990356
Test set avg_accuracy=85.90% avg_sensitivity=56.39%, avg_specificity=95.71% avg_auc=88.94%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.177485 Test loss=0.360040 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.15638306736946106
[5/24] Train loss=0.1756594479084015
[10/24] Train loss=0.17220240831375122
[15/24] Train loss=0.16847945749759674
[20/24] Train loss=0.1532927006483078
Test set avg_accuracy=86.68% avg_sensitivity=61.40%, avg_specificity=95.09% avg_auc=89.00%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.176167 Test loss=0.344210 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.17189830541610718
[5/24] Train loss=0.1736159771680832
[10/24] Train loss=0.17947176098823547
[15/24] Train loss=0.18918362259864807
[20/24] Train loss=0.1543143391609192
Test set avg_accuracy=82.68% avg_sensitivity=78.04%, avg_specificity=84.23% avg_auc=89.80%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.178362 Test loss=0.381677 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.17140690982341766
[5/24] Train loss=0.17203176021575928
[10/24] Train loss=0.17666085064411163
[15/24] Train loss=0.1671903133392334
[20/24] Train loss=0.14665013551712036
Test set avg_accuracy=86.00% avg_sensitivity=77.62%, avg_specificity=88.79% avg_auc=91.45%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.173601 Test loss=0.338522 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.16072136163711548
[5/24] Train loss=0.16860036551952362
[10/24] Train loss=0.17314091324806213
[15/24] Train loss=0.17650815844535828
[20/24] Train loss=0.1537744104862213
Test set avg_accuracy=85.14% avg_sensitivity=76.37%, avg_specificity=88.06% avg_auc=91.07%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.176458 Test loss=0.342804 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.16637922823429108
[5/24] Train loss=0.171406090259552
[10/24] Train loss=0.17922335863113403
[15/24] Train loss=0.17685656249523163
[20/24] Train loss=0.16751378774642944
Test set avg_accuracy=81.35% avg_sensitivity=83.72%, avg_specificity=80.57% avg_auc=89.03%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.176923 Test loss=0.434925 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.1711946725845337
[5/24] Train loss=0.16730913519859314
[10/24] Train loss=0.17597351968288422
[15/24] Train loss=0.17148971557617188
[20/24] Train loss=0.15303771197795868
Test set avg_accuracy=85.98% avg_sensitivity=77.88%, avg_specificity=88.67% avg_auc=91.11%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.174225 Test loss=0.336574 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.16428837180137634
[5/24] Train loss=0.16956987977027893
[10/24] Train loss=0.1666126400232315
[15/24] Train loss=0.16265307366847992
[20/24] Train loss=0.1484307050704956
Test set avg_accuracy=83.88% avg_sensitivity=79.39%, avg_specificity=85.37% avg_auc=90.74%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.172240 Test loss=0.359972 Current lr=[0.000224838296036774]

[0/24] Train loss=0.16485454142093658
[5/24] Train loss=0.1737685650587082
[10/24] Train loss=0.17018194496631622
[15/24] Train loss=0.17824803292751312
[20/24] Train loss=0.14498791098594666
Test set avg_accuracy=87.04% avg_sensitivity=63.12%, avg_specificity=95.00% avg_auc=89.81%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.172558 Test loss=0.337537 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.15768247842788696
[5/24] Train loss=0.17057816684246063
[10/24] Train loss=0.1819581389427185
[15/24] Train loss=0.16393227875232697
[20/24] Train loss=0.15634788572788239
Test set avg_accuracy=83.91% avg_sensitivity=82.94%, avg_specificity=84.23% avg_auc=90.59%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.169822 Test loss=0.386463 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.1542716920375824
[5/24] Train loss=0.16684265434741974
[10/24] Train loss=0.17736203968524933
[15/24] Train loss=0.17295603454113007
[20/24] Train loss=0.14931128919124603
Test set avg_accuracy=84.64% avg_sensitivity=76.68%, avg_specificity=87.28% avg_auc=90.52%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.171732 Test loss=0.351834 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.15532925724983215
[5/24] Train loss=0.1623079925775528
[10/24] Train loss=0.17078661918640137
[15/24] Train loss=0.1635201871395111
[20/24] Train loss=0.14367841184139252
Test set avg_accuracy=81.29% avg_sensitivity=84.19%, avg_specificity=80.32% avg_auc=90.14%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.167616 Test loss=0.418826 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.16034871339797974
[5/24] Train loss=0.16545620560646057
[10/24] Train loss=0.16457657516002655
[15/24] Train loss=0.15678414702415466
[20/24] Train loss=0.1531960517168045
Test set avg_accuracy=83.39% avg_sensitivity=82.16%, avg_specificity=83.79% avg_auc=90.71%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.169894 Test loss=0.378368 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.15947088599205017
[5/24] Train loss=0.16839368641376495
[10/24] Train loss=0.1709839403629303
[15/24] Train loss=0.16012351214885712
[20/24] Train loss=0.15491773188114166
Test set avg_accuracy=86.54% avg_sensitivity=66.15%, avg_specificity=93.32% avg_auc=90.22%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.169173 Test loss=0.336482 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1562231332063675
[5/24] Train loss=0.16733255982398987
[10/24] Train loss=0.16898015141487122
[15/24] Train loss=0.15719906985759735
[20/24] Train loss=0.14659538865089417
Test set avg_accuracy=79.09% avg_sensitivity=87.01%, avg_specificity=76.45% avg_auc=89.16%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.168612 Test loss=0.471928 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.16183771193027496
[5/24] Train loss=0.1700793355703354
[10/24] Train loss=0.17418630421161652
[15/24] Train loss=0.16288426518440247
[20/24] Train loss=0.14994442462921143
Test set avg_accuracy=86.34% avg_sensitivity=73.19%, avg_specificity=90.72% avg_auc=90.96%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.169292 Test loss=0.334739 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.16253796219825745
[5/24] Train loss=0.16859214007854462
[10/24] Train loss=0.171166330575943
[15/24] Train loss=0.16374057531356812
[20/24] Train loss=0.14513875544071198
Test set avg_accuracy=82.07% avg_sensitivity=67.61%, avg_specificity=86.88% avg_auc=86.79%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.169672 Test loss=0.413809 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.17078810930252075
[5/24] Train loss=0.1705494523048401
[10/24] Train loss=0.16632181406021118
[15/24] Train loss=0.1597556173801422
[20/24] Train loss=0.14239943027496338
Test set avg_accuracy=84.51% avg_sensitivity=74.60%, avg_specificity=87.80% avg_auc=90.12%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.166467 Test loss=0.360236 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.15733645856380463
[5/24] Train loss=0.17758789658546448
[10/24] Train loss=0.1740538626909256
[15/24] Train loss=0.1673920601606369
[20/24] Train loss=0.15327982604503632
Test set avg_accuracy=81.18% avg_sensitivity=77.67%, avg_specificity=82.35% avg_auc=87.57%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.168215 Test loss=0.428922 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.15657015144824982
[5/24] Train loss=0.18101172149181366
[10/24] Train loss=0.16628892719745636
[15/24] Train loss=0.16438789665699005
[20/24] Train loss=0.14502258598804474
Test set avg_accuracy=87.02% avg_sensitivity=74.96%, avg_specificity=91.03% avg_auc=91.59%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.167630 Test loss=0.323266 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.14567989110946655
[5/24] Train loss=0.17193365097045898
[10/24] Train loss=0.17249928414821625
[15/24] Train loss=0.16240276396274567
[20/24] Train loss=0.14608259499073029
Test set avg_accuracy=81.03% avg_sensitivity=87.12%, avg_specificity=79.00% avg_auc=89.80%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.165598 Test loss=0.435836 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.16270753741264343
[5/24] Train loss=0.17507538199424744
[10/24] Train loss=0.17167896032333374
[15/24] Train loss=0.16476251184940338
[20/24] Train loss=0.14072728157043457
Test set avg_accuracy=86.05% avg_sensitivity=62.23%, avg_specificity=93.98% avg_auc=90.07%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.166006 Test loss=0.343449 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1563834398984909
[5/24] Train loss=0.16378380358219147
[10/24] Train loss=0.1653434932231903
[15/24] Train loss=0.16186317801475525
[20/24] Train loss=0.14643079042434692
Test set avg_accuracy=86.60% avg_sensitivity=67.71%, avg_specificity=92.89% avg_auc=90.17%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.165889 Test loss=0.338076 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15553264319896698
[5/24] Train loss=0.17910507321357727
[10/24] Train loss=0.16088572144508362
[15/24] Train loss=0.16405269503593445
[20/24] Train loss=0.15382903814315796
Test set avg_accuracy=86.78% avg_sensitivity=72.82%, avg_specificity=91.43% avg_auc=91.67%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.170251 Test loss=0.326302 Current lr=[0.000156543481933168]

[0/24] Train loss=0.15530124306678772
[5/24] Train loss=0.16662833094596863
[10/24] Train loss=0.15878035128116608
[15/24] Train loss=0.1610422432422638
[20/24] Train loss=0.1456259787082672
Test set avg_accuracy=85.78% avg_sensitivity=54.62%, avg_specificity=96.15% avg_auc=87.72%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.163030 Test loss=0.372989 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.14903858304023743
[5/24] Train loss=0.16562491655349731
[10/24] Train loss=0.16844911873340607
[15/24] Train loss=0.1661101132631302
[20/24] Train loss=0.14323361217975616
Test set avg_accuracy=85.96% avg_sensitivity=52.74%, avg_specificity=97.02% avg_auc=88.35%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.161865 Test loss=0.371348 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15262778103351593
[5/24] Train loss=0.16227729618549347
[10/24] Train loss=0.1593235582113266
[15/24] Train loss=0.1540038138628006
[20/24] Train loss=0.1394578069448471
Test set avg_accuracy=86.72% avg_sensitivity=59.94%, avg_specificity=95.63% avg_auc=88.90%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.160695 Test loss=0.361481 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15142971277236938
[5/24] Train loss=0.15676520764827728
[10/24] Train loss=0.15225350856781006
[15/24] Train loss=0.15816234052181244
[20/24] Train loss=0.1379915028810501
Test set avg_accuracy=86.29% avg_sensitivity=61.76%, avg_specificity=94.45% avg_auc=89.55%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.157733 Test loss=0.346197 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15098248422145844
[5/24] Train loss=0.15490110218524933
[10/24] Train loss=0.15145522356033325
[15/24] Train loss=0.1602441668510437
[20/24] Train loss=0.1441258192062378
Test set avg_accuracy=85.85% avg_sensitivity=52.48%, avg_specificity=96.95% avg_auc=88.14%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.160153 Test loss=0.387884 Current lr=[0.000134135431043539]

[0/24] Train loss=0.14720489084720612
[5/24] Train loss=0.1673532873392105
[10/24] Train loss=0.15054331719875336
[15/24] Train loss=0.1627269834280014
[20/24] Train loss=0.1432017982006073
Test set avg_accuracy=85.34% avg_sensitivity=50.60%, avg_specificity=96.89% avg_auc=87.23%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.158176 Test loss=0.402835 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.14409741759300232
[5/24] Train loss=0.16049204766750336
[10/24] Train loss=0.1524597853422165
[15/24] Train loss=0.15349656343460083
[20/24] Train loss=0.14411123096942902
Test set avg_accuracy=86.54% avg_sensitivity=65.41%, avg_specificity=93.56% avg_auc=90.15%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.157753 Test loss=0.335453 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.14650467038154602
[5/24] Train loss=0.1578269898891449
[10/24] Train loss=0.1490209698677063
[15/24] Train loss=0.1560373455286026
[20/24] Train loss=0.13718228042125702
Test set avg_accuracy=87.33% avg_sensitivity=66.72%, avg_specificity=94.19% avg_auc=90.48%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.156683 Test loss=0.328119 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.14829856157302856
[5/24] Train loss=0.1590268462896347
[10/24] Train loss=0.14628031849861145
[15/24] Train loss=0.15585865080356598
[20/24] Train loss=0.1348264068365097
Test set avg_accuracy=86.94% avg_sensitivity=64.63%, avg_specificity=94.36% avg_auc=90.10%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.154360 Test loss=0.341408 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14182667434215546
[5/24] Train loss=0.15658843517303467
[10/24] Train loss=0.14952713251113892
[15/24] Train loss=0.14965157210826874
[20/24] Train loss=0.1339697539806366
Test set avg_accuracy=87.32% avg_sensitivity=65.52%, avg_specificity=94.57% avg_auc=90.50%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.151763 Test loss=0.331414 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14787869155406952
[5/24] Train loss=0.15287381410598755
[10/24] Train loss=0.14095677435398102
[15/24] Train loss=0.15010423958301544
[20/24] Train loss=0.1308116316795349
Test set avg_accuracy=86.82% avg_sensitivity=68.44%, avg_specificity=92.94% avg_auc=90.68%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.152325 Test loss=0.332264 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.14380735158920288
[5/24] Train loss=0.1520935446023941
[10/24] Train loss=0.1474161595106125
[15/24] Train loss=0.14911986887454987
[20/24] Train loss=0.13436919450759888
Test set avg_accuracy=86.52% avg_sensitivity=67.29%, avg_specificity=92.92% avg_auc=89.85%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.151008 Test loss=0.345371 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1438150554895401
[5/24] Train loss=0.15308085083961487
[10/24] Train loss=0.14577706158161163
[15/24] Train loss=0.1539090871810913
[20/24] Train loss=0.13320936262607574
Test set avg_accuracy=84.28% avg_sensitivity=42.46%, avg_specificity=98.20% avg_auc=85.17%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.150643 Test loss=0.441082 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14168988168239594
[5/24] Train loss=0.15644796192646027
[10/24] Train loss=0.14458169043064117
[15/24] Train loss=0.14488407969474792
[20/24] Train loss=0.13181191682815552
Test set avg_accuracy=86.89% avg_sensitivity=70.21%, avg_specificity=92.43% avg_auc=91.33%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.149603 Test loss=0.329569 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14229722321033478
[5/24] Train loss=0.150373175740242
[10/24] Train loss=0.15387216210365295
[15/24] Train loss=0.15213483572006226
[20/24] Train loss=0.13416415452957153
Test set avg_accuracy=86.74% avg_sensitivity=66.04%, avg_specificity=93.63% avg_auc=89.42%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.150365 Test loss=0.341883 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.13887394964694977
[5/24] Train loss=0.151589497923851
[10/24] Train loss=0.14388802647590637
[15/24] Train loss=0.14703169465065002
[20/24] Train loss=0.13598981499671936
Test set avg_accuracy=86.59% avg_sensitivity=64.68%, avg_specificity=93.87% avg_auc=90.84%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.150295 Test loss=0.340091 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.13903109729290009
[5/24] Train loss=0.15550553798675537
[10/24] Train loss=0.146092489361763
[15/24] Train loss=0.14607885479927063
[20/24] Train loss=0.12955418229103088
Test set avg_accuracy=86.64% avg_sensitivity=74.86%, avg_specificity=90.56% avg_auc=91.32%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.149562 Test loss=0.331262 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13924892246723175
[5/24] Train loss=0.1498020887374878
[10/24] Train loss=0.14487387239933014
[15/24] Train loss=0.14363805949687958
[20/24] Train loss=0.1307118535041809
Test set avg_accuracy=86.16% avg_sensitivity=69.95%, avg_specificity=91.55% avg_auc=90.82%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.147616 Test loss=0.339644 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13598893582820892
[5/24] Train loss=0.15142342448234558
[10/24] Train loss=0.14299818873405457
[15/24] Train loss=0.1459776908159256
[20/24] Train loss=0.13196872174739838
Test set avg_accuracy=86.91% avg_sensitivity=67.66%, avg_specificity=93.32% avg_auc=90.52%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.145675 Test loss=0.340818 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13807517290115356
[5/24] Train loss=0.14699295163154602
[10/24] Train loss=0.13744482398033142
[15/24] Train loss=0.13946807384490967
[20/24] Train loss=0.12770743668079376
Test set avg_accuracy=86.93% avg_sensitivity=69.85%, avg_specificity=92.61% avg_auc=91.07%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.144555 Test loss=0.326741 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13920961320400238
[5/24] Train loss=0.14745448529720306
[10/24] Train loss=0.13765278458595276
[15/24] Train loss=0.14189107716083527
[20/24] Train loss=0.13021326065063477
Test set avg_accuracy=86.21% avg_sensitivity=60.82%, avg_specificity=94.66% avg_auc=89.35%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.142073 Test loss=0.354093 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1330498307943344
[5/24] Train loss=0.14479485154151917
[10/24] Train loss=0.13638240098953247
[15/24] Train loss=0.1408306211233139
[20/24] Train loss=0.12341031432151794
Test set avg_accuracy=87.01% avg_sensitivity=68.39%, avg_specificity=93.20% avg_auc=90.61%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.140649 Test loss=0.330817 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13402478396892548
[5/24] Train loss=0.14796270430088043
[10/24] Train loss=0.13334397971630096
[15/24] Train loss=0.13522635400295258
[20/24] Train loss=0.12477541714906693
Test set avg_accuracy=87.04% avg_sensitivity=69.69%, avg_specificity=92.82% avg_auc=90.77%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.139194 Test loss=0.327898 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13131383061408997
[5/24] Train loss=0.14246651530265808
[10/24] Train loss=0.13566061854362488
[15/24] Train loss=0.13801392912864685
[20/24] Train loss=0.12476129829883575
Test set avg_accuracy=86.73% avg_sensitivity=68.28%, avg_specificity=92.87% avg_auc=90.59%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.138129 Test loss=0.335004 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13387958705425262
[5/24] Train loss=0.1440102607011795
[10/24] Train loss=0.13437682390213013
[15/24] Train loss=0.13391438126564026
[20/24] Train loss=0.1224089190363884
Test set avg_accuracy=86.61% avg_sensitivity=71.41%, avg_specificity=91.67% avg_auc=90.95%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.137118 Test loss=0.328232 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1296592652797699
[5/24] Train loss=0.14167235791683197
[10/24] Train loss=0.1321551501750946
[15/24] Train loss=0.1357382982969284
[20/24] Train loss=0.1193641647696495
Test set avg_accuracy=86.76% avg_sensitivity=71.47%, avg_specificity=91.84% avg_auc=91.24%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.136089 Test loss=0.328814 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.12925830483436584
[5/24] Train loss=0.14189667999744415
[10/24] Train loss=0.13474112749099731
[15/24] Train loss=0.13162732124328613
[20/24] Train loss=0.12207593768835068
Test set avg_accuracy=87.11% avg_sensitivity=71.62%, avg_specificity=92.26% avg_auc=91.16%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.135818 Test loss=0.326409 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12831199169158936
[5/24] Train loss=0.14178034663200378
[10/24] Train loss=0.1328090876340866
[15/24] Train loss=0.13127823173999786
[20/24] Train loss=0.11963047087192535
Test set avg_accuracy=86.73% avg_sensitivity=68.91%, avg_specificity=92.66% avg_auc=90.88%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.134823 Test loss=0.331743 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12837058305740356
[5/24] Train loss=0.13854365050792694
[10/24] Train loss=0.13186389207839966
[15/24] Train loss=0.13411715626716614
[20/24] Train loss=0.12062406539916992
Test set avg_accuracy=87.16% avg_sensitivity=69.12%, avg_specificity=93.16% avg_auc=90.87%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.134221 Test loss=0.333877 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1285378783941269
[5/24] Train loss=0.137014240026474
[10/24] Train loss=0.13185153901576996
[15/24] Train loss=0.1302170604467392
[20/24] Train loss=0.12112407386302948
Test set avg_accuracy=87.04% avg_sensitivity=68.28%, avg_specificity=93.28% avg_auc=90.87%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.133368 Test loss=0.332934 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1287013292312622
[5/24] Train loss=0.1409454345703125
[10/24] Train loss=0.13379967212677002
[15/24] Train loss=0.13227114081382751
[20/24] Train loss=0.12117928266525269
Test set avg_accuracy=86.47% avg_sensitivity=71.78%, avg_specificity=91.36% avg_auc=91.23%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.133915 Test loss=0.333508 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12487926334142685
[5/24] Train loss=0.14098890125751495
[10/24] Train loss=0.13035224378108978
[15/24] Train loss=0.12998802959918976
[20/24] Train loss=0.12258346378803253
Test set avg_accuracy=86.29% avg_sensitivity=72.98%, avg_specificity=90.72% avg_auc=91.01%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.133953 Test loss=0.335890 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12759318947792053
[5/24] Train loss=0.14026205241680145
[10/24] Train loss=0.12974821031093597
[15/24] Train loss=0.13325342535972595
[20/24] Train loss=0.12167277932167053
Test set avg_accuracy=86.78% avg_sensitivity=71.52%, avg_specificity=91.86% avg_auc=91.08%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.133637 Test loss=0.333687 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1266431361436844
[5/24] Train loss=0.14347213506698608
[10/24] Train loss=0.1265089213848114
[15/24] Train loss=0.13281144201755524
[20/24] Train loss=0.12119417637586594
Test set avg_accuracy=86.48% avg_sensitivity=75.95%, avg_specificity=89.99% avg_auc=91.39%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.133777 Test loss=0.334386 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12696634232997894
[5/24] Train loss=0.14308205246925354
[10/24] Train loss=0.13058961927890778
[15/24] Train loss=0.13031920790672302
[20/24] Train loss=0.12124410271644592
Test set avg_accuracy=86.76% avg_sensitivity=76.11%, avg_specificity=90.30% avg_auc=91.31%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.133520 Test loss=0.329186 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12869206070899963
[5/24] Train loss=0.13764946162700653
[10/24] Train loss=0.1294933259487152
[15/24] Train loss=0.12841899693012238
[20/24] Train loss=0.11792506277561188
Test set avg_accuracy=86.85% avg_sensitivity=76.58%, avg_specificity=90.27% avg_auc=91.59%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.131797 Test loss=0.327790 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12544101476669312
[5/24] Train loss=0.13542306423187256
[10/24] Train loss=0.12967798113822937
[15/24] Train loss=0.1270471066236496
[20/24] Train loss=0.11855144798755646
Test set avg_accuracy=86.90% avg_sensitivity=73.34%, avg_specificity=91.41% avg_auc=91.56%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.130371 Test loss=0.324621 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12240426242351532
[5/24] Train loss=0.13390403985977173
[10/24] Train loss=0.1282535046339035
[15/24] Train loss=0.12596851587295532
[20/24] Train loss=0.11466395854949951
Test set avg_accuracy=86.64% avg_sensitivity=74.49%, avg_specificity=90.68% avg_auc=91.38%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.128670 Test loss=0.331120 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12358453869819641
[5/24] Train loss=0.13421469926834106
[10/24] Train loss=0.12634342908859253
[15/24] Train loss=0.12390856444835663
[20/24] Train loss=0.11617547273635864
Test set avg_accuracy=86.60% avg_sensitivity=73.60%, avg_specificity=90.92% avg_auc=91.47%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.128599 Test loss=0.329203 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12383250147104263
[5/24] Train loss=0.13596925139427185
[10/24] Train loss=0.1239141970872879
[15/24] Train loss=0.1259257197380066
[20/24] Train loss=0.1171584203839302
Test set avg_accuracy=86.58% avg_sensitivity=70.94%, avg_specificity=91.78% avg_auc=91.18%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.128137 Test loss=0.329287 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.11971253156661987
[5/24] Train loss=0.13408075273036957
[10/24] Train loss=0.1268085241317749
[15/24] Train loss=0.12786921858787537
[20/24] Train loss=0.11558352410793304
Test set avg_accuracy=86.41% avg_sensitivity=74.96%, avg_specificity=90.21% avg_auc=91.06%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.128197 Test loss=0.334056 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12171987444162369
[5/24] Train loss=0.13482621312141418
[10/24] Train loss=0.12483531981706619
[15/24] Train loss=0.12564627826213837
[20/24] Train loss=0.11517859250307083
Test set avg_accuracy=86.64% avg_sensitivity=72.46%, avg_specificity=91.36% avg_auc=91.19%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.127281 Test loss=0.328539 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12022949010133743
[5/24] Train loss=0.13249142467975616
[10/24] Train loss=0.12447160482406616
[15/24] Train loss=0.12273600697517395
[20/24] Train loss=0.11574900150299072
Test set avg_accuracy=86.71% avg_sensitivity=74.23%, avg_specificity=90.86% avg_auc=91.14%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.126795 Test loss=0.332504 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.11840592324733734
[5/24] Train loss=0.13304851949214935
[10/24] Train loss=0.12622815370559692
[15/24] Train loss=0.12436860799789429
[20/24] Train loss=0.11348210275173187
Test set avg_accuracy=86.69% avg_sensitivity=75.17%, avg_specificity=90.53% avg_auc=91.12%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.126835 Test loss=0.334750 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11944447457790375
[5/24] Train loss=0.13283434510231018
[10/24] Train loss=0.12213874608278275
[15/24] Train loss=0.12368924915790558
[20/24] Train loss=0.11574476957321167
Test set avg_accuracy=86.73% avg_sensitivity=72.98%, avg_specificity=91.31% avg_auc=91.09%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.126450 Test loss=0.331549 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12046840041875839
[5/24] Train loss=0.13344508409500122
[10/24] Train loss=0.12405966967344284
[15/24] Train loss=0.12224094569683075
[20/24] Train loss=0.11566653847694397
Test set avg_accuracy=86.56% avg_sensitivity=73.14%, avg_specificity=91.03% avg_auc=91.15%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.125983 Test loss=0.331540 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11993688344955444
[5/24] Train loss=0.13558754324913025
[10/24] Train loss=0.12255505472421646
[15/24] Train loss=0.1240302175283432
[20/24] Train loss=0.11589252203702927
Test set avg_accuracy=86.58% avg_sensitivity=73.08%, avg_specificity=91.06% avg_auc=91.21%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.126056 Test loss=0.331028 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1200818419456482
[5/24] Train loss=0.13373792171478271
[10/24] Train loss=0.12292587757110596
[15/24] Train loss=0.12131736427545547
[20/24] Train loss=0.11469585448503494
Test set avg_accuracy=86.46% avg_sensitivity=72.40%, avg_specificity=91.13% avg_auc=91.10%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.125979 Test loss=0.333282 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12104246765375137
[5/24] Train loss=0.13220056891441345
[10/24] Train loss=0.12117259204387665
[15/24] Train loss=0.12084853649139404
[20/24] Train loss=0.1177666112780571
Test set avg_accuracy=86.47% avg_sensitivity=73.08%, avg_specificity=90.92% avg_auc=91.09%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.125726 Test loss=0.334098 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12032217532396317
[5/24] Train loss=0.1320776492357254
[10/24] Train loss=0.12453318387269974
[15/24] Train loss=0.12113943696022034
[20/24] Train loss=0.11411797255277634
Test set avg_accuracy=86.56% avg_sensitivity=73.24%, avg_specificity=90.99% avg_auc=91.16%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.125770 Test loss=0.333558 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11699297279119492
[5/24] Train loss=0.13184359669685364
[10/24] Train loss=0.1252884864807129
[15/24] Train loss=0.12126189470291138
[20/24] Train loss=0.11418991535902023
Test set avg_accuracy=86.52% avg_sensitivity=72.93%, avg_specificity=91.05% avg_auc=91.16%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.124954 Test loss=0.332919 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11828751862049103
[5/24] Train loss=0.13298265635967255
[10/24] Train loss=0.12419436126947403
[15/24] Train loss=0.12046720087528229
[20/24] Train loss=0.11502007395029068
Test set avg_accuracy=86.50% avg_sensitivity=72.77%, avg_specificity=91.06% avg_auc=91.15%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.125530 Test loss=0.333225 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11959096789360046
[5/24] Train loss=0.13105948269367218
[10/24] Train loss=0.12417709082365036
[15/24] Train loss=0.11942953616380692
[20/24] Train loss=0.11227340251207352
Test set avg_accuracy=86.48% avg_sensitivity=72.72%, avg_specificity=91.06% avg_auc=91.15%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.125558 Test loss=0.333132 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11750742048025131
[5/24] Train loss=0.13406236469745636
[10/24] Train loss=0.1257544755935669
[15/24] Train loss=0.11977158486843109
[20/24] Train loss=0.11396588385105133
Test set avg_accuracy=86.51% avg_sensitivity=72.82%, avg_specificity=91.06% avg_auc=91.16%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.125466 Test loss=0.333148 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=87.12% sen=77.00%, spe=90.49%, auc=92.60%!
Fold[2] Avg_overlap=0.73%(0.21342322224095886)
[0/24] Train loss=0.7648150324821472
[5/24] Train loss=0.7508692741394043
[10/24] Train loss=0.7516667246818542
[15/24] Train loss=0.7340576648712158
[20/24] Train loss=0.7284872531890869
Test set avg_accuracy=55.09% avg_sensitivity=49.91%, avg_specificity=57.06% avg_auc=56.70%
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.741953 Test loss=0.675513 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7286519408226013
[5/24] Train loss=0.7158874869346619
[10/24] Train loss=0.7141895890235901
[15/24] Train loss=0.693164587020874
[20/24] Train loss=0.6972411870956421
Test set avg_accuracy=64.18% avg_sensitivity=59.95%, avg_specificity=65.78% avg_auc=67.47%
Best model saved!! Metric=-68.61418114295013!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.711074 Test loss=0.626131 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6989441514015198
[5/24] Train loss=0.6912010312080383
[10/24] Train loss=0.6900089383125305
[15/24] Train loss=0.6681677103042603
[20/24] Train loss=0.6629215478897095
Test set avg_accuracy=68.03% avg_sensitivity=66.49%, avg_specificity=68.62% avg_auc=74.34%
Best model saved!! Metric=-48.51238201735913!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.684738 Test loss=0.599164 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6608873009681702
[5/24] Train loss=0.6663438081741333
[10/24] Train loss=0.6688891053199768
[15/24] Train loss=0.6476614475250244
[20/24] Train loss=0.6299994587898254
Test set avg_accuracy=71.64% avg_sensitivity=72.70%, avg_specificity=71.24% avg_auc=78.46%
Best model saved!! Metric=-31.95925417669983!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.656374 Test loss=0.572662 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6277130246162415
[5/24] Train loss=0.6416195631027222
[10/24] Train loss=0.6397668719291687
[15/24] Train loss=0.6149002313613892
[20/24] Train loss=0.6036555171012878
Test set avg_accuracy=74.48% avg_sensitivity=75.78%, avg_specificity=73.99% avg_auc=81.46%
Best model saved!! Metric=-20.29080108542435!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.628446 Test loss=0.544121 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.599057137966156
[5/24] Train loss=0.6096555590629578
[10/24] Train loss=0.6139551401138306
[15/24] Train loss=0.5840421319007874
[20/24] Train loss=0.5731953382492065
Test set avg_accuracy=76.09% avg_sensitivity=77.39%, avg_specificity=75.60% avg_auc=83.45%
Best model saved!! Metric=-13.460501363516457!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.599967 Test loss=0.520768 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5717750787734985
[5/24] Train loss=0.5763317942619324
[10/24] Train loss=0.5873119831085205
[15/24] Train loss=0.5547013878822327
[20/24] Train loss=0.5365771651268005
Test set avg_accuracy=78.03% avg_sensitivity=77.63%, avg_specificity=78.19% avg_auc=85.18%
Best model saved!! Metric=-6.966749949834238!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.569715 Test loss=0.489609 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5414682030677795
[5/24] Train loss=0.5547540783882141
[10/24] Train loss=0.5645163655281067
[15/24] Train loss=0.5320760011672974
[20/24] Train loss=0.5066110491752625
Test set avg_accuracy=79.73% avg_sensitivity=76.54%, avg_specificity=80.93% avg_auc=86.39%
Best model saved!! Metric=-2.4047434977707383!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.540866 Test loss=0.463804 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.514120876789093
[5/24] Train loss=0.5207173824310303
[10/24] Train loss=0.5156056880950928
[15/24] Train loss=0.49423936009407043
[20/24] Train loss=0.4761718213558197
Test set avg_accuracy=81.73% avg_sensitivity=75.73%, avg_specificity=84.00% avg_auc=87.38%
Best model saved!! Metric=2.8489396541149574!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.507823 Test loss=0.438616 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.48340150713920593
[5/24] Train loss=0.48677030205726624
[10/24] Train loss=0.49319130182266235
[15/24] Train loss=0.4650651216506958
[20/24] Train loss=0.43899479508399963
Test set avg_accuracy=83.06% avg_sensitivity=76.02%, avg_specificity=85.73% avg_auc=88.58%
Best model saved!! Metric=7.387288687741233!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.477454 Test loss=0.418504 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.45040878653526306
[5/24] Train loss=0.4580550789833069
[10/24] Train loss=0.46016544103622437
[15/24] Train loss=0.43947145342826843
[20/24] Train loss=0.4144690930843353
Test set avg_accuracy=84.43% avg_sensitivity=77.20%, avg_specificity=87.16% avg_auc=89.57%
Best model saved!! Metric=12.36499547267151!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.447973 Test loss=0.400965 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4226703345775604
[5/24] Train loss=0.43304014205932617
[10/24] Train loss=0.4369998574256897
[15/24] Train loss=0.41171616315841675
[20/24] Train loss=0.38553330302238464
Test set avg_accuracy=85.25% avg_sensitivity=75.78%, avg_specificity=88.83% avg_auc=90.20%
Best model saved!! Metric=14.060885499537704!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.420885 Test loss=0.382248 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.39240729808807373
[5/24] Train loss=0.41030174493789673
[10/24] Train loss=0.4194769859313965
[15/24] Train loss=0.39454910159111023
[20/24] Train loss=0.36129483580589294
Test set avg_accuracy=86.17% avg_sensitivity=76.21%, avg_specificity=89.95% avg_auc=90.80%
Best model saved!! Metric=17.128659398478646!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.396228 Test loss=0.367039 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3752412796020508
[5/24] Train loss=0.3915381133556366
[10/24] Train loss=0.4091556668281555
[15/24] Train loss=0.3716360032558441
[20/24] Train loss=0.33846133947372437
Test set avg_accuracy=86.67% avg_sensitivity=73.03%, avg_specificity=91.83% avg_auc=91.09%
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.375853 Test loss=0.349642 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3510204255580902
[5/24] Train loss=0.3668486773967743
[10/24] Train loss=0.3828951120376587
[15/24] Train loss=0.3575267791748047
[20/24] Train loss=0.3239666223526001
Test set avg_accuracy=86.86% avg_sensitivity=75.17%, avg_specificity=91.29% avg_auc=91.66%
Best model saved!! Metric=18.982155806928063!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.357161 Test loss=0.342516 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3342876434326172
[5/24] Train loss=0.348748117685318
[10/24] Train loss=0.3744652569293976
[15/24] Train loss=0.3433722257614136
[20/24] Train loss=0.3113304376602173
Test set avg_accuracy=87.04% avg_sensitivity=74.08%, avg_specificity=91.96% avg_auc=91.84%
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.342952 Test loss=0.330337 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.32052382826805115
[5/24] Train loss=0.3334219753742218
[10/24] Train loss=0.35811319947242737
[15/24] Train loss=0.33781835436820984
[20/24] Train loss=0.2972164452075958
Test set avg_accuracy=86.76% avg_sensitivity=76.92%, avg_specificity=90.48% avg_auc=92.22%
Best model saved!! Metric=20.377440330200727!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.329138 Test loss=0.329496 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3110215663909912
[5/24] Train loss=0.32398614287376404
[10/24] Train loss=0.3542778789997101
[15/24] Train loss=0.3272252082824707
[20/24] Train loss=0.2862996459007263
Test set avg_accuracy=87.06% avg_sensitivity=77.49%, avg_specificity=90.68% avg_auc=92.50%
Best model saved!! Metric=21.72727388351896!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.319534 Test loss=0.323904 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.30099958181381226
[5/24] Train loss=0.31234627962112427
[10/24] Train loss=0.34382638335227966
[15/24] Train loss=0.3134569823741913
[20/24] Train loss=0.2765384614467621
Test set avg_accuracy=87.37% avg_sensitivity=74.98%, avg_specificity=92.06% avg_auc=92.69%
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.308521 Test loss=0.309762 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2890363931655884
[5/24] Train loss=0.29942598938941956
[10/24] Train loss=0.3327586352825165
[15/24] Train loss=0.30433180928230286
[20/24] Train loss=0.2676180899143219
Test set avg_accuracy=87.36% avg_sensitivity=71.23%, avg_specificity=93.46% avg_auc=92.78%
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.298613 Test loss=0.303746 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2816803753376007
[5/24] Train loss=0.28648820519447327
[10/24] Train loss=0.3274695575237274
[15/24] Train loss=0.30678966641426086
[20/24] Train loss=0.2591131925582886
Test set avg_accuracy=87.57% avg_sensitivity=68.53%, avg_specificity=94.78% avg_auc=92.95%
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.291437 Test loss=0.300607 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.27726003527641296
[5/24] Train loss=0.28494030237197876
[10/24] Train loss=0.32623738050460815
[15/24] Train loss=0.30013683438301086
[20/24] Train loss=0.24733279645442963
Test set avg_accuracy=87.66% avg_sensitivity=66.92%, avg_specificity=95.51% avg_auc=92.97%
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.285107 Test loss=0.301287 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2650800943374634
[5/24] Train loss=0.2679493725299835
[10/24] Train loss=0.3179317116737366
[15/24] Train loss=0.29103192687034607
[20/24] Train loss=0.24561765789985657
Test set avg_accuracy=88.07% avg_sensitivity=70.00%, avg_specificity=94.92% avg_auc=93.30%
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.277513 Test loss=0.293486 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2614928185939789
[5/24] Train loss=0.2654513716697693
[10/24] Train loss=0.3060096800327301
[15/24] Train loss=0.284004807472229
[20/24] Train loss=0.24351583421230316
Test set avg_accuracy=87.70% avg_sensitivity=66.97%, avg_specificity=95.55% avg_auc=93.06%
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.272742 Test loss=0.299973 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.25360262393951416
[5/24] Train loss=0.2560562789440155
[10/24] Train loss=0.3057200312614441
[15/24] Train loss=0.282129168510437
[20/24] Train loss=0.23907533288002014
Test set avg_accuracy=87.67% avg_sensitivity=66.07%, avg_specificity=95.85% avg_auc=93.32%
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.266633 Test loss=0.297074 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2548576891422272
[5/24] Train loss=0.25488293170928955
[10/24] Train loss=0.3004230856895447
[15/24] Train loss=0.2707464396953583
[20/24] Train loss=0.2321392297744751
Test set avg_accuracy=87.73% avg_sensitivity=64.69%, avg_specificity=96.46% avg_auc=93.35%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.261199 Test loss=0.301983 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2534835636615753
[5/24] Train loss=0.24141623079776764
[10/24] Train loss=0.2988271415233612
[15/24] Train loss=0.26879897713661194
[20/24] Train loss=0.23464283347129822
Test set avg_accuracy=88.11% avg_sensitivity=71.66%, avg_specificity=94.34% avg_auc=93.67%
Best model saved!! Metric=21.787823866182535!!
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.256018 Test loss=0.284726 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.23786069452762604
[5/24] Train loss=0.24127748608589172
[10/24] Train loss=0.294976145029068
[15/24] Train loss=0.26262959837913513
[20/24] Train loss=0.22627145051956177
Test set avg_accuracy=87.60% avg_sensitivity=73.65%, avg_specificity=92.89% avg_auc=92.80%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.253374 Test loss=0.302558 Current lr=[0.000210185142098938]

[0/24] Train loss=0.24463896453380585
[5/24] Train loss=0.22664783895015717
[10/24] Train loss=0.2843348979949951
[15/24] Train loss=0.2697874903678894
[20/24] Train loss=0.22256118059158325
Test set avg_accuracy=84.91% avg_sensitivity=50.43%, avg_specificity=97.97% avg_auc=91.62%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.249815 Test loss=0.364664 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.24069644510746002
[5/24] Train loss=0.23364488780498505
[10/24] Train loss=0.28865426778793335
[15/24] Train loss=0.25909775495529175
[20/24] Train loss=0.21633374691009521
Test set avg_accuracy=87.20% avg_sensitivity=63.18%, avg_specificity=96.30% avg_auc=93.16%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.246319 Test loss=0.304506 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.23146848380565643
[5/24] Train loss=0.22211597859859467
[10/24] Train loss=0.2833186686038971
[15/24] Train loss=0.2523570656776428
[20/24] Train loss=0.21452192962169647
Test set avg_accuracy=81.48% avg_sensitivity=36.11%, avg_specificity=98.67% avg_auc=89.67%
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.243054 Test loss=0.445908 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2309979498386383
[5/24] Train loss=0.22974403202533722
[10/24] Train loss=0.2733672559261322
[15/24] Train loss=0.2529076039791107
[20/24] Train loss=0.20870858430862427
Test set avg_accuracy=88.16% avg_sensitivity=69.48%, avg_specificity=95.24% avg_auc=93.48%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.238364 Test loss=0.289717 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2229446917772293
[5/24] Train loss=0.21896995604038239
[10/24] Train loss=0.26987001299858093
[15/24] Train loss=0.25630417466163635
[20/24] Train loss=0.21574418246746063
Test set avg_accuracy=86.78% avg_sensitivity=61.80%, avg_specificity=96.25% avg_auc=92.55%
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.234099 Test loss=0.315166 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.22044186294078827
[5/24] Train loss=0.22336724400520325
[10/24] Train loss=0.2766435742378235
[15/24] Train loss=0.25267350673675537
[20/24] Train loss=0.2013622373342514
Test set avg_accuracy=82.67% avg_sensitivity=41.90%, avg_specificity=98.11% avg_auc=89.23%
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.232532 Test loss=0.426635 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.22107230126857758
[5/24] Train loss=0.21230845153331757
[10/24] Train loss=0.2633199095726013
[15/24] Train loss=0.2414522022008896
[20/24] Train loss=0.20961187779903412
Test set avg_accuracy=87.07% avg_sensitivity=74.98%, avg_specificity=91.65% avg_auc=91.90%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.233156 Test loss=0.317695 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.21573862433433533
[5/24] Train loss=0.2122412919998169
[10/24] Train loss=0.27590543031692505
[15/24] Train loss=0.237317755818367
[20/24] Train loss=0.20198014378547668
Test set avg_accuracy=87.29% avg_sensitivity=68.58%, avg_specificity=94.38% avg_auc=92.07%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.229014 Test loss=0.311754 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.21300378441810608
[5/24] Train loss=0.20270606875419617
[10/24] Train loss=0.2523300051689148
[15/24] Train loss=0.2333599030971527
[20/24] Train loss=0.2101338803768158
Test set avg_accuracy=82.81% avg_sensitivity=75.83%, avg_specificity=85.46% avg_auc=88.28%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.223718 Test loss=0.397244 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2225494384765625
[5/24] Train loss=0.19983913004398346
[10/24] Train loss=0.26951754093170166
[15/24] Train loss=0.23385821282863617
[20/24] Train loss=0.19480663537979126
Test set avg_accuracy=81.29% avg_sensitivity=83.93%, avg_specificity=80.29% avg_auc=90.11%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.223800 Test loss=0.416687 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.21319124102592468
[5/24] Train loss=0.192058727145195
[10/24] Train loss=0.2525680959224701
[15/24] Train loss=0.22928893566131592
[20/24] Train loss=0.20123545825481415
Test set avg_accuracy=85.36% avg_sensitivity=77.44%, avg_specificity=88.37% avg_auc=91.86%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.221055 Test loss=0.330415 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.20908063650131226
[5/24] Train loss=0.21379230916500092
[10/24] Train loss=0.267768919467926
[15/24] Train loss=0.23215851187705994
[20/24] Train loss=0.1989894062280655
Test set avg_accuracy=87.32% avg_sensitivity=68.15%, avg_specificity=94.58% avg_auc=92.09%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.221793 Test loss=0.313635 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.20173531770706177
[5/24] Train loss=0.18918251991271973
[10/24] Train loss=0.24945631623268127
[15/24] Train loss=0.22246231138706207
[20/24] Train loss=0.1977609246969223
Test set avg_accuracy=85.82% avg_sensitivity=65.40%, avg_specificity=93.55% avg_auc=90.98%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.215067 Test loss=0.335423 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.20336827635765076
[5/24] Train loss=0.1800965964794159
[10/24] Train loss=0.250810444355011
[15/24] Train loss=0.22806213796138763
[20/24] Train loss=0.19120793044567108
Test set avg_accuracy=81.84% avg_sensitivity=74.41%, avg_specificity=84.65% avg_auc=88.25%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.209638 Test loss=0.402432 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.20074422657489777
[5/24] Train loss=0.18497195839881897
[10/24] Train loss=0.2409481704235077
[15/24] Train loss=0.2306225448846817
[20/24] Train loss=0.18308450281620026
Test set avg_accuracy=78.87% avg_sensitivity=81.99%, avg_specificity=77.68% avg_auc=88.86%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.207790 Test loss=0.441871 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.20194852352142334
[5/24] Train loss=0.19315895438194275
[10/24] Train loss=0.24607017636299133
[15/24] Train loss=0.2292504757642746
[20/24] Train loss=0.1980665922164917
Test set avg_accuracy=87.42% avg_sensitivity=73.32%, avg_specificity=92.76% avg_auc=92.94%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.211730 Test loss=0.297708 Current lr=[0.00029967723776099]

[0/24] Train loss=0.19711901247501373
[5/24] Train loss=0.18551261723041534
[10/24] Train loss=0.24827773869037628
[15/24] Train loss=0.22619874775409698
[20/24] Train loss=0.20141172409057617
Test set avg_accuracy=81.25% avg_sensitivity=36.49%, avg_specificity=98.20% avg_auc=86.50%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.209723 Test loss=0.497020 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.20915569365024567
[5/24] Train loss=0.18831591308116913
[10/24] Train loss=0.2436743527650833
[15/24] Train loss=0.212165966629982
[20/24] Train loss=0.18564622104167938
Test set avg_accuracy=87.32% avg_sensitivity=73.51%, avg_specificity=92.55% avg_auc=93.03%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.205583 Test loss=0.295171 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.19880449771881104
[5/24] Train loss=0.19958211481571198
[10/24] Train loss=0.24368223547935486
[15/24] Train loss=0.21212515234947205
[20/24] Train loss=0.18740028142929077
Test set avg_accuracy=86.45% avg_sensitivity=62.13%, avg_specificity=95.66% avg_auc=90.81%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.206047 Test loss=0.349493 Current lr=[0.000299720220882401]

[0/24] Train loss=0.20281045138835907
[5/24] Train loss=0.20082585513591766
[10/24] Train loss=0.2567942440509796
[15/24] Train loss=0.21928060054779053
[20/24] Train loss=0.18405388295650482
Test set avg_accuracy=83.16% avg_sensitivity=53.22%, avg_specificity=94.51% avg_auc=87.64%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.209441 Test loss=0.422742 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19926230609416962
[5/24] Train loss=0.1661931425333023
[10/24] Train loss=0.24864335358142853
[15/24] Train loss=0.2189851552248001
[20/24] Train loss=0.19541271030902863
Test set avg_accuracy=85.40% avg_sensitivity=56.92%, avg_specificity=96.19% avg_auc=91.16%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.202336 Test loss=0.364532 Current lr=[0.000298904600941902]

[0/24] Train loss=0.19439005851745605
[5/24] Train loss=0.16803327202796936
[10/24] Train loss=0.24205251038074493
[15/24] Train loss=0.20881642401218414
[20/24] Train loss=0.18345819413661957
Test set avg_accuracy=85.42% avg_sensitivity=80.43%, avg_specificity=87.31% avg_auc=91.45%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.201994 Test loss=0.344167 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.18765243887901306
[5/24] Train loss=0.18044832348823547
[10/24] Train loss=0.23835600912570953
[15/24] Train loss=0.21669040620326996
[20/24] Train loss=0.17917323112487793
Test set avg_accuracy=85.62% avg_sensitivity=56.82%, avg_specificity=96.54% avg_auc=90.44%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.201468 Test loss=0.355828 Current lr=[0.000297555943323901]

[0/24] Train loss=0.18855388462543488
[5/24] Train loss=0.18755578994750977
[10/24] Train loss=0.231902614235878
[15/24] Train loss=0.2144445776939392
[20/24] Train loss=0.1761999875307083
Test set avg_accuracy=85.65% avg_sensitivity=58.82%, avg_specificity=95.82% avg_auc=89.94%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.197221 Test loss=0.372969 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.18691271543502808
[5/24] Train loss=0.18354687094688416
[10/24] Train loss=0.24273422360420227
[15/24] Train loss=0.216556116938591
[20/24] Train loss=0.17665056884288788
Test set avg_accuracy=86.39% avg_sensitivity=66.07%, avg_specificity=94.09% avg_auc=91.26%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.197316 Test loss=0.332077 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.1759665161371231
[5/24] Train loss=0.17756405472755432
[10/24] Train loss=0.2254248559474945
[15/24] Train loss=0.21116401255130768
[20/24] Train loss=0.18263296782970428
Test set avg_accuracy=86.52% avg_sensitivity=66.59%, avg_specificity=94.08% avg_auc=91.92%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.195138 Test loss=0.322935 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.19284673035144806
[5/24] Train loss=0.16080953180789948
[10/24] Train loss=0.22746802866458893
[15/24] Train loss=0.20899996161460876
[20/24] Train loss=0.1781645119190216
Test set avg_accuracy=88.05% avg_sensitivity=76.02%, avg_specificity=92.60% avg_auc=93.50%
Best model saved!! Metric=24.166838923183604!!
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.194593 Test loss=0.290445 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.17678815126419067
[5/24] Train loss=0.16441217064857483
[10/24] Train loss=0.22294887900352478
[15/24] Train loss=0.20026831328868866
[20/24] Train loss=0.17639167606830597
Test set avg_accuracy=86.32% avg_sensitivity=60.05%, avg_specificity=96.27% avg_auc=90.93%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.186792 Test loss=0.351202 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.1752709150314331
[5/24] Train loss=0.16671566665172577
[10/24] Train loss=0.2161111682653427
[15/24] Train loss=0.201298788189888
[20/24] Train loss=0.16987094283103943
Test set avg_accuracy=85.85% avg_sensitivity=57.77%, avg_specificity=96.48% avg_auc=89.17%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.186443 Test loss=0.378807 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.17144350707530975
[5/24] Train loss=0.1665760725736618
[10/24] Train loss=0.21438553929328918
[15/24] Train loss=0.20838652551174164
[20/24] Train loss=0.17269137501716614
Test set avg_accuracy=85.74% avg_sensitivity=56.35%, avg_specificity=96.88% avg_auc=90.21%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.188915 Test loss=0.375376 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.19320152699947357
[5/24] Train loss=0.16352619230747223
[10/24] Train loss=0.2231741100549698
[15/24] Train loss=0.20109273493289948
[20/24] Train loss=0.17135891318321228
Test set avg_accuracy=86.37% avg_sensitivity=62.61%, avg_specificity=95.37% avg_auc=90.67%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.188155 Test loss=0.347114 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18201176822185516
[5/24] Train loss=0.1501329243183136
[10/24] Train loss=0.20193935930728912
[15/24] Train loss=0.19689923524856567
[20/24] Train loss=0.16706573963165283
Test set avg_accuracy=85.57% avg_sensitivity=56.16%, avg_specificity=96.71% avg_auc=90.08%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.182650 Test loss=0.373052 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.19062714278697968
[5/24] Train loss=0.1583794504404068
[10/24] Train loss=0.19264991581439972
[15/24] Train loss=0.2034003734588623
[20/24] Train loss=0.17327697575092316
Test set avg_accuracy=86.78% avg_sensitivity=78.58%, avg_specificity=89.89% avg_auc=92.49%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.182529 Test loss=0.316161 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.18969686329364777
[5/24] Train loss=0.1562776267528534
[10/24] Train loss=0.19626198709011078
[15/24] Train loss=0.1973227560520172
[20/24] Train loss=0.17686891555786133
Test set avg_accuracy=86.77% avg_sensitivity=79.67%, avg_specificity=89.46% avg_auc=92.55%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.180967 Test loss=0.321477 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.17864775657653809
[5/24] Train loss=0.1573868989944458
[10/24] Train loss=0.2092059701681137
[15/24] Train loss=0.19632692635059357
[20/24] Train loss=0.18387220799922943
Test set avg_accuracy=87.75% avg_sensitivity=78.39%, avg_specificity=91.29% avg_auc=92.87%
Best model saved!! Metric=24.300962247859346!!
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.182272 Test loss=0.301745 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.18180835247039795
[5/24] Train loss=0.15435677766799927
[10/24] Train loss=0.21047912538051605
[15/24] Train loss=0.20748794078826904
[20/24] Train loss=0.16619011759757996
Test set avg_accuracy=87.06% avg_sensitivity=80.95%, avg_specificity=89.37% avg_auc=93.27%
Best model saved!! Metric=24.644646061826933!!
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.186450 Test loss=0.307645 Current lr=[0.000276307469034998]

[0/24] Train loss=0.17248444259166718
[5/24] Train loss=0.15812909603118896
[10/24] Train loss=0.22371236979961395
[15/24] Train loss=0.19017159938812256
[20/24] Train loss=0.17557446658611298
Test set avg_accuracy=86.52% avg_sensitivity=71.66%, avg_specificity=92.15% avg_auc=91.80%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.181924 Test loss=0.322012 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.1802111715078354
[5/24] Train loss=0.16044268012046814
[10/24] Train loss=0.19798129796981812
[15/24] Train loss=0.19461432099342346
[20/24] Train loss=0.17505328357219696
Test set avg_accuracy=86.90% avg_sensitivity=65.64%, avg_specificity=94.96% avg_auc=91.82%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.180511 Test loss=0.327665 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.17156776785850525
[5/24] Train loss=0.16033805906772614
[10/24] Train loss=0.21179582178592682
[15/24] Train loss=0.19536776840686798
[20/24] Train loss=0.1690255105495453
Test set avg_accuracy=87.02% avg_sensitivity=72.94%, avg_specificity=92.35% avg_auc=92.40%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.181397 Test loss=0.311656 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.17727573215961456
[5/24] Train loss=0.15592113137245178
[10/24] Train loss=0.20955690741539001
[15/24] Train loss=0.22881346940994263
[20/24] Train loss=0.18183408677577972
Test set avg_accuracy=86.32% avg_sensitivity=81.28%, avg_specificity=88.22% avg_auc=92.18%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.181896 Test loss=0.330480 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.17676962912082672
[5/24] Train loss=0.161712184548378
[10/24] Train loss=0.207065150141716
[15/24] Train loss=0.19191180169582367
[20/24] Train loss=0.17109045386314392
Test set avg_accuracy=83.83% avg_sensitivity=48.96%, avg_specificity=97.04% avg_auc=87.07%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.179249 Test loss=0.427433 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.1772012710571289
[5/24] Train loss=0.1463446468114853
[10/24] Train loss=0.2140776365995407
[15/24] Train loss=0.18300163745880127
[20/24] Train loss=0.16513380408287048
Test set avg_accuracy=86.17% avg_sensitivity=63.55%, avg_specificity=94.74% avg_auc=89.33%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.176504 Test loss=0.351604 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.17575639486312866
[5/24] Train loss=0.15189088881015778
[10/24] Train loss=0.20251595973968506
[15/24] Train loss=0.18853765726089478
[20/24] Train loss=0.16995395720005035
Test set avg_accuracy=87.14% avg_sensitivity=67.63%, avg_specificity=94.52% avg_auc=91.29%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.177853 Test loss=0.328958 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.17075492441654205
[5/24] Train loss=0.1573149561882019
[10/24] Train loss=0.20764732360839844
[15/24] Train loss=0.20082859694957733
[20/24] Train loss=0.16408316791057587
Test set avg_accuracy=83.18% avg_sensitivity=46.68%, avg_specificity=97.00% avg_auc=86.50%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.175714 Test loss=0.472034 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.16560590267181396
[5/24] Train loss=0.1518135815858841
[10/24] Train loss=0.1888270527124405
[15/24] Train loss=0.19271378219127655
[20/24] Train loss=0.15987008810043335
Test set avg_accuracy=85.16% avg_sensitivity=63.55%, avg_specificity=93.34% avg_auc=89.60%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.172487 Test loss=0.360842 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1688171923160553
[5/24] Train loss=0.15477630496025085
[10/24] Train loss=0.19873864948749542
[15/24] Train loss=0.19826717674732208
[20/24] Train loss=0.16446253657341003
Test set avg_accuracy=80.09% avg_sensitivity=35.07%, avg_specificity=97.15% avg_auc=79.15%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.179574 Test loss=0.549323 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.16838806867599487
[5/24] Train loss=0.1569431722164154
[10/24] Train loss=0.2039545327425003
[15/24] Train loss=0.1937347799539566
[20/24] Train loss=0.1572461724281311
Test set avg_accuracy=85.81% avg_sensitivity=66.68%, avg_specificity=93.05% avg_auc=89.91%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.175365 Test loss=0.354837 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1683630347251892
[5/24] Train loss=0.15907199680805206
[10/24] Train loss=0.19192999601364136
[15/24] Train loss=0.1914287954568863
[20/24] Train loss=0.16420955955982208
Test set avg_accuracy=86.95% avg_sensitivity=77.30%, avg_specificity=90.61% avg_auc=91.99%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.177378 Test loss=0.320556 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.15884040296077728
[5/24] Train loss=0.1609126478433609
[10/24] Train loss=0.19499754905700684
[15/24] Train loss=0.2137545645236969
[20/24] Train loss=0.17186327278614044
Test set avg_accuracy=84.53% avg_sensitivity=83.03%, avg_specificity=85.10% avg_auc=91.00%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.179499 Test loss=0.363820 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.171425923705101
[5/24] Train loss=0.15470018982887268
[10/24] Train loss=0.18276455998420715
[15/24] Train loss=0.19689083099365234
[20/24] Train loss=0.16665026545524597
Test set avg_accuracy=87.27% avg_sensitivity=78.20%, avg_specificity=90.70% avg_auc=92.49%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.174787 Test loss=0.316198 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.17168034613132477
[5/24] Train loss=0.153253972530365
[10/24] Train loss=0.19239211082458496
[15/24] Train loss=0.19278956949710846
[20/24] Train loss=0.17991949617862701
Test set avg_accuracy=82.88% avg_sensitivity=86.30%, avg_specificity=81.58% avg_auc=90.43%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.174658 Test loss=0.412585 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17003479599952698
[5/24] Train loss=0.14680452644824982
[10/24] Train loss=0.18839529156684875
[15/24] Train loss=0.18558871746063232
[20/24] Train loss=0.15875934064388275
Test set avg_accuracy=86.91% avg_sensitivity=80.00%, avg_specificity=89.53% avg_auc=92.60%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.174303 Test loss=0.316947 Current lr=[0.000224838296036774]

[0/24] Train loss=0.16123239696025848
[5/24] Train loss=0.15008215606212616
[10/24] Train loss=0.19447673857212067
[15/24] Train loss=0.1848900318145752
[20/24] Train loss=0.1637161374092102
Test set avg_accuracy=87.34% avg_sensitivity=79.43%, avg_specificity=90.34% avg_auc=92.61%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.171076 Test loss=0.308038 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.16760142147541046
[5/24] Train loss=0.1481752097606659
[10/24] Train loss=0.18719658255577087
[15/24] Train loss=0.1797444075345993
[20/24] Train loss=0.16266168653964996
Test set avg_accuracy=86.17% avg_sensitivity=64.79%, avg_specificity=94.27% avg_auc=89.85%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.167258 Test loss=0.346896 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.16204822063446045
[5/24] Train loss=0.14392560720443726
[10/24] Train loss=0.194938525557518
[15/24] Train loss=0.1759427785873413
[20/24] Train loss=0.1560526043176651
Test set avg_accuracy=86.60% avg_sensitivity=71.33%, avg_specificity=92.39% avg_auc=91.87%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.167868 Test loss=0.324932 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.14905031025409698
[5/24] Train loss=0.14356836676597595
[10/24] Train loss=0.19149647653102875
[15/24] Train loss=0.18195639550685883
[20/24] Train loss=0.15830902755260468
Test set avg_accuracy=86.81% avg_sensitivity=69.00%, avg_specificity=93.55% avg_auc=90.87%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.166161 Test loss=0.330233 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.15989241003990173
[5/24] Train loss=0.14239931106567383
[10/24] Train loss=0.1865697205066681
[15/24] Train loss=0.18148483335971832
[20/24] Train loss=0.15624289214611053
Test set avg_accuracy=86.60% avg_sensitivity=69.05%, avg_specificity=93.25% avg_auc=91.07%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.165921 Test loss=0.325578 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.16024552285671234
[5/24] Train loss=0.1533535271883011
[10/24] Train loss=0.18759864568710327
[15/24] Train loss=0.18063725531101227
[20/24] Train loss=0.15895888209342957
Test set avg_accuracy=87.27% avg_sensitivity=71.71%, avg_specificity=93.16% avg_auc=91.79%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.168153 Test loss=0.317126 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.16040565073490143
[5/24] Train loss=0.15504634380340576
[10/24] Train loss=0.18409442901611328
[15/24] Train loss=0.17930668592453003
[20/24] Train loss=0.1537332981824875
Test set avg_accuracy=86.99% avg_sensitivity=70.05%, avg_specificity=93.41% avg_auc=91.71%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.165173 Test loss=0.323330 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1580708920955658
[5/24] Train loss=0.15282846987247467
[10/24] Train loss=0.1897982656955719
[15/24] Train loss=0.17490023374557495
[20/24] Train loss=0.15602217614650726
Test set avg_accuracy=86.98% avg_sensitivity=78.01%, avg_specificity=90.38% avg_auc=91.94%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.166105 Test loss=0.319640 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.15639181435108185
[5/24] Train loss=0.15529277920722961
[10/24] Train loss=0.19518691301345825
[15/24] Train loss=0.1723228245973587
[20/24] Train loss=0.15896211564540863
Test set avg_accuracy=81.84% avg_sensitivity=40.19%, avg_specificity=97.61% avg_auc=80.84%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.165365 Test loss=0.516020 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.1612771451473236
[5/24] Train loss=0.13841325044631958
[10/24] Train loss=0.18588848412036896
[15/24] Train loss=0.17334797978401184
[20/24] Train loss=0.16288122534751892
Test set avg_accuracy=87.55% avg_sensitivity=76.26%, avg_specificity=91.83% avg_auc=92.70%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.167084 Test loss=0.302615 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.15593639016151428
[5/24] Train loss=0.1476135551929474
[10/24] Train loss=0.18132780492305756
[15/24] Train loss=0.1759737730026245
[20/24] Train loss=0.15860514342784882
Test set avg_accuracy=86.21% avg_sensitivity=66.26%, avg_specificity=93.77% avg_auc=90.03%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.163808 Test loss=0.349989 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.15227283537387848
[5/24] Train loss=0.14717510342597961
[10/24] Train loss=0.178635835647583
[15/24] Train loss=0.17235907912254333
[20/24] Train loss=0.151397243142128
Test set avg_accuracy=85.82% avg_sensitivity=67.35%, avg_specificity=92.82% avg_auc=91.01%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.160226 Test loss=0.343152 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.15353721380233765
[5/24] Train loss=0.14017507433891296
[10/24] Train loss=0.17530928552150726
[15/24] Train loss=0.1732352375984192
[20/24] Train loss=0.1527034491300583
Test set avg_accuracy=86.58% avg_sensitivity=68.15%, avg_specificity=93.55% avg_auc=90.81%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.159841 Test loss=0.337817 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15231062471866608
[5/24] Train loss=0.14423049986362457
[10/24] Train loss=0.17690648138523102
[15/24] Train loss=0.16956877708435059
[20/24] Train loss=0.15731529891490936
Test set avg_accuracy=86.08% avg_sensitivity=64.22%, avg_specificity=94.36% avg_auc=89.19%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.157494 Test loss=0.360233 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.15143640339374542
[5/24] Train loss=0.13721075654029846
[10/24] Train loss=0.1771487146615982
[15/24] Train loss=0.1717236489057541
[20/24] Train loss=0.15215496718883514
Test set avg_accuracy=84.11% avg_sensitivity=51.00%, avg_specificity=96.66% avg_auc=87.55%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.157177 Test loss=0.410949 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15411190688610077
[5/24] Train loss=0.14704470336437225
[10/24] Train loss=0.17473722994327545
[15/24] Train loss=0.17153117060661316
[20/24] Train loss=0.15693753957748413
Test set avg_accuracy=85.95% avg_sensitivity=61.66%, avg_specificity=95.15% avg_auc=89.40%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.160737 Test loss=0.358153 Current lr=[0.000156543481933168]

[0/24] Train loss=0.1554536521434784
[5/24] Train loss=0.13938859105110168
[10/24] Train loss=0.17510879039764404
[15/24] Train loss=0.17957976460456848
[20/24] Train loss=0.14929905533790588
Test set avg_accuracy=85.40% avg_sensitivity=59.57%, avg_specificity=95.19% avg_auc=88.81%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.156638 Test loss=0.381106 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.15218137204647064
[5/24] Train loss=0.1399945467710495
[10/24] Train loss=0.1700371652841568
[15/24] Train loss=0.16924671828746796
[20/24] Train loss=0.14990344643592834
Test set avg_accuracy=86.32% avg_sensitivity=64.22%, avg_specificity=94.69% avg_auc=90.28%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.155119 Test loss=0.349667 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.151918426156044
[5/24] Train loss=0.1457747220993042
[10/24] Train loss=0.1670132726430893
[15/24] Train loss=0.17416684329509735
[20/24] Train loss=0.1492878943681717
Test set avg_accuracy=86.03% avg_sensitivity=60.90%, avg_specificity=95.55% avg_auc=88.78%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.156396 Test loss=0.368569 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.1428227424621582
[5/24] Train loss=0.14989443123340607
[10/24] Train loss=0.17124322056770325
[15/24] Train loss=0.17074568569660187
[20/24] Train loss=0.15271727740764618
Test set avg_accuracy=86.60% avg_sensitivity=65.26%, avg_specificity=94.69% avg_auc=91.25%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.158017 Test loss=0.331737 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.149696946144104
[5/24] Train loss=0.13752517104148865
[10/24] Train loss=0.1732930839061737
[15/24] Train loss=0.17120182514190674
[20/24] Train loss=0.14555662870407104
Test set avg_accuracy=86.97% avg_sensitivity=66.11%, avg_specificity=94.87% avg_auc=91.45%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.154817 Test loss=0.329070 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1552700400352478
[5/24] Train loss=0.13649407029151917
[10/24] Train loss=0.17073874175548553
[15/24] Train loss=0.16845937073230743
[20/24] Train loss=0.1493750363588333
Test set avg_accuracy=86.56% avg_sensitivity=62.89%, avg_specificity=95.53% avg_auc=91.25%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.155323 Test loss=0.339026 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15160080790519714
[5/24] Train loss=0.1476067304611206
[10/24] Train loss=0.16729199886322021
[15/24] Train loss=0.16949708759784698
[20/24] Train loss=0.15017889440059662
Test set avg_accuracy=84.96% avg_sensitivity=53.32%, avg_specificity=96.95% avg_auc=86.46%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.154383 Test loss=0.414450 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.149827778339386
[5/24] Train loss=0.14237937331199646
[10/24] Train loss=0.1621956080198288
[15/24] Train loss=0.17542465031147003
[20/24] Train loss=0.14510579407215118
Test set avg_accuracy=85.10% avg_sensitivity=54.60%, avg_specificity=96.66% avg_auc=88.08%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.152863 Test loss=0.403206 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.145297572016716
[5/24] Train loss=0.14117023348808289
[10/24] Train loss=0.16187383234500885
[15/24] Train loss=0.16957369446754456
[20/24] Train loss=0.1512821465730667
Test set avg_accuracy=87.17% avg_sensitivity=71.47%, avg_specificity=93.12% avg_auc=91.82%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.151829 Test loss=0.322937 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14727628231048584
[5/24] Train loss=0.139090895652771
[10/24] Train loss=0.15936556458473206
[15/24] Train loss=0.16385337710380554
[20/24] Train loss=0.14681977033615112
Test set avg_accuracy=86.89% avg_sensitivity=73.84%, avg_specificity=91.83% avg_auc=92.22%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.150211 Test loss=0.315651 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1469104140996933
[5/24] Train loss=0.1377900093793869
[10/24] Train loss=0.17294949293136597
[15/24] Train loss=0.15856952965259552
[20/24] Train loss=0.14860950410366058
Test set avg_accuracy=86.73% avg_sensitivity=64.64%, avg_specificity=95.10% avg_auc=92.10%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.150998 Test loss=0.324366 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.14494042098522186
[5/24] Train loss=0.1391148567199707
[10/24] Train loss=0.16071689128875732
[15/24] Train loss=0.16845270991325378
[20/24] Train loss=0.14177678525447845
Test set avg_accuracy=85.38% avg_sensitivity=58.82%, avg_specificity=95.44% avg_auc=90.32%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.148278 Test loss=0.369764 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.14760619401931763
[5/24] Train loss=0.13980837166309357
[10/24] Train loss=0.1591712087392807
[15/24] Train loss=0.15866504609584808
[20/24] Train loss=0.14422208070755005
Test set avg_accuracy=87.37% avg_sensitivity=77.20%, avg_specificity=91.22% avg_auc=92.30%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.148760 Test loss=0.312932 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.13880552351474762
[5/24] Train loss=0.13459263741970062
[10/24] Train loss=0.16369670629501343
[15/24] Train loss=0.16181139647960663
[20/24] Train loss=0.1398664116859436
Test set avg_accuracy=87.28% avg_sensitivity=78.34%, avg_specificity=90.66% avg_auc=92.81%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.145652 Test loss=0.311431 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14585082232952118
[5/24] Train loss=0.13007767498493195
[10/24] Train loss=0.15663890540599823
[15/24] Train loss=0.15693299472332
[20/24] Train loss=0.14271727204322815
Test set avg_accuracy=87.77% avg_sensitivity=77.91%, avg_specificity=91.51% avg_auc=92.73%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.144688 Test loss=0.306286 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1410299688577652
[5/24] Train loss=0.12955325841903687
[10/24] Train loss=0.15948902070522308
[15/24] Train loss=0.15962326526641846
[20/24] Train loss=0.13603432476520538
Test set avg_accuracy=87.10% avg_sensitivity=80.19%, avg_specificity=89.71% avg_auc=92.51%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.143370 Test loss=0.319449 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1389615386724472
[5/24] Train loss=0.125912606716156
[10/24] Train loss=0.14956022799015045
[15/24] Train loss=0.1539895385503769
[20/24] Train loss=0.14031699299812317
Test set avg_accuracy=87.84% avg_sensitivity=71.18%, avg_specificity=94.15% avg_auc=92.17%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.140388 Test loss=0.310852 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13784559071063995
[5/24] Train loss=0.12637756764888763
[10/24] Train loss=0.1494901329278946
[15/24] Train loss=0.15252390503883362
[20/24] Train loss=0.13694635033607483
Test set avg_accuracy=87.99% avg_sensitivity=77.06%, avg_specificity=92.14% avg_auc=92.78%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.138719 Test loss=0.300581 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13885988295078278
[5/24] Train loss=0.12694236636161804
[10/24] Train loss=0.14695200324058533
[15/24] Train loss=0.15121673047542572
[20/24] Train loss=0.13664186000823975
Test set avg_accuracy=87.50% avg_sensitivity=75.83%, avg_specificity=91.92% avg_auc=92.53%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.138348 Test loss=0.309320 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.136980801820755
[5/24] Train loss=0.12572766840457916
[10/24] Train loss=0.15212610363960266
[15/24] Train loss=0.15087738633155823
[20/24] Train loss=0.13601374626159668
Test set avg_accuracy=87.07% avg_sensitivity=68.48%, avg_specificity=94.11% avg_auc=91.58%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.137907 Test loss=0.319750 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1354352980852127
[5/24] Train loss=0.126966655254364
[10/24] Train loss=0.1438693255186081
[15/24] Train loss=0.15075169503688812
[20/24] Train loss=0.1345413625240326
Test set avg_accuracy=87.20% avg_sensitivity=73.70%, avg_specificity=92.32% avg_auc=92.34%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.138081 Test loss=0.312666 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1321006864309311
[5/24] Train loss=0.1271592527627945
[10/24] Train loss=0.14425699412822723
[15/24] Train loss=0.14914453029632568
[20/24] Train loss=0.13439103960990906
Test set avg_accuracy=87.75% avg_sensitivity=74.98%, avg_specificity=92.59% avg_auc=92.62%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.137022 Test loss=0.303170 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13390226662158966
[5/24] Train loss=0.1227089911699295
[10/24] Train loss=0.14340750873088837
[15/24] Train loss=0.14797964692115784
[20/24] Train loss=0.13377952575683594
Test set avg_accuracy=87.67% avg_sensitivity=77.87%, avg_specificity=91.38% avg_auc=92.54%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.135462 Test loss=0.310787 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13197825849056244
[5/24] Train loss=0.12613974511623383
[10/24] Train loss=0.14639894664287567
[15/24] Train loss=0.14752614498138428
[20/24] Train loss=0.13142085075378418
Test set avg_accuracy=87.53% avg_sensitivity=74.31%, avg_specificity=92.53% avg_auc=91.95%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.135340 Test loss=0.314526 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13126079738140106
[5/24] Train loss=0.12179019302129745
[10/24] Train loss=0.15317632257938385
[15/24] Train loss=0.14841653406620026
[20/24] Train loss=0.1341777890920639
Test set avg_accuracy=87.64% avg_sensitivity=75.26%, avg_specificity=92.33% avg_auc=92.35%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.134900 Test loss=0.310729 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1300804316997528
[5/24] Train loss=0.11897820979356766
[10/24] Train loss=0.14218024909496307
[15/24] Train loss=0.14379805326461792
[20/24] Train loss=0.13376882672309875
Test set avg_accuracy=87.30% avg_sensitivity=73.60%, avg_specificity=92.50% avg_auc=92.56%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.132709 Test loss=0.304947 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13124999403953552
[5/24] Train loss=0.12263285368680954
[10/24] Train loss=0.1393052190542221
[15/24] Train loss=0.14501705765724182
[20/24] Train loss=0.13181984424591064
Test set avg_accuracy=87.73% avg_sensitivity=76.73%, avg_specificity=91.90% avg_auc=92.57%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.132914 Test loss=0.308167 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12741786241531372
[5/24] Train loss=0.11944369226694107
[10/24] Train loss=0.1417396515607834
[15/24] Train loss=0.14981456100940704
[20/24] Train loss=0.13469576835632324
Test set avg_accuracy=87.71% avg_sensitivity=76.16%, avg_specificity=92.08% avg_auc=92.53%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.132138 Test loss=0.306132 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12849080562591553
[5/24] Train loss=0.12061011791229248
[10/24] Train loss=0.1406545490026474
[15/24] Train loss=0.1402512788772583
[20/24] Train loss=0.12855857610702515
Test set avg_accuracy=87.32% avg_sensitivity=73.55%, avg_specificity=92.53% avg_auc=92.20%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.130827 Test loss=0.309390 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12653657793998718
[5/24] Train loss=0.12173528969287872
[10/24] Train loss=0.1408604234457016
[15/24] Train loss=0.14533667266368866
[20/24] Train loss=0.1306823194026947
Test set avg_accuracy=87.55% avg_sensitivity=75.78%, avg_specificity=92.01% avg_auc=92.04%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.130753 Test loss=0.311841 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12675216794013977
[5/24] Train loss=0.11866530030965805
[10/24] Train loss=0.1395944058895111
[15/24] Train loss=0.14213500916957855
[20/24] Train loss=0.12862014770507812
Test set avg_accuracy=87.85% avg_sensitivity=78.96%, avg_specificity=91.22% avg_auc=92.73%
Best model saved!! Metric=24.756163144958194!!
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.129517 Test loss=0.304248 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12374413013458252
[5/24] Train loss=0.11591322720050812
[10/24] Train loss=0.13570009171962738
[15/24] Train loss=0.13751433789730072
[20/24] Train loss=0.1301812380552292
Test set avg_accuracy=87.80% avg_sensitivity=80.62%, avg_specificity=90.52% avg_auc=92.48%
Best model saved!! Metric=25.411674662169844!!
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.128564 Test loss=0.310771 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1247316375374794
[5/24] Train loss=0.11563317477703094
[10/24] Train loss=0.1391865760087967
[15/24] Train loss=0.1405176818370819
[20/24] Train loss=0.12865996360778809
Test set avg_accuracy=87.80% avg_sensitivity=79.43%, avg_specificity=90.97% avg_auc=92.66%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.128388 Test loss=0.305264 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12394783645868301
[5/24] Train loss=0.11811087280511856
[10/24] Train loss=0.13553273677825928
[15/24] Train loss=0.13746340572834015
[20/24] Train loss=0.129916250705719
Test set avg_accuracy=87.70% avg_sensitivity=77.06%, avg_specificity=91.72% avg_auc=92.52%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.127997 Test loss=0.307866 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12359803915023804
[5/24] Train loss=0.11448894441127777
[10/24] Train loss=0.13403506577014923
[15/24] Train loss=0.14313161373138428
[20/24] Train loss=0.12724633514881134
Test set avg_accuracy=88.03% avg_sensitivity=76.30%, avg_specificity=92.48% avg_auc=92.67%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.127522 Test loss=0.304231 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12587594985961914
[5/24] Train loss=0.11806744337081909
[10/24] Train loss=0.132679745554924
[15/24] Train loss=0.14152267575263977
[20/24] Train loss=0.13102568686008453
Test set avg_accuracy=87.96% avg_sensitivity=76.82%, avg_specificity=92.17% avg_auc=92.70%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.128188 Test loss=0.303607 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12096097320318222
[5/24] Train loss=0.11617279052734375
[10/24] Train loss=0.13109837472438812
[15/24] Train loss=0.13776367902755737
[20/24] Train loss=0.12965774536132812
Test set avg_accuracy=87.50% avg_sensitivity=73.65%, avg_specificity=92.75% avg_auc=92.54%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.127033 Test loss=0.309606 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.11982914805412292
[5/24] Train loss=0.11805051565170288
[10/24] Train loss=0.13455216586589813
[15/24] Train loss=0.13662376999855042
[20/24] Train loss=0.12758666276931763
Test set avg_accuracy=87.85% avg_sensitivity=78.67%, avg_specificity=91.33% avg_auc=92.82%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.126558 Test loss=0.303382 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12264154106378555
[5/24] Train loss=0.11456247419118881
[10/24] Train loss=0.1329754739999771
[15/24] Train loss=0.13317136466503143
[20/24] Train loss=0.12566399574279785
Test set avg_accuracy=87.97% avg_sensitivity=75.88%, avg_specificity=92.55% avg_auc=92.74%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.125615 Test loss=0.303375 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12027441710233688
[5/24] Train loss=0.11459256708621979
[10/24] Train loss=0.13077032566070557
[15/24] Train loss=0.13477644324302673
[20/24] Train loss=0.12671881914138794
Test set avg_accuracy=87.60% avg_sensitivity=76.45%, avg_specificity=91.83% avg_auc=92.59%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.124792 Test loss=0.306054 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12342569977045059
[5/24] Train loss=0.11505525559186935
[10/24] Train loss=0.13149379193782806
[15/24] Train loss=0.13496561348438263
[20/24] Train loss=0.12499971687793732
Test set avg_accuracy=88.02% avg_sensitivity=77.96%, avg_specificity=91.83% avg_auc=92.85%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.124825 Test loss=0.300325 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.11893639713525772
[5/24] Train loss=0.11245644837617874
[10/24] Train loss=0.13032233715057373
[15/24] Train loss=0.13474440574645996
[20/24] Train loss=0.1258365660905838
Test set avg_accuracy=87.90% avg_sensitivity=75.50%, avg_specificity=92.60% avg_auc=92.71%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.123386 Test loss=0.304158 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.11913035064935684
[5/24] Train loss=0.11231528222560883
[10/24] Train loss=0.12902064621448517
[15/24] Train loss=0.13251979649066925
[20/24] Train loss=0.12712860107421875
Test set avg_accuracy=87.90% avg_sensitivity=76.68%, avg_specificity=92.15% avg_auc=92.74%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.123152 Test loss=0.303494 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.11735287308692932
[5/24] Train loss=0.11284574121236801
[10/24] Train loss=0.12969380617141724
[15/24] Train loss=0.13432906568050385
[20/24] Train loss=0.12459911406040192
Test set avg_accuracy=88.07% avg_sensitivity=76.82%, avg_specificity=92.33% avg_auc=92.72%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.122729 Test loss=0.304257 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11754444986581802
[5/24] Train loss=0.11037514358758926
[10/24] Train loss=0.12888287007808685
[15/24] Train loss=0.13128042221069336
[20/24] Train loss=0.12346173077821732
Test set avg_accuracy=88.02% avg_sensitivity=77.20%, avg_specificity=92.12% avg_auc=92.82%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.122231 Test loss=0.302121 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.11982786655426025
[5/24] Train loss=0.1133219301700592
[10/24] Train loss=0.12763695418834686
[15/24] Train loss=0.1338973343372345
[20/24] Train loss=0.12428431957960129
Test set avg_accuracy=87.99% avg_sensitivity=76.64%, avg_specificity=92.30% avg_auc=92.76%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.122233 Test loss=0.303137 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11803201586008072
[5/24] Train loss=0.11120520532131195
[10/24] Train loss=0.13318584859371185
[15/24] Train loss=0.1321779191493988
[20/24] Train loss=0.12354542315006256
Test set avg_accuracy=87.97% avg_sensitivity=76.59%, avg_specificity=92.28% avg_auc=92.79%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.122100 Test loss=0.302378 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1178428903222084
[5/24] Train loss=0.11198468506336212
[10/24] Train loss=0.12915141880512238
[15/24] Train loss=0.13265442848205566
[20/24] Train loss=0.1240251287817955
Test set avg_accuracy=88.07% avg_sensitivity=76.97%, avg_specificity=92.28% avg_auc=92.80%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.122132 Test loss=0.301900 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1181110218167305
[5/24] Train loss=0.11006127297878265
[10/24] Train loss=0.12913182377815247
[15/24] Train loss=0.13088208436965942
[20/24] Train loss=0.12225676327943802
Test set avg_accuracy=88.03% avg_sensitivity=76.78%, avg_specificity=92.30% avg_auc=92.79%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.121521 Test loss=0.301983 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11971382051706314
[5/24] Train loss=0.11220519244670868
[10/24] Train loss=0.12867704033851624
[15/24] Train loss=0.13218161463737488
[20/24] Train loss=0.12173127382993698
Test set avg_accuracy=88.12% avg_sensitivity=76.68%, avg_specificity=92.46% avg_auc=92.77%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.121860 Test loss=0.302503 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11756624281406403
[5/24] Train loss=0.11060751229524612
[10/24] Train loss=0.12730801105499268
[15/24] Train loss=0.1297566294670105
[20/24] Train loss=0.12377267330884933
Test set avg_accuracy=88.07% avg_sensitivity=76.59%, avg_specificity=92.42% avg_auc=92.77%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.121437 Test loss=0.302586 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1180281862616539
[5/24] Train loss=0.11217554658651352
[10/24] Train loss=0.12828846275806427
[15/24] Train loss=0.13123486936092377
[20/24] Train loss=0.12428044527769089
Test set avg_accuracy=88.09% avg_sensitivity=76.68%, avg_specificity=92.41% avg_auc=92.77%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.121841 Test loss=0.302591 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11776882410049438
[5/24] Train loss=0.11169710755348206
[10/24] Train loss=0.1268017739057541
[15/24] Train loss=0.13157868385314941
[20/24] Train loss=0.12240767478942871
Test set avg_accuracy=88.01% avg_sensitivity=76.64%, avg_specificity=92.32% avg_auc=92.77%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.121666 Test loss=0.302682 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11753485351800919
[5/24] Train loss=0.11151079088449478
[10/24] Train loss=0.12726853787899017
[15/24] Train loss=0.13202553987503052
[20/24] Train loss=0.1243305578827858
Test set avg_accuracy=88.02% avg_sensitivity=76.64%, avg_specificity=92.33% avg_auc=92.77%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.121678 Test loss=0.302660 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=87.80% sen=80.62%, spe=90.52%, auc=92.48%!
Fold[3] Avg_overlap=0.66%(0.24798745885339638)
[0/24] Train loss=0.7456067204475403
[5/24] Train loss=0.7445705533027649
[10/24] Train loss=0.7403539419174194
[15/24] Train loss=0.731516420841217
[20/24] Train loss=0.715496301651001
Test set avg_accuracy=57.28% avg_sensitivity=56.62%, avg_specificity=57.51% avg_auc=59.85%
Best model saved!! Metric=-94.74246053547557!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.736768 Test loss=0.687002 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7180004119873047
[5/24] Train loss=0.7195967435836792
[10/24] Train loss=0.709834635257721
[15/24] Train loss=0.6973379850387573
[20/24] Train loss=0.6936837434768677
Test set avg_accuracy=62.51% avg_sensitivity=68.77%, avg_specificity=60.31% avg_auc=70.53%
Best model saved!! Metric=-63.879941692271274!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.707698 Test loss=0.636794 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6838971376419067
[5/24] Train loss=0.6905301809310913
[10/24] Train loss=0.6889834403991699
[15/24] Train loss=0.6711220145225525
[20/24] Train loss=0.6688371300697327
Test set avg_accuracy=68.31% avg_sensitivity=74.21%, avg_specificity=66.23% avg_auc=76.94%
Best model saved!! Metric=-40.310577951086515!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.680975 Test loss=0.597459 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6571019887924194
[5/24] Train loss=0.6678891777992249
[10/24] Train loss=0.6711021065711975
[15/24] Train loss=0.6423621773719788
[20/24] Train loss=0.6340118646621704
Test set avg_accuracy=71.03% avg_sensitivity=78.21%, avg_specificity=68.50% avg_auc=80.57%
Best model saved!! Metric=-27.69427251027703!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.654556 Test loss=0.568472 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6336366534233093
[5/24] Train loss=0.6394681334495544
[10/24] Train loss=0.6419521570205688
[15/24] Train loss=0.6182997226715088
[20/24] Train loss=0.6004542112350464
Test set avg_accuracy=73.41% avg_sensitivity=79.81%, avg_specificity=71.16% avg_auc=82.72%
Best model saved!! Metric=-18.90579244434177!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.625023 Test loss=0.542589 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5956538915634155
[5/24] Train loss=0.6062787771224976
[10/24] Train loss=0.6171034574508667
[15/24] Train loss=0.5913220047950745
[20/24] Train loss=0.5724466443061829
Test set avg_accuracy=75.61% avg_sensitivity=81.86%, avg_specificity=73.41% avg_auc=84.50%
Best model saved!! Metric=-10.617907650798003!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.596308 Test loss=0.519644 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.565341591835022
[5/24] Train loss=0.5779191851615906
[10/24] Train loss=0.5952368974685669
[15/24] Train loss=0.5617948770523071
[20/24] Train loss=0.5395820736885071
Test set avg_accuracy=77.88% avg_sensitivity=81.06%, avg_specificity=76.76% avg_auc=85.81%
Best model saved!! Metric=-4.496863116332108!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.566442 Test loss=0.491562 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5349669456481934
[5/24] Train loss=0.5378078818321228
[10/24] Train loss=0.556259036064148
[15/24] Train loss=0.5246031284332275
[20/24] Train loss=0.513973593711853
Test set avg_accuracy=79.45% avg_sensitivity=80.61%, avg_specificity=79.05% avg_auc=87.02%
Best model saved!! Metric=0.1282290750095001!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.533971 Test loss=0.468024 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5001758337020874
[5/24] Train loss=0.5060164332389832
[10/24] Train loss=0.5330106019973755
[15/24] Train loss=0.48687154054641724
[20/24] Train loss=0.48164939880371094
Test set avg_accuracy=81.65% avg_sensitivity=78.16%, avg_specificity=82.88% avg_auc=87.96%
Best model saved!! Metric=4.656385175055334!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.503043 Test loss=0.438007 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4662700295448303
[5/24] Train loss=0.4674097001552582
[10/24] Train loss=0.4990754723548889
[15/24] Train loss=0.4662843942642212
[20/24] Train loss=0.4468766450881958
Test set avg_accuracy=82.77% avg_sensitivity=78.31%, avg_specificity=84.35% avg_auc=88.91%
Best model saved!! Metric=8.33755683142428!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.471842 Test loss=0.419666 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4462131857872009
[5/24] Train loss=0.43847256898880005
[10/24] Train loss=0.4627090394496918
[15/24] Train loss=0.4350712299346924
[20/24] Train loss=0.4224451780319214
Test set avg_accuracy=84.14% avg_sensitivity=76.96%, avg_specificity=86.67% avg_auc=89.52%
Best model saved!! Metric=11.293705969640186!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.443691 Test loss=0.398263 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4128771722316742
[5/24] Train loss=0.409181147813797
[10/24] Train loss=0.43797269463539124
[15/24] Train loss=0.41290339827537537
[20/24] Train loss=0.39357197284698486
Test set avg_accuracy=84.86% avg_sensitivity=76.41%, avg_specificity=87.83% avg_auc=90.06%
Best model saved!! Metric=13.158071494853246!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.417510 Test loss=0.382907 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.39634546637535095
[5/24] Train loss=0.384499728679657
[10/24] Train loss=0.4216521382331848
[15/24] Train loss=0.39180752635002136
[20/24] Train loss=0.3767874538898468
Test set avg_accuracy=85.77% avg_sensitivity=75.06%, avg_specificity=89.54% avg_auc=90.48%
Best model saved!! Metric=14.852414490803355!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.394924 Test loss=0.363765 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.372600793838501
[5/24] Train loss=0.35632839798927307
[10/24] Train loss=0.39798590540885925
[15/24] Train loss=0.3715287148952484
[20/24] Train loss=0.3543136417865753
Test set avg_accuracy=86.34% avg_sensitivity=74.46%, avg_specificity=90.53% avg_auc=90.84%
Best model saved!! Metric=16.172738753196683!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.373543 Test loss=0.350415 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.353748619556427
[5/24] Train loss=0.335925430059433
[10/24] Train loss=0.38370731472969055
[15/24] Train loss=0.3535473346710205
[20/24] Train loss=0.33988726139068604
Test set avg_accuracy=86.77% avg_sensitivity=73.91%, avg_specificity=91.30% avg_auc=91.15%
Best model saved!! Metric=17.133117062044775!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.356768 Test loss=0.339912 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.33570536971092224
[5/24] Train loss=0.31840184330940247
[10/24] Train loss=0.3672398626804352
[15/24] Train loss=0.3385430872440338
[20/24] Train loss=0.32346785068511963
Test set avg_accuracy=87.17% avg_sensitivity=73.11%, avg_specificity=92.13% avg_auc=91.54%
Best model saved!! Metric=17.960723304678652!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.340738 Test loss=0.328867 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.32497039437294006
[5/24] Train loss=0.31117454171180725
[10/24] Train loss=0.3522947132587433
[15/24] Train loss=0.3308945298194885
[20/24] Train loss=0.3126271069049835
Test set avg_accuracy=87.29% avg_sensitivity=74.71%, avg_specificity=91.72% avg_auc=91.83%
Best model saved!! Metric=19.553449668456864!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.328766 Test loss=0.322919 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.30745238065719604
[5/24] Train loss=0.29647713899612427
[10/24] Train loss=0.3480779528617859
[15/24] Train loss=0.3262844383716583
[20/24] Train loss=0.29702144861221313
Test set avg_accuracy=87.66% avg_sensitivity=73.31%, avg_specificity=92.71% avg_auc=92.19%
Best model saved!! Metric=19.870724379292128!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.317483 Test loss=0.313114 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.30116984248161316
[5/24] Train loss=0.2895330488681793
[10/24] Train loss=0.329458624124527
[15/24] Train loss=0.3152565062046051
[20/24] Train loss=0.2957828640937805
Test set avg_accuracy=87.64% avg_sensitivity=74.36%, avg_specificity=92.32% avg_auc=92.21%
Best model saved!! Metric=20.54229697736423!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.307928 Test loss=0.310110 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2864677906036377
[5/24] Train loss=0.2809809744358063
[10/24] Train loss=0.3206319212913513
[15/24] Train loss=0.30501487851142883
[20/24] Train loss=0.28599250316619873
Test set avg_accuracy=87.68% avg_sensitivity=75.46%, avg_specificity=91.99% avg_auc=92.45%
Best model saved!! Metric=21.58002373037597!!
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.297227 Test loss=0.305520 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2858937680721283
[5/24] Train loss=0.26750776171684265
[10/24] Train loss=0.3237065374851227
[15/24] Train loss=0.2911171317100525
[20/24] Train loss=0.2725445628166199
Test set avg_accuracy=86.89% avg_sensitivity=80.86%, avg_specificity=89.01% avg_auc=92.72%
Best model saved!! Metric=23.482445579051685!!
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.290956 Test loss=0.320827 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2719837427139282
[5/24] Train loss=0.26455458998680115
[10/24] Train loss=0.3036070764064789
[15/24] Train loss=0.2856079339981079
[20/24] Train loss=0.2680668234825134
Test set avg_accuracy=87.57% avg_sensitivity=78.76%, avg_specificity=90.67% avg_auc=92.97%
Best model saved!! Metric=23.95969486216238!!
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.282955 Test loss=0.305492 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.27029621601104736
[5/24] Train loss=0.25437870621681213
[10/24] Train loss=0.30188554525375366
[15/24] Train loss=0.2846796214580536
[20/24] Train loss=0.2608726918697357
Test set avg_accuracy=88.06% avg_sensitivity=75.66%, avg_specificity=92.43% avg_auc=92.92%
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.276604 Test loss=0.296659 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.26248860359191895
[5/24] Train loss=0.24535930156707764
[10/24] Train loss=0.2895411252975464
[15/24] Train loss=0.2793126702308655
[20/24] Train loss=0.25583183765411377
Test set avg_accuracy=88.26% avg_sensitivity=71.51%, avg_specificity=94.15% avg_auc=93.09%
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.270132 Test loss=0.287057 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.25878894329071045
[5/24] Train loss=0.23547106981277466
[10/24] Train loss=0.28583982586860657
[15/24] Train loss=0.26555946469306946
[20/24] Train loss=0.2505812644958496
Test set avg_accuracy=87.97% avg_sensitivity=69.92%, avg_specificity=94.33% avg_auc=92.96%
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.262602 Test loss=0.290791 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2590387165546417
[5/24] Train loss=0.2300787717103958
[10/24] Train loss=0.28126606345176697
[15/24] Train loss=0.2644414007663727
[20/24] Train loss=0.24546192586421967
Test set avg_accuracy=88.10% avg_sensitivity=78.71%, avg_specificity=91.41% avg_auc=93.41%
Best model saved!! Metric=25.627222375286664!!
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.259452 Test loss=0.292518 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.25061506032943726
[5/24] Train loss=0.2216562181711197
[10/24] Train loss=0.2835350036621094
[15/24] Train loss=0.26573485136032104
[20/24] Train loss=0.2385668158531189
Test set avg_accuracy=87.99% avg_sensitivity=69.22%, avg_specificity=94.61% avg_auc=93.02%
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.253704 Test loss=0.287881 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2451898753643036
[5/24] Train loss=0.22696001827716827
[10/24] Train loss=0.2749253213405609
[15/24] Train loss=0.2559008002281189
[20/24] Train loss=0.23961856961250305
Test set avg_accuracy=88.02% avg_sensitivity=72.16%, avg_specificity=93.61% avg_auc=92.97%
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.248986 Test loss=0.290143 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2376101166009903
[5/24] Train loss=0.22188368439674377
[10/24] Train loss=0.27451610565185547
[15/24] Train loss=0.2512754201889038
[20/24] Train loss=0.23217914998531342
Test set avg_accuracy=87.98% avg_sensitivity=72.41%, avg_specificity=93.47% avg_auc=92.88%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.243923 Test loss=0.289319 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.23433473706245422
[5/24] Train loss=0.20696978271007538
[10/24] Train loss=0.2732768654823303
[15/24] Train loss=0.24671682715415955
[20/24] Train loss=0.23806262016296387
Test set avg_accuracy=88.14% avg_sensitivity=70.76%, avg_specificity=94.26% avg_auc=93.32%
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.241666 Test loss=0.286891 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.23940029740333557
[5/24] Train loss=0.20785453915596008
[10/24] Train loss=0.2636198103427887
[15/24] Train loss=0.2461734265089035
[20/24] Train loss=0.22781608998775482
Test set avg_accuracy=87.79% avg_sensitivity=72.01%, avg_specificity=93.34% avg_auc=92.74%
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.238035 Test loss=0.293225 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2261781245470047
[5/24] Train loss=0.2067025601863861
[10/24] Train loss=0.26703861355781555
[15/24] Train loss=0.24036669731140137
[20/24] Train loss=0.23506471514701843
Test set avg_accuracy=87.30% avg_sensitivity=62.42%, avg_specificity=96.07% avg_auc=92.11%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.235404 Test loss=0.305333 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.22916346788406372
[5/24] Train loss=0.20607584714889526
[10/24] Train loss=0.25948837399482727
[15/24] Train loss=0.23544181883335114
[20/24] Train loss=0.22631146013736725
Test set avg_accuracy=88.11% avg_sensitivity=75.16%, avg_specificity=92.67% avg_auc=93.51%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.231752 Test loss=0.285914 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.22534799575805664
[5/24] Train loss=0.20004013180732727
[10/24] Train loss=0.253808856010437
[15/24] Train loss=0.23147214949131012
[20/24] Train loss=0.2272855043411255
Test set avg_accuracy=88.27% avg_sensitivity=75.16%, avg_specificity=92.89% avg_auc=93.07%
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.231615 Test loss=0.286137 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.21827848255634308
[5/24] Train loss=0.18732552230358124
[10/24] Train loss=0.24480639398097992
[15/24] Train loss=0.2314714938402176
[20/24] Train loss=0.2200823426246643
Test set avg_accuracy=87.15% avg_sensitivity=77.56%, avg_specificity=90.53% avg_auc=92.95%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.223424 Test loss=0.302732 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2224593311548233
[5/24] Train loss=0.1868019700050354
[10/24] Train loss=0.24043522775173187
[15/24] Train loss=0.22935302555561066
[20/24] Train loss=0.21480971574783325
Test set avg_accuracy=87.02% avg_sensitivity=62.12%, avg_specificity=95.79% avg_auc=90.92%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.221964 Test loss=0.328042 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.22953303158283234
[5/24] Train loss=0.18292774260044098
[10/24] Train loss=0.25717470049858093
[15/24] Train loss=0.24169233441352844
[20/24] Train loss=0.2171248197555542
Test set avg_accuracy=87.77% avg_sensitivity=73.21%, avg_specificity=92.90% avg_auc=92.82%
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.224098 Test loss=0.296122 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.21106590330600739
[5/24] Train loss=0.189469113945961
[10/24] Train loss=0.2444273829460144
[15/24] Train loss=0.2348475307226181
[20/24] Train loss=0.20627900958061218
Test set avg_accuracy=87.38% avg_sensitivity=65.47%, avg_specificity=95.10% avg_auc=91.89%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.220312 Test loss=0.310923 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2119712084531784
[5/24] Train loss=0.1873801052570343
[10/24] Train loss=0.2506576180458069
[15/24] Train loss=0.22028851509094238
[20/24] Train loss=0.2111862599849701
Test set avg_accuracy=87.42% avg_sensitivity=76.46%, avg_specificity=91.28% avg_auc=92.85%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.220224 Test loss=0.298863 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2264639288187027
[5/24] Train loss=0.18678689002990723
[10/24] Train loss=0.2476092129945755
[15/24] Train loss=0.22797350585460663
[20/24] Train loss=0.21306350827217102
Test set avg_accuracy=88.48% avg_sensitivity=75.61%, avg_specificity=93.01% avg_auc=93.34%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.222535 Test loss=0.282314 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.21433807909488678
[5/24] Train loss=0.18460293114185333
[10/24] Train loss=0.2371790111064911
[15/24] Train loss=0.22864076495170593
[20/24] Train loss=0.21342222392559052
Test set avg_accuracy=88.12% avg_sensitivity=79.11%, avg_specificity=91.30% avg_auc=93.33%
Best model saved!! Metric=25.869778429591335!!
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.216442 Test loss=0.290008 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.19940781593322754
[5/24] Train loss=0.17675191164016724
[10/24] Train loss=0.2323816418647766
[15/24] Train loss=0.22030259668827057
[20/24] Train loss=0.21517996490001678
Test set avg_accuracy=87.60% avg_sensitivity=69.32%, avg_specificity=94.05% avg_auc=91.53%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.214162 Test loss=0.309071 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.21504105627536774
[5/24] Train loss=0.18385347723960876
[10/24] Train loss=0.23658117651939392
[15/24] Train loss=0.2218962162733078
[20/24] Train loss=0.1926298290491104
Test set avg_accuracy=88.46% avg_sensitivity=73.56%, avg_specificity=93.71% avg_auc=93.46%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.212212 Test loss=0.279603 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.1990807056427002
[5/24] Train loss=0.18126066029071808
[10/24] Train loss=0.23374952375888824
[15/24] Train loss=0.22112375497817993
[20/24] Train loss=0.21839597821235657
Test set avg_accuracy=86.30% avg_sensitivity=83.96%, avg_specificity=87.13% avg_auc=92.71%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.209827 Test loss=0.322988 Current lr=[0.00029967723776099]

[0/24] Train loss=0.1970566213130951
[5/24] Train loss=0.17175957560539246
[10/24] Train loss=0.2366122305393219
[15/24] Train loss=0.22267603874206543
[20/24] Train loss=0.2030104696750641
Test set avg_accuracy=87.60% avg_sensitivity=65.87%, avg_specificity=95.26% avg_auc=91.86%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.207677 Test loss=0.307701 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.20614661276340485
[5/24] Train loss=0.18076716363430023
[10/24] Train loss=0.24040523171424866
[15/24] Train loss=0.22913135588169098
[20/24] Train loss=0.20416133105754852
Test set avg_accuracy=64.48% avg_sensitivity=89.36%, avg_specificity=55.71% avg_auc=82.44%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.210221 Test loss=0.704631 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.20567071437835693
[5/24] Train loss=0.16986551880836487
[10/24] Train loss=0.2310061901807785
[15/24] Train loss=0.20838060975074768
[20/24] Train loss=0.20467829704284668
Test set avg_accuracy=84.73% avg_sensitivity=84.61%, avg_specificity=84.77% avg_auc=92.73%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.203354 Test loss=0.335766 Current lr=[0.000299720220882401]

[0/24] Train loss=0.1911584734916687
[5/24] Train loss=0.17662712931632996
[10/24] Train loss=0.23076815903186798
[15/24] Train loss=0.22119322419166565
[20/24] Train loss=0.20272497832775116
Test set avg_accuracy=65.51% avg_sensitivity=91.95%, avg_specificity=56.19% avg_auc=85.17%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.202292 Test loss=0.689003 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19884470105171204
[5/24] Train loss=0.16655273735523224
[10/24] Train loss=0.2375704050064087
[15/24] Train loss=0.21645531058311462
[20/24] Train loss=0.20329581201076508
Test set avg_accuracy=82.85% avg_sensitivity=86.61%, avg_specificity=81.53% avg_auc=92.17%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.204959 Test loss=0.372833 Current lr=[0.000298904600941902]

[0/24] Train loss=0.19634956121444702
[5/24] Train loss=0.16980130970478058
[10/24] Train loss=0.21785610914230347
[15/24] Train loss=0.22850444912910461
[20/24] Train loss=0.2149796336889267
Test set avg_accuracy=86.73% avg_sensitivity=77.31%, avg_specificity=90.05% avg_auc=92.08%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.203375 Test loss=0.310810 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.19532884657382965
[5/24] Train loss=0.1670413464307785
[10/24] Train loss=0.2147255688905716
[15/24] Train loss=0.22464200854301453
[20/24] Train loss=0.1964969038963318
Test set avg_accuracy=84.96% avg_sensitivity=83.21%, avg_specificity=85.58% avg_auc=92.28%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.200276 Test loss=0.348092 Current lr=[0.000297555943323901]

[0/24] Train loss=0.1985236555337906
[5/24] Train loss=0.1694536954164505
[10/24] Train loss=0.21860350668430328
[15/24] Train loss=0.2179987132549286
[20/24] Train loss=0.20183084905147552
Test set avg_accuracy=83.20% avg_sensitivity=81.76%, avg_specificity=83.71% avg_auc=90.67%
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.197713 Test loss=0.384019 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.1983688622713089
[5/24] Train loss=0.1628444492816925
[10/24] Train loss=0.2271607667207718
[15/24] Train loss=0.21169856190681458
[20/24] Train loss=0.18980029225349426
Test set avg_accuracy=86.03% avg_sensitivity=74.36%, avg_specificity=90.14% avg_auc=90.42%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.196785 Test loss=0.335340 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.19807882606983185
[5/24] Train loss=0.17123818397521973
[10/24] Train loss=0.20599624514579773
[15/24] Train loss=0.20869025588035583
[20/24] Train loss=0.19280657172203064
Test set avg_accuracy=85.95% avg_sensitivity=77.11%, avg_specificity=89.06% avg_auc=91.84%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.196419 Test loss=0.328217 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.18638189136981964
[5/24] Train loss=0.17902322113513947
[10/24] Train loss=0.20182077586650848
[15/24] Train loss=0.20999814569950104
[20/24] Train loss=0.1840435117483139
Test set avg_accuracy=87.46% avg_sensitivity=75.06%, avg_specificity=91.83% avg_auc=92.62%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.194320 Test loss=0.301581 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.20007282495498657
[5/24] Train loss=0.15949048101902008
[10/24] Train loss=0.21346543729305267
[15/24] Train loss=0.2172018438577652
[20/24] Train loss=0.19427628815174103
Test set avg_accuracy=86.29% avg_sensitivity=58.87%, avg_specificity=95.95% avg_auc=89.12%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.192136 Test loss=0.361139 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.2015022337436676
[5/24] Train loss=0.16663970053195953
[10/24] Train loss=0.21521958708763123
[15/24] Train loss=0.22215856611728668
[20/24] Train loss=0.1837577074766159
Test set avg_accuracy=87.04% avg_sensitivity=61.62%, avg_specificity=96.00% avg_auc=91.32%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.196799 Test loss=0.321199 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.18175412714481354
[5/24] Train loss=0.16545681655406952
[10/24] Train loss=0.207277312874794
[15/24] Train loss=0.20406252145767212
[20/24] Train loss=0.18148387968540192
Test set avg_accuracy=87.12% avg_sensitivity=73.36%, avg_specificity=91.97% avg_auc=91.85%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.190788 Test loss=0.313902 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.19322223961353302
[5/24] Train loss=0.15724141895771027
[10/24] Train loss=0.19520752131938934
[15/24] Train loss=0.19675417244434357
[20/24] Train loss=0.17761683464050293
Test set avg_accuracy=86.82% avg_sensitivity=78.66%, avg_specificity=89.70% avg_auc=92.62%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.185085 Test loss=0.312965 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18890570104122162
[5/24] Train loss=0.15738004446029663
[10/24] Train loss=0.20913773775100708
[15/24] Train loss=0.20105896890163422
[20/24] Train loss=0.1825285106897354
Test set avg_accuracy=84.26% avg_sensitivity=46.78%, avg_specificity=97.46% avg_auc=86.39%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.186243 Test loss=0.431655 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.19591085612773895
[5/24] Train loss=0.15260636806488037
[10/24] Train loss=0.2112530767917633
[15/24] Train loss=0.20709222555160522
[20/24] Train loss=0.19346340000629425
Test set avg_accuracy=86.24% avg_sensitivity=58.37%, avg_specificity=96.06% avg_auc=89.52%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.188301 Test loss=0.350311 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.195950448513031
[5/24] Train loss=0.177540123462677
[10/24] Train loss=0.19986942410469055
[15/24] Train loss=0.19399532675743103
[20/24] Train loss=0.1900123953819275
Test set avg_accuracy=88.10% avg_sensitivity=70.06%, avg_specificity=94.45% avg_auc=91.94%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.190447 Test loss=0.300701 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.17765431106090546
[5/24] Train loss=0.15514227747917175
[10/24] Train loss=0.19466833770275116
[15/24] Train loss=0.19940614700317383
[20/24] Train loss=0.1803075075149536
Test set avg_accuracy=87.58% avg_sensitivity=67.62%, avg_specificity=94.61% avg_auc=91.34%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.182936 Test loss=0.312005 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.1782291829586029
[5/24] Train loss=0.16070979833602905
[10/24] Train loss=0.21652978658676147
[15/24] Train loss=0.20356214046478271
[20/24] Train loss=0.1848951131105423
Test set avg_accuracy=87.41% avg_sensitivity=64.37%, avg_specificity=95.53% avg_auc=91.35%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.184147 Test loss=0.313786 Current lr=[0.000276307469034998]

[0/24] Train loss=0.18620863556861877
[5/24] Train loss=0.15821455419063568
[10/24] Train loss=0.20310597121715546
[15/24] Train loss=0.18951652944087982
[20/24] Train loss=0.1800946444272995
Test set avg_accuracy=85.09% avg_sensitivity=53.57%, avg_specificity=96.20% avg_auc=87.50%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.183885 Test loss=0.386898 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.17904578149318695
[5/24] Train loss=0.16164621710777283
[10/24] Train loss=0.20794472098350525
[15/24] Train loss=0.186408132314682
[20/24] Train loss=0.17708152532577515
Test set avg_accuracy=87.10% avg_sensitivity=65.47%, avg_specificity=94.72% avg_auc=91.22%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.183022 Test loss=0.317334 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.17597468197345734
[5/24] Train loss=0.17828676104545593
[10/24] Train loss=0.19195415079593658
[15/24] Train loss=0.19252896308898926
[20/24] Train loss=0.1723439246416092
Test set avg_accuracy=83.46% avg_sensitivity=41.73%, avg_specificity=98.17% avg_auc=83.99%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.181697 Test loss=0.476042 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.1842900514602661
[5/24] Train loss=0.14786183834075928
[10/24] Train loss=0.1985434591770172
[15/24] Train loss=0.18745069205760956
[20/24] Train loss=0.17167317867279053
Test set avg_accuracy=87.38% avg_sensitivity=66.57%, avg_specificity=94.72% avg_auc=91.08%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.179836 Test loss=0.322148 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.16795407235622406
[5/24] Train loss=0.1398502141237259
[10/24] Train loss=0.1852535605430603
[15/24] Train loss=0.19317850470542908
[20/24] Train loss=0.17320404946804047
Test set avg_accuracy=87.73% avg_sensitivity=69.92%, avg_specificity=94.01% avg_auc=91.84%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.177712 Test loss=0.305529 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.17726001143455505
[5/24] Train loss=0.1523197740316391
[10/24] Train loss=0.19421841204166412
[15/24] Train loss=0.1897059828042984
[20/24] Train loss=0.17421963810920715
Test set avg_accuracy=85.23% avg_sensitivity=81.56%, avg_specificity=86.53% avg_auc=91.17%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.178105 Test loss=0.347537 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.17966067790985107
[5/24] Train loss=0.14659933745861053
[10/24] Train loss=0.20048275589942932
[15/24] Train loss=0.19477885961532593
[20/24] Train loss=0.17480361461639404
Test set avg_accuracy=86.29% avg_sensitivity=57.37%, avg_specificity=96.48% avg_auc=90.21%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.179391 Test loss=0.349277 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.16936080157756805
[5/24] Train loss=0.15831606090068817
[10/24] Train loss=0.18900831043720245
[15/24] Train loss=0.1760791391134262
[20/24] Train loss=0.169698566198349
Test set avg_accuracy=84.74% avg_sensitivity=49.93%, avg_specificity=97.01% avg_auc=86.99%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.177574 Test loss=0.392045 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.17803551256656647
[5/24] Train loss=0.14965471625328064
[10/24] Train loss=0.19900768995285034
[15/24] Train loss=0.2025715559720993
[20/24] Train loss=0.17791837453842163
Test set avg_accuracy=87.45% avg_sensitivity=71.41%, avg_specificity=93.10% avg_auc=90.94%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.184392 Test loss=0.314820 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.17871135473251343
[5/24] Train loss=0.16241614520549774
[10/24] Train loss=0.22540602087974548
[15/24] Train loss=0.20274841785430908
[20/24] Train loss=0.17297421395778656
Test set avg_accuracy=85.35% avg_sensitivity=79.61%, avg_specificity=87.37% avg_auc=91.08%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.182117 Test loss=0.350661 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.1684449464082718
[5/24] Train loss=0.15478461980819702
[10/24] Train loss=0.1920810043811798
[15/24] Train loss=0.18432725965976715
[20/24] Train loss=0.17823109030723572
Test set avg_accuracy=85.46% avg_sensitivity=76.51%, avg_specificity=88.61% avg_auc=90.16%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.177149 Test loss=0.355082 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.17741116881370544
[5/24] Train loss=0.16271843016147614
[10/24] Train loss=0.1858971267938614
[15/24] Train loss=0.18144187331199646
[20/24] Train loss=0.17249667644500732
Test set avg_accuracy=84.56% avg_sensitivity=49.23%, avg_specificity=97.01% avg_auc=86.58%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.176596 Test loss=0.404406 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.18177837133407593
[5/24] Train loss=0.14741697907447815
[10/24] Train loss=0.18900993466377258
[15/24] Train loss=0.17868877947330475
[20/24] Train loss=0.16735893487930298
Test set avg_accuracy=87.50% avg_sensitivity=72.76%, avg_specificity=92.69% avg_auc=91.34%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.174527 Test loss=0.320120 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.16481584310531616
[5/24] Train loss=0.14849384129047394
[10/24] Train loss=0.18689528107643127
[15/24] Train loss=0.17763224244117737
[20/24] Train loss=0.16964611411094666
Test set avg_accuracy=87.14% avg_sensitivity=67.32%, avg_specificity=94.12% avg_auc=90.80%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.168736 Test loss=0.326591 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.17087820172309875
[5/24] Train loss=0.14612285792827606
[10/24] Train loss=0.17825037240982056
[15/24] Train loss=0.18062397837638855
[20/24] Train loss=0.16636380553245544
Test set avg_accuracy=86.33% avg_sensitivity=60.62%, avg_specificity=95.39% avg_auc=89.33%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.168327 Test loss=0.348975 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.16598209738731384
[5/24] Train loss=0.1392623782157898
[10/24] Train loss=0.1842706948518753
[15/24] Train loss=0.17226728796958923
[20/24] Train loss=0.16922730207443237
Test set avg_accuracy=85.38% avg_sensitivity=77.51%, avg_specificity=88.15% avg_auc=90.96%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.169286 Test loss=0.351570 Current lr=[0.000224838296036774]

[0/24] Train loss=0.167355477809906
[5/24] Train loss=0.1468055695295334
[10/24] Train loss=0.18565917015075684
[15/24] Train loss=0.18179303407669067
[20/24] Train loss=0.17377600073814392
Test set avg_accuracy=86.72% avg_sensitivity=78.61%, avg_specificity=89.58% avg_auc=91.67%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.173699 Test loss=0.332784 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.18753886222839355
[5/24] Train loss=0.15582352876663208
[10/24] Train loss=0.17788900434970856
[15/24] Train loss=0.18199928104877472
[20/24] Train loss=0.17374809086322784
Test set avg_accuracy=85.90% avg_sensitivity=82.31%, avg_specificity=87.16% avg_auc=91.80%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.172895 Test loss=0.334865 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.17500148713588715
[5/24] Train loss=0.13698922097682953
[10/24] Train loss=0.17355504631996155
[15/24] Train loss=0.18212556838989258
[20/24] Train loss=0.17154914140701294
Test set avg_accuracy=87.04% avg_sensitivity=67.52%, avg_specificity=93.92% avg_auc=91.03%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.167709 Test loss=0.322170 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.17467202246189117
[5/24] Train loss=0.14108197391033173
[10/24] Train loss=0.18796657025814056
[15/24] Train loss=0.17295904457569122
[20/24] Train loss=0.1684824526309967
Test set avg_accuracy=86.91% avg_sensitivity=69.42%, avg_specificity=93.08% avg_auc=90.54%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.167701 Test loss=0.326778 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.16194872558116913
[5/24] Train loss=0.1415518820285797
[10/24] Train loss=0.17324526607990265
[15/24] Train loss=0.1711636632680893
[20/24] Train loss=0.1640641838312149
Test set avg_accuracy=87.27% avg_sensitivity=63.57%, avg_specificity=95.62% avg_auc=89.77%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.164096 Test loss=0.334556 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.16313672065734863
[5/24] Train loss=0.13563215732574463
[10/24] Train loss=0.16390928626060486
[15/24] Train loss=0.1750263124704361
[20/24] Train loss=0.16047056019306183
Test set avg_accuracy=87.21% avg_sensitivity=75.61%, avg_specificity=91.30% avg_auc=91.69%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.162869 Test loss=0.316178 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.16906197369098663
[5/24] Train loss=0.14115187525749207
[10/24] Train loss=0.16447004675865173
[15/24] Train loss=0.172949880361557
[20/24] Train loss=0.1654432862997055
Test set avg_accuracy=87.33% avg_sensitivity=72.01%, avg_specificity=92.73% avg_auc=91.27%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.163123 Test loss=0.317999 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.16602389514446259
[5/24] Train loss=0.14255553483963013
[10/24] Train loss=0.1647331267595291
[15/24] Train loss=0.1693025380373001
[20/24] Train loss=0.1637939214706421
Test set avg_accuracy=87.64% avg_sensitivity=74.91%, avg_specificity=92.13% avg_auc=91.42%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.162724 Test loss=0.316606 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.15761688351631165
[5/24] Train loss=0.1414223462343216
[10/24] Train loss=0.17865245044231415
[15/24] Train loss=0.17768970131874084
[20/24] Train loss=0.16133476793766022
Test set avg_accuracy=87.37% avg_sensitivity=69.22%, avg_specificity=93.77% avg_auc=90.61%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.162620 Test loss=0.322183 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.15994007885456085
[5/24] Train loss=0.14511634409427643
[10/24] Train loss=0.16967526078224182
[15/24] Train loss=0.17636601626873016
[20/24] Train loss=0.16839995980262756
Test set avg_accuracy=86.99% avg_sensitivity=77.71%, avg_specificity=90.26% avg_auc=92.17%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.163181 Test loss=0.313847 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.15790782868862152
[5/24] Train loss=0.13625602424144745
[10/24] Train loss=0.16457997262477875
[15/24] Train loss=0.16584472358226776
[20/24] Train loss=0.1587422490119934
Test set avg_accuracy=87.77% avg_sensitivity=69.37%, avg_specificity=94.26% avg_auc=91.05%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.159365 Test loss=0.320884 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.15984825789928436
[5/24] Train loss=0.13528317213058472
[10/24] Train loss=0.16745758056640625
[15/24] Train loss=0.16481752693653107
[20/24] Train loss=0.16138297319412231
Test set avg_accuracy=87.54% avg_sensitivity=73.06%, avg_specificity=92.64% avg_auc=91.33%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.157776 Test loss=0.314226 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.15704065561294556
[5/24] Train loss=0.1432337462902069
[10/24] Train loss=0.16105282306671143
[15/24] Train loss=0.1596405953168869
[20/24] Train loss=0.15292686223983765
Test set avg_accuracy=86.82% avg_sensitivity=64.37%, avg_specificity=94.73% avg_auc=89.31%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.158296 Test loss=0.340251 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15648327767848969
[5/24] Train loss=0.14222754538059235
[10/24] Train loss=0.16242684423923492
[15/24] Train loss=0.1672157496213913
[20/24] Train loss=0.1557062417268753
Test set avg_accuracy=87.01% avg_sensitivity=65.67%, avg_specificity=94.52% avg_auc=90.41%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.158869 Test loss=0.329108 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.16399210691452026
[5/24] Train loss=0.13140185177326202
[10/24] Train loss=0.15498273074626923
[15/24] Train loss=0.1682649850845337
[20/24] Train loss=0.15494883060455322
Test set avg_accuracy=86.91% avg_sensitivity=70.91%, avg_specificity=92.55% avg_auc=90.57%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.156031 Test loss=0.330624 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15343962609767914
[5/24] Train loss=0.13509105145931244
[10/24] Train loss=0.17055122554302216
[15/24] Train loss=0.16401399672031403
[20/24] Train loss=0.16160567104816437
Test set avg_accuracy=86.82% avg_sensitivity=75.11%, avg_specificity=90.95% avg_auc=90.63%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.155269 Test loss=0.334256 Current lr=[0.000156543481933168]

[0/24] Train loss=0.15502776205539703
[5/24] Train loss=0.12807142734527588
[10/24] Train loss=0.1631116271018982
[15/24] Train loss=0.15943379700183868
[20/24] Train loss=0.14833562076091766
Test set avg_accuracy=87.02% avg_sensitivity=67.32%, avg_specificity=93.96% avg_auc=90.08%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.153593 Test loss=0.332963 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.15282577276229858
[5/24] Train loss=0.13348007202148438
[10/24] Train loss=0.15631279349327087
[15/24] Train loss=0.17087994515895844
[20/24] Train loss=0.16311578452587128
Test set avg_accuracy=85.22% avg_sensitivity=53.07%, avg_specificity=96.55% avg_auc=86.58%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.156079 Test loss=0.406185 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15212520956993103
[5/24] Train loss=0.13934403657913208
[10/24] Train loss=0.16581326723098755
[15/24] Train loss=0.16037999093532562
[20/24] Train loss=0.1588434875011444
Test set avg_accuracy=85.38% avg_sensitivity=61.97%, avg_specificity=93.63% avg_auc=87.59%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.154760 Test loss=0.371513 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15176507830619812
[5/24] Train loss=0.13978981971740723
[10/24] Train loss=0.16496309638023376
[15/24] Train loss=0.1616859883069992
[20/24] Train loss=0.14986123144626617
Test set avg_accuracy=87.27% avg_sensitivity=73.96%, avg_specificity=91.95% avg_auc=91.24%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.152868 Test loss=0.322370 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15259969234466553
[5/24] Train loss=0.13154000043869019
[10/24] Train loss=0.15628167986869812
[15/24] Train loss=0.16374725103378296
[20/24] Train loss=0.1497838944196701
Test set avg_accuracy=86.72% avg_sensitivity=69.82%, avg_specificity=92.67% avg_auc=90.11%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.151082 Test loss=0.338122 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15233653783798218
[5/24] Train loss=0.1313132792711258
[10/24] Train loss=0.14741398394107819
[15/24] Train loss=0.1676139235496521
[20/24] Train loss=0.15335328876972198
Test set avg_accuracy=86.42% avg_sensitivity=71.86%, avg_specificity=91.55% avg_auc=90.31%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.150362 Test loss=0.337249 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.14644229412078857
[5/24] Train loss=0.13553109765052795
[10/24] Train loss=0.15391699969768524
[15/24] Train loss=0.16764196753501892
[20/24] Train loss=0.15530161559581757
Test set avg_accuracy=85.81% avg_sensitivity=72.91%, avg_specificity=90.35% avg_auc=89.64%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.151747 Test loss=0.351747 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.15030092000961304
[5/24] Train loss=0.134272962808609
[10/24] Train loss=0.15709148347377777
[15/24] Train loss=0.1609167605638504
[20/24] Train loss=0.1568109095096588
Test set avg_accuracy=86.64% avg_sensitivity=67.17%, avg_specificity=93.50% avg_auc=90.26%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.151591 Test loss=0.338610 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15127307176589966
[5/24] Train loss=0.13138188421726227
[10/24] Train loss=0.15558956563472748
[15/24] Train loss=0.1652630865573883
[20/24] Train loss=0.14801369607448578
Test set avg_accuracy=86.45% avg_sensitivity=67.37%, avg_specificity=93.17% avg_auc=90.17%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.150992 Test loss=0.346167 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1463967263698578
[5/24] Train loss=0.12938512861728668
[10/24] Train loss=0.16344431042671204
[15/24] Train loss=0.15570200979709625
[20/24] Train loss=0.1496727615594864
Test set avg_accuracy=86.60% avg_sensitivity=64.57%, avg_specificity=94.37% avg_auc=88.97%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.149371 Test loss=0.355688 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14889654517173767
[5/24] Train loss=0.1323782354593277
[10/24] Train loss=0.15154807269573212
[15/24] Train loss=0.15426065027713776
[20/24] Train loss=0.15090195834636688
Test set avg_accuracy=87.46% avg_sensitivity=72.61%, avg_specificity=92.69% avg_auc=91.32%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.148166 Test loss=0.317734 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.14376913011074066
[5/24] Train loss=0.13025638461112976
[10/24] Train loss=0.15776316821575165
[15/24] Train loss=0.15792007744312286
[20/24] Train loss=0.14558127522468567
Test set avg_accuracy=87.55% avg_sensitivity=75.81%, avg_specificity=91.69% avg_auc=91.78%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.145880 Test loss=0.318237 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.14706529676914215
[5/24] Train loss=0.12439209967851639
[10/24] Train loss=0.1517907977104187
[15/24] Train loss=0.151020348072052
[20/24] Train loss=0.14756807684898376
Test set avg_accuracy=87.60% avg_sensitivity=77.66%, avg_specificity=91.11% avg_auc=91.79%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.142689 Test loss=0.317636 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1421128809452057
[5/24] Train loss=0.1233041062951088
[10/24] Train loss=0.1466904729604721
[15/24] Train loss=0.14637614786624908
[20/24] Train loss=0.14600302278995514
Test set avg_accuracy=87.42% avg_sensitivity=71.06%, avg_specificity=93.19% avg_auc=90.90%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.140386 Test loss=0.328300 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14161907136440277
[5/24] Train loss=0.11656466126441956
[10/24] Train loss=0.15053746104240417
[15/24] Train loss=0.14752095937728882
[20/24] Train loss=0.14030548930168152
Test set avg_accuracy=87.25% avg_sensitivity=73.01%, avg_specificity=92.27% avg_auc=91.18%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.138811 Test loss=0.325383 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.14406153559684753
[5/24] Train loss=0.12268184125423431
[10/24] Train loss=0.1448015570640564
[15/24] Train loss=0.14809399843215942
[20/24] Train loss=0.1425529271364212
Test set avg_accuracy=87.07% avg_sensitivity=70.46%, avg_specificity=92.92% avg_auc=90.88%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.139627 Test loss=0.329868 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14025942981243134
[5/24] Train loss=0.12241404503583908
[10/24] Train loss=0.1491498351097107
[15/24] Train loss=0.1470511257648468
[20/24] Train loss=0.13635124266147614
Test set avg_accuracy=86.81% avg_sensitivity=76.36%, avg_specificity=90.49% avg_auc=91.20%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.137757 Test loss=0.328559 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14068341255187988
[5/24] Train loss=0.11866649240255356
[10/24] Train loss=0.1403563916683197
[15/24] Train loss=0.14519774913787842
[20/24] Train loss=0.14036673307418823
Test set avg_accuracy=87.01% avg_sensitivity=74.96%, avg_specificity=91.25% avg_auc=90.84%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.136435 Test loss=0.332303 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13681429624557495
[5/24] Train loss=0.12021617591381073
[10/24] Train loss=0.136477530002594
[15/24] Train loss=0.14604714512825012
[20/24] Train loss=0.143511563539505
Test set avg_accuracy=87.02% avg_sensitivity=75.66%, avg_specificity=91.02% avg_auc=91.29%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.135956 Test loss=0.329382 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1411265730857849
[5/24] Train loss=0.11442966014146805
[10/24] Train loss=0.13593542575836182
[15/24] Train loss=0.14297457039356232
[20/24] Train loss=0.1396210491657257
Test set avg_accuracy=87.25% avg_sensitivity=70.76%, avg_specificity=93.06% avg_auc=90.43%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.134267 Test loss=0.332192 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13706442713737488
[5/24] Train loss=0.11510530859231949
[10/24] Train loss=0.13924938440322876
[15/24] Train loss=0.14008086919784546
[20/24] Train loss=0.14084652066230774
Test set avg_accuracy=86.76% avg_sensitivity=75.71%, avg_specificity=90.65% avg_auc=91.06%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.133505 Test loss=0.334607 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1329791098833084
[5/24] Train loss=0.11490920931100845
[10/24] Train loss=0.13522449135780334
[15/24] Train loss=0.14048679172992706
[20/24] Train loss=0.13649073243141174
Test set avg_accuracy=86.93% avg_sensitivity=76.61%, avg_specificity=90.56% avg_auc=91.19%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.131923 Test loss=0.333363 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1355142593383789
[5/24] Train loss=0.11189053952693939
[10/24] Train loss=0.13768520951271057
[15/24] Train loss=0.13915520906448364
[20/24] Train loss=0.13659080862998962
Test set avg_accuracy=87.11% avg_sensitivity=76.66%, avg_specificity=90.79% avg_auc=91.22%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.132302 Test loss=0.334184 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13223223388195038
[5/24] Train loss=0.1137620210647583
[10/24] Train loss=0.13717767596244812
[15/24] Train loss=0.14082923531532288
[20/24] Train loss=0.1364949345588684
Test set avg_accuracy=86.91% avg_sensitivity=74.21%, avg_specificity=91.39% avg_auc=90.72%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.131530 Test loss=0.337095 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.133306622505188
[5/24] Train loss=0.11411076039075851
[10/24] Train loss=0.13766153156757355
[15/24] Train loss=0.14462214708328247
[20/24] Train loss=0.13513383269309998
Test set avg_accuracy=87.70% avg_sensitivity=71.76%, avg_specificity=93.31% avg_auc=91.17%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.132341 Test loss=0.322493 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.12951846420764923
[5/24] Train loss=0.11381828784942627
[10/24] Train loss=0.1377619057893753
[15/24] Train loss=0.13952550292015076
[20/24] Train loss=0.13257110118865967
Test set avg_accuracy=87.21% avg_sensitivity=70.16%, avg_specificity=93.22% avg_auc=90.49%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.131151 Test loss=0.330850 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1309201717376709
[5/24] Train loss=0.1149917021393776
[10/24] Train loss=0.13308703899383545
[15/24] Train loss=0.13909117877483368
[20/24] Train loss=0.13341614603996277
Test set avg_accuracy=87.46% avg_sensitivity=70.61%, avg_specificity=93.40% avg_auc=91.05%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.129789 Test loss=0.326333 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13013821840286255
[5/24] Train loss=0.11276841163635254
[10/24] Train loss=0.13275763392448425
[15/24] Train loss=0.13862529397010803
[20/24] Train loss=0.13363583385944366
Test set avg_accuracy=87.32% avg_sensitivity=69.87%, avg_specificity=93.47% avg_auc=90.87%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.129115 Test loss=0.329760 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12866561114788055
[5/24] Train loss=0.11099044978618622
[10/24] Train loss=0.13139081001281738
[15/24] Train loss=0.13956613838672638
[20/24] Train loss=0.1305675208568573
Test set avg_accuracy=87.20% avg_sensitivity=68.47%, avg_specificity=93.80% avg_auc=90.49%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.128002 Test loss=0.333908 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12691712379455566
[5/24] Train loss=0.1097533330321312
[10/24] Train loss=0.13225702941417694
[15/24] Train loss=0.13519123196601868
[20/24] Train loss=0.1336755007505417
Test set avg_accuracy=87.41% avg_sensitivity=68.62%, avg_specificity=94.03% avg_auc=90.55%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.127488 Test loss=0.330418 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12480238825082779
[5/24] Train loss=0.11020863056182861
[10/24] Train loss=0.13128851354122162
[15/24] Train loss=0.13388904929161072
[20/24] Train loss=0.13089406490325928
Test set avg_accuracy=88.01% avg_sensitivity=73.81%, avg_specificity=93.01% avg_auc=91.27%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.127514 Test loss=0.320855 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12532201409339905
[5/24] Train loss=0.11239099502563477
[10/24] Train loss=0.13177810609340668
[15/24] Train loss=0.13313409686088562
[20/24] Train loss=0.12920939922332764
Test set avg_accuracy=87.46% avg_sensitivity=74.31%, avg_specificity=92.09% avg_auc=91.29%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.127977 Test loss=0.321083 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12527288496494293
[5/24] Train loss=0.1111103966832161
[10/24] Train loss=0.13557472825050354
[15/24] Train loss=0.13337364792823792
[20/24] Train loss=0.1286848783493042
Test set avg_accuracy=86.77% avg_sensitivity=78.56%, avg_specificity=89.66% avg_auc=91.31%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.126622 Test loss=0.328061 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12886610627174377
[5/24] Train loss=0.10874176025390625
[10/24] Train loss=0.12802591919898987
[15/24] Train loss=0.1330386996269226
[20/24] Train loss=0.12753844261169434
Test set avg_accuracy=87.30% avg_sensitivity=74.71%, avg_specificity=91.74% avg_auc=91.19%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.125264 Test loss=0.323701 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12777599692344666
[5/24] Train loss=0.10849841684103012
[10/24] Train loss=0.1293586641550064
[15/24] Train loss=0.1324954330921173
[20/24] Train loss=0.13011644780635834
Test set avg_accuracy=87.40% avg_sensitivity=74.36%, avg_specificity=91.99% avg_auc=91.12%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.125490 Test loss=0.323589 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12108913064002991
[5/24] Train loss=0.10966446250677109
[10/24] Train loss=0.12808164954185486
[15/24] Train loss=0.1339396834373474
[20/24] Train loss=0.12686550617218018
Test set avg_accuracy=87.32% avg_sensitivity=76.86%, avg_specificity=91.00% avg_auc=91.42%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.124576 Test loss=0.326627 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1225752905011177
[5/24] Train loss=0.10705011337995529
[10/24] Train loss=0.12506282329559326
[15/24] Train loss=0.13093002140522003
[20/24] Train loss=0.12747012078762054
Test set avg_accuracy=87.50% avg_sensitivity=75.56%, avg_specificity=91.71% avg_auc=91.11%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.123912 Test loss=0.326560 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1280028373003006
[5/24] Train loss=0.10864075273275375
[10/24] Train loss=0.12857379019260406
[15/24] Train loss=0.1318543702363968
[20/24] Train loss=0.12808775901794434
Test set avg_accuracy=87.14% avg_sensitivity=76.11%, avg_specificity=91.02% avg_auc=91.25%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.123922 Test loss=0.329740 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12413816899061203
[5/24] Train loss=0.1068822368979454
[10/24] Train loss=0.12813739478588104
[15/24] Train loss=0.13068203628063202
[20/24] Train loss=0.12585099041461945
Test set avg_accuracy=87.55% avg_sensitivity=73.31%, avg_specificity=92.57% avg_auc=91.25%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.122934 Test loss=0.320630 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12268910557031631
[5/24] Train loss=0.10698781907558441
[10/24] Train loss=0.1267063021659851
[15/24] Train loss=0.12967948615550995
[20/24] Train loss=0.1250268667936325
Test set avg_accuracy=87.55% avg_sensitivity=74.21%, avg_specificity=92.25% avg_auc=91.29%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.122367 Test loss=0.320885 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1242101863026619
[5/24] Train loss=0.10816900432109833
[10/24] Train loss=0.12354795634746552
[15/24] Train loss=0.12990979850292206
[20/24] Train loss=0.12470216304063797
Test set avg_accuracy=87.46% avg_sensitivity=75.06%, avg_specificity=91.83% avg_auc=91.17%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.122001 Test loss=0.324954 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1192217469215393
[5/24] Train loss=0.10807125270366669
[10/24] Train loss=0.12393888831138611
[15/24] Train loss=0.13053002953529358
[20/24] Train loss=0.124516561627388
Test set avg_accuracy=87.80% avg_sensitivity=74.91%, avg_specificity=92.34% avg_auc=91.18%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.121313 Test loss=0.322804 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.11935624480247498
[5/24] Train loss=0.10709095001220703
[10/24] Train loss=0.1262359470129013
[15/24] Train loss=0.1303272843360901
[20/24] Train loss=0.12386737763881683
Test set avg_accuracy=87.67% avg_sensitivity=74.76%, avg_specificity=92.22% avg_auc=91.09%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.120943 Test loss=0.323059 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.11916591972112656
[5/24] Train loss=0.10668621957302094
[10/24] Train loss=0.12390267103910446
[15/24] Train loss=0.12784363329410553
[20/24] Train loss=0.12336400896310806
Test set avg_accuracy=87.71% avg_sensitivity=74.51%, avg_specificity=92.36% avg_auc=91.12%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.120545 Test loss=0.324531 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11896618455648422
[5/24] Train loss=0.10668337345123291
[10/24] Train loss=0.1248844712972641
[15/24] Train loss=0.12923477590084076
[20/24] Train loss=0.12391910701990128
Test set avg_accuracy=87.85% avg_sensitivity=75.31%, avg_specificity=92.27% avg_auc=91.27%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.120482 Test loss=0.321603 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12095430493354797
[5/24] Train loss=0.10483157634735107
[10/24] Train loss=0.12192483246326447
[15/24] Train loss=0.12697181105613708
[20/24] Train loss=0.12706896662712097
Test set avg_accuracy=87.75% avg_sensitivity=75.26%, avg_specificity=92.15% avg_auc=91.20%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.120383 Test loss=0.323392 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12027747184038162
[5/24] Train loss=0.10620931535959244
[10/24] Train loss=0.12357349693775177
[15/24] Train loss=0.1273403763771057
[20/24] Train loss=0.12437974661588669
Test set avg_accuracy=87.66% avg_sensitivity=75.41%, avg_specificity=91.97% avg_auc=91.29%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.120292 Test loss=0.322473 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1197659894824028
[5/24] Train loss=0.10567528754472733
[10/24] Train loss=0.12476356327533722
[15/24] Train loss=0.12852230668067932
[20/24] Train loss=0.12250017374753952
Test set avg_accuracy=87.70% avg_sensitivity=74.61%, avg_specificity=92.30% avg_auc=91.30%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.120038 Test loss=0.321455 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12194716930389404
[5/24] Train loss=0.10670594871044159
[10/24] Train loss=0.12460044026374817
[15/24] Train loss=0.12553241848945618
[20/24] Train loss=0.12241802364587784
Test set avg_accuracy=87.76% avg_sensitivity=74.86%, avg_specificity=92.30% avg_auc=91.24%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.120252 Test loss=0.322211 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11873842030763626
[5/24] Train loss=0.10582508146762848
[10/24] Train loss=0.12293563783168793
[15/24] Train loss=0.12731707096099854
[20/24] Train loss=0.1231575533747673
Test set avg_accuracy=87.79% avg_sensitivity=74.66%, avg_specificity=92.41% avg_auc=91.23%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.119971 Test loss=0.322397 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12259847670793533
[5/24] Train loss=0.10605891793966293
[10/24] Train loss=0.12421537190675735
[15/24] Train loss=0.12652884423732758
[20/24] Train loss=0.1221441999077797
Test set avg_accuracy=87.68% avg_sensitivity=74.71%, avg_specificity=92.25% avg_auc=91.21%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.119790 Test loss=0.322941 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11853215843439102
[5/24] Train loss=0.10615082085132599
[10/24] Train loss=0.12214384973049164
[15/24] Train loss=0.1276923418045044
[20/24] Train loss=0.12268995493650436
Test set avg_accuracy=87.70% avg_sensitivity=74.66%, avg_specificity=92.29% avg_auc=91.22%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.119600 Test loss=0.322652 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1197759211063385
[5/24] Train loss=0.10580819845199585
[10/24] Train loss=0.12289264798164368
[15/24] Train loss=0.12745994329452515
[20/24] Train loss=0.12390993535518646
Test set avg_accuracy=87.66% avg_sensitivity=74.66%, avg_specificity=92.23% avg_auc=91.21%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.120098 Test loss=0.322825 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11984272301197052
[5/24] Train loss=0.10463761538267136
[10/24] Train loss=0.123820461332798
[15/24] Train loss=0.12733229994773865
[20/24] Train loss=0.12237229943275452
Test set avg_accuracy=87.66% avg_sensitivity=74.66%, avg_specificity=92.23% avg_auc=91.21%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.119545 Test loss=0.322911 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=88.12% sen=79.11%, spe=91.30%, auc=93.33%!
Fold[4] Avg_overlap=0.70%(0.23192184976106234)
[0/24] Train loss=0.7329081892967224
[5/24] Train loss=0.7195181846618652
[10/24] Train loss=0.7141275405883789
[15/24] Train loss=0.7107742428779602
[20/24] Train loss=0.70183265209198
Test set avg_accuracy=60.21% avg_sensitivity=48.39%, avg_specificity=64.24% avg_auc=60.68%
Best model saved!! Metric=-92.48393854811037!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.717124 Test loss=0.653862 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6982095241546631
[5/24] Train loss=0.6955733299255371
[10/24] Train loss=0.6942771077156067
[15/24] Train loss=0.6839895844459534
[20/24] Train loss=0.6759940385818481
Test set avg_accuracy=69.84% avg_sensitivity=62.06%, avg_specificity=72.50% avg_auc=73.21%
Best model saved!! Metric=-48.391286899529376!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.688553 Test loss=0.599561 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6712449193000793
[5/24] Train loss=0.6667848229408264
[10/24] Train loss=0.6748257279396057
[15/24] Train loss=0.648638129234314
[20/24] Train loss=0.6433444619178772
Test set avg_accuracy=72.11% avg_sensitivity=67.08%, avg_specificity=73.83% avg_auc=77.44%
Best model saved!! Metric=-35.548997844435476!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.661168 Test loss=0.564528 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6418759822845459
[5/24] Train loss=0.6324390172958374
[10/24] Train loss=0.6374455094337463
[15/24] Train loss=0.6159573197364807
[20/24] Train loss=0.6035142540931702
Test set avg_accuracy=73.70% avg_sensitivity=72.04%, avg_specificity=74.26% avg_auc=80.66%
Best model saved!! Metric=-25.339436334017932!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.630308 Test loss=0.538763 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6122915148735046
[5/24] Train loss=0.6073338985443115
[10/24] Train loss=0.6136367917060852
[15/24] Train loss=0.5838337540626526
[20/24] Train loss=0.5805166959762573
Test set avg_accuracy=75.30% avg_sensitivity=75.68%, avg_specificity=75.17% avg_auc=83.18%
Best model saved!! Metric=-16.674628980340657!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.602161 Test loss=0.514974 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.583534836769104
[5/24] Train loss=0.5729628801345825
[10/24] Train loss=0.5882794260978699
[15/24] Train loss=0.5539776086807251
[20/24] Train loss=0.5541481971740723
Test set avg_accuracy=76.86% avg_sensitivity=79.06%, avg_specificity=76.11% avg_auc=85.14%
Best model saved!! Metric=-8.825860551251282!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.574111 Test loss=0.492416 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5546488761901855
[5/24] Train loss=0.5468394160270691
[10/24] Train loss=0.5640661716461182
[15/24] Train loss=0.5192117691040039
[20/24] Train loss=0.5279396772384644
Test set avg_accuracy=78.35% avg_sensitivity=79.37%, avg_specificity=78.00% avg_auc=86.67%
Best model saved!! Metric=-3.623610869014243!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.546668 Test loss=0.469636 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5236067175865173
[5/24] Train loss=0.5153008699417114
[10/24] Train loss=0.5320732593536377
[15/24] Train loss=0.49404051899909973
[20/24] Train loss=0.4954986274242401
Test set avg_accuracy=80.33% avg_sensitivity=78.85%, avg_specificity=80.83% avg_auc=87.89%
Best model saved!! Metric=1.9009960461461048!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.518189 Test loss=0.443716 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5034582614898682
[5/24] Train loss=0.48688116669654846
[10/24] Train loss=0.5042155385017395
[15/24] Train loss=0.46275582909584045
[20/24] Train loss=0.4678029716014862
Test set avg_accuracy=82.51% avg_sensitivity=78.44%, avg_specificity=83.90% avg_auc=89.24%
Best model saved!! Metric=8.099844094230178!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.490613 Test loss=0.416444 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4709543287754059
[5/24] Train loss=0.4575139284133911
[10/24] Train loss=0.48151588439941406
[15/24] Train loss=0.43273621797561646
[20/24] Train loss=0.44017407298088074
Test set avg_accuracy=83.91% avg_sensitivity=78.80%, avg_specificity=85.65% avg_auc=90.39%
Best model saved!! Metric=12.748513597903255!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.463528 Test loss=0.397416 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4458409249782562
[5/24] Train loss=0.43017733097076416
[10/24] Train loss=0.4488222301006317
[15/24] Train loss=0.4120934307575226
[20/24] Train loss=0.409360408782959
Test set avg_accuracy=84.99% avg_sensitivity=77.83%, avg_specificity=87.43% avg_auc=91.25%
Best model saved!! Metric=15.495115051777503!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.436553 Test loss=0.375993 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.42051729559898376
[5/24] Train loss=0.4087015986442566
[10/24] Train loss=0.4327319264411926
[15/24] Train loss=0.3849494159221649
[20/24] Train loss=0.382612407207489
Test set avg_accuracy=86.17% avg_sensitivity=76.34%, avg_specificity=89.52% avg_auc=91.76%
Best model saved!! Metric=17.802070753516517!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.413088 Test loss=0.354885 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.39726290106773376
[5/24] Train loss=0.3802330195903778
[10/24] Train loss=0.40928924083709717
[15/24] Train loss=0.3629873991012573
[20/24] Train loss=0.36556243896484375
Test set avg_accuracy=86.63% avg_sensitivity=72.81%, avg_specificity=91.34% avg_auc=91.97%
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.390140 Test loss=0.338928 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3766602575778961
[5/24] Train loss=0.35695260763168335
[10/24] Train loss=0.3862029016017914
[15/24] Train loss=0.3440535068511963
[20/24] Train loss=0.3423907160758972
Test set avg_accuracy=87.12% avg_sensitivity=73.12%, avg_specificity=91.90% avg_auc=92.20%
Best model saved!! Metric=18.342589862192582!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.369124 Test loss=0.328806 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.36262038350105286
[5/24] Train loss=0.33785921335220337
[10/24] Train loss=0.37775442004203796
[15/24] Train loss=0.3229466676712036
[20/24] Train loss=0.3268572986125946
Test set avg_accuracy=87.16% avg_sensitivity=76.40%, avg_specificity=90.83% avg_auc=92.92%
Best model saved!! Metric=21.31203190927738!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.353096 Test loss=0.319694 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3418438136577606
[5/24] Train loss=0.3235182464122772
[10/24] Train loss=0.3625664710998535
[15/24] Train loss=0.31299325823783875
[20/24] Train loss=0.31228506565093994
Test set avg_accuracy=87.55% avg_sensitivity=75.63%, avg_specificity=91.62% avg_auc=93.11%
Best model saved!! Metric=21.907237559624278!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.337791 Test loss=0.308510 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.32948508858680725
[5/24] Train loss=0.3118880093097687
[10/24] Train loss=0.35786622762680054
[15/24] Train loss=0.3041345179080963
[20/24] Train loss=0.30646032094955444
Test set avg_accuracy=87.55% avg_sensitivity=74.40%, avg_specificity=92.04% avg_auc=93.30%
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.326241 Test loss=0.299597 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3206454813480377
[5/24] Train loss=0.3003755807876587
[10/24] Train loss=0.3452954888343811
[15/24] Train loss=0.28565406799316406
[20/24] Train loss=0.2968669831752777
Test set avg_accuracy=87.67% avg_sensitivity=79.88%, avg_specificity=90.33% avg_auc=93.92%
Best model saved!! Metric=25.793194565395098!!
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.316158 Test loss=0.298426 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3097175657749176
[5/24] Train loss=0.2951996922492981
[10/24] Train loss=0.33599695563316345
[15/24] Train loss=0.28092634677886963
[20/24] Train loss=0.2844608426094055
Test set avg_accuracy=87.70% avg_sensitivity=79.98%, avg_specificity=90.33% avg_auc=93.87%
Best model saved!! Metric=25.872920547899867!!
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.307202 Test loss=0.296301 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.30307862162590027
[5/24] Train loss=0.2779787480831146
[10/24] Train loss=0.3234139084815979
[15/24] Train loss=0.27042701840400696
[20/24] Train loss=0.2716105282306671
Test set avg_accuracy=88.33% avg_sensitivity=76.14%, avg_specificity=92.49% avg_auc=93.69%
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.298346 Test loss=0.285581 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2917706370353699
[5/24] Train loss=0.27348804473876953
[10/24] Train loss=0.32228875160217285
[15/24] Train loss=0.2679416835308075
[20/24] Train loss=0.268553227186203
Test set avg_accuracy=88.39% avg_sensitivity=75.27%, avg_specificity=92.86% avg_auc=93.88%
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.290757 Test loss=0.280447 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.28268375992774963
[5/24] Train loss=0.2643718719482422
[10/24] Train loss=0.30983102321624756
[15/24] Train loss=0.2554924488067627
[20/24] Train loss=0.2618771195411682
Test set avg_accuracy=88.63% avg_sensitivity=74.96%, avg_specificity=93.29% avg_auc=93.87%
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.282530 Test loss=0.279504 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.28127622604370117
[5/24] Train loss=0.2618958353996277
[10/24] Train loss=0.31329724192619324
[15/24] Train loss=0.25017091631889343
[20/24] Train loss=0.2622028887271881
Test set avg_accuracy=88.48% avg_sensitivity=75.06%, avg_specificity=93.05% avg_auc=94.05%
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.278613 Test loss=0.274858 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.277364581823349
[5/24] Train loss=0.2605487108230591
[10/24] Train loss=0.30871832370758057
[15/24] Train loss=0.24916087090969086
[20/24] Train loss=0.2529861032962799
Test set avg_accuracy=88.92% avg_sensitivity=72.35%, avg_specificity=94.57% avg_auc=94.05%
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.273830 Test loss=0.269968 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2648151218891144
[5/24] Train loss=0.2462339848279953
[10/24] Train loss=0.2978019118309021
[15/24] Train loss=0.24160659313201904
[20/24] Train loss=0.2468206286430359
Test set avg_accuracy=88.88% avg_sensitivity=71.48%, avg_specificity=94.81% avg_auc=94.05%
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.267513 Test loss=0.268217 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.26142722368240356
[5/24] Train loss=0.24092909693717957
[10/24] Train loss=0.29241839051246643
[15/24] Train loss=0.23552148044109344
[20/24] Train loss=0.24106983840465546
Test set avg_accuracy=88.65% avg_sensitivity=67.43%, avg_specificity=95.88% avg_auc=93.62%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.260939 Test loss=0.278692 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.25382885336875916
[5/24] Train loss=0.24235211312770844
[10/24] Train loss=0.28943783044815063
[15/24] Train loss=0.23156577348709106
[20/24] Train loss=0.24242748320102692
Test set avg_accuracy=88.57% avg_sensitivity=70.66%, avg_specificity=94.67% avg_auc=93.87%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.256433 Test loss=0.270414 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.24992072582244873
[5/24] Train loss=0.23832063376903534
[10/24] Train loss=0.2855868935585022
[15/24] Train loss=0.22984007000923157
[20/24] Train loss=0.2413090616464615
Test set avg_accuracy=87.55% avg_sensitivity=59.09%, avg_specificity=97.26% avg_auc=93.12%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.252541 Test loss=0.298848 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2550185024738312
[5/24] Train loss=0.23196136951446533
[10/24] Train loss=0.27925020456314087
[15/24] Train loss=0.22700591385364532
[20/24] Train loss=0.23833873867988586
Test set avg_accuracy=84.48% avg_sensitivity=43.16%, avg_specificity=98.57% avg_auc=90.11%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.247873 Test loss=0.378173 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.25618213415145874
[5/24] Train loss=0.223871111869812
[10/24] Train loss=0.2737620174884796
[15/24] Train loss=0.21539700031280518
[20/24] Train loss=0.23498231172561646
Test set avg_accuracy=87.01% avg_sensitivity=56.84%, avg_specificity=97.29% avg_auc=91.80%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.245013 Test loss=0.315760 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.24261440336704254
[5/24] Train loss=0.22310924530029297
[10/24] Train loss=0.2825615704059601
[15/24] Train loss=0.2235560268163681
[20/24] Train loss=0.22650238871574402
Test set avg_accuracy=88.14% avg_sensitivity=70.15%, avg_specificity=94.27% avg_auc=93.28%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.241692 Test loss=0.281127 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.23201413452625275
[5/24] Train loss=0.2160397619009018
[10/24] Train loss=0.27406758069992065
[15/24] Train loss=0.2182323932647705
[20/24] Train loss=0.22176015377044678
Test set avg_accuracy=87.10% avg_sensitivity=58.93%, avg_specificity=96.70% avg_auc=92.25%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.238227 Test loss=0.312158 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2325303554534912
[5/24] Train loss=0.21770738065242767
[10/24] Train loss=0.2718592584133148
[15/24] Train loss=0.2143382430076599
[20/24] Train loss=0.2290511578321457
Test set avg_accuracy=85.40% avg_sensitivity=48.18%, avg_specificity=98.10% avg_auc=89.96%
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.235930 Test loss=0.370469 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.23911970853805542
[5/24] Train loss=0.2039034217596054
[10/24] Train loss=0.258590430021286
[15/24] Train loss=0.21545089781284332
[20/24] Train loss=0.21809527277946472
Test set avg_accuracy=88.12% avg_sensitivity=77.57%, avg_specificity=91.72% avg_auc=93.67%
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.233749 Test loss=0.279423 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.23848825693130493
[5/24] Train loss=0.20503763854503632
[10/24] Train loss=0.2690914571285248
[15/24] Train loss=0.2124081403017044
[20/24] Train loss=0.20834581553936005
Test set avg_accuracy=87.62% avg_sensitivity=83.72%, avg_specificity=88.95% avg_auc=94.53%
Best model saved!! Metric=28.80700914325952!!
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.231450 Test loss=0.283881 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.21518844366073608
[5/24] Train loss=0.19497567415237427
[10/24] Train loss=0.25510209798812866
[15/24] Train loss=0.210298091173172
[20/24] Train loss=0.212225541472435
Test set avg_accuracy=86.60% avg_sensitivity=85.51%, avg_specificity=86.97% avg_auc=94.14%
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.226414 Test loss=0.296676 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.22340203821659088
[5/24] Train loss=0.1954590231180191
[10/24] Train loss=0.25994673371315
[15/24] Train loss=0.21009443700313568
[20/24] Train loss=0.20203448832035065
Test set avg_accuracy=88.20% avg_sensitivity=75.68%, avg_specificity=92.47% avg_auc=93.81%
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.225066 Test loss=0.270653 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2158249169588089
[5/24] Train loss=0.19445976614952087
[10/24] Train loss=0.24818038940429688
[15/24] Train loss=0.20599782466888428
[20/24] Train loss=0.21578747034072876
Test set avg_accuracy=86.30% avg_sensitivity=83.97%, avg_specificity=87.10% avg_auc=93.77%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.220218 Test loss=0.303761 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.20942798256874084
[5/24] Train loss=0.18665362894535065
[10/24] Train loss=0.25203925371170044
[15/24] Train loss=0.19971294701099396
[20/24] Train loss=0.21260885894298553
Test set avg_accuracy=83.84% avg_sensitivity=86.07%, avg_specificity=83.08% avg_auc=92.45%
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.218396 Test loss=0.363951 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.23273974657058716
[5/24] Train loss=0.18282119929790497
[10/24] Train loss=0.2361118048429489
[15/24] Train loss=0.20117615163326263
[20/24] Train loss=0.20716427266597748
Test set avg_accuracy=86.60% avg_sensitivity=85.97%, avg_specificity=86.82% avg_auc=94.17%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.217731 Test loss=0.298541 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.212014839053154
[5/24] Train loss=0.189409077167511
[10/24] Train loss=0.24793317914009094
[15/24] Train loss=0.19700628519058228
[20/24] Train loss=0.1954134702682495
Test set avg_accuracy=88.24% avg_sensitivity=78.14%, avg_specificity=91.69% avg_auc=94.05%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.215588 Test loss=0.269262 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.21317218244075775
[5/24] Train loss=0.20330771803855896
[10/24] Train loss=0.24053889513015747
[15/24] Train loss=0.19371654093265533
[20/24] Train loss=0.21014615893363953
Test set avg_accuracy=84.09% avg_sensitivity=86.84%, avg_specificity=83.15% avg_auc=93.47%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.219260 Test loss=0.336489 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2207767218351364
[5/24] Train loss=0.1903676837682724
[10/24] Train loss=0.2454037368297577
[15/24] Train loss=0.19853419065475464
[20/24] Train loss=0.20031215250492096
Test set avg_accuracy=87.92% avg_sensitivity=74.45%, avg_specificity=92.51% avg_auc=93.18%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.218623 Test loss=0.279774 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.21908102929592133
[5/24] Train loss=0.1788586527109146
[10/24] Train loss=0.23062686622142792
[15/24] Train loss=0.20188114047050476
[20/24] Train loss=0.19627708196640015
Test set avg_accuracy=88.46% avg_sensitivity=77.78%, avg_specificity=92.11% avg_auc=94.34%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.215910 Test loss=0.265567 Current lr=[0.00029967723776099]

[0/24] Train loss=0.21880948543548584
[5/24] Train loss=0.182012677192688
[10/24] Train loss=0.2286805659532547
[15/24] Train loss=0.20093125104904175
[20/24] Train loss=0.20010922849178314
Test set avg_accuracy=88.10% avg_sensitivity=82.33%, avg_specificity=90.06% avg_auc=94.45%
Best model saved!! Metric=28.945296914577867!!
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.213749 Test loss=0.271799 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.21124020218849182
[5/24] Train loss=0.18264217674732208
[10/24] Train loss=0.22637012600898743
[15/24] Train loss=0.20021264255046844
[20/24] Train loss=0.1856251209974289
Test set avg_accuracy=88.57% avg_sensitivity=80.90%, avg_specificity=91.18% avg_auc=94.83%
Best model saved!! Metric=29.476452864207346!!
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.208577 Test loss=0.257149 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.20765073597431183
[5/24] Train loss=0.17595930397510529
[10/24] Train loss=0.2175479382276535
[15/24] Train loss=0.20390592515468597
[20/24] Train loss=0.19202680885791779
Test set avg_accuracy=87.63% avg_sensitivity=78.49%, avg_specificity=90.75% avg_auc=93.71%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.206849 Test loss=0.283937 Current lr=[0.000299720220882401]

[0/24] Train loss=0.200969398021698
[5/24] Train loss=0.17482046782970428
[10/24] Train loss=0.2386600375175476
[15/24] Train loss=0.19145868718624115
[20/24] Train loss=0.18229323625564575
Test set avg_accuracy=88.05% avg_sensitivity=68.46%, avg_specificity=94.73% avg_auc=92.52%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.208353 Test loss=0.298112 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.20532512664794922
[5/24] Train loss=0.19327381253242493
[10/24] Train loss=0.22798152267932892
[15/24] Train loss=0.2004222273826599
[20/24] Train loss=0.18853674829006195
Test set avg_accuracy=89.06% avg_sensitivity=75.01%, avg_specificity=93.85% avg_auc=94.71%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.206362 Test loss=0.255831 Current lr=[0.000298904600941902]

[0/24] Train loss=0.20359507203102112
[5/24] Train loss=0.18309511244297028
[10/24] Train loss=0.21742166578769684
[15/24] Train loss=0.19012445211410522
[20/24] Train loss=0.20197603106498718
Test set avg_accuracy=87.96% avg_sensitivity=67.95%, avg_specificity=94.78% avg_auc=93.35%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.202283 Test loss=0.283484 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.20091548562049866
[5/24] Train loss=0.17964662611484528
[10/24] Train loss=0.21559341251850128
[15/24] Train loss=0.18885263800621033
[20/24] Train loss=0.19133132696151733
Test set avg_accuracy=88.19% avg_sensitivity=66.36%, avg_specificity=95.63% avg_auc=92.09%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.201371 Test loss=0.301787 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2035171240568161
[5/24] Train loss=0.1871037632226944
[10/24] Train loss=0.21429263055324554
[15/24] Train loss=0.19402234256267548
[20/24] Train loss=0.19226746261119843
Test set avg_accuracy=88.14% avg_sensitivity=75.17%, avg_specificity=92.56% avg_auc=94.18%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.200656 Test loss=0.268291 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.19847345352172852
[5/24] Train loss=0.16218048334121704
[10/24] Train loss=0.2365683764219284
[15/24] Train loss=0.1841922253370285
[20/24] Train loss=0.17631633579730988
Test set avg_accuracy=84.87% avg_sensitivity=79.83%, avg_specificity=86.59% avg_auc=92.17%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.196594 Test loss=0.329042 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.19349057972431183
[5/24] Train loss=0.1637168675661087
[10/24] Train loss=0.23281888663768768
[15/24] Train loss=0.1914004385471344
[20/24] Train loss=0.19702480733394623
Test set avg_accuracy=88.45% avg_sensitivity=71.99%, avg_specificity=94.06% avg_auc=93.89%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.200267 Test loss=0.273549 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.19344909489154816
[5/24] Train loss=0.16613700985908508
[10/24] Train loss=0.21572135388851166
[15/24] Train loss=0.19872616231441498
[20/24] Train loss=0.18925315141677856
Test set avg_accuracy=86.86% avg_sensitivity=56.99%, avg_specificity=97.05% avg_auc=90.96%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.193508 Test loss=0.341719 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2020469307899475
[5/24] Train loss=0.16839076578617096
[10/24] Train loss=0.2023676484823227
[15/24] Train loss=0.18395055830478668
[20/24] Train loss=0.19263695180416107
Test set avg_accuracy=86.88% avg_sensitivity=59.81%, avg_specificity=96.11% avg_auc=91.04%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.194633 Test loss=0.323364 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.21634212136268616
[5/24] Train loss=0.17159850895404816
[10/24] Train loss=0.20390629768371582
[15/24] Train loss=0.18787799775600433
[20/24] Train loss=0.18136553466320038
Test set avg_accuracy=88.39% avg_sensitivity=76.80%, avg_specificity=92.33% avg_auc=94.24%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.198001 Test loss=0.269445 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.19152869284152985
[5/24] Train loss=0.16667057573795319
[10/24] Train loss=0.2014564871788025
[15/24] Train loss=0.18801429867744446
[20/24] Train loss=0.18792328238487244
Test set avg_accuracy=81.80% avg_sensitivity=36.82%, avg_specificity=97.14% avg_auc=85.49%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.192388 Test loss=0.475228 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.21021786332130432
[5/24] Train loss=0.16352388262748718
[10/24] Train loss=0.21965914964675903
[15/24] Train loss=0.18699109554290771
[20/24] Train loss=0.18745854496955872
Test set avg_accuracy=86.51% avg_sensitivity=57.91%, avg_specificity=96.26% avg_auc=90.53%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.195633 Test loss=0.331715 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2043556272983551
[5/24] Train loss=0.16222858428955078
[10/24] Train loss=0.19989779591560364
[15/24] Train loss=0.18165850639343262
[20/24] Train loss=0.18229340016841888
Test set avg_accuracy=87.85% avg_sensitivity=62.42%, avg_specificity=96.53% avg_auc=90.77%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.189822 Test loss=0.314993 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.20096509158611298
[5/24] Train loss=0.16288447380065918
[10/24] Train loss=0.20368129014968872
[15/24] Train loss=0.1756121814250946
[20/24] Train loss=0.17573273181915283
Test set avg_accuracy=84.23% avg_sensitivity=43.06%, avg_specificity=98.27% avg_auc=86.07%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.189851 Test loss=0.433604 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.19986164569854736
[5/24] Train loss=0.16637593507766724
[10/24] Train loss=0.18699149787425995
[15/24] Train loss=0.1750255972146988
[20/24] Train loss=0.1837899088859558
Test set avg_accuracy=87.16% avg_sensitivity=63.18%, avg_specificity=95.34% avg_auc=92.17%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.189018 Test loss=0.312768 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.19600678980350494
[5/24] Train loss=0.16232503950595856
[10/24] Train loss=0.19164443016052246
[15/24] Train loss=0.17408454418182373
[20/24] Train loss=0.18207179009914398
Test set avg_accuracy=87.75% avg_sensitivity=63.80%, avg_specificity=95.91% avg_auc=92.51%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.188191 Test loss=0.306976 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.1911870837211609
[5/24] Train loss=0.1640697717666626
[10/24] Train loss=0.19871817529201508
[15/24] Train loss=0.17174477875232697
[20/24] Train loss=0.17627207934856415
Test set avg_accuracy=87.76% avg_sensitivity=80.44%, avg_specificity=90.26% avg_auc=93.83%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.185036 Test loss=0.283569 Current lr=[0.000276307469034998]

[0/24] Train loss=0.18768025934696198
[5/24] Train loss=0.16301070153713226
[10/24] Train loss=0.20561741292476654
[15/24] Train loss=0.18016596138477325
[20/24] Train loss=0.17220105230808258
Test set avg_accuracy=82.37% avg_sensitivity=37.12%, avg_specificity=97.80% avg_auc=83.95%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.186574 Test loss=0.505834 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.20083485543727875
[5/24] Train loss=0.1631801724433899
[10/24] Train loss=0.19987452030181885
[15/24] Train loss=0.16846224665641785
[20/24] Train loss=0.16971483826637268
Test set avg_accuracy=88.06% avg_sensitivity=82.44%, avg_specificity=89.98% avg_auc=94.47%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.185815 Test loss=0.270592 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.18327955901622772
[5/24] Train loss=0.1525987982749939
[10/24] Train loss=0.1882404088973999
[15/24] Train loss=0.16981805860996246
[20/24] Train loss=0.1660369634628296
Test set avg_accuracy=88.46% avg_sensitivity=71.99%, avg_specificity=94.08% avg_auc=92.57%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.180991 Test loss=0.291978 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.1909971833229065
[5/24] Train loss=0.15961316227912903
[10/24] Train loss=0.18756628036499023
[15/24] Train loss=0.17621402442455292
[20/24] Train loss=0.17594683170318604
Test set avg_accuracy=87.57% avg_sensitivity=66.92%, avg_specificity=94.60% avg_auc=91.36%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.181799 Test loss=0.317797 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.18796104192733765
[5/24] Train loss=0.16466183960437775
[10/24] Train loss=0.1811680942773819
[15/24] Train loss=0.17265087366104126
[20/24] Train loss=0.17146074771881104
Test set avg_accuracy=79.95% avg_sensitivity=83.05%, avg_specificity=78.89% avg_auc=89.02%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.182024 Test loss=0.435727 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.19628611207008362
[5/24] Train loss=0.16761796176433563
[10/24] Train loss=0.1878003478050232
[15/24] Train loss=0.1748635321855545
[20/24] Train loss=0.17936453223228455
Test set avg_accuracy=88.11% avg_sensitivity=81.77%, avg_specificity=90.27% avg_auc=94.23%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.187010 Test loss=0.281771 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.1924697458744049
[5/24] Train loss=0.1624557226896286
[10/24] Train loss=0.19504430890083313
[15/24] Train loss=0.169562429189682
[20/24] Train loss=0.17012521624565125
Test set avg_accuracy=88.20% avg_sensitivity=65.75%, avg_specificity=95.86% avg_auc=93.01%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.180587 Test loss=0.297460 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.19393174350261688
[5/24] Train loss=0.15412448346614838
[10/24] Train loss=0.17671561241149902
[15/24] Train loss=0.17495028674602509
[20/24] Train loss=0.17393025755882263
Test set avg_accuracy=87.37% avg_sensitivity=79.26%, avg_specificity=90.13% avg_auc=93.47%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.179290 Test loss=0.293163 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.18279892206192017
[5/24] Train loss=0.16635765135288239
[10/24] Train loss=0.1902618259191513
[15/24] Train loss=0.17363670468330383
[20/24] Train loss=0.17625190317630768
Test set avg_accuracy=86.97% avg_sensitivity=79.37%, avg_specificity=89.56% avg_auc=93.12%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.181266 Test loss=0.302664 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.18172457814216614
[5/24] Train loss=0.1618821769952774
[10/24] Train loss=0.18300512433052063
[15/24] Train loss=0.17247731983661652
[20/24] Train loss=0.17046181857585907
Test set avg_accuracy=86.38% avg_sensitivity=83.97%, avg_specificity=87.20% avg_auc=93.40%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.177244 Test loss=0.311274 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.18649649620056152
[5/24] Train loss=0.15638642013072968
[10/24] Train loss=0.18488295376300812
[15/24] Train loss=0.1741323620080948
[20/24] Train loss=0.1680469661951065
Test set avg_accuracy=87.23% avg_sensitivity=82.13%, avg_specificity=88.96% avg_auc=93.41%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.179250 Test loss=0.301318 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.19791200757026672
[5/24] Train loss=0.16158388555049896
[10/24] Train loss=0.17585201561450958
[15/24] Train loss=0.1645711064338684
[20/24] Train loss=0.1683800369501114
Test set avg_accuracy=84.74% avg_sensitivity=85.15%, avg_specificity=84.60% avg_auc=93.04%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.176730 Test loss=0.333854 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.18372361361980438
[5/24] Train loss=0.1605219542980194
[10/24] Train loss=0.17398008704185486
[15/24] Train loss=0.16905677318572998
[20/24] Train loss=0.16788294911384583
Test set avg_accuracy=88.03% avg_sensitivity=70.71%, avg_specificity=93.94% avg_auc=92.19%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.175309 Test loss=0.296451 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.18249891698360443
[5/24] Train loss=0.1516306847333908
[10/24] Train loss=0.16738680005073547
[15/24] Train loss=0.16469839215278625
[20/24] Train loss=0.17073583602905273
Test set avg_accuracy=87.11% avg_sensitivity=83.56%, avg_specificity=88.32% avg_auc=93.58%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.174109 Test loss=0.301336 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.17858433723449707
[5/24] Train loss=0.15029539167881012
[10/24] Train loss=0.17206493020057678
[15/24] Train loss=0.17179442942142487
[20/24] Train loss=0.17647962272167206
Test set avg_accuracy=87.38% avg_sensitivity=83.05%, avg_specificity=88.86% avg_auc=93.44%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.172326 Test loss=0.299072 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.178170844912529
[5/24] Train loss=0.15184268355369568
[10/24] Train loss=0.16675330698490143
[15/24] Train loss=0.1657116562128067
[20/24] Train loss=0.1639954000711441
Test set avg_accuracy=87.25% avg_sensitivity=78.90%, avg_specificity=90.10% avg_auc=92.74%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.171223 Test loss=0.300830 Current lr=[0.000224838296036774]

[0/24] Train loss=0.17988543212413788
[5/24] Train loss=0.15005633234977722
[10/24] Train loss=0.16807928681373596
[15/24] Train loss=0.15711763501167297
[20/24] Train loss=0.16519999504089355
Test set avg_accuracy=87.33% avg_sensitivity=77.78%, avg_specificity=90.59% avg_auc=92.38%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.173080 Test loss=0.307239 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.18218590319156647
[5/24] Train loss=0.1531306356191635
[10/24] Train loss=0.180730938911438
[15/24] Train loss=0.16227681934833527
[20/24] Train loss=0.159219428896904
Test set avg_accuracy=86.50% avg_sensitivity=64.98%, avg_specificity=93.84% avg_auc=89.27%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.173366 Test loss=0.337875 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.18166807293891907
[5/24] Train loss=0.1500917226076126
[10/24] Train loss=0.16296394169330597
[15/24] Train loss=0.15764667093753815
[20/24] Train loss=0.16308671236038208
Test set avg_accuracy=88.89% avg_sensitivity=70.51%, avg_specificity=95.16% avg_auc=92.67%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.170309 Test loss=0.288016 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1796441525220871
[5/24] Train loss=0.15181046724319458
[10/24] Train loss=0.16708536446094513
[15/24] Train loss=0.15979500114917755
[20/24] Train loss=0.16163307428359985
Test set avg_accuracy=88.45% avg_sensitivity=69.38%, avg_specificity=94.95% avg_auc=91.80%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.165943 Test loss=0.298246 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.18433356285095215
[5/24] Train loss=0.14439766108989716
[10/24] Train loss=0.1709386259317398
[15/24] Train loss=0.1595088690519333
[20/24] Train loss=0.1652347296476364
Test set avg_accuracy=88.58% avg_sensitivity=69.94%, avg_specificity=94.94% avg_auc=93.06%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.166700 Test loss=0.282060 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.17054596543312073
[5/24] Train loss=0.1455782949924469
[10/24] Train loss=0.16945253312587738
[15/24] Train loss=0.16532489657402039
[20/24] Train loss=0.1627386063337326
Test set avg_accuracy=87.72% avg_sensitivity=77.27%, avg_specificity=91.29% avg_auc=93.11%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.167344 Test loss=0.289725 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.17260171473026276
[5/24] Train loss=0.15937316417694092
[10/24] Train loss=0.1796453297138214
[15/24] Train loss=0.15998399257659912
[20/24] Train loss=0.15807141363620758
Test set avg_accuracy=88.35% avg_sensitivity=67.59%, avg_specificity=95.43% avg_auc=92.53%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.169318 Test loss=0.294645 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.17143888771533966
[5/24] Train loss=0.15086597204208374
[10/24] Train loss=0.17140910029411316
[15/24] Train loss=0.1608472317457199
[20/24] Train loss=0.1591128557920456
Test set avg_accuracy=87.68% avg_sensitivity=64.62%, avg_specificity=95.55% avg_auc=91.63%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.167060 Test loss=0.311346 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.17007215321063995
[5/24] Train loss=0.14905215799808502
[10/24] Train loss=0.15957660973072052
[15/24] Train loss=0.15132081508636475
[20/24] Train loss=0.16163121163845062
Test set avg_accuracy=88.27% avg_sensitivity=69.23%, avg_specificity=94.76% avg_auc=92.98%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.167843 Test loss=0.290774 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.17099851369857788
[5/24] Train loss=0.14130936563014984
[10/24] Train loss=0.17285868525505066
[15/24] Train loss=0.16076059639453888
[20/24] Train loss=0.16018810868263245
Test set avg_accuracy=88.06% avg_sensitivity=70.87%, avg_specificity=93.92% avg_auc=92.95%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.167587 Test loss=0.294234 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.16459479928016663
[5/24] Train loss=0.14962515234947205
[10/24] Train loss=0.1656467169523239
[15/24] Train loss=0.1559981405735016
[20/24] Train loss=0.16465525329113007
Test set avg_accuracy=87.76% avg_sensitivity=76.50%, avg_specificity=91.60% avg_auc=93.23%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.162505 Test loss=0.291157 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.16692055761814117
[5/24] Train loss=0.15257366001605988
[10/24] Train loss=0.15936830639839172
[15/24] Train loss=0.15063636004924774
[20/24] Train loss=0.15470635890960693
Test set avg_accuracy=84.54% avg_sensitivity=77.68%, avg_specificity=86.89% avg_auc=90.98%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.162486 Test loss=0.356423 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.17712122201919556
[5/24] Train loss=0.1567004919052124
[10/24] Train loss=0.1608002483844757
[15/24] Train loss=0.16270902752876282
[20/24] Train loss=0.15962722897529602
Test set avg_accuracy=88.79% avg_sensitivity=71.99%, avg_specificity=94.52% avg_auc=93.57%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.165627 Test loss=0.283172 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.17073488235473633
[5/24] Train loss=0.15865734219551086
[10/24] Train loss=0.17767184972763062
[15/24] Train loss=0.15283311903476715
[20/24] Train loss=0.15245060622692108
Test set avg_accuracy=87.92% avg_sensitivity=81.62%, avg_specificity=90.06% avg_auc=93.92%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.167086 Test loss=0.285958 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.16558292508125305
[5/24] Train loss=0.14841003715991974
[10/24] Train loss=0.15693369507789612
[15/24] Train loss=0.14586776494979858
[20/24] Train loss=0.16151191294193268
Test set avg_accuracy=87.96% avg_sensitivity=64.82%, avg_specificity=95.84% avg_auc=93.17%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.162183 Test loss=0.293808 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.17458106577396393
[5/24] Train loss=0.1440366506576538
[10/24] Train loss=0.15498469769954681
[15/24] Train loss=0.1513773649930954
[20/24] Train loss=0.14819590747356415
Test set avg_accuracy=87.45% avg_sensitivity=78.70%, avg_specificity=90.43% avg_auc=93.07%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.159613 Test loss=0.299901 Current lr=[0.000156543481933168]

[0/24] Train loss=0.15972885489463806
[5/24] Train loss=0.14276829361915588
[10/24] Train loss=0.15182000398635864
[15/24] Train loss=0.14654624462127686
[20/24] Train loss=0.14847035706043243
Test set avg_accuracy=88.68% avg_sensitivity=69.74%, avg_specificity=95.15% avg_auc=93.17%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.155848 Test loss=0.286578 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1608591377735138
[5/24] Train loss=0.13846993446350098
[10/24] Train loss=0.1518288105726242
[15/24] Train loss=0.15062810480594635
[20/24] Train loss=0.14706456661224365
Test set avg_accuracy=88.09% avg_sensitivity=67.38%, avg_specificity=95.15% avg_auc=92.50%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.154984 Test loss=0.297091 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.16703197360038757
[5/24] Train loss=0.14318327605724335
[10/24] Train loss=0.14958961308002472
[15/24] Train loss=0.14266522228717804
[20/24] Train loss=0.14331208169460297
Test set avg_accuracy=89.22% avg_sensitivity=74.30%, avg_specificity=94.31% avg_auc=93.30%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.153236 Test loss=0.280245 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15773539245128632
[5/24] Train loss=0.14211712777614594
[10/24] Train loss=0.1591992825269699
[15/24] Train loss=0.1443171203136444
[20/24] Train loss=0.15132580697536469
Test set avg_accuracy=88.80% avg_sensitivity=69.53%, avg_specificity=95.37% avg_auc=92.79%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.154761 Test loss=0.289644 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1533633917570114
[5/24] Train loss=0.14322657883167267
[10/24] Train loss=0.15235570073127747
[15/24] Train loss=0.14947882294654846
[20/24] Train loss=0.14560286700725555
Test set avg_accuracy=87.73% avg_sensitivity=61.96%, avg_specificity=96.53% avg_auc=91.23%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.154096 Test loss=0.318127 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16310057044029236
[5/24] Train loss=0.1426444798707962
[10/24] Train loss=0.15196345746517181
[15/24] Train loss=0.14707724750041962
[20/24] Train loss=0.14270183444023132
Test set avg_accuracy=88.91% avg_sensitivity=72.35%, avg_specificity=94.55% avg_auc=93.53%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.151633 Test loss=0.281096 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15858609974384308
[5/24] Train loss=0.14706067740917206
[10/24] Train loss=0.15363188087940216
[15/24] Train loss=0.1480437070131302
[20/24] Train loss=0.141758531332016
Test set avg_accuracy=86.00% avg_sensitivity=51.97%, avg_specificity=97.61% avg_auc=86.33%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.152486 Test loss=0.394248 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1690351963043213
[5/24] Train loss=0.1415949910879135
[10/24] Train loss=0.1501953899860382
[15/24] Train loss=0.14425939321517944
[20/24] Train loss=0.14546503126621246
Test set avg_accuracy=88.71% avg_sensitivity=69.33%, avg_specificity=95.32% avg_auc=93.06%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.152401 Test loss=0.286508 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15714071691036224
[5/24] Train loss=0.14735640585422516
[10/24] Train loss=0.1492093801498413
[15/24] Train loss=0.14337477087974548
[20/24] Train loss=0.139881432056427
Test set avg_accuracy=88.03% avg_sensitivity=67.95%, avg_specificity=94.88% avg_auc=92.02%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.151292 Test loss=0.299673 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.15906375646591187
[5/24] Train loss=0.1363409012556076
[10/24] Train loss=0.14685748517513275
[15/24] Train loss=0.14046485722064972
[20/24] Train loss=0.14761142432689667
Test set avg_accuracy=88.18% avg_sensitivity=70.40%, avg_specificity=94.24% avg_auc=92.89%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.151342 Test loss=0.292406 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16272316873073578
[5/24] Train loss=0.1490839421749115
[10/24] Train loss=0.1472136229276657
[15/24] Train loss=0.14624297618865967
[20/24] Train loss=0.14103981852531433
Test set avg_accuracy=86.25% avg_sensitivity=54.89%, avg_specificity=96.94% avg_auc=87.02%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.152229 Test loss=0.386465 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15965798497200012
[5/24] Train loss=0.14144545793533325
[10/24] Train loss=0.14911162853240967
[15/24] Train loss=0.14256304502487183
[20/24] Train loss=0.14226578176021576
Test set avg_accuracy=88.76% avg_sensitivity=69.38%, avg_specificity=95.37% avg_auc=93.01%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.150833 Test loss=0.287448 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15782420337200165
[5/24] Train loss=0.13572782278060913
[10/24] Train loss=0.1468273550271988
[15/24] Train loss=0.13964281976222992
[20/24] Train loss=0.14209112524986267
Test set avg_accuracy=88.97% avg_sensitivity=73.37%, avg_specificity=94.29% avg_auc=93.35%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.149004 Test loss=0.279982 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.15615400671958923
[5/24] Train loss=0.13676494359970093
[10/24] Train loss=0.14219434559345245
[15/24] Train loss=0.13827811181545258
[20/24] Train loss=0.14123138785362244
Test set avg_accuracy=88.54% avg_sensitivity=77.21%, avg_specificity=92.40% avg_auc=93.35%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.146334 Test loss=0.287267 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15325137972831726
[5/24] Train loss=0.1341659426689148
[10/24] Train loss=0.14096035063266754
[15/24] Train loss=0.13765211403369904
[20/24] Train loss=0.1363338679075241
Test set avg_accuracy=88.10% avg_sensitivity=78.90%, avg_specificity=91.23% avg_auc=93.37%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.144649 Test loss=0.293934 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.15254628658294678
[5/24] Train loss=0.13318371772766113
[10/24] Train loss=0.13790953159332275
[15/24] Train loss=0.13719192147254944
[20/24] Train loss=0.13794973492622375
Test set avg_accuracy=88.72% avg_sensitivity=76.24%, avg_specificity=92.98% avg_auc=93.29%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.142781 Test loss=0.288002 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1519254744052887
[5/24] Train loss=0.13330285251140594
[10/24] Train loss=0.13693419098854065
[15/24] Train loss=0.13484123349189758
[20/24] Train loss=0.13609305024147034
Test set avg_accuracy=88.54% avg_sensitivity=70.92%, avg_specificity=94.55% avg_auc=92.74%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.142278 Test loss=0.288584 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1484544724225998
[5/24] Train loss=0.13886268436908722
[10/24] Train loss=0.13729944825172424
[15/24] Train loss=0.1331743448972702
[20/24] Train loss=0.1350250244140625
Test set avg_accuracy=88.83% avg_sensitivity=73.32%, avg_specificity=94.12% avg_auc=93.18%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.141194 Test loss=0.286635 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.15051095187664032
[5/24] Train loss=0.130706787109375
[10/24] Train loss=0.13400602340698242
[15/24] Train loss=0.13766616582870483
[20/24] Train loss=0.13420501351356506
Test set avg_accuracy=87.97% avg_sensitivity=80.49%, avg_specificity=90.52% avg_auc=93.51%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.139694 Test loss=0.298108 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15258170664310455
[5/24] Train loss=0.13039690256118774
[10/24] Train loss=0.1320313662290573
[15/24] Train loss=0.13679753243923187
[20/24] Train loss=0.1349569857120514
Test set avg_accuracy=88.71% avg_sensitivity=77.37%, avg_specificity=92.58% avg_auc=93.27%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.138975 Test loss=0.287682 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14874932169914246
[5/24] Train loss=0.12744763493537903
[10/24] Train loss=0.1337633728981018
[15/24] Train loss=0.12952309846878052
[20/24] Train loss=0.13209529221057892
Test set avg_accuracy=88.78% avg_sensitivity=74.30%, avg_specificity=93.71% avg_auc=93.03%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.138202 Test loss=0.282436 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14431576430797577
[5/24] Train loss=0.12555786967277527
[10/24] Train loss=0.12728260457515717
[15/24] Train loss=0.1290711760520935
[20/24] Train loss=0.12931691110134125
Test set avg_accuracy=88.66% avg_sensitivity=71.38%, avg_specificity=94.55% avg_auc=92.47%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.136286 Test loss=0.293059 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14393717050552368
[5/24] Train loss=0.12546248733997345
[10/24] Train loss=0.13308806717395782
[15/24] Train loss=0.12518063187599182
[20/24] Train loss=0.130604550242424
Test set avg_accuracy=88.83% avg_sensitivity=70.51%, avg_specificity=95.08% avg_auc=92.59%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.135807 Test loss=0.290555 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14813576638698578
[5/24] Train loss=0.1264207363128662
[10/24] Train loss=0.12626643478870392
[15/24] Train loss=0.12941566109657288
[20/24] Train loss=0.1296771764755249
Test set avg_accuracy=88.82% avg_sensitivity=72.25%, avg_specificity=94.46% avg_auc=92.53%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.134729 Test loss=0.290878 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14204123616218567
[5/24] Train loss=0.12404359132051468
[10/24] Train loss=0.12184622138738632
[15/24] Train loss=0.12315426766872406
[20/24] Train loss=0.12600523233413696
Test set avg_accuracy=88.71% avg_sensitivity=71.38%, avg_specificity=94.62% avg_auc=92.43%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.132651 Test loss=0.293224 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.14573733508586884
[5/24] Train loss=0.12360119074583054
[10/24] Train loss=0.127451092004776
[15/24] Train loss=0.127861887216568
[20/24] Train loss=0.12969699501991272
Test set avg_accuracy=88.63% avg_sensitivity=71.38%, avg_specificity=94.52% avg_auc=92.43%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.133232 Test loss=0.293145 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.144338458776474
[5/24] Train loss=0.12478318810462952
[10/24] Train loss=0.12424470484256744
[15/24] Train loss=0.12819533050060272
[20/24] Train loss=0.12698815762996674
Test set avg_accuracy=88.62% avg_sensitivity=72.61%, avg_specificity=94.08% avg_auc=92.53%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.132045 Test loss=0.289499 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.14288537204265594
[5/24] Train loss=0.12265105545520782
[10/24] Train loss=0.1265702247619629
[15/24] Train loss=0.12320079654455185
[20/24] Train loss=0.12403696775436401
Test set avg_accuracy=88.84% avg_sensitivity=69.38%, avg_specificity=95.48% avg_auc=92.59%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.130756 Test loss=0.293072 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13956663012504578
[5/24] Train loss=0.12426365166902542
[10/24] Train loss=0.12180942296981812
[15/24] Train loss=0.12424895167350769
[20/24] Train loss=0.12707361578941345
Test set avg_accuracy=88.63% avg_sensitivity=73.43%, avg_specificity=93.82% avg_auc=92.87%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.130634 Test loss=0.286724 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13971982896327972
[5/24] Train loss=0.12256842851638794
[10/24] Train loss=0.12390231341123581
[15/24] Train loss=0.12266577780246735
[20/24] Train loss=0.12734349071979523
Test set avg_accuracy=88.76% avg_sensitivity=69.74%, avg_specificity=95.25% avg_auc=92.61%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.130270 Test loss=0.287573 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.14000150561332703
[5/24] Train loss=0.12086637318134308
[10/24] Train loss=0.12270063161849976
[15/24] Train loss=0.12298880517482758
[20/24] Train loss=0.12497241050004959
Test set avg_accuracy=88.98% avg_sensitivity=72.30%, avg_specificity=94.67% avg_auc=93.03%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.129651 Test loss=0.283204 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.14153070747852325
[5/24] Train loss=0.1222940981388092
[10/24] Train loss=0.12373474985361099
[15/24] Train loss=0.12225733697414398
[20/24] Train loss=0.12711986899375916
Test set avg_accuracy=88.96% avg_sensitivity=73.37%, avg_specificity=94.27% avg_auc=93.12%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.129661 Test loss=0.283923 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1399662047624588
[5/24] Train loss=0.12259504944086075
[10/24] Train loss=0.12240877747535706
[15/24] Train loss=0.12183532118797302
[20/24] Train loss=0.12190058082342148
Test set avg_accuracy=89.04% avg_sensitivity=72.71%, avg_specificity=94.60% avg_auc=92.93%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.128937 Test loss=0.283209 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13513024151325226
[5/24] Train loss=0.12079779803752899
[10/24] Train loss=0.12098085880279541
[15/24] Train loss=0.12375310063362122
[20/24] Train loss=0.12454774230718613
Test set avg_accuracy=88.87% avg_sensitivity=75.68%, avg_specificity=93.36% avg_auc=93.20%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.128699 Test loss=0.281961 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.14109961688518524
[5/24] Train loss=0.12279786169528961
[10/24] Train loss=0.11966945230960846
[15/24] Train loss=0.12011614441871643
[20/24] Train loss=0.125566303730011
Test set avg_accuracy=88.48% avg_sensitivity=78.49%, avg_specificity=91.88% avg_auc=92.91%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.128492 Test loss=0.292137 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13653898239135742
[5/24] Train loss=0.11974237114191055
[10/24] Train loss=0.11827012151479721
[15/24] Train loss=0.12236277014017105
[20/24] Train loss=0.12354505062103271
Test set avg_accuracy=88.67% avg_sensitivity=76.04%, avg_specificity=92.98% avg_auc=92.94%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.127713 Test loss=0.285015 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13585755228996277
[5/24] Train loss=0.12475170195102692
[10/24] Train loss=0.1205887570977211
[15/24] Train loss=0.12283964455127716
[20/24] Train loss=0.12152550369501114
Test set avg_accuracy=88.89% avg_sensitivity=77.62%, avg_specificity=92.74% avg_auc=93.34%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.127019 Test loss=0.283799 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13929696381092072
[5/24] Train loss=0.11941219121217728
[10/24] Train loss=0.1188766360282898
[15/24] Train loss=0.11830643564462662
[20/24] Train loss=0.12486361712217331
Test set avg_accuracy=88.95% avg_sensitivity=75.63%, avg_specificity=93.49% avg_auc=92.93%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.126361 Test loss=0.284544 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13513581454753876
[5/24] Train loss=0.12027217447757721
[10/24] Train loss=0.12064818292856216
[15/24] Train loss=0.11833816021680832
[20/24] Train loss=0.12189928442239761
Test set avg_accuracy=88.74% avg_sensitivity=75.83%, avg_specificity=93.14% avg_auc=92.83%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.125797 Test loss=0.288156 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13456425070762634
[5/24] Train loss=0.12099909037351608
[10/24] Train loss=0.11780817061662674
[15/24] Train loss=0.1185046061873436
[20/24] Train loss=0.12095553427934647
Test set avg_accuracy=88.83% avg_sensitivity=76.70%, avg_specificity=92.96% avg_auc=92.96%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.125683 Test loss=0.288942 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.13507160544395447
[5/24] Train loss=0.11900115758180618
[10/24] Train loss=0.11924518644809723
[15/24] Train loss=0.11688899248838425
[20/24] Train loss=0.12238480150699615
Test set avg_accuracy=88.78% avg_sensitivity=76.65%, avg_specificity=92.91% avg_auc=93.12%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.124670 Test loss=0.285475 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1327308565378189
[5/24] Train loss=0.11820481717586517
[10/24] Train loss=0.11825686693191528
[15/24] Train loss=0.11920205503702164
[20/24] Train loss=0.11836902797222137
Test set avg_accuracy=88.62% avg_sensitivity=75.63%, avg_specificity=93.05% avg_auc=92.88%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.124158 Test loss=0.288313 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.13477757573127747
[5/24] Train loss=0.11805705726146698
[10/24] Train loss=0.11455785483121872
[15/24] Train loss=0.11298058182001114
[20/24] Train loss=0.12221895903348923
Test set avg_accuracy=88.74% avg_sensitivity=75.99%, avg_specificity=93.09% avg_auc=92.94%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.123437 Test loss=0.288042 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13334621489048004
[5/24] Train loss=0.11467982828617096
[10/24] Train loss=0.11673591285943985
[15/24] Train loss=0.11617106199264526
[20/24] Train loss=0.120354562997818
Test set avg_accuracy=88.46% avg_sensitivity=75.01%, avg_specificity=93.05% avg_auc=92.78%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.123343 Test loss=0.289269 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13255855441093445
[5/24] Train loss=0.11841147392988205
[10/24] Train loss=0.11845313012599945
[15/24] Train loss=0.1130046620965004
[20/24] Train loss=0.11940621584653854
Test set avg_accuracy=88.68% avg_sensitivity=75.27%, avg_specificity=93.26% avg_auc=92.83%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.122921 Test loss=0.287610 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.13595356047153473
[5/24] Train loss=0.11748422682285309
[10/24] Train loss=0.11725380271673203
[15/24] Train loss=0.11389923840761185
[20/24] Train loss=0.11916594207286835
Test set avg_accuracy=88.66% avg_sensitivity=75.01%, avg_specificity=93.31% avg_auc=92.82%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.122440 Test loss=0.287478 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13063524663448334
[5/24] Train loss=0.11692385375499725
[10/24] Train loss=0.12038090080022812
[15/24] Train loss=0.11258462816476822
[20/24] Train loss=0.11992089450359344
Test set avg_accuracy=88.53% avg_sensitivity=75.22%, avg_specificity=93.07% avg_auc=92.88%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.122534 Test loss=0.287935 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13360156118869781
[5/24] Train loss=0.11697985976934433
[10/24] Train loss=0.11734890937805176
[15/24] Train loss=0.11788278073072433
[20/24] Train loss=0.1190577894449234
Test set avg_accuracy=88.67% avg_sensitivity=75.52%, avg_specificity=93.16% avg_auc=92.90%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.122308 Test loss=0.287713 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13116386532783508
[5/24] Train loss=0.1161622405052185
[10/24] Train loss=0.117568239569664
[15/24] Train loss=0.11470430344343185
[20/24] Train loss=0.11861708015203476
Test set avg_accuracy=88.68% avg_sensitivity=75.52%, avg_specificity=93.17% avg_auc=92.93%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.121958 Test loss=0.287192 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13245588541030884
[5/24] Train loss=0.11597374826669693
[10/24] Train loss=0.11798249930143356
[15/24] Train loss=0.11382699757814407
[20/24] Train loss=0.1206318810582161
Test set avg_accuracy=88.66% avg_sensitivity=75.22%, avg_specificity=93.24% avg_auc=92.88%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.122261 Test loss=0.287718 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.13259437680244446
[5/24] Train loss=0.11628030240535736
[10/24] Train loss=0.116791270673275
[15/24] Train loss=0.11334486305713654
[20/24] Train loss=0.11881651729345322
Test set avg_accuracy=88.61% avg_sensitivity=75.63%, avg_specificity=93.03% avg_auc=92.92%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.122282 Test loss=0.287744 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.13110409677028656
[5/24] Train loss=0.11599913984537125
[10/24] Train loss=0.11683213710784912
[15/24] Train loss=0.11619548499584198
[20/24] Train loss=0.11895474046468735
Test set avg_accuracy=88.63% avg_sensitivity=75.63%, avg_specificity=93.07% avg_auc=92.93%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.122048 Test loss=0.287703 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13161158561706543
[5/24] Train loss=0.1155686303973198
[10/24] Train loss=0.11589393764734268
[15/24] Train loss=0.11526165902614594
[20/24] Train loss=0.11989559233188629
Test set avg_accuracy=88.67% avg_sensitivity=75.63%, avg_specificity=93.12% avg_auc=92.91%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.122087 Test loss=0.287665 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.13231909275054932
[5/24] Train loss=0.1158108189702034
[10/24] Train loss=0.11481446772813797
[15/24] Train loss=0.1170368567109108
[20/24] Train loss=0.12167053669691086
Test set avg_accuracy=88.68% avg_sensitivity=75.68%, avg_specificity=93.12% avg_auc=92.91%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.122329 Test loss=0.287581 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=88.57% sen=80.90%, spe=91.18%, auc=94.83%!
Fold[5] Avg_overlap=0.71%(0.21340589550152225)
[0/24] Train loss=0.7328906059265137
[5/24] Train loss=0.739238440990448
[10/24] Train loss=0.7215195298194885
[15/24] Train loss=0.7209128141403198
[20/24] Train loss=0.7051137685775757
Test set avg_accuracy=60.53% avg_sensitivity=44.58%, avg_specificity=66.48% avg_auc=57.04%
Best model saved!! Metric=-97.3751200938073!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.722948 Test loss=0.677533 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7015843987464905
[5/24] Train loss=0.6934729814529419
[10/24] Train loss=0.6959386467933655
[15/24] Train loss=0.6811425685882568
[20/24] Train loss=0.6702315211296082
Test set avg_accuracy=67.72% avg_sensitivity=55.90%, avg_specificity=72.12% avg_auc=70.47%
Best model saved!! Metric=-59.78361956697086!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.691721 Test loss=0.608002 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6614165306091309
[5/24] Train loss=0.6728973984718323
[10/24] Train loss=0.6715826988220215
[15/24] Train loss=0.643928050994873
[20/24] Train loss=0.6460663080215454
Test set avg_accuracy=71.76% avg_sensitivity=65.98%, avg_specificity=73.91% avg_auc=76.99%
Best model saved!! Metric=-37.36550940939783!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.662024 Test loss=0.572153 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6383047699928284
[5/24] Train loss=0.6475805044174194
[10/24] Train loss=0.6383524537086487
[15/24] Train loss=0.6246654391288757
[20/24] Train loss=0.6134202480316162
Test set avg_accuracy=74.05% avg_sensitivity=71.31%, avg_specificity=75.07% avg_auc=80.86%
Best model saved!! Metric=-24.710505686786362!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.635474 Test loss=0.542704 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6057496666908264
[5/24] Train loss=0.6092240214347839
[10/24] Train loss=0.6090277433395386
[15/24] Train loss=0.589783787727356
[20/24] Train loss=0.5868902802467346
Test set avg_accuracy=76.86% avg_sensitivity=73.46%, avg_specificity=78.13% avg_auc=83.34%
Best model saved!! Metric=-14.204762020828085!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.604415 Test loss=0.511674 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5720825791358948
[5/24] Train loss=0.5663394927978516
[10/24] Train loss=0.5832964181900024
[15/24] Train loss=0.5559676885604858
[20/24] Train loss=0.5460074543952942
Test set avg_accuracy=78.40% avg_sensitivity=74.09%, avg_specificity=80.00% avg_auc=85.51%
Best model saved!! Metric=-8.002714474470395!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.574282 Test loss=0.482444 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5476070642471313
[5/24] Train loss=0.5409286618232727
[10/24] Train loss=0.5516989827156067
[15/24] Train loss=0.5265601873397827
[20/24] Train loss=0.5203579068183899
Test set avg_accuracy=80.12% avg_sensitivity=74.42%, avg_specificity=82.24% avg_auc=87.19%
Best model saved!! Metric=-2.032011303916704!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.544088 Test loss=0.454936 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5161744356155396
[5/24] Train loss=0.5121182799339294
[10/24] Train loss=0.5259526968002319
[15/24] Train loss=0.4981856346130371
[20/24] Train loss=0.48118695616722107
Test set avg_accuracy=81.98% avg_sensitivity=74.57%, avg_specificity=84.74% avg_auc=88.75%
Best model saved!! Metric=4.040796237555654!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.513271 Test loss=0.427604 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.48097747564315796
[5/24] Train loss=0.4874824583530426
[10/24] Train loss=0.4910721778869629
[15/24] Train loss=0.47133690118789673
[20/24] Train loss=0.45489639043807983
Test set avg_accuracy=83.67% avg_sensitivity=76.78%, avg_specificity=86.24% avg_auc=89.89%
Best model saved!! Metric=10.57524613567547!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.483519 Test loss=0.408765 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4619416892528534
[5/24] Train loss=0.45742562413215637
[10/24] Train loss=0.4641529321670532
[15/24] Train loss=0.4392681419849396
[20/24] Train loss=0.4271063804626465
Test set avg_accuracy=84.80% avg_sensitivity=77.06%, avg_specificity=87.69% avg_auc=90.80%
Best model saved!! Metric=14.354940011047773!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.456951 Test loss=0.388532 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.441223680973053
[5/24] Train loss=0.4299813210964203
[10/24] Train loss=0.4403901696205139
[15/24] Train loss=0.41906657814979553
[20/24] Train loss=0.40390023589134216
Test set avg_accuracy=85.82% avg_sensitivity=76.25%, avg_specificity=89.39% avg_auc=91.48%
Best model saved!! Metric=16.93065763273124!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.431897 Test loss=0.368190 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4114094078540802
[5/24] Train loss=0.4049520790576935
[10/24] Train loss=0.41137492656707764
[15/24] Train loss=0.39204564690589905
[20/24] Train loss=0.3750019669532776
Test set avg_accuracy=86.59% avg_sensitivity=75.58%, avg_specificity=90.69% avg_auc=92.17%
Best model saved!! Metric=19.01983650435578!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.408631 Test loss=0.348069 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.38453465700149536
[5/24] Train loss=0.39032652974128723
[10/24] Train loss=0.3893182873725891
[15/24] Train loss=0.3754664957523346
[20/24] Train loss=0.35858604311943054
Test set avg_accuracy=87.24% avg_sensitivity=74.42%, avg_specificity=92.01% avg_auc=92.57%
Best model saved!! Metric=20.24099166036703!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.388698 Test loss=0.330599 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3640625774860382
[5/24] Train loss=0.3673888146877289
[10/24] Train loss=0.3745776116847992
[15/24] Train loss=0.3599238395690918
[20/24] Train loss=0.33863067626953125
Test set avg_accuracy=87.70% avg_sensitivity=77.16%, avg_specificity=91.62% avg_auc=92.98%
Best model saved!! Metric=23.45267809154538!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.370918 Test loss=0.322095 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3508297801017761
[5/24] Train loss=0.35143622756004333
[10/24] Train loss=0.35745030641555786
[15/24] Train loss=0.3468535244464874
[20/24] Train loss=0.3258802592754364
Test set avg_accuracy=88.11% avg_sensitivity=78.31%, avg_specificity=91.76% avg_auc=93.31%
Best model saved!! Metric=25.49686540978793!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.354698 Test loss=0.312110 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3403662145137787
[5/24] Train loss=0.33516913652420044
[10/24] Train loss=0.3401559293270111
[15/24] Train loss=0.3320431709289551
[20/24] Train loss=0.31052839756011963
Test set avg_accuracy=88.79% avg_sensitivity=77.78%, avg_specificity=92.89% avg_auc=93.52%
Best model saved!! Metric=26.982622062012354!!
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.340178 Test loss=0.300726 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.324799120426178
[5/24] Train loss=0.32746967673301697
[10/24] Train loss=0.3302704393863678
[15/24] Train loss=0.3192438781261444
[20/24] Train loss=0.2950303554534912
Test set avg_accuracy=88.95% avg_sensitivity=77.40%, avg_specificity=93.25% avg_auc=93.75%
Best model saved!! Metric=27.343587110737843!!
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.328826 Test loss=0.293511 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.31304627656936646
[5/24] Train loss=0.3154310882091522
[10/24] Train loss=0.3264763653278351
[15/24] Train loss=0.30440372228622437
[20/24] Train loss=0.28384342789649963
Test set avg_accuracy=88.91% avg_sensitivity=79.46%, avg_specificity=92.42% avg_auc=93.81%
Best model saved!! Metric=28.602112241881017!!
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.318589 Test loss=0.292541 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.30458706617355347
[5/24] Train loss=0.313063383102417
[10/24] Train loss=0.3155348002910614
[15/24] Train loss=0.3030693233013153
[20/24] Train loss=0.277018278837204
Test set avg_accuracy=89.40% avg_sensitivity=79.65%, avg_specificity=93.03% avg_auc=94.05%
Best model saved!! Metric=30.132110883916724!!
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.309683 Test loss=0.286727 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.29597538709640503
[5/24] Train loss=0.2955610454082489
[10/24] Train loss=0.30293145775794983
[15/24] Train loss=0.28958410024642944
[20/24] Train loss=0.26698029041290283
Test set avg_accuracy=89.23% avg_sensitivity=79.75%, avg_specificity=92.76% avg_auc=94.05%
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.300702 Test loss=0.284330 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.282139390707016
[5/24] Train loss=0.2907012403011322
[10/24] Train loss=0.29955941438674927
[15/24] Train loss=0.2888297736644745
[20/24] Train loss=0.2631779909133911
Test set avg_accuracy=89.43% avg_sensitivity=77.30%, avg_specificity=93.94% avg_auc=94.21%
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.292827 Test loss=0.275697 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2829245626926422
[5/24] Train loss=0.2822663187980652
[10/24] Train loss=0.29149219393730164
[15/24] Train loss=0.2792382836341858
[20/24] Train loss=0.25141891837120056
Test set avg_accuracy=89.74% avg_sensitivity=76.01%, avg_specificity=94.85% avg_auc=94.13%
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.284625 Test loss=0.269442 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.27240481972694397
[5/24] Train loss=0.27357855439186096
[10/24] Train loss=0.2864745557308197
[15/24] Train loss=0.2782512903213501
[20/24] Train loss=0.24339236319065094
Test set avg_accuracy=88.74% avg_sensitivity=68.19%, avg_specificity=96.39% avg_auc=93.66%
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.277826 Test loss=0.283964 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.26913002133369446
[5/24] Train loss=0.2716695964336395
[10/24] Train loss=0.2796430289745331
[15/24] Train loss=0.27073177695274353
[20/24] Train loss=0.2344868928194046
Test set avg_accuracy=88.74% avg_sensitivity=67.42%, avg_specificity=96.68% avg_auc=93.59%
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.273819 Test loss=0.282536 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.26228854060173035
[5/24] Train loss=0.272009938955307
[10/24] Train loss=0.27908530831336975
[15/24] Train loss=0.2650068998336792
[20/24] Train loss=0.2331676334142685
Test set avg_accuracy=89.92% avg_sensitivity=76.01%, avg_specificity=95.10% avg_auc=94.26%
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.268775 Test loss=0.264080 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.25418761372566223
[5/24] Train loss=0.26604777574539185
[10/24] Train loss=0.27837735414505005
[15/24] Train loss=0.25799018144607544
[20/24] Train loss=0.2254524528980255
Test set avg_accuracy=87.37% avg_sensitivity=60.08%, avg_specificity=97.53% avg_auc=92.82%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.262935 Test loss=0.310732 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.25416263937950134
[5/24] Train loss=0.25896281003952026
[10/24] Train loss=0.2666760981082916
[15/24] Train loss=0.2532246708869934
[20/24] Train loss=0.22142069041728973
Test set avg_accuracy=89.09% avg_sensitivity=69.43%, avg_specificity=96.41% avg_auc=93.87%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.259157 Test loss=0.276953 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.24191008508205414
[5/24] Train loss=0.25046756863594055
[10/24] Train loss=0.2591976523399353
[15/24] Train loss=0.246800035238266
[20/24] Train loss=0.22165118157863617
Test set avg_accuracy=89.21% avg_sensitivity=71.79%, avg_specificity=95.69% avg_auc=93.93%
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.251166 Test loss=0.271208 Current lr=[0.000210185142098938]

[0/24] Train loss=0.23317618668079376
[5/24] Train loss=0.23808996379375458
[10/24] Train loss=0.26122719049453735
[15/24] Train loss=0.25611618161201477
[20/24] Train loss=0.2175779938697815
Test set avg_accuracy=83.82% avg_sensitivity=43.47%, avg_specificity=98.84% avg_auc=91.07%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.246088 Test loss=0.384680 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.25205501914024353
[5/24] Train loss=0.23407626152038574
[10/24] Train loss=0.25668033957481384
[15/24] Train loss=0.2467479556798935
[20/24] Train loss=0.2092546820640564
Test set avg_accuracy=88.32% avg_sensitivity=64.59%, avg_specificity=97.16% avg_auc=92.79%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.241702 Test loss=0.298691 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.23817875981330872
[5/24] Train loss=0.24145439267158508
[10/24] Train loss=0.2554985582828522
[15/24] Train loss=0.24321211874485016
[20/24] Train loss=0.2119801938533783
Test set avg_accuracy=87.54% avg_sensitivity=60.89%, avg_specificity=97.46% avg_auc=92.85%
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.240158 Test loss=0.307846 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.23338527977466583
[5/24] Train loss=0.22642581164836884
[10/24] Train loss=0.24946382641792297
[15/24] Train loss=0.24116994440555573
[20/24] Train loss=0.20601290464401245
Test set avg_accuracy=87.19% avg_sensitivity=60.32%, avg_specificity=97.19% avg_auc=92.53%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.238617 Test loss=0.312153 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2281339019536972
[5/24] Train loss=0.21643629670143127
[10/24] Train loss=0.2553926408290863
[15/24] Train loss=0.241043820977211
[20/24] Train loss=0.20312131941318512
Test set avg_accuracy=88.23% avg_sensitivity=64.83%, avg_specificity=96.94% avg_auc=92.83%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.233685 Test loss=0.297216 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.21911747753620148
[5/24] Train loss=0.22367402911186218
[10/24] Train loss=0.24776123464107513
[15/24] Train loss=0.22732162475585938
[20/24] Train loss=0.21425184607505798
Test set avg_accuracy=84.31% avg_sensitivity=45.49%, avg_specificity=98.77% avg_auc=91.51%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.233816 Test loss=0.375091 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.23146872222423553
[5/24] Train loss=0.21826931834220886
[10/24] Train loss=0.23444660007953644
[15/24] Train loss=0.23039984703063965
[20/24] Train loss=0.20626774430274963
Test set avg_accuracy=87.83% avg_sensitivity=64.97%, avg_specificity=96.34% avg_auc=91.35%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.225154 Test loss=0.311217 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2148895114660263
[5/24] Train loss=0.20524071156978607
[10/24] Train loss=0.24048103392124176
[15/24] Train loss=0.22442756593227386
[20/24] Train loss=0.19635945558547974
Test set avg_accuracy=89.10% avg_sensitivity=68.33%, avg_specificity=96.84% avg_auc=93.56%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.223612 Test loss=0.281254 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.22744382917881012
[5/24] Train loss=0.19842098653316498
[10/24] Train loss=0.22912627458572388
[15/24] Train loss=0.2132667601108551
[20/24] Train loss=0.20027440786361694
Test set avg_accuracy=88.27% avg_sensitivity=65.55%, avg_specificity=96.73% avg_auc=93.21%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.220113 Test loss=0.292495 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.21233762800693512
[5/24] Train loss=0.2053527683019638
[10/24] Train loss=0.22656762599945068
[15/24] Train loss=0.2197958081960678
[20/24] Train loss=0.19381563365459442
Test set avg_accuracy=78.29% avg_sensitivity=21.16%, avg_specificity=99.57% avg_auc=81.18%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.216368 Test loss=0.585938 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.23544983565807343
[5/24] Train loss=0.1968027800321579
[10/24] Train loss=0.23453128337860107
[15/24] Train loss=0.22081802785396576
[20/24] Train loss=0.18553651869297028
Test set avg_accuracy=75.21% avg_sensitivity=9.50%, avg_specificity=99.68% avg_auc=79.22%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.218040 Test loss=0.686055 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.22656972706317902
[5/24] Train loss=0.20689702033996582
[10/24] Train loss=0.23778747022151947
[15/24] Train loss=0.20107972621917725
[20/24] Train loss=0.1862250119447708
Test set avg_accuracy=80.79% avg_sensitivity=32.58%, avg_specificity=98.75% avg_auc=87.09%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.216121 Test loss=0.502122 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.21311141550540924
[5/24] Train loss=0.19944685697555542
[10/24] Train loss=0.21235933899879456
[15/24] Train loss=0.2221207171678543
[20/24] Train loss=0.19370757043361664
Test set avg_accuracy=84.80% avg_sensitivity=86.42%, avg_specificity=84.20% avg_auc=92.79%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.217876 Test loss=0.345192 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2233521193265915
[5/24] Train loss=0.19311344623565674
[10/24] Train loss=0.2283027619123459
[15/24] Train loss=0.2207603007555008
[20/24] Train loss=0.192030668258667
Test set avg_accuracy=89.21% avg_sensitivity=70.63%, avg_specificity=96.12% avg_auc=93.41%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.214741 Test loss=0.280131 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.1997888684272766
[5/24] Train loss=0.20367009937763214
[10/24] Train loss=0.2286645621061325
[15/24] Train loss=0.21154238283634186
[20/24] Train loss=0.18250276148319244
Test set avg_accuracy=89.32% avg_sensitivity=74.57%, avg_specificity=94.82% avg_auc=92.98%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.209972 Test loss=0.278707 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.21262384951114655
[5/24] Train loss=0.19277890026569366
[10/24] Train loss=0.22028516232967377
[15/24] Train loss=0.21152809262275696
[20/24] Train loss=0.18608716130256653
Test set avg_accuracy=88.41% avg_sensitivity=68.62%, avg_specificity=95.78% avg_auc=92.80%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.208521 Test loss=0.294241 Current lr=[0.00029967723776099]

[0/24] Train loss=0.20281459391117096
[5/24] Train loss=0.1894358992576599
[10/24] Train loss=0.2300189733505249
[15/24] Train loss=0.21203528344631195
[20/24] Train loss=0.19709087908267975
Test set avg_accuracy=87.76% avg_sensitivity=65.60%, avg_specificity=96.02% avg_auc=92.25%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.211053 Test loss=0.308768 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.20973235368728638
[5/24] Train loss=0.1898569017648697
[10/24] Train loss=0.21406757831573486
[15/24] Train loss=0.2108427733182907
[20/24] Train loss=0.1852908879518509
Test set avg_accuracy=89.38% avg_sensitivity=74.57%, avg_specificity=94.89% avg_auc=93.15%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.204536 Test loss=0.275076 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.20560771226882935
[5/24] Train loss=0.19818148016929626
[10/24] Train loss=0.2199881225824356
[15/24] Train loss=0.19995224475860596
[20/24] Train loss=0.17516764998435974
Test set avg_accuracy=89.13% avg_sensitivity=73.94%, avg_specificity=94.78% avg_auc=93.15%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.203919 Test loss=0.277095 Current lr=[0.000299720220882401]

[0/24] Train loss=0.21048273146152496
[5/24] Train loss=0.18242397904396057
[10/24] Train loss=0.2133597731590271
[15/24] Train loss=0.20642942190170288
[20/24] Train loss=0.17490945756435394
Test set avg_accuracy=88.44% avg_sensitivity=72.74%, avg_specificity=94.28% avg_auc=93.22%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.203711 Test loss=0.282885 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.20718686282634735
[5/24] Train loss=0.19050002098083496
[10/24] Train loss=0.20304258167743683
[15/24] Train loss=0.19828788936138153
[20/24] Train loss=0.18134155869483948
Test set avg_accuracy=81.51% avg_sensitivity=35.36%, avg_specificity=98.70% avg_auc=85.78%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.200305 Test loss=0.490903 Current lr=[0.000298904600941902]

[0/24] Train loss=0.19875125586986542
[5/24] Train loss=0.17905999720096588
[10/24] Train loss=0.21845869719982147
[15/24] Train loss=0.20342010259628296
[20/24] Train loss=0.18817056715488434
Test set avg_accuracy=84.93% avg_sensitivity=51.20%, avg_specificity=97.50% avg_auc=89.22%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.201296 Test loss=0.390373 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.19671978056430817
[5/24] Train loss=0.1965913623571396
[10/24] Train loss=0.20515525341033936
[15/24] Train loss=0.19633832573890686
[20/24] Train loss=0.166555255651474
Test set avg_accuracy=89.44% avg_sensitivity=78.55%, avg_specificity=93.50% avg_auc=93.80%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.194435 Test loss=0.265881 Current lr=[0.000297555943323901]

[0/24] Train loss=0.19922900199890137
[5/24] Train loss=0.1797380894422531
[10/24] Train loss=0.20114581286907196
[15/24] Train loss=0.18431158363819122
[20/24] Train loss=0.17534735798835754
Test set avg_accuracy=88.11% avg_sensitivity=67.27%, avg_specificity=95.87% avg_auc=92.19%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.193686 Test loss=0.308713 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.19023409485816956
[5/24] Train loss=0.18692351877689362
[10/24] Train loss=0.2050049751996994
[15/24] Train loss=0.19590651988983154
[20/24] Train loss=0.1752053052186966
Test set avg_accuracy=81.38% avg_sensitivity=33.93%, avg_specificity=99.05% avg_auc=85.54%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.197921 Test loss=0.493940 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.21465355157852173
[5/24] Train loss=0.19602395594120026
[10/24] Train loss=0.20454663038253784
[15/24] Train loss=0.2048947513103485
[20/24] Train loss=0.17763711512088776
Test set avg_accuracy=86.20% avg_sensitivity=56.86%, avg_specificity=97.12% avg_auc=90.70%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.200008 Test loss=0.350728 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.17948849499225616
[5/24] Train loss=0.18975229561328888
[10/24] Train loss=0.2048420011997223
[15/24] Train loss=0.19265489280223846
[20/24] Train loss=0.17163750529289246
Test set avg_accuracy=88.98% avg_sensitivity=80.13%, avg_specificity=92.28% avg_auc=93.24%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.196383 Test loss=0.281692 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.18891948461532593
[5/24] Train loss=0.17408283054828644
[10/24] Train loss=0.19776421785354614
[15/24] Train loss=0.18557065725326538
[20/24] Train loss=0.17305409908294678
Test set avg_accuracy=88.61% avg_sensitivity=76.58%, avg_specificity=93.08% avg_auc=92.66%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.193218 Test loss=0.283565 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.19454075396060944
[5/24] Train loss=0.1851050853729248
[10/24] Train loss=0.21048413217067719
[15/24] Train loss=0.18126621842384338
[20/24] Train loss=0.16667300462722778
Test set avg_accuracy=87.62% avg_sensitivity=66.31%, avg_specificity=95.55% avg_auc=92.19%
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.193670 Test loss=0.308555 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.17586863040924072
[5/24] Train loss=0.1850186139345169
[10/24] Train loss=0.18365271389484406
[15/24] Train loss=0.18488486111164093
[20/24] Train loss=0.17556464672088623
Test set avg_accuracy=87.97% avg_sensitivity=65.40%, avg_specificity=96.37% avg_auc=92.00%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.187267 Test loss=0.307420 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.18707457184791565
[5/24] Train loss=0.17371970415115356
[10/24] Train loss=0.1990351527929306
[15/24] Train loss=0.19298055768013
[20/24] Train loss=0.17611578106880188
Test set avg_accuracy=89.57% avg_sensitivity=77.98%, avg_specificity=93.89% avg_auc=93.15%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.187490 Test loss=0.272865 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18697622418403625
[5/24] Train loss=0.1816311925649643
[10/24] Train loss=0.1935233473777771
[15/24] Train loss=0.1855975091457367
[20/24] Train loss=0.16384275257587433
Test set avg_accuracy=83.74% avg_sensitivity=85.17%, avg_specificity=83.20% avg_auc=91.91%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.185716 Test loss=0.367459 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.1876484900712967
[5/24] Train loss=0.1770375370979309
[10/24] Train loss=0.18335188925266266
[15/24] Train loss=0.18440894782543182
[20/24] Train loss=0.1686290204524994
Test set avg_accuracy=88.74% avg_sensitivity=80.85%, avg_specificity=91.67% avg_auc=93.51%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.185661 Test loss=0.280609 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.17622406780719757
[5/24] Train loss=0.16900290548801422
[10/24] Train loss=0.1934678852558136
[15/24] Train loss=0.17622773349285126
[20/24] Train loss=0.16643229126930237
Test set avg_accuracy=87.72% avg_sensitivity=82.53%, avg_specificity=89.65% avg_auc=92.72%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.182945 Test loss=0.306581 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.19163565337657928
[5/24] Train loss=0.17617356777191162
[10/24] Train loss=0.2014676183462143
[15/24] Train loss=0.19028107821941376
[20/24] Train loss=0.17480972409248352
Test set avg_accuracy=87.23% avg_sensitivity=81.38%, avg_specificity=89.40% avg_auc=92.76%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.187156 Test loss=0.304295 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.18012912571430206
[5/24] Train loss=0.18351680040359497
[10/24] Train loss=0.18973928689956665
[15/24] Train loss=0.1676616221666336
[20/24] Train loss=0.1760755032300949
Test set avg_accuracy=85.74% avg_sensitivity=85.12%, avg_specificity=85.97% avg_auc=92.68%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.183273 Test loss=0.336794 Current lr=[0.000276307469034998]

[0/24] Train loss=0.17548443377017975
[5/24] Train loss=0.18273387849330902
[10/24] Train loss=0.18728744983673096
[15/24] Train loss=0.19306613504886627
[20/24] Train loss=0.15665283799171448
Test set avg_accuracy=82.19% avg_sensitivity=85.89%, avg_specificity=80.81% avg_auc=91.20%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.181633 Test loss=0.398570 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.17741014063358307
[5/24] Train loss=0.1685585230588913
[10/24] Train loss=0.19175679981708527
[15/24] Train loss=0.1783728152513504
[20/24] Train loss=0.17210595309734344
Test set avg_accuracy=88.85% avg_sensitivity=73.56%, avg_specificity=94.55% avg_auc=92.72%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.180507 Test loss=0.286167 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.1749679148197174
[5/24] Train loss=0.1666496992111206
[10/24] Train loss=0.18251992762088776
[15/24] Train loss=0.18454982340335846
[20/24] Train loss=0.1659812033176422
Test set avg_accuracy=88.24% avg_sensitivity=80.33%, avg_specificity=91.19% avg_auc=92.80%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.179586 Test loss=0.299559 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.1788998693227768
[5/24] Train loss=0.16537754237651825
[10/24] Train loss=0.1768723577260971
[15/24] Train loss=0.1697746068239212
[20/24] Train loss=0.1709665060043335
Test set avg_accuracy=84.04% avg_sensitivity=86.76%, avg_specificity=83.02% avg_auc=92.19%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.177851 Test loss=0.370121 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.18283753097057343
[5/24] Train loss=0.16353577375411987
[10/24] Train loss=0.17618052661418915
[15/24] Train loss=0.1709284782409668
[20/24] Train loss=0.1639764904975891
Test set avg_accuracy=83.97% avg_sensitivity=83.21%, avg_specificity=84.26% avg_auc=91.37%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.176789 Test loss=0.368054 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.17907960712909698
[5/24] Train loss=0.16658347845077515
[10/24] Train loss=0.18019041419029236
[15/24] Train loss=0.17411284148693085
[20/24] Train loss=0.1568804830312729
Test set avg_accuracy=87.76% avg_sensitivity=84.84%, avg_specificity=88.85% avg_auc=93.42%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.176419 Test loss=0.299824 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.17831175029277802
[5/24] Train loss=0.1676991581916809
[10/24] Train loss=0.17223559319972992
[15/24] Train loss=0.16708345711231232
[20/24] Train loss=0.1644509732723236
Test set avg_accuracy=88.31% avg_sensitivity=81.67%, avg_specificity=90.78% avg_auc=92.70%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.178096 Test loss=0.297093 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.16948239505290985
[5/24] Train loss=0.17784962058067322
[10/24] Train loss=0.1714196801185608
[15/24] Train loss=0.175934836268425
[20/24] Train loss=0.15945403277873993
Test set avg_accuracy=88.12% avg_sensitivity=78.69%, avg_specificity=91.64% avg_auc=93.14%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.176995 Test loss=0.288272 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.17203471064567566
[5/24] Train loss=0.16996517777442932
[10/24] Train loss=0.17645420134067535
[15/24] Train loss=0.1688489019870758
[20/24] Train loss=0.1649705022573471
Test set avg_accuracy=89.26% avg_sensitivity=79.85%, avg_specificity=92.76% avg_auc=92.91%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.174182 Test loss=0.279423 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.17542290687561035
[5/24] Train loss=0.16495352983474731
[10/24] Train loss=0.16952826082706451
[15/24] Train loss=0.16643445193767548
[20/24] Train loss=0.16629546880722046
Test set avg_accuracy=88.98% avg_sensitivity=78.21%, avg_specificity=92.99% avg_auc=93.04%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.170627 Test loss=0.283536 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.16532056033611298
[5/24] Train loss=0.16634118556976318
[10/24] Train loss=0.17127463221549988
[15/24] Train loss=0.1720317006111145
[20/24] Train loss=0.15204721689224243
Test set avg_accuracy=89.11% avg_sensitivity=77.98%, avg_specificity=93.26% avg_auc=93.46%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.172228 Test loss=0.273647 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.17221006751060486
[5/24] Train loss=0.1586039811372757
[10/24] Train loss=0.17974339425563812
[15/24] Train loss=0.1674814671278
[20/24] Train loss=0.15636664628982544
Test set avg_accuracy=87.33% avg_sensitivity=68.67%, avg_specificity=94.28% avg_auc=91.41%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.171554 Test loss=0.315678 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.1656518429517746
[5/24] Train loss=0.1579248607158661
[10/24] Train loss=0.17192526161670685
[15/24] Train loss=0.1751209795475006
[20/24] Train loss=0.15544475615024567
Test set avg_accuracy=87.58% avg_sensitivity=64.92%, avg_specificity=96.02% avg_auc=90.70%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.168376 Test loss=0.322919 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.17636717855930328
[5/24] Train loss=0.15828578174114227
[10/24] Train loss=0.17404194176197052
[15/24] Train loss=0.16358168423175812
[20/24] Train loss=0.14881783723831177
Test set avg_accuracy=87.51% avg_sensitivity=68.33%, avg_specificity=94.66% avg_auc=91.26%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.166834 Test loss=0.315508 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.16701027750968933
[5/24] Train loss=0.15206223726272583
[10/24] Train loss=0.1733556091785431
[15/24] Train loss=0.1678614318370819
[20/24] Train loss=0.1571342796087265
Test set avg_accuracy=88.48% avg_sensitivity=79.46%, avg_specificity=91.83% avg_auc=92.92%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.169224 Test loss=0.289045 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17199309170246124
[5/24] Train loss=0.15331929922103882
[10/24] Train loss=0.16684703528881073
[15/24] Train loss=0.16572660207748413
[20/24] Train loss=0.15465007722377777
Test set avg_accuracy=85.70% avg_sensitivity=55.57%, avg_specificity=96.93% avg_auc=88.50%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.167629 Test loss=0.373015 Current lr=[0.000224838296036774]

[0/24] Train loss=0.1588316112756729
[5/24] Train loss=0.16356223821640015
[10/24] Train loss=0.1623288244009018
[15/24] Train loss=0.1685543805360794
[20/24] Train loss=0.15486600995063782
Test set avg_accuracy=86.34% avg_sensitivity=57.44%, avg_specificity=97.11% avg_auc=89.27%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.168825 Test loss=0.350417 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.16615159809589386
[5/24] Train loss=0.15546922385692596
[10/24] Train loss=0.16490134596824646
[15/24] Train loss=0.15862582623958588
[20/24] Train loss=0.1629439741373062
Test set avg_accuracy=87.86% avg_sensitivity=78.17%, avg_specificity=91.48% avg_auc=92.93%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.167372 Test loss=0.295398 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.16418594121932983
[5/24] Train loss=0.15956103801727295
[10/24] Train loss=0.16913239657878876
[15/24] Train loss=0.16034333407878876
[20/24] Train loss=0.15467502176761627
Test set avg_accuracy=88.40% avg_sensitivity=79.61%, avg_specificity=91.67% avg_auc=92.52%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.165807 Test loss=0.294923 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.16491854190826416
[5/24] Train loss=0.14910683035850525
[10/24] Train loss=0.16495339572429657
[15/24] Train loss=0.15994901955127716
[20/24] Train loss=0.15175004303455353
Test set avg_accuracy=88.20% avg_sensitivity=85.41%, avg_specificity=89.24% avg_auc=93.19%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.163572 Test loss=0.300381 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.1637059599161148
[5/24] Train loss=0.1572156548500061
[10/24] Train loss=0.16094787418842316
[15/24] Train loss=0.15495209395885468
[20/24] Train loss=0.14369311928749084
Test set avg_accuracy=88.72% avg_sensitivity=76.01%, avg_specificity=93.46% avg_auc=92.83%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.162095 Test loss=0.288422 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.15864591300487518
[5/24] Train loss=0.15450020134449005
[10/24] Train loss=0.16193142533302307
[15/24] Train loss=0.15016357600688934
[20/24] Train loss=0.14380529522895813
Test set avg_accuracy=85.14% avg_sensitivity=52.59%, avg_specificity=97.27% avg_auc=86.53%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.161442 Test loss=0.412676 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.16503186523914337
[5/24] Train loss=0.14443346858024597
[10/24] Train loss=0.15070277452468872
[15/24] Train loss=0.15399445593357086
[20/24] Train loss=0.15039940178394318
Test set avg_accuracy=88.11% avg_sensitivity=75.72%, avg_specificity=92.73% avg_auc=92.16%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.158526 Test loss=0.297430 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.15861551463603973
[5/24] Train loss=0.14828018844127655
[10/24] Train loss=0.1577121764421463
[15/24] Train loss=0.15286560356616974
[20/24] Train loss=0.14629040658473969
Test set avg_accuracy=88.96% avg_sensitivity=74.23%, avg_specificity=94.44% avg_auc=92.45%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.159607 Test loss=0.288119 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1575983166694641
[5/24] Train loss=0.14242075383663177
[10/24] Train loss=0.14296430349349976
[15/24] Train loss=0.14834921061992645
[20/24] Train loss=0.1415691375732422
Test set avg_accuracy=89.23% avg_sensitivity=79.99%, avg_specificity=92.67% avg_auc=93.07%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.154996 Test loss=0.279120 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.1514710634946823
[5/24] Train loss=0.15490086376667023
[10/24] Train loss=0.1597760021686554
[15/24] Train loss=0.1524604856967926
[20/24] Train loss=0.15615376830101013
Test set avg_accuracy=85.64% avg_sensitivity=86.32%, avg_specificity=85.38% avg_auc=92.05%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.157793 Test loss=0.351137 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.15815047919750214
[5/24] Train loss=0.15045589208602905
[10/24] Train loss=0.15776289999485016
[15/24] Train loss=0.1473274528980255
[20/24] Train loss=0.15920919179916382
Test set avg_accuracy=87.75% avg_sensitivity=84.36%, avg_specificity=89.01% avg_auc=93.44%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.160778 Test loss=0.298179 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.16094283759593964
[5/24] Train loss=0.15011921525001526
[10/24] Train loss=0.1508648693561554
[15/24] Train loss=0.16654838621616364
[20/24] Train loss=0.14927010238170624
Test set avg_accuracy=87.55% avg_sensitivity=63.48%, avg_specificity=96.52% avg_auc=91.35%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.160227 Test loss=0.331608 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.16286523640155792
[5/24] Train loss=0.1504870057106018
[10/24] Train loss=0.15912918746471405
[15/24] Train loss=0.15147244930267334
[20/24] Train loss=0.14584723114967346
Test set avg_accuracy=89.24% avg_sensitivity=74.33%, avg_specificity=94.80% avg_auc=93.00%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.160179 Test loss=0.282339 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15785549581050873
[5/24] Train loss=0.1446049064397812
[10/24] Train loss=0.1502297967672348
[15/24] Train loss=0.15033651888370514
[20/24] Train loss=0.14494794607162476
Test set avg_accuracy=86.52% avg_sensitivity=58.35%, avg_specificity=97.02% avg_auc=89.24%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.157538 Test loss=0.357827 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.15342137217521667
[5/24] Train loss=0.1575113832950592
[10/24] Train loss=0.15850703418254852
[15/24] Train loss=0.145987868309021
[20/24] Train loss=0.14149613678455353
Test set avg_accuracy=86.00% avg_sensitivity=59.31%, avg_specificity=95.94% avg_auc=89.44%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.157364 Test loss=0.364914 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.16085295379161835
[5/24] Train loss=0.15122124552726746
[10/24] Train loss=0.1449982225894928
[15/24] Train loss=0.15754380822181702
[20/24] Train loss=0.1397792249917984
Test set avg_accuracy=87.03% avg_sensitivity=62.43%, avg_specificity=96.19% avg_auc=90.52%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.156072 Test loss=0.346232 Current lr=[0.000156543481933168]

[0/24] Train loss=0.15301257371902466
[5/24] Train loss=0.14710423350334167
[10/24] Train loss=0.1540955752134323
[15/24] Train loss=0.1450369954109192
[20/24] Train loss=0.14186865091323853
Test set avg_accuracy=88.14% avg_sensitivity=71.07%, avg_specificity=94.50% avg_auc=92.20%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.155233 Test loss=0.306061 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.15500207245349884
[5/24] Train loss=0.14946748316287994
[10/24] Train loss=0.1452338844537735
[15/24] Train loss=0.1493261456489563
[20/24] Train loss=0.14159022271633148
Test set avg_accuracy=87.30% avg_sensitivity=66.75%, avg_specificity=94.96% avg_auc=90.74%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.153723 Test loss=0.324625 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15625689923763275
[5/24] Train loss=0.15675389766693115
[10/24] Train loss=0.143971249461174
[15/24] Train loss=0.15324820578098297
[20/24] Train loss=0.1444420963525772
Test set avg_accuracy=88.33% avg_sensitivity=83.01%, avg_specificity=90.31% avg_auc=93.20%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.154299 Test loss=0.294253 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15301787853240967
[5/24] Train loss=0.1476098746061325
[10/24] Train loss=0.14563316106796265
[15/24] Train loss=0.14714772999286652
[20/24] Train loss=0.14589226245880127
Test set avg_accuracy=87.86% avg_sensitivity=70.78%, avg_specificity=94.23% avg_auc=92.12%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.152756 Test loss=0.306717 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.16167180240154266
[5/24] Train loss=0.14717772603034973
[10/24] Train loss=0.14672696590423584
[15/24] Train loss=0.14997504651546478
[20/24] Train loss=0.1410493552684784
Test set avg_accuracy=88.55% avg_sensitivity=73.75%, avg_specificity=94.07% avg_auc=92.37%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.154173 Test loss=0.294543 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15928727388381958
[5/24] Train loss=0.1442749947309494
[10/24] Train loss=0.14368776977062225
[15/24] Train loss=0.15750065445899963
[20/24] Train loss=0.13756689429283142
Test set avg_accuracy=88.74% avg_sensitivity=71.02%, avg_specificity=95.34% avg_auc=92.26%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.153590 Test loss=0.294892 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15448503196239471
[5/24] Train loss=0.14711745083332062
[10/24] Train loss=0.14145654439926147
[15/24] Train loss=0.14224298298358917
[20/24] Train loss=0.1411653608083725
Test set avg_accuracy=89.21% avg_sensitivity=73.85%, avg_specificity=94.92% avg_auc=93.07%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.150019 Test loss=0.281804 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1539326161146164
[5/24] Train loss=0.14338091015815735
[10/24] Train loss=0.14388880133628845
[15/24] Train loss=0.15195856988430023
[20/24] Train loss=0.13700655102729797
Test set avg_accuracy=87.67% avg_sensitivity=63.29%, avg_specificity=96.75% avg_auc=90.73%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.151070 Test loss=0.331377 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15497399866580963
[5/24] Train loss=0.1438170224428177
[10/24] Train loss=0.15866750478744507
[15/24] Train loss=0.14498139917850494
[20/24] Train loss=0.13677436113357544
Test set avg_accuracy=88.62% avg_sensitivity=70.25%, avg_specificity=95.46% avg_auc=92.59%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.150967 Test loss=0.294228 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14846916496753693
[5/24] Train loss=0.14100214838981628
[10/24] Train loss=0.14349734783172607
[15/24] Train loss=0.13859765231609344
[20/24] Train loss=0.13644178211688995
Test set avg_accuracy=89.64% avg_sensitivity=78.36%, avg_specificity=93.83% avg_auc=93.40%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.148478 Test loss=0.272462 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15177257359027863
[5/24] Train loss=0.1450105458498001
[10/24] Train loss=0.1471884846687317
[15/24] Train loss=0.14503213763237
[20/24] Train loss=0.1355019062757492
Test set avg_accuracy=89.22% avg_sensitivity=74.23%, avg_specificity=94.80% avg_auc=92.84%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.148117 Test loss=0.285985 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1451803296804428
[5/24] Train loss=0.142076313495636
[10/24] Train loss=0.1384471356868744
[15/24] Train loss=0.13914833962917328
[20/24] Train loss=0.13658645749092102
Test set avg_accuracy=89.18% avg_sensitivity=71.98%, avg_specificity=95.59% avg_auc=92.81%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.147004 Test loss=0.290695 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1486586034297943
[5/24] Train loss=0.14005975425243378
[10/24] Train loss=0.14391128718852997
[15/24] Train loss=0.13801705837249756
[20/24] Train loss=0.1323598176240921
Test set avg_accuracy=89.48% avg_sensitivity=73.94%, avg_specificity=95.26% avg_auc=93.34%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.146657 Test loss=0.280037 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1464007943868637
[5/24] Train loss=0.13773122429847717
[10/24] Train loss=0.1365898996591568
[15/24] Train loss=0.14186906814575195
[20/24] Train loss=0.13385894894599915
Test set avg_accuracy=88.88% avg_sensitivity=74.14%, avg_specificity=94.37% avg_auc=93.17%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.147496 Test loss=0.290367 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.1452183574438095
[5/24] Train loss=0.14794878661632538
[10/24] Train loss=0.1429097056388855
[15/24] Train loss=0.1394370198249817
[20/24] Train loss=0.1329113245010376
Test set avg_accuracy=89.45% avg_sensitivity=78.69%, avg_specificity=93.46% avg_auc=93.05%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.148792 Test loss=0.280489 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.14972764253616333
[5/24] Train loss=0.14318734407424927
[10/24] Train loss=0.13834959268569946
[15/24] Train loss=0.13897573947906494
[20/24] Train loss=0.13708806037902832
Test set avg_accuracy=89.71% avg_sensitivity=78.89%, avg_specificity=93.75% avg_auc=93.40%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.145981 Test loss=0.273908 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14806751906871796
[5/24] Train loss=0.1378745585680008
[10/24] Train loss=0.1326964795589447
[15/24] Train loss=0.13985630869865417
[20/24] Train loss=0.12579327821731567
Test set avg_accuracy=89.34% avg_sensitivity=79.46%, avg_specificity=93.01% avg_auc=92.88%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.144578 Test loss=0.281441 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14431601762771606
[5/24] Train loss=0.13194629549980164
[10/24] Train loss=0.1492612212896347
[15/24] Train loss=0.13421858847141266
[20/24] Train loss=0.12896272540092468
Test set avg_accuracy=89.22% avg_sensitivity=79.03%, avg_specificity=93.01% avg_auc=92.53%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.142939 Test loss=0.291492 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14212645590305328
[5/24] Train loss=0.1366918385028839
[10/24] Train loss=0.13518674671649933
[15/24] Train loss=0.13928595185279846
[20/24] Train loss=0.13222284615039825
Test set avg_accuracy=89.06% avg_sensitivity=77.69%, avg_specificity=93.30% avg_auc=92.56%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.142745 Test loss=0.286316 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14280402660369873
[5/24] Train loss=0.13014091551303864
[10/24] Train loss=0.13507364690303802
[15/24] Train loss=0.13539238274097443
[20/24] Train loss=0.12626180052757263
Test set avg_accuracy=89.57% avg_sensitivity=77.26%, avg_specificity=94.16% avg_auc=92.64%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.139832 Test loss=0.282256 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1402798295021057
[5/24] Train loss=0.12972860038280487
[10/24] Train loss=0.130327969789505
[15/24] Train loss=0.13018950819969177
[20/24] Train loss=0.12448794394731522
Test set avg_accuracy=89.52% avg_sensitivity=76.39%, avg_specificity=94.41% avg_auc=92.68%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.135917 Test loss=0.283173 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.13472604751586914
[5/24] Train loss=0.13146968185901642
[10/24] Train loss=0.12783293426036835
[15/24] Train loss=0.12949612736701965
[20/24] Train loss=0.12485621869564056
Test set avg_accuracy=88.92% avg_sensitivity=81.57%, avg_specificity=91.65% avg_auc=93.11%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.134886 Test loss=0.284267 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13551242649555206
[5/24] Train loss=0.12818606197834015
[10/24] Train loss=0.1304137259721756
[15/24] Train loss=0.12716762721538544
[20/24] Train loss=0.13024397194385529
Test set avg_accuracy=89.39% avg_sensitivity=80.85%, avg_specificity=92.57% avg_auc=92.80%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.134395 Test loss=0.279524 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13849814236164093
[5/24] Train loss=0.12611542642116547
[10/24] Train loss=0.12807616591453552
[15/24] Train loss=0.12716439366340637
[20/24] Train loss=0.1237298995256424
Test set avg_accuracy=89.99% avg_sensitivity=79.80%, avg_specificity=93.78% avg_auc=92.96%
Best model saved!! Metric=30.530131390835578!!
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.132894 Test loss=0.276435 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13680443167686462
[5/24] Train loss=0.12683050334453583
[10/24] Train loss=0.12592804431915283
[15/24] Train loss=0.1280987709760666
[20/24] Train loss=0.12444160878658295
Test set avg_accuracy=89.22% avg_sensitivity=81.86%, avg_specificity=91.96% avg_auc=92.86%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.131899 Test loss=0.283625 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1320512443780899
[5/24] Train loss=0.12449190765619278
[10/24] Train loss=0.12421852350234985
[15/24] Train loss=0.12483160197734833
[20/24] Train loss=0.12428061664104462
Test set avg_accuracy=89.60% avg_sensitivity=79.03%, avg_specificity=93.53% avg_auc=92.87%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.131277 Test loss=0.278385 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13147902488708496
[5/24] Train loss=0.12477497011423111
[10/24] Train loss=0.12239187955856323
[15/24] Train loss=0.12271695584058762
[20/24] Train loss=0.1215021163225174
Test set avg_accuracy=89.49% avg_sensitivity=79.61%, avg_specificity=93.17% avg_auc=92.69%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.129825 Test loss=0.281000 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12889215350151062
[5/24] Train loss=0.1264449805021286
[10/24] Train loss=0.12397301942110062
[15/24] Train loss=0.12211614102125168
[20/24] Train loss=0.12146006524562836
Test set avg_accuracy=89.58% avg_sensitivity=80.13%, avg_specificity=93.10% avg_auc=92.88%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.129086 Test loss=0.279453 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13018128275871277
[5/24] Train loss=0.12471935898065567
[10/24] Train loss=0.12534014880657196
[15/24] Train loss=0.12408945709466934
[20/24] Train loss=0.1210949495434761
Test set avg_accuracy=88.80% avg_sensitivity=81.72%, avg_specificity=91.44% avg_auc=92.67%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.128405 Test loss=0.288246 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12933482229709625
[5/24] Train loss=0.12315291166305542
[10/24] Train loss=0.12352024763822556
[15/24] Train loss=0.12421776354312897
[20/24] Train loss=0.12114913016557693
Test set avg_accuracy=89.49% avg_sensitivity=78.41%, avg_specificity=93.62% avg_auc=92.90%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.128536 Test loss=0.279999 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1307559758424759
[5/24] Train loss=0.12192433327436447
[10/24] Train loss=0.12203137576580048
[15/24] Train loss=0.12331940978765488
[20/24] Train loss=0.12212061882019043
Test set avg_accuracy=89.65% avg_sensitivity=79.61%, avg_specificity=93.39% avg_auc=92.93%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.127532 Test loss=0.278301 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12790431082248688
[5/24] Train loss=0.12362433224916458
[10/24] Train loss=0.1207890585064888
[15/24] Train loss=0.12452774494886398
[20/24] Train loss=0.12113196402788162
Test set avg_accuracy=89.35% avg_sensitivity=77.74%, avg_specificity=93.67% avg_auc=92.59%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.127095 Test loss=0.284166 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1317077875137329
[5/24] Train loss=0.1230720728635788
[10/24] Train loss=0.12130703777074814
[15/24] Train loss=0.12161039561033249
[20/24] Train loss=0.12013445049524307
Test set avg_accuracy=89.73% avg_sensitivity=81.24%, avg_specificity=92.89% avg_auc=93.06%
Best model saved!! Metric=30.913520143175333!!
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.126925 Test loss=0.277168 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12768112123012543
[5/24] Train loss=0.12171591818332672
[10/24] Train loss=0.12043532729148865
[15/24] Train loss=0.12382669001817703
[20/24] Train loss=0.12028442323207855
Test set avg_accuracy=89.54% avg_sensitivity=80.33%, avg_specificity=92.98% avg_auc=92.81%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.126078 Test loss=0.280316 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12511590123176575
[5/24] Train loss=0.12227413803339005
[10/24] Train loss=0.11919032782316208
[15/24] Train loss=0.12125303596258163
[20/24] Train loss=0.11814717203378677
Test set avg_accuracy=89.39% avg_sensitivity=81.00%, avg_specificity=92.51% avg_auc=93.03%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.125801 Test loss=0.277258 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12575259804725647
[5/24] Train loss=0.12177927047014236
[10/24] Train loss=0.11913034319877625
[15/24] Train loss=0.11980700492858887
[20/24] Train loss=0.11916649341583252
Test set avg_accuracy=89.67% avg_sensitivity=79.13%, avg_specificity=93.60% avg_auc=92.71%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.125313 Test loss=0.279793 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12825526297092438
[5/24] Train loss=0.12525390088558197
[10/24] Train loss=0.12032336741685867
[15/24] Train loss=0.12168226391077042
[20/24] Train loss=0.12020952999591827
Test set avg_accuracy=89.74% avg_sensitivity=78.84%, avg_specificity=93.80% avg_auc=92.82%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.126231 Test loss=0.278388 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12196672707796097
[5/24] Train loss=0.1205800250172615
[10/24] Train loss=0.12098219245672226
[15/24] Train loss=0.12163095921278
[20/24] Train loss=0.11830134689807892
Test set avg_accuracy=89.62% avg_sensitivity=77.59%, avg_specificity=94.10% avg_auc=93.00%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.125715 Test loss=0.276614 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12349724024534225
[5/24] Train loss=0.12008152902126312
[10/24] Train loss=0.12086249887943268
[15/24] Train loss=0.11940908432006836
[20/24] Train loss=0.1168505921959877
Test set avg_accuracy=89.82% avg_sensitivity=79.85%, avg_specificity=93.53% avg_auc=92.93%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.124592 Test loss=0.276860 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12496468424797058
[5/24] Train loss=0.12127197533845901
[10/24] Train loss=0.1187674030661583
[15/24] Train loss=0.11953440308570862
[20/24] Train loss=0.11640529334545135
Test set avg_accuracy=89.56% avg_sensitivity=79.51%, avg_specificity=93.30% avg_auc=92.77%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.123779 Test loss=0.279312 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12640857696533203
[5/24] Train loss=0.11905093491077423
[10/24] Train loss=0.11811041831970215
[15/24] Train loss=0.1172320619225502
[20/24] Train loss=0.11789440363645554
Test set avg_accuracy=89.62% avg_sensitivity=79.27%, avg_specificity=93.48% avg_auc=93.07%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.123026 Test loss=0.276628 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1226557269692421
[5/24] Train loss=0.12102329730987549
[10/24] Train loss=0.11619330197572708
[15/24] Train loss=0.11833131313323975
[20/24] Train loss=0.1148926317691803
Test set avg_accuracy=89.64% avg_sensitivity=78.84%, avg_specificity=93.66% avg_auc=92.83%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.122319 Test loss=0.277273 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12342916429042816
[5/24] Train loss=0.11979837715625763
[10/24] Train loss=0.11874860525131226
[15/24] Train loss=0.11436832696199417
[20/24] Train loss=0.11645297706127167
Test set avg_accuracy=89.66% avg_sensitivity=77.54%, avg_specificity=94.17% avg_auc=92.92%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.122237 Test loss=0.276524 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12147366255521774
[5/24] Train loss=0.12082505226135254
[10/24] Train loss=0.11600901931524277
[15/24] Train loss=0.11652301996946335
[20/24] Train loss=0.11476612091064453
Test set avg_accuracy=89.80% avg_sensitivity=79.22%, avg_specificity=93.75% avg_auc=92.76%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.121529 Test loss=0.278269 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12089429050683975
[5/24] Train loss=0.11938335001468658
[10/24] Train loss=0.11740468442440033
[15/24] Train loss=0.11497394740581512
[20/24] Train loss=0.1148328185081482
Test set avg_accuracy=89.60% avg_sensitivity=77.78%, avg_specificity=94.00% avg_auc=92.87%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.121437 Test loss=0.277040 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12342514097690582
[5/24] Train loss=0.1202639788389206
[10/24] Train loss=0.11692976206541061
[15/24] Train loss=0.11478879302740097
[20/24] Train loss=0.11589017510414124
Test set avg_accuracy=89.79% avg_sensitivity=79.27%, avg_specificity=93.71% avg_auc=92.82%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.121348 Test loss=0.277233 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12221989780664444
[5/24] Train loss=0.11791087687015533
[10/24] Train loss=0.11621548980474472
[15/24] Train loss=0.11753804981708527
[20/24] Train loss=0.11913137882947922
Test set avg_accuracy=89.71% avg_sensitivity=78.50%, avg_specificity=93.89% avg_auc=92.81%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.120764 Test loss=0.277668 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12217698246240616
[5/24] Train loss=0.11661829799413681
[10/24] Train loss=0.11454332619905472
[15/24] Train loss=0.11538288742303848
[20/24] Train loss=0.11509159952402115
Test set avg_accuracy=89.86% avg_sensitivity=79.27%, avg_specificity=93.80% avg_auc=92.88%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.120636 Test loss=0.276177 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12075511366128922
[5/24] Train loss=0.11798185855150223
[10/24] Train loss=0.11519932746887207
[15/24] Train loss=0.11649955809116364
[20/24] Train loss=0.1145908385515213
Test set avg_accuracy=89.87% avg_sensitivity=78.93%, avg_specificity=93.94% avg_auc=92.91%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.120569 Test loss=0.275815 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12111405283212662
[5/24] Train loss=0.11809428036212921
[10/24] Train loss=0.11565051227807999
[15/24] Train loss=0.11628909409046173
[20/24] Train loss=0.11339984089136124
Test set avg_accuracy=89.74% avg_sensitivity=78.41%, avg_specificity=93.96% avg_auc=92.89%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.120790 Test loss=0.276196 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11822973191738129
[5/24] Train loss=0.11807360500097275
[10/24] Train loss=0.11503295600414276
[15/24] Train loss=0.11424260586500168
[20/24] Train loss=0.11545894294977188
Test set avg_accuracy=89.71% avg_sensitivity=78.55%, avg_specificity=93.87% avg_auc=92.88%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.120492 Test loss=0.276286 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12100577354431152
[5/24] Train loss=0.11847097426652908
[10/24] Train loss=0.1163022369146347
[15/24] Train loss=0.11476697027683258
[20/24] Train loss=0.11684441566467285
Test set avg_accuracy=89.73% avg_sensitivity=78.74%, avg_specificity=93.82% avg_auc=92.88%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.120480 Test loss=0.276174 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12164650857448578
[5/24] Train loss=0.11657200753688812
[10/24] Train loss=0.11483588814735413
[15/24] Train loss=0.11399901658296585
[20/24] Train loss=0.11631859093904495
Test set avg_accuracy=89.74% avg_sensitivity=78.55%, avg_specificity=93.91% avg_auc=92.86%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.120304 Test loss=0.276493 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1212441697716713
[5/24] Train loss=0.11722579598426819
[10/24] Train loss=0.11498292535543442
[15/24] Train loss=0.11520939320325851
[20/24] Train loss=0.11585953831672668
Test set avg_accuracy=89.70% avg_sensitivity=78.60%, avg_specificity=93.83% avg_auc=92.87%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.119890 Test loss=0.276246 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=89.73% sen=81.24%, spe=92.89%, auc=93.06%!
Fold[6] Avg_overlap=0.73%(0.23167142617967726)
[0/24] Train loss=0.730572521686554
[5/24] Train loss=0.7226088643074036
[10/24] Train loss=0.7173227071762085
[15/24] Train loss=0.7039325833320618
[20/24] Train loss=0.698053777217865
Test set avg_accuracy=57.10% avg_sensitivity=46.49%, avg_specificity=61.14% avg_auc=56.13%
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.715719 Test loss=0.674498 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7054078578948975
[5/24] Train loss=0.694130539894104
[10/24] Train loss=0.6899006366729736
[15/24] Train loss=0.6773169040679932
[20/24] Train loss=0.6697681546211243
Test set avg_accuracy=65.40% avg_sensitivity=58.18%, avg_specificity=68.16% avg_auc=68.82%
Best model saved!! Metric=-65.44045125080265!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.687817 Test loss=0.623326 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6662805676460266
[5/24] Train loss=0.6663298606872559
[10/24] Train loss=0.6663498282432556
[15/24] Train loss=0.6499090194702148
[20/24] Train loss=0.6410657167434692
Test set avg_accuracy=68.75% avg_sensitivity=65.25%, avg_specificity=70.08% avg_auc=75.21%
Best model saved!! Metric=-46.708107401982204!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.660861 Test loss=0.590515 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6489638090133667
[5/24] Train loss=0.6390260457992554
[10/24] Train loss=0.6376606225967407
[15/24] Train loss=0.6227748990058899
[20/24] Train loss=0.6105513572692871
Test set avg_accuracy=72.02% avg_sensitivity=69.45%, avg_specificity=73.00% avg_auc=78.89%
Best model saved!! Metric=-32.64083248385117!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.634351 Test loss=0.560237 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6144453287124634
[5/24] Train loss=0.6171967387199402
[10/24] Train loss=0.6166753172874451
[15/24] Train loss=0.592628002166748
[20/24] Train loss=0.5847366452217102
Test set avg_accuracy=75.18% avg_sensitivity=72.42%, avg_specificity=76.24% avg_auc=81.56%
Best model saved!! Metric=-20.605970021270664!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.607156 Test loss=0.530966 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5851888060569763
[5/24] Train loss=0.5821348428726196
[10/24] Train loss=0.593651294708252
[15/24] Train loss=0.5557121634483337
[20/24] Train loss=0.5483291745185852
Test set avg_accuracy=77.73% avg_sensitivity=74.54%, avg_specificity=78.95% avg_auc=83.88%
Best model saved!! Metric=-10.893133992515175!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.578317 Test loss=0.502200 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5505245327949524
[5/24] Train loss=0.5496937036514282
[10/24] Train loss=0.5599024891853333
[15/24] Train loss=0.5278779864311218
[20/24] Train loss=0.5153036117553711
Test set avg_accuracy=79.77% avg_sensitivity=75.86%, avg_specificity=81.26% avg_auc=86.14%
Best model saved!! Metric=-2.9746203760139593!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.549416 Test loss=0.470304 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5242167115211487
[5/24] Train loss=0.5209144949913025
[10/24] Train loss=0.5332436561584473
[15/24] Train loss=0.49913543462753296
[20/24] Train loss=0.4882855713367462
Test set avg_accuracy=81.25% avg_sensitivity=77.27%, avg_specificity=82.77% avg_auc=88.14%
Best model saved!! Metric=3.432028132656754!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.519601 Test loss=0.441466 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.4971711039543152
[5/24] Train loss=0.4886988699436188
[10/24] Train loss=0.5011653304100037
[15/24] Train loss=0.4653607904911041
[20/24] Train loss=0.4570353925228119
Test set avg_accuracy=83.15% avg_sensitivity=76.66%, avg_specificity=85.63% avg_auc=89.74%
Best model saved!! Metric=9.177551849872188!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.490311 Test loss=0.410447 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4708101451396942
[5/24] Train loss=0.4566216468811035
[10/24] Train loss=0.46957680583000183
[15/24] Train loss=0.4387248456478119
[20/24] Train loss=0.4258745014667511
Test set avg_accuracy=84.82% avg_sensitivity=76.28%, avg_specificity=88.07% avg_auc=91.08%
Best model saved!! Metric=14.260199618156832!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.460787 Test loss=0.385069 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.43809255957603455
[5/24] Train loss=0.4286203384399414
[10/24] Train loss=0.4432389736175537
[15/24] Train loss=0.41139253973960876
[20/24] Train loss=0.39454659819602966
Test set avg_accuracy=86.07% avg_sensitivity=76.71%, avg_specificity=89.64% avg_auc=92.00%
Best model saved!! Metric=18.412773431162222!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.432958 Test loss=0.365291 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4117686152458191
[5/24] Train loss=0.3989814221858978
[10/24] Train loss=0.41409727931022644
[15/24] Train loss=0.38589850068092346
[20/24] Train loss=0.3689647912979126
Test set avg_accuracy=86.78% avg_sensitivity=73.03%, avg_specificity=92.03% avg_auc=92.41%
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.406995 Test loss=0.343831 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3904072642326355
[5/24] Train loss=0.3737355172634125
[10/24] Train loss=0.39513495564460754
[15/24] Train loss=0.3624171316623688
[20/24] Train loss=0.3493354916572571
Test set avg_accuracy=87.33% avg_sensitivity=70.86%, avg_specificity=93.61% avg_auc=92.78%
Best model saved!! Metric=18.583164764092743!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.385122 Test loss=0.330723 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3711797297000885
[5/24] Train loss=0.3496677577495575
[10/24] Train loss=0.37961867451667786
[15/24] Train loss=0.34940868616104126
[20/24] Train loss=0.33124879002571106
Test set avg_accuracy=87.59% avg_sensitivity=70.39%, avg_specificity=94.15% avg_auc=93.27%
Best model saved!! Metric=19.40405995953124!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.366507 Test loss=0.318464 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.35477957129478455
[5/24] Train loss=0.34046486020088196
[10/24] Train loss=0.365508109331131
[15/24] Train loss=0.3337302803993225
[20/24] Train loss=0.3223523497581482
Test set avg_accuracy=88.26% avg_sensitivity=73.03%, avg_specificity=94.06% avg_auc=93.86%
Best model saved!! Metric=23.21294777391836!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.351324 Test loss=0.304981 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.33243829011917114
[5/24] Train loss=0.3199184536933899
[10/24] Train loss=0.3541955351829529
[15/24] Train loss=0.3195851445198059
[20/24] Train loss=0.30697697401046753
Test set avg_accuracy=88.10% avg_sensitivity=70.82%, avg_specificity=94.69% avg_auc=94.06%
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.336527 Test loss=0.300551 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3247508406639099
[5/24] Train loss=0.3065619170665741
[10/24] Train loss=0.3330734968185425
[15/24] Train loss=0.30706143379211426
[20/24] Train loss=0.29009947180747986
Test set avg_accuracy=88.46% avg_sensitivity=71.05%, avg_specificity=95.11% avg_auc=94.33%
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.325244 Test loss=0.290649 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.30942103266716003
[5/24] Train loss=0.2929933965206146
[10/24] Train loss=0.33436691761016846
[15/24] Train loss=0.302613765001297
[20/24] Train loss=0.2837609350681305
Test set avg_accuracy=89.11% avg_sensitivity=77.89%, avg_specificity=93.40% avg_auc=94.76%
Best model saved!! Metric=29.158069186814203!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.315254 Test loss=0.284659 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.30537205934524536
[5/24] Train loss=0.28660380840301514
[10/24] Train loss=0.31704896688461304
[15/24] Train loss=0.2929098904132843
[20/24] Train loss=0.27481403946876526
Test set avg_accuracy=89.04% avg_sensitivity=73.31%, avg_specificity=95.04% avg_auc=94.84%
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.307051 Test loss=0.278547 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.29503971338272095
[5/24] Train loss=0.2717260420322418
[10/24] Train loss=0.3195798993110657
[15/24] Train loss=0.2810947000980377
[20/24] Train loss=0.26954174041748047
Test set avg_accuracy=88.65% avg_sensitivity=71.57%, avg_specificity=95.16% avg_auc=94.59%
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.296593 Test loss=0.279167 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.28906217217445374
[5/24] Train loss=0.27108848094940186
[10/24] Train loss=0.30297189950942993
[15/24] Train loss=0.27911245822906494
[20/24] Train loss=0.2557591199874878
Test set avg_accuracy=89.23% avg_sensitivity=75.58%, avg_specificity=94.44% avg_auc=94.99%
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.291386 Test loss=0.272191 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2834858000278473
[5/24] Train loss=0.2612343430519104
[10/24] Train loss=0.30267253518104553
[15/24] Train loss=0.27217650413513184
[20/24] Train loss=0.2537223696708679
Test set avg_accuracy=89.39% avg_sensitivity=75.67%, avg_specificity=94.62% avg_auc=95.02%
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.284589 Test loss=0.267579 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2795223295688629
[5/24] Train loss=0.25028756260871887
[10/24] Train loss=0.29765743017196655
[15/24] Train loss=0.26599031686782837
[20/24] Train loss=0.2452242076396942
Test set avg_accuracy=88.98% avg_sensitivity=71.05%, avg_specificity=95.83% avg_auc=95.04%
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.278080 Test loss=0.270219 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.27009397745132446
[5/24] Train loss=0.24014490842819214
[10/24] Train loss=0.2856217920780182
[15/24] Train loss=0.2579900026321411
[20/24] Train loss=0.24397751688957214
Test set avg_accuracy=89.35% avg_sensitivity=73.93%, avg_specificity=95.23% avg_auc=95.19%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.271442 Test loss=0.259648 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2654193639755249
[5/24] Train loss=0.24145212769508362
[10/24] Train loss=0.28012698888778687
[15/24] Train loss=0.24915404617786407
[20/24] Train loss=0.238790363073349
Test set avg_accuracy=86.76% avg_sensitivity=58.42%, avg_specificity=97.57% avg_auc=93.94%
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.266836 Test loss=0.306535 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.26192909479141235
[5/24] Train loss=0.23481501638889313
[10/24] Train loss=0.27812036871910095
[15/24] Train loss=0.24426010251045227
[20/24] Train loss=0.2311011403799057
Test set avg_accuracy=88.72% avg_sensitivity=69.07%, avg_specificity=96.22% avg_auc=94.17%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.261814 Test loss=0.281708 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.25867727398872375
[5/24] Train loss=0.22882811725139618
[10/24] Train loss=0.2755042612552643
[15/24] Train loss=0.24337731301784515
[20/24] Train loss=0.2307380735874176
Test set avg_accuracy=87.32% avg_sensitivity=63.13%, avg_specificity=96.55% avg_auc=93.14%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.257354 Test loss=0.301355 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.26066723465919495
[5/24] Train loss=0.226353719830513
[10/24] Train loss=0.2735324501991272
[15/24] Train loss=0.24281758069992065
[20/24] Train loss=0.23370467126369476
Test set avg_accuracy=87.93% avg_sensitivity=65.06%, avg_specificity=96.65% avg_auc=94.30%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.253992 Test loss=0.284078 Current lr=[0.000210185142098938]

[0/24] Train loss=0.24544958770275116
[5/24] Train loss=0.22420823574066162
[10/24] Train loss=0.26994046568870544
[15/24] Train loss=0.23646233975887299
[20/24] Train loss=0.22709132730960846
Test set avg_accuracy=86.45% avg_sensitivity=57.00%, avg_specificity=97.68% avg_auc=92.26%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.249324 Test loss=0.328526 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2547723948955536
[5/24] Train loss=0.21829797327518463
[10/24] Train loss=0.2597877085208893
[15/24] Train loss=0.23739129304885864
[20/24] Train loss=0.22026602923870087
Test set avg_accuracy=87.84% avg_sensitivity=63.13%, avg_specificity=97.27% avg_auc=94.10%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.245312 Test loss=0.293987 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.24082477390766144
[5/24] Train loss=0.20894916355609894
[10/24] Train loss=0.2591017782688141
[15/24] Train loss=0.23639941215515137
[20/24] Train loss=0.22054174542427063
Test set avg_accuracy=84.38% avg_sensitivity=47.01%, avg_specificity=98.63% avg_auc=92.36%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.238624 Test loss=0.381989 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.24812789261341095
[5/24] Train loss=0.2222772091627121
[10/24] Train loss=0.25963714718818665
[15/24] Train loss=0.23379941284656525
[20/24] Train loss=0.21943995356559753
Test set avg_accuracy=86.98% avg_sensitivity=60.44%, avg_specificity=97.10% avg_auc=93.88%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.242769 Test loss=0.305439 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.24642246961593628
[5/24] Train loss=0.20742550492286682
[10/24] Train loss=0.2529977858066559
[15/24] Train loss=0.2408485859632492
[20/24] Train loss=0.21620523929595947
Test set avg_accuracy=89.70% avg_sensitivity=76.43%, avg_specificity=94.77% avg_auc=95.40%
Best model saved!! Metric=30.288336811754846!!
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.237386 Test loss=0.251720 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.23224398493766785
[5/24] Train loss=0.19835449755191803
[10/24] Train loss=0.25042545795440674
[15/24] Train loss=0.22829043865203857
[20/24] Train loss=0.22940750420093536
Test set avg_accuracy=83.41% avg_sensitivity=43.28%, avg_specificity=98.72% avg_auc=89.14%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.233582 Test loss=0.423229 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.23269473016262054
[5/24] Train loss=0.19392870366573334
[10/24] Train loss=0.24859404563903809
[15/24] Train loss=0.22120489180088043
[20/24] Train loss=0.21231944859027863
Test set avg_accuracy=89.02% avg_sensitivity=81.47%, avg_specificity=91.91% avg_auc=94.98%
Best model saved!! Metric=31.37632320873894!!
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.227704 Test loss=0.265901 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.22389626502990723
[5/24] Train loss=0.1864071637392044
[10/24] Train loss=0.23668339848518372
[15/24] Train loss=0.23394939303398132
[20/24] Train loss=0.21438463032245636
Test set avg_accuracy=87.77% avg_sensitivity=64.45%, avg_specificity=96.67% avg_auc=93.94%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.227641 Test loss=0.287882 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2178708165884018
[5/24] Train loss=0.19287310540676117
[10/24] Train loss=0.24632467329502106
[15/24] Train loss=0.2191859930753708
[20/24] Train loss=0.20910775661468506
Test set avg_accuracy=89.66% avg_sensitivity=82.27%, avg_specificity=92.48% avg_auc=95.11%
Best model saved!! Metric=33.52135311935807!!
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.224055 Test loss=0.262326 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2285611480474472
[5/24] Train loss=0.19058649241924286
[10/24] Train loss=0.23388031125068665
[15/24] Train loss=0.22008760273456573
[20/24] Train loss=0.20556846261024475
Test set avg_accuracy=86.39% avg_sensitivity=57.10%, avg_specificity=97.57% avg_auc=91.83%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.223155 Test loss=0.341479 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.21163490414619446
[5/24] Train loss=0.19431467354297638
[10/24] Train loss=0.23529769480228424
[15/24] Train loss=0.2255539745092392
[20/24] Train loss=0.2046334594488144
Test set avg_accuracy=88.02% avg_sensitivity=65.72%, avg_specificity=96.53% avg_auc=93.59%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.217887 Test loss=0.291812 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.21495863795280457
[5/24] Train loss=0.1868753284215927
[10/24] Train loss=0.23301948606967926
[15/24] Train loss=0.21739760041236877
[20/24] Train loss=0.19902704656124115
Test set avg_accuracy=80.85% avg_sensitivity=33.19%, avg_specificity=99.03% avg_auc=82.96%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.218046 Test loss=0.556700 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.21255341172218323
[5/24] Train loss=0.18670617043972015
[10/24] Train loss=0.2365727573633194
[15/24] Train loss=0.23533564805984497
[20/24] Train loss=0.20502077043056488
Test set avg_accuracy=90.00% avg_sensitivity=77.56%, avg_specificity=94.75% avg_auc=95.45%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.221457 Test loss=0.243212 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.20052610337734222
[5/24] Train loss=0.17483550310134888
[10/24] Train loss=0.22703225910663605
[15/24] Train loss=0.22301031649112701
[20/24] Train loss=0.20029506087303162
Test set avg_accuracy=88.82% avg_sensitivity=82.89%, avg_specificity=91.08% avg_auc=94.56%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.216707 Test loss=0.275418 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2054511159658432
[5/24] Train loss=0.18562887609004974
[10/24] Train loss=0.2339811772108078
[15/24] Train loss=0.21318651735782623
[20/24] Train loss=0.19327771663665771
Test set avg_accuracy=89.99% avg_sensitivity=79.73%, avg_specificity=93.90% avg_auc=95.33%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.215569 Test loss=0.245547 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2010115087032318
[5/24] Train loss=0.17798402905464172
[10/24] Train loss=0.22289839386940002
[15/24] Train loss=0.21182577311992645
[20/24] Train loss=0.19782838225364685
Test set avg_accuracy=89.54% avg_sensitivity=81.33%, avg_specificity=92.68% avg_auc=94.83%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.211584 Test loss=0.259593 Current lr=[0.00029967723776099]

[0/24] Train loss=0.19018039107322693
[5/24] Train loss=0.16654495894908905
[10/24] Train loss=0.23204006254673004
[15/24] Train loss=0.21331001818180084
[20/24] Train loss=0.193617582321167
Test set avg_accuracy=87.97% avg_sensitivity=72.09%, avg_specificity=94.03% avg_auc=93.89%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.209290 Test loss=0.282799 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2003437876701355
[5/24] Train loss=0.166244238615036
[10/24] Train loss=0.22082535922527313
[15/24] Train loss=0.21180422604084015
[20/24] Train loss=0.19179004430770874
Test set avg_accuracy=89.19% avg_sensitivity=72.32%, avg_specificity=95.63% avg_auc=93.82%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.206237 Test loss=0.277678 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.19193491339683533
[5/24] Train loss=0.16802963614463806
[10/24] Train loss=0.2168388068675995
[15/24] Train loss=0.22999919950962067
[20/24] Train loss=0.19172842800617218
Test set avg_accuracy=89.10% avg_sensitivity=72.04%, avg_specificity=95.61% avg_auc=94.61%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.203440 Test loss=0.263232 Current lr=[0.000299720220882401]

[0/24] Train loss=0.18933649361133575
[5/24] Train loss=0.1620965600013733
[10/24] Train loss=0.2145039141178131
[15/24] Train loss=0.21303512156009674
[20/24] Train loss=0.1789669692516327
Test set avg_accuracy=89.23% avg_sensitivity=78.60%, avg_specificity=93.29% avg_auc=95.25%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.200629 Test loss=0.252491 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2023734152317047
[5/24] Train loss=0.16085995733737946
[10/24] Train loss=0.22505821287631989
[15/24] Train loss=0.21017710864543915
[20/24] Train loss=0.1794009655714035
Test set avg_accuracy=86.33% avg_sensitivity=59.26%, avg_specificity=96.65% avg_auc=91.45%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.200525 Test loss=0.344547 Current lr=[0.000298904600941902]

[0/24] Train loss=0.20232966542243958
[5/24] Train loss=0.15479345619678497
[10/24] Train loss=0.20685391128063202
[15/24] Train loss=0.20753178000450134
[20/24] Train loss=0.1794472485780716
Test set avg_accuracy=89.24% avg_sensitivity=76.76%, avg_specificity=94.01% avg_auc=94.95%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.198937 Test loss=0.257332 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.1908082365989685
[5/24] Train loss=0.17423713207244873
[10/24] Train loss=0.21843867003917694
[15/24] Train loss=0.2101137936115265
[20/24] Train loss=0.18427006900310516
Test set avg_accuracy=89.78% avg_sensitivity=80.34%, avg_specificity=93.38% avg_auc=95.74%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.195059 Test loss=0.239880 Current lr=[0.000297555943323901]

[0/24] Train loss=0.1834200620651245
[5/24] Train loss=0.1618252545595169
[10/24] Train loss=0.21140912175178528
[15/24] Train loss=0.20675978064537048
[20/24] Train loss=0.17800983786582947
Test set avg_accuracy=88.42% avg_sensitivity=71.29%, avg_specificity=94.96% avg_auc=93.85%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.195208 Test loss=0.282078 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.18735142052173615
[5/24] Train loss=0.16845877468585968
[10/24] Train loss=0.20736438035964966
[15/24] Train loss=0.20546390116214752
[20/24] Train loss=0.18713045120239258
Test set avg_accuracy=89.39% avg_sensitivity=74.49%, avg_specificity=95.07% avg_auc=94.98%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.195962 Test loss=0.257626 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.19000159204006195
[5/24] Train loss=0.1549711674451828
[10/24] Train loss=0.19701014459133148
[15/24] Train loss=0.19068482518196106
[20/24] Train loss=0.17259378731250763
Test set avg_accuracy=87.85% avg_sensitivity=65.49%, avg_specificity=96.38% avg_auc=93.61%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.192065 Test loss=0.294212 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.1811322569847107
[5/24] Train loss=0.1611795574426651
[10/24] Train loss=0.1983374059200287
[15/24] Train loss=0.19408266246318817
[20/24] Train loss=0.17783594131469727
Test set avg_accuracy=88.96% avg_sensitivity=79.11%, avg_specificity=92.71% avg_auc=94.12%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.189607 Test loss=0.275726 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.17493084073066711
[5/24] Train loss=0.14930744469165802
[10/24] Train loss=0.20396128296852112
[15/24] Train loss=0.1925869584083557
[20/24] Train loss=0.18537753820419312
Test set avg_accuracy=88.78% avg_sensitivity=79.26%, avg_specificity=92.41% avg_auc=94.20%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.188340 Test loss=0.273532 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.17427600920200348
[5/24] Train loss=0.15933683514595032
[10/24] Train loss=0.1993563324213028
[15/24] Train loss=0.19307997822761536
[20/24] Train loss=0.17287935316562653
Test set avg_accuracy=88.40% avg_sensitivity=67.09%, avg_specificity=96.53% avg_auc=92.91%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.186929 Test loss=0.300423 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.1808013916015625
[5/24] Train loss=0.1623377501964569
[10/24] Train loss=0.19983085989952087
[15/24] Train loss=0.19461989402770996
[20/24] Train loss=0.17585588991641998
Test set avg_accuracy=88.23% avg_sensitivity=68.03%, avg_specificity=95.93% avg_auc=92.52%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.187140 Test loss=0.306540 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.19292707741260529
[5/24] Train loss=0.15768469870090485
[10/24] Train loss=0.1946546584367752
[15/24] Train loss=0.18753281235694885
[20/24] Train loss=0.1740015745162964
Test set avg_accuracy=88.96% avg_sensitivity=79.96%, avg_specificity=92.39% avg_auc=94.60%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.183094 Test loss=0.266501 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18610285222530365
[5/24] Train loss=0.16059067845344543
[10/24] Train loss=0.20186659693717957
[15/24] Train loss=0.1970948576927185
[20/24] Train loss=0.17885631322860718
Test set avg_accuracy=85.99% avg_sensitivity=84.72%, avg_specificity=86.47% avg_auc=92.96%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.192074 Test loss=0.328866 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.19454637169837952
[5/24] Train loss=0.17549201846122742
[10/24] Train loss=0.19910801947116852
[15/24] Train loss=0.1945119947195053
[20/24] Train loss=0.17611227929592133
Test set avg_accuracy=87.97% avg_sensitivity=65.16%, avg_specificity=96.67% avg_auc=92.40%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.188888 Test loss=0.316046 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.17690175771713257
[5/24] Train loss=0.15071389079093933
[10/24] Train loss=0.20410220324993134
[15/24] Train loss=0.18871934711933136
[20/24] Train loss=0.17090632021427155
Test set avg_accuracy=89.54% avg_sensitivity=82.27%, avg_specificity=92.32% avg_auc=95.30%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.184503 Test loss=0.253043 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.17275455594062805
[5/24] Train loss=0.16119103133678436
[10/24] Train loss=0.1917831301689148
[15/24] Train loss=0.19010025262832642
[20/24] Train loss=0.17538782954216003
Test set avg_accuracy=89.71% avg_sensitivity=78.26%, avg_specificity=94.08% avg_auc=94.23%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.183348 Test loss=0.261281 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.17581064999103546
[5/24] Train loss=0.14536413550376892
[10/24] Train loss=0.19713817536830902
[15/24] Train loss=0.2001398503780365
[20/24] Train loss=0.18488310277462006
Test set avg_accuracy=89.00% avg_sensitivity=76.90%, avg_specificity=93.61% avg_auc=93.82%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.184293 Test loss=0.275335 Current lr=[0.000276307469034998]

[0/24] Train loss=0.1774897575378418
[5/24] Train loss=0.1521815061569214
[10/24] Train loss=0.20620086789131165
[15/24] Train loss=0.17955675721168518
[20/24] Train loss=0.17354610562324524
Test set avg_accuracy=88.79% avg_sensitivity=70.91%, avg_specificity=95.61% avg_auc=94.32%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.183231 Test loss=0.269469 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.170891672372818
[5/24] Train loss=0.14801159501075745
[10/24] Train loss=0.1968773752450943
[15/24] Train loss=0.18173937499523163
[20/24] Train loss=0.1778654009103775
Test set avg_accuracy=87.86% avg_sensitivity=80.43%, avg_specificity=90.70% avg_auc=93.96%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.180397 Test loss=0.285268 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.17991039156913757
[5/24] Train loss=0.15159954130649567
[10/24] Train loss=0.1942000538110733
[15/24] Train loss=0.18158555030822754
[20/24] Train loss=0.15829184651374817
Test set avg_accuracy=89.28% avg_sensitivity=74.59%, avg_specificity=94.89% avg_auc=93.99%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.178207 Test loss=0.271867 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.16676375269889832
[5/24] Train loss=0.15828938782215118
[10/24] Train loss=0.1856452375650406
[15/24] Train loss=0.1732693910598755
[20/24] Train loss=0.1757022887468338
Test set avg_accuracy=81.74% avg_sensitivity=37.44%, avg_specificity=98.65% avg_auc=86.00%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.180901 Test loss=0.492488 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.17489279806613922
[5/24] Train loss=0.15029460191726685
[10/24] Train loss=0.18586599826812744
[15/24] Train loss=0.18175087869167328
[20/24] Train loss=0.17779168486595154
Test set avg_accuracy=89.39% avg_sensitivity=76.47%, avg_specificity=94.32% avg_auc=94.45%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.177423 Test loss=0.265599 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.16771046817302704
[5/24] Train loss=0.14419902861118317
[10/24] Train loss=0.1841641217470169
[15/24] Train loss=0.17095999419689178
[20/24] Train loss=0.16463299095630646
Test set avg_accuracy=87.75% avg_sensitivity=65.82%, avg_specificity=96.11% avg_auc=91.99%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.171800 Test loss=0.316175 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.1605922430753708
[5/24] Train loss=0.14418460428714752
[10/24] Train loss=0.1764766126871109
[15/24] Train loss=0.1680031567811966
[20/24] Train loss=0.16795247793197632
Test set avg_accuracy=89.43% avg_sensitivity=73.41%, avg_specificity=95.54% avg_auc=93.78%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.171450 Test loss=0.272963 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.17573440074920654
[5/24] Train loss=0.149034783244133
[10/24] Train loss=0.1805456578731537
[15/24] Train loss=0.17529621720314026
[20/24] Train loss=0.15523119270801544
Test set avg_accuracy=88.49% avg_sensitivity=80.53%, avg_specificity=91.53% avg_auc=93.75%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.170307 Test loss=0.282813 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.16961295902729034
[5/24] Train loss=0.14904555678367615
[10/24] Train loss=0.1905643492937088
[15/24] Train loss=0.18736112117767334
[20/24] Train loss=0.16955512762069702
Test set avg_accuracy=80.83% avg_sensitivity=33.10%, avg_specificity=99.05% avg_auc=79.26%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.176877 Test loss=0.571697 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1837296038866043
[5/24] Train loss=0.14165674149990082
[10/24] Train loss=0.1772914081811905
[15/24] Train loss=0.17113284766674042
[20/24] Train loss=0.17690888047218323
Test set avg_accuracy=87.15% avg_sensitivity=59.64%, avg_specificity=97.64% avg_auc=90.91%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.174396 Test loss=0.348908 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.17440873384475708
[5/24] Train loss=0.13780680298805237
[10/24] Train loss=0.17165571451187134
[15/24] Train loss=0.17544297873973846
[20/24] Train loss=0.1600980907678604
Test set avg_accuracy=85.72% avg_sensitivity=54.64%, avg_specificity=97.57% avg_auc=89.03%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.170825 Test loss=0.383687 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1622815877199173
[5/24] Train loss=0.1418738067150116
[10/24] Train loss=0.17206434905529022
[15/24] Train loss=0.1707683950662613
[20/24] Train loss=0.1671237200498581
Test set avg_accuracy=87.73% avg_sensitivity=65.35%, avg_specificity=96.28% avg_auc=90.24%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.168501 Test loss=0.326454 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.16651296615600586
[5/24] Train loss=0.13901910185813904
[10/24] Train loss=0.1775818020105362
[15/24] Train loss=0.16772432625293732
[20/24] Train loss=0.15849941968917847
Test set avg_accuracy=87.70% avg_sensitivity=73.60%, avg_specificity=93.07% avg_auc=91.99%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.166194 Test loss=0.302706 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.1701114922761917
[5/24] Train loss=0.13773034512996674
[10/24] Train loss=0.16973331570625305
[15/24] Train loss=0.1630777269601822
[20/24] Train loss=0.16356304287910461
Test set avg_accuracy=85.48% avg_sensitivity=56.58%, avg_specificity=96.51% avg_auc=87.87%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.168521 Test loss=0.378980 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.16175369918346405
[5/24] Train loss=0.14156624674797058
[10/24] Train loss=0.18431143462657928
[15/24] Train loss=0.1746102124452591
[20/24] Train loss=0.16339629888534546
Test set avg_accuracy=85.17% avg_sensitivity=54.13%, avg_specificity=97.01% avg_auc=89.89%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.168691 Test loss=0.369506 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17023029923439026
[5/24] Train loss=0.14195096492767334
[10/24] Train loss=0.18189242482185364
[15/24] Train loss=0.16687685251235962
[20/24] Train loss=0.16202053427696228
Test set avg_accuracy=80.05% avg_sensitivity=29.99%, avg_specificity=99.15% avg_auc=78.83%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.171069 Test loss=0.549424 Current lr=[0.000224838296036774]

[0/24] Train loss=0.17343343794345856
[5/24] Train loss=0.1515534222126007
[10/24] Train loss=0.1659606248140335
[15/24] Train loss=0.1583753079175949
[20/24] Train loss=0.15525352954864502
Test set avg_accuracy=87.76% avg_sensitivity=62.09%, avg_specificity=97.55% avg_auc=90.19%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.166129 Test loss=0.340864 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.1600341498851776
[5/24] Train loss=0.13014256954193115
[10/24] Train loss=0.1697152853012085
[15/24] Train loss=0.17077232897281647
[20/24] Train loss=0.1688009351491928
Test set avg_accuracy=88.68% avg_sensitivity=68.84%, avg_specificity=96.26% avg_auc=92.11%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.170304 Test loss=0.306571 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.17462532222270966
[5/24] Train loss=0.14623036980628967
[10/24] Train loss=0.17157454788684845
[15/24] Train loss=0.17303676903247833
[20/24] Train loss=0.16270987689495087
Test set avg_accuracy=85.96% avg_sensitivity=56.34%, avg_specificity=97.27% avg_auc=88.51%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.170129 Test loss=0.376190 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.16410870850086212
[5/24] Train loss=0.13851496577262878
[10/24] Train loss=0.19723232090473175
[15/24] Train loss=0.18199777603149414
[20/24] Train loss=0.15119807422161102
Test set avg_accuracy=86.22% avg_sensitivity=57.85%, avg_specificity=97.05% avg_auc=89.78%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.169299 Test loss=0.357592 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.16515281796455383
[5/24] Train loss=0.13943278789520264
[10/24] Train loss=0.18155820667743683
[15/24] Train loss=0.1803700029850006
[20/24] Train loss=0.16764962673187256
Test set avg_accuracy=84.47% avg_sensitivity=49.55%, avg_specificity=97.79% avg_auc=85.73%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.169013 Test loss=0.456554 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.17288650572299957
[5/24] Train loss=0.14859798550605774
[10/24] Train loss=0.17222602665424347
[15/24] Train loss=0.16557903587818146
[20/24] Train loss=0.15435566008090973
Test set avg_accuracy=88.53% avg_sensitivity=70.49%, avg_specificity=95.41% avg_auc=91.57%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.166524 Test loss=0.303733 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.16547024250030518
[5/24] Train loss=0.1411401778459549
[10/24] Train loss=0.17176713049411774
[15/24] Train loss=0.17077359557151794
[20/24] Train loss=0.168257474899292
Test set avg_accuracy=88.68% avg_sensitivity=82.51%, avg_specificity=91.04% avg_auc=93.93%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.166388 Test loss=0.283168 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.16461357474327087
[5/24] Train loss=0.13487927615642548
[10/24] Train loss=0.1672772616147995
[15/24] Train loss=0.1636561155319214
[20/24] Train loss=0.1583169847726822
Test set avg_accuracy=87.84% avg_sensitivity=64.12%, avg_specificity=96.89% avg_auc=91.32%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.164072 Test loss=0.323118 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.16681154072284698
[5/24] Train loss=0.13958269357681274
[10/24] Train loss=0.1628991961479187
[15/24] Train loss=0.1647997945547104
[20/24] Train loss=0.15375369787216187
Test set avg_accuracy=89.53% avg_sensitivity=75.44%, avg_specificity=94.91% avg_auc=93.29%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.166416 Test loss=0.275660 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.16085726022720337
[5/24] Train loss=0.13706809282302856
[10/24] Train loss=0.1662413626909256
[15/24] Train loss=0.1649041324853897
[20/24] Train loss=0.16114874184131622
Test set avg_accuracy=88.82% avg_sensitivity=73.03%, avg_specificity=94.84% avg_auc=93.93%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.164427 Test loss=0.281071 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1584588587284088
[5/24] Train loss=0.14434675872325897
[10/24] Train loss=0.17180411517620087
[15/24] Train loss=0.16006797552108765
[20/24] Train loss=0.159251868724823
Test set avg_accuracy=88.05% avg_sensitivity=65.44%, avg_specificity=96.67% avg_auc=92.06%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.161636 Test loss=0.315794 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.16464100778102875
[5/24] Train loss=0.14068107306957245
[10/24] Train loss=0.15690724551677704
[15/24] Train loss=0.1593165546655655
[20/24] Train loss=0.15010493993759155
Test set avg_accuracy=89.02% avg_sensitivity=69.97%, avg_specificity=96.29% avg_auc=92.89%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.158096 Test loss=0.293141 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.15464875102043152
[5/24] Train loss=0.13689157366752625
[10/24] Train loss=0.1576581746339798
[15/24] Train loss=0.1545143723487854
[20/24] Train loss=0.1491079032421112
Test set avg_accuracy=87.32% avg_sensitivity=61.20%, avg_specificity=97.28% avg_auc=89.84%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.156023 Test loss=0.346909 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15572570264339447
[5/24] Train loss=0.1373721957206726
[10/24] Train loss=0.15423396229743958
[15/24] Train loss=0.15245087444782257
[20/24] Train loss=0.14617103338241577
Test set avg_accuracy=88.97% avg_sensitivity=71.52%, avg_specificity=95.63% avg_auc=92.69%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.154503 Test loss=0.288727 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1477666199207306
[5/24] Train loss=0.13008169829845428
[10/24] Train loss=0.1494566947221756
[15/24] Train loss=0.15184393525123596
[20/24] Train loss=0.1513754427433014
Test set avg_accuracy=89.08% avg_sensitivity=70.06%, avg_specificity=96.33% avg_auc=93.52%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.155313 Test loss=0.280087 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15149693191051483
[5/24] Train loss=0.1342279613018036
[10/24] Train loss=0.1473902314901352
[15/24] Train loss=0.15000177919864655
[20/24] Train loss=0.14563363790512085
Test set avg_accuracy=89.71% avg_sensitivity=78.97%, avg_specificity=93.81% avg_auc=94.10%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.153368 Test loss=0.263446 Current lr=[0.000156543481933168]

[0/24] Train loss=0.15320366621017456
[5/24] Train loss=0.13252653181552887
[10/24] Train loss=0.15434008836746216
[15/24] Train loss=0.15529651939868927
[20/24] Train loss=0.14847369492053986
Test set avg_accuracy=89.49% avg_sensitivity=77.84%, avg_specificity=93.94% avg_auc=93.98%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.151982 Test loss=0.269246 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.14318114519119263
[5/24] Train loss=0.12540407478809357
[10/24] Train loss=0.15056894719600677
[15/24] Train loss=0.14856082201004028
[20/24] Train loss=0.14251264929771423
Test set avg_accuracy=89.38% avg_sensitivity=72.80%, avg_specificity=95.70% avg_auc=93.73%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.148905 Test loss=0.277277 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.14552828669548035
[5/24] Train loss=0.12973546981811523
[10/24] Train loss=0.1533360630273819
[15/24] Train loss=0.15167078375816345
[20/24] Train loss=0.14442217350006104
Test set avg_accuracy=88.57% avg_sensitivity=69.64%, avg_specificity=95.79% avg_auc=92.53%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.150522 Test loss=0.297939 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15154625475406647
[5/24] Train loss=0.1346036195755005
[10/24] Train loss=0.1548403799533844
[15/24] Train loss=0.15077544748783112
[20/24] Train loss=0.13699057698249817
Test set avg_accuracy=88.28% avg_sensitivity=67.94%, avg_specificity=96.04% avg_auc=91.44%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.148515 Test loss=0.314269 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15181809663772583
[5/24] Train loss=0.12779763340950012
[10/24] Train loss=0.14760716259479523
[15/24] Train loss=0.1464594006538391
[20/24] Train loss=0.14333048462867737
Test set avg_accuracy=89.64% avg_sensitivity=76.80%, avg_specificity=94.53% avg_auc=93.59%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.148348 Test loss=0.275496 Current lr=[0.000134135431043539]

[0/24] Train loss=0.14767460525035858
[5/24] Train loss=0.1283414661884308
[10/24] Train loss=0.1457829773426056
[15/24] Train loss=0.14910940825939178
[20/24] Train loss=0.14232315123081207
Test set avg_accuracy=89.38% avg_sensitivity=78.83%, avg_specificity=93.40% avg_auc=93.86%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.147740 Test loss=0.271302 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1452576071023941
[5/24] Train loss=0.13062290847301483
[10/24] Train loss=0.14076881110668182
[15/24] Train loss=0.14359138906002045
[20/24] Train loss=0.14289377629756927
Test set avg_accuracy=88.66% avg_sensitivity=73.17%, avg_specificity=94.57% avg_auc=92.73%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.148265 Test loss=0.294098 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.14806020259857178
[5/24] Train loss=0.13285282254219055
[10/24] Train loss=0.14198866486549377
[15/24] Train loss=0.143072247505188
[20/24] Train loss=0.14431391656398773
Test set avg_accuracy=89.21% avg_sensitivity=74.30%, avg_specificity=94.89% avg_auc=92.78%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.149158 Test loss=0.285415 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15045882761478424
[5/24] Train loss=0.1297667771577835
[10/24] Train loss=0.14115092158317566
[15/24] Train loss=0.15110719203948975
[20/24] Train loss=0.1526731252670288
Test set avg_accuracy=88.85% avg_sensitivity=68.79%, avg_specificity=96.51% avg_auc=91.50%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.147445 Test loss=0.307606 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1450476199388504
[5/24] Train loss=0.12840524315834045
[10/24] Train loss=0.1498144268989563
[15/24] Train loss=0.14948037266731262
[20/24] Train loss=0.14599688351154327
Test set avg_accuracy=88.14% avg_sensitivity=67.56%, avg_specificity=95.99% avg_auc=91.54%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.150570 Test loss=0.315305 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14834251999855042
[5/24] Train loss=0.13122324645519257
[10/24] Train loss=0.1485777646303177
[15/24] Train loss=0.15114299952983856
[20/24] Train loss=0.14137797057628632
Test set avg_accuracy=88.12% avg_sensitivity=64.64%, avg_specificity=97.09% avg_auc=91.23%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.147308 Test loss=0.327768 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1469411998987198
[5/24] Train loss=0.13088500499725342
[10/24] Train loss=0.14518746733665466
[15/24] Train loss=0.1455758810043335
[20/24] Train loss=0.13722582161426544
Test set avg_accuracy=88.93% avg_sensitivity=69.26%, avg_specificity=96.44% avg_auc=92.34%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.148262 Test loss=0.298501 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1446956843137741
[5/24] Train loss=0.13251349329948425
[10/24] Train loss=0.1429200917482376
[15/24] Train loss=0.14427684247493744
[20/24] Train loss=0.13809557259082794
Test set avg_accuracy=89.13% avg_sensitivity=72.65%, avg_specificity=95.41% avg_auc=93.74%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.146445 Test loss=0.279808 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1434411108493805
[5/24] Train loss=0.1307312399148941
[10/24] Train loss=0.14315231144428253
[15/24] Train loss=0.14326117932796478
[20/24] Train loss=0.13942109048366547
Test set avg_accuracy=89.11% avg_sensitivity=70.25%, avg_specificity=96.31% avg_auc=91.95%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.143052 Test loss=0.300014 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.13689473271369934
[5/24] Train loss=0.1237555742263794
[10/24] Train loss=0.14067192375659943
[15/24] Train loss=0.13710817694664001
[20/24] Train loss=0.13935470581054688
Test set avg_accuracy=88.66% avg_sensitivity=71.52%, avg_specificity=95.20% avg_auc=93.21%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.141646 Test loss=0.290564 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.14530342817306519
[5/24] Train loss=0.12305709719657898
[10/24] Train loss=0.1327153444290161
[15/24] Train loss=0.13413791358470917
[20/24] Train loss=0.13547348976135254
Test set avg_accuracy=89.05% avg_sensitivity=75.72%, avg_specificity=94.14% avg_auc=93.55%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.139690 Test loss=0.282564 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14169152081012726
[5/24] Train loss=0.12436747550964355
[10/24] Train loss=0.13370588421821594
[15/24] Train loss=0.1297084540128708
[20/24] Train loss=0.13493090867996216
Test set avg_accuracy=88.70% avg_sensitivity=68.98%, avg_specificity=96.22% avg_auc=92.12%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.137749 Test loss=0.302311 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14150111377239227
[5/24] Train loss=0.12383215129375458
[10/24] Train loss=0.1330350935459137
[15/24] Train loss=0.1329164355993271
[20/24] Train loss=0.13069939613342285
Test set avg_accuracy=88.84% avg_sensitivity=70.20%, avg_specificity=95.95% avg_auc=92.51%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.135990 Test loss=0.300697 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13497447967529297
[5/24] Train loss=0.11698279529809952
[10/24] Train loss=0.13100431859493256
[15/24] Train loss=0.13281813263893127
[20/24] Train loss=0.13250386714935303
Test set avg_accuracy=88.96% avg_sensitivity=72.42%, avg_specificity=95.27% avg_auc=92.78%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.134102 Test loss=0.290639 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13952434062957764
[5/24] Train loss=0.11667574197053909
[10/24] Train loss=0.13337987661361694
[15/24] Train loss=0.13290314376354218
[20/24] Train loss=0.13085129857063293
Test set avg_accuracy=89.09% avg_sensitivity=73.60%, avg_specificity=95.00% avg_auc=93.90%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.134832 Test loss=0.278549 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13573889434337616
[5/24] Train loss=0.11815934628248215
[10/24] Train loss=0.12929557263851166
[15/24] Train loss=0.13081327080726624
[20/24] Train loss=0.1297444999217987
Test set avg_accuracy=88.93% avg_sensitivity=76.14%, avg_specificity=93.81% avg_auc=93.74%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.133579 Test loss=0.277969 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.13193294405937195
[5/24] Train loss=0.11968538165092468
[10/24] Train loss=0.13185109198093414
[15/24] Train loss=0.12895779311656952
[20/24] Train loss=0.12699444591999054
Test set avg_accuracy=88.84% avg_sensitivity=73.55%, avg_specificity=94.68% avg_auc=93.40%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.132941 Test loss=0.284462 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13433387875556946
[5/24] Train loss=0.11641013622283936
[10/24] Train loss=0.13015127182006836
[15/24] Train loss=0.12763768434524536
[20/24] Train loss=0.12926846742630005
Test set avg_accuracy=88.66% avg_sensitivity=69.92%, avg_specificity=95.81% avg_auc=91.82%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.132337 Test loss=0.308569 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13604673743247986
[5/24] Train loss=0.11684899032115936
[10/24] Train loss=0.12992286682128906
[15/24] Train loss=0.1271875947713852
[20/24] Train loss=0.13281844556331635
Test set avg_accuracy=88.83% avg_sensitivity=70.96%, avg_specificity=95.65% avg_auc=92.61%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.131448 Test loss=0.296100 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13102197647094727
[5/24] Train loss=0.11680416017770767
[10/24] Train loss=0.12504760921001434
[15/24] Train loss=0.12639938294887543
[20/24] Train loss=0.12953920662403107
Test set avg_accuracy=89.00% avg_sensitivity=71.66%, avg_specificity=95.61% avg_auc=92.08%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.130319 Test loss=0.298284 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.13386128842830658
[5/24] Train loss=0.1176757887005806
[10/24] Train loss=0.12401127070188522
[15/24] Train loss=0.12430886179208755
[20/24] Train loss=0.13032737374305725
Test set avg_accuracy=88.91% avg_sensitivity=70.58%, avg_specificity=95.90% avg_auc=92.61%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.129752 Test loss=0.298603 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13048601150512695
[5/24] Train loss=0.11646496504545212
[10/24] Train loss=0.12283459305763245
[15/24] Train loss=0.12723283469676971
[20/24] Train loss=0.12919193506240845
Test set avg_accuracy=89.40% avg_sensitivity=75.62%, avg_specificity=94.66% avg_auc=93.38%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.129209 Test loss=0.281510 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13028891384601593
[5/24] Train loss=0.11540410667657852
[10/24] Train loss=0.12547031044960022
[15/24] Train loss=0.12489230185747147
[20/24] Train loss=0.1275007128715515
Test set avg_accuracy=88.89% avg_sensitivity=69.92%, avg_specificity=96.13% avg_auc=92.08%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.128689 Test loss=0.303375 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1287836730480194
[5/24] Train loss=0.11619042605161667
[10/24] Train loss=0.12925703823566437
[15/24] Train loss=0.12312749028205872
[20/24] Train loss=0.12752026319503784
Test set avg_accuracy=88.79% avg_sensitivity=71.33%, avg_specificity=95.45% avg_auc=92.36%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.127881 Test loss=0.297476 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1276601105928421
[5/24] Train loss=0.11584310978651047
[10/24] Train loss=0.12168359011411667
[15/24] Train loss=0.12405943125486374
[20/24] Train loss=0.1259828805923462
Test set avg_accuracy=89.05% avg_sensitivity=76.52%, avg_specificity=93.83% avg_auc=93.32%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.126853 Test loss=0.286673 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12643618881702423
[5/24] Train loss=0.11458658427000046
[10/24] Train loss=0.12399806082248688
[15/24] Train loss=0.12262599915266037
[20/24] Train loss=0.12832817435264587
Test set avg_accuracy=89.02% avg_sensitivity=78.50%, avg_specificity=93.04% avg_auc=93.53%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.126931 Test loss=0.282219 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12737402319908142
[5/24] Train loss=0.1125529333949089
[10/24] Train loss=0.12432336807250977
[15/24] Train loss=0.12642091512680054
[20/24] Train loss=0.12462478876113892
Test set avg_accuracy=88.88% avg_sensitivity=76.90%, avg_specificity=93.45% avg_auc=93.21%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.126725 Test loss=0.288274 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12922224402427673
[5/24] Train loss=0.11441066861152649
[10/24] Train loss=0.12280676513910294
[15/24] Train loss=0.12325239926576614
[20/24] Train loss=0.12493540346622467
Test set avg_accuracy=88.91% avg_sensitivity=77.18%, avg_specificity=93.38% avg_auc=93.26%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.126656 Test loss=0.286124 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12747682631015778
[5/24] Train loss=0.1124429777264595
[10/24] Train loss=0.12296344339847565
[15/24] Train loss=0.1256270706653595
[20/24] Train loss=0.12766586244106293
Test set avg_accuracy=88.84% avg_sensitivity=76.10%, avg_specificity=93.70% avg_auc=92.87%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.126910 Test loss=0.289429 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1273614913225174
[5/24] Train loss=0.11624007672071457
[10/24] Train loss=0.12300152331590652
[15/24] Train loss=0.12409753352403641
[20/24] Train loss=0.12504252791404724
Test set avg_accuracy=89.04% avg_sensitivity=75.86%, avg_specificity=94.06% avg_auc=92.96%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.126284 Test loss=0.287258 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1246461272239685
[5/24] Train loss=0.12122191488742828
[10/24] Train loss=0.1215503141283989
[15/24] Train loss=0.12113020569086075
[20/24] Train loss=0.12669920921325684
Test set avg_accuracy=89.18% avg_sensitivity=75.44%, avg_specificity=94.42% avg_auc=93.21%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.126406 Test loss=0.281786 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1279812455177307
[5/24] Train loss=0.11403702199459076
[10/24] Train loss=0.12075502425432205
[15/24] Train loss=0.12083975225687027
[20/24] Train loss=0.12431580573320389
Test set avg_accuracy=89.53% avg_sensitivity=76.24%, avg_specificity=94.60% avg_auc=93.23%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.125367 Test loss=0.283198 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12519153952598572
[5/24] Train loss=0.11075174808502197
[10/24] Train loss=0.12134423106908798
[15/24] Train loss=0.12493626773357391
[20/24] Train loss=0.12282053381204605
Test set avg_accuracy=89.32% avg_sensitivity=77.23%, avg_specificity=93.94% avg_auc=93.23%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.124059 Test loss=0.282253 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12333948165178299
[5/24] Train loss=0.1127430647611618
[10/24] Train loss=0.12245523929595947
[15/24] Train loss=0.11913776397705078
[20/24] Train loss=0.12017549574375153
Test set avg_accuracy=89.31% avg_sensitivity=75.25%, avg_specificity=94.68% avg_auc=92.95%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.123449 Test loss=0.285171 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1267005056142807
[5/24] Train loss=0.11398012936115265
[10/24] Train loss=0.11833754181861877
[15/24] Train loss=0.1211126446723938
[20/24] Train loss=0.12160957604646683
Test set avg_accuracy=89.43% avg_sensitivity=76.00%, avg_specificity=94.55% avg_auc=92.83%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.123440 Test loss=0.285456 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12190212309360504
[5/24] Train loss=0.11101919412612915
[10/24] Train loss=0.11895283311605453
[15/24] Train loss=0.11731167882680893
[20/24] Train loss=0.11994393169879913
Test set avg_accuracy=89.30% avg_sensitivity=76.24%, avg_specificity=94.28% avg_auc=92.90%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.121897 Test loss=0.286549 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12124684453010559
[5/24] Train loss=0.11122459173202515
[10/24] Train loss=0.11738448590040207
[15/24] Train loss=0.11731253564357758
[20/24] Train loss=0.11965791881084442
Test set avg_accuracy=89.32% avg_sensitivity=75.95%, avg_specificity=94.42% avg_auc=92.89%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.121525 Test loss=0.286227 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.11955247819423676
[5/24] Train loss=0.11008614301681519
[10/24] Train loss=0.11992456763982773
[15/24] Train loss=0.11653272807598114
[20/24] Train loss=0.11953723430633545
Test set avg_accuracy=89.28% avg_sensitivity=75.72%, avg_specificity=94.46% avg_auc=92.70%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.121422 Test loss=0.287914 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12174570560455322
[5/24] Train loss=0.11148464679718018
[10/24] Train loss=0.1170848160982132
[15/24] Train loss=0.11687695235013962
[20/24] Train loss=0.11898103356361389
Test set avg_accuracy=89.30% avg_sensitivity=75.44%, avg_specificity=94.59% avg_auc=92.81%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.121291 Test loss=0.287025 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12125127017498016
[5/24] Train loss=0.11022862046957016
[10/24] Train loss=0.11863807588815689
[15/24] Train loss=0.11508016288280487
[20/24] Train loss=0.11959583312273026
Test set avg_accuracy=89.19% avg_sensitivity=76.14%, avg_specificity=94.17% avg_auc=92.87%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.120446 Test loss=0.287050 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.11899960041046143
[5/24] Train loss=0.10929226130247116
[10/24] Train loss=0.11731022596359253
[15/24] Train loss=0.11794889718294144
[20/24] Train loss=0.11950446665287018
Test set avg_accuracy=89.19% avg_sensitivity=75.25%, avg_specificity=94.51% avg_auc=92.82%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.120787 Test loss=0.287554 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12078963965177536
[5/24] Train loss=0.11001668125391006
[10/24] Train loss=0.11630265414714813
[15/24] Train loss=0.11919252574443817
[20/24] Train loss=0.1196935698390007
Test set avg_accuracy=89.26% avg_sensitivity=75.67%, avg_specificity=94.44% avg_auc=92.77%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.120738 Test loss=0.288594 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1223825141787529
[5/24] Train loss=0.10873878747224808
[10/24] Train loss=0.11685572564601898
[15/24] Train loss=0.11573614180088043
[20/24] Train loss=0.11927581578493118
Test set avg_accuracy=89.36% avg_sensitivity=75.95%, avg_specificity=94.48% avg_auc=92.87%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.120533 Test loss=0.286784 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12121989578008652
[5/24] Train loss=0.11145702749490738
[10/24] Train loss=0.11528139561414719
[15/24] Train loss=0.11816791445016861
[20/24] Train loss=0.11945652961730957
Test set avg_accuracy=89.35% avg_sensitivity=75.72%, avg_specificity=94.55% avg_auc=92.79%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.120452 Test loss=0.287119 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11961357295513153
[5/24] Train loss=0.1094813197851181
[10/24] Train loss=0.11882168054580688
[15/24] Train loss=0.11745850741863251
[20/24] Train loss=0.11776081472635269
Test set avg_accuracy=89.36% avg_sensitivity=75.81%, avg_specificity=94.53% avg_auc=92.88%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.120500 Test loss=0.286467 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12179142981767654
[5/24] Train loss=0.11298337578773499
[10/24] Train loss=0.11747816205024719
[15/24] Train loss=0.1157178282737732
[20/24] Train loss=0.11971526592969894
Test set avg_accuracy=89.34% avg_sensitivity=75.62%, avg_specificity=94.57% avg_auc=92.86%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.120326 Test loss=0.286915 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12286043912172318
[5/24] Train loss=0.11014352738857269
[10/24] Train loss=0.11566533148288727
[15/24] Train loss=0.11495579779148102
[20/24] Train loss=0.11842870712280273
Test set avg_accuracy=89.31% avg_sensitivity=75.62%, avg_specificity=94.53% avg_auc=92.87%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.120308 Test loss=0.286756 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1188388466835022
[5/24] Train loss=0.10857919603586197
[10/24] Train loss=0.11608647555112839
[15/24] Train loss=0.11658753454685211
[20/24] Train loss=0.11841075122356415
Test set avg_accuracy=89.28% avg_sensitivity=75.67%, avg_specificity=94.48% avg_auc=92.86%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.119944 Test loss=0.286808 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12122507393360138
[5/24] Train loss=0.10963470488786697
[10/24] Train loss=0.11796118319034576
[15/24] Train loss=0.11316592246294022
[20/24] Train loss=0.11862251907587051
Test set avg_accuracy=89.31% avg_sensitivity=75.62%, avg_specificity=94.53% avg_auc=92.86%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.120004 Test loss=0.286871 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=89.66% sen=82.27%, spe=92.48%, auc=95.11%!
Fold[7] Avg_overlap=0.74%(0.20462157156347396)
[0/24] Train loss=0.7576534748077393
[5/24] Train loss=0.7538456916809082
[10/24] Train loss=0.7543845772743225
[15/24] Train loss=0.7335790991783142
[20/24] Train loss=0.7357263565063477
Test set avg_accuracy=55.53% avg_sensitivity=49.66%, avg_specificity=57.51% avg_auc=55.44%
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.743815 Test loss=0.686024 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7149572372436523
[5/24] Train loss=0.7167173624038696
[10/24] Train loss=0.7149004936218262
[15/24] Train loss=0.7136752009391785
[20/24] Train loss=0.6955273151397705
Test set avg_accuracy=61.08% avg_sensitivity=65.77%, avg_specificity=59.51% avg_auc=66.69%
Best model saved!! Metric=-72.95046064059856!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.712743 Test loss=0.657167 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6952084302902222
[5/24] Train loss=0.6896937489509583
[10/24] Train loss=0.6852208971977234
[15/24] Train loss=0.6715662479400635
[20/24] Train loss=0.6784225702285767
Test set avg_accuracy=66.45% avg_sensitivity=72.86%, avg_specificity=64.29% avg_auc=74.70%
Best model saved!! Metric=-47.69788922224579!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.684364 Test loss=0.620296 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6592240333557129
[5/24] Train loss=0.6619663238525391
[10/24] Train loss=0.6622065305709839
[15/24] Train loss=0.6412762999534607
[20/24] Train loss=0.6337308287620544
Test set avg_accuracy=70.34% avg_sensitivity=77.94%, avg_specificity=67.79% avg_auc=79.28%
Best model saved!! Metric=-30.659852668276784!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.653527 Test loss=0.594544 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6192743182182312
[5/24] Train loss=0.6271534562110901
[10/24] Train loss=0.6249788999557495
[15/24] Train loss=0.5988001227378845
[20/24] Train loss=0.601513147354126
Test set avg_accuracy=72.96% avg_sensitivity=80.58%, avg_specificity=70.39% avg_auc=82.10%
Best model saved!! Metric=-19.96564747335242!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.620728 Test loss=0.566181 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5884233117103577
[5/24] Train loss=0.5941656231880188
[10/24] Train loss=0.5966944694519043
[15/24] Train loss=0.5717670321464539
[20/24] Train loss=0.5618221759796143
Test set avg_accuracy=75.05% avg_sensitivity=81.98%, avg_specificity=72.73% avg_auc=84.56%
Best model saved!! Metric=-11.685113751085197!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.588739 Test loss=0.536094 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5575000047683716
[5/24] Train loss=0.5604413151741028
[10/24] Train loss=0.5688644051551819
[15/24] Train loss=0.5436966419219971
[20/24] Train loss=0.5284839868545532
Test set avg_accuracy=77.21% avg_sensitivity=82.03%, avg_specificity=75.60% avg_auc=86.49%
Best model saved!! Metric=-4.671209505694051!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.558550 Test loss=0.503134 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5257432460784912
[5/24] Train loss=0.5256682634353638
[10/24] Train loss=0.5362146496772766
[15/24] Train loss=0.510197103023529
[20/24] Train loss=0.501613438129425
Test set avg_accuracy=80.40% avg_sensitivity=81.20%, avg_specificity=80.14% avg_auc=88.16%
Best model saved!! Metric=3.896188115921561!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.528050 Test loss=0.463019 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.49095162749290466
[5/24] Train loss=0.504088282585144
[10/24] Train loss=0.5092231631278992
[15/24] Train loss=0.483578085899353
[20/24] Train loss=0.46333709359169006
Test set avg_accuracy=82.34% avg_sensitivity=83.74%, avg_specificity=81.88% avg_auc=89.85%
Best model saved!! Metric=11.805537919075206!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.499003 Test loss=0.439712 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4703062176704407
[5/24] Train loss=0.4687814712524414
[10/24] Train loss=0.4813978374004364
[15/24] Train loss=0.45799702405929565
[20/24] Train loss=0.4324832558631897
Test set avg_accuracy=84.53% avg_sensitivity=82.44%, avg_specificity=85.23% avg_auc=90.97%
Best model saved!! Metric=17.175002152334343!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.469478 Test loss=0.409146 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4442901909351349
[5/24] Train loss=0.44312262535095215
[10/24] Train loss=0.445239782333374
[15/24] Train loss=0.43173131346702576
[20/24] Train loss=0.4030923843383789
Test set avg_accuracy=86.59% avg_sensitivity=80.79%, avg_specificity=88.54% avg_auc=92.16%
Best model saved!! Metric=22.070776345266566!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.441510 Test loss=0.372826 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4181777834892273
[5/24] Train loss=0.4114340543746948
[10/24] Train loss=0.43219709396362305
[15/24] Train loss=0.4082449674606323
[20/24] Train loss=0.37888672947883606
Test set avg_accuracy=87.68% avg_sensitivity=79.65%, avg_specificity=90.38% avg_auc=92.75%
Best model saved!! Metric=24.458525733987855!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.416882 Test loss=0.349189 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.39731866121292114
[5/24] Train loss=0.3916762173175812
[10/24] Train loss=0.4127407371997833
[15/24] Train loss=0.3890730142593384
[20/24] Train loss=0.35770976543426514
Test set avg_accuracy=88.57% avg_sensitivity=76.70%, avg_specificity=92.56% avg_auc=93.10%
Best model saved!! Metric=24.9158491263328!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.395137 Test loss=0.327532 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.37214764952659607
[5/24] Train loss=0.3746247887611389
[10/24] Train loss=0.38624346256256104
[15/24] Train loss=0.3725874125957489
[20/24] Train loss=0.34014034271240234
Test set avg_accuracy=88.98% avg_sensitivity=74.11%, avg_specificity=93.98% avg_auc=93.21%
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.375589 Test loss=0.312140 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.35519295930862427
[5/24] Train loss=0.3486539125442505
[10/24] Train loss=0.371345579624176
[15/24] Train loss=0.3524767756462097
[20/24] Train loss=0.3143327832221985
Test set avg_accuracy=89.11% avg_sensitivity=72.66%, avg_specificity=94.64% avg_auc=93.46%
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.358083 Test loss=0.301938 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.34211695194244385
[5/24] Train loss=0.3393920958042145
[10/24] Train loss=0.3566937744617462
[15/24] Train loss=0.33847659826278687
[20/24] Train loss=0.30330225825309753
Test set avg_accuracy=89.32% avg_sensitivity=75.19%, avg_specificity=94.07% avg_auc=93.88%
Best model saved!! Metric=26.467052962542837!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.343749 Test loss=0.290598 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.32540106773376465
[5/24] Train loss=0.31912314891815186
[10/24] Train loss=0.33853596448898315
[15/24] Train loss=0.32832422852516174
[20/24] Train loss=0.2894154489040375
Test set avg_accuracy=89.53% avg_sensitivity=77.89%, avg_specificity=93.44% avg_auc=94.17%
Best model saved!! Metric=29.029363332298615!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.331691 Test loss=0.286465 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.31369203329086304
[5/24] Train loss=0.3085769712924957
[10/24] Train loss=0.3256185054779053
[15/24] Train loss=0.3186706602573395
[20/24] Train loss=0.2737824618816376
Test set avg_accuracy=89.47% avg_sensitivity=74.68%, avg_specificity=94.43% avg_auc=94.11%
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.319198 Test loss=0.278321 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.30292901396751404
[5/24] Train loss=0.29747551679611206
[10/24] Train loss=0.3180871605873108
[15/24] Train loss=0.31268712878227234
[20/24] Train loss=0.2630002796649933
Test set avg_accuracy=89.47% avg_sensitivity=77.94%, avg_specificity=93.34% avg_auc=94.33%
Best model saved!! Metric=29.069737622741414!!
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.308963 Test loss=0.275360 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2945455312728882
[5/24] Train loss=0.2934851050376892
[10/24] Train loss=0.3089601993560791
[15/24] Train loss=0.30061450600624084
[20/24] Train loss=0.2602635324001312
Test set avg_accuracy=89.82% avg_sensitivity=76.95%, avg_specificity=94.14% avg_auc=94.71%
Best model saved!! Metric=29.62049717310994!!
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.301978 Test loss=0.265149 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.28428399562835693
[5/24] Train loss=0.2785656154155731
[10/24] Train loss=0.29732897877693176
[15/24] Train loss=0.30423274636268616
[20/24] Train loss=0.24593116343021393
Test set avg_accuracy=89.99% avg_sensitivity=76.39%, avg_specificity=94.56% avg_auc=94.83%
Best model saved!! Metric=29.75372274011052!!
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.293401 Test loss=0.259775 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.27866417169570923
[5/24] Train loss=0.2742207944393158
[10/24] Train loss=0.2945949137210846
[15/24] Train loss=0.29052481055259705
[20/24] Train loss=0.24031361937522888
Test set avg_accuracy=90.00% avg_sensitivity=74.83%, avg_specificity=95.09% avg_auc=94.90%
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.286179 Test loss=0.256748 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.27496975660324097
[5/24] Train loss=0.26828932762145996
[10/24] Train loss=0.29165831208229065
[15/24] Train loss=0.2807409465312958
[20/24] Train loss=0.23406754434108734
Test set avg_accuracy=89.90% avg_sensitivity=75.09%, avg_specificity=94.87% avg_auc=94.87%
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.278325 Test loss=0.256287 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2691143751144409
[5/24] Train loss=0.255230188369751
[10/24] Train loss=0.2816058099269867
[15/24] Train loss=0.28136515617370605
[20/24] Train loss=0.22864088416099548
Test set avg_accuracy=89.49% avg_sensitivity=80.99%, avg_specificity=92.35% avg_auc=94.58%
Best model saved!! Metric=31.413918242085686!!
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.273546 Test loss=0.269689 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.26446568965911865
[5/24] Train loss=0.25049516558647156
[10/24] Train loss=0.2726343870162964
[15/24] Train loss=0.2672053873538971
[20/24] Train loss=0.22435596585273743
Test set avg_accuracy=89.92% avg_sensitivity=78.51%, avg_specificity=93.76% avg_auc=94.84%
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.266364 Test loss=0.255473 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.25872302055358887
[5/24] Train loss=0.24747617542743683
[10/24] Train loss=0.27092215418815613
[15/24] Train loss=0.27201730012893677
[20/24] Train loss=0.21911457180976868
Test set avg_accuracy=89.11% avg_sensitivity=74.05%, avg_specificity=94.17% avg_auc=93.71%
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.260819 Test loss=0.270533 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.25474390387535095
[5/24] Train loss=0.23819726705551147
[10/24] Train loss=0.26992157101631165
[15/24] Train loss=0.2662893235683441
[20/24] Train loss=0.21583901345729828
Test set avg_accuracy=90.16% avg_sensitivity=78.87%, avg_specificity=93.95% avg_auc=94.91%
Best model saved!! Metric=31.8850757368336!!
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.255968 Test loss=0.253762 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.25752323865890503
[5/24] Train loss=0.24103987216949463
[10/24] Train loss=0.2609370946884155
[15/24] Train loss=0.25555357336997986
[20/24] Train loss=0.21069253981113434
Test set avg_accuracy=89.79% avg_sensitivity=80.22%, avg_specificity=93.01% avg_auc=95.05%
Best model saved!! Metric=32.06464395882449!!
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.250975 Test loss=0.255630 Current lr=[0.000210185142098938]

[0/24] Train loss=0.24298551678657532
[5/24] Train loss=0.22520659863948822
[10/24] Train loss=0.26227155327796936
[15/24] Train loss=0.2605854272842407
[20/24] Train loss=0.20706325769424438
Test set avg_accuracy=88.85% avg_sensitivity=74.57%, avg_specificity=93.65% avg_auc=93.41%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.245688 Test loss=0.273592 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2423940896987915
[5/24] Train loss=0.2172316610813141
[10/24] Train loss=0.26024994254112244
[15/24] Train loss=0.2466227114200592
[20/24] Train loss=0.201038658618927
Test set avg_accuracy=88.62% avg_sensitivity=76.13%, avg_specificity=92.82% avg_auc=93.89%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.241607 Test loss=0.269782 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2370750606060028
[5/24] Train loss=0.21677352488040924
[10/24] Train loss=0.25597745180130005
[15/24] Train loss=0.24405783414840698
[20/24] Train loss=0.20066796243190765
Test set avg_accuracy=89.13% avg_sensitivity=80.06%, avg_specificity=92.17% avg_auc=94.46%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.240437 Test loss=0.265706 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2293609231710434
[5/24] Train loss=0.20396408438682556
[10/24] Train loss=0.2555455267429352
[15/24] Train loss=0.23807312548160553
[20/24] Train loss=0.20882266759872437
Test set avg_accuracy=89.74% avg_sensitivity=79.03%, avg_specificity=93.34% avg_auc=94.68%
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.235847 Test loss=0.259027 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.23257675766944885
[5/24] Train loss=0.20650871098041534
[10/24] Train loss=0.25244301557540894
[15/24] Train loss=0.23771226406097412
[20/24] Train loss=0.19757524132728577
Test set avg_accuracy=89.13% avg_sensitivity=76.70%, avg_specificity=93.30% avg_auc=93.56%
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.234489 Test loss=0.273947 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.23170770704746246
[5/24] Train loss=0.1984717845916748
[10/24] Train loss=0.2550508379936218
[15/24] Train loss=0.24434514343738556
[20/24] Train loss=0.2011122852563858
Test set avg_accuracy=88.78% avg_sensitivity=79.08%, avg_specificity=92.03% avg_auc=94.25%
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.231432 Test loss=0.274397 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.22031860053539276
[5/24] Train loss=0.20483459532260895
[10/24] Train loss=0.24322734773159027
[15/24] Train loss=0.2271459400653839
[20/24] Train loss=0.19174577295780182
Test set avg_accuracy=89.09% avg_sensitivity=69.39%, avg_specificity=95.70% avg_auc=93.74%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.225912 Test loss=0.269062 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.22571958601474762
[5/24] Train loss=0.19571009278297424
[10/24] Train loss=0.23960299789905548
[15/24] Train loss=0.22087788581848145
[20/24] Train loss=0.19983671605587006
Test set avg_accuracy=88.46% avg_sensitivity=67.48%, avg_specificity=95.51% avg_auc=92.46%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.222900 Test loss=0.286358 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.21947956085205078
[5/24] Train loss=0.19509357213974
[10/24] Train loss=0.23800621926784515
[15/24] Train loss=0.23040083050727844
[20/24] Train loss=0.1941906213760376
Test set avg_accuracy=87.27% avg_sensitivity=58.93%, avg_specificity=96.78% avg_auc=90.52%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.225442 Test loss=0.326588 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.23391038179397583
[5/24] Train loss=0.20840251445770264
[10/24] Train loss=0.2420138120651245
[15/24] Train loss=0.22132375836372375
[20/24] Train loss=0.20063620805740356
Test set avg_accuracy=83.24% avg_sensitivity=37.03%, avg_specificity=98.77% avg_auc=86.35%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.225360 Test loss=0.449602 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.23026283085346222
[5/24] Train loss=0.20400944352149963
[10/24] Train loss=0.24504441022872925
[15/24] Train loss=0.23108626902103424
[20/24] Train loss=0.18862874805927277
Test set avg_accuracy=88.50% avg_sensitivity=75.09%, avg_specificity=93.01% avg_auc=93.50%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.226749 Test loss=0.274602 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.22418038547039032
[5/24] Train loss=0.19011567533016205
[10/24] Train loss=0.2376212179660797
[15/24] Train loss=0.23558934032917023
[20/24] Train loss=0.18256433308124542
Test set avg_accuracy=85.99% avg_sensitivity=81.46%, avg_specificity=87.51% avg_auc=92.94%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.219134 Test loss=0.313401 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.21793785691261292
[5/24] Train loss=0.18206074833869934
[10/24] Train loss=0.24823330342769623
[15/24] Train loss=0.22088830173015594
[20/24] Train loss=0.17938143014907837
Test set avg_accuracy=88.16% avg_sensitivity=71.98%, avg_specificity=93.60% avg_auc=92.96%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.216852 Test loss=0.284185 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.20941798388957977
[5/24] Train loss=0.18808960914611816
[10/24] Train loss=0.22455909848213196
[15/24] Train loss=0.22088722884655
[20/24] Train loss=0.18812355399131775
Test set avg_accuracy=88.10% avg_sensitivity=78.97%, avg_specificity=91.16% avg_auc=93.82%
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.212317 Test loss=0.277819 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.21362334489822388
[5/24] Train loss=0.1890542060136795
[10/24] Train loss=0.2246812880039215
[15/24] Train loss=0.2166295349597931
[20/24] Train loss=0.17143514752388
Test set avg_accuracy=88.49% avg_sensitivity=72.86%, avg_specificity=93.74% avg_auc=92.30%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.208949 Test loss=0.291230 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.213233083486557
[5/24] Train loss=0.20095588266849518
[10/24] Train loss=0.24218818545341492
[15/24] Train loss=0.22080101072788239
[20/24] Train loss=0.18091781437397003
Test set avg_accuracy=88.19% avg_sensitivity=79.49%, avg_specificity=91.11% avg_auc=93.08%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.218385 Test loss=0.289383 Current lr=[0.00029967723776099]

[0/24] Train loss=0.21581639349460602
[5/24] Train loss=0.1860564649105072
[10/24] Train loss=0.20630459487438202
[15/24] Train loss=0.2282005399465561
[20/24] Train loss=0.18087728321552277
Test set avg_accuracy=68.85% avg_sensitivity=90.94%, avg_specificity=61.44% avg_auc=87.42%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.210189 Test loss=0.616980 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.20326651632785797
[5/24] Train loss=0.18436971306800842
[10/24] Train loss=0.23969818651676178
[15/24] Train loss=0.21826565265655518
[20/24] Train loss=0.17878974974155426
Test set avg_accuracy=77.92% avg_sensitivity=87.36%, avg_specificity=74.74% avg_auc=90.58%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.210364 Test loss=0.452808 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.20525039732456207
[5/24] Train loss=0.18197259306907654
[10/24] Train loss=0.213715061545372
[15/24] Train loss=0.20144303143024445
[20/24] Train loss=0.18572697043418884
Test set avg_accuracy=88.57% avg_sensitivity=77.11%, avg_specificity=92.42% avg_auc=93.25%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.200478 Test loss=0.281237 Current lr=[0.000299720220882401]

[0/24] Train loss=0.20357543230056763
[5/24] Train loss=0.17728164792060852
[10/24] Train loss=0.20974183082580566
[15/24] Train loss=0.20760083198547363
[20/24] Train loss=0.17875713109970093
Test set avg_accuracy=88.03% avg_sensitivity=65.25%, avg_specificity=95.69% avg_auc=91.42%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.205242 Test loss=0.303919 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2064853012561798
[5/24] Train loss=0.17592987418174744
[10/24] Train loss=0.21639569103717804
[15/24] Train loss=0.20731788873672485
[20/24] Train loss=0.16969744861125946
Test set avg_accuracy=85.65% avg_sensitivity=52.82%, avg_specificity=96.68% avg_auc=89.81%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.200477 Test loss=0.359502 Current lr=[0.000298904600941902]

[0/24] Train loss=0.24004895985126495
[5/24] Train loss=0.17678290605545044
[10/24] Train loss=0.21219342947006226
[15/24] Train loss=0.2171563357114792
[20/24] Train loss=0.17345789074897766
Test set avg_accuracy=87.89% avg_sensitivity=77.06%, avg_specificity=91.53% avg_auc=92.61%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.202692 Test loss=0.297484 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.20422331988811493
[5/24] Train loss=0.16720767319202423
[10/24] Train loss=0.19824635982513428
[15/24] Train loss=0.2123824506998062
[20/24] Train loss=0.17338238656520844
Test set avg_accuracy=87.16% avg_sensitivity=59.61%, avg_specificity=96.42% avg_auc=90.44%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.197968 Test loss=0.334123 Current lr=[0.000297555943323901]

[0/24] Train loss=0.19772639870643616
[5/24] Train loss=0.17109009623527527
[10/24] Train loss=0.2088768184185028
[15/24] Train loss=0.21383464336395264
[20/24] Train loss=0.17256365716457367
Test set avg_accuracy=88.54% avg_sensitivity=76.59%, avg_specificity=92.56% avg_auc=92.80%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.195909 Test loss=0.284386 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.19814737141132355
[5/24] Train loss=0.2010372430086136
[10/24] Train loss=0.21037474274635315
[15/24] Train loss=0.2158481478691101
[20/24] Train loss=0.17995145916938782
Test set avg_accuracy=84.13% avg_sensitivity=42.62%, avg_specificity=98.07% avg_auc=85.94%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.203850 Test loss=0.452179 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.21507418155670166
[5/24] Train loss=0.17123089730739594
[10/24] Train loss=0.2041085958480835
[15/24] Train loss=0.21639694273471832
[20/24] Train loss=0.16513672471046448
Test set avg_accuracy=84.31% avg_sensitivity=82.50%, avg_specificity=84.92% avg_auc=91.93%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.197134 Test loss=0.354686 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.20073188841342926
[5/24] Train loss=0.1640911102294922
[10/24] Train loss=0.1911131888628006
[15/24] Train loss=0.20337684452533722
[20/24] Train loss=0.167562335729599
Test set avg_accuracy=85.53% avg_sensitivity=53.70%, avg_specificity=96.23% avg_auc=87.29%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.192456 Test loss=0.389660 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2036544531583786
[5/24] Train loss=0.16515201330184937
[10/24] Train loss=0.20243051648139954
[15/24] Train loss=0.2043115794658661
[20/24] Train loss=0.17040832340717316
Test set avg_accuracy=87.43% avg_sensitivity=64.99%, avg_specificity=94.97% avg_auc=91.13%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.195210 Test loss=0.314912 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.21141685545444489
[5/24] Train loss=0.16148678958415985
[10/24] Train loss=0.1907663494348526
[15/24] Train loss=0.19711129367351532
[20/24] Train loss=0.16253866255283356
Test set avg_accuracy=86.89% avg_sensitivity=85.86%, avg_specificity=87.23% avg_auc=93.68%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.193268 Test loss=0.309497 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.19145210087299347
[5/24] Train loss=0.16286475956439972
[10/24] Train loss=0.18313410878181458
[15/24] Train loss=0.2073836773633957
[20/24] Train loss=0.1594209372997284
Test set avg_accuracy=87.66% avg_sensitivity=74.52%, avg_specificity=92.07% avg_auc=92.38%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.187595 Test loss=0.298680 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.18457888066768646
[5/24] Train loss=0.16584931313991547
[10/24] Train loss=0.19058957695960999
[15/24] Train loss=0.19400915503501892
[20/24] Train loss=0.16498737037181854
Test set avg_accuracy=88.31% avg_sensitivity=67.74%, avg_specificity=95.22% avg_auc=92.16%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.189266 Test loss=0.290380 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.20451197028160095
[5/24] Train loss=0.16457152366638184
[10/24] Train loss=0.1924806386232376
[15/24] Train loss=0.19575339555740356
[20/24] Train loss=0.16814035177230835
Test set avg_accuracy=88.45% avg_sensitivity=71.52%, avg_specificity=94.14% avg_auc=93.06%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.190405 Test loss=0.287646 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.18850262463092804
[5/24] Train loss=0.1624930202960968
[10/24] Train loss=0.18684887886047363
[15/24] Train loss=0.192290797829628
[20/24] Train loss=0.15414725244045258
Test set avg_accuracy=89.22% avg_sensitivity=79.75%, avg_specificity=92.40% avg_auc=93.94%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.183806 Test loss=0.269120 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.18504808843135834
[5/24] Train loss=0.17944258451461792
[10/24] Train loss=0.19281019270420074
[15/24] Train loss=0.19794905185699463
[20/24] Train loss=0.15950511395931244
Test set avg_accuracy=89.22% avg_sensitivity=74.83%, avg_specificity=94.05% avg_auc=92.97%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.187801 Test loss=0.283411 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.18209916353225708
[5/24] Train loss=0.15554073452949524
[10/24] Train loss=0.19804897904396057
[15/24] Train loss=0.19483859837055206
[20/24] Train loss=0.1626945436000824
Test set avg_accuracy=84.53% avg_sensitivity=88.50%, avg_specificity=83.20% avg_auc=93.23%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.185980 Test loss=0.341161 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.18584854900836945
[5/24] Train loss=0.16169361770153046
[10/24] Train loss=0.20174406468868256
[15/24] Train loss=0.18752145767211914
[20/24] Train loss=0.15634728968143463
Test set avg_accuracy=88.54% avg_sensitivity=76.23%, avg_specificity=92.68% avg_auc=92.84%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.182906 Test loss=0.285801 Current lr=[0.000276307469034998]

[0/24] Train loss=0.17384006083011627
[5/24] Train loss=0.1641523838043213
[10/24] Train loss=0.17868083715438843
[15/24] Train loss=0.19529354572296143
[20/24] Train loss=0.1592663824558258
Test set avg_accuracy=88.87% avg_sensitivity=73.85%, avg_specificity=93.91% avg_auc=93.66%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.183001 Test loss=0.275233 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.18541795015335083
[5/24] Train loss=0.15647657215595245
[10/24] Train loss=0.18091002106666565
[15/24] Train loss=0.1893831342458725
[20/24] Train loss=0.15491555631160736
Test set avg_accuracy=87.33% avg_sensitivity=64.47%, avg_specificity=95.01% avg_auc=91.74%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.181378 Test loss=0.307169 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.18330810964107513
[5/24] Train loss=0.16700543463230133
[10/24] Train loss=0.1822025328874588
[15/24] Train loss=0.19643090665340424
[20/24] Train loss=0.15694524347782135
Test set avg_accuracy=88.27% avg_sensitivity=69.45%, avg_specificity=94.59% avg_auc=93.02%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.179045 Test loss=0.288433 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.18116523325443268
[5/24] Train loss=0.1558191031217575
[10/24] Train loss=0.1906113475561142
[15/24] Train loss=0.19449011981487274
[20/24] Train loss=0.14853042364120483
Test set avg_accuracy=86.85% avg_sensitivity=57.43%, avg_specificity=96.73% avg_auc=88.52%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.180133 Test loss=0.361110 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.17386481165885925
[5/24] Train loss=0.16091597080230713
[10/24] Train loss=0.17782828211784363
[15/24] Train loss=0.18659304082393646
[20/24] Train loss=0.15499429404735565
Test set avg_accuracy=87.50% avg_sensitivity=61.89%, avg_specificity=96.10% avg_auc=90.97%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.175886 Test loss=0.325187 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.1748976707458496
[5/24] Train loss=0.15743450820446014
[10/24] Train loss=0.18675696849822998
[15/24] Train loss=0.19371096789836884
[20/24] Train loss=0.15755261480808258
Test set avg_accuracy=88.33% avg_sensitivity=80.48%, avg_specificity=90.97% avg_auc=93.59%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.181531 Test loss=0.283240 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.17899981141090393
[5/24] Train loss=0.1554652601480484
[10/24] Train loss=0.17712926864624023
[15/24] Train loss=0.19898271560668945
[20/24] Train loss=0.15660332143306732
Test set avg_accuracy=86.47% avg_sensitivity=75.71%, avg_specificity=90.09% avg_auc=91.12%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.180334 Test loss=0.326976 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.18240316212177277
[5/24] Train loss=0.15924394130706787
[10/24] Train loss=0.16954714059829712
[15/24] Train loss=0.18486440181732178
[20/24] Train loss=0.1523825079202652
Test set avg_accuracy=87.75% avg_sensitivity=78.61%, avg_specificity=90.82% avg_auc=93.25%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.178658 Test loss=0.290899 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.1805996298789978
[5/24] Train loss=0.1565915197134018
[10/24] Train loss=0.1746753603219986
[15/24] Train loss=0.1769280582666397
[20/24] Train loss=0.1447831392288208
Test set avg_accuracy=87.32% avg_sensitivity=76.95%, avg_specificity=90.80% avg_auc=92.26%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.173762 Test loss=0.308011 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1716957539319992
[5/24] Train loss=0.16059322655200958
[10/24] Train loss=0.17240262031555176
[15/24] Train loss=0.1788906753063202
[20/24] Train loss=0.14956431090831757
Test set avg_accuracy=88.50% avg_sensitivity=71.10%, avg_specificity=94.35% avg_auc=93.27%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.173475 Test loss=0.280559 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.1771537810564041
[5/24] Train loss=0.153232142329216
[10/24] Train loss=0.17754508554935455
[15/24] Train loss=0.1781606674194336
[20/24] Train loss=0.14344827830791473
Test set avg_accuracy=86.63% avg_sensitivity=80.53%, avg_specificity=88.68% avg_auc=92.88%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.170159 Test loss=0.311971 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.18078544735908508
[5/24] Train loss=0.1672823429107666
[10/24] Train loss=0.16980816423892975
[15/24] Train loss=0.17610926926136017
[20/24] Train loss=0.14543794095516205
Test set avg_accuracy=87.29% avg_sensitivity=63.44%, avg_specificity=95.30% avg_auc=90.50%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.171660 Test loss=0.328646 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.16776907444000244
[5/24] Train loss=0.15891782939434052
[10/24] Train loss=0.1704796403646469
[15/24] Train loss=0.17811760306358337
[20/24] Train loss=0.14449982345104218
Test set avg_accuracy=88.50% avg_sensitivity=67.84%, avg_specificity=95.44% avg_auc=91.39%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.170646 Test loss=0.302904 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.16390781104564667
[5/24] Train loss=0.14983268082141876
[10/24] Train loss=0.18259111046791077
[15/24] Train loss=0.17868618667125702
[20/24] Train loss=0.14182819426059723
Test set avg_accuracy=88.57% avg_sensitivity=71.93%, avg_specificity=94.16% avg_auc=93.27%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.168822 Test loss=0.284532 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.17851942777633667
[5/24] Train loss=0.14789055287837982
[10/24] Train loss=0.17455697059631348
[15/24] Train loss=0.1675817221403122
[20/24] Train loss=0.14677628874778748
Test set avg_accuracy=86.98% avg_sensitivity=56.65%, avg_specificity=97.16% avg_auc=89.72%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.168123 Test loss=0.351588 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.1698414534330368
[5/24] Train loss=0.15016411244869232
[10/24] Train loss=0.16835492849349976
[15/24] Train loss=0.17175178229808807
[20/24] Train loss=0.14677412807941437
Test set avg_accuracy=86.84% avg_sensitivity=62.61%, avg_specificity=94.97% avg_auc=90.61%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.167654 Test loss=0.319900 Current lr=[0.000224838296036774]

[0/24] Train loss=0.1676202118396759
[5/24] Train loss=0.14582808315753937
[10/24] Train loss=0.16785851120948792
[15/24] Train loss=0.16903404891490936
[20/24] Train loss=0.13932335376739502
Test set avg_accuracy=85.79% avg_sensitivity=58.36%, avg_specificity=95.01% avg_auc=89.44%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.164263 Test loss=0.354305 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.1709602177143097
[5/24] Train loss=0.147212952375412
[10/24] Train loss=0.17425213754177094
[15/24] Train loss=0.17761000990867615
[20/24] Train loss=0.1437302976846695
Test set avg_accuracy=86.43% avg_sensitivity=53.50%, avg_specificity=97.50% avg_auc=88.50%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.165351 Test loss=0.356054 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.18441222608089447
[5/24] Train loss=0.15404878556728363
[10/24] Train loss=0.17119638621807098
[15/24] Train loss=0.17466120421886444
[20/24] Train loss=0.14087516069412231
Test set avg_accuracy=87.23% avg_sensitivity=69.39%, avg_specificity=93.22% avg_auc=91.95%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.166725 Test loss=0.302040 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.165852352976799
[5/24] Train loss=0.1432562619447708
[10/24] Train loss=0.17102496325969696
[15/24] Train loss=0.17635565996170044
[20/24] Train loss=0.14460112154483795
Test set avg_accuracy=84.97% avg_sensitivity=45.62%, avg_specificity=98.19% avg_auc=88.35%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.169186 Test loss=0.390913 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.1866801679134369
[5/24] Train loss=0.14837954938411713
[10/24] Train loss=0.16562491655349731
[15/24] Train loss=0.18079152703285217
[20/24] Train loss=0.14754614233970642
Test set avg_accuracy=87.97% avg_sensitivity=68.57%, avg_specificity=94.49% avg_auc=92.05%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.170344 Test loss=0.303560 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.17167901992797852
[5/24] Train loss=0.14660461246967316
[10/24] Train loss=0.17834189534187317
[15/24] Train loss=0.16970501840114594
[20/24] Train loss=0.13623347878456116
Test set avg_accuracy=88.03% avg_sensitivity=67.12%, avg_specificity=95.06% avg_auc=90.70%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.168127 Test loss=0.310723 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.166836678981781
[5/24] Train loss=0.14215295016765594
[10/24] Train loss=0.17720481753349304
[15/24] Train loss=0.1673959195613861
[20/24] Train loss=0.13934575021266937
Test set avg_accuracy=87.55% avg_sensitivity=66.44%, avg_specificity=94.64% avg_auc=90.82%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.165912 Test loss=0.312499 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1725195050239563
[5/24] Train loss=0.14452297985553741
[10/24] Train loss=0.16530410945415497
[15/24] Train loss=0.16967704892158508
[20/24] Train loss=0.13935136795043945
Test set avg_accuracy=88.29% avg_sensitivity=75.92%, avg_specificity=92.45% avg_auc=92.55%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.164387 Test loss=0.289370 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.17121364176273346
[5/24] Train loss=0.14488033950328827
[10/24] Train loss=0.17015767097473145
[15/24] Train loss=0.16920283436775208
[20/24] Train loss=0.1452273726463318
Test set avg_accuracy=88.54% avg_sensitivity=71.26%, avg_specificity=94.35% avg_auc=92.03%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.165091 Test loss=0.290142 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.17081484198570251
[5/24] Train loss=0.14273495972156525
[10/24] Train loss=0.16269655525684357
[15/24] Train loss=0.1751282513141632
[20/24] Train loss=0.1444479078054428
Test set avg_accuracy=87.08% avg_sensitivity=58.05%, avg_specificity=96.83% avg_auc=89.51%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.166023 Test loss=0.347319 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1619000881910324
[5/24] Train loss=0.1493034064769745
[10/24] Train loss=0.16862663626670837
[15/24] Train loss=0.164469376206398
[20/24] Train loss=0.14118093252182007
Test set avg_accuracy=89.08% avg_sensitivity=76.85%, avg_specificity=93.18% avg_auc=93.90%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.162373 Test loss=0.267608 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.1760193407535553
[5/24] Train loss=0.1407446265220642
[10/24] Train loss=0.15916195511817932
[15/24] Train loss=0.16313835978507996
[20/24] Train loss=0.14463552832603455
Test set avg_accuracy=88.70% avg_sensitivity=77.58%, avg_specificity=92.43% avg_auc=93.44%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.160529 Test loss=0.280652 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.16846922039985657
[5/24] Train loss=0.1378989964723587
[10/24] Train loss=0.15696485340595245
[15/24] Train loss=0.16132231056690216
[20/24] Train loss=0.13938184082508087
Test set avg_accuracy=88.35% avg_sensitivity=66.08%, avg_specificity=95.83% avg_auc=90.89%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.158489 Test loss=0.312700 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.16421394050121307
[5/24] Train loss=0.14591361582279205
[10/24] Train loss=0.15391163527965546
[15/24] Train loss=0.15795990824699402
[20/24] Train loss=0.13180431723594666
Test set avg_accuracy=88.10% avg_sensitivity=66.44%, avg_specificity=95.37% avg_auc=91.49%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.158141 Test loss=0.306785 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.16564573347568512
[5/24] Train loss=0.13565099239349365
[10/24] Train loss=0.14673875272274017
[15/24] Train loss=0.15900474786758423
[20/24] Train loss=0.1351180523633957
Test set avg_accuracy=89.14% avg_sensitivity=68.98%, avg_specificity=95.91% avg_auc=91.21%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.154248 Test loss=0.296129 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.16653570532798767
[5/24] Train loss=0.1392744481563568
[10/24] Train loss=0.15426136553287506
[15/24] Train loss=0.15474355220794678
[20/24] Train loss=0.13890404999256134
Test set avg_accuracy=88.84% avg_sensitivity=73.80%, avg_specificity=93.89% avg_auc=91.96%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.155776 Test loss=0.291205 Current lr=[0.000156543481933168]

[0/24] Train loss=0.16386611759662628
[5/24] Train loss=0.13659484684467316
[10/24] Train loss=0.1511501669883728
[15/24] Train loss=0.16251114010810852
[20/24] Train loss=0.13632088899612427
Test set avg_accuracy=88.53% avg_sensitivity=68.57%, avg_specificity=95.23% avg_auc=90.88%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.156001 Test loss=0.308025 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.166007399559021
[5/24] Train loss=0.1416185349225998
[10/24] Train loss=0.15361487865447998
[15/24] Train loss=0.15134328603744507
[20/24] Train loss=0.13689157366752625
Test set avg_accuracy=89.06% avg_sensitivity=71.05%, avg_specificity=95.11% avg_auc=91.82%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.155306 Test loss=0.292673 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.16372868418693542
[5/24] Train loss=0.1368231326341629
[10/24] Train loss=0.15264877676963806
[15/24] Train loss=0.14977465569972992
[20/24] Train loss=0.13456840813159943
Test set avg_accuracy=87.55% avg_sensitivity=60.02%, avg_specificity=96.80% avg_auc=88.66%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.153229 Test loss=0.342103 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.159450501203537
[5/24] Train loss=0.14140450954437256
[10/24] Train loss=0.1493953913450241
[15/24] Train loss=0.1551854908466339
[20/24] Train loss=0.13134953379631042
Test set avg_accuracy=89.27% avg_sensitivity=72.14%, avg_specificity=95.03% avg_auc=92.59%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.151599 Test loss=0.280811 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15489462018013
[5/24] Train loss=0.1399463713169098
[10/24] Train loss=0.14520052075386047
[15/24] Train loss=0.15611913800239563
[20/24] Train loss=0.12986455857753754
Test set avg_accuracy=89.21% avg_sensitivity=72.81%, avg_specificity=94.71% avg_auc=92.92%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.148839 Test loss=0.279398 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1583203375339508
[5/24] Train loss=0.13467662036418915
[10/24] Train loss=0.15742865204811096
[15/24] Train loss=0.1493273228406906
[20/24] Train loss=0.12849336862564087
Test set avg_accuracy=88.62% avg_sensitivity=67.74%, avg_specificity=95.63% avg_auc=91.36%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.148528 Test loss=0.300559 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1537250578403473
[5/24] Train loss=0.14085102081298828
[10/24] Train loss=0.14552177488803864
[15/24] Train loss=0.14839789271354675
[20/24] Train loss=0.12902289628982544
Test set avg_accuracy=88.59% avg_sensitivity=69.24%, avg_specificity=95.09% avg_auc=91.71%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.149444 Test loss=0.297406 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.15010233223438263
[5/24] Train loss=0.13463431596755981
[10/24] Train loss=0.153748020529747
[15/24] Train loss=0.15713104605674744
[20/24] Train loss=0.12908527255058289
Test set avg_accuracy=89.22% avg_sensitivity=73.49%, avg_specificity=94.50% avg_auc=92.74%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.148096 Test loss=0.282390 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.1532086580991745
[5/24] Train loss=0.13257929682731628
[10/24] Train loss=0.14406733214855194
[15/24] Train loss=0.1534663587808609
[20/24] Train loss=0.12823817133903503
Test set avg_accuracy=89.56% avg_sensitivity=79.34%, avg_specificity=92.99% avg_auc=93.54%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.147330 Test loss=0.267802 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14938682317733765
[5/24] Train loss=0.1389218419790268
[10/24] Train loss=0.14645320177078247
[15/24] Train loss=0.14752033352851868
[20/24] Train loss=0.12892507016658783
Test set avg_accuracy=89.45% avg_sensitivity=77.68%, avg_specificity=93.41% avg_auc=93.80%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.146510 Test loss=0.266062 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15243394672870636
[5/24] Train loss=0.14362135529518127
[10/24] Train loss=0.14577814936637878
[15/24] Train loss=0.15371614694595337
[20/24] Train loss=0.12818798422813416
Test set avg_accuracy=89.40% avg_sensitivity=68.00%, avg_specificity=96.59% avg_auc=91.97%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.147547 Test loss=0.287192 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.14872802793979645
[5/24] Train loss=0.14490023255348206
[10/24] Train loss=0.13942761719226837
[15/24] Train loss=0.14911989867687225
[20/24] Train loss=0.12847647070884705
Test set avg_accuracy=88.26% avg_sensitivity=81.87%, avg_specificity=90.40% avg_auc=93.55%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.146466 Test loss=0.286884 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.14369405806064606
[5/24] Train loss=0.13680681586265564
[10/24] Train loss=0.1421116292476654
[15/24] Train loss=0.1435805708169937
[20/24] Train loss=0.1317836046218872
Test set avg_accuracy=89.44% avg_sensitivity=71.26%, avg_specificity=95.55% avg_auc=92.84%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.147695 Test loss=0.282618 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14841042459011078
[5/24] Train loss=0.13158321380615234
[10/24] Train loss=0.1659645140171051
[15/24] Train loss=0.14401252567768097
[20/24] Train loss=0.12944772839546204
Test set avg_accuracy=89.08% avg_sensitivity=77.84%, avg_specificity=92.85% avg_auc=93.23%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.145597 Test loss=0.277854 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15167346596717834
[5/24] Train loss=0.1302574723958969
[10/24] Train loss=0.1489289551973343
[15/24] Train loss=0.14977972209453583
[20/24] Train loss=0.12033972889184952
Test set avg_accuracy=88.20% avg_sensitivity=80.32%, avg_specificity=90.85% avg_auc=92.75%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.144236 Test loss=0.297731 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1491665542125702
[5/24] Train loss=0.13101640343666077
[10/24] Train loss=0.1369793713092804
[15/24] Train loss=0.1419718712568283
[20/24] Train loss=0.12056569010019302
Test set avg_accuracy=89.61% avg_sensitivity=73.43%, avg_specificity=95.04% avg_auc=92.70%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.141253 Test loss=0.274050 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14149126410484314
[5/24] Train loss=0.12834008038043976
[10/24] Train loss=0.1431291252374649
[15/24] Train loss=0.14099745452404022
[20/24] Train loss=0.12199027091264725
Test set avg_accuracy=88.63% avg_sensitivity=73.49%, avg_specificity=93.72% avg_auc=92.84%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.140609 Test loss=0.284426 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1460220366716385
[5/24] Train loss=0.12813760340213776
[10/24] Train loss=0.13845524191856384
[15/24] Train loss=0.1466497927904129
[20/24] Train loss=0.12153845280408859
Test set avg_accuracy=89.51% avg_sensitivity=76.07%, avg_specificity=94.02% avg_auc=91.93%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.139988 Test loss=0.280241 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14524851739406586
[5/24] Train loss=0.12888318300247192
[10/24] Train loss=0.13847027719020844
[15/24] Train loss=0.1515408605337143
[20/24] Train loss=0.12545722723007202
Test set avg_accuracy=89.34% avg_sensitivity=74.83%, avg_specificity=94.21% avg_auc=93.04%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.141482 Test loss=0.274173 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14202287793159485
[5/24] Train loss=0.12698283791542053
[10/24] Train loss=0.13086296617984772
[15/24] Train loss=0.1384308636188507
[20/24] Train loss=0.12072426080703735
Test set avg_accuracy=89.11% avg_sensitivity=71.00%, avg_specificity=95.20% avg_auc=91.97%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.137745 Test loss=0.289327 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1393933892250061
[5/24] Train loss=0.12536311149597168
[10/24] Train loss=0.13319000601768494
[15/24] Train loss=0.14014632999897003
[20/24] Train loss=0.12116824090480804
Test set avg_accuracy=89.09% avg_sensitivity=73.43%, avg_specificity=94.35% avg_auc=92.35%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.136281 Test loss=0.282217 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.13974791765213013
[5/24] Train loss=0.12564857304096222
[10/24] Train loss=0.13214097917079926
[15/24] Train loss=0.13737472891807556
[20/24] Train loss=0.12302415817975998
Test set avg_accuracy=88.96% avg_sensitivity=70.43%, avg_specificity=95.18% avg_auc=90.94%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.135923 Test loss=0.300944 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13821256160736084
[5/24] Train loss=0.12205368280410767
[10/24] Train loss=0.1358552873134613
[15/24] Train loss=0.13698938488960266
[20/24] Train loss=0.11919999867677689
Test set avg_accuracy=89.19% avg_sensitivity=72.55%, avg_specificity=94.78% avg_auc=92.70%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.134629 Test loss=0.279851 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14106953144073486
[5/24] Train loss=0.12387066334486008
[10/24] Train loss=0.13165323436260223
[15/24] Train loss=0.13270138204097748
[20/24] Train loss=0.11946023255586624
Test set avg_accuracy=88.91% avg_sensitivity=74.94%, avg_specificity=93.60% avg_auc=92.26%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.134006 Test loss=0.289129 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13643907010555267
[5/24] Train loss=0.12284518033266068
[10/24] Train loss=0.1333453208208084
[15/24] Train loss=0.13606898486614227
[20/24] Train loss=0.11668796092271805
Test set avg_accuracy=89.21% avg_sensitivity=75.50%, avg_specificity=93.81% avg_auc=92.82%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.132433 Test loss=0.277451 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.13396987318992615
[5/24] Train loss=0.12673932313919067
[10/24] Train loss=0.12727104127407074
[15/24] Train loss=0.13549131155014038
[20/24] Train loss=0.11709193885326385
Test set avg_accuracy=89.38% avg_sensitivity=75.04%, avg_specificity=94.19% avg_auc=92.98%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.131806 Test loss=0.275317 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1355108618736267
[5/24] Train loss=0.1209549829363823
[10/24] Train loss=0.12735258042812347
[15/24] Train loss=0.13351787626743317
[20/24] Train loss=0.11635580658912659
Test set avg_accuracy=88.61% avg_sensitivity=74.21%, avg_specificity=93.44% avg_auc=92.72%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.131120 Test loss=0.284589 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13159234821796417
[5/24] Train loss=0.11973825097084045
[10/24] Train loss=0.125083789229393
[15/24] Train loss=0.13026314973831177
[20/24] Train loss=0.11453675478696823
Test set avg_accuracy=88.96% avg_sensitivity=73.23%, avg_specificity=94.24% avg_auc=92.23%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.129827 Test loss=0.285536 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13477548956871033
[5/24] Train loss=0.1186179369688034
[10/24] Train loss=0.12914276123046875
[15/24] Train loss=0.1323280930519104
[20/24] Train loss=0.11421733349561691
Test set avg_accuracy=89.44% avg_sensitivity=73.69%, avg_specificity=94.73% avg_auc=92.95%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.130100 Test loss=0.277940 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13421565294265747
[5/24] Train loss=0.12030758708715439
[10/24] Train loss=0.12887290120124817
[15/24] Train loss=0.13485293090343475
[20/24] Train loss=0.11652740091085434
Test set avg_accuracy=89.24% avg_sensitivity=72.50%, avg_specificity=94.87% avg_auc=92.54%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.129578 Test loss=0.277230 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13216248154640198
[5/24] Train loss=0.11711849272251129
[10/24] Train loss=0.1255183070898056
[15/24] Train loss=0.12937133014202118
[20/24] Train loss=0.11494392156600952
Test set avg_accuracy=88.96% avg_sensitivity=71.78%, avg_specificity=94.73% avg_auc=92.47%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.128658 Test loss=0.284217 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1318821907043457
[5/24] Train loss=0.11862801760435104
[10/24] Train loss=0.124227374792099
[15/24] Train loss=0.12968610227108002
[20/24] Train loss=0.11444667726755142
Test set avg_accuracy=89.15% avg_sensitivity=70.90%, avg_specificity=95.29% avg_auc=92.35%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.128566 Test loss=0.280717 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13003641366958618
[5/24] Train loss=0.12104711681604385
[10/24] Train loss=0.1253121793270111
[15/24] Train loss=0.1303907334804535
[20/24] Train loss=0.11330584436655045
Test set avg_accuracy=89.21% avg_sensitivity=77.16%, avg_specificity=93.25% avg_auc=93.12%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.129024 Test loss=0.276807 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12970110774040222
[5/24] Train loss=0.12059693038463593
[10/24] Train loss=0.12309898436069489
[15/24] Train loss=0.12696754932403564
[20/24] Train loss=0.11441226303577423
Test set avg_accuracy=89.35% avg_sensitivity=77.68%, avg_specificity=93.27% avg_auc=92.81%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.128197 Test loss=0.281079 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1271587461233139
[5/24] Train loss=0.12047050148248672
[10/24] Train loss=0.12227259576320648
[15/24] Train loss=0.12517006695270538
[20/24] Train loss=0.11111272871494293
Test set avg_accuracy=88.88% avg_sensitivity=78.51%, avg_specificity=92.36% avg_auc=92.89%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.128059 Test loss=0.281168 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1283729374408722
[5/24] Train loss=0.11799152195453644
[10/24] Train loss=0.12392513453960419
[15/24] Train loss=0.12513525784015656
[20/24] Train loss=0.11351116746664047
Test set avg_accuracy=89.13% avg_sensitivity=74.37%, avg_specificity=94.09% avg_auc=92.49%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.127463 Test loss=0.283031 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13028499484062195
[5/24] Train loss=0.11398269981145859
[10/24] Train loss=0.12363065779209137
[15/24] Train loss=0.12605968117713928
[20/24] Train loss=0.11267455667257309
Test set avg_accuracy=89.02% avg_sensitivity=76.44%, avg_specificity=93.25% avg_auc=93.11%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.126741 Test loss=0.275334 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1294052004814148
[5/24] Train loss=0.11471410095691681
[10/24] Train loss=0.1219262182712555
[15/24] Train loss=0.12466166168451309
[20/24] Train loss=0.11023583263158798
Test set avg_accuracy=89.26% avg_sensitivity=76.13%, avg_specificity=93.67% avg_auc=92.77%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.125641 Test loss=0.276810 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1256914585828781
[5/24] Train loss=0.11702623963356018
[10/24] Train loss=0.11717530339956284
[15/24] Train loss=0.12209808826446533
[20/24] Train loss=0.10908885300159454
Test set avg_accuracy=89.13% avg_sensitivity=76.18%, avg_specificity=93.48% avg_auc=92.79%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.123784 Test loss=0.276768 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12514807283878326
[5/24] Train loss=0.11518571525812149
[10/24] Train loss=0.12015977501869202
[15/24] Train loss=0.12088540196418762
[20/24] Train loss=0.11029677838087082
Test set avg_accuracy=89.23% avg_sensitivity=75.66%, avg_specificity=93.79% avg_auc=92.99%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.123437 Test loss=0.273179 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12785345315933228
[5/24] Train loss=0.11465876549482346
[10/24] Train loss=0.11831348389387131
[15/24] Train loss=0.12151698023080826
[20/24] Train loss=0.10963338613510132
Test set avg_accuracy=89.11% avg_sensitivity=75.50%, avg_specificity=93.69% avg_auc=92.83%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.123532 Test loss=0.276281 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1242363229393959
[5/24] Train loss=0.1139078289270401
[10/24] Train loss=0.11876652389764786
[15/24] Train loss=0.12183288484811783
[20/24] Train loss=0.11144859343767166
Test set avg_accuracy=89.31% avg_sensitivity=76.23%, avg_specificity=93.70% avg_auc=92.89%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.122866 Test loss=0.275904 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12610208988189697
[5/24] Train loss=0.11304069310426712
[10/24] Train loss=0.1189793273806572
[15/24] Train loss=0.1203245148062706
[20/24] Train loss=0.11111491918563843
Test set avg_accuracy=89.36% avg_sensitivity=76.33%, avg_specificity=93.74% avg_auc=93.09%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.123013 Test loss=0.274504 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12175726145505905
[5/24] Train loss=0.11444192379713058
[10/24] Train loss=0.11687199771404266
[15/24] Train loss=0.12023967504501343
[20/24] Train loss=0.1100725382566452
Test set avg_accuracy=89.28% avg_sensitivity=75.50%, avg_specificity=93.91% avg_auc=92.73%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.122552 Test loss=0.275212 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12317988276481628
[5/24] Train loss=0.11283789575099945
[10/24] Train loss=0.11715980619192123
[15/24] Train loss=0.12083545327186584
[20/24] Train loss=0.10846861451864243
Test set avg_accuracy=89.35% avg_sensitivity=75.71%, avg_specificity=93.93% avg_auc=92.85%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.122230 Test loss=0.275583 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12352687865495682
[5/24] Train loss=0.11074481159448624
[10/24] Train loss=0.11708881705999374
[15/24] Train loss=0.12151290476322174
[20/24] Train loss=0.11022960394620895
Test set avg_accuracy=89.39% avg_sensitivity=76.44%, avg_specificity=93.74% avg_auc=92.98%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.121702 Test loss=0.273478 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12517422437667847
[5/24] Train loss=0.11143770813941956
[10/24] Train loss=0.11543186753988266
[15/24] Train loss=0.12237129360437393
[20/24] Train loss=0.10853229463100433
Test set avg_accuracy=89.47% avg_sensitivity=75.61%, avg_specificity=94.12% avg_auc=92.77%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.121763 Test loss=0.274708 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12193681299686432
[5/24] Train loss=0.11212779581546783
[10/24] Train loss=0.11702219396829605
[15/24] Train loss=0.12219791859388351
[20/24] Train loss=0.10911343991756439
Test set avg_accuracy=89.35% avg_sensitivity=75.97%, avg_specificity=93.84% avg_auc=92.82%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.121199 Test loss=0.275335 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12218663841485977
[5/24] Train loss=0.11363288015127182
[10/24] Train loss=0.11707139760255814
[15/24] Train loss=0.11946835368871689
[20/24] Train loss=0.10857414454221725
Test set avg_accuracy=89.41% avg_sensitivity=75.50%, avg_specificity=94.09% avg_auc=92.83%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.120705 Test loss=0.274915 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12241675704717636
[5/24] Train loss=0.1115303710103035
[10/24] Train loss=0.11587735265493393
[15/24] Train loss=0.11978217959403992
[20/24] Train loss=0.10815945267677307
Test set avg_accuracy=89.39% avg_sensitivity=75.71%, avg_specificity=93.98% avg_auc=92.88%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.120603 Test loss=0.274668 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12253168970346451
[5/24] Train loss=0.11074434220790863
[10/24] Train loss=0.11618560552597046
[15/24] Train loss=0.12249152362346649
[20/24] Train loss=0.10922128707170486
Test set avg_accuracy=89.36% avg_sensitivity=75.56%, avg_specificity=94.00% avg_auc=92.87%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.121144 Test loss=0.274640 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12289952486753464
[5/24] Train loss=0.11318626999855042
[10/24] Train loss=0.11751031130552292
[15/24] Train loss=0.12035681307315826
[20/24] Train loss=0.10953439772129059
Test set avg_accuracy=89.39% avg_sensitivity=75.82%, avg_specificity=93.95% avg_auc=92.88%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.121179 Test loss=0.274567 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1234755888581276
[5/24] Train loss=0.11507820338010788
[10/24] Train loss=0.11573506891727448
[15/24] Train loss=0.12085236608982086
[20/24] Train loss=0.10679034143686295
Test set avg_accuracy=89.40% avg_sensitivity=75.92%, avg_specificity=93.93% avg_auc=92.88%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.120507 Test loss=0.274635 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12378183007240295
[5/24] Train loss=0.11243046820163727
[10/24] Train loss=0.11727315932512283
[15/24] Train loss=0.12149452418088913
[20/24] Train loss=0.11024477332830429
Test set avg_accuracy=89.36% avg_sensitivity=75.76%, avg_specificity=93.93% avg_auc=92.87%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.121012 Test loss=0.274652 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=89.79% sen=80.22%, spe=93.01%, auc=95.05%!
Fold[8] Avg_overlap=0.70%(0.22916735158971466)
[0/23] Train loss=0.727591335773468
[5/23] Train loss=0.7242757678031921
[10/23] Train loss=0.7273313403129578
[15/23] Train loss=0.7120803594589233
[20/23] Train loss=0.7024338245391846
Test set avg_accuracy=60.73% avg_sensitivity=46.15%, avg_specificity=65.37% avg_auc=58.20%
Best model saved!! Metric=-95.55641805390064!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.719165 Test loss=0.673189 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.7006435990333557
[5/23] Train loss=0.6903331279754639
[10/23] Train loss=0.6984859704971313
[15/23] Train loss=0.6857298612594604
[20/23] Train loss=0.6746131777763367
Test set avg_accuracy=63.44% avg_sensitivity=58.11%, avg_specificity=65.13% avg_auc=67.15%
Best model saved!! Metric=-72.16357353978923!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.691684 Test loss=0.641413 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.6678149700164795
[5/23] Train loss=0.6747764945030212
[10/23] Train loss=0.6699459552764893
[15/23] Train loss=0.6535706520080566
[20/23] Train loss=0.6515017747879028
Test set avg_accuracy=67.71% avg_sensitivity=62.91%, avg_specificity=69.24% avg_auc=72.45%
Best model saved!! Metric=-53.69589372958673!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.665804 Test loss=0.608308 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.6486995816230774
[5/23] Train loss=0.6480075120925903
[10/23] Train loss=0.6494049429893494
[15/23] Train loss=0.6344759464263916
[20/23] Train loss=0.6192069053649902
Test set avg_accuracy=70.53% avg_sensitivity=68.03%, avg_specificity=71.33% avg_auc=76.59%
Best model saved!! Metric=-39.50961031281689!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.641461 Test loss=0.583662 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.6225907802581787
[5/23] Train loss=0.614913821220398
[10/23] Train loss=0.6258638501167297
[15/23] Train loss=0.601919949054718
[20/23] Train loss=0.597493588924408
Test set avg_accuracy=72.89% avg_sensitivity=73.05%, avg_specificity=72.84% avg_auc=79.73%
Best model saved!! Metric=-27.495867833427795!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.613997 Test loss=0.557578 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.5900216698646545
[5/23] Train loss=0.5885757207870483
[10/23] Train loss=0.6006560921669006
[15/23] Train loss=0.5702298879623413
[20/23] Train loss=0.569607675075531
Test set avg_accuracy=73.98% avg_sensitivity=77.04%, avg_specificity=73.01% avg_auc=81.94%
Best model saved!! Metric=-20.023574747232303!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.586423 Test loss=0.537327 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.5631940364837646
[5/23] Train loss=0.5594831109046936
[10/23] Train loss=0.567334771156311
[15/23] Train loss=0.5416102409362793
[20/23] Train loss=0.540067195892334
Test set avg_accuracy=75.99% avg_sensitivity=76.93%, avg_specificity=75.69% avg_auc=84.19%
Best model saved!! Metric=-13.201129622024538!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.556534 Test loss=0.504199 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.5350009202957153
[5/23] Train loss=0.5230734944343567
[10/23] Train loss=0.5371508598327637
[15/23] Train loss=0.5139533281326294
[20/23] Train loss=0.5077565908432007
Test set avg_accuracy=78.26% avg_sensitivity=78.44%, avg_specificity=78.20% avg_auc=86.26%
Best model saved!! Metric=-4.851014264216488!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.528638 Test loss=0.475124 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.5056461095809937
[5/23] Train loss=0.4981995224952698
[10/23] Train loss=0.506373941898346
[15/23] Train loss=0.4860316812992096
[20/23] Train loss=0.4805920422077179
Test set avg_accuracy=81.16% avg_sensitivity=78.33%, avg_specificity=82.06% avg_auc=88.37%
Best model saved!! Metric=3.9193553061458317!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.498814 Test loss=0.443068 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.46884211897850037
[5/23] Train loss=0.47686219215393066
[10/23] Train loss=0.4755420982837677
[15/23] Train loss=0.4601703882217407
[20/23] Train loss=0.4482366740703583
Test set avg_accuracy=83.63% avg_sensitivity=73.64%, avg_specificity=86.82% avg_auc=89.55%
Best model saved!! Metric=7.639212092795262!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.468394 Test loss=0.407876 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.4437313675880432
[5/23] Train loss=0.43487149477005005
[10/23] Train loss=0.45115071535110474
[15/23] Train loss=0.4291841983795166
[20/23] Train loss=0.41834378242492676
Test set avg_accuracy=85.43% avg_sensitivity=72.83%, avg_specificity=89.44% avg_auc=90.60%
Best model saved!! Metric=12.301642429838154!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.439610 Test loss=0.382802 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.4156215786933899
[5/23] Train loss=0.4076054096221924
[10/23] Train loss=0.4241480231285095
[15/23] Train loss=0.40713879466056824
[20/23] Train loss=0.3916051685810089
Test set avg_accuracy=86.86% avg_sensitivity=71.97%, avg_specificity=91.61% avg_auc=91.54%
Best model saved!! Metric=15.972023936052281!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.413986 Test loss=0.356270 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.3948507606983185
[5/23] Train loss=0.38966333866119385
[10/23] Train loss=0.40688470005989075
[15/23] Train loss=0.38349077105522156
[20/23] Train loss=0.36931338906288147
Test set avg_accuracy=87.51% avg_sensitivity=69.38%, avg_specificity=93.29% avg_auc=91.86%
Best model saved!! Metric=16.03581157405266!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.391169 Test loss=0.338098 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.3674556314945221
[5/23] Train loss=0.36740195751190186
[10/23] Train loss=0.38946521282196045
[15/23] Train loss=0.35914281010627747
[20/23] Train loss=0.3463824987411499
Test set avg_accuracy=87.86% avg_sensitivity=71.00%, avg_specificity=93.24% avg_auc=92.14%
Best model saved!! Metric=18.23997521006136!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.372068 Test loss=0.326716 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.35023730993270874
[5/23] Train loss=0.3404550552368164
[10/23] Train loss=0.36905500292778015
[15/23] Train loss=0.34133246541023254
[20/23] Train loss=0.33240434527397156
Test set avg_accuracy=88.23% avg_sensitivity=72.18%, avg_specificity=93.34% avg_auc=92.59%
Best model saved!! Metric=20.339843066143786!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.354694 Test loss=0.317867 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.3388921916484833
[5/23] Train loss=0.3255859911441803
[10/23] Train loss=0.3585016131401062
[15/23] Train loss=0.327368825674057
[20/23] Train loss=0.30788055062294006
Test set avg_accuracy=88.40% avg_sensitivity=69.11%, avg_specificity=94.54% avg_auc=92.87%
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.338600 Test loss=0.302204 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.320496141910553
[5/23] Train loss=0.3151547312736511
[10/23] Train loss=0.34710121154785156
[15/23] Train loss=0.3151709735393524
[20/23] Train loss=0.29285579919815063
Test set avg_accuracy=88.40% avg_sensitivity=69.43%, avg_specificity=94.44% avg_auc=92.67%
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.327709 Test loss=0.297318 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.3127891719341278
[5/23] Train loss=0.29610058665275574
[10/23] Train loss=0.33423101902008057
[15/23] Train loss=0.304242342710495
[20/23] Train loss=0.2890062630176544
Test set avg_accuracy=88.82% avg_sensitivity=69.81%, avg_specificity=94.87% avg_auc=93.00%
Best model saved!! Metric=20.495999091646112!!
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.317488 Test loss=0.291811 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.3013504445552826
[5/23] Train loss=0.28731220960617065
[10/23] Train loss=0.32875654101371765
[15/23] Train loss=0.2963729798793793
[20/23] Train loss=0.2759666442871094
Test set avg_accuracy=88.65% avg_sensitivity=76.01%, avg_specificity=92.67% avg_auc=93.63%
Best model saved!! Metric=24.952958259585316!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.308271 Test loss=0.286192 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.2907857298851013
[5/23] Train loss=0.2806164622306824
[10/23] Train loss=0.3170779049396515
[15/23] Train loss=0.2817147672176361
[20/23] Train loss=0.26490330696105957
Test set avg_accuracy=89.13% avg_sensitivity=71.75%, avg_specificity=94.66% avg_auc=93.46%
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.297904 Test loss=0.277921 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.27777591347694397
[5/23] Train loss=0.2684503495693207
[10/23] Train loss=0.31271079182624817
[15/23] Train loss=0.2769411504268646
[20/23] Train loss=0.2605528235435486
Test set avg_accuracy=89.40% avg_sensitivity=70.89%, avg_specificity=95.30% avg_auc=93.73%
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.291568 Test loss=0.271859 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.28010234236717224
[5/23] Train loss=0.2659235894680023
[10/23] Train loss=0.3192419707775116
[15/23] Train loss=0.27067410945892334
[20/23] Train loss=0.25962620973587036
Test set avg_accuracy=90.03% avg_sensitivity=68.73%, avg_specificity=96.81% avg_auc=93.73%
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.286541 Test loss=0.269316 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.26731765270233154
[5/23] Train loss=0.2523259222507477
[10/23] Train loss=0.29777953028678894
[15/23] Train loss=0.2601548731327057
[20/23] Train loss=0.24538804590702057
Test set avg_accuracy=89.65% avg_sensitivity=69.11%, avg_specificity=96.19% avg_auc=93.97%
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.277888 Test loss=0.265522 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.26492440700531006
[5/23] Train loss=0.24972303211688995
[10/23] Train loss=0.29997915029525757
[15/23] Train loss=0.2614608407020569
[20/23] Train loss=0.2408093512058258
Test set avg_accuracy=89.79% avg_sensitivity=70.94%, avg_specificity=95.79% avg_auc=94.04%
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.274096 Test loss=0.262562 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.26536116003990173
[5/23] Train loss=0.2480437308549881
[10/23] Train loss=0.28540530800819397
[15/23] Train loss=0.2532269358634949
[20/23] Train loss=0.24136656522750854
Test set avg_accuracy=89.38% avg_sensitivity=64.37%, avg_specificity=97.34% avg_auc=93.54%
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.269281 Test loss=0.275031 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.25422853231430054
[5/23] Train loss=0.2364053875207901
[10/23] Train loss=0.28283533453941345
[15/23] Train loss=0.2490999400615692
[20/23] Train loss=0.2343738079071045
Test set avg_accuracy=89.47% avg_sensitivity=63.29%, avg_specificity=97.80% avg_auc=93.43%
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.263734 Test loss=0.275740 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.25543564558029175
[5/23] Train loss=0.23236402869224548
[10/23] Train loss=0.2822253108024597
[15/23] Train loss=0.23887313902378082
[20/23] Train loss=0.23016037046909332
Test set avg_accuracy=89.91% avg_sensitivity=66.04%, avg_specificity=97.51% avg_auc=94.11%
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.257843 Test loss=0.263807 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.24231845140457153
[5/23] Train loss=0.21885618567466736
[10/23] Train loss=0.27486833930015564
[15/23] Train loss=0.23998866975307465
[20/23] Train loss=0.21999669075012207
Test set avg_accuracy=88.59% avg_sensitivity=58.76%, avg_specificity=98.09% avg_auc=92.88%
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.252223 Test loss=0.291790 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.23961281776428223
[5/23] Train loss=0.2388429194688797
[10/23] Train loss=0.2657316327095032
[15/23] Train loss=0.2424333691596985
[20/23] Train loss=0.21428607404232025
Test set avg_accuracy=88.24% avg_sensitivity=81.73%, avg_specificity=90.32% avg_auc=93.93%
Best model saved!! Metric=28.21133711303979!!
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.250643 Test loss=0.283287 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.23801566660404205
[5/23] Train loss=0.20819368958473206
[10/23] Train loss=0.25702211260795593
[15/23] Train loss=0.23093120753765106
[20/23] Train loss=0.21554963290691376
Test set avg_accuracy=86.61% avg_sensitivity=85.50%, avg_specificity=86.97% avg_auc=93.61%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.244555 Test loss=0.313970 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.2332681566476822
[5/23] Train loss=0.21853038668632507
[10/23] Train loss=0.2596893906593323
[15/23] Train loss=0.23541121184825897
[20/23] Train loss=0.21350251138210297
Test set avg_accuracy=90.36% avg_sensitivity=71.48%, avg_specificity=96.38% avg_auc=94.38%
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.242164 Test loss=0.250128 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.2311544120311737
[5/23] Train loss=0.19984038174152374
[10/23] Train loss=0.25904756784439087
[15/23] Train loss=0.22902870178222656
[20/23] Train loss=0.212538942694664
Test set avg_accuracy=87.72% avg_sensitivity=82.43%, avg_specificity=89.41% avg_auc=93.82%
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.235203 Test loss=0.293845 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.22476442158222198
[5/23] Train loss=0.2053978145122528
[10/23] Train loss=0.24424400925636292
[15/23] Train loss=0.22729381918907166
[20/23] Train loss=0.2068713903427124
Test set avg_accuracy=89.51% avg_sensitivity=63.40%, avg_specificity=97.82% avg_auc=93.11%
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.231458 Test loss=0.279289 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.22202931344509125
[5/23] Train loss=0.2024519145488739
[10/23] Train loss=0.23913536965847015
[15/23] Train loss=0.22856026887893677
[20/23] Train loss=0.20372451841831207
Test set avg_accuracy=90.09% avg_sensitivity=71.70%, avg_specificity=95.95% avg_auc=94.06%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.228711 Test loss=0.254130 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.22022520005702972
[5/23] Train loss=0.1938718557357788
[10/23] Train loss=0.24256132543087006
[15/23] Train loss=0.21343733370304108
[20/23] Train loss=0.20649009943008423
Test set avg_accuracy=89.57% avg_sensitivity=80.00%, avg_specificity=92.62% avg_auc=94.31%
Best model saved!! Metric=30.497642648190137!!
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.228311 Test loss=0.259220 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.2195960283279419
[5/23] Train loss=0.1947421282529831
[10/23] Train loss=0.23017072677612305
[15/23] Train loss=0.2122071236371994
[20/23] Train loss=0.19519339501857758
Test set avg_accuracy=88.29% avg_sensitivity=81.56%, avg_specificity=90.44% avg_auc=93.56%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.222877 Test loss=0.280834 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.21490396559238434
[5/23] Train loss=0.1939343959093094
[10/23] Train loss=0.2326481193304062
[15/23] Train loss=0.217119961977005
[20/23] Train loss=0.19517463445663452
Test set avg_accuracy=89.23% avg_sensitivity=82.21%, avg_specificity=91.47% avg_auc=94.23%
Best model saved!! Metric=31.13712349346777!!
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.218276 Test loss=0.266973 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.21658776700496674
[5/23] Train loss=0.18280112743377686
[10/23] Train loss=0.23024627566337585
[15/23] Train loss=0.21472452580928802
[20/23] Train loss=0.1976584792137146
Test set avg_accuracy=88.55% avg_sensitivity=58.54%, avg_specificity=98.11% avg_auc=90.62%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.219533 Test loss=0.314633 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.21078279614448547
[5/23] Train loss=0.18168145418167114
[10/23] Train loss=0.2245672196149826
[15/23] Train loss=0.21313904225826263
[20/23] Train loss=0.19235002994537354
Test set avg_accuracy=88.36% avg_sensitivity=57.47%, avg_specificity=98.20% avg_auc=91.11%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.220629 Test loss=0.315260 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.2174580693244934
[5/23] Train loss=0.1844344288110733
[10/23] Train loss=0.21628428995609283
[15/23] Train loss=0.21623589098453522
[20/23] Train loss=0.19555361568927765
Test set avg_accuracy=86.34% avg_sensitivity=47.44%, avg_specificity=98.73% avg_auc=87.90%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.214129 Test loss=0.370282 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.21119138598442078
[5/23] Train loss=0.17273324728012085
[10/23] Train loss=0.21554486453533173
[15/23] Train loss=0.2231539487838745
[20/23] Train loss=0.18442904949188232
Test set avg_accuracy=88.78% avg_sensitivity=59.84%, avg_specificity=97.99% avg_auc=91.19%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.212680 Test loss=0.301751 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.19803500175476074
[5/23] Train loss=0.16428042948246002
[10/23] Train loss=0.21817006170749664
[15/23] Train loss=0.21076813340187073
[20/23] Train loss=0.18397386372089386
Test set avg_accuracy=89.10% avg_sensitivity=61.94%, avg_specificity=97.75% avg_auc=92.86%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.211692 Test loss=0.285512 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.2060130536556244
[5/23] Train loss=0.1850125938653946
[10/23] Train loss=0.23581473529338837
[15/23] Train loss=0.20649442076683044
[20/23] Train loss=0.183633953332901
Test set avg_accuracy=87.97% avg_sensitivity=58.38%, avg_specificity=97.39% avg_auc=90.02%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.214504 Test loss=0.341825 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.2081238031387329
[5/23] Train loss=0.18949156999588013
[10/23] Train loss=0.22272661328315735
[15/23] Train loss=0.20605461299419403
[20/23] Train loss=0.17829717695713043
Test set avg_accuracy=88.58% avg_sensitivity=78.01%, avg_specificity=91.95% avg_auc=92.82%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.210030 Test loss=0.288144 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.197961688041687
[5/23] Train loss=0.18215329945087433
[10/23] Train loss=0.2029149830341339
[15/23] Train loss=0.20531614124774933
[20/23] Train loss=0.17524561285972595
Test set avg_accuracy=89.15% avg_sensitivity=77.25%, avg_specificity=92.94% avg_auc=93.90%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.207074 Test loss=0.263184 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.19792678952217102
[5/23] Train loss=0.17418868839740753
[10/23] Train loss=0.19840554893016815
[15/23] Train loss=0.20682381093502045
[20/23] Train loss=0.1697888970375061
Test set avg_accuracy=89.13% avg_sensitivity=66.31%, avg_specificity=96.39% avg_auc=92.82%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.201578 Test loss=0.281590 Current lr=[0.000299926900870094]

[0/23] Train loss=0.19796660542488098
[5/23] Train loss=0.16387714445590973
[10/23] Train loss=0.20254842936992645
[15/23] Train loss=0.20645053684711456
[20/23] Train loss=0.17450329661369324
Test set avg_accuracy=89.28% avg_sensitivity=78.65%, avg_specificity=92.67% avg_auc=94.04%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.206940 Test loss=0.262472 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.20213855803012848
[5/23] Train loss=0.17042997479438782
[10/23] Train loss=0.20102855563163757
[15/23] Train loss=0.21090589463710785
[20/23] Train loss=0.18158498406410217
Test set avg_accuracy=86.73% avg_sensitivity=81.29%, avg_specificity=88.46% avg_auc=92.68%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.206857 Test loss=0.310453 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.202444925904274
[5/23] Train loss=0.17792053520679474
[10/23] Train loss=0.19952940940856934
[15/23] Train loss=0.19888150691986084
[20/23] Train loss=0.17528976500034332
Test set avg_accuracy=88.44% avg_sensitivity=58.76%, avg_specificity=97.89% avg_auc=91.54%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.207781 Test loss=0.307747 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.1939062476158142
[5/23] Train loss=0.15682998299598694
[10/23] Train loss=0.20973825454711914
[15/23] Train loss=0.2002468854188919
[20/23] Train loss=0.18015719950199127
Test set avg_accuracy=89.67% avg_sensitivity=65.55%, avg_specificity=97.36% avg_auc=94.01%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.198065 Test loss=0.263120 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.18557342886924744
[5/23] Train loss=0.17118725180625916
[10/23] Train loss=0.19687539339065552
[15/23] Train loss=0.2106543928384781
[20/23] Train loss=0.1739686131477356
Test set avg_accuracy=89.24% avg_sensitivity=69.16%, avg_specificity=95.64% avg_auc=93.24%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.199841 Test loss=0.266961 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.19372737407684326
[5/23] Train loss=0.15325228869915009
[10/23] Train loss=0.19206951558589935
[15/23] Train loss=0.19844192266464233
[20/23] Train loss=0.1831905096769333
Test set avg_accuracy=89.21% avg_sensitivity=63.99%, avg_specificity=97.24% avg_auc=91.74%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.197220 Test loss=0.292984 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.19045011699199677
[5/23] Train loss=0.159133180975914
[10/23] Train loss=0.1876997947692871
[15/23] Train loss=0.2043484002351761
[20/23] Train loss=0.1770147979259491
Test set avg_accuracy=89.74% avg_sensitivity=76.82%, avg_specificity=93.85% avg_auc=93.82%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.196724 Test loss=0.260437 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.2000354826450348
[5/23] Train loss=0.15672780573368073
[10/23] Train loss=0.19711819291114807
[15/23] Train loss=0.19210238754749298
[20/23] Train loss=0.17557096481323242
Test set avg_accuracy=89.13% avg_sensitivity=78.76%, avg_specificity=92.43% avg_auc=93.33%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.193621 Test loss=0.273544 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.19006752967834473
[5/23] Train loss=0.1586853414773941
[10/23] Train loss=0.1921711564064026
[15/23] Train loss=0.20671206712722778
[20/23] Train loss=0.18416374921798706
Test set avg_accuracy=88.95% avg_sensitivity=71.11%, avg_specificity=94.63% avg_auc=92.70%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.197250 Test loss=0.276044 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.18672554194927216
[5/23] Train loss=0.16861335933208466
[10/23] Train loss=0.18780796229839325
[15/23] Train loss=0.20758464932441711
[20/23] Train loss=0.1633651852607727
Test set avg_accuracy=88.92% avg_sensitivity=71.59%, avg_specificity=94.44% avg_auc=92.59%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.192097 Test loss=0.278140 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.17988984286785126
[5/23] Train loss=0.15301333367824554
[10/23] Train loss=0.18134309351444244
[15/23] Train loss=0.18637509644031525
[20/23] Train loss=0.1577933430671692
Test set avg_accuracy=88.83% avg_sensitivity=68.79%, avg_specificity=95.21% avg_auc=92.09%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.185820 Test loss=0.283330 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.18269088864326477
[5/23] Train loss=0.16162431240081787
[10/23] Train loss=0.18916982412338257
[15/23] Train loss=0.20070971548557281
[20/23] Train loss=0.16701336205005646
Test set avg_accuracy=89.22% avg_sensitivity=68.63%, avg_specificity=95.78% avg_auc=92.91%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.188474 Test loss=0.274386 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.18304015696048737
[5/23] Train loss=0.15551897883415222
[10/23] Train loss=0.1865972876548767
[15/23] Train loss=0.20398858189582825
[20/23] Train loss=0.16493076086044312
Test set avg_accuracy=86.21% avg_sensitivity=81.29%, avg_specificity=87.78% avg_auc=92.59%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.188499 Test loss=0.309995 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.1819790005683899
[5/23] Train loss=0.1516774296760559
[10/23] Train loss=0.19033488631248474
[15/23] Train loss=0.20109689235687256
[20/23] Train loss=0.1744231879711151
Test set avg_accuracy=86.80% avg_sensitivity=51.48%, avg_specificity=98.04% avg_auc=89.29%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.188415 Test loss=0.363974 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.18651585280895233
[5/23] Train loss=0.15130312740802765
[10/23] Train loss=0.17729172110557556
[15/23] Train loss=0.18006552755832672
[20/23] Train loss=0.1669270247220993
Test set avg_accuracy=89.14% avg_sensitivity=65.28%, avg_specificity=96.74% avg_auc=90.40%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.185079 Test loss=0.303343 Current lr=[0.000283047938381597]

[0/23] Train loss=0.17794324457645416
[5/23] Train loss=0.1605045646429062
[10/23] Train loss=0.18865832686424255
[15/23] Train loss=0.18740947544574738
[20/23] Train loss=0.16118374466896057
Test set avg_accuracy=87.25% avg_sensitivity=77.90%, avg_specificity=90.23% avg_auc=91.98%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.182317 Test loss=0.304513 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.17945371568202972
[5/23] Train loss=0.14729779958724976
[10/23] Train loss=0.16810494661331177
[15/23] Train loss=0.18346641957759857
[20/23] Train loss=0.15885049104690552
Test set avg_accuracy=88.91% avg_sensitivity=70.24%, avg_specificity=94.85% avg_auc=92.24%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.178066 Test loss=0.284234 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.1614447981119156
[5/23] Train loss=0.1468852162361145
[10/23] Train loss=0.17815031111240387
[15/23] Train loss=0.18840347230434418
[20/23] Train loss=0.157601460814476
Test set avg_accuracy=88.58% avg_sensitivity=72.13%, avg_specificity=93.82% avg_auc=91.92%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.181643 Test loss=0.296427 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.17046448588371277
[5/23] Train loss=0.16002897918224335
[10/23] Train loss=0.17698456346988678
[15/23] Train loss=0.19328783452510834
[20/23] Train loss=0.1576290726661682
Test set avg_accuracy=87.83% avg_sensitivity=77.14%, avg_specificity=91.23% avg_auc=92.40%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.180955 Test loss=0.299215 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.1697782576084137
[5/23] Train loss=0.15181484818458557
[10/23] Train loss=0.17988848686218262
[15/23] Train loss=0.17862741649150848
[20/23] Train loss=0.16040481626987457
Test set avg_accuracy=88.58% avg_sensitivity=68.68%, avg_specificity=94.92% avg_auc=92.03%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.176875 Test loss=0.289736 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.17219632863998413
[5/23] Train loss=0.1440906673669815
[10/23] Train loss=0.18698157370090485
[15/23] Train loss=0.1859014630317688
[20/23] Train loss=0.15307049453258514
Test set avg_accuracy=88.87% avg_sensitivity=69.22%, avg_specificity=95.12% avg_auc=92.25%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.177251 Test loss=0.282549 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.17070043087005615
[5/23] Train loss=0.1497906744480133
[10/23] Train loss=0.19354897737503052
[15/23] Train loss=0.18644031882286072
[20/23] Train loss=0.15983402729034424
Test set avg_accuracy=89.13% avg_sensitivity=71.91%, avg_specificity=94.61% avg_auc=92.33%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.179165 Test loss=0.281841 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.1724933534860611
[5/23] Train loss=0.15738338232040405
[10/23] Train loss=0.1693144291639328
[15/23] Train loss=0.1708775907754898
[20/23] Train loss=0.1559421271085739
Test set avg_accuracy=84.92% avg_sensitivity=42.59%, avg_specificity=98.40% avg_auc=85.75%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.175382 Test loss=0.413760 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.1691187620162964
[5/23] Train loss=0.15150509774684906
[10/23] Train loss=0.1720706820487976
[15/23] Train loss=0.17220273613929749
[20/23] Train loss=0.1594717800617218
Test set avg_accuracy=87.11% avg_sensitivity=55.53%, avg_specificity=97.17% avg_auc=89.23%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.174609 Test loss=0.333321 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.16922566294670105
[5/23] Train loss=0.13966691493988037
[10/23] Train loss=0.16863645613193512
[15/23] Train loss=0.17117822170257568
[20/23] Train loss=0.1565476953983307
Test set avg_accuracy=88.72% avg_sensitivity=69.65%, avg_specificity=94.80% avg_auc=90.93%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.170984 Test loss=0.296766 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.17006289958953857
[5/23] Train loss=0.1385270059108734
[10/23] Train loss=0.17210054397583008
[15/23] Train loss=0.164549320936203
[20/23] Train loss=0.15941192209720612
Test set avg_accuracy=83.67% avg_sensitivity=84.96%, avg_specificity=83.26% avg_auc=91.84%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.171470 Test loss=0.366968 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.17158252000808716
[5/23] Train loss=0.14669594168663025
[10/23] Train loss=0.16287286579608917
[15/23] Train loss=0.17380039393901825
[20/23] Train loss=0.1537313014268875
Test set avg_accuracy=87.34% avg_sensitivity=57.41%, avg_specificity=96.88% avg_auc=88.32%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.174138 Test loss=0.340707 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.16967207193374634
[5/23] Train loss=0.1477704495191574
[10/23] Train loss=0.17304711043834686
[15/23] Train loss=0.174745574593544
[20/23] Train loss=0.1541832983493805
Test set avg_accuracy=85.35% avg_sensitivity=82.53%, avg_specificity=86.25% avg_auc=91.69%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.171751 Test loss=0.340469 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.16912734508514404
[5/23] Train loss=0.14346188306808472
[10/23] Train loss=0.17524418234825134
[15/23] Train loss=0.1631695032119751
[20/23] Train loss=0.14919933676719666
Test set avg_accuracy=88.54% avg_sensitivity=77.68%, avg_specificity=92.00% avg_auc=92.34%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.168840 Test loss=0.293695 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.1626334935426712
[5/23] Train loss=0.14086750149726868
[10/23] Train loss=0.16450807452201843
[15/23] Train loss=0.16270513832569122
[20/23] Train loss=0.15357820689678192
Test set avg_accuracy=86.80% avg_sensitivity=69.49%, avg_specificity=92.31% avg_auc=91.10%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.169159 Test loss=0.315055 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.16587822139263153
[5/23] Train loss=0.14041654765605927
[10/23] Train loss=0.1696830540895462
[15/23] Train loss=0.17067494988441467
[20/23] Train loss=0.15355360507965088
Test set avg_accuracy=87.88% avg_sensitivity=58.87%, avg_specificity=97.12% avg_auc=89.42%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.168245 Test loss=0.347273 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.1694219708442688
[5/23] Train loss=0.1486305296421051
[10/23] Train loss=0.16522496938705444
[15/23] Train loss=0.17884862422943115
[20/23] Train loss=0.15701724588871002
Test set avg_accuracy=87.89% avg_sensitivity=71.75%, avg_specificity=93.03% avg_auc=91.55%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.170133 Test loss=0.304619 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.17309072613716125
[5/23] Train loss=0.14229603111743927
[10/23] Train loss=0.1679050624370575
[15/23] Train loss=0.16956348717212677
[20/23] Train loss=0.15646566450595856
Test set avg_accuracy=86.97% avg_sensitivity=64.80%, avg_specificity=94.03% avg_auc=90.32%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.170106 Test loss=0.320401 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.18188251554965973
[5/23] Train loss=0.14440451562404633
[10/23] Train loss=0.17062048614025116
[15/23] Train loss=0.15520307421684265
[20/23] Train loss=0.1568349301815033
Test set avg_accuracy=88.62% avg_sensitivity=71.43%, avg_specificity=94.09% avg_auc=91.71%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.169871 Test loss=0.298709 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.16465626657009125
[5/23] Train loss=0.14809590578079224
[10/23] Train loss=0.16273468732833862
[15/23] Train loss=0.17004813253879547
[20/23] Train loss=0.15481679141521454
Test set avg_accuracy=83.02% avg_sensitivity=86.63%, avg_specificity=81.87% avg_auc=91.33%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.169050 Test loss=0.391599 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.17086681723594666
[5/23] Train loss=0.14631682634353638
[10/23] Train loss=0.18149517476558685
[15/23] Train loss=0.17420071363449097
[20/23] Train loss=0.1574176549911499
Test set avg_accuracy=86.94% avg_sensitivity=79.30%, avg_specificity=89.37% avg_auc=92.24%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.173220 Test loss=0.310975 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.17282812297344208
[5/23] Train loss=0.14509062469005585
[10/23] Train loss=0.16379742324352264
[15/23] Train loss=0.16265450417995453
[20/23] Train loss=0.14551398158073425
Test set avg_accuracy=89.11% avg_sensitivity=77.14%, avg_specificity=92.93% avg_auc=92.85%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.165756 Test loss=0.280029 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.16058973968029022
[5/23] Train loss=0.14174437522888184
[10/23] Train loss=0.15961869060993195
[15/23] Train loss=0.16139498353004456
[20/23] Train loss=0.15410831570625305
Test set avg_accuracy=89.70% avg_sensitivity=75.85%, avg_specificity=94.11% avg_auc=92.66%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.164405 Test loss=0.271726 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.16703949868679047
[5/23] Train loss=0.14179357886314392
[10/23] Train loss=0.16141320765018463
[15/23] Train loss=0.1655120551586151
[20/23] Train loss=0.14340050518512726
Test set avg_accuracy=86.82% avg_sensitivity=53.15%, avg_specificity=97.55% avg_auc=88.68%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.164837 Test loss=0.354501 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.16586370766162872
[5/23] Train loss=0.1412029266357422
[10/23] Train loss=0.16347254812717438
[15/23] Train loss=0.15057681500911713
[20/23] Train loss=0.15131299197673798
Test set avg_accuracy=88.83% avg_sensitivity=66.15%, avg_specificity=96.05% avg_auc=91.06%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.164855 Test loss=0.296538 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.1649792492389679
[5/23] Train loss=0.14000365138053894
[10/23] Train loss=0.1498178243637085
[15/23] Train loss=0.16147898137569427
[20/23] Train loss=0.14384955167770386
Test set avg_accuracy=88.97% avg_sensitivity=70.89%, avg_specificity=94.73% avg_auc=91.48%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.162830 Test loss=0.289998 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.15519961714744568
[5/23] Train loss=0.13769648969173431
[10/23] Train loss=0.1482706516981125
[15/23] Train loss=0.15900589525699615
[20/23] Train loss=0.1437927782535553
Test set avg_accuracy=89.51% avg_sensitivity=70.08%, avg_specificity=95.69% avg_auc=92.13%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.159793 Test loss=0.281276 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.15939529240131378
[5/23] Train loss=0.13868208229541779
[10/23] Train loss=0.14757198095321655
[15/23] Train loss=0.15606334805488586
[20/23] Train loss=0.13789978623390198
Test set avg_accuracy=88.53% avg_sensitivity=61.78%, avg_specificity=97.05% avg_auc=90.21%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.158210 Test loss=0.312684 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.1547059565782547
[5/23] Train loss=0.13624700903892517
[10/23] Train loss=0.1516464501619339
[15/23] Train loss=0.15242677927017212
[20/23] Train loss=0.14103753864765167
Test set avg_accuracy=88.89% avg_sensitivity=75.31%, avg_specificity=93.22% avg_auc=91.94%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.157950 Test loss=0.285885 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.15190662443637848
[5/23] Train loss=0.13846410810947418
[10/23] Train loss=0.14443032443523407
[15/23] Train loss=0.14913474023342133
[20/23] Train loss=0.13770917057991028
Test set avg_accuracy=88.02% avg_sensitivity=66.04%, avg_specificity=95.02% avg_auc=89.76%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.155695 Test loss=0.319661 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.15374359488487244
[5/23] Train loss=0.14013738930225372
[10/23] Train loss=0.1490078717470169
[15/23] Train loss=0.1516294926404953
[20/23] Train loss=0.1398123949766159
Test set avg_accuracy=89.57% avg_sensitivity=74.56%, avg_specificity=94.35% avg_auc=92.70%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.157002 Test loss=0.272981 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.1597159206867218
[5/23] Train loss=0.1363612562417984
[10/23] Train loss=0.15741173923015594
[15/23] Train loss=0.1565985083580017
[20/23] Train loss=0.13966208696365356
Test set avg_accuracy=89.28% avg_sensitivity=72.35%, avg_specificity=94.68% avg_auc=91.86%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.159437 Test loss=0.283860 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.158181831240654
[5/23] Train loss=0.13109873235225677
[10/23] Train loss=0.14598283171653748
[15/23] Train loss=0.14912761747837067
[20/23] Train loss=0.13685521483421326
Test set avg_accuracy=89.17% avg_sensitivity=69.97%, avg_specificity=95.28% avg_auc=91.97%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.155589 Test loss=0.284920 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.15660853683948517
[5/23] Train loss=0.1345568597316742
[10/23] Train loss=0.1544998586177826
[15/23] Train loss=0.15584589540958405
[20/23] Train loss=0.14141729474067688
Test set avg_accuracy=87.54% avg_sensitivity=64.85%, avg_specificity=94.76% avg_auc=89.32%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.160606 Test loss=0.322404 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.1572965681552887
[5/23] Train loss=0.14047718048095703
[10/23] Train loss=0.15382227301597595
[15/23] Train loss=0.15070617198944092
[20/23] Train loss=0.13987237215042114
Test set avg_accuracy=88.85% avg_sensitivity=72.29%, avg_specificity=94.13% avg_auc=91.63%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.156632 Test loss=0.290980 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.1558578610420227
[5/23] Train loss=0.13856980204582214
[10/23] Train loss=0.15801553428173065
[15/23] Train loss=0.16238747537136078
[20/23] Train loss=0.1374243199825287
Test set avg_accuracy=87.97% avg_sensitivity=58.49%, avg_specificity=97.36% avg_auc=89.87%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.157071 Test loss=0.325421 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.1507185697555542
[5/23] Train loss=0.1426466405391693
[10/23] Train loss=0.15226542949676514
[15/23] Train loss=0.14497698843479156
[20/23] Train loss=0.1351843923330307
Test set avg_accuracy=88.97% avg_sensitivity=66.58%, avg_specificity=96.10% avg_auc=91.96%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.154882 Test loss=0.289428 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.155035600066185
[5/23] Train loss=0.13219039142131805
[10/23] Train loss=0.14570224285125732
[15/23] Train loss=0.1503385305404663
[20/23] Train loss=0.13443076610565186
Test set avg_accuracy=89.36% avg_sensitivity=69.60%, avg_specificity=95.66% avg_auc=91.66%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.153899 Test loss=0.285252 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.14928263425827026
[5/23] Train loss=0.13734392821788788
[10/23] Train loss=0.14163021743297577
[15/23] Train loss=0.14968325197696686
[20/23] Train loss=0.14160983264446259
Test set avg_accuracy=87.66% avg_sensitivity=58.11%, avg_specificity=97.06% avg_auc=89.62%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.154243 Test loss=0.335874 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.15080389380455017
[5/23] Train loss=0.13244211673736572
[10/23] Train loss=0.14131301641464233
[15/23] Train loss=0.15387862920761108
[20/23] Train loss=0.13345152139663696
Test set avg_accuracy=88.24% avg_sensitivity=58.87%, avg_specificity=97.60% avg_auc=89.20%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.152520 Test loss=0.331052 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.1508142352104187
[5/23] Train loss=0.13358362019062042
[10/23] Train loss=0.13650649785995483
[15/23] Train loss=0.14286890625953674
[20/23] Train loss=0.13084733486175537
Test set avg_accuracy=88.85% avg_sensitivity=73.75%, avg_specificity=93.67% avg_auc=92.25%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.148838 Test loss=0.289951 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.1436876505613327
[5/23] Train loss=0.12827792763710022
[10/23] Train loss=0.13693059980869293
[15/23] Train loss=0.14428924024105072
[20/23] Train loss=0.1380382478237152
Test set avg_accuracy=88.97% avg_sensitivity=68.03%, avg_specificity=95.64% avg_auc=91.47%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.147408 Test loss=0.295284 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.13901978731155396
[5/23] Train loss=0.13732638955116272
[10/23] Train loss=0.13685570657253265
[15/23] Train loss=0.14234678447246552
[20/23] Train loss=0.12840402126312256
Test set avg_accuracy=88.28% avg_sensitivity=61.19%, avg_specificity=96.91% avg_auc=89.03%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.147583 Test loss=0.329236 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.1434718519449234
[5/23] Train loss=0.12687191367149353
[10/23] Train loss=0.1315370798110962
[15/23] Train loss=0.13171187043190002
[20/23] Train loss=0.13202957808971405
Test set avg_accuracy=89.27% avg_sensitivity=69.87%, avg_specificity=95.45% avg_auc=91.88%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.144260 Test loss=0.291094 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.14043951034545898
[5/23] Train loss=0.1270722895860672
[10/23] Train loss=0.1322742998600006
[15/23] Train loss=0.13811738789081573
[20/23] Train loss=0.1294834166765213
Test set avg_accuracy=89.13% avg_sensitivity=67.17%, avg_specificity=96.12% avg_auc=91.20%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.142277 Test loss=0.303048 Current lr=[0.000112073915556435]

[0/23] Train loss=0.14262838661670685
[5/23] Train loss=0.129337877035141
[10/23] Train loss=0.13696694374084473
[15/23] Train loss=0.1347726285457611
[20/23] Train loss=0.13258831202983856
Test set avg_accuracy=89.10% avg_sensitivity=66.36%, avg_specificity=96.34% avg_auc=89.70%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.141911 Test loss=0.314363 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.14443054795265198
[5/23] Train loss=0.12733636796474457
[10/23] Train loss=0.140289306640625
[15/23] Train loss=0.1314421445131302
[20/23] Train loss=0.13036003708839417
Test set avg_accuracy=87.90% avg_sensitivity=80.92%, avg_specificity=90.13% avg_auc=92.55%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.141900 Test loss=0.302317 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.1383638083934784
[5/23] Train loss=0.12240887433290482
[10/23] Train loss=0.13512341678142548
[15/23] Train loss=0.1368325650691986
[20/23] Train loss=0.1228364035487175
Test set avg_accuracy=89.02% avg_sensitivity=74.77%, avg_specificity=93.56% avg_auc=91.70%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.140040 Test loss=0.291901 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.13886986672878265
[5/23] Train loss=0.12432853877544403
[10/23] Train loss=0.1285610944032669
[15/23] Train loss=0.1284237802028656
[20/23] Train loss=0.12184125930070877
Test set avg_accuracy=88.98% avg_sensitivity=69.92%, avg_specificity=95.06% avg_auc=91.56%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.138137 Test loss=0.292412 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.13719314336776733
[5/23] Train loss=0.12158706039190292
[10/23] Train loss=0.12996353209018707
[15/23] Train loss=0.13052210211753845
[20/23] Train loss=0.12464706599712372
Test set avg_accuracy=88.61% avg_sensitivity=75.36%, avg_specificity=92.82% avg_auc=92.05%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.137428 Test loss=0.294536 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.14087645709514618
[5/23] Train loss=0.12034358084201813
[10/23] Train loss=0.1324363797903061
[15/23] Train loss=0.1266983300447464
[20/23] Train loss=0.12118186056613922
Test set avg_accuracy=88.84% avg_sensitivity=76.06%, avg_specificity=92.91% avg_auc=92.66%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.135734 Test loss=0.284062 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.13310401141643524
[5/23] Train loss=0.1232263594865799
[10/23] Train loss=0.12624786794185638
[15/23] Train loss=0.12719044089317322
[20/23] Train loss=0.12333457171916962
Test set avg_accuracy=89.06% avg_sensitivity=76.06%, avg_specificity=93.20% avg_auc=92.14%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.134077 Test loss=0.291035 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.12979157269001007
[5/23] Train loss=0.1235552728176117
[10/23] Train loss=0.12662774324417114
[15/23] Train loss=0.12317557632923126
[20/23] Train loss=0.12005199491977692
Test set avg_accuracy=89.10% avg_sensitivity=71.86%, avg_specificity=94.59% avg_auc=91.80%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.133614 Test loss=0.290879 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.12743282318115234
[5/23] Train loss=0.1213437095284462
[10/23] Train loss=0.12594276666641235
[15/23] Train loss=0.12513722479343414
[20/23] Train loss=0.1213323324918747
Test set avg_accuracy=88.80% avg_sensitivity=69.65%, avg_specificity=94.90% avg_auc=91.32%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.132378 Test loss=0.301173 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.12849946320056915
[5/23] Train loss=0.11793450266122818
[10/23] Train loss=0.12368158251047134
[15/23] Train loss=0.12586340308189392
[20/23] Train loss=0.12260297685861588
Test set avg_accuracy=88.55% avg_sensitivity=75.96%, avg_specificity=92.57% avg_auc=91.88%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.131485 Test loss=0.297671 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.12944123148918152
[5/23] Train loss=0.12187120318412781
[10/23] Train loss=0.12741167843341827
[15/23] Train loss=0.12445542216300964
[20/23] Train loss=0.11652199923992157
Test set avg_accuracy=88.78% avg_sensitivity=68.52%, avg_specificity=95.23% avg_auc=90.39%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.132581 Test loss=0.311196 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.13088062405586243
[5/23] Train loss=0.11699584871530533
[10/23] Train loss=0.13190250098705292
[15/23] Train loss=0.12402960658073425
[20/23] Train loss=0.11729467660188675
Test set avg_accuracy=88.45% avg_sensitivity=67.71%, avg_specificity=95.06% avg_auc=91.32%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.131057 Test loss=0.301787 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.13162723183631897
[5/23] Train loss=0.11955981701612473
[10/23] Train loss=0.12539254128932953
[15/23] Train loss=0.12367615103721619
[20/23] Train loss=0.11983951926231384
Test set avg_accuracy=88.40% avg_sensitivity=68.36%, avg_specificity=94.78% avg_auc=91.45%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.130871 Test loss=0.301664 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.12472199648618698
[5/23] Train loss=0.11592547595500946
[10/23] Train loss=0.12438316643238068
[15/23] Train loss=0.12230920046567917
[20/23] Train loss=0.11818696558475494
Test set avg_accuracy=88.85% avg_sensitivity=67.44%, avg_specificity=95.67% avg_auc=89.83%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.129362 Test loss=0.307745 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.124732606112957
[5/23] Train loss=0.11777238547801971
[10/23] Train loss=0.12023479491472244
[15/23] Train loss=0.12086480855941772
[20/23] Train loss=0.11789600551128387
Test set avg_accuracy=88.74% avg_sensitivity=69.97%, avg_specificity=94.71% avg_auc=91.62%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.128270 Test loss=0.294786 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.12252309173345566
[5/23] Train loss=0.11645344644784927
[10/23] Train loss=0.11966337263584137
[15/23] Train loss=0.12314081192016602
[20/23] Train loss=0.11615914106369019
Test set avg_accuracy=88.68% avg_sensitivity=66.04%, avg_specificity=95.90% avg_auc=90.72%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.128298 Test loss=0.308629 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.12991724908351898
[5/23] Train loss=0.11480545997619629
[10/23] Train loss=0.11940997838973999
[15/23] Train loss=0.11823516339063644
[20/23] Train loss=0.11781003326177597
Test set avg_accuracy=88.54% avg_sensitivity=68.46%, avg_specificity=94.94% avg_auc=91.21%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.126791 Test loss=0.299056 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.12312767654657364
[5/23] Train loss=0.1139531210064888
[10/23] Train loss=0.11806734651327133
[15/23] Train loss=0.12110739201307297
[20/23] Train loss=0.11720331758260727
Test set avg_accuracy=88.67% avg_sensitivity=67.12%, avg_specificity=95.54% avg_auc=89.18%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.125860 Test loss=0.316813 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.12120428681373596
[5/23] Train loss=0.11595460027456284
[10/23] Train loss=0.11853665113449097
[15/23] Train loss=0.118959940969944
[20/23] Train loss=0.11016649752855301
Test set avg_accuracy=88.75% avg_sensitivity=69.27%, avg_specificity=94.95% avg_auc=91.18%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.125714 Test loss=0.297565 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.12232832610607147
[5/23] Train loss=0.11381994187831879
[10/23] Train loss=0.11760731041431427
[15/23] Train loss=0.12297777086496353
[20/23] Train loss=0.1129356250166893
Test set avg_accuracy=88.20% avg_sensitivity=69.27%, avg_specificity=94.23% avg_auc=90.49%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.125505 Test loss=0.310505 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.1258580982685089
[5/23] Train loss=0.11412007361650467
[10/23] Train loss=0.11645422875881195
[15/23] Train loss=0.11842187494039536
[20/23] Train loss=0.1133325845003128
Test set avg_accuracy=88.62% avg_sensitivity=77.90%, avg_specificity=92.03% avg_auc=91.70%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.125687 Test loss=0.301725 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.11986088007688522
[5/23] Train loss=0.11349699646234512
[10/23] Train loss=0.11705321073532104
[15/23] Train loss=0.12208182364702225
[20/23] Train loss=0.11638027429580688
Test set avg_accuracy=88.62% avg_sensitivity=73.58%, avg_specificity=93.41% avg_auc=91.55%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.124554 Test loss=0.296235 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.11735128611326218
[5/23] Train loss=0.11394452303647995
[10/23] Train loss=0.11873706430196762
[15/23] Train loss=0.11995986849069595
[20/23] Train loss=0.11412885040044785
Test set avg_accuracy=88.80% avg_sensitivity=74.61%, avg_specificity=93.32% avg_auc=91.44%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.124161 Test loss=0.297942 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.12159722298383713
[5/23] Train loss=0.11507505923509598
[10/23] Train loss=0.11646654456853867
[15/23] Train loss=0.1219184473156929
[20/23] Train loss=0.10983703285455704
Test set avg_accuracy=88.53% avg_sensitivity=79.30%, avg_specificity=91.47% avg_auc=92.09%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.123742 Test loss=0.299200 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.11599008738994598
[5/23] Train loss=0.11498576402664185
[10/23] Train loss=0.11649376153945923
[15/23] Train loss=0.11778610944747925
[20/23] Train loss=0.11352156847715378
Test set avg_accuracy=89.02% avg_sensitivity=73.37%, avg_specificity=94.01% avg_auc=91.91%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.123007 Test loss=0.288946 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.11687487363815308
[5/23] Train loss=0.11594092100858688
[10/23] Train loss=0.11362985521554947
[15/23] Train loss=0.11976990103721619
[20/23] Train loss=0.10962788760662079
Test set avg_accuracy=89.00% avg_sensitivity=71.32%, avg_specificity=94.63% avg_auc=91.39%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.122479 Test loss=0.295645 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.11406036466360092
[5/23] Train loss=0.11369817703962326
[10/23] Train loss=0.1171264722943306
[15/23] Train loss=0.11634433269500732
[20/23] Train loss=0.11239947378635406
Test set avg_accuracy=89.01% avg_sensitivity=75.26%, avg_specificity=93.39% avg_auc=91.98%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.122190 Test loss=0.290889 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.1157710999250412
[5/23] Train loss=0.10971163958311081
[10/23] Train loss=0.11453191936016083
[15/23] Train loss=0.11352263391017914
[20/23] Train loss=0.1090908870100975
Test set avg_accuracy=89.01% avg_sensitivity=75.04%, avg_specificity=93.46% avg_auc=91.61%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.121059 Test loss=0.293590 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.11558113992214203
[5/23] Train loss=0.11218893527984619
[10/23] Train loss=0.11214137822389603
[15/23] Train loss=0.11288464814424515
[20/23] Train loss=0.11114440113306046
Test set avg_accuracy=88.96% avg_sensitivity=74.12%, avg_specificity=93.68% avg_auc=91.70%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.120018 Test loss=0.293328 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.115120530128479
[5/23] Train loss=0.11137465387582779
[10/23] Train loss=0.11450652033090591
[15/23] Train loss=0.11278529465198517
[20/23] Train loss=0.10870608687400818
Test set avg_accuracy=88.89% avg_sensitivity=72.13%, avg_specificity=94.23% avg_auc=91.43%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.119265 Test loss=0.295939 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.11489719897508621
[5/23] Train loss=0.10956443846225739
[10/23] Train loss=0.11192339658737183
[15/23] Train loss=0.11377865821123123
[20/23] Train loss=0.10854478180408478
Test set avg_accuracy=88.76% avg_sensitivity=73.37%, avg_specificity=93.67% avg_auc=91.75%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.118606 Test loss=0.293043 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.11334643512964249
[5/23] Train loss=0.1098933145403862
[10/23] Train loss=0.11202478408813477
[15/23] Train loss=0.11232350021600723
[20/23] Train loss=0.10975868254899979
Test set avg_accuracy=88.76% avg_sensitivity=73.05%, avg_specificity=93.77% avg_auc=91.70%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.118637 Test loss=0.292622 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.1108826994895935
[5/23] Train loss=0.11090398579835892
[10/23] Train loss=0.11005185544490814
[15/23] Train loss=0.11170981079339981
[20/23] Train loss=0.11145644634962082
Test set avg_accuracy=89.06% avg_sensitivity=73.32%, avg_specificity=94.08% avg_auc=91.77%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.118619 Test loss=0.290755 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.11304701119661331
[5/23] Train loss=0.10910183936357498
[10/23] Train loss=0.11228042840957642
[15/23] Train loss=0.11378729343414307
[20/23] Train loss=0.10700774192810059
Test set avg_accuracy=88.98% avg_sensitivity=73.26%, avg_specificity=93.99% avg_auc=91.79%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.118081 Test loss=0.290882 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.11244160681962967
[5/23] Train loss=0.10929025709629059
[10/23] Train loss=0.11151134967803955
[15/23] Train loss=0.11252130568027496
[20/23] Train loss=0.10843738913536072
Test set avg_accuracy=89.06% avg_sensitivity=73.15%, avg_specificity=94.13% avg_auc=91.82%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.117931 Test loss=0.289801 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.11278518289327621
[5/23] Train loss=0.11040706932544708
[10/23] Train loss=0.10970854759216309
[15/23] Train loss=0.11161485314369202
[20/23] Train loss=0.10957574099302292
Test set avg_accuracy=89.15% avg_sensitivity=73.75%, avg_specificity=94.06% avg_auc=91.92%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.117683 Test loss=0.288153 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.11084619164466858
[5/23] Train loss=0.10759185999631882
[10/23] Train loss=0.11058557033538818
[15/23] Train loss=0.11048789322376251
[20/23] Train loss=0.10726308822631836
Test set avg_accuracy=89.26% avg_sensitivity=74.77%, avg_specificity=93.87% avg_auc=91.85%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.116926 Test loss=0.289654 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.11063721030950546
[5/23] Train loss=0.10974304378032684
[10/23] Train loss=0.11170133203268051
[15/23] Train loss=0.11110930889844894
[20/23] Train loss=0.10733705013990402
Test set avg_accuracy=89.13% avg_sensitivity=73.64%, avg_specificity=94.06% avg_auc=91.75%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.117320 Test loss=0.290652 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.11365450918674469
[5/23] Train loss=0.10892999172210693
[10/23] Train loss=0.11033434420824051
[15/23] Train loss=0.11129164695739746
[20/23] Train loss=0.10945957899093628
Test set avg_accuracy=89.06% avg_sensitivity=73.64%, avg_specificity=93.97% avg_auc=91.79%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.117753 Test loss=0.290399 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.11313552409410477
[5/23] Train loss=0.10900314152240753
[10/23] Train loss=0.11190696805715561
[15/23] Train loss=0.11159764230251312
[20/23] Train loss=0.10691264271736145
Test set avg_accuracy=88.98% avg_sensitivity=73.10%, avg_specificity=94.04% avg_auc=91.74%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.117225 Test loss=0.291225 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.1104419156908989
[5/23] Train loss=0.10973162204027176
[10/23] Train loss=0.11115716397762299
[15/23] Train loss=0.11024459451436996
[20/23] Train loss=0.10675787925720215
Test set avg_accuracy=89.01% avg_sensitivity=73.21%, avg_specificity=94.04% avg_auc=91.79%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.116775 Test loss=0.290805 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.11034215986728668
[5/23] Train loss=0.10896290838718414
[10/23] Train loss=0.11135160177946091
[15/23] Train loss=0.11546982079744339
[20/23] Train loss=0.10695898532867432
Test set avg_accuracy=89.05% avg_sensitivity=73.21%, avg_specificity=94.09% avg_auc=91.77%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.117358 Test loss=0.290921 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.11316287517547607
[5/23] Train loss=0.10865691304206848
[10/23] Train loss=0.1123090386390686
[15/23] Train loss=0.10965435206890106
[20/23] Train loss=0.10631545633077621
Test set avg_accuracy=89.02% avg_sensitivity=73.10%, avg_specificity=94.09% avg_auc=91.76%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.116908 Test loss=0.291035 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.11138075590133667
[5/23] Train loss=0.10845763236284256
[10/23] Train loss=0.11040069907903671
[15/23] Train loss=0.11464247852563858
[20/23] Train loss=0.10582853853702545
Test set avg_accuracy=89.01% avg_sensitivity=73.15%, avg_specificity=94.06% avg_auc=91.76%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.117116 Test loss=0.291187 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=89.23% sen=82.21%, spe=91.47%, auc=94.23%!
Fold[9] Avg_overlap=0.69%(0.2411443020777964)
[0/24] Train loss=0.7300283908843994
[5/24] Train loss=0.7213819622993469
[10/24] Train loss=0.7138884663581848
[15/24] Train loss=0.7096177935600281
[20/24] Train loss=0.6999885439872742
Test set avg_accuracy=61.13% avg_sensitivity=43.40%, avg_specificity=66.27% avg_auc=57.22%
Best model saved!! Metric=-97.97353761332538!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.712765 Test loss=0.661856 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6920833587646484
[5/24] Train loss=0.6882398724555969
[10/24] Train loss=0.6843134760856628
[15/24] Train loss=0.6723635792732239
[20/24] Train loss=0.6619750261306763
Test set avg_accuracy=69.32% avg_sensitivity=51.39%, avg_specificity=74.52% avg_auc=69.78%
Best model saved!! Metric=-60.98481962442716!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.681405 Test loss=0.590871 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6623502969741821
[5/24] Train loss=0.6530278921127319
[10/24] Train loss=0.6580554246902466
[15/24] Train loss=0.6466631889343262
[20/24] Train loss=0.6400600671768188
Test set avg_accuracy=75.09% avg_sensitivity=58.11%, avg_specificity=80.01% avg_auc=76.91%
Best model saved!! Metric=-35.87458798301301!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.653872 Test loss=0.544161 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6326943635940552
[5/24] Train loss=0.6278870105743408
[10/24] Train loss=0.629327654838562
[15/24] Train loss=0.6206218004226685
[20/24] Train loss=0.6125142574310303
Test set avg_accuracy=76.69% avg_sensitivity=62.75%, avg_specificity=80.74% avg_auc=80.06%
Best model saved!! Metric=-25.764582421472433!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.626141 Test loss=0.513174 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5960059762001038
[5/24] Train loss=0.5970280766487122
[10/24] Train loss=0.6104570031166077
[15/24] Train loss=0.5944636464118958
[20/24] Train loss=0.5859271883964539
Test set avg_accuracy=78.10% avg_sensitivity=67.50%, avg_specificity=81.17% avg_auc=82.66%
Best model saved!! Metric=-16.567684849570284!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.600983 Test loss=0.485833 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5734469294548035
[5/24] Train loss=0.5744341611862183
[10/24] Train loss=0.584397554397583
[15/24] Train loss=0.5678874254226685
[20/24] Train loss=0.5587771534919739
Test set avg_accuracy=79.62% avg_sensitivity=69.12%, avg_specificity=82.67% avg_auc=84.58%
Best model saved!! Metric=-10.012244559543547!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.574183 Test loss=0.458237 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5445090532302856
[5/24] Train loss=0.5479459166526794
[10/24] Train loss=0.5634558796882629
[15/24] Train loss=0.5359722375869751
[20/24] Train loss=0.5332716107368469
Test set avg_accuracy=81.84% avg_sensitivity=71.26%, avg_specificity=84.90% avg_auc=86.41%
Best model saved!! Metric=-1.5919929719730277!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.547666 Test loss=0.432896 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5158611536026001
[5/24] Train loss=0.5231005549430847
[10/24] Train loss=0.5344712734222412
[15/24] Train loss=0.5073766112327576
[20/24] Train loss=0.5009981393814087
Test set avg_accuracy=84.21% avg_sensitivity=71.49%, avg_specificity=87.89% avg_auc=88.08%
Best model saved!! Metric=5.667672820426247!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.519331 Test loss=0.403723 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.49081939458847046
[5/24] Train loss=0.49241259694099426
[10/24] Train loss=0.496271550655365
[15/24] Train loss=0.47466155886650085
[20/24] Train loss=0.4747244119644165
Test set avg_accuracy=85.98% avg_sensitivity=70.05%, avg_specificity=90.59% avg_auc=88.92%
Best model saved!! Metric=9.532943187627922!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.489967 Test loss=0.380614 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4666091501712799
[5/24] Train loss=0.4625498652458191
[10/24] Train loss=0.47502008080482483
[15/24] Train loss=0.44601595401763916
[20/24] Train loss=0.44217804074287415
Test set avg_accuracy=86.98% avg_sensitivity=69.64%, avg_specificity=92.01% avg_auc=89.96%
Best model saved!! Metric=12.585962063278217!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.461986 Test loss=0.361609 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.44018498063087463
[5/24] Train loss=0.42975643277168274
[10/24] Train loss=0.43771424889564514
[15/24] Train loss=0.42258933186531067
[20/24] Train loss=0.41321107745170593
Test set avg_accuracy=87.51% avg_sensitivity=69.58%, avg_specificity=92.71% avg_auc=90.89%
Best model saved!! Metric=14.697623451085263!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.435703 Test loss=0.341197 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.41633933782577515
[5/24] Train loss=0.40996694564819336
[10/24] Train loss=0.4109426736831665
[15/24] Train loss=0.39560726284980774
[20/24] Train loss=0.39129915833473206
Test set avg_accuracy=88.18% avg_sensitivity=72.02%, avg_specificity=92.86% avg_auc=91.58%
Best model saved!! Metric=18.63795309147521!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.410229 Test loss=0.328566 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3990043103694916
[5/24] Train loss=0.3829987049102783
[10/24] Train loss=0.3890669643878937
[15/24] Train loss=0.3753387928009033
[20/24] Train loss=0.3640826642513275
Test set avg_accuracy=88.68% avg_sensitivity=73.58%, avg_specificity=93.06% avg_auc=92.33%
Best model saved!! Metric=21.659825683700248!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.388742 Test loss=0.313371 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.37263455986976624
[5/24] Train loss=0.36569222807884216
[10/24] Train loss=0.36824730038642883
[15/24] Train loss=0.35452598333358765
[20/24] Train loss=0.3442417085170746
Test set avg_accuracy=89.11% avg_sensitivity=68.37%, avg_specificity=95.13% avg_auc=92.23%
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.369544 Test loss=0.297120 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.35916081070899963
[5/24] Train loss=0.34775564074516296
[10/24] Train loss=0.35691171884536743
[15/24] Train loss=0.3368051052093506
[20/24] Train loss=0.33196690678596497
Test set avg_accuracy=89.27% avg_sensitivity=67.32%, avg_specificity=95.63% avg_auc=92.51%
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.352259 Test loss=0.286923 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.34773045778274536
[5/24] Train loss=0.33278968930244446
[10/24] Train loss=0.34146514534950256
[15/24] Train loss=0.3280142545700073
[20/24] Train loss=0.31664106249809265
Test set avg_accuracy=89.48% avg_sensitivity=66.69%, avg_specificity=96.09% avg_auc=92.88%
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.339777 Test loss=0.280347 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.32874229550361633
[5/24] Train loss=0.3181719481945038
[10/24] Train loss=0.3313157260417938
[15/24] Train loss=0.3132637143135071
[20/24] Train loss=0.30641084909439087
Test set avg_accuracy=89.62% avg_sensitivity=69.81%, avg_specificity=95.36% avg_auc=93.47%
Best model saved!! Metric=22.271371701236774!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.327557 Test loss=0.271098 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.31840357184410095
[5/24] Train loss=0.3120809495449066
[10/24] Train loss=0.31758707761764526
[15/24] Train loss=0.3060271143913269
[20/24] Train loss=0.29582539200782776
Test set avg_accuracy=89.53% avg_sensitivity=66.63%, avg_specificity=96.17% avg_auc=93.09%
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.316860 Test loss=0.269368 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.31169676780700684
[5/24] Train loss=0.30287161469459534
[10/24] Train loss=0.30836665630340576
[15/24] Train loss=0.2948615252971649
[20/24] Train loss=0.2836548388004303
Test set avg_accuracy=89.92% avg_sensitivity=68.48%, avg_specificity=96.14% avg_auc=93.62%
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.306235 Test loss=0.261201 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.30556681752204895
[5/24] Train loss=0.2930198907852173
[10/24] Train loss=0.3045119643211365
[15/24] Train loss=0.2877713739871979
[20/24] Train loss=0.276178777217865
Test set avg_accuracy=90.25% avg_sensitivity=72.60%, avg_specificity=95.36% avg_auc=93.94%
Best model saved!! Metric=26.145090830630124!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.298911 Test loss=0.255702 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.28979718685150146
[5/24] Train loss=0.2847067713737488
[10/24] Train loss=0.2989407777786255
[15/24] Train loss=0.2861660122871399
[20/24] Train loss=0.27469122409820557
Test set avg_accuracy=90.27% avg_sensitivity=74.16%, avg_specificity=94.94% avg_auc=94.16%
Best model saved!! Metric=27.540855413544207!!
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.291520 Test loss=0.255190 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2932894229888916
[5/24] Train loss=0.27854251861572266
[10/24] Train loss=0.28482621908187866
[15/24] Train loss=0.2700292766094208
[20/24] Train loss=0.2647629380226135
Test set avg_accuracy=90.47% avg_sensitivity=73.12%, avg_specificity=95.50% avg_auc=94.35%
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.283163 Test loss=0.248493 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.28109538555145264
[5/24] Train loss=0.2656903564929962
[10/24] Train loss=0.2809879183769226
[15/24] Train loss=0.26473748683929443
[20/24] Train loss=0.26484882831573486
Test set avg_accuracy=90.55% avg_sensitivity=72.77%, avg_specificity=95.70% avg_auc=93.93%
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.277541 Test loss=0.249218 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.28520655632019043
[5/24] Train loss=0.25927892327308655
[10/24] Train loss=0.27490630745887756
[15/24] Train loss=0.26636049151420593
[20/24] Train loss=0.2581009864807129
Test set avg_accuracy=90.68% avg_sensitivity=72.36%, avg_specificity=95.99% avg_auc=94.16%
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.272669 Test loss=0.245160 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2780976891517639
[5/24] Train loss=0.2589165270328522
[10/24] Train loss=0.2655060589313507
[15/24] Train loss=0.2599242627620697
[20/24] Train loss=0.25160732865333557
Test set avg_accuracy=90.40% avg_sensitivity=68.19%, avg_specificity=96.84% avg_auc=93.72%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.266984 Test loss=0.251105 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2721947431564331
[5/24] Train loss=0.24789179861545563
[10/24] Train loss=0.26291289925575256
[15/24] Train loss=0.250059574842453
[20/24] Train loss=0.24216265976428986
Test set avg_accuracy=90.36% avg_sensitivity=68.83%, avg_specificity=96.61% avg_auc=94.04%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.260751 Test loss=0.249470 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2724371552467346
[5/24] Train loss=0.23728860914707184
[10/24] Train loss=0.2572501301765442
[15/24] Train loss=0.25071170926094055
[20/24] Train loss=0.24176354706287384
Test set avg_accuracy=90.47% avg_sensitivity=69.29%, avg_specificity=96.61% avg_auc=93.86%
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.257085 Test loss=0.251589 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2782692611217499
[5/24] Train loss=0.24047529697418213
[10/24] Train loss=0.2605190873146057
[15/24] Train loss=0.24000775814056396
[20/24] Train loss=0.2333824187517166
Test set avg_accuracy=88.88% avg_sensitivity=57.53%, avg_specificity=97.97% avg_auc=93.03%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.252788 Test loss=0.279024 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2677973508834839
[5/24] Train loss=0.22574961185455322
[10/24] Train loss=0.25138765573501587
[15/24] Train loss=0.24299101531505585
[20/24] Train loss=0.23500528931617737
Test set avg_accuracy=85.90% avg_sensitivity=40.09%, avg_specificity=99.18% avg_auc=91.47%
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.247621 Test loss=0.345025 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2710019052028656
[5/24] Train loss=0.23241135478019714
[10/24] Train loss=0.24906328320503235
[15/24] Train loss=0.24014940857887268
[20/24] Train loss=0.23110534250736237
Test set avg_accuracy=89.49% avg_sensitivity=61.76%, avg_specificity=97.53% avg_auc=92.79%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.247074 Test loss=0.269086 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2555461823940277
[5/24] Train loss=0.21276870369911194
[10/24] Train loss=0.2540072798728943
[15/24] Train loss=0.23514926433563232
[20/24] Train loss=0.23099727928638458
Test set avg_accuracy=88.20% avg_sensitivity=53.42%, avg_specificity=98.29% avg_auc=91.91%
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.241628 Test loss=0.300509 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.27091673016548157
[5/24] Train loss=0.22559024393558502
[10/24] Train loss=0.24165096879005432
[15/24] Train loss=0.23597440123558044
[20/24] Train loss=0.23367299139499664
Test set avg_accuracy=87.99% avg_sensitivity=51.85%, avg_specificity=98.47% avg_auc=92.05%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.241757 Test loss=0.302138 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.25890451669692993
[5/24] Train loss=0.20801660418510437
[10/24] Train loss=0.22862032055854797
[15/24] Train loss=0.24204020202159882
[20/24] Train loss=0.22499993443489075
Test set avg_accuracy=90.21% avg_sensitivity=70.86%, avg_specificity=95.82% avg_auc=94.31%
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.237473 Test loss=0.244907 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.25067129731178284
[5/24] Train loss=0.2150591015815735
[10/24] Train loss=0.2320382297039032
[15/24] Train loss=0.2336423397064209
[20/24] Train loss=0.22489023208618164
Test set avg_accuracy=90.21% avg_sensitivity=72.07%, avg_specificity=95.47% avg_auc=93.72%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.232980 Test loss=0.248891 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.23922283947467804
[5/24] Train loss=0.21617960929870605
[10/24] Train loss=0.23446038365364075
[15/24] Train loss=0.22666719555854797
[20/24] Train loss=0.2181609869003296
Test set avg_accuracy=89.69% avg_sensitivity=66.05%, avg_specificity=96.54% avg_auc=93.12%
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.231465 Test loss=0.270336 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2527657747268677
[5/24] Train loss=0.20170556008815765
[10/24] Train loss=0.22602878510951996
[15/24] Train loss=0.23056194186210632
[20/24] Train loss=0.2243802547454834
Test set avg_accuracy=88.82% avg_sensitivity=57.42%, avg_specificity=97.92% avg_auc=92.47%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.229508 Test loss=0.288179 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.24407970905303955
[5/24] Train loss=0.21817421913146973
[10/24] Train loss=0.22768308222293854
[15/24] Train loss=0.22554302215576172
[20/24] Train loss=0.22389735281467438
Test set avg_accuracy=89.57% avg_sensitivity=66.40%, avg_specificity=96.29% avg_auc=92.82%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.230942 Test loss=0.268078 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.25082555413246155
[5/24] Train loss=0.2097748965024948
[10/24] Train loss=0.22884495556354523
[15/24] Train loss=0.22788392007350922
[20/24] Train loss=0.2236730307340622
Test set avg_accuracy=87.32% avg_sensitivity=49.36%, avg_specificity=98.32% avg_auc=89.54%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.229633 Test loss=0.332325 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.24365359544754028
[5/24] Train loss=0.20832644402980804
[10/24] Train loss=0.22832264006137848
[15/24] Train loss=0.2224499136209488
[20/24] Train loss=0.21567480266094208
Test set avg_accuracy=90.07% avg_sensitivity=66.74%, avg_specificity=96.83% avg_auc=93.74%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.230009 Test loss=0.255058 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.24225738644599915
[5/24] Train loss=0.20360490679740906
[10/24] Train loss=0.23216471076011658
[15/24] Train loss=0.22352123260498047
[20/24] Train loss=0.22132238745689392
Test set avg_accuracy=84.60% avg_sensitivity=34.36%, avg_specificity=99.16% avg_auc=90.07%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.227807 Test loss=0.376095 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.23783990740776062
[5/24] Train loss=0.19827793538570404
[10/24] Train loss=0.22820019721984863
[15/24] Train loss=0.22995249927043915
[20/24] Train loss=0.21458175778388977
Test set avg_accuracy=89.93% avg_sensitivity=67.50%, avg_specificity=96.44% avg_auc=92.81%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.226047 Test loss=0.266778 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2329811304807663
[5/24] Train loss=0.18636955320835114
[10/24] Train loss=0.21530579030513763
[15/24] Train loss=0.21733181178569794
[20/24] Train loss=0.20739708840847015
Test set avg_accuracy=89.90% avg_sensitivity=70.39%, avg_specificity=95.55% avg_auc=93.92%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.219043 Test loss=0.252170 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.23461748659610748
[5/24] Train loss=0.18640965223312378
[10/24] Train loss=0.2122410237789154
[15/24] Train loss=0.21994677186012268
[20/24] Train loss=0.22252099215984344
Test set avg_accuracy=89.79% avg_sensitivity=64.48%, avg_specificity=97.13% avg_auc=93.09%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.218395 Test loss=0.264639 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.22394528985023499
[5/24] Train loss=0.19139355421066284
[10/24] Train loss=0.20076441764831543
[15/24] Train loss=0.2226613461971283
[20/24] Train loss=0.20710474252700806
Test set avg_accuracy=88.42% avg_sensitivity=80.59%, avg_specificity=90.70% avg_auc=93.33%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.217760 Test loss=0.309732 Current lr=[0.00029967723776099]

[0/24] Train loss=0.22960907220840454
[5/24] Train loss=0.18157505989074707
[10/24] Train loss=0.22913002967834473
[15/24] Train loss=0.22114601731300354
[20/24] Train loss=0.20659518241882324
Test set avg_accuracy=88.70% avg_sensitivity=77.93%, avg_specificity=91.82% avg_auc=93.21%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.215398 Test loss=0.279140 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2173490971326828
[5/24] Train loss=0.19230322539806366
[10/24] Train loss=0.2121613621711731
[15/24] Train loss=0.21675866842269897
[20/24] Train loss=0.21449321508407593
Test set avg_accuracy=89.39% avg_sensitivity=62.40%, avg_specificity=97.21% avg_auc=91.91%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.214903 Test loss=0.282492 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2209155112504959
[5/24] Train loss=0.18544436991214752
[10/24] Train loss=0.2015564888715744
[15/24] Train loss=0.23047667741775513
[20/24] Train loss=0.20143449306488037
Test set avg_accuracy=89.49% avg_sensitivity=64.83%, avg_specificity=96.64% avg_auc=92.52%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.216709 Test loss=0.272760 Current lr=[0.000299720220882401]

[0/24] Train loss=0.21707852184772491
[5/24] Train loss=0.18235763907432556
[10/24] Train loss=0.2006312906742096
[15/24] Train loss=0.2185823768377304
[20/24] Train loss=0.20343342423439026
Test set avg_accuracy=87.49% avg_sensitivity=82.39%, avg_specificity=88.97% avg_auc=93.64%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.211239 Test loss=0.298277 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.22014114260673523
[5/24] Train loss=0.17850591242313385
[10/24] Train loss=0.19891972839832306
[15/24] Train loss=0.21632912755012512
[20/24] Train loss=0.2051904797554016
Test set avg_accuracy=89.31% avg_sensitivity=67.79%, avg_specificity=95.55% avg_auc=91.52%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.207972 Test loss=0.280004 Current lr=[0.000298904600941902]

[0/24] Train loss=0.21799053251743317
[5/24] Train loss=0.17191359400749207
[10/24] Train loss=0.2200433909893036
[15/24] Train loss=0.22362126410007477
[20/24] Train loss=0.20663650333881378
Test set avg_accuracy=85.66% avg_sensitivity=42.12%, avg_specificity=98.29% avg_auc=86.42%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.209134 Test loss=0.388690 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.22397004067897797
[5/24] Train loss=0.19579532742500305
[10/24] Train loss=0.20406968891620636
[15/24] Train loss=0.2062433809041977
[20/24] Train loss=0.1956004947423935
Test set avg_accuracy=88.74% avg_sensitivity=60.95%, avg_specificity=96.79% avg_auc=90.66%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.204864 Test loss=0.295904 Current lr=[0.000297555943323901]

[0/24] Train loss=0.20817743241786957
[5/24] Train loss=0.18908318877220154
[10/24] Train loss=0.18608927726745605
[15/24] Train loss=0.20860370993614197
[20/24] Train loss=0.1979156732559204
Test set avg_accuracy=88.71% avg_sensitivity=66.28%, avg_specificity=95.21% avg_auc=91.52%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.200624 Test loss=0.289488 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2172834575176239
[5/24] Train loss=0.17868711054325104
[10/24] Train loss=0.20379479229450226
[15/24] Train loss=0.21678224205970764
[20/24] Train loss=0.19155122339725494
Test set avg_accuracy=90.21% avg_sensitivity=76.42%, avg_specificity=94.21% avg_auc=94.21%
Best model saved!! Metric=29.04760319329874!!
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.204262 Test loss=0.247603 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.20633026957511902
[5/24] Train loss=0.17172372341156006
[10/24] Train loss=0.1957504004240036
[15/24] Train loss=0.20762258768081665
[20/24] Train loss=0.18871213495731354
Test set avg_accuracy=85.70% avg_sensitivity=83.55%, avg_specificity=86.33% avg_auc=92.77%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.200075 Test loss=0.325267 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2166433036327362
[5/24] Train loss=0.1680702269077301
[10/24] Train loss=0.2101462334394455
[15/24] Train loss=0.20738928020000458
[20/24] Train loss=0.19849027693271637
Test set avg_accuracy=86.54% avg_sensitivity=80.65%, avg_specificity=88.24% avg_auc=92.40%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.201902 Test loss=0.312923 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.20527754724025726
[5/24] Train loss=0.16716058552265167
[10/24] Train loss=0.21051888167858124
[15/24] Train loss=0.2188878357410431
[20/24] Train loss=0.2078123539686203
Test set avg_accuracy=88.18% avg_sensitivity=65.47%, avg_specificity=94.76% avg_auc=90.84%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.202290 Test loss=0.296341 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.21358424425125122
[5/24] Train loss=0.18948298692703247
[10/24] Train loss=0.18182481825351715
[15/24] Train loss=0.20920182764530182
[20/24] Train loss=0.19469912350177765
Test set avg_accuracy=85.65% avg_sensitivity=42.24%, avg_specificity=98.24% avg_auc=85.15%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.194534 Test loss=0.409516 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.21026255190372467
[5/24] Train loss=0.16736912727355957
[10/24] Train loss=0.1778183877468109
[15/24] Train loss=0.207659512758255
[20/24] Train loss=0.18432462215423584
Test set avg_accuracy=86.42% avg_sensitivity=81.52%, avg_specificity=87.84% avg_auc=92.08%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.194011 Test loss=0.321228 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.20934417843818665
[5/24] Train loss=0.18542227149009705
[10/24] Train loss=0.17689350247383118
[15/24] Train loss=0.22217567265033722
[20/24] Train loss=0.18458668887615204
Test set avg_accuracy=89.48% avg_sensitivity=65.41%, avg_specificity=96.46% avg_auc=91.64%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.195713 Test loss=0.285985 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.20096026360988617
[5/24] Train loss=0.17868608236312866
[10/24] Train loss=0.1925712376832962
[15/24] Train loss=0.20970454812049866
[20/24] Train loss=0.183682382106781
Test set avg_accuracy=89.66% avg_sensitivity=63.27%, avg_specificity=97.31% avg_auc=91.93%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.193365 Test loss=0.281917 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.20395992696285248
[5/24] Train loss=0.1674252152442932
[10/24] Train loss=0.19547127187252045
[15/24] Train loss=0.2180960774421692
[20/24] Train loss=0.1845787912607193
Test set avg_accuracy=89.36% avg_sensitivity=68.66%, avg_specificity=95.36% avg_auc=91.04%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.195073 Test loss=0.286720 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2057386189699173
[5/24] Train loss=0.1754269003868103
[10/24] Train loss=0.1820756494998932
[15/24] Train loss=0.19169454276561737
[20/24] Train loss=0.19258709251880646
Test set avg_accuracy=89.86% avg_sensitivity=73.75%, avg_specificity=94.52% avg_auc=93.63%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.191862 Test loss=0.256642 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.1958480179309845
[5/24] Train loss=0.17231576144695282
[10/24] Train loss=0.185188889503479
[15/24] Train loss=0.20672839879989624
[20/24] Train loss=0.17932161688804626
Test set avg_accuracy=89.84% avg_sensitivity=71.67%, avg_specificity=95.11% avg_auc=92.58%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.190550 Test loss=0.265573 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.20052386820316315
[5/24] Train loss=0.1678980588912964
[10/24] Train loss=0.1991361379623413
[15/24] Train loss=0.20218484103679657
[20/24] Train loss=0.18743206560611725
Test set avg_accuracy=88.35% avg_sensitivity=58.81%, avg_specificity=96.91% avg_auc=90.89%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.194137 Test loss=0.299480 Current lr=[0.000276307469034998]

[0/24] Train loss=0.19922178983688354
[5/24] Train loss=0.17725831270217896
[10/24] Train loss=0.20116639137268066
[15/24] Train loss=0.20238201320171356
[20/24] Train loss=0.1815556138753891
Test set avg_accuracy=89.05% avg_sensitivity=72.77%, avg_specificity=93.77% avg_auc=92.97%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.194453 Test loss=0.270158 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.19765406847000122
[5/24] Train loss=0.17586852610111237
[10/24] Train loss=0.1819213330745697
[15/24] Train loss=0.19380493462085724
[20/24] Train loss=0.1861223578453064
Test set avg_accuracy=89.38% avg_sensitivity=76.36%, avg_specificity=93.15% avg_auc=93.38%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.188804 Test loss=0.265661 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2003553807735443
[5/24] Train loss=0.16221356391906738
[10/24] Train loss=0.18790380656719208
[15/24] Train loss=0.1895774006843567
[20/24] Train loss=0.17444907128810883
Test set avg_accuracy=89.60% avg_sensitivity=72.48%, avg_specificity=94.56% avg_auc=92.50%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.188083 Test loss=0.265973 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.19751137495040894
[5/24] Train loss=0.16484299302101135
[10/24] Train loss=0.18709741532802582
[15/24] Train loss=0.1857629120349884
[20/24] Train loss=0.17121998965740204
Test set avg_accuracy=89.00% avg_sensitivity=60.89%, avg_specificity=97.14% avg_auc=90.45%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.184073 Test loss=0.297283 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.19347544014453888
[5/24] Train loss=0.15632976591587067
[10/24] Train loss=0.17769800126552582
[15/24] Train loss=0.19313247501850128
[20/24] Train loss=0.17190738022327423
Test set avg_accuracy=89.57% avg_sensitivity=72.07%, avg_specificity=94.64% avg_auc=92.43%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.181013 Test loss=0.270474 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.1938774138689041
[5/24] Train loss=0.16288290917873383
[10/24] Train loss=0.17415767908096313
[15/24] Train loss=0.18412238359451294
[20/24] Train loss=0.18001027405261993
Test set avg_accuracy=90.03% avg_sensitivity=73.52%, avg_specificity=94.81% avg_auc=92.92%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.183238 Test loss=0.260082 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.193588525056839
[5/24] Train loss=0.16017253696918488
[10/24] Train loss=0.17165419459342957
[15/24] Train loss=0.18342523276805878
[20/24] Train loss=0.17064863443374634
Test set avg_accuracy=89.61% avg_sensitivity=74.62%, avg_specificity=93.95% avg_auc=93.05%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.177458 Test loss=0.261747 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.19085443019866943
[5/24] Train loss=0.16159074008464813
[10/24] Train loss=0.18827523291110992
[15/24] Train loss=0.1840774565935135
[20/24] Train loss=0.1757851392030716
Test set avg_accuracy=89.21% avg_sensitivity=70.51%, avg_specificity=94.63% avg_auc=91.74%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.182425 Test loss=0.277369 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.18421471118927002
[5/24] Train loss=0.16004963219165802
[10/24] Train loss=0.16375257074832916
[15/24] Train loss=0.1888323426246643
[20/24] Train loss=0.17794232070446014
Test set avg_accuracy=88.41% avg_sensitivity=79.20%, avg_specificity=91.08% avg_auc=93.08%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.178193 Test loss=0.284170 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1932460218667984
[5/24] Train loss=0.16268838942050934
[10/24] Train loss=0.17103339731693268
[15/24] Train loss=0.18417778611183167
[20/24] Train loss=0.17081522941589355
Test set avg_accuracy=87.17% avg_sensitivity=50.81%, avg_specificity=97.72% avg_auc=87.05%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.176426 Test loss=0.352195 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.18465769290924072
[5/24] Train loss=0.15771104395389557
[10/24] Train loss=0.17237679660320282
[15/24] Train loss=0.17898474633693695
[20/24] Train loss=0.16763082146644592
Test set avg_accuracy=89.69% avg_sensitivity=67.15%, avg_specificity=96.22% avg_auc=91.67%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.176386 Test loss=0.279937 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.18296124041080475
[5/24] Train loss=0.15433302521705627
[10/24] Train loss=0.1616252064704895
[15/24] Train loss=0.18426451086997986
[20/24] Train loss=0.1654292792081833
Test set avg_accuracy=89.39% avg_sensitivity=70.74%, avg_specificity=94.79% avg_auc=92.13%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.175321 Test loss=0.273090 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.1911381036043167
[5/24] Train loss=0.16018244624137878
[10/24] Train loss=0.1660231053829193
[15/24] Train loss=0.17626601457595825
[20/24] Train loss=0.1646081954240799
Test set avg_accuracy=89.09% avg_sensitivity=64.14%, avg_specificity=96.32% avg_auc=90.14%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.174846 Test loss=0.295050 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.18970409035682678
[5/24] Train loss=0.15719811618328094
[10/24] Train loss=0.1727338582277298
[15/24] Train loss=0.17561207711696625
[20/24] Train loss=0.16252702474594116
Test set avg_accuracy=88.68% avg_sensitivity=75.38%, avg_specificity=92.54% avg_auc=92.10%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.173946 Test loss=0.283054 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.1935829222202301
[5/24] Train loss=0.15574687719345093
[10/24] Train loss=0.1657904088497162
[15/24] Train loss=0.1782023310661316
[20/24] Train loss=0.17260977625846863
Test set avg_accuracy=87.76% avg_sensitivity=57.82%, avg_specificity=96.44% avg_auc=90.27%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.174517 Test loss=0.309651 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.18720071017742157
[5/24] Train loss=0.15608321130275726
[10/24] Train loss=0.1803908348083496
[15/24] Train loss=0.18330006301403046
[20/24] Train loss=0.1700625866651535
Test set avg_accuracy=85.10% avg_sensitivity=38.99%, avg_specificity=98.47% avg_auc=82.52%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.178169 Test loss=0.417989 Current lr=[0.000224838296036774]

[0/24] Train loss=0.18916215002536774
[5/24] Train loss=0.15124571323394775
[10/24] Train loss=0.1637236475944519
[15/24] Train loss=0.18317465484142303
[20/24] Train loss=0.1793031394481659
Test set avg_accuracy=89.91% avg_sensitivity=75.32%, avg_specificity=94.14% avg_auc=93.19%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.176510 Test loss=0.261406 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.19044111669063568
[5/24] Train loss=0.147328183054924
[10/24] Train loss=0.18681950867176056
[15/24] Train loss=0.1833084225654602
[20/24] Train loss=0.16833439469337463
Test set avg_accuracy=89.47% avg_sensitivity=74.10%, avg_specificity=93.92% avg_auc=92.54%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.176013 Test loss=0.269171 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.1812862753868103
[5/24] Train loss=0.16072769463062286
[10/24] Train loss=0.18382862210273743
[15/24] Train loss=0.18023419380187988
[20/24] Train loss=0.16591298580169678
Test set avg_accuracy=88.75% avg_sensitivity=75.61%, avg_specificity=92.56% avg_auc=92.35%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.177734 Test loss=0.282325 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.19681741297245026
[5/24] Train loss=0.1513497233390808
[10/24] Train loss=0.16277354955673218
[15/24] Train loss=0.17635338008403778
[20/24] Train loss=0.1615498960018158
Test set avg_accuracy=89.15% avg_sensitivity=72.31%, avg_specificity=94.04% avg_auc=92.36%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.174870 Test loss=0.273797 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.18251042068004608
[5/24] Train loss=0.15581004321575165
[10/24] Train loss=0.18109923601150513
[15/24] Train loss=0.17521467804908752
[20/24] Train loss=0.15930844843387604
Test set avg_accuracy=87.93% avg_sensitivity=79.55%, avg_specificity=90.36% avg_auc=93.17%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.177408 Test loss=0.289400 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.19137278199195862
[5/24] Train loss=0.1498473584651947
[10/24] Train loss=0.16185761988162994
[15/24] Train loss=0.17090585827827454
[20/24] Train loss=0.15834511816501617
Test set avg_accuracy=87.70% avg_sensitivity=80.82%, avg_specificity=89.69% avg_auc=92.73%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.170978 Test loss=0.302333 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.17953930795192719
[5/24] Train loss=0.15659910440444946
[10/24] Train loss=0.15966828167438507
[15/24] Train loss=0.174743190407753
[20/24] Train loss=0.16482485830783844
Test set avg_accuracy=88.33% avg_sensitivity=75.38%, avg_specificity=92.09% avg_auc=91.59%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.170471 Test loss=0.293647 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.18682889640331268
[5/24] Train loss=0.15156276524066925
[10/24] Train loss=0.15732643008232117
[15/24] Train loss=0.16951827704906464
[20/24] Train loss=0.15646739304065704
Test set avg_accuracy=88.78% avg_sensitivity=77.23%, avg_specificity=92.12% avg_auc=92.84%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.169195 Test loss=0.284822 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1773594319820404
[5/24] Train loss=0.15995784103870392
[10/24] Train loss=0.15831583738327026
[15/24] Train loss=0.17064589262008667
[20/24] Train loss=0.15146087110042572
Test set avg_accuracy=87.76% avg_sensitivity=83.49%, avg_specificity=89.00% avg_auc=92.73%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.165962 Test loss=0.306197 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.17268365621566772
[5/24] Train loss=0.15398801863193512
[10/24] Train loss=0.16144625842571259
[15/24] Train loss=0.16717390716075897
[20/24] Train loss=0.15962153673171997
Test set avg_accuracy=88.01% avg_sensitivity=79.95%, avg_specificity=90.34% avg_auc=92.61%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.167100 Test loss=0.297704 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.17213261127471924
[5/24] Train loss=0.15463165938854218
[10/24] Train loss=0.16054245829582214
[15/24] Train loss=0.16507747769355774
[20/24] Train loss=0.15692998468875885
Test set avg_accuracy=87.27% avg_sensitivity=79.72%, avg_specificity=89.45% avg_auc=91.95%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.165664 Test loss=0.312253 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.17618955671787262
[5/24] Train loss=0.15519796311855316
[10/24] Train loss=0.16121962666511536
[15/24] Train loss=0.16205503046512604
[20/24] Train loss=0.16138973832130432
Test set avg_accuracy=89.40% avg_sensitivity=64.08%, avg_specificity=96.74% avg_auc=90.76%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.166942 Test loss=0.290786 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.17256379127502441
[5/24] Train loss=0.14870168268680573
[10/24] Train loss=0.1547498106956482
[15/24] Train loss=0.16630640625953674
[20/24] Train loss=0.15319301187992096
Test set avg_accuracy=88.66% avg_sensitivity=67.15%, avg_specificity=94.89% avg_auc=89.80%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.162991 Test loss=0.305621 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.178200826048851
[5/24] Train loss=0.1503046452999115
[10/24] Train loss=0.14856615662574768
[15/24] Train loss=0.1689731478691101
[20/24] Train loss=0.15160785615444183
Test set avg_accuracy=89.44% avg_sensitivity=69.00%, avg_specificity=95.36% avg_auc=91.35%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.161157 Test loss=0.282264 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.16381220519542694
[5/24] Train loss=0.15126974880695343
[10/24] Train loss=0.14984865486621857
[15/24] Train loss=0.15923768281936646
[20/24] Train loss=0.14632150530815125
Test set avg_accuracy=89.69% avg_sensitivity=72.13%, avg_specificity=94.78% avg_auc=92.14%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.160239 Test loss=0.272593 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.17006811499595642
[5/24] Train loss=0.1461881399154663
[10/24] Train loss=0.15536461770534515
[15/24] Train loss=0.160548597574234
[20/24] Train loss=0.1525915116071701
Test set avg_accuracy=89.48% avg_sensitivity=67.44%, avg_specificity=95.87% avg_auc=91.39%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.161501 Test loss=0.284799 Current lr=[0.000156543481933168]

[0/24] Train loss=0.17774440348148346
[5/24] Train loss=0.1443987637758255
[10/24] Train loss=0.145041823387146
[15/24] Train loss=0.16028115153312683
[20/24] Train loss=0.15662641823291779
Test set avg_accuracy=88.78% avg_sensitivity=72.36%, avg_specificity=93.53% avg_auc=91.35%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.160575 Test loss=0.292034 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.16668261587619781
[5/24] Train loss=0.15016578137874603
[10/24] Train loss=0.14989888668060303
[15/24] Train loss=0.15340478718280792
[20/24] Train loss=0.15006482601165771
Test set avg_accuracy=90.21% avg_sensitivity=72.13%, avg_specificity=95.45% avg_auc=92.00%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.157261 Test loss=0.267433 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.16110160946846008
[5/24] Train loss=0.1456170529127121
[10/24] Train loss=0.1434735357761383
[15/24] Train loss=0.15845324099063873
[20/24] Train loss=0.14839640259742737
Test set avg_accuracy=89.73% avg_sensitivity=64.48%, avg_specificity=97.04% avg_auc=91.44%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.156452 Test loss=0.282229 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.160344198346138
[5/24] Train loss=0.1461464911699295
[10/24] Train loss=0.15133623778820038
[15/24] Train loss=0.15378303825855255
[20/24] Train loss=0.13948829472064972
Test set avg_accuracy=89.66% avg_sensitivity=69.70%, avg_specificity=95.45% avg_auc=91.77%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.154793 Test loss=0.279477 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1563687026500702
[5/24] Train loss=0.14077825844287872
[10/24] Train loss=0.1484268307685852
[15/24] Train loss=0.1528228521347046
[20/24] Train loss=0.14460457861423492
Test set avg_accuracy=89.01% avg_sensitivity=79.72%, avg_specificity=91.70% avg_auc=93.35%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.152308 Test loss=0.277974 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1559833288192749
[5/24] Train loss=0.14181607961654663
[10/24] Train loss=0.14041176438331604
[15/24] Train loss=0.15044660866260529
[20/24] Train loss=0.14149361848831177
Test set avg_accuracy=90.27% avg_sensitivity=77.40%, avg_specificity=94.00% avg_auc=93.35%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.151200 Test loss=0.258965 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15620654821395874
[5/24] Train loss=0.13971936702728271
[10/24] Train loss=0.14077170193195343
[15/24] Train loss=0.1504589319229126
[20/24] Train loss=0.1441844403743744
Test set avg_accuracy=90.22% avg_sensitivity=69.81%, avg_specificity=96.14% avg_auc=92.33%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.151606 Test loss=0.269328 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.16039897501468658
[5/24] Train loss=0.1386343389749527
[10/24] Train loss=0.14394383132457733
[15/24] Train loss=0.14954759180545807
[20/24] Train loss=0.14858239889144897
Test set avg_accuracy=90.35% avg_sensitivity=73.12%, avg_specificity=95.35% avg_auc=92.67%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.151530 Test loss=0.258889 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15266603231430054
[5/24] Train loss=0.1401595026254654
[10/24] Train loss=0.14400826394557953
[15/24] Train loss=0.1445024609565735
[20/24] Train loss=0.14553482830524445
Test set avg_accuracy=89.13% avg_sensitivity=80.19%, avg_specificity=91.72% avg_auc=93.18%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.150059 Test loss=0.277473 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.15667569637298584
[5/24] Train loss=0.14386022090911865
[10/24] Train loss=0.13959901034832
[15/24] Train loss=0.15073296427726746
[20/24] Train loss=0.14528827369213104
Test set avg_accuracy=90.18% avg_sensitivity=70.34%, avg_specificity=95.94% avg_auc=92.33%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.151301 Test loss=0.267839 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1585746705532074
[5/24] Train loss=0.1409405767917633
[10/24] Train loss=0.13543422520160675
[15/24] Train loss=0.15647099912166595
[20/24] Train loss=0.14586776494979858
Test set avg_accuracy=89.57% avg_sensitivity=75.67%, avg_specificity=93.60% avg_auc=92.60%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.152080 Test loss=0.271574 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15380164980888367
[5/24] Train loss=0.13700492680072784
[10/24] Train loss=0.14671747386455536
[15/24] Train loss=0.14855904877185822
[20/24] Train loss=0.14787700772285461
Test set avg_accuracy=90.12% avg_sensitivity=76.54%, avg_specificity=94.05% avg_auc=92.94%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.151273 Test loss=0.261569 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15393175184726715
[5/24] Train loss=0.13853412866592407
[10/24] Train loss=0.14151981472969055
[15/24] Train loss=0.15189245343208313
[20/24] Train loss=0.13841190934181213
Test set avg_accuracy=90.13% avg_sensitivity=69.06%, avg_specificity=96.24% avg_auc=91.78%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.149907 Test loss=0.271573 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.15720076858997345
[5/24] Train loss=0.13666783273220062
[10/24] Train loss=0.14068323373794556
[15/24] Train loss=0.144119530916214
[20/24] Train loss=0.1471063643693924
Test set avg_accuracy=90.08% avg_sensitivity=73.00%, avg_specificity=95.03% avg_auc=92.53%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.149133 Test loss=0.267628 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15694905817508698
[5/24] Train loss=0.14619597792625427
[10/24] Train loss=0.1381029635667801
[15/24] Train loss=0.14876894652843475
[20/24] Train loss=0.14588063955307007
Test set avg_accuracy=90.13% avg_sensitivity=70.97%, avg_specificity=95.68% avg_auc=91.57%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.149745 Test loss=0.270246 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.15496312081813812
[5/24] Train loss=0.13835950195789337
[10/24] Train loss=0.14256851375102997
[15/24] Train loss=0.15115229785442352
[20/24] Train loss=0.14480169117450714
Test set avg_accuracy=90.17% avg_sensitivity=73.06%, avg_specificity=95.13% avg_auc=92.91%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.149979 Test loss=0.265936 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1541508138179779
[5/24] Train loss=0.14235897362232208
[10/24] Train loss=0.1426943838596344
[15/24] Train loss=0.14973177015781403
[20/24] Train loss=0.14657220244407654
Test set avg_accuracy=88.65% avg_sensitivity=75.55%, avg_specificity=92.44% avg_auc=91.77%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.148889 Test loss=0.291360 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.15238282084465027
[5/24] Train loss=0.1380685269832611
[10/24] Train loss=0.13593070209026337
[15/24] Train loss=0.14871589839458466
[20/24] Train loss=0.14354321360588074
Test set avg_accuracy=89.45% avg_sensitivity=65.06%, avg_specificity=96.52% avg_auc=90.67%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.147016 Test loss=0.287913 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1477760672569275
[5/24] Train loss=0.13388974964618683
[10/24] Train loss=0.1371474713087082
[15/24] Train loss=0.15127021074295044
[20/24] Train loss=0.1393166333436966
Test set avg_accuracy=89.01% avg_sensitivity=64.48%, avg_specificity=96.12% avg_auc=90.80%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.144549 Test loss=0.296041 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1532168686389923
[5/24] Train loss=0.13207434117794037
[10/24] Train loss=0.12962894141674042
[15/24] Train loss=0.14344556629657745
[20/24] Train loss=0.1350015103816986
Test set avg_accuracy=89.47% avg_sensitivity=67.03%, avg_specificity=95.97% avg_auc=91.40%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.143232 Test loss=0.284780 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14821526408195496
[5/24] Train loss=0.1347343772649765
[10/24] Train loss=0.13412559032440186
[15/24] Train loss=0.1475820690393448
[20/24] Train loss=0.13555119931697845
Test set avg_accuracy=89.49% avg_sensitivity=65.12%, avg_specificity=96.56% avg_auc=91.04%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.142895 Test loss=0.285917 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1463538408279419
[5/24] Train loss=0.13459642231464386
[10/24] Train loss=0.1327354907989502
[15/24] Train loss=0.140847310423851
[20/24] Train loss=0.13710123300552368
Test set avg_accuracy=89.57% avg_sensitivity=74.68%, avg_specificity=93.89% avg_auc=92.13%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.141209 Test loss=0.271077 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14891524612903595
[5/24] Train loss=0.13519218564033508
[10/24] Train loss=0.12558183073997498
[15/24] Train loss=0.1423967480659485
[20/24] Train loss=0.13529014587402344
Test set avg_accuracy=89.86% avg_sensitivity=75.43%, avg_specificity=94.04% avg_auc=92.31%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.140069 Test loss=0.271174 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14086145162582397
[5/24] Train loss=0.1322578489780426
[10/24] Train loss=0.12714123725891113
[15/24] Train loss=0.14235293865203857
[20/24] Train loss=0.13310515880584717
Test set avg_accuracy=89.51% avg_sensitivity=73.87%, avg_specificity=94.04% avg_auc=91.92%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.138738 Test loss=0.276636 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14250941574573517
[5/24] Train loss=0.12872880697250366
[10/24] Train loss=0.12828485667705536
[15/24] Train loss=0.14013801515102386
[20/24] Train loss=0.13528986275196075
Test set avg_accuracy=89.97% avg_sensitivity=70.92%, avg_specificity=95.50% avg_auc=92.08%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.136805 Test loss=0.268362 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1393469274044037
[5/24] Train loss=0.12810713052749634
[10/24] Train loss=0.1278195083141327
[15/24] Train loss=0.13578051328659058
[20/24] Train loss=0.1353704333305359
Test set avg_accuracy=89.52% avg_sensitivity=66.34%, avg_specificity=96.24% avg_auc=90.79%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.135972 Test loss=0.287808 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.145099937915802
[5/24] Train loss=0.12383408844470978
[10/24] Train loss=0.12400292605161667
[15/24] Train loss=0.13221147656440735
[20/24] Train loss=0.1292380690574646
Test set avg_accuracy=89.26% avg_sensitivity=72.94%, avg_specificity=93.99% avg_auc=92.19%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.134572 Test loss=0.277396 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1411888152360916
[5/24] Train loss=0.12449667602777481
[10/24] Train loss=0.12642034888267517
[15/24] Train loss=0.1316685676574707
[20/24] Train loss=0.12863093614578247
Test set avg_accuracy=89.96% avg_sensitivity=70.34%, avg_specificity=95.65% avg_auc=91.90%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.133175 Test loss=0.271486 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13994364440441132
[5/24] Train loss=0.12449231743812561
[10/24] Train loss=0.12371731549501419
[15/24] Train loss=0.13221986591815948
[20/24] Train loss=0.1284826248884201
Test set avg_accuracy=90.09% avg_sensitivity=71.73%, avg_specificity=95.41% avg_auc=91.86%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.133166 Test loss=0.270983 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.14173279702663422
[5/24] Train loss=0.12241595983505249
[10/24] Train loss=0.12304306775331497
[15/24] Train loss=0.13361890614032745
[20/24] Train loss=0.13119463622570038
Test set avg_accuracy=89.99% avg_sensitivity=69.41%, avg_specificity=95.95% avg_auc=91.58%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.134093 Test loss=0.276702 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1444210708141327
[5/24] Train loss=0.12488765269517899
[10/24] Train loss=0.1250612437725067
[15/24] Train loss=0.1304687112569809
[20/24] Train loss=0.12568967044353485
Test set avg_accuracy=89.66% avg_sensitivity=72.89%, avg_specificity=94.52% avg_auc=92.32%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.132996 Test loss=0.272635 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.14018245041370392
[5/24] Train loss=0.12687534093856812
[10/24] Train loss=0.12045398354530334
[15/24] Train loss=0.13256993889808655
[20/24] Train loss=0.130141943693161
Test set avg_accuracy=90.08% avg_sensitivity=70.34%, avg_specificity=95.80% avg_auc=91.92%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.132883 Test loss=0.270417 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13565558195114136
[5/24] Train loss=0.12628425657749176
[10/24] Train loss=0.12147127091884613
[15/24] Train loss=0.13049301505088806
[20/24] Train loss=0.13010868430137634
Test set avg_accuracy=90.13% avg_sensitivity=71.73%, avg_specificity=95.47% avg_auc=91.90%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.132052 Test loss=0.270468 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13551326096057892
[5/24] Train loss=0.12870565056800842
[10/24] Train loss=0.1187920942902565
[15/24] Train loss=0.1301690638065338
[20/24] Train loss=0.12894856929779053
Test set avg_accuracy=89.35% avg_sensitivity=72.65%, avg_specificity=94.19% avg_auc=92.26%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.131746 Test loss=0.273366 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13708357512950897
[5/24] Train loss=0.12570419907569885
[10/24] Train loss=0.12180636078119278
[15/24] Train loss=0.1312611997127533
[20/24] Train loss=0.12797139585018158
Test set avg_accuracy=90.00% avg_sensitivity=71.67%, avg_specificity=95.31% avg_auc=91.97%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.131793 Test loss=0.269203 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1336187720298767
[5/24] Train loss=0.12746725976467133
[10/24] Train loss=0.1221989095211029
[15/24] Train loss=0.12904876470565796
[20/24] Train loss=0.13073259592056274
Test set avg_accuracy=90.23% avg_sensitivity=71.32%, avg_specificity=95.72% avg_auc=91.65%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.131865 Test loss=0.271298 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1335485279560089
[5/24] Train loss=0.12528018653392792
[10/24] Train loss=0.12128029763698578
[15/24] Train loss=0.126364067196846
[20/24] Train loss=0.12418686598539352
Test set avg_accuracy=89.96% avg_sensitivity=73.64%, avg_specificity=94.69% avg_auc=92.34%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.130697 Test loss=0.269029 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13661789894104004
[5/24] Train loss=0.12115316092967987
[10/24] Train loss=0.11770740151405334
[15/24] Train loss=0.1277792602777481
[20/24] Train loss=0.12306791543960571
Test set avg_accuracy=90.43% avg_sensitivity=72.31%, avg_specificity=95.68% avg_auc=91.59%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.129500 Test loss=0.271079 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13321736454963684
[5/24] Train loss=0.12056881934404373
[10/24] Train loss=0.11675217747688293
[15/24] Train loss=0.12672066688537598
[20/24] Train loss=0.12491870671510696
Test set avg_accuracy=89.83% avg_sensitivity=73.81%, avg_specificity=94.47% avg_auc=92.17%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.128312 Test loss=0.269342 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1314973384141922
[5/24] Train loss=0.12251456081867218
[10/24] Train loss=0.11797685921192169
[15/24] Train loss=0.12575598061084747
[20/24] Train loss=0.12238668650388718
Test set avg_accuracy=90.44% avg_sensitivity=72.02%, avg_specificity=95.78% avg_auc=91.62%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.127673 Test loss=0.268235 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1312827169895172
[5/24] Train loss=0.12132728099822998
[10/24] Train loss=0.11570452898740768
[15/24] Train loss=0.12612192332744598
[20/24] Train loss=0.12272904068231583
Test set avg_accuracy=90.42% avg_sensitivity=71.38%, avg_specificity=95.94% avg_auc=91.69%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.127909 Test loss=0.269400 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13166745007038116
[5/24] Train loss=0.12001864612102509
[10/24] Train loss=0.11550985276699066
[15/24] Train loss=0.12610755860805511
[20/24] Train loss=0.12270806729793549
Test set avg_accuracy=90.21% avg_sensitivity=73.52%, avg_specificity=95.05% avg_auc=91.99%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.127371 Test loss=0.267048 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12988309562206268
[5/24] Train loss=0.11914803832769394
[10/24] Train loss=0.11566810309886932
[15/24] Train loss=0.12414306402206421
[20/24] Train loss=0.12377598136663437
Test set avg_accuracy=90.13% avg_sensitivity=73.29%, avg_specificity=95.01% avg_auc=92.11%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.127046 Test loss=0.266794 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13212984800338745
[5/24] Train loss=0.1216718927025795
[10/24] Train loss=0.11486198753118515
[15/24] Train loss=0.12602083384990692
[20/24] Train loss=0.12368661910295486
Test set avg_accuracy=90.14% avg_sensitivity=72.94%, avg_specificity=95.13% avg_auc=91.96%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.126818 Test loss=0.268031 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1323622167110443
[5/24] Train loss=0.11777912825345993
[10/24] Train loss=0.11380688101053238
[15/24] Train loss=0.12566547095775604
[20/24] Train loss=0.12360768765211105
Test set avg_accuracy=90.29% avg_sensitivity=73.12%, avg_specificity=95.26% avg_auc=92.00%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.126689 Test loss=0.266529 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.13065683841705322
[5/24] Train loss=0.11795829236507416
[10/24] Train loss=0.11546146869659424
[15/24] Train loss=0.12481356412172318
[20/24] Train loss=0.12197235971689224
Test set avg_accuracy=90.38% avg_sensitivity=73.58%, avg_specificity=95.25% avg_auc=91.98%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.126124 Test loss=0.266145 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13248582184314728
[5/24] Train loss=0.1195552796125412
[10/24] Train loss=0.1152249127626419
[15/24] Train loss=0.12356800585985184
[20/24] Train loss=0.12403526902198792
Test set avg_accuracy=90.36% avg_sensitivity=73.17%, avg_specificity=95.35% avg_auc=91.97%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.125960 Test loss=0.266261 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12943799793720245
[5/24] Train loss=0.1202206164598465
[10/24] Train loss=0.1134200394153595
[15/24] Train loss=0.12467402964830399
[20/24] Train loss=0.120841845870018
Test set avg_accuracy=90.13% avg_sensitivity=72.83%, avg_specificity=95.15% avg_auc=91.99%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.126085 Test loss=0.266559 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12832164764404297
[5/24] Train loss=0.11787635833024979
[10/24] Train loss=0.11438233405351639
[15/24] Train loss=0.1231604814529419
[20/24] Train loss=0.12176208198070526
Test set avg_accuracy=90.20% avg_sensitivity=72.65%, avg_specificity=95.28% avg_auc=91.97%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.125557 Test loss=0.266263 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1298377513885498
[5/24] Train loss=0.12066293507814407
[10/24] Train loss=0.11470277607440948
[15/24] Train loss=0.1258760392665863
[20/24] Train loss=0.12409233301877975
Test set avg_accuracy=90.26% avg_sensitivity=72.94%, avg_specificity=95.28% avg_auc=91.95%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.126292 Test loss=0.266423 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1305745244026184
[5/24] Train loss=0.12136167287826538
[10/24] Train loss=0.11390500515699387
[15/24] Train loss=0.12485918402671814
[20/24] Train loss=0.1236567422747612
Test set avg_accuracy=90.31% avg_sensitivity=73.12%, avg_specificity=95.30% avg_auc=91.96%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.125690 Test loss=0.266105 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12932629883289337
[5/24] Train loss=0.11810428649187088
[10/24] Train loss=0.11432301253080368
[15/24] Train loss=0.12272221595048904
[20/24] Train loss=0.12268812954425812
Test set avg_accuracy=90.26% avg_sensitivity=72.94%, avg_specificity=95.28% avg_auc=91.96%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.125575 Test loss=0.266039 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12992683053016663
[5/24] Train loss=0.11950698494911194
[10/24] Train loss=0.11525901407003403
[15/24] Train loss=0.12175317108631134
[20/24] Train loss=0.12227517366409302
Test set avg_accuracy=90.25% avg_sensitivity=73.00%, avg_specificity=95.25% avg_auc=91.95%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.125733 Test loss=0.266143 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.13120967149734497
[5/24] Train loss=0.11922714859247208
[10/24] Train loss=0.11723126471042633
[15/24] Train loss=0.12436039745807648
[20/24] Train loss=0.12308678776025772
Test set avg_accuracy=90.33% avg_sensitivity=73.00%, avg_specificity=95.35% avg_auc=91.96%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.125770 Test loss=0.266074 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=90.21% sen=76.42%, spe=94.21%, auc=94.21%!
Fold[10] Avg_overlap=0.70%(0.248082584065883)
Final Avg Result: avg_acc=88.81%(1.0477694852484423) avg_sen=80.09% (2.0076739270690593) avg_spe=91.79% (1.2900637156097605) avg_auc=93.87% (0.9759350876884786) avg_overlap=0.71% (0.02351162248837572)
