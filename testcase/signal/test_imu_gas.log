/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/24] Train loss=0.7252772450447083
[5/24] Train loss=0.7136523127555847
[10/24] Train loss=0.7061485648155212
[15/24] Train loss=0.6966822743415833
[20/24] Train loss=0.6999857425689697
Test set avg_accuracy=60.29% avg_sensitivity=45.32%, avg_specificity=65.63% avg_auc=59.00%
Best model saved!! Metric=-95.76346192872509!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.705036 Test loss=0.673887 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6925162076950073
[5/24] Train loss=0.6899897456169128
[10/24] Train loss=0.688572347164154
[15/24] Train loss=0.6688704490661621
[20/24] Train loss=0.6648754477500916
Test set avg_accuracy=64.15% avg_sensitivity=70.06%, avg_specificity=62.04% avg_auc=70.77%
Best model saved!! Metric=-58.974227523981575!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.679411 Test loss=0.643029 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6658647060394287
[5/24] Train loss=0.6576107144355774
[10/24] Train loss=0.6599098443984985
[15/24] Train loss=0.6405286192893982
[20/24] Train loss=0.6392667293548584
Test set avg_accuracy=67.20% avg_sensitivity=73.82%, avg_specificity=64.83% avg_auc=75.45%
Best model saved!! Metric=-44.691057250436145!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.652891 Test loss=0.616746 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6401095390319824
[5/24] Train loss=0.633696973323822
[10/24] Train loss=0.6354836225509644
[15/24] Train loss=0.6152969002723694
[20/24] Train loss=0.6001624464988708
Test set avg_accuracy=69.83% avg_sensitivity=77.14%, avg_specificity=67.22% avg_auc=78.91%
Best model saved!! Metric=-32.89972056686547!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.627699 Test loss=0.588237 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6032578945159912
[5/24] Train loss=0.6026594042778015
[10/24] Train loss=0.610654890537262
[15/24] Train loss=0.5835067629814148
[20/24] Train loss=0.575827419757843
Test set avg_accuracy=71.88% avg_sensitivity=79.66%, avg_specificity=69.09% avg_auc=81.17%
Best model saved!! Metric=-24.199795142259163!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.599185 Test loss=0.561681 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.573273241519928
[5/24] Train loss=0.5776558518409729
[10/24] Train loss=0.5831235647201538
[15/24] Train loss=0.5559008717536926
[20/24] Train loss=0.5520915389060974
Test set avg_accuracy=72.94% avg_sensitivity=82.43%, avg_specificity=69.55% avg_auc=83.29%
Best model saved!! Metric=-17.778824425849507!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.573051 Test loss=0.538613 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5474869012832642
[5/24] Train loss=0.5469722151756287
[10/24] Train loss=0.5585319399833679
[15/24] Train loss=0.525854229927063
[20/24] Train loss=0.5205311179161072
Test set avg_accuracy=75.92% avg_sensitivity=82.09%, avg_specificity=73.72% avg_auc=85.08%
Best model saved!! Metric=-9.181703931652706!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.544121 Test loss=0.503060 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5160728693008423
[5/24] Train loss=0.5153089761734009
[10/24] Train loss=0.5293877124786377
[15/24] Train loss=0.4988553524017334
[20/24] Train loss=0.4859635531902313
Test set avg_accuracy=78.12% avg_sensitivity=80.65%, avg_specificity=77.22% avg_auc=86.68%
Best model saved!! Metric=-3.3157821951502484!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.513414 Test loss=0.474818 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.4872403144836426
[5/24] Train loss=0.4882126748561859
[10/24] Train loss=0.4937713146209717
[15/24] Train loss=0.46805745363235474
[20/24] Train loss=0.4600147306919098
Test set avg_accuracy=80.12% avg_sensitivity=81.44%, avg_specificity=79.64% avg_auc=88.26%
Best model saved!! Metric=3.460987828045191!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.483786 Test loss=0.444942 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4524872899055481
[5/24] Train loss=0.45199358463287354
[10/24] Train loss=0.4726899564266205
[15/24] Train loss=0.44253820180892944
[20/24] Train loss=0.4297580420970917
Test set avg_accuracy=81.85% avg_sensitivity=81.30%, avg_specificity=82.05% avg_auc=89.54%
Best model saved!! Metric=8.727415396513095!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.455215 Test loss=0.417439 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4233909845352173
[5/24] Train loss=0.42301225662231445
[10/24] Train loss=0.43791961669921875
[15/24] Train loss=0.41950738430023193
[20/24] Train loss=0.40114063024520874
Test set avg_accuracy=83.22% avg_sensitivity=78.92%, avg_specificity=84.75% avg_auc=90.33%
Best model saved!! Metric=11.215974807055886!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.427487 Test loss=0.392342 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.39509788155555725
[5/24] Train loss=0.3957782983779907
[10/24] Train loss=0.42109689116477966
[15/24] Train loss=0.3963223993778229
[20/24] Train loss=0.3718390166759491
Test set avg_accuracy=84.69% avg_sensitivity=78.23%, avg_specificity=86.99% avg_auc=90.88%
Best model saved!! Metric=14.786532258826057!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.402286 Test loss=0.371670 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3768799602985382
[5/24] Train loss=0.37602517008781433
[10/24] Train loss=0.3922780454158783
[15/24] Train loss=0.3748784065246582
[20/24] Train loss=0.3578132092952728
Test set avg_accuracy=85.72% avg_sensitivity=75.80%, avg_specificity=89.26% avg_auc=91.13%
Best model saved!! Metric=15.908473101383521!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.381629 Test loss=0.352869 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.35433128476142883
[5/24] Train loss=0.35371583700180054
[10/24] Train loss=0.38228949904441833
[15/24] Train loss=0.35771065950393677
[20/24] Train loss=0.3448503017425537
Test set avg_accuracy=86.30% avg_sensitivity=75.31%, avg_specificity=90.23% avg_auc=91.53%
Best model saved!! Metric=17.367357225883538!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.363824 Test loss=0.342018 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3352071940898895
[5/24] Train loss=0.3320954144001007
[10/24] Train loss=0.3608560860157013
[15/24] Train loss=0.34287023544311523
[20/24] Train loss=0.3325510323047638
Test set avg_accuracy=86.68% avg_sensitivity=74.47%, avg_specificity=91.04% avg_auc=91.81%
Best model saved!! Metric=17.997150830558382!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.349327 Test loss=0.329513 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3172372281551361
[5/24] Train loss=0.3223625719547272
[10/24] Train loss=0.35648417472839355
[15/24] Train loss=0.33642780780792236
[20/24] Train loss=0.319626122713089
Test set avg_accuracy=86.86% avg_sensitivity=75.11%, avg_specificity=91.06% avg_auc=92.21%
Best model saved!! Metric=19.24436961563599!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.336749 Test loss=0.324712 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.30632105469703674
[5/24] Train loss=0.3074204623699188
[10/24] Train loss=0.3444214165210724
[15/24] Train loss=0.3229040205478668
[20/24] Train loss=0.30300313234329224
Test set avg_accuracy=87.02% avg_sensitivity=71.80%, avg_specificity=92.45% avg_auc=92.11%
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.325207 Test loss=0.318445 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3016658425331116
[5/24] Train loss=0.2979971170425415
[10/24] Train loss=0.3382253646850586
[15/24] Train loss=0.309546560049057
[20/24] Train loss=0.29932618141174316
Test set avg_accuracy=86.94% avg_sensitivity=73.73%, avg_specificity=91.66% avg_auc=92.48%
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.315478 Test loss=0.311659 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.2792483866214752
[5/24] Train loss=0.29145729541778564
[10/24] Train loss=0.32591119408607483
[15/24] Train loss=0.30732157826423645
[20/24] Train loss=0.2897254526615143
Test set avg_accuracy=87.01% avg_sensitivity=78.97%, avg_specificity=89.87% avg_auc=92.98%
Best model saved!! Metric=22.833109381866066!!
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.307551 Test loss=0.313336 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2851899266242981
[5/24] Train loss=0.28265705704689026
[10/24] Train loss=0.31991755962371826
[15/24] Train loss=0.29239603877067566
[20/24] Train loss=0.279735803604126
Test set avg_accuracy=87.21% avg_sensitivity=77.98%, avg_specificity=90.51% avg_auc=92.91%
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.301371 Test loss=0.311124 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.27078133821487427
[5/24] Train loss=0.2717454433441162
[10/24] Train loss=0.3181225657463074
[15/24] Train loss=0.29108116030693054
[20/24] Train loss=0.2736057937145233
Test set avg_accuracy=87.15% avg_sensitivity=79.22%, avg_specificity=89.98% avg_auc=93.11%
Best model saved!! Metric=23.453301632475757!!
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.294608 Test loss=0.306509 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2667365074157715
[5/24] Train loss=0.26904773712158203
[10/24] Train loss=0.31753242015838623
[15/24] Train loss=0.2861923277378082
[20/24] Train loss=0.26456043124198914
Test set avg_accuracy=87.28% avg_sensitivity=70.91%, avg_specificity=93.13% avg_auc=93.03%
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.288744 Test loss=0.297425 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.26014021039009094
[5/24] Train loss=0.26050320267677307
[10/24] Train loss=0.31248342990875244
[15/24] Train loss=0.2839438021183014
[20/24] Train loss=0.2652316987514496
Test set avg_accuracy=87.53% avg_sensitivity=69.67%, avg_specificity=93.90% avg_auc=92.96%
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.283553 Test loss=0.296386 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.25473257899284363
[5/24] Train loss=0.25076109170913696
[10/24] Train loss=0.29991239309310913
[15/24] Train loss=0.2737683653831482
[20/24] Train loss=0.25612786412239075
Test set avg_accuracy=87.98% avg_sensitivity=73.73%, avg_specificity=93.07% avg_auc=93.50%
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.277709 Test loss=0.286055 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2524259686470032
[5/24] Train loss=0.25078803300857544
[10/24] Train loss=0.2987197935581207
[15/24] Train loss=0.27970296144485474
[20/24] Train loss=0.2519233822822571
Test set avg_accuracy=87.68% avg_sensitivity=66.45%, avg_specificity=95.26% avg_auc=93.13%
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.273868 Test loss=0.294852 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.24721086025238037
[5/24] Train loss=0.2436780035495758
[10/24] Train loss=0.2968807816505432
[15/24] Train loss=0.2667217254638672
[20/24] Train loss=0.25545015931129456
Test set avg_accuracy=87.46% avg_sensitivity=74.67%, avg_specificity=92.03% avg_auc=93.03%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.269623 Test loss=0.297749 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.23993001878261566
[5/24] Train loss=0.24081355333328247
[10/24] Train loss=0.28824031352996826
[15/24] Train loss=0.26201075315475464
[20/24] Train loss=0.25126782059669495
Test set avg_accuracy=87.94% avg_sensitivity=69.22%, avg_specificity=94.63% avg_auc=93.50%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.266458 Test loss=0.287170 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.23492056131362915
[5/24] Train loss=0.24123965203762054
[10/24] Train loss=0.2839578092098236
[15/24] Train loss=0.2486531138420105
[20/24] Train loss=0.24196875095367432
Test set avg_accuracy=87.37% avg_sensitivity=61.80%, avg_specificity=96.50% avg_auc=92.90%
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.263344 Test loss=0.302106 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2435901165008545
[5/24] Train loss=0.2280026525259018
[10/24] Train loss=0.2861270606517792
[15/24] Train loss=0.25408947467803955
[20/24] Train loss=0.23589299619197845
Test set avg_accuracy=87.66% avg_sensitivity=64.52%, avg_specificity=95.92% avg_auc=92.67%
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.258143 Test loss=0.300968 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.23405802249908447
[5/24] Train loss=0.22733032703399658
[10/24] Train loss=0.28332996368408203
[15/24] Train loss=0.247940331697464
[20/24] Train loss=0.23730434477329254
Test set avg_accuracy=87.64% avg_sensitivity=64.52%, avg_specificity=95.90% avg_auc=92.88%
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.256550 Test loss=0.297071 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.23263674974441528
[5/24] Train loss=0.22561262547969818
[10/24] Train loss=0.2846115231513977
[15/24] Train loss=0.2416180968284607
[20/24] Train loss=0.23168829083442688
Test set avg_accuracy=86.56% avg_sensitivity=57.69%, avg_specificity=96.87% avg_auc=91.58%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.253544 Test loss=0.325111 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.22840452194213867
[5/24] Train loss=0.22486744821071625
[10/24] Train loss=0.27863046526908875
[15/24] Train loss=0.23585419356822968
[20/24] Train loss=0.22876597940921783
Test set avg_accuracy=87.67% avg_sensitivity=65.26%, avg_specificity=95.67% avg_auc=92.83%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.249742 Test loss=0.295952 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.22923754155635834
[5/24] Train loss=0.22062824666500092
[10/24] Train loss=0.283464640378952
[15/24] Train loss=0.2442217618227005
[20/24] Train loss=0.23007537424564362
Test set avg_accuracy=82.94% avg_sensitivity=39.19%, avg_specificity=98.57% avg_auc=90.15%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.247592 Test loss=0.400790 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.23526380956172943
[5/24] Train loss=0.2183317095041275
[10/24] Train loss=0.2774723768234253
[15/24] Train loss=0.2335462123155594
[20/24] Train loss=0.2256825864315033
Test set avg_accuracy=81.74% avg_sensitivity=34.44%, avg_specificity=98.64% avg_auc=88.68%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.246384 Test loss=0.416038 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.21562865376472473
[5/24] Train loss=0.2027483433485031
[10/24] Train loss=0.28229814767837524
[15/24] Train loss=0.24499446153640747
[20/24] Train loss=0.2199302613735199
Test set avg_accuracy=84.64% avg_sensitivity=48.94%, avg_specificity=97.38% avg_auc=91.24%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.243551 Test loss=0.349916 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.22708773612976074
[5/24] Train loss=0.21137207746505737
[10/24] Train loss=0.27853623032569885
[15/24] Train loss=0.23602306842803955
[20/24] Train loss=0.23012244701385498
Test set avg_accuracy=86.68% avg_sensitivity=73.68%, avg_specificity=91.32% avg_auc=91.83%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.241979 Test loss=0.316549 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.23038925230503082
[5/24] Train loss=0.22178679704666138
[10/24] Train loss=0.27589812874794006
[15/24] Train loss=0.22906126081943512
[20/24] Train loss=0.22745344042778015
Test set avg_accuracy=86.99% avg_sensitivity=77.93%, avg_specificity=90.23% avg_auc=92.62%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.243259 Test loss=0.307770 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.213478684425354
[5/24] Train loss=0.20372754335403442
[10/24] Train loss=0.2658383548259735
[15/24] Train loss=0.22533558309078217
[20/24] Train loss=0.2227618247270584
Test set avg_accuracy=79.06% avg_sensitivity=21.77%, avg_specificity=99.52% avg_auc=82.91%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.238847 Test loss=0.553720 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.24624212086200714
[5/24] Train loss=0.22204110026359558
[10/24] Train loss=0.276983380317688
[15/24] Train loss=0.2336059957742691
[20/24] Train loss=0.2149198055267334
Test set avg_accuracy=88.06% avg_sensitivity=70.66%, avg_specificity=94.27% avg_auc=93.45%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.241668 Test loss=0.281357 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2171977311372757
[5/24] Train loss=0.2037772536277771
[10/24] Train loss=0.2717803418636322
[15/24] Train loss=0.2327084094285965
[20/24] Train loss=0.21684709191322327
Test set avg_accuracy=83.92% avg_sensitivity=48.99%, avg_specificity=96.40% avg_auc=87.96%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.235857 Test loss=0.394370 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2140265554189682
[5/24] Train loss=0.21238292753696442
[10/24] Train loss=0.279100626707077
[15/24] Train loss=0.23401649296283722
[20/24] Train loss=0.22558856010437012
Test set avg_accuracy=87.55% avg_sensitivity=75.90%, avg_specificity=91.71% avg_auc=93.15%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.236847 Test loss=0.295507 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2062089890241623
[5/24] Train loss=0.20274269580841064
[10/24] Train loss=0.2727625370025635
[15/24] Train loss=0.2281297743320465
[20/24] Train loss=0.2193370908498764
Test set avg_accuracy=85.31% avg_sensitivity=55.32%, avg_specificity=96.02% avg_auc=89.63%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.234324 Test loss=0.356856 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.21773113310337067
[5/24] Train loss=0.19437536597251892
[10/24] Train loss=0.26923224329948425
[15/24] Train loss=0.23128096759319305
[20/24] Train loss=0.21450994908809662
Test set avg_accuracy=82.45% avg_sensitivity=41.02%, avg_specificity=97.24% avg_auc=86.74%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.235595 Test loss=0.435720 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.23475858569145203
[5/24] Train loss=0.2104455679655075
[10/24] Train loss=0.26579663157463074
[15/24] Train loss=0.22466591000556946
[20/24] Train loss=0.2105642557144165
Test set avg_accuracy=85.83% avg_sensitivity=61.75%, avg_specificity=94.43% avg_auc=90.42%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.231885 Test loss=0.335471 Current lr=[0.00029967723776099]

[0/24] Train loss=0.21168982982635498
[5/24] Train loss=0.19469335675239563
[10/24] Train loss=0.259337842464447
[15/24] Train loss=0.22526539862155914
[20/24] Train loss=0.20928631722927094
Test set avg_accuracy=87.90% avg_sensitivity=70.51%, avg_specificity=94.12% avg_auc=92.78%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.230164 Test loss=0.293270 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.21642714738845825
[5/24] Train loss=0.19452524185180664
[10/24] Train loss=0.2704028785228729
[15/24] Train loss=0.21995873749256134
[20/24] Train loss=0.21093466877937317
Test set avg_accuracy=86.20% avg_sensitivity=57.84%, avg_specificity=96.32% avg_auc=91.35%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.226564 Test loss=0.331483 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.20760959386825562
[5/24] Train loss=0.1901559680700302
[10/24] Train loss=0.24824003875255585
[15/24] Train loss=0.2178666889667511
[20/24] Train loss=0.21764671802520752
Test set avg_accuracy=84.75% avg_sensitivity=50.92%, avg_specificity=96.84% avg_auc=86.97%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.220329 Test loss=0.388648 Current lr=[0.000299720220882401]

[0/24] Train loss=0.20025211572647095
[5/24] Train loss=0.18600212037563324
[10/24] Train loss=0.2584371268749237
[15/24] Train loss=0.23402027785778046
[20/24] Train loss=0.21150748431682587
Test set avg_accuracy=86.39% avg_sensitivity=69.87%, avg_specificity=92.30% avg_auc=91.89%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.224616 Test loss=0.312957 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19570767879486084
[5/24] Train loss=0.18985138833522797
[10/24] Train loss=0.2603400945663452
[15/24] Train loss=0.23607833683490753
[20/24] Train loss=0.2058115005493164
Test set avg_accuracy=82.80% avg_sensitivity=40.23%, avg_specificity=98.00% avg_auc=87.50%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.225528 Test loss=0.449353 Current lr=[0.000298904600941902]

[0/24] Train loss=0.20424659550189972
[5/24] Train loss=0.19319580495357513
[10/24] Train loss=0.2682438790798187
[15/24] Train loss=0.21945726871490479
[20/24] Train loss=0.20954370498657227
Test set avg_accuracy=84.84% avg_sensitivity=53.74%, avg_specificity=95.95% avg_auc=89.02%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.226151 Test loss=0.363089 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.19736211001873016
[5/24] Train loss=0.19593992829322815
[10/24] Train loss=0.25923094153404236
[15/24] Train loss=0.22441956400871277
[20/24] Train loss=0.19875860214233398
Test set avg_accuracy=87.04% avg_sensitivity=65.56%, avg_specificity=94.72% avg_auc=91.44%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.223163 Test loss=0.317063 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2042197585105896
[5/24] Train loss=0.18410120904445648
[10/24] Train loss=0.2501029968261719
[15/24] Train loss=0.21903792023658752
[20/24] Train loss=0.20189198851585388
Test set avg_accuracy=84.60% avg_sensitivity=54.97%, avg_specificity=95.18% avg_auc=88.06%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.218214 Test loss=0.376891 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.20133797824382782
[5/24] Train loss=0.1932584047317505
[10/24] Train loss=0.2566201984882355
[15/24] Train loss=0.22203926742076874
[20/24] Train loss=0.19927723705768585
Test set avg_accuracy=85.09% avg_sensitivity=57.30%, avg_specificity=95.02% avg_auc=88.34%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.219880 Test loss=0.369051 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.199544757604599
[5/24] Train loss=0.1829303354024887
[10/24] Train loss=0.25326088070869446
[15/24] Train loss=0.22704897820949554
[20/24] Train loss=0.21218904852867126
Test set avg_accuracy=86.45% avg_sensitivity=64.08%, avg_specificity=94.43% avg_auc=91.62%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.220669 Test loss=0.318606 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2033841907978058
[5/24] Train loss=0.18126724660396576
[10/24] Train loss=0.24421267211437225
[15/24] Train loss=0.215529203414917
[20/24] Train loss=0.1932760775089264
Test set avg_accuracy=86.11% avg_sensitivity=71.94%, avg_specificity=91.16% avg_auc=91.25%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.213387 Test loss=0.330077 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.1919984221458435
[5/24] Train loss=0.193092480301857
[10/24] Train loss=0.24868108332157135
[15/24] Train loss=0.2291872799396515
[20/24] Train loss=0.19922830164432526
Test set avg_accuracy=86.84% avg_sensitivity=77.78%, avg_specificity=90.07% avg_auc=92.65%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.214815 Test loss=0.305275 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.19982248544692993
[5/24] Train loss=0.1829700618982315
[10/24] Train loss=0.23578371107578278
[15/24] Train loss=0.23170407116413116
[20/24] Train loss=0.19970519840717316
Test set avg_accuracy=84.30% avg_sensitivity=80.41%, avg_specificity=85.69% avg_auc=91.62%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.218394 Test loss=0.344512 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.19404704868793488
[5/24] Train loss=0.1873047798871994
[10/24] Train loss=0.24497586488723755
[15/24] Train loss=0.2217758297920227
[20/24] Train loss=0.19840390980243683
Test set avg_accuracy=79.67% avg_sensitivity=85.90%, avg_specificity=77.45% avg_auc=89.36%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.216133 Test loss=0.454813 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.20206189155578613
[5/24] Train loss=0.17807289958000183
[10/24] Train loss=0.24139010906219482
[15/24] Train loss=0.2155790477991104
[20/24] Train loss=0.20544438064098358
Test set avg_accuracy=85.34% avg_sensitivity=78.18%, avg_specificity=87.90% avg_auc=91.65%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.214349 Test loss=0.334946 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.19631953537464142
[5/24] Train loss=0.18364198505878448
[10/24] Train loss=0.2482433170080185
[15/24] Train loss=0.2158806473016739
[20/24] Train loss=0.20451807975769043
Test set avg_accuracy=80.09% avg_sensitivity=82.93%, avg_specificity=79.08% avg_auc=89.65%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.210474 Test loss=0.432518 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.18156656622886658
[5/24] Train loss=0.17770753800868988
[10/24] Train loss=0.23609954118728638
[15/24] Train loss=0.21571296453475952
[20/24] Train loss=0.19173724949359894
Test set avg_accuracy=84.51% avg_sensitivity=66.55%, avg_specificity=90.92% avg_auc=89.29%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.205807 Test loss=0.360950 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.19048400223255157
[5/24] Train loss=0.17674583196640015
[10/24] Train loss=0.2402201145887375
[15/24] Train loss=0.20475232601165771
[20/24] Train loss=0.19536705315113068
Test set avg_accuracy=85.99% avg_sensitivity=67.74%, avg_specificity=92.51% avg_auc=90.76%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.207240 Test loss=0.335831 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.19218795001506805
[5/24] Train loss=0.1700132191181183
[10/24] Train loss=0.24359312653541565
[15/24] Train loss=0.2074050009250641
[20/24] Train loss=0.2019043117761612
Test set avg_accuracy=86.61% avg_sensitivity=75.31%, avg_specificity=90.65% avg_auc=92.04%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.203336 Test loss=0.316586 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.1907602846622467
[5/24] Train loss=0.18009519577026367
[10/24] Train loss=0.22942587733268738
[15/24] Train loss=0.20017904043197632
[20/24] Train loss=0.18979483842849731
Test set avg_accuracy=86.34% avg_sensitivity=70.91%, avg_specificity=91.85% avg_auc=90.98%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.201691 Test loss=0.327446 Current lr=[0.000276307469034998]

[0/24] Train loss=0.18240779638290405
[5/24] Train loss=0.17318443953990936
[10/24] Train loss=0.22724464535713196
[15/24] Train loss=0.2074459195137024
[20/24] Train loss=0.18825463950634003
Test set avg_accuracy=86.52% avg_sensitivity=78.13%, avg_specificity=89.52% avg_auc=92.37%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.197233 Test loss=0.315181 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.18514084815979004
[5/24] Train loss=0.17458659410476685
[10/24] Train loss=0.24020716547966003
[15/24] Train loss=0.20569947361946106
[20/24] Train loss=0.1890302449464798
Test set avg_accuracy=84.08% avg_sensitivity=47.40%, avg_specificity=97.17% avg_auc=86.98%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.203781 Test loss=0.395400 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.17847780883312225
[5/24] Train loss=0.18342216312885284
[10/24] Train loss=0.2227095663547516
[15/24] Train loss=0.21846608817577362
[20/24] Train loss=0.18606069684028625
Test set avg_accuracy=85.90% avg_sensitivity=56.46%, avg_specificity=96.41% avg_auc=88.94%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.199662 Test loss=0.366373 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.1805969625711441
[5/24] Train loss=0.17083775997161865
[10/24] Train loss=0.23119595646858215
[15/24] Train loss=0.19481952488422394
[20/24] Train loss=0.18280142545700073
Test set avg_accuracy=81.00% avg_sensitivity=87.14%, avg_specificity=78.81% avg_auc=89.79%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.200951 Test loss=0.443532 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.1804320216178894
[5/24] Train loss=0.17658370733261108
[10/24] Train loss=0.23127038776874542
[15/24] Train loss=0.21204455196857452
[20/24] Train loss=0.1896204799413681
Test set avg_accuracy=85.76% avg_sensitivity=73.58%, avg_specificity=90.10% avg_auc=91.69%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.204404 Test loss=0.321196 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.18307943642139435
[5/24] Train loss=0.17689765989780426
[10/24] Train loss=0.22099123895168304
[15/24] Train loss=0.19861938059329987
[20/24] Train loss=0.18912604451179504
Test set avg_accuracy=82.16% avg_sensitivity=86.64%, avg_specificity=80.56% avg_auc=90.99%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.198899 Test loss=0.404449 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.18328343331813812
[5/24] Train loss=0.18525910377502441
[10/24] Train loss=0.22401228547096252
[15/24] Train loss=0.20324914157390594
[20/24] Train loss=0.20077353715896606
Test set avg_accuracy=86.52% avg_sensitivity=73.18%, avg_specificity=91.29% avg_auc=91.49%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.202407 Test loss=0.318737 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.18730247020721436
[5/24] Train loss=0.1719713807106018
[10/24] Train loss=0.23660694062709808
[15/24] Train loss=0.20970012247562408
[20/24] Train loss=0.1837203949689865
Test set avg_accuracy=84.53% avg_sensitivity=84.36%, avg_specificity=84.59% avg_auc=92.23%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.199413 Test loss=0.350153 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.17321383953094482
[5/24] Train loss=0.16750085353851318
[10/24] Train loss=0.24518433213233948
[15/24] Train loss=0.21007034182548523
[20/24] Train loss=0.19118833541870117
Test set avg_accuracy=81.46% avg_sensitivity=83.62%, avg_specificity=80.69% avg_auc=89.82%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.198425 Test loss=0.411189 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.17105194926261902
[5/24] Train loss=0.17044952511787415
[10/24] Train loss=0.23069623112678528
[15/24] Train loss=0.19760294258594513
[20/24] Train loss=0.18586820363998413
Test set avg_accuracy=86.04% avg_sensitivity=70.71%, avg_specificity=91.52% avg_auc=90.04%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.195512 Test loss=0.335608 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.17582720518112183
[5/24] Train loss=0.1608065366744995
[10/24] Train loss=0.2258843183517456
[15/24] Train loss=0.19873909652233124
[20/24] Train loss=0.19669368863105774
Test set avg_accuracy=86.76% avg_sensitivity=66.80%, avg_specificity=93.89% avg_auc=91.59%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.194353 Test loss=0.313840 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.18031153082847595
[5/24] Train loss=0.173244446516037
[10/24] Train loss=0.22163358330726624
[15/24] Train loss=0.18865592777729034
[20/24] Train loss=0.1768016517162323
Test set avg_accuracy=82.41% avg_sensitivity=85.60%, avg_specificity=81.27% avg_auc=91.38%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.195414 Test loss=0.394199 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.17368873953819275
[5/24] Train loss=0.17072977125644684
[10/24] Train loss=0.22593775391578674
[15/24] Train loss=0.21077774465084076
[20/24] Train loss=0.19568486511707306
Test set avg_accuracy=85.64% avg_sensitivity=74.91%, avg_specificity=89.47% avg_auc=91.42%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.195986 Test loss=0.324517 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.1816026121377945
[5/24] Train loss=0.16887471079826355
[10/24] Train loss=0.22172343730926514
[15/24] Train loss=0.18524052202701569
[20/24] Train loss=0.17438994348049164
Test set avg_accuracy=85.69% avg_sensitivity=67.44%, avg_specificity=92.21% avg_auc=90.63%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.189763 Test loss=0.330635 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.16235409677028656
[5/24] Train loss=0.17890436947345734
[10/24] Train loss=0.22526958584785461
[15/24] Train loss=0.20568807423114777
[20/24] Train loss=0.1875506043434143
Test set avg_accuracy=84.61% avg_sensitivity=82.38%, avg_specificity=85.40% avg_auc=91.63%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.194850 Test loss=0.349031 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.18014490604400635
[5/24] Train loss=0.1680983603000641
[10/24] Train loss=0.23363123834133148
[15/24] Train loss=0.20365238189697266
[20/24] Train loss=0.18273036181926727
Test set avg_accuracy=86.11% avg_sensitivity=69.77%, avg_specificity=91.94% avg_auc=90.43%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.193051 Test loss=0.334277 Current lr=[0.000224838296036774]

[0/24] Train loss=0.16543783247470856
[5/24] Train loss=0.16381582617759705
[10/24] Train loss=0.21370844542980194
[15/24] Train loss=0.18759207427501678
[20/24] Train loss=0.17883121967315674
Test set avg_accuracy=85.43% avg_sensitivity=77.73%, avg_specificity=88.18% avg_auc=91.29%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.189227 Test loss=0.337928 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.17506660521030426
[5/24] Train loss=0.17192336916923523
[10/24] Train loss=0.22548766434192657
[15/24] Train loss=0.18665705621242523
[20/24] Train loss=0.17900872230529785
Test set avg_accuracy=87.12% avg_sensitivity=75.41%, avg_specificity=91.31% avg_auc=92.38%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.195091 Test loss=0.304680 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.17325487732887268
[5/24] Train loss=0.17446208000183105
[10/24] Train loss=0.21808743476867676
[15/24] Train loss=0.1954997479915619
[20/24] Train loss=0.1845056116580963
Test set avg_accuracy=86.16% avg_sensitivity=78.38%, avg_specificity=88.94% avg_auc=92.30%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.189503 Test loss=0.318953 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.17030589282512665
[5/24] Train loss=0.16749687492847443
[10/24] Train loss=0.21699365973472595
[15/24] Train loss=0.1865176260471344
[20/24] Train loss=0.16955611109733582
Test set avg_accuracy=81.68% avg_sensitivity=86.05%, avg_specificity=80.12% avg_auc=90.64%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.186566 Test loss=0.415210 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.17093494534492493
[5/24] Train loss=0.16047745943069458
[10/24] Train loss=0.21441605687141418
[15/24] Train loss=0.18828153610229492
[20/24] Train loss=0.1804904043674469
Test set avg_accuracy=71.50% avg_sensitivity=89.71%, avg_specificity=64.99% avg_auc=86.80%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.187979 Test loss=0.598069 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.18208050727844238
[5/24] Train loss=0.170246422290802
[10/24] Train loss=0.2074921429157257
[15/24] Train loss=0.19291189312934875
[20/24] Train loss=0.17410700023174286
Test set avg_accuracy=84.62% avg_sensitivity=81.00%, avg_specificity=85.92% avg_auc=91.56%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.186523 Test loss=0.347886 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1667344868183136
[5/24] Train loss=0.15604908764362335
[10/24] Train loss=0.2061690390110016
[15/24] Train loss=0.17882627248764038
[20/24] Train loss=0.1789056807756424
Test set avg_accuracy=75.83% avg_sensitivity=89.41%, avg_specificity=70.98% avg_auc=88.08%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.180423 Test loss=0.543127 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.16079677641391754
[5/24] Train loss=0.16768266260623932
[10/24] Train loss=0.2063901126384735
[15/24] Train loss=0.1867518573999405
[20/24] Train loss=0.172785684466362
Test set avg_accuracy=86.25% avg_sensitivity=73.08%, avg_specificity=90.95% avg_auc=91.08%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.184170 Test loss=0.323960 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.15799804031848907
[5/24] Train loss=0.1590784192085266
[10/24] Train loss=0.19951589405536652
[15/24] Train loss=0.1837260127067566
[20/24] Train loss=0.17092950642108917
Test set avg_accuracy=81.63% avg_sensitivity=85.25%, avg_specificity=80.33% avg_auc=90.66%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.178999 Test loss=0.402367 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.1637660712003708
[5/24] Train loss=0.15376384556293488
[10/24] Train loss=0.19954103231430054
[15/24] Train loss=0.1813909113407135
[20/24] Train loss=0.17824682593345642
Test set avg_accuracy=68.97% avg_sensitivity=89.36%, avg_specificity=61.69% avg_auc=85.18%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.176756 Test loss=0.632947 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.16505369544029236
[5/24] Train loss=0.17022378742694855
[10/24] Train loss=0.20340336859226227
[15/24] Train loss=0.18674199283123016
[20/24] Train loss=0.17468221485614777
Test set avg_accuracy=85.56% avg_sensitivity=79.07%, avg_specificity=87.88% avg_auc=91.94%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.183232 Test loss=0.329389 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.16371189057826996
[5/24] Train loss=0.16895249485969543
[10/24] Train loss=0.205415740609169
[15/24] Train loss=0.18234267830848694
[20/24] Train loss=0.17237292230129242
Test set avg_accuracy=85.99% avg_sensitivity=70.95%, avg_specificity=91.36% avg_auc=91.41%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.182679 Test loss=0.323872 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1585536152124405
[5/24] Train loss=0.16791969537734985
[10/24] Train loss=0.21126039326190948
[15/24] Train loss=0.18313093483448029
[20/24] Train loss=0.17408578097820282
Test set avg_accuracy=84.35% avg_sensitivity=81.64%, avg_specificity=85.32% avg_auc=90.77%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.181419 Test loss=0.365940 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.16552357375621796
[5/24] Train loss=0.15871109068393707
[10/24] Train loss=0.19872793555259705
[15/24] Train loss=0.17827863991260529
[20/24] Train loss=0.18183864653110504
Test set avg_accuracy=85.39% avg_sensitivity=77.54%, avg_specificity=88.20% avg_auc=91.26%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.180063 Test loss=0.342242 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.17095842957496643
[5/24] Train loss=0.1575341373682022
[10/24] Train loss=0.19615116715431213
[15/24] Train loss=0.18936985731124878
[20/24] Train loss=0.18096233904361725
Test set avg_accuracy=85.83% avg_sensitivity=78.97%, avg_specificity=88.28% avg_auc=92.02%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.179616 Test loss=0.333993 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.16577109694480896
[5/24] Train loss=0.1637418568134308
[10/24] Train loss=0.20678074657917023
[15/24] Train loss=0.1906965672969818
[20/24] Train loss=0.17468421161174774
Test set avg_accuracy=85.38% avg_sensitivity=75.41%, avg_specificity=88.94% avg_auc=91.30%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.178951 Test loss=0.331703 Current lr=[0.000156543481933168]

[0/24] Train loss=0.163849875330925
[5/24] Train loss=0.15782007575035095
[10/24] Train loss=0.20165416598320007
[15/24] Train loss=0.17440104484558105
[20/24] Train loss=0.16810500621795654
Test set avg_accuracy=86.28% avg_sensitivity=64.62%, avg_specificity=94.01% avg_auc=89.64%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.175031 Test loss=0.352867 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.15547820925712585
[5/24] Train loss=0.16110651195049286
[10/24] Train loss=0.19448095560073853
[15/24] Train loss=0.1756071299314499
[20/24] Train loss=0.17063285410404205
Test set avg_accuracy=86.55% avg_sensitivity=65.96%, avg_specificity=93.90% avg_auc=90.47%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.171774 Test loss=0.333102 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.16484345495700836
[5/24] Train loss=0.15483282506465912
[10/24] Train loss=0.1967286914587021
[15/24] Train loss=0.18164590001106262
[20/24] Train loss=0.17582575976848602
Test set avg_accuracy=86.48% avg_sensitivity=67.74%, avg_specificity=93.18% avg_auc=90.85%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.173536 Test loss=0.325895 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.1572861522436142
[5/24] Train loss=0.15072764456272125
[10/24] Train loss=0.1858949512243271
[15/24] Train loss=0.17340904474258423
[20/24] Train loss=0.16708149015903473
Test set avg_accuracy=86.35% avg_sensitivity=78.48%, avg_specificity=89.17% avg_auc=92.48%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.168460 Test loss=0.322119 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15329556167125702
[5/24] Train loss=0.14902397990226746
[10/24] Train loss=0.18879860639572144
[15/24] Train loss=0.17315684258937836
[20/24] Train loss=0.16244272887706757
Test set avg_accuracy=87.29% avg_sensitivity=70.21%, avg_specificity=93.39% avg_auc=91.11%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.165811 Test loss=0.322023 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15545642375946045
[5/24] Train loss=0.1521090865135193
[10/24] Train loss=0.1889013797044754
[15/24] Train loss=0.17149575054645538
[20/24] Train loss=0.1663477122783661
Test set avg_accuracy=87.03% avg_sensitivity=76.84%, avg_specificity=90.67% avg_auc=91.86%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.165873 Test loss=0.318964 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1463916003704071
[5/24] Train loss=0.15501992404460907
[10/24] Train loss=0.1788518875837326
[15/24] Train loss=0.16967441141605377
[20/24] Train loss=0.1621890813112259
Test set avg_accuracy=86.98% avg_sensitivity=63.73%, avg_specificity=95.28% avg_auc=89.59%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.164448 Test loss=0.335184 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.15461455285549164
[5/24] Train loss=0.14921973645687103
[10/24] Train loss=0.17789466679096222
[15/24] Train loss=0.16955901682376862
[20/24] Train loss=0.1588522046804428
Test set avg_accuracy=85.99% avg_sensitivity=80.06%, avg_specificity=88.11% avg_auc=92.52%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.163882 Test loss=0.323521 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.1481521874666214
[5/24] Train loss=0.1533282995223999
[10/24] Train loss=0.1794438511133194
[15/24] Train loss=0.16668587923049927
[20/24] Train loss=0.15946850180625916
Test set avg_accuracy=86.21% avg_sensitivity=61.41%, avg_specificity=95.07% avg_auc=89.06%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.164243 Test loss=0.352235 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.15104344487190247
[5/24] Train loss=0.14534617960453033
[10/24] Train loss=0.18287606537342072
[15/24] Train loss=0.18131403625011444
[20/24] Train loss=0.15493473410606384
Test set avg_accuracy=86.18% avg_sensitivity=63.43%, avg_specificity=94.31% avg_auc=88.65%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.161701 Test loss=0.356729 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1473914235830307
[5/24] Train loss=0.1458940953016281
[10/24] Train loss=0.16909176111221313
[15/24] Train loss=0.17092785239219666
[20/24] Train loss=0.1503712385892868
Test set avg_accuracy=86.71% avg_sensitivity=72.49%, avg_specificity=91.78% avg_auc=90.90%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.159099 Test loss=0.326623 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1420917809009552
[5/24] Train loss=0.14161454141139984
[10/24] Train loss=0.16967487335205078
[15/24] Train loss=0.16531845927238464
[20/24] Train loss=0.15393444895744324
Test set avg_accuracy=86.54% avg_sensitivity=63.93%, avg_specificity=94.61% avg_auc=88.65%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.156594 Test loss=0.358755 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.14080002903938293
[5/24] Train loss=0.14068575203418732
[10/24] Train loss=0.17124146223068237
[15/24] Train loss=0.17432668805122375
[20/24] Train loss=0.1537056416273117
Test set avg_accuracy=86.77% avg_sensitivity=67.24%, avg_specificity=93.74% avg_auc=89.36%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.157981 Test loss=0.343894 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14026932418346405
[5/24] Train loss=0.1439819633960724
[10/24] Train loss=0.17002752423286438
[15/24] Train loss=0.16327862441539764
[20/24] Train loss=0.1532008945941925
Test set avg_accuracy=86.72% avg_sensitivity=73.03%, avg_specificity=91.61% avg_auc=90.69%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.157574 Test loss=0.334845 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.13953368365764618
[5/24] Train loss=0.1386791169643402
[10/24] Train loss=0.16855673491954803
[15/24] Train loss=0.17143790423870087
[20/24] Train loss=0.15041546523571014
Test set avg_accuracy=86.18% avg_sensitivity=69.27%, avg_specificity=92.22% avg_auc=89.89%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.154842 Test loss=0.345156 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.13828477263450623
[5/24] Train loss=0.1441584974527359
[10/24] Train loss=0.17005521059036255
[15/24] Train loss=0.16304394602775574
[20/24] Train loss=0.15153449773788452
Test set avg_accuracy=86.86% avg_sensitivity=69.12%, avg_specificity=93.20% avg_auc=90.72%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.155989 Test loss=0.331648 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14824619889259338
[5/24] Train loss=0.14112123847007751
[10/24] Train loss=0.1704353392124176
[15/24] Train loss=0.1602545529603958
[20/24] Train loss=0.15156733989715576
Test set avg_accuracy=86.69% avg_sensitivity=70.95%, avg_specificity=92.31% avg_auc=90.45%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.155246 Test loss=0.331548 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14049005508422852
[5/24] Train loss=0.13958796858787537
[10/24] Train loss=0.16552495956420898
[15/24] Train loss=0.16184811294078827
[20/24] Train loss=0.1483980417251587
Test set avg_accuracy=86.54% avg_sensitivity=73.82%, avg_specificity=91.08% avg_auc=90.64%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.153323 Test loss=0.339878 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14019516110420227
[5/24] Train loss=0.1383582502603531
[10/24] Train loss=0.1572873890399933
[15/24] Train loss=0.1582982987165451
[20/24] Train loss=0.1554519534111023
Test set avg_accuracy=86.33% avg_sensitivity=66.20%, avg_specificity=93.51% avg_auc=89.26%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.152883 Test loss=0.349523 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13925117254257202
[5/24] Train loss=0.14701059460639954
[10/24] Train loss=0.1652073860168457
[15/24] Train loss=0.16775377094745636
[20/24] Train loss=0.15685655176639557
Test set avg_accuracy=85.81% avg_sensitivity=78.92%, avg_specificity=88.27% avg_auc=92.11%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.153482 Test loss=0.334162 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13705770671367645
[5/24] Train loss=0.13866308331489563
[10/24] Train loss=0.16086968779563904
[15/24] Train loss=0.1608683466911316
[20/24] Train loss=0.1535697728395462
Test set avg_accuracy=86.15% avg_sensitivity=76.74%, avg_specificity=89.50% avg_auc=91.36%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.152011 Test loss=0.341411 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1351238638162613
[5/24] Train loss=0.13610588014125824
[10/24] Train loss=0.1593930572271347
[15/24] Train loss=0.1554924100637436
[20/24] Train loss=0.1513076275587082
Test set avg_accuracy=85.68% avg_sensitivity=78.62%, avg_specificity=88.20% avg_auc=91.78%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.150703 Test loss=0.334357 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1338391751050949
[5/24] Train loss=0.13511304557323456
[10/24] Train loss=0.16053541004657745
[15/24] Train loss=0.1544717401266098
[20/24] Train loss=0.1492704153060913
Test set avg_accuracy=87.29% avg_sensitivity=74.32%, avg_specificity=91.92% avg_auc=91.52%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.148788 Test loss=0.320544 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1351117342710495
[5/24] Train loss=0.13607889413833618
[10/24] Train loss=0.1614820808172226
[15/24] Train loss=0.15535733103752136
[20/24] Train loss=0.1493605375289917
Test set avg_accuracy=87.11% avg_sensitivity=73.63%, avg_specificity=91.92% avg_auc=91.48%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.147203 Test loss=0.320802 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13604357838630676
[5/24] Train loss=0.13044968247413635
[10/24] Train loss=0.15336450934410095
[15/24] Train loss=0.1490844190120697
[20/24] Train loss=0.14314037561416626
Test set avg_accuracy=86.68% avg_sensitivity=76.99%, avg_specificity=90.14% avg_auc=91.72%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.144430 Test loss=0.324543 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.12698325514793396
[5/24] Train loss=0.12990087270736694
[10/24] Train loss=0.1551993489265442
[15/24] Train loss=0.14792756736278534
[20/24] Train loss=0.146551713347435
Test set avg_accuracy=86.80% avg_sensitivity=73.73%, avg_specificity=91.46% avg_auc=91.79%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.144117 Test loss=0.320259 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1293421983718872
[5/24] Train loss=0.13521616160869598
[10/24] Train loss=0.15270298719406128
[15/24] Train loss=0.14753861725330353
[20/24] Train loss=0.14751583337783813
Test set avg_accuracy=86.95% avg_sensitivity=71.90%, avg_specificity=92.33% avg_auc=91.34%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.142142 Test loss=0.324282 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13083051145076752
[5/24] Train loss=0.12975065410137177
[10/24] Train loss=0.15205399692058563
[15/24] Train loss=0.14772120118141174
[20/24] Train loss=0.1427006721496582
Test set avg_accuracy=86.94% avg_sensitivity=69.62%, avg_specificity=93.13% avg_auc=91.16%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.142086 Test loss=0.330074 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13279224932193756
[5/24] Train loss=0.12670199573040009
[10/24] Train loss=0.1450694054365158
[15/24] Train loss=0.15002216398715973
[20/24] Train loss=0.1401299685239792
Test set avg_accuracy=86.67% avg_sensitivity=70.26%, avg_specificity=92.53% avg_auc=90.50%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.140903 Test loss=0.340688 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12674102187156677
[5/24] Train loss=0.12688815593719482
[10/24] Train loss=0.1470874845981598
[15/24] Train loss=0.14835508167743683
[20/24] Train loss=0.14093920588493347
Test set avg_accuracy=86.86% avg_sensitivity=68.28%, avg_specificity=93.50% avg_auc=90.53%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.140932 Test loss=0.339783 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1275378316640854
[5/24] Train loss=0.12987758219242096
[10/24] Train loss=0.14396950602531433
[15/24] Train loss=0.14901205897331238
[20/24] Train loss=0.14257730543613434
Test set avg_accuracy=85.94% avg_sensitivity=73.18%, avg_specificity=90.49% avg_auc=90.63%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.139880 Test loss=0.345822 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13120797276496887
[5/24] Train loss=0.1324603259563446
[10/24] Train loss=0.14539673924446106
[15/24] Train loss=0.14659161865711212
[20/24] Train loss=0.14026150107383728
Test set avg_accuracy=86.59% avg_sensitivity=78.18%, avg_specificity=89.59% avg_auc=91.69%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.140897 Test loss=0.326832 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12801365554332733
[5/24] Train loss=0.12886866927146912
[10/24] Train loss=0.14571323990821838
[15/24] Train loss=0.14071622490882874
[20/24] Train loss=0.14531823992729187
Test set avg_accuracy=86.11% avg_sensitivity=74.76%, avg_specificity=90.16% avg_auc=91.06%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.139369 Test loss=0.337514 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12645357847213745
[5/24] Train loss=0.1257670521736145
[10/24] Train loss=0.14552932977676392
[15/24] Train loss=0.14041386544704437
[20/24] Train loss=0.14195579290390015
Test set avg_accuracy=85.76% avg_sensitivity=80.16%, avg_specificity=87.75% avg_auc=91.64%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.138533 Test loss=0.338439 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12551862001419067
[5/24] Train loss=0.12469672411680222
[10/24] Train loss=0.14177949726581573
[15/24] Train loss=0.1406518667936325
[20/24] Train loss=0.13892816007137299
Test set avg_accuracy=86.52% avg_sensitivity=76.89%, avg_specificity=89.96% avg_auc=91.83%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.137720 Test loss=0.326626 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12794260680675507
[5/24] Train loss=0.12618909776210785
[10/24] Train loss=0.14118099212646484
[15/24] Train loss=0.14239788055419922
[20/24] Train loss=0.1432669758796692
Test set avg_accuracy=86.07% avg_sensitivity=78.57%, avg_specificity=88.74% avg_auc=92.13%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.137788 Test loss=0.327696 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12538763880729675
[5/24] Train loss=0.12341126799583435
[10/24] Train loss=0.14008395373821259
[15/24] Train loss=0.14261694252490997
[20/24] Train loss=0.1390756368637085
Test set avg_accuracy=86.84% avg_sensitivity=74.62%, avg_specificity=91.20% avg_auc=91.59%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.136548 Test loss=0.326435 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1252286434173584
[5/24] Train loss=0.12361344695091248
[10/24] Train loss=0.13932031393051147
[15/24] Train loss=0.13750645518302917
[20/24] Train loss=0.1377132534980774
Test set avg_accuracy=86.51% avg_sensitivity=73.53%, avg_specificity=91.15% avg_auc=91.31%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.135656 Test loss=0.330882 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12323421239852905
[5/24] Train loss=0.12182073295116425
[10/24] Train loss=0.13667726516723633
[15/24] Train loss=0.13882087171077728
[20/24] Train loss=0.13662759959697723
Test set avg_accuracy=86.37% avg_sensitivity=76.05%, avg_specificity=90.05% avg_auc=91.57%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.133648 Test loss=0.329841 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12077551335096359
[5/24] Train loss=0.12049835920333862
[10/24] Train loss=0.1357988566160202
[15/24] Train loss=0.14203093945980072
[20/24] Train loss=0.1361428052186966
Test set avg_accuracy=86.47% avg_sensitivity=75.71%, avg_specificity=90.32% avg_auc=91.44%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.133111 Test loss=0.330436 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12235788255929947
[5/24] Train loss=0.12203579396009445
[10/24] Train loss=0.13805221021175385
[15/24] Train loss=0.13795720040798187
[20/24] Train loss=0.13846540451049805
Test set avg_accuracy=86.76% avg_sensitivity=74.76%, avg_specificity=91.04% avg_auc=91.34%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.132735 Test loss=0.327639 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1227005198597908
[5/24] Train loss=0.11910825967788696
[10/24] Train loss=0.13804253935813904
[15/24] Train loss=0.1385800838470459
[20/24] Train loss=0.13598601520061493
Test set avg_accuracy=86.64% avg_sensitivity=74.72%, avg_specificity=90.90% avg_auc=91.17%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.132736 Test loss=0.330475 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.11975627392530441
[5/24] Train loss=0.11837446689605713
[10/24] Train loss=0.13497479259967804
[15/24] Train loss=0.13842539489269257
[20/24] Train loss=0.13605110347270966
Test set avg_accuracy=86.78% avg_sensitivity=76.65%, avg_specificity=90.40% avg_auc=91.40%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.131371 Test loss=0.330778 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12137775868177414
[5/24] Train loss=0.1187080442905426
[10/24] Train loss=0.136427104473114
[15/24] Train loss=0.13453362882137299
[20/24] Train loss=0.1336953490972519
Test set avg_accuracy=86.67% avg_sensitivity=75.11%, avg_specificity=90.79% avg_auc=91.34%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.130776 Test loss=0.329624 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1194903627038002
[5/24] Train loss=0.11917822062969208
[10/24] Train loss=0.13843029737472534
[15/24] Train loss=0.13612870872020721
[20/24] Train loss=0.13487344980239868
Test set avg_accuracy=86.81% avg_sensitivity=75.06%, avg_specificity=91.01% avg_auc=91.19%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.130552 Test loss=0.329612 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12011223286390305
[5/24] Train loss=0.11761114746332169
[10/24] Train loss=0.13566532731056213
[15/24] Train loss=0.13657626509666443
[20/24] Train loss=0.13280914723873138
Test set avg_accuracy=86.26% avg_sensitivity=76.00%, avg_specificity=89.93% avg_auc=91.30%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.131023 Test loss=0.333667 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11961506307125092
[5/24] Train loss=0.11937923729419708
[10/24] Train loss=0.13373570144176483
[15/24] Train loss=0.13591134548187256
[20/24] Train loss=0.13599342107772827
Test set avg_accuracy=86.55% avg_sensitivity=75.11%, avg_specificity=90.63% avg_auc=91.24%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.130632 Test loss=0.332906 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.11971533298492432
[5/24] Train loss=0.12014852464199066
[10/24] Train loss=0.13435788452625275
[15/24] Train loss=0.13541729748249054
[20/24] Train loss=0.1355908215045929
Test set avg_accuracy=86.63% avg_sensitivity=74.96%, avg_specificity=90.79% avg_auc=91.33%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.130279 Test loss=0.332565 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11964612454175949
[5/24] Train loss=0.12030959129333496
[10/24] Train loss=0.1341480165719986
[15/24] Train loss=0.1373271346092224
[20/24] Train loss=0.13458067178726196
Test set avg_accuracy=86.65% avg_sensitivity=75.46%, avg_specificity=90.65% avg_auc=91.29%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.130180 Test loss=0.332392 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12084023654460907
[5/24] Train loss=0.11652790009975433
[10/24] Train loss=0.13347461819648743
[15/24] Train loss=0.13667158782482147
[20/24] Train loss=0.13380637764930725
Test set avg_accuracy=86.55% avg_sensitivity=75.56%, avg_specificity=90.48% avg_auc=91.30%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.129953 Test loss=0.332800 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12072566896677017
[5/24] Train loss=0.11888416856527328
[10/24] Train loss=0.1364050954580307
[15/24] Train loss=0.13853242993354797
[20/24] Train loss=0.13329066336154938
Test set avg_accuracy=86.54% avg_sensitivity=75.46%, avg_specificity=90.49% avg_auc=91.37%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.130248 Test loss=0.331965 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1163877546787262
[5/24] Train loss=0.11860489100217819
[10/24] Train loss=0.13405264914035797
[15/24] Train loss=0.1367873251438141
[20/24] Train loss=0.1333698034286499
Test set avg_accuracy=86.46% avg_sensitivity=75.36%, avg_specificity=90.42% avg_auc=91.35%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.129935 Test loss=0.332273 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12112223356962204
[5/24] Train loss=0.11850301176309586
[10/24] Train loss=0.13297095894813538
[15/24] Train loss=0.13571679592132568
[20/24] Train loss=0.13245050609111786
Test set avg_accuracy=86.54% avg_sensitivity=75.41%, avg_specificity=90.51% avg_auc=91.35%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.130037 Test loss=0.332134 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11824046075344086
[5/24] Train loss=0.12117709219455719
[10/24] Train loss=0.13390754163265228
[15/24] Train loss=0.13398155570030212
[20/24] Train loss=0.13557954132556915
Test set avg_accuracy=86.55% avg_sensitivity=75.41%, avg_specificity=90.53% avg_auc=91.33%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.130293 Test loss=0.331877 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=87.15% sen=79.22%, spe=89.98%, auc=93.11%!
Fold[1] Avg_overlap=0.69%(±0.2246010715099812)
[0/24] Train loss=0.7202529907226562
[5/24] Train loss=0.7188862562179565
[10/24] Train loss=0.7063055038452148
[15/24] Train loss=0.7047073245048523
[20/24] Train loss=0.6875250935554504
Test set avg_accuracy=53.03% avg_sensitivity=52.32%, avg_specificity=53.27% avg_auc=54.87%
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.706147 Test loss=0.699665 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6961041688919067
[5/24] Train loss=0.6881211996078491
[10/24] Train loss=0.6778358817100525
[15/24] Train loss=0.667191743850708
[20/24] Train loss=0.6718945503234863
Test set avg_accuracy=64.78% avg_sensitivity=59.05%, avg_specificity=66.68% avg_auc=67.97%
Best model saved!! Metric=-67.51470323544325!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.678296 Test loss=0.625745 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.659528374671936
[5/24] Train loss=0.6507132649421692
[10/24] Train loss=0.6464981436729431
[15/24] Train loss=0.6379836201667786
[20/24] Train loss=0.6404278874397278
Test set avg_accuracy=69.38% avg_sensitivity=66.41%, avg_specificity=70.36% avg_auc=74.86%
Best model saved!! Metric=-44.994041764549294!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.649843 Test loss=0.587160 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6347489953041077
[5/24] Train loss=0.6245293021202087
[10/24] Train loss=0.6133148074150085
[15/24] Train loss=0.6126635074615479
[20/24] Train loss=0.6082698106765747
Test set avg_accuracy=72.71% avg_sensitivity=70.01%, avg_specificity=73.61% avg_auc=78.56%
Best model saved!! Metric=-31.123709275466297!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.623175 Test loss=0.557938 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6043344140052795
[5/24] Train loss=0.5879594683647156
[10/24] Train loss=0.5869620442390442
[15/24] Train loss=0.5885500311851501
[20/24] Train loss=0.581800103187561
Test set avg_accuracy=74.21% avg_sensitivity=72.14%, avg_specificity=74.89% avg_auc=81.02%
Best model saved!! Metric=-23.74206417366723!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.595502 Test loss=0.535841 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5743467211723328
[5/24] Train loss=0.5647850036621094
[10/24] Train loss=0.5551974177360535
[15/24] Train loss=0.5518232583999634
[20/24] Train loss=0.5482209324836731
Test set avg_accuracy=75.98% avg_sensitivity=73.03%, avg_specificity=76.96% avg_auc=82.81%
Best model saved!! Metric=-17.221673218641513!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.566088 Test loss=0.510356 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5372220873832703
[5/24] Train loss=0.5278987288475037
[10/24] Train loss=0.5300542712211609
[15/24] Train loss=0.5207783579826355
[20/24] Train loss=0.522034764289856
Test set avg_accuracy=77.30% avg_sensitivity=74.44%, avg_specificity=78.26% avg_auc=84.39%
Best model saved!! Metric=-11.607576994480326!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.536660 Test loss=0.488237 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5107085704803467
[5/24] Train loss=0.49746954441070557
[10/24] Train loss=0.499079167842865
[15/24] Train loss=0.49284613132476807
[20/24] Train loss=0.48575645685195923
Test set avg_accuracy=79.23% avg_sensitivity=74.23%, avg_specificity=80.90% avg_auc=85.48%
Best model saved!! Metric=-6.161186288579529!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.507325 Test loss=0.462908 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.4835159480571747
[5/24] Train loss=0.4682067334651947
[10/24] Train loss=0.46477869153022766
[15/24] Train loss=0.46322599053382874
[20/24] Train loss=0.4548978805541992
Test set avg_accuracy=80.46% avg_sensitivity=75.43%, avg_specificity=82.13% avg_auc=86.70%
Best model saved!! Metric=-1.2886082597465531!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.477607 Test loss=0.443544 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4502240717411041
[5/24] Train loss=0.4342036247253418
[10/24] Train loss=0.4400302767753601
[15/24] Train loss=0.43387502431869507
[20/24] Train loss=0.42155635356903076
Test set avg_accuracy=82.15% avg_sensitivity=74.91%, avg_specificity=84.56% avg_auc=87.64%
Best model saved!! Metric=3.249093375794999!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.449232 Test loss=0.420998 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.42494502663612366
[5/24] Train loss=0.40750765800476074
[10/24] Train loss=0.4160105288028717
[15/24] Train loss=0.4028775691986084
[20/24] Train loss=0.3953789472579956
Test set avg_accuracy=82.84% avg_sensitivity=75.64%, avg_specificity=85.23% avg_auc=88.60%
Best model saved!! Metric=6.310462037937668!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.423625 Test loss=0.407130 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.39545938372612
[5/24] Train loss=0.3861595094203949
[10/24] Train loss=0.39518865942955017
[15/24] Train loss=0.38211315870285034
[20/24] Train loss=0.36908504366874695
Test set avg_accuracy=84.28% avg_sensitivity=72.72%, avg_specificity=88.13% avg_auc=89.20%
Best model saved!! Metric=8.332208249622255!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.401471 Test loss=0.378673 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.37945234775543213
[5/24] Train loss=0.3666516840457916
[10/24] Train loss=0.37926816940307617
[15/24] Train loss=0.36473962664604187
[20/24] Train loss=0.3477630913257599
Test set avg_accuracy=84.53% avg_sensitivity=73.66%, avg_specificity=88.15% avg_auc=89.62%
Best model saved!! Metric=9.958107298701222!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.381764 Test loss=0.374119 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.35588303208351135
[5/24] Train loss=0.3481210172176361
[10/24] Train loss=0.3587949573993683
[15/24] Train loss=0.3491232693195343
[20/24] Train loss=0.3352528512477875
Test set avg_accuracy=85.17% avg_sensitivity=72.93%, avg_specificity=89.24% avg_auc=90.15%
Best model saved!! Metric=11.488578676588247!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.364061 Test loss=0.357019 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.34212708473205566
[5/24] Train loss=0.329507052898407
[10/24] Train loss=0.349777489900589
[15/24] Train loss=0.33204492926597595
[20/24] Train loss=0.3152432143688202
Test set avg_accuracy=85.17% avg_sensitivity=74.54%, avg_specificity=88.70% avg_auc=90.43%
Best model saved!! Metric=12.850358910630348!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.350676 Test loss=0.358049 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.32049357891082764
[5/24] Train loss=0.3215467035770416
[10/24] Train loss=0.33207276463508606
[15/24] Train loss=0.3187141716480255
[20/24] Train loss=0.3002343475818634
Test set avg_accuracy=85.39% avg_sensitivity=73.60%, avg_specificity=89.31% avg_auc=90.80%
Best model saved!! Metric=13.104787921759709!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.337080 Test loss=0.345427 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3099607527256012
[5/24] Train loss=0.30904218554496765
[10/24] Train loss=0.3227064907550812
[15/24] Train loss=0.3069528341293335
[20/24] Train loss=0.2870329022407532
Test set avg_accuracy=85.10% avg_sensitivity=74.75%, avg_specificity=88.55% avg_auc=90.91%
Best model saved!! Metric=13.316570348854526!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.326891 Test loss=0.345529 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.2941710352897644
[5/24] Train loss=0.2957877516746521
[10/24] Train loss=0.3114715814590454
[15/24] Train loss=0.2985142469406128
[20/24] Train loss=0.2789496183395386
Test set avg_accuracy=85.57% avg_sensitivity=72.72%, avg_specificity=89.85% avg_auc=91.21%
Best model saved!! Metric=13.351473251126862!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.316720 Test loss=0.333620 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.29015257954597473
[5/24] Train loss=0.28793737292289734
[10/24] Train loss=0.3091455101966858
[15/24] Train loss=0.29626160860061646
[20/24] Train loss=0.26868316531181335
Test set avg_accuracy=86.04% avg_sensitivity=70.06%, avg_specificity=91.36% avg_auc=91.42%
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.308675 Test loss=0.320195 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2751133143901825
[5/24] Train loss=0.2821587920188904
[10/24] Train loss=0.29751795530319214
[15/24] Train loss=0.2896389365196228
[20/24] Train loss=0.2606343924999237
Test set avg_accuracy=85.78% avg_sensitivity=74.49%, avg_specificity=89.54% avg_auc=91.63%
Best model saved!! Metric=15.434509406439588!!
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.301582 Test loss=0.324456 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.27386876940727234
[5/24] Train loss=0.27195867896080017
[10/24] Train loss=0.2954062223434448
[15/24] Train loss=0.2784942388534546
[20/24] Train loss=0.25481489300727844
Test set avg_accuracy=85.57% avg_sensitivity=74.39%, avg_specificity=89.29% avg_auc=91.66%
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.294750 Test loss=0.322252 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.26454800367355347
[5/24] Train loss=0.27619922161102295
[10/24] Train loss=0.2907426953315735
[15/24] Train loss=0.2653560936450958
[20/24] Train loss=0.25225287675857544
Test set avg_accuracy=85.65% avg_sensitivity=75.33%, avg_specificity=89.09% avg_auc=91.61%
Best model saved!! Metric=15.676967855091362!!
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.288499 Test loss=0.325792 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.26534324884414673
[5/24] Train loss=0.276358425617218
[10/24] Train loss=0.2818264663219452
[15/24] Train loss=0.260826975107193
[20/24] Train loss=0.24183520674705505
Test set avg_accuracy=84.38% avg_sensitivity=78.77%, avg_specificity=86.24% avg_auc=91.14%
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.284159 Test loss=0.349872 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.25816115736961365
[5/24] Train loss=0.25868526101112366
[10/24] Train loss=0.28076833486557007
[15/24] Train loss=0.2546043395996094
[20/24] Train loss=0.24139957129955292
Test set avg_accuracy=86.28% avg_sensitivity=73.45%, avg_specificity=90.54% avg_auc=91.96%
Best model saved!! Metric=16.227001828315224!!
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.276769 Test loss=0.315754 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.255470871925354
[5/24] Train loss=0.2563433349132538
[10/24] Train loss=0.2654467225074768
[15/24] Train loss=0.2502983808517456
[20/24] Train loss=0.22851882874965668
Test set avg_accuracy=86.22% avg_sensitivity=74.33%, avg_specificity=90.18% avg_auc=91.85%
Best model saved!! Metric=16.591820844807472!!
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.270454 Test loss=0.315139 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.24106095731258392
[5/24] Train loss=0.25764569640159607
[10/24] Train loss=0.26517778635025024
[15/24] Train loss=0.2519754469394684
[20/24] Train loss=0.23114356398582458
Test set avg_accuracy=85.60% avg_sensitivity=77.73%, avg_specificity=88.22% avg_auc=91.54%
Best model saved!! Metric=17.080892760960666!!
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.267924 Test loss=0.330867 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.24411828815937042
[5/24] Train loss=0.2447201907634735
[10/24] Train loss=0.2615543007850647
[15/24] Train loss=0.24187305569648743
[20/24] Train loss=0.23243878781795502
Test set avg_accuracy=86.41% avg_sensitivity=58.58%, avg_specificity=95.66% avg_auc=91.55%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.263965 Test loss=0.317398 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.24260596930980682
[5/24] Train loss=0.24287822842597961
[10/24] Train loss=0.2618426978588104
[15/24] Train loss=0.24621039628982544
[20/24] Train loss=0.22314906120300293
Test set avg_accuracy=86.54% avg_sensitivity=71.83%, avg_specificity=91.43% avg_auc=91.97%
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.260882 Test loss=0.305726 Current lr=[0.000210185142098938]

[0/24] Train loss=0.23232579231262207
[5/24] Train loss=0.23992666602134705
[10/24] Train loss=0.2586618661880493
[15/24] Train loss=0.24857769906520844
[20/24] Train loss=0.22695481777191162
Test set avg_accuracy=86.78% avg_sensitivity=73.08%, avg_specificity=91.34% avg_auc=92.10%
Best model saved!! Metric=17.308387708623144!!
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.258177 Test loss=0.304824 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.22454312443733215
[5/24] Train loss=0.23600630462169647
[10/24] Train loss=0.2574619948863983
[15/24] Train loss=0.23711015284061432
[20/24] Train loss=0.21821001172065735
Test set avg_accuracy=85.14% avg_sensitivity=48.20%, avg_specificity=97.43% avg_auc=90.43%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.252674 Test loss=0.346691 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.23148450255393982
[5/24] Train loss=0.22261664271354675
[10/24] Train loss=0.25237709283828735
[15/24] Train loss=0.23124265670776367
[20/24] Train loss=0.2241869419813156
Test set avg_accuracy=86.55% avg_sensitivity=64.06%, avg_specificity=94.03% avg_auc=91.74%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.248227 Test loss=0.308165 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.23229286074638367
[5/24] Train loss=0.22307823598384857
[10/24] Train loss=0.26144200563430786
[15/24] Train loss=0.23636873066425323
[20/24] Train loss=0.2135993391275406
Test set avg_accuracy=86.35% avg_sensitivity=69.64%, avg_specificity=91.91% avg_auc=91.57%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.245113 Test loss=0.311811 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.22204060852527618
[5/24] Train loss=0.22052253782749176
[10/24] Train loss=0.2558571994304657
[15/24] Train loss=0.22903244197368622
[20/24] Train loss=0.21338018774986267
Test set avg_accuracy=84.83% avg_sensitivity=74.28%, avg_specificity=88.34% avg_auc=90.49%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.243872 Test loss=0.345932 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.222561314702034
[5/24] Train loss=0.21878241002559662
[10/24] Train loss=0.24539700150489807
[15/24] Train loss=0.22097766399383545
[20/24] Train loss=0.2057369500398636
Test set avg_accuracy=84.32% avg_sensitivity=51.23%, avg_specificity=95.33% avg_auc=89.44%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.240803 Test loss=0.352023 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.22007052600383759
[5/24] Train loss=0.2116994708776474
[10/24] Train loss=0.24031710624694824
[15/24] Train loss=0.22709831595420837
[20/24] Train loss=0.2187841832637787
Test set avg_accuracy=85.53% avg_sensitivity=71.83%, avg_specificity=90.09% avg_auc=90.19%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.241862 Test loss=0.337290 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.21599559485912323
[5/24] Train loss=0.2123340368270874
[10/24] Train loss=0.24784137308597565
[15/24] Train loss=0.22706487774848938
[20/24] Train loss=0.21179358661174774
Test set avg_accuracy=85.65% avg_sensitivity=53.99%, avg_specificity=96.18% avg_auc=90.54%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.238471 Test loss=0.336597 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.21958860754966736
[5/24] Train loss=0.21533101797103882
[10/24] Train loss=0.24288268387317657
[15/24] Train loss=0.22417514026165009
[20/24] Train loss=0.21228766441345215
Test set avg_accuracy=85.98% avg_sensitivity=59.15%, avg_specificity=94.90% avg_auc=90.18%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.236033 Test loss=0.333090 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.22055529057979584
[5/24] Train loss=0.21329283714294434
[10/24] Train loss=0.24390995502471924
[15/24] Train loss=0.22330081462860107
[20/24] Train loss=0.2174408733844757
Test set avg_accuracy=85.42% avg_sensitivity=68.28%, avg_specificity=91.12% avg_auc=90.50%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.238387 Test loss=0.332175 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.22108060121536255
[5/24] Train loss=0.2095060795545578
[10/24] Train loss=0.23010395467281342
[15/24] Train loss=0.21467746794223785
[20/24] Train loss=0.21095061302185059
Test set avg_accuracy=84.48% avg_sensitivity=47.26%, avg_specificity=96.86% avg_auc=89.73%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.232492 Test loss=0.366272 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.21576863527297974
[5/24] Train loss=0.21325817704200745
[10/24] Train loss=0.25106072425842285
[15/24] Train loss=0.21937641501426697
[20/24] Train loss=0.19638516008853912
Test set avg_accuracy=82.30% avg_sensitivity=33.39%, avg_specificity=98.58% avg_auc=87.70%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.232903 Test loss=0.452209 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2030881643295288
[5/24] Train loss=0.2142544835805893
[10/24] Train loss=0.2354522943496704
[15/24] Train loss=0.22045369446277618
[20/24] Train loss=0.201530322432518
Test set avg_accuracy=86.60% avg_sensitivity=69.33%, avg_specificity=92.35% avg_auc=91.64%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.229095 Test loss=0.308711 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.21190033853054047
[5/24] Train loss=0.19898740947246552
[10/24] Train loss=0.23734880983829498
[15/24] Train loss=0.21043547987937927
[20/24] Train loss=0.21589119732379913
Test set avg_accuracy=82.46% avg_sensitivity=75.53%, avg_specificity=84.76% avg_auc=89.04%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.227479 Test loss=0.387161 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.21566161513328552
[5/24] Train loss=0.21378237009048462
[10/24] Train loss=0.2453458309173584
[15/24] Train loss=0.22657209634780884
[20/24] Train loss=0.19679655134677887
Test set avg_accuracy=78.53% avg_sensitivity=77.31%, avg_specificity=78.93% avg_auc=85.86%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.230362 Test loss=0.465914 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.21548379957675934
[5/24] Train loss=0.20665770769119263
[10/24] Train loss=0.23084495961666107
[15/24] Train loss=0.2033405750989914
[20/24] Train loss=0.19685828685760498
Test set avg_accuracy=85.33% avg_sensitivity=61.61%, avg_specificity=93.22% avg_auc=89.06%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.224348 Test loss=0.351088 Current lr=[0.00029967723776099]

[0/24] Train loss=0.20451605319976807
[5/24] Train loss=0.21671642363071442
[10/24] Train loss=0.23369157314300537
[15/24] Train loss=0.21975724399089813
[20/24] Train loss=0.20099392533302307
Test set avg_accuracy=83.98% avg_sensitivity=77.62%, avg_specificity=86.10% avg_auc=90.50%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.225024 Test loss=0.354541 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2098674774169922
[5/24] Train loss=0.2045477032661438
[10/24] Train loss=0.22753417491912842
[15/24] Train loss=0.2100621461868286
[20/24] Train loss=0.18841296434402466
Test set avg_accuracy=82.90% avg_sensitivity=80.33%, avg_specificity=83.76% avg_auc=90.08%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.218169 Test loss=0.370747 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.206481471657753
[5/24] Train loss=0.22823888063430786
[10/24] Train loss=0.23381395637989044
[15/24] Train loss=0.2170746922492981
[20/24] Train loss=0.1998973935842514
Test set avg_accuracy=86.07% avg_sensitivity=60.09%, avg_specificity=94.71% avg_auc=90.09%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.222121 Test loss=0.340429 Current lr=[0.000299720220882401]

[0/24] Train loss=0.20555418729782104
[5/24] Train loss=0.19672827422618866
[10/24] Train loss=0.21919241547584534
[15/24] Train loss=0.209323912858963
[20/24] Train loss=0.18372109532356262
Test set avg_accuracy=85.74% avg_sensitivity=61.29%, avg_specificity=93.87% avg_auc=89.58%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.212185 Test loss=0.351201 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.20029114186763763
[5/24] Train loss=0.1999186873435974
[10/24] Train loss=0.23228485882282257
[15/24] Train loss=0.21082526445388794
[20/24] Train loss=0.19969628751277924
Test set avg_accuracy=85.52% avg_sensitivity=60.77%, avg_specificity=93.75% avg_auc=89.99%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.219071 Test loss=0.336562 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2015867382287979
[5/24] Train loss=0.2012854516506195
[10/24] Train loss=0.21655189990997314
[15/24] Train loss=0.21514660120010376
[20/24] Train loss=0.2013031244277954
Test set avg_accuracy=84.69% avg_sensitivity=57.69%, avg_specificity=93.67% avg_auc=88.70%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.217455 Test loss=0.380259 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2019266039133072
[5/24] Train loss=0.1973886638879776
[10/24] Train loss=0.2095838189125061
[15/24] Train loss=0.19787344336509705
[20/24] Train loss=0.18198874592781067
Test set avg_accuracy=84.40% avg_sensitivity=76.53%, avg_specificity=87.02% avg_auc=90.30%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.209543 Test loss=0.356442 Current lr=[0.000297555943323901]

[0/24] Train loss=0.20350539684295654
[5/24] Train loss=0.19961847364902496
[10/24] Train loss=0.22473594546318054
[15/24] Train loss=0.20949934422969818
[20/24] Train loss=0.18648438155651093
Test set avg_accuracy=84.74% avg_sensitivity=54.72%, avg_specificity=94.72% avg_auc=87.63%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.213594 Test loss=0.383367 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.20095127820968628
[5/24] Train loss=0.19883674383163452
[10/24] Train loss=0.2095847874879837
[15/24] Train loss=0.20486973226070404
[20/24] Train loss=0.1826724112033844
Test set avg_accuracy=84.70% avg_sensitivity=75.01%, avg_specificity=87.92% avg_auc=90.33%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.210782 Test loss=0.346068 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.20656119287014008
[5/24] Train loss=0.1901119500398636
[10/24] Train loss=0.21633820235729218
[15/24] Train loss=0.20506919920444489
[20/24] Train loss=0.18534012138843536
Test set avg_accuracy=85.23% avg_sensitivity=59.00%, avg_specificity=93.96% avg_auc=88.40%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.211858 Test loss=0.374035 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.19307661056518555
[5/24] Train loss=0.2072770595550537
[10/24] Train loss=0.2154311239719391
[15/24] Train loss=0.22320020198822021
[20/24] Train loss=0.19460701942443848
Test set avg_accuracy=85.14% avg_sensitivity=53.16%, avg_specificity=95.78% avg_auc=89.26%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.211251 Test loss=0.355565 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.19162504374980927
[5/24] Train loss=0.20849275588989258
[10/24] Train loss=0.20621716976165771
[15/24] Train loss=0.20149081945419312
[20/24] Train loss=0.17939609289169312
Test set avg_accuracy=84.64% avg_sensitivity=76.42%, avg_specificity=87.37% avg_auc=90.40%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.208814 Test loss=0.352413 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.19056013226509094
[5/24] Train loss=0.19707776606082916
[10/24] Train loss=0.2118576467037201
[15/24] Train loss=0.20178428292274475
[20/24] Train loss=0.18732589483261108
Test set avg_accuracy=85.39% avg_sensitivity=56.86%, avg_specificity=94.88% avg_auc=88.88%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.205002 Test loss=0.370099 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.18688930571079254
[5/24] Train loss=0.1856619119644165
[10/24] Train loss=0.1999008059501648
[15/24] Train loss=0.18617881834506989
[20/24] Train loss=0.18962988257408142
Test set avg_accuracy=85.26% avg_sensitivity=72.30%, avg_specificity=89.57% avg_auc=89.30%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.201065 Test loss=0.355418 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.1992763876914978
[5/24] Train loss=0.1892346292734146
[10/24] Train loss=0.20788542926311493
[15/24] Train loss=0.19863298535346985
[20/24] Train loss=0.17985452711582184
Test set avg_accuracy=75.85% avg_sensitivity=85.71%, avg_specificity=72.57% avg_auc=86.44%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.202405 Test loss=0.546723 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.1835862398147583
[5/24] Train loss=0.21305742859840393
[10/24] Train loss=0.20801320672035217
[15/24] Train loss=0.1885232776403427
[20/24] Train loss=0.17813155055046082
Test set avg_accuracy=85.29% avg_sensitivity=55.19%, avg_specificity=95.30% avg_auc=88.83%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.203936 Test loss=0.359871 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.1781560629606247
[5/24] Train loss=0.19303375482559204
[10/24] Train loss=0.21038228273391724
[15/24] Train loss=0.19604575634002686
[20/24] Train loss=0.1864432543516159
Test set avg_accuracy=84.41% avg_sensitivity=57.59%, avg_specificity=93.34% avg_auc=87.77%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.205018 Test loss=0.380083 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.19387836754322052
[5/24] Train loss=0.19133485853672028
[10/24] Train loss=0.21328061819076538
[15/24] Train loss=0.19106848537921906
[20/24] Train loss=0.19312849640846252
Test set avg_accuracy=84.36% avg_sensitivity=66.82%, avg_specificity=90.20% avg_auc=89.18%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.203755 Test loss=0.353914 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.19135819375514984
[5/24] Train loss=0.19938959181308746
[10/24] Train loss=0.21199892461299896
[15/24] Train loss=0.18437336385250092
[20/24] Train loss=0.18039599061012268
Test set avg_accuracy=85.99% avg_sensitivity=68.86%, avg_specificity=91.69% avg_auc=91.14%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.200043 Test loss=0.324398 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.1755140721797943
[5/24] Train loss=0.20668178796768188
[10/24] Train loss=0.2010287344455719
[15/24] Train loss=0.1826332062482834
[20/24] Train loss=0.1787305325269699
Test set avg_accuracy=83.52% avg_sensitivity=75.27%, avg_specificity=86.26% avg_auc=89.73%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.199654 Test loss=0.379996 Current lr=[0.000276307469034998]

[0/24] Train loss=0.1800917387008667
[5/24] Train loss=0.1971086710691452
[10/24] Train loss=0.20459827780723572
[15/24] Train loss=0.19670166075229645
[20/24] Train loss=0.18893849849700928
Test set avg_accuracy=85.90% avg_sensitivity=71.05%, avg_specificity=90.84% avg_auc=90.21%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.198590 Test loss=0.345549 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.17489412426948547
[5/24] Train loss=0.20257356762886047
[10/24] Train loss=0.21762524545192719
[15/24] Train loss=0.1880788952112198
[20/24] Train loss=0.1828031837940216
Test set avg_accuracy=85.96% avg_sensitivity=69.54%, avg_specificity=91.43% avg_auc=90.89%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.203785 Test loss=0.323576 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.18561668694019318
[5/24] Train loss=0.19538374245166779
[10/24] Train loss=0.20115941762924194
[15/24] Train loss=0.1861744374036789
[20/24] Train loss=0.18005375564098358
Test set avg_accuracy=85.42% avg_sensitivity=66.20%, avg_specificity=91.81% avg_auc=90.01%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.197833 Test loss=0.342857 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.18109813332557678
[5/24] Train loss=0.2000158131122589
[10/24] Train loss=0.20078308880329132
[15/24] Train loss=0.1845238208770752
[20/24] Train loss=0.18248800933361053
Test set avg_accuracy=85.34% avg_sensitivity=70.01%, avg_specificity=90.44% avg_auc=90.73%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.202729 Test loss=0.334871 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.17372816801071167
[5/24] Train loss=0.18773403763771057
[10/24] Train loss=0.1929050236940384
[15/24] Train loss=0.18979902565479279
[20/24] Train loss=0.17945922911167145
Test set avg_accuracy=83.95% avg_sensitivity=79.13%, avg_specificity=85.55% avg_auc=90.77%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.197689 Test loss=0.352182 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.18393930792808533
[5/24] Train loss=0.1943047046661377
[10/24] Train loss=0.19170746207237244
[15/24] Train loss=0.19385139644145966
[20/24] Train loss=0.1850695163011551
Test set avg_accuracy=83.85% avg_sensitivity=79.24%, avg_specificity=85.39% avg_auc=90.43%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.195422 Test loss=0.367221 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.18727128207683563
[5/24] Train loss=0.19612844288349152
[10/24] Train loss=0.2073599100112915
[15/24] Train loss=0.1837684065103531
[20/24] Train loss=0.18931318819522858
Test set avg_accuracy=80.39% avg_sensitivity=83.05%, avg_specificity=79.51% avg_auc=88.99%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.199004 Test loss=0.437453 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.18875132501125336
[5/24] Train loss=0.19022399187088013
[10/24] Train loss=0.1928122490644455
[15/24] Train loss=0.1792437732219696
[20/24] Train loss=0.17642098665237427
Test set avg_accuracy=80.73% avg_sensitivity=82.21%, avg_specificity=80.24% avg_auc=88.69%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.193761 Test loss=0.432559 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.18541473150253296
[5/24] Train loss=0.19801853597164154
[10/24] Train loss=0.20071297883987427
[15/24] Train loss=0.19114138185977936
[20/24] Train loss=0.1748686283826828
Test set avg_accuracy=75.95% avg_sensitivity=83.46%, avg_specificity=73.45% avg_auc=86.62%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.199557 Test loss=0.504956 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.18168435990810394
[5/24] Train loss=0.1843748241662979
[10/24] Train loss=0.19488970935344696
[15/24] Train loss=0.18331165611743927
[20/24] Train loss=0.16566359996795654
Test set avg_accuracy=83.67% avg_sensitivity=60.56%, avg_specificity=91.36% avg_auc=86.53%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.195302 Test loss=0.383481 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.1826014667749405
[5/24] Train loss=0.19939185678958893
[10/24] Train loss=0.20575155317783356
[15/24] Train loss=0.1719904989004135
[20/24] Train loss=0.17196187376976013
Test set avg_accuracy=81.94% avg_sensitivity=83.72%, avg_specificity=81.35% avg_auc=90.00%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.195657 Test loss=0.412732 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1854146122932434
[5/24] Train loss=0.17996002733707428
[10/24] Train loss=0.19348368048667908
[15/24] Train loss=0.1812829077243805
[20/24] Train loss=0.1659664511680603
Test set avg_accuracy=85.18% avg_sensitivity=58.22%, avg_specificity=94.15% avg_auc=85.17%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.191639 Test loss=0.393408 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.17885710299015045
[5/24] Train loss=0.1794387847185135
[10/24] Train loss=0.19286595284938812
[15/24] Train loss=0.1787017583847046
[20/24] Train loss=0.17861488461494446
Test set avg_accuracy=83.91% avg_sensitivity=79.81%, avg_specificity=85.27% avg_auc=90.37%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.191422 Test loss=0.373577 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.17220111191272736
[5/24] Train loss=0.17773663997650146
[10/24] Train loss=0.20488235354423523
[15/24] Train loss=0.1789526641368866
[20/24] Train loss=0.1806568205356598
Test set avg_accuracy=85.22% avg_sensitivity=72.40%, avg_specificity=89.48% avg_auc=90.03%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.189977 Test loss=0.355482 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.18157601356506348
[5/24] Train loss=0.17836660146713257
[10/24] Train loss=0.19341526925563812
[15/24] Train loss=0.17155614495277405
[20/24] Train loss=0.16405156254768372
Test set avg_accuracy=84.91% avg_sensitivity=77.41%, avg_specificity=87.40% avg_auc=90.04%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.187956 Test loss=0.357950 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.1705627143383026
[5/24] Train loss=0.17902614176273346
[10/24] Train loss=0.18600639700889587
[15/24] Train loss=0.17429710924625397
[20/24] Train loss=0.17046096920967102
Test set avg_accuracy=85.47% avg_sensitivity=64.63%, avg_specificity=92.40% avg_auc=88.74%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.187061 Test loss=0.352657 Current lr=[0.000224838296036774]

[0/24] Train loss=0.1737278699874878
[5/24] Train loss=0.17336028814315796
[10/24] Train loss=0.1824507862329483
[15/24] Train loss=0.1675424724817276
[20/24] Train loss=0.16286122798919678
Test set avg_accuracy=84.90% avg_sensitivity=64.53%, avg_specificity=91.67% avg_auc=88.73%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.184035 Test loss=0.363126 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.16416674852371216
[5/24] Train loss=0.17633908987045288
[10/24] Train loss=0.19311676919460297
[15/24] Train loss=0.16572614014148712
[20/24] Train loss=0.16046807169914246
Test set avg_accuracy=82.60% avg_sensitivity=80.70%, avg_specificity=83.24% avg_auc=89.62%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.181593 Test loss=0.395402 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.16553622484207153
[5/24] Train loss=0.1775190234184265
[10/24] Train loss=0.19528138637542725
[15/24] Train loss=0.16950516402721405
[20/24] Train loss=0.15992309153079987
Test set avg_accuracy=82.45% avg_sensitivity=82.21%, avg_specificity=82.53% avg_auc=89.91%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.181687 Test loss=0.394994 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.16088244318962097
[5/24] Train loss=0.1808995008468628
[10/24] Train loss=0.18274572491645813
[15/24] Train loss=0.16554060578346252
[20/24] Train loss=0.1640581488609314
Test set avg_accuracy=84.82% avg_sensitivity=63.38%, avg_specificity=91.95% avg_auc=90.39%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.183820 Test loss=0.339728 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.1633789837360382
[5/24] Train loss=0.17773324251174927
[10/24] Train loss=0.1857227385044098
[15/24] Train loss=0.17164187133312225
[20/24] Train loss=0.1687566488981247
Test set avg_accuracy=85.72% avg_sensitivity=69.27%, avg_specificity=91.19% avg_auc=90.28%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.181641 Test loss=0.336101 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.16969773173332214
[5/24] Train loss=0.1740085333585739
[10/24] Train loss=0.18352869153022766
[15/24] Train loss=0.17161856591701508
[20/24] Train loss=0.15603555738925934
Test set avg_accuracy=83.67% avg_sensitivity=77.36%, avg_specificity=85.77% avg_auc=89.93%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.180920 Test loss=0.370669 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.16899745166301727
[5/24] Train loss=0.17678700387477875
[10/24] Train loss=0.18539683520793915
[15/24] Train loss=0.16631831228733063
[20/24] Train loss=0.16493941843509674
Test set avg_accuracy=81.60% avg_sensitivity=35.99%, avg_specificity=96.77% avg_auc=83.68%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.180429 Test loss=0.467751 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1687854677438736
[5/24] Train loss=0.17936637997627258
[10/24] Train loss=0.18131425976753235
[15/24] Train loss=0.1634596735239029
[20/24] Train loss=0.1593301147222519
Test set avg_accuracy=85.51% avg_sensitivity=74.49%, avg_specificity=89.17% avg_auc=90.80%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.177832 Test loss=0.339322 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.15790142118930817
[5/24] Train loss=0.17387494444847107
[10/24] Train loss=0.18209831416606903
[15/24] Train loss=0.16104887425899506
[20/24] Train loss=0.15560497343540192
Test set avg_accuracy=85.64% avg_sensitivity=68.86%, avg_specificity=91.22% avg_auc=90.28%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.178638 Test loss=0.341203 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.18609637022018433
[5/24] Train loss=0.183867946267128
[10/24] Train loss=0.17347458004951477
[15/24] Train loss=0.1638398915529251
[20/24] Train loss=0.1516931653022766
Test set avg_accuracy=85.82% avg_sensitivity=73.08%, avg_specificity=90.06% avg_auc=91.05%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.177955 Test loss=0.336918 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.16733869910240173
[5/24] Train loss=0.17167483270168304
[10/24] Train loss=0.1841098517179489
[15/24] Train loss=0.15246306359767914
[20/24] Train loss=0.15848736464977264
Test set avg_accuracy=83.45% avg_sensitivity=48.30%, avg_specificity=95.14% avg_auc=84.28%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.176933 Test loss=0.422228 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.16083310544490814
[5/24] Train loss=0.17169399559497833
[10/24] Train loss=0.17797140777111053
[15/24] Train loss=0.16501280665397644
[20/24] Train loss=0.1573249250650406
Test set avg_accuracy=84.77% avg_sensitivity=61.40%, avg_specificity=92.54% avg_auc=88.10%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.175836 Test loss=0.369804 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.15467806160449982
[5/24] Train loss=0.1806688755750656
[10/24] Train loss=0.1825956255197525
[15/24] Train loss=0.15485350787639618
[20/24] Train loss=0.14851288497447968
Test set avg_accuracy=84.82% avg_sensitivity=54.67%, avg_specificity=94.85% avg_auc=86.48%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.173106 Test loss=0.397864 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.1602313071489334
[5/24] Train loss=0.17564918100833893
[10/24] Train loss=0.18029174208641052
[15/24] Train loss=0.16872017085552216
[20/24] Train loss=0.1512080729007721
Test set avg_accuracy=84.14% avg_sensitivity=54.67%, avg_specificity=93.94% avg_auc=85.33%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.174661 Test loss=0.399046 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.15862609446048737
[5/24] Train loss=0.1653708964586258
[10/24] Train loss=0.16660556197166443
[15/24] Train loss=0.15749002993106842
[20/24] Train loss=0.15668319165706635
Test set avg_accuracy=84.52% avg_sensitivity=76.06%, avg_specificity=87.33% avg_auc=90.45%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.172963 Test loss=0.354047 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15438371896743774
[5/24] Train loss=0.17007263004779816
[10/24] Train loss=0.17179077863693237
[15/24] Train loss=0.16333016753196716
[20/24] Train loss=0.15039575099945068
Test set avg_accuracy=84.27% avg_sensitivity=55.19%, avg_specificity=93.94% avg_auc=87.21%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.172518 Test loss=0.388845 Current lr=[0.000156543481933168]

[0/24] Train loss=0.1541040539741516
[5/24] Train loss=0.16823810338974
[10/24] Train loss=0.17665717005729675
[15/24] Train loss=0.16342255473136902
[20/24] Train loss=0.1516874134540558
Test set avg_accuracy=85.22% avg_sensitivity=57.38%, avg_specificity=94.48% avg_auc=87.29%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.170873 Test loss=0.381767 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.16522303223609924
[5/24] Train loss=0.16995951533317566
[10/24] Train loss=0.1660262942314148
[15/24] Train loss=0.15471430122852325
[20/24] Train loss=0.1527058184146881
Test set avg_accuracy=83.15% avg_sensitivity=53.78%, avg_specificity=92.92% avg_auc=84.73%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.169580 Test loss=0.412831 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15495869517326355
[5/24] Train loss=0.1685551106929779
[10/24] Train loss=0.18262626230716705
[15/24] Train loss=0.1579068899154663
[20/24] Train loss=0.14997722208499908
Test set avg_accuracy=85.85% avg_sensitivity=59.36%, avg_specificity=94.66% avg_auc=89.37%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.169434 Test loss=0.362183 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15443889796733856
[5/24] Train loss=0.1727036088705063
[10/24] Train loss=0.17062236368656158
[15/24] Train loss=0.1505136936903
[20/24] Train loss=0.15345704555511475
Test set avg_accuracy=81.13% avg_sensitivity=66.51%, avg_specificity=86.00% avg_auc=85.60%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.171612 Test loss=0.426438 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15453876554965973
[5/24] Train loss=0.16932055354118347
[10/24] Train loss=0.178244948387146
[15/24] Train loss=0.15897949039936066
[20/24] Train loss=0.1632581204175949
Test set avg_accuracy=84.14% avg_sensitivity=45.80%, avg_specificity=96.89% avg_auc=85.60%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.169206 Test loss=0.420936 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15279093384742737
[5/24] Train loss=0.17167240381240845
[10/24] Train loss=0.1650228202342987
[15/24] Train loss=0.15875571966171265
[20/24] Train loss=0.15053781867027283
Test set avg_accuracy=86.48% avg_sensitivity=67.50%, avg_specificity=92.80% avg_auc=90.52%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.166882 Test loss=0.332626 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15045160055160522
[5/24] Train loss=0.1693585067987442
[10/24] Train loss=0.16449302434921265
[15/24] Train loss=0.15299898386001587
[20/24] Train loss=0.15066024661064148
Test set avg_accuracy=86.56% avg_sensitivity=65.99%, avg_specificity=93.41% avg_auc=91.21%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.166917 Test loss=0.326104 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.15482006967067719
[5/24] Train loss=0.16969002783298492
[10/24] Train loss=0.16568394005298615
[15/24] Train loss=0.15294867753982544
[20/24] Train loss=0.1442732959985733
Test set avg_accuracy=86.13% avg_sensitivity=60.56%, avg_specificity=94.64% avg_auc=89.77%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.166160 Test loss=0.353024 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.14414742588996887
[5/24] Train loss=0.16614918410778046
[10/24] Train loss=0.16760744154453278
[15/24] Train loss=0.15115462243556976
[20/24] Train loss=0.15098565816879272
Test set avg_accuracy=85.77% avg_sensitivity=77.67%, avg_specificity=88.46% avg_auc=90.90%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.163806 Test loss=0.343976 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1461365520954132
[5/24] Train loss=0.1621360033750534
[10/24] Train loss=0.1652161031961441
[15/24] Train loss=0.15315240621566772
[20/24] Train loss=0.14700038731098175
Test set avg_accuracy=85.99% avg_sensitivity=75.38%, avg_specificity=89.52% avg_auc=91.01%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.162091 Test loss=0.337356 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15107329189777374
[5/24] Train loss=0.1531095653772354
[10/24] Train loss=0.160123810172081
[15/24] Train loss=0.14958792924880981
[20/24] Train loss=0.1481955349445343
Test set avg_accuracy=86.47% avg_sensitivity=75.53%, avg_specificity=90.11% avg_auc=91.16%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.161559 Test loss=0.336817 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.14427046477794647
[5/24] Train loss=0.16045720875263214
[10/24] Train loss=0.1666182577610016
[15/24] Train loss=0.15110966563224792
[20/24] Train loss=0.14143387973308563
Test set avg_accuracy=86.03% avg_sensitivity=63.80%, avg_specificity=93.42% avg_auc=89.01%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.159870 Test loss=0.353850 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.14105206727981567
[5/24] Train loss=0.1572314202785492
[10/24] Train loss=0.1592094451189041
[15/24] Train loss=0.1522742658853531
[20/24] Train loss=0.15046285092830658
Test set avg_accuracy=85.96% avg_sensitivity=67.29%, avg_specificity=92.17% avg_auc=89.87%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.159779 Test loss=0.350742 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14808779954910278
[5/24] Train loss=0.15695153176784515
[10/24] Train loss=0.16434438526630402
[15/24] Train loss=0.15187104046344757
[20/24] Train loss=0.14395087957382202
Test set avg_accuracy=85.76% avg_sensitivity=76.16%, avg_specificity=88.95% avg_auc=90.90%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.160300 Test loss=0.350281 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14117753505706787
[5/24] Train loss=0.16071707010269165
[10/24] Train loss=0.16655433177947998
[15/24] Train loss=0.14897865056991577
[20/24] Train loss=0.13953270018100739
Test set avg_accuracy=86.18% avg_sensitivity=73.76%, avg_specificity=90.32% avg_auc=91.23%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.159002 Test loss=0.334846 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1494206190109253
[5/24] Train loss=0.15516133606433868
[10/24] Train loss=0.15805378556251526
[15/24] Train loss=0.15216468274593353
[20/24] Train loss=0.14171235263347626
Test set avg_accuracy=85.56% avg_sensitivity=58.27%, avg_specificity=94.64% avg_auc=89.69%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.156795 Test loss=0.366611 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.13912923634052277
[5/24] Train loss=0.1551368087530136
[10/24] Train loss=0.1573060154914856
[15/24] Train loss=0.15458449721336365
[20/24] Train loss=0.14331668615341187
Test set avg_accuracy=85.74% avg_sensitivity=73.97%, avg_specificity=89.66% avg_auc=90.36%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.157849 Test loss=0.348060 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13657627999782562
[5/24] Train loss=0.15539292991161346
[10/24] Train loss=0.15902644395828247
[15/24] Train loss=0.14698487520217896
[20/24] Train loss=0.14725366234779358
Test set avg_accuracy=86.24% avg_sensitivity=65.21%, avg_specificity=93.23% avg_auc=89.65%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.155727 Test loss=0.347234 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1421937644481659
[5/24] Train loss=0.1591770350933075
[10/24] Train loss=0.15764184296131134
[15/24] Train loss=0.14371256530284882
[20/24] Train loss=0.13887523114681244
Test set avg_accuracy=85.30% avg_sensitivity=67.61%, avg_specificity=91.19% avg_auc=90.52%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.153959 Test loss=0.348962 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1470925658941269
[5/24] Train loss=0.15241986513137817
[10/24] Train loss=0.1513354480266571
[15/24] Train loss=0.14056171476840973
[20/24] Train loss=0.13752149045467377
Test set avg_accuracy=86.08% avg_sensitivity=75.01%, avg_specificity=89.76% avg_auc=91.22%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.150405 Test loss=0.338644 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13525718450546265
[5/24] Train loss=0.15065427124500275
[10/24] Train loss=0.14768365025520325
[15/24] Train loss=0.13850370049476624
[20/24] Train loss=0.139304056763649
Test set avg_accuracy=85.77% avg_sensitivity=62.60%, avg_specificity=93.48% avg_auc=89.58%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.148433 Test loss=0.354394 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.13493414223194122
[5/24] Train loss=0.14925047755241394
[10/24] Train loss=0.15288513898849487
[15/24] Train loss=0.14374040067195892
[20/24] Train loss=0.1376343071460724
Test set avg_accuracy=85.68% avg_sensitivity=73.97%, avg_specificity=89.57% avg_auc=90.86%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.148426 Test loss=0.349312 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13760849833488464
[5/24] Train loss=0.1454334855079651
[10/24] Train loss=0.1479293256998062
[15/24] Train loss=0.13444462418556213
[20/24] Train loss=0.13525518774986267
Test set avg_accuracy=85.91% avg_sensitivity=74.33%, avg_specificity=89.76% avg_auc=90.84%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.146180 Test loss=0.340931 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13293923437595367
[5/24] Train loss=0.15000787377357483
[10/24] Train loss=0.14741308987140656
[15/24] Train loss=0.13368219137191772
[20/24] Train loss=0.13224588334560394
Test set avg_accuracy=85.90% avg_sensitivity=70.84%, avg_specificity=90.91% avg_auc=90.69%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.143833 Test loss=0.341669 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1331789791584015
[5/24] Train loss=0.14857591688632965
[10/24] Train loss=0.14632733166217804
[15/24] Train loss=0.13475874066352844
[20/24] Train loss=0.13395054638385773
Test set avg_accuracy=85.89% avg_sensitivity=74.54%, avg_specificity=89.66% avg_auc=90.98%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.144263 Test loss=0.345218 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.12899884581565857
[5/24] Train loss=0.1448575109243393
[10/24] Train loss=0.14219647645950317
[15/24] Train loss=0.13291187584400177
[20/24] Train loss=0.13408489525318146
Test set avg_accuracy=86.03% avg_sensitivity=74.33%, avg_specificity=89.92% avg_auc=90.64%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.142459 Test loss=0.345180 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13060079514980316
[5/24] Train loss=0.14870893955230713
[10/24] Train loss=0.14051492512226105
[15/24] Train loss=0.12996812164783478
[20/24] Train loss=0.131423681974411
Test set avg_accuracy=85.91% avg_sensitivity=71.00%, avg_specificity=90.87% avg_auc=90.81%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.141768 Test loss=0.341820 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12718719244003296
[5/24] Train loss=0.14406651258468628
[10/24] Train loss=0.14093443751335144
[15/24] Train loss=0.131443589925766
[20/24] Train loss=0.1274564117193222
Test set avg_accuracy=86.48% avg_sensitivity=71.47%, avg_specificity=91.48% avg_auc=90.80%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.140411 Test loss=0.340505 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1296830177307129
[5/24] Train loss=0.14334148168563843
[10/24] Train loss=0.13997507095336914
[15/24] Train loss=0.12895148992538452
[20/24] Train loss=0.129069983959198
Test set avg_accuracy=86.29% avg_sensitivity=71.62%, avg_specificity=91.17% avg_auc=90.53%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.139471 Test loss=0.342273 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12732619047164917
[5/24] Train loss=0.14519557356834412
[10/24] Train loss=0.13801148533821106
[15/24] Train loss=0.1339946687221527
[20/24] Train loss=0.12924286723136902
Test set avg_accuracy=86.21% avg_sensitivity=68.91%, avg_specificity=91.97% avg_auc=90.51%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.138492 Test loss=0.343506 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1273372918367386
[5/24] Train loss=0.14004738628864288
[10/24] Train loss=0.1363649070262909
[15/24] Train loss=0.1313769817352295
[20/24] Train loss=0.12423136085271835
Test set avg_accuracy=86.13% avg_sensitivity=71.47%, avg_specificity=91.01% avg_auc=90.70%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.137387 Test loss=0.343362 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12499886006116867
[5/24] Train loss=0.13679060339927673
[10/24] Train loss=0.13653068244457245
[15/24] Train loss=0.12511608004570007
[20/24] Train loss=0.12492082267999649
Test set avg_accuracy=86.04% avg_sensitivity=69.64%, avg_specificity=91.50% avg_auc=90.52%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.136650 Test loss=0.345073 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12853248417377472
[5/24] Train loss=0.14010609686374664
[10/24] Train loss=0.13425655663013458
[15/24] Train loss=0.12917715311050415
[20/24] Train loss=0.12595905363559723
Test set avg_accuracy=86.11% avg_sensitivity=69.17%, avg_specificity=91.74% avg_auc=90.81%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.137102 Test loss=0.340567 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1233757957816124
[5/24] Train loss=0.1419747769832611
[10/24] Train loss=0.13364385068416595
[15/24] Train loss=0.12844160199165344
[20/24] Train loss=0.12309880554676056
Test set avg_accuracy=85.83% avg_sensitivity=69.95%, avg_specificity=91.12% avg_auc=90.52%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.135874 Test loss=0.347070 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12494657188653946
[5/24] Train loss=0.14077194035053253
[10/24] Train loss=0.13369882106781006
[15/24] Train loss=0.12738795578479767
[20/24] Train loss=0.12556397914886475
Test set avg_accuracy=85.74% avg_sensitivity=71.26%, avg_specificity=90.56% avg_auc=90.75%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.134926 Test loss=0.346665 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12793929874897003
[5/24] Train loss=0.13980334997177124
[10/24] Train loss=0.13336430490016937
[15/24] Train loss=0.12882955372333527
[20/24] Train loss=0.12445983290672302
Test set avg_accuracy=85.79% avg_sensitivity=74.96%, avg_specificity=89.40% avg_auc=90.77%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.135034 Test loss=0.348053 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12441672384738922
[5/24] Train loss=0.13616527616977692
[10/24] Train loss=0.13018274307250977
[15/24] Train loss=0.12678620219230652
[20/24] Train loss=0.12758100032806396
Test set avg_accuracy=86.04% avg_sensitivity=74.02%, avg_specificity=90.04% avg_auc=90.31%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.134406 Test loss=0.350695 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12264109402894974
[5/24] Train loss=0.13906249403953552
[10/24] Train loss=0.13278193771839142
[15/24] Train loss=0.12670941650867462
[20/24] Train loss=0.1259862184524536
Test set avg_accuracy=86.24% avg_sensitivity=72.98%, avg_specificity=90.65% avg_auc=90.66%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.134269 Test loss=0.344140 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12412555515766144
[5/24] Train loss=0.13827040791511536
[10/24] Train loss=0.13241271674633026
[15/24] Train loss=0.12163355201482773
[20/24] Train loss=0.12344135344028473
Test set avg_accuracy=86.18% avg_sensitivity=71.99%, avg_specificity=90.91% avg_auc=90.53%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.134460 Test loss=0.344141 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12283693253993988
[5/24] Train loss=0.13528448343276978
[10/24] Train loss=0.13348500430583954
[15/24] Train loss=0.12350917607545853
[20/24] Train loss=0.1234140694141388
Test set avg_accuracy=86.18% avg_sensitivity=74.91%, avg_specificity=89.94% avg_auc=90.79%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.132707 Test loss=0.347015 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.11857261508703232
[5/24] Train loss=0.13404646515846252
[10/24] Train loss=0.13131003081798553
[15/24] Train loss=0.12521903216838837
[20/24] Train loss=0.12090589851140976
Test set avg_accuracy=86.07% avg_sensitivity=72.25%, avg_specificity=90.66% avg_auc=90.53%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.130999 Test loss=0.347876 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1205725371837616
[5/24] Train loss=0.1310165971517563
[10/24] Train loss=0.13091392815113068
[15/24] Train loss=0.12005281448364258
[20/24] Train loss=0.12277738004922867
Test set avg_accuracy=86.03% avg_sensitivity=72.25%, avg_specificity=90.61% avg_auc=90.52%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.130657 Test loss=0.348915 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12095504999160767
[5/24] Train loss=0.1333570033311844
[10/24] Train loss=0.13081860542297363
[15/24] Train loss=0.12275704741477966
[20/24] Train loss=0.1201811358332634
Test set avg_accuracy=85.96% avg_sensitivity=72.46%, avg_specificity=90.46% avg_auc=90.55%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.130341 Test loss=0.348092 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.11920416355133057
[5/24] Train loss=0.13280875980854034
[10/24] Train loss=0.13076896965503693
[15/24] Train loss=0.12369590252637863
[20/24] Train loss=0.11749148368835449
Test set avg_accuracy=85.85% avg_sensitivity=70.68%, avg_specificity=90.89% avg_auc=90.52%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.129268 Test loss=0.346650 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11604778468608856
[5/24] Train loss=0.13056935369968414
[10/24] Train loss=0.12764990329742432
[15/24] Train loss=0.12291352450847626
[20/24] Train loss=0.119963638484478
Test set avg_accuracy=86.02% avg_sensitivity=72.77%, avg_specificity=90.42% avg_auc=90.45%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.129095 Test loss=0.348710 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.11939074099063873
[5/24] Train loss=0.13104908168315887
[10/24] Train loss=0.12955275177955627
[15/24] Train loss=0.12368559092283249
[20/24] Train loss=0.1193637102842331
Test set avg_accuracy=85.94% avg_sensitivity=71.62%, avg_specificity=90.70% avg_auc=90.61%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.129524 Test loss=0.347257 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11961819976568222
[5/24] Train loss=0.13115325570106506
[10/24] Train loss=0.12643210589885712
[15/24] Train loss=0.1203678548336029
[20/24] Train loss=0.12168875336647034
Test set avg_accuracy=85.74% avg_sensitivity=70.63%, avg_specificity=90.77% avg_auc=90.59%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.128969 Test loss=0.345671 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12030091881752014
[5/24] Train loss=0.1325802057981491
[10/24] Train loss=0.12561461329460144
[15/24] Train loss=0.12144719064235687
[20/24] Train loss=0.1199086606502533
Test set avg_accuracy=85.98% avg_sensitivity=71.83%, avg_specificity=90.68% avg_auc=90.54%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.128837 Test loss=0.346261 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11582942306995392
[5/24] Train loss=0.13061034679412842
[10/24] Train loss=0.12663722038269043
[15/24] Train loss=0.11949635297060013
[20/24] Train loss=0.12249104678630829
Test set avg_accuracy=85.81% avg_sensitivity=72.09%, avg_specificity=90.37% avg_auc=90.53%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.128130 Test loss=0.347231 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1194719523191452
[5/24] Train loss=0.130815327167511
[10/24] Train loss=0.12779048085212708
[15/24] Train loss=0.12308676540851593
[20/24] Train loss=0.12004826217889786
Test set avg_accuracy=85.89% avg_sensitivity=72.04%, avg_specificity=90.49% avg_auc=90.56%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.128670 Test loss=0.346870 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11944406479597092
[5/24] Train loss=0.13307151198387146
[10/24] Train loss=0.1282505840063095
[15/24] Train loss=0.1213192492723465
[20/24] Train loss=0.1189722940325737
Test set avg_accuracy=85.91% avg_sensitivity=71.62%, avg_specificity=90.66% avg_auc=90.53%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.128101 Test loss=0.346585 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11862080544233322
[5/24] Train loss=0.13198211789131165
[10/24] Train loss=0.1295071244239807
[15/24] Train loss=0.11982204020023346
[20/24] Train loss=0.11700072884559631
Test set avg_accuracy=85.91% avg_sensitivity=71.57%, avg_specificity=90.68% avg_auc=90.54%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.127921 Test loss=0.346904 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11821682751178741
[5/24] Train loss=0.1306559443473816
[10/24] Train loss=0.13026747107505798
[15/24] Train loss=0.11920987069606781
[20/24] Train loss=0.11888464540243149
Test set avg_accuracy=85.92% avg_sensitivity=71.47%, avg_specificity=90.73% avg_auc=90.52%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.128633 Test loss=0.346607 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11662343889474869
[5/24] Train loss=0.1331081986427307
[10/24] Train loss=0.1274845004081726
[15/24] Train loss=0.11879386007785797
[20/24] Train loss=0.11877795308828354
Test set avg_accuracy=85.87% avg_sensitivity=71.41%, avg_specificity=90.68% avg_auc=90.53%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.128317 Test loss=0.346623 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=86.78% sen=73.08%, spe=91.34%, auc=92.10%!
Fold[2] Avg_overlap=0.71%(±0.2236359458660556)
[0/24] Train loss=0.7658023834228516
[5/24] Train loss=0.7529327869415283
[10/24] Train loss=0.7489019632339478
[15/24] Train loss=0.7315308451652527
[20/24] Train loss=0.7282052636146545
Test set avg_accuracy=57.02% avg_sensitivity=47.49%, avg_specificity=60.63% avg_auc=56.49%
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.742589 Test loss=0.669523 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7293878793716431
[5/24] Train loss=0.7195560932159424
[10/24] Train loss=0.7170578241348267
[15/24] Train loss=0.6977704763412476
[20/24] Train loss=0.6988558173179626
Test set avg_accuracy=63.49% avg_sensitivity=58.06%, avg_specificity=65.55% avg_auc=67.10%
Best model saved!! Metric=-71.80901188308502!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.713021 Test loss=0.628243 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7009516358375549
[5/24] Train loss=0.6962374448776245
[10/24] Train loss=0.6950907707214355
[15/24] Train loss=0.6712421774864197
[20/24] Train loss=0.6668321490287781
Test set avg_accuracy=68.29% avg_sensitivity=66.16%, avg_specificity=69.10% avg_auc=73.88%
Best model saved!! Metric=-48.55799290180836!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.687412 Test loss=0.599237 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6639760732650757
[5/24] Train loss=0.6676743626594543
[10/24] Train loss=0.6723198294639587
[15/24] Train loss=0.6492599248886108
[20/24] Train loss=0.6353438496589661
Test set avg_accuracy=72.04% avg_sensitivity=73.22%, avg_specificity=71.60% avg_auc=78.31%
Best model saved!! Metric=-30.82445294928685!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.660028 Test loss=0.573509 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6344284415245056
[5/24] Train loss=0.6429683566093445
[10/24] Train loss=0.6486954092979431
[15/24] Train loss=0.6155334115028381
[20/24] Train loss=0.6065741777420044
Test set avg_accuracy=73.62% avg_sensitivity=75.50%, avg_specificity=72.91% avg_auc=81.10%
Best model saved!! Metric=-22.871971928081763!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.631382 Test loss=0.550500 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6035500168800354
[5/24] Train loss=0.6161773204803467
[10/24] Train loss=0.6170337796211243
[15/24] Train loss=0.5901167988777161
[20/24] Train loss=0.5719009637832642
Test set avg_accuracy=75.48% avg_sensitivity=76.97%, avg_specificity=74.92% avg_auc=83.05%
Best model saved!! Metric=-15.585839162667568!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.602594 Test loss=0.522354 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.574140727519989
[5/24] Train loss=0.5840739011764526
[10/24] Train loss=0.5893633961677551
[15/24] Train loss=0.5593058466911316
[20/24] Train loss=0.5436693429946899
Test set avg_accuracy=77.17% avg_sensitivity=76.92%, avg_specificity=77.27% avg_auc=84.74%
Best model saved!! Metric=-9.89354775480669!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.574039 Test loss=0.495789 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.546842098236084
[5/24] Train loss=0.5616881251335144
[10/24] Train loss=0.5677503943443298
[15/24] Train loss=0.5355658531188965
[20/24] Train loss=0.5154292583465576
Test set avg_accuracy=79.30% avg_sensitivity=76.82%, avg_specificity=80.23% avg_auc=85.92%
Best model saved!! Metric=-3.7287446448475663!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.545831 Test loss=0.469720 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5237256288528442
[5/24] Train loss=0.5260792970657349
[10/24] Train loss=0.5246275067329407
[15/24] Train loss=0.4997163414955139
[20/24] Train loss=0.4863141179084778
Test set avg_accuracy=80.87% avg_sensitivity=75.97%, avg_specificity=82.73% avg_auc=86.96%
Best model saved!! Metric=0.532729203537599!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.513558 Test loss=0.448661 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.48556196689605713
[5/24] Train loss=0.4965909719467163
[10/24] Train loss=0.5013613104820251
[15/24] Train loss=0.4735157787799835
[20/24] Train loss=0.4494496285915375
Test set avg_accuracy=82.51% avg_sensitivity=75.69%, avg_specificity=85.10% avg_auc=88.07%
Best model saved!! Metric=5.372117041013254!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.483731 Test loss=0.427070 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4567406475543976
[5/24] Train loss=0.46587279438972473
[10/24] Train loss=0.47121134400367737
[15/24] Train loss=0.44888100028038025
[20/24] Train loss=0.4230594336986542
Test set avg_accuracy=83.89% avg_sensitivity=76.35%, avg_specificity=86.75% avg_auc=89.08%
Best model saved!! Metric=10.07448964298274!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.454390 Test loss=0.408330 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4266517460346222
[5/24] Train loss=0.4418884515762329
[10/24] Train loss=0.44289064407348633
[15/24] Train loss=0.4200894236564636
[20/24] Train loss=0.39246225357055664
Test set avg_accuracy=84.71% avg_sensitivity=75.88%, avg_specificity=88.06% avg_auc=89.70%
Best model saved!! Metric=12.348259646364951!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.428063 Test loss=0.391493 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3961448669433594
[5/24] Train loss=0.4168054759502411
[10/24] Train loss=0.42837539315223694
[15/24] Train loss=0.40458858013153076
[20/24] Train loss=0.3695836067199707
Test set avg_accuracy=85.36% avg_sensitivity=74.41%, avg_specificity=89.52% avg_auc=90.37%
Best model saved!! Metric=13.662140490412128!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.403392 Test loss=0.372478 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3768523633480072
[5/24] Train loss=0.4014812409877777
[10/24] Train loss=0.41766244173049927
[15/24] Train loss=0.3786381781101227
[20/24] Train loss=0.34914812445640564
Test set avg_accuracy=85.78% avg_sensitivity=74.88%, avg_specificity=89.91% avg_auc=90.79%
Best model saved!! Metric=15.36309927718736!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.383678 Test loss=0.360499 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.35608890652656555
[5/24] Train loss=0.3776004910469055
[10/24] Train loss=0.3952055275440216
[15/24] Train loss=0.366216242313385
[20/24] Train loss=0.3363490104675293
Test set avg_accuracy=85.87% avg_sensitivity=76.54%, avg_specificity=89.41% avg_auc=91.13%
Best model saved!! Metric=16.951764829393824!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.366011 Test loss=0.354622 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.339946448802948
[5/24] Train loss=0.36171793937683105
[10/24] Train loss=0.3870961666107178
[15/24] Train loss=0.3503378629684448
[20/24] Train loss=0.3286731541156769
Test set avg_accuracy=86.35% avg_sensitivity=74.64%, avg_specificity=90.79% avg_auc=91.40%
Best model saved!! Metric=17.188187785218133!!
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.352371 Test loss=0.341340 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3249732553958893
[5/24] Train loss=0.34582382440567017
[10/24] Train loss=0.3679247200489044
[15/24] Train loss=0.34518012404441833
[20/24] Train loss=0.3041336238384247
Test set avg_accuracy=86.35% avg_sensitivity=77.16%, avg_specificity=89.84% avg_auc=91.62%
Best model saved!! Metric=18.968387228750274!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.338231 Test loss=0.340476 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.310493141412735
[5/24] Train loss=0.334012895822525
[10/24] Train loss=0.36821049451828003
[15/24] Train loss=0.3335092067718506
[20/24] Train loss=0.2969619631767273
Test set avg_accuracy=86.68% avg_sensitivity=76.02%, avg_specificity=90.72% avg_auc=91.89%
Best model saved!! Metric=19.30272731212827!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.328424 Test loss=0.331096 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3024349808692932
[5/24] Train loss=0.32200321555137634
[10/24] Train loss=0.35769063234329224
[15/24] Train loss=0.323173463344574
[20/24] Train loss=0.2874073386192322
Test set avg_accuracy=86.86% avg_sensitivity=74.36%, avg_specificity=91.60% avg_auc=92.25%
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.318010 Test loss=0.317808 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2941509485244751
[5/24] Train loss=0.3139706552028656
[10/24] Train loss=0.347118079662323
[15/24] Train loss=0.316349595785141
[20/24] Train loss=0.27714774012565613
Test set avg_accuracy=87.24% avg_sensitivity=74.50%, avg_specificity=92.06% avg_auc=92.50%
Best model saved!! Metric=20.304921510943572!!
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.308921 Test loss=0.312590 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2875894606113434
[5/24] Train loss=0.3101032078266144
[10/24] Train loss=0.3445969521999359
[15/24] Train loss=0.31604182720184326
[20/24] Train loss=0.2711760997772217
Test set avg_accuracy=87.70% avg_sensitivity=72.27%, avg_specificity=93.54% avg_auc=92.84%
Best model saved!! Metric=20.349987595935403!!
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.301717 Test loss=0.302064 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2786237895488739
[5/24] Train loss=0.3001890480518341
[10/24] Train loss=0.3395534157752991
[15/24] Train loss=0.31076788902282715
[20/24] Train loss=0.2560943067073822
Test set avg_accuracy=87.76% avg_sensitivity=70.05%, avg_specificity=94.47% avg_auc=92.70%
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.293569 Test loss=0.303480 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.27025240659713745
[5/24] Train loss=0.28614288568496704
[10/24] Train loss=0.3356570601463318
[15/24] Train loss=0.2999664843082428
[20/24] Train loss=0.25859683752059937
Test set avg_accuracy=87.58% avg_sensitivity=70.33%, avg_specificity=94.11% avg_auc=92.97%
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.287852 Test loss=0.298781 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2648964524269104
[5/24] Train loss=0.2837567925453186
[10/24] Train loss=0.3145853281021118
[15/24] Train loss=0.2942679226398468
[20/24] Train loss=0.2543743848800659
Test set avg_accuracy=87.58% avg_sensitivity=66.16%, avg_specificity=95.69% avg_auc=92.94%
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.281927 Test loss=0.302336 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.25948700308799744
[5/24] Train loss=0.2754077613353729
[10/24] Train loss=0.3198758661746979
[15/24] Train loss=0.289634644985199
[20/24] Train loss=0.25124531984329224
Test set avg_accuracy=87.79% avg_sensitivity=67.87%, avg_specificity=95.33% avg_auc=93.02%
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.277376 Test loss=0.299082 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2569274306297302
[5/24] Train loss=0.2732797861099243
[10/24] Train loss=0.3131357729434967
[15/24] Train loss=0.27898475527763367
[20/24] Train loss=0.24319158494472504
Test set avg_accuracy=86.89% avg_sensitivity=60.47%, avg_specificity=96.89% avg_auc=92.85%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.271115 Test loss=0.314362 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.25175008177757263
[5/24] Train loss=0.2651362419128418
[10/24] Train loss=0.3210732340812683
[15/24] Train loss=0.2867274880409241
[20/24] Train loss=0.241330087184906
Test set avg_accuracy=86.43% avg_sensitivity=58.48%, avg_specificity=97.02% avg_auc=92.55%
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.267811 Test loss=0.325224 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2481093555688858
[5/24] Train loss=0.26655715703964233
[10/24] Train loss=0.30985552072525024
[15/24] Train loss=0.2651776373386383
[20/24] Train loss=0.24316830933094025
Test set avg_accuracy=87.83% avg_sensitivity=67.63%, avg_specificity=95.48% avg_auc=93.23%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.264483 Test loss=0.296928 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2432623952627182
[5/24] Train loss=0.25441813468933105
[10/24] Train loss=0.2965839207172394
[15/24] Train loss=0.2735641598701477
[20/24] Train loss=0.23530112206935883
Test set avg_accuracy=85.65% avg_sensitivity=55.59%, avg_specificity=97.04% avg_auc=92.22%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.260761 Test loss=0.343662 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.24065372347831726
[5/24] Train loss=0.25931474566459656
[10/24] Train loss=0.2995709180831909
[15/24] Train loss=0.2672519087791443
[20/24] Train loss=0.23391534388065338
Test set avg_accuracy=83.98% avg_sensitivity=47.20%, avg_specificity=97.92% avg_auc=91.19%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.255883 Test loss=0.387434 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2554510235786438
[5/24] Train loss=0.25514286756515503
[10/24] Train loss=0.3021005690097809
[15/24] Train loss=0.2691735327243805
[20/24] Train loss=0.22877174615859985
Test set avg_accuracy=83.18% avg_sensitivity=43.13%, avg_specificity=98.35% avg_auc=90.96%
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.255380 Test loss=0.409726 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.23381879925727844
[5/24] Train loss=0.25346502661705017
[10/24] Train loss=0.298924058675766
[15/24] Train loss=0.2630890905857086
[20/24] Train loss=0.22938425838947296
Test set avg_accuracy=86.28% avg_sensitivity=58.29%, avg_specificity=96.88% avg_auc=92.03%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.250348 Test loss=0.335584 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2353515774011612
[5/24] Train loss=0.2496379017829895
[10/24] Train loss=0.2886248826980591
[15/24] Train loss=0.26230359077453613
[20/24] Train loss=0.23215405642986298
Test set avg_accuracy=87.46% avg_sensitivity=73.74%, avg_specificity=92.66% avg_auc=92.78%
Best model saved!! Metric=20.64325305302185!!
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.246960 Test loss=0.305341 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2298056036233902
[5/24] Train loss=0.24739626049995422
[10/24] Train loss=0.2892805337905884
[15/24] Train loss=0.2625040113925934
[20/24] Train loss=0.22194132208824158
Test set avg_accuracy=85.43% avg_sensitivity=54.41%, avg_specificity=97.18% avg_auc=91.40%
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.245689 Test loss=0.348921 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.21669140458106995
[5/24] Train loss=0.2381734549999237
[10/24] Train loss=0.2865617573261261
[15/24] Train loss=0.24504122138023376
[20/24] Train loss=0.22694943845272064
Test set avg_accuracy=86.86% avg_sensitivity=66.73%, avg_specificity=94.49% avg_auc=92.63%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.240855 Test loss=0.306701 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.22949254512786865
[5/24] Train loss=0.23807094991207123
[10/24] Train loss=0.2945401668548584
[15/24] Train loss=0.25835344195365906
[20/24] Train loss=0.22134490311145782
Test set avg_accuracy=87.12% avg_sensitivity=66.64%, avg_specificity=94.88% avg_auc=92.37%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.240453 Test loss=0.314500 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.21352729201316833
[5/24] Train loss=0.23939098417758942
[10/24] Train loss=0.27946221828460693
[15/24] Train loss=0.2502267062664032
[20/24] Train loss=0.21990668773651123
Test set avg_accuracy=86.95% avg_sensitivity=66.54%, avg_specificity=94.69% avg_auc=92.49%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.238892 Test loss=0.311217 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2117968648672104
[5/24] Train loss=0.24096785485744476
[10/24] Train loss=0.28448811173439026
[15/24] Train loss=0.24238795042037964
[20/24] Train loss=0.2251899242401123
Test set avg_accuracy=82.21% avg_sensitivity=39.86%, avg_specificity=98.26% avg_auc=88.44%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.240407 Test loss=0.441707 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2275189906358719
[5/24] Train loss=0.22764791548252106
[10/24] Train loss=0.3058139383792877
[15/24] Train loss=0.23988164961338043
[20/24] Train loss=0.21231161057949066
Test set avg_accuracy=85.25% avg_sensitivity=54.27%, avg_specificity=96.98% avg_auc=91.51%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.237801 Test loss=0.346256 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.21757753193378448
[5/24] Train loss=0.2421010434627533
[10/24] Train loss=0.2867792248725891
[15/24] Train loss=0.23445045948028564
[20/24] Train loss=0.22282502055168152
Test set avg_accuracy=87.24% avg_sensitivity=70.14%, avg_specificity=93.72% avg_auc=92.59%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.236119 Test loss=0.305722 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.21568849682807922
[5/24] Train loss=0.21845293045043945
[10/24] Train loss=0.27410948276519775
[15/24] Train loss=0.2376689463853836
[20/24] Train loss=0.21060693264007568
Test set avg_accuracy=79.26% avg_sensitivity=82.32%, avg_specificity=78.10% avg_auc=89.08%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.233259 Test loss=0.429907 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2133435606956482
[5/24] Train loss=0.219318687915802
[10/24] Train loss=0.2652417719364166
[15/24] Train loss=0.24547752737998962
[20/24] Train loss=0.20961830019950867
Test set avg_accuracy=87.12% avg_sensitivity=79.29%, avg_specificity=90.09% avg_auc=92.98%
Best model saved!! Metric=23.48533796577952!!
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.227739 Test loss=0.302115 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.21443043649196625
[5/24] Train loss=0.20773717761039734
[10/24] Train loss=0.27858391404151917
[15/24] Train loss=0.2336963564157486
[20/24] Train loss=0.20740389823913574
Test set avg_accuracy=87.33% avg_sensitivity=67.01%, avg_specificity=95.03% avg_auc=92.00%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.227093 Test loss=0.316568 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.20299142599105835
[5/24] Train loss=0.2148531973361969
[10/24] Train loss=0.2568833827972412
[15/24] Train loss=0.22623282670974731
[20/24] Train loss=0.20411473512649536
Test set avg_accuracy=82.06% avg_sensitivity=39.57%, avg_specificity=98.15% avg_auc=87.68%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.221054 Test loss=0.469712 Current lr=[0.00029967723776099]

[0/24] Train loss=0.19958211481571198
[5/24] Train loss=0.20387379825115204
[10/24] Train loss=0.2702850103378296
[15/24] Train loss=0.2312227040529251
[20/24] Train loss=0.20218458771705627
Test set avg_accuracy=85.94% avg_sensitivity=69.53%, avg_specificity=92.15% avg_auc=90.51%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.222518 Test loss=0.340538 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2088259905576706
[5/24] Train loss=0.20074941217899323
[10/24] Train loss=0.2782399356365204
[15/24] Train loss=0.23391762375831604
[20/24] Train loss=0.2068542242050171
Test set avg_accuracy=82.93% avg_sensitivity=45.92%, avg_specificity=96.95% avg_auc=88.40%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.220729 Test loss=0.414585 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.22325371205806732
[5/24] Train loss=0.21190939843654633
[10/24] Train loss=0.2720874547958374
[15/24] Train loss=0.22841905057430267
[20/24] Train loss=0.208530992269516
Test set avg_accuracy=85.00% avg_sensitivity=74.88%, avg_specificity=88.83% avg_auc=90.63%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.220929 Test loss=0.348182 Current lr=[0.000299720220882401]

[0/24] Train loss=0.21328319609165192
[5/24] Train loss=0.19138209521770477
[10/24] Train loss=0.265542209148407
[15/24] Train loss=0.23777800798416138
[20/24] Train loss=0.21302223205566406
Test set avg_accuracy=86.52% avg_sensitivity=62.94%, avg_specificity=95.46% avg_auc=91.84%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.222559 Test loss=0.320542 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.20298685133457184
[5/24] Train loss=0.20917662978172302
[10/24] Train loss=0.2608535885810852
[15/24] Train loss=0.22977305948734283
[20/24] Train loss=0.19782179594039917
Test set avg_accuracy=86.38% avg_sensitivity=68.15%, avg_specificity=93.29% avg_auc=91.21%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.214879 Test loss=0.328605 Current lr=[0.000298904600941902]

[0/24] Train loss=0.20535704493522644
[5/24] Train loss=0.20577281713485718
[10/24] Train loss=0.2662472128868103
[15/24] Train loss=0.22158916294574738
[20/24] Train loss=0.19905605912208557
Test set avg_accuracy=82.11% avg_sensitivity=41.28%, avg_specificity=97.58% avg_auc=85.69%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.213617 Test loss=0.461576 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.20960091054439545
[5/24] Train loss=0.2000303715467453
[10/24] Train loss=0.25665315985679626
[15/24] Train loss=0.2293296903371811
[20/24] Train loss=0.19624608755111694
Test set avg_accuracy=85.99% avg_sensitivity=56.54%, avg_specificity=97.15% avg_auc=90.30%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.215214 Test loss=0.350748 Current lr=[0.000297555943323901]

[0/24] Train loss=0.21241897344589233
[5/24] Train loss=0.1988915205001831
[10/24] Train loss=0.26544925570487976
[15/24] Train loss=0.2101486623287201
[20/24] Train loss=0.21077373623847961
Test set avg_accuracy=83.48% avg_sensitivity=49.76%, avg_specificity=96.25% avg_auc=88.05%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.213640 Test loss=0.414373 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.1958490014076233
[5/24] Train loss=0.18791718780994415
[10/24] Train loss=0.2572196424007416
[15/24] Train loss=0.20863540470600128
[20/24] Train loss=0.1951538622379303
Test set avg_accuracy=84.43% avg_sensitivity=50.57%, avg_specificity=97.25% avg_auc=89.53%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.206607 Test loss=0.382327 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.19834785163402557
[5/24] Train loss=0.1885589361190796
[10/24] Train loss=0.2460511326789856
[15/24] Train loss=0.21959741413593292
[20/24] Train loss=0.1962691992521286
Test set avg_accuracy=86.21% avg_sensitivity=64.64%, avg_specificity=94.38% avg_auc=91.05%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.205828 Test loss=0.334603 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.19772380590438843
[5/24] Train loss=0.17822542786598206
[10/24] Train loss=0.24473100900650024
[15/24] Train loss=0.21489083766937256
[20/24] Train loss=0.19131803512573242
Test set avg_accuracy=75.92% avg_sensitivity=14.55%, avg_specificity=99.17% avg_auc=79.79%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.203824 Test loss=0.713968 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.21005335450172424
[5/24] Train loss=0.19502173364162445
[10/24] Train loss=0.2401077300310135
[15/24] Train loss=0.2145613133907318
[20/24] Train loss=0.18853150308132172
Test set avg_accuracy=85.70% avg_sensitivity=61.71%, avg_specificity=94.79% avg_auc=90.34%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.206978 Test loss=0.347205 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.1974509358406067
[5/24] Train loss=0.19432759284973145
[10/24] Train loss=0.23347383737564087
[15/24] Train loss=0.21989032626152039
[20/24] Train loss=0.1946813017129898
Test set avg_accuracy=85.46% avg_sensitivity=59.72%, avg_specificity=95.21% avg_auc=90.15%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.209792 Test loss=0.355040 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.19935059547424316
[5/24] Train loss=0.1844024807214737
[10/24] Train loss=0.25297853350639343
[15/24] Train loss=0.23654745519161224
[20/24] Train loss=0.18912459909915924
Test set avg_accuracy=83.40% avg_sensitivity=46.64%, avg_specificity=97.32% avg_auc=85.52%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.208264 Test loss=0.436040 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.19360774755477905
[5/24] Train loss=0.18420448899269104
[10/24] Train loss=0.23901031911373138
[15/24] Train loss=0.2073582410812378
[20/24] Train loss=0.1908627301454544
Test set avg_accuracy=86.22% avg_sensitivity=63.79%, avg_specificity=94.72% avg_auc=91.25%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.201276 Test loss=0.342426 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.20159058272838593
[5/24] Train loss=0.18368443846702576
[10/24] Train loss=0.23962700366973877
[15/24] Train loss=0.21293507516384125
[20/24] Train loss=0.18871892988681793
Test set avg_accuracy=84.24% avg_sensitivity=50.28%, avg_specificity=97.11% avg_auc=89.17%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.200959 Test loss=0.391200 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.19512677192687988
[5/24] Train loss=0.18419450521469116
[10/24] Train loss=0.2285798043012619
[15/24] Train loss=0.20849016308784485
[20/24] Train loss=0.19847692549228668
Test set avg_accuracy=86.39% avg_sensitivity=63.51%, avg_specificity=95.06% avg_auc=90.87%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.202565 Test loss=0.339539 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.1906297206878662
[5/24] Train loss=0.18132828176021576
[10/24] Train loss=0.22411134839057922
[15/24] Train loss=0.20525869727134705
[20/24] Train loss=0.1945706456899643
Test set avg_accuracy=84.40% avg_sensitivity=52.37%, avg_specificity=96.54% avg_auc=88.07%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.195788 Test loss=0.396974 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.1879463642835617
[5/24] Train loss=0.18003781139850616
[10/24] Train loss=0.2457941174507141
[15/24] Train loss=0.20264485478401184
[20/24] Train loss=0.1877536177635193
Test set avg_accuracy=86.45% avg_sensitivity=67.73%, avg_specificity=93.54% avg_auc=91.31%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.197235 Test loss=0.329509 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.18770496547222137
[5/24] Train loss=0.18039840459823608
[10/24] Train loss=0.22854790091514587
[15/24] Train loss=0.21150794625282288
[20/24] Train loss=0.1817716658115387
Test set avg_accuracy=83.12% avg_sensitivity=48.67%, avg_specificity=96.18% avg_auc=84.69%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.196880 Test loss=0.437426 Current lr=[0.000276307469034998]

[0/24] Train loss=0.19233788549900055
[5/24] Train loss=0.17996859550476074
[10/24] Train loss=0.23336681723594666
[15/24] Train loss=0.2044680416584015
[20/24] Train loss=0.19225099682807922
Test set avg_accuracy=79.17% avg_sensitivity=27.91%, avg_specificity=98.58% avg_auc=82.29%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.194059 Test loss=0.551202 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.18923650681972504
[5/24] Train loss=0.19005216658115387
[10/24] Train loss=0.23812390863895416
[15/24] Train loss=0.2042113095521927
[20/24] Train loss=0.18259677290916443
Test set avg_accuracy=79.10% avg_sensitivity=27.96%, avg_specificity=98.47% avg_auc=79.69%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.197981 Test loss=0.567627 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.19097784161567688
[5/24] Train loss=0.1701522320508957
[10/24] Train loss=0.24627158045768738
[15/24] Train loss=0.20500227808952332
[20/24] Train loss=0.1904238760471344
Test set avg_accuracy=87.03% avg_sensitivity=66.26%, avg_specificity=94.90% avg_auc=91.61%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.197881 Test loss=0.323981 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.19455017149448395
[5/24] Train loss=0.1815587729215622
[10/24] Train loss=0.22977539896965027
[15/24] Train loss=0.20277516543865204
[20/24] Train loss=0.18848277628421783
Test set avg_accuracy=86.30% avg_sensitivity=71.56%, avg_specificity=91.89% avg_auc=90.99%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.194478 Test loss=0.329862 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.18050198256969452
[5/24] Train loss=0.17809617519378662
[10/24] Train loss=0.21571052074432373
[15/24] Train loss=0.21523654460906982
[20/24] Train loss=0.18493129312992096
Test set avg_accuracy=86.68% avg_sensitivity=65.64%, avg_specificity=94.65% avg_auc=90.51%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.192944 Test loss=0.338823 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.17259454727172852
[5/24] Train loss=0.171807199716568
[10/24] Train loss=0.25349780917167664
[15/24] Train loss=0.2041882574558258
[20/24] Train loss=0.18431387841701508
Test set avg_accuracy=86.09% avg_sensitivity=61.71%, avg_specificity=95.33% avg_auc=91.05%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.194404 Test loss=0.347165 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.18847008049488068
[5/24] Train loss=0.17316441237926483
[10/24] Train loss=0.24996307492256165
[15/24] Train loss=0.20559324324131012
[20/24] Train loss=0.17536285519599915
Test set avg_accuracy=85.64% avg_sensitivity=60.71%, avg_specificity=95.08% avg_auc=89.46%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.194330 Test loss=0.363608 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.1791115552186966
[5/24] Train loss=0.1687341183423996
[10/24] Train loss=0.22892577946186066
[15/24] Train loss=0.20540867745876312
[20/24] Train loss=0.17958562076091766
Test set avg_accuracy=72.94% avg_sensitivity=86.21%, avg_specificity=67.92% avg_auc=86.37%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.188988 Test loss=0.551024 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.19898608326911926
[5/24] Train loss=0.17220494151115417
[10/24] Train loss=0.23448708653450012
[15/24] Train loss=0.2101431041955948
[20/24] Train loss=0.1786944419145584
Test set avg_accuracy=86.81% avg_sensitivity=72.65%, avg_specificity=92.17% avg_auc=91.41%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.196022 Test loss=0.322063 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1877308338880539
[5/24] Train loss=0.16699708998203278
[10/24] Train loss=0.224387988448143
[15/24] Train loss=0.19955375790596008
[20/24] Train loss=0.1827632635831833
Test set avg_accuracy=86.29% avg_sensitivity=68.86%, avg_specificity=92.89% avg_auc=89.43%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.188157 Test loss=0.343369 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.18595410883426666
[5/24] Train loss=0.16784442961215973
[10/24] Train loss=0.23395147919654846
[15/24] Train loss=0.1991630345582962
[20/24] Train loss=0.17763552069664001
Test set avg_accuracy=84.99% avg_sensitivity=56.54%, avg_specificity=95.76% avg_auc=88.79%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.186667 Test loss=0.383638 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.17055173218250275
[5/24] Train loss=0.17771686613559723
[10/24] Train loss=0.23286671936511993
[15/24] Train loss=0.20838996767997742
[20/24] Train loss=0.18091657757759094
Test set avg_accuracy=86.41% avg_sensitivity=68.82%, avg_specificity=93.07% avg_auc=91.83%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.186317 Test loss=0.326264 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.17407652735710144
[5/24] Train loss=0.17390842735767365
[10/24] Train loss=0.22605283558368683
[15/24] Train loss=0.2056203931570053
[20/24] Train loss=0.18454177677631378
Test set avg_accuracy=86.34% avg_sensitivity=63.74%, avg_specificity=94.90% avg_auc=90.71%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.190550 Test loss=0.341738 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.18772949278354645
[5/24] Train loss=0.17162419855594635
[10/24] Train loss=0.22068792581558228
[15/24] Train loss=0.21120062470436096
[20/24] Train loss=0.1937561184167862
Test set avg_accuracy=86.90% avg_sensitivity=75.40%, avg_specificity=91.26% avg_auc=92.36%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.192146 Test loss=0.316791 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.17566391825675964
[5/24] Train loss=0.16418753564357758
[10/24] Train loss=0.215134859085083
[15/24] Train loss=0.20891667902469635
[20/24] Train loss=0.18370448052883148
Test set avg_accuracy=85.70% avg_sensitivity=80.62%, avg_specificity=87.63% avg_auc=91.86%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.184802 Test loss=0.334087 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17116007208824158
[5/24] Train loss=0.16643930971622467
[10/24] Train loss=0.2287583202123642
[15/24] Train loss=0.2012459635734558
[20/24] Train loss=0.17330870032310486
Test set avg_accuracy=86.68% avg_sensitivity=66.59%, avg_specificity=94.29% avg_auc=90.48%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.187816 Test loss=0.338657 Current lr=[0.000224838296036774]

[0/24] Train loss=0.18151678144931793
[5/24] Train loss=0.1719355583190918
[10/24] Train loss=0.20838189125061035
[15/24] Train loss=0.20717361569404602
[20/24] Train loss=0.17820389568805695
Test set avg_accuracy=85.23% avg_sensitivity=76.68%, avg_specificity=88.47% avg_auc=90.72%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.190628 Test loss=0.345707 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.18404756486415863
[5/24] Train loss=0.17495805025100708
[10/24] Train loss=0.22042924165725708
[15/24] Train loss=0.19779399037361145
[20/24] Train loss=0.18891198933124542
Test set avg_accuracy=86.73% avg_sensitivity=76.11%, avg_specificity=90.75% avg_auc=92.06%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.188441 Test loss=0.318174 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.1706613302230835
[5/24] Train loss=0.1658911406993866
[10/24] Train loss=0.2263110727071762
[15/24] Train loss=0.20283102989196777
[20/24] Train loss=0.1723698079586029
Test set avg_accuracy=86.37% avg_sensitivity=76.82%, avg_specificity=89.98% avg_auc=92.08%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.185923 Test loss=0.319685 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1705363392829895
[5/24] Train loss=0.1639426052570343
[10/24] Train loss=0.20936164259910583
[15/24] Train loss=0.20212577283382416
[20/24] Train loss=0.1779269576072693
Test set avg_accuracy=83.75% avg_sensitivity=81.90%, avg_specificity=84.45% avg_auc=91.01%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.184584 Test loss=0.362835 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.17100748419761658
[5/24] Train loss=0.16200867295265198
[10/24] Train loss=0.209808811545372
[15/24] Train loss=0.20331156253814697
[20/24] Train loss=0.1785803884267807
Test set avg_accuracy=85.36% avg_sensitivity=74.69%, avg_specificity=89.41% avg_auc=90.11%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.182694 Test loss=0.350778 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.191570445895195
[5/24] Train loss=0.18484513461589813
[10/24] Train loss=0.20991013944149017
[15/24] Train loss=0.19413907825946808
[20/24] Train loss=0.17726072669029236
Test set avg_accuracy=84.57% avg_sensitivity=80.90%, avg_specificity=85.96% avg_auc=91.09%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.185628 Test loss=0.361740 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.16952259838581085
[5/24] Train loss=0.16544154286384583
[10/24] Train loss=0.20504117012023926
[15/24] Train loss=0.1814572960138321
[20/24] Train loss=0.18499839305877686
Test set avg_accuracy=86.22% avg_sensitivity=67.06%, avg_specificity=93.48% avg_auc=90.89%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.180850 Test loss=0.338094 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.17532703280448914
[5/24] Train loss=0.15734265744686127
[10/24] Train loss=0.21691729128360748
[15/24] Train loss=0.18951386213302612
[20/24] Train loss=0.1767059564590454
Test set avg_accuracy=77.23% avg_sensitivity=88.06%, avg_specificity=73.12% avg_auc=88.58%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.183497 Test loss=0.491810 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1717313826084137
[5/24] Train loss=0.1633751392364502
[10/24] Train loss=0.21365782618522644
[15/24] Train loss=0.1954357773065567
[20/24] Train loss=0.18426571786403656
Test set avg_accuracy=86.09% avg_sensitivity=65.69%, avg_specificity=93.82% avg_auc=90.54%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.180552 Test loss=0.345961 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.16761742532253265
[5/24] Train loss=0.15071532130241394
[10/24] Train loss=0.22307902574539185
[15/24] Train loss=0.19789840281009674
[20/24] Train loss=0.1797104924917221
Test set avg_accuracy=86.51% avg_sensitivity=76.68%, avg_specificity=90.23% avg_auc=91.86%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.180480 Test loss=0.320335 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.17474263906478882
[5/24] Train loss=0.15788646042346954
[10/24] Train loss=0.2129872888326645
[15/24] Train loss=0.1855388730764389
[20/24] Train loss=0.1741543561220169
Test set avg_accuracy=86.34% avg_sensitivity=73.60%, avg_specificity=91.17% avg_auc=91.35%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.177719 Test loss=0.329207 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.1698564738035202
[5/24] Train loss=0.153705894947052
[10/24] Train loss=0.20707805454730988
[15/24] Train loss=0.18249814212322235
[20/24] Train loss=0.171770840883255
Test set avg_accuracy=86.52% avg_sensitivity=79.10%, avg_specificity=89.34% avg_auc=91.78%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.175634 Test loss=0.337039 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1704491376876831
[5/24] Train loss=0.15843899548053741
[10/24] Train loss=0.19882602989673615
[15/24] Train loss=0.18289948999881744
[20/24] Train loss=0.17136700451374054
Test set avg_accuracy=86.29% avg_sensitivity=68.53%, avg_specificity=93.02% avg_auc=91.56%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.174709 Test loss=0.330513 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.16604933142662048
[5/24] Train loss=0.16117005050182343
[10/24] Train loss=0.20098912715911865
[15/24] Train loss=0.1900334656238556
[20/24] Train loss=0.16848447918891907
Test set avg_accuracy=86.99% avg_sensitivity=73.98%, avg_specificity=91.92% avg_auc=92.29%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.174565 Test loss=0.315296 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.15979833900928497
[5/24] Train loss=0.15817762911319733
[10/24] Train loss=0.20318588614463806
[15/24] Train loss=0.186255544424057
[20/24] Train loss=0.16844302415847778
Test set avg_accuracy=84.69% avg_sensitivity=86.16%, avg_specificity=84.13% avg_auc=91.73%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.171133 Test loss=0.374910 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.1710565686225891
[5/24] Train loss=0.1713075041770935
[10/24] Train loss=0.19859550893306732
[15/24] Train loss=0.18776357173919678
[20/24] Train loss=0.17087215185165405
Test set avg_accuracy=86.48% avg_sensitivity=69.29%, avg_specificity=93.00% avg_auc=91.03%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.176877 Test loss=0.330401 Current lr=[0.000156543481933168]

[0/24] Train loss=0.16446587443351746
[5/24] Train loss=0.1569455862045288
[10/24] Train loss=0.19753283262252808
[15/24] Train loss=0.18316714465618134
[20/24] Train loss=0.17318396270275116
Test set avg_accuracy=84.96% avg_sensitivity=83.98%, avg_specificity=85.33% avg_auc=91.84%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.171985 Test loss=0.356887 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.16222691535949707
[5/24] Train loss=0.15103396773338318
[10/24] Train loss=0.19502754509449005
[15/24] Train loss=0.17937879264354706
[20/24] Train loss=0.16857856512069702
Test set avg_accuracy=85.69% avg_sensitivity=59.91%, avg_specificity=95.46% avg_auc=90.02%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.167901 Test loss=0.362455 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15927866101264954
[5/24] Train loss=0.1534976363182068
[10/24] Train loss=0.19935160875320435
[15/24] Train loss=0.17619985342025757
[20/24] Train loss=0.16494885087013245
Test set avg_accuracy=85.82% avg_sensitivity=63.89%, avg_specificity=94.13% avg_auc=87.88%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.166586 Test loss=0.359979 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15257948637008667
[5/24] Train loss=0.14548294246196747
[10/24] Train loss=0.1909467726945877
[15/24] Train loss=0.18268850445747375
[20/24] Train loss=0.16736075282096863
Test set avg_accuracy=87.08% avg_sensitivity=74.93%, avg_specificity=91.69% avg_auc=91.95%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.164237 Test loss=0.319845 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15563975274562836
[5/24] Train loss=0.1450139433145523
[10/24] Train loss=0.18046356737613678
[15/24] Train loss=0.19073031842708588
[20/24] Train loss=0.16423805058002472
Test set avg_accuracy=85.48% avg_sensitivity=60.09%, avg_specificity=95.10% avg_auc=89.30%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.165354 Test loss=0.371915 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15312747657299042
[5/24] Train loss=0.15083196759223938
[10/24] Train loss=0.18807794153690338
[15/24] Train loss=0.18149733543395996
[20/24] Train loss=0.17304307222366333
Test set avg_accuracy=86.46% avg_sensitivity=69.00%, avg_specificity=93.07% avg_auc=91.08%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.165412 Test loss=0.332879 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15274493396282196
[5/24] Train loss=0.1476210057735443
[10/24] Train loss=0.17948776483535767
[15/24] Train loss=0.1772552728652954
[20/24] Train loss=0.16078908741474152
Test set avg_accuracy=87.02% avg_sensitivity=72.13%, avg_specificity=92.66% avg_auc=90.61%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.160747 Test loss=0.330723 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1541687548160553
[5/24] Train loss=0.14428482949733734
[10/24] Train loss=0.1853923201560974
[15/24] Train loss=0.1714981496334076
[20/24] Train loss=0.1579182744026184
Test set avg_accuracy=86.41% avg_sensitivity=64.41%, avg_specificity=94.74% avg_auc=90.52%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.159477 Test loss=0.351721 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15334412455558777
[5/24] Train loss=0.14352978765964508
[10/24] Train loss=0.1730697751045227
[15/24] Train loss=0.17372271418571472
[20/24] Train loss=0.15723229944705963
Test set avg_accuracy=86.59% avg_sensitivity=69.38%, avg_specificity=93.11% avg_auc=89.27%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.158328 Test loss=0.343759 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.15144413709640503
[5/24] Train loss=0.1444658637046814
[10/24] Train loss=0.18251411616802216
[15/24] Train loss=0.18156112730503082
[20/24] Train loss=0.16433008015155792
Test set avg_accuracy=86.85% avg_sensitivity=68.06%, avg_specificity=93.97% avg_auc=91.55%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.158495 Test loss=0.331617 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15082277357578278
[5/24] Train loss=0.1405443400144577
[10/24] Train loss=0.17662949860095978
[15/24] Train loss=0.17412996292114258
[20/24] Train loss=0.15415532886981964
Test set avg_accuracy=85.98% avg_sensitivity=61.18%, avg_specificity=95.37% avg_auc=85.51%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.156153 Test loss=0.381530 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.14761093258857727
[5/24] Train loss=0.14391811192035675
[10/24] Train loss=0.17299284040927887
[15/24] Train loss=0.17591217160224915
[20/24] Train loss=0.1591598391532898
Test set avg_accuracy=87.02% avg_sensitivity=71.56%, avg_specificity=92.87% avg_auc=92.01%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.158773 Test loss=0.322164 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15212930738925934
[5/24] Train loss=0.14518138766288757
[10/24] Train loss=0.17507506906986237
[15/24] Train loss=0.17118385434150696
[20/24] Train loss=0.15855436027050018
Test set avg_accuracy=85.38% avg_sensitivity=61.61%, avg_specificity=94.38% avg_auc=90.09%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.156426 Test loss=0.364152 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14730247855186462
[5/24] Train loss=0.14366187155246735
[10/24] Train loss=0.1722300946712494
[15/24] Train loss=0.16945117712020874
[20/24] Train loss=0.15322110056877136
Test set avg_accuracy=86.82% avg_sensitivity=72.80%, avg_specificity=92.14% avg_auc=91.89%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.156569 Test loss=0.327237 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15293152630329132
[5/24] Train loss=0.1412552148103714
[10/24] Train loss=0.18145795166492462
[15/24] Train loss=0.16798169910907745
[20/24] Train loss=0.15772785246372223
Test set avg_accuracy=86.25% avg_sensitivity=69.72%, avg_specificity=92.51% avg_auc=88.06%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.156544 Test loss=0.363331 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.14953294396400452
[5/24] Train loss=0.13867396116256714
[10/24] Train loss=0.18910320103168488
[15/24] Train loss=0.1673632115125656
[20/24] Train loss=0.14913971722126007
Test set avg_accuracy=86.97% avg_sensitivity=69.10%, avg_specificity=93.73% avg_auc=91.08%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.156028 Test loss=0.337806 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1459140032529831
[5/24] Train loss=0.14332325756549835
[10/24] Train loss=0.1715395748615265
[15/24] Train loss=0.16801606118679047
[20/24] Train loss=0.15752337872982025
Test set avg_accuracy=87.64% avg_sensitivity=74.79%, avg_specificity=92.51% avg_auc=92.07%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.154808 Test loss=0.318271 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14359451830387115
[5/24] Train loss=0.13615785539150238
[10/24] Train loss=0.16325518488883972
[15/24] Train loss=0.16387630999088287
[20/24] Train loss=0.1518009454011917
Test set avg_accuracy=87.36% avg_sensitivity=73.65%, avg_specificity=92.55% avg_auc=91.21%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.150471 Test loss=0.323334 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14447197318077087
[5/24] Train loss=0.13809850811958313
[10/24] Train loss=0.16389691829681396
[15/24] Train loss=0.17083607614040375
[20/24] Train loss=0.1501823216676712
Test set avg_accuracy=86.50% avg_sensitivity=78.10%, avg_specificity=89.68% avg_auc=91.83%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.150634 Test loss=0.332849 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14502742886543274
[5/24] Train loss=0.14167645573616028
[10/24] Train loss=0.17084471881389618
[15/24] Train loss=0.17016637325286865
[20/24] Train loss=0.15640825033187866
Test set avg_accuracy=86.02% avg_sensitivity=61.61%, avg_specificity=95.26% avg_auc=91.02%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.152065 Test loss=0.348655 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14154234528541565
[5/24] Train loss=0.1399109959602356
[10/24] Train loss=0.17193703353405
[15/24] Train loss=0.1651706099510193
[20/24] Train loss=0.15282396972179413
Test set avg_accuracy=87.32% avg_sensitivity=75.02%, avg_specificity=91.97% avg_auc=92.30%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.150627 Test loss=0.314996 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14049658179283142
[5/24] Train loss=0.13289237022399902
[10/24] Train loss=0.1722377985715866
[15/24] Train loss=0.159115731716156
[20/24] Train loss=0.15208204090595245
Test set avg_accuracy=87.32% avg_sensitivity=73.51%, avg_specificity=92.55% avg_auc=92.31%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.148626 Test loss=0.309767 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14186245203018188
[5/24] Train loss=0.13527190685272217
[10/24] Train loss=0.16694819927215576
[15/24] Train loss=0.16220450401306152
[20/24] Train loss=0.14929434657096863
Test set avg_accuracy=86.47% avg_sensitivity=76.68%, avg_specificity=90.18% avg_auc=89.93%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.146830 Test loss=0.350898 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13977739214897156
[5/24] Train loss=0.12780337035655975
[10/24] Train loss=0.16433604061603546
[15/24] Train loss=0.1562977284193039
[20/24] Train loss=0.14420925080776215
Test set avg_accuracy=87.08% avg_sensitivity=75.40%, avg_specificity=91.51% avg_auc=91.99%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.144347 Test loss=0.326809 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13466396927833557
[5/24] Train loss=0.12807776033878326
[10/24] Train loss=0.15849396586418152
[15/24] Train loss=0.15560568869113922
[20/24] Train loss=0.1446218341588974
Test set avg_accuracy=87.17% avg_sensitivity=77.20%, avg_specificity=90.95% avg_auc=92.02%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.143626 Test loss=0.323970 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1387883573770523
[5/24] Train loss=0.12953665852546692
[10/24] Train loss=0.15889941155910492
[15/24] Train loss=0.15456850826740265
[20/24] Train loss=0.14268435537815094
Test set avg_accuracy=87.19% avg_sensitivity=74.83%, avg_specificity=91.87% avg_auc=91.93%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.142164 Test loss=0.318423 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1350199580192566
[5/24] Train loss=0.12959089875221252
[10/24] Train loss=0.15977376699447632
[15/24] Train loss=0.1508428305387497
[20/24] Train loss=0.1437963843345642
Test set avg_accuracy=87.02% avg_sensitivity=77.44%, avg_specificity=90.65% avg_auc=92.10%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.141075 Test loss=0.325733 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13710497319698334
[5/24] Train loss=0.12492598593235016
[10/24] Train loss=0.15814894437789917
[15/24] Train loss=0.15690530836582184
[20/24] Train loss=0.138011634349823
Test set avg_accuracy=87.33% avg_sensitivity=71.94%, avg_specificity=93.16% avg_auc=91.91%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.139972 Test loss=0.321166 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13033278286457062
[5/24] Train loss=0.13037875294685364
[10/24] Train loss=0.15393106639385223
[15/24] Train loss=0.15008112788200378
[20/24] Train loss=0.1403307020664215
Test set avg_accuracy=87.42% avg_sensitivity=74.22%, avg_specificity=92.42% avg_auc=92.28%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.138556 Test loss=0.314457 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13372300565242767
[5/24] Train loss=0.12484891712665558
[10/24] Train loss=0.1517152488231659
[15/24] Train loss=0.15347836911678314
[20/24] Train loss=0.14406980574131012
Test set avg_accuracy=87.36% avg_sensitivity=73.98%, avg_specificity=92.42% avg_auc=92.29%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.138178 Test loss=0.314141 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13301554322242737
[5/24] Train loss=0.12279310822486877
[10/24] Train loss=0.14954128861427307
[15/24] Train loss=0.14927677810192108
[20/24] Train loss=0.1361674815416336
Test set avg_accuracy=87.10% avg_sensitivity=73.27%, avg_specificity=92.33% avg_auc=92.25%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.137679 Test loss=0.318101 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13213299214839935
[5/24] Train loss=0.12148343026638031
[10/24] Train loss=0.14912675321102142
[15/24] Train loss=0.14890214800834656
[20/24] Train loss=0.13990382850170135
Test set avg_accuracy=86.85% avg_sensitivity=71.56%, avg_specificity=92.64% avg_auc=91.86%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.137185 Test loss=0.327981 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12825924158096313
[5/24] Train loss=0.12373006343841553
[10/24] Train loss=0.1537497639656067
[15/24] Train loss=0.14686159789562225
[20/24] Train loss=0.13415494561195374
Test set avg_accuracy=86.80% avg_sensitivity=70.33%, avg_specificity=93.03% avg_auc=91.97%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.135645 Test loss=0.323001 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13072489202022552
[5/24] Train loss=0.12342092394828796
[10/24] Train loss=0.1430814564228058
[15/24] Train loss=0.14830170571804047
[20/24] Train loss=0.13680925965309143
Test set avg_accuracy=87.17% avg_sensitivity=73.41%, avg_specificity=92.39% avg_auc=92.18%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.135174 Test loss=0.318856 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13002653419971466
[5/24] Train loss=0.12341053783893585
[10/24] Train loss=0.14773349463939667
[15/24] Train loss=0.14605315029621124
[20/24] Train loss=0.13305024802684784
Test set avg_accuracy=86.93% avg_sensitivity=77.35%, avg_specificity=90.56% avg_auc=92.10%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.135581 Test loss=0.324671 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12905098497867584
[5/24] Train loss=0.12039537727832794
[10/24] Train loss=0.14896874129772186
[15/24] Train loss=0.15438543260097504
[20/24] Train loss=0.1364973932504654
Test set avg_accuracy=87.01% avg_sensitivity=75.36%, avg_specificity=91.42% avg_auc=92.12%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.134780 Test loss=0.320873 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1314150094985962
[5/24] Train loss=0.11959510296583176
[10/24] Train loss=0.14484603703022003
[15/24] Train loss=0.14766421914100647
[20/24] Train loss=0.13566413521766663
Test set avg_accuracy=87.23% avg_sensitivity=75.07%, avg_specificity=91.83% avg_auc=92.39%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.134311 Test loss=0.314752 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12814341485500336
[5/24] Train loss=0.12683337926864624
[10/24] Train loss=0.14710623025894165
[15/24] Train loss=0.14383159577846527
[20/24] Train loss=0.13820108771324158
Test set avg_accuracy=87.21% avg_sensitivity=76.07%, avg_specificity=91.44% avg_auc=92.50%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.134319 Test loss=0.313159 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12607605755329132
[5/24] Train loss=0.12089303135871887
[10/24] Train loss=0.1432705670595169
[15/24] Train loss=0.14304165542125702
[20/24] Train loss=0.13535867631435394
Test set avg_accuracy=87.11% avg_sensitivity=73.89%, avg_specificity=92.12% avg_auc=92.26%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.133295 Test loss=0.316420 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12591806054115295
[5/24] Train loss=0.12211719155311584
[10/24] Train loss=0.14397388696670532
[15/24] Train loss=0.13997071981430054
[20/24] Train loss=0.1345357894897461
Test set avg_accuracy=87.17% avg_sensitivity=74.79%, avg_specificity=91.87% avg_auc=92.28%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.131539 Test loss=0.315793 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12521019577980042
[5/24] Train loss=0.1213470846414566
[10/24] Train loss=0.14407889544963837
[15/24] Train loss=0.1421326994895935
[20/24] Train loss=0.13121230900287628
Test set avg_accuracy=87.43% avg_sensitivity=77.63%, avg_specificity=91.15% avg_auc=92.34%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.131328 Test loss=0.314568 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12500949203968048
[5/24] Train loss=0.11909575760364532
[10/24] Train loss=0.14343143999576569
[15/24] Train loss=0.14155589044094086
[20/24] Train loss=0.1324690580368042
Test set avg_accuracy=87.21% avg_sensitivity=74.98%, avg_specificity=91.85% avg_auc=92.17%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.130537 Test loss=0.317240 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1255853772163391
[5/24] Train loss=0.11801682412624359
[10/24] Train loss=0.1384994238615036
[15/24] Train loss=0.1413080096244812
[20/24] Train loss=0.13074377179145813
Test set avg_accuracy=87.08% avg_sensitivity=75.40%, avg_specificity=91.51% avg_auc=92.21%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.130272 Test loss=0.318117 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12365520745515823
[5/24] Train loss=0.11811139434576035
[10/24] Train loss=0.1411077380180359
[15/24] Train loss=0.14230193197727203
[20/24] Train loss=0.1344384253025055
Test set avg_accuracy=87.23% avg_sensitivity=75.92%, avg_specificity=91.51% avg_auc=92.25%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.129528 Test loss=0.316242 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12439801543951035
[5/24] Train loss=0.11768678575754166
[10/24] Train loss=0.14128002524375916
[15/24] Train loss=0.13830222189426422
[20/24] Train loss=0.13001438975334167
Test set avg_accuracy=87.33% avg_sensitivity=75.50%, avg_specificity=91.81% avg_auc=92.34%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.129187 Test loss=0.314343 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12417368590831757
[5/24] Train loss=0.11773170530796051
[10/24] Train loss=0.1382748931646347
[15/24] Train loss=0.14228016138076782
[20/24] Train loss=0.13013891875743866
Test set avg_accuracy=87.30% avg_sensitivity=75.26%, avg_specificity=91.87% avg_auc=92.31%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.128484 Test loss=0.315489 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1231156587600708
[5/24] Train loss=0.11794520169496536
[10/24] Train loss=0.14333270490169525
[15/24] Train loss=0.14013536274433136
[20/24] Train loss=0.13102132081985474
Test set avg_accuracy=87.19% avg_sensitivity=75.12%, avg_specificity=91.76% avg_auc=92.30%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.129075 Test loss=0.314887 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12367404997348785
[5/24] Train loss=0.1190279871225357
[10/24] Train loss=0.14411689341068268
[15/24] Train loss=0.14197461307048798
[20/24] Train loss=0.13122136890888214
Test set avg_accuracy=87.19% avg_sensitivity=75.07%, avg_specificity=91.78% avg_auc=92.25%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.128951 Test loss=0.316291 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12176217138767242
[5/24] Train loss=0.11461266130208969
[10/24] Train loss=0.14073464274406433
[15/24] Train loss=0.13870792090892792
[20/24] Train loss=0.129039004445076
Test set avg_accuracy=87.17% avg_sensitivity=75.12%, avg_specificity=91.74% avg_auc=92.25%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.128617 Test loss=0.316520 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12162964791059494
[5/24] Train loss=0.11752548813819885
[10/24] Train loss=0.14088843762874603
[15/24] Train loss=0.13727572560310364
[20/24] Train loss=0.12915508449077606
Test set avg_accuracy=87.21% avg_sensitivity=75.40%, avg_specificity=91.69% avg_auc=92.28%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.128175 Test loss=0.316204 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12400196492671967
[5/24] Train loss=0.11670874059200287
[10/24] Train loss=0.13968563079833984
[15/24] Train loss=0.13699649274349213
[20/24] Train loss=0.13214412331581116
Test set avg_accuracy=87.24% avg_sensitivity=75.31%, avg_specificity=91.76% avg_auc=92.28%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.128154 Test loss=0.315953 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.124178446829319
[5/24] Train loss=0.1196034699678421
[10/24] Train loss=0.14039187133312225
[15/24] Train loss=0.13702958822250366
[20/24] Train loss=0.1284850388765335
Test set avg_accuracy=87.25% avg_sensitivity=75.55%, avg_specificity=91.69% avg_auc=92.29%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.128328 Test loss=0.315999 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12244938313961029
[5/24] Train loss=0.1184719130396843
[10/24] Train loss=0.14084041118621826
[15/24] Train loss=0.13806657493114471
[20/24] Train loss=0.12901240587234497
Test set avg_accuracy=87.27% avg_sensitivity=75.31%, avg_specificity=91.80% avg_auc=92.28%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.128447 Test loss=0.316058 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12392272055149078
[5/24] Train loss=0.11517339199781418
[10/24] Train loss=0.13893401622772217
[15/24] Train loss=0.13753680884838104
[20/24] Train loss=0.12901200354099274
Test set avg_accuracy=87.25% avg_sensitivity=75.31%, avg_specificity=91.78% avg_auc=92.28%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.128457 Test loss=0.316194 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=87.12% sen=79.29%, spe=90.09%, auc=92.98%!
Fold[3] Avg_overlap=0.68%(±0.2494602101030974)
[0/24] Train loss=0.7451978921890259
[5/24] Train loss=0.7476672530174255
[10/24] Train loss=0.7407651543617249
[15/24] Train loss=0.7307126522064209
[20/24] Train loss=0.7148600816726685
Test set avg_accuracy=59.40% avg_sensitivity=53.57%, avg_specificity=61.45% avg_auc=59.78%
Best model saved!! Metric=-91.7933650039195!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.736883 Test loss=0.683291 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7187548875808716
[5/24] Train loss=0.7164626121520996
[10/24] Train loss=0.7135776877403259
[15/24] Train loss=0.6992568969726562
[20/24] Train loss=0.6897177696228027
Test set avg_accuracy=65.09% avg_sensitivity=67.37%, avg_specificity=64.29% avg_auc=71.32%
Best model saved!! Metric=-57.934848125137336!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.706993 Test loss=0.633089 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6843898892402649
[5/24] Train loss=0.6897859573364258
[10/24] Train loss=0.6875134706497192
[15/24] Train loss=0.6718349456787109
[20/24] Train loss=0.6674922108650208
Test set avg_accuracy=68.83% avg_sensitivity=74.26%, avg_specificity=66.91% avg_auc=77.39%
Best model saved!! Metric=-38.60745145371713!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.679377 Test loss=0.595405 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6552361249923706
[5/24] Train loss=0.6652144193649292
[10/24] Train loss=0.6704342365264893
[15/24] Train loss=0.6383097767829895
[20/24] Train loss=0.6261183619499207
Test set avg_accuracy=70.92% avg_sensitivity=78.56%, avg_specificity=68.23% avg_auc=80.50%
Best model saved!! Metric=-27.782594836391667!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.652788 Test loss=0.570537 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6309402585029602
[5/24] Train loss=0.6376190781593323
[10/24] Train loss=0.6437432765960693
[15/24] Train loss=0.6195055246353149
[20/24] Train loss=0.5991981029510498
Test set avg_accuracy=72.77% avg_sensitivity=79.91%, avg_specificity=70.26% avg_auc=82.68%
Best model saved!! Metric=-20.382045332628422!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.624226 Test loss=0.544990 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5935539603233337
[5/24] Train loss=0.6018626093864441
[10/24] Train loss=0.615166187286377
[15/24] Train loss=0.5905025005340576
[20/24] Train loss=0.5717278122901917
Test set avg_accuracy=74.86% avg_sensitivity=81.06%, avg_specificity=72.67% avg_auc=84.50%
Best model saved!! Metric=-12.912943006700345!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.595026 Test loss=0.520809 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5679446458816528
[5/24] Train loss=0.5748174786567688
[10/24] Train loss=0.5927426815032959
[15/24] Train loss=0.5574854612350464
[20/24] Train loss=0.5402251482009888
Test set avg_accuracy=77.54% avg_sensitivity=80.86%, avg_specificity=76.37% avg_auc=86.06%
Best model saved!! Metric=-5.171598721599096!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.565751 Test loss=0.492247 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5365003347396851
[5/24] Train loss=0.5381166338920593
[10/24] Train loss=0.5535884499549866
[15/24] Train loss=0.5220604538917542
[20/24] Train loss=0.5125806331634521
Test set avg_accuracy=79.56% avg_sensitivity=81.01%, avg_specificity=79.05% avg_auc=87.28%
Best model saved!! Metric=0.8934668613373304!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.533391 Test loss=0.468752 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5024397373199463
[5/24] Train loss=0.5025609135627747
[10/24] Train loss=0.5273623466491699
[15/24] Train loss=0.4885769188404083
[20/24] Train loss=0.4803345501422882
Test set avg_accuracy=81.43% avg_sensitivity=79.11%, avg_specificity=82.25% avg_auc=88.13%
Best model saved!! Metric=4.926940362744787!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.502502 Test loss=0.445366 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.46953755617141724
[5/24] Train loss=0.46483519673347473
[10/24] Train loss=0.4974634349346161
[15/24] Train loss=0.4669906795024872
[20/24] Train loss=0.44581764936447144
Test set avg_accuracy=82.85% avg_sensitivity=79.26%, avg_specificity=84.12% avg_auc=88.86%
Best model saved!! Metric=9.084963320280139!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.473293 Test loss=0.424461 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4478609263896942
[5/24] Train loss=0.44105252623558044
[10/24] Train loss=0.47041115164756775
[15/24] Train loss=0.4417859613895416
[20/24] Train loss=0.42211365699768066
Test set avg_accuracy=83.65% avg_sensitivity=76.36%, avg_specificity=86.21% avg_auc=89.41%
Best model saved!! Metric=9.626032703625299!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.446461 Test loss=0.400922 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4159910976886749
[5/24] Train loss=0.41291162371635437
[10/24] Train loss=0.44648629426956177
[15/24] Train loss=0.41830629110336304
[20/24] Train loss=0.39592573046684265
Test set avg_accuracy=84.49% avg_sensitivity=75.76%, avg_specificity=87.57% avg_auc=89.89%
Best model saved!! Metric=11.709767827638615!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.422055 Test loss=0.385111 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.39829400181770325
[5/24] Train loss=0.3879662752151489
[10/24] Train loss=0.43173596262931824
[15/24] Train loss=0.39475417137145996
[20/24] Train loss=0.38055363297462463
Test set avg_accuracy=85.68% avg_sensitivity=72.26%, avg_specificity=90.40% avg_auc=90.15%
Best model saved!! Metric=12.496280355706105!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.400117 Test loss=0.364158 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3768879175186157
[5/24] Train loss=0.3621933162212372
[10/24] Train loss=0.4147639274597168
[15/24] Train loss=0.3743019700050354
[20/24] Train loss=0.36303451657295227
Test set avg_accuracy=86.11% avg_sensitivity=74.21%, avg_specificity=90.30% avg_auc=90.80%
Best model saved!! Metric=15.419042501690043!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.380165 Test loss=0.355510 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3598698079586029
[5/24] Train loss=0.34453222155570984
[10/24] Train loss=0.3956884443759918
[15/24] Train loss=0.3566029965877533
[20/24] Train loss=0.3452225625514984
Test set avg_accuracy=86.64% avg_sensitivity=73.11%, avg_specificity=91.41% avg_auc=91.00%
Best model saved!! Metric=16.16237108240871!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.363304 Test loss=0.344295 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3437519073486328
[5/24] Train loss=0.3281804323196411
[10/24] Train loss=0.38333940505981445
[15/24] Train loss=0.345453143119812
[20/24] Train loss=0.3321748673915863
Test set avg_accuracy=86.61% avg_sensitivity=73.31%, avg_specificity=91.30% avg_auc=91.36%
Best model saved!! Metric=16.5886301187098!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.348057 Test loss=0.338977 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.32972484827041626
[5/24] Train loss=0.31951192021369934
[10/24] Train loss=0.36810436844825745
[15/24] Train loss=0.33952733874320984
[20/24] Train loss=0.31993934512138367
Test set avg_accuracy=86.86% avg_sensitivity=74.16%, avg_specificity=91.34% avg_auc=91.81%
Best model saved!! Metric=18.174043331801926!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.336386 Test loss=0.329803 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.31599161028862
[5/24] Train loss=0.30350688099861145
[10/24] Train loss=0.36159032583236694
[15/24] Train loss=0.32647594809532166
[20/24] Train loss=0.3081096112728119
Test set avg_accuracy=86.98% avg_sensitivity=75.26%, avg_specificity=91.11% avg_auc=92.07%
Best model saved!! Metric=19.42307378512716!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.323728 Test loss=0.323521 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3034309446811676
[5/24] Train loss=0.2908434569835663
[10/24] Train loss=0.3428119122982025
[15/24] Train loss=0.3141215443611145
[20/24] Train loss=0.2985793948173523
Test set avg_accuracy=87.11% avg_sensitivity=75.31%, avg_specificity=91.27% avg_auc=92.00%
Best model saved!! Metric=19.689681606689604!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.313044 Test loss=0.317551 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.29151836037635803
[5/24] Train loss=0.28765177726745605
[10/24] Train loss=0.33127760887145996
[15/24] Train loss=0.30807217955589294
[20/24] Train loss=0.28873884677886963
Test set avg_accuracy=87.04% avg_sensitivity=76.91%, avg_specificity=90.61% avg_auc=92.31%
Best model saved!! Metric=20.87558954622554!!
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.303691 Test loss=0.317264 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.28965088725090027
[5/24] Train loss=0.2788535952568054
[10/24] Train loss=0.3290770351886749
[15/24] Train loss=0.30024394392967224
[20/24] Train loss=0.2793969511985779
Test set avg_accuracy=86.81% avg_sensitivity=77.91%, avg_specificity=89.95% avg_auc=92.28%
Best model saved!! Metric=20.948993391439288!!
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.297170 Test loss=0.318004 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.27393466234207153
[5/24] Train loss=0.2702538073062897
[10/24] Train loss=0.3122605085372925
[15/24] Train loss=0.28878289461135864
[20/24] Train loss=0.27546948194503784
Test set avg_accuracy=87.80% avg_sensitivity=73.96%, avg_specificity=92.67% avg_auc=92.72%
Best model saved!! Metric=21.16044404432644!!
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.288416 Test loss=0.301359 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2725915312767029
[5/24] Train loss=0.2698335647583008
[10/24] Train loss=0.318372905254364
[15/24] Train loss=0.2844011187553406
[20/24] Train loss=0.2712014615535736
Test set avg_accuracy=87.41% avg_sensitivity=73.61%, avg_specificity=92.27% avg_auc=92.52%
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.284059 Test loss=0.302998 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.27119192481040955
[5/24] Train loss=0.25735798478126526
[10/24] Train loss=0.29995280504226685
[15/24] Train loss=0.2848525643348694
[20/24] Train loss=0.2652462422847748
Test set avg_accuracy=87.59% avg_sensitivity=73.91%, avg_specificity=92.41% avg_auc=92.50%
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.278562 Test loss=0.301058 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2631656527519226
[5/24] Train loss=0.24683615565299988
[10/24] Train loss=0.2967458963394165
[15/24] Train loss=0.2782607078552246
[20/24] Train loss=0.2567157745361328
Test set avg_accuracy=87.76% avg_sensitivity=73.96%, avg_specificity=92.62% avg_auc=92.91%
Best model saved!! Metric=21.255893439637816!!
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.272077 Test loss=0.296763 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.26245546340942383
[5/24] Train loss=0.24799789488315582
[10/24] Train loss=0.2972554564476013
[15/24] Train loss=0.2758725583553314
[20/24] Train loss=0.25765618681907654
Test set avg_accuracy=86.81% avg_sensitivity=77.56%, avg_specificity=90.07% avg_auc=92.68%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.267293 Test loss=0.310579 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2570051848888397
[5/24] Train loss=0.24144908785820007
[10/24] Train loss=0.304579496383667
[15/24] Train loss=0.27134907245635986
[20/24] Train loss=0.24789837002754211
Test set avg_accuracy=87.75% avg_sensitivity=70.51%, avg_specificity=93.82% avg_auc=92.01%
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.263423 Test loss=0.302700 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.25247225165367126
[5/24] Train loss=0.23800037801265717
[10/24] Train loss=0.2927257716655731
[15/24] Train loss=0.26389893889427185
[20/24] Train loss=0.2436227649450302
Test set avg_accuracy=87.76% avg_sensitivity=75.31%, avg_specificity=92.15% avg_auc=92.77%
Best model saved!! Metric=21.98893068928203!!
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.260002 Test loss=0.298980 Current lr=[0.000210185142098938]

[0/24] Train loss=0.24345272779464722
[5/24] Train loss=0.23128008842468262
[10/24] Train loss=0.29757773876190186
[15/24] Train loss=0.2619805932044983
[20/24] Train loss=0.24456776678562164
Test set avg_accuracy=86.84% avg_sensitivity=65.32%, avg_specificity=94.42% avg_auc=91.35%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.256523 Test loss=0.316625 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2511090338230133
[5/24] Train loss=0.2229781597852707
[10/24] Train loss=0.29525700211524963
[15/24] Train loss=0.24536481499671936
[20/24] Train loss=0.23938053846359253
Test set avg_accuracy=85.51% avg_sensitivity=53.17%, avg_specificity=96.90% avg_auc=90.85%
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.252026 Test loss=0.347643 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2472071349620819
[5/24] Train loss=0.22116902470588684
[10/24] Train loss=0.28290215134620667
[15/24] Train loss=0.24854087829589844
[20/24] Train loss=0.23629523813724518
Test set avg_accuracy=87.76% avg_sensitivity=71.66%, avg_specificity=93.43% avg_auc=92.80%
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.248078 Test loss=0.293126 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.23894187808036804
[5/24] Train loss=0.22615838050842285
[10/24] Train loss=0.28604361414909363
[15/24] Train loss=0.246634840965271
[20/24] Train loss=0.2383829653263092
Test set avg_accuracy=87.34% avg_sensitivity=65.92%, avg_specificity=94.89% avg_auc=91.78%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.248174 Test loss=0.308628 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.23656632006168365
[5/24] Train loss=0.22814568877220154
[10/24] Train loss=0.2661052644252777
[15/24] Train loss=0.24409708380699158
[20/24] Train loss=0.23536019027233124
Test set avg_accuracy=86.45% avg_sensitivity=77.31%, avg_specificity=89.66% avg_auc=92.50%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.243250 Test loss=0.311466 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2289278507232666
[5/24] Train loss=0.21698735654354095
[10/24] Train loss=0.28254491090774536
[15/24] Train loss=0.23361217975616455
[20/24] Train loss=0.22944311797618866
Test set avg_accuracy=87.54% avg_sensitivity=76.76%, avg_specificity=91.34% avg_auc=92.89%
Best model saved!! Metric=22.526450475320317!!
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.244189 Test loss=0.295464 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.23050329089164734
[5/24] Train loss=0.2230304777622223
[10/24] Train loss=0.28045743703842163
[15/24] Train loss=0.23330816626548767
[20/24] Train loss=0.23746195435523987
Test set avg_accuracy=86.88% avg_sensitivity=62.77%, avg_specificity=95.37% avg_auc=92.13%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.240473 Test loss=0.312958 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.23703046143054962
[5/24] Train loss=0.21678782999515533
[10/24] Train loss=0.2724761962890625
[15/24] Train loss=0.23623871803283691
[20/24] Train loss=0.22600460052490234
Test set avg_accuracy=88.29% avg_sensitivity=71.31%, avg_specificity=94.28% avg_auc=92.93%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.237970 Test loss=0.290161 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2294556051492691
[5/24] Train loss=0.20875884592533112
[10/24] Train loss=0.26687467098236084
[15/24] Train loss=0.24422824382781982
[20/24] Train loss=0.2368701994419098
Test set avg_accuracy=86.77% avg_sensitivity=70.66%, avg_specificity=92.45% avg_auc=92.03%
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.235508 Test loss=0.309438 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.22503291070461273
[5/24] Train loss=0.2049155831336975
[10/24] Train loss=0.2703929543495178
[15/24] Train loss=0.23373520374298096
[20/24] Train loss=0.22231937944889069
Test set avg_accuracy=85.10% avg_sensitivity=55.12%, avg_specificity=95.67% avg_auc=88.54%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.233807 Test loss=0.382291 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.23461733758449554
[5/24] Train loss=0.1959105134010315
[10/24] Train loss=0.2730645537376404
[15/24] Train loss=0.23199152946472168
[20/24] Train loss=0.23724843561649323
Test set avg_accuracy=85.86% avg_sensitivity=55.87%, avg_specificity=96.43% avg_auc=91.17%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.229591 Test loss=0.341652 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.22617687284946442
[5/24] Train loss=0.2003965526819229
[10/24] Train loss=0.26773709058761597
[15/24] Train loss=0.23220936954021454
[20/24] Train loss=0.23349280655384064
Test set avg_accuracy=86.81% avg_sensitivity=69.17%, avg_specificity=93.03% avg_auc=91.18%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.229292 Test loss=0.318345 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.23598375916481018
[5/24] Train loss=0.2017604261636734
[10/24] Train loss=0.2720296382904053
[15/24] Train loss=0.22842083871364594
[20/24] Train loss=0.21721860766410828
Test set avg_accuracy=85.17% avg_sensitivity=81.41%, avg_specificity=86.49% avg_auc=91.73%
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.229597 Test loss=0.344106 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.21897244453430176
[5/24] Train loss=0.19383740425109863
[10/24] Train loss=0.26968520879745483
[15/24] Train loss=0.21647557616233826
[20/24] Train loss=0.21469371020793915
Test set avg_accuracy=87.53% avg_sensitivity=70.51%, avg_specificity=93.52% avg_auc=92.04%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.224431 Test loss=0.305448 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2223266214132309
[5/24] Train loss=0.21342700719833374
[10/24] Train loss=0.2544376850128174
[15/24] Train loss=0.22750242054462433
[20/24] Train loss=0.21883255243301392
Test set avg_accuracy=87.92% avg_sensitivity=69.57%, avg_specificity=94.38% avg_auc=92.50%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.230015 Test loss=0.297205 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.21234215795993805
[5/24] Train loss=0.20606043934822083
[10/24] Train loss=0.26284417510032654
[15/24] Train loss=0.22194163501262665
[20/24] Train loss=0.22248050570487976
Test set avg_accuracy=87.36% avg_sensitivity=71.46%, avg_specificity=92.96% avg_auc=91.31%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.224706 Test loss=0.313903 Current lr=[0.00029967723776099]

[0/24] Train loss=0.21946120262145996
[5/24] Train loss=0.19511353969573975
[10/24] Train loss=0.26895561814308167
[15/24] Train loss=0.21715061366558075
[20/24] Train loss=0.21670180559158325
Test set avg_accuracy=87.86% avg_sensitivity=67.32%, avg_specificity=95.10% avg_auc=91.14%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.222129 Test loss=0.312495 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.21883365511894226
[5/24] Train loss=0.20656099915504456
[10/24] Train loss=0.27286621928215027
[15/24] Train loss=0.2213526964187622
[20/24] Train loss=0.2162346988916397
Test set avg_accuracy=86.58% avg_sensitivity=79.61%, avg_specificity=89.03% avg_auc=92.41%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.225006 Test loss=0.323360 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.21514222025871277
[5/24] Train loss=0.20182040333747864
[10/24] Train loss=0.25364652276039124
[15/24] Train loss=0.21552413702011108
[20/24] Train loss=0.21359002590179443
Test set avg_accuracy=85.98% avg_sensitivity=59.97%, avg_specificity=95.14% avg_auc=89.93%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.220828 Test loss=0.340926 Current lr=[0.000299720220882401]

[0/24] Train loss=0.21150599420070648
[5/24] Train loss=0.1875729113817215
[10/24] Train loss=0.2573243975639343
[15/24] Train loss=0.22572709619998932
[20/24] Train loss=0.21678577363491058
Test set avg_accuracy=83.42% avg_sensitivity=42.33%, avg_specificity=97.90% avg_auc=87.82%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.217657 Test loss=0.412415 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2159096896648407
[5/24] Train loss=0.20186905562877655
[10/24] Train loss=0.2622983455657959
[15/24] Train loss=0.21806460618972778
[20/24] Train loss=0.22009219229221344
Test set avg_accuracy=82.83% avg_sensitivity=81.21%, avg_specificity=83.39% avg_auc=90.02%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.219098 Test loss=0.380247 Current lr=[0.000298904600941902]

[0/24] Train loss=0.21815723180770874
[5/24] Train loss=0.19551527500152588
[10/24] Train loss=0.2549963891506195
[15/24] Train loss=0.22168324887752533
[20/24] Train loss=0.2247614860534668
Test set avg_accuracy=85.64% avg_sensitivity=76.26%, avg_specificity=88.94% avg_auc=91.45%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.220054 Test loss=0.332416 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2123960256576538
[5/24] Train loss=0.19774991273880005
[10/24] Train loss=0.24323992431163788
[15/24] Train loss=0.21349340677261353
[20/24] Train loss=0.21274055540561676
Test set avg_accuracy=85.38% avg_sensitivity=79.16%, avg_specificity=87.57% avg_auc=92.11%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.215767 Test loss=0.332106 Current lr=[0.000297555943323901]

[0/24] Train loss=0.21160845458507538
[5/24] Train loss=0.1860496550798416
[10/24] Train loss=0.2549702525138855
[15/24] Train loss=0.2296568602323532
[20/24] Train loss=0.21763896942138672
Test set avg_accuracy=82.47% avg_sensitivity=87.01%, avg_specificity=80.88% avg_auc=91.64%
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.213324 Test loss=0.392336 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.21017181873321533
[5/24] Train loss=0.1780826449394226
[10/24] Train loss=0.25075048208236694
[15/24] Train loss=0.22607435286045074
[20/24] Train loss=0.2015637755393982
Test set avg_accuracy=87.23% avg_sensitivity=71.46%, avg_specificity=92.78% avg_auc=91.38%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.211364 Test loss=0.316208 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.21273718774318695
[5/24] Train loss=0.20543614029884338
[10/24] Train loss=0.24278117716312408
[15/24] Train loss=0.2258007824420929
[20/24] Train loss=0.21298059821128845
Test set avg_accuracy=83.82% avg_sensitivity=79.66%, avg_specificity=85.28% avg_auc=90.83%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.213243 Test loss=0.362723 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.21589429676532745
[5/24] Train loss=0.17217953503131866
[10/24] Train loss=0.25120359659194946
[15/24] Train loss=0.21861408650875092
[20/24] Train loss=0.21591529250144958
Test set avg_accuracy=85.01% avg_sensitivity=73.06%, avg_specificity=89.22% avg_auc=89.90%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.212996 Test loss=0.351155 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.20296292006969452
[5/24] Train loss=0.17233343422412872
[10/24] Train loss=0.23360717296600342
[15/24] Train loss=0.22672125697135925
[20/24] Train loss=0.21495375037193298
Test set avg_accuracy=86.82% avg_sensitivity=61.92%, avg_specificity=95.60% avg_auc=90.43%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.212458 Test loss=0.326284 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.21670320630073547
[5/24] Train loss=0.18554942309856415
[10/24] Train loss=0.24165943264961243
[15/24] Train loss=0.22289696335792542
[20/24] Train loss=0.2120475023984909
Test set avg_accuracy=77.45% avg_sensitivity=87.56%, avg_specificity=73.89% avg_auc=89.71%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.214460 Test loss=0.469482 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.20773327350616455
[5/24] Train loss=0.1741025447845459
[10/24] Train loss=0.2214217334985733
[15/24] Train loss=0.20057997107505798
[20/24] Train loss=0.20467938482761383
Test set avg_accuracy=81.94% avg_sensitivity=82.21%, avg_specificity=81.85% avg_auc=90.11%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.205798 Test loss=0.396368 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.20381316542625427
[5/24] Train loss=0.18789061903953552
[10/24] Train loss=0.25216594338417053
[15/24] Train loss=0.20642618834972382
[20/24] Train loss=0.21545912325382233
Test set avg_accuracy=87.30% avg_sensitivity=70.91%, avg_specificity=93.08% avg_auc=92.09%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.207148 Test loss=0.307673 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.20336373150348663
[5/24] Train loss=0.17527002096176147
[10/24] Train loss=0.22444166243076324
[15/24] Train loss=0.2052941769361496
[20/24] Train loss=0.20647822320461273
Test set avg_accuracy=86.47% avg_sensitivity=76.56%, avg_specificity=89.96% avg_auc=91.80%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.201517 Test loss=0.320099 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.19991843402385712
[5/24] Train loss=0.18651212751865387
[10/24] Train loss=0.22208139300346375
[15/24] Train loss=0.20251873135566711
[20/24] Train loss=0.21591788530349731
Test set avg_accuracy=87.23% avg_sensitivity=79.41%, avg_specificity=89.98% avg_auc=92.35%
Best model saved!! Metric=22.967751247059823!!
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.203860 Test loss=0.314134 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.20908653736114502
[5/24] Train loss=0.17901986837387085
[10/24] Train loss=0.2191614806652069
[15/24] Train loss=0.21267272531986237
[20/24] Train loss=0.19836759567260742
Test set avg_accuracy=86.84% avg_sensitivity=70.16%, avg_specificity=92.71% avg_auc=91.40%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.205814 Test loss=0.315776 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.21629278361797333
[5/24] Train loss=0.18194405734539032
[10/24] Train loss=0.2310153990983963
[15/24] Train loss=0.20600536465644836
[20/24] Train loss=0.2016696035861969
Test set avg_accuracy=87.15% avg_sensitivity=79.71%, avg_specificity=89.77% avg_auc=92.67%
Best model saved!! Metric=23.29743871694744!!
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.202566 Test loss=0.310479 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.19913862645626068
[5/24] Train loss=0.1825084090232849
[10/24] Train loss=0.22882266342639923
[15/24] Train loss=0.20361702144145966
[20/24] Train loss=0.20269572734832764
Test set avg_accuracy=87.15% avg_sensitivity=74.11%, avg_specificity=91.74% avg_auc=92.29%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.202622 Test loss=0.311469 Current lr=[0.000276307469034998]

[0/24] Train loss=0.19231261312961578
[5/24] Train loss=0.1731768101453781
[10/24] Train loss=0.2277262806892395
[15/24] Train loss=0.20620647072792053
[20/24] Train loss=0.20269817113876343
Test set avg_accuracy=84.77% avg_sensitivity=51.82%, avg_specificity=96.37% avg_auc=89.92%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.199759 Test loss=0.372383 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.19459879398345947
[5/24] Train loss=0.1652754247188568
[10/24] Train loss=0.22369696199893951
[15/24] Train loss=0.19604960083961487
[20/24] Train loss=0.197584867477417
Test set avg_accuracy=86.91% avg_sensitivity=74.01%, avg_specificity=91.46% avg_auc=90.60%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.196365 Test loss=0.330220 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.20850351452827454
[5/24] Train loss=0.16641341149806976
[10/24] Train loss=0.20883561670780182
[15/24] Train loss=0.1947941929101944
[20/24] Train loss=0.2099788784980774
Test set avg_accuracy=82.99% avg_sensitivity=78.56%, avg_specificity=84.56% avg_auc=89.62%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.200171 Test loss=0.387693 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.20865599811077118
[5/24] Train loss=0.16767150163650513
[10/24] Train loss=0.22037672996520996
[15/24] Train loss=0.2112961858510971
[20/24] Train loss=0.19981521368026733
Test set avg_accuracy=82.73% avg_sensitivity=83.71%, avg_specificity=82.39% avg_auc=91.07%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.200240 Test loss=0.382373 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2021048367023468
[5/24] Train loss=0.17573782801628113
[10/24] Train loss=0.2549208104610443
[15/24] Train loss=0.20184998214244843
[20/24] Train loss=0.20016369223594666
Test set avg_accuracy=87.16% avg_sensitivity=75.91%, avg_specificity=91.13% avg_auc=92.25%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.200336 Test loss=0.308800 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.19499926269054413
[5/24] Train loss=0.1601298749446869
[10/24] Train loss=0.21439898014068604
[15/24] Train loss=0.20529143512248993
[20/24] Train loss=0.19250886142253876
Test set avg_accuracy=86.13% avg_sensitivity=65.57%, avg_specificity=93.38% avg_auc=90.63%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.192599 Test loss=0.331823 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.19481392204761505
[5/24] Train loss=0.15985961258411407
[10/24] Train loss=0.22452159225940704
[15/24] Train loss=0.1946052610874176
[20/24] Train loss=0.1906905323266983
Test set avg_accuracy=87.42% avg_sensitivity=71.81%, avg_specificity=92.92% avg_auc=91.16%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.194472 Test loss=0.316368 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.1878998577594757
[5/24] Train loss=0.1698964387178421
[10/24] Train loss=0.211556538939476
[15/24] Train loss=0.19382385909557343
[20/24] Train loss=0.19018836319446564
Test set avg_accuracy=83.88% avg_sensitivity=45.48%, avg_specificity=97.41% avg_auc=85.60%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.189079 Test loss=0.449525 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.19817450642585754
[5/24] Train loss=0.15967108309268951
[10/24] Train loss=0.213833749294281
[15/24] Train loss=0.1979028433561325
[20/24] Train loss=0.1840866357088089
Test set avg_accuracy=86.73% avg_sensitivity=70.86%, avg_specificity=92.32% avg_auc=90.66%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.189367 Test loss=0.335261 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1798618733882904
[5/24] Train loss=0.1584794968366623
[10/24] Train loss=0.2102261632680893
[15/24] Train loss=0.2012396901845932
[20/24] Train loss=0.19358544051647186
Test set avg_accuracy=86.25% avg_sensitivity=59.97%, avg_specificity=95.51% avg_auc=89.63%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.189373 Test loss=0.352490 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.18157711625099182
[5/24] Train loss=0.16876262426376343
[10/24] Train loss=0.21688799560070038
[15/24] Train loss=0.1954880654811859
[20/24] Train loss=0.18707449734210968
Test set avg_accuracy=87.08% avg_sensitivity=63.12%, avg_specificity=95.53% avg_auc=90.04%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.188010 Test loss=0.330383 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.18469582498073578
[5/24] Train loss=0.1612398326396942
[10/24] Train loss=0.20372602343559265
[15/24] Train loss=0.18602445721626282
[20/24] Train loss=0.18825663626194
Test set avg_accuracy=86.80% avg_sensitivity=73.26%, avg_specificity=91.57% avg_auc=91.31%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.184318 Test loss=0.323189 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.18209029734134674
[5/24] Train loss=0.1527828872203827
[10/24] Train loss=0.20066092908382416
[15/24] Train loss=0.18723444640636444
[20/24] Train loss=0.18227902054786682
Test set avg_accuracy=86.13% avg_sensitivity=66.67%, avg_specificity=92.99% avg_auc=89.80%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.186786 Test loss=0.342876 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.1850130409002304
[5/24] Train loss=0.16126087307929993
[10/24] Train loss=0.19793157279491425
[15/24] Train loss=0.19250313937664032
[20/24] Train loss=0.18718662858009338
Test set avg_accuracy=86.90% avg_sensitivity=71.61%, avg_specificity=92.29% avg_auc=91.30%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.182029 Test loss=0.318292 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.17847402393817902
[5/24] Train loss=0.15485112369060516
[10/24] Train loss=0.20574094355106354
[15/24] Train loss=0.189924955368042
[20/24] Train loss=0.18634764850139618
Test set avg_accuracy=85.26% avg_sensitivity=54.22%, avg_specificity=96.20% avg_auc=86.95%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.180335 Test loss=0.396600 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17060381174087524
[5/24] Train loss=0.14706027507781982
[10/24] Train loss=0.21458058059215546
[15/24] Train loss=0.19558735191822052
[20/24] Train loss=0.18985071778297424
Test set avg_accuracy=86.68% avg_sensitivity=63.92%, avg_specificity=94.70% avg_auc=89.37%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.183062 Test loss=0.353940 Current lr=[0.000224838296036774]

[0/24] Train loss=0.18560126423835754
[5/24] Train loss=0.1570696234703064
[10/24] Train loss=0.19817951321601868
[15/24] Train loss=0.19355759024620056
[20/24] Train loss=0.1899542212486267
Test set avg_accuracy=87.47% avg_sensitivity=75.61%, avg_specificity=91.65% avg_auc=91.55%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.182630 Test loss=0.320111 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.1754792034626007
[5/24] Train loss=0.15681375563144684
[10/24] Train loss=0.20602567493915558
[15/24] Train loss=0.19061090052127838
[20/24] Train loss=0.19206683337688446
Test set avg_accuracy=82.63% avg_sensitivity=43.88%, avg_specificity=96.28% avg_auc=84.79%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.185822 Test loss=0.452670 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.17752991616725922
[5/24] Train loss=0.1585577428340912
[10/24] Train loss=0.202420175075531
[15/24] Train loss=0.18894062936306
[20/24] Train loss=0.19929766654968262
Test set avg_accuracy=86.88% avg_sensitivity=70.01%, avg_specificity=92.82% avg_auc=90.56%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.183321 Test loss=0.326706 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.18256153166294098
[5/24] Train loss=0.15549026429653168
[10/24] Train loss=0.21162597835063934
[15/24] Train loss=0.1945854276418686
[20/24] Train loss=0.18056818842887878
Test set avg_accuracy=87.20% avg_sensitivity=73.76%, avg_specificity=91.94% avg_auc=91.58%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.181394 Test loss=0.316715 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.17933408915996552
[5/24] Train loss=0.152680441737175
[10/24] Train loss=0.20219336450099945
[15/24] Train loss=0.1855156421661377
[20/24] Train loss=0.1944383829832077
Test set avg_accuracy=83.88% avg_sensitivity=48.08%, avg_specificity=96.50% avg_auc=84.28%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.181203 Test loss=0.435444 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.18133237957954407
[5/24] Train loss=0.17391350865364075
[10/24] Train loss=0.20875565707683563
[15/24] Train loss=0.1882038116455078
[20/24] Train loss=0.1895640790462494
Test set avg_accuracy=85.20% avg_sensitivity=56.57%, avg_specificity=95.28% avg_auc=87.59%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.188312 Test loss=0.391479 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.181692972779274
[5/24] Train loss=0.16024260222911835
[10/24] Train loss=0.21961495280265808
[15/24] Train loss=0.1867453157901764
[20/24] Train loss=0.18743427097797394
Test set avg_accuracy=83.16% avg_sensitivity=80.51%, avg_specificity=84.10% avg_auc=89.96%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.182080 Test loss=0.398316 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.17824925482273102
[5/24] Train loss=0.15286415815353394
[10/24] Train loss=0.18709896504878998
[15/24] Train loss=0.18481245636940002
[20/24] Train loss=0.17739227414131165
Test set avg_accuracy=87.11% avg_sensitivity=76.61%, avg_specificity=90.81% avg_auc=91.42%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.175792 Test loss=0.323165 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1750640869140625
[5/24] Train loss=0.14580877125263214
[10/24] Train loss=0.19054274260997772
[15/24] Train loss=0.18550944328308105
[20/24] Train loss=0.17829757928848267
Test set avg_accuracy=85.96% avg_sensitivity=78.56%, avg_specificity=88.57% avg_auc=91.22%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.174888 Test loss=0.340044 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.17374257743358612
[5/24] Train loss=0.15496394038200378
[10/24] Train loss=0.19356769323349
[15/24] Train loss=0.18060602247714996
[20/24] Train loss=0.17769186198711395
Test set avg_accuracy=85.89% avg_sensitivity=77.56%, avg_specificity=88.82% avg_auc=91.10%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.174442 Test loss=0.343119 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.16549856960773468
[5/24] Train loss=0.15393312275409698
[10/24] Train loss=0.20048238337039948
[15/24] Train loss=0.18233780562877655
[20/24] Train loss=0.175129234790802
Test set avg_accuracy=86.61% avg_sensitivity=74.41%, avg_specificity=90.91% avg_auc=91.00%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.177268 Test loss=0.329702 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.17560890316963196
[5/24] Train loss=0.14688269793987274
[10/24] Train loss=0.19352389872074127
[15/24] Train loss=0.18298348784446716
[20/24] Train loss=0.1812959611415863
Test set avg_accuracy=86.97% avg_sensitivity=66.57%, avg_specificity=94.15% avg_auc=89.29%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.175128 Test loss=0.346580 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.17304694652557373
[5/24] Train loss=0.16005252301692963
[10/24] Train loss=0.20518456399440765
[15/24] Train loss=0.18182896077632904
[20/24] Train loss=0.1775582730770111
Test set avg_accuracy=86.82% avg_sensitivity=76.86%, avg_specificity=90.33% avg_auc=91.36%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.176747 Test loss=0.326363 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.16804775595664978
[5/24] Train loss=0.14782468974590302
[10/24] Train loss=0.18653908371925354
[15/24] Train loss=0.17849929630756378
[20/24] Train loss=0.17063981294631958
Test set avg_accuracy=83.48% avg_sensitivity=77.71%, avg_specificity=85.51% avg_auc=90.02%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.173033 Test loss=0.381997 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1718032956123352
[5/24] Train loss=0.14641200006008148
[10/24] Train loss=0.18980075418949127
[15/24] Train loss=0.17307698726654053
[20/24] Train loss=0.17103345692157745
Test set avg_accuracy=87.21% avg_sensitivity=73.91%, avg_specificity=91.90% avg_auc=91.21%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.175190 Test loss=0.319776 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.16811667382717133
[5/24] Train loss=0.14624466001987457
[10/24] Train loss=0.19076645374298096
[15/24] Train loss=0.1702231466770172
[20/24] Train loss=0.1767609417438507
Test set avg_accuracy=86.03% avg_sensitivity=78.01%, avg_specificity=88.85% avg_auc=91.00%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.171562 Test loss=0.340681 Current lr=[0.000156543481933168]

[0/24] Train loss=0.16448600590229034
[5/24] Train loss=0.14646679162979126
[10/24] Train loss=0.18657004833221436
[15/24] Train loss=0.17162086069583893
[20/24] Train loss=0.16912858188152313
Test set avg_accuracy=86.25% avg_sensitivity=82.76%, avg_specificity=87.48% avg_auc=91.72%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.169359 Test loss=0.338296 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1653701663017273
[5/24] Train loss=0.14223967492580414
[10/24] Train loss=0.18965069949626923
[15/24] Train loss=0.16702605783939362
[20/24] Train loss=0.17477096617221832
Test set avg_accuracy=87.43% avg_sensitivity=73.81%, avg_specificity=92.23% avg_auc=90.95%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.169634 Test loss=0.321503 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15823890268802643
[5/24] Train loss=0.149180606007576
[10/24] Train loss=0.18854622542858124
[15/24] Train loss=0.17524608969688416
[20/24] Train loss=0.16467957198619843
Test set avg_accuracy=87.37% avg_sensitivity=65.92%, avg_specificity=94.93% avg_auc=90.53%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.167192 Test loss=0.333404 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15217365324497223
[5/24] Train loss=0.14547844231128693
[10/24] Train loss=0.19088387489318848
[15/24] Train loss=0.17356562614440918
[20/24] Train loss=0.16574546694755554
Test set avg_accuracy=87.29% avg_sensitivity=67.27%, avg_specificity=94.35% avg_auc=89.48%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.164623 Test loss=0.333926 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.16095760464668274
[5/24] Train loss=0.15164124965667725
[10/24] Train loss=0.18334640562534332
[15/24] Train loss=0.1735927313566208
[20/24] Train loss=0.1648983657360077
Test set avg_accuracy=86.54% avg_sensitivity=67.87%, avg_specificity=93.11% avg_auc=90.52%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.166111 Test loss=0.334873 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15844692289829254
[5/24] Train loss=0.14236359298229218
[10/24] Train loss=0.17769566178321838
[15/24] Train loss=0.17623789608478546
[20/24] Train loss=0.1685435026884079
Test set avg_accuracy=86.25% avg_sensitivity=58.37%, avg_specificity=96.07% avg_auc=87.66%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.165275 Test loss=0.376077 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.157511368393898
[5/24] Train loss=0.14285491406917572
[10/24] Train loss=0.17563217878341675
[15/24] Train loss=0.16476395726203918
[20/24] Train loss=0.16894803941249847
Test set avg_accuracy=87.73% avg_sensitivity=70.21%, avg_specificity=93.91% avg_auc=91.30%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.165646 Test loss=0.315463 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.159706249833107
[5/24] Train loss=0.13783764839172363
[10/24] Train loss=0.17403246462345123
[15/24] Train loss=0.17085184156894684
[20/24] Train loss=0.1690746694803238
Test set avg_accuracy=85.42% avg_sensitivity=53.97%, avg_specificity=96.50% avg_auc=87.84%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.165291 Test loss=0.381732 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15388701856136322
[5/24] Train loss=0.14063745737075806
[10/24] Train loss=0.171791210770607
[15/24] Train loss=0.17755763232707977
[20/24] Train loss=0.1662524938583374
Test set avg_accuracy=82.72% avg_sensitivity=73.01%, avg_specificity=86.14% avg_auc=87.65%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.163189 Test loss=0.398374 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1586741805076599
[5/24] Train loss=0.14811564981937408
[10/24] Train loss=0.17523561418056488
[15/24] Train loss=0.16432829201221466
[20/24] Train loss=0.1640390306711197
Test set avg_accuracy=87.11% avg_sensitivity=64.62%, avg_specificity=95.03% avg_auc=89.81%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.163675 Test loss=0.346445 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15340980887413025
[5/24] Train loss=0.14671358466148376
[10/24] Train loss=0.17573602497577667
[15/24] Train loss=0.16632786393165588
[20/24] Train loss=0.16576729714870453
Test set avg_accuracy=87.70% avg_sensitivity=68.52%, avg_specificity=94.45% avg_auc=90.89%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.161536 Test loss=0.326648 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15235596895217896
[5/24] Train loss=0.1412079930305481
[10/24] Train loss=0.16825750470161438
[15/24] Train loss=0.17034992575645447
[20/24] Train loss=0.1606084555387497
Test set avg_accuracy=87.14% avg_sensitivity=70.66%, avg_specificity=92.94% avg_auc=91.06%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.159316 Test loss=0.323123 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15392032265663147
[5/24] Train loss=0.13906802237033844
[10/24] Train loss=0.17162510752677917
[15/24] Train loss=0.15988276898860931
[20/24] Train loss=0.1619470715522766
Test set avg_accuracy=87.29% avg_sensitivity=72.56%, avg_specificity=92.48% avg_auc=90.73%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.159465 Test loss=0.323451 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1513541340827942
[5/24] Train loss=0.13888078927993774
[10/24] Train loss=0.17508621513843536
[15/24] Train loss=0.16784144937992096
[20/24] Train loss=0.15662769973278046
Test set avg_accuracy=86.07% avg_sensitivity=57.42%, avg_specificity=96.16% avg_auc=87.42%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.157013 Test loss=0.391216 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15236125886440277
[5/24] Train loss=0.13596370816230774
[10/24] Train loss=0.1699811965227127
[15/24] Train loss=0.1634448915719986
[20/24] Train loss=0.1572936773300171
Test set avg_accuracy=86.61% avg_sensitivity=63.67%, avg_specificity=94.70% avg_auc=89.69%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.154807 Test loss=0.342546 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.14660683274269104
[5/24] Train loss=0.1366882026195526
[10/24] Train loss=0.16891935467720032
[15/24] Train loss=0.16289564967155457
[20/24] Train loss=0.15220820903778076
Test set avg_accuracy=87.53% avg_sensitivity=69.02%, avg_specificity=94.05% avg_auc=90.38%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.152551 Test loss=0.329222 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1420370489358902
[5/24] Train loss=0.13641272485256195
[10/24] Train loss=0.1742630898952484
[15/24] Train loss=0.1601496785879135
[20/24] Train loss=0.15767721831798553
Test set avg_accuracy=88.02% avg_sensitivity=69.97%, avg_specificity=94.38% avg_auc=90.90%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.151221 Test loss=0.320636 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14291395246982574
[5/24] Train loss=0.12962214648723602
[10/24] Train loss=0.16558517515659332
[15/24] Train loss=0.15240365266799927
[20/24] Train loss=0.1531262993812561
Test set avg_accuracy=87.92% avg_sensitivity=73.06%, avg_specificity=93.15% avg_auc=91.34%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.149224 Test loss=0.315587 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13852673768997192
[5/24] Train loss=0.12882626056671143
[10/24] Train loss=0.16122230887413025
[15/24] Train loss=0.15217965841293335
[20/24] Train loss=0.1493704915046692
Test set avg_accuracy=86.86% avg_sensitivity=67.02%, avg_specificity=93.85% avg_auc=89.91%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.146855 Test loss=0.340374 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14276711642742157
[5/24] Train loss=0.1265232414007187
[10/24] Train loss=0.16133980453014374
[15/24] Train loss=0.15339429676532745
[20/24] Train loss=0.14775221049785614
Test set avg_accuracy=87.46% avg_sensitivity=73.51%, avg_specificity=92.38% avg_auc=90.68%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.146228 Test loss=0.327983 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13841195404529572
[5/24] Train loss=0.12763099372386932
[10/24] Train loss=0.15700791776180267
[15/24] Train loss=0.1574074774980545
[20/24] Train loss=0.1495913863182068
Test set avg_accuracy=87.49% avg_sensitivity=75.26%, avg_specificity=91.79% avg_auc=91.64%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.144875 Test loss=0.315768 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1370241940021515
[5/24] Train loss=0.12826652824878693
[10/24] Train loss=0.16395677626132965
[15/24] Train loss=0.15392079949378967
[20/24] Train loss=0.14728803932666779
Test set avg_accuracy=87.27% avg_sensitivity=70.21%, avg_specificity=93.27% avg_auc=90.69%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.145260 Test loss=0.323920 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1377970427274704
[5/24] Train loss=0.12967295944690704
[10/24] Train loss=0.1569046676158905
[15/24] Train loss=0.15040592849254608
[20/24] Train loss=0.1474819928407669
Test set avg_accuracy=87.06% avg_sensitivity=77.06%, avg_specificity=90.58% avg_auc=91.55%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.144638 Test loss=0.323622 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13738688826560974
[5/24] Train loss=0.12642139196395874
[10/24] Train loss=0.1610669493675232
[15/24] Train loss=0.1511967033147812
[20/24] Train loss=0.14341165125370026
Test set avg_accuracy=86.37% avg_sensitivity=66.07%, avg_specificity=93.52% avg_auc=88.95%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.143398 Test loss=0.352444 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13122542202472687
[5/24] Train loss=0.13043174147605896
[10/24] Train loss=0.15291453897953033
[15/24] Train loss=0.15438681840896606
[20/24] Train loss=0.14965079724788666
Test set avg_accuracy=87.37% avg_sensitivity=76.56%, avg_specificity=91.18% avg_auc=91.05%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.143501 Test loss=0.325770 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1304742693901062
[5/24] Train loss=0.12566512823104858
[10/24] Train loss=0.1558896005153656
[15/24] Train loss=0.14968957006931305
[20/24] Train loss=0.1450670212507248
Test set avg_accuracy=87.16% avg_sensitivity=75.31%, avg_specificity=91.34% avg_auc=90.99%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.141622 Test loss=0.328641 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13110952079296112
[5/24] Train loss=0.1236911490559578
[10/24] Train loss=0.1540694683790207
[15/24] Train loss=0.14908134937286377
[20/24] Train loss=0.14365151524543762
Test set avg_accuracy=87.53% avg_sensitivity=75.66%, avg_specificity=91.71% avg_auc=91.23%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.140741 Test loss=0.322436 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13162530958652496
[5/24] Train loss=0.12221156060695648
[10/24] Train loss=0.1514541655778885
[15/24] Train loss=0.142992302775383
[20/24] Train loss=0.1417132169008255
Test set avg_accuracy=86.42% avg_sensitivity=69.62%, avg_specificity=92.34% avg_auc=89.77%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.139002 Test loss=0.338771 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13121628761291504
[5/24] Train loss=0.12407586723566055
[10/24] Train loss=0.15660934150218964
[15/24] Train loss=0.14661778509616852
[20/24] Train loss=0.13895170390605927
Test set avg_accuracy=86.90% avg_sensitivity=75.16%, avg_specificity=91.04% avg_auc=90.67%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.139128 Test loss=0.333692 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13249105215072632
[5/24] Train loss=0.12415234744548798
[10/24] Train loss=0.1520543247461319
[15/24] Train loss=0.145577073097229
[20/24] Train loss=0.14485938847064972
Test set avg_accuracy=87.34% avg_sensitivity=72.36%, avg_specificity=92.62% avg_auc=90.24%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.138856 Test loss=0.332665 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13246873021125793
[5/24] Train loss=0.12159563601016998
[10/24] Train loss=0.15292523801326752
[15/24] Train loss=0.13892900943756104
[20/24] Train loss=0.1415848433971405
Test set avg_accuracy=87.19% avg_sensitivity=77.26%, avg_specificity=90.68% avg_auc=91.31%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.137629 Test loss=0.324324 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13311830163002014
[5/24] Train loss=0.12130291014909744
[10/24] Train loss=0.15139926970005035
[15/24] Train loss=0.14233297109603882
[20/24] Train loss=0.13945242762565613
Test set avg_accuracy=87.11% avg_sensitivity=77.01%, avg_specificity=90.67% avg_auc=91.28%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.137530 Test loss=0.325686 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13082905113697052
[5/24] Train loss=0.12054020911455154
[10/24] Train loss=0.14992095530033112
[15/24] Train loss=0.13886204361915588
[20/24] Train loss=0.13740144670009613
Test set avg_accuracy=87.70% avg_sensitivity=76.96%, avg_specificity=91.48% avg_auc=91.34%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.136503 Test loss=0.318701 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12857145071029663
[5/24] Train loss=0.11783743649721146
[10/24] Train loss=0.14639241993427277
[15/24] Train loss=0.14187483489513397
[20/24] Train loss=0.13726460933685303
Test set avg_accuracy=87.36% avg_sensitivity=77.26%, avg_specificity=90.91% avg_auc=91.01%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.134936 Test loss=0.326095 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12720884382724762
[5/24] Train loss=0.12478110939264297
[10/24] Train loss=0.15011586248874664
[15/24] Train loss=0.1440458744764328
[20/24] Train loss=0.1375475972890854
Test set avg_accuracy=87.12% avg_sensitivity=78.86%, avg_specificity=90.03% avg_auc=91.39%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.136115 Test loss=0.327864 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12663157284259796
[5/24] Train loss=0.124176986515522
[10/24] Train loss=0.15000241994857788
[15/24] Train loss=0.1443316787481308
[20/24] Train loss=0.1417492926120758
Test set avg_accuracy=87.17% avg_sensitivity=78.61%, avg_specificity=90.19% avg_auc=91.28%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.136171 Test loss=0.327750 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12568870186805725
[5/24] Train loss=0.12041117995977402
[10/24] Train loss=0.14390739798545837
[15/24] Train loss=0.13958320021629333
[20/24] Train loss=0.13728317618370056
Test set avg_accuracy=87.94% avg_sensitivity=74.96%, avg_specificity=92.52% avg_auc=90.88%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.135064 Test loss=0.320851 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1265881061553955
[5/24] Train loss=0.11930930614471436
[10/24] Train loss=0.14923451840877533
[15/24] Train loss=0.13807614147663116
[20/24] Train loss=0.13793343305587769
Test set avg_accuracy=87.49% avg_sensitivity=77.16%, avg_specificity=91.13% avg_auc=91.13%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.133937 Test loss=0.326094 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12590885162353516
[5/24] Train loss=0.11676912754774094
[10/24] Train loss=0.14444202184677124
[15/24] Train loss=0.1379077434539795
[20/24] Train loss=0.1346336305141449
Test set avg_accuracy=87.92% avg_sensitivity=76.36%, avg_specificity=91.99% avg_auc=91.16%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.132400 Test loss=0.321975 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12414317578077316
[5/24] Train loss=0.11612897366285324
[10/24] Train loss=0.14540107548236847
[15/24] Train loss=0.13749513030052185
[20/24] Train loss=0.1358339786529541
Test set avg_accuracy=87.76% avg_sensitivity=76.96%, avg_specificity=91.57% avg_auc=91.13%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.132360 Test loss=0.324295 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12689143419265747
[5/24] Train loss=0.11759182065725327
[10/24] Train loss=0.14257071912288666
[15/24] Train loss=0.13487069308757782
[20/24] Train loss=0.133224755525589
Test set avg_accuracy=87.60% avg_sensitivity=76.06%, avg_specificity=91.67% avg_auc=91.09%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.130941 Test loss=0.323994 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12311366945505142
[5/24] Train loss=0.11676014959812164
[10/24] Train loss=0.14394280314445496
[15/24] Train loss=0.13807789981365204
[20/24] Train loss=0.13415220379829407
Test set avg_accuracy=87.83% avg_sensitivity=76.61%, avg_specificity=91.78% avg_auc=91.18%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.130486 Test loss=0.322634 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12398214638233185
[5/24] Train loss=0.11540764570236206
[10/24] Train loss=0.1433987021446228
[15/24] Train loss=0.1392301619052887
[20/24] Train loss=0.1354891061782837
Test set avg_accuracy=87.86% avg_sensitivity=75.66%, avg_specificity=92.16% avg_auc=91.11%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.130294 Test loss=0.321339 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12485247105360031
[5/24] Train loss=0.11454235017299652
[10/24] Train loss=0.14061158895492554
[15/24] Train loss=0.13333575427532196
[20/24] Train loss=0.1346217393875122
Test set avg_accuracy=87.75% avg_sensitivity=76.31%, avg_specificity=91.78% avg_auc=91.16%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.129606 Test loss=0.322552 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12558026611804962
[5/24] Train loss=0.11520306020975113
[10/24] Train loss=0.14072774350643158
[15/24] Train loss=0.13505809009075165
[20/24] Train loss=0.13330040872097015
Test set avg_accuracy=87.63% avg_sensitivity=77.01%, avg_specificity=91.37% avg_auc=91.10%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.129488 Test loss=0.324701 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12284494936466217
[5/24] Train loss=0.11504925787448883
[10/24] Train loss=0.14003382623195648
[15/24] Train loss=0.13604623079299927
[20/24] Train loss=0.13371555507183075
Test set avg_accuracy=87.73% avg_sensitivity=75.96%, avg_specificity=91.88% avg_auc=90.95%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.129497 Test loss=0.323825 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12324998527765274
[5/24] Train loss=0.11563295871019363
[10/24] Train loss=0.14029818773269653
[15/24] Train loss=0.13197414577007294
[20/24] Train loss=0.130963534116745
Test set avg_accuracy=87.66% avg_sensitivity=76.11%, avg_specificity=91.72% avg_auc=90.90%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.129236 Test loss=0.325850 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12381423264741898
[5/24] Train loss=0.11343564093112946
[10/24] Train loss=0.1398613303899765
[15/24] Train loss=0.13396571576595306
[20/24] Train loss=0.1329946219921112
Test set avg_accuracy=87.54% avg_sensitivity=76.16%, avg_specificity=91.55% avg_auc=91.03%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.128627 Test loss=0.325494 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12221969664096832
[5/24] Train loss=0.11481863260269165
[10/24] Train loss=0.14064715802669525
[15/24] Train loss=0.13137352466583252
[20/24] Train loss=0.1330036222934723
Test set avg_accuracy=87.63% avg_sensitivity=76.56%, avg_specificity=91.53% avg_auc=91.13%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.129082 Test loss=0.323676 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12442317605018616
[5/24] Train loss=0.11445089429616928
[10/24] Train loss=0.14165465533733368
[15/24] Train loss=0.1327025294303894
[20/24] Train loss=0.13389727473258972
Test set avg_accuracy=87.73% avg_sensitivity=76.16%, avg_specificity=91.81% avg_auc=91.06%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.128721 Test loss=0.323123 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12542372941970825
[5/24] Train loss=0.11433485150337219
[10/24] Train loss=0.14146077632904053
[15/24] Train loss=0.13139072060585022
[20/24] Train loss=0.13375242054462433
Test set avg_accuracy=87.75% avg_sensitivity=76.11%, avg_specificity=91.85% avg_auc=91.07%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.128491 Test loss=0.323413 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12153469771146774
[5/24] Train loss=0.11341965198516846
[10/24] Train loss=0.14156383275985718
[15/24] Train loss=0.13309526443481445
[20/24] Train loss=0.1317090541124344
Test set avg_accuracy=87.71% avg_sensitivity=76.26%, avg_specificity=91.74% avg_auc=91.08%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.128695 Test loss=0.323603 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1211007833480835
[5/24] Train loss=0.11589490622282028
[10/24] Train loss=0.14142492413520813
[15/24] Train loss=0.13170453906059265
[20/24] Train loss=0.1359311193227768
Test set avg_accuracy=87.71% avg_sensitivity=76.31%, avg_specificity=91.72% avg_auc=91.07%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.128509 Test loss=0.323621 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12293233722448349
[5/24] Train loss=0.11279042810201645
[10/24] Train loss=0.14338944852352142
[15/24] Train loss=0.13550011813640594
[20/24] Train loss=0.128864586353302
Test set avg_accuracy=87.72% avg_sensitivity=76.31%, avg_specificity=91.74% avg_auc=91.07%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.128319 Test loss=0.323449 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=87.15% sen=79.71%, spe=89.77%, auc=92.67%!
Fold[4] Avg_overlap=0.67%(±0.2420497406771436)
[0/24] Train loss=0.7321744561195374
[5/24] Train loss=0.7209714651107788
[10/24] Train loss=0.7142660617828369
[15/24] Train loss=0.7087742686271667
[20/24] Train loss=0.7085250020027161
Test set avg_accuracy=61.28% avg_sensitivity=43.16%, avg_specificity=67.45% avg_auc=58.91%
Best model saved!! Metric=-95.19596546513533!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.718474 Test loss=0.652725 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.703435480594635
[5/24] Train loss=0.6946086883544922
[10/24] Train loss=0.6929401755332947
[15/24] Train loss=0.6853270530700684
[20/24] Train loss=0.6808570027351379
Test set avg_accuracy=68.67% avg_sensitivity=61.55%, avg_specificity=71.10% avg_auc=72.73%
Best model saved!! Metric=-51.94921940902594!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.691313 Test loss=0.603484 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6752740144729614
[5/24] Train loss=0.6689221858978271
[10/24] Train loss=0.6730656623840332
[15/24] Train loss=0.6570484042167664
[20/24] Train loss=0.6501625776290894
Test set avg_accuracy=71.80% avg_sensitivity=66.97%, avg_specificity=73.44% avg_auc=77.47%
Best model saved!! Metric=-36.31737867088694!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.664469 Test loss=0.567861 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6446892619132996
[5/24] Train loss=0.6361241936683655
[10/24] Train loss=0.6408185362815857
[15/24] Train loss=0.6215518116950989
[20/24] Train loss=0.6090916395187378
Test set avg_accuracy=74.36% avg_sensitivity=72.76%, avg_specificity=74.91% avg_auc=81.26%
Best model saved!! Metric=-22.71133879406068!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.634296 Test loss=0.536930 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6189622282981873
[5/24] Train loss=0.6153378486633301
[10/24] Train loss=0.6177070736885071
[15/24] Train loss=0.5889979600906372
[20/24] Train loss=0.5874049663543701
Test set avg_accuracy=75.79% avg_sensitivity=75.83%, avg_specificity=75.78% avg_auc=83.88%
Best model saved!! Metric=-14.709497708185069!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.606605 Test loss=0.509792 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.587801456451416
[5/24] Train loss=0.5751952528953552
[10/24] Train loss=0.5938185453414917
[15/24] Train loss=0.5588229298591614
[20/24] Train loss=0.555819034576416
Test set avg_accuracy=77.85% avg_sensitivity=76.86%, avg_specificity=78.19% avg_auc=85.44%
Best model saved!! Metric=-7.66368185192627!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.576036 Test loss=0.483192 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5593778491020203
[5/24] Train loss=0.5484322309494019
[10/24] Train loss=0.5666782855987549
[15/24] Train loss=0.5244648456573486
[20/24] Train loss=0.5259509086608887
Test set avg_accuracy=79.39% avg_sensitivity=77.27%, avg_specificity=80.11% avg_auc=86.89%
Best model saved!! Metric=-2.3404117196484577!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.547653 Test loss=0.458984 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5264182090759277
[5/24] Train loss=0.5129771828651428
[10/24] Train loss=0.5367551445960999
[15/24] Train loss=0.494685560464859
[20/24] Train loss=0.4957861304283142
Test set avg_accuracy=80.79% avg_sensitivity=78.55%, avg_specificity=81.56% avg_auc=88.26%
Best model saved!! Metric=3.165082158064152!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.519163 Test loss=0.439758 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5033472180366516
[5/24] Train loss=0.4860195517539978
[10/24] Train loss=0.5052675604820251
[15/24] Train loss=0.46657243371009827
[20/24] Train loss=0.4728235900402069
Test set avg_accuracy=82.14% avg_sensitivity=77.52%, avg_specificity=83.71% avg_auc=89.12%
Best model saved!! Metric=6.480996318250149!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.491099 Test loss=0.418893 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4725070595741272
[5/24] Train loss=0.4575408101081848
[10/24] Train loss=0.48642492294311523
[15/24] Train loss=0.43940168619155884
[20/24] Train loss=0.44645094871520996
Test set avg_accuracy=83.87% avg_sensitivity=76.45%, avg_specificity=86.40% avg_auc=90.10%
Best model saved!! Metric=10.811514508606564!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.465820 Test loss=0.394915 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4473952353000641
[5/24] Train loss=0.43406006693840027
[10/24] Train loss=0.45674392580986023
[15/24] Train loss=0.42041051387786865
[20/24] Train loss=0.423126757144928
Test set avg_accuracy=85.27% avg_sensitivity=76.04%, avg_specificity=88.42% avg_auc=90.86%
Best model saved!! Metric=14.59838608438183!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.441157 Test loss=0.374986 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.42290565371513367
[5/24] Train loss=0.41211727261543274
[10/24] Train loss=0.44447144865989685
[15/24] Train loss=0.39190590381622314
[20/24] Train loss=0.39625129103660583
Test set avg_accuracy=86.35% avg_sensitivity=72.86%, avg_specificity=90.96% avg_auc=91.16%
Best model saved!! Metric=15.332610239037166!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.417498 Test loss=0.355203 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.40335193276405334
[5/24] Train loss=0.38891109824180603
[10/24] Train loss=0.4213295876979828
[15/24] Train loss=0.3699173927307129
[20/24] Train loss=0.3740537464618683
Test set avg_accuracy=86.90% avg_sensitivity=69.07%, avg_specificity=92.98% avg_auc=91.06%
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.394744 Test loss=0.342927 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3797183632850647
[5/24] Train loss=0.36576515436172485
[10/24] Train loss=0.39910465478897095
[15/24] Train loss=0.35160917043685913
[20/24] Train loss=0.3512912392616272
Test set avg_accuracy=87.04% avg_sensitivity=73.27%, avg_specificity=91.74% avg_auc=91.80%
Best model saved!! Metric=17.861910724360754!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.374290 Test loss=0.332948 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.36833715438842773
[5/24] Train loss=0.3421928584575653
[10/24] Train loss=0.38695481419563293
[15/24] Train loss=0.33241111040115356
[20/24] Train loss=0.3381700813770294
Test set avg_accuracy=87.25% avg_sensitivity=72.96%, avg_specificity=92.13% avg_auc=92.16%
Best model saved!! Metric=18.505601552143474!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.359378 Test loss=0.322588 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.34718629717826843
[5/24] Train loss=0.33038631081581116
[10/24] Train loss=0.3735074996948242
[15/24] Train loss=0.32514688372612
[20/24] Train loss=0.31770792603492737
Test set avg_accuracy=87.43% avg_sensitivity=74.24%, avg_specificity=91.93% avg_auc=92.44%
Best model saved!! Metric=20.048217751205883!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.344078 Test loss=0.315985 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3362145721912384
[5/24] Train loss=0.3162963390350342
[10/24] Train loss=0.36530858278274536
[15/24] Train loss=0.30704888701438904
[20/24] Train loss=0.31342849135398865
Test set avg_accuracy=87.79% avg_sensitivity=76.45%, avg_specificity=91.65% avg_auc=92.87%
Best model saved!! Metric=22.75732146036671!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.332586 Test loss=0.309445 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3307410776615143
[5/24] Train loss=0.3059535324573517
[10/24] Train loss=0.35283011198043823
[15/24] Train loss=0.2961960732936859
[20/24] Train loss=0.3063569962978363
Test set avg_accuracy=87.71% avg_sensitivity=75.42%, avg_specificity=91.90% avg_auc=93.03%
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.322961 Test loss=0.301229 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.31634199619293213
[5/24] Train loss=0.2986358404159546
[10/24] Train loss=0.34638407826423645
[15/24] Train loss=0.2899889051914215
[20/24] Train loss=0.2904762923717499
Test set avg_accuracy=87.67% avg_sensitivity=76.29%, avg_specificity=91.55% avg_auc=93.30%
Best model saved!! Metric=22.81445040734745!!
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.313632 Test loss=0.298608 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.30742672085762024
[5/24] Train loss=0.289257675409317
[10/24] Train loss=0.3368069529533386
[15/24] Train loss=0.2798234820365906
[20/24] Train loss=0.27856510877609253
Test set avg_accuracy=87.88% avg_sensitivity=75.52%, avg_specificity=92.09% avg_auc=93.33%
Best model saved!! Metric=22.823142816289533!!
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.305520 Test loss=0.292776 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2946271002292633
[5/24] Train loss=0.2811409533023834
[10/24] Train loss=0.3339577615261078
[15/24] Train loss=0.2741924822330475
[20/24] Train loss=0.2744157910346985
Test set avg_accuracy=87.93% avg_sensitivity=77.27%, avg_specificity=91.57% avg_auc=93.67%
Best model saved!! Metric=24.436496945757398!!
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.299017 Test loss=0.290473 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2874358594417572
[5/24] Train loss=0.27430957555770874
[10/24] Train loss=0.32438015937805176
[15/24] Train loss=0.26314231753349304
[20/24] Train loss=0.271178662776947
Test set avg_accuracy=87.68% avg_sensitivity=78.03%, avg_specificity=90.97% avg_auc=93.74%
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.292128 Test loss=0.292980 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2851768136024475
[5/24] Train loss=0.2727154791355133
[10/24] Train loss=0.32317137718200684
[15/24] Train loss=0.2554270625114441
[20/24] Train loss=0.2694578766822815
Test set avg_accuracy=87.70% avg_sensitivity=78.24%, avg_specificity=90.92% avg_auc=93.86%
Best model saved!! Metric=24.715612046770076!!
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.287336 Test loss=0.288408 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2837642729282379
[5/24] Train loss=0.2621961534023285
[10/24] Train loss=0.3222908079624176
[15/24] Train loss=0.25485384464263916
[20/24] Train loss=0.2561658024787903
Test set avg_accuracy=88.22% avg_sensitivity=72.30%, avg_specificity=93.64% avg_auc=93.57%
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.282956 Test loss=0.279202 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2698730528354645
[5/24] Train loss=0.25175008177757263
[10/24] Train loss=0.3156910240650177
[15/24] Train loss=0.24670515954494476
[20/24] Train loss=0.25328561663627625
Test set avg_accuracy=87.60% avg_sensitivity=78.08%, avg_specificity=90.85% avg_auc=93.63%
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.277614 Test loss=0.291228 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2717714011669159
[5/24] Train loss=0.25170984864234924
[10/24] Train loss=0.3114027678966522
[15/24] Train loss=0.24515175819396973
[20/24] Train loss=0.2491522580385208
Test set avg_accuracy=87.94% avg_sensitivity=73.22%, avg_specificity=92.96% avg_auc=93.65%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.272434 Test loss=0.278972 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2602275609970093
[5/24] Train loss=0.25161710381507874
[10/24] Train loss=0.3066520392894745
[15/24] Train loss=0.23892290890216827
[20/24] Train loss=0.24432821571826935
Test set avg_accuracy=88.03% avg_sensitivity=72.50%, avg_specificity=93.33% avg_auc=93.37%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.267106 Test loss=0.281913 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2630654275417328
[5/24] Train loss=0.2455887347459793
[10/24] Train loss=0.3072987496852875
[15/24] Train loss=0.23575855791568756
[20/24] Train loss=0.2458615005016327
Test set avg_accuracy=88.19% avg_sensitivity=66.72%, avg_specificity=95.51% avg_auc=93.16%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.263504 Test loss=0.286089 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2596151828765869
[5/24] Train loss=0.23553252220153809
[10/24] Train loss=0.30158960819244385
[15/24] Train loss=0.23620302975177765
[20/24] Train loss=0.23842085897922516
Test set avg_accuracy=87.85% avg_sensitivity=70.30%, avg_specificity=93.84% avg_auc=92.79%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.258658 Test loss=0.288257 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2531285285949707
[5/24] Train loss=0.2369820773601532
[10/24] Train loss=0.3003033995628357
[15/24] Train loss=0.22845874726772308
[20/24] Train loss=0.23987847566604614
Test set avg_accuracy=86.50% avg_sensitivity=54.33%, avg_specificity=97.47% avg_auc=91.82%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.259200 Test loss=0.323271 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2636180520057678
[5/24] Train loss=0.22674426436424255
[10/24] Train loss=0.2957911789417267
[15/24] Train loss=0.22859416902065277
[20/24] Train loss=0.23589815199375153
Test set avg_accuracy=86.72% avg_sensitivity=60.62%, avg_specificity=95.62% avg_auc=91.23%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.256560 Test loss=0.319805 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.24803614616394043
[5/24] Train loss=0.23131196200847626
[10/24] Train loss=0.3095809519290924
[15/24] Train loss=0.22701366245746613
[20/24] Train loss=0.23331643640995026
Test set avg_accuracy=87.24% avg_sensitivity=60.88%, avg_specificity=96.23% avg_auc=91.80%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.252280 Test loss=0.313157 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2571277618408203
[5/24] Train loss=0.21747437119483948
[10/24] Train loss=0.28926676511764526
[15/24] Train loss=0.21990065276622772
[20/24] Train loss=0.232489213347435
Test set avg_accuracy=85.78% avg_sensitivity=54.79%, avg_specificity=96.35% avg_auc=90.34%
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.250296 Test loss=0.338825 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.24981464445590973
[5/24] Train loss=0.21459634602069855
[10/24] Train loss=0.28933215141296387
[15/24] Train loss=0.2149335741996765
[20/24] Train loss=0.23050343990325928
Test set avg_accuracy=86.25% avg_sensitivity=54.17%, avg_specificity=97.19% avg_auc=90.29%
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.245783 Test loss=0.342864 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.24750138819217682
[5/24] Train loss=0.20435550808906555
[10/24] Train loss=0.2862427830696106
[15/24] Train loss=0.20876169204711914
[20/24] Train loss=0.22276702523231506
Test set avg_accuracy=85.95% avg_sensitivity=55.20%, avg_specificity=96.44% avg_auc=90.77%
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.240770 Test loss=0.337080 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.24490571022033691
[5/24] Train loss=0.20325008034706116
[10/24] Train loss=0.28372690081596375
[15/24] Train loss=0.2114664614200592
[20/24] Train loss=0.21718254685401917
Test set avg_accuracy=86.50% avg_sensitivity=54.99%, avg_specificity=97.24% avg_auc=90.78%
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.238154 Test loss=0.337970 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.25163549184799194
[5/24] Train loss=0.20741237699985504
[10/24] Train loss=0.2865092158317566
[15/24] Train loss=0.21155871450901031
[20/24] Train loss=0.21356533467769623
Test set avg_accuracy=86.43% avg_sensitivity=59.29%, avg_specificity=95.69% avg_auc=91.23%
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.240695 Test loss=0.323183 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.23119720816612244
[5/24] Train loss=0.21769803762435913
[10/24] Train loss=0.2720719277858734
[15/24] Train loss=0.20553086698055267
[20/24] Train loss=0.22212156653404236
Test set avg_accuracy=87.60% avg_sensitivity=71.74%, avg_specificity=93.02% avg_auc=92.56%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.236585 Test loss=0.291895 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.22912918031215668
[5/24] Train loss=0.21077470481395721
[10/24] Train loss=0.2719951868057251
[15/24] Train loss=0.20285604894161224
[20/24] Train loss=0.22272928059101105
Test set avg_accuracy=86.89% avg_sensitivity=75.37%, avg_specificity=90.82% avg_auc=92.84%
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.233977 Test loss=0.296098 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.23704057931900024
[5/24] Train loss=0.19817829132080078
[10/24] Train loss=0.27293315529823303
[15/24] Train loss=0.20008111000061035
[20/24] Train loss=0.21972310543060303
Test set avg_accuracy=82.88% avg_sensitivity=83.36%, avg_specificity=82.71% avg_auc=91.96%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.231677 Test loss=0.362603 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2208373099565506
[5/24] Train loss=0.19410847127437592
[10/24] Train loss=0.28627797961235046
[15/24] Train loss=0.20381519198417664
[20/24] Train loss=0.20368064939975739
Test set avg_accuracy=86.72% avg_sensitivity=77.16%, avg_specificity=89.98% avg_auc=92.29%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.228863 Test loss=0.305722 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2259703427553177
[5/24] Train loss=0.19906695187091827
[10/24] Train loss=0.2734241485595703
[15/24] Train loss=0.20410721004009247
[20/24] Train loss=0.21590396761894226
Test set avg_accuracy=84.87% avg_sensitivity=63.08%, avg_specificity=92.30% avg_auc=89.23%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.229411 Test loss=0.348647 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2389361560344696
[5/24] Train loss=0.19676972925662994
[10/24] Train loss=0.3001214265823364
[15/24] Train loss=0.20195849239826202
[20/24] Train loss=0.21384651958942413
Test set avg_accuracy=82.71% avg_sensitivity=85.20%, avg_specificity=81.86% avg_auc=92.35%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.233738 Test loss=0.373196 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.21569930016994476
[5/24] Train loss=0.19632016122341156
[10/24] Train loss=0.27153944969177246
[15/24] Train loss=0.19295643270015717
[20/24] Train loss=0.2066255360841751
Test set avg_accuracy=76.56% avg_sensitivity=82.64%, avg_specificity=74.49% avg_auc=87.69%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.224131 Test loss=0.488920 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2192511409521103
[5/24] Train loss=0.17816902697086334
[10/24] Train loss=0.26399630308151245
[15/24] Train loss=0.19357703626155853
[20/24] Train loss=0.20439355075359344
Test set avg_accuracy=86.13% avg_sensitivity=68.92%, avg_specificity=92.00% avg_auc=91.20%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.220434 Test loss=0.319637 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.22796320915222168
[5/24] Train loss=0.20521073043346405
[10/24] Train loss=0.2757512629032135
[15/24] Train loss=0.20055800676345825
[20/24] Train loss=0.2152017056941986
Test set avg_accuracy=86.07% avg_sensitivity=73.58%, avg_specificity=90.33% avg_auc=91.63%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.224282 Test loss=0.320084 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.22006915509700775
[5/24] Train loss=0.1796124428510666
[10/24] Train loss=0.2862056791782379
[15/24] Train loss=0.1939018964767456
[20/24] Train loss=0.2077123373746872
Test set avg_accuracy=85.66% avg_sensitivity=52.64%, avg_specificity=96.93% avg_auc=89.08%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.222303 Test loss=0.371554 Current lr=[0.000299720220882401]

[0/24] Train loss=0.21696962416172028
[5/24] Train loss=0.18506412208080292
[10/24] Train loss=0.262054443359375
[15/24] Train loss=0.20087455213069916
[20/24] Train loss=0.20864607393741608
Test set avg_accuracy=87.58% avg_sensitivity=76.55%, avg_specificity=91.34% avg_auc=93.25%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.220459 Test loss=0.288990 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2174386978149414
[5/24] Train loss=0.18889157474040985
[10/24] Train loss=0.2649598717689514
[15/24] Train loss=0.19710150361061096
[20/24] Train loss=0.19699813425540924
Test set avg_accuracy=87.11% avg_sensitivity=58.47%, avg_specificity=96.87% avg_auc=91.91%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.217663 Test loss=0.320529 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2248578816652298
[5/24] Train loss=0.19289322197437286
[10/24] Train loss=0.25757238268852234
[15/24] Train loss=0.20044384896755219
[20/24] Train loss=0.20435874164104462
Test set avg_accuracy=84.06% avg_sensitivity=45.06%, avg_specificity=97.36% avg_auc=86.64%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.219112 Test loss=0.409332 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.22221918404102325
[5/24] Train loss=0.17976751923561096
[10/24] Train loss=0.26805993914604187
[15/24] Train loss=0.18938113749027252
[20/24] Train loss=0.20815156400203705
Test set avg_accuracy=84.22% avg_sensitivity=77.73%, avg_specificity=86.43% avg_auc=91.12%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.214972 Test loss=0.353374 Current lr=[0.000297555943323901]

[0/24] Train loss=0.21629051864147186
[5/24] Train loss=0.17974886298179626
[10/24] Train loss=0.24491767585277557
[15/24] Train loss=0.1832418292760849
[20/24] Train loss=0.20899561047554016
Test set avg_accuracy=85.78% avg_sensitivity=62.21%, avg_specificity=93.82% avg_auc=91.00%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.211234 Test loss=0.330643 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.22115781903266907
[5/24] Train loss=0.19393697381019592
[10/24] Train loss=0.2500559389591217
[15/24] Train loss=0.19650104641914368
[20/24] Train loss=0.20060577988624573
Test set avg_accuracy=85.25% avg_sensitivity=50.23%, avg_specificity=97.19% avg_auc=89.23%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.217009 Test loss=0.377897 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.22074177861213684
[5/24] Train loss=0.1966821551322937
[10/24] Train loss=0.2545762062072754
[15/24] Train loss=0.18961547315120697
[20/24] Train loss=0.20475547015666962
Test set avg_accuracy=69.36% avg_sensitivity=86.69%, avg_specificity=63.45% avg_auc=84.96%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.216276 Test loss=0.595925 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2552148401737213
[5/24] Train loss=0.18457156419754028
[10/24] Train loss=0.2527364194393158
[15/24] Train loss=0.19591642916202545
[20/24] Train loss=0.2101012021303177
Test set avg_accuracy=87.73% avg_sensitivity=69.18%, avg_specificity=94.06% avg_auc=91.91%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.218733 Test loss=0.297164 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2229149341583252
[5/24] Train loss=0.1939479261636734
[10/24] Train loss=0.2381734400987625
[15/24] Train loss=0.18025963008403778
[20/24] Train loss=0.1997518688440323
Test set avg_accuracy=86.76% avg_sensitivity=77.37%, avg_specificity=89.96% avg_auc=92.75%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.208785 Test loss=0.305299 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.21187050640583038
[5/24] Train loss=0.1875586360692978
[10/24] Train loss=0.23308908939361572
[15/24] Train loss=0.18685175478458405
[20/24] Train loss=0.19751028716564178
Test set avg_accuracy=87.29% avg_sensitivity=64.62%, avg_specificity=95.02% avg_auc=91.58%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.208303 Test loss=0.311373 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.21120314300060272
[5/24] Train loss=0.1893790066242218
[10/24] Train loss=0.23174268007278442
[15/24] Train loss=0.19285358488559723
[20/24] Train loss=0.21263253688812256
Test set avg_accuracy=86.78% avg_sensitivity=72.15%, avg_specificity=91.78% avg_auc=92.24%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.207112 Test loss=0.304468 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.20940907299518585
[5/24] Train loss=0.1867973804473877
[10/24] Train loss=0.2240820974111557
[15/24] Train loss=0.18800102174282074
[20/24] Train loss=0.19834241271018982
Test set avg_accuracy=88.26% avg_sensitivity=71.53%, avg_specificity=93.96% avg_auc=92.85%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.205118 Test loss=0.284444 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.20760391652584076
[5/24] Train loss=0.17301535606384277
[10/24] Train loss=0.22918199002742767
[15/24] Train loss=0.18508991599082947
[20/24] Train loss=0.20171287655830383
Test set avg_accuracy=87.57% avg_sensitivity=65.95%, avg_specificity=94.94% avg_auc=91.45%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.203268 Test loss=0.316226 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2110232710838318
[5/24] Train loss=0.17094257473945618
[10/24] Train loss=0.22491054236888885
[15/24] Train loss=0.1865827590227127
[20/24] Train loss=0.1885339468717575
Test set avg_accuracy=87.49% avg_sensitivity=61.85%, avg_specificity=96.23% avg_auc=91.18%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.201552 Test loss=0.321559 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2075347751379013
[5/24] Train loss=0.18002015352249146
[10/24] Train loss=0.2273726910352707
[15/24] Train loss=0.1803208738565445
[20/24] Train loss=0.19944751262664795
Test set avg_accuracy=85.55% avg_sensitivity=78.08%, avg_specificity=88.09% avg_auc=90.99%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.198545 Test loss=0.341518 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.1997648924589157
[5/24] Train loss=0.17746002972126007
[10/24] Train loss=0.2267007678747177
[15/24] Train loss=0.17779512703418732
[20/24] Train loss=0.18633420765399933
Test set avg_accuracy=85.90% avg_sensitivity=58.93%, avg_specificity=95.09% avg_auc=89.29%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.198042 Test loss=0.345763 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.20590125024318695
[5/24] Train loss=0.16864028573036194
[10/24] Train loss=0.227964386343956
[15/24] Train loss=0.18265938758850098
[20/24] Train loss=0.19148357212543488
Test set avg_accuracy=87.30% avg_sensitivity=67.03%, avg_specificity=94.22% avg_auc=91.70%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.198573 Test loss=0.305799 Current lr=[0.000276307469034998]

[0/24] Train loss=0.19256943464279175
[5/24] Train loss=0.16429243981838226
[10/24] Train loss=0.22052903473377228
[15/24] Train loss=0.19768963754177094
[20/24] Train loss=0.19965742528438568
Test set avg_accuracy=81.41% avg_sensitivity=33.49%, avg_specificity=97.75% avg_auc=82.08%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.198267 Test loss=0.517352 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.20366588234901428
[5/24] Train loss=0.18888020515441895
[10/24] Train loss=0.23683390021324158
[15/24] Train loss=0.19415242969989777
[20/24] Train loss=0.19002096354961395
Test set avg_accuracy=86.69% avg_sensitivity=57.76%, avg_specificity=96.56% avg_auc=89.78%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.204246 Test loss=0.334971 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.19491203129291534
[5/24] Train loss=0.18384352326393127
[10/24] Train loss=0.2419636845588684
[15/24] Train loss=0.17933782935142517
[20/24] Train loss=0.20358532667160034
Test set avg_accuracy=87.07% avg_sensitivity=57.45%, avg_specificity=97.17% avg_auc=89.72%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.204743 Test loss=0.350184 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.21231268346309662
[5/24] Train loss=0.17905741930007935
[10/24] Train loss=0.22549550235271454
[15/24] Train loss=0.17669805884361267
[20/24] Train loss=0.1902354657649994
Test set avg_accuracy=87.92% avg_sensitivity=75.27%, avg_specificity=92.23% avg_auc=92.76%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.196468 Test loss=0.291809 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.19866575300693512
[5/24] Train loss=0.17364287376403809
[10/24] Train loss=0.21629473567008972
[15/24] Train loss=0.18586000800132751
[20/24] Train loss=0.18599247932434082
Test set avg_accuracy=85.23% avg_sensitivity=51.00%, avg_specificity=96.91% avg_auc=86.87%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.193529 Test loss=0.392026 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.21270625293254852
[5/24] Train loss=0.1783243715763092
[10/24] Train loss=0.22102324664592743
[15/24] Train loss=0.18390943109989166
[20/24] Train loss=0.1922062635421753
Test set avg_accuracy=87.23% avg_sensitivity=58.73%, avg_specificity=96.94% avg_auc=90.08%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.195300 Test loss=0.338176 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.19042928516864777
[5/24] Train loss=0.1614152491092682
[10/24] Train loss=0.2184971570968628
[15/24] Train loss=0.1820455938577652
[20/24] Train loss=0.189298614859581
Test set avg_accuracy=85.40% avg_sensitivity=50.69%, avg_specificity=97.24% avg_auc=87.70%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.193249 Test loss=0.388984 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.19852909445762634
[5/24] Train loss=0.16812509298324585
[10/24] Train loss=0.21190670132637024
[15/24] Train loss=0.18883423507213593
[20/24] Train loss=0.18482078611850739
Test set avg_accuracy=86.59% avg_sensitivity=61.03%, avg_specificity=95.30% avg_auc=89.41%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.195273 Test loss=0.336280 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.18662488460540771
[5/24] Train loss=0.1583196520805359
[10/24] Train loss=0.21237246692180634
[15/24] Train loss=0.1717674285173416
[20/24] Train loss=0.1842155009508133
Test set avg_accuracy=82.59% avg_sensitivity=83.26%, avg_specificity=82.36% avg_auc=91.36%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.191962 Test loss=0.382878 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.18953213095664978
[5/24] Train loss=0.1621348261833191
[10/24] Train loss=0.21728506684303284
[15/24] Train loss=0.17451433837413788
[20/24] Train loss=0.182755708694458
Test set avg_accuracy=87.08% avg_sensitivity=64.77%, avg_specificity=94.69% avg_auc=90.78%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.190099 Test loss=0.318985 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.19976596534252167
[5/24] Train loss=0.16015686094760895
[10/24] Train loss=0.21065229177474976
[15/24] Train loss=0.16664709150791168
[20/24] Train loss=0.17621460556983948
Test set avg_accuracy=83.37% avg_sensitivity=78.39%, avg_specificity=85.07% avg_auc=90.01%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.188014 Test loss=0.376811 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.19388890266418457
[5/24] Train loss=0.1676226258277893
[10/24] Train loss=0.21378788352012634
[15/24] Train loss=0.16534537076950073
[20/24] Train loss=0.18221324682235718
Test set avg_accuracy=85.08% avg_sensitivity=74.96%, avg_specificity=88.53% avg_auc=91.18%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.185249 Test loss=0.334652 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.18741917610168457
[5/24] Train loss=0.15782907605171204
[10/24] Train loss=0.20573990046977997
[15/24] Train loss=0.1667788028717041
[20/24] Train loss=0.18179307878017426
Test set avg_accuracy=84.14% avg_sensitivity=46.19%, avg_specificity=97.08% avg_auc=85.81%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.185304 Test loss=0.423753 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.20158399641513824
[5/24] Train loss=0.1621745526790619
[10/24] Train loss=0.20246578752994537
[15/24] Train loss=0.16949671506881714
[20/24] Train loss=0.17596372961997986
Test set avg_accuracy=86.63% avg_sensitivity=60.01%, avg_specificity=95.70% avg_auc=88.88%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.185626 Test loss=0.360419 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.19769619405269623
[5/24] Train loss=0.15831664204597473
[10/24] Train loss=0.21219131350517273
[15/24] Train loss=0.164412260055542
[20/24] Train loss=0.18382304906845093
Test set avg_accuracy=86.78% avg_sensitivity=73.32%, avg_specificity=91.37% avg_auc=91.99%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.184303 Test loss=0.311309 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.18653911352157593
[5/24] Train loss=0.15739034116268158
[10/24] Train loss=0.19977016746997833
[15/24] Train loss=0.16327854990959167
[20/24] Train loss=0.1759275645017624
Test set avg_accuracy=87.80% avg_sensitivity=70.10%, avg_specificity=93.84% avg_auc=91.69%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.181067 Test loss=0.305327 Current lr=[0.000224838296036774]

[0/24] Train loss=0.1841578334569931
[5/24] Train loss=0.15702931582927704
[10/24] Train loss=0.20479588210582733
[15/24] Train loss=0.17146652936935425
[20/24] Train loss=0.18410193920135498
Test set avg_accuracy=86.67% avg_sensitivity=79.62%, avg_specificity=89.07% avg_auc=93.02%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.184839 Test loss=0.305737 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.18728332221508026
[5/24] Train loss=0.16219864785671234
[10/24] Train loss=0.20294345915317535
[15/24] Train loss=0.16574516892433167
[20/24] Train loss=0.17674840986728668
Test set avg_accuracy=86.74% avg_sensitivity=69.48%, avg_specificity=92.63% avg_auc=91.96%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.180010 Test loss=0.309781 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.18232391774654388
[5/24] Train loss=0.15996608138084412
[10/24] Train loss=0.1941242665052414
[15/24] Train loss=0.16500678658485413
[20/24] Train loss=0.17971733212471008
Test set avg_accuracy=87.10% avg_sensitivity=68.71%, avg_specificity=93.36% avg_auc=91.34%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.179398 Test loss=0.311967 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.18602855503559113
[5/24] Train loss=0.1645658016204834
[10/24] Train loss=0.19710642099380493
[15/24] Train loss=0.16496814787387848
[20/24] Train loss=0.17941810190677643
Test set avg_accuracy=83.91% avg_sensitivity=44.24%, avg_specificity=97.43% avg_auc=85.93%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.178043 Test loss=0.426011 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.18665164709091187
[5/24] Train loss=0.1562839299440384
[10/24] Train loss=0.1975695639848709
[15/24] Train loss=0.1706869751214981
[20/24] Train loss=0.18027663230895996
Test set avg_accuracy=87.57% avg_sensitivity=74.09%, avg_specificity=92.16% avg_auc=92.24%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.182570 Test loss=0.299826 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.19639575481414795
[5/24] Train loss=0.15605810284614563
[10/24] Train loss=0.20166783034801483
[15/24] Train loss=0.17157649993896484
[20/24] Train loss=0.19900907576084137
Test set avg_accuracy=87.16% avg_sensitivity=62.93%, avg_specificity=95.43% avg_auc=90.54%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.187761 Test loss=0.322299 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.206432044506073
[5/24] Train loss=0.16394191980361938
[10/24] Train loss=0.19591915607452393
[15/24] Train loss=0.17155198752880096
[20/24] Train loss=0.1842542439699173
Test set avg_accuracy=86.80% avg_sensitivity=60.37%, avg_specificity=95.81% avg_auc=90.23%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.184491 Test loss=0.329395 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1857122778892517
[5/24] Train loss=0.16959083080291748
[10/24] Train loss=0.2059326022863388
[15/24] Train loss=0.17741860449314117
[20/24] Train loss=0.18905311822891235
Test set avg_accuracy=87.37% avg_sensitivity=68.41%, avg_specificity=93.84% avg_auc=91.41%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.190183 Test loss=0.315088 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.19313804805278778
[5/24] Train loss=0.16688129305839539
[10/24] Train loss=0.21380269527435303
[15/24] Train loss=0.16796185076236725
[20/24] Train loss=0.18162919580936432
Test set avg_accuracy=87.32% avg_sensitivity=75.12%, avg_specificity=91.48% avg_auc=92.92%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.189002 Test loss=0.297015 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.18737275898456573
[5/24] Train loss=0.16657648980617523
[10/24] Train loss=0.21306687593460083
[15/24] Train loss=0.17069080471992493
[20/24] Train loss=0.18129272758960724
Test set avg_accuracy=87.47% avg_sensitivity=72.66%, avg_specificity=92.53% avg_auc=92.87%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.185631 Test loss=0.295292 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1952947974205017
[5/24] Train loss=0.1710016429424286
[10/24] Train loss=0.20091110467910767
[15/24] Train loss=0.16528306901454926
[20/24] Train loss=0.1770130693912506
Test set avg_accuracy=85.52% avg_sensitivity=79.62%, avg_specificity=87.53% avg_auc=91.64%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.180769 Test loss=0.341191 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.18803763389587402
[5/24] Train loss=0.15837517380714417
[10/24] Train loss=0.18841063976287842
[15/24] Train loss=0.15673580765724182
[20/24] Train loss=0.18153846263885498
Test set avg_accuracy=87.23% avg_sensitivity=73.89%, avg_specificity=91.78% avg_auc=92.00%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.179059 Test loss=0.306333 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1846112757921219
[5/24] Train loss=0.15574103593826294
[10/24] Train loss=0.193929523229599
[15/24] Train loss=0.1678917557001114
[20/24] Train loss=0.18583761155605316
Test set avg_accuracy=87.64% avg_sensitivity=70.97%, avg_specificity=93.33% avg_auc=91.27%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.179352 Test loss=0.306407 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.1805364191532135
[5/24] Train loss=0.16007356345653534
[10/24] Train loss=0.196191668510437
[15/24] Train loss=0.1550639271736145
[20/24] Train loss=0.1777401715517044
Test set avg_accuracy=87.23% avg_sensitivity=75.01%, avg_specificity=91.39% avg_auc=92.40%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.178259 Test loss=0.302088 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.18006621301174164
[5/24] Train loss=0.1562144011259079
[10/24] Train loss=0.19468073546886444
[15/24] Train loss=0.16376358270645142
[20/24] Train loss=0.18189166486263275
Test set avg_accuracy=84.26% avg_sensitivity=69.18%, avg_specificity=89.40% avg_auc=88.50%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.178363 Test loss=0.367069 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.18950988352298737
[5/24] Train loss=0.14811883866786957
[10/24] Train loss=0.18982326984405518
[15/24] Train loss=0.1619216948747635
[20/24] Train loss=0.17794284224510193
Test set avg_accuracy=86.99% avg_sensitivity=75.01%, avg_specificity=91.08% avg_auc=92.28%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.175165 Test loss=0.304320 Current lr=[0.000156543481933168]

[0/24] Train loss=0.1849316507577896
[5/24] Train loss=0.15514756739139557
[10/24] Train loss=0.18793067336082458
[15/24] Train loss=0.1542852222919464
[20/24] Train loss=0.1778929978609085
Test set avg_accuracy=87.60% avg_sensitivity=69.79%, avg_specificity=93.68% avg_auc=91.39%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.171372 Test loss=0.311339 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.17891138792037964
[5/24] Train loss=0.1483239233493805
[10/24] Train loss=0.18144561350345612
[15/24] Train loss=0.15881679952144623
[20/24] Train loss=0.16919636726379395
Test set avg_accuracy=86.86% avg_sensitivity=64.72%, avg_specificity=94.41% avg_auc=90.40%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.168527 Test loss=0.321132 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.17229822278022766
[5/24] Train loss=0.14611555635929108
[10/24] Train loss=0.17484059929847717
[15/24] Train loss=0.14990800619125366
[20/24] Train loss=0.17665737867355347
Test set avg_accuracy=87.86% avg_sensitivity=66.21%, avg_specificity=95.25% avg_auc=91.24%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.166403 Test loss=0.307679 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.1738731414079666
[5/24] Train loss=0.15123480558395386
[10/24] Train loss=0.18486571311950684
[15/24] Train loss=0.15540562570095062
[20/24] Train loss=0.1710440069437027
Test set avg_accuracy=87.81% avg_sensitivity=70.87%, avg_specificity=93.59% avg_auc=91.13%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.167906 Test loss=0.309917 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.17562127113342285
[5/24] Train loss=0.15320588648319244
[10/24] Train loss=0.1842098981142044
[15/24] Train loss=0.15185515582561493
[20/24] Train loss=0.16541141271591187
Test set avg_accuracy=87.79% avg_sensitivity=77.47%, avg_specificity=91.30% avg_auc=93.10%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.168985 Test loss=0.294164 Current lr=[0.000134135431043539]

[0/24] Train loss=0.17320573329925537
[5/24] Train loss=0.151483952999115
[10/24] Train loss=0.1747286319732666
[15/24] Train loss=0.15206106007099152
[20/24] Train loss=0.1694623976945877
Test set avg_accuracy=87.02% avg_sensitivity=68.31%, avg_specificity=93.40% avg_auc=90.67%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.165367 Test loss=0.319459 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1646135449409485
[5/24] Train loss=0.14492426812648773
[10/24] Train loss=0.17597520351409912
[15/24] Train loss=0.15338581800460815
[20/24] Train loss=0.1721918284893036
Test set avg_accuracy=87.11% avg_sensitivity=62.37%, avg_specificity=95.55% avg_auc=90.17%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.164139 Test loss=0.333988 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.17158114910125732
[5/24] Train loss=0.1413026750087738
[10/24] Train loss=0.17571358382701874
[15/24] Train loss=0.15402092039585114
[20/24] Train loss=0.16536876559257507
Test set avg_accuracy=88.33% avg_sensitivity=74.91%, avg_specificity=92.91% avg_auc=92.87%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.162170 Test loss=0.289922 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.16846054792404175
[5/24] Train loss=0.14713327586650848
[10/24] Train loss=0.17324557900428772
[15/24] Train loss=0.16024905443191528
[20/24] Train loss=0.16945995390415192
Test set avg_accuracy=87.93% avg_sensitivity=66.92%, avg_specificity=95.09% avg_auc=90.52%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.164331 Test loss=0.315724 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.16760461032390594
[5/24] Train loss=0.15088865160942078
[10/24] Train loss=0.1687139868736267
[15/24] Train loss=0.14916862547397614
[20/24] Train loss=0.16421866416931152
Test set avg_accuracy=87.79% avg_sensitivity=64.52%, avg_specificity=95.72% avg_auc=90.91%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.160364 Test loss=0.323010 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16495691239833832
[5/24] Train loss=0.1458825170993805
[10/24] Train loss=0.16414862871170044
[15/24] Train loss=0.14718705415725708
[20/24] Train loss=0.16558828949928284
Test set avg_accuracy=87.80% avg_sensitivity=70.35%, avg_specificity=93.75% avg_auc=91.44%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.159226 Test loss=0.310578 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.16190595924854279
[5/24] Train loss=0.14233160018920898
[10/24] Train loss=0.16361558437347412
[15/24] Train loss=0.15258117020130157
[20/24] Train loss=0.16538681089878082
Test set avg_accuracy=87.90% avg_sensitivity=68.00%, avg_specificity=94.69% avg_auc=91.50%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.157810 Test loss=0.313558 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.16677670180797577
[5/24] Train loss=0.14331668615341187
[10/24] Train loss=0.15673451125621796
[15/24] Train loss=0.1545899212360382
[20/24] Train loss=0.16252245008945465
Test set avg_accuracy=87.98% avg_sensitivity=69.23%, avg_specificity=94.38% avg_auc=91.33%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.158245 Test loss=0.310682 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1659344881772995
[5/24] Train loss=0.148466557264328
[10/24] Train loss=0.15856501460075378
[15/24] Train loss=0.15522882342338562
[20/24] Train loss=0.15937389433383942
Test set avg_accuracy=87.96% avg_sensitivity=71.74%, avg_specificity=93.49% avg_auc=92.28%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.160047 Test loss=0.303029 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.16689527034759521
[5/24] Train loss=0.1470649689435959
[10/24] Train loss=0.15566639602184296
[15/24] Train loss=0.14674869179725647
[20/24] Train loss=0.16279543936252594
Test set avg_accuracy=87.88% avg_sensitivity=75.01%, avg_specificity=92.26% avg_auc=92.66%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.157801 Test loss=0.302964 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1570923775434494
[5/24] Train loss=0.14479593932628632
[10/24] Train loss=0.15533842146396637
[15/24] Train loss=0.1499045193195343
[20/24] Train loss=0.15951840579509735
Test set avg_accuracy=87.80% avg_sensitivity=69.94%, avg_specificity=93.89% avg_auc=92.42%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.155134 Test loss=0.308314 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.15816189348697662
[5/24] Train loss=0.13883556425571442
[10/24] Train loss=0.15714041888713837
[15/24] Train loss=0.15074998140335083
[20/24] Train loss=0.16121307015419006
Test set avg_accuracy=87.88% avg_sensitivity=71.89%, avg_specificity=93.33% avg_auc=92.34%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.155603 Test loss=0.307235 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.15974877774715424
[5/24] Train loss=0.1418057382106781
[10/24] Train loss=0.15889890491962433
[15/24] Train loss=0.14368773996829987
[20/24] Train loss=0.16174636781215668
Test set avg_accuracy=88.09% avg_sensitivity=69.69%, avg_specificity=94.36% avg_auc=91.99%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.154912 Test loss=0.307454 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.15713123977184296
[5/24] Train loss=0.14284271001815796
[10/24] Train loss=0.16518987715244293
[15/24] Train loss=0.14587756991386414
[20/24] Train loss=0.15525920689105988
Test set avg_accuracy=87.89% avg_sensitivity=73.02%, avg_specificity=92.96% avg_auc=91.97%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.156217 Test loss=0.310449 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15509887039661407
[5/24] Train loss=0.14130862057209015
[10/24] Train loss=0.16211502254009247
[15/24] Train loss=0.1506468653678894
[20/24] Train loss=0.1571185141801834
Test set avg_accuracy=87.17% avg_sensitivity=70.05%, avg_specificity=93.02% avg_auc=91.30%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.153572 Test loss=0.318521 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.15328125655651093
[5/24] Train loss=0.13938398659229279
[10/24] Train loss=0.15590955317020416
[15/24] Train loss=0.1449354588985443
[20/24] Train loss=0.1572825163602829
Test set avg_accuracy=87.94% avg_sensitivity=73.32%, avg_specificity=92.93% avg_auc=92.51%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.151933 Test loss=0.299007 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.15446309745311737
[5/24] Train loss=0.13852429389953613
[10/24] Train loss=0.14945001900196075
[15/24] Train loss=0.1398763358592987
[20/24] Train loss=0.15225480496883392
Test set avg_accuracy=88.01% avg_sensitivity=68.82%, avg_specificity=94.55% avg_auc=91.06%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.147696 Test loss=0.316383 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1511310487985611
[5/24] Train loss=0.13944491744041443
[10/24] Train loss=0.15696801245212555
[15/24] Train loss=0.13583314418792725
[20/24] Train loss=0.15102946758270264
Test set avg_accuracy=87.79% avg_sensitivity=72.50%, avg_specificity=93.00% avg_auc=91.44%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.146995 Test loss=0.311045 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.15242189168930054
[5/24] Train loss=0.13184672594070435
[10/24] Train loss=0.15397904813289642
[15/24] Train loss=0.13729140162467957
[20/24] Train loss=0.15036408603191376
Test set avg_accuracy=87.27% avg_sensitivity=63.03%, avg_specificity=95.53% avg_auc=90.10%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.145169 Test loss=0.331180 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.15283945202827454
[5/24] Train loss=0.13170172274112701
[10/24] Train loss=0.14586083590984344
[15/24] Train loss=0.13257449865341187
[20/24] Train loss=0.1479824185371399
Test set avg_accuracy=87.64% avg_sensitivity=71.79%, avg_specificity=93.05% avg_auc=91.59%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.144615 Test loss=0.313725 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.15030698478221893
[5/24] Train loss=0.13134220242500305
[10/24] Train loss=0.14582227170467377
[15/24] Train loss=0.13272449374198914
[20/24] Train loss=0.1470593810081482
Test set avg_accuracy=87.68% avg_sensitivity=69.89%, avg_specificity=93.75% avg_auc=91.10%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.143359 Test loss=0.315301 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14875619113445282
[5/24] Train loss=0.13271792232990265
[10/24] Train loss=0.13895098865032196
[15/24] Train loss=0.13439306616783142
[20/24] Train loss=0.1458788961172104
Test set avg_accuracy=88.18% avg_sensitivity=65.75%, avg_specificity=95.83% avg_auc=90.43%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.142482 Test loss=0.317773 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1476624608039856
[5/24] Train loss=0.13194426894187927
[10/24] Train loss=0.14129851758480072
[15/24] Train loss=0.12915438413619995
[20/24] Train loss=0.14120544493198395
Test set avg_accuracy=88.05% avg_sensitivity=67.23%, avg_specificity=95.15% avg_auc=90.53%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.141537 Test loss=0.321413 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.14818474650382996
[5/24] Train loss=0.12875139713287354
[10/24] Train loss=0.14176172018051147
[15/24] Train loss=0.13192489743232727
[20/24] Train loss=0.14111068844795227
Test set avg_accuracy=87.81% avg_sensitivity=69.33%, avg_specificity=94.12% avg_auc=91.66%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.140311 Test loss=0.310340 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1462125927209854
[5/24] Train loss=0.12999676167964935
[10/24] Train loss=0.13881388306617737
[15/24] Train loss=0.13390101492404938
[20/24] Train loss=0.1403873860836029
Test set avg_accuracy=87.89% avg_sensitivity=67.90%, avg_specificity=94.71% avg_auc=91.22%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.139891 Test loss=0.318404 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.14682051539421082
[5/24] Train loss=0.128092423081398
[10/24] Train loss=0.13958190381526947
[15/24] Train loss=0.132313072681427
[20/24] Train loss=0.1418430656194687
Test set avg_accuracy=87.53% avg_sensitivity=72.09%, avg_specificity=92.79% avg_auc=91.64%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.138826 Test loss=0.312748 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.14647065103054047
[5/24] Train loss=0.12931007146835327
[10/24] Train loss=0.13417989015579224
[15/24] Train loss=0.13241255283355713
[20/24] Train loss=0.13589608669281006
Test set avg_accuracy=87.83% avg_sensitivity=68.25%, avg_specificity=94.50% avg_auc=91.31%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.139018 Test loss=0.313228 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.14471063017845154
[5/24] Train loss=0.12992100417613983
[10/24] Train loss=0.1376620978116989
[15/24] Train loss=0.13319413363933563
[20/24] Train loss=0.14122922718524933
Test set avg_accuracy=87.92% avg_sensitivity=72.25%, avg_specificity=93.26% avg_auc=91.64%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.139912 Test loss=0.305092 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1463455855846405
[5/24] Train loss=0.13046474754810333
[10/24] Train loss=0.13511118292808533
[15/24] Train loss=0.12947958707809448
[20/24] Train loss=0.14338809251785278
Test set avg_accuracy=87.67% avg_sensitivity=75.12%, avg_specificity=91.95% avg_auc=92.16%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.140200 Test loss=0.305079 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1426309496164322
[5/24] Train loss=0.1322423666715622
[10/24] Train loss=0.1433478146791458
[15/24] Train loss=0.12608040869235992
[20/24] Train loss=0.14000968635082245
Test set avg_accuracy=87.49% avg_sensitivity=77.16%, avg_specificity=91.01% avg_auc=92.22%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.139194 Test loss=0.309138 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.14724977314472198
[5/24] Train loss=0.13010212779045105
[10/24] Train loss=0.13040168583393097
[15/24] Train loss=0.12701453268527985
[20/24] Train loss=0.1383693516254425
Test set avg_accuracy=87.81% avg_sensitivity=72.09%, avg_specificity=93.17% avg_auc=92.14%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.137453 Test loss=0.305323 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.14347732067108154
[5/24] Train loss=0.13033604621887207
[10/24] Train loss=0.1297210454940796
[15/24] Train loss=0.12869194149971008
[20/24] Train loss=0.1364813894033432
Test set avg_accuracy=88.05% avg_sensitivity=69.74%, avg_specificity=94.29% avg_auc=91.32%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.135966 Test loss=0.313286 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.14226290583610535
[5/24] Train loss=0.12499968707561493
[10/24] Train loss=0.13185761868953705
[15/24] Train loss=0.12673747539520264
[20/24] Train loss=0.13431961834430695
Test set avg_accuracy=87.81% avg_sensitivity=71.58%, avg_specificity=93.35% avg_auc=92.17%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.134754 Test loss=0.303823 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.14158856868743896
[5/24] Train loss=0.1253141462802887
[10/24] Train loss=0.13024716079235077
[15/24] Train loss=0.125181183218956
[20/24] Train loss=0.13295088708400726
Test set avg_accuracy=87.75% avg_sensitivity=73.58%, avg_specificity=92.58% avg_auc=92.10%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.134362 Test loss=0.304561 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.14199821650981903
[5/24] Train loss=0.1255033016204834
[10/24] Train loss=0.13084754347801208
[15/24] Train loss=0.12734928727149963
[20/24] Train loss=0.13236206769943237
Test set avg_accuracy=87.79% avg_sensitivity=70.61%, avg_specificity=93.64% avg_auc=91.95%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.134060 Test loss=0.306299 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1410645842552185
[5/24] Train loss=0.12432035803794861
[10/24] Train loss=0.13385160267353058
[15/24] Train loss=0.12517806887626648
[20/24] Train loss=0.13118737936019897
Test set avg_accuracy=87.77% avg_sensitivity=71.68%, avg_specificity=93.26% avg_auc=92.00%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.133248 Test loss=0.306933 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1407151073217392
[5/24] Train loss=0.1251934915781021
[10/24] Train loss=0.12914161384105682
[15/24] Train loss=0.12439333647489548
[20/24] Train loss=0.1321285367012024
Test set avg_accuracy=87.60% avg_sensitivity=71.22%, avg_specificity=93.19% avg_auc=91.99%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.133000 Test loss=0.306698 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.14106342196464539
[5/24] Train loss=0.12386327236890793
[10/24] Train loss=0.12965671718120575
[15/24] Train loss=0.12112601101398468
[20/24] Train loss=0.13591541349887848
Test set avg_accuracy=87.79% avg_sensitivity=71.89%, avg_specificity=93.21% avg_auc=92.08%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.132251 Test loss=0.305789 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13889870047569275
[5/24] Train loss=0.12216570973396301
[10/24] Train loss=0.12703672051429749
[15/24] Train loss=0.12203468382358551
[20/24] Train loss=0.13154257833957672
Test set avg_accuracy=87.72% avg_sensitivity=71.79%, avg_specificity=93.16% avg_auc=92.01%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.131496 Test loss=0.307429 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13920527696609497
[5/24] Train loss=0.1205693930387497
[10/24] Train loss=0.130380779504776
[15/24] Train loss=0.12294621020555496
[20/24] Train loss=0.12985341250896454
Test set avg_accuracy=87.80% avg_sensitivity=71.53%, avg_specificity=93.35% avg_auc=92.00%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.131527 Test loss=0.307093 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1431790143251419
[5/24] Train loss=0.12340135872364044
[10/24] Train loss=0.12908092141151428
[15/24] Train loss=0.1218949556350708
[20/24] Train loss=0.1306864619255066
Test set avg_accuracy=87.73% avg_sensitivity=71.43%, avg_specificity=93.29% avg_auc=92.02%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.131189 Test loss=0.306410 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1415911614894867
[5/24] Train loss=0.1226978525519371
[10/24] Train loss=0.12782396376132965
[15/24] Train loss=0.12129495292901993
[20/24] Train loss=0.13202835619449615
Test set avg_accuracy=87.80% avg_sensitivity=71.74%, avg_specificity=93.28% avg_auc=92.00%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.130874 Test loss=0.307045 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13529622554779053
[5/24] Train loss=0.12417209893465042
[10/24] Train loss=0.1297888457775116
[15/24] Train loss=0.12379152327775955
[20/24] Train loss=0.13019594550132751
Test set avg_accuracy=87.71% avg_sensitivity=71.79%, avg_specificity=93.14% avg_auc=91.98%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.130559 Test loss=0.307350 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13612836599349976
[5/24] Train loss=0.12203562259674072
[10/24] Train loss=0.12594807147979736
[15/24] Train loss=0.12160095572471619
[20/24] Train loss=0.1299232691526413
Test set avg_accuracy=87.67% avg_sensitivity=71.79%, avg_specificity=93.09% avg_auc=92.03%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.129910 Test loss=0.306546 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13917164504528046
[5/24] Train loss=0.1207679808139801
[10/24] Train loss=0.130165696144104
[15/24] Train loss=0.12405148148536682
[20/24] Train loss=0.13764604926109314
Test set avg_accuracy=87.73% avg_sensitivity=71.27%, avg_specificity=93.35% avg_auc=91.91%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.130682 Test loss=0.308170 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.136306032538414
[5/24] Train loss=0.12478671222925186
[10/24] Train loss=0.12559670209884644
[15/24] Train loss=0.12076739966869354
[20/24] Train loss=0.12930166721343994
Test set avg_accuracy=87.72% avg_sensitivity=71.27%, avg_specificity=93.33% avg_auc=91.95%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.130010 Test loss=0.308005 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.13731423020362854
[5/24] Train loss=0.12149171531200409
[10/24] Train loss=0.1272570788860321
[15/24] Train loss=0.1228376105427742
[20/24] Train loss=0.1291637420654297
Test set avg_accuracy=87.70% avg_sensitivity=71.38%, avg_specificity=93.26% avg_auc=91.99%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.130274 Test loss=0.307818 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.135542631149292
[5/24] Train loss=0.12398923933506012
[10/24] Train loss=0.12749145925045013
[15/24] Train loss=0.12366233766078949
[20/24] Train loss=0.13292384147644043
Test set avg_accuracy=87.72% avg_sensitivity=71.22%, avg_specificity=93.35% avg_auc=91.93%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.130097 Test loss=0.308123 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1399921029806137
[5/24] Train loss=0.12225667387247086
[10/24] Train loss=0.127183735370636
[15/24] Train loss=0.123336561024189
[20/24] Train loss=0.12956629693508148
Test set avg_accuracy=87.72% avg_sensitivity=71.33%, avg_specificity=93.31% avg_auc=91.96%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.130528 Test loss=0.308044 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=87.70% sen=78.24%, spe=90.92%, auc=93.86%!
Fold[5] Avg_overlap=0.66%(±0.2409536431396346)
[0/24] Train loss=0.7341407537460327
[5/24] Train loss=0.7392740845680237
[10/24] Train loss=0.7218098640441895
[15/24] Train loss=0.7208027243614197
[20/24] Train loss=0.709271252155304
Test set avg_accuracy=59.64% avg_sensitivity=48.61%, avg_specificity=63.74% avg_auc=58.08%
Best model saved!! Metric=-95.93239825871876!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.723137 Test loss=0.680341 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7072516083717346
[5/24] Train loss=0.6933868527412415
[10/24] Train loss=0.6953974962234497
[15/24] Train loss=0.6832340359687805
[20/24] Train loss=0.6722972393035889
Test set avg_accuracy=68.82% avg_sensitivity=56.29%, avg_specificity=73.48% avg_auc=71.32%
Best model saved!! Metric=-56.096645074291025!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.693225 Test loss=0.604810 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6662808060646057
[5/24] Train loss=0.6710866689682007
[10/24] Train loss=0.6716091632843018
[15/24] Train loss=0.6492710113525391
[20/24] Train loss=0.6493622064590454
Test set avg_accuracy=72.85% avg_sensitivity=63.82%, avg_specificity=76.22% avg_auc=77.27%
Best model saved!! Metric=-35.848090837522406!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.663842 Test loss=0.564781 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6427457332611084
[5/24] Train loss=0.6463344693183899
[10/24] Train loss=0.6428120136260986
[15/24] Train loss=0.6306501626968384
[20/24] Train loss=0.6177725791931152
Test set avg_accuracy=74.75% avg_sensitivity=68.71%, avg_specificity=77.00% avg_auc=80.40%
Best model saved!! Metric=-25.129806356890754!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.637490 Test loss=0.538908 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6139706969261169
[5/24] Train loss=0.6142080426216125
[10/24] Train loss=0.6127578616142273
[15/24] Train loss=0.5984328985214233
[20/24] Train loss=0.589789867401123
Test set avg_accuracy=76.86% avg_sensitivity=72.17%, avg_specificity=78.61% avg_auc=82.55%
Best model saved!! Metric=-15.807634376870723!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.608194 Test loss=0.517636 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.580862820148468
[5/24] Train loss=0.5735701322555542
[10/24] Train loss=0.5848020911216736
[15/24] Train loss=0.5613024830818176
[20/24] Train loss=0.5556496977806091
Test set avg_accuracy=78.09% avg_sensitivity=74.38%, avg_specificity=79.47% avg_auc=84.72%
Best model saved!! Metric=-9.352998180682235!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.579006 Test loss=0.494586 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5551775693893433
[5/24] Train loss=0.544105052947998
[10/24] Train loss=0.5556330680847168
[15/24] Train loss=0.5287656784057617
[20/24] Train loss=0.5256454348564148
Test set avg_accuracy=79.44% avg_sensitivity=74.52%, avg_specificity=81.27% avg_auc=86.31%
Best model saved!! Metric=-4.4524695664220815!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.549059 Test loss=0.468599 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5233392715454102
[5/24] Train loss=0.5226951837539673
[10/24] Train loss=0.5287899374961853
[15/24] Train loss=0.5078418254852295
[20/24] Train loss=0.488089382648468
Test set avg_accuracy=80.99% avg_sensitivity=75.86%, avg_specificity=82.90% avg_auc=87.94%
Best model saved!! Metric=1.6899187113590415!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.519856 Test loss=0.441798 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.49165284633636475
[5/24] Train loss=0.4932607412338257
[10/24] Train loss=0.5026617646217346
[15/24] Train loss=0.4748813807964325
[20/24] Train loss=0.46263957023620605
Test set avg_accuracy=82.70% avg_sensitivity=76.82%, avg_specificity=84.88% avg_auc=89.42%
Best model saved!! Metric=7.8169407126388535!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.490895 Test loss=0.415765 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.470132052898407
[5/24] Train loss=0.46497422456741333
[10/24] Train loss=0.4761295020580292
[15/24] Train loss=0.44695818424224854
[20/24] Train loss=0.43916475772857666
Test set avg_accuracy=84.04% avg_sensitivity=77.30%, avg_specificity=86.54% avg_auc=90.29%
Best model saved!! Metric=12.174902437224375!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.464335 Test loss=0.398145 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4465601146221161
[5/24] Train loss=0.43324676156044006
[10/24] Train loss=0.4551885724067688
[15/24] Train loss=0.4226635694503784
[20/24] Train loss=0.41335588693618774
Test set avg_accuracy=85.81% avg_sensitivity=75.86%, avg_specificity=89.51% avg_auc=90.95%
Best model saved!! Metric=16.13256564904235!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.438033 Test loss=0.371628 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4165881872177124
[5/24] Train loss=0.4101696312427521
[10/24] Train loss=0.42024627327919006
[15/24] Train loss=0.39389294385910034
[20/24] Train loss=0.38122808933258057
Test set avg_accuracy=86.63% avg_sensitivity=75.67%, avg_specificity=90.71% avg_auc=91.50%
Best model saved!! Metric=18.51086565451307!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.414045 Test loss=0.354043 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.38802480697631836
[5/24] Train loss=0.39749467372894287
[10/24] Train loss=0.4033285081386566
[15/24] Train loss=0.3772302269935608
[20/24] Train loss=0.36836978793144226
Test set avg_accuracy=87.24% avg_sensitivity=74.52%, avg_specificity=91.98% avg_auc=91.99%
Best model saved!! Metric=19.723235969779182!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.394169 Test loss=0.335782 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3678566813468933
[5/24] Train loss=0.37151268124580383
[10/24] Train loss=0.3832986354827881
[15/24] Train loss=0.36326295137405396
[20/24] Train loss=0.34469255805015564
Test set avg_accuracy=87.66% avg_sensitivity=76.34%, avg_specificity=91.87% avg_auc=92.43%
Best model saved!! Metric=22.298139806126926!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.375589 Test loss=0.327699 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.35527878999710083
[5/24] Train loss=0.35631999373435974
[10/24] Train loss=0.36724209785461426
[15/24] Train loss=0.3481541574001312
[20/24] Train loss=0.32975950837135315
Test set avg_accuracy=88.22% avg_sensitivity=77.26%, avg_specificity=92.30% avg_auc=92.93%
Best model saved!! Metric=24.70413252248204!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.359196 Test loss=0.316996 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3379289507865906
[5/24] Train loss=0.34095194935798645
[10/24] Train loss=0.3483916223049164
[15/24] Train loss=0.3316032290458679
[20/24] Train loss=0.3135920464992523
Test set avg_accuracy=88.24% avg_sensitivity=74.42%, avg_specificity=93.39% avg_auc=93.04%
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.344907 Test loss=0.305340 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.33011871576309204
[5/24] Train loss=0.3293061852455139
[10/24] Train loss=0.34305205941200256
[15/24] Train loss=0.32461631298065186
[20/24] Train loss=0.302278608083725
Test set avg_accuracy=88.50% avg_sensitivity=78.55%, avg_specificity=92.21% avg_auc=93.35%
Best model saved!! Metric=26.614402901436094!!
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.334854 Test loss=0.302504 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3174137771129608
[5/24] Train loss=0.31727731227874756
[10/24] Train loss=0.3317373991012573
[15/24] Train loss=0.3078516721725464
[20/24] Train loss=0.2872263491153717
Test set avg_accuracy=88.84% avg_sensitivity=77.45%, avg_specificity=93.08% avg_auc=93.44%
Best model saved!! Metric=26.8087719756697!!
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.323948 Test loss=0.294097 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.30362486839294434
[5/24] Train loss=0.3142147660255432
[10/24] Train loss=0.3228306472301483
[15/24] Train loss=0.3049616515636444
[20/24] Train loss=0.2845194339752197
Test set avg_accuracy=88.95% avg_sensitivity=81.38%, avg_specificity=91.76% avg_auc=93.74%
Best model saved!! Metric=29.82897048712819!!
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.315022 Test loss=0.295377 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2969984710216522
[5/24] Train loss=0.3011624217033386
[10/24] Train loss=0.3109264671802521
[15/24] Train loss=0.2925596535205841
[20/24] Train loss=0.27195486426353455
Test set avg_accuracy=88.65% avg_sensitivity=81.77%, avg_specificity=91.21% avg_auc=93.68%
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.307019 Test loss=0.293721 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2872248589992523
[5/24] Train loss=0.294538289308548
[10/24] Train loss=0.3043399155139923
[15/24] Train loss=0.29028162360191345
[20/24] Train loss=0.26859426498413086
Test set avg_accuracy=89.34% avg_sensitivity=78.31%, avg_specificity=93.44% avg_auc=93.67%
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.299872 Test loss=0.281606 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2842381000518799
[5/24] Train loss=0.2830720543861389
[10/24] Train loss=0.29785987734794617
[15/24] Train loss=0.28070583939552307
[20/24] Train loss=0.2602657079696655
Test set avg_accuracy=89.61% avg_sensitivity=78.93%, avg_specificity=93.58% avg_auc=93.89%
Best model saved!! Metric=30.02278175201235!!
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.293146 Test loss=0.277330 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2769061326980591
[5/24] Train loss=0.2773497998714447
[10/24] Train loss=0.2940290868282318
[15/24] Train loss=0.27771759033203125
[20/24] Train loss=0.2516075372695923
Test set avg_accuracy=88.97% avg_sensitivity=71.02%, avg_specificity=95.66% avg_auc=93.53%
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.285370 Test loss=0.280253 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.27235424518585205
[5/24] Train loss=0.27604618668556213
[10/24] Train loss=0.2845494747161865
[15/24] Train loss=0.2615686357021332
[20/24] Train loss=0.24699530005455017
Test set avg_accuracy=89.58% avg_sensitivity=76.54%, avg_specificity=94.44% avg_auc=93.96%
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.280032 Test loss=0.269016 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.26410210132598877
[5/24] Train loss=0.27596887946128845
[10/24] Train loss=0.2908068001270294
[15/24] Train loss=0.2612397074699402
[20/24] Train loss=0.24226553738117218
Test set avg_accuracy=89.61% avg_sensitivity=78.45%, avg_specificity=93.76% avg_auc=94.08%
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.276189 Test loss=0.268753 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2597237825393677
[5/24] Train loss=0.2611967921257019
[10/24] Train loss=0.2807375192642212
[15/24] Train loss=0.25002220273017883
[20/24] Train loss=0.24686795473098755
Test set avg_accuracy=87.16% avg_sensitivity=59.36%, avg_specificity=97.52% avg_auc=92.79%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.268625 Test loss=0.309344 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.25495269894599915
[5/24] Train loss=0.26738616824150085
[10/24] Train loss=0.2772676646709442
[15/24] Train loss=0.2507508397102356
[20/24] Train loss=0.23762977123260498
Test set avg_accuracy=88.87% avg_sensitivity=68.71%, avg_specificity=96.37% avg_auc=93.62%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.268645 Test loss=0.280572 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.25071391463279724
[5/24] Train loss=0.2548436224460602
[10/24] Train loss=0.2683413028717041
[15/24] Train loss=0.24540778994560242
[20/24] Train loss=0.23556742072105408
Test set avg_accuracy=89.43% avg_sensitivity=80.47%, avg_specificity=92.76% avg_auc=93.85%
Best model saved!! Metric=30.51044867929609!!
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.261571 Test loss=0.275687 Current lr=[0.000210185142098938]

[0/24] Train loss=0.24297547340393066
[5/24] Train loss=0.25934427976608276
[10/24] Train loss=0.26485154032707214
[15/24] Train loss=0.24472375214099884
[20/24] Train loss=0.23691289126873016
Test set avg_accuracy=87.68% avg_sensitivity=61.80%, avg_specificity=97.32% avg_auc=93.03%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.257307 Test loss=0.304851 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.25003132224082947
[5/24] Train loss=0.25264468789100647
[10/24] Train loss=0.2638309895992279
[15/24] Train loss=0.23883479833602905
[20/24] Train loss=0.23037613928318024
Test set avg_accuracy=89.51% avg_sensitivity=76.01%, avg_specificity=94.53% avg_auc=93.78%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.256052 Test loss=0.269190 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2402748167514801
[5/24] Train loss=0.2540832459926605
[10/24] Train loss=0.2552906274795532
[15/24] Train loss=0.22745798528194427
[20/24] Train loss=0.22568732500076294
Test set avg_accuracy=88.89% avg_sensitivity=69.91%, avg_specificity=95.96% avg_auc=93.38%
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.250388 Test loss=0.281941 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.23865710198879242
[5/24] Train loss=0.23975954949855804
[10/24] Train loss=0.25420281291007996
[15/24] Train loss=0.22808906435966492
[20/24] Train loss=0.2244643121957779
Test set avg_accuracy=87.98% avg_sensitivity=66.36%, avg_specificity=96.03% avg_auc=92.78%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.246725 Test loss=0.292293 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.23249822854995728
[5/24] Train loss=0.24113081395626068
[10/24] Train loss=0.2558356821537018
[15/24] Train loss=0.22237499058246613
[20/24] Train loss=0.21268442273139954
Test set avg_accuracy=78.62% avg_sensitivity=22.22%, avg_specificity=99.62% avg_auc=87.97%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.245199 Test loss=0.508602 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2430916726589203
[5/24] Train loss=0.23511114716529846
[10/24] Train loss=0.2563725411891937
[15/24] Train loss=0.23030206561088562
[20/24] Train loss=0.22370755672454834
Test set avg_accuracy=89.10% avg_sensitivity=72.74%, avg_specificity=95.19% avg_auc=93.52%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.244184 Test loss=0.276534 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2297654002904892
[5/24] Train loss=0.2293536365032196
[10/24] Train loss=0.25204479694366455
[15/24] Train loss=0.22583380341529846
[20/24] Train loss=0.2180093675851822
Test set avg_accuracy=86.17% avg_sensitivity=60.17%, avg_specificity=95.85% avg_auc=91.33%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.240504 Test loss=0.333502 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2271149754524231
[5/24] Train loss=0.21842019259929657
[10/24] Train loss=0.24717353284358978
[15/24] Train loss=0.2154483199119568
[20/24] Train loss=0.21010422706604004
Test set avg_accuracy=88.36% avg_sensitivity=69.72%, avg_specificity=95.30% avg_auc=92.88%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.235591 Test loss=0.287349 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.23309718072414398
[5/24] Train loss=0.21997487545013428
[10/24] Train loss=0.23379157483577728
[15/24] Train loss=0.21666504442691803
[20/24] Train loss=0.21099470555782318
Test set avg_accuracy=89.49% avg_sensitivity=78.12%, avg_specificity=93.73% avg_auc=93.36%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.233312 Test loss=0.271974 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2368411123752594
[5/24] Train loss=0.22389428317546844
[10/24] Train loss=0.23571868240833282
[15/24] Train loss=0.217588871717453
[20/24] Train loss=0.20707443356513977
Test set avg_accuracy=88.93% avg_sensitivity=80.33%, avg_specificity=92.14% avg_auc=93.80%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.230537 Test loss=0.273497 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.21845614910125732
[5/24] Train loss=0.22101221978664398
[10/24] Train loss=0.2400858998298645
[15/24] Train loss=0.21692143380641937
[20/24] Train loss=0.2028365284204483
Test set avg_accuracy=83.42% avg_sensitivity=43.09%, avg_specificity=98.45% avg_auc=89.67%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.229026 Test loss=0.405158 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.22715923190116882
[5/24] Train loss=0.21501708030700684
[10/24] Train loss=0.23690339922904968
[15/24] Train loss=0.21804656088352203
[20/24] Train loss=0.21536731719970703
Test set avg_accuracy=86.91% avg_sensitivity=62.04%, avg_specificity=96.18% avg_auc=90.75%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.227192 Test loss=0.330744 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.22832687199115753
[5/24] Train loss=0.20440179109573364
[10/24] Train loss=0.2299167811870575
[15/24] Train loss=0.21848566830158234
[20/24] Train loss=0.19965419173240662
Test set avg_accuracy=88.06% avg_sensitivity=65.12%, avg_specificity=96.60% avg_auc=92.63%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.224181 Test loss=0.298586 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.21487249433994293
[5/24] Train loss=0.20336924493312836
[10/24] Train loss=0.23112322390079498
[15/24] Train loss=0.21393515169620514
[20/24] Train loss=0.208380326628685
Test set avg_accuracy=88.40% avg_sensitivity=73.51%, avg_specificity=93.94% avg_auc=93.00%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.224720 Test loss=0.284276 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.22466260194778442
[5/24] Train loss=0.20994320511817932
[10/24] Train loss=0.23382006585597992
[15/24] Train loss=0.20546701550483704
[20/24] Train loss=0.2014758288860321
Test set avg_accuracy=88.87% avg_sensitivity=79.70%, avg_specificity=92.28% avg_auc=93.71%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.224020 Test loss=0.276023 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.22387273609638214
[5/24] Train loss=0.20962028205394745
[10/24] Train loss=0.23300638794898987
[15/24] Train loss=0.213576078414917
[20/24] Train loss=0.2048710286617279
Test set avg_accuracy=89.13% avg_sensitivity=73.27%, avg_specificity=95.03% avg_auc=93.01%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.222224 Test loss=0.278292 Current lr=[0.00029967723776099]

[0/24] Train loss=0.20909234881401062
[5/24] Train loss=0.19495481252670288
[10/24] Train loss=0.22947104275226593
[15/24] Train loss=0.19912923872470856
[20/24] Train loss=0.20403669774532318
Test set avg_accuracy=86.69% avg_sensitivity=80.37%, avg_specificity=89.05% avg_auc=91.55%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.216891 Test loss=0.329969 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.21155358850955963
[5/24] Train loss=0.20494019985198975
[10/24] Train loss=0.2287275791168213
[15/24] Train loss=0.2086653858423233
[20/24] Train loss=0.2154829502105713
Test set avg_accuracy=84.86% avg_sensitivity=85.60%, avg_specificity=84.58% avg_auc=92.68%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.221741 Test loss=0.339829 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2122427374124527
[5/24] Train loss=0.19761468470096588
[10/24] Train loss=0.22117562592029572
[15/24] Train loss=0.19815009832382202
[20/24] Train loss=0.21254611015319824
Test set avg_accuracy=88.37% avg_sensitivity=68.76%, avg_specificity=95.68% avg_auc=92.43%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.216958 Test loss=0.295440 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2161531299352646
[5/24] Train loss=0.19619202613830566
[10/24] Train loss=0.217703178524971
[15/24] Train loss=0.20186428725719452
[20/24] Train loss=0.19308987259864807
Test set avg_accuracy=81.42% avg_sensitivity=34.26%, avg_specificity=98.98% avg_auc=86.08%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.214187 Test loss=0.473972 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.22105088829994202
[5/24] Train loss=0.18909130990505219
[10/24] Train loss=0.23186340928077698
[15/24] Train loss=0.21407519280910492
[20/24] Train loss=0.20580342411994934
Test set avg_accuracy=88.95% avg_sensitivity=72.98%, avg_specificity=94.89% avg_auc=93.03%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.217872 Test loss=0.280108 Current lr=[0.000298904600941902]

[0/24] Train loss=0.21234771609306335
[5/24] Train loss=0.19242167472839355
[10/24] Train loss=0.22279883921146393
[15/24] Train loss=0.1901586651802063
[20/24] Train loss=0.19778312742710114
Test set avg_accuracy=88.53% avg_sensitivity=70.11%, avg_specificity=95.39% avg_auc=91.47%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.212725 Test loss=0.306953 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.1933647245168686
[5/24] Train loss=0.2028525471687317
[10/24] Train loss=0.22261840105056763
[15/24] Train loss=0.19135704636573792
[20/24] Train loss=0.19198580086231232
Test set avg_accuracy=86.74% avg_sensitivity=77.40%, avg_specificity=90.23% avg_auc=91.49%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.215672 Test loss=0.318696 Current lr=[0.000297555943323901]

[0/24] Train loss=0.21987108886241913
[5/24] Train loss=0.19605474174022675
[10/24] Train loss=0.22449955344200134
[15/24] Train loss=0.2013603001832962
[20/24] Train loss=0.19742615520954132
Test set avg_accuracy=89.35% avg_sensitivity=79.85%, avg_specificity=92.89% avg_auc=93.90%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.215080 Test loss=0.266539 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2126546949148178
[5/24] Train loss=0.18289490044116974
[10/24] Train loss=0.216349259018898
[15/24] Train loss=0.1935967206954956
[20/24] Train loss=0.18573656678199768
Test set avg_accuracy=88.93% avg_sensitivity=78.41%, avg_specificity=92.85% avg_auc=92.92%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.209259 Test loss=0.281326 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.20208096504211426
[5/24] Train loss=0.17668035626411438
[10/24] Train loss=0.21802817285060883
[15/24] Train loss=0.19353105127811432
[20/24] Train loss=0.19253221154212952
Test set avg_accuracy=89.28% avg_sensitivity=78.12%, avg_specificity=93.44% avg_auc=93.06%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.203880 Test loss=0.275585 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.19610336422920227
[5/24] Train loss=0.18540538847446442
[10/24] Train loss=0.22044792771339417
[15/24] Train loss=0.190142422914505
[20/24] Train loss=0.18892864882946014
Test set avg_accuracy=87.41% avg_sensitivity=73.13%, avg_specificity=92.73% avg_auc=91.74%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.204594 Test loss=0.310199 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.20631998777389526
[5/24] Train loss=0.19625550508499146
[10/24] Train loss=0.21127928793430328
[15/24] Train loss=0.20184098184108734
[20/24] Train loss=0.1905020773410797
Test set avg_accuracy=84.69% avg_sensitivity=85.32%, avg_specificity=84.45% avg_auc=92.16%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.211095 Test loss=0.354236 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.19783063232898712
[5/24] Train loss=0.20771826803684235
[10/24] Train loss=0.23312954604625702
[15/24] Train loss=0.18225635588169098
[20/24] Train loss=0.1819337010383606
Test set avg_accuracy=87.90% avg_sensitivity=69.87%, avg_specificity=94.62% avg_auc=91.75%
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.207511 Test loss=0.306404 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.19780059158802032
[5/24] Train loss=0.18721778690814972
[10/24] Train loss=0.21208134293556213
[15/24] Train loss=0.18629935383796692
[20/24] Train loss=0.1860944628715515
Test set avg_accuracy=85.42% avg_sensitivity=81.57%, avg_specificity=86.85% avg_auc=91.64%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.203856 Test loss=0.347406 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.1950269192457199
[5/24] Train loss=0.179096058011055
[10/24] Train loss=0.22368426620960236
[15/24] Train loss=0.1892540007829666
[20/24] Train loss=0.1907118707895279
Test set avg_accuracy=87.15% avg_sensitivity=64.49%, avg_specificity=95.59% avg_auc=90.09%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.201518 Test loss=0.329529 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.1959894299507141
[5/24] Train loss=0.1745903044939041
[10/24] Train loss=0.20901191234588623
[15/24] Train loss=0.18091870844364166
[20/24] Train loss=0.18905659019947052
Test set avg_accuracy=88.23% avg_sensitivity=79.56%, avg_specificity=91.46% avg_auc=93.32%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.197533 Test loss=0.284362 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.19375847280025482
[5/24] Train loss=0.18084825575351715
[10/24] Train loss=0.2067747712135315
[15/24] Train loss=0.18909180164337158
[20/24] Train loss=0.1822713315486908
Test set avg_accuracy=88.93% avg_sensitivity=81.29%, avg_specificity=91.78% avg_auc=93.15%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.194850 Test loss=0.278839 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.18584348261356354
[5/24] Train loss=0.16751433908939362
[10/24] Train loss=0.20542143285274506
[15/24] Train loss=0.17360877990722656
[20/24] Train loss=0.17744049429893494
Test set avg_accuracy=85.39% avg_sensitivity=55.66%, avg_specificity=96.46% avg_auc=88.06%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.195717 Test loss=0.364101 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2152576893568039
[5/24] Train loss=0.17651306092739105
[10/24] Train loss=0.2053595632314682
[15/24] Train loss=0.193723663687706
[20/24] Train loss=0.1909060925245285
Test set avg_accuracy=87.30% avg_sensitivity=82.92%, avg_specificity=88.94% avg_auc=92.52%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.195283 Test loss=0.313926 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.19037607312202454
[5/24] Train loss=0.16458140313625336
[10/24] Train loss=0.2097475528717041
[15/24] Train loss=0.17515534162521362
[20/24] Train loss=0.17913682758808136
Test set avg_accuracy=87.30% avg_sensitivity=69.19%, avg_specificity=94.05% avg_auc=91.19%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.192245 Test loss=0.314201 Current lr=[0.000276307469034998]

[0/24] Train loss=0.18264690041542053
[5/24] Train loss=0.17604076862335205
[10/24] Train loss=0.20558452606201172
[15/24] Train loss=0.17157867550849915
[20/24] Train loss=0.1792379915714264
Test set avg_accuracy=88.23% avg_sensitivity=76.20%, avg_specificity=92.71% avg_auc=92.42%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.192533 Test loss=0.289189 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.1954653263092041
[5/24] Train loss=0.16778981685638428
[10/24] Train loss=0.2039743810892105
[15/24] Train loss=0.18163719773292542
[20/24] Train loss=0.17557461559772491
Test set avg_accuracy=88.42% avg_sensitivity=76.97%, avg_specificity=92.69% avg_auc=92.26%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.192121 Test loss=0.291066 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.19305826723575592
[5/24] Train loss=0.18295638263225555
[10/24] Train loss=0.20424973964691162
[15/24] Train loss=0.18295864760875702
[20/24] Train loss=0.19400031864643097
Test set avg_accuracy=87.40% avg_sensitivity=80.18%, avg_specificity=90.08% avg_auc=92.22%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.195948 Test loss=0.307426 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.1892489641904831
[5/24] Train loss=0.18761053681373596
[10/24] Train loss=0.20651093125343323
[15/24] Train loss=0.17767660319805145
[20/24] Train loss=0.17225266993045807
Test set avg_accuracy=88.68% avg_sensitivity=68.86%, avg_specificity=96.07% avg_auc=91.74%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.189102 Test loss=0.300141 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.1880960315465927
[5/24] Train loss=0.17197181284427643
[10/24] Train loss=0.22371244430541992
[15/24] Train loss=0.18154916167259216
[20/24] Train loss=0.1828245371580124
Test set avg_accuracy=88.19% avg_sensitivity=75.43%, avg_specificity=92.94% avg_auc=91.99%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.194150 Test loss=0.299619 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.1972774863243103
[5/24] Train loss=0.17460308969020844
[10/24] Train loss=0.2039324939250946
[15/24] Train loss=0.17172206938266754
[20/24] Train loss=0.17837786674499512
Test set avg_accuracy=87.25% avg_sensitivity=69.58%, avg_specificity=93.83% avg_auc=90.80%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.193145 Test loss=0.322247 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.19152896106243134
[5/24] Train loss=0.17622843384742737
[10/24] Train loss=0.19865275919437408
[15/24] Train loss=0.17867130041122437
[20/24] Train loss=0.17177605628967285
Test set avg_accuracy=85.20% avg_sensitivity=83.59%, avg_specificity=85.79% avg_auc=91.69%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.190384 Test loss=0.354886 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.17562884092330933
[5/24] Train loss=0.1654062569141388
[10/24] Train loss=0.19772282242774963
[15/24] Train loss=0.1747446209192276
[20/24] Train loss=0.16731788218021393
Test set avg_accuracy=88.31% avg_sensitivity=71.93%, avg_specificity=94.41% avg_auc=91.38%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.185557 Test loss=0.302095 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.1770373433828354
[5/24] Train loss=0.16674388945102692
[10/24] Train loss=0.1947622448205948
[15/24] Train loss=0.18474625051021576
[20/24] Train loss=0.17444093525409698
Test set avg_accuracy=87.12% avg_sensitivity=71.93%, avg_specificity=92.78% avg_auc=90.97%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.182644 Test loss=0.319201 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.17886702716350555
[5/24] Train loss=0.16332446038722992
[10/24] Train loss=0.19884879887104034
[15/24] Train loss=0.17273785173892975
[20/24] Train loss=0.17336119711399078
Test set avg_accuracy=87.42% avg_sensitivity=81.29%, avg_specificity=89.71% avg_auc=92.54%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.185039 Test loss=0.307679 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.17611421644687653
[5/24] Train loss=0.1676768660545349
[10/24] Train loss=0.20061466097831726
[15/24] Train loss=0.16245576739311218
[20/24] Train loss=0.17053328454494476
Test set avg_accuracy=88.59% avg_sensitivity=70.25%, avg_specificity=95.43% avg_auc=92.56%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.182723 Test loss=0.292011 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.17877334356307983
[5/24] Train loss=0.16220715641975403
[10/24] Train loss=0.1941876858472824
[15/24] Train loss=0.17035941779613495
[20/24] Train loss=0.16600842773914337
Test set avg_accuracy=79.01% avg_sensitivity=85.60%, avg_specificity=76.55% avg_auc=88.95%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.180312 Test loss=0.462780 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.17806397378444672
[5/24] Train loss=0.16151635348796844
[10/24] Train loss=0.19813576340675354
[15/24] Train loss=0.1645854413509369
[20/24] Train loss=0.16996829211711884
Test set avg_accuracy=88.52% avg_sensitivity=76.34%, avg_specificity=93.05% avg_auc=92.44%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.183171 Test loss=0.289966 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.18042951822280884
[5/24] Train loss=0.17770177125930786
[10/24] Train loss=0.1998494416475296
[15/24] Train loss=0.16965456306934357
[20/24] Train loss=0.17185859382152557
Test set avg_accuracy=88.01% avg_sensitivity=72.84%, avg_specificity=93.66% avg_auc=92.33%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.184776 Test loss=0.296853 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.17699964344501495
[5/24] Train loss=0.16070662438869476
[10/24] Train loss=0.19475632905960083
[15/24] Train loss=0.17221152782440186
[20/24] Train loss=0.17267866432666779
Test set avg_accuracy=76.71% avg_sensitivity=88.96%, avg_specificity=72.14% avg_auc=90.50%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.186759 Test loss=0.481370 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17314912378787994
[5/24] Train loss=0.16575857996940613
[10/24] Train loss=0.18320167064666748
[15/24] Train loss=0.17535671591758728
[20/24] Train loss=0.18336379528045654
Test set avg_accuracy=88.65% avg_sensitivity=80.04%, avg_specificity=91.85% avg_auc=92.64%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.181508 Test loss=0.288610 Current lr=[0.000224838296036774]

[0/24] Train loss=0.17427882552146912
[5/24] Train loss=0.1674862951040268
[10/24] Train loss=0.18762391805648804
[15/24] Train loss=0.16462263464927673
[20/24] Train loss=0.163508802652359
Test set avg_accuracy=87.49% avg_sensitivity=80.52%, avg_specificity=90.08% avg_auc=91.87%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.180839 Test loss=0.310658 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.17164282500743866
[5/24] Train loss=0.16657215356826782
[10/24] Train loss=0.18652087450027466
[15/24] Train loss=0.16210907697677612
[20/24] Train loss=0.1648607701063156
Test set avg_accuracy=86.74% avg_sensitivity=73.22%, avg_specificity=91.78% avg_auc=90.66%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.179186 Test loss=0.322466 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.1768973171710968
[5/24] Train loss=0.16927441954612732
[10/24] Train loss=0.19234144687652588
[15/24] Train loss=0.16754789650440216
[20/24] Train loss=0.16450218856334686
Test set avg_accuracy=88.49% avg_sensitivity=73.18%, avg_specificity=94.19% avg_auc=92.11%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.178790 Test loss=0.293068 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.17056690156459808
[5/24] Train loss=0.15653541684150696
[10/24] Train loss=0.17669402062892914
[15/24] Train loss=0.16089674830436707
[20/24] Train loss=0.15692438185214996
Test set avg_accuracy=82.21% avg_sensitivity=84.74%, avg_specificity=81.27% avg_auc=90.27%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.177212 Test loss=0.409388 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.17340603470802307
[5/24] Train loss=0.15820877254009247
[10/24] Train loss=0.18172289431095123
[15/24] Train loss=0.16641665995121002
[20/24] Train loss=0.17084671556949615
Test set avg_accuracy=85.95% avg_sensitivity=84.45%, avg_specificity=86.51% avg_auc=92.36%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.177975 Test loss=0.334633 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.16879276931285858
[5/24] Train loss=0.15803678333759308
[10/24] Train loss=0.18310736119747162
[15/24] Train loss=0.17643240094184875
[20/24] Train loss=0.16107667982578278
Test set avg_accuracy=87.10% avg_sensitivity=75.58%, avg_specificity=91.39% avg_auc=91.04%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.177614 Test loss=0.320836 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1707303822040558
[5/24] Train loss=0.16276152431964874
[10/24] Train loss=0.1865987926721573
[15/24] Train loss=0.1628372222185135
[20/24] Train loss=0.16649794578552246
Test set avg_accuracy=88.01% avg_sensitivity=74.71%, avg_specificity=92.96% avg_auc=92.12%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.177193 Test loss=0.299040 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1633414924144745
[5/24] Train loss=0.1665971279144287
[10/24] Train loss=0.1835917830467224
[15/24] Train loss=0.1523621380329132
[20/24] Train loss=0.1620369255542755
Test set avg_accuracy=86.22% avg_sensitivity=84.26%, avg_specificity=86.95% avg_auc=92.08%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.173135 Test loss=0.336842 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.16013219952583313
[5/24] Train loss=0.1622515171766281
[10/24] Train loss=0.1780777871608734
[15/24] Train loss=0.16002745926380157
[20/24] Train loss=0.16100458800792694
Test set avg_accuracy=78.96% avg_sensitivity=85.08%, avg_specificity=76.68% avg_auc=88.65%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.172885 Test loss=0.473030 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.16475586593151093
[5/24] Train loss=0.1647178828716278
[10/24] Train loss=0.1826695054769516
[15/24] Train loss=0.15518392622470856
[20/24] Train loss=0.16639293730258942
Test set avg_accuracy=87.30% avg_sensitivity=76.25%, avg_specificity=91.42% avg_auc=91.30%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.171997 Test loss=0.315270 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.17008206248283386
[5/24] Train loss=0.15962450206279755
[10/24] Train loss=0.18062394857406616
[15/24] Train loss=0.16218777000904083
[20/24] Train loss=0.1637214571237564
Test set avg_accuracy=87.12% avg_sensitivity=68.67%, avg_specificity=94.00% avg_auc=90.20%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.172564 Test loss=0.330793 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.16619718074798584
[5/24] Train loss=0.15785859525203705
[10/24] Train loss=0.16904599964618683
[15/24] Train loss=0.15082257986068726
[20/24] Train loss=0.16187621653079987
Test set avg_accuracy=87.68% avg_sensitivity=75.62%, avg_specificity=92.17% avg_auc=92.08%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.170380 Test loss=0.300515 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.15786860883235931
[5/24] Train loss=0.15254440903663635
[10/24] Train loss=0.18050925433635712
[15/24] Train loss=0.16014282405376434
[20/24] Train loss=0.15727128088474274
Test set avg_accuracy=88.20% avg_sensitivity=74.18%, avg_specificity=93.42% avg_auc=91.64%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.167926 Test loss=0.304135 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.16535525023937225
[5/24] Train loss=0.1564696729183197
[10/24] Train loss=0.1675633192062378
[15/24] Train loss=0.15546980500221252
[20/24] Train loss=0.15857480466365814
Test set avg_accuracy=88.16% avg_sensitivity=70.25%, avg_specificity=94.84% avg_auc=91.40%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.167704 Test loss=0.309219 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.15976811945438385
[5/24] Train loss=0.16115716099739075
[10/24] Train loss=0.1754356473684311
[15/24] Train loss=0.15234693884849548
[20/24] Train loss=0.16209349036216736
Test set avg_accuracy=86.15% avg_sensitivity=69.43%, avg_specificity=92.37% avg_auc=90.43%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.170111 Test loss=0.334455 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.16485151648521423
[5/24] Train loss=0.1649330109357834
[10/24] Train loss=0.17934326827526093
[15/24] Train loss=0.15634895861148834
[20/24] Train loss=0.16356593370437622
Test set avg_accuracy=87.94% avg_sensitivity=68.76%, avg_specificity=95.09% avg_auc=90.72%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.170420 Test loss=0.319733 Current lr=[0.000156543481933168]

[0/24] Train loss=0.17202983796596527
[5/24] Train loss=0.15935176610946655
[10/24] Train loss=0.179387167096138
[15/24] Train loss=0.15812118351459503
[20/24] Train loss=0.15900689363479614
Test set avg_accuracy=88.44% avg_sensitivity=75.82%, avg_specificity=93.14% avg_auc=92.28%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.169375 Test loss=0.295332 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1619134098291397
[5/24] Train loss=0.15789780020713806
[10/24] Train loss=0.17449603974819183
[15/24] Train loss=0.16077230870723724
[20/24] Train loss=0.15504387021064758
Test set avg_accuracy=88.59% avg_sensitivity=73.03%, avg_specificity=94.39% avg_auc=91.83%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.167612 Test loss=0.299570 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.16102613508701324
[5/24] Train loss=0.1531326174736023
[10/24] Train loss=0.17553772032260895
[15/24] Train loss=0.15791137516498566
[20/24] Train loss=0.15407247841358185
Test set avg_accuracy=86.42% avg_sensitivity=58.01%, avg_specificity=97.00% avg_auc=88.77%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.165265 Test loss=0.361861 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.16471555829048157
[5/24] Train loss=0.15012019872665405
[10/24] Train loss=0.16778995096683502
[15/24] Train loss=0.14813530445098877
[20/24] Train loss=0.15957920253276825
Test set avg_accuracy=88.75% avg_sensitivity=71.45%, avg_specificity=95.19% avg_auc=91.50%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.166096 Test loss=0.304424 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15679027140140533
[5/24] Train loss=0.15131935477256775
[10/24] Train loss=0.1683191955089569
[15/24] Train loss=0.1581636518239975
[20/24] Train loss=0.15399576723575592
Test set avg_accuracy=87.79% avg_sensitivity=67.27%, avg_specificity=95.43% avg_auc=91.36%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.164537 Test loss=0.311184 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15359312295913696
[5/24] Train loss=0.1540343314409256
[10/24] Train loss=0.16834279894828796
[15/24] Train loss=0.1534755825996399
[20/24] Train loss=0.1503840982913971
Test set avg_accuracy=87.84% avg_sensitivity=68.04%, avg_specificity=95.21% avg_auc=90.35%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.164341 Test loss=0.321325 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15861578285694122
[5/24] Train loss=0.14951273798942566
[10/24] Train loss=0.1639239341020584
[15/24] Train loss=0.14725226163864136
[20/24] Train loss=0.15556326508522034
Test set avg_accuracy=87.53% avg_sensitivity=63.92%, avg_specificity=96.32% avg_auc=90.25%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.161786 Test loss=0.332695 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1583678424358368
[5/24] Train loss=0.15147726237773895
[10/24] Train loss=0.17628203332424164
[15/24] Train loss=0.1555827558040619
[20/24] Train loss=0.14630623161792755
Test set avg_accuracy=85.44% avg_sensitivity=52.74%, avg_specificity=97.62% avg_auc=87.90%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.159955 Test loss=0.394323 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15594667196273804
[5/24] Train loss=0.144180566072464
[10/24] Train loss=0.17180326581001282
[15/24] Train loss=0.1557401567697525
[20/24] Train loss=0.14969614148139954
Test set avg_accuracy=88.18% avg_sensitivity=68.52%, avg_specificity=95.50% avg_auc=91.14%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.159012 Test loss=0.312665 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.15105292201042175
[5/24] Train loss=0.14558131992816925
[10/24] Train loss=0.16925828158855438
[15/24] Train loss=0.1516469120979309
[20/24] Train loss=0.1461409628391266
Test set avg_accuracy=88.61% avg_sensitivity=73.85%, avg_specificity=94.10% avg_auc=91.84%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.156393 Test loss=0.293245 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1529323309659958
[5/24] Train loss=0.1506926268339157
[10/24] Train loss=0.16089430451393127
[15/24] Train loss=0.1576605588197708
[20/24] Train loss=0.14569008350372314
Test set avg_accuracy=88.71% avg_sensitivity=73.56%, avg_specificity=94.35% avg_auc=92.02%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.155642 Test loss=0.290605 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15306775271892548
[5/24] Train loss=0.1495109498500824
[10/24] Train loss=0.15698713064193726
[15/24] Train loss=0.1431899219751358
[20/24] Train loss=0.14580529928207397
Test set avg_accuracy=88.18% avg_sensitivity=74.23%, avg_specificity=93.37% avg_auc=91.79%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.154568 Test loss=0.302899 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15076765418052673
[5/24] Train loss=0.14910361170768738
[10/24] Train loss=0.15905654430389404
[15/24] Train loss=0.14343497157096863
[20/24] Train loss=0.14685991406440735
Test set avg_accuracy=88.52% avg_sensitivity=73.85%, avg_specificity=93.98% avg_auc=92.23%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.154822 Test loss=0.293852 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.15141119062900543
[5/24] Train loss=0.1428002119064331
[10/24] Train loss=0.16236931085586548
[15/24] Train loss=0.14792433381080627
[20/24] Train loss=0.1407705396413803
Test set avg_accuracy=88.78% avg_sensitivity=77.35%, avg_specificity=93.03% avg_auc=92.62%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.154604 Test loss=0.289562 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.1515635997056961
[5/24] Train loss=0.147194966673851
[10/24] Train loss=0.16706058382987976
[15/24] Train loss=0.1427449882030487
[20/24] Train loss=0.14599844813346863
Test set avg_accuracy=89.02% avg_sensitivity=75.67%, avg_specificity=94.00% avg_auc=92.10%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.154269 Test loss=0.293150 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1517413854598999
[5/24] Train loss=0.1437227874994278
[10/24] Train loss=0.15600071847438812
[15/24] Train loss=0.14308418333530426
[20/24] Train loss=0.14829595386981964
Test set avg_accuracy=88.44% avg_sensitivity=77.88%, avg_specificity=92.37% avg_auc=91.97%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.152022 Test loss=0.295325 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.15122033655643463
[5/24] Train loss=0.14938417077064514
[10/24] Train loss=0.15562690794467926
[15/24] Train loss=0.14325179159641266
[20/24] Train loss=0.14438529312610626
Test set avg_accuracy=88.23% avg_sensitivity=75.58%, avg_specificity=92.94% avg_auc=92.55%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.154137 Test loss=0.291756 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14893366396427155
[5/24] Train loss=0.14414915442466736
[10/24] Train loss=0.16255894303321838
[15/24] Train loss=0.1461275815963745
[20/24] Train loss=0.1472679227590561
Test set avg_accuracy=87.90% avg_sensitivity=75.34%, avg_specificity=92.58% avg_auc=92.28%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.153510 Test loss=0.300969 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.15234868228435516
[5/24] Train loss=0.138718843460083
[10/24] Train loss=0.16152970492839813
[15/24] Train loss=0.14223192632198334
[20/24] Train loss=0.14759941399097443
Test set avg_accuracy=89.04% avg_sensitivity=78.50%, avg_specificity=92.96% avg_auc=92.72%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.151133 Test loss=0.282526 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14697803556919098
[5/24] Train loss=0.14049044251441956
[10/24] Train loss=0.1503017544746399
[15/24] Train loss=0.13900868594646454
[20/24] Train loss=0.1362736076116562
Test set avg_accuracy=87.59% avg_sensitivity=79.22%, avg_specificity=90.71% avg_auc=92.37%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.149150 Test loss=0.303114 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14442580938339233
[5/24] Train loss=0.14489009976387024
[10/24] Train loss=0.152940571308136
[15/24] Train loss=0.13801829516887665
[20/24] Train loss=0.14088420569896698
Test set avg_accuracy=88.82% avg_sensitivity=76.30%, avg_specificity=93.48% avg_auc=92.42%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.147562 Test loss=0.288440 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14122551679611206
[5/24] Train loss=0.14081919193267822
[10/24] Train loss=0.14725594222545624
[15/24] Train loss=0.1356046199798584
[20/24] Train loss=0.13754211366176605
Test set avg_accuracy=88.05% avg_sensitivity=75.34%, avg_specificity=92.78% avg_auc=92.04%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.146628 Test loss=0.303582 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1493433266878128
[5/24] Train loss=0.1339477002620697
[10/24] Train loss=0.15207591652870178
[15/24] Train loss=0.1310216635465622
[20/24] Train loss=0.13696831464767456
Test set avg_accuracy=89.01% avg_sensitivity=75.77%, avg_specificity=93.94% avg_auc=92.81%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.144570 Test loss=0.284887 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14000533521175385
[5/24] Train loss=0.13545994460582733
[10/24] Train loss=0.1478433907032013
[15/24] Train loss=0.1346358358860016
[20/24] Train loss=0.1325732171535492
Test set avg_accuracy=88.78% avg_sensitivity=77.98%, avg_specificity=92.80% avg_auc=92.46%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.143221 Test loss=0.287747 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14300505816936493
[5/24] Train loss=0.13433106243610382
[10/24] Train loss=0.1433015912771225
[15/24] Train loss=0.13265186548233032
[20/24] Train loss=0.13380424678325653
Test set avg_accuracy=87.70% avg_sensitivity=81.24%, avg_specificity=90.10% avg_auc=92.38%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.141565 Test loss=0.299383 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.139439657330513
[5/24] Train loss=0.13390593230724335
[10/24] Train loss=0.14214955270290375
[15/24] Train loss=0.13366800546646118
[20/24] Train loss=0.13217385113239288
Test set avg_accuracy=88.50% avg_sensitivity=78.84%, avg_specificity=92.10% avg_auc=92.45%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.141707 Test loss=0.297368 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13765372335910797
[5/24] Train loss=0.13713569939136505
[10/24] Train loss=0.1443459391593933
[15/24] Train loss=0.1338633894920349
[20/24] Train loss=0.13413141667842865
Test set avg_accuracy=88.68% avg_sensitivity=78.26%, avg_specificity=92.57% avg_auc=92.20%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.140730 Test loss=0.291528 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13663892447948456
[5/24] Train loss=0.13117903470993042
[10/24] Train loss=0.14182984828948975
[15/24] Train loss=0.13156305253505707
[20/24] Train loss=0.13388414680957794
Test set avg_accuracy=88.54% avg_sensitivity=77.30%, avg_specificity=92.73% avg_auc=92.25%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.139161 Test loss=0.295059 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13629961013793945
[5/24] Train loss=0.1320156753063202
[10/24] Train loss=0.14487221837043762
[15/24] Train loss=0.1292772889137268
[20/24] Train loss=0.13601438701152802
Test set avg_accuracy=87.84% avg_sensitivity=78.60%, avg_specificity=91.28% avg_auc=92.19%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.138431 Test loss=0.303488 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13271938264369965
[5/24] Train loss=0.13218949735164642
[10/24] Train loss=0.13778197765350342
[15/24] Train loss=0.13119453191757202
[20/24] Train loss=0.1291702389717102
Test set avg_accuracy=88.31% avg_sensitivity=77.88%, avg_specificity=92.19% avg_auc=92.26%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.137925 Test loss=0.295887 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13370053470134735
[5/24] Train loss=0.13498027622699738
[10/24] Train loss=0.13749641180038452
[15/24] Train loss=0.13369064033031464
[20/24] Train loss=0.13308784365653992
Test set avg_accuracy=88.52% avg_sensitivity=76.54%, avg_specificity=92.98% avg_auc=91.95%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.137957 Test loss=0.296667 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13131484389305115
[5/24] Train loss=0.13042819499969482
[10/24] Train loss=0.1367609053850174
[15/24] Train loss=0.13138222694396973
[20/24] Train loss=0.13228091597557068
Test set avg_accuracy=88.59% avg_sensitivity=80.04%, avg_specificity=91.78% avg_auc=92.66%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.137985 Test loss=0.290570 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13069812953472137
[5/24] Train loss=0.13251574337482452
[10/24] Train loss=0.14079174399375916
[15/24] Train loss=0.1275346726179123
[20/24] Train loss=0.13242113590240479
Test set avg_accuracy=88.27% avg_sensitivity=78.93%, avg_specificity=91.74% avg_auc=92.08%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.137960 Test loss=0.299488 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13493040204048157
[5/24] Train loss=0.1315084993839264
[10/24] Train loss=0.13997915387153625
[15/24] Train loss=0.13095080852508545
[20/24] Train loss=0.13327686488628387
Test set avg_accuracy=89.15% avg_sensitivity=78.60%, avg_specificity=93.08% avg_auc=92.49%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.137217 Test loss=0.287900 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13205361366271973
[5/24] Train loss=0.13148866593837738
[10/24] Train loss=0.137513667345047
[15/24] Train loss=0.1285417228937149
[20/24] Train loss=0.12766428291797638
Test set avg_accuracy=88.95% avg_sensitivity=76.39%, avg_specificity=93.62% avg_auc=92.43%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.134678 Test loss=0.288188 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13165134191513062
[5/24] Train loss=0.1280260980129242
[10/24] Train loss=0.13290493190288544
[15/24] Train loss=0.12812817096710205
[20/24] Train loss=0.12706898152828217
Test set avg_accuracy=88.75% avg_sensitivity=77.54%, avg_specificity=92.92% avg_auc=92.75%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.133916 Test loss=0.286209 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13209298253059387
[5/24] Train loss=0.13163480162620544
[10/24] Train loss=0.1317748725414276
[15/24] Train loss=0.130410298705101
[20/24] Train loss=0.12732765078544617
Test set avg_accuracy=89.10% avg_sensitivity=77.06%, avg_specificity=93.58% avg_auc=92.46%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.133432 Test loss=0.288108 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1260797530412674
[5/24] Train loss=0.12751680612564087
[10/24] Train loss=0.13343386352062225
[15/24] Train loss=0.1293349266052246
[20/24] Train loss=0.12491928040981293
Test set avg_accuracy=88.93% avg_sensitivity=78.98%, avg_specificity=92.64% avg_auc=92.62%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.132656 Test loss=0.288193 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13147325813770294
[5/24] Train loss=0.12643694877624512
[10/24] Train loss=0.13171450793743134
[15/24] Train loss=0.12713314592838287
[20/24] Train loss=0.12370842695236206
Test set avg_accuracy=89.26% avg_sensitivity=78.45%, avg_specificity=93.28% avg_auc=92.44%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.132234 Test loss=0.288041 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1272977739572525
[5/24] Train loss=0.12865500152111053
[10/24] Train loss=0.131740540266037
[15/24] Train loss=0.1266820728778839
[20/24] Train loss=0.12480531632900238
Test set avg_accuracy=89.05% avg_sensitivity=76.44%, avg_specificity=93.75% avg_auc=92.20%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.131002 Test loss=0.292515 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12850803136825562
[5/24] Train loss=0.12318236380815506
[10/24] Train loss=0.13003623485565186
[15/24] Train loss=0.12558239698410034
[20/24] Train loss=0.12571175396442413
Test set avg_accuracy=89.06% avg_sensitivity=79.22%, avg_specificity=92.73% avg_auc=92.13%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.130308 Test loss=0.293383 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1284674108028412
[5/24] Train loss=0.12710176408290863
[10/24] Train loss=0.12822014093399048
[15/24] Train loss=0.12496812641620636
[20/24] Train loss=0.12450771778821945
Test set avg_accuracy=89.10% avg_sensitivity=78.07%, avg_specificity=93.21% avg_auc=92.34%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.129947 Test loss=0.290505 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12647958099842072
[5/24] Train loss=0.12559479475021362
[10/24] Train loss=0.1340080350637436
[15/24] Train loss=0.12361496686935425
[20/24] Train loss=0.12601260840892792
Test set avg_accuracy=89.06% avg_sensitivity=77.69%, avg_specificity=93.30% avg_auc=92.24%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.129861 Test loss=0.291067 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12692652642726898
[5/24] Train loss=0.1288856714963913
[10/24] Train loss=0.13010188937187195
[15/24] Train loss=0.12580172717571259
[20/24] Train loss=0.12416113913059235
Test set avg_accuracy=89.08% avg_sensitivity=77.74%, avg_specificity=93.30% avg_auc=92.39%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.129802 Test loss=0.288464 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12451226264238358
[5/24] Train loss=0.1259036660194397
[10/24] Train loss=0.12942396104335785
[15/24] Train loss=0.12399457395076752
[20/24] Train loss=0.12284905463457108
Test set avg_accuracy=89.11% avg_sensitivity=78.02%, avg_specificity=93.25% avg_auc=92.34%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.129444 Test loss=0.289137 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12544909119606018
[5/24] Train loss=0.12508100271224976
[10/24] Train loss=0.12862880527973175
[15/24] Train loss=0.12537060678005219
[20/24] Train loss=0.12461959570646286
Test set avg_accuracy=89.10% avg_sensitivity=77.64%, avg_specificity=93.37% avg_auc=92.34%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.128735 Test loss=0.288459 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12480991333723068
[5/24] Train loss=0.12309929728507996
[10/24] Train loss=0.129159614443779
[15/24] Train loss=0.12215685844421387
[20/24] Train loss=0.1252020299434662
Test set avg_accuracy=89.09% avg_sensitivity=77.98%, avg_specificity=93.23% avg_auc=92.37%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.128319 Test loss=0.288617 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12394820153713226
[5/24] Train loss=0.12248431146144867
[10/24] Train loss=0.12518100440502167
[15/24] Train loss=0.12318361550569534
[20/24] Train loss=0.12372825294733047
Test set avg_accuracy=89.11% avg_sensitivity=78.26%, avg_specificity=93.16% avg_auc=92.28%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.128134 Test loss=0.289070 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12452227622270584
[5/24] Train loss=0.12230885773897171
[10/24] Train loss=0.1285211592912674
[15/24] Train loss=0.12477394938468933
[20/24] Train loss=0.12384450435638428
Test set avg_accuracy=89.13% avg_sensitivity=77.98%, avg_specificity=93.28% avg_auc=92.30%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.128063 Test loss=0.288553 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1237390786409378
[5/24] Train loss=0.1253395676612854
[10/24] Train loss=0.13134223222732544
[15/24] Train loss=0.1227024495601654
[20/24] Train loss=0.12486027926206589
Test set avg_accuracy=89.14% avg_sensitivity=77.64%, avg_specificity=93.42% avg_auc=92.27%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.128267 Test loss=0.288733 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12219903618097305
[5/24] Train loss=0.12305368483066559
[10/24] Train loss=0.12544980645179749
[15/24] Train loss=0.12204425036907196
[20/24] Train loss=0.12416290491819382
Test set avg_accuracy=89.15% avg_sensitivity=77.78%, avg_specificity=93.39% avg_auc=92.27%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.127728 Test loss=0.288799 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12306497991085052
[5/24] Train loss=0.12500770390033722
[10/24] Train loss=0.1279086470603943
[15/24] Train loss=0.12244859337806702
[20/24] Train loss=0.12202844023704529
Test set avg_accuracy=89.11% avg_sensitivity=77.88%, avg_specificity=93.30% avg_auc=92.29%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.128050 Test loss=0.288936 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12329909205436707
[5/24] Train loss=0.12353388220071793
[10/24] Train loss=0.12824022769927979
[15/24] Train loss=0.12529611587524414
[20/24] Train loss=0.12155263125896454
Test set avg_accuracy=89.15% avg_sensitivity=77.88%, avg_specificity=93.35% avg_auc=92.28%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.128371 Test loss=0.288952 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12232545763254166
[5/24] Train loss=0.12338165193796158
[10/24] Train loss=0.13072890043258667
[15/24] Train loss=0.12474992126226425
[20/24] Train loss=0.12443670630455017
Test set avg_accuracy=89.17% avg_sensitivity=77.88%, avg_specificity=93.37% avg_auc=92.28%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.127692 Test loss=0.288827 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=89.43% sen=80.47%, spe=92.76%, auc=93.85%!
Fold[6] Avg_overlap=0.69%(±0.2299722525502234)
[0/24] Train loss=0.733307421207428
[5/24] Train loss=0.7251846790313721
[10/24] Train loss=0.7165218591690063
[15/24] Train loss=0.7065260410308838
[20/24] Train loss=0.7021128535270691
Test set avg_accuracy=56.99% avg_sensitivity=45.31%, avg_specificity=61.45% avg_auc=56.50%
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.717077 Test loss=0.673638 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7025784254074097
[5/24] Train loss=0.6941229701042175
[10/24] Train loss=0.6894201636314392
[15/24] Train loss=0.677123486995697
[20/24] Train loss=0.6707936525344849
Test set avg_accuracy=65.48% avg_sensitivity=56.34%, avg_specificity=68.97% avg_auc=68.74%
Best model saved!! Metric=-66.46956055761166!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.688094 Test loss=0.626159 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6677590012550354
[5/24] Train loss=0.6661711931228638
[10/24] Train loss=0.6649414300918579
[15/24] Train loss=0.6482069492340088
[20/24] Train loss=0.6403395533561707
Test set avg_accuracy=68.06% avg_sensitivity=66.01%, avg_specificity=68.84% avg_auc=74.61%
Best model saved!! Metric=-48.478322663560704!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.660574 Test loss=0.596985 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6462224721908569
[5/24] Train loss=0.6380146145820618
[10/24] Train loss=0.6395801901817322
[15/24] Train loss=0.6208271980285645
[20/24] Train loss=0.6114923357963562
Test set avg_accuracy=71.11% avg_sensitivity=70.58%, avg_specificity=71.31% avg_auc=78.40%
Best model saved!! Metric=-34.60144939120241!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.633861 Test loss=0.568799 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6145755648612976
[5/24] Train loss=0.6169188618659973
[10/24] Train loss=0.6180301308631897
[15/24] Train loss=0.5918406248092651
[20/24] Train loss=0.5840491056442261
Test set avg_accuracy=74.66% avg_sensitivity=71.71%, avg_specificity=75.79% avg_auc=80.67%
Best model saved!! Metric=-23.17078926580018!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.608036 Test loss=0.536675 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5841076374053955
[5/24] Train loss=0.5838992595672607
[10/24] Train loss=0.5954965949058533
[15/24] Train loss=0.5596206784248352
[20/24] Train loss=0.5527145862579346
Test set avg_accuracy=77.04% avg_sensitivity=72.61%, avg_specificity=78.74% avg_auc=82.87%
Best model saved!! Metric=-14.744436631970288!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.579893 Test loss=0.507629 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.553805947303772
[5/24] Train loss=0.5536229014396667
[10/24] Train loss=0.5632046461105347
[15/24] Train loss=0.5314881205558777
[20/24] Train loss=0.5199750065803528
Test set avg_accuracy=78.87% avg_sensitivity=75.25%, avg_specificity=80.25% avg_auc=85.34%
Best model saved!! Metric=-6.2999365210136204!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.551617 Test loss=0.479815 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5277912616729736
[5/24] Train loss=0.5230672955513
[10/24] Train loss=0.5364281535148621
[15/24] Train loss=0.49871009588241577
[20/24] Train loss=0.4912915825843811
Test set avg_accuracy=81.13% avg_sensitivity=74.35%, avg_specificity=83.72% avg_auc=86.87%
Best model saved!! Metric=0.0706398730541764!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.522595 Test loss=0.446108 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.49890846014022827
[5/24] Train loss=0.49013277888298035
[10/24] Train loss=0.5051060914993286
[15/24] Train loss=0.4691477417945862
[20/24] Train loss=0.462250679731369
Test set avg_accuracy=82.54% avg_sensitivity=75.72%, avg_specificity=85.14% avg_auc=88.71%
Best model saved!! Metric=6.106986681208497!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.494602 Test loss=0.420557 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.475126177072525
[5/24] Train loss=0.46001556515693665
[10/24] Train loss=0.47849205136299133
[15/24] Train loss=0.4412926733493805
[20/24] Train loss=0.4340541362762451
Test set avg_accuracy=84.10% avg_sensitivity=72.75%, avg_specificity=88.43% avg_auc=89.94%
Best model saved!! Metric=9.227909426574556!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.465549 Test loss=0.392187 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.44073599576950073
[5/24] Train loss=0.4330502450466156
[10/24] Train loss=0.4528837502002716
[15/24] Train loss=0.4139769971370697
[20/24] Train loss=0.40365907549858093
Test set avg_accuracy=85.18% avg_sensitivity=72.94%, avg_specificity=89.85% avg_auc=90.93%
Best model saved!! Metric=12.903570046913899!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.438464 Test loss=0.371652 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4128531217575073
[5/24] Train loss=0.4035623371601105
[10/24] Train loss=0.42465412616729736
[15/24] Train loss=0.39180976152420044
[20/24] Train loss=0.3769548535346985
Test set avg_accuracy=86.37% avg_sensitivity=73.74%, avg_specificity=91.19% avg_auc=91.85%
Best model saved!! Metric=17.141769437416613!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.412898 Test loss=0.350455 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3906216621398926
[5/24] Train loss=0.3739010989665985
[10/24] Train loss=0.4040171205997467
[15/24] Train loss=0.3677425980567932
[20/24] Train loss=0.35884082317352295
Test set avg_accuracy=86.98% avg_sensitivity=69.73%, avg_specificity=93.56% avg_auc=92.07%
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.390481 Test loss=0.336851 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3706877827644348
[5/24] Train loss=0.35452529788017273
[10/24] Train loss=0.3903760612010956
[15/24] Train loss=0.35080498456954956
[20/24] Train loss=0.34038978815078735
Test set avg_accuracy=87.41% avg_sensitivity=70.44%, avg_specificity=93.88% avg_auc=92.68%
Best model saved!! Metric=18.409310206411433!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.373173 Test loss=0.323793 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3611949384212494
[5/24] Train loss=0.34479930996894836
[10/24] Train loss=0.374344140291214
[15/24] Train loss=0.34015873074531555
[20/24] Train loss=0.3365415036678314
Test set avg_accuracy=88.06% avg_sensitivity=73.31%, avg_specificity=93.69% avg_auc=93.37%
Best model saved!! Metric=22.425669902067014!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.358685 Test loss=0.311939 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.336995005607605
[5/24] Train loss=0.32119113206863403
[10/24] Train loss=0.36490491032600403
[15/24] Train loss=0.32488203048706055
[20/24] Train loss=0.31654199957847595
Test set avg_accuracy=87.89% avg_sensitivity=69.21%, avg_specificity=95.02% avg_auc=93.48%
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.343637 Test loss=0.306216 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.32722869515419006
[5/24] Train loss=0.30990397930145264
[10/24] Train loss=0.3458196818828583
[15/24] Train loss=0.31121161580085754
[20/24] Train loss=0.2999202311038971
Test set avg_accuracy=88.78% avg_sensitivity=75.11%, avg_specificity=93.99% avg_auc=93.98%
Best model saved!! Metric=25.85399698359224!!
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.332701 Test loss=0.294812 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3104657530784607
[5/24] Train loss=0.29547566175460815
[10/24] Train loss=0.3393303155899048
[15/24] Train loss=0.30888983607292175
[20/24] Train loss=0.2894015908241272
Test set avg_accuracy=88.93% avg_sensitivity=75.20%, avg_specificity=94.17% avg_auc=94.16%
Best model saved!! Metric=26.461308202581307!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.321402 Test loss=0.287622 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.31030359864234924
[5/24] Train loss=0.28967800736427307
[10/24] Train loss=0.3317864239215851
[15/24] Train loss=0.29284778237342834
[20/24] Train loss=0.282642126083374
Test set avg_accuracy=88.98% avg_sensitivity=76.14%, avg_specificity=93.88% avg_auc=94.46%
Best model saved!! Metric=27.466588389791667!!
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.313587 Test loss=0.281489 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.29948681592941284
[5/24] Train loss=0.2738431394100189
[10/24] Train loss=0.32522767782211304
[15/24] Train loss=0.2855633497238159
[20/24] Train loss=0.2758042514324188
Test set avg_accuracy=88.63% avg_sensitivity=73.31%, avg_specificity=94.48% avg_auc=94.44%
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.304366 Test loss=0.279210 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.29122215509414673
[5/24] Train loss=0.2643607258796692
[10/24] Train loss=0.31883203983306885
[15/24] Train loss=0.27894777059555054
[20/24] Train loss=0.267657995223999
Test set avg_accuracy=88.93% avg_sensitivity=73.08%, avg_specificity=94.98% avg_auc=94.47%
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.298596 Test loss=0.276174 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2860856354236603
[5/24] Train loss=0.2623213231563568
[10/24] Train loss=0.30990439653396606
[15/24] Train loss=0.2719554901123047
[20/24] Train loss=0.26073017716407776
Test set avg_accuracy=88.62% avg_sensitivity=70.58%, avg_specificity=95.50% avg_auc=94.30%
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.293677 Test loss=0.280136 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.28594934940338135
[5/24] Train loss=0.2515795826911926
[10/24] Train loss=0.31019410490989685
[15/24] Train loss=0.2682599425315857
[20/24] Train loss=0.25179147720336914
Test set avg_accuracy=88.78% avg_sensitivity=70.72%, avg_specificity=95.66% avg_auc=94.72%
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.285894 Test loss=0.273436 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.27398595213890076
[5/24] Train loss=0.24506612122058868
[10/24] Train loss=0.3024948239326477
[15/24] Train loss=0.26024097204208374
[20/24] Train loss=0.2520289719104767
Test set avg_accuracy=88.85% avg_sensitivity=71.24%, avg_specificity=95.57% avg_auc=94.72%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.280807 Test loss=0.271240 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.27175283432006836
[5/24] Train loss=0.24952921271324158
[10/24] Train loss=0.30195704102516174
[15/24] Train loss=0.2554050087928772
[20/24] Train loss=0.24729929864406586
Test set avg_accuracy=87.20% avg_sensitivity=60.82%, avg_specificity=97.27% avg_auc=93.92%
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.277164 Test loss=0.302784 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.27366018295288086
[5/24] Train loss=0.2467004656791687
[10/24] Train loss=0.28433656692504883
[15/24] Train loss=0.25430282950401306
[20/24] Train loss=0.24161644279956818
Test set avg_accuracy=88.37% avg_sensitivity=67.99%, avg_specificity=96.15% avg_auc=94.46%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.271799 Test loss=0.278923 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2670469880104065
[5/24] Train loss=0.24039509892463684
[10/24] Train loss=0.28939273953437805
[15/24] Train loss=0.24595026671886444
[20/24] Train loss=0.23963305354118347
Test set avg_accuracy=87.90% avg_sensitivity=65.21%, avg_specificity=96.56% avg_auc=94.09%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.266472 Test loss=0.290172 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2623573839664459
[5/24] Train loss=0.2304365336894989
[10/24] Train loss=0.2817680537700653
[15/24] Train loss=0.25121673941612244
[20/24] Train loss=0.23758536577224731
Test set avg_accuracy=87.68% avg_sensitivity=64.17%, avg_specificity=96.65% avg_auc=94.01%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.265381 Test loss=0.290678 Current lr=[0.000210185142098938]

[0/24] Train loss=0.255559504032135
[5/24] Train loss=0.23476378619670868
[10/24] Train loss=0.27719753980636597
[15/24] Train loss=0.24520429968833923
[20/24] Train loss=0.23995140194892883
Test set avg_accuracy=86.51% avg_sensitivity=57.14%, avg_specificity=97.72% avg_auc=93.68%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.260385 Test loss=0.317428 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2582560181617737
[5/24] Train loss=0.23081618547439575
[10/24] Train loss=0.27225998044013977
[15/24] Train loss=0.24170920252799988
[20/24] Train loss=0.22902722656726837
Test set avg_accuracy=85.79% avg_sensitivity=53.47%, avg_specificity=98.13% avg_auc=93.33%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.256474 Test loss=0.334224 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2516814172267914
[5/24] Train loss=0.2203725129365921
[10/24] Train loss=0.27365344762802124
[15/24] Train loss=0.24069872498512268
[20/24] Train loss=0.22749389708042145
Test set avg_accuracy=85.38% avg_sensitivity=52.66%, avg_specificity=97.86% avg_auc=92.52%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.252355 Test loss=0.354124 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.24535825848579407
[5/24] Train loss=0.22038646042346954
[10/24] Train loss=0.2736988067626953
[15/24] Train loss=0.23030011355876923
[20/24] Train loss=0.22056370973587036
Test set avg_accuracy=87.21% avg_sensitivity=62.05%, avg_specificity=96.82% avg_auc=94.01%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.249294 Test loss=0.298524 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.25209593772888184
[5/24] Train loss=0.2145969718694687
[10/24] Train loss=0.2653444707393646
[15/24] Train loss=0.2400486171245575
[20/24] Train loss=0.2222922444343567
Test set avg_accuracy=85.95% avg_sensitivity=54.55%, avg_specificity=97.93% avg_auc=92.24%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.244769 Test loss=0.337313 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2544570863246918
[5/24] Train loss=0.224915012717247
[10/24] Train loss=0.2668288052082062
[15/24] Train loss=0.23660098016262054
[20/24] Train loss=0.22496943175792694
Test set avg_accuracy=87.84% avg_sensitivity=66.24%, avg_specificity=96.08% avg_auc=93.95%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.245323 Test loss=0.286836 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2443084865808487
[5/24] Train loss=0.2072262167930603
[10/24] Train loss=0.25473031401634216
[15/24] Train loss=0.22692136466503143
[20/24] Train loss=0.22724473476409912
Test set avg_accuracy=85.70% avg_sensitivity=53.65%, avg_specificity=97.93% avg_auc=93.08%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.239685 Test loss=0.331123 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.23386959731578827
[5/24] Train loss=0.21438193321228027
[10/24] Train loss=0.2570156157016754
[15/24] Train loss=0.22702057659626007
[20/24] Train loss=0.22005611658096313
Test set avg_accuracy=86.42% avg_sensitivity=58.09%, avg_specificity=97.23% avg_auc=92.62%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.239767 Test loss=0.335357 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.23411300778388977
[5/24] Train loss=0.2121998518705368
[10/24] Train loss=0.26260051131248474
[15/24] Train loss=0.2462666928768158
[20/24] Train loss=0.22585278749465942
Test set avg_accuracy=88.65% avg_sensitivity=71.24%, avg_specificity=95.29% avg_auc=94.08%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.241271 Test loss=0.275385 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.23231647908687592
[5/24] Train loss=0.20930227637290955
[10/24] Train loss=0.2568933963775635
[15/24] Train loss=0.23874536156654358
[20/24] Train loss=0.21549318730831146
Test set avg_accuracy=86.56% avg_sensitivity=62.00%, avg_specificity=95.93% avg_auc=90.71%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.238080 Test loss=0.333386 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.22830986976623535
[5/24] Train loss=0.20340296626091003
[10/24] Train loss=0.2598678469657898
[15/24] Train loss=0.23613056540489197
[20/24] Train loss=0.21663914620876312
Test set avg_accuracy=82.29% avg_sensitivity=39.04%, avg_specificity=98.79% avg_auc=88.17%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.236727 Test loss=0.442719 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.22882023453712463
[5/24] Train loss=0.1897178739309311
[10/24] Train loss=0.24958868324756622
[15/24] Train loss=0.23689404129981995
[20/24] Train loss=0.21545352041721344
Test set avg_accuracy=87.53% avg_sensitivity=65.35%, avg_specificity=95.99% avg_auc=93.33%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.231404 Test loss=0.298879 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.22283247113227844
[5/24] Train loss=0.18589408695697784
[10/24] Train loss=0.24606531858444214
[15/24] Train loss=0.22897043824195862
[20/24] Train loss=0.22736290097236633
Test set avg_accuracy=81.85% avg_sensitivity=37.53%, avg_specificity=98.76% avg_auc=88.48%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.229343 Test loss=0.452653 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.22098994255065918
[5/24] Train loss=0.19284430146217346
[10/24] Train loss=0.26074790954589844
[15/24] Train loss=0.22679588198661804
[20/24] Train loss=0.21077696979045868
Test set avg_accuracy=86.73% avg_sensitivity=59.55%, avg_specificity=97.10% avg_auc=93.64%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.229369 Test loss=0.308845 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2096008062362671
[5/24] Train loss=0.1988600492477417
[10/24] Train loss=0.26011040806770325
[15/24] Train loss=0.23871135711669922
[20/24] Train loss=0.21006958186626434
Test set avg_accuracy=88.39% avg_sensitivity=73.88%, avg_specificity=93.92% avg_auc=93.81%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.229771 Test loss=0.280583 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.22321149706840515
[5/24] Train loss=0.18725605309009552
[10/24] Train loss=0.24342451989650726
[15/24] Train loss=0.21877361834049225
[20/24] Train loss=0.2124091535806656
Test set avg_accuracy=86.95% avg_sensitivity=67.94%, avg_specificity=94.21% avg_auc=92.51%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.225566 Test loss=0.307595 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2280729115009308
[5/24] Train loss=0.19446730613708496
[10/24] Train loss=0.23865126073360443
[15/24] Train loss=0.22094514966011047
[20/24] Train loss=0.2121252417564392
Test set avg_accuracy=87.53% avg_sensitivity=73.13%, avg_specificity=93.02% avg_auc=93.63%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.225448 Test loss=0.290608 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.21938826143741608
[5/24] Train loss=0.1982828825712204
[10/24] Train loss=0.241096630692482
[15/24] Train loss=0.22165703773498535
[20/24] Train loss=0.20886562764644623
Test set avg_accuracy=85.44% avg_sensitivity=54.60%, avg_specificity=97.21% avg_auc=91.35%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.221344 Test loss=0.344874 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.21151641011238098
[5/24] Train loss=0.19191494584083557
[10/24] Train loss=0.23781272768974304
[15/24] Train loss=0.22297263145446777
[20/24] Train loss=0.2105867713689804
Test set avg_accuracy=87.11% avg_sensitivity=75.91%, avg_specificity=91.38% avg_auc=92.97%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.219888 Test loss=0.300579 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2168605476617813
[5/24] Train loss=0.21862520277500153
[10/24] Train loss=0.23456326127052307
[15/24] Train loss=0.20930670201778412
[20/24] Train loss=0.20749929547309875
Test set avg_accuracy=78.24% avg_sensitivity=23.48%, avg_specificity=99.14% avg_auc=82.63%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.223690 Test loss=0.595447 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.22702434659004211
[5/24] Train loss=0.20089268684387207
[10/24] Train loss=0.23495306074619293
[15/24] Train loss=0.224740669131279
[20/24] Train loss=0.20337340235710144
Test set avg_accuracy=84.75% avg_sensitivity=50.26%, avg_specificity=97.91% avg_auc=90.01%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.218316 Test loss=0.374371 Current lr=[0.000298904600941902]

[0/24] Train loss=0.21226508915424347
[5/24] Train loss=0.1866185963153839
[10/24] Train loss=0.2313726544380188
[15/24] Train loss=0.20809893310070038
[20/24] Train loss=0.19986464083194733
Test set avg_accuracy=77.53% avg_sensitivity=20.23%, avg_specificity=99.39% avg_auc=81.32%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.214517 Test loss=0.617187 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.20507122576236725
[5/24] Train loss=0.18226395547389984
[10/24] Train loss=0.23089709877967834
[15/24] Train loss=0.2142467498779297
[20/24] Train loss=0.20200365781784058
Test set avg_accuracy=80.79% avg_sensitivity=33.62%, avg_specificity=98.79% avg_auc=85.67%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.212803 Test loss=0.511542 Current lr=[0.000297555943323901]

[0/24] Train loss=0.20936152338981628
[5/24] Train loss=0.17981186509132385
[10/24] Train loss=0.23649926483631134
[15/24] Train loss=0.2228064239025116
[20/24] Train loss=0.20332114398479462
Test set avg_accuracy=84.00% avg_sensitivity=46.96%, avg_specificity=98.13% avg_auc=88.07%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.218180 Test loss=0.420950 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.21467992663383484
[5/24] Train loss=0.1998077780008316
[10/24] Train loss=0.22559837996959686
[15/24] Train loss=0.21923403441905975
[20/24] Train loss=0.20432698726654053
Test set avg_accuracy=86.86% avg_sensitivity=61.20%, avg_specificity=96.65% avg_auc=92.38%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.217622 Test loss=0.326964 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.20929007232189178
[5/24] Train loss=0.1900988072156906
[10/24] Train loss=0.24007277190685272
[15/24] Train loss=0.2122957408428192
[20/24] Train loss=0.20948919653892517
Test set avg_accuracy=84.06% avg_sensitivity=48.28%, avg_specificity=97.72% avg_auc=87.20%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.214271 Test loss=0.442828 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2103222906589508
[5/24] Train loss=0.1852056235074997
[10/24] Train loss=0.2341679334640503
[15/24] Train loss=0.2172088772058487
[20/24] Train loss=0.20639930665493011
Test set avg_accuracy=81.97% avg_sensitivity=37.81%, avg_specificity=98.81% avg_auc=87.16%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.215637 Test loss=0.460423 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.20386652648448944
[5/24] Train loss=0.18128234148025513
[10/24] Train loss=0.22491855919361115
[15/24] Train loss=0.21555691957473755
[20/24] Train loss=0.20338265597820282
Test set avg_accuracy=87.11% avg_sensitivity=63.51%, avg_specificity=96.11% avg_auc=92.56%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.212213 Test loss=0.314800 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.19704551994800568
[5/24] Train loss=0.1698538213968277
[10/24] Train loss=0.22535143792629242
[15/24] Train loss=0.21950393915176392
[20/24] Train loss=0.20581510663032532
Test set avg_accuracy=88.05% avg_sensitivity=77.84%, avg_specificity=91.94% avg_auc=93.95%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.210306 Test loss=0.281929 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.20507006347179413
[5/24] Train loss=0.17474941909313202
[10/24] Train loss=0.2242630124092102
[15/24] Train loss=0.21941176056861877
[20/24] Train loss=0.1997462809085846
Test set avg_accuracy=88.44% avg_sensitivity=73.03%, avg_specificity=94.32% avg_auc=94.14%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.210970 Test loss=0.275985 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2015628218650818
[5/24] Train loss=0.17082606256008148
[10/24] Train loss=0.22552242875099182
[15/24] Train loss=0.20369645953178406
[20/24] Train loss=0.19891802966594696
Test set avg_accuracy=88.27% avg_sensitivity=73.69%, avg_specificity=93.83% avg_auc=93.54%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.205416 Test loss=0.285847 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.19220127165317535
[5/24] Train loss=0.17496895790100098
[10/24] Train loss=0.22664566338062286
[15/24] Train loss=0.2067999243736267
[20/24] Train loss=0.20083403587341309
Test set avg_accuracy=83.96% avg_sensitivity=47.52%, avg_specificity=97.86% avg_auc=90.08%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.204731 Test loss=0.381890 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.20677819848060608
[5/24] Train loss=0.16406196355819702
[10/24] Train loss=0.21844062209129333
[15/24] Train loss=0.20592747628688812
[20/24] Train loss=0.18939518928527832
Test set avg_accuracy=86.65% avg_sensitivity=64.64%, avg_specificity=95.05% avg_auc=92.01%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.201928 Test loss=0.323792 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.19716709852218628
[5/24] Train loss=0.17464259266853333
[10/24] Train loss=0.2234089970588684
[15/24] Train loss=0.21122682094573975
[20/24] Train loss=0.1877456158399582
Test set avg_accuracy=88.11% avg_sensitivity=74.02%, avg_specificity=93.49% avg_auc=93.95%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.201723 Test loss=0.280336 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.18721824884414673
[5/24] Train loss=0.17910729348659515
[10/24] Train loss=0.23060964047908783
[15/24] Train loss=0.21683120727539062
[20/24] Train loss=0.18911010026931763
Test set avg_accuracy=85.96% avg_sensitivity=57.99%, avg_specificity=96.64% avg_auc=91.77%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.201786 Test loss=0.342048 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.1923311948776245
[5/24] Train loss=0.17079970240592957
[10/24] Train loss=0.20878589153289795
[15/24] Train loss=0.20368675887584686
[20/24] Train loss=0.18574096262454987
Test set avg_accuracy=82.32% avg_sensitivity=39.89%, avg_specificity=98.51% avg_auc=85.29%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.199149 Test loss=0.470528 Current lr=[0.000276307469034998]

[0/24] Train loss=0.20252282917499542
[5/24] Train loss=0.17392797768115997
[10/24] Train loss=0.23293446004390717
[15/24] Train loss=0.2069263607263565
[20/24] Train loss=0.18331484496593475
Test set avg_accuracy=85.18% avg_sensitivity=53.47%, avg_specificity=97.28% avg_auc=90.69%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.202262 Test loss=0.377225 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.1838122457265854
[5/24] Train loss=0.16148047149181366
[10/24] Train loss=0.21235139667987823
[15/24] Train loss=0.20877350866794586
[20/24] Train loss=0.1951509416103363
Test set avg_accuracy=84.15% avg_sensitivity=48.28%, avg_specificity=97.84% avg_auc=89.87%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.199280 Test loss=0.406620 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.19476740062236786
[5/24] Train loss=0.1670977622270584
[10/24] Train loss=0.21786189079284668
[15/24] Train loss=0.20055460929870605
[20/24] Train loss=0.18612462282180786
Test set avg_accuracy=87.45% avg_sensitivity=66.34%, avg_specificity=95.50% avg_auc=92.47%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.195184 Test loss=0.312253 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.1905866414308548
[5/24] Train loss=0.1706622987985611
[10/24] Train loss=0.21812321245670319
[15/24] Train loss=0.1935776323080063
[20/24] Train loss=0.18462763726711273
Test set avg_accuracy=84.23% avg_sensitivity=50.59%, avg_specificity=97.07% avg_auc=88.26%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.194693 Test loss=0.403809 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.18280565738677979
[5/24] Train loss=0.15681277215480804
[10/24] Train loss=0.2103232741355896
[15/24] Train loss=0.19471490383148193
[20/24] Train loss=0.1873733103275299
Test set avg_accuracy=88.18% avg_sensitivity=76.80%, avg_specificity=92.52% avg_auc=93.03%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.191761 Test loss=0.292267 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.19272971153259277
[5/24] Train loss=0.15239961445331573
[10/24] Train loss=0.20528171956539154
[15/24] Train loss=0.19925883412361145
[20/24] Train loss=0.18181824684143066
Test set avg_accuracy=86.20% avg_sensitivity=57.52%, avg_specificity=97.14% avg_auc=90.55%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.190773 Test loss=0.345592 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.18983960151672363
[5/24] Train loss=0.16232925653457642
[10/24] Train loss=0.20955078303813934
[15/24] Train loss=0.19220411777496338
[20/24] Train loss=0.19184811413288116
Test set avg_accuracy=88.11% avg_sensitivity=73.69%, avg_specificity=93.61% avg_auc=93.32%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.188784 Test loss=0.286476 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.19461524486541748
[5/24] Train loss=0.15878407657146454
[10/24] Train loss=0.22401395440101624
[15/24] Train loss=0.19061988592147827
[20/24] Train loss=0.18369083106517792
Test set avg_accuracy=86.08% avg_sensitivity=59.08%, avg_specificity=96.38% avg_auc=89.67%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.191079 Test loss=0.348388 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.18983875215053558
[5/24] Train loss=0.1640082448720932
[10/24] Train loss=0.21384859085083008
[15/24] Train loss=0.20253148674964905
[20/24] Train loss=0.18380051851272583
Test set avg_accuracy=85.90% avg_sensitivity=57.24%, avg_specificity=96.83% avg_auc=89.26%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.195068 Test loss=0.369761 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.18469128012657166
[5/24] Train loss=0.16365036368370056
[10/24] Train loss=0.2254147231578827
[15/24] Train loss=0.1927640736103058
[20/24] Train loss=0.19804149866104126
Test set avg_accuracy=87.92% avg_sensitivity=69.59%, avg_specificity=94.91% avg_auc=92.55%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.198057 Test loss=0.299788 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.1820562481880188
[5/24] Train loss=0.16665545105934143
[10/24] Train loss=0.21273337304592133
[15/24] Train loss=0.2015717625617981
[20/24] Train loss=0.18801362812519073
Test set avg_accuracy=82.38% avg_sensitivity=40.12%, avg_specificity=98.51% avg_auc=86.23%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.192521 Test loss=0.458545 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.18956789374351501
[5/24] Train loss=0.15436042845249176
[10/24] Train loss=0.22252967953681946
[15/24] Train loss=0.19335350394248962
[20/24] Train loss=0.20141258835792542
Test set avg_accuracy=85.35% avg_sensitivity=60.73%, avg_specificity=94.75% avg_auc=90.27%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.196779 Test loss=0.352112 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.1900041401386261
[5/24] Train loss=0.1740284115076065
[10/24] Train loss=0.22614216804504395
[15/24] Train loss=0.1903337836265564
[20/24] Train loss=0.18995915353298187
Test set avg_accuracy=81.03% avg_sensitivity=35.69%, avg_specificity=98.33% avg_auc=79.52%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.193425 Test loss=0.522799 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.18986620008945465
[5/24] Train loss=0.158792644739151
[10/24] Train loss=0.21142582595348358
[15/24] Train loss=0.19417943060398102
[20/24] Train loss=0.1899954229593277
Test set avg_accuracy=85.87% avg_sensitivity=56.67%, avg_specificity=97.01% avg_auc=86.92%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.189709 Test loss=0.375283 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.1823437511920929
[5/24] Train loss=0.15579523146152496
[10/24] Train loss=0.20290160179138184
[15/24] Train loss=0.19063550233840942
[20/24] Train loss=0.18948571383953094
Test set avg_accuracy=83.74% avg_sensitivity=47.38%, avg_specificity=97.61% avg_auc=87.04%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.188442 Test loss=0.417873 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.1895606964826584
[5/24] Train loss=0.1595183163881302
[10/24] Train loss=0.21731185913085938
[15/24] Train loss=0.19676139950752258
[20/24] Train loss=0.18551985919475555
Test set avg_accuracy=74.51% avg_sensitivity=8.86%, avg_specificity=99.55% avg_auc=77.40%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.191919 Test loss=0.653764 Current lr=[0.000224838296036774]

[0/24] Train loss=0.18149781227111816
[5/24] Train loss=0.15720470249652863
[10/24] Train loss=0.205540731549263
[15/24] Train loss=0.18460680544376373
[20/24] Train loss=0.18020682036876678
Test set avg_accuracy=84.43% avg_sensitivity=50.87%, avg_specificity=97.23% avg_auc=85.53%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.185300 Test loss=0.407839 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.1750287264585495
[5/24] Train loss=0.1540517508983612
[10/24] Train loss=0.21087487041950226
[15/24] Train loss=0.18963265419006348
[20/24] Train loss=0.18298228085041046
Test set avg_accuracy=86.85% avg_sensitivity=60.73%, avg_specificity=96.82% avg_auc=89.78%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.190682 Test loss=0.347179 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.18290551006793976
[5/24] Train loss=0.15147696435451508
[10/24] Train loss=0.21999575197696686
[15/24] Train loss=0.1853223294019699
[20/24] Train loss=0.1744844913482666
Test set avg_accuracy=88.39% avg_sensitivity=80.29%, avg_specificity=91.47% avg_auc=93.70%
Best model saved!! Metric=27.85061325185599!!
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.185702 Test loss=0.283327 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.17307151854038239
[5/24] Train loss=0.1585116684436798
[10/24] Train loss=0.20408500730991364
[15/24] Train loss=0.18711848556995392
[20/24] Train loss=0.18401481211185455
Test set avg_accuracy=87.40% avg_sensitivity=79.02%, avg_specificity=90.59% avg_auc=92.33%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.182467 Test loss=0.311212 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.17232146859169006
[5/24] Train loss=0.1505003273487091
[10/24] Train loss=0.20785857737064362
[15/24] Train loss=0.18846382200717926
[20/24] Train loss=0.17404194176197052
Test set avg_accuracy=85.46% avg_sensitivity=62.28%, avg_specificity=94.30% avg_auc=87.35%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.183619 Test loss=0.368083 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.1871669441461563
[5/24] Train loss=0.16040562093257904
[10/24] Train loss=0.20592001080513
[15/24] Train loss=0.17830096185207367
[20/24] Train loss=0.17594081163406372
Test set avg_accuracy=86.77% avg_sensitivity=65.58%, avg_specificity=94.86% avg_auc=91.02%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.182427 Test loss=0.325502 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.17164604365825653
[5/24] Train loss=0.1660381406545639
[10/24] Train loss=0.20596441626548767
[15/24] Train loss=0.1791182905435562
[20/24] Train loss=0.17512181401252747
Test set avg_accuracy=86.77% avg_sensitivity=65.25%, avg_specificity=94.98% avg_auc=90.14%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.180725 Test loss=0.345436 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.17405463755130768
[5/24] Train loss=0.15096834301948547
[10/24] Train loss=0.2067408263683319
[15/24] Train loss=0.17281574010849
[20/24] Train loss=0.17702150344848633
Test set avg_accuracy=85.00% avg_sensitivity=53.47%, avg_specificity=97.03% avg_auc=86.90%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.181114 Test loss=0.406581 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.16658549010753632
[5/24] Train loss=0.15100817382335663
[10/24] Train loss=0.20440375804901123
[15/24] Train loss=0.18028493225574493
[20/24] Train loss=0.17770761251449585
Test set avg_accuracy=88.22% avg_sensitivity=77.98%, avg_specificity=92.12% avg_auc=92.53%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.180007 Test loss=0.296973 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.17917948961257935
[5/24] Train loss=0.14595240354537964
[10/24] Train loss=0.2024143636226654
[15/24] Train loss=0.18237003684043884
[20/24] Train loss=0.17041561007499695
Test set avg_accuracy=85.70% avg_sensitivity=57.57%, avg_specificity=96.44% avg_auc=89.96%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.181261 Test loss=0.358769 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1714393049478531
[5/24] Train loss=0.14818283915519714
[10/24] Train loss=0.19222792983055115
[15/24] Train loss=0.18699423968791962
[20/24] Train loss=0.1681545376777649
Test set avg_accuracy=86.67% avg_sensitivity=63.93%, avg_specificity=95.34% avg_auc=89.84%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.177168 Test loss=0.341472 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.17683567106723785
[5/24] Train loss=0.15141096711158752
[10/24] Train loss=0.19656912982463837
[15/24] Train loss=0.16914142668247223
[20/24] Train loss=0.17470236122608185
Test set avg_accuracy=87.75% avg_sensitivity=70.53%, avg_specificity=94.32% avg_auc=92.54%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.174427 Test loss=0.300665 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1720496267080307
[5/24] Train loss=0.14372524619102478
[10/24] Train loss=0.1800907403230667
[15/24] Train loss=0.17079244554042816
[20/24] Train loss=0.176878422498703
Test set avg_accuracy=87.73% avg_sensitivity=70.20%, avg_specificity=94.42% avg_auc=92.55%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.173673 Test loss=0.300270 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.16486239433288574
[5/24] Train loss=0.15087251365184784
[10/24] Train loss=0.18305005133152008
[15/24] Train loss=0.17239443957805634
[20/24] Train loss=0.16951267421245575
Test set avg_accuracy=87.84% avg_sensitivity=77.27%, avg_specificity=91.87% avg_auc=92.37%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.173781 Test loss=0.304161 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.16492997109889984
[5/24] Train loss=0.14780700206756592
[10/24] Train loss=0.1839137226343155
[15/24] Train loss=0.17681603133678436
[20/24] Train loss=0.17343522608280182
Test set avg_accuracy=88.54% avg_sensitivity=83.26%, avg_specificity=90.56% avg_auc=93.77%
Best model saved!! Metric=30.131451240683376!!
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.172383 Test loss=0.287804 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.16747601330280304
[5/24] Train loss=0.1428796499967575
[10/24] Train loss=0.1725204586982727
[15/24] Train loss=0.17589592933654785
[20/24] Train loss=0.1707293540239334
Test set avg_accuracy=84.60% avg_sensitivity=49.65%, avg_specificity=97.93% avg_auc=86.63%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.170990 Test loss=0.438160 Current lr=[0.000156543481933168]

[0/24] Train loss=0.16551950573921204
[5/24] Train loss=0.1537092924118042
[10/24] Train loss=0.18178193271160126
[15/24] Train loss=0.16394668817520142
[20/24] Train loss=0.1721690446138382
Test set avg_accuracy=88.41% avg_sensitivity=72.37%, avg_specificity=94.53% avg_auc=93.44%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.168179 Test loss=0.287507 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.15975554287433624
[5/24] Train loss=0.14454492926597595
[10/24] Train loss=0.1713668256998062
[15/24] Train loss=0.16620592772960663
[20/24] Train loss=0.1697586178779602
Test set avg_accuracy=88.71% avg_sensitivity=72.28%, avg_specificity=94.98% avg_auc=92.94%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.168609 Test loss=0.291173 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.16644370555877686
[5/24] Train loss=0.14487357437610626
[10/24] Train loss=0.17633740603923798
[15/24] Train loss=0.16971269249916077
[20/24] Train loss=0.17327648401260376
Test set avg_accuracy=86.82% avg_sensitivity=59.78%, avg_specificity=97.14% avg_auc=91.60%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.166531 Test loss=0.331647 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15179190039634705
[5/24] Train loss=0.1360936015844345
[10/24] Train loss=0.18290956318378448
[15/24] Train loss=0.17233668267726898
[20/24] Train loss=0.1627752184867859
Test set avg_accuracy=87.59% avg_sensitivity=66.67%, avg_specificity=95.57% avg_auc=92.69%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.164956 Test loss=0.312104 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.16012556850910187
[5/24] Train loss=0.1524372547864914
[10/24] Train loss=0.1715622842311859
[15/24] Train loss=0.1638011932373047
[20/24] Train loss=0.16396959125995636
Test set avg_accuracy=87.84% avg_sensitivity=74.82%, avg_specificity=92.80% avg_auc=92.75%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.164683 Test loss=0.298116 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1543915867805481
[5/24] Train loss=0.13593769073486328
[10/24] Train loss=0.17389309406280518
[15/24] Train loss=0.16537828743457794
[20/24] Train loss=0.17150695621967316
Test set avg_accuracy=87.33% avg_sensitivity=65.58%, avg_specificity=95.63% avg_auc=91.89%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.162818 Test loss=0.317062 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15182019770145416
[5/24] Train loss=0.14114463329315186
[10/24] Train loss=0.16886845231056213
[15/24] Train loss=0.16479159891605377
[20/24] Train loss=0.15836575627326965
Test set avg_accuracy=87.04% avg_sensitivity=64.50%, avg_specificity=95.65% avg_auc=91.68%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.160695 Test loss=0.324445 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.15581023693084717
[5/24] Train loss=0.13824625313282013
[10/24] Train loss=0.1586758941411972
[15/24] Train loss=0.16397632658481598
[20/24] Train loss=0.16341206431388855
Test set avg_accuracy=88.68% avg_sensitivity=76.05%, avg_specificity=93.51% avg_auc=94.00%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.159377 Test loss=0.276198 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15011517703533173
[5/24] Train loss=0.1367712765932083
[10/24] Train loss=0.16162513196468353
[15/24] Train loss=0.15303878486156464
[20/24] Train loss=0.15986904501914978
Test set avg_accuracy=88.26% avg_sensitivity=72.42%, avg_specificity=94.30% avg_auc=93.60%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.155602 Test loss=0.287878 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14735347032546997
[5/24] Train loss=0.13188478350639343
[10/24] Train loss=0.1487232893705368
[15/24] Train loss=0.15479066967964172
[20/24] Train loss=0.15485425293445587
Test set avg_accuracy=88.72% avg_sensitivity=78.64%, avg_specificity=92.57% avg_auc=94.33%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.154117 Test loss=0.276995 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1543271243572235
[5/24] Train loss=0.13377444446086884
[10/24] Train loss=0.15483132004737854
[15/24] Train loss=0.1592056155204773
[20/24] Train loss=0.1540105789899826
Test set avg_accuracy=88.23% avg_sensitivity=71.43%, avg_specificity=94.64% avg_auc=93.14%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.154495 Test loss=0.293966 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1489817351102829
[5/24] Train loss=0.1360471099615097
[10/24] Train loss=0.15968869626522064
[15/24] Train loss=0.15300120413303375
[20/24] Train loss=0.1508771777153015
Test set avg_accuracy=87.38% avg_sensitivity=64.45%, avg_specificity=96.13% avg_auc=91.05%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.154129 Test loss=0.328787 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.14880621433258057
[5/24] Train loss=0.13286970555782318
[10/24] Train loss=0.15684844553470612
[15/24] Train loss=0.15656057000160217
[20/24] Train loss=0.15573741495609283
Test set avg_accuracy=88.36% avg_sensitivity=76.19%, avg_specificity=93.00% avg_auc=93.84%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.155289 Test loss=0.284039 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.15297673642635345
[5/24] Train loss=0.13371042907238007
[10/24] Train loss=0.1616210639476776
[15/24] Train loss=0.15192297101020813
[20/24] Train loss=0.15481054782867432
Test set avg_accuracy=88.50% avg_sensitivity=76.38%, avg_specificity=93.13% avg_auc=93.85%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.153537 Test loss=0.277973 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15136036276817322
[5/24] Train loss=0.134153351187706
[10/24] Train loss=0.15860988199710846
[15/24] Train loss=0.1530175358057022
[20/24] Train loss=0.1541033238172531
Test set avg_accuracy=85.47% avg_sensitivity=54.13%, avg_specificity=97.43% avg_auc=87.60%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.155032 Test loss=0.389852 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.15106409788131714
[5/24] Train loss=0.13430210947990417
[10/24] Train loss=0.15455295145511627
[15/24] Train loss=0.1548195481300354
[20/24] Train loss=0.1506115049123764
Test set avg_accuracy=87.84% avg_sensitivity=65.16%, avg_specificity=96.49% avg_auc=91.32%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.154830 Test loss=0.323020 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14659200608730316
[5/24] Train loss=0.1309487223625183
[10/24] Train loss=0.1530868262052536
[15/24] Train loss=0.14781852066516876
[20/24] Train loss=0.15459267795085907
Test set avg_accuracy=88.27% avg_sensitivity=76.14%, avg_specificity=92.89% avg_auc=93.50%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.153317 Test loss=0.283325 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14917238056659698
[5/24] Train loss=0.13068006932735443
[10/24] Train loss=0.14882485568523407
[15/24] Train loss=0.1528075784444809
[20/24] Train loss=0.1533016860485077
Test set avg_accuracy=86.95% avg_sensitivity=62.33%, avg_specificity=96.35% avg_auc=90.95%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.151637 Test loss=0.338181 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14902904629707336
[5/24] Train loss=0.12950126826763153
[10/24] Train loss=0.15435512363910675
[15/24] Train loss=0.14804333448410034
[20/24] Train loss=0.1559397429227829
Test set avg_accuracy=86.85% avg_sensitivity=65.25%, avg_specificity=95.09% avg_auc=91.74%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.150708 Test loss=0.327073 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14818939566612244
[5/24] Train loss=0.12579894065856934
[10/24] Train loss=0.15006469190120697
[15/24] Train loss=0.14491765201091766
[20/24] Train loss=0.1476896107196808
Test set avg_accuracy=88.14% avg_sensitivity=73.17%, avg_specificity=93.85% avg_auc=93.33%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.149441 Test loss=0.291709 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14819854497909546
[5/24] Train loss=0.12663081288337708
[10/24] Train loss=0.1457957923412323
[15/24] Train loss=0.14752919971942902
[20/24] Train loss=0.14585131406784058
Test set avg_accuracy=87.94% avg_sensitivity=71.48%, avg_specificity=94.23% avg_auc=93.50%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.145688 Test loss=0.290634 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14390650391578674
[5/24] Train loss=0.1296764612197876
[10/24] Train loss=0.1505967527627945
[15/24] Train loss=0.14131155610084534
[20/24] Train loss=0.14696964621543884
Test set avg_accuracy=88.02% avg_sensitivity=72.37%, avg_specificity=93.99% avg_auc=93.47%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.144647 Test loss=0.291044 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1399717777967453
[5/24] Train loss=0.12350017577409744
[10/24] Train loss=0.14399518072605133
[15/24] Train loss=0.14393842220306396
[20/24] Train loss=0.1430654674768448
Test set avg_accuracy=87.80% avg_sensitivity=69.64%, avg_specificity=94.73% avg_auc=93.21%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.143125 Test loss=0.301983 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1480005979537964
[5/24] Train loss=0.12521079182624817
[10/24] Train loss=0.1457599699497223
[15/24] Train loss=0.14480020105838776
[20/24] Train loss=0.14416632056236267
Test set avg_accuracy=87.57% avg_sensitivity=70.53%, avg_specificity=94.06% avg_auc=93.07%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.142898 Test loss=0.296914 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14141550660133362
[5/24] Train loss=0.12536418437957764
[10/24] Train loss=0.13809671998023987
[15/24] Train loss=0.1470290571451187
[20/24] Train loss=0.1471559703350067
Test set avg_accuracy=88.48% avg_sensitivity=74.07%, avg_specificity=93.97% avg_auc=93.69%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.141790 Test loss=0.286772 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1388828605413437
[5/24] Train loss=0.12087327986955643
[10/24] Train loss=0.13703638315200806
[15/24] Train loss=0.13839668035507202
[20/24] Train loss=0.14206552505493164
Test set avg_accuracy=88.36% avg_sensitivity=72.51%, avg_specificity=94.41% avg_auc=93.02%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.140772 Test loss=0.295199 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13800984621047974
[5/24] Train loss=0.12028989940881729
[10/24] Train loss=0.1452430784702301
[15/24] Train loss=0.14068934321403503
[20/24] Train loss=0.13948139548301697
Test set avg_accuracy=88.01% avg_sensitivity=71.33%, avg_specificity=94.37% avg_auc=92.65%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.140266 Test loss=0.299101 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13858932256698608
[5/24] Train loss=0.12209337949752808
[10/24] Train loss=0.14298385381698608
[15/24] Train loss=0.13773007690906525
[20/24] Train loss=0.13937368988990784
Test set avg_accuracy=87.59% avg_sensitivity=67.99%, avg_specificity=95.07% avg_auc=91.91%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.138610 Test loss=0.317809 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1387859731912613
[5/24] Train loss=0.12039285153150558
[10/24] Train loss=0.13936637341976166
[15/24] Train loss=0.13673332333564758
[20/24] Train loss=0.13922272622585297
Test set avg_accuracy=87.64% avg_sensitivity=66.67%, avg_specificity=95.65% avg_auc=91.30%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.138360 Test loss=0.321938 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1379653960466385
[5/24] Train loss=0.12088180333375931
[10/24] Train loss=0.13834638893604279
[15/24] Train loss=0.1385214626789093
[20/24] Train loss=0.1373155564069748
Test set avg_accuracy=88.16% avg_sensitivity=68.93%, avg_specificity=95.50% avg_auc=92.76%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.136885 Test loss=0.300664 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1349189579486847
[5/24] Train loss=0.12174053490161896
[10/24] Train loss=0.1354736089706421
[15/24] Train loss=0.13316650688648224
[20/24] Train loss=0.14268606901168823
Test set avg_accuracy=87.73% avg_sensitivity=72.47%, avg_specificity=93.56% avg_auc=92.94%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.136469 Test loss=0.297496 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.14089295268058777
[5/24] Train loss=0.1208663061261177
[10/24] Train loss=0.13569492101669312
[15/24] Train loss=0.13702349364757538
[20/24] Train loss=0.13828560709953308
Test set avg_accuracy=88.36% avg_sensitivity=75.77%, avg_specificity=93.16% avg_auc=93.40%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.137292 Test loss=0.285622 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13715778291225433
[5/24] Train loss=0.11975039541721344
[10/24] Train loss=0.13586920499801636
[15/24] Train loss=0.139756441116333
[20/24] Train loss=0.1361396759748459
Test set avg_accuracy=88.10% avg_sensitivity=76.57%, avg_specificity=92.50% avg_auc=93.15%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.136799 Test loss=0.293873 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13411271572113037
[5/24] Train loss=0.12155023217201233
[10/24] Train loss=0.1351204365491867
[15/24] Train loss=0.13669094443321228
[20/24] Train loss=0.13473975658416748
Test set avg_accuracy=88.40% avg_sensitivity=80.25%, avg_specificity=91.51% avg_auc=93.70%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.136379 Test loss=0.284988 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13379508256912231
[5/24] Train loss=0.12073522806167603
[10/24] Train loss=0.13330787420272827
[15/24] Train loss=0.1330195665359497
[20/24] Train loss=0.13901762664318085
Test set avg_accuracy=88.28% avg_sensitivity=71.57%, avg_specificity=94.66% avg_auc=93.11%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.135128 Test loss=0.294971 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13360141217708588
[5/24] Train loss=0.1211063340306282
[10/24] Train loss=0.13391049206256866
[15/24] Train loss=0.12910020351409912
[20/24] Train loss=0.1416447013616562
Test set avg_accuracy=88.74% avg_sensitivity=75.15%, avg_specificity=93.92% avg_auc=93.68%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.135510 Test loss=0.282746 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13479888439178467
[5/24] Train loss=0.11798344552516937
[10/24] Train loss=0.13424208760261536
[15/24] Train loss=0.12739604711532593
[20/24] Train loss=0.1333039253950119
Test set avg_accuracy=88.71% avg_sensitivity=75.39%, avg_specificity=93.79% avg_auc=93.60%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.133377 Test loss=0.283240 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13471703231334686
[5/24] Train loss=0.11676008254289627
[10/24] Train loss=0.12956400215625763
[15/24] Train loss=0.1305430382490158
[20/24] Train loss=0.13589462637901306
Test set avg_accuracy=88.83% avg_sensitivity=75.39%, avg_specificity=93.96% avg_auc=93.82%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.131960 Test loss=0.283009 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13096390664577484
[5/24] Train loss=0.1201351210474968
[10/24] Train loss=0.12773588299751282
[15/24] Train loss=0.12999312579631805
[20/24] Train loss=0.13231247663497925
Test set avg_accuracy=88.61% avg_sensitivity=74.40%, avg_specificity=94.03% avg_auc=93.53%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.131112 Test loss=0.285347 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13477638363838196
[5/24] Train loss=0.11777520924806595
[10/24] Train loss=0.13015814125537872
[15/24] Train loss=0.1297208070755005
[20/24] Train loss=0.1322442591190338
Test set avg_accuracy=88.71% avg_sensitivity=74.82%, avg_specificity=94.01% avg_auc=93.50%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.130784 Test loss=0.283594 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.13176414370536804
[5/24] Train loss=0.11578309535980225
[10/24] Train loss=0.12823575735092163
[15/24] Train loss=0.12664027512073517
[20/24] Train loss=0.12931011617183685
Test set avg_accuracy=88.84% avg_sensitivity=75.77%, avg_specificity=93.83% avg_auc=93.45%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.130209 Test loss=0.282601 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12922097742557526
[5/24] Train loss=0.1137915849685669
[10/24] Train loss=0.12894557416439056
[15/24] Train loss=0.12748531997203827
[20/24] Train loss=0.13124117255210876
Test set avg_accuracy=88.57% avg_sensitivity=73.22%, avg_specificity=94.42% avg_auc=93.17%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.129564 Test loss=0.288203 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1311827152967453
[5/24] Train loss=0.11436909437179565
[10/24] Train loss=0.13062189519405365
[15/24] Train loss=0.1272650957107544
[20/24] Train loss=0.12878650426864624
Test set avg_accuracy=88.83% avg_sensitivity=75.34%, avg_specificity=93.97% avg_auc=93.33%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.129191 Test loss=0.283276 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12861350178718567
[5/24] Train loss=0.11653048545122147
[10/24] Train loss=0.1286962479352951
[15/24] Train loss=0.127630352973938
[20/24] Train loss=0.13057132065296173
Test set avg_accuracy=88.61% avg_sensitivity=73.83%, avg_specificity=94.24% avg_auc=93.30%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.129172 Test loss=0.285867 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1309128701686859
[5/24] Train loss=0.11609026044607162
[10/24] Train loss=0.13001590967178345
[15/24] Train loss=0.12665414810180664
[20/24] Train loss=0.1317276507616043
Test set avg_accuracy=88.55% avg_sensitivity=74.63%, avg_specificity=93.87% avg_auc=93.34%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.128956 Test loss=0.285009 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12963445484638214
[5/24] Train loss=0.1134374812245369
[10/24] Train loss=0.1247432604432106
[15/24] Train loss=0.12496041506528854
[20/24] Train loss=0.13252803683280945
Test set avg_accuracy=88.68% avg_sensitivity=74.26%, avg_specificity=94.19% avg_auc=93.31%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.128630 Test loss=0.285948 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1276015341281891
[5/24] Train loss=0.11604304611682892
[10/24] Train loss=0.12800508737564087
[15/24] Train loss=0.12575247883796692
[20/24] Train loss=0.13121004402637482
Test set avg_accuracy=88.49% avg_sensitivity=73.13%, avg_specificity=94.35% avg_auc=93.32%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.128189 Test loss=0.286400 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12695901095867157
[5/24] Train loss=0.11433500796556473
[10/24] Train loss=0.12507732212543488
[15/24] Train loss=0.12350745499134064
[20/24] Train loss=0.13195626437664032
Test set avg_accuracy=88.80% avg_sensitivity=74.73%, avg_specificity=94.17% avg_auc=93.34%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.128432 Test loss=0.284593 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12650363147258759
[5/24] Train loss=0.11707569658756256
[10/24] Train loss=0.12663744390010834
[15/24] Train loss=0.1268598437309265
[20/24] Train loss=0.12980470061302185
Test set avg_accuracy=88.63% avg_sensitivity=74.02%, avg_specificity=94.21% avg_auc=93.31%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.127910 Test loss=0.285684 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1272231936454773
[5/24] Train loss=0.11452610790729523
[10/24] Train loss=0.12534432113170624
[15/24] Train loss=0.12466403841972351
[20/24] Train loss=0.12994077801704407
Test set avg_accuracy=88.61% avg_sensitivity=73.88%, avg_specificity=94.23% avg_auc=93.26%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.127359 Test loss=0.286453 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12725894153118134
[5/24] Train loss=0.1154787540435791
[10/24] Train loss=0.12631717324256897
[15/24] Train loss=0.12484815716743469
[20/24] Train loss=0.13107101619243622
Test set avg_accuracy=88.63% avg_sensitivity=73.93%, avg_specificity=94.24% avg_auc=93.24%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.127905 Test loss=0.286507 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12980598211288452
[5/24] Train loss=0.115364208817482
[10/24] Train loss=0.12520606815814972
[15/24] Train loss=0.12505756318569183
[20/24] Train loss=0.12762154638767242
Test set avg_accuracy=88.67% avg_sensitivity=73.97%, avg_specificity=94.28% avg_auc=93.26%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.128334 Test loss=0.286429 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12673930823802948
[5/24] Train loss=0.11493653059005737
[10/24] Train loss=0.12676654756069183
[15/24] Train loss=0.12558689713478088
[20/24] Train loss=0.1289648413658142
Test set avg_accuracy=88.61% avg_sensitivity=73.93%, avg_specificity=94.21% avg_auc=93.26%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.127782 Test loss=0.286434 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12905660271644592
[5/24] Train loss=0.11256597191095352
[10/24] Train loss=0.12746445834636688
[15/24] Train loss=0.12339698523283005
[20/24] Train loss=0.1279698610305786
Test set avg_accuracy=88.62% avg_sensitivity=73.93%, avg_specificity=94.23% avg_auc=93.25%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.127367 Test loss=0.286489 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=88.54% sen=83.26%, spe=90.56%, auc=93.77%!
Fold[7] Avg_overlap=0.70%(±0.22342203908928665)
[0/24] Train loss=0.7622122764587402
[5/24] Train loss=0.7568991184234619
[10/24] Train loss=0.7519441246986389
[15/24] Train loss=0.733507513999939
[20/24] Train loss=0.737770140171051
Test set avg_accuracy=53.85% avg_sensitivity=49.46%, avg_specificity=55.33% avg_auc=54.43%
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.746247 Test loss=0.693057 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7187378406524658
[5/24] Train loss=0.7192440032958984
[10/24] Train loss=0.7177407741546631
[15/24] Train loss=0.7192568182945251
[20/24] Train loss=0.6983479261398315
Test set avg_accuracy=59.34% avg_sensitivity=63.02%, avg_specificity=58.10% avg_auc=64.27%
Best model saved!! Metric=-81.26773256839458!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.716732 Test loss=0.665199 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.702809751033783
[5/24] Train loss=0.6973669528961182
[10/24] Train loss=0.6928123235702515
[15/24] Train loss=0.6798723340034485
[20/24] Train loss=0.6770775318145752
Test set avg_accuracy=63.33% avg_sensitivity=70.12%, avg_specificity=61.05% avg_auc=71.22%
Best model saved!! Metric=-60.27496888733071!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.690002 Test loss=0.636561 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6693243980407715
[5/24] Train loss=0.6720552444458008
[10/24] Train loss=0.6665752530097961
[15/24] Train loss=0.6514385938644409
[20/24] Train loss=0.6419520378112793
Test set avg_accuracy=67.29% avg_sensitivity=74.37%, avg_specificity=64.92% avg_auc=76.13%
Best model saved!! Metric=-43.29526845338529!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.662077 Test loss=0.610459 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6300661563873291
[5/24] Train loss=0.6325384974479675
[10/24] Train loss=0.6355906128883362
[15/24] Train loss=0.6120009422302246
[20/24] Train loss=0.6130611300468445
Test set avg_accuracy=70.68% avg_sensitivity=79.39%, avg_specificity=67.75% avg_auc=80.23%
Best model saved!! Metric=-27.950772870060163!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.630423 Test loss=0.584748 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.600796103477478
[5/24] Train loss=0.6024130582809448
[10/24] Train loss=0.6051893830299377
[15/24] Train loss=0.5788277387619019
[20/24] Train loss=0.5727664232254028
Test set avg_accuracy=73.62% avg_sensitivity=80.84%, avg_specificity=71.19% avg_auc=82.90%
Best model saved!! Metric=-17.450976050214535!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.597852 Test loss=0.548561 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5655612945556641
[5/24] Train loss=0.5668178796768188
[10/24] Train loss=0.5772331953048706
[15/24] Train loss=0.553450882434845
[20/24] Train loss=0.5357406735420227
Test set avg_accuracy=75.91% avg_sensitivity=81.05%, avg_specificity=74.19% avg_auc=85.23%
Best model saved!! Metric=-9.629295337469216!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.568031 Test loss=0.515440 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5364487171173096
[5/24] Train loss=0.5392650961875916
[10/24] Train loss=0.5393796563148499
[15/24] Train loss=0.5161689519882202
[20/24] Train loss=0.5068827867507935
Test set avg_accuracy=78.83% avg_sensitivity=81.46%, avg_specificity=77.94% avg_auc=87.02%
Best model saved!! Metric=-0.7425497999944781!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.535966 Test loss=0.478457 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.49981266260147095
[5/24] Train loss=0.5076854825019836
[10/24] Train loss=0.5140464901924133
[15/24] Train loss=0.49249473214149475
[20/24] Train loss=0.4677425026893616
Test set avg_accuracy=81.02% avg_sensitivity=82.13%, avg_specificity=80.64% avg_auc=88.69%
Best model saved!! Metric=6.476775697498212!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.505736 Test loss=0.448837 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4757537543773651
[5/24] Train loss=0.47353434562683105
[10/24] Train loss=0.4838329553604126
[15/24] Train loss=0.45994409918785095
[20/24] Train loss=0.4386015236377716
Test set avg_accuracy=83.31% avg_sensitivity=81.56%, avg_specificity=83.89% avg_auc=89.80%
Best model saved!! Metric=12.563734617274605!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.475140 Test loss=0.419943 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.45033735036849976
[5/24] Train loss=0.4473303258419037
[10/24] Train loss=0.4552047848701477
[15/24] Train loss=0.4352685213088989
[20/24] Train loss=0.40539833903312683
Test set avg_accuracy=86.15% avg_sensitivity=78.51%, avg_specificity=88.71% avg_auc=90.78%
Best model saved!! Metric=18.144139660716604!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.447297 Test loss=0.378618 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4191367030143738
[5/24] Train loss=0.4155988097190857
[10/24] Train loss=0.4364485740661621
[15/24] Train loss=0.41027209162712097
[20/24] Train loss=0.38442856073379517
Test set avg_accuracy=86.85% avg_sensitivity=78.97%, avg_specificity=89.49% avg_auc=91.69%
Best model saved!! Metric=21.006544112104308!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.422223 Test loss=0.358771 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3968859612941742
[5/24] Train loss=0.39580944180488586
[10/24] Train loss=0.41884252429008484
[15/24] Train loss=0.3882455825805664
[20/24] Train loss=0.3622492849826813
Test set avg_accuracy=87.79% avg_sensitivity=76.44%, avg_specificity=91.60% avg_auc=92.31%
Best model saved!! Metric=22.129508560067663!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.400840 Test loss=0.337859 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.37317347526550293
[5/24] Train loss=0.37394583225250244
[10/24] Train loss=0.39180314540863037
[15/24] Train loss=0.3728889226913452
[20/24] Train loss=0.34093645215034485
Test set avg_accuracy=88.32% avg_sensitivity=72.04%, avg_specificity=93.79% avg_auc=92.47%
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.381041 Test loss=0.320466 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3532266914844513
[5/24] Train loss=0.35347628593444824
[10/24] Train loss=0.37509429454803467
[15/24] Train loss=0.3551779091358185
[20/24] Train loss=0.3172398507595062
Test set avg_accuracy=88.88% avg_sensitivity=73.38%, avg_specificity=94.09% avg_auc=92.88%
Best model saved!! Metric=23.230397351413075!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.363227 Test loss=0.308667 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.34000688791275024
[5/24] Train loss=0.3448787331581116
[10/24] Train loss=0.35847875475883484
[15/24] Train loss=0.3407762944698334
[20/24] Train loss=0.3055824041366577
Test set avg_accuracy=89.01% avg_sensitivity=74.05%, avg_specificity=94.03% avg_auc=93.24%
Best model saved!! Metric=24.33765174566946!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.349486 Test loss=0.298869 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3244655132293701
[5/24] Train loss=0.3246484398841858
[10/24] Train loss=0.34691351652145386
[15/24] Train loss=0.33198434114456177
[20/24] Train loss=0.2936722934246063
Test set avg_accuracy=89.10% avg_sensitivity=74.94%, avg_specificity=93.86% avg_auc=93.47%
Best model saved!! Metric=25.371018949274173!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.337139 Test loss=0.294197 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3136410415172577
[5/24] Train loss=0.3117855191230774
[10/24] Train loss=0.3336845338344574
[15/24] Train loss=0.3184634745121002
[20/24] Train loss=0.27878883481025696
Test set avg_accuracy=89.32% avg_sensitivity=75.35%, avg_specificity=94.02% avg_auc=93.75%
Best model saved!! Metric=26.442109980542256!!
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.325337 Test loss=0.286665 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.30296269059181213
[5/24] Train loss=0.3019569516181946
[10/24] Train loss=0.3257818818092346
[15/24] Train loss=0.31428512930870056
[20/24] Train loss=0.26856833696365356
Test set avg_accuracy=88.89% avg_sensitivity=79.03%, avg_specificity=92.21% avg_auc=93.87%
Best model saved!! Metric=27.999289987007046!!
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.314956 Test loss=0.289744 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.29515376687049866
[5/24] Train loss=0.29711997509002686
[10/24] Train loss=0.3108918070793152
[15/24] Train loss=0.30449551343917847
[20/24] Train loss=0.26380619406700134
Test set avg_accuracy=89.44% avg_sensitivity=75.97%, avg_specificity=93.96% avg_auc=93.92%
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.307265 Test loss=0.276453 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2879861295223236
[5/24] Train loss=0.28589555621147156
[10/24] Train loss=0.3026795983314514
[15/24] Train loss=0.30210959911346436
[20/24] Train loss=0.25106921792030334
Test set avg_accuracy=89.43% avg_sensitivity=74.47%, avg_specificity=94.45% avg_auc=94.06%
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.301283 Test loss=0.273430 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2850430905818939
[5/24] Train loss=0.2717806100845337
[10/24] Train loss=0.302688866853714
[15/24] Train loss=0.2939363420009613
[20/24] Train loss=0.24575629830360413
Test set avg_accuracy=89.28% avg_sensitivity=78.97%, avg_specificity=92.75% avg_auc=94.31%
Best model saved!! Metric=29.31110282063294!!
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.294708 Test loss=0.271787 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2758130431175232
[5/24] Train loss=0.2711419463157654
[10/24] Train loss=0.29636043310165405
[15/24] Train loss=0.28323864936828613
[20/24] Train loss=0.2440963238477707
Test set avg_accuracy=89.34% avg_sensitivity=70.59%, avg_specificity=95.63% avg_auc=93.95%
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.287992 Test loss=0.269406 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.27094021439552307
[5/24] Train loss=0.26038455963134766
[10/24] Train loss=0.28942713141441345
[15/24] Train loss=0.28145524859428406
[20/24] Train loss=0.23601293563842773
Test set avg_accuracy=89.31% avg_sensitivity=76.54%, avg_specificity=93.60% avg_auc=94.16%
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.282135 Test loss=0.269368 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.26268383860588074
[5/24] Train loss=0.2578699588775635
[10/24] Train loss=0.2814039885997772
[15/24] Train loss=0.27231302857398987
[20/24] Train loss=0.23406226933002472
Test set avg_accuracy=89.58% avg_sensitivity=73.02%, avg_specificity=95.15% avg_auc=93.77%
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.277256 Test loss=0.269181 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2574826776981354
[5/24] Train loss=0.2562933564186096
[10/24] Train loss=0.28276821970939636
[15/24] Train loss=0.2719306945800781
[20/24] Train loss=0.22913524508476257
Test set avg_accuracy=88.93% avg_sensitivity=67.32%, avg_specificity=96.19% avg_auc=93.22%
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.273206 Test loss=0.279972 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.25455546379089355
[5/24] Train loss=0.2504452168941498
[10/24] Train loss=0.27148205041885376
[15/24] Train loss=0.2644936740398407
[20/24] Train loss=0.22609031200408936
Test set avg_accuracy=89.19% avg_sensitivity=78.04%, avg_specificity=92.94% avg_auc=94.14%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.268452 Test loss=0.265016 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.25508245825767517
[5/24] Train loss=0.24454966187477112
[10/24] Train loss=0.26456934213638306
[15/24] Train loss=0.262652724981308
[20/24] Train loss=0.2207922786474228
Test set avg_accuracy=89.02% avg_sensitivity=67.94%, avg_specificity=96.10% avg_auc=93.74%
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.263690 Test loss=0.271701 Current lr=[0.000210185142098938]

[0/24] Train loss=0.24667462706565857
[5/24] Train loss=0.23653532564640045
[10/24] Train loss=0.2700330317020416
[15/24] Train loss=0.2603719234466553
[20/24] Train loss=0.22019901871681213
Test set avg_accuracy=89.30% avg_sensitivity=77.63%, avg_specificity=93.22% avg_auc=94.12%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.260816 Test loss=0.266621 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.24264639616012573
[5/24] Train loss=0.23093104362487793
[10/24] Train loss=0.26371681690216064
[15/24] Train loss=0.25622886419296265
[20/24] Train loss=0.21795828640460968
Test set avg_accuracy=85.25% avg_sensitivity=47.44%, avg_specificity=97.95% avg_auc=90.42%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.255502 Test loss=0.357285 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.25547081232070923
[5/24] Train loss=0.23224344849586487
[10/24] Train loss=0.25802910327911377
[15/24] Train loss=0.25973010063171387
[20/24] Train loss=0.22055605053901672
Test set avg_accuracy=89.71% avg_sensitivity=75.19%, avg_specificity=94.59% avg_auc=93.69%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.255897 Test loss=0.266607 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.24354639649391174
[5/24] Train loss=0.22217236459255219
[10/24] Train loss=0.2657756805419922
[15/24] Train loss=0.2488512545824051
[20/24] Train loss=0.21770459413528442
Test set avg_accuracy=88.02% avg_sensitivity=80.17%, avg_specificity=90.66% avg_auc=93.49%
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.252099 Test loss=0.286585 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.24024495482444763
[5/24] Train loss=0.22172340750694275
[10/24] Train loss=0.25820934772491455
[15/24] Train loss=0.24692842364311218
[20/24] Train loss=0.2161165028810501
Test set avg_accuracy=89.21% avg_sensitivity=76.80%, avg_specificity=93.37% avg_auc=94.03%
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.248300 Test loss=0.262498 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.23508675396442413
[5/24] Train loss=0.21077926456928253
[10/24] Train loss=0.2595612406730652
[15/24] Train loss=0.2470756322145462
[20/24] Train loss=0.2147284597158432
Test set avg_accuracy=88.50% avg_sensitivity=67.22%, avg_specificity=95.65% avg_auc=93.25%
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.244771 Test loss=0.277188 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.23729680478572845
[5/24] Train loss=0.22031323611736298
[10/24] Train loss=0.2479415237903595
[15/24] Train loss=0.24309676885604858
[20/24] Train loss=0.20810507237911224
Test set avg_accuracy=89.87% avg_sensitivity=76.49%, avg_specificity=94.36% avg_auc=94.46%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.243832 Test loss=0.259959 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.23295985162258148
[5/24] Train loss=0.22482088208198547
[10/24] Train loss=0.25623905658721924
[15/24] Train loss=0.2350359708070755
[20/24] Train loss=0.21095861494541168
Test set avg_accuracy=88.78% avg_sensitivity=79.75%, avg_specificity=91.81% avg_auc=94.06%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.241600 Test loss=0.269346 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.22959573566913605
[5/24] Train loss=0.21036969125270844
[10/24] Train loss=0.26454904675483704
[15/24] Train loss=0.24403966963291168
[20/24] Train loss=0.21391373872756958
Test set avg_accuracy=89.23% avg_sensitivity=79.75%, avg_specificity=92.42% avg_auc=94.34%
Best model saved!! Metric=29.73636366595079!!
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.241506 Test loss=0.262716 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2272748500108719
[5/24] Train loss=0.2130732387304306
[10/24] Train loss=0.23984430730342865
[15/24] Train loss=0.24400673806667328
[20/24] Train loss=0.20676463842391968
Test set avg_accuracy=88.49% avg_sensitivity=65.41%, avg_specificity=96.24% avg_auc=92.31%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.240173 Test loss=0.291309 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.22751930356025696
[5/24] Train loss=0.21308915317058563
[10/24] Train loss=0.2579381763935089
[15/24] Train loss=0.243088960647583
[20/24] Train loss=0.21613305807113647
Test set avg_accuracy=85.56% avg_sensitivity=82.91%, avg_specificity=86.45% avg_auc=92.83%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.240470 Test loss=0.321750 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.22405023872852325
[5/24] Train loss=0.21300531923770905
[10/24] Train loss=0.2561313211917877
[15/24] Train loss=0.23727771639823914
[20/24] Train loss=0.21060115098953247
Test set avg_accuracy=89.19% avg_sensitivity=73.07%, avg_specificity=94.61% avg_auc=93.12%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.235407 Test loss=0.275859 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.23237435519695282
[5/24] Train loss=0.19559355080127716
[10/24] Train loss=0.2458261102437973
[15/24] Train loss=0.24819426238536835
[20/24] Train loss=0.2046133130788803
Test set avg_accuracy=87.49% avg_sensitivity=83.22%, avg_specificity=88.92% avg_auc=93.75%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.235533 Test loss=0.301464 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.23154295980930328
[5/24] Train loss=0.20352081954479218
[10/24] Train loss=0.2463165670633316
[15/24] Train loss=0.23113267123699188
[20/24] Train loss=0.20320813357830048
Test set avg_accuracy=88.62% avg_sensitivity=75.40%, avg_specificity=93.06% avg_auc=92.72%
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.231132 Test loss=0.284342 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.22031784057617188
[5/24] Train loss=0.20089296996593475
[10/24] Train loss=0.25552302598953247
[15/24] Train loss=0.2314530909061432
[20/24] Train loss=0.19980429112911224
Test set avg_accuracy=82.07% avg_sensitivity=85.60%, avg_specificity=80.88% avg_auc=91.54%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.232800 Test loss=0.398205 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.21925555169582367
[5/24] Train loss=0.20712554454803467
[10/24] Train loss=0.23911453783512115
[15/24] Train loss=0.22415082156658173
[20/24] Train loss=0.20736151933670044
Test set avg_accuracy=86.88% avg_sensitivity=81.15%, avg_specificity=88.80% avg_auc=92.60%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.232601 Test loss=0.318056 Current lr=[0.00029967723776099]

[0/24] Train loss=0.23201516270637512
[5/24] Train loss=0.19627641141414642
[10/24] Train loss=0.2381618320941925
[15/24] Train loss=0.2273404747247696
[20/24] Train loss=0.20464880764484406
Test set avg_accuracy=87.86% avg_sensitivity=79.96%, avg_specificity=90.52% avg_auc=92.88%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.225723 Test loss=0.295530 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.22307242453098297
[5/24] Train loss=0.20746591687202454
[10/24] Train loss=0.24540652334690094
[15/24] Train loss=0.23310132324695587
[20/24] Train loss=0.19266512989997864
Test set avg_accuracy=88.57% avg_sensitivity=72.66%, avg_specificity=93.91% avg_auc=92.76%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.228395 Test loss=0.282789 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.22451603412628174
[5/24] Train loss=0.21525317430496216
[10/24] Train loss=0.2386116087436676
[15/24] Train loss=0.2238897830247879
[20/24] Train loss=0.19640539586544037
Test set avg_accuracy=88.37% avg_sensitivity=70.90%, avg_specificity=94.24% avg_auc=91.79%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.228017 Test loss=0.299398 Current lr=[0.000299720220882401]

[0/24] Train loss=0.21089932322502136
[5/24] Train loss=0.18920810520648956
[10/24] Train loss=0.23623697459697723
[15/24] Train loss=0.2297637164592743
[20/24] Train loss=0.2054511457681656
Test set avg_accuracy=89.17% avg_sensitivity=73.49%, avg_specificity=94.43% avg_auc=92.91%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.226380 Test loss=0.279158 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.22505265474319458
[5/24] Train loss=0.1955460011959076
[10/24] Train loss=0.2304307222366333
[15/24] Train loss=0.21421706676483154
[20/24] Train loss=0.18310163915157318
Test set avg_accuracy=88.66% avg_sensitivity=76.54%, avg_specificity=92.73% avg_auc=93.03%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.219717 Test loss=0.280617 Current lr=[0.000298904600941902]

[0/24] Train loss=0.22462137043476105
[5/24] Train loss=0.18316414952278137
[10/24] Train loss=0.22569289803504944
[15/24] Train loss=0.22544994950294495
[20/24] Train loss=0.1957961469888687
Test set avg_accuracy=76.35% avg_sensitivity=85.86%, avg_specificity=73.16% avg_auc=89.36%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.225161 Test loss=0.465525 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.20836083590984344
[5/24] Train loss=0.1809704601764679
[10/24] Train loss=0.23186863958835602
[15/24] Train loss=0.2212029993534088
[20/24] Train loss=0.18478606641292572
Test set avg_accuracy=88.44% avg_sensitivity=67.32%, avg_specificity=95.53% avg_auc=92.08%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.217600 Test loss=0.298278 Current lr=[0.000297555943323901]

[0/24] Train loss=0.21972981095314026
[5/24] Train loss=0.19804173707962036
[10/24] Train loss=0.23748786747455597
[15/24] Train loss=0.22943413257598877
[20/24] Train loss=0.1953897774219513
Test set avg_accuracy=89.65% avg_sensitivity=75.30%, avg_specificity=94.47% avg_auc=93.38%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.219512 Test loss=0.268699 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.21086646616458893
[5/24] Train loss=0.19372287392616272
[10/24] Train loss=0.23600180447101593
[15/24] Train loss=0.22421418130397797
[20/24] Train loss=0.19493383169174194
Test set avg_accuracy=84.67% avg_sensitivity=45.42%, avg_specificity=97.86% avg_auc=87.16%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.221187 Test loss=0.410300 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2158079892396927
[5/24] Train loss=0.19483032822608948
[10/24] Train loss=0.24667988717556
[15/24] Train loss=0.2187359631061554
[20/24] Train loss=0.17720681428909302
Test set avg_accuracy=88.36% avg_sensitivity=76.49%, avg_specificity=92.35% avg_auc=93.05%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.217071 Test loss=0.284301 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.20453372597694397
[5/24] Train loss=0.2073146253824234
[10/24] Train loss=0.23556217551231384
[15/24] Train loss=0.21575818955898285
[20/24] Train loss=0.18498845398426056
Test set avg_accuracy=88.19% avg_sensitivity=71.83%, avg_specificity=93.69% avg_auc=92.26%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.211561 Test loss=0.291410 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.21950818598270416
[5/24] Train loss=0.18090572953224182
[10/24] Train loss=0.22299714386463165
[15/24] Train loss=0.21432581543922424
[20/24] Train loss=0.18690918385982513
Test set avg_accuracy=88.61% avg_sensitivity=68.93%, avg_specificity=95.22% avg_auc=91.91%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.214050 Test loss=0.289866 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.2076093852519989
[5/24] Train loss=0.1845402866601944
[10/24] Train loss=0.2186826914548874
[15/24] Train loss=0.21954695880413055
[20/24] Train loss=0.1846928894519806
Test set avg_accuracy=89.18% avg_sensitivity=73.23%, avg_specificity=94.54% avg_auc=92.44%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.214053 Test loss=0.284176 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.21180732548236847
[5/24] Train loss=0.19221191108226776
[10/24] Train loss=0.22668053209781647
[15/24] Train loss=0.22802512347698212
[20/24] Train loss=0.18857167661190033
Test set avg_accuracy=87.67% avg_sensitivity=80.58%, avg_specificity=90.05% avg_auc=93.40%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.217536 Test loss=0.300654 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2047678828239441
[5/24] Train loss=0.17949318885803223
[10/24] Train loss=0.20978550612926483
[15/24] Train loss=0.20926202833652496
[20/24] Train loss=0.17899636924266815
Test set avg_accuracy=89.36% avg_sensitivity=71.72%, avg_specificity=95.29% avg_auc=92.84%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.209132 Test loss=0.272987 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.207737535238266
[5/24] Train loss=0.18145491182804108
[10/24] Train loss=0.24200886487960815
[15/24] Train loss=0.22155795991420746
[20/24] Train loss=0.18338949978351593
Test set avg_accuracy=84.26% avg_sensitivity=82.03%, avg_specificity=85.01% avg_auc=91.01%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.212230 Test loss=0.361061 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.21064747869968414
[5/24] Train loss=0.1813361942768097
[10/24] Train loss=0.21756163239479065
[15/24] Train loss=0.21512246131896973
[20/24] Train loss=0.18344469368457794
Test set avg_accuracy=87.59% avg_sensitivity=60.23%, avg_specificity=96.78% avg_auc=90.38%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.208618 Test loss=0.325256 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.20394019782543182
[5/24] Train loss=0.18342113494873047
[10/24] Train loss=0.21006153523921967
[15/24] Train loss=0.21997186541557312
[20/24] Train loss=0.18863020837306976
Test set avg_accuracy=88.28% avg_sensitivity=77.63%, avg_specificity=91.86% avg_auc=93.19%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.207543 Test loss=0.285286 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.1959315985441208
[5/24] Train loss=0.18338175117969513
[10/24] Train loss=0.22284632921218872
[15/24] Train loss=0.21368660032749176
[20/24] Train loss=0.1681462675333023
Test set avg_accuracy=87.70% avg_sensitivity=74.00%, avg_specificity=92.29% avg_auc=91.37%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.206444 Test loss=0.305561 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.21557216346263885
[5/24] Train loss=0.17221657931804657
[10/24] Train loss=0.2302095592021942
[15/24] Train loss=0.23024235665798187
[20/24] Train loss=0.1818256825208664
Test set avg_accuracy=89.14% avg_sensitivity=74.16%, avg_specificity=94.17% avg_auc=93.43%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.212204 Test loss=0.272575 Current lr=[0.000276307469034998]

[0/24] Train loss=0.1961207240819931
[5/24] Train loss=0.1692723035812378
[10/24] Train loss=0.22034893929958344
[15/24] Train loss=0.20059055089950562
[20/24] Train loss=0.17683681845664978
Test set avg_accuracy=87.30% avg_sensitivity=79.65%, avg_specificity=89.88% avg_auc=92.36%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.202444 Test loss=0.305657 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.19644588232040405
[5/24] Train loss=0.1768483817577362
[10/24] Train loss=0.21300062537193298
[15/24] Train loss=0.19834496080875397
[20/24] Train loss=0.17075245082378387
Test set avg_accuracy=87.10% avg_sensitivity=59.76%, avg_specificity=96.28% avg_auc=89.67%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.198728 Test loss=0.327974 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.215094655752182
[5/24] Train loss=0.17278382182121277
[10/24] Train loss=0.21972714364528656
[15/24] Train loss=0.2074652761220932
[20/24] Train loss=0.17325808107852936
Test set avg_accuracy=86.88% avg_sensitivity=71.62%, avg_specificity=92.00% avg_auc=91.70%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.203162 Test loss=0.317913 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.21318796277046204
[5/24] Train loss=0.1766984611749649
[10/24] Train loss=0.2083260715007782
[15/24] Train loss=0.2007511705160141
[20/24] Train loss=0.16960729658603668
Test set avg_accuracy=87.60% avg_sensitivity=74.73%, avg_specificity=91.93% avg_auc=91.69%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.203947 Test loss=0.312400 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.20199915766716003
[5/24] Train loss=0.17410117387771606
[10/24] Train loss=0.21007899940013885
[15/24] Train loss=0.1979437917470932
[20/24] Train loss=0.1692226678133011
Test set avg_accuracy=88.66% avg_sensitivity=72.60%, avg_specificity=94.05% avg_auc=92.60%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.198149 Test loss=0.289979 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.20407478511333466
[5/24] Train loss=0.16579577326774597
[10/24] Train loss=0.19844943284988403
[15/24] Train loss=0.20711378753185272
[20/24] Train loss=0.16984571516513824
Test set avg_accuracy=86.77% avg_sensitivity=78.25%, avg_specificity=89.63% avg_auc=91.22%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.195068 Test loss=0.321403 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.19586443901062012
[5/24] Train loss=0.16317062079906464
[10/24] Train loss=0.201616108417511
[15/24] Train loss=0.20007850229740143
[20/24] Train loss=0.17440272867679596
Test set avg_accuracy=85.25% avg_sensitivity=48.21%, avg_specificity=97.69% avg_auc=89.88%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.195641 Test loss=0.346000 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.19967086613178253
[5/24] Train loss=0.16836705803871155
[10/24] Train loss=0.20933005213737488
[15/24] Train loss=0.19663774967193604
[20/24] Train loss=0.17016905546188354
Test set avg_accuracy=88.33% avg_sensitivity=78.97%, avg_specificity=91.48% avg_auc=92.25%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.195585 Test loss=0.296646 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.19871507585048676
[5/24] Train loss=0.1656748205423355
[10/24] Train loss=0.20565593242645264
[15/24] Train loss=0.19206289947032928
[20/24] Train loss=0.16169549524784088
Test set avg_accuracy=85.78% avg_sensitivity=76.18%, avg_specificity=89.01% avg_auc=90.51%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.190810 Test loss=0.334267 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.18903860449790955
[5/24] Train loss=0.17154322564601898
[10/24] Train loss=0.19510185718536377
[15/24] Train loss=0.1903243213891983
[20/24] Train loss=0.15568962693214417
Test set avg_accuracy=87.38% avg_sensitivity=77.32%, avg_specificity=90.76% avg_auc=91.79%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.191386 Test loss=0.304412 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.19284147024154663
[5/24] Train loss=0.16701772809028625
[10/24] Train loss=0.19891367852687836
[15/24] Train loss=0.1917458325624466
[20/24] Train loss=0.1683700829744339
Test set avg_accuracy=86.34% avg_sensitivity=51.58%, avg_specificity=98.02% avg_auc=88.44%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.196226 Test loss=0.371826 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2023545354604721
[5/24] Train loss=0.16165174543857574
[10/24] Train loss=0.21166002750396729
[15/24] Train loss=0.1983610987663269
[20/24] Train loss=0.17106254398822784
Test set avg_accuracy=88.37% avg_sensitivity=65.77%, avg_specificity=95.96% avg_auc=91.24%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.195232 Test loss=0.300617 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.18863758444786072
[5/24] Train loss=0.16094377636909485
[10/24] Train loss=0.1936953067779541
[15/24] Train loss=0.20036834478378296
[20/24] Train loss=0.16160359978675842
Test set avg_accuracy=82.53% avg_sensitivity=74.21%, avg_specificity=85.32% avg_auc=87.62%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.190337 Test loss=0.392528 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.19911861419677734
[5/24] Train loss=0.1618490368127823
[10/24] Train loss=0.19890160858631134
[15/24] Train loss=0.20231519639492035
[20/24] Train loss=0.16011875867843628
Test set avg_accuracy=89.11% avg_sensitivity=72.97%, avg_specificity=94.54% avg_auc=92.92%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.194696 Test loss=0.278044 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.1871834546327591
[5/24] Train loss=0.16675008833408356
[10/24] Train loss=0.20448243618011475
[15/24] Train loss=0.18914452195167542
[20/24] Train loss=0.15591727197170258
Test set avg_accuracy=88.24% avg_sensitivity=75.09%, avg_specificity=92.66% avg_auc=92.00%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.194903 Test loss=0.297916 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.19071567058563232
[5/24] Train loss=0.1628921926021576
[10/24] Train loss=0.19556653499603271
[15/24] Train loss=0.20661167800426483
[20/24] Train loss=0.15634401142597198
Test set avg_accuracy=87.36% avg_sensitivity=61.26%, avg_specificity=96.12% avg_auc=89.75%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.190918 Test loss=0.330415 Current lr=[0.000224838296036774]

[0/24] Train loss=0.18757806718349457
[5/24] Train loss=0.16559778153896332
[10/24] Train loss=0.20196013152599335
[15/24] Train loss=0.19027718901634216
[20/24] Train loss=0.159392848610878
Test set avg_accuracy=87.70% avg_sensitivity=64.16%, avg_specificity=95.60% avg_auc=90.41%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.189846 Test loss=0.315277 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.1852244734764099
[5/24] Train loss=0.16452853381633759
[10/24] Train loss=0.19367444515228271
[15/24] Train loss=0.1917506605386734
[20/24] Train loss=0.15143688023090363
Test set avg_accuracy=87.71% avg_sensitivity=71.62%, avg_specificity=93.11% avg_auc=91.28%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.188235 Test loss=0.301471 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.18052807450294495
[5/24] Train loss=0.16464649140834808
[10/24] Train loss=0.18607547879219055
[15/24] Train loss=0.18223054707050323
[20/24] Train loss=0.1570800095796585
Test set avg_accuracy=86.60% avg_sensitivity=55.10%, avg_specificity=97.18% avg_auc=88.97%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.185090 Test loss=0.360568 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.18596553802490234
[5/24] Train loss=0.16933280229568481
[10/24] Train loss=0.18400469422340393
[15/24] Train loss=0.1809091717004776
[20/24] Train loss=0.15181304514408112
Test set avg_accuracy=88.78% avg_sensitivity=79.80%, avg_specificity=91.79% avg_auc=93.07%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.185362 Test loss=0.287972 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.18151873350143433
[5/24] Train loss=0.17229589819908142
[10/24] Train loss=0.193913534283638
[15/24] Train loss=0.18187402188777924
[20/24] Train loss=0.15393869578838348
Test set avg_accuracy=88.23% avg_sensitivity=71.78%, avg_specificity=93.76% avg_auc=91.47%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.185753 Test loss=0.305561 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.18588747084140778
[5/24] Train loss=0.157621830701828
[10/24] Train loss=0.1939864456653595
[15/24] Train loss=0.1862226277589798
[20/24] Train loss=0.1524810940027237
Test set avg_accuracy=88.26% avg_sensitivity=76.75%, avg_specificity=92.12% avg_auc=92.45%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.185283 Test loss=0.294307 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.18095646798610687
[5/24] Train loss=0.15546205639839172
[10/24] Train loss=0.18727630376815796
[15/24] Train loss=0.18263645470142365
[20/24] Train loss=0.15806080400943756
Test set avg_accuracy=88.72% avg_sensitivity=74.94%, avg_specificity=93.36% avg_auc=93.22%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.182482 Test loss=0.280002 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.18371476233005524
[5/24] Train loss=0.15351900458335876
[10/24] Train loss=0.19506321847438812
[15/24] Train loss=0.1912268102169037
[20/24] Train loss=0.15665976703166962
Test set avg_accuracy=88.88% avg_sensitivity=71.10%, avg_specificity=94.85% avg_auc=91.00%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.182800 Test loss=0.295508 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1761845350265503
[5/24] Train loss=0.16383621096611023
[10/24] Train loss=0.18771913647651672
[15/24] Train loss=0.18246661126613617
[20/24] Train loss=0.1530040055513382
Test set avg_accuracy=88.29% avg_sensitivity=69.14%, avg_specificity=94.73% avg_auc=90.34%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.181845 Test loss=0.312593 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.17949025332927704
[5/24] Train loss=0.17286038398742676
[10/24] Train loss=0.1957109272480011
[15/24] Train loss=0.1800657957792282
[20/24] Train loss=0.15604735910892487
Test set avg_accuracy=86.37% avg_sensitivity=61.37%, avg_specificity=94.76% avg_auc=88.85%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.184864 Test loss=0.342354 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1804584413766861
[5/24] Train loss=0.15889737010002136
[10/24] Train loss=0.18554650247097015
[15/24] Train loss=0.17414402961730957
[20/24] Train loss=0.15078605711460114
Test set avg_accuracy=88.31% avg_sensitivity=75.66%, avg_specificity=92.56% avg_auc=92.43%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.178596 Test loss=0.295354 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.17933379113674164
[5/24] Train loss=0.17040683329105377
[10/24] Train loss=0.18042857944965363
[15/24] Train loss=0.17856650054454803
[20/24] Train loss=0.15352623164653778
Test set avg_accuracy=87.88% avg_sensitivity=69.96%, avg_specificity=93.89% avg_auc=91.30%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.178843 Test loss=0.310545 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.18590541183948517
[5/24] Train loss=0.16384658217430115
[10/24] Train loss=0.18306942284107208
[15/24] Train loss=0.1739184409379959
[20/24] Train loss=0.14689452946186066
Test set avg_accuracy=88.54% avg_sensitivity=72.66%, avg_specificity=93.88% avg_auc=91.57%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.177957 Test loss=0.294861 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.18249674141407013
[5/24] Train loss=0.15885746479034424
[10/24] Train loss=0.18341942131519318
[15/24] Train loss=0.18081843852996826
[20/24] Train loss=0.14688117802143097
Test set avg_accuracy=87.36% avg_sensitivity=68.15%, avg_specificity=93.81% avg_auc=89.64%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.176773 Test loss=0.334088 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1703033596277237
[5/24] Train loss=0.15132597088813782
[10/24] Train loss=0.17561699450016022
[15/24] Train loss=0.16466611623764038
[20/24] Train loss=0.1431773602962494
Test set avg_accuracy=87.43% avg_sensitivity=68.41%, avg_specificity=93.83% avg_auc=90.30%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.170652 Test loss=0.321921 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.1684364676475525
[5/24] Train loss=0.14669983088970184
[10/24] Train loss=0.16635540127754211
[15/24] Train loss=0.16515953838825226
[20/24] Train loss=0.14447350800037384
Test set avg_accuracy=87.79% avg_sensitivity=64.89%, avg_specificity=95.48% avg_auc=88.47%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.168439 Test loss=0.338395 Current lr=[0.000156543481933168]

[0/24] Train loss=0.17616400122642517
[5/24] Train loss=0.1493585705757141
[10/24] Train loss=0.16369947791099548
[15/24] Train loss=0.17381103336811066
[20/24] Train loss=0.14388278126716614
Test set avg_accuracy=85.25% avg_sensitivity=58.67%, avg_specificity=94.17% avg_auc=85.57%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.169979 Test loss=0.377655 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1759851574897766
[5/24] Train loss=0.14791756868362427
[10/24] Train loss=0.1801241934299469
[15/24] Train loss=0.16767586767673492
[20/24] Train loss=0.14559656381607056
Test set avg_accuracy=87.80% avg_sensitivity=72.92%, avg_specificity=92.80% avg_auc=90.91%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.170611 Test loss=0.317181 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.17376741766929626
[5/24] Train loss=0.1433684378862381
[10/24] Train loss=0.1687854826450348
[15/24] Train loss=0.16002359986305237
[20/24] Train loss=0.14151190221309662
Test set avg_accuracy=87.01% avg_sensitivity=58.62%, avg_specificity=96.54% avg_auc=89.15%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.165963 Test loss=0.347970 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.17428763210773468
[5/24] Train loss=0.15360629558563232
[10/24] Train loss=0.17112129926681519
[15/24] Train loss=0.1669076681137085
[20/24] Train loss=0.13788986206054688
Test set avg_accuracy=88.39% avg_sensitivity=67.32%, avg_specificity=95.46% avg_auc=91.31%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.168788 Test loss=0.308661 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.16722369194030762
[5/24] Train loss=0.14760664105415344
[10/24] Train loss=0.17502611875534058
[15/24] Train loss=0.1676488220691681
[20/24] Train loss=0.14474953711032867
Test set avg_accuracy=88.35% avg_sensitivity=72.04%, avg_specificity=93.83% avg_auc=91.02%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.168656 Test loss=0.305556 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16989383101463318
[5/24] Train loss=0.14784298837184906
[10/24] Train loss=0.17026488482952118
[15/24] Train loss=0.16288617253303528
[20/24] Train loss=0.14560264348983765
Test set avg_accuracy=89.19% avg_sensitivity=74.62%, avg_specificity=94.09% avg_auc=92.44%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.167829 Test loss=0.283756 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.166510671377182
[5/24] Train loss=0.15464714169502258
[10/24] Train loss=0.16719412803649902
[15/24] Train loss=0.15892603993415833
[20/24] Train loss=0.1367741823196411
Test set avg_accuracy=87.90% avg_sensitivity=64.63%, avg_specificity=95.72% avg_auc=89.34%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.163820 Test loss=0.337241 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.15957766771316528
[5/24] Train loss=0.14515826106071472
[10/24] Train loss=0.1638697385787964
[15/24] Train loss=0.16050441563129425
[20/24] Train loss=0.15143516659736633
Test set avg_accuracy=87.60% avg_sensitivity=67.69%, avg_specificity=94.29% avg_auc=89.79%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.162108 Test loss=0.339783 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.16293761134147644
[5/24] Train loss=0.1438756138086319
[10/24] Train loss=0.16106437146663666
[15/24] Train loss=0.16172926127910614
[20/24] Train loss=0.14218035340309143
Test set avg_accuracy=88.28% avg_sensitivity=73.85%, avg_specificity=93.13% avg_auc=92.15%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.161212 Test loss=0.296078 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.16381287574768066
[5/24] Train loss=0.1396319717168808
[10/24] Train loss=0.16646231710910797
[15/24] Train loss=0.15541747212409973
[20/24] Train loss=0.14128999412059784
Test set avg_accuracy=88.33% avg_sensitivity=73.17%, avg_specificity=93.42% avg_auc=92.00%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.159928 Test loss=0.300688 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15614013373851776
[5/24] Train loss=0.1484925001859665
[10/24] Train loss=0.16475462913513184
[15/24] Train loss=0.15479515492916107
[20/24] Train loss=0.1362946331501007
Test set avg_accuracy=87.02% avg_sensitivity=82.91%, avg_specificity=88.40% avg_auc=92.27%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.159395 Test loss=0.322155 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.16516822576522827
[5/24] Train loss=0.14746247231960297
[10/24] Train loss=0.1671503633260727
[15/24] Train loss=0.1538810133934021
[20/24] Train loss=0.13574804365634918
Test set avg_accuracy=88.63% avg_sensitivity=73.95%, avg_specificity=93.56% avg_auc=91.48%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.159103 Test loss=0.297160 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1601080298423767
[5/24] Train loss=0.1437404751777649
[10/24] Train loss=0.15643969178199768
[15/24] Train loss=0.14953725039958954
[20/24] Train loss=0.13895390927791595
Test set avg_accuracy=88.59% avg_sensitivity=75.76%, avg_specificity=92.90% avg_auc=91.92%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.158410 Test loss=0.298250 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1571929156780243
[5/24] Train loss=0.14607520401477814
[10/24] Train loss=0.16634631156921387
[15/24] Train loss=0.15763060748577118
[20/24] Train loss=0.1410152167081833
Test set avg_accuracy=88.55% avg_sensitivity=73.64%, avg_specificity=93.56% avg_auc=91.83%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.158610 Test loss=0.299566 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15897929668426514
[5/24] Train loss=0.14104430377483368
[10/24] Train loss=0.1570533812046051
[15/24] Train loss=0.1496148556470871
[20/24] Train loss=0.13272413611412048
Test set avg_accuracy=87.63% avg_sensitivity=80.06%, avg_specificity=90.17% avg_auc=92.25%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.155458 Test loss=0.309228 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.159712016582489
[5/24] Train loss=0.13499727845191956
[10/24] Train loss=0.1544625610113144
[15/24] Train loss=0.1463543325662613
[20/24] Train loss=0.12887613475322723
Test set avg_accuracy=87.94% avg_sensitivity=78.09%, avg_specificity=91.25% avg_auc=92.28%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.153263 Test loss=0.302278 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.16034655272960663
[5/24] Train loss=0.13911494612693787
[10/24] Train loss=0.15192490816116333
[15/24] Train loss=0.1457795798778534
[20/24] Train loss=0.12984010577201843
Test set avg_accuracy=88.70% avg_sensitivity=79.39%, avg_specificity=91.82% avg_auc=92.59%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.152299 Test loss=0.290732 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.15303613245487213
[5/24] Train loss=0.13526517152786255
[10/24] Train loss=0.1518956571817398
[15/24] Train loss=0.1493457704782486
[20/24] Train loss=0.1286652535200119
Test set avg_accuracy=88.16% avg_sensitivity=71.52%, avg_specificity=93.76% avg_auc=90.89%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.150532 Test loss=0.306449 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.15167786180973053
[5/24] Train loss=0.12883850932121277
[10/24] Train loss=0.15338429808616638
[15/24] Train loss=0.15081968903541565
[20/24] Train loss=0.1252494901418686
Test set avg_accuracy=88.24% avg_sensitivity=78.72%, avg_specificity=91.44% avg_auc=92.27%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.149579 Test loss=0.300795 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14553624391555786
[5/24] Train loss=0.1324487030506134
[10/24] Train loss=0.1525510847568512
[15/24] Train loss=0.14403048157691956
[20/24] Train loss=0.12560825049877167
Test set avg_accuracy=88.87% avg_sensitivity=77.42%, avg_specificity=92.71% avg_auc=92.28%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.148243 Test loss=0.291221 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14625734090805054
[5/24] Train loss=0.13520394265651703
[10/24] Train loss=0.145541712641716
[15/24] Train loss=0.1427045315504074
[20/24] Train loss=0.12766611576080322
Test set avg_accuracy=89.11% avg_sensitivity=76.75%, avg_specificity=93.27% avg_auc=91.89%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.147468 Test loss=0.293967 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14572639763355255
[5/24] Train loss=0.13081122934818268
[10/24] Train loss=0.14743857085704803
[15/24] Train loss=0.14253492653369904
[20/24] Train loss=0.1265060156583786
Test set avg_accuracy=88.45% avg_sensitivity=74.16%, avg_specificity=93.25% avg_auc=91.24%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.146447 Test loss=0.302146 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14669668674468994
[5/24] Train loss=0.1292731612920761
[10/24] Train loss=0.14916247129440308
[15/24] Train loss=0.14319418370723724
[20/24] Train loss=0.12751220166683197
Test set avg_accuracy=88.65% avg_sensitivity=72.09%, avg_specificity=94.21% avg_auc=90.99%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.145438 Test loss=0.303793 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.143593430519104
[5/24] Train loss=0.12827056646347046
[10/24] Train loss=0.14145605266094208
[15/24] Train loss=0.14206473529338837
[20/24] Train loss=0.12340769171714783
Test set avg_accuracy=88.42% avg_sensitivity=74.31%, avg_specificity=93.16% avg_auc=92.07%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.144888 Test loss=0.292589 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14265857636928558
[5/24] Train loss=0.13556498289108276
[10/24] Train loss=0.1438785046339035
[15/24] Train loss=0.13807383179664612
[20/24] Train loss=0.1280149221420288
Test set avg_accuracy=88.65% avg_sensitivity=74.26%, avg_specificity=93.48% avg_auc=91.60%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.143309 Test loss=0.302370 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.14343135058879852
[5/24] Train loss=0.1260044127702713
[10/24] Train loss=0.1429748237133026
[15/24] Train loss=0.1396683007478714
[20/24] Train loss=0.12129750847816467
Test set avg_accuracy=88.63% avg_sensitivity=73.74%, avg_specificity=93.63% avg_auc=91.60%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.142100 Test loss=0.302660 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14370281994342804
[5/24] Train loss=0.13302122056484222
[10/24] Train loss=0.13959020376205444
[15/24] Train loss=0.1371082365512848
[20/24] Train loss=0.12260520458221436
Test set avg_accuracy=88.76% avg_sensitivity=73.85%, avg_specificity=93.77% avg_auc=91.30%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.141066 Test loss=0.296407 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13899314403533936
[5/24] Train loss=0.12769672274589539
[10/24] Train loss=0.13962753117084503
[15/24] Train loss=0.14049680531024933
[20/24] Train loss=0.1247355192899704
Test set avg_accuracy=88.45% avg_sensitivity=74.26%, avg_specificity=93.22% avg_auc=91.86%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.140196 Test loss=0.299546 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13942274451255798
[5/24] Train loss=0.13039496541023254
[10/24] Train loss=0.14110183715820312
[15/24] Train loss=0.13904133439064026
[20/24] Train loss=0.12107060104608536
Test set avg_accuracy=88.80% avg_sensitivity=75.87%, avg_specificity=93.15% avg_auc=92.03%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.140161 Test loss=0.292804 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.14139942824840546
[5/24] Train loss=0.12948913872241974
[10/24] Train loss=0.13983452320098877
[15/24] Train loss=0.1392650306224823
[20/24] Train loss=0.12258581072092056
Test set avg_accuracy=88.85% avg_sensitivity=73.80%, avg_specificity=93.91% avg_auc=91.96%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.139775 Test loss=0.290295 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.14271707832813263
[5/24] Train loss=0.12689664959907532
[10/24] Train loss=0.13493573665618896
[15/24] Train loss=0.13802380859851837
[20/24] Train loss=0.1267930120229721
Test set avg_accuracy=88.46% avg_sensitivity=76.59%, avg_specificity=92.45% avg_auc=91.80%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.140151 Test loss=0.301292 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1399151235818863
[5/24] Train loss=0.1316370666027069
[10/24] Train loss=0.13803069293498993
[15/24] Train loss=0.1384487897157669
[20/24] Train loss=0.12155027687549591
Test set avg_accuracy=89.05% avg_sensitivity=77.27%, avg_specificity=93.01% avg_auc=92.03%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.139837 Test loss=0.292397 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1366858333349228
[5/24] Train loss=0.12556076049804688
[10/24] Train loss=0.13894565403461456
[15/24] Train loss=0.13587717711925507
[20/24] Train loss=0.12067097425460815
Test set avg_accuracy=87.90% avg_sensitivity=81.10%, avg_specificity=90.19% avg_auc=92.09%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.137584 Test loss=0.307687 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13970708847045898
[5/24] Train loss=0.12684626877307892
[10/24] Train loss=0.13448187708854675
[15/24] Train loss=0.13601142168045044
[20/24] Train loss=0.11980882287025452
Test set avg_accuracy=88.33% avg_sensitivity=78.04%, avg_specificity=91.79% avg_auc=92.11%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.137382 Test loss=0.303066 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13824982941150665
[5/24] Train loss=0.1259143054485321
[10/24] Train loss=0.1318448781967163
[15/24] Train loss=0.13575242459774017
[20/24] Train loss=0.11940300464630127
Test set avg_accuracy=88.57% avg_sensitivity=77.27%, avg_specificity=92.36% avg_auc=91.99%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.137113 Test loss=0.296465 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1372217833995819
[5/24] Train loss=0.12986357510089874
[10/24] Train loss=0.13458523154258728
[15/24] Train loss=0.1320410817861557
[20/24] Train loss=0.12387402355670929
Test set avg_accuracy=88.91% avg_sensitivity=75.35%, avg_specificity=93.46% avg_auc=91.75%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.137016 Test loss=0.295590 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13526587188243866
[5/24] Train loss=0.12506234645843506
[10/24] Train loss=0.13829217851161957
[15/24] Train loss=0.13317812979221344
[20/24] Train loss=0.1196083053946495
Test set avg_accuracy=88.62% avg_sensitivity=77.11%, avg_specificity=92.49% avg_auc=91.70%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.137007 Test loss=0.298210 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13881848752498627
[5/24] Train loss=0.122300885617733
[10/24] Train loss=0.1325070559978485
[15/24] Train loss=0.13405649363994598
[20/24] Train loss=0.12034179270267487
Test set avg_accuracy=88.46% avg_sensitivity=77.63%, avg_specificity=92.10% avg_auc=92.04%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.135312 Test loss=0.296485 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1370653361082077
[5/24] Train loss=0.12444255501031876
[10/24] Train loss=0.12969397008419037
[15/24] Train loss=0.13094906508922577
[20/24] Train loss=0.11773982644081116
Test set avg_accuracy=88.78% avg_sensitivity=75.45%, avg_specificity=93.25% avg_auc=91.84%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.133548 Test loss=0.295372 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13570646941661835
[5/24] Train loss=0.12094135582447052
[10/24] Train loss=0.1293661892414093
[15/24] Train loss=0.13092774152755737
[20/24] Train loss=0.11775083839893341
Test set avg_accuracy=88.74% avg_sensitivity=77.94%, avg_specificity=92.36% avg_auc=92.17%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.132592 Test loss=0.291052 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.13358555734157562
[5/24] Train loss=0.12037324905395508
[10/24] Train loss=0.12929220497608185
[15/24] Train loss=0.1295974999666214
[20/24] Train loss=0.11795423924922943
Test set avg_accuracy=88.91% avg_sensitivity=76.85%, avg_specificity=92.96% avg_auc=91.86%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.132530 Test loss=0.291649 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13410122692584991
[5/24] Train loss=0.11928911507129669
[10/24] Train loss=0.13176600635051727
[15/24] Train loss=0.12923185527324677
[20/24] Train loss=0.11557160317897797
Test set avg_accuracy=88.68% avg_sensitivity=77.47%, avg_specificity=92.45% avg_auc=92.05%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.131259 Test loss=0.293799 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1320803314447403
[5/24] Train loss=0.11977992951869965
[10/24] Train loss=0.12996284663677216
[15/24] Train loss=0.12869969010353088
[20/24] Train loss=0.11567752808332443
Test set avg_accuracy=88.66% avg_sensitivity=76.13%, avg_specificity=92.87% avg_auc=91.88%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.131473 Test loss=0.294769 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12921485304832458
[5/24] Train loss=0.12117381393909454
[10/24] Train loss=0.12879259884357452
[15/24] Train loss=0.12924452126026154
[20/24] Train loss=0.11439760774374008
Test set avg_accuracy=88.71% avg_sensitivity=77.27%, avg_specificity=92.56% avg_auc=92.00%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.130801 Test loss=0.292634 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13216111063957214
[5/24] Train loss=0.1214212030172348
[10/24] Train loss=0.1260264664888382
[15/24] Train loss=0.12876704335212708
[20/24] Train loss=0.11467945575714111
Test set avg_accuracy=88.80% avg_sensitivity=76.07%, avg_specificity=93.08% avg_auc=91.95%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.130601 Test loss=0.291725 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12968994677066803
[5/24] Train loss=0.11881543695926666
[10/24] Train loss=0.1295824944972992
[15/24] Train loss=0.12833327054977417
[20/24] Train loss=0.11562484502792358
Test set avg_accuracy=88.76% avg_sensitivity=76.39%, avg_specificity=92.92% avg_auc=91.92%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.129924 Test loss=0.294926 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13393040001392365
[5/24] Train loss=0.12211786210536957
[10/24] Train loss=0.12896201014518738
[15/24] Train loss=0.13056179881095886
[20/24] Train loss=0.11462069302797318
Test set avg_accuracy=88.75% avg_sensitivity=77.01%, avg_specificity=92.69% avg_auc=91.84%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.130105 Test loss=0.294235 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13214588165283203
[5/24] Train loss=0.11881779134273529
[10/24] Train loss=0.12752418220043182
[15/24] Train loss=0.12971162796020508
[20/24] Train loss=0.11383075267076492
Test set avg_accuracy=88.80% avg_sensitivity=76.33%, avg_specificity=92.99% avg_auc=91.87%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.129860 Test loss=0.293436 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13000400364398956
[5/24] Train loss=0.11898913979530334
[10/24] Train loss=0.12654796242713928
[15/24] Train loss=0.12915410101413727
[20/24] Train loss=0.11411794275045395
Test set avg_accuracy=88.78% avg_sensitivity=76.59%, avg_specificity=92.87% avg_auc=91.91%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.129716 Test loss=0.292737 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12780070304870605
[5/24] Train loss=0.11960190534591675
[10/24] Train loss=0.1270797699689865
[15/24] Train loss=0.12954291701316833
[20/24] Train loss=0.11423314362764359
Test set avg_accuracy=88.80% avg_sensitivity=76.80%, avg_specificity=92.83% avg_auc=91.88%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.129234 Test loss=0.292987 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.13134995102882385
[5/24] Train loss=0.11883578449487686
[10/24] Train loss=0.12640485167503357
[15/24] Train loss=0.12798374891281128
[20/24] Train loss=0.11471407115459442
Test set avg_accuracy=88.80% avg_sensitivity=76.70%, avg_specificity=92.87% avg_auc=91.88%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.129766 Test loss=0.293249 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1311749964952469
[5/24] Train loss=0.11719081550836563
[10/24] Train loss=0.12855924665927887
[15/24] Train loss=0.12863308191299438
[20/24] Train loss=0.11519626528024673
Test set avg_accuracy=88.80% avg_sensitivity=76.75%, avg_specificity=92.85% avg_auc=91.89%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.129337 Test loss=0.293282 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13001573085784912
[5/24] Train loss=0.11988483369350433
[10/24] Train loss=0.12686122953891754
[15/24] Train loss=0.1294543594121933
[20/24] Train loss=0.11214450746774673
Test set avg_accuracy=88.76% avg_sensitivity=76.70%, avg_specificity=92.82% avg_auc=91.89%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.128898 Test loss=0.293281 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.13174499571323395
[5/24] Train loss=0.11820609867572784
[10/24] Train loss=0.12771956622600555
[15/24] Train loss=0.12717437744140625
[20/24] Train loss=0.11298154294490814
Test set avg_accuracy=88.76% avg_sensitivity=76.75%, avg_specificity=92.80% avg_auc=91.89%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.129079 Test loss=0.293394 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=89.23% sen=79.75%, spe=92.42%, auc=94.34%!
Fold[8] Avg_overlap=0.70%(±0.23791022526159425)
[0/23] Train loss=0.7282302379608154
[5/23] Train loss=0.7262518405914307
[10/23] Train loss=0.7215134501457214
[15/23] Train loss=0.7164390683174133
[20/23] Train loss=0.7040895223617554
Test set avg_accuracy=61.52% avg_sensitivity=42.53%, avg_specificity=67.57% avg_auc=57.52%
Best model saved!! Metric=-96.85344437591823!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.721016 Test loss=0.669081 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.7077527046203613
[5/23] Train loss=0.6955717206001282
[10/23] Train loss=0.6986674070358276
[15/23] Train loss=0.6922178268432617
[20/23] Train loss=0.6791864037513733
Test set avg_accuracy=64.78% avg_sensitivity=54.61%, avg_specificity=68.02% avg_auc=65.56%
Best model saved!! Metric=-73.0305232144785!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.695878 Test loss=0.647842 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.6749942898750305
[5/23] Train loss=0.678056001663208
[10/23] Train loss=0.670444667339325
[15/23] Train loss=0.6613810658454895
[20/23] Train loss=0.6579305529594421
Test set avg_accuracy=67.54% avg_sensitivity=59.35%, avg_specificity=70.15% avg_auc=70.93%
Best model saved!! Metric=-58.03412676922942!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.671497 Test loss=0.618281 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.6525335311889648
[5/23] Train loss=0.6496654748916626
[10/23] Train loss=0.6508535742759705
[15/23] Train loss=0.6426829695701599
[20/23] Train loss=0.6240123510360718
Test set avg_accuracy=69.96% avg_sensitivity=64.42%, avg_specificity=71.73% avg_auc=75.15%
Best model saved!! Metric=-44.747862518509294!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.646554 Test loss=0.593289 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.6276819109916687
[5/23] Train loss=0.6183578968048096
[10/23] Train loss=0.6294687986373901
[15/23] Train loss=0.6087138652801514
[20/23] Train loss=0.601783037185669
Test set avg_accuracy=72.40% avg_sensitivity=69.27%, avg_specificity=73.39% avg_auc=78.35%
Best model saved!! Metric=-32.58750597696361!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.618256 Test loss=0.568823 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.597303032875061
[5/23] Train loss=0.5892806053161621
[10/23] Train loss=0.60282963514328
[15/23] Train loss=0.5709589123725891
[20/23] Train loss=0.5716981291770935
Test set avg_accuracy=73.66% avg_sensitivity=72.24%, avg_specificity=74.11% avg_auc=81.02%
Best model saved!! Metric=-24.967459126486048!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.588577 Test loss=0.539889 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.562863290309906
[5/23] Train loss=0.5651873350143433
[10/23] Train loss=0.568415105342865
[15/23] Train loss=0.5454011559486389
[20/23] Train loss=0.537272572517395
Test set avg_accuracy=76.20% avg_sensitivity=73.32%, avg_specificity=77.12% avg_auc=83.62%
Best model saved!! Metric=-15.754037800438823!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.556777 Test loss=0.503833 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.5381433367729187
[5/23] Train loss=0.531317412853241
[10/23] Train loss=0.5376690626144409
[15/23] Train loss=0.5126628279685974
[20/23] Train loss=0.5078884959220886
Test set avg_accuracy=78.50% avg_sensitivity=73.85%, avg_specificity=79.98% avg_auc=85.68%
Best model saved!! Metric=-7.9778280256450245!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.528210 Test loss=0.472786 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.5048052668571472
[5/23] Train loss=0.497892290353775
[10/23] Train loss=0.5072861909866333
[15/23] Train loss=0.4857933223247528
[20/23] Train loss=0.4805028736591339
Test set avg_accuracy=81.21% avg_sensitivity=74.99%, avg_specificity=83.19% avg_auc=87.64%
Best model saved!! Metric=1.0339283725981119!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.498190 Test loss=0.444775 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.46644651889801025
[5/23] Train loss=0.4786270260810852
[10/23] Train loss=0.4810032248497009
[15/23] Train loss=0.4632788896560669
[20/23] Train loss=0.4508955776691437
Test set avg_accuracy=83.07% avg_sensitivity=74.45%, avg_specificity=85.82% avg_auc=89.12%
Best model saved!! Metric=6.457676566253667!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.470260 Test loss=0.416941 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.44435834884643555
[5/23] Train loss=0.4379654824733734
[10/23] Train loss=0.4608980417251587
[15/23] Train loss=0.43123859167099
[20/23] Train loss=0.42145103216171265
Test set avg_accuracy=84.70% avg_sensitivity=72.40%, avg_specificity=88.62% avg_auc=90.00%
Best model saved!! Metric=9.713715655354804!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.442099 Test loss=0.390213 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.4143267571926117
[5/23] Train loss=0.4121093153953552
[10/23] Train loss=0.43096989393234253
[15/23] Train loss=0.4111741781234741
[20/23] Train loss=0.3983197808265686
Test set avg_accuracy=85.48% avg_sensitivity=71.97%, avg_specificity=89.79% avg_auc=90.92%
Best model saved!! Metric=12.151280221022347!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.418698 Test loss=0.365634 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.39741411805152893
[5/23] Train loss=0.39493682980537415
[10/23] Train loss=0.41396644711494446
[15/23] Train loss=0.3890010416507721
[20/23] Train loss=0.37016698718070984
Test set avg_accuracy=87.03% avg_sensitivity=68.09%, avg_specificity=93.06% avg_auc=91.19%
Best model saved!! Metric=13.373672174149434!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.396978 Test loss=0.342818 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.37188124656677246
[5/23] Train loss=0.37502673268318176
[10/23] Train loss=0.39625170826911926
[15/23] Train loss=0.3668321669101715
[20/23] Train loss=0.3541029095649719
Test set avg_accuracy=87.42% avg_sensitivity=64.10%, avg_specificity=94.85% avg_auc=91.29%
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.378972 Test loss=0.328991 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.3588673770427704
[5/23] Train loss=0.34782829880714417
[10/23] Train loss=0.3792155086994171
[15/23] Train loss=0.34648579359054565
[20/23] Train loss=0.33701375126838684
Test set avg_accuracy=87.64% avg_sensitivity=64.74%, avg_specificity=94.94% avg_auc=91.62%
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.361750 Test loss=0.319529 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.3431386351585388
[5/23] Train loss=0.3309691846370697
[10/23] Train loss=0.3632206618785858
[15/23] Train loss=0.33232221007347107
[20/23] Train loss=0.3151112198829651
Test set avg_accuracy=88.15% avg_sensitivity=67.82%, avg_specificity=94.63% avg_auc=92.37%
Best model saved!! Metric=16.967658396766268!!
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.345821 Test loss=0.308445 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.3241293132305145
[5/23] Train loss=0.32017767429351807
[10/23] Train loss=0.353044718503952
[15/23] Train loss=0.32060521841049194
[20/23] Train loss=0.30178242921829224
Test set avg_accuracy=88.10% avg_sensitivity=70.08%, avg_specificity=93.84% avg_auc=92.64%
Best model saved!! Metric=18.65703706729674!!
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.334787 Test loss=0.301565 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.3181544542312622
[5/23] Train loss=0.3047212064266205
[10/23] Train loss=0.339731901884079
[15/23] Train loss=0.3103490471839905
[20/23] Train loss=0.29361823201179504
Test set avg_accuracy=88.24% avg_sensitivity=66.25%, avg_specificity=95.24% avg_auc=92.57%
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.324019 Test loss=0.295467 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.30334874987602234
[5/23] Train loss=0.2989802658557892
[10/23] Train loss=0.3329700529575348
[15/23] Train loss=0.30229151248931885
[20/23] Train loss=0.2810192108154297
Test set avg_accuracy=88.76% avg_sensitivity=72.51%, avg_specificity=93.94% avg_auc=93.14%
Best model saved!! Metric=22.347482270349616!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.315068 Test loss=0.287673 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.2928065061569214
[5/23] Train loss=0.287217915058136
[10/23] Train loss=0.32256096601486206
[15/23] Train loss=0.29256653785705566
[20/23] Train loss=0.2710551619529724
Test set avg_accuracy=88.63% avg_sensitivity=73.91%, avg_specificity=93.32% avg_auc=93.21%
Best model saved!! Metric=23.071362758551885!!
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.306683 Test loss=0.286724 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.28427979350090027
[5/23] Train loss=0.2785094678401947
[10/23] Train loss=0.32052290439605713
[15/23] Train loss=0.2858031690120697
[20/23] Train loss=0.26409173011779785
Test set avg_accuracy=88.95% avg_sensitivity=73.69%, avg_specificity=93.80% avg_auc=93.49%
Best model saved!! Metric=23.9319001936247!!
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.299270 Test loss=0.279555 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.2849707007408142
[5/23] Train loss=0.2684028148651123
[10/23] Train loss=0.3253284692764282
[15/23] Train loss=0.2785297930240631
[20/23] Train loss=0.2605631649494171
Test set avg_accuracy=89.08% avg_sensitivity=73.53%, avg_specificity=94.03% avg_auc=93.38%
Best model saved!! Metric=24.014988459399063!!
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.294088 Test loss=0.279432 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.27058207988739014
[5/23] Train loss=0.2570149004459381
[10/23] Train loss=0.3073675334453583
[15/23] Train loss=0.26718127727508545
[20/23] Train loss=0.2507722079753876
Test set avg_accuracy=88.55% avg_sensitivity=75.42%, avg_specificity=92.74% avg_auc=93.43%
Best model saved!! Metric=24.145562411791587!!
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.287296 Test loss=0.285522 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.2719365656375885
[5/23] Train loss=0.25667932629585266
[10/23] Train loss=0.3053005337715149
[15/23] Train loss=0.2679474353790283
[20/23] Train loss=0.24478042125701904
Test set avg_accuracy=88.23% avg_sensitivity=77.90%, avg_specificity=91.52% avg_auc=93.52%
Best model saved!! Metric=25.16720444878898!!
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.282893 Test loss=0.287768 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.27099117636680603
[5/23] Train loss=0.2516724467277527
[10/23] Train loss=0.29881638288497925
[15/23] Train loss=0.2549268305301666
[20/23] Train loss=0.2429552525281906
Test set avg_accuracy=88.26% avg_sensitivity=79.30%, avg_specificity=91.11% avg_auc=93.64%
Best model saved!! Metric=26.29716893164668!!
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.277751 Test loss=0.286875 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.2620941400527954
[5/23] Train loss=0.2427423894405365
[10/23] Train loss=0.29072272777557373
[15/23] Train loss=0.24940647184848785
[20/23] Train loss=0.24175462126731873
Test set avg_accuracy=87.19% avg_sensitivity=80.38%, avg_specificity=89.36% avg_auc=93.58%
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.273110 Test loss=0.297929 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.2556914687156677
[5/23] Train loss=0.24248142540454865
[10/23] Train loss=0.2877644896507263
[15/23] Train loss=0.2451002597808838
[20/23] Train loss=0.23222437500953674
Test set avg_accuracy=89.79% avg_sensitivity=73.58%, avg_specificity=94.95% avg_auc=93.53%
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.266475 Test loss=0.269964 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.24856826663017273
[5/23] Train loss=0.22958655655384064
[10/23] Train loss=0.29053473472595215
[15/23] Train loss=0.24423977732658386
[20/23] Train loss=0.22733163833618164
Test set avg_accuracy=89.75% avg_sensitivity=74.39%, avg_specificity=94.64% avg_auc=93.59%
Best model saved!! Metric=26.382554538588053!!
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.262543 Test loss=0.267010 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.24136699736118317
[5/23] Train loss=0.23481503129005432
[10/23] Train loss=0.28424862027168274
[15/23] Train loss=0.24327227473258972
[20/23] Train loss=0.2257443219423294
Test set avg_accuracy=89.41% avg_sensitivity=65.50%, avg_specificity=97.03% avg_auc=92.93%
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.258051 Test loss=0.274269 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.24179883301258087
[5/23] Train loss=0.22224369645118713
[10/23] Train loss=0.2816857397556305
[15/23] Train loss=0.23583699762821198
[20/23] Train loss=0.21930694580078125
Test set avg_accuracy=87.66% avg_sensitivity=79.30%, avg_specificity=90.32% avg_auc=92.95%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.256441 Test loss=0.301375 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.23940767347812653
[5/23] Train loss=0.2223789393901825
[10/23] Train loss=0.28027987480163574
[15/23] Train loss=0.2315039187669754
[20/23] Train loss=0.2187402844429016
Test set avg_accuracy=88.20% avg_sensitivity=80.43%, avg_specificity=90.68% avg_auc=93.43%
Best model saved!! Metric=26.74059824826763!!
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.252516 Test loss=0.300330 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.23652464151382446
[5/23] Train loss=0.22539441287517548
[10/23] Train loss=0.2799440026283264
[15/23] Train loss=0.22924324870109558
[20/23] Train loss=0.21293742954730988
Test set avg_accuracy=87.08% avg_sensitivity=80.16%, avg_specificity=89.29% avg_auc=92.63%
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.247893 Test loss=0.313782 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.23556946218013763
[5/23] Train loss=0.2164335697889328
[10/23] Train loss=0.2753952145576477
[15/23] Train loss=0.22450940310955048
[20/23] Train loss=0.21281889081001282
Test set avg_accuracy=86.63% avg_sensitivity=74.99%, avg_specificity=90.33% avg_auc=91.00%
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.242672 Test loss=0.331460 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.22783121466636658
[5/23] Train loss=0.21702940762043
[10/23] Train loss=0.2799580991268158
[15/23] Train loss=0.2293475717306137
[20/23] Train loss=0.21440166234970093
Test set avg_accuracy=88.95% avg_sensitivity=73.26%, avg_specificity=93.94% avg_auc=92.92%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.244387 Test loss=0.272306 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.2270447164773941
[5/23] Train loss=0.2118883728981018
[10/23] Train loss=0.2751253843307495
[15/23] Train loss=0.21942999958992004
[20/23] Train loss=0.21248185634613037
Test set avg_accuracy=89.14% avg_sensitivity=72.40%, avg_specificity=94.47% avg_auc=92.80%
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.239279 Test loss=0.275344 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.22025758028030396
[5/23] Train loss=0.20389418303966522
[10/23] Train loss=0.2684277594089508
[15/23] Train loss=0.2158546894788742
[20/23] Train loss=0.20993563532829285
Test set avg_accuracy=84.60% avg_sensitivity=85.18%, avg_specificity=84.41% avg_auc=92.86%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.237730 Test loss=0.333778 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.22950662672519684
[5/23] Train loss=0.19989551603794098
[10/23] Train loss=0.267676442861557
[15/23] Train loss=0.2132905125617981
[20/23] Train loss=0.21456295251846313
Test set avg_accuracy=86.30% avg_sensitivity=77.36%, avg_specificity=89.15% avg_auc=91.60%
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.237237 Test loss=0.317422 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.21877503395080566
[5/23] Train loss=0.19378145039081573
[10/23] Train loss=0.2704935073852539
[15/23] Train loss=0.21586869657039642
[20/23] Train loss=0.20509304106235504
Test set avg_accuracy=87.90% avg_sensitivity=65.39%, avg_specificity=95.07% avg_auc=91.43%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.233582 Test loss=0.297666 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.21789921820163727
[5/23] Train loss=0.19873927533626556
[10/23] Train loss=0.25674116611480713
[15/23] Train loss=0.2230803668498993
[20/23] Train loss=0.20374754071235657
Test set avg_accuracy=87.62% avg_sensitivity=76.28%, avg_specificity=91.23% avg_auc=92.55%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.231689 Test loss=0.291975 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.21502149105072021
[5/23] Train loss=0.21364378929138184
[10/23] Train loss=0.27359166741371155
[15/23] Train loss=0.21827538311481476
[20/23] Train loss=0.22475653886795044
Test set avg_accuracy=88.52% avg_sensitivity=71.16%, avg_specificity=94.04% avg_auc=92.05%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.234256 Test loss=0.287464 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.21977002918720245
[5/23] Train loss=0.19968503713607788
[10/23] Train loss=0.26843297481536865
[15/23] Train loss=0.21640712022781372
[20/23] Train loss=0.20282882452011108
Test set avg_accuracy=87.93% avg_sensitivity=72.99%, avg_specificity=92.69% avg_auc=92.87%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.228732 Test loss=0.283259 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.21614781022071838
[5/23] Train loss=0.19011394679546356
[10/23] Train loss=0.24881094694137573
[15/23] Train loss=0.21338273584842682
[20/23] Train loss=0.20097553730010986
Test set avg_accuracy=88.28% avg_sensitivity=76.71%, avg_specificity=91.97% avg_auc=92.98%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.229194 Test loss=0.289278 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.2132219672203064
[5/23] Train loss=0.18539777398109436
[10/23] Train loss=0.2527943551540375
[15/23] Train loss=0.2119123339653015
[20/23] Train loss=0.20973683893680573
Test set avg_accuracy=86.61% avg_sensitivity=66.52%, avg_specificity=93.01% avg_auc=89.81%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.225827 Test loss=0.322426 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.21256428956985474
[5/23] Train loss=0.19615784287452698
[10/23] Train loss=0.26377397775650024
[15/23] Train loss=0.20563718676567078
[20/23] Train loss=0.20133216679096222
Test set avg_accuracy=85.61% avg_sensitivity=51.59%, avg_specificity=96.45% avg_auc=87.62%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.224677 Test loss=0.368508 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.22785823047161102
[5/23] Train loss=0.19740235805511475
[10/23] Train loss=0.25809165835380554
[15/23] Train loss=0.2107609510421753
[20/23] Train loss=0.2025490254163742
Test set avg_accuracy=85.25% avg_sensitivity=80.11%, avg_specificity=86.88% avg_auc=91.86%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.229470 Test loss=0.328480 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.20961424708366394
[5/23] Train loss=0.19359427690505981
[10/23] Train loss=0.2530283033847809
[15/23] Train loss=0.2028002142906189
[20/23] Train loss=0.18877482414245605
Test set avg_accuracy=88.87% avg_sensitivity=70.03%, avg_specificity=94.87% avg_auc=91.53%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.218861 Test loss=0.291887 Current lr=[0.000299926900870094]

[0/23] Train loss=0.2124498337507248
[5/23] Train loss=0.17822369933128357
[10/23] Train loss=0.23750270903110504
[15/23] Train loss=0.2055312842130661
[20/23] Train loss=0.1877899169921875
Test set avg_accuracy=88.83% avg_sensitivity=77.25%, avg_specificity=92.52% avg_auc=93.22%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.216197 Test loss=0.271292 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.2114592045545578
[5/23] Train loss=0.18102338910102844
[10/23] Train loss=0.24368733167648315
[15/23] Train loss=0.20286214351654053
[20/23] Train loss=0.18219318985939026
Test set avg_accuracy=87.15% avg_sensitivity=79.84%, avg_specificity=89.48% avg_auc=92.43%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.215794 Test loss=0.310372 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.20787189900875092
[5/23] Train loss=0.18687772750854492
[10/23] Train loss=0.24821491539478302
[15/23] Train loss=0.20560303330421448
[20/23] Train loss=0.19340932369232178
Test set avg_accuracy=88.24% avg_sensitivity=64.85%, avg_specificity=95.69% avg_auc=92.44%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.220787 Test loss=0.287236 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.2116788625717163
[5/23] Train loss=0.18208204209804535
[10/23] Train loss=0.24425844848155975
[15/23] Train loss=0.21105004847049713
[20/23] Train loss=0.19033484160900116
Test set avg_accuracy=86.77% avg_sensitivity=78.01%, avg_specificity=89.56% avg_auc=92.21%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.218167 Test loss=0.308028 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.2010364979505539
[5/23] Train loss=0.18188060820102692
[10/23] Train loss=0.23527954518795013
[15/23] Train loss=0.20637774467468262
[20/23] Train loss=0.19509164988994598
Test set avg_accuracy=88.54% avg_sensitivity=76.28%, avg_specificity=92.45% avg_auc=93.43%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.217711 Test loss=0.272418 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.2101895809173584
[5/23] Train loss=0.17627406120300293
[10/23] Train loss=0.23135891556739807
[15/23] Train loss=0.20981937646865845
[20/23] Train loss=0.17761704325675964
Test set avg_accuracy=86.65% avg_sensitivity=59.46%, avg_specificity=95.31% avg_auc=90.36%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.217438 Test loss=0.322435 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.21046976745128632
[5/23] Train loss=0.1835566908121109
[10/23] Train loss=0.2493695169687271
[15/23] Train loss=0.2059992402791977
[20/23] Train loss=0.1894492506980896
Test set avg_accuracy=85.79% avg_sensitivity=80.65%, avg_specificity=87.43% avg_auc=92.16%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.216806 Test loss=0.332595 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.21423445641994476
[5/23] Train loss=0.18725447356700897
[10/23] Train loss=0.2251608520746231
[15/23] Train loss=0.2071019858121872
[20/23] Train loss=0.2149909883737564
Test set avg_accuracy=82.04% avg_sensitivity=82.32%, avg_specificity=81.96% avg_auc=89.89%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.218019 Test loss=0.391408 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.21703825891017914
[5/23] Train loss=0.186287984251976
[10/23] Train loss=0.22474394738674164
[15/23] Train loss=0.21244746446609497
[20/23] Train loss=0.18869081139564514
Test set avg_accuracy=88.35% avg_sensitivity=67.22%, avg_specificity=95.07% avg_auc=92.09%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.217131 Test loss=0.295320 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.21015386283397675
[5/23] Train loss=0.1796397864818573
[10/23] Train loss=0.24946288764476776
[15/23] Train loss=0.2136448323726654
[20/23] Train loss=0.1870490461587906
Test set avg_accuracy=86.05% avg_sensitivity=81.94%, avg_specificity=87.36% avg_auc=92.32%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.216988 Test loss=0.317455 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.21338847279548645
[5/23] Train loss=0.178847074508667
[10/23] Train loss=0.22948381304740906
[15/23] Train loss=0.20964911580085754
[20/23] Train loss=0.1880982369184494
Test set avg_accuracy=87.76% avg_sensitivity=72.08%, avg_specificity=92.76% avg_auc=92.53%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.211262 Test loss=0.286756 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.20446275174617767
[5/23] Train loss=0.17599494755268097
[10/23] Train loss=0.21669620275497437
[15/23] Train loss=0.1956656575202942
[20/23] Train loss=0.1845814287662506
Test set avg_accuracy=87.75% avg_sensitivity=70.08%, avg_specificity=93.37% avg_auc=91.60%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.204276 Test loss=0.295203 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.1958201825618744
[5/23] Train loss=0.17355118691921234
[10/23] Train loss=0.22409074008464813
[15/23] Train loss=0.18695811927318573
[20/23] Train loss=0.18119263648986816
Test set avg_accuracy=86.82% avg_sensitivity=59.08%, avg_specificity=95.66% avg_auc=87.34%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.200658 Test loss=0.343986 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.20053109526634216
[5/23] Train loss=0.17958255112171173
[10/23] Train loss=0.22979260981082916
[15/23] Train loss=0.19656996428966522
[20/23] Train loss=0.17918074131011963
Test set avg_accuracy=88.19% avg_sensitivity=65.88%, avg_specificity=95.30% avg_auc=91.07%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.205128 Test loss=0.300839 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.19148407876491547
[5/23] Train loss=0.1655748188495636
[10/23] Train loss=0.219952791929245
[15/23] Train loss=0.19102033972740173
[20/23] Train loss=0.17121049761772156
Test set avg_accuracy=87.06% avg_sensitivity=54.18%, avg_specificity=97.53% avg_auc=87.02%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.197488 Test loss=0.367779 Current lr=[0.000283047938381597]

[0/23] Train loss=0.18821175396442413
[5/23] Train loss=0.16580455005168915
[10/23] Train loss=0.22216549515724182
[15/23] Train loss=0.20014387369155884
[20/23] Train loss=0.17821986973285675
Test set avg_accuracy=85.48% avg_sensitivity=51.91%, avg_specificity=96.17% avg_auc=87.65%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.200762 Test loss=0.366374 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.18315303325653076
[5/23] Train loss=0.18558599054813385
[10/23] Train loss=0.23680421710014343
[15/23] Train loss=0.18160668015480042
[20/23] Train loss=0.1756458431482315
Test set avg_accuracy=88.45% avg_sensitivity=63.18%, avg_specificity=96.50% avg_auc=90.33%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.199943 Test loss=0.314484 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.18658819794654846
[5/23] Train loss=0.17497453093528748
[10/23] Train loss=0.20219412446022034
[15/23] Train loss=0.19034433364868164
[20/23] Train loss=0.1749151051044464
Test set avg_accuracy=87.85% avg_sensitivity=64.26%, avg_specificity=95.36% avg_auc=90.30%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.197437 Test loss=0.314444 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.18797440826892853
[5/23] Train loss=0.1755741983652115
[10/23] Train loss=0.22186002135276794
[15/23] Train loss=0.19315996766090393
[20/23] Train loss=0.1852990835905075
Test set avg_accuracy=87.59% avg_sensitivity=68.03%, avg_specificity=93.82% avg_auc=91.40%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.201739 Test loss=0.305983 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.19473524391651154
[5/23] Train loss=0.16578571498394012
[10/23] Train loss=0.21663857996463776
[15/23] Train loss=0.1831730753183365
[20/23] Train loss=0.17864005267620087
Test set avg_accuracy=87.98% avg_sensitivity=79.84%, avg_specificity=90.58% avg_auc=92.05%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.198131 Test loss=0.305853 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.19072675704956055
[5/23] Train loss=0.1675097942352295
[10/23] Train loss=0.2341364622116089
[15/23] Train loss=0.18471229076385498
[20/23] Train loss=0.16874578595161438
Test set avg_accuracy=87.11% avg_sensitivity=73.64%, avg_specificity=91.40% avg_auc=91.17%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.198790 Test loss=0.312587 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.19481562077999115
[5/23] Train loss=0.16571678221225739
[10/23] Train loss=0.2072240263223648
[15/23] Train loss=0.18846876919269562
[20/23] Train loss=0.16851238906383514
Test set avg_accuracy=86.73% avg_sensitivity=53.37%, avg_specificity=97.36% avg_auc=85.99%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.191036 Test loss=0.365383 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.19218039512634277
[5/23] Train loss=0.17589034140110016
[10/23] Train loss=0.2055802345275879
[15/23] Train loss=0.1815561205148697
[20/23] Train loss=0.16868998110294342
Test set avg_accuracy=87.84% avg_sensitivity=68.95%, avg_specificity=93.85% avg_auc=90.87%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.192357 Test loss=0.305870 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.18666160106658936
[5/23] Train loss=0.16586339473724365
[10/23] Train loss=0.20672564208507538
[15/23] Train loss=0.17572848498821259
[20/23] Train loss=0.17020538449287415
Test set avg_accuracy=86.17% avg_sensitivity=80.49%, avg_specificity=87.98% avg_auc=91.60%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.190498 Test loss=0.326851 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.19566762447357178
[5/23] Train loss=0.16826105117797852
[10/23] Train loss=0.21273070573806763
[15/23] Train loss=0.1736438274383545
[20/23] Train loss=0.17286936938762665
Test set avg_accuracy=86.82% avg_sensitivity=69.76%, avg_specificity=92.26% avg_auc=90.01%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.188688 Test loss=0.322993 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.18124635517597198
[5/23] Train loss=0.15852922201156616
[10/23] Train loss=0.19718457758426666
[15/23] Train loss=0.17446865141391754
[20/23] Train loss=0.159720316529274
Test set avg_accuracy=87.03% avg_sensitivity=52.72%, avg_specificity=97.96% avg_auc=85.17%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.184377 Test loss=0.386877 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.17553921043872833
[5/23] Train loss=0.162759929895401
[10/23] Train loss=0.1988137662410736
[15/23] Train loss=0.1787293553352356
[20/23] Train loss=0.16691100597381592
Test set avg_accuracy=87.96% avg_sensitivity=61.99%, avg_specificity=96.22% avg_auc=89.15%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.184847 Test loss=0.324828 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.17754016816616058
[5/23] Train loss=0.1607130765914917
[10/23] Train loss=0.20530155301094055
[15/23] Train loss=0.18272210657596588
[20/23] Train loss=0.16912487149238586
Test set avg_accuracy=87.57% avg_sensitivity=71.91%, avg_specificity=92.55% avg_auc=91.24%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.183662 Test loss=0.309443 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.18699555099010468
[5/23] Train loss=0.15543565154075623
[10/23] Train loss=0.19469916820526123
[15/23] Train loss=0.17184370756149292
[20/23] Train loss=0.15878364443778992
Test set avg_accuracy=87.30% avg_sensitivity=63.77%, avg_specificity=94.80% avg_auc=89.59%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.181712 Test loss=0.325703 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.17093400657176971
[5/23] Train loss=0.1552075296640396
[10/23] Train loss=0.20554867386817932
[15/23] Train loss=0.1616561859846115
[20/23] Train loss=0.16264934837818146
Test set avg_accuracy=87.71% avg_sensitivity=63.67%, avg_specificity=95.36% avg_auc=90.30%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.180544 Test loss=0.313436 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.1739012897014618
[5/23] Train loss=0.1526840329170227
[10/23] Train loss=0.19862474501132965
[15/23] Train loss=0.1622007042169571
[20/23] Train loss=0.16564323008060455
Test set avg_accuracy=84.95% avg_sensitivity=41.19%, avg_specificity=98.88% avg_auc=83.69%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.182677 Test loss=0.445168 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.17173518240451813
[5/23] Train loss=0.15882793068885803
[10/23] Train loss=0.19105806946754456
[15/23] Train loss=0.16897501051425934
[20/23] Train loss=0.17385289072990417
Test set avg_accuracy=86.65% avg_sensitivity=50.94%, avg_specificity=98.03% avg_auc=88.03%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.181724 Test loss=0.371671 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.17780345678329468
[5/23] Train loss=0.1613500714302063
[10/23] Train loss=0.19224275648593903
[15/23] Train loss=0.17162318527698517
[20/23] Train loss=0.15975472331047058
Test set avg_accuracy=87.28% avg_sensitivity=61.08%, avg_specificity=95.62% avg_auc=90.67%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.183492 Test loss=0.321322 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.17696186900138855
[5/23] Train loss=0.1465430110692978
[10/23] Train loss=0.19758008420467377
[15/23] Train loss=0.16743412613868713
[20/23] Train loss=0.15394048392772675
Test set avg_accuracy=87.41% avg_sensitivity=69.70%, avg_specificity=93.05% avg_auc=90.29%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.178227 Test loss=0.313487 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.1835499256849289
[5/23] Train loss=0.1487058699131012
[10/23] Train loss=0.188898503780365
[15/23] Train loss=0.17046797275543213
[20/23] Train loss=0.16661064326763153
Test set avg_accuracy=87.90% avg_sensitivity=63.88%, avg_specificity=95.55% avg_auc=88.78%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.179740 Test loss=0.323612 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.17009109258651733
[5/23] Train loss=0.15497420728206635
[10/23] Train loss=0.20083297789096832
[15/23] Train loss=0.17312651872634888
[20/23] Train loss=0.156712606549263
Test set avg_accuracy=87.19% avg_sensitivity=59.25%, avg_specificity=96.09% avg_auc=88.67%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.179087 Test loss=0.334406 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.1646059900522232
[5/23] Train loss=0.1457757204771042
[10/23] Train loss=0.17821894586086273
[15/23] Train loss=0.1566745489835739
[20/23] Train loss=0.1550760716199875
Test set avg_accuracy=87.68% avg_sensitivity=76.87%, avg_specificity=91.12% avg_auc=92.12%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.175353 Test loss=0.301928 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.16809894144535065
[5/23] Train loss=0.15129227936267853
[10/23] Train loss=0.1849483847618103
[15/23] Train loss=0.16543424129486084
[20/23] Train loss=0.16094271838665009
Test set avg_accuracy=87.77% avg_sensitivity=60.00%, avg_specificity=96.62% avg_auc=89.54%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.178319 Test loss=0.324336 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.1680683195590973
[5/23] Train loss=0.15309616923332214
[10/23] Train loss=0.19018007814884186
[15/23] Train loss=0.1592414826154709
[20/23] Train loss=0.16338196396827698
Test set avg_accuracy=88.39% avg_sensitivity=67.28%, avg_specificity=95.11% avg_auc=91.95%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.178157 Test loss=0.292364 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.16497835516929626
[5/23] Train loss=0.15132564306259155
[10/23] Train loss=0.18416287004947662
[15/23] Train loss=0.15651020407676697
[20/23] Train loss=0.15649265050888062
Test set avg_accuracy=87.77% avg_sensitivity=60.22%, avg_specificity=96.55% avg_auc=89.31%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.175406 Test loss=0.343132 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.1826360821723938
[5/23] Train loss=0.15263237059116364
[10/23] Train loss=0.19469892978668213
[15/23] Train loss=0.1655801236629486
[20/23] Train loss=0.1526482254266739
Test set avg_accuracy=87.42% avg_sensitivity=70.30%, avg_specificity=92.88% avg_auc=92.18%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.181809 Test loss=0.301369 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.17968672513961792
[5/23] Train loss=0.15387669205665588
[10/23] Train loss=0.18159016966819763
[15/23] Train loss=0.1682218313217163
[20/23] Train loss=0.16192752122879028
Test set avg_accuracy=84.79% avg_sensitivity=83.72%, avg_specificity=85.13% avg_auc=91.86%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.176134 Test loss=0.351264 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.18427163362503052
[5/23] Train loss=0.15390437841415405
[10/23] Train loss=0.17736591398715973
[15/23] Train loss=0.16672389209270477
[20/23] Train loss=0.16016645729541779
Test set avg_accuracy=84.51% avg_sensitivity=81.40%, avg_specificity=85.49% avg_auc=91.48%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.178445 Test loss=0.356638 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.17327989637851715
[5/23] Train loss=0.1575290560722351
[10/23] Train loss=0.16806885600090027
[15/23] Train loss=0.16525521874427795
[20/23] Train loss=0.15386530756950378
Test set avg_accuracy=87.88% avg_sensitivity=65.66%, avg_specificity=94.95% avg_auc=91.44%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.174906 Test loss=0.309854 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.16423837840557098
[5/23] Train loss=0.14970164000988007
[10/23] Train loss=0.171798437833786
[15/23] Train loss=0.15793699026107788
[20/23] Train loss=0.14878986775875092
Test set avg_accuracy=87.06% avg_sensitivity=55.15%, avg_specificity=97.22% avg_auc=88.10%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.168325 Test loss=0.357876 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.16613222658634186
[5/23] Train loss=0.14889603853225708
[10/23] Train loss=0.17067261040210724
[15/23] Train loss=0.15139205753803253
[20/23] Train loss=0.1518387496471405
Test set avg_accuracy=86.29% avg_sensitivity=72.18%, avg_specificity=90.78% avg_auc=90.11%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.167610 Test loss=0.335259 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.1672137826681137
[5/23] Train loss=0.14138661324977875
[10/23] Train loss=0.16871266067028046
[15/23] Train loss=0.15382786095142365
[20/23] Train loss=0.14889571070671082
Test set avg_accuracy=86.89% avg_sensitivity=68.52%, avg_specificity=92.74% avg_auc=90.12%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.166299 Test loss=0.328887 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.15773150324821472
[5/23] Train loss=0.1487531065940857
[10/23] Train loss=0.1656707376241684
[15/23] Train loss=0.15827268362045288
[20/23] Train loss=0.14971576631069183
Test set avg_accuracy=86.55% avg_sensitivity=67.06%, avg_specificity=92.76% avg_auc=90.14%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.165289 Test loss=0.332142 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.16082851588726044
[5/23] Train loss=0.14617307484149933
[10/23] Train loss=0.16861292719841003
[15/23] Train loss=0.1575770080089569
[20/23] Train loss=0.1540004163980484
Test set avg_accuracy=87.92% avg_sensitivity=64.26%, avg_specificity=95.45% avg_auc=89.82%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.165962 Test loss=0.325615 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.1592000275850296
[5/23] Train loss=0.14523489773273468
[10/23] Train loss=0.16490794718265533
[15/23] Train loss=0.1569753885269165
[20/23] Train loss=0.15007740259170532
Test set avg_accuracy=88.15% avg_sensitivity=71.05%, avg_specificity=93.60% avg_auc=91.46%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.165848 Test loss=0.304119 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.16000321507453918
[5/23] Train loss=0.14630047976970673
[10/23] Train loss=0.16803917288780212
[15/23] Train loss=0.14806462824344635
[20/23] Train loss=0.14284242689609528
Test set avg_accuracy=88.19% avg_sensitivity=63.72%, avg_specificity=95.98% avg_auc=89.38%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.160968 Test loss=0.323727 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.16555805504322052
[5/23] Train loss=0.14438588917255402
[10/23] Train loss=0.16076000034809113
[15/23] Train loss=0.15030509233474731
[20/23] Train loss=0.14573457837104797
Test set avg_accuracy=88.22% avg_sensitivity=68.52%, avg_specificity=94.49% avg_auc=90.99%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.161771 Test loss=0.301190 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.15794697403907776
[5/23] Train loss=0.14315882325172424
[10/23] Train loss=0.16443650424480438
[15/23] Train loss=0.15644638240337372
[20/23] Train loss=0.14544284343719482
Test set avg_accuracy=87.88% avg_sensitivity=61.13%, avg_specificity=96.39% avg_auc=88.60%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.160287 Test loss=0.335359 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.15195955336093903
[5/23] Train loss=0.1418348103761673
[10/23] Train loss=0.16683155298233032
[15/23] Train loss=0.15667347609996796
[20/23] Train loss=0.14667925238609314
Test set avg_accuracy=88.55% avg_sensitivity=67.28%, avg_specificity=95.33% avg_auc=90.39%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.162564 Test loss=0.309482 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.16078433394432068
[5/23] Train loss=0.13850997388362885
[10/23] Train loss=0.1682152897119522
[15/23] Train loss=0.1499876081943512
[20/23] Train loss=0.1415286511182785
Test set avg_accuracy=87.34% avg_sensitivity=54.29%, avg_specificity=97.87% avg_auc=88.22%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.160915 Test loss=0.353047 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.14854605495929718
[5/23] Train loss=0.1437218338251114
[10/23] Train loss=0.15963134169578552
[15/23] Train loss=0.14763577282428741
[20/23] Train loss=0.13954149186611176
Test set avg_accuracy=87.62% avg_sensitivity=58.44%, avg_specificity=96.91% avg_auc=87.18%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.157914 Test loss=0.345551 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.15229423344135284
[5/23] Train loss=0.14141029119491577
[10/23] Train loss=0.16326920688152313
[15/23] Train loss=0.15208271145820618
[20/23] Train loss=0.14244209229946136
Test set avg_accuracy=88.63% avg_sensitivity=72.08%, avg_specificity=93.91% avg_auc=92.35%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.159527 Test loss=0.286667 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.14814624190330505
[5/23] Train loss=0.1458219587802887
[10/23] Train loss=0.15495911240577698
[15/23] Train loss=0.1582472175359726
[20/23] Train loss=0.14444825053215027
Test set avg_accuracy=88.09% avg_sensitivity=63.72%, avg_specificity=95.85% avg_auc=89.81%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.159799 Test loss=0.319713 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.15680824220180511
[5/23] Train loss=0.14673548936843872
[10/23] Train loss=0.1661093384027481
[15/23] Train loss=0.15557700395584106
[20/23] Train loss=0.14067399501800537
Test set avg_accuracy=88.61% avg_sensitivity=68.25%, avg_specificity=95.09% avg_auc=91.57%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.158225 Test loss=0.299897 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.14600668847560883
[5/23] Train loss=0.13669221103191376
[10/23] Train loss=0.1567201316356659
[15/23] Train loss=0.14322681725025177
[20/23] Train loss=0.14356009662151337
Test set avg_accuracy=87.99% avg_sensitivity=76.33%, avg_specificity=91.71% avg_auc=91.57%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.152758 Test loss=0.309863 Current lr=[0.000112073915556435]

[0/23] Train loss=0.14950527250766754
[5/23] Train loss=0.13944081962108612
[10/23] Train loss=0.15572302043437958
[15/23] Train loss=0.1488150954246521
[20/23] Train loss=0.1394171416759491
Test set avg_accuracy=87.59% avg_sensitivity=71.97%, avg_specificity=92.57% avg_auc=90.44%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.154852 Test loss=0.314717 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.14986582100391388
[5/23] Train loss=0.14387138187885284
[10/23] Train loss=0.15788644552230835
[15/23] Train loss=0.15103502571582794
[20/23] Train loss=0.13993485271930695
Test set avg_accuracy=88.22% avg_sensitivity=67.01%, avg_specificity=94.97% avg_auc=90.67%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.155945 Test loss=0.309498 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.1504015028476715
[5/23] Train loss=0.1493406742811203
[10/23] Train loss=0.14909687638282776
[15/23] Train loss=0.1532910168170929
[20/23] Train loss=0.13739021122455597
Test set avg_accuracy=87.21% avg_sensitivity=52.67%, avg_specificity=98.21% avg_auc=87.00%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.155925 Test loss=0.382017 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.1473497450351715
[5/23] Train loss=0.15336087346076965
[10/23] Train loss=0.1593540608882904
[15/23] Train loss=0.14439840614795685
[20/23] Train loss=0.1317499727010727
Test set avg_accuracy=88.50% avg_sensitivity=72.51%, avg_specificity=93.60% avg_auc=92.03%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.152823 Test loss=0.299144 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.1515646129846573
[5/23] Train loss=0.13657167553901672
[10/23] Train loss=0.14873982965946198
[15/23] Train loss=0.141393780708313
[20/23] Train loss=0.13457153737545013
Test set avg_accuracy=88.41% avg_sensitivity=73.80%, avg_specificity=93.06% avg_auc=92.97%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.150348 Test loss=0.295254 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.14391295611858368
[5/23] Train loss=0.1308901309967041
[10/23] Train loss=0.15860861539840698
[15/23] Train loss=0.1394631713628769
[20/23] Train loss=0.13250288367271423
Test set avg_accuracy=87.93% avg_sensitivity=73.37%, avg_specificity=92.57% avg_auc=92.52%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.147997 Test loss=0.299770 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.13912524282932281
[5/23] Train loss=0.13427887856960297
[10/23] Train loss=0.14561787247657776
[15/23] Train loss=0.1372729390859604
[20/23] Train loss=0.1318841427564621
Test set avg_accuracy=88.23% avg_sensitivity=77.52%, avg_specificity=91.64% avg_auc=92.60%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.146428 Test loss=0.302274 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.13682711124420166
[5/23] Train loss=0.13570325076580048
[10/23] Train loss=0.14527350664138794
[15/23] Train loss=0.1357797533273697
[20/23] Train loss=0.13002260029315948
Test set avg_accuracy=88.14% avg_sensitivity=73.85%, avg_specificity=92.69% avg_auc=92.58%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.145272 Test loss=0.296951 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.1368345469236374
[5/23] Train loss=0.12937495112419128
[10/23] Train loss=0.1479988396167755
[15/23] Train loss=0.13297758996486664
[20/23] Train loss=0.13147452473640442
Test set avg_accuracy=88.01% avg_sensitivity=69.33%, avg_specificity=93.96% avg_auc=91.26%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.143418 Test loss=0.314032 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.13289731740951538
[5/23] Train loss=0.13606959581375122
[10/23] Train loss=0.14407648146152496
[15/23] Train loss=0.13227194547653198
[20/23] Train loss=0.12880253791809082
Test set avg_accuracy=87.59% avg_sensitivity=67.06%, avg_specificity=94.13% avg_auc=91.10%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.142553 Test loss=0.316963 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.13398928940296173
[5/23] Train loss=0.12929071485996246
[10/23] Train loss=0.14142844080924988
[15/23] Train loss=0.1327105015516281
[20/23] Train loss=0.12524613738059998
Test set avg_accuracy=87.15% avg_sensitivity=62.26%, avg_specificity=95.07% avg_auc=89.68%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.140903 Test loss=0.332208 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.13562136888504028
[5/23] Train loss=0.12921956181526184
[10/23] Train loss=0.13844150304794312
[15/23] Train loss=0.1319490224123001
[20/23] Train loss=0.12947224080562592
Test set avg_accuracy=87.94% avg_sensitivity=71.05%, avg_specificity=93.32% avg_auc=91.03%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.139115 Test loss=0.313942 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.13642293214797974
[5/23] Train loss=0.12750892341136932
[10/23] Train loss=0.1379716992378235
[15/23] Train loss=0.13238242268562317
[20/23] Train loss=0.12743888795375824
Test set avg_accuracy=87.92% avg_sensitivity=68.89%, avg_specificity=93.97% avg_auc=90.78%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.138606 Test loss=0.315781 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.13271184265613556
[5/23] Train loss=0.12446001917123795
[10/23] Train loss=0.13911835849285126
[15/23] Train loss=0.1309615522623062
[20/23] Train loss=0.12384523451328278
Test set avg_accuracy=87.62% avg_sensitivity=74.72%, avg_specificity=91.73% avg_auc=91.03%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.137531 Test loss=0.320315 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.13278694450855255
[5/23] Train loss=0.12436304986476898
[10/23] Train loss=0.13405925035476685
[15/23] Train loss=0.13163670897483826
[20/23] Train loss=0.13011224567890167
Test set avg_accuracy=88.07% avg_sensitivity=65.07%, avg_specificity=95.40% avg_auc=90.02%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.136864 Test loss=0.320768 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.1296662986278534
[5/23] Train loss=0.12470370531082153
[10/23] Train loss=0.1296941041946411
[15/23] Train loss=0.13216638565063477
[20/23] Train loss=0.12802110612392426
Test set avg_accuracy=87.80% avg_sensitivity=69.00%, avg_specificity=93.79% avg_auc=90.24%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.137132 Test loss=0.319931 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.13258394598960876
[5/23] Train loss=0.12959137558937073
[10/23] Train loss=0.13032037019729614
[15/23] Train loss=0.12904371321201324
[20/23] Train loss=0.12990455329418182
Test set avg_accuracy=87.68% avg_sensitivity=70.35%, avg_specificity=93.20% avg_auc=90.62%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.136626 Test loss=0.315966 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.1292218565940857
[5/23] Train loss=0.12344186007976532
[10/23] Train loss=0.13302579522132874
[15/23] Train loss=0.12828008830547333
[20/23] Train loss=0.12386156618595123
Test set avg_accuracy=87.67% avg_sensitivity=77.30%, avg_specificity=90.97% avg_auc=92.21%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.135024 Test loss=0.310245 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.1282983422279358
[5/23] Train loss=0.12141753733158112
[10/23] Train loss=0.13200533390045166
[15/23] Train loss=0.12217163294553757
[20/23] Train loss=0.12115930765867233
Test set avg_accuracy=88.16% avg_sensitivity=74.07%, avg_specificity=92.65% avg_auc=91.17%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.133267 Test loss=0.312019 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.12872250378131866
[5/23] Train loss=0.12306319922208786
[10/23] Train loss=0.13699465990066528
[15/23] Train loss=0.12510374188423157
[20/23] Train loss=0.12000168859958649
Test set avg_accuracy=87.57% avg_sensitivity=73.58%, avg_specificity=92.02% avg_auc=91.16%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.132877 Test loss=0.319067 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.12590624392032623
[5/23] Train loss=0.12443174421787262
[10/23] Train loss=0.1313701570034027
[15/23] Train loss=0.12782172858715057
[20/23] Train loss=0.12235891819000244
Test set avg_accuracy=87.47% avg_sensitivity=74.29%, avg_specificity=91.67% avg_auc=91.52%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.131395 Test loss=0.315638 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.12621954083442688
[5/23] Train loss=0.11895424872636795
[10/23] Train loss=0.13293035328388214
[15/23] Train loss=0.1263432502746582
[20/23] Train loss=0.11959584057331085
Test set avg_accuracy=88.32% avg_sensitivity=74.23%, avg_specificity=92.81% avg_auc=91.80%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.131528 Test loss=0.308861 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.12442634999752045
[5/23] Train loss=0.12052390724420547
[10/23] Train loss=0.12687331438064575
[15/23] Train loss=0.1256951093673706
[20/23] Train loss=0.11959758400917053
Test set avg_accuracy=87.92% avg_sensitivity=71.00%, avg_specificity=93.30% avg_auc=90.79%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.130272 Test loss=0.316857 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.12290022522211075
[5/23] Train loss=0.11894644796848297
[10/23] Train loss=0.12789785861968994
[15/23] Train loss=0.12675629556179047
[20/23] Train loss=0.11858024448156357
Test set avg_accuracy=87.89% avg_sensitivity=72.29%, avg_specificity=92.86% avg_auc=90.98%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.129890 Test loss=0.317279 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.12767164409160614
[5/23] Train loss=0.1208030954003334
[10/23] Train loss=0.1260368824005127
[15/23] Train loss=0.12419439107179642
[20/23] Train loss=0.11765728145837784
Test set avg_accuracy=87.84% avg_sensitivity=70.67%, avg_specificity=93.30% avg_auc=90.45%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.130529 Test loss=0.315101 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.12198618054389954
[5/23] Train loss=0.1234111562371254
[10/23] Train loss=0.12416280806064606
[15/23] Train loss=0.12372390180826187
[20/23] Train loss=0.11788677424192429
Test set avg_accuracy=88.26% avg_sensitivity=73.75%, avg_specificity=92.88% avg_auc=91.20%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.129895 Test loss=0.314450 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.12372638285160065
[5/23] Train loss=0.11854948103427887
[10/23] Train loss=0.12813535332679749
[15/23] Train loss=0.12264122068881989
[20/23] Train loss=0.12434867769479752
Test set avg_accuracy=88.12% avg_sensitivity=73.85%, avg_specificity=92.67% avg_auc=91.68%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.129911 Test loss=0.311287 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.123528391122818
[5/23] Train loss=0.11704205721616745
[10/23] Train loss=0.12599143385887146
[15/23] Train loss=0.12024905532598495
[20/23] Train loss=0.11732833087444305
Test set avg_accuracy=88.10% avg_sensitivity=73.42%, avg_specificity=92.77% avg_auc=91.56%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.128357 Test loss=0.311856 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.11843526363372803
[5/23] Train loss=0.11719220876693726
[10/23] Train loss=0.12259514629840851
[15/23] Train loss=0.12040103226900101
[20/23] Train loss=0.11807261407375336
Test set avg_accuracy=88.29% avg_sensitivity=71.86%, avg_specificity=93.53% avg_auc=91.35%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.127254 Test loss=0.309620 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.11891794204711914
[5/23] Train loss=0.11667633801698685
[10/23] Train loss=0.12164262682199478
[15/23] Train loss=0.11975561827421188
[20/23] Train loss=0.11647957563400269
Test set avg_accuracy=88.29% avg_sensitivity=72.88%, avg_specificity=93.20% avg_auc=91.26%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.126152 Test loss=0.312117 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.11951429396867752
[5/23] Train loss=0.11515965312719345
[10/23] Train loss=0.11926595121622086
[15/23] Train loss=0.11969955265522003
[20/23] Train loss=0.11502061039209366
Test set avg_accuracy=88.31% avg_sensitivity=72.56%, avg_specificity=93.32% avg_auc=91.55%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.126434 Test loss=0.307719 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.11837708950042725
[5/23] Train loss=0.11851949989795685
[10/23] Train loss=0.12122239917516708
[15/23] Train loss=0.11859462410211563
[20/23] Train loss=0.11424542218446732
Test set avg_accuracy=88.16% avg_sensitivity=73.91%, avg_specificity=92.70% avg_auc=91.57%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.125537 Test loss=0.310579 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.11888110637664795
[5/23] Train loss=0.11528711766004562
[10/23] Train loss=0.12036436051130295
[15/23] Train loss=0.11773382127285004
[20/23] Train loss=0.11386692523956299
Test set avg_accuracy=88.31% avg_sensitivity=72.08%, avg_specificity=93.48% avg_auc=91.28%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.125222 Test loss=0.311883 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.11925346404314041
[5/23] Train loss=0.11486101150512695
[10/23] Train loss=0.12139831483364105
[15/23] Train loss=0.11824826151132584
[20/23] Train loss=0.11424747854471207
Test set avg_accuracy=88.18% avg_sensitivity=72.13%, avg_specificity=93.29% avg_auc=91.40%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.125116 Test loss=0.311360 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.11690209805965424
[5/23] Train loss=0.11437635868787766
[10/23] Train loss=0.12376777827739716
[15/23] Train loss=0.11870771646499634
[20/23] Train loss=0.11272511631250381
Test set avg_accuracy=88.20% avg_sensitivity=72.61%, avg_specificity=93.17% avg_auc=91.37%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.125033 Test loss=0.310896 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.11861304193735123
[5/23] Train loss=0.11449485272169113
[10/23] Train loss=0.11830798536539078
[15/23] Train loss=0.11887074261903763
[20/23] Train loss=0.115289106965065
Test set avg_accuracy=88.28% avg_sensitivity=73.10%, avg_specificity=93.12% avg_auc=91.41%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.124117 Test loss=0.311307 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.1174004077911377
[5/23] Train loss=0.11466516554355621
[10/23] Train loss=0.11976317316293716
[15/23] Train loss=0.11565946787595749
[20/23] Train loss=0.11225803941488266
Test set avg_accuracy=88.31% avg_sensitivity=72.56%, avg_specificity=93.32% avg_auc=91.32%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.123593 Test loss=0.312134 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.11858485639095306
[5/23] Train loss=0.1140761747956276
[10/23] Train loss=0.12110400944948196
[15/23] Train loss=0.11898467689752579
[20/23] Train loss=0.11142117530107498
Test set avg_accuracy=88.29% avg_sensitivity=72.02%, avg_specificity=93.48% avg_auc=91.31%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.123979 Test loss=0.312159 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.11866653710603714
[5/23] Train loss=0.11401700228452682
[10/23] Train loss=0.11921591311693192
[15/23] Train loss=0.11818686127662659
[20/23] Train loss=0.11318997293710709
Test set avg_accuracy=88.31% avg_sensitivity=72.72%, avg_specificity=93.27% avg_auc=91.43%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.123864 Test loss=0.311960 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.1183420792222023
[5/23] Train loss=0.11238928139209747
[10/23] Train loss=0.12169856578111649
[15/23] Train loss=0.11812543123960495
[20/23] Train loss=0.1101706251502037
Test set avg_accuracy=88.29% avg_sensitivity=72.78%, avg_specificity=93.24% avg_auc=91.49%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.123804 Test loss=0.311610 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.1150398775935173
[5/23] Train loss=0.11254443228244781
[10/23] Train loss=0.12039178609848022
[15/23] Train loss=0.11766178905963898
[20/23] Train loss=0.11339669674634933
Test set avg_accuracy=88.36% avg_sensitivity=72.72%, avg_specificity=93.34% avg_auc=91.47%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.123240 Test loss=0.311660 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.120615653693676
[5/23] Train loss=0.11323507875204086
[10/23] Train loss=0.12180320173501968
[15/23] Train loss=0.11813332885503769
[20/23] Train loss=0.11155307292938232
Test set avg_accuracy=88.35% avg_sensitivity=72.56%, avg_specificity=93.37% avg_auc=91.48%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.124280 Test loss=0.311473 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.11925298720598221
[5/23] Train loss=0.11395693570375443
[10/23] Train loss=0.12279468029737473
[15/23] Train loss=0.1159314215183258
[20/23] Train loss=0.11245589703321457
Test set avg_accuracy=88.32% avg_sensitivity=72.51%, avg_specificity=93.36% avg_auc=91.44%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.124321 Test loss=0.311825 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.11432605236768723
[5/23] Train loss=0.11323408782482147
[10/23] Train loss=0.11964577436447144
[15/23] Train loss=0.11811133474111557
[20/23] Train loss=0.11332733929157257
Test set avg_accuracy=88.33% avg_sensitivity=72.67%, avg_specificity=93.32% avg_auc=91.49%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.123246 Test loss=0.311634 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=88.20% sen=80.43%, spe=90.68%, auc=93.43%!
Fold[9] Avg_overlap=0.68%(±0.2415745195410518)
[0/24] Train loss=0.730418860912323
[5/24] Train loss=0.7180289030075073
[10/24] Train loss=0.7145782113075256
[15/24] Train loss=0.7049582004547119
[20/24] Train loss=0.6946380138397217
Test set avg_accuracy=61.51% avg_sensitivity=40.90%, avg_specificity=67.48% avg_auc=57.84%
Best model saved!! Metric=-98.26417462827862!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.709846 Test loss=0.661080 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6933556199073792
[5/24] Train loss=0.6822596788406372
[10/24] Train loss=0.6842758655548096
[15/24] Train loss=0.6733816862106323
[20/24] Train loss=0.6550394296646118
Test set avg_accuracy=68.33% avg_sensitivity=50.58%, avg_specificity=73.48% avg_auc=70.05%
Best model saved!! Metric=-63.561391227426235!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.679172 Test loss=0.590430 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6611825823783875
[5/24] Train loss=0.6546199917793274
[10/24] Train loss=0.6582940816879272
[15/24] Train loss=0.6477321982383728
[20/24] Train loss=0.637130618095398
Test set avg_accuracy=74.52% avg_sensitivity=58.29%, avg_specificity=79.22% avg_auc=76.17%
Best model saved!! Metric=-37.80393523706046!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.653103 Test loss=0.551924 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6285446286201477
[5/24] Train loss=0.6321945786476135
[10/24] Train loss=0.6296132802963257
[15/24] Train loss=0.6287676095962524
[20/24] Train loss=0.6067368984222412
Test set avg_accuracy=76.12% avg_sensitivity=63.62%, avg_specificity=79.74% avg_auc=79.38%
Best model saved!! Metric=-27.144000924738044!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.626975 Test loss=0.520668 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5941585302352905
[5/24] Train loss=0.5981162190437317
[10/24] Train loss=0.6083061099052429
[15/24] Train loss=0.5961115956306458
[20/24] Train loss=0.5871500372886658
Test set avg_accuracy=78.05% avg_sensitivity=68.71%, avg_specificity=80.75% avg_auc=82.39%
Best model saved!! Metric=-16.092697177734976!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.601406 Test loss=0.490029 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5744073390960693
[5/24] Train loss=0.5768831968307495
[10/24] Train loss=0.5851238965988159
[15/24] Train loss=0.5687009692192078
[20/24] Train loss=0.5609697103500366
Test set avg_accuracy=79.65% avg_sensitivity=69.35%, avg_specificity=82.63% avg_auc=84.20%
Best model saved!! Metric=-10.162331115780091!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.575422 Test loss=0.458530 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5478140711784363
[5/24] Train loss=0.5505251884460449
[10/24] Train loss=0.5657017230987549
[15/24] Train loss=0.5384790301322937
[20/24] Train loss=0.5343133807182312
Test set avg_accuracy=81.72% avg_sensitivity=73.87%, avg_specificity=83.99% avg_auc=86.41%
Best model saved!! Metric=-0.011810406920432115!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.550066 Test loss=0.437632 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5179027318954468
[5/24] Train loss=0.5251409411430359
[10/24] Train loss=0.5319375395774841
[15/24] Train loss=0.5104448795318604
[20/24] Train loss=0.5005689859390259
Test set avg_accuracy=83.72% avg_sensitivity=71.78%, avg_specificity=87.19% avg_auc=87.68%
Best model saved!! Metric=4.370005023465609!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.521248 Test loss=0.407240 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.4915942847728729
[5/24] Train loss=0.49530133605003357
[10/24] Train loss=0.4984101951122284
[15/24] Train loss=0.47899115085601807
[20/24] Train loss=0.4708060920238495
Test set avg_accuracy=85.26% avg_sensitivity=71.84%, avg_specificity=89.15% avg_auc=88.99%
Best model saved!! Metric=9.247747111626893!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.491795 Test loss=0.384214 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4710978865623474
[5/24] Train loss=0.4657540023326874
[10/24] Train loss=0.47565963864326477
[15/24] Train loss=0.45240259170532227
[20/24] Train loss=0.44072040915489197
Test set avg_accuracy=86.46% avg_sensitivity=71.90%, avg_specificity=90.68% avg_auc=89.89%
Best model saved!! Metric=12.931100601586564!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.464933 Test loss=0.365257 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.44181928038597107
[5/24] Train loss=0.4288065731525421
[10/24] Train loss=0.44145679473876953
[15/24] Train loss=0.42447322607040405
[20/24] Train loss=0.41179248690605164
Test set avg_accuracy=87.50% avg_sensitivity=68.13%, avg_specificity=93.11% avg_auc=90.40%
Best model saved!! Metric=13.149153747677744!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.438469 Test loss=0.340808 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4174177944660187
[5/24] Train loss=0.41075751185417175
[10/24] Train loss=0.41669732332229614
[15/24] Train loss=0.39887258410453796
[20/24] Train loss=0.39213845133781433
Test set avg_accuracy=88.09% avg_sensitivity=67.73%, avg_specificity=93.99% avg_auc=91.00%
Best model saved!! Metric=14.804763680321827!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.413687 Test loss=0.326884 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.40085265040397644
[5/24] Train loss=0.38547614216804504
[10/24] Train loss=0.3934437930583954
[15/24] Train loss=0.37780097126960754
[20/24] Train loss=0.36307764053344727
Test set avg_accuracy=88.35% avg_sensitivity=69.52%, avg_specificity=93.80% avg_auc=91.94%
Best model saved!! Metric=17.614310390337423!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.392173 Test loss=0.312468 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3759024143218994
[5/24] Train loss=0.370761513710022
[10/24] Train loss=0.3733339309692383
[15/24] Train loss=0.36129894852638245
[20/24] Train loss=0.3490464687347412
Test set avg_accuracy=88.93% avg_sensitivity=69.87%, avg_specificity=94.46% avg_auc=92.43%
Best model saved!! Metric=19.69706532146546!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.374529 Test loss=0.298561 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3606989085674286
[5/24] Train loss=0.3535395562648773
[10/24] Train loss=0.36237603425979614
[15/24] Train loss=0.34201547503471375
[20/24] Train loss=0.33227694034576416
Test set avg_accuracy=89.11% avg_sensitivity=72.60%, avg_specificity=93.90% avg_auc=93.05%
Best model saved!! Metric=22.66359874737479!!
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.357142 Test loss=0.290650 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3461421728134155
[5/24] Train loss=0.337535560131073
[10/24] Train loss=0.3492913246154785
[15/24] Train loss=0.33159324526786804
[20/24] Train loss=0.31666505336761475
Test set avg_accuracy=89.44% avg_sensitivity=69.24%, avg_specificity=95.30% avg_auc=93.05%
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.345483 Test loss=0.279036 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.33253195881843567
[5/24] Train loss=0.32528072595596313
[10/24] Train loss=0.33852913975715637
[15/24] Train loss=0.3181619942188263
[20/24] Train loss=0.3087863624095917
Test set avg_accuracy=89.41% avg_sensitivity=73.06%, avg_specificity=94.16% avg_auc=93.53%
Best model saved!! Metric=24.16309009705445!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.333020 Test loss=0.273690 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.31983834505081177
[5/24] Train loss=0.318590372800827
[10/24] Train loss=0.32131531834602356
[15/24] Train loss=0.31101763248443604
[20/24] Train loss=0.300387978553772
Test set avg_accuracy=89.58% avg_sensitivity=73.46%, avg_specificity=94.26% avg_auc=93.79%
Best model saved!! Metric=25.09568702527281!!
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.322837 Test loss=0.269586 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3093547224998474
[5/24] Train loss=0.31190866231918335
[10/24] Train loss=0.3139090836048126
[15/24] Train loss=0.30285853147506714
[20/24] Train loss=0.28660082817077637
Test set avg_accuracy=89.79% avg_sensitivity=72.02%, avg_specificity=94.94% avg_auc=93.78%
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.312927 Test loss=0.261097 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3032895624637604
[5/24] Train loss=0.3032558858394623
[10/24] Train loss=0.3103516399860382
[15/24] Train loss=0.288993775844574
[20/24] Train loss=0.2812051773071289
Test set avg_accuracy=90.03% avg_sensitivity=72.94%, avg_specificity=94.98% avg_auc=93.90%
Best model saved!! Metric=25.847320369241956!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.306111 Test loss=0.257923 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.29534193873405457
[5/24] Train loss=0.289753794670105
[10/24] Train loss=0.30695441365242004
[15/24] Train loss=0.2887521982192993
[20/24] Train loss=0.2767660319805145
Test set avg_accuracy=90.00% avg_sensitivity=73.46%, avg_specificity=94.79% avg_auc=94.02%
Best model saved!! Metric=26.281211769958233!!
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.299061 Test loss=0.255920 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2946324646472931
[5/24] Train loss=0.28387564420700073
[10/24] Train loss=0.29857581853866577
[15/24] Train loss=0.2772926390171051
[20/24] Train loss=0.2703745663166046
Test set avg_accuracy=90.12% avg_sensitivity=69.87%, avg_specificity=95.99% avg_auc=93.78%
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.291076 Test loss=0.252364 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.28551042079925537
[5/24] Train loss=0.2746492028236389
[10/24] Train loss=0.29552161693573
[15/24] Train loss=0.2730167806148529
[20/24] Train loss=0.263842910528183
Test set avg_accuracy=90.42% avg_sensitivity=73.70%, avg_specificity=95.26% avg_auc=94.16%
Best model saved!! Metric=27.532341844964876!!
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.286383 Test loss=0.248153 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2843547463417053
[5/24] Train loss=0.2695244252681732
[10/24] Train loss=0.28500446677207947
[15/24] Train loss=0.2678300142288208
[20/24] Train loss=0.2586797773838043
Test set avg_accuracy=90.46% avg_sensitivity=70.34%, avg_specificity=96.29% avg_auc=93.47%
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.281480 Test loss=0.254055 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.27216657996177673
[5/24] Train loss=0.2675572335720062
[10/24] Train loss=0.2787075936794281
[15/24] Train loss=0.2653871178627014
[20/24] Train loss=0.2550346553325653
Test set avg_accuracy=90.44% avg_sensitivity=72.02%, avg_specificity=95.78% avg_auc=94.23%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.276699 Test loss=0.244821 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2725963592529297
[5/24] Train loss=0.26051220297813416
[10/24] Train loss=0.27601802349090576
[15/24] Train loss=0.25544238090515137
[20/24] Train loss=0.24488213658332825
Test set avg_accuracy=88.54% avg_sensitivity=56.37%, avg_specificity=97.87% avg_auc=92.42%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.271114 Test loss=0.284928 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2751207947731018
[5/24] Train loss=0.2513050436973572
[10/24] Train loss=0.27046576142311096
[15/24] Train loss=0.24973903596401215
[20/24] Train loss=0.24162918329238892
Test set avg_accuracy=88.14% avg_sensitivity=52.84%, avg_specificity=98.37% avg_auc=91.51%
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.267785 Test loss=0.306639 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.27860987186431885
[5/24] Train loss=0.24971985816955566
[10/24] Train loss=0.2735510766506195
[15/24] Train loss=0.2499246895313263
[20/24] Train loss=0.24331726133823395
Test set avg_accuracy=89.90% avg_sensitivity=67.15%, avg_specificity=96.49% avg_auc=93.93%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.264275 Test loss=0.252402 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2633611857891083
[5/24] Train loss=0.2452067881822586
[10/24] Train loss=0.2595970034599304
[15/24] Train loss=0.24400731921195984
[20/24] Train loss=0.24434877932071686
Test set avg_accuracy=88.97% avg_sensitivity=59.10%, avg_specificity=97.63% avg_auc=93.03%
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.258911 Test loss=0.275922 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.265180766582489
[5/24] Train loss=0.23772937059402466
[10/24] Train loss=0.26097121834754944
[15/24] Train loss=0.24605996906757355
[20/24] Train loss=0.24428711831569672
Test set avg_accuracy=90.16% avg_sensitivity=69.41%, avg_specificity=96.17% avg_auc=94.28%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.257978 Test loss=0.248832 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.25632962584495544
[5/24] Train loss=0.22938737273216248
[10/24] Train loss=0.26336073875427246
[15/24] Train loss=0.2458193302154541
[20/24] Train loss=0.23997139930725098
Test set avg_accuracy=89.58% avg_sensitivity=68.60%, avg_specificity=95.67% avg_auc=94.16%
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.256264 Test loss=0.249644 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2628343403339386
[5/24] Train loss=0.26281046867370605
[10/24] Train loss=0.2646309733390808
[15/24] Train loss=0.24757489562034607
[20/24] Train loss=0.23436042666435242
Test set avg_accuracy=90.01% avg_sensitivity=72.60%, avg_specificity=95.06% avg_auc=94.26%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.257382 Test loss=0.250348 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.257070928812027
[5/24] Train loss=0.23296238481998444
[10/24] Train loss=0.25084972381591797
[15/24] Train loss=0.23866568505764008
[20/24] Train loss=0.23556482791900635
Test set avg_accuracy=89.08% avg_sensitivity=59.39%, avg_specificity=97.68% avg_auc=93.00%
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.248628 Test loss=0.273697 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2578233778476715
[5/24] Train loss=0.22846876084804535
[10/24] Train loss=0.25128740072250366
[15/24] Train loss=0.24794574081897736
[20/24] Train loss=0.24158672988414764
Test set avg_accuracy=89.61% avg_sensitivity=61.36%, avg_specificity=97.80% avg_auc=93.49%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.248127 Test loss=0.264061 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.26213139295578003
[5/24] Train loss=0.2253553867340088
[10/24] Train loss=0.2697470486164093
[15/24] Train loss=0.23964694142341614
[20/24] Train loss=0.23126208782196045
Test set avg_accuracy=88.61% avg_sensitivity=57.88%, avg_specificity=97.51% avg_auc=91.87%
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.246797 Test loss=0.294262 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2548395097255707
[5/24] Train loss=0.2246166318655014
[10/24] Train loss=0.24398429691791534
[15/24] Train loss=0.23839783668518066
[20/24] Train loss=0.23650901019573212
Test set avg_accuracy=89.41% avg_sensitivity=63.90%, avg_specificity=96.81% avg_auc=92.76%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.243826 Test loss=0.270106 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2570227086544037
[5/24] Train loss=0.2125273197889328
[10/24] Train loss=0.24671205878257751
[15/24] Train loss=0.23630298674106598
[20/24] Train loss=0.23252539336681366
Test set avg_accuracy=89.13% avg_sensitivity=60.95%, avg_specificity=97.30% avg_auc=92.00%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.241093 Test loss=0.282483 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.24564924836158752
[5/24] Train loss=0.21316443383693695
[10/24] Train loss=0.2396095097064972
[15/24] Train loss=0.23341143131256104
[20/24] Train loss=0.22416023910045624
Test set avg_accuracy=89.93% avg_sensitivity=68.08%, avg_specificity=96.27% avg_auc=93.39%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.238564 Test loss=0.256968 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2526411712169647
[5/24] Train loss=0.21109507977962494
[10/24] Train loss=0.24688251316547394
[15/24] Train loss=0.22471988201141357
[20/24] Train loss=0.2242034375667572
Test set avg_accuracy=88.44% avg_sensitivity=55.10%, avg_specificity=98.10% avg_auc=92.50%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.236269 Test loss=0.287997 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.24643637239933014
[5/24] Train loss=0.21326783299446106
[10/24] Train loss=0.23313693702220917
[15/24] Train loss=0.23188439011573792
[20/24] Train loss=0.22587981820106506
Test set avg_accuracy=88.61% avg_sensitivity=66.57%, avg_specificity=94.99% avg_auc=92.76%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.233238 Test loss=0.272909 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.24481713771820068
[5/24] Train loss=0.2186499685049057
[10/24] Train loss=0.24978533387184143
[15/24] Train loss=0.23894211649894714
[20/24] Train loss=0.22232452034950256
Test set avg_accuracy=89.54% avg_sensitivity=72.02%, avg_specificity=94.63% avg_auc=93.45%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.237158 Test loss=0.264890 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.24515563249588013
[5/24] Train loss=0.19392116367816925
[10/24] Train loss=0.25125354528427124
[15/24] Train loss=0.23599553108215332
[20/24] Train loss=0.2290201634168625
Test set avg_accuracy=88.58% avg_sensitivity=57.71%, avg_specificity=97.53% avg_auc=92.59%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.237745 Test loss=0.281690 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.24439430236816406
[5/24] Train loss=0.2148308902978897
[10/24] Train loss=0.25128549337387085
[15/24] Train loss=0.2293936312198639
[20/24] Train loss=0.2172573208808899
Test set avg_accuracy=88.12% avg_sensitivity=52.55%, avg_specificity=98.44% avg_auc=91.15%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.238017 Test loss=0.324795 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.23863638937473297
[5/24] Train loss=0.202503502368927
[10/24] Train loss=0.24397505819797516
[15/24] Train loss=0.22910605370998383
[20/24] Train loss=0.22404538094997406
Test set avg_accuracy=88.15% avg_sensitivity=75.49%, avg_specificity=91.82% avg_auc=93.25%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.231281 Test loss=0.279640 Current lr=[0.00029967723776099]

[0/24] Train loss=0.24020104110240936
[5/24] Train loss=0.2115873098373413
[10/24] Train loss=0.25655776262283325
[15/24] Train loss=0.2268037647008896
[20/24] Train loss=0.22926734387874603
Test set avg_accuracy=87.85% avg_sensitivity=74.91%, avg_specificity=91.60% avg_auc=91.93%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.233417 Test loss=0.291137 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.23593197762966156
[5/24] Train loss=0.1968556046485901
[10/24] Train loss=0.2456251084804535
[15/24] Train loss=0.22289563715457916
[20/24] Train loss=0.2215057760477066
Test set avg_accuracy=89.48% avg_sensitivity=63.27%, avg_specificity=97.08% avg_auc=92.11%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.228440 Test loss=0.277356 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.24361631274223328
[5/24] Train loss=0.2015589028596878
[10/24] Train loss=0.24221643805503845
[15/24] Train loss=0.22435417771339417
[20/24] Train loss=0.2271193265914917
Test set avg_accuracy=85.18% avg_sensitivity=81.87%, avg_specificity=86.14% avg_auc=92.30%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.229500 Test loss=0.331889 Current lr=[0.000299720220882401]

[0/24] Train loss=0.23412470519542694
[5/24] Train loss=0.19374871253967285
[10/24] Train loss=0.23520053923130035
[15/24] Train loss=0.2266986072063446
[20/24] Train loss=0.21712981164455414
Test set avg_accuracy=87.53% avg_sensitivity=77.64%, avg_specificity=90.39% avg_auc=92.49%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.226047 Test loss=0.299917 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.22614070773124695
[5/24] Train loss=0.20013965666294098
[10/24] Train loss=0.23550531268119812
[15/24] Train loss=0.21721020340919495
[20/24] Train loss=0.21527549624443054
Test set avg_accuracy=87.90% avg_sensitivity=72.25%, avg_specificity=92.44% avg_auc=91.94%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.222111 Test loss=0.289600 Current lr=[0.000298904600941902]

[0/24] Train loss=0.22772403061389923
[5/24] Train loss=0.20229803025722504
[10/24] Train loss=0.237212672829628
[15/24] Train loss=0.2220051884651184
[20/24] Train loss=0.21460002660751343
Test set avg_accuracy=85.39% avg_sensitivity=75.03%, avg_specificity=88.39% avg_auc=90.84%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.224305 Test loss=0.335398 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2293906956911087
[5/24] Train loss=0.19276875257492065
[10/24] Train loss=0.23617401719093323
[15/24] Train loss=0.2116735428571701
[20/24] Train loss=0.22313354909420013
Test set avg_accuracy=88.24% avg_sensitivity=68.60%, avg_specificity=93.94% avg_auc=91.77%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.221272 Test loss=0.290156 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2234058827161789
[5/24] Train loss=0.20957887172698975
[10/24] Train loss=0.22482410073280334
[15/24] Train loss=0.20081377029418945
[20/24] Train loss=0.21234539151191711
Test set avg_accuracy=82.59% avg_sensitivity=84.94%, avg_specificity=81.91% avg_auc=91.02%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.219244 Test loss=0.383949 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2280946522951126
[5/24] Train loss=0.18904276192188263
[10/24] Train loss=0.2299669086933136
[15/24] Train loss=0.2103251814842224
[20/24] Train loss=0.21589133143424988
Test set avg_accuracy=89.00% avg_sensitivity=78.16%, avg_specificity=92.14% avg_auc=93.89%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.219473 Test loss=0.266616 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.21871201694011688
[5/24] Train loss=0.19558484852313995
[10/24] Train loss=0.2337319552898407
[15/24] Train loss=0.2076396644115448
[20/24] Train loss=0.20685966312885284
Test set avg_accuracy=75.52% avg_sensitivity=84.76%, avg_specificity=72.84% avg_auc=87.56%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.218528 Test loss=0.516305 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.22378750145435333
[5/24] Train loss=0.189789816737175
[10/24] Train loss=0.22935816645622253
[15/24] Train loss=0.21023495495319366
[20/24] Train loss=0.21622741222381592
Test set avg_accuracy=83.93% avg_sensitivity=83.66%, avg_specificity=84.01% avg_auc=91.71%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.213915 Test loss=0.358304 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2233159989118576
[5/24] Train loss=0.18661648035049438
[10/24] Train loss=0.22041134536266327
[15/24] Train loss=0.20671336352825165
[20/24] Train loss=0.20951800048351288
Test set avg_accuracy=87.23% avg_sensitivity=78.45%, avg_specificity=89.77% avg_auc=92.70%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.214933 Test loss=0.301988 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.20838147401809692
[5/24] Train loss=0.18228785693645477
[10/24] Train loss=0.22779785096645355
[15/24] Train loss=0.2109849452972412
[20/24] Train loss=0.21350957453250885
Test set avg_accuracy=88.40% avg_sensitivity=76.71%, avg_specificity=91.79% avg_auc=92.48%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.211183 Test loss=0.288998 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2255336493253708
[5/24] Train loss=0.19608671963214874
[10/24] Train loss=0.22679774463176727
[15/24] Train loss=0.21405798196792603
[20/24] Train loss=0.2059839814901352
Test set avg_accuracy=89.09% avg_sensitivity=64.77%, avg_specificity=96.14% avg_auc=91.78%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.211407 Test loss=0.282644 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.21576237678527832
[5/24] Train loss=0.17827387154102325
[10/24] Train loss=0.21775595843791962
[15/24] Train loss=0.20844267308712006
[20/24] Train loss=0.1987491399049759
Test set avg_accuracy=87.96% avg_sensitivity=54.40%, avg_specificity=97.68% avg_auc=89.97%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.209054 Test loss=0.328549 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2176693230867386
[5/24] Train loss=0.17703023552894592
[10/24] Train loss=0.2160525768995285
[15/24] Train loss=0.2064536064863205
[20/24] Train loss=0.20378698408603668
Test set avg_accuracy=89.23% avg_sensitivity=72.48%, avg_specificity=94.09% avg_auc=93.02%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.209196 Test loss=0.270706 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2086227834224701
[5/24] Train loss=0.17542213201522827
[10/24] Train loss=0.2100098431110382
[15/24] Train loss=0.2039288878440857
[20/24] Train loss=0.20059065520763397
Test set avg_accuracy=88.79% avg_sensitivity=75.72%, avg_specificity=92.58% avg_auc=93.05%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.203734 Test loss=0.279010 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.20686960220336914
[5/24] Train loss=0.1830248087644577
[10/24] Train loss=0.21716652810573578
[15/24] Train loss=0.19840657711029053
[20/24] Train loss=0.19955378770828247
Test set avg_accuracy=88.83% avg_sensitivity=62.69%, avg_specificity=96.41% avg_auc=91.90%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.205334 Test loss=0.288071 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.20798709988594055
[5/24] Train loss=0.18798115849494934
[10/24] Train loss=0.20701752603054047
[15/24] Train loss=0.20552000403404236
[20/24] Train loss=0.20166853070259094
Test set avg_accuracy=87.46% avg_sensitivity=79.26%, avg_specificity=89.84% avg_auc=93.15%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.202154 Test loss=0.296759 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.21439802646636963
[5/24] Train loss=0.16652123630046844
[10/24] Train loss=0.1984468549489975
[15/24] Train loss=0.19354219734668732
[20/24] Train loss=0.19376921653747559
Test set avg_accuracy=89.06% avg_sensitivity=75.14%, avg_specificity=93.10% avg_auc=93.33%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.199239 Test loss=0.272706 Current lr=[0.000276307469034998]

[0/24] Train loss=0.20773771405220032
[5/24] Train loss=0.18954123556613922
[10/24] Train loss=0.21200238168239594
[15/24] Train loss=0.20195533335208893
[20/24] Train loss=0.19482341408729553
Test set avg_accuracy=81.81% avg_sensitivity=84.88%, avg_specificity=80.92% avg_auc=90.02%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.203874 Test loss=0.412664 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.21101580560207367
[5/24] Train loss=0.18805450201034546
[10/24] Train loss=0.20561948418617249
[15/24] Train loss=0.19459684193134308
[20/24] Train loss=0.2027004063129425
Test set avg_accuracy=75.39% avg_sensitivity=86.67%, avg_specificity=72.12% avg_auc=88.43%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.202878 Test loss=0.511184 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2110753208398819
[5/24] Train loss=0.17691056430339813
[10/24] Train loss=0.20189517736434937
[15/24] Train loss=0.19907407462596893
[20/24] Train loss=0.1997808814048767
Test set avg_accuracy=88.61% avg_sensitivity=71.78%, avg_specificity=93.48% avg_auc=92.16%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.201062 Test loss=0.285343 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.20772728323936462
[5/24] Train loss=0.1755780577659607
[10/24] Train loss=0.20828881859779358
[15/24] Train loss=0.19543814659118652
[20/24] Train loss=0.18967007100582123
Test set avg_accuracy=87.97% avg_sensitivity=62.40%, avg_specificity=95.38% avg_auc=89.63%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.200785 Test loss=0.316581 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.22634628415107727
[5/24] Train loss=0.1805909126996994
[10/24] Train loss=0.1980385184288025
[15/24] Train loss=0.18804919719696045
[20/24] Train loss=0.18988139927387238
Test set avg_accuracy=88.75% avg_sensitivity=71.67%, avg_specificity=93.70% avg_auc=91.45%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.196333 Test loss=0.292138 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.20154589414596558
[5/24] Train loss=0.17184294760227203
[10/24] Train loss=0.19669406116008759
[15/24] Train loss=0.1961153894662857
[20/24] Train loss=0.19380147755146027
Test set avg_accuracy=82.94% avg_sensitivity=81.05%, avg_specificity=83.49% avg_auc=90.25%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.194562 Test loss=0.378320 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.18977518379688263
[5/24] Train loss=0.17164352536201477
[10/24] Train loss=0.20228756964206696
[15/24] Train loss=0.1969289928674698
[20/24] Train loss=0.18958310782909393
Test set avg_accuracy=84.18% avg_sensitivity=83.37%, avg_specificity=84.41% avg_auc=91.24%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.192196 Test loss=0.368858 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.20070311427116394
[5/24] Train loss=0.17072470486164093
[10/24] Train loss=0.1972239464521408
[15/24] Train loss=0.18145008385181427
[20/24] Train loss=0.17816461622714996
Test set avg_accuracy=88.41% avg_sensitivity=57.88%, avg_specificity=97.26% avg_auc=88.13%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.190837 Test loss=0.332372 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2060386836528778
[5/24] Train loss=0.1706080436706543
[10/24] Train loss=0.18522490561008453
[15/24] Train loss=0.18291722238063812
[20/24] Train loss=0.1872294545173645
Test set avg_accuracy=89.08% avg_sensitivity=75.61%, avg_specificity=92.98% avg_auc=93.31%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.192116 Test loss=0.269574 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1923564076423645
[5/24] Train loss=0.17188915610313416
[10/24] Train loss=0.18976202607154846
[15/24] Train loss=0.19505006074905396
[20/24] Train loss=0.19090519845485687
Test set avg_accuracy=86.72% avg_sensitivity=48.67%, avg_specificity=97.75% avg_auc=88.59%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.192941 Test loss=0.358055 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.19216413795948029
[5/24] Train loss=0.17344047129154205
[10/24] Train loss=0.19480565190315247
[15/24] Train loss=0.18610762059688568
[20/24] Train loss=0.18607865273952484
Test set avg_accuracy=88.80% avg_sensitivity=62.11%, avg_specificity=96.54% avg_auc=91.76%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.188904 Test loss=0.295727 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.19123001396656036
[5/24] Train loss=0.1625252515077591
[10/24] Train loss=0.1857195943593979
[15/24] Train loss=0.1814803034067154
[20/24] Train loss=0.17534689605236053
Test set avg_accuracy=89.47% avg_sensitivity=70.39%, avg_specificity=94.99% avg_auc=92.14%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.186165 Test loss=0.277492 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.18912437558174133
[5/24] Train loss=0.16997742652893066
[10/24] Train loss=0.18871884047985077
[15/24] Train loss=0.1853915899991989
[20/24] Train loss=0.1787985861301422
Test set avg_accuracy=89.27% avg_sensitivity=76.42%, avg_specificity=93.00% avg_auc=93.75%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.184636 Test loss=0.264814 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.18242643773555756
[5/24] Train loss=0.17576682567596436
[10/24] Train loss=0.19700349867343903
[15/24] Train loss=0.18804392218589783
[20/24] Train loss=0.18081693351268768
Test set avg_accuracy=88.80% avg_sensitivity=73.17%, avg_specificity=93.33% avg_auc=92.87%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.187438 Test loss=0.274917 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2010887861251831
[5/24] Train loss=0.17673802375793457
[10/24] Train loss=0.19855369627475739
[15/24] Train loss=0.1848663091659546
[20/24] Train loss=0.17795264720916748
Test set avg_accuracy=89.02% avg_sensitivity=67.32%, avg_specificity=95.31% avg_auc=92.07%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.187387 Test loss=0.282862 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.19224508106708527
[5/24] Train loss=0.16183333098888397
[10/24] Train loss=0.18077033758163452
[15/24] Train loss=0.18895764648914337
[20/24] Train loss=0.18250137567520142
Test set avg_accuracy=88.92% avg_sensitivity=61.12%, avg_specificity=96.98% avg_auc=89.63%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.185210 Test loss=0.304437 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2018204778432846
[5/24] Train loss=0.1612035483121872
[10/24] Train loss=0.1831492930650711
[15/24] Train loss=0.17414961755275726
[20/24] Train loss=0.19029396772384644
Test set avg_accuracy=88.79% avg_sensitivity=73.12%, avg_specificity=93.33% avg_auc=91.90%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.183755 Test loss=0.287374 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.19484813511371613
[5/24] Train loss=0.16259616613388062
[10/24] Train loss=0.1843186765909195
[15/24] Train loss=0.18424534797668457
[20/24] Train loss=0.17682397365570068
Test set avg_accuracy=87.37% avg_sensitivity=75.78%, avg_specificity=90.73% avg_auc=90.96%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.183209 Test loss=0.315298 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.19293951988220215
[5/24] Train loss=0.181518092751503
[10/24] Train loss=0.19051380455493927
[15/24] Train loss=0.18102671205997467
[20/24] Train loss=0.18061982095241547
Test set avg_accuracy=89.00% avg_sensitivity=68.89%, avg_specificity=94.83% avg_auc=91.93%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.183932 Test loss=0.280765 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.18453606963157654
[5/24] Train loss=0.1607121080160141
[10/24] Train loss=0.1850018948316574
[15/24] Train loss=0.17544159293174744
[20/24] Train loss=0.17888741195201874
Test set avg_accuracy=88.97% avg_sensitivity=74.04%, avg_specificity=93.30% avg_auc=91.56%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.184083 Test loss=0.285848 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.19206564128398895
[5/24] Train loss=0.16882652044296265
[10/24] Train loss=0.19741231203079224
[15/24] Train loss=0.1812996119260788
[20/24] Train loss=0.18230293691158295
Test set avg_accuracy=88.16% avg_sensitivity=73.87%, avg_specificity=92.31% avg_auc=91.66%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.187704 Test loss=0.298839 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.17587512731552124
[5/24] Train loss=0.16708877682685852
[10/24] Train loss=0.17591950297355652
[15/24] Train loss=0.1823400855064392
[20/24] Train loss=0.17754383385181427
Test set avg_accuracy=88.87% avg_sensitivity=62.28%, avg_specificity=96.57% avg_auc=90.52%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.179985 Test loss=0.303769 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.18275713920593262
[5/24] Train loss=0.16176895797252655
[10/24] Train loss=0.1795835942029953
[15/24] Train loss=0.1763955056667328
[20/24] Train loss=0.17832836508750916
Test set avg_accuracy=88.63% avg_sensitivity=66.28%, avg_specificity=95.11% avg_auc=91.57%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.180280 Test loss=0.294514 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.18520893156528473
[5/24] Train loss=0.1590937227010727
[10/24] Train loss=0.17737118899822235
[15/24] Train loss=0.16948799788951874
[20/24] Train loss=0.17930476367473602
Test set avg_accuracy=88.16% avg_sensitivity=60.49%, avg_specificity=96.19% avg_auc=89.60%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.181508 Test loss=0.317926 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.17502477765083313
[5/24] Train loss=0.16539694368839264
[10/24] Train loss=0.19347667694091797
[15/24] Train loss=0.17899590730667114
[20/24] Train loss=0.1745174378156662
Test set avg_accuracy=87.72% avg_sensitivity=55.50%, avg_specificity=97.06% avg_auc=88.87%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.182682 Test loss=0.333763 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.19185082614421844
[5/24] Train loss=0.15812598168849945
[10/24] Train loss=0.17544899880886078
[15/24] Train loss=0.17638374865055084
[20/24] Train loss=0.17184360325336456
Test set avg_accuracy=89.34% avg_sensitivity=67.96%, avg_specificity=95.53% avg_auc=90.86%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.177569 Test loss=0.285785 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.18424417078495026
[5/24] Train loss=0.15630634129047394
[10/24] Train loss=0.18611879646778107
[15/24] Train loss=0.1717955321073532
[20/24] Train loss=0.17492257058620453
Test set avg_accuracy=89.24% avg_sensitivity=71.44%, avg_specificity=94.41% avg_auc=92.23%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.179206 Test loss=0.277749 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.1798994094133377
[5/24] Train loss=0.16761142015457153
[10/24] Train loss=0.19054408371448517
[15/24] Train loss=0.1683872938156128
[20/24] Train loss=0.17461074888706207
Test set avg_accuracy=87.30% avg_sensitivity=80.59%, avg_specificity=89.25% avg_auc=92.26%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.177469 Test loss=0.309877 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.18098631501197815
[5/24] Train loss=0.1640278846025467
[10/24] Train loss=0.17775338888168335
[15/24] Train loss=0.16342440247535706
[20/24] Train loss=0.16910293698310852
Test set avg_accuracy=89.06% avg_sensitivity=64.08%, avg_specificity=96.31% avg_auc=89.79%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.173748 Test loss=0.304920 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.17549379169940948
[5/24] Train loss=0.15436074137687683
[10/24] Train loss=0.1796080321073532
[15/24] Train loss=0.1707182228565216
[20/24] Train loss=0.17586418986320496
Test set avg_accuracy=89.47% avg_sensitivity=69.35%, avg_specificity=95.30% avg_auc=90.88%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.172347 Test loss=0.292036 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1707819551229477
[5/24] Train loss=0.1612735241651535
[10/24] Train loss=0.16695323586463928
[15/24] Train loss=0.16499187052249908
[20/24] Train loss=0.18025225400924683
Test set avg_accuracy=89.40% avg_sensitivity=70.10%, avg_specificity=94.99% avg_auc=91.50%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.173149 Test loss=0.283173 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.18303045630455017
[5/24] Train loss=0.15817491710186005
[10/24] Train loss=0.17833486199378967
[15/24] Train loss=0.16265060007572174
[20/24] Train loss=0.17282932996749878
Test set avg_accuracy=88.98% avg_sensitivity=68.48%, avg_specificity=94.93% avg_auc=90.85%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.173848 Test loss=0.292419 Current lr=[0.000156543481933168]

[0/24] Train loss=0.17896130681037903
[5/24] Train loss=0.15349198877811432
[10/24] Train loss=0.16773703694343567
[15/24] Train loss=0.16869941353797913
[20/24] Train loss=0.1681796759366989
Test set avg_accuracy=88.41% avg_sensitivity=61.99%, avg_specificity=96.07% avg_auc=89.32%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.171305 Test loss=0.317032 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.16940182447433472
[5/24] Train loss=0.16366083920001984
[10/24] Train loss=0.1685847043991089
[15/24] Train loss=0.1709929257631302
[20/24] Train loss=0.16763199865818024
Test set avg_accuracy=88.49% avg_sensitivity=71.96%, avg_specificity=93.28% avg_auc=91.61%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.168887 Test loss=0.293958 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.16777165234088898
[5/24] Train loss=0.155408576130867
[10/24] Train loss=0.17177821695804596
[15/24] Train loss=0.1795526146888733
[20/24] Train loss=0.16904772818088531
Test set avg_accuracy=88.45% avg_sensitivity=69.52%, avg_specificity=93.94% avg_auc=91.40%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.170440 Test loss=0.295721 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.17402788996696472
[5/24] Train loss=0.15521015226840973
[10/24] Train loss=0.1603524088859558
[15/24] Train loss=0.16241493821144104
[20/24] Train loss=0.17150098085403442
Test set avg_accuracy=87.41% avg_sensitivity=54.17%, avg_specificity=97.04% avg_auc=88.61%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.168990 Test loss=0.353347 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.17117272317409515
[5/24] Train loss=0.15412969887256622
[10/24] Train loss=0.16713030636310577
[15/24] Train loss=0.1676112860441208
[20/24] Train loss=0.17592433094978333
Test set avg_accuracy=89.57% avg_sensitivity=68.54%, avg_specificity=95.67% avg_auc=91.45%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.168486 Test loss=0.280857 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16183175146579742
[5/24] Train loss=0.15434733033180237
[10/24] Train loss=0.16044273972511292
[15/24] Train loss=0.17062528431415558
[20/24] Train loss=0.16436943411827087
Test set avg_accuracy=88.72% avg_sensitivity=60.66%, avg_specificity=96.86% avg_auc=90.12%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.166552 Test loss=0.316172 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1634545773267746
[5/24] Train loss=0.16126717627048492
[10/24] Train loss=0.16433849930763245
[15/24] Train loss=0.16026084125041962
[20/24] Train loss=0.15968124568462372
Test set avg_accuracy=89.78% avg_sensitivity=76.77%, avg_specificity=93.55% avg_auc=93.24%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.164450 Test loss=0.263098 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.16448065638542175
[5/24] Train loss=0.14776970446109772
[10/24] Train loss=0.15974485874176025
[15/24] Train loss=0.15555378794670105
[20/24] Train loss=0.15965160727500916
Test set avg_accuracy=89.78% avg_sensitivity=69.64%, avg_specificity=95.62% avg_auc=91.88%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.160087 Test loss=0.272714 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15892085433006287
[5/24] Train loss=0.1427401304244995
[10/24] Train loss=0.15377038717269897
[15/24] Train loss=0.15436908602714539
[20/24] Train loss=0.1567392647266388
Test set avg_accuracy=89.93% avg_sensitivity=73.00%, avg_specificity=94.84% avg_auc=92.54%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.157579 Test loss=0.270524 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1607288122177124
[5/24] Train loss=0.1454034298658371
[10/24] Train loss=0.1579011082649231
[15/24] Train loss=0.16212758421897888
[20/24] Train loss=0.15604624152183533
Test set avg_accuracy=89.14% avg_sensitivity=66.22%, avg_specificity=95.78% avg_auc=91.21%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.158539 Test loss=0.290109 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1622442603111267
[5/24] Train loss=0.15196403861045837
[10/24] Train loss=0.15001410245895386
[15/24] Train loss=0.15769784152507782
[20/24] Train loss=0.15385206043720245
Test set avg_accuracy=89.48% avg_sensitivity=68.95%, avg_specificity=95.43% avg_auc=91.74%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.157196 Test loss=0.283675 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15655671060085297
[5/24] Train loss=0.14661484956741333
[10/24] Train loss=0.15456941723823547
[15/24] Train loss=0.15224038064479828
[20/24] Train loss=0.15514124929904938
Test set avg_accuracy=89.73% avg_sensitivity=69.12%, avg_specificity=95.70% avg_auc=92.40%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.156549 Test loss=0.273011 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1549195796251297
[5/24] Train loss=0.14858631789684296
[10/24] Train loss=0.1475280225276947
[15/24] Train loss=0.16066016256809235
[20/24] Train loss=0.15727490186691284
Test set avg_accuracy=89.91% avg_sensitivity=74.22%, avg_specificity=94.46% avg_auc=93.32%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.155574 Test loss=0.258391 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1598149687051773
[5/24] Train loss=0.14190371334552765
[10/24] Train loss=0.1525350660085678
[15/24] Train loss=0.15397559106349945
[20/24] Train loss=0.15686258673667908
Test set avg_accuracy=89.74% avg_sensitivity=75.32%, avg_specificity=93.92% avg_auc=92.81%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.154568 Test loss=0.268938 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15195001661777496
[5/24] Train loss=0.15143881738185883
[10/24] Train loss=0.1486687809228897
[15/24] Train loss=0.15282097458839417
[20/24] Train loss=0.15036055445671082
Test set avg_accuracy=89.58% avg_sensitivity=68.42%, avg_specificity=95.72% avg_auc=92.42%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.153636 Test loss=0.276270 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1531917154788971
[5/24] Train loss=0.1437520831823349
[10/24] Train loss=0.1481258124113083
[15/24] Train loss=0.1476340889930725
[20/24] Train loss=0.14790408313274384
Test set avg_accuracy=89.92% avg_sensitivity=69.76%, avg_specificity=95.77% avg_auc=91.37%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.151956 Test loss=0.279201 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.15094681084156036
[5/24] Train loss=0.14238232374191284
[10/24] Train loss=0.1510774940252304
[15/24] Train loss=0.15181852877140045
[20/24] Train loss=0.1546422690153122
Test set avg_accuracy=89.91% avg_sensitivity=69.35%, avg_specificity=95.87% avg_auc=92.12%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.151394 Test loss=0.271868 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.157176673412323
[5/24] Train loss=0.146473228931427
[10/24] Train loss=0.14884454011917114
[15/24] Train loss=0.15287631750106812
[20/24] Train loss=0.14520274102687836
Test set avg_accuracy=89.84% avg_sensitivity=71.26%, avg_specificity=95.23% avg_auc=92.69%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.150607 Test loss=0.267176 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.15278120338916779
[5/24] Train loss=0.1395285725593567
[10/24] Train loss=0.14756610989570618
[15/24] Train loss=0.150967076420784
[20/24] Train loss=0.14689259231090546
Test set avg_accuracy=89.56% avg_sensitivity=75.67%, avg_specificity=93.58% avg_auc=92.51%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.149139 Test loss=0.275727 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14717163145542145
[5/24] Train loss=0.13782702386379242
[10/24] Train loss=0.1426037847995758
[15/24] Train loss=0.14778251945972443
[20/24] Train loss=0.15774746239185333
Test set avg_accuracy=89.87% avg_sensitivity=68.89%, avg_specificity=95.95% avg_auc=92.42%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.149061 Test loss=0.270478 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.15153387188911438
[5/24] Train loss=0.14723622798919678
[10/24] Train loss=0.1455289125442505
[15/24] Train loss=0.14692014455795288
[20/24] Train loss=0.1435607671737671
Test set avg_accuracy=88.78% avg_sensitivity=61.18%, avg_specificity=96.78% avg_auc=87.92%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.149164 Test loss=0.319502 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.15079277753829956
[5/24] Train loss=0.14177952706813812
[10/24] Train loss=0.14895965158939362
[15/24] Train loss=0.14935481548309326
[20/24] Train loss=0.14308369159698486
Test set avg_accuracy=89.61% avg_sensitivity=69.81%, avg_specificity=95.35% avg_auc=92.09%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.146179 Test loss=0.276137 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.146719828248024
[5/24] Train loss=0.13709120452404022
[10/24] Train loss=0.13870345056056976
[15/24] Train loss=0.14772240817546844
[20/24] Train loss=0.14315074682235718
Test set avg_accuracy=89.71% avg_sensitivity=68.13%, avg_specificity=95.97% avg_auc=91.17%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.145185 Test loss=0.281797 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14759446680545807
[5/24] Train loss=0.13604211807250977
[10/24] Train loss=0.14246149361133575
[15/24] Train loss=0.14911018311977386
[20/24] Train loss=0.1408911943435669
Test set avg_accuracy=89.62% avg_sensitivity=67.56%, avg_specificity=96.02% avg_auc=90.82%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.143942 Test loss=0.289246 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14500901103019714
[5/24] Train loss=0.1328294724225998
[10/24] Train loss=0.13453197479248047
[15/24] Train loss=0.14271028339862823
[20/24] Train loss=0.1403476446866989
Test set avg_accuracy=89.62% avg_sensitivity=67.15%, avg_specificity=96.14% avg_auc=91.30%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.142166 Test loss=0.284776 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.14339393377304077
[5/24] Train loss=0.13288220763206482
[10/24] Train loss=0.13600032031536102
[15/24] Train loss=0.14238326251506805
[20/24] Train loss=0.1401994526386261
Test set avg_accuracy=89.54% avg_sensitivity=72.89%, avg_specificity=94.37% avg_auc=91.78%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.140079 Test loss=0.275544 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14049339294433594
[5/24] Train loss=0.13432833552360535
[10/24] Train loss=0.13183501362800598
[15/24] Train loss=0.14526203274726868
[20/24] Train loss=0.14228224754333496
Test set avg_accuracy=90.03% avg_sensitivity=73.75%, avg_specificity=94.74% avg_auc=92.56%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.139473 Test loss=0.269740 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13766689598560333
[5/24] Train loss=0.1319318264722824
[10/24] Train loss=0.13454501330852509
[15/24] Train loss=0.1422950178384781
[20/24] Train loss=0.13507556915283203
Test set avg_accuracy=89.35% avg_sensitivity=68.89%, avg_specificity=95.28% avg_auc=91.23%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.138247 Test loss=0.285639 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13741526007652283
[5/24] Train loss=0.13145045936107635
[10/24] Train loss=0.13135944306850433
[15/24] Train loss=0.1455690711736679
[20/24] Train loss=0.13757827877998352
Test set avg_accuracy=89.82% avg_sensitivity=70.51%, avg_specificity=95.41% avg_auc=91.72%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.137063 Test loss=0.274580 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13990183174610138
[5/24] Train loss=0.1301560252904892
[10/24] Train loss=0.13311289250850677
[15/24] Train loss=0.139481782913208
[20/24] Train loss=0.13565593957901
Test set avg_accuracy=89.52% avg_sensitivity=67.96%, avg_specificity=95.77% avg_auc=90.98%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.137009 Test loss=0.282473 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1390448659658432
[5/24] Train loss=0.1302584558725357
[10/24] Train loss=0.1318788379430771
[15/24] Train loss=0.14046375453472137
[20/24] Train loss=0.13324427604675293
Test set avg_accuracy=89.05% avg_sensitivity=67.79%, avg_specificity=95.21% avg_auc=90.57%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.136444 Test loss=0.293859 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1381799429655075
[5/24] Train loss=0.13119447231292725
[10/24] Train loss=0.1305818408727646
[15/24] Train loss=0.14036794006824493
[20/24] Train loss=0.13509491086006165
Test set avg_accuracy=89.91% avg_sensitivity=71.15%, avg_specificity=95.35% avg_auc=91.37%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.135854 Test loss=0.276274 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13614928722381592
[5/24] Train loss=0.13297976553440094
[10/24] Train loss=0.12358251959085464
[15/24] Train loss=0.1376163810491562
[20/24] Train loss=0.13385730981826782
Test set avg_accuracy=89.67% avg_sensitivity=72.83%, avg_specificity=94.56% avg_auc=91.92%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.135590 Test loss=0.271898 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13331763446331024
[5/24] Train loss=0.1318155825138092
[10/24] Train loss=0.12465739995241165
[15/24] Train loss=0.14107055962085724
[20/24] Train loss=0.13276877999305725
Test set avg_accuracy=89.62% avg_sensitivity=73.35%, avg_specificity=94.34% avg_auc=91.15%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.135745 Test loss=0.279013 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13207145035266876
[5/24] Train loss=0.13209721446037292
[10/24] Train loss=0.12598761916160583
[15/24] Train loss=0.1381663978099823
[20/24] Train loss=0.13388803601264954
Test set avg_accuracy=89.69% avg_sensitivity=74.86%, avg_specificity=93.99% avg_auc=91.47%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.134992 Test loss=0.281237 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1331116408109665
[5/24] Train loss=0.1294420212507248
[10/24] Train loss=0.1305469274520874
[15/24] Train loss=0.13483548164367676
[20/24] Train loss=0.13845904171466827
Test set avg_accuracy=89.40% avg_sensitivity=68.48%, avg_specificity=95.47% avg_auc=91.02%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.135538 Test loss=0.290477 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1358882039785385
[5/24] Train loss=0.1277063637971878
[10/24] Train loss=0.12704989314079285
[15/24] Train loss=0.1336584836244583
[20/24] Train loss=0.1299598067998886
Test set avg_accuracy=89.65% avg_sensitivity=70.80%, avg_specificity=95.11% avg_auc=91.59%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.133326 Test loss=0.278399 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13548597693443298
[5/24] Train loss=0.1254282146692276
[10/24] Train loss=0.12505920231342316
[15/24] Train loss=0.13115470111370087
[20/24] Train loss=0.13044215738773346
Test set avg_accuracy=89.74% avg_sensitivity=69.81%, avg_specificity=95.52% avg_auc=90.82%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.131619 Test loss=0.283183 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13196858763694763
[5/24] Train loss=0.1248723715543747
[10/24] Train loss=0.12107504904270172
[15/24] Train loss=0.13189668953418732
[20/24] Train loss=0.13110974431037903
Test set avg_accuracy=89.47% avg_sensitivity=73.70%, avg_specificity=94.04% avg_auc=91.54%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.130627 Test loss=0.279226 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13044558465480804
[5/24] Train loss=0.12367627024650574
[10/24] Train loss=0.12121846526861191
[15/24] Train loss=0.13277468085289001
[20/24] Train loss=0.12862196564674377
Test set avg_accuracy=89.77% avg_sensitivity=70.57%, avg_specificity=95.33% avg_auc=91.24%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.130241 Test loss=0.280457 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.13229508697986603
[5/24] Train loss=0.12483084201812744
[10/24] Train loss=0.12006738036870956
[15/24] Train loss=0.13182218372821808
[20/24] Train loss=0.12999431788921356
Test set avg_accuracy=89.60% avg_sensitivity=71.78%, avg_specificity=94.76% avg_auc=91.42%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.129511 Test loss=0.279590 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13047756254673004
[5/24] Train loss=0.12327113747596741
[10/24] Train loss=0.11953243613243103
[15/24] Train loss=0.13335371017456055
[20/24] Train loss=0.12866486608982086
Test set avg_accuracy=89.75% avg_sensitivity=72.54%, avg_specificity=94.74% avg_auc=91.35%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.129188 Test loss=0.280465 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12911958992481232
[5/24] Train loss=0.12244563549757004
[10/24] Train loss=0.11920242756605148
[15/24] Train loss=0.13253852725028992
[20/24] Train loss=0.12743985652923584
Test set avg_accuracy=89.73% avg_sensitivity=70.92%, avg_specificity=95.18% avg_auc=91.14%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.129073 Test loss=0.281313 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12964418530464172
[5/24] Train loss=0.12031091749668121
[10/24] Train loss=0.11830828338861465
[15/24] Train loss=0.13120272755622864
[20/24] Train loss=0.12793119251728058
Test set avg_accuracy=89.75% avg_sensitivity=72.31%, avg_specificity=94.81% avg_auc=91.61%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.128311 Test loss=0.278121 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12803319096565247
[5/24] Train loss=0.12399308383464813
[10/24] Train loss=0.11988618224859238
[15/24] Train loss=0.13033777475357056
[20/24] Train loss=0.12663738429546356
Test set avg_accuracy=89.79% avg_sensitivity=71.90%, avg_specificity=94.98% avg_auc=91.35%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.128449 Test loss=0.279843 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12683820724487305
[5/24] Train loss=0.12153004109859467
[10/24] Train loss=0.11961328983306885
[15/24] Train loss=0.12914302945137024
[20/24] Train loss=0.12607252597808838
Test set avg_accuracy=89.62% avg_sensitivity=72.13%, avg_specificity=94.69% avg_auc=91.40%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.127785 Test loss=0.278723 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12903712689876556
[5/24] Train loss=0.12112516164779663
[10/24] Train loss=0.11880016326904297
[15/24] Train loss=0.1264180988073349
[20/24] Train loss=0.12838506698608398
Test set avg_accuracy=89.64% avg_sensitivity=72.02%, avg_specificity=94.74% avg_auc=91.47%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.127572 Test loss=0.278326 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12528370320796967
[5/24] Train loss=0.12257638573646545
[10/24] Train loss=0.12107078731060028
[15/24] Train loss=0.13024002313613892
[20/24] Train loss=0.12796109914779663
Test set avg_accuracy=89.66% avg_sensitivity=72.13%, avg_specificity=94.74% avg_auc=91.59%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.127664 Test loss=0.277078 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13055405020713806
[5/24] Train loss=0.12094006687402725
[10/24] Train loss=0.11738533526659012
[15/24] Train loss=0.12889082729816437
[20/24] Train loss=0.12669961154460907
Test set avg_accuracy=89.74% avg_sensitivity=72.02%, avg_specificity=94.88% avg_auc=91.39%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.127353 Test loss=0.278430 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13005386292934418
[5/24] Train loss=0.11910944432020187
[10/24] Train loss=0.11828698962926865
[15/24] Train loss=0.12744176387786865
[20/24] Train loss=0.1269197314977646
Test set avg_accuracy=89.71% avg_sensitivity=71.78%, avg_specificity=94.91% avg_auc=91.35%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.127395 Test loss=0.278991 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12980227172374725
[5/24] Train loss=0.12361430376768112
[10/24] Train loss=0.11794660240411758
[15/24] Train loss=0.13004213571548462
[20/24] Train loss=0.12786191701889038
Test set avg_accuracy=89.74% avg_sensitivity=71.90%, avg_specificity=94.91% avg_auc=91.35%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.127544 Test loss=0.278956 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1281317174434662
[5/24] Train loss=0.12265577912330627
[10/24] Train loss=0.12155050784349442
[15/24] Train loss=0.12794262170791626
[20/24] Train loss=0.1263430267572403
Test set avg_accuracy=89.73% avg_sensitivity=71.84%, avg_specificity=94.91% avg_auc=91.39%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.126943 Test loss=0.278404 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12588274478912354
[5/24] Train loss=0.11987356096506119
[10/24] Train loss=0.11893191933631897
[15/24] Train loss=0.1291077882051468
[20/24] Train loss=0.12723535299301147
Test set avg_accuracy=89.73% avg_sensitivity=71.90%, avg_specificity=94.89% avg_auc=91.39%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.126669 Test loss=0.278495 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.13130328059196472
[5/24] Train loss=0.12269245833158493
[10/24] Train loss=0.11700668931007385
[15/24] Train loss=0.1296970397233963
[20/24] Train loss=0.1256410777568817
Test set avg_accuracy=89.71% avg_sensitivity=71.84%, avg_specificity=94.89% avg_auc=91.37%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.126984 Test loss=0.278618 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=90.42% sen=73.70%, spe=95.26%, auc=94.16%!
Fold[10] Avg_overlap=0.70%(±0.22385173259981941)
Final Avg Result: avg_acc=88.17%(±1.2122388840402578) avg_sen=78.72% (±3.0999612588758922) avg_spe=91.38% (±1.6888664349458347) avg_auc=93.43% (±0.7054428110646149) avg_overlap=0.69% (±0.016768436625040607)
