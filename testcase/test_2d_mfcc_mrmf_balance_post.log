/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/23] Train loss=1.2079455852508545
[5/23] Train loss=1.4475764036178589
[10/23] Train loss=1.3584855794906616
[15/23] Train loss=1.3219190835952759
[20/23] Train loss=1.2465884685516357
Test set avg_accuracy=77.31% avg_sensitivity=59.19%, avg_specificity=83.45% avg_auc=0.7019
Best model saved!! Metric=-35.85559687603376!!
Fold[1] Epoch: 1 [1/100 (1%)] Train loss=1.354058 Test loss=0.621214 Current lr=[4.263712153319496e-05]

[0/23] Train loss=1.1160931587219238
[5/23] Train loss=1.2048182487487793
[10/23] Train loss=1.0871760845184326
[15/23] Train loss=1.0911064147949219
[20/23] Train loss=0.9735455513000488
Test set avg_accuracy=82.18% avg_sensitivity=74.86%, avg_specificity=84.66% avg_auc=0.8492
Best model saved!! Metric=0.6197129703083704!!
Fold[1] Epoch: 2 [2/100 (2%)] Train loss=1.103049 Test loss=0.482766 Current lr=[5.051950942452628e-05]

[0/23] Train loss=0.8682977557182312
[5/23] Train loss=1.0413007736206055
[10/23] Train loss=0.8424019813537598
[15/23] Train loss=0.9133783578872681
[20/23] Train loss=0.7742553949356079
Test set avg_accuracy=82.18% avg_sensitivity=79.41%, avg_specificity=83.12% avg_auc=0.8775
Best model saved!! Metric=6.460296912175895!!
Fold[1] Epoch: 3 [3/100 (3%)] Train loss=0.936204 Test loss=0.473599 Current lr=[6.356055194548904e-05]

[0/23] Train loss=0.7604478597640991
[5/23] Train loss=0.995997965335846
[10/23] Train loss=0.748229444026947
[15/23] Train loss=0.7787163257598877
[20/23] Train loss=0.7045862078666687
Test set avg_accuracy=83.53% avg_sensitivity=81.24%, avg_specificity=84.30% avg_auc=0.8978
Best model saved!! Metric=12.854348394007339!!
Fold[1] Epoch: 4 [4/100 (4%)] Train loss=0.847364 Test loss=0.433234 Current lr=[8.161695403755248e-05]

[0/23] Train loss=0.6821075677871704
[5/23] Train loss=0.9753057360649109
[10/23] Train loss=0.713138222694397
[15/23] Train loss=0.7656368017196655
[20/23] Train loss=0.6169899106025696
Test set avg_accuracy=85.00% avg_sensitivity=79.13%, avg_specificity=86.99% avg_auc=0.9070
Best model saved!! Metric=15.820774637708574!!
Fold[1] Epoch: 5 [5/100 (5%)] Train loss=0.809055 Test loss=0.389512 Current lr=[0.00010449031183917899]

[0/23] Train loss=0.58208829164505
[5/23] Train loss=0.9224143624305725
[10/23] Train loss=0.6907215118408203
[15/23] Train loss=0.6957630515098572
[20/23] Train loss=0.6023398041725159
Test set avg_accuracy=85.56% avg_sensitivity=84.05%, avg_specificity=86.06% avg_auc=0.9182
Best model saved!! Metric=21.493745905850282!!
Fold[1] Epoch: 6 [6/100 (6%)] Train loss=0.781921 Test loss=0.395366 Current lr=[0.00013192929274872232]

[0/23] Train loss=0.5859857201576233
[5/23] Train loss=0.9285691380500793
[10/23] Train loss=0.6926838755607605
[15/23] Train loss=0.6534571051597595
[20/23] Train loss=0.5509641170501709
Test set avg_accuracy=87.31% avg_sensitivity=83.73%, avg_specificity=88.53% avg_auc=0.9269
Best model saved!! Metric=26.261131889619737!!
Fold[1] Epoch: 7 [7/100 (7%)] Train loss=0.759874 Test loss=0.356261 Current lr=[0.00016363239706865967]

[0/23] Train loss=0.5124448537826538
[5/23] Train loss=0.8942129015922546
[10/23] Train loss=0.6623404026031494
[15/23] Train loss=0.6449646949768066
[20/23] Train loss=0.5332961082458496
Test set avg_accuracy=86.54% avg_sensitivity=85.39%, avg_specificity=86.93% avg_auc=0.9281
Fold[1] Epoch: 8 [8/100 (8%)] Train loss=0.745230 Test loss=0.386995 Current lr=[0.00019925127088619402]

[0/23] Train loss=0.5225566029548645
[5/23] Train loss=0.903738796710968
[10/23] Train loss=0.6316526532173157
[15/23] Train loss=0.5828587412834167
[20/23] Train loss=0.47607386112213135
Test set avg_accuracy=87.59% avg_sensitivity=84.17%, avg_specificity=88.75% avg_auc=0.9308
Best model saved!! Metric=27.595083573542965!!
Fold[1] Epoch: 9 [9/100 (9%)] Train loss=0.725469 Test loss=0.352842 Current lr=[0.00023839453378827395]

[0/23] Train loss=0.5095415115356445
[5/23] Train loss=0.8718273639678955
[10/23] Train loss=0.6483131051063538
[15/23] Train loss=0.6265299320220947
[20/23] Train loss=0.47782278060913086
Test set avg_accuracy=87.12% avg_sensitivity=85.80%, avg_specificity=87.57% avg_auc=0.9351
Best model saved!! Metric=27.99891397377423!!
Fold[1] Epoch: 10 [10/100 (10%)] Train loss=0.716319 Test loss=0.361861 Current lr=[0.00028063207935207196]

[0/23] Train loss=0.48049160838127136
[5/23] Train loss=0.8432814478874207
[10/23] Train loss=0.6354846954345703
[15/23] Train loss=0.5914751887321472
[20/23] Train loss=0.4779733121395111
Test set avg_accuracy=88.26% avg_sensitivity=83.69%, avg_specificity=89.81% avg_auc=0.9352
Best model saved!! Metric=29.275119004372417!!
Fold[1] Epoch: 11 [11/100 (11%)] Train loss=0.695641 Test loss=0.327036 Current lr=[0.0003254998011571065]

[0/23] Train loss=0.4810832738876343
[5/23] Train loss=0.8276858925819397
[10/23] Train loss=0.6034571528434753
[15/23] Train loss=0.5825853943824768
[20/23] Train loss=0.4711884558200836
Test set avg_accuracy=88.49% avg_sensitivity=82.63%, avg_specificity=90.47% avg_auc=0.9380
Best model saved!! Metric=29.38550124487492!!
Fold[1] Epoch: 12 [12/100 (12%)] Train loss=0.704141 Test loss=0.306475 Current lr=[0.0003725046923895547]

[0/23] Train loss=0.43860068917274475
[5/23] Train loss=0.8152094483375549
[10/23] Train loss=0.6078322529792786
[15/23] Train loss=0.5777969360351562
[20/23] Train loss=0.4824797511100769
Test set avg_accuracy=89.90% avg_sensitivity=79.62%, avg_specificity=93.38% avg_auc=0.9393
Best model saved!! Metric=30.816674953789146!!
Fold[1] Epoch: 13 [13/100 (13%)] Train loss=0.696266 Test loss=0.282120 Current lr=[0.0004211302630042728]

[0/23] Train loss=0.4296688437461853
[5/23] Train loss=0.802180290222168
[10/23] Train loss=0.5926499366760254
[15/23] Train loss=0.557811439037323
[20/23] Train loss=0.4886711835861206
Test set avg_accuracy=88.15% avg_sensitivity=86.25%, avg_specificity=88.79% avg_auc=0.9411
Best model saved!! Metric=31.294306500228444!!
Fold[1] Epoch: 14 [14/100 (14%)] Train loss=0.685038 Test loss=0.316377 Current lr=[0.0004708422149207104]

[0/23] Train loss=0.43226468563079834
[5/23] Train loss=0.7853012084960938
[10/23] Train loss=0.5930930376052856
[15/23] Train loss=0.5090148448944092
[20/23] Train loss=0.45499444007873535
Test set avg_accuracy=88.82% avg_sensitivity=80.27%, avg_specificity=91.71% avg_auc=0.9368
Fold[1] Epoch: 15 [15/100 (15%)] Train loss=0.669277 Test loss=0.285354 Current lr=[0.0005210943128936348]

[0/23] Train loss=0.4239157438278198
[5/23] Train loss=0.8302925825119019
[10/23] Train loss=0.56358802318573
[15/23] Train loss=0.5292537212371826
[20/23] Train loss=0.4487899839878082
Test set avg_accuracy=88.97% avg_sensitivity=83.16%, avg_specificity=90.94% avg_auc=0.9438
Best model saved!! Metric=31.444329207937187!!
Fold[1] Epoch: 16 [16/100 (16%)] Train loss=0.656714 Test loss=0.277597 Current lr=[0.0005713343865494929]

[0/23] Train loss=0.4234468638896942
[5/23] Train loss=0.8340803980827332
[10/23] Train loss=0.566497802734375
[15/23] Train loss=0.5166272521018982
[20/23] Train loss=0.46522125601768494
Test set avg_accuracy=89.70% avg_sensitivity=74.25%, avg_specificity=94.93% avg_auc=0.9345
Fold[1] Epoch: 17 [17/100 (17%)] Train loss=0.652391 Test loss=0.277658 Current lr=[0.0006210103976380052]

[0/23] Train loss=0.4255973994731903
[5/23] Train loss=0.8133444786071777
[10/23] Train loss=0.5459111332893372
[15/23] Train loss=0.5265494585037231
[20/23] Train loss=0.4535789489746094
Test set avg_accuracy=87.99% avg_sensitivity=83.20%, avg_specificity=89.62% avg_auc=0.9422
Fold[1] Epoch: 18 [18/100 (18%)] Train loss=0.651452 Test loss=0.288907 Current lr=[0.0006695765058319851]

[0/23] Train loss=0.42183318734169006
[5/23] Train loss=0.7752987742424011
[10/23] Train loss=0.5831023454666138
[15/23] Train loss=0.5099311470985413
[20/23] Train loss=0.4280896484851837
Test set avg_accuracy=89.73% avg_sensitivity=74.82%, avg_specificity=94.78% avg_auc=0.9389
Fold[1] Epoch: 19 [19/100 (19%)] Train loss=0.642076 Test loss=0.271854 Current lr=[0.0007164990664243417]

[0/23] Train loss=0.4050382971763611
[5/23] Train loss=0.8051170110702515
[10/23] Train loss=0.5350459218025208
[15/23] Train loss=0.46697282791137695
[20/23] Train loss=0.4445028305053711
Test set avg_accuracy=88.99% avg_sensitivity=83.89%, avg_specificity=90.72% avg_auc=0.9479
Best model saved!! Metric=32.38751619062967!!
Fold[1] Epoch: 20 [20/100 (20%)] Train loss=0.635721 Test loss=0.275729 Current lr=[0.0007612624940195301]

[0/23] Train loss=0.3835330307483673
[5/23] Train loss=0.792473316192627
[10/23] Train loss=0.5734196305274963
[15/23] Train loss=0.4735528826713562
[20/23] Train loss=0.4057707190513611
Test set avg_accuracy=89.62% avg_sensitivity=76.28%, avg_specificity=94.13% avg_auc=0.9423
Fold[1] Epoch: 21 [21/100 (21%)] Train loss=0.627550 Test loss=0.274303 Current lr=[0.000803374927789172]

[0/23] Train loss=0.38920193910598755
[5/23] Train loss=0.7402421832084656
[10/23] Train loss=0.5128023624420166
[15/23] Train loss=0.47221556305885315
[20/23] Train loss=0.4266641438007355
Test set avg_accuracy=88.49% avg_sensitivity=84.13%, avg_specificity=89.96% avg_auc=0.9419
Fold[1] Epoch: 22 [22/100 (22%)] Train loss=0.615726 Test loss=0.289646 Current lr=[0.0008423736360419787]

[0/23] Train loss=0.3780737519264221
[5/23] Train loss=0.7848170399665833
[10/23] Train loss=0.5427141189575195
[15/23] Train loss=0.511986255645752
[20/23] Train loss=0.43411317467689514
Test set avg_accuracy=89.60% avg_sensitivity=82.55%, avg_specificity=91.99% avg_auc=0.9454
Best model saved!! Metric=32.66698259024268!!
Fold[1] Epoch: 23 [23/100 (23%)] Train loss=0.624869 Test loss=0.278878 Current lr=[0.0008778301007225328]

[0/23] Train loss=0.38359129428863525
[5/23] Train loss=0.7806662917137146
[10/23] Train loss=0.5127938389778137
[15/23] Train loss=0.4814806580543518
[20/23] Train loss=0.4743374288082123
Test set avg_accuracy=89.48% avg_sensitivity=79.58%, avg_specificity=92.83% avg_auc=0.9427
Fold[1] Epoch: 24 [24/100 (24%)] Train loss=0.614739 Test loss=0.272906 Current lr=[0.0009093547259704173]

[0/23] Train loss=0.40725818276405334
[5/23] Train loss=0.8059244751930237
[10/23] Train loss=0.5274865627288818
[15/23] Train loss=0.4923393130302429
[20/23] Train loss=0.4801507294178009
Test set avg_accuracy=87.04% avg_sensitivity=83.40%, avg_specificity=88.27% avg_auc=0.9366
Fold[1] Epoch: 25 [25/100 (25%)] Train loss=0.622711 Test loss=0.318865 Current lr=[0.0009366011190020192]

[0/23] Train loss=0.3805716335773468
[5/23] Train loss=0.7917838096618652
[10/23] Train loss=0.48829764127731323
[15/23] Train loss=0.49052587151527405
[20/23] Train loss=0.4438488483428955
Test set avg_accuracy=88.74% avg_sensitivity=81.57%, avg_specificity=91.17% avg_auc=0.9428
Fold[1] Epoch: 26 [26/100 (26%)] Train loss=0.612770 Test loss=0.283626 Current lr=[0.0009592698962766488]

[0/23] Train loss=0.38790184259414673
[5/23] Train loss=0.7699451446533203
[10/23] Train loss=0.5036895275115967
[15/23] Train loss=0.4898483157157898
[20/23] Train loss=0.4603062868118286
Test set avg_accuracy=88.51% avg_sensitivity=84.01%, avg_specificity=90.03% avg_auc=0.9468
Fold[1] Epoch: 27 [27/100 (27%)] Train loss=0.611017 Test loss=0.280075 Current lr=[0.0009771119731247974]

[0/23] Train loss=0.3782058358192444
[5/23] Train loss=0.7682127356529236
[10/23] Train loss=0.5097530484199524
[15/23] Train loss=0.5077861547470093
[20/23] Train loss=0.42230379581451416
Test set avg_accuracy=90.53% avg_sensitivity=77.79%, avg_specificity=94.85% avg_auc=0.9458
Fold[1] Epoch: 28 [28/100 (28%)] Train loss=0.591887 Test loss=0.255616 Current lr=[0.0009899313006920766]

[0/23] Train loss=0.33722707629203796
[5/23] Train loss=0.7129591703414917
[10/23] Train loss=0.5134903788566589
[15/23] Train loss=0.47661280632019043
[20/23] Train loss=0.42357176542282104
Test set avg_accuracy=87.28% avg_sensitivity=88.12%, avg_specificity=87.00% avg_auc=0.9480
Fold[1] Epoch: 29 [29/100 (29%)] Train loss=0.571474 Test loss=0.294899 Current lr=[0.0009975870201252835]

[0/23] Train loss=0.3482285439968109
[5/23] Train loss=0.7176958918571472
[10/23] Train loss=0.548526406288147
[15/23] Train loss=0.4662342667579651
[20/23] Train loss=0.420463889837265
Test set avg_accuracy=87.96% avg_sensitivity=87.39%, avg_specificity=88.16% avg_auc=0.9487
Fold[1] Epoch: 30 [30/100 (30%)] Train loss=0.603552 Test loss=0.289827 Current lr=[0.000999999048111397]

[0/23] Train loss=0.3970983028411865
[5/23] Train loss=0.7441095113754272
[10/23] Train loss=0.48303964734077454
[15/23] Train loss=0.4643217623233795
[20/23] Train loss=0.38580721616744995
Test set avg_accuracy=89.72% avg_sensitivity=83.12%, avg_specificity=91.96% avg_auc=0.9491
Best model saved!! Metric=33.70202501881669!!
Fold[1] Epoch: 31 [31/100 (31%)] Train loss=0.581243 Test loss=0.261684 Current lr=[0.000999451812190372]

[0/23] Train loss=0.3501036465167999
[5/23] Train loss=0.7142090797424316
[10/23] Train loss=0.48381316661834717
[15/23] Train loss=0.4715132713317871
[20/23] Train loss=0.45030152797698975
Test set avg_accuracy=88.46% avg_sensitivity=85.15%, avg_specificity=89.58% avg_auc=0.9428
Fold[1] Epoch: 32 [32/100 (32%)] Train loss=0.572526 Test loss=0.298193 Current lr=[0.0009978987508156897]

[0/23] Train loss=0.34926271438598633
[5/23] Train loss=0.7472093105316162
[10/23] Train loss=0.48766836524009705
[15/23] Train loss=0.5334215760231018
[20/23] Train loss=0.465557724237442
Test set avg_accuracy=84.47% avg_sensitivity=41.70%, avg_specificity=98.94% avg_auc=0.9177
Fold[1] Epoch: 33 [33/100 (33%)] Train loss=0.618782 Test loss=0.359581 Current lr=[0.0009953429916462733]

[0/23] Train loss=0.38742494583129883
[5/23] Train loss=0.7833266258239746
[10/23] Train loss=0.47605517506599426
[15/23] Train loss=0.48602062463760376
[20/23] Train loss=0.4391312897205353
Test set avg_accuracy=89.12% avg_sensitivity=79.01%, avg_specificity=92.54% avg_auc=0.9451
Fold[1] Epoch: 34 [34/100 (34%)] Train loss=0.603552 Test loss=0.274726 Current lr=[0.000991789681640963]

[0/23] Train loss=0.37219274044036865
[5/23] Train loss=0.7794855237007141
[10/23] Train loss=0.5133947730064392
[15/23] Train loss=0.48170915246009827
[20/23] Train loss=0.41494813561439514
Test set avg_accuracy=89.92% avg_sensitivity=80.23%, avg_specificity=93.20% avg_auc=0.9441
Fold[1] Epoch: 35 [35/100 (35%)] Train loss=0.615138 Test loss=0.283914 Current lr=[0.0009872459766932253]

[0/23] Train loss=0.3815850019454956
[5/23] Train loss=0.7916492223739624
[10/23] Train loss=0.4677492678165436
[15/23] Train loss=0.4803581237792969
[20/23] Train loss=0.4349260926246643
Test set avg_accuracy=88.40% avg_sensitivity=84.87%, avg_specificity=89.59% avg_auc=0.9484
Fold[1] Epoch: 36 [36/100 (36%)] Train loss=0.580044 Test loss=0.282221 Current lr=[0.0009817210272201372]

[0/23] Train loss=0.3763384521007538
[5/23] Train loss=0.7480069398880005
[10/23] Train loss=0.5378276109695435
[15/23] Train loss=0.4972893297672272
[20/23] Train loss=0.45764896273612976
Test set avg_accuracy=88.32% avg_sensitivity=83.85%, avg_specificity=89.84% avg_auc=0.9473
Fold[1] Epoch: 37 [37/100 (37%)] Train loss=0.594778 Test loss=0.279915 Current lr=[0.0009752259597346622]

[0/23] Train loss=0.35575246810913086
[5/23] Train loss=0.7350798845291138
[10/23] Train loss=0.5189058780670166
[15/23] Train loss=0.5672515630722046
[20/23] Train loss=0.41942980885505676
Test set avg_accuracy=88.10% avg_sensitivity=85.03%, avg_specificity=89.14% avg_auc=0.9458
Fold[1] Epoch: 38 [38/100 (38%)] Train loss=0.588677 Test loss=0.286450 Current lr=[0.000967773854438336]

[0/23] Train loss=0.3830280900001526
[5/23] Train loss=0.7573320865631104
[10/23] Train loss=0.5056555271148682
[15/23] Train loss=0.4626123309135437
[20/23] Train loss=0.42272084951400757
Test set avg_accuracy=89.65% avg_sensitivity=80.19%, avg_specificity=92.85% avg_auc=0.9440
Fold[1] Epoch: 39 [39/100 (39%)] Train loss=0.571467 Test loss=0.267910 Current lr=[0.000959379718879479]

[0/23] Train loss=0.3680972754955292
[5/23] Train loss=0.7083072066307068
[10/23] Train loss=0.5097312331199646
[15/23] Train loss=0.48701056838035583
[20/23] Train loss=0.38713905215263367
Test set avg_accuracy=89.21% avg_sensitivity=85.48%, avg_specificity=90.47% avg_auc=0.9463
Best model saved!! Metric=33.78249580952057!!
Fold[1] Epoch: 40 [40/100 (40%)] Train loss=0.571198 Test loss=0.279291 Current lr=[0.0009500604577299936]

[0/23] Train loss=0.360095351934433
[5/23] Train loss=0.7456696033477783
[10/23] Train loss=0.5113295912742615
[15/23] Train loss=0.4502711892127991
[20/23] Train loss=0.3969348967075348
Test set avg_accuracy=87.35% avg_sensitivity=89.83%, avg_specificity=86.51% avg_auc=0.9508
Fold[1] Epoch: 41 [41/100 (41%)] Train loss=0.565699 Test loss=0.302761 Current lr=[0.0009398348387416027]

[0/23] Train loss=0.38521963357925415
[5/23] Train loss=0.681717038154602
[10/23] Train loss=0.4424816071987152
[15/23] Train loss=0.43047577142715454
[20/23] Train loss=0.3625646233558655
Test set avg_accuracy=86.77% avg_sensitivity=90.81%, avg_specificity=85.40% avg_auc=0.9528
Fold[1] Epoch: 42 [42/100 (42%)] Train loss=0.537085 Test loss=0.311065 Current lr=[0.000928723454950097]

[0/23] Train loss=0.37548962235450745
[5/23] Train loss=0.6774173378944397
[10/23] Train loss=0.450167715549469
[15/23] Train loss=0.4638543725013733
[20/23] Train loss=0.3732529878616333
Test set avg_accuracy=89.01% avg_sensitivity=84.74%, avg_specificity=90.46% avg_auc=0.9485
Fold[1] Epoch: 43 [43/100 (43%)] Train loss=0.528149 Test loss=0.279224 Current lr=[0.0009167486832037001]

[0/23] Train loss=0.35218241810798645
[5/23] Train loss=0.6379132270812988
[10/23] Train loss=0.4826865494251251
[15/23] Train loss=0.4468369781970978
[20/23] Train loss=0.347824364900589
Test set avg_accuracy=88.99% avg_sensitivity=84.95%, avg_specificity=90.36% avg_auc=0.9505
Fold[1] Epoch: 44 [44/100 (44%)] Train loss=0.521066 Test loss=0.283449 Current lr=[0.0009039346390990754]

[0/23] Train loss=0.36553311347961426
[5/23] Train loss=0.6387630105018616
[10/23] Train loss=0.49419042468070984
[15/23] Train loss=0.43015366792678833
[20/23] Train loss=0.35107043385505676
Test set avg_accuracy=88.16% avg_sensitivity=89.38%, avg_specificity=87.74% avg_auc=0.9495
Best model saved!! Metric=34.23010782669128!!
Fold[1] Epoch: 45 [45/100 (45%)] Train loss=0.512830 Test loss=0.320965 Current lr=[0.000890307128415723]

[0/23] Train loss=0.3748808205127716
[5/23] Train loss=0.6626275777816772
[10/23] Train loss=0.5118051171302795
[15/23] Train loss=0.4575582444667816
[20/23] Train loss=0.36879074573516846
Test set avg_accuracy=88.35% avg_sensitivity=90.81%, avg_specificity=87.52% avg_auc=0.9549
Best model saved!! Metric=36.1757019180833!!
Fold[1] Epoch: 46 [46/100 (46%)] Train loss=0.516167 Test loss=0.312944 Current lr=[0.0008758935951465738]

[0/23] Train loss=0.3572114109992981
[5/23] Train loss=0.6900529861450195
[10/23] Train loss=0.4578140676021576
[15/23] Train loss=0.3843790590763092
[20/23] Train loss=0.32764527201652527
Test set avg_accuracy=85.79% avg_sensitivity=90.76%, avg_specificity=84.11% avg_auc=0.9502
Fold[1] Epoch: 47 [47/100 (47%)] Train loss=0.500263 Test loss=0.345377 Current lr=[0.0008607230662294413]

[0/23] Train loss=0.33345872163772583
[5/23] Train loss=0.6709495782852173
[10/23] Train loss=0.4516826272010803
[15/23] Train loss=0.41670340299606323
[20/23] Train loss=0.3314809501171112
Test set avg_accuracy=88.73% avg_sensitivity=86.62%, avg_specificity=89.45% avg_auc=0.9498
Fold[1] Epoch: 48 [48/100 (48%)] Train loss=0.494750 Test loss=0.295622 Current lr=[0.0008448260930906307]

[0/23] Train loss=0.34419047832489014
[5/23] Train loss=0.6089457869529724
[10/23] Train loss=0.45746442675590515
[15/23] Train loss=0.4044994115829468
[20/23] Train loss=0.32690057158470154
Test set avg_accuracy=87.50% avg_sensitivity=89.26%, avg_specificity=86.90% avg_auc=0.9511
Fold[1] Epoch: 49 [49/100 (49%)] Train loss=0.483126 Test loss=0.324308 Current lr=[0.0008282346901184324]

[0/23] Train loss=0.3540969491004944
[5/23] Train loss=0.6316760182380676
[10/23] Train loss=0.4466886818408966
[15/23] Train loss=0.4064747095108032
[20/23] Train loss=0.36249032616615295
Test set avg_accuracy=86.73% avg_sensitivity=89.71%, avg_specificity=85.72% avg_auc=0.9506
Fold[1] Epoch: 50 [50/100 (50%)] Train loss=0.483665 Test loss=0.357318 Current lr=[0.000810982270190405]

[0/23] Train loss=0.36083897948265076
[5/23] Train loss=0.6287201046943665
[10/23] Train loss=0.44248515367507935
[15/23] Train loss=0.38519084453582764
[20/23] Train loss=0.3340379595756531
Test set avg_accuracy=87.73% avg_sensitivity=88.89%, avg_specificity=87.33% avg_auc=0.9497
Fold[1] Epoch: 51 [51/100 (51%)] Train loss=0.472226 Test loss=0.334508 Current lr=[0.0007931035773842862]

[0/23] Train loss=0.36709877848625183
[5/23] Train loss=0.6578695178031921
[10/23] Train loss=0.45482420921325684
[15/23] Train loss=0.4106014668941498
[20/23] Train loss=0.3294994831085205
Test set avg_accuracy=87.37% avg_sensitivity=90.20%, avg_specificity=86.41% avg_auc=0.9483
Fold[1] Epoch: 52 [52/100 (52%)] Train loss=0.463853 Test loss=0.342623 Current lr=[0.0007746346170080441]

[0/23] Train loss=0.34086447954177856
[5/23] Train loss=0.5998457074165344
[10/23] Train loss=0.4444909393787384
[15/23] Train loss=0.3868047595024109
[20/23] Train loss=0.32551345229148865
Test set avg_accuracy=88.73% avg_sensitivity=89.06%, avg_specificity=88.63% avg_auc=0.9491
Fold[1] Epoch: 53 [53/100 (53%)] Train loss=0.454344 Test loss=0.315777 Current lr=[0.0007556125830899786]

[0/23] Train loss=0.338446706533432
[5/23] Train loss=0.6108178496360779
[10/23] Train loss=0.42236796021461487
[15/23] Train loss=0.39176246523857117
[20/23] Train loss=0.3082650601863861
Test set avg_accuracy=87.30% avg_sensitivity=88.65%, avg_specificity=86.85% avg_auc=0.9475
Fold[1] Epoch: 54 [54/100 (54%)] Train loss=0.446592 Test loss=0.334921 Current lr=[0.0007360757834748981]

[0/23] Train loss=0.3033204972743988
[5/23] Train loss=0.5530533790588379
[10/23] Train loss=0.42846226692199707
[15/23] Train loss=0.3650253117084503
[20/23] Train loss=0.28529712557792664
Test set avg_accuracy=88.74% avg_sensitivity=87.35%, avg_specificity=89.22% avg_auc=0.9500
Fold[1] Epoch: 55 [55/100 (55%)] Train loss=0.425683 Test loss=0.312930 Current lr=[0.000716063562677219]

[0/23] Train loss=0.32024312019348145
[5/23] Train loss=0.5440149307250977
[10/23] Train loss=0.409621000289917
[15/23] Train loss=0.3576672077178955
[20/23] Train loss=0.2717685103416443
Test set avg_accuracy=90.01% avg_sensitivity=79.74%, avg_specificity=93.49% avg_auc=0.9443
Fold[1] Epoch: 56 [56/100 (56%)] Train loss=0.413903 Test loss=0.303010 Current lr=[0.0006956162226463489]

[0/23] Train loss=0.267715722322464
[5/23] Train loss=0.4946771264076233
[10/23] Train loss=0.4113374948501587
[15/23] Train loss=0.3870660960674286
[20/23] Train loss=0.26831161975860596
Test set avg_accuracy=90.04% avg_sensitivity=84.70%, avg_specificity=91.85% avg_auc=0.9498
Fold[1] Epoch: 57 [57/100 (57%)] Train loss=0.407216 Test loss=0.299729 Current lr=[0.0006747749416039243]

[0/23] Train loss=0.2613071799278259
[5/23] Train loss=0.5544493198394775
[10/23] Train loss=0.41389331221580505
[15/23] Train loss=0.3552268147468567
[20/23] Train loss=0.24746672809123993
Test set avg_accuracy=89.35% avg_sensitivity=86.29%, avg_specificity=90.39% avg_auc=0.9494
Fold[1] Epoch: 58 [58/100 (58%)] Train loss=0.403603 Test loss=0.327835 Current lr=[0.000653581691116352]

[0/23] Train loss=0.26753997802734375
[5/23] Train loss=0.5357640385627747
[10/23] Train loss=0.4040127098560333
[15/23] Train loss=0.35224252939224243
[20/23] Train loss=0.26672980189323425
Test set avg_accuracy=89.35% avg_sensitivity=84.99%, avg_specificity=90.83% avg_auc=0.9493
Fold[1] Epoch: 59 [59/100 (59%)] Train loss=0.396361 Test loss=0.314452 Current lr=[0.0006320791515696602]

[0/23] Train loss=0.27397704124450684
[5/23] Train loss=0.5225516557693481
[10/23] Train loss=0.37113475799560547
[15/23] Train loss=0.3391170799732208
[20/23] Train loss=0.25278013944625854
Test set avg_accuracy=90.00% avg_sensitivity=84.30%, avg_specificity=91.93% avg_auc=0.9483
Fold[1] Epoch: 60 [60/100 (60%)] Train loss=0.382280 Test loss=0.306793 Current lr=[0.0006103106262168818]

[0/23] Train loss=0.2637595236301422
[5/23] Train loss=0.49901455640792847
[10/23] Train loss=0.38306114077568054
[15/23] Train loss=0.32991352677345276
[20/23] Train loss=0.2710568606853485
Test set avg_accuracy=89.47% avg_sensitivity=84.62%, avg_specificity=91.10% avg_auc=0.9476
Fold[1] Epoch: 61 [61/100 (61%)] Train loss=0.372052 Test loss=0.309280 Current lr=[0.0005883199539710647]

[0/23] Train loss=0.2427356094121933
[5/23] Train loss=0.4491642415523529
[10/23] Train loss=0.35840559005737305
[15/23] Train loss=0.32316458225250244
[20/23] Train loss=0.2480747401714325
Test set avg_accuracy=89.09% avg_sensitivity=87.18%, avg_specificity=89.74% avg_auc=0.9503
Fold[1] Epoch: 62 [62/100 (62%)] Train loss=0.356333 Test loss=0.310428 Current lr=[0.0005661514211195354]

[0/23] Train loss=0.24341142177581787
[5/23] Train loss=0.4470396935939789
[10/23] Train loss=0.36528515815734863
[15/23] Train loss=0.3020087778568268
[20/23] Train loss=0.23747174441814423
Test set avg_accuracy=87.64% avg_sensitivity=87.10%, avg_specificity=87.83% avg_auc=0.9457
Fold[1] Epoch: 63 [63/100 (63%)] Train loss=0.344283 Test loss=0.344368 Current lr=[0.00054384967213721]

[0/23] Train loss=0.2547547519207001
[5/23] Train loss=0.4297575056552887
[10/23] Train loss=0.35643988847732544
[15/23] Train loss=0.30511024594306946
[20/23] Train loss=0.23066718876361847
Test set avg_accuracy=89.03% avg_sensitivity=85.76%, avg_specificity=90.14% avg_auc=0.9468
Fold[1] Epoch: 64 [64/100 (64%)] Train loss=0.341967 Test loss=0.323991 Current lr=[0.000521459619778564]

[0/23] Train loss=0.22821210324764252
[5/23] Train loss=0.4431834816932678
[10/23] Train loss=0.35131222009658813
[15/23] Train loss=0.32840099930763245
[20/23] Train loss=0.24026599526405334
Test set avg_accuracy=89.60% avg_sensitivity=84.58%, avg_specificity=91.30% avg_auc=0.9479
Fold[1] Epoch: 65 [65/100 (65%)] Train loss=0.336678 Test loss=0.312899 Current lr=[0.0004990263546293204]

[0/23] Train loss=0.240650936961174
[5/23] Train loss=0.3893313407897949
[10/23] Train loss=0.3254275918006897
[15/23] Train loss=0.28083688020706177
[20/23] Train loss=0.23541073501110077
Test set avg_accuracy=89.79% avg_sensitivity=84.87%, avg_specificity=91.46% avg_auc=0.9491
Fold[1] Epoch: 66 [66/100 (66%)] Train loss=0.318979 Test loss=0.298676 Current lr=[0.000476595054300012]

[0/23] Train loss=0.20420339703559875
[5/23] Train loss=0.3924548327922821
[10/23] Train loss=0.33163565397262573
[15/23] Train loss=0.27580466866493225
[20/23] Train loss=0.21466173231601715
Test set avg_accuracy=89.73% avg_sensitivity=82.51%, avg_specificity=92.18% avg_auc=0.9454
Fold[1] Epoch: 67 [67/100 (67%)] Train loss=0.312207 Test loss=0.311222 Current lr=[0.0004542108924442853]

[0/23] Train loss=0.19700519740581512
[5/23] Train loss=0.396211177110672
[10/23] Train loss=0.30194205045700073
[15/23] Train loss=0.2533600628376007
[20/23] Train loss=0.21757350862026215
Test set avg_accuracy=89.95% avg_sensitivity=81.45%, avg_specificity=92.83% avg_auc=0.9461
Fold[1] Epoch: 68 [68/100 (68%)] Train loss=0.296092 Test loss=0.307868 Current lr=[0.000431918947785175]

[0/23] Train loss=0.1775820255279541
[5/23] Train loss=0.38195791840553284
[10/23] Train loss=0.31611213088035583
[15/23] Train loss=0.264813095331192
[20/23] Train loss=0.24563027918338776
Test set avg_accuracy=90.03% avg_sensitivity=72.78%, avg_specificity=95.87% avg_auc=0.9378
Fold[1] Epoch: 69 [69/100 (69%)] Train loss=0.292677 Test loss=0.341440 Current lr=[0.0004097641133325535]

[0/23] Train loss=0.20236049592494965
[5/23] Train loss=0.35857418179512024
[10/23] Train loss=0.338897168636322
[15/23] Train loss=0.2943006455898285
[20/23] Train loss=0.23088374733924866
Test set avg_accuracy=90.04% avg_sensitivity=78.93%, avg_specificity=93.80% avg_auc=0.9445
Fold[1] Epoch: 70 [70/100 (70%)] Train loss=0.301925 Test loss=0.305242 Current lr=[0.00038779100597458526]

[0/23] Train loss=0.1770072728395462
[5/23] Train loss=0.3882172107696533
[10/23] Train loss=0.2938069999217987
[15/23] Train loss=0.27879878878593445
[20/23] Train loss=0.19562296569347382
Test set avg_accuracy=89.35% avg_sensitivity=79.37%, avg_specificity=92.73% avg_auc=0.9417
Fold[1] Epoch: 71 [71/100 (71%)] Train loss=0.284517 Test loss=0.326144 Current lr=[0.0003660438766252499]

[0/23] Train loss=0.19552533328533173
[5/23] Train loss=0.3460339903831482
[10/23] Train loss=0.2861340641975403
[15/23] Train loss=0.2553364634513855
[20/23] Train loss=0.17623357474803925
Test set avg_accuracy=89.89% avg_sensitivity=82.10%, avg_specificity=92.52% avg_auc=0.9444
Fold[1] Epoch: 72 [72/100 (72%)] Train loss=0.268330 Test loss=0.326669 Current lr=[0.0003445665211088922]

[0/23] Train loss=0.1872820258140564
[5/23] Train loss=0.34866011142730713
[10/23] Train loss=0.27956029772758484
[15/23] Train loss=0.25262242555618286
[20/23] Train loss=0.1736537665128708
Test set avg_accuracy=89.91% avg_sensitivity=80.59%, avg_specificity=93.06% avg_auc=0.9441
Fold[1] Epoch: 73 [73/100 (73%)] Train loss=0.263963 Test loss=0.342256 Current lr=[0.00032340219196125877]

[0/23] Train loss=0.17700298130512238
[5/23] Train loss=0.29388365149497986
[10/23] Train loss=0.24522294104099274
[15/23] Train loss=0.23916658759117126
[20/23] Train loss=0.2028600424528122
Test set avg_accuracy=89.74% avg_sensitivity=84.13%, avg_specificity=91.64% avg_auc=0.9468
Fold[1] Epoch: 74 [74/100 (74%)] Train loss=0.255109 Test loss=0.341023 Current lr=[0.0003025935113246488]

[0/23] Train loss=0.16985134780406952
[5/23] Train loss=0.3253247141838074
[10/23] Train loss=0.24599093198776245
[15/23] Train loss=0.22736167907714844
[20/23] Train loss=0.1796903759241104
Test set avg_accuracy=89.16% avg_sensitivity=85.72%, avg_specificity=90.32% avg_auc=0.9457
Fold[1] Epoch: 75 [75/100 (75%)] Train loss=0.246124 Test loss=0.356737 Current lr=[0.0002821823851125901]

[0/23] Train loss=0.17948071658611298
[5/23] Train loss=0.26775118708610535
[10/23] Train loss=0.2718934416770935
[15/23] Train loss=0.23271073400974274
[20/23] Train loss=0.17374251782894135
Test set avg_accuracy=89.15% avg_sensitivity=86.45%, avg_specificity=90.06% avg_auc=0.9457
Fold[1] Epoch: 76 [76/100 (76%)] Train loss=0.235904 Test loss=0.373652 Current lr=[0.00026220991861690765]

[0/23] Train loss=0.18992137908935547
[5/23] Train loss=0.2687142491340637
[10/23] Train loss=0.22377905249595642
[15/23] Train loss=0.2568701505661011
[20/23] Train loss=0.1576247215270996
Test set avg_accuracy=89.68% avg_sensitivity=86.86%, avg_specificity=90.64% avg_auc=0.9454
Fold[1] Epoch: 77 [77/100 (77%)] Train loss=0.226139 Test loss=0.371570 Current lr=[0.00024271633372713536]

[0/23] Train loss=0.16810092329978943
[5/23] Train loss=0.263454794883728
[10/23] Train loss=0.2212143987417221
[15/23] Train loss=0.21735338866710663
[20/23] Train loss=0.1658317595720291
Test set avg_accuracy=89.99% avg_sensitivity=83.36%, avg_specificity=92.23% avg_auc=0.9441
Fold[1] Epoch: 78 [78/100 (78%)] Train loss=0.213407 Test loss=0.370506 Current lr=[0.00022374088792898362]

[0/23] Train loss=0.15308058261871338
[5/23] Train loss=0.2521068751811981
[10/23] Train loss=0.21387551724910736
[15/23] Train loss=0.1928562968969345
[20/23] Train loss=0.14420825242996216
Test set avg_accuracy=89.59% avg_sensitivity=84.38%, avg_specificity=91.35% avg_auc=0.9459
Fold[1] Epoch: 79 [79/100 (79%)] Train loss=0.204780 Test loss=0.358313 Current lr=[0.00020532179524498774]

[0/23] Train loss=0.1529054194688797
[5/23] Train loss=0.2582935690879822
[10/23] Train loss=0.20048972964286804
[15/23] Train loss=0.21759815514087677
[20/23] Train loss=0.14572401344776154
Test set avg_accuracy=89.70% avg_sensitivity=83.20%, avg_specificity=91.90% avg_auc=0.9442
Fold[1] Epoch: 80 [80/100 (80%)] Train loss=0.199520 Test loss=0.377315 Current lr=[0.000187496149276552]

[0/23] Train loss=0.14742979407310486
[5/23] Train loss=0.2368735671043396
[10/23] Train loss=0.20255377888679504
[15/23] Train loss=0.19981589913368225
[20/23] Train loss=0.13793471455574036
Test set avg_accuracy=89.56% avg_sensitivity=83.97%, avg_specificity=91.45% avg_auc=0.9446
Fold[1] Epoch: 81 [81/100 (81%)] Train loss=0.193569 Test loss=0.382048 Current lr=[0.00017029984850237305]

[0/23] Train loss=0.1429162323474884
[5/23] Train loss=0.2150232493877411
[10/23] Train loss=0.2035958617925644
[15/23] Train loss=0.18959671258926392
[20/23] Train loss=0.15253950655460358
Test set avg_accuracy=89.80% avg_sensitivity=83.16%, avg_specificity=92.05% avg_auc=0.9433
Fold[1] Epoch: 82 [82/100 (82%)] Train loss=0.186234 Test loss=0.383947 Current lr=[0.00015376752398368106]

[0/23] Train loss=0.14725489914417267
[5/23] Train loss=0.2226720005273819
[10/23] Train loss=0.18708880245685577
[15/23] Train loss=0.18571510910987854
[20/23] Train loss=0.1323421448469162
Test set avg_accuracy=89.51% avg_sensitivity=83.56%, avg_specificity=91.52% avg_auc=0.9437
Fold[1] Epoch: 83 [83/100 (83%)] Train loss=0.184683 Test loss=0.381019 Current lr=[0.00013793246962189157]

[0/23] Train loss=0.12735021114349365
[5/23] Train loss=0.2115500569343567
[10/23] Train loss=0.17971646785736084
[15/23] Train loss=0.1727837175130844
[20/23] Train loss=0.1360291689634323
Test set avg_accuracy=89.81% avg_sensitivity=83.44%, avg_specificity=91.97% avg_auc=0.9442
Fold[1] Epoch: 84 [84/100 (84%)] Train loss=0.176823 Test loss=0.395314 Current lr=[0.00012282657510911843]

[0/23] Train loss=0.13060902059078217
[5/23] Train loss=0.2126297652721405
[10/23] Train loss=0.17925119400024414
[15/23] Train loss=0.17694133520126343
[20/23] Train loss=0.13823460042476654
Test set avg_accuracy=89.63% avg_sensitivity=83.48%, avg_specificity=91.71% avg_auc=0.9443
Fold[1] Epoch: 85 [85/100 (85%)] Train loss=0.174769 Test loss=0.391837 Current lr=[0.0001084802617065783]

[0/23] Train loss=0.12406861782073975
[5/23] Train loss=0.20321030914783478
[10/23] Train loss=0.183367058634758
[15/23] Train loss=0.18268141150474548
[20/23] Train loss=0.13691936433315277
Test set avg_accuracy=89.75% avg_sensitivity=83.12%, avg_specificity=92.00% avg_auc=0.9448
Fold[1] Epoch: 86 [86/100 (86%)] Train loss=0.166722 Test loss=0.385999 Current lr=[9.492242098021878e-05]

[0/23] Train loss=0.11391358077526093
[5/23] Train loss=0.21686401963233948
[10/23] Train loss=0.18350949883460999
[15/23] Train loss=0.18347296118736267
[20/23] Train loss=0.13020308315753937
Test set avg_accuracy=89.96% avg_sensitivity=83.12%, avg_specificity=92.27% avg_auc=0.9447
Fold[1] Epoch: 87 [87/100 (87%)] Train loss=0.167943 Test loss=0.392411 Current lr=[8.218035661694964e-05]

[0/23] Train loss=0.12255550175905228
[5/23] Train loss=0.20061103999614716
[10/23] Train loss=0.16440193355083466
[15/23] Train loss=0.17480877041816711
[20/23] Train loss=0.1402788758277893
Test set avg_accuracy=89.92% avg_sensitivity=83.73%, avg_specificity=92.01% avg_auc=0.9450
Fold[1] Epoch: 88 [88/100 (88%)] Train loss=0.164874 Test loss=0.402054 Current lr=[7.02797294386511e-05]

[0/23] Train loss=0.11911115050315857
[5/23] Train loss=0.18528054654598236
[10/23] Train loss=0.16846343874931335
[15/23] Train loss=0.14997167885303497
[20/23] Train loss=0.12855307757854462
Test set avg_accuracy=89.81% avg_sensitivity=83.28%, avg_specificity=92.03% avg_auc=0.9444
Fold[1] Epoch: 89 [89/100 (89%)] Train loss=0.161721 Test loss=0.401374 Current lr=[5.924450572469346e-05]

[0/23] Train loss=0.13016408681869507
[5/23] Train loss=0.19790856540203094
[10/23] Train loss=0.1644936352968216
[15/23] Train loss=0.15826524794101715
[20/23] Train loss=0.13263528048992157
Test set avg_accuracy=89.88% avg_sensitivity=82.75%, avg_specificity=92.29% avg_auc=0.9441
Fold[1] Epoch: 90 [90/100 (90%)] Train loss=0.160780 Test loss=0.404969 Current lr=[4.90969089470401e-05]

[0/23] Train loss=0.11993804574012756
[5/23] Train loss=0.18730634450912476
[10/23] Train loss=0.15411245822906494
[15/23] Train loss=0.1515243500471115
[20/23] Train loss=0.13708597421646118
Test set avg_accuracy=89.88% avg_sensitivity=83.03%, avg_specificity=92.19% avg_auc=0.9440
Fold[1] Epoch: 91 [91/100 (91%)] Train loss=0.157105 Test loss=0.408957 Current lr=[3.985737501513232e-05]

[0/23] Train loss=0.11512605845928192
[5/23] Train loss=0.18772616982460022
[10/23] Train loss=0.16517280042171478
[15/23] Train loss=0.15133045613765717
[20/23] Train loss=0.11220118403434753
Test set avg_accuracy=90.10% avg_sensitivity=83.20%, avg_specificity=92.44% avg_auc=0.9444
Fold[1] Epoch: 92 [92/100 (92%)] Train loss=0.154876 Test loss=0.408741 Current lr=[3.154451112068745e-05]

[0/23] Train loss=0.10470139980316162
[5/23] Train loss=0.19816361367702484
[10/23] Train loss=0.15998324751853943
[15/23] Train loss=0.14195378124713898
[20/23] Train loss=0.13009081780910492
Test set avg_accuracy=89.93% avg_sensitivity=83.24%, avg_specificity=92.19% avg_auc=0.9445
Fold[1] Epoch: 93 [93/100 (93%)] Train loss=0.154615 Test loss=0.407790 Current lr=[2.4175058265291265e-05]

[0/23] Train loss=0.1107407659292221
[5/23] Train loss=0.19101037085056305
[10/23] Train loss=0.15818847715854645
[15/23] Train loss=0.1533517837524414
[20/23] Train loss=0.1231665387749672
Test set avg_accuracy=89.81% avg_sensitivity=83.20%, avg_specificity=92.05% avg_auc=0.9445
Fold[1] Epoch: 94 [94/100 (94%)] Train loss=0.154740 Test loss=0.408002 Current lr=[1.7763857546248248e-05]

[0/23] Train loss=0.10739156603813171
[5/23] Train loss=0.202670156955719
[10/23] Train loss=0.1647665947675705
[15/23] Train loss=0.1724168062210083
[20/23] Train loss=0.12300170958042145
Test set avg_accuracy=89.93% avg_sensitivity=83.16%, avg_specificity=92.22% avg_auc=0.9444
Fold[1] Epoch: 95 [95/100 (95%)] Train loss=0.155847 Test loss=0.407715 Current lr=[1.2323820268587161e-05]

[0/23] Train loss=0.13027158379554749
[5/23] Train loss=0.17132781445980072
[10/23] Train loss=0.18801076710224152
[15/23] Train loss=0.14611949026584625
[20/23] Train loss=0.14441917836666107
Test set avg_accuracy=90.06% avg_sensitivity=83.28%, avg_specificity=92.36% avg_auc=0.9445
Fold[1] Epoch: 96 [96/100 (96%)] Train loss=0.154549 Test loss=0.407593 Current lr=[7.865901943410707e-06]

[0/23] Train loss=0.10914505273103714
[5/23] Train loss=0.1712602823972702
[10/23] Train loss=0.1562652736902237
[15/23] Train loss=0.14955076575279236
[20/23] Train loss=0.12194754183292389
Test set avg_accuracy=90.13% avg_sensitivity=83.24%, avg_specificity=92.47% avg_auc=0.9444
Fold[1] Epoch: 97 [97/100 (97%)] Train loss=0.153689 Test loss=0.408138 Current lr=[4.399080224954306e-06]

[0/23] Train loss=0.10873391479253769
[5/23] Train loss=0.20296162366867065
[10/23] Train loss=0.1661015897989273
[15/23] Train loss=0.14614911377429962
[20/23] Train loss=0.13546250760555267
Test set avg_accuracy=90.14% avg_sensitivity=83.20%, avg_specificity=92.50% avg_auc=0.9444
Fold[1] Epoch: 98 [98/100 (98%)] Train loss=0.154646 Test loss=0.408656 Current lr=[1.930336830785271e-06]

[0/23] Train loss=0.1089404821395874
[5/23] Train loss=0.1671276092529297
[10/23] Train loss=0.14992178976535797
[15/23] Train loss=0.15166039764881134
[20/23] Train loss=0.12744587659835815
Test set avg_accuracy=90.13% avg_sensitivity=83.16%, avg_specificity=92.50% avg_auc=0.9444
Fold[1] Epoch: 99 [99/100 (99%)] Train loss=0.152660 Test loss=0.408800 Current lr=[4.6464348155246055e-07]

[0/23] Train loss=0.10584083199501038
[5/23] Train loss=0.1869426965713501
[10/23] Train loss=0.16690270602703094
[15/23] Train loss=0.15304280817508698
[20/23] Train loss=0.12222127616405487
Test set avg_accuracy=90.12% avg_sensitivity=83.12%, avg_specificity=92.50% avg_auc=0.9444
Fold[1] Epoch: 100 [100/100 (100%)] Train loss=0.151309 Test loss=0.408042 Current lr=[4.951888602991508e-09]

Fold[1] Best Result: acc=88.35390946502058 sen=90.80553295362083, spe=87.52409804461581, auc=0.9549216145482609!
[0/23] Train loss=1.3967148065567017
[5/23] Train loss=1.4276524782180786
[10/23] Train loss=1.322035312652588
[15/23] Train loss=1.20672607421875
[20/23] Train loss=1.1196539402008057
Test set avg_accuracy=74.13% avg_sensitivity=13.02%, avg_specificity=92.46% avg_auc=0.6820
Best model saved!! Metric=-78.19730326485544!!
Fold[2] Epoch: 1 [1/100 (1%)] Train loss=1.280997 Test loss=0.563575 Current lr=[4.263712153319496e-05]

[0/23] Train loss=1.038602352142334
[5/23] Train loss=1.1580559015274048
[10/23] Train loss=0.9887481331825256
[15/23] Train loss=1.0130856037139893
[20/23] Train loss=0.8607522249221802
Test set avg_accuracy=76.71% avg_sensitivity=40.82%, avg_specificity=87.48% avg_auc=0.7787
Best model saved!! Metric=-43.113763670450595!!
Fold[2] Epoch: 2 [2/100 (2%)] Train loss=1.032337 Test loss=0.633594 Current lr=[5.051950942452628e-05]

[0/23] Train loss=0.890799343585968
[5/23] Train loss=1.0810198783874512
[10/23] Train loss=0.8830361366271973
[15/23] Train loss=0.9253454208374023
[20/23] Train loss=0.8184890151023865
Test set avg_accuracy=80.20% avg_sensitivity=49.68%, avg_specificity=89.35% avg_auc=0.8278
Best model saved!! Metric=-23.980365696503!!
Fold[2] Epoch: 3 [3/100 (3%)] Train loss=0.935565 Test loss=0.512611 Current lr=[6.356055194548904e-05]

[0/23] Train loss=0.8480499982833862
[5/23] Train loss=0.9815627336502075
[10/23] Train loss=0.8028855323791504
[15/23] Train loss=0.8585453629493713
[20/23] Train loss=0.7018582820892334
Test set avg_accuracy=81.98% avg_sensitivity=58.00%, avg_specificity=89.18% avg_auc=0.8543
Best model saved!! Metric=-11.412455403396567!!
Fold[2] Epoch: 4 [4/100 (4%)] Train loss=0.871796 Test loss=0.467936 Current lr=[8.161695403755248e-05]

[0/23] Train loss=0.7635583877563477
[5/23] Train loss=0.9630772471427917
[10/23] Train loss=0.7205018997192383
[15/23] Train loss=0.8027870059013367
[20/23] Train loss=0.6562954783439636
Test set avg_accuracy=83.38% avg_sensitivity=66.55%, avg_specificity=88.43% avg_auc=0.8850
Best model saved!! Metric=0.8583334203553781!!
Fold[2] Epoch: 5 [5/100 (5%)] Train loss=0.817174 Test loss=0.423951 Current lr=[0.00010449031183917899]

[0/23] Train loss=0.7129200100898743
[5/23] Train loss=0.9423795938491821
[10/23] Train loss=0.6916406750679016
[15/23] Train loss=0.6922276020050049
[20/23] Train loss=0.5841582417488098
Test set avg_accuracy=85.46% avg_sensitivity=66.64%, avg_specificity=91.10% avg_auc=0.9012
Best model saved!! Metric=7.31846102770065!!
Fold[2] Epoch: 6 [6/100 (6%)] Train loss=0.779730 Test loss=0.392222 Current lr=[0.00013192929274872232]

[0/23] Train loss=0.6552416086196899
[5/23] Train loss=0.9364191293716431
[10/23] Train loss=0.6785876154899597
[15/23] Train loss=0.6823055744171143
[20/23] Train loss=0.5533413887023926
Test set avg_accuracy=86.34% avg_sensitivity=72.33%, avg_specificity=90.55% avg_auc=0.9146
Best model saved!! Metric=14.67969817137794!!
Fold[2] Epoch: 7 [7/100 (7%)] Train loss=0.759333 Test loss=0.370249 Current lr=[0.00016363239706865967]

[0/23] Train loss=0.5745232105255127
[5/23] Train loss=0.9430983662605286
[10/23] Train loss=0.7023252248764038
[15/23] Train loss=0.6316239237785339
[20/23] Train loss=0.5270715355873108
Test set avg_accuracy=86.86% avg_sensitivity=72.97%, avg_specificity=91.03% avg_auc=0.9140
Best model saved!! Metric=16.26636706342364!!
Fold[2] Epoch: 8 [8/100 (8%)] Train loss=0.746736 Test loss=0.381241 Current lr=[0.00019925127088619402]

[0/23] Train loss=0.5682615637779236
[5/23] Train loss=0.8843823075294495
[10/23] Train loss=0.6682544946670532
[15/23] Train loss=0.5823158025741577
[20/23] Train loss=0.47935569286346436
Test set avg_accuracy=86.99% avg_sensitivity=69.30%, avg_specificity=92.30% avg_auc=0.9188
Fold[2] Epoch: 9 [9/100 (9%)] Train loss=0.723267 Test loss=0.350373 Current lr=[0.00023839453378827395]

[0/23] Train loss=0.5867201685905457
[5/23] Train loss=0.9010648131370544
[10/23] Train loss=0.6561390161514282
[15/23] Train loss=0.6039800047874451
[20/23] Train loss=0.4811078608036041
Test set avg_accuracy=87.61% avg_sensitivity=69.98%, avg_specificity=92.89% avg_auc=0.9144
Fold[2] Epoch: 10 [10/100 (10%)] Train loss=0.727588 Test loss=0.361380 Current lr=[0.00028063207935207196]

[0/23] Train loss=0.5578486323356628
[5/23] Train loss=0.876723051071167
[10/23] Train loss=0.6337981820106506
[15/23] Train loss=0.5971448421478271
[20/23] Train loss=0.49943357706069946
Test set avg_accuracy=87.16% avg_sensitivity=56.60%, avg_specificity=96.32% avg_auc=0.9188
Fold[2] Epoch: 11 [11/100 (11%)] Train loss=0.704192 Test loss=0.342716 Current lr=[0.0003254998011571065]

[0/23] Train loss=0.5540445446968079
[5/23] Train loss=0.8373087644577026
[10/23] Train loss=0.6403204798698425
[15/23] Train loss=0.5492645502090454
[20/23] Train loss=0.5111302137374878
Test set avg_accuracy=87.46% avg_sensitivity=68.17%, avg_specificity=93.25% avg_auc=0.9209
Fold[2] Epoch: 12 [12/100 (12%)] Train loss=0.716907 Test loss=0.301604 Current lr=[0.0003725046923895547]

[0/23] Train loss=0.5427772998809814
[5/23] Train loss=0.8535371422767639
[10/23] Train loss=0.6280726790428162
[15/23] Train loss=0.6002766489982605
[20/23] Train loss=0.4644676446914673
Test set avg_accuracy=88.10% avg_sensitivity=78.66%, avg_specificity=90.93% avg_auc=0.9263
Best model saved!! Metric=24.318466052441384!!
Fold[2] Epoch: 13 [13/100 (13%)] Train loss=0.686823 Test loss=0.323751 Current lr=[0.0004211302630042728]

[0/23] Train loss=0.48884716629981995
[5/23] Train loss=0.8950179219245911
[10/23] Train loss=0.6142103672027588
[15/23] Train loss=0.58943110704422
[20/23] Train loss=0.4672360122203827
Test set avg_accuracy=88.19% avg_sensitivity=76.58%, avg_specificity=91.67% avg_auc=0.9296
Fold[2] Epoch: 14 [14/100 (14%)] Train loss=0.677319 Test loss=0.307862 Current lr=[0.0004708422149207104]

[0/23] Train loss=0.5091499090194702
[5/23] Train loss=0.8113998174667358
[10/23] Train loss=0.5827903747558594
[15/23] Train loss=0.5004902482032776
[20/23] Train loss=0.4661167860031128
Test set avg_accuracy=87.95% avg_sensitivity=72.56%, avg_specificity=92.57% avg_auc=0.9249
Fold[2] Epoch: 15 [15/100 (15%)] Train loss=0.652350 Test loss=0.304029 Current lr=[0.0005210943128936348]

[0/23] Train loss=0.4940505027770996
[5/23] Train loss=0.8396684527397156
[10/23] Train loss=0.6024506688117981
[15/23] Train loss=0.5300189256668091
[20/23] Train loss=0.43244636058807373
Test set avg_accuracy=87.81% avg_sensitivity=77.49%, avg_specificity=90.91% avg_auc=0.9243
Fold[2] Epoch: 16 [16/100 (16%)] Train loss=0.655711 Test loss=0.319923 Current lr=[0.0005713343865494929]

[0/23] Train loss=0.5101142525672913
[5/23] Train loss=0.7481051087379456
[10/23] Train loss=0.4965311884880066
[15/23] Train loss=0.4857253432273865
[20/23] Train loss=0.4407464265823364
Test set avg_accuracy=88.51% avg_sensitivity=68.17%, avg_specificity=94.62% avg_auc=0.9208
Fold[2] Epoch: 17 [17/100 (17%)] Train loss=0.630485 Test loss=0.319799 Current lr=[0.0006210103976380052]

[0/23] Train loss=0.4903346598148346
[5/23] Train loss=0.8072379231452942
[10/23] Train loss=0.5837826132774353
[15/23] Train loss=0.5276510119438171
[20/23] Train loss=0.48426148295402527
Test set avg_accuracy=87.26% avg_sensitivity=75.81%, avg_specificity=90.70% avg_auc=0.9253
Fold[2] Epoch: 18 [18/100 (18%)] Train loss=0.653717 Test loss=0.310498 Current lr=[0.0006695765058319851]

[0/23] Train loss=0.5056771039962769
[5/23] Train loss=0.7781990170478821
[10/23] Train loss=0.4895298182964325
[15/23] Train loss=0.4895569384098053
[20/23] Train loss=0.47156909108161926
Test set avg_accuracy=87.05% avg_sensitivity=80.56%, avg_specificity=89.00% avg_auc=0.9322
Fold[2] Epoch: 19 [19/100 (19%)] Train loss=0.623400 Test loss=0.318271 Current lr=[0.0007164990664243417]

[0/23] Train loss=0.5026573538780212
[5/23] Train loss=0.824310302734375
[10/23] Train loss=0.5194151997566223
[15/23] Train loss=0.5067757368087769
[20/23] Train loss=0.47631320357322693
Test set avg_accuracy=87.87% avg_sensitivity=75.90%, avg_specificity=91.46% avg_auc=0.9303
Fold[2] Epoch: 20 [20/100 (20%)] Train loss=0.636700 Test loss=0.304736 Current lr=[0.0007612624940195301]

[0/23] Train loss=0.4957510828971863
[5/23] Train loss=0.7988073825836182
[10/23] Train loss=0.5041550993919373
[15/23] Train loss=0.4960806965827942
[20/23] Train loss=0.4618724584579468
Test set avg_accuracy=87.91% avg_sensitivity=80.11%, avg_specificity=90.25% avg_auc=0.9320
Best model saved!! Metric=25.467964817607772!!
Fold[2] Epoch: 21 [21/100 (21%)] Train loss=0.612686 Test loss=0.323598 Current lr=[0.000803374927789172]

[0/23] Train loss=0.4834184944629669
[5/23] Train loss=0.7592519521713257
[10/23] Train loss=0.5248146653175354
[15/23] Train loss=0.47615641355514526
[20/23] Train loss=0.4745132625102997
Test set avg_accuracy=88.46% avg_sensitivity=73.60%, avg_specificity=92.92% avg_auc=0.9290
Fold[2] Epoch: 22 [22/100 (22%)] Train loss=0.606306 Test loss=0.309378 Current lr=[0.0008423736360419787]

[0/23] Train loss=0.49222642183303833
[5/23] Train loss=0.7613659501075745
[10/23] Train loss=0.5516220331192017
[15/23] Train loss=0.4712338149547577
[20/23] Train loss=0.4577856957912445
Test set avg_accuracy=89.23% avg_sensitivity=73.24%, avg_specificity=94.03% avg_auc=0.9256
Fold[2] Epoch: 23 [23/100 (23%)] Train loss=0.622456 Test loss=0.302305 Current lr=[0.0008778301007225328]

[0/23] Train loss=0.5165684223175049
[5/23] Train loss=0.7541052103042603
[10/23] Train loss=0.5134327411651611
[15/23] Train loss=0.47168293595314026
[20/23] Train loss=0.47696471214294434
Test set avg_accuracy=88.34% avg_sensitivity=76.99%, avg_specificity=91.74% avg_auc=0.9284
Fold[2] Epoch: 24 [24/100 (24%)] Train loss=0.608471 Test loss=0.310557 Current lr=[0.0009093547259704173]

[0/23] Train loss=0.48722949624061584
[5/23] Train loss=0.7676752805709839
[10/23] Train loss=0.5303508043289185
[15/23] Train loss=0.4584779143333435
[20/23] Train loss=0.42140528559684753
Test set avg_accuracy=88.49% avg_sensitivity=70.48%, avg_specificity=93.90% avg_auc=0.9246
Fold[2] Epoch: 25 [25/100 (25%)] Train loss=0.604920 Test loss=0.301786 Current lr=[0.0009366011190020192]

[0/23] Train loss=0.48695313930511475
[5/23] Train loss=0.7780398726463318
[10/23] Train loss=0.49017655849456787
[15/23] Train loss=0.46101999282836914
[20/23] Train loss=0.4332687258720398
Test set avg_accuracy=87.98% avg_sensitivity=78.30%, avg_specificity=90.89% avg_auc=0.9330
Fold[2] Epoch: 26 [26/100 (26%)] Train loss=0.589178 Test loss=0.308758 Current lr=[0.0009592698962766488]

[0/23] Train loss=0.455028772354126
[5/23] Train loss=0.7427000999450684
[10/23] Train loss=0.4828120768070221
[15/23] Train loss=0.46322304010391235
[20/23] Train loss=0.4389319121837616
Test set avg_accuracy=88.47% avg_sensitivity=72.69%, avg_specificity=93.20% avg_auc=0.9311
Fold[2] Epoch: 27 [27/100 (27%)] Train loss=0.586597 Test loss=0.302748 Current lr=[0.0009771119731247974]

[0/23] Train loss=0.4786374568939209
[5/23] Train loss=0.7500176429748535
[10/23] Train loss=0.48977014422416687
[15/23] Train loss=0.4650403559207916
[20/23] Train loss=0.4180094301700592
Test set avg_accuracy=87.89% avg_sensitivity=79.07%, avg_specificity=90.53% avg_auc=0.9330
Fold[2] Epoch: 28 [28/100 (28%)] Train loss=0.575399 Test loss=0.317088 Current lr=[0.0009899313006920766]

[0/23] Train loss=0.4689479470252991
[5/23] Train loss=0.7054137587547302
[10/23] Train loss=0.4809631109237671
[15/23] Train loss=0.43431785702705383
[20/23] Train loss=0.43796664476394653
Test set avg_accuracy=88.56% avg_sensitivity=63.25%, avg_specificity=96.15% avg_auc=0.9186
Fold[2] Epoch: 29 [29/100 (29%)] Train loss=0.564716 Test loss=0.329614 Current lr=[0.0009975870201252835]

[0/23] Train loss=0.45215779542922974
[5/23] Train loss=0.7037847638130188
[10/23] Train loss=0.47652667760849
[15/23] Train loss=0.41130438446998596
[20/23] Train loss=0.42713117599487305
Test set avg_accuracy=88.24% avg_sensitivity=78.48%, avg_specificity=91.17% avg_auc=0.9298
Fold[2] Epoch: 30 [30/100 (30%)] Train loss=0.559131 Test loss=0.324765 Current lr=[0.000999999048111397]

[0/23] Train loss=0.42758193612098694
[5/23] Train loss=0.6974921226501465
[10/23] Train loss=0.4963463842868805
[15/23] Train loss=0.4634394943714142
[20/23] Train loss=0.4425010681152344
Test set avg_accuracy=87.69% avg_sensitivity=80.65%, avg_specificity=89.80% avg_auc=0.9320
Fold[2] Epoch: 31 [31/100 (31%)] Train loss=0.561132 Test loss=0.319029 Current lr=[0.000999451812190372]

[0/23] Train loss=0.4606139063835144
[5/23] Train loss=0.7600311040878296
[10/23] Train loss=0.4936344623565674
[15/23] Train loss=0.424284964799881
[20/23] Train loss=0.4082833230495453
Test set avg_accuracy=88.20% avg_sensitivity=71.07%, avg_specificity=93.34% avg_auc=0.9260
Fold[2] Epoch: 32 [32/100 (32%)] Train loss=0.563488 Test loss=0.311063 Current lr=[0.0009978987508156897]

[0/23] Train loss=0.4316851496696472
[5/23] Train loss=0.7250834107398987
[10/23] Train loss=0.45754191279411316
[15/23] Train loss=0.4362849295139313
[20/23] Train loss=0.4093954563140869
Test set avg_accuracy=88.69% avg_sensitivity=76.54%, avg_specificity=92.34% avg_auc=0.9354
Fold[2] Epoch: 33 [33/100 (33%)] Train loss=0.544593 Test loss=0.307783 Current lr=[0.0009953429916462733]

[0/23] Train loss=0.4388915002346039
[5/23] Train loss=0.6991444230079651
[10/23] Train loss=0.4872024655342102
[15/23] Train loss=0.4544568955898285
[20/23] Train loss=0.38255608081817627
Test set avg_accuracy=88.88% avg_sensitivity=74.55%, avg_specificity=93.18% avg_auc=0.9313
Fold[2] Epoch: 34 [34/100 (34%)] Train loss=0.543524 Test loss=0.308388 Current lr=[0.000991789681640963]

[0/23] Train loss=0.43241357803344727
[5/23] Train loss=0.712783932685852
[10/23] Train loss=0.4690173268318176
[15/23] Train loss=0.45209595561027527
[20/23] Train loss=0.4243256747722626
Test set avg_accuracy=88.59% avg_sensitivity=77.31%, avg_specificity=91.97% avg_auc=0.9283
Fold[2] Epoch: 35 [35/100 (35%)] Train loss=0.541606 Test loss=0.307383 Current lr=[0.0009872459766932253]

[0/23] Train loss=0.45043614506721497
[5/23] Train loss=0.6366734504699707
[10/23] Train loss=0.47360602021217346
[15/23] Train loss=0.3805144429206848
[20/23] Train loss=0.38350576162338257
Test set avg_accuracy=89.38% avg_sensitivity=77.76%, avg_specificity=92.87% avg_auc=0.9353
Best model saved!! Metric=27.53116214424538!!
Fold[2] Epoch: 36 [36/100 (36%)] Train loss=0.523411 Test loss=0.296017 Current lr=[0.0009817210272201372]

[0/23] Train loss=0.41453561186790466
[5/23] Train loss=0.6773846745491028
[10/23] Train loss=0.5023536682128906
[15/23] Train loss=0.4318515658378601
[20/23] Train loss=0.37270388007164
Test set avg_accuracy=88.47% avg_sensitivity=76.08%, avg_specificity=92.19% avg_auc=0.9317
Fold[2] Epoch: 37 [37/100 (37%)] Train loss=0.534715 Test loss=0.314395 Current lr=[0.0009752259597346622]

[0/23] Train loss=0.4327327311038971
[5/23] Train loss=0.6216256618499756
[10/23] Train loss=0.460766464471817
[15/23] Train loss=0.3963317573070526
[20/23] Train loss=0.3612656891345978
Test set avg_accuracy=87.29% avg_sensitivity=81.15%, avg_specificity=89.14% avg_auc=0.9329
Fold[2] Epoch: 38 [38/100 (38%)] Train loss=0.516238 Test loss=0.323792 Current lr=[0.000967773854438336]

[0/23] Train loss=0.42405688762664795
[5/23] Train loss=0.6164345741271973
[10/23] Train loss=0.44994568824768066
[15/23] Train loss=0.4388956129550934
[20/23] Train loss=0.3860243260860443
Test set avg_accuracy=88.59% avg_sensitivity=79.88%, avg_specificity=91.20% avg_auc=0.9357
Fold[2] Epoch: 39 [39/100 (39%)] Train loss=0.519390 Test loss=0.324464 Current lr=[0.000959379718879479]

[0/23] Train loss=0.4235016107559204
[5/23] Train loss=0.6453297138214111
[10/23] Train loss=0.5216876864433289
[15/23] Train loss=0.41527828574180603
[20/23] Train loss=0.3548697531223297
Test set avg_accuracy=86.36% avg_sensitivity=83.23%, avg_specificity=87.31% avg_auc=0.9330
Fold[2] Epoch: 40 [40/100 (40%)] Train loss=0.513184 Test loss=0.366891 Current lr=[0.0009500604577299936]

[0/23] Train loss=0.42955178022384644
[5/23] Train loss=0.689918041229248
[10/23] Train loss=0.45879337191581726
[15/23] Train loss=0.4177184998989105
[20/23] Train loss=0.3438773453235626
Test set avg_accuracy=87.03% avg_sensitivity=82.37%, avg_specificity=88.43% avg_auc=0.9361
Fold[2] Epoch: 41 [41/100 (41%)] Train loss=0.496262 Test loss=0.350694 Current lr=[0.0009398348387416027]

[0/23] Train loss=0.41496214270591736
[5/23] Train loss=0.5700532793998718
[10/23] Train loss=0.4468388259410858
[15/23] Train loss=0.404494047164917
[20/23] Train loss=0.3475588262081146
Test set avg_accuracy=88.47% avg_sensitivity=78.48%, avg_specificity=91.47% avg_auc=0.9335
Fold[2] Epoch: 42 [42/100 (42%)] Train loss=0.477108 Test loss=0.342128 Current lr=[0.000928723454950097]

[0/23] Train loss=0.4186320900917053
[5/23] Train loss=0.5752034783363342
[10/23] Train loss=0.4178203344345093
[15/23] Train loss=0.3970089256763458
[20/23] Train loss=0.34567344188690186
Test set avg_accuracy=87.78% avg_sensitivity=80.65%, avg_specificity=89.92% avg_auc=0.9346
Fold[2] Epoch: 43 [43/100 (43%)] Train loss=0.459964 Test loss=0.349209 Current lr=[0.0009167486832037001]

[0/23] Train loss=0.39298516511917114
[5/23] Train loss=0.6154837608337402
[10/23] Train loss=0.43788501620292664
[15/23] Train loss=0.3822508752346039
[20/23] Train loss=0.3199297785758972
Test set avg_accuracy=87.48% avg_sensitivity=83.14%, avg_specificity=88.78% avg_auc=0.9383
Fold[2] Epoch: 44 [44/100 (44%)] Train loss=0.457262 Test loss=0.377428 Current lr=[0.0009039346390990754]

[0/23] Train loss=0.3962485194206238
[5/23] Train loss=0.5669317245483398
[10/23] Train loss=0.40400034189224243
[15/23] Train loss=0.3984280228614807
[20/23] Train loss=0.3353848159313202
Test set avg_accuracy=87.57% avg_sensitivity=81.83%, avg_specificity=89.30% avg_auc=0.9347
Fold[2] Epoch: 45 [45/100 (45%)] Train loss=0.442325 Test loss=0.363648 Current lr=[0.000890307128415723]

[0/23] Train loss=0.37725189328193665
[5/23] Train loss=0.5279481410980225
[10/23] Train loss=0.41675713658332825
[15/23] Train loss=0.39752575755119324
[20/23] Train loss=0.3174876868724823
Test set avg_accuracy=87.06% avg_sensitivity=82.32%, avg_specificity=88.49% avg_auc=0.9369
Fold[2] Epoch: 46 [46/100 (46%)] Train loss=0.430797 Test loss=0.356026 Current lr=[0.0008758935951465738]

[0/23] Train loss=0.3828372657299042
[5/23] Train loss=0.5827401876449585
[10/23] Train loss=0.38441893458366394
[15/23] Train loss=0.34062787890434265
[20/23] Train loss=0.3082687556743622
Test set avg_accuracy=85.52% avg_sensitivity=84.76%, avg_specificity=85.75% avg_auc=0.9353
Fold[2] Epoch: 47 [47/100 (47%)] Train loss=0.422208 Test loss=0.412359 Current lr=[0.0008607230662294413]

[0/23] Train loss=0.3797954022884369
[5/23] Train loss=0.5212247967720032
[10/23] Train loss=0.4017177224159241
[15/23] Train loss=0.356423556804657
[20/23] Train loss=0.3299560546875
Test set avg_accuracy=82.62% avg_sensitivity=86.93%, avg_specificity=81.32% avg_auc=0.9273
Fold[2] Epoch: 48 [48/100 (48%)] Train loss=0.422585 Test loss=0.464378 Current lr=[0.0008448260930906307]

[0/23] Train loss=0.3889644742012024
[5/23] Train loss=0.524645209312439
[10/23] Train loss=0.38313642144203186
[15/23] Train loss=0.3445839285850525
[20/23] Train loss=0.280516117811203
Test set avg_accuracy=87.91% avg_sensitivity=82.41%, avg_specificity=89.56% avg_auc=0.9383
Best model saved!! Metric=27.707116808805804!!
Fold[2] Epoch: 49 [49/100 (49%)] Train loss=0.399622 Test loss=0.359878 Current lr=[0.0008282346901184324]

[0/23] Train loss=0.3748687207698822
[5/23] Train loss=0.5364718437194824
[10/23] Train loss=0.39507731795310974
[15/23] Train loss=0.337222158908844
[20/23] Train loss=0.26485154032707214
Test set avg_accuracy=87.42% avg_sensitivity=84.31%, avg_specificity=88.35% avg_auc=0.9343
Fold[2] Epoch: 50 [50/100 (50%)] Train loss=0.396646 Test loss=0.389120 Current lr=[0.000810982270190405]

[0/23] Train loss=0.3541768789291382
[5/23] Train loss=0.44409406185150146
[10/23] Train loss=0.36586281657218933
[15/23] Train loss=0.3219898045063019
[20/23] Train loss=0.2518968880176544
Test set avg_accuracy=87.90% avg_sensitivity=80.38%, avg_specificity=90.15% avg_auc=0.9356
Fold[2] Epoch: 51 [51/100 (51%)] Train loss=0.373839 Test loss=0.359285 Current lr=[0.0007931035773842862]

[0/23] Train loss=0.3269481062889099
[5/23] Train loss=0.43841373920440674
[10/23] Train loss=0.34177687764167786
[15/23] Train loss=0.30118268728256226
[20/23] Train loss=0.27044638991355896
Test set avg_accuracy=87.03% avg_sensitivity=83.09%, avg_specificity=88.21% avg_auc=0.9383
Fold[2] Epoch: 52 [52/100 (52%)] Train loss=0.354099 Test loss=0.381300 Current lr=[0.0007746346170080441]

[0/23] Train loss=0.34187811613082886
[5/23] Train loss=0.4237954616546631
[10/23] Train loss=0.3672724664211273
[15/23] Train loss=0.27595895528793335
[20/23] Train loss=0.2559143900871277
Test set avg_accuracy=88.09% avg_sensitivity=76.72%, avg_specificity=91.50% avg_auc=0.9336
Fold[2] Epoch: 53 [53/100 (53%)] Train loss=0.339260 Test loss=0.363478 Current lr=[0.0007556125830899786]

[0/23] Train loss=0.3225710391998291
[5/23] Train loss=0.36437129974365234
[10/23] Train loss=0.3248763978481293
[15/23] Train loss=0.30480825901031494
[20/23] Train loss=0.21901914477348328
Test set avg_accuracy=87.60% avg_sensitivity=78.35%, avg_specificity=90.37% avg_auc=0.9293
Fold[2] Epoch: 54 [54/100 (54%)] Train loss=0.323441 Test loss=0.403984 Current lr=[0.0007360757834748981]

[0/23] Train loss=0.3387429714202881
[5/23] Train loss=0.4995158016681671
[10/23] Train loss=0.3452734053134918
[15/23] Train loss=0.28317150473594666
[20/23] Train loss=0.23503418266773224
Test set avg_accuracy=87.69% avg_sensitivity=80.33%, avg_specificity=89.90% avg_auc=0.9354
Fold[2] Epoch: 55 [55/100 (55%)] Train loss=0.362559 Test loss=0.376118 Current lr=[0.000716063562677219]

[0/23] Train loss=0.2699110209941864
[5/23] Train loss=0.41036805510520935
[10/23] Train loss=0.297243595123291
[15/23] Train loss=0.2695043683052063
[20/23] Train loss=0.2118746042251587
Test set avg_accuracy=88.64% avg_sensitivity=79.57%, avg_specificity=91.36% avg_auc=0.9351
Fold[2] Epoch: 56 [56/100 (56%)] Train loss=0.314934 Test loss=0.387616 Current lr=[0.0006956162226463489]

[0/23] Train loss=0.29144343733787537
[5/23] Train loss=0.3672942519187927
[10/23] Train loss=0.30686119198799133
[15/23] Train loss=0.26871833205223083
[20/23] Train loss=0.2255886346101761
Test set avg_accuracy=87.80% avg_sensitivity=73.92%, avg_specificity=91.97% avg_auc=0.9298
Fold[2] Epoch: 57 [57/100 (57%)] Train loss=0.303624 Test loss=0.408975 Current lr=[0.0006747749416039243]

[0/23] Train loss=0.2837059795856476
[5/23] Train loss=0.3596848249435425
[10/23] Train loss=0.3095686435699463
[15/23] Train loss=0.25214073061943054
[20/23] Train loss=0.2494751662015915
Test set avg_accuracy=88.05% avg_sensitivity=79.16%, avg_specificity=90.72% avg_auc=0.9326
Fold[2] Epoch: 58 [58/100 (58%)] Train loss=0.289233 Test loss=0.420377 Current lr=[0.000653581691116352]

[0/23] Train loss=0.2764498293399811
[5/23] Train loss=0.32484230399131775
[10/23] Train loss=0.2825465202331543
[15/23] Train loss=0.25588318705558777
[20/23] Train loss=0.17960841953754425
Test set avg_accuracy=88.33% avg_sensitivity=72.06%, avg_specificity=93.20% avg_auc=0.9289
Fold[2] Epoch: 59 [59/100 (59%)] Train loss=0.266349 Test loss=0.421780 Current lr=[0.0006320791515696602]

[0/23] Train loss=0.2549709677696228
[5/23] Train loss=0.3116678297519684
[10/23] Train loss=0.2680807113647461
[15/23] Train loss=0.2372594028711319
[20/23] Train loss=0.17290453612804413
Test set avg_accuracy=88.81% avg_sensitivity=68.49%, avg_specificity=94.90% avg_auc=0.9265
Fold[2] Epoch: 60 [60/100 (60%)] Train loss=0.260190 Test loss=0.447549 Current lr=[0.0006103106262168818]

[0/23] Train loss=0.24931354820728302
[5/23] Train loss=0.30027079582214355
[10/23] Train loss=0.27489614486694336
[15/23] Train loss=0.2557951509952545
[20/23] Train loss=0.18067586421966553
Test set avg_accuracy=88.66% avg_sensitivity=72.97%, avg_specificity=93.37% avg_auc=0.9278
Fold[2] Epoch: 61 [61/100 (61%)] Train loss=0.265063 Test loss=0.445058 Current lr=[0.0005883199539710647]

[0/23] Train loss=0.2351093590259552
[5/23] Train loss=0.306425005197525
[10/23] Train loss=0.2616606652736664
[15/23] Train loss=0.22927993535995483
[20/23] Train loss=0.18544332683086395
Test set avg_accuracy=88.88% avg_sensitivity=75.09%, avg_specificity=93.02% avg_auc=0.9320
Fold[2] Epoch: 62 [62/100 (62%)] Train loss=0.246654 Test loss=0.424575 Current lr=[0.0005661514211195354]

[0/23] Train loss=0.23246289789676666
[5/23] Train loss=0.28356191515922546
[10/23] Train loss=0.2683921158313751
[15/23] Train loss=0.21785151958465576
[20/23] Train loss=0.18909551203250885
Test set avg_accuracy=89.38% avg_sensitivity=74.82%, avg_specificity=93.75% avg_auc=0.9304
Fold[2] Epoch: 63 [63/100 (63%)] Train loss=0.236206 Test loss=0.423935 Current lr=[0.00054384967213721]

[0/23] Train loss=0.2253340631723404
[5/23] Train loss=0.26790595054626465
[10/23] Train loss=0.2602044641971588
[15/23] Train loss=0.25324180722236633
[20/23] Train loss=0.18110336363315582
Test set avg_accuracy=88.77% avg_sensitivity=72.20%, avg_specificity=93.75% avg_auc=0.9260
Fold[2] Epoch: 64 [64/100 (64%)] Train loss=0.236307 Test loss=0.418713 Current lr=[0.000521459619778564]

[0/23] Train loss=0.22066235542297363
[5/23] Train loss=0.25456520915031433
[10/23] Train loss=0.2544204890727997
[15/23] Train loss=0.23151655495166779
[20/23] Train loss=0.16469800472259521
Test set avg_accuracy=88.05% avg_sensitivity=71.47%, avg_specificity=93.03% avg_auc=0.9276
Fold[2] Epoch: 65 [65/100 (65%)] Train loss=0.222045 Test loss=0.427985 Current lr=[0.0004990263546293204]

[0/23] Train loss=0.20320574939250946
[5/23] Train loss=0.26370033621788025
[10/23] Train loss=0.23192644119262695
[15/23] Train loss=0.2329096645116806
[20/23] Train loss=0.15651284158229828
Test set avg_accuracy=88.90% avg_sensitivity=73.06%, avg_specificity=93.65% avg_auc=0.9289
Fold[2] Epoch: 66 [66/100 (66%)] Train loss=0.202603 Test loss=0.427297 Current lr=[0.000476595054300012]

[0/23] Train loss=0.2064812332391739
[5/23] Train loss=0.2174384593963623
[10/23] Train loss=0.21446989476680756
[15/23] Train loss=0.1911163479089737
[20/23] Train loss=0.13960355520248413
Test set avg_accuracy=88.77% avg_sensitivity=74.68%, avg_specificity=93.00% avg_auc=0.9297
Fold[2] Epoch: 67 [67/100 (67%)] Train loss=0.191054 Test loss=0.433341 Current lr=[0.0004542108924442853]

[0/23] Train loss=0.17544607818126678
[5/23] Train loss=0.21045731008052826
[10/23] Train loss=0.19802196323871613
[15/23] Train loss=0.1774781197309494
[20/23] Train loss=0.14893794059753418
Test set avg_accuracy=88.62% avg_sensitivity=74.32%, avg_specificity=92.91% avg_auc=0.9302
Fold[2] Epoch: 68 [68/100 (68%)] Train loss=0.177841 Test loss=0.418691 Current lr=[0.000431918947785175]

[0/23] Train loss=0.1733357459306717
[5/23] Train loss=0.2351662516593933
[10/23] Train loss=0.17926155030727386
[15/23] Train loss=0.17933401465415955
[20/23] Train loss=0.12537559866905212
Test set avg_accuracy=88.62% avg_sensitivity=75.41%, avg_specificity=92.58% avg_auc=0.9325
Fold[2] Epoch: 69 [69/100 (69%)] Train loss=0.170376 Test loss=0.431687 Current lr=[0.0004097641133325535]

[0/23] Train loss=0.16684241592884064
[5/23] Train loss=0.20749275386333466
[10/23] Train loss=0.16246849298477173
[15/23] Train loss=0.1667344719171524
[20/23] Train loss=0.11007718741893768
Test set avg_accuracy=88.74% avg_sensitivity=73.01%, avg_specificity=93.46% avg_auc=0.9268
Fold[2] Epoch: 70 [70/100 (70%)] Train loss=0.162180 Test loss=0.478007 Current lr=[0.00038779100597458526]

[0/23] Train loss=0.1465427726507187
[5/23] Train loss=0.1792457103729248
[10/23] Train loss=0.14805427193641663
[15/23] Train loss=0.16834905743598938
[20/23] Train loss=0.12113109230995178
Test set avg_accuracy=88.95% avg_sensitivity=75.63%, avg_specificity=92.95% avg_auc=0.9297
Fold[2] Epoch: 71 [71/100 (71%)] Train loss=0.152154 Test loss=0.481428 Current lr=[0.0003660438766252499]

[0/23] Train loss=0.1526070088148117
[5/23] Train loss=0.19912628829479218
[10/23] Train loss=0.1599913388490677
[15/23] Train loss=0.153330460190773
[20/23] Train loss=0.1299908459186554
Test set avg_accuracy=88.12% avg_sensitivity=79.02%, avg_specificity=90.84% avg_auc=0.9299
Fold[2] Epoch: 72 [72/100 (72%)] Train loss=0.151196 Test loss=0.483835 Current lr=[0.0003445665211088922]

[0/23] Train loss=0.15237119793891907
[5/23] Train loss=0.1752399355173111
[10/23] Train loss=0.16537658870220184
[15/23] Train loss=0.16800877451896667
[20/23] Train loss=0.12932465970516205
Test set avg_accuracy=88.29% avg_sensitivity=79.57%, avg_specificity=90.91% avg_auc=0.9316
Fold[2] Epoch: 73 [73/100 (73%)] Train loss=0.147101 Test loss=0.493109 Current lr=[0.00032340219196125877]

[0/23] Train loss=0.1411667764186859
[5/23] Train loss=0.1484421342611313
[10/23] Train loss=0.17637580633163452
[15/23] Train loss=0.14831195771694183
[20/23] Train loss=0.1222870945930481
Test set avg_accuracy=88.63% avg_sensitivity=77.58%, avg_specificity=91.94% avg_auc=0.9321
Fold[2] Epoch: 74 [74/100 (74%)] Train loss=0.139792 Test loss=0.484156 Current lr=[0.0003025935113246488]

[0/23] Train loss=0.1503666639328003
[5/23] Train loss=0.1475902497768402
[10/23] Train loss=0.1577141135931015
[15/23] Train loss=0.13219156861305237
[20/23] Train loss=0.10302398353815079
Test set avg_accuracy=88.18% avg_sensitivity=77.08%, avg_specificity=91.51% avg_auc=0.9314
Fold[2] Epoch: 75 [75/100 (75%)] Train loss=0.126298 Test loss=0.491999 Current lr=[0.0002821823851125901]

[0/23] Train loss=0.11332565546035767
[5/23] Train loss=0.14329546689987183
[10/23] Train loss=0.14563046395778656
[15/23] Train loss=0.13139796257019043
[20/23] Train loss=0.09205556660890579
Test set avg_accuracy=88.66% avg_sensitivity=74.68%, avg_specificity=92.85% avg_auc=0.9304
Fold[2] Epoch: 76 [76/100 (76%)] Train loss=0.117285 Test loss=0.503970 Current lr=[0.00026220991861690765]

[0/23] Train loss=0.1078515574336052
[5/23] Train loss=0.1239483505487442
[10/23] Train loss=0.1473504602909088
[15/23] Train loss=0.12172804027795792
[20/23] Train loss=0.08948145806789398
Test set avg_accuracy=88.71% avg_sensitivity=73.92%, avg_specificity=93.15% avg_auc=0.9300
Fold[2] Epoch: 77 [77/100 (77%)] Train loss=0.108635 Test loss=0.511899 Current lr=[0.00024271633372713536]

[0/23] Train loss=0.10817653685808182
[5/23] Train loss=0.13119187951087952
[10/23] Train loss=0.11373743414878845
[15/23] Train loss=0.11896844208240509
[20/23] Train loss=0.08719242364168167
Test set avg_accuracy=88.75% avg_sensitivity=74.95%, avg_specificity=92.89% avg_auc=0.9307
Fold[2] Epoch: 78 [78/100 (78%)] Train loss=0.105697 Test loss=0.512686 Current lr=[0.00022374088792898362]

[0/23] Train loss=0.09983562678098679
[5/23] Train loss=0.1208755224943161
[10/23] Train loss=0.10717196762561798
[15/23] Train loss=0.11199013143777847
[20/23] Train loss=0.08386045694351196
Test set avg_accuracy=88.87% avg_sensitivity=76.49%, avg_specificity=92.58% avg_auc=0.9319
Fold[2] Epoch: 79 [79/100 (79%)] Train loss=0.098853 Test loss=0.538433 Current lr=[0.00020532179524498774]

[0/23] Train loss=0.09459221363067627
[5/23] Train loss=0.11584548652172089
[10/23] Train loss=0.10559771209955215
[15/23] Train loss=0.10091367363929749
[20/23] Train loss=0.07340392470359802
Test set avg_accuracy=88.49% avg_sensitivity=75.59%, avg_specificity=92.36% avg_auc=0.9304
Fold[2] Epoch: 80 [80/100 (80%)] Train loss=0.094464 Test loss=0.542658 Current lr=[0.000187496149276552]

[0/23] Train loss=0.09999728202819824
[5/23] Train loss=0.10594331473112106
[10/23] Train loss=0.09632226824760437
[15/23] Train loss=0.10232456773519516
[20/23] Train loss=0.07172033935785294
Test set avg_accuracy=89.13% avg_sensitivity=75.54%, avg_specificity=93.20% avg_auc=0.9307
Fold[2] Epoch: 81 [81/100 (81%)] Train loss=0.090245 Test loss=0.553436 Current lr=[0.00017029984850237305]

[0/23] Train loss=0.0869225338101387
[5/23] Train loss=0.12271690368652344
[10/23] Train loss=0.0978303849697113
[15/23] Train loss=0.1048671081662178
[20/23] Train loss=0.07035396248102188
Test set avg_accuracy=89.14% avg_sensitivity=77.31%, avg_specificity=92.69% avg_auc=0.9321
Fold[2] Epoch: 82 [82/100 (82%)] Train loss=0.090561 Test loss=0.546566 Current lr=[0.00015376752398368106]

[0/23] Train loss=0.0877523273229599
[5/23] Train loss=0.09946531057357788
[10/23] Train loss=0.0918961763381958
[15/23] Train loss=0.1008172407746315
[20/23] Train loss=0.07343441247940063
Test set avg_accuracy=89.31% avg_sensitivity=75.09%, avg_specificity=93.57% avg_auc=0.9316
Fold[2] Epoch: 83 [83/100 (83%)] Train loss=0.089032 Test loss=0.552852 Current lr=[0.00013793246962189157]

[0/23] Train loss=0.097557932138443
[5/23] Train loss=0.10178866982460022
[10/23] Train loss=0.083671435713768
[15/23] Train loss=0.08716107904911041
[20/23] Train loss=0.08137384802103043
Test set avg_accuracy=88.97% avg_sensitivity=75.50%, avg_specificity=93.02% avg_auc=0.9303
Fold[2] Epoch: 84 [84/100 (84%)] Train loss=0.083646 Test loss=0.570664 Current lr=[0.00012282657510911843]

[0/23] Train loss=0.08351455628871918
[5/23] Train loss=0.0820850357413292
[10/23] Train loss=0.09188748896121979
[15/23] Train loss=0.09699025750160217
[20/23] Train loss=0.06126834452152252
Test set avg_accuracy=89.14% avg_sensitivity=74.77%, avg_specificity=93.45% avg_auc=0.9299
Fold[2] Epoch: 85 [85/100 (85%)] Train loss=0.080840 Test loss=0.579740 Current lr=[0.0001084802617065783]

[0/23] Train loss=0.07573385536670685
[5/23] Train loss=0.08016352355480194
[10/23] Train loss=0.08292049169540405
[15/23] Train loss=0.09147807955741882
[20/23] Train loss=0.06819573789834976
Test set avg_accuracy=89.16% avg_sensitivity=74.73%, avg_specificity=93.49% avg_auc=0.9300
Fold[2] Epoch: 86 [86/100 (86%)] Train loss=0.078370 Test loss=0.587607 Current lr=[9.492242098021878e-05]

[0/23] Train loss=0.07930156588554382
[5/23] Train loss=0.0963837131857872
[10/23] Train loss=0.10049403458833694
[15/23] Train loss=0.09842153638601303
[20/23] Train loss=0.060048311948776245
Test set avg_accuracy=89.05% avg_sensitivity=76.13%, avg_specificity=92.92% avg_auc=0.9302
Fold[2] Epoch: 87 [87/100 (87%)] Train loss=0.077258 Test loss=0.589910 Current lr=[8.218035661694964e-05]

[0/23] Train loss=0.07426713407039642
[5/23] Train loss=0.10080087929964066
[10/23] Train loss=0.0841258242726326
[15/23] Train loss=0.09436950832605362
[20/23] Train loss=0.06343989074230194
Test set avg_accuracy=89.02% avg_sensitivity=76.04%, avg_specificity=92.92% avg_auc=0.9299
Fold[2] Epoch: 88 [88/100 (88%)] Train loss=0.074353 Test loss=0.584129 Current lr=[7.02797294386511e-05]

[0/23] Train loss=0.07756702601909637
[5/23] Train loss=0.09485579282045364
[10/23] Train loss=0.08327416330575943
[15/23] Train loss=0.09422600269317627
[20/23] Train loss=0.06460829079151154
Test set avg_accuracy=89.33% avg_sensitivity=76.04%, avg_specificity=93.31% avg_auc=0.9305
Fold[2] Epoch: 89 [89/100 (89%)] Train loss=0.074245 Test loss=0.584278 Current lr=[5.924450572469346e-05]

[0/23] Train loss=0.07447157055139542
[5/23] Train loss=0.08065919578075409
[10/23] Train loss=0.08527766168117523
[15/23] Train loss=0.09229965507984161
[20/23] Train loss=0.065274178981781
Test set avg_accuracy=89.38% avg_sensitivity=76.27%, avg_specificity=93.31% avg_auc=0.9307
Fold[2] Epoch: 90 [90/100 (90%)] Train loss=0.071790 Test loss=0.576926 Current lr=[4.90969089470401e-05]

[0/23] Train loss=0.08286504447460175
[5/23] Train loss=0.08404594659805298
[10/23] Train loss=0.07834510505199432
[15/23] Train loss=0.10521245747804642
[20/23] Train loss=0.06057657301425934
Test set avg_accuracy=89.10% avg_sensitivity=76.04%, avg_specificity=93.02% avg_auc=0.9308
Fold[2] Epoch: 91 [91/100 (91%)] Train loss=0.072167 Test loss=0.579556 Current lr=[3.985737501513232e-05]

[0/23] Train loss=0.0734599381685257
[5/23] Train loss=0.08262452483177185
[10/23] Train loss=0.09542805701494217
[15/23] Train loss=0.07467152178287506
[20/23] Train loss=0.06623619049787521
Test set avg_accuracy=89.24% avg_sensitivity=76.40%, avg_specificity=93.10% avg_auc=0.9311
Fold[2] Epoch: 92 [92/100 (92%)] Train loss=0.071648 Test loss=0.587749 Current lr=[3.154451112068745e-05]

[0/23] Train loss=0.06869480758905411
[5/23] Train loss=0.09207206219434738
[10/23] Train loss=0.08320016413927078
[15/23] Train loss=0.0840192437171936
[20/23] Train loss=0.06850426644086838
Test set avg_accuracy=89.38% avg_sensitivity=75.90%, avg_specificity=93.42% avg_auc=0.9311
Fold[2] Epoch: 93 [93/100 (93%)] Train loss=0.070342 Test loss=0.588301 Current lr=[2.4175058265291265e-05]

[0/23] Train loss=0.07367759197950363
[5/23] Train loss=0.09274569153785706
[10/23] Train loss=0.0884471908211708
[15/23] Train loss=0.08639485388994217
[20/23] Train loss=0.051979850977659225
Test set avg_accuracy=89.48% avg_sensitivity=75.63%, avg_specificity=93.64% avg_auc=0.9311
Fold[2] Epoch: 94 [94/100 (94%)] Train loss=0.070889 Test loss=0.596732 Current lr=[1.7763857546248248e-05]

[0/23] Train loss=0.07280709594488144
[5/23] Train loss=0.08251498639583588
[10/23] Train loss=0.08767510205507278
[15/23] Train loss=0.07074156403541565
[20/23] Train loss=0.05818711221218109
Test set avg_accuracy=89.53% avg_sensitivity=75.68%, avg_specificity=93.68% avg_auc=0.9311
Fold[2] Epoch: 95 [95/100 (95%)] Train loss=0.068369 Test loss=0.597020 Current lr=[1.2323820268587161e-05]

[0/23] Train loss=0.0701000913977623
[5/23] Train loss=0.07991652190685272
[10/23] Train loss=0.07325084507465363
[15/23] Train loss=0.07423441112041473
[20/23] Train loss=0.05309387296438217
Test set avg_accuracy=89.46% avg_sensitivity=75.68%, avg_specificity=93.60% avg_auc=0.9309
Fold[2] Epoch: 96 [96/100 (96%)] Train loss=0.067221 Test loss=0.598539 Current lr=[7.865901943410707e-06]

[0/23] Train loss=0.06951402127742767
[5/23] Train loss=0.09432177245616913
[10/23] Train loss=0.08021421730518341
[15/23] Train loss=0.08190695941448212
[20/23] Train loss=0.06544094532728195
Test set avg_accuracy=89.44% avg_sensitivity=75.72%, avg_specificity=93.56% avg_auc=0.9308
Fold[2] Epoch: 97 [97/100 (97%)] Train loss=0.068561 Test loss=0.599039 Current lr=[4.399080224954306e-06]

[0/23] Train loss=0.0781378224492073
[5/23] Train loss=0.10643452405929565
[10/23] Train loss=0.07894223183393478
[15/23] Train loss=0.08287755399942398
[20/23] Train loss=0.05583848059177399
Test set avg_accuracy=89.45% avg_sensitivity=75.68%, avg_specificity=93.58% avg_auc=0.9309
Fold[2] Epoch: 98 [98/100 (98%)] Train loss=0.070019 Test loss=0.599399 Current lr=[1.930336830785271e-06]

[0/23] Train loss=0.0719733014702797
[5/23] Train loss=0.07660525292158127
[10/23] Train loss=0.07396762818098068
[15/23] Train loss=0.0883839800953865
[20/23] Train loss=0.06334090232849121
Test set avg_accuracy=89.46% avg_sensitivity=75.81%, avg_specificity=93.56% avg_auc=0.9309
Fold[2] Epoch: 99 [99/100 (99%)] Train loss=0.067795 Test loss=0.599249 Current lr=[4.6464348155246055e-07]

[0/23] Train loss=0.06790606677532196
[5/23] Train loss=0.08483362197875977
[10/23] Train loss=0.09290522336959839
[15/23] Train loss=0.09069627523422241
[20/23] Train loss=0.04543647915124893
Test set avg_accuracy=89.40% avg_sensitivity=75.54%, avg_specificity=93.56% avg_auc=0.9308
Fold[2] Epoch: 100 [100/100 (100%)] Train loss=0.068893 Test loss=0.599437 Current lr=[4.951888602991508e-09]

Fold[2] Best Result: acc=87.90818988002087 sen=82.41410488245931, spe=89.5564898955649, auc=0.9382833215076073!
[0/23] Train loss=1.394556999206543
[5/23] Train loss=1.4566640853881836
[10/23] Train loss=1.233022928237915
[15/23] Train loss=1.1609879732131958
[20/23] Train loss=1.0151746273040771
Test set avg_accuracy=68.23% avg_sensitivity=4.48%, avg_specificity=97.76% avg_auc=0.6919
Best model saved!! Metric=-86.33967538281757!!
Fold[3] Epoch: 1 [1/100 (1%)] Train loss=1.202079 Test loss=0.824740 Current lr=[4.263712153319496e-05]

[0/23] Train loss=1.0703932046890259
[5/23] Train loss=1.0783628225326538
[10/23] Train loss=0.9047026038169861
[15/23] Train loss=0.9765631556510925
[20/23] Train loss=0.8886024355888367
Test set avg_accuracy=77.36% avg_sensitivity=50.15%, avg_specificity=89.97% avg_auc=0.8314
Best model saved!! Metric=-25.37926885282815!!
Fold[3] Epoch: 2 [2/100 (2%)] Train loss=0.971476 Test loss=0.559701 Current lr=[5.051950942452628e-05]

[0/23] Train loss=0.8459677696228027
[5/23] Train loss=1.0743718147277832
[10/23] Train loss=0.8442490696907043
[15/23] Train loss=0.8147140741348267
[20/23] Train loss=0.7783191800117493
Test set avg_accuracy=79.64% avg_sensitivity=57.78%, avg_specificity=89.77% avg_auc=0.8585
Best model saved!! Metric=-12.964060663176227!!
Fold[3] Epoch: 3 [3/100 (3%)] Train loss=0.873811 Test loss=0.486003 Current lr=[6.356055194548904e-05]

[0/23] Train loss=0.7913859486579895
[5/23] Train loss=1.0578317642211914
[10/23] Train loss=0.7350103259086609
[15/23] Train loss=0.7582663893699646
[20/23] Train loss=0.6792784929275513
Test set avg_accuracy=81.09% avg_sensitivity=63.22%, avg_specificity=89.37% avg_auc=0.8719
Best model saved!! Metric=-5.129016211282071!!
Fold[3] Epoch: 4 [4/100 (4%)] Train loss=0.806010 Test loss=0.457061 Current lr=[8.161695403755248e-05]

[0/23] Train loss=0.7041852474212646
[5/23] Train loss=1.0425678491592407
[10/23] Train loss=0.6874989867210388
[15/23] Train loss=0.7200483083724976
[20/23] Train loss=0.5977799892425537
Test set avg_accuracy=82.01% avg_sensitivity=70.08%, avg_specificity=87.53% avg_auc=0.8918
Best model saved!! Metric=2.7997968316871695!!
Fold[3] Epoch: 5 [5/100 (5%)] Train loss=0.771378 Test loss=0.428334 Current lr=[0.00010449031183917899]

[0/23] Train loss=0.6679239273071289
[5/23] Train loss=1.0469334125518799
[10/23] Train loss=0.6138280630111694
[15/23] Train loss=0.6355417966842651
[20/23] Train loss=0.5564830303192139
Test set avg_accuracy=82.14% avg_sensitivity=68.52%, avg_specificity=88.45% avg_auc=0.8938
Fold[3] Epoch: 6 [6/100 (6%)] Train loss=0.718004 Test loss=0.439709 Current lr=[0.00013192929274872232]

[0/23] Train loss=0.6257923245429993
[5/23] Train loss=0.9738304018974304
[10/23] Train loss=0.6278125643730164
[15/23] Train loss=0.629518449306488
[20/23] Train loss=0.5105496644973755
Test set avg_accuracy=82.44% avg_sensitivity=72.24%, avg_specificity=87.16% avg_auc=0.9010
Best model saved!! Metric=5.928258325757742!!
Fold[3] Epoch: 7 [7/100 (7%)] Train loss=0.709190 Test loss=0.443248 Current lr=[0.00016363239706865967]

[0/23] Train loss=0.5804225206375122
[5/23] Train loss=0.9516717791557312
[10/23] Train loss=0.6018849611282349
[15/23] Train loss=0.6028076410293579
[20/23] Train loss=0.4937329590320587
Test set avg_accuracy=82.35% avg_sensitivity=72.57%, avg_specificity=86.88% avg_auc=0.9012
Fold[3] Epoch: 8 [8/100 (8%)] Train loss=0.681467 Test loss=0.450844 Current lr=[0.00019925127088619402]

[0/23] Train loss=0.539948582649231
[5/23] Train loss=1.002065658569336
[10/23] Train loss=0.5984553098678589
[15/23] Train loss=0.5688650608062744
[20/23] Train loss=0.471696674823761
Test set avg_accuracy=83.14% avg_sensitivity=73.60%, avg_specificity=87.56% avg_auc=0.9026
Best model saved!! Metric=8.555581310641422!!
Fold[3] Epoch: 9 [9/100 (9%)] Train loss=0.670457 Test loss=0.456631 Current lr=[0.00023839453378827395]

[0/23] Train loss=0.5408980250358582
[5/23] Train loss=0.9903146028518677
[10/23] Train loss=0.5928152203559875
[15/23] Train loss=0.5558351874351501
[20/23] Train loss=0.4624762535095215
Test set avg_accuracy=83.18% avg_sensitivity=69.32%, avg_specificity=89.60% avg_auc=0.8977
Fold[3] Epoch: 10 [10/100 (10%)] Train loss=0.656930 Test loss=0.458978 Current lr=[0.00028063207935207196]

[0/23] Train loss=0.5075321197509766
[5/23] Train loss=0.9303959608078003
[10/23] Train loss=0.5749934315681458
[15/23] Train loss=0.5393953919410706
[20/23] Train loss=0.4588252007961273
Test set avg_accuracy=82.80% avg_sensitivity=75.02%, avg_specificity=86.41% avg_auc=0.9066
Best model saved!! Metric=8.894143688626958!!
Fold[3] Epoch: 11 [11/100 (11%)] Train loss=0.644337 Test loss=0.414642 Current lr=[0.0003254998011571065]

[0/23] Train loss=0.49396374821662903
[5/23] Train loss=0.946353554725647
[10/23] Train loss=0.5452167987823486
[15/23] Train loss=0.5379681587219238
[20/23] Train loss=0.46458500623703003
Test set avg_accuracy=83.71% avg_sensitivity=70.35%, avg_specificity=89.89% avg_auc=0.9011
Fold[3] Epoch: 12 [12/100 (12%)] Train loss=0.630997 Test loss=0.433108 Current lr=[0.0003725046923895547]

[0/23] Train loss=0.5299533009529114
[5/23] Train loss=0.8740720152854919
[10/23] Train loss=0.5460760593414307
[15/23] Train loss=0.5401194095611572
[20/23] Train loss=0.4697062075138092
Test set avg_accuracy=83.14% avg_sensitivity=77.21%, avg_specificity=85.88% avg_auc=0.9073
Best model saved!! Metric=10.969390401388402!!
Fold[3] Epoch: 13 [13/100 (13%)] Train loss=0.621919 Test loss=0.399627 Current lr=[0.0004211302630042728]

[0/23] Train loss=0.4910457134246826
[5/23] Train loss=0.9078090190887451
[10/23] Train loss=0.5464077591896057
[15/23] Train loss=0.5071837902069092
[20/23] Train loss=0.4309200644493103
Test set avg_accuracy=83.38% avg_sensitivity=67.60%, avg_specificity=90.69% avg_auc=0.8972
Fold[3] Epoch: 14 [14/100 (14%)] Train loss=0.611139 Test loss=0.446086 Current lr=[0.0004708422149207104]

[0/23] Train loss=0.5240816473960876
[5/23] Train loss=0.8453046083450317
[10/23] Train loss=0.5398507714271545
[15/23] Train loss=0.49038341641426086
[20/23] Train loss=0.43602463603019714
Test set avg_accuracy=83.23% avg_sensitivity=78.97%, avg_specificity=85.21% avg_auc=0.9109
Best model saved!! Metric=12.499531865209182!!
Fold[3] Epoch: 15 [15/100 (15%)] Train loss=0.605480 Test loss=0.392120 Current lr=[0.0005210943128936348]

[0/23] Train loss=0.4923493266105652
[5/23] Train loss=0.8778452277183533
[10/23] Train loss=0.5363409519195557
[15/23] Train loss=0.49106723070144653
[20/23] Train loss=0.45045846700668335
Test set avg_accuracy=83.20% avg_sensitivity=77.71%, avg_specificity=85.75% avg_auc=0.9105
Fold[3] Epoch: 16 [16/100 (16%)] Train loss=0.599811 Test loss=0.387787 Current lr=[0.0005713343865494929]

[0/23] Train loss=0.5127522349357605
[5/23] Train loss=0.9020825028419495
[10/23] Train loss=0.5321884751319885
[15/23] Train loss=0.5119485855102539
[20/23] Train loss=0.4305437505245209
Test set avg_accuracy=83.78% avg_sensitivity=71.11%, avg_specificity=89.65% avg_auc=0.9073
Fold[3] Epoch: 17 [17/100 (17%)] Train loss=0.591105 Test loss=0.384395 Current lr=[0.0006210103976380052]

[0/23] Train loss=0.48818647861480713
[5/23] Train loss=0.8306953310966492
[10/23] Train loss=0.49488845467567444
[15/23] Train loss=0.4848170876502991
[20/23] Train loss=0.4396323263645172
Test set avg_accuracy=84.50% avg_sensitivity=71.11%, avg_specificity=90.71% avg_auc=0.9033
Fold[3] Epoch: 18 [18/100 (18%)] Train loss=0.581928 Test loss=0.406327 Current lr=[0.0006695765058319851]

[0/23] Train loss=0.47553515434265137
[5/23] Train loss=0.8040774464607239
[10/23] Train loss=0.48785296082496643
[15/23] Train loss=0.49406614899635315
[20/23] Train loss=0.4278755187988281
Test set avg_accuracy=83.58% avg_sensitivity=69.65%, avg_specificity=90.03% avg_auc=0.9090
Fold[3] Epoch: 19 [19/100 (19%)] Train loss=0.577706 Test loss=0.408575 Current lr=[0.0007164990664243417]

[0/23] Train loss=0.4582045376300812
[5/23] Train loss=0.8380057215690613
[10/23] Train loss=0.4975431561470032
[15/23] Train loss=0.4928089380264282
[20/23] Train loss=0.4493394196033478
Test set avg_accuracy=84.55% avg_sensitivity=74.06%, avg_specificity=89.40% avg_auc=0.9086
Best model saved!! Metric=12.87337289386731!!
Fold[3] Epoch: 20 [20/100 (20%)] Train loss=0.572547 Test loss=0.411731 Current lr=[0.0007612624940195301]

[0/23] Train loss=0.46684134006500244
[5/23] Train loss=0.8204636573791504
[10/23] Train loss=0.48013535141944885
[15/23] Train loss=0.47413283586502075
[20/23] Train loss=0.40889814496040344
Test set avg_accuracy=83.77% avg_sensitivity=72.64%, avg_specificity=88.92% avg_auc=0.9048
Fold[3] Epoch: 21 [21/100 (21%)] Train loss=0.571267 Test loss=0.415536 Current lr=[0.000803374927789172]

[0/23] Train loss=0.4946182370185852
[5/23] Train loss=0.8337000012397766
[10/23] Train loss=0.46806856989860535
[15/23] Train loss=0.4563804268836975
[20/23] Train loss=0.4292687475681305
Test set avg_accuracy=83.25% avg_sensitivity=79.80%, avg_specificity=84.85% avg_auc=0.9132
Best model saved!! Metric=13.224696575903447!!
Fold[3] Epoch: 22 [22/100 (22%)] Train loss=0.561173 Test loss=0.421158 Current lr=[0.0008423736360419787]

[0/23] Train loss=0.47293829917907715
[5/23] Train loss=0.7993841171264648
[10/23] Train loss=0.46385806798934937
[15/23] Train loss=0.4480915665626526
[20/23] Train loss=0.4225219786167145
Test set avg_accuracy=83.98% avg_sensitivity=78.77%, avg_specificity=86.39% avg_auc=0.9196
Best model saved!! Metric=15.102122305326507!!
Fold[3] Epoch: 23 [23/100 (23%)] Train loss=0.570898 Test loss=0.413163 Current lr=[0.0008778301007225328]

[0/23] Train loss=0.48660942912101746
[5/23] Train loss=0.786300003528595
[10/23] Train loss=0.43927574157714844
[15/23] Train loss=0.43197527527809143
[20/23] Train loss=0.42258763313293457
Test set avg_accuracy=84.34% avg_sensitivity=73.43%, avg_specificity=89.39% avg_auc=0.9139
Fold[3] Epoch: 24 [24/100 (24%)] Train loss=0.573970 Test loss=0.414184 Current lr=[0.0009093547259704173]

[0/23] Train loss=0.46817460656166077
[5/23] Train loss=0.7598299980163574
[10/23] Train loss=0.4845453202724457
[15/23] Train loss=0.44918569922447205
[20/23] Train loss=0.4243253171443939
Test set avg_accuracy=83.85% avg_sensitivity=77.08%, avg_specificity=86.99% avg_auc=0.9164
Fold[3] Epoch: 25 [25/100 (25%)] Train loss=0.567328 Test loss=0.401586 Current lr=[0.0009366011190020192]

[0/23] Train loss=0.4614856541156769
[5/23] Train loss=0.8106379508972168
[10/23] Train loss=0.496519535779953
[15/23] Train loss=0.4682963788509369
[20/23] Train loss=0.4159146249294281
Test set avg_accuracy=83.95% avg_sensitivity=76.42%, avg_specificity=87.43% avg_auc=0.9110
Fold[3] Epoch: 26 [26/100 (26%)] Train loss=0.559698 Test loss=0.401151 Current lr=[0.0009592698962766488]

[0/23] Train loss=0.4395339787006378
[5/23] Train loss=0.7713014483451843
[10/23] Train loss=0.4402781128883362
[15/23] Train loss=0.4430842995643616
[20/23] Train loss=0.4251667261123657
Test set avg_accuracy=83.94% avg_sensitivity=70.75%, avg_specificity=90.05% avg_auc=0.9049
Fold[3] Epoch: 27 [27/100 (27%)] Train loss=0.552569 Test loss=0.412965 Current lr=[0.0009771119731247974]

[0/23] Train loss=0.47204843163490295
[5/23] Train loss=0.7648451924324036
[10/23] Train loss=0.46255093812942505
[15/23] Train loss=0.4365352690219879
[20/23] Train loss=0.40952080488204956
Test set avg_accuracy=83.66% avg_sensitivity=79.54%, avg_specificity=85.58% avg_auc=0.9187
Fold[3] Epoch: 28 [28/100 (28%)] Train loss=0.535093 Test loss=0.409855 Current lr=[0.0009899313006920766]

[0/23] Train loss=0.4596169590950012
[5/23] Train loss=0.7005411982536316
[10/23] Train loss=0.4375070333480835
[15/23] Train loss=0.4774154722690582
[20/23] Train loss=0.41096121072769165
Test set avg_accuracy=84.62% avg_sensitivity=76.25%, avg_specificity=88.49% avg_auc=0.9137
Fold[3] Epoch: 29 [29/100 (29%)] Train loss=0.528924 Test loss=0.393679 Current lr=[0.0009975870201252835]

[0/23] Train loss=0.44358065724372864
[5/23] Train loss=0.7931120991706848
[10/23] Train loss=0.4886434078216553
[15/23] Train loss=0.45166197419166565
[20/23] Train loss=0.3971589207649231
Test set avg_accuracy=83.86% avg_sensitivity=74.10%, avg_specificity=88.39% avg_auc=0.9092
Fold[3] Epoch: 30 [30/100 (30%)] Train loss=0.531964 Test loss=0.383338 Current lr=[0.000999999048111397]

[0/23] Train loss=0.46158474683761597
[5/23] Train loss=0.7088416218757629
[10/23] Train loss=0.44150859117507935
[15/23] Train loss=0.4925232529640198
[20/23] Train loss=0.40507033467292786
Test set avg_accuracy=84.01% avg_sensitivity=79.10%, avg_specificity=86.28% avg_auc=0.9107
Fold[3] Epoch: 31 [31/100 (31%)] Train loss=0.510567 Test loss=0.412346 Current lr=[0.000999451812190372]

[0/23] Train loss=0.44664233922958374
[5/23] Train loss=0.7296133041381836
[10/23] Train loss=0.45360642671585083
[15/23] Train loss=0.4053556025028229
[20/23] Train loss=0.33915895223617554
Test set avg_accuracy=84.15% avg_sensitivity=73.90%, avg_specificity=88.89% avg_auc=0.9103
Fold[3] Epoch: 32 [32/100 (32%)] Train loss=0.501392 Test loss=0.399132 Current lr=[0.0009978987508156897]

[0/23] Train loss=0.4371275305747986
[5/23] Train loss=0.7049404978752136
[10/23] Train loss=0.4337158203125
[15/23] Train loss=0.4228905439376831
[20/23] Train loss=0.3687290847301483
Test set avg_accuracy=84.28% avg_sensitivity=70.32%, avg_specificity=90.75% avg_auc=0.9076
Fold[3] Epoch: 33 [33/100 (33%)] Train loss=0.497101 Test loss=0.419419 Current lr=[0.0009953429916462733]

[0/23] Train loss=0.42881834506988525
[5/23] Train loss=0.6729742288589478
[10/23] Train loss=0.46253257989883423
[15/23] Train loss=0.3896499574184418
[20/23] Train loss=0.34519511461257935
Test set avg_accuracy=84.45% avg_sensitivity=76.12%, avg_specificity=88.31% avg_auc=0.9150
Fold[3] Epoch: 34 [34/100 (34%)] Train loss=0.480327 Test loss=0.382460 Current lr=[0.000991789681640963]

[0/23] Train loss=0.4283572733402252
[5/23] Train loss=0.6606469750404358
[10/23] Train loss=0.4175060987472534
[15/23] Train loss=0.3923592269420624
[20/23] Train loss=0.3417218029499054
Test set avg_accuracy=84.55% avg_sensitivity=66.87%, avg_specificity=92.73% avg_auc=0.9005
Fold[3] Epoch: 35 [35/100 (35%)] Train loss=0.468648 Test loss=0.444670 Current lr=[0.0009872459766932253]

[0/23] Train loss=0.4083191752433777
[5/23] Train loss=0.6101404428482056
[10/23] Train loss=0.4476219415664673
[15/23] Train loss=0.38234204053878784
[20/23] Train loss=0.3436487019062042
Test set avg_accuracy=83.85% avg_sensitivity=71.77%, avg_specificity=89.45% avg_auc=0.9050
Fold[3] Epoch: 36 [36/100 (36%)] Train loss=0.458904 Test loss=0.434992 Current lr=[0.0009817210272201372]

[0/23] Train loss=0.4010254144668579
[5/23] Train loss=0.6845106482505798
[10/23] Train loss=0.42690375447273254
[15/23] Train loss=0.37481001019477844
[20/23] Train loss=0.3429733216762543
Test set avg_accuracy=84.09% avg_sensitivity=73.93%, avg_specificity=88.80% avg_auc=0.9122
Fold[3] Epoch: 37 [37/100 (37%)] Train loss=0.454283 Test loss=0.408642 Current lr=[0.0009752259597346622]

[0/23] Train loss=0.3784506022930145
[5/23] Train loss=0.6443911790847778
[10/23] Train loss=0.4471474885940552
[15/23] Train loss=0.3372132182121277
[20/23] Train loss=0.31282973289489746
Test set avg_accuracy=83.86% avg_sensitivity=68.69%, avg_specificity=90.89% avg_auc=0.9033
Fold[3] Epoch: 38 [38/100 (38%)] Train loss=0.443357 Test loss=0.438019 Current lr=[0.000967773854438336]

[0/23] Train loss=0.38952410221099854
[5/23] Train loss=0.6195011734962463
[10/23] Train loss=0.41776612401008606
[15/23] Train loss=0.3663683235645294
[20/23] Train loss=0.32550889253616333
Test set avg_accuracy=83.83% avg_sensitivity=73.73%, avg_specificity=88.51% avg_auc=0.9026
Fold[3] Epoch: 39 [39/100 (39%)] Train loss=0.427140 Test loss=0.441056 Current lr=[0.000959379718879479]

[0/23] Train loss=0.4381009042263031
[5/23] Train loss=0.5757720470428467
[10/23] Train loss=0.4273868799209595
[15/23] Train loss=0.3593110144138336
[20/23] Train loss=0.3063833713531494
Test set avg_accuracy=83.55% avg_sensitivity=59.90%, avg_specificity=94.50% avg_auc=0.8921
Fold[3] Epoch: 40 [40/100 (40%)] Train loss=0.416759 Test loss=0.513710 Current lr=[0.0009500604577299936]

[0/23] Train loss=0.4117390811443329
[5/23] Train loss=0.5510991811752319
[10/23] Train loss=0.3904308080673218
[15/23] Train loss=0.37497660517692566
[20/23] Train loss=0.30869874358177185
Test set avg_accuracy=84.59% avg_sensitivity=77.08%, avg_specificity=88.06% avg_auc=0.9135
Fold[3] Epoch: 41 [41/100 (41%)] Train loss=0.403509 Test loss=0.420483 Current lr=[0.0009398348387416027]

[0/23] Train loss=0.38987433910369873
[5/23] Train loss=0.5187520384788513
[10/23] Train loss=0.3672212064266205
[15/23] Train loss=0.31324031949043274
[20/23] Train loss=0.29029393196105957
Test set avg_accuracy=84.96% avg_sensitivity=68.23%, avg_specificity=92.70% avg_auc=0.9067
Fold[3] Epoch: 42 [42/100 (42%)] Train loss=0.395680 Test loss=0.457351 Current lr=[0.000928723454950097]

[0/23] Train loss=0.3586257994174957
[5/23] Train loss=0.5319809913635254
[10/23] Train loss=0.39863258600234985
[15/23] Train loss=0.3522985279560089
[20/23] Train loss=0.27522844076156616
Test set avg_accuracy=84.45% avg_sensitivity=68.59%, avg_specificity=91.80% avg_auc=0.9065
Fold[3] Epoch: 43 [43/100 (43%)] Train loss=0.396005 Test loss=0.471335 Current lr=[0.0009167486832037001]

[0/23] Train loss=0.33974841237068176
[5/23] Train loss=0.49015408754348755
[10/23] Train loss=0.3889896869659424
[15/23] Train loss=0.36043721437454224
[20/23] Train loss=0.272343248128891
Test set avg_accuracy=85.48% avg_sensitivity=69.35%, avg_specificity=92.95% avg_auc=0.9050
Fold[3] Epoch: 44 [44/100 (44%)] Train loss=0.380549 Test loss=0.479639 Current lr=[0.0009039346390990754]

[0/23] Train loss=0.3631850779056549
[5/23] Train loss=0.45109567046165466
[10/23] Train loss=0.3591296970844269
[15/23] Train loss=0.306453138589859
[20/23] Train loss=0.2931651175022125
Test set avg_accuracy=85.00% avg_sensitivity=72.11%, avg_specificity=90.97% avg_auc=0.9142
Fold[3] Epoch: 45 [45/100 (45%)] Train loss=0.367363 Test loss=0.451732 Current lr=[0.000890307128415723]

[0/23] Train loss=0.3436291515827179
[5/23] Train loss=0.5103673338890076
[10/23] Train loss=0.39564430713653564
[15/23] Train loss=0.2975430190563202
[20/23] Train loss=0.2720237672328949
Test set avg_accuracy=84.31% avg_sensitivity=74.89%, avg_specificity=88.68% avg_auc=0.9164
Fold[3] Epoch: 46 [46/100 (46%)] Train loss=0.366217 Test loss=0.458653 Current lr=[0.0008758935951465738]

[0/23] Train loss=0.3347128629684448
[5/23] Train loss=0.46445131301879883
[10/23] Train loss=0.38301560282707214
[15/23] Train loss=0.30323177576065063
[20/23] Train loss=0.27565714716911316
Test set avg_accuracy=84.40% avg_sensitivity=75.06%, avg_specificity=88.73% avg_auc=0.9145
Fold[3] Epoch: 47 [47/100 (47%)] Train loss=0.350562 Test loss=0.478974 Current lr=[0.0008607230662294413]

[0/23] Train loss=0.3586123287677765
[5/23] Train loss=0.5063626170158386
[10/23] Train loss=0.32576608657836914
[15/23] Train loss=0.2988634705543518
[20/23] Train loss=0.2575456500053406
Test set avg_accuracy=85.22% avg_sensitivity=77.98%, avg_specificity=88.57% avg_auc=0.9211
Best model saved!! Metric=17.877514107077502!!
Fold[3] Epoch: 48 [48/100 (48%)] Train loss=0.337842 Test loss=0.456868 Current lr=[0.0008448260930906307]

[0/23] Train loss=0.33407673239707947
[5/23] Train loss=0.44932106137275696
[10/23] Train loss=0.3304346203804016
[15/23] Train loss=0.29478150606155396
[20/23] Train loss=0.23276224732398987
Test set avg_accuracy=85.38% avg_sensitivity=76.35%, avg_specificity=89.55% avg_auc=0.9184
Fold[3] Epoch: 49 [49/100 (49%)] Train loss=0.325688 Test loss=0.465855 Current lr=[0.0008282346901184324]

[0/23] Train loss=0.3144656717777252
[5/23] Train loss=0.3788457214832306
[10/23] Train loss=0.36023375391960144
[15/23] Train loss=0.28415998816490173
[20/23] Train loss=0.23368319869041443
Test set avg_accuracy=83.71% avg_sensitivity=82.79%, avg_specificity=84.13% avg_auc=0.9207
Fold[3] Epoch: 50 [50/100 (50%)] Train loss=0.314540 Test loss=0.509889 Current lr=[0.000810982270190405]

[0/23] Train loss=0.3352647125720978
[5/23] Train loss=0.42011505365371704
[10/23] Train loss=0.2827591598033905
[15/23] Train loss=0.274502694606781
[20/23] Train loss=0.23423312604427338
Test set avg_accuracy=84.76% avg_sensitivity=78.94%, avg_specificity=87.45% avg_auc=0.9191
Fold[3] Epoch: 51 [51/100 (51%)] Train loss=0.307524 Test loss=0.457002 Current lr=[0.0007931035773842862]

[0/23] Train loss=0.2718108892440796
[5/23] Train loss=0.33984139561653137
[10/23] Train loss=0.29145464301109314
[15/23] Train loss=0.25522586703300476
[20/23] Train loss=0.2016390711069107
Test set avg_accuracy=84.01% avg_sensitivity=81.33%, avg_specificity=85.25% avg_auc=0.9197
Fold[3] Epoch: 52 [52/100 (52%)] Train loss=0.275925 Test loss=0.500697 Current lr=[0.0007746346170080441]

[0/23] Train loss=0.2748781442642212
[5/23] Train loss=0.34603556990623474
[10/23] Train loss=0.25150975584983826
[15/23] Train loss=0.2901075482368469
[20/23] Train loss=0.24832244217395782
Test set avg_accuracy=84.46% avg_sensitivity=76.48%, avg_specificity=88.16% avg_auc=0.9136
Fold[3] Epoch: 53 [53/100 (53%)] Train loss=0.277111 Test loss=0.522838 Current lr=[0.0007556125830899786]

[0/23] Train loss=0.25946447253227234
[5/23] Train loss=0.3528287410736084
[10/23] Train loss=0.2474270761013031
[15/23] Train loss=0.26405254006385803
[20/23] Train loss=0.2195603996515274
Test set avg_accuracy=85.12% avg_sensitivity=72.57%, avg_specificity=90.94% avg_auc=0.9205
Fold[3] Epoch: 54 [54/100 (54%)] Train loss=0.275610 Test loss=0.477633 Current lr=[0.0007360757834748981]

[0/23] Train loss=0.2397482544183731
[5/23] Train loss=0.2927877902984619
[10/23] Train loss=0.24754741787910461
[15/23] Train loss=0.2516616880893707
[20/23] Train loss=0.1781436949968338
Test set avg_accuracy=85.25% avg_sensitivity=68.13%, avg_specificity=93.18% avg_auc=0.9156
Fold[3] Epoch: 55 [55/100 (55%)] Train loss=0.245757 Test loss=0.514862 Current lr=[0.000716063562677219]

[0/23] Train loss=0.27803975343704224
[5/23] Train loss=0.2736826241016388
[10/23] Train loss=0.20423203706741333
[15/23] Train loss=0.22744490206241608
[20/23] Train loss=0.17661407589912415
Test set avg_accuracy=84.83% avg_sensitivity=70.02%, avg_specificity=91.69% avg_auc=0.9153
Fold[3] Epoch: 56 [56/100 (56%)] Train loss=0.226569 Test loss=0.502632 Current lr=[0.0006956162226463489]

[0/23] Train loss=0.21638016402721405
[5/23] Train loss=0.2743130624294281
[10/23] Train loss=0.20903246104717255
[15/23] Train loss=0.23614640533924103
[20/23] Train loss=0.1667991578578949
Test set avg_accuracy=85.07% avg_sensitivity=75.06%, avg_specificity=89.71% avg_auc=0.9158
Fold[3] Epoch: 57 [57/100 (57%)] Train loss=0.203775 Test loss=0.532300 Current lr=[0.0006747749416039243]

[0/23] Train loss=0.1920226663351059
[5/23] Train loss=0.24460794031620026
[10/23] Train loss=0.20089006423950195
[15/23] Train loss=0.19169960916042328
[20/23] Train loss=0.16667146980762482
Test set avg_accuracy=85.15% avg_sensitivity=73.90%, avg_specificity=90.37% avg_auc=0.9177
Fold[3] Epoch: 58 [58/100 (58%)] Train loss=0.185766 Test loss=0.518747 Current lr=[0.000653581691116352]

[0/23] Train loss=0.18161173164844513
[5/23] Train loss=0.2034078985452652
[10/23] Train loss=0.16544069349765778
[15/23] Train loss=0.21733489632606506
[20/23] Train loss=0.14879606664180756
Test set avg_accuracy=84.88% avg_sensitivity=69.09%, avg_specificity=92.20% avg_auc=0.9123
Fold[3] Epoch: 59 [59/100 (59%)] Train loss=0.171399 Test loss=0.564267 Current lr=[0.0006320791515696602]

[0/23] Train loss=0.19911353290081024
[5/23] Train loss=0.19175848364830017
[10/23] Train loss=0.18206308782100677
[15/23] Train loss=0.1574012190103531
[20/23] Train loss=0.14028984308242798
Test set avg_accuracy=85.05% avg_sensitivity=70.65%, avg_specificity=91.72% avg_auc=0.9105
Fold[3] Epoch: 60 [60/100 (60%)] Train loss=0.163451 Test loss=0.592251 Current lr=[0.0006103106262168818]

[0/23] Train loss=0.1707049161195755
[5/23] Train loss=0.18322843313217163
[10/23] Train loss=0.15033765137195587
[15/23] Train loss=0.1689578890800476
[20/23] Train loss=0.1298692226409912
Test set avg_accuracy=85.06% avg_sensitivity=71.48%, avg_specificity=91.35% avg_auc=0.9123
Fold[3] Epoch: 61 [61/100 (61%)] Train loss=0.149390 Test loss=0.595770 Current lr=[0.0005883199539710647]

[0/23] Train loss=0.15742452442646027
[5/23] Train loss=0.19142727553844452
[10/23] Train loss=0.1297253519296646
[15/23] Train loss=0.15678241848945618
[20/23] Train loss=0.10383561253547668
Test set avg_accuracy=85.01% avg_sensitivity=71.67%, avg_specificity=91.18% avg_auc=0.9135
Fold[3] Epoch: 62 [62/100 (62%)] Train loss=0.139059 Test loss=0.596834 Current lr=[0.0005661514211195354]

[0/23] Train loss=0.15615104138851166
[5/23] Train loss=0.1778862029314041
[10/23] Train loss=0.11870993673801422
[15/23] Train loss=0.16397683322429657
[20/23] Train loss=0.09900446981191635
Test set avg_accuracy=85.22% avg_sensitivity=73.27%, avg_specificity=90.75% avg_auc=0.9161
Fold[3] Epoch: 63 [63/100 (63%)] Train loss=0.129085 Test loss=0.616040 Current lr=[0.00054384967213721]

[0/23] Train loss=0.15193769335746765
[5/23] Train loss=0.1547790765762329
[10/23] Train loss=0.14606961607933044
[15/23] Train loss=0.11276443302631378
[20/23] Train loss=0.12202180922031403
Test set avg_accuracy=85.24% avg_sensitivity=71.31%, avg_specificity=91.69% avg_auc=0.9127
Fold[3] Epoch: 64 [64/100 (64%)] Train loss=0.121994 Test loss=0.698933 Current lr=[0.000521459619778564]

[0/23] Train loss=0.14110711216926575
[5/23] Train loss=0.14438782632350922
[10/23] Train loss=0.13406947255134583
[15/23] Train loss=0.10290653258562088
[20/23] Train loss=0.08921530097723007
Test set avg_accuracy=84.78% avg_sensitivity=70.15%, avg_specificity=91.55% avg_auc=0.9143
Fold[3] Epoch: 65 [65/100 (65%)] Train loss=0.112517 Test loss=0.745811 Current lr=[0.0004990263546293204]

[0/23] Train loss=0.13508129119873047
[5/23] Train loss=0.16200114786624908
[10/23] Train loss=0.10640735179185867
[15/23] Train loss=0.12445063143968582
[20/23] Train loss=0.08998331427574158
Test set avg_accuracy=85.15% avg_sensitivity=72.04%, avg_specificity=91.23% avg_auc=0.9147
Fold[3] Epoch: 66 [66/100 (66%)] Train loss=0.110730 Test loss=0.721613 Current lr=[0.000476595054300012]

[0/23] Train loss=0.10937963426113129
[5/23] Train loss=0.135492205619812
[10/23] Train loss=0.11675748974084854
[15/23] Train loss=0.10584118962287903
[20/23] Train loss=0.07789037376642227
Test set avg_accuracy=84.46% avg_sensitivity=67.69%, avg_specificity=92.23% avg_auc=0.9134
Fold[3] Epoch: 67 [67/100 (67%)] Train loss=0.101488 Test loss=0.748977 Current lr=[0.0004542108924442853]

[0/23] Train loss=0.0966295450925827
[5/23] Train loss=0.13025784492492676
[10/23] Train loss=0.1023084968328476
[15/23] Train loss=0.11127878725528717
[20/23] Train loss=0.07809817045927048
Test set avg_accuracy=84.72% avg_sensitivity=68.92%, avg_specificity=92.04% avg_auc=0.9120
Fold[3] Epoch: 68 [68/100 (68%)] Train loss=0.094906 Test loss=0.743952 Current lr=[0.000431918947785175]

[0/23] Train loss=0.08514178544282913
[5/23] Train loss=0.11373025923967361
[10/23] Train loss=0.0874565914273262
[15/23] Train loss=0.10106497257947922
[20/23] Train loss=0.07041751593351364
Test set avg_accuracy=85.28% avg_sensitivity=69.68%, avg_specificity=92.50% avg_auc=0.9131
Fold[3] Epoch: 69 [69/100 (69%)] Train loss=0.087944 Test loss=0.772879 Current lr=[0.0004097641133325535]

[0/23] Train loss=0.09457168728113174
[5/23] Train loss=0.11663668602705002
[10/23] Train loss=0.0787595734000206
[15/23] Train loss=0.104189433157444
[20/23] Train loss=0.07652413100004196
Test set avg_accuracy=84.69% avg_sensitivity=66.10%, avg_specificity=93.30% avg_auc=0.9090
Fold[3] Epoch: 70 [70/100 (70%)] Train loss=0.084588 Test loss=0.792739 Current lr=[0.00038779100597458526]

[0/23] Train loss=0.07147499918937683
[5/23] Train loss=0.10460083186626434
[10/23] Train loss=0.07612305134534836
[15/23] Train loss=0.08013863116502762
[20/23] Train loss=0.06669111549854279
Test set avg_accuracy=84.94% avg_sensitivity=68.26%, avg_specificity=92.67% avg_auc=0.9124
Fold[3] Epoch: 71 [71/100 (71%)] Train loss=0.075148 Test loss=0.781431 Current lr=[0.0003660438766252499]

[0/23] Train loss=0.07504063099622726
[5/23] Train loss=0.10569621622562408
[10/23] Train loss=0.07964262366294861
[15/23] Train loss=0.08399240672588348
[20/23] Train loss=0.05409778654575348
Test set avg_accuracy=84.84% avg_sensitivity=68.69%, avg_specificity=92.32% avg_auc=0.9134
Fold[3] Epoch: 72 [72/100 (72%)] Train loss=0.071503 Test loss=0.829213 Current lr=[0.0003445665211088922]

[0/23] Train loss=0.07404948025941849
[5/23] Train loss=0.10061708092689514
[10/23] Train loss=0.05608474463224411
[15/23] Train loss=0.07656385749578476
[20/23] Train loss=0.06974782049655914
Test set avg_accuracy=84.78% avg_sensitivity=67.96%, avg_specificity=92.57% avg_auc=0.9134
Fold[3] Epoch: 73 [73/100 (73%)] Train loss=0.065228 Test loss=0.833044 Current lr=[0.00032340219196125877]

[0/23] Train loss=0.06411895900964737
[5/23] Train loss=0.08593060821294785
[10/23] Train loss=0.07036121934652328
[15/23] Train loss=0.07551643997430801
[20/23] Train loss=0.052569739520549774
Test set avg_accuracy=85.00% avg_sensitivity=67.46%, avg_specificity=93.12% avg_auc=0.9117
Fold[3] Epoch: 74 [74/100 (74%)] Train loss=0.062866 Test loss=0.839805 Current lr=[0.0003025935113246488]

[0/23] Train loss=0.06652012467384338
[5/23] Train loss=0.07576242834329605
[10/23] Train loss=0.06880252063274384
[15/23] Train loss=0.07389143854379654
[20/23] Train loss=0.042527586221694946
Test set avg_accuracy=85.10% avg_sensitivity=68.33%, avg_specificity=92.87% avg_auc=0.9146
Fold[3] Epoch: 75 [75/100 (75%)] Train loss=0.058410 Test loss=0.864990 Current lr=[0.0002821823851125901]

[0/23] Train loss=0.05159267038106918
[5/23] Train loss=0.090250663459301
[10/23] Train loss=0.057332843542099
[15/23] Train loss=0.0753389373421669
[20/23] Train loss=0.05517633259296417
Test set avg_accuracy=84.81% avg_sensitivity=66.83%, avg_specificity=93.13% avg_auc=0.9106
Fold[3] Epoch: 76 [76/100 (76%)] Train loss=0.055747 Test loss=0.896015 Current lr=[0.00026220991861690765]

[0/23] Train loss=0.05665602907538414
[5/23] Train loss=0.08030890673398972
[10/23] Train loss=0.05861198157072067
[15/23] Train loss=0.06423236429691315
[20/23] Train loss=0.04189136624336243
Test set avg_accuracy=85.06% avg_sensitivity=69.92%, avg_specificity=92.07% avg_auc=0.9144
Fold[3] Epoch: 77 [77/100 (77%)] Train loss=0.052547 Test loss=0.852571 Current lr=[0.00024271633372713536]

[0/23] Train loss=0.047156237065792084
[5/23] Train loss=0.06733138859272003
[10/23] Train loss=0.05499567836523056
[15/23] Train loss=0.06326781213283539
[20/23] Train loss=0.0402793250977993
Test set avg_accuracy=85.17% avg_sensitivity=68.46%, avg_specificity=92.90% avg_auc=0.9133
Fold[3] Epoch: 78 [78/100 (78%)] Train loss=0.049692 Test loss=0.846853 Current lr=[0.00022374088792898362]

[0/23] Train loss=0.04697928577661514
[5/23] Train loss=0.06590575724840164
[10/23] Train loss=0.04988648369908333
[15/23] Train loss=0.06573718786239624
[20/23] Train loss=0.04870888218283653
Test set avg_accuracy=84.96% avg_sensitivity=69.12%, avg_specificity=92.29% avg_auc=0.9146
Fold[3] Epoch: 79 [79/100 (79%)] Train loss=0.046159 Test loss=0.891874 Current lr=[0.00020532179524498774]

[0/23] Train loss=0.03735332563519478
[5/23] Train loss=0.07141750305891037
[10/23] Train loss=0.04859078675508499
[15/23] Train loss=0.06498538702726364
[20/23] Train loss=0.03465167060494423
Test set avg_accuracy=84.98% avg_sensitivity=67.36%, avg_specificity=93.13% avg_auc=0.9138
Fold[3] Epoch: 80 [80/100 (80%)] Train loss=0.046000 Test loss=0.866373 Current lr=[0.000187496149276552]

[0/23] Train loss=0.05335761606693268
[5/23] Train loss=0.07191433012485504
[10/23] Train loss=0.06131266802549362
[15/23] Train loss=0.07191497832536697
[20/23] Train loss=0.03930070251226425
Test set avg_accuracy=85.06% avg_sensitivity=67.96%, avg_specificity=92.98% avg_auc=0.9140
Fold[3] Epoch: 81 [81/100 (81%)] Train loss=0.044841 Test loss=0.944498 Current lr=[0.00017029984850237305]

[0/23] Train loss=0.04476626589894295
[5/23] Train loss=0.06859052926301956
[10/23] Train loss=0.04433706775307655
[15/23] Train loss=0.05335332825779915
[20/23] Train loss=0.04040619358420372
Test set avg_accuracy=85.00% avg_sensitivity=67.86%, avg_specificity=92.93% avg_auc=0.9140
Fold[3] Epoch: 82 [82/100 (82%)] Train loss=0.042775 Test loss=0.953307 Current lr=[0.00015376752398368106]

[0/23] Train loss=0.04225488752126694
[5/23] Train loss=0.061505332589149475
[10/23] Train loss=0.04870143532752991
[15/23] Train loss=0.04796615242958069
[20/23] Train loss=0.03909194469451904
Test set avg_accuracy=84.85% avg_sensitivity=67.06%, avg_specificity=93.09% avg_auc=0.9142
Fold[3] Epoch: 83 [83/100 (83%)] Train loss=0.041304 Test loss=0.900061 Current lr=[0.00013793246962189157]

[0/23] Train loss=0.04814537987112999
[5/23] Train loss=0.0656050518155098
[10/23] Train loss=0.045736201107501984
[15/23] Train loss=0.05053936317563057
[20/23] Train loss=0.03511642664670944
Test set avg_accuracy=85.14% avg_sensitivity=68.36%, avg_specificity=92.92% avg_auc=0.9144
Fold[3] Epoch: 84 [84/100 (84%)] Train loss=0.038065 Test loss=0.912406 Current lr=[0.00012282657510911843]

[0/23] Train loss=0.03811880573630333
[5/23] Train loss=0.052100230008363724
[10/23] Train loss=0.03952402621507645
[15/23] Train loss=0.04620858281850815
[20/23] Train loss=0.040621716529130936
Test set avg_accuracy=85.07% avg_sensitivity=68.03%, avg_specificity=92.96% avg_auc=0.9144
Fold[3] Epoch: 85 [85/100 (85%)] Train loss=0.037946 Test loss=0.908729 Current lr=[0.0001084802617065783]

[0/23] Train loss=0.043190792202949524
[5/23] Train loss=0.039708513766527176
[10/23] Train loss=0.03139152377843857
[15/23] Train loss=0.050913006067276
[20/23] Train loss=0.030173957347869873
Test set avg_accuracy=85.14% avg_sensitivity=67.56%, avg_specificity=93.29% avg_auc=0.9144
Fold[3] Epoch: 86 [86/100 (86%)] Train loss=0.036300 Test loss=0.915593 Current lr=[9.492242098021878e-05]

[0/23] Train loss=0.03881193697452545
[5/23] Train loss=0.05743546783924103
[10/23] Train loss=0.037621527910232544
[15/23] Train loss=0.04406723380088806
[20/23] Train loss=0.040678925812244415
Test set avg_accuracy=85.10% avg_sensitivity=67.43%, avg_specificity=93.29% avg_auc=0.9143
Fold[3] Epoch: 87 [87/100 (87%)] Train loss=0.035355 Test loss=0.922598 Current lr=[8.218035661694964e-05]

[0/23] Train loss=0.0462995283305645
[5/23] Train loss=0.04825150966644287
[10/23] Train loss=0.04186205193400383
[15/23] Train loss=0.044196803122758865
[20/23] Train loss=0.03843951225280762
Test set avg_accuracy=85.19% avg_sensitivity=68.29%, avg_specificity=93.01% avg_auc=0.9146
Fold[3] Epoch: 88 [88/100 (88%)] Train loss=0.036766 Test loss=0.938870 Current lr=[7.02797294386511e-05]

[0/23] Train loss=0.03457317128777504
[5/23] Train loss=0.05269555747509003
[10/23] Train loss=0.034590836614370346
[15/23] Train loss=0.04835338518023491
[20/23] Train loss=0.031905483454465866
Test set avg_accuracy=84.98% avg_sensitivity=67.33%, avg_specificity=93.15% avg_auc=0.9143
Fold[3] Epoch: 89 [89/100 (89%)] Train loss=0.033954 Test loss=0.919871 Current lr=[5.924450572469346e-05]

[0/23] Train loss=0.041057173162698746
[5/23] Train loss=0.05738387629389763
[10/23] Train loss=0.04019612446427345
[15/23] Train loss=0.04692805930972099
[20/23] Train loss=0.028068332001566887
Test set avg_accuracy=85.10% avg_sensitivity=67.33%, avg_specificity=93.33% avg_auc=0.9143
Fold[3] Epoch: 90 [90/100 (90%)] Train loss=0.033632 Test loss=0.910430 Current lr=[4.90969089470401e-05]

[0/23] Train loss=0.03587551414966583
[5/23] Train loss=0.0566006675362587
[10/23] Train loss=0.04008622467517853
[15/23] Train loss=0.04464277997612953
[20/23] Train loss=0.025450563058257103
Test set avg_accuracy=85.05% avg_sensitivity=67.40%, avg_specificity=93.23% avg_auc=0.9143
Fold[3] Epoch: 91 [91/100 (91%)] Train loss=0.034092 Test loss=0.922018 Current lr=[3.985737501513232e-05]

[0/23] Train loss=0.03600374981760979
[5/23] Train loss=0.04888441041111946
[10/23] Train loss=0.0376460887491703
[15/23] Train loss=0.05292303115129471
[20/23] Train loss=0.023989614099264145
Test set avg_accuracy=85.04% avg_sensitivity=67.46%, avg_specificity=93.18% avg_auc=0.9143
Fold[3] Epoch: 92 [92/100 (92%)] Train loss=0.033974 Test loss=0.941404 Current lr=[3.154451112068745e-05]

[0/23] Train loss=0.03173673897981644
[5/23] Train loss=0.04120422154664993
[10/23] Train loss=0.03852900117635727
[15/23] Train loss=0.061599548906087875
[20/23] Train loss=0.028301015496253967
Test set avg_accuracy=85.14% avg_sensitivity=67.43%, avg_specificity=93.35% avg_auc=0.9142
Fold[3] Epoch: 93 [93/100 (93%)] Train loss=0.034296 Test loss=0.950836 Current lr=[2.4175058265291265e-05]

[0/23] Train loss=0.03763464465737343
[5/23] Train loss=0.047211676836013794
[10/23] Train loss=0.04526715725660324
[15/23] Train loss=0.035375021398067474
[20/23] Train loss=0.02630634792149067
Test set avg_accuracy=85.18% avg_sensitivity=67.46%, avg_specificity=93.38% avg_auc=0.9142
Fold[3] Epoch: 94 [94/100 (94%)] Train loss=0.033759 Test loss=0.943006 Current lr=[1.7763857546248248e-05]

[0/23] Train loss=0.03710804134607315
[5/23] Train loss=0.05309988185763359
[10/23] Train loss=0.0338369645178318
[15/23] Train loss=0.03487135469913483
[20/23] Train loss=0.025739505887031555
Test set avg_accuracy=85.19% avg_sensitivity=67.43%, avg_specificity=93.41% avg_auc=0.9141
Fold[3] Epoch: 95 [95/100 (95%)] Train loss=0.032824 Test loss=0.945026 Current lr=[1.2323820268587161e-05]

[0/23] Train loss=0.03348148614168167
[5/23] Train loss=0.05404161661863327
[10/23] Train loss=0.03377477079629898
[15/23] Train loss=0.03977755457162857
[20/23] Train loss=0.03196520730853081
Test set avg_accuracy=85.00% avg_sensitivity=67.26%, avg_specificity=93.21% avg_auc=0.9141
Fold[3] Epoch: 96 [96/100 (96%)] Train loss=0.033592 Test loss=0.953307 Current lr=[7.865901943410707e-06]

[0/23] Train loss=0.03569667786359787
[5/23] Train loss=0.05042877048254013
[10/23] Train loss=0.02822939306497574
[15/23] Train loss=0.0451638363301754
[20/23] Train loss=0.029912196099758148
Test set avg_accuracy=85.04% avg_sensitivity=67.40%, avg_specificity=93.21% avg_auc=0.9142
Fold[3] Epoch: 97 [97/100 (97%)] Train loss=0.032023 Test loss=0.970749 Current lr=[4.399080224954306e-06]

[0/23] Train loss=0.03403719514608383
[5/23] Train loss=0.04257714003324509
[10/23] Train loss=0.03957685828208923
[15/23] Train loss=0.042937785387039185
[20/23] Train loss=0.030573131516575813
Test set avg_accuracy=85.07% avg_sensitivity=67.50%, avg_specificity=93.21% avg_auc=0.9142
Fold[3] Epoch: 98 [98/100 (98%)] Train loss=0.032602 Test loss=0.962652 Current lr=[1.930336830785271e-06]

[0/23] Train loss=0.030958091840147972
[5/23] Train loss=0.05152484402060509
[10/23] Train loss=0.027954183518886566
[15/23] Train loss=0.047629013657569885
[20/23] Train loss=0.025910023599863052
Test set avg_accuracy=85.03% avg_sensitivity=67.36%, avg_specificity=93.21% avg_auc=0.9141
Fold[3] Epoch: 99 [99/100 (99%)] Train loss=0.031776 Test loss=0.963365 Current lr=[4.6464348155246055e-07]

[0/23] Train loss=0.03079509362578392
[5/23] Train loss=0.0490734837949276
[10/23] Train loss=0.046002548187971115
[15/23] Train loss=0.037144776433706284
[20/23] Train loss=0.025997107848525047
Test set avg_accuracy=85.03% avg_sensitivity=67.36%, avg_specificity=93.21% avg_auc=0.9142
Fold[3] Epoch: 100 [100/100 (100%)] Train loss=0.032893 Test loss=0.970762 Current lr=[4.951888602991508e-09]

Fold[3] Best Result: acc=85.21784776902888 sen=77.97678275290215, spe=88.57142857142857, auc=0.921114550137179!
[0/23] Train loss=1.3962602615356445
[5/23] Train loss=1.4386382102966309
[10/23] Train loss=1.343222975730896
[15/23] Train loss=1.2301820516586304
[20/23] Train loss=1.147783875465393
Test set avg_accuracy=75.36% avg_sensitivity=4.31%, avg_specificity=98.13% avg_auc=0.6665
Best model saved!! Metric=-81.54211003118746!!
Fold[4] Epoch: 1 [1/100 (1%)] Train loss=1.302408 Test loss=0.658767 Current lr=[4.263712153319496e-05]

[0/23] Train loss=1.1152430772781372
[5/23] Train loss=1.1457321643829346
[10/23] Train loss=1.0576690435409546
[15/23] Train loss=0.9527156949043274
[20/23] Train loss=0.8904197216033936
Test set avg_accuracy=77.18% avg_sensitivity=33.51%, avg_specificity=91.18% avg_auc=0.7897
Best model saved!! Metric=-45.15701350686608!!
Fold[4] Epoch: 2 [2/100 (2%)] Train loss=1.066051 Test loss=0.639867 Current lr=[5.051950942452628e-05]

[0/23] Train loss=0.9415291547775269
[5/23] Train loss=0.9564216732978821
[10/23] Train loss=0.849733293056488
[15/23] Train loss=0.8883854746818542
[20/23] Train loss=0.7975707054138184
Test set avg_accuracy=81.12% avg_sensitivity=52.13%, avg_specificity=90.41% avg_auc=0.8364
Best model saved!! Metric=-18.69883464459467!!
Fold[4] Epoch: 3 [3/100 (3%)] Train loss=0.932953 Test loss=0.502461 Current lr=[6.356055194548904e-05]

[0/23] Train loss=0.8208304643630981
[5/23] Train loss=0.9681621789932251
[10/23] Train loss=0.7900948524475098
[15/23] Train loss=0.7724089622497559
[20/23] Train loss=0.6952172517776489
Test set avg_accuracy=83.33% avg_sensitivity=59.29%, avg_specificity=91.03% avg_auc=0.8659
Best model saved!! Metric=-5.756326467227714!!
Fold[4] Epoch: 4 [4/100 (4%)] Train loss=0.868350 Test loss=0.430007 Current lr=[8.161695403755248e-05]

[0/23] Train loss=0.7390678524971008
[5/23] Train loss=0.9693347215652466
[10/23] Train loss=0.7126415371894836
[15/23] Train loss=0.7364647388458252
[20/23] Train loss=0.6129516363143921
Test set avg_accuracy=85.55% avg_sensitivity=69.81%, avg_specificity=90.59% avg_auc=0.9038
Best model saved!! Metric=10.330599160618354!!
Fold[4] Epoch: 5 [5/100 (5%)] Train loss=0.814352 Test loss=0.369285 Current lr=[0.00010449031183917899]

[0/23] Train loss=0.6781139373779297
[5/23] Train loss=0.9548601508140564
[10/23] Train loss=0.683824360370636
[15/23] Train loss=0.6435953974723816
[20/23] Train loss=0.563339114189148
Test set avg_accuracy=85.92% avg_sensitivity=75.20%, avg_specificity=89.36% avg_auc=0.9164
Best model saved!! Metric=16.13108156064324!!
Fold[4] Epoch: 6 [6/100 (6%)] Train loss=0.766726 Test loss=0.359438 Current lr=[0.00013192929274872232]

[0/23] Train loss=0.6204507350921631
[5/23] Train loss=0.922586977481842
[10/23] Train loss=0.6479458808898926
[15/23] Train loss=0.6117322444915771
[20/23] Train loss=0.5039580464363098
Test set avg_accuracy=86.32% avg_sensitivity=74.60%, avg_specificity=90.08% avg_auc=0.9207
Best model saved!! Metric=17.073373578859893!!
Fold[4] Epoch: 7 [7/100 (7%)] Train loss=0.728994 Test loss=0.353178 Current lr=[0.00016363239706865967]

[0/23] Train loss=0.6080992817878723
[5/23] Train loss=0.9283317923545837
[10/23] Train loss=0.6423911452293396
[15/23] Train loss=0.5748873949050903
[20/23] Train loss=0.48318901658058167
Test set avg_accuracy=86.43% avg_sensitivity=76.76%, avg_specificity=89.52% avg_auc=0.9196
Best model saved!! Metric=18.670839291356202!!
Fold[4] Epoch: 8 [8/100 (8%)] Train loss=0.710042 Test loss=0.365300 Current lr=[0.00019925127088619402]

[0/23] Train loss=0.5611248016357422
[5/23] Train loss=0.9712708592414856
[10/23] Train loss=0.6546642184257507
[15/23] Train loss=0.5750730037689209
[20/23] Train loss=0.4438118636608124
Test set avg_accuracy=86.79% avg_sensitivity=74.90%, avg_specificity=90.60% avg_auc=0.9217
Fold[4] Epoch: 9 [9/100 (9%)] Train loss=0.703900 Test loss=0.367560 Current lr=[0.00023839453378827395]

[0/23] Train loss=0.5354858636856079
[5/23] Train loss=0.9735124111175537
[10/23] Train loss=0.6165903210639954
[15/23] Train loss=0.5675182938575745
[20/23] Train loss=0.454928457736969
Test set avg_accuracy=88.16% avg_sensitivity=75.38%, avg_specificity=92.26% avg_auc=0.9201
Best model saved!! Metric=21.81633196458904!!
Fold[4] Epoch: 10 [10/100 (10%)] Train loss=0.687515 Test loss=0.350869 Current lr=[0.00028063207935207196]

[0/23] Train loss=0.5414823889732361
[5/23] Train loss=0.946372389793396
[10/23] Train loss=0.6230867505073547
[15/23] Train loss=0.5680086016654968
[20/23] Train loss=0.4642634093761444
Test set avg_accuracy=88.15% avg_sensitivity=75.08%, avg_specificity=92.34% avg_auc=0.9207
Fold[4] Epoch: 11 [11/100 (11%)] Train loss=0.682157 Test loss=0.344218 Current lr=[0.0003254998011571065]

[0/23] Train loss=0.5366914868354797
[5/23] Train loss=0.9454752206802368
[10/23] Train loss=0.6298527717590332
[15/23] Train loss=0.5822142362594604
[20/23] Train loss=0.45590561628341675
Test set avg_accuracy=86.04% avg_sensitivity=82.23%, avg_specificity=87.26% avg_auc=0.9279
Best model saved!! Metric=22.318387220639494!!
Fold[4] Epoch: 12 [12/100 (12%)] Train loss=0.676054 Test loss=0.375549 Current lr=[0.0003725046923895547]

[0/23] Train loss=0.5143569707870483
[5/23] Train loss=0.9428213238716125
[10/23] Train loss=0.6567108035087585
[15/23] Train loss=0.5539143085479736
[20/23] Train loss=0.4035630226135254
Test set avg_accuracy=88.57% avg_sensitivity=71.45%, avg_specificity=94.06% avg_auc=0.9148
Fold[4] Epoch: 13 [13/100 (13%)] Train loss=0.668241 Test loss=0.350409 Current lr=[0.0004211302630042728]

[0/23] Train loss=0.5179916620254517
[5/23] Train loss=0.8923178315162659
[10/23] Train loss=0.613074541091919
[15/23] Train loss=0.5381468534469604
[20/23] Train loss=0.4497945010662079
Test set avg_accuracy=87.82% avg_sensitivity=76.28%, avg_specificity=91.51% avg_auc=0.9255
Fold[4] Epoch: 14 [14/100 (14%)] Train loss=0.641506 Test loss=0.331481 Current lr=[0.0004708422149207104]

[0/23] Train loss=0.5109828114509583
[5/23] Train loss=0.8760152459144592
[10/23] Train loss=0.5871266722679138
[15/23] Train loss=0.5681253671646118
[20/23] Train loss=0.4382845461368561
Test set avg_accuracy=88.12% avg_sensitivity=70.94%, avg_specificity=93.63% avg_auc=0.9147
Fold[4] Epoch: 15 [15/100 (15%)] Train loss=0.644662 Test loss=0.358928 Current lr=[0.0005210943128936348]

[0/23] Train loss=0.5430905818939209
[5/23] Train loss=0.7790548801422119
[10/23] Train loss=0.5574544072151184
[15/23] Train loss=0.468265563249588
[20/23] Train loss=0.458373099565506
Test set avg_accuracy=88.36% avg_sensitivity=74.08%, avg_specificity=92.94% avg_auc=0.9289
Fold[4] Epoch: 16 [16/100 (16%)] Train loss=0.635789 Test loss=0.302073 Current lr=[0.0005713343865494929]

[0/23] Train loss=0.5045614242553711
[5/23] Train loss=0.8560812473297119
[10/23] Train loss=0.5915570855140686
[15/23] Train loss=0.5060953497886658
[20/23] Train loss=0.4395110011100769
Test set avg_accuracy=88.77% avg_sensitivity=70.03%, avg_specificity=94.78% avg_auc=0.9200
Fold[4] Epoch: 17 [17/100 (17%)] Train loss=0.620141 Test loss=0.317014 Current lr=[0.0006210103976380052]

[0/23] Train loss=0.5019461512565613
[5/23] Train loss=0.7731808423995972
[10/23] Train loss=0.5565708875656128
[15/23] Train loss=0.4933188259601593
[20/23] Train loss=0.4229103624820709
Test set avg_accuracy=88.01% avg_sensitivity=64.12%, avg_specificity=95.66% avg_auc=0.9105
Fold[4] Epoch: 18 [18/100 (18%)] Train loss=0.608576 Test loss=0.345504 Current lr=[0.0006695765058319851]

[0/23] Train loss=0.5035722255706787
[5/23] Train loss=0.8222373127937317
[10/23] Train loss=0.5466540455818176
[15/23] Train loss=0.49506014585494995
[20/23] Train loss=0.4353635013103485
Test set avg_accuracy=88.81% avg_sensitivity=71.41%, avg_specificity=94.39% avg_auc=0.9237
Fold[4] Epoch: 19 [19/100 (19%)] Train loss=0.603830 Test loss=0.327908 Current lr=[0.0007164990664243417]

[0/23] Train loss=0.48827895522117615
[5/23] Train loss=0.784551203250885
[10/23] Train loss=0.5852948427200317
[15/23] Train loss=0.5351490378379822
[20/23] Train loss=0.4035968780517578
Test set avg_accuracy=88.59% avg_sensitivity=75.03%, avg_specificity=92.94% avg_auc=0.9247
Best model saved!! Metric=23.029525446737114!!
Fold[4] Epoch: 20 [20/100 (20%)] Train loss=0.613541 Test loss=0.339575 Current lr=[0.0007612624940195301]

[0/23] Train loss=0.5086689591407776
[5/23] Train loss=0.811265766620636
[10/23] Train loss=0.5150852799415588
[15/23] Train loss=0.5184947848320007
[20/23] Train loss=0.45349907875061035
Test set avg_accuracy=88.17% avg_sensitivity=77.15%, avg_specificity=91.71% avg_auc=0.9276
Best model saved!! Metric=23.78413941251989!!
Fold[4] Epoch: 21 [21/100 (21%)] Train loss=0.603892 Test loss=0.334801 Current lr=[0.000803374927789172]

[0/23] Train loss=0.4912838935852051
[5/23] Train loss=0.8289932608604431
[10/23] Train loss=0.5509440302848816
[15/23] Train loss=0.4847061038017273
[20/23] Train loss=0.4171987473964691
Test set avg_accuracy=89.05% avg_sensitivity=75.46%, avg_specificity=93.41% avg_auc=0.9273
Best model saved!! Metric=24.658284213762705!!
Fold[4] Epoch: 22 [22/100 (22%)] Train loss=0.595910 Test loss=0.318310 Current lr=[0.0008423736360419787]

[0/23] Train loss=0.47239938378334045
[5/23] Train loss=0.7761475443840027
[10/23] Train loss=0.5546402931213379
[15/23] Train loss=0.47343480587005615
[20/23] Train loss=0.4468867778778076
Test set avg_accuracy=85.32% avg_sensitivity=82.28%, avg_specificity=86.29% avg_auc=0.9275
Fold[4] Epoch: 23 [23/100 (23%)] Train loss=0.595205 Test loss=0.369333 Current lr=[0.0008778301007225328]

[0/23] Train loss=0.4948276877403259
[5/23] Train loss=0.7195024490356445
[10/23] Train loss=0.5115460157394409
[15/23] Train loss=0.4573051929473877
[20/23] Train loss=0.42990386486053467
Test set avg_accuracy=88.45% avg_sensitivity=65.37%, avg_specificity=95.84% avg_auc=0.9180
Fold[4] Epoch: 24 [24/100 (24%)] Train loss=0.575182 Test loss=0.348478 Current lr=[0.0009093547259704173]

[0/23] Train loss=0.4693473279476166
[5/23] Train loss=0.7461827993392944
[10/23] Train loss=0.5138905644416809
[15/23] Train loss=0.46075472235679626
[20/23] Train loss=0.430866539478302
Test set avg_accuracy=86.54% avg_sensitivity=79.78%, avg_specificity=88.71% avg_auc=0.9284
Fold[4] Epoch: 25 [25/100 (25%)] Train loss=0.573030 Test loss=0.358843 Current lr=[0.0009366011190020192]

[0/23] Train loss=0.47741052508354187
[5/23] Train loss=0.7460632920265198
[10/23] Train loss=0.5226549506187439
[15/23] Train loss=0.45261359214782715
[20/23] Train loss=0.3810155689716339
Test set avg_accuracy=88.82% avg_sensitivity=75.25%, avg_specificity=93.17% avg_auc=0.9232
Fold[4] Epoch: 26 [26/100 (26%)] Train loss=0.568605 Test loss=0.337187 Current lr=[0.0009592698962766488]

[0/23] Train loss=0.4616869390010834
[5/23] Train loss=0.7192294597625732
[10/23] Train loss=0.5571448802947998
[15/23] Train loss=0.48395219445228577
[20/23] Train loss=0.3996754586696625
Test set avg_accuracy=88.44% avg_sensitivity=71.24%, avg_specificity=93.95% avg_auc=0.9186
Fold[4] Epoch: 27 [27/100 (27%)] Train loss=0.574054 Test loss=0.342782 Current lr=[0.0009771119731247974]

[0/23] Train loss=0.48113298416137695
[5/23] Train loss=0.6848876476287842
[10/23] Train loss=0.4943109452724457
[15/23] Train loss=0.42812174558639526
[20/23] Train loss=0.3848854601383209
Test set avg_accuracy=87.90% avg_sensitivity=77.88%, avg_specificity=91.11% avg_auc=0.9270
Fold[4] Epoch: 28 [28/100 (28%)] Train loss=0.543774 Test loss=0.345185 Current lr=[0.0009899313006920766]

[0/23] Train loss=0.44382789731025696
[5/23] Train loss=0.6665811538696289
[10/23] Train loss=0.48284509778022766
[15/23] Train loss=0.40202489495277405
[20/23] Train loss=0.3729579448699951
Test set avg_accuracy=89.26% avg_sensitivity=70.63%, avg_specificity=95.23% avg_auc=0.9260
Fold[4] Epoch: 29 [29/100 (29%)] Train loss=0.529432 Test loss=0.328212 Current lr=[0.0009975870201252835]

[0/23] Train loss=0.47314876317977905
[5/23] Train loss=0.6988531351089478
[10/23] Train loss=0.4984547197818756
[15/23] Train loss=0.44682636857032776
[20/23] Train loss=0.39259615540504456
Test set avg_accuracy=88.25% avg_sensitivity=79.00%, avg_specificity=91.21% avg_auc=0.9284
Best model saved!! Metric=25.30160925004852!!
Fold[4] Epoch: 30 [30/100 (30%)] Train loss=0.533965 Test loss=0.336355 Current lr=[0.000999999048111397]

[0/23] Train loss=0.4516170620918274
[5/23] Train loss=0.670435905456543
[10/23] Train loss=0.4907200336456299
[15/23] Train loss=0.4539737403392792
[20/23] Train loss=0.39165109395980835
Test set avg_accuracy=88.74% avg_sensitivity=75.59%, avg_specificity=92.95% avg_auc=0.9241
Fold[4] Epoch: 31 [31/100 (31%)] Train loss=0.543872 Test loss=0.360575 Current lr=[0.000999451812190372]

[0/23] Train loss=0.44719114899635315
[5/23] Train loss=0.698883593082428
[10/23] Train loss=0.45804035663604736
[15/23] Train loss=0.4172767400741577
[20/23] Train loss=0.38497158885002136
Test set avg_accuracy=88.99% avg_sensitivity=72.10%, avg_specificity=94.40% avg_auc=0.9234
Fold[4] Epoch: 32 [32/100 (32%)] Train loss=0.519536 Test loss=0.346700 Current lr=[0.0009978987508156897]

[0/23] Train loss=0.4567246437072754
[5/23] Train loss=0.693810760974884
[10/23] Train loss=0.5005654096603394
[15/23] Train loss=0.4412713646888733
[20/23] Train loss=0.3936068117618561
Test set avg_accuracy=88.69% avg_sensitivity=77.19%, avg_specificity=92.37% avg_auc=0.9306
Best model saved!! Metric=25.30384395662377!!
Fold[4] Epoch: 33 [33/100 (33%)] Train loss=0.521923 Test loss=0.325704 Current lr=[0.0009953429916462733]

[0/23] Train loss=0.425158828496933
[5/23] Train loss=0.6398404240608215
[10/23] Train loss=0.543348491191864
[15/23] Train loss=0.39047694206237793
[20/23] Train loss=0.36331450939178467
Test set avg_accuracy=89.31% avg_sensitivity=72.14%, avg_specificity=94.82% avg_auc=0.9217
Fold[4] Epoch: 34 [34/100 (34%)] Train loss=0.519313 Test loss=0.359377 Current lr=[0.000991789681640963]

[0/23] Train loss=0.44844990968704224
[5/23] Train loss=0.6114112734794617
[10/23] Train loss=0.48789459466934204
[15/23] Train loss=0.41810449957847595
[20/23] Train loss=0.3418589234352112
Test set avg_accuracy=88.27% avg_sensitivity=68.05%, avg_specificity=94.75% avg_auc=0.9177
Fold[4] Epoch: 35 [35/100 (35%)] Train loss=0.508172 Test loss=0.386513 Current lr=[0.0009872459766932253]

[0/23] Train loss=0.4266373813152313
[5/23] Train loss=0.6336936354637146
[10/23] Train loss=0.47006332874298096
[15/23] Train loss=0.3968353271484375
[20/23] Train loss=0.40168312191963196
Test set avg_accuracy=88.80% avg_sensitivity=72.70%, avg_specificity=93.96% avg_auc=0.9259
Fold[4] Epoch: 36 [36/100 (36%)] Train loss=0.490213 Test loss=0.354850 Current lr=[0.0009817210272201372]

[0/23] Train loss=0.42587435245513916
[5/23] Train loss=0.6052841544151306
[10/23] Train loss=0.44896093010902405
[15/23] Train loss=0.36860981583595276
[20/23] Train loss=0.3479750454425812
Test set avg_accuracy=88.51% avg_sensitivity=74.08%, avg_specificity=93.13% avg_auc=0.9273
Fold[4] Epoch: 37 [37/100 (37%)] Train loss=0.488551 Test loss=0.347120 Current lr=[0.0009752259597346622]

[0/23] Train loss=0.42244675755500793
[5/23] Train loss=0.6064465641975403
[10/23] Train loss=0.44549477100372314
[15/23] Train loss=0.40982475876808167
[20/23] Train loss=0.3520089089870453
Test set avg_accuracy=88.78% avg_sensitivity=79.34%, avg_specificity=91.80% avg_auc=0.9269
Best model saved!! Metric=26.62350043576052!!
Fold[4] Epoch: 38 [38/100 (38%)] Train loss=0.470650 Test loss=0.377369 Current lr=[0.000967773854438336]

[0/23] Train loss=0.40829896926879883
[5/23] Train loss=0.6012248992919922
[10/23] Train loss=0.5078719258308411
[15/23] Train loss=0.37725478410720825
[20/23] Train loss=0.3092704117298126
Test set avg_accuracy=88.82% avg_sensitivity=77.45%, avg_specificity=92.47% avg_auc=0.9281
Fold[4] Epoch: 39 [39/100 (39%)] Train loss=0.485255 Test loss=0.358660 Current lr=[0.000959379718879479]

[0/23] Train loss=0.3901928663253784
[5/23] Train loss=0.5630168318748474
[10/23] Train loss=0.4747087359428406
[15/23] Train loss=0.4153168201446533
[20/23] Train loss=0.3168368935585022
Test set avg_accuracy=87.78% avg_sensitivity=78.91%, avg_specificity=90.62% avg_auc=0.9284
Fold[4] Epoch: 40 [40/100 (40%)] Train loss=0.471140 Test loss=0.384571 Current lr=[0.0009500604577299936]

[0/23] Train loss=0.37936562299728394
[5/23] Train loss=0.5905195474624634
[10/23] Train loss=0.47145527601242065
[15/23] Train loss=0.4433367848396301
[20/23] Train loss=0.3129037916660309
Test set avg_accuracy=86.45% avg_sensitivity=81.59%, avg_specificity=88.00% avg_auc=0.9313
Fold[4] Epoch: 41 [41/100 (41%)] Train loss=0.463503 Test loss=0.376234 Current lr=[0.0009398348387416027]

[0/23] Train loss=0.4022146463394165
[5/23] Train loss=0.5628599524497986
[10/23] Train loss=0.4696575999259949
[15/23] Train loss=0.3674086928367615
[20/23] Train loss=0.31254321336746216
Test set avg_accuracy=88.53% avg_sensitivity=69.90%, avg_specificity=94.50% avg_auc=0.9263
Fold[4] Epoch: 42 [42/100 (42%)] Train loss=0.450990 Test loss=0.393102 Current lr=[0.000928723454950097]

[0/23] Train loss=0.40859344601631165
[5/23] Train loss=0.5466886758804321
[10/23] Train loss=0.41926145553588867
[15/23] Train loss=0.3564968705177307
[20/23] Train loss=0.3019353151321411
Test set avg_accuracy=87.61% avg_sensitivity=79.04%, avg_specificity=90.35% avg_auc=0.9317
Fold[4] Epoch: 43 [43/100 (43%)] Train loss=0.430809 Test loss=0.383755 Current lr=[0.0009167486832037001]

[0/23] Train loss=0.4058518409729004
[5/23] Train loss=0.5999327301979065
[10/23] Train loss=0.46912744641304016
[15/23] Train loss=0.36456888914108276
[20/23] Train loss=0.32790225744247437
Test set avg_accuracy=85.43% avg_sensitivity=83.40%, avg_specificity=86.08% avg_auc=0.9317
Fold[4] Epoch: 44 [44/100 (44%)] Train loss=0.454350 Test loss=0.393194 Current lr=[0.0009039346390990754]

[0/23] Train loss=0.396940141916275
[5/23] Train loss=0.5412787199020386
[10/23] Train loss=0.4360849857330322
[15/23] Train loss=0.33272385597229004
[20/23] Train loss=0.29755666851997375
Test set avg_accuracy=85.91% avg_sensitivity=83.27%, avg_specificity=86.76% avg_auc=0.9346
Fold[4] Epoch: 45 [45/100 (45%)] Train loss=0.427238 Test loss=0.395710 Current lr=[0.000890307128415723]

[0/23] Train loss=0.37733519077301025
[5/23] Train loss=0.5830956101417542
[10/23] Train loss=0.45807352662086487
[15/23] Train loss=0.34519094228744507
[20/23] Train loss=0.2906930148601532
Test set avg_accuracy=88.27% avg_sensitivity=77.45%, avg_specificity=91.74% avg_auc=0.9288
Fold[4] Epoch: 46 [46/100 (46%)] Train loss=0.424148 Test loss=0.379455 Current lr=[0.0008758935951465738]

[0/23] Train loss=0.36973267793655396
[5/23] Train loss=0.539794385433197
[10/23] Train loss=0.38263341784477234
[15/23] Train loss=0.30765169858932495
[20/23] Train loss=0.28532543778419495
Test set avg_accuracy=88.22% avg_sensitivity=80.12%, avg_specificity=90.81% avg_auc=0.9304
Fold[4] Epoch: 47 [47/100 (47%)] Train loss=0.405519 Test loss=0.384489 Current lr=[0.0008607230662294413]

[0/23] Train loss=0.3847271203994751
[5/23] Train loss=0.449128657579422
[10/23] Train loss=0.3474709987640381
[15/23] Train loss=0.310526043176651
[20/23] Train loss=0.26134341955184937
Test set avg_accuracy=86.14% avg_sensitivity=83.61%, avg_specificity=86.95% avg_auc=0.9342
Fold[4] Epoch: 48 [48/100 (48%)] Train loss=0.393586 Test loss=0.395614 Current lr=[0.0008448260930906307]

[0/23] Train loss=0.3642014265060425
[5/23] Train loss=0.46063247323036194
[10/23] Train loss=0.32984042167663574
[15/23] Train loss=0.2761188745498657
[20/23] Train loss=0.2873462736606598
Test set avg_accuracy=86.68% avg_sensitivity=80.72%, avg_specificity=88.58% avg_auc=0.9306
Fold[4] Epoch: 49 [49/100 (49%)] Train loss=0.388448 Test loss=0.406711 Current lr=[0.0008282346901184324]

[0/23] Train loss=0.363513320684433
[5/23] Train loss=0.4686761796474457
[10/23] Train loss=0.340478777885437
[15/23] Train loss=0.31258639693260193
[20/23] Train loss=0.27672278881073
Test set avg_accuracy=88.33% avg_sensitivity=78.78%, avg_specificity=91.39% avg_auc=0.9352
Fold[4] Epoch: 50 [50/100 (50%)] Train loss=0.370993 Test loss=0.372146 Current lr=[0.000810982270190405]

[0/23] Train loss=0.342242568731308
[5/23] Train loss=0.3777645528316498
[10/23] Train loss=0.3395843505859375
[15/23] Train loss=0.2964840233325958
[20/23] Train loss=0.2552419602870941
Test set avg_accuracy=87.40% avg_sensitivity=78.83%, avg_specificity=90.15% avg_auc=0.9336
Fold[4] Epoch: 51 [51/100 (51%)] Train loss=0.334505 Test loss=0.429509 Current lr=[0.0007931035773842862]

[0/23] Train loss=0.3240784704685211
[5/23] Train loss=0.3715566396713257
[10/23] Train loss=0.2871631681919098
[15/23] Train loss=0.2751220762729645
[20/23] Train loss=0.2363537698984146
Test set avg_accuracy=89.42% avg_sensitivity=75.38%, avg_specificity=93.92% avg_auc=0.9333
Fold[4] Epoch: 52 [52/100 (52%)] Train loss=0.310248 Test loss=0.381106 Current lr=[0.0007746346170080441]

[0/23] Train loss=0.30870145559310913
[5/23] Train loss=0.3432071805000305
[10/23] Train loss=0.2796165645122528
[15/23] Train loss=0.23468205332756042
[20/23] Train loss=0.23986153304576874
Test set avg_accuracy=88.08% avg_sensitivity=77.79%, avg_specificity=91.38% avg_auc=0.9350
Fold[4] Epoch: 53 [53/100 (53%)] Train loss=0.295641 Test loss=0.385560 Current lr=[0.0007556125830899786]

[0/23] Train loss=0.28316253423690796
[5/23] Train loss=0.3201024830341339
[10/23] Train loss=0.3001611530780792
[15/23] Train loss=0.22771720588207245
[20/23] Train loss=0.1877404898405075
Test set avg_accuracy=89.25% avg_sensitivity=74.34%, avg_specificity=94.03% avg_auc=0.9330
Fold[4] Epoch: 54 [54/100 (54%)] Train loss=0.278662 Test loss=0.385734 Current lr=[0.0007360757834748981]

[0/23] Train loss=0.29620057344436646
[5/23] Train loss=0.317841500043869
[10/23] Train loss=0.26419341564178467
[15/23] Train loss=0.2101026326417923
[20/23] Train loss=0.18442469835281372
Test set avg_accuracy=88.52% avg_sensitivity=77.06%, avg_specificity=92.19% avg_auc=0.9337
Fold[4] Epoch: 55 [55/100 (55%)] Train loss=0.266975 Test loss=0.399755 Current lr=[0.000716063562677219]

[0/23] Train loss=0.27055466175079346
[5/23] Train loss=0.3377731740474701
[10/23] Train loss=0.2612076997756958
[15/23] Train loss=0.24080845713615417
[20/23] Train loss=0.1853087991476059
Test set avg_accuracy=88.82% avg_sensitivity=76.41%, avg_specificity=92.80% avg_auc=0.9312
Fold[4] Epoch: 56 [56/100 (56%)] Train loss=0.255491 Test loss=0.424017 Current lr=[0.0006956162226463489]

[0/23] Train loss=0.2808753252029419
[5/23] Train loss=0.3114301860332489
[10/23] Train loss=0.25979867577552795
[15/23] Train loss=0.21045942604541779
[20/23] Train loss=0.17712567746639252
Test set avg_accuracy=89.41% avg_sensitivity=74.43%, avg_specificity=94.21% avg_auc=0.9327
Fold[4] Epoch: 57 [57/100 (57%)] Train loss=0.253493 Test loss=0.441951 Current lr=[0.0006747749416039243]

[0/23] Train loss=0.2357223778963089
[5/23] Train loss=0.2689678370952606
[10/23] Train loss=0.255786657333374
[15/23] Train loss=0.20500712096691132
[20/23] Train loss=0.1834934651851654
Test set avg_accuracy=88.74% avg_sensitivity=73.22%, avg_specificity=93.71% avg_auc=0.9305
Fold[4] Epoch: 58 [58/100 (58%)] Train loss=0.232477 Test loss=0.434817 Current lr=[0.000653581691116352]

[0/23] Train loss=0.2294062227010727
[5/23] Train loss=0.27268943190574646
[10/23] Train loss=0.2376822978258133
[15/23] Train loss=0.2130664736032486
[20/23] Train loss=0.17572642862796783
Test set avg_accuracy=89.37% avg_sensitivity=70.59%, avg_specificity=95.38% avg_auc=0.9296
Fold[4] Epoch: 59 [59/100 (59%)] Train loss=0.218854 Test loss=0.454503 Current lr=[0.0006320791515696602]

[0/23] Train loss=0.215187668800354
[5/23] Train loss=0.2822546362876892
[10/23] Train loss=0.22173021733760834
[15/23] Train loss=0.22293871641159058
[20/23] Train loss=0.16203920543193817
Test set avg_accuracy=88.67% avg_sensitivity=70.16%, avg_specificity=94.60% avg_auc=0.9256
Fold[4] Epoch: 60 [60/100 (60%)] Train loss=0.210397 Test loss=0.480927 Current lr=[0.0006103106262168818]

[0/23] Train loss=0.19570988416671753
[5/23] Train loss=0.2325943261384964
[10/23] Train loss=0.21753215789794922
[15/23] Train loss=0.17431588470935822
[20/23] Train loss=0.1443798840045929
Test set avg_accuracy=88.74% avg_sensitivity=73.95%, avg_specificity=93.48% avg_auc=0.9273
Fold[4] Epoch: 61 [61/100 (61%)] Train loss=0.199619 Test loss=0.525831 Current lr=[0.0005883199539710647]

[0/23] Train loss=0.16277384757995605
[5/23] Train loss=0.22182749211788177
[10/23] Train loss=0.22972652316093445
[15/23] Train loss=0.18085826933383942
[20/23] Train loss=0.13338646292686462
Test set avg_accuracy=88.94% avg_sensitivity=69.73%, avg_specificity=95.09% avg_auc=0.9261
Fold[4] Epoch: 62 [62/100 (62%)] Train loss=0.195095 Test loss=0.512661 Current lr=[0.0005661514211195354]

[0/23] Train loss=0.19895845651626587
[5/23] Train loss=0.21501107513904572
[10/23] Train loss=0.19803790748119354
[15/23] Train loss=0.17907121777534485
[20/23] Train loss=0.14015710353851318
Test set avg_accuracy=89.17% avg_sensitivity=72.10%, avg_specificity=94.64% avg_auc=0.9277
Fold[4] Epoch: 63 [63/100 (63%)] Train loss=0.187830 Test loss=0.452157 Current lr=[0.00054384967213721]

[0/23] Train loss=0.19757741689682007
[5/23] Train loss=0.21117495000362396
[10/23] Train loss=0.1991032361984253
[15/23] Train loss=0.1769571602344513
[20/23] Train loss=0.16258291900157928
Test set avg_accuracy=88.81% avg_sensitivity=73.35%, avg_specificity=93.77% avg_auc=0.9311
Fold[4] Epoch: 64 [64/100 (64%)] Train loss=0.184741 Test loss=0.443188 Current lr=[0.000521459619778564]

[0/23] Train loss=0.19545066356658936
[5/23] Train loss=0.17035748064517975
[10/23] Train loss=0.16681142151355743
[15/23] Train loss=0.1897258311510086
[20/23] Train loss=0.13167241215705872
Test set avg_accuracy=88.84% avg_sensitivity=73.18%, avg_specificity=93.86% avg_auc=0.9288
Fold[4] Epoch: 65 [65/100 (65%)] Train loss=0.175226 Test loss=0.444630 Current lr=[0.0004990263546293204]

[0/23] Train loss=0.1541302353143692
[5/23] Train loss=0.1935720294713974
[10/23] Train loss=0.13835608959197998
[15/23] Train loss=0.15889324247837067
[20/23] Train loss=0.13079513609409332
Test set avg_accuracy=88.87% avg_sensitivity=74.77%, avg_specificity=93.39% avg_auc=0.9260
Fold[4] Epoch: 66 [66/100 (66%)] Train loss=0.162844 Test loss=0.475775 Current lr=[0.000476595054300012]

[0/23] Train loss=0.1473981887102127
[5/23] Train loss=0.1590065211057663
[10/23] Train loss=0.14631114900112152
[15/23] Train loss=0.15021878480911255
[20/23] Train loss=0.12605176866054535
Test set avg_accuracy=88.84% avg_sensitivity=73.48%, avg_specificity=93.77% avg_auc=0.9272
Fold[4] Epoch: 67 [67/100 (67%)] Train loss=0.146071 Test loss=0.514522 Current lr=[0.0004542108924442853]

[0/23] Train loss=0.15663525462150574
[5/23] Train loss=0.17181125283241272
[10/23] Train loss=0.15481069684028625
[15/23] Train loss=0.1444784253835678
[20/23] Train loss=0.12581956386566162
Test set avg_accuracy=88.71% avg_sensitivity=72.70%, avg_specificity=93.84% avg_auc=0.9306
Fold[4] Epoch: 68 [68/100 (68%)] Train loss=0.139978 Test loss=0.512404 Current lr=[0.000431918947785175]

[0/23] Train loss=0.16651710867881775
[5/23] Train loss=0.14545005559921265
[10/23] Train loss=0.12218775600194931
[15/23] Train loss=0.12575079500675201
[20/23] Train loss=0.1164613887667656
Test set avg_accuracy=88.28% avg_sensitivity=75.72%, avg_specificity=92.30% avg_auc=0.9305
Fold[4] Epoch: 69 [69/100 (69%)] Train loss=0.134617 Test loss=0.517482 Current lr=[0.0004097641133325535]

[0/23] Train loss=0.13658447563648224
[5/23] Train loss=0.14833010733127594
[10/23] Train loss=0.1342228204011917
[15/23] Train loss=0.12183359265327454
[20/23] Train loss=0.10578051954507828
Test set avg_accuracy=87.66% avg_sensitivity=77.71%, avg_specificity=90.85% avg_auc=0.9298
Fold[4] Epoch: 70 [70/100 (70%)] Train loss=0.121959 Test loss=0.607821 Current lr=[0.00038779100597458526]

[0/23] Train loss=0.12938079237937927
[5/23] Train loss=0.14364124834537506
[10/23] Train loss=0.11267758905887604
[15/23] Train loss=0.09390908479690552
[20/23] Train loss=0.09233737736940384
Test set avg_accuracy=88.34% avg_sensitivity=76.33%, avg_specificity=92.19% avg_auc=0.9314
Fold[4] Epoch: 71 [71/100 (71%)] Train loss=0.114451 Test loss=0.634373 Current lr=[0.0003660438766252499]

[0/23] Train loss=0.10943596065044403
[5/23] Train loss=0.14212258160114288
[10/23] Train loss=0.1008254662156105
[15/23] Train loss=0.104001984000206
[20/23] Train loss=0.07885394990444183
Test set avg_accuracy=88.63% avg_sensitivity=75.64%, avg_specificity=92.80% avg_auc=0.9322
Fold[4] Epoch: 72 [72/100 (72%)] Train loss=0.105305 Test loss=0.575126 Current lr=[0.0003445665211088922]

[0/23] Train loss=0.11322261393070221
[5/23] Train loss=0.11451131850481033
[10/23] Train loss=0.08688754588365555
[15/23] Train loss=0.08904599398374557
[20/23] Train loss=0.08283253014087677
Test set avg_accuracy=88.48% avg_sensitivity=75.16%, avg_specificity=92.74% avg_auc=0.9319
Fold[4] Epoch: 73 [73/100 (73%)] Train loss=0.093387 Test loss=0.583615 Current lr=[0.00032340219196125877]

[0/23] Train loss=0.0962054431438446
[5/23] Train loss=0.10910987108945847
[10/23] Train loss=0.10137149691581726
[15/23] Train loss=0.0892399400472641
[20/23] Train loss=0.0760653093457222
Test set avg_accuracy=89.01% avg_sensitivity=74.39%, avg_specificity=93.70% avg_auc=0.9323
Fold[4] Epoch: 74 [74/100 (74%)] Train loss=0.088949 Test loss=0.606244 Current lr=[0.0003025935113246488]

[0/23] Train loss=0.09310215711593628
[5/23] Train loss=0.10784484446048737
[10/23] Train loss=0.08564618974924088
[15/23] Train loss=0.08259137719869614
[20/23] Train loss=0.070316843688488
Test set avg_accuracy=89.36% avg_sensitivity=73.26%, avg_specificity=94.51% avg_auc=0.9320
Fold[4] Epoch: 75 [75/100 (75%)] Train loss=0.084823 Test loss=0.602274 Current lr=[0.0002821823851125901]

[0/23] Train loss=0.07229126244783401
[5/23] Train loss=0.08656204491853714
[10/23] Train loss=0.0886707529425621
[15/23] Train loss=0.08041076362133026
[20/23] Train loss=0.06060038506984711
Test set avg_accuracy=89.17% avg_sensitivity=73.26%, avg_specificity=94.26% avg_auc=0.9321
Fold[4] Epoch: 76 [76/100 (76%)] Train loss=0.075830 Test loss=0.619852 Current lr=[0.00026220991861690765]

[0/23] Train loss=0.07702034711837769
[5/23] Train loss=0.08149326592683792
[10/23] Train loss=0.07326056063175201
[15/23] Train loss=0.0837167352437973
[20/23] Train loss=0.05580229312181473
Test set avg_accuracy=89.01% avg_sensitivity=73.91%, avg_specificity=93.85% avg_auc=0.9330
Fold[4] Epoch: 77 [77/100 (77%)] Train loss=0.071194 Test loss=0.624686 Current lr=[0.00024271633372713536]

[0/23] Train loss=0.07340670377016068
[5/23] Train loss=0.08519768714904785
[10/23] Train loss=0.0675206407904625
[15/23] Train loss=0.06445600837469101
[20/23] Train loss=0.05467219278216362
Test set avg_accuracy=89.08% avg_sensitivity=74.86%, avg_specificity=93.64% avg_auc=0.9329
Fold[4] Epoch: 78 [78/100 (78%)] Train loss=0.069136 Test loss=0.642892 Current lr=[0.00022374088792898362]

[0/23] Train loss=0.07765267044305801
[5/23] Train loss=0.0719151720404625
[10/23] Train loss=0.0749535858631134
[15/23] Train loss=0.06870683282613754
[20/23] Train loss=0.051937978714704514
Test set avg_accuracy=89.43% avg_sensitivity=73.39%, avg_specificity=94.57% avg_auc=0.9331
Fold[4] Epoch: 79 [79/100 (79%)] Train loss=0.065622 Test loss=0.660529 Current lr=[0.00020532179524498774]

[0/23] Train loss=0.07480372488498688
[5/23] Train loss=0.07225847244262695
[10/23] Train loss=0.06372953206300735
[15/23] Train loss=0.07513917237520218
[20/23] Train loss=0.04926970973610878
Test set avg_accuracy=88.80% avg_sensitivity=73.91%, avg_specificity=93.57% avg_auc=0.9334
Fold[4] Epoch: 80 [80/100 (80%)] Train loss=0.062524 Test loss=0.663300 Current lr=[0.000187496149276552]

[0/23] Train loss=0.06428414583206177
[5/23] Train loss=0.0772617980837822
[10/23] Train loss=0.05395360663533211
[15/23] Train loss=0.0686604306101799
[20/23] Train loss=0.05386824160814285
Test set avg_accuracy=89.16% avg_sensitivity=73.26%, avg_specificity=94.25% avg_auc=0.9333
Fold[4] Epoch: 81 [81/100 (81%)] Train loss=0.060898 Test loss=0.668270 Current lr=[0.00017029984850237305]

[0/23] Train loss=0.05705403909087181
[5/23] Train loss=0.07937649637460709
[10/23] Train loss=0.0643431544303894
[15/23] Train loss=0.0634230226278305
[20/23] Train loss=0.051251370459795
Test set avg_accuracy=89.02% avg_sensitivity=73.70%, avg_specificity=93.93% avg_auc=0.9329
Fold[4] Epoch: 82 [82/100 (82%)] Train loss=0.058268 Test loss=0.683558 Current lr=[0.00015376752398368106]

[0/23] Train loss=0.05220148712396622
[5/23] Train loss=0.0705549567937851
[10/23] Train loss=0.06598275154829025
[15/23] Train loss=0.05504518747329712
[20/23] Train loss=0.05487443879246712
Test set avg_accuracy=89.21% avg_sensitivity=73.05%, avg_specificity=94.39% avg_auc=0.9322
Fold[4] Epoch: 83 [83/100 (83%)] Train loss=0.057921 Test loss=0.679489 Current lr=[0.00013793246962189157]

[0/23] Train loss=0.058422427624464035
[5/23] Train loss=0.07005927711725235
[10/23] Train loss=0.058477722108364105
[15/23] Train loss=0.04756420478224754
[20/23] Train loss=0.038780540227890015
Test set avg_accuracy=89.12% avg_sensitivity=73.01%, avg_specificity=94.28% avg_auc=0.9324
Fold[4] Epoch: 84 [84/100 (84%)] Train loss=0.054086 Test loss=0.675893 Current lr=[0.00012282657510911843]

[0/23] Train loss=0.052092134952545166
[5/23] Train loss=0.06313596665859222
[10/23] Train loss=0.05280029773712158
[15/23] Train loss=0.06275174021720886
[20/23] Train loss=0.04779573157429695
Test set avg_accuracy=89.25% avg_sensitivity=72.75%, avg_specificity=94.54% avg_auc=0.9324
Fold[4] Epoch: 85 [85/100 (85%)] Train loss=0.052026 Test loss=0.679117 Current lr=[0.0001084802617065783]

[0/23] Train loss=0.05551422759890556
[5/23] Train loss=0.06959938257932663
[10/23] Train loss=0.049866918474435806
[15/23] Train loss=0.050199784338474274
[20/23] Train loss=0.04453164339065552
Test set avg_accuracy=89.21% avg_sensitivity=73.26%, avg_specificity=94.32% avg_auc=0.9325
Fold[4] Epoch: 86 [86/100 (86%)] Train loss=0.051961 Test loss=0.689879 Current lr=[9.492242098021878e-05]

[0/23] Train loss=0.044469255954027176
[5/23] Train loss=0.05612505227327347
[10/23] Train loss=0.061078526079654694
[15/23] Train loss=0.054479341953992844
[20/23] Train loss=0.042712144553661346
Test set avg_accuracy=89.36% avg_sensitivity=73.74%, avg_specificity=94.36% avg_auc=0.9328
Fold[4] Epoch: 87 [87/100 (87%)] Train loss=0.052057 Test loss=0.672321 Current lr=[8.218035661694964e-05]

[0/23] Train loss=0.05007500946521759
[5/23] Train loss=0.06639030575752258
[10/23] Train loss=0.051660437136888504
[15/23] Train loss=0.05043190345168114
[20/23] Train loss=0.04320969805121422
Test set avg_accuracy=89.18% avg_sensitivity=73.35%, avg_specificity=94.25% avg_auc=0.9324
Fold[4] Epoch: 88 [88/100 (88%)] Train loss=0.050807 Test loss=0.703230 Current lr=[7.02797294386511e-05]

[0/23] Train loss=0.05404676869511604
[5/23] Train loss=0.06392378360033035
[10/23] Train loss=0.057322949171066284
[15/23] Train loss=0.04618102312088013
[20/23] Train loss=0.05337858200073242
Test set avg_accuracy=89.35% avg_sensitivity=73.31%, avg_specificity=94.49% avg_auc=0.9319
Fold[4] Epoch: 89 [89/100 (89%)] Train loss=0.051272 Test loss=0.711141 Current lr=[5.924450572469346e-05]

[0/23] Train loss=0.0662742331624031
[5/23] Train loss=0.06269185990095139
[10/23] Train loss=0.05354185774922371
[15/23] Train loss=0.05782812833786011
[20/23] Train loss=0.03915238752961159
Test set avg_accuracy=89.18% avg_sensitivity=73.22%, avg_specificity=94.29% avg_auc=0.9319
Fold[4] Epoch: 90 [90/100 (90%)] Train loss=0.048128 Test loss=0.712048 Current lr=[4.90969089470401e-05]

[0/23] Train loss=0.05816683918237686
[5/23] Train loss=0.05315661057829857
[10/23] Train loss=0.05308729037642479
[15/23] Train loss=0.0538916252553463
[20/23] Train loss=0.0544392466545105
Test set avg_accuracy=89.21% avg_sensitivity=73.44%, avg_specificity=94.26% avg_auc=0.9322
Fold[4] Epoch: 91 [91/100 (91%)] Train loss=0.047635 Test loss=0.714771 Current lr=[3.985737501513232e-05]

[0/23] Train loss=0.050040654838085175
[5/23] Train loss=0.052695274353027344
[10/23] Train loss=0.04583708941936493
[15/23] Train loss=0.045480456203222275
[20/23] Train loss=0.03951486945152283
Test set avg_accuracy=89.22% avg_sensitivity=72.96%, avg_specificity=94.43% avg_auc=0.9324
Fold[4] Epoch: 92 [92/100 (92%)] Train loss=0.046473 Test loss=0.723087 Current lr=[3.154451112068745e-05]

[0/23] Train loss=0.05550265312194824
[5/23] Train loss=0.07014396786689758
[10/23] Train loss=0.04223306477069855
[15/23] Train loss=0.05134065821766853
[20/23] Train loss=0.03610607981681824
Test set avg_accuracy=89.36% avg_sensitivity=73.05%, avg_specificity=94.58% avg_auc=0.9323
Fold[4] Epoch: 93 [93/100 (93%)] Train loss=0.047308 Test loss=0.723382 Current lr=[2.4175058265291265e-05]

[0/23] Train loss=0.053934305906295776
[5/23] Train loss=0.05828015133738518
[10/23] Train loss=0.042926985770463943
[15/23] Train loss=0.05135722458362579
[20/23] Train loss=0.050581637769937515
Test set avg_accuracy=89.34% avg_sensitivity=72.75%, avg_specificity=94.65% avg_auc=0.9322
Fold[4] Epoch: 94 [94/100 (94%)] Train loss=0.044834 Test loss=0.724679 Current lr=[1.7763857546248248e-05]

[0/23] Train loss=0.051477450877428055
[5/23] Train loss=0.0809498131275177
[10/23] Train loss=0.03739157319068909
[15/23] Train loss=0.056894224137067795
[20/23] Train loss=0.043051332235336304
Test set avg_accuracy=89.22% avg_sensitivity=72.53%, avg_specificity=94.57% avg_auc=0.9322
Fold[4] Epoch: 95 [95/100 (95%)] Train loss=0.045843 Test loss=0.725193 Current lr=[1.2323820268587161e-05]

[0/23] Train loss=0.04531416669487953
[5/23] Train loss=0.054679758846759796
[10/23] Train loss=0.05050564557313919
[15/23] Train loss=0.05886613577604294
[20/23] Train loss=0.03891046345233917
Test set avg_accuracy=89.24% avg_sensitivity=72.57%, avg_specificity=94.58% avg_auc=0.9322
Fold[4] Epoch: 96 [96/100 (96%)] Train loss=0.043000 Test loss=0.734918 Current lr=[7.865901943410707e-06]

[0/23] Train loss=0.05668600648641586
[5/23] Train loss=0.0476921945810318
[10/23] Train loss=0.04690805822610855
[15/23] Train loss=0.046170424669981
[20/23] Train loss=0.03964007645845413
Test set avg_accuracy=89.19% avg_sensitivity=72.70%, avg_specificity=94.47% avg_auc=0.9322
Fold[4] Epoch: 97 [97/100 (97%)] Train loss=0.043989 Test loss=0.734999 Current lr=[4.399080224954306e-06]

[0/23] Train loss=0.05190359801054001
[5/23] Train loss=0.05890876427292824
[10/23] Train loss=0.049857042729854584
[15/23] Train loss=0.05054151266813278
[20/23] Train loss=0.035076770931482315
Test set avg_accuracy=89.09% avg_sensitivity=72.79%, avg_specificity=94.32% avg_auc=0.9322
Fold[4] Epoch: 98 [98/100 (98%)] Train loss=0.043580 Test loss=0.734854 Current lr=[1.930336830785271e-06]

[0/23] Train loss=0.045244257897138596
[5/23] Train loss=0.05954265967011452
[10/23] Train loss=0.04189202934503555
[15/23] Train loss=0.05739375948905945
[20/23] Train loss=0.03301011770963669
Test set avg_accuracy=89.12% avg_sensitivity=72.79%, avg_specificity=94.35% avg_auc=0.9322
Fold[4] Epoch: 99 [99/100 (99%)] Train loss=0.046326 Test loss=0.734487 Current lr=[4.6464348155246055e-07]

[0/23] Train loss=0.05058687552809715
[5/23] Train loss=0.062174469232559204
[10/23] Train loss=0.04939817264676094
[15/23] Train loss=0.046467579901218414
[20/23] Train loss=0.03860044479370117
Test set avg_accuracy=89.18% avg_sensitivity=72.70%, avg_specificity=94.46% avg_auc=0.9322
Fold[4] Epoch: 100 [100/100 (100%)] Train loss=0.045344 Test loss=0.734859 Current lr=[4.951888602991508e-09]

Fold[4] Best Result: acc=88.78074306645736 sen=79.34454506252695, spe=91.8048645660586, auc=0.9269334774071761!
[0/23] Train loss=1.3986161947250366
[5/23] Train loss=1.4248723983764648
[10/23] Train loss=1.2988839149475098
[15/23] Train loss=1.1947275400161743
[20/23] Train loss=1.0700520277023315
Test set avg_accuracy=74.43% avg_sensitivity=9.31%, avg_specificity=96.47% avg_auc=0.7880
Best model saved!! Metric=-66.98764693946788!!
Fold[5] Epoch: 1 [1/100 (1%)] Train loss=1.254219 Test loss=0.492511 Current lr=[4.263712153319496e-05]

[0/23] Train loss=1.025872826576233
[5/23] Train loss=1.050108551979065
[10/23] Train loss=0.9972647428512573
[15/23] Train loss=0.9309691190719604
[20/23] Train loss=0.8249221444129944
Test set avg_accuracy=80.16% avg_sensitivity=47.10%, avg_specificity=91.34% avg_auc=0.8385
Best model saved!! Metric=-23.544491138234086!!
Fold[5] Epoch: 2 [2/100 (2%)] Train loss=0.989320 Test loss=0.481798 Current lr=[5.051950942452628e-05]

[0/23] Train loss=0.8541856408119202
[5/23] Train loss=0.9405922293663025
[10/23] Train loss=0.8675035834312439
[15/23] Train loss=0.8223419785499573
[20/23] Train loss=0.7605574727058411
Test set avg_accuracy=82.45% avg_sensitivity=53.44%, avg_specificity=92.27% avg_auc=0.8671
Best model saved!! Metric=-11.138117192082218!!
Fold[5] Epoch: 3 [3/100 (3%)] Train loss=0.901073 Test loss=0.444701 Current lr=[6.356055194548904e-05]

[0/23] Train loss=0.8256495594978333
[5/23] Train loss=0.9420446753501892
[10/23] Train loss=0.820773184299469
[15/23] Train loss=0.7780094742774963
[20/23] Train loss=0.6618572473526001
Test set avg_accuracy=83.96% avg_sensitivity=62.71%, avg_specificity=91.15% avg_auc=0.8873
Best model saved!! Metric=0.535293373245807!!
Fold[5] Epoch: 4 [4/100 (4%)] Train loss=0.848814 Test loss=0.395157 Current lr=[8.161695403755248e-05]

[0/23] Train loss=0.7282459735870361
[5/23] Train loss=0.9253858923912048
[10/23] Train loss=0.791161060333252
[15/23] Train loss=0.7218354344367981
[20/23] Train loss=0.6184303760528564
Test set avg_accuracy=85.87% avg_sensitivity=73.68%, avg_specificity=90.00% avg_auc=0.9092
Best model saved!! Metric=14.46870950004436!!
Fold[5] Epoch: 5 [5/100 (5%)] Train loss=0.811826 Test loss=0.356359 Current lr=[0.00010449031183917899]

[0/23] Train loss=0.7179586291313171
[5/23] Train loss=0.9150277376174927
[10/23] Train loss=0.7622782588005066
[15/23] Train loss=0.6522306799888611
[20/23] Train loss=0.5771879553794861
Test set avg_accuracy=86.79% avg_sensitivity=76.82%, avg_specificity=90.17% avg_auc=0.9173
Best model saved!! Metric=19.505174744122897!!
Fold[5] Epoch: 6 [6/100 (6%)] Train loss=0.776486 Test loss=0.337167 Current lr=[0.00013192929274872232]

[0/23] Train loss=0.6566155552864075
[5/23] Train loss=0.9027605652809143
[10/23] Train loss=0.7348194718360901
[15/23] Train loss=0.6285218000411987
[20/23] Train loss=0.5370379686355591
Test set avg_accuracy=85.01% avg_sensitivity=83.15%, avg_specificity=85.64% avg_auc=0.9247
Best model saved!! Metric=20.28183408661763!!
Fold[5] Epoch: 7 [7/100 (7%)] Train loss=0.744724 Test loss=0.358172 Current lr=[0.00016363239706865967]

[0/23] Train loss=0.6049869060516357
[5/23] Train loss=0.8694125413894653
[10/23] Train loss=0.6869759559631348
[15/23] Train loss=0.6031225919723511
[20/23] Train loss=0.4884651303291321
Test set avg_accuracy=85.19% avg_sensitivity=84.06%, avg_specificity=85.57% avg_auc=0.9271
Best model saved!! Metric=21.533831824724714!!
Fold[5] Epoch: 8 [8/100 (8%)] Train loss=0.719925 Test loss=0.369962 Current lr=[0.00019925127088619402]

[0/23] Train loss=0.5735236406326294
[5/23] Train loss=0.9077075719833374
[10/23] Train loss=0.7212243676185608
[15/23] Train loss=0.6167775392532349
[20/23] Train loss=0.4637289047241211
Test set avg_accuracy=84.80% avg_sensitivity=86.84%, avg_specificity=84.12% avg_auc=0.9296
Best model saved!! Metric=22.71788807401306!!
Fold[5] Epoch: 9 [9/100 (9%)] Train loss=0.720313 Test loss=0.402548 Current lr=[0.00023839453378827395]

[0/23] Train loss=0.5861762166023254
[5/23] Train loss=0.936989963054657
[10/23] Train loss=0.778908371925354
[15/23] Train loss=0.5955974459648132
[20/23] Train loss=0.49505698680877686
Test set avg_accuracy=86.26% avg_sensitivity=81.25%, avg_specificity=87.95% avg_auc=0.9280
Fold[5] Epoch: 10 [10/100 (10%)] Train loss=0.719642 Test loss=0.363399 Current lr=[0.00028063207935207196]

[0/23] Train loss=0.5675391554832458
[5/23] Train loss=0.9287269711494446
[10/23] Train loss=0.7300530076026917
[15/23] Train loss=0.5466585159301758
[20/23] Train loss=0.48874181509017944
Test set avg_accuracy=86.57% avg_sensitivity=86.18%, avg_specificity=86.71% avg_auc=0.9372
Best model saved!! Metric=27.177949550414358!!
Fold[5] Epoch: 11 [11/100 (11%)] Train loss=0.696827 Test loss=0.326644 Current lr=[0.0003254998011571065]

[0/23] Train loss=0.5424851179122925
[5/23] Train loss=0.9080946445465088
[10/23] Train loss=0.7370326519012451
[15/23] Train loss=0.5592538118362427
[20/23] Train loss=0.5368001461029053
Test set avg_accuracy=88.64% avg_sensitivity=83.28%, avg_specificity=90.46% avg_auc=0.9384
Best model saved!! Metric=30.221775470249924!!
Fold[5] Epoch: 12 [12/100 (12%)] Train loss=0.692438 Test loss=0.309384 Current lr=[0.0003725046923895547]

[0/23] Train loss=0.5307838320732117
[5/23] Train loss=0.9813569784164429
[10/23] Train loss=0.7518521547317505
[15/23] Train loss=0.5514568090438843
[20/23] Train loss=0.458810955286026
Test set avg_accuracy=88.23% avg_sensitivity=85.89%, avg_specificity=89.02% avg_auc=0.9422
Best model saved!! Metric=31.34758478151086!!
Fold[5] Epoch: 13 [13/100 (13%)] Train loss=0.691580 Test loss=0.305336 Current lr=[0.0004211302630042728]

[0/23] Train loss=0.5402952432632446
[5/23] Train loss=0.9266816973686218
[10/23] Train loss=0.7234200239181519
[15/23] Train loss=0.5380258560180664
[20/23] Train loss=0.4662817120552063
Test set avg_accuracy=85.83% avg_sensitivity=89.40%, avg_specificity=84.62% avg_auc=0.9444
Fold[5] Epoch: 14 [14/100 (14%)] Train loss=0.679886 Test loss=0.356925 Current lr=[0.0004708422149207104]

[0/23] Train loss=0.5112325549125671
[5/23] Train loss=0.9055829644203186
[10/23] Train loss=0.7230995893478394
[15/23] Train loss=0.5408729314804077
[20/23] Train loss=0.4516633152961731
Test set avg_accuracy=87.41% avg_sensitivity=89.32%, avg_specificity=86.76% avg_auc=0.9442
Best model saved!! Metric=31.909994490322205!!
Fold[5] Epoch: 15 [15/100 (15%)] Train loss=0.666529 Test loss=0.318950 Current lr=[0.0005210943128936348]

[0/23] Train loss=0.484798789024353
[5/23] Train loss=0.965535044670105
[10/23] Train loss=0.7029121518135071
[15/23] Train loss=0.5169580578804016
[20/23] Train loss=0.42241308093070984
Test set avg_accuracy=89.30% avg_sensitivity=86.01%, avg_specificity=90.42% avg_auc=0.9459
Best model saved!! Metric=34.3217385524539!!
Fold[5] Epoch: 16 [16/100 (16%)] Train loss=0.660926 Test loss=0.292844 Current lr=[0.0005713343865494929]

[0/23] Train loss=0.4729112982749939
[5/23] Train loss=0.8516133427619934
[10/23] Train loss=0.6907122135162354
[15/23] Train loss=0.521182656288147
[20/23] Train loss=0.4462348520755768
Test set avg_accuracy=88.05% avg_sensitivity=85.68%, avg_specificity=88.85% avg_auc=0.9417
Fold[5] Epoch: 17 [17/100 (17%)] Train loss=0.641749 Test loss=0.291981 Current lr=[0.0006210103976380052]

[0/23] Train loss=0.5085840225219727
[5/23] Train loss=0.9141837358474731
[10/23] Train loss=0.6909787654876709
[15/23] Train loss=0.5461019277572632
[20/23] Train loss=0.4020339548587799
Test set avg_accuracy=87.25% avg_sensitivity=88.87%, avg_specificity=86.71% avg_auc=0.9452
Fold[5] Epoch: 18 [18/100 (18%)] Train loss=0.641972 Test loss=0.333906 Current lr=[0.0006695765058319851]

[0/23] Train loss=0.5071374177932739
[5/23] Train loss=0.8451285362243652
[10/23] Train loss=0.6696781516075134
[15/23] Train loss=0.5159704685211182
[20/23] Train loss=0.45712849497795105
Test set avg_accuracy=90.16% avg_sensitivity=81.91%, avg_specificity=92.95% avg_auc=0.9424
Fold[5] Epoch: 19 [19/100 (19%)] Train loss=0.622760 Test loss=0.273988 Current lr=[0.0007164990664243417]

[0/23] Train loss=0.5055918097496033
[5/23] Train loss=0.7738784551620483
[10/23] Train loss=0.6283012628555298
[15/23] Train loss=0.5120964050292969
[20/23] Train loss=0.4199340045452118
Test set avg_accuracy=89.23% avg_sensitivity=86.01%, avg_specificity=90.32% avg_auc=0.9411
Fold[5] Epoch: 20 [20/100 (20%)] Train loss=0.610520 Test loss=0.291664 Current lr=[0.0007612624940195301]

[0/23] Train loss=0.48688647150993347
[5/23] Train loss=0.8544793128967285
[10/23] Train loss=0.6110343933105469
[15/23] Train loss=0.4637560546398163
[20/23] Train loss=0.420419842004776
Test set avg_accuracy=89.68% avg_sensitivity=83.86%, avg_specificity=91.65% avg_auc=0.9469
Fold[5] Epoch: 21 [21/100 (21%)] Train loss=0.603132 Test loss=0.271469 Current lr=[0.000803374927789172]

[0/23] Train loss=0.4758576452732086
[5/23] Train loss=0.7696046233177185
[10/23] Train loss=0.6431140303611755
[15/23] Train loss=0.4683161675930023
[20/23] Train loss=0.4108344316482544
Test set avg_accuracy=84.56% avg_sensitivity=90.52%, avg_specificity=82.55% avg_auc=0.9391
Fold[5] Epoch: 22 [22/100 (22%)] Train loss=0.597515 Test loss=0.362393 Current lr=[0.0008423736360419787]

[0/23] Train loss=0.4896470904350281
[5/23] Train loss=0.8224579095840454
[10/23] Train loss=0.5962882041931152
[15/23] Train loss=0.4565799832344055
[20/23] Train loss=0.40129056572914124
Test set avg_accuracy=86.50% avg_sensitivity=88.74%, avg_specificity=85.74% avg_auc=0.9466
Fold[5] Epoch: 23 [23/100 (23%)] Train loss=0.596976 Test loss=0.322262 Current lr=[0.0008778301007225328]

[0/23] Train loss=0.4629817008972168
[5/23] Train loss=0.8206826448440552
[10/23] Train loss=0.5711172819137573
[15/23] Train loss=0.4664357900619507
[20/23] Train loss=0.429097056388855
Test set avg_accuracy=89.70% avg_sensitivity=83.44%, avg_specificity=91.82% avg_auc=0.9440
Fold[5] Epoch: 24 [24/100 (24%)] Train loss=0.585052 Test loss=0.285897 Current lr=[0.0009093547259704173]

[0/23] Train loss=0.4745962917804718
[5/23] Train loss=0.7550073266029358
[10/23] Train loss=0.5937662124633789
[15/23] Train loss=0.44650447368621826
[20/23] Train loss=0.4093528687953949
Test set avg_accuracy=88.60% avg_sensitivity=87.21%, avg_specificity=89.07% avg_auc=0.9447
Fold[5] Epoch: 25 [25/100 (25%)] Train loss=0.576876 Test loss=0.301070 Current lr=[0.0009366011190020192]

[0/23] Train loss=0.4487915337085724
[5/23] Train loss=0.8219676613807678
[10/23] Train loss=0.5909484624862671
[15/23] Train loss=0.49131181836128235
[20/23] Train loss=0.42788517475128174
Test set avg_accuracy=88.68% avg_sensitivity=83.73%, avg_specificity=90.35% avg_auc=0.9407
Fold[5] Epoch: 26 [26/100 (26%)] Train loss=0.582431 Test loss=0.296684 Current lr=[0.0009592698962766488]

[0/23] Train loss=0.44791966676712036
[5/23] Train loss=0.7575463056564331
[10/23] Train loss=0.5206015110015869
[15/23] Train loss=0.42819368839263916
[20/23] Train loss=0.40919989347457886
Test set avg_accuracy=88.59% avg_sensitivity=83.65%, avg_specificity=90.26% avg_auc=0.9461
Fold[5] Epoch: 27 [27/100 (27%)] Train loss=0.571738 Test loss=0.297184 Current lr=[0.0009771119731247974]

[0/23] Train loss=0.48261478543281555
[5/23] Train loss=0.7606298923492432
[10/23] Train loss=0.4862612187862396
[15/23] Train loss=0.4499572813510895
[20/23] Train loss=0.40042150020599365
Test set avg_accuracy=89.91% avg_sensitivity=85.39%, avg_specificity=91.44% avg_auc=0.9462
Best model saved!! Metric=35.361553009954484!!
Fold[5] Epoch: 28 [28/100 (28%)] Train loss=0.558298 Test loss=0.276410 Current lr=[0.0009899313006920766]

[0/23] Train loss=0.4780080020427704
[5/23] Train loss=0.7177097797393799
[10/23] Train loss=0.56626957654953
[15/23] Train loss=0.4608698785305023
[20/23] Train loss=0.43280425667762756
Test set avg_accuracy=88.85% avg_sensitivity=84.19%, avg_specificity=90.43% avg_auc=0.9398
Fold[5] Epoch: 29 [29/100 (29%)] Train loss=0.562256 Test loss=0.296235 Current lr=[0.0009975870201252835]

[0/23] Train loss=0.5112398862838745
[5/23] Train loss=0.6721630096435547
[10/23] Train loss=0.6033703684806824
[15/23] Train loss=0.43214741349220276
[20/23] Train loss=0.406416654586792
Test set avg_accuracy=88.54% avg_sensitivity=87.58%, avg_specificity=88.86% avg_auc=0.9474
Fold[5] Epoch: 30 [30/100 (30%)] Train loss=0.565241 Test loss=0.285380 Current lr=[0.000999999048111397]

[0/23] Train loss=0.466434121131897
[5/23] Train loss=0.6954098343849182
[10/23] Train loss=0.5294907093048096
[15/23] Train loss=0.44483861327171326
[20/23] Train loss=0.3830045759677887
Test set avg_accuracy=89.80% avg_sensitivity=82.04%, avg_specificity=92.42% avg_auc=0.9455
Fold[5] Epoch: 31 [31/100 (31%)] Train loss=0.558598 Test loss=0.276343 Current lr=[0.000999451812190372]

[0/23] Train loss=0.4721771776676178
[5/23] Train loss=0.7142010927200317
[10/23] Train loss=0.5928035378456116
[15/23] Train loss=0.420896977186203
[20/23] Train loss=0.37752944231033325
Test set avg_accuracy=89.51% avg_sensitivity=86.05%, avg_specificity=90.68% avg_auc=0.9478
Fold[5] Epoch: 32 [32/100 (32%)] Train loss=0.549035 Test loss=0.275656 Current lr=[0.0009978987508156897]

[0/23] Train loss=0.4442238509654999
[5/23] Train loss=0.7262210845947266
[10/23] Train loss=0.5815691947937012
[15/23] Train loss=0.4033971428871155
[20/23] Train loss=0.3838943541049957
Test set avg_accuracy=89.35% avg_sensitivity=80.38%, avg_specificity=92.38% avg_auc=0.9363
Fold[5] Epoch: 33 [33/100 (33%)] Train loss=0.535789 Test loss=0.295706 Current lr=[0.0009953429916462733]

[0/23] Train loss=0.44127732515335083
[5/23] Train loss=0.7278640866279602
[10/23] Train loss=0.5655413866043091
[15/23] Train loss=0.3977033793926239
[20/23] Train loss=0.3718818724155426
Test set avg_accuracy=89.95% avg_sensitivity=81.62%, avg_specificity=92.77% avg_auc=0.9467
Fold[5] Epoch: 34 [34/100 (34%)] Train loss=0.523822 Test loss=0.268760 Current lr=[0.000991789681640963]

[0/23] Train loss=0.4223850667476654
[5/23] Train loss=0.6771966218948364
[10/23] Train loss=0.5599161386489868
[15/23] Train loss=0.4171799123287201
[20/23] Train loss=0.35683929920196533
Test set avg_accuracy=89.83% avg_sensitivity=80.42%, avg_specificity=93.01% avg_auc=0.9405
Fold[5] Epoch: 35 [35/100 (35%)] Train loss=0.521905 Test loss=0.289283 Current lr=[0.0009872459766932253]

[0/23] Train loss=0.41793444752693176
[5/23] Train loss=0.6295925974845886
[10/23] Train loss=0.5727103352546692
[15/23] Train loss=0.4413883090019226
[20/23] Train loss=0.36762717366218567
Test set avg_accuracy=90.13% avg_sensitivity=82.70%, avg_specificity=92.65% avg_auc=0.9449
Fold[5] Epoch: 36 [36/100 (36%)] Train loss=0.515108 Test loss=0.283878 Current lr=[0.0009817210272201372]

[0/23] Train loss=0.42029958963394165
[5/23] Train loss=0.6425453424453735
[10/23] Train loss=0.5303834676742554
[15/23] Train loss=0.4128970801830292
[20/23] Train loss=0.3512137830257416
Test set avg_accuracy=90.30% avg_sensitivity=85.76%, avg_specificity=91.83% avg_auc=0.9510
Best model saved!! Metric=36.9939650873374!!
Fold[5] Epoch: 37 [37/100 (37%)] Train loss=0.506307 Test loss=0.269044 Current lr=[0.0009752259597346622]

[0/23] Train loss=0.4281567335128784
[5/23] Train loss=0.6137909293174744
[10/23] Train loss=0.5708582997322083
[15/23] Train loss=0.4810299873352051
[20/23] Train loss=0.36080148816108704
Test set avg_accuracy=89.83% avg_sensitivity=80.30%, avg_specificity=93.05% avg_auc=0.9423
Fold[5] Epoch: 38 [38/100 (38%)] Train loss=0.508679 Test loss=0.286406 Current lr=[0.000967773854438336]

[0/23] Train loss=0.3863440454006195
[5/23] Train loss=0.6184695959091187
[10/23] Train loss=0.53719562292099
[15/23] Train loss=0.41324129700660706
[20/23] Train loss=0.3567061424255371
Test set avg_accuracy=89.65% avg_sensitivity=82.20%, avg_specificity=92.17% avg_auc=0.9428
Fold[5] Epoch: 39 [39/100 (39%)] Train loss=0.490521 Test loss=0.300618 Current lr=[0.000959379718879479]

[0/23] Train loss=0.3890126645565033
[5/23] Train loss=0.5714154243469238
[10/23] Train loss=0.5302925705909729
[15/23] Train loss=0.41381052136421204
[20/23] Train loss=0.3611440658569336
Test set avg_accuracy=89.69% avg_sensitivity=84.15%, avg_specificity=91.57% avg_auc=0.9458
Fold[5] Epoch: 40 [40/100 (40%)] Train loss=0.476240 Test loss=0.288869 Current lr=[0.0009500604577299936]

[0/23] Train loss=0.40044546127319336
[5/23] Train loss=0.5837839245796204
[10/23] Train loss=0.5480552315711975
[15/23] Train loss=0.39084312319755554
[20/23] Train loss=0.32386043667793274
Test set avg_accuracy=88.13% avg_sensitivity=89.11%, avg_specificity=87.80% avg_auc=0.9503
Fold[5] Epoch: 41 [41/100 (41%)] Train loss=0.476935 Test loss=0.335306 Current lr=[0.0009398348387416027]

[0/23] Train loss=0.43282613158226013
[5/23] Train loss=0.5866571664810181
[10/23] Train loss=0.5345888733863831
[15/23] Train loss=0.40640589594841003
[20/23] Train loss=0.3006449341773987
Test set avg_accuracy=88.99% avg_sensitivity=88.53%, avg_specificity=89.14% avg_auc=0.9491
Fold[5] Epoch: 42 [42/100 (42%)] Train loss=0.467329 Test loss=0.321751 Current lr=[0.000928723454950097]

[0/23] Train loss=0.39639386534690857
[5/23] Train loss=0.6346525549888611
[10/23] Train loss=0.4708486795425415
[15/23] Train loss=0.40265196561813354
[20/23] Train loss=0.31629443168640137
Test set avg_accuracy=88.19% avg_sensitivity=88.82%, avg_specificity=87.98% avg_auc=0.9496
Fold[5] Epoch: 43 [43/100 (43%)] Train loss=0.461911 Test loss=0.352065 Current lr=[0.0009167486832037001]

[0/23] Train loss=0.38679617643356323
[5/23] Train loss=0.5894262194633484
[10/23] Train loss=0.4921130836009979
[15/23] Train loss=0.4059232771396637
[20/23] Train loss=0.2977088689804077
Test set avg_accuracy=89.50% avg_sensitivity=87.29%, avg_specificity=90.25% avg_auc=0.9488
Fold[5] Epoch: 44 [44/100 (44%)] Train loss=0.445034 Test loss=0.308728 Current lr=[0.0009039346390990754]

[0/23] Train loss=0.36743995547294617
[5/23] Train loss=0.5392913222312927
[10/23] Train loss=0.4658815562725067
[15/23] Train loss=0.4070345461368561
[20/23] Train loss=0.2880719304084778
Test set avg_accuracy=87.50% avg_sensitivity=90.77%, avg_specificity=86.40% avg_auc=0.9490
Fold[5] Epoch: 45 [45/100 (45%)] Train loss=0.436152 Test loss=0.366427 Current lr=[0.000890307128415723]

[0/23] Train loss=0.3502095639705658
[5/23] Train loss=0.5534891486167908
[10/23] Train loss=0.44870954751968384
[15/23] Train loss=0.3550144135951996
[20/23] Train loss=0.2812683582305908
Test set avg_accuracy=87.60% avg_sensitivity=89.69%, avg_specificity=86.89% avg_auc=0.9486
Fold[5] Epoch: 46 [46/100 (46%)] Train loss=0.422347 Test loss=0.354166 Current lr=[0.0008758935951465738]

[0/23] Train loss=0.373343288898468
[5/23] Train loss=0.509724497795105
[10/23] Train loss=0.4770313501358032
[15/23] Train loss=0.37976783514022827
[20/23] Train loss=0.3297545611858368
Test set avg_accuracy=88.06% avg_sensitivity=88.91%, avg_specificity=87.77% avg_auc=0.9492
Fold[5] Epoch: 47 [47/100 (47%)] Train loss=0.435126 Test loss=0.339321 Current lr=[0.0008607230662294413]

[0/23] Train loss=0.3797261416912079
[5/23] Train loss=0.4994429647922516
[10/23] Train loss=0.440898060798645
[15/23] Train loss=0.34192967414855957
[20/23] Train loss=0.2600395679473877
Test set avg_accuracy=86.52% avg_sensitivity=89.61%, avg_specificity=85.47% avg_auc=0.9420
Fold[5] Epoch: 48 [48/100 (48%)] Train loss=0.407140 Test loss=0.438636 Current lr=[0.0008448260930906307]

[0/23] Train loss=0.34582605957984924
[5/23] Train loss=0.475990891456604
[10/23] Train loss=0.4314417243003845
[15/23] Train loss=0.3463291823863983
[20/23] Train loss=0.29261818528175354
Test set avg_accuracy=89.29% avg_sensitivity=84.73%, avg_specificity=90.84% avg_auc=0.9443
Fold[5] Epoch: 49 [49/100 (49%)] Train loss=0.404349 Test loss=0.332044 Current lr=[0.0008282346901184324]

[0/23] Train loss=0.35711440443992615
[5/23] Train loss=0.4523996412754059
[10/23] Train loss=0.35821133852005005
[15/23] Train loss=0.3098702132701874
[20/23] Train loss=0.2786523699760437
Test set avg_accuracy=89.86% avg_sensitivity=86.26%, avg_specificity=91.08% avg_auc=0.9491
Fold[5] Epoch: 50 [50/100 (50%)] Train loss=0.368032 Test loss=0.320899 Current lr=[0.000810982270190405]

[0/23] Train loss=0.29761064052581787
[5/23] Train loss=0.3938579261302948
[10/23] Train loss=0.34186604619026184
[15/23] Train loss=0.30163463950157166
[20/23] Train loss=0.2427874654531479
Test set avg_accuracy=88.01% avg_sensitivity=88.45%, avg_specificity=87.86% avg_auc=0.9436
Fold[5] Epoch: 51 [51/100 (51%)] Train loss=0.338351 Test loss=0.351081 Current lr=[0.0007931035773842862]

[0/23] Train loss=0.28552770614624023
[5/23] Train loss=0.40645524859428406
[10/23] Train loss=0.31569498777389526
[15/23] Train loss=0.30010172724723816
[20/23] Train loss=0.25377437472343445
Test set avg_accuracy=90.55% avg_sensitivity=80.30%, avg_specificity=94.02% avg_auc=0.9398
Fold[5] Epoch: 52 [52/100 (52%)] Train loss=0.346916 Test loss=0.329126 Current lr=[0.0007746346170080441]

[0/23] Train loss=0.2950039803981781
[5/23] Train loss=0.3824228048324585
[10/23] Train loss=0.3365950584411621
[15/23] Train loss=0.2780354619026184
[20/23] Train loss=0.20816302299499512
Test set avg_accuracy=89.60% avg_sensitivity=82.95%, avg_specificity=91.85% avg_auc=0.9416
Fold[5] Epoch: 53 [53/100 (53%)] Train loss=0.315765 Test loss=0.328598 Current lr=[0.0007556125830899786]

[0/23] Train loss=0.30017659068107605
[5/23] Train loss=0.3348304033279419
[10/23] Train loss=0.2927343249320984
[15/23] Train loss=0.24732355773448944
[20/23] Train loss=0.24024584889411926
Test set avg_accuracy=89.48% avg_sensitivity=83.49%, avg_specificity=91.51% avg_auc=0.9408
Fold[5] Epoch: 54 [54/100 (54%)] Train loss=0.295961 Test loss=0.344028 Current lr=[0.0007360757834748981]

[0/23] Train loss=0.2346022129058838
[5/23] Train loss=0.2945196330547333
[10/23] Train loss=0.2921094298362732
[15/23] Train loss=0.2475346475839615
[20/23] Train loss=0.20061084628105164
Test set avg_accuracy=89.18% avg_sensitivity=85.47%, avg_specificity=90.43% avg_auc=0.9416
Fold[5] Epoch: 55 [55/100 (55%)] Train loss=0.275936 Test loss=0.346728 Current lr=[0.000716063562677219]

[0/23] Train loss=0.2344687134027481
[5/23] Train loss=0.2752002775669098
[10/23] Train loss=0.2511531710624695
[15/23] Train loss=0.22876036167144775
[20/23] Train loss=0.2071724683046341
Test set avg_accuracy=88.28% avg_sensitivity=86.47%, avg_specificity=88.89% avg_auc=0.9405
Fold[5] Epoch: 56 [56/100 (56%)] Train loss=0.252985 Test loss=0.361585 Current lr=[0.0006956162226463489]

[0/23] Train loss=0.21921618282794952
[5/23] Train loss=0.29531821608543396
[10/23] Train loss=0.2731705904006958
[15/23] Train loss=0.23909519612789154
[20/23] Train loss=0.1883964240550995
Test set avg_accuracy=88.78% avg_sensitivity=84.56%, avg_specificity=90.21% avg_auc=0.9391
Fold[5] Epoch: 57 [57/100 (57%)] Train loss=0.245423 Test loss=0.350352 Current lr=[0.0006747749416039243]

[0/23] Train loss=0.23896381258964539
[5/23] Train loss=0.2918233871459961
[10/23] Train loss=0.28197798132896423
[15/23] Train loss=0.2145516276359558
[20/23] Train loss=0.17491436004638672
Test set avg_accuracy=89.20% avg_sensitivity=83.53%, avg_specificity=91.12% avg_auc=0.9418
Fold[5] Epoch: 58 [58/100 (58%)] Train loss=0.227694 Test loss=0.353368 Current lr=[0.000653581691116352]

[0/23] Train loss=0.20619170367717743
[5/23] Train loss=0.25530990958213806
[10/23] Train loss=0.2373977154493332
[15/23] Train loss=0.20309600234031677
[20/23] Train loss=0.16398805379867554
Test set avg_accuracy=90.06% avg_sensitivity=84.35%, avg_specificity=91.99% avg_auc=0.9436
Fold[5] Epoch: 59 [59/100 (59%)] Train loss=0.215452 Test loss=0.347996 Current lr=[0.0006320791515696602]

[0/23] Train loss=0.20351232588291168
[5/23] Train loss=0.26129716634750366
[10/23] Train loss=0.21190707385540009
[15/23] Train loss=0.21117974817752838
[20/23] Train loss=0.13915275037288666
Test set avg_accuracy=89.83% avg_sensitivity=85.26%, avg_specificity=91.37% avg_auc=0.9440
Fold[5] Epoch: 60 [60/100 (60%)] Train loss=0.202936 Test loss=0.362872 Current lr=[0.0006103106262168818]

[0/23] Train loss=0.1867896169424057
[5/23] Train loss=0.2233746498823166
[10/23] Train loss=0.20552317798137665
[15/23] Train loss=0.196245476603508
[20/23] Train loss=0.16203737258911133
Test set avg_accuracy=89.57% avg_sensitivity=81.79%, avg_specificity=92.20% avg_auc=0.9404
Fold[5] Epoch: 61 [61/100 (61%)] Train loss=0.195115 Test loss=0.377507 Current lr=[0.0005883199539710647]

[0/23] Train loss=0.19228766858577728
[5/23] Train loss=0.21979235112667084
[10/23] Train loss=0.19098788499832153
[15/23] Train loss=0.1814631074666977
[20/23] Train loss=0.13856028020381927
Test set avg_accuracy=88.95% avg_sensitivity=83.98%, avg_specificity=90.63% avg_auc=0.9415
Fold[5] Epoch: 62 [62/100 (62%)] Train loss=0.189523 Test loss=0.389663 Current lr=[0.0005661514211195354]

[0/23] Train loss=0.1768203228712082
[5/23] Train loss=0.19606755673885345
[10/23] Train loss=0.1950615495443344
[15/23] Train loss=0.17720940709114075
[20/23] Train loss=0.13045121729373932
Test set avg_accuracy=89.65% avg_sensitivity=80.13%, avg_specificity=92.87% avg_auc=0.9372
Fold[5] Epoch: 63 [63/100 (63%)] Train loss=0.181088 Test loss=0.386690 Current lr=[0.00054384967213721]

[0/23] Train loss=0.16697536408901215
[5/23] Train loss=0.19107140600681305
[10/23] Train loss=0.1769009679555893
[15/23] Train loss=0.18225814402103424
[20/23] Train loss=0.14141349494457245
Test set avg_accuracy=89.06% avg_sensitivity=83.36%, avg_specificity=90.99% avg_auc=0.9387
Fold[5] Epoch: 64 [64/100 (64%)] Train loss=0.170692 Test loss=0.397872 Current lr=[0.000521459619778564]

[0/23] Train loss=0.14772024750709534
[5/23] Train loss=0.19418196380138397
[10/23] Train loss=0.16296181082725525
[15/23] Train loss=0.16967260837554932
[20/23] Train loss=0.11698104441165924
Test set avg_accuracy=90.04% avg_sensitivity=79.97%, avg_specificity=93.44% avg_auc=0.9407
Fold[5] Epoch: 65 [65/100 (65%)] Train loss=0.160500 Test loss=0.383164 Current lr=[0.0004990263546293204]

[0/23] Train loss=0.13929429650306702
[5/23] Train loss=0.18485236167907715
[10/23] Train loss=0.1798895001411438
[15/23] Train loss=0.1598372459411621
[20/23] Train loss=0.15113034844398499
Test set avg_accuracy=89.63% avg_sensitivity=80.84%, avg_specificity=92.60% avg_auc=0.9407
Fold[5] Epoch: 66 [66/100 (66%)] Train loss=0.158203 Test loss=0.373960 Current lr=[0.000476595054300012]

[0/23] Train loss=0.14106735587120056
[5/23] Train loss=0.170396089553833
[10/23] Train loss=0.16367806494235992
[15/23] Train loss=0.17240680754184723
[20/23] Train loss=0.12845377624034882
Test set avg_accuracy=89.76% avg_sensitivity=85.35%, avg_specificity=91.26% avg_auc=0.9446
Fold[5] Epoch: 67 [67/100 (67%)] Train loss=0.150640 Test loss=0.384291 Current lr=[0.0004542108924442853]

[0/23] Train loss=0.13676121830940247
[5/23] Train loss=0.1596832573413849
[10/23] Train loss=0.16563165187835693
[15/23] Train loss=0.14640700817108154
[20/23] Train loss=0.1336633861064911
Test set avg_accuracy=88.46% avg_sensitivity=86.75%, avg_specificity=89.03% avg_auc=0.9419
Fold[5] Epoch: 68 [68/100 (68%)] Train loss=0.139843 Test loss=0.442229 Current lr=[0.000431918947785175]

[0/23] Train loss=0.15180006623268127
[5/23] Train loss=0.15917201340198517
[10/23] Train loss=0.13456246256828308
[15/23] Train loss=0.13596709072589874
[20/23] Train loss=0.11385218799114227
Test set avg_accuracy=89.07% avg_sensitivity=86.47%, avg_specificity=89.96% avg_auc=0.9434
Fold[5] Epoch: 69 [69/100 (69%)] Train loss=0.137700 Test loss=0.456426 Current lr=[0.0004097641133325535]

[0/23] Train loss=0.1343080699443817
[5/23] Train loss=0.17310084402561188
[10/23] Train loss=0.1294287145137787
[15/23] Train loss=0.14135195314884186
[20/23] Train loss=0.11139293015003204
Test set avg_accuracy=89.21% avg_sensitivity=85.97%, avg_specificity=90.31% avg_auc=0.9436
Fold[5] Epoch: 70 [70/100 (70%)] Train loss=0.126882 Test loss=0.466491 Current lr=[0.00038779100597458526]

[0/23] Train loss=0.11917436122894287
[5/23] Train loss=0.13816414773464203
[10/23] Train loss=0.1218288466334343
[15/23] Train loss=0.1366865336894989
[20/23] Train loss=0.08402713388204575
Test set avg_accuracy=89.21% avg_sensitivity=84.98%, avg_specificity=90.64% avg_auc=0.9439
Fold[5] Epoch: 71 [71/100 (71%)] Train loss=0.115596 Test loss=0.470368 Current lr=[0.0003660438766252499]

[0/23] Train loss=0.10883688926696777
[5/23] Train loss=0.12329301983118057
[10/23] Train loss=0.10026060044765472
[15/23] Train loss=0.129685640335083
[20/23] Train loss=0.08057785034179688
Test set avg_accuracy=89.84% avg_sensitivity=84.85%, avg_specificity=91.53% avg_auc=0.9430
Fold[5] Epoch: 72 [72/100 (72%)] Train loss=0.105792 Test loss=0.443302 Current lr=[0.0003445665211088922]

[0/23] Train loss=0.09041187167167664
[5/23] Train loss=0.13387921452522278
[10/23] Train loss=0.11942528188228607
[15/23] Train loss=0.09760815650224686
[20/23] Train loss=0.08217234909534454
Test set avg_accuracy=89.58% avg_sensitivity=84.02%, avg_specificity=91.46% avg_auc=0.9421
Fold[5] Epoch: 73 [73/100 (73%)] Train loss=0.095915 Test loss=0.463482 Current lr=[0.00032340219196125877]

[0/23] Train loss=0.0975617915391922
[5/23] Train loss=0.09977158904075623
[10/23] Train loss=0.08887333422899246
[15/23] Train loss=0.09173524379730225
[20/23] Train loss=0.08222837001085281
Test set avg_accuracy=90.37% avg_sensitivity=83.53%, avg_specificity=92.69% avg_auc=0.9430
Fold[5] Epoch: 74 [74/100 (74%)] Train loss=0.089908 Test loss=0.443444 Current lr=[0.0003025935113246488]

[0/23] Train loss=0.07965638488531113
[5/23] Train loss=0.118044912815094
[10/23] Train loss=0.0805714875459671
[15/23] Train loss=0.1012505367398262
[20/23] Train loss=0.07482076436281204
Test set avg_accuracy=89.71% avg_sensitivity=84.31%, avg_specificity=91.54% avg_auc=0.9424
Fold[5] Epoch: 75 [75/100 (75%)] Train loss=0.083840 Test loss=0.464009 Current lr=[0.0002821823851125901]

[0/23] Train loss=0.06819885969161987
[5/23] Train loss=0.09429150819778442
[10/23] Train loss=0.09407711774110794
[15/23] Train loss=0.09273555129766464
[20/23] Train loss=0.08483972400426865
Test set avg_accuracy=89.84% avg_sensitivity=83.32%, avg_specificity=92.04% avg_auc=0.9416
Fold[5] Epoch: 76 [76/100 (76%)] Train loss=0.080256 Test loss=0.481164 Current lr=[0.00026220991861690765]

[0/23] Train loss=0.0791952833533287
[5/23] Train loss=0.0766911506652832
[10/23] Train loss=0.08137023448944092
[15/23] Train loss=0.09246674180030823
[20/23] Train loss=0.06263140588998795
Test set avg_accuracy=89.70% avg_sensitivity=83.32%, avg_specificity=91.86% avg_auc=0.9429
Fold[5] Epoch: 77 [77/100 (77%)] Train loss=0.074277 Test loss=0.472779 Current lr=[0.00024271633372713536]

[0/23] Train loss=0.06739644706249237
[5/23] Train loss=0.0848064199090004
[10/23] Train loss=0.08337532728910446
[15/23] Train loss=0.0932442918419838
[20/23] Train loss=0.05666836351156235
Test set avg_accuracy=90.34% avg_sensitivity=83.65%, avg_specificity=92.60% avg_auc=0.9438
Fold[5] Epoch: 78 [78/100 (78%)] Train loss=0.072355 Test loss=0.463675 Current lr=[0.00022374088792898362]

[0/23] Train loss=0.07185545563697815
[5/23] Train loss=0.08907752484083176
[10/23] Train loss=0.07952777296304703
[15/23] Train loss=0.07814624160528183
[20/23] Train loss=0.05627630650997162
Test set avg_accuracy=89.88% avg_sensitivity=82.95%, avg_specificity=92.23% avg_auc=0.9428
Fold[5] Epoch: 79 [79/100 (79%)] Train loss=0.067962 Test loss=0.490374 Current lr=[0.00020532179524498774]

[0/23] Train loss=0.06285203248262405
[5/23] Train loss=0.0779261365532875
[10/23] Train loss=0.07848980277776718
[15/23] Train loss=0.07590967416763306
[20/23] Train loss=0.05124404653906822
Test set avg_accuracy=89.92% avg_sensitivity=82.41%, avg_specificity=92.46% avg_auc=0.9431
Fold[5] Epoch: 80 [80/100 (80%)] Train loss=0.065013 Test loss=0.481519 Current lr=[0.000187496149276552]

[0/23] Train loss=0.0719272792339325
[5/23] Train loss=0.07574225217103958
[10/23] Train loss=0.07359116524457932
[15/23] Train loss=0.08242049813270569
[20/23] Train loss=0.05725441128015518
Test set avg_accuracy=89.74% avg_sensitivity=83.44%, avg_specificity=91.88% avg_auc=0.9437
Fold[5] Epoch: 81 [81/100 (81%)] Train loss=0.062805 Test loss=0.487311 Current lr=[0.00017029984850237305]

[0/23] Train loss=0.05796348676085472
[5/23] Train loss=0.09039773046970367
[10/23] Train loss=0.08235234767198563
[15/23] Train loss=0.07608895748853683
[20/23] Train loss=0.052018675953149796
Test set avg_accuracy=89.74% avg_sensitivity=83.20%, avg_specificity=91.96% avg_auc=0.9429
Fold[5] Epoch: 82 [82/100 (82%)] Train loss=0.063066 Test loss=0.495050 Current lr=[0.00015376752398368106]

[0/23] Train loss=0.05623401328921318
[5/23] Train loss=0.06999211013317108
[10/23] Train loss=0.06725984811782837
[15/23] Train loss=0.07248292118310928
[20/23] Train loss=0.07275335490703583
Test set avg_accuracy=89.76% avg_sensitivity=82.95%, avg_specificity=92.07% avg_auc=0.9433
Fold[5] Epoch: 83 [83/100 (83%)] Train loss=0.060951 Test loss=0.491522 Current lr=[0.00013793246962189157]

[0/23] Train loss=0.06042364239692688
[5/23] Train loss=0.05819433182477951
[10/23] Train loss=0.06371007114648819
[15/23] Train loss=0.08108007162809372
[20/23] Train loss=0.04234050586819649
Test set avg_accuracy=89.72% avg_sensitivity=83.53%, avg_specificity=91.82% avg_auc=0.9435
Fold[5] Epoch: 84 [84/100 (84%)] Train loss=0.056888 Test loss=0.495718 Current lr=[0.00012282657510911843]

[0/23] Train loss=0.059312280267477036
[5/23] Train loss=0.0824318379163742
[10/23] Train loss=0.061694808304309845
[15/23] Train loss=0.07096745073795319
[20/23] Train loss=0.05456850305199623
Test set avg_accuracy=89.69% avg_sensitivity=83.36%, avg_specificity=91.83% avg_auc=0.9435
Fold[5] Epoch: 85 [85/100 (85%)] Train loss=0.056795 Test loss=0.501440 Current lr=[0.0001084802617065783]

[0/23] Train loss=0.050345297902822495
[5/23] Train loss=0.08971679210662842
[10/23] Train loss=0.06621173024177551
[15/23] Train loss=0.06559982895851135
[20/23] Train loss=0.044630564749240875
Test set avg_accuracy=89.82% avg_sensitivity=83.77%, avg_specificity=91.86% avg_auc=0.9434
Fold[5] Epoch: 86 [86/100 (86%)] Train loss=0.055580 Test loss=0.500498 Current lr=[9.492242098021878e-05]

[0/23] Train loss=0.05151619762182236
[5/23] Train loss=0.05984850600361824
[10/23] Train loss=0.05493519827723503
[15/23] Train loss=0.0838850662112236
[20/23] Train loss=0.04098724573850632
Test set avg_accuracy=89.72% avg_sensitivity=83.28%, avg_specificity=91.90% avg_auc=0.9431
Fold[5] Epoch: 87 [87/100 (87%)] Train loss=0.053234 Test loss=0.508672 Current lr=[8.218035661694964e-05]

[0/23] Train loss=0.05217708647251129
[5/23] Train loss=0.060276616364717484
[10/23] Train loss=0.058656126260757446
[15/23] Train loss=0.07508336007595062
[20/23] Train loss=0.0485202893614769
Test set avg_accuracy=89.69% avg_sensitivity=82.86%, avg_specificity=92.00% avg_auc=0.9429
Fold[5] Epoch: 88 [88/100 (88%)] Train loss=0.051303 Test loss=0.512994 Current lr=[7.02797294386511e-05]

[0/23] Train loss=0.04904194921255112
[5/23] Train loss=0.06657237559556961
[10/23] Train loss=0.05374300479888916
[15/23] Train loss=0.06337172538042068
[20/23] Train loss=0.0403042770922184
Test set avg_accuracy=89.75% avg_sensitivity=83.15%, avg_specificity=91.99% avg_auc=0.9429
Fold[5] Epoch: 89 [89/100 (89%)] Train loss=0.051718 Test loss=0.513678 Current lr=[5.924450572469346e-05]

[0/23] Train loss=0.05095676705241203
[5/23] Train loss=0.060068611055612564
[10/23] Train loss=0.06578979641199112
[15/23] Train loss=0.07819794118404388
[20/23] Train loss=0.042705655097961426
Test set avg_accuracy=89.80% avg_sensitivity=83.53%, avg_specificity=91.92% avg_auc=0.9431
Fold[5] Epoch: 90 [90/100 (90%)] Train loss=0.051010 Test loss=0.511247 Current lr=[4.90969089470401e-05]

[0/23] Train loss=0.05212013050913811
[5/23] Train loss=0.05359382554888725
[10/23] Train loss=0.054064661264419556
[15/23] Train loss=0.0556931234896183
[20/23] Train loss=0.04442765563726425
Test set avg_accuracy=89.82% avg_sensitivity=83.65%, avg_specificity=91.90% avg_auc=0.9434
Fold[5] Epoch: 91 [91/100 (91%)] Train loss=0.050852 Test loss=0.511645 Current lr=[3.985737501513232e-05]

[0/23] Train loss=0.04681045189499855
[5/23] Train loss=0.05895039066672325
[10/23] Train loss=0.05297475680708885
[15/23] Train loss=0.06332821398973465
[20/23] Train loss=0.03657722845673561
Test set avg_accuracy=89.77% avg_sensitivity=83.44%, avg_specificity=91.92% avg_auc=0.9433
Fold[5] Epoch: 92 [92/100 (92%)] Train loss=0.047955 Test loss=0.514024 Current lr=[3.154451112068745e-05]

[0/23] Train loss=0.04489611089229584
[5/23] Train loss=0.06290452182292938
[10/23] Train loss=0.052691567689180374
[15/23] Train loss=0.0607144795358181
[20/23] Train loss=0.052081700414419174
Test set avg_accuracy=89.94% avg_sensitivity=83.36%, avg_specificity=92.17% avg_auc=0.9432
Fold[5] Epoch: 93 [93/100 (93%)] Train loss=0.048330 Test loss=0.514977 Current lr=[2.4175058265291265e-05]

[0/23] Train loss=0.042495857924222946
[5/23] Train loss=0.05670849233865738
[10/23] Train loss=0.055005740374326706
[15/23] Train loss=0.063175268471241
[20/23] Train loss=0.04835917428135872
Test set avg_accuracy=89.90% avg_sensitivity=83.15%, avg_specificity=92.18% avg_auc=0.9432
Fold[5] Epoch: 94 [94/100 (94%)] Train loss=0.046147 Test loss=0.515810 Current lr=[1.7763857546248248e-05]

[0/23] Train loss=0.047478366643190384
[5/23] Train loss=0.05055743828415871
[10/23] Train loss=0.05138106644153595
[15/23] Train loss=0.06493969261646271
[20/23] Train loss=0.0408393070101738
Test set avg_accuracy=89.98% avg_sensitivity=83.36%, avg_specificity=92.23% avg_auc=0.9431
Fold[5] Epoch: 95 [95/100 (95%)] Train loss=0.048387 Test loss=0.515900 Current lr=[1.2323820268587161e-05]

[0/23] Train loss=0.04159528389573097
[5/23] Train loss=0.06044931337237358
[10/23] Train loss=0.05262402072548866
[15/23] Train loss=0.06475784629583359
[20/23] Train loss=0.04008009284734726
Test set avg_accuracy=89.97% avg_sensitivity=83.53%, avg_specificity=92.16% avg_auc=0.9431
Fold[5] Epoch: 96 [96/100 (96%)] Train loss=0.045908 Test loss=0.516826 Current lr=[7.865901943410707e-06]

[0/23] Train loss=0.049936361610889435
[5/23] Train loss=0.05155493691563606
[10/23] Train loss=0.0440601222217083
[15/23] Train loss=0.06568349152803421
[20/23] Train loss=0.03759492561221123
Test set avg_accuracy=90.06% avg_sensitivity=83.40%, avg_specificity=92.31% avg_auc=0.9431
Fold[5] Epoch: 97 [97/100 (97%)] Train loss=0.047695 Test loss=0.516244 Current lr=[4.399080224954306e-06]

[0/23] Train loss=0.04773573949933052
[5/23] Train loss=0.07457617670297623
[10/23] Train loss=0.053663887083530426
[15/23] Train loss=0.058777619153261185
[20/23] Train loss=0.04138322174549103
Test set avg_accuracy=90.03% avg_sensitivity=83.49%, avg_specificity=92.24% avg_auc=0.9431
Fold[5] Epoch: 98 [98/100 (98%)] Train loss=0.049960 Test loss=0.516668 Current lr=[1.930336830785271e-06]

[0/23] Train loss=0.047962430864572525
[5/23] Train loss=0.05440254136919975
[10/23] Train loss=0.046905454248189926
[15/23] Train loss=0.05538974329829216
[20/23] Train loss=0.03863585367798805
Test set avg_accuracy=90.04% avg_sensitivity=83.40%, avg_specificity=92.28% avg_auc=0.9431
Fold[5] Epoch: 99 [99/100 (99%)] Train loss=0.046564 Test loss=0.516638 Current lr=[4.6464348155246055e-07]

[0/23] Train loss=0.03816571831703186
[5/23] Train loss=0.05847509950399399
[10/23] Train loss=0.04524606838822365
[15/23] Train loss=0.06463401764631271
[20/23] Train loss=0.03916552662849426
Test set avg_accuracy=89.97% avg_sensitivity=83.49%, avg_specificity=92.17% avg_auc=0.9430
Fold[5] Epoch: 100 [100/100 (100%)] Train loss=0.047263 Test loss=0.516280 Current lr=[4.951888602991508e-09]

Fold[5] Best Result: acc=90.29827315541601 sen=85.76158940397352, spe=91.83359013867488, auc=0.95100512389273!
[0/23] Train loss=1.3992042541503906
[5/23] Train loss=1.4747246503829956
[10/23] Train loss=1.3722646236419678
[15/23] Train loss=1.2381250858306885
[20/23] Train loss=1.1474202871322632
Test set avg_accuracy=75.78% avg_sensitivity=7.07%, avg_specificity=96.45% avg_auc=0.7288
Best model saved!! Metric=-73.81976072532784!!
Fold[6] Epoch: 1 [1/100 (1%)] Train loss=1.313090 Test loss=0.501482 Current lr=[4.263712153319496e-05]

[0/23] Train loss=1.1080055236816406
[5/23] Train loss=1.0427354574203491
[10/23] Train loss=1.187501311302185
[15/23] Train loss=0.9436569809913635
[20/23] Train loss=0.8674272894859314
Test set avg_accuracy=81.07% avg_sensitivity=61.41%, avg_specificity=86.98% avg_auc=0.8550
Best model saved!! Metric=-11.053518016839124!!
Fold[6] Epoch: 2 [2/100 (2%)] Train loss=1.028593 Test loss=0.459669 Current lr=[5.051950942452628e-05]

[0/23] Train loss=0.8944488763809204
[5/23] Train loss=0.9738190174102783
[10/23] Train loss=1.0350016355514526
[15/23] Train loss=0.8145105242729187
[20/23] Train loss=0.750812828540802
Test set avg_accuracy=83.23% avg_sensitivity=53.88%, avg_specificity=92.06% avg_auc=0.8661
Best model saved!! Metric=-10.229042838344945!!
Fold[6] Epoch: 3 [3/100 (3%)] Train loss=0.901009 Test loss=0.455289 Current lr=[6.356055194548904e-05]

[0/23] Train loss=0.8145375847816467
[5/23] Train loss=0.9573402404785156
[10/23] Train loss=1.0114836692810059
[15/23] Train loss=0.741396427154541
[20/23] Train loss=0.6934593319892883
Test set avg_accuracy=84.62% avg_sensitivity=54.20%, avg_specificity=93.77% avg_auc=0.8856
Best model saved!! Metric=-4.848924495750566!!
Fold[6] Epoch: 4 [4/100 (4%)] Train loss=0.855938 Test loss=0.393312 Current lr=[8.161695403755248e-05]

[0/23] Train loss=0.7539157867431641
[5/23] Train loss=0.9363932609558105
[10/23] Train loss=0.9796033501625061
[15/23] Train loss=0.7139647603034973
[20/23] Train loss=0.6384748816490173
Test set avg_accuracy=87.20% avg_sensitivity=67.52%, avg_specificity=93.13% avg_auc=0.9196
Best model saved!! Metric=13.806636956426955!!
Fold[6] Epoch: 5 [5/100 (5%)] Train loss=0.814075 Test loss=0.319611 Current lr=[0.00010449031183917899]

[0/23] Train loss=0.7097590565681458
[5/23] Train loss=0.9039623737335205
[10/23] Train loss=0.9633484482765198
[15/23] Train loss=0.6598314046859741
[20/23] Train loss=0.5743988156318665
Test set avg_accuracy=89.11% avg_sensitivity=76.92%, avg_specificity=92.78% avg_auc=0.9361
Best model saved!! Metric=26.42526425991602!!
Fold[6] Epoch: 6 [6/100 (6%)] Train loss=0.780975 Test loss=0.291704 Current lr=[0.00013192929274872232]

[0/23] Train loss=0.6542795896530151
[5/23] Train loss=0.9687760472297668
[10/23] Train loss=0.9101260900497437
[15/23] Train loss=0.6499571204185486
[20/23] Train loss=0.533417284488678
Test set avg_accuracy=89.82% avg_sensitivity=82.76%, avg_specificity=91.95% avg_auc=0.9443
Best model saved!! Metric=32.952639859064774!!
Fold[6] Epoch: 7 [7/100 (7%)] Train loss=0.766939 Test loss=0.288442 Current lr=[0.00016363239706865967]

[0/23] Train loss=0.6180866360664368
[5/23] Train loss=0.9421805739402771
[10/23] Train loss=0.9130185842514038
[15/23] Train loss=0.6367118954658508
[20/23] Train loss=0.5275474786758423
Test set avg_accuracy=89.89% avg_sensitivity=80.75%, avg_specificity=92.65% avg_auc=0.9439
Fold[6] Epoch: 8 [8/100 (8%)] Train loss=0.749908 Test loss=0.282209 Current lr=[0.00019925127088619402]

[0/23] Train loss=0.5828251242637634
[5/23] Train loss=1.0265049934387207
[10/23] Train loss=0.9559206366539001
[15/23] Train loss=0.6151185631752014
[20/23] Train loss=0.48201438784599304
Test set avg_accuracy=89.21% avg_sensitivity=87.27%, avg_specificity=89.79% avg_auc=0.9462
Best model saved!! Metric=34.888865937488475!!
Fold[6] Epoch: 9 [9/100 (9%)] Train loss=0.736415 Test loss=0.332277 Current lr=[0.00023839453378827395]

[0/23] Train loss=0.5390679836273193
[5/23] Train loss=1.0284103155136108
[10/23] Train loss=0.912676215171814
[15/23] Train loss=0.6034443974494934
[20/23] Train loss=0.4610136151313782
Test set avg_accuracy=90.71% avg_sensitivity=84.67%, avg_specificity=92.52% avg_auc=0.9468
Best model saved!! Metric=36.58454286540781!!
Fold[6] Epoch: 10 [10/100 (10%)] Train loss=0.726388 Test loss=0.291814 Current lr=[0.00028063207935207196]

[0/23] Train loss=0.5370506048202515
[5/23] Train loss=0.9328318238258362
[10/23] Train loss=0.8509171009063721
[15/23] Train loss=0.5458815693855286
[20/23] Train loss=0.47725388407707214
Test set avg_accuracy=89.60% avg_sensitivity=88.37%, avg_specificity=89.97% avg_auc=0.9496
Best model saved!! Metric=36.89139433394868!!
Fold[6] Epoch: 11 [11/100 (11%)] Train loss=0.698235 Test loss=0.305047 Current lr=[0.0003254998011571065]

[0/23] Train loss=0.538375735282898
[5/23] Train loss=0.9323993921279907
[10/23] Train loss=0.9403128623962402
[15/23] Train loss=0.5308231115341187
[20/23] Train loss=0.4921049177646637
Test set avg_accuracy=89.36% avg_sensitivity=87.59%, avg_specificity=89.89% avg_auc=0.9516
Fold[6] Epoch: 12 [12/100 (12%)] Train loss=0.705184 Test loss=0.299772 Current lr=[0.0003725046923895547]

[0/23] Train loss=0.49993306398391724
[5/23] Train loss=0.952159583568573
[10/23] Train loss=0.8421492576599121
[15/23] Train loss=0.5343401432037354
[20/23] Train loss=0.4344629943370819
Test set avg_accuracy=90.15% avg_sensitivity=87.41%, avg_specificity=90.97% avg_auc=0.9528
Best model saved!! Metric=37.811563236654266!!
Fold[6] Epoch: 13 [13/100 (13%)] Train loss=0.672899 Test loss=0.312249 Current lr=[0.0004211302630042728]

[0/23] Train loss=0.5035945177078247
[5/23] Train loss=0.8497851490974426
[10/23] Train loss=0.8472431898117065
[15/23] Train loss=0.5059218406677246
[20/23] Train loss=0.44690361618995667
Test set avg_accuracy=89.81% avg_sensitivity=88.32%, avg_specificity=90.26% avg_auc=0.9526
Fold[6] Epoch: 14 [14/100 (14%)] Train loss=0.654419 Test loss=0.307866 Current lr=[0.0004708422149207104]

[0/23] Train loss=0.5045804381370544
[5/23] Train loss=0.9273836612701416
[10/23] Train loss=0.8654598593711853
[15/23] Train loss=0.5228168368339539
[20/23] Train loss=0.4530441462993622
Test set avg_accuracy=89.51% avg_sensitivity=90.24%, avg_specificity=89.30% avg_auc=0.9540
Best model saved!! Metric=38.448521898613144!!
Fold[6] Epoch: 15 [15/100 (15%)] Train loss=0.667936 Test loss=0.303436 Current lr=[0.0005210943128936348]

[0/23] Train loss=0.4944000542163849
[5/23] Train loss=0.8724696040153503
[10/23] Train loss=0.8244352340698242
[15/23] Train loss=0.5139870047569275
[20/23] Train loss=0.42672136425971985
Test set avg_accuracy=91.20% avg_sensitivity=81.98%, avg_specificity=93.98% avg_auc=0.9490
Fold[6] Epoch: 16 [16/100 (16%)] Train loss=0.654313 Test loss=0.258100 Current lr=[0.0005713343865494929]

[0/23] Train loss=0.4892052710056305
[5/23] Train loss=0.8635610938072205
[10/23] Train loss=0.7562585473060608
[15/23] Train loss=0.48926153779029846
[20/23] Train loss=0.44897955656051636
Test set avg_accuracy=90.57% avg_sensitivity=87.91%, avg_specificity=91.37% avg_auc=0.9531
Best model saved!! Metric=39.15676718302424!!
Fold[6] Epoch: 17 [17/100 (17%)] Train loss=0.639507 Test loss=0.279945 Current lr=[0.0006210103976380052]

[0/23] Train loss=0.5088508725166321
[5/23] Train loss=0.8543432950973511
[10/23] Train loss=0.8152786493301392
[15/23] Train loss=0.5048262476921082
[20/23] Train loss=0.4462513029575348
Test set avg_accuracy=91.03% avg_sensitivity=84.31%, avg_specificity=93.06% avg_auc=0.9536
Fold[6] Epoch: 18 [18/100 (18%)] Train loss=0.645893 Test loss=0.248655 Current lr=[0.0006695765058319851]

[0/23] Train loss=0.5091765522956848
[5/23] Train loss=0.8142557740211487
[10/23] Train loss=0.7101156115531921
[15/23] Train loss=0.47503605484962463
[20/23] Train loss=0.4580841362476349
Test set avg_accuracy=90.97% avg_sensitivity=86.36%, avg_specificity=92.36% avg_auc=0.9539
Fold[6] Epoch: 19 [19/100 (19%)] Train loss=0.625278 Test loss=0.254873 Current lr=[0.0007164990664243417]

[0/23] Train loss=0.5199953317642212
[5/23] Train loss=0.8077672123908997
[10/23] Train loss=0.7787393927574158
[15/23] Train loss=0.4551006555557251
[20/23] Train loss=0.4129413664340973
Test set avg_accuracy=90.20% avg_sensitivity=84.49%, avg_specificity=91.92% avg_auc=0.9528
Fold[6] Epoch: 20 [20/100 (20%)] Train loss=0.622793 Test loss=0.257679 Current lr=[0.0007612624940195301]

[0/23] Train loss=0.49379396438598633
[5/23] Train loss=0.8128464818000793
[10/23] Train loss=0.731565535068512
[15/23] Train loss=0.49397534132003784
[20/23] Train loss=0.427396684885025
Test set avg_accuracy=90.26% avg_sensitivity=83.99%, avg_specificity=92.15% avg_auc=0.9500
Fold[6] Epoch: 21 [21/100 (21%)] Train loss=0.621811 Test loss=0.262604 Current lr=[0.000803374927789172]

[0/23] Train loss=0.5052044987678528
[5/23] Train loss=0.7839192748069763
[10/23] Train loss=0.7130887508392334
[15/23] Train loss=0.4891609251499176
[20/23] Train loss=0.42736247181892395
Test set avg_accuracy=90.71% avg_sensitivity=83.58%, avg_specificity=92.85% avg_auc=0.9533
Fold[6] Epoch: 22 [22/100 (22%)] Train loss=0.609027 Test loss=0.256395 Current lr=[0.0008423736360419787]

[0/23] Train loss=0.5032548904418945
[5/23] Train loss=0.7949531078338623
[10/23] Train loss=0.725496232509613
[15/23] Train loss=0.4415076971054077
[20/23] Train loss=0.4479476809501648
Test set avg_accuracy=91.47% avg_sensitivity=80.06%, avg_specificity=94.90% avg_auc=0.9557
Fold[6] Epoch: 23 [23/100 (23%)] Train loss=0.599565 Test loss=0.234367 Current lr=[0.0008778301007225328]

[0/23] Train loss=0.5028527975082397
[5/23] Train loss=0.6716964244842529
[10/23] Train loss=0.6727166175842285
[15/23] Train loss=0.4607623219490051
[20/23] Train loss=0.41889268159866333
Test set avg_accuracy=90.57% avg_sensitivity=85.40%, avg_specificity=92.12% avg_auc=0.9532
Fold[6] Epoch: 24 [24/100 (24%)] Train loss=0.579397 Test loss=0.254081 Current lr=[0.0009093547259704173]

[0/23] Train loss=0.46558305621147156
[5/23] Train loss=0.7137212753295898
[10/23] Train loss=0.6905538439750671
[15/23] Train loss=0.45438680052757263
[20/23] Train loss=0.46037983894348145
Test set avg_accuracy=91.50% avg_sensitivity=85.81%, avg_specificity=93.21% avg_auc=0.9558
Best model saved!! Metric=40.09908704313722!!
Fold[6] Epoch: 25 [25/100 (25%)] Train loss=0.582323 Test loss=0.252492 Current lr=[0.0009366011190020192]

[0/23] Train loss=0.48193061351776123
[5/23] Train loss=0.6991292238235474
[10/23] Train loss=0.6874790787696838
[15/23] Train loss=0.4150046110153198
[20/23] Train loss=0.4612753987312317
Test set avg_accuracy=90.98% avg_sensitivity=77.10%, avg_specificity=95.16% avg_auc=0.9497
Fold[6] Epoch: 26 [26/100 (26%)] Train loss=0.585883 Test loss=0.241193 Current lr=[0.0009592698962766488]

[0/23] Train loss=0.4663694500923157
[5/23] Train loss=0.7823283672332764
[10/23] Train loss=0.6658501625061035
[15/23] Train loss=0.4020863473415375
[20/23] Train loss=0.41078460216522217
Test set avg_accuracy=90.56% avg_sensitivity=87.09%, avg_specificity=91.60% avg_auc=0.9560
Fold[6] Epoch: 27 [27/100 (27%)] Train loss=0.583132 Test loss=0.253358 Current lr=[0.0009771119731247974]

[0/23] Train loss=0.4722040593624115
[5/23] Train loss=0.6953721046447754
[10/23] Train loss=0.692258358001709
[15/23] Train loss=0.4104693531990051
[20/23] Train loss=0.3859803080558777
Test set avg_accuracy=89.95% avg_sensitivity=85.72%, avg_specificity=91.22% avg_auc=0.9518
Fold[6] Epoch: 28 [28/100 (28%)] Train loss=0.565087 Test loss=0.270905 Current lr=[0.0009899313006920766]

[0/23] Train loss=0.48805850744247437
[5/23] Train loss=0.7718495726585388
[10/23] Train loss=0.7020581960678101
[15/23] Train loss=0.430318146944046
[20/23] Train loss=0.4306885898113251
Test set avg_accuracy=89.81% avg_sensitivity=86.27%, avg_specificity=90.88% avg_auc=0.9514
Fold[6] Epoch: 29 [29/100 (29%)] Train loss=0.575250 Test loss=0.278906 Current lr=[0.0009975870201252835]

[0/23] Train loss=0.4577002227306366
[5/23] Train loss=0.6911605596542358
[10/23] Train loss=0.7112656235694885
[15/23] Train loss=0.45123323798179626
[20/23] Train loss=0.3774351477622986
Test set avg_accuracy=90.37% avg_sensitivity=78.06%, avg_specificity=94.07% avg_auc=0.9437
Fold[6] Epoch: 30 [30/100 (30%)] Train loss=0.564384 Test loss=0.264143 Current lr=[0.000999999048111397]

[0/23] Train loss=0.47010067105293274
[5/23] Train loss=0.7178572416305542
[10/23] Train loss=0.6963701248168945
[15/23] Train loss=0.4317050278186798
[20/23] Train loss=0.3864804208278656
Test set avg_accuracy=90.86% avg_sensitivity=82.03%, avg_specificity=93.52% avg_auc=0.9495
Fold[6] Epoch: 31 [31/100 (31%)] Train loss=0.556978 Test loss=0.256585 Current lr=[0.000999451812190372]

[0/23] Train loss=0.45029646158218384
[5/23] Train loss=0.6824617385864258
[10/23] Train loss=0.6922347545623779
[15/23] Train loss=0.44771644473075867
[20/23] Train loss=0.38785940408706665
Test set avg_accuracy=90.73% avg_sensitivity=77.05%, avg_specificity=94.84% avg_auc=0.9416
Fold[6] Epoch: 32 [32/100 (32%)] Train loss=0.554202 Test loss=0.280498 Current lr=[0.0009978987508156897]

[0/23] Train loss=0.440015971660614
[5/23] Train loss=0.6275268793106079
[10/23] Train loss=0.6936883926391602
[15/23] Train loss=0.4521559476852417
[20/23] Train loss=0.40752556920051575
Test set avg_accuracy=91.13% avg_sensitivity=81.66%, avg_specificity=93.98% avg_auc=0.9498
Fold[6] Epoch: 33 [33/100 (33%)] Train loss=0.542721 Test loss=0.254434 Current lr=[0.0009953429916462733]

[0/23] Train loss=0.4472569525241852
[5/23] Train loss=0.6279047131538391
[10/23] Train loss=0.659641444683075
[15/23] Train loss=0.4300314784049988
[20/23] Train loss=0.38878917694091797
Test set avg_accuracy=90.37% avg_sensitivity=86.13%, avg_specificity=91.64% avg_auc=0.9516
Fold[6] Epoch: 34 [34/100 (34%)] Train loss=0.527105 Test loss=0.272476 Current lr=[0.000991789681640963]

[0/23] Train loss=0.46036458015441895
[5/23] Train loss=0.6556433439254761
[10/23] Train loss=0.6747490763664246
[15/23] Train loss=0.3812488317489624
[20/23] Train loss=0.39649105072021484
Test set avg_accuracy=90.82% avg_sensitivity=86.91%, avg_specificity=92.00% avg_auc=0.9518
Fold[6] Epoch: 35 [35/100 (35%)] Train loss=0.531908 Test loss=0.271554 Current lr=[0.0009872459766932253]

[0/23] Train loss=0.4336091876029968
[5/23] Train loss=0.6453531980514526
[10/23] Train loss=0.6812859177589417
[15/23] Train loss=0.42253732681274414
[20/23] Train loss=0.38381943106651306
Test set avg_accuracy=90.06% avg_sensitivity=84.58%, avg_specificity=91.71% avg_auc=0.9496
Fold[6] Epoch: 36 [36/100 (36%)] Train loss=0.510224 Test loss=0.288092 Current lr=[0.0009817210272201372]

[0/23] Train loss=0.43397605419158936
[5/23] Train loss=0.6186599135398865
[10/23] Train loss=0.6876523494720459
[15/23] Train loss=0.41216301918029785
[20/23] Train loss=0.36545220017433167
Test set avg_accuracy=89.57% avg_sensitivity=86.91%, avg_specificity=90.37% avg_auc=0.9525
Fold[6] Epoch: 37 [37/100 (37%)] Train loss=0.507813 Test loss=0.297556 Current lr=[0.0009752259597346622]

[0/23] Train loss=0.41558563709259033
[5/23] Train loss=0.6172689199447632
[10/23] Train loss=0.6807533502578735
[15/23] Train loss=0.3847705125808716
[20/23] Train loss=0.34694838523864746
Test set avg_accuracy=89.41% avg_sensitivity=88.00%, avg_specificity=89.83% avg_auc=0.9485
Fold[6] Epoch: 38 [38/100 (38%)] Train loss=0.504083 Test loss=0.320243 Current lr=[0.000967773854438336]

[0/23] Train loss=0.4229564368724823
[5/23] Train loss=0.6012946963310242
[10/23] Train loss=0.7107970118522644
[15/23] Train loss=0.4164324104785919
[20/23] Train loss=0.36088746786117554
Test set avg_accuracy=90.18% avg_sensitivity=86.72%, avg_specificity=91.22% avg_auc=0.9508
Fold[6] Epoch: 39 [39/100 (39%)] Train loss=0.511213 Test loss=0.303360 Current lr=[0.000959379718879479]

[0/23] Train loss=0.43263667821884155
[5/23] Train loss=0.629008948802948
[10/23] Train loss=0.6733985543251038
[15/23] Train loss=0.39724764227867126
[20/23] Train loss=0.3470565676689148
Test set avg_accuracy=87.82% avg_sensitivity=90.33%, avg_specificity=87.06% avg_auc=0.9534
Fold[6] Epoch: 40 [40/100 (40%)] Train loss=0.488933 Test loss=0.361626 Current lr=[0.0009500604577299936]

[0/23] Train loss=0.37832164764404297
[5/23] Train loss=0.622608482837677
[10/23] Train loss=0.6661224961280823
[15/23] Train loss=0.3717248737812042
[20/23] Train loss=0.35014718770980835
Test set avg_accuracy=89.64% avg_sensitivity=89.28%, avg_specificity=89.75% avg_auc=0.9522
Fold[6] Epoch: 41 [41/100 (41%)] Train loss=0.484344 Test loss=0.305834 Current lr=[0.0009398348387416027]

[0/23] Train loss=0.41184407472610474
[5/23] Train loss=0.5620970726013184
[10/23] Train loss=0.7686436176300049
[15/23] Train loss=0.4042629301548004
[20/23] Train loss=0.3466743230819702
Test set avg_accuracy=88.97% avg_sensitivity=89.55%, avg_specificity=88.79% avg_auc=0.9513
Fold[6] Epoch: 42 [42/100 (42%)] Train loss=0.487517 Test loss=0.350346 Current lr=[0.000928723454950097]

[0/23] Train loss=0.4213383197784424
[5/23] Train loss=0.6239067912101746
[10/23] Train loss=0.625728189945221
[15/23] Train loss=0.3825504779815674
[20/23] Train loss=0.3122519552707672
Test set avg_accuracy=89.67% avg_sensitivity=89.64%, avg_specificity=89.68% avg_auc=0.9516
Fold[6] Epoch: 43 [43/100 (43%)] Train loss=0.471725 Test loss=0.316218 Current lr=[0.0009167486832037001]

[0/23] Train loss=0.4110698699951172
[5/23] Train loss=0.5968832969665527
[10/23] Train loss=0.6218160390853882
[15/23] Train loss=0.36263227462768555
[20/23] Train loss=0.33171120285987854
Test set avg_accuracy=89.97% avg_sensitivity=87.45%, avg_specificity=90.72% avg_auc=0.9514
Fold[6] Epoch: 44 [44/100 (44%)] Train loss=0.464864 Test loss=0.328686 Current lr=[0.0009039346390990754]

[0/23] Train loss=0.37997499108314514
[5/23] Train loss=0.5947942733764648
[10/23] Train loss=0.6196264028549194
[15/23] Train loss=0.33820128440856934
[20/23] Train loss=0.29541492462158203
Test set avg_accuracy=90.09% avg_sensitivity=88.09%, avg_specificity=90.70% avg_auc=0.9496
Fold[6] Epoch: 45 [45/100 (45%)] Train loss=0.460976 Test loss=0.345997 Current lr=[0.000890307128415723]

[0/23] Train loss=0.3883856236934662
[5/23] Train loss=0.47698891162872314
[10/23] Train loss=0.6040130257606506
[15/23] Train loss=0.3108309805393219
[20/23] Train loss=0.28408607840538025
Test set avg_accuracy=89.09% avg_sensitivity=88.00%, avg_specificity=89.42% avg_auc=0.9498
Fold[6] Epoch: 46 [46/100 (46%)] Train loss=0.427530 Test loss=0.367175 Current lr=[0.0008758935951465738]

[0/23] Train loss=0.3880169689655304
[5/23] Train loss=0.5063140392303467
[10/23] Train loss=0.5300070643424988
[15/23] Train loss=0.3402153253555298
[20/23] Train loss=0.30585160851478577
Test set avg_accuracy=90.56% avg_sensitivity=87.91%, avg_specificity=91.36% avg_auc=0.9509
Fold[6] Epoch: 47 [47/100 (47%)] Train loss=0.430665 Test loss=0.336022 Current lr=[0.0008607230662294413]

[0/23] Train loss=0.3598768711090088
[5/23] Train loss=0.4972931742668152
[10/23] Train loss=0.521929144859314
[15/23] Train loss=0.3320915102958679
[20/23] Train loss=0.282947838306427
Test set avg_accuracy=90.21% avg_sensitivity=88.32%, avg_specificity=90.78% avg_auc=0.9509
Fold[6] Epoch: 48 [48/100 (48%)] Train loss=0.402985 Test loss=0.345176 Current lr=[0.0008448260930906307]

[0/23] Train loss=0.35230377316474915
[5/23] Train loss=0.46893081068992615
[10/23] Train loss=0.5274180769920349
[15/23] Train loss=0.3230302035808563
[20/23] Train loss=0.27122223377227783
Test set avg_accuracy=89.75% avg_sensitivity=88.91%, avg_specificity=90.00% avg_auc=0.9507
Fold[6] Epoch: 49 [49/100 (49%)] Train loss=0.387365 Test loss=0.371025 Current lr=[0.0008282346901184324]

[0/23] Train loss=0.3346826434135437
[5/23] Train loss=0.42644307017326355
[10/23] Train loss=0.4653889536857605
[15/23] Train loss=0.3267251253128052
[20/23] Train loss=0.25291019678115845
Test set avg_accuracy=90.33% avg_sensitivity=87.73%, avg_specificity=91.11% avg_auc=0.9500
Fold[6] Epoch: 50 [50/100 (50%)] Train loss=0.363742 Test loss=0.365462 Current lr=[0.000810982270190405]

[0/23] Train loss=0.3394410312175751
[5/23] Train loss=0.40810075402259827
[10/23] Train loss=0.42055222392082214
[15/23] Train loss=0.2999342381954193
[20/23] Train loss=0.23963208496570587
Test set avg_accuracy=90.28% avg_sensitivity=88.18%, avg_specificity=90.92% avg_auc=0.9532
Fold[6] Epoch: 51 [51/100 (51%)] Train loss=0.351822 Test loss=0.332884 Current lr=[0.0007931035773842862]

[0/23] Train loss=0.29241377115249634
[5/23] Train loss=0.37541142106056213
[10/23] Train loss=0.3864511549472809
[15/23] Train loss=0.2833540439605713
[20/23] Train loss=0.24276229739189148
Test set avg_accuracy=90.08% avg_sensitivity=83.80%, avg_specificity=91.97% avg_auc=0.9492
Fold[6] Epoch: 52 [52/100 (52%)] Train loss=0.334312 Test loss=0.325071 Current lr=[0.0007746346170080441]

[0/23] Train loss=0.3098519444465637
[5/23] Train loss=0.3545733094215393
[10/23] Train loss=0.3593441843986511
[15/23] Train loss=0.30580753087997437
[20/23] Train loss=0.23258544504642487
Test set avg_accuracy=89.94% avg_sensitivity=88.46%, avg_specificity=90.38% avg_auc=0.9503
Fold[6] Epoch: 53 [53/100 (53%)] Train loss=0.328673 Test loss=0.347822 Current lr=[0.0007556125830899786]

[0/23] Train loss=0.31779298186302185
[5/23] Train loss=0.3199270963668823
[10/23] Train loss=0.3586641550064087
[15/23] Train loss=0.2666117548942566
[20/23] Train loss=0.22371792793273926
Test set avg_accuracy=89.62% avg_sensitivity=89.28%, avg_specificity=89.72% avg_auc=0.9507
Fold[6] Epoch: 54 [54/100 (54%)] Train loss=0.306425 Test loss=0.343661 Current lr=[0.0007360757834748981]

[0/23] Train loss=0.276641845703125
[5/23] Train loss=0.3396013081073761
[10/23] Train loss=0.32136648893356323
[15/23] Train loss=0.2644878029823303
[20/23] Train loss=0.24550622701644897
Test set avg_accuracy=89.70% avg_sensitivity=85.90%, avg_specificity=90.85% avg_auc=0.9468
Fold[6] Epoch: 55 [55/100 (55%)] Train loss=0.291545 Test loss=0.319244 Current lr=[0.000716063562677219]

[0/23] Train loss=0.2886148989200592
[5/23] Train loss=0.3033744692802429
[10/23] Train loss=0.3222942650318146
[15/23] Train loss=0.2472326159477234
[20/23] Train loss=0.2139154076576233
Test set avg_accuracy=89.94% avg_sensitivity=88.50%, avg_specificity=90.37% avg_auc=0.9499
Fold[6] Epoch: 56 [56/100 (56%)] Train loss=0.281590 Test loss=0.332577 Current lr=[0.0006956162226463489]

[0/23] Train loss=0.25417768955230713
[5/23] Train loss=0.35894420742988586
[10/23] Train loss=0.2890295684337616
[15/23] Train loss=0.2452114373445511
[20/23] Train loss=0.19679804146289825
Test set avg_accuracy=90.42% avg_sensitivity=84.67%, avg_specificity=92.15% avg_auc=0.9486
Fold[6] Epoch: 57 [57/100 (57%)] Train loss=0.269727 Test loss=0.318026 Current lr=[0.0006747749416039243]

[0/23] Train loss=0.2427980899810791
[5/23] Train loss=0.31684231758117676
[10/23] Train loss=0.2790866494178772
[15/23] Train loss=0.23129041492938995
[20/23] Train loss=0.20988643169403076
Test set avg_accuracy=89.31% avg_sensitivity=89.32%, avg_specificity=89.31% avg_auc=0.9465
Fold[6] Epoch: 58 [58/100 (58%)] Train loss=0.252623 Test loss=0.374094 Current lr=[0.000653581691116352]

[0/23] Train loss=0.22742965817451477
[5/23] Train loss=0.29163986444473267
[10/23] Train loss=0.2468227744102478
[15/23] Train loss=0.21283438801765442
[20/23] Train loss=0.20159971714019775
Test set avg_accuracy=89.85% avg_sensitivity=87.14%, avg_specificity=90.67% avg_auc=0.9478
Fold[6] Epoch: 59 [59/100 (59%)] Train loss=0.241390 Test loss=0.324562 Current lr=[0.0006320791515696602]

[0/23] Train loss=0.24496711790561676
[5/23] Train loss=0.25431665778160095
[10/23] Train loss=0.22115397453308105
[15/23] Train loss=0.21244998276233673
[20/23] Train loss=0.17912712693214417
Test set avg_accuracy=90.46% avg_sensitivity=84.44%, avg_specificity=92.27% avg_auc=0.9458
Fold[6] Epoch: 60 [60/100 (60%)] Train loss=0.226245 Test loss=0.326539 Current lr=[0.0006103106262168818]

[0/23] Train loss=0.2134215086698532
[5/23] Train loss=0.25049489736557007
[10/23] Train loss=0.2152707874774933
[15/23] Train loss=0.1957789957523346
[20/23] Train loss=0.17206917703151703
Test set avg_accuracy=90.90% avg_sensitivity=83.90%, avg_specificity=93.00% avg_auc=0.9464
Fold[6] Epoch: 61 [61/100 (61%)] Train loss=0.207697 Test loss=0.350863 Current lr=[0.0005883199539710647]

[0/23] Train loss=0.19258137047290802
[5/23] Train loss=0.24558450281620026
[10/23] Train loss=0.2047937959432602
[15/23] Train loss=0.16867689788341522
[20/23] Train loss=0.17141234874725342
Test set avg_accuracy=90.82% avg_sensitivity=84.99%, avg_specificity=92.58% avg_auc=0.9456
Fold[6] Epoch: 62 [62/100 (62%)] Train loss=0.197936 Test loss=0.382693 Current lr=[0.0005661514211195354]

[0/23] Train loss=0.1823693960905075
[5/23] Train loss=0.2232711911201477
[10/23] Train loss=0.19999362528324127
[15/23] Train loss=0.17301662266254425
[20/23] Train loss=0.1429920792579651
Test set avg_accuracy=91.20% avg_sensitivity=87.36%, avg_specificity=92.36% avg_auc=0.9489
Fold[6] Epoch: 63 [63/100 (63%)] Train loss=0.183697 Test loss=0.376578 Current lr=[0.00054384967213721]

[0/23] Train loss=0.1849544495344162
[5/23] Train loss=0.2484573870897293
[10/23] Train loss=0.22076043486595154
[15/23] Train loss=0.1557939201593399
[20/23] Train loss=0.14541465044021606
Test set avg_accuracy=90.95% avg_sensitivity=80.79%, avg_specificity=94.00% avg_auc=0.9437
Fold[6] Epoch: 64 [64/100 (64%)] Train loss=0.180012 Test loss=0.393192 Current lr=[0.000521459619778564]

[0/23] Train loss=0.17790891230106354
[5/23] Train loss=0.2177611142396927
[10/23] Train loss=0.18781204521656036
[15/23] Train loss=0.1503671556711197
[20/23] Train loss=0.1389441043138504
Test set avg_accuracy=90.63% avg_sensitivity=81.89%, avg_specificity=93.26% avg_auc=0.9457
Fold[6] Epoch: 65 [65/100 (65%)] Train loss=0.169317 Test loss=0.384514 Current lr=[0.0004990263546293204]

[0/23] Train loss=0.167711079120636
[5/23] Train loss=0.210225448012352
[10/23] Train loss=0.1662755161523819
[15/23] Train loss=0.16513963043689728
[20/23] Train loss=0.13173051178455353
Test set avg_accuracy=91.36% avg_sensitivity=84.95%, avg_specificity=93.29% avg_auc=0.9503
Fold[6] Epoch: 66 [66/100 (66%)] Train loss=0.162738 Test loss=0.375851 Current lr=[0.000476595054300012]

[0/23] Train loss=0.14926227927207947
[5/23] Train loss=0.18545855581760406
[10/23] Train loss=0.15289460122585297
[15/23] Train loss=0.16685527563095093
[20/23] Train loss=0.1207328587770462
Test set avg_accuracy=91.08% avg_sensitivity=85.54%, avg_specificity=92.74% avg_auc=0.9515
Fold[6] Epoch: 67 [67/100 (67%)] Train loss=0.157618 Test loss=0.370375 Current lr=[0.0004542108924442853]

[0/23] Train loss=0.1435575634241104
[5/23] Train loss=0.17191115021705627
[10/23] Train loss=0.16728633642196655
[15/23] Train loss=0.15005196630954742
[20/23] Train loss=0.11386226117610931
Test set avg_accuracy=90.57% avg_sensitivity=87.64%, avg_specificity=91.45% avg_auc=0.9491
Fold[6] Epoch: 68 [68/100 (68%)] Train loss=0.145288 Test loss=0.407834 Current lr=[0.000431918947785175]

[0/23] Train loss=0.14441201090812683
[5/23] Train loss=0.149061918258667
[10/23] Train loss=0.15640729665756226
[15/23] Train loss=0.14314159750938416
[20/23] Train loss=0.10543728619813919
Test set avg_accuracy=90.22% avg_sensitivity=87.50%, avg_specificity=91.04% avg_auc=0.9503
Fold[6] Epoch: 69 [69/100 (69%)] Train loss=0.137229 Test loss=0.469306 Current lr=[0.0004097641133325535]

[0/23] Train loss=0.14514821767807007
[5/23] Train loss=0.15560728311538696
[10/23] Train loss=0.14666658639907837
[15/23] Train loss=0.14138470590114594
[20/23] Train loss=0.11873214691877365
Test set avg_accuracy=90.39% avg_sensitivity=87.82%, avg_specificity=91.16% avg_auc=0.9518
Fold[6] Epoch: 70 [70/100 (70%)] Train loss=0.133849 Test loss=0.455311 Current lr=[0.00038779100597458526]

[0/23] Train loss=0.13572347164154053
[5/23] Train loss=0.11528962105512619
[10/23] Train loss=0.1571650207042694
[15/23] Train loss=0.12299708276987076
[20/23] Train loss=0.10101158916950226
Test set avg_accuracy=89.43% avg_sensitivity=88.37%, avg_specificity=89.75% avg_auc=0.9496
Fold[6] Epoch: 71 [71/100 (71%)] Train loss=0.123092 Test loss=0.497791 Current lr=[0.0003660438766252499]

[0/23] Train loss=0.12310949712991714
[5/23] Train loss=0.12371779978275299
[10/23] Train loss=0.11314629763364792
[15/23] Train loss=0.10974189639091492
[20/23] Train loss=0.08210575580596924
Test set avg_accuracy=89.81% avg_sensitivity=88.64%, avg_specificity=90.16% avg_auc=0.9503
Fold[6] Epoch: 72 [72/100 (72%)] Train loss=0.113516 Test loss=0.521152 Current lr=[0.0003445665211088922]

[0/23] Train loss=0.11919298022985458
[5/23] Train loss=0.12536996603012085
[10/23] Train loss=0.10804161429405212
[15/23] Train loss=0.10306058824062347
[20/23] Train loss=0.09353335201740265
Test set avg_accuracy=89.98% avg_sensitivity=87.27%, avg_specificity=90.79% avg_auc=0.9497
Fold[6] Epoch: 73 [73/100 (73%)] Train loss=0.108232 Test loss=0.486714 Current lr=[0.00032340219196125877]

[0/23] Train loss=0.091384656727314
[5/23] Train loss=0.12677662074565887
[10/23] Train loss=0.10662662982940674
[15/23] Train loss=0.11528543382883072
[20/23] Train loss=0.08734443038702011
Test set avg_accuracy=91.07% avg_sensitivity=86.77%, avg_specificity=92.36% avg_auc=0.9514
Fold[6] Epoch: 74 [74/100 (74%)] Train loss=0.103671 Test loss=0.460569 Current lr=[0.0003025935113246488]

[0/23] Train loss=0.08835542947053909
[5/23] Train loss=0.12892550230026245
[10/23] Train loss=0.10261763632297516
[15/23] Train loss=0.08922096341848373
[20/23] Train loss=0.08444435149431229
Test set avg_accuracy=90.61% avg_sensitivity=83.99%, avg_specificity=92.60% avg_auc=0.9494
Fold[6] Epoch: 75 [75/100 (75%)] Train loss=0.097246 Test loss=0.448601 Current lr=[0.0002821823851125901]

[0/23] Train loss=0.080888532102108
[5/23] Train loss=0.11000097543001175
[10/23] Train loss=0.09136012941598892
[15/23] Train loss=0.08633989095687866
[20/23] Train loss=0.06662405282258987
Test set avg_accuracy=90.95% avg_sensitivity=83.85%, avg_specificity=93.08% avg_auc=0.9491
Fold[6] Epoch: 76 [76/100 (76%)] Train loss=0.085357 Test loss=0.470159 Current lr=[0.00026220991861690765]

[0/23] Train loss=0.08187536150217056
[5/23] Train loss=0.09530165791511536
[10/23] Train loss=0.08598393201828003
[15/23] Train loss=0.07742471247911453
[20/23] Train loss=0.0655311793088913
Test set avg_accuracy=90.95% avg_sensitivity=85.45%, avg_specificity=92.60% avg_auc=0.9500
Fold[6] Epoch: 77 [77/100 (77%)] Train loss=0.079876 Test loss=0.473393 Current lr=[0.00024271633372713536]

[0/23] Train loss=0.07901047170162201
[5/23] Train loss=0.08987053483724594
[10/23] Train loss=0.08521737158298492
[15/23] Train loss=0.08553968369960785
[20/23] Train loss=0.05987410247325897
Test set avg_accuracy=90.99% avg_sensitivity=84.85%, avg_specificity=92.84% avg_auc=0.9506
Fold[6] Epoch: 78 [78/100 (78%)] Train loss=0.080943 Test loss=0.454842 Current lr=[0.00022374088792898362]

[0/23] Train loss=0.06579813361167908
[5/23] Train loss=0.1079113706946373
[10/23] Train loss=0.0772707387804985
[15/23] Train loss=0.08435646444559097
[20/23] Train loss=0.05751302093267441
Test set avg_accuracy=91.19% avg_sensitivity=85.77%, avg_specificity=92.82% avg_auc=0.9511
Fold[6] Epoch: 79 [79/100 (79%)] Train loss=0.075016 Test loss=0.462831 Current lr=[0.00020532179524498774]

[0/23] Train loss=0.06409038603305817
[5/23] Train loss=0.08795157074928284
[10/23] Train loss=0.07771438360214233
[15/23] Train loss=0.08076908439397812
[20/23] Train loss=0.056616947054862976
Test set avg_accuracy=91.16% avg_sensitivity=84.17%, avg_specificity=93.26% avg_auc=0.9500
Fold[6] Epoch: 80 [80/100 (80%)] Train loss=0.072884 Test loss=0.492728 Current lr=[0.000187496149276552]

[0/23] Train loss=0.08410217612981796
[5/23] Train loss=0.08128612488508224
[10/23] Train loss=0.07243422418832779
[15/23] Train loss=0.07274353504180908
[20/23] Train loss=0.05357503890991211
Test set avg_accuracy=91.13% avg_sensitivity=84.95%, avg_specificity=92.99% avg_auc=0.9506
Fold[6] Epoch: 81 [81/100 (81%)] Train loss=0.072052 Test loss=0.469749 Current lr=[0.00017029984850237305]

[0/23] Train loss=0.06260192394256592
[5/23] Train loss=0.07015952467918396
[10/23] Train loss=0.0654994547367096
[15/23] Train loss=0.07611142098903656
[20/23] Train loss=0.06625846028327942
Test set avg_accuracy=90.95% avg_sensitivity=85.26%, avg_specificity=92.66% avg_auc=0.9514
Fold[6] Epoch: 82 [82/100 (82%)] Train loss=0.066760 Test loss=0.480250 Current lr=[0.00015376752398368106]

[0/23] Train loss=0.06445164978504181
[5/23] Train loss=0.08126066625118256
[10/23] Train loss=0.06540882587432861
[15/23] Train loss=0.0755213275551796
[20/23] Train loss=0.06781033426523209
Test set avg_accuracy=91.10% avg_sensitivity=84.53%, avg_specificity=93.07% avg_auc=0.9501
Fold[6] Epoch: 83 [83/100 (83%)] Train loss=0.063935 Test loss=0.525372 Current lr=[0.00013793246962189157]

[0/23] Train loss=0.05925866588950157
[5/23] Train loss=0.07781250774860382
[10/23] Train loss=0.07243543863296509
[15/23] Train loss=0.07441984862089157
[20/23] Train loss=0.0439036563038826
Test set avg_accuracy=91.29% avg_sensitivity=85.26%, avg_specificity=93.10% avg_auc=0.9500
Fold[6] Epoch: 84 [84/100 (84%)] Train loss=0.063147 Test loss=0.526191 Current lr=[0.00012282657510911843]

[0/23] Train loss=0.06626199185848236
[5/23] Train loss=0.07025661319494247
[10/23] Train loss=0.07045946270227432
[15/23] Train loss=0.06501368433237076
[20/23] Train loss=0.045791249722242355
Test set avg_accuracy=91.31% avg_sensitivity=84.99%, avg_specificity=93.21% avg_auc=0.9501
Fold[6] Epoch: 85 [85/100 (85%)] Train loss=0.061373 Test loss=0.506968 Current lr=[0.0001084802617065783]

[0/23] Train loss=0.05801338329911232
[5/23] Train loss=0.06910564750432968
[10/23] Train loss=0.05352465435862541
[15/23] Train loss=0.06480371952056885
[20/23] Train loss=0.056860122829675674
Test set avg_accuracy=91.11% avg_sensitivity=84.99%, avg_specificity=92.95% avg_auc=0.9502
Fold[6] Epoch: 86 [86/100 (86%)] Train loss=0.058410 Test loss=0.516118 Current lr=[9.492242098021878e-05]

[0/23] Train loss=0.05828823521733284
[5/23] Train loss=0.059695709496736526
[10/23] Train loss=0.057167135179042816
[15/23] Train loss=0.07283216714859009
[20/23] Train loss=0.046696171164512634
Test set avg_accuracy=91.10% avg_sensitivity=84.63%, avg_specificity=93.04% avg_auc=0.9500
Fold[6] Epoch: 87 [87/100 (87%)] Train loss=0.054995 Test loss=0.519723 Current lr=[8.218035661694964e-05]

[0/23] Train loss=0.05615666136145592
[5/23] Train loss=0.0630432516336441
[10/23] Train loss=0.060903385281562805
[15/23] Train loss=0.0637495368719101
[20/23] Train loss=0.039639975875616074
Test set avg_accuracy=91.20% avg_sensitivity=84.12%, avg_specificity=93.33% avg_auc=0.9502
Fold[6] Epoch: 88 [88/100 (88%)] Train loss=0.054425 Test loss=0.509613 Current lr=[7.02797294386511e-05]

[0/23] Train loss=0.0493888258934021
[5/23] Train loss=0.07271762937307358
[10/23] Train loss=0.05821288749575615
[15/23] Train loss=0.071714386343956
[20/23] Train loss=0.04616478085517883
Test set avg_accuracy=91.24% avg_sensitivity=84.76%, avg_specificity=93.19% avg_auc=0.9503
Fold[6] Epoch: 89 [89/100 (89%)] Train loss=0.057234 Test loss=0.511087 Current lr=[5.924450572469346e-05]

[0/23] Train loss=0.04544830322265625
[5/23] Train loss=0.06173805147409439
[10/23] Train loss=0.05594807118177414
[15/23] Train loss=0.0664902925491333
[20/23] Train loss=0.04358293488621712
Test set avg_accuracy=91.27% avg_sensitivity=84.76%, avg_specificity=93.22% avg_auc=0.9503
Fold[6] Epoch: 90 [90/100 (90%)] Train loss=0.052959 Test loss=0.512991 Current lr=[4.90969089470401e-05]

[0/23] Train loss=0.05669845640659332
[5/23] Train loss=0.06220291182398796
[10/23] Train loss=0.048901233822107315
[15/23] Train loss=0.050812724977731705
[20/23] Train loss=0.04825253412127495
Test set avg_accuracy=91.15% avg_sensitivity=84.40%, avg_specificity=93.18% avg_auc=0.9504
Fold[6] Epoch: 91 [91/100 (91%)] Train loss=0.053649 Test loss=0.521487 Current lr=[3.985737501513232e-05]

[0/23] Train loss=0.051221128553152084
[5/23] Train loss=0.05850996449589729
[10/23] Train loss=0.05319362133741379
[15/23] Train loss=0.06482547521591187
[20/23] Train loss=0.034235041588544846
Test set avg_accuracy=91.18% avg_sensitivity=84.44%, avg_specificity=93.21% avg_auc=0.9505
Fold[6] Epoch: 92 [92/100 (92%)] Train loss=0.050523 Test loss=0.523063 Current lr=[3.154451112068745e-05]

[0/23] Train loss=0.050020214170217514
[5/23] Train loss=0.06253896653652191
[10/23] Train loss=0.04991848021745682
[15/23] Train loss=0.04499777406454086
[20/23] Train loss=0.04097011312842369
Test set avg_accuracy=91.35% avg_sensitivity=84.53%, avg_specificity=93.40% avg_auc=0.9505
Fold[6] Epoch: 93 [93/100 (93%)] Train loss=0.052611 Test loss=0.514304 Current lr=[2.4175058265291265e-05]

[0/23] Train loss=0.0432899110019207
[5/23] Train loss=0.06578561663627625
[10/23] Train loss=0.055861372500658035
[15/23] Train loss=0.06309902667999268
[20/23] Train loss=0.04203394427895546
Test set avg_accuracy=91.36% avg_sensitivity=84.58%, avg_specificity=93.40% avg_auc=0.9505
Fold[6] Epoch: 94 [94/100 (94%)] Train loss=0.051976 Test loss=0.515446 Current lr=[1.7763857546248248e-05]

[0/23] Train loss=0.043744880706071854
[5/23] Train loss=0.055702898651361465
[10/23] Train loss=0.05185958743095398
[15/23] Train loss=0.06624230742454529
[20/23] Train loss=0.04285993054509163
Test set avg_accuracy=91.23% avg_sensitivity=84.63%, avg_specificity=93.22% avg_auc=0.9505
Fold[6] Epoch: 95 [95/100 (95%)] Train loss=0.050438 Test loss=0.523583 Current lr=[1.2323820268587161e-05]

[0/23] Train loss=0.04295424371957779
[5/23] Train loss=0.0691116601228714
[10/23] Train loss=0.050111886113882065
[15/23] Train loss=0.05882266163825989
[20/23] Train loss=0.041663799434900284
Test set avg_accuracy=91.24% avg_sensitivity=84.72%, avg_specificity=93.21% avg_auc=0.9504
Fold[6] Epoch: 96 [96/100 (96%)] Train loss=0.049920 Test loss=0.524110 Current lr=[7.865901943410707e-06]

[0/23] Train loss=0.04625886678695679
[5/23] Train loss=0.05625257268548012
[10/23] Train loss=0.059384409338235855
[15/23] Train loss=0.05284934118390083
[20/23] Train loss=0.03776010125875473
Test set avg_accuracy=91.23% avg_sensitivity=84.76%, avg_specificity=93.18% avg_auc=0.9504
Fold[6] Epoch: 97 [97/100 (97%)] Train loss=0.050844 Test loss=0.524437 Current lr=[4.399080224954306e-06]

[0/23] Train loss=0.04708840325474739
[5/23] Train loss=0.06024892255663872
[10/23] Train loss=0.052742213010787964
[15/23] Train loss=0.06061399728059769
[20/23] Train loss=0.047268375754356384
Test set avg_accuracy=91.24% avg_sensitivity=84.76%, avg_specificity=93.19% avg_auc=0.9504
Fold[6] Epoch: 98 [98/100 (98%)] Train loss=0.051158 Test loss=0.524525 Current lr=[1.930336830785271e-06]

[0/23] Train loss=0.04121081158518791
[5/23] Train loss=0.05540730059146881
[10/23] Train loss=0.04479549825191498
[15/23] Train loss=0.0598025806248188
[20/23] Train loss=0.038675714284181595
Test set avg_accuracy=91.26% avg_sensitivity=84.76%, avg_specificity=93.21% avg_auc=0.9505
Fold[6] Epoch: 99 [99/100 (99%)] Train loss=0.047811 Test loss=0.524580 Current lr=[4.6464348155246055e-07]

[0/23] Train loss=0.05091428756713867
[5/23] Train loss=0.054868534207344055
[10/23] Train loss=0.050185635685920715
[15/23] Train loss=0.05917404964566231
[20/23] Train loss=0.03502986580133438
Test set avg_accuracy=91.27% avg_sensitivity=84.76%, avg_specificity=93.22% avg_auc=0.9504
Fold[6] Epoch: 100 [100/100 (100%)] Train loss=0.048091 Test loss=0.524522 Current lr=[4.951888602991508e-09]

Fold[6] Best Result: acc=91.49789029535866 sen=85.81204379562044, spe=93.20801317233808, auc=0.9558113977982003!
[0/23] Train loss=1.388524055480957
[5/23] Train loss=1.444380283355713
[10/23] Train loss=1.3275208473205566
[15/23] Train loss=1.1642416715621948
[20/23] Train loss=1.0716825723648071
Test set avg_accuracy=74.82% avg_sensitivity=8.53%, avg_specificity=96.24% avg_auc=0.7341
Best model saved!! Metric=-72.9937374804485!!
Fold[7] Epoch: 1 [1/100 (1%)] Train loss=1.272659 Test loss=0.513088 Current lr=[4.263712153319496e-05]

[0/23] Train loss=1.064602017402649
[5/23] Train loss=1.053308367729187
[10/23] Train loss=1.1090877056121826
[15/23] Train loss=0.8300114274024963
[20/23] Train loss=0.8235788345336914
Test set avg_accuracy=78.78% avg_sensitivity=37.54%, avg_specificity=92.10% avg_auc=0.8146
Best model saved!! Metric=-36.11206848704239!!
Fold[7] Epoch: 2 [2/100 (2%)] Train loss=1.004079 Test loss=0.533743 Current lr=[5.051950942452628e-05]

[0/23] Train loss=0.855906069278717
[5/23] Train loss=0.9238395094871521
[10/23] Train loss=1.0869975090026855
[15/23] Train loss=0.7755332589149475
[20/23] Train loss=0.7193608283996582
Test set avg_accuracy=81.18% avg_sensitivity=40.02%, avg_specificity=94.47% avg_auc=0.8486
Best model saved!! Metric=-25.47099042744275!!
Fold[7] Epoch: 3 [3/100 (3%)] Train loss=0.898070 Test loss=0.481492 Current lr=[6.356055194548904e-05]

[0/23] Train loss=0.7882262468338013
[5/23] Train loss=0.9420644640922546
[10/23] Train loss=1.031752586364746
[15/23] Train loss=0.6944719552993774
[20/23] Train loss=0.6606848239898682
Test set avg_accuracy=84.95% avg_sensitivity=53.67%, avg_specificity=95.05% avg_auc=0.8839
Best model saved!! Metric=-3.94571426040417!!
Fold[7] Epoch: 4 [4/100 (4%)] Train loss=0.842935 Test loss=0.376465 Current lr=[8.161695403755248e-05]

[0/23] Train loss=0.7577104568481445
[5/23] Train loss=0.9335940480232239
[10/23] Train loss=0.9314387440681458
[15/23] Train loss=0.6491394639015198
[20/23] Train loss=0.5954590439796448
Test set avg_accuracy=86.09% avg_sensitivity=61.60%, avg_specificity=94.00% avg_auc=0.9019
Best model saved!! Metric=5.890993589864193!!
Fold[7] Epoch: 5 [5/100 (5%)] Train loss=0.799714 Test loss=0.346521 Current lr=[0.00010449031183917899]

[0/23] Train loss=0.688434898853302
[5/23] Train loss=0.9233531355857849
[10/23] Train loss=0.9089445471763611
[15/23] Train loss=0.6301224827766418
[20/23] Train loss=0.5546223521232605
Test set avg_accuracy=87.40% avg_sensitivity=64.42%, avg_specificity=94.82% avg_auc=0.9149
Best model saved!! Metric=12.127309884691552!!
Fold[7] Epoch: 6 [6/100 (6%)] Train loss=0.776639 Test loss=0.332192 Current lr=[0.00013192929274872232]

[0/23] Train loss=0.6428236961364746
[5/23] Train loss=0.9218246340751648
[10/23] Train loss=0.8846568465232849
[15/23] Train loss=0.5893958210945129
[20/23] Train loss=0.5615140795707703
Test set avg_accuracy=87.99% avg_sensitivity=65.53%, avg_specificity=95.25% avg_auc=0.9180
Best model saved!! Metric=14.560046379568348!!
Fold[7] Epoch: 7 [7/100 (7%)] Train loss=0.758835 Test loss=0.331750 Current lr=[0.00016363239706865967]

[0/23] Train loss=0.6419325470924377
[5/23] Train loss=0.92577064037323
[10/23] Train loss=0.8793843984603882
[15/23] Train loss=0.6072181463241577
[20/23] Train loss=0.5383585691452026
Test set avg_accuracy=88.69% avg_sensitivity=70.78%, avg_specificity=94.47% avg_auc=0.9251
Best model saved!! Metric=20.44366201820501!!
Fold[7] Epoch: 8 [8/100 (8%)] Train loss=0.745595 Test loss=0.318210 Current lr=[0.00019925127088619402]

[0/23] Train loss=0.602967381477356
[5/23] Train loss=0.9021397233009338
[10/23] Train loss=0.8339434862136841
[15/23] Train loss=0.5484094619750977
[20/23] Train loss=0.46544721722602844
Test set avg_accuracy=89.03% avg_sensitivity=77.43%, avg_specificity=92.78% avg_auc=0.9316
Best model saved!! Metric=26.406343720249406!!
Fold[7] Epoch: 9 [9/100 (9%)] Train loss=0.713141 Test loss=0.305533 Current lr=[0.00023839453378827395]

[0/23] Train loss=0.5708937644958496
[5/23] Train loss=0.8974124193191528
[10/23] Train loss=0.8373585343360901
[15/23] Train loss=0.49799734354019165
[20/23] Train loss=0.4866880178451538
Test set avg_accuracy=87.34% avg_sensitivity=86.01%, avg_specificity=87.78% avg_auc=0.9379
Best model saved!! Metric=28.911598992101624!!
Fold[7] Epoch: 10 [10/100 (10%)] Train loss=0.696619 Test loss=0.335783 Current lr=[0.00028063207935207196]

[0/23] Train loss=0.5715321898460388
[5/23] Train loss=0.9444602727890015
[10/23] Train loss=0.8670780062675476
[15/23] Train loss=0.4862843453884125
[20/23] Train loss=0.44639039039611816
Test set avg_accuracy=87.50% avg_sensitivity=88.05%, avg_specificity=87.32% avg_auc=0.9415
Best model saved!! Metric=31.021175367167004!!
Fold[7] Epoch: 11 [11/100 (11%)] Train loss=0.688690 Test loss=0.332177 Current lr=[0.0003254998011571065]

[0/23] Train loss=0.5290347933769226
[5/23] Train loss=0.9035118222236633
[10/23] Train loss=0.8499042391777039
[15/23] Train loss=0.48567238450050354
[20/23] Train loss=0.4324040412902832
Test set avg_accuracy=88.99% avg_sensitivity=82.68%, avg_specificity=91.03% avg_auc=0.9379
Fold[7] Epoch: 12 [12/100 (12%)] Train loss=0.675680 Test loss=0.307127 Current lr=[0.0003725046923895547]

[0/23] Train loss=0.5010039210319519
[5/23] Train loss=0.8867830038070679
[10/23] Train loss=0.795703649520874
[15/23] Train loss=0.4829632043838501
[20/23] Train loss=0.42281752824783325
Test set avg_accuracy=89.06% avg_sensitivity=85.62%, avg_specificity=90.17% avg_auc=0.9443
Best model saved!! Metric=33.288993738499585!!
Fold[7] Epoch: 13 [13/100 (13%)] Train loss=0.665940 Test loss=0.299562 Current lr=[0.0004211302630042728]

[0/23] Train loss=0.50465327501297
[5/23] Train loss=0.9244429469108582
[10/23] Train loss=0.8480004072189331
[15/23] Train loss=0.5008662939071655
[20/23] Train loss=0.4779303967952728
Test set avg_accuracy=87.04% avg_sensitivity=87.20%, avg_specificity=86.99% avg_auc=0.9409
Fold[7] Epoch: 14 [14/100 (14%)] Train loss=0.672814 Test loss=0.336938 Current lr=[0.0004708422149207104]

[0/23] Train loss=0.5309972167015076
[5/23] Train loss=0.9153712391853333
[10/23] Train loss=0.8293310403823853
[15/23] Train loss=0.5023396015167236
[20/23] Train loss=0.42249205708503723
Test set avg_accuracy=89.01% avg_sensitivity=84.22%, avg_specificity=90.56% avg_auc=0.9384
Fold[7] Epoch: 15 [15/100 (15%)] Train loss=0.675919 Test loss=0.303444 Current lr=[0.0005210943128936348]

[0/23] Train loss=0.5238672494888306
[5/23] Train loss=0.8899099230766296
[10/23] Train loss=0.7972754836082458
[15/23] Train loss=0.49405667185783386
[20/23] Train loss=0.4512844383716583
Test set avg_accuracy=90.66% avg_sensitivity=83.40%, avg_specificity=93.00% avg_auc=0.9416
Best model saved!! Metric=35.2232234074378!!
Fold[7] Epoch: 16 [16/100 (16%)] Train loss=0.650552 Test loss=0.282495 Current lr=[0.0005713343865494929]

[0/23] Train loss=0.5006193518638611
[5/23] Train loss=0.9258366227149963
[10/23] Train loss=0.8119049668312073
[15/23] Train loss=0.4968966841697693
[20/23] Train loss=0.4104406535625458
Test set avg_accuracy=89.17% avg_sensitivity=82.72%, avg_specificity=91.25% avg_auc=0.9397
Fold[7] Epoch: 17 [17/100 (17%)] Train loss=0.639223 Test loss=0.291151 Current lr=[0.0006210103976380052]

[0/23] Train loss=0.48219823837280273
[5/23] Train loss=0.8635158538818359
[10/23] Train loss=0.7792797684669495
[15/23] Train loss=0.48360496759414673
[20/23] Train loss=0.44019466638565063
Test set avg_accuracy=90.26% avg_sensitivity=76.37%, avg_specificity=94.75% avg_auc=0.9314
Fold[7] Epoch: 18 [18/100 (18%)] Train loss=0.635341 Test loss=0.279135 Current lr=[0.0006695765058319851]

[0/23] Train loss=0.5181607604026794
[5/23] Train loss=0.8097653985023499
[10/23] Train loss=0.6809656023979187
[15/23] Train loss=0.5018428564071655
[20/23] Train loss=0.4378824830055237
Test set avg_accuracy=89.97% avg_sensitivity=76.32%, avg_specificity=94.38% avg_auc=0.9314
Fold[7] Epoch: 19 [19/100 (19%)] Train loss=0.618477 Test loss=0.284698 Current lr=[0.0007164990664243417]

[0/23] Train loss=0.47454574704170227
[5/23] Train loss=0.8244917988777161
[10/23] Train loss=0.6931840777397156
[15/23] Train loss=0.49033522605895996
[20/23] Train loss=0.49018537998199463
Test set avg_accuracy=88.00% avg_sensitivity=85.88%, avg_specificity=88.69% avg_auc=0.9412
Fold[7] Epoch: 20 [20/100 (20%)] Train loss=0.619391 Test loss=0.304830 Current lr=[0.0007612624940195301]

[0/23] Train loss=0.4942340850830078
[5/23] Train loss=0.8077993988990784
[10/23] Train loss=0.6989134550094604
[15/23] Train loss=0.4656328558921814
[20/23] Train loss=0.4751957654953003
Test set avg_accuracy=85.85% avg_sensitivity=88.31%, avg_specificity=85.06% avg_auc=0.9423
Fold[7] Epoch: 21 [21/100 (21%)] Train loss=0.617928 Test loss=0.332660 Current lr=[0.000803374927789172]

[0/23] Train loss=0.4896644353866577
[5/23] Train loss=0.8653981685638428
[10/23] Train loss=0.7408688068389893
[15/23] Train loss=0.4640774130821228
[20/23] Train loss=0.48357146978378296
Test set avg_accuracy=90.26% avg_sensitivity=79.22%, avg_specificity=93.83% avg_auc=0.9415
Fold[7] Epoch: 22 [22/100 (22%)] Train loss=0.622936 Test loss=0.264036 Current lr=[0.0008423736360419787]

[0/23] Train loss=0.4956829249858856
[5/23] Train loss=0.8175445795059204
[10/23] Train loss=0.7141966223716736
[15/23] Train loss=0.4924778640270233
[20/23] Train loss=0.4313344657421112
Test set avg_accuracy=89.53% avg_sensitivity=79.65%, avg_specificity=92.72% avg_auc=0.9380
Fold[7] Epoch: 23 [23/100 (23%)] Train loss=0.615827 Test loss=0.271134 Current lr=[0.0008778301007225328]

[0/23] Train loss=0.5369403958320618
[5/23] Train loss=0.7940776944160461
[10/23] Train loss=0.7413971424102783
[15/23] Train loss=0.5245116353034973
[20/23] Train loss=0.5012761354446411
Test set avg_accuracy=89.67% avg_sensitivity=69.54%, avg_specificity=96.17% avg_auc=0.9340
Fold[7] Epoch: 24 [24/100 (24%)] Train loss=0.612131 Test loss=0.293714 Current lr=[0.0009093547259704173]

[0/23] Train loss=0.463372141122818
[5/23] Train loss=0.7419087886810303
[10/23] Train loss=0.7016106247901917
[15/23] Train loss=0.4416641294956207
[20/23] Train loss=0.40602731704711914
Test set avg_accuracy=90.27% avg_sensitivity=79.14%, avg_specificity=93.87% avg_auc=0.9420
Fold[7] Epoch: 25 [25/100 (25%)] Train loss=0.584931 Test loss=0.260097 Current lr=[0.0009366011190020192]

[0/23] Train loss=0.47993069887161255
[5/23] Train loss=0.7265592217445374
[10/23] Train loss=0.6714118123054504
[15/23] Train loss=0.4130537211894989
[20/23] Train loss=0.40640807151794434
Test set avg_accuracy=89.53% avg_sensitivity=82.12%, avg_specificity=91.92% avg_auc=0.9396
Fold[7] Epoch: 26 [26/100 (26%)] Train loss=0.566647 Test loss=0.275704 Current lr=[0.0009592698962766488]

[0/23] Train loss=0.4589661955833435
[5/23] Train loss=0.7257292866706848
[10/23] Train loss=0.6769946217536926
[15/23] Train loss=0.4202326238155365
[20/23] Train loss=0.4285835921764374
Test set avg_accuracy=87.78% avg_sensitivity=86.39%, avg_specificity=88.23% avg_auc=0.9427
Fold[7] Epoch: 27 [27/100 (27%)] Train loss=0.564501 Test loss=0.300830 Current lr=[0.0009771119731247974]

[0/23] Train loss=0.47808435559272766
[5/23] Train loss=0.7565838694572449
[10/23] Train loss=0.6563056111335754
[15/23] Train loss=0.4368648827075958
[20/23] Train loss=0.3920244574546814
Test set avg_accuracy=90.22% avg_sensitivity=77.60%, avg_specificity=94.29% avg_auc=0.9386
Fold[7] Epoch: 28 [28/100 (28%)] Train loss=0.565695 Test loss=0.278367 Current lr=[0.0009899313006920766]

[0/23] Train loss=0.5092244148254395
[5/23] Train loss=0.750988781452179
[10/23] Train loss=0.6271275877952576
[15/23] Train loss=0.39603501558303833
[20/23] Train loss=0.38771092891693115
Test set avg_accuracy=88.93% avg_sensitivity=70.26%, avg_specificity=94.96% avg_auc=0.9235
Fold[7] Epoch: 29 [29/100 (29%)] Train loss=0.545167 Test loss=0.328442 Current lr=[0.0009975870201252835]

[0/23] Train loss=0.4714440405368805
[5/23] Train loss=0.6770069599151611
[10/23] Train loss=0.6729699969291687
[15/23] Train loss=0.42108505964279175
[20/23] Train loss=0.4140014052391052
Test set avg_accuracy=89.81% avg_sensitivity=81.27%, avg_specificity=92.57% avg_auc=0.9420
Fold[7] Epoch: 30 [30/100 (30%)] Train loss=0.546372 Test loss=0.276607 Current lr=[0.000999999048111397]

[0/23] Train loss=0.4598924219608307
[5/23] Train loss=0.6817063093185425
[10/23] Train loss=0.6360210180282593
[15/23] Train loss=0.39945152401924133
[20/23] Train loss=0.37823981046676636
Test set avg_accuracy=90.03% avg_sensitivity=73.29%, avg_specificity=95.44% avg_auc=0.9313
Fold[7] Epoch: 31 [31/100 (31%)] Train loss=0.526406 Test loss=0.289609 Current lr=[0.000999451812190372]

[0/23] Train loss=0.47085586190223694
[5/23] Train loss=0.6565555930137634
[10/23] Train loss=0.6335312128067017
[15/23] Train loss=0.395131379365921
[20/23] Train loss=0.35455799102783203
Test set avg_accuracy=90.52% avg_sensitivity=76.83%, avg_specificity=94.94% avg_auc=0.9386
Fold[7] Epoch: 32 [32/100 (32%)] Train loss=0.521199 Test loss=0.285079 Current lr=[0.0009978987508156897]

[0/23] Train loss=0.4576006233692169
[5/23] Train loss=0.7346038222312927
[10/23] Train loss=0.6398540139198303
[15/23] Train loss=0.40933507680892944
[20/23] Train loss=0.3895110487937927
Test set avg_accuracy=90.16% avg_sensitivity=71.67%, avg_specificity=96.13% avg_auc=0.9293
Fold[7] Epoch: 33 [33/100 (33%)] Train loss=0.527913 Test loss=0.305657 Current lr=[0.0009953429916462733]

[0/23] Train loss=0.41780850291252136
[5/23] Train loss=0.6389850974082947
[10/23] Train loss=0.6363409757614136
[15/23] Train loss=0.4109405279159546
[20/23] Train loss=0.3741209805011749
Test set avg_accuracy=89.92% avg_sensitivity=70.14%, avg_specificity=96.31% avg_auc=0.9303
Fold[7] Epoch: 34 [34/100 (34%)] Train loss=0.525533 Test loss=0.306426 Current lr=[0.000991789681640963]

[0/23] Train loss=0.4599430561065674
[5/23] Train loss=0.6806132793426514
[10/23] Train loss=0.6082667708396912
[15/23] Train loss=0.4325849413871765
[20/23] Train loss=0.3509571850299835
Test set avg_accuracy=89.07% avg_sensitivity=85.15%, avg_specificity=90.34% avg_auc=0.9456
Fold[7] Epoch: 35 [35/100 (35%)] Train loss=0.501722 Test loss=0.294246 Current lr=[0.0009872459766932253]

[0/23] Train loss=0.43716245889663696
[5/23] Train loss=0.6273412704467773
[10/23] Train loss=0.596723198890686
[15/23] Train loss=0.3843829333782196
[20/23] Train loss=0.33506643772125244
Test set avg_accuracy=90.18% avg_sensitivity=78.92%, avg_specificity=93.81% avg_auc=0.9353
Fold[7] Epoch: 36 [36/100 (36%)] Train loss=0.493484 Test loss=0.295376 Current lr=[0.0009817210272201372]

[0/23] Train loss=0.42360517382621765
[5/23] Train loss=0.6374094486236572
[10/23] Train loss=0.5984942317008972
[15/23] Train loss=0.38673099875450134
[20/23] Train loss=0.32146719098091125
Test set avg_accuracy=90.28% avg_sensitivity=78.54%, avg_specificity=94.07% avg_auc=0.9373
Fold[7] Epoch: 37 [37/100 (37%)] Train loss=0.478661 Test loss=0.311150 Current lr=[0.0009752259597346622]

[0/23] Train loss=0.4214545786380768
[5/23] Train loss=0.5747326016426086
[10/23] Train loss=0.6011340022087097
[15/23] Train loss=0.3815770745277405
[20/23] Train loss=0.3491950035095215
Test set avg_accuracy=90.88% avg_sensitivity=75.90%, avg_specificity=95.71% avg_auc=0.9357
Fold[7] Epoch: 38 [38/100 (38%)] Train loss=0.469970 Test loss=0.321263 Current lr=[0.000967773854438336]

[0/23] Train loss=0.3927564322948456
[5/23] Train loss=0.5984498858451843
[10/23] Train loss=0.6181743741035461
[15/23] Train loss=0.36463895440101624
[20/23] Train loss=0.30280083417892456
Test set avg_accuracy=90.05% avg_sensitivity=83.11%, avg_specificity=92.30% avg_auc=0.9431
Fold[7] Epoch: 39 [39/100 (39%)] Train loss=0.465318 Test loss=0.304691 Current lr=[0.000959379718879479]

[0/23] Train loss=0.40549275279045105
[5/23] Train loss=0.5474621057510376
[10/23] Train loss=0.5398780107498169
[15/23] Train loss=0.3641587495803833
[20/23] Train loss=0.29486504197120667
Test set avg_accuracy=89.90% avg_sensitivity=85.03%, avg_specificity=91.47% avg_auc=0.9390
Fold[7] Epoch: 40 [40/100 (40%)] Train loss=0.454783 Test loss=0.326234 Current lr=[0.0009500604577299936]

[0/23] Train loss=0.3990827202796936
[5/23] Train loss=0.5997965931892395
[10/23] Train loss=0.5760490894317627
[15/23] Train loss=0.37119728326797485
[20/23] Train loss=0.30352023243904114
Test set avg_accuracy=89.33% avg_sensitivity=84.51%, avg_specificity=90.89% avg_auc=0.9425
Fold[7] Epoch: 41 [41/100 (41%)] Train loss=0.449465 Test loss=0.330929 Current lr=[0.0009398348387416027]

[0/23] Train loss=0.37927380204200745
[5/23] Train loss=0.5607544779777527
[10/23] Train loss=0.6115781664848328
[15/23] Train loss=0.3259883522987366
[20/23] Train loss=0.3017371594905853
Test set avg_accuracy=88.59% avg_sensitivity=87.84%, avg_specificity=88.84% avg_auc=0.9446
Fold[7] Epoch: 42 [42/100 (42%)] Train loss=0.454718 Test loss=0.340197 Current lr=[0.000928723454950097]

[0/23] Train loss=0.4009952247142792
[5/23] Train loss=0.5598531365394592
[10/23] Train loss=0.518478274345398
[15/23] Train loss=0.3267657160758972
[20/23] Train loss=0.31104084849357605
Test set avg_accuracy=89.49% avg_sensitivity=83.83%, avg_specificity=91.32% avg_auc=0.9377
Fold[7] Epoch: 43 [43/100 (43%)] Train loss=0.435853 Test loss=0.338221 Current lr=[0.0009167486832037001]

[0/23] Train loss=0.37731513381004333
[5/23] Train loss=0.5682868361473083
[10/23] Train loss=0.565455436706543
[15/23] Train loss=0.32972434163093567
[20/23] Train loss=0.27612441778182983
Test set avg_accuracy=89.15% avg_sensitivity=85.96%, avg_specificity=90.17% avg_auc=0.9381
Fold[7] Epoch: 44 [44/100 (44%)] Train loss=0.424815 Test loss=0.371222 Current lr=[0.0009039346390990754]

[0/23] Train loss=0.3810330629348755
[5/23] Train loss=0.4681168794631958
[10/23] Train loss=0.4593850374221802
[15/23] Train loss=0.3364754617214203
[20/23] Train loss=0.2670341730117798
Test set avg_accuracy=89.33% avg_sensitivity=85.37%, avg_specificity=90.61% avg_auc=0.9433
Fold[7] Epoch: 45 [45/100 (45%)] Train loss=0.395275 Test loss=0.347707 Current lr=[0.000890307128415723]

[0/23] Train loss=0.3510156273841858
[5/23] Train loss=0.4418511986732483
[10/23] Train loss=0.42694005370140076
[15/23] Train loss=0.29199498891830444
[20/23] Train loss=0.2714000344276428
Test set avg_accuracy=86.62% avg_sensitivity=89.51%, avg_specificity=85.69% avg_auc=0.9446
Fold[7] Epoch: 46 [46/100 (46%)] Train loss=0.382666 Test loss=0.370968 Current lr=[0.0008758935951465738]

[0/23] Train loss=0.32992619276046753
[5/23] Train loss=0.4567050337791443
[10/23] Train loss=0.4121384918689728
[15/23] Train loss=0.3166339695453644
[20/23] Train loss=0.2588803470134735
Test set avg_accuracy=90.42% avg_sensitivity=80.08%, avg_specificity=93.76% avg_auc=0.9369
Fold[7] Epoch: 47 [47/100 (47%)] Train loss=0.363883 Test loss=0.341223 Current lr=[0.0008607230662294413]

[0/23] Train loss=0.340215265750885
[5/23] Train loss=0.3697859048843384
[10/23] Train loss=0.38158348202705383
[15/23] Train loss=0.2805026173591614
[20/23] Train loss=0.24697156250476837
Test set avg_accuracy=90.52% avg_sensitivity=79.14%, avg_specificity=94.20% avg_auc=0.9308
Fold[7] Epoch: 48 [48/100 (48%)] Train loss=0.342564 Test loss=0.372874 Current lr=[0.0008448260930906307]

[0/23] Train loss=0.32471659779548645
[5/23] Train loss=0.35456597805023193
[10/23] Train loss=0.3469677269458771
[15/23] Train loss=0.2648164927959442
[20/23] Train loss=0.2064938098192215
Test set avg_accuracy=90.65% avg_sensitivity=77.22%, avg_specificity=94.98% avg_auc=0.9326
Fold[7] Epoch: 49 [49/100 (49%)] Train loss=0.315130 Test loss=0.355150 Current lr=[0.0008282346901184324]

[0/23] Train loss=0.2949305474758148
[5/23] Train loss=0.3492128551006317
[10/23] Train loss=0.34291306138038635
[15/23] Train loss=0.26066353917121887
[20/23] Train loss=0.22524778544902802
Test set avg_accuracy=90.66% avg_sensitivity=75.04%, avg_specificity=95.70% avg_auc=0.9332
Fold[7] Epoch: 50 [50/100 (50%)] Train loss=0.295741 Test loss=0.379532 Current lr=[0.000810982270190405]

[0/23] Train loss=0.3246937096118927
[5/23] Train loss=0.3478410542011261
[10/23] Train loss=0.3216513395309448
[15/23] Train loss=0.2859909236431122
[20/23] Train loss=0.21610549092292786
Test set avg_accuracy=90.05% avg_sensitivity=69.24%, avg_specificity=96.78% avg_auc=0.9285
Fold[7] Epoch: 51 [51/100 (51%)] Train loss=0.299233 Test loss=0.406427 Current lr=[0.0007931035773842862]

[0/23] Train loss=0.2730987071990967
[5/23] Train loss=0.3702155351638794
[10/23] Train loss=0.2955332398414612
[15/23] Train loss=0.25875815749168396
[20/23] Train loss=0.17894196510314941
Test set avg_accuracy=91.06% avg_sensitivity=75.17%, avg_specificity=96.20% avg_auc=0.9346
Fold[7] Epoch: 52 [52/100 (52%)] Train loss=0.280929 Test loss=0.356061 Current lr=[0.0007746346170080441]

[0/23] Train loss=0.2465682476758957
[5/23] Train loss=0.32751065492630005
[10/23] Train loss=0.3303331434726715
[15/23] Train loss=0.2645733952522278
[20/23] Train loss=0.1706390380859375
Test set avg_accuracy=90.65% avg_sensitivity=75.13%, avg_specificity=95.66% avg_auc=0.9322
Fold[7] Epoch: 53 [53/100 (53%)] Train loss=0.273792 Test loss=0.391277 Current lr=[0.0007556125830899786]

[0/23] Train loss=0.24766620993614197
[5/23] Train loss=0.3167750835418701
[10/23] Train loss=0.2891215682029724
[15/23] Train loss=0.2584724724292755
[20/23] Train loss=0.20349717140197754
Test set avg_accuracy=90.47% avg_sensitivity=79.18%, avg_specificity=94.12% avg_auc=0.9404
Fold[7] Epoch: 54 [54/100 (54%)] Train loss=0.263903 Test loss=0.365719 Current lr=[0.0007360757834748981]

[0/23] Train loss=0.22408975660800934
[5/23] Train loss=0.2997242212295532
[10/23] Train loss=0.27687233686447144
[15/23] Train loss=0.2480674684047699
[20/23] Train loss=0.18184007704257965
Test set avg_accuracy=90.74% avg_sensitivity=78.03%, avg_specificity=94.85% avg_auc=0.9390
Fold[7] Epoch: 55 [55/100 (55%)] Train loss=0.252781 Test loss=0.389252 Current lr=[0.000716063562677219]

[0/23] Train loss=0.2639992833137512
[5/23] Train loss=0.2638254165649414
[10/23] Train loss=0.30823957920074463
[15/23] Train loss=0.23262359201908112
[20/23] Train loss=0.15444834530353546
Test set avg_accuracy=90.99% avg_sensitivity=77.90%, avg_specificity=95.22% avg_auc=0.9374
Fold[7] Epoch: 56 [56/100 (56%)] Train loss=0.241656 Test loss=0.391959 Current lr=[0.0006956162226463489]

[0/23] Train loss=0.2142314910888672
[5/23] Train loss=0.27265048027038574
[10/23] Train loss=0.23584024608135223
[15/23] Train loss=0.19889657199382782
[20/23] Train loss=0.15430611371994019
Test set avg_accuracy=90.62% avg_sensitivity=75.34%, avg_specificity=95.56% avg_auc=0.9343
Fold[7] Epoch: 57 [57/100 (57%)] Train loss=0.215805 Test loss=0.411863 Current lr=[0.0006747749416039243]

[0/23] Train loss=0.20292100310325623
[5/23] Train loss=0.24062156677246094
[10/23] Train loss=0.22440911829471588
[15/23] Train loss=0.18370673060417175
[20/23] Train loss=0.14770746231079102
Test set avg_accuracy=90.58% avg_sensitivity=74.62%, avg_specificity=95.74% avg_auc=0.9322
Fold[7] Epoch: 58 [58/100 (58%)] Train loss=0.200571 Test loss=0.446411 Current lr=[0.000653581691116352]

[0/23] Train loss=0.18406130373477936
[5/23] Train loss=0.18429821729660034
[10/23] Train loss=0.21175263822078705
[15/23] Train loss=0.17097757756710052
[20/23] Train loss=0.12038908153772354
Test set avg_accuracy=89.86% avg_sensitivity=71.25%, avg_specificity=95.88% avg_auc=0.9304
Fold[7] Epoch: 59 [59/100 (59%)] Train loss=0.185201 Test loss=0.446204 Current lr=[0.0006320791515696602]

[0/23] Train loss=0.1982911080121994
[5/23] Train loss=0.2176329344511032
[10/23] Train loss=0.18535149097442627
[15/23] Train loss=0.18166373670101166
[20/23] Train loss=0.12934644520282745
Test set avg_accuracy=90.53% avg_sensitivity=76.66%, avg_specificity=95.01% avg_auc=0.9349
Fold[7] Epoch: 60 [60/100 (60%)] Train loss=0.183289 Test loss=0.406914 Current lr=[0.0006103106262168818]

[0/23] Train loss=0.1602673977613449
[5/23] Train loss=0.19414082169532776
[10/23] Train loss=0.1973772644996643
[15/23] Train loss=0.16414280235767365
[20/23] Train loss=0.11835776269435883
Test set avg_accuracy=89.89% avg_sensitivity=73.25%, avg_specificity=95.26% avg_auc=0.9295
Fold[7] Epoch: 61 [61/100 (61%)] Train loss=0.166163 Test loss=0.468750 Current lr=[0.0005883199539710647]

[0/23] Train loss=0.14649154245853424
[5/23] Train loss=0.17596089839935303
[10/23] Train loss=0.16944631934165955
[15/23] Train loss=0.16256889700889587
[20/23] Train loss=0.10317572206258774
Test set avg_accuracy=90.54% avg_sensitivity=77.30%, avg_specificity=94.82% avg_auc=0.9337
Fold[7] Epoch: 62 [62/100 (62%)] Train loss=0.155749 Test loss=0.412980 Current lr=[0.0005661514211195354]

[0/23] Train loss=0.15071769058704376
[5/23] Train loss=0.1711670458316803
[10/23] Train loss=0.18259887397289276
[15/23] Train loss=0.13978341221809387
[20/23] Train loss=0.10481222718954086
Test set avg_accuracy=89.90% avg_sensitivity=74.53%, avg_specificity=94.86% avg_auc=0.9323
Fold[7] Epoch: 63 [63/100 (63%)] Train loss=0.150492 Test loss=0.448103 Current lr=[0.00054384967213721]

[0/23] Train loss=0.1367146223783493
[5/23] Train loss=0.163149893283844
[10/23] Train loss=0.14631739258766174
[15/23] Train loss=0.148795023560524
[20/23] Train loss=0.08553794771432877
Test set avg_accuracy=90.29% avg_sensitivity=74.70%, avg_specificity=95.33% avg_auc=0.9330
Fold[7] Epoch: 64 [64/100 (64%)] Train loss=0.138409 Test loss=0.450806 Current lr=[0.000521459619778564]

[0/23] Train loss=0.13170461356639862
[5/23] Train loss=0.15068121254444122
[10/23] Train loss=0.1529998481273651
[15/23] Train loss=0.12911221385002136
[20/23] Train loss=0.08453674614429474
Test set avg_accuracy=89.49% avg_sensitivity=73.25%, avg_specificity=94.74% avg_auc=0.9317
Fold[7] Epoch: 65 [65/100 (65%)] Train loss=0.133033 Test loss=0.506823 Current lr=[0.0004990263546293204]

[0/23] Train loss=0.12095470726490021
[5/23] Train loss=0.1462264358997345
[10/23] Train loss=0.14457973837852478
[15/23] Train loss=0.1349010169506073
[20/23] Train loss=0.09897707402706146
Test set avg_accuracy=89.86% avg_sensitivity=78.58%, avg_specificity=93.51% avg_auc=0.9357
Fold[7] Epoch: 66 [66/100 (66%)] Train loss=0.129474 Test loss=0.442734 Current lr=[0.000476595054300012]

[0/23] Train loss=0.11097101867198944
[5/23] Train loss=0.14872367680072784
[10/23] Train loss=0.14164918661117554
[15/23] Train loss=0.11973821371793747
[20/23] Train loss=0.10322623699903488
Test set avg_accuracy=90.10% avg_sensitivity=77.69%, avg_specificity=94.12% avg_auc=0.9366
Fold[7] Epoch: 67 [67/100 (67%)] Train loss=0.123180 Test loss=0.479788 Current lr=[0.0004542108924442853]

[0/23] Train loss=0.12595273554325104
[5/23] Train loss=0.14704327285289764
[10/23] Train loss=0.15358032286167145
[15/23] Train loss=0.11172837018966675
[20/23] Train loss=0.10891532152891159
Test set avg_accuracy=90.32% avg_sensitivity=80.59%, avg_specificity=93.47% avg_auc=0.9363
Fold[7] Epoch: 68 [68/100 (68%)] Train loss=0.118185 Test loss=0.485648 Current lr=[0.000431918947785175]

[0/23] Train loss=0.11454746872186661
[5/23] Train loss=0.11675741523504257
[10/23] Train loss=0.12445104867219925
[15/23] Train loss=0.11744710057973862
[20/23] Train loss=0.08736366778612137
Test set avg_accuracy=90.25% avg_sensitivity=80.97%, avg_specificity=93.25% avg_auc=0.9362
Fold[7] Epoch: 69 [69/100 (69%)] Train loss=0.110530 Test loss=0.498316 Current lr=[0.0004097641133325535]

[0/23] Train loss=0.10444465279579163
[5/23] Train loss=0.11388856917619705
[10/23] Train loss=0.10234865546226501
[15/23] Train loss=0.11389745771884918
[20/23] Train loss=0.06814683973789215
Test set avg_accuracy=90.68% avg_sensitivity=79.27%, avg_specificity=94.36% avg_auc=0.9367
Fold[7] Epoch: 70 [70/100 (70%)] Train loss=0.100771 Test loss=0.496418 Current lr=[0.00038779100597458526]

[0/23] Train loss=0.08589762449264526
[5/23] Train loss=0.10223936289548874
[10/23] Train loss=0.09740372002124786
[15/23] Train loss=0.09550607949495316
[20/23] Train loss=0.07530678808689117
Test set avg_accuracy=90.43% avg_sensitivity=79.01%, avg_specificity=94.12% avg_auc=0.9385
Fold[7] Epoch: 71 [71/100 (71%)] Train loss=0.088647 Test loss=0.502070 Current lr=[0.0003660438766252499]

[0/23] Train loss=0.08572039753198624
[5/23] Train loss=0.08968272060155869
[10/23] Train loss=0.08764977753162384
[15/23] Train loss=0.08419740200042725
[20/23] Train loss=0.05590781569480896
Test set avg_accuracy=90.41% avg_sensitivity=76.19%, avg_specificity=95.00% avg_auc=0.9374
Fold[7] Epoch: 72 [72/100 (72%)] Train loss=0.080608 Test loss=0.505973 Current lr=[0.0003445665211088922]

[0/23] Train loss=0.08192571252584457
[5/23] Train loss=0.07641295343637466
[10/23] Train loss=0.07973429560661316
[15/23] Train loss=0.08331695199012756
[20/23] Train loss=0.049662280827760696
Test set avg_accuracy=90.53% avg_sensitivity=76.92%, avg_specificity=94.93% avg_auc=0.9379
Fold[7] Epoch: 73 [73/100 (73%)] Train loss=0.074748 Test loss=0.487646 Current lr=[0.00032340219196125877]

[0/23] Train loss=0.06600321829319
[5/23] Train loss=0.08533945679664612
[10/23] Train loss=0.0819617360830307
[15/23] Train loss=0.07234325259923935
[20/23] Train loss=0.048038728535175323
Test set avg_accuracy=90.44% avg_sensitivity=77.18%, avg_specificity=94.72% avg_auc=0.9390
Fold[7] Epoch: 74 [74/100 (74%)] Train loss=0.070167 Test loss=0.505197 Current lr=[0.0003025935113246488]

[0/23] Train loss=0.06709324568510056
[5/23] Train loss=0.08084223419427872
[10/23] Train loss=0.07467947155237198
[15/23] Train loss=0.08166138827800751
[20/23] Train loss=0.04416908323764801
Test set avg_accuracy=90.50% avg_sensitivity=77.30%, avg_specificity=94.76% avg_auc=0.9379
Fold[7] Epoch: 75 [75/100 (75%)] Train loss=0.063284 Test loss=0.523085 Current lr=[0.0002821823851125901]

[0/23] Train loss=0.0637456476688385
[5/23] Train loss=0.05987659841775894
[10/23] Train loss=0.06687435507774353
[15/23] Train loss=0.05697482451796532
[20/23] Train loss=0.03956227749586105
Test set avg_accuracy=90.45% avg_sensitivity=76.62%, avg_specificity=94.91% avg_auc=0.9376
Fold[7] Epoch: 76 [76/100 (76%)] Train loss=0.058950 Test loss=0.527472 Current lr=[0.00026220991861690765]

[0/23] Train loss=0.0561971478164196
[5/23] Train loss=0.06407671421766281
[10/23] Train loss=0.06266748160123825
[15/23] Train loss=0.06516511738300323
[20/23] Train loss=0.04079477861523628
Test set avg_accuracy=90.39% avg_sensitivity=75.68%, avg_specificity=95.14% avg_auc=0.9382
Fold[7] Epoch: 77 [77/100 (77%)] Train loss=0.055133 Test loss=0.534490 Current lr=[0.00024271633372713536]

[0/23] Train loss=0.04980635270476341
[5/23] Train loss=0.06508033722639084
[10/23] Train loss=0.05146421119570732
[15/23] Train loss=0.07677562534809113
[20/23] Train loss=0.03951679542660713
Test set avg_accuracy=90.70% avg_sensitivity=76.24%, avg_specificity=95.37% avg_auc=0.9379
Fold[7] Epoch: 78 [78/100 (78%)] Train loss=0.052305 Test loss=0.551033 Current lr=[0.00022374088792898362]

[0/23] Train loss=0.05191662162542343
[5/23] Train loss=0.06461691111326218
[10/23] Train loss=0.05554807186126709
[15/23] Train loss=0.06565079092979431
[20/23] Train loss=0.036280713975429535
Test set avg_accuracy=90.74% avg_sensitivity=78.28%, avg_specificity=94.76% avg_auc=0.9388
Fold[7] Epoch: 79 [79/100 (79%)] Train loss=0.050046 Test loss=0.538301 Current lr=[0.00020532179524498774]

[0/23] Train loss=0.04924848675727844
[5/23] Train loss=0.06305427849292755
[10/23] Train loss=0.05337994545698166
[15/23] Train loss=0.050332628190517426
[20/23] Train loss=0.041631877422332764
Test set avg_accuracy=90.60% avg_sensitivity=77.52%, avg_specificity=94.83% avg_auc=0.9385
Fold[7] Epoch: 80 [80/100 (80%)] Train loss=0.047972 Test loss=0.552857 Current lr=[0.000187496149276552]

[0/23] Train loss=0.03540308028459549
[5/23] Train loss=0.052997488528490067
[10/23] Train loss=0.051070526242256165
[15/23] Train loss=0.05857756733894348
[20/23] Train loss=0.04346920922398567
Test set avg_accuracy=90.35% avg_sensitivity=76.15%, avg_specificity=94.94% avg_auc=0.9376
Fold[7] Epoch: 81 [81/100 (81%)] Train loss=0.048157 Test loss=0.560880 Current lr=[0.00017029984850237305]

[0/23] Train loss=0.05478475242853165
[5/23] Train loss=0.04938806965947151
[10/23] Train loss=0.046719785779714584
[15/23] Train loss=0.0730464830994606
[20/23] Train loss=0.03287172317504883
Test set avg_accuracy=90.52% avg_sensitivity=76.62%, avg_specificity=95.01% avg_auc=0.9378
Fold[7] Epoch: 82 [82/100 (82%)] Train loss=0.048450 Test loss=0.557826 Current lr=[0.00015376752398368106]

[0/23] Train loss=0.041536055505275726
[5/23] Train loss=0.048838693648576736
[10/23] Train loss=0.05871382728219032
[15/23] Train loss=0.06384975463151932
[20/23] Train loss=0.04117690399289131
Test set avg_accuracy=90.58% avg_sensitivity=76.75%, avg_specificity=95.05% avg_auc=0.9384
Fold[7] Epoch: 83 [83/100 (83%)] Train loss=0.046258 Test loss=0.561112 Current lr=[0.00013793246962189157]

[0/23] Train loss=0.04579443857073784
[5/23] Train loss=0.05312393605709076
[10/23] Train loss=0.05075691640377045
[15/23] Train loss=0.05576160550117493
[20/23] Train loss=0.03175107389688492
Test set avg_accuracy=90.41% avg_sensitivity=76.32%, avg_specificity=94.96% avg_auc=0.9378
Fold[7] Epoch: 84 [84/100 (84%)] Train loss=0.042811 Test loss=0.570540 Current lr=[0.00012282657510911843]

[0/23] Train loss=0.04438123479485512
[5/23] Train loss=0.04634791612625122
[10/23] Train loss=0.051292385905981064
[15/23] Train loss=0.049891259521245956
[20/23] Train loss=0.024854596704244614
Test set avg_accuracy=90.53% avg_sensitivity=76.54%, avg_specificity=95.05% avg_auc=0.9381
Fold[7] Epoch: 85 [85/100 (85%)] Train loss=0.042020 Test loss=0.565593 Current lr=[0.0001084802617065783]

[0/23] Train loss=0.04029242321848869
[5/23] Train loss=0.046458978205919266
[10/23] Train loss=0.046497609466314316
[15/23] Train loss=0.06162803992629051
[20/23] Train loss=0.02509739249944687
Test set avg_accuracy=90.64% avg_sensitivity=77.22%, avg_specificity=94.97% avg_auc=0.9388
Fold[7] Epoch: 86 [86/100 (86%)] Train loss=0.041948 Test loss=0.561763 Current lr=[9.492242098021878e-05]

[0/23] Train loss=0.039003439247608185
[5/23] Train loss=0.05898034945130348
[10/23] Train loss=0.04623758792877197
[15/23] Train loss=0.05919582396745682
[20/23] Train loss=0.02759055234491825
Test set avg_accuracy=90.58% avg_sensitivity=77.43%, avg_specificity=94.83% avg_auc=0.9386
Fold[7] Epoch: 87 [87/100 (87%)] Train loss=0.041719 Test loss=0.568932 Current lr=[8.218035661694964e-05]

[0/23] Train loss=0.0394439734518528
[5/23] Train loss=0.0392034649848938
[10/23] Train loss=0.04421922564506531
[15/23] Train loss=0.0579133965075016
[20/23] Train loss=0.02476184070110321
Test set avg_accuracy=90.58% avg_sensitivity=76.92%, avg_specificity=95.00% avg_auc=0.9387
Fold[7] Epoch: 88 [88/100 (88%)] Train loss=0.039531 Test loss=0.572891 Current lr=[7.02797294386511e-05]

[0/23] Train loss=0.038824908435344696
[5/23] Train loss=0.049260158091783524
[10/23] Train loss=0.039028335362672806
[15/23] Train loss=0.049569446593523026
[20/23] Train loss=0.031296342611312866
Test set avg_accuracy=90.52% avg_sensitivity=76.41%, avg_specificity=95.08% avg_auc=0.9386
Fold[7] Epoch: 89 [89/100 (89%)] Train loss=0.038275 Test loss=0.573124 Current lr=[5.924450572469346e-05]

[0/23] Train loss=0.04490380734205246
[5/23] Train loss=0.0451471246778965
[10/23] Train loss=0.04988924786448479
[15/23] Train loss=0.04950239136815071
[20/23] Train loss=0.026083340868353844
Test set avg_accuracy=90.46% avg_sensitivity=76.66%, avg_specificity=94.91% avg_auc=0.9384
Fold[7] Epoch: 90 [90/100 (90%)] Train loss=0.037218 Test loss=0.575748 Current lr=[4.90969089470401e-05]

[0/23] Train loss=0.044948481023311615
[5/23] Train loss=0.04813401401042938
[10/23] Train loss=0.052202049642801285
[15/23] Train loss=0.060203999280929565
[20/23] Train loss=0.024322906509041786
Test set avg_accuracy=90.53% avg_sensitivity=77.26%, avg_specificity=94.82% avg_auc=0.9386
Fold[7] Epoch: 91 [91/100 (91%)] Train loss=0.038653 Test loss=0.572397 Current lr=[3.985737501513232e-05]

[0/23] Train loss=0.03825712576508522
[5/23] Train loss=0.04479829594492912
[10/23] Train loss=0.04486532136797905
[15/23] Train loss=0.05965257063508034
[20/23] Train loss=0.025859087705612183
Test set avg_accuracy=90.61% avg_sensitivity=77.13%, avg_specificity=94.97% avg_auc=0.9387
Fold[7] Epoch: 92 [92/100 (92%)] Train loss=0.036812 Test loss=0.573950 Current lr=[3.154451112068745e-05]

[0/23] Train loss=0.03945469111204147
[5/23] Train loss=0.04052995517849922
[10/23] Train loss=0.04149908572435379
[15/23] Train loss=0.05323876440525055
[20/23] Train loss=0.030627688392996788
Test set avg_accuracy=90.55% avg_sensitivity=77.09%, avg_specificity=94.90% avg_auc=0.9388
Fold[7] Epoch: 93 [93/100 (93%)] Train loss=0.038109 Test loss=0.575356 Current lr=[2.4175058265291265e-05]

[0/23] Train loss=0.032001085579395294
[5/23] Train loss=0.04254017397761345
[10/23] Train loss=0.040955256670713425
[15/23] Train loss=0.055020254105329514
[20/23] Train loss=0.027966029942035675
Test set avg_accuracy=90.51% avg_sensitivity=77.18%, avg_specificity=94.82% avg_auc=0.9387
Fold[7] Epoch: 94 [94/100 (94%)] Train loss=0.036688 Test loss=0.577395 Current lr=[1.7763857546248248e-05]

[0/23] Train loss=0.034084711223840714
[5/23] Train loss=0.04682893306016922
[10/23] Train loss=0.03606370463967323
[15/23] Train loss=0.056988343596458435
[20/23] Train loss=0.03072224371135235
Test set avg_accuracy=90.54% avg_sensitivity=76.92%, avg_specificity=94.94% avg_auc=0.9386
Fold[7] Epoch: 95 [95/100 (95%)] Train loss=0.036223 Test loss=0.579416 Current lr=[1.2323820268587161e-05]

[0/23] Train loss=0.03044605441391468
[5/23] Train loss=0.03878344967961311
[10/23] Train loss=0.030534055083990097
[15/23] Train loss=0.06619079411029816
[20/23] Train loss=0.023690499365329742
Test set avg_accuracy=90.45% avg_sensitivity=76.54%, avg_specificity=94.94% avg_auc=0.9385
Fold[7] Epoch: 96 [96/100 (96%)] Train loss=0.035334 Test loss=0.580563 Current lr=[7.865901943410707e-06]

[0/23] Train loss=0.03241369128227234
[5/23] Train loss=0.039464306086301804
[10/23] Train loss=0.0338636115193367
[15/23] Train loss=0.05240761861205101
[20/23] Train loss=0.02326892502605915
Test set avg_accuracy=90.42% avg_sensitivity=76.49%, avg_specificity=94.91% avg_auc=0.9385
Fold[7] Epoch: 97 [97/100 (97%)] Train loss=0.035299 Test loss=0.581230 Current lr=[4.399080224954306e-06]

[0/23] Train loss=0.034816332161426544
[5/23] Train loss=0.04936886951327324
[10/23] Train loss=0.03723950311541557
[15/23] Train loss=0.05165443941950798
[20/23] Train loss=0.02294955402612686
Test set avg_accuracy=90.41% avg_sensitivity=76.45%, avg_specificity=94.91% avg_auc=0.9385
Fold[7] Epoch: 98 [98/100 (98%)] Train loss=0.036364 Test loss=0.581077 Current lr=[1.930336830785271e-06]

[0/23] Train loss=0.03985564038157463
[5/23] Train loss=0.04254800081253052
[10/23] Train loss=0.04655768349766731
[15/23] Train loss=0.04456305503845215
[20/23] Train loss=0.02478911355137825
Test set avg_accuracy=90.43% avg_sensitivity=76.49%, avg_specificity=94.93% avg_auc=0.9385
Fold[7] Epoch: 99 [99/100 (99%)] Train loss=0.036381 Test loss=0.580818 Current lr=[4.6464348155246055e-07]

[0/23] Train loss=0.03954990208148956
[5/23] Train loss=0.04229981079697609
[10/23] Train loss=0.03844255954027176
[15/23] Train loss=0.04988846182823181
[20/23] Train loss=0.02614661492407322
Test set avg_accuracy=90.42% avg_sensitivity=76.45%, avg_specificity=94.93% avg_auc=0.9385
Fold[7] Epoch: 100 [100/100 (100%)] Train loss=0.036415 Test loss=0.581141 Current lr=[4.951888602991508e-09]

Fold[7] Best Result: acc=90.65625 sen=83.40443686006826, spe=92.99889746416758, auc=0.9416363908320196!
[0/23] Train loss=1.394079327583313
[5/23] Train loss=1.4900867938995361
[10/23] Train loss=1.384185552597046
[15/23] Train loss=1.3069368600845337
[20/23] Train loss=1.1861743927001953
Test set avg_accuracy=75.72% avg_sensitivity=19.84%, avg_specificity=92.54% avg_auc=0.7475
Best model saved!! Metric=-63.15377055139432!!
Fold[8] Epoch: 1 [1/100 (1%)] Train loss=1.336562 Test loss=0.495519 Current lr=[4.263712153319496e-05]

[0/23] Train loss=1.1602438688278198
[5/23] Train loss=1.105495810508728
[10/23] Train loss=1.1624444723129272
[15/23] Train loss=1.0001192092895508
[20/23] Train loss=0.8856695294380188
Test set avg_accuracy=80.73% avg_sensitivity=64.29%, avg_specificity=85.68% avg_auc=0.8452
Best model saved!! Metric=-10.779787640528628!!
Fold[8] Epoch: 2 [2/100 (2%)] Train loss=1.077584 Test loss=0.447403 Current lr=[5.051950942452628e-05]

[0/23] Train loss=0.9059851765632629
[5/23] Train loss=0.9674075841903687
[10/23] Train loss=1.0393381118774414
[15/23] Train loss=0.8624077439308167
[20/23] Train loss=0.7648817896842957
Test set avg_accuracy=83.03% avg_sensitivity=66.32%, avg_specificity=88.06% avg_auc=0.8752
Best model saved!! Metric=-1.0754204985910158!!
Fold[8] Epoch: 3 [3/100 (3%)] Train loss=0.937101 Test loss=0.437318 Current lr=[6.356055194548904e-05]

[0/23] Train loss=0.8345674276351929
[5/23] Train loss=0.9361077547073364
[10/23] Train loss=1.0157628059387207
[15/23] Train loss=0.7735151052474976
[20/23] Train loss=0.7033712267875671
Test set avg_accuracy=84.87% avg_sensitivity=71.43%, avg_specificity=88.91% avg_auc=0.8978
Best model saved!! Metric=8.979105310486252!!
Fold[8] Epoch: 4 [4/100 (4%)] Train loss=0.879306 Test loss=0.386562 Current lr=[8.161695403755248e-05]

[0/23] Train loss=0.7612845301628113
[5/23] Train loss=0.9319006204605103
[10/23] Train loss=0.9697025418281555
[15/23] Train loss=0.7870275378227234
[20/23] Train loss=0.6339682936668396
Test set avg_accuracy=85.74% avg_sensitivity=80.80%, avg_specificity=87.22% avg_auc=0.9181
Best model saved!! Metric=19.56800778416306!!
Fold[8] Epoch: 5 [5/100 (5%)] Train loss=0.840000 Test loss=0.356201 Current lr=[0.00010449031183917899]

[0/23] Train loss=0.711787760257721
[5/23] Train loss=0.8898597359657288
[10/23] Train loss=0.904669463634491
[15/23] Train loss=0.7275781631469727
[20/23] Train loss=0.5876723527908325
Test set avg_accuracy=87.63% avg_sensitivity=78.72%, avg_specificity=90.31% avg_auc=0.9306
Best model saved!! Metric=23.72112003948092!!
Fold[8] Epoch: 6 [6/100 (6%)] Train loss=0.802672 Test loss=0.320404 Current lr=[0.00013192929274872232]

[0/23] Train loss=0.6618762016296387
[5/23] Train loss=0.9348827600479126
[10/23] Train loss=0.871661901473999
[15/23] Train loss=0.755852997303009
[20/23] Train loss=0.5356377363204956
Test set avg_accuracy=87.45% avg_sensitivity=83.68%, avg_specificity=88.58% avg_auc=0.9405
Best model saved!! Metric=27.75542367366808!!
Fold[8] Epoch: 7 [7/100 (7%)] Train loss=0.784425 Test loss=0.327828 Current lr=[0.00016363239706865967]

[0/23] Train loss=0.6160773038864136
[5/23] Train loss=0.9777770042419434
[10/23] Train loss=0.8732485771179199
[15/23] Train loss=0.7203531265258789
[20/23] Train loss=0.533889651298523
Test set avg_accuracy=88.40% avg_sensitivity=84.13%, avg_specificity=89.69% avg_auc=0.9414
Best model saved!! Metric=30.348774493619864!!
Fold[8] Epoch: 8 [8/100 (8%)] Train loss=0.768351 Test loss=0.302695 Current lr=[0.00019925127088619402]

[0/23] Train loss=0.6035218834877014
[5/23] Train loss=0.9315789937973022
[10/23] Train loss=0.8184922933578491
[15/23] Train loss=0.7046701312065125
[20/23] Train loss=0.5006020665168762
Test set avg_accuracy=87.63% avg_sensitivity=86.56%, avg_specificity=87.95% avg_auc=0.9454
Best model saved!! Metric=30.682846736429298!!
Fold[8] Epoch: 9 [9/100 (9%)] Train loss=0.731061 Test loss=0.319738 Current lr=[0.00023839453378827395]

[0/23] Train loss=0.5421711206436157
[5/23] Train loss=0.9219143986701965
[10/23] Train loss=0.8321354985237122
[15/23] Train loss=0.6827742457389832
[20/23] Train loss=0.4727831482887268
Test set avg_accuracy=88.98% avg_sensitivity=85.57%, avg_specificity=90.01% avg_auc=0.9489
Best model saved!! Metric=33.452360922589136!!
Fold[8] Epoch: 10 [10/100 (10%)] Train loss=0.724899 Test loss=0.313206 Current lr=[0.00028063207935207196]

[0/23] Train loss=0.5390148162841797
[5/23] Train loss=0.908212423324585
[10/23] Train loss=0.8453789949417114
[15/23] Train loss=0.639540433883667
[20/23] Train loss=0.4672836363315582
Test set avg_accuracy=89.62% avg_sensitivity=86.56%, avg_specificity=90.54% avg_auc=0.9509
Best model saved!! Metric=35.795547439725155!!
Fold[8] Epoch: 11 [11/100 (11%)] Train loss=0.705675 Test loss=0.289921 Current lr=[0.0003254998011571065]

[0/23] Train loss=0.506267249584198
[5/23] Train loss=0.9422507286071777
[10/23] Train loss=0.9472312331199646
[15/23] Train loss=0.6383536458015442
[20/23] Train loss=0.4956167936325073
Test set avg_accuracy=89.23% avg_sensitivity=89.78%, avg_specificity=89.06% avg_auc=0.9485
Best model saved!! Metric=36.91594655050944!!
Fold[8] Epoch: 12 [12/100 (12%)] Train loss=0.712190 Test loss=0.329424 Current lr=[0.0003725046923895547]

[0/23] Train loss=0.5424078702926636
[5/23] Train loss=0.8625593781471252
[10/23] Train loss=0.8377394676208496
[15/23] Train loss=0.6027199029922485
[20/23] Train loss=0.4352649450302124
Test set avg_accuracy=89.74% avg_sensitivity=87.50%, avg_specificity=90.42% avg_auc=0.9550
Best model saved!! Metric=37.15883230959794!!
Fold[8] Epoch: 13 [13/100 (13%)] Train loss=0.683634 Test loss=0.289832 Current lr=[0.0004211302630042728]

[0/23] Train loss=0.5027406811714172
[5/23] Train loss=0.9059360027313232
[10/23] Train loss=0.7894369959831238
[15/23] Train loss=0.6004838347434998
[20/23] Train loss=0.44764748215675354
Test set avg_accuracy=89.52% avg_sensitivity=89.78%, avg_specificity=89.45% avg_auc=0.9578
Best model saved!! Metric=38.527870927193604!!
Fold[8] Epoch: 14 [14/100 (14%)] Train loss=0.668058 Test loss=0.291780 Current lr=[0.0004708422149207104]

[0/23] Train loss=0.48847225308418274
[5/23] Train loss=0.939304769039154
[10/23] Train loss=0.8337330222129822
[15/23] Train loss=0.6209644675254822
[20/23] Train loss=0.42228034138679504
Test set avg_accuracy=90.98% avg_sensitivity=84.28%, avg_specificity=93.00% avg_auc=0.9576
Fold[8] Epoch: 15 [15/100 (15%)] Train loss=0.664548 Test loss=0.259155 Current lr=[0.0005210943128936348]

[0/23] Train loss=0.4793139696121216
[5/23] Train loss=0.8739025592803955
[10/23] Train loss=0.8314182758331299
[15/23] Train loss=0.5799386501312256
[20/23] Train loss=0.4498079717159271
Test set avg_accuracy=89.26% avg_sensitivity=88.84%, avg_specificity=89.39% avg_auc=0.9561
Fold[8] Epoch: 16 [16/100 (16%)] Train loss=0.649352 Test loss=0.277060 Current lr=[0.0005713343865494929]

[0/23] Train loss=0.4995359182357788
[5/23] Train loss=0.8899746537208557
[10/23] Train loss=0.7863909006118774
[15/23] Train loss=0.6026742458343506
[20/23] Train loss=0.46005579829216003
Test set avg_accuracy=90.07% avg_sensitivity=87.05%, avg_specificity=90.98% avg_auc=0.9534
Fold[8] Epoch: 17 [17/100 (17%)] Train loss=0.653405 Test loss=0.264459 Current lr=[0.0006210103976380052]

[0/23] Train loss=0.5130054354667664
[5/23] Train loss=0.8935608863830566
[10/23] Train loss=0.8357807993888855
[15/23] Train loss=0.5599411725997925
[20/23] Train loss=0.46347641944885254
Test set avg_accuracy=88.34% avg_sensitivity=90.13%, avg_specificity=87.80% avg_auc=0.9544
Fold[8] Epoch: 18 [18/100 (18%)] Train loss=0.668222 Test loss=0.297456 Current lr=[0.0006695765058319851]

[0/23] Train loss=0.5252602100372314
[5/23] Train loss=0.8793784379959106
[10/23] Train loss=0.7463443875312805
[15/23] Train loss=0.5745740532875061
[20/23] Train loss=0.40934714674949646
Test set avg_accuracy=90.89% avg_sensitivity=84.57%, avg_specificity=92.79% avg_auc=0.9553
Fold[8] Epoch: 19 [19/100 (19%)] Train loss=0.640325 Test loss=0.248756 Current lr=[0.0007164990664243417]

[0/23] Train loss=0.46550703048706055
[5/23] Train loss=0.8526057600975037
[10/23] Train loss=0.7638288736343384
[15/23] Train loss=0.5791960954666138
[20/23] Train loss=0.42840519547462463
Test set avg_accuracy=90.26% avg_sensitivity=88.99%, avg_specificity=90.64% avg_auc=0.9575
Best model saved!! Metric=39.63963648579204!!
Fold[8] Epoch: 20 [20/100 (20%)] Train loss=0.624150 Test loss=0.248921 Current lr=[0.0007612624940195301]

[0/23] Train loss=0.4822092354297638
[5/23] Train loss=0.8110843300819397
[10/23] Train loss=0.7760424613952637
[15/23] Train loss=0.5949040651321411
[20/23] Train loss=0.48150748014450073
Test set avg_accuracy=89.55% avg_sensitivity=87.80%, avg_specificity=90.07% avg_auc=0.9546
Fold[8] Epoch: 21 [21/100 (21%)] Train loss=0.636904 Test loss=0.263983 Current lr=[0.000803374927789172]

[0/23] Train loss=0.5323166251182556
[5/23] Train loss=0.8369131088256836
[10/23] Train loss=0.7352252006530762
[15/23] Train loss=0.5800859332084656
[20/23] Train loss=0.48017480969429016
Test set avg_accuracy=89.59% avg_sensitivity=87.00%, avg_specificity=90.37% avg_auc=0.9557
Fold[8] Epoch: 22 [22/100 (22%)] Train loss=0.619758 Test loss=0.253845 Current lr=[0.0008423736360419787]

[0/23] Train loss=0.47975727915763855
[5/23] Train loss=0.782232403755188
[10/23] Train loss=0.7825977802276611
[15/23] Train loss=0.5436647534370422
[20/23] Train loss=0.42095792293548584
Test set avg_accuracy=90.67% avg_sensitivity=84.67%, avg_specificity=92.48% avg_auc=0.9529
Fold[8] Epoch: 23 [23/100 (23%)] Train loss=0.613932 Test loss=0.247064 Current lr=[0.0008778301007225328]

[0/23] Train loss=0.4778963029384613
[5/23] Train loss=0.8058145642280579
[10/23] Train loss=0.7468276023864746
[15/23] Train loss=0.5465790629386902
[20/23] Train loss=0.4133339822292328
Test set avg_accuracy=90.15% avg_sensitivity=87.65%, avg_specificity=90.91% avg_auc=0.9539
Fold[8] Epoch: 24 [24/100 (24%)] Train loss=0.606225 Test loss=0.262064 Current lr=[0.0009093547259704173]

[0/23] Train loss=0.48525306582450867
[5/23] Train loss=0.8301460146903992
[10/23] Train loss=0.6970394849777222
[15/23] Train loss=0.5522064566612244
[20/23] Train loss=0.4113084673881531
Test set avg_accuracy=91.00% avg_sensitivity=83.58%, avg_specificity=93.24% avg_auc=0.9537
Fold[8] Epoch: 25 [25/100 (25%)] Train loss=0.594155 Test loss=0.247251 Current lr=[0.0009366011190020192]

[0/23] Train loss=0.45088714361190796
[5/23] Train loss=0.7385953068733215
[10/23] Train loss=0.6865099668502808
[15/23] Train loss=0.5333546996116638
[20/23] Train loss=0.4649805426597595
Test set avg_accuracy=89.39% avg_sensitivity=86.41%, avg_specificity=90.28% avg_auc=0.9529
Fold[8] Epoch: 26 [26/100 (26%)] Train loss=0.580038 Test loss=0.270791 Current lr=[0.0009592698962766488]

[0/23] Train loss=0.4625699520111084
[5/23] Train loss=0.7703458666801453
[10/23] Train loss=0.7027941346168518
[15/23] Train loss=0.5255780220031738
[20/23] Train loss=0.3954910337924957
Test set avg_accuracy=90.04% avg_sensitivity=84.28%, avg_specificity=91.77% avg_auc=0.9556
Fold[8] Epoch: 27 [27/100 (27%)] Train loss=0.568601 Test loss=0.246658 Current lr=[0.0009771119731247974]

[0/23] Train loss=0.4557502269744873
[5/23] Train loss=0.708001434803009
[10/23] Train loss=0.695850670337677
[15/23] Train loss=0.5694476366043091
[20/23] Train loss=0.40829432010650635
Test set avg_accuracy=89.37% avg_sensitivity=87.95%, avg_specificity=89.80% avg_auc=0.9559
Fold[8] Epoch: 28 [28/100 (28%)] Train loss=0.564718 Test loss=0.265662 Current lr=[0.0009899313006920766]

[0/23] Train loss=0.4754331111907959
[5/23] Train loss=0.7359498739242554
[10/23] Train loss=0.6587417721748352
[15/23] Train loss=0.5255053639411926
[20/23] Train loss=0.427718847990036
Test set avg_accuracy=90.21% avg_sensitivity=87.80%, avg_specificity=90.94% avg_auc=0.9553
Fold[8] Epoch: 29 [29/100 (29%)] Train loss=0.565063 Test loss=0.256575 Current lr=[0.0009975870201252835]

[0/23] Train loss=0.45951810479164124
[5/23] Train loss=0.7625672221183777
[10/23] Train loss=0.6679952144622803
[15/23] Train loss=0.5149503946304321
[20/23] Train loss=0.3625929057598114
Test set avg_accuracy=90.13% avg_sensitivity=80.70%, avg_specificity=92.97% avg_auc=0.9487
Fold[8] Epoch: 30 [30/100 (30%)] Train loss=0.550852 Test loss=0.265666 Current lr=[0.000999999048111397]

[0/23] Train loss=0.43223512172698975
[5/23] Train loss=0.6454936861991882
[10/23] Train loss=0.6609889268875122
[15/23] Train loss=0.49617981910705566
[20/23] Train loss=0.38420113921165466
Test set avg_accuracy=91.14% avg_sensitivity=80.95%, avg_specificity=94.21% avg_auc=0.9559
Fold[8] Epoch: 31 [31/100 (31%)] Train loss=0.539441 Test loss=0.235261 Current lr=[0.000999451812190372]

[0/23] Train loss=0.44252046942710876
[5/23] Train loss=0.6354032754898071
[10/23] Train loss=0.629364550113678
[15/23] Train loss=0.5007475018501282
[20/23] Train loss=0.37664690613746643
Test set avg_accuracy=90.18% avg_sensitivity=86.26%, avg_specificity=91.36% avg_auc=0.9572
Fold[8] Epoch: 32 [32/100 (32%)] Train loss=0.521540 Test loss=0.270972 Current lr=[0.0009978987508156897]

[0/23] Train loss=0.41028541326522827
[5/23] Train loss=0.6477911472320557
[10/23] Train loss=0.6302310824394226
[15/23] Train loss=0.49285292625427246
[20/23] Train loss=0.38156071305274963
Test set avg_accuracy=91.43% avg_sensitivity=83.78%, avg_specificity=93.73% avg_auc=0.9571
Fold[8] Epoch: 33 [33/100 (33%)] Train loss=0.513650 Test loss=0.243771 Current lr=[0.0009953429916462733]

[0/23] Train loss=0.40741491317749023
[5/23] Train loss=0.7039405107498169
[10/23] Train loss=0.6695184707641602
[15/23] Train loss=0.488430380821228
[20/23] Train loss=0.36634209752082825
Test set avg_accuracy=90.84% avg_sensitivity=83.78%, avg_specificity=92.97% avg_auc=0.9540
Fold[8] Epoch: 34 [34/100 (34%)] Train loss=0.508604 Test loss=0.257427 Current lr=[0.000991789681640963]

[0/23] Train loss=0.39278098940849304
[5/23] Train loss=0.7090986967086792
[10/23] Train loss=0.6846829056739807
[15/23] Train loss=0.5137351155281067
[20/23] Train loss=0.37622857093811035
Test set avg_accuracy=90.63% avg_sensitivity=87.40%, avg_specificity=91.60% avg_auc=0.9561
Fold[8] Epoch: 35 [35/100 (35%)] Train loss=0.519029 Test loss=0.263975 Current lr=[0.0009872459766932253]

[0/23] Train loss=0.44217684864997864
[5/23] Train loss=0.6946447491645813
[10/23] Train loss=0.6547365784645081
[15/23] Train loss=0.47786659002304077
[20/23] Train loss=0.37893664836883545
Test set avg_accuracy=90.21% avg_sensitivity=87.55%, avg_specificity=91.01% avg_auc=0.9553
Fold[8] Epoch: 36 [36/100 (36%)] Train loss=0.533396 Test loss=0.268170 Current lr=[0.0009817210272201372]

[0/23] Train loss=0.4542559087276459
[5/23] Train loss=0.6564891338348389
[10/23] Train loss=0.6359533071517944
[15/23] Train loss=0.5019165277481079
[20/23] Train loss=0.3530777394771576
Test set avg_accuracy=90.91% avg_sensitivity=85.52%, avg_specificity=92.54% avg_auc=0.9566
Fold[8] Epoch: 37 [37/100 (37%)] Train loss=0.505091 Test loss=0.262486 Current lr=[0.0009752259597346622]

[0/23] Train loss=0.4231348931789398
[5/23] Train loss=0.6696879863739014
[10/23] Train loss=0.6112320423126221
[15/23] Train loss=0.4918154776096344
[20/23] Train loss=0.40551793575286865
Test set avg_accuracy=89.80% avg_sensitivity=89.73%, avg_specificity=89.82% avg_auc=0.9581
Fold[8] Epoch: 38 [38/100 (38%)] Train loss=0.493274 Test loss=0.289248 Current lr=[0.000967773854438336]

[0/23] Train loss=0.4346180558204651
[5/23] Train loss=0.6073073744773865
[10/23] Train loss=0.6360260248184204
[15/23] Train loss=0.4598045349121094
[20/23] Train loss=0.32528966665267944
Test set avg_accuracy=90.40% avg_sensitivity=82.69%, avg_specificity=92.72% avg_auc=0.9544
Fold[8] Epoch: 39 [39/100 (39%)] Train loss=0.476428 Test loss=0.271581 Current lr=[0.000959379718879479]

[0/23] Train loss=0.3861393630504608
[5/23] Train loss=0.5827076435089111
[10/23] Train loss=0.6728894710540771
[15/23] Train loss=0.5852568745613098
[20/23] Train loss=0.3323535919189453
Test set avg_accuracy=90.81% avg_sensitivity=85.42%, avg_specificity=92.43% avg_auc=0.9545
Fold[8] Epoch: 40 [40/100 (40%)] Train loss=0.467165 Test loss=0.292980 Current lr=[0.0009500604577299936]

[0/23] Train loss=0.39303138852119446
[5/23] Train loss=0.5340071320533752
[10/23] Train loss=0.5757201313972473
[15/23] Train loss=0.4095354378223419
[20/23] Train loss=0.34981751441955566
Test set avg_accuracy=89.31% avg_sensitivity=89.68%, avg_specificity=89.19% avg_auc=0.9551
Fold[8] Epoch: 41 [41/100 (41%)] Train loss=0.454532 Test loss=0.325470 Current lr=[0.0009398348387416027]

[0/23] Train loss=0.3931286036968231
[5/23] Train loss=0.5671725273132324
[10/23] Train loss=0.6126497983932495
[15/23] Train loss=0.45778217911720276
[20/23] Train loss=0.2949111759662628
Test set avg_accuracy=88.95% avg_sensitivity=91.42%, avg_specificity=88.21% avg_auc=0.9547
Fold[8] Epoch: 42 [42/100 (42%)] Train loss=0.460160 Test loss=0.373182 Current lr=[0.000928723454950097]

[0/23] Train loss=0.3924456834793091
[5/23] Train loss=0.553342342376709
[10/23] Train loss=0.564985454082489
[15/23] Train loss=0.4364861249923706
[20/23] Train loss=0.29625874757766724
Test set avg_accuracy=89.15% avg_sensitivity=90.13%, avg_specificity=88.85% avg_auc=0.9577
Fold[8] Epoch: 43 [43/100 (43%)] Train loss=0.451981 Test loss=0.346203 Current lr=[0.0009167486832037001]

[0/23] Train loss=0.3944418728351593
[5/23] Train loss=0.5558651685714722
[10/23] Train loss=0.5463294982910156
[15/23] Train loss=0.4558851718902588
[20/23] Train loss=0.29022952914237976
Test set avg_accuracy=89.03% avg_sensitivity=90.62%, avg_specificity=88.55% avg_auc=0.9563
Fold[8] Epoch: 44 [44/100 (44%)] Train loss=0.447094 Test loss=0.350712 Current lr=[0.0009039346390990754]

[0/23] Train loss=0.367799311876297
[5/23] Train loss=0.47288498282432556
[10/23] Train loss=0.5105931162834167
[15/23] Train loss=0.4346141517162323
[20/23] Train loss=0.2851288318634033
Test set avg_accuracy=90.42% avg_sensitivity=88.99%, avg_specificity=90.85% avg_auc=0.9563
Best model saved!! Metric=39.88393582076441!!
Fold[8] Epoch: 45 [45/100 (45%)] Train loss=0.426976 Test loss=0.333332 Current lr=[0.000890307128415723]

[0/23] Train loss=0.40415075421333313
[5/23] Train loss=0.5288503170013428
[10/23] Train loss=0.5345868468284607
[15/23] Train loss=0.42512354254722595
[20/23] Train loss=0.2690090537071228
Test set avg_accuracy=90.20% avg_sensitivity=86.81%, avg_specificity=91.22% avg_auc=0.9558
Fold[8] Epoch: 46 [46/100 (46%)] Train loss=0.420133 Test loss=0.330381 Current lr=[0.0008758935951465738]

[0/23] Train loss=0.35803255438804626
[5/23] Train loss=0.44745388627052307
[10/23] Train loss=0.4583231210708618
[15/23] Train loss=0.40227675437927246
[20/23] Train loss=0.266836553812027
Test set avg_accuracy=90.05% avg_sensitivity=88.94%, avg_specificity=90.39% avg_auc=0.9557
Fold[8] Epoch: 47 [47/100 (47%)] Train loss=0.390873 Test loss=0.330563 Current lr=[0.0008607230662294413]

[0/23] Train loss=0.3482411205768585
[5/23] Train loss=0.45557183027267456
[10/23] Train loss=0.4833938777446747
[15/23] Train loss=0.3946586847305298
[20/23] Train loss=0.2616420090198517
Test set avg_accuracy=90.36% avg_sensitivity=86.95%, avg_specificity=91.39% avg_auc=0.9548
Fold[8] Epoch: 48 [48/100 (48%)] Train loss=0.384060 Test loss=0.312246 Current lr=[0.0008448260930906307]

[0/23] Train loss=0.3298715054988861
[5/23] Train loss=0.4141804575920105
[10/23] Train loss=0.4453805387020111
[15/23] Train loss=0.3784882426261902
[20/23] Train loss=0.2759048044681549
Test set avg_accuracy=90.22% avg_sensitivity=87.50%, avg_specificity=91.04% avg_auc=0.9573
Fold[8] Epoch: 49 [49/100 (49%)] Train loss=0.352132 Test loss=0.303665 Current lr=[0.0008282346901184324]

[0/23] Train loss=0.3128291070461273
[5/23] Train loss=0.4114600419998169
[10/23] Train loss=0.3766437768936157
[15/23] Train loss=0.3402690291404724
[20/23] Train loss=0.23464304208755493
Test set avg_accuracy=90.22% avg_sensitivity=86.90%, avg_specificity=91.22% avg_auc=0.9534
Fold[8] Epoch: 50 [50/100 (50%)] Train loss=0.336816 Test loss=0.329518 Current lr=[0.000810982270190405]

[0/23] Train loss=0.29145729541778564
[5/23] Train loss=0.3457373082637787
[10/23] Train loss=0.3460722863674164
[15/23] Train loss=0.3152921199798584
[20/23] Train loss=0.22131656110286713
Test set avg_accuracy=90.98% avg_sensitivity=82.49%, avg_specificity=93.54% avg_auc=0.9519
Fold[8] Epoch: 51 [51/100 (51%)] Train loss=0.318227 Test loss=0.328445 Current lr=[0.0007931035773842862]

[0/23] Train loss=0.29367586970329285
[5/23] Train loss=0.34324532747268677
[10/23] Train loss=0.38889607787132263
[15/23] Train loss=0.33038389682769775
[20/23] Train loss=0.2193063348531723
Test set avg_accuracy=91.49% avg_sensitivity=83.53%, avg_specificity=93.88% avg_auc=0.9532
Fold[8] Epoch: 52 [52/100 (52%)] Train loss=0.300087 Test loss=0.324384 Current lr=[0.0007746346170080441]

[0/23] Train loss=0.26577603816986084
[5/23] Train loss=0.31387150287628174
[10/23] Train loss=0.3280170261859894
[15/23] Train loss=0.2865709960460663
[20/23] Train loss=0.18575838208198547
Test set avg_accuracy=90.50% avg_sensitivity=85.12%, avg_specificity=92.12% avg_auc=0.9536
Fold[8] Epoch: 53 [53/100 (53%)] Train loss=0.273509 Test loss=0.359132 Current lr=[0.0007556125830899786]

[0/23] Train loss=0.25235435366630554
[5/23] Train loss=0.32995322346687317
[10/23] Train loss=0.32106146216392517
[15/23] Train loss=0.29493242502212524
[20/23] Train loss=0.17213600873947144
Test set avg_accuracy=90.83% avg_sensitivity=82.19%, avg_specificity=93.43% avg_auc=0.9552
Fold[8] Epoch: 54 [54/100 (54%)] Train loss=0.272958 Test loss=0.333002 Current lr=[0.0007360757834748981]

[0/23] Train loss=0.22912511229515076
[5/23] Train loss=0.2840491235256195
[10/23] Train loss=0.3309341073036194
[15/23] Train loss=0.2509342432022095
[20/23] Train loss=0.16738705337047577
Test set avg_accuracy=90.27% avg_sensitivity=83.04%, avg_specificity=92.45% avg_auc=0.9509
Fold[8] Epoch: 55 [55/100 (55%)] Train loss=0.256502 Test loss=0.356298 Current lr=[0.000716063562677219]

[0/23] Train loss=0.2171596735715866
[5/23] Train loss=0.3036370873451233
[10/23] Train loss=0.3139220178127289
[15/23] Train loss=0.2622988224029541
[20/23] Train loss=0.1551770716905594
Test set avg_accuracy=90.74% avg_sensitivity=81.94%, avg_specificity=93.39% avg_auc=0.9523
Fold[8] Epoch: 56 [56/100 (56%)] Train loss=0.249136 Test loss=0.354818 Current lr=[0.0006956162226463489]

[0/23] Train loss=0.21286357939243317
[5/23] Train loss=0.23834069073200226
[10/23] Train loss=0.27873069047927856
[15/23] Train loss=0.26545876264572144
[20/23] Train loss=0.17313502728939056
Test set avg_accuracy=89.80% avg_sensitivity=82.14%, avg_specificity=92.10% avg_auc=0.9494
Fold[8] Epoch: 57 [57/100 (57%)] Train loss=0.239429 Test loss=0.369658 Current lr=[0.0006747749416039243]

[0/23] Train loss=0.21387435495853424
[5/23] Train loss=0.2565677762031555
[10/23] Train loss=0.2820199131965637
[15/23] Train loss=0.26306527853012085
[20/23] Train loss=0.16810843348503113
Test set avg_accuracy=90.80% avg_sensitivity=81.15%, avg_specificity=93.70% avg_auc=0.9501
Fold[8] Epoch: 58 [58/100 (58%)] Train loss=0.227492 Test loss=0.351676 Current lr=[0.000653581691116352]

[0/23] Train loss=0.18469247221946716
[5/23] Train loss=0.21650545299053192
[10/23] Train loss=0.26293128728866577
[15/23] Train loss=0.21571773290634155
[20/23] Train loss=0.14617642760276794
Test set avg_accuracy=89.74% avg_sensitivity=77.88%, avg_specificity=93.31% avg_auc=0.9450
Fold[8] Epoch: 59 [59/100 (59%)] Train loss=0.214601 Test loss=0.357213 Current lr=[0.0006320791515696602]

[0/23] Train loss=0.20105133950710297
[5/23] Train loss=0.18353760242462158
[10/23] Train loss=0.218167245388031
[15/23] Train loss=0.22714301943778992
[20/23] Train loss=0.1525263637304306
Test set avg_accuracy=90.52% avg_sensitivity=78.67%, avg_specificity=94.09% avg_auc=0.9467
Fold[8] Epoch: 60 [60/100 (60%)] Train loss=0.196483 Test loss=0.348512 Current lr=[0.0006103106262168818]

[0/23] Train loss=0.18928538262844086
[5/23] Train loss=0.17549607157707214
[10/23] Train loss=0.20843276381492615
[15/23] Train loss=0.20658652484416962
[20/23] Train loss=0.11260614544153214
Test set avg_accuracy=90.24% avg_sensitivity=82.89%, avg_specificity=92.45% avg_auc=0.9462
Fold[8] Epoch: 61 [61/100 (61%)] Train loss=0.179478 Test loss=0.361659 Current lr=[0.0005883199539710647]

[0/23] Train loss=0.1746717244386673
[5/23] Train loss=0.2132778912782669
[10/23] Train loss=0.19383153319358826
[15/23] Train loss=0.20618121325969696
[20/23] Train loss=0.12060917168855667
Test set avg_accuracy=89.75% avg_sensitivity=83.98%, avg_specificity=91.49% avg_auc=0.9477
Fold[8] Epoch: 62 [62/100 (62%)] Train loss=0.181083 Test loss=0.359680 Current lr=[0.0005661514211195354]

[0/23] Train loss=0.16151559352874756
[5/23] Train loss=0.20067119598388672
[10/23] Train loss=0.2053123116493225
[15/23] Train loss=0.17802633345127106
[20/23] Train loss=0.12352607399225235
Test set avg_accuracy=90.15% avg_sensitivity=81.99%, avg_specificity=92.61% avg_auc=0.9497
Fold[8] Epoch: 63 [63/100 (63%)] Train loss=0.170357 Test loss=0.362177 Current lr=[0.00054384967213721]

[0/23] Train loss=0.1662404090166092
[5/23] Train loss=0.14314374327659607
[10/23] Train loss=0.15245096385478973
[15/23] Train loss=0.1626022756099701
[20/23] Train loss=0.11272969096899033
Test set avg_accuracy=90.76% avg_sensitivity=80.41%, avg_specificity=93.88% avg_auc=0.9492
Fold[8] Epoch: 64 [64/100 (64%)] Train loss=0.153658 Test loss=0.368301 Current lr=[0.000521459619778564]

[0/23] Train loss=0.15872643887996674
[5/23] Train loss=0.15970838069915771
[10/23] Train loss=0.1508437544107437
[15/23] Train loss=0.15963269770145416
[20/23] Train loss=0.10218167304992676
Test set avg_accuracy=91.04% avg_sensitivity=83.23%, avg_specificity=93.39% avg_auc=0.9505
Fold[8] Epoch: 65 [65/100 (65%)] Train loss=0.142968 Test loss=0.401043 Current lr=[0.0004990263546293204]

[0/23] Train loss=0.13283590972423553
[5/23] Train loss=0.1722862273454666
[10/23] Train loss=0.15468209981918335
[15/23] Train loss=0.17985627055168152
[20/23] Train loss=0.10024822503328323
Test set avg_accuracy=90.81% avg_sensitivity=81.30%, avg_specificity=93.67% avg_auc=0.9497
Fold[8] Epoch: 66 [66/100 (66%)] Train loss=0.136723 Test loss=0.393810 Current lr=[0.000476595054300012]

[0/23] Train loss=0.12154919654130936
[5/23] Train loss=0.1577700823545456
[10/23] Train loss=0.13776040077209473
[15/23] Train loss=0.15493951737880707
[20/23] Train loss=0.09929055720567703
Test set avg_accuracy=90.81% avg_sensitivity=85.57%, avg_specificity=92.39% avg_auc=0.9502
Fold[8] Epoch: 67 [67/100 (67%)] Train loss=0.131519 Test loss=0.407120 Current lr=[0.0004542108924442853]

[0/23] Train loss=0.1307462453842163
[5/23] Train loss=0.12251350283622742
[10/23] Train loss=0.16500918567180634
[15/23] Train loss=0.1384173035621643
[20/23] Train loss=0.09764985740184784
Test set avg_accuracy=89.43% avg_sensitivity=87.70%, avg_specificity=89.95% avg_auc=0.9500
Fold[8] Epoch: 68 [68/100 (68%)] Train loss=0.127411 Test loss=0.487898 Current lr=[0.000431918947785175]

[0/23] Train loss=0.12822313606739044
[5/23] Train loss=0.11479838937520981
[10/23] Train loss=0.12478988617658615
[15/23] Train loss=0.11484041810035706
[20/23] Train loss=0.09008791297674179
Test set avg_accuracy=89.76% avg_sensitivity=87.55%, avg_specificity=90.43% avg_auc=0.9501
Fold[8] Epoch: 69 [69/100 (69%)] Train loss=0.112458 Test loss=0.505027 Current lr=[0.0004097641133325535]

[0/23] Train loss=0.11856450140476227
[5/23] Train loss=0.11335041373968124
[10/23] Train loss=0.1072927713394165
[15/23] Train loss=0.11548446863889694
[20/23] Train loss=0.08234835416078568
Test set avg_accuracy=89.71% avg_sensitivity=87.60%, avg_specificity=90.34% avg_auc=0.9509
Fold[8] Epoch: 70 [70/100 (70%)] Train loss=0.111896 Test loss=0.486100 Current lr=[0.00038779100597458526]

[0/23] Train loss=0.11031989008188248
[5/23] Train loss=0.10759595036506653
[10/23] Train loss=0.09055212885141373
[15/23] Train loss=0.09528972208499908
[20/23] Train loss=0.07865698635578156
Test set avg_accuracy=90.76% avg_sensitivity=82.84%, avg_specificity=93.15% avg_auc=0.9491
Fold[8] Epoch: 71 [71/100 (71%)] Train loss=0.098422 Test loss=0.472487 Current lr=[0.0003660438766252499]

[0/23] Train loss=0.0847960039973259
[5/23] Train loss=0.12179253995418549
[10/23] Train loss=0.09926348179578781
[15/23] Train loss=0.08196645230054855
[20/23] Train loss=0.06866078823804855
Test set avg_accuracy=90.51% avg_sensitivity=81.25%, avg_specificity=93.30% avg_auc=0.9493
Fold[8] Epoch: 72 [72/100 (72%)] Train loss=0.084092 Test loss=0.480295 Current lr=[0.0003445665211088922]

[0/23] Train loss=0.085507832467556
[5/23] Train loss=0.08646086603403091
[10/23] Train loss=0.08316851407289505
[15/23] Train loss=0.0677001103758812
[20/23] Train loss=0.05548328161239624
Test set avg_accuracy=90.72% avg_sensitivity=82.49%, avg_specificity=93.19% avg_auc=0.9501
Fold[8] Epoch: 73 [73/100 (73%)] Train loss=0.074723 Test loss=0.485809 Current lr=[0.00032340219196125877]

[0/23] Train loss=0.06576202809810638
[5/23] Train loss=0.07855597883462906
[10/23] Train loss=0.07572475075721741
[15/23] Train loss=0.06804025173187256
[20/23] Train loss=0.04661666974425316
Test set avg_accuracy=90.87% avg_sensitivity=82.29%, avg_specificity=93.45% avg_auc=0.9504
Fold[8] Epoch: 74 [74/100 (74%)] Train loss=0.064293 Test loss=0.491248 Current lr=[0.0003025935113246488]

[0/23] Train loss=0.06304383277893066
[5/23] Train loss=0.07960227876901627
[10/23] Train loss=0.06858392059803009
[15/23] Train loss=0.06029565632343292
[20/23] Train loss=0.0570712648332119
Test set avg_accuracy=91.02% avg_sensitivity=82.79%, avg_specificity=93.49% avg_auc=0.9507
Fold[8] Epoch: 75 [75/100 (75%)] Train loss=0.063944 Test loss=0.510331 Current lr=[0.0002821823851125901]

[0/23] Train loss=0.06190086156129837
[5/23] Train loss=0.061495520174503326
[10/23] Train loss=0.07243548333644867
[15/23] Train loss=0.06387573480606079
[20/23] Train loss=0.046042703092098236
Test set avg_accuracy=90.88% avg_sensitivity=82.49%, avg_specificity=93.40% avg_auc=0.9505
Fold[8] Epoch: 76 [76/100 (76%)] Train loss=0.057522 Test loss=0.521557 Current lr=[0.00026220991861690765]

[0/23] Train loss=0.054623447358608246
[5/23] Train loss=0.0584394596517086
[10/23] Train loss=0.05774252861738205
[15/23] Train loss=0.06136176735162735
[20/23] Train loss=0.04287497699260712
Test set avg_accuracy=90.74% avg_sensitivity=81.89%, avg_specificity=93.40% avg_auc=0.9508
Fold[8] Epoch: 77 [77/100 (77%)] Train loss=0.055427 Test loss=0.505676 Current lr=[0.00024271633372713536]

[0/23] Train loss=0.06523672491312027
[5/23] Train loss=0.0572291798889637
[10/23] Train loss=0.052537791430950165
[15/23] Train loss=0.04842167720198631
[20/23] Train loss=0.04991244524717331
Test set avg_accuracy=91.00% avg_sensitivity=82.44%, avg_specificity=93.58% avg_auc=0.9518
Fold[8] Epoch: 78 [78/100 (78%)] Train loss=0.053780 Test loss=0.519273 Current lr=[0.00022374088792898362]

[0/23] Train loss=0.052553266286849976
[5/23] Train loss=0.06050105020403862
[10/23] Train loss=0.05673162266612053
[15/23] Train loss=0.05149172991514206
[20/23] Train loss=0.03483522683382034
Test set avg_accuracy=91.00% avg_sensitivity=82.14%, avg_specificity=93.67% avg_auc=0.9513
Fold[8] Epoch: 79 [79/100 (79%)] Train loss=0.050507 Test loss=0.515272 Current lr=[0.00020532179524498774]

[0/23] Train loss=0.05536094680428505
[5/23] Train loss=0.06315857172012329
[10/23] Train loss=0.05800538882613182
[15/23] Train loss=0.04748005419969559
[20/23] Train loss=0.04041309654712677
Test set avg_accuracy=90.79% avg_sensitivity=82.24%, avg_specificity=93.36% avg_auc=0.9509
Fold[8] Epoch: 80 [80/100 (80%)] Train loss=0.049249 Test loss=0.522957 Current lr=[0.000187496149276552]

[0/23] Train loss=0.046990957111120224
[5/23] Train loss=0.05347868800163269
[10/23] Train loss=0.05634746700525284
[15/23] Train loss=0.04865730181336403
[20/23] Train loss=0.030623946338891983
Test set avg_accuracy=90.81% avg_sensitivity=82.09%, avg_specificity=93.43% avg_auc=0.9506
Fold[8] Epoch: 81 [81/100 (81%)] Train loss=0.045986 Test loss=0.522661 Current lr=[0.00017029984850237305]

[0/23] Train loss=0.04160633310675621
[5/23] Train loss=0.04945799335837364
[10/23] Train loss=0.06082496792078018
[15/23] Train loss=0.0403745137155056
[20/23] Train loss=0.02986469492316246
Test set avg_accuracy=90.95% avg_sensitivity=82.54%, avg_specificity=93.48% avg_auc=0.9506
Fold[8] Epoch: 82 [82/100 (82%)] Train loss=0.043968 Test loss=0.534832 Current lr=[0.00015376752398368106]

[0/23] Train loss=0.048919834196567535
[5/23] Train loss=0.04856276512145996
[10/23] Train loss=0.05261716991662979
[15/23] Train loss=0.042779404670000076
[20/23] Train loss=0.03157274052500725
Test set avg_accuracy=90.95% avg_sensitivity=81.99%, avg_specificity=93.64% avg_auc=0.9501
Fold[8] Epoch: 83 [83/100 (83%)] Train loss=0.044279 Test loss=0.537272 Current lr=[0.00013793246962189157]

[0/23] Train loss=0.04643669351935387
[5/23] Train loss=0.046419210731983185
[10/23] Train loss=0.050048768520355225
[15/23] Train loss=0.040255818516016006
[20/23] Train loss=0.03415082022547722
Test set avg_accuracy=90.90% avg_sensitivity=82.04%, avg_specificity=93.57% avg_auc=0.9499
Fold[8] Epoch: 84 [84/100 (84%)] Train loss=0.041782 Test loss=0.540827 Current lr=[0.00012282657510911843]

[0/23] Train loss=0.039998333901166916
[5/23] Train loss=0.03688538074493408
[10/23] Train loss=0.048431575298309326
[15/23] Train loss=0.046196114271879196
[20/23] Train loss=0.028623998165130615
Test set avg_accuracy=90.67% avg_sensitivity=82.44%, avg_specificity=93.15% avg_auc=0.9508
Fold[8] Epoch: 85 [85/100 (85%)] Train loss=0.041305 Test loss=0.545041 Current lr=[0.0001084802617065783]

[0/23] Train loss=0.040763527154922485
[5/23] Train loss=0.041288018226623535
[10/23] Train loss=0.04632945731282234
[15/23] Train loss=0.03739440068602562
[20/23] Train loss=0.03281283751130104
Test set avg_accuracy=90.80% avg_sensitivity=82.34%, avg_specificity=93.34% avg_auc=0.9503
Fold[8] Epoch: 86 [86/100 (86%)] Train loss=0.040137 Test loss=0.542042 Current lr=[9.492242098021878e-05]

[0/23] Train loss=0.03650662302970886
[5/23] Train loss=0.04116975516080856
[10/23] Train loss=0.04789707437157631
[15/23] Train loss=0.0395100936293602
[20/23] Train loss=0.03338222578167915
Test set avg_accuracy=90.64% avg_sensitivity=81.70%, avg_specificity=93.33% avg_auc=0.9500
Fold[8] Epoch: 87 [87/100 (87%)] Train loss=0.038820 Test loss=0.556865 Current lr=[8.218035661694964e-05]

[0/23] Train loss=0.043229930102825165
[5/23] Train loss=0.04980463907122612
[10/23] Train loss=0.04361126199364662
[15/23] Train loss=0.04302401468157768
[20/23] Train loss=0.03184632956981659
Test set avg_accuracy=90.73% avg_sensitivity=81.80%, avg_specificity=93.42% avg_auc=0.9503
Fold[8] Epoch: 88 [88/100 (88%)] Train loss=0.038072 Test loss=0.542817 Current lr=[7.02797294386511e-05]

[0/23] Train loss=0.0394812673330307
[5/23] Train loss=0.04127873480319977
[10/23] Train loss=0.04163039103150368
[15/23] Train loss=0.0339655764400959
[20/23] Train loss=0.03457305207848549
Test set avg_accuracy=90.84% avg_sensitivity=82.14%, avg_specificity=93.46% avg_auc=0.9505
Fold[8] Epoch: 89 [89/100 (89%)] Train loss=0.036743 Test loss=0.548348 Current lr=[5.924450572469346e-05]

[0/23] Train loss=0.0407419353723526
[5/23] Train loss=0.04332254081964493
[10/23] Train loss=0.046951353549957275
[15/23] Train loss=0.04351595416665077
[20/23] Train loss=0.028310060501098633
Test set avg_accuracy=90.81% avg_sensitivity=82.14%, avg_specificity=93.42% avg_auc=0.9505
Fold[8] Epoch: 90 [90/100 (90%)] Train loss=0.037127 Test loss=0.561732 Current lr=[4.90969089470401e-05]

[0/23] Train loss=0.03495316579937935
[5/23] Train loss=0.039670173078775406
[10/23] Train loss=0.046130772680044174
[15/23] Train loss=0.035489510744810104
[20/23] Train loss=0.02540951780974865
Test set avg_accuracy=90.97% avg_sensitivity=81.85%, avg_specificity=93.72% avg_auc=0.9504
Fold[8] Epoch: 91 [91/100 (91%)] Train loss=0.035711 Test loss=0.560367 Current lr=[3.985737501513232e-05]

[0/23] Train loss=0.03760119527578354
[5/23] Train loss=0.037989139556884766
[10/23] Train loss=0.05093339830636978
[15/23] Train loss=0.03342033922672272
[20/23] Train loss=0.028568118810653687
Test set avg_accuracy=90.96% avg_sensitivity=81.89%, avg_specificity=93.69% avg_auc=0.9505
Fold[8] Epoch: 92 [92/100 (92%)] Train loss=0.033855 Test loss=0.558972 Current lr=[3.154451112068745e-05]

[0/23] Train loss=0.03617562726140022
[5/23] Train loss=0.0390433706343174
[10/23] Train loss=0.043185967952013016
[15/23] Train loss=0.03174738585948944
[20/23] Train loss=0.04104935750365257
Test set avg_accuracy=90.83% avg_sensitivity=81.94%, avg_specificity=93.51% avg_auc=0.9506
Fold[8] Epoch: 93 [93/100 (93%)] Train loss=0.034803 Test loss=0.557992 Current lr=[2.4175058265291265e-05]

[0/23] Train loss=0.028534723445773125
[5/23] Train loss=0.04848446696996689
[10/23] Train loss=0.04956190660595894
[15/23] Train loss=0.03908160701394081
[20/23] Train loss=0.024317629635334015
Test set avg_accuracy=90.79% avg_sensitivity=81.99%, avg_specificity=93.43% avg_auc=0.9507
Fold[8] Epoch: 94 [94/100 (94%)] Train loss=0.034580 Test loss=0.558649 Current lr=[1.7763857546248248e-05]

[0/23] Train loss=0.042297013103961945
[5/23] Train loss=0.03785623237490654
[10/23] Train loss=0.04151672124862671
[15/23] Train loss=0.030405785888433456
[20/23] Train loss=0.023657193407416344
Test set avg_accuracy=90.76% avg_sensitivity=82.14%, avg_specificity=93.36% avg_auc=0.9507
Fold[8] Epoch: 95 [95/100 (95%)] Train loss=0.032922 Test loss=0.559456 Current lr=[1.2323820268587161e-05]

[0/23] Train loss=0.0367562472820282
[5/23] Train loss=0.035605717450380325
[10/23] Train loss=0.03921886533498764
[15/23] Train loss=0.03798985853791237
[20/23] Train loss=0.02917449362576008
Test set avg_accuracy=90.79% avg_sensitivity=82.19%, avg_specificity=93.37% avg_auc=0.9506
Fold[8] Epoch: 96 [96/100 (96%)] Train loss=0.032981 Test loss=0.559703 Current lr=[7.865901943410707e-06]

[0/23] Train loss=0.034780409187078476
[5/23] Train loss=0.03532258793711662
[10/23] Train loss=0.03977489843964577
[15/23] Train loss=0.028033029288053513
[20/23] Train loss=0.023694222792983055
Test set avg_accuracy=90.83% avg_sensitivity=82.19%, avg_specificity=93.43% avg_auc=0.9506
Fold[8] Epoch: 97 [97/100 (97%)] Train loss=0.035120 Test loss=0.559869 Current lr=[4.399080224954306e-06]

[0/23] Train loss=0.03016442432999611
[5/23] Train loss=0.041627924889326096
[10/23] Train loss=0.05292097479104996
[15/23] Train loss=0.03247854858636856
[20/23] Train loss=0.02679019793868065
Test set avg_accuracy=90.82% avg_sensitivity=82.19%, avg_specificity=93.42% avg_auc=0.9506
Fold[8] Epoch: 98 [98/100 (98%)] Train loss=0.035570 Test loss=0.559899 Current lr=[1.930336830785271e-06]

[0/23] Train loss=0.032960519194602966
[5/23] Train loss=0.03889555484056473
[10/23] Train loss=0.03555762395262718
[15/23] Train loss=0.0371876060962677
[20/23] Train loss=0.027967650443315506
Test set avg_accuracy=90.82% avg_sensitivity=82.19%, avg_specificity=93.42% avg_auc=0.9507
Fold[8] Epoch: 99 [99/100 (99%)] Train loss=0.033907 Test loss=0.559964 Current lr=[4.6464348155246055e-07]

[0/23] Train loss=0.04320232570171356
[5/23] Train loss=0.039903514087200165
[10/23] Train loss=0.04089243337512016
[15/23] Train loss=0.02505093440413475
[20/23] Train loss=0.024671465158462524
Test set avg_accuracy=90.82% avg_sensitivity=82.19%, avg_specificity=93.42% avg_auc=0.9507
Fold[8] Epoch: 100 [100/100 (100%)] Train loss=0.033996 Test loss=0.559975 Current lr=[4.951888602991508e-09]

Fold[8] Best Result: acc=90.4188181296615 sen=88.98809523809523, spe=90.84938050455293, auc=0.9562764194845476!
[0/23] Train loss=1.3883222341537476
[5/23] Train loss=1.4069945812225342
[10/23] Train loss=1.3307409286499023
[15/23] Train loss=1.2041605710983276
[20/23] Train loss=1.0909199714660645
Test set avg_accuracy=74.32% avg_sensitivity=20.08%, avg_specificity=92.77% avg_auc=0.7311
Best model saved!! Metric=-65.70397069471291!!
Fold[9] Epoch: 1 [1/100 (1%)] Train loss=1.249743 Test loss=0.526435 Current lr=[4.263712153319496e-05]

[0/23] Train loss=1.0411971807479858
[5/23] Train loss=1.0145095586776733
[10/23] Train loss=1.0935338735580444
[15/23] Train loss=0.9161517024040222
[20/23] Train loss=0.9430137276649475
Test set avg_accuracy=78.38% avg_sensitivity=44.58%, avg_specificity=89.88% avg_auc=0.8040
Best model saved!! Metric=-32.75073002459078!!
Fold[9] Epoch: 2 [2/100 (2%)] Train loss=0.998286 Test loss=0.518690 Current lr=[5.051950942452628e-05]

[0/23] Train loss=0.8780389428138733
[5/23] Train loss=0.9698021411895752
[10/23] Train loss=1.0473284721374512
[15/23] Train loss=0.8532189130783081
[20/23] Train loss=0.8435556888580322
Test set avg_accuracy=80.27% avg_sensitivity=44.86%, avg_specificity=92.31% avg_auc=0.8271
Best model saved!! Metric=-25.836566829958727!!
Fold[9] Epoch: 3 [3/100 (3%)] Train loss=0.913933 Test loss=0.503626 Current lr=[6.356055194548904e-05]

[0/23] Train loss=0.8382075428962708
[5/23] Train loss=0.935671865940094
[10/23] Train loss=1.0455821752548218
[15/23] Train loss=0.8037670850753784
[20/23] Train loss=0.7862537503242493
Test set avg_accuracy=82.95% avg_sensitivity=57.46%, avg_specificity=91.62% avg_auc=0.8601
Best model saved!! Metric=-7.962867728362951!!
Fold[9] Epoch: 4 [4/100 (4%)] Train loss=0.867944 Test loss=0.445864 Current lr=[8.161695403755248e-05]

[0/23] Train loss=0.8164569139480591
[5/23] Train loss=0.9282182455062866
[10/23] Train loss=0.961945116519928
[15/23] Train loss=0.769774854183197
[20/23] Train loss=0.7254552841186523
Test set avg_accuracy=84.60% avg_sensitivity=64.76%, avg_specificity=91.35% avg_auc=0.8857
Best model saved!! Metric=3.282700276181888!!
Fold[9] Epoch: 5 [5/100 (5%)] Train loss=0.828765 Test loss=0.398636 Current lr=[0.00010449031183917899]

[0/23] Train loss=0.759000301361084
[5/23] Train loss=0.941315233707428
[10/23] Train loss=0.9079821109771729
[15/23] Train loss=0.7551950216293335
[20/23] Train loss=0.6745543479919434
Test set avg_accuracy=85.57% avg_sensitivity=73.59%, avg_specificity=89.64% avg_auc=0.9056
Best model saved!! Metric=13.370302117215534!!
Fold[9] Epoch: 6 [6/100 (6%)] Train loss=0.794367 Test loss=0.366168 Current lr=[0.00013192929274872232]

[0/23] Train loss=0.6676456332206726
[5/23] Train loss=0.9097791314125061
[10/23] Train loss=0.9019052386283875
[15/23] Train loss=0.7042323350906372
[20/23] Train loss=0.6508206725120544
Test set avg_accuracy=86.17% avg_sensitivity=77.13%, avg_specificity=89.25% avg_auc=0.9162
Best model saved!! Metric=18.16453094417078!!
Fold[9] Epoch: 7 [7/100 (7%)] Train loss=0.762597 Test loss=0.368036 Current lr=[0.00016363239706865967]

[0/23] Train loss=0.6277753710746765
[5/23] Train loss=0.9041703343391418
[10/23] Train loss=0.8819621205329895
[15/23] Train loss=0.6961574554443359
[20/23] Train loss=0.5876011848449707
Test set avg_accuracy=85.69% avg_sensitivity=79.54%, avg_specificity=87.78% avg_auc=0.9193
Best model saved!! Metric=18.938458991337654!!
Fold[9] Epoch: 8 [8/100 (8%)] Train loss=0.734295 Test loss=0.386238 Current lr=[0.00019925127088619402]

[0/23] Train loss=0.5864641070365906
[5/23] Train loss=0.8835529088973999
[10/23] Train loss=0.8700575828552246
[15/23] Train loss=0.6931167244911194
[20/23] Train loss=0.6044681668281555
Test set avg_accuracy=87.03% avg_sensitivity=76.29%, avg_specificity=90.69% avg_auc=0.9200
Best model saved!! Metric=20.011275282737707!!
Fold[9] Epoch: 9 [9/100 (9%)] Train loss=0.720230 Test loss=0.373406 Current lr=[0.00023839453378827395]

[0/23] Train loss=0.5734488368034363
[5/23] Train loss=0.9560872912406921
[10/23] Train loss=0.8979317545890808
[15/23] Train loss=0.669668972492218
[20/23] Train loss=0.5640214681625366
Test set avg_accuracy=86.31% avg_sensitivity=81.26%, avg_specificity=88.03% avg_auc=0.9269
Best model saved!! Metric=22.29778403993999!!
Fold[9] Epoch: 10 [10/100 (10%)] Train loss=0.712130 Test loss=0.391106 Current lr=[0.00028063207935207196]

[0/23] Train loss=0.510732889175415
[5/23] Train loss=0.9355061650276184
[10/23] Train loss=0.8890546560287476
[15/23] Train loss=0.6289416551589966
[20/23] Train loss=0.5343764424324036
Test set avg_accuracy=86.41% avg_sensitivity=78.24%, avg_specificity=89.18% avg_auc=0.9222
Fold[9] Epoch: 11 [11/100 (11%)] Train loss=0.692754 Test loss=0.380857 Current lr=[0.0003254998011571065]

[0/23] Train loss=0.5443935394287109
[5/23] Train loss=0.8817845582962036
[10/23] Train loss=0.8475841879844666
[15/23] Train loss=0.6295105218887329
[20/23] Train loss=0.5478772521018982
Test set avg_accuracy=86.55% avg_sensitivity=82.85%, avg_specificity=87.81% avg_auc=0.9302
Best model saved!! Metric=24.226217188395584!!
Fold[9] Epoch: 12 [12/100 (12%)] Train loss=0.680113 Test loss=0.390262 Current lr=[0.0003725046923895547]

[0/23] Train loss=0.5104444026947021
[5/23] Train loss=0.9041510224342346
[10/23] Train loss=0.8421290516853333
[15/23] Train loss=0.6168674230575562
[20/23] Train loss=0.5595941543579102
Test set avg_accuracy=87.27% avg_sensitivity=73.36%, avg_specificity=92.00% avg_auc=0.9189
Fold[9] Epoch: 13 [13/100 (13%)] Train loss=0.669353 Test loss=0.346904 Current lr=[0.0004211302630042728]

[0/23] Train loss=0.5196124911308289
[5/23] Train loss=0.8522851467132568
[10/23] Train loss=0.7979912757873535
[15/23] Train loss=0.6352553367614746
[20/23] Train loss=0.546881377696991
Test set avg_accuracy=87.13% avg_sensitivity=77.13%, avg_specificity=90.53% avg_auc=0.9255
Fold[9] Epoch: 14 [14/100 (14%)] Train loss=0.654167 Test loss=0.334210 Current lr=[0.0004708422149207104]

[0/23] Train loss=0.5123533606529236
[5/23] Train loss=0.8419713377952576
[10/23] Train loss=0.8287323713302612
[15/23] Train loss=0.5896968245506287
[20/23] Train loss=0.5054512023925781
Test set avg_accuracy=87.13% avg_sensitivity=81.54%, avg_specificity=89.03% avg_auc=0.9301
Best model saved!! Metric=24.704751613488998!!
Fold[9] Epoch: 15 [15/100 (15%)] Train loss=0.648895 Test loss=0.343372 Current lr=[0.0005210943128936348]

[0/23] Train loss=0.5159091949462891
[5/23] Train loss=0.8798748254776001
[10/23] Train loss=0.8450948596000671
[15/23] Train loss=0.5938779711723328
[20/23] Train loss=0.5416737794876099
Test set avg_accuracy=86.31% avg_sensitivity=88.01%, avg_specificity=85.74% avg_auc=0.9345
Best model saved!! Metric=27.50216877369285!!
Fold[9] Epoch: 16 [16/100 (16%)] Train loss=0.650272 Test loss=0.365658 Current lr=[0.0005713343865494929]

[0/23] Train loss=0.4866337776184082
[5/23] Train loss=0.9146087169647217
[10/23] Train loss=0.7738032341003418
[15/23] Train loss=0.5809144377708435
[20/23] Train loss=0.5807478427886963
Test set avg_accuracy=87.34% avg_sensitivity=68.53%, avg_specificity=93.74% avg_auc=0.9212
Fold[9] Epoch: 17 [17/100 (17%)] Train loss=0.646197 Test loss=0.323961 Current lr=[0.0006210103976380052]

[0/23] Train loss=0.5374745726585388
[5/23] Train loss=0.8418607115745544
[10/23] Train loss=0.8029568791389465
[15/23] Train loss=0.5755382776260376
[20/23] Train loss=0.49364322423934937
Test set avg_accuracy=87.69% avg_sensitivity=77.45%, avg_specificity=91.18% avg_auc=0.9219
Fold[9] Epoch: 18 [18/100 (18%)] Train loss=0.640844 Test loss=0.336277 Current lr=[0.0006695765058319851]

[0/23] Train loss=0.5036128163337708
[5/23] Train loss=0.8273701071739197
[10/23] Train loss=0.7997608780860901
[15/23] Train loss=0.5802490711212158
[20/23] Train loss=0.5101063847541809
Test set avg_accuracy=87.76% avg_sensitivity=80.99%, avg_specificity=90.07% avg_auc=0.9337
Fold[9] Epoch: 19 [19/100 (19%)] Train loss=0.619295 Test loss=0.317830 Current lr=[0.0007164990664243417]

[0/23] Train loss=0.4413262903690338
[5/23] Train loss=0.8349714875221252
[10/23] Train loss=0.7997279167175293
[15/23] Train loss=0.5774970054626465
[20/23] Train loss=0.5145004391670227
Test set avg_accuracy=87.80% avg_sensitivity=75.08%, avg_specificity=92.13% avg_auc=0.9280
Fold[9] Epoch: 20 [20/100 (20%)] Train loss=0.621656 Test loss=0.304517 Current lr=[0.0007612624940195301]

[0/23] Train loss=0.4880084693431854
[5/23] Train loss=0.8411360383033752
[10/23] Train loss=0.7798782587051392
[15/23] Train loss=0.548071563243866
[20/23] Train loss=0.527895987033844
Test set avg_accuracy=87.62% avg_sensitivity=75.13%, avg_specificity=91.87% avg_auc=0.9244
Fold[9] Epoch: 21 [21/100 (21%)] Train loss=0.618125 Test loss=0.322750 Current lr=[0.000803374927789172]

[0/23] Train loss=0.4859502911567688
[5/23] Train loss=0.7968542575836182
[10/23] Train loss=0.7289778590202332
[15/23] Train loss=0.5508114099502563
[20/23] Train loss=0.48253798484802246
Test set avg_accuracy=87.55% avg_sensitivity=78.89%, avg_specificity=90.50% avg_auc=0.9320
Fold[9] Epoch: 22 [22/100 (22%)] Train loss=0.601993 Test loss=0.314492 Current lr=[0.0008423736360419787]

[0/23] Train loss=0.4607282876968384
[5/23] Train loss=0.7886157035827637
[10/23] Train loss=0.7121351957321167
[15/23] Train loss=0.594724714756012
[20/23] Train loss=0.5018611550331116
Test set avg_accuracy=86.57% avg_sensitivity=58.76%, avg_specificity=96.03% avg_auc=0.8989
Fold[9] Epoch: 23 [23/100 (23%)] Train loss=0.610109 Test loss=0.381035 Current lr=[0.0008778301007225328]

[0/23] Train loss=0.46353140473365784
[5/23] Train loss=0.8075100779533386
[10/23] Train loss=0.7370564937591553
[15/23] Train loss=0.6036399006843567
[20/23] Train loss=0.5397395491600037
Test set avg_accuracy=86.63% avg_sensitivity=85.63%, avg_specificity=86.97% avg_auc=0.9387
Fold[9] Epoch: 24 [24/100 (24%)] Train loss=0.610984 Test loss=0.332769 Current lr=[0.0009093547259704173]

[0/23] Train loss=0.4605420231819153
[5/23] Train loss=0.8060942888259888
[10/23] Train loss=0.743508517742157
[15/23] Train loss=0.5914552211761475
[20/23] Train loss=0.47294744849205017
Test set avg_accuracy=88.00% avg_sensitivity=81.96%, avg_specificity=90.05% avg_auc=0.9323
Fold[9] Epoch: 25 [25/100 (25%)] Train loss=0.603958 Test loss=0.327852 Current lr=[0.0009366011190020192]

[0/23] Train loss=0.46690961718559265
[5/23] Train loss=0.7432664632797241
[10/23] Train loss=0.7155079245567322
[15/23] Train loss=0.5507263541221619
[20/23] Train loss=0.49056798219680786
Test set avg_accuracy=87.35% avg_sensitivity=77.08%, avg_specificity=90.84% avg_auc=0.9309
Fold[9] Epoch: 26 [26/100 (26%)] Train loss=0.590530 Test loss=0.305624 Current lr=[0.0009592698962766488]

[0/23] Train loss=0.44972363114356995
[5/23] Train loss=0.7968661189079285
[10/23] Train loss=0.7367650866508484
[15/23] Train loss=0.5291221141815186
[20/23] Train loss=0.4772428870201111
Test set avg_accuracy=87.53% avg_sensitivity=85.87%, avg_specificity=88.09% avg_auc=0.9370
Best model saved!! Metric=29.19193909228308!!
Fold[9] Epoch: 27 [27/100 (27%)] Train loss=0.583842 Test loss=0.321750 Current lr=[0.0009771119731247974]

[0/23] Train loss=0.4711475670337677
[5/23] Train loss=0.825930655002594
[10/23] Train loss=0.7783980369567871
[15/23] Train loss=0.5340626239776611
[20/23] Train loss=0.48555392026901245
Test set avg_accuracy=87.87% avg_sensitivity=77.03%, avg_specificity=91.56% avg_auc=0.9251
Fold[9] Epoch: 28 [28/100 (28%)] Train loss=0.603583 Test loss=0.322135 Current lr=[0.0009899313006920766]

[0/23] Train loss=0.4481154978275299
[5/23] Train loss=0.7122071981430054
[10/23] Train loss=0.6996518969535828
[15/23] Train loss=0.5277978181838989
[20/23] Train loss=0.42958682775497437
Test set avg_accuracy=88.27% avg_sensitivity=81.31%, avg_specificity=90.64% avg_auc=0.9287
Fold[9] Epoch: 29 [29/100 (29%)] Train loss=0.566671 Test loss=0.325904 Current lr=[0.0009975870201252835]

[0/23] Train loss=0.47133979201316833
[5/23] Train loss=0.6978448033332825
[10/23] Train loss=0.7189318537712097
[15/23] Train loss=0.5476166605949402
[20/23] Train loss=0.44413065910339355
Test set avg_accuracy=88.06% avg_sensitivity=76.34%, avg_specificity=92.05% avg_auc=0.9164
Fold[9] Epoch: 30 [30/100 (30%)] Train loss=0.569248 Test loss=0.344404 Current lr=[0.000999999048111397]

[0/23] Train loss=0.47078773379325867
[5/23] Train loss=0.7232197523117065
[10/23] Train loss=0.6993154883384705
[15/23] Train loss=0.5418228507041931
[20/23] Train loss=0.47018882632255554
Test set avg_accuracy=88.01% avg_sensitivity=74.80%, avg_specificity=92.50% avg_auc=0.9246
Fold[9] Epoch: 31 [31/100 (31%)] Train loss=0.565243 Test loss=0.329743 Current lr=[0.000999451812190372]

[0/23] Train loss=0.4437932074069977
[5/23] Train loss=0.6906065344810486
[10/23] Train loss=0.6936948299407959
[15/23] Train loss=0.5222709774971008
[20/23] Train loss=0.45229488611221313
Test set avg_accuracy=87.81% avg_sensitivity=79.27%, avg_specificity=90.72% avg_auc=0.9180
Fold[9] Epoch: 32 [32/100 (32%)] Train loss=0.553305 Test loss=0.359310 Current lr=[0.0009978987508156897]

[0/23] Train loss=0.4147978127002716
[5/23] Train loss=0.6835071444511414
[10/23] Train loss=0.6825222969055176
[15/23] Train loss=0.5046376585960388
[20/23] Train loss=0.43266433477401733
Test set avg_accuracy=88.46% avg_sensitivity=81.54%, avg_specificity=90.81% avg_auc=0.9275
Fold[9] Epoch: 33 [33/100 (33%)] Train loss=0.535561 Test loss=0.335331 Current lr=[0.0009953429916462733]

[0/23] Train loss=0.4425170421600342
[5/23] Train loss=0.6555054783821106
[10/23] Train loss=0.7104343771934509
[15/23] Train loss=0.5077235698699951
[20/23] Train loss=0.42171603441238403
Test set avg_accuracy=87.88% avg_sensitivity=83.22%, avg_specificity=89.47% avg_auc=0.9356
Fold[9] Epoch: 34 [34/100 (34%)] Train loss=0.532281 Test loss=0.328651 Current lr=[0.000991789681640963]

[0/23] Train loss=0.42748430371284485
[5/23] Train loss=0.708374559879303
[10/23] Train loss=0.7367319464683533
[15/23] Train loss=0.5360456109046936
[20/23] Train loss=0.4545551836490631
Test set avg_accuracy=87.75% avg_sensitivity=70.53%, avg_specificity=93.61% avg_auc=0.9245
Fold[9] Epoch: 35 [35/100 (35%)] Train loss=0.547517 Test loss=0.327790 Current lr=[0.0009872459766932253]

[0/23] Train loss=0.41626524925231934
[5/23] Train loss=0.7220408916473389
[10/23] Train loss=0.7336938381195068
[15/23] Train loss=0.5053059458732605
[20/23] Train loss=0.4305792450904846
Test set avg_accuracy=87.03% avg_sensitivity=81.13%, avg_specificity=89.04% avg_auc=0.9288
Fold[9] Epoch: 36 [36/100 (36%)] Train loss=0.536681 Test loss=0.346846 Current lr=[0.0009817210272201372]

[0/23] Train loss=0.3945283889770508
[5/23] Train loss=0.6787227988243103
[10/23] Train loss=0.6640610098838806
[15/23] Train loss=0.5107537508010864
[20/23] Train loss=0.4205440878868103
Test set avg_accuracy=87.17% avg_sensitivity=82.75%, avg_specificity=88.68% avg_auc=0.9303
Fold[9] Epoch: 37 [37/100 (37%)] Train loss=0.530951 Test loss=0.357788 Current lr=[0.0009752259597346622]

[0/23] Train loss=0.46021828055381775
[5/23] Train loss=0.7213550806045532
[10/23] Train loss=0.7224480509757996
[15/23] Train loss=0.4911326766014099
[20/23] Train loss=0.4293260872364044
Test set avg_accuracy=87.15% avg_sensitivity=79.59%, avg_specificity=89.72% avg_auc=0.9268
Fold[9] Epoch: 38 [38/100 (38%)] Train loss=0.542701 Test loss=0.382095 Current lr=[0.000967773854438336]

[0/23] Train loss=0.4071192443370819
[5/23] Train loss=0.669189453125
[10/23] Train loss=0.7415891885757446
[15/23] Train loss=0.4782925248146057
[20/23] Train loss=0.3932511806488037
Test set avg_accuracy=87.19% avg_sensitivity=79.68%, avg_specificity=89.74% avg_auc=0.9221
Fold[9] Epoch: 39 [39/100 (39%)] Train loss=0.529586 Test loss=0.380388 Current lr=[0.000959379718879479]

[0/23] Train loss=0.41414034366607666
[5/23] Train loss=0.6597154140472412
[10/23] Train loss=0.6646072864532471
[15/23] Train loss=0.5090805888175964
[20/23] Train loss=0.4450647234916687
Test set avg_accuracy=87.92% avg_sensitivity=77.87%, avg_specificity=91.33% avg_auc=0.9185
Fold[9] Epoch: 40 [40/100 (40%)] Train loss=0.521185 Test loss=0.380805 Current lr=[0.0009500604577299936]

[0/23] Train loss=0.4155440628528595
[5/23] Train loss=0.6290188431739807
[10/23] Train loss=0.6086910367012024
[15/23] Train loss=0.49403491616249084
[20/23] Train loss=0.3875190317630768
Test set avg_accuracy=88.02% avg_sensitivity=81.59%, avg_specificity=90.21% avg_auc=0.9268
Fold[9] Epoch: 41 [41/100 (41%)] Train loss=0.500459 Test loss=0.375582 Current lr=[0.0009398348387416027]

[0/23] Train loss=0.38913753628730774
[5/23] Train loss=0.6706470847129822
[10/23] Train loss=0.6835610866546631
[15/23] Train loss=0.4875364601612091
[20/23] Train loss=0.4075186252593994
Test set avg_accuracy=87.85% avg_sensitivity=80.01%, avg_specificity=90.51% avg_auc=0.9298
Fold[9] Epoch: 42 [42/100 (42%)] Train loss=0.518831 Test loss=0.363625 Current lr=[0.000928723454950097]

[0/23] Train loss=0.4070858359336853
[5/23] Train loss=0.6123772859573364
[10/23] Train loss=0.6566298604011536
[15/23] Train loss=0.5107408761978149
[20/23] Train loss=0.41336944699287415
Test set avg_accuracy=88.04% avg_sensitivity=82.24%, avg_specificity=90.01% avg_auc=0.9350
Fold[9] Epoch: 43 [43/100 (43%)] Train loss=0.495194 Test loss=0.359295 Current lr=[0.0009167486832037001]

[0/23] Train loss=0.4067053198814392
[5/23] Train loss=0.6589332222938538
[10/23] Train loss=0.6569843292236328
[15/23] Train loss=0.4977840185165405
[20/23] Train loss=0.40554893016815186
Test set avg_accuracy=87.74% avg_sensitivity=77.87%, avg_specificity=91.10% avg_auc=0.9300
Fold[9] Epoch: 44 [44/100 (44%)] Train loss=0.501336 Test loss=0.380942 Current lr=[0.0009039346390990754]

[0/23] Train loss=0.39673689007759094
[5/23] Train loss=0.6038296818733215
[10/23] Train loss=0.5961281061172485
[15/23] Train loss=0.4908498525619507
[20/23] Train loss=0.3876810073852539
Test set avg_accuracy=87.46% avg_sensitivity=70.48%, avg_specificity=93.23% avg_auc=0.9191
Fold[9] Epoch: 45 [45/100 (45%)] Train loss=0.485370 Test loss=0.414809 Current lr=[0.000890307128415723]

[0/23] Train loss=0.4295111894607544
[5/23] Train loss=0.5519144535064697
[10/23] Train loss=0.5948642492294312
[15/23] Train loss=0.4636412560939789
[20/23] Train loss=0.4008149802684784
Test set avg_accuracy=87.45% avg_sensitivity=83.36%, avg_specificity=88.84% avg_auc=0.9384
Fold[9] Epoch: 46 [46/100 (46%)] Train loss=0.474252 Test loss=0.376057 Current lr=[0.0008758935951465738]

[0/23] Train loss=0.37969985604286194
[5/23] Train loss=0.5918424725532532
[10/23] Train loss=0.582886815071106
[15/23] Train loss=0.4651281535625458
[20/23] Train loss=0.40380704402923584
Test set avg_accuracy=87.63% avg_sensitivity=75.08%, avg_specificity=91.90% avg_auc=0.9260
Fold[9] Epoch: 47 [47/100 (47%)] Train loss=0.470731 Test loss=0.385987 Current lr=[0.0008607230662294413]

[0/23] Train loss=0.382425993680954
[5/23] Train loss=0.5181299448013306
[10/23] Train loss=0.5305044054985046
[15/23] Train loss=0.45285743474960327
[20/23] Train loss=0.3688461482524872
Test set avg_accuracy=87.71% avg_sensitivity=84.80%, avg_specificity=88.69% avg_auc=0.9388
Fold[9] Epoch: 48 [48/100 (48%)] Train loss=0.456261 Test loss=0.371628 Current lr=[0.0008448260930906307]

[0/23] Train loss=0.36942222714424133
[5/23] Train loss=0.5354535579681396
[10/23] Train loss=0.5442537069320679
[15/23] Train loss=0.46356967091560364
[20/23] Train loss=0.3902805745601654
Test set avg_accuracy=87.87% avg_sensitivity=78.34%, avg_specificity=91.11% avg_auc=0.9325
Fold[9] Epoch: 49 [49/100 (49%)] Train loss=0.449869 Test loss=0.368876 Current lr=[0.0008282346901184324]

[0/23] Train loss=0.3671119809150696
[5/23] Train loss=0.5151503682136536
[10/23] Train loss=0.5056226849555969
[15/23] Train loss=0.43585991859436035
[20/23] Train loss=0.38582658767700195
Test set avg_accuracy=87.95% avg_sensitivity=78.01%, avg_specificity=91.33% avg_auc=0.9284
Fold[9] Epoch: 50 [50/100 (50%)] Train loss=0.434861 Test loss=0.367348 Current lr=[0.000810982270190405]

[0/23] Train loss=0.3629883825778961
[5/23] Train loss=0.49392378330230713
[10/23] Train loss=0.4813588857650757
[15/23] Train loss=0.446271151304245
[20/23] Train loss=0.3586317300796509
Test set avg_accuracy=88.72% avg_sensitivity=80.33%, avg_specificity=91.57% avg_auc=0.9337
Fold[9] Epoch: 51 [51/100 (51%)] Train loss=0.413791 Test loss=0.372152 Current lr=[0.0007931035773842862]

[0/23] Train loss=0.37770918011665344
[5/23] Train loss=0.5005325078964233
[10/23] Train loss=0.4783574044704437
[15/23] Train loss=0.4241664409637451
[20/23] Train loss=0.3421647250652313
Test set avg_accuracy=88.35% avg_sensitivity=81.92%, avg_specificity=90.54% avg_auc=0.9406
Fold[9] Epoch: 52 [52/100 (52%)] Train loss=0.392253 Test loss=0.363570 Current lr=[0.0007746346170080441]

[0/23] Train loss=0.3341883420944214
[5/23] Train loss=0.4436475336551666
[10/23] Train loss=0.48647552728652954
[15/23] Train loss=0.39248690009117126
[20/23] Train loss=0.30696043372154236
Test set avg_accuracy=88.93% avg_sensitivity=80.29%, avg_specificity=91.87% avg_auc=0.9379
Fold[9] Epoch: 53 [53/100 (53%)] Train loss=0.395042 Test loss=0.354244 Current lr=[0.0007556125830899786]

[0/23] Train loss=0.34538865089416504
[5/23] Train loss=0.4891638457775116
[10/23] Train loss=0.43104270100593567
[15/23] Train loss=0.3984217643737793
[20/23] Train loss=0.3039148449897766
Test set avg_accuracy=88.06% avg_sensitivity=82.98%, avg_specificity=89.78% avg_auc=0.9383
Fold[9] Epoch: 54 [54/100 (54%)] Train loss=0.373583 Test loss=0.360794 Current lr=[0.0007360757834748981]

[0/23] Train loss=0.3498677611351013
[5/23] Train loss=0.397977352142334
[10/23] Train loss=0.42347604036331177
[15/23] Train loss=0.3841593265533447
[20/23] Train loss=0.2983412444591522
Test set avg_accuracy=87.89% avg_sensitivity=82.38%, avg_specificity=89.77% avg_auc=0.9347
Fold[9] Epoch: 55 [55/100 (55%)] Train loss=0.358815 Test loss=0.371521 Current lr=[0.000716063562677219]

[0/23] Train loss=0.3250134289264679
[5/23] Train loss=0.4281318485736847
[10/23] Train loss=0.4113875925540924
[15/23] Train loss=0.3912520408630371
[20/23] Train loss=0.31256285309791565
Test set avg_accuracy=87.96% avg_sensitivity=79.92%, avg_specificity=90.70% avg_auc=0.9325
Fold[9] Epoch: 56 [56/100 (56%)] Train loss=0.353383 Test loss=0.363668 Current lr=[0.0006956162226463489]

[0/23] Train loss=0.31154534220695496
[5/23] Train loss=0.3803252577781677
[10/23] Train loss=0.37148529291152954
[15/23] Train loss=0.3499704599380493
[20/23] Train loss=0.2916085124015808
Test set avg_accuracy=88.93% avg_sensitivity=79.64%, avg_specificity=92.09% avg_auc=0.9302
Fold[9] Epoch: 57 [57/100 (57%)] Train loss=0.335848 Test loss=0.376560 Current lr=[0.0006747749416039243]

[0/23] Train loss=0.2960050702095032
[5/23] Train loss=0.36719948053359985
[10/23] Train loss=0.3822210431098938
[15/23] Train loss=0.38503286242485046
[20/23] Train loss=0.30317944288253784
Test set avg_accuracy=88.21% avg_sensitivity=79.73%, avg_specificity=91.10% avg_auc=0.9357
Fold[9] Epoch: 58 [58/100 (58%)] Train loss=0.328848 Test loss=0.375225 Current lr=[0.000653581691116352]

[0/23] Train loss=0.3003045320510864
[5/23] Train loss=0.3709360957145691
[10/23] Train loss=0.386852890253067
[15/23] Train loss=0.34691157937049866
[20/23] Train loss=0.24636299908161163
Test set avg_accuracy=88.65% avg_sensitivity=78.34%, avg_specificity=92.16% avg_auc=0.9342
Fold[9] Epoch: 59 [59/100 (59%)] Train loss=0.326632 Test loss=0.380448 Current lr=[0.0006320791515696602]

[0/23] Train loss=0.2792261242866516
[5/23] Train loss=0.34931662678718567
[10/23] Train loss=0.32360291481018066
[15/23] Train loss=0.3093838393688202
[20/23] Train loss=0.25397464632987976
Test set avg_accuracy=88.47% avg_sensitivity=82.75%, avg_specificity=90.42% avg_auc=0.9381
Best model saved!! Metric=29.45052821842159!!
Fold[9] Epoch: 60 [60/100 (60%)] Train loss=0.302885 Test loss=0.366196 Current lr=[0.0006103106262168818]

[0/23] Train loss=0.27684715390205383
[5/23] Train loss=0.3497675955295563
[10/23] Train loss=0.34884804487228394
[15/23] Train loss=0.32856160402297974
[20/23] Train loss=0.28266599774360657
Test set avg_accuracy=89.04% avg_sensitivity=80.43%, avg_specificity=91.97% avg_auc=0.9373
Fold[9] Epoch: 61 [61/100 (61%)] Train loss=0.295504 Test loss=0.354265 Current lr=[0.0005883199539710647]

[0/23] Train loss=0.2883959412574768
[5/23] Train loss=0.3105488121509552
[10/23] Train loss=0.3487001359462738
[15/23] Train loss=0.2961810231208801
[20/23] Train loss=0.24250659346580505
Test set avg_accuracy=88.66% avg_sensitivity=78.75%, avg_specificity=92.03% avg_auc=0.9369
Fold[9] Epoch: 62 [62/100 (62%)] Train loss=0.283505 Test loss=0.369125 Current lr=[0.0005661514211195354]

[0/23] Train loss=0.27422893047332764
[5/23] Train loss=0.3268137276172638
[10/23] Train loss=0.29730385541915894
[15/23] Train loss=0.2961626350879669
[20/23] Train loss=0.26300209760665894
Test set avg_accuracy=88.90% avg_sensitivity=79.50%, avg_specificity=92.09% avg_auc=0.9362
Fold[9] Epoch: 63 [63/100 (63%)] Train loss=0.273104 Test loss=0.366259 Current lr=[0.00054384967213721]

[0/23] Train loss=0.25405511260032654
[5/23] Train loss=0.27873551845550537
[10/23] Train loss=0.28348708152770996
[15/23] Train loss=0.3047831356525421
[20/23] Train loss=0.2085418552160263
Test set avg_accuracy=88.63% avg_sensitivity=82.10%, avg_specificity=90.84% avg_auc=0.9369
Fold[9] Epoch: 64 [64/100 (64%)] Train loss=0.258481 Test loss=0.378159 Current lr=[0.000521459619778564]

[0/23] Train loss=0.23828929662704468
[5/23] Train loss=0.26007694005966187
[10/23] Train loss=0.2882820963859558
[15/23] Train loss=0.26622825860977173
[20/23] Train loss=0.2089938074350357
Test set avg_accuracy=88.25% avg_sensitivity=77.50%, avg_specificity=91.90% avg_auc=0.9322
Fold[9] Epoch: 65 [65/100 (65%)] Train loss=0.247519 Test loss=0.395177 Current lr=[0.0004990263546293204]

[0/23] Train loss=0.23072971403598785
[5/23] Train loss=0.24714167416095734
[10/23] Train loss=0.24494345486164093
[15/23] Train loss=0.28509894013404846
[20/23] Train loss=0.20908358693122864
Test set avg_accuracy=88.94% avg_sensitivity=80.89%, avg_specificity=91.68% avg_auc=0.9384
Fold[9] Epoch: 66 [66/100 (66%)] Train loss=0.236652 Test loss=0.376411 Current lr=[0.000476595054300012]

[0/23] Train loss=0.24123325943946838
[5/23] Train loss=0.2886511981487274
[10/23] Train loss=0.2672431766986847
[15/23] Train loss=0.23555782437324524
[20/23] Train loss=0.211420476436615
Test set avg_accuracy=89.16% avg_sensitivity=82.89%, avg_specificity=91.29% avg_auc=0.9378
Best model saved!! Metric=31.111360530416704!!
Fold[9] Epoch: 67 [67/100 (67%)] Train loss=0.230087 Test loss=0.398577 Current lr=[0.0004542108924442853]

[0/23] Train loss=0.2272103726863861
[5/23] Train loss=0.2477889209985733
[10/23] Train loss=0.2361718863248825
[15/23] Train loss=0.22485031187534332
[20/23] Train loss=0.18289072811603546
Test set avg_accuracy=88.70% avg_sensitivity=78.43%, avg_specificity=92.19% avg_auc=0.9369
Fold[9] Epoch: 68 [68/100 (68%)] Train loss=0.219307 Test loss=0.402240 Current lr=[0.000431918947785175]

[0/23] Train loss=0.21411721408367157
[5/23] Train loss=0.23926743865013123
[10/23] Train loss=0.23461727797985077
[15/23] Train loss=0.2114894986152649
[20/23] Train loss=0.19771423935890198
Test set avg_accuracy=89.03% avg_sensitivity=80.15%, avg_specificity=92.05% avg_auc=0.9379
Fold[9] Epoch: 69 [69/100 (69%)] Train loss=0.207930 Test loss=0.388990 Current lr=[0.0004097641133325535]

[0/23] Train loss=0.1816454827785492
[5/23] Train loss=0.2825137972831726
[10/23] Train loss=0.20686522126197815
[15/23] Train loss=0.2103329449892044
[20/23] Train loss=0.17223648726940155
Test set avg_accuracy=89.03% avg_sensitivity=81.87%, avg_specificity=91.46% avg_auc=0.9388
Fold[9] Epoch: 70 [70/100 (70%)] Train loss=0.207893 Test loss=0.389923 Current lr=[0.00038779100597458526]

[0/23] Train loss=0.16517922282218933
[5/23] Train loss=0.26010969281196594
[10/23] Train loss=0.1937062293291092
[15/23] Train loss=0.22570106387138367
[20/23] Train loss=0.16857464611530304
Test set avg_accuracy=88.83% avg_sensitivity=80.52%, avg_specificity=91.65% avg_auc=0.9369
Fold[9] Epoch: 71 [71/100 (71%)] Train loss=0.191689 Test loss=0.406279 Current lr=[0.0003660438766252499]

[0/23] Train loss=0.17129574716091156
[5/23] Train loss=0.21512818336486816
[10/23] Train loss=0.19962741434574127
[15/23] Train loss=0.19361267983913422
[20/23] Train loss=0.17404571175575256
Test set avg_accuracy=88.50% avg_sensitivity=81.17%, avg_specificity=90.99% avg_auc=0.9348
Fold[9] Epoch: 72 [72/100 (72%)] Train loss=0.184982 Test loss=0.442524 Current lr=[0.0003445665211088922]

[0/23] Train loss=0.16093136370182037
[5/23] Train loss=0.17915168404579163
[10/23] Train loss=0.19286270439624786
[15/23] Train loss=0.18728192150592804
[20/23] Train loss=0.14463329315185547
Test set avg_accuracy=88.54% avg_sensitivity=84.01%, avg_specificity=90.09% avg_auc=0.9369
Fold[9] Epoch: 73 [73/100 (73%)] Train loss=0.173599 Test loss=0.450727 Current lr=[0.00032340219196125877]

[0/23] Train loss=0.17814575135707855
[5/23] Train loss=0.17304658889770508
[10/23] Train loss=0.16397728025913239
[15/23] Train loss=0.1622122824192047
[20/23] Train loss=0.13919377326965332
Test set avg_accuracy=88.44% avg_sensitivity=84.05%, avg_specificity=89.93% avg_auc=0.9393
Fold[9] Epoch: 74 [74/100 (74%)] Train loss=0.163229 Test loss=0.477606 Current lr=[0.0003025935113246488]

[0/23] Train loss=0.1504858434200287
[5/23] Train loss=0.15846125781536102
[10/23] Train loss=0.167720764875412
[15/23] Train loss=0.1635740101337433
[20/23] Train loss=0.1328447461128235
Test set avg_accuracy=88.33% avg_sensitivity=87.12%, avg_specificity=88.74% avg_auc=0.9408
Best model saved!! Metric=32.27449623187861!!
Fold[9] Epoch: 75 [75/100 (75%)] Train loss=0.152190 Test loss=0.461822 Current lr=[0.0002821823851125901]

[0/23] Train loss=0.14505994319915771
[5/23] Train loss=0.16362883150577545
[10/23] Train loss=0.13037274777889252
[15/23] Train loss=0.1701718270778656
[20/23] Train loss=0.1342102289199829
Test set avg_accuracy=88.37% avg_sensitivity=80.38%, avg_specificity=91.08% avg_auc=0.9371
Fold[9] Epoch: 76 [76/100 (76%)] Train loss=0.144956 Test loss=0.464809 Current lr=[0.00026220991861690765]

[0/23] Train loss=0.14529401063919067
[5/23] Train loss=0.14552298188209534
[10/23] Train loss=0.15833912789821625
[15/23] Train loss=0.1426992416381836
[20/23] Train loss=0.1141531765460968
Test set avg_accuracy=88.60% avg_sensitivity=79.73%, avg_specificity=91.62% avg_auc=0.9377
Fold[9] Epoch: 77 [77/100 (77%)] Train loss=0.136263 Test loss=0.466557 Current lr=[0.00024271633372713536]

[0/23] Train loss=0.12340939790010452
[5/23] Train loss=0.13566647469997406
[10/23] Train loss=0.13641558587551117
[15/23] Train loss=0.12108945846557617
[20/23] Train loss=0.11821061372756958
Test set avg_accuracy=88.87% avg_sensitivity=82.89%, avg_specificity=90.91% avg_auc=0.9395
Fold[9] Epoch: 78 [78/100 (78%)] Train loss=0.125617 Test loss=0.471346 Current lr=[0.00022374088792898362]

[0/23] Train loss=0.12466695159673691
[5/23] Train loss=0.1394568383693695
[10/23] Train loss=0.12769483029842377
[15/23] Train loss=0.1199207603931427
[20/23] Train loss=0.10857474058866501
Test set avg_accuracy=88.45% avg_sensitivity=79.27%, avg_specificity=91.57% avg_auc=0.9369
Fold[9] Epoch: 79 [79/100 (79%)] Train loss=0.118930 Test loss=0.486096 Current lr=[0.00020532179524498774]

[0/23] Train loss=0.1110265925526619
[5/23] Train loss=0.133135125041008
[10/23] Train loss=0.12861177325248718
[15/23] Train loss=0.11822440475225449
[20/23] Train loss=0.09689786285161972
Test set avg_accuracy=88.58% avg_sensitivity=80.15%, avg_specificity=91.45% avg_auc=0.9377
Fold[9] Epoch: 80 [80/100 (80%)] Train loss=0.116524 Test loss=0.484396 Current lr=[0.000187496149276552]

[0/23] Train loss=0.11021256446838379
[5/23] Train loss=0.11724904179573059
[10/23] Train loss=0.11981521546840668
[15/23] Train loss=0.10516514629125595
[20/23] Train loss=0.10525313764810562
Test set avg_accuracy=88.65% avg_sensitivity=78.48%, avg_specificity=92.11% avg_auc=0.9366
Fold[9] Epoch: 81 [81/100 (81%)] Train loss=0.112331 Test loss=0.484031 Current lr=[0.00017029984850237305]

[0/23] Train loss=0.10830981284379959
[5/23] Train loss=0.11690657585859299
[10/23] Train loss=0.11625206470489502
[15/23] Train loss=0.09619179368019104
[20/23] Train loss=0.10419571399688721
Test set avg_accuracy=88.74% avg_sensitivity=80.47%, avg_specificity=91.56% avg_auc=0.9382
Fold[9] Epoch: 82 [82/100 (82%)] Train loss=0.107466 Test loss=0.488996 Current lr=[0.00015376752398368106]

[0/23] Train loss=0.10425881296396255
[5/23] Train loss=0.12138938158750534
[10/23] Train loss=0.10739678144454956
[15/23] Train loss=0.10671486705541611
[20/23] Train loss=0.10035315155982971
Test set avg_accuracy=88.68% avg_sensitivity=78.99%, avg_specificity=91.98% avg_auc=0.9378
Fold[9] Epoch: 83 [83/100 (83%)] Train loss=0.105196 Test loss=0.485227 Current lr=[0.00013793246962189157]

[0/23] Train loss=0.10665560513734818
[5/23] Train loss=0.12159402668476105
[10/23] Train loss=0.10323763638734818
[15/23] Train loss=0.10007558763027191
[20/23] Train loss=0.10392840206623077
Test set avg_accuracy=88.84% avg_sensitivity=79.59%, avg_specificity=91.98% avg_auc=0.9374
Fold[9] Epoch: 84 [84/100 (84%)] Train loss=0.102111 Test loss=0.497943 Current lr=[0.00012282657510911843]

[0/23] Train loss=0.08375215530395508
[5/23] Train loss=0.10629814118146896
[10/23] Train loss=0.10299551486968994
[15/23] Train loss=0.10106756538152695
[20/23] Train loss=0.08913879096508026
Test set avg_accuracy=88.76% avg_sensitivity=79.64%, avg_specificity=91.86% avg_auc=0.9382
Fold[9] Epoch: 85 [85/100 (85%)] Train loss=0.100040 Test loss=0.494318 Current lr=[0.0001084802617065783]

[0/23] Train loss=0.09998586028814316
[5/23] Train loss=0.11705167591571808
[10/23] Train loss=0.10147823393344879
[15/23] Train loss=0.09214549511671066
[20/23] Train loss=0.09904006123542786
Test set avg_accuracy=88.92% avg_sensitivity=80.20%, avg_specificity=91.89% avg_auc=0.9385
Fold[9] Epoch: 86 [86/100 (86%)] Train loss=0.098025 Test loss=0.497965 Current lr=[9.492242098021878e-05]

[0/23] Train loss=0.08609721064567566
[5/23] Train loss=0.10513659566640854
[10/23] Train loss=0.0956493392586708
[15/23] Train loss=0.09568413347005844
[20/23] Train loss=0.08965736627578735
Test set avg_accuracy=88.81% avg_sensitivity=80.01%, avg_specificity=91.81% avg_auc=0.9380
Fold[9] Epoch: 87 [87/100 (87%)] Train loss=0.092835 Test loss=0.507977 Current lr=[8.218035661694964e-05]

[0/23] Train loss=0.08289036154747009
[5/23] Train loss=0.10897368937730789
[10/23] Train loss=0.08658076077699661
[15/23] Train loss=0.10859828442335129
[20/23] Train loss=0.08961211144924164
Test set avg_accuracy=88.61% avg_sensitivity=79.08%, avg_specificity=91.86% avg_auc=0.9374
Fold[9] Epoch: 88 [88/100 (88%)] Train loss=0.091333 Test loss=0.507448 Current lr=[7.02797294386511e-05]

[0/23] Train loss=0.08892641961574554
[5/23] Train loss=0.10818138718605042
[10/23] Train loss=0.09505104273557663
[15/23] Train loss=0.078396737575531
[20/23] Train loss=0.08250755816698074
Test set avg_accuracy=88.72% avg_sensitivity=78.99%, avg_specificity=92.03% avg_auc=0.9374
Fold[9] Epoch: 89 [89/100 (89%)] Train loss=0.090912 Test loss=0.512677 Current lr=[5.924450572469346e-05]

[0/23] Train loss=0.09087661653757095
[5/23] Train loss=0.08912056684494019
[10/23] Train loss=0.10242888331413269
[15/23] Train loss=0.09406786412000656
[20/23] Train loss=0.08346647024154663
Test set avg_accuracy=88.87% avg_sensitivity=79.92%, avg_specificity=91.92% avg_auc=0.9378
Fold[9] Epoch: 90 [90/100 (90%)] Train loss=0.090562 Test loss=0.513412 Current lr=[4.90969089470401e-05]

[0/23] Train loss=0.0886901244521141
[5/23] Train loss=0.10143572092056274
[10/23] Train loss=0.09359924495220184
[15/23] Train loss=0.08899477869272232
[20/23] Train loss=0.081387959420681
Test set avg_accuracy=88.87% avg_sensitivity=79.50%, avg_specificity=92.06% avg_auc=0.9378
Fold[9] Epoch: 91 [91/100 (91%)] Train loss=0.088011 Test loss=0.515883 Current lr=[3.985737501513232e-05]

[0/23] Train loss=0.08233978599309921
[5/23] Train loss=0.09392654895782471
[10/23] Train loss=0.09659865498542786
[15/23] Train loss=0.09558525681495667
[20/23] Train loss=0.07901208102703094
Test set avg_accuracy=88.94% avg_sensitivity=79.73%, avg_specificity=92.08% avg_auc=0.9377
Fold[9] Epoch: 92 [92/100 (92%)] Train loss=0.085380 Test loss=0.516630 Current lr=[3.154451112068745e-05]

[0/23] Train loss=0.0812770426273346
[5/23] Train loss=0.09517890214920044
[10/23] Train loss=0.08235611021518707
[15/23] Train loss=0.08712703734636307
[20/23] Train loss=0.08601007610559464
Test set avg_accuracy=88.88% avg_sensitivity=79.36%, avg_specificity=92.13% avg_auc=0.9375
Fold[9] Epoch: 93 [93/100 (93%)] Train loss=0.087738 Test loss=0.518970 Current lr=[2.4175058265291265e-05]

[0/23] Train loss=0.0842093899846077
[5/23] Train loss=0.10472745448350906
[10/23] Train loss=0.09849434345960617
[15/23] Train loss=0.09330672025680542
[20/23] Train loss=0.08696825802326202
Test set avg_accuracy=88.76% avg_sensitivity=79.08%, avg_specificity=92.05% avg_auc=0.9375
Fold[9] Epoch: 94 [94/100 (94%)] Train loss=0.087400 Test loss=0.520054 Current lr=[1.7763857546248248e-05]

[0/23] Train loss=0.08183553069829941
[5/23] Train loss=0.1079278215765953
[10/23] Train loss=0.08093500882387161
[15/23] Train loss=0.09329663962125778
[20/23] Train loss=0.07979491353034973
Test set avg_accuracy=88.77% avg_sensitivity=79.13%, avg_specificity=92.05% avg_auc=0.9375
Fold[9] Epoch: 95 [95/100 (95%)] Train loss=0.086284 Test loss=0.519154 Current lr=[1.2323820268587161e-05]

[0/23] Train loss=0.0947505384683609
[5/23] Train loss=0.09664279967546463
[10/23] Train loss=0.10492551326751709
[15/23] Train loss=0.0840100422501564
[20/23] Train loss=0.07689112424850464
Test set avg_accuracy=88.79% avg_sensitivity=79.13%, avg_specificity=92.08% avg_auc=0.9374
Fold[9] Epoch: 96 [96/100 (96%)] Train loss=0.084702 Test loss=0.518805 Current lr=[7.865901943410707e-06]

[0/23] Train loss=0.08557440340518951
[5/23] Train loss=0.10524944961071014
[10/23] Train loss=0.09092064201831818
[15/23] Train loss=0.07653931528329849
[20/23] Train loss=0.07492953538894653
Test set avg_accuracy=88.77% avg_sensitivity=79.36%, avg_specificity=91.97% avg_auc=0.9376
Fold[9] Epoch: 97 [97/100 (97%)] Train loss=0.082815 Test loss=0.517833 Current lr=[4.399080224954306e-06]

[0/23] Train loss=0.08579669892787933
[5/23] Train loss=0.1010235846042633
[10/23] Train loss=0.1081053763628006
[15/23] Train loss=0.079816073179245
[20/23] Train loss=0.0795273408293724
Test set avg_accuracy=88.77% avg_sensitivity=79.36%, avg_specificity=91.97% avg_auc=0.9376
Fold[9] Epoch: 98 [98/100 (98%)] Train loss=0.084469 Test loss=0.517698 Current lr=[1.930336830785271e-06]

[0/23] Train loss=0.09175688773393631
[5/23] Train loss=0.10425255447626114
[10/23] Train loss=0.09333617240190506
[15/23] Train loss=0.09324941039085388
[20/23] Train loss=0.08923353254795074
Test set avg_accuracy=88.76% avg_sensitivity=79.31%, avg_specificity=91.97% avg_auc=0.9375
Fold[9] Epoch: 99 [99/100 (99%)] Train loss=0.086400 Test loss=0.518266 Current lr=[4.6464348155246055e-07]

[0/23] Train loss=0.07933558523654938
[5/23] Train loss=0.10301026701927185
[10/23] Train loss=0.10344445705413818
[15/23] Train loss=0.08094917982816696
[20/23] Train loss=0.0842517539858818
Test set avg_accuracy=88.73% avg_sensitivity=79.22%, avg_specificity=91.97% avg_auc=0.9375
Fold[9] Epoch: 100 [100/100 (100%)] Train loss=0.086545 Test loss=0.518214 Current lr=[4.951888602991508e-09]

Fold[9] Best Result: acc=88.33038348082596 sen=87.12226871222687, spe=88.74130297280203, auc=0.9408054106602375!
[0/23] Train loss=1.3939658403396606
[5/23] Train loss=1.471740484237671
[10/23] Train loss=1.374879240989685
[15/23] Train loss=1.2642453908920288
[20/23] Train loss=1.324974536895752
Test set avg_accuracy=77.47% avg_sensitivity=1.03%, avg_specificity=99.60% avg_auc=0.6547
Best model saved!! Metric=-82.42982658743374!!
Fold[10] Epoch: 1 [1/100 (1%)] Train loss=1.320676 Test loss=0.514125 Current lr=[4.263712153319496e-05]

[0/23] Train loss=1.163996934890747
[5/23] Train loss=1.073612928390503
[10/23] Train loss=1.124990463256836
[15/23] Train loss=0.9979584813117981
[20/23] Train loss=1.1012293100357056
Test set avg_accuracy=80.40% avg_sensitivity=61.31%, avg_specificity=85.93% avg_auc=0.8185
Best model saved!! Metric=-16.50798717998051!!
Fold[10] Epoch: 2 [2/100 (2%)] Train loss=1.046919 Test loss=0.517625 Current lr=[5.051950942452628e-05]

[0/23] Train loss=0.963598370552063
[5/23] Train loss=0.9800951480865479
[10/23] Train loss=1.0380748510360718
[15/23] Train loss=0.822456419467926
[20/23] Train loss=1.1271746158599854
Test set avg_accuracy=82.15% avg_sensitivity=64.23%, avg_specificity=87.33% avg_auc=0.8511
Best model saved!! Metric=-7.1810281263033495!!
Fold[10] Epoch: 3 [3/100 (3%)] Train loss=0.928851 Test loss=0.479882 Current lr=[6.356055194548904e-05]

[0/23] Train loss=0.836283266544342
[5/23] Train loss=0.9298021793365479
[10/23] Train loss=1.01803719997406
[15/23] Train loss=0.7992377877235413
[20/23] Train loss=1.0147825479507446
Test set avg_accuracy=84.37% avg_sensitivity=76.57%, avg_specificity=86.63% avg_auc=0.8881
Best model saved!! Metric=10.37374122082869!!
Fold[10] Epoch: 4 [4/100 (4%)] Train loss=0.858892 Test loss=0.420447 Current lr=[8.161695403755248e-05]

[0/23] Train loss=0.8013473749160767
[5/23] Train loss=0.901789665222168
[10/23] Train loss=0.9177573323249817
[15/23] Train loss=0.7744189500808716
[20/23] Train loss=0.9617545008659363
Test set avg_accuracy=86.40% avg_sensitivity=80.37%, avg_specificity=88.15% avg_auc=0.9109
Best model saved!! Metric=20.00856194235521!!
Fold[10] Epoch: 5 [5/100 (5%)] Train loss=0.815179 Test loss=0.369569 Current lr=[0.00010449031183917899]

[0/23] Train loss=0.7097864747047424
[5/23] Train loss=0.9001654982566833
[10/23] Train loss=0.8791739344596863
[15/23] Train loss=0.7452331185340881
[20/23] Train loss=0.9902727007865906
Test set avg_accuracy=85.86% avg_sensitivity=89.00%, avg_specificity=84.95% avg_auc=0.9259
Best model saved!! Metric=26.39925339153304!!
Fold[10] Epoch: 6 [6/100 (6%)] Train loss=0.780996 Test loss=0.389974 Current lr=[0.00013192929274872232]

[0/23] Train loss=0.660567581653595
[5/23] Train loss=0.8552639484405518
[10/23] Train loss=0.8677599430084229
[15/23] Train loss=0.6743856072425842
[20/23] Train loss=0.9814149737358093
Test set avg_accuracy=85.99% avg_sensitivity=89.00%, avg_specificity=85.11% avg_auc=0.9350
Best model saved!! Metric=27.602268542610915!!
Fold[10] Epoch: 7 [7/100 (7%)] Train loss=0.755938 Test loss=0.374030 Current lr=[0.00016363239706865967]

[0/23] Train loss=0.6110038161277771
[5/23] Train loss=0.8976401686668396
[10/23] Train loss=0.8679926991462708
[15/23] Train loss=0.6663439273834229
[20/23] Train loss=0.9597042798995972
Test set avg_accuracy=87.15% avg_sensitivity=88.08%, avg_specificity=86.88% avg_auc=0.9357
Best model saved!! Metric=29.67825878993093!!
Fold[10] Epoch: 8 [8/100 (8%)] Train loss=0.736104 Test loss=0.350888 Current lr=[0.00019925127088619402]

[0/23] Train loss=0.6012693047523499
[5/23] Train loss=0.8953485488891602
[10/23] Train loss=0.8628002405166626
[15/23] Train loss=0.6576193571090698
[20/23] Train loss=0.935633659362793
Test set avg_accuracy=88.05% avg_sensitivity=88.13%, avg_specificity=88.03% avg_auc=0.9389
Best model saved!! Metric=32.10308635852121!!
Fold[10] Epoch: 9 [9/100 (9%)] Train loss=0.718630 Test loss=0.353160 Current lr=[0.00023839453378827395]

[0/23] Train loss=0.6185728907585144
[5/23] Train loss=0.9193454384803772
[10/23] Train loss=0.9267945885658264
[15/23] Train loss=0.6775227189064026
[20/23] Train loss=0.9817977547645569
Test set avg_accuracy=89.80% avg_sensitivity=86.59%, avg_specificity=90.73% avg_auc=0.9449
Best model saved!! Metric=35.61831546865152!!
Fold[10] Epoch: 10 [10/100 (10%)] Train loss=0.730038 Test loss=0.312762 Current lr=[0.00028063207935207196]

[0/23] Train loss=0.5754078030586243
[5/23] Train loss=0.9595841765403748
[10/23] Train loss=0.8362069725990295
[15/23] Train loss=0.6324281096458435
[20/23] Train loss=0.9235798120498657
Test set avg_accuracy=90.50% avg_sensitivity=87.36%, avg_specificity=91.40% avg_auc=0.9462
Best model saved!! Metric=37.87931385930172!!
Fold[10] Epoch: 11 [11/100 (11%)] Train loss=0.711308 Test loss=0.304927 Current lr=[0.0003254998011571065]

[0/23] Train loss=0.5444905757904053
[5/23] Train loss=0.9297162890434265
[10/23] Train loss=0.8849634528160095
[15/23] Train loss=0.683914065361023
[20/23] Train loss=0.8806402087211609
Test set avg_accuracy=91.18% avg_sensitivity=83.66%, avg_specificity=93.35% avg_auc=0.9408
Fold[10] Epoch: 12 [12/100 (12%)] Train loss=0.706300 Test loss=0.281452 Current lr=[0.0003725046923895547]

[0/23] Train loss=0.531346321105957
[5/23] Train loss=0.9178749918937683
[10/23] Train loss=0.8590354919433594
[15/23] Train loss=0.6323437690734863
[20/23] Train loss=0.941070556640625
Test set avg_accuracy=91.26% avg_sensitivity=84.64%, avg_specificity=93.17% avg_auc=0.9478
Fold[10] Epoch: 13 [13/100 (13%)] Train loss=0.696948 Test loss=0.272974 Current lr=[0.0004211302630042728]

[0/23] Train loss=0.4995212256908417
[5/23] Train loss=0.9469854235649109
[10/23] Train loss=0.8672104477882385
[15/23] Train loss=0.6572283506393433
[20/23] Train loss=0.8708783984184265
Test set avg_accuracy=90.25% avg_sensitivity=89.41%, avg_specificity=90.50% avg_auc=0.9542
Best model saved!! Metric=39.58084304820258!!
Fold[10] Epoch: 14 [14/100 (14%)] Train loss=0.688186 Test loss=0.270518 Current lr=[0.0004708422149207104]

[0/23] Train loss=0.5416645407676697
[5/23] Train loss=0.8700348138809204
[10/23] Train loss=0.8494410514831543
[15/23] Train loss=0.6055443286895752
[20/23] Train loss=0.9217733144760132
Test set avg_accuracy=91.03% avg_sensitivity=80.37%, avg_specificity=94.11% avg_auc=0.9446
Fold[10] Epoch: 15 [15/100 (15%)] Train loss=0.675052 Test loss=0.254014 Current lr=[0.0005210943128936348]

[0/23] Train loss=0.4958467185497284
[5/23] Train loss=0.8536727428436279
[10/23] Train loss=0.8710328340530396
[15/23] Train loss=0.6367350816726685
[20/23] Train loss=0.8687808513641357
Test set avg_accuracy=90.42% avg_sensitivity=87.92%, avg_specificity=91.14% avg_auc=0.9518
Fold[10] Epoch: 16 [16/100 (16%)] Train loss=0.676433 Test loss=0.267025 Current lr=[0.0005713343865494929]

[0/23] Train loss=0.5180847644805908
[5/23] Train loss=0.9097642302513123
[10/23] Train loss=0.7979555130004883
[15/23] Train loss=0.5500208139419556
[20/23] Train loss=0.8848486542701721
Test set avg_accuracy=89.60% avg_sensitivity=90.18%, avg_specificity=89.43% avg_auc=0.9529
Fold[10] Epoch: 17 [17/100 (17%)] Train loss=0.664014 Test loss=0.284723 Current lr=[0.0006210103976380052]

[0/23] Train loss=0.5162386894226074
[5/23] Train loss=0.8809989094734192
[10/23] Train loss=0.8058563470840454
[15/23] Train loss=0.6068608164787292
[20/23] Train loss=0.7806195020675659
Test set avg_accuracy=91.50% avg_sensitivity=82.07%, avg_specificity=94.23% avg_auc=0.9426
Fold[10] Epoch: 18 [18/100 (18%)] Train loss=0.651454 Test loss=0.255369 Current lr=[0.0006695765058319851]

[0/23] Train loss=0.5008925795555115
[5/23] Train loss=0.860041618347168
[10/23] Train loss=0.7973902821540833
[15/23] Train loss=0.5403981804847717
[20/23] Train loss=0.813605785369873
Test set avg_accuracy=90.80% avg_sensitivity=88.44%, avg_specificity=91.48% avg_auc=0.9484
Fold[10] Epoch: 19 [19/100 (19%)] Train loss=0.639583 Test loss=0.265455 Current lr=[0.0007164990664243417]

[0/23] Train loss=0.5056122541427612
[5/23] Train loss=0.832223653793335
[10/23] Train loss=0.7748467922210693
[15/23] Train loss=0.5766139030456543
[20/23] Train loss=0.8141006231307983
Test set avg_accuracy=91.43% avg_sensitivity=85.71%, avg_specificity=93.08% avg_auc=0.9515
Fold[10] Epoch: 20 [20/100 (20%)] Train loss=0.637748 Test loss=0.244821 Current lr=[0.0007612624940195301]

[0/23] Train loss=0.5026773810386658
[5/23] Train loss=0.8364729881286621
[10/23] Train loss=0.7865190505981445
[15/23] Train loss=0.5896981954574585
[20/23] Train loss=0.8186928033828735
Test set avg_accuracy=91.34% avg_sensitivity=83.61%, avg_specificity=93.58% avg_auc=0.9480
Fold[10] Epoch: 21 [21/100 (21%)] Train loss=0.632226 Test loss=0.253930 Current lr=[0.000803374927789172]

[0/23] Train loss=0.4793393313884735
[5/23] Train loss=0.7644709348678589
[10/23] Train loss=0.7245246171951294
[15/23] Train loss=0.5728470087051392
[20/23] Train loss=0.8066616058349609
Test set avg_accuracy=90.82% avg_sensitivity=87.31%, avg_specificity=91.84% avg_auc=0.9507
Fold[10] Epoch: 22 [22/100 (22%)] Train loss=0.598675 Test loss=0.257369 Current lr=[0.0008423736360419787]

[0/23] Train loss=0.497749924659729
[5/23] Train loss=0.890736997127533
[10/23] Train loss=0.7598922252655029
[15/23] Train loss=0.5359857678413391
[20/23] Train loss=0.796083390712738
Test set avg_accuracy=91.44% avg_sensitivity=81.35%, avg_specificity=94.36% avg_auc=0.9508
Fold[10] Epoch: 23 [23/100 (23%)] Train loss=0.625258 Test loss=0.240629 Current lr=[0.0008778301007225328]

[0/23] Train loss=0.48967644572257996
[5/23] Train loss=0.8221744298934937
[10/23] Train loss=0.801790177822113
[15/23] Train loss=0.5337861180305481
[20/23] Train loss=0.7678690552711487
Test set avg_accuracy=92.05% avg_sensitivity=84.94%, avg_specificity=94.11% avg_auc=0.9526
Best model saved!! Metric=40.370269696125575!!
Fold[10] Epoch: 24 [24/100 (24%)] Train loss=0.614471 Test loss=0.240481 Current lr=[0.0009093547259704173]

[0/23] Train loss=0.48936739563941956
[5/23] Train loss=0.7939904928207397
[10/23] Train loss=0.6884749531745911
[15/23] Train loss=0.5796039700508118
[20/23] Train loss=0.7743988633155823
Test set avg_accuracy=90.81% avg_sensitivity=86.95%, avg_specificity=91.92% avg_auc=0.9529
Fold[10] Epoch: 25 [25/100 (25%)] Train loss=0.586784 Test loss=0.257322 Current lr=[0.0009366011190020192]

[0/23] Train loss=0.4658932685852051
[5/23] Train loss=0.768721878528595
[10/23] Train loss=0.6965239644050598
[15/23] Train loss=0.5239202976226807
[20/23] Train loss=0.7631929516792297
Test set avg_accuracy=90.46% avg_sensitivity=89.93%, avg_specificity=90.62% avg_auc=0.9509
Fold[10] Epoch: 26 [26/100 (26%)] Train loss=0.584620 Test loss=0.279521 Current lr=[0.0009592698962766488]

[0/23] Train loss=0.4680367708206177
[5/23] Train loss=0.7442947030067444
[10/23] Train loss=0.7143727540969849
[15/23] Train loss=0.5474352240562439
[20/23] Train loss=0.7713860273361206
Test set avg_accuracy=91.72% avg_sensitivity=83.30%, avg_specificity=94.16% avg_auc=0.9512
Fold[10] Epoch: 27 [27/100 (27%)] Train loss=0.587111 Test loss=0.240245 Current lr=[0.0009771119731247974]

[0/23] Train loss=0.4766888916492462
[5/23] Train loss=0.731338381767273
[10/23] Train loss=0.7153857350349426
[15/23] Train loss=0.5420784950256348
[20/23] Train loss=0.7963298559188843
Test set avg_accuracy=91.13% avg_sensitivity=88.39%, avg_specificity=91.92% avg_auc=0.9533
Best model saved!! Metric=40.772326204825674!!
Fold[10] Epoch: 28 [28/100 (28%)] Train loss=0.578718 Test loss=0.253122 Current lr=[0.0009899313006920766]

[0/23] Train loss=0.48085227608680725
[5/23] Train loss=0.7800537347793579
[10/23] Train loss=0.7092655301094055
[15/23] Train loss=0.5805271863937378
[20/23] Train loss=0.7151225209236145
Test set avg_accuracy=90.20% avg_sensitivity=87.41%, avg_specificity=91.00% avg_auc=0.9555
Fold[10] Epoch: 29 [29/100 (29%)] Train loss=0.579993 Test loss=0.254935 Current lr=[0.0009975870201252835]

[0/23] Train loss=0.47977548837661743
[5/23] Train loss=0.7043223977088928
[10/23] Train loss=0.7268248796463013
[15/23] Train loss=0.5448670387268066
[20/23] Train loss=0.7370527982711792
Test set avg_accuracy=91.53% avg_sensitivity=85.97%, avg_specificity=93.14% avg_auc=0.9555
Fold[10] Epoch: 30 [30/100 (30%)] Train loss=0.561854 Test loss=0.238481 Current lr=[0.000999999048111397]

[0/23] Train loss=0.44720563292503357
[5/23] Train loss=0.768326997756958
[10/23] Train loss=0.7101824879646301
[15/23] Train loss=0.532637357711792
[20/23] Train loss=0.7234317660331726
Test set avg_accuracy=90.93% avg_sensitivity=83.76%, avg_specificity=93.01% avg_auc=0.9482
Fold[10] Epoch: 31 [31/100 (31%)] Train loss=0.552760 Test loss=0.259875 Current lr=[0.000999451812190372]

[0/23] Train loss=0.4809054434299469
[5/23] Train loss=0.7296063303947449
[10/23] Train loss=0.659692645072937
[15/23] Train loss=0.5134525299072266
[20/23] Train loss=0.702978789806366
Test set avg_accuracy=90.36% avg_sensitivity=87.56%, avg_specificity=91.17% avg_auc=0.9527
Fold[10] Epoch: 32 [32/100 (32%)] Train loss=0.556840 Test loss=0.271653 Current lr=[0.0009978987508156897]

[0/23] Train loss=0.4618946313858032
[5/23] Train loss=0.7138872742652893
[10/23] Train loss=0.7106318473815918
[15/23] Train loss=0.5183264017105103
[20/23] Train loss=0.7203066945075989
Test set avg_accuracy=89.79% avg_sensitivity=87.98%, avg_specificity=90.32% avg_auc=0.9489
Fold[10] Epoch: 33 [33/100 (33%)] Train loss=0.543993 Test loss=0.280170 Current lr=[0.0009953429916462733]

[0/23] Train loss=0.482205867767334
[5/23] Train loss=0.7603237628936768
[10/23] Train loss=0.695452094078064
[15/23] Train loss=0.5431441068649292
[20/23] Train loss=0.7287602424621582
Test set avg_accuracy=91.83% avg_sensitivity=85.82%, avg_specificity=93.58% avg_auc=0.9525
Fold[10] Epoch: 34 [34/100 (34%)] Train loss=0.544712 Test loss=0.246526 Current lr=[0.000991789681640963]

[0/23] Train loss=0.42369940876960754
[5/23] Train loss=0.6719873547554016
[10/23] Train loss=0.6748864054679871
[15/23] Train loss=0.5126078128814697
[20/23] Train loss=0.6977484822273254
Test set avg_accuracy=90.21% avg_sensitivity=86.54%, avg_specificity=91.27% avg_auc=0.9502
Fold[10] Epoch: 35 [35/100 (35%)] Train loss=0.521914 Test loss=0.281184 Current lr=[0.0009872459766932253]

[0/23] Train loss=0.43480589985847473
[5/23] Train loss=0.7627177238464355
[10/23] Train loss=0.6983996629714966
[15/23] Train loss=0.532824695110321
[20/23] Train loss=0.6784160137176514
Test set avg_accuracy=91.58% avg_sensitivity=88.08%, avg_specificity=92.59% avg_auc=0.9552
Best model saved!! Metric=41.77654396414424!!
Fold[10] Epoch: 36 [36/100 (36%)] Train loss=0.533794 Test loss=0.253930 Current lr=[0.0009817210272201372]

[0/23] Train loss=0.42250722646713257
[5/23] Train loss=0.6615305542945862
[10/23] Train loss=0.6666072010993958
[15/23] Train loss=0.4986515939235687
[20/23] Train loss=0.6939198970794678
Test set avg_accuracy=91.55% avg_sensitivity=82.84%, avg_specificity=94.07% avg_auc=0.9510
Fold[10] Epoch: 37 [37/100 (37%)] Train loss=0.523584 Test loss=0.246843 Current lr=[0.0009752259597346622]

[0/23] Train loss=0.4251103401184082
[5/23] Train loss=0.6442113518714905
[10/23] Train loss=0.755112886428833
[15/23] Train loss=0.5218767523765564
[20/23] Train loss=0.6690455675125122
Test set avg_accuracy=90.53% avg_sensitivity=89.00%, avg_specificity=90.97% avg_auc=0.9541
Fold[10] Epoch: 38 [38/100 (38%)] Train loss=0.522492 Test loss=0.282551 Current lr=[0.000967773854438336]

[0/23] Train loss=0.3981434106826782
[5/23] Train loss=0.6599494218826294
[10/23] Train loss=0.6804494857788086
[15/23] Train loss=0.48595303297042847
[20/23] Train loss=0.6698227524757385
Test set avg_accuracy=88.60% avg_sensitivity=91.21%, avg_specificity=87.85% avg_auc=0.9520
Fold[10] Epoch: 39 [39/100 (39%)] Train loss=0.498112 Test loss=0.325412 Current lr=[0.000959379718879479]

[0/23] Train loss=0.43952855467796326
[5/23] Train loss=0.703406035900116
[10/23] Train loss=0.678277313709259
[15/23] Train loss=0.5230645537376404
[20/23] Train loss=0.6845832467079163
Test set avg_accuracy=90.88% avg_sensitivity=86.90%, avg_specificity=92.03% avg_auc=0.9554
Fold[10] Epoch: 40 [40/100 (40%)] Train loss=0.514618 Test loss=0.256931 Current lr=[0.0009500604577299936]

[0/23] Train loss=0.43470245599746704
[5/23] Train loss=0.6224454045295715
[10/23] Train loss=0.660731315612793
[15/23] Train loss=0.5235390067100525
[20/23] Train loss=0.6452730894088745
Test set avg_accuracy=90.97% avg_sensitivity=84.38%, avg_specificity=92.88% avg_auc=0.9527
Fold[10] Epoch: 41 [41/100 (41%)] Train loss=0.502323 Test loss=0.263255 Current lr=[0.0009398348387416027]

[0/23] Train loss=0.4064175486564636
[5/23] Train loss=0.61745685338974
[10/23] Train loss=0.6204293966293335
[15/23] Train loss=0.48737967014312744
[20/23] Train loss=0.622654139995575
Test set avg_accuracy=90.48% avg_sensitivity=85.87%, avg_specificity=91.82% avg_auc=0.9494
Fold[10] Epoch: 42 [42/100 (42%)] Train loss=0.485382 Test loss=0.292168 Current lr=[0.000928723454950097]

[0/23] Train loss=0.4278404116630554
[5/23] Train loss=0.6214961409568787
[10/23] Train loss=0.5789992213249207
[15/23] Train loss=0.4662090837955475
[20/23] Train loss=0.6025809645652771
Test set avg_accuracy=90.92% avg_sensitivity=83.45%, avg_specificity=93.08% avg_auc=0.9528
Fold[10] Epoch: 43 [43/100 (43%)] Train loss=0.477058 Test loss=0.266751 Current lr=[0.0009167486832037001]

[0/23] Train loss=0.39843159914016724
[5/23] Train loss=0.5377029180526733
[10/23] Train loss=0.5727031230926514
[15/23] Train loss=0.4577789008617401
[20/23] Train loss=0.5599719882011414
Test set avg_accuracy=90.61% avg_sensitivity=88.49%, avg_specificity=91.23% avg_auc=0.9546
Fold[10] Epoch: 44 [44/100 (44%)] Train loss=0.454870 Test loss=0.315349 Current lr=[0.0009039346390990754]

[0/23] Train loss=0.39325881004333496
[5/23] Train loss=0.5304144620895386
[10/23] Train loss=0.5554108023643494
[15/23] Train loss=0.4482567608356476
[20/23] Train loss=0.5235639214515686
Test set avg_accuracy=91.76% avg_sensitivity=85.05%, avg_specificity=93.71% avg_auc=0.9522
Fold[10] Epoch: 45 [45/100 (45%)] Train loss=0.444111 Test loss=0.288713 Current lr=[0.000890307128415723]

[0/23] Train loss=0.40327054262161255
[5/23] Train loss=0.4816270172595978
[10/23] Train loss=0.57477205991745
[15/23] Train loss=0.44990280270576477
[20/23] Train loss=0.5749334096908569
Test set avg_accuracy=90.91% avg_sensitivity=86.59%, avg_specificity=92.16% avg_auc=0.9533
Fold[10] Epoch: 46 [46/100 (46%)] Train loss=0.448109 Test loss=0.287493 Current lr=[0.0008758935951465738]

[0/23] Train loss=0.3662472665309906
[5/23] Train loss=0.5271412134170532
[10/23] Train loss=0.6113561391830444
[15/23] Train loss=0.4433356821537018
[20/23] Train loss=0.5508775115013123
Test set avg_accuracy=91.10% avg_sensitivity=87.46%, avg_specificity=92.15% avg_auc=0.9546
Fold[10] Epoch: 47 [47/100 (47%)] Train loss=0.445904 Test loss=0.296581 Current lr=[0.0008607230662294413]

[0/23] Train loss=0.3717133104801178
[5/23] Train loss=0.5003771185874939
[10/23] Train loss=0.46876782178878784
[15/23] Train loss=0.43340304493904114
[20/23] Train loss=0.5671259760856628
Test set avg_accuracy=90.55% avg_sensitivity=86.02%, avg_specificity=91.86% avg_auc=0.9534
Fold[10] Epoch: 48 [48/100 (48%)] Train loss=0.416431 Test loss=0.292624 Current lr=[0.0008448260930906307]

[0/23] Train loss=0.3602989614009857
[5/23] Train loss=0.4938853681087494
[10/23] Train loss=0.4717906415462494
[15/23] Train loss=0.3769572675228119
[20/23] Train loss=0.49225619435310364
Test set avg_accuracy=91.89% avg_sensitivity=82.68%, avg_specificity=94.56% avg_auc=0.9466
Fold[10] Epoch: 49 [49/100 (49%)] Train loss=0.400531 Test loss=0.293651 Current lr=[0.0008282346901184324]

[0/23] Train loss=0.3379630446434021
[5/23] Train loss=0.43130531907081604
[10/23] Train loss=0.42818912863731384
[15/23] Train loss=0.3886922299861908
[20/23] Train loss=0.5360862016677856
Test set avg_accuracy=90.91% avg_sensitivity=85.46%, avg_specificity=92.49% avg_auc=0.9522
Fold[10] Epoch: 50 [50/100 (50%)] Train loss=0.376841 Test loss=0.294243 Current lr=[0.000810982270190405]

[0/23] Train loss=0.3187004625797272
[5/23] Train loss=0.4331497550010681
[10/23] Train loss=0.4360371530056
[15/23] Train loss=0.3485235273838043
[20/23] Train loss=0.4772094190120697
Test set avg_accuracy=91.22% avg_sensitivity=84.58%, avg_specificity=93.14% avg_auc=0.9475
Fold[10] Epoch: 51 [51/100 (51%)] Train loss=0.364515 Test loss=0.314074 Current lr=[0.0007931035773842862]

[0/23] Train loss=0.31712138652801514
[5/23] Train loss=0.3883054554462433
[10/23] Train loss=0.43088042736053467
[15/23] Train loss=0.36707279086112976
[20/23] Train loss=0.456302285194397
Test set avg_accuracy=91.74% avg_sensitivity=80.99%, avg_specificity=94.85% avg_auc=0.9461
Fold[10] Epoch: 52 [52/100 (52%)] Train loss=0.348255 Test loss=0.309406 Current lr=[0.0007746346170080441]

[0/23] Train loss=0.3058124780654907
[5/23] Train loss=0.41850510239601135
[10/23] Train loss=0.42118126153945923
[15/23] Train loss=0.3353945016860962
[20/23] Train loss=0.38780930638313293
Test set avg_accuracy=91.53% avg_sensitivity=75.64%, avg_specificity=96.13% avg_auc=0.9413
Fold[10] Epoch: 53 [53/100 (53%)] Train loss=0.337062 Test loss=0.305358 Current lr=[0.0007556125830899786]

[0/23] Train loss=0.3455936312675476
[5/23] Train loss=0.3368692398071289
[10/23] Train loss=0.38191792368888855
[15/23] Train loss=0.3397483229637146
[20/23] Train loss=0.37694111466407776
Test set avg_accuracy=90.85% avg_sensitivity=70.71%, avg_specificity=96.68% avg_auc=0.9416
Fold[10] Epoch: 54 [54/100 (54%)] Train loss=0.313819 Test loss=0.321442 Current lr=[0.0007360757834748981]

[0/23] Train loss=0.30007243156433105
[5/23] Train loss=0.33121752738952637
[10/23] Train loss=0.36293232440948486
[15/23] Train loss=0.3064921200275421
[20/23] Train loss=0.36389681696891785
Test set avg_accuracy=92.20% avg_sensitivity=80.16%, avg_specificity=95.69% avg_auc=0.9495
Fold[10] Epoch: 55 [55/100 (55%)] Train loss=0.302166 Test loss=0.295249 Current lr=[0.000716063562677219]

[0/23] Train loss=0.27555322647094727
[5/23] Train loss=0.3846428394317627
[10/23] Train loss=0.3235357999801636
[15/23] Train loss=0.3343640863895416
[20/23] Train loss=0.3530478775501251
Test set avg_accuracy=92.06% avg_sensitivity=77.29%, avg_specificity=96.34% avg_auc=0.9468
Fold[10] Epoch: 56 [56/100 (56%)] Train loss=0.299539 Test loss=0.314688 Current lr=[0.0006956162226463489]

[0/23] Train loss=0.27671924233436584
[5/23] Train loss=0.35343876481056213
[10/23] Train loss=0.32401028275489807
[15/23] Train loss=0.2832685708999634
[20/23] Train loss=0.35565266013145447
Test set avg_accuracy=92.64% avg_sensitivity=81.55%, avg_specificity=95.85% avg_auc=0.9534
Fold[10] Epoch: 57 [57/100 (57%)] Train loss=0.283523 Test loss=0.288918 Current lr=[0.0006747749416039243]

[0/23] Train loss=0.2540189325809479
[5/23] Train loss=0.31877946853637695
[10/23] Train loss=0.33910614252090454
[15/23] Train loss=0.2774609923362732
[20/23] Train loss=0.29108569025993347
Test set avg_accuracy=91.97% avg_sensitivity=78.57%, avg_specificity=95.85% avg_auc=0.9509
Fold[10] Epoch: 58 [58/100 (58%)] Train loss=0.264501 Test loss=0.313569 Current lr=[0.000653581691116352]

[0/23] Train loss=0.2508217394351959
[5/23] Train loss=0.3108106851577759
[10/23] Train loss=0.30425789952278137
[15/23] Train loss=0.28773418068885803
[20/23] Train loss=0.2955933213233948
Test set avg_accuracy=92.27% avg_sensitivity=80.88%, avg_specificity=95.57% avg_auc=0.9531
Fold[10] Epoch: 59 [59/100 (59%)] Train loss=0.259069 Test loss=0.306164 Current lr=[0.0006320791515696602]

[0/23] Train loss=0.2167338728904724
[5/23] Train loss=0.3065628707408905
[10/23] Train loss=0.28451868891716003
[15/23] Train loss=0.2664775848388672
[20/23] Train loss=0.30024453997612
Test set avg_accuracy=91.91% avg_sensitivity=78.31%, avg_specificity=95.85% avg_auc=0.9466
Fold[10] Epoch: 60 [60/100 (60%)] Train loss=0.247247 Test loss=0.327605 Current lr=[0.0006103106262168818]

[0/23] Train loss=0.20965269207954407
[5/23] Train loss=0.27438411116600037
[10/23] Train loss=0.2755218744277954
[15/23] Train loss=0.2562231123447418
[20/23] Train loss=0.29704582691192627
Test set avg_accuracy=92.16% avg_sensitivity=79.45%, avg_specificity=95.84% avg_auc=0.9448
Fold[10] Epoch: 61 [61/100 (61%)] Train loss=0.235892 Test loss=0.339987 Current lr=[0.0005883199539710647]

[0/23] Train loss=0.18556390702724457
[5/23] Train loss=0.24182868003845215
[10/23] Train loss=0.2874687910079956
[15/23] Train loss=0.24593979120254517
[20/23] Train loss=0.2952133119106293
Test set avg_accuracy=91.91% avg_sensitivity=79.09%, avg_specificity=95.63% avg_auc=0.9424
Fold[10] Epoch: 62 [62/100 (62%)] Train loss=0.230569 Test loss=0.350350 Current lr=[0.0005661514211195354]

[0/23] Train loss=0.2052554190158844
[5/23] Train loss=0.25995495915412903
[10/23] Train loss=0.28563669323921204
[15/23] Train loss=0.26975399255752563
[20/23] Train loss=0.2568800151348114
Test set avg_accuracy=92.11% avg_sensitivity=80.32%, avg_specificity=95.52% avg_auc=0.9482
Fold[10] Epoch: 63 [63/100 (63%)] Train loss=0.226518 Test loss=0.324614 Current lr=[0.00054384967213721]

[0/23] Train loss=0.20029374957084656
[5/23] Train loss=0.23773513734340668
[10/23] Train loss=0.2713792622089386
[15/23] Train loss=0.23420944809913635
[20/23] Train loss=0.2790001332759857
Test set avg_accuracy=91.56% avg_sensitivity=81.14%, avg_specificity=94.57% avg_auc=0.9450
Fold[10] Epoch: 64 [64/100 (64%)] Train loss=0.232067 Test loss=0.329186 Current lr=[0.000521459619778564]

[0/23] Train loss=0.1926208883523941
[5/23] Train loss=0.27536118030548096
[10/23] Train loss=0.23695969581604004
[15/23] Train loss=0.24994167685508728
[20/23] Train loss=0.25414764881134033
Test set avg_accuracy=91.73% avg_sensitivity=77.54%, avg_specificity=95.84% avg_auc=0.9484
Fold[10] Epoch: 65 [65/100 (65%)] Train loss=0.214737 Test loss=0.338653 Current lr=[0.0004990263546293204]

[0/23] Train loss=0.17054203152656555
[5/23] Train loss=0.2253372073173523
[10/23] Train loss=0.22434185445308685
[15/23] Train loss=0.25015825033187866
[20/23] Train loss=0.23335637152194977
Test set avg_accuracy=91.74% avg_sensitivity=79.34%, avg_specificity=95.33% avg_auc=0.9515
Fold[10] Epoch: 66 [66/100 (66%)] Train loss=0.201039 Test loss=0.324293 Current lr=[0.000476595054300012]

[0/23] Train loss=0.18342608213424683
[5/23] Train loss=0.2170662134885788
[10/23] Train loss=0.21604396402835846
[15/23] Train loss=0.19701966643333435
[20/23] Train loss=0.27153000235557556
Test set avg_accuracy=91.91% avg_sensitivity=80.58%, avg_specificity=95.20% avg_auc=0.9500
Fold[10] Epoch: 67 [67/100 (67%)] Train loss=0.199785 Test loss=0.304799 Current lr=[0.0004542108924442853]

[0/23] Train loss=0.19780373573303223
[5/23] Train loss=0.1825866401195526
[10/23] Train loss=0.23227670788764954
[15/23] Train loss=0.20329603552818298
[20/23] Train loss=0.20427757501602173
Test set avg_accuracy=92.19% avg_sensitivity=80.11%, avg_specificity=95.69% avg_auc=0.9487
Fold[10] Epoch: 68 [68/100 (68%)] Train loss=0.183647 Test loss=0.313988 Current lr=[0.000431918947785175]

[0/23] Train loss=0.17572391033172607
[5/23] Train loss=0.20266684889793396
[10/23] Train loss=0.17187635600566864
[15/23] Train loss=0.18134188652038574
[20/23] Train loss=0.19802993535995483
Test set avg_accuracy=92.02% avg_sensitivity=82.12%, avg_specificity=94.88% avg_auc=0.9500
Fold[10] Epoch: 69 [69/100 (69%)] Train loss=0.167161 Test loss=0.324990 Current lr=[0.0004097641133325535]

[0/23] Train loss=0.1499866247177124
[5/23] Train loss=0.16141481697559357
[10/23] Train loss=0.157404363155365
[15/23] Train loss=0.16637910902500153
[20/23] Train loss=0.19068565964698792
Test set avg_accuracy=91.48% avg_sensitivity=84.79%, avg_specificity=93.41% avg_auc=0.9521
Fold[10] Epoch: 70 [70/100 (70%)] Train loss=0.154870 Test loss=0.348128 Current lr=[0.00038779100597458526]

[0/23] Train loss=0.15309134125709534
[5/23] Train loss=0.16424179077148438
[10/23] Train loss=0.14407797157764435
[15/23] Train loss=0.1313626617193222
[20/23] Train loss=0.15663884580135345
Test set avg_accuracy=91.60% avg_sensitivity=84.94%, avg_specificity=93.53% avg_auc=0.9531
Fold[10] Epoch: 71 [71/100 (71%)] Train loss=0.144715 Test loss=0.364232 Current lr=[0.0003660438766252499]

[0/23] Train loss=0.14712822437286377
[5/23] Train loss=0.14078406989574432
[10/23] Train loss=0.14936615526676178
[15/23] Train loss=0.11988204717636108
[20/23] Train loss=0.16648001968860626
Test set avg_accuracy=91.66% avg_sensitivity=84.74%, avg_specificity=93.66% avg_auc=0.9508
Fold[10] Epoch: 72 [72/100 (72%)] Train loss=0.131813 Test loss=0.376983 Current lr=[0.0003445665211088922]

[0/23] Train loss=0.13214196264743805
[5/23] Train loss=0.1396344006061554
[10/23] Train loss=0.13943517208099365
[15/23] Train loss=0.12470531463623047
[20/23] Train loss=0.13934196531772614
Test set avg_accuracy=91.58% avg_sensitivity=81.65%, avg_specificity=94.45% avg_auc=0.9505
Fold[10] Epoch: 73 [73/100 (73%)] Train loss=0.123814 Test loss=0.376051 Current lr=[0.00032340219196125877]

[0/23] Train loss=0.11700233072042465
[5/23] Train loss=0.11927171051502228
[10/23] Train loss=0.12857024371623993
[15/23] Train loss=0.10699694603681564
[20/23] Train loss=0.13289456069469452
Test set avg_accuracy=92.19% avg_sensitivity=81.86%, avg_specificity=95.18% avg_auc=0.9513
Fold[10] Epoch: 74 [74/100 (74%)] Train loss=0.112402 Test loss=0.379944 Current lr=[0.0003025935113246488]

[0/23] Train loss=0.1127411425113678
[5/23] Train loss=0.1155509203672409
[10/23] Train loss=0.12382924556732178
[15/23] Train loss=0.11726435273885727
[20/23] Train loss=0.13633695244789124
Test set avg_accuracy=92.11% avg_sensitivity=81.60%, avg_specificity=95.15% avg_auc=0.9525
Fold[10] Epoch: 75 [75/100 (75%)] Train loss=0.106630 Test loss=0.370968 Current lr=[0.0002821823851125901]

[0/23] Train loss=0.10736928880214691
[5/23] Train loss=0.12445742636919022
[10/23] Train loss=0.09934341907501221
[15/23] Train loss=0.0971430167555809
[20/23] Train loss=0.1117362454533577
Test set avg_accuracy=92.19% avg_sensitivity=80.58%, avg_specificity=95.55% avg_auc=0.9524
Fold[10] Epoch: 76 [76/100 (76%)] Train loss=0.096199 Test loss=0.381268 Current lr=[0.00026220991861690765]

[0/23] Train loss=0.1101863905787468
[5/23] Train loss=0.09814706444740295
[10/23] Train loss=0.10061194747686386
[15/23] Train loss=0.09916932880878448
[20/23] Train loss=0.11217746883630753
Test set avg_accuracy=91.70% avg_sensitivity=81.19%, avg_specificity=94.74% avg_auc=0.9519
Fold[10] Epoch: 77 [77/100 (77%)] Train loss=0.092862 Test loss=0.380587 Current lr=[0.00024271633372713536]

[0/23] Train loss=0.09285800158977509
[5/23] Train loss=0.09100893884897232
[10/23] Train loss=0.09383655339479446
[15/23] Train loss=0.08831281960010529
[20/23] Train loss=0.10239548236131668
Test set avg_accuracy=91.94% avg_sensitivity=80.58%, avg_specificity=95.23% avg_auc=0.9524
Fold[10] Epoch: 78 [78/100 (78%)] Train loss=0.087078 Test loss=0.381601 Current lr=[0.00022374088792898362]

[0/23] Train loss=0.09209584444761276
[5/23] Train loss=0.0874127671122551
[10/23] Train loss=0.09294643253087997
[15/23] Train loss=0.08666183054447174
[20/23] Train loss=0.09977740794420242
Test set avg_accuracy=92.06% avg_sensitivity=80.37%, avg_specificity=95.45% avg_auc=0.9537
Fold[10] Epoch: 79 [79/100 (79%)] Train loss=0.084155 Test loss=0.385986 Current lr=[0.00020532179524498774]

[0/23] Train loss=0.08023236691951752
[5/23] Train loss=0.0948556587100029
[10/23] Train loss=0.08227218687534332
[15/23] Train loss=0.08724026381969452
[20/23] Train loss=0.10082047432661057
Test set avg_accuracy=91.58% avg_sensitivity=80.78%, avg_specificity=94.71% avg_auc=0.9533
Fold[10] Epoch: 80 [80/100 (80%)] Train loss=0.079574 Test loss=0.386099 Current lr=[0.000187496149276552]

[0/23] Train loss=0.07966428250074387
[5/23] Train loss=0.08254830539226532
[10/23] Train loss=0.08798695355653763
[15/23] Train loss=0.07609742134809494
[20/23] Train loss=0.07746759057044983
Test set avg_accuracy=91.98% avg_sensitivity=79.60%, avg_specificity=95.57% avg_auc=0.9525
Fold[10] Epoch: 81 [81/100 (81%)] Train loss=0.077004 Test loss=0.393780 Current lr=[0.00017029984850237305]

[0/23] Train loss=0.06426174938678741
[5/23] Train loss=0.0803992971777916
[10/23] Train loss=0.07585027068853378
[15/23] Train loss=0.08369127660989761
[20/23] Train loss=0.07282260805368423
Test set avg_accuracy=91.85% avg_sensitivity=80.06%, avg_specificity=95.26% avg_auc=0.9534
Fold[10] Epoch: 82 [82/100 (82%)] Train loss=0.073451 Test loss=0.402631 Current lr=[0.00015376752398368106]

[0/23] Train loss=0.07922594994306564
[5/23] Train loss=0.10032574087381363
[10/23] Train loss=0.06750629097223282
[15/23] Train loss=0.07067717611789703
[20/23] Train loss=0.0838267058134079
Test set avg_accuracy=92.25% avg_sensitivity=80.78%, avg_specificity=95.57% avg_auc=0.9531
Fold[10] Epoch: 83 [83/100 (83%)] Train loss=0.071847 Test loss=0.394221 Current lr=[0.00013793246962189157]

[0/23] Train loss=0.06538800895214081
[5/23] Train loss=0.07741966843605042
[10/23] Train loss=0.072132907807827
[15/23] Train loss=0.0711873471736908
[20/23] Train loss=0.07986587285995483
Test set avg_accuracy=92.09% avg_sensitivity=80.52%, avg_specificity=95.43% avg_auc=0.9528
Fold[10] Epoch: 84 [84/100 (84%)] Train loss=0.067946 Test loss=0.401048 Current lr=[0.00012282657510911843]

[0/23] Train loss=0.0695706382393837
[5/23] Train loss=0.07757587730884552
[10/23] Train loss=0.06570464372634888
[15/23] Train loss=0.059658028185367584
[20/23] Train loss=0.08166801184415817
Test set avg_accuracy=91.98% avg_sensitivity=80.11%, avg_specificity=95.42% avg_auc=0.9520
Fold[10] Epoch: 85 [85/100 (85%)] Train loss=0.067289 Test loss=0.410978 Current lr=[0.0001084802617065783]

[0/23] Train loss=0.07103116065263748
[5/23] Train loss=0.0801994577050209
[10/23] Train loss=0.0750197023153305
[15/23] Train loss=0.08130580931901932
[20/23] Train loss=0.07091693580150604
Test set avg_accuracy=92.10% avg_sensitivity=80.58%, avg_specificity=95.43% avg_auc=0.9522
Fold[10] Epoch: 86 [86/100 (86%)] Train loss=0.065925 Test loss=0.407462 Current lr=[9.492242098021878e-05]

[0/23] Train loss=0.07707832753658295
[5/23] Train loss=0.07787295430898666
[10/23] Train loss=0.0719916895031929
[15/23] Train loss=0.05617793649435043
[20/23] Train loss=0.07951190322637558
Test set avg_accuracy=92.10% avg_sensitivity=80.27%, avg_specificity=95.52% avg_auc=0.9523
Fold[10] Epoch: 87 [87/100 (87%)] Train loss=0.064923 Test loss=0.410326 Current lr=[8.218035661694964e-05]

[0/23] Train loss=0.058931831270456314
[5/23] Train loss=0.07429564744234085
[10/23] Train loss=0.06333411484956741
[15/23] Train loss=0.06924134492874146
[20/23] Train loss=0.07514122873544693
Test set avg_accuracy=92.16% avg_sensitivity=80.73%, avg_specificity=95.46% avg_auc=0.9524
Fold[10] Epoch: 88 [88/100 (88%)] Train loss=0.062017 Test loss=0.413135 Current lr=[7.02797294386511e-05]

[0/23] Train loss=0.06989342719316483
[5/23] Train loss=0.07313903421163559
[10/23] Train loss=0.06004106253385544
[15/23] Train loss=0.06375356018543243
[20/23] Train loss=0.06541721522808075
Test set avg_accuracy=92.13% avg_sensitivity=80.58%, avg_specificity=95.48% avg_auc=0.9527
Fold[10] Epoch: 89 [89/100 (89%)] Train loss=0.060486 Test loss=0.412512 Current lr=[5.924450572469346e-05]

[0/23] Train loss=0.06146566569805145
[5/23] Train loss=0.06319893896579742
[10/23] Train loss=0.06504302471876144
[15/23] Train loss=0.06271517276763916
[20/23] Train loss=0.07897922396659851
Test set avg_accuracy=92.04% avg_sensitivity=79.96%, avg_specificity=95.54% avg_auc=0.9527
Fold[10] Epoch: 90 [90/100 (90%)] Train loss=0.061316 Test loss=0.412492 Current lr=[4.90969089470401e-05]

[0/23] Train loss=0.05271124467253685
[5/23] Train loss=0.05707453563809395
[10/23] Train loss=0.059061672538518906
[15/23] Train loss=0.05946379899978638
[20/23] Train loss=0.08163335174322128
Test set avg_accuracy=92.08% avg_sensitivity=80.22%, avg_specificity=95.51% avg_auc=0.9525
Fold[10] Epoch: 91 [91/100 (91%)] Train loss=0.057774 Test loss=0.412534 Current lr=[3.985737501513232e-05]

[0/23] Train loss=0.07313739508390427
[5/23] Train loss=0.066450335085392
[10/23] Train loss=0.06403028964996338
[15/23] Train loss=0.060427986085414886
[20/23] Train loss=0.0726962760090828
Test set avg_accuracy=92.04% avg_sensitivity=80.37%, avg_specificity=95.42% avg_auc=0.9524
Fold[10] Epoch: 92 [92/100 (92%)] Train loss=0.060399 Test loss=0.412139 Current lr=[3.154451112068745e-05]

[0/23] Train loss=0.0595175065100193
[5/23] Train loss=0.06419070065021515
[10/23] Train loss=0.06632906943559647
[15/23] Train loss=0.05901814624667168
[20/23] Train loss=0.06417948752641678
Test set avg_accuracy=92.02% avg_sensitivity=80.16%, avg_specificity=95.45% avg_auc=0.9522
Fold[10] Epoch: 93 [93/100 (93%)] Train loss=0.056887 Test loss=0.413704 Current lr=[2.4175058265291265e-05]

[0/23] Train loss=0.0576680526137352
[5/23] Train loss=0.06022346392273903
[10/23] Train loss=0.0634201392531395
[15/23] Train loss=0.058301616460084915
[20/23] Train loss=0.07232687622308731
Test set avg_accuracy=92.12% avg_sensitivity=80.27%, avg_specificity=95.55% avg_auc=0.9522
Fold[10] Epoch: 94 [94/100 (94%)] Train loss=0.056042 Test loss=0.414661 Current lr=[1.7763857546248248e-05]

[0/23] Train loss=0.05177789181470871
[5/23] Train loss=0.07655348628759384
[10/23] Train loss=0.0632096454501152
[15/23] Train loss=0.06035419553518295
[20/23] Train loss=0.07046040147542953
Test set avg_accuracy=92.04% avg_sensitivity=80.22%, avg_specificity=95.46% avg_auc=0.9523
Fold[10] Epoch: 95 [95/100 (95%)] Train loss=0.058037 Test loss=0.414825 Current lr=[1.2323820268587161e-05]

[0/23] Train loss=0.05976512283086777
[5/23] Train loss=0.06856391578912735
[10/23] Train loss=0.06095077097415924
[15/23] Train loss=0.06549671292304993
[20/23] Train loss=0.07206876575946808
Test set avg_accuracy=92.05% avg_sensitivity=80.22%, avg_specificity=95.48% avg_auc=0.9522
Fold[10] Epoch: 96 [96/100 (96%)] Train loss=0.059292 Test loss=0.415376 Current lr=[7.865901943410707e-06]

[0/23] Train loss=0.06354578584432602
[5/23] Train loss=0.06134740635752678
[10/23] Train loss=0.05116558447480202
[15/23] Train loss=0.05908162146806717
[20/23] Train loss=0.05566474050283432
Test set avg_accuracy=92.06% avg_sensitivity=80.32%, avg_specificity=95.46% avg_auc=0.9523
Fold[10] Epoch: 97 [97/100 (97%)] Train loss=0.055789 Test loss=0.415311 Current lr=[4.399080224954306e-06]

[0/23] Train loss=0.07004444301128387
[5/23] Train loss=0.0620628222823143
[10/23] Train loss=0.06556539982557297
[15/23] Train loss=0.05914733558893204
[20/23] Train loss=0.06867887824773788
Test set avg_accuracy=92.05% avg_sensitivity=80.32%, avg_specificity=95.45% avg_auc=0.9523
Fold[10] Epoch: 98 [98/100 (98%)] Train loss=0.057288 Test loss=0.415276 Current lr=[1.930336830785271e-06]

[0/23] Train loss=0.05819380655884743
[5/23] Train loss=0.06571723520755768
[10/23] Train loss=0.05675751715898514
[15/23] Train loss=0.06530413776636124
[20/23] Train loss=0.07393167167901993
Test set avg_accuracy=92.05% avg_sensitivity=80.32%, avg_specificity=95.45% avg_auc=0.9523
Fold[10] Epoch: 99 [99/100 (99%)] Train loss=0.057043 Test loss=0.415222 Current lr=[4.6464348155246055e-07]

[0/23] Train loss=0.061235878616571426
[5/23] Train loss=0.06366486102342606
[10/23] Train loss=0.06093328446149826
[15/23] Train loss=0.06343729794025421
[20/23] Train loss=0.06950743496417999
Test set avg_accuracy=92.05% avg_sensitivity=80.32%, avg_specificity=95.45% avg_auc=0.9523
Fold[10] Epoch: 100 [100/100 (100%)] Train loss=0.056444 Test loss=0.415434 Current lr=[4.951888602991508e-09]

Fold[10] Best Result: acc=91.58016147635524 sen=88.0781089414183, spe=92.59369422962523, auc=0.9552457931674547!
Final Avg Result: avg_acc=89.304247% avg_sen=84.970751% avg_spe=90.768176% avg_auc=0.944203
