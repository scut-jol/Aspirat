[0/24] Train loss=0.947068989276886
[5/24] Train loss=0.7749770283699036
[10/24] Train loss=0.6999996304512024
[15/24] Train loss=0.6630908250808716
[20/24] Train loss=0.6421300768852234
Test set avg_accuracy=73.52% avg_sensitivity=1.24%, avg_specificity=99.33% avg_auc=50.82%
Best model saved!! Metric=-101.09942064329357!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.717968 Test loss=0.595626 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6205381155014038
[5/24] Train loss=0.5857149958610535
[10/24] Train loss=0.607617974281311
[15/24] Train loss=0.6111257076263428
[20/24] Train loss=0.6146643161773682
Test set avg_accuracy=73.70% avg_sensitivity=0.20%, avg_specificity=99.95% avg_auc=52.52%
Best model saved!! Metric=-99.63906167149129!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.606342 Test loss=0.579181 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.5947865843772888
[5/24] Train loss=0.5730279684066772
[10/24] Train loss=0.5957677364349365
[15/24] Train loss=0.6018599271774292
[20/24] Train loss=0.6002249717712402
Test set avg_accuracy=73.66% avg_sensitivity=0.20%, avg_specificity=99.89% avg_auc=55.44%
Best model saved!! Metric=-96.80756701841779!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.593084 Test loss=0.574194 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.5969425439834595
[5/24] Train loss=0.5775448083877563
[10/24] Train loss=0.5825514793395996
[15/24] Train loss=0.5968510508537292
[20/24] Train loss=0.5957697629928589
Test set avg_accuracy=73.66% avg_sensitivity=0.30%, avg_specificity=99.86% avg_auc=58.61%
Best model saved!! Metric=-93.5706411510518!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.590368 Test loss=0.568835 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5817432999610901
[5/24] Train loss=0.5682836771011353
[10/24] Train loss=0.5832348465919495
[15/24] Train loss=0.5954996347427368
[20/24] Train loss=0.5990767478942871
Test set avg_accuracy=73.68% avg_sensitivity=0.25%, avg_specificity=99.91% avg_auc=62.42%
Best model saved!! Metric=-89.73425468544201!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.582733 Test loss=0.562097 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5769593715667725
[5/24] Train loss=0.5612817406654358
[10/24] Train loss=0.5786515474319458
[15/24] Train loss=0.5832000374794006
[20/24] Train loss=0.5777836441993713
Test set avg_accuracy=73.71% avg_sensitivity=0.49%, avg_specificity=99.86% avg_auc=65.86%
Best model saved!! Metric=-86.07087493960853!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.575749 Test loss=0.555608 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5694706439971924
[5/24] Train loss=0.5501789450645447
[10/24] Train loss=0.570030152797699
[15/24] Train loss=0.5760651230812073
[20/24] Train loss=0.5746082663536072
Test set avg_accuracy=73.65% avg_sensitivity=0.69%, avg_specificity=99.70% avg_auc=69.59%
Best model saved!! Metric=-82.36760831780823!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.568358 Test loss=0.548823 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5615535378456116
[5/24] Train loss=0.5436406135559082
[10/24] Train loss=0.5659254789352417
[15/24] Train loss=0.5662640929222107
[20/24] Train loss=0.5677976012229919
Test set avg_accuracy=73.49% avg_sensitivity=0.74%, avg_specificity=99.47% avg_auc=72.52%
Best model saved!! Metric=-79.77361412883256!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.559911 Test loss=0.541211 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5505468249320984
[5/24] Train loss=0.5345523953437805
[10/24] Train loss=0.5521425008773804
[15/24] Train loss=0.5576675534248352
[20/24] Train loss=0.5562872290611267
Test set avg_accuracy=73.36% avg_sensitivity=1.19%, avg_specificity=99.13% avg_auc=75.25%
Best model saved!! Metric=-77.07352993116149!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.551074 Test loss=0.532232 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5451534390449524
[5/24] Train loss=0.5210643410682678
[10/24] Train loss=0.5470618009567261
[15/24] Train loss=0.543083131313324
[20/24] Train loss=0.542335033416748
Test set avg_accuracy=73.18% avg_sensitivity=2.33%, avg_specificity=98.48% avg_auc=77.57%
Best model saved!! Metric=-74.44214642062228!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.541778 Test loss=0.520818 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5294874906539917
[5/24] Train loss=0.5038200616836548
[10/24] Train loss=0.5323740839958191
[15/24] Train loss=0.5339688658714294
[20/24] Train loss=0.5298563838005066
Test set avg_accuracy=73.03% avg_sensitivity=3.86%, avg_specificity=97.74% avg_auc=79.24%
Best model saved!! Metric=-72.12387376847346!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.529210 Test loss=0.507102 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5124834179878235
[5/24] Train loss=0.4942554235458374
[10/24] Train loss=0.5277761816978455
[15/24] Train loss=0.5153712034225464
[20/24] Train loss=0.5106344223022461
Test set avg_accuracy=73.40% avg_sensitivity=7.52%, avg_specificity=96.93% avg_auc=80.80%
Best model saved!! Metric=-67.355927757743!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.515495 Test loss=0.491113 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.49110978841781616
[5/24] Train loss=0.46821364760398865
[10/24] Train loss=0.5114432573318481
[15/24] Train loss=0.499223530292511
[20/24] Train loss=0.4976452887058258
Test set avg_accuracy=74.95% avg_sensitivity=20.09%, avg_specificity=94.54% avg_auc=82.09%
Best model saved!! Metric=-54.33799126646065!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.497854 Test loss=0.473093 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.47558555006980896
[5/24] Train loss=0.4596061408519745
[10/24] Train loss=0.49353545904159546
[15/24] Train loss=0.48230433464050293
[20/24] Train loss=0.4772653877735138
Test set avg_accuracy=76.34% avg_sensitivity=30.58%, avg_specificity=92.68% avg_auc=83.32%
Best model saved!! Metric=-43.074714090899235!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.482156 Test loss=0.455522 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.45732495188713074
[5/24] Train loss=0.4391200542449951
[10/24] Train loss=0.488911896944046
[15/24] Train loss=0.4604063034057617
[20/24] Train loss=0.45934122800827026
Test set avg_accuracy=78.15% avg_sensitivity=43.34%, avg_specificity=90.58% avg_auc=84.05%
Best model saved!! Metric=-29.876339325581256!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.466746 Test loss=0.442774 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.44447067379951477
[5/24] Train loss=0.42757880687713623
[10/24] Train loss=0.4688208997249603
[15/24] Train loss=0.4503338932991028
[20/24] Train loss=0.4458613395690918
Test set avg_accuracy=79.41% avg_sensitivity=51.56%, avg_specificity=89.36% avg_auc=84.93%
Best model saved!! Metric=-20.733256527573957!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.454098 Test loss=0.430983 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4345131516456604
[5/24] Train loss=0.4149075448513031
[10/24] Train loss=0.4636884033679962
[15/24] Train loss=0.4372965693473816
[20/24] Train loss=0.4326905906200409
Test set avg_accuracy=80.25% avg_sensitivity=56.41%, avg_specificity=88.76% avg_auc=85.65%
Best model saved!! Metric=-14.930363860582084!!
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.442497 Test loss=0.420528 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4167024791240692
[5/24] Train loss=0.41256746649742126
[10/24] Train loss=0.4533926248550415
[15/24] Train loss=0.4318384528160095
[20/24] Train loss=0.42096731066703796
Test set avg_accuracy=80.59% avg_sensitivity=56.51%, avg_specificity=89.19% avg_auc=86.27%
Best model saved!! Metric=-13.452704995535704!!
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.432286 Test loss=0.408451 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.40735894441604614
[5/24] Train loss=0.3965264856815338
[10/24] Train loss=0.4471195638179779
[15/24] Train loss=0.42916616797447205
[20/24] Train loss=0.4070133566856384
Test set avg_accuracy=81.07% avg_sensitivity=53.04%, avg_specificity=91.08% avg_auc=86.80%
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.423063 Test loss=0.397626 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.39323192834854126
[5/24] Train loss=0.3813953697681427
[10/24] Train loss=0.4319121241569519
[15/24] Train loss=0.41897639632225037
[20/24] Train loss=0.4027581214904785
Test set avg_accuracy=81.09% avg_sensitivity=49.73%, avg_specificity=92.30% avg_auc=87.13%
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.414961 Test loss=0.391319 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.38036537170410156
[5/24] Train loss=0.3803569972515106
[10/24] Train loss=0.41590094566345215
[15/24] Train loss=0.4007696509361267
[20/24] Train loss=0.3890343904495239
Test set avg_accuracy=81.48% avg_sensitivity=50.72%, avg_specificity=92.47% avg_auc=87.53%
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.404061 Test loss=0.385399 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.37709638476371765
[5/24] Train loss=0.37526825070381165
[10/24] Train loss=0.402904212474823
[15/24] Train loss=0.3928660452365875
[20/24] Train loss=0.38596901297569275
Test set avg_accuracy=81.97% avg_sensitivity=56.41%, avg_specificity=91.09% avg_auc=88.08%
Best model saved!! Metric=-8.453564018313621!!
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.396379 Test loss=0.378239 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.37006786465644836
[5/24] Train loss=0.3674338757991791
[10/24] Train loss=0.39478790760040283
[15/24] Train loss=0.3795895576477051
[20/24] Train loss=0.37905681133270264
Test set avg_accuracy=82.27% avg_sensitivity=55.12%, avg_specificity=91.96% avg_auc=88.37%
Best model saved!! Metric=-8.285681527966325!!
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.389164 Test loss=0.373547 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3613746464252472
[5/24] Train loss=0.3597721457481384
[10/24] Train loss=0.3987441658973694
[15/24] Train loss=0.3733842074871063
[20/24] Train loss=0.37008827924728394
Test set avg_accuracy=82.32% avg_sensitivity=53.34%, avg_specificity=92.67% avg_auc=88.57%
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.384680 Test loss=0.370515 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3602171242237091
[5/24] Train loss=0.35881271958351135
[10/24] Train loss=0.38557592034339905
[15/24] Train loss=0.37261730432510376
[20/24] Train loss=0.36167871952056885
Test set avg_accuracy=82.51% avg_sensitivity=53.44%, avg_specificity=92.90% avg_auc=88.72%
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.381050 Test loss=0.368384 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3526860773563385
[5/24] Train loss=0.3595852851867676
[10/24] Train loss=0.381250262260437
[15/24] Train loss=0.3672051429748535
[20/24] Train loss=0.35911989212036133
Test set avg_accuracy=82.55% avg_sensitivity=52.55%, avg_specificity=93.27% avg_auc=88.83%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.377484 Test loss=0.367509 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.34318020939826965
[5/24] Train loss=0.3614500164985657
[10/24] Train loss=0.3758971095085144
[15/24] Train loss=0.36367765069007874
[20/24] Train loss=0.3566335141658783
Test set avg_accuracy=82.54% avg_sensitivity=51.90%, avg_specificity=93.48% avg_auc=88.93%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.373149 Test loss=0.366408 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3417888879776001
[5/24] Train loss=0.3537853956222534
[10/24] Train loss=0.37526899576187134
[15/24] Train loss=0.36617839336395264
[20/24] Train loss=0.358402281999588
Test set avg_accuracy=82.83% avg_sensitivity=54.38%, avg_specificity=92.98% avg_auc=89.07%
Best model saved!! Metric=-6.741964902891496!!
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.370477 Test loss=0.362971 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3404461741447449
[5/24] Train loss=0.3425184488296509
[10/24] Train loss=0.3715346157550812
[15/24] Train loss=0.3696492612361908
[20/24] Train loss=0.35518285632133484
Test set avg_accuracy=83.12% avg_sensitivity=56.11%, avg_specificity=92.77% avg_auc=89.23%
Best model saved!! Metric=-4.765768069743764!!
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.367123 Test loss=0.360553 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.33916234970092773
[5/24] Train loss=0.34597721695899963
[10/24] Train loss=0.36861443519592285
[15/24] Train loss=0.36122894287109375
[20/24] Train loss=0.35750722885131836
Test set avg_accuracy=83.06% avg_sensitivity=56.41%, avg_specificity=92.58% avg_auc=89.27%
Best model saved!! Metric=-4.682443986261937!!
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.366185 Test loss=0.359802 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.33982348442077637
[5/24] Train loss=0.3462342321872711
[10/24] Train loss=0.3694688677787781
[15/24] Train loss=0.3590245246887207
[20/24] Train loss=0.35612356662750244
Test set avg_accuracy=83.05% avg_sensitivity=55.67%, avg_specificity=92.83% avg_auc=89.27%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.364626 Test loss=0.359816 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3319879174232483
[5/24] Train loss=0.3438582420349121
[10/24] Train loss=0.369008868932724
[15/24] Train loss=0.35913053154945374
[20/24] Train loss=0.349232941865921
Test set avg_accuracy=83.16% avg_sensitivity=53.93%, avg_specificity=93.60% avg_auc=89.24%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.363337 Test loss=0.361737 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.33658367395401
[5/24] Train loss=0.3449375331401825
[10/24] Train loss=0.3709545135498047
[15/24] Train loss=0.3575668931007385
[20/24] Train loss=0.3452240824699402
Test set avg_accuracy=83.07% avg_sensitivity=53.98%, avg_specificity=93.46% avg_auc=89.32%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.362072 Test loss=0.360484 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.33245399594306946
[5/24] Train loss=0.3350576162338257
[10/24] Train loss=0.3647269904613495
[15/24] Train loss=0.3549221456050873
[20/24] Train loss=0.3450275659561157
Test set avg_accuracy=82.90% avg_sensitivity=50.22%, avg_specificity=94.58% avg_auc=89.22%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.361153 Test loss=0.365490 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3359033167362213
[5/24] Train loss=0.3396429419517517
[10/24] Train loss=0.3662283718585968
[15/24] Train loss=0.34860387444496155
[20/24] Train loss=0.34384140372276306
Test set avg_accuracy=83.14% avg_sensitivity=52.15%, avg_specificity=94.20% avg_auc=89.15%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.359736 Test loss=0.364914 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3336881399154663
[5/24] Train loss=0.3358151912689209
[10/24] Train loss=0.35992756485939026
[15/24] Train loss=0.35238927602767944
[20/24] Train loss=0.3413885235786438
Test set avg_accuracy=82.92% avg_sensitivity=52.25%, avg_specificity=93.87% avg_auc=89.29%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.359206 Test loss=0.362086 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.32985809445381165
[5/24] Train loss=0.3375164866447449
[10/24] Train loss=0.361209511756897
[15/24] Train loss=0.3526914119720459
[20/24] Train loss=0.3380219340324402
Test set avg_accuracy=83.07% avg_sensitivity=53.09%, avg_specificity=93.78% avg_auc=89.32%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.357599 Test loss=0.361601 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.33125802874565125
[5/24] Train loss=0.33618929982185364
[10/24] Train loss=0.36185699701309204
[15/24] Train loss=0.35275277495384216
[20/24] Train loss=0.34200990200042725
Test set avg_accuracy=83.19% avg_sensitivity=53.39%, avg_specificity=93.83% avg_auc=89.43%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.356772 Test loss=0.359666 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3325856924057007
[5/24] Train loss=0.33949530124664307
[10/24] Train loss=0.362994521856308
[15/24] Train loss=0.3525252640247345
[20/24] Train loss=0.3445001244544983
Test set avg_accuracy=82.99% avg_sensitivity=53.44%, avg_specificity=93.55% avg_auc=89.37%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.356945 Test loss=0.360159 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.32663729786872864
[5/24] Train loss=0.34171348810195923
[10/24] Train loss=0.36396732926368713
[15/24] Train loss=0.35624271631240845
[20/24] Train loss=0.3396745026111603
Test set avg_accuracy=83.11% avg_sensitivity=53.34%, avg_specificity=93.74% avg_auc=89.40%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.355939 Test loss=0.359808 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3272458016872406
[5/24] Train loss=0.33935967087745667
[10/24] Train loss=0.35966306924819946
[15/24] Train loss=0.3565569519996643
[20/24] Train loss=0.33962512016296387
Test set avg_accuracy=83.23% avg_sensitivity=53.59%, avg_specificity=93.82% avg_auc=89.47%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.354633 Test loss=0.359023 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.32970666885375977
[5/24] Train loss=0.33737078309059143
[10/24] Train loss=0.35902372002601624
[15/24] Train loss=0.3562694191932678
[20/24] Train loss=0.33639562129974365
Test set avg_accuracy=83.15% avg_sensitivity=52.00%, avg_specificity=94.27% avg_auc=89.35%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.354615 Test loss=0.362174 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.32668536901474
[5/24] Train loss=0.33656439185142517
[10/24] Train loss=0.36029186844825745
[15/24] Train loss=0.3591873347759247
[20/24] Train loss=0.3388676643371582
Test set avg_accuracy=83.14% avg_sensitivity=53.34%, avg_specificity=93.78% avg_auc=89.51%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.353227 Test loss=0.358470 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3268989026546478
[5/24] Train loss=0.3358895182609558
[10/24] Train loss=0.3631168603897095
[15/24] Train loss=0.356253981590271
[20/24] Train loss=0.3404031991958618
Test set avg_accuracy=83.12% avg_sensitivity=53.64%, avg_specificity=93.66% avg_auc=89.34%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.353933 Test loss=0.360930 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3250650465488434
[5/24] Train loss=0.3349989056587219
[10/24] Train loss=0.3589159846305847
[15/24] Train loss=0.35345637798309326
[20/24] Train loss=0.34004995226860046
Test set avg_accuracy=83.16% avg_sensitivity=52.75%, avg_specificity=94.03% avg_auc=89.43%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.353433 Test loss=0.360335 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.32589930295944214
[5/24] Train loss=0.3417510390281677
[10/24] Train loss=0.35838958621025085
[15/24] Train loss=0.35606372356414795
[20/24] Train loss=0.34108787775039673
Test set avg_accuracy=83.28% avg_sensitivity=52.85%, avg_specificity=94.15% avg_auc=89.54%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.353885 Test loss=0.358971 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3272264897823334
[5/24] Train loss=0.34209853410720825
[10/24] Train loss=0.3570654094219208
[15/24] Train loss=0.3581535816192627
[20/24] Train loss=0.33831337094306946
Test set avg_accuracy=83.06% avg_sensitivity=51.01%, avg_specificity=94.50% avg_auc=89.44%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.354140 Test loss=0.361841 Current lr=[0.000299720220882401]

[0/24] Train loss=0.325595885515213
[5/24] Train loss=0.335472047328949
[10/24] Train loss=0.3568141460418701
[15/24] Train loss=0.35539424419403076
[20/24] Train loss=0.34074556827545166
Test set avg_accuracy=83.18% avg_sensitivity=52.94%, avg_specificity=93.97% avg_auc=89.49%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.353197 Test loss=0.359319 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.32141008973121643
[5/24] Train loss=0.3392000198364258
[10/24] Train loss=0.3623693883419037
[15/24] Train loss=0.36051395535469055
[20/24] Train loss=0.34138643741607666
Test set avg_accuracy=83.33% avg_sensitivity=52.85%, avg_specificity=94.22% avg_auc=89.44%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.353079 Test loss=0.360086 Current lr=[0.000298904600941902]

[0/24] Train loss=0.32343700528144836
[5/24] Train loss=0.3355679512023926
[10/24] Train loss=0.3639456629753113
[15/24] Train loss=0.3568584620952606
[20/24] Train loss=0.3377331495285034
Test set avg_accuracy=83.41% avg_sensitivity=53.98%, avg_specificity=93.92% avg_auc=89.60%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.352718 Test loss=0.357428 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.32637643814086914
[5/24] Train loss=0.33518341183662415
[10/24] Train loss=0.3629170358181
[15/24] Train loss=0.3547326326370239
[20/24] Train loss=0.3381592631340027
Test set avg_accuracy=83.26% avg_sensitivity=53.64%, avg_specificity=93.83% avg_auc=89.50%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.351488 Test loss=0.358503 Current lr=[0.000297555943323901]

[0/24] Train loss=0.32255351543426514
[5/24] Train loss=0.3373936712741852
[10/24] Train loss=0.3556181490421295
[15/24] Train loss=0.3521042764186859
[20/24] Train loss=0.34196847677230835
Test set avg_accuracy=83.27% avg_sensitivity=53.74%, avg_specificity=93.82% avg_auc=89.54%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.351622 Test loss=0.358222 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3217640221118927
[5/24] Train loss=0.3303004801273346
[10/24] Train loss=0.3616529107093811
[15/24] Train loss=0.35761377215385437
[20/24] Train loss=0.33587393164634705
Test set avg_accuracy=83.29% avg_sensitivity=54.08%, avg_specificity=93.73% avg_auc=89.61%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.352166 Test loss=0.356722 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3210729658603668
[5/24] Train loss=0.3356059491634369
[10/24] Train loss=0.35979780554771423
[15/24] Train loss=0.3552931249141693
[20/24] Train loss=0.339280903339386
Test set avg_accuracy=83.32% avg_sensitivity=53.19%, avg_specificity=94.08% avg_auc=89.59%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.351703 Test loss=0.357997 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.32168009877204895
[5/24] Train loss=0.33807477355003357
[10/24] Train loss=0.3580232858657837
[15/24] Train loss=0.3498455882072449
[20/24] Train loss=0.3381904363632202
Test set avg_accuracy=83.39% avg_sensitivity=53.29%, avg_specificity=94.13% avg_auc=89.57%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.351758 Test loss=0.358278 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.320660799741745
[5/24] Train loss=0.3347277045249939
[10/24] Train loss=0.36042654514312744
[15/24] Train loss=0.355656236410141
[20/24] Train loss=0.33982551097869873
Test set avg_accuracy=83.19% avg_sensitivity=50.42%, avg_specificity=94.89% avg_auc=89.60%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.350730 Test loss=0.361210 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3257458806037903
[5/24] Train loss=0.3350028097629547
[10/24] Train loss=0.35598552227020264
[15/24] Train loss=0.34580114483833313
[20/24] Train loss=0.33997222781181335
Test set avg_accuracy=83.35% avg_sensitivity=54.03%, avg_specificity=93.82% avg_auc=89.44%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.351251 Test loss=0.359421 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3206802010536194
[5/24] Train loss=0.33371075987815857
[10/24] Train loss=0.3613307476043701
[15/24] Train loss=0.353350967168808
[20/24] Train loss=0.341476708650589
Test set avg_accuracy=83.48% avg_sensitivity=54.23%, avg_specificity=93.92% avg_auc=89.65%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.350904 Test loss=0.356711 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3173164129257202
[5/24] Train loss=0.3351346254348755
[10/24] Train loss=0.36450812220573425
[15/24] Train loss=0.3518458306789398
[20/24] Train loss=0.3374989926815033
Test set avg_accuracy=83.40% avg_sensitivity=54.23%, avg_specificity=93.82% avg_auc=89.67%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.350697 Test loss=0.355681 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3155456483364105
[5/24] Train loss=0.3368624448776245
[10/24] Train loss=0.35327067971229553
[15/24] Train loss=0.35171401500701904
[20/24] Train loss=0.33453822135925293
Test set avg_accuracy=83.36% avg_sensitivity=54.18%, avg_specificity=93.78% avg_auc=89.57%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.349848 Test loss=0.357217 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3191054165363312
[5/24] Train loss=0.33515051007270813
[10/24] Train loss=0.3598804771900177
[15/24] Train loss=0.35535624623298645
[20/24] Train loss=0.3353055715560913
Test set avg_accuracy=83.41% avg_sensitivity=53.29%, avg_specificity=94.17% avg_auc=89.58%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.349485 Test loss=0.358102 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.32139071822166443
[5/24] Train loss=0.33372852206230164
[10/24] Train loss=0.3604164719581604
[15/24] Train loss=0.3538857400417328
[20/24] Train loss=0.3398323953151703
Test set avg_accuracy=83.57% avg_sensitivity=53.93%, avg_specificity=94.15% avg_auc=89.66%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.351159 Test loss=0.356908 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3189695477485657
[5/24] Train loss=0.334041029214859
[10/24] Train loss=0.3584720194339752
[15/24] Train loss=0.35055485367774963
[20/24] Train loss=0.33630460500717163
Test set avg_accuracy=83.42% avg_sensitivity=54.58%, avg_specificity=93.73% avg_auc=89.59%
Best model saved!! Metric=-4.68198224281894!!
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.349379 Test loss=0.356719 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3186238706111908
[5/24] Train loss=0.3315477669239044
[10/24] Train loss=0.3602331280708313
[15/24] Train loss=0.3504617512226105
[20/24] Train loss=0.33343130350112915
Test set avg_accuracy=83.57% avg_sensitivity=53.88%, avg_specificity=94.17% avg_auc=89.51%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.349312 Test loss=0.358808 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3192412257194519
[5/24] Train loss=0.33725911378860474
[10/24] Train loss=0.35741254687309265
[15/24] Train loss=0.35651159286499023
[20/24] Train loss=0.3369702100753784
Test set avg_accuracy=83.49% avg_sensitivity=55.07%, avg_specificity=93.64% avg_auc=89.63%
Best model saved!! Metric=-4.1720173939305525!!
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.349637 Test loss=0.355852 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.31855645775794983
[5/24] Train loss=0.3325566053390503
[10/24] Train loss=0.3580489158630371
[15/24] Train loss=0.35478609800338745
[20/24] Train loss=0.3347218930721283
Test set avg_accuracy=83.39% avg_sensitivity=52.99%, avg_specificity=94.24% avg_auc=89.70%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.350174 Test loss=0.356545 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.31755825877189636
[5/24] Train loss=0.33342888951301575
[10/24] Train loss=0.36199745535850525
[15/24] Train loss=0.35471466183662415
[20/24] Train loss=0.32997792959213257
Test set avg_accuracy=83.48% avg_sensitivity=53.74%, avg_specificity=94.10% avg_auc=89.69%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.349016 Test loss=0.356044 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.31912678480148315
[5/24] Train loss=0.33117765188217163
[10/24] Train loss=0.35593780875205994
[15/24] Train loss=0.3517015278339386
[20/24] Train loss=0.332384318113327
Test set avg_accuracy=83.54% avg_sensitivity=54.13%, avg_specificity=94.04% avg_auc=89.74%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.348917 Test loss=0.354819 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3167891204357147
[5/24] Train loss=0.3321370482444763
[10/24] Train loss=0.3573670983314514
[15/24] Train loss=0.3469807803630829
[20/24] Train loss=0.3340654969215393
Test set avg_accuracy=83.48% avg_sensitivity=53.88%, avg_specificity=94.04% avg_auc=89.71%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.349067 Test loss=0.355650 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3188682198524475
[5/24] Train loss=0.33140692114830017
[10/24] Train loss=0.35401278734207153
[15/24] Train loss=0.3531709909439087
[20/24] Train loss=0.33258432149887085
Test set avg_accuracy=83.50% avg_sensitivity=55.52%, avg_specificity=93.50% avg_auc=89.68%
Best model saved!! Metric=-3.805542253860885!!
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.349595 Test loss=0.354491 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.31719499826431274
[5/24] Train loss=0.3300555646419525
[10/24] Train loss=0.35588133335113525
[15/24] Train loss=0.35085609555244446
[20/24] Train loss=0.33080485463142395
Test set avg_accuracy=83.50% avg_sensitivity=54.18%, avg_specificity=93.97% avg_auc=89.74%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.348336 Test loss=0.354447 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.31870341300964355
[5/24] Train loss=0.33154991269111633
[10/24] Train loss=0.35361266136169434
[15/24] Train loss=0.35321539640426636
[20/24] Train loss=0.3311289846897125
Test set avg_accuracy=83.55% avg_sensitivity=54.23%, avg_specificity=94.03% avg_auc=89.69%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.348575 Test loss=0.355349 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.31814107298851013
[5/24] Train loss=0.3296292722225189
[10/24] Train loss=0.35859739780426025
[15/24] Train loss=0.3434290885925293
[20/24] Train loss=0.3304663598537445
Test set avg_accuracy=83.57% avg_sensitivity=55.27%, avg_specificity=93.67% avg_auc=89.76%
Best model saved!! Metric=-3.726819813823411!!
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.348110 Test loss=0.353103 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.31565967202186584
[5/24] Train loss=0.3301441967487335
[10/24] Train loss=0.3603396415710449
[15/24] Train loss=0.3495003283023834
[20/24] Train loss=0.3283120095729828
Test set avg_accuracy=83.44% avg_sensitivity=52.75%, avg_specificity=94.40% avg_auc=89.68%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.347854 Test loss=0.356916 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3195575773715973
[5/24] Train loss=0.332309752702713
[10/24] Train loss=0.36036208271980286
[15/24] Train loss=0.35284045338630676
[20/24] Train loss=0.32886409759521484
Test set avg_accuracy=83.49% avg_sensitivity=53.83%, avg_specificity=94.08% avg_auc=89.63%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.348684 Test loss=0.356577 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3187657594680786
[5/24] Train loss=0.32895758748054504
[10/24] Train loss=0.35753849148750305
[15/24] Train loss=0.349189430475235
[20/24] Train loss=0.32460710406303406
Test set avg_accuracy=83.49% avg_sensitivity=54.68%, avg_specificity=93.78% avg_auc=89.68%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.348508 Test loss=0.354758 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.31607717275619507
[5/24] Train loss=0.32976648211479187
[10/24] Train loss=0.3567090928554535
[15/24] Train loss=0.3515702188014984
[20/24] Train loss=0.32477420568466187
Test set avg_accuracy=83.36% avg_sensitivity=53.09%, avg_specificity=94.17% avg_auc=89.64%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.348106 Test loss=0.357224 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3241334557533264
[5/24] Train loss=0.33317267894744873
[10/24] Train loss=0.3589455187320709
[15/24] Train loss=0.34850090742111206
[20/24] Train loss=0.33559370040893555
Test set avg_accuracy=83.35% avg_sensitivity=53.39%, avg_specificity=94.04% avg_auc=89.64%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.348843 Test loss=0.356877 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3131689131259918
[5/24] Train loss=0.3299810290336609
[10/24] Train loss=0.3624136447906494
[15/24] Train loss=0.34843093156814575
[20/24] Train loss=0.3294049799442291
Test set avg_accuracy=83.27% avg_sensitivity=52.80%, avg_specificity=94.15% avg_auc=89.59%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.349794 Test loss=0.358268 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3221586346626282
[5/24] Train loss=0.33048975467681885
[10/24] Train loss=0.36096125841140747
[15/24] Train loss=0.3412262201309204
[20/24] Train loss=0.3346059024333954
Test set avg_accuracy=83.46% avg_sensitivity=55.17%, avg_specificity=93.57% avg_auc=89.49%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.350020 Test loss=0.357479 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3159808814525604
[5/24] Train loss=0.33231309056282043
[10/24] Train loss=0.3573298752307892
[15/24] Train loss=0.35296520590782166
[20/24] Train loss=0.33486780524253845
Test set avg_accuracy=83.59% avg_sensitivity=57.94%, avg_specificity=92.75% avg_auc=89.68%
Best model saved!! Metric=-2.0249086171231383!!
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.349585 Test loss=0.352519 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.31437036395072937
[5/24] Train loss=0.3350939154624939
[10/24] Train loss=0.3563384413719177
[15/24] Train loss=0.35495126247406006
[20/24] Train loss=0.33027777075767517
Test set avg_accuracy=83.55% avg_sensitivity=58.04%, avg_specificity=92.67% avg_auc=89.61%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.348620 Test loss=0.353259 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3148801326751709
[5/24] Train loss=0.3331327736377716
[10/24] Train loss=0.36088117957115173
[15/24] Train loss=0.3492824137210846
[20/24] Train loss=0.3329492211341858
Test set avg_accuracy=83.66% avg_sensitivity=59.08%, avg_specificity=92.44% avg_auc=89.67%
Best model saved!! Metric=-1.1549404491358217!!
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.349325 Test loss=0.352401 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3198319673538208
[5/24] Train loss=0.3319833278656006
[10/24] Train loss=0.3565906286239624
[15/24] Train loss=0.3578723967075348
[20/24] Train loss=0.3255399465560913
Test set avg_accuracy=83.66% avg_sensitivity=59.38%, avg_specificity=92.33% avg_auc=89.66%
Best model saved!! Metric=-0.9769716939579354!!
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.349436 Test loss=0.352542 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3144480288028717
[5/24] Train loss=0.3373120129108429
[10/24] Train loss=0.3600555658340454
[15/24] Train loss=0.3557467758655548
[20/24] Train loss=0.32963091135025024
Test set avg_accuracy=83.58% avg_sensitivity=58.63%, avg_specificity=92.49% avg_auc=89.50%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.348904 Test loss=0.354562 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.31549888849258423
[5/24] Train loss=0.32877975702285767
[10/24] Train loss=0.3568349778652191
[15/24] Train loss=0.3549535274505615
[20/24] Train loss=0.32918405532836914
Test set avg_accuracy=83.63% avg_sensitivity=58.78%, avg_specificity=92.51% avg_auc=89.59%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.348505 Test loss=0.353390 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3165566921234131
[5/24] Train loss=0.3332935869693756
[10/24] Train loss=0.3586580753326416
[15/24] Train loss=0.35408535599708557
[20/24] Train loss=0.32834523916244507
Test set avg_accuracy=83.40% avg_sensitivity=57.40%, avg_specificity=92.68% avg_auc=89.47%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.348528 Test loss=0.355391 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.318183034658432
[5/24] Train loss=0.3277839124202728
[10/24] Train loss=0.3571355938911438
[15/24] Train loss=0.35170748829841614
[20/24] Train loss=0.32915806770324707
Test set avg_accuracy=83.57% avg_sensitivity=58.88%, avg_specificity=92.38% avg_auc=89.56%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.347866 Test loss=0.353579 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.31610193848609924
[5/24] Train loss=0.33452895283699036
[10/24] Train loss=0.3583413362503052
[15/24] Train loss=0.35916760563850403
[20/24] Train loss=0.324078768491745
Test set avg_accuracy=83.58% avg_sensitivity=58.14%, avg_specificity=92.67% avg_auc=89.51%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.348965 Test loss=0.354553 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3163703978061676
[5/24] Train loss=0.33477452397346497
[10/24] Train loss=0.35666537284851074
[15/24] Train loss=0.35364511609077454
[20/24] Train loss=0.3259088397026062
Test set avg_accuracy=83.41% avg_sensitivity=57.15%, avg_specificity=92.79% avg_auc=89.40%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.349276 Test loss=0.356562 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.31284067034721375
[5/24] Train loss=0.3348981738090515
[10/24] Train loss=0.3573831021785736
[15/24] Train loss=0.34717103838920593
[20/24] Train loss=0.3234691917896271
Test set avg_accuracy=83.37% avg_sensitivity=56.31%, avg_specificity=93.04% avg_auc=89.37%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.349885 Test loss=0.357897 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.31597959995269775
[5/24] Train loss=0.3411441147327423
[10/24] Train loss=0.35830432176589966
[15/24] Train loss=0.3493300974369049
[20/24] Train loss=0.3256235420703888
Test set avg_accuracy=83.39% avg_sensitivity=56.90%, avg_specificity=92.84% avg_auc=89.45%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.351294 Test loss=0.356191 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.31664907932281494
[5/24] Train loss=0.34220030903816223
[10/24] Train loss=0.36078524589538574
[15/24] Train loss=0.34500065445899963
[20/24] Train loss=0.3296504020690918
Test set avg_accuracy=83.84% avg_sensitivity=63.43%, avg_specificity=91.13% avg_auc=89.57%
Best model saved!! Metric=1.9754472779895025!!
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.353945 Test loss=0.353026 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.31845974922180176
[5/24] Train loss=0.3374839127063751
[10/24] Train loss=0.3665263056755066
[15/24] Train loss=0.34264472126960754
[20/24] Train loss=0.3404863774776459
Test set avg_accuracy=83.75% avg_sensitivity=67.44%, avg_specificity=89.57% avg_auc=89.56%
Best model saved!! Metric=4.3290941010886!!
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.353520 Test loss=0.356020 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3212834894657135
[5/24] Train loss=0.32683566212654114
[10/24] Train loss=0.3579218089580536
[15/24] Train loss=0.3443548083305359
[20/24] Train loss=0.3352101743221283
Test set avg_accuracy=83.74% avg_sensitivity=65.31%, avg_specificity=90.32% avg_auc=89.64%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.349470 Test loss=0.353157 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.32120415568351746
[5/24] Train loss=0.32988226413726807
[10/24] Train loss=0.3572370409965515
[15/24] Train loss=0.34226858615875244
[20/24] Train loss=0.3334605097770691
Test set avg_accuracy=83.83% avg_sensitivity=65.61%, avg_specificity=90.33% avg_auc=89.62%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.348637 Test loss=0.353723 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3189321756362915
[5/24] Train loss=0.3291180431842804
[10/24] Train loss=0.3609199821949005
[15/24] Train loss=0.3395235240459442
[20/24] Train loss=0.33499664068222046
Test set avg_accuracy=83.91% avg_sensitivity=65.46%, avg_specificity=90.49% avg_auc=89.63%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.349558 Test loss=0.353054 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3191831409931183
[5/24] Train loss=0.3264928460121155
[10/24] Train loss=0.3588521480560303
[15/24] Train loss=0.34454238414764404
[20/24] Train loss=0.33387747406959534
Test set avg_accuracy=83.80% avg_sensitivity=65.41%, avg_specificity=90.37% avg_auc=89.64%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.347389 Test loss=0.353492 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3198455274105072
[5/24] Train loss=0.33076879382133484
[10/24] Train loss=0.3594791889190674
[15/24] Train loss=0.3432055115699768
[20/24] Train loss=0.33438050746917725
Test set avg_accuracy=83.72% avg_sensitivity=65.51%, avg_specificity=90.23% avg_auc=89.62%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.348182 Test loss=0.352701 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3210708498954773
[5/24] Train loss=0.3323073387145996
[10/24] Train loss=0.35706207156181335
[15/24] Train loss=0.34345266222953796
[20/24] Train loss=0.33433103561401367
Test set avg_accuracy=83.87% avg_sensitivity=64.92%, avg_specificity=90.63% avg_auc=89.61%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.347887 Test loss=0.352846 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3204743266105652
[5/24] Train loss=0.32946810126304626
[10/24] Train loss=0.3591485321521759
[15/24] Train loss=0.3443939685821533
[20/24] Train loss=0.33067548274993896
Test set avg_accuracy=83.88% avg_sensitivity=64.57%, avg_specificity=90.78% avg_auc=89.70%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.347417 Test loss=0.351614 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3194238245487213
[5/24] Train loss=0.3257482647895813
[10/24] Train loss=0.36092862486839294
[15/24] Train loss=0.34235626459121704
[20/24] Train loss=0.32976654171943665
Test set avg_accuracy=83.88% avg_sensitivity=65.12%, avg_specificity=90.58% avg_auc=89.71%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.347488 Test loss=0.351911 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3161316215991974
[5/24] Train loss=0.3297645151615143
[10/24] Train loss=0.3579561412334442
[15/24] Train loss=0.34517908096313477
[20/24] Train loss=0.32989609241485596
Test set avg_accuracy=83.92% avg_sensitivity=64.52%, avg_specificity=90.85% avg_auc=89.72%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.347220 Test loss=0.351176 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.31980451941490173
[5/24] Train loss=0.32815760374069214
[10/24] Train loss=0.35614410042762756
[15/24] Train loss=0.3440774381160736
[20/24] Train loss=0.32920271158218384
Test set avg_accuracy=84.01% avg_sensitivity=64.37%, avg_specificity=91.02% avg_auc=89.68%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.347821 Test loss=0.351749 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.32240989804267883
[5/24] Train loss=0.32275742292404175
[10/24] Train loss=0.36182278394699097
[15/24] Train loss=0.3464159369468689
[20/24] Train loss=0.3312082588672638
Test set avg_accuracy=84.06% avg_sensitivity=65.51%, avg_specificity=90.69% avg_auc=89.59%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.347314 Test loss=0.353863 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.325330913066864
[5/24] Train loss=0.33073538541793823
[10/24] Train loss=0.35650649666786194
[15/24] Train loss=0.34723806381225586
[20/24] Train loss=0.3286188244819641
Test set avg_accuracy=84.13% avg_sensitivity=65.81%, avg_specificity=90.67% avg_auc=89.64%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.348242 Test loss=0.353266 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.32304441928863525
[5/24] Train loss=0.33384203910827637
[10/24] Train loss=0.3596991002559662
[15/24] Train loss=0.3476827144622803
[20/24] Train loss=0.3274728059768677
Test set avg_accuracy=83.96% avg_sensitivity=67.44%, avg_specificity=89.86% avg_auc=89.73%
Best model saved!! Metric=4.987237036533145!!
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.348115 Test loss=0.354082 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.32440415024757385
[5/24] Train loss=0.33773478865623474
[10/24] Train loss=0.3612660765647888
[15/24] Train loss=0.3508785367012024
[20/24] Train loss=0.3247652053833008
Test set avg_accuracy=83.79% avg_sensitivity=69.47%, avg_specificity=88.90% avg_auc=89.70%
Best model saved!! Metric=5.865467177900939!!
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.348609 Test loss=0.357321 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.32739222049713135
[5/24] Train loss=0.3360759913921356
[10/24] Train loss=0.3647047281265259
[15/24] Train loss=0.34780243039131165
[20/24] Train loss=0.33470889925956726
Test set avg_accuracy=83.42% avg_sensitivity=71.99%, avg_specificity=87.51% avg_auc=89.60%
Best model saved!! Metric=6.524191071328431!!
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.349865 Test loss=0.365642 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.33598291873931885
[5/24] Train loss=0.34010908007621765
[10/24] Train loss=0.36330556869506836
[15/24] Train loss=0.342868834733963
[20/24] Train loss=0.343515008687973
Test set avg_accuracy=83.09% avg_sensitivity=73.13%, avg_specificity=86.64% avg_auc=89.51%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.351440 Test loss=0.370497 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3411972224712372
[5/24] Train loss=0.3421887457370758
[10/24] Train loss=0.35443782806396484
[15/24] Train loss=0.34233543276786804
[20/24] Train loss=0.35833126306533813
Test set avg_accuracy=83.83% avg_sensitivity=69.97%, avg_specificity=88.78% avg_auc=89.70%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.350006 Test loss=0.360216 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3276832699775696
[5/24] Train loss=0.3257656991481781
[10/24] Train loss=0.3571043908596039
[15/24] Train loss=0.3411164879798889
[20/24] Train loss=0.34525856375694275
Test set avg_accuracy=84.08% avg_sensitivity=68.58%, avg_specificity=89.61% avg_auc=89.77%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.347582 Test loss=0.355851 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3215709328651428
[5/24] Train loss=0.3333529829978943
[10/24] Train loss=0.36391377449035645
[15/24] Train loss=0.3411441445350647
[20/24] Train loss=0.34503042697906494
Test set avg_accuracy=84.02% avg_sensitivity=68.43%, avg_specificity=89.59% avg_auc=89.78%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.346532 Test loss=0.356135 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3235064744949341
[5/24] Train loss=0.32831403613090515
[10/24] Train loss=0.3599117696285248
[15/24] Train loss=0.3399103283882141
[20/24] Train loss=0.3460312783718109
Test set avg_accuracy=84.02% avg_sensitivity=68.38%, avg_specificity=89.61% avg_auc=89.80%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.346251 Test loss=0.355838 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.32566502690315247
[5/24] Train loss=0.3250698149204254
[10/24] Train loss=0.35735130310058594
[15/24] Train loss=0.33923447132110596
[20/24] Train loss=0.3452828526496887
Test set avg_accuracy=84.09% avg_sensitivity=67.74%, avg_specificity=89.93% avg_auc=89.79%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.345430 Test loss=0.354859 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3244411051273346
[5/24] Train loss=0.3292098641395569
[10/24] Train loss=0.3563110828399658
[15/24] Train loss=0.3405021131038666
[20/24] Train loss=0.34580010175704956
Test set avg_accuracy=84.17% avg_sensitivity=67.59%, avg_specificity=90.09% avg_auc=89.80%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.345314 Test loss=0.354333 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3206845223903656
[5/24] Train loss=0.32666894793510437
[10/24] Train loss=0.35619357228279114
[15/24] Train loss=0.3406336307525635
[20/24] Train loss=0.3381388485431671
Test set avg_accuracy=84.19% avg_sensitivity=67.34%, avg_specificity=90.21% avg_auc=89.81%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.343869 Test loss=0.353817 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3209582269191742
[5/24] Train loss=0.3303939998149872
[10/24] Train loss=0.3551258444786072
[15/24] Train loss=0.33950355648994446
[20/24] Train loss=0.3409796953201294
Test set avg_accuracy=84.21% avg_sensitivity=67.05%, avg_specificity=90.33% avg_auc=89.82%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.343710 Test loss=0.353502 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3213406503200531
[5/24] Train loss=0.3308853209018707
[10/24] Train loss=0.3570306897163391
[15/24] Train loss=0.3430187404155731
[20/24] Train loss=0.3433392643928528
Test set avg_accuracy=84.19% avg_sensitivity=66.70%, avg_specificity=90.44% avg_auc=89.83%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.344574 Test loss=0.352555 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3193807005882263
[5/24] Train loss=0.32823818922042847
[10/24] Train loss=0.3569050431251526
[15/24] Train loss=0.33770042657852173
[20/24] Train loss=0.340988427400589
Test set avg_accuracy=84.22% avg_sensitivity=66.25%, avg_specificity=90.63% avg_auc=89.85%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.343374 Test loss=0.351581 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.31768912076950073
[5/24] Train loss=0.3258695602416992
[10/24] Train loss=0.354872465133667
[15/24] Train loss=0.341481477022171
[20/24] Train loss=0.33932337164878845
Test set avg_accuracy=84.24% avg_sensitivity=66.01%, avg_specificity=90.76% avg_auc=89.86%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.343234 Test loss=0.351160 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.31850627064704895
[5/24] Train loss=0.3251587748527527
[10/24] Train loss=0.3558284342288971
[15/24] Train loss=0.3394497036933899
[20/24] Train loss=0.33794477581977844
Test set avg_accuracy=84.21% avg_sensitivity=65.31%, avg_specificity=90.95% avg_auc=89.86%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.343781 Test loss=0.350636 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3180674910545349
[5/24] Train loss=0.32681944966316223
[10/24] Train loss=0.35491734743118286
[15/24] Train loss=0.3392932713031769
[20/24] Train loss=0.34150463342666626
Test set avg_accuracy=83.98% avg_sensitivity=63.83%, avg_specificity=91.18% avg_auc=89.85%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.343253 Test loss=0.349920 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.31368643045425415
[5/24] Train loss=0.32445910573005676
[10/24] Train loss=0.3583866059780121
[15/24] Train loss=0.3425876200199127
[20/24] Train loss=0.3386247158050537
Test set avg_accuracy=84.08% avg_sensitivity=64.03%, avg_specificity=91.24% avg_auc=89.87%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.342909 Test loss=0.349793 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3166336119174957
[5/24] Train loss=0.3287108838558197
[10/24] Train loss=0.3527394235134125
[15/24] Train loss=0.3435973525047302
[20/24] Train loss=0.3409455716609955
Test set avg_accuracy=84.05% avg_sensitivity=63.63%, avg_specificity=91.34% avg_auc=89.86%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.342519 Test loss=0.349623 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.31574052572250366
[5/24] Train loss=0.32620882987976074
[10/24] Train loss=0.3546861410140991
[15/24] Train loss=0.34243547916412354
[20/24] Train loss=0.33857882022857666
Test set avg_accuracy=84.02% avg_sensitivity=63.24%, avg_specificity=91.45% avg_auc=89.87%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.342558 Test loss=0.349423 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.31402918696403503
[5/24] Train loss=0.3307759165763855
[10/24] Train loss=0.35478639602661133
[15/24] Train loss=0.3393833041191101
[20/24] Train loss=0.33742496371269226
Test set avg_accuracy=84.01% avg_sensitivity=63.04%, avg_specificity=91.50% avg_auc=89.88%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.342564 Test loss=0.349042 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3150101900100708
[5/24] Train loss=0.32877472043037415
[10/24] Train loss=0.3566133677959442
[15/24] Train loss=0.34440457820892334
[20/24] Train loss=0.33178219199180603
Test set avg_accuracy=84.13% avg_sensitivity=62.30%, avg_specificity=91.92% avg_auc=89.86%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.342720 Test loss=0.349149 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3129398226737976
[5/24] Train loss=0.32566121220588684
[10/24] Train loss=0.3559838831424713
[15/24] Train loss=0.33855846524238586
[20/24] Train loss=0.3305882215499878
Test set avg_accuracy=84.04% avg_sensitivity=62.25%, avg_specificity=91.82% avg_auc=89.87%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.341494 Test loss=0.348962 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.30950242280960083
[5/24] Train loss=0.3274762034416199
[10/24] Train loss=0.3541306257247925
[15/24] Train loss=0.3391399383544922
[20/24] Train loss=0.3279271125793457
Test set avg_accuracy=84.01% avg_sensitivity=62.69%, avg_specificity=91.62% avg_auc=89.87%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.342226 Test loss=0.348933 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3134549856185913
[5/24] Train loss=0.33098700642585754
[10/24] Train loss=0.35475656390190125
[15/24] Train loss=0.3401118218898773
[20/24] Train loss=0.3269932270050049
Test set avg_accuracy=84.00% avg_sensitivity=63.48%, avg_specificity=91.32% avg_auc=89.88%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.342799 Test loss=0.349245 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3141203224658966
[5/24] Train loss=0.3287813365459442
[10/24] Train loss=0.3526090383529663
[15/24] Train loss=0.3367357552051544
[20/24] Train loss=0.32522112131118774
Test set avg_accuracy=84.15% avg_sensitivity=65.71%, avg_specificity=90.74% avg_auc=89.87%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.343145 Test loss=0.350351 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3169228732585907
[5/24] Train loss=0.3304802179336548
[10/24] Train loss=0.361083060503006
[15/24] Train loss=0.3415791988372803
[20/24] Train loss=0.3222528100013733
Test set avg_accuracy=84.11% avg_sensitivity=67.69%, avg_specificity=89.98% avg_auc=89.85%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.342821 Test loss=0.352488 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.3215563893318176
[5/24] Train loss=0.32774388790130615
[10/24] Train loss=0.3595348596572876
[15/24] Train loss=0.3399772047996521
[20/24] Train loss=0.32374274730682373
Test set avg_accuracy=84.13% avg_sensitivity=68.28%, avg_specificity=89.79% avg_auc=89.83%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.342522 Test loss=0.353558 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.32140740752220154
[5/24] Train loss=0.32716989517211914
[10/24] Train loss=0.3549446165561676
[15/24] Train loss=0.3422408699989319
[20/24] Train loss=0.32543572783470154
Test set avg_accuracy=84.14% avg_sensitivity=67.54%, avg_specificity=90.07% avg_auc=89.86%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.342169 Test loss=0.352089 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.318939745426178
[5/24] Train loss=0.32498377561569214
[10/24] Train loss=0.3566872775554657
[15/24] Train loss=0.3404257595539093
[20/24] Train loss=0.32501423358917236
Test set avg_accuracy=84.19% avg_sensitivity=66.70%, avg_specificity=90.44% avg_auc=89.89%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.340341 Test loss=0.350901 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3205462694168091
[5/24] Train loss=0.3297330439090729
[10/24] Train loss=0.36001208424568176
[15/24] Train loss=0.33986520767211914
[20/24] Train loss=0.3258686363697052
Test set avg_accuracy=84.21% avg_sensitivity=66.65%, avg_specificity=90.48% avg_auc=89.91%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.341966 Test loss=0.350998 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.3199611008167267
[5/24] Train loss=0.3253036439418793
[10/24] Train loss=0.3536865711212158
[15/24] Train loss=0.3392299711704254
[20/24] Train loss=0.3262718915939331
Test set avg_accuracy=84.30% avg_sensitivity=66.70%, avg_specificity=90.58% avg_auc=89.91%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.341140 Test loss=0.350639 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.316144734621048
[5/24] Train loss=0.32625409960746765
[10/24] Train loss=0.3518800139427185
[15/24] Train loss=0.33798104524612427
[20/24] Train loss=0.3268577754497528
Test set avg_accuracy=84.24% avg_sensitivity=66.20%, avg_specificity=90.69% avg_auc=89.91%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.340486 Test loss=0.350128 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3143077492713928
[5/24] Train loss=0.3233315944671631
[10/24] Train loss=0.35760360956192017
[15/24] Train loss=0.34088003635406494
[20/24] Train loss=0.3293597102165222
Test set avg_accuracy=84.19% avg_sensitivity=66.35%, avg_specificity=90.56% avg_auc=89.90%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.340904 Test loss=0.350441 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.31368306279182434
[5/24] Train loss=0.32880356907844543
[10/24] Train loss=0.3525358736515045
[15/24] Train loss=0.3351214826107025
[20/24] Train loss=0.3277188539505005
Test set avg_accuracy=84.18% avg_sensitivity=65.71%, avg_specificity=90.78% avg_auc=89.91%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.339763 Test loss=0.349954 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.31179091334342957
[5/24] Train loss=0.3245595395565033
[10/24] Train loss=0.35852739214897156
[15/24] Train loss=0.3387207090854645
[20/24] Train loss=0.3269059658050537
Test set avg_accuracy=84.15% avg_sensitivity=65.51%, avg_specificity=90.81% avg_auc=89.90%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.339318 Test loss=0.349915 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.31819409132003784
[5/24] Train loss=0.32695573568344116
[10/24] Train loss=0.35484579205513
[15/24] Train loss=0.33938583731651306
[20/24] Train loss=0.33053913712501526
Test set avg_accuracy=84.18% avg_sensitivity=65.71%, avg_specificity=90.78% avg_auc=89.90%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.340828 Test loss=0.350077 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3146153688430786
[5/24] Train loss=0.32512763142585754
[10/24] Train loss=0.3559211790561676
[15/24] Train loss=0.33729612827301025
[20/24] Train loss=0.324969619512558
Test set avg_accuracy=84.15% avg_sensitivity=65.51%, avg_specificity=90.81% avg_auc=89.91%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.341214 Test loss=0.349943 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3142379820346832
[5/24] Train loss=0.3274865746498108
[10/24] Train loss=0.3576369881629944
[15/24] Train loss=0.3394492566585541
[20/24] Train loss=0.3268824517726898
Test set avg_accuracy=84.15% avg_sensitivity=65.46%, avg_specificity=90.83% avg_auc=89.90%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.340177 Test loss=0.349852 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.31542524695396423
[5/24] Train loss=0.3221946954727173
[10/24] Train loss=0.3578941226005554
[15/24] Train loss=0.34230661392211914
[20/24] Train loss=0.3250356912612915
Test set avg_accuracy=84.14% avg_sensitivity=65.41%, avg_specificity=90.83% avg_auc=89.90%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.341110 Test loss=0.349803 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.316839337348938
[5/24] Train loss=0.3287842273712158
[10/24] Train loss=0.354911744594574
[15/24] Train loss=0.340075820684433
[20/24] Train loss=0.3252362608909607
Test set avg_accuracy=84.21% avg_sensitivity=65.46%, avg_specificity=90.90% avg_auc=89.91%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.340535 Test loss=0.349740 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3151046335697174
[5/24] Train loss=0.32554829120635986
[10/24] Train loss=0.35335874557495117
[15/24] Train loss=0.33991575241088867
[20/24] Train loss=0.33182039856910706
Test set avg_accuracy=84.21% avg_sensitivity=65.46%, avg_specificity=90.90% avg_auc=89.91%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.340551 Test loss=0.349747 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.31525149941444397
[5/24] Train loss=0.32613125443458557
[10/24] Train loss=0.35483089089393616
[15/24] Train loss=0.34113526344299316
[20/24] Train loss=0.32551562786102295
Test set avg_accuracy=84.18% avg_sensitivity=65.36%, avg_specificity=90.90% avg_auc=89.91%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.340295 Test loss=0.349752 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3134489953517914
[5/24] Train loss=0.3249123692512512
[10/24] Train loss=0.3589414954185486
[15/24] Train loss=0.33765724301338196
[20/24] Train loss=0.32488706707954407
Test set avg_accuracy=84.18% avg_sensitivity=65.36%, avg_specificity=90.90% avg_auc=89.91%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.339707 Test loss=0.349750 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=83.42% sen=71.99%, spe=87.51%, auc=89.60%!
Fold[1] Avg_overlap=0.62%(±0.2785002549821032)
[0/24] Train loss=0.8058410882949829
[5/24] Train loss=0.7556361556053162
[10/24] Train loss=0.6585817337036133
[15/24] Train loss=0.6281548142433167
[20/24] Train loss=0.611405611038208
Test set avg_accuracy=75.03% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=49.03%
Best model saved!! Metric=-101.96618556385096!!
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.680263 Test loss=0.578831 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6004461646080017
[5/24] Train loss=0.6329644918441772
[10/24] Train loss=0.6165528893470764
[15/24] Train loss=0.5962501764297485
[20/24] Train loss=0.5844504833221436
Test set avg_accuracy=74.97% avg_sensitivity=0.00%, avg_specificity=99.91% avg_auc=51.05%
Best model saved!! Metric=-100.06180223556848!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.606167 Test loss=0.565152 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.5858858823776245
[5/24] Train loss=0.6147950887680054
[10/24] Train loss=0.6053219437599182
[15/24] Train loss=0.5888217091560364
[20/24] Train loss=0.582223653793335
Test set avg_accuracy=74.99% avg_sensitivity=0.00%, avg_specificity=99.93% avg_auc=53.67%
Best model saved!! Metric=-97.41060997225684!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.596316 Test loss=0.562120 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.5761218070983887
[5/24] Train loss=0.6080910563468933
[10/24] Train loss=0.5937710404396057
[15/24] Train loss=0.582950234413147
[20/24] Train loss=0.5809807777404785
Test set avg_accuracy=74.93% avg_sensitivity=0.05%, avg_specificity=99.84% avg_auc=57.29%
Best model saved!! Metric=-93.8768470217897!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.591029 Test loss=0.555922 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.576975405216217
[5/24] Train loss=0.608212411403656
[10/24] Train loss=0.5843547582626343
[15/24] Train loss=0.5765355825424194
[20/24] Train loss=0.5700250267982483
Test set avg_accuracy=74.96% avg_sensitivity=0.00%, avg_specificity=99.90% avg_auc=61.90%
Best model saved!! Metric=-89.2473916582452!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.582819 Test loss=0.547990 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5566830039024353
[5/24] Train loss=0.5944530963897705
[10/24] Train loss=0.5802982449531555
[15/24] Train loss=0.566552996635437
[20/24] Train loss=0.5614305734634399
Test set avg_accuracy=74.93% avg_sensitivity=0.21%, avg_specificity=99.79% avg_auc=67.01%
Best model saved!! Metric=-84.0589406051341!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.573671 Test loss=0.539086 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5519258379936218
[5/24] Train loss=0.5801718831062317
[10/24] Train loss=0.5591594576835632
[15/24] Train loss=0.5632305145263672
[20/24] Train loss=0.5463911294937134
Test set avg_accuracy=74.95% avg_sensitivity=0.37%, avg_specificity=99.76% avg_auc=70.96%
Best model saved!! Metric=-79.96943161425155!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.563658 Test loss=0.530067 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5469075441360474
[5/24] Train loss=0.5668957829475403
[10/24] Train loss=0.5467524528503418
[15/24] Train loss=0.5433095693588257
[20/24] Train loss=0.5306810736656189
Test set avg_accuracy=74.86% avg_sensitivity=0.83%, avg_specificity=99.48% avg_auc=73.81%
Best model saved!! Metric=-77.01965597191821!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.550857 Test loss=0.519829 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5335660576820374
[5/24] Train loss=0.5553117990493774
[10/24] Train loss=0.5369760990142822
[15/24] Train loss=0.5368092060089111
[20/24] Train loss=0.5191028714179993
Test set avg_accuracy=74.71% avg_sensitivity=1.77%, avg_specificity=98.98% avg_auc=75.92%
Best model saved!! Metric=-74.61790529622714!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.540625 Test loss=0.508938 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5180981159210205
[5/24] Train loss=0.5478106737136841
[10/24] Train loss=0.5240544080734253
[15/24] Train loss=0.5142099857330322
[20/24] Train loss=0.5043326020240784
Test set avg_accuracy=74.69% avg_sensitivity=3.76%, avg_specificity=98.28% avg_auc=77.93%
Best model saved!! Metric=-71.34194783565695!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.525654 Test loss=0.496557 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5056231617927551
[5/24] Train loss=0.5206923484802246
[10/24] Train loss=0.5055287480354309
[15/24] Train loss=0.5015105605125427
[20/24] Train loss=0.4893539547920227
Test set avg_accuracy=74.70% avg_sensitivity=8.24%, avg_specificity=96.81% avg_auc=79.92%
Best model saved!! Metric=-66.32880978304725!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.513011 Test loss=0.482189 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.48064395785331726
[5/24] Train loss=0.5029140114784241
[10/24] Train loss=0.492403119802475
[15/24] Train loss=0.48518985509872437
[20/24] Train loss=0.47736525535583496
Test set avg_accuracy=75.69% avg_sensitivity=19.30%, avg_specificity=94.45% avg_auc=81.01%
Best model saved!! Metric=-55.555481079309615!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.497226 Test loss=0.469157 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.47204044461250305
[5/24] Train loss=0.48670676350593567
[10/24] Train loss=0.47518008947372437
[15/24] Train loss=0.46533384919166565
[20/24] Train loss=0.4598957896232605
Test set avg_accuracy=76.78% avg_sensitivity=27.70%, avg_specificity=93.11% avg_auc=81.75%
Best model saved!! Metric=-46.65122061063256!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.482442 Test loss=0.456984 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.44944706559181213
[5/24] Train loss=0.4631892144680023
[10/24] Train loss=0.46178197860717773
[15/24] Train loss=0.45252367854118347
[20/24] Train loss=0.44077858328819275
Test set avg_accuracy=77.58% avg_sensitivity=36.62%, avg_specificity=91.20% avg_auc=82.37%
Best model saved!! Metric=-38.225522302675834!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.466826 Test loss=0.447498 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.44590169191360474
[5/24] Train loss=0.45842549204826355
[10/24] Train loss=0.4437961280345917
[15/24] Train loss=0.43029922246932983
[20/24] Train loss=0.4280760586261749
Test set avg_accuracy=78.29% avg_sensitivity=46.43%, avg_specificity=88.89% avg_auc=82.91%
Best model saved!! Metric=-29.47768816146293!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.455709 Test loss=0.441610 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.42713192105293274
[5/24] Train loss=0.4443695545196533
[10/24] Train loss=0.4407225549221039
[15/24] Train loss=0.42272043228149414
[20/24] Train loss=0.42503008246421814
Test set avg_accuracy=78.68% avg_sensitivity=48.20%, avg_specificity=88.83% avg_auc=83.25%
Best model saved!! Metric=-27.036074315035506!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.447100 Test loss=0.434026 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4206578731536865
[5/24] Train loss=0.44294607639312744
[10/24] Train loss=0.44407129287719727
[15/24] Train loss=0.41395261883735657
[20/24] Train loss=0.4138372838497162
Test set avg_accuracy=78.92% avg_sensitivity=51.49%, avg_specificity=88.04% avg_auc=83.17%
Best model saved!! Metric=-24.38239754545892!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.442265 Test loss=0.432662 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4159105122089386
[5/24] Train loss=0.43957018852233887
[10/24] Train loss=0.4257652163505554
[15/24] Train loss=0.40168771147727966
[20/24] Train loss=0.4074335992336273
Test set avg_accuracy=78.45% avg_sensitivity=51.64%, avg_specificity=87.37% avg_auc=83.01%
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.434609 Test loss=0.431266 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.40923386812210083
[5/24] Train loss=0.4189271628856659
[10/24] Train loss=0.41984620690345764
[15/24] Train loss=0.3953879773616791
[20/24] Train loss=0.3928954601287842
Test set avg_accuracy=78.57% avg_sensitivity=49.30%, avg_specificity=88.30% avg_auc=82.97%
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.426890 Test loss=0.426928 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4036411643028259
[5/24] Train loss=0.41641199588775635
[10/24] Train loss=0.4105933904647827
[15/24] Train loss=0.39201387763023376
[20/24] Train loss=0.39038988947868347
Test set avg_accuracy=79.06% avg_sensitivity=47.99%, avg_specificity=89.40% avg_auc=83.70%
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.418039 Test loss=0.417675 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3861163556575775
[5/24] Train loss=0.3964788317680359
[10/24] Train loss=0.404543399810791
[15/24] Train loss=0.3824571669101715
[20/24] Train loss=0.3793574273586273
Test set avg_accuracy=79.92% avg_sensitivity=47.52%, avg_specificity=90.70% avg_auc=84.46%
Best model saved!! Metric=-23.392243966794005!!
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.408105 Test loss=0.409351 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.37581560015678406
[5/24] Train loss=0.38481783866882324
[10/24] Train loss=0.3945680260658264
[15/24] Train loss=0.37503838539123535
[20/24] Train loss=0.3749535381793976
Test set avg_accuracy=80.20% avg_sensitivity=44.24%, avg_specificity=92.16% avg_auc=84.67%
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.400163 Test loss=0.407864 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3617326617240906
[5/24] Train loss=0.3678404688835144
[10/24] Train loss=0.38211917877197266
[15/24] Train loss=0.36381280422210693
[20/24] Train loss=0.3683147430419922
Test set avg_accuracy=80.36% avg_sensitivity=43.14%, avg_specificity=92.75% avg_auc=84.91%
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.391783 Test loss=0.405241 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3637754023075104
[5/24] Train loss=0.36583808064460754
[10/24] Train loss=0.380813866853714
[15/24] Train loss=0.354159951210022
[20/24] Train loss=0.35931530594825745
Test set avg_accuracy=80.53% avg_sensitivity=42.15%, avg_specificity=93.30% avg_auc=84.89%
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.387170 Test loss=0.406842 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.36372265219688416
[5/24] Train loss=0.35393914580345154
[10/24] Train loss=0.3754333555698395
[15/24] Train loss=0.3502468466758728
[20/24] Train loss=0.355391263961792
Test set avg_accuracy=80.66% avg_sensitivity=39.85%, avg_specificity=94.24% avg_auc=85.33%
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.379631 Test loss=0.407577 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3558928370475769
[5/24] Train loss=0.357909232378006
[10/24] Train loss=0.36596667766571045
[15/24] Train loss=0.34721171855926514
[20/24] Train loss=0.352245569229126
Test set avg_accuracy=81.09% avg_sensitivity=41.26%, avg_specificity=94.34% avg_auc=85.68%
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.375387 Test loss=0.404391 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.35299646854400635
[5/24] Train loss=0.35024866461753845
[10/24] Train loss=0.36284777522087097
[15/24] Train loss=0.3427819013595581
[20/24] Train loss=0.3335418999195099
Test set avg_accuracy=81.54% avg_sensitivity=44.91%, avg_specificity=93.72% avg_auc=86.11%
Best model saved!! Metric=-19.718887340881636!!
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.369756 Test loss=0.393712 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.34530019760131836
[5/24] Train loss=0.3439114987850189
[10/24] Train loss=0.35733145475387573
[15/24] Train loss=0.33608952164649963
[20/24] Train loss=0.328914076089859
Test set avg_accuracy=81.63% avg_sensitivity=47.99%, avg_specificity=92.82% avg_auc=86.40%
Best model saved!! Metric=-17.161791896992376!!
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.363884 Test loss=0.387617 Current lr=[0.000210185142098938]

[0/24] Train loss=0.33944544196128845
[5/24] Train loss=0.34648096561431885
[10/24] Train loss=0.3551199436187744
[15/24] Train loss=0.32938671112060547
[20/24] Train loss=0.32955893874168396
Test set avg_accuracy=81.90% avg_sensitivity=45.75%, avg_specificity=93.93% avg_auc=86.56%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.361992 Test loss=0.388571 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.33476436138153076
[5/24] Train loss=0.34523776173591614
[10/24] Train loss=0.3535505533218384
[15/24] Train loss=0.32569336891174316
[20/24] Train loss=0.3254302442073822
Test set avg_accuracy=81.93% avg_sensitivity=44.08%, avg_specificity=94.52% avg_auc=86.64%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.359487 Test loss=0.390237 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3353545367717743
[5/24] Train loss=0.3502231240272522
[10/24] Train loss=0.35089772939682007
[15/24] Train loss=0.32750600576400757
[20/24] Train loss=0.31944945454597473
Test set avg_accuracy=81.78% avg_sensitivity=43.45%, avg_specificity=94.53% avg_auc=86.67%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.357344 Test loss=0.392620 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.33512192964553833
[5/24] Train loss=0.3533552885055542
[10/24] Train loss=0.35320723056793213
[15/24] Train loss=0.32778501510620117
[20/24] Train loss=0.32037967443466187
Test set avg_accuracy=81.90% avg_sensitivity=43.82%, avg_specificity=94.57% avg_auc=86.74%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.355224 Test loss=0.391392 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3324156701564789
[5/24] Train loss=0.3551492989063263
[10/24] Train loss=0.3475664258003235
[15/24] Train loss=0.3204692304134369
[20/24] Train loss=0.3128775358200073
Test set avg_accuracy=81.97% avg_sensitivity=43.77%, avg_specificity=94.67% avg_auc=86.74%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.354405 Test loss=0.391858 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.33168190717697144
[5/24] Train loss=0.3608897030353546
[10/24] Train loss=0.3433957099914551
[15/24] Train loss=0.322563499212265
[20/24] Train loss=0.32099756598472595
Test set avg_accuracy=81.91% avg_sensitivity=44.24%, avg_specificity=94.45% avg_auc=86.87%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.353249 Test loss=0.390607 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.33196356892585754
[5/24] Train loss=0.3531005084514618
[10/24] Train loss=0.34362900257110596
[15/24] Train loss=0.3185194432735443
[20/24] Train loss=0.31579235196113586
Test set avg_accuracy=82.06% avg_sensitivity=44.18%, avg_specificity=94.66% avg_auc=87.03%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.351006 Test loss=0.388796 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.33087611198425293
[5/24] Train loss=0.3623240888118744
[10/24] Train loss=0.34208229184150696
[15/24] Train loss=0.3199599087238312
[20/24] Train loss=0.3087459206581116
Test set avg_accuracy=82.16% avg_sensitivity=44.76%, avg_specificity=94.60% avg_auc=87.14%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.350294 Test loss=0.387218 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.32143065333366394
[5/24] Train loss=0.3530060350894928
[10/24] Train loss=0.33703702688217163
[15/24] Train loss=0.31621140241622925
[20/24] Train loss=0.3113553524017334
Test set avg_accuracy=82.14% avg_sensitivity=44.29%, avg_specificity=94.72% avg_auc=87.10%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.347434 Test loss=0.389171 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.32429957389831543
[5/24] Train loss=0.35610657930374146
[10/24] Train loss=0.3402623236179352
[15/24] Train loss=0.3141717314720154
[20/24] Train loss=0.3066228926181793
Test set avg_accuracy=82.27% avg_sensitivity=44.44%, avg_specificity=94.85% avg_auc=87.21%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.347346 Test loss=0.388241 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.32588687539100647
[5/24] Train loss=0.3517047166824341
[10/24] Train loss=0.3358106017112732
[15/24] Train loss=0.3170712888240814
[20/24] Train loss=0.30572009086608887
Test set avg_accuracy=82.47% avg_sensitivity=46.43%, avg_specificity=94.46% avg_auc=87.28%
Best model saved!! Metric=-15.354837075219315!!
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.346369 Test loss=0.385013 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.32101309299468994
[5/24] Train loss=0.3530493378639221
[10/24] Train loss=0.34073323011398315
[15/24] Train loss=0.31502285599708557
[20/24] Train loss=0.3016628324985504
Test set avg_accuracy=82.32% avg_sensitivity=45.17%, avg_specificity=94.67% avg_auc=87.33%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.345842 Test loss=0.385441 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3210400938987732
[5/24] Train loss=0.35876744985580444
[10/24] Train loss=0.3341503143310547
[15/24] Train loss=0.31292420625686646
[20/24] Train loss=0.3076368570327759
Test set avg_accuracy=82.76% avg_sensitivity=48.51%, avg_specificity=94.15% avg_auc=87.43%
Best model saved!! Metric=-13.144249212684748!!
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.344964 Test loss=0.380149 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3184877038002014
[5/24] Train loss=0.35463717579841614
[10/24] Train loss=0.33457109332084656
[15/24] Train loss=0.31186729669570923
[20/24] Train loss=0.30595022439956665
Test set avg_accuracy=82.53% avg_sensitivity=46.32%, avg_specificity=94.57% avg_auc=87.45%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.343779 Test loss=0.382455 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3176657557487488
[5/24] Train loss=0.35141393542289734
[10/24] Train loss=0.3318480849266052
[15/24] Train loss=0.31260910630226135
[20/24] Train loss=0.30659133195877075
Test set avg_accuracy=82.54% avg_sensitivity=46.17%, avg_specificity=94.64% avg_auc=87.48%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.343409 Test loss=0.382714 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3188270628452301
[5/24] Train loss=0.35240718722343445
[10/24] Train loss=0.3312380313873291
[15/24] Train loss=0.3113290071487427
[20/24] Train loss=0.30243536829948425
Test set avg_accuracy=82.86% avg_sensitivity=48.46%, avg_specificity=94.31% avg_auc=87.59%
Best model saved!! Metric=-12.772057728841666!!
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.342413 Test loss=0.378233 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3172372281551361
[5/24] Train loss=0.34445416927337646
[10/24] Train loss=0.33306682109832764
[15/24] Train loss=0.3116772472858429
[20/24] Train loss=0.3006458580493927
Test set avg_accuracy=82.53% avg_sensitivity=45.54%, avg_specificity=94.83% avg_auc=87.56%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.340778 Test loss=0.382179 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.31984183192253113
[5/24] Train loss=0.34912219643592834
[10/24] Train loss=0.3323076367378235
[15/24] Train loss=0.3073960244655609
[20/24] Train loss=0.3013197183609009
Test set avg_accuracy=82.89% avg_sensitivity=48.72%, avg_specificity=94.26% avg_auc=87.72%
Best model saved!! Metric=-12.408709674249437!!
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.340698 Test loss=0.375606 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3148225247859955
[5/24] Train loss=0.3471057415008545
[10/24] Train loss=0.3353011906147003
[15/24] Train loss=0.3096252679824829
[20/24] Train loss=0.2984578609466553
Test set avg_accuracy=83.05% avg_sensitivity=49.71%, avg_specificity=94.13% avg_auc=87.71%
Best model saved!! Metric=-11.390137651806874!!
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.340109 Test loss=0.374897 Current lr=[0.000299720220882401]

[0/24] Train loss=0.312541127204895
[5/24] Train loss=0.3439411222934723
[10/24] Train loss=0.32761308550834656
[15/24] Train loss=0.30555418133735657
[20/24] Train loss=0.3005152642726898
Test set avg_accuracy=82.90% avg_sensitivity=48.20%, avg_specificity=94.45% avg_auc=87.79%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.338306 Test loss=0.375818 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.31583163142204285
[5/24] Train loss=0.35094213485717773
[10/24] Train loss=0.33436471223831177
[15/24] Train loss=0.3077993094921112
[20/24] Train loss=0.2987430691719055
Test set avg_accuracy=82.90% avg_sensitivity=48.51%, avg_specificity=94.34% avg_auc=87.71%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.338960 Test loss=0.376713 Current lr=[0.000298904600941902]

[0/24] Train loss=0.31189271807670593
[5/24] Train loss=0.3412967324256897
[10/24] Train loss=0.3288019895553589
[15/24] Train loss=0.307594895362854
[20/24] Train loss=0.29960137605667114
Test set avg_accuracy=82.84% avg_sensitivity=47.63%, avg_specificity=94.55% avg_auc=87.81%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.337897 Test loss=0.376851 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.31544750928878784
[5/24] Train loss=0.35202524065971375
[10/24] Train loss=0.3313450813293457
[15/24] Train loss=0.3041081130504608
[20/24] Train loss=0.2976866066455841
Test set avg_accuracy=82.71% avg_sensitivity=47.47%, avg_specificity=94.43% avg_auc=87.75%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.338769 Test loss=0.376987 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3130948543548584
[5/24] Train loss=0.34286224842071533
[10/24] Train loss=0.3291034698486328
[15/24] Train loss=0.3043608069419861
[20/24] Train loss=0.29587143659591675
Test set avg_accuracy=82.93% avg_sensitivity=48.88%, avg_specificity=94.26% avg_auc=87.82%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.336640 Test loss=0.374389 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.31110891699790955
[5/24] Train loss=0.34626469016075134
[10/24] Train loss=0.3302590250968933
[15/24] Train loss=0.31160032749176025
[20/24] Train loss=0.29870301485061646
Test set avg_accuracy=83.07% avg_sensitivity=50.18%, avg_specificity=94.01% avg_auc=87.83%
Best model saved!! Metric=-10.903320134737001!!
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.337269 Test loss=0.372901 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3090483248233795
[5/24] Train loss=0.33985745906829834
[10/24] Train loss=0.32794174551963806
[15/24] Train loss=0.30628976225852966
[20/24] Train loss=0.2942001521587372
Test set avg_accuracy=83.12% avg_sensitivity=50.13%, avg_specificity=94.10% avg_auc=87.83%
Best model saved!! Metric=-10.816347094785897!!
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.335345 Test loss=0.372984 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.31185057759284973
[5/24] Train loss=0.34604519605636597
[10/24] Train loss=0.3322572708129883
[15/24] Train loss=0.30511167645454407
[20/24] Train loss=0.2959986925125122
Test set avg_accuracy=83.02% avg_sensitivity=49.77%, avg_specificity=94.08% avg_auc=87.87%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.335300 Test loss=0.372319 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.30652493238449097
[5/24] Train loss=0.3473714292049408
[10/24] Train loss=0.32926854491233826
[15/24] Train loss=0.3042992651462555
[20/24] Train loss=0.2946007251739502
Test set avg_accuracy=82.93% avg_sensitivity=49.35%, avg_specificity=94.10% avg_auc=87.79%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.336012 Test loss=0.374829 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3110411465167999
[5/24] Train loss=0.34409263730049133
[10/24] Train loss=0.33073654770851135
[15/24] Train loss=0.2998186945915222
[20/24] Train loss=0.2933349311351776
Test set avg_accuracy=83.11% avg_sensitivity=51.59%, avg_specificity=93.60% avg_auc=87.87%
Best model saved!! Metric=-9.828826728078049!!
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.334788 Test loss=0.370650 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.31059229373931885
[5/24] Train loss=0.33673906326293945
[10/24] Train loss=0.32858067750930786
[15/24] Train loss=0.3054046928882599
[20/24] Train loss=0.293704092502594
Test set avg_accuracy=83.03% avg_sensitivity=49.97%, avg_specificity=94.03% avg_auc=87.87%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.334510 Test loss=0.372093 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3081103265285492
[5/24] Train loss=0.34011468291282654
[10/24] Train loss=0.32845625281333923
[15/24] Train loss=0.30703818798065186
[20/24] Train loss=0.2932712733745575
Test set avg_accuracy=83.19% avg_sensitivity=49.56%, avg_specificity=94.38% avg_auc=87.93%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.333525 Test loss=0.372252 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.307823121547699
[5/24] Train loss=0.34085172414779663
[10/24] Train loss=0.33126863837242126
[15/24] Train loss=0.30302709341049194
[20/24] Train loss=0.2967061400413513
Test set avg_accuracy=83.09% avg_sensitivity=48.77%, avg_specificity=94.50% avg_auc=87.98%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.334116 Test loss=0.372566 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3062158524990082
[5/24] Train loss=0.3369589149951935
[10/24] Train loss=0.3256605267524719
[15/24] Train loss=0.30321595072746277
[20/24] Train loss=0.2927868664264679
Test set avg_accuracy=83.11% avg_sensitivity=50.60%, avg_specificity=93.93% avg_auc=87.95%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.332914 Test loss=0.370541 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3069782555103302
[5/24] Train loss=0.3378088176250458
[10/24] Train loss=0.32284262776374817
[15/24] Train loss=0.3021406829357147
[20/24] Train loss=0.29084691405296326
Test set avg_accuracy=83.22% avg_sensitivity=50.70%, avg_specificity=94.03% avg_auc=87.99%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.331660 Test loss=0.369993 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3056976795196533
[5/24] Train loss=0.3383101522922516
[10/24] Train loss=0.32872357964515686
[15/24] Train loss=0.30254313349723816
[20/24] Train loss=0.29252398014068604
Test set avg_accuracy=83.15% avg_sensitivity=49.87%, avg_specificity=94.22% avg_auc=88.04%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.331856 Test loss=0.370210 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3063032627105713
[5/24] Train loss=0.3427879512310028
[10/24] Train loss=0.32295089960098267
[15/24] Train loss=0.29925304651260376
[20/24] Train loss=0.2911226749420166
Test set avg_accuracy=82.99% avg_sensitivity=49.24%, avg_specificity=94.22% avg_auc=88.00%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.331452 Test loss=0.370993 Current lr=[0.000276307469034998]

[0/24] Train loss=0.30670011043548584
[5/24] Train loss=0.34052976965904236
[10/24] Train loss=0.3284655213356018
[15/24] Train loss=0.3026561141014099
[20/24] Train loss=0.29302412271499634
Test set avg_accuracy=83.01% avg_sensitivity=49.97%, avg_specificity=94.00% avg_auc=87.98%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.331696 Test loss=0.371053 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3075410723686218
[5/24] Train loss=0.335237979888916
[10/24] Train loss=0.32638031244277954
[15/24] Train loss=0.30463385581970215
[20/24] Train loss=0.29258930683135986
Test set avg_accuracy=82.94% avg_sensitivity=49.71%, avg_specificity=94.00% avg_auc=87.92%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.331400 Test loss=0.371783 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3051201403141022
[5/24] Train loss=0.33561715483665466
[10/24] Train loss=0.32850274443626404
[15/24] Train loss=0.2976028025150299
[20/24] Train loss=0.28971895575523376
Test set avg_accuracy=82.96% avg_sensitivity=49.30%, avg_specificity=94.15% avg_auc=88.01%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.331193 Test loss=0.371010 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3058925271034241
[5/24] Train loss=0.3444182574748993
[10/24] Train loss=0.32946911454200745
[15/24] Train loss=0.30367323756217957
[20/24] Train loss=0.2906235456466675
Test set avg_accuracy=83.23% avg_sensitivity=51.75%, avg_specificity=93.70% avg_auc=88.05%
Best model saved!! Metric=-9.27500873826709!!
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.331761 Test loss=0.368152 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3003014326095581
[5/24] Train loss=0.34015437960624695
[10/24] Train loss=0.3202756941318512
[15/24] Train loss=0.30018487572669983
[20/24] Train loss=0.29234984517097473
Test set avg_accuracy=83.07% avg_sensitivity=49.66%, avg_specificity=94.19% avg_auc=88.04%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.330065 Test loss=0.370470 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.30402669310569763
[5/24] Train loss=0.33786845207214355
[10/24] Train loss=0.32789915800094604
[15/24] Train loss=0.29989275336265564
[20/24] Train loss=0.2940216660499573
Test set avg_accuracy=82.97% avg_sensitivity=48.46%, avg_specificity=94.45% avg_auc=87.98%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.329780 Test loss=0.372507 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.30524855852127075
[5/24] Train loss=0.34228456020355225
[10/24] Train loss=0.3260749578475952
[15/24] Train loss=0.2955659031867981
[20/24] Train loss=0.29376471042633057
Test set avg_accuracy=82.98% avg_sensitivity=49.19%, avg_specificity=94.22% avg_auc=88.02%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.330182 Test loss=0.370638 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3071651756763458
[5/24] Train loss=0.3381940722465515
[10/24] Train loss=0.3272886276245117
[15/24] Train loss=0.30051785707473755
[20/24] Train loss=0.29020068049430847
Test set avg_accuracy=83.02% avg_sensitivity=49.35%, avg_specificity=94.22% avg_auc=88.05%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.328937 Test loss=0.370194 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.30519118905067444
[5/24] Train loss=0.3340079188346863
[10/24] Train loss=0.32621511816978455
[15/24] Train loss=0.29566898941993713
[20/24] Train loss=0.2906768321990967
Test set avg_accuracy=83.05% avg_sensitivity=48.10%, avg_specificity=94.67% avg_auc=87.96%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.328988 Test loss=0.373160 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.30375176668167114
[5/24] Train loss=0.3423464894294739
[10/24] Train loss=0.32666444778442383
[15/24] Train loss=0.3000241816043854
[20/24] Train loss=0.2926928400993347
Test set avg_accuracy=82.86% avg_sensitivity=47.42%, avg_specificity=94.66% avg_auc=87.92%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.330555 Test loss=0.375119 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.30833497643470764
[5/24] Train loss=0.33491653203964233
[10/24] Train loss=0.32312464714050293
[15/24] Train loss=0.29508286714553833
[20/24] Train loss=0.28938746452331543
Test set avg_accuracy=82.93% avg_sensitivity=47.63%, avg_specificity=94.67% avg_auc=87.98%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.328481 Test loss=0.373348 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3066011965274811
[5/24] Train loss=0.33115801215171814
[10/24] Train loss=0.32602477073669434
[15/24] Train loss=0.29669880867004395
[20/24] Train loss=0.2917228937149048
Test set avg_accuracy=82.73% avg_sensitivity=46.32%, avg_specificity=94.85% avg_auc=87.90%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.329406 Test loss=0.375651 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.30734410881996155
[5/24] Train loss=0.3238702416419983
[10/24] Train loss=0.32732316851615906
[15/24] Train loss=0.29962435364723206
[20/24] Train loss=0.2887120842933655
Test set avg_accuracy=82.90% avg_sensitivity=47.37%, avg_specificity=94.72% avg_auc=87.99%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.327711 Test loss=0.372593 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3063339293003082
[5/24] Train loss=0.326447993516922
[10/24] Train loss=0.33139148354530334
[15/24] Train loss=0.2997601330280304
[20/24] Train loss=0.28931817412376404
Test set avg_accuracy=82.79% avg_sensitivity=47.84%, avg_specificity=94.41% avg_auc=87.95%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.329072 Test loss=0.372783 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3067488968372345
[5/24] Train loss=0.32895031571388245
[10/24] Train loss=0.32233068346977234
[15/24] Train loss=0.3012259304523468
[20/24] Train loss=0.29035723209381104
Test set avg_accuracy=82.79% avg_sensitivity=47.94%, avg_specificity=94.38% avg_auc=87.98%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.328444 Test loss=0.372097 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3042536973953247
[5/24] Train loss=0.3266814351081848
[10/24] Train loss=0.3260388970375061
[15/24] Train loss=0.3004952371120453
[20/24] Train loss=0.28644290566444397
Test set avg_accuracy=82.84% avg_sensitivity=47.47%, avg_specificity=94.60% avg_auc=87.97%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.328540 Test loss=0.372607 Current lr=[0.000224838296036774]

[0/24] Train loss=0.30564138293266296
[5/24] Train loss=0.3227713108062744
[10/24] Train loss=0.3236120939254761
[15/24] Train loss=0.2999347746372223
[20/24] Train loss=0.28773003816604614
Test set avg_accuracy=83.05% avg_sensitivity=50.50%, avg_specificity=93.87% avg_auc=87.94%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.328010 Test loss=0.370239 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3034552335739136
[5/24] Train loss=0.32087236642837524
[10/24] Train loss=0.3297223150730133
[15/24] Train loss=0.2971881031990051
[20/24] Train loss=0.2879491448402405
Test set avg_accuracy=82.98% avg_sensitivity=49.40%, avg_specificity=94.15% avg_auc=87.99%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.327568 Test loss=0.370018 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.30623680353164673
[5/24] Train loss=0.32457563281059265
[10/24] Train loss=0.32665857672691345
[15/24] Train loss=0.29841482639312744
[20/24] Train loss=0.28767865896224976
Test set avg_accuracy=82.94% avg_sensitivity=49.97%, avg_specificity=93.91% avg_auc=88.06%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.328081 Test loss=0.368680 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.30093851685523987
[5/24] Train loss=0.33053290843963623
[10/24] Train loss=0.32422345876693726
[15/24] Train loss=0.29891589283943176
[20/24] Train loss=0.28935110569000244
Test set avg_accuracy=83.05% avg_sensitivity=49.40%, avg_specificity=94.24% avg_auc=87.95%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.327635 Test loss=0.370584 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.30814775824546814
[5/24] Train loss=0.3249097168445587
[10/24] Train loss=0.3280966579914093
[15/24] Train loss=0.300209105014801
[20/24] Train loss=0.2927074134349823
Test set avg_accuracy=83.22% avg_sensitivity=51.38%, avg_specificity=93.81% avg_auc=87.99%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.328577 Test loss=0.367753 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2992963492870331
[5/24] Train loss=0.3186539113521576
[10/24] Train loss=0.3260939419269562
[15/24] Train loss=0.29972365498542786
[20/24] Train loss=0.2859767973423004
Test set avg_accuracy=83.06% avg_sensitivity=49.87%, avg_specificity=94.10% avg_auc=87.86%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.326266 Test loss=0.371228 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.30201485753059387
[5/24] Train loss=0.32215243577957153
[10/24] Train loss=0.3272847533226013
[15/24] Train loss=0.29404598474502563
[20/24] Train loss=0.2865632176399231
Test set avg_accuracy=83.09% avg_sensitivity=49.71%, avg_specificity=94.19% avg_auc=88.02%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.325308 Test loss=0.369341 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.30093854665756226
[5/24] Train loss=0.3251590132713318
[10/24] Train loss=0.3257370889186859
[15/24] Train loss=0.2988796532154083
[20/24] Train loss=0.2871776223182678
Test set avg_accuracy=83.09% avg_sensitivity=50.08%, avg_specificity=94.07% avg_auc=87.93%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.326964 Test loss=0.370251 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.30044907331466675
[5/24] Train loss=0.3182842433452606
[10/24] Train loss=0.3224508762359619
[15/24] Train loss=0.2968885004520416
[20/24] Train loss=0.2880643904209137
Test set avg_accuracy=82.94% avg_sensitivity=49.61%, avg_specificity=94.03% avg_auc=87.87%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.326169 Test loss=0.371223 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2989121973514557
[5/24] Train loss=0.32084497809410095
[10/24] Train loss=0.3251807689666748
[15/24] Train loss=0.29446837306022644
[20/24] Train loss=0.2895614206790924
Test set avg_accuracy=83.12% avg_sensitivity=50.39%, avg_specificity=94.01% avg_auc=87.87%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.325637 Test loss=0.371386 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.30383989214897156
[5/24] Train loss=0.32256999611854553
[10/24] Train loss=0.3238694965839386
[15/24] Train loss=0.297839879989624
[20/24] Train loss=0.28520333766937256
Test set avg_accuracy=83.24% avg_sensitivity=50.39%, avg_specificity=94.17% avg_auc=87.94%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.325753 Test loss=0.371613 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3006231486797333
[5/24] Train loss=0.3191791772842407
[10/24] Train loss=0.32684776186943054
[15/24] Train loss=0.2991759777069092
[20/24] Train loss=0.2862863838672638
Test set avg_accuracy=83.02% avg_sensitivity=48.93%, avg_specificity=94.36% avg_auc=87.83%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.326163 Test loss=0.373941 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3032849133014679
[5/24] Train loss=0.3159080743789673
[10/24] Train loss=0.3232511878013611
[15/24] Train loss=0.29831990599632263
[20/24] Train loss=0.2860370874404907
Test set avg_accuracy=83.02% avg_sensitivity=48.93%, avg_specificity=94.36% avg_auc=87.78%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.326054 Test loss=0.375734 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.30244365334510803
[5/24] Train loss=0.31624358892440796
[10/24] Train loss=0.319926917552948
[15/24] Train loss=0.2975477874279022
[20/24] Train loss=0.29197245836257935
Test set avg_accuracy=83.28% avg_sensitivity=51.75%, avg_specificity=93.77% avg_auc=87.86%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.327486 Test loss=0.371349 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.29782572388648987
[5/24] Train loss=0.31954672932624817
[10/24] Train loss=0.3259122371673584
[15/24] Train loss=0.2990659773349762
[20/24] Train loss=0.2830166816711426
Test set avg_accuracy=83.75% avg_sensitivity=58.79%, avg_specificity=92.05% avg_auc=88.08%
Best model saved!! Metric=-3.326402438124724!!
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.329211 Test loss=0.363796 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2991887629032135
[5/24] Train loss=0.31374087929725647
[10/24] Train loss=0.3232535421848297
[15/24] Train loss=0.3018183410167694
[20/24] Train loss=0.2812550961971283
Test set avg_accuracy=83.88% avg_sensitivity=60.35%, avg_specificity=91.71% avg_auc=88.13%
Best model saved!! Metric=-1.925718182762246!!
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.327144 Test loss=0.363338 Current lr=[0.000156543481933168]

[0/24] Train loss=0.29226094484329224
[5/24] Train loss=0.31962648034095764
[10/24] Train loss=0.32015374302864075
[15/24] Train loss=0.2966788113117218
[20/24] Train loss=0.282768577337265
Test set avg_accuracy=83.66% avg_sensitivity=59.42%, avg_specificity=91.72% avg_auc=88.14%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.324288 Test loss=0.362925 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.29423511028289795
[5/24] Train loss=0.3171851336956024
[10/24] Train loss=0.3203941285610199
[15/24] Train loss=0.29003456234931946
[20/24] Train loss=0.2825782597064972
Test set avg_accuracy=83.91% avg_sensitivity=60.20%, avg_specificity=91.79% avg_auc=88.18%
Best model saved!! Metric=-1.9208529251323654!!
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.323564 Test loss=0.362547 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.28905627131462097
[5/24] Train loss=0.3159100413322449
[10/24] Train loss=0.3202268183231354
[15/24] Train loss=0.29407981038093567
[20/24] Train loss=0.2811303734779358
Test set avg_accuracy=83.79% avg_sensitivity=59.52%, avg_specificity=91.86% avg_auc=88.18%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.323728 Test loss=0.362560 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.2930866777896881
[5/24] Train loss=0.31895142793655396
[10/24] Train loss=0.3223123848438263
[15/24] Train loss=0.2993772625923157
[20/24] Train loss=0.27996930480003357
Test set avg_accuracy=83.82% avg_sensitivity=59.99%, avg_specificity=91.74% avg_auc=88.21%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.323985 Test loss=0.362125 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.2881492078304291
[5/24] Train loss=0.3156990706920624
[10/24] Train loss=0.320884644985199
[15/24] Train loss=0.3002487123012543
[20/24] Train loss=0.2861866056919098
Test set avg_accuracy=83.66% avg_sensitivity=59.99%, avg_specificity=91.53% avg_auc=88.18%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.324201 Test loss=0.362195 Current lr=[0.000134135431043539]

[0/24] Train loss=0.29480910301208496
[5/24] Train loss=0.3186728358268738
[10/24] Train loss=0.3244471848011017
[15/24] Train loss=0.2982674539089203
[20/24] Train loss=0.28347405791282654
Test set avg_accuracy=83.40% avg_sensitivity=58.69%, avg_specificity=91.62% avg_auc=88.10%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.324260 Test loss=0.363368 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.29035454988479614
[5/24] Train loss=0.3147495985031128
[10/24] Train loss=0.32081928849220276
[15/24] Train loss=0.2931000590324402
[20/24] Train loss=0.28255122900009155
Test set avg_accuracy=83.48% avg_sensitivity=59.57%, avg_specificity=91.43% avg_auc=88.14%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.322515 Test loss=0.362842 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2944827973842621
[5/24] Train loss=0.32109105587005615
[10/24] Train loss=0.3232390880584717
[15/24] Train loss=0.2964707911014557
[20/24] Train loss=0.28484025597572327
Test set avg_accuracy=83.50% avg_sensitivity=59.73%, avg_specificity=91.41% avg_auc=88.13%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.323020 Test loss=0.363251 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.29230621457099915
[5/24] Train loss=0.3176352381706238
[10/24] Train loss=0.32555559277534485
[15/24] Train loss=0.29930180311203003
[20/24] Train loss=0.28359517455101013
Test set avg_accuracy=83.75% avg_sensitivity=60.30%, avg_specificity=91.55% avg_auc=88.19%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.323086 Test loss=0.362091 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.29338839650154114
[5/24] Train loss=0.31540438532829285
[10/24] Train loss=0.3165960907936096
[15/24] Train loss=0.2950284481048584
[20/24] Train loss=0.28401097655296326
Test set avg_accuracy=83.85% avg_sensitivity=61.82%, avg_specificity=91.19% avg_auc=88.25%
Best model saved!! Metric=-0.8950574910766207!!
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.322569 Test loss=0.361428 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.29193758964538574
[5/24] Train loss=0.32001662254333496
[10/24] Train loss=0.3271154463291168
[15/24] Train loss=0.29637402296066284
[20/24] Train loss=0.27965760231018066
Test set avg_accuracy=83.83% avg_sensitivity=63.59%, avg_specificity=90.56% avg_auc=88.26%
Best model saved!! Metric=0.23941693655386587!!
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.324637 Test loss=0.362060 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.2959860563278198
[5/24] Train loss=0.32589343190193176
[10/24] Train loss=0.33568528294563293
[15/24] Train loss=0.3006049692630768
[20/24] Train loss=0.28249263763427734
Test set avg_accuracy=83.57% avg_sensitivity=68.60%, avg_specificity=88.55% avg_auc=88.18%
Best model saved!! Metric=2.8905732158954436!!
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.327634 Test loss=0.369458 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.30372336506843567
[5/24] Train loss=0.3509177565574646
[10/24] Train loss=0.34036654233932495
[15/24] Train loss=0.29726508259773254
[20/24] Train loss=0.2831946313381195
Test set avg_accuracy=82.92% avg_sensitivity=72.87%, avg_specificity=86.26% avg_auc=87.98%
Best model saved!! Metric=4.0290761509824335!!
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.331317 Test loss=0.384457 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.32817342877388
[5/24] Train loss=0.34020623564720154
[10/24] Train loss=0.3212786018848419
[15/24] Train loss=0.308978796005249
[20/24] Train loss=0.30408281087875366
Test set avg_accuracy=83.67% avg_sensitivity=67.40%, avg_specificity=89.09% avg_auc=88.17%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.331364 Test loss=0.367704 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.30109068751335144
[5/24] Train loss=0.31571465730667114
[10/24] Train loss=0.32660946249961853
[15/24] Train loss=0.30943620204925537
[20/24] Train loss=0.2941998839378357
Test set avg_accuracy=83.70% avg_sensitivity=63.85%, avg_specificity=90.30% avg_auc=88.21%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.324626 Test loss=0.362973 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2979282736778259
[5/24] Train loss=0.32156902551651
[10/24] Train loss=0.32387590408325195
[15/24] Train loss=0.2997440993785858
[20/24] Train loss=0.28945818543434143
Test set avg_accuracy=83.79% avg_sensitivity=66.09%, avg_specificity=89.68% avg_auc=88.24%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.323194 Test loss=0.364695 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.29617011547088623
[5/24] Train loss=0.32393762469291687
[10/24] Train loss=0.3229241967201233
[15/24] Train loss=0.30376964807510376
[20/24] Train loss=0.2885988652706146
Test set avg_accuracy=83.71% avg_sensitivity=65.83%, avg_specificity=89.66% avg_auc=88.21%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.324180 Test loss=0.365251 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.29925867915153503
[5/24] Train loss=0.32381319999694824
[10/24] Train loss=0.3219887912273407
[15/24] Train loss=0.3036820888519287
[20/24] Train loss=0.29378119111061096
Test set avg_accuracy=83.63% avg_sensitivity=64.95%, avg_specificity=89.85% avg_auc=88.20%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.324611 Test loss=0.364426 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.300000935792923
[5/24] Train loss=0.32005152106285095
[10/24] Train loss=0.32230669260025024
[15/24] Train loss=0.30369341373443604
[20/24] Train loss=0.28948888182640076
Test set avg_accuracy=83.62% avg_sensitivity=64.89%, avg_specificity=89.85% avg_auc=88.16%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.323429 Test loss=0.365287 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.30197402834892273
[5/24] Train loss=0.32256457209587097
[10/24] Train loss=0.3177228271961212
[15/24] Train loss=0.30108731985092163
[20/24] Train loss=0.2913489043712616
Test set avg_accuracy=83.55% avg_sensitivity=64.68%, avg_specificity=89.83% avg_auc=88.11%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.322816 Test loss=0.365931 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3021508753299713
[5/24] Train loss=0.3158986568450928
[10/24] Train loss=0.32175955176353455
[15/24] Train loss=0.30244988203048706
[20/24] Train loss=0.28839927911758423
Test set avg_accuracy=83.76% avg_sensitivity=64.42%, avg_specificity=90.20% avg_auc=88.21%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.321253 Test loss=0.363683 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.30076512694358826
[5/24] Train loss=0.3156081438064575
[10/24] Train loss=0.3202401399612427
[15/24] Train loss=0.3041303753852844
[20/24] Train loss=0.2932344675064087
Test set avg_accuracy=83.84% avg_sensitivity=64.16%, avg_specificity=90.39% avg_auc=88.30%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.321186 Test loss=0.361773 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.29656291007995605
[5/24] Train loss=0.31342729926109314
[10/24] Train loss=0.3218592405319214
[15/24] Train loss=0.30441945791244507
[20/24] Train loss=0.2921624481678009
Test set avg_accuracy=83.91% avg_sensitivity=64.11%, avg_specificity=90.49% avg_auc=88.34%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.320766 Test loss=0.361161 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.29262062907218933
[5/24] Train loss=0.3157356381416321
[10/24] Train loss=0.3176158666610718
[15/24] Train loss=0.3022274672985077
[20/24] Train loss=0.2871209681034088
Test set avg_accuracy=84.02% avg_sensitivity=63.48%, avg_specificity=90.86% avg_auc=88.34%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.320003 Test loss=0.360597 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.29522305727005005
[5/24] Train loss=0.3158954679965973
[10/24] Train loss=0.3215111196041107
[15/24] Train loss=0.30092233419418335
[20/24] Train loss=0.28827738761901855
Test set avg_accuracy=84.02% avg_sensitivity=63.22%, avg_specificity=90.94% avg_auc=88.35%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.319733 Test loss=0.360284 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.29104432463645935
[5/24] Train loss=0.31478121876716614
[10/24] Train loss=0.321643203496933
[15/24] Train loss=0.3021191358566284
[20/24] Train loss=0.2816096246242523
Test set avg_accuracy=84.02% avg_sensitivity=62.81%, avg_specificity=91.08% avg_auc=88.33%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.318595 Test loss=0.360261 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.2941227853298187
[5/24] Train loss=0.3118560314178467
[10/24] Train loss=0.31814825534820557
[15/24] Train loss=0.2953636944293976
[20/24] Train loss=0.28463566303253174
Test set avg_accuracy=84.01% avg_sensitivity=62.91%, avg_specificity=91.03% avg_auc=88.34%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.318578 Test loss=0.360337 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.28970471024513245
[5/24] Train loss=0.31347745656967163
[10/24] Train loss=0.32000023126602173
[15/24] Train loss=0.29952800273895264
[20/24] Train loss=0.28516727685928345
Test set avg_accuracy=84.01% avg_sensitivity=62.60%, avg_specificity=91.13% avg_auc=88.37%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.318842 Test loss=0.359679 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.2922210097312927
[5/24] Train loss=0.3179174065589905
[10/24] Train loss=0.3189123570919037
[15/24] Train loss=0.30085158348083496
[20/24] Train loss=0.28255119919776917
Test set avg_accuracy=84.05% avg_sensitivity=62.65%, avg_specificity=91.17% avg_auc=88.36%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.317247 Test loss=0.360009 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.29163751006126404
[5/24] Train loss=0.31631186604499817
[10/24] Train loss=0.3223605453968048
[15/24] Train loss=0.2978378236293793
[20/24] Train loss=0.2846957743167877
Test set avg_accuracy=84.10% avg_sensitivity=62.49%, avg_specificity=91.29% avg_auc=88.37%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.318340 Test loss=0.359622 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.29172906279563904
[5/24] Train loss=0.3101308345794678
[10/24] Train loss=0.3181404769420624
[15/24] Train loss=0.29983144998550415
[20/24] Train loss=0.28214263916015625
Test set avg_accuracy=84.10% avg_sensitivity=62.39%, avg_specificity=91.32% avg_auc=88.37%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.317299 Test loss=0.359657 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.2910648584365845
[5/24] Train loss=0.315071165561676
[10/24] Train loss=0.32015740871429443
[15/24] Train loss=0.299108624458313
[20/24] Train loss=0.28334397077560425
Test set avg_accuracy=84.08% avg_sensitivity=62.60%, avg_specificity=91.22% avg_auc=88.37%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.316893 Test loss=0.359690 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.2924994230270386
[5/24] Train loss=0.3152540922164917
[10/24] Train loss=0.32090842723846436
[15/24] Train loss=0.3017083704471588
[20/24] Train loss=0.2801592946052551
Test set avg_accuracy=84.06% avg_sensitivity=62.08%, avg_specificity=91.38% avg_auc=88.38%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.317097 Test loss=0.359489 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.29065054655075073
[5/24] Train loss=0.3163025975227356
[10/24] Train loss=0.31904423236846924
[15/24] Train loss=0.3043071925640106
[20/24] Train loss=0.28053879737854004
Test set avg_accuracy=84.05% avg_sensitivity=62.70%, avg_specificity=91.15% avg_auc=88.38%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.317563 Test loss=0.359613 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.2911488115787506
[5/24] Train loss=0.31847289204597473
[10/24] Train loss=0.3172655999660492
[15/24] Train loss=0.299966037273407
[20/24] Train loss=0.27928873896598816
Test set avg_accuracy=84.02% avg_sensitivity=62.96%, avg_specificity=91.03% avg_auc=88.39%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.317811 Test loss=0.359693 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.2924457788467407
[5/24] Train loss=0.31751951575279236
[10/24] Train loss=0.3187779188156128
[15/24] Train loss=0.2984483242034912
[20/24] Train loss=0.2790040969848633
Test set avg_accuracy=83.98% avg_sensitivity=63.69%, avg_specificity=90.73% avg_auc=88.39%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.317695 Test loss=0.360228 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.2921757400035858
[5/24] Train loss=0.3118043541908264
[10/24] Train loss=0.31968042254447937
[15/24] Train loss=0.29616090655326843
[20/24] Train loss=0.2807766795158386
Test set avg_accuracy=83.95% avg_sensitivity=64.53%, avg_specificity=90.40% avg_auc=88.38%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.316378 Test loss=0.361075 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.2947239279747009
[5/24] Train loss=0.3091042935848236
[10/24] Train loss=0.3198608458042145
[15/24] Train loss=0.2976340055465698
[20/24] Train loss=0.27792784571647644
Test set avg_accuracy=83.91% avg_sensitivity=65.05%, avg_specificity=90.18% avg_auc=88.38%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.317145 Test loss=0.361507 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.29610851407051086
[5/24] Train loss=0.3080974221229553
[10/24] Train loss=0.31833702325820923
[15/24] Train loss=0.29576194286346436
[20/24] Train loss=0.27965831756591797
Test set avg_accuracy=83.87% avg_sensitivity=64.11%, avg_specificity=90.44% avg_auc=88.36%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.316607 Test loss=0.360964 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.2895618975162506
[5/24] Train loss=0.3109351694583893
[10/24] Train loss=0.31654974818229675
[15/24] Train loss=0.2960541546344757
[20/24] Train loss=0.2762088179588318
Test set avg_accuracy=83.89% avg_sensitivity=64.06%, avg_specificity=90.49% avg_auc=88.36%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.316009 Test loss=0.360901 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.2900638282299042
[5/24] Train loss=0.307166188955307
[10/24] Train loss=0.31754329800605774
[15/24] Train loss=0.2979872524738312
[20/24] Train loss=0.2819273769855499
Test set avg_accuracy=83.96% avg_sensitivity=63.59%, avg_specificity=90.73% avg_auc=88.37%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.315915 Test loss=0.360366 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.28625762462615967
[5/24] Train loss=0.30977994203567505
[10/24] Train loss=0.31701409816741943
[15/24] Train loss=0.29715120792388916
[20/24] Train loss=0.28376615047454834
Test set avg_accuracy=83.98% avg_sensitivity=63.48%, avg_specificity=90.80% avg_auc=88.39%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.315302 Test loss=0.359953 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.29101434350013733
[5/24] Train loss=0.3092707395553589
[10/24] Train loss=0.3168785870075226
[15/24] Train loss=0.29108545184135437
[20/24] Train loss=0.2780885100364685
Test set avg_accuracy=84.00% avg_sensitivity=63.33%, avg_specificity=90.87% avg_auc=88.39%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.315363 Test loss=0.359778 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.2924343943595886
[5/24] Train loss=0.3100147545337677
[10/24] Train loss=0.32182008028030396
[15/24] Train loss=0.2939874231815338
[20/24] Train loss=0.2801811695098877
Test set avg_accuracy=83.95% avg_sensitivity=63.02%, avg_specificity=90.91% avg_auc=88.39%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.315508 Test loss=0.359682 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.2901155650615692
[5/24] Train loss=0.30405256152153015
[10/24] Train loss=0.3169543147087097
[15/24] Train loss=0.2940264046192169
[20/24] Train loss=0.28065815567970276
Test set avg_accuracy=83.97% avg_sensitivity=63.17%, avg_specificity=90.89% avg_auc=88.39%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.314965 Test loss=0.359697 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.2900944650173187
[5/24] Train loss=0.3104254901409149
[10/24] Train loss=0.3164192736148834
[15/24] Train loss=0.2942279279232025
[20/24] Train loss=0.28122514486312866
Test set avg_accuracy=84.00% avg_sensitivity=62.86%, avg_specificity=91.03% avg_auc=88.39%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.315500 Test loss=0.359517 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.2900755703449249
[5/24] Train loss=0.30663198232650757
[10/24] Train loss=0.3146885633468628
[15/24] Train loss=0.2949405908584595
[20/24] Train loss=0.27956780791282654
Test set avg_accuracy=84.00% avg_sensitivity=62.96%, avg_specificity=90.99% avg_auc=88.39%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.314542 Test loss=0.359537 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.2916083037853241
[5/24] Train loss=0.30882424116134644
[10/24] Train loss=0.315836638212204
[15/24] Train loss=0.2939034402370453
[20/24] Train loss=0.27852118015289307
Test set avg_accuracy=83.98% avg_sensitivity=62.96%, avg_specificity=90.98% avg_auc=88.40%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.315531 Test loss=0.359498 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.29114705324172974
[5/24] Train loss=0.3090835511684418
[10/24] Train loss=0.31426337361335754
[15/24] Train loss=0.29105326533317566
[20/24] Train loss=0.28079095482826233
Test set avg_accuracy=83.97% avg_sensitivity=62.86%, avg_specificity=90.99% avg_auc=88.40%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.313947 Test loss=0.359486 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.2909555733203888
[5/24] Train loss=0.31347280740737915
[10/24] Train loss=0.32136502861976624
[15/24] Train loss=0.29715418815612793
[20/24] Train loss=0.27931085228919983
Test set avg_accuracy=84.04% avg_sensitivity=62.75%, avg_specificity=91.12% avg_auc=88.40%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.316458 Test loss=0.359419 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.2865579128265381
[5/24] Train loss=0.31030547618865967
[10/24] Train loss=0.3155384957790375
[15/24] Train loss=0.2922137677669525
[20/24] Train loss=0.2806692123413086
Test set avg_accuracy=84.01% avg_sensitivity=62.70%, avg_specificity=91.10% avg_auc=88.40%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.315158 Test loss=0.359386 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.2941588759422302
[5/24] Train loss=0.3099575340747833
[10/24] Train loss=0.3181363642215729
[15/24] Train loss=0.2950562834739685
[20/24] Train loss=0.28160667419433594
Test set avg_accuracy=84.01% avg_sensitivity=62.70%, avg_specificity=91.10% avg_auc=88.40%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.315530 Test loss=0.359386 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.2924012541770935
[5/24] Train loss=0.31194961071014404
[10/24] Train loss=0.31586378812789917
[15/24] Train loss=0.2936038374900818
[20/24] Train loss=0.2781899869441986
Test set avg_accuracy=84.01% avg_sensitivity=62.70%, avg_specificity=91.10% avg_auc=88.40%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.315354 Test loss=0.359388 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.28844043612480164
[5/24] Train loss=0.31020456552505493
[10/24] Train loss=0.3155738115310669
[15/24] Train loss=0.2957637310028076
[20/24] Train loss=0.27892208099365234
Test set avg_accuracy=84.01% avg_sensitivity=62.70%, avg_specificity=91.10% avg_auc=88.40%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.314812 Test loss=0.359386 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=82.92% sen=72.87%, spe=86.26%, auc=87.98%!
Fold[2] Avg_overlap=0.65%(±0.2436515069224336)
[0/24] Train loss=0.8043196797370911
[5/24] Train loss=0.6907939910888672
[10/24] Train loss=0.674929678440094
[15/24] Train loss=0.6388824582099915
[20/24] Train loss=0.6346140503883362
Test set avg_accuracy=72.41% avg_sensitivity=0.47%, avg_specificity=99.66% avg_auc=51.59%
Best model saved!! Metric=-101.86721005687345!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.662420 Test loss=0.595060 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6086819171905518
[5/24] Train loss=0.5849654674530029
[10/24] Train loss=0.6371780037879944
[15/24] Train loss=0.6154910326004028
[20/24] Train loss=0.6145612597465515
Test set avg_accuracy=72.41% avg_sensitivity=0.09%, avg_specificity=99.80% avg_auc=56.73%
Best model saved!! Metric=-96.96767633270794!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.595801 Test loss=0.582786 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.5967794060707092
[5/24] Train loss=0.5646151304244995
[10/24] Train loss=0.6302570104598999
[15/24] Train loss=0.6080483198165894
[20/24] Train loss=0.600318431854248
Test set avg_accuracy=72.42% avg_sensitivity=0.28%, avg_specificity=99.75% avg_auc=60.43%
Best model saved!! Metric=-93.11466979396224!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.587114 Test loss=0.576290 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.5890364050865173
[5/24] Train loss=0.5628468990325928
[10/24] Train loss=0.6235417723655701
[15/24] Train loss=0.5921186208724976
[20/24] Train loss=0.5921709537506104
Test set avg_accuracy=72.38% avg_sensitivity=0.28%, avg_specificity=99.69% avg_auc=64.80%
Best model saved!! Metric=-88.84159125403099!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.579448 Test loss=0.568910 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5758084058761597
[5/24] Train loss=0.5545562505722046
[10/24] Train loss=0.6125285029411316
[15/24] Train loss=0.5837022066116333
[20/24] Train loss=0.580237090587616
Test set avg_accuracy=72.40% avg_sensitivity=0.66%, avg_specificity=99.57% avg_auc=68.34%
Best model saved!! Metric=-85.03186838627151!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.570793 Test loss=0.561465 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5653676390647888
[5/24] Train loss=0.544414758682251
[10/24] Train loss=0.602973997592926
[15/24] Train loss=0.5766183733940125
[20/24] Train loss=0.5750387907028198
Test set avg_accuracy=72.50% avg_sensitivity=1.18%, avg_specificity=99.52% avg_auc=72.10%
Best model saved!! Metric=-80.69696325099763!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.562662 Test loss=0.553861 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5597348809242249
[5/24] Train loss=0.539174497127533
[10/24] Train loss=0.6001706123352051
[15/24] Train loss=0.5659803152084351
[20/24] Train loss=0.5636470317840576
Test set avg_accuracy=72.46% avg_sensitivity=1.33%, avg_specificity=99.41% avg_auc=75.56%
Best model saved!! Metric=-77.24076083314897!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.553176 Test loss=0.545110 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5441875457763672
[5/24] Train loss=0.5273474454879761
[10/24] Train loss=0.5835856199264526
[15/24] Train loss=0.5540668368339539
[20/24] Train loss=0.5487323999404907
Test set avg_accuracy=72.49% avg_sensitivity=2.13%, avg_specificity=99.14% avg_auc=77.99%
Best model saved!! Metric=-74.2557863255181!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.544317 Test loss=0.534869 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5425189137458801
[5/24] Train loss=0.5181775093078613
[10/24] Train loss=0.5726357698440552
[15/24] Train loss=0.5420447587966919
[20/24] Train loss=0.547822892665863
Test set avg_accuracy=72.41% avg_sensitivity=2.89%, avg_specificity=98.74% avg_auc=80.14%
Best model saved!! Metric=-71.81846806567142!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.534852 Test loss=0.523017 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5219705700874329
[5/24] Train loss=0.5057845115661621
[10/24] Train loss=0.569985568523407
[15/24] Train loss=0.5333706140518188
[20/24] Train loss=0.5233465433120728
Test set avg_accuracy=72.53% avg_sensitivity=4.83%, avg_specificity=98.17% avg_auc=81.86%
Best model saved!! Metric=-68.61060778409784!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.523137 Test loss=0.509437 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5084273815155029
[5/24] Train loss=0.49692752957344055
[10/24] Train loss=0.5559608936309814
[15/24] Train loss=0.522548258304596
[20/24] Train loss=0.5022210478782654
Test set avg_accuracy=72.85% avg_sensitivity=7.82%, avg_specificity=97.49% avg_auc=83.38%
Best model saved!! Metric=-64.45920013326725!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.508135 Test loss=0.492331 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4967692196369171
[5/24] Train loss=0.48028528690338135
[10/24] Train loss=0.5392072796821594
[15/24] Train loss=0.4981710612773895
[20/24] Train loss=0.49314144253730774
Test set avg_accuracy=73.57% avg_sensitivity=12.70%, avg_specificity=96.62% avg_auc=84.43%
Best model saved!! Metric=-58.67366598916276!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.493826 Test loss=0.475404 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4777520000934601
[5/24] Train loss=0.46724075078964233
[10/24] Train loss=0.5189554691314697
[15/24] Train loss=0.48694780468940735
[20/24] Train loss=0.4739874005317688
Test set avg_accuracy=75.21% avg_sensitivity=22.09%, avg_specificity=95.33% avg_auc=85.24%
Best model saved!! Metric=-48.13251174907326!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.478750 Test loss=0.458048 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.457688570022583
[5/24] Train loss=0.45412302017211914
[10/24] Train loss=0.5125981569290161
[15/24] Train loss=0.4629552364349365
[20/24] Train loss=0.45660364627838135
Test set avg_accuracy=77.86% avg_sensitivity=35.73%, avg_specificity=93.82% avg_auc=86.01%
Best model saved!! Metric=-32.5654370024193!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.463637 Test loss=0.441290 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.45507127046585083
[5/24] Train loss=0.4299603998661041
[10/24] Train loss=0.4967533349990845
[15/24] Train loss=0.46704337000846863
[20/24] Train loss=0.4383765757083893
Test set avg_accuracy=79.26% avg_sensitivity=42.84%, avg_specificity=93.05% avg_auc=86.46%
Best model saved!! Metric=-24.382950899048737!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.452375 Test loss=0.429587 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.43919500708580017
[5/24] Train loss=0.4276033043861389
[10/24] Train loss=0.4827736020088196
[15/24] Train loss=0.4429856836795807
[20/24] Train loss=0.42809316515922546
Test set avg_accuracy=80.64% avg_sensitivity=52.80%, avg_specificity=91.18% avg_auc=86.93%
Best model saved!! Metric=-14.447236171440025!!
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.441469 Test loss=0.421057 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4323519468307495
[5/24] Train loss=0.42927783727645874
[10/24] Train loss=0.4719517230987549
[15/24] Train loss=0.4473790228366852
[20/24] Train loss=0.41653698682785034
Test set avg_accuracy=81.09% avg_sensitivity=56.59%, avg_specificity=90.38% avg_auc=87.21%
Best model saved!! Metric=-10.73085200634749!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.433736 Test loss=0.413800 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4254646301269531
[5/24] Train loss=0.4287455379962921
[10/24] Train loss=0.4667890667915344
[15/24] Train loss=0.4438527524471283
[20/24] Train loss=0.4101570248603821
Test set avg_accuracy=81.72% avg_sensitivity=61.85%, avg_specificity=89.25% avg_auc=87.72%
Best model saved!! Metric=-5.468007085605869!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.428260 Test loss=0.408058 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4212673306465149
[5/24] Train loss=0.4323703944683075
[10/24] Train loss=0.45902177691459656
[15/24] Train loss=0.4399339258670807
[20/24] Train loss=0.39789602160453796
Test set avg_accuracy=82.21% avg_sensitivity=62.23%, avg_specificity=89.78% avg_auc=88.06%
Best model saved!! Metric=-3.7104332497355017!!
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.421924 Test loss=0.398824 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4050605297088623
[5/24] Train loss=0.421073317527771
[10/24] Train loss=0.4517424404621124
[15/24] Train loss=0.441699743270874
[20/24] Train loss=0.3879968225955963
Test set avg_accuracy=82.36% avg_sensitivity=60.66%, avg_specificity=90.57% avg_auc=88.39%
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.411815 Test loss=0.389744 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.39373457431793213
[5/24] Train loss=0.4027349054813385
[10/24] Train loss=0.4415789544582367
[15/24] Train loss=0.4361640512943268
[20/24] Train loss=0.38055428862571716
Test set avg_accuracy=82.27% avg_sensitivity=53.55%, avg_specificity=93.14% avg_auc=88.59%
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.402811 Test loss=0.383272 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3823557496070862
[5/24] Train loss=0.39194127917289734
[10/24] Train loss=0.4243197441101074
[15/24] Train loss=0.4135851562023163
[20/24] Train loss=0.3703148066997528
Test set avg_accuracy=82.12% avg_sensitivity=52.18%, avg_specificity=93.46% avg_auc=88.76%
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.392910 Test loss=0.379969 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.37079113721847534
[5/24] Train loss=0.37935343384742737
[10/24] Train loss=0.4262606203556061
[15/24] Train loss=0.3983812630176544
[20/24] Train loss=0.3628731071949005
Test set avg_accuracy=83.07% avg_sensitivity=58.44%, avg_specificity=92.41% avg_auc=89.13%
Best model saved!! Metric=-2.952873151843143!!
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.385669 Test loss=0.373124 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.363996297121048
[5/24] Train loss=0.3776935040950775
[10/24] Train loss=0.4200453460216522
[15/24] Train loss=0.39792850613594055
[20/24] Train loss=0.3632047772407532
Test set avg_accuracy=83.16% avg_sensitivity=59.48%, avg_specificity=92.14% avg_auc=89.51%
Best model saved!! Metric=-1.706996916134166!!
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.381853 Test loss=0.367374 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3628685772418976
[5/24] Train loss=0.3685644865036011
[10/24] Train loss=0.4142214059829712
[15/24] Train loss=0.38190189003944397
[20/24] Train loss=0.35516002774238586
Test set avg_accuracy=83.49% avg_sensitivity=56.26%, avg_specificity=93.81% avg_auc=89.70%
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.374487 Test loss=0.364353 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.34679070115089417
[5/24] Train loss=0.36777135729789734
[10/24] Train loss=0.4096940755844116
[15/24] Train loss=0.39272087812423706
[20/24] Train loss=0.34520018100738525
Test set avg_accuracy=83.10% avg_sensitivity=53.27%, avg_specificity=94.40% avg_auc=89.82%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.370632 Test loss=0.365207 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.34490180015563965
[5/24] Train loss=0.3593076169490814
[10/24] Train loss=0.40121230483055115
[15/24] Train loss=0.3979654610157013
[20/24] Train loss=0.34466516971588135
Test set avg_accuracy=83.36% avg_sensitivity=57.96%, avg_specificity=92.98% avg_auc=89.89%
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.366649 Test loss=0.359677 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3421643078327179
[5/24] Train loss=0.3547837436199188
[10/24] Train loss=0.4003579020500183
[15/24] Train loss=0.39379000663757324
[20/24] Train loss=0.34346282482147217
Test set avg_accuracy=83.15% avg_sensitivity=55.17%, avg_specificity=93.75% avg_auc=89.77%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.363922 Test loss=0.363109 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3376176953315735
[5/24] Train loss=0.35093268752098083
[10/24] Train loss=0.3940355181694031
[15/24] Train loss=0.3855772912502289
[20/24] Train loss=0.3394261598587036
Test set avg_accuracy=83.31% avg_sensitivity=54.83%, avg_specificity=94.09% avg_auc=90.00%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.361088 Test loss=0.360244 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.34075796604156494
[5/24] Train loss=0.3510631024837494
[10/24] Train loss=0.39609986543655396
[15/24] Train loss=0.3763149380683899
[20/24] Train loss=0.34126514196395874
Test set avg_accuracy=83.40% avg_sensitivity=54.22%, avg_specificity=94.45% avg_auc=90.08%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.360015 Test loss=0.360816 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3346542418003082
[5/24] Train loss=0.3489348292350769
[10/24] Train loss=0.3981281518936157
[15/24] Train loss=0.3764684796333313
[20/24] Train loss=0.3408656418323517
Test set avg_accuracy=83.42% avg_sensitivity=54.03%, avg_specificity=94.56% avg_auc=90.12%
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.359515 Test loss=0.360039 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.32891425490379333
[5/24] Train loss=0.34978777170181274
[10/24] Train loss=0.3964885175228119
[15/24] Train loss=0.3821750283241272
[20/24] Train loss=0.34407731890678406
Test set avg_accuracy=83.45% avg_sensitivity=54.36%, avg_specificity=94.47% avg_auc=90.08%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.358938 Test loss=0.360263 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.330646276473999
[5/24] Train loss=0.34754690527915955
[10/24] Train loss=0.39594462513923645
[15/24] Train loss=0.3863450586795807
[20/24] Train loss=0.3413562774658203
Test set avg_accuracy=83.42% avg_sensitivity=54.79%, avg_specificity=94.27% avg_auc=90.04%
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.357034 Test loss=0.360175 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3304494321346283
[5/24] Train loss=0.3476088345050812
[10/24] Train loss=0.3960036337375641
[15/24] Train loss=0.38284093141555786
[20/24] Train loss=0.34161990880966187
Test set avg_accuracy=83.45% avg_sensitivity=53.79%, avg_specificity=94.69% avg_auc=90.04%
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.356231 Test loss=0.361196 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3339444100856781
[5/24] Train loss=0.35179275274276733
[10/24] Train loss=0.3924490213394165
[15/24] Train loss=0.3922043442726135
[20/24] Train loss=0.3385518491268158
Test set avg_accuracy=83.71% avg_sensitivity=54.12%, avg_specificity=94.92% avg_auc=90.24%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.354961 Test loss=0.359061 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3301655054092407
[5/24] Train loss=0.34803786873817444
[10/24] Train loss=0.392772912979126
[15/24] Train loss=0.383414089679718
[20/24] Train loss=0.3377303183078766
Test set avg_accuracy=83.33% avg_sensitivity=53.51%, avg_specificity=94.63% avg_auc=90.06%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.355534 Test loss=0.361617 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3265220820903778
[5/24] Train loss=0.34812185168266296
[10/24] Train loss=0.39537301659584045
[15/24] Train loss=0.3759872019290924
[20/24] Train loss=0.3325977623462677
Test set avg_accuracy=83.35% avg_sensitivity=52.13%, avg_specificity=95.17% avg_auc=90.03%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.352676 Test loss=0.364193 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3269653916358948
[5/24] Train loss=0.34781789779663086
[10/24] Train loss=0.38719698786735535
[15/24] Train loss=0.37155839800834656
[20/24] Train loss=0.33691510558128357
Test set avg_accuracy=83.37% avg_sensitivity=51.09%, avg_specificity=95.60% avg_auc=90.24%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.350918 Test loss=0.364565 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.32903558015823364
[5/24] Train loss=0.349626362323761
[10/24] Train loss=0.38928982615470886
[15/24] Train loss=0.3741627037525177
[20/24] Train loss=0.33465301990509033
Test set avg_accuracy=83.29% avg_sensitivity=50.28%, avg_specificity=95.80% avg_auc=90.35%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.350927 Test loss=0.364624 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3250039219856262
[5/24] Train loss=0.3477185368537903
[10/24] Train loss=0.38621941208839417
[15/24] Train loss=0.3773707151412964
[20/24] Train loss=0.3271017372608185
Test set avg_accuracy=83.29% avg_sensitivity=49.67%, avg_specificity=96.03% avg_auc=90.31%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.349670 Test loss=0.365622 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3300945460796356
[5/24] Train loss=0.3523922860622406
[10/24] Train loss=0.3931424617767334
[15/24] Train loss=0.3816811740398407
[20/24] Train loss=0.32689741253852844
Test set avg_accuracy=83.58% avg_sensitivity=51.61%, avg_specificity=95.69% avg_auc=90.28%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.349822 Test loss=0.363079 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.32397183775901794
[5/24] Train loss=0.3447444438934326
[10/24] Train loss=0.3904067873954773
[15/24] Train loss=0.37471458315849304
[20/24] Train loss=0.3297301232814789
Test set avg_accuracy=83.26% avg_sensitivity=50.33%, avg_specificity=95.73% avg_auc=90.20%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.347905 Test loss=0.365223 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.32646626234054565
[5/24] Train loss=0.3480418920516968
[10/24] Train loss=0.38917267322540283
[15/24] Train loss=0.37703800201416016
[20/24] Train loss=0.33121034502983093
Test set avg_accuracy=83.49% avg_sensitivity=51.37%, avg_specificity=95.66% avg_auc=90.31%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.347914 Test loss=0.362982 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.32307612895965576
[5/24] Train loss=0.3452509045600891
[10/24] Train loss=0.38614508509635925
[15/24] Train loss=0.3737829327583313
[20/24] Train loss=0.32305052876472473
Test set avg_accuracy=83.52% avg_sensitivity=51.80%, avg_specificity=95.53% avg_auc=90.24%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.347107 Test loss=0.362679 Current lr=[0.00029967723776099]

[0/24] Train loss=0.32480451464653015
[5/24] Train loss=0.3472124934196472
[10/24] Train loss=0.3892371952533722
[15/24] Train loss=0.37060654163360596
[20/24] Train loss=0.3251625597476959
Test set avg_accuracy=83.09% avg_sensitivity=48.39%, avg_specificity=96.23% avg_auc=90.22%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.347385 Test loss=0.369610 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3259732127189636
[5/24] Train loss=0.3478439450263977
[10/24] Train loss=0.3908786475658417
[15/24] Train loss=0.38324248790740967
[20/24] Train loss=0.32831650972366333
Test set avg_accuracy=83.45% avg_sensitivity=51.28%, avg_specificity=95.64% avg_auc=90.36%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.346703 Test loss=0.362030 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3186884820461273
[5/24] Train loss=0.3502465784549713
[10/24] Train loss=0.3867622911930084
[15/24] Train loss=0.3696299195289612
[20/24] Train loss=0.3225557804107666
Test set avg_accuracy=83.48% avg_sensitivity=50.85%, avg_specificity=95.83% avg_auc=90.38%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.344601 Test loss=0.361907 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3229338526725769
[5/24] Train loss=0.34722673892974854
[10/24] Train loss=0.3907354176044464
[15/24] Train loss=0.36814746260643005
[20/24] Train loss=0.32372039556503296
Test set avg_accuracy=83.55% avg_sensitivity=50.81%, avg_specificity=95.96% avg_auc=90.44%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.343559 Test loss=0.361528 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.32227638363838196
[5/24] Train loss=0.3465687334537506
[10/24] Train loss=0.38859134912490845
[15/24] Train loss=0.36947670578956604
[20/24] Train loss=0.32258644700050354
Test set avg_accuracy=83.75% avg_sensitivity=52.13%, avg_specificity=95.73% avg_auc=90.49%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.344257 Test loss=0.358899 Current lr=[0.000298904600941902]

[0/24] Train loss=0.31898751854896545
[5/24] Train loss=0.34838512539863586
[10/24] Train loss=0.38709190487861633
[15/24] Train loss=0.37675008177757263
[20/24] Train loss=0.32499271631240845
Test set avg_accuracy=83.79% avg_sensitivity=52.70%, avg_specificity=95.57% avg_auc=90.50%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.344336 Test loss=0.357977 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3182823956012726
[5/24] Train loss=0.3453482389450073
[10/24] Train loss=0.38746899366378784
[15/24] Train loss=0.36745670437812805
[20/24] Train loss=0.32549768686294556
Test set avg_accuracy=83.66% avg_sensitivity=52.09%, avg_specificity=95.62% avg_auc=90.49%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.342363 Test loss=0.359311 Current lr=[0.000297555943323901]

[0/24] Train loss=0.31895941495895386
[5/24] Train loss=0.3452194333076477
[10/24] Train loss=0.3869342505931854
[15/24] Train loss=0.3763118386268616
[20/24] Train loss=0.3226941227912903
Test set avg_accuracy=83.59% avg_sensitivity=51.00%, avg_specificity=95.94% avg_auc=90.46%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.342811 Test loss=0.360786 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.31832191348075867
[5/24] Train loss=0.34404146671295166
[10/24] Train loss=0.3898533284664154
[15/24] Train loss=0.3718027174472809
[20/24] Train loss=0.31842049956321716
Test set avg_accuracy=83.72% avg_sensitivity=52.23%, avg_specificity=95.66% avg_auc=90.48%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.342591 Test loss=0.359158 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3194374740123749
[5/24] Train loss=0.3484649956226349
[10/24] Train loss=0.3877856433391571
[15/24] Train loss=0.3721224069595337
[20/24] Train loss=0.31959617137908936
Test set avg_accuracy=83.57% avg_sensitivity=50.76%, avg_specificity=96.00% avg_auc=90.45%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.341758 Test loss=0.362189 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3202022612094879
[5/24] Train loss=0.3474317193031311
[10/24] Train loss=0.3829449415206909
[15/24] Train loss=0.36785656213760376
[20/24] Train loss=0.3163496255874634
Test set avg_accuracy=83.97% avg_sensitivity=54.03%, avg_specificity=95.31% avg_auc=90.59%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.340653 Test loss=0.355280 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3153879940509796
[5/24] Train loss=0.34683090448379517
[10/24] Train loss=0.39005738496780396
[15/24] Train loss=0.3680027425289154
[20/24] Train loss=0.31796959042549133
Test set avg_accuracy=83.88% avg_sensitivity=52.46%, avg_specificity=95.78% avg_auc=90.49%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.340548 Test loss=0.358218 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.318485289812088
[5/24] Train loss=0.344467431306839
[10/24] Train loss=0.38829469680786133
[15/24] Train loss=0.36683911085128784
[20/24] Train loss=0.31684359908103943
Test set avg_accuracy=83.85% avg_sensitivity=51.61%, avg_specificity=96.07% avg_auc=90.61%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.339545 Test loss=0.358816 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.31539809703826904
[5/24] Train loss=0.3435913324356079
[10/24] Train loss=0.3878439962863922
[15/24] Train loss=0.3664010465145111
[20/24] Train loss=0.3139485716819763
Test set avg_accuracy=84.00% avg_sensitivity=53.60%, avg_specificity=95.51% avg_auc=90.51%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.338338 Test loss=0.356217 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3118405044078827
[5/24] Train loss=0.3448692560195923
[10/24] Train loss=0.38296714425086975
[15/24] Train loss=0.37846487760543823
[20/24] Train loss=0.3165719509124756
Test set avg_accuracy=84.10% avg_sensitivity=53.84%, avg_specificity=95.57% avg_auc=90.60%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.338269 Test loss=0.354911 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3113005459308624
[5/24] Train loss=0.34403979778289795
[10/24] Train loss=0.3878236711025238
[15/24] Train loss=0.3647027611732483
[20/24] Train loss=0.3122066259384155
Test set avg_accuracy=84.13% avg_sensitivity=54.17%, avg_specificity=95.48% avg_auc=90.55%
Best model saved!! Metric=-1.6726970407154624!!
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.337991 Test loss=0.355004 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.31593412160873413
[5/24] Train loss=0.34555405378341675
[10/24] Train loss=0.3853241801261902
[15/24] Train loss=0.3643602132797241
[20/24] Train loss=0.31370189785957336
Test set avg_accuracy=83.82% avg_sensitivity=51.90%, avg_specificity=95.91% avg_auc=90.56%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.337494 Test loss=0.357676 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3158472776412964
[5/24] Train loss=0.3419383466243744
[10/24] Train loss=0.383009672164917
[15/24] Train loss=0.36252760887145996
[20/24] Train loss=0.3127453923225403
Test set avg_accuracy=84.13% avg_sensitivity=53.79%, avg_specificity=95.62% avg_auc=90.67%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.336552 Test loss=0.353463 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3124699294567108
[5/24] Train loss=0.3423551023006439
[10/24] Train loss=0.38403576612472534
[15/24] Train loss=0.3656778037548065
[20/24] Train loss=0.311710000038147
Test set avg_accuracy=84.05% avg_sensitivity=53.03%, avg_specificity=95.80% avg_auc=90.70%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.335236 Test loss=0.354314 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3137430250644684
[5/24] Train loss=0.3381696343421936
[10/24] Train loss=0.3830389082431793
[15/24] Train loss=0.3615940809249878
[20/24] Train loss=0.3063183128833771
Test set avg_accuracy=84.09% avg_sensitivity=52.46%, avg_specificity=96.07% avg_auc=90.74%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.335258 Test loss=0.355394 Current lr=[0.000276307469034998]

[0/24] Train loss=0.31238630414009094
[5/24] Train loss=0.3391259014606476
[10/24] Train loss=0.3850567042827606
[15/24] Train loss=0.3615349531173706
[20/24] Train loss=0.30778422951698303
Test set avg_accuracy=83.97% avg_sensitivity=51.80%, avg_specificity=96.16% avg_auc=90.68%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.334334 Test loss=0.357077 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3116070032119751
[5/24] Train loss=0.3396611213684082
[10/24] Train loss=0.38722458481788635
[15/24] Train loss=0.3671914339065552
[20/24] Train loss=0.3108742833137512
Test set avg_accuracy=84.06% avg_sensitivity=53.51%, avg_specificity=95.64% avg_auc=90.74%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.334796 Test loss=0.352755 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.31015342473983765
[5/24] Train loss=0.3405233323574066
[10/24] Train loss=0.38455137610435486
[15/24] Train loss=0.35002487897872925
[20/24] Train loss=0.3052501082420349
Test set avg_accuracy=83.98% avg_sensitivity=52.04%, avg_specificity=96.09% avg_auc=90.78%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.333423 Test loss=0.355870 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.31176602840423584
[5/24] Train loss=0.34436899423599243
[10/24] Train loss=0.3826613128185272
[15/24] Train loss=0.3622778356075287
[20/24] Train loss=0.3066151440143585
Test set avg_accuracy=84.14% avg_sensitivity=53.55%, avg_specificity=95.73% avg_auc=90.65%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.333474 Test loss=0.354486 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3106822371482849
[5/24] Train loss=0.33810561895370483
[10/24] Train loss=0.38630563020706177
[15/24] Train loss=0.3551989495754242
[20/24] Train loss=0.3090142011642456
Test set avg_accuracy=83.98% avg_sensitivity=52.46%, avg_specificity=95.92% avg_auc=90.82%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.332103 Test loss=0.353269 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3127596080303192
[5/24] Train loss=0.3408377468585968
[10/24] Train loss=0.3801361620426178
[15/24] Train loss=0.36062002182006836
[20/24] Train loss=0.3025814890861511
Test set avg_accuracy=83.89% avg_sensitivity=52.23%, avg_specificity=95.89% avg_auc=90.81%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.331586 Test loss=0.352682 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3067866861820221
[5/24] Train loss=0.3405684530735016
[10/24] Train loss=0.3836383819580078
[15/24] Train loss=0.34956610202789307
[20/24] Train loss=0.3011174499988556
Test set avg_accuracy=84.31% avg_sensitivity=53.98%, avg_specificity=95.80% avg_auc=90.84%
Best model saved!! Metric=-1.0741946309854953!!
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.331313 Test loss=0.351129 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.30954062938690186
[5/24] Train loss=0.33629947900772095
[10/24] Train loss=0.37846648693084717
[15/24] Train loss=0.35621413588523865
[20/24] Train loss=0.3016524910926819
Test set avg_accuracy=84.02% avg_sensitivity=52.75%, avg_specificity=95.87% avg_auc=90.89%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.330792 Test loss=0.351903 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3065623342990875
[5/24] Train loss=0.3379856050014496
[10/24] Train loss=0.3854573667049408
[15/24] Train loss=0.35758185386657715
[20/24] Train loss=0.301570326089859
Test set avg_accuracy=84.10% avg_sensitivity=52.23%, avg_specificity=96.18% avg_auc=90.90%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.332267 Test loss=0.352950 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.30802541971206665
[5/24] Train loss=0.34250402450561523
[10/24] Train loss=0.3817256689071655
[15/24] Train loss=0.35401636362075806
[20/24] Train loss=0.30373722314834595
Test set avg_accuracy=84.26% avg_sensitivity=53.84%, avg_specificity=95.78% avg_auc=90.85%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.330835 Test loss=0.350908 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3051239848136902
[5/24] Train loss=0.3392086327075958
[10/24] Train loss=0.3846466839313507
[15/24] Train loss=0.3502295911312103
[20/24] Train loss=0.30142804980278015
Test set avg_accuracy=84.19% avg_sensitivity=54.08%, avg_specificity=95.60% avg_auc=90.83%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.329976 Test loss=0.350729 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.31389370560646057
[5/24] Train loss=0.33841803669929504
[10/24] Train loss=0.3823467493057251
[15/24] Train loss=0.35459622740745544
[20/24] Train loss=0.2986140847206116
Test set avg_accuracy=84.38% avg_sensitivity=53.93%, avg_specificity=95.91% avg_auc=90.98%
Best model saved!! Metric=-0.802899546487204!!
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.329376 Test loss=0.348887 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3094419836997986
[5/24] Train loss=0.33273109793663025
[10/24] Train loss=0.38471588492393494
[15/24] Train loss=0.34307512640953064
[20/24] Train loss=0.30366480350494385
Test set avg_accuracy=84.32% avg_sensitivity=53.55%, avg_specificity=95.98% avg_auc=90.89%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.329573 Test loss=0.350560 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.30424773693084717
[5/24] Train loss=0.3312590420246124
[10/24] Train loss=0.3810983896255493
[15/24] Train loss=0.3482940196990967
[20/24] Train loss=0.2968195676803589
Test set avg_accuracy=84.58% avg_sensitivity=55.78%, avg_specificity=95.49% avg_auc=90.92%
Best model saved!! Metric=0.7744851537660935!!
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.328267 Test loss=0.347187 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.29878610372543335
[5/24] Train loss=0.33001938462257385
[10/24] Train loss=0.38770076632499695
[15/24] Train loss=0.34254559874534607
[20/24] Train loss=0.3010236322879791
Test set avg_accuracy=84.51% avg_sensitivity=55.92%, avg_specificity=95.33% avg_auc=90.89%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.328858 Test loss=0.346453 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.30719107389450073
[5/24] Train loss=0.3344864845275879
[10/24] Train loss=0.3850474953651428
[15/24] Train loss=0.3497306704521179
[20/24] Train loss=0.3010202646255493
Test set avg_accuracy=84.99% avg_sensitivity=59.15%, avg_specificity=94.78% avg_auc=91.06%
Best model saved!! Metric=3.9715997219433277!!
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.329335 Test loss=0.341007 Current lr=[0.000224838296036774]

[0/24] Train loss=0.30191975831985474
[5/24] Train loss=0.33605432510375977
[10/24] Train loss=0.38606804609298706
[15/24] Train loss=0.36140939593315125
[20/24] Train loss=0.302016019821167
Test set avg_accuracy=85.00% avg_sensitivity=59.76%, avg_specificity=94.56% avg_auc=91.00%
Best model saved!! Metric=4.319739293949489!!
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.328647 Test loss=0.340535 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.30344054102897644
[5/24] Train loss=0.3298565745353699
[10/24] Train loss=0.38170915842056274
[15/24] Train loss=0.35560131072998047
[20/24] Train loss=0.29850009083747864
Test set avg_accuracy=84.88% avg_sensitivity=59.05%, avg_specificity=94.67% avg_auc=91.02%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.327202 Test loss=0.340699 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3061578869819641
[5/24] Train loss=0.33573323488235474
[10/24] Train loss=0.38384607434272766
[15/24] Train loss=0.35805535316467285
[20/24] Train loss=0.3006807863712311
Test set avg_accuracy=84.91% avg_sensitivity=59.43%, avg_specificity=94.56% avg_auc=91.04%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.328106 Test loss=0.340864 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.30662408471107483
[5/24] Train loss=0.33410996198654175
[10/24] Train loss=0.3839104473590851
[15/24] Train loss=0.3577687740325928
[20/24] Train loss=0.295710951089859
Test set avg_accuracy=84.88% avg_sensitivity=59.57%, avg_specificity=94.47% avg_auc=91.01%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.327684 Test loss=0.340436 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3047987222671509
[5/24] Train loss=0.3310985565185547
[10/24] Train loss=0.3788806200027466
[15/24] Train loss=0.3540666997432709
[20/24] Train loss=0.29748377203941345
Test set avg_accuracy=84.83% avg_sensitivity=57.25%, avg_specificity=95.28% avg_auc=90.97%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.326496 Test loss=0.344232 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3043445646762848
[5/24] Train loss=0.33180955052375793
[10/24] Train loss=0.3825274109840393
[15/24] Train loss=0.3498513102531433
[20/24] Train loss=0.29811450839042664
Test set avg_accuracy=84.80% avg_sensitivity=58.86%, avg_specificity=94.63% avg_auc=90.92%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.326887 Test loss=0.342565 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3040298521518707
[5/24] Train loss=0.33411136269569397
[10/24] Train loss=0.3853270411491394
[15/24] Train loss=0.36014384031295776
[20/24] Train loss=0.2946978509426117
Test set avg_accuracy=84.57% avg_sensitivity=56.59%, avg_specificity=95.17% avg_auc=90.94%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.327342 Test loss=0.345224 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.302333265542984
[5/24] Train loss=0.3345869183540344
[10/24] Train loss=0.3832273483276367
[15/24] Train loss=0.3500165343284607
[20/24] Train loss=0.2923896312713623
Test set avg_accuracy=84.66% avg_sensitivity=56.82%, avg_specificity=95.21% avg_auc=90.96%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.326312 Test loss=0.344794 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.303297221660614
[5/24] Train loss=0.3348095118999481
[10/24] Train loss=0.3821731209754944
[15/24] Train loss=0.34780940413475037
[20/24] Train loss=0.29499366879463196
Test set avg_accuracy=84.57% avg_sensitivity=56.73%, avg_specificity=95.12% avg_auc=90.88%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.325973 Test loss=0.345778 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3042858839035034
[5/24] Train loss=0.3252395689487457
[10/24] Train loss=0.3790460526943207
[15/24] Train loss=0.3436269164085388
[20/24] Train loss=0.2931806147098541
Test set avg_accuracy=84.71% avg_sensitivity=57.87%, avg_specificity=94.88% avg_auc=90.87%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.324133 Test loss=0.344606 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.30311745405197144
[5/24] Train loss=0.3289516568183899
[10/24] Train loss=0.3785247504711151
[15/24] Train loss=0.3462022542953491
[20/24] Train loss=0.2947806715965271
Test set avg_accuracy=84.27% avg_sensitivity=54.98%, avg_specificity=95.37% avg_auc=90.73%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.325760 Test loss=0.349727 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.30458125472068787
[5/24] Train loss=0.33685502409935
[10/24] Train loss=0.3810475468635559
[15/24] Train loss=0.34742358326911926
[20/24] Train loss=0.29362598061561584
Test set avg_accuracy=84.36% avg_sensitivity=56.40%, avg_specificity=94.96% avg_auc=90.73%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.327305 Test loss=0.347051 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.30540701746940613
[5/24] Train loss=0.33318066596984863
[10/24] Train loss=0.38102900981903076
[15/24] Train loss=0.3338223993778229
[20/24] Train loss=0.2964230179786682
Test set avg_accuracy=84.86% avg_sensitivity=59.81%, avg_specificity=94.34% avg_auc=90.93%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.326679 Test loss=0.341016 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3043237030506134
[5/24] Train loss=0.33305490016937256
[10/24] Train loss=0.38669344782829285
[15/24] Train loss=0.32992905378341675
[20/24] Train loss=0.29524579644203186
Test set avg_accuracy=85.21% avg_sensitivity=65.21%, avg_specificity=92.78% avg_auc=91.01%
Best model saved!! Metric=8.210230769667106!!
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.327558 Test loss=0.335925 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.30921003222465515
[5/24] Train loss=0.3316463530063629
[10/24] Train loss=0.383433997631073
[15/24] Train loss=0.3291230797767639
[20/24] Train loss=0.2990255653858185
Test set avg_accuracy=84.93% avg_sensitivity=67.82%, avg_specificity=91.42% avg_auc=90.94%
Best model saved!! Metric=9.110089618591175!!
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.327375 Test loss=0.336422 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3059351444244385
[5/24] Train loss=0.33086130023002625
[10/24] Train loss=0.3794465959072113
[15/24] Train loss=0.3301229774951935
[20/24] Train loss=0.3005545139312744
Test set avg_accuracy=85.29% avg_sensitivity=67.49%, avg_specificity=92.03% avg_auc=91.00%
Best model saved!! Metric=9.800680597153573!!
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.325778 Test loss=0.335175 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3066536784172058
[5/24] Train loss=0.33132562041282654
[10/24] Train loss=0.38359084725379944
[15/24] Train loss=0.33334988355636597
[20/24] Train loss=0.29874345660209656
Test set avg_accuracy=85.20% avg_sensitivity=66.97%, avg_specificity=92.10% avg_auc=90.99%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.325067 Test loss=0.335571 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.30624258518218994
[5/24] Train loss=0.3275708556175232
[10/24] Train loss=0.380414217710495
[15/24] Train loss=0.3304612636566162
[20/24] Train loss=0.2982467710971832
Test set avg_accuracy=85.21% avg_sensitivity=66.16%, avg_specificity=92.42% avg_auc=91.00%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.323867 Test loss=0.335216 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3046192228794098
[5/24] Train loss=0.3345629572868347
[10/24] Train loss=0.3774113655090332
[15/24] Train loss=0.33407220244407654
[20/24] Train loss=0.2940525710582733
Test set avg_accuracy=85.20% avg_sensitivity=66.45%, avg_specificity=92.30% avg_auc=91.00%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.324352 Test loss=0.335461 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3054754436016083
[5/24] Train loss=0.33210745453834534
[10/24] Train loss=0.38394054770469666
[15/24] Train loss=0.33090534806251526
[20/24] Train loss=0.29563942551612854
Test set avg_accuracy=85.14% avg_sensitivity=65.69%, avg_specificity=92.51% avg_auc=91.01%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.323585 Test loss=0.335029 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.30350762605667114
[5/24] Train loss=0.3277429938316345
[10/24] Train loss=0.3775283992290497
[15/24] Train loss=0.33176442980766296
[20/24] Train loss=0.29802146553993225
Test set avg_accuracy=85.20% avg_sensitivity=65.45%, avg_specificity=92.68% avg_auc=90.99%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.322989 Test loss=0.335809 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3034657835960388
[5/24] Train loss=0.3326568603515625
[10/24] Train loss=0.37941908836364746
[15/24] Train loss=0.3302329182624817
[20/24] Train loss=0.2928275763988495
Test set avg_accuracy=85.12% avg_sensitivity=65.97%, avg_specificity=92.37% avg_auc=91.05%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.323512 Test loss=0.334170 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.30151721835136414
[5/24] Train loss=0.3329339027404785
[10/24] Train loss=0.3822561502456665
[15/24] Train loss=0.3381904065608978
[20/24] Train loss=0.2979418635368347
Test set avg_accuracy=85.22% avg_sensitivity=66.16%, avg_specificity=92.44% avg_auc=91.03%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.323226 Test loss=0.334685 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.30318304896354675
[5/24] Train loss=0.3304821848869324
[10/24] Train loss=0.380397766828537
[15/24] Train loss=0.33376389741897583
[20/24] Train loss=0.2922055125236511
Test set avg_accuracy=85.10% avg_sensitivity=64.83%, avg_specificity=92.78% avg_auc=91.04%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.323365 Test loss=0.334463 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3035717308521271
[5/24] Train loss=0.3310019373893738
[10/24] Train loss=0.3853355944156647
[15/24] Train loss=0.33544397354125977
[20/24] Train loss=0.29211392998695374
Test set avg_accuracy=85.03% avg_sensitivity=64.88%, avg_specificity=92.66% avg_auc=90.99%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.322524 Test loss=0.335065 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.2997331917285919
[5/24] Train loss=0.3327683210372925
[10/24] Train loss=0.3819684684276581
[15/24] Train loss=0.3400716781616211
[20/24] Train loss=0.2948227822780609
Test set avg_accuracy=84.82% avg_sensitivity=65.45%, avg_specificity=92.15% avg_auc=90.90%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.324608 Test loss=0.336357 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.302846223115921
[5/24] Train loss=0.33225423097610474
[10/24] Train loss=0.38310250639915466
[15/24] Train loss=0.3428100049495697
[20/24] Train loss=0.2909330427646637
Test set avg_accuracy=85.03% avg_sensitivity=66.16%, avg_specificity=92.17% avg_auc=90.99%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.323091 Test loss=0.334811 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.30205124616622925
[5/24] Train loss=0.33644819259643555
[10/24] Train loss=0.388507604598999
[15/24] Train loss=0.34579208493232727
[20/24] Train loss=0.29118889570236206
Test set avg_accuracy=85.01% avg_sensitivity=67.54%, avg_specificity=91.63% avg_auc=91.04%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.323569 Test loss=0.334326 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3032589256763458
[5/24] Train loss=0.3398708701133728
[10/24] Train loss=0.3915334939956665
[15/24] Train loss=0.34437188506126404
[20/24] Train loss=0.2909739315509796
Test set avg_accuracy=85.01% avg_sensitivity=71.23%, avg_specificity=90.23% avg_auc=90.94%
Best model saved!! Metric=11.415302862143733!!
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.324998 Test loss=0.338287 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.31154683232307434
[5/24] Train loss=0.352438747882843
[10/24] Train loss=0.3936866223812103
[15/24] Train loss=0.33816853165626526
[20/24] Train loss=0.2997327446937561
Test set avg_accuracy=84.49% avg_sensitivity=74.36%, avg_specificity=88.33% avg_auc=90.79%
Best model saved!! Metric=11.974987197090883!!
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.328643 Test loss=0.346720 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3260338008403778
[5/24] Train loss=0.3496958315372467
[10/24] Train loss=0.38591277599334717
[15/24] Train loss=0.32746899127960205
[20/24] Train loss=0.3173535168170929
Test set avg_accuracy=85.00% avg_sensitivity=69.86%, avg_specificity=90.74% avg_auc=91.00%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.329995 Test loss=0.336338 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3104945719242096
[5/24] Train loss=0.3340037763118744
[10/24] Train loss=0.385747492313385
[15/24] Train loss=0.3252953290939331
[20/24] Train loss=0.30751150846481323
Test set avg_accuracy=85.12% avg_sensitivity=66.07%, avg_specificity=92.33% avg_auc=91.06%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.324214 Test loss=0.334094 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.30101892352104187
[5/24] Train loss=0.3302634060382843
[10/24] Train loss=0.38487672805786133
[15/24] Train loss=0.32709774374961853
[20/24] Train loss=0.3068796694278717
Test set avg_accuracy=85.00% avg_sensitivity=67.20%, avg_specificity=91.74% avg_auc=91.07%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.322136 Test loss=0.334558 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3042837679386139
[5/24] Train loss=0.3321681022644043
[10/24] Train loss=0.38361650705337524
[15/24] Train loss=0.3289291560649872
[20/24] Train loss=0.3055497109889984
Test set avg_accuracy=85.08% avg_sensitivity=67.01%, avg_specificity=91.92% avg_auc=91.10%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.322387 Test loss=0.333457 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3051108717918396
[5/24] Train loss=0.3346215784549713
[10/24] Train loss=0.3858146369457245
[15/24] Train loss=0.3257400095462799
[20/24] Train loss=0.3011559545993805
Test set avg_accuracy=85.05% avg_sensitivity=66.64%, avg_specificity=92.03% avg_auc=91.09%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.321931 Test loss=0.334041 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.30338186025619507
[5/24] Train loss=0.3355676531791687
[10/24] Train loss=0.37816888093948364
[15/24] Train loss=0.3240373730659485
[20/24] Train loss=0.3034038245677948
Test set avg_accuracy=85.04% avg_sensitivity=66.49%, avg_specificity=92.06% avg_auc=91.04%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.321603 Test loss=0.334303 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3010447919368744
[5/24] Train loss=0.3362817168235779
[10/24] Train loss=0.3883848488330841
[15/24] Train loss=0.32752490043640137
[20/24] Train loss=0.2991066575050354
Test set avg_accuracy=84.83% avg_sensitivity=66.92%, avg_specificity=91.62% avg_auc=90.88%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.322875 Test loss=0.336836 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.31058982014656067
[5/24] Train loss=0.3371501564979553
[10/24] Train loss=0.38449257612228394
[15/24] Train loss=0.3243967294692993
[20/24] Train loss=0.2988734841346741
Test set avg_accuracy=84.58% avg_sensitivity=66.11%, avg_specificity=91.58% avg_auc=90.66%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.323098 Test loss=0.339859 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3110228478908539
[5/24] Train loss=0.3357473611831665
[10/24] Train loss=0.38009753823280334
[15/24] Train loss=0.3238949775695801
[20/24] Train loss=0.3002098798751831
Test set avg_accuracy=84.91% avg_sensitivity=66.35%, avg_specificity=91.94% avg_auc=90.86%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.322203 Test loss=0.336797 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.30777427554130554
[5/24] Train loss=0.32954591512680054
[10/24] Train loss=0.3792019784450531
[15/24] Train loss=0.3263886272907257
[20/24] Train loss=0.29713529348373413
Test set avg_accuracy=85.04% avg_sensitivity=64.36%, avg_specificity=92.87% avg_auc=91.05%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.321484 Test loss=0.334419 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.30303189158439636
[5/24] Train loss=0.32730695605278015
[10/24] Train loss=0.386557936668396
[15/24] Train loss=0.31891873478889465
[20/24] Train loss=0.3028797209262848
Test set avg_accuracy=85.07% avg_sensitivity=64.08%, avg_specificity=93.02% avg_auc=91.11%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.320083 Test loss=0.333907 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.2989709675312042
[5/24] Train loss=0.3289938271045685
[10/24] Train loss=0.37750813364982605
[15/24] Train loss=0.32144877314567566
[20/24] Train loss=0.3019573986530304
Test set avg_accuracy=85.13% avg_sensitivity=64.03%, avg_specificity=93.12% avg_auc=91.08%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.319216 Test loss=0.334070 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.29981476068496704
[5/24] Train loss=0.3278833031654358
[10/24] Train loss=0.37760287523269653
[15/24] Train loss=0.3238643705844879
[20/24] Train loss=0.2991267740726471
Test set avg_accuracy=85.07% avg_sensitivity=63.74%, avg_specificity=93.14% avg_auc=91.11%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.319264 Test loss=0.333913 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.29968351125717163
[5/24] Train loss=0.3241645395755768
[10/24] Train loss=0.3803175091743469
[15/24] Train loss=0.3217270076274872
[20/24] Train loss=0.29802748560905457
Test set avg_accuracy=85.07% avg_sensitivity=63.84%, avg_specificity=93.11% avg_auc=91.14%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.318474 Test loss=0.333465 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.2974127233028412
[5/24] Train loss=0.3305995464324951
[10/24] Train loss=0.3773241937160492
[15/24] Train loss=0.3205452561378479
[20/24] Train loss=0.29782721400260925
Test set avg_accuracy=85.13% avg_sensitivity=63.60%, avg_specificity=93.29% avg_auc=91.14%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.319044 Test loss=0.333593 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.2950678765773773
[5/24] Train loss=0.32519209384918213
[10/24] Train loss=0.37609177827835083
[15/24] Train loss=0.3278542160987854
[20/24] Train loss=0.29543712735176086
Test set avg_accuracy=85.07% avg_sensitivity=63.46%, avg_specificity=93.25% avg_auc=91.17%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.317970 Test loss=0.333257 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.30132925510406494
[5/24] Train loss=0.32182419300079346
[10/24] Train loss=0.37621861696243286
[15/24] Train loss=0.31846246123313904
[20/24] Train loss=0.2950066924095154
Test set avg_accuracy=85.13% avg_sensitivity=63.55%, avg_specificity=93.30% avg_auc=91.16%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.318261 Test loss=0.333296 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.2986631691455841
[5/24] Train loss=0.32819780707359314
[10/24] Train loss=0.37826716899871826
[15/24] Train loss=0.3186376094818115
[20/24] Train loss=0.291424959897995
Test set avg_accuracy=85.18% avg_sensitivity=63.46%, avg_specificity=93.41% avg_auc=91.16%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.317552 Test loss=0.333596 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.29856544733047485
[5/24] Train loss=0.3258019983768463
[10/24] Train loss=0.37473154067993164
[15/24] Train loss=0.32069721817970276
[20/24] Train loss=0.2918168008327484
Test set avg_accuracy=85.21% avg_sensitivity=63.51%, avg_specificity=93.43% avg_auc=91.17%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.317451 Test loss=0.333319 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.2970559597015381
[5/24] Train loss=0.32791954278945923
[10/24] Train loss=0.38015514612197876
[15/24] Train loss=0.32053157687187195
[20/24] Train loss=0.291449636220932
Test set avg_accuracy=85.27% avg_sensitivity=63.79%, avg_specificity=93.41% avg_auc=91.17%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.317749 Test loss=0.333196 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.299063503742218
[5/24] Train loss=0.32715559005737305
[10/24] Train loss=0.37320801615715027
[15/24] Train loss=0.32416632771492004
[20/24] Train loss=0.2907615005970001
Test set avg_accuracy=85.23% avg_sensitivity=64.64%, avg_specificity=93.03% avg_auc=91.18%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.317361 Test loss=0.332549 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.29962286353111267
[5/24] Train loss=0.3257782757282257
[10/24] Train loss=0.3790547847747803
[15/24] Train loss=0.3210398256778717
[20/24] Train loss=0.2904103696346283
Test set avg_accuracy=85.29% avg_sensitivity=65.83%, avg_specificity=92.66% avg_auc=91.16%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.317322 Test loss=0.332191 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.30507680773735046
[5/24] Train loss=0.3260174095630646
[10/24] Train loss=0.3801940381526947
[15/24] Train loss=0.32247194647789
[20/24] Train loss=0.29092222452163696
Test set avg_accuracy=85.16% avg_sensitivity=65.88%, avg_specificity=92.46% avg_auc=91.16%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.317385 Test loss=0.332131 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.2991602122783661
[5/24] Train loss=0.32391980290412903
[10/24] Train loss=0.377513587474823
[15/24] Train loss=0.3224502503871918
[20/24] Train loss=0.2913351356983185
Test set avg_accuracy=85.14% avg_sensitivity=66.21%, avg_specificity=92.32% avg_auc=91.15%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.317476 Test loss=0.332319 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.30117398500442505
[5/24] Train loss=0.3231143057346344
[10/24] Train loss=0.3802320659160614
[15/24] Train loss=0.32235562801361084
[20/24] Train loss=0.2952403128147125
Test set avg_accuracy=85.12% avg_sensitivity=65.17%, avg_specificity=92.68% avg_auc=91.14%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.317435 Test loss=0.332621 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.30186381936073303
[5/24] Train loss=0.3247268795967102
[10/24] Train loss=0.3747718334197998
[15/24] Train loss=0.3253408670425415
[20/24] Train loss=0.29135164618492126
Test set avg_accuracy=85.13% avg_sensitivity=64.93%, avg_specificity=92.78% avg_auc=91.13%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.316659 Test loss=0.332803 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.2975451350212097
[5/24] Train loss=0.32636868953704834
[10/24] Train loss=0.376755028963089
[15/24] Train loss=0.32337138056755066
[20/24] Train loss=0.2899724543094635
Test set avg_accuracy=85.12% avg_sensitivity=64.50%, avg_specificity=92.93% avg_auc=91.16%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.316698 Test loss=0.332515 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.298471063375473
[5/24] Train loss=0.32293054461479187
[10/24] Train loss=0.380692720413208
[15/24] Train loss=0.32965680956840515
[20/24] Train loss=0.2966723144054413
Test set avg_accuracy=85.22% avg_sensitivity=64.69%, avg_specificity=93.00% avg_auc=91.17%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.316082 Test loss=0.332314 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.29969000816345215
[5/24] Train loss=0.32309871912002563
[10/24] Train loss=0.37807101011276245
[15/24] Train loss=0.3246866762638092
[20/24] Train loss=0.2919142246246338
Test set avg_accuracy=85.14% avg_sensitivity=64.03%, avg_specificity=93.14% avg_auc=91.18%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.316848 Test loss=0.332476 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.2970529794692993
[5/24] Train loss=0.32226791977882385
[10/24] Train loss=0.3765832781791687
[15/24] Train loss=0.32267698645591736
[20/24] Train loss=0.28779464960098267
Test set avg_accuracy=85.13% avg_sensitivity=64.12%, avg_specificity=93.09% avg_auc=91.18%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.316101 Test loss=0.332466 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.2989950478076935
[5/24] Train loss=0.3226099908351898
[10/24] Train loss=0.374948650598526
[15/24] Train loss=0.3218299448490143
[20/24] Train loss=0.2926842272281647
Test set avg_accuracy=85.21% avg_sensitivity=64.17%, avg_specificity=93.18% avg_auc=91.19%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.316011 Test loss=0.332365 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.29983699321746826
[5/24] Train loss=0.3203563094139099
[10/24] Train loss=0.37724146246910095
[15/24] Train loss=0.3209385573863983
[20/24] Train loss=0.29035550355911255
Test set avg_accuracy=85.17% avg_sensitivity=63.93%, avg_specificity=93.21% avg_auc=91.18%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.316327 Test loss=0.332544 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.2985817492008209
[5/24] Train loss=0.32417911291122437
[10/24] Train loss=0.37526991963386536
[15/24] Train loss=0.3246750235557556
[20/24] Train loss=0.2908221185207367
Test set avg_accuracy=85.20% avg_sensitivity=63.79%, avg_specificity=93.30% avg_auc=91.19%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.316133 Test loss=0.332595 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.2967783808708191
[5/24] Train loss=0.32040730118751526
[10/24] Train loss=0.3753701150417328
[15/24] Train loss=0.3232950270175934
[20/24] Train loss=0.29000142216682434
Test set avg_accuracy=85.18% avg_sensitivity=63.89%, avg_specificity=93.25% avg_auc=91.19%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.316115 Test loss=0.332520 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.2983023524284363
[5/24] Train loss=0.32279810309410095
[10/24] Train loss=0.382861852645874
[15/24] Train loss=0.31993404030799866
[20/24] Train loss=0.2926703989505768
Test set avg_accuracy=85.20% avg_sensitivity=63.79%, avg_specificity=93.30% avg_auc=91.19%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.315915 Test loss=0.332547 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.29955217242240906
[5/24] Train loss=0.32348400354385376
[10/24] Train loss=0.37732794880867004
[15/24] Train loss=0.3265133500099182
[20/24] Train loss=0.2917223274707794
Test set avg_accuracy=85.21% avg_sensitivity=63.74%, avg_specificity=93.34% avg_auc=91.19%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.316251 Test loss=0.332562 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.29753655195236206
[5/24] Train loss=0.32035353779792786
[10/24] Train loss=0.37403619289398193
[15/24] Train loss=0.32434922456741333
[20/24] Train loss=0.294157475233078
Test set avg_accuracy=85.23% avg_sensitivity=63.79%, avg_specificity=93.36% avg_auc=91.19%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.315941 Test loss=0.332544 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.2936190962791443
[5/24] Train loss=0.3258230984210968
[10/24] Train loss=0.3778696358203888
[15/24] Train loss=0.3242799937725067
[20/24] Train loss=0.29233431816101074
Test set avg_accuracy=85.21% avg_sensitivity=63.70%, avg_specificity=93.36% avg_auc=91.19%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.315966 Test loss=0.332560 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.2996479868888855
[5/24] Train loss=0.3256780505180359
[10/24] Train loss=0.3802645206451416
[15/24] Train loss=0.31980833411216736
[20/24] Train loss=0.2929879426956177
Test set avg_accuracy=85.22% avg_sensitivity=63.70%, avg_specificity=93.38% avg_auc=91.19%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.316752 Test loss=0.332567 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.29477137327194214
[5/24] Train loss=0.3255826234817505
[10/24] Train loss=0.3765769600868225
[15/24] Train loss=0.3192595839500427
[20/24] Train loss=0.291446328163147
Test set avg_accuracy=85.22% avg_sensitivity=63.70%, avg_specificity=93.38% avg_auc=91.19%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.315612 Test loss=0.332570 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=84.49% sen=74.36%, spe=88.33%, auc=90.79%!
Fold[3] Avg_overlap=0.64%(±0.23909413355166514)
[0/24] Train loss=0.8871643543243408
[5/24] Train loss=0.7671882510185242
[10/24] Train loss=0.7212221026420593
[15/24] Train loss=0.6703721880912781
[20/24] Train loss=0.6452993154525757
Test set avg_accuracy=73.22% avg_sensitivity=2.90%, avg_specificity=97.99% avg_auc=51.89%
Best model saved!! Metric=-100.00438019525302!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.713896 Test loss=0.600143 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6340834498405457
[5/24] Train loss=0.6097909808158875
[10/24] Train loss=0.63055819272995
[15/24] Train loss=0.6144644618034363
[20/24] Train loss=0.6102402210235596
Test set avg_accuracy=73.96% avg_sensitivity=0.30%, avg_specificity=99.91% avg_auc=55.01%
Best model saved!! Metric=-96.81557307496982!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.610505 Test loss=0.573807 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.5994725823402405
[5/24] Train loss=0.5755905508995056
[10/24] Train loss=0.6173585653305054
[15/24] Train loss=0.6088489890098572
[20/24] Train loss=0.5972731709480286
Test set avg_accuracy=73.95% avg_sensitivity=0.20%, avg_specificity=99.93% avg_auc=58.32%
Best model saved!! Metric=-93.6017824152999!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.593594 Test loss=0.568253 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.596146821975708
[5/24] Train loss=0.568949282169342
[10/24] Train loss=0.6168440580368042
[15/24] Train loss=0.6024816036224365
[20/24] Train loss=0.596594512462616
Test set avg_accuracy=73.96% avg_sensitivity=0.30%, avg_specificity=99.91% avg_auc=60.57%
Best model saved!! Metric=-91.26399070450687!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.589142 Test loss=0.564941 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5934144854545593
[5/24] Train loss=0.5663031935691833
[10/24] Train loss=0.6062179803848267
[15/24] Train loss=0.5969251394271851
[20/24] Train loss=0.5982456803321838
Test set avg_accuracy=73.98% avg_sensitivity=0.35%, avg_specificity=99.93% avg_auc=63.45%
Best model saved!! Metric=-88.28242732695766!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.584843 Test loss=0.559329 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5830633044242859
[5/24] Train loss=0.5565308928489685
[10/24] Train loss=0.6003269553184509
[15/24] Train loss=0.5829938650131226
[20/24] Train loss=0.5811687707901001
Test set avg_accuracy=73.97% avg_sensitivity=0.35%, avg_specificity=99.91% avg_auc=67.76%
Best model saved!! Metric=-84.01163743314885!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.575686 Test loss=0.551281 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5740746855735779
[5/24] Train loss=0.5495736598968506
[10/24] Train loss=0.5904964208602905
[15/24] Train loss=0.5781692862510681
[20/24] Train loss=0.5701610445976257
Test set avg_accuracy=74.00% avg_sensitivity=0.90%, avg_specificity=99.75% avg_auc=71.23%
Best model saved!! Metric=-80.1167782822854!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.568693 Test loss=0.544276 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5594620108604431
[5/24] Train loss=0.535463809967041
[10/24] Train loss=0.5899402499198914
[15/24] Train loss=0.5686330199241638
[20/24] Train loss=0.565329372882843
Test set avg_accuracy=74.00% avg_sensitivity=1.15%, avg_specificity=99.67% avg_auc=74.42%
Best model saved!! Metric=-76.76424166100279!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.560181 Test loss=0.534927 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5553536415100098
[5/24] Train loss=0.5257871150970459
[10/24] Train loss=0.577950119972229
[15/24] Train loss=0.5549376606941223
[20/24] Train loss=0.5518755912780762
Test set avg_accuracy=73.96% avg_sensitivity=1.70%, avg_specificity=99.42% avg_auc=77.47%
Best model saved!! Metric=-73.4528223320106!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.549529 Test loss=0.522861 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.541986882686615
[5/24] Train loss=0.5186074376106262
[10/24] Train loss=0.5639042854309082
[15/24] Train loss=0.5486636757850647
[20/24] Train loss=0.5374191403388977
Test set avg_accuracy=74.06% avg_sensitivity=3.30%, avg_specificity=99.00% avg_auc=79.89%
Best model saved!! Metric=-69.75573034599974!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.538340 Test loss=0.509065 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5282266139984131
[5/24] Train loss=0.5075158476829529
[10/24] Train loss=0.5561063289642334
[15/24] Train loss=0.539471447467804
[20/24] Train loss=0.5267543196678162
Test set avg_accuracy=74.39% avg_sensitivity=6.00%, avg_specificity=98.49% avg_auc=81.76%
Best model saved!! Metric=-65.37045474486628!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.526726 Test loss=0.493306 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5148986577987671
[5/24] Train loss=0.4856768548488617
[10/24] Train loss=0.5457528829574585
[15/24] Train loss=0.5226172208786011
[20/24] Train loss=0.5131291747093201
Test set avg_accuracy=74.83% avg_sensitivity=8.30%, avg_specificity=98.27% avg_auc=82.95%
Best model saved!! Metric=-61.64836831575958!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.512136 Test loss=0.478070 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4989822506904602
[5/24] Train loss=0.47507867217063904
[10/24] Train loss=0.5285460948944092
[15/24] Train loss=0.4982547461986542
[20/24] Train loss=0.4926677346229553
Test set avg_accuracy=75.62% avg_sensitivity=15.74%, avg_specificity=96.72% avg_auc=84.18%
Best model saved!! Metric=-53.73098180835625!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.495876 Test loss=0.459315 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4793703258037567
[5/24] Train loss=0.45535892248153687
[10/24] Train loss=0.5162666440010071
[15/24] Train loss=0.4874950349330902
[20/24] Train loss=0.4782457649707794
Test set avg_accuracy=77.06% avg_sensitivity=24.24%, avg_specificity=95.67% avg_auc=85.09%
Best model saved!! Metric=-43.950711463305566!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.479707 Test loss=0.442219 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.46803808212280273
[5/24] Train loss=0.43713343143463135
[10/24] Train loss=0.5053237676620483
[15/24] Train loss=0.468222439289093
[20/24] Train loss=0.46053028106689453
Test set avg_accuracy=78.71% avg_sensitivity=33.68%, avg_specificity=94.58% avg_auc=85.84%
Best model saved!! Metric=-33.189025003340696!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.465944 Test loss=0.427386 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4445715844631195
[5/24] Train loss=0.42331662774086
[10/24] Train loss=0.49374130368232727
[15/24] Train loss=0.45526596903800964
[20/24] Train loss=0.44826576113700867
Test set avg_accuracy=80.39% avg_sensitivity=42.98%, avg_specificity=93.57% avg_auc=86.65%
Best model saved!! Metric=-22.408895648198538!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.453697 Test loss=0.414529 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.43446022272109985
[5/24] Train loss=0.4163345992565155
[10/24] Train loss=0.4875240623950958
[15/24] Train loss=0.4460301697254181
[20/24] Train loss=0.4344874918460846
Test set avg_accuracy=81.17% avg_sensitivity=48.38%, avg_specificity=92.73% avg_auc=87.08%
Best model saved!! Metric=-16.644211146044775!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.442125 Test loss=0.404670 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.42523252964019775
[5/24] Train loss=0.4133451581001282
[10/24] Train loss=0.47769200801849365
[15/24] Train loss=0.43882665038108826
[20/24] Train loss=0.41928237676620483
Test set avg_accuracy=81.48% avg_sensitivity=49.23%, avg_specificity=92.85% avg_auc=87.61%
Best model saved!! Metric=-14.83052917847953!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.432081 Test loss=0.394411 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4145048260688782
[5/24] Train loss=0.3964274823665619
[10/24] Train loss=0.4549928903579712
[15/24] Train loss=0.4330347776412964
[20/24] Train loss=0.4092041552066803
Test set avg_accuracy=81.93% avg_sensitivity=48.08%, avg_specificity=93.85% avg_auc=88.24%
Best model saved!! Metric=-13.903743461404552!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.419835 Test loss=0.383177 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3935726583003998
[5/24] Train loss=0.38310766220092773
[10/24] Train loss=0.445954293012619
[15/24] Train loss=0.41496706008911133
[20/24] Train loss=0.39289554953575134
Test set avg_accuracy=82.28% avg_sensitivity=49.33%, avg_specificity=93.89% avg_auc=88.62%
Best model saved!! Metric=-11.889321600452853!!
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.406361 Test loss=0.375909 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.38394656777381897
[5/24] Train loss=0.3700012266635895
[10/24] Train loss=0.43462666869163513
[15/24] Train loss=0.39792752265930176
[20/24] Train loss=0.38328585028648376
Test set avg_accuracy=82.92% avg_sensitivity=55.52%, avg_specificity=92.57% avg_auc=89.01%
Best model saved!! Metric=-5.9816517388426576!!
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.393752 Test loss=0.367691 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3774765431880951
[5/24] Train loss=0.36409643292427063
[10/24] Train loss=0.4159550070762634
[15/24] Train loss=0.38354602456092834
[20/24] Train loss=0.3722907304763794
Test set avg_accuracy=83.06% avg_sensitivity=56.32%, avg_specificity=92.48% avg_auc=89.22%
Best model saved!! Metric=-4.917114428924165!!
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.384603 Test loss=0.362712 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3584364056587219
[5/24] Train loss=0.35872724652290344
[10/24] Train loss=0.40986618399620056
[15/24] Train loss=0.37255239486694336
[20/24] Train loss=0.362396776676178
Test set avg_accuracy=82.90% avg_sensitivity=52.92%, avg_specificity=93.47% avg_auc=89.43%
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.378600 Test loss=0.360065 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3543316125869751
[5/24] Train loss=0.35124194622039795
[10/24] Train loss=0.4097319543361664
[15/24] Train loss=0.36795422434806824
[20/24] Train loss=0.35259854793548584
Test set avg_accuracy=82.70% avg_sensitivity=50.97%, avg_specificity=93.87% avg_auc=89.55%
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.373174 Test loss=0.359168 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3513937294483185
[5/24] Train loss=0.3437204360961914
[10/24] Train loss=0.4054962396621704
[15/24] Train loss=0.3753586709499359
[20/24] Train loss=0.3520987629890442
Test set avg_accuracy=82.80% avg_sensitivity=50.22%, avg_specificity=94.28% avg_auc=89.64%
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.369391 Test loss=0.359128 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3460724353790283
[5/24] Train loss=0.3469369411468506
[10/24] Train loss=0.39829933643341064
[15/24] Train loss=0.37050962448120117
[20/24] Train loss=0.3489574193954468
Test set avg_accuracy=83.05% avg_sensitivity=51.72%, avg_specificity=94.08% avg_auc=89.65%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.364325 Test loss=0.357666 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.33823877573013306
[5/24] Train loss=0.3438255488872528
[10/24] Train loss=0.39578238129615784
[15/24] Train loss=0.37376201152801514
[20/24] Train loss=0.35384923219680786
Test set avg_accuracy=83.55% avg_sensitivity=56.27%, avg_specificity=93.17% avg_auc=89.85%
Best model saved!! Metric=-3.158445104326482!!
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.361145 Test loss=0.352095 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.34161099791526794
[5/24] Train loss=0.33732131123542786
[10/24] Train loss=0.39171072840690613
[15/24] Train loss=0.36918845772743225
[20/24] Train loss=0.3491024971008301
Test set avg_accuracy=83.58% avg_sensitivity=55.57%, avg_specificity=93.45% avg_auc=89.90%
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.358104 Test loss=0.351545 Current lr=[0.000210185142098938]

[0/24] Train loss=0.33296525478363037
[5/24] Train loss=0.33895930647850037
[10/24] Train loss=0.38552024960517883
[15/24] Train loss=0.36348605155944824
[20/24] Train loss=0.3460484743118286
Test set avg_accuracy=83.19% avg_sensitivity=50.07%, avg_specificity=94.86% avg_auc=89.97%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.355161 Test loss=0.355632 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.33059075474739075
[5/24] Train loss=0.34184303879737854
[10/24] Train loss=0.39026084542274475
[15/24] Train loss=0.3567696213722229
[20/24] Train loss=0.3386712670326233
Test set avg_accuracy=83.12% avg_sensitivity=51.47%, avg_specificity=94.28% avg_auc=90.02%
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.353030 Test loss=0.352150 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.330372154712677
[5/24] Train loss=0.3427707254886627
[10/24] Train loss=0.3876999318599701
[15/24] Train loss=0.3646543025970459
[20/24] Train loss=0.3431767225265503
Test set avg_accuracy=83.29% avg_sensitivity=52.47%, avg_specificity=94.15% avg_auc=90.05%
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.352712 Test loss=0.351000 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3266929090023041
[5/24] Train loss=0.3426204323768616
[10/24] Train loss=0.38557034730911255
[15/24] Train loss=0.36022868752479553
[20/24] Train loss=0.34455397725105286
Test set avg_accuracy=83.48% avg_sensitivity=52.12%, avg_specificity=94.52% avg_auc=90.12%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.351182 Test loss=0.350839 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.326788991689682
[5/24] Train loss=0.3426716923713684
[10/24] Train loss=0.38586166501045227
[15/24] Train loss=0.3672512173652649
[20/24] Train loss=0.33760887384414673
Test set avg_accuracy=83.28% avg_sensitivity=50.62%, avg_specificity=94.79% avg_auc=90.11%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.349748 Test loss=0.352761 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.32552218437194824
[5/24] Train loss=0.3459151089191437
[10/24] Train loss=0.38594844937324524
[15/24] Train loss=0.3679348826408386
[20/24] Train loss=0.3407106399536133
Test set avg_accuracy=83.45% avg_sensitivity=52.27%, avg_specificity=94.44% avg_auc=90.13%
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.349926 Test loss=0.350580 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3237268030643463
[5/24] Train loss=0.3440747857093811
[10/24] Train loss=0.3842089772224426
[15/24] Train loss=0.36088263988494873
[20/24] Train loss=0.3407617211341858
Test set avg_accuracy=83.36% avg_sensitivity=51.37%, avg_specificity=94.63% avg_auc=90.13%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.349586 Test loss=0.351614 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.32449355721473694
[5/24] Train loss=0.3335503041744232
[10/24] Train loss=0.3826952874660492
[15/24] Train loss=0.36385679244995117
[20/24] Train loss=0.33697086572647095
Test set avg_accuracy=83.59% avg_sensitivity=52.82%, avg_specificity=94.44% avg_auc=90.15%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.347959 Test loss=0.349635 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3263608515262604
[5/24] Train loss=0.34314584732055664
[10/24] Train loss=0.38226351141929626
[15/24] Train loss=0.3682410717010498
[20/24] Train loss=0.3383534252643585
Test set avg_accuracy=83.93% avg_sensitivity=55.17%, avg_specificity=94.07% avg_auc=90.26%
Best model saved!! Metric=-2.571036524845951!!
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.347326 Test loss=0.346428 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3163982331752777
[5/24] Train loss=0.33345311880111694
[10/24] Train loss=0.3774526119232178
[15/24] Train loss=0.3570263981819153
[20/24] Train loss=0.33549320697784424
Test set avg_accuracy=83.63% avg_sensitivity=53.77%, avg_specificity=94.15% avg_auc=90.23%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.344804 Test loss=0.347698 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.31968456506729126
[5/24] Train loss=0.3366857171058655
[10/24] Train loss=0.378153532743454
[15/24] Train loss=0.360527366399765
[20/24] Train loss=0.3322492241859436
Test set avg_accuracy=83.71% avg_sensitivity=53.67%, avg_specificity=94.29% avg_auc=90.28%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.344100 Test loss=0.347451 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3241274654865265
[5/24] Train loss=0.339701384305954
[10/24] Train loss=0.3793485760688782
[15/24] Train loss=0.35425078868865967
[20/24] Train loss=0.3376308083534241
Test set avg_accuracy=83.37% avg_sensitivity=51.17%, avg_specificity=94.72% avg_auc=90.32%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.343826 Test loss=0.349491 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.31955453753471375
[5/24] Train loss=0.34011805057525635
[10/24] Train loss=0.38142868876457214
[15/24] Train loss=0.35632288455963135
[20/24] Train loss=0.3287384808063507
Test set avg_accuracy=84.09% avg_sensitivity=55.92%, avg_specificity=94.01% avg_auc=90.28%
Best model saved!! Metric=-1.6936908303969958!!
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.343519 Test loss=0.345210 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.31777453422546387
[5/24] Train loss=0.33265769481658936
[10/24] Train loss=0.3793211579322815
[15/24] Train loss=0.36135077476501465
[20/24] Train loss=0.3319263756275177
Test set avg_accuracy=83.98% avg_sensitivity=55.47%, avg_specificity=94.03% avg_auc=90.38%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.341539 Test loss=0.344757 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.31516823172569275
[5/24] Train loss=0.3383748531341553
[10/24] Train loss=0.3770759105682373
[15/24] Train loss=0.35964536666870117
[20/24] Train loss=0.33840441703796387
Test set avg_accuracy=83.87% avg_sensitivity=54.72%, avg_specificity=94.14% avg_auc=90.35%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.341223 Test loss=0.345189 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3134905695915222
[5/24] Train loss=0.33764591813087463
[10/24] Train loss=0.37410077452659607
[15/24] Train loss=0.36036252975463867
[20/24] Train loss=0.33295339345932007
Test set avg_accuracy=84.06% avg_sensitivity=55.77%, avg_specificity=94.03% avg_auc=90.34%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.341258 Test loss=0.344997 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3140324652194977
[5/24] Train loss=0.3326195478439331
[10/24] Train loss=0.3756133019924164
[15/24] Train loss=0.35985612869262695
[20/24] Train loss=0.3323677182197571
Test set avg_accuracy=84.00% avg_sensitivity=55.67%, avg_specificity=93.98% avg_auc=90.36%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.339506 Test loss=0.344308 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3077860176563263
[5/24] Train loss=0.3335471451282501
[10/24] Train loss=0.374483585357666
[15/24] Train loss=0.3523159921169281
[20/24] Train loss=0.32821208238601685
Test set avg_accuracy=84.36% avg_sensitivity=58.12%, avg_specificity=93.61% avg_auc=90.46%
Best model saved!! Metric=0.5500240771221669!!
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.338459 Test loss=0.341030 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.31016504764556885
[5/24] Train loss=0.3283677399158478
[10/24] Train loss=0.369792640209198
[15/24] Train loss=0.3556932508945465
[20/24] Train loss=0.32850590348243713
Test set avg_accuracy=83.89% avg_sensitivity=54.77%, avg_specificity=94.15% avg_auc=90.43%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.337087 Test loss=0.343867 Current lr=[0.000299720220882401]

[0/24] Train loss=0.31237927079200745
[5/24] Train loss=0.3303711712360382
[10/24] Train loss=0.37047305703163147
[15/24] Train loss=0.3560639023780823
[20/24] Train loss=0.32927626371383667
Test set avg_accuracy=84.19% avg_sensitivity=57.22%, avg_specificity=93.70% avg_auc=90.44%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.337321 Test loss=0.341782 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3135889172554016
[5/24] Train loss=0.33479610085487366
[10/24] Train loss=0.3757339119911194
[15/24] Train loss=0.3522421717643738
[20/24] Train loss=0.32605600357055664
Test set avg_accuracy=84.18% avg_sensitivity=56.62%, avg_specificity=93.89% avg_auc=90.43%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.336574 Test loss=0.342545 Current lr=[0.000298904600941902]

[0/24] Train loss=0.30813848972320557
[5/24] Train loss=0.3341081142425537
[10/24] Train loss=0.37547367811203003
[15/24] Train loss=0.3447455167770386
[20/24] Train loss=0.32707348465919495
Test set avg_accuracy=84.06% avg_sensitivity=56.42%, avg_specificity=93.80% avg_auc=90.36%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.335935 Test loss=0.343629 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.31248000264167786
[5/24] Train loss=0.32950523495674133
[10/24] Train loss=0.3746199607849121
[15/24] Train loss=0.3538742959499359
[20/24] Train loss=0.3284732401371002
Test set avg_accuracy=84.14% avg_sensitivity=56.82%, avg_specificity=93.77% avg_auc=90.41%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.335764 Test loss=0.342491 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3121049404144287
[5/24] Train loss=0.3320700526237488
[10/24] Train loss=0.3697703182697296
[15/24] Train loss=0.34575778245925903
[20/24] Train loss=0.322247713804245
Test set avg_accuracy=84.73% avg_sensitivity=60.87%, avg_specificity=93.13% avg_auc=90.49%
Best model saved!! Metric=3.2175587697820163!!
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.334831 Test loss=0.338821 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3086191415786743
[5/24] Train loss=0.3310244381427765
[10/24] Train loss=0.3721034526824951
[15/24] Train loss=0.3474997878074646
[20/24] Train loss=0.3215236961841583
Test set avg_accuracy=84.24% avg_sensitivity=57.62%, avg_specificity=93.63% avg_auc=90.51%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.333997 Test loss=0.340491 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.30804622173309326
[5/24] Train loss=0.3308829069137573
[10/24] Train loss=0.37102439999580383
[15/24] Train loss=0.350698322057724
[20/24] Train loss=0.33230897784233093
Test set avg_accuracy=84.38% avg_sensitivity=58.27%, avg_specificity=93.57% avg_auc=90.46%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.334452 Test loss=0.340925 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3074653148651123
[5/24] Train loss=0.3286079466342926
[10/24] Train loss=0.37239548563957214
[15/24] Train loss=0.34471264481544495
[20/24] Train loss=0.32533013820648193
Test set avg_accuracy=84.47% avg_sensitivity=58.12%, avg_specificity=93.75% avg_auc=90.52%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.332588 Test loss=0.340268 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3070325255393982
[5/24] Train loss=0.3295728266239166
[10/24] Train loss=0.3712640702724457
[15/24] Train loss=0.3496381342411041
[20/24] Train loss=0.32717370986938477
Test set avg_accuracy=84.60% avg_sensitivity=59.62%, avg_specificity=93.40% avg_auc=90.52%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.333891 Test loss=0.339197 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3065127432346344
[5/24] Train loss=0.3327163755893707
[10/24] Train loss=0.3698104918003082
[15/24] Train loss=0.34526383876800537
[20/24] Train loss=0.3213742971420288
Test set avg_accuracy=84.74% avg_sensitivity=60.47%, avg_specificity=93.29% avg_auc=90.49%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.331966 Test loss=0.339170 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.30582869052886963
[5/24] Train loss=0.3254885971546173
[10/24] Train loss=0.3700987994670868
[15/24] Train loss=0.3456982970237732
[20/24] Train loss=0.31839892268180847
Test set avg_accuracy=84.73% avg_sensitivity=60.92%, avg_specificity=93.11% avg_auc=90.59%
Best model saved!! Metric=3.350750670045983!!
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.331301 Test loss=0.337224 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.30446678400039673
[5/24] Train loss=0.32872503995895386
[10/24] Train loss=0.36668598651885986
[15/24] Train loss=0.34632551670074463
[20/24] Train loss=0.31864550709724426
Test set avg_accuracy=84.75% avg_sensitivity=60.37%, avg_specificity=93.34% avg_auc=90.60%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.330334 Test loss=0.337565 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.30488839745521545
[5/24] Train loss=0.3264237344264984
[10/24] Train loss=0.3693079650402069
[15/24] Train loss=0.34524428844451904
[20/24] Train loss=0.32583925127983093
Test set avg_accuracy=84.44% avg_sensitivity=59.22%, avg_specificity=93.33% avg_auc=90.54%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.330651 Test loss=0.339036 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3022047281265259
[5/24] Train loss=0.32692375779151917
[10/24] Train loss=0.3730038106441498
[15/24] Train loss=0.3432982265949249
[20/24] Train loss=0.31534621119499207
Test set avg_accuracy=84.49% avg_sensitivity=58.57%, avg_specificity=93.63% avg_auc=90.62%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.330573 Test loss=0.338337 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.300287127494812
[5/24] Train loss=0.32816144824028015
[10/24] Train loss=0.36999112367630005
[15/24] Train loss=0.3439488410949707
[20/24] Train loss=0.3198852837085724
Test set avg_accuracy=84.54% avg_sensitivity=59.22%, avg_specificity=93.47% avg_auc=90.50%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.330528 Test loss=0.339835 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.30433642864227295
[5/24] Train loss=0.3313547968864441
[10/24] Train loss=0.373869925737381
[15/24] Train loss=0.3439212441444397
[20/24] Train loss=0.3210914731025696
Test set avg_accuracy=84.49% avg_sensitivity=59.07%, avg_specificity=93.45% avg_auc=90.62%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.330180 Test loss=0.337971 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.30711403489112854
[5/24] Train loss=0.32465046644210815
[10/24] Train loss=0.36867043375968933
[15/24] Train loss=0.3409018814563751
[20/24] Train loss=0.3171755075454712
Test set avg_accuracy=84.77% avg_sensitivity=61.02%, avg_specificity=93.13% avg_auc=90.65%
Best model saved!! Metric=3.5697372949706647!!
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.327679 Test loss=0.336130 Current lr=[0.000276307469034998]

[0/24] Train loss=0.30385029315948486
[5/24] Train loss=0.32656487822532654
[10/24] Train loss=0.3699779212474823
[15/24] Train loss=0.34386736154556274
[20/24] Train loss=0.31127771735191345
Test set avg_accuracy=84.87% avg_sensitivity=62.42%, avg_specificity=92.78% avg_auc=90.59%
Best model saved!! Metric=4.656367475434237!!
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.328842 Test loss=0.336614 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3044489026069641
[5/24] Train loss=0.3208594024181366
[10/24] Train loss=0.3690098524093628
[15/24] Train loss=0.34032517671585083
[20/24] Train loss=0.31755563616752625
Test set avg_accuracy=84.62% avg_sensitivity=60.52%, avg_specificity=93.11% avg_auc=90.63%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.327005 Test loss=0.336856 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.30261558294296265
[5/24] Train loss=0.32660388946533203
[10/24] Train loss=0.36945492029190063
[15/24] Train loss=0.3358093202114105
[20/24] Train loss=0.31996163725852966
Test set avg_accuracy=84.77% avg_sensitivity=60.62%, avg_specificity=93.27% avg_auc=90.66%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.327935 Test loss=0.336362 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3043726682662964
[5/24] Train loss=0.3239329159259796
[10/24] Train loss=0.3667861819267273
[15/24] Train loss=0.3366395831108093
[20/24] Train loss=0.314955472946167
Test set avg_accuracy=84.77% avg_sensitivity=61.37%, avg_specificity=93.01% avg_auc=90.64%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.327004 Test loss=0.336204 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3049212396144867
[5/24] Train loss=0.3240342140197754
[10/24] Train loss=0.364324688911438
[15/24] Train loss=0.3366931974887848
[20/24] Train loss=0.3145192563533783
Test set avg_accuracy=84.75% avg_sensitivity=61.27%, avg_specificity=93.03% avg_auc=90.66%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.327199 Test loss=0.335792 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.29865777492523193
[5/24] Train loss=0.3228403925895691
[10/24] Train loss=0.37336045503616333
[15/24] Train loss=0.33951207995414734
[20/24] Train loss=0.3123233914375305
Test set avg_accuracy=84.64% avg_sensitivity=59.67%, avg_specificity=93.43% avg_auc=90.64%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.325932 Test loss=0.337231 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3011130690574646
[5/24] Train loss=0.32325032353401184
[10/24] Train loss=0.3661845028400421
[15/24] Train loss=0.33246859908103943
[20/24] Train loss=0.3161335289478302
Test set avg_accuracy=84.75% avg_sensitivity=61.12%, avg_specificity=93.08% avg_auc=90.68%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.325493 Test loss=0.335715 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.30401769280433655
[5/24] Train loss=0.32025185227394104
[10/24] Train loss=0.36774352192878723
[15/24] Train loss=0.3307931423187256
[20/24] Train loss=0.3091781735420227
Test set avg_accuracy=84.60% avg_sensitivity=60.17%, avg_specificity=93.20% avg_auc=90.74%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.325620 Test loss=0.334930 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3041130304336548
[5/24] Train loss=0.31931522488594055
[10/24] Train loss=0.36379146575927734
[15/24] Train loss=0.33501890301704407
[20/24] Train loss=0.31401297450065613
Test set avg_accuracy=84.77% avg_sensitivity=61.22%, avg_specificity=93.06% avg_auc=90.71%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.325804 Test loss=0.334821 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3026527464389801
[5/24] Train loss=0.32190874218940735
[10/24] Train loss=0.36511480808258057
[15/24] Train loss=0.3322966992855072
[20/24] Train loss=0.31665822863578796
Test set avg_accuracy=84.66% avg_sensitivity=60.57%, avg_specificity=93.15% avg_auc=90.72%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.325602 Test loss=0.335218 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.30055734515190125
[5/24] Train loss=0.32136183977127075
[10/24] Train loss=0.367628812789917
[15/24] Train loss=0.33478203415870667
[20/24] Train loss=0.3098558485507965
Test set avg_accuracy=84.87% avg_sensitivity=61.37%, avg_specificity=93.15% avg_auc=90.72%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.324581 Test loss=0.334795 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.30166226625442505
[5/24] Train loss=0.3202253580093384
[10/24] Train loss=0.3677230477333069
[15/24] Train loss=0.32915377616882324
[20/24] Train loss=0.3083479404449463
Test set avg_accuracy=84.74% avg_sensitivity=59.97%, avg_specificity=93.47% avg_auc=90.77%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.322774 Test loss=0.334840 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.29959890246391296
[5/24] Train loss=0.31898024678230286
[10/24] Train loss=0.3663861155509949
[15/24] Train loss=0.33444780111312866
[20/24] Train loss=0.3095134496688843
Test set avg_accuracy=85.04% avg_sensitivity=63.12%, avg_specificity=92.76% avg_auc=90.81%
Best model saved!! Metric=5.7268913272662445!!
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.323736 Test loss=0.332692 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.29761549830436707
[5/24] Train loss=0.32120510935783386
[10/24] Train loss=0.3617456555366516
[15/24] Train loss=0.33142638206481934
[20/24] Train loss=0.3150120675563812
Test set avg_accuracy=84.77% avg_sensitivity=61.27%, avg_specificity=93.04% avg_auc=90.79%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.323317 Test loss=0.333545 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3016898036003113
[5/24] Train loss=0.31578898429870605
[10/24] Train loss=0.364690363407135
[15/24] Train loss=0.32866957783699036
[20/24] Train loss=0.3117397427558899
Test set avg_accuracy=84.79% avg_sensitivity=61.22%, avg_specificity=93.10% avg_auc=90.77%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.323267 Test loss=0.333995 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3007843792438507
[5/24] Train loss=0.316731333732605
[10/24] Train loss=0.36729469895362854
[15/24] Train loss=0.331743448972702
[20/24] Train loss=0.3103199601173401
Test set avg_accuracy=84.65% avg_sensitivity=60.42%, avg_specificity=93.19% avg_auc=90.82%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.323513 Test loss=0.333419 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2988019287586212
[5/24] Train loss=0.3189384341239929
[10/24] Train loss=0.36753788590431213
[15/24] Train loss=0.3279348611831665
[20/24] Train loss=0.3077545464038849
Test set avg_accuracy=84.57% avg_sensitivity=59.97%, avg_specificity=93.24% avg_auc=90.74%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.323164 Test loss=0.334992 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2992826998233795
[5/24] Train loss=0.3221740126609802
[10/24] Train loss=0.3688218295574188
[15/24] Train loss=0.3303069472312927
[20/24] Train loss=0.31281930208206177
Test set avg_accuracy=84.54% avg_sensitivity=59.22%, avg_specificity=93.47% avg_auc=90.78%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.323046 Test loss=0.335305 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.29881393909454346
[5/24] Train loss=0.3172314465045929
[10/24] Train loss=0.36749058961868286
[15/24] Train loss=0.32533368468284607
[20/24] Train loss=0.3137795925140381
Test set avg_accuracy=84.64% avg_sensitivity=60.72%, avg_specificity=93.06% avg_auc=90.80%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.323473 Test loss=0.333509 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2975773215293884
[5/24] Train loss=0.3201916813850403
[10/24] Train loss=0.36866238713264465
[15/24] Train loss=0.3309036195278168
[20/24] Train loss=0.3067726790904999
Test set avg_accuracy=84.86% avg_sensitivity=61.52%, avg_specificity=93.08% avg_auc=90.81%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.322263 Test loss=0.333110 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2921457588672638
[5/24] Train loss=0.3138289749622345
[10/24] Train loss=0.37278786301612854
[15/24] Train loss=0.32502084970474243
[20/24] Train loss=0.30942147970199585
Test set avg_accuracy=84.77% avg_sensitivity=60.77%, avg_specificity=93.22% avg_auc=90.83%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.321320 Test loss=0.333140 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.30018553137779236
[5/24] Train loss=0.3137242794036865
[10/24] Train loss=0.3689352869987488
[15/24] Train loss=0.32872653007507324
[20/24] Train loss=0.30897918343544006
Test set avg_accuracy=85.03% avg_sensitivity=63.32%, avg_specificity=92.67% avg_auc=90.82%
Best model saved!! Metric=5.844096805323787!!
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.320317 Test loss=0.331994 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.29459699988365173
[5/24] Train loss=0.313727468252182
[10/24] Train loss=0.3653087317943573
[15/24] Train loss=0.3334500789642334
[20/24] Train loss=0.3037325143814087
Test set avg_accuracy=84.74% avg_sensitivity=60.87%, avg_specificity=93.15% avg_auc=90.84%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.319621 Test loss=0.332879 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.29631102085113525
[5/24] Train loss=0.31407296657562256
[10/24] Train loss=0.3682096004486084
[15/24] Train loss=0.3307238519191742
[20/24] Train loss=0.31068307161331177
Test set avg_accuracy=84.91% avg_sensitivity=63.22%, avg_specificity=92.55% avg_auc=90.83%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.321151 Test loss=0.331790 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2994629144668579
[5/24] Train loss=0.3173299729824066
[10/24] Train loss=0.36278995871543884
[15/24] Train loss=0.3296833634376526
[20/24] Train loss=0.30212923884391785
Test set avg_accuracy=84.83% avg_sensitivity=63.02%, avg_specificity=92.52% avg_auc=90.82%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.319517 Test loss=0.331870 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2953600585460663
[5/24] Train loss=0.3169378340244293
[10/24] Train loss=0.3654145896434784
[15/24] Train loss=0.3366039991378784
[20/24] Train loss=0.3059142827987671
Test set avg_accuracy=85.05% avg_sensitivity=63.87%, avg_specificity=92.52% avg_auc=90.81%
Best model saved!! Metric=6.247811054962931!!
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.320055 Test loss=0.331911 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2990093529224396
[5/24] Train loss=0.31222033500671387
[10/24] Train loss=0.3681457042694092
[15/24] Train loss=0.32736942172050476
[20/24] Train loss=0.3058511018753052
Test set avg_accuracy=84.84% avg_sensitivity=62.22%, avg_specificity=92.82% avg_auc=90.84%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.319195 Test loss=0.331929 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.29486554861068726
[5/24] Train loss=0.31454014778137207
[10/24] Train loss=0.37094008922576904
[15/24] Train loss=0.326900839805603
[20/24] Train loss=0.3072238564491272
Test set avg_accuracy=84.83% avg_sensitivity=62.27%, avg_specificity=92.78% avg_auc=90.83%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.318842 Test loss=0.332171 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2975761592388153
[5/24] Train loss=0.31585270166397095
[10/24] Train loss=0.36590680480003357
[15/24] Train loss=0.32700055837631226
[20/24] Train loss=0.3041752874851227
Test set avg_accuracy=84.92% avg_sensitivity=62.52%, avg_specificity=92.82% avg_auc=90.88%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.318514 Test loss=0.331340 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.29818522930145264
[5/24] Train loss=0.3169783353805542
[10/24] Train loss=0.36508893966674805
[15/24] Train loss=0.32635626196861267
[20/24] Train loss=0.3022128939628601
Test set avg_accuracy=84.92% avg_sensitivity=63.57%, avg_specificity=92.45% avg_auc=90.86%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.318137 Test loss=0.331133 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.29665592312812805
[5/24] Train loss=0.31227198243141174
[10/24] Train loss=0.365909606218338
[15/24] Train loss=0.3282383978366852
[20/24] Train loss=0.3035171329975128
Test set avg_accuracy=84.93% avg_sensitivity=62.97%, avg_specificity=92.67% avg_auc=90.86%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.318889 Test loss=0.331392 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2939717769622803
[5/24] Train loss=0.3127056956291199
[10/24] Train loss=0.36537840962409973
[15/24] Train loss=0.3291756510734558
[20/24] Train loss=0.3014847934246063
Test set avg_accuracy=84.93% avg_sensitivity=63.22%, avg_specificity=92.59% avg_auc=90.84%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.318360 Test loss=0.331442 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2962836027145386
[5/24] Train loss=0.31196001172065735
[10/24] Train loss=0.36123278737068176
[15/24] Train loss=0.3251133859157562
[20/24] Train loss=0.29984965920448303
Test set avg_accuracy=84.74% avg_sensitivity=61.32%, avg_specificity=92.99% avg_auc=90.85%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.317746 Test loss=0.332215 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2992091476917267
[5/24] Train loss=0.31381458044052124
[10/24] Train loss=0.364088773727417
[15/24] Train loss=0.33102336525917053
[20/24] Train loss=0.2976653277873993
Test set avg_accuracy=84.70% avg_sensitivity=62.57%, avg_specificity=92.50% avg_auc=90.75%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.318738 Test loss=0.332962 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.298854261636734
[5/24] Train loss=0.3111737370491028
[10/24] Train loss=0.3680826425552368
[15/24] Train loss=0.32211196422576904
[20/24] Train loss=0.29594263434410095
Test set avg_accuracy=84.54% avg_sensitivity=61.42%, avg_specificity=92.69% avg_auc=90.79%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.320176 Test loss=0.332807 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.2929515242576599
[5/24] Train loss=0.3167882263660431
[10/24] Train loss=0.3669062554836273
[15/24] Train loss=0.31761443614959717
[20/24] Train loss=0.2986762523651123
Test set avg_accuracy=84.92% avg_sensitivity=65.12%, avg_specificity=91.90% avg_auc=90.81%
Best model saved!! Metric=6.748683553814303!!
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.320711 Test loss=0.331317 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.2962036430835724
[5/24] Train loss=0.31940045952796936
[10/24] Train loss=0.36588865518569946
[15/24] Train loss=0.3196435272693634
[20/24] Train loss=0.31032291054725647
Test set avg_accuracy=85.29% avg_sensitivity=69.97%, avg_specificity=90.68% avg_auc=90.70%
Best model saved!! Metric=10.634424075765878!!
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.321792 Test loss=0.334665 Current lr=[0.000134135431043539]

[0/24] Train loss=0.30351653695106506
[5/24] Train loss=0.31236910820007324
[10/24] Train loss=0.36600548028945923
[15/24] Train loss=0.31698641180992126
[20/24] Train loss=0.30489617586135864
Test set avg_accuracy=85.43% avg_sensitivity=68.72%, avg_specificity=91.32% avg_auc=90.59%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.318899 Test loss=0.335693 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.30406031012535095
[5/24] Train loss=0.31428492069244385
[10/24] Train loss=0.36739709973335266
[15/24] Train loss=0.3187768757343292
[20/24] Train loss=0.30000174045562744
Test set avg_accuracy=85.29% avg_sensitivity=67.52%, avg_specificity=91.55% avg_auc=90.76%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.318656 Test loss=0.332378 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.29795482754707336
[5/24] Train loss=0.31328141689300537
[10/24] Train loss=0.3622285723686218
[15/24] Train loss=0.3141574561595917
[20/24] Train loss=0.3049640357494354
Test set avg_accuracy=85.29% avg_sensitivity=68.07%, avg_specificity=91.35% avg_auc=90.75%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.317340 Test loss=0.332609 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.2986755669116974
[5/24] Train loss=0.3129752576351166
[10/24] Train loss=0.36877596378326416
[15/24] Train loss=0.3167559504508972
[20/24] Train loss=0.3006053566932678
Test set avg_accuracy=85.31% avg_sensitivity=68.47%, avg_specificity=91.25% avg_auc=90.69%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.318705 Test loss=0.333899 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3025760352611542
[5/24] Train loss=0.3108556270599365
[10/24] Train loss=0.3712122142314911
[15/24] Train loss=0.3173949718475342
[20/24] Train loss=0.3018970787525177
Test set avg_accuracy=85.26% avg_sensitivity=67.77%, avg_specificity=91.42% avg_auc=90.80%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.318739 Test loss=0.331902 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3010096251964569
[5/24] Train loss=0.309096097946167
[10/24] Train loss=0.3721114695072174
[15/24] Train loss=0.3217507302761078
[20/24] Train loss=0.3023478388786316
Test set avg_accuracy=85.36% avg_sensitivity=70.21%, avg_specificity=90.70% avg_auc=90.85%
Best model saved!! Metric=11.13570428808751!!
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.318629 Test loss=0.331780 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.29818829894065857
[5/24] Train loss=0.3144528865814209
[10/24] Train loss=0.36341267824172974
[15/24] Train loss=0.32146143913269043
[20/24] Train loss=0.30287259817123413
Test set avg_accuracy=85.10% avg_sensitivity=70.71%, avg_specificity=90.17% avg_auc=90.75%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.318471 Test loss=0.334642 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.30557286739349365
[5/24] Train loss=0.317629873752594
[10/24] Train loss=0.366449236869812
[15/24] Train loss=0.3243929147720337
[20/24] Train loss=0.3015635907649994
Test set avg_accuracy=85.08% avg_sensitivity=70.86%, avg_specificity=90.09% avg_auc=90.79%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.318813 Test loss=0.334126 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3030824363231659
[5/24] Train loss=0.31921660900115967
[10/24] Train loss=0.3692368268966675
[15/24] Train loss=0.3197454512119293
[20/24] Train loss=0.29906585812568665
Test set avg_accuracy=85.16% avg_sensitivity=71.56%, avg_specificity=89.95% avg_auc=90.78%
Best model saved!! Metric=11.448610599063016!!
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.317857 Test loss=0.334926 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.30100661516189575
[5/24] Train loss=0.3192962110042572
[10/24] Train loss=0.37300214171409607
[15/24] Train loss=0.3223191797733307
[20/24] Train loss=0.29728958010673523
Test set avg_accuracy=85.34% avg_sensitivity=72.86%, avg_specificity=89.73% avg_auc=90.76%
Best model saved!! Metric=12.694131876492193!!
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.318521 Test loss=0.336396 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3040587902069092
[5/24] Train loss=0.3183871805667877
[10/24] Train loss=0.3722315728664398
[15/24] Train loss=0.3215121328830719
[20/24] Train loss=0.3006496727466583
Test set avg_accuracy=85.10% avg_sensitivity=74.46%, avg_specificity=88.85% avg_auc=90.68%
Best model saved!! Metric=13.098027281701647!!
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.318292 Test loss=0.340873 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3118329644203186
[5/24] Train loss=0.3300696313381195
[10/24] Train loss=0.37548136711120605
[15/24] Train loss=0.3190135359764099
[20/24] Train loss=0.31347593665122986
Test set avg_accuracy=84.66% avg_sensitivity=76.16%, avg_specificity=87.66% avg_auc=90.60%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.321306 Test loss=0.346582 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3183119595050812
[5/24] Train loss=0.32854795455932617
[10/24] Train loss=0.37088271975517273
[15/24] Train loss=0.3162584900856018
[20/24] Train loss=0.3291538953781128
Test set avg_accuracy=84.97% avg_sensitivity=74.01%, avg_specificity=88.84% avg_auc=90.75%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.323456 Test loss=0.339771 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3034711480140686
[5/24] Train loss=0.31005752086639404
[10/24] Train loss=0.3644864559173584
[15/24] Train loss=0.32057473063468933
[20/24] Train loss=0.32129040360450745
Test set avg_accuracy=85.18% avg_sensitivity=69.67%, avg_specificity=90.65% avg_auc=90.90%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.320359 Test loss=0.330998 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.2993306517601013
[5/24] Train loss=0.31008899211883545
[10/24] Train loss=0.3630690574645996
[15/24] Train loss=0.3201386332511902
[20/24] Train loss=0.3137359917163849
Test set avg_accuracy=85.18% avg_sensitivity=69.82%, avg_specificity=90.60% avg_auc=90.91%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.316497 Test loss=0.331511 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.30117252469062805
[5/24] Train loss=0.31279900670051575
[10/24] Train loss=0.3679282069206238
[15/24] Train loss=0.3169465661048889
[20/24] Train loss=0.31210780143737793
Test set avg_accuracy=85.20% avg_sensitivity=71.26%, avg_specificity=90.10% avg_auc=90.90%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.317102 Test loss=0.333265 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3012647330760956
[5/24] Train loss=0.317672997713089
[10/24] Train loss=0.369804710149765
[15/24] Train loss=0.3213067948818207
[20/24] Train loss=0.31443989276885986
Test set avg_accuracy=85.03% avg_sensitivity=70.76%, avg_specificity=90.05% avg_auc=90.84%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.318057 Test loss=0.334165 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.304182767868042
[5/24] Train loss=0.31685441732406616
[10/24] Train loss=0.36620160937309265
[15/24] Train loss=0.31675806641578674
[20/24] Train loss=0.3071095943450928
Test set avg_accuracy=84.93% avg_sensitivity=71.31%, avg_specificity=89.73% avg_auc=90.79%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.318019 Test loss=0.335536 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.30454644560813904
[5/24] Train loss=0.3163682818412781
[10/24] Train loss=0.36495891213417053
[15/24] Train loss=0.3190877437591553
[20/24] Train loss=0.3186677396297455
Test set avg_accuracy=85.18% avg_sensitivity=70.31%, avg_specificity=90.42% avg_auc=90.91%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.318603 Test loss=0.332423 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.30096763372421265
[5/24] Train loss=0.3133912980556488
[10/24] Train loss=0.3629865348339081
[15/24] Train loss=0.31936895847320557
[20/24] Train loss=0.31095048785209656
Test set avg_accuracy=85.29% avg_sensitivity=68.77%, avg_specificity=91.11% avg_auc=90.98%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.317308 Test loss=0.329728 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.2926649749279022
[5/24] Train loss=0.3104364573955536
[10/24] Train loss=0.35859280824661255
[15/24] Train loss=0.3148200511932373
[20/24] Train loss=0.3075372278690338
Test set avg_accuracy=85.33% avg_sensitivity=68.62%, avg_specificity=91.21% avg_auc=90.99%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.315169 Test loss=0.329621 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.2965349555015564
[5/24] Train loss=0.3127336800098419
[10/24] Train loss=0.36285606026649475
[15/24] Train loss=0.3125665485858917
[20/24] Train loss=0.310629278421402
Test set avg_accuracy=85.33% avg_sensitivity=69.42%, avg_specificity=90.93% avg_auc=90.97%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.314958 Test loss=0.329986 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.29870885610580444
[5/24] Train loss=0.30747103691101074
[10/24] Train loss=0.36358579993247986
[15/24] Train loss=0.31569740176200867
[20/24] Train loss=0.30897098779678345
Test set avg_accuracy=85.40% avg_sensitivity=68.37%, avg_specificity=91.41% avg_auc=90.98%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.315007 Test loss=0.329525 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.29552677273750305
[5/24] Train loss=0.30848363041877747
[10/24] Train loss=0.359442800283432
[15/24] Train loss=0.31628668308258057
[20/24] Train loss=0.30711033940315247
Test set avg_accuracy=85.30% avg_sensitivity=68.52%, avg_specificity=91.21% avg_auc=90.98%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.313967 Test loss=0.329511 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.29727718234062195
[5/24] Train loss=0.31228992342948914
[10/24] Train loss=0.3606749475002289
[15/24] Train loss=0.3148762583732605
[20/24] Train loss=0.3050600290298462
Test set avg_accuracy=85.42% avg_sensitivity=68.17%, avg_specificity=91.49% avg_auc=90.99%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.313765 Test loss=0.329201 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.29607972502708435
[5/24] Train loss=0.3079969882965088
[10/24] Train loss=0.35966476798057556
[15/24] Train loss=0.31422966718673706
[20/24] Train loss=0.2998661398887634
Test set avg_accuracy=85.36% avg_sensitivity=68.47%, avg_specificity=91.32% avg_auc=91.01%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.313319 Test loss=0.328947 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.2960529029369354
[5/24] Train loss=0.3095153272151947
[10/24] Train loss=0.3623219430446625
[15/24] Train loss=0.31836003065109253
[20/24] Train loss=0.3059961199760437
Test set avg_accuracy=85.34% avg_sensitivity=67.47%, avg_specificity=91.64% avg_auc=90.98%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.314333 Test loss=0.329125 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3003557026386261
[5/24] Train loss=0.30828410387039185
[10/24] Train loss=0.3607749044895172
[15/24] Train loss=0.31803375482559204
[20/24] Train loss=0.3064153790473938
Test set avg_accuracy=85.39% avg_sensitivity=68.37%, avg_specificity=91.39% avg_auc=90.99%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.313554 Test loss=0.329216 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3000795245170593
[5/24] Train loss=0.3116585612297058
[10/24] Train loss=0.3623892664909363
[15/24] Train loss=0.3142567574977875
[20/24] Train loss=0.30045726895332336
Test set avg_accuracy=85.30% avg_sensitivity=68.12%, avg_specificity=91.35% avg_auc=90.98%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.313418 Test loss=0.329134 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.29545044898986816
[5/24] Train loss=0.3116455376148224
[10/24] Train loss=0.35974231362342834
[15/24] Train loss=0.3168744742870331
[20/24] Train loss=0.2996317744255066
Test set avg_accuracy=85.44% avg_sensitivity=68.77%, avg_specificity=91.32% avg_auc=90.97%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.312868 Test loss=0.329444 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.2973742187023163
[5/24] Train loss=0.30662980675697327
[10/24] Train loss=0.36021724343299866
[15/24] Train loss=0.314463347196579
[20/24] Train loss=0.2999613881111145
Test set avg_accuracy=85.46% avg_sensitivity=69.27%, avg_specificity=91.16% avg_auc=90.97%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.312314 Test loss=0.329776 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.29686281085014343
[5/24] Train loss=0.3071736991405487
[10/24] Train loss=0.3600793182849884
[15/24] Train loss=0.3094756305217743
[20/24] Train loss=0.29855096340179443
Test set avg_accuracy=85.33% avg_sensitivity=69.42%, avg_specificity=90.93% avg_auc=90.97%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.313000 Test loss=0.329814 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.29839518666267395
[5/24] Train loss=0.30789774656295776
[10/24] Train loss=0.3580409288406372
[15/24] Train loss=0.31465640664100647
[20/24] Train loss=0.30563318729400635
Test set avg_accuracy=85.31% avg_sensitivity=70.01%, avg_specificity=90.70% avg_auc=90.97%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.312826 Test loss=0.330333 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.2982470393180847
[5/24] Train loss=0.30876046419143677
[10/24] Train loss=0.3586541712284088
[15/24] Train loss=0.3186144530773163
[20/24] Train loss=0.305075466632843
Test set avg_accuracy=85.34% avg_sensitivity=69.97%, avg_specificity=90.76% avg_auc=90.96%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.313760 Test loss=0.330357 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.2960858941078186
[5/24] Train loss=0.3040843904018402
[10/24] Train loss=0.3596712052822113
[15/24] Train loss=0.3159918487071991
[20/24] Train loss=0.30337080359458923
Test set avg_accuracy=85.26% avg_sensitivity=69.52%, avg_specificity=90.81% avg_auc=90.96%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.312911 Test loss=0.330009 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.29820817708969116
[5/24] Train loss=0.30769312381744385
[10/24] Train loss=0.35651570558547974
[15/24] Train loss=0.3114352524280548
[20/24] Train loss=0.3046748638153076
Test set avg_accuracy=85.31% avg_sensitivity=68.87%, avg_specificity=91.11% avg_auc=90.98%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.312394 Test loss=0.329375 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.29535147547721863
[5/24] Train loss=0.30591776967048645
[10/24] Train loss=0.35736334323883057
[15/24] Train loss=0.31235748529434204
[20/24] Train loss=0.3031010329723358
Test set avg_accuracy=85.36% avg_sensitivity=68.12%, avg_specificity=91.44% avg_auc=90.98%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.312047 Test loss=0.329014 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.29400503635406494
[5/24] Train loss=0.3064573407173157
[10/24] Train loss=0.35836338996887207
[15/24] Train loss=0.31164446473121643
[20/24] Train loss=0.30436474084854126
Test set avg_accuracy=85.39% avg_sensitivity=67.87%, avg_specificity=91.57% avg_auc=90.98%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.311679 Test loss=0.328847 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.2966962158679962
[5/24] Train loss=0.30663472414016724
[10/24] Train loss=0.3609551787376404
[15/24] Train loss=0.3135446608066559
[20/24] Train loss=0.30202925205230713
Test set avg_accuracy=85.34% avg_sensitivity=67.92%, avg_specificity=91.48% avg_auc=90.98%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.312558 Test loss=0.328875 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.29321742057800293
[5/24] Train loss=0.31053775548934937
[10/24] Train loss=0.36075472831726074
[15/24] Train loss=0.3163428008556366
[20/24] Train loss=0.3021448850631714
Test set avg_accuracy=85.39% avg_sensitivity=67.82%, avg_specificity=91.58% avg_auc=90.98%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.311785 Test loss=0.328828 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.29468145966529846
[5/24] Train loss=0.30486634373664856
[10/24] Train loss=0.35743236541748047
[15/24] Train loss=0.3175685703754425
[20/24] Train loss=0.30031874775886536
Test set avg_accuracy=85.38% avg_sensitivity=67.82%, avg_specificity=91.57% avg_auc=90.98%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.312294 Test loss=0.328882 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.2971646785736084
[5/24] Train loss=0.3111104667186737
[10/24] Train loss=0.36026060581207275
[15/24] Train loss=0.31208154559135437
[20/24] Train loss=0.29981493949890137
Test set avg_accuracy=85.39% avg_sensitivity=67.77%, avg_specificity=91.60% avg_auc=90.99%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.312040 Test loss=0.328809 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.2933788597583771
[5/24] Train loss=0.3070034682750702
[10/24] Train loss=0.36120784282684326
[15/24] Train loss=0.3158845007419586
[20/24] Train loss=0.2994992136955261
Test set avg_accuracy=85.35% avg_sensitivity=67.52%, avg_specificity=91.64% avg_auc=90.99%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.311981 Test loss=0.328741 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.294620543718338
[5/24] Train loss=0.30483701825141907
[10/24] Train loss=0.3645625710487366
[15/24] Train loss=0.3123593032360077
[20/24] Train loss=0.2977982759475708
Test set avg_accuracy=85.36% avg_sensitivity=67.57%, avg_specificity=91.64% avg_auc=90.99%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.311938 Test loss=0.328768 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.29235243797302246
[5/24] Train loss=0.3055236339569092
[10/24] Train loss=0.3613664209842682
[15/24] Train loss=0.31094107031822205
[20/24] Train loss=0.30463582277297974
Test set avg_accuracy=85.40% avg_sensitivity=67.77%, avg_specificity=91.62% avg_auc=90.98%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.311829 Test loss=0.328846 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.29366591572761536
[5/24] Train loss=0.3069693148136139
[10/24] Train loss=0.3540523648262024
[15/24] Train loss=0.31582707166671753
[20/24] Train loss=0.3003078103065491
Test set avg_accuracy=85.34% avg_sensitivity=67.37%, avg_specificity=91.67% avg_auc=90.98%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.311727 Test loss=0.328825 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.29400739073753357
[5/24] Train loss=0.3074439764022827
[10/24] Train loss=0.3614715039730072
[15/24] Train loss=0.3121697008609772
[20/24] Train loss=0.2998403012752533
Test set avg_accuracy=85.34% avg_sensitivity=67.37%, avg_specificity=91.67% avg_auc=90.98%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.312519 Test loss=0.328802 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.2943115532398224
[5/24] Train loss=0.30728116631507874
[10/24] Train loss=0.360183984041214
[15/24] Train loss=0.3118525445461273
[20/24] Train loss=0.3029246926307678
Test set avg_accuracy=85.34% avg_sensitivity=67.37%, avg_specificity=91.67% avg_auc=90.98%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.311622 Test loss=0.328795 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.29399892687797546
[5/24] Train loss=0.30269816517829895
[10/24] Train loss=0.35983914136886597
[15/24] Train loss=0.31304463744163513
[20/24] Train loss=0.3058582544326782
Test set avg_accuracy=85.34% avg_sensitivity=67.37%, avg_specificity=91.67% avg_auc=90.98%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.311040 Test loss=0.328793 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=85.10% sen=74.46%, spe=88.85%, auc=90.68%!
Fold[4] Avg_overlap=0.65%(±0.2551628271411595)
[0/24] Train loss=1.0969496965408325
[5/24] Train loss=0.8637745380401611
[10/24] Train loss=0.7408958673477173
[15/24] Train loss=0.6586039662361145
[20/24] Train loss=0.6434109807014465
Test set avg_accuracy=73.37% avg_sensitivity=7.27%, avg_specificity=95.91% avg_auc=52.45%
Best model saved!! Metric=-96.9913053258527!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.765660 Test loss=0.591326 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6356953978538513
[5/24] Train loss=0.6094988584518433
[10/24] Train loss=0.612201452255249
[15/24] Train loss=0.5848494172096252
[20/24] Train loss=0.6140378713607788
Test set avg_accuracy=74.44% avg_sensitivity=0.10%, avg_specificity=99.79% avg_auc=55.06%
Best model saved!! Metric=-96.60685720449753!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.602241 Test loss=0.565915 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6085309386253357
[5/24] Train loss=0.5925003886222839
[10/24] Train loss=0.5908421874046326
[15/24] Train loss=0.5784697532653809
[20/24] Train loss=0.6089282035827637
Test set avg_accuracy=74.24% avg_sensitivity=0.46%, avg_specificity=99.41% avg_auc=60.05%
Best model saved!! Metric=-91.83475446147777!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.588054 Test loss=0.559991 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6032375693321228
[5/24] Train loss=0.5772031545639038
[10/24] Train loss=0.5950241684913635
[15/24] Train loss=0.582200825214386
[20/24] Train loss=0.5927501320838928
Test set avg_accuracy=74.26% avg_sensitivity=1.08%, avg_specificity=99.21% avg_auc=63.26%
Best model saved!! Metric=-88.1891932705834!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.582725 Test loss=0.554611 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6006947755813599
[5/24] Train loss=0.5743002891540527
[10/24] Train loss=0.5872604846954346
[15/24] Train loss=0.5695023536682129
[20/24] Train loss=0.5926509499549866
Test set avg_accuracy=74.22% avg_sensitivity=0.92%, avg_specificity=99.21% avg_auc=66.65%
Best model saved!! Metric=-84.99592709257297!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.576410 Test loss=0.546676 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5937007069587708
[5/24] Train loss=0.5651857852935791
[10/24] Train loss=0.5858630537986755
[15/24] Train loss=0.5561302900314331
[20/24] Train loss=0.5807903409004211
Test set avg_accuracy=74.18% avg_sensitivity=1.59%, avg_specificity=98.93% avg_auc=70.60%
Best model saved!! Metric=-80.69548727912719!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.568831 Test loss=0.539530 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5822736024856567
[5/24] Train loss=0.5600306391716003
[10/24] Train loss=0.5746884942054749
[15/24] Train loss=0.5508826375007629
[20/24] Train loss=0.5703622698783875
Test set avg_accuracy=74.14% avg_sensitivity=2.00%, avg_specificity=98.74% avg_auc=72.80%
Best model saved!! Metric=-78.31663215480188!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.561625 Test loss=0.532563 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5774208307266235
[5/24] Train loss=0.5464705228805542
[10/24] Train loss=0.5763119459152222
[15/24] Train loss=0.5449530482292175
[20/24] Train loss=0.5622640252113342
Test set avg_accuracy=74.05% avg_sensitivity=2.61%, avg_specificity=98.41% avg_auc=75.62%
Best model saved!! Metric=-75.30975174169481!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.553475 Test loss=0.524301 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5659751892089844
[5/24] Train loss=0.5452345609664917
[10/24] Train loss=0.5595502257347107
[15/24] Train loss=0.5376295447349548
[20/24] Train loss=0.557475209236145
Test set avg_accuracy=74.09% avg_sensitivity=3.84%, avg_specificity=98.04% avg_auc=77.50%
Best model saved!! Metric=-72.52471569949292!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.545444 Test loss=0.514935 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5555793046951294
[5/24] Train loss=0.531516432762146
[10/24] Train loss=0.560899019241333
[15/24] Train loss=0.5280596017837524
[20/24] Train loss=0.5443652272224426
Test set avg_accuracy=73.78% avg_sensitivity=4.61%, avg_specificity=97.36% avg_auc=79.02%
Best model saved!! Metric=-71.23686965939626!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.535853 Test loss=0.504793 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5397083759307861
[5/24] Train loss=0.5195297598838806
[10/24] Train loss=0.541211724281311
[15/24] Train loss=0.5165387392044067
[20/24] Train loss=0.5405483245849609
Test set avg_accuracy=73.97% avg_sensitivity=6.86%, avg_specificity=96.86% avg_auc=80.71%
Best model saved!! Metric=-67.59872015989222!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.523833 Test loss=0.493128 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5443288683891296
[5/24] Train loss=0.5003413558006287
[10/24] Train loss=0.5344383716583252
[15/24] Train loss=0.5035884380340576
[20/24] Train loss=0.5159648060798645
Test set avg_accuracy=74.41% avg_sensitivity=11.62%, avg_specificity=95.83% avg_auc=82.06%
Best model saved!! Metric=-62.0763955140728!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.511990 Test loss=0.479484 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5221696496009827
[5/24] Train loss=0.49210816621780396
[10/24] Train loss=0.5232461094856262
[15/24] Train loss=0.48242977261543274
[20/24] Train loss=0.5051887035369873
Test set avg_accuracy=75.26% avg_sensitivity=18.95%, avg_specificity=94.46% avg_auc=83.22%
Best model saved!! Metric=-54.10468558655471!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.498171 Test loss=0.464634 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.50677889585495
[5/24] Train loss=0.47673118114471436
[10/24] Train loss=0.5132405757904053
[15/24] Train loss=0.46138906478881836
[20/24] Train loss=0.4983466863632202
Test set avg_accuracy=77.03% avg_sensitivity=30.93%, avg_specificity=92.75% avg_auc=84.24%
Best model saved!! Metric=-41.04703888965779!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.482991 Test loss=0.450142 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4818459749221802
[5/24] Train loss=0.45672425627708435
[10/24] Train loss=0.5040478110313416
[15/24] Train loss=0.4541463553905487
[20/24] Train loss=0.4801807701587677
Test set avg_accuracy=78.10% avg_sensitivity=39.17%, avg_specificity=91.37% avg_auc=84.95%
Best model saved!! Metric=-32.410794205618764!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.471890 Test loss=0.438815 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.47260406613349915
[5/24] Train loss=0.45441341400146484
[10/24] Train loss=0.5001258254051208
[15/24] Train loss=0.4343514144420624
[20/24] Train loss=0.4626505374908447
Test set avg_accuracy=78.87% avg_sensitivity=46.19%, avg_specificity=90.01% avg_auc=85.55%
Best model saved!! Metric=-25.386824563302532!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.461780 Test loss=0.428074 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.46131888031959534
[5/24] Train loss=0.44443026185035706
[10/24] Train loss=0.49903732538223267
[15/24] Train loss=0.4257700741291046
[20/24] Train loss=0.44931262731552124
Test set avg_accuracy=79.77% avg_sensitivity=46.65%, avg_specificity=91.06% avg_auc=86.09%
Best model saved!! Metric=-22.440336449037538!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.452125 Test loss=0.415219 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.45213934779167175
[5/24] Train loss=0.4423937201499939
[10/24] Train loss=0.48753467202186584
[15/24] Train loss=0.41878125071525574
[20/24] Train loss=0.4360467493534088
Test set avg_accuracy=80.04% avg_sensitivity=45.01%, avg_specificity=91.99% avg_auc=86.52%
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.443278 Test loss=0.404998 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4398266673088074
[5/24] Train loss=0.4285627007484436
[10/24] Train loss=0.4731539785861969
[15/24] Train loss=0.41056254506111145
[20/24] Train loss=0.4296325147151947
Test set avg_accuracy=79.77% avg_sensitivity=40.35%, avg_specificity=93.21% avg_auc=86.61%
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.431727 Test loss=0.399427 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.42728596925735474
[5/24] Train loss=0.4145742952823639
[10/24] Train loss=0.45275697112083435
[15/24] Train loss=0.39457520842552185
[20/24] Train loss=0.42367956042289734
Test set avg_accuracy=80.21% avg_sensitivity=42.19%, avg_specificity=93.17% avg_auc=86.91%
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.422432 Test loss=0.393909 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.42440226674079895
[5/24] Train loss=0.40311503410339355
[10/24] Train loss=0.4473017752170563
[15/24] Train loss=0.39231494069099426
[20/24] Train loss=0.4128856360912323
Test set avg_accuracy=81.39% avg_sensitivity=50.28%, avg_specificity=92.00% avg_auc=87.53%
Best model saved!! Metric=-14.796646746523265!!
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.415174 Test loss=0.386764 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.4198963940143585
[5/24] Train loss=0.41102468967437744
[10/24] Train loss=0.44452333450317383
[15/24] Train loss=0.38201892375946045
[20/24] Train loss=0.41333797574043274
Test set avg_accuracy=81.46% avg_sensitivity=48.39%, avg_specificity=92.74% avg_auc=87.77%
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.410107 Test loss=0.382169 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.41189366579055786
[5/24] Train loss=0.3983193337917328
[10/24] Train loss=0.44572240114212036
[15/24] Train loss=0.38299643993377686
[20/24] Train loss=0.4025947153568268
Test set avg_accuracy=81.71% avg_sensitivity=45.31%, avg_specificity=94.12% avg_auc=87.89%
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.406698 Test loss=0.380014 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.41032156348228455
[5/24] Train loss=0.3984713554382324
[10/24] Train loss=0.4331328868865967
[15/24] Train loss=0.36849039793014526
[20/24] Train loss=0.3928234875202179
Test set avg_accuracy=80.94% avg_sensitivity=38.10%, avg_specificity=95.55% avg_auc=88.05%
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.400740 Test loss=0.382138 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.4047505259513855
[5/24] Train loss=0.3892013728618622
[10/24] Train loss=0.4278775751590729
[15/24] Train loss=0.3635883033275604
[20/24] Train loss=0.38523104786872864
Test set avg_accuracy=81.74% avg_sensitivity=39.68%, avg_specificity=96.09% avg_auc=88.68%
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.391229 Test loss=0.375404 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.4001093804836273
[5/24] Train loss=0.38283777236938477
[10/24] Train loss=0.4170316159725189
[15/24] Train loss=0.35197216272354126
[20/24] Train loss=0.3707960844039917
Test set avg_accuracy=80.91% avg_sensitivity=34.36%, avg_specificity=96.79% avg_auc=89.11%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.383375 Test loss=0.378592 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.4076350927352905
[5/24] Train loss=0.37571004033088684
[10/24] Train loss=0.41276249289512634
[15/24] Train loss=0.34673357009887695
[20/24] Train loss=0.36093205213546753
Test set avg_accuracy=81.29% avg_sensitivity=35.89%, avg_specificity=96.77% avg_auc=89.21%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.379657 Test loss=0.377180 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3932531774044037
[5/24] Train loss=0.37237200140953064
[10/24] Train loss=0.40815111994743347
[15/24] Train loss=0.34130117297172546
[20/24] Train loss=0.36435869336128235
Test set avg_accuracy=81.71% avg_sensitivity=38.56%, avg_specificity=96.42% avg_auc=89.51%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.376186 Test loss=0.372383 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3927086889743805
[5/24] Train loss=0.3760656416416168
[10/24] Train loss=0.40581971406936646
[15/24] Train loss=0.3337599039077759
[20/24] Train loss=0.36215803027153015
Test set avg_accuracy=82.67% avg_sensitivity=43.16%, avg_specificity=96.14% avg_auc=89.76%
Best model saved!! Metric=-14.270039738279259!!
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.372818 Test loss=0.363093 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.37999218702316284
[5/24] Train loss=0.37238654494285583
[10/24] Train loss=0.40197882056236267
[15/24] Train loss=0.33629825711250305
[20/24] Train loss=0.36428573727607727
Test set avg_accuracy=82.80% avg_sensitivity=43.88%, avg_specificity=96.07% avg_auc=89.78%
Best model saved!! Metric=-13.46587844132938!!
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.370001 Test loss=0.361555 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3793772757053375
[5/24] Train loss=0.37497463822364807
[10/24] Train loss=0.4000132083892822
[15/24] Train loss=0.3379344046115875
[20/24] Train loss=0.35064077377319336
Test set avg_accuracy=82.51% avg_sensitivity=41.88%, avg_specificity=96.37% avg_auc=89.72%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.367892 Test loss=0.365840 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3788455128669739
[5/24] Train loss=0.3681931495666504
[10/24] Train loss=0.399827241897583
[15/24] Train loss=0.3397321105003357
[20/24] Train loss=0.3488633632659912
Test set avg_accuracy=82.25% avg_sensitivity=40.45%, avg_specificity=96.51% avg_auc=89.71%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.364866 Test loss=0.369320 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3871387541294098
[5/24] Train loss=0.3638857305049896
[10/24] Train loss=0.39564719796180725
[15/24] Train loss=0.3389347493648529
[20/24] Train loss=0.3480397164821625
Test set avg_accuracy=82.67% avg_sensitivity=42.14%, avg_specificity=96.49% avg_auc=89.95%
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.363741 Test loss=0.364860 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.37579500675201416
[5/24] Train loss=0.36059537529945374
[10/24] Train loss=0.3927675485610962
[15/24] Train loss=0.3339509069919586
[20/24] Train loss=0.3403850793838501
Test set avg_accuracy=82.85% avg_sensitivity=43.52%, avg_specificity=96.26% avg_auc=90.00%
Best model saved!! Metric=-13.358993207100063!!
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.363047 Test loss=0.361902 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.37464407086372375
[5/24] Train loss=0.3575499951839447
[10/24] Train loss=0.39419621229171753
[15/24] Train loss=0.3325461745262146
[20/24] Train loss=0.336099773645401
Test set avg_accuracy=83.18% avg_sensitivity=45.06%, avg_specificity=96.18% avg_auc=89.96%
Best model saved!! Metric=-11.627013930183665!!
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.360561 Test loss=0.361404 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.37272289395332336
[5/24] Train loss=0.35613900423049927
[10/24] Train loss=0.39696282148361206
[15/24] Train loss=0.3298359215259552
[20/24] Train loss=0.33618807792663574
Test set avg_accuracy=83.28% avg_sensitivity=45.67%, avg_specificity=96.11% avg_auc=90.12%
Best model saved!! Metric=-10.820507639431455!!
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.359684 Test loss=0.357874 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3711487352848053
[5/24] Train loss=0.3588677942752838
[10/24] Train loss=0.3936710059642792
[15/24] Train loss=0.3300653398036957
[20/24] Train loss=0.3418174982070923
Test set avg_accuracy=83.68% avg_sensitivity=48.54%, avg_specificity=95.67% avg_auc=90.18%
Best model saved!! Metric=-7.922586300281388!!
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.359123 Test loss=0.353316 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.36645156145095825
[5/24] Train loss=0.36116915941238403
[10/24] Train loss=0.3914211094379425
[15/24] Train loss=0.32873260974884033
[20/24] Train loss=0.340013325214386
Test set avg_accuracy=83.82% avg_sensitivity=48.23%, avg_specificity=95.95% avg_auc=90.25%
Best model saved!! Metric=-7.756561601014589!!
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.358381 Test loss=0.353245 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3630824685096741
[5/24] Train loss=0.35636967420578003
[10/24] Train loss=0.38955095410346985
[15/24] Train loss=0.32619547843933105
[20/24] Train loss=0.32874077558517456
Test set avg_accuracy=83.92% avg_sensitivity=48.75%, avg_specificity=95.91% avg_auc=90.36%
Best model saved!! Metric=-7.062354727213766!!
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.356471 Test loss=0.350951 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3601684868335724
[5/24] Train loss=0.35305044054985046
[10/24] Train loss=0.3930669128894806
[15/24] Train loss=0.3295533061027527
[20/24] Train loss=0.34213945269584656
Test set avg_accuracy=83.84% avg_sensitivity=48.08%, avg_specificity=96.04% avg_auc=90.33%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.356490 Test loss=0.352703 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3671402931213379
[5/24] Train loss=0.36018145084381104
[10/24] Train loss=0.39323198795318604
[15/24] Train loss=0.32569509744644165
[20/24] Train loss=0.33546170592308044
Test set avg_accuracy=84.02% avg_sensitivity=49.36%, avg_specificity=95.84% avg_auc=90.37%
Best model saved!! Metric=-6.405001338280165!!
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.356090 Test loss=0.350311 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.36080968379974365
[5/24] Train loss=0.35422414541244507
[10/24] Train loss=0.378267377614975
[15/24] Train loss=0.329307496547699
[20/24] Train loss=0.33175769448280334
Test set avg_accuracy=83.93% avg_sensitivity=49.51%, avg_specificity=95.67% avg_auc=90.23%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.353589 Test loss=0.351126 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3662033677101135
[5/24] Train loss=0.35305094718933105
[10/24] Train loss=0.38621968030929565
[15/24] Train loss=0.32581058144569397
[20/24] Train loss=0.33402130007743835
Test set avg_accuracy=83.82% avg_sensitivity=48.13%, avg_specificity=95.98% avg_auc=90.25%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.354334 Test loss=0.353806 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.36190667748451233
[5/24] Train loss=0.3531818389892578
[10/24] Train loss=0.37979719042778015
[15/24] Train loss=0.3271513879299164
[20/24] Train loss=0.33324623107910156
Test set avg_accuracy=83.72% avg_sensitivity=48.03%, avg_specificity=95.90% avg_auc=90.29%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.353729 Test loss=0.353543 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3671402633190155
[5/24] Train loss=0.35437196493148804
[10/24] Train loss=0.38203373551368713
[15/24] Train loss=0.3242706060409546
[20/24] Train loss=0.3307834267616272
Test set avg_accuracy=83.91% avg_sensitivity=48.44%, avg_specificity=96.00% avg_auc=90.44%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.353058 Test loss=0.350231 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.36235591769218445
[5/24] Train loss=0.3505186140537262
[10/24] Train loss=0.3867429494857788
[15/24] Train loss=0.32356542348861694
[20/24] Train loss=0.33045610785484314
Test set avg_accuracy=83.95% avg_sensitivity=48.39%, avg_specificity=96.07% avg_auc=90.47%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.352254 Test loss=0.350968 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.35867607593536377
[5/24] Train loss=0.3541423976421356
[10/24] Train loss=0.3824760317802429
[15/24] Train loss=0.32582998275756836
[20/24] Train loss=0.3319934606552124
Test set avg_accuracy=83.78% avg_sensitivity=48.18%, avg_specificity=95.91% avg_auc=90.35%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.352218 Test loss=0.351991 Current lr=[0.000299720220882401]

[0/24] Train loss=0.36480486392974854
[5/24] Train loss=0.35114264488220215
[10/24] Train loss=0.3858788311481476
[15/24] Train loss=0.31968194246292114
[20/24] Train loss=0.3316727876663208
Test set avg_accuracy=83.95% avg_sensitivity=49.21%, avg_specificity=95.79% avg_auc=90.41%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.352251 Test loss=0.349712 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.359024316072464
[5/24] Train loss=0.35754987597465515
[10/24] Train loss=0.38562119007110596
[15/24] Train loss=0.3214137554168701
[20/24] Train loss=0.33154213428497314
Test set avg_accuracy=84.17% avg_sensitivity=50.28%, avg_specificity=95.72% avg_auc=90.50%
Best model saved!! Metric=-5.328463478795527!!
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.352476 Test loss=0.347597 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3590278625488281
[5/24] Train loss=0.3534992039203644
[10/24] Train loss=0.38599613308906555
[15/24] Train loss=0.3210275173187256
[20/24] Train loss=0.330873966217041
Test set avg_accuracy=84.26% avg_sensitivity=51.77%, avg_specificity=95.34% avg_auc=90.60%
Best model saved!! Metric=-4.0382338148705585!!
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.351985 Test loss=0.343896 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.35475221276283264
[5/24] Train loss=0.35470637679100037
[10/24] Train loss=0.3902783691883087
[15/24] Train loss=0.32361769676208496
[20/24] Train loss=0.3344418406486511
Test set avg_accuracy=84.00% avg_sensitivity=49.26%, avg_specificity=95.84% avg_auc=90.49%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.351997 Test loss=0.348538 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3559744358062744
[5/24] Train loss=0.35429275035858154
[10/24] Train loss=0.38490983843803406
[15/24] Train loss=0.3191626965999603
[20/24] Train loss=0.33150798082351685
Test set avg_accuracy=84.35% avg_sensitivity=52.94%, avg_specificity=95.06% avg_auc=90.61%
Best model saved!! Metric=-3.041374698967303!!
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.351707 Test loss=0.342167 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.35071152448654175
[5/24] Train loss=0.3532567024230957
[10/24] Train loss=0.38069048523902893
[15/24] Train loss=0.32025331258773804
[20/24] Train loss=0.336855947971344
Test set avg_accuracy=84.24% avg_sensitivity=51.51%, avg_specificity=95.41% avg_auc=90.55%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.350555 Test loss=0.344811 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.35309964418411255
[5/24] Train loss=0.35466888546943665
[10/24] Train loss=0.38561001420021057
[15/24] Train loss=0.3236899673938751
[20/24] Train loss=0.33261623978614807
Test set avg_accuracy=84.11% avg_sensitivity=50.23%, avg_specificity=95.67% avg_auc=90.55%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.352149 Test loss=0.346166 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3558399975299835
[5/24] Train loss=0.36049938201904297
[10/24] Train loss=0.3818780481815338
[15/24] Train loss=0.3257477283477783
[20/24] Train loss=0.33527663350105286
Test set avg_accuracy=83.79% avg_sensitivity=48.34%, avg_specificity=95.88% avg_auc=90.39%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.352364 Test loss=0.350756 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.36110153794288635
[5/24] Train loss=0.35247665643692017
[10/24] Train loss=0.3793133497238159
[15/24] Train loss=0.33038529753685
[20/24] Train loss=0.3356552720069885
Test set avg_accuracy=83.45% avg_sensitivity=46.19%, avg_specificity=96.16% avg_auc=90.28%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.353213 Test loss=0.354559 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.365221232175827
[5/24] Train loss=0.3506086468696594
[10/24] Train loss=0.38059601187705994
[15/24] Train loss=0.32525065541267395
[20/24] Train loss=0.3310648798942566
Test set avg_accuracy=84.14% avg_sensitivity=51.15%, avg_specificity=95.39% avg_auc=90.58%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.352788 Test loss=0.344022 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3526625633239746
[5/24] Train loss=0.3525097966194153
[10/24] Train loss=0.3775026500225067
[15/24] Train loss=0.32310691475868225
[20/24] Train loss=0.3286656439304352
Test set avg_accuracy=84.39% avg_sensitivity=53.10%, avg_specificity=95.06% avg_auc=90.57%
Best model saved!! Metric=-2.8885152180383784!!
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.351867 Test loss=0.341809 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.34747475385665894
[5/24] Train loss=0.35428380966186523
[10/24] Train loss=0.38251617550849915
[15/24] Train loss=0.31862929463386536
[20/24] Train loss=0.33223840594291687
Test set avg_accuracy=84.77% avg_sensitivity=56.02%, avg_specificity=94.57% avg_auc=90.68%
Best model saved!! Metric=0.02929720032200578!!
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.351894 Test loss=0.338209 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.35258302092552185
[5/24] Train loss=0.3565415143966675
[10/24] Train loss=0.37630629539489746
[15/24] Train loss=0.3194943964481354
[20/24] Train loss=0.3376803398132324
Test set avg_accuracy=84.48% avg_sensitivity=53.35%, avg_specificity=95.09% avg_auc=90.54%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.350882 Test loss=0.341729 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3486427664756775
[5/24] Train loss=0.3541262447834015
[10/24] Train loss=0.37423574924468994
[15/24] Train loss=0.32054734230041504
[20/24] Train loss=0.3306279182434082
Test set avg_accuracy=84.60% avg_sensitivity=54.22%, avg_specificity=94.95% avg_auc=90.54%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.350513 Test loss=0.341049 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3495602607727051
[5/24] Train loss=0.3550374507904053
[10/24] Train loss=0.37777000665664673
[15/24] Train loss=0.3243473172187805
[20/24] Train loss=0.32796287536621094
Test set avg_accuracy=84.74% avg_sensitivity=54.99%, avg_specificity=94.88% avg_auc=90.62%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.350467 Test loss=0.339765 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3478405177593231
[5/24] Train loss=0.3552495837211609
[10/24] Train loss=0.3773568272590637
[15/24] Train loss=0.31661105155944824
[20/24] Train loss=0.33090007305145264
Test set avg_accuracy=84.77% avg_sensitivity=55.71%, avg_specificity=94.67% avg_auc=90.61%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.349384 Test loss=0.338925 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.34697654843330383
[5/24] Train loss=0.356564998626709
[10/24] Train loss=0.3799186646938324
[15/24] Train loss=0.3204810619354248
[20/24] Train loss=0.33088260889053345
Test set avg_accuracy=84.75% avg_sensitivity=54.94%, avg_specificity=94.92% avg_auc=90.56%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.350288 Test loss=0.340181 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3482097089290619
[5/24] Train loss=0.3553369343280792
[10/24] Train loss=0.38031771779060364
[15/24] Train loss=0.3184966742992401
[20/24] Train loss=0.32933011651039124
Test set avg_accuracy=84.79% avg_sensitivity=55.30%, avg_specificity=94.85% avg_auc=90.60%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.349921 Test loss=0.339429 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3472987711429596
[5/24] Train loss=0.35461822152137756
[10/24] Train loss=0.37615224719047546
[15/24] Train loss=0.3186177909374237
[20/24] Train loss=0.33113136887550354
Test set avg_accuracy=84.73% avg_sensitivity=54.84%, avg_specificity=94.92% avg_auc=90.56%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.348713 Test loss=0.340337 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3503321409225464
[5/24] Train loss=0.3551059067249298
[10/24] Train loss=0.37600353360176086
[15/24] Train loss=0.31510525941848755
[20/24] Train loss=0.32999172806739807
Test set avg_accuracy=84.73% avg_sensitivity=55.04%, avg_specificity=94.85% avg_auc=90.57%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.349738 Test loss=0.339915 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3493155837059021
[5/24] Train loss=0.35601282119750977
[10/24] Train loss=0.37778452038764954
[15/24] Train loss=0.31821495294570923
[20/24] Train loss=0.32761481404304504
Test set avg_accuracy=84.82% avg_sensitivity=55.86%, avg_specificity=94.69% avg_auc=90.65%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.349485 Test loss=0.337989 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3459241986274719
[5/24] Train loss=0.35609200596809387
[10/24] Train loss=0.3776708245277405
[15/24] Train loss=0.3173512816429138
[20/24] Train loss=0.32639631628990173
Test set avg_accuracy=84.92% avg_sensitivity=55.86%, avg_specificity=94.83% avg_auc=90.66%
Best model saved!! Metric=0.28065815908394853!!
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.348935 Test loss=0.338076 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.34653252363204956
[5/24] Train loss=0.3556857705116272
[10/24] Train loss=0.3730742633342743
[15/24] Train loss=0.3131686747074127
[20/24] Train loss=0.33117786049842834
Test set avg_accuracy=84.90% avg_sensitivity=56.48%, avg_specificity=94.59% avg_auc=90.68%
Best model saved!! Metric=0.6398480618527103!!
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.347768 Test loss=0.337172 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3480208218097687
[5/24] Train loss=0.35341596603393555
[10/24] Train loss=0.3755987584590912
[15/24] Train loss=0.3150762617588043
[20/24] Train loss=0.3273303210735321
Test set avg_accuracy=84.91% avg_sensitivity=55.71%, avg_specificity=94.87% avg_auc=90.68%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.348548 Test loss=0.337918 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.344746857881546
[5/24] Train loss=0.35563698410987854
[10/24] Train loss=0.3767779767513275
[15/24] Train loss=0.31831762194633484
[20/24] Train loss=0.32559022307395935
Test set avg_accuracy=85.08% avg_sensitivity=57.55%, avg_specificity=94.46% avg_auc=90.76%
Best model saved!! Metric=1.8590306748376477!!
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.348895 Test loss=0.335373 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3433631360530853
[5/24] Train loss=0.3574141263961792
[10/24] Train loss=0.3810867369174957
[15/24] Train loss=0.3208705186843872
[20/24] Train loss=0.32796406745910645
Test set avg_accuracy=85.05% avg_sensitivity=57.91%, avg_specificity=94.31% avg_auc=90.63%
Best model saved!! Metric=1.9018858918163488!!
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.350017 Test loss=0.336777 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.34555843472480774
[5/24] Train loss=0.3573387861251831
[10/24] Train loss=0.3715873956680298
[15/24] Train loss=0.31581154465675354
[20/24] Train loss=0.32498788833618164
Test set avg_accuracy=85.03% avg_sensitivity=59.34%, avg_specificity=93.78% avg_auc=90.75%
Best model saved!! Metric=2.90439798693653!!
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.348876 Test loss=0.333916 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3405175805091858
[5/24] Train loss=0.35259151458740234
[10/24] Train loss=0.3758857846260071
[15/24] Train loss=0.3235933482646942
[20/24] Train loss=0.32843562960624695
Test set avg_accuracy=85.10% avg_sensitivity=62.06%, avg_specificity=92.96% avg_auc=90.82%
Best model saved!! Metric=4.947443154259545!!
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.351253 Test loss=0.333539 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3471654951572418
[5/24] Train loss=0.3509509861469269
[10/24] Train loss=0.3763889968395233
[15/24] Train loss=0.32642728090286255
[20/24] Train loss=0.332864910364151
Test set avg_accuracy=85.23% avg_sensitivity=67.38%, avg_specificity=91.32% avg_auc=90.79%
Best model saved!! Metric=8.731457253634431!!
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.352153 Test loss=0.335555 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3486560881137848
[5/24] Train loss=0.3477657437324524
[10/24] Train loss=0.37464508414268494
[15/24] Train loss=0.32867294549942017
[20/24] Train loss=0.3408721387386322
Test set avg_accuracy=85.16% avg_sensitivity=68.82%, avg_specificity=90.73% avg_auc=90.66%
Best model saved!! Metric=9.35820656063109!!
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.351608 Test loss=0.338135 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3525456190109253
[5/24] Train loss=0.3510681390762329
[10/24] Train loss=0.37550362944602966
[15/24] Train loss=0.3226162791252136
[20/24] Train loss=0.3437696695327759
Test set avg_accuracy=85.00% avg_sensitivity=67.64%, avg_specificity=90.92% avg_auc=90.53%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.349770 Test loss=0.339410 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.350713312625885
[5/24] Train loss=0.3536129891872406
[10/24] Train loss=0.3778230845928192
[15/24] Train loss=0.31862959265708923
[20/24] Train loss=0.33569788932800293
Test set avg_accuracy=85.04% avg_sensitivity=66.26%, avg_specificity=91.44% avg_auc=90.58%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.349013 Test loss=0.337491 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.35041525959968567
[5/24] Train loss=0.3501420021057129
[10/24] Train loss=0.3772302269935608
[15/24] Train loss=0.3217335045337677
[20/24] Train loss=0.3366315960884094
Test set avg_accuracy=84.96% avg_sensitivity=65.80%, avg_specificity=91.50% avg_auc=90.51%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.348621 Test loss=0.337755 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3469105064868927
[5/24] Train loss=0.35099461674690247
[10/24] Train loss=0.37456512451171875
[15/24] Train loss=0.3194710612297058
[20/24] Train loss=0.34074506163597107
Test set avg_accuracy=85.14% avg_sensitivity=66.87%, avg_specificity=91.37% avg_auc=90.49%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.348326 Test loss=0.338455 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3499198853969574
[5/24] Train loss=0.3509058952331543
[10/24] Train loss=0.38055142760276794
[15/24] Train loss=0.321025550365448
[20/24] Train loss=0.33305320143699646
Test set avg_accuracy=85.04% avg_sensitivity=66.10%, avg_specificity=91.50% avg_auc=90.62%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.347742 Test loss=0.336131 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.34490370750427246
[5/24] Train loss=0.34930184483528137
[10/24] Train loss=0.37678077816963196
[15/24] Train loss=0.31734684109687805
[20/24] Train loss=0.33412298560142517
Test set avg_accuracy=85.07% avg_sensitivity=66.21%, avg_specificity=91.50% avg_auc=90.54%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.346142 Test loss=0.337165 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.34694814682006836
[5/24] Train loss=0.35040444135665894
[10/24] Train loss=0.37176090478897095
[15/24] Train loss=0.31758618354797363
[20/24] Train loss=0.33458226919174194
Test set avg_accuracy=85.08% avg_sensitivity=66.26%, avg_specificity=91.50% avg_auc=90.50%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.346931 Test loss=0.337476 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3530396521091461
[5/24] Train loss=0.3486882448196411
[10/24] Train loss=0.37894344329833984
[15/24] Train loss=0.3171074688434601
[20/24] Train loss=0.33059751987457275
Test set avg_accuracy=85.07% avg_sensitivity=65.03%, avg_specificity=91.90% avg_auc=90.49%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.347057 Test loss=0.336655 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3478313684463501
[5/24] Train loss=0.34791630506515503
[10/24] Train loss=0.37480929493904114
[15/24] Train loss=0.31833550333976746
[20/24] Train loss=0.3300256133079529
Test set avg_accuracy=85.05% avg_sensitivity=65.18%, avg_specificity=91.83% avg_auc=90.47%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.345479 Test loss=0.337086 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.34493932127952576
[5/24] Train loss=0.3497875928878784
[10/24] Train loss=0.3815756142139435
[15/24] Train loss=0.31391847133636475
[20/24] Train loss=0.3349333703517914
Test set avg_accuracy=85.12% avg_sensitivity=66.10%, avg_specificity=91.60% avg_auc=90.58%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.346259 Test loss=0.336097 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3467428982257843
[5/24] Train loss=0.35477402806282043
[10/24] Train loss=0.37474972009658813
[15/24] Train loss=0.3186970055103302
[20/24] Train loss=0.33161604404449463
Test set avg_accuracy=85.10% avg_sensitivity=65.18%, avg_specificity=91.90% avg_auc=90.77%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.346488 Test loss=0.333056 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.3412843942642212
[5/24] Train loss=0.34726613759994507
[10/24] Train loss=0.37524357438087463
[15/24] Train loss=0.31956547498703003
[20/24] Train loss=0.33146217465400696
Test set avg_accuracy=85.21% avg_sensitivity=66.31%, avg_specificity=91.65% avg_auc=90.97%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.346240 Test loss=0.331382 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3438546359539032
[5/24] Train loss=0.3485305905342102
[10/24] Train loss=0.3787041902542114
[15/24] Train loss=0.3191019892692566
[20/24] Train loss=0.33320724964141846
Test set avg_accuracy=85.25% avg_sensitivity=67.38%, avg_specificity=91.34% avg_auc=91.00%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.345726 Test loss=0.330915 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.34166625142097473
[5/24] Train loss=0.3496277630329132
[10/24] Train loss=0.37702205777168274
[15/24] Train loss=0.3195497989654541
[20/24] Train loss=0.32495951652526855
Test set avg_accuracy=85.22% avg_sensitivity=66.46%, avg_specificity=91.62% avg_auc=91.00%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.345447 Test loss=0.330373 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.33776724338531494
[5/24] Train loss=0.3486667275428772
[10/24] Train loss=0.3774522840976715
[15/24] Train loss=0.31474536657333374
[20/24] Train loss=0.3268343210220337
Test set avg_accuracy=85.31% avg_sensitivity=66.41%, avg_specificity=91.76% avg_auc=91.02%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.342985 Test loss=0.330236 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3371342420578003
[5/24] Train loss=0.34823137521743774
[10/24] Train loss=0.37478384375572205
[15/24] Train loss=0.3150005042552948
[20/24] Train loss=0.3255346417427063
Test set avg_accuracy=85.20% avg_sensitivity=66.00%, avg_specificity=91.74% avg_auc=90.97%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.342646 Test loss=0.329905 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.338507741689682
[5/24] Train loss=0.34758466482162476
[10/24] Train loss=0.3766207695007324
[15/24] Train loss=0.3151872754096985
[20/24] Train loss=0.32420262694358826
Test set avg_accuracy=85.17% avg_sensitivity=66.26%, avg_specificity=91.62% avg_auc=90.98%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.342813 Test loss=0.330718 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3379031717777252
[5/24] Train loss=0.3494800329208374
[10/24] Train loss=0.37846502661705017
[15/24] Train loss=0.31246188282966614
[20/24] Train loss=0.32393527030944824
Test set avg_accuracy=85.17% avg_sensitivity=65.95%, avg_specificity=91.72% avg_auc=90.99%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.343332 Test loss=0.329747 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.33824875950813293
[5/24] Train loss=0.3460139334201813
[10/24] Train loss=0.37763723731040955
[15/24] Train loss=0.3123733103275299
[20/24] Train loss=0.3227505385875702
Test set avg_accuracy=85.18% avg_sensitivity=65.69%, avg_specificity=91.83% avg_auc=91.01%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.341994 Test loss=0.329458 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3354688882827759
[5/24] Train loss=0.34773576259613037
[10/24] Train loss=0.3757035732269287
[15/24] Train loss=0.3113534450531006
[20/24] Train loss=0.32464316487312317
Test set avg_accuracy=85.27% avg_sensitivity=65.34%, avg_specificity=92.07% avg_auc=91.03%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.341117 Test loss=0.328942 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3410819470882416
[5/24] Train loss=0.34534838795661926
[10/24] Train loss=0.3778708279132843
[15/24] Train loss=0.31114399433135986
[20/24] Train loss=0.3212626576423645
Test set avg_accuracy=85.23% avg_sensitivity=65.75%, avg_specificity=91.88% avg_auc=91.06%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.341428 Test loss=0.328655 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3352143168449402
[5/24] Train loss=0.3460717797279358
[10/24] Train loss=0.38179317116737366
[15/24] Train loss=0.3085097074508667
[20/24] Train loss=0.3181019723415375
Test set avg_accuracy=85.16% avg_sensitivity=65.23%, avg_specificity=91.95% avg_auc=91.03%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.341765 Test loss=0.328359 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.33536359667778015
[5/24] Train loss=0.34384605288505554
[10/24] Train loss=0.3805373013019562
[15/24] Train loss=0.31149348616600037
[20/24] Train loss=0.3188125789165497
Test set avg_accuracy=85.26% avg_sensitivity=65.90%, avg_specificity=91.86% avg_auc=91.08%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.342067 Test loss=0.328269 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.33192873001098633
[5/24] Train loss=0.3458715081214905
[10/24] Train loss=0.38564592599868774
[15/24] Train loss=0.3143153786659241
[20/24] Train loss=0.318941205739975
Test set avg_accuracy=85.16% avg_sensitivity=67.18%, avg_specificity=91.29% avg_auc=91.04%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.342669 Test loss=0.329490 Current lr=[0.000134135431043539]

[0/24] Train loss=0.33899053931236267
[5/24] Train loss=0.35350853204727173
[10/24] Train loss=0.3922868072986603
[15/24] Train loss=0.3134938180446625
[20/24] Train loss=0.3163684904575348
Test set avg_accuracy=85.16% avg_sensitivity=69.94%, avg_specificity=90.34% avg_auc=91.04%
Best model saved!! Metric=10.484696536206059!!
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.344946 Test loss=0.333680 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.34226250648498535
[5/24] Train loss=0.3562823235988617
[10/24] Train loss=0.3929932415485382
[15/24] Train loss=0.31419479846954346
[20/24] Train loss=0.3234104812145233
Test set avg_accuracy=84.62% avg_sensitivity=74.14%, avg_specificity=88.20% avg_auc=90.96%
Best model saved!! Metric=11.924180187518033!!
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.346322 Test loss=0.343317 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3533798158168793
[5/24] Train loss=0.36466094851493835
[10/24] Train loss=0.39141708612442017
[15/24] Train loss=0.31087806820869446
[20/24] Train loss=0.34697985649108887
Test set avg_accuracy=84.57% avg_sensitivity=75.73%, avg_specificity=87.59% avg_auc=90.82%
Best model saved!! Metric=12.710008486465952!!
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.348618 Test loss=0.350619 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3647955060005188
[5/24] Train loss=0.35677745938301086
[10/24] Train loss=0.3803400993347168
[15/24] Train loss=0.3222593665122986
[20/24] Train loss=0.3575613796710968
Test set avg_accuracy=85.00% avg_sensitivity=70.76%, avg_specificity=89.86% avg_auc=91.03%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.348496 Test loss=0.336622 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.34681594371795654
[5/24] Train loss=0.3440428078174591
[10/24] Train loss=0.3737200200557709
[15/24] Train loss=0.3190247416496277
[20/24] Train loss=0.344583660364151
Test set avg_accuracy=85.25% avg_sensitivity=68.10%, avg_specificity=91.09% avg_auc=91.06%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.342433 Test loss=0.332008 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3409140706062317
[5/24] Train loss=0.34372472763061523
[10/24] Train loss=0.37428727746009827
[15/24] Train loss=0.31752198934555054
[20/24] Train loss=0.33957406878471375
Test set avg_accuracy=85.17% avg_sensitivity=69.18%, avg_specificity=90.62% avg_auc=91.05%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.340910 Test loss=0.333770 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3422829508781433
[5/24] Train loss=0.346258282661438
[10/24] Train loss=0.3780932128429413
[15/24] Train loss=0.3186676800251007
[20/24] Train loss=0.34231168031692505
Test set avg_accuracy=85.08% avg_sensitivity=69.23%, avg_specificity=90.48% avg_auc=91.04%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.342636 Test loss=0.334455 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.342262864112854
[5/24] Train loss=0.347015380859375
[10/24] Train loss=0.3736864924430847
[15/24] Train loss=0.31698793172836304
[20/24] Train loss=0.34019267559051514
Test set avg_accuracy=85.27% avg_sensitivity=68.25%, avg_specificity=91.08% avg_auc=91.08%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.340543 Test loss=0.331727 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3389403223991394
[5/24] Train loss=0.3514109253883362
[10/24] Train loss=0.37290599942207336
[15/24] Train loss=0.31919118762016296
[20/24] Train loss=0.34524810314178467
Test set avg_accuracy=85.33% avg_sensitivity=67.74%, avg_specificity=91.32% avg_auc=91.12%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.340589 Test loss=0.330780 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3404201567173004
[5/24] Train loss=0.34512192010879517
[10/24] Train loss=0.3756297528743744
[15/24] Train loss=0.31625258922576904
[20/24] Train loss=0.338034063577652
Test set avg_accuracy=85.36% avg_sensitivity=68.10%, avg_specificity=91.25% avg_auc=91.14%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.340124 Test loss=0.331306 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3404831886291504
[5/24] Train loss=0.34835466742515564
[10/24] Train loss=0.3749379813671112
[15/24] Train loss=0.31753742694854736
[20/24] Train loss=0.3387887179851532
Test set avg_accuracy=85.38% avg_sensitivity=67.74%, avg_specificity=91.39% avg_auc=91.14%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.339842 Test loss=0.330887 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.34081995487213135
[5/24] Train loss=0.34034261107444763
[10/24] Train loss=0.37441420555114746
[15/24] Train loss=0.31605708599090576
[20/24] Train loss=0.33566543459892273
Test set avg_accuracy=85.36% avg_sensitivity=67.03%, avg_specificity=91.62% avg_auc=91.15%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.338212 Test loss=0.329340 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.33160948753356934
[5/24] Train loss=0.34367212653160095
[10/24] Train loss=0.37609368562698364
[15/24] Train loss=0.31204909086227417
[20/24] Train loss=0.3388078510761261
Test set avg_accuracy=85.39% avg_sensitivity=67.28%, avg_specificity=91.57% avg_auc=91.19%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.338559 Test loss=0.330046 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.33803051710128784
[5/24] Train loss=0.3416881859302521
[10/24] Train loss=0.3739074170589447
[15/24] Train loss=0.3110691010951996
[20/24] Train loss=0.33609411120414734
Test set avg_accuracy=85.38% avg_sensitivity=66.62%, avg_specificity=91.78% avg_auc=91.19%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.337723 Test loss=0.328828 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.33207279443740845
[5/24] Train loss=0.3442404568195343
[10/24] Train loss=0.37233495712280273
[15/24] Train loss=0.31486430764198303
[20/24] Train loss=0.3333657383918762
Test set avg_accuracy=85.48% avg_sensitivity=66.36%, avg_specificity=92.00% avg_auc=91.22%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.337418 Test loss=0.328343 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3344394266605377
[5/24] Train loss=0.3455745279788971
[10/24] Train loss=0.3752763569355011
[15/24] Train loss=0.3155462443828583
[20/24] Train loss=0.3340889811515808
Test set avg_accuracy=85.42% avg_sensitivity=66.36%, avg_specificity=91.92% avg_auc=91.23%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.338039 Test loss=0.328395 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3322139382362366
[5/24] Train loss=0.3387663662433624
[10/24] Train loss=0.3720954656600952
[15/24] Train loss=0.3146773874759674
[20/24] Train loss=0.3316194415092468
Test set avg_accuracy=85.42% avg_sensitivity=65.95%, avg_specificity=92.06% avg_auc=91.22%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.337155 Test loss=0.328037 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.33611756563186646
[5/24] Train loss=0.3412005305290222
[10/24] Train loss=0.37283092737197876
[15/24] Train loss=0.3141306936740875
[20/24] Train loss=0.3354601263999939
Test set avg_accuracy=85.38% avg_sensitivity=65.80%, avg_specificity=92.06% avg_auc=91.23%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.336915 Test loss=0.327508 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3309279978275299
[5/24] Train loss=0.3427893817424774
[10/24] Train loss=0.37155959010124207
[15/24] Train loss=0.3124631941318512
[20/24] Train loss=0.3350098133087158
Test set avg_accuracy=85.42% avg_sensitivity=65.23%, avg_specificity=92.30% avg_auc=91.23%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.336328 Test loss=0.326887 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3318127691745758
[5/24] Train loss=0.3411257863044739
[10/24] Train loss=0.37123316526412964
[15/24] Train loss=0.3162294626235962
[20/24] Train loss=0.33102282881736755
Test set avg_accuracy=85.36% avg_sensitivity=64.77%, avg_specificity=92.39% avg_auc=91.22%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.335794 Test loss=0.326974 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.33394861221313477
[5/24] Train loss=0.3456719219684601
[10/24] Train loss=0.3701828718185425
[15/24] Train loss=0.31447023153305054
[20/24] Train loss=0.3340333104133606
Test set avg_accuracy=85.34% avg_sensitivity=64.11%, avg_specificity=92.58% avg_auc=91.24%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.336533 Test loss=0.326733 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3329177498817444
[5/24] Train loss=0.34170326590538025
[10/24] Train loss=0.37253090739250183
[15/24] Train loss=0.3142852187156677
[20/24] Train loss=0.3281465768814087
Test set avg_accuracy=85.27% avg_sensitivity=63.39%, avg_specificity=92.74% avg_auc=91.25%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.335604 Test loss=0.326342 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.33106303215026855
[5/24] Train loss=0.3414424657821655
[10/24] Train loss=0.3701363503932953
[15/24] Train loss=0.3147164583206177
[20/24] Train loss=0.3259428143501282
Test set avg_accuracy=85.25% avg_sensitivity=63.13%, avg_specificity=92.79% avg_auc=91.24%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.335325 Test loss=0.326132 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3315330147743225
[5/24] Train loss=0.34226569533348083
[10/24] Train loss=0.37192031741142273
[15/24] Train loss=0.3079242408275604
[20/24] Train loss=0.32654890418052673
Test set avg_accuracy=85.17% avg_sensitivity=62.37%, avg_specificity=92.95% avg_auc=91.25%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.334406 Test loss=0.325768 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.32604339718818665
[5/24] Train loss=0.34465542435646057
[10/24] Train loss=0.37235331535339355
[15/24] Train loss=0.31286922097206116
[20/24] Train loss=0.32668551802635193
Test set avg_accuracy=85.23% avg_sensitivity=61.80%, avg_specificity=93.23% avg_auc=91.26%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.335159 Test loss=0.325898 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3277105391025543
[5/24] Train loss=0.34574079513549805
[10/24] Train loss=0.3697760999202728
[15/24] Train loss=0.3159618675708771
[20/24] Train loss=0.3224736750125885
Test set avg_accuracy=85.26% avg_sensitivity=61.03%, avg_specificity=93.52% avg_auc=91.26%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.335600 Test loss=0.326080 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.32903146743774414
[5/24] Train loss=0.3408769965171814
[10/24] Train loss=0.37210750579833984
[15/24] Train loss=0.31477800011634827
[20/24] Train loss=0.32571688294410706
Test set avg_accuracy=85.30% avg_sensitivity=61.24%, avg_specificity=93.50% avg_auc=91.25%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.335586 Test loss=0.325944 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3291139006614685
[5/24] Train loss=0.3461794853210449
[10/24] Train loss=0.36917898058891296
[15/24] Train loss=0.3206077218055725
[20/24] Train loss=0.32171425223350525
Test set avg_accuracy=85.20% avg_sensitivity=61.50%, avg_specificity=93.28% avg_auc=91.26%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.335476 Test loss=0.325673 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3292442262172699
[5/24] Train loss=0.34522902965545654
[10/24] Train loss=0.37566861510276794
[15/24] Train loss=0.3180224895477295
[20/24] Train loss=0.31798797845840454
Test set avg_accuracy=85.20% avg_sensitivity=63.65%, avg_specificity=92.54% avg_auc=91.28%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.336941 Test loss=0.325730 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3287512958049774
[5/24] Train loss=0.34330958127975464
[10/24] Train loss=0.3663874566555023
[15/24] Train loss=0.3165923058986664
[20/24] Train loss=0.30995622277259827
Test set avg_accuracy=85.49% avg_sensitivity=66.72%, avg_specificity=91.90% avg_auc=91.25%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.335624 Test loss=0.327300 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3314160704612732
[5/24] Train loss=0.34890615940093994
[10/24] Train loss=0.3706299662590027
[15/24] Train loss=0.30921563506126404
[20/24] Train loss=0.313235878944397
Test set avg_accuracy=85.42% avg_sensitivity=68.36%, avg_specificity=91.23% avg_auc=91.24%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.335484 Test loss=0.329381 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3383371829986572
[5/24] Train loss=0.34005439281463623
[10/24] Train loss=0.37265944480895996
[15/24] Train loss=0.30692440271377563
[20/24] Train loss=0.3166714608669281
Test set avg_accuracy=85.40% avg_sensitivity=68.71%, avg_specificity=91.09% avg_auc=91.21%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.334968 Test loss=0.330060 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.33603397011756897
[5/24] Train loss=0.34022819995880127
[10/24] Train loss=0.3680470287799835
[15/24] Train loss=0.3061228394508362
[20/24] Train loss=0.32033389806747437
Test set avg_accuracy=85.46% avg_sensitivity=67.49%, avg_specificity=91.58% avg_auc=91.23%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.334238 Test loss=0.328512 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.3307303786277771
[5/24] Train loss=0.33774295449256897
[10/24] Train loss=0.3712742030620575
[15/24] Train loss=0.3060988187789917
[20/24] Train loss=0.3210107386112213
Test set avg_accuracy=85.48% avg_sensitivity=66.82%, avg_specificity=91.85% avg_auc=91.23%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.332646 Test loss=0.327830 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.32967257499694824
[5/24] Train loss=0.33674558997154236
[10/24] Train loss=0.3706861138343811
[15/24] Train loss=0.3076251149177551
[20/24] Train loss=0.31642594933509827
Test set avg_accuracy=85.51% avg_sensitivity=66.82%, avg_specificity=91.88% avg_auc=91.25%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.333060 Test loss=0.327391 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3339214324951172
[5/24] Train loss=0.33754783868789673
[10/24] Train loss=0.3698113262653351
[15/24] Train loss=0.3086298108100891
[20/24] Train loss=0.31535235047340393
Test set avg_accuracy=85.49% avg_sensitivity=66.82%, avg_specificity=91.86% avg_auc=91.27%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.333309 Test loss=0.327311 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.33158451318740845
[5/24] Train loss=0.339434951543808
[10/24] Train loss=0.37088093161582947
[15/24] Train loss=0.311847060918808
[20/24] Train loss=0.31497785449028015
Test set avg_accuracy=85.51% avg_sensitivity=66.51%, avg_specificity=91.99% avg_auc=91.27%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.333442 Test loss=0.326914 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.33378687500953674
[5/24] Train loss=0.34193772077560425
[10/24] Train loss=0.37541836500167847
[15/24] Train loss=0.3049992024898529
[20/24] Train loss=0.3170701563358307
Test set avg_accuracy=85.49% avg_sensitivity=66.51%, avg_specificity=91.97% avg_auc=91.27%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.333096 Test loss=0.327032 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3353428840637207
[5/24] Train loss=0.336087703704834
[10/24] Train loss=0.36402273178100586
[15/24] Train loss=0.30932512879371643
[20/24] Train loss=0.3180115222930908
Test set avg_accuracy=85.59% avg_sensitivity=66.10%, avg_specificity=92.23% avg_auc=91.29%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.333335 Test loss=0.326541 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3331623375415802
[5/24] Train loss=0.3421398401260376
[10/24] Train loss=0.3713166415691376
[15/24] Train loss=0.30826130509376526
[20/24] Train loss=0.31631743907928467
Test set avg_accuracy=85.59% avg_sensitivity=66.00%, avg_specificity=92.26% avg_auc=91.29%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.333489 Test loss=0.326492 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3313368558883667
[5/24] Train loss=0.3391689658164978
[10/24] Train loss=0.3733527660369873
[15/24] Train loss=0.30475878715515137
[20/24] Train loss=0.3166601359844208
Test set avg_accuracy=85.53% avg_sensitivity=66.10%, avg_specificity=92.16% avg_auc=91.28%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.332734 Test loss=0.326575 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.3274708390235901
[5/24] Train loss=0.34045132994651794
[10/24] Train loss=0.3715430796146393
[15/24] Train loss=0.311739981174469
[20/24] Train loss=0.316707044839859
Test set avg_accuracy=85.52% avg_sensitivity=65.85%, avg_specificity=92.23% avg_auc=91.28%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.332987 Test loss=0.326411 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.32933759689331055
[5/24] Train loss=0.3364420235157013
[10/24] Train loss=0.3665139079093933
[15/24] Train loss=0.304796427488327
[20/24] Train loss=0.31855955719947815
Test set avg_accuracy=85.52% avg_sensitivity=65.80%, avg_specificity=92.25% avg_auc=91.29%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.332806 Test loss=0.326366 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.33163008093833923
[5/24] Train loss=0.33889347314834595
[10/24] Train loss=0.37254074215888977
[15/24] Train loss=0.30675551295280457
[20/24] Train loss=0.31829744577407837
Test set avg_accuracy=85.52% avg_sensitivity=65.80%, avg_specificity=92.25% avg_auc=91.29%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.332436 Test loss=0.326313 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3265450894832611
[5/24] Train loss=0.33694398403167725
[10/24] Train loss=0.3736497461795807
[15/24] Train loss=0.3097003400325775
[20/24] Train loss=0.3158799111843109
Test set avg_accuracy=85.53% avg_sensitivity=65.75%, avg_specificity=92.28% avg_auc=91.29%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.332332 Test loss=0.326253 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.33392804861068726
[5/24] Train loss=0.33658894896507263
[10/24] Train loss=0.3739365339279175
[15/24] Train loss=0.3054669499397278
[20/24] Train loss=0.3172019422054291
Test set avg_accuracy=85.55% avg_sensitivity=65.75%, avg_specificity=92.30% avg_auc=91.29%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.332817 Test loss=0.326247 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.33246615529060364
[5/24] Train loss=0.33562496304512024
[10/24] Train loss=0.37282976508140564
[15/24] Train loss=0.3112260699272156
[20/24] Train loss=0.3151710629463196
Test set avg_accuracy=85.55% avg_sensitivity=65.75%, avg_specificity=92.30% avg_auc=91.29%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.333638 Test loss=0.326246 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.32833054661750793
[5/24] Train loss=0.3385778069496155
[10/24] Train loss=0.37120115756988525
[15/24] Train loss=0.30676189064979553
[20/24] Train loss=0.31958749890327454
Test set avg_accuracy=85.55% avg_sensitivity=65.75%, avg_specificity=92.30% avg_auc=91.29%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.333238 Test loss=0.326243 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.33023351430892944
[5/24] Train loss=0.3379599153995514
[10/24] Train loss=0.3699793517589569
[15/24] Train loss=0.30713534355163574
[20/24] Train loss=0.31906670331954956
Test set avg_accuracy=85.55% avg_sensitivity=65.75%, avg_specificity=92.30% avg_auc=91.29%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.331856 Test loss=0.326239 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=84.57% sen=75.73%, spe=87.59%, auc=90.82%!
Fold[5] Avg_overlap=0.63%(±0.2562577459558943)
[0/24] Train loss=0.8344998955726624
[5/24] Train loss=0.7098655700683594
[10/24] Train loss=0.6606459617614746
[15/24] Train loss=0.6164523959159851
[20/24] Train loss=0.6212843656539917
Test set avg_accuracy=72.81% avg_sensitivity=0.14%, avg_specificity=99.87% avg_auc=51.65%
Best model saved!! Metric=-101.52092536964297!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.671788 Test loss=0.592177 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6110245585441589
[5/24] Train loss=0.5804378986358643
[10/24] Train loss=0.5873450636863708
[15/24] Train loss=0.5731166005134583
[20/24] Train loss=0.5979886651039124
Test set avg_accuracy=72.84% avg_sensitivity=0.05%, avg_specificity=99.95% avg_auc=54.95%
Best model saved!! Metric=-98.21557997080676!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.595203 Test loss=0.581538 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.596564531326294
[5/24] Train loss=0.5685409903526306
[10/24] Train loss=0.5878728628158569
[15/24] Train loss=0.5684818029403687
[20/24] Train loss=0.5861209034919739
Test set avg_accuracy=72.81% avg_sensitivity=0.00%, avg_specificity=99.93% avg_auc=58.52%
Best model saved!! Metric=-94.74113921858087!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.586931 Test loss=0.575927 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.595281720161438
[5/24] Train loss=0.5659077763557434
[10/24] Train loss=0.5824449062347412
[15/24] Train loss=0.5658944249153137
[20/24] Train loss=0.5790124535560608
Test set avg_accuracy=72.83% avg_sensitivity=0.14%, avg_specificity=99.89% avg_auc=61.81%
Best model saved!! Metric=-91.3253759547481!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.581066 Test loss=0.570418 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5734081864356995
[5/24] Train loss=0.5597854852676392
[10/24] Train loss=0.5704768896102905
[15/24] Train loss=0.5499734282493591
[20/24] Train loss=0.5733255743980408
Test set avg_accuracy=72.84% avg_sensitivity=0.24%, avg_specificity=99.87% avg_auc=65.87%
Best model saved!! Metric=-87.17911592807813!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.571414 Test loss=0.562856 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5685544013977051
[5/24] Train loss=0.5488126277923584
[10/24] Train loss=0.5622254610061646
[15/24] Train loss=0.5452542901039124
[20/24] Train loss=0.5587647557258606
Test set avg_accuracy=72.76% avg_sensitivity=0.48%, avg_specificity=99.68% avg_auc=69.86%
Best model saved!! Metric=-83.2206055606166!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.563703 Test loss=0.554385 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5600524544715881
[5/24] Train loss=0.541409969329834
[10/24] Train loss=0.5582207441329956
[15/24] Train loss=0.5362322330474854
[20/24] Train loss=0.5565820336341858
Test set avg_accuracy=72.85% avg_sensitivity=1.44%, avg_specificity=99.45% avg_auc=72.75%
Best model saved!! Metric=-79.51350460990437!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.555223 Test loss=0.545869 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5532088279724121
[5/24] Train loss=0.5274083018302917
[10/24] Train loss=0.5485464930534363
[15/24] Train loss=0.5289210081100464
[20/24] Train loss=0.5434181690216064
Test set avg_accuracy=72.99% avg_sensitivity=2.54%, avg_specificity=99.23% avg_auc=75.36%
Best model saved!! Metric=-75.86844249154066!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.544958 Test loss=0.535712 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5392192006111145
[5/24] Train loss=0.5181576609611511
[10/24] Train loss=0.5384570360183716
[15/24] Train loss=0.5098673105239868
[20/24] Train loss=0.5309162735939026
Test set avg_accuracy=73.11% avg_sensitivity=4.22%, avg_specificity=98.77% avg_auc=77.55%
Best model saved!! Metric=-72.34952010138745!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.532680 Test loss=0.523716 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5275290608406067
[5/24] Train loss=0.5092641711235046
[10/24] Train loss=0.5233941674232483
[15/24] Train loss=0.4975806176662445
[20/24] Train loss=0.5150946974754333
Test set avg_accuracy=73.28% avg_sensitivity=5.28%, avg_specificity=98.61% avg_auc=78.62%
Best model saved!! Metric=-70.21461522591541!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.520786 Test loss=0.512755 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5158807635307312
[5/24] Train loss=0.4879869818687439
[10/24] Train loss=0.5136582255363464
[15/24] Train loss=0.4766032099723816
[20/24] Train loss=0.50063556432724
Test set avg_accuracy=73.68% avg_sensitivity=8.45%, avg_specificity=97.98% avg_auc=80.14%
Best model saved!! Metric=-65.74447653162711!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.507008 Test loss=0.498816 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.48989278078079224
[5/24] Train loss=0.4677325189113617
[10/24] Train loss=0.5065804123878479
[15/24] Train loss=0.4599253535270691
[20/24] Train loss=0.4790353775024414
Test set avg_accuracy=74.79% avg_sensitivity=15.45%, avg_specificity=96.89% avg_auc=81.76%
Best model saved!! Metric=-57.10221283871077!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.491593 Test loss=0.481507 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.47334399819374084
[5/24] Train loss=0.45916321873664856
[10/24] Train loss=0.48776909708976746
[15/24] Train loss=0.449757844209671
[20/24] Train loss=0.4661499857902527
Test set avg_accuracy=76.04% avg_sensitivity=23.18%, avg_specificity=95.73% avg_auc=83.21%
Best model saved!! Metric=-47.84265295291354!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.477238 Test loss=0.464469 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.46648961305618286
[5/24] Train loss=0.44438835978507996
[10/24] Train loss=0.48198041319847107
[15/24] Train loss=0.4375683069229126
[20/24] Train loss=0.4552571773529053
Test set avg_accuracy=77.38% avg_sensitivity=31.38%, avg_specificity=94.51% avg_auc=84.61%
Best model saved!! Metric=-38.11229745652229!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.464208 Test loss=0.446800 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4518114924430847
[5/24] Train loss=0.43006592988967896
[10/24] Train loss=0.4569229781627655
[15/24] Train loss=0.4241398572921753
[20/24] Train loss=0.44082313776016235
Test set avg_accuracy=78.87% avg_sensitivity=40.16%, avg_specificity=93.28% avg_auc=85.56%
Best model saved!! Metric=-28.12552528223133!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.449444 Test loss=0.431628 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4456714689731598
[5/24] Train loss=0.4211508631706238
[10/24] Train loss=0.449049711227417
[15/24] Train loss=0.4090118408203125
[20/24] Train loss=0.4284479022026062
Test set avg_accuracy=80.13% avg_sensitivity=47.07%, avg_specificity=92.44% avg_auc=86.40%
Best model saved!! Metric=-19.951395060371247!!
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.438628 Test loss=0.418315 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.43344563245773315
[5/24] Train loss=0.4114934206008911
[10/24] Train loss=0.44252678751945496
[15/24] Train loss=0.3958994746208191
[20/24] Train loss=0.4053758382797241
Test set avg_accuracy=80.62% avg_sensitivity=46.69%, avg_specificity=93.26% avg_auc=87.11%
Best model saved!! Metric=-18.316719407473663!!
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.426958 Test loss=0.405906 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.41479405760765076
[5/24] Train loss=0.3999967873096466
[10/24] Train loss=0.4320816397666931
[15/24] Train loss=0.38331276178359985
[20/24] Train loss=0.39881959557533264
Test set avg_accuracy=81.02% avg_sensitivity=45.68%, avg_specificity=94.17% avg_auc=87.71%
Best model saved!! Metric=-17.419014357149813!!
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.416402 Test loss=0.396437 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.40038567781448364
[5/24] Train loss=0.38589149713516235
[10/24] Train loss=0.4060990512371063
[15/24] Train loss=0.3763590157032013
[20/24] Train loss=0.3877265453338623
Test set avg_accuracy=82.04% avg_sensitivity=51.10%, avg_specificity=93.57% avg_auc=88.23%
Best model saved!! Metric=-11.056501379887244!!
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.406671 Test loss=0.386760 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.389191597700119
[5/24] Train loss=0.37243276834487915
[10/24] Train loss=0.4021092355251312
[15/24] Train loss=0.372329980134964
[20/24] Train loss=0.37392669916152954
Test set avg_accuracy=82.76% avg_sensitivity=54.56%, avg_specificity=93.26% avg_auc=88.80%
Best model saved!! Metric=-6.618098491542021!!
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.397407 Test loss=0.377984 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.37737324833869934
[5/24] Train loss=0.3670230805873871
[10/24] Train loss=0.39191102981567383
[15/24] Train loss=0.3661677837371826
[20/24] Train loss=0.3724142611026764
Test set avg_accuracy=83.06% avg_sensitivity=56.19%, avg_specificity=93.07% avg_auc=89.13%
Best model saved!! Metric=-4.5568299880993095!!
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.393783 Test loss=0.370826 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.37102052569389343
[5/24] Train loss=0.3689170479774475
[10/24] Train loss=0.38545212149620056
[15/24] Train loss=0.3712453544139862
[20/24] Train loss=0.3647162914276123
Test set avg_accuracy=83.35% avg_sensitivity=61.37%, avg_specificity=91.53% avg_auc=89.31%
Best model saved!! Metric=-0.4416325910805057!!
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.391541 Test loss=0.366594 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3738381266593933
[5/24] Train loss=0.35535910725593567
[10/24] Train loss=0.379982590675354
[15/24] Train loss=0.3534766733646393
[20/24] Train loss=0.3668000102043152
Test set avg_accuracy=83.66% avg_sensitivity=61.56%, avg_specificity=91.89% avg_auc=89.64%
Best model saved!! Metric=0.7549561945752785!!
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.384478 Test loss=0.361139 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3680154085159302
[5/24] Train loss=0.36394158005714417
[10/24] Train loss=0.3767353892326355
[15/24] Train loss=0.35247835516929626
[20/24] Train loss=0.35235464572906494
Test set avg_accuracy=83.80% avg_sensitivity=59.26%, avg_specificity=92.94% avg_auc=89.66%
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.381297 Test loss=0.359543 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.35710805654525757
[5/24] Train loss=0.35861748456954956
[10/24] Train loss=0.37660181522369385
[15/24] Train loss=0.3548802137374878
[20/24] Train loss=0.3535548448562622
Test set avg_accuracy=84.04% avg_sensitivity=60.60%, avg_specificity=92.76% avg_auc=89.77%
Best model saved!! Metric=1.178585661737614!!
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.379365 Test loss=0.356996 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.35727277398109436
[5/24] Train loss=0.3509054481983185
[10/24] Train loss=0.37549835443496704
[15/24] Train loss=0.3466067910194397
[20/24] Train loss=0.34045037627220154
Test set avg_accuracy=84.05% avg_sensitivity=59.50%, avg_specificity=93.19% avg_auc=89.88%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.375525 Test loss=0.355815 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3576454222202301
[5/24] Train loss=0.3508649170398712
[10/24] Train loss=0.3681276738643646
[15/24] Train loss=0.3424137234687805
[20/24] Train loss=0.3372914791107178
Test set avg_accuracy=84.04% avg_sensitivity=59.17%, avg_specificity=93.30% avg_auc=89.85%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.371848 Test loss=0.355422 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.34631863236427307
[5/24] Train loss=0.3467407524585724
[10/24] Train loss=0.3627835214138031
[15/24] Train loss=0.3389029800891876
[20/24] Train loss=0.33503392338752747
Test set avg_accuracy=83.72% avg_sensitivity=55.28%, avg_specificity=94.32% avg_auc=90.02%
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.368216 Test loss=0.355911 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3453584611415863
[5/24] Train loss=0.3486345112323761
[10/24] Train loss=0.3676758110523224
[15/24] Train loss=0.3345956802368164
[20/24] Train loss=0.33107975125312805
Test set avg_accuracy=83.88% avg_sensitivity=56.09%, avg_specificity=94.23% avg_auc=90.03%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.368676 Test loss=0.354970 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.34262707829475403
[5/24] Train loss=0.3446705937385559
[10/24] Train loss=0.37051236629486084
[15/24] Train loss=0.33538317680358887
[20/24] Train loss=0.3322976529598236
Test set avg_accuracy=83.95% avg_sensitivity=56.33%, avg_specificity=94.23% avg_auc=90.10%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.366548 Test loss=0.354237 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.34470051527023315
[5/24] Train loss=0.3477516770362854
[10/24] Train loss=0.3638887107372284
[15/24] Train loss=0.3379790484905243
[20/24] Train loss=0.3263465464115143
Test set avg_accuracy=84.08% avg_sensitivity=56.43%, avg_specificity=94.37% avg_auc=90.02%
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.365314 Test loss=0.355253 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3473738431930542
[5/24] Train loss=0.345513254404068
[10/24] Train loss=0.364425927400589
[15/24] Train loss=0.3409518599510193
[20/24] Train loss=0.33194398880004883
Test set avg_accuracy=84.21% avg_sensitivity=57.44%, avg_specificity=94.17% avg_auc=90.03%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.365020 Test loss=0.354310 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3425780236721039
[5/24] Train loss=0.34306472539901733
[10/24] Train loss=0.35962995886802673
[15/24] Train loss=0.3376902937889099
[20/24] Train loss=0.32659053802490234
Test set avg_accuracy=84.19% avg_sensitivity=56.29%, avg_specificity=94.59% avg_auc=90.20%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.361987 Test loss=0.353162 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3399348258972168
[5/24] Train loss=0.34567809104919434
[10/24] Train loss=0.35840684175491333
[15/24] Train loss=0.32963448762893677
[20/24] Train loss=0.32030341029167175
Test set avg_accuracy=83.82% avg_sensitivity=53.93%, avg_specificity=94.94% avg_auc=90.07%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.360144 Test loss=0.358004 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.34232205152511597
[5/24] Train loss=0.3401900827884674
[10/24] Train loss=0.3609207570552826
[15/24] Train loss=0.3329683542251587
[20/24] Train loss=0.3210850656032562
Test set avg_accuracy=84.01% avg_sensitivity=54.80%, avg_specificity=94.89% avg_auc=90.12%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.359662 Test loss=0.356337 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.34081563353538513
[5/24] Train loss=0.3457055985927582
[10/24] Train loss=0.3547727167606354
[15/24] Train loss=0.3259125351905823
[20/24] Train loss=0.3182468116283417
Test set avg_accuracy=83.72% avg_sensitivity=53.36%, avg_specificity=95.03% avg_auc=90.16%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.357473 Test loss=0.357628 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3353257179260254
[5/24] Train loss=0.34150272607803345
[10/24] Train loss=0.35861659049987793
[15/24] Train loss=0.32385700941085815
[20/24] Train loss=0.31181520223617554
Test set avg_accuracy=83.78% avg_sensitivity=51.92%, avg_specificity=95.64% avg_auc=90.21%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.355692 Test loss=0.360045 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.33294063806533813
[5/24] Train loss=0.3421019911766052
[10/24] Train loss=0.3544863760471344
[15/24] Train loss=0.3279170095920563
[20/24] Train loss=0.3218613862991333
Test set avg_accuracy=83.67% avg_sensitivity=51.34%, avg_specificity=95.71% avg_auc=90.22%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.354615 Test loss=0.360837 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.33332252502441406
[5/24] Train loss=0.34066513180732727
[10/24] Train loss=0.35356050729751587
[15/24] Train loss=0.3242749571800232
[20/24] Train loss=0.31754812598228455
Test set avg_accuracy=83.55% avg_sensitivity=50.62%, avg_specificity=95.82% avg_auc=90.28%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.352578 Test loss=0.361036 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3350067138671875
[5/24] Train loss=0.33678072690963745
[10/24] Train loss=0.3530615568161011
[15/24] Train loss=0.32180097699165344
[20/24] Train loss=0.3161989152431488
Test set avg_accuracy=83.52% avg_sensitivity=50.38%, avg_specificity=95.85% avg_auc=90.27%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.351988 Test loss=0.361750 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.33582377433776855
[5/24] Train loss=0.3384266197681427
[10/24] Train loss=0.34735366702079773
[15/24] Train loss=0.32333624362945557
[20/24] Train loss=0.3119576871395111
Test set avg_accuracy=83.65% avg_sensitivity=50.82%, avg_specificity=95.87% avg_auc=90.40%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.349217 Test loss=0.359259 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3332834541797638
[5/24] Train loss=0.33659490942955017
[10/24] Train loss=0.3492044508457184
[15/24] Train loss=0.3254088759422302
[20/24] Train loss=0.3124053180217743
Test set avg_accuracy=83.72% avg_sensitivity=51.49%, avg_specificity=95.73% avg_auc=90.41%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.347863 Test loss=0.357427 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3309437334537506
[5/24] Train loss=0.3432755470275879
[10/24] Train loss=0.3473998010158539
[15/24] Train loss=0.3247513771057129
[20/24] Train loss=0.31101271510124207
Test set avg_accuracy=83.48% avg_sensitivity=49.62%, avg_specificity=96.09% avg_auc=90.43%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.347115 Test loss=0.361975 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.33247116208076477
[5/24] Train loss=0.34205466508865356
[10/24] Train loss=0.3464798927307129
[15/24] Train loss=0.3172677457332611
[20/24] Train loss=0.3101169168949127
Test set avg_accuracy=83.33% avg_sensitivity=49.14%, avg_specificity=96.07% avg_auc=90.47%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.345449 Test loss=0.361409 Current lr=[0.00029967723776099]

[0/24] Train loss=0.33271870017051697
[5/24] Train loss=0.3442010283470154
[10/24] Train loss=0.34471631050109863
[15/24] Train loss=0.31754598021507263
[20/24] Train loss=0.3110372722148895
Test set avg_accuracy=83.31% avg_sensitivity=49.90%, avg_specificity=95.75% avg_auc=90.61%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.345837 Test loss=0.356685 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.32928717136383057
[5/24] Train loss=0.343810111284256
[10/24] Train loss=0.3515365421772003
[15/24] Train loss=0.3203437924385071
[20/24] Train loss=0.3087465465068817
Test set avg_accuracy=83.32% avg_sensitivity=49.38%, avg_specificity=95.96% avg_auc=90.58%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.344020 Test loss=0.359205 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.32922807335853577
[5/24] Train loss=0.3445092737674713
[10/24] Train loss=0.34463509917259216
[15/24] Train loss=0.316182404756546
[20/24] Train loss=0.309375137090683
Test set avg_accuracy=83.32% avg_sensitivity=48.94%, avg_specificity=96.12% avg_auc=90.56%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.343677 Test loss=0.361285 Current lr=[0.000299720220882401]

[0/24] Train loss=0.33563336730003357
[5/24] Train loss=0.34544533491134644
[10/24] Train loss=0.3406943082809448
[15/24] Train loss=0.31894809007644653
[20/24] Train loss=0.3073529005050659
Test set avg_accuracy=83.55% avg_sensitivity=50.38%, avg_specificity=95.91% avg_auc=90.74%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.341814 Test loss=0.355623 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.32871466875076294
[5/24] Train loss=0.3487529754638672
[10/24] Train loss=0.33824852108955383
[15/24] Train loss=0.31907400488853455
[20/24] Train loss=0.30987823009490967
Test set avg_accuracy=83.75% avg_sensitivity=51.63%, avg_specificity=95.71% avg_auc=90.76%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.341742 Test loss=0.353101 Current lr=[0.000298904600941902]

[0/24] Train loss=0.32675114274024963
[5/24] Train loss=0.34694597125053406
[10/24] Train loss=0.33871105313301086
[15/24] Train loss=0.31174007058143616
[20/24] Train loss=0.30498626828193665
Test set avg_accuracy=83.67% avg_sensitivity=51.82%, avg_specificity=95.53% avg_auc=90.83%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.340081 Test loss=0.351189 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3239504396915436
[5/24] Train loss=0.3559548854827881
[10/24] Train loss=0.33566373586654663
[15/24] Train loss=0.3127882480621338
[20/24] Train loss=0.3054940402507782
Test set avg_accuracy=84.01% avg_sensitivity=53.21%, avg_specificity=95.48% avg_auc=90.88%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.340293 Test loss=0.348349 Current lr=[0.000297555943323901]

[0/24] Train loss=0.32469096779823303
[5/24] Train loss=0.35036954283714294
[10/24] Train loss=0.3374670445919037
[15/24] Train loss=0.30796244740486145
[20/24] Train loss=0.30837002396583557
Test set avg_accuracy=84.21% avg_sensitivity=54.51%, avg_specificity=95.26% avg_auc=90.93%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.338570 Test loss=0.345091 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.32217761874198914
[5/24] Train loss=0.3470173180103302
[10/24] Train loss=0.33594828844070435
[15/24] Train loss=0.3081309497356415
[20/24] Train loss=0.30402672290802
Test set avg_accuracy=84.15% avg_sensitivity=54.08%, avg_specificity=95.35% avg_auc=90.99%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.337913 Test loss=0.344446 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3224502205848694
[5/24] Train loss=0.34374427795410156
[10/24] Train loss=0.3366864025592804
[15/24] Train loss=0.314345121383667
[20/24] Train loss=0.30150237679481506
Test set avg_accuracy=84.40% avg_sensitivity=55.09%, avg_specificity=95.32% avg_auc=91.00%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.337692 Test loss=0.343100 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3257831931114197
[5/24] Train loss=0.3542022705078125
[10/24] Train loss=0.3363918364048004
[15/24] Train loss=0.31400275230407715
[20/24] Train loss=0.3014732599258423
Test set avg_accuracy=84.40% avg_sensitivity=54.99%, avg_specificity=95.35% avg_auc=91.03%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.337383 Test loss=0.342978 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3221549093723297
[5/24] Train loss=0.34974950551986694
[10/24] Train loss=0.3357609212398529
[15/24] Train loss=0.31156647205352783
[20/24] Train loss=0.2995615601539612
Test set avg_accuracy=84.64% avg_sensitivity=57.05%, avg_specificity=94.91% avg_auc=91.06%
Best model saved!! Metric=1.6605021060880318!!
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.336232 Test loss=0.339730 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.31962087750434875
[5/24] Train loss=0.34499385952949524
[10/24] Train loss=0.3390020430088043
[15/24] Train loss=0.3095867335796356
[20/24] Train loss=0.30181509256362915
Test set avg_accuracy=84.95% avg_sensitivity=58.49%, avg_specificity=94.80% avg_auc=91.13%
Best model saved!! Metric=3.3724970839924566!!
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.335796 Test loss=0.337697 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.32336127758026123
[5/24] Train loss=0.35048550367355347
[10/24] Train loss=0.33630895614624023
[15/24] Train loss=0.308379590511322
[20/24] Train loss=0.29837432503700256
Test set avg_accuracy=84.70% avg_sensitivity=57.29%, avg_specificity=94.91% avg_auc=91.12%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.335771 Test loss=0.338580 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3233610689640045
[5/24] Train loss=0.34052562713623047
[10/24] Train loss=0.3373092710971832
[15/24] Train loss=0.31190547347068787
[20/24] Train loss=0.3015054762363434
Test set avg_accuracy=84.87% avg_sensitivity=58.21%, avg_specificity=94.80% avg_auc=91.08%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.335592 Test loss=0.337829 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3188096582889557
[5/24] Train loss=0.3454527258872986
[10/24] Train loss=0.33836793899536133
[15/24] Train loss=0.30956658720970154
[20/24] Train loss=0.2946929335594177
Test set avg_accuracy=85.22% avg_sensitivity=59.64%, avg_specificity=94.75% avg_auc=91.19%
Best model saved!! Metric=4.806603913195225!!
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.334477 Test loss=0.335653 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3201444149017334
[5/24] Train loss=0.3453230857849121
[10/24] Train loss=0.33962637186050415
[15/24] Train loss=0.3130265772342682
[20/24] Train loss=0.29989930987358093
Test set avg_accuracy=85.10% avg_sensitivity=59.45%, avg_specificity=94.66% avg_auc=91.20%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.334724 Test loss=0.335421 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.31985414028167725
[5/24] Train loss=0.3417644500732422
[10/24] Train loss=0.3364257216453552
[15/24] Train loss=0.30839985609054565
[20/24] Train loss=0.295751690864563
Test set avg_accuracy=85.03% avg_sensitivity=58.59%, avg_specificity=94.87% avg_auc=91.22%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.333262 Test loss=0.335900 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.32257309556007385
[5/24] Train loss=0.3448515832424164
[10/24] Train loss=0.3386293947696686
[15/24] Train loss=0.3080117106437683
[20/24] Train loss=0.2952783703804016
Test set avg_accuracy=84.88% avg_sensitivity=57.68%, avg_specificity=95.01% avg_auc=91.21%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.334560 Test loss=0.337218 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.31870973110198975
[5/24] Train loss=0.34733590483665466
[10/24] Train loss=0.33570197224617004
[15/24] Train loss=0.31626206636428833
[20/24] Train loss=0.29960304498672485
Test set avg_accuracy=84.56% avg_sensitivity=55.28%, avg_specificity=95.46% avg_auc=91.17%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.334280 Test loss=0.340543 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3183578550815582
[5/24] Train loss=0.34690093994140625
[10/24] Train loss=0.3401244282722473
[15/24] Train loss=0.3116915822029114
[20/24] Train loss=0.2999705672264099
Test set avg_accuracy=84.80% avg_sensitivity=57.01%, avg_specificity=95.16% avg_auc=91.21%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.332829 Test loss=0.337733 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.31620681285858154
[5/24] Train loss=0.3457859456539154
[10/24] Train loss=0.3320232033729553
[15/24] Train loss=0.3137117624282837
[20/24] Train loss=0.29814422130584717
Test set avg_accuracy=84.74% avg_sensitivity=55.85%, avg_specificity=95.50% avg_auc=91.21%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.333194 Test loss=0.339684 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.31538522243499756
[5/24] Train loss=0.3446829617023468
[10/24] Train loss=0.3350016474723816
[15/24] Train loss=0.30794069170951843
[20/24] Train loss=0.2984539866447449
Test set avg_accuracy=85.03% avg_sensitivity=59.12%, avg_specificity=94.67% avg_auc=91.25%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.331598 Test loss=0.334617 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.31837910413742065
[5/24] Train loss=0.34387150406837463
[10/24] Train loss=0.3336859941482544
[15/24] Train loss=0.30772078037261963
[20/24] Train loss=0.29881972074508667
Test set avg_accuracy=84.57% avg_sensitivity=55.33%, avg_specificity=95.46% avg_auc=91.24%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.331205 Test loss=0.339654 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.31844374537467957
[5/24] Train loss=0.3490924835205078
[10/24] Train loss=0.33314281702041626
[15/24] Train loss=0.3143419921398163
[20/24] Train loss=0.2960537374019623
Test set avg_accuracy=84.92% avg_sensitivity=57.97%, avg_specificity=94.96% avg_auc=91.29%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.331799 Test loss=0.335106 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3136001229286194
[5/24] Train loss=0.3441648781299591
[10/24] Train loss=0.3392236530780792
[15/24] Train loss=0.30363091826438904
[20/24] Train loss=0.294512003660202
Test set avg_accuracy=84.84% avg_sensitivity=56.91%, avg_specificity=95.25% avg_auc=91.28%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.330366 Test loss=0.336909 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3131316900253296
[5/24] Train loss=0.34092575311660767
[10/24] Train loss=0.33779001235961914
[15/24] Train loss=0.3048442006111145
[20/24] Train loss=0.2965587079524994
Test set avg_accuracy=85.17% avg_sensitivity=58.54%, avg_specificity=95.09% avg_auc=91.29%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.330000 Test loss=0.334801 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.31679415702819824
[5/24] Train loss=0.34228211641311646
[10/24] Train loss=0.33522099256515503
[15/24] Train loss=0.3076777756214142
[20/24] Train loss=0.2948695123195648
Test set avg_accuracy=85.22% avg_sensitivity=59.74%, avg_specificity=94.71% avg_auc=91.32%
Best model saved!! Metric=4.9898690710609515!!
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.329908 Test loss=0.332954 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3139859139919281
[5/24] Train loss=0.3356982171535492
[10/24] Train loss=0.3328797221183777
[15/24] Train loss=0.30204880237579346
[20/24] Train loss=0.2969872057437897
Test set avg_accuracy=84.71% avg_sensitivity=55.33%, avg_specificity=95.66% avg_auc=91.36%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.329800 Test loss=0.338451 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.31607842445373535
[5/24] Train loss=0.34490761160850525
[10/24] Train loss=0.3313322961330414
[15/24] Train loss=0.3080243468284607
[20/24] Train loss=0.29635775089263916
Test set avg_accuracy=85.09% avg_sensitivity=57.97%, avg_specificity=95.19% avg_auc=91.31%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.329929 Test loss=0.335545 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3145551085472107
[5/24] Train loss=0.34049972891807556
[10/24] Train loss=0.3319641947746277
[15/24] Train loss=0.30717751383781433
[20/24] Train loss=0.296619713306427
Test set avg_accuracy=85.14% avg_sensitivity=58.21%, avg_specificity=95.18% avg_auc=91.23%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.330220 Test loss=0.336268 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3170868456363678
[5/24] Train loss=0.33968695998191833
[10/24] Train loss=0.32909175753593445
[15/24] Train loss=0.30609145760536194
[20/24] Train loss=0.2977030277252197
Test set avg_accuracy=84.91% avg_sensitivity=56.00%, avg_specificity=95.68% avg_auc=91.13%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.330527 Test loss=0.341343 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3169369399547577
[5/24] Train loss=0.34367433190345764
[10/24] Train loss=0.33288949728012085
[15/24] Train loss=0.30871328711509705
[20/24] Train loss=0.29733389616012573
Test set avg_accuracy=84.52% avg_sensitivity=53.74%, avg_specificity=95.98% avg_auc=91.04%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.331363 Test loss=0.345596 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.31563857197761536
[5/24] Train loss=0.34610918164253235
[10/24] Train loss=0.3317610025405884
[15/24] Train loss=0.3036954998970032
[20/24] Train loss=0.29831185936927795
Test set avg_accuracy=84.26% avg_sensitivity=52.93%, avg_specificity=95.93% avg_auc=90.91%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.330692 Test loss=0.348741 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.31602391600608826
[5/24] Train loss=0.3399944603443146
[10/24] Train loss=0.3405812680721283
[15/24] Train loss=0.307791143655777
[20/24] Train loss=0.2934815585613251
Test set avg_accuracy=84.28% avg_sensitivity=52.50%, avg_specificity=96.12% avg_auc=91.04%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.332118 Test loss=0.348097 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.31830474734306335
[5/24] Train loss=0.33661216497421265
[10/24] Train loss=0.341545045375824
[15/24] Train loss=0.30758413672447205
[20/24] Train loss=0.2919517457485199
Test set avg_accuracy=85.14% avg_sensitivity=58.64%, avg_specificity=95.01% avg_auc=91.20%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.331905 Test loss=0.336570 Current lr=[0.000224838296036774]

[0/24] Train loss=0.31573188304901123
[5/24] Train loss=0.33686399459838867
[10/24] Train loss=0.34017133712768555
[15/24] Train loss=0.3057451844215393
[20/24] Train loss=0.29479849338531494
Test set avg_accuracy=84.74% avg_sensitivity=56.33%, avg_specificity=95.32% avg_auc=91.14%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.330951 Test loss=0.340265 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.31346186995506287
[5/24] Train loss=0.34084388613700867
[10/24] Train loss=0.33508846163749695
[15/24] Train loss=0.3093429207801819
[20/24] Train loss=0.2900084853172302
Test set avg_accuracy=84.64% avg_sensitivity=55.57%, avg_specificity=95.46% avg_auc=91.15%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.330923 Test loss=0.340868 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.314871609210968
[5/24] Train loss=0.3360540568828583
[10/24] Train loss=0.33809396624565125
[15/24] Train loss=0.30737343430519104
[20/24] Train loss=0.28999269008636475
Test set avg_accuracy=84.45% avg_sensitivity=54.75%, avg_specificity=95.51% avg_auc=91.05%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.331347 Test loss=0.344161 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.31789737939834595
[5/24] Train loss=0.3429561257362366
[10/24] Train loss=0.33225709199905396
[15/24] Train loss=0.307693749666214
[20/24] Train loss=0.28887641429901123
Test set avg_accuracy=84.73% avg_sensitivity=56.33%, avg_specificity=95.30% avg_auc=91.08%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.331650 Test loss=0.341378 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3152170479297638
[5/24] Train loss=0.34080734848976135
[10/24] Train loss=0.3319481909275055
[15/24] Train loss=0.30633822083473206
[20/24] Train loss=0.2914145290851593
Test set avg_accuracy=84.35% avg_sensitivity=54.27%, avg_specificity=95.55% avg_auc=90.91%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.332727 Test loss=0.347398 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.31685787439346313
[5/24] Train loss=0.34307050704956055
[10/24] Train loss=0.3365015387535095
[15/24] Train loss=0.30760303139686584
[20/24] Train loss=0.2904123067855835
Test set avg_accuracy=85.03% avg_sensitivity=59.79%, avg_specificity=94.42% avg_auc=91.07%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.335540 Test loss=0.335766 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.31556859612464905
[5/24] Train loss=0.3399394452571869
[10/24] Train loss=0.3382238447666168
[15/24] Train loss=0.30750352144241333
[20/24] Train loss=0.3019202649593353
Test set avg_accuracy=85.47% avg_sensitivity=67.47%, avg_specificity=92.17% avg_auc=91.09%
Best model saved!! Metric=10.202458029727865!!
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.337468 Test loss=0.331134 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3280051648616791
[5/24] Train loss=0.3358990252017975
[10/24] Train loss=0.3326505720615387
[15/24] Train loss=0.3069405257701874
[20/24] Train loss=0.30655741691589355
Test set avg_accuracy=85.48% avg_sensitivity=66.75%, avg_specificity=92.46% avg_auc=91.05%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.334342 Test loss=0.331435 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.3211342990398407
[5/24] Train loss=0.3364638686180115
[10/24] Train loss=0.3325673043727875
[15/24] Train loss=0.30781951546669006
[20/24] Train loss=0.298022985458374
Test set avg_accuracy=85.29% avg_sensitivity=64.30%, avg_specificity=93.10% avg_auc=91.06%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.330986 Test loss=0.331972 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3209943175315857
[5/24] Train loss=0.3359595835208893
[10/24] Train loss=0.33137229084968567
[15/24] Train loss=0.3059348464012146
[20/24] Train loss=0.2992947995662689
Test set avg_accuracy=85.49% avg_sensitivity=65.69%, avg_specificity=92.87% avg_auc=91.18%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.330278 Test loss=0.329692 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3226524293422699
[5/24] Train loss=0.33906808495521545
[10/24] Train loss=0.329307496547699
[15/24] Train loss=0.30122262239456177
[20/24] Train loss=0.29773640632629395
Test set avg_accuracy=85.49% avg_sensitivity=66.31%, avg_specificity=92.64% avg_auc=91.19%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.329605 Test loss=0.329251 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.32611674070358276
[5/24] Train loss=0.3322150409221649
[10/24] Train loss=0.3314446210861206
[15/24] Train loss=0.3054071068763733
[20/24] Train loss=0.30089879035949707
Test set avg_accuracy=85.48% avg_sensitivity=65.50%, avg_specificity=92.92% avg_auc=91.19%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.330783 Test loss=0.329412 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3196806013584137
[5/24] Train loss=0.33084872364997864
[10/24] Train loss=0.3326217234134674
[15/24] Train loss=0.3029554486274719
[20/24] Train loss=0.2953358590602875
Test set avg_accuracy=85.42% avg_sensitivity=65.16%, avg_specificity=92.96% avg_auc=91.16%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.329170 Test loss=0.329839 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3216903805732727
[5/24] Train loss=0.33637526631355286
[10/24] Train loss=0.3273080885410309
[15/24] Train loss=0.30143845081329346
[20/24] Train loss=0.29740217328071594
Test set avg_accuracy=85.46% avg_sensitivity=65.40%, avg_specificity=92.92% avg_auc=91.18%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.329399 Test loss=0.329615 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3175833523273468
[5/24] Train loss=0.3379462957382202
[10/24] Train loss=0.33026206493377686
[15/24] Train loss=0.30348119139671326
[20/24] Train loss=0.29710623621940613
Test set avg_accuracy=85.62% avg_sensitivity=66.36%, avg_specificity=92.80% avg_auc=91.30%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.330107 Test loss=0.327615 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3199943006038666
[5/24] Train loss=0.33261364698410034
[10/24] Train loss=0.33326607942581177
[15/24] Train loss=0.3095041513442993
[20/24] Train loss=0.2968953549861908
Test set avg_accuracy=86.16% avg_sensitivity=69.34%, avg_specificity=92.42% avg_auc=91.41%
Best model saved!! Metric=13.325960778326476!!
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.330850 Test loss=0.326125 Current lr=[0.000156543481933168]

[0/24] Train loss=0.32262319326400757
[5/24] Train loss=0.33119863271713257
[10/24] Train loss=0.3320837616920471
[15/24] Train loss=0.31142279505729675
[20/24] Train loss=0.3016275465488434
Test set avg_accuracy=85.82% avg_sensitivity=71.69%, avg_specificity=91.08% avg_auc=91.30%
Best model saved!! Metric=13.894634163815269!!
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.330685 Test loss=0.329189 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3318467140197754
[5/24] Train loss=0.3407618999481201
[10/24] Train loss=0.3347495496273041
[15/24] Train loss=0.30711910128593445
[20/24] Train loss=0.3023950159549713
Test set avg_accuracy=85.99% avg_sensitivity=70.30%, avg_specificity=91.83% avg_auc=91.41%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.329465 Test loss=0.326511 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3216814696788788
[5/24] Train loss=0.34242841601371765
[10/24] Train loss=0.33554452657699585
[15/24] Train loss=0.30326101183891296
[20/24] Train loss=0.2982661724090576
Test set avg_accuracy=86.03% avg_sensitivity=70.54%, avg_specificity=91.80% avg_auc=91.42%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.326943 Test loss=0.326003 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.32717567682266235
[5/24] Train loss=0.33883506059646606
[10/24] Train loss=0.33089837431907654
[15/24] Train loss=0.30376315116882324
[20/24] Train loss=0.29436472058296204
Test set avg_accuracy=86.09% avg_sensitivity=70.15%, avg_specificity=92.03% avg_auc=91.48%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.326860 Test loss=0.325074 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.31796249747276306
[5/24] Train loss=0.340302973985672
[10/24] Train loss=0.33103251457214355
[15/24] Train loss=0.3063598871231079
[20/24] Train loss=0.29492348432540894
Test set avg_accuracy=86.02% avg_sensitivity=71.50%, avg_specificity=91.42% avg_auc=91.44%
Best model saved!! Metric=14.377683037067897!!
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.325964 Test loss=0.326057 Current lr=[0.000134135431043539]

[0/24] Train loss=0.32593125104904175
[5/24] Train loss=0.3384783864021301
[10/24] Train loss=0.33413416147232056
[15/24] Train loss=0.3052467107772827
[20/24] Train loss=0.2949379086494446
Test set avg_accuracy=86.05% avg_sensitivity=70.54%, avg_specificity=91.83% avg_auc=91.46%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.326136 Test loss=0.325286 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.32249096035957336
[5/24] Train loss=0.3390718102455139
[10/24] Train loss=0.33371907472610474
[15/24] Train loss=0.3012336194515228
[20/24] Train loss=0.29221639037132263
Test set avg_accuracy=86.05% avg_sensitivity=70.92%, avg_specificity=91.69% avg_auc=91.49%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.325104 Test loss=0.325002 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3238743841648102
[5/24] Train loss=0.33639413118362427
[10/24] Train loss=0.33848071098327637
[15/24] Train loss=0.30038174986839294
[20/24] Train loss=0.2900165915489197
Test set avg_accuracy=86.21% avg_sensitivity=70.87%, avg_specificity=91.92% avg_auc=91.49%
Best model saved!! Metric=14.49685978614076!!
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.325162 Test loss=0.324559 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3191206753253937
[5/24] Train loss=0.3398771584033966
[10/24] Train loss=0.3340490162372589
[15/24] Train loss=0.30058005452156067
[20/24] Train loss=0.291149765253067
Test set avg_accuracy=86.21% avg_sensitivity=71.40%, avg_specificity=91.73% avg_auc=91.53%
Best model saved!! Metric=14.872526563479667!!
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.324959 Test loss=0.324521 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3223227858543396
[5/24] Train loss=0.34220224618911743
[10/24] Train loss=0.34120434522628784
[15/24] Train loss=0.3051462769508362
[20/24] Train loss=0.2954079210758209
Test set avg_accuracy=86.17% avg_sensitivity=71.64%, avg_specificity=91.58% avg_auc=91.54%
Best model saved!! Metric=14.932498848402801!!
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.324862 Test loss=0.324854 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3234003186225891
[5/24] Train loss=0.33913034200668335
[10/24] Train loss=0.3376379907131195
[15/24] Train loss=0.3009108304977417
[20/24] Train loss=0.2931995689868927
Test set avg_accuracy=85.96% avg_sensitivity=72.12%, avg_specificity=91.12% avg_auc=91.55%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.324360 Test loss=0.325497 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.32673442363739014
[5/24] Train loss=0.3454298973083496
[10/24] Train loss=0.3407849669456482
[15/24] Train loss=0.3007354140281677
[20/24] Train loss=0.29313209652900696
Test set avg_accuracy=85.91% avg_sensitivity=73.42%, avg_specificity=90.56% avg_auc=91.54%
Best model saved!! Metric=15.428822155037622!!
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.325261 Test loss=0.327084 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3322657346725464
[5/24] Train loss=0.3483157157897949
[10/24] Train loss=0.3428793251514435
[15/24] Train loss=0.2997336983680725
[20/24] Train loss=0.2982712984085083
Test set avg_accuracy=85.82% avg_sensitivity=74.81%, avg_specificity=89.92% avg_auc=91.52%
Best model saved!! Metric=16.072044611914336!!
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.326618 Test loss=0.329996 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3339129388332367
[5/24] Train loss=0.35102522373199463
[10/24] Train loss=0.3407738506793976
[15/24] Train loss=0.30059802532196045
[20/24] Train loss=0.3110949397087097
Test set avg_accuracy=85.82% avg_sensitivity=74.52%, avg_specificity=90.03% avg_auc=91.54%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.328292 Test loss=0.329445 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.33474206924438477
[5/24] Train loss=0.3466797471046448
[10/24] Train loss=0.332430362701416
[15/24] Train loss=0.3068605959415436
[20/24] Train loss=0.3166324198246002
Test set avg_accuracy=86.09% avg_sensitivity=71.11%, avg_specificity=91.67% avg_auc=91.60%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.328742 Test loss=0.324160 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3227359354496002
[5/24] Train loss=0.33997759222984314
[10/24] Train loss=0.3336355984210968
[15/24] Train loss=0.30387914180755615
[20/24] Train loss=0.2975051999092102
Test set avg_accuracy=86.12% avg_sensitivity=68.81%, avg_specificity=92.57% avg_auc=91.57%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.324822 Test loss=0.323570 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3117731213569641
[5/24] Train loss=0.33369556069374084
[10/24] Train loss=0.3328178822994232
[15/24] Train loss=0.29954469203948975
[20/24] Train loss=0.2958304286003113
Test set avg_accuracy=86.07% avg_sensitivity=69.67%, avg_specificity=92.17% avg_auc=91.57%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.322850 Test loss=0.323981 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.31662946939468384
[5/24] Train loss=0.3437376320362091
[10/24] Train loss=0.3350358009338379
[15/24] Train loss=0.29926735162734985
[20/24] Train loss=0.2993508279323578
Test set avg_accuracy=85.90% avg_sensitivity=70.73%, avg_specificity=91.55% avg_auc=91.47%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.323572 Test loss=0.326350 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.32642996311187744
[5/24] Train loss=0.3414105772972107
[10/24] Train loss=0.3355991244316101
[15/24] Train loss=0.30040213465690613
[20/24] Train loss=0.2986961603164673
Test set avg_accuracy=85.74% avg_sensitivity=71.16%, avg_specificity=91.17% avg_auc=91.30%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.324560 Test loss=0.329657 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.32808101177215576
[5/24] Train loss=0.3409702479839325
[10/24] Train loss=0.3325674831867218
[15/24] Train loss=0.29640328884124756
[20/24] Train loss=0.301378071308136
Test set avg_accuracy=85.70% avg_sensitivity=70.49%, avg_specificity=91.37% avg_auc=91.31%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.324598 Test loss=0.328955 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3199537992477417
[5/24] Train loss=0.33698782324790955
[10/24] Train loss=0.3310260772705078
[15/24] Train loss=0.301007479429245
[20/24] Train loss=0.30398398637771606
Test set avg_accuracy=86.11% avg_sensitivity=69.87%, avg_specificity=92.16% avg_auc=91.58%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.324200 Test loss=0.324122 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.31966859102249146
[5/24] Train loss=0.33301785588264465
[10/24] Train loss=0.325329065322876
[15/24] Train loss=0.30053821206092834
[20/24] Train loss=0.30548134446144104
Test set avg_accuracy=86.05% avg_sensitivity=67.80%, avg_specificity=92.85% avg_auc=91.66%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.322995 Test loss=0.322402 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.31500333547592163
[5/24] Train loss=0.3353050947189331
[10/24] Train loss=0.3312315344810486
[15/24] Train loss=0.29987412691116333
[20/24] Train loss=0.2948131263256073
Test set avg_accuracy=86.08% avg_sensitivity=67.56%, avg_specificity=92.98% avg_auc=91.68%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.321107 Test loss=0.322223 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.30974870920181274
[5/24] Train loss=0.33460402488708496
[10/24] Train loss=0.3242579400539398
[15/24] Train loss=0.2981417775154114
[20/24] Train loss=0.2972368597984314
Test set avg_accuracy=86.02% avg_sensitivity=67.47%, avg_specificity=92.92% avg_auc=91.69%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.320300 Test loss=0.321940 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.30777066946029663
[5/24] Train loss=0.3340171277523041
[10/24] Train loss=0.32323330640792847
[15/24] Train loss=0.2986434996128082
[20/24] Train loss=0.29779306054115295
Test set avg_accuracy=86.04% avg_sensitivity=67.61%, avg_specificity=92.91% avg_auc=91.68%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.319678 Test loss=0.321931 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.31208592653274536
[5/24] Train loss=0.33427995443344116
[10/24] Train loss=0.32823461294174194
[15/24] Train loss=0.2919025719165802
[20/24] Train loss=0.29576900601387024
Test set avg_accuracy=86.04% avg_sensitivity=67.32%, avg_specificity=93.01% avg_auc=91.68%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.319621 Test loss=0.321986 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.31224849820137024
[5/24] Train loss=0.3337283134460449
[10/24] Train loss=0.32505786418914795
[15/24] Train loss=0.29829394817352295
[20/24] Train loss=0.29738298058509827
Test set avg_accuracy=86.16% avg_sensitivity=67.03%, avg_specificity=93.28% avg_auc=91.71%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.319741 Test loss=0.321456 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3140566647052765
[5/24] Train loss=0.32629257440567017
[10/24] Train loss=0.3276340067386627
[15/24] Train loss=0.3002108335494995
[20/24] Train loss=0.2959890067577362
Test set avg_accuracy=85.98% avg_sensitivity=66.94%, avg_specificity=93.07% avg_auc=91.68%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.319318 Test loss=0.321890 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3093741834163666
[5/24] Train loss=0.3295968174934387
[10/24] Train loss=0.32548952102661133
[15/24] Train loss=0.2959965765476227
[20/24] Train loss=0.290271133184433
Test set avg_accuracy=86.08% avg_sensitivity=66.70%, avg_specificity=93.30% avg_auc=91.72%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.318486 Test loss=0.321427 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.30684593319892883
[5/24] Train loss=0.33044666051864624
[10/24] Train loss=0.32549038529396057
[15/24] Train loss=0.29982951283454895
[20/24] Train loss=0.290815144777298
Test set avg_accuracy=86.09% avg_sensitivity=66.22%, avg_specificity=93.50% avg_auc=91.71%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.318074 Test loss=0.321591 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3131004571914673
[5/24] Train loss=0.3315304219722748
[10/24] Train loss=0.3275038003921509
[15/24] Train loss=0.2961386442184448
[20/24] Train loss=0.29382359981536865
Test set avg_accuracy=86.02% avg_sensitivity=66.27%, avg_specificity=93.37% avg_auc=91.72%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.319224 Test loss=0.321441 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.30824244022369385
[5/24] Train loss=0.3279227018356323
[10/24] Train loss=0.3254857063293457
[15/24] Train loss=0.29625359177589417
[20/24] Train loss=0.28948351740837097
Test set avg_accuracy=86.20% avg_sensitivity=67.18%, avg_specificity=93.28% avg_auc=91.73%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.318263 Test loss=0.321047 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3077419400215149
[5/24] Train loss=0.3303917944431305
[10/24] Train loss=0.32535606622695923
[15/24] Train loss=0.2953394651412964
[20/24] Train loss=0.2864283323287964
Test set avg_accuracy=85.99% avg_sensitivity=65.88%, avg_specificity=93.48% avg_auc=91.74%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.318358 Test loss=0.321184 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3062370717525482
[5/24] Train loss=0.33169275522232056
[10/24] Train loss=0.32811325788497925
[15/24] Train loss=0.2917778193950653
[20/24] Train loss=0.2889633774757385
Test set avg_accuracy=85.94% avg_sensitivity=65.83%, avg_specificity=93.42% avg_auc=91.73%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.318123 Test loss=0.321277 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.30926623940467834
[5/24] Train loss=0.3314940333366394
[10/24] Train loss=0.3224163353443146
[15/24] Train loss=0.29448410868644714
[20/24] Train loss=0.29250702261924744
Test set avg_accuracy=86.15% avg_sensitivity=67.08%, avg_specificity=93.25% avg_auc=91.72%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.318215 Test loss=0.321063 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3139663636684418
[5/24] Train loss=0.3320099711418152
[10/24] Train loss=0.32295864820480347
[15/24] Train loss=0.29506245255470276
[20/24] Train loss=0.28884994983673096
Test set avg_accuracy=86.25% avg_sensitivity=67.66%, avg_specificity=93.17% avg_auc=91.74%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.318694 Test loss=0.320877 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3040802776813507
[5/24] Train loss=0.3316410183906555
[10/24] Train loss=0.3278895914554596
[15/24] Train loss=0.2928195595741272
[20/24] Train loss=0.291142076253891
Test set avg_accuracy=86.25% avg_sensitivity=68.09%, avg_specificity=93.01% avg_auc=91.74%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.317754 Test loss=0.320838 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.31117790937423706
[5/24] Train loss=0.3273407220840454
[10/24] Train loss=0.3203102946281433
[15/24] Train loss=0.2940984070301056
[20/24] Train loss=0.28676658868789673
Test set avg_accuracy=86.25% avg_sensitivity=68.23%, avg_specificity=92.96% avg_auc=91.73%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.317953 Test loss=0.320874 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.3113623857498169
[5/24] Train loss=0.33134689927101135
[10/24] Train loss=0.32200032472610474
[15/24] Train loss=0.29240185022354126
[20/24] Train loss=0.2890948951244354
Test set avg_accuracy=86.25% avg_sensitivity=68.09%, avg_specificity=93.01% avg_auc=91.72%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.317028 Test loss=0.321077 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.3078244626522064
[5/24] Train loss=0.32786306738853455
[10/24] Train loss=0.32954955101013184
[15/24] Train loss=0.28999456763267517
[20/24] Train loss=0.2886715233325958
Test set avg_accuracy=86.16% avg_sensitivity=67.56%, avg_specificity=93.08% avg_auc=91.71%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.317096 Test loss=0.321191 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3120565712451935
[5/24] Train loss=0.32893505692481995
[10/24] Train loss=0.3294389247894287
[15/24] Train loss=0.29342156648635864
[20/24] Train loss=0.29027074575424194
Test set avg_accuracy=86.17% avg_sensitivity=67.51%, avg_specificity=93.12% avg_auc=91.73%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.317341 Test loss=0.320966 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.30765053629875183
[5/24] Train loss=0.33101803064346313
[10/24] Train loss=0.3242480158805847
[15/24] Train loss=0.29499107599258423
[20/24] Train loss=0.2889392077922821
Test set avg_accuracy=86.17% avg_sensitivity=66.70%, avg_specificity=93.42% avg_auc=91.73%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.316953 Test loss=0.321082 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.30648303031921387
[5/24] Train loss=0.33284029364585876
[10/24] Train loss=0.32700130343437195
[15/24] Train loss=0.29673269391059875
[20/24] Train loss=0.28794506192207336
Test set avg_accuracy=86.16% avg_sensitivity=66.75%, avg_specificity=93.39% avg_auc=91.74%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.317552 Test loss=0.320957 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.31291887164115906
[5/24] Train loss=0.3297140300273895
[10/24] Train loss=0.3254894018173218
[15/24] Train loss=0.29299071431159973
[20/24] Train loss=0.28960177302360535
Test set avg_accuracy=86.13% avg_sensitivity=66.46%, avg_specificity=93.46% avg_auc=91.74%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.317468 Test loss=0.320960 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.30784928798675537
[5/24] Train loss=0.3286128044128418
[10/24] Train loss=0.32388147711753845
[15/24] Train loss=0.29249313473701477
[20/24] Train loss=0.2867375910282135
Test set avg_accuracy=86.07% avg_sensitivity=66.36%, avg_specificity=93.41% avg_auc=91.74%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.316807 Test loss=0.320866 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3139339089393616
[5/24] Train loss=0.331349641084671
[10/24] Train loss=0.32656538486480713
[15/24] Train loss=0.29265856742858887
[20/24] Train loss=0.28672006726264954
Test set avg_accuracy=86.08% avg_sensitivity=66.12%, avg_specificity=93.51% avg_auc=91.74%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.316701 Test loss=0.320989 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.3095911741256714
[5/24] Train loss=0.33053088188171387
[10/24] Train loss=0.3212070167064667
[15/24] Train loss=0.29050979018211365
[20/24] Train loss=0.28921404480934143
Test set avg_accuracy=86.05% avg_sensitivity=66.17%, avg_specificity=93.46% avg_auc=91.75%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.316753 Test loss=0.320827 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.30923429131507874
[5/24] Train loss=0.33012551069259644
[10/24] Train loss=0.3247774839401245
[15/24] Train loss=0.2954060435295105
[20/24] Train loss=0.2861173152923584
Test set avg_accuracy=86.12% avg_sensitivity=66.46%, avg_specificity=93.44% avg_auc=91.75%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.317087 Test loss=0.320784 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3129779100418091
[5/24] Train loss=0.3270324468612671
[10/24] Train loss=0.3201887011528015
[15/24] Train loss=0.29535001516342163
[20/24] Train loss=0.28868159651756287
Test set avg_accuracy=86.09% avg_sensitivity=66.27%, avg_specificity=93.48% avg_auc=91.75%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.317474 Test loss=0.320863 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3082789182662964
[5/24] Train loss=0.3271803855895996
[10/24] Train loss=0.3239043653011322
[15/24] Train loss=0.29043492674827576
[20/24] Train loss=0.2890913784503937
Test set avg_accuracy=86.02% avg_sensitivity=65.98%, avg_specificity=93.48% avg_auc=91.75%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.317396 Test loss=0.320869 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.31015071272850037
[5/24] Train loss=0.32680991291999817
[10/24] Train loss=0.32855844497680664
[15/24] Train loss=0.29481157660484314
[20/24] Train loss=0.2917459011077881
Test set avg_accuracy=86.02% avg_sensitivity=65.98%, avg_specificity=93.48% avg_auc=91.75%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.317724 Test loss=0.320890 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3073709011077881
[5/24] Train loss=0.3254964053630829
[10/24] Train loss=0.32979780435562134
[15/24] Train loss=0.2951490879058838
[20/24] Train loss=0.29018300771713257
Test set avg_accuracy=86.02% avg_sensitivity=65.98%, avg_specificity=93.48% avg_auc=91.75%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.317345 Test loss=0.320894 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3073118329048157
[5/24] Train loss=0.33029991388320923
[10/24] Train loss=0.326345831155777
[15/24] Train loss=0.29395022988319397
[20/24] Train loss=0.2887035012245178
Test set avg_accuracy=86.03% avg_sensitivity=65.98%, avg_specificity=93.50% avg_auc=91.75%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.316126 Test loss=0.320898 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.30966314673423767
[5/24] Train loss=0.3292323052883148
[10/24] Train loss=0.3252538740634918
[15/24] Train loss=0.29334479570388794
[20/24] Train loss=0.29184049367904663
Test set avg_accuracy=86.03% avg_sensitivity=65.98%, avg_specificity=93.50% avg_auc=91.75%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.317616 Test loss=0.320899 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=85.82% sen=74.81%, spe=89.92%, auc=91.52%!
Fold[6] Avg_overlap=0.65%(±0.25531403945407655)
[0/24] Train loss=0.8414534330368042
[5/24] Train loss=0.7205643653869629
[10/24] Train loss=0.6831330060958862
[15/24] Train loss=0.6320767998695374
[20/24] Train loss=0.6286618709564209
Test set avg_accuracy=71.89% avg_sensitivity=1.37%, avg_specificity=98.79% avg_auc=49.09%
Best model saved!! Metric=-104.85683701533799!!
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.687863 Test loss=0.613052 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6202400922775269
[5/24] Train loss=0.5772546529769897
[10/24] Train loss=0.6107639074325562
[15/24] Train loss=0.5887053608894348
[20/24] Train loss=0.5971391797065735
Test set avg_accuracy=72.36% avg_sensitivity=0.05%, avg_specificity=99.95% avg_auc=52.35%
Best model saved!! Metric=-101.29878456107744!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.599484 Test loss=0.591179 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6006723046302795
[5/24] Train loss=0.5674871206283569
[10/24] Train loss=0.5929948091506958
[15/24] Train loss=0.568307638168335
[20/24] Train loss=0.5966766476631165
Test set avg_accuracy=72.37% avg_sensitivity=0.05%, avg_specificity=99.96% avg_auc=56.26%
Best model saved!! Metric=-97.35635413425219!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.587822 Test loss=0.584690 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.5940603613853455
[5/24] Train loss=0.5588712096214294
[10/24] Train loss=0.5890329480171204
[15/24] Train loss=0.5680427551269531
[20/24] Train loss=0.5811122059822083
Test set avg_accuracy=72.38% avg_sensitivity=0.14%, avg_specificity=99.95% avg_auc=60.20%
Best model saved!! Metric=-93.32864843099789!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.580950 Test loss=0.577666 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.582310140132904
[5/24] Train loss=0.5494145750999451
[10/24] Train loss=0.5864526629447937
[15/24] Train loss=0.5553312301635742
[20/24] Train loss=0.5762783885002136
Test set avg_accuracy=72.38% avg_sensitivity=0.28%, avg_specificity=99.89% avg_auc=64.79%
Best model saved!! Metric=-88.64820235848222!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.573332 Test loss=0.569818 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.577584981918335
[5/24] Train loss=0.5388570427894592
[10/24] Train loss=0.5750910043716431
[15/24] Train loss=0.5546442270278931
[20/24] Train loss=0.567759096622467
Test set avg_accuracy=72.41% avg_sensitivity=0.57%, avg_specificity=99.82% avg_auc=69.11%
Best model saved!! Metric=-84.09421271545904!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.564991 Test loss=0.562073 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5686540007591248
[5/24] Train loss=0.5333489775657654
[10/24] Train loss=0.5679473876953125
[15/24] Train loss=0.543717086315155
[20/24] Train loss=0.5614545345306396
Test set avg_accuracy=72.16% avg_sensitivity=0.85%, avg_specificity=99.37% avg_auc=72.49%
Best model saved!! Metric=-81.13263488756843!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.557223 Test loss=0.553270 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5605255365371704
[5/24] Train loss=0.5175586938858032
[10/24] Train loss=0.5602298974990845
[15/24] Train loss=0.5319743752479553
[20/24] Train loss=0.5499810576438904
Test set avg_accuracy=72.12% avg_sensitivity=1.37%, avg_specificity=99.12% avg_auc=75.77%
Best model saved!! Metric=-77.62275487478351!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.548163 Test loss=0.543093 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5565251708030701
[5/24] Train loss=0.5072023868560791
[10/24] Train loss=0.5433229804039001
[15/24] Train loss=0.5295662879943848
[20/24] Train loss=0.5363828539848328
Test set avg_accuracy=72.15% avg_sensitivity=2.69%, avg_specificity=98.65% avg_auc=77.88%
Best model saved!! Metric=-74.62842624758824!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.538072 Test loss=0.531980 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5382030010223389
[5/24] Train loss=0.49244430661201477
[10/24] Train loss=0.5380539894104004
[15/24] Train loss=0.5101758241653442
[20/24] Train loss=0.5294238328933716
Test set avg_accuracy=72.41% avg_sensitivity=5.23%, avg_specificity=98.04% avg_auc=80.06%
Best model saved!! Metric=-70.26254930858178!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.526136 Test loss=0.518510 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5264132618904114
[5/24] Train loss=0.4874468743801117
[10/24] Train loss=0.5302491188049316
[15/24] Train loss=0.5020654797554016
[20/24] Train loss=0.5089271664619446
Test set avg_accuracy=72.68% avg_sensitivity=7.31%, avg_specificity=97.63% avg_auc=81.42%
Best model saved!! Metric=-66.965849032069!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.515336 Test loss=0.507177 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5149936079978943
[5/24] Train loss=0.47339868545532227
[10/24] Train loss=0.514678955078125
[15/24] Train loss=0.4886775016784668
[20/24] Train loss=0.5036277174949646
Test set avg_accuracy=72.97% avg_sensitivity=11.13%, avg_specificity=96.56% avg_auc=82.67%
Best model saved!! Metric=-62.67341612857031!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.500756 Test loss=0.492553 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4997860789299011
[5/24] Train loss=0.4542265832424164
[10/24] Train loss=0.4986858069896698
[15/24] Train loss=0.4712684154510498
[20/24] Train loss=0.4750675559043884
Test set avg_accuracy=74.13% avg_sensitivity=18.76%, avg_specificity=95.25% avg_auc=83.45%
Best model saved!! Metric=-54.40914553790829!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.487756 Test loss=0.476641 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.48360559344291687
[5/24] Train loss=0.43377622961997986
[10/24] Train loss=0.4988352060317993
[15/24] Train loss=0.4634600579738617
[20/24] Train loss=0.47253164649009705
Test set avg_accuracy=75.40% avg_sensitivity=26.40%, avg_specificity=94.10% avg_auc=84.36%
Best model saved!! Metric=-45.734717744756026!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.475614 Test loss=0.461927 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.46095097064971924
[5/24] Train loss=0.42097005248069763
[10/24] Train loss=0.47937819361686707
[15/24] Train loss=0.440721720457077
[20/24] Train loss=0.4515950083732605
Test set avg_accuracy=77.75% avg_sensitivity=38.19%, avg_specificity=92.84% avg_auc=84.93%
Best model saved!! Metric=-32.289627096467186!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.461511 Test loss=0.447459 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.45306339859962463
[5/24] Train loss=0.41579076647758484
[10/24] Train loss=0.47645145654678345
[15/24] Train loss=0.43026989698410034
[20/24] Train loss=0.4367520213127136
Test set avg_accuracy=79.34% avg_sensitivity=46.77%, avg_specificity=91.76% avg_auc=85.51%
Best model saved!! Metric=-22.62550954286172!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.452501 Test loss=0.437488 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4545440375804901
[5/24] Train loss=0.40732741355895996
[10/24] Train loss=0.4692671597003937
[15/24] Train loss=0.41791072487831116
[20/24] Train loss=0.4241616427898407
Test set avg_accuracy=79.77% avg_sensitivity=48.70%, avg_specificity=91.62% avg_auc=86.13%
Best model saved!! Metric=-19.787369031960438!!
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.444568 Test loss=0.427557 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.44315531849861145
[5/24] Train loss=0.39655637741088867
[10/24] Train loss=0.46832889318466187
[15/24] Train loss=0.4163050651550293
[20/24] Train loss=0.41129395365715027
Test set avg_accuracy=80.40% avg_sensitivity=50.92%, avg_specificity=91.65% avg_auc=86.73%
Best model saved!! Metric=-16.291199458766584!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.437387 Test loss=0.417141 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.42577245831489563
[5/24] Train loss=0.39312174916267395
[10/24] Train loss=0.46238571405410767
[15/24] Train loss=0.4033299684524536
[20/24] Train loss=0.4027958810329437
Test set avg_accuracy=80.73% avg_sensitivity=47.52%, avg_specificity=93.40% avg_auc=87.55%
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.427537 Test loss=0.405304 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.41511037945747375
[5/24] Train loss=0.37536466121673584
[10/24] Train loss=0.4361279010772705
[15/24] Train loss=0.3845865726470947
[20/24] Train loss=0.39509350061416626
Test set avg_accuracy=81.42% avg_sensitivity=46.91%, avg_specificity=94.59% avg_auc=88.21%
Best model saved!! Metric=-14.874705600004994!!
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.414654 Test loss=0.395603 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3941291868686676
[5/24] Train loss=0.37522420287132263
[10/24] Train loss=0.43130165338516235
[15/24] Train loss=0.3792111873626709
[20/24] Train loss=0.38492631912231445
Test set avg_accuracy=82.53% avg_sensitivity=50.97%, avg_specificity=94.57% avg_auc=89.27%
Best model saved!! Metric=-8.673372037713534!!
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.405754 Test loss=0.381584 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.39435744285583496
[5/24] Train loss=0.3622343838214874
[10/24] Train loss=0.4224664568901062
[15/24] Train loss=0.37135550379753113
[20/24] Train loss=0.3702452778816223
Test set avg_accuracy=83.44% avg_sensitivity=53.94%, avg_specificity=94.69% avg_auc=89.86%
Best model saved!! Metric=-4.068534575394956!!
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.395956 Test loss=0.371141 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3811419606208801
[5/24] Train loss=0.35260114073753357
[10/24] Train loss=0.41610443592071533
[15/24] Train loss=0.3740001916885376
[20/24] Train loss=0.36255380511283875
Test set avg_accuracy=83.31% avg_sensitivity=51.77%, avg_specificity=95.34% avg_auc=90.20%
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.390835 Test loss=0.366520 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.37061649560928345
[5/24] Train loss=0.3477163314819336
[10/24] Train loss=0.41104504466056824
[15/24] Train loss=0.3645435571670532
[20/24] Train loss=0.3563840389251709
Test set avg_accuracy=83.46% avg_sensitivity=51.53%, avg_specificity=95.65% avg_auc=90.38%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.385120 Test loss=0.363106 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3692990839481354
[5/24] Train loss=0.34755951166152954
[10/24] Train loss=0.408113956451416
[15/24] Train loss=0.36179372668266296
[20/24] Train loss=0.34962892532348633
Test set avg_accuracy=83.55% avg_sensitivity=50.26%, avg_specificity=96.26% avg_auc=90.47%
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.380860 Test loss=0.364432 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.36206114292144775
[5/24] Train loss=0.34559985995292664
[10/24] Train loss=0.4024125039577484
[15/24] Train loss=0.34923532605171204
[20/24] Train loss=0.3439398407936096
Test set avg_accuracy=82.97% avg_sensitivity=46.68%, avg_specificity=96.82% avg_auc=90.61%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.374026 Test loss=0.368924 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.35689425468444824
[5/24] Train loss=0.3400231897830963
[10/24] Train loss=0.39282289147377014
[15/24] Train loss=0.34142282605171204
[20/24] Train loss=0.34499526023864746
Test set avg_accuracy=82.90% avg_sensitivity=45.69%, avg_specificity=97.10% avg_auc=90.74%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.369294 Test loss=0.370765 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.35522711277008057
[5/24] Train loss=0.32742515206336975
[10/24] Train loss=0.38640084862709045
[15/24] Train loss=0.34106433391571045
[20/24] Train loss=0.3316810131072998
Test set avg_accuracy=82.54% avg_sensitivity=43.89%, avg_specificity=97.28% avg_auc=90.81%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.363537 Test loss=0.374505 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3501467704772949
[5/24] Train loss=0.33072587847709656
[10/24] Train loss=0.38903796672821045
[15/24] Train loss=0.3457653522491455
[20/24] Train loss=0.34221628308296204
Test set avg_accuracy=81.84% avg_sensitivity=40.12%, avg_specificity=97.75% avg_auc=90.76%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.363627 Test loss=0.385958 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.35422536730766296
[5/24] Train loss=0.3272278904914856
[10/24] Train loss=0.3844641447067261
[15/24] Train loss=0.34208256006240845
[20/24] Train loss=0.3356214463710785
Test set avg_accuracy=82.04% avg_sensitivity=40.83%, avg_specificity=97.77% avg_auc=90.91%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.361653 Test loss=0.383060 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3573116362094879
[5/24] Train loss=0.33092862367630005
[10/24] Train loss=0.3847072124481201
[15/24] Train loss=0.33575156331062317
[20/24] Train loss=0.3375324606895447
Test set avg_accuracy=82.59% avg_sensitivity=43.56%, avg_specificity=97.48% avg_auc=91.01%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.359808 Test loss=0.374594 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.34760305285453796
[5/24] Train loss=0.33959880471229553
[10/24] Train loss=0.3766748607158661
[15/24] Train loss=0.3387172818183899
[20/24] Train loss=0.3334268629550934
Test set avg_accuracy=83.20% avg_sensitivity=46.49%, avg_specificity=97.21% avg_auc=91.16%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.359051 Test loss=0.365557 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.34566569328308105
[5/24] Train loss=0.32791948318481445
[10/24] Train loss=0.38142529129981995
[15/24] Train loss=0.3295202851295471
[20/24] Train loss=0.32986724376678467
Test set avg_accuracy=83.79% avg_sensitivity=50.73%, avg_specificity=96.40% avg_auc=91.15%
Best model saved!! Metric=-3.92358089447589!!
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.355819 Test loss=0.355542 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3408069610595703
[5/24] Train loss=0.3300813138484955
[10/24] Train loss=0.38639935851097107
[15/24] Train loss=0.32707709074020386
[20/24] Train loss=0.3242364525794983
Test set avg_accuracy=84.32% avg_sensitivity=53.14%, avg_specificity=96.22% avg_auc=91.28%
Best model saved!! Metric=-1.040549554290493!!
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.353176 Test loss=0.349084 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.34312522411346436
[5/24] Train loss=0.3213943541049957
[10/24] Train loss=0.3760756254196167
[15/24] Train loss=0.32599368691444397
[20/24] Train loss=0.32897287607192993
Test set avg_accuracy=84.78% avg_sensitivity=56.39%, avg_specificity=95.61% avg_auc=91.11%
Best model saved!! Metric=1.8883831427361528!!
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.353119 Test loss=0.346577 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3435381352901459
[5/24] Train loss=0.32276809215545654
[10/24] Train loss=0.3865256905555725
[15/24] Train loss=0.3252257704734802
[20/24] Train loss=0.32679036259651184
Test set avg_accuracy=84.97% avg_sensitivity=57.00%, avg_specificity=95.65% avg_auc=91.09%
Best model saved!! Metric=2.7117489653762448!!
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.352706 Test loss=0.345810 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3451102077960968
[5/24] Train loss=0.32323727011680603
[10/24] Train loss=0.3810965418815613
[15/24] Train loss=0.325711190700531
[20/24] Train loss=0.3255334794521332
Test set avg_accuracy=85.09% avg_sensitivity=57.00%, avg_specificity=95.81% avg_auc=91.25%
Best model saved!! Metric=3.153053758764699!!
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.350755 Test loss=0.343783 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.34353718161582947
[5/24] Train loss=0.3195303678512573
[10/24] Train loss=0.37829339504241943
[15/24] Train loss=0.3251062035560608
[20/24] Train loss=0.3256962299346924
Test set avg_accuracy=85.12% avg_sensitivity=56.34%, avg_specificity=96.10% avg_auc=91.42%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.348860 Test loss=0.342562 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3438398540019989
[5/24] Train loss=0.32503828406333923
[10/24] Train loss=0.3728311061859131
[15/24] Train loss=0.3194005489349365
[20/24] Train loss=0.3198370635509491
Test set avg_accuracy=85.14% avg_sensitivity=57.38%, avg_specificity=95.74% avg_auc=91.46%
Best model saved!! Metric=3.7231963762470954!!
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.348356 Test loss=0.339944 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3413897454738617
[5/24] Train loss=0.319975346326828
[10/24] Train loss=0.37877994775772095
[15/24] Train loss=0.318132221698761
[20/24] Train loss=0.32919740676879883
Test set avg_accuracy=85.03% avg_sensitivity=57.05%, avg_specificity=95.70% avg_auc=91.49%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.347319 Test loss=0.340894 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.34083783626556396
[5/24] Train loss=0.3236111104488373
[10/24] Train loss=0.38028648495674133
[15/24] Train loss=0.3227270245552063
[20/24] Train loss=0.32309553027153015
Test set avg_accuracy=85.27% avg_sensitivity=58.46%, avg_specificity=95.50% avg_auc=91.60%
Best model saved!! Metric=4.835404073652207!!
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.347292 Test loss=0.337512 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.336363822221756
[5/24] Train loss=0.3212112784385681
[10/24] Train loss=0.3724651336669922
[15/24] Train loss=0.3171885311603546
[20/24] Train loss=0.32082000374794006
Test set avg_accuracy=85.33% avg_sensitivity=58.18%, avg_specificity=95.68% avg_auc=91.79%
Best model saved!! Metric=4.975116245422527!!
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.345823 Test loss=0.335219 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3347119092941284
[5/24] Train loss=0.3187132179737091
[10/24] Train loss=0.37542739510536194
[15/24] Train loss=0.3234044015407562
[20/24] Train loss=0.31914225220680237
Test set avg_accuracy=85.00% avg_sensitivity=56.95%, avg_specificity=95.70% avg_auc=91.73%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.344964 Test loss=0.336417 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3339681923389435
[5/24] Train loss=0.3177054226398468
[10/24] Train loss=0.3710159361362457
[15/24] Train loss=0.3173633813858032
[20/24] Train loss=0.3163411617279053
Test set avg_accuracy=85.25% avg_sensitivity=57.24%, avg_specificity=95.93% avg_auc=91.84%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.343794 Test loss=0.335686 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3384877145290375
[5/24] Train loss=0.32202956080436707
[10/24] Train loss=0.37053748965263367
[15/24] Train loss=0.3161277174949646
[20/24] Train loss=0.32312753796577454
Test set avg_accuracy=85.79% avg_sensitivity=60.44%, avg_specificity=95.47% avg_auc=91.96%
Best model saved!! Metric=7.663669599591884!!
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.342657 Test loss=0.330843 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3357451856136322
[5/24] Train loss=0.3260876536369324
[10/24] Train loss=0.36802735924720764
[15/24] Train loss=0.3201409578323364
[20/24] Train loss=0.31167691946029663
Test set avg_accuracy=85.86% avg_sensitivity=60.87%, avg_specificity=95.39% avg_auc=92.04%
Best model saved!! Metric=8.164950295791847!!
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.342170 Test loss=0.328260 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3358851969242096
[5/24] Train loss=0.3189139664173126
[10/24] Train loss=0.36276519298553467
[15/24] Train loss=0.31651556491851807
[20/24] Train loss=0.31318697333335876
Test set avg_accuracy=85.95% avg_sensitivity=61.90%, avg_specificity=95.13% avg_auc=92.09%
Best model saved!! Metric=9.06761279077515!!
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.340820 Test loss=0.326753 Current lr=[0.000299720220882401]

[0/24] Train loss=0.33307158946990967
[5/24] Train loss=0.3238011300563812
[10/24] Train loss=0.3641062080860138
[15/24] Train loss=0.30823206901550293
[20/24] Train loss=0.31513476371765137
Test set avg_accuracy=86.03% avg_sensitivity=62.09%, avg_specificity=95.16% avg_auc=92.17%
Best model saved!! Metric=9.451420968760708!!
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.339346 Test loss=0.325360 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3309105634689331
[5/24] Train loss=0.323317289352417
[10/24] Train loss=0.3662255108356476
[15/24] Train loss=0.31056830286979675
[20/24] Train loss=0.30997607111930847
Test set avg_accuracy=85.99% avg_sensitivity=61.43%, avg_specificity=95.36% avg_auc=92.20%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.339786 Test loss=0.326335 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3292655944824219
[5/24] Train loss=0.32062438130378723
[10/24] Train loss=0.3590866029262543
[15/24] Train loss=0.3097253143787384
[20/24] Train loss=0.3105632960796356
Test set avg_accuracy=85.76% avg_sensitivity=60.54%, avg_specificity=95.38% avg_auc=92.20%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.337456 Test loss=0.326829 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3329036235809326
[5/24] Train loss=0.3179975748062134
[10/24] Train loss=0.3601258099079132
[15/24] Train loss=0.3110436201095581
[20/24] Train loss=0.3128884732723236
Test set avg_accuracy=85.76% avg_sensitivity=59.97%, avg_specificity=95.59% avg_auc=92.23%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.337214 Test loss=0.327061 Current lr=[0.000297555943323901]

[0/24] Train loss=0.32754477858543396
[5/24] Train loss=0.31612658500671387
[10/24] Train loss=0.3640241324901581
[15/24] Train loss=0.3080185651779175
[20/24] Train loss=0.31312182545661926
Test set avg_accuracy=86.08% avg_sensitivity=61.43%, avg_specificity=95.48% avg_auc=92.29%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.336799 Test loss=0.324658 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.32777148485183716
[5/24] Train loss=0.31857508420944214
[10/24] Train loss=0.3590397834777832
[15/24] Train loss=0.3036571741104126
[20/24] Train loss=0.31100159883499146
Test set avg_accuracy=86.12% avg_sensitivity=62.00%, avg_specificity=95.32% avg_auc=92.31%
Best model saved!! Metric=9.75189387927788!!
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.336562 Test loss=0.323339 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.33095529675483704
[5/24] Train loss=0.3137464225292206
[10/24] Train loss=0.36146020889282227
[15/24] Train loss=0.30597323179244995
[20/24] Train loss=0.3110048472881317
Test set avg_accuracy=86.05% avg_sensitivity=61.62%, avg_specificity=95.38% avg_auc=92.29%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.335922 Test loss=0.323649 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.32931816577911377
[5/24] Train loss=0.31425991654396057
[10/24] Train loss=0.3567633628845215
[15/24] Train loss=0.30667662620544434
[20/24] Train loss=0.3126133680343628
Test set avg_accuracy=86.08% avg_sensitivity=61.95%, avg_specificity=95.29% avg_auc=92.35%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.334992 Test loss=0.322014 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.32514113187789917
[5/24] Train loss=0.31490132212638855
[10/24] Train loss=0.3603685796260834
[15/24] Train loss=0.30351290106773376
[20/24] Train loss=0.31063589453697205
Test set avg_accuracy=86.28% avg_sensitivity=62.85%, avg_specificity=95.21% avg_auc=92.38%
Best model saved!! Metric=10.7185622119908!!
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.334356 Test loss=0.321614 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.32925644516944885
[5/24] Train loss=0.31227436661720276
[10/24] Train loss=0.3585045039653778
[15/24] Train loss=0.30289292335510254
[20/24] Train loss=0.30642372369766235
Test set avg_accuracy=86.08% avg_sensitivity=61.43%, avg_specificity=95.48% avg_auc=92.34%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.333721 Test loss=0.323049 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3288043439388275
[5/24] Train loss=0.3156992197036743
[10/24] Train loss=0.36026668548583984
[15/24] Train loss=0.3058469295501709
[20/24] Train loss=0.3082599937915802
Test set avg_accuracy=86.18% avg_sensitivity=62.61%, avg_specificity=95.18% avg_auc=92.37%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.333376 Test loss=0.321290 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3247006833553314
[5/24] Train loss=0.309902161359787
[10/24] Train loss=0.36166471242904663
[15/24] Train loss=0.30104318261146545
[20/24] Train loss=0.30757495760917664
Test set avg_accuracy=86.11% avg_sensitivity=61.10%, avg_specificity=95.65% avg_auc=92.48%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.333027 Test loss=0.322234 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3264411985874176
[5/24] Train loss=0.3119897246360779
[10/24] Train loss=0.36017993092536926
[15/24] Train loss=0.30323487520217896
[20/24] Train loss=0.3086027503013611
Test set avg_accuracy=86.05% avg_sensitivity=62.14%, avg_specificity=95.18% avg_auc=92.45%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.331784 Test loss=0.320601 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3250127136707306
[5/24] Train loss=0.3161160349845886
[10/24] Train loss=0.35495129227638245
[15/24] Train loss=0.30083945393562317
[20/24] Train loss=0.3069687783718109
Test set avg_accuracy=85.94% avg_sensitivity=60.40%, avg_specificity=95.68% avg_auc=92.50%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.331592 Test loss=0.322162 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3246730864048004
[5/24] Train loss=0.3127301037311554
[10/24] Train loss=0.3595024347305298
[15/24] Train loss=0.3026043176651001
[20/24] Train loss=0.30725640058517456
Test set avg_accuracy=86.11% avg_sensitivity=61.06%, avg_specificity=95.66% avg_auc=92.49%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.331307 Test loss=0.321156 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3259512782096863
[5/24] Train loss=0.3118709325790405
[10/24] Train loss=0.3559930622577667
[15/24] Train loss=0.3035741150379181
[20/24] Train loss=0.3043532967567444
Test set avg_accuracy=86.51% avg_sensitivity=64.45%, avg_specificity=94.93% avg_auc=92.51%
Best model saved!! Metric=12.402905275638588!!
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.330670 Test loss=0.317359 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.32241562008857727
[5/24] Train loss=0.31187838315963745
[10/24] Train loss=0.35416069626808167
[15/24] Train loss=0.29834914207458496
[20/24] Train loss=0.3061462938785553
Test set avg_accuracy=86.26% avg_sensitivity=62.28%, avg_specificity=95.41% avg_auc=92.49%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.330524 Test loss=0.319433 Current lr=[0.000276307469034998]

[0/24] Train loss=0.32493796944618225
[5/24] Train loss=0.3076629340648651
[10/24] Train loss=0.3619809150695801
[15/24] Train loss=0.3032149374485016
[20/24] Train loss=0.3069435954093933
Test set avg_accuracy=86.03% avg_sensitivity=60.73%, avg_specificity=95.68% avg_auc=92.49%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.330478 Test loss=0.321174 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3242233097553253
[5/24] Train loss=0.3151489794254303
[10/24] Train loss=0.35743942856788635
[15/24] Train loss=0.30192193388938904
[20/24] Train loss=0.2989633083343506
Test set avg_accuracy=86.42% avg_sensitivity=63.08%, avg_specificity=95.32% avg_auc=92.49%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.329832 Test loss=0.317999 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.32477718591690063
[5/24] Train loss=0.31241533160209656
[10/24] Train loss=0.352892130613327
[15/24] Train loss=0.3022659420967102
[20/24] Train loss=0.29949328303337097
Test set avg_accuracy=86.29% avg_sensitivity=62.75%, avg_specificity=95.27% avg_auc=92.55%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.329282 Test loss=0.318418 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.32470858097076416
[5/24] Train loss=0.3072957694530487
[10/24] Train loss=0.35681217908859253
[15/24] Train loss=0.2987830936908722
[20/24] Train loss=0.2931879162788391
Test set avg_accuracy=86.48% avg_sensitivity=64.03%, avg_specificity=95.05% avg_auc=92.46%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.328059 Test loss=0.316978 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3204856812953949
[5/24] Train loss=0.31046590209007263
[10/24] Train loss=0.3571404814720154
[15/24] Train loss=0.29959163069725037
[20/24] Train loss=0.2952251732349396
Test set avg_accuracy=86.37% avg_sensitivity=63.22%, avg_specificity=95.20% avg_auc=92.54%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.328500 Test loss=0.317214 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3228469491004944
[5/24] Train loss=0.3102557957172394
[10/24] Train loss=0.35720178484916687
[15/24] Train loss=0.3004585802555084
[20/24] Train loss=0.29131582379341125
Test set avg_accuracy=86.63% avg_sensitivity=64.97%, avg_specificity=94.89% avg_auc=92.56%
Best model saved!! Metric=13.043652185777404!!
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.328558 Test loss=0.315287 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3238445222377777
[5/24] Train loss=0.3118123710155487
[10/24] Train loss=0.3589093089103699
[15/24] Train loss=0.2947348356246948
[20/24] Train loss=0.29676732420921326
Test set avg_accuracy=86.18% avg_sensitivity=61.95%, avg_specificity=95.43% avg_auc=92.60%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.328037 Test loss=0.317687 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.32640764117240906
[5/24] Train loss=0.3132227063179016
[10/24] Train loss=0.35517019033432007
[15/24] Train loss=0.2965760827064514
[20/24] Train loss=0.2941187024116516
Test set avg_accuracy=86.30% avg_sensitivity=62.94%, avg_specificity=95.21% avg_auc=92.63%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.328326 Test loss=0.316453 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.31862980127334595
[5/24] Train loss=0.3110100030899048
[10/24] Train loss=0.3573352098464966
[15/24] Train loss=0.29660239815711975
[20/24] Train loss=0.29505839943885803
Test set avg_accuracy=86.21% avg_sensitivity=62.42%, avg_specificity=95.29% avg_auc=92.62%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.326742 Test loss=0.316717 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3216035068035126
[5/24] Train loss=0.31102409958839417
[10/24] Train loss=0.3577403426170349
[15/24] Train loss=0.29865700006484985
[20/24] Train loss=0.29504403471946716
Test set avg_accuracy=86.09% avg_sensitivity=60.91%, avg_specificity=95.70% avg_auc=92.73%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.326142 Test loss=0.317683 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.31925511360168457
[5/24] Train loss=0.3125894069671631
[10/24] Train loss=0.3587031960487366
[15/24] Train loss=0.29568156599998474
[20/24] Train loss=0.2942052185535431
Test set avg_accuracy=86.41% avg_sensitivity=62.61%, avg_specificity=95.48% avg_auc=92.73%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.327490 Test loss=0.315236 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3188219368457794
[5/24] Train loss=0.3093129098415375
[10/24] Train loss=0.3562781810760498
[15/24] Train loss=0.3031890392303467
[20/24] Train loss=0.29029813408851624
Test set avg_accuracy=86.26% avg_sensitivity=62.00%, avg_specificity=95.52% avg_auc=92.73%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.325415 Test loss=0.315851 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3181211054325104
[5/24] Train loss=0.3094771206378937
[10/24] Train loss=0.3545382618904114
[15/24] Train loss=0.2940129339694977
[20/24] Train loss=0.29305151104927063
Test set avg_accuracy=86.13% avg_sensitivity=61.15%, avg_specificity=95.66% avg_auc=92.78%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.325191 Test loss=0.316692 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3157779276371002
[5/24] Train loss=0.3052453398704529
[10/24] Train loss=0.3515286445617676
[15/24] Train loss=0.30097395181655884
[20/24] Train loss=0.2868115305900574
Test set avg_accuracy=86.17% avg_sensitivity=61.24%, avg_specificity=95.68% avg_auc=92.75%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.325249 Test loss=0.317125 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3162098228931427
[5/24] Train loss=0.3073972761631012
[10/24] Train loss=0.3557804822921753
[15/24] Train loss=0.29980501532554626
[20/24] Train loss=0.28440219163894653
Test set avg_accuracy=85.77% avg_sensitivity=58.23%, avg_specificity=96.28% avg_auc=92.57%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.326502 Test loss=0.324821 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3192477524280548
[5/24] Train loss=0.31227537989616394
[10/24] Train loss=0.3540956676006317
[15/24] Train loss=0.30137571692466736
[20/24] Train loss=0.291180819272995
Test set avg_accuracy=85.03% avg_sensitivity=54.03%, avg_specificity=96.85% avg_auc=92.29%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.329219 Test loss=0.336664 Current lr=[0.000224838296036774]

[0/24] Train loss=0.32411473989486694
[5/24] Train loss=0.31143710017204285
[10/24] Train loss=0.35948243737220764
[15/24] Train loss=0.3043431341648102
[20/24] Train loss=0.28525054454803467
Test set avg_accuracy=85.31% avg_sensitivity=55.59%, avg_specificity=96.65% avg_auc=92.60%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.327438 Test loss=0.328266 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.32092490792274475
[5/24] Train loss=0.30977752804756165
[10/24] Train loss=0.35829436779022217
[15/24] Train loss=0.29208052158355713
[20/24] Train loss=0.2860807776451111
Test set avg_accuracy=85.66% avg_sensitivity=57.94%, avg_specificity=96.24% avg_auc=92.66%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.325369 Test loss=0.322988 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3184646666049957
[5/24] Train loss=0.3122771978378296
[10/24] Train loss=0.35947883129119873
[15/24] Train loss=0.2960464060306549
[20/24] Train loss=0.28365039825439453
Test set avg_accuracy=85.61% avg_sensitivity=57.66%, avg_specificity=96.28% avg_auc=92.76%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.324987 Test loss=0.321845 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3194292187690735
[5/24] Train loss=0.312599778175354
[10/24] Train loss=0.3576947748661041
[15/24] Train loss=0.29792848229408264
[20/24] Train loss=0.28832295536994934
Test set avg_accuracy=85.57% avg_sensitivity=56.91%, avg_specificity=96.51% avg_auc=92.76%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.326600 Test loss=0.323541 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3187968134880066
[5/24] Train loss=0.31043943762779236
[10/24] Train loss=0.35622066259384155
[15/24] Train loss=0.29838335514068604
[20/24] Train loss=0.2842300534248352
Test set avg_accuracy=85.43% avg_sensitivity=56.06%, avg_specificity=96.64% avg_auc=92.76%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.325647 Test loss=0.325760 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3190256953239441
[5/24] Train loss=0.3145330548286438
[10/24] Train loss=0.3546084463596344
[15/24] Train loss=0.295483261346817
[20/24] Train loss=0.2867504358291626
Test set avg_accuracy=85.52% avg_sensitivity=56.39%, avg_specificity=96.64% avg_auc=92.72%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.326060 Test loss=0.326625 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.32039472460746765
[5/24] Train loss=0.31477364897727966
[10/24] Train loss=0.356008917093277
[15/24] Train loss=0.30160030722618103
[20/24] Train loss=0.28386372327804565
Test set avg_accuracy=84.69% avg_sensitivity=52.57%, avg_specificity=96.94% avg_auc=92.56%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.326972 Test loss=0.335954 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.32375824451446533
[5/24] Train loss=0.3118174970149994
[10/24] Train loss=0.3588389456272125
[15/24] Train loss=0.306652307510376
[20/24] Train loss=0.28409451246261597
Test set avg_accuracy=85.47% avg_sensitivity=56.29%, avg_specificity=96.60% avg_auc=92.64%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.327155 Test loss=0.327768 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.32084521651268005
[5/24] Train loss=0.3127935528755188
[10/24] Train loss=0.3555046319961548
[15/24] Train loss=0.2955560088157654
[20/24] Train loss=0.2852029800415039
Test set avg_accuracy=85.40% avg_sensitivity=56.20%, avg_specificity=96.55% avg_auc=92.73%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.324838 Test loss=0.325781 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.32178589701652527
[5/24] Train loss=0.30944857001304626
[10/24] Train loss=0.35332491993904114
[15/24] Train loss=0.29734912514686584
[20/24] Train loss=0.28522205352783203
Test set avg_accuracy=85.52% avg_sensitivity=57.14%, avg_specificity=96.35% avg_auc=92.78%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.323441 Test loss=0.323334 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3181646168231964
[5/24] Train loss=0.3086496591567993
[10/24] Train loss=0.3523634076118469
[15/24] Train loss=0.29657167196273804
[20/24] Train loss=0.28099727630615234
Test set avg_accuracy=85.65% avg_sensitivity=57.94%, avg_specificity=96.22% avg_auc=92.76%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.323798 Test loss=0.321685 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.31876400113105774
[5/24] Train loss=0.3099910318851471
[10/24] Train loss=0.35221630334854126
[15/24] Train loss=0.2974050045013428
[20/24] Train loss=0.28124603629112244
Test set avg_accuracy=85.81% avg_sensitivity=58.93%, avg_specificity=96.06% avg_auc=92.81%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.324442 Test loss=0.319547 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3175508677959442
[5/24] Train loss=0.3104293644428253
[10/24] Train loss=0.3497801125049591
[15/24] Train loss=0.3004154860973358
[20/24] Train loss=0.28548216819763184
Test set avg_accuracy=86.26% avg_sensitivity=61.62%, avg_specificity=95.66% avg_auc=92.78%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.324034 Test loss=0.315069 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.31388920545578003
[5/24] Train loss=0.3107193410396576
[10/24] Train loss=0.3478390574455261
[15/24] Train loss=0.3001250624656677
[20/24] Train loss=0.28584596514701843
Test set avg_accuracy=86.64% avg_sensitivity=63.98%, avg_specificity=95.29% avg_auc=92.80%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.324355 Test loss=0.311375 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3182930052280426
[5/24] Train loss=0.30465561151504517
[10/24] Train loss=0.35065340995788574
[15/24] Train loss=0.2972012162208557
[20/24] Train loss=0.29058146476745605
Test set avg_accuracy=86.52% avg_sensitivity=64.40%, avg_specificity=94.96% avg_auc=92.72%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.323687 Test loss=0.311388 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.31984999775886536
[5/24] Train loss=0.30674880743026733
[10/24] Train loss=0.3501572906970978
[15/24] Train loss=0.2970869243144989
[20/24] Train loss=0.29063740372657776
Test set avg_accuracy=86.78% avg_sensitivity=66.15%, avg_specificity=94.66% avg_auc=92.71%
Best model saved!! Metric=14.302734695533672!!
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.323428 Test loss=0.309783 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3198653757572174
[5/24] Train loss=0.3021250367164612
[10/24] Train loss=0.35036247968673706
[15/24] Train loss=0.29196697473526
[20/24] Train loss=0.2892826199531555
Test set avg_accuracy=86.64% avg_sensitivity=65.30%, avg_specificity=94.78% avg_auc=92.71%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.321447 Test loss=0.310430 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3207271695137024
[5/24] Train loss=0.30892109870910645
[10/24] Train loss=0.348330557346344
[15/24] Train loss=0.2932164669036865
[20/24] Train loss=0.2903735935688019
Test set avg_accuracy=86.72% avg_sensitivity=65.44%, avg_specificity=94.84% avg_auc=92.79%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.321328 Test loss=0.309297 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3166652321815491
[5/24] Train loss=0.30608484148979187
[10/24] Train loss=0.35373663902282715
[15/24] Train loss=0.29165858030319214
[20/24] Train loss=0.2904309630393982
Test set avg_accuracy=86.60% avg_sensitivity=64.45%, avg_specificity=95.05% avg_auc=92.74%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.321180 Test loss=0.311197 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.31834810972213745
[5/24] Train loss=0.3061864376068115
[10/24] Train loss=0.35354170203208923
[15/24] Train loss=0.2905730605125427
[20/24] Train loss=0.286236971616745
Test set avg_accuracy=86.61% avg_sensitivity=64.17%, avg_specificity=95.18% avg_auc=92.89%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.320531 Test loss=0.309337 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3189176619052887
[5/24] Train loss=0.30866071581840515
[10/24] Train loss=0.3529662489891052
[15/24] Train loss=0.29444029927253723
[20/24] Train loss=0.283733993768692
Test set avg_accuracy=86.51% avg_sensitivity=64.07%, avg_specificity=95.07% avg_auc=92.82%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.321209 Test loss=0.309810 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3147788345813751
[5/24] Train loss=0.30438774824142456
[10/24] Train loss=0.354221373796463
[15/24] Train loss=0.294534295797348
[20/24] Train loss=0.28636592626571655
Test set avg_accuracy=86.95% avg_sensitivity=66.86%, avg_specificity=94.62% avg_auc=92.94%
Best model saved!! Metric=15.365799325793532!!
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.321336 Test loss=0.306513 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.31318631768226624
[5/24] Train loss=0.2994033396244049
[10/24] Train loss=0.3528887629508972
[15/24] Train loss=0.29503923654556274
[20/24] Train loss=0.2878780663013458
Test set avg_accuracy=86.95% avg_sensitivity=68.46%, avg_specificity=94.01% avg_auc=92.96%
Best model saved!! Metric=16.37923040446536!!
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.321119 Test loss=0.305390 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.31826052069664
[5/24] Train loss=0.3049047291278839
[10/24] Train loss=0.3564872145652771
[15/24] Train loss=0.2968297302722931
[20/24] Train loss=0.2901633083820343
Test set avg_accuracy=86.61% avg_sensitivity=68.32%, avg_specificity=93.60% avg_auc=92.87%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.321106 Test loss=0.306444 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.31730660796165466
[5/24] Train loss=0.3073914349079132
[10/24] Train loss=0.3553769886493683
[15/24] Train loss=0.2900380492210388
[20/24] Train loss=0.28922635316848755
Test set avg_accuracy=86.68% avg_sensitivity=67.47%, avg_specificity=94.01% avg_auc=92.91%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.319756 Test loss=0.306011 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3190155327320099
[5/24] Train loss=0.30756062269210815
[10/24] Train loss=0.3538006544113159
[15/24] Train loss=0.2926803231239319
[20/24] Train loss=0.28522011637687683
Test set avg_accuracy=86.76% avg_sensitivity=67.14%, avg_specificity=94.24% avg_auc=92.97%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.318745 Test loss=0.305857 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3190440535545349
[5/24] Train loss=0.30599093437194824
[10/24] Train loss=0.35629191994667053
[15/24] Train loss=0.28941524028778076
[20/24] Train loss=0.28441035747528076
Test set avg_accuracy=86.80% avg_sensitivity=67.37%, avg_specificity=94.21% avg_auc=92.97%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.318410 Test loss=0.305381 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3150315582752228
[5/24] Train loss=0.3112777769565582
[10/24] Train loss=0.35663074254989624
[15/24] Train loss=0.29004499316215515
[20/24] Train loss=0.2890913486480713
Test set avg_accuracy=86.98% avg_sensitivity=68.13%, avg_specificity=94.17% avg_auc=93.02%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.319001 Test loss=0.304160 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.31382814049720764
[5/24] Train loss=0.307237446308136
[10/24] Train loss=0.3590092062950134
[15/24] Train loss=0.29035449028015137
[20/24] Train loss=0.28110772371292114
Test set avg_accuracy=87.02% avg_sensitivity=68.18%, avg_specificity=94.21% avg_auc=93.03%
Best model saved!! Metric=16.42651110965552!!
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.318988 Test loss=0.304058 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3151625990867615
[5/24] Train loss=0.3066723644733429
[10/24] Train loss=0.36365842819213867
[15/24] Train loss=0.2902314066886902
[20/24] Train loss=0.28278017044067383
Test set avg_accuracy=87.11% avg_sensitivity=69.78%, avg_specificity=93.72% avg_auc=93.00%
Best model saved!! Metric=17.60900152575489!!
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.319378 Test loss=0.304019 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3209223449230194
[5/24] Train loss=0.31536346673965454
[10/24] Train loss=0.3626258671283722
[15/24] Train loss=0.29378485679626465
[20/24] Train loss=0.2853945791721344
Test set avg_accuracy=87.34% avg_sensitivity=72.18%, avg_specificity=93.13% avg_auc=92.94%
Best model saved!! Metric=19.59298483790829!!
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.320893 Test loss=0.305227 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.323866069316864
[5/24] Train loss=0.3200124204158783
[10/24] Train loss=0.371643602848053
[15/24] Train loss=0.28899386525154114
[20/24] Train loss=0.2944263517856598
Test set avg_accuracy=87.38% avg_sensitivity=74.96%, avg_specificity=92.12% avg_auc=92.73%
Best model saved!! Metric=21.202216690052794!!
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.324550 Test loss=0.311680 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.33934175968170166
[5/24] Train loss=0.3184293806552887
[10/24] Train loss=0.35731106996536255
[15/24] Train loss=0.3007444739341736
[20/24] Train loss=0.32055145502090454
Test set avg_accuracy=87.45% avg_sensitivity=72.32%, avg_specificity=93.22% avg_auc=92.99%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.327296 Test loss=0.305093 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3221677243709564
[5/24] Train loss=0.30580630898475647
[10/24] Train loss=0.3554939031600952
[15/24] Train loss=0.30101168155670166
[20/24] Train loss=0.2988346517086029
Test set avg_accuracy=86.73% avg_sensitivity=66.62%, avg_specificity=94.41% avg_auc=92.97%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.323131 Test loss=0.306360 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.31501179933547974
[5/24] Train loss=0.3127748668193817
[10/24] Train loss=0.3560105860233307
[15/24] Train loss=0.29520419239997864
[20/24] Train loss=0.2896391749382019
Test set avg_accuracy=86.95% avg_sensitivity=69.92%, avg_specificity=93.45% avg_auc=92.89%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.319149 Test loss=0.306562 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.32051074504852295
[5/24] Train loss=0.31118491291999817
[10/24] Train loss=0.36341750621795654
[15/24] Train loss=0.2939445674419403
[20/24] Train loss=0.29832059144973755
Test set avg_accuracy=86.90% avg_sensitivity=70.39%, avg_specificity=93.20% avg_auc=92.71%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.321745 Test loss=0.310005 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3267796039581299
[5/24] Train loss=0.31160953640937805
[10/24] Train loss=0.35520851612091064
[15/24] Train loss=0.29849258065223694
[20/24] Train loss=0.30552610754966736
Test set avg_accuracy=86.94% avg_sensitivity=70.53%, avg_specificity=93.20% avg_auc=92.72%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.321859 Test loss=0.309948 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3254152536392212
[5/24] Train loss=0.3089075982570648
[10/24] Train loss=0.3504522442817688
[15/24] Train loss=0.3028537333011627
[20/24] Train loss=0.30254340171813965
Test set avg_accuracy=86.67% avg_sensitivity=67.56%, avg_specificity=93.96% avg_auc=92.98%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.321324 Test loss=0.306243 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.31924331188201904
[5/24] Train loss=0.2987467646598816
[10/24] Train loss=0.3525058329105377
[15/24] Train loss=0.2956327497959137
[20/24] Train loss=0.2979925274848938
Test set avg_accuracy=86.82% avg_sensitivity=66.29%, avg_specificity=94.66% avg_auc=93.06%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.318815 Test loss=0.306136 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3131425380706787
[5/24] Train loss=0.2981779873371124
[10/24] Train loss=0.34730321168899536
[15/24] Train loss=0.2965160012245178
[20/24] Train loss=0.2932059168815613
Test set avg_accuracy=86.84% avg_sensitivity=66.71%, avg_specificity=94.51% avg_auc=93.05%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.316598 Test loss=0.305893 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3101070821285248
[5/24] Train loss=0.3048194348812103
[10/24] Train loss=0.3465993106365204
[15/24] Train loss=0.2971150279045105
[20/24] Train loss=0.2952391803264618
Test set avg_accuracy=86.78% avg_sensitivity=66.95%, avg_specificity=94.35% avg_auc=93.05%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.316916 Test loss=0.305466 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.3146597743034363
[5/24] Train loss=0.30204933881759644
[10/24] Train loss=0.34958145022392273
[15/24] Train loss=0.29666927456855774
[20/24] Train loss=0.29214152693748474
Test set avg_accuracy=86.72% avg_sensitivity=65.82%, avg_specificity=94.69% avg_auc=93.06%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.316534 Test loss=0.306330 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3131333589553833
[5/24] Train loss=0.30111458897590637
[10/24] Train loss=0.3468600809574127
[15/24] Train loss=0.2935291528701782
[20/24] Train loss=0.2895355522632599
Test set avg_accuracy=86.80% avg_sensitivity=65.82%, avg_specificity=94.80% avg_auc=93.06%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.315675 Test loss=0.306589 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.31176990270614624
[5/24] Train loss=0.3047938048839569
[10/24] Train loss=0.34472915530204773
[15/24] Train loss=0.2944523096084595
[20/24] Train loss=0.28952544927597046
Test set avg_accuracy=86.74% avg_sensitivity=65.30%, avg_specificity=94.93% avg_auc=93.07%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.316242 Test loss=0.306732 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3132367730140686
[5/24] Train loss=0.29621103405952454
[10/24] Train loss=0.3511178493499756
[15/24] Train loss=0.29405030608177185
[20/24] Train loss=0.28938567638397217
Test set avg_accuracy=86.82% avg_sensitivity=66.01%, avg_specificity=94.77% avg_auc=93.07%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.315181 Test loss=0.306037 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.31089428067207336
[5/24] Train loss=0.30467846989631653
[10/24] Train loss=0.3458384871482849
[15/24] Train loss=0.29633307456970215
[20/24] Train loss=0.28884273767471313
Test set avg_accuracy=86.76% avg_sensitivity=65.77%, avg_specificity=94.77% avg_auc=93.06%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.315026 Test loss=0.306346 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.31195196509361267
[5/24] Train loss=0.2997584939002991
[10/24] Train loss=0.3444388210773468
[15/24] Train loss=0.2887172996997833
[20/24] Train loss=0.2920762002468109
Test set avg_accuracy=86.72% avg_sensitivity=65.35%, avg_specificity=94.87% avg_auc=93.07%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.314722 Test loss=0.306524 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.31187593936920166
[5/24] Train loss=0.2996908724308014
[10/24] Train loss=0.34363284707069397
[15/24] Train loss=0.2919366955757141
[20/24] Train loss=0.2855801284313202
Test set avg_accuracy=86.73% avg_sensitivity=65.21%, avg_specificity=94.95% avg_auc=93.08%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.314362 Test loss=0.306556 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.31305864453315735
[5/24] Train loss=0.30407392978668213
[10/24] Train loss=0.3460348844528198
[15/24] Train loss=0.2928798198699951
[20/24] Train loss=0.2861635386943817
Test set avg_accuracy=86.73% avg_sensitivity=65.25%, avg_specificity=94.93% avg_auc=93.08%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.314742 Test loss=0.306463 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3138327896595001
[5/24] Train loss=0.3009033501148224
[10/24] Train loss=0.34848859906196594
[15/24] Train loss=0.29211536049842834
[20/24] Train loss=0.28332096338272095
Test set avg_accuracy=86.74% avg_sensitivity=65.87%, avg_specificity=94.71% avg_auc=93.08%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.314506 Test loss=0.305701 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.31658104062080383
[5/24] Train loss=0.2990819811820984
[10/24] Train loss=0.3465006351470947
[15/24] Train loss=0.29094359278678894
[20/24] Train loss=0.283220112323761
Test set avg_accuracy=86.86% avg_sensitivity=66.71%, avg_specificity=94.55% avg_auc=93.08%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.314020 Test loss=0.305032 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3087855279445648
[5/24] Train loss=0.3010556101799011
[10/24] Train loss=0.3450683057308197
[15/24] Train loss=0.28817296028137207
[20/24] Train loss=0.2810536324977875
Test set avg_accuracy=86.80% avg_sensitivity=66.67%, avg_specificity=94.48% avg_auc=93.08%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.313718 Test loss=0.304878 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3114868104457855
[5/24] Train loss=0.3019077479839325
[10/24] Train loss=0.34461891651153564
[15/24] Train loss=0.29135411977767944
[20/24] Train loss=0.2844892144203186
Test set avg_accuracy=86.91% avg_sensitivity=67.52%, avg_specificity=94.32% avg_auc=93.07%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.314581 Test loss=0.304251 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.3185573220252991
[5/24] Train loss=0.3003922402858734
[10/24] Train loss=0.34512487053871155
[15/24] Train loss=0.2872028648853302
[20/24] Train loss=0.2843928933143616
Test set avg_accuracy=86.91% avg_sensitivity=67.56%, avg_specificity=94.30% avg_auc=93.07%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.314073 Test loss=0.304334 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.3150632381439209
[5/24] Train loss=0.3036016523838043
[10/24] Train loss=0.34568464756011963
[15/24] Train loss=0.29044783115386963
[20/24] Train loss=0.28460079431533813
Test set avg_accuracy=86.82% avg_sensitivity=67.04%, avg_specificity=94.37% avg_auc=93.05%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.314601 Test loss=0.304950 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.31318917870521545
[5/24] Train loss=0.3013279139995575
[10/24] Train loss=0.34816208481788635
[15/24] Train loss=0.28825119137763977
[20/24] Train loss=0.2853853404521942
Test set avg_accuracy=86.78% avg_sensitivity=66.76%, avg_specificity=94.42% avg_auc=93.06%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.313819 Test loss=0.305397 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3146929442882538
[5/24] Train loss=0.2986980080604553
[10/24] Train loss=0.34776413440704346
[15/24] Train loss=0.2886294722557068
[20/24] Train loss=0.2865668833255768
Test set avg_accuracy=86.82% avg_sensitivity=66.15%, avg_specificity=94.71% avg_auc=93.08%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.313535 Test loss=0.305353 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.3140258491039276
[5/24] Train loss=0.300949364900589
[10/24] Train loss=0.3449162244796753
[15/24] Train loss=0.2875889539718628
[20/24] Train loss=0.2886739671230316
Test set avg_accuracy=86.74% avg_sensitivity=65.49%, avg_specificity=94.86% avg_auc=93.10%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.313377 Test loss=0.305681 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.31105080246925354
[5/24] Train loss=0.29670450091362
[10/24] Train loss=0.3462459146976471
[15/24] Train loss=0.291927307844162
[20/24] Train loss=0.2836610674858093
Test set avg_accuracy=86.74% avg_sensitivity=65.54%, avg_specificity=94.84% avg_auc=93.10%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.312939 Test loss=0.305671 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.32042041420936584
[5/24] Train loss=0.29798445105552673
[10/24] Train loss=0.3435593545436859
[15/24] Train loss=0.29003459215164185
[20/24] Train loss=0.2841499447822571
Test set avg_accuracy=86.77% avg_sensitivity=65.54%, avg_specificity=94.87% avg_auc=93.10%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.313442 Test loss=0.305743 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.31142231822013855
[5/24] Train loss=0.29726582765579224
[10/24] Train loss=0.3478109836578369
[15/24] Train loss=0.29088708758354187
[20/24] Train loss=0.28617018461227417
Test set avg_accuracy=86.71% avg_sensitivity=65.25%, avg_specificity=94.89% avg_auc=93.10%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.312843 Test loss=0.305834 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3094998002052307
[5/24] Train loss=0.29835861921310425
[10/24] Train loss=0.34571725130081177
[15/24] Train loss=0.28974953293800354
[20/24] Train loss=0.2859557867050171
Test set avg_accuracy=86.73% avg_sensitivity=65.30%, avg_specificity=94.91% avg_auc=93.10%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.312980 Test loss=0.305855 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.31317174434661865
[5/24] Train loss=0.2995222210884094
[10/24] Train loss=0.34786370396614075
[15/24] Train loss=0.2886090874671936
[20/24] Train loss=0.2859385907649994
Test set avg_accuracy=86.71% avg_sensitivity=65.16%, avg_specificity=94.93% avg_auc=93.10%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.312972 Test loss=0.306021 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.31313326954841614
[5/24] Train loss=0.30060622096061707
[10/24] Train loss=0.34314775466918945
[15/24] Train loss=0.28455817699432373
[20/24] Train loss=0.28204345703125
Test set avg_accuracy=86.67% avg_sensitivity=65.02%, avg_specificity=94.93% avg_auc=93.10%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.312804 Test loss=0.306109 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3119885325431824
[5/24] Train loss=0.29938405752182007
[10/24] Train loss=0.3459938168525696
[15/24] Train loss=0.2904549539089203
[20/24] Train loss=0.289625883102417
Test set avg_accuracy=86.72% avg_sensitivity=65.02%, avg_specificity=95.00% avg_auc=93.10%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.312706 Test loss=0.306171 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3138008713722229
[5/24] Train loss=0.3012142777442932
[10/24] Train loss=0.3462773263454437
[15/24] Train loss=0.2881101667881012
[20/24] Train loss=0.2837677597999573
Test set avg_accuracy=86.69% avg_sensitivity=65.02%, avg_specificity=94.96% avg_auc=93.10%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.313297 Test loss=0.306102 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.31294068694114685
[5/24] Train loss=0.2997039258480072
[10/24] Train loss=0.346934974193573
[15/24] Train loss=0.28564777970314026
[20/24] Train loss=0.2874246835708618
Test set avg_accuracy=86.72% avg_sensitivity=65.06%, avg_specificity=94.98% avg_auc=93.10%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.313101 Test loss=0.306145 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3121802806854248
[5/24] Train loss=0.29861751198768616
[10/24] Train loss=0.3438876271247864
[15/24] Train loss=0.2874440848827362
[20/24] Train loss=0.27941596508026123
Test set avg_accuracy=86.73% avg_sensitivity=65.06%, avg_specificity=95.00% avg_auc=93.10%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.312655 Test loss=0.306151 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.30605408549308777
[5/24] Train loss=0.2972991168498993
[10/24] Train loss=0.3470279574394226
[15/24] Train loss=0.2890807092189789
[20/24] Train loss=0.2818399965763092
Test set avg_accuracy=86.73% avg_sensitivity=65.06%, avg_specificity=95.00% avg_auc=93.10%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.312260 Test loss=0.306146 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3096368908882141
[5/24] Train loss=0.30288735032081604
[10/24] Train loss=0.3498230278491974
[15/24] Train loss=0.2892824709415436
[20/24] Train loss=0.2832529842853546
Test set avg_accuracy=86.73% avg_sensitivity=65.06%, avg_specificity=95.00% avg_auc=93.10%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.312936 Test loss=0.306150 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=87.38% sen=74.96%, spe=92.12%, auc=92.73%!
Fold[7] Avg_overlap=0.70%(±0.21453121491849267)
[0/24] Train loss=0.9072409868240356
[5/24] Train loss=0.7659040093421936
[10/24] Train loss=0.6981539726257324
[15/24] Train loss=0.6508800983428955
[20/24] Train loss=0.6140121817588806
Test set avg_accuracy=73.53% avg_sensitivity=3.94%, avg_specificity=96.90% avg_auc=50.07%
Best model saved!! Metric=-101.55788163245698!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.707157 Test loss=0.587233 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6265613436698914
[5/24] Train loss=0.593949019908905
[10/24] Train loss=0.6122384667396545
[15/24] Train loss=0.5905765891075134
[20/24] Train loss=0.5779910087585449
Test set avg_accuracy=74.80% avg_sensitivity=0.41%, avg_specificity=99.79% avg_auc=51.98%
Best model saved!! Metric=-99.011986356503!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.603669 Test loss=0.569234 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6162552237510681
[5/24] Train loss=0.5818541646003723
[10/24] Train loss=0.6009019613265991
[15/24] Train loss=0.5847496390342712
[20/24] Train loss=0.5696239471435547
Test set avg_accuracy=74.79% avg_sensitivity=0.57%, avg_specificity=99.72% avg_auc=55.07%
Best model saved!! Metric=-95.84600656837864!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.594092 Test loss=0.564668 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6054361462593079
[5/24] Train loss=0.5722443461418152
[10/24] Train loss=0.5986615419387817
[15/24] Train loss=0.5815666913986206
[20/24] Train loss=0.56395423412323
Test set avg_accuracy=74.82% avg_sensitivity=0.62%, avg_specificity=99.74% avg_auc=58.04%
Best model saved!! Metric=-92.7767814745895!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.588921 Test loss=0.558972 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6027056574821472
[5/24] Train loss=0.5563279986381531
[10/24] Train loss=0.5836667418479919
[15/24] Train loss=0.5753586292266846
[20/24] Train loss=0.5581006407737732
Test set avg_accuracy=74.83% avg_sensitivity=0.57%, avg_specificity=99.77% avg_auc=61.54%
Best model saved!! Metric=-89.29008782814269!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.580090 Test loss=0.551333 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.588329017162323
[5/24] Train loss=0.5530971884727478
[10/24] Train loss=0.5785226225852966
[15/24] Train loss=0.5671426653862
[20/24] Train loss=0.5456832051277161
Test set avg_accuracy=74.86% avg_sensitivity=0.93%, avg_specificity=99.69% avg_auc=65.13%
Best model saved!! Metric=-85.39614091526158!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.571424 Test loss=0.544576 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5777926445007324
[5/24] Train loss=0.5444043278694153
[10/24] Train loss=0.5709898471832275
[15/24] Train loss=0.5620887875556946
[20/24] Train loss=0.5351808667182922
Test set avg_accuracy=74.95% avg_sensitivity=1.50%, avg_specificity=99.62% avg_auc=69.03%
Best model saved!! Metric=-80.90014463127459!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.563648 Test loss=0.535763 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5696506500244141
[5/24] Train loss=0.5299496650695801
[10/24] Train loss=0.5684228539466858
[15/24] Train loss=0.5441608428955078
[20/24] Train loss=0.5275919437408447
Test set avg_accuracy=74.83% avg_sensitivity=2.02%, avg_specificity=99.29% avg_auc=72.77%
Best model saved!! Metric=-77.09682502756915!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.553284 Test loss=0.524876 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5658635497093201
[5/24] Train loss=0.5250223875045776
[10/24] Train loss=0.5509507060050964
[15/24] Train loss=0.5320197343826294
[20/24] Train loss=0.5051202774047852
Test set avg_accuracy=74.95% avg_sensitivity=4.14%, avg_specificity=98.73% avg_auc=75.91%
Best model saved!! Metric=-72.26416182598811!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.541173 Test loss=0.512422 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.542238712310791
[5/24] Train loss=0.5035796165466309
[10/24] Train loss=0.5377582311630249
[15/24] Train loss=0.5122295022010803
[20/24] Train loss=0.495536744594574
Test set avg_accuracy=75.14% avg_sensitivity=6.94%, avg_specificity=98.05% avg_auc=78.23%
Best model saved!! Metric=-67.63830823442956!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.526055 Test loss=0.498462 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5220221281051636
[5/24] Train loss=0.48230308294296265
[10/24] Train loss=0.5311237573623657
[15/24] Train loss=0.4976791739463806
[20/24] Train loss=0.4756411612033844
Test set avg_accuracy=75.48% avg_sensitivity=10.05%, avg_specificity=97.46% avg_auc=79.84%
Best model saved!! Metric=-63.16751885917979!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.509977 Test loss=0.483665 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5028526782989502
[5/24] Train loss=0.4606681168079376
[10/24] Train loss=0.5144497156143188
[15/24] Train loss=0.4825384318828583
[20/24] Train loss=0.45520657300949097
Test set avg_accuracy=76.15% avg_sensitivity=14.97%, avg_specificity=96.70% avg_auc=81.33%
Best model saved!! Metric=-56.86559026416891!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.493397 Test loss=0.468512 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.48707839846611023
[5/24] Train loss=0.4530346691608429
[10/24] Train loss=0.4990905523300171
[15/24] Train loss=0.4589971601963043
[20/24] Train loss=0.44421398639678955
Test set avg_accuracy=77.37% avg_sensitivity=23.51%, avg_specificity=95.46% avg_auc=82.57%
Best model saved!! Metric=-47.09390440404349!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.478086 Test loss=0.454140 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4732491374015808
[5/24] Train loss=0.4335879683494568
[10/24] Train loss=0.4868713915348053
[15/24] Train loss=0.4477373957633972
[20/24] Train loss=0.43028008937835693
Test set avg_accuracy=78.50% avg_sensitivity=32.94%, avg_specificity=93.81% avg_auc=83.63%
Best model saved!! Metric=-37.12321417077593!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.463900 Test loss=0.440642 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4564467966556549
[5/24] Train loss=0.4155963361263275
[10/24] Train loss=0.47167903184890747
[15/24] Train loss=0.4306179881095886
[20/24] Train loss=0.41692647337913513
Test set avg_accuracy=79.48% avg_sensitivity=41.95%, avg_specificity=92.09% avg_auc=84.73%
Best model saved!! Metric=-27.759396066284246!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.450398 Test loss=0.428686 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.44487524032592773
[5/24] Train loss=0.3996354341506958
[10/24] Train loss=0.4606790244579315
[15/24] Train loss=0.4203924536705017
[20/24] Train loss=0.40108442306518555
Test set avg_accuracy=80.51% avg_sensitivity=49.30%, avg_specificity=90.99% avg_auc=85.73%
Best model saved!! Metric=-19.47542318577753!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.437476 Test loss=0.418961 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.43195173144340515
[5/24] Train loss=0.3940849304199219
[10/24] Train loss=0.4521358013153076
[15/24] Train loss=0.4083843529224396
[20/24] Train loss=0.3932662606239319
Test set avg_accuracy=81.56% avg_sensitivity=53.03%, avg_specificity=91.15% avg_auc=86.52%
Best model saved!! Metric=-13.739859476382946!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.429350 Test loss=0.407480 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4134008586406708
[5/24] Train loss=0.3883225619792938
[10/24] Train loss=0.4497806429862976
[15/24] Train loss=0.40286606550216675
[20/24] Train loss=0.3833009898662567
Test set avg_accuracy=81.77% avg_sensitivity=51.48%, avg_specificity=91.95% avg_auc=87.10%
Best model saved!! Metric=-13.709072612978098!!
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.420391 Test loss=0.394893 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3932221233844757
[5/24] Train loss=0.38443973660469055
[10/24] Train loss=0.43505966663360596
[15/24] Train loss=0.39861273765563965
[20/24] Train loss=0.37291088700294495
Test set avg_accuracy=81.74% avg_sensitivity=44.90%, avg_specificity=94.12% avg_auc=87.73%
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.409073 Test loss=0.382219 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3887420892715454
[5/24] Train loss=0.3612997233867645
[10/24] Train loss=0.4142829477787018
[15/24] Train loss=0.38200175762176514
[20/24] Train loss=0.36186933517456055
Test set avg_accuracy=81.91% avg_sensitivity=42.98%, avg_specificity=94.99% avg_auc=88.34%
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.398830 Test loss=0.375804 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.38332173228263855
[5/24] Train loss=0.3532640039920807
[10/24] Train loss=0.40157631039619446
[15/24] Train loss=0.36242273449897766
[20/24] Train loss=0.34695732593536377
Test set avg_accuracy=82.62% avg_sensitivity=47.80%, avg_specificity=94.31% avg_auc=89.04%
Best model saved!! Metric=-12.235365066050953!!
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.387182 Test loss=0.365019 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3681308329105377
[5/24] Train loss=0.35022950172424316
[10/24] Train loss=0.3938129246234894
[15/24] Train loss=0.35810670256614685
[20/24] Train loss=0.33739835023880005
Test set avg_accuracy=82.38% avg_sensitivity=44.59%, avg_specificity=95.08% avg_auc=89.23%
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.380141 Test loss=0.362671 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3671180307865143
[5/24] Train loss=0.3496624231338501
[10/24] Train loss=0.3897647559642792
[15/24] Train loss=0.35627755522727966
[20/24] Train loss=0.33694887161254883
Test set avg_accuracy=82.28% avg_sensitivity=41.33%, avg_specificity=96.03% avg_auc=89.31%
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.377878 Test loss=0.365906 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3671562373638153
[5/24] Train loss=0.3419378995895386
[10/24] Train loss=0.38743579387664795
[15/24] Train loss=0.35722699761390686
[20/24] Train loss=0.3289891481399536
Test set avg_accuracy=82.62% avg_sensitivity=44.12%, avg_specificity=95.55% avg_auc=89.69%
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.373266 Test loss=0.358582 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.36210572719573975
[5/24] Train loss=0.3390332758426666
[10/24] Train loss=0.38180312514305115
[15/24] Train loss=0.3565695583820343
[20/24] Train loss=0.32563236355781555
Test set avg_accuracy=83.09% avg_sensitivity=44.90%, avg_specificity=95.91% avg_auc=89.85%
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.368246 Test loss=0.356439 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3534581661224365
[5/24] Train loss=0.33516383171081543
[10/24] Train loss=0.379464715719223
[15/24] Train loss=0.3471176028251648
[20/24] Train loss=0.3200114667415619
Test set avg_accuracy=82.75% avg_sensitivity=42.21%, avg_specificity=96.36% avg_auc=90.05%
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.364042 Test loss=0.358137 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3632771968841553
[5/24] Train loss=0.34254544973373413
[10/24] Train loss=0.37320277094841003
[15/24] Train loss=0.3437822461128235
[20/24] Train loss=0.32016459107398987
Test set avg_accuracy=82.47% avg_sensitivity=40.13%, avg_specificity=96.70% avg_auc=90.00%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.364321 Test loss=0.360450 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3605839014053345
[5/24] Train loss=0.34333336353302
[10/24] Train loss=0.3742414712905884
[15/24] Train loss=0.3445155620574951
[20/24] Train loss=0.3258691430091858
Test set avg_accuracy=82.60% avg_sensitivity=40.45%, avg_specificity=96.76% avg_auc=90.10%
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.364698 Test loss=0.359037 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3560148775577545
[5/24] Train loss=0.3488236963748932
[10/24] Train loss=0.3665938675403595
[15/24] Train loss=0.34171774983406067
[20/24] Train loss=0.3153015077114105
Test set avg_accuracy=82.70% avg_sensitivity=41.22%, avg_specificity=96.63% avg_auc=90.06%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.360364 Test loss=0.357035 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.34900858998298645
[5/24] Train loss=0.3463321328163147
[10/24] Train loss=0.36769452691078186
[15/24] Train loss=0.3416093587875366
[20/24] Train loss=0.32141387462615967
Test set avg_accuracy=82.30% avg_sensitivity=38.74%, avg_specificity=96.94% avg_auc=90.15%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.361705 Test loss=0.361543 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.35655802488327026
[5/24] Train loss=0.34413784742355347
[10/24] Train loss=0.3678133487701416
[15/24] Train loss=0.3400900065898895
[20/24] Train loss=0.3158664107322693
Test set avg_accuracy=82.24% avg_sensitivity=38.11%, avg_specificity=97.06% avg_auc=90.31%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.358905 Test loss=0.361601 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.35359638929367065
[5/24] Train loss=0.3438204526901245
[10/24] Train loss=0.36768487095832825
[15/24] Train loss=0.3348388969898224
[20/24] Train loss=0.31591105461120605
Test set avg_accuracy=82.93% avg_sensitivity=41.90%, avg_specificity=96.71% avg_auc=90.41%
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.357209 Test loss=0.353922 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3494521379470825
[5/24] Train loss=0.34356093406677246
[10/24] Train loss=0.3617831766605377
[15/24] Train loss=0.3420572578907013
[20/24] Train loss=0.30516722798347473
Test set avg_accuracy=83.28% avg_sensitivity=44.90%, avg_specificity=96.17% avg_auc=90.28%
Best model saved!! Metric=-11.366538609623774!!
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.354104 Test loss=0.351870 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3457048535346985
[5/24] Train loss=0.34401264786720276
[10/24] Train loss=0.3659206032752991
[15/24] Train loss=0.3452005684375763
[20/24] Train loss=0.3043052852153778
Test set avg_accuracy=83.95% avg_sensitivity=49.35%, avg_specificity=95.56% avg_auc=90.34%
Best model saved!! Metric=-6.796124981438005!!
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.353556 Test loss=0.345302 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.33809760212898254
[5/24] Train loss=0.33721697330474854
[10/24] Train loss=0.3605809807777405
[15/24] Train loss=0.343235045671463
[20/24] Train loss=0.3071785271167755
Test set avg_accuracy=83.61% avg_sensitivity=47.18%, avg_specificity=95.84% avg_auc=90.37%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.350870 Test loss=0.347917 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3439221978187561
[5/24] Train loss=0.3397597670555115
[10/24] Train loss=0.3644978404045105
[15/24] Train loss=0.34221574664115906
[20/24] Train loss=0.30548039078712463
Test set avg_accuracy=83.26% avg_sensitivity=43.86%, avg_specificity=96.49% avg_auc=90.50%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.351351 Test loss=0.351534 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3406217098236084
[5/24] Train loss=0.337091326713562
[10/24] Train loss=0.3690256178379059
[15/24] Train loss=0.34124675393104553
[20/24] Train loss=0.3029884397983551
Test set avg_accuracy=83.53% avg_sensitivity=45.88%, avg_specificity=96.17% avg_auc=90.58%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.351057 Test loss=0.346213 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.33972057700157166
[5/24] Train loss=0.32995256781578064
[10/24] Train loss=0.36753857135772705
[15/24] Train loss=0.3417392075061798
[20/24] Train loss=0.30447885394096375
Test set avg_accuracy=83.41% avg_sensitivity=44.02%, avg_specificity=96.64% avg_auc=90.63%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.349794 Test loss=0.349235 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3451164960861206
[5/24] Train loss=0.32924821972846985
[10/24] Train loss=0.36313560605049133
[15/24] Train loss=0.3433672785758972
[20/24] Train loss=0.3052479028701782
Test set avg_accuracy=83.57% avg_sensitivity=45.47%, avg_specificity=96.36% avg_auc=90.62%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.349294 Test loss=0.347910 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.34957799315452576
[5/24] Train loss=0.32212838530540466
[10/24] Train loss=0.36637529730796814
[15/24] Train loss=0.3399844765663147
[20/24] Train loss=0.3087978661060333
Test set avg_accuracy=83.42% avg_sensitivity=45.00%, avg_specificity=96.33% avg_auc=90.48%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.348887 Test loss=0.349990 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3426451086997986
[5/24] Train loss=0.32998067140579224
[10/24] Train loss=0.3627748191356659
[15/24] Train loss=0.3398344814777374
[20/24] Train loss=0.30458715558052063
Test set avg_accuracy=83.63% avg_sensitivity=45.93%, avg_specificity=96.30% avg_auc=90.62%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.348425 Test loss=0.347318 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3411847651004791
[5/24] Train loss=0.33169472217559814
[10/24] Train loss=0.356597363948822
[15/24] Train loss=0.3373093903064728
[20/24] Train loss=0.2954692244529724
Test set avg_accuracy=84.13% avg_sensitivity=50.60%, avg_specificity=95.39% avg_auc=90.57%
Best model saved!! Metric=-5.32081128738885!!
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.347402 Test loss=0.340401 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.331651896238327
[5/24] Train loss=0.32742828130722046
[10/24] Train loss=0.35848256945610046
[15/24] Train loss=0.3350428640842438
[20/24] Train loss=0.29890868067741394
Test set avg_accuracy=83.78% avg_sensitivity=48.06%, avg_specificity=95.77% avg_auc=90.55%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.345555 Test loss=0.343925 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.33997583389282227
[5/24] Train loss=0.33393797278404236
[10/24] Train loss=0.3643341064453125
[15/24] Train loss=0.3328087627887726
[20/24] Train loss=0.29935118556022644
Test set avg_accuracy=83.75% avg_sensitivity=47.85%, avg_specificity=95.81% avg_auc=90.67%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.346650 Test loss=0.343367 Current lr=[0.00029967723776099]

[0/24] Train loss=0.33570870757102966
[5/24] Train loss=0.3328931927680969
[10/24] Train loss=0.35818174481391907
[15/24] Train loss=0.33279433846473694
[20/24] Train loss=0.2924954891204834
Test set avg_accuracy=83.79% avg_sensitivity=47.90%, avg_specificity=95.84% avg_auc=90.64%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.345702 Test loss=0.342669 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3290170729160309
[5/24] Train loss=0.33037811517715454
[10/24] Train loss=0.356934130191803
[15/24] Train loss=0.33554381132125854
[20/24] Train loss=0.2951154112815857
Test set avg_accuracy=83.92% avg_sensitivity=48.52%, avg_specificity=95.81% avg_auc=90.72%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.344450 Test loss=0.340842 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.33809447288513184
[5/24] Train loss=0.3292764723300934
[10/24] Train loss=0.3600672483444214
[15/24] Train loss=0.33589744567871094
[20/24] Train loss=0.29993167519569397
Test set avg_accuracy=83.91% avg_sensitivity=48.73%, avg_specificity=95.72% avg_auc=90.52%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.345002 Test loss=0.343362 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3391259014606476
[5/24] Train loss=0.3280613124370575
[10/24] Train loss=0.35319578647613525
[15/24] Train loss=0.3302253782749176
[20/24] Train loss=0.29511764645576477
Test set avg_accuracy=83.82% avg_sensitivity=47.85%, avg_specificity=95.89% avg_auc=90.69%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.343675 Test loss=0.343159 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3362080454826355
[5/24] Train loss=0.32712677121162415
[10/24] Train loss=0.35484981536865234
[15/24] Train loss=0.33522218465805054
[20/24] Train loss=0.29397767782211304
Test set avg_accuracy=84.08% avg_sensitivity=48.47%, avg_specificity=96.03% avg_auc=90.78%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.342930 Test loss=0.340691 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3342479169368744
[5/24] Train loss=0.3200993239879608
[10/24] Train loss=0.3570275902748108
[15/24] Train loss=0.33395034074783325
[20/24] Train loss=0.2927340865135193
Test set avg_accuracy=83.91% avg_sensitivity=48.37%, avg_specificity=95.84% avg_auc=90.62%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.342996 Test loss=0.342699 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.33264052867889404
[5/24] Train loss=0.3228866755962372
[10/24] Train loss=0.35260871052742004
[15/24] Train loss=0.3345997631549835
[20/24] Train loss=0.2907763719558716
Test set avg_accuracy=83.62% avg_sensitivity=46.25%, avg_specificity=96.17% avg_auc=90.68%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.341929 Test loss=0.344853 Current lr=[0.000297555943323901]

[0/24] Train loss=0.33510759472846985
[5/24] Train loss=0.3264773190021515
[10/24] Train loss=0.35534048080444336
[15/24] Train loss=0.3302555978298187
[20/24] Train loss=0.2929074168205261
Test set avg_accuracy=83.92% avg_sensitivity=47.80%, avg_specificity=96.05% avg_auc=90.73%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.342943 Test loss=0.342028 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3336942791938782
[5/24] Train loss=0.32752522826194763
[10/24] Train loss=0.35471370816230774
[15/24] Train loss=0.336289644241333
[20/24] Train loss=0.29593315720558167
Test set avg_accuracy=83.46% avg_sensitivity=45.11%, avg_specificity=96.35% avg_auc=90.72%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.342805 Test loss=0.346680 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3347089886665344
[5/24] Train loss=0.3285001814365387
[10/24] Train loss=0.3531503677368164
[15/24] Train loss=0.3339688777923584
[20/24] Train loss=0.29667267203330994
Test set avg_accuracy=83.52% avg_sensitivity=45.42%, avg_specificity=96.31% avg_auc=90.73%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.342121 Test loss=0.345476 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.33643752336502075
[5/24] Train loss=0.3254150152206421
[10/24] Train loss=0.35443300008773804
[15/24] Train loss=0.33356210589408875
[20/24] Train loss=0.292612761259079
Test set avg_accuracy=83.59% avg_sensitivity=45.93%, avg_specificity=96.24% avg_auc=90.71%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.341139 Test loss=0.345158 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.33601778745651245
[5/24] Train loss=0.32591813802719116
[10/24] Train loss=0.35565224289894104
[15/24] Train loss=0.3452993631362915
[20/24] Train loss=0.2943868935108185
Test set avg_accuracy=83.41% avg_sensitivity=44.74%, avg_specificity=96.40% avg_auc=90.78%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.342142 Test loss=0.346139 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3357550799846649
[5/24] Train loss=0.3289288580417633
[10/24] Train loss=0.3548077344894409
[15/24] Train loss=0.3393791913986206
[20/24] Train loss=0.2953640818595886
Test set avg_accuracy=83.15% avg_sensitivity=43.40%, avg_specificity=96.50% avg_auc=90.78%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.341197 Test loss=0.347766 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.33184027671813965
[5/24] Train loss=0.33557894825935364
[10/24] Train loss=0.3565981984138489
[15/24] Train loss=0.347685843706131
[20/24] Train loss=0.2984970808029175
Test set avg_accuracy=84.32% avg_sensitivity=50.80%, avg_specificity=95.58% avg_auc=90.78%
Best model saved!! Metric=-4.509211659706075!!
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.343402 Test loss=0.337069 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.33336979150772095
[5/24] Train loss=0.3280017375946045
[10/24] Train loss=0.35060665011405945
[15/24] Train loss=0.3454202115535736
[20/24] Train loss=0.2951010465621948
Test set avg_accuracy=84.62% avg_sensitivity=52.62%, avg_specificity=95.37% avg_auc=90.74%
Best model saved!! Metric=-2.649260264469106!!
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.342041 Test loss=0.335539 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3267342448234558
[5/24] Train loss=0.3291746973991394
[10/24] Train loss=0.3517661690711975
[15/24] Train loss=0.3411619961261749
[20/24] Train loss=0.2976944148540497
Test set avg_accuracy=84.49% avg_sensitivity=52.30%, avg_specificity=95.30% avg_auc=90.72%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.341777 Test loss=0.335963 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3276728391647339
[5/24] Train loss=0.3201788663864136
[10/24] Train loss=0.3507377505302429
[15/24] Train loss=0.3381713330745697
[20/24] Train loss=0.29276710748672485
Test set avg_accuracy=84.54% avg_sensitivity=53.03%, avg_specificity=95.13% avg_auc=90.65%
Best model saved!! Metric=-2.6483676270153893!!
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.340573 Test loss=0.336347 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3295985162258148
[5/24] Train loss=0.33097124099731445
[10/24] Train loss=0.34611061215400696
[15/24] Train loss=0.33772629499435425
[20/24] Train loss=0.29379042983055115
Test set avg_accuracy=84.31% avg_sensitivity=51.11%, avg_specificity=95.46% avg_auc=90.64%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.340478 Test loss=0.338054 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.330997109413147
[5/24] Train loss=0.3264486789703369
[10/24] Train loss=0.3484804034233093
[15/24] Train loss=0.3308785557746887
[20/24] Train loss=0.29495158791542053
Test set avg_accuracy=84.40% avg_sensitivity=51.73%, avg_specificity=95.37% avg_auc=90.61%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.339817 Test loss=0.337696 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3281550705432892
[5/24] Train loss=0.32672956585884094
[10/24] Train loss=0.3502736985683441
[15/24] Train loss=0.3325381278991699
[20/24] Train loss=0.29001134634017944
Test set avg_accuracy=84.18% avg_sensitivity=50.80%, avg_specificity=95.39% avg_auc=90.58%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.338483 Test loss=0.339084 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3308376371860504
[5/24] Train loss=0.3301422595977783
[10/24] Train loss=0.3460788130760193
[15/24] Train loss=0.33733439445495605
[20/24] Train loss=0.28842678666114807
Test set avg_accuracy=84.39% avg_sensitivity=51.58%, avg_specificity=95.41% avg_auc=90.81%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.338040 Test loss=0.335259 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3262552320957184
[5/24] Train loss=0.32667648792266846
[10/24] Train loss=0.34924671053886414
[15/24] Train loss=0.33849653601646423
[20/24] Train loss=0.28973403573036194
Test set avg_accuracy=84.31% avg_sensitivity=51.68%, avg_specificity=95.27% avg_auc=90.70%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.339281 Test loss=0.336334 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3289363384246826
[5/24] Train loss=0.3233879506587982
[10/24] Train loss=0.35127511620521545
[15/24] Train loss=0.332478791475296
[20/24] Train loss=0.2889009118080139
Test set avg_accuracy=84.15% avg_sensitivity=50.60%, avg_specificity=95.43% avg_auc=90.69%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.338317 Test loss=0.337607 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.32651641964912415
[5/24] Train loss=0.32953575253486633
[10/24] Train loss=0.3497295677661896
[15/24] Train loss=0.3358533978462219
[20/24] Train loss=0.2909238636493683
Test set avg_accuracy=84.05% avg_sensitivity=49.97%, avg_specificity=95.49% avg_auc=90.69%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.338134 Test loss=0.338053 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3266065716743469
[5/24] Train loss=0.3264728784561157
[10/24] Train loss=0.34992721676826477
[15/24] Train loss=0.33873215317726135
[20/24] Train loss=0.29272177815437317
Test set avg_accuracy=84.32% avg_sensitivity=51.27%, avg_specificity=95.43% avg_auc=90.76%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.339309 Test loss=0.336309 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.32747983932495117
[5/24] Train loss=0.3284197151660919
[10/24] Train loss=0.3502318859100342
[15/24] Train loss=0.3373180031776428
[20/24] Train loss=0.2955430746078491
Test set avg_accuracy=84.78% avg_sensitivity=53.86%, avg_specificity=95.16% avg_auc=90.92%
Best model saved!! Metric=-1.2742541869255248!!
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.340067 Test loss=0.332248 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.32376351952552795
[5/24] Train loss=0.32026544213294983
[10/24] Train loss=0.3479643762111664
[15/24] Train loss=0.3324119448661804
[20/24] Train loss=0.2963361144065857
Test set avg_accuracy=84.65% avg_sensitivity=52.56%, avg_specificity=95.43% avg_auc=90.89%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.339674 Test loss=0.333728 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.32735738158226013
[5/24] Train loss=0.3199332654476166
[10/24] Train loss=0.3516336679458618
[15/24] Train loss=0.3285037875175476
[20/24] Train loss=0.2959529757499695
Test set avg_accuracy=83.27% avg_sensitivity=43.19%, avg_specificity=96.73% avg_auc=90.82%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.338790 Test loss=0.346777 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3333381116390228
[5/24] Train loss=0.3302699029445648
[10/24] Train loss=0.35392364859580994
[15/24] Train loss=0.32832440733909607
[20/24] Train loss=0.2875513732433319
Test set avg_accuracy=83.62% avg_sensitivity=46.56%, avg_specificity=96.07% avg_auc=90.64%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.341853 Test loss=0.344125 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3339296281337738
[5/24] Train loss=0.32212164998054504
[10/24] Train loss=0.352268785238266
[15/24] Train loss=0.33014699816703796
[20/24] Train loss=0.2887588441371918
Test set avg_accuracy=84.28% avg_sensitivity=50.28%, avg_specificity=95.70% avg_auc=90.94%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.339197 Test loss=0.335770 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3274594247341156
[5/24] Train loss=0.31567370891571045
[10/24] Train loss=0.35012972354888916
[15/24] Train loss=0.32909050583839417
[20/24] Train loss=0.2909119129180908
Test set avg_accuracy=84.08% avg_sensitivity=48.73%, avg_specificity=95.95% avg_auc=90.85%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.337475 Test loss=0.338508 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.32726722955703735
[5/24] Train loss=0.31894251704216003
[10/24] Train loss=0.35131749510765076
[15/24] Train loss=0.3283860385417938
[20/24] Train loss=0.2796754837036133
Test set avg_accuracy=84.28% avg_sensitivity=49.92%, avg_specificity=95.83% avg_auc=90.84%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.337361 Test loss=0.337420 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3261415362358093
[5/24] Train loss=0.32136836647987366
[10/24] Train loss=0.35365742444992065
[15/24] Train loss=0.3305661976337433
[20/24] Train loss=0.2862582802772522
Test set avg_accuracy=84.22% avg_sensitivity=50.08%, avg_specificity=95.69% avg_auc=90.89%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.338058 Test loss=0.336504 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3239910304546356
[5/24] Train loss=0.31917569041252136
[10/24] Train loss=0.35169607400894165
[15/24] Train loss=0.3305027186870575
[20/24] Train loss=0.28565528988838196
Test set avg_accuracy=84.43% avg_sensitivity=51.17%, avg_specificity=95.60% avg_auc=90.95%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.337258 Test loss=0.334096 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.32273954153060913
[5/24] Train loss=0.3150138556957245
[10/24] Train loss=0.3535025417804718
[15/24] Train loss=0.3311299681663513
[20/24] Train loss=0.28310641646385193
Test set avg_accuracy=84.49% avg_sensitivity=52.51%, avg_specificity=95.23% avg_auc=90.91%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.337750 Test loss=0.333586 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.32560399174690247
[5/24] Train loss=0.31969380378723145
[10/24] Train loss=0.34737735986709595
[15/24] Train loss=0.33030402660369873
[20/24] Train loss=0.28370875120162964
Test set avg_accuracy=84.40% avg_sensitivity=50.80%, avg_specificity=95.69% avg_auc=90.89%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.336661 Test loss=0.335643 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3254769444465637
[5/24] Train loss=0.32196274399757385
[10/24] Train loss=0.34974026679992676
[15/24] Train loss=0.33064308762550354
[20/24] Train loss=0.2834952771663666
Test set avg_accuracy=84.22% avg_sensitivity=51.11%, avg_specificity=95.34% avg_auc=90.82%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.335742 Test loss=0.335550 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3281985819339752
[5/24] Train loss=0.32115790247917175
[10/24] Train loss=0.35161077976226807
[15/24] Train loss=0.32825377583503723
[20/24] Train loss=0.27903056144714355
Test set avg_accuracy=84.31% avg_sensitivity=51.06%, avg_specificity=95.48% avg_auc=90.85%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.337432 Test loss=0.335714 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.32309213280677795
[5/24] Train loss=0.3229539394378662
[10/24] Train loss=0.35128384828567505
[15/24] Train loss=0.33254510164260864
[20/24] Train loss=0.28316831588745117
Test set avg_accuracy=84.32% avg_sensitivity=51.01%, avg_specificity=95.51% avg_auc=90.88%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.335956 Test loss=0.334842 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3226727545261383
[5/24] Train loss=0.3177088499069214
[10/24] Train loss=0.35156896710395813
[15/24] Train loss=0.32792073488235474
[20/24] Train loss=0.2827996611595154
Test set avg_accuracy=84.22% avg_sensitivity=50.13%, avg_specificity=95.67% avg_auc=90.84%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.336014 Test loss=0.336519 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3258678615093231
[5/24] Train loss=0.31836238503456116
[10/24] Train loss=0.3512862026691437
[15/24] Train loss=0.3318442404270172
[20/24] Train loss=0.2792372405529022
Test set avg_accuracy=83.96% avg_sensitivity=49.09%, avg_specificity=95.67% avg_auc=90.75%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.335995 Test loss=0.338327 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3299715220928192
[5/24] Train loss=0.3187170922756195
[10/24] Train loss=0.34772446751594543
[15/24] Train loss=0.33146536350250244
[20/24] Train loss=0.2823773920536041
Test set avg_accuracy=83.95% avg_sensitivity=48.21%, avg_specificity=95.95% avg_auc=90.68%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.336193 Test loss=0.340621 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3306207060813904
[5/24] Train loss=0.3165578246116638
[10/24] Train loss=0.35404229164123535
[15/24] Train loss=0.33087342977523804
[20/24] Train loss=0.2873772978782654
Test set avg_accuracy=84.01% avg_sensitivity=48.94%, avg_specificity=95.79% avg_auc=90.81%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.336836 Test loss=0.338920 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3243488073348999
[5/24] Train loss=0.3157547116279602
[10/24] Train loss=0.3510706126689911
[15/24] Train loss=0.3287371098995209
[20/24] Train loss=0.28275713324546814
Test set avg_accuracy=83.95% avg_sensitivity=48.68%, avg_specificity=95.79% avg_auc=90.84%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.335865 Test loss=0.338656 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.32339560985565186
[5/24] Train loss=0.3117321729660034
[10/24] Train loss=0.35414138436317444
[15/24] Train loss=0.33055365085601807
[20/24] Train loss=0.2851724326610565
Test set avg_accuracy=84.39% avg_sensitivity=50.91%, avg_specificity=95.63% avg_auc=90.89%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.335080 Test loss=0.335404 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3238503932952881
[5/24] Train loss=0.31346896290779114
[10/24] Train loss=0.34896206855773926
[15/24] Train loss=0.32918304204940796
[20/24] Train loss=0.2831362187862396
Test set avg_accuracy=84.31% avg_sensitivity=50.39%, avg_specificity=95.70% avg_auc=90.78%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.335496 Test loss=0.337044 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.32530176639556885
[5/24] Train loss=0.3147839307785034
[10/24] Train loss=0.34806394577026367
[15/24] Train loss=0.3249056041240692
[20/24] Train loss=0.28402361273765564
Test set avg_accuracy=84.15% avg_sensitivity=49.82%, avg_specificity=95.69% avg_auc=90.77%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.336015 Test loss=0.337707 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.32346874475479126
[5/24] Train loss=0.3152320981025696
[10/24] Train loss=0.34844380617141724
[15/24] Train loss=0.32401251792907715
[20/24] Train loss=0.2815735638141632
Test set avg_accuracy=84.44% avg_sensitivity=51.58%, avg_specificity=95.48% avg_auc=90.86%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.335457 Test loss=0.334182 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3248785734176636
[5/24] Train loss=0.3180169463157654
[10/24] Train loss=0.3487569987773895
[15/24] Train loss=0.32227274775505066
[20/24] Train loss=0.2824942469596863
Test set avg_accuracy=85.01% avg_sensitivity=57.95%, avg_specificity=94.10% avg_auc=90.90%
Best model saved!! Metric=1.9654393702657416!!
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.337741 Test loss=0.328864 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3219843804836273
[5/24] Train loss=0.314541220664978
[10/24] Train loss=0.34814250469207764
[15/24] Train loss=0.32639461755752563
[20/24] Train loss=0.27876803278923035
Test set avg_accuracy=85.31% avg_sensitivity=60.75%, avg_specificity=93.56% avg_auc=90.97%
Best model saved!! Metric=4.588390189264899!!
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.335339 Test loss=0.326778 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.32218819856643677
[5/24] Train loss=0.31386318802833557
[10/24] Train loss=0.3444119989871979
[15/24] Train loss=0.32829973101615906
[20/24] Train loss=0.28180721402168274
Test set avg_accuracy=85.12% avg_sensitivity=58.93%, avg_specificity=93.91% avg_auc=90.93%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.334868 Test loss=0.327635 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3169481158256531
[5/24] Train loss=0.3137229084968567
[10/24] Train loss=0.3497813045978546
[15/24] Train loss=0.3240508437156677
[20/24] Train loss=0.28068807721138
Test set avg_accuracy=85.31% avg_sensitivity=61.11%, avg_specificity=93.44% avg_auc=90.92%
Best model saved!! Metric=4.782340115395286!!
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.334039 Test loss=0.326763 Current lr=[0.000156543481933168]

[0/24] Train loss=0.317667156457901
[5/24] Train loss=0.31188738346099854
[10/24] Train loss=0.3470074534416199
[15/24] Train loss=0.32011285424232483
[20/24] Train loss=0.28096798062324524
Test set avg_accuracy=85.23% avg_sensitivity=59.81%, avg_specificity=93.77% avg_auc=90.95%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.332965 Test loss=0.326877 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.31888696551322937
[5/24] Train loss=0.3094065487384796
[10/24] Train loss=0.343268483877182
[15/24] Train loss=0.32432302832603455
[20/24] Train loss=0.28039637207984924
Test set avg_accuracy=85.29% avg_sensitivity=59.87%, avg_specificity=93.83% avg_auc=90.95%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.332320 Test loss=0.326434 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3150181472301483
[5/24] Train loss=0.3071497082710266
[10/24] Train loss=0.34167489409446716
[15/24] Train loss=0.31992360949516296
[20/24] Train loss=0.2768843173980713
Test set avg_accuracy=85.29% avg_sensitivity=59.61%, avg_specificity=93.91% avg_auc=90.98%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.332477 Test loss=0.326363 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3225027322769165
[5/24] Train loss=0.3126114010810852
[10/24] Train loss=0.34002557396888733
[15/24] Train loss=0.3259948492050171
[20/24] Train loss=0.2801281213760376
Test set avg_accuracy=85.30% avg_sensitivity=61.37%, avg_specificity=93.34% avg_auc=90.98%
Best model saved!! Metric=4.986716872384356!!
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.332644 Test loss=0.325683 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3156758248806
[5/24] Train loss=0.3093610405921936
[10/24] Train loss=0.34593549370765686
[15/24] Train loss=0.3197181224822998
[20/24] Train loss=0.27842846512794495
Test set avg_accuracy=85.27% avg_sensitivity=59.87%, avg_specificity=93.81% avg_auc=90.92%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.331418 Test loss=0.326844 Current lr=[0.000134135431043539]

[0/24] Train loss=0.31809189915657043
[5/24] Train loss=0.3135046362876892
[10/24] Train loss=0.3455785810947418
[15/24] Train loss=0.3241078555583954
[20/24] Train loss=0.28097206354141235
Test set avg_accuracy=85.35% avg_sensitivity=61.37%, avg_specificity=93.41% avg_auc=90.97%
Best model saved!! Metric=5.097982362360533!!
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.332246 Test loss=0.325761 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.319428026676178
[5/24] Train loss=0.30904439091682434
[10/24] Train loss=0.3431219160556793
[15/24] Train loss=0.32101282477378845
[20/24] Train loss=0.2771102786064148
Test set avg_accuracy=85.38% avg_sensitivity=60.07%, avg_specificity=93.88% avg_auc=91.04%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.331170 Test loss=0.324925 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3157941997051239
[5/24] Train loss=0.30943137407302856
[10/24] Train loss=0.34614208340644836
[15/24] Train loss=0.3201327919960022
[20/24] Train loss=0.27900201082229614
Test set avg_accuracy=85.56% avg_sensitivity=61.73%, avg_specificity=93.56% avg_auc=91.05%
Best model saved!! Metric=5.905172462173553!!
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.331629 Test loss=0.324524 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3155437707901001
[5/24] Train loss=0.30796346068382263
[10/24] Train loss=0.3477957248687744
[15/24] Train loss=0.3217184245586395
[20/24] Train loss=0.27898287773132324
Test set avg_accuracy=85.65% avg_sensitivity=62.71%, avg_specificity=93.36% avg_auc=91.12%
Best model saved!! Metric=6.84296543716637!!
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.331729 Test loss=0.323410 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3148406445980072
[5/24] Train loss=0.30823424458503723
[10/24] Train loss=0.3471391201019287
[15/24] Train loss=0.32850831747055054
[20/24] Train loss=0.27971068024635315
Test set avg_accuracy=85.49% avg_sensitivity=62.82%, avg_specificity=93.11% avg_auc=91.14%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.331876 Test loss=0.323153 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3176962733268738
[5/24] Train loss=0.307814359664917
[10/24] Train loss=0.3470657169818878
[15/24] Train loss=0.32789626717567444
[20/24] Train loss=0.28060898184776306
Test set avg_accuracy=85.49% avg_sensitivity=64.01%, avg_specificity=92.71% avg_auc=91.14%
Best model saved!! Metric=7.356293529643494!!
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.331219 Test loss=0.323202 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3182896077632904
[5/24] Train loss=0.3127693831920624
[10/24] Train loss=0.34744417667388916
[15/24] Train loss=0.32361361384391785
[20/24] Train loss=0.2789619565010071
Test set avg_accuracy=85.55% avg_sensitivity=64.89%, avg_specificity=92.49% avg_auc=91.18%
Best model saved!! Metric=8.104077977411961!!
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.331339 Test loss=0.322987 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3192673921585083
[5/24] Train loss=0.31879934668540955
[10/24] Train loss=0.3522337079048157
[15/24] Train loss=0.32673096656799316
[20/24] Train loss=0.2782408595085144
Test set avg_accuracy=85.82% avg_sensitivity=67.12%, avg_specificity=92.10% avg_auc=91.16%
Best model saved!! Metric=10.199037766790369!!
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.331856 Test loss=0.323961 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3185601532459259
[5/24] Train loss=0.3202524781227112
[10/24] Train loss=0.3548910915851593
[15/24] Train loss=0.322032630443573
[20/24] Train loss=0.27777382731437683
Test set avg_accuracy=85.69% avg_sensitivity=70.07%, avg_specificity=90.94% avg_auc=91.07%
Best model saved!! Metric=11.76393431243585!!
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.332807 Test loss=0.328278 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.32182225584983826
[5/24] Train loss=0.3231063783168793
[10/24] Train loss=0.35806071758270264
[15/24] Train loss=0.3212084472179413
[20/24] Train loss=0.27667176723480225
Test set avg_accuracy=84.88% avg_sensitivity=71.52%, avg_specificity=89.37% avg_auc=90.65%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.334583 Test loss=0.338411 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3320588171482086
[5/24] Train loss=0.32616814970970154
[10/24] Train loss=0.35401442646980286
[15/24] Train loss=0.3226903975009918
[20/24] Train loss=0.299079030752182
Test set avg_accuracy=85.44% avg_sensitivity=71.15%, avg_specificity=90.24% avg_auc=91.01%
Best model saved!! Metric=11.851989608828617!!
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.337299 Test loss=0.332832 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3294627368450165
[5/24] Train loss=0.31228139996528625
[10/24] Train loss=0.3505786955356598
[15/24] Train loss=0.3321777284145355
[20/24] Train loss=0.28958025574684143
Test set avg_accuracy=85.79% avg_sensitivity=65.67%, avg_specificity=92.56% avg_auc=91.26%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.334346 Test loss=0.322572 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3150958716869354
[5/24] Train loss=0.31126099824905396
[10/24] Train loss=0.34822601079940796
[15/24] Train loss=0.327333003282547
[20/24] Train loss=0.2832571268081665
Test set avg_accuracy=85.73% avg_sensitivity=66.75%, avg_specificity=92.10% avg_auc=91.27%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.330249 Test loss=0.323544 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3180290460586548
[5/24] Train loss=0.3177408277988434
[10/24] Train loss=0.3518126308917999
[15/24] Train loss=0.32576149702072144
[20/24] Train loss=0.2867480218410492
Test set avg_accuracy=85.57% avg_sensitivity=67.94%, avg_specificity=91.49% avg_auc=91.24%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.332966 Test loss=0.325773 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3221983015537262
[5/24] Train loss=0.32064205408096313
[10/24] Train loss=0.3511253297328949
[15/24] Train loss=0.32754382491111755
[20/24] Train loss=0.2883477807044983
Test set avg_accuracy=85.48% avg_sensitivity=72.50%, avg_specificity=89.84% avg_auc=90.95%
Best model saved!! Metric=12.771231301949726!!
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.334661 Test loss=0.335461 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3314254879951477
[5/24] Train loss=0.33104562759399414
[10/24] Train loss=0.3523462414741516
[15/24] Train loss=0.3215142786502838
[20/24] Train loss=0.3005440831184387
Test set avg_accuracy=85.61% avg_sensitivity=71.26%, avg_specificity=90.43% avg_auc=91.04%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.336251 Test loss=0.332253 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3257037103176117
[5/24] Train loss=0.3149133324623108
[10/24] Train loss=0.34778955578804016
[15/24] Train loss=0.3277028799057007
[20/24] Train loss=0.2933802306652069
Test set avg_accuracy=85.59% avg_sensitivity=65.15%, avg_specificity=92.45% avg_auc=91.28%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.332868 Test loss=0.323694 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.31927645206451416
[5/24] Train loss=0.31281059980392456
[10/24] Train loss=0.3395915627479553
[15/24] Train loss=0.3233902156352997
[20/24] Train loss=0.2866157591342926
Test set avg_accuracy=85.35% avg_sensitivity=65.35%, avg_specificity=92.07% avg_auc=91.28%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.328757 Test loss=0.323600 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3194062113761902
[5/24] Train loss=0.31498828530311584
[10/24] Train loss=0.34388792514801025
[15/24] Train loss=0.32343941926956177
[20/24] Train loss=0.2866707146167755
Test set avg_accuracy=85.44% avg_sensitivity=65.67%, avg_specificity=92.09% avg_auc=91.26%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.329567 Test loss=0.324459 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3221805989742279
[5/24] Train loss=0.31516769528388977
[10/24] Train loss=0.3405642509460449
[15/24] Train loss=0.3273303806781769
[20/24] Train loss=0.28540268540382385
Test set avg_accuracy=85.53% avg_sensitivity=64.32%, avg_specificity=92.66% avg_auc=91.28%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.329132 Test loss=0.322829 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.3146842420101166
[5/24] Train loss=0.3100360631942749
[10/24] Train loss=0.3406337797641754
[15/24] Train loss=0.32384687662124634
[20/24] Train loss=0.2847858667373657
Test set avg_accuracy=85.51% avg_sensitivity=63.90%, avg_specificity=92.76% avg_auc=91.28%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.327997 Test loss=0.322426 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3179267644882202
[5/24] Train loss=0.31042495369911194
[10/24] Train loss=0.3436358571052551
[15/24] Train loss=0.3202582001686096
[20/24] Train loss=0.2852911055088043
Test set avg_accuracy=85.61% avg_sensitivity=63.49%, avg_specificity=93.04% avg_auc=91.30%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.327567 Test loss=0.322175 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3161582052707672
[5/24] Train loss=0.307020902633667
[10/24] Train loss=0.3414643704891205
[15/24] Train loss=0.3214322030544281
[20/24] Train loss=0.28361397981643677
Test set avg_accuracy=85.57% avg_sensitivity=63.70%, avg_specificity=92.92% avg_auc=91.32%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.327146 Test loss=0.321704 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3177216947078705
[5/24] Train loss=0.31273525953292847
[10/24] Train loss=0.34092482924461365
[15/24] Train loss=0.32071441411972046
[20/24] Train loss=0.2865181267261505
Test set avg_accuracy=85.72% avg_sensitivity=63.28%, avg_specificity=93.25% avg_auc=91.31%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.326973 Test loss=0.321622 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.31741219758987427
[5/24] Train loss=0.3104657828807831
[10/24] Train loss=0.3408788740634918
[15/24] Train loss=0.3178408443927765
[20/24] Train loss=0.282580703496933
Test set avg_accuracy=85.73% avg_sensitivity=62.71%, avg_specificity=93.46% avg_auc=91.33%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.325677 Test loss=0.321197 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.31450408697128296
[5/24] Train loss=0.3084767162799835
[10/24] Train loss=0.34398984909057617
[15/24] Train loss=0.31962645053863525
[20/24] Train loss=0.28093650937080383
Test set avg_accuracy=85.73% avg_sensitivity=61.78%, avg_specificity=93.77% avg_auc=91.32%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.326412 Test loss=0.321302 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.31317031383514404
[5/24] Train loss=0.31269213557243347
[10/24] Train loss=0.3413492441177368
[15/24] Train loss=0.32308346033096313
[20/24] Train loss=0.2844821512699127
Test set avg_accuracy=85.78% avg_sensitivity=62.14%, avg_specificity=93.72% avg_auc=91.33%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.326648 Test loss=0.321111 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.311873197555542
[5/24] Train loss=0.3110450506210327
[10/24] Train loss=0.339952677488327
[15/24] Train loss=0.32081592082977295
[20/24] Train loss=0.2766697108745575
Test set avg_accuracy=85.81% avg_sensitivity=62.30%, avg_specificity=93.70% avg_auc=91.32%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.325902 Test loss=0.321172 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.31020987033843994
[5/24] Train loss=0.3101501762866974
[10/24] Train loss=0.3367699384689331
[15/24] Train loss=0.3250868022441864
[20/24] Train loss=0.2793438732624054
Test set avg_accuracy=85.76% avg_sensitivity=61.26%, avg_specificity=93.98% avg_auc=91.33%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.325899 Test loss=0.321047 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.31903842091560364
[5/24] Train loss=0.3141176402568817
[10/24] Train loss=0.3403572142124176
[15/24] Train loss=0.321933776140213
[20/24] Train loss=0.27911850810050964
Test set avg_accuracy=85.74% avg_sensitivity=62.14%, avg_specificity=93.67% avg_auc=91.34%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.326566 Test loss=0.320689 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.312419593334198
[5/24] Train loss=0.31439560651779175
[10/24] Train loss=0.3415379524230957
[15/24] Train loss=0.32165566086769104
[20/24] Train loss=0.27823564410209656
Test set avg_accuracy=85.68% avg_sensitivity=63.49%, avg_specificity=93.13% avg_auc=91.36%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.326836 Test loss=0.320769 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.311414897441864
[5/24] Train loss=0.3162108063697815
[10/24] Train loss=0.3390144407749176
[15/24] Train loss=0.3176707625389099
[20/24] Train loss=0.27435755729675293
Test set avg_accuracy=85.91% avg_sensitivity=66.18%, avg_specificity=92.54% avg_auc=91.35%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.326392 Test loss=0.321524 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.31461843848228455
[5/24] Train loss=0.30900752544403076
[10/24] Train loss=0.34281206130981445
[15/24] Train loss=0.32176896929740906
[20/24] Train loss=0.27271005511283875
Test set avg_accuracy=85.82% avg_sensitivity=67.06%, avg_specificity=92.12% avg_auc=91.35%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.326580 Test loss=0.322185 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.3178972899913788
[5/24] Train loss=0.31254467368125916
[10/24] Train loss=0.3444339632987976
[15/24] Train loss=0.3175300061702728
[20/24] Train loss=0.27840912342071533
Test set avg_accuracy=85.90% avg_sensitivity=67.84%, avg_specificity=91.96% avg_auc=91.35%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.326565 Test loss=0.322715 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.31849753856658936
[5/24] Train loss=0.30904728174209595
[10/24] Train loss=0.34340789914131165
[15/24] Train loss=0.31930407881736755
[20/24] Train loss=0.27472203969955444
Test set avg_accuracy=85.86% avg_sensitivity=67.43%, avg_specificity=92.05% avg_auc=91.35%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.325996 Test loss=0.322481 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.31661537289619446
[5/24] Train loss=0.30831822752952576
[10/24] Train loss=0.3419592082500458
[15/24] Train loss=0.31827113032341003
[20/24] Train loss=0.2752254605293274
Test set avg_accuracy=85.77% avg_sensitivity=66.34%, avg_specificity=92.29% avg_auc=91.37%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.325864 Test loss=0.321388 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.3161643147468567
[5/24] Train loss=0.3075444996356964
[10/24] Train loss=0.34398353099823
[15/24] Train loss=0.3201129734516144
[20/24] Train loss=0.28052401542663574
Test set avg_accuracy=85.83% avg_sensitivity=65.61%, avg_specificity=92.62% avg_auc=91.37%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.325035 Test loss=0.321002 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.31534531712532043
[5/24] Train loss=0.3122178614139557
[10/24] Train loss=0.3431910276412964
[15/24] Train loss=0.3143981695175171
[20/24] Train loss=0.2763455808162689
Test set avg_accuracy=85.87% avg_sensitivity=65.56%, avg_specificity=92.69% avg_auc=91.38%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.324733 Test loss=0.320788 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3146493434906006
[5/24] Train loss=0.30610620975494385
[10/24] Train loss=0.3413675129413605
[15/24] Train loss=0.32027867436408997
[20/24] Train loss=0.2771272659301758
Test set avg_accuracy=85.86% avg_sensitivity=65.15%, avg_specificity=92.82% avg_auc=91.38%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.325117 Test loss=0.320544 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3138992488384247
[5/24] Train loss=0.30868497490882874
[10/24] Train loss=0.3407853841781616
[15/24] Train loss=0.31515124440193176
[20/24] Train loss=0.2727316617965698
Test set avg_accuracy=85.86% avg_sensitivity=65.20%, avg_specificity=92.80% avg_auc=91.37%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.323730 Test loss=0.320558 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.31310221552848816
[5/24] Train loss=0.3050506114959717
[10/24] Train loss=0.34283551573753357
[15/24] Train loss=0.31927117705345154
[20/24] Train loss=0.2761008143424988
Test set avg_accuracy=85.81% avg_sensitivity=64.68%, avg_specificity=92.90% avg_auc=91.38%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.324363 Test loss=0.320411 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.3141933083534241
[5/24] Train loss=0.3142026960849762
[10/24] Train loss=0.33687499165534973
[15/24] Train loss=0.3201242685317993
[20/24] Train loss=0.2765015959739685
Test set avg_accuracy=85.87% avg_sensitivity=65.15%, avg_specificity=92.83% avg_auc=91.38%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.324755 Test loss=0.320522 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3160513937473297
[5/24] Train loss=0.31149527430534363
[10/24] Train loss=0.342200368642807
[15/24] Train loss=0.3182867169380188
[20/24] Train loss=0.27480393648147583
Test set avg_accuracy=85.78% avg_sensitivity=64.84%, avg_specificity=92.82% avg_auc=91.38%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.324548 Test loss=0.320416 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3126086890697479
[5/24] Train loss=0.30916380882263184
[10/24] Train loss=0.34229540824890137
[15/24] Train loss=0.319303959608078
[20/24] Train loss=0.2771182954311371
Test set avg_accuracy=85.83% avg_sensitivity=64.58%, avg_specificity=92.97% avg_auc=91.39%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.324343 Test loss=0.320310 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.31581810116767883
[5/24] Train loss=0.31325238943099976
[10/24] Train loss=0.34046244621276855
[15/24] Train loss=0.318194717168808
[20/24] Train loss=0.27778831124305725
Test set avg_accuracy=85.81% avg_sensitivity=64.68%, avg_specificity=92.90% avg_auc=91.38%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.324236 Test loss=0.320355 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.31227537989616394
[5/24] Train loss=0.3102667033672333
[10/24] Train loss=0.3409370481967926
[15/24] Train loss=0.3158930540084839
[20/24] Train loss=0.2804211676120758
Test set avg_accuracy=85.79% avg_sensitivity=64.63%, avg_specificity=92.90% avg_auc=91.38%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.324079 Test loss=0.320358 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.31397777795791626
[5/24] Train loss=0.30781689286231995
[10/24] Train loss=0.3395116329193115
[15/24] Train loss=0.32114386558532715
[20/24] Train loss=0.2795480787754059
Test set avg_accuracy=85.82% avg_sensitivity=64.63%, avg_specificity=92.94% avg_auc=91.38%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.324211 Test loss=0.320333 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3134763240814209
[5/24] Train loss=0.30782821774482727
[10/24] Train loss=0.34656158089637756
[15/24] Train loss=0.31603819131851196
[20/24] Train loss=0.2765009105205536
Test set avg_accuracy=85.85% avg_sensitivity=64.63%, avg_specificity=92.97% avg_auc=91.38%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.324164 Test loss=0.320326 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3138660490512848
[5/24] Train loss=0.30654922127723694
[10/24] Train loss=0.3401164412498474
[15/24] Train loss=0.31971296668052673
[20/24] Train loss=0.27765941619873047
Test set avg_accuracy=85.85% avg_sensitivity=64.63%, avg_specificity=92.97% avg_auc=91.38%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.323969 Test loss=0.320324 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=85.48% sen=72.50%, spe=89.84%, auc=90.95%!
Fold[8] Avg_overlap=0.64%(±0.24972362370999468)
[0/23] Train loss=1.1069445610046387
[5/23] Train loss=0.8151470422744751
[10/23] Train loss=0.6908698081970215
[15/23] Train loss=0.6321225762367249
[20/23] Train loss=0.6105382442474365
Test set avg_accuracy=75.64% avg_sensitivity=0.92%, avg_specificity=99.43% avg_auc=52.79%
Best model saved!! Metric=-97.22236115248391!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.749553 Test loss=0.574246 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.623447060585022
[5/23] Train loss=0.5977383852005005
[10/23] Train loss=0.6080206632614136
[15/23] Train loss=0.5866839289665222
[20/23] Train loss=0.584638774394989
Test set avg_accuracy=75.74% avg_sensitivity=0.59%, avg_specificity=99.67% avg_auc=55.84%
Best model saved!! Metric=-94.14647439280797!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.610947 Test loss=0.550609 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.5960322618484497
[5/23] Train loss=0.5648969411849976
[10/23] Train loss=0.587112307548523
[15/23] Train loss=0.5752671360969543
[20/23] Train loss=0.5760397911071777
Test set avg_accuracy=75.61% avg_sensitivity=1.02%, avg_specificity=99.36% avg_auc=61.32%
Best model saved!! Metric=-88.68256868567532!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.593536 Test loss=0.545594 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.5916135907173157
[5/23] Train loss=0.5736213326454163
[10/23] Train loss=0.5898002982139587
[15/23] Train loss=0.5635313987731934
[20/23] Train loss=0.5647767782211304
Test set avg_accuracy=75.68% avg_sensitivity=1.02%, avg_specificity=99.45% avg_auc=63.94%
Best model saved!! Metric=-85.9089513947534!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.584902 Test loss=0.537501 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.5775424242019653
[5/23] Train loss=0.5638230443000793
[10/23] Train loss=0.5762559771537781
[15/23] Train loss=0.5590392351150513
[20/23] Train loss=0.5589169859886169
Test set avg_accuracy=75.57% avg_sensitivity=1.13%, avg_specificity=99.28% avg_auc=67.42%
Best model saved!! Metric=-82.59946513405751!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.580264 Test loss=0.531093 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.5659278035163879
[5/23] Train loss=0.5501984357833862
[10/23] Train loss=0.5697135925292969
[15/23] Train loss=0.5527294278144836
[20/23] Train loss=0.5511820912361145
Test set avg_accuracy=75.57% avg_sensitivity=1.40%, avg_specificity=99.19% avg_auc=71.23%
Best model saved!! Metric=-78.60381482113455!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.569187 Test loss=0.523355 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.565680742263794
[5/23] Train loss=0.5453795790672302
[10/23] Train loss=0.560218334197998
[15/23] Train loss=0.543717622756958
[20/23] Train loss=0.5412400960922241
Test set avg_accuracy=75.39% avg_sensitivity=2.43%, avg_specificity=98.63% avg_auc=74.13%
Best model saved!! Metric=-75.42821747423157!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.562728 Test loss=0.515871 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.5466938018798828
[5/23] Train loss=0.5397232174873352
[10/23] Train loss=0.5577569603919983
[15/23] Train loss=0.5287644863128662
[20/23] Train loss=0.5336036086082458
Test set avg_accuracy=75.25% avg_sensitivity=3.56%, avg_specificity=98.08% avg_auc=76.16%
Best model saved!! Metric=-72.95353657299222!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.553270 Test loss=0.507364 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.5315768718719482
[5/23] Train loss=0.5123531818389893
[10/23] Train loss=0.5464357733726501
[15/23] Train loss=0.5241050124168396
[20/23] Train loss=0.5171273350715637
Test set avg_accuracy=75.22% avg_sensitivity=6.31%, avg_specificity=97.17% avg_auc=78.13%
Best model saved!! Metric=-69.17307915934005!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.541394 Test loss=0.497619 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.524002730846405
[5/23] Train loss=0.5090209245681763
[10/23] Train loss=0.5399574041366577
[15/23] Train loss=0.5116568803787231
[20/23] Train loss=0.4996459484100342
Test set avg_accuracy=75.39% avg_sensitivity=8.36%, avg_specificity=96.74% avg_auc=79.54%
Best model saved!! Metric=-65.97405692913249!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.530425 Test loss=0.485190 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.5123709440231323
[5/23] Train loss=0.4900309443473816
[10/23] Train loss=0.5183593034744263
[15/23] Train loss=0.49537336826324463
[20/23] Train loss=0.49380502104759216
Test set avg_accuracy=75.56% avg_sensitivity=11.81%, avg_specificity=95.86% avg_auc=80.74%
Best model saved!! Metric=-62.035263982961794!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.516371 Test loss=0.472565 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.5020724534988403
[5/23] Train loss=0.4819096326828003
[10/23] Train loss=0.5123369693756104
[15/23] Train loss=0.4826886057853699
[20/23] Train loss=0.47539636492729187
Test set avg_accuracy=76.08% avg_sensitivity=19.08%, avg_specificity=94.23% avg_auc=81.66%
Best model saved!! Metric=-54.94290953166633!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.502296 Test loss=0.462489 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.48372963070869446
[5/23] Train loss=0.4670199751853943
[10/23] Train loss=0.5027653574943542
[15/23] Train loss=0.4677239656448364
[20/23] Train loss=0.46548762917518616
Test set avg_accuracy=76.94% avg_sensitivity=28.25%, avg_specificity=92.45% avg_auc=82.73%
Best model saved!! Metric=-45.63448486888277!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.489166 Test loss=0.453153 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.47370514273643494
[5/23] Train loss=0.4565282464027405
[10/23] Train loss=0.4860284924507141
[15/23] Train loss=0.45147231221199036
[20/23] Train loss=0.44502222537994385
Test set avg_accuracy=78.14% avg_sensitivity=38.17%, avg_specificity=90.87% avg_auc=83.39%
Best model saved!! Metric=-35.433007474337636!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.475936 Test loss=0.444443 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.4655485153198242
[5/23] Train loss=0.44136133790016174
[10/23] Train loss=0.47989022731781006
[15/23] Train loss=0.445151150226593
[20/23] Train loss=0.4313913881778717
Test set avg_accuracy=78.61% avg_sensitivity=48.41%, avg_specificity=88.22% avg_auc=83.96%
Best model saved!! Metric=-26.805142219198395!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.464165 Test loss=0.441391 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.4614226222038269
[5/23] Train loss=0.4348680377006531
[10/23] Train loss=0.4764305055141449
[15/23] Train loss=0.433130145072937
[20/23] Train loss=0.42107874155044556
Test set avg_accuracy=79.00% avg_sensitivity=54.77%, avg_specificity=86.71% avg_auc=84.23%
Best model saved!! Metric=-21.285875223895147!!
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.457657 Test loss=0.437947 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.45579713582992554
[5/23] Train loss=0.4303075075149536
[10/23] Train loss=0.4731779396533966
[15/23] Train loss=0.41496074199676514
[20/23] Train loss=0.4205736815929413
Test set avg_accuracy=79.19% avg_sensitivity=55.63%, avg_specificity=86.70% avg_auc=84.60%
Best model saved!! Metric=-19.880308567977373!!
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.448761 Test loss=0.428782 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.44338464736938477
[5/23] Train loss=0.4176824688911438
[10/23] Train loss=0.46048083901405334
[15/23] Train loss=0.41125330328941345
[20/23] Train loss=0.4104563593864441
Test set avg_accuracy=79.43% avg_sensitivity=53.10%, avg_specificity=87.81% avg_auc=84.96%
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.440456 Test loss=0.414990 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.4233834445476532
[5/23] Train loss=0.4175296425819397
[10/23] Train loss=0.4517056345939636
[15/23] Train loss=0.40043744444847107
[20/23] Train loss=0.39725369215011597
Test set avg_accuracy=79.60% avg_sensitivity=46.79%, avg_specificity=90.04% avg_auc=85.33%
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.431501 Test loss=0.402658 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.4157792031764984
[5/23] Train loss=0.39928704500198364
[10/23] Train loss=0.4336398243904114
[15/23] Train loss=0.3975937068462372
[20/23] Train loss=0.39006277918815613
Test set avg_accuracy=80.01% avg_sensitivity=51.32%, avg_specificity=89.15% avg_auc=85.77%
Best model saved!! Metric=-19.746006502598995!!
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.424878 Test loss=0.399522 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.4090481698513031
[5/23] Train loss=0.3955613970756531
[10/23] Train loss=0.4325101971626282
[15/23] Train loss=0.39206039905548096
[20/23] Train loss=0.39037781953811646
Test set avg_accuracy=80.36% avg_sensitivity=52.24%, avg_specificity=89.32% avg_auc=86.11%
Best model saved!! Metric=-17.96931530507578!!
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.417474 Test loss=0.394733 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.4018116295337677
[5/23] Train loss=0.3980003595352173
[10/23] Train loss=0.42202380299568176
[15/23] Train loss=0.3859233558177948
[20/23] Train loss=0.3904777765274048
Test set avg_accuracy=80.61% avg_sensitivity=54.23%, avg_specificity=89.01% avg_auc=86.19%
Best model saved!! Metric=-15.957607728744186!!
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.414972 Test loss=0.392803 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.4042232930660248
[5/23] Train loss=0.387925922870636
[10/23] Train loss=0.4226190149784088
[15/23] Train loss=0.39050257205963135
[20/23] Train loss=0.38270702958106995
Test set avg_accuracy=80.82% avg_sensitivity=54.93%, avg_specificity=89.06% avg_auc=86.13%
Best model saved!! Metric=-15.050182508271348!!
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.411116 Test loss=0.391088 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.391303688287735
[5/23] Train loss=0.388295441865921
[10/23] Train loss=0.42266151309013367
[15/23] Train loss=0.3781402111053467
[20/23] Train loss=0.3776608109474182
Test set avg_accuracy=81.12% avg_sensitivity=53.32%, avg_specificity=89.97% avg_auc=86.29%
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.406600 Test loss=0.386452 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.386601060628891
[5/23] Train loss=0.3806898295879364
[10/23] Train loss=0.415554940700531
[15/23] Train loss=0.36513781547546387
[20/23] Train loss=0.3685859441757202
Test set avg_accuracy=81.15% avg_sensitivity=49.49%, avg_specificity=91.23% avg_auc=86.74%
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.401428 Test loss=0.379985 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.3807187080383301
[5/23] Train loss=0.38345178961753845
[10/23] Train loss=0.41709908843040466
[15/23] Train loss=0.3593074679374695
[20/23] Train loss=0.3643744885921478
Test set avg_accuracy=81.56% avg_sensitivity=50.51%, avg_specificity=91.45% avg_auc=87.27%
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.398555 Test loss=0.374233 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.38244059681892395
[5/23] Train loss=0.38211631774902344
[10/23] Train loss=0.41548478603363037
[15/23] Train loss=0.3562348186969757
[20/23] Train loss=0.3602324426174164
Test set avg_accuracy=81.90% avg_sensitivity=48.46%, avg_specificity=92.55% avg_auc=87.82%
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.393001 Test loss=0.368474 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.36723190546035767
[5/23] Train loss=0.3767740726470947
[10/23] Train loss=0.4040057361125946
[15/23] Train loss=0.3480227291584015
[20/23] Train loss=0.3534759283065796
Test set avg_accuracy=82.57% avg_sensitivity=48.09%, avg_specificity=93.55% avg_auc=88.42%
Best model saved!! Metric=-13.387271387166471!!
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.386285 Test loss=0.362722 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.3578101396560669
[5/23] Train loss=0.3690372109413147
[10/23] Train loss=0.3948177397251129
[15/23] Train loss=0.33889803290367126
[20/23] Train loss=0.34051668643951416
Test set avg_accuracy=82.80% avg_sensitivity=47.60%, avg_specificity=94.01% avg_auc=88.76%
Best model saved!! Metric=-12.832079201275207!!
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.379876 Test loss=0.358719 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.35940298438072205
[5/23] Train loss=0.36447596549987793
[10/23] Train loss=0.39422890543937683
[15/23] Train loss=0.34738364815711975
[20/23] Train loss=0.3381038010120392
Test set avg_accuracy=82.72% avg_sensitivity=46.31%, avg_specificity=94.32% avg_auc=88.74%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.375939 Test loss=0.359102 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.35217154026031494
[5/23] Train loss=0.3575018346309662
[10/23] Train loss=0.3971768915653229
[15/23] Train loss=0.33629781007766724
[20/23] Train loss=0.33017778396606445
Test set avg_accuracy=83.06% avg_sensitivity=49.22%, avg_specificity=93.84% avg_auc=88.65%
Best model saved!! Metric=-11.23966804112731!!
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.371129 Test loss=0.357786 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.3556690216064453
[5/23] Train loss=0.35078752040863037
[10/23] Train loss=0.3895995020866394
[15/23] Train loss=0.34100261330604553
[20/23] Train loss=0.3326491117477417
Test set avg_accuracy=83.14% avg_sensitivity=47.98%, avg_specificity=94.33% avg_auc=89.18%
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.368615 Test loss=0.352884 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.3446260690689087
[5/23] Train loss=0.35517191886901855
[10/23] Train loss=0.3856271207332611
[15/23] Train loss=0.33223456144332886
[20/23] Train loss=0.32698118686676025
Test set avg_accuracy=83.58% avg_sensitivity=53.80%, avg_specificity=93.06% avg_auc=89.27%
Best model saved!! Metric=-6.28420842226474!!
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.366389 Test loss=0.348828 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.3497840166091919
[5/23] Train loss=0.3560037612915039
[10/23] Train loss=0.3711453974246979
[15/23] Train loss=0.3278517723083496
[20/23] Train loss=0.3281487822532654
Test set avg_accuracy=83.61% avg_sensitivity=51.21%, avg_specificity=93.92% avg_auc=89.44%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.363728 Test loss=0.347932 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.3410041332244873
[5/23] Train loss=0.3550461232662201
[10/23] Train loss=0.3772589862346649
[15/23] Train loss=0.33048880100250244
[20/23] Train loss=0.3246147334575653
Test set avg_accuracy=83.71% avg_sensitivity=53.58%, avg_specificity=93.30% avg_auc=89.29%
Best model saved!! Metric=-6.110822503701868!!
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.362519 Test loss=0.348440 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.3455383777618408
[5/23] Train loss=0.3536664545536041
[10/23] Train loss=0.3751850128173828
[15/23] Train loss=0.32135602831840515
[20/23] Train loss=0.32268840074539185
Test set avg_accuracy=83.48% avg_sensitivity=52.99%, avg_specificity=93.18% avg_auc=89.26%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.361356 Test loss=0.348790 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.347310870885849
[5/23] Train loss=0.35131552815437317
[10/23] Train loss=0.37181156873703003
[15/23] Train loss=0.3282058537006378
[20/23] Train loss=0.3240039050579071
Test set avg_accuracy=83.44% avg_sensitivity=50.73%, avg_specificity=93.85% avg_auc=89.28%
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.359252 Test loss=0.349507 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.3425543010234833
[5/23] Train loss=0.34959858655929565
[10/23] Train loss=0.36517074704170227
[15/23] Train loss=0.3284751772880554
[20/23] Train loss=0.3289957344532013
Test set avg_accuracy=83.09% avg_sensitivity=48.68%, avg_specificity=94.04% avg_auc=89.15%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.357113 Test loss=0.352363 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.34727364778518677
[5/23] Train loss=0.34840530157089233
[10/23] Train loss=0.3722757399082184
[15/23] Train loss=0.3280232548713684
[20/23] Train loss=0.3334961533546448
Test set avg_accuracy=82.81% avg_sensitivity=46.36%, avg_specificity=94.42% avg_auc=88.95%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.357651 Test loss=0.357113 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.3465692102909088
[5/23] Train loss=0.3485466539859772
[10/23] Train loss=0.36625826358795166
[15/23] Train loss=0.3287632167339325
[20/23] Train loss=0.3295067548751831
Test set avg_accuracy=83.26% avg_sensitivity=48.03%, avg_specificity=94.47% avg_auc=89.33%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.357624 Test loss=0.351902 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.3418639302253723
[5/23] Train loss=0.3429599702358246
[10/23] Train loss=0.37039241194725037
[15/23] Train loss=0.3327452540397644
[20/23] Train loss=0.31793519854545593
Test set avg_accuracy=83.49% avg_sensitivity=50.19%, avg_specificity=94.09% avg_auc=89.41%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.356347 Test loss=0.348804 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.34014958143234253
[5/23] Train loss=0.347012996673584
[10/23] Train loss=0.3701794445514679
[15/23] Train loss=0.326183021068573
[20/23] Train loss=0.31807729601860046
Test set avg_accuracy=84.01% avg_sensitivity=55.80%, avg_specificity=93.00% avg_auc=89.64%
Best model saved!! Metric=-3.558140648558364!!
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.357835 Test loss=0.343454 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.33812931180000305
[5/23] Train loss=0.3547264337539673
[10/23] Train loss=0.3724468946456909
[15/23] Train loss=0.3213613033294678
[20/23] Train loss=0.32020673155784607
Test set avg_accuracy=84.13% avg_sensitivity=58.87%, avg_specificity=92.17% avg_auc=89.58%
Best model saved!! Metric=-1.2569289939131352!!
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.357488 Test loss=0.343479 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.3406688868999481
[5/23] Train loss=0.3516455888748169
[10/23] Train loss=0.36429938673973083
[15/23] Train loss=0.32318341732025146
[20/23] Train loss=0.3163827657699585
Test set avg_accuracy=83.96% avg_sensitivity=56.50%, avg_specificity=92.70% avg_auc=89.74%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.354356 Test loss=0.341548 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.335783988237381
[5/23] Train loss=0.3468495011329651
[10/23] Train loss=0.3656005859375
[15/23] Train loss=0.32560908794403076
[20/23] Train loss=0.31449830532073975
Test set avg_accuracy=83.97% avg_sensitivity=55.74%, avg_specificity=92.96% avg_auc=89.72%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.354406 Test loss=0.341818 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.34075334668159485
[5/23] Train loss=0.3417316675186157
[10/23] Train loss=0.3647580146789551
[15/23] Train loss=0.3217453062534332
[20/23] Train loss=0.3112315535545349
Test set avg_accuracy=84.05% avg_sensitivity=57.79%, avg_specificity=92.41% avg_auc=89.74%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.353483 Test loss=0.341271 Current lr=[0.000299926900870094]

[0/23] Train loss=0.3392578363418579
[5/23] Train loss=0.34668371081352234
[10/23] Train loss=0.36291754245758057
[15/23] Train loss=0.31693604588508606
[20/23] Train loss=0.3118494749069214
Test set avg_accuracy=84.09% avg_sensitivity=55.63%, avg_specificity=93.15% avg_auc=89.79%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.351967 Test loss=0.340776 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.3387543559074402
[5/23] Train loss=0.34372007846832275
[10/23] Train loss=0.36771655082702637
[15/23] Train loss=0.32312023639678955
[20/23] Train loss=0.31534358859062195
Test set avg_accuracy=84.08% avg_sensitivity=55.63%, avg_specificity=93.13% avg_auc=89.73%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.352107 Test loss=0.341705 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.332858145236969
[5/23] Train loss=0.3422158658504486
[10/23] Train loss=0.36473166942596436
[15/23] Train loss=0.3231861889362335
[20/23] Train loss=0.3107023537158966
Test set avg_accuracy=84.15% avg_sensitivity=57.09%, avg_specificity=92.77% avg_auc=89.73%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.351484 Test loss=0.340848 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.3323807716369629
[5/23] Train loss=0.3411698341369629
[10/23] Train loss=0.36271682381629944
[15/23] Train loss=0.3218839764595032
[20/23] Train loss=0.31010058522224426
Test set avg_accuracy=84.14% avg_sensitivity=57.57%, avg_specificity=92.60% avg_auc=89.88%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.350161 Test loss=0.339070 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.33172130584716797
[5/23] Train loss=0.3424832820892334
[10/23] Train loss=0.3701695501804352
[15/23] Train loss=0.31670278310775757
[20/23] Train loss=0.31177493929862976
Test set avg_accuracy=84.18% avg_sensitivity=57.90%, avg_specificity=92.55% avg_auc=89.89%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.350070 Test loss=0.338756 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.3317142128944397
[5/23] Train loss=0.3436620831489563
[10/23] Train loss=0.36255908012390137
[15/23] Train loss=0.31892484426498413
[20/23] Train loss=0.30952614545822144
Test set avg_accuracy=84.14% avg_sensitivity=56.60%, avg_specificity=92.91% avg_auc=89.73%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.349643 Test loss=0.340670 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.335807740688324
[5/23] Train loss=0.34218472242355347
[10/23] Train loss=0.36694127321243286
[15/23] Train loss=0.316731721162796
[20/23] Train loss=0.3138825297355652
Test set avg_accuracy=84.28% avg_sensitivity=57.25%, avg_specificity=92.89% avg_auc=89.79%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.350075 Test loss=0.339803 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.3312298655509949
[5/23] Train loss=0.34652698040008545
[10/23] Train loss=0.36174455285072327
[15/23] Train loss=0.3173976540565491
[20/23] Train loss=0.3136534094810486
Test set avg_accuracy=84.31% avg_sensitivity=58.01%, avg_specificity=92.69% avg_auc=89.96%
Best model saved!! Metric=-1.0352356405858956!!
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.349874 Test loss=0.337840 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.3274184465408325
[5/23] Train loss=0.34198078513145447
[10/23] Train loss=0.36277005076408386
[15/23] Train loss=0.3155903220176697
[20/23] Train loss=0.3107052147388458
Test set avg_accuracy=84.34% avg_sensitivity=58.49%, avg_specificity=92.57% avg_auc=89.87%
Best model saved!! Metric=-0.7333914219485536!!
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.348519 Test loss=0.338650 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.328850120306015
[5/23] Train loss=0.3444531559944153
[10/23] Train loss=0.36307844519615173
[15/23] Train loss=0.31811630725860596
[20/23] Train loss=0.3081030249595642
Test set avg_accuracy=84.32% avg_sensitivity=58.92%, avg_specificity=92.41% avg_auc=90.00%
Best model saved!! Metric=-0.33982294209284447!!
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.348359 Test loss=0.337343 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.32708749175071716
[5/23] Train loss=0.33879873156547546
[10/23] Train loss=0.35703152418136597
[15/23] Train loss=0.31623923778533936
[20/23] Train loss=0.309170126914978
Test set avg_accuracy=84.28% avg_sensitivity=57.25%, avg_specificity=92.89% avg_auc=89.91%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.345841 Test loss=0.338420 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.3268609642982483
[5/23] Train loss=0.34445324540138245
[10/23] Train loss=0.36390420794487
[15/23] Train loss=0.3178921043872833
[20/23] Train loss=0.30751243233680725
Test set avg_accuracy=84.30% avg_sensitivity=60.27%, avg_specificity=91.95% avg_auc=89.98%
Best model saved!! Metric=0.4983811948335912!!
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.347648 Test loss=0.337860 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.33044734597206116
[5/23] Train loss=0.3437047600746155
[10/23] Train loss=0.3578709661960602
[15/23] Train loss=0.31344854831695557
[20/23] Train loss=0.3115658164024353
Test set avg_accuracy=84.30% avg_sensitivity=58.65%, avg_specificity=92.46% avg_auc=90.06%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.346547 Test loss=0.336801 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.32632169127464294
[5/23] Train loss=0.34122025966644287
[10/23] Train loss=0.36115121841430664
[15/23] Train loss=0.31518229842185974
[20/23] Train loss=0.3110431432723999
Test set avg_accuracy=84.31% avg_sensitivity=58.11%, avg_specificity=92.65% avg_auc=90.05%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.345642 Test loss=0.336765 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.32729876041412354
[5/23] Train loss=0.3416000008583069
[10/23] Train loss=0.359443336725235
[15/23] Train loss=0.3172752857208252
[20/23] Train loss=0.30725693702697754
Test set avg_accuracy=84.39% avg_sensitivity=58.81%, avg_specificity=92.53% avg_auc=90.18%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.345474 Test loss=0.335113 Current lr=[0.000283047938381597]

[0/23] Train loss=0.3277784287929535
[5/23] Train loss=0.34521299600601196
[10/23] Train loss=0.3606339395046234
[15/23] Train loss=0.31000658869743347
[20/23] Train loss=0.3079833686351776
Test set avg_accuracy=84.36% avg_sensitivity=59.30%, avg_specificity=92.34% avg_auc=90.05%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.345156 Test loss=0.336296 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.32784149050712585
[5/23] Train loss=0.34433767199516296
[10/23] Train loss=0.36086970567703247
[15/23] Train loss=0.31412041187286377
[20/23] Train loss=0.30616018176078796
Test set avg_accuracy=84.41% avg_sensitivity=58.38%, avg_specificity=92.70% avg_auc=90.22%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.344597 Test loss=0.334457 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.3275128901004791
[5/23] Train loss=0.3450312614440918
[10/23] Train loss=0.36352095007896423
[15/23] Train loss=0.31544697284698486
[20/23] Train loss=0.3097003996372223
Test set avg_accuracy=84.49% avg_sensitivity=58.71%, avg_specificity=92.70% avg_auc=90.18%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.345340 Test loss=0.334673 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.32531899213790894
[5/23] Train loss=0.3440789580345154
[10/23] Train loss=0.35654211044311523
[15/23] Train loss=0.3147633671760559
[20/23] Train loss=0.30522453784942627
Test set avg_accuracy=84.47% avg_sensitivity=59.62%, avg_specificity=92.38% avg_auc=90.18%
Best model saved!! Metric=0.6491103301693926!!
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.344057 Test loss=0.334792 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.3275810778141022
[5/23] Train loss=0.3419128656387329
[10/23] Train loss=0.3614851236343384
[15/23] Train loss=0.3115576207637787
[20/23] Train loss=0.311178594827652
Test set avg_accuracy=84.39% avg_sensitivity=59.25%, avg_specificity=92.39% avg_auc=90.16%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.344372 Test loss=0.335027 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.32601025700569153
[5/23] Train loss=0.3428264856338501
[10/23] Train loss=0.3570089638233185
[15/23] Train loss=0.309772253036499
[20/23] Train loss=0.3052549958229065
Test set avg_accuracy=84.24% avg_sensitivity=58.38%, avg_specificity=92.48% avg_auc=90.13%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.343306 Test loss=0.335481 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.326554536819458
[5/23] Train loss=0.3405241370201111
[10/23] Train loss=0.3575214445590973
[15/23] Train loss=0.3113625943660736
[20/23] Train loss=0.3082590699195862
Test set avg_accuracy=84.32% avg_sensitivity=59.14%, avg_specificity=92.34% avg_auc=90.20%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.342844 Test loss=0.334772 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.3244992196559906
[5/23] Train loss=0.339400053024292
[10/23] Train loss=0.35919445753097534
[15/23] Train loss=0.307228684425354
[20/23] Train loss=0.3021545112133026
Test set avg_accuracy=84.31% avg_sensitivity=58.54%, avg_specificity=92.52% avg_auc=90.25%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.342079 Test loss=0.333818 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.32079094648361206
[5/23] Train loss=0.3428111672401428
[10/23] Train loss=0.35685208439826965
[15/23] Train loss=0.3106764554977417
[20/23] Train loss=0.30230945348739624
Test set avg_accuracy=84.49% avg_sensitivity=59.03%, avg_specificity=92.60% avg_auc=90.35%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.341936 Test loss=0.332542 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.3223053812980652
[5/23] Train loss=0.34240850806236267
[10/23] Train loss=0.3549584746360779
[15/23] Train loss=0.31056106090545654
[20/23] Train loss=0.30681154131889343
Test set avg_accuracy=84.40% avg_sensitivity=58.54%, avg_specificity=92.64% avg_auc=90.31%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.341835 Test loss=0.333075 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.31967559456825256
[5/23] Train loss=0.3429621160030365
[10/23] Train loss=0.3526579737663269
[15/23] Train loss=0.31174996495246887
[20/23] Train loss=0.30921706557273865
Test set avg_accuracy=84.56% avg_sensitivity=59.73%, avg_specificity=92.46% avg_auc=90.33%
Best model saved!! Metric=1.0781019115679413!!
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.343031 Test loss=0.332486 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.32193389534950256
[5/23] Train loss=0.34672611951828003
[10/23] Train loss=0.35334309935569763
[15/23] Train loss=0.30827265977859497
[20/23] Train loss=0.30868348479270935
Test set avg_accuracy=84.58% avg_sensitivity=60.22%, avg_specificity=92.34% avg_auc=90.31%
Best model saved!! Metric=1.4553345364382722!!
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.342799 Test loss=0.333009 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.32011473178863525
[5/23] Train loss=0.3444850444793701
[10/23] Train loss=0.3542468547821045
[15/23] Train loss=0.31176331639289856
[20/23] Train loss=0.3126010298728943
Test set avg_accuracy=84.96% avg_sensitivity=65.50%, avg_specificity=91.16% avg_auc=90.40%
Best model saved!! Metric=6.018341801100135!!
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.344759 Test loss=0.334550 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.327211856842041
[5/23] Train loss=0.33464494347572327
[10/23] Train loss=0.3576369285583496
[15/23] Train loss=0.325221449136734
[20/23] Train loss=0.29756149649620056
Test set avg_accuracy=84.96% avg_sensitivity=71.97%, avg_specificity=89.10% avg_auc=90.38%
Best model saved!! Metric=10.410748358022062!!
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.344802 Test loss=0.342141 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.3394559323787689
[5/23] Train loss=0.32767969369888306
[10/23] Train loss=0.34618493914604187
[15/23] Train loss=0.3216778337955475
[20/23] Train loss=0.2996985912322998
Test set avg_accuracy=84.95% avg_sensitivity=72.02%, avg_specificity=89.06% avg_auc=90.35%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.342452 Test loss=0.343320 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.342732310295105
[5/23] Train loss=0.3293878138065338
[10/23] Train loss=0.35292598605155945
[15/23] Train loss=0.31425240635871887
[20/23] Train loss=0.3004244565963745
Test set avg_accuracy=84.99% avg_sensitivity=71.21%, avg_specificity=89.37% avg_auc=90.37%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.341027 Test loss=0.341627 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.3371173143386841
[5/23] Train loss=0.3300357460975647
[10/23] Train loss=0.3508659303188324
[15/23] Train loss=0.3175446391105652
[20/23] Train loss=0.2957860231399536
Test set avg_accuracy=84.95% avg_sensitivity=71.27%, avg_specificity=89.30% avg_auc=90.41%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.339864 Test loss=0.340592 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.33755865693092346
[5/23] Train loss=0.33002007007598877
[10/23] Train loss=0.35256844758987427
[15/23] Train loss=0.313345730304718
[20/23] Train loss=0.2953168451786041
Test set avg_accuracy=85.08% avg_sensitivity=70.94%, avg_specificity=89.58% avg_auc=90.43%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.341037 Test loss=0.339385 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.33340781927108765
[5/23] Train loss=0.3275454342365265
[10/23] Train loss=0.3547872006893158
[15/23] Train loss=0.31733691692352295
[20/23] Train loss=0.2962917983531952
Test set avg_accuracy=85.00% avg_sensitivity=71.86%, avg_specificity=89.18% avg_auc=90.44%
Best model saved!! Metric=10.482197517439232!!
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.339767 Test loss=0.340877 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.33616507053375244
[5/23] Train loss=0.3274933695793152
[10/23] Train loss=0.35205206274986267
[15/23] Train loss=0.31068962812423706
[20/23] Train loss=0.2986963391304016
Test set avg_accuracy=85.03% avg_sensitivity=71.11%, avg_specificity=89.46% avg_auc=90.43%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.338550 Test loss=0.339757 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.33879655599594116
[5/23] Train loss=0.3284757435321808
[10/23] Train loss=0.35017645359039307
[15/23] Train loss=0.3140847086906433
[20/23] Train loss=0.29763370752334595
Test set avg_accuracy=85.18% avg_sensitivity=71.81%, avg_specificity=89.44% avg_auc=90.43%
Best model saved!! Metric=10.860831282367187!!
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.338280 Test loss=0.340218 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.3374408781528473
[5/23] Train loss=0.32277193665504456
[10/23] Train loss=0.3484528362751007
[15/23] Train loss=0.3131130635738373
[20/23] Train loss=0.29749470949172974
Test set avg_accuracy=85.23% avg_sensitivity=72.02%, avg_specificity=89.44% avg_auc=90.49%
Best model saved!! Metric=11.186981920167042!!
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.337030 Test loss=0.339210 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.3365868628025055
[5/23] Train loss=0.32742008566856384
[10/23] Train loss=0.35093775391578674
[15/23] Train loss=0.3136368691921234
[20/23] Train loss=0.29481974244117737
Test set avg_accuracy=85.25% avg_sensitivity=71.59%, avg_specificity=89.60% avg_auc=90.51%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.337254 Test loss=0.338093 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.33354371786117554
[5/23] Train loss=0.3269287049770355
[10/23] Train loss=0.3541608452796936
[15/23] Train loss=0.31436315178871155
[20/23] Train loss=0.2950970530509949
Test set avg_accuracy=85.25% avg_sensitivity=71.64%, avg_specificity=89.58% avg_auc=90.51%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.335666 Test loss=0.337761 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.33251631259918213
[5/23] Train loss=0.3255932033061981
[10/23] Train loss=0.35353395342826843
[15/23] Train loss=0.3073333501815796
[20/23] Train loss=0.2958492040634155
Test set avg_accuracy=85.23% avg_sensitivity=71.21%, avg_specificity=89.70% avg_auc=90.56%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.336046 Test loss=0.336906 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.3344264030456543
[5/23] Train loss=0.3254821002483368
[10/23] Train loss=0.35175296664237976
[15/23] Train loss=0.31395184993743896
[20/23] Train loss=0.29382598400115967
Test set avg_accuracy=85.35% avg_sensitivity=71.11%, avg_specificity=89.89% avg_auc=90.55%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.335995 Test loss=0.336269 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.33055487275123596
[5/23] Train loss=0.3248612880706787
[10/23] Train loss=0.34777072072029114
[15/23] Train loss=0.3067706525325775
[20/23] Train loss=0.2916385233402252
Test set avg_accuracy=85.34% avg_sensitivity=71.05%, avg_specificity=89.89% avg_auc=90.55%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.334861 Test loss=0.336207 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.33215340971946716
[5/23] Train loss=0.3247888684272766
[10/23] Train loss=0.35240811109542847
[15/23] Train loss=0.3080054819583893
[20/23] Train loss=0.29246801137924194
Test set avg_accuracy=85.21% avg_sensitivity=70.24%, avg_specificity=89.97% avg_auc=90.60%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.334600 Test loss=0.333993 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.3287017345428467
[5/23] Train loss=0.32486599683761597
[10/23] Train loss=0.351146399974823
[15/23] Train loss=0.30713433027267456
[20/23] Train loss=0.2903319299221039
Test set avg_accuracy=85.07% avg_sensitivity=70.51%, avg_specificity=89.70% avg_auc=90.55%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.333499 Test loss=0.335718 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.33204299211502075
[5/23] Train loss=0.328547865152359
[10/23] Train loss=0.3499596416950226
[15/23] Train loss=0.31014084815979004
[20/23] Train loss=0.2994133234024048
Test set avg_accuracy=85.00% avg_sensitivity=70.78%, avg_specificity=89.53% avg_auc=90.56%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.334985 Test loss=0.336968 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.33577731251716614
[5/23] Train loss=0.3207188546657562
[10/23] Train loss=0.351970374584198
[15/23] Train loss=0.3075076639652252
[20/23] Train loss=0.29315003752708435
Test set avg_accuracy=85.03% avg_sensitivity=69.27%, avg_specificity=90.04% avg_auc=90.52%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.333383 Test loss=0.333803 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.3279435932636261
[5/23] Train loss=0.32524147629737854
[10/23] Train loss=0.34963786602020264
[15/23] Train loss=0.3042539060115814
[20/23] Train loss=0.2928452789783478
Test set avg_accuracy=84.91% avg_sensitivity=70.08%, avg_specificity=89.63% avg_auc=90.56%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.333543 Test loss=0.335053 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.33153215050697327
[5/23] Train loss=0.3246828317642212
[10/23] Train loss=0.34932681918144226
[15/23] Train loss=0.3032490015029907
[20/23] Train loss=0.2944829761981964
Test set avg_accuracy=84.88% avg_sensitivity=69.16%, avg_specificity=89.89% avg_auc=90.53%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.332818 Test loss=0.334449 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.3273106813430786
[5/23] Train loss=0.32649147510528564
[10/23] Train loss=0.34798210859298706
[15/23] Train loss=0.3063820004463196
[20/23] Train loss=0.29641884565353394
Test set avg_accuracy=85.08% avg_sensitivity=69.87%, avg_specificity=89.92% avg_auc=90.66%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.332598 Test loss=0.332894 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.32648488879203796
[5/23] Train loss=0.32865995168685913
[10/23] Train loss=0.3527325987815857
[15/23] Train loss=0.30525505542755127
[20/23] Train loss=0.2905859649181366
Test set avg_accuracy=85.64% avg_sensitivity=70.89%, avg_specificity=90.33% avg_auc=90.81%
Best model saved!! Metric=11.667432121696763!!
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.332431 Test loss=0.329760 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.3228437006473541
[5/23] Train loss=0.3198286294937134
[10/23] Train loss=0.3498448133468628
[15/23] Train loss=0.30381256341934204
[20/23] Train loss=0.2885769009590149
Test set avg_accuracy=85.48% avg_sensitivity=71.70%, avg_specificity=89.87% avg_auc=90.84%
Best model saved!! Metric=11.891233716389223!!
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.330621 Test loss=0.330907 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.3266974985599518
[5/23] Train loss=0.32808566093444824
[10/23] Train loss=0.35352247953414917
[15/23] Train loss=0.2998271584510803
[20/23] Train loss=0.2932102084159851
Test set avg_accuracy=85.49% avg_sensitivity=71.37%, avg_specificity=89.99% avg_auc=90.86%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.330812 Test loss=0.329951 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.3281286060810089
[5/23] Train loss=0.32334262132644653
[10/23] Train loss=0.3516486585140228
[15/23] Train loss=0.2997633218765259
[20/23] Train loss=0.2906222939491272
Test set avg_accuracy=85.53% avg_sensitivity=70.89%, avg_specificity=90.20% avg_auc=90.90%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.330425 Test loss=0.328843 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.327211856842041
[5/23] Train loss=0.31932806968688965
[10/23] Train loss=0.3481866717338562
[15/23] Train loss=0.30223536491394043
[20/23] Train loss=0.288993775844574
Test set avg_accuracy=85.57% avg_sensitivity=71.37%, avg_specificity=90.09% avg_auc=90.93%
Best model saved!! Metric=11.970950052828641!!
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.329354 Test loss=0.328928 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.32615986466407776
[5/23] Train loss=0.3211662471294403
[10/23] Train loss=0.35453683137893677
[15/23] Train loss=0.2991386651992798
[20/23] Train loss=0.2891371548175812
Test set avg_accuracy=85.47% avg_sensitivity=71.81%, avg_specificity=89.82% avg_auc=90.93%
Best model saved!! Metric=12.022770568467081!!
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.329372 Test loss=0.329400 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.32574763894081116
[5/23] Train loss=0.3209461569786072
[10/23] Train loss=0.35283026099205017
[15/23] Train loss=0.30142199993133545
[20/23] Train loss=0.28808289766311646
Test set avg_accuracy=85.52% avg_sensitivity=71.97%, avg_specificity=89.84% avg_auc=90.96%
Best model saved!! Metric=12.289848753899463!!
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.329368 Test loss=0.328936 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.32406848669052124
[5/23] Train loss=0.32357388734817505
[10/23] Train loss=0.35730183124542236
[15/23] Train loss=0.30002105236053467
[20/23] Train loss=0.2909630835056305
Test set avg_accuracy=85.36% avg_sensitivity=72.78%, avg_specificity=89.37% avg_auc=90.95%
Best model saved!! Metric=12.468117454083426!!
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.329470 Test loss=0.330811 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.32957467436790466
[5/23] Train loss=0.33193764090538025
[10/23] Train loss=0.35723939538002014
[15/23] Train loss=0.30227363109588623
[20/23] Train loss=0.2866245210170746
Test set avg_accuracy=85.43% avg_sensitivity=75.74%, avg_specificity=88.52% avg_auc=90.89%
Best model saved!! Metric=14.576908211914215!!
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.331039 Test loss=0.337618 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.3383830487728119
[5/23] Train loss=0.3314433991909027
[10/23] Train loss=0.3650347590446472
[15/23] Train loss=0.3004045784473419
[20/23] Train loss=0.294275164604187
Test set avg_accuracy=84.77% avg_sensitivity=77.04%, avg_specificity=87.23% avg_auc=90.75%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.333150 Test loss=0.346963 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.34556517004966736
[5/23] Train loss=0.33505600690841675
[10/23] Train loss=0.3661760985851288
[15/23] Train loss=0.3031609058380127
[20/23] Train loss=0.2922578454017639
Test set avg_accuracy=84.70% avg_sensitivity=77.09%, avg_specificity=87.12% avg_auc=90.69%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.335864 Test loss=0.350604 Current lr=[0.000112073915556435]

[0/23] Train loss=0.34957316517829895
[5/23] Train loss=0.3205098509788513
[10/23] Train loss=0.3472795784473419
[15/23] Train loss=0.31834709644317627
[20/23] Train loss=0.3036532998085022
Test set avg_accuracy=85.43% avg_sensitivity=68.89%, avg_specificity=90.70% avg_auc=90.93%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.335641 Test loss=0.327955 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.31938937306404114
[5/23] Train loss=0.3195773661136627
[10/23] Train loss=0.3522118330001831
[15/23] Train loss=0.3163200616836548
[20/23] Train loss=0.29434534907341003
Test set avg_accuracy=85.36% avg_sensitivity=65.93%, avg_specificity=91.55% avg_auc=90.98%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.330388 Test loss=0.324681 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.31206411123275757
[5/23] Train loss=0.31991374492645264
[10/23] Train loss=0.34596240520477295
[15/23] Train loss=0.30920442938804626
[20/23] Train loss=0.294273316860199
Test set avg_accuracy=85.61% avg_sensitivity=69.38%, avg_specificity=90.78% avg_auc=91.00%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.327650 Test loss=0.327547 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.323668509721756
[5/23] Train loss=0.32628971338272095
[10/23] Train loss=0.3491212725639343
[15/23] Train loss=0.3117484450340271
[20/23] Train loss=0.29501280188560486
Test set avg_accuracy=85.48% avg_sensitivity=67.71%, avg_specificity=91.14% avg_auc=90.99%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.329305 Test loss=0.325785 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.31998297572135925
[5/23] Train loss=0.31692689657211304
[10/23] Train loss=0.35148948431015015
[15/23] Train loss=0.3137509524822235
[20/23] Train loss=0.2969796657562256
Test set avg_accuracy=85.47% avg_sensitivity=67.28%, avg_specificity=91.26% avg_auc=90.99%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.328771 Test loss=0.325252 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.3162410259246826
[5/23] Train loss=0.31922632455825806
[10/23] Train loss=0.34785196185112
[15/23] Train loss=0.3130362331867218
[20/23] Train loss=0.2934717833995819
Test set avg_accuracy=85.43% avg_sensitivity=67.65%, avg_specificity=91.09% avg_auc=90.94%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.327228 Test loss=0.326610 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.31649869680404663
[5/23] Train loss=0.3186638057231903
[10/23] Train loss=0.34982338547706604
[15/23] Train loss=0.30967551469802856
[20/23] Train loss=0.29422101378440857
Test set avg_accuracy=85.38% avg_sensitivity=67.82%, avg_specificity=90.97% avg_auc=90.90%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.327368 Test loss=0.326918 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.3223935663700104
[5/23] Train loss=0.32092925906181335
[10/23] Train loss=0.35333380103111267
[15/23] Train loss=0.3092862367630005
[20/23] Train loss=0.2885280251502991
Test set avg_accuracy=85.21% avg_sensitivity=67.92%, avg_specificity=90.71% avg_auc=90.75%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.327265 Test loss=0.329110 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.3223804235458374
[5/23] Train loss=0.32165542244911194
[10/23] Train loss=0.3527182936668396
[15/23] Train loss=0.305569589138031
[20/23] Train loss=0.2921368181705475
Test set avg_accuracy=85.14% avg_sensitivity=67.17%, avg_specificity=90.87% avg_auc=90.70%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.327823 Test loss=0.329344 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.31991833448410034
[5/23] Train loss=0.3217101991176605
[10/23] Train loss=0.3474516272544861
[15/23] Train loss=0.31012389063835144
[20/23] Train loss=0.291042685508728
Test set avg_accuracy=85.27% avg_sensitivity=65.88%, avg_specificity=91.45% avg_auc=90.88%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.325709 Test loss=0.325461 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.314621239900589
[5/23] Train loss=0.31622040271759033
[10/23] Train loss=0.3424961566925049
[15/23] Train loss=0.3041776120662689
[20/23] Train loss=0.2917719781398773
Test set avg_accuracy=85.36% avg_sensitivity=66.04%, avg_specificity=91.52% avg_auc=91.07%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.325448 Test loss=0.323343 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.31200677156448364
[5/23] Train loss=0.31628337502479553
[10/23] Train loss=0.3425140380859375
[15/23] Train loss=0.30748265981674194
[20/23] Train loss=0.28990665078163147
Test set avg_accuracy=85.35% avg_sensitivity=65.18%, avg_specificity=91.78% avg_auc=91.07%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.325196 Test loss=0.322852 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.31403928995132446
[5/23] Train loss=0.31976020336151123
[10/23] Train loss=0.3412944972515106
[15/23] Train loss=0.306266725063324
[20/23] Train loss=0.2906551957130432
Test set avg_accuracy=85.38% avg_sensitivity=64.91%, avg_specificity=91.90% avg_auc=91.12%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.323613 Test loss=0.321650 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.31532758474349976
[5/23] Train loss=0.3172086775302887
[10/23] Train loss=0.34733352065086365
[15/23] Train loss=0.30111053586006165
[20/23] Train loss=0.28902891278266907
Test set avg_accuracy=85.25% avg_sensitivity=64.31%, avg_specificity=91.91% avg_auc=91.11%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.323748 Test loss=0.321424 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.31094977259635925
[5/23] Train loss=0.3130647838115692
[10/23] Train loss=0.34844210743904114
[15/23] Train loss=0.30833473801612854
[20/23] Train loss=0.29400601983070374
Test set avg_accuracy=85.33% avg_sensitivity=64.42%, avg_specificity=91.98% avg_auc=91.14%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.323327 Test loss=0.321194 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.31454259157180786
[5/23] Train loss=0.31448814272880554
[10/23] Train loss=0.3487067222595215
[15/23] Train loss=0.3040383458137512
[20/23] Train loss=0.2874374985694885
Test set avg_accuracy=85.30% avg_sensitivity=64.26%, avg_specificity=92.00% avg_auc=91.15%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.323541 Test loss=0.320926 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.31399595737457275
[5/23] Train loss=0.3175661861896515
[10/23] Train loss=0.34550052881240845
[15/23] Train loss=0.3078792095184326
[20/23] Train loss=0.2910759747028351
Test set avg_accuracy=85.38% avg_sensitivity=63.56%, avg_specificity=92.33% avg_auc=91.14%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.323294 Test loss=0.320490 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.3088372051715851
[5/23] Train loss=0.31337061524391174
[10/23] Train loss=0.3421953618526459
[15/23] Train loss=0.304486483335495
[20/23] Train loss=0.28735703229904175
Test set avg_accuracy=85.38% avg_sensitivity=63.56%, avg_specificity=92.33% avg_auc=91.15%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.322266 Test loss=0.319965 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.31004002690315247
[5/23] Train loss=0.3123193383216858
[10/23] Train loss=0.34495216608047485
[15/23] Train loss=0.3026580512523651
[20/23] Train loss=0.2842552363872528
Test set avg_accuracy=85.38% avg_sensitivity=63.18%, avg_specificity=92.45% avg_auc=91.17%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.322605 Test loss=0.319975 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.31145229935646057
[5/23] Train loss=0.31472259759902954
[10/23] Train loss=0.34889501333236694
[15/23] Train loss=0.3040487468242645
[20/23] Train loss=0.2887784540653229
Test set avg_accuracy=85.40% avg_sensitivity=63.02%, avg_specificity=92.53% avg_auc=91.20%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.322206 Test loss=0.319337 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.30620306730270386
[5/23] Train loss=0.31789714097976685
[10/23] Train loss=0.34134089946746826
[15/23] Train loss=0.30144384503364563
[20/23] Train loss=0.2899976372718811
Test set avg_accuracy=85.47% avg_sensitivity=62.96%, avg_specificity=92.64% avg_auc=91.20%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.321405 Test loss=0.319183 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.30467280745506287
[5/23] Train loss=0.3157130777835846
[10/23] Train loss=0.3447721600532532
[15/23] Train loss=0.3028939664363861
[20/23] Train loss=0.2854090631008148
Test set avg_accuracy=85.44% avg_sensitivity=62.91%, avg_specificity=92.62% avg_auc=91.20%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.321061 Test loss=0.319147 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.30908089876174927
[5/23] Train loss=0.31488993763923645
[10/23] Train loss=0.34961605072021484
[15/23] Train loss=0.30471837520599365
[20/23] Train loss=0.28605857491493225
Test set avg_accuracy=85.39% avg_sensitivity=62.43%, avg_specificity=92.70% avg_auc=91.22%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.322024 Test loss=0.319015 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.3112930655479431
[5/23] Train loss=0.3176749646663666
[10/23] Train loss=0.34769633412361145
[15/23] Train loss=0.30356451869010925
[20/23] Train loss=0.2836242914199829
Test set avg_accuracy=85.48% avg_sensitivity=62.26%, avg_specificity=92.88% avg_auc=91.24%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.321887 Test loss=0.318515 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.3102789521217346
[5/23] Train loss=0.3157443404197693
[10/23] Train loss=0.35004425048828125
[15/23] Train loss=0.306718111038208
[20/23] Train loss=0.28810665011405945
Test set avg_accuracy=85.44% avg_sensitivity=62.64%, avg_specificity=92.70% avg_auc=91.23%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.321603 Test loss=0.318570 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.3107657730579376
[5/23] Train loss=0.3097117245197296
[10/23] Train loss=0.3433507978916168
[15/23] Train loss=0.3005494475364685
[20/23] Train loss=0.2854858636856079
Test set avg_accuracy=85.42% avg_sensitivity=63.45%, avg_specificity=92.41% avg_auc=91.24%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.320750 Test loss=0.318685 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.3073359429836273
[5/23] Train loss=0.3166424036026001
[10/23] Train loss=0.3457546532154083
[15/23] Train loss=0.30626150965690613
[20/23] Train loss=0.28575456142425537
Test set avg_accuracy=85.48% avg_sensitivity=65.18%, avg_specificity=91.95% avg_auc=91.24%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.320427 Test loss=0.319252 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.3078649640083313
[5/23] Train loss=0.31449878215789795
[10/23] Train loss=0.34494173526763916
[15/23] Train loss=0.30333849787712097
[20/23] Train loss=0.28655532002449036
Test set avg_accuracy=85.56% avg_sensitivity=66.31%, avg_specificity=91.69% avg_auc=91.25%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.321376 Test loss=0.319897 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.3143218159675598
[5/23] Train loss=0.3136059045791626
[10/23] Train loss=0.33811965584754944
[15/23] Train loss=0.30004921555519104
[20/23] Train loss=0.2821141481399536
Test set avg_accuracy=85.53% avg_sensitivity=66.04%, avg_specificity=91.74% avg_auc=91.24%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.320064 Test loss=0.319761 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.31311604380607605
[5/23] Train loss=0.31349921226501465
[10/23] Train loss=0.3424386978149414
[15/23] Train loss=0.30073103308677673
[20/23] Train loss=0.28092923760414124
Test set avg_accuracy=85.44% avg_sensitivity=65.12%, avg_specificity=91.91% avg_auc=91.25%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.319202 Test loss=0.318962 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.30907657742500305
[5/23] Train loss=0.31518855690956116
[10/23] Train loss=0.3463461995124817
[15/23] Train loss=0.30039218068122864
[20/23] Train loss=0.28795161843299866
Test set avg_accuracy=85.47% avg_sensitivity=64.91%, avg_specificity=92.02% avg_auc=91.26%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.320820 Test loss=0.318849 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.31276971101760864
[5/23] Train loss=0.3140529990196228
[10/23] Train loss=0.3435531258583069
[15/23] Train loss=0.29962241649627686
[20/23] Train loss=0.2843477427959442
Test set avg_accuracy=85.51% avg_sensitivity=64.91%, avg_specificity=92.07% avg_auc=91.28%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.320251 Test loss=0.318659 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.3100750148296356
[5/23] Train loss=0.3109970688819885
[10/23] Train loss=0.3375867009162903
[15/23] Train loss=0.2946239709854126
[20/23] Train loss=0.2849898934364319
Test set avg_accuracy=85.49% avg_sensitivity=64.74%, avg_specificity=92.10% avg_auc=91.28%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.319268 Test loss=0.318434 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.30990132689476013
[5/23] Train loss=0.30944639444351196
[10/23] Train loss=0.3392336070537567
[15/23] Train loss=0.2952287793159485
[20/23] Train loss=0.28640681505203247
Test set avg_accuracy=85.57% avg_sensitivity=64.96%, avg_specificity=92.14% avg_auc=91.29%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.319459 Test loss=0.318377 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.30724895000457764
[5/23] Train loss=0.3112443685531616
[10/23] Train loss=0.348937451839447
[15/23] Train loss=0.30029281973838806
[20/23] Train loss=0.28742748498916626
Test set avg_accuracy=85.55% avg_sensitivity=64.80%, avg_specificity=92.15% avg_auc=91.29%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.319563 Test loss=0.318277 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.3111642897129059
[5/23] Train loss=0.3095954954624176
[10/23] Train loss=0.3428756296634674
[15/23] Train loss=0.2954742908477783
[20/23] Train loss=0.28070348501205444
Test set avg_accuracy=85.48% avg_sensitivity=64.47%, avg_specificity=92.17% avg_auc=91.29%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.318966 Test loss=0.318164 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.3060002624988556
[5/23] Train loss=0.3099314570426941
[10/23] Train loss=0.34792783856391907
[15/23] Train loss=0.30281153321266174
[20/23] Train loss=0.28445303440093994
Test set avg_accuracy=85.52% avg_sensitivity=64.64%, avg_specificity=92.17% avg_auc=91.29%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.320235 Test loss=0.318218 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.3078392744064331
[5/23] Train loss=0.3098328411579132
[10/23] Train loss=0.34800711274147034
[15/23] Train loss=0.3012121617794037
[20/23] Train loss=0.28356707096099854
Test set avg_accuracy=85.52% avg_sensitivity=64.53%, avg_specificity=92.21% avg_auc=91.29%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.319158 Test loss=0.318136 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.31361666321754456
[5/23] Train loss=0.31256377696990967
[10/23] Train loss=0.34161487221717834
[15/23] Train loss=0.2951629161834717
[20/23] Train loss=0.2846602201461792
Test set avg_accuracy=85.47% avg_sensitivity=64.26%, avg_specificity=92.22% avg_auc=91.29%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.319068 Test loss=0.318067 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.30987805128097534
[5/23] Train loss=0.30979403853416443
[10/23] Train loss=0.3480296730995178
[15/23] Train loss=0.2970796227455139
[20/23] Train loss=0.2851513624191284
Test set avg_accuracy=85.48% avg_sensitivity=64.26%, avg_specificity=92.24% avg_auc=91.29%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.319346 Test loss=0.318062 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.30892035365104675
[5/23] Train loss=0.31384557485580444
[10/23] Train loss=0.34263232350349426
[15/23] Train loss=0.2982868254184723
[20/23] Train loss=0.28323227167129517
Test set avg_accuracy=85.49% avg_sensitivity=64.42%, avg_specificity=92.21% avg_auc=91.29%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.319837 Test loss=0.318078 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.30566689372062683
[5/23] Train loss=0.3160605728626251
[10/23] Train loss=0.34187641739845276
[15/23] Train loss=0.2962567210197449
[20/23] Train loss=0.2860657870769501
Test set avg_accuracy=85.51% avg_sensitivity=64.42%, avg_specificity=92.22% avg_auc=91.29%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.319622 Test loss=0.318063 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.3099709451198578
[5/23] Train loss=0.3142046630382538
[10/23] Train loss=0.3473880887031555
[15/23] Train loss=0.30091407895088196
[20/23] Train loss=0.28561386466026306
Test set avg_accuracy=85.51% avg_sensitivity=64.42%, avg_specificity=92.22% avg_auc=91.29%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.320378 Test loss=0.318059 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.3093041777610779
[5/23] Train loss=0.3107917904853821
[10/23] Train loss=0.3418741226196289
[15/23] Train loss=0.2997332513332367
[20/23] Train loss=0.2795880436897278
Test set avg_accuracy=85.51% avg_sensitivity=64.42%, avg_specificity=92.22% avg_auc=91.29%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.319559 Test loss=0.318056 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=85.43% sen=75.74%, spe=88.52%, auc=90.89%!
Fold[9] Avg_overlap=0.67%(±0.242580767440984)
[0/24] Train loss=0.8360142111778259
[5/24] Train loss=0.725251317024231
[10/24] Train loss=0.6770521402359009
[15/24] Train loss=0.641309380531311
[20/24] Train loss=0.6313104033470154
Test set avg_accuracy=77.49% avg_sensitivity=0.87%, avg_specificity=99.70% avg_auc=52.24%
Best model saved!! Metric=-95.7015911042127!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.680485 Test loss=0.551975 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6201136112213135
[5/24] Train loss=0.6022151708602905
[10/24] Train loss=0.5998323559761047
[15/24] Train loss=0.5980899930000305
[20/24] Train loss=0.6057290434837341
Test set avg_accuracy=77.53% avg_sensitivity=0.23%, avg_specificity=99.93% avg_auc=55.59%
Best model saved!! Metric=-92.71918759389452!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.599650 Test loss=0.535185 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6027110815048218
[5/24] Train loss=0.5914083123207092
[10/24] Train loss=0.5877048969268799
[15/24] Train loss=0.5956448912620544
[20/24] Train loss=0.6000632047653198
Test set avg_accuracy=77.53% avg_sensitivity=0.29%, avg_specificity=99.92% avg_auc=59.64%
Best model saved!! Metric=-88.62585578895191!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.589596 Test loss=0.532407 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.5986734628677368
[5/24] Train loss=0.5811067223548889
[10/24] Train loss=0.5855013132095337
[15/24] Train loss=0.5926809906959534
[20/24] Train loss=0.5958534479141235
Test set avg_accuracy=77.55% avg_sensitivity=0.41%, avg_specificity=99.92% avg_auc=61.93%
Best model saved!! Metric=-86.19914265532985!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.585040 Test loss=0.527331 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5940003395080566
[5/24] Train loss=0.5782307982444763
[10/24] Train loss=0.5797281861305237
[15/24] Train loss=0.5860076546669006
[20/24] Train loss=0.5906331539154053
Test set avg_accuracy=77.54% avg_sensitivity=0.46%, avg_specificity=99.88% avg_auc=65.00%
Best model saved!! Metric=-83.11209755248426!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.579880 Test loss=0.522129 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5813701152801514
[5/24] Train loss=0.5764634013175964
[10/24] Train loss=0.5769327282905579
[15/24] Train loss=0.5775430798530579
[20/24] Train loss=0.5880621075630188
Test set avg_accuracy=77.53% avg_sensitivity=0.64%, avg_specificity=99.82% avg_auc=68.61%
Best model saved!! Metric=-79.41165428814486!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.574335 Test loss=0.515432 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5771925449371338
[5/24] Train loss=0.5664753317832947
[10/24] Train loss=0.564921498298645
[15/24] Train loss=0.5688263177871704
[20/24] Train loss=0.573513925075531
Test set avg_accuracy=77.54% avg_sensitivity=0.93%, avg_specificity=99.75% avg_auc=71.55%
Best model saved!! Metric=-76.24083930413684!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.566414 Test loss=0.508353 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5716657042503357
[5/24] Train loss=0.5595645308494568
[10/24] Train loss=0.5576919913291931
[15/24] Train loss=0.559718906879425
[20/24] Train loss=0.5642769932746887
Test set avg_accuracy=77.50% avg_sensitivity=1.27%, avg_specificity=99.60% avg_auc=74.54%
Best model saved!! Metric=-73.08598677150545!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.558302 Test loss=0.500382 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5555638670921326
[5/24] Train loss=0.5432217717170715
[10/24] Train loss=0.5474759340286255
[15/24] Train loss=0.5515494346618652
[20/24] Train loss=0.5574357509613037
Test set avg_accuracy=77.46% avg_sensitivity=2.14%, avg_specificity=99.29% avg_auc=76.79%
Best model saved!! Metric=-70.3129140564091!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.548194 Test loss=0.490236 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5449379086494446
[5/24] Train loss=0.5404722094535828
[10/24] Train loss=0.5475612878799438
[15/24] Train loss=0.5426216125488281
[20/24] Train loss=0.5462135672569275
Test set avg_accuracy=77.38% avg_sensitivity=3.42%, avg_specificity=98.82% avg_auc=78.52%
Best model saved!! Metric=-67.85773136059831!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.540556 Test loss=0.479032 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5369256138801575
[5/24] Train loss=0.529202401638031
[10/24] Train loss=0.5379976034164429
[15/24] Train loss=0.525326132774353
[20/24] Train loss=0.5292496085166931
Test set avg_accuracy=77.30% avg_sensitivity=4.29%, avg_specificity=98.47% avg_auc=80.26%
Best model saved!! Metric=-65.67658374485872!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.526569 Test loss=0.465226 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5160283446311951
[5/24] Train loss=0.5104547739028931
[10/24] Train loss=0.5294780731201172
[15/24] Train loss=0.5132271647453308
[20/24] Train loss=0.5228022336959839
Test set avg_accuracy=77.62% avg_sensitivity=8.98%, avg_specificity=97.51% avg_auc=81.95%
Best model saved!! Metric=-59.942389963527845!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.515786 Test loss=0.451002 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4930521249771118
[5/24] Train loss=0.49329107999801636
[10/24] Train loss=0.5192188620567322
[15/24] Train loss=0.4975265860557556
[20/24] Train loss=0.5072370767593384
Test set avg_accuracy=78.67% avg_sensitivity=15.70%, avg_specificity=96.93% avg_auc=83.25%
Best model saved!! Metric=-51.447481939315736!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.501433 Test loss=0.436269 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.486232727766037
[5/24] Train loss=0.47714224457740784
[10/24] Train loss=0.4980039596557617
[15/24] Train loss=0.48718738555908203
[20/24] Train loss=0.48918265104293823
Test set avg_accuracy=79.92% avg_sensitivity=24.86%, avg_specificity=95.89% avg_auc=84.63%
Best model saved!! Metric=-40.709206435073305!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.486803 Test loss=0.422116 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4611425995826721
[5/24] Train loss=0.4765941798686981
[10/24] Train loss=0.485164999961853
[15/24] Train loss=0.4648822247982025
[20/24] Train loss=0.4740598797798157
Test set avg_accuracy=80.94% avg_sensitivity=33.78%, avg_specificity=94.61% avg_auc=85.48%
Best model saved!! Metric=-31.192616524875355!!
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.471185 Test loss=0.408684 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4428912103176117
[5/24] Train loss=0.45555123686790466
[10/24] Train loss=0.47879934310913086
[15/24] Train loss=0.44969189167022705
[20/24] Train loss=0.45816195011138916
Test set avg_accuracy=81.68% avg_sensitivity=38.47%, avg_specificity=94.21% avg_auc=86.18%
Best model saved!! Metric=-25.464414189624314!!
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.459385 Test loss=0.395021 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4323204755783081
[5/24] Train loss=0.44929951429367065
[10/24] Train loss=0.47352978587150574
[15/24] Train loss=0.44069623947143555
[20/24] Train loss=0.4463326334953308
Test set avg_accuracy=82.27% avg_sensitivity=40.90%, avg_specificity=94.26% avg_auc=86.58%
Best model saved!! Metric=-21.993180146135828!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.448143 Test loss=0.384092 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4192574918270111
[5/24] Train loss=0.4361034035682678
[10/24] Train loss=0.4649772346019745
[15/24] Train loss=0.42733728885650635
[20/24] Train loss=0.4380667507648468
Test set avg_accuracy=82.49% avg_sensitivity=37.25%, avg_specificity=95.60% avg_auc=86.76%
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.437498 Test loss=0.375964 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4079129099845886
[5/24] Train loss=0.41614973545074463
[10/24] Train loss=0.4389055371284485
[15/24] Train loss=0.41408249735832214
[20/24] Train loss=0.42675119638442993
Test set avg_accuracy=82.88% avg_sensitivity=37.31%, avg_specificity=96.09% avg_auc=87.23%
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.427935 Test loss=0.369509 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.39423874020576477
[5/24] Train loss=0.4007852375507355
[10/24] Train loss=0.4305240213871002
[15/24] Train loss=0.4071299433708191
[20/24] Train loss=0.4078502655029297
Test set avg_accuracy=83.72% avg_sensitivity=44.26%, avg_specificity=95.16% avg_auc=87.72%
Best model saved!! Metric=-15.1272773472475!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.416197 Test loss=0.361318 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3856872320175171
[5/24] Train loss=0.4033721685409546
[10/24] Train loss=0.4123239815235138
[15/24] Train loss=0.3940986692905426
[20/24] Train loss=0.41055426001548767
Test set avg_accuracy=84.05% avg_sensitivity=43.16%, avg_specificity=95.90% avg_auc=88.02%
Best model saved!! Metric=-14.866534722746628!!
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.409106 Test loss=0.356489 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.38060256838798523
[5/24] Train loss=0.3934798836708069
[10/24] Train loss=0.4088864028453827
[15/24] Train loss=0.37954166531562805
[20/24] Train loss=0.39798006415367126
Test set avg_accuracy=84.14% avg_sensitivity=40.21%, avg_specificity=96.88% avg_auc=88.22%
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.401545 Test loss=0.355036 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3809487819671631
[5/24] Train loss=0.39060887694358826
[10/24] Train loss=0.3953326344490051
[15/24] Train loss=0.37862664461135864
[20/24] Train loss=0.38668179512023926
Test set avg_accuracy=83.63% avg_sensitivity=35.81%, avg_specificity=97.50% avg_auc=88.38%
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.393539 Test loss=0.357264 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.37921610474586487
[5/24] Train loss=0.37704870104789734
[10/24] Train loss=0.40097907185554504
[15/24] Train loss=0.37254562973976135
[20/24] Train loss=0.3798936903476715
Test set avg_accuracy=84.48% avg_sensitivity=40.85%, avg_specificity=97.13% avg_auc=88.84%
Best model saved!! Metric=-14.70429938885129!!
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.386043 Test loss=0.347410 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3678348958492279
[5/24] Train loss=0.3831280767917633
[10/24] Train loss=0.3917137086391449
[15/24] Train loss=0.36432600021362305
[20/24] Train loss=0.3691730797290802
Test set avg_accuracy=84.40% avg_sensitivity=39.05%, avg_specificity=97.55% avg_auc=88.88%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.380206 Test loss=0.351013 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.368225634098053
[5/24] Train loss=0.38622426986694336
[10/24] Train loss=0.3871573507785797
[15/24] Train loss=0.36386677622795105
[20/24] Train loss=0.3682430386543274
Test set avg_accuracy=84.22% avg_sensitivity=37.14%, avg_specificity=97.87% avg_auc=89.07%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.377885 Test loss=0.352569 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.368609756231308
[5/24] Train loss=0.36984044313430786
[10/24] Train loss=0.3772791028022766
[15/24] Train loss=0.3565743863582611
[20/24] Train loss=0.36331719160079956
Test set avg_accuracy=84.77% avg_sensitivity=39.46%, avg_specificity=97.90% avg_auc=89.36%
Best model saved!! Metric=-14.520151118258525!!
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.373943 Test loss=0.344929 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3626505136489868
[5/24] Train loss=0.38554486632347107
[10/24] Train loss=0.3772125840187073
[15/24] Train loss=0.3494625985622406
[20/24] Train loss=0.3564895689487457
Test set avg_accuracy=84.74% avg_sensitivity=39.51%, avg_specificity=97.85% avg_auc=89.54%
Best model saved!! Metric=-14.358660016317977!!
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.370651 Test loss=0.343746 Current lr=[0.000210185142098938]

[0/24] Train loss=0.35961514711380005
[5/24] Train loss=0.38921764492988586
[10/24] Train loss=0.37006497383117676
[15/24] Train loss=0.3474106788635254
[20/24] Train loss=0.35878947377204895
Test set avg_accuracy=84.97% avg_sensitivity=40.61%, avg_specificity=97.83% avg_auc=89.57%
Best model saved!! Metric=-13.006298957888546!!
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.370059 Test loss=0.341917 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.35055214166641235
[5/24] Train loss=0.3890124261379242
[10/24] Train loss=0.3712294399738312
[15/24] Train loss=0.34352922439575195
[20/24] Train loss=0.3526071012020111
Test set avg_accuracy=85.39% avg_sensitivity=44.15%, avg_specificity=97.35% avg_auc=89.86%
Best model saved!! Metric=-9.25689221483092!!
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.367434 Test loss=0.334242 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3423982262611389
[5/24] Train loss=0.3804982900619507
[10/24] Train loss=0.36304664611816406
[15/24] Train loss=0.3457810580730438
[20/24] Train loss=0.3492470681667328
Test set avg_accuracy=85.57% avg_sensitivity=47.74%, avg_specificity=96.54% avg_auc=90.02%
Best model saved!! Metric=-6.127814820116313!!
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.364331 Test loss=0.328441 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3441295027732849
[5/24] Train loss=0.374560683965683
[10/24] Train loss=0.36718687415122986
[15/24] Train loss=0.33887216448783875
[20/24] Train loss=0.3476663827896118
Test set avg_accuracy=85.68% avg_sensitivity=49.42%, avg_specificity=96.19% avg_auc=90.13%
Best model saved!! Metric=-4.58159589571936!!
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.361399 Test loss=0.325413 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.33672258257865906
[5/24] Train loss=0.3762437403202057
[10/24] Train loss=0.3647193908691406
[15/24] Train loss=0.3453761041164398
[20/24] Train loss=0.34333479404449463
Test set avg_accuracy=85.81% avg_sensitivity=49.83%, avg_specificity=96.24% avg_auc=90.18%
Best model saved!! Metric=-3.949679994399574!!
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.361161 Test loss=0.324798 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.33532050251960754
[5/24] Train loss=0.36862635612487793
[10/24] Train loss=0.37052831053733826
[15/24] Train loss=0.3463304340839386
[20/24] Train loss=0.3408055305480957
Test set avg_accuracy=85.72% avg_sensitivity=47.86%, avg_specificity=96.69% avg_auc=90.17%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.357979 Test loss=0.326075 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3355514705181122
[5/24] Train loss=0.36893415451049805
[10/24] Train loss=0.3679809272289276
[15/24] Train loss=0.3434112071990967
[20/24] Train loss=0.34295183420181274
Test set avg_accuracy=85.60% avg_sensitivity=43.74%, avg_specificity=97.73% avg_auc=90.18%
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.358450 Test loss=0.333226 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.34571847319602966
[5/24] Train loss=0.374011754989624
[10/24] Train loss=0.3670293688774109
[15/24] Train loss=0.3452317416667938
[20/24] Train loss=0.33706140518188477
Test set avg_accuracy=85.77% avg_sensitivity=46.29%, avg_specificity=97.21% avg_auc=90.18%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.358360 Test loss=0.328932 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3386949598789215
[5/24] Train loss=0.373826801776886
[10/24] Train loss=0.36559975147247314
[15/24] Train loss=0.34334638714790344
[20/24] Train loss=0.33603161573410034
Test set avg_accuracy=85.69% avg_sensitivity=45.08%, avg_specificity=97.46% avg_auc=90.21%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.357447 Test loss=0.330066 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3368039131164551
[5/24] Train loss=0.370865136384964
[10/24] Train loss=0.3647772967815399
[15/24] Train loss=0.34457671642303467
[20/24] Train loss=0.33988603949546814
Test set avg_accuracy=85.55% avg_sensitivity=44.84%, avg_specificity=97.35% avg_auc=90.21%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.357648 Test loss=0.329313 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.33873140811920166
[5/24] Train loss=0.37335559725761414
[10/24] Train loss=0.36283403635025024
[15/24] Train loss=0.3438923954963684
[20/24] Train loss=0.34107914566993713
Test set avg_accuracy=85.64% avg_sensitivity=45.08%, avg_specificity=97.40% avg_auc=90.25%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.357039 Test loss=0.329362 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.33820921182632446
[5/24] Train loss=0.372708797454834
[10/24] Train loss=0.3653120994567871
[15/24] Train loss=0.3414803445339203
[20/24] Train loss=0.32989776134490967
Test set avg_accuracy=85.51% avg_sensitivity=43.97%, avg_specificity=97.55% avg_auc=90.21%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.356739 Test loss=0.330974 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.33475446701049805
[5/24] Train loss=0.37843775749206543
[10/24] Train loss=0.36321666836738586
[15/24] Train loss=0.34620365500450134
[20/24] Train loss=0.33088937401771545
Test set avg_accuracy=85.62% avg_sensitivity=44.32%, avg_specificity=97.60% avg_auc=90.24%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.356200 Test loss=0.330613 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3362008035182953
[5/24] Train loss=0.37119060754776
[10/24] Train loss=0.3660106360912323
[15/24] Train loss=0.3464398980140686
[20/24] Train loss=0.3365597724914551
Test set avg_accuracy=85.64% avg_sensitivity=45.71%, avg_specificity=97.21% avg_auc=90.21%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.356364 Test loss=0.327939 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3383377194404602
[5/24] Train loss=0.37899279594421387
[10/24] Train loss=0.3645157814025879
[15/24] Train loss=0.33889511227607727
[20/24] Train loss=0.3339550793170929
Test set avg_accuracy=85.76% avg_sensitivity=46.00%, avg_specificity=97.28% avg_auc=90.32%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.356048 Test loss=0.327499 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.33180105686187744
[5/24] Train loss=0.3746454417705536
[10/24] Train loss=0.3600888252258301
[15/24] Train loss=0.346562922000885
[20/24] Train loss=0.3354642391204834
Test set avg_accuracy=85.72% avg_sensitivity=46.23%, avg_specificity=97.16% avg_auc=90.36%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.355251 Test loss=0.326294 Current lr=[0.00029967723776099]

[0/24] Train loss=0.33674851059913635
[5/24] Train loss=0.37476980686187744
[10/24] Train loss=0.35999858379364014
[15/24] Train loss=0.3423430323600769
[20/24] Train loss=0.33498677611351013
Test set avg_accuracy=85.90% avg_sensitivity=47.16%, avg_specificity=97.13% avg_auc=90.39%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.355215 Test loss=0.325181 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.336783230304718
[5/24] Train loss=0.367989182472229
[10/24] Train loss=0.3623546063899994
[15/24] Train loss=0.3446936011314392
[20/24] Train loss=0.3325001001358032
Test set avg_accuracy=85.78% avg_sensitivity=46.93%, avg_specificity=97.04% avg_auc=90.36%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.353789 Test loss=0.325328 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.33244088292121887
[5/24] Train loss=0.36614978313446045
[10/24] Train loss=0.36329180002212524
[15/24] Train loss=0.3399266004562378
[20/24] Train loss=0.3285580575466156
Test set avg_accuracy=85.91% avg_sensitivity=47.62%, avg_specificity=97.01% avg_auc=90.40%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.353252 Test loss=0.324536 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3311642110347748
[5/24] Train loss=0.3725956380367279
[10/24] Train loss=0.3659457266330719
[15/24] Train loss=0.34075605869293213
[20/24] Train loss=0.3325558006763458
Test set avg_accuracy=85.89% avg_sensitivity=46.76%, avg_specificity=97.23% avg_auc=90.40%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.353763 Test loss=0.324493 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3267821669578552
[5/24] Train loss=0.368998259305954
[10/24] Train loss=0.35997825860977173
[15/24] Train loss=0.340121865272522
[20/24] Train loss=0.33555343747138977
Test set avg_accuracy=86.18% avg_sensitivity=50.17%, avg_specificity=96.62% avg_auc=90.43%
Best model saved!! Metric=-2.5913384168138833!!
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.352502 Test loss=0.320733 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3278241455554962
[5/24] Train loss=0.3689333200454712
[10/24] Train loss=0.3640938103199005
[15/24] Train loss=0.3421134352684021
[20/24] Train loss=0.3303106129169464
Test set avg_accuracy=85.98% avg_sensitivity=47.97%, avg_specificity=96.99% avg_auc=90.34%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.352528 Test loss=0.323546 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3280167579650879
[5/24] Train loss=0.3660481870174408
[10/24] Train loss=0.3611830472946167
[15/24] Train loss=0.33847469091415405
[20/24] Train loss=0.33070167899131775
Test set avg_accuracy=85.86% avg_sensitivity=46.76%, avg_specificity=97.20% avg_auc=90.42%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.351323 Test loss=0.324304 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3268252909183502
[5/24] Train loss=0.36871102452278137
[10/24] Train loss=0.36080971360206604
[15/24] Train loss=0.3351232409477234
[20/24] Train loss=0.3322213888168335
Test set avg_accuracy=86.15% avg_sensitivity=48.03%, avg_specificity=97.20% avg_auc=90.38%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.352818 Test loss=0.324317 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.32956457138061523
[5/24] Train loss=0.37080174684524536
[10/24] Train loss=0.3638002574443817
[15/24] Train loss=0.3345223367214203
[20/24] Train loss=0.33015188574790955
Test set avg_accuracy=86.07% avg_sensitivity=49.77%, avg_specificity=96.59% avg_auc=90.47%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.352701 Test loss=0.320054 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3267071545124054
[5/24] Train loss=0.3659572899341583
[10/24] Train loss=0.3616876006126404
[15/24] Train loss=0.33841589093208313
[20/24] Train loss=0.3298986256122589
Test set avg_accuracy=86.08% avg_sensitivity=49.94%, avg_specificity=96.56% avg_auc=90.40%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.351437 Test loss=0.320628 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.32815462350845337
[5/24] Train loss=0.36306032538414
[10/24] Train loss=0.3620932102203369
[15/24] Train loss=0.3382788896560669
[20/24] Train loss=0.3265725374221802
Test set avg_accuracy=86.11% avg_sensitivity=48.26%, avg_specificity=97.08% avg_auc=90.44%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.350724 Test loss=0.322795 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.32706865668296814
[5/24] Train loss=0.36952897906303406
[10/24] Train loss=0.3621971011161804
[15/24] Train loss=0.3353058099746704
[20/24] Train loss=0.32876068353652954
Test set avg_accuracy=86.07% avg_sensitivity=48.03%, avg_specificity=97.09% avg_auc=90.41%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.351270 Test loss=0.322562 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.32556062936782837
[5/24] Train loss=0.36820459365844727
[10/24] Train loss=0.36517003178596497
[15/24] Train loss=0.3358421325683594
[20/24] Train loss=0.32921016216278076
Test set avg_accuracy=86.22% avg_sensitivity=49.42%, avg_specificity=96.89% avg_auc=90.44%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.351534 Test loss=0.321826 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3287561535835266
[5/24] Train loss=0.36265116930007935
[10/24] Train loss=0.36359134316444397
[15/24] Train loss=0.33372384309768677
[20/24] Train loss=0.3304111063480377
Test set avg_accuracy=86.18% avg_sensitivity=49.30%, avg_specificity=96.88% avg_auc=90.42%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.350219 Test loss=0.321175 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3291710913181305
[5/24] Train loss=0.3674669563770294
[10/24] Train loss=0.360609769821167
[15/24] Train loss=0.3375140130519867
[20/24] Train loss=0.32769644260406494
Test set avg_accuracy=86.09% avg_sensitivity=48.15%, avg_specificity=97.09% avg_auc=90.48%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.349801 Test loss=0.322547 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3262735903263092
[5/24] Train loss=0.37597334384918213
[10/24] Train loss=0.35952916741371155
[15/24] Train loss=0.33457720279693604
[20/24] Train loss=0.32487690448760986
Test set avg_accuracy=86.22% avg_sensitivity=50.17%, avg_specificity=96.67% avg_auc=90.43%
Best model saved!! Metric=-2.5005954200272242!!
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.351368 Test loss=0.320625 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3253203332424164
[5/24] Train loss=0.3665781319141388
[10/24] Train loss=0.3652920722961426
[15/24] Train loss=0.3341901898384094
[20/24] Train loss=0.3267819881439209
Test set avg_accuracy=86.26% avg_sensitivity=50.81%, avg_specificity=96.54% avg_auc=90.43%
Best model saved!! Metric=-1.9554513389913026!!
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.350310 Test loss=0.319160 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.32363563776016235
[5/24] Train loss=0.3670057952404022
[10/24] Train loss=0.36346399784088135
[15/24] Train loss=0.33724701404571533
[20/24] Train loss=0.3298153877258301
Test set avg_accuracy=86.24% avg_sensitivity=49.48%, avg_specificity=96.89% avg_auc=90.37%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.349339 Test loss=0.322173 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.32340800762176514
[5/24] Train loss=0.3669978678226471
[10/24] Train loss=0.3599715828895569
[15/24] Train loss=0.3355883061885834
[20/24] Train loss=0.33137184381484985
Test set avg_accuracy=86.21% avg_sensitivity=50.17%, avg_specificity=96.66% avg_auc=90.49%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.350764 Test loss=0.319243 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.324144184589386
[5/24] Train loss=0.3698682487010956
[10/24] Train loss=0.358949214220047
[15/24] Train loss=0.3352597653865814
[20/24] Train loss=0.32786205410957336
Test set avg_accuracy=86.21% avg_sensitivity=49.36%, avg_specificity=96.89% avg_auc=90.48%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.349477 Test loss=0.320967 Current lr=[0.000276307469034998]

[0/24] Train loss=0.32521528005599976
[5/24] Train loss=0.3679775297641754
[10/24] Train loss=0.3558610677719116
[15/24] Train loss=0.330450177192688
[20/24] Train loss=0.32560649514198303
Test set avg_accuracy=86.33% avg_sensitivity=50.75%, avg_specificity=96.64% avg_auc=90.46%
Best model saved!! Metric=-1.822270208378157!!
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.350401 Test loss=0.319490 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3202778100967407
[5/24] Train loss=0.36616313457489014
[10/24] Train loss=0.3593302071094513
[15/24] Train loss=0.33006829023361206
[20/24] Train loss=0.328130304813385
Test set avg_accuracy=86.18% avg_sensitivity=49.94%, avg_specificity=96.69% avg_auc=90.40%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.349623 Test loss=0.321187 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3273196518421173
[5/24] Train loss=0.36818501353263855
[10/24] Train loss=0.35847342014312744
[15/24] Train loss=0.33084025979042053
[20/24] Train loss=0.327816903591156
Test set avg_accuracy=86.17% avg_sensitivity=48.26%, avg_specificity=97.16% avg_auc=90.42%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.349797 Test loss=0.322632 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3235805034637451
[5/24] Train loss=0.37348151206970215
[10/24] Train loss=0.35694777965545654
[15/24] Train loss=0.3296407461166382
[20/24] Train loss=0.3300724923610687
Test set avg_accuracy=86.11% avg_sensitivity=47.86%, avg_specificity=97.20% avg_auc=90.33%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.351435 Test loss=0.325161 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3225700557231903
[5/24] Train loss=0.37606081366539
[10/24] Train loss=0.3577924966812134
[15/24] Train loss=0.33648279309272766
[20/24] Train loss=0.33828964829444885
Test set avg_accuracy=85.51% avg_sensitivity=43.11%, avg_specificity=97.80% avg_auc=90.11%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.353143 Test loss=0.336540 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.338655948638916
[5/24] Train loss=0.3720519542694092
[10/24] Train loss=0.3680148422718048
[15/24] Train loss=0.3370809555053711
[20/24] Train loss=0.3275720775127411
Test set avg_accuracy=85.60% avg_sensitivity=43.45%, avg_specificity=97.82% avg_auc=90.20%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.352436 Test loss=0.333088 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3343871235847473
[5/24] Train loss=0.3602045178413391
[10/24] Train loss=0.3675116002559662
[15/24] Train loss=0.33121606707572937
[20/24] Train loss=0.32828405499458313
Test set avg_accuracy=85.87% avg_sensitivity=44.73%, avg_specificity=97.80% avg_auc=90.36%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.349964 Test loss=0.328374 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.32654625177383423
[5/24] Train loss=0.35914385318756104
[10/24] Train loss=0.3663085699081421
[15/24] Train loss=0.32777169346809387
[20/24] Train loss=0.3253970146179199
Test set avg_accuracy=85.89% avg_sensitivity=45.13%, avg_specificity=97.70% avg_auc=90.31%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.348915 Test loss=0.328557 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3292182385921478
[5/24] Train loss=0.3654387891292572
[10/24] Train loss=0.3657088279724121
[15/24] Train loss=0.3311334252357483
[20/24] Train loss=0.3259228765964508
Test set avg_accuracy=85.94% avg_sensitivity=45.48%, avg_specificity=97.67% avg_auc=90.40%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.348829 Test loss=0.327360 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3252306282520294
[5/24] Train loss=0.36170271039009094
[10/24] Train loss=0.3624197840690613
[15/24] Train loss=0.32861724495887756
[20/24] Train loss=0.32618775963783264
Test set avg_accuracy=85.77% avg_sensitivity=44.32%, avg_specificity=97.78% avg_auc=90.22%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.349571 Test loss=0.330909 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.33094078302383423
[5/24] Train loss=0.3599499464035034
[10/24] Train loss=0.3685145378112793
[15/24] Train loss=0.32557615637779236
[20/24] Train loss=0.3231939971446991
Test set avg_accuracy=85.95% avg_sensitivity=46.12%, avg_specificity=97.50% avg_auc=90.31%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.348864 Test loss=0.326410 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.32415518164634705
[5/24] Train loss=0.3641330301761627
[10/24] Train loss=0.36435985565185547
[15/24] Train loss=0.32733258605003357
[20/24] Train loss=0.3268892168998718
Test set avg_accuracy=85.85% avg_sensitivity=45.19%, avg_specificity=97.63% avg_auc=90.27%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.349074 Test loss=0.329645 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3261829614639282
[5/24] Train loss=0.35801106691360474
[10/24] Train loss=0.3732934892177582
[15/24] Train loss=0.33199557662010193
[20/24] Train loss=0.32385146617889404
Test set avg_accuracy=85.91% avg_sensitivity=46.29%, avg_specificity=97.40% avg_auc=90.30%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.348881 Test loss=0.325997 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.32806673645973206
[5/24] Train loss=0.3577556908130646
[10/24] Train loss=0.36878445744514465
[15/24] Train loss=0.33198118209838867
[20/24] Train loss=0.3230973780155182
Test set avg_accuracy=86.00% avg_sensitivity=46.87%, avg_specificity=97.35% avg_auc=90.35%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.348299 Test loss=0.324989 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.32686519622802734
[5/24] Train loss=0.35355475544929504
[10/24] Train loss=0.371498703956604
[15/24] Train loss=0.3292269706726074
[20/24] Train loss=0.32215172052383423
Test set avg_accuracy=86.02% avg_sensitivity=47.97%, avg_specificity=97.04% avg_auc=90.34%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.349138 Test loss=0.323353 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3254088759422302
[5/24] Train loss=0.35434189438819885
[10/24] Train loss=0.3639613091945648
[15/24] Train loss=0.33240941166877747
[20/24] Train loss=0.32811975479125977
Test set avg_accuracy=86.11% avg_sensitivity=47.10%, avg_specificity=97.41% avg_auc=90.30%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.347247 Test loss=0.326028 Current lr=[0.000224838296036774]

[0/24] Train loss=0.32425299286842346
[5/24] Train loss=0.35396698117256165
[10/24] Train loss=0.3669029474258423
[15/24] Train loss=0.32909083366394043
[20/24] Train loss=0.325790673494339
Test set avg_accuracy=86.15% avg_sensitivity=47.74%, avg_specificity=97.28% avg_auc=90.34%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.348648 Test loss=0.323753 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.32752713561058044
[5/24] Train loss=0.35755655169487
[10/24] Train loss=0.367462694644928
[15/24] Train loss=0.3267427980899811
[20/24] Train loss=0.3246100842952728
Test set avg_accuracy=86.29% avg_sensitivity=50.23%, avg_specificity=96.74% avg_auc=90.31%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.347024 Test loss=0.321264 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.32043832540512085
[5/24] Train loss=0.3556579351425171
[10/24] Train loss=0.3607650697231293
[15/24] Train loss=0.32876983284950256
[20/24] Train loss=0.318013072013855
Test set avg_accuracy=86.07% avg_sensitivity=47.16%, avg_specificity=97.35% avg_auc=90.18%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.346396 Test loss=0.326921 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3225976824760437
[5/24] Train loss=0.3575194180011749
[10/24] Train loss=0.36363470554351807
[15/24] Train loss=0.3225417733192444
[20/24] Train loss=0.3238433599472046
Test set avg_accuracy=86.16% avg_sensitivity=47.86%, avg_specificity=97.26% avg_auc=90.33%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.346887 Test loss=0.324250 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.32313698530197144
[5/24] Train loss=0.3527139723300934
[10/24] Train loss=0.3653332591056824
[15/24] Train loss=0.32943862676620483
[20/24] Train loss=0.3220100700855255
Test set avg_accuracy=86.18% avg_sensitivity=49.94%, avg_specificity=96.69% avg_auc=90.22%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.347636 Test loss=0.322210 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3213384449481964
[5/24] Train loss=0.3559402525424957
[10/24] Train loss=0.3618183135986328
[15/24] Train loss=0.32755547761917114
[20/24] Train loss=0.32505685091018677
Test set avg_accuracy=86.22% avg_sensitivity=48.03%, avg_specificity=97.30% avg_auc=90.29%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.346179 Test loss=0.324652 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3245869278907776
[5/24] Train loss=0.36089810729026794
[10/24] Train loss=0.3657563328742981
[15/24] Train loss=0.3306500017642975
[20/24] Train loss=0.3227604329586029
Test set avg_accuracy=86.03% avg_sensitivity=48.20%, avg_specificity=96.99% avg_auc=90.23%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.348136 Test loss=0.324731 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3288272023200989
[5/24] Train loss=0.358031690120697
[10/24] Train loss=0.36525994539260864
[15/24] Train loss=0.3304879069328308
[20/24] Train loss=0.3227911591529846
Test set avg_accuracy=86.03% avg_sensitivity=47.39%, avg_specificity=97.23% avg_auc=90.19%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.347436 Test loss=0.326231 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.3246019780635834
[5/24] Train loss=0.35100945830345154
[10/24] Train loss=0.3625703752040863
[15/24] Train loss=0.33667096495628357
[20/24] Train loss=0.32298383116722107
Test set avg_accuracy=86.11% avg_sensitivity=47.39%, avg_specificity=97.33% avg_auc=90.18%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.346915 Test loss=0.327343 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.32689619064331055
[5/24] Train loss=0.3572707772254944
[10/24] Train loss=0.36813005805015564
[15/24] Train loss=0.33102571964263916
[20/24] Train loss=0.3230627179145813
Test set avg_accuracy=85.86% avg_sensitivity=46.41%, avg_specificity=97.30% avg_auc=89.99%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.348186 Test loss=0.331517 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3273419141769409
[5/24] Train loss=0.3488520681858063
[10/24] Train loss=0.3619365692138672
[15/24] Train loss=0.3280782699584961
[20/24] Train loss=0.32323527336120605
Test set avg_accuracy=86.05% avg_sensitivity=47.10%, avg_specificity=97.35% avg_auc=90.15%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.348216 Test loss=0.327485 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3222859799861908
[5/24] Train loss=0.34698498249053955
[10/24] Train loss=0.36055007576942444
[15/24] Train loss=0.32601770758628845
[20/24] Train loss=0.32032719254493713
Test set avg_accuracy=86.02% avg_sensitivity=46.81%, avg_specificity=97.38% avg_auc=90.12%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.347735 Test loss=0.329256 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3250129818916321
[5/24] Train loss=0.35113322734832764
[10/24] Train loss=0.362999826669693
[15/24] Train loss=0.3261207640171051
[20/24] Train loss=0.31993409991264343
Test set avg_accuracy=86.08% avg_sensitivity=48.38%, avg_specificity=97.01% avg_auc=90.27%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.348435 Test loss=0.324284 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3237261474132538
[5/24] Train loss=0.34836530685424805
[10/24] Train loss=0.36261942982673645
[15/24] Train loss=0.3293013870716095
[20/24] Train loss=0.3197349011898041
Test set avg_accuracy=86.50% avg_sensitivity=54.00%, avg_specificity=95.92% avg_auc=90.26%
Best model saved!! Metric=0.670019980376459!!
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.349191 Test loss=0.318844 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.31618350744247437
[5/24] Train loss=0.34885719418525696
[10/24] Train loss=0.3569677472114563
[15/24] Train loss=0.3336282968521118
[20/24] Train loss=0.3200033903121948
Test set avg_accuracy=86.56% avg_sensitivity=56.20%, avg_specificity=95.36% avg_auc=90.32%
Best model saved!! Metric=2.447601342817137!!
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.348529 Test loss=0.316417 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.31501147150993347
[5/24] Train loss=0.3468862771987915
[10/24] Train loss=0.35626134276390076
[15/24] Train loss=0.3304613530635834
[20/24] Train loss=0.3215906023979187
Test set avg_accuracy=86.52% avg_sensitivity=58.23%, avg_specificity=94.73% avg_auc=90.31%
Best model saved!! Metric=3.782514136600966!!
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.346482 Test loss=0.315831 Current lr=[0.000156543481933168]

[0/24] Train loss=0.31688985228538513
[5/24] Train loss=0.3495059609413147
[10/24] Train loss=0.3613804280757904
[15/24] Train loss=0.32964664697647095
[20/24] Train loss=0.32296645641326904
Test set avg_accuracy=86.30% avg_sensitivity=57.30%, avg_specificity=94.71% avg_auc=90.28%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.346175 Test loss=0.316349 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.31178560853004456
[5/24] Train loss=0.3579016625881195
[10/24] Train loss=0.36264047026634216
[15/24] Train loss=0.3251400887966156
[20/24] Train loss=0.32152944803237915
Test set avg_accuracy=86.56% avg_sensitivity=56.60%, avg_specificity=95.25% avg_auc=90.30%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.346061 Test loss=0.316184 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.31298887729644775
[5/24] Train loss=0.35189491510391235
[10/24] Train loss=0.36360111832618713
[15/24] Train loss=0.324933260679245
[20/24] Train loss=0.3212110996246338
Test set avg_accuracy=86.52% avg_sensitivity=58.11%, avg_specificity=94.76% avg_auc=90.34%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.345988 Test loss=0.315373 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3153160810470581
[5/24] Train loss=0.3531804084777832
[10/24] Train loss=0.3640543520450592
[15/24] Train loss=0.3276160657405853
[20/24] Train loss=0.32431718707084656
Test set avg_accuracy=86.52% avg_sensitivity=57.82%, avg_specificity=94.84% avg_auc=90.35%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.346428 Test loss=0.315050 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.31589803099632263
[5/24] Train loss=0.35268867015838623
[10/24] Train loss=0.36443856358528137
[15/24] Train loss=0.3250298500061035
[20/24] Train loss=0.32066842913627625
Test set avg_accuracy=86.54% avg_sensitivity=57.82%, avg_specificity=94.86% avg_auc=90.35%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.345298 Test loss=0.315051 Current lr=[0.000134135431043539]

[0/24] Train loss=0.31215548515319824
[5/24] Train loss=0.3511298894882202
[10/24] Train loss=0.3573547601699829
[15/24] Train loss=0.3246362805366516
[20/24] Train loss=0.32275065779685974
Test set avg_accuracy=86.51% avg_sensitivity=58.40%, avg_specificity=94.66% avg_auc=90.33%
Best model saved!! Metric=3.9032047900584033!!
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.344889 Test loss=0.314992 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3185117244720459
[5/24] Train loss=0.3507029712200165
[10/24] Train loss=0.3623960614204407
[15/24] Train loss=0.3255326747894287
[20/24] Train loss=0.3240382671356201
Test set avg_accuracy=86.56% avg_sensitivity=57.88%, avg_specificity=94.88% avg_auc=90.35%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.345857 Test loss=0.315019 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3170965313911438
[5/24] Train loss=0.35114747285842896
[10/24] Train loss=0.3626975119113922
[15/24] Train loss=0.3295149803161621
[20/24] Train loss=0.3162512481212616
Test set avg_accuracy=86.77% avg_sensitivity=58.69%, avg_specificity=94.91% avg_auc=90.43%
Best model saved!! Metric=4.805866696494931!!
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.346107 Test loss=0.313494 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.31625789403915405
[5/24] Train loss=0.35069540143013
[10/24] Train loss=0.3619879484176636
[15/24] Train loss=0.3296129107475281
[20/24] Train loss=0.3202260732650757
Test set avg_accuracy=86.74% avg_sensitivity=59.15%, avg_specificity=94.74% avg_auc=90.42%
Best model saved!! Metric=5.064753786448648!!
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.345739 Test loss=0.313337 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.31573978066444397
[5/24] Train loss=0.35484546422958374
[10/24] Train loss=0.36126571893692017
[15/24] Train loss=0.3309271037578583
[20/24] Train loss=0.32680583000183105
Test set avg_accuracy=86.67% avg_sensitivity=60.72%, avg_specificity=94.19% avg_auc=90.36%
Best model saved!! Metric=5.935706906029807!!
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.346296 Test loss=0.313765 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.31742650270462036
[5/24] Train loss=0.35891807079315186
[10/24] Train loss=0.3685747981071472
[15/24] Train loss=0.32662642002105713
[20/24] Train loss=0.3206833600997925
Test set avg_accuracy=86.68% avg_sensitivity=60.78%, avg_specificity=94.19% avg_auc=90.44%
Best model saved!! Metric=6.08671106537237!!
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.346738 Test loss=0.312881 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.31483492255210876
[5/24] Train loss=0.36387133598327637
[10/24] Train loss=0.3742755949497223
[15/24] Train loss=0.3261178135871887
[20/24] Train loss=0.3212429881095886
Test set avg_accuracy=86.61% avg_sensitivity=62.51%, avg_specificity=93.60% avg_auc=90.51%
Best model saved!! Metric=7.241718133895851!!
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.347136 Test loss=0.312897 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3145163953304291
[5/24] Train loss=0.37041980028152466
[10/24] Train loss=0.3810185492038727
[15/24] Train loss=0.33183616399765015
[20/24] Train loss=0.32238078117370605
Test set avg_accuracy=86.02% avg_sensitivity=66.22%, avg_specificity=91.75% avg_auc=90.52%
Best model saved!! Metric=8.51037579510701!!
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.349796 Test loss=0.317278 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.32110363245010376
[5/24] Train loss=0.37125876545906067
[10/24] Train loss=0.38408592343330383
[15/24] Train loss=0.32547229528427124
[20/24] Train loss=0.32605764269828796
Test set avg_accuracy=85.56% avg_sensitivity=68.54%, avg_specificity=90.49% avg_auc=90.33%
Best model saved!! Metric=8.919810840275318!!
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.350665 Test loss=0.325631 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.33088600635528564
[5/24] Train loss=0.37310969829559326
[10/24] Train loss=0.37007632851600647
[15/24] Train loss=0.3318982422351837
[20/24] Train loss=0.3464961647987366
Test set avg_accuracy=86.24% avg_sensitivity=64.48%, avg_specificity=92.54% avg_auc=90.47%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.352215 Test loss=0.316227 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.31846290826797485
[5/24] Train loss=0.3544039726257324
[10/24] Train loss=0.3635440468788147
[15/24] Train loss=0.330836683511734
[20/24] Train loss=0.33243146538734436
Test set avg_accuracy=86.72% avg_sensitivity=61.24%, avg_specificity=94.10% avg_auc=90.50%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.346770 Test loss=0.313222 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3107830584049225
[5/24] Train loss=0.3546287715435028
[10/24] Train loss=0.361360639333725
[15/24] Train loss=0.330986887216568
[20/24] Train loss=0.33052173256874084
Test set avg_accuracy=86.45% avg_sensitivity=62.63%, avg_specificity=93.35% avg_auc=90.55%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.344494 Test loss=0.313986 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.313882976770401
[5/24] Train loss=0.34953412413597107
[10/24] Train loss=0.3633313775062561
[15/24] Train loss=0.33132848143577576
[20/24] Train loss=0.3332732021808624
Test set avg_accuracy=86.45% avg_sensitivity=62.57%, avg_specificity=93.37% avg_auc=90.53%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.346042 Test loss=0.313791 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.31862056255340576
[5/24] Train loss=0.3522167503833771
[10/24] Train loss=0.3602098226547241
[15/24] Train loss=0.3287718594074249
[20/24] Train loss=0.32780274748802185
Test set avg_accuracy=86.69% avg_sensitivity=61.82%, avg_specificity=93.90% avg_auc=90.54%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.345056 Test loss=0.313141 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3140247166156769
[5/24] Train loss=0.3566862642765045
[10/24] Train loss=0.36190328001976013
[15/24] Train loss=0.3273874521255493
[20/24] Train loss=0.32801884412765503
Test set avg_accuracy=86.58% avg_sensitivity=62.57%, avg_specificity=93.53% avg_auc=90.55%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.344113 Test loss=0.313249 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.31534144282341003
[5/24] Train loss=0.35629239678382874
[10/24] Train loss=0.36416512727737427
[15/24] Train loss=0.33133649826049805
[20/24] Train loss=0.3285638391971588
Test set avg_accuracy=86.77% avg_sensitivity=62.28%, avg_specificity=93.87% avg_auc=90.47%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.345993 Test loss=0.314119 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3171706795692444
[5/24] Train loss=0.35728520154953003
[10/24] Train loss=0.36075717210769653
[15/24] Train loss=0.3292446434497833
[20/24] Train loss=0.3300858438014984
Test set avg_accuracy=86.74% avg_sensitivity=63.27%, avg_specificity=93.55% avg_auc=90.45%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.344779 Test loss=0.314860 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.31860023736953735
[5/24] Train loss=0.36078956723213196
[10/24] Train loss=0.36146101355552673
[15/24] Train loss=0.32775577902793884
[20/24] Train loss=0.333869069814682
Test set avg_accuracy=86.84% avg_sensitivity=62.63%, avg_specificity=93.85% avg_auc=90.47%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.345883 Test loss=0.314086 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.31508949398994446
[5/24] Train loss=0.35819321870803833
[10/24] Train loss=0.3581174314022064
[15/24] Train loss=0.32875609397888184
[20/24] Train loss=0.32680216431617737
Test set avg_accuracy=86.77% avg_sensitivity=61.53%, avg_specificity=94.09% avg_auc=90.57%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.343982 Test loss=0.312380 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.31267035007476807
[5/24] Train loss=0.3491489589214325
[10/24] Train loss=0.356068879365921
[15/24] Train loss=0.3332953453063965
[20/24] Train loss=0.3242974281311035
Test set avg_accuracy=86.85% avg_sensitivity=60.02%, avg_specificity=94.63% avg_auc=90.57%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.343082 Test loss=0.312159 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.31468358635902405
[5/24] Train loss=0.3502180874347687
[10/24] Train loss=0.35776934027671814
[15/24] Train loss=0.32894986867904663
[20/24] Train loss=0.3317929804325104
Test set avg_accuracy=86.81% avg_sensitivity=60.66%, avg_specificity=94.39% avg_auc=90.58%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.342763 Test loss=0.311931 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3172735273838043
[5/24] Train loss=0.3515394330024719
[10/24] Train loss=0.3594115674495697
[15/24] Train loss=0.3259994685649872
[20/24] Train loss=0.3199940025806427
Test set avg_accuracy=86.91% avg_sensitivity=60.20%, avg_specificity=94.66% avg_auc=90.57%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.342090 Test loss=0.311969 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.31314510107040405
[5/24] Train loss=0.3482968509197235
[10/24] Train loss=0.3577008843421936
[15/24] Train loss=0.32676857709884644
[20/24] Train loss=0.32726913690567017
Test set avg_accuracy=86.94% avg_sensitivity=59.73%, avg_specificity=94.83% avg_auc=90.60%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.341630 Test loss=0.311691 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3113726079463959
[5/24] Train loss=0.3490486741065979
[10/24] Train loss=0.35755854845046997
[15/24] Train loss=0.3329959511756897
[20/24] Train loss=0.3277832269668579
Test set avg_accuracy=86.88% avg_sensitivity=58.17%, avg_specificity=95.20% avg_auc=90.58%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.342221 Test loss=0.311985 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3134990632534027
[5/24] Train loss=0.353999525308609
[10/24] Train loss=0.35798248648643494
[15/24] Train loss=0.328622967004776
[20/24] Train loss=0.32646068930625916
Test set avg_accuracy=86.88% avg_sensitivity=57.94%, avg_specificity=95.26% avg_auc=90.60%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.341374 Test loss=0.311900 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3117038905620575
[5/24] Train loss=0.35345014929771423
[10/24] Train loss=0.3604332208633423
[15/24] Train loss=0.3294907212257385
[20/24] Train loss=0.32473024725914
Test set avg_accuracy=86.86% avg_sensitivity=57.82%, avg_specificity=95.28% avg_auc=90.60%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.342329 Test loss=0.311893 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3106367886066437
[5/24] Train loss=0.34961801767349243
[10/24] Train loss=0.35642027854919434
[15/24] Train loss=0.33025220036506653
[20/24] Train loss=0.32457029819488525
Test set avg_accuracy=86.76% avg_sensitivity=57.01%, avg_specificity=95.38% avg_auc=90.58%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.341370 Test loss=0.312332 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3096775710582733
[5/24] Train loss=0.3565172255039215
[10/24] Train loss=0.35785016417503357
[15/24] Train loss=0.3339605927467346
[20/24] Train loss=0.32509273290634155
Test set avg_accuracy=86.71% avg_sensitivity=56.32%, avg_specificity=95.52% avg_auc=90.61%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.341399 Test loss=0.312372 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.31587517261505127
[5/24] Train loss=0.3526303470134735
[10/24] Train loss=0.3588264584541321
[15/24] Train loss=0.3288527727127075
[20/24] Train loss=0.323341429233551
Test set avg_accuracy=86.65% avg_sensitivity=55.79%, avg_specificity=95.60% avg_auc=90.59%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.341177 Test loss=0.312634 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.31110137701034546
[5/24] Train loss=0.35494810342788696
[10/24] Train loss=0.3582872152328491
[15/24] Train loss=0.33248060941696167
[20/24] Train loss=0.32136133313179016
Test set avg_accuracy=86.67% avg_sensitivity=55.79%, avg_specificity=95.62% avg_auc=90.59%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.342121 Test loss=0.312737 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.30975624918937683
[5/24] Train loss=0.35047951340675354
[10/24] Train loss=0.35801875591278076
[15/24] Train loss=0.33242934942245483
[20/24] Train loss=0.3172377347946167
Test set avg_accuracy=86.77% avg_sensitivity=57.07%, avg_specificity=95.38% avg_auc=90.61%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.340860 Test loss=0.311929 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3110409677028656
[5/24] Train loss=0.354071706533432
[10/24] Train loss=0.3563382029533386
[15/24] Train loss=0.33025264739990234
[20/24] Train loss=0.3177044987678528
Test set avg_accuracy=86.91% avg_sensitivity=59.27%, avg_specificity=94.93% avg_auc=90.66%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.341722 Test loss=0.310785 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.30994078516960144
[5/24] Train loss=0.3575080931186676
[10/24] Train loss=0.356442928314209
[15/24] Train loss=0.3259676992893219
[20/24] Train loss=0.31597989797592163
Test set avg_accuracy=86.86% avg_sensitivity=61.36%, avg_specificity=94.26% avg_auc=90.67%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.341970 Test loss=0.310725 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.3160240948200226
[5/24] Train loss=0.35429874062538147
[10/24] Train loss=0.35736149549484253
[15/24] Train loss=0.32762178778648376
[20/24] Train loss=0.31650182604789734
Test set avg_accuracy=86.93% avg_sensitivity=61.99%, avg_specificity=94.16% avg_auc=90.68%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.341772 Test loss=0.310636 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.3114210069179535
[5/24] Train loss=0.34946832060813904
[10/24] Train loss=0.3500889241695404
[15/24] Train loss=0.32685935497283936
[20/24] Train loss=0.31747761368751526
Test set avg_accuracy=86.81% avg_sensitivity=61.30%, avg_specificity=94.21% avg_auc=90.68%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.340857 Test loss=0.310579 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3148268461227417
[5/24] Train loss=0.3518986701965332
[10/24] Train loss=0.3503606915473938
[15/24] Train loss=0.32462531328201294
[20/24] Train loss=0.3194800317287445
Test set avg_accuracy=86.89% avg_sensitivity=61.01%, avg_specificity=94.39% avg_auc=90.68%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.341319 Test loss=0.310442 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.3134668469429016
[5/24] Train loss=0.34802553057670593
[10/24] Train loss=0.35549071431159973
[15/24] Train loss=0.3248180150985718
[20/24] Train loss=0.3221263289451599
Test set avg_accuracy=86.88% avg_sensitivity=60.89%, avg_specificity=94.41% avg_auc=90.69%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.340035 Test loss=0.310234 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.31178373098373413
[5/24] Train loss=0.34992632269859314
[10/24] Train loss=0.3558961749076843
[15/24] Train loss=0.3222285211086273
[20/24] Train loss=0.3183733820915222
Test set avg_accuracy=86.89% avg_sensitivity=60.60%, avg_specificity=94.51% avg_auc=90.68%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.339893 Test loss=0.310404 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3112204074859619
[5/24] Train loss=0.34808364510536194
[10/24] Train loss=0.3552659749984741
[15/24] Train loss=0.3248414397239685
[20/24] Train loss=0.31683585047721863
Test set avg_accuracy=86.98% avg_sensitivity=60.37%, avg_specificity=94.69% avg_auc=90.68%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.340027 Test loss=0.310384 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.31247103214263916
[5/24] Train loss=0.345927894115448
[10/24] Train loss=0.35303783416748047
[15/24] Train loss=0.3247290849685669
[20/24] Train loss=0.32019343972206116
Test set avg_accuracy=86.88% avg_sensitivity=60.49%, avg_specificity=94.52% avg_auc=90.69%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.339543 Test loss=0.310303 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3115040063858032
[5/24] Train loss=0.34360483288764954
[10/24] Train loss=0.3567347526550293
[15/24] Train loss=0.3264590799808502
[20/24] Train loss=0.3153308928012848
Test set avg_accuracy=86.93% avg_sensitivity=60.49%, avg_specificity=94.59% avg_auc=90.68%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.338929 Test loss=0.310343 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.312982976436615
[5/24] Train loss=0.3501126170158386
[10/24] Train loss=0.3538023829460144
[15/24] Train loss=0.32591527700424194
[20/24] Train loss=0.31965482234954834
Test set avg_accuracy=86.93% avg_sensitivity=60.31%, avg_specificity=94.64% avg_auc=90.68%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.340079 Test loss=0.310373 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3104855418205261
[5/24] Train loss=0.3491193652153015
[10/24] Train loss=0.35357585549354553
[15/24] Train loss=0.32399871945381165
[20/24] Train loss=0.31991660594940186
Test set avg_accuracy=86.90% avg_sensitivity=60.31%, avg_specificity=94.61% avg_auc=90.68%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.339670 Test loss=0.310386 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.312460333108902
[5/24] Train loss=0.34345048666000366
[10/24] Train loss=0.3528478741645813
[15/24] Train loss=0.3198109567165375
[20/24] Train loss=0.31790849566459656
Test set avg_accuracy=86.93% avg_sensitivity=60.31%, avg_specificity=94.64% avg_auc=90.68%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.339286 Test loss=0.310354 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3093934953212738
[5/24] Train loss=0.35271573066711426
[10/24] Train loss=0.3568584620952606
[15/24] Train loss=0.3272929787635803
[20/24] Train loss=0.31788745522499084
Test set avg_accuracy=86.97% avg_sensitivity=60.20%, avg_specificity=94.73% avg_auc=90.68%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.340141 Test loss=0.310369 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.3118177056312561
[5/24] Train loss=0.34901532530784607
[10/24] Train loss=0.3587353825569153
[15/24] Train loss=0.32274654507637024
[20/24] Train loss=0.3191829323768616
Test set avg_accuracy=86.94% avg_sensitivity=60.14%, avg_specificity=94.71% avg_auc=90.68%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.339338 Test loss=0.310372 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.30767470598220825
[5/24] Train loss=0.3488672077655792
[10/24] Train loss=0.356195330619812
[15/24] Train loss=0.32461902499198914
[20/24] Train loss=0.31844156980514526
Test set avg_accuracy=86.94% avg_sensitivity=60.14%, avg_specificity=94.71% avg_auc=90.68%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.339623 Test loss=0.310373 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3145415782928467
[5/24] Train loss=0.3465505838394165
[10/24] Train loss=0.35491353273391724
[15/24] Train loss=0.32576534152030945
[20/24] Train loss=0.3178972899913788
Test set avg_accuracy=86.95% avg_sensitivity=60.14%, avg_specificity=94.73% avg_auc=90.68%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.338797 Test loss=0.310376 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.31438180804252625
[5/24] Train loss=0.34949010610580444
[10/24] Train loss=0.3567812442779541
[15/24] Train loss=0.326726496219635
[20/24] Train loss=0.31453853845596313
Test set avg_accuracy=86.95% avg_sensitivity=60.14%, avg_specificity=94.73% avg_auc=90.68%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.339350 Test loss=0.310377 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=85.56% sen=68.54%, spe=90.49%, auc=90.33%!
Fold[10] Avg_overlap=0.63%(±0.2691049856741696)
Final Avg Result: avg_acc=85.02%(±1.2628671990369953) avg_sen=73.60% (±2.2030495655527944) avg_spe=88.94% (±1.698235225642281) avg_auc=90.63% (±1.230624261459359) avg_overlap=0.65% (±0.02215578150744214)
