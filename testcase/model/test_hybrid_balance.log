[0/24] Train loss=2.007472515106201
[5/24] Train loss=1.6538697481155396
[10/24] Train loss=1.5392929315567017
[15/24] Train loss=1.4859271049499512
[20/24] Train loss=1.449851393699646
Test set avg_accuracy=49.45% avg_sensitivity=55.02%, avg_specificity=47.46% avg_auc=53.45%
Best model saved!! Metric=-120.6130850778021!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=1.576450 Test loss=0.703377 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.4520037174224854
[5/24] Train loss=1.435242772102356
[10/24] Train loss=1.4393388032913208
[15/24] Train loss=1.4233081340789795
[20/24] Train loss=1.413125991821289
Test set avg_accuracy=54.53% avg_sensitivity=61.65%, avg_specificity=51.99% avg_auc=58.77%
Best model saved!! Metric=-99.0553191560404!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=1.432587 Test loss=0.688061 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.4058597087860107
[5/24] Train loss=1.4008638858795166
[10/24] Train loss=1.4098565578460693
[15/24] Train loss=1.3997751474380493
[20/24] Train loss=1.3727447986602783
Test set avg_accuracy=59.01% avg_sensitivity=62.74%, avg_specificity=57.68% avg_auc=63.36%
Best model saved!! Metric=-83.21108911827969!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=1.399872 Test loss=0.677353 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.3904948234558105
[5/24] Train loss=1.3792309761047363
[10/24] Train loss=1.3689749240875244
[15/24] Train loss=1.3726763725280762
[20/24] Train loss=1.3564587831497192
Test set avg_accuracy=59.31% avg_sensitivity=67.74%, avg_specificity=56.30% avg_auc=67.03%
Best model saved!! Metric=-75.62637580605934!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=1.377117 Test loss=0.673985 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.353188157081604
[5/24] Train loss=1.3623132705688477
[10/24] Train loss=1.3692247867584229
[15/24] Train loss=1.3613834381103516
[20/24] Train loss=1.3599656820297241
Test set avg_accuracy=64.48% avg_sensitivity=67.84%, avg_specificity=63.28% avg_auc=70.45%
Best model saved!! Metric=-59.9581506725037!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=1.357944 Test loss=0.663313 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.3404496908187866
[5/24] Train loss=1.3384160995483398
[10/24] Train loss=1.3470113277435303
[15/24] Train loss=1.334174633026123
[20/24] Train loss=1.3061403036117554
Test set avg_accuracy=64.22% avg_sensitivity=72.49%, avg_specificity=61.27% avg_auc=72.49%
Best model saved!! Metric=-55.53603224359021!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=1.337094 Test loss=0.656777 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.3203643560409546
[5/24] Train loss=1.3075989484786987
[10/24] Train loss=1.3260176181793213
[15/24] Train loss=1.3044532537460327
[20/24] Train loss=1.2795814275741577
Test set avg_accuracy=68.76% avg_sensitivity=76.69%, avg_specificity=65.93% avg_auc=76.51%
Best model saved!! Metric=-38.099121232319604!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=1.311282 Test loss=0.641854 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.2867152690887451
[5/24] Train loss=1.2631202936172485
[10/24] Train loss=1.288643717765808
[15/24] Train loss=1.260817527770996
[20/24] Train loss=1.2513837814331055
Test set avg_accuracy=72.55% avg_sensitivity=75.41%, avg_specificity=71.53% avg_auc=78.76%
Best model saved!! Metric=-27.749880697112502!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=1.275378 Test loss=0.616924 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.2410950660705566
[5/24] Train loss=1.2335549592971802
[10/24] Train loss=1.256306529045105
[15/24] Train loss=1.2248090505599976
[20/24] Train loss=1.2030144929885864
Test set avg_accuracy=74.22% avg_sensitivity=75.80%, avg_specificity=73.65% avg_auc=80.48%
Best model saved!! Metric=-21.840796173553727!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=1.233731 Test loss=0.593523 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.188694953918457
[5/24] Train loss=1.168818473815918
[10/24] Train loss=1.2220853567123413
[15/24] Train loss=1.1695901155471802
[20/24] Train loss=1.144926905632019
Test set avg_accuracy=74.56% avg_sensitivity=79.17%, avg_specificity=72.91% avg_auc=81.81%
Best model saved!! Metric=-17.551158404196457!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=1.186857 Test loss=0.580203 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.141883373260498
[5/24] Train loss=1.115051031112671
[10/24] Train loss=1.1665070056915283
[15/24] Train loss=1.118580937385559
[20/24] Train loss=1.0983363389968872
Test set avg_accuracy=75.25% avg_sensitivity=80.55%, avg_specificity=73.35% avg_auc=82.80%
Best model saved!! Metric=-14.048651264995172!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=1.142127 Test loss=0.557923 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.0817832946777344
[5/24] Train loss=1.0829100608825684
[10/24] Train loss=1.142175555229187
[15/24] Train loss=1.0835671424865723
[20/24] Train loss=1.043148398399353
Test set avg_accuracy=75.07% avg_sensitivity=83.23%, avg_specificity=72.15% avg_auc=83.83%
Best model saved!! Metric=-11.729784176170028!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=1.100177 Test loss=0.547550 Current lr=[5.97283087248885e-05]

[0/24] Train loss=1.0479649305343628
[5/24] Train loss=1.0350302457809448
[10/24] Train loss=1.097400426864624
[15/24] Train loss=1.0452393293380737
[20/24] Train loss=1.018930435180664
Test set avg_accuracy=75.73% avg_sensitivity=83.77%, avg_specificity=72.86% avg_auc=84.59%
Best model saved!! Metric=-9.05508744410642!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=1.061590 Test loss=0.526129 Current lr=[6.744022406141468e-05]

[0/24] Train loss=1.0051212310791016
[5/24] Train loss=1.0153768062591553
[10/24] Train loss=1.0652453899383545
[15/24] Train loss=1.012507438659668
[20/24] Train loss=0.9795875549316406
Test set avg_accuracy=76.88% avg_sensitivity=82.68%, avg_specificity=74.80% avg_auc=85.31%
Best model saved!! Metric=-6.32855948002765!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=1.033467 Test loss=0.498871 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.967042863368988
[5/24] Train loss=0.9748430252075195
[10/24] Train loss=1.0595470666885376
[15/24] Train loss=0.9784154295921326
[20/24] Train loss=0.9535149335861206
Test set avg_accuracy=75.95% avg_sensitivity=86.19%, avg_specificity=72.29% avg_auc=86.04%
Best model saved!! Metric=-5.525393446827479!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=1.007354 Test loss=0.505225 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.9607682824134827
[5/24] Train loss=0.9645770192146301
[10/24] Train loss=1.024503469467163
[15/24] Train loss=0.9693487286567688
[20/24] Train loss=0.9324468374252319
Test set avg_accuracy=76.20% avg_sensitivity=86.69%, avg_specificity=72.45% avg_auc=86.75%
Best model saved!! Metric=-3.9157899265624536!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.984459 Test loss=0.496101 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.9434987902641296
[5/24] Train loss=0.9269784092903137
[10/24] Train loss=1.014255404472351
[15/24] Train loss=0.9400716423988342
[20/24] Train loss=0.9163829684257507
Test set avg_accuracy=76.90% avg_sensitivity=85.40%, avg_specificity=73.86% avg_auc=87.31%
Best model saved!! Metric=-2.5189811210983493!!
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.963712 Test loss=0.477912 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.9090518355369568
[5/24] Train loss=0.9178105592727661
[10/24] Train loss=0.9831221103668213
[15/24] Train loss=0.9132465720176697
[20/24] Train loss=0.8851321339607239
Test set avg_accuracy=79.45% avg_sensitivity=83.77%, avg_specificity=77.91% avg_auc=88.42%
Best model saved!! Metric=3.5572140756615482!!
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.939790 Test loss=0.436628 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.8724806308746338
[5/24] Train loss=0.8953596949577332
[10/24] Train loss=0.9469907879829407
[15/24] Train loss=0.9027994871139526
[20/24] Train loss=0.8476070761680603
Test set avg_accuracy=79.95% avg_sensitivity=81.59%, avg_specificity=79.36% avg_auc=88.95%
Best model saved!! Metric=3.8561561723552558!!
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.910006 Test loss=0.415822 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.8433833122253418
[5/24] Train loss=0.8568360805511475
[10/24] Train loss=0.9094886183738708
[15/24] Train loss=0.8665737509727478
[20/24] Train loss=0.8451829552650452
Test set avg_accuracy=79.30% avg_sensitivity=84.91%, avg_specificity=77.29% avg_auc=89.37%
Best model saved!! Metric=4.867064105573689!!
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.886419 Test loss=0.429825 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.8289667963981628
[5/24] Train loss=0.858001172542572
[10/24] Train loss=0.8966702222824097
[15/24] Train loss=0.8576955795288086
[20/24] Train loss=0.8292657732963562
Test set avg_accuracy=79.71% avg_sensitivity=85.25%, avg_specificity=77.73% avg_auc=89.57%
Best model saved!! Metric=6.271376921670296!!
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.872202 Test loss=0.424359 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.8071171045303345
[5/24] Train loss=0.8538085222244263
[10/24] Train loss=0.8703079223632812
[15/24] Train loss=0.8297049403190613
[20/24] Train loss=0.8203901052474976
Test set avg_accuracy=79.96% avg_sensitivity=84.86%, avg_specificity=78.21% avg_auc=89.72%
Best model saved!! Metric=6.755070564214677!!
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.859576 Test loss=0.422242 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.8031663298606873
[5/24] Train loss=0.8466216921806335
[10/24] Train loss=0.8546541929244995
[15/24] Train loss=0.823042631149292
[20/24] Train loss=0.822468638420105
Test set avg_accuracy=80.18% avg_sensitivity=83.33%, avg_specificity=79.06% avg_auc=89.96%
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.851589 Test loss=0.408084 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.7737817168235779
[5/24] Train loss=0.834033727645874
[10/24] Train loss=0.8759790062904358
[15/24] Train loss=0.7997642755508423
[20/24] Train loss=0.7916151881217957
Test set avg_accuracy=81.32% avg_sensitivity=81.44%, avg_specificity=81.27% avg_auc=90.15%
Best model saved!! Metric=8.174875996977477!!
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.840235 Test loss=0.391952 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.7752416133880615
[5/24] Train loss=0.8261159658432007
[10/24] Train loss=0.850242018699646
[15/24] Train loss=0.8108351826667786
[20/24] Train loss=0.7688131332397461
Test set avg_accuracy=81.65% avg_sensitivity=80.21%, avg_specificity=82.17% avg_auc=90.20%
Best model saved!! Metric=8.230341194700245!!
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.831936 Test loss=0.384804 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.7672686576843262
[5/24] Train loss=0.8184994459152222
[10/24] Train loss=0.8382754325866699
[15/24] Train loss=0.8128023743629456
[20/24] Train loss=0.7651960253715515
Test set avg_accuracy=82.08% avg_sensitivity=77.93%, avg_specificity=83.57% avg_auc=90.31%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.824443 Test loss=0.373724 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.7459003925323486
[5/24] Train loss=0.8609525561332703
[10/24] Train loss=0.8406834006309509
[15/24] Train loss=0.8092905282974243
[20/24] Train loss=0.7720206379890442
Test set avg_accuracy=81.28% avg_sensitivity=81.99%, avg_specificity=81.02% avg_auc=90.51%
Best model saved!! Metric=8.79896876216921!!
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.817726 Test loss=0.388542 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.7438309192657471
[5/24] Train loss=0.8254624009132385
[10/24] Train loss=0.8366535902023315
[15/24] Train loss=0.7797068953514099
[20/24] Train loss=0.7595338821411133
Test set avg_accuracy=82.20% avg_sensitivity=79.66%, avg_specificity=83.11% avg_auc=90.50%
Best model saved!! Metric=9.473466268693556!!
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.806932 Test loss=0.374781 Current lr=[0.000210185142098938]

[0/24] Train loss=0.7394905090332031
[5/24] Train loss=0.8220920562744141
[10/24] Train loss=0.8422603607177734
[15/24] Train loss=0.7912178039550781
[20/24] Train loss=0.7414093613624573
Test set avg_accuracy=82.20% avg_sensitivity=79.37%, avg_specificity=83.21% avg_auc=90.62%
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.805296 Test loss=0.371682 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.7393598556518555
[5/24] Train loss=0.8291621208190918
[10/24] Train loss=0.8438582420349121
[15/24] Train loss=0.7696352005004883
[20/24] Train loss=0.7732100486755371
Test set avg_accuracy=82.20% avg_sensitivity=78.62%, avg_specificity=83.48% avg_auc=90.69%
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.803698 Test loss=0.367507 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.7406432628631592
[5/24] Train loss=0.8167746663093567
[10/24] Train loss=0.8334140181541443
[15/24] Train loss=0.7623056173324585
[20/24] Train loss=0.7358964085578918
Test set avg_accuracy=81.99% avg_sensitivity=80.46%, avg_specificity=82.54% avg_auc=90.51%
Best model saved!! Metric=9.493736310820907!!
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.795516 Test loss=0.375328 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.7276380062103271
[5/24] Train loss=0.8464460372924805
[10/24] Train loss=0.8356815576553345
[15/24] Train loss=0.775137186050415
[20/24] Train loss=0.7338364124298096
Test set avg_accuracy=82.36% avg_sensitivity=79.96%, avg_specificity=83.21% avg_auc=90.76%
Best model saved!! Metric=10.287782715200365!!
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.789142 Test loss=0.368663 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.7227066159248352
[5/24] Train loss=0.8429788947105408
[10/24] Train loss=0.8252566456794739
[15/24] Train loss=0.7773763537406921
[20/24] Train loss=0.7282552123069763
Test set avg_accuracy=81.97% avg_sensitivity=81.10%, avg_specificity=82.28% avg_auc=90.73%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.784502 Test loss=0.376286 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.7225830554962158
[5/24] Train loss=0.8141307830810547
[10/24] Train loss=0.8279318809509277
[15/24] Train loss=0.7629172205924988
[20/24] Train loss=0.7255717515945435
Test set avg_accuracy=82.37% avg_sensitivity=79.47%, avg_specificity=83.41% avg_auc=90.89%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.781133 Test loss=0.366052 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.7138522267341614
[5/24] Train loss=0.8371201157569885
[10/24] Train loss=0.8270583152770996
[15/24] Train loss=0.7665648460388184
[20/24] Train loss=0.7273923754692078
Test set avg_accuracy=82.20% avg_sensitivity=80.55%, avg_specificity=82.79% avg_auc=90.84%
Best model saved!! Metric=10.38311446781573!!
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.775469 Test loss=0.369937 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.7065368294715881
[5/24] Train loss=0.8347067832946777
[10/24] Train loss=0.8128108382225037
[15/24] Train loss=0.7649202346801758
[20/24] Train loss=0.7123876214027405
Test set avg_accuracy=82.02% avg_sensitivity=83.33%, avg_specificity=81.55% avg_auc=91.04%
Best model saved!! Metric=11.934885858257772!!
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.773665 Test loss=0.379053 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.6923708915710449
[5/24] Train loss=0.8077924251556396
[10/24] Train loss=0.8240797519683838
[15/24] Train loss=0.7550451159477234
[20/24] Train loss=0.7004979848861694
Test set avg_accuracy=82.50% avg_sensitivity=81.40%, avg_specificity=82.89% avg_auc=90.96%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.764801 Test loss=0.368516 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.6970211267471313
[5/24] Train loss=0.8170119524002075
[10/24] Train loss=0.8269892334938049
[15/24] Train loss=0.7538769841194153
[20/24] Train loss=0.7219483256340027
Test set avg_accuracy=82.66% avg_sensitivity=81.54%, avg_specificity=83.05% avg_auc=91.17%
Best model saved!! Metric=12.420119719596485!!
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.765985 Test loss=0.367170 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.6997391581535339
[5/24] Train loss=0.8183552622795105
[10/24] Train loss=0.8182727694511414
[15/24] Train loss=0.7459682822227478
[20/24] Train loss=0.7209084630012512
Test set avg_accuracy=82.25% avg_sensitivity=81.30%, avg_specificity=82.59% avg_auc=90.89%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.761182 Test loss=0.370812 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.6986761093139648
[5/24] Train loss=0.8285356760025024
[10/24] Train loss=0.8262647390365601
[15/24] Train loss=0.749741792678833
[20/24] Train loss=0.6973535418510437
Test set avg_accuracy=82.59% avg_sensitivity=81.59%, avg_specificity=82.95% avg_auc=91.17%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.759667 Test loss=0.366840 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.6888021230697632
[5/24] Train loss=0.8148688673973083
[10/24] Train loss=0.8142021894454956
[15/24] Train loss=0.7452322840690613
[20/24] Train loss=0.6945205926895142
Test set avg_accuracy=81.91% avg_sensitivity=82.78%, avg_specificity=81.60% avg_auc=90.91%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.754276 Test loss=0.376939 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.6948560476303101
[5/24] Train loss=0.8082265257835388
[10/24] Train loss=0.8111728429794312
[15/24] Train loss=0.7425628304481506
[20/24] Train loss=0.6960318684577942
Test set avg_accuracy=82.21% avg_sensitivity=82.29%, avg_specificity=82.19% avg_auc=91.03%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.753106 Test loss=0.373204 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.6816006898880005
[5/24] Train loss=0.7983713746070862
[10/24] Train loss=0.8029789328575134
[15/24] Train loss=0.7427812814712524
[20/24] Train loss=0.6861822009086609
Test set avg_accuracy=82.45% avg_sensitivity=81.99%, avg_specificity=82.61% avg_auc=91.21%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.746171 Test loss=0.368128 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.6804702281951904
[5/24] Train loss=0.8059969544410706
[10/24] Train loss=0.8173060417175293
[15/24] Train loss=0.7352041006088257
[20/24] Train loss=0.6893670558929443
Test set avg_accuracy=82.47% avg_sensitivity=82.53%, avg_specificity=82.45% avg_auc=91.20%
Best model saved!! Metric=12.664668021561013!!
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.745536 Test loss=0.370308 Current lr=[0.00029967723776099]

[0/24] Train loss=0.677130401134491
[5/24] Train loss=0.7955427169799805
[10/24] Train loss=0.8049863576889038
[15/24] Train loss=0.7351341843605042
[20/24] Train loss=0.6853857040405273
Test set avg_accuracy=82.45% avg_sensitivity=82.93%, avg_specificity=82.28% avg_auc=91.34%
Best model saved!! Metric=12.992377946571025!!
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.742293 Test loss=0.370680 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.6747661828994751
[5/24] Train loss=0.7943780422210693
[10/24] Train loss=0.7978246808052063
[15/24] Train loss=0.7280252575874329
[20/24] Train loss=0.6926729083061218
Test set avg_accuracy=82.96% avg_sensitivity=82.73%, avg_specificity=83.04% avg_auc=91.56%
Best model saved!! Metric=14.286692730987198!!
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.737898 Test loss=0.366297 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.6810522675514221
[5/24] Train loss=0.8124475479125977
[10/24] Train loss=0.797245979309082
[15/24] Train loss=0.7443849444389343
[20/24] Train loss=0.6812039017677307
Test set avg_accuracy=82.96% avg_sensitivity=82.09%, avg_specificity=83.27% avg_auc=91.55%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.738215 Test loss=0.362325 Current lr=[0.000299720220882401]

[0/24] Train loss=0.6799501776695251
[5/24] Train loss=0.7813227772712708
[10/24] Train loss=0.7932500243186951
[15/24] Train loss=0.7187373042106628
[20/24] Train loss=0.6634534001350403
Test set avg_accuracy=82.72% avg_sensitivity=83.18%, avg_specificity=82.56% avg_auc=91.55%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.732683 Test loss=0.368560 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.6624414920806885
[5/24] Train loss=0.7990912795066833
[10/24] Train loss=0.803199827671051
[15/24] Train loss=0.7471986413002014
[20/24] Train loss=0.6770636439323425
Test set avg_accuracy=82.77% avg_sensitivity=83.77%, avg_specificity=82.42% avg_auc=91.65%
Best model saved!! Metric=14.608473911721816!!
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.732466 Test loss=0.367499 Current lr=[0.000298904600941902]

[0/24] Train loss=0.6614115238189697
[5/24] Train loss=0.7744651436805725
[10/24] Train loss=0.8078340888023376
[15/24] Train loss=0.721468448638916
[20/24] Train loss=0.6558409929275513
Test set avg_accuracy=82.84% avg_sensitivity=84.66%, avg_specificity=82.19% avg_auc=91.78%
Best model saved!! Metric=15.468185749266752!!
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.726484 Test loss=0.368504 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.6649848222732544
[5/24] Train loss=0.7795659899711609
[10/24] Train loss=0.8053609132766724
[15/24] Train loss=0.7156837582588196
[20/24] Train loss=0.6623014807701111
Test set avg_accuracy=82.89% avg_sensitivity=83.23%, avg_specificity=82.77% avg_auc=91.67%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.722639 Test loss=0.365466 Current lr=[0.000297555943323901]

[0/24] Train loss=0.6565358638763428
[5/24] Train loss=0.8043653964996338
[10/24] Train loss=0.7873387932777405
[15/24] Train loss=0.7144034504890442
[20/24] Train loss=0.6676100492477417
Test set avg_accuracy=82.93% avg_sensitivity=84.56%, avg_specificity=82.35% avg_auc=91.80%
Best model saved!! Metric=15.638829073121727!!
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.722304 Test loss=0.369237 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.6602234244346619
[5/24] Train loss=0.7647948265075684
[10/24] Train loss=0.8023108243942261
[15/24] Train loss=0.7195166349411011
[20/24] Train loss=0.657478928565979
Test set avg_accuracy=83.18% avg_sensitivity=84.27%, avg_specificity=82.79% avg_auc=91.85%
Best model saved!! Metric=16.07801741135961!!
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.719754 Test loss=0.365256 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.6604464650154114
[5/24] Train loss=0.769208550453186
[10/24] Train loss=0.7870187759399414
[15/24] Train loss=0.7109256982803345
[20/24] Train loss=0.6629962921142578
Test set avg_accuracy=83.59% avg_sensitivity=83.42%, avg_specificity=83.65% avg_auc=91.89%
Best model saved!! Metric=16.56105731279858!!
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.715181 Test loss=0.358838 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.6572052836418152
[5/24] Train loss=0.7870346307754517
[10/24] Train loss=0.7861473560333252
[15/24] Train loss=0.6997544765472412
[20/24] Train loss=0.6509153246879578
Test set avg_accuracy=83.84% avg_sensitivity=82.63%, avg_specificity=84.27% avg_auc=91.92%
Best model saved!! Metric=16.66461095337219!!
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.714012 Test loss=0.353578 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.6549177169799805
[5/24] Train loss=0.7978782057762146
[10/24] Train loss=0.7973489761352539
[15/24] Train loss=0.7148493528366089
[20/24] Train loss=0.652475118637085
Test set avg_accuracy=83.98% avg_sensitivity=83.67%, avg_specificity=84.10% avg_auc=92.02%
Best model saved!! Metric=17.772910101350988!!
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.711825 Test loss=0.354727 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.6639240384101868
[5/24] Train loss=0.7654619812965393
[10/24] Train loss=0.7779831290245056
[15/24] Train loss=0.692071259021759
[20/24] Train loss=0.6489925384521484
Test set avg_accuracy=83.31% avg_sensitivity=83.42%, avg_specificity=83.27% avg_auc=91.92%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.708919 Test loss=0.360271 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.6510958671569824
[5/24] Train loss=0.7697189450263977
[10/24] Train loss=0.7959387302398682
[15/24] Train loss=0.7042077779769897
[20/24] Train loss=0.6557955741882324
Test set avg_accuracy=83.53% avg_sensitivity=84.81%, avg_specificity=83.07% avg_auc=92.10%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.706537 Test loss=0.362175 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.6519117951393127
[5/24] Train loss=0.7710974812507629
[10/24] Train loss=0.8004247546195984
[15/24] Train loss=0.6965829730033875
[20/24] Train loss=0.6389301419258118
Test set avg_accuracy=83.53% avg_sensitivity=84.86%, avg_specificity=83.05% avg_auc=92.08%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.706029 Test loss=0.362247 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.6443060636520386
[5/24] Train loss=0.7766858339309692
[10/24] Train loss=0.7711774706840515
[15/24] Train loss=0.7003356218338013
[20/24] Train loss=0.6299915909767151
Test set avg_accuracy=83.23% avg_sensitivity=84.66%, avg_specificity=82.72% avg_auc=92.09%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.701640 Test loss=0.362638 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.6453750729560852
[5/24] Train loss=0.7720231413841248
[10/24] Train loss=0.7829544544219971
[15/24] Train loss=0.7113817930221558
[20/24] Train loss=0.6378947496414185
Test set avg_accuracy=83.98% avg_sensitivity=83.67%, avg_specificity=84.10% avg_auc=92.14%
Best model saved!! Metric=17.891059005956507!!
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.700132 Test loss=0.352510 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.6521502137184143
[5/24] Train loss=0.7687562704086304
[10/24] Train loss=0.7838096022605896
[15/24] Train loss=0.6912902593612671
[20/24] Train loss=0.6292794942855835
Test set avg_accuracy=83.24% avg_sensitivity=84.81%, avg_specificity=82.68% avg_auc=92.16%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.700416 Test loss=0.361089 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.6404926776885986
[5/24] Train loss=0.7658101916313171
[10/24] Train loss=0.7860492467880249
[15/24] Train loss=0.6799987554550171
[20/24] Train loss=0.6298596858978271
Test set avg_accuracy=83.82% avg_sensitivity=84.31%, avg_specificity=83.64% avg_auc=92.19%
Best model saved!! Metric=17.953635451403628!!
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.694052 Test loss=0.357154 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.6386705636978149
[5/24] Train loss=0.7583563327789307
[10/24] Train loss=0.7797147631645203
[15/24] Train loss=0.6898671388626099
[20/24] Train loss=0.6180577874183655
Test set avg_accuracy=83.66% avg_sensitivity=84.61%, avg_specificity=83.32% avg_auc=92.13%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.692584 Test loss=0.359160 Current lr=[0.000276307469034998]

[0/24] Train loss=0.6428441405296326
[5/24] Train loss=0.773810088634491
[10/24] Train loss=0.7795339822769165
[15/24] Train loss=0.6899234056472778
[20/24] Train loss=0.6269751191139221
Test set avg_accuracy=83.29% avg_sensitivity=85.75%, avg_specificity=82.42% avg_auc=92.21%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.691496 Test loss=0.364748 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.6446796655654907
[5/24] Train loss=0.7582764625549316
[10/24] Train loss=0.78489089012146
[15/24] Train loss=0.6845558285713196
[20/24] Train loss=0.6134129166603088
Test set avg_accuracy=83.53% avg_sensitivity=85.11%, avg_specificity=82.97% avg_auc=92.25%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.691894 Test loss=0.359706 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.6304069757461548
[5/24] Train loss=0.7586112022399902
[10/24] Train loss=0.7957907915115356
[15/24] Train loss=0.6888298392295837
[20/24] Train loss=0.6071746945381165
Test set avg_accuracy=83.54% avg_sensitivity=82.73%, avg_specificity=83.83% avg_auc=92.03%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.690669 Test loss=0.351685 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.6320005059242249
[5/24] Train loss=0.7692621350288391
[10/24] Train loss=0.764010488986969
[15/24] Train loss=0.6745945811271667
[20/24] Train loss=0.6083728075027466
Test set avg_accuracy=83.84% avg_sensitivity=82.04%, avg_specificity=84.48% avg_auc=92.02%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.689770 Test loss=0.347281 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.6264626979827881
[5/24] Train loss=0.7564443349838257
[10/24] Train loss=0.7762563824653625
[15/24] Train loss=0.6708158254623413
[20/24] Train loss=0.6161521673202515
Test set avg_accuracy=83.93% avg_sensitivity=81.30%, avg_specificity=84.87% avg_auc=92.14%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.687706 Test loss=0.340390 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.6405179500579834
[5/24] Train loss=0.7526865601539612
[10/24] Train loss=0.7605237364768982
[15/24] Train loss=0.6681373119354248
[20/24] Train loss=0.6091782450675964
Test set avg_accuracy=84.13% avg_sensitivity=81.40%, avg_specificity=85.10% avg_auc=92.14%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.688540 Test loss=0.340923 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.6265562176704407
[5/24] Train loss=0.7385170459747314
[10/24] Train loss=0.7669816017150879
[15/24] Train loss=0.6606147289276123
[20/24] Train loss=0.6108861565589905
Test set avg_accuracy=84.04% avg_sensitivity=82.53%, avg_specificity=84.57% avg_auc=92.18%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.683477 Test loss=0.344173 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.6173132061958313
[5/24] Train loss=0.7270762920379639
[10/24] Train loss=0.7791417241096497
[15/24] Train loss=0.6693757772445679
[20/24] Train loss=0.6372315287590027
Test set avg_accuracy=83.40% avg_sensitivity=84.86%, avg_specificity=82.88% avg_auc=92.15%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.682524 Test loss=0.359647 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.6183001399040222
[5/24] Train loss=0.7179611921310425
[10/24] Train loss=0.7748201489448547
[15/24] Train loss=0.6635696887969971
[20/24] Train loss=0.6238674521446228
Test set avg_accuracy=83.46% avg_sensitivity=85.45%, avg_specificity=82.75% avg_auc=92.11%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.678834 Test loss=0.361202 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.6189420223236084
[5/24] Train loss=0.7322431802749634
[10/24] Train loss=0.7840321063995361
[15/24] Train loss=0.6687517166137695
[20/24] Train loss=0.6086005568504333
Test set avg_accuracy=83.54% avg_sensitivity=85.01%, avg_specificity=83.02% avg_auc=92.23%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.673431 Test loss=0.357497 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.6119111776351929
[5/24] Train loss=0.7284560203552246
[10/24] Train loss=0.7680118083953857
[15/24] Train loss=0.6768699884414673
[20/24] Train loss=0.607611894607544
Test set avg_accuracy=83.53% avg_sensitivity=84.27%, avg_specificity=83.27% avg_auc=92.23%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.673333 Test loss=0.353539 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.6127210259437561
[5/24] Train loss=0.7315265536308289
[10/24] Train loss=0.7572651505470276
[15/24] Train loss=0.6610674858093262
[20/24] Train loss=0.6032289862632751
Test set avg_accuracy=83.58% avg_sensitivity=84.31%, avg_specificity=83.32% avg_auc=92.28%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.670586 Test loss=0.353038 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.6168071031570435
[5/24] Train loss=0.7134771347045898
[10/24] Train loss=0.7570895552635193
[15/24] Train loss=0.6703277826309204
[20/24] Train loss=0.5973666310310364
Test set avg_accuracy=83.66% avg_sensitivity=84.41%, avg_specificity=83.39% avg_auc=92.35%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.666701 Test loss=0.352269 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.6270281672477722
[5/24] Train loss=0.7249486446380615
[10/24] Train loss=0.7629688382148743
[15/24] Train loss=0.6682444214820862
[20/24] Train loss=0.6172099113464355
Test set avg_accuracy=83.52% avg_sensitivity=85.16%, avg_specificity=82.93% avg_auc=92.30%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.668459 Test loss=0.357539 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.6076253652572632
[5/24] Train loss=0.7148059606552124
[10/24] Train loss=0.7731325030326843
[15/24] Train loss=0.6567671895027161
[20/24] Train loss=0.6074912548065186
Test set avg_accuracy=83.57% avg_sensitivity=85.95%, avg_specificity=82.72% avg_auc=92.32%
Best model saved!! Metric=18.55219014688339!!
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.668388 Test loss=0.360876 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.6259685754776001
[5/24] Train loss=0.7248007655143738
[10/24] Train loss=0.7577016949653625
[15/24] Train loss=0.647110641002655
[20/24] Train loss=0.6106342077255249
Test set avg_accuracy=83.63% avg_sensitivity=85.16%, avg_specificity=83.09% avg_auc=92.34%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.664890 Test loss=0.353783 Current lr=[0.000224838296036774]

[0/24] Train loss=0.6146533489227295
[5/24] Train loss=0.7246611714363098
[10/24] Train loss=0.7512578368186951
[15/24] Train loss=0.6461697220802307
[20/24] Train loss=0.5985860228538513
Test set avg_accuracy=83.68% avg_sensitivity=85.40%, avg_specificity=83.07% avg_auc=92.31%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.663158 Test loss=0.357190 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.605919599533081
[5/24] Train loss=0.7256988883018494
[10/24] Train loss=0.7568916082382202
[15/24] Train loss=0.6626888513565063
[20/24] Train loss=0.6012155413627625
Test set avg_accuracy=83.58% avg_sensitivity=85.90%, avg_specificity=82.75% avg_auc=92.44%
Best model saved!! Metric=18.67039738705519!!
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.661731 Test loss=0.358275 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.6104622483253479
[5/24] Train loss=0.7153385281562805
[10/24] Train loss=0.7550331354141235
[15/24] Train loss=0.6322871446609497
[20/24] Train loss=0.6113519072532654
Test set avg_accuracy=83.93% avg_sensitivity=84.02%, avg_specificity=83.90% avg_auc=92.36%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.660114 Test loss=0.349538 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.6172020435333252
[5/24] Train loss=0.7076578736305237
[10/24] Train loss=0.7499727010726929
[15/24] Train loss=0.648938000202179
[20/24] Train loss=0.5946781635284424
Test set avg_accuracy=83.80% avg_sensitivity=84.41%, avg_specificity=83.58% avg_auc=92.41%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.660078 Test loss=0.351150 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.6130300164222717
[5/24] Train loss=0.7278310060501099
[10/24] Train loss=0.755593478679657
[15/24] Train loss=0.6439676880836487
[20/24] Train loss=0.5867457389831543
Test set avg_accuracy=83.75% avg_sensitivity=85.21%, avg_specificity=83.23% avg_auc=92.32%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.657127 Test loss=0.356393 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.6048917174339294
[5/24] Train loss=0.6958047747612
[10/24] Train loss=0.7475898861885071
[15/24] Train loss=0.642136812210083
[20/24] Train loss=0.5910838842391968
Test set avg_accuracy=83.59% avg_sensitivity=84.86%, avg_specificity=83.14% avg_auc=92.35%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.655123 Test loss=0.356529 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.6029381155967712
[5/24] Train loss=0.7073549032211304
[10/24] Train loss=0.7498429417610168
[15/24] Train loss=0.6325361132621765
[20/24] Train loss=0.5946640372276306
Test set avg_accuracy=83.97% avg_sensitivity=83.92%, avg_specificity=83.99% avg_auc=92.31%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.652320 Test loss=0.347861 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.6053941249847412
[5/24] Train loss=0.6990560293197632
[10/24] Train loss=0.752985417842865
[15/24] Train loss=0.6321374773979187
[20/24] Train loss=0.5967037677764893
Test set avg_accuracy=83.65% avg_sensitivity=85.45%, avg_specificity=83.00% avg_auc=92.35%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.651837 Test loss=0.356853 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.5993916988372803
[5/24] Train loss=0.6960551142692566
[10/24] Train loss=0.7487134337425232
[15/24] Train loss=0.6466845870018005
[20/24] Train loss=0.584164559841156
Test set avg_accuracy=83.35% avg_sensitivity=85.30%, avg_specificity=82.65% avg_auc=92.33%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.652388 Test loss=0.360723 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.6028373837471008
[5/24] Train loss=0.7109341621398926
[10/24] Train loss=0.752103328704834
[15/24] Train loss=0.6393513679504395
[20/24] Train loss=0.592614471912384
Test set avg_accuracy=83.91% avg_sensitivity=83.62%, avg_specificity=84.01% avg_auc=92.22%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.651136 Test loss=0.347607 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.5874192714691162
[5/24] Train loss=0.7028923630714417
[10/24] Train loss=0.7460778951644897
[15/24] Train loss=0.6297802925109863
[20/24] Train loss=0.5874009728431702
Test set avg_accuracy=84.19% avg_sensitivity=83.87%, avg_specificity=84.31% avg_auc=92.34%
Best model saved!! Metric=18.70852043840887!!
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.648103 Test loss=0.346036 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.604141116142273
[5/24] Train loss=0.7057758569717407
[10/24] Train loss=0.738923966884613
[15/24] Train loss=0.6324161291122437
[20/24] Train loss=0.5734655857086182
Test set avg_accuracy=84.02% avg_sensitivity=83.52%, avg_specificity=84.20% avg_auc=92.27%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.650943 Test loss=0.346234 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.5966485142707825
[5/24] Train loss=0.6984336972236633
[10/24] Train loss=0.7448492646217346
[15/24] Train loss=0.6341516971588135
[20/24] Train loss=0.5834041833877563
Test set avg_accuracy=84.09% avg_sensitivity=83.08%, avg_specificity=84.45% avg_auc=92.27%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.650313 Test loss=0.345102 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.590649425983429
[5/24] Train loss=0.7051154375076294
[10/24] Train loss=0.7491713762283325
[15/24] Train loss=0.6257767677307129
[20/24] Train loss=0.5778483152389526
Test set avg_accuracy=83.39% avg_sensitivity=85.25%, avg_specificity=82.72% avg_auc=92.25%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.653533 Test loss=0.360619 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.5857086777687073
[5/24] Train loss=0.6914228200912476
[10/24] Train loss=0.7671664357185364
[15/24] Train loss=0.637340784072876
[20/24] Train loss=0.6095049977302551
Test set avg_accuracy=81.56% avg_sensitivity=89.61%, avg_specificity=78.69% avg_auc=92.38%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.656238 Test loss=0.402712 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.6159582734107971
[5/24] Train loss=0.6994472146034241
[10/24] Train loss=0.7388443350791931
[15/24] Train loss=0.6354573965072632
[20/24] Train loss=0.624592661857605
Test set avg_accuracy=81.94% avg_sensitivity=88.32%, avg_specificity=79.66% avg_auc=92.40%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.655600 Test loss=0.390515 Current lr=[0.000156543481933168]

[0/24] Train loss=0.6068795919418335
[5/24] Train loss=0.7048028707504272
[10/24] Train loss=0.732627272605896
[15/24] Train loss=0.6151255965232849
[20/24] Train loss=0.5941660404205322
Test set avg_accuracy=82.67% avg_sensitivity=87.93%, avg_specificity=80.79% avg_auc=92.41%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.642853 Test loss=0.378944 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.6016275882720947
[5/24] Train loss=0.6816604733467102
[10/24] Train loss=0.7300916314125061
[15/24] Train loss=0.6216209530830383
[20/24] Train loss=0.5951429009437561
Test set avg_accuracy=82.57% avg_sensitivity=88.17%, avg_specificity=80.56% avg_auc=92.48%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.638205 Test loss=0.379420 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.602299153804779
[5/24] Train loss=0.7026253938674927
[10/24] Train loss=0.7311038970947266
[15/24] Train loss=0.6263234615325928
[20/24] Train loss=0.6083575487136841
Test set avg_accuracy=82.37% avg_sensitivity=88.37%, avg_specificity=80.23% avg_auc=92.48%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.642173 Test loss=0.385318 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.6101986169815063
[5/24] Train loss=0.7018959522247314
[10/24] Train loss=0.7179878354072571
[15/24] Train loss=0.6262883543968201
[20/24] Train loss=0.6129916310310364
Test set avg_accuracy=82.37% avg_sensitivity=88.47%, avg_specificity=80.19% avg_auc=92.42%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.640038 Test loss=0.386852 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.605175793170929
[5/24] Train loss=0.6988933682441711
[10/24] Train loss=0.7220327258110046
[15/24] Train loss=0.6191977262496948
[20/24] Train loss=0.593126654624939
Test set avg_accuracy=82.81% avg_sensitivity=88.12%, avg_specificity=80.92% avg_auc=92.49%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.639070 Test loss=0.378109 Current lr=[0.000134135431043539]

[0/24] Train loss=0.6003689169883728
[5/24] Train loss=0.6851879358291626
[10/24] Train loss=0.7205315828323364
[15/24] Train loss=0.6166618466377258
[20/24] Train loss=0.5930677652359009
Test set avg_accuracy=82.30% avg_sensitivity=88.37%, avg_specificity=80.14% avg_auc=92.48%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.635047 Test loss=0.385385 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.5950400233268738
[5/24] Train loss=0.6801590323448181
[10/24] Train loss=0.7119932174682617
[15/24] Train loss=0.6106271147727966
[20/24] Train loss=0.5912004709243774
Test set avg_accuracy=82.38% avg_sensitivity=88.57%, avg_specificity=80.17% avg_auc=92.48%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.632507 Test loss=0.384468 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.6005685925483704
[5/24] Train loss=0.6783564686775208
[10/24] Train loss=0.7177107334136963
[15/24] Train loss=0.6065300107002258
[20/24] Train loss=0.5811856985092163
Test set avg_accuracy=82.89% avg_sensitivity=88.47%, avg_specificity=80.90% avg_auc=92.51%
Best model saved!! Metric=18.773895368674417!!
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.632918 Test loss=0.377580 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.6002639532089233
[5/24] Train loss=0.6817790269851685
[10/24] Train loss=0.7273744344711304
[15/24] Train loss=0.5988562703132629
[20/24] Train loss=0.584648847579956
Test set avg_accuracy=82.50% avg_sensitivity=88.32%, avg_specificity=80.42% avg_auc=92.47%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.628481 Test loss=0.381817 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.5922113060951233
[5/24] Train loss=0.6767979264259338
[10/24] Train loss=0.7091355919837952
[15/24] Train loss=0.6064954400062561
[20/24] Train loss=0.581527054309845
Test set avg_accuracy=82.53% avg_sensitivity=88.52%, avg_specificity=80.39% avg_auc=92.54%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.628538 Test loss=0.380035 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.596605122089386
[5/24] Train loss=0.6704947352409363
[10/24] Train loss=0.7108921408653259
[15/24] Train loss=0.5959464311599731
[20/24] Train loss=0.5933141112327576
Test set avg_accuracy=82.32% avg_sensitivity=88.67%, avg_specificity=80.05% avg_auc=92.52%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.627318 Test loss=0.381805 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.6036059260368347
[5/24] Train loss=0.680357813835144
[10/24] Train loss=0.7063188552856445
[15/24] Train loss=0.5994778275489807
[20/24] Train loss=0.5780802965164185
Test set avg_accuracy=82.46% avg_sensitivity=88.27%, avg_specificity=80.39% avg_auc=92.50%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.626577 Test loss=0.379557 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.5892550349235535
[5/24] Train loss=0.6645546555519104
[10/24] Train loss=0.7088780999183655
[15/24] Train loss=0.5997750759124756
[20/24] Train loss=0.5885236263275146
Test set avg_accuracy=82.55% avg_sensitivity=88.12%, avg_specificity=80.56% avg_auc=92.52%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.624216 Test loss=0.377797 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.5870116949081421
[5/24] Train loss=0.6632838249206543
[10/24] Train loss=0.7055542469024658
[15/24] Train loss=0.5943532586097717
[20/24] Train loss=0.5755967497825623
Test set avg_accuracy=82.40% avg_sensitivity=88.42%, avg_specificity=80.24% avg_auc=92.53%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.624420 Test loss=0.382580 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.5878844261169434
[5/24] Train loss=0.6766420602798462
[10/24] Train loss=0.6895448565483093
[15/24] Train loss=0.5978443622589111
[20/24] Train loss=0.5866488218307495
Test set avg_accuracy=82.45% avg_sensitivity=88.57%, avg_specificity=80.26% avg_auc=92.55%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.620850 Test loss=0.379686 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.5909286737442017
[5/24] Train loss=0.6602072715759277
[10/24] Train loss=0.7072899341583252
[15/24] Train loss=0.5945879817008972
[20/24] Train loss=0.5726485848426819
Test set avg_accuracy=82.68% avg_sensitivity=88.42%, avg_specificity=80.63% avg_auc=92.59%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.624460 Test loss=0.376133 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.5798623561859131
[5/24] Train loss=0.6739534139633179
[10/24] Train loss=0.72081059217453
[15/24] Train loss=0.6000345349311829
[20/24] Train loss=0.5638604164123535
Test set avg_accuracy=83.18% avg_sensitivity=87.78%, avg_specificity=81.53% avg_auc=92.70%
Best model saved!! Metric=19.184793680571772!!
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.622609 Test loss=0.365518 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.5737017393112183
[5/24] Train loss=0.6649139523506165
[10/24] Train loss=0.7171998620033264
[15/24] Train loss=0.5883265137672424
[20/24] Train loss=0.5670976042747498
Test set avg_accuracy=83.03% avg_sensitivity=88.03%, avg_specificity=81.25% avg_auc=92.71%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.621056 Test loss=0.369922 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.5863292217254639
[5/24] Train loss=0.6616851687431335
[10/24] Train loss=0.7160897850990295
[15/24] Train loss=0.5904051065444946
[20/24] Train loss=0.5723892450332642
Test set avg_accuracy=82.45% avg_sensitivity=89.21%, avg_specificity=80.03% avg_auc=92.71%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.619602 Test loss=0.383900 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.5782991051673889
[5/24] Train loss=0.6562584042549133
[10/24] Train loss=0.7086536884307861
[15/24] Train loss=0.594925045967102
[20/24] Train loss=0.5826756954193115
Test set avg_accuracy=82.25% avg_sensitivity=89.66%, avg_specificity=79.61% avg_auc=92.76%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.616860 Test loss=0.388844 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.5787579417228699
[5/24] Train loss=0.6590064764022827
[10/24] Train loss=0.7147449851036072
[15/24] Train loss=0.595203697681427
[20/24] Train loss=0.5689439177513123
Test set avg_accuracy=82.12% avg_sensitivity=89.71%, avg_specificity=79.41% avg_auc=92.76%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.615006 Test loss=0.390734 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.5889943838119507
[5/24] Train loss=0.6557272672653198
[10/24] Train loss=0.7058488726615906
[15/24] Train loss=0.59743732213974
[20/24] Train loss=0.5771690011024475
Test set avg_accuracy=82.14% avg_sensitivity=89.71%, avg_specificity=79.43% avg_auc=92.77%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.612953 Test loss=0.390748 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.5849388837814331
[5/24] Train loss=0.6707699298858643
[10/24] Train loss=0.7061649560928345
[15/24] Train loss=0.6058127284049988
[20/24] Train loss=0.5870948433876038
Test set avg_accuracy=82.10% avg_sensitivity=90.15%, avg_specificity=79.22% avg_auc=92.70%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.616048 Test loss=0.393202 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.5814862847328186
[5/24] Train loss=0.65424644947052
[10/24] Train loss=0.7104829549789429
[15/24] Train loss=0.5837851762771606
[20/24] Train loss=0.5875172019004822
Test set avg_accuracy=82.57% avg_sensitivity=88.47%, avg_specificity=80.46% avg_auc=92.72%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.611209 Test loss=0.377398 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.5779770016670227
[5/24] Train loss=0.6484508514404297
[10/24] Train loss=0.7171010971069336
[15/24] Train loss=0.5860437154769897
[20/24] Train loss=0.5705523490905762
Test set avg_accuracy=82.81% avg_sensitivity=88.27%, avg_specificity=80.86% avg_auc=92.75%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.612135 Test loss=0.372307 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.57135009765625
[5/24] Train loss=0.6478320956230164
[10/24] Train loss=0.7030022740364075
[15/24] Train loss=0.5801798701286316
[20/24] Train loss=0.5687506794929504
Test set avg_accuracy=82.55% avg_sensitivity=88.62%, avg_specificity=80.39% avg_auc=92.74%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.608341 Test loss=0.379397 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.5754067897796631
[5/24] Train loss=0.6503618955612183
[10/24] Train loss=0.7044616341590881
[15/24] Train loss=0.5809625387191772
[20/24] Train loss=0.5739803910255432
Test set avg_accuracy=82.71% avg_sensitivity=88.47%, avg_specificity=80.65% avg_auc=92.73%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.608541 Test loss=0.375367 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.565503716468811
[5/24] Train loss=0.6485982537269592
[10/24] Train loss=0.706081211566925
[15/24] Train loss=0.5899550318717957
[20/24] Train loss=0.5650551915168762
Test set avg_accuracy=82.70% avg_sensitivity=88.27%, avg_specificity=80.70% avg_auc=92.74%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.607716 Test loss=0.375568 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.5766350030899048
[5/24] Train loss=0.6515889763832092
[10/24] Train loss=0.6961789727210999
[15/24] Train loss=0.5918298959732056
[20/24] Train loss=0.5686206221580505
Test set avg_accuracy=82.64% avg_sensitivity=88.27%, avg_specificity=80.63% avg_auc=92.77%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.607507 Test loss=0.374545 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.5736576318740845
[5/24] Train loss=0.6388635039329529
[10/24] Train loss=0.69137042760849
[15/24] Train loss=0.5944418907165527
[20/24] Train loss=0.5703308582305908
Test set avg_accuracy=82.64% avg_sensitivity=88.42%, avg_specificity=80.58% avg_auc=92.77%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.605831 Test loss=0.375167 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.5728117823600769
[5/24] Train loss=0.648878276348114
[10/24] Train loss=0.6936317682266235
[15/24] Train loss=0.5870028734207153
[20/24] Train loss=0.5714779496192932
Test set avg_accuracy=82.68% avg_sensitivity=88.32%, avg_specificity=80.67% avg_auc=92.78%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.606126 Test loss=0.374048 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.5734733939170837
[5/24] Train loss=0.6588922142982483
[10/24] Train loss=0.7102630734443665
[15/24] Train loss=0.600172758102417
[20/24] Train loss=0.5655778050422668
Test set avg_accuracy=82.75% avg_sensitivity=88.32%, avg_specificity=80.76% avg_auc=92.79%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.605760 Test loss=0.373148 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.5629953742027283
[5/24] Train loss=0.640137255191803
[10/24] Train loss=0.7011322975158691
[15/24] Train loss=0.5789015293121338
[20/24] Train loss=0.5613202452659607
Test set avg_accuracy=82.75% avg_sensitivity=88.62%, avg_specificity=80.65% avg_auc=92.80%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.601342 Test loss=0.374947 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.5635407567024231
[5/24] Train loss=0.6416806578636169
[10/24] Train loss=0.7038477063179016
[15/24] Train loss=0.5884646773338318
[20/24] Train loss=0.5699111819267273
Test set avg_accuracy=82.67% avg_sensitivity=88.97%, avg_specificity=80.42% avg_auc=92.79%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.603708 Test loss=0.379017 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.5718621611595154
[5/24] Train loss=0.6397186517715454
[10/24] Train loss=0.7030531167984009
[15/24] Train loss=0.5850053429603577
[20/24] Train loss=0.5674223899841309
Test set avg_accuracy=82.75% avg_sensitivity=88.67%, avg_specificity=80.63% avg_auc=92.81%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.606587 Test loss=0.374689 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.5654662251472473
[5/24] Train loss=0.6377761363983154
[10/24] Train loss=0.692602813243866
[15/24] Train loss=0.5785449147224426
[20/24] Train loss=0.5641945600509644
Test set avg_accuracy=82.68% avg_sensitivity=88.82%, avg_specificity=80.49% avg_auc=92.80%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.602647 Test loss=0.376894 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.5730753540992737
[5/24] Train loss=0.6477358341217041
[10/24] Train loss=0.7014678120613098
[15/24] Train loss=0.5936543941497803
[20/24] Train loss=0.5589836835861206
Test set avg_accuracy=82.55% avg_sensitivity=89.02%, avg_specificity=80.24% avg_auc=92.83%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.603255 Test loss=0.380466 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.5751891136169434
[5/24] Train loss=0.6304008364677429
[10/24] Train loss=0.7109852433204651
[15/24] Train loss=0.5881056785583496
[20/24] Train loss=0.5652673244476318
Test set avg_accuracy=82.72% avg_sensitivity=88.92%, avg_specificity=80.51% avg_auc=92.84%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.602821 Test loss=0.376489 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.5716014504432678
[5/24] Train loss=0.6469336748123169
[10/24] Train loss=0.6885684132575989
[15/24] Train loss=0.5913075804710388
[20/24] Train loss=0.5733370780944824
Test set avg_accuracy=82.83% avg_sensitivity=88.82%, avg_specificity=80.69% avg_auc=92.84%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.603866 Test loss=0.374539 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.5679002404212952
[5/24] Train loss=0.63914555311203
[10/24] Train loss=0.7009853720664978
[15/24] Train loss=0.5911544561386108
[20/24] Train loss=0.575668215751648
Test set avg_accuracy=82.96% avg_sensitivity=88.22%, avg_specificity=81.07% avg_auc=92.83%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.600734 Test loss=0.368265 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.5711789727210999
[5/24] Train loss=0.6438456177711487
[10/24] Train loss=0.705517590045929
[15/24] Train loss=0.5894080400466919
[20/24] Train loss=0.5735933184623718
Test set avg_accuracy=83.23% avg_sensitivity=87.63%, avg_specificity=81.66% avg_auc=92.83%
Best model saved!! Metric=19.347239676175676!!
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.604897 Test loss=0.360983 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.5759567618370056
[5/24] Train loss=0.6416160464286804
[10/24] Train loss=0.6950011253356934
[15/24] Train loss=0.5792225003242493
[20/24] Train loss=0.565922737121582
Test set avg_accuracy=83.24% avg_sensitivity=87.18%, avg_specificity=81.83% avg_auc=92.81%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.602023 Test loss=0.359436 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.5681928992271423
[5/24] Train loss=0.6474857926368713
[10/24] Train loss=0.6908490657806396
[15/24] Train loss=0.576000988483429
[20/24] Train loss=0.5749121904373169
Test set avg_accuracy=83.05% avg_sensitivity=87.53%, avg_specificity=81.45% avg_auc=92.80%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.601146 Test loss=0.363954 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.5443280935287476
[5/24] Train loss=0.6296851634979248
[10/24] Train loss=0.7074770927429199
[15/24] Train loss=0.5842275023460388
[20/24] Train loss=0.5641573667526245
Test set avg_accuracy=83.01% avg_sensitivity=87.48%, avg_specificity=81.41% avg_auc=92.80%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.599623 Test loss=0.364456 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.5684577226638794
[5/24] Train loss=0.6481247544288635
[10/24] Train loss=0.6903669834136963
[15/24] Train loss=0.5798609852790833
[20/24] Train loss=0.5758150815963745
Test set avg_accuracy=83.11% avg_sensitivity=87.43%, avg_specificity=81.57% avg_auc=92.81%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.598373 Test loss=0.362993 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.5547075271606445
[5/24] Train loss=0.6378483176231384
[10/24] Train loss=0.7059650421142578
[15/24] Train loss=0.5871016383171082
[20/24] Train loss=0.5581390261650085
Test set avg_accuracy=83.10% avg_sensitivity=87.38%, avg_specificity=81.57% avg_auc=92.79%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.597116 Test loss=0.363725 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.5714754462242126
[5/24] Train loss=0.6418967247009277
[10/24] Train loss=0.7109971046447754
[15/24] Train loss=0.582328200340271
[20/24] Train loss=0.5708677768707275
Test set avg_accuracy=83.03% avg_sensitivity=87.63%, avg_specificity=81.39% avg_auc=92.81%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.602219 Test loss=0.364177 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.5602460503578186
[5/24] Train loss=0.6414456963539124
[10/24] Train loss=0.6945767998695374
[15/24] Train loss=0.5780872106552124
[20/24] Train loss=0.559192955493927
Test set avg_accuracy=83.06% avg_sensitivity=87.48%, avg_specificity=81.48% avg_auc=92.80%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.599505 Test loss=0.364178 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.5596482753753662
[5/24] Train loss=0.6415453553199768
[10/24] Train loss=0.7016318440437317
[15/24] Train loss=0.5833388566970825
[20/24] Train loss=0.5525489449501038
Test set avg_accuracy=83.06% avg_sensitivity=87.53%, avg_specificity=81.46% avg_auc=92.80%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.598042 Test loss=0.364241 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.5592311024665833
[5/24] Train loss=0.6304799318313599
[10/24] Train loss=0.7018857002258301
[15/24] Train loss=0.583573043346405
[20/24] Train loss=0.55872642993927
Test set avg_accuracy=83.03% avg_sensitivity=87.53%, avg_specificity=81.43% avg_auc=92.80%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.601052 Test loss=0.364506 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.5604970455169678
[5/24] Train loss=0.6546498537063599
[10/24] Train loss=0.6926172971725464
[15/24] Train loss=0.5814258456230164
[20/24] Train loss=0.5568187236785889
Test set avg_accuracy=83.05% avg_sensitivity=87.53%, avg_specificity=81.45% avg_auc=92.80%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.599827 Test loss=0.364193 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.5647072196006775
[5/24] Train loss=0.6420419812202454
[10/24] Train loss=0.6914477348327637
[15/24] Train loss=0.5772380232810974
[20/24] Train loss=0.568558394908905
Test set avg_accuracy=83.03% avg_sensitivity=87.53%, avg_specificity=81.43% avg_auc=92.80%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.599541 Test loss=0.364317 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.5559181571006775
[5/24] Train loss=0.6430229544639587
[10/24] Train loss=0.6896936893463135
[15/24] Train loss=0.5779166221618652
[20/24] Train loss=0.5666047930717468
Test set avg_accuracy=83.03% avg_sensitivity=87.48%, avg_specificity=81.45% avg_auc=92.80%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.598213 Test loss=0.364353 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.5560415983200073
[5/24] Train loss=0.6355770826339722
[10/24] Train loss=0.7124520540237427
[15/24] Train loss=0.5761855840682983
[20/24] Train loss=0.5559932589530945
Test set avg_accuracy=83.03% avg_sensitivity=87.48%, avg_specificity=81.45% avg_auc=92.80%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.598539 Test loss=0.364359 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=83.23% sen=87.63%, spe=81.66%, auc=92.83%!
Fold[1] Avg_overlap=0.62%(±0.23764892855624345)
[0/24] Train loss=2.051121234893799
[5/24] Train loss=1.7641888856887817
[10/24] Train loss=1.5247243642807007
[15/24] Train loss=1.483004093170166
[20/24] Train loss=1.4786179065704346
Test set avg_accuracy=46.81% avg_sensitivity=60.72%, avg_specificity=42.18% avg_auc=53.10%
Best model saved!! Metric=-123.19140091056862!!
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=1.618700 Test loss=0.728462 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.466431975364685
[5/24] Train loss=1.4451897144317627
[10/24] Train loss=1.4577187299728394
[15/24] Train loss=1.4142471551895142
[20/24] Train loss=1.4075149297714233
Test set avg_accuracy=58.37% avg_sensitivity=55.56%, avg_specificity=59.31% avg_auc=59.92%
Best model saved!! Metric=-92.84049292846994!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=1.433144 Test loss=0.680316 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.4039220809936523
[5/24] Train loss=1.3818286657333374
[10/24] Train loss=1.4088695049285889
[15/24] Train loss=1.3830119371414185
[20/24] Train loss=1.3803514242172241
Test set avg_accuracy=63.42% avg_sensitivity=54.30%, avg_specificity=66.46% avg_auc=65.17%
Best model saved!! Metric=-76.64422363956282!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=1.393057 Test loss=0.662436 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.3783375024795532
[5/24] Train loss=1.3509072065353394
[10/24] Train loss=1.3662595748901367
[15/24] Train loss=1.3666188716888428
[20/24] Train loss=1.3626681566238403
Test set avg_accuracy=65.47% avg_sensitivity=65.05%, avg_specificity=65.61% avg_auc=69.49%
Best model saved!! Metric=-60.3785209768421!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=1.364810 Test loss=0.660960 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.3524718284606934
[5/24] Train loss=1.3328850269317627
[10/24] Train loss=1.338775634765625
[15/24] Train loss=1.3377758264541626
[20/24] Train loss=1.3382885456085205
Test set avg_accuracy=69.40% avg_sensitivity=65.73%, avg_specificity=70.62% avg_auc=73.38%
Best model saved!! Metric=-46.87249200391423!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=1.338466 Test loss=0.642385 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.3111865520477295
[5/24] Train loss=1.3037768602371216
[10/24] Train loss=1.316029667854309
[15/24] Train loss=1.2963207960128784
[20/24] Train loss=1.301498532295227
Test set avg_accuracy=69.97% avg_sensitivity=70.68%, avg_specificity=69.74% avg_auc=75.87%
Best model saved!! Metric=-39.73349457687735!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=1.310024 Test loss=0.633791 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.2849888801574707
[5/24] Train loss=1.2471625804901123
[10/24] Train loss=1.261587381362915
[15/24] Train loss=1.2775119543075562
[20/24] Train loss=1.2439652681350708
Test set avg_accuracy=71.63% avg_sensitivity=73.19%, avg_specificity=71.11% avg_auc=77.86%
Best model saved!! Metric=-32.22036487585822!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=1.272391 Test loss=0.619472 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.2511757612228394
[5/24] Train loss=1.2026350498199463
[10/24] Train loss=1.214885950088501
[15/24] Train loss=1.218029260635376
[20/24] Train loss=1.2060130834579468
Test set avg_accuracy=73.31% avg_sensitivity=76.11%, avg_specificity=72.38% avg_auc=79.53%
Best model saved!! Metric=-24.67640516862106!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=1.228637 Test loss=0.599865 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.2043296098709106
[5/24] Train loss=1.140082597732544
[10/24] Train loss=1.1760929822921753
[15/24] Train loss=1.170889139175415
[20/24] Train loss=1.144311785697937
Test set avg_accuracy=73.97% avg_sensitivity=77.93%, avg_specificity=72.65% avg_auc=81.10%
Best model saved!! Metric=-20.343768541096793!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=1.184640 Test loss=0.586155 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.1371839046478271
[5/24] Train loss=1.1002641916275024
[10/24] Train loss=1.1211941242218018
[15/24] Train loss=1.1091885566711426
[20/24] Train loss=1.101301670074463
Test set avg_accuracy=74.13% avg_sensitivity=78.72%, avg_specificity=72.60% avg_auc=81.74%
Best model saved!! Metric=-18.81609374034015!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=1.132800 Test loss=0.571715 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.0986876487731934
[5/24] Train loss=1.0374983549118042
[10/24] Train loss=1.0775326490402222
[15/24] Train loss=1.0732091665267944
[20/24] Train loss=1.0581066608428955
Test set avg_accuracy=74.49% avg_sensitivity=79.92%, avg_specificity=72.69% avg_auc=82.39%
Best model saved!! Metric=-16.510187208660327!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=1.097025 Test loss=0.561551 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.0487217903137207
[5/24] Train loss=1.0077370405197144
[10/24] Train loss=1.0460354089736938
[15/24] Train loss=1.040476679801941
[20/24] Train loss=1.025266408920288
Test set avg_accuracy=74.62% avg_sensitivity=81.12%, avg_specificity=72.46% avg_auc=82.91%
Best model saved!! Metric=-14.890660447940817!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=1.060102 Test loss=0.552473 Current lr=[5.97283087248885e-05]

[0/24] Train loss=1.014155626296997
[5/24] Train loss=0.9631066918373108
[10/24] Train loss=1.009661316871643
[15/24] Train loss=0.9852014780044556
[20/24] Train loss=0.9817962050437927
Test set avg_accuracy=75.66% avg_sensitivity=78.72%, avg_specificity=74.65% avg_auc=83.27%
Best model saved!! Metric=-13.696119931211072!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=1.025901 Test loss=0.523041 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.9669633507728577
[5/24] Train loss=0.9226317405700684
[10/24] Train loss=0.9771982431411743
[15/24] Train loss=0.9711163640022278
[20/24] Train loss=0.9536886215209961
Test set avg_accuracy=75.69% avg_sensitivity=80.18%, avg_specificity=74.20% avg_auc=83.74%
Best model saved!! Metric=-12.194260420222264!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.996723 Test loss=0.516746 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.9499710202217102
[5/24] Train loss=0.9038563370704651
[10/24] Train loss=0.9421858191490173
[15/24] Train loss=0.9294145703315735
[20/24] Train loss=0.9351733326911926
Test set avg_accuracy=75.99% avg_sensitivity=80.33%, avg_specificity=74.54% avg_auc=84.28%
Best model saved!! Metric=-10.852710938463858!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.969842 Test loss=0.505598 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.9132815599441528
[5/24] Train loss=0.8559513688087463
[10/24] Train loss=0.9495066404342651
[15/24] Train loss=0.9291043877601624
[20/24] Train loss=0.913516640663147
Test set avg_accuracy=76.41% avg_sensitivity=78.87%, avg_specificity=75.59% avg_auc=84.53%
Best model saved!! Metric=-10.60121030543452!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.954526 Test loss=0.489919 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.911125123500824
[5/24] Train loss=0.8569323420524597
[10/24] Train loss=0.9642937183380127
[15/24] Train loss=0.9084247946739197
[20/24] Train loss=0.8785644173622131
Test set avg_accuracy=76.94% avg_sensitivity=78.20%, avg_specificity=76.52% avg_auc=84.97%
Best model saved!! Metric=-9.370616527314908!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.944636 Test loss=0.473586 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.8724825978279114
[5/24] Train loss=0.840151309967041
[10/24] Train loss=0.9400026798248291
[15/24] Train loss=0.8825973868370056
[20/24] Train loss=0.8578532338142395
Test set avg_accuracy=76.68% avg_sensitivity=79.13%, avg_specificity=75.86% avg_auc=85.31%
Best model saved!! Metric=-9.016347075975347!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.926430 Test loss=0.471551 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.8468904495239258
[5/24] Train loss=0.7999427914619446
[10/24] Train loss=0.9214863181114197
[15/24] Train loss=0.8844961524009705
[20/24] Train loss=0.8236236572265625
Test set avg_accuracy=77.54% avg_sensitivity=78.14%, avg_specificity=77.34% avg_auc=85.50%
Best model saved!! Metric=-7.483413821027298!!
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.911306 Test loss=0.461767 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.8469034433364868
[5/24] Train loss=0.8039413690567017
[10/24] Train loss=0.8855870366096497
[15/24] Train loss=0.84949791431427
[20/24] Train loss=0.8071849346160889
Test set avg_accuracy=77.88% avg_sensitivity=78.30%, avg_specificity=77.74% avg_auc=85.92%
Best model saved!! Metric=-6.163153926147629!!
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.895437 Test loss=0.454783 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.8097048997879028
[5/24] Train loss=0.767348051071167
[10/24] Train loss=0.8871088027954102
[15/24] Train loss=0.8133088946342468
[20/24] Train loss=0.7880043387413025
Test set avg_accuracy=78.76% avg_sensitivity=76.32%, avg_specificity=79.58% avg_auc=86.35%
Best model saved!! Metric=-4.9894955115143915!!
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.872849 Test loss=0.439966 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.7942042946815491
[5/24] Train loss=0.7826628684997559
[10/24] Train loss=0.8649345636367798
[15/24] Train loss=0.7846909165382385
[20/24] Train loss=0.7857264876365662
Test set avg_accuracy=80.39% avg_sensitivity=72.40%, avg_specificity=83.05% avg_auc=86.45%
Best model saved!! Metric=-3.7079823897385467!!
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.856020 Test loss=0.416191 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.790970504283905
[5/24] Train loss=0.7669235467910767
[10/24] Train loss=0.8241063952445984
[15/24] Train loss=0.7698812484741211
[20/24] Train loss=0.7693760991096497
Test set avg_accuracy=80.69% avg_sensitivity=72.04%, avg_specificity=83.57% avg_auc=86.75%
Best model saved!! Metric=-2.949048918178093!!
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.840304 Test loss=0.411147 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.7849805951118469
[5/24] Train loss=0.7446476221084595
[10/24] Train loss=0.8181111812591553
[15/24] Train loss=0.7464259266853333
[20/24] Train loss=0.7450754642486572
Test set avg_accuracy=80.77% avg_sensitivity=74.49%, avg_specificity=82.86% avg_auc=87.08%
Best model saved!! Metric=-0.8012931335539122!!
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.822769 Test loss=0.413406 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.7736813426017761
[5/24] Train loss=0.7381149530410767
[10/24] Train loss=0.8218640089035034
[15/24] Train loss=0.736304759979248
[20/24] Train loss=0.7399332523345947
Test set avg_accuracy=81.37% avg_sensitivity=71.41%, avg_specificity=84.68% avg_auc=87.24%
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.809411 Test loss=0.401013 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.7560003399848938
[5/24] Train loss=0.7495620846748352
[10/24] Train loss=0.7951683402061462
[15/24] Train loss=0.7346785664558411
[20/24] Train loss=0.7297546863555908
Test set avg_accuracy=81.67% avg_sensitivity=69.43%, avg_specificity=85.74% avg_auc=87.39%
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.802070 Test loss=0.393457 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.7677204608917236
[5/24] Train loss=0.7510789632797241
[10/24] Train loss=0.7954959273338318
[15/24] Train loss=0.7397326827049255
[20/24] Train loss=0.7089626789093018
Test set avg_accuracy=82.06% avg_sensitivity=67.92%, avg_specificity=86.76% avg_auc=87.57%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.799251 Test loss=0.385106 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.7746080160140991
[5/24] Train loss=0.7522897720336914
[10/24] Train loss=0.7952419519424438
[15/24] Train loss=0.7202675938606262
[20/24] Train loss=0.7140477895736694
Test set avg_accuracy=82.19% avg_sensitivity=69.85%, avg_specificity=86.29% avg_auc=87.69%
Best model saved!! Metric=0.01836715743071693!!
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.793225 Test loss=0.386131 Current lr=[0.000210185142098938]

[0/24] Train loss=0.772975742816925
[5/24] Train loss=0.7539712190628052
[10/24] Train loss=0.7869693040847778
[15/24] Train loss=0.689127504825592
[20/24] Train loss=0.7018743753433228
Test set avg_accuracy=81.99% avg_sensitivity=70.37%, avg_specificity=85.86% avg_auc=87.88%
Best model saved!! Metric=0.10209537107981248!!
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.784495 Test loss=0.384165 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.7453339695930481
[5/24] Train loss=0.7607346177101135
[10/24] Train loss=0.7849324941635132
[15/24] Train loss=0.6886512041091919
[20/24] Train loss=0.7032654285430908
Test set avg_accuracy=81.60% avg_sensitivity=72.67%, avg_specificity=84.57% avg_auc=87.92%
Best model saved!! Metric=0.7648055038874162!!
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.779451 Test loss=0.392148 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.7406113147735596
[5/24] Train loss=0.7400357723236084
[10/24] Train loss=0.7806048393249512
[15/24] Train loss=0.6957252621650696
[20/24] Train loss=0.6849797964096069
Test set avg_accuracy=81.99% avg_sensitivity=69.27%, avg_specificity=86.22% avg_auc=87.91%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.772733 Test loss=0.383739 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.7505881190299988
[5/24] Train loss=0.7580180168151855
[10/24] Train loss=0.7748716473579407
[15/24] Train loss=0.690563440322876
[20/24] Train loss=0.6827666163444519
Test set avg_accuracy=81.97% avg_sensitivity=73.34%, avg_specificity=84.83% avg_auc=88.07%
Best model saved!! Metric=2.2099469023550427!!
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.768429 Test loss=0.389353 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.7129569053649902
[5/24] Train loss=0.7551131248474121
[10/24] Train loss=0.7738797664642334
[15/24] Train loss=0.6748785972595215
[20/24] Train loss=0.6715028882026672
Test set avg_accuracy=81.71% avg_sensitivity=70.94%, avg_specificity=85.29% avg_auc=87.95%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.764635 Test loss=0.388417 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.7238304615020752
[5/24] Train loss=0.7612740397453308
[10/24] Train loss=0.7670071125030518
[15/24] Train loss=0.67998206615448
[20/24] Train loss=0.6900515556335449
Test set avg_accuracy=81.93% avg_sensitivity=72.72%, avg_specificity=84.99% avg_auc=88.24%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.761645 Test loss=0.386661 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.7227667570114136
[5/24] Train loss=0.7330905795097351
[10/24] Train loss=0.761536180973053
[15/24] Train loss=0.6677499413490295
[20/24] Train loss=0.6639142036437988
Test set avg_accuracy=82.07% avg_sensitivity=73.55%, avg_specificity=84.90% avg_auc=88.30%
Best model saved!! Metric=2.8217273457172496!!
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.753816 Test loss=0.387237 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.7075728178024292
[5/24] Train loss=0.7411636114120483
[10/24] Train loss=0.7532875537872314
[15/24] Train loss=0.6635077595710754
[20/24] Train loss=0.6578086018562317
Test set avg_accuracy=82.32% avg_sensitivity=73.66%, avg_specificity=85.20% avg_auc=88.40%
Best model saved!! Metric=3.577596865495437!!
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.749596 Test loss=0.384412 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.7021406888961792
[5/24] Train loss=0.7295898199081421
[10/24] Train loss=0.7426257133483887
[15/24] Train loss=0.6654564142227173
[20/24] Train loss=0.6601073145866394
Test set avg_accuracy=82.66% avg_sensitivity=71.41%, avg_specificity=86.40% avg_auc=88.52%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.746628 Test loss=0.375086 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.7055817246437073
[5/24] Train loss=0.7339277863502502
[10/24] Train loss=0.7644252181053162
[15/24] Train loss=0.6534263491630554
[20/24] Train loss=0.6476624011993408
Test set avg_accuracy=82.57% avg_sensitivity=72.25%, avg_specificity=86.00% avg_auc=88.57%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.745149 Test loss=0.375740 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.7039090991020203
[5/24] Train loss=0.7453821301460266
[10/24] Train loss=0.7558688521385193
[15/24] Train loss=0.6678001880645752
[20/24] Train loss=0.6374364495277405
Test set avg_accuracy=82.73% avg_sensitivity=72.04%, avg_specificity=86.29% avg_auc=88.61%
Best model saved!! Metric=3.6788667394806396!!
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.738623 Test loss=0.373821 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.693762481212616
[5/24] Train loss=0.7613881826400757
[10/24] Train loss=0.7673918008804321
[15/24] Train loss=0.6578699350357056
[20/24] Train loss=0.6406694650650024
Test set avg_accuracy=82.83% avg_sensitivity=72.30%, avg_specificity=86.33% avg_auc=88.65%
Best model saved!! Metric=4.10517823804787!!
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.737594 Test loss=0.373730 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.6914968490600586
[5/24] Train loss=0.7539122700691223
[10/24] Train loss=0.7470394372940063
[15/24] Train loss=0.6628727316856384
[20/24] Train loss=0.6583174467086792
Test set avg_accuracy=82.97% avg_sensitivity=71.67%, avg_specificity=86.73% avg_auc=88.76%
Best model saved!! Metric=4.127341163694155!!
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.736257 Test loss=0.369052 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.6906828284263611
[5/24] Train loss=0.7442547678947449
[10/24] Train loss=0.7372668981552124
[15/24] Train loss=0.6618959307670593
[20/24] Train loss=0.6401908993721008
Test set avg_accuracy=83.01% avg_sensitivity=71.31%, avg_specificity=86.90% avg_auc=88.81%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.729397 Test loss=0.367710 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.6805356740951538
[5/24] Train loss=0.723319411277771
[10/24] Train loss=0.7272235155105591
[15/24] Train loss=0.6666784286499023
[20/24] Train loss=0.6308056116104126
Test set avg_accuracy=83.26% avg_sensitivity=69.27%, avg_specificity=87.91% avg_auc=88.73%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.728244 Test loss=0.364118 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.6974650621414185
[5/24] Train loss=0.7064986824989319
[10/24] Train loss=0.7274829149246216
[15/24] Train loss=0.6607583165168762
[20/24] Train loss=0.6253047585487366
Test set avg_accuracy=83.35% avg_sensitivity=70.06%, avg_specificity=87.77% avg_auc=88.81%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.727665 Test loss=0.363498 Current lr=[0.00029967723776099]

[0/24] Train loss=0.6972542405128479
[5/24] Train loss=0.669370174407959
[10/24] Train loss=0.7461089491844177
[15/24] Train loss=0.6614431738853455
[20/24] Train loss=0.6327545046806335
Test set avg_accuracy=82.86% avg_sensitivity=73.40%, avg_specificity=86.01% avg_auc=88.87%
Best model saved!! Metric=5.146289043070695!!
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.728348 Test loss=0.373882 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.6781241297721863
[5/24] Train loss=0.6677852869033813
[10/24] Train loss=0.739432156085968
[15/24] Train loss=0.6427746415138245
[20/24] Train loss=0.6271196603775024
Test set avg_accuracy=82.80% avg_sensitivity=72.72%, avg_specificity=86.15% avg_auc=88.83%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.720382 Test loss=0.373037 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.6702284812927246
[5/24] Train loss=0.6770908832550049
[10/24] Train loss=0.7356855869293213
[15/24] Train loss=0.644595742225647
[20/24] Train loss=0.614626407623291
Test set avg_accuracy=83.15% avg_sensitivity=72.09%, avg_specificity=86.83% avg_auc=88.84%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.717151 Test loss=0.369618 Current lr=[0.000299720220882401]

[0/24] Train loss=0.674942672252655
[5/24] Train loss=0.6739575862884521
[10/24] Train loss=0.7234786152839661
[15/24] Train loss=0.649702787399292
[20/24] Train loss=0.6212668418884277
Test set avg_accuracy=83.10% avg_sensitivity=71.73%, avg_specificity=86.88% avg_auc=88.92%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.715231 Test loss=0.368111 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.6846500635147095
[5/24] Train loss=0.6775581240653992
[10/24] Train loss=0.7305402755737305
[15/24] Train loss=0.6401913166046143
[20/24] Train loss=0.6054703593254089
Test set avg_accuracy=83.05% avg_sensitivity=72.40%, avg_specificity=86.59% avg_auc=88.85%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.712626 Test loss=0.372167 Current lr=[0.000298904600941902]

[0/24] Train loss=0.6644125580787659
[5/24] Train loss=0.6691422462463379
[10/24] Train loss=0.721187174320221
[15/24] Train loss=0.6397894620895386
[20/24] Train loss=0.6099272966384888
Test set avg_accuracy=83.23% avg_sensitivity=71.88%, avg_specificity=87.00% avg_auc=88.98%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.711636 Test loss=0.368438 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.676200270652771
[5/24] Train loss=0.6804800033569336
[10/24] Train loss=0.7324923872947693
[15/24] Train loss=0.6269806027412415
[20/24] Train loss=0.6093779802322388
Test set avg_accuracy=83.01% avg_sensitivity=72.30%, avg_specificity=86.57% avg_auc=88.95%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.709311 Test loss=0.371121 Current lr=[0.000297555943323901]

[0/24] Train loss=0.6690525412559509
[5/24] Train loss=0.6631670594215393
[10/24] Train loss=0.7272583246231079
[15/24] Train loss=0.6405742764472961
[20/24] Train loss=0.6019283533096313
Test set avg_accuracy=83.09% avg_sensitivity=72.82%, avg_specificity=86.50% avg_auc=88.96%
Best model saved!! Metric=5.367634158055836!!
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.706087 Test loss=0.372024 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.6570020914077759
[5/24] Train loss=0.6658212542533875
[10/24] Train loss=0.7207379937171936
[15/24] Train loss=0.6375457644462585
[20/24] Train loss=0.6073713898658752
Test set avg_accuracy=82.89% avg_sensitivity=74.02%, avg_specificity=85.84% avg_auc=88.88%
Best model saved!! Metric=5.63280785464876!!
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.702562 Test loss=0.377568 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.6566012501716614
[5/24] Train loss=0.6620402336120605
[10/24] Train loss=0.7123445272445679
[15/24] Train loss=0.6297489404678345
[20/24] Train loss=0.5978294014930725
Test set avg_accuracy=83.26% avg_sensitivity=71.94%, avg_specificity=87.02% avg_auc=89.03%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.696454 Test loss=0.367273 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.6598414182662964
[5/24] Train loss=0.6799695491790771
[10/24] Train loss=0.7255336046218872
[15/24] Train loss=0.6194173097610474
[20/24] Train loss=0.5966410040855408
Test set avg_accuracy=83.27% avg_sensitivity=71.99%, avg_specificity=87.02% avg_auc=88.98%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.697035 Test loss=0.368406 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.6618452072143555
[5/24] Train loss=0.6799694299697876
[10/24] Train loss=0.7192218899726868
[15/24] Train loss=0.6177381277084351
[20/24] Train loss=0.5834017992019653
Test set avg_accuracy=83.49% avg_sensitivity=71.88%, avg_specificity=87.35% avg_auc=89.04%
Best model saved!! Metric=5.761069694576349!!
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.695879 Test loss=0.366149 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.6562526822090149
[5/24] Train loss=0.6610514521598816
[10/24] Train loss=0.7209445238113403
[15/24] Train loss=0.6092027425765991
[20/24] Train loss=0.578519344329834
Test set avg_accuracy=83.07% avg_sensitivity=73.40%, avg_specificity=86.29% avg_auc=89.02%
Best model saved!! Metric=5.776104877104871!!
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.694895 Test loss=0.372606 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.6561260223388672
[5/24] Train loss=0.6562322378158569
[10/24] Train loss=0.7137831449508667
[15/24] Train loss=0.6211743950843811
[20/24] Train loss=0.583710253238678
Test set avg_accuracy=82.92% avg_sensitivity=74.96%, avg_specificity=85.56% avg_auc=89.07%
Best model saved!! Metric=6.505788210927008!!
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.691699 Test loss=0.377565 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.6431190967559814
[5/24] Train loss=0.6563442349433899
[10/24] Train loss=0.7075255513191223
[15/24] Train loss=0.6165739297866821
[20/24] Train loss=0.5887002348899841
Test set avg_accuracy=83.12% avg_sensitivity=74.65%, avg_specificity=85.94% avg_auc=89.12%
Best model saved!! Metric=6.841931288051583!!
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.688398 Test loss=0.374386 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.6453524231910706
[5/24] Train loss=0.6608363389968872
[10/24] Train loss=0.7130276560783386
[15/24] Train loss=0.6040595173835754
[20/24] Train loss=0.5918669700622559
Test set avg_accuracy=83.24% avg_sensitivity=74.65%, avg_specificity=86.10% avg_auc=89.19%
Best model saved!! Metric=7.178558704392302!!
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.687968 Test loss=0.372390 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.6411703824996948
[5/24] Train loss=0.6497718691825867
[10/24] Train loss=0.700524091720581
[15/24] Train loss=0.6193960309028625
[20/24] Train loss=0.5846179127693176
Test set avg_accuracy=83.07% avg_sensitivity=74.86%, avg_specificity=85.81% avg_auc=89.12%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.683851 Test loss=0.376079 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.6452653408050537
[5/24] Train loss=0.6538649201393127
[10/24] Train loss=0.6888750195503235
[15/24] Train loss=0.6111807823181152
[20/24] Train loss=0.579572319984436
Test set avg_accuracy=83.22% avg_sensitivity=73.97%, avg_specificity=86.29% avg_auc=89.15%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.681080 Test loss=0.371422 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.6415011286735535
[5/24] Train loss=0.650708019733429
[10/24] Train loss=0.712159276008606
[15/24] Train loss=0.6042606830596924
[20/24] Train loss=0.5715177655220032
Test set avg_accuracy=83.42% avg_sensitivity=73.66%, avg_specificity=86.67% avg_auc=89.07%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.680383 Test loss=0.370762 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.6527562737464905
[5/24] Train loss=0.6648737788200378
[10/24] Train loss=0.6934284567832947
[15/24] Train loss=0.5976710319519043
[20/24] Train loss=0.577958345413208
Test set avg_accuracy=83.57% avg_sensitivity=74.23%, avg_specificity=86.67% avg_auc=89.12%
Best model saved!! Metric=7.595782123727702!!
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.679382 Test loss=0.371621 Current lr=[0.000276307469034998]

[0/24] Train loss=0.6530941128730774
[5/24] Train loss=0.6511380672454834
[10/24] Train loss=0.7158429622650146
[15/24] Train loss=0.5965882539749146
[20/24] Train loss=0.5743319988250732
Test set avg_accuracy=82.89% avg_sensitivity=76.21%, avg_specificity=85.11% avg_auc=89.19%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.676904 Test loss=0.379698 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.634039044380188
[5/24] Train loss=0.6398362517356873
[10/24] Train loss=0.7102287411689758
[15/24] Train loss=0.607851505279541
[20/24] Train loss=0.582961916923523
Test set avg_accuracy=83.07% avg_sensitivity=75.69%, avg_specificity=85.53% avg_auc=89.21%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.674976 Test loss=0.376867 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.6401243805885315
[5/24] Train loss=0.6505697965621948
[10/24] Train loss=0.7076478004455566
[15/24] Train loss=0.5965720415115356
[20/24] Train loss=0.5681784152984619
Test set avg_accuracy=82.94% avg_sensitivity=76.06%, avg_specificity=85.23% avg_auc=89.27%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.674600 Test loss=0.376413 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.6294235587120056
[5/24] Train loss=0.6669110059738159
[10/24] Train loss=0.7064024806022644
[15/24] Train loss=0.6011995077133179
[20/24] Train loss=0.5793546438217163
Test set avg_accuracy=82.77% avg_sensitivity=76.68%, avg_specificity=84.80% avg_auc=89.19%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.674373 Test loss=0.382487 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.6325284242630005
[5/24] Train loss=0.6497312784194946
[10/24] Train loss=0.6867333054542542
[15/24] Train loss=0.5931130051612854
[20/24] Train loss=0.5738042593002319
Test set avg_accuracy=82.70% avg_sensitivity=76.53%, avg_specificity=84.75% avg_auc=89.28%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.669759 Test loss=0.380754 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.6227443814277649
[5/24] Train loss=0.6484261751174927
[10/24] Train loss=0.6965056657791138
[15/24] Train loss=0.5938888192176819
[20/24] Train loss=0.5727922916412354
Test set avg_accuracy=82.75% avg_sensitivity=76.79%, avg_specificity=84.73% avg_auc=89.15%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.667655 Test loss=0.383431 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.6336165070533752
[5/24] Train loss=0.6520475149154663
[10/24] Train loss=0.7051602602005005
[15/24] Train loss=0.587277352809906
[20/24] Train loss=0.578593373298645
Test set avg_accuracy=82.92% avg_sensitivity=77.67%, avg_specificity=84.66% avg_auc=89.37%
Best model saved!! Metric=8.616567939975766!!
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.670488 Test loss=0.381731 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.6253265738487244
[5/24] Train loss=0.6556400656700134
[10/24] Train loss=0.7039338946342468
[15/24] Train loss=0.6003748774528503
[20/24] Train loss=0.562089741230011
Test set avg_accuracy=82.83% avg_sensitivity=76.89%, avg_specificity=84.80% avg_auc=89.35%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.666154 Test loss=0.379597 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.6210464835166931
[5/24] Train loss=0.6575110554695129
[10/24] Train loss=0.6901445388793945
[15/24] Train loss=0.592693567276001
[20/24] Train loss=0.5738752484321594
Test set avg_accuracy=83.28% avg_sensitivity=73.97%, avg_specificity=86.38% avg_auc=89.30%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.665989 Test loss=0.367830 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.6309618949890137
[5/24] Train loss=0.6655170917510986
[10/24] Train loss=0.6915348172187805
[15/24] Train loss=0.6034432053565979
[20/24] Train loss=0.561350405216217
Test set avg_accuracy=83.44% avg_sensitivity=73.40%, avg_specificity=86.78% avg_auc=89.17%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.669762 Test loss=0.367155 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.6521549224853516
[5/24] Train loss=0.641129732131958
[10/24] Train loss=0.6981124877929688
[15/24] Train loss=0.5818473100662231
[20/24] Train loss=0.5677173733711243
Test set avg_accuracy=83.03% avg_sensitivity=75.53%, avg_specificity=85.53% avg_auc=89.24%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.667645 Test loss=0.375910 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.6234742999076843
[5/24] Train loss=0.6444100737571716
[10/24] Train loss=0.6913563013076782
[15/24] Train loss=0.585010826587677
[20/24] Train loss=0.5678303241729736
Test set avg_accuracy=83.37% avg_sensitivity=74.80%, avg_specificity=86.22% avg_auc=89.30%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.664223 Test loss=0.369897 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.6363674402236938
[5/24] Train loss=0.6349786520004272
[10/24] Train loss=0.6947076320648193
[15/24] Train loss=0.5847027897834778
[20/24] Train loss=0.5590946674346924
Test set avg_accuracy=83.19% avg_sensitivity=75.33%, avg_specificity=85.81% avg_auc=89.37%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.659667 Test loss=0.370616 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.6197636127471924
[5/24] Train loss=0.6400201320648193
[10/24] Train loss=0.697695255279541
[15/24] Train loss=0.590864360332489
[20/24] Train loss=0.5647850036621094
Test set avg_accuracy=83.05% avg_sensitivity=76.06%, avg_specificity=85.37% avg_auc=89.40%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.663184 Test loss=0.373467 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.6196168661117554
[5/24] Train loss=0.6509212851524353
[10/24] Train loss=0.6823992729187012
[15/24] Train loss=0.5915923118591309
[20/24] Train loss=0.559571385383606
Test set avg_accuracy=83.03% avg_sensitivity=77.57%, avg_specificity=84.85% avg_auc=89.49%
Best model saved!! Metric=8.948397965083558!!
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.662281 Test loss=0.379085 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.6118782758712769
[5/24] Train loss=0.6406323909759521
[10/24] Train loss=0.6997785568237305
[15/24] Train loss=0.618828296661377
[20/24] Train loss=0.5673784017562866
Test set avg_accuracy=81.42% avg_sensitivity=80.86%, avg_specificity=81.61% avg_auc=89.38%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.666439 Test loss=0.405531 Current lr=[0.000224838296036774]

[0/24] Train loss=0.607414722442627
[5/24] Train loss=0.6326642036437988
[10/24] Train loss=0.6876340508460999
[15/24] Train loss=0.6196414232254028
[20/24] Train loss=0.5832227468490601
Test set avg_accuracy=80.16% avg_sensitivity=82.89%, avg_specificity=79.25% avg_auc=89.27%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.663635 Test loss=0.426249 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.6193512082099915
[5/24] Train loss=0.6332516074180603
[10/24] Train loss=0.6955333352088928
[15/24] Train loss=0.5931299924850464
[20/24] Train loss=0.5828807353973389
Test set avg_accuracy=81.20% avg_sensitivity=81.01%, avg_specificity=81.26% avg_auc=89.33%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.655575 Test loss=0.408390 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.6156498193740845
[5/24] Train loss=0.6391199827194214
[10/24] Train loss=0.6713719964027405
[15/24] Train loss=0.5866390466690063
[20/24] Train loss=0.5652192831039429
Test set avg_accuracy=81.77% avg_sensitivity=81.06%, avg_specificity=82.01% avg_auc=89.52%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.651728 Test loss=0.399631 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.6092736721038818
[5/24] Train loss=0.6345410943031311
[10/24] Train loss=0.6721937656402588
[15/24] Train loss=0.5964831113815308
[20/24] Train loss=0.5680525302886963
Test set avg_accuracy=81.65% avg_sensitivity=79.92%, avg_specificity=82.23% avg_auc=89.45%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.652658 Test loss=0.395389 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.6117350459098816
[5/24] Train loss=0.6271175742149353
[10/24] Train loss=0.6851441860198975
[15/24] Train loss=0.5901714563369751
[20/24] Train loss=0.5727898478507996
Test set avg_accuracy=81.81% avg_sensitivity=80.33%, avg_specificity=82.30% avg_auc=89.47%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.651667 Test loss=0.396621 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.606651782989502
[5/24] Train loss=0.6198542714118958
[10/24] Train loss=0.682165265083313
[15/24] Train loss=0.5912202596664429
[20/24] Train loss=0.5607814788818359
Test set avg_accuracy=82.02% avg_sensitivity=79.50%, avg_specificity=82.86% avg_auc=89.56%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.648616 Test loss=0.390636 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.6031539440155029
[5/24] Train loss=0.6233356595039368
[10/24] Train loss=0.6764512658119202
[15/24] Train loss=0.582169234752655
[20/24] Train loss=0.5583378076553345
Test set avg_accuracy=82.02% avg_sensitivity=79.66%, avg_specificity=82.80% avg_auc=89.47%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.645551 Test loss=0.391996 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.603197455406189
[5/24] Train loss=0.6317785978317261
[10/24] Train loss=0.6704992055892944
[15/24] Train loss=0.5943039059638977
[20/24] Train loss=0.5586463809013367
Test set avg_accuracy=81.84% avg_sensitivity=80.59%, avg_specificity=82.25% avg_auc=89.62%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.648321 Test loss=0.396418 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.6075995564460754
[5/24] Train loss=0.6227450966835022
[10/24] Train loss=0.696628987789154
[15/24] Train loss=0.5937560200691223
[20/24] Train loss=0.5584884881973267
Test set avg_accuracy=81.30% avg_sensitivity=82.42%, avg_specificity=80.93% avg_auc=89.72%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.650637 Test loss=0.412035 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.5882168412208557
[5/24] Train loss=0.6202316880226135
[10/24] Train loss=0.6946360468864441
[15/24] Train loss=0.5995475053787231
[20/24] Train loss=0.5781859755516052
Test set avg_accuracy=80.44% avg_sensitivity=84.51%, avg_specificity=79.09% avg_auc=89.70%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.649421 Test loss=0.433685 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.6045978665351868
[5/24] Train loss=0.6300046443939209
[10/24] Train loss=0.6719058752059937
[15/24] Train loss=0.5898541212081909
[20/24] Train loss=0.5712131857872009
Test set avg_accuracy=80.60% avg_sensitivity=84.40%, avg_specificity=79.33% avg_auc=89.81%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.644728 Test loss=0.430874 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.5972148776054382
[5/24] Train loss=0.6192816495895386
[10/24] Train loss=0.6774136424064636
[15/24] Train loss=0.587723970413208
[20/24] Train loss=0.5550671815872192
Test set avg_accuracy=81.24% avg_sensitivity=83.67%, avg_specificity=80.43% avg_auc=89.89%
Best model saved!! Metric=9.222764949027507!!
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.639609 Test loss=0.418721 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.5948268175125122
[5/24] Train loss=0.6115072965621948
[10/24] Train loss=0.6681177020072937
[15/24] Train loss=0.5760951042175293
[20/24] Train loss=0.5472185015678406
Test set avg_accuracy=81.48% avg_sensitivity=83.15%, avg_specificity=80.93% avg_auc=89.87%
Best model saved!! Metric=9.431568937980217!!
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.633076 Test loss=0.412183 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.593214750289917
[5/24] Train loss=0.6087372303009033
[10/24] Train loss=0.6677033305168152
[15/24] Train loss=0.5789071917533875
[20/24] Train loss=0.5710407495498657
Test set avg_accuracy=81.20% avg_sensitivity=83.52%, avg_specificity=80.43% avg_auc=89.86%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.636402 Test loss=0.418203 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.5887629389762878
[5/24] Train loss=0.6100365519523621
[10/24] Train loss=0.6713768243789673
[15/24] Train loss=0.5684230923652649
[20/24] Train loss=0.5540218353271484
Test set avg_accuracy=81.29% avg_sensitivity=83.20%, avg_specificity=80.65% avg_auc=89.93%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.633174 Test loss=0.413966 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.5906795263290405
[5/24] Train loss=0.6005527973175049
[10/24] Train loss=0.660892903804779
[15/24] Train loss=0.5779996514320374
[20/24] Train loss=0.5544097423553467
Test set avg_accuracy=81.55% avg_sensitivity=82.52%, avg_specificity=81.23% avg_auc=89.93%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.631612 Test loss=0.408611 Current lr=[0.000156543481933168]

[0/24] Train loss=0.5792904496192932
[5/24] Train loss=0.6189178228378296
[10/24] Train loss=0.6587623953819275
[15/24] Train loss=0.5695556998252869
[20/24] Train loss=0.5598983764648438
Test set avg_accuracy=81.54% avg_sensitivity=83.05%, avg_specificity=81.03% avg_auc=89.92%
Best model saved!! Metric=9.540057825027105!!
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.631230 Test loss=0.411164 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.5856197476387024
[5/24] Train loss=0.604425311088562
[10/24] Train loss=0.6588252186775208
[15/24] Train loss=0.5553274154663086
[20/24] Train loss=0.5505118370056152
Test set avg_accuracy=81.35% avg_sensitivity=83.57%, avg_specificity=80.62% avg_auc=89.94%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.627726 Test loss=0.415554 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.5873280763626099
[5/24] Train loss=0.6027274131774902
[10/24] Train loss=0.6579244136810303
[15/24] Train loss=0.5593973994255066
[20/24] Train loss=0.5493104457855225
Test set avg_accuracy=81.76% avg_sensitivity=82.99%, avg_specificity=81.35% avg_auc=89.98%
Best model saved!! Metric=10.076048443123199!!
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.626961 Test loss=0.409320 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.5890101790428162
[5/24] Train loss=0.6150131821632385
[10/24] Train loss=0.6689295768737793
[15/24] Train loss=0.5667310953140259
[20/24] Train loss=0.5431539416313171
Test set avg_accuracy=81.85% avg_sensitivity=82.73%, avg_specificity=81.55% avg_auc=90.01%
Best model saved!! Metric=10.14310775179446!!
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.627426 Test loss=0.405632 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.5761336088180542
[5/24] Train loss=0.6072708368301392
[10/24] Train loss=0.6581164598464966
[15/24] Train loss=0.5623311400413513
[20/24] Train loss=0.5504698157310486
Test set avg_accuracy=81.74% avg_sensitivity=82.73%, avg_specificity=81.42% avg_auc=89.97%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.625412 Test loss=0.408839 Current lr=[0.000134135431043539]

[0/24] Train loss=0.5884978771209717
[5/24] Train loss=0.6156010031700134
[10/24] Train loss=0.6650421619415283
[15/24] Train loss=0.5591763854026794
[20/24] Train loss=0.5397247076034546
Test set avg_accuracy=81.85% avg_sensitivity=82.89%, avg_specificity=81.50% avg_auc=90.02%
Best model saved!! Metric=10.264984118315525!!
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.625518 Test loss=0.408833 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.5704106688499451
[5/24] Train loss=0.6021949052810669
[10/24] Train loss=0.6569466590881348
[15/24] Train loss=0.5515602231025696
[20/24] Train loss=0.5428256392478943
Test set avg_accuracy=81.81% avg_sensitivity=82.37%, avg_specificity=81.62% avg_auc=90.03%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.621298 Test loss=0.406282 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.5796862840652466
[5/24] Train loss=0.6071134209632874
[10/24] Train loss=0.6534263491630554
[15/24] Train loss=0.5559619069099426
[20/24] Train loss=0.5453274250030518
Test set avg_accuracy=81.82% avg_sensitivity=82.47%, avg_specificity=81.61% avg_auc=90.03%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.621353 Test loss=0.406017 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.5704500079154968
[5/24] Train loss=0.6015818119049072
[10/24] Train loss=0.6604024767875671
[15/24] Train loss=0.5601884722709656
[20/24] Train loss=0.5407317280769348
Test set avg_accuracy=81.81% avg_sensitivity=82.16%, avg_specificity=81.69% avg_auc=90.07%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.620214 Test loss=0.404618 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.574744462966919
[5/24] Train loss=0.5956832766532898
[10/24] Train loss=0.6433273553848267
[15/24] Train loss=0.5508398413658142
[20/24] Train loss=0.5332263112068176
Test set avg_accuracy=81.95% avg_sensitivity=82.21%, avg_specificity=81.87% avg_auc=90.09%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.616279 Test loss=0.404038 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.5724784135818481
[5/24] Train loss=0.6004889607429504
[10/24] Train loss=0.6615579724311829
[15/24] Train loss=0.5555591583251953
[20/24] Train loss=0.5394099354743958
Test set avg_accuracy=81.50% avg_sensitivity=83.36%, avg_specificity=80.88% avg_auc=90.06%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.619418 Test loss=0.413303 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.5724515318870544
[5/24] Train loss=0.5929086804389954
[10/24] Train loss=0.6599726676940918
[15/24] Train loss=0.5529363751411438
[20/24] Train loss=0.5306997299194336
Test set avg_accuracy=81.89% avg_sensitivity=82.47%, avg_specificity=81.69% avg_auc=90.08%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.615624 Test loss=0.404766 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.5606241226196289
[5/24] Train loss=0.5989480018615723
[10/24] Train loss=0.6552605032920837
[15/24] Train loss=0.5556797385215759
[20/24] Train loss=0.5205671787261963
Test set avg_accuracy=81.65% avg_sensitivity=82.37%, avg_specificity=81.42% avg_auc=90.00%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.613151 Test loss=0.408347 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.5720581412315369
[5/24] Train loss=0.5888400673866272
[10/24] Train loss=0.664481520652771
[15/24] Train loss=0.5545930862426758
[20/24] Train loss=0.5306555032730103
Test set avg_accuracy=81.56% avg_sensitivity=82.94%, avg_specificity=81.10% avg_auc=90.05%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.614670 Test loss=0.409366 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.5627781748771667
[5/24] Train loss=0.597547173500061
[10/24] Train loss=0.6697879433631897
[15/24] Train loss=0.5474250912666321
[20/24] Train loss=0.5312915444374084
Test set avg_accuracy=81.26% avg_sensitivity=83.26%, avg_specificity=80.60% avg_auc=90.03%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.616091 Test loss=0.412959 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.5686343312263489
[5/24] Train loss=0.6115327477455139
[10/24] Train loss=0.6758845448493958
[15/24] Train loss=0.5507550835609436
[20/24] Train loss=0.5288246870040894
Test set avg_accuracy=81.20% avg_sensitivity=83.62%, avg_specificity=80.39% avg_auc=90.04%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.616270 Test loss=0.416500 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.5641005039215088
[5/24] Train loss=0.5974767208099365
[10/24] Train loss=0.6658451557159424
[15/24] Train loss=0.5398259162902832
[20/24] Train loss=0.5205437541007996
Test set avg_accuracy=80.64% avg_sensitivity=84.45%, avg_specificity=79.37% avg_auc=90.01%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.614435 Test loss=0.427666 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.5762976408004761
[5/24] Train loss=0.6083782315254211
[10/24] Train loss=0.6640294194221497
[15/24] Train loss=0.5563533902168274
[20/24] Train loss=0.5438971519470215
Test set avg_accuracy=80.39% avg_sensitivity=85.39%, avg_specificity=78.73% avg_auc=90.08%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.616130 Test loss=0.433774 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.5803360939025879
[5/24] Train loss=0.5927844643592834
[10/24] Train loss=0.6581695079803467
[15/24] Train loss=0.5528001189231873
[20/24] Train loss=0.5440634489059448
Test set avg_accuracy=80.70% avg_sensitivity=85.08%, avg_specificity=79.25% avg_auc=90.14%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.612868 Test loss=0.429129 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.5832927823066711
[5/24] Train loss=0.596950352191925
[10/24] Train loss=0.6564124226570129
[15/24] Train loss=0.558643639087677
[20/24] Train loss=0.5483534336090088
Test set avg_accuracy=81.18% avg_sensitivity=83.78%, avg_specificity=80.32% avg_auc=90.18%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.614568 Test loss=0.418482 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.5770106315612793
[5/24] Train loss=0.5950241684913635
[10/24] Train loss=0.664457380771637
[15/24] Train loss=0.5582822561264038
[20/24] Train loss=0.5318263173103333
Test set avg_accuracy=81.15% avg_sensitivity=83.52%, avg_specificity=80.36% avg_auc=90.12%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.609605 Test loss=0.420350 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.5746243000030518
[5/24] Train loss=0.5892599821090698
[10/24] Train loss=0.6567111015319824
[15/24] Train loss=0.5629002451896667
[20/24] Train loss=0.5393550992012024
Test set avg_accuracy=81.45% avg_sensitivity=83.46%, avg_specificity=80.77% avg_auc=90.23%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.606443 Test loss=0.414406 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.5797991752624512
[5/24] Train loss=0.5817234516143799
[10/24] Train loss=0.6689113974571228
[15/24] Train loss=0.5535376667976379
[20/24] Train loss=0.5362818837165833
Test set avg_accuracy=81.50% avg_sensitivity=83.41%, avg_specificity=80.86% avg_auc=90.24%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.605775 Test loss=0.412582 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.5714741945266724
[5/24] Train loss=0.5872476100921631
[10/24] Train loss=0.6491705775260925
[15/24] Train loss=0.5544806718826294
[20/24] Train loss=0.5362089276313782
Test set avg_accuracy=81.85% avg_sensitivity=82.58%, avg_specificity=81.61% avg_auc=90.27%
Best model saved!! Metric=10.304725526255694!!
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.601676 Test loss=0.403154 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.5665717124938965
[5/24] Train loss=0.5864194631576538
[10/24] Train loss=0.663300096988678
[15/24] Train loss=0.5541610717773438
[20/24] Train loss=0.524795413017273
Test set avg_accuracy=81.91% avg_sensitivity=82.52%, avg_specificity=81.71% avg_auc=90.28%
Best model saved!! Metric=10.429172517305915!!
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.602714 Test loss=0.401101 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.5611656308174133
[5/24] Train loss=0.5775389671325684
[10/24] Train loss=0.6593208909034729
[15/24] Train loss=0.5453794002532959
[20/24] Train loss=0.5226820111274719
Test set avg_accuracy=81.82% avg_sensitivity=82.73%, avg_specificity=81.52% avg_auc=90.24%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.600263 Test loss=0.403262 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.5645444393157959
[5/24] Train loss=0.5763819217681885
[10/24] Train loss=0.6454657316207886
[15/24] Train loss=0.5439491271972656
[20/24] Train loss=0.5291566252708435
Test set avg_accuracy=81.81% avg_sensitivity=82.32%, avg_specificity=81.64% avg_auc=90.27%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.602111 Test loss=0.400762 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.5631594657897949
[5/24] Train loss=0.5830956101417542
[10/24] Train loss=0.6495167016983032
[15/24] Train loss=0.5418276786804199
[20/24] Train loss=0.5245301723480225
Test set avg_accuracy=81.85% avg_sensitivity=82.89%, avg_specificity=81.50% avg_auc=90.28%
Best model saved!! Metric=10.516973881587816!!
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.600183 Test loss=0.403133 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.5648841261863708
[5/24] Train loss=0.5872055292129517
[10/24] Train loss=0.6499693989753723
[15/24] Train loss=0.5532464385032654
[20/24] Train loss=0.5237444639205933
Test set avg_accuracy=81.86% avg_sensitivity=82.32%, avg_specificity=81.71% avg_auc=90.29%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.597334 Test loss=0.399661 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.5581892728805542
[5/24] Train loss=0.577785074710846
[10/24] Train loss=0.6578490734100342
[15/24] Train loss=0.5469963550567627
[20/24] Train loss=0.5253999829292297
Test set avg_accuracy=81.88% avg_sensitivity=82.58%, avg_specificity=81.64% avg_auc=90.27%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.598872 Test loss=0.401895 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.5537223815917969
[5/24] Train loss=0.5727388262748718
[10/24] Train loss=0.6492672562599182
[15/24] Train loss=0.5449367761611938
[20/24] Train loss=0.517876386642456
Test set avg_accuracy=81.76% avg_sensitivity=82.99%, avg_specificity=81.35% avg_auc=90.30%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.597548 Test loss=0.404669 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.5505752563476562
[5/24] Train loss=0.5842792987823486
[10/24] Train loss=0.661492109298706
[15/24] Train loss=0.5464847683906555
[20/24] Train loss=0.5128766298294067
Test set avg_accuracy=81.73% avg_sensitivity=82.89%, avg_specificity=81.35% avg_auc=90.30%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.595962 Test loss=0.403144 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.5577995181083679
[5/24] Train loss=0.5810645222663879
[10/24] Train loss=0.6615129113197327
[15/24] Train loss=0.5468810796737671
[20/24] Train loss=0.513230562210083
Test set avg_accuracy=81.73% avg_sensitivity=82.68%, avg_specificity=81.42% avg_auc=90.30%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.597449 Test loss=0.402507 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.5550182461738586
[5/24] Train loss=0.5755215287208557
[10/24] Train loss=0.6489155888557434
[15/24] Train loss=0.5473854541778564
[20/24] Train loss=0.5157076120376587
Test set avg_accuracy=81.64% avg_sensitivity=83.46%, avg_specificity=81.03% avg_auc=90.30%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.596751 Test loss=0.409248 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.5625047087669373
[5/24] Train loss=0.5825879573822021
[10/24] Train loss=0.64423006772995
[15/24] Train loss=0.5424256324768066
[20/24] Train loss=0.5221230983734131
Test set avg_accuracy=81.55% avg_sensitivity=83.93%, avg_specificity=80.76% avg_auc=90.30%
Best model saved!! Metric=10.538426610883661!!
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.598771 Test loss=0.411817 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.5677542686462402
[5/24] Train loss=0.5842646360397339
[10/24] Train loss=0.6543547511100769
[15/24] Train loss=0.5378704071044922
[20/24] Train loss=0.5200238823890686
Test set avg_accuracy=81.55% avg_sensitivity=84.04%, avg_specificity=80.72% avg_auc=90.30%
Best model saved!! Metric=10.604485782993336!!
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.599312 Test loss=0.411503 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.5600736141204834
[5/24] Train loss=0.5618118643760681
[10/24] Train loss=0.65728759765625
[15/24] Train loss=0.5404419302940369
[20/24] Train loss=0.519035279750824
Test set avg_accuracy=81.37% avg_sensitivity=84.45%, avg_specificity=80.34% avg_auc=90.26%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.597125 Test loss=0.417324 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.5561918020248413
[5/24] Train loss=0.5639551877975464
[10/24] Train loss=0.6527096629142761
[15/24] Train loss=0.5328373312950134
[20/24] Train loss=0.5188661813735962
Test set avg_accuracy=81.33% avg_sensitivity=84.45%, avg_specificity=80.29% avg_auc=90.26%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.596775 Test loss=0.417340 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.5686880946159363
[5/24] Train loss=0.5694831013679504
[10/24] Train loss=0.650100588798523
[15/24] Train loss=0.5356423258781433
[20/24] Train loss=0.5150226354598999
Test set avg_accuracy=81.74% avg_sensitivity=83.72%, avg_specificity=81.09% avg_auc=90.28%
Best model saved!! Metric=10.831551581946556!!
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.595494 Test loss=0.408434 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.5520370602607727
[5/24] Train loss=0.5670762658119202
[10/24] Train loss=0.6503642201423645
[15/24] Train loss=0.534397542476654
[20/24] Train loss=0.5164225101470947
Test set avg_accuracy=81.86% avg_sensitivity=82.42%, avg_specificity=81.68% avg_auc=90.29%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.596519 Test loss=0.400022 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.5338677763938904
[5/24] Train loss=0.5625782012939453
[10/24] Train loss=0.6473509669303894
[15/24] Train loss=0.5360100269317627
[20/24] Train loss=0.5235476493835449
Test set avg_accuracy=82.11% avg_sensitivity=81.27%, avg_specificity=82.39% avg_auc=90.30%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.593450 Test loss=0.392877 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.5460286140441895
[5/24] Train loss=0.573247492313385
[10/24] Train loss=0.653832197189331
[15/24] Train loss=0.5427023768424988
[20/24] Train loss=0.5346473455429077
Test set avg_accuracy=82.19% avg_sensitivity=81.22%, avg_specificity=82.51% avg_auc=90.31%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.593870 Test loss=0.391307 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.5608043670654297
[5/24] Train loss=0.5762325525283813
[10/24] Train loss=0.6477589011192322
[15/24] Train loss=0.5209264159202576
[20/24] Train loss=0.5221545100212097
Test set avg_accuracy=82.06% avg_sensitivity=81.85%, avg_specificity=82.13% avg_auc=90.30%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.592994 Test loss=0.394869 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.5571411848068237
[5/24] Train loss=0.570795476436615
[10/24] Train loss=0.6597990989685059
[15/24] Train loss=0.5320267081260681
[20/24] Train loss=0.5225381255149841
Test set avg_accuracy=82.02% avg_sensitivity=81.59%, avg_specificity=82.16% avg_auc=90.31%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.592935 Test loss=0.394177 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.5502012968063354
[5/24] Train loss=0.5638362169265747
[10/24] Train loss=0.6432247757911682
[15/24] Train loss=0.5288829803466797
[20/24] Train loss=0.5186310410499573
Test set avg_accuracy=82.03% avg_sensitivity=81.69%, avg_specificity=82.14% avg_auc=90.31%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.591609 Test loss=0.395170 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.546442985534668
[5/24] Train loss=0.5793756246566772
[10/24] Train loss=0.6457439661026001
[15/24] Train loss=0.532211422920227
[20/24] Train loss=0.5175778269767761
Test set avg_accuracy=82.10% avg_sensitivity=81.85%, avg_specificity=82.18% avg_auc=90.31%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.592905 Test loss=0.394807 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.5440706014633179
[5/24] Train loss=0.56902015209198
[10/24] Train loss=0.6367465257644653
[15/24] Train loss=0.531631588935852
[20/24] Train loss=0.5161876678466797
Test set avg_accuracy=82.10% avg_sensitivity=81.69%, avg_specificity=82.23% avg_auc=90.31%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.590350 Test loss=0.393863 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.5525369048118591
[5/24] Train loss=0.5720400810241699
[10/24] Train loss=0.6463710069656372
[15/24] Train loss=0.536865234375
[20/24] Train loss=0.5085729956626892
Test set avg_accuracy=82.02% avg_sensitivity=81.79%, avg_specificity=82.09% avg_auc=90.31%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.593584 Test loss=0.395262 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.5632648468017578
[5/24] Train loss=0.5713881850242615
[10/24] Train loss=0.6434547901153564
[15/24] Train loss=0.5246987342834473
[20/24] Train loss=0.5187655687332153
Test set avg_accuracy=82.04% avg_sensitivity=81.74%, avg_specificity=82.14% avg_auc=90.31%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.590449 Test loss=0.394420 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.5555309653282166
[5/24] Train loss=0.5796236991882324
[10/24] Train loss=0.6566975712776184
[15/24] Train loss=0.5392921566963196
[20/24] Train loss=0.5199201703071594
Test set avg_accuracy=82.03% avg_sensitivity=81.74%, avg_specificity=82.13% avg_auc=90.31%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.594641 Test loss=0.394421 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.5415118336677551
[5/24] Train loss=0.5785651803016663
[10/24] Train loss=0.6431050896644592
[15/24] Train loss=0.5285488367080688
[20/24] Train loss=0.511765718460083
Test set avg_accuracy=82.08% avg_sensitivity=81.74%, avg_specificity=82.20% avg_auc=90.31%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.590812 Test loss=0.394182 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.5580568313598633
[5/24] Train loss=0.5761098265647888
[10/24] Train loss=0.6567360162734985
[15/24] Train loss=0.5320430397987366
[20/24] Train loss=0.5222134590148926
Test set avg_accuracy=82.07% avg_sensitivity=81.74%, avg_specificity=82.18% avg_auc=90.31%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.592113 Test loss=0.394332 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.5561140775680542
[5/24] Train loss=0.5787917375564575
[10/24] Train loss=0.6361496448516846
[15/24] Train loss=0.5311375260353088
[20/24] Train loss=0.5124125480651855
Test set avg_accuracy=82.07% avg_sensitivity=81.74%, avg_specificity=82.18% avg_auc=90.31%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.591805 Test loss=0.394381 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.5432592630386353
[5/24] Train loss=0.5722249150276184
[10/24] Train loss=0.6414168477058411
[15/24] Train loss=0.532782793045044
[20/24] Train loss=0.5109151005744934
Test set avg_accuracy=82.07% avg_sensitivity=81.74%, avg_specificity=82.18% avg_auc=90.31%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.590064 Test loss=0.394373 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=81.74% sen=83.72%, spe=81.09%, auc=90.28%!
Fold[2] Avg_overlap=0.61%(±0.22788730130585125)
[0/24] Train loss=1.7235032320022583
[5/24] Train loss=1.5298142433166504
[10/24] Train loss=1.465254783630371
[15/24] Train loss=1.4493328332901
[20/24] Train loss=1.4522662162780762
Test set avg_accuracy=48.96% avg_sensitivity=60.33%, avg_specificity=44.65% avg_auc=55.74%
Best model saved!! Metric=-116.31861579325036!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=1.492727 Test loss=0.702540 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.4414409399032593
[5/24] Train loss=1.4165771007537842
[10/24] Train loss=1.4200562238693237
[15/24] Train loss=1.4119346141815186
[20/24] Train loss=1.4034026861190796
Test set avg_accuracy=61.35% avg_sensitivity=56.64%, avg_specificity=63.14% avg_auc=63.89%
Best model saved!! Metric=-80.98179443163414!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=1.409688 Test loss=0.668679 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3992822170257568
[5/24] Train loss=1.3755090236663818
[10/24] Train loss=1.3864339590072632
[15/24] Train loss=1.377340316772461
[20/24] Train loss=1.3643261194229126
Test set avg_accuracy=65.48% avg_sensitivity=60.33%, avg_specificity=67.43% avg_auc=69.14%
Best model saved!! Metric=-63.60982088601627!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=1.379358 Test loss=0.659146 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.3668795824050903
[5/24] Train loss=1.351885437965393
[10/24] Train loss=1.3764554262161255
[15/24] Train loss=1.343749761581421
[20/24] Train loss=1.345467448234558
Test set avg_accuracy=68.54% avg_sensitivity=60.57%, avg_specificity=71.56% avg_auc=72.83%
Best model saved!! Metric=-52.49520571159535!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=1.352578 Test loss=0.642239 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.333703637123108
[5/24] Train loss=1.3321200609207153
[10/24] Train loss=1.345668911933899
[15/24] Train loss=1.3122286796569824
[20/24] Train loss=1.3065180778503418
Test set avg_accuracy=71.55% avg_sensitivity=64.98%, avg_specificity=74.04% avg_auc=76.28%
Best model saved!! Metric=-39.154835586538994!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=1.326534 Test loss=0.629821 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.2999706268310547
[5/24] Train loss=1.2995282411575317
[10/24] Train loss=1.3126211166381836
[15/24] Train loss=1.2845990657806396
[20/24] Train loss=1.2753634452819824
Test set avg_accuracy=73.68% avg_sensitivity=71.80%, avg_specificity=74.40% avg_auc=79.58%
Best model saved!! Metric=-26.533045575874766!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=1.296655 Test loss=0.614519 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.2680894136428833
[5/24] Train loss=1.2683618068695068
[10/24] Train loss=1.2875361442565918
[15/24] Train loss=1.2404180765151978
[20/24] Train loss=1.2150890827178955
Test set avg_accuracy=75.56% avg_sensitivity=75.26%, avg_specificity=75.67% avg_auc=82.21%
Best model saved!! Metric=-17.295626727439966!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=1.254540 Test loss=0.591295 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.213489055633545
[5/24] Train loss=1.2148879766464233
[10/24] Train loss=1.2274326086044312
[15/24] Train loss=1.1810170412063599
[20/24] Train loss=1.1573052406311035
Test set avg_accuracy=77.03% avg_sensitivity=76.21%, avg_specificity=77.34% avg_auc=83.60%
Best model saved!! Metric=-11.817848505024386!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=1.208264 Test loss=0.564445 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.1692986488342285
[5/24] Train loss=1.1585742235183716
[10/24] Train loss=1.183904767036438
[15/24] Train loss=1.1285994052886963
[20/24] Train loss=1.1269499063491821
Test set avg_accuracy=77.58% avg_sensitivity=77.91%, avg_specificity=77.45% avg_auc=84.59%
Best model saved!! Metric=-8.461563752371802!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=1.159577 Test loss=0.540136 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.0997480154037476
[5/24] Train loss=1.115500807762146
[10/24] Train loss=1.1642228364944458
[15/24] Train loss=1.0921889543533325
[20/24] Train loss=1.0528632402420044
Test set avg_accuracy=77.62% avg_sensitivity=80.24%, avg_specificity=76.62% avg_auc=85.35%
Best model saved!! Metric=-6.1679597427612265!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=1.113389 Test loss=0.519887 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.0476877689361572
[5/24] Train loss=1.0820430517196655
[10/24] Train loss=1.1191500425338745
[15/24] Train loss=1.0443153381347656
[20/24] Train loss=1.0004825592041016
Test set avg_accuracy=77.34% avg_sensitivity=82.27%, avg_specificity=75.48% avg_auc=85.98%
Best model saved!! Metric=-4.924358604831227!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=1.064987 Test loss=0.510225 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.0146433115005493
[5/24] Train loss=1.0404341220855713
[10/24] Train loss=1.0910530090332031
[15/24] Train loss=1.0123742818832397
[20/24] Train loss=0.9752897024154663
Test set avg_accuracy=76.77% avg_sensitivity=85.92%, avg_specificity=73.30% avg_auc=86.66%
Best model saved!! Metric=-3.3458122034369495!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=1.034852 Test loss=0.514117 Current lr=[5.97283087248885e-05]

[0/24] Train loss=1.005669116973877
[5/24] Train loss=1.0336267948150635
[10/24] Train loss=1.0601725578308105
[15/24] Train loss=0.9874944090843201
[20/24] Train loss=0.9413959383964539
Test set avg_accuracy=76.29% avg_sensitivity=87.68%, avg_specificity=71.97% avg_auc=87.09%
Best model saved!! Metric=-2.970711849723898!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=1.007856 Test loss=0.513543 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.9724106192588806
[5/24] Train loss=1.0434012413024902
[10/24] Train loss=1.044050693511963
[15/24] Train loss=0.9596101641654968
[20/24] Train loss=0.9105772972106934
Test set avg_accuracy=76.89% avg_sensitivity=87.49%, avg_specificity=72.87% avg_auc=87.67%
Best model saved!! Metric=-1.0859979027868718!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.986249 Test loss=0.497594 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.9631866812705994
[5/24] Train loss=0.9973090887069702
[10/24] Train loss=1.027490496635437
[15/24] Train loss=1.0034109354019165
[20/24] Train loss=0.8866497278213501
Test set avg_accuracy=78.68% avg_sensitivity=83.93%, avg_specificity=76.70% avg_auc=88.23%
Best model saved!! Metric=1.5451066785008152!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.965629 Test loss=0.455049 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.9077624678611755
[5/24] Train loss=0.952406108379364
[10/24] Train loss=0.9972341656684875
[15/24] Train loss=0.917970597743988
[20/24] Train loss=0.8613449931144714
Test set avg_accuracy=77.96% avg_sensitivity=86.54%, avg_specificity=74.70% avg_auc=88.83%
Best model saved!! Metric=2.024806910504253!!
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.935814 Test loss=0.463917 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.8901916146278381
[5/24] Train loss=0.965546190738678
[10/24] Train loss=0.9700804352760315
[15/24] Train loss=0.9137359261512756
[20/24] Train loss=0.8401036858558655
Test set avg_accuracy=77.92% avg_sensitivity=87.68%, avg_specificity=74.22% avg_auc=89.32%
Best model saved!! Metric=3.1364884948423537!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.913712 Test loss=0.463349 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.8868780136108398
[5/24] Train loss=0.9490893483161926
[10/24] Train loss=0.953986406326294
[15/24] Train loss=0.8756299614906311
[20/24] Train loss=0.8195938467979431
Test set avg_accuracy=79.53% avg_sensitivity=85.55%, avg_specificity=77.25% avg_auc=89.72%
Best model saved!! Metric=6.048182279391128!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.895761 Test loss=0.437205 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.8635237812995911
[5/24] Train loss=0.910611629486084
[10/24] Train loss=0.9303773641586304
[15/24] Train loss=0.842143177986145
[20/24] Train loss=0.8005362153053284
Test set avg_accuracy=80.66% avg_sensitivity=83.51%, avg_specificity=79.59% avg_auc=90.04%
Best model saved!! Metric=7.793551893926505!!
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.875886 Test loss=0.412213 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.820959210395813
[5/24] Train loss=0.8738168478012085
[10/24] Train loss=0.9044984579086304
[15/24] Train loss=0.8556472063064575
[20/24] Train loss=0.7649917006492615
Test set avg_accuracy=80.31% avg_sensitivity=84.83%, avg_specificity=78.60% avg_auc=90.15%
Best model saved!! Metric=7.897237975103607!!
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.854358 Test loss=0.420294 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.8147306442260742
[5/24] Train loss=0.8799616694450378
[10/24] Train loss=0.8985615968704224
[15/24] Train loss=0.859455406665802
[20/24] Train loss=0.7552170157432556
Test set avg_accuracy=79.80% avg_sensitivity=86.02%, avg_specificity=77.45% avg_auc=90.43%
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.844726 Test loss=0.425383 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.8050757646560669
[5/24] Train loss=0.8544358015060425
[10/24] Train loss=0.8718183040618896
[15/24] Train loss=0.8652388453483582
[20/24] Train loss=0.7554850578308105
Test set avg_accuracy=80.13% avg_sensitivity=85.92%, avg_specificity=77.94% avg_auc=90.51%
Best model saved!! Metric=8.503297070389493!!
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.834257 Test loss=0.420574 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.790016233921051
[5/24] Train loss=0.823939323425293
[10/24] Train loss=0.889692485332489
[15/24] Train loss=0.8724699020385742
[20/24] Train loss=0.7593022584915161
Test set avg_accuracy=80.14% avg_sensitivity=85.83%, avg_specificity=77.99% avg_auc=90.56%
Best model saved!! Metric=8.522222929801941!!
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.830265 Test loss=0.422213 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.7773451209068298
[5/24] Train loss=0.8384079337120056
[10/24] Train loss=0.8722070455551147
[15/24] Train loss=0.8976446986198425
[20/24] Train loss=0.7472827434539795
Test set avg_accuracy=78.84% avg_sensitivity=87.44%, avg_specificity=75.58% avg_auc=90.67%
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.827496 Test loss=0.439395 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.8057223558425903
[5/24] Train loss=0.8259674310684204
[10/24] Train loss=0.8596325516700745
[15/24] Train loss=0.8916579484939575
[20/24] Train loss=0.7520247101783752
Test set avg_accuracy=79.87% avg_sensitivity=86.68%, avg_specificity=77.29% avg_auc=90.73%
Best model saved!! Metric=8.570354090620299!!
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.818128 Test loss=0.423919 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.7664682269096375
[5/24] Train loss=0.8099242448806763
[10/24] Train loss=0.8628038167953491
[15/24] Train loss=0.8783572316169739
[20/24] Train loss=0.7217885851860046
Test set avg_accuracy=80.53% avg_sensitivity=85.55%, avg_specificity=78.64% avg_auc=90.99%
Best model saved!! Metric=9.703440729754291!!
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.803952 Test loss=0.410121 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.7496072053909302
[5/24] Train loss=0.8131230473518372
[10/24] Train loss=0.8576442003250122
[15/24] Train loss=0.8243776559829712
[20/24] Train loss=0.713846743106842
Test set avg_accuracy=81.77% avg_sensitivity=84.22%, avg_specificity=80.84% avg_auc=91.14%
Best model saved!! Metric=11.972820961708095!!
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.797696 Test loss=0.389711 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.7376379370689392
[5/24] Train loss=0.8002690076828003
[10/24] Train loss=0.8755912184715271
[15/24] Train loss=0.8029385209083557
[20/24] Train loss=0.7080221176147461
Test set avg_accuracy=82.93% avg_sensitivity=82.18%, avg_specificity=83.21% avg_auc=91.27%
Best model saved!! Metric=13.594062494682092!!
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.791955 Test loss=0.371615 Current lr=[0.000210185142098938]

[0/24] Train loss=0.730491042137146
[5/24] Train loss=0.7948452234268188
[10/24] Train loss=0.8523793816566467
[15/24] Train loss=0.7914929986000061
[20/24] Train loss=0.6763232946395874
Test set avg_accuracy=83.80% avg_sensitivity=81.00%, avg_specificity=84.87% avg_auc=91.29%
Best model saved!! Metric=14.949236753398509!!
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.779274 Test loss=0.361179 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.7246002554893494
[5/24] Train loss=0.8233166933059692
[10/24] Train loss=0.8463444113731384
[15/24] Train loss=0.784564733505249
[20/24] Train loss=0.6689706444740295
Test set avg_accuracy=83.70% avg_sensitivity=81.00%, avg_specificity=84.72% avg_auc=91.33%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.775254 Test loss=0.358811 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.7042582631111145
[5/24] Train loss=0.8212587833404541
[10/24] Train loss=0.8475156426429749
[15/24] Train loss=0.7960337996482849
[20/24] Train loss=0.6771289110183716
Test set avg_accuracy=84.21% avg_sensitivity=79.91%, avg_specificity=85.83% avg_auc=91.33%
Best model saved!! Metric=15.275249362026031!!
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.772741 Test loss=0.352984 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.7096182107925415
[5/24] Train loss=0.8368737697601318
[10/24] Train loss=0.8486055135726929
[15/24] Train loss=0.8149645328521729
[20/24] Train loss=0.6721176505088806
Test set avg_accuracy=83.91% avg_sensitivity=79.05%, avg_specificity=85.75% avg_auc=91.43%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.771812 Test loss=0.350903 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.698838472366333
[5/24] Train loss=0.8230860829353333
[10/24] Train loss=0.8371424078941345
[15/24] Train loss=0.7937089800834656
[20/24] Train loss=0.6590880155563354
Test set avg_accuracy=84.48% avg_sensitivity=78.91%, avg_specificity=86.59% avg_auc=91.45%
Best model saved!! Metric=15.425076968129332!!
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.762077 Test loss=0.345207 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.6965813040733337
[5/24] Train loss=0.8342316150665283
[10/24] Train loss=0.8361389636993408
[15/24] Train loss=0.8037795424461365
[20/24] Train loss=0.6629809141159058
Test set avg_accuracy=84.09% avg_sensitivity=80.43%, avg_specificity=85.48% avg_auc=91.52%
Best model saved!! Metric=15.512665485023305!!
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.761708 Test loss=0.352117 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.7021071314811707
[5/24] Train loss=0.8383408188819885
[10/24] Train loss=0.8333701491355896
[15/24] Train loss=0.8147724866867065
[20/24] Train loss=0.6630724668502808
Test set avg_accuracy=84.39% avg_sensitivity=80.76%, avg_specificity=85.76% avg_auc=91.54%
Best model saved!! Metric=16.451716835103127!!
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.755863 Test loss=0.350504 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.704998791217804
[5/24] Train loss=0.8077915906906128
[10/24] Train loss=0.8402703404426575
[15/24] Train loss=0.7858171463012695
[20/24] Train loss=0.6450392603874207
Test set avg_accuracy=83.98% avg_sensitivity=80.76%, avg_specificity=85.21% avg_auc=91.59%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.751166 Test loss=0.352453 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.6813164353370667
[5/24] Train loss=0.8337201476097107
[10/24] Train loss=0.8251475691795349
[15/24] Train loss=0.7743678092956543
[20/24] Train loss=0.6438087224960327
Test set avg_accuracy=84.22% avg_sensitivity=80.76%, avg_specificity=85.53% avg_auc=91.63%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.745659 Test loss=0.350209 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.6834981441497803
[5/24] Train loss=0.8168874382972717
[10/24] Train loss=0.8160189986228943
[15/24] Train loss=0.7695230841636658
[20/24] Train loss=0.6478870511054993
Test set avg_accuracy=84.24% avg_sensitivity=80.19%, avg_specificity=85.78% avg_auc=91.68%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.740846 Test loss=0.348011 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.6833606958389282
[5/24] Train loss=0.811893880367279
[10/24] Train loss=0.8212578296661377
[15/24] Train loss=0.7895276546478271
[20/24] Train loss=0.6511891484260559
Test set avg_accuracy=84.26% avg_sensitivity=80.57%, avg_specificity=85.66% avg_auc=91.65%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.743965 Test loss=0.349783 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.6823151111602783
[5/24] Train loss=0.8079673051834106
[10/24] Train loss=0.8166146874427795
[15/24] Train loss=0.7770022749900818
[20/24] Train loss=0.6356019377708435
Test set avg_accuracy=83.87% avg_sensitivity=82.09%, avg_specificity=84.54% avg_auc=91.66%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.737014 Test loss=0.355451 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.6782814860343933
[5/24] Train loss=0.8046849370002747
[10/24] Train loss=0.8312733173370361
[15/24] Train loss=0.7708520889282227
[20/24] Train loss=0.6298887133598328
Test set avg_accuracy=84.32% avg_sensitivity=80.81%, avg_specificity=85.66% avg_auc=91.74%
Best model saved!! Metric=16.522947297925867!!
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.733244 Test loss=0.347927 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.6761958003044128
[5/24] Train loss=0.7874699234962463
[10/24] Train loss=0.8159336447715759
[15/24] Train loss=0.7746726274490356
[20/24] Train loss=0.635722279548645
Test set avg_accuracy=84.24% avg_sensitivity=81.04%, avg_specificity=85.46% avg_auc=91.70%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.728797 Test loss=0.348224 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.6798944473266602
[5/24] Train loss=0.7972290515899658
[10/24] Train loss=0.8107098937034607
[15/24] Train loss=0.7733445763587952
[20/24] Train loss=0.6333923935890198
Test set avg_accuracy=83.68% avg_sensitivity=82.56%, avg_specificity=84.11% avg_auc=91.71%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.725661 Test loss=0.357002 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.6677455902099609
[5/24] Train loss=0.7873665690422058
[10/24] Train loss=0.8129597306251526
[15/24] Train loss=0.7555186152458191
[20/24] Train loss=0.6174033880233765
Test set avg_accuracy=83.79% avg_sensitivity=82.51%, avg_specificity=84.27% avg_auc=91.75%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.722749 Test loss=0.354905 Current lr=[0.00029967723776099]

[0/24] Train loss=0.6699974536895752
[5/24] Train loss=0.7681068778038025
[10/24] Train loss=0.8253746032714844
[15/24] Train loss=0.7465686202049255
[20/24] Train loss=0.6230006217956543
Test set avg_accuracy=84.08% avg_sensitivity=81.52%, avg_specificity=85.04% avg_auc=91.70%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.718927 Test loss=0.351299 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.6635528802871704
[5/24] Train loss=0.775607705116272
[10/24] Train loss=0.8120095729827881
[15/24] Train loss=0.7579796314239502
[20/24] Train loss=0.6213489770889282
Test set avg_accuracy=84.40% avg_sensitivity=81.04%, avg_specificity=85.67% avg_auc=91.80%
Best model saved!! Metric=16.92059036611444!!
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.716221 Test loss=0.345428 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.6572844386100769
[5/24] Train loss=0.7859206795692444
[10/24] Train loss=0.7983075976371765
[15/24] Train loss=0.7553033828735352
[20/24] Train loss=0.6106220483779907
Test set avg_accuracy=84.17% avg_sensitivity=82.61%, avg_specificity=84.76% avg_auc=91.85%
Best model saved!! Metric=17.378626471647664!!
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.713854 Test loss=0.352995 Current lr=[0.000299720220882401]

[0/24] Train loss=0.6664081811904907
[5/24] Train loss=0.764691174030304
[10/24] Train loss=0.8113723993301392
[15/24] Train loss=0.7444421648979187
[20/24] Train loss=0.6168126463890076
Test set avg_accuracy=84.14% avg_sensitivity=82.75%, avg_specificity=84.67% avg_auc=91.82%
Best model saved!! Metric=17.379616891225012!!
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.709767 Test loss=0.354302 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.670283317565918
[5/24] Train loss=0.7520879507064819
[10/24] Train loss=0.8032649159431458
[15/24] Train loss=0.7404375076293945
[20/24] Train loss=0.6139037013053894
Test set avg_accuracy=84.22% avg_sensitivity=82.70%, avg_specificity=84.79% avg_auc=91.90%
Best model saved!! Metric=17.61131085835595!!
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.708053 Test loss=0.352143 Current lr=[0.000298904600941902]

[0/24] Train loss=0.6559499502182007
[5/24] Train loss=0.7680025100708008
[10/24] Train loss=0.806651771068573
[15/24] Train loss=0.7497884035110474
[20/24] Train loss=0.6125160455703735
Test set avg_accuracy=83.52% avg_sensitivity=83.74%, avg_specificity=83.43% avg_auc=91.85%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.708147 Test loss=0.359359 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.6647180318832397
[5/24] Train loss=0.7611052393913269
[10/24] Train loss=0.803712010383606
[15/24] Train loss=0.7397872805595398
[20/24] Train loss=0.6171990633010864
Test set avg_accuracy=84.10% avg_sensitivity=83.18%, avg_specificity=84.45% avg_auc=91.88%
Best model saved!! Metric=17.611819717490448!!
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.703573 Test loss=0.353675 Current lr=[0.000297555943323901]

[0/24] Train loss=0.6656730771064758
[5/24] Train loss=0.7421090602874756
[10/24] Train loss=0.8072896599769592
[15/24] Train loss=0.739561140537262
[20/24] Train loss=0.6037516593933105
Test set avg_accuracy=84.40% avg_sensitivity=82.27%, avg_specificity=85.21% avg_auc=91.95%
Best model saved!! Metric=17.829938856248646!!
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.701977 Test loss=0.348106 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.6578525304794312
[5/24] Train loss=0.766264021396637
[10/24] Train loss=0.8134545683860779
[15/24] Train loss=0.7280418276786804
[20/24] Train loss=0.6088852286338806
Test set avg_accuracy=83.97% avg_sensitivity=82.89%, avg_specificity=84.38% avg_auc=91.90%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.701601 Test loss=0.353217 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.6458096504211426
[5/24] Train loss=0.7528871297836304
[10/24] Train loss=0.8108853697776794
[15/24] Train loss=0.7416896820068359
[20/24] Train loss=0.5974337458610535
Test set avg_accuracy=84.40% avg_sensitivity=81.94%, avg_specificity=85.33% avg_auc=91.93%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.697925 Test loss=0.346790 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.6585876941680908
[5/24] Train loss=0.7676144242286682
[10/24] Train loss=0.8001294732093811
[15/24] Train loss=0.7277351021766663
[20/24] Train loss=0.59501051902771
Test set avg_accuracy=84.08% avg_sensitivity=82.94%, avg_specificity=84.51% avg_auc=91.94%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.696372 Test loss=0.352449 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.6536224484443665
[5/24] Train loss=0.744615375995636
[10/24] Train loss=0.819821298122406
[15/24] Train loss=0.724255383014679
[20/24] Train loss=0.5967252254486084
Test set avg_accuracy=83.93% avg_sensitivity=83.03%, avg_specificity=84.27% avg_auc=91.92%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.693103 Test loss=0.353825 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.654941737651825
[5/24] Train loss=0.7237006425857544
[10/24] Train loss=0.8047341108322144
[15/24] Train loss=0.7016404867172241
[20/24] Train loss=0.5966646075248718
Test set avg_accuracy=84.06% avg_sensitivity=82.75%, avg_specificity=84.56% avg_auc=91.98%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.687767 Test loss=0.351509 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.6487460732460022
[5/24] Train loss=0.7390521168708801
[10/24] Train loss=0.8117561936378479
[15/24] Train loss=0.723616361618042
[20/24] Train loss=0.595852792263031
Test set avg_accuracy=84.11% avg_sensitivity=82.84%, avg_specificity=84.60% avg_auc=92.01%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.690181 Test loss=0.350781 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.6318100094795227
[5/24] Train loss=0.7474825978279114
[10/24] Train loss=0.784430205821991
[15/24] Train loss=0.7539803981781006
[20/24] Train loss=0.6048850417137146
Test set avg_accuracy=83.80% avg_sensitivity=82.80%, avg_specificity=84.18% avg_auc=92.00%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.689700 Test loss=0.352216 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.6394414305686951
[5/24] Train loss=0.7386064529418945
[10/24] Train loss=0.8009209036827087
[15/24] Train loss=0.7023502588272095
[20/24] Train loss=0.5890359282493591
Test set avg_accuracy=83.50% avg_sensitivity=83.51%, avg_specificity=83.50% avg_auc=92.01%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.683288 Test loss=0.358364 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.6529264450073242
[5/24] Train loss=0.7285621762275696
[10/24] Train loss=0.8103934526443481
[15/24] Train loss=0.6966386437416077
[20/24] Train loss=0.5909975171089172
Test set avg_accuracy=84.13% avg_sensitivity=82.75%, avg_specificity=84.65% avg_auc=92.02%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.680952 Test loss=0.349114 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.6458126306533813
[5/24] Train loss=0.7238112688064575
[10/24] Train loss=0.7900645136833191
[15/24] Train loss=0.7032971978187561
[20/24] Train loss=0.5880642533302307
Test set avg_accuracy=84.38% avg_sensitivity=82.18%, avg_specificity=85.21% avg_auc=92.03%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.678138 Test loss=0.345691 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.6426854133605957
[5/24] Train loss=0.7459926009178162
[10/24] Train loss=0.7934809923171997
[15/24] Train loss=0.7190850973129272
[20/24] Train loss=0.5921993851661682
Test set avg_accuracy=83.89% avg_sensitivity=83.51%, avg_specificity=84.04% avg_auc=92.01%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.680653 Test loss=0.354095 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.6415683031082153
[5/24] Train loss=0.7209493517875671
[10/24] Train loss=0.7901498675346375
[15/24] Train loss=0.7033656239509583
[20/24] Train loss=0.5814144611358643
Test set avg_accuracy=83.80% avg_sensitivity=83.65%, avg_specificity=83.86% avg_auc=92.08%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.677279 Test loss=0.353345 Current lr=[0.000276307469034998]

[0/24] Train loss=0.6373674273490906
[5/24] Train loss=0.7032760977745056
[10/24] Train loss=0.7872970700263977
[15/24] Train loss=0.6905719637870789
[20/24] Train loss=0.5836774706840515
Test set avg_accuracy=84.09% avg_sensitivity=83.41%, avg_specificity=84.34% avg_auc=92.06%
Best model saved!! Metric=17.905162528255914!!
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.670542 Test loss=0.351320 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.6372089982032776
[5/24] Train loss=0.7109652757644653
[10/24] Train loss=0.7977029085159302
[15/24] Train loss=0.7024465203285217
[20/24] Train loss=0.5879241228103638
Test set avg_accuracy=84.38% avg_sensitivity=82.04%, avg_specificity=85.26% avg_auc=92.05%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.671641 Test loss=0.342950 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.6418983936309814
[5/24] Train loss=0.721516489982605
[10/24] Train loss=0.7835467457771301
[15/24] Train loss=0.6942993998527527
[20/24] Train loss=0.5863803625106812
Test set avg_accuracy=84.26% avg_sensitivity=83.27%, avg_specificity=84.63% avg_auc=92.12%
Best model saved!! Metric=18.27805465712133!!
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.669647 Test loss=0.349722 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.6338763236999512
[5/24] Train loss=0.7228765487670898
[10/24] Train loss=0.7870234847068787
[15/24] Train loss=0.6987771987915039
[20/24] Train loss=0.5850929617881775
Test set avg_accuracy=83.88% avg_sensitivity=83.98%, avg_specificity=83.84% avg_auc=92.07%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.671477 Test loss=0.355758 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.6408627033233643
[5/24] Train loss=0.7073965072631836
[10/24] Train loss=0.797257125377655
[15/24] Train loss=0.6756325364112854
[20/24] Train loss=0.5816074013710022
Test set avg_accuracy=83.74% avg_sensitivity=83.93%, avg_specificity=83.66% avg_auc=92.16%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.665027 Test loss=0.354483 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.6393604874610901
[5/24] Train loss=0.7018898129463196
[10/24] Train loss=0.774272084236145
[15/24] Train loss=0.6806813478469849
[20/24] Train loss=0.570119321346283
Test set avg_accuracy=84.61% avg_sensitivity=81.66%, avg_specificity=85.73% avg_auc=92.15%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.662704 Test loss=0.338694 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.6265827417373657
[5/24] Train loss=0.7137308120727539
[10/24] Train loss=0.7709636092185974
[15/24] Train loss=0.6967585682868958
[20/24] Train loss=0.5746936202049255
Test set avg_accuracy=84.43% avg_sensitivity=83.08%, avg_specificity=84.94% avg_auc=92.14%
Best model saved!! Metric=18.5894290070934!!
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.662650 Test loss=0.345827 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.6260552406311035
[5/24] Train loss=0.7009681463241577
[10/24] Train loss=0.7588055729866028
[15/24] Train loss=0.6995378136634827
[20/24] Train loss=0.566294252872467
Test set avg_accuracy=84.47% avg_sensitivity=82.56%, avg_specificity=85.19% avg_auc=92.13%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.659212 Test loss=0.345010 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.6253275275230408
[5/24] Train loss=0.701734721660614
[10/24] Train loss=0.7651947140693665
[15/24] Train loss=0.6908329129219055
[20/24] Train loss=0.5698356032371521
Test set avg_accuracy=84.43% avg_sensitivity=82.37%, avg_specificity=85.21% avg_auc=92.07%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.664049 Test loss=0.347229 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.6340359449386597
[5/24] Train loss=0.7153109312057495
[10/24] Train loss=0.7645219564437866
[15/24] Train loss=0.6665129661560059
[20/24] Train loss=0.5686777830123901
Test set avg_accuracy=84.22% avg_sensitivity=83.13%, avg_specificity=84.63% avg_auc=92.08%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.658055 Test loss=0.351578 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.626708447933197
[5/24] Train loss=0.7019380331039429
[10/24] Train loss=0.7773250341415405
[15/24] Train loss=0.6674185991287231
[20/24] Train loss=0.5715835690498352
Test set avg_accuracy=84.19% avg_sensitivity=82.94%, avg_specificity=84.67% avg_auc=92.17%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.655117 Test loss=0.347820 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.6409460306167603
[5/24] Train loss=0.7009234428405762
[10/24] Train loss=0.7665573358535767
[15/24] Train loss=0.6797987818717957
[20/24] Train loss=0.5668689012527466
Test set avg_accuracy=84.71% avg_sensitivity=81.71%, avg_specificity=85.85% avg_auc=92.15%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.652559 Test loss=0.340840 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.6379932761192322
[5/24] Train loss=0.7129822373390198
[10/24] Train loss=0.7597090601921082
[15/24] Train loss=0.6667604446411133
[20/24] Train loss=0.572837233543396
Test set avg_accuracy=84.26% avg_sensitivity=82.37%, avg_specificity=84.97% avg_auc=92.11%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.652358 Test loss=0.346725 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.6183902025222778
[5/24] Train loss=0.6976156830787659
[10/24] Train loss=0.7551334500312805
[15/24] Train loss=0.6655745506286621
[20/24] Train loss=0.5602496862411499
Test set avg_accuracy=84.35% avg_sensitivity=83.22%, avg_specificity=84.78% avg_auc=92.20%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.650464 Test loss=0.347591 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.6114188432693481
[5/24] Train loss=0.6853581666946411
[10/24] Train loss=0.7661244869232178
[15/24] Train loss=0.6535608768463135
[20/24] Train loss=0.56349116563797
Test set avg_accuracy=84.54% avg_sensitivity=82.65%, avg_specificity=85.26% avg_auc=92.18%
Best model saved!! Metric=18.639134141339156!!
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.647046 Test loss=0.342636 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.6296228170394897
[5/24] Train loss=0.6986390948295593
[10/24] Train loss=0.7545942664146423
[15/24] Train loss=0.6730387806892395
[20/24] Train loss=0.5547330379486084
Test set avg_accuracy=84.14% avg_sensitivity=83.13%, avg_specificity=84.52% avg_auc=92.16%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.647864 Test loss=0.348186 Current lr=[0.000224838296036774]

[0/24] Train loss=0.6111864447593689
[5/24] Train loss=0.688446581363678
[10/24] Train loss=0.7500842213630676
[15/24] Train loss=0.6673597693443298
[20/24] Train loss=0.5570661425590515
Test set avg_accuracy=84.31% avg_sensitivity=83.18%, avg_specificity=84.74% avg_auc=92.23%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.645128 Test loss=0.345437 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.6117607355117798
[5/24] Train loss=0.6664019823074341
[10/24] Train loss=0.7526564598083496
[15/24] Train loss=0.64990234375
[20/24] Train loss=0.5596279501914978
Test set avg_accuracy=83.83% avg_sensitivity=84.27%, avg_specificity=83.66% avg_auc=92.26%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.642311 Test loss=0.353616 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.6245829463005066
[5/24] Train loss=0.6767870187759399
[10/24] Train loss=0.7577754259109497
[15/24] Train loss=0.6658520698547363
[20/24] Train loss=0.562897801399231
Test set avg_accuracy=84.21% avg_sensitivity=82.84%, avg_specificity=84.72% avg_auc=92.25%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.645215 Test loss=0.344334 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.6245540976524353
[5/24] Train loss=0.6791865229606628
[10/24] Train loss=0.7514045238494873
[15/24] Train loss=0.6518036723136902
[20/24] Train loss=0.5563237071037292
Test set avg_accuracy=84.00% avg_sensitivity=83.74%, avg_specificity=84.09% avg_auc=92.25%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.642129 Test loss=0.349427 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.6182547807693481
[5/24] Train loss=0.667270839214325
[10/24] Train loss=0.7423299551010132
[15/24] Train loss=0.6460106372833252
[20/24] Train loss=0.564357578754425
Test set avg_accuracy=84.24% avg_sensitivity=82.37%, avg_specificity=84.96% avg_auc=92.15%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.638776 Test loss=0.345144 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.6207563281059265
[5/24] Train loss=0.6911323070526123
[10/24] Train loss=0.7453405261039734
[15/24] Train loss=0.6469541192054749
[20/24] Train loss=0.5647501349449158
Test set avg_accuracy=84.06% avg_sensitivity=83.32%, avg_specificity=84.34% avg_auc=92.23%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.640586 Test loss=0.347575 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.6032224297523499
[5/24] Train loss=0.6800874471664429
[10/24] Train loss=0.7446290254592896
[15/24] Train loss=0.6524741649627686
[20/24] Train loss=0.5527982115745544
Test set avg_accuracy=84.38% avg_sensitivity=82.80%, avg_specificity=84.97% avg_auc=92.23%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.637273 Test loss=0.342855 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.6100412011146545
[5/24] Train loss=0.6730743050575256
[10/24] Train loss=0.7388503551483154
[15/24] Train loss=0.6462314128875732
[20/24] Train loss=0.5519160032272339
Test set avg_accuracy=84.57% avg_sensitivity=81.80%, avg_specificity=85.62% avg_auc=92.18%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.634324 Test loss=0.340361 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.6020659804344177
[5/24] Train loss=0.6727470755577087
[10/24] Train loss=0.7487077116966248
[15/24] Train loss=0.6383492946624756
[20/24] Train loss=0.5589307546615601
Test set avg_accuracy=84.66% avg_sensitivity=81.90%, avg_specificity=85.71% avg_auc=92.13%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.633132 Test loss=0.339694 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.6103774905204773
[5/24] Train loss=0.6569699048995972
[10/24] Train loss=0.7294526696205139
[15/24] Train loss=0.6357119679450989
[20/24] Train loss=0.5591455101966858
Test set avg_accuracy=84.73% avg_sensitivity=81.99%, avg_specificity=85.76% avg_auc=92.18%
Best model saved!! Metric=18.656034025691966!!
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.631051 Test loss=0.338983 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.6127924919128418
[5/24] Train loss=0.6736834645271301
[10/24] Train loss=0.7453157901763916
[15/24] Train loss=0.6245825886726379
[20/24] Train loss=0.5510799288749695
Test set avg_accuracy=85.16% avg_sensitivity=79.86%, avg_specificity=87.16% avg_auc=92.11%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.631116 Test loss=0.331238 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.6086641550064087
[5/24] Train loss=0.6699963808059692
[10/24] Train loss=0.752187967300415
[15/24] Train loss=0.6316522359848022
[20/24] Train loss=0.5490411520004272
Test set avg_accuracy=84.87% avg_sensitivity=81.09%, avg_specificity=86.30% avg_auc=92.10%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.632167 Test loss=0.336736 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.6032889485359192
[5/24] Train loss=0.6520233154296875
[10/24] Train loss=0.731693685054779
[15/24] Train loss=0.6221859455108643
[20/24] Train loss=0.5556382536888123
Test set avg_accuracy=85.25% avg_sensitivity=80.47%, avg_specificity=87.06% avg_auc=92.16%
Best model saved!! Metric=18.932344823778067!!
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.627957 Test loss=0.331811 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.6037228107452393
[5/24] Train loss=0.6594265699386597
[10/24] Train loss=0.7297139763832092
[15/24] Train loss=0.6285622715950012
[20/24] Train loss=0.5451950430870056
Test set avg_accuracy=85.00% avg_sensitivity=81.00%, avg_specificity=86.52% avg_auc=92.14%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.626864 Test loss=0.335967 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.615821361541748
[5/24] Train loss=0.6668388843536377
[10/24] Train loss=0.7365819215774536
[15/24] Train loss=0.6309676170349121
[20/24] Train loss=0.5453345775604248
Test set avg_accuracy=84.79% avg_sensitivity=81.04%, avg_specificity=86.21% avg_auc=92.13%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.628303 Test loss=0.336866 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.5970972180366516
[5/24] Train loss=0.6489754915237427
[10/24] Train loss=0.7330219149589539
[15/24] Train loss=0.6267759203910828
[20/24] Train loss=0.5502026677131653
Test set avg_accuracy=85.08% avg_sensitivity=80.43%, avg_specificity=86.84% avg_auc=92.19%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.625536 Test loss=0.331795 Current lr=[0.000156543481933168]

[0/24] Train loss=0.6074957847595215
[5/24] Train loss=0.6541981101036072
[10/24] Train loss=0.7363640069961548
[15/24] Train loss=0.6322116255760193
[20/24] Train loss=0.5484809279441833
Test set avg_accuracy=84.57% avg_sensitivity=81.33%, avg_specificity=85.80% avg_auc=92.17%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.626524 Test loss=0.338868 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.5850025415420532
[5/24] Train loss=0.6542709469795227
[10/24] Train loss=0.7270199060440063
[15/24] Train loss=0.6282851099967957
[20/24] Train loss=0.5551866292953491
Test set avg_accuracy=84.93% avg_sensitivity=81.28%, avg_specificity=86.32% avg_auc=92.15%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.626201 Test loss=0.336154 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.5992414355278015
[5/24] Train loss=0.674366295337677
[10/24] Train loss=0.7309660911560059
[15/24] Train loss=0.6199852228164673
[20/24] Train loss=0.5374879240989685
Test set avg_accuracy=83.71% avg_sensitivity=84.74%, avg_specificity=83.32% avg_auc=92.17%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.636047 Test loss=0.361224 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.6072564721107483
[5/24] Train loss=0.661914587020874
[10/24] Train loss=0.7502416968345642
[15/24] Train loss=0.6273049712181091
[20/24] Train loss=0.5742906928062439
Test set avg_accuracy=81.33% avg_sensitivity=89.10%, avg_specificity=78.38% avg_auc=92.12%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.642248 Test loss=0.412211 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.6509801745414734
[5/24] Train loss=0.6998679041862488
[10/24] Train loss=0.7269141674041748
[15/24] Train loss=0.6310251951217651
[20/24] Train loss=0.5495196580886841
Test set avg_accuracy=83.52% avg_sensitivity=85.02%, avg_specificity=82.94% avg_auc=92.13%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.636253 Test loss=0.364868 Current lr=[0.000134135431043539]

[0/24] Train loss=0.6122810244560242
[5/24] Train loss=0.6848436594009399
[10/24] Train loss=0.7307071685791016
[15/24] Train loss=0.6160401105880737
[20/24] Train loss=0.5444011688232422
Test set avg_accuracy=82.99% avg_sensitivity=85.92%, avg_specificity=81.89% avg_auc=92.22%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.627899 Test loss=0.370932 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.6144277453422546
[5/24] Train loss=0.6676372289657593
[10/24] Train loss=0.7411847710609436
[15/24] Train loss=0.6314398050308228
[20/24] Train loss=0.5543687343597412
Test set avg_accuracy=82.85% avg_sensitivity=86.21%, avg_specificity=81.58% avg_auc=92.21%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.626642 Test loss=0.374589 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.6180335879325867
[5/24] Train loss=0.6647936701774597
[10/24] Train loss=0.7234856486320496
[15/24] Train loss=0.6308988928794861
[20/24] Train loss=0.5478554964065552
Test set avg_accuracy=82.64% avg_sensitivity=86.16%, avg_specificity=81.31% avg_auc=92.08%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.626775 Test loss=0.377736 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.6222438216209412
[5/24] Train loss=0.6782007217407227
[10/24] Train loss=0.7270771265029907
[15/24] Train loss=0.6135517358779907
[20/24] Train loss=0.5440151691436768
Test set avg_accuracy=83.12% avg_sensitivity=85.26%, avg_specificity=82.32% avg_auc=92.17%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.620921 Test loss=0.365689 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.6045252680778503
[5/24] Train loss=0.6781930923461914
[10/24] Train loss=0.7280657887458801
[15/24] Train loss=0.6206976175308228
[20/24] Train loss=0.5485236644744873
Test set avg_accuracy=83.45% avg_sensitivity=85.31%, avg_specificity=82.75% avg_auc=92.29%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.621505 Test loss=0.361113 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.6038068532943726
[5/24] Train loss=0.6585520505905151
[10/24] Train loss=0.729155957698822
[15/24] Train loss=0.6230162382125854
[20/24] Train loss=0.542052686214447
Test set avg_accuracy=83.48% avg_sensitivity=85.07%, avg_specificity=82.87% avg_auc=92.29%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.616738 Test loss=0.359160 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.5918200612068176
[5/24] Train loss=0.6642670035362244
[10/24] Train loss=0.7187016010284424
[15/24] Train loss=0.6125379204750061
[20/24] Train loss=0.5327498912811279
Test set avg_accuracy=83.53% avg_sensitivity=85.07%, avg_specificity=82.94% avg_auc=92.27%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.612486 Test loss=0.359533 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.5844075679779053
[5/24] Train loss=0.6555231809616089
[10/24] Train loss=0.7267133593559265
[15/24] Train loss=0.6056559085845947
[20/24] Train loss=0.5371368527412415
Test set avg_accuracy=83.45% avg_sensitivity=85.36%, avg_specificity=82.73% avg_auc=92.30%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.613317 Test loss=0.361053 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.5978729724884033
[5/24] Train loss=0.6618021130561829
[10/24] Train loss=0.715519368648529
[15/24] Train loss=0.619914710521698
[20/24] Train loss=0.5366743803024292
Test set avg_accuracy=83.39% avg_sensitivity=85.36%, avg_specificity=82.64% avg_auc=92.35%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.611841 Test loss=0.361413 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.5936117768287659
[5/24] Train loss=0.6467320919036865
[10/24] Train loss=0.7103192806243896
[15/24] Train loss=0.6082854866981506
[20/24] Train loss=0.5377892851829529
Test set avg_accuracy=83.42% avg_sensitivity=85.17%, avg_specificity=82.76% avg_auc=92.32%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.608861 Test loss=0.359687 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.5896310210227966
[5/24] Train loss=0.6595362424850464
[10/24] Train loss=0.729114830493927
[15/24] Train loss=0.6154268980026245
[20/24] Train loss=0.5430598258972168
Test set avg_accuracy=83.48% avg_sensitivity=85.17%, avg_specificity=82.84% avg_auc=92.29%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.607320 Test loss=0.360547 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.5871650576591492
[5/24] Train loss=0.6427912712097168
[10/24] Train loss=0.7243954539299011
[15/24] Train loss=0.6161924600601196
[20/24] Train loss=0.5390022397041321
Test set avg_accuracy=83.11% avg_sensitivity=85.78%, avg_specificity=82.10% avg_auc=92.30%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.608943 Test loss=0.366536 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.5936077237129211
[5/24] Train loss=0.6428191661834717
[10/24] Train loss=0.7295184135437012
[15/24] Train loss=0.6195099353790283
[20/24] Train loss=0.5391457080841064
Test set avg_accuracy=83.20% avg_sensitivity=85.31%, avg_specificity=82.41% avg_auc=92.31%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.607773 Test loss=0.363418 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.594946563243866
[5/24] Train loss=0.654073178768158
[10/24] Train loss=0.7171798348426819
[15/24] Train loss=0.6098271608352661
[20/24] Train loss=0.5271816849708557
Test set avg_accuracy=83.22% avg_sensitivity=86.26%, avg_specificity=82.06% avg_auc=92.36%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.605250 Test loss=0.368420 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.5935555100440979
[5/24] Train loss=0.656844437122345
[10/24] Train loss=0.714789628982544
[15/24] Train loss=0.6124278903007507
[20/24] Train loss=0.5420292615890503
Test set avg_accuracy=83.03% avg_sensitivity=87.68%, avg_specificity=81.27% avg_auc=92.38%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.606279 Test loss=0.379010 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.5857768058776855
[5/24] Train loss=0.6708250641822815
[10/24] Train loss=0.7271798849105835
[15/24] Train loss=0.6102139949798584
[20/24] Train loss=0.5374191403388977
Test set avg_accuracy=82.75% avg_sensitivity=88.01%, avg_specificity=80.75% avg_auc=92.38%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.606972 Test loss=0.385369 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.6115802526473999
[5/24] Train loss=0.655872642993927
[10/24] Train loss=0.7097650766372681
[15/24] Train loss=0.6000043153762817
[20/24] Train loss=0.5370240211486816
Test set avg_accuracy=82.81% avg_sensitivity=87.30%, avg_specificity=81.11% avg_auc=92.33%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.605644 Test loss=0.380104 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.6057436466217041
[5/24] Train loss=0.6484798789024353
[10/24] Train loss=0.7067952752113342
[15/24] Train loss=0.5949330925941467
[20/24] Train loss=0.5374362468719482
Test set avg_accuracy=83.10% avg_sensitivity=86.30%, avg_specificity=81.89% avg_auc=92.34%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.603520 Test loss=0.369636 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.6001391410827637
[5/24] Train loss=0.6367202997207642
[10/24] Train loss=0.6989445090293884
[15/24] Train loss=0.6033933162689209
[20/24] Train loss=0.5306048393249512
Test set avg_accuracy=83.62% avg_sensitivity=84.74%, avg_specificity=83.20% avg_auc=92.28%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.602258 Test loss=0.359068 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.5840556025505066
[5/24] Train loss=0.6264779567718506
[10/24] Train loss=0.7034994959831238
[15/24] Train loss=0.5908377766609192
[20/24] Train loss=0.5310037136077881
Test set avg_accuracy=83.65% avg_sensitivity=84.55%, avg_specificity=83.30% avg_auc=92.31%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.598722 Test loss=0.357119 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.5802798867225647
[5/24] Train loss=0.6394875049591064
[10/24] Train loss=0.6941748857498169
[15/24] Train loss=0.5907732844352722
[20/24] Train loss=0.5343589782714844
Test set avg_accuracy=83.61% avg_sensitivity=84.88%, avg_specificity=83.12% avg_auc=92.31%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.596924 Test loss=0.359240 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.5804839134216309
[5/24] Train loss=0.634059727191925
[10/24] Train loss=0.7005268335342407
[15/24] Train loss=0.5990846157073975
[20/24] Train loss=0.5351588726043701
Test set avg_accuracy=83.67% avg_sensitivity=84.98%, avg_specificity=83.18% avg_auc=92.34%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.597062 Test loss=0.357736 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.583017885684967
[5/24] Train loss=0.6282531023025513
[10/24] Train loss=0.7065392136573792
[15/24] Train loss=0.5996139049530029
[20/24] Train loss=0.5297349691390991
Test set avg_accuracy=83.82% avg_sensitivity=84.74%, avg_specificity=83.46% avg_auc=92.34%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.595926 Test loss=0.355954 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.5787936449050903
[5/24] Train loss=0.6373895406723022
[10/24] Train loss=0.6928678154945374
[15/24] Train loss=0.5945891737937927
[20/24] Train loss=0.5343817472457886
Test set avg_accuracy=83.78% avg_sensitivity=85.02%, avg_specificity=83.30% avg_auc=92.35%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.597039 Test loss=0.357866 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.5794273614883423
[5/24] Train loss=0.6299499869346619
[10/24] Train loss=0.6945233345031738
[15/24] Train loss=0.607438325881958
[20/24] Train loss=0.536474883556366
Test set avg_accuracy=83.82% avg_sensitivity=84.98%, avg_specificity=83.38% avg_auc=92.33%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.594939 Test loss=0.357162 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.5931707620620728
[5/24] Train loss=0.6155280470848083
[10/24] Train loss=0.6925551891326904
[15/24] Train loss=0.5961050987243652
[20/24] Train loss=0.5300183296203613
Test set avg_accuracy=83.67% avg_sensitivity=85.02%, avg_specificity=83.16% avg_auc=92.35%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.595450 Test loss=0.358092 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.5763682723045349
[5/24] Train loss=0.6228689551353455
[10/24] Train loss=0.6933426260948181
[15/24] Train loss=0.5944845080375671
[20/24] Train loss=0.5302733778953552
Test set avg_accuracy=83.72% avg_sensitivity=84.55%, avg_specificity=83.41% avg_auc=92.30%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.591446 Test loss=0.357497 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.5830397605895996
[5/24] Train loss=0.6222034692764282
[10/24] Train loss=0.683667004108429
[15/24] Train loss=0.5892689824104309
[20/24] Train loss=0.5211437344551086
Test set avg_accuracy=83.76% avg_sensitivity=85.40%, avg_specificity=83.14% avg_auc=92.35%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.590446 Test loss=0.359792 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.5743133425712585
[5/24] Train loss=0.6219013333320618
[10/24] Train loss=0.6969958543777466
[15/24] Train loss=0.5933007597923279
[20/24] Train loss=0.5305883884429932
Test set avg_accuracy=83.61% avg_sensitivity=85.26%, avg_specificity=82.98% avg_auc=92.33%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.591576 Test loss=0.360558 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.5848267674446106
[5/24] Train loss=0.615554928779602
[10/24] Train loss=0.6896990537643433
[15/24] Train loss=0.5985081195831299
[20/24] Train loss=0.526418149471283
Test set avg_accuracy=83.61% avg_sensitivity=85.45%, avg_specificity=82.91% avg_auc=92.36%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.591495 Test loss=0.361154 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.5824885368347168
[5/24] Train loss=0.6179131269454956
[10/24] Train loss=0.6990336179733276
[15/24] Train loss=0.5881006121635437
[20/24] Train loss=0.5232706069946289
Test set avg_accuracy=83.42% avg_sensitivity=86.45%, avg_specificity=82.28% avg_auc=92.37%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.591937 Test loss=0.367510 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.5995911955833435
[5/24] Train loss=0.6161572337150574
[10/24] Train loss=0.6986033916473389
[15/24] Train loss=0.6018366813659668
[20/24] Train loss=0.5252062082290649
Test set avg_accuracy=83.33% avg_sensitivity=86.16%, avg_specificity=82.26% avg_auc=92.35%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.592767 Test loss=0.368423 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.584250807762146
[5/24] Train loss=0.6123719811439514
[10/24] Train loss=0.6912558078765869
[15/24] Train loss=0.6067226529121399
[20/24] Train loss=0.5252267718315125
Test set avg_accuracy=83.39% avg_sensitivity=86.78%, avg_specificity=82.10% avg_auc=92.37%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.593348 Test loss=0.370523 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.5939614772796631
[5/24] Train loss=0.6159399151802063
[10/24] Train loss=0.6973623037338257
[15/24] Train loss=0.6071503758430481
[20/24] Train loss=0.5368137359619141
Test set avg_accuracy=83.54% avg_sensitivity=85.64%, avg_specificity=82.75% avg_auc=92.36%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.594142 Test loss=0.363937 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.5841392278671265
[5/24] Train loss=0.6217227578163147
[10/24] Train loss=0.6941640377044678
[15/24] Train loss=0.59850013256073
[20/24] Train loss=0.5413658618927002
Test set avg_accuracy=83.80% avg_sensitivity=83.89%, avg_specificity=83.77% avg_auc=92.29%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.594529 Test loss=0.354025 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.5778425931930542
[5/24] Train loss=0.6265848278999329
[10/24] Train loss=0.6999855637550354
[15/24] Train loss=0.5958110690116882
[20/24] Train loss=0.528610110282898
Test set avg_accuracy=84.35% avg_sensitivity=82.61%, avg_specificity=85.01% avg_auc=92.25%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.592922 Test loss=0.345496 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.5709083676338196
[5/24] Train loss=0.6162835955619812
[10/24] Train loss=0.6995373368263245
[15/24] Train loss=0.6028097867965698
[20/24] Train loss=0.5451984405517578
Test set avg_accuracy=84.28% avg_sensitivity=82.89%, avg_specificity=84.81% avg_auc=92.29%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.590682 Test loss=0.346049 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.5720151662826538
[5/24] Train loss=0.6168169975280762
[10/24] Train loss=0.7000480890274048
[15/24] Train loss=0.5953549742698669
[20/24] Train loss=0.5265700221061707
Test set avg_accuracy=84.26% avg_sensitivity=83.27%, avg_specificity=84.63% avg_auc=92.31%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.589390 Test loss=0.347868 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.5772035121917725
[5/24] Train loss=0.615246593952179
[10/24] Train loss=0.6867735385894775
[15/24] Train loss=0.5885462164878845
[20/24] Train loss=0.5260127782821655
Test set avg_accuracy=84.31% avg_sensitivity=82.99%, avg_specificity=84.81% avg_auc=92.30%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.588773 Test loss=0.346270 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.5750727653503418
[5/24] Train loss=0.6114502549171448
[10/24] Train loss=0.6898810863494873
[15/24] Train loss=0.5908418297767639
[20/24] Train loss=0.5253928899765015
Test set avg_accuracy=84.28% avg_sensitivity=83.22%, avg_specificity=84.69% avg_auc=92.32%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.587581 Test loss=0.347551 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.5767236351966858
[5/24] Train loss=0.605198085308075
[10/24] Train loss=0.6951025128364563
[15/24] Train loss=0.5873109698295593
[20/24] Train loss=0.5281845331192017
Test set avg_accuracy=84.24% avg_sensitivity=83.13%, avg_specificity=84.67% avg_auc=92.31%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.587975 Test loss=0.347155 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.5668146014213562
[5/24] Train loss=0.610817551612854
[10/24] Train loss=0.6883212327957153
[15/24] Train loss=0.6014654040336609
[20/24] Train loss=0.5221045613288879
Test set avg_accuracy=84.27% avg_sensitivity=83.27%, avg_specificity=84.65% avg_auc=92.32%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.588540 Test loss=0.347561 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.5762948393821716
[5/24] Train loss=0.6147157549858093
[10/24] Train loss=0.6830406785011292
[15/24] Train loss=0.59464031457901
[20/24] Train loss=0.5288390517234802
Test set avg_accuracy=84.24% avg_sensitivity=83.18%, avg_specificity=84.65% avg_auc=92.32%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.588186 Test loss=0.347257 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.5699899196624756
[5/24] Train loss=0.6192355751991272
[10/24] Train loss=0.709991991519928
[15/24] Train loss=0.5848287343978882
[20/24] Train loss=0.5269220471382141
Test set avg_accuracy=84.24% avg_sensitivity=83.13%, avg_specificity=84.67% avg_auc=92.32%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.588283 Test loss=0.347070 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.5679489970207214
[5/24] Train loss=0.6131255030632019
[10/24] Train loss=0.6884303689002991
[15/24] Train loss=0.606112539768219
[20/24] Train loss=0.5249422192573547
Test set avg_accuracy=84.24% avg_sensitivity=83.18%, avg_specificity=84.65% avg_auc=92.32%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.586880 Test loss=0.347180 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.5689461827278137
[5/24] Train loss=0.6155819296836853
[10/24] Train loss=0.6914710998535156
[15/24] Train loss=0.5975000262260437
[20/24] Train loss=0.5305323600769043
Test set avg_accuracy=84.26% avg_sensitivity=83.22%, avg_specificity=84.65% avg_auc=92.32%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.587556 Test loss=0.347462 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.5757323503494263
[5/24] Train loss=0.6260533332824707
[10/24] Train loss=0.6885649561882019
[15/24] Train loss=0.5921657681465149
[20/24] Train loss=0.525800347328186
Test set avg_accuracy=84.26% avg_sensitivity=83.22%, avg_specificity=84.65% avg_auc=92.32%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.586303 Test loss=0.347569 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.5770289301872253
[5/24] Train loss=0.6234943866729736
[10/24] Train loss=0.7005878686904907
[15/24] Train loss=0.5884203910827637
[20/24] Train loss=0.5275676846504211
Test set avg_accuracy=84.26% avg_sensitivity=83.22%, avg_specificity=84.65% avg_auc=92.32%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.587684 Test loss=0.347593 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.5717437267303467
[5/24] Train loss=0.6252931952476501
[10/24] Train loss=0.6780595779418945
[15/24] Train loss=0.584480881690979
[20/24] Train loss=0.5194523334503174
Test set avg_accuracy=84.26% avg_sensitivity=83.22%, avg_specificity=84.65% avg_auc=92.32%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.585897 Test loss=0.347597 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=85.25% sen=80.47%, spe=87.06%, auc=92.16%!
Fold[3] Avg_overlap=0.64%(±0.23016361522735151)
[0/24] Train loss=1.6293612718582153
[5/24] Train loss=1.4980242252349854
[10/24] Train loss=1.4865084886550903
[15/24] Train loss=1.4407954216003418
[20/24] Train loss=1.4276682138442993
Test set avg_accuracy=57.03% avg_sensitivity=46.28%, avg_specificity=60.82% avg_auc=55.85%
Best model saved!! Metric=-106.02559136273122!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=1.477652 Test loss=0.678440 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.4361544847488403
[5/24] Train loss=1.4465394020080566
[10/24] Train loss=1.4148904085159302
[15/24] Train loss=1.3988415002822876
[20/24] Train loss=1.397127389907837
Test set avg_accuracy=61.71% avg_sensitivity=55.12%, avg_specificity=64.03% avg_auc=62.70%
Best model saved!! Metric=-82.44980391377321!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=1.412574 Test loss=0.673268 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.393287181854248
[5/24] Train loss=1.3909871578216553
[10/24] Train loss=1.3908827304840088
[15/24] Train loss=1.3786003589630127
[20/24] Train loss=1.3658969402313232
Test set avg_accuracy=64.99% avg_sensitivity=61.82%, avg_specificity=66.10% avg_auc=68.02%
Best model saved!! Metric=-65.06683562342022!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=1.381976 Test loss=0.664439 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.3701764345169067
[5/24] Train loss=1.3579744100570679
[10/24] Train loss=1.374921441078186
[15/24] Train loss=1.3603483438491821
[20/24] Train loss=1.3491477966308594
Test set avg_accuracy=68.95% avg_sensitivity=62.32%, avg_specificity=71.28% avg_auc=72.43%
Best model saved!! Metric=-51.02592251992621!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=1.358407 Test loss=0.650307 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.3423396348953247
[5/24] Train loss=1.3366097211837769
[10/24] Train loss=1.3470407724380493
[15/24] Train loss=1.323573112487793
[20/24] Train loss=1.3269706964492798
Test set avg_accuracy=70.61% avg_sensitivity=67.62%, avg_specificity=71.67% avg_auc=75.70%
Best model saved!! Metric=-40.40247785909055!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=1.334566 Test loss=0.639427 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.3112720251083374
[5/24] Train loss=1.3053867816925049
[10/24] Train loss=1.3218845129013062
[15/24] Train loss=1.2779070138931274
[20/24] Train loss=1.2797023057937622
Test set avg_accuracy=72.59% avg_sensitivity=71.86%, avg_specificity=72.85% avg_auc=78.55%
Best model saved!! Metric=-30.147215044336647!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=1.304093 Test loss=0.625558 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.275038242340088
[5/24] Train loss=1.2615100145339966
[10/24] Train loss=1.2891104221343994
[15/24] Train loss=1.251686453819275
[20/24] Train loss=1.2432925701141357
Test set avg_accuracy=73.68% avg_sensitivity=75.11%, avg_specificity=73.18% avg_auc=80.44%
Best model saved!! Metric=-23.584285564698064!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=1.270970 Test loss=0.608885 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.2312076091766357
[5/24] Train loss=1.2241542339324951
[10/24] Train loss=1.2643539905548096
[15/24] Train loss=1.2049167156219482
[20/24] Train loss=1.1975253820419312
Test set avg_accuracy=75.40% avg_sensitivity=74.66%, avg_specificity=75.66% avg_auc=82.06%
Best model saved!! Metric=-18.211872873240495!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=1.230905 Test loss=0.578945 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.18028724193573
[5/24] Train loss=1.1736292839050293
[10/24] Train loss=1.224572777748108
[15/24] Train loss=1.1570181846618652
[20/24] Train loss=1.1555266380310059
Test set avg_accuracy=76.76% avg_sensitivity=73.11%, avg_specificity=78.04% avg_auc=83.28%
Best model saved!! Metric=-14.806689101989988!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=1.183704 Test loss=0.545551 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.1325517892837524
[5/24] Train loss=1.128806710243225
[10/24] Train loss=1.1838711500167847
[15/24] Train loss=1.1176981925964355
[20/24] Train loss=1.1007682085037231
Test set avg_accuracy=77.06% avg_sensitivity=77.66%, avg_specificity=76.84% avg_auc=84.37%
Best model saved!! Metric=-10.068757388397273!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=1.138309 Test loss=0.528615 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.0828945636749268
[5/24] Train loss=1.08577561378479
[10/24] Train loss=1.160083532333374
[15/24] Train loss=1.079083800315857
[20/24] Train loss=1.0831387042999268
Test set avg_accuracy=77.21% avg_sensitivity=82.11%, avg_specificity=75.49% avg_auc=85.22%
Best model saved!! Metric=-5.9725729710312265!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=1.101207 Test loss=0.516531 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.044482707977295
[5/24] Train loss=1.0493826866149902
[10/24] Train loss=1.131600260734558
[15/24] Train loss=1.048109531402588
[20/24] Train loss=1.0415620803833008
Test set avg_accuracy=76.68% avg_sensitivity=84.56%, avg_specificity=73.90% avg_auc=85.91%
Best model saved!! Metric=-4.947385387222511!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=1.064096 Test loss=0.513043 Current lr=[5.97283087248885e-05]

[0/24] Train loss=1.0215957164764404
[5/24] Train loss=1.0232013463974
[10/24] Train loss=1.0885505676269531
[15/24] Train loss=1.0004141330718994
[20/24] Train loss=1.0035688877105713
Test set avg_accuracy=76.08% avg_sensitivity=87.16%, avg_specificity=72.18% avg_auc=86.64%
Best model saved!! Metric=-3.9410097437689586!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=1.028233 Test loss=0.511777 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.9853108525276184
[5/24] Train loss=1.0093961954116821
[10/24] Train loss=1.0644218921661377
[15/24] Train loss=0.9857076406478882
[20/24] Train loss=0.9659388661384583
Test set avg_accuracy=77.17% avg_sensitivity=86.16%, avg_specificity=74.01% avg_auc=87.14%
Best model saved!! Metric=-1.515873139131486!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.999599 Test loss=0.488214 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.9498454332351685
[5/24] Train loss=0.983376681804657
[10/24] Train loss=1.0511940717697144
[15/24] Train loss=0.9520227909088135
[20/24] Train loss=0.9397989511489868
Test set avg_accuracy=77.73% avg_sensitivity=85.66%, avg_specificity=74.94% avg_auc=87.60%
Best model saved!! Metric=-0.06206785974636375!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.976567 Test loss=0.470627 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.9213047027587891
[5/24] Train loss=0.935798168182373
[10/24] Train loss=1.0273997783660889
[15/24] Train loss=0.9220490455627441
[20/24] Train loss=0.9168287515640259
Test set avg_accuracy=77.17% avg_sensitivity=88.36%, avg_specificity=73.23% avg_auc=88.23%
Best model saved!! Metric=0.9989594252167393!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.956300 Test loss=0.478597 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.903403103351593
[5/24] Train loss=0.927463710308075
[10/24] Train loss=1.0252947807312012
[15/24] Train loss=0.8990187644958496
[20/24] Train loss=0.9028360247612
Test set avg_accuracy=78.26% avg_sensitivity=86.81%, avg_specificity=75.24% avg_auc=88.75%
Best model saved!! Metric=3.0565641266463928!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.934620 Test loss=0.451560 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.8830621838569641
[5/24] Train loss=0.8868677020072937
[10/24] Train loss=1.0125571489334106
[15/24] Train loss=0.8832240104675293
[20/24] Train loss=0.8770904541015625
Test set avg_accuracy=79.02% avg_sensitivity=86.41%, avg_specificity=76.42% avg_auc=89.07%
Best model saved!! Metric=4.927138757312903!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.920310 Test loss=0.437897 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.8557391166687012
[5/24] Train loss=0.8596900701522827
[10/24] Train loss=0.9772776961326599
[15/24] Train loss=0.8682236075401306
[20/24] Train loss=0.8536256551742554
Test set avg_accuracy=80.18% avg_sensitivity=84.96%, avg_specificity=78.50% avg_auc=89.44%
Best model saved!! Metric=7.084036779318993!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.900534 Test loss=0.417304 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.8157243728637695
[5/24] Train loss=0.8456358313560486
[10/24] Train loss=0.9638190269470215
[15/24] Train loss=0.8535172939300537
[20/24] Train loss=0.8153778314590454
Test set avg_accuracy=81.74% avg_sensitivity=81.66%, avg_specificity=81.77% avg_auc=89.67%
Best model saved!! Metric=8.849684017110576!!
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.878689 Test loss=0.391464 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.8070778250694275
[5/24] Train loss=0.8561992645263672
[10/24] Train loss=0.9230005741119385
[15/24] Train loss=0.8721970915794373
[20/24] Train loss=0.7953159213066101
Test set avg_accuracy=81.37% avg_sensitivity=83.96%, avg_specificity=80.45% avg_auc=89.93%
Best model saved!! Metric=9.7127123955906!!
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.861085 Test loss=0.398127 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.7851449847221375
[5/24] Train loss=0.8429099321365356
[10/24] Train loss=0.8901005387306213
[15/24] Train loss=0.8473942279815674
[20/24] Train loss=0.7787731289863586
Test set avg_accuracy=81.22% avg_sensitivity=84.41%, avg_specificity=80.10% avg_auc=90.09%
Best model saved!! Metric=9.827326661495363!!
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.835907 Test loss=0.400482 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.7675626277923584
[5/24] Train loss=0.8391041159629822
[10/24] Train loss=0.8730112910270691
[15/24] Train loss=0.8177005648612976
[20/24] Train loss=0.7897905111312866
Test set avg_accuracy=81.16% avg_sensitivity=84.61%, avg_specificity=79.94% avg_auc=90.20%
Best model saved!! Metric=9.908711145203299!!
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.823155 Test loss=0.403051 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.7511809468269348
[5/24] Train loss=0.8157085180282593
[10/24] Train loss=0.8812260031700134
[15/24] Train loss=0.8027384877204895
[20/24] Train loss=0.7691630721092224
Test set avg_accuracy=81.64% avg_sensitivity=84.06%, avg_specificity=80.79% avg_auc=90.43%
Best model saved!! Metric=10.918409597752188!!
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.810400 Test loss=0.393661 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.7523289322853088
[5/24] Train loss=0.8174437880516052
[10/24] Train loss=0.8690298795700073
[15/24] Train loss=0.8008183836936951
[20/24] Train loss=0.7796053290367126
Test set avg_accuracy=82.90% avg_sensitivity=82.26%, avg_specificity=83.13% avg_auc=90.56%
Best model saved!! Metric=12.856739897324388!!
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.805647 Test loss=0.374987 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.7333829998970032
[5/24] Train loss=0.8334280848503113
[10/24] Train loss=0.8632022142410278
[15/24] Train loss=0.7819639444351196
[20/24] Train loss=0.7586580514907837
Test set avg_accuracy=82.68% avg_sensitivity=81.96%, avg_specificity=82.94% avg_auc=90.65%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.797962 Test loss=0.373111 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.7242391705513
[5/24] Train loss=0.8564771413803101
[10/24] Train loss=0.8577476739883423
[15/24] Train loss=0.803198516368866
[20/24] Train loss=0.7709657549858093
Test set avg_accuracy=82.89% avg_sensitivity=81.81%, avg_specificity=83.27% avg_auc=90.69%
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.797140 Test loss=0.369897 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.7327457666397095
[5/24] Train loss=0.8344858884811401
[10/24] Train loss=0.8469294905662537
[15/24] Train loss=0.7951069474220276
[20/24] Train loss=0.7512959837913513
Test set avg_accuracy=83.55% avg_sensitivity=80.26%, avg_specificity=84.72% avg_auc=90.77%
Best model saved!! Metric=13.297519552894144!!
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.786932 Test loss=0.359435 Current lr=[0.000210185142098938]

[0/24] Train loss=0.7137153148651123
[5/24] Train loss=0.8491261005401611
[10/24] Train loss=0.8328849077224731
[15/24] Train loss=0.7779794335365295
[20/24] Train loss=0.735349714756012
Test set avg_accuracy=82.16% avg_sensitivity=84.16%, avg_specificity=81.46% avg_auc=90.79%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.779905 Test loss=0.384149 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.7100736498832703
[5/24] Train loss=0.8283469080924988
[10/24] Train loss=0.8447694778442383
[15/24] Train loss=0.759388267993927
[20/24] Train loss=0.7199951410293579
Test set avg_accuracy=83.82% avg_sensitivity=80.61%, avg_specificity=84.94% avg_auc=90.88%
Best model saved!! Metric=14.252913612005614!!
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.768195 Test loss=0.355487 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.7104489803314209
[5/24] Train loss=0.8845721483230591
[10/24] Train loss=0.8344674706459045
[15/24] Train loss=0.7891036868095398
[20/24] Train loss=0.7188674807548523
Test set avg_accuracy=81.95% avg_sensitivity=85.71%, avg_specificity=80.63% avg_auc=90.87%
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.774780 Test loss=0.394247 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.695787250995636
[5/24] Train loss=0.8017947673797607
[10/24] Train loss=0.836027204990387
[15/24] Train loss=0.736687183380127
[20/24] Train loss=0.713208794593811
Test set avg_accuracy=83.76% avg_sensitivity=80.51%, avg_specificity=84.91% avg_auc=90.91%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.755742 Test loss=0.356715 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.6934072375297546
[5/24] Train loss=0.883944034576416
[10/24] Train loss=0.8251389861106873
[15/24] Train loss=0.7878471612930298
[20/24] Train loss=0.7199549078941345
Test set avg_accuracy=82.70% avg_sensitivity=84.56%, avg_specificity=82.04% avg_auc=91.04%
Best model saved!! Metric=14.33707622810249!!
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.765447 Test loss=0.378519 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.6873677968978882
[5/24] Train loss=0.7939929366111755
[10/24] Train loss=0.8260586261749268
[15/24] Train loss=0.7436938881874084
[20/24] Train loss=0.6991037726402283
Test set avg_accuracy=82.85% avg_sensitivity=83.46%, avg_specificity=82.64% avg_auc=91.07%
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.746585 Test loss=0.371601 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.6783345937728882
[5/24] Train loss=0.8312355279922485
[10/24] Train loss=0.8194122910499573
[15/24] Train loss=0.7661337852478027
[20/24] Train loss=0.7110926508903503
Test set avg_accuracy=83.85% avg_sensitivity=82.46%, avg_specificity=84.35% avg_auc=91.27%
Best model saved!! Metric=15.932897155269856!!
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.753366 Test loss=0.358535 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.6744111776351929
[5/24] Train loss=0.8081653118133545
[10/24] Train loss=0.8095399141311646
[15/24] Train loss=0.7321754693984985
[20/24] Train loss=0.6816886067390442
Test set avg_accuracy=82.54% avg_sensitivity=84.31%, avg_specificity=81.92% avg_auc=91.10%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.745455 Test loss=0.379087 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.6835174560546875
[5/24] Train loss=0.8246344923973083
[10/24] Train loss=0.8041676878929138
[15/24] Train loss=0.7558033466339111
[20/24] Train loss=0.6945968866348267
Test set avg_accuracy=83.27% avg_sensitivity=82.96%, avg_specificity=83.38% avg_auc=91.28%
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.740554 Test loss=0.365755 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.6681395769119263
[5/24] Train loss=0.807206392288208
[10/24] Train loss=0.8067545890808105
[15/24] Train loss=0.7269086241722107
[20/24] Train loss=0.6916489601135254
Test set avg_accuracy=83.46% avg_sensitivity=83.56%, avg_specificity=83.43% avg_auc=91.42%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.734856 Test loss=0.362761 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.6648457646369934
[5/24] Train loss=0.8116840720176697
[10/24] Train loss=0.8043115139007568
[15/24] Train loss=0.7391744256019592
[20/24] Train loss=0.6818508505821228
Test set avg_accuracy=82.93% avg_sensitivity=85.11%, avg_specificity=82.16% avg_auc=91.42%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.732417 Test loss=0.374976 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.6778092980384827
[5/24] Train loss=0.7988449335098267
[10/24] Train loss=0.8065940737724304
[15/24] Train loss=0.7236573696136475
[20/24] Train loss=0.6841927170753479
Test set avg_accuracy=83.80% avg_sensitivity=82.66%, avg_specificity=84.20% avg_auc=91.55%
Best model saved!! Metric=16.211578180908674!!
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.727009 Test loss=0.355102 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.6707218289375305
[5/24] Train loss=0.8170675039291382
[10/24] Train loss=0.8041471242904663
[15/24] Train loss=0.7444426417350769
[20/24] Train loss=0.6769167184829712
Test set avg_accuracy=83.33% avg_sensitivity=84.71%, avg_specificity=82.85% avg_auc=91.54%
Best model saved!! Metric=16.432705992487115!!
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.728095 Test loss=0.369607 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.6579623818397522
[5/24] Train loss=0.779930591583252
[10/24] Train loss=0.806160032749176
[15/24] Train loss=0.7237166166305542
[20/24] Train loss=0.6584643125534058
Test set avg_accuracy=83.28% avg_sensitivity=84.26%, avg_specificity=82.94% avg_auc=91.56%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.718586 Test loss=0.365371 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.6594220995903015
[5/24] Train loss=0.8027163743972778
[10/24] Train loss=0.7906196713447571
[15/24] Train loss=0.7234889268875122
[20/24] Train loss=0.6652697324752808
Test set avg_accuracy=83.85% avg_sensitivity=83.81%, avg_specificity=83.87% avg_auc=91.65%
Best model saved!! Metric=17.184661658649446!!
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.717613 Test loss=0.358082 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.6549593806266785
[5/24] Train loss=0.8041040301322937
[10/24] Train loss=0.7862580418586731
[15/24] Train loss=0.737497091293335
[20/24] Train loss=0.6655084490776062
Test set avg_accuracy=83.55% avg_sensitivity=83.61%, avg_specificity=83.54% avg_auc=91.62%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.718216 Test loss=0.360869 Current lr=[0.00029967723776099]

[0/24] Train loss=0.6597606539726257
[5/24] Train loss=0.7933066487312317
[10/24] Train loss=0.7863709926605225
[15/24] Train loss=0.7208067774772644
[20/24] Train loss=0.6496915817260742
Test set avg_accuracy=83.70% avg_sensitivity=83.01%, avg_specificity=83.94% avg_auc=91.40%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.714053 Test loss=0.360169 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.6507490873336792
[5/24] Train loss=0.7975665330886841
[10/24] Train loss=0.7900457382202148
[15/24] Train loss=0.7140452265739441
[20/24] Train loss=0.6645346283912659
Test set avg_accuracy=83.42% avg_sensitivity=83.91%, avg_specificity=83.25% avg_auc=91.56%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.712548 Test loss=0.364650 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.6558235287666321
[5/24] Train loss=0.7949607968330383
[10/24] Train loss=0.7840875387191772
[15/24] Train loss=0.7213879227638245
[20/24] Train loss=0.6583316922187805
Test set avg_accuracy=82.89% avg_sensitivity=85.41%, avg_specificity=82.00% avg_auc=91.64%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.709670 Test loss=0.375887 Current lr=[0.000299720220882401]

[0/24] Train loss=0.6585003137588501
[5/24] Train loss=0.7622970938682556
[10/24] Train loss=0.8008132576942444
[15/24] Train loss=0.7127060294151306
[20/24] Train loss=0.6681773066520691
Test set avg_accuracy=83.28% avg_sensitivity=84.66%, avg_specificity=82.80% avg_auc=91.61%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.704252 Test loss=0.369178 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.6631970405578613
[5/24] Train loss=0.7723461985588074
[10/24] Train loss=0.7924335598945618
[15/24] Train loss=0.7129824757575989
[20/24] Train loss=0.658552348613739
Test set avg_accuracy=83.63% avg_sensitivity=84.31%, avg_specificity=83.39% avg_auc=91.76%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.701959 Test loss=0.359468 Current lr=[0.000298904600941902]

[0/24] Train loss=0.6447510123252869
[5/24] Train loss=0.7724711298942566
[10/24] Train loss=0.7919085621833801
[15/24] Train loss=0.6900397539138794
[20/24] Train loss=0.6571324467658997
Test set avg_accuracy=83.48% avg_sensitivity=84.76%, avg_specificity=83.03% avg_auc=91.82%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.697487 Test loss=0.363796 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.6499102115631104
[5/24] Train loss=0.749812126159668
[10/24] Train loss=0.7837640047073364
[15/24] Train loss=0.6930134296417236
[20/24] Train loss=0.639839231967926
Test set avg_accuracy=83.68% avg_sensitivity=84.26%, avg_specificity=83.48% avg_auc=91.81%
Best model saved!! Metric=17.238285189016437!!
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.693414 Test loss=0.358273 Current lr=[0.000297555943323901]

[0/24] Train loss=0.644810140132904
[5/24] Train loss=0.7802747488021851
[10/24] Train loss=0.7714090347290039
[15/24] Train loss=0.7018291354179382
[20/24] Train loss=0.6531428098678589
Test set avg_accuracy=83.63% avg_sensitivity=84.81%, avg_specificity=83.22% avg_auc=91.91%
Best model saved!! Metric=17.569466817672975!!
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.695121 Test loss=0.361660 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.642206609249115
[5/24] Train loss=0.771924614906311
[10/24] Train loss=0.7769037485122681
[15/24] Train loss=0.6947919130325317
[20/24] Train loss=0.639832079410553
Test set avg_accuracy=83.58% avg_sensitivity=84.76%, avg_specificity=83.17% avg_auc=91.87%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.691334 Test loss=0.361506 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.6371970176696777
[5/24] Train loss=0.7737579941749573
[10/24] Train loss=0.7688354849815369
[15/24] Train loss=0.6936596035957336
[20/24] Train loss=0.6601661443710327
Test set avg_accuracy=83.58% avg_sensitivity=84.26%, avg_specificity=83.34% avg_auc=91.84%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.692049 Test loss=0.360548 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.6411383748054504
[5/24] Train loss=0.7554208636283875
[10/24] Train loss=0.7728682160377502
[15/24] Train loss=0.6859638094902039
[20/24] Train loss=0.6464088559150696
Test set avg_accuracy=83.39% avg_sensitivity=85.06%, avg_specificity=82.80% avg_auc=91.84%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.684892 Test loss=0.368274 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.6376450061798096
[5/24] Train loss=0.7566280364990234
[10/24] Train loss=0.7821980118751526
[15/24] Train loss=0.698338508605957
[20/24] Train loss=0.6401021480560303
Test set avg_accuracy=83.45% avg_sensitivity=85.66%, avg_specificity=82.67% avg_auc=91.92%
Best model saved!! Metric=17.699908377631274!!
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.687252 Test loss=0.367418 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.6386249661445618
[5/24] Train loss=0.7556267380714417
[10/24] Train loss=0.7717346549034119
[15/24] Train loss=0.668045699596405
[20/24] Train loss=0.6324469447135925
Test set avg_accuracy=83.85% avg_sensitivity=84.26%, avg_specificity=83.71% avg_auc=91.91%
Best model saved!! Metric=17.731108808379744!!
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.681367 Test loss=0.357914 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.6379173398017883
[5/24] Train loss=0.7567103505134583
[10/24] Train loss=0.7639373540878296
[15/24] Train loss=0.6863568425178528
[20/24] Train loss=0.6268266439437866
Test set avg_accuracy=84.19% avg_sensitivity=84.71%, avg_specificity=84.01% avg_auc=92.10%
Best model saved!! Metric=19.007454156406993!!
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.680775 Test loss=0.355434 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.627764105796814
[5/24] Train loss=0.7501615881919861
[10/24] Train loss=0.7712782025337219
[15/24] Train loss=0.6761560440063477
[20/24] Train loss=0.6180071234703064
Test set avg_accuracy=84.34% avg_sensitivity=84.26%, avg_specificity=84.36% avg_auc=92.07%
Best model saved!! Metric=19.03169456951946!!
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.675655 Test loss=0.350149 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.630845308303833
[5/24] Train loss=0.7581481337547302
[10/24] Train loss=0.7580320835113525
[15/24] Train loss=0.6795236468315125
[20/24] Train loss=0.6401835680007935
Test set avg_accuracy=84.22% avg_sensitivity=84.46%, avg_specificity=84.13% avg_auc=92.06%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.675818 Test loss=0.352670 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.6170628666877747
[5/24] Train loss=0.7492502331733704
[10/24] Train loss=0.7675772905349731
[15/24] Train loss=0.7037456631660461
[20/24] Train loss=0.6304411888122559
Test set avg_accuracy=83.92% avg_sensitivity=85.76%, avg_specificity=83.27% avg_auc=92.18%
Best model saved!! Metric=19.13056956854051!!
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.676964 Test loss=0.360721 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.6179660558700562
[5/24] Train loss=0.7216485738754272
[10/24] Train loss=0.7580065727233887
[15/24] Train loss=0.6745812296867371
[20/24] Train loss=0.6295161843299866
Test set avg_accuracy=83.96% avg_sensitivity=85.06%, avg_specificity=83.57% avg_auc=92.12%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.669476 Test loss=0.357884 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.6202155351638794
[5/24] Train loss=0.7598985433578491
[10/24] Train loss=0.7668822407722473
[15/24] Train loss=0.6695046424865723
[20/24] Train loss=0.6289917826652527
Test set avg_accuracy=84.02% avg_sensitivity=84.86%, avg_specificity=83.73% avg_auc=92.07%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.669703 Test loss=0.357135 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.6365519762039185
[5/24] Train loss=0.7325440049171448
[10/24] Train loss=0.7516340017318726
[15/24] Train loss=0.6706188321113586
[20/24] Train loss=0.613105297088623
Test set avg_accuracy=84.14% avg_sensitivity=84.61%, avg_specificity=83.98% avg_auc=92.08%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.664054 Test loss=0.353952 Current lr=[0.000276307469034998]

[0/24] Train loss=0.627181887626648
[5/24] Train loss=0.7460986971855164
[10/24] Train loss=0.745538055896759
[15/24] Train loss=0.6725336909294128
[20/24] Train loss=0.609662652015686
Test set avg_accuracy=83.80% avg_sensitivity=85.36%, avg_specificity=83.25% avg_auc=92.10%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.666184 Test loss=0.360961 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.6316252946853638
[5/24] Train loss=0.7299209833145142
[10/24] Train loss=0.7551814317703247
[15/24] Train loss=0.6702909469604492
[20/24] Train loss=0.6168115139007568
Test set avg_accuracy=84.09% avg_sensitivity=85.21%, avg_specificity=83.69% avg_auc=92.12%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.662820 Test loss=0.358593 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.6276220083236694
[5/24] Train loss=0.7248464226722717
[10/24] Train loss=0.7470293045043945
[15/24] Train loss=0.6637983322143555
[20/24] Train loss=0.6366735100746155
Test set avg_accuracy=83.95% avg_sensitivity=85.61%, avg_specificity=83.36% avg_auc=92.14%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.663376 Test loss=0.359685 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.6269452571868896
[5/24] Train loss=0.7294980883598328
[10/24] Train loss=0.7339303493499756
[15/24] Train loss=0.668326199054718
[20/24] Train loss=0.606961727142334
Test set avg_accuracy=82.97% avg_sensitivity=86.61%, avg_specificity=81.69% avg_auc=92.06%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.659911 Test loss=0.377560 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.6430143117904663
[5/24] Train loss=0.7145982980728149
[10/24] Train loss=0.7427222728729248
[15/24] Train loss=0.6508370041847229
[20/24] Train loss=0.6035453677177429
Test set avg_accuracy=83.48% avg_sensitivity=85.86%, avg_specificity=82.64% avg_auc=92.08%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.655785 Test loss=0.367239 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.6209954619407654
[5/24] Train loss=0.7113157510757446
[10/24] Train loss=0.7655481100082397
[15/24] Train loss=0.6611906886100769
[20/24] Train loss=0.6045861840248108
Test set avg_accuracy=83.39% avg_sensitivity=86.16%, avg_specificity=82.41% avg_auc=92.14%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.655020 Test loss=0.367687 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.6236754059791565
[5/24] Train loss=0.7109529972076416
[10/24] Train loss=0.7473155856132507
[15/24] Train loss=0.6393056511878967
[20/24] Train loss=0.6036410331726074
Test set avg_accuracy=83.53% avg_sensitivity=85.76%, avg_specificity=82.74% avg_auc=92.01%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.651077 Test loss=0.366565 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.6212424039840698
[5/24] Train loss=0.7078965902328491
[10/24] Train loss=0.7464495301246643
[15/24] Train loss=0.6520613431930542
[20/24] Train loss=0.5813785791397095
Test set avg_accuracy=83.32% avg_sensitivity=86.56%, avg_specificity=82.18% avg_auc=92.05%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.651024 Test loss=0.372764 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.6216832995414734
[5/24] Train loss=0.7170580625534058
[10/24] Train loss=0.7416582107543945
[15/24] Train loss=0.6342145800590515
[20/24] Train loss=0.6096508502960205
Test set avg_accuracy=83.48% avg_sensitivity=85.81%, avg_specificity=82.66% avg_auc=92.00%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.649433 Test loss=0.370135 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.6221546530723572
[5/24] Train loss=0.7052645683288574
[10/24] Train loss=0.7504554390907288
[15/24] Train loss=0.6249613761901855
[20/24] Train loss=0.6100587248802185
Test set avg_accuracy=83.31% avg_sensitivity=86.41%, avg_specificity=82.22% avg_auc=92.09%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.649684 Test loss=0.372046 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.6087728142738342
[5/24] Train loss=0.7033326625823975
[10/24] Train loss=0.7503612041473389
[15/24] Train loss=0.6432639360427856
[20/24] Train loss=0.5972245931625366
Test set avg_accuracy=84.24% avg_sensitivity=85.21%, avg_specificity=83.91% avg_auc=92.21%
Best model saved!! Metric=19.56369199815262!!
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.646014 Test loss=0.354115 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.615129828453064
[5/24] Train loss=0.7122679352760315
[10/24] Train loss=0.7336785793304443
[15/24] Train loss=0.6349767446517944
[20/24] Train loss=0.5876949429512024
Test set avg_accuracy=83.91% avg_sensitivity=86.36%, avg_specificity=83.04% avg_auc=92.18%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.642540 Test loss=0.364801 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.6148145198822021
[5/24] Train loss=0.6925416588783264
[10/24] Train loss=0.7399069666862488
[15/24] Train loss=0.6498008966445923
[20/24] Train loss=0.5864025354385376
Test set avg_accuracy=83.66% avg_sensitivity=86.41%, avg_specificity=82.69% avg_auc=92.26%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.640662 Test loss=0.364840 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.6171303391456604
[5/24] Train loss=0.7087789177894592
[10/24] Train loss=0.720977246761322
[15/24] Train loss=0.64044588804245
[20/24] Train loss=0.602355420589447
Test set avg_accuracy=84.01% avg_sensitivity=85.86%, avg_specificity=83.36% avg_auc=92.25%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.642272 Test loss=0.359091 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.6144421100616455
[5/24] Train loss=0.688553512096405
[10/24] Train loss=0.7304666042327881
[15/24] Train loss=0.6325732469558716
[20/24] Train loss=0.5974974632263184
Test set avg_accuracy=83.26% avg_sensitivity=86.61%, avg_specificity=82.07% avg_auc=92.11%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.638647 Test loss=0.372043 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.616956353187561
[5/24] Train loss=0.6801862716674805
[10/24] Train loss=0.7442920804023743
[15/24] Train loss=0.6355445981025696
[20/24] Train loss=0.5913382768630981
Test set avg_accuracy=83.22% avg_sensitivity=86.96%, avg_specificity=81.90% avg_auc=92.17%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.640347 Test loss=0.373014 Current lr=[0.000224838296036774]

[0/24] Train loss=0.6059467792510986
[5/24] Train loss=0.6906495094299316
[10/24] Train loss=0.7417831420898438
[15/24] Train loss=0.6369662284851074
[20/24] Train loss=0.5824840068817139
Test set avg_accuracy=83.18% avg_sensitivity=87.01%, avg_specificity=81.83% avg_auc=92.22%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.637531 Test loss=0.375305 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.6108244061470032
[5/24] Train loss=0.6894729137420654
[10/24] Train loss=0.7339550256729126
[15/24] Train loss=0.6304211616516113
[20/24] Train loss=0.5838910937309265
Test set avg_accuracy=84.51% avg_sensitivity=84.56%, avg_specificity=84.49% avg_auc=92.34%
Best model saved!! Metric=19.888190024386034!!
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.633382 Test loss=0.345662 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.6070157885551453
[5/24] Train loss=0.7046322226524353
[10/24] Train loss=0.71503084897995
[15/24] Train loss=0.6259379386901855
[20/24] Train loss=0.588361382484436
Test set avg_accuracy=83.50% avg_sensitivity=86.86%, avg_specificity=82.32% avg_auc=92.34%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.636453 Test loss=0.367374 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.6105614900588989
[5/24] Train loss=0.6948578357696533
[10/24] Train loss=0.7238650321960449
[15/24] Train loss=0.6369194388389587
[20/24] Train loss=0.5676532983779907
Test set avg_accuracy=83.75% avg_sensitivity=86.36%, avg_specificity=82.83% avg_auc=92.27%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.632169 Test loss=0.361721 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.5934262871742249
[5/24] Train loss=0.6794095039367676
[10/24] Train loss=0.7195168137550354
[15/24] Train loss=0.622683048248291
[20/24] Train loss=0.5819039940834045
Test set avg_accuracy=83.72% avg_sensitivity=86.56%, avg_specificity=82.73% avg_auc=92.33%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.629415 Test loss=0.362642 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.6031784415245056
[5/24] Train loss=0.6807275414466858
[10/24] Train loss=0.727448582649231
[15/24] Train loss=0.6227687001228333
[20/24] Train loss=0.5722358226776123
Test set avg_accuracy=83.40% avg_sensitivity=86.71%, avg_specificity=82.23% avg_auc=92.32%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.627967 Test loss=0.365836 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.6087995171546936
[5/24] Train loss=0.6755741238594055
[10/24] Train loss=0.7150505185127258
[15/24] Train loss=0.6276648044586182
[20/24] Train loss=0.5671234130859375
Test set avg_accuracy=83.45% avg_sensitivity=87.01%, avg_specificity=82.20% avg_auc=92.31%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.626241 Test loss=0.366986 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.6054770350456238
[5/24] Train loss=0.6782744526863098
[10/24] Train loss=0.7220680117607117
[15/24] Train loss=0.6293381452560425
[20/24] Train loss=0.5744615793228149
Test set avg_accuracy=83.46% avg_sensitivity=87.31%, avg_specificity=82.11% avg_auc=92.37%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.627618 Test loss=0.367075 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.6073705554008484
[5/24] Train loss=0.6794915795326233
[10/24] Train loss=0.7015131711959839
[15/24] Train loss=0.6135998368263245
[20/24] Train loss=0.5620031356811523
Test set avg_accuracy=84.13% avg_sensitivity=85.21%, avg_specificity=83.75% avg_auc=92.33%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.624455 Test loss=0.348988 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.5961706042289734
[5/24] Train loss=0.6905983090400696
[10/24] Train loss=0.7105658650398254
[15/24] Train loss=0.6236141324043274
[20/24] Train loss=0.5657098293304443
Test set avg_accuracy=84.36% avg_sensitivity=85.11%, avg_specificity=84.10% avg_auc=92.29%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.625728 Test loss=0.350518 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.5952358841896057
[5/24] Train loss=0.6701361536979675
[10/24] Train loss=0.7059229612350464
[15/24] Train loss=0.6031113266944885
[20/24] Train loss=0.5640203952789307
Test set avg_accuracy=85.00% avg_sensitivity=83.66%, avg_specificity=85.47% avg_auc=92.38%
Best model saved!! Metric=20.51157560856832!!
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.621665 Test loss=0.337692 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.5905905961990356
[5/24] Train loss=0.67655348777771
[10/24] Train loss=0.7092703580856323
[15/24] Train loss=0.6128979325294495
[20/24] Train loss=0.5713706016540527
Test set avg_accuracy=85.03% avg_sensitivity=83.11%, avg_specificity=85.70% avg_auc=92.33%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.621279 Test loss=0.334860 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.5968001484870911
[5/24] Train loss=0.6757119297981262
[10/24] Train loss=0.7183673977851868
[15/24] Train loss=0.6049569249153137
[20/24] Train loss=0.5709672570228577
Test set avg_accuracy=85.01% avg_sensitivity=83.56%, avg_specificity=85.53% avg_auc=92.45%
Best model saved!! Metric=20.550952343014316!!
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.621965 Test loss=0.337092 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.5873127579689026
[5/24] Train loss=0.6733349561691284
[10/24] Train loss=0.717164158821106
[15/24] Train loss=0.6061181426048279
[20/24] Train loss=0.5774423480033875
Test set avg_accuracy=84.62% avg_sensitivity=85.76%, avg_specificity=84.22% avg_auc=92.52%
Best model saved!! Metric=21.117666951076075!!
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.619948 Test loss=0.347550 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.594461977481842
[5/24] Train loss=0.6585863828659058
[10/24] Train loss=0.7194656729698181
[15/24] Train loss=0.5980421304702759
[20/24] Train loss=0.5776788592338562
Test set avg_accuracy=84.31% avg_sensitivity=85.06%, avg_specificity=84.05% avg_auc=92.38%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.617463 Test loss=0.348504 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.5880237817764282
[5/24] Train loss=0.653396487236023
[10/24] Train loss=0.7114953994750977
[15/24] Train loss=0.6042065024375916
[20/24] Train loss=0.5664735436439514
Test set avg_accuracy=84.08% avg_sensitivity=85.56%, avg_specificity=83.55% avg_auc=92.29%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.615010 Test loss=0.353621 Current lr=[0.000156543481933168]

[0/24] Train loss=0.5951460599899292
[5/24] Train loss=0.6541728973388672
[10/24] Train loss=0.701637864112854
[15/24] Train loss=0.5960227251052856
[20/24] Train loss=0.5663875937461853
Test set avg_accuracy=84.32% avg_sensitivity=85.26%, avg_specificity=83.99% avg_auc=92.42%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.611394 Test loss=0.347196 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.5892370939254761
[5/24] Train loss=0.6484840512275696
[10/24] Train loss=0.7083048820495605
[15/24] Train loss=0.5981506109237671
[20/24] Train loss=0.5571513772010803
Test set avg_accuracy=84.01% avg_sensitivity=85.41%, avg_specificity=83.52% avg_auc=92.41%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.614578 Test loss=0.349204 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.5858760476112366
[5/24] Train loss=0.6505109071731567
[10/24] Train loss=0.7276524901390076
[15/24] Train loss=0.5899150371551514
[20/24] Train loss=0.5535907745361328
Test set avg_accuracy=83.74% avg_sensitivity=86.01%, avg_specificity=82.94% avg_auc=92.45%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.619697 Test loss=0.354756 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.5708873867988586
[5/24] Train loss=0.6579172015190125
[10/24] Train loss=0.731774091720581
[15/24] Train loss=0.599524974822998
[20/24] Train loss=0.5975276231765747
Test set avg_accuracy=81.03% avg_sensitivity=90.20%, avg_specificity=77.80% avg_auc=92.29%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.624026 Test loss=0.415119 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.6246930956840515
[5/24] Train loss=0.685721755027771
[10/24] Train loss=0.6884145736694336
[15/24] Train loss=0.6013449430465698
[20/24] Train loss=0.6074231266975403
Test set avg_accuracy=81.77% avg_sensitivity=89.26%, avg_specificity=79.13% avg_auc=92.34%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.625095 Test loss=0.396630 Current lr=[0.000134135431043539]

[0/24] Train loss=0.6149125099182129
[5/24] Train loss=0.6740112900733948
[10/24] Train loss=0.7113379240036011
[15/24] Train loss=0.6005651354789734
[20/24] Train loss=0.564326286315918
Test set avg_accuracy=82.11% avg_sensitivity=89.41%, avg_specificity=79.54% avg_auc=92.36%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.613884 Test loss=0.392528 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.6046806573867798
[5/24] Train loss=0.6581379175186157
[10/24] Train loss=0.6896530389785767
[15/24] Train loss=0.5875809192657471
[20/24] Train loss=0.5808089375495911
Test set avg_accuracy=81.37% avg_sensitivity=90.00%, avg_specificity=78.32% avg_auc=92.35%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.613507 Test loss=0.405155 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.6061187982559204
[5/24] Train loss=0.6773796677589417
[10/24] Train loss=0.6875688433647156
[15/24] Train loss=0.5768627524375916
[20/24] Train loss=0.5793900489807129
Test set avg_accuracy=81.64% avg_sensitivity=90.00%, avg_specificity=78.69% avg_auc=92.30%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.612703 Test loss=0.404628 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.6094450354576111
[5/24] Train loss=0.6688143610954285
[10/24] Train loss=0.697458803653717
[15/24] Train loss=0.5893113613128662
[20/24] Train loss=0.5611005425453186
Test set avg_accuracy=81.95% avg_sensitivity=89.66%, avg_specificity=79.24% avg_auc=92.41%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.609486 Test loss=0.394202 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.6082461476325989
[5/24] Train loss=0.6632440090179443
[10/24] Train loss=0.6928516626358032
[15/24] Train loss=0.583855390548706
[20/24] Train loss=0.5544324517250061
Test set avg_accuracy=82.49% avg_sensitivity=88.46%, avg_specificity=80.38% avg_auc=92.43%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.606131 Test loss=0.378356 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.5847014784812927
[5/24] Train loss=0.6435660123825073
[10/24] Train loss=0.6988327503204346
[15/24] Train loss=0.5912071466445923
[20/24] Train loss=0.5702843070030212
Test set avg_accuracy=82.34% avg_sensitivity=88.81%, avg_specificity=80.07% avg_auc=92.48%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.603677 Test loss=0.383451 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.5871119499206543
[5/24] Train loss=0.6655849814414978
[10/24] Train loss=0.6914255023002625
[15/24] Train loss=0.5873200297355652
[20/24] Train loss=0.5587481260299683
Test set avg_accuracy=82.66% avg_sensitivity=88.61%, avg_specificity=80.56% avg_auc=92.48%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.603641 Test loss=0.377644 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.594849705696106
[5/24] Train loss=0.6629793047904968
[10/24] Train loss=0.6895023584365845
[15/24] Train loss=0.5956910848617554
[20/24] Train loss=0.5533583760261536
Test set avg_accuracy=82.43% avg_sensitivity=89.01%, avg_specificity=80.12% avg_auc=92.47%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.603249 Test loss=0.383251 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.5921485424041748
[5/24] Train loss=0.6500332951545715
[10/24] Train loss=0.7032654881477356
[15/24] Train loss=0.5782857537269592
[20/24] Train loss=0.5546861290931702
Test set avg_accuracy=82.46% avg_sensitivity=88.66%, avg_specificity=80.28% avg_auc=92.47%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.599778 Test loss=0.380226 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.5886514186859131
[5/24] Train loss=0.6494925022125244
[10/24] Train loss=0.6922227740287781
[15/24] Train loss=0.5775529146194458
[20/24] Train loss=0.545869767665863
Test set avg_accuracy=82.27% avg_sensitivity=89.51%, avg_specificity=79.71% avg_auc=92.51%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.600847 Test loss=0.388321 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.5911974906921387
[5/24] Train loss=0.670323371887207
[10/24] Train loss=0.7016891837120056
[15/24] Train loss=0.582636296749115
[20/24] Train loss=0.5510490536689758
Test set avg_accuracy=82.70% avg_sensitivity=88.71%, avg_specificity=80.58% avg_auc=92.49%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.599276 Test loss=0.380911 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.5836147665977478
[5/24] Train loss=0.6650172472000122
[10/24] Train loss=0.6933997869491577
[15/24] Train loss=0.5797868371009827
[20/24] Train loss=0.5571408867835999
Test set avg_accuracy=82.42% avg_sensitivity=89.26%, avg_specificity=80.01% avg_auc=92.50%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.598359 Test loss=0.387365 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.5902240872383118
[5/24] Train loss=0.6569795608520508
[10/24] Train loss=0.7033112049102783
[15/24] Train loss=0.5842726826667786
[20/24] Train loss=0.5496440529823303
Test set avg_accuracy=82.23% avg_sensitivity=89.66%, avg_specificity=79.61% avg_auc=92.49%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.595506 Test loss=0.393150 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.5878875255584717
[5/24] Train loss=0.6522711515426636
[10/24] Train loss=0.6983180046081543
[15/24] Train loss=0.5795338749885559
[20/24] Train loss=0.5584245920181274
Test set avg_accuracy=81.61% avg_sensitivity=90.35%, avg_specificity=78.53% avg_auc=92.51%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.595479 Test loss=0.405946 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.605369508266449
[5/24] Train loss=0.655038595199585
[10/24] Train loss=0.6922468543052673
[15/24] Train loss=0.5922845005989075
[20/24] Train loss=0.5774713754653931
Test set avg_accuracy=81.34% avg_sensitivity=90.50%, avg_specificity=78.11% avg_auc=92.52%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.597897 Test loss=0.410517 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.6084278225898743
[5/24] Train loss=0.644106924533844
[10/24] Train loss=0.6984282732009888
[15/24] Train loss=0.589679479598999
[20/24] Train loss=0.587939977645874
Test set avg_accuracy=81.86% avg_sensitivity=90.55%, avg_specificity=78.80% avg_auc=92.58%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.601071 Test loss=0.400753 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.6012848019599915
[5/24] Train loss=0.6450968980789185
[10/24] Train loss=0.6984043717384338
[15/24] Train loss=0.5984190702438354
[20/24] Train loss=0.5857535600662231
Test set avg_accuracy=82.45% avg_sensitivity=89.96%, avg_specificity=79.80% avg_auc=92.54%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.599735 Test loss=0.389182 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.5881341695785522
[5/24] Train loss=0.6283139586448669
[10/24] Train loss=0.694513201713562
[15/24] Train loss=0.5891572833061218
[20/24] Train loss=0.5611913800239563
Test set avg_accuracy=82.41% avg_sensitivity=89.71%, avg_specificity=79.84% avg_auc=92.46%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.595528 Test loss=0.389382 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.5878561735153198
[5/24] Train loss=0.6249381899833679
[10/24] Train loss=0.6919339895248413
[15/24] Train loss=0.5793434381484985
[20/24] Train loss=0.5597570538520813
Test set avg_accuracy=82.85% avg_sensitivity=89.01%, avg_specificity=80.68% avg_auc=92.53%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.591473 Test loss=0.378706 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.5802766680717468
[5/24] Train loss=0.6235603094100952
[10/24] Train loss=0.6686331629753113
[15/24] Train loss=0.5858550667762756
[20/24] Train loss=0.5584340691566467
Test set avg_accuracy=83.20% avg_sensitivity=88.26%, avg_specificity=81.42% avg_auc=92.55%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.592289 Test loss=0.371421 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.5719035267829895
[5/24] Train loss=0.624908983707428
[10/24] Train loss=0.6683954000473022
[15/24] Train loss=0.5722183585166931
[20/24] Train loss=0.5572236776351929
Test set avg_accuracy=83.36% avg_sensitivity=88.01%, avg_specificity=81.72% avg_auc=92.57%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.589867 Test loss=0.369188 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.575186014175415
[5/24] Train loss=0.62224280834198
[10/24] Train loss=0.6698501110076904
[15/24] Train loss=0.5724985003471375
[20/24] Train loss=0.5641900897026062
Test set avg_accuracy=83.10% avg_sensitivity=88.41%, avg_specificity=81.23% avg_auc=92.54%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.586412 Test loss=0.373544 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.5760292410850525
[5/24] Train loss=0.6120055317878723
[10/24] Train loss=0.6656142473220825
[15/24] Train loss=0.5793503522872925
[20/24] Train loss=0.5595927834510803
Test set avg_accuracy=83.57% avg_sensitivity=87.56%, avg_specificity=82.16% avg_auc=92.55%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.586506 Test loss=0.364885 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.5690949559211731
[5/24] Train loss=0.6048520803451538
[10/24] Train loss=0.6801236867904663
[15/24] Train loss=0.5787079334259033
[20/24] Train loss=0.5472888350486755
Test set avg_accuracy=83.23% avg_sensitivity=88.06%, avg_specificity=81.53% avg_auc=92.53%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.582651 Test loss=0.371145 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.5720967650413513
[5/24] Train loss=0.6176393032073975
[10/24] Train loss=0.6702568531036377
[15/24] Train loss=0.577495276927948
[20/24] Train loss=0.5531431436538696
Test set avg_accuracy=83.35% avg_sensitivity=87.91%, avg_specificity=81.74% avg_auc=92.56%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.584212 Test loss=0.368629 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.5760864019393921
[5/24] Train loss=0.6256117820739746
[10/24] Train loss=0.6701697111129761
[15/24] Train loss=0.5726937055587769
[20/24] Train loss=0.5367830991744995
Test set avg_accuracy=83.10% avg_sensitivity=88.36%, avg_specificity=81.25% avg_auc=92.55%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.582943 Test loss=0.373723 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.5779203772544861
[5/24] Train loss=0.6194731593132019
[10/24] Train loss=0.6742298603057861
[15/24] Train loss=0.5864032506942749
[20/24] Train loss=0.5507369637489319
Test set avg_accuracy=83.28% avg_sensitivity=88.11%, avg_specificity=81.58% avg_auc=92.53%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.583837 Test loss=0.371221 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.5802897214889526
[5/24] Train loss=0.616300642490387
[10/24] Train loss=0.6674790978431702
[15/24] Train loss=0.5779042840003967
[20/24] Train loss=0.5544607043266296
Test set avg_accuracy=83.29% avg_sensitivity=88.16%, avg_specificity=81.58% avg_auc=92.54%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.582585 Test loss=0.370395 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.5727905631065369
[5/24] Train loss=0.617118239402771
[10/24] Train loss=0.6730883717536926
[15/24] Train loss=0.5803619027137756
[20/24] Train loss=0.542978048324585
Test set avg_accuracy=83.12% avg_sensitivity=88.56%, avg_specificity=81.21% avg_auc=92.53%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.581579 Test loss=0.375879 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.5753233432769775
[5/24] Train loss=0.624195396900177
[10/24] Train loss=0.6694598197937012
[15/24] Train loss=0.5804256200790405
[20/24] Train loss=0.5503858327865601
Test set avg_accuracy=82.80% avg_sensitivity=88.71%, avg_specificity=80.72% avg_auc=92.54%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.582174 Test loss=0.379717 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.5851437449455261
[5/24] Train loss=0.6187713742256165
[10/24] Train loss=0.6716185808181763
[15/24] Train loss=0.5683085322380066
[20/24] Train loss=0.543448269367218
Test set avg_accuracy=82.64% avg_sensitivity=89.16%, avg_specificity=80.35% avg_auc=92.52%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.581014 Test loss=0.384339 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.5831485986709595
[5/24] Train loss=0.6101272702217102
[10/24] Train loss=0.6646503806114197
[15/24] Train loss=0.5781643390655518
[20/24] Train loss=0.5453102588653564
Test set avg_accuracy=82.67% avg_sensitivity=89.16%, avg_specificity=80.38% avg_auc=92.52%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.582977 Test loss=0.384139 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.5753585696220398
[5/24] Train loss=0.6196328997612
[10/24] Train loss=0.6570185422897339
[15/24] Train loss=0.5818215012550354
[20/24] Train loss=0.5609630346298218
Test set avg_accuracy=82.92% avg_sensitivity=88.61%, avg_specificity=80.91% avg_auc=92.52%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.584498 Test loss=0.379119 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.5730109214782715
[5/24] Train loss=0.6144291162490845
[10/24] Train loss=0.668865978717804
[15/24] Train loss=0.5973392128944397
[20/24] Train loss=0.5628465414047241
Test set avg_accuracy=83.29% avg_sensitivity=88.06%, avg_specificity=81.62% avg_auc=92.54%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.584863 Test loss=0.370810 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.5630007982254028
[5/24] Train loss=0.5986406207084656
[10/24] Train loss=0.6660999655723572
[15/24] Train loss=0.5736857652664185
[20/24] Train loss=0.5644300580024719
Test set avg_accuracy=83.83% avg_sensitivity=86.61%, avg_specificity=82.85% avg_auc=92.55%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.583444 Test loss=0.356334 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.5650363564491272
[5/24] Train loss=0.6157638430595398
[10/24] Train loss=0.6663414239883423
[15/24] Train loss=0.5642478466033936
[20/24] Train loss=0.5692151784896851
Test set avg_accuracy=84.57% avg_sensitivity=85.66%, avg_specificity=84.19% avg_auc=92.56%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.581540 Test loss=0.346248 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.5649651885032654
[5/24] Train loss=0.6070343255996704
[10/24] Train loss=0.6761672496795654
[15/24] Train loss=0.5617335438728333
[20/24] Train loss=0.5460284352302551
Test set avg_accuracy=84.34% avg_sensitivity=86.16%, avg_specificity=83.69% avg_auc=92.56%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.577404 Test loss=0.349742 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.5548624396324158
[5/24] Train loss=0.6146611571311951
[10/24] Train loss=0.6732784509658813
[15/24] Train loss=0.5644904971122742
[20/24] Train loss=0.5569051504135132
Test set avg_accuracy=84.00% avg_sensitivity=86.86%, avg_specificity=82.99% avg_auc=92.56%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.578888 Test loss=0.356214 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.5715857148170471
[5/24] Train loss=0.5983632802963257
[10/24] Train loss=0.6792998909950256
[15/24] Train loss=0.5749378800392151
[20/24] Train loss=0.5578927397727966
Test set avg_accuracy=84.11% avg_sensitivity=86.36%, avg_specificity=83.32% avg_auc=92.55%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.578669 Test loss=0.353612 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.5593038201332092
[5/24] Train loss=0.6184142827987671
[10/24] Train loss=0.6773961782455444
[15/24] Train loss=0.5820955038070679
[20/24] Train loss=0.560147225856781
Test set avg_accuracy=84.04% avg_sensitivity=86.66%, avg_specificity=83.11% avg_auc=92.55%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.578956 Test loss=0.354560 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.5679733157157898
[5/24] Train loss=0.6022893786430359
[10/24] Train loss=0.6634219288825989
[15/24] Train loss=0.570959746837616
[20/24] Train loss=0.5521489977836609
Test set avg_accuracy=84.04% avg_sensitivity=86.51%, avg_specificity=83.17% avg_auc=92.55%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.578076 Test loss=0.354573 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.5654906034469604
[5/24] Train loss=0.6178784370422363
[10/24] Train loss=0.6654070615768433
[15/24] Train loss=0.5605519413948059
[20/24] Train loss=0.5428606271743774
Test set avg_accuracy=84.00% avg_sensitivity=86.66%, avg_specificity=83.06% avg_auc=92.55%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.577227 Test loss=0.355734 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.5699955821037292
[5/24] Train loss=0.6013062000274658
[10/24] Train loss=0.6721106767654419
[15/24] Train loss=0.566483199596405
[20/24] Train loss=0.5433566570281982
Test set avg_accuracy=84.00% avg_sensitivity=86.51%, avg_specificity=83.11% avg_auc=92.55%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.576768 Test loss=0.354854 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.5716134905815125
[5/24] Train loss=0.6001597046852112
[10/24] Train loss=0.6755354404449463
[15/24] Train loss=0.5584535598754883
[20/24] Train loss=0.5488889217376709
Test set avg_accuracy=84.00% avg_sensitivity=86.56%, avg_specificity=83.10% avg_auc=92.55%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.577776 Test loss=0.355590 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.5568134188652039
[5/24] Train loss=0.6026828289031982
[10/24] Train loss=0.6734591126441956
[15/24] Train loss=0.5571944117546082
[20/24] Train loss=0.559066116809845
Test set avg_accuracy=83.95% avg_sensitivity=86.56%, avg_specificity=83.03% avg_auc=92.55%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.576398 Test loss=0.356249 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.5606862306594849
[5/24] Train loss=0.6087978482246399
[10/24] Train loss=0.6541951894760132
[15/24] Train loss=0.5703071355819702
[20/24] Train loss=0.5511808395385742
Test set avg_accuracy=83.95% avg_sensitivity=86.56%, avg_specificity=83.03% avg_auc=92.55%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.576100 Test loss=0.356184 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.5680375695228577
[5/24] Train loss=0.60807865858078
[10/24] Train loss=0.6667124032974243
[15/24] Train loss=0.5637056231498718
[20/24] Train loss=0.5486482977867126
Test set avg_accuracy=83.95% avg_sensitivity=86.56%, avg_specificity=83.03% avg_auc=92.55%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.577976 Test loss=0.356056 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.568416178226471
[5/24] Train loss=0.6087575554847717
[10/24] Train loss=0.6630572080612183
[15/24] Train loss=0.5647396445274353
[20/24] Train loss=0.5457406640052795
Test set avg_accuracy=83.96% avg_sensitivity=86.56%, avg_specificity=83.04% avg_auc=92.55%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.577436 Test loss=0.356059 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.5587174892425537
[5/24] Train loss=0.605624794960022
[10/24] Train loss=0.6621531248092651
[15/24] Train loss=0.5694786310195923
[20/24] Train loss=0.5521993041038513
Test set avg_accuracy=83.96% avg_sensitivity=86.56%, avg_specificity=83.04% avg_auc=92.55%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.576971 Test loss=0.356057 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=84.62% sen=85.76%, spe=84.22%, auc=92.52%!
Fold[4] Avg_overlap=0.63%(±0.23553609116713078)
[0/24] Train loss=1.9380275011062622
[5/24] Train loss=1.610975742340088
[10/24] Train loss=1.5057892799377441
[15/24] Train loss=1.4409679174423218
[20/24] Train loss=1.4303780794143677
Test set avg_accuracy=62.19% avg_sensitivity=39.99%, avg_specificity=69.76% avg_auc=57.33%
Best model saved!! Metric=-96.73494648131027!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=1.546765 Test loss=0.659078 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.4192252159118652
[5/24] Train loss=1.4123778343200684
[10/24] Train loss=1.4138880968093872
[15/24] Train loss=1.3818527460098267
[20/24] Train loss=1.3947280645370483
Test set avg_accuracy=59.35% avg_sensitivity=61.24%, avg_specificity=58.70% avg_auc=63.59%
Best model saved!! Metric=-83.1129756914186!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=1.403114 Test loss=0.682949 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3650190830230713
[5/24] Train loss=1.3717875480651855
[10/24] Train loss=1.3733514547348022
[15/24] Train loss=1.3598374128341675
[20/24] Train loss=1.374704122543335
Test set avg_accuracy=68.03% avg_sensitivity=57.86%, avg_specificity=71.50% avg_auc=69.31%
Best model saved!! Metric=-59.291843110297094!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=1.373426 Test loss=0.657792 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.353163480758667
[5/24] Train loss=1.3354594707489014
[10/24] Train loss=1.363168716430664
[15/24] Train loss=1.3409699201583862
[20/24] Train loss=1.33385169506073
Test set avg_accuracy=66.88% avg_sensitivity=67.28%, avg_specificity=66.74% avg_auc=72.33%
Best model saved!! Metric=-52.77827915996228!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=1.347305 Test loss=0.658897 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.3330144882202148
[5/24] Train loss=1.322117805480957
[10/24] Train loss=1.348700761795044
[15/24] Train loss=1.3164421319961548
[20/24] Train loss=1.3230751752853394
Test set avg_accuracy=69.17% avg_sensitivity=67.79%, avg_specificity=69.64% avg_auc=75.16%
Best model saved!! Metric=-44.24643774233154!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=1.326796 Test loss=0.644419 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.309957504272461
[5/24] Train loss=1.286835789680481
[10/24] Train loss=1.3317941427230835
[15/24] Train loss=1.2738124132156372
[20/24] Train loss=1.2816298007965088
Test set avg_accuracy=71.18% avg_sensitivity=71.58%, avg_specificity=71.05% avg_auc=77.40%
Best model saved!! Metric=-34.78627673065087!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=1.298322 Test loss=0.631308 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.2695783376693726
[5/24] Train loss=1.2498202323913574
[10/24] Train loss=1.3002312183380127
[15/24] Train loss=1.2429624795913696
[20/24] Train loss=1.2530001401901245
Test set avg_accuracy=72.03% avg_sensitivity=75.93%, avg_specificity=70.70% avg_auc=78.99%
Best model saved!! Metric=-28.34108070396863!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=1.266832 Test loss=0.619934 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.2470757961273193
[5/24] Train loss=1.2070155143737793
[10/24] Train loss=1.2847968339920044
[15/24] Train loss=1.2114033699035645
[20/24] Train loss=1.2153030633926392
Test set avg_accuracy=73.63% avg_sensitivity=77.78%, avg_specificity=72.22% avg_auc=80.73%
Best model saved!! Metric=-21.644063476042902!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=1.232713 Test loss=0.600242 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.1960405111312866
[5/24] Train loss=1.1836881637573242
[10/24] Train loss=1.229535698890686
[15/24] Train loss=1.1659266948699951
[20/24] Train loss=1.1826871633529663
Test set avg_accuracy=74.93% avg_sensitivity=80.44%, avg_specificity=73.06% avg_auc=82.26%
Best model saved!! Metric=-15.308533504132711!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=1.193215 Test loss=0.582820 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.1513502597808838
[5/24] Train loss=1.134278416633606
[10/24] Train loss=1.223543643951416
[15/24] Train loss=1.1186232566833496
[20/24] Train loss=1.141223669052124
Test set avg_accuracy=75.69% avg_sensitivity=83.00%, avg_specificity=73.20% avg_auc=83.53%
Best model saved!! Metric=-10.586054677396334!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=1.153832 Test loss=0.564181 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.0955431461334229
[5/24] Train loss=1.0814268589019775
[10/24] Train loss=1.1659722328186035
[15/24] Train loss=1.0779212713241577
[20/24] Train loss=1.1191917657852173
Test set avg_accuracy=75.83% avg_sensitivity=85.92%, avg_specificity=72.39% avg_auc=84.61%
Best model saved!! Metric=-7.246246143549243!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=1.110107 Test loss=0.554318 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.0938290357589722
[5/24] Train loss=1.0416654348373413
[10/24] Train loss=1.1310346126556396
[15/24] Train loss=1.0340547561645508
[20/24] Train loss=1.0537612438201904
Test set avg_accuracy=76.12% avg_sensitivity=87.66%, avg_specificity=72.18% avg_auc=85.37%
Best model saved!! Metric=-4.6637361309370675!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=1.073833 Test loss=0.542676 Current lr=[5.97283087248885e-05]

[0/24] Train loss=1.0522626638412476
[5/24] Train loss=1.02798593044281
[10/24] Train loss=1.1167856454849243
[15/24] Train loss=0.9962362051010132
[20/24] Train loss=1.0231032371520996
Test set avg_accuracy=76.86% avg_sensitivity=87.25%, avg_specificity=73.32% avg_auc=85.92%
Best model saved!! Metric=-2.6514176830488054!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=1.043101 Test loss=0.520371 Current lr=[6.744022406141468e-05]

[0/24] Train loss=1.0132153034210205
[5/24] Train loss=0.9985734820365906
[10/24] Train loss=1.0947277545928955
[15/24] Train loss=0.9575368762016296
[20/24] Train loss=1.0171425342559814
Test set avg_accuracy=76.37% avg_sensitivity=88.89%, avg_specificity=72.10% avg_auc=86.46%
Best model saved!! Metric=-2.1879203956847846!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=1.013247 Test loss=0.518615 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.9836029410362244
[5/24] Train loss=0.9623872637748718
[10/24] Train loss=1.0833635330200195
[15/24] Train loss=0.9414898157119751
[20/24] Train loss=0.9845188856124878
Test set avg_accuracy=76.68% avg_sensitivity=88.79%, avg_specificity=72.55% avg_auc=87.06%
Best model saved!! Metric=-0.9204216120643736!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.994809 Test loss=0.507667 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.9636151790618896
[5/24] Train loss=0.9571722149848938
[10/24] Train loss=1.0498045682907104
[15/24] Train loss=0.9269699454307556
[20/24] Train loss=0.9585127830505371
Test set avg_accuracy=76.11% avg_sensitivity=89.66%, avg_specificity=71.49% avg_auc=87.49%
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.976435 Test loss=0.505954 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.9588978290557861
[5/24] Train loss=0.9304788708686829
[10/24] Train loss=1.0598151683807373
[15/24] Train loss=0.921156108379364
[20/24] Train loss=0.9427523016929626
Test set avg_accuracy=76.54% avg_sensitivity=88.43%, avg_specificity=72.48% avg_auc=87.84%
Best model saved!! Metric=-0.7095998324091823!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.965642 Test loss=0.486925 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.944513738155365
[5/24] Train loss=0.9335739612579346
[10/24] Train loss=1.043887972831726
[15/24] Train loss=0.8913394808769226
[20/24] Train loss=0.9166573286056519
Test set avg_accuracy=76.72% avg_sensitivity=88.48%, avg_specificity=72.71% avg_auc=88.22%
Best model saved!! Metric=0.1214544306704255!!
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.956768 Test loss=0.477055 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.93059903383255
[5/24] Train loss=0.9223784804344177
[10/24] Train loss=1.050328254699707
[15/24] Train loss=0.8829752206802368
[20/24] Train loss=0.9108696579933167
Test set avg_accuracy=77.42% avg_sensitivity=88.07%, avg_specificity=73.79% avg_auc=88.32%
Best model saved!! Metric=1.59998676583713!!
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.944519 Test loss=0.466701 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.9053376913070679
[5/24] Train loss=0.9209828972816467
[10/24] Train loss=1.024200677871704
[15/24] Train loss=0.860004186630249
[20/24] Train loss=0.8895534873008728
Test set avg_accuracy=78.54% avg_sensitivity=86.99%, avg_specificity=75.66% avg_auc=88.73%
Best model saved!! Metric=3.929693897475971!!
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.932607 Test loss=0.446310 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.893724262714386
[5/24] Train loss=0.900317370891571
[10/24] Train loss=1.0135388374328613
[15/24] Train loss=0.8406187295913696
[20/24] Train loss=0.8581923842430115
Test set avg_accuracy=79.84% avg_sensitivity=84.79%, avg_specificity=78.16% avg_auc=88.90%
Best model saved!! Metric=5.696594267383233!!
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.914489 Test loss=0.422811 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.8836921453475952
[5/24] Train loss=0.9094499349594116
[10/24] Train loss=0.9846271872520447
[15/24] Train loss=0.8025791049003601
[20/24] Train loss=0.8479835987091064
Test set avg_accuracy=81.08% avg_sensitivity=80.29%, avg_specificity=81.35% avg_auc=88.87%
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.897395 Test loss=0.400863 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.8683294057846069
[5/24] Train loss=0.8757721185684204
[10/24] Train loss=0.9896286725997925
[15/24] Train loss=0.8152209520339966
[20/24] Train loss=0.8310195207595825
Test set avg_accuracy=81.43% avg_sensitivity=79.47%, avg_specificity=82.10% avg_auc=89.24%
Best model saved!! Metric=6.239568057342581!!
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.881903 Test loss=0.389828 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.8519083857536316
[5/24] Train loss=0.8775081634521484
[10/24] Train loss=0.9461095929145813
[15/24] Train loss=0.8026056885719299
[20/24] Train loss=0.8199544548988342
Test set avg_accuracy=82.34% avg_sensitivity=76.29%, avg_specificity=84.41% avg_auc=89.57%
Best model saved!! Metric=6.616364758327592!!
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.872627 Test loss=0.370393 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.847512423992157
[5/24] Train loss=0.8516498804092407
[10/24] Train loss=0.9506731629371643
[15/24] Train loss=0.8209072351455688
[20/24] Train loss=0.7969004511833191
Test set avg_accuracy=83.37% avg_sensitivity=72.66%, avg_specificity=87.03% avg_auc=89.97%
Best model saved!! Metric=7.021867515113755!!
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.858870 Test loss=0.357030 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.8420547842979431
[5/24] Train loss=0.8456767201423645
[10/24] Train loss=0.9350377917289734
[15/24] Train loss=0.7900373339653015
[20/24] Train loss=0.7712721824645996
Test set avg_accuracy=83.72% avg_sensitivity=74.04%, avg_specificity=87.03% avg_auc=90.45%
Best model saved!! Metric=9.236582887070455!!
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.843871 Test loss=0.351278 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.8402020335197449
[5/24] Train loss=0.8392997980117798
[10/24] Train loss=0.9315557479858398
[15/24] Train loss=0.7769503593444824
[20/24] Train loss=0.747966468334198
Test set avg_accuracy=84.06% avg_sensitivity=73.63%, avg_specificity=87.62% avg_auc=90.75%
Best model saved!! Metric=10.058386214105525!!
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.837124 Test loss=0.346767 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.8016777634620667
[5/24] Train loss=0.8279915452003479
[10/24] Train loss=0.9223100543022156
[15/24] Train loss=0.753855288028717
[20/24] Train loss=0.7517873644828796
Test set avg_accuracy=84.06% avg_sensitivity=73.63%, avg_specificity=87.62% avg_auc=90.89%
Best model saved!! Metric=10.204763034640408!!
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.825340 Test loss=0.343314 Current lr=[0.000210185142098938]

[0/24] Train loss=0.8064066767692566
[5/24] Train loss=0.8260102868080139
[10/24] Train loss=0.9210271239280701
[15/24] Train loss=0.7510586380958557
[20/24] Train loss=0.7340807914733887
Test set avg_accuracy=84.30% avg_sensitivity=75.17%, avg_specificity=87.41% avg_auc=91.11%
Best model saved!! Metric=11.986157386117412!!
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.819527 Test loss=0.343564 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.7860177159309387
[5/24] Train loss=0.8059436082839966
[10/24] Train loss=0.9255861639976501
[15/24] Train loss=0.7399581074714661
[20/24] Train loss=0.7312930226325989
Test set avg_accuracy=84.15% avg_sensitivity=78.65%, avg_specificity=86.03% avg_auc=91.24%
Best model saved!! Metric=14.075840813302193!!
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.814292 Test loss=0.351279 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.7761243581771851
[5/24] Train loss=0.8021845817565918
[10/24] Train loss=0.9269395470619202
[15/24] Train loss=0.7332824468612671
[20/24] Train loss=0.7181774973869324
Test set avg_accuracy=84.36% avg_sensitivity=78.03%, avg_specificity=86.52% avg_auc=91.43%
Best model saved!! Metric=14.341939883104857!!
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.803757 Test loss=0.341982 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.7612841725349426
[5/24] Train loss=0.808045506477356
[10/24] Train loss=0.9033437371253967
[15/24] Train loss=0.742535412311554
[20/24] Train loss=0.7142500281333923
Test set avg_accuracy=84.31% avg_sensitivity=75.27%, avg_specificity=87.39% avg_auc=91.02%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.798978 Test loss=0.343158 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.7814188599586487
[5/24] Train loss=0.7980006337165833
[10/24] Train loss=0.9071571826934814
[15/24] Train loss=0.7293290495872498
[20/24] Train loss=0.7048445343971252
Test set avg_accuracy=84.48% avg_sensitivity=78.49%, avg_specificity=86.52% avg_auc=91.45%
Best model saved!! Metric=14.943658620098944!!
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.796579 Test loss=0.343361 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.7533562779426575
[5/24] Train loss=0.7919986844062805
[10/24] Train loss=0.8980664610862732
[15/24] Train loss=0.7114834189414978
[20/24] Train loss=0.6955533623695374
Test set avg_accuracy=84.69% avg_sensitivity=78.65%, avg_specificity=86.75% avg_auc=91.55%
Best model saved!! Metric=15.629156069725141!!
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.791983 Test loss=0.340740 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.7454622387886047
[5/24] Train loss=0.7834212183952332
[10/24] Train loss=0.8916550874710083
[15/24] Train loss=0.7129366993904114
[20/24] Train loss=0.68150395154953
Test set avg_accuracy=84.53% avg_sensitivity=77.88%, avg_specificity=86.80% avg_auc=91.51%
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.785780 Test loss=0.340329 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.7470566630363464
[5/24] Train loss=0.7884281277656555
[10/24] Train loss=0.9059635400772095
[15/24] Train loss=0.6992141008377075
[20/24] Train loss=0.6875974535942078
Test set avg_accuracy=84.39% avg_sensitivity=80.18%, avg_specificity=85.82% avg_auc=91.82%
Best model saved!! Metric=16.210396513394997!!
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.784589 Test loss=0.342746 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.7333411574363708
[5/24] Train loss=0.7778322100639343
[10/24] Train loss=0.8879589438438416
[15/24] Train loss=0.7012590169906616
[20/24] Train loss=0.6962734460830688
Test set avg_accuracy=84.34% avg_sensitivity=81.00%, avg_specificity=85.47% avg_auc=91.76%
Best model saved!! Metric=16.5749846523441!!
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.779796 Test loss=0.347226 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.7341616153717041
[5/24] Train loss=0.7930690050125122
[10/24] Train loss=0.8742081522941589
[15/24] Train loss=0.6921330690383911
[20/24] Train loss=0.6760807037353516
Test set avg_accuracy=84.44% avg_sensitivity=79.26%, avg_specificity=86.21% avg_auc=91.71%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.774856 Test loss=0.342095 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.72999507188797
[5/24] Train loss=0.776334285736084
[10/24] Train loss=0.8896201252937317
[15/24] Train loss=0.6873986721038818
[20/24] Train loss=0.659617006778717
Test set avg_accuracy=84.52% avg_sensitivity=79.83%, avg_specificity=86.12% avg_auc=91.82%
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.770106 Test loss=0.340665 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.7241986989974976
[5/24] Train loss=0.7720699906349182
[10/24] Train loss=0.8905171155929565
[15/24] Train loss=0.6870189905166626
[20/24] Train loss=0.6840786933898926
Test set avg_accuracy=84.70% avg_sensitivity=80.29%, avg_specificity=86.21% avg_auc=91.97%
Best model saved!! Metric=17.164926777419595!!
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.767025 Test loss=0.337892 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.7255624532699585
[5/24] Train loss=0.7705371975898743
[10/24] Train loss=0.8870788812637329
[15/24] Train loss=0.6833100914955139
[20/24] Train loss=0.6706988215446472
Test set avg_accuracy=85.01% avg_sensitivity=80.18%, avg_specificity=86.66% avg_auc=92.07%
Best model saved!! Metric=17.924675376884338!!
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.762089 Test loss=0.334344 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.7160464525222778
[5/24] Train loss=0.7699216604232788
[10/24] Train loss=0.8530328273773193
[15/24] Train loss=0.6814110279083252
[20/24] Train loss=0.6533231735229492
Test set avg_accuracy=85.07% avg_sensitivity=80.08%, avg_specificity=86.76% avg_auc=92.01%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.753060 Test loss=0.332733 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.7240861058235168
[5/24] Train loss=0.767648458480835
[10/24] Train loss=0.8856821656227112
[15/24] Train loss=0.6774245500564575
[20/24] Train loss=0.6536985039710999
Test set avg_accuracy=85.07% avg_sensitivity=80.13%, avg_specificity=86.75% avg_auc=92.08%
Best model saved!! Metric=18.024072791226132!!
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.755332 Test loss=0.331558 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.7083234786987305
[5/24] Train loss=0.7657696604728699
[10/24] Train loss=0.8684574365615845
[15/24] Train loss=0.6658499240875244
[20/24] Train loss=0.6645740866661072
Test set avg_accuracy=84.52% avg_sensitivity=81.72%, avg_specificity=85.47% avg_auc=92.15%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.752587 Test loss=0.341132 Current lr=[0.00029967723776099]

[0/24] Train loss=0.713800311088562
[5/24] Train loss=0.7730110287666321
[10/24] Train loss=0.8589004874229431
[15/24] Train loss=0.6542890071868896
[20/24] Train loss=0.6631917953491211
Test set avg_accuracy=84.48% avg_sensitivity=81.62%, avg_specificity=85.45% avg_auc=92.19%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.744344 Test loss=0.340898 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.7028719782829285
[5/24] Train loss=0.7543013691902161
[10/24] Train loss=0.8622570633888245
[15/24] Train loss=0.6566181778907776
[20/24] Train loss=0.6485653519630432
Test set avg_accuracy=85.08% avg_sensitivity=80.70%, avg_specificity=86.57% avg_auc=92.30%
Best model saved!! Metric=18.643683031229983!!
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.738654 Test loss=0.331470 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.6932659149169922
[5/24] Train loss=0.746595561504364
[10/24] Train loss=0.8477034568786621
[15/24] Train loss=0.6609128713607788
[20/24] Train loss=0.6538236141204834
Test set avg_accuracy=84.80% avg_sensitivity=80.65%, avg_specificity=86.22% avg_auc=92.19%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.738496 Test loss=0.333721 Current lr=[0.000299720220882401]

[0/24] Train loss=0.7043814659118652
[5/24] Train loss=0.7576878070831299
[10/24] Train loss=0.866324782371521
[15/24] Train loss=0.6382868885993958
[20/24] Train loss=0.6465775966644287
Test set avg_accuracy=85.03% avg_sensitivity=82.13%, avg_specificity=86.01% avg_auc=92.41%
Best model saved!! Metric=19.58408675469704!!
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.735214 Test loss=0.332794 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.6934015154838562
[5/24] Train loss=0.7644932866096497
[10/24] Train loss=0.8520146012306213
[15/24] Train loss=0.6390557885169983
[20/24] Train loss=0.6383196115493774
Test set avg_accuracy=85.03% avg_sensitivity=81.21%, avg_specificity=86.33% avg_auc=92.40%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.732157 Test loss=0.331463 Current lr=[0.000298904600941902]

[0/24] Train loss=0.6864021420478821
[5/24] Train loss=0.7450116276741028
[10/24] Train loss=0.8503237366676331
[15/24] Train loss=0.6448448896408081
[20/24] Train loss=0.6304020881652832
Test set avg_accuracy=85.05% avg_sensitivity=82.13%, avg_specificity=86.05% avg_auc=92.48%
Best model saved!! Metric=19.71518141680012!!
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.726052 Test loss=0.332966 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.6912858486175537
[5/24] Train loss=0.7459611892700195
[10/24] Train loss=0.8698420524597168
[15/24] Train loss=0.6371367573738098
[20/24] Train loss=0.6354838609695435
Test set avg_accuracy=84.74% avg_sensitivity=80.65%, avg_specificity=86.14% avg_auc=92.40%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.726630 Test loss=0.332605 Current lr=[0.000297555943323901]

[0/24] Train loss=0.6845734715461731
[5/24] Train loss=0.7392310500144958
[10/24] Train loss=0.8405513763427734
[15/24] Train loss=0.6295398473739624
[20/24] Train loss=0.6238158345222473
Test set avg_accuracy=84.84% avg_sensitivity=82.49%, avg_specificity=85.65% avg_auc=92.54%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.723010 Test loss=0.335465 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.679876983165741
[5/24] Train loss=0.7339528799057007
[10/24] Train loss=0.8376372456550598
[15/24] Train loss=0.6339412927627563
[20/24] Train loss=0.6290025115013123
Test set avg_accuracy=85.12% avg_sensitivity=82.64%, avg_specificity=85.96% avg_auc=92.52%
Best model saved!! Metric=20.241857153032754!!
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.719154 Test loss=0.334067 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.6760576963424683
[5/24] Train loss=0.738942563533783
[10/24] Train loss=0.8477446436882019
[15/24] Train loss=0.636625349521637
[20/24] Train loss=0.6212945580482483
Test set avg_accuracy=84.92% avg_sensitivity=83.46%, avg_specificity=85.42% avg_auc=92.62%
Best model saved!! Metric=20.420184630248343!!
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.718349 Test loss=0.335805 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.6761544942855835
[5/24] Train loss=0.7325764894485474
[10/24] Train loss=0.8461905717849731
[15/24] Train loss=0.6305207014083862
[20/24] Train loss=0.6289260983467102
Test set avg_accuracy=84.79% avg_sensitivity=83.00%, avg_specificity=85.40% avg_auc=92.60%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.716671 Test loss=0.336697 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.6699472069740295
[5/24] Train loss=0.7352451682090759
[10/24] Train loss=0.8413403034210205
[15/24] Train loss=0.6334223747253418
[20/24] Train loss=0.6287317872047424
Test set avg_accuracy=85.12% avg_sensitivity=82.69%, avg_specificity=85.94% avg_auc=92.65%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.711063 Test loss=0.330672 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.6689811944961548
[5/24] Train loss=0.7336418628692627
[10/24] Train loss=0.8317686915397644
[15/24] Train loss=0.6313899755477905
[20/24] Train loss=0.61687171459198
Test set avg_accuracy=84.78% avg_sensitivity=83.41%, avg_specificity=85.25% avg_auc=92.73%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.708779 Test loss=0.335869 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.6716032028198242
[5/24] Train loss=0.7259913682937622
[10/24] Train loss=0.8155061602592468
[15/24] Train loss=0.631070613861084
[20/24] Train loss=0.6105495691299438
Test set avg_accuracy=85.09% avg_sensitivity=82.39%, avg_specificity=86.01% avg_auc=92.71%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.706261 Test loss=0.329500 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.6649637222290039
[5/24] Train loss=0.7195658087730408
[10/24] Train loss=0.8351134657859802
[15/24] Train loss=0.6261524558067322
[20/24] Train loss=0.6078165769577026
Test set avg_accuracy=85.33% avg_sensitivity=82.69%, avg_specificity=86.22% avg_auc=92.78%
Best model saved!! Metric=21.02505835875506!!
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.704802 Test loss=0.327595 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.6684495210647583
[5/24] Train loss=0.7233257293701172
[10/24] Train loss=0.8189465999603271
[15/24] Train loss=0.6158475279808044
[20/24] Train loss=0.6226078867912292
Test set avg_accuracy=85.09% avg_sensitivity=82.59%, avg_specificity=85.94% avg_auc=92.71%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.702317 Test loss=0.330422 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.6581128239631653
[5/24] Train loss=0.721890926361084
[10/24] Train loss=0.8169907331466675
[15/24] Train loss=0.6241867542266846
[20/24] Train loss=0.6039955615997314
Test set avg_accuracy=84.90% avg_sensitivity=83.61%, avg_specificity=85.33% avg_auc=92.78%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.696470 Test loss=0.335460 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.6605419516563416
[5/24] Train loss=0.7215805649757385
[10/24] Train loss=0.8178275227546692
[15/24] Train loss=0.624942421913147
[20/24] Train loss=0.5961849689483643
Test set avg_accuracy=85.07% avg_sensitivity=83.10%, avg_specificity=85.73% avg_auc=92.84%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.694620 Test loss=0.329601 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.6619457602500916
[5/24] Train loss=0.7167646288871765
[10/24] Train loss=0.8193103075027466
[15/24] Train loss=0.6156625151634216
[20/24] Train loss=0.6058735251426697
Test set avg_accuracy=85.07% avg_sensitivity=83.05%, avg_specificity=85.75% avg_auc=92.85%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.693888 Test loss=0.328717 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.656088650226593
[5/24] Train loss=0.7182729840278625
[10/24] Train loss=0.8301604986190796
[15/24] Train loss=0.6182352900505066
[20/24] Train loss=0.6073084473609924
Test set avg_accuracy=84.87% avg_sensitivity=83.72%, avg_specificity=85.26% avg_auc=92.79%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.694292 Test loss=0.334075 Current lr=[0.000276307469034998]

[0/24] Train loss=0.6592355370521545
[5/24] Train loss=0.7207024693489075
[10/24] Train loss=0.8114913105964661
[15/24] Train loss=0.6135151386260986
[20/24] Train loss=0.5986328721046448
Test set avg_accuracy=85.14% avg_sensitivity=83.00%, avg_specificity=85.87% avg_auc=92.86%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.691467 Test loss=0.328231 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.6557195782661438
[5/24] Train loss=0.7130482196807861
[10/24] Train loss=0.8156291842460632
[15/24] Train loss=0.6091786026954651
[20/24] Train loss=0.6037527322769165
Test set avg_accuracy=85.14% avg_sensitivity=83.67%, avg_specificity=85.65% avg_auc=92.91%
Best model saved!! Metric=21.361817896348853!!
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.686217 Test loss=0.331776 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.6580221056938171
[5/24] Train loss=0.717022716999054
[10/24] Train loss=0.8054975867271423
[15/24] Train loss=0.6070134043693542
[20/24] Train loss=0.602368950843811
Test set avg_accuracy=85.07% avg_sensitivity=83.77%, avg_specificity=85.51% avg_auc=92.93%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.686914 Test loss=0.331252 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.6552131772041321
[5/24] Train loss=0.7076061367988586
[10/24] Train loss=0.8190023303031921
[15/24] Train loss=0.6096301078796387
[20/24] Train loss=0.6085917353630066
Test set avg_accuracy=84.91% avg_sensitivity=85.25%, avg_specificity=84.79% avg_auc=92.96%
Best model saved!! Metric=21.915250955317305!!
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.684717 Test loss=0.339042 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.6599648594856262
[5/24] Train loss=0.7091211080551147
[10/24] Train loss=0.8043063282966614
[15/24] Train loss=0.6018664836883545
[20/24] Train loss=0.5937854051589966
Test set avg_accuracy=84.86% avg_sensitivity=84.33%, avg_specificity=85.04% avg_auc=92.73%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.685138 Test loss=0.336494 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.662577211856842
[5/24] Train loss=0.7095063924789429
[10/24] Train loss=0.8055278062820435
[15/24] Train loss=0.5859655141830444
[20/24] Train loss=0.5991209149360657
Test set avg_accuracy=84.75% avg_sensitivity=84.69%, avg_specificity=84.77% avg_auc=92.89%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.678976 Test loss=0.337728 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.659088671207428
[5/24] Train loss=0.7022232413291931
[10/24] Train loss=0.8026228547096252
[15/24] Train loss=0.5915530323982239
[20/24] Train loss=0.5978942513465881
Test set avg_accuracy=84.97% avg_sensitivity=84.43%, avg_specificity=85.16% avg_auc=92.81%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.679380 Test loss=0.335362 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.6596159338951111
[5/24] Train loss=0.705025315284729
[10/24] Train loss=0.7932542562484741
[15/24] Train loss=0.5975692868232727
[20/24] Train loss=0.5921818614006042
Test set avg_accuracy=85.20% avg_sensitivity=84.18%, avg_specificity=85.54% avg_auc=92.93%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.677714 Test loss=0.331837 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.6494075059890747
[5/24] Train loss=0.7100711464881897
[10/24] Train loss=0.8022942543029785
[15/24] Train loss=0.5949472188949585
[20/24] Train loss=0.6002792716026306
Test set avg_accuracy=84.92% avg_sensitivity=84.90%, avg_specificity=84.93% avg_auc=93.08%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.674859 Test loss=0.333091 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.6522691249847412
[5/24] Train loss=0.7121639847755432
[10/24] Train loss=0.7761145234107971
[15/24] Train loss=0.5845345258712769
[20/24] Train loss=0.5887067914009094
Test set avg_accuracy=85.22% avg_sensitivity=84.02%, avg_specificity=85.63% avg_auc=93.02%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.672254 Test loss=0.327842 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.6439306139945984
[5/24] Train loss=0.6967341303825378
[10/24] Train loss=0.7948098182678223
[15/24] Train loss=0.5932613015174866
[20/24] Train loss=0.5876601338386536
Test set avg_accuracy=85.23% avg_sensitivity=84.23%, avg_specificity=85.58% avg_auc=93.02%
Best model saved!! Metric=22.061001526587688!!
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.672586 Test loss=0.329915 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.6462621092796326
[5/24] Train loss=0.6999238729476929
[10/24] Train loss=0.7999672293663025
[15/24] Train loss=0.5810316801071167
[20/24] Train loss=0.5854448676109314
Test set avg_accuracy=85.10% avg_sensitivity=84.18%, avg_specificity=85.42% avg_auc=93.08%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.672616 Test loss=0.329979 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.6471222639083862
[5/24] Train loss=0.7216344475746155
[10/24] Train loss=0.7939453721046448
[15/24] Train loss=0.6081023216247559
[20/24] Train loss=0.6043651700019836
Test set avg_accuracy=84.38% avg_sensitivity=86.33%, avg_specificity=83.71% avg_auc=92.95%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.678741 Test loss=0.345292 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.6594864726066589
[5/24] Train loss=0.7084687948226929
[10/24] Train loss=0.8088632225990295
[15/24] Train loss=0.6331323385238647
[20/24] Train loss=0.6236540675163269
Test set avg_accuracy=81.93% avg_sensitivity=90.22%, avg_specificity=79.10% avg_auc=93.15%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.682685 Test loss=0.388462 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.6915870308876038
[5/24] Train loss=0.6968111991882324
[10/24] Train loss=0.7966512441635132
[15/24] Train loss=0.6056542992591858
[20/24] Train loss=0.622961699962616
Test set avg_accuracy=82.14% avg_sensitivity=90.17%, avg_specificity=79.40% avg_auc=93.13%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.675984 Test loss=0.388992 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.6911616921424866
[5/24] Train loss=0.6856229305267334
[10/24] Train loss=0.8019242882728577
[15/24] Train loss=0.5996043086051941
[20/24] Train loss=0.6274558901786804
Test set avg_accuracy=82.71% avg_sensitivity=89.40%, avg_specificity=80.43% avg_auc=93.16%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.667660 Test loss=0.378127 Current lr=[0.000224838296036774]

[0/24] Train loss=0.6758590936660767
[5/24] Train loss=0.6762412190437317
[10/24] Train loss=0.7786375880241394
[15/24] Train loss=0.6043528318405151
[20/24] Train loss=0.6201348900794983
Test set avg_accuracy=82.83% avg_sensitivity=89.50%, avg_specificity=80.55% avg_auc=93.20%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.662820 Test loss=0.376892 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.671959638595581
[5/24] Train loss=0.6853045225143433
[10/24] Train loss=0.8031439781188965
[15/24] Train loss=0.6021287441253662
[20/24] Train loss=0.6059234738349915
Test set avg_accuracy=82.81% avg_sensitivity=89.35%, avg_specificity=80.58% avg_auc=93.16%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.661747 Test loss=0.379269 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.6748982071876526
[5/24] Train loss=0.6647636890411377
[10/24] Train loss=0.782633900642395
[15/24] Train loss=0.5843065977096558
[20/24] Train loss=0.6102335453033447
Test set avg_accuracy=83.03% avg_sensitivity=89.14%, avg_specificity=80.95% avg_auc=93.22%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.655208 Test loss=0.374704 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.6622461080551147
[5/24] Train loss=0.6740902066230774
[10/24] Train loss=0.77897709608078
[15/24] Train loss=0.5912465453147888
[20/24] Train loss=0.618309736251831
Test set avg_accuracy=82.60% avg_sensitivity=89.96%, avg_specificity=80.09% avg_auc=93.20%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.657922 Test loss=0.383587 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.6822587847709656
[5/24] Train loss=0.6733309626579285
[10/24] Train loss=0.7882917523384094
[15/24] Train loss=0.5839902758598328
[20/24] Train loss=0.5959171652793884
Test set avg_accuracy=83.23% avg_sensitivity=89.25%, avg_specificity=81.18% avg_auc=93.23%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.653710 Test loss=0.373290 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.668863832950592
[5/24] Train loss=0.6707420349121094
[10/24] Train loss=0.7777323722839355
[15/24] Train loss=0.5854618549346924
[20/24] Train loss=0.5965368747711182
Test set avg_accuracy=83.11% avg_sensitivity=89.25%, avg_specificity=81.02% avg_auc=93.25%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.649842 Test loss=0.373699 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.6559244990348816
[5/24] Train loss=0.6624200344085693
[10/24] Train loss=0.7961277961730957
[15/24] Train loss=0.5799119472503662
[20/24] Train loss=0.6041797399520874
Test set avg_accuracy=83.37% avg_sensitivity=89.09%, avg_specificity=81.42% avg_auc=93.26%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.647795 Test loss=0.370200 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.6619576215744019
[5/24] Train loss=0.6641088128089905
[10/24] Train loss=0.7798728346824646
[15/24] Train loss=0.577646791934967
[20/24] Train loss=0.5914667248725891
Test set avg_accuracy=83.75% avg_sensitivity=88.33%, avg_specificity=82.19% avg_auc=93.27%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.643833 Test loss=0.363028 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.649342954158783
[5/24] Train loss=0.6452088952064514
[10/24] Train loss=0.7630471587181091
[15/24] Train loss=0.5869268178939819
[20/24] Train loss=0.5857861042022705
Test set avg_accuracy=83.31% avg_sensitivity=88.68%, avg_specificity=81.47% avg_auc=93.28%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.642242 Test loss=0.367956 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.6677812337875366
[5/24] Train loss=0.6675947904586792
[10/24] Train loss=0.7728176712989807
[15/24] Train loss=0.5764681696891785
[20/24] Train loss=0.5928940176963806
Test set avg_accuracy=83.63% avg_sensitivity=88.99%, avg_specificity=81.81% avg_auc=93.28%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.641498 Test loss=0.368085 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.6548587679862976
[5/24] Train loss=0.668950080871582
[10/24] Train loss=0.7708186507225037
[15/24] Train loss=0.5793792605400085
[20/24] Train loss=0.573370635509491
Test set avg_accuracy=83.79% avg_sensitivity=88.33%, avg_specificity=82.24% avg_auc=93.32%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.640147 Test loss=0.362476 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.6456015110015869
[5/24] Train loss=0.6637060642242432
[10/24] Train loss=0.7860448956489563
[15/24] Train loss=0.5730311274528503
[20/24] Train loss=0.585833728313446
Test set avg_accuracy=83.95% avg_sensitivity=88.22%, avg_specificity=82.49% avg_auc=93.32%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.636097 Test loss=0.360916 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.6431406736373901
[5/24] Train loss=0.6615351438522339
[10/24] Train loss=0.7524275779724121
[15/24] Train loss=0.567740797996521
[20/24] Train loss=0.5702264308929443
Test set avg_accuracy=84.02% avg_sensitivity=88.53%, avg_specificity=82.49% avg_auc=93.35%
Best model saved!! Metric=22.38714134139019!!
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.632365 Test loss=0.361578 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.6491496562957764
[5/24] Train loss=0.6560072898864746
[10/24] Train loss=0.7581268548965454
[15/24] Train loss=0.5682560801506042
[20/24] Train loss=0.5765467882156372
Test set avg_accuracy=83.92% avg_sensitivity=88.79%, avg_specificity=82.26% avg_auc=93.37%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.632161 Test loss=0.362099 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.6485849022865295
[5/24] Train loss=0.6553196310997009
[10/24] Train loss=0.7774012684822083
[15/24] Train loss=0.5580255389213562
[20/24] Train loss=0.5692773461341858
Test set avg_accuracy=84.13% avg_sensitivity=88.02%, avg_specificity=82.80% avg_auc=93.35%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.632195 Test loss=0.357538 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.6491208672523499
[5/24] Train loss=0.6588661670684814
[10/24] Train loss=0.7463776469230652
[15/24] Train loss=0.5594866871833801
[20/24] Train loss=0.5775967240333557
Test set avg_accuracy=83.97% avg_sensitivity=88.84%, avg_specificity=82.31% avg_auc=93.37%
Best model saved!! Metric=22.489195339233333!!
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.631180 Test loss=0.362391 Current lr=[0.000156543481933168]

[0/24] Train loss=0.6425944566726685
[5/24] Train loss=0.6595852375030518
[10/24] Train loss=0.7549588084220886
[15/24] Train loss=0.5505372881889343
[20/24] Train loss=0.5787994861602783
Test set avg_accuracy=84.22% avg_sensitivity=87.81%, avg_specificity=82.99% avg_auc=93.36%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.627821 Test loss=0.353883 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.646966814994812
[5/24] Train loss=0.6397187113761902
[10/24] Train loss=0.7513993382453918
[15/24] Train loss=0.5563563108444214
[20/24] Train loss=0.5612080097198486
Test set avg_accuracy=84.30% avg_sensitivity=87.81%, avg_specificity=83.10% avg_auc=93.36%
Best model saved!! Metric=22.564274301786497!!
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.625736 Test loss=0.353635 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.6322058439254761
[5/24] Train loss=0.6380046010017395
[10/24] Train loss=0.7611520886421204
[15/24] Train loss=0.5467280745506287
[20/24] Train loss=0.5624159574508667
Test set avg_accuracy=84.35% avg_sensitivity=87.40%, avg_specificity=83.31% avg_auc=93.38%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.625059 Test loss=0.351046 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.6326053142547607
[5/24] Train loss=0.644538164138794
[10/24] Train loss=0.749796986579895
[15/24] Train loss=0.5487886071205139
[20/24] Train loss=0.570691704750061
Test set avg_accuracy=84.23% avg_sensitivity=87.66%, avg_specificity=83.06% avg_auc=93.40%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.623469 Test loss=0.352159 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.6142065525054932
[5/24] Train loss=0.6436541080474854
[10/24] Train loss=0.7490115165710449
[15/24] Train loss=0.5498055219650269
[20/24] Train loss=0.5610992312431335
Test set avg_accuracy=84.62% avg_sensitivity=86.84%, avg_specificity=83.87% avg_auc=93.38%
Best model saved!! Metric=22.705862986301497!!
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.620395 Test loss=0.344297 Current lr=[0.000134135431043539]

[0/24] Train loss=0.6324768662452698
[5/24] Train loss=0.6358391046524048
[10/24] Train loss=0.7550129294395447
[15/24] Train loss=0.541840136051178
[20/24] Train loss=0.5590779185295105
Test set avg_accuracy=84.22% avg_sensitivity=88.22%, avg_specificity=82.85% avg_auc=93.39%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.620234 Test loss=0.355801 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.6299518942832947
[5/24] Train loss=0.6262039542198181
[10/24] Train loss=0.7430188655853271
[15/24] Train loss=0.5512759685516357
[20/24] Train loss=0.5613483190536499
Test set avg_accuracy=84.43% avg_sensitivity=87.10%, avg_specificity=83.52% avg_auc=93.40%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.618592 Test loss=0.347656 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.6223741173744202
[5/24] Train loss=0.6355440616607666
[10/24] Train loss=0.7551937699317932
[15/24] Train loss=0.5392290949821472
[20/24] Train loss=0.561846911907196
Test set avg_accuracy=84.41% avg_sensitivity=87.40%, avg_specificity=83.39% avg_auc=93.40%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.617722 Test loss=0.348177 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.622690737247467
[5/24] Train loss=0.625071108341217
[10/24] Train loss=0.7498686909675598
[15/24] Train loss=0.5395434498786926
[20/24] Train loss=0.5641870498657227
Test set avg_accuracy=84.60% avg_sensitivity=87.51%, avg_specificity=83.60% avg_auc=93.45%
Best model saved!! Metric=23.15552363467205!!
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.617006 Test loss=0.346372 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.6201629042625427
[5/24] Train loss=0.6326244473457336
[10/24] Train loss=0.7521216869354248
[15/24] Train loss=0.5346968770027161
[20/24] Train loss=0.5460452437400818
Test set avg_accuracy=84.53% avg_sensitivity=86.99%, avg_specificity=83.69% avg_auc=93.46%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.613834 Test loss=0.344764 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.6191302537918091
[5/24] Train loss=0.6342295408248901
[10/24] Train loss=0.7444801926612854
[15/24] Train loss=0.53455650806427
[20/24] Train loss=0.5516605377197266
Test set avg_accuracy=84.47% avg_sensitivity=87.66%, avg_specificity=83.38% avg_auc=93.47%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.615577 Test loss=0.347367 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.6145529747009277
[5/24] Train loss=0.6361945867538452
[10/24] Train loss=0.7551969885826111
[15/24] Train loss=0.5382329821586609
[20/24] Train loss=0.5470417737960815
Test set avg_accuracy=84.36% avg_sensitivity=88.22%, avg_specificity=83.05% avg_auc=93.46%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.615460 Test loss=0.352272 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.6176741123199463
[5/24] Train loss=0.6436352729797363
[10/24] Train loss=0.7508226037025452
[15/24] Train loss=0.5279989838600159
[20/24] Train loss=0.5460196733474731
Test set avg_accuracy=84.32% avg_sensitivity=88.38%, avg_specificity=82.94% avg_auc=93.51%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.612931 Test loss=0.352900 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.6217616200447083
[5/24] Train loss=0.6543188691139221
[10/24] Train loss=0.7514215707778931
[15/24] Train loss=0.538962185382843
[20/24] Train loss=0.5431832671165466
Test set avg_accuracy=84.26% avg_sensitivity=88.22%, avg_specificity=82.91% avg_auc=93.52%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.613676 Test loss=0.354919 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.6211488842964172
[5/24] Train loss=0.6483158469200134
[10/24] Train loss=0.7636885643005371
[15/24] Train loss=0.5368165373802185
[20/24] Train loss=0.5441962480545044
Test set avg_accuracy=83.82% avg_sensitivity=89.76%, avg_specificity=81.79% avg_auc=93.51%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.615182 Test loss=0.368418 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.6410681009292603
[5/24] Train loss=0.6609638333320618
[10/24] Train loss=0.7600601315498352
[15/24] Train loss=0.5263234972953796
[20/24] Train loss=0.5471874475479126
Test set avg_accuracy=82.98% avg_sensitivity=91.40%, avg_specificity=80.11% avg_auc=93.48%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.613606 Test loss=0.388324 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.6571474075317383
[5/24] Train loss=0.6580004692077637
[10/24] Train loss=0.7602205872535706
[15/24] Train loss=0.5299503803253174
[20/24] Train loss=0.5717243552207947
Test set avg_accuracy=83.27% avg_sensitivity=90.83%, avg_specificity=80.69% avg_auc=93.47%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.611413 Test loss=0.384227 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.6375899910926819
[5/24] Train loss=0.6371262073516846
[10/24] Train loss=0.7488460540771484
[15/24] Train loss=0.5394870042800903
[20/24] Train loss=0.5707606077194214
Test set avg_accuracy=83.95% avg_sensitivity=88.94%, avg_specificity=82.24% avg_auc=93.47%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.609987 Test loss=0.363480 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.6241287589073181
[5/24] Train loss=0.6137382984161377
[10/24] Train loss=0.7411026358604431
[15/24] Train loss=0.5457939505577087
[20/24] Train loss=0.5691107511520386
Test set avg_accuracy=84.80% avg_sensitivity=86.99%, avg_specificity=84.06% avg_auc=93.41%
Best model saved!! Metric=23.27050732329458!!
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.607484 Test loss=0.344133 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.5962888598442078
[5/24] Train loss=0.6152004599571228
[10/24] Train loss=0.7248809337615967
[15/24] Train loss=0.5299451351165771
[20/24] Train loss=0.5543799996376038
Test set avg_accuracy=84.96% avg_sensitivity=87.30%, avg_specificity=84.16% avg_auc=93.45%
Best model saved!! Metric=23.87897247075638!!
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.600223 Test loss=0.343855 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.5997315049171448
[5/24] Train loss=0.6251302361488342
[10/24] Train loss=0.7367068529129028
[15/24] Train loss=0.5391986966133118
[20/24] Train loss=0.5558350086212158
Test set avg_accuracy=84.66% avg_sensitivity=87.71%, avg_specificity=83.62% avg_auc=93.45%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.602012 Test loss=0.348423 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.6028541922569275
[5/24] Train loss=0.6110904216766357
[10/24] Train loss=0.739088237285614
[15/24] Train loss=0.5291630029678345
[20/24] Train loss=0.5553014278411865
Test set avg_accuracy=84.84% avg_sensitivity=86.94%, avg_specificity=84.13% avg_auc=93.43%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.600703 Test loss=0.342962 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.6048809289932251
[5/24] Train loss=0.6120642423629761
[10/24] Train loss=0.721504271030426
[15/24] Train loss=0.5280298590660095
[20/24] Train loss=0.555047333240509
Test set avg_accuracy=84.54% avg_sensitivity=87.51%, avg_specificity=83.53% avg_auc=93.41%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.597433 Test loss=0.348858 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.6074301600456238
[5/24] Train loss=0.6141887903213501
[10/24] Train loss=0.7285260558128357
[15/24] Train loss=0.5228450298309326
[20/24] Train loss=0.5695155262947083
Test set avg_accuracy=84.73% avg_sensitivity=86.89%, avg_specificity=83.99% avg_auc=93.41%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.596464 Test loss=0.344663 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.5970782041549683
[5/24] Train loss=0.6146740317344666
[10/24] Train loss=0.7290268540382385
[15/24] Train loss=0.532783031463623
[20/24] Train loss=0.5506778359413147
Test set avg_accuracy=84.62% avg_sensitivity=87.10%, avg_specificity=83.78% avg_auc=93.45%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.596190 Test loss=0.344870 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.6014146208763123
[5/24] Train loss=0.6162129044532776
[10/24] Train loss=0.7226476669311523
[15/24] Train loss=0.5275529623031616
[20/24] Train loss=0.5547704100608826
Test set avg_accuracy=84.96% avg_sensitivity=86.79%, avg_specificity=84.34% avg_auc=93.43%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.595210 Test loss=0.340655 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.5989707112312317
[5/24] Train loss=0.609626829624176
[10/24] Train loss=0.7297587990760803
[15/24] Train loss=0.5260753631591797
[20/24] Train loss=0.5457423329353333
Test set avg_accuracy=85.05% avg_sensitivity=86.74%, avg_specificity=84.48% avg_auc=93.44%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.594074 Test loss=0.338471 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.5972536206245422
[5/24] Train loss=0.6098264455795288
[10/24] Train loss=0.7219855189323425
[15/24] Train loss=0.5226383209228516
[20/24] Train loss=0.5444127917289734
Test set avg_accuracy=84.83% avg_sensitivity=87.15%, avg_specificity=84.04% avg_auc=93.44%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.593957 Test loss=0.342430 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.602347731590271
[5/24] Train loss=0.6071421504020691
[10/24] Train loss=0.7164421677589417
[15/24] Train loss=0.5112704634666443
[20/24] Train loss=0.5416745543479919
Test set avg_accuracy=84.96% avg_sensitivity=86.89%, avg_specificity=84.30% avg_auc=93.45%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.589664 Test loss=0.339905 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.5963661670684814
[5/24] Train loss=0.610908567905426
[10/24] Train loss=0.7242324948310852
[15/24] Train loss=0.5149372220039368
[20/24] Train loss=0.5482876896858215
Test set avg_accuracy=85.20% avg_sensitivity=86.33%, avg_specificity=84.81% avg_auc=93.44%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.591280 Test loss=0.334282 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.5958582758903503
[5/24] Train loss=0.6106730699539185
[10/24] Train loss=0.7208716869354248
[15/24] Train loss=0.5182088613510132
[20/24] Train loss=0.5390934944152832
Test set avg_accuracy=84.97% avg_sensitivity=86.74%, avg_specificity=84.37% avg_auc=93.45%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.590644 Test loss=0.338874 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.5946568846702576
[5/24] Train loss=0.5963685512542725
[10/24] Train loss=0.7225791811943054
[15/24] Train loss=0.5054157376289368
[20/24] Train loss=0.5372700095176697
Test set avg_accuracy=84.93% avg_sensitivity=86.58%, avg_specificity=84.37% avg_auc=93.44%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.589338 Test loss=0.338845 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.5983685255050659
[5/24] Train loss=0.611304521560669
[10/24] Train loss=0.7233138680458069
[15/24] Train loss=0.5208280682563782
[20/24] Train loss=0.5351866483688354
Test set avg_accuracy=84.92% avg_sensitivity=86.53%, avg_specificity=84.37% avg_auc=93.44%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.590302 Test loss=0.338306 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.5975591540336609
[5/24] Train loss=0.6138306260108948
[10/24] Train loss=0.7445156574249268
[15/24] Train loss=0.5182865262031555
[20/24] Train loss=0.5397627949714661
Test set avg_accuracy=84.93% avg_sensitivity=86.74%, avg_specificity=84.32% avg_auc=93.43%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.592635 Test loss=0.339059 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.5953423976898193
[5/24] Train loss=0.6008930802345276
[10/24] Train loss=0.7140026092529297
[15/24] Train loss=0.5194260478019714
[20/24] Train loss=0.5337095260620117
Test set avg_accuracy=84.77% avg_sensitivity=87.10%, avg_specificity=83.97% avg_auc=93.44%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.588428 Test loss=0.343385 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.602480411529541
[5/24] Train loss=0.6177777647972107
[10/24] Train loss=0.7226653099060059
[15/24] Train loss=0.5169281363487244
[20/24] Train loss=0.529345691204071
Test set avg_accuracy=84.69% avg_sensitivity=87.20%, avg_specificity=83.83% avg_auc=93.43%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.587505 Test loss=0.345105 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.5962297320365906
[5/24] Train loss=0.6063040494918823
[10/24] Train loss=0.7192437648773193
[15/24] Train loss=0.5136744976043701
[20/24] Train loss=0.5395177602767944
Test set avg_accuracy=84.61% avg_sensitivity=87.35%, avg_specificity=83.67% avg_auc=93.42%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.587762 Test loss=0.349669 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.5932726860046387
[5/24] Train loss=0.5984516739845276
[10/24] Train loss=0.7101112008094788
[15/24] Train loss=0.5188366770744324
[20/24] Train loss=0.5438612699508667
Test set avg_accuracy=84.66% avg_sensitivity=87.97%, avg_specificity=83.53% avg_auc=93.41%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.587109 Test loss=0.353175 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.5892438292503357
[5/24] Train loss=0.5953053832054138
[10/24] Train loss=0.7205641269683838
[15/24] Train loss=0.5050328373908997
[20/24] Train loss=0.5508927702903748
Test set avg_accuracy=84.70% avg_sensitivity=87.76%, avg_specificity=83.66% avg_auc=93.39%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.587418 Test loss=0.350848 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.5917319059371948
[5/24] Train loss=0.5947380661964417
[10/24] Train loss=0.7183376550674438
[15/24] Train loss=0.5154834389686584
[20/24] Train loss=0.541819155216217
Test set avg_accuracy=84.83% avg_sensitivity=86.94%, avg_specificity=84.11% avg_auc=93.41%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.586230 Test loss=0.344413 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.600649356842041
[5/24] Train loss=0.5941149592399597
[10/24] Train loss=0.7122994065284729
[15/24] Train loss=0.5148642659187317
[20/24] Train loss=0.5309845209121704
Test set avg_accuracy=84.97% avg_sensitivity=86.69%, avg_specificity=84.39% avg_auc=93.42%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.586947 Test loss=0.340985 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.589945912361145
[5/24] Train loss=0.6088164448738098
[10/24] Train loss=0.7180759906768799
[15/24] Train loss=0.5190770626068115
[20/24] Train loss=0.5356252193450928
Test set avg_accuracy=85.05% avg_sensitivity=86.58%, avg_specificity=84.53% avg_auc=93.43%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.585499 Test loss=0.338179 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.5921127796173096
[5/24] Train loss=0.6098533868789673
[10/24] Train loss=0.731207549571991
[15/24] Train loss=0.5051050186157227
[20/24] Train loss=0.5427395105361938
Test set avg_accuracy=84.97% avg_sensitivity=86.94%, avg_specificity=84.30% avg_auc=93.44%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.584419 Test loss=0.339886 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.5958195328712463
[5/24] Train loss=0.5927568674087524
[10/24] Train loss=0.7065578103065491
[15/24] Train loss=0.5093685388565063
[20/24] Train loss=0.53644859790802
Test set avg_accuracy=85.05% avg_sensitivity=86.48%, avg_specificity=84.56% avg_auc=93.43%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.586814 Test loss=0.336352 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.5851218700408936
[5/24] Train loss=0.6093012690544128
[10/24] Train loss=0.7235407829284668
[15/24] Train loss=0.5117304921150208
[20/24] Train loss=0.5251442193984985
Test set avg_accuracy=85.00% avg_sensitivity=86.84%, avg_specificity=84.37% avg_auc=93.44%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.585770 Test loss=0.338624 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.5828352570533752
[5/24] Train loss=0.5998387932777405
[10/24] Train loss=0.7279313802719116
[15/24] Train loss=0.5057795643806458
[20/24] Train loss=0.5382458567619324
Test set avg_accuracy=85.12% avg_sensitivity=86.48%, avg_specificity=84.65% avg_auc=93.44%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.585014 Test loss=0.336467 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.5815752744674683
[5/24] Train loss=0.6121382713317871
[10/24] Train loss=0.7168617844581604
[15/24] Train loss=0.5161288380622864
[20/24] Train loss=0.5282688140869141
Test set avg_accuracy=85.03% avg_sensitivity=86.58%, avg_specificity=84.49% avg_auc=93.44%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.583655 Test loss=0.337315 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.5898019671440125
[5/24] Train loss=0.6004444360733032
[10/24] Train loss=0.7118859887123108
[15/24] Train loss=0.5076026916503906
[20/24] Train loss=0.5426845550537109
Test set avg_accuracy=85.01% avg_sensitivity=86.58%, avg_specificity=84.48% avg_auc=93.44%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.585121 Test loss=0.336840 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.5856351256370544
[5/24] Train loss=0.6063740253448486
[10/24] Train loss=0.7225862741470337
[15/24] Train loss=0.5144004225730896
[20/24] Train loss=0.5423598885536194
Test set avg_accuracy=85.05% avg_sensitivity=86.58%, avg_specificity=84.53% avg_auc=93.44%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.582915 Test loss=0.336830 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.585825502872467
[5/24] Train loss=0.5995281934738159
[10/24] Train loss=0.7214761972427368
[15/24] Train loss=0.5182518362998962
[20/24] Train loss=0.5278646945953369
Test set avg_accuracy=85.07% avg_sensitivity=86.53%, avg_specificity=84.56% avg_auc=93.44%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.583993 Test loss=0.336310 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.5933644771575928
[5/24] Train loss=0.5950794816017151
[10/24] Train loss=0.7127419114112854
[15/24] Train loss=0.5010311603546143
[20/24] Train loss=0.5402262210845947
Test set avg_accuracy=85.08% avg_sensitivity=86.58%, avg_specificity=84.56% avg_auc=93.44%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.583246 Test loss=0.336302 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.5917710065841675
[5/24] Train loss=0.5928025245666504
[10/24] Train loss=0.7248062491416931
[15/24] Train loss=0.5168051719665527
[20/24] Train loss=0.5334484577178955
Test set avg_accuracy=85.07% avg_sensitivity=86.58%, avg_specificity=84.55% avg_auc=93.44%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.586340 Test loss=0.336541 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.5838773250579834
[5/24] Train loss=0.6014492511749268
[10/24] Train loss=0.7129022479057312
[15/24] Train loss=0.5063232779502869
[20/24] Train loss=0.530676543712616
Test set avg_accuracy=85.04% avg_sensitivity=86.58%, avg_specificity=84.51% avg_auc=93.44%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.584416 Test loss=0.336629 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.5904104113578796
[5/24] Train loss=0.5972446799278259
[10/24] Train loss=0.7109122276306152
[15/24] Train loss=0.5134880542755127
[20/24] Train loss=0.5413910746574402
Test set avg_accuracy=85.05% avg_sensitivity=86.58%, avg_specificity=84.53% avg_auc=93.44%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.582580 Test loss=0.336617 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=84.96% sen=87.30%, spe=84.16%, auc=93.45%!
Fold[5] Avg_overlap=0.61%(±0.2287209142690649)
[0/24] Train loss=1.5998828411102295
[5/24] Train loss=1.4736151695251465
[10/24] Train loss=1.4652161598205566
[15/24] Train loss=1.439070463180542
[20/24] Train loss=1.4363652467727661
Test set avg_accuracy=56.47% avg_sensitivity=53.45%, avg_specificity=57.59% avg_auc=57.31%
Best model saved!! Metric=-101.16480817989566!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=1.469217 Test loss=0.683099 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.425271987915039
[5/24] Train loss=1.3994296789169312
[10/24] Train loss=1.3949559926986694
[15/24] Train loss=1.3768682479858398
[20/24] Train loss=1.3913257122039795
Test set avg_accuracy=60.09% avg_sensitivity=62.09%, avg_specificity=59.35% avg_auc=64.77%
Best model saved!! Metric=-79.69580474419736!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=1.402464 Test loss=0.672484 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.38826322555542
[5/24] Train loss=1.3550115823745728
[10/24] Train loss=1.3729462623596191
[15/24] Train loss=1.3453342914581299
[20/24] Train loss=1.352405071258545
Test set avg_accuracy=64.87% avg_sensitivity=63.20%, avg_specificity=65.49% avg_auc=69.60%
Best model saved!! Metric=-62.84296261079226!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=1.366380 Test loss=0.657428 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.3503646850585938
[5/24] Train loss=1.3256523609161377
[10/24] Train loss=1.3393985033035278
[15/24] Train loss=1.3241466283798218
[20/24] Train loss=1.321016550064087
Test set avg_accuracy=68.02% avg_sensitivity=65.36%, avg_specificity=69.01% avg_auc=73.12%
Best model saved!! Metric=-50.48792840901348!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=1.336786 Test loss=0.644662 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.304499626159668
[5/24] Train loss=1.2925450801849365
[10/24] Train loss=1.3191083669662476
[15/24] Train loss=1.2802084684371948
[20/24] Train loss=1.2940877676010132
Test set avg_accuracy=69.77% avg_sensitivity=66.12%, avg_specificity=71.12% avg_auc=75.43%
Best model saved!! Metric=-43.55773817139057!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=1.306254 Test loss=0.630401 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.2760107517242432
[5/24] Train loss=1.2595362663269043
[10/24] Train loss=1.2816864252090454
[15/24] Train loss=1.251778483390808
[20/24] Train loss=1.2653419971466064
Test set avg_accuracy=70.95% avg_sensitivity=68.86%, avg_specificity=71.73% avg_auc=77.16%
Best model saved!! Metric=-37.30061841611685!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=1.275467 Test loss=0.616087 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.2451156377792358
[5/24] Train loss=1.234021782875061
[10/24] Train loss=1.2577375173568726
[15/24] Train loss=1.2043222188949585
[20/24] Train loss=1.2249282598495483
Test set avg_accuracy=72.88% avg_sensitivity=69.15%, avg_specificity=74.27% avg_auc=78.88%
Best model saved!! Metric=-30.825506534835228!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=1.242756 Test loss=0.594673 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.2150980234146118
[5/24] Train loss=1.18401038646698
[10/24] Train loss=1.2239383459091187
[15/24] Train loss=1.1722084283828735
[20/24] Train loss=1.1728577613830566
Test set avg_accuracy=73.62% avg_sensitivity=71.35%, avg_specificity=74.46% avg_auc=80.34%
Best model saved!! Metric=-26.223757811367392!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=1.204054 Test loss=0.575243 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.1663256883621216
[5/24] Train loss=1.1410174369812012
[10/24] Train loss=1.1789644956588745
[15/24] Train loss=1.1169676780700684
[20/24] Train loss=1.1322962045669556
Test set avg_accuracy=75.03% avg_sensitivity=74.95%, avg_specificity=75.05% avg_auc=82.10%
Best model saved!! Metric=-18.872282334985172!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=1.159657 Test loss=0.553967 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.1233729124069214
[5/24] Train loss=1.108635663986206
[10/24] Train loss=1.1376187801361084
[15/24] Train loss=1.0661909580230713
[20/24] Train loss=1.0914115905761719
Test set avg_accuracy=75.86% avg_sensitivity=77.93%, avg_specificity=75.09% avg_auc=83.57%
Best model saved!! Metric=-13.55154008329913!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=1.118083 Test loss=0.535693 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.0889850854873657
[5/24] Train loss=1.0441031455993652
[10/24] Train loss=1.0934669971466064
[15/24] Train loss=1.0170643329620361
[20/24] Train loss=1.0459409952163696
Test set avg_accuracy=75.89% avg_sensitivity=83.01%, avg_specificity=73.23% avg_auc=84.81%
Best model saved!! Metric=-9.062313340645929!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=1.074737 Test loss=0.528262 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.0412594079971313
[5/24] Train loss=1.0110938549041748
[10/24] Train loss=1.0628008842468262
[15/24] Train loss=0.9835823178291321
[20/24] Train loss=1.0034271478652954
Test set avg_accuracy=75.82% avg_sensitivity=86.08%, avg_specificity=72.00% avg_auc=85.92%
Best model saved!! Metric=-6.174089520088401!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=1.036549 Test loss=0.522478 Current lr=[5.97283087248885e-05]

[0/24] Train loss=1.0160068273544312
[5/24] Train loss=1.0034160614013672
[10/24] Train loss=1.0317356586456299
[15/24] Train loss=0.964948832988739
[20/24] Train loss=0.9551507830619812
Test set avg_accuracy=76.58% avg_sensitivity=86.37%, avg_specificity=72.93% avg_auc=86.76%
Best model saved!! Metric=-3.3640476684344662!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=1.001900 Test loss=0.505334 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.9997480511665344
[5/24] Train loss=0.9599490165710449
[10/24] Train loss=1.016356348991394
[15/24] Train loss=0.9265627861022949
[20/24] Train loss=0.9282132983207703
Test set avg_accuracy=77.27% avg_sensitivity=85.51%, avg_specificity=74.20% avg_auc=87.44%
Best model saved!! Metric=-1.5919137684375642!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.977970 Test loss=0.483126 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.9541023373603821
[5/24] Train loss=0.9402428269386292
[10/24] Train loss=0.9486947655677795
[15/24] Train loss=0.9155582785606384
[20/24] Train loss=0.9191274046897888
Test set avg_accuracy=76.78% avg_sensitivity=88.05%, avg_specificity=72.59% avg_auc=88.25%
Best model saved!! Metric=-0.3277243669445511!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.948858 Test loss=0.484757 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.9492868185043335
[5/24] Train loss=0.9192937612533569
[10/24] Train loss=0.9263522028923035
[15/24] Train loss=0.8926582932472229
[20/24] Train loss=0.9060043692588806
Test set avg_accuracy=75.94% avg_sensitivity=89.88%, avg_specificity=70.75% avg_auc=88.93%
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.932494 Test loss=0.494153 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.9476782083511353
[5/24] Train loss=0.8966009020805359
[10/24] Train loss=0.9095515608787537
[15/24] Train loss=0.8719862699508667
[20/24] Train loss=0.8698718547821045
Test set avg_accuracy=76.74% avg_sensitivity=90.50%, avg_specificity=71.62% avg_auc=89.42%
Best model saved!! Metric=2.282684101487817!!
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.915514 Test loss=0.481492 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.9163364768028259
[5/24] Train loss=0.8776849508285522
[10/24] Train loss=0.9055883288383484
[15/24] Train loss=0.8532899618148804
[20/24] Train loss=0.8459473252296448
Test set avg_accuracy=77.37% avg_sensitivity=89.54%, avg_specificity=72.84% avg_auc=89.71%
Best model saved!! Metric=3.4585385642999!!
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.900206 Test loss=0.466871 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.8979771733283997
[5/24] Train loss=0.8628743886947632
[10/24] Train loss=0.8753217458724976
[15/24] Train loss=0.8539801239967346
[20/24] Train loss=0.8291168808937073
Test set avg_accuracy=77.57% avg_sensitivity=89.83%, avg_specificity=73.00% avg_auc=89.81%
Best model saved!! Metric=4.196242188203854!!
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.887659 Test loss=0.467258 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.8830161094665527
[5/24] Train loss=0.8377891778945923
[10/24] Train loss=0.8794302940368652
[15/24] Train loss=0.8349462747573853
[20/24] Train loss=0.809874951839447
Test set avg_accuracy=78.62% avg_sensitivity=89.20%, avg_specificity=74.68% avg_auc=90.17%
Best model saved!! Metric=6.666656784196462!!
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.868921 Test loss=0.448872 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.8520908951759338
[5/24] Train loss=0.8305191397666931
[10/24] Train loss=0.8522844910621643
[15/24] Train loss=0.7984941005706787
[20/24] Train loss=0.7883380055427551
Test set avg_accuracy=81.45% avg_sensitivity=84.98%, avg_specificity=80.13% avg_auc=90.39%
Best model saved!! Metric=10.941372202639243!!
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.854630 Test loss=0.400549 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.8104633688926697
[5/24] Train loss=0.8249381184577942
[10/24] Train loss=0.854735255241394
[15/24] Train loss=0.8011943101882935
[20/24] Train loss=0.7553952932357788
Test set avg_accuracy=82.24% avg_sensitivity=82.63%, avg_specificity=82.09% avg_auc=90.36%
Best model saved!! Metric=11.3210637642416!!
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.849364 Test loss=0.387695 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.7931162714958191
[5/24] Train loss=0.8073285818099976
[10/24] Train loss=0.8581949472427368
[15/24] Train loss=0.7626494765281677
[20/24] Train loss=0.7548538446426392
Test set avg_accuracy=83.11% avg_sensitivity=82.10%, avg_specificity=83.49% avg_auc=90.51%
Best model saved!! Metric=13.212683124388036!!
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.841542 Test loss=0.377645 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.7895736694335938
[5/24] Train loss=0.8273696303367615
[10/24] Train loss=0.8475507497787476
[15/24] Train loss=0.7738863825798035
[20/24] Train loss=0.7279331088066101
Test set avg_accuracy=83.09% avg_sensitivity=81.72%, avg_specificity=83.60% avg_auc=90.66%
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.838121 Test loss=0.373186 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.7774814963340759
[5/24] Train loss=0.8145372271537781
[10/24] Train loss=0.8391586542129517
[15/24] Train loss=0.7763609886169434
[20/24] Train loss=0.7312999367713928
Test set avg_accuracy=82.97% avg_sensitivity=82.44%, avg_specificity=83.17% avg_auc=90.65%
Best model saved!! Metric=13.224375076315809!!
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.825825 Test loss=0.375752 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.7757048606872559
[5/24] Train loss=0.8026719689369202
[10/24] Train loss=0.828143298625946
[15/24] Train loss=0.7477356195449829
[20/24] Train loss=0.7068695425987244
Test set avg_accuracy=84.43% avg_sensitivity=79.70%, avg_specificity=86.19% avg_auc=90.95%
Best model saved!! Metric=15.268205110747672!!
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.810265 Test loss=0.355036 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.7621709704399109
[5/24] Train loss=0.8045685887336731
[10/24] Train loss=0.7879646420478821
[15/24] Train loss=0.7222461700439453
[20/24] Train loss=0.7003107666969299
Test set avg_accuracy=84.43% avg_sensitivity=79.13%, avg_specificity=86.40% avg_auc=91.04%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.794935 Test loss=0.350949 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.7432490587234497
[5/24] Train loss=0.8048251271247864
[10/24] Train loss=0.7802521586418152
[15/24] Train loss=0.7244045734405518
[20/24] Train loss=0.6938064694404602
Test set avg_accuracy=84.61% avg_sensitivity=80.37%, avg_specificity=86.19% avg_auc=91.26%
Best model saved!! Metric=16.434962305986318!!
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.780126 Test loss=0.350608 Current lr=[0.000210185142098938]

[0/24] Train loss=0.7478525638580322
[5/24] Train loss=0.8027205467224121
[10/24] Train loss=0.7723479270935059
[15/24] Train loss=0.7328147888183594
[20/24] Train loss=0.6884010434150696
Test set avg_accuracy=84.65% avg_sensitivity=79.46%, avg_specificity=86.58% avg_auc=91.27%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.776759 Test loss=0.347795 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.7339194416999817
[5/24] Train loss=0.8067533373832703
[10/24] Train loss=0.7784464359283447
[15/24] Train loss=0.714948832988739
[20/24] Train loss=0.6766212582588196
Test set avg_accuracy=84.10% avg_sensitivity=82.58%, avg_specificity=84.67% avg_auc=91.46%
Best model saved!! Metric=16.811804529198255!!
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.768956 Test loss=0.357289 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.7418869137763977
[5/24] Train loss=0.8208808898925781
[10/24] Train loss=0.7731504440307617
[15/24] Train loss=0.7234771847724915
[20/24] Train loss=0.6722190380096436
Test set avg_accuracy=84.62% avg_sensitivity=81.14%, avg_specificity=85.92% avg_auc=91.50%
Best model saved!! Metric=17.1820384489115!!
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.764213 Test loss=0.349268 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.7356038093566895
[5/24] Train loss=0.8325503468513489
[10/24] Train loss=0.7685689330101013
[15/24] Train loss=0.7194498777389526
[20/24] Train loss=0.6760095357894897
Test set avg_accuracy=83.72% avg_sensitivity=83.45%, avg_specificity=83.83% avg_auc=91.54%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.762288 Test loss=0.360853 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.7388598322868347
[5/24] Train loss=0.799435555934906
[10/24] Train loss=0.7684127688407898
[15/24] Train loss=0.7224694490432739
[20/24] Train loss=0.6634294390678406
Test set avg_accuracy=82.10% avg_sensitivity=86.37%, avg_specificity=80.50% avg_auc=91.52%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.759035 Test loss=0.386312 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.7553476691246033
[5/24] Train loss=0.7964853048324585
[10/24] Train loss=0.7786867022514343
[15/24] Train loss=0.7156497240066528
[20/24] Train loss=0.646238386631012
Test set avg_accuracy=83.37% avg_sensitivity=86.04%, avg_specificity=82.38% avg_auc=91.71%
Best model saved!! Metric=17.49775614691076!!
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.755600 Test loss=0.371790 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.7518641352653503
[5/24] Train loss=0.7882614731788635
[10/24] Train loss=0.7706494927406311
[15/24] Train loss=0.6982226967811584
[20/24] Train loss=0.6598941087722778
Test set avg_accuracy=83.22% avg_sensitivity=85.80%, avg_specificity=82.26% avg_auc=91.74%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.746574 Test loss=0.371712 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.7421597838401794
[5/24] Train loss=0.7933337688446045
[10/24] Train loss=0.7711145281791687
[15/24] Train loss=0.6880995035171509
[20/24] Train loss=0.6564176082611084
Test set avg_accuracy=83.31% avg_sensitivity=86.04%, avg_specificity=82.29% avg_auc=91.83%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.743522 Test loss=0.372073 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.735699474811554
[5/24] Train loss=0.7866670489311218
[10/24] Train loss=0.7847971320152283
[15/24] Train loss=0.6854211091995239
[20/24] Train loss=0.6291557550430298
Test set avg_accuracy=82.02% avg_sensitivity=88.63%, avg_specificity=79.56% avg_auc=91.85%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.739993 Test loss=0.396417 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.746326208114624
[5/24] Train loss=0.7698466181755066
[10/24] Train loss=0.7611163854598999
[15/24] Train loss=0.6810435056686401
[20/24] Train loss=0.6322625279426575
Test set avg_accuracy=82.36% avg_sensitivity=87.24%, avg_specificity=80.54% avg_auc=91.80%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.732702 Test loss=0.384893 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.7463070154190063
[5/24] Train loss=0.769037663936615
[10/24] Train loss=0.7675964832305908
[15/24] Train loss=0.6905039548873901
[20/24] Train loss=0.6441648006439209
Test set avg_accuracy=83.46% avg_sensitivity=86.42%, avg_specificity=82.36% avg_auc=92.06%
Best model saved!! Metric=18.308778839091715!!
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.732896 Test loss=0.368819 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.7325878739356995
[5/24] Train loss=0.7597346901893616
[10/24] Train loss=0.7671539783477783
[15/24] Train loss=0.6779986619949341
[20/24] Train loss=0.6349300146102905
Test set avg_accuracy=83.46% avg_sensitivity=87.04%, avg_specificity=82.13% avg_auc=92.16%
Best model saved!! Metric=18.802212076981675!!
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.728241 Test loss=0.369910 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.7301130294799805
[5/24] Train loss=0.7589881420135498
[10/24] Train loss=0.756962776184082
[15/24] Train loss=0.6754472851753235
[20/24] Train loss=0.6295842528343201
Test set avg_accuracy=83.50% avg_sensitivity=86.85%, avg_specificity=82.26% avg_auc=92.16%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.723254 Test loss=0.368897 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.7256458401679993
[5/24] Train loss=0.759777307510376
[10/24] Train loss=0.7670317888259888
[15/24] Train loss=0.6662917137145996
[20/24] Train loss=0.6229962706565857
Test set avg_accuracy=83.95% avg_sensitivity=86.90%, avg_specificity=82.84% avg_auc=92.33%
Best model saved!! Metric=20.017866723677756!!
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.720868 Test loss=0.365324 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.7120198011398315
[5/24] Train loss=0.7633534073829651
[10/24] Train loss=0.7669325470924377
[15/24] Train loss=0.6649230122566223
[20/24] Train loss=0.6153783202171326
Test set avg_accuracy=83.14% avg_sensitivity=88.48%, avg_specificity=81.15% avg_auc=92.31%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.718219 Test loss=0.380234 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.7218157052993774
[5/24] Train loss=0.7514573931694031
[10/24] Train loss=0.7549026608467102
[15/24] Train loss=0.6538113355636597
[20/24] Train loss=0.6173065900802612
Test set avg_accuracy=84.60% avg_sensitivity=86.90%, avg_specificity=83.74% avg_auc=92.50%
Best model saved!! Metric=21.737535693367235!!
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.711783 Test loss=0.359046 Current lr=[0.00029967723776099]

[0/24] Train loss=0.7019444108009338
[5/24] Train loss=0.7620731592178345
[10/24] Train loss=0.7645395398139954
[15/24] Train loss=0.6610986590385437
[20/24] Train loss=0.6120861172676086
Test set avg_accuracy=83.96% avg_sensitivity=87.67%, avg_specificity=82.58% avg_auc=92.54%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.714839 Test loss=0.363115 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.7065516710281372
[5/24] Train loss=0.7504299283027649
[10/24] Train loss=0.7610324621200562
[15/24] Train loss=0.6633726954460144
[20/24] Train loss=0.605481743812561
Test set avg_accuracy=84.66% avg_sensitivity=86.85%, avg_specificity=83.85% avg_auc=92.59%
Best model saved!! Metric=21.9453161478677!!
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.710022 Test loss=0.356183 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.7070246934890747
[5/24] Train loss=0.7443893551826477
[10/24] Train loss=0.7376430630683899
[15/24] Train loss=0.6457048058509827
[20/24] Train loss=0.6027840971946716
Test set avg_accuracy=85.82% avg_sensitivity=82.77%, avg_specificity=86.95% avg_auc=92.62%
Best model saved!! Metric=22.165580027257604!!
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.712048 Test loss=0.329173 Current lr=[0.000299720220882401]

[0/24] Train loss=0.6909134984016418
[5/24] Train loss=0.7807554006576538
[10/24] Train loss=0.7022186517715454
[15/24] Train loss=0.6646353006362915
[20/24] Train loss=0.5995231866836548
Test set avg_accuracy=86.17% avg_sensitivity=81.96%, avg_specificity=87.74% avg_auc=92.60%
Best model saved!! Metric=22.475829085657566!!
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.703502 Test loss=0.324120 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.6807191371917725
[5/24] Train loss=0.7647908926010132
[10/24] Train loss=0.7004144191741943
[15/24] Train loss=0.6559507250785828
[20/24] Train loss=0.6020337343215942
Test set avg_accuracy=85.65% avg_sensitivity=84.40%, avg_specificity=86.12% avg_auc=92.62%
Best model saved!! Metric=22.79171727949131!!
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.697468 Test loss=0.336011 Current lr=[0.000298904600941902]

[0/24] Train loss=0.6765743494033813
[5/24] Train loss=0.7516835331916809
[10/24] Train loss=0.7106608152389526
[15/24] Train loss=0.6388332843780518
[20/24] Train loss=0.5821719765663147
Test set avg_accuracy=85.86% avg_sensitivity=84.79%, avg_specificity=86.26% avg_auc=92.68%
Best model saved!! Metric=23.58709935479689!!
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.694991 Test loss=0.334592 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.6777061223983765
[5/24] Train loss=0.763774037361145
[10/24] Train loss=0.7004203796386719
[15/24] Train loss=0.6419557332992554
[20/24] Train loss=0.5824795961380005
Test set avg_accuracy=85.89% avg_sensitivity=84.31%, avg_specificity=86.47% avg_auc=92.72%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.693230 Test loss=0.332260 Current lr=[0.000297555943323901]

[0/24] Train loss=0.6723740100860596
[5/24] Train loss=0.7614042162895203
[10/24] Train loss=0.7046000361442566
[15/24] Train loss=0.6223545670509338
[20/24] Train loss=0.590933084487915
Test set avg_accuracy=86.05% avg_sensitivity=83.06%, avg_specificity=87.17% avg_auc=92.68%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.691846 Test loss=0.325954 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.6766177415847778
[5/24] Train loss=0.7507755756378174
[10/24] Train loss=0.7042966485023499
[15/24] Train loss=0.63155597448349
[20/24] Train loss=0.593904972076416
Test set avg_accuracy=85.85% avg_sensitivity=83.69%, avg_specificity=86.65% avg_auc=92.69%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.687261 Test loss=0.330730 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.6758032441139221
[5/24] Train loss=0.7437559962272644
[10/24] Train loss=0.6941388845443726
[15/24] Train loss=0.6368679404258728
[20/24] Train loss=0.5949681997299194
Test set avg_accuracy=85.62% avg_sensitivity=84.64%, avg_specificity=85.99% avg_auc=92.78%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.685366 Test loss=0.333702 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.6770932674407959
[5/24] Train loss=0.7483495473861694
[10/24] Train loss=0.7076613306999207
[15/24] Train loss=0.6460788249969482
[20/24] Train loss=0.5774827003479004
Test set avg_accuracy=85.85% avg_sensitivity=84.12%, avg_specificity=86.49% avg_auc=92.78%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.686093 Test loss=0.329249 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.6673007607460022
[5/24] Train loss=0.7478041648864746
[10/24] Train loss=0.6976850032806396
[15/24] Train loss=0.6401671171188354
[20/24] Train loss=0.580163836479187
Test set avg_accuracy=85.42% avg_sensitivity=85.51%, avg_specificity=85.38% avg_auc=92.83%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.682851 Test loss=0.339381 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.6651747822761536
[5/24] Train loss=0.739102303981781
[10/24] Train loss=0.7063219547271729
[15/24] Train loss=0.6396805644035339
[20/24] Train loss=0.5813133716583252
Test set avg_accuracy=86.16% avg_sensitivity=83.83%, avg_specificity=87.03% avg_auc=92.82%
Best model saved!! Metric=23.834306470821403!!
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.683317 Test loss=0.323899 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.6689441800117493
[5/24] Train loss=0.759286105632782
[10/24] Train loss=0.6919088959693909
[15/24] Train loss=0.6350918412208557
[20/24] Train loss=0.5767753720283508
Test set avg_accuracy=86.25% avg_sensitivity=83.73%, avg_specificity=87.19% avg_auc=92.87%
Best model saved!! Metric=24.037156373005672!!
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.679812 Test loss=0.323762 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.6713120937347412
[5/24] Train loss=0.7421613335609436
[10/24] Train loss=0.6857755184173584
[15/24] Train loss=0.6352797746658325
[20/24] Train loss=0.5803837180137634
Test set avg_accuracy=86.30% avg_sensitivity=83.01%, avg_specificity=87.53% avg_auc=92.81%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.678036 Test loss=0.321454 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.6533430814743042
[5/24] Train loss=0.7455375790596008
[10/24] Train loss=0.6816501617431641
[15/24] Train loss=0.6234613060951233
[20/24] Train loss=0.5694006085395813
Test set avg_accuracy=86.13% avg_sensitivity=83.78%, avg_specificity=87.01% avg_auc=92.92%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.675385 Test loss=0.323250 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.6603330373764038
[5/24] Train loss=0.7445977926254272
[10/24] Train loss=0.6820946335792542
[15/24] Train loss=0.6244532465934753
[20/24] Train loss=0.5735583305358887
Test set avg_accuracy=86.25% avg_sensitivity=84.21%, avg_specificity=87.01% avg_auc=92.89%
Best model saved!! Metric=24.35833451094078!!
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.672778 Test loss=0.325143 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.6598485112190247
[5/24] Train loss=0.7402496337890625
[10/24] Train loss=0.6836750507354736
[15/24] Train loss=0.622384786605835
[20/24] Train loss=0.5717742443084717
Test set avg_accuracy=86.32% avg_sensitivity=83.88%, avg_specificity=87.22% avg_auc=92.97%
Best model saved!! Metric=24.385383664361072!!
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.671975 Test loss=0.321938 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.659150242805481
[5/24] Train loss=0.7424275279045105
[10/24] Train loss=0.6743531823158264
[15/24] Train loss=0.6172395944595337
[20/24] Train loss=0.5688091516494751
Test set avg_accuracy=86.90% avg_sensitivity=81.86%, avg_specificity=88.78% avg_auc=92.91%
Best model saved!! Metric=24.445856718273333!!
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.671207 Test loss=0.313985 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.6498401761054993
[5/24] Train loss=0.7550954222679138
[10/24] Train loss=0.685789942741394
[15/24] Train loss=0.6383349895477295
[20/24] Train loss=0.5713632106781006
Test set avg_accuracy=87.28% avg_sensitivity=78.36%, avg_specificity=90.60% avg_auc=92.81%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.673314 Test loss=0.306103 Current lr=[0.000276307469034998]

[0/24] Train loss=0.6679773926734924
[5/24] Train loss=0.7472896575927734
[10/24] Train loss=0.6935158371925354
[15/24] Train loss=0.6405027508735657
[20/24] Train loss=0.5738141536712646
Test set avg_accuracy=87.28% avg_sensitivity=78.21%, avg_specificity=90.65% avg_auc=92.86%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.678887 Test loss=0.304129 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.6528541445732117
[5/24] Train loss=0.7112066149711609
[10/24] Train loss=0.7048925161361694
[15/24] Train loss=0.628704845905304
[20/24] Train loss=0.5742181539535522
Test set avg_accuracy=86.76% avg_sensitivity=82.10%, avg_specificity=88.49% avg_auc=92.84%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.677968 Test loss=0.315170 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.6346359848976135
[5/24] Train loss=0.7084078788757324
[10/24] Train loss=0.7030959129333496
[15/24] Train loss=0.6134383082389832
[20/24] Train loss=0.5838204026222229
Test set avg_accuracy=86.65% avg_sensitivity=83.21%, avg_specificity=87.94% avg_auc=92.83%
Best model saved!! Metric=24.628633451305603!!
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.670577 Test loss=0.318639 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.6491774320602417
[5/24] Train loss=0.7097137570381165
[10/24] Train loss=0.6837608814239502
[15/24] Train loss=0.6092137694358826
[20/24] Train loss=0.5775254368782043
Test set avg_accuracy=86.84% avg_sensitivity=81.38%, avg_specificity=88.87% avg_auc=92.83%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.665724 Test loss=0.312189 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.6466250419616699
[5/24] Train loss=0.7176693081855774
[10/24] Train loss=0.6878884434700012
[15/24] Train loss=0.6250753998756409
[20/24] Train loss=0.5754635334014893
Test set avg_accuracy=86.74% avg_sensitivity=82.25%, avg_specificity=88.42% avg_auc=92.85%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.667365 Test loss=0.315992 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.6404446959495544
[5/24] Train loss=0.7208213806152344
[10/24] Train loss=0.6805253624916077
[15/24] Train loss=0.6141201257705688
[20/24] Train loss=0.5610926151275635
Test set avg_accuracy=86.82% avg_sensitivity=82.34%, avg_specificity=88.49% avg_auc=92.86%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.660529 Test loss=0.314658 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.6344579458236694
[5/24] Train loss=0.70616215467453
[10/24] Train loss=0.6894354820251465
[15/24] Train loss=0.612845242023468
[20/24] Train loss=0.5808167457580566
Test set avg_accuracy=86.51% avg_sensitivity=82.92%, avg_specificity=87.85% avg_auc=92.87%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.659146 Test loss=0.317951 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.6355510950088501
[5/24] Train loss=0.7130399942398071
[10/24] Train loss=0.6806606650352478
[15/24] Train loss=0.6132495403289795
[20/24] Train loss=0.5620935559272766
Test set avg_accuracy=86.76% avg_sensitivity=82.25%, avg_specificity=88.44% avg_auc=92.86%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.658494 Test loss=0.314241 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.6347246766090393
[5/24] Train loss=0.6946835517883301
[10/24] Train loss=0.6771109700202942
[15/24] Train loss=0.6011422872543335
[20/24] Train loss=0.5646735429763794
Test set avg_accuracy=86.67% avg_sensitivity=82.25%, avg_specificity=88.31% avg_auc=92.90%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.657630 Test loss=0.315235 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.6378046870231628
[5/24] Train loss=0.7043758630752563
[10/24] Train loss=0.6710097193717957
[15/24] Train loss=0.6127372980117798
[20/24] Train loss=0.5656028985977173
Test set avg_accuracy=86.97% avg_sensitivity=82.15%, avg_specificity=88.76% avg_auc=92.92%
Best model saved!! Metric=24.798628659700938!!
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.656095 Test loss=0.312469 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.6384543180465698
[5/24] Train loss=0.6982273459434509
[10/24] Train loss=0.6807217001914978
[15/24] Train loss=0.6087383031845093
[20/24] Train loss=0.5742743015289307
Test set avg_accuracy=86.58% avg_sensitivity=83.25%, avg_specificity=87.81% avg_auc=92.98%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.658243 Test loss=0.316773 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.6353957056999207
[5/24] Train loss=0.7006836533546448
[10/24] Train loss=0.6637285351753235
[15/24] Train loss=0.607938826084137
[20/24] Train loss=0.5670270323753357
Test set avg_accuracy=86.51% avg_sensitivity=83.59%, avg_specificity=87.60% avg_auc=92.93%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.657710 Test loss=0.318437 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.629183292388916
[5/24] Train loss=0.7065901756286621
[10/24] Train loss=0.6731389760971069
[15/24] Train loss=0.6195271611213684
[20/24] Train loss=0.5624398589134216
Test set avg_accuracy=86.35% avg_sensitivity=84.74%, avg_specificity=86.95% avg_auc=92.98%
Best model saved!! Metric=25.034140983391396!!
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.659697 Test loss=0.323801 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.6325396299362183
[5/24] Train loss=0.7062835693359375
[10/24] Train loss=0.6759973168373108
[15/24] Train loss=0.62361741065979
[20/24] Train loss=0.5895854830741882
Test set avg_accuracy=85.38% avg_sensitivity=86.13%, avg_specificity=85.10% avg_auc=93.02%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.662226 Test loss=0.337602 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.637738049030304
[5/24] Train loss=0.6951643824577332
[10/24] Train loss=0.6852590441703796
[15/24] Train loss=0.6239064335823059
[20/24] Train loss=0.5973218679428101
Test set avg_accuracy=83.98% avg_sensitivity=87.72%, avg_specificity=82.59% avg_auc=92.97%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.659540 Test loss=0.363245 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.6664725542068481
[5/24] Train loss=0.7027559876441956
[10/24] Train loss=0.6725703477859497
[15/24] Train loss=0.6276457905769348
[20/24] Train loss=0.611562967300415
Test set avg_accuracy=84.27% avg_sensitivity=88.05%, avg_specificity=82.86% avg_auc=93.06%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.659623 Test loss=0.359714 Current lr=[0.000224838296036774]

[0/24] Train loss=0.65910404920578
[5/24] Train loss=0.7166492342948914
[10/24] Train loss=0.6893697381019592
[15/24] Train loss=0.6011248826980591
[20/24] Train loss=0.6033419370651245
Test set avg_accuracy=85.04% avg_sensitivity=87.09%, avg_specificity=84.27% avg_auc=93.06%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.654427 Test loss=0.347447 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.6472947001457214
[5/24] Train loss=0.7104004621505737
[10/24] Train loss=0.6704439520835876
[15/24] Train loss=0.6049536466598511
[20/24] Train loss=0.5861477851867676
Test set avg_accuracy=85.20% avg_sensitivity=86.90%, avg_specificity=84.56% avg_auc=93.03%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.649493 Test loss=0.345189 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.6472793817520142
[5/24] Train loss=0.688241720199585
[10/24] Train loss=0.6711025238037109
[15/24] Train loss=0.603622317314148
[20/24] Train loss=0.5823490619659424
Test set avg_accuracy=85.25% avg_sensitivity=86.71%, avg_specificity=84.70% avg_auc=93.04%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.645448 Test loss=0.343287 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.645942211151123
[5/24] Train loss=0.699423611164093
[10/24] Train loss=0.6627539396286011
[15/24] Train loss=0.600773274898529
[20/24] Train loss=0.5724689960479736
Test set avg_accuracy=84.92% avg_sensitivity=87.14%, avg_specificity=84.10% avg_auc=93.08%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.646196 Test loss=0.346951 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.643555760383606
[5/24] Train loss=0.6955175399780273
[10/24] Train loss=0.6585144996643066
[15/24] Train loss=0.595099687576294
[20/24] Train loss=0.5813155174255371
Test set avg_accuracy=85.38% avg_sensitivity=86.52%, avg_specificity=84.95% avg_auc=93.10%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.642963 Test loss=0.339215 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.6315136551856995
[5/24] Train loss=0.697761595249176
[10/24] Train loss=0.6665728688240051
[15/24] Train loss=0.6094378232955933
[20/24] Train loss=0.580669105052948
Test set avg_accuracy=85.04% avg_sensitivity=87.19%, avg_specificity=84.24% avg_auc=93.11%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.642010 Test loss=0.346982 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.6295762658119202
[5/24] Train loss=0.6943631172180176
[10/24] Train loss=0.6672302484512329
[15/24] Train loss=0.6014420986175537
[20/24] Train loss=0.5972639918327332
Test set avg_accuracy=85.05% avg_sensitivity=87.76%, avg_specificity=84.04% avg_auc=93.15%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.642109 Test loss=0.346403 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.6470109820365906
[5/24] Train loss=0.6962447166442871
[10/24] Train loss=0.6617056727409363
[15/24] Train loss=0.6045548915863037
[20/24] Train loss=0.5943165421485901
Test set avg_accuracy=84.74% avg_sensitivity=87.96%, avg_specificity=83.54% avg_auc=93.10%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.644006 Test loss=0.350620 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.6308750510215759
[5/24] Train loss=0.697097897529602
[10/24] Train loss=0.6753989458084106
[15/24] Train loss=0.6087641716003418
[20/24] Train loss=0.583236813545227
Test set avg_accuracy=84.82% avg_sensitivity=88.00%, avg_specificity=83.63% avg_auc=93.12%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.642135 Test loss=0.350300 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.6326415538787842
[5/24] Train loss=0.7005512118339539
[10/24] Train loss=0.6584629416465759
[15/24] Train loss=0.5946630835533142
[20/24] Train loss=0.581480085849762
Test set avg_accuracy=85.07% avg_sensitivity=87.24%, avg_specificity=84.26% avg_auc=93.13%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.635225 Test loss=0.344278 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.64351886510849
[5/24] Train loss=0.6985428333282471
[10/24] Train loss=0.6675326228141785
[15/24] Train loss=0.5719835162162781
[20/24] Train loss=0.5756955742835999
Test set avg_accuracy=85.39% avg_sensitivity=86.71%, avg_specificity=84.90% avg_auc=93.15%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.633632 Test loss=0.336983 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.6411280035972595
[5/24] Train loss=0.681647777557373
[10/24] Train loss=0.6606742739677429
[15/24] Train loss=0.5780449509620667
[20/24] Train loss=0.5755560994148254
Test set avg_accuracy=85.33% avg_sensitivity=86.71%, avg_specificity=84.81% avg_auc=93.16%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.631685 Test loss=0.338731 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.6303486227989197
[5/24] Train loss=0.6761786937713623
[10/24] Train loss=0.6611995697021484
[15/24] Train loss=0.5753839015960693
[20/24] Train loss=0.574428141117096
Test set avg_accuracy=85.49% avg_sensitivity=86.80%, avg_specificity=85.01% avg_auc=93.18%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.629390 Test loss=0.339108 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.6262409687042236
[5/24] Train loss=0.6923328042030334
[10/24] Train loss=0.6593030095100403
[15/24] Train loss=0.5779284834861755
[20/24] Train loss=0.5818482041358948
Test set avg_accuracy=85.23% avg_sensitivity=87.00%, avg_specificity=84.58% avg_auc=93.17%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.631959 Test loss=0.340702 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.6193692684173584
[5/24] Train loss=0.6899033784866333
[10/24] Train loss=0.6514326930046082
[15/24] Train loss=0.5843569040298462
[20/24] Train loss=0.56479412317276
Test set avg_accuracy=85.65% avg_sensitivity=85.70%, avg_specificity=85.63% avg_auc=93.14%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.625551 Test loss=0.331587 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.6215262413024902
[5/24] Train loss=0.6730414628982544
[10/24] Train loss=0.6601823568344116
[15/24] Train loss=0.5857369899749756
[20/24] Train loss=0.5686826109886169
Test set avg_accuracy=85.29% avg_sensitivity=86.95%, avg_specificity=84.67% avg_auc=93.17%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.624745 Test loss=0.340649 Current lr=[0.000156543481933168]

[0/24] Train loss=0.6205495595932007
[5/24] Train loss=0.673425555229187
[10/24] Train loss=0.6519118547439575
[15/24] Train loss=0.5805935263633728
[20/24] Train loss=0.5640427470207214
Test set avg_accuracy=85.21% avg_sensitivity=86.80%, avg_specificity=84.61% avg_auc=93.14%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.623122 Test loss=0.339616 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.6306747794151306
[5/24] Train loss=0.6806128025054932
[10/24] Train loss=0.6694067716598511
[15/24] Train loss=0.5805541276931763
[20/24] Train loss=0.565139651298523
Test set avg_accuracy=85.59% avg_sensitivity=86.56%, avg_specificity=85.22% avg_auc=93.20%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.623674 Test loss=0.334469 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.6203311085700989
[5/24] Train loss=0.6750363111495972
[10/24] Train loss=0.6548008322715759
[15/24] Train loss=0.5717335939407349
[20/24] Train loss=0.5601916313171387
Test set avg_accuracy=85.61% avg_sensitivity=86.61%, avg_specificity=85.24% avg_auc=93.18%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.618936 Test loss=0.334672 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.6220060586929321
[5/24] Train loss=0.6566200852394104
[10/24] Train loss=0.6429787874221802
[15/24] Train loss=0.5757305026054382
[20/24] Train loss=0.5527217984199524
Test set avg_accuracy=85.60% avg_sensitivity=86.42%, avg_specificity=85.29% avg_auc=93.17%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.619059 Test loss=0.334680 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.6074090003967285
[5/24] Train loss=0.6751171946525574
[10/24] Train loss=0.6385110020637512
[15/24] Train loss=0.5639044642448425
[20/24] Train loss=0.554630696773529
Test set avg_accuracy=85.36% avg_sensitivity=86.80%, avg_specificity=84.83% avg_auc=93.17%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.616210 Test loss=0.336494 Current lr=[0.000134135431043539]

[0/24] Train loss=0.6251863837242126
[5/24] Train loss=0.6687957048416138
[10/24] Train loss=0.64085453748703
[15/24] Train loss=0.5647884607315063
[20/24] Train loss=0.5528436303138733
Test set avg_accuracy=85.48% avg_sensitivity=86.47%, avg_specificity=85.11% avg_auc=93.15%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.615514 Test loss=0.335940 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.6225811243057251
[5/24] Train loss=0.6729931235313416
[10/24] Train loss=0.6335305571556091
[15/24] Train loss=0.5571236610412598
[20/24] Train loss=0.5533159971237183
Test set avg_accuracy=85.39% avg_sensitivity=86.37%, avg_specificity=85.03% avg_auc=93.14%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.613378 Test loss=0.335721 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.6158208250999451
[5/24] Train loss=0.6569427847862244
[10/24] Train loss=0.6523356437683105
[15/24] Train loss=0.5635452270507812
[20/24] Train loss=0.5512709021568298
Test set avg_accuracy=85.78% avg_sensitivity=85.89%, avg_specificity=85.74% avg_auc=93.10%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.612611 Test loss=0.331668 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.6099904775619507
[5/24] Train loss=0.661449134349823
[10/24] Train loss=0.6396257281303406
[15/24] Train loss=0.5538303852081299
[20/24] Train loss=0.550245463848114
Test set avg_accuracy=85.40% avg_sensitivity=86.52%, avg_specificity=84.99% avg_auc=93.12%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.611637 Test loss=0.337635 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.6205270886421204
[5/24] Train loss=0.662580132484436
[10/24] Train loss=0.6556398868560791
[15/24] Train loss=0.5668083429336548
[20/24] Train loss=0.5550761818885803
Test set avg_accuracy=85.44% avg_sensitivity=86.61%, avg_specificity=85.01% avg_auc=93.13%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.613332 Test loss=0.336758 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.6003636717796326
[5/24] Train loss=0.6604865789413452
[10/24] Train loss=0.6381461024284363
[15/24] Train loss=0.5637215971946716
[20/24] Train loss=0.5570337772369385
Test set avg_accuracy=85.69% avg_sensitivity=86.18%, avg_specificity=85.51% avg_auc=93.08%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.609856 Test loss=0.333922 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.6039173007011414
[5/24] Train loss=0.6572192311286926
[10/24] Train loss=0.6425485014915466
[15/24] Train loss=0.5666988492012024
[20/24] Train loss=0.552029013633728
Test set avg_accuracy=85.43% avg_sensitivity=86.52%, avg_specificity=85.03% avg_auc=93.06%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.610358 Test loss=0.336933 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.6113229393959045
[5/24] Train loss=0.6557513475418091
[10/24] Train loss=0.6460264921188354
[15/24] Train loss=0.5608347654342651
[20/24] Train loss=0.5555996298789978
Test set avg_accuracy=85.40% avg_sensitivity=86.71%, avg_specificity=84.92% avg_auc=93.12%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.611399 Test loss=0.337929 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.6049729585647583
[5/24] Train loss=0.6529290080070496
[10/24] Train loss=0.6411565542221069
[15/24] Train loss=0.5603992938995361
[20/24] Train loss=0.5500741600990295
Test set avg_accuracy=85.23% avg_sensitivity=86.66%, avg_specificity=84.70% avg_auc=93.16%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.611286 Test loss=0.339434 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.6050868034362793
[5/24] Train loss=0.6761388778686523
[10/24] Train loss=0.6505566239356995
[15/24] Train loss=0.5586090087890625
[20/24] Train loss=0.5519089102745056
Test set avg_accuracy=85.14% avg_sensitivity=87.81%, avg_specificity=84.15% avg_auc=93.24%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.609197 Test loss=0.344164 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.6100918054580688
[5/24] Train loss=0.6811822652816772
[10/24] Train loss=0.6478622555732727
[15/24] Train loss=0.5691801309585571
[20/24] Train loss=0.5475367307662964
Test set avg_accuracy=84.71% avg_sensitivity=88.48%, avg_specificity=83.31% avg_auc=93.24%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.610581 Test loss=0.352439 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.6085963249206543
[5/24] Train loss=0.6718354821205139
[10/24] Train loss=0.6500360369682312
[15/24] Train loss=0.5586668848991394
[20/24] Train loss=0.5541200637817383
Test set avg_accuracy=84.60% avg_sensitivity=89.16%, avg_specificity=82.90% avg_auc=93.23%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.609389 Test loss=0.357437 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.623916506767273
[5/24] Train loss=0.6784063577651978
[10/24] Train loss=0.6258849501609802
[15/24] Train loss=0.5536971092224121
[20/24] Train loss=0.5690732002258301
Test set avg_accuracy=84.95% avg_sensitivity=88.44%, avg_specificity=83.65% avg_auc=93.24%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.606666 Test loss=0.349250 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.6190065145492554
[5/24] Train loss=0.6532064080238342
[10/24] Train loss=0.6252333521842957
[15/24] Train loss=0.5571615695953369
[20/24] Train loss=0.5640100836753845
Test set avg_accuracy=85.59% avg_sensitivity=87.33%, avg_specificity=84.94% avg_auc=93.23%
Best model saved!! Metric=25.0810634056716!!
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.603169 Test loss=0.338252 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.6038221716880798
[5/24] Train loss=0.6414180397987366
[10/24] Train loss=0.618517279624939
[15/24] Train loss=0.5481747388839722
[20/24] Train loss=0.5511555075645447
Test set avg_accuracy=85.60% avg_sensitivity=87.09%, avg_specificity=85.04% avg_auc=93.23%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.599013 Test loss=0.336190 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.5961365699768066
[5/24] Train loss=0.6448416709899902
[10/24] Train loss=0.6294476985931396
[15/24] Train loss=0.5479321479797363
[20/24] Train loss=0.5618826746940613
Test set avg_accuracy=85.44% avg_sensitivity=87.52%, avg_specificity=84.67% avg_auc=93.24%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.597919 Test loss=0.339928 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.6003062129020691
[5/24] Train loss=0.6422057747840881
[10/24] Train loss=0.6193551421165466
[15/24] Train loss=0.5483952760696411
[20/24] Train loss=0.5598558187484741
Test set avg_accuracy=85.62% avg_sensitivity=86.85%, avg_specificity=85.17% avg_auc=93.22%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.598101 Test loss=0.334598 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.5956647396087646
[5/24] Train loss=0.657261312007904
[10/24] Train loss=0.6316128373146057
[15/24] Train loss=0.5470338463783264
[20/24] Train loss=0.5535411834716797
Test set avg_accuracy=85.56% avg_sensitivity=87.14%, avg_specificity=84.97% avg_auc=93.22%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.596737 Test loss=0.337238 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.5972906947135925
[5/24] Train loss=0.6541643142700195
[10/24] Train loss=0.6113529801368713
[15/24] Train loss=0.5440443158149719
[20/24] Train loss=0.5544390678405762
Test set avg_accuracy=85.69% avg_sensitivity=87.04%, avg_specificity=85.19% avg_auc=93.25%
Best model saved!! Metric=25.16835055598507!!
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.594398 Test loss=0.334904 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.5951030850410461
[5/24] Train loss=0.6434588432312012
[10/24] Train loss=0.6062813401222229
[15/24] Train loss=0.5512641072273254
[20/24] Train loss=0.5405526757240295
Test set avg_accuracy=85.60% avg_sensitivity=87.19%, avg_specificity=85.01% avg_auc=93.26%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.592022 Test loss=0.336104 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.5952804088592529
[5/24] Train loss=0.6558547019958496
[10/24] Train loss=0.6241292357444763
[15/24] Train loss=0.5382661819458008
[20/24] Train loss=0.5444453954696655
Test set avg_accuracy=85.68% avg_sensitivity=87.00%, avg_specificity=85.19% avg_auc=93.26%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.592755 Test loss=0.334957 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.5964388251304626
[5/24] Train loss=0.6430147290229797
[10/24] Train loss=0.6094528436660767
[15/24] Train loss=0.5502927303314209
[20/24] Train loss=0.5459769368171692
Test set avg_accuracy=85.60% avg_sensitivity=87.19%, avg_specificity=85.01% avg_auc=93.26%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.591343 Test loss=0.336407 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.596157968044281
[5/24] Train loss=0.633661150932312
[10/24] Train loss=0.6085008382797241
[15/24] Train loss=0.5475775003433228
[20/24] Train loss=0.5391924977302551
Test set avg_accuracy=85.69% avg_sensitivity=86.90%, avg_specificity=85.24% avg_auc=93.26%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.591380 Test loss=0.333090 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.5863869190216064
[5/24] Train loss=0.6415804624557495
[10/24] Train loss=0.6158654093742371
[15/24] Train loss=0.5443501472473145
[20/24] Train loss=0.5306858420372009
Test set avg_accuracy=85.49% avg_sensitivity=87.33%, avg_specificity=84.81% avg_auc=93.29%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.590246 Test loss=0.337392 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.5827403664588928
[5/24] Train loss=0.6403061151504517
[10/24] Train loss=0.6110318899154663
[15/24] Train loss=0.551388144493103
[20/24] Train loss=0.5350960493087769
Test set avg_accuracy=85.51% avg_sensitivity=87.24%, avg_specificity=84.86% avg_auc=93.28%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.588776 Test loss=0.336349 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.6023150682449341
[5/24] Train loss=0.6396059989929199
[10/24] Train loss=0.6105684041976929
[15/24] Train loss=0.5434718132019043
[20/24] Train loss=0.5369478464126587
Test set avg_accuracy=85.59% avg_sensitivity=87.38%, avg_specificity=84.92% avg_auc=93.30%
Best model saved!! Metric=25.18089564806023!!
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.589830 Test loss=0.336968 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.59848952293396
[5/24] Train loss=0.6309681534767151
[10/24] Train loss=0.6102467179298401
[15/24] Train loss=0.5449760556221008
[20/24] Train loss=0.535246729850769
Test set avg_accuracy=85.56% avg_sensitivity=87.57%, avg_specificity=84.81% avg_auc=93.29%
Best model saved!! Metric=25.23285046640686!!
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.588436 Test loss=0.338231 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.5865421891212463
[5/24] Train loss=0.6334091424942017
[10/24] Train loss=0.6074803471565247
[15/24] Train loss=0.5314532518386841
[20/24] Train loss=0.5315997004508972
Test set avg_accuracy=85.57% avg_sensitivity=87.57%, avg_specificity=84.83% avg_auc=93.30%
Best model saved!! Metric=25.269340558698133!!
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.587245 Test loss=0.337467 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.5785611867904663
[5/24] Train loss=0.6349149346351624
[10/24] Train loss=0.6202744841575623
[15/24] Train loss=0.5338493585586548
[20/24] Train loss=0.5345668196678162
Test set avg_accuracy=85.52% avg_sensitivity=87.67%, avg_specificity=84.72% avg_auc=93.30%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.589625 Test loss=0.339516 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.5938714146614075
[5/24] Train loss=0.6313087940216064
[10/24] Train loss=0.5990995168685913
[15/24] Train loss=0.5393224358558655
[20/24] Train loss=0.5494880080223083
Test set avg_accuracy=85.36% avg_sensitivity=87.81%, avg_specificity=84.45% avg_auc=93.29%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.588130 Test loss=0.341847 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.6012218594551086
[5/24] Train loss=0.6315905451774597
[10/24] Train loss=0.6060482263565063
[15/24] Train loss=0.5488511919975281
[20/24] Train loss=0.5475687384605408
Test set avg_accuracy=85.51% avg_sensitivity=87.76%, avg_specificity=84.67% avg_auc=93.30%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.590941 Test loss=0.340376 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.5867648124694824
[5/24] Train loss=0.6345125436782837
[10/24] Train loss=0.6196199059486389
[15/24] Train loss=0.5444210171699524
[20/24] Train loss=0.5610143542289734
Test set avg_accuracy=85.82% avg_sensitivity=87.00%, avg_specificity=85.38% avg_auc=93.30%
Best model saved!! Metric=25.499329524773657!!
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.591024 Test loss=0.332448 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.5959869623184204
[5/24] Train loss=0.6293596029281616
[10/24] Train loss=0.6104721426963806
[15/24] Train loss=0.5435798764228821
[20/24] Train loss=0.5544718503952026
Test set avg_accuracy=86.63% avg_sensitivity=85.51%, avg_specificity=87.04% avg_auc=93.28%
Best model saved!! Metric=26.462644173307012!!
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.590964 Test loss=0.321335 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.5888556838035583
[5/24] Train loss=0.6287944912910461
[10/24] Train loss=0.6241914629936218
[15/24] Train loss=0.5377670526504517
[20/24] Train loss=0.5610967874526978
Test set avg_accuracy=87.03% avg_sensitivity=84.79%, avg_specificity=87.87% avg_auc=93.27%
Best model saved!! Metric=26.95562667980556!!
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.586370 Test loss=0.315292 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.5745453834533691
[5/24] Train loss=0.6231986284255981
[10/24] Train loss=0.6356585621833801
[15/24] Train loss=0.5377739071846008
[20/24] Train loss=0.5488486289978027
Test set avg_accuracy=87.06% avg_sensitivity=85.08%, avg_specificity=87.79% avg_auc=93.27%
Best model saved!! Metric=27.198130886893892!!
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.587272 Test loss=0.316713 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.582288920879364
[5/24] Train loss=0.6338548064231873
[10/24] Train loss=0.6185478568077087
[15/24] Train loss=0.5411428809165955
[20/24] Train loss=0.5403769612312317
Test set avg_accuracy=86.55% avg_sensitivity=85.41%, avg_specificity=86.97% avg_auc=93.27%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.583969 Test loss=0.321522 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.5734862089157104
[5/24] Train loss=0.6351837515830994
[10/24] Train loss=0.6090971827507019
[15/24] Train loss=0.5465263724327087
[20/24] Train loss=0.545085608959198
Test set avg_accuracy=86.65% avg_sensitivity=85.41%, avg_specificity=87.12% avg_auc=93.28%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.583719 Test loss=0.320721 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.5757678151130676
[5/24] Train loss=0.6411288380622864
[10/24] Train loss=0.61424320936203
[15/24] Train loss=0.5410260558128357
[20/24] Train loss=0.5403562188148499
Test set avg_accuracy=86.64% avg_sensitivity=85.51%, avg_specificity=87.06% avg_auc=93.29%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.585467 Test loss=0.321147 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.5909730792045593
[5/24] Train loss=0.6352019309997559
[10/24] Train loss=0.6132320165634155
[15/24] Train loss=0.5359717607498169
[20/24] Train loss=0.5458435416221619
Test set avg_accuracy=86.60% avg_sensitivity=85.46%, avg_specificity=87.03% avg_auc=93.29%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.585079 Test loss=0.321161 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.581038236618042
[5/24] Train loss=0.6356908679008484
[10/24] Train loss=0.6093993186950684
[15/24] Train loss=0.5370370149612427
[20/24] Train loss=0.5305868983268738
Test set avg_accuracy=86.60% avg_sensitivity=85.51%, avg_specificity=87.01% avg_auc=93.29%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.582272 Test loss=0.321373 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.5931805968284607
[5/24] Train loss=0.6353690028190613
[10/24] Train loss=0.6207901239395142
[15/24] Train loss=0.5385152697563171
[20/24] Train loss=0.5307499170303345
Test set avg_accuracy=86.59% avg_sensitivity=85.51%, avg_specificity=86.99% avg_auc=93.29%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.584134 Test loss=0.321497 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.5880137085914612
[5/24] Train loss=0.6294184327125549
[10/24] Train loss=0.5965350866317749
[15/24] Train loss=0.5362705588340759
[20/24] Train loss=0.5370143055915833
Test set avg_accuracy=86.54% avg_sensitivity=85.56%, avg_specificity=86.90% avg_auc=93.29%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.582762 Test loss=0.322255 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.5824847221374512
[5/24] Train loss=0.6303312182426453
[10/24] Train loss=0.6041526198387146
[15/24] Train loss=0.54990154504776
[20/24] Train loss=0.5359742045402527
Test set avg_accuracy=86.56% avg_sensitivity=85.56%, avg_specificity=86.94% avg_auc=93.29%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.581994 Test loss=0.322017 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.5877864956855774
[5/24] Train loss=0.6227951645851135
[10/24] Train loss=0.6056331992149353
[15/24] Train loss=0.539008617401123
[20/24] Train loss=0.5402569770812988
Test set avg_accuracy=86.55% avg_sensitivity=85.56%, avg_specificity=86.92% avg_auc=93.29%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.582291 Test loss=0.322691 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.5810091495513916
[5/24] Train loss=0.6266301870346069
[10/24] Train loss=0.6059224605560303
[15/24] Train loss=0.5293324589729309
[20/24] Train loss=0.5434445738792419
Test set avg_accuracy=86.55% avg_sensitivity=85.56%, avg_specificity=86.92% avg_auc=93.29%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.584416 Test loss=0.322420 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.5935267806053162
[5/24] Train loss=0.6225792169570923
[10/24] Train loss=0.6177874207496643
[15/24] Train loss=0.5314556956291199
[20/24] Train loss=0.5376521348953247
Test set avg_accuracy=86.54% avg_sensitivity=85.56%, avg_specificity=86.90% avg_auc=93.29%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.584639 Test loss=0.322366 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.5839673280715942
[5/24] Train loss=0.6300415396690369
[10/24] Train loss=0.6171242594718933
[15/24] Train loss=0.5419877767562866
[20/24] Train loss=0.5444959402084351
Test set avg_accuracy=86.54% avg_sensitivity=85.56%, avg_specificity=86.90% avg_auc=93.29%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.583841 Test loss=0.322399 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.5756102204322815
[5/24] Train loss=0.6427246928215027
[10/24] Train loss=0.6137209534645081
[15/24] Train loss=0.5416481494903564
[20/24] Train loss=0.5348915457725525
Test set avg_accuracy=86.54% avg_sensitivity=85.56%, avg_specificity=86.90% avg_auc=93.30%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.581038 Test loss=0.322396 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.5829508900642395
[5/24] Train loss=0.6403089165687561
[10/24] Train loss=0.6142367124557495
[15/24] Train loss=0.5395960807800293
[20/24] Train loss=0.5375677943229675
Test set avg_accuracy=86.54% avg_sensitivity=85.56%, avg_specificity=86.90% avg_auc=93.30%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.584559 Test loss=0.322405 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=87.06% sen=85.08%, spe=87.79%, auc=93.27%!
Fold[6] Avg_overlap=0.65%(±0.2413894356802532)
[0/24] Train loss=1.811655879020691
[5/24] Train loss=1.584919810295105
[10/24] Train loss=1.4819997549057007
[15/24] Train loss=1.434509515762329
[20/24] Train loss=1.4251501560211182
Test set avg_accuracy=50.79% avg_sensitivity=60.68%, avg_specificity=47.02% avg_auc=55.94%
Best model saved!! Metric=-111.56767273902096!!
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=1.519043 Test loss=0.697599 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.4061623811721802
[5/24] Train loss=1.401082158088684
[10/24] Train loss=1.414710521697998
[15/24] Train loss=1.3930352926254272
[20/24] Train loss=1.3729090690612793
Test set avg_accuracy=63.42% avg_sensitivity=54.50%, avg_specificity=66.83% avg_auc=64.74%
Best model saved!! Metric=-76.50620771128794!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=1.394701 Test loss=0.666535 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.377864122390747
[5/24] Train loss=1.3709458112716675
[10/24] Train loss=1.3757652044296265
[15/24] Train loss=1.3441072702407837
[20/24] Train loss=1.362026333808899
Test set avg_accuracy=67.15% avg_sensitivity=61.39%, avg_specificity=69.35% avg_auc=70.24%
Best model saved!! Metric=-57.87396917363319!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=1.366529 Test loss=0.659576 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.3485647439956665
[5/24] Train loss=1.350190281867981
[10/24] Train loss=1.3517029285430908
[15/24] Train loss=1.325313925743103
[20/24] Train loss=1.3164777755737305
Test set avg_accuracy=71.67% avg_sensitivity=62.09%, avg_specificity=75.32% avg_auc=74.46%
Best model saved!! Metric=-42.46513009176177!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=1.340274 Test loss=0.643071 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.313289999961853
[5/24] Train loss=1.3254389762878418
[10/24] Train loss=1.338318943977356
[15/24] Train loss=1.2866290807724
[20/24] Train loss=1.2932274341583252
Test set avg_accuracy=72.46% avg_sensitivity=68.32%, avg_specificity=74.04% avg_auc=77.26%
Best model saved!! Metric=-33.91802245289145!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=1.314397 Test loss=0.635597 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.2914353609085083
[5/24] Train loss=1.283874750137329
[10/24] Train loss=1.2998523712158203
[15/24] Train loss=1.2637746334075928
[20/24] Train loss=1.2602547407150269
Test set avg_accuracy=74.27% avg_sensitivity=69.68%, avg_specificity=76.02% avg_auc=79.36%
Best model saved!! Metric=-26.664931386458377!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=1.285724 Test loss=0.618969 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.2566338777542114
[5/24] Train loss=1.2538613080978394
[10/24] Train loss=1.2833960056304932
[15/24] Train loss=1.2261086702346802
[20/24] Train loss=1.2277796268463135
Test set avg_accuracy=74.97% avg_sensitivity=71.81%, avg_specificity=76.18% avg_auc=80.85%
Best model saved!! Metric=-22.184500508464808!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=1.254028 Test loss=0.603420 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.2170377969741821
[5/24] Train loss=1.202520489692688
[10/24] Train loss=1.2505357265472412
[15/24] Train loss=1.1943535804748535
[20/24] Train loss=1.1850618124008179
Test set avg_accuracy=75.81% avg_sensitivity=73.31%, avg_specificity=76.76% avg_auc=82.08%
Best model saved!! Metric=-18.042444891292547!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=1.216648 Test loss=0.581936 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.1962641477584839
[5/24] Train loss=1.160503625869751
[10/24] Train loss=1.2014878988265991
[15/24] Train loss=1.1453585624694824
[20/24] Train loss=1.1318947076797485
Test set avg_accuracy=76.94% avg_sensitivity=73.55%, avg_specificity=78.23% avg_auc=83.25%
Best model saved!! Metric=-14.030963135114035!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=1.174345 Test loss=0.555305 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.1339349746704102
[5/24] Train loss=1.1045955419540405
[10/24] Train loss=1.1789454221725464
[15/24] Train loss=1.0884294509887695
[20/24] Train loss=1.0951985120773315
Test set avg_accuracy=77.46% avg_sensitivity=77.65%, avg_specificity=77.39% avg_auc=84.39%
Best model saved!! Metric=-9.107709373167765!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=1.129866 Test loss=0.542954 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.0939700603485107
[5/24] Train loss=1.0863265991210938
[10/24] Train loss=1.1473194360733032
[15/24] Train loss=1.0660278797149658
[20/24] Train loss=1.0440887212753296
Test set avg_accuracy=77.89% avg_sensitivity=79.07%, avg_specificity=77.44% avg_auc=85.06%
Best model saved!! Metric=-6.545329997858886!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=1.095046 Test loss=0.525927 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.0616660118103027
[5/24] Train loss=1.0455518960952759
[10/24] Train loss=1.105984091758728
[15/24] Train loss=1.026591420173645
[20/24] Train loss=1.0171393156051636
Test set avg_accuracy=77.12% avg_sensitivity=82.60%, avg_specificity=75.03% avg_auc=85.66%
Best model saved!! Metric=-5.587397418754193!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=1.057414 Test loss=0.524724 Current lr=[5.97283087248885e-05]

[0/24] Train loss=1.0434845685958862
[5/24] Train loss=1.0174778699874878
[10/24] Train loss=1.0710012912750244
[15/24] Train loss=0.9997173547744751
[20/24] Train loss=0.963438868522644
Test set avg_accuracy=77.25% avg_sensitivity=84.68%, avg_specificity=74.42% avg_auc=86.32%
Best model saved!! Metric=-3.3258330155759666!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=1.032706 Test loss=0.518194 Current lr=[6.744022406141468e-05]

[0/24] Train loss=1.009501576423645
[5/24] Train loss=0.9904129505157471
[10/24] Train loss=1.0780879259109497
[15/24] Train loss=0.9811208248138428
[20/24] Train loss=0.9443451166152954
Test set avg_accuracy=78.22% avg_sensitivity=83.97%, avg_specificity=76.02% avg_auc=87.14%
Best model saved!! Metric=-0.6537579946102028!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=1.007802 Test loss=0.492429 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.9678201675415039
[5/24] Train loss=0.9570081233978271
[10/24] Train loss=1.0317370891571045
[15/24] Train loss=0.9349030256271362
[20/24] Train loss=0.9118269085884094
Test set avg_accuracy=79.62% avg_sensitivity=82.13%, avg_specificity=78.67% avg_auc=87.89%
Best model saved!! Metric=2.3061482576082284!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.975878 Test loss=0.460611 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.9308111667633057
[5/24] Train loss=0.9342123866081238
[10/24] Train loss=1.0186140537261963
[15/24] Train loss=0.9152255654335022
[20/24] Train loss=0.8861468434333801
Test set avg_accuracy=79.58% avg_sensitivity=84.72%, avg_specificity=77.62% avg_auc=88.67%
Best model saved!! Metric=4.604232200646649!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.954193 Test loss=0.456922 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.9210867881774902
[5/24] Train loss=0.9152738451957703
[10/24] Train loss=0.9890410900115967
[15/24] Train loss=0.9043487906455994
[20/24] Train loss=0.8624905347824097
Test set avg_accuracy=80.10% avg_sensitivity=84.82%, avg_specificity=78.31% avg_auc=89.59%
Best model saved!! Metric=6.8225986362995314!!
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.937020 Test loss=0.441983 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.8959015607833862
[5/24] Train loss=0.8680635690689087
[10/24] Train loss=0.9763351678848267
[15/24] Train loss=0.9001726508140564
[20/24] Train loss=0.8182042837142944
Test set avg_accuracy=81.67% avg_sensitivity=84.25%, avg_specificity=80.68% avg_auc=90.31%
Best model saved!! Metric=10.905152892900887!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.915601 Test loss=0.416511 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.86357581615448
[5/24] Train loss=0.849260687828064
[10/24] Train loss=0.9571722149848938
[15/24] Train loss=0.8766956925392151
[20/24] Train loss=0.7956725358963013
Test set avg_accuracy=83.12% avg_sensitivity=82.65%, avg_specificity=83.31% avg_auc=90.88%
Best model saved!! Metric=13.958543966531408!!
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.894179 Test loss=0.388950 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.8299493789672852
[5/24] Train loss=0.8395677208900452
[10/24] Train loss=0.9263055920600891
[15/24] Train loss=0.8152691125869751
[20/24] Train loss=0.7835001349449158
Test set avg_accuracy=84.23% avg_sensitivity=79.59%, avg_specificity=86.00% avg_auc=91.22%
Best model saved!! Metric=15.038878573634776!!
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.873535 Test loss=0.365449 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.800839900970459
[5/24] Train loss=0.8282041549682617
[10/24] Train loss=0.9069377183914185
[15/24] Train loss=0.7912008166313171
[20/24] Train loss=0.7591230273246765
Test set avg_accuracy=84.79% avg_sensitivity=79.63%, avg_specificity=86.76% avg_auc=91.54%
Best model saved!! Metric=16.721325949764065!!
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.857219 Test loss=0.356267 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.8005450367927551
[5/24] Train loss=0.8290436267852783
[10/24] Train loss=0.8940614461898804
[15/24] Train loss=0.7786161303520203
[20/24] Train loss=0.7404575347900391
Test set avg_accuracy=84.79% avg_sensitivity=80.43%, avg_specificity=86.45% avg_auc=91.78%
Best model saved!! Metric=17.461188310065282!!
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.833693 Test loss=0.354116 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.7809298634529114
[5/24] Train loss=0.8206239342689514
[10/24] Train loss=0.8790472745895386
[15/24] Train loss=0.7671447396278381
[20/24] Train loss=0.7305253744125366
Test set avg_accuracy=84.90% avg_sensitivity=80.53%, avg_specificity=86.56% avg_auc=91.94%
Best model saved!! Metric=17.930937367983205!!
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.823624 Test loss=0.352487 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.7758777141571045
[5/24] Train loss=0.8255622386932373
[10/24] Train loss=0.8785166144371033
[15/24] Train loss=0.760956883430481
[20/24] Train loss=0.7345659732818604
Test set avg_accuracy=85.16% avg_sensitivity=80.25%, avg_specificity=87.03% avg_auc=92.16%
Best model saved!! Metric=18.589941422492032!!
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.812077 Test loss=0.345176 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.7630544900894165
[5/24] Train loss=0.8252277970314026
[10/24] Train loss=0.8662866353988647
[15/24] Train loss=0.7551434636116028
[20/24] Train loss=0.730112612247467
Test set avg_accuracy=84.73% avg_sensitivity=81.85%, avg_specificity=85.82% avg_auc=92.21%
Best model saved!! Metric=18.607439185309417!!
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.808383 Test loss=0.352341 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.7608846426010132
[5/24] Train loss=0.8213641047477722
[10/24] Train loss=0.8803796172142029
[15/24] Train loss=0.7654914259910583
[20/24] Train loss=0.699839174747467
Test set avg_accuracy=84.15% avg_sensitivity=84.35%, avg_specificity=84.08% avg_auc=92.19%
Best model saved!! Metric=18.773396806965863!!
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.803196 Test loss=0.362724 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.7533814907073975
[5/24] Train loss=0.804864764213562
[10/24] Train loss=0.8674862384796143
[15/24] Train loss=0.7740151882171631
[20/24] Train loss=0.7056460976600647
Test set avg_accuracy=83.24% avg_sensitivity=86.66%, avg_specificity=81.94% avg_auc=92.11%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.796646 Test loss=0.381015 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.7794778347015381
[5/24] Train loss=0.7679290175437927
[10/24] Train loss=0.8898231387138367
[15/24] Train loss=0.7718854546546936
[20/24] Train loss=0.6938451528549194
Test set avg_accuracy=83.40% avg_sensitivity=85.81%, avg_specificity=82.48% avg_auc=91.94%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.792857 Test loss=0.376446 Current lr=[0.000210185142098938]

[0/24] Train loss=0.7657029628753662
[5/24] Train loss=0.7826331257820129
[10/24] Train loss=0.8757985830307007
[15/24] Train loss=0.767753541469574
[20/24] Train loss=0.6813141107559204
Test set avg_accuracy=83.93% avg_sensitivity=85.81%, avg_specificity=83.22% avg_auc=92.64%
Best model saved!! Metric=19.596769732698547!!
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.786707 Test loss=0.363039 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.7434601187705994
[5/24] Train loss=0.7733976244926453
[10/24] Train loss=0.8477334976196289
[15/24] Train loss=0.7398734092712402
[20/24] Train loss=0.6826624870300293
Test set avg_accuracy=83.96% avg_sensitivity=86.19%, avg_specificity=83.11% avg_auc=92.43%
Best model saved!! Metric=19.682562189801587!!
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.773885 Test loss=0.368219 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.7567931413650513
[5/24] Train loss=0.781707763671875
[10/24] Train loss=0.8579587936401367
[15/24] Train loss=0.7316535115242004
[20/24] Train loss=0.6822599768638611
Test set avg_accuracy=83.87% avg_sensitivity=85.53%, avg_specificity=83.23% avg_auc=92.44%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.772409 Test loss=0.363039 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.742286741733551
[5/24] Train loss=0.7974918484687805
[10/24] Train loss=0.8573704957962036
[15/24] Train loss=0.7298672199249268
[20/24] Train loss=0.6806246638298035
Test set avg_accuracy=82.96% avg_sensitivity=86.99%, avg_specificity=81.42% avg_auc=92.23%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.769757 Test loss=0.381179 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.756538450717926
[5/24] Train loss=0.7602014541625977
[10/24] Train loss=0.862761914730072
[15/24] Train loss=0.7146995663642883
[20/24] Train loss=0.6621151566505432
Test set avg_accuracy=83.48% avg_sensitivity=87.32%, avg_specificity=82.01% avg_auc=92.77%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.759185 Test loss=0.370588 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.7422249913215637
[5/24] Train loss=0.7681002616882324
[10/24] Train loss=0.843299150466919
[15/24] Train loss=0.7139906883239746
[20/24] Train loss=0.6570286750793457
Test set avg_accuracy=82.90% avg_sensitivity=88.21%, avg_specificity=80.88% avg_auc=92.78%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.754301 Test loss=0.381168 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.7568597793579102
[5/24] Train loss=0.7643752098083496
[10/24] Train loss=0.8172547817230225
[15/24] Train loss=0.6918705105781555
[20/24] Train loss=0.6668814420700073
Test set avg_accuracy=83.58% avg_sensitivity=87.22%, avg_specificity=82.19% avg_auc=92.90%
Best model saved!! Metric=19.89495997298684!!
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.749539 Test loss=0.366025 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.7338358759880066
[5/24] Train loss=0.7891622185707092
[10/24] Train loss=0.8613693118095398
[15/24] Train loss=0.7081089615821838
[20/24] Train loss=0.6451424360275269
Test set avg_accuracy=82.75% avg_sensitivity=88.26%, avg_specificity=80.64% avg_auc=92.75%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.750638 Test loss=0.381254 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.7470297813415527
[5/24] Train loss=0.7582480907440186
[10/24] Train loss=0.8307411670684814
[15/24] Train loss=0.6830454468727112
[20/24] Train loss=0.6498081088066101
Test set avg_accuracy=83.84% avg_sensitivity=86.61%, avg_specificity=82.78% avg_auc=92.63%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.740316 Test loss=0.366183 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.7418833374977112
[5/24] Train loss=0.7587929368019104
[10/24] Train loss=0.8326511979103088
[15/24] Train loss=0.6998785734176636
[20/24] Train loss=0.6392024159431458
Test set avg_accuracy=84.05% avg_sensitivity=87.22%, avg_specificity=82.84% avg_auc=92.93%
Best model saved!! Metric=21.036489455082744!!
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.740800 Test loss=0.361284 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.7326329946517944
[5/24] Train loss=0.7457460761070251
[10/24] Train loss=0.8233705759048462
[15/24] Train loss=0.6842154264450073
[20/24] Train loss=0.6340171098709106
Test set avg_accuracy=83.12% avg_sensitivity=88.07%, avg_specificity=81.24% avg_auc=92.82%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.733590 Test loss=0.375628 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.7471453547477722
[5/24] Train loss=0.74399733543396
[10/24] Train loss=0.8195452690124512
[15/24] Train loss=0.6879302859306335
[20/24] Train loss=0.6539304256439209
Test set avg_accuracy=84.09% avg_sensitivity=87.55%, avg_specificity=82.77% avg_auc=92.96%
Best model saved!! Metric=21.36582460273145!!
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.731714 Test loss=0.362545 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.7303796410560608
[5/24] Train loss=0.7489711046218872
[10/24] Train loss=0.8311842679977417
[15/24] Train loss=0.6979675889015198
[20/24] Train loss=0.6302910447120667
Test set avg_accuracy=83.96% avg_sensitivity=87.51%, avg_specificity=82.60% avg_auc=93.06%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.731781 Test loss=0.362825 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.7109528183937073
[5/24] Train loss=0.7336675524711609
[10/24] Train loss=0.8161329030990601
[15/24] Train loss=0.6694468259811401
[20/24] Train loss=0.6200448870658875
Test set avg_accuracy=84.71% avg_sensitivity=86.70%, avg_specificity=83.95% avg_auc=93.22%
Best model saved!! Metric=22.590639421928287!!
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.724189 Test loss=0.349789 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.7068407535552979
[5/24] Train loss=0.7344326376914978
[10/24] Train loss=0.8187008500099182
[15/24] Train loss=0.6844329833984375
[20/24] Train loss=0.6141403913497925
Test set avg_accuracy=85.39% avg_sensitivity=85.62%, avg_specificity=85.30% avg_auc=93.19%
Best model saved!! Metric=23.506276407866864!!
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.722077 Test loss=0.340260 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.6993229389190674
[5/24] Train loss=0.7394218444824219
[10/24] Train loss=0.7932066321372986
[15/24] Train loss=0.6514440774917603
[20/24] Train loss=0.609428346157074
Test set avg_accuracy=85.95% avg_sensitivity=84.96%, avg_specificity=86.33% avg_auc=93.22%
Best model saved!! Metric=24.45569311449637!!
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.717505 Test loss=0.334137 Current lr=[0.00029967723776099]

[0/24] Train loss=0.7001315355300903
[5/24] Train loss=0.7523225545883179
[10/24] Train loss=0.7773463129997253
[15/24] Train loss=0.6476224660873413
[20/24] Train loss=0.6271030306816101
Test set avg_accuracy=86.00% avg_sensitivity=83.73%, avg_specificity=86.87% avg_auc=93.16%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.715463 Test loss=0.329220 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.6903359889984131
[5/24] Train loss=0.7769150137901306
[10/24] Train loss=0.7782823443412781
[15/24] Train loss=0.6556950211524963
[20/24] Train loss=0.6165042519569397
Test set avg_accuracy=86.11% avg_sensitivity=84.16%, avg_specificity=86.85% avg_auc=93.17%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.710877 Test loss=0.328931 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.6982088685035706
[5/24] Train loss=0.7660667896270752
[10/24] Train loss=0.7756428122520447
[15/24] Train loss=0.6439021229743958
[20/24] Train loss=0.6281666159629822
Test set avg_accuracy=86.05% avg_sensitivity=85.48%, avg_specificity=86.27% avg_auc=93.32%
Best model saved!! Metric=25.126546624853205!!
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.709068 Test loss=0.332293 Current lr=[0.000299720220882401]

[0/24] Train loss=0.6847739815711975
[5/24] Train loss=0.7615504264831543
[10/24] Train loss=0.765566349029541
[15/24] Train loss=0.6336566209793091
[20/24] Train loss=0.6192328333854675
Test set avg_accuracy=85.57% avg_sensitivity=86.28%, avg_specificity=85.30% avg_auc=93.25%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.704058 Test loss=0.339869 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.6978029012680054
[5/24] Train loss=0.7394198775291443
[10/24] Train loss=0.7714634537696838
[15/24] Train loss=0.6286210417747498
[20/24] Train loss=0.6003125905990601
Test set avg_accuracy=85.26% avg_sensitivity=86.61%, avg_specificity=84.75% avg_auc=93.06%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.700701 Test loss=0.350463 Current lr=[0.000298904600941902]

[0/24] Train loss=0.7036020159721375
[5/24] Train loss=0.7198439836502075
[10/24] Train loss=0.7674073576927185
[15/24] Train loss=0.6311705708503723
[20/24] Train loss=0.60435551404953
Test set avg_accuracy=85.94% avg_sensitivity=85.95%, avg_specificity=85.93% avg_auc=93.31%
Best model saved!! Metric=25.127384958737196!!
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.696972 Test loss=0.335889 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.690729022026062
[5/24] Train loss=0.724311351776123
[10/24] Train loss=0.7723549008369446
[15/24] Train loss=0.6386069059371948
[20/24] Train loss=0.6048098206520081
Test set avg_accuracy=85.53% avg_sensitivity=85.86%, avg_specificity=85.41% avg_auc=93.17%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.695929 Test loss=0.340586 Current lr=[0.000297555943323901]

[0/24] Train loss=0.692142903804779
[5/24] Train loss=0.7131227254867554
[10/24] Train loss=0.7829329371452332
[15/24] Train loss=0.6357923746109009
[20/24] Train loss=0.6067357659339905
Test set avg_accuracy=86.25% avg_sensitivity=84.35%, avg_specificity=86.98% avg_auc=93.38%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.693011 Test loss=0.324601 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.689933180809021
[5/24] Train loss=0.7536264657974243
[10/24] Train loss=0.7547367215156555
[15/24] Train loss=0.6306759119033813
[20/24] Train loss=0.6101925373077393
Test set avg_accuracy=85.21% avg_sensitivity=86.99%, avg_specificity=84.53% avg_auc=93.27%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.692564 Test loss=0.346115 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.7036071419715881
[5/24] Train loss=0.7014665603637695
[10/24] Train loss=0.7620135545730591
[15/24] Train loss=0.6222312450408936
[20/24] Train loss=0.6048535704612732
Test set avg_accuracy=85.29% avg_sensitivity=86.89%, avg_specificity=84.67% avg_auc=93.32%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.687180 Test loss=0.345370 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.6956964731216431
[5/24] Train loss=0.7096136212348938
[10/24] Train loss=0.7465758323669434
[15/24] Train loss=0.623622715473175
[20/24] Train loss=0.6090851426124573
Test set avg_accuracy=85.13% avg_sensitivity=86.61%, avg_specificity=84.57% avg_auc=93.27%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.684597 Test loss=0.346327 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.692296028137207
[5/24] Train loss=0.7079223990440369
[10/24] Train loss=0.7586039900779724
[15/24] Train loss=0.6242402791976929
[20/24] Train loss=0.6089114546775818
Test set avg_accuracy=84.71% avg_sensitivity=86.56%, avg_specificity=84.01% avg_auc=93.12%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.683637 Test loss=0.352427 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.7088285088539124
[5/24] Train loss=0.7037868499755859
[10/24] Train loss=0.7766501903533936
[15/24] Train loss=0.6243816614151001
[20/24] Train loss=0.5949018597602844
Test set avg_accuracy=85.12% avg_sensitivity=87.93%, avg_specificity=84.04% avg_auc=93.42%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.682983 Test loss=0.351914 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.7017225027084351
[5/24] Train loss=0.6987401843070984
[10/24] Train loss=0.7626587152481079
[15/24] Train loss=0.6232104301452637
[20/24] Train loss=0.5991014242172241
Test set avg_accuracy=85.13% avg_sensitivity=87.79%, avg_specificity=84.12% avg_auc=93.48%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.679465 Test loss=0.347046 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.6880951523780823
[5/24] Train loss=0.6878520250320435
[10/24] Train loss=0.7679459452629089
[15/24] Train loss=0.6192882657051086
[20/24] Train loss=0.5905649065971375
Test set avg_accuracy=85.74% avg_sensitivity=86.94%, avg_specificity=85.29% avg_auc=93.62%
Best model saved!! Metric=25.582664848174247!!
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.679074 Test loss=0.335138 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.681219756603241
[5/24] Train loss=0.6855280995368958
[10/24] Train loss=0.7496196031570435
[15/24] Train loss=0.6119111776351929
[20/24] Train loss=0.5996859669685364
Test set avg_accuracy=87.38% avg_sensitivity=83.45%, avg_specificity=88.88% avg_auc=93.71%
Best model saved!! Metric=27.42854589918217!!
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.678451 Test loss=0.309144 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.6535239219665527
[5/24] Train loss=0.7271412014961243
[10/24] Train loss=0.7300785183906555
[15/24] Train loss=0.6062995195388794
[20/24] Train loss=0.5995503067970276
Test set avg_accuracy=86.56% avg_sensitivity=85.24%, avg_specificity=87.07% avg_auc=93.64%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.672877 Test loss=0.321175 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.6619998216629028
[5/24] Train loss=0.68866366147995
[10/24] Train loss=0.7523797750473022
[15/24] Train loss=0.6167198419570923
[20/24] Train loss=0.5976680517196655
Test set avg_accuracy=86.71% avg_sensitivity=84.91%, avg_specificity=87.39% avg_auc=93.69%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.669828 Test loss=0.318631 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.6643084287643433
[5/24] Train loss=0.6868640184402466
[10/24] Train loss=0.7367041707038879
[15/24] Train loss=0.612411618232727
[20/24] Train loss=0.5863267183303833
Test set avg_accuracy=86.00% avg_sensitivity=86.47%, avg_specificity=85.82% avg_auc=93.65%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.668241 Test loss=0.330657 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.676310122013092
[5/24] Train loss=0.6778470277786255
[10/24] Train loss=0.73612380027771
[15/24] Train loss=0.5981453061103821
[20/24] Train loss=0.5929709076881409
Test set avg_accuracy=86.25% avg_sensitivity=85.81%, avg_specificity=86.42% avg_auc=93.63%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.665283 Test loss=0.327137 Current lr=[0.000276307469034998]

[0/24] Train loss=0.6733173727989197
[5/24] Train loss=0.6636391878128052
[10/24] Train loss=0.7359585165977478
[15/24] Train loss=0.6030195355415344
[20/24] Train loss=0.5845891833305359
Test set avg_accuracy=86.74% avg_sensitivity=85.10%, avg_specificity=87.37% avg_auc=93.74%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.661503 Test loss=0.317465 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.6584421992301941
[5/24] Train loss=0.6960932612419128
[10/24] Train loss=0.7326784133911133
[15/24] Train loss=0.5982629656791687
[20/24] Train loss=0.5790097713470459
Test set avg_accuracy=86.76% avg_sensitivity=85.43%, avg_specificity=87.26% avg_auc=93.72%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.662736 Test loss=0.319319 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.6659284830093384
[5/24] Train loss=0.6839331388473511
[10/24] Train loss=0.7184619903564453
[15/24] Train loss=0.6028422117233276
[20/24] Train loss=0.593534529209137
Test set avg_accuracy=86.88% avg_sensitivity=85.05%, avg_specificity=87.57% avg_auc=93.69%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.660853 Test loss=0.318548 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.6666750311851501
[5/24] Train loss=0.6778338551521301
[10/24] Train loss=0.7279062271118164
[15/24] Train loss=0.6059582829475403
[20/24] Train loss=0.5725210905075073
Test set avg_accuracy=86.38% avg_sensitivity=85.81%, avg_specificity=86.60% avg_auc=93.71%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.656377 Test loss=0.322938 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.6595346927642822
[5/24] Train loss=0.6841866374015808
[10/24] Train loss=0.7217135429382324
[15/24] Train loss=0.603929340839386
[20/24] Train loss=0.582475483417511
Test set avg_accuracy=86.60% avg_sensitivity=85.38%, avg_specificity=87.07% avg_auc=93.72%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.655363 Test loss=0.319497 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.662053644657135
[5/24] Train loss=0.6731542348861694
[10/24] Train loss=0.718056321144104
[15/24] Train loss=0.5955353379249573
[20/24] Train loss=0.5687011480331421
Test set avg_accuracy=86.08% avg_sensitivity=86.89%, avg_specificity=85.77% avg_auc=93.72%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.651997 Test loss=0.329498 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.6635358333587646
[5/24] Train loss=0.6725794076919556
[10/24] Train loss=0.7234756946563721
[15/24] Train loss=0.585956335067749
[20/24] Train loss=0.5871068239212036
Test set avg_accuracy=86.55% avg_sensitivity=86.14%, avg_specificity=86.71% avg_auc=93.77%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.653898 Test loss=0.321280 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.663295567035675
[5/24] Train loss=0.670828640460968
[10/24] Train loss=0.7218108177185059
[15/24] Train loss=0.5909019708633423
[20/24] Train loss=0.5623389482498169
Test set avg_accuracy=85.98% avg_sensitivity=87.27%, avg_specificity=85.48% avg_auc=93.75%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.652261 Test loss=0.330768 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.6604889035224915
[5/24] Train loss=0.67109614610672
[10/24] Train loss=0.7195655107498169
[15/24] Train loss=0.5962983965873718
[20/24] Train loss=0.5747870802879333
Test set avg_accuracy=86.89% avg_sensitivity=85.38%, avg_specificity=87.46% avg_auc=93.70%
Best model saved!! Metric=27.436407226980023!!
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.648745 Test loss=0.317977 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.6538833975791931
[5/24] Train loss=0.6803820729255676
[10/24] Train loss=0.722155749797821
[15/24] Train loss=0.5953903794288635
[20/24] Train loss=0.5741609930992126
Test set avg_accuracy=86.42% avg_sensitivity=86.85%, avg_specificity=86.26% avg_auc=93.77%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.648672 Test loss=0.323537 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.6600391864776611
[5/24] Train loss=0.6582463383674622
[10/24] Train loss=0.7105226516723633
[15/24] Train loss=0.587714672088623
[20/24] Train loss=0.5697493553161621
Test set avg_accuracy=86.64% avg_sensitivity=86.19%, avg_specificity=86.81% avg_auc=93.80%
Best model saved!! Metric=27.437004738197402!!
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.647813 Test loss=0.320439 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.6448129415512085
[5/24] Train loss=0.6738481521606445
[10/24] Train loss=0.7218145728111267
[15/24] Train loss=0.6029261946678162
[20/24] Train loss=0.563258707523346
Test set avg_accuracy=87.24% avg_sensitivity=84.72%, avg_specificity=88.20% avg_auc=93.77%
Best model saved!! Metric=27.930171519435902!!
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.648732 Test loss=0.310640 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.6434524655342102
[5/24] Train loss=0.6836015582084656
[10/24] Train loss=0.706611156463623
[15/24] Train loss=0.5952694416046143
[20/24] Train loss=0.5531036257743835
Test set avg_accuracy=87.75% avg_sensitivity=82.51%, avg_specificity=89.75% avg_auc=93.70%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.647544 Test loss=0.302042 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.6451054215431213
[5/24] Train loss=0.6942492723464966
[10/24] Train loss=0.6953203082084656
[15/24] Train loss=0.6187111735343933
[20/24] Train loss=0.555570125579834
Test set avg_accuracy=87.92% avg_sensitivity=77.75%, avg_specificity=91.80% avg_auc=93.52%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.649768 Test loss=0.293062 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.6493234634399414
[5/24] Train loss=0.6689294576644897
[10/24] Train loss=0.7178815603256226
[15/24] Train loss=0.6081788539886475
[20/24] Train loss=0.5700122714042664
Test set avg_accuracy=87.98% avg_sensitivity=82.46%, avg_specificity=90.09% avg_auc=93.78%
Best model saved!! Metric=28.306153252301485!!
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.648507 Test loss=0.297072 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.6411283016204834
[5/24] Train loss=0.6450523734092712
[10/24] Train loss=0.7030349373817444
[15/24] Train loss=0.5852080583572388
[20/24] Train loss=0.5693466663360596
Test set avg_accuracy=87.70% avg_sensitivity=82.93%, avg_specificity=89.51% avg_auc=93.70%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.641573 Test loss=0.301392 Current lr=[0.000224838296036774]

[0/24] Train loss=0.6405250430107117
[5/24] Train loss=0.6549201011657715
[10/24] Train loss=0.710139811038971
[15/24] Train loss=0.5893210768699646
[20/24] Train loss=0.568756103515625
Test set avg_accuracy=87.81% avg_sensitivity=80.76%, avg_specificity=90.50% avg_auc=93.68%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.638168 Test loss=0.295664 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.6482189893722534
[5/24] Train loss=0.6494849920272827
[10/24] Train loss=0.714457094669342
[15/24] Train loss=0.5754525065422058
[20/24] Train loss=0.5531312823295593
Test set avg_accuracy=87.79% avg_sensitivity=81.57%, avg_specificity=90.16% avg_auc=93.76%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.635720 Test loss=0.295878 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.6435286402702332
[5/24] Train loss=0.6496905088424683
[10/24] Train loss=0.7090746164321899
[15/24] Train loss=0.5882408618927002
[20/24] Train loss=0.5602516531944275
Test set avg_accuracy=87.86% avg_sensitivity=82.56%, avg_specificity=89.89% avg_auc=93.74%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.634165 Test loss=0.298396 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.6313062310218811
[5/24] Train loss=0.6369630098342896
[10/24] Train loss=0.7061311602592468
[15/24] Train loss=0.5873867273330688
[20/24] Train loss=0.5567708611488342
Test set avg_accuracy=87.94% avg_sensitivity=81.19%, avg_specificity=90.52% avg_auc=93.74%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.635430 Test loss=0.294702 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.6314441561698914
[5/24] Train loss=0.6435343623161316
[10/24] Train loss=0.6987677216529846
[15/24] Train loss=0.5835622549057007
[20/24] Train loss=0.5692890286445618
Test set avg_accuracy=87.72% avg_sensitivity=83.40%, avg_specificity=89.37% avg_auc=93.74%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.633127 Test loss=0.303133 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.6303561329841614
[5/24] Train loss=0.6333138942718506
[10/24] Train loss=0.6914534568786621
[15/24] Train loss=0.5686824321746826
[20/24] Train loss=0.5481905341148376
Test set avg_accuracy=87.86% avg_sensitivity=82.60%, avg_specificity=89.87% avg_auc=93.68%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.627097 Test loss=0.301270 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.6317533850669861
[5/24] Train loss=0.6319051384925842
[10/24] Train loss=0.7170655727386475
[15/24] Train loss=0.5878604054450989
[20/24] Train loss=0.5419222712516785
Test set avg_accuracy=87.88% avg_sensitivity=82.18%, avg_specificity=90.05% avg_auc=93.70%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.626067 Test loss=0.298862 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.6334342360496521
[5/24] Train loss=0.6316406726837158
[10/24] Train loss=0.6957474946975708
[15/24] Train loss=0.5818741917610168
[20/24] Train loss=0.5566943883895874
Test set avg_accuracy=87.85% avg_sensitivity=82.08%, avg_specificity=90.05% avg_auc=93.73%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.624564 Test loss=0.298257 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.6250227689743042
[5/24] Train loss=0.6254927515983582
[10/24] Train loss=0.6921298503875732
[15/24] Train loss=0.5748724937438965
[20/24] Train loss=0.5444970726966858
Test set avg_accuracy=87.75% avg_sensitivity=82.56%, avg_specificity=89.73% avg_auc=93.69%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.622711 Test loss=0.299914 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.6334827542304993
[5/24] Train loss=0.636059582233429
[10/24] Train loss=0.6827260255813599
[15/24] Train loss=0.5768644213676453
[20/24] Train loss=0.5586467981338501
Test set avg_accuracy=87.92% avg_sensitivity=81.52%, avg_specificity=90.36% avg_auc=93.72%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.620784 Test loss=0.295371 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.6300708055496216
[5/24] Train loss=0.6140305995941162
[10/24] Train loss=0.6909444332122803
[15/24] Train loss=0.5782905220985413
[20/24] Train loss=0.5464270114898682
Test set avg_accuracy=87.59% avg_sensitivity=83.78%, avg_specificity=89.04% avg_auc=93.74%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.619856 Test loss=0.303109 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.6286857724189758
[5/24] Train loss=0.6195486187934875
[10/24] Train loss=0.6958175301551819
[15/24] Train loss=0.5658572912216187
[20/24] Train loss=0.5488235950469971
Test set avg_accuracy=87.84% avg_sensitivity=82.84%, avg_specificity=89.75% avg_auc=93.76%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.618617 Test loss=0.299249 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.6229408979415894
[5/24] Train loss=0.625469446182251
[10/24] Train loss=0.6761518120765686
[15/24] Train loss=0.5828052759170532
[20/24] Train loss=0.5495375990867615
Test set avg_accuracy=87.75% avg_sensitivity=82.89%, avg_specificity=89.60% avg_auc=93.71%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.618220 Test loss=0.300611 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.6090102195739746
[5/24] Train loss=0.6294786334037781
[10/24] Train loss=0.6815791130065918
[15/24] Train loss=0.571280300617218
[20/24] Train loss=0.5433830618858337
Test set avg_accuracy=87.53% avg_sensitivity=83.92%, avg_specificity=88.90% avg_auc=93.78%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.620607 Test loss=0.303620 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.6260114312171936
[5/24] Train loss=0.6175514459609985
[10/24] Train loss=0.6765434741973877
[15/24] Train loss=0.5799359679222107
[20/24] Train loss=0.551011860370636
Test set avg_accuracy=87.30% avg_sensitivity=84.82%, avg_specificity=88.25% avg_auc=93.78%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.619238 Test loss=0.308809 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.6195395588874817
[5/24] Train loss=0.6306793689727783
[10/24] Train loss=0.6876775026321411
[15/24] Train loss=0.5944346785545349
[20/24] Train loss=0.5619470477104187
Test set avg_accuracy=85.68% avg_sensitivity=88.35%, avg_specificity=84.66% avg_auc=93.80%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.625273 Test loss=0.338057 Current lr=[0.000156543481933168]

[0/24] Train loss=0.6480700373649597
[5/24] Train loss=0.6256360411643982
[10/24] Train loss=0.6783003211021423
[15/24] Train loss=0.591276228427887
[20/24] Train loss=0.5835636258125305
Test set avg_accuracy=84.45% avg_sensitivity=89.20%, avg_specificity=82.64% avg_auc=93.75%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.624669 Test loss=0.355755 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.6785737872123718
[5/24] Train loss=0.6674108505249023
[10/24] Train loss=0.6912906765937805
[15/24] Train loss=0.5808413028717041
[20/24] Train loss=0.5623442530632019
Test set avg_accuracy=86.59% avg_sensitivity=87.36%, avg_specificity=86.29% avg_auc=93.94%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.623260 Test loss=0.322704 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.627841591835022
[5/24] Train loss=0.6411893963813782
[10/24] Train loss=0.6935299634933472
[15/24] Train loss=0.5739004611968994
[20/24] Train loss=0.5461490154266357
Test set avg_accuracy=86.97% avg_sensitivity=86.80%, avg_specificity=87.03% avg_auc=93.95%
Best model saved!! Metric=28.744083907766765!!
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.614860 Test loss=0.317176 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.6252953410148621
[5/24] Train loss=0.621768057346344
[10/24] Train loss=0.6783593893051147
[15/24] Train loss=0.5669030547142029
[20/24] Train loss=0.5614422559738159
Test set avg_accuracy=86.38% avg_sensitivity=87.93%, avg_specificity=85.79% avg_auc=93.94%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.611521 Test loss=0.326091 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.6489893794059753
[5/24] Train loss=0.6326534748077393
[10/24] Train loss=0.6749050617218018
[15/24] Train loss=0.5749595761299133
[20/24] Train loss=0.5590670108795166
Test set avg_accuracy=86.29% avg_sensitivity=88.26%, avg_specificity=85.54% avg_auc=93.96%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.612636 Test loss=0.327934 Current lr=[0.000134135431043539]

[0/24] Train loss=0.626928985118866
[5/24] Train loss=0.6331643462181091
[10/24] Train loss=0.6815941333770752
[15/24] Train loss=0.5734128355979919
[20/24] Train loss=0.5487987995147705
Test set avg_accuracy=86.61% avg_sensitivity=87.60%, avg_specificity=86.24% avg_auc=93.96%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.607469 Test loss=0.321722 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.6248332262039185
[5/24] Train loss=0.621486246585846
[10/24] Train loss=0.6716077327728271
[15/24] Train loss=0.5598121881484985
[20/24] Train loss=0.546948254108429
Test set avg_accuracy=87.10% avg_sensitivity=87.18%, avg_specificity=87.07% avg_auc=93.98%
Best model saved!! Metric=29.316999375123984!!
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.602474 Test loss=0.315540 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.6238065361976624
[5/24] Train loss=0.6211269497871399
[10/24] Train loss=0.6750679016113281
[15/24] Train loss=0.5547931790351868
[20/24] Train loss=0.5522316098213196
Test set avg_accuracy=86.91% avg_sensitivity=87.51%, avg_specificity=86.69% avg_auc=93.98%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.601857 Test loss=0.319637 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.6197746396064758
[5/24] Train loss=0.6173153519630432
[10/24] Train loss=0.6764726638793945
[15/24] Train loss=0.5530587434768677
[20/24] Train loss=0.5412850379943848
Test set avg_accuracy=87.16% avg_sensitivity=86.99%, avg_specificity=87.23% avg_auc=94.00%
Best model saved!! Metric=29.378698298020566!!
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.600473 Test loss=0.313890 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.6242387890815735
[5/24] Train loss=0.6155021786689758
[10/24] Train loss=0.6773779392242432
[15/24] Train loss=0.5523107647895813
[20/24] Train loss=0.537846028804779
Test set avg_accuracy=86.89% avg_sensitivity=87.41%, avg_specificity=86.69% avg_auc=93.98%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.598543 Test loss=0.319067 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.6213791370391846
[5/24] Train loss=0.6160390973091125
[10/24] Train loss=0.6731191277503967
[15/24] Train loss=0.5513507723808289
[20/24] Train loss=0.5401386618614197
Test set avg_accuracy=86.85% avg_sensitivity=87.41%, avg_specificity=86.63% avg_auc=94.01%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.597742 Test loss=0.318595 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.6258639097213745
[5/24] Train loss=0.6238868832588196
[10/24] Train loss=0.6870741248130798
[15/24] Train loss=0.547367513179779
[20/24] Train loss=0.5481772422790527
Test set avg_accuracy=86.94% avg_sensitivity=87.41%, avg_specificity=86.76% avg_auc=94.00%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.598247 Test loss=0.317852 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.6172896027565002
[5/24] Train loss=0.62844318151474
[10/24] Train loss=0.6715606451034546
[15/24] Train loss=0.5541489720344543
[20/24] Train loss=0.5316661596298218
Test set avg_accuracy=86.97% avg_sensitivity=87.60%, avg_specificity=86.72% avg_auc=94.01%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.596639 Test loss=0.318816 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.6076104044914246
[5/24] Train loss=0.6065410375595093
[10/24] Train loss=0.6718816757202148
[15/24] Train loss=0.5487097501754761
[20/24] Train loss=0.5455278158187866
Test set avg_accuracy=86.85% avg_sensitivity=87.93%, avg_specificity=86.44% avg_auc=94.02%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.594341 Test loss=0.319877 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.6194432973861694
[5/24] Train loss=0.6166447401046753
[10/24] Train loss=0.6606584787368774
[15/24] Train loss=0.5517051815986633
[20/24] Train loss=0.543197512626648
Test set avg_accuracy=86.50% avg_sensitivity=87.84%, avg_specificity=85.99% avg_auc=94.02%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.597069 Test loss=0.323656 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.6224315166473389
[5/24] Train loss=0.6158584952354431
[10/24] Train loss=0.6757344007492065
[15/24] Train loss=0.551001787185669
[20/24] Train loss=0.5195276737213135
Test set avg_accuracy=86.59% avg_sensitivity=88.35%, avg_specificity=85.91% avg_auc=94.03%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.595831 Test loss=0.324506 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.6297396421432495
[5/24] Train loss=0.6200026869773865
[10/24] Train loss=0.6705487370491028
[15/24] Train loss=0.5413995385169983
[20/24] Train loss=0.5458033680915833
Test set avg_accuracy=85.90% avg_sensitivity=89.20%, avg_specificity=84.64% avg_auc=94.04%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.595007 Test loss=0.335718 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.6365074515342712
[5/24] Train loss=0.6364635825157166
[10/24] Train loss=0.6756381988525391
[15/24] Train loss=0.5526390075683594
[20/24] Train loss=0.5487537384033203
Test set avg_accuracy=85.17% avg_sensitivity=89.77%, avg_specificity=83.41% avg_auc=94.04%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.598878 Test loss=0.346689 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.6387678980827332
[5/24] Train loss=0.6362040638923645
[10/24] Train loss=0.6667889356613159
[15/24] Train loss=0.5577007532119751
[20/24] Train loss=0.5630590319633484
Test set avg_accuracy=84.70% avg_sensitivity=90.62%, avg_specificity=82.44% avg_auc=94.06%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.601261 Test loss=0.354301 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.649155855178833
[5/24] Train loss=0.6051490902900696
[10/24] Train loss=0.6687936782836914
[15/24] Train loss=0.581689178943634
[20/24] Train loss=0.582249104976654
Test set avg_accuracy=86.50% avg_sensitivity=87.93%, avg_specificity=85.95% avg_auc=94.02%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.607574 Test loss=0.323596 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.6168237328529358
[5/24] Train loss=0.5851296186447144
[10/24] Train loss=0.6688306331634521
[15/24] Train loss=0.5751965045928955
[20/24] Train loss=0.5564754605293274
Test set avg_accuracy=87.21% avg_sensitivity=85.76%, avg_specificity=87.77% avg_auc=93.94%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.597328 Test loss=0.308780 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.6099296808242798
[5/24] Train loss=0.5921674370765686
[10/24] Train loss=0.6606684923171997
[15/24] Train loss=0.549092710018158
[20/24] Train loss=0.5476095080375671
Test set avg_accuracy=87.08% avg_sensitivity=86.33%, avg_specificity=87.37% avg_auc=93.94%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.587889 Test loss=0.311412 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.6133021116256714
[5/24] Train loss=0.5853612422943115
[10/24] Train loss=0.6733144521713257
[15/24] Train loss=0.5548303127288818
[20/24] Train loss=0.5449647307395935
Test set avg_accuracy=87.16% avg_sensitivity=86.14%, avg_specificity=87.55% avg_auc=93.96%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.587209 Test loss=0.311013 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.6095306873321533
[5/24] Train loss=0.5831528306007385
[10/24] Train loss=0.643868088722229
[15/24] Train loss=0.5517692565917969
[20/24] Train loss=0.5356681942939758
Test set avg_accuracy=87.16% avg_sensitivity=86.47%, avg_specificity=87.43% avg_auc=94.00%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.584583 Test loss=0.311191 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.5927395224571228
[5/24] Train loss=0.5948241949081421
[10/24] Train loss=0.6515050530433655
[15/24] Train loss=0.5437437295913696
[20/24] Train loss=0.5445883870124817
Test set avg_accuracy=87.06% avg_sensitivity=86.23%, avg_specificity=87.37% avg_auc=93.98%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.584737 Test loss=0.313001 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.5971013903617859
[5/24] Train loss=0.5849866271018982
[10/24] Train loss=0.6544619202613831
[15/24] Train loss=0.5529155731201172
[20/24] Train loss=0.5433056354522705
Test set avg_accuracy=87.15% avg_sensitivity=86.14%, avg_specificity=87.53% avg_auc=93.98%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.582971 Test loss=0.310529 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.5947465300559998
[5/24] Train loss=0.5818120837211609
[10/24] Train loss=0.6442053914070129
[15/24] Train loss=0.5481747984886169
[20/24] Train loss=0.5304585099220276
Test set avg_accuracy=87.36% avg_sensitivity=86.00%, avg_specificity=87.88% avg_auc=93.98%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.581312 Test loss=0.308196 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.5969797968864441
[5/24] Train loss=0.578615128993988
[10/24] Train loss=0.641056478023529
[15/24] Train loss=0.5441378355026245
[20/24] Train loss=0.5260903835296631
Test set avg_accuracy=87.19% avg_sensitivity=86.14%, avg_specificity=87.59% avg_auc=93.97%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.578723 Test loss=0.310773 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.5971047878265381
[5/24] Train loss=0.5755714774131775
[10/24] Train loss=0.6545708179473877
[15/24] Train loss=0.5459263920783997
[20/24] Train loss=0.526032030582428
Test set avg_accuracy=87.21% avg_sensitivity=86.28%, avg_specificity=87.57% avg_auc=93.96%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.579886 Test loss=0.311011 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.5872310996055603
[5/24] Train loss=0.5778615474700928
[10/24] Train loss=0.6476921439170837
[15/24] Train loss=0.5480291247367859
[20/24] Train loss=0.5319129824638367
Test set avg_accuracy=87.15% avg_sensitivity=86.04%, avg_specificity=87.57% avg_auc=93.97%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.577974 Test loss=0.310895 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.595035195350647
[5/24] Train loss=0.580518901348114
[10/24] Train loss=0.6364197731018066
[15/24] Train loss=0.5356974005699158
[20/24] Train loss=0.5398256182670593
Test set avg_accuracy=87.14% avg_sensitivity=86.28%, avg_specificity=87.46% avg_auc=93.99%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.577399 Test loss=0.311539 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.5895867347717285
[5/24] Train loss=0.5667213797569275
[10/24] Train loss=0.6402202844619751
[15/24] Train loss=0.5497695803642273
[20/24] Train loss=0.5280691385269165
Test set avg_accuracy=87.12% avg_sensitivity=86.19%, avg_specificity=87.48% avg_auc=93.98%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.575943 Test loss=0.311625 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.5993753671646118
[5/24] Train loss=0.5844586491584778
[10/24] Train loss=0.6425623893737793
[15/24] Train loss=0.5420680046081543
[20/24] Train loss=0.5328494906425476
Test set avg_accuracy=86.99% avg_sensitivity=86.52%, avg_specificity=87.17% avg_auc=93.98%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.577915 Test loss=0.314378 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.6035706996917725
[5/24] Train loss=0.5733368992805481
[10/24] Train loss=0.6522055864334106
[15/24] Train loss=0.5405815243721008
[20/24] Train loss=0.5214210748672485
Test set avg_accuracy=87.01% avg_sensitivity=86.28%, avg_specificity=87.28% avg_auc=93.99%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.576295 Test loss=0.312965 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.6037976145744324
[5/24] Train loss=0.5778497457504272
[10/24] Train loss=0.6494913101196289
[15/24] Train loss=0.535121500492096
[20/24] Train loss=0.5229113698005676
Test set avg_accuracy=86.88% avg_sensitivity=86.80%, avg_specificity=86.90% avg_auc=93.99%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.575595 Test loss=0.316354 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.5893144011497498
[5/24] Train loss=0.5733271837234497
[10/24] Train loss=0.6326287388801575
[15/24] Train loss=0.5280749797821045
[20/24] Train loss=0.5234972238540649
Test set avg_accuracy=86.80% avg_sensitivity=86.99%, avg_specificity=86.72% avg_auc=93.97%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.575371 Test loss=0.317546 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.5966801047325134
[5/24] Train loss=0.5768885612487793
[10/24] Train loss=0.6545335650444031
[15/24] Train loss=0.5463831424713135
[20/24] Train loss=0.5399090051651001
Test set avg_accuracy=86.80% avg_sensitivity=86.99%, avg_specificity=86.72% avg_auc=93.95%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.578185 Test loss=0.317667 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.6093297004699707
[5/24] Train loss=0.5772273540496826
[10/24] Train loss=0.6400948166847229
[15/24] Train loss=0.5324813723564148
[20/24] Train loss=0.5361902117729187
Test set avg_accuracy=86.99% avg_sensitivity=86.47%, avg_specificity=87.19% avg_auc=93.92%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.576828 Test loss=0.314028 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.5990636348724365
[5/24] Train loss=0.5736390948295593
[10/24] Train loss=0.6534518003463745
[15/24] Train loss=0.5347011685371399
[20/24] Train loss=0.5382903218269348
Test set avg_accuracy=87.12% avg_sensitivity=85.43%, avg_specificity=87.77% avg_auc=93.84%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.579531 Test loss=0.309246 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.5935896039009094
[5/24] Train loss=0.5760288834571838
[10/24] Train loss=0.6550981998443604
[15/24] Train loss=0.5329224467277527
[20/24] Train loss=0.5387741327285767
Test set avg_accuracy=87.30% avg_sensitivity=84.49%, avg_specificity=88.38% avg_auc=93.84%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.578180 Test loss=0.304069 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.5947428941726685
[5/24] Train loss=0.570904552936554
[10/24] Train loss=0.6473852396011353
[15/24] Train loss=0.5310148596763611
[20/24] Train loss=0.5322251319885254
Test set avg_accuracy=87.51% avg_sensitivity=84.63%, avg_specificity=88.61% avg_auc=93.89%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.575427 Test loss=0.302441 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.5972277522087097
[5/24] Train loss=0.5758504271507263
[10/24] Train loss=0.6449765563011169
[15/24] Train loss=0.5357110500335693
[20/24] Train loss=0.5302541255950928
Test set avg_accuracy=87.57% avg_sensitivity=85.01%, avg_specificity=88.54% avg_auc=93.93%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.572926 Test loss=0.303101 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.5832064151763916
[5/24] Train loss=0.5625823140144348
[10/24] Train loss=0.6445368528366089
[15/24] Train loss=0.5381177663803101
[20/24] Train loss=0.5294071435928345
Test set avg_accuracy=87.59% avg_sensitivity=85.34%, avg_specificity=88.45% avg_auc=93.92%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.571525 Test loss=0.304751 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.6086546778678894
[5/24] Train loss=0.5563000440597534
[10/24] Train loss=0.6390949487686157
[15/24] Train loss=0.5360038876533508
[20/24] Train loss=0.5189265012741089
Test set avg_accuracy=87.63% avg_sensitivity=85.20%, avg_specificity=88.56% avg_auc=93.92%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.573678 Test loss=0.303480 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.5879938006401062
[5/24] Train loss=0.5629738569259644
[10/24] Train loss=0.6499163508415222
[15/24] Train loss=0.5421901345252991
[20/24] Train loss=0.5210219621658325
Test set avg_accuracy=87.50% avg_sensitivity=85.34%, avg_specificity=88.33% avg_auc=93.93%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.574077 Test loss=0.304574 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.5860776305198669
[5/24] Train loss=0.5694641470909119
[10/24] Train loss=0.643644392490387
[15/24] Train loss=0.5266125798225403
[20/24] Train loss=0.5332468152046204
Test set avg_accuracy=87.53% avg_sensitivity=85.29%, avg_specificity=88.38% avg_auc=93.93%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.573202 Test loss=0.304611 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.5943024158477783
[5/24] Train loss=0.5604583024978638
[10/24] Train loss=0.6511867642402649
[15/24] Train loss=0.5427076816558838
[20/24] Train loss=0.5263245701789856
Test set avg_accuracy=87.57% avg_sensitivity=85.20%, avg_specificity=88.47% avg_auc=93.93%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.571603 Test loss=0.303744 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.5926613211631775
[5/24] Train loss=0.5676895380020142
[10/24] Train loss=0.6333730816841125
[15/24] Train loss=0.5326668620109558
[20/24] Train loss=0.5179883241653442
Test set avg_accuracy=87.50% avg_sensitivity=85.24%, avg_specificity=88.36% avg_auc=93.93%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.569771 Test loss=0.304297 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.58844393491745
[5/24] Train loss=0.5733415484428406
[10/24] Train loss=0.6416279673576355
[15/24] Train loss=0.5393385887145996
[20/24] Train loss=0.5297155380249023
Test set avg_accuracy=87.54% avg_sensitivity=85.38%, avg_specificity=88.36% avg_auc=93.93%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.571696 Test loss=0.304404 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.5971585512161255
[5/24] Train loss=0.5784065127372742
[10/24] Train loss=0.6348934769630432
[15/24] Train loss=0.5305373668670654
[20/24] Train loss=0.5107172131538391
Test set avg_accuracy=87.49% avg_sensitivity=85.43%, avg_specificity=88.27% avg_auc=93.93%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.572114 Test loss=0.304906 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.5891423225402832
[5/24] Train loss=0.5680738091468811
[10/24] Train loss=0.6471928954124451
[15/24] Train loss=0.5264976620674133
[20/24] Train loss=0.5286303758621216
Test set avg_accuracy=87.50% avg_sensitivity=85.34%, avg_specificity=88.33% avg_auc=93.93%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.571422 Test loss=0.304546 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.5963261127471924
[5/24] Train loss=0.5695757865905762
[10/24] Train loss=0.6377006769180298
[15/24] Train loss=0.5327125191688538
[20/24] Train loss=0.516211748123169
Test set avg_accuracy=87.50% avg_sensitivity=85.34%, avg_specificity=88.33% avg_auc=93.93%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.571068 Test loss=0.304565 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.5794661641120911
[5/24] Train loss=0.5559614300727844
[10/24] Train loss=0.6437703967094421
[15/24] Train loss=0.5443145036697388
[20/24] Train loss=0.5252254605293274
Test set avg_accuracy=87.50% avg_sensitivity=85.34%, avg_specificity=88.33% avg_auc=93.93%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.569821 Test loss=0.304623 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.592327356338501
[5/24] Train loss=0.5814391374588013
[10/24] Train loss=0.6516954898834229
[15/24] Train loss=0.530734658241272
[20/24] Train loss=0.5262819528579712
Test set avg_accuracy=87.50% avg_sensitivity=85.34%, avg_specificity=88.33% avg_auc=93.93%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.572920 Test loss=0.304625 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=87.16% sen=86.99%, spe=87.23%, auc=94.00%!
Fold[7] Avg_overlap=0.66%(±0.21941255809835988)
[0/24] Train loss=1.7851529121398926
[5/24] Train loss=1.568650722503662
[10/24] Train loss=1.4916986227035522
[15/24] Train loss=1.455803632736206
[20/24] Train loss=1.437233328819275
Test set avg_accuracy=58.37% avg_sensitivity=45.05%, avg_specificity=62.85% avg_auc=53.75%
Best model saved!! Metric=-105.98228075960125!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=1.516346 Test loss=0.679442 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.421515703201294
[5/24] Train loss=1.4308829307556152
[10/24] Train loss=1.424587607383728
[15/24] Train loss=1.3941619396209717
[20/24] Train loss=1.3981349468231201
Test set avg_accuracy=54.70% avg_sensitivity=63.28%, avg_specificity=51.82% avg_auc=60.76%
Best model saved!! Metric=-95.43703885664586!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=1.412492 Test loss=0.688164 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.4010233879089355
[5/24] Train loss=1.3887500762939453
[10/24] Train loss=1.4013097286224365
[15/24] Train loss=1.3744438886642456
[20/24] Train loss=1.3635237216949463
Test set avg_accuracy=59.83% avg_sensitivity=60.49%, avg_specificity=59.61% avg_auc=64.17%
Best model saved!! Metric=-81.9027030498114!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=1.385993 Test loss=0.672640 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.373665452003479
[5/24] Train loss=1.3556158542633057
[10/24] Train loss=1.3787031173706055
[15/24] Train loss=1.3537780046463013
[20/24] Train loss=1.3369606733322144
Test set avg_accuracy=63.97% avg_sensitivity=63.39%, avg_specificity=64.17% avg_auc=68.78%
Best model saved!! Metric=-65.68951261862254!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=1.361302 Test loss=0.663772 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.355761170387268
[5/24] Train loss=1.3101344108581543
[10/24] Train loss=1.3380577564239502
[15/24] Train loss=1.3263083696365356
[20/24] Train loss=1.3175158500671387
Test set avg_accuracy=66.37% avg_sensitivity=65.92%, avg_specificity=66.52% avg_auc=72.10%
Best model saved!! Metric=-55.094572494465524!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=1.334148 Test loss=0.651294 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.308186650276184
[5/24] Train loss=1.2878296375274658
[10/24] Train loss=1.3169658184051514
[15/24] Train loss=1.2868400812149048
[20/24] Train loss=1.276343822479248
Test set avg_accuracy=68.22% avg_sensitivity=71.83%, avg_specificity=67.00% avg_auc=75.51%
Best model saved!! Metric=-43.44125667892669!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=1.301044 Test loss=0.638830 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.2783257961273193
[5/24] Train loss=1.2446088790893555
[10/24] Train loss=1.2766622304916382
[15/24] Train loss=1.2551809549331665
[20/24] Train loss=1.233137845993042
Test set avg_accuracy=69.93% avg_sensitivity=74.37%, avg_specificity=68.45% avg_auc=77.67%
Best model saved!! Metric=-35.58303802659809!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=1.266806 Test loss=0.623658 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.236276388168335
[5/24] Train loss=1.1929395198822021
[10/24] Train loss=1.2558541297912598
[15/24] Train loss=1.1971089839935303
[20/24] Train loss=1.1950539350509644
Test set avg_accuracy=70.51% avg_sensitivity=76.75%, avg_specificity=68.41% avg_auc=79.31%
Best model saved!! Metric=-31.02692350749605!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=1.224188 Test loss=0.609345 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.1936684846878052
[5/24] Train loss=1.1602563858032227
[10/24] Train loss=1.2018041610717773
[15/24] Train loss=1.1491018533706665
[20/24] Train loss=1.1235857009887695
Test set avg_accuracy=72.64% avg_sensitivity=75.09%, avg_specificity=71.82% avg_auc=80.46%
Best model saved!! Metric=-25.98319027051913!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=1.178929 Test loss=0.579638 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.1312404870986938
[5/24] Train loss=1.1032404899597168
[10/24] Train loss=1.1690768003463745
[15/24] Train loss=1.0925583839416504
[20/24] Train loss=1.0861256122589111
Test set avg_accuracy=73.05% avg_sensitivity=79.03%, avg_specificity=71.04% avg_auc=81.72%
Best model saved!! Metric=-21.167397556261093!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=1.130410 Test loss=0.567197 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.0805342197418213
[5/24] Train loss=1.0442979335784912
[10/24] Train loss=1.1384375095367432
[15/24] Train loss=1.0436064004898071
[20/24] Train loss=1.029387354850769
Test set avg_accuracy=73.85% avg_sensitivity=80.17%, avg_specificity=71.73% avg_auc=82.96%
Best model saved!! Metric=-17.29079043257532!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=1.084123 Test loss=0.546512 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.0212104320526123
[5/24] Train loss=1.000441074371338
[10/24] Train loss=1.0903161764144897
[15/24] Train loss=1.0016636848449707
[20/24] Train loss=0.981848955154419
Test set avg_accuracy=73.72% avg_sensitivity=83.79%, avg_specificity=70.34% avg_auc=84.22%
Best model saved!! Metric=-13.920815589477101!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=1.041311 Test loss=0.542104 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.9985377788543701
[5/24] Train loss=0.9944790601730347
[10/24] Train loss=1.0565648078918457
[15/24] Train loss=0.9582197070121765
[20/24] Train loss=0.9558190107345581
Test set avg_accuracy=74.40% avg_sensitivity=84.62%, avg_specificity=70.97% avg_auc=85.26%
Best model saved!! Metric=-10.745902944149407!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=1.011674 Test loss=0.524929 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.9727573990821838
[5/24] Train loss=0.9565600752830505
[10/24] Train loss=1.0356144905090332
[15/24] Train loss=0.947514533996582
[20/24] Train loss=0.9191637635231018
Test set avg_accuracy=76.52% avg_sensitivity=82.13%, avg_specificity=74.64% avg_auc=86.11%
Best model saved!! Metric=-6.594185189700227!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.980175 Test loss=0.490675 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.9314780235290527
[5/24] Train loss=0.9074699878692627
[10/24] Train loss=0.9898261427879333
[15/24] Train loss=0.9153421521186829
[20/24] Train loss=0.8950543999671936
Test set avg_accuracy=77.49% avg_sensitivity=81.77%, avg_specificity=76.05% avg_auc=87.09%
Best model saved!! Metric=-3.606573230125079!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.953487 Test loss=0.465766 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.9054851531982422
[5/24] Train loss=0.8755161762237549
[10/24] Train loss=0.9740903973579407
[15/24] Train loss=0.896556556224823
[20/24] Train loss=0.8645991683006287
Test set avg_accuracy=78.67% avg_sensitivity=83.01%, avg_specificity=77.21% avg_auc=87.99%
Best model saved!! Metric=0.8891814299836795!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.925531 Test loss=0.451969 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.876087486743927
[5/24] Train loss=0.8591340780258179
[10/24] Train loss=0.9372857809066772
[15/24] Train loss=0.866378128528595
[20/24] Train loss=0.8425349593162537
Test set avg_accuracy=80.61% avg_sensitivity=80.22%, avg_specificity=80.74% avg_auc=88.61%
Best model saved!! Metric=4.179926903327541!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.906872 Test loss=0.420150 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.8345181941986084
[5/24] Train loss=0.8386508226394653
[10/24] Train loss=0.9214133620262146
[15/24] Train loss=0.8403451442718506
[20/24] Train loss=0.8183473944664001
Test set avg_accuracy=81.68% avg_sensitivity=79.75%, avg_specificity=82.33% avg_auc=89.14%
Best model saved!! Metric=6.8967726049321385!!
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.890130 Test loss=0.404003 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.8059400916099548
[5/24] Train loss=0.8373086452484131
[10/24] Train loss=0.891059398651123
[15/24] Train loss=0.8458720445632935
[20/24] Train loss=0.7802792191505432
Test set avg_accuracy=82.84% avg_sensitivity=75.19%, avg_specificity=85.41% avg_auc=89.43%
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.870132 Test loss=0.377313 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.8160712122917175
[5/24] Train loss=0.8035037517547607
[10/24] Train loss=0.8753435015678406
[15/24] Train loss=0.83331698179245
[20/24] Train loss=0.7551381587982178
Test set avg_accuracy=82.29% avg_sensitivity=79.75%, avg_specificity=83.14% avg_auc=89.80%
Best model saved!! Metric=8.9909540216197!!
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.860608 Test loss=0.386154 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.80595862865448
[5/24] Train loss=0.8134176135063171
[10/24] Train loss=0.8632497787475586
[15/24] Train loss=0.8057833909988403
[20/24] Train loss=0.7457370758056641
Test set avg_accuracy=82.58% avg_sensitivity=81.46%, avg_specificity=82.95% avg_auc=90.07%
Best model saved!! Metric=11.057326975909348!!
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.839034 Test loss=0.386860 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.7722460031509399
[5/24] Train loss=0.8142857551574707
[10/24] Train loss=0.8588821887969971
[15/24] Train loss=0.7835687398910522
[20/24] Train loss=0.7247620820999146
Test set avg_accuracy=83.16% avg_sensitivity=79.70%, avg_specificity=84.33% avg_auc=90.33%
Best model saved!! Metric=11.522819328805639!!
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.828426 Test loss=0.373476 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.7696176171302795
[5/24] Train loss=0.813044548034668
[10/24] Train loss=0.8557747602462769
[15/24] Train loss=0.7899153828620911
[20/24] Train loss=0.7250200510025024
Test set avg_accuracy=84.26% avg_sensitivity=76.02%, avg_specificity=87.02% avg_auc=90.49%
Best model saved!! Metric=11.790572886400923!!
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.824748 Test loss=0.356865 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.7802702188491821
[5/24] Train loss=0.8294627666473389
[10/24] Train loss=0.8431069850921631
[15/24] Train loss=0.7831291556358337
[20/24] Train loss=0.7113153338432312
Test set avg_accuracy=84.32% avg_sensitivity=76.49%, avg_specificity=86.95% avg_auc=90.51%
Best model saved!! Metric=12.274613757796104!!
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.822116 Test loss=0.354530 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.7654986381530762
[5/24] Train loss=0.8202443718910217
[10/24] Train loss=0.8190328478813171
[15/24] Train loss=0.7892158627510071
[20/24] Train loss=0.6989352107048035
Test set avg_accuracy=84.51% avg_sensitivity=75.09%, avg_specificity=87.67% avg_auc=90.59%
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.811510 Test loss=0.350357 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.7535569667816162
[5/24] Train loss=0.8677256107330322
[10/24] Train loss=0.8322386741638184
[15/24] Train loss=0.7647916674613953
[20/24] Train loss=0.6950174570083618
Test set avg_accuracy=84.44% avg_sensitivity=77.16%, avg_specificity=86.88% avg_auc=90.65%
Best model saved!! Metric=13.13548766118653!!
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.810952 Test loss=0.352762 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.7520765662193298
[5/24] Train loss=0.8594262599945068
[10/24] Train loss=0.8146700263023376
[15/24] Train loss=0.7650312185287476
[20/24] Train loss=0.6804807782173157
Test set avg_accuracy=84.51% avg_sensitivity=79.13%, avg_specificity=86.31% avg_auc=90.73%
Best model saved!! Metric=14.672750226328219!!
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.803047 Test loss=0.358114 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.7475429773330688
[5/24] Train loss=0.8305191397666931
[10/24] Train loss=0.8249136805534363
[15/24] Train loss=0.7672885656356812
[20/24] Train loss=0.6939268112182617
Test set avg_accuracy=83.95% avg_sensitivity=80.68%, avg_specificity=85.04% avg_auc=90.74%
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.798850 Test loss=0.363776 Current lr=[0.000210185142098938]

[0/24] Train loss=0.7372801899909973
[5/24] Train loss=0.8587573170661926
[10/24] Train loss=0.8031264543533325
[15/24] Train loss=0.7641701698303223
[20/24] Train loss=0.6670260429382324
Test set avg_accuracy=84.51% avg_sensitivity=81.36%, avg_specificity=85.56% avg_auc=91.05%
Best model saved!! Metric=16.470153760088493!!
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.786790 Test loss=0.359302 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.714969277381897
[5/24] Train loss=0.8455982208251953
[10/24] Train loss=0.8171151280403137
[15/24] Train loss=0.780154824256897
[20/24] Train loss=0.6841156482696533
Test set avg_accuracy=83.65% avg_sensitivity=82.60%, avg_specificity=84.00% avg_auc=91.05%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.791101 Test loss=0.368011 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.7155088186264038
[5/24] Train loss=0.8224154114723206
[10/24] Train loss=0.80340975522995
[15/24] Train loss=0.7777081727981567
[20/24] Train loss=0.6758546829223633
Test set avg_accuracy=84.27% avg_sensitivity=80.94%, avg_specificity=85.39% avg_auc=91.19%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.780225 Test loss=0.358152 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.7178972363471985
[5/24] Train loss=0.8137193322181702
[10/24] Train loss=0.8264543414115906
[15/24] Train loss=0.7740767002105713
[20/24] Train loss=0.6652393341064453
Test set avg_accuracy=84.69% avg_sensitivity=81.05%, avg_specificity=85.91% avg_auc=91.30%
Best model saved!! Metric=16.94325321274887!!
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.776323 Test loss=0.353910 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.7190660834312439
[5/24] Train loss=0.817514955997467
[10/24] Train loss=0.8078775405883789
[15/24] Train loss=0.7852705121040344
[20/24] Train loss=0.6550570726394653
Test set avg_accuracy=84.47% avg_sensitivity=81.82%, avg_specificity=85.35% avg_auc=91.35%
Best model saved!! Metric=16.9922272836547!!
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.770813 Test loss=0.356371 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.7110635042190552
[5/24] Train loss=0.8232595324516296
[10/24] Train loss=0.8084216713905334
[15/24] Train loss=0.7788485884666443
[20/24] Train loss=0.6359887719154358
Test set avg_accuracy=84.70% avg_sensitivity=81.25%, avg_specificity=85.86% avg_auc=91.38%
Best model saved!! Metric=17.197083268842135!!
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.770167 Test loss=0.352854 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.7052958607673645
[5/24] Train loss=0.820707380771637
[10/24] Train loss=0.7901256680488586
[15/24] Train loss=0.7732415795326233
[20/24] Train loss=0.6503138542175293
Test set avg_accuracy=84.84% avg_sensitivity=80.32%, avg_specificity=86.36% avg_auc=91.54%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.764311 Test loss=0.346818 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.7141037583351135
[5/24] Train loss=0.8245524168014526
[10/24] Train loss=0.7819571495056152
[15/24] Train loss=0.7642284631729126
[20/24] Train loss=0.6358393430709839
Test set avg_accuracy=84.88% avg_sensitivity=79.54%, avg_specificity=86.68% avg_auc=91.46%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.761770 Test loss=0.345859 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.6977039575576782
[5/24] Train loss=0.8002683520317078
[10/24] Train loss=0.7787361145019531
[15/24] Train loss=0.7480852603912354
[20/24] Train loss=0.6241676807403564
Test set avg_accuracy=85.04% avg_sensitivity=78.51%, avg_specificity=87.23% avg_auc=91.43%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.756013 Test loss=0.341778 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.7055359482765198
[5/24] Train loss=0.80131596326828
[10/24] Train loss=0.7819734811782837
[15/24] Train loss=0.755841076374054
[20/24] Train loss=0.6329209804534912
Test set avg_accuracy=85.52% avg_sensitivity=76.54%, avg_specificity=88.54% avg_auc=91.42%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.755407 Test loss=0.335620 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.717382550239563
[5/24] Train loss=0.8208686113357544
[10/24] Train loss=0.7812209129333496
[15/24] Train loss=0.7496550679206848
[20/24] Train loss=0.6366183161735535
Test set avg_accuracy=84.26% avg_sensitivity=81.41%, avg_specificity=85.21% avg_auc=91.42%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.756477 Test loss=0.353956 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.7060191631317139
[5/24] Train loss=0.7590494751930237
[10/24] Train loss=0.7652931809425354
[15/24] Train loss=0.7405551671981812
[20/24] Train loss=0.6486784815788269
Test set avg_accuracy=85.43% avg_sensitivity=77.78%, avg_specificity=88.00% avg_auc=91.59%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.740042 Test loss=0.336412 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.6972537040710449
[5/24] Train loss=0.7924337387084961
[10/24] Train loss=0.7646939754486084
[15/24] Train loss=0.7293116450309753
[20/24] Train loss=0.6210926175117493
Test set avg_accuracy=84.40% avg_sensitivity=82.08%, avg_specificity=85.18% avg_auc=91.67%
Best model saved!! Metric=17.337749998352294!!
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.742447 Test loss=0.351180 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.6929594278335571
[5/24] Train loss=0.7718822360038757
[10/24] Train loss=0.7411736845970154
[15/24] Train loss=0.7322751879692078
[20/24] Train loss=0.6092044711112976
Test set avg_accuracy=85.14% avg_sensitivity=81.31%, avg_specificity=86.43% avg_auc=91.85%
Best model saved!! Metric=18.73540915897209!!
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.732501 Test loss=0.341285 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.6810862421989441
[5/24] Train loss=0.7861738801002502
[10/24] Train loss=0.7487531304359436
[15/24] Train loss=0.7239190936088562
[20/24] Train loss=0.6144334673881531
Test set avg_accuracy=85.76% avg_sensitivity=79.54%, avg_specificity=87.84% avg_auc=91.96%
Best model saved!! Metric=19.09592271150767!!
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.726128 Test loss=0.331894 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.6903767585754395
[5/24] Train loss=0.8081784844398499
[10/24] Train loss=0.7705294489860535
[15/24] Train loss=0.727608323097229
[20/24] Train loss=0.6073154211044312
Test set avg_accuracy=84.70% avg_sensitivity=82.55%, avg_specificity=85.42% avg_auc=91.98%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.734130 Test loss=0.343834 Current lr=[0.00029967723776099]

[0/24] Train loss=0.6801809072494507
[5/24] Train loss=0.7717075943946838
[10/24] Train loss=0.7481984496116638
[15/24] Train loss=0.7080973386764526
[20/24] Train loss=0.5865955948829651
Test set avg_accuracy=85.26% avg_sensitivity=81.67%, avg_specificity=86.47% avg_auc=92.08%
Best model saved!! Metric=19.470676366437473!!
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.721011 Test loss=0.338737 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.6711929440498352
[5/24] Train loss=0.7736484408378601
[10/24] Train loss=0.7451902627944946
[15/24] Train loss=0.7188026309013367
[20/24] Train loss=0.5950919389724731
Test set avg_accuracy=85.00% avg_sensitivity=82.29%, avg_specificity=85.91% avg_auc=92.02%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.718631 Test loss=0.341135 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.6812547445297241
[5/24] Train loss=0.7662175893783569
[10/24] Train loss=0.7621696591377258
[15/24] Train loss=0.7303809523582458
[20/24] Train loss=0.603000283241272
Test set avg_accuracy=85.52% avg_sensitivity=81.51%, avg_specificity=86.87% avg_auc=92.19%
Best model saved!! Metric=20.089361271319802!!
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.715347 Test loss=0.334286 Current lr=[0.000299720220882401]

[0/24] Train loss=0.6825432181358337
[5/24] Train loss=0.7614056468009949
[10/24] Train loss=0.7345107197761536
[15/24] Train loss=0.7168905138969421
[20/24] Train loss=0.5906895995140076
Test set avg_accuracy=85.47% avg_sensitivity=81.46%, avg_specificity=86.82% avg_auc=92.19%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.711747 Test loss=0.333118 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.6756902933120728
[5/24] Train loss=0.7544070482254028
[10/24] Train loss=0.7400607466697693
[15/24] Train loss=0.7164347171783447
[20/24] Train loss=0.5801113247871399
Test set avg_accuracy=84.87% avg_sensitivity=83.22%, avg_specificity=85.42% avg_auc=92.20%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.708494 Test loss=0.344776 Current lr=[0.000298904600941902]

[0/24] Train loss=0.6748112440109253
[5/24] Train loss=0.7122820615768433
[10/24] Train loss=0.732843816280365
[15/24] Train loss=0.7067809700965881
[20/24] Train loss=0.5838921070098877
Test set avg_accuracy=85.66% avg_sensitivity=80.94%, avg_specificity=87.25% avg_auc=92.31%
Best model saved!! Metric=20.16513448973383!!
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.702826 Test loss=0.328765 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.6627596616744995
[5/24] Train loss=0.7411181330680847
[10/24] Train loss=0.7309716939926147
[15/24] Train loss=0.7121527194976807
[20/24] Train loss=0.5683572888374329
Test set avg_accuracy=85.31% avg_sensitivity=82.91%, avg_specificity=86.12% avg_auc=92.30%
Best model saved!! Metric=20.637356983210722!!
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.701652 Test loss=0.336522 Current lr=[0.000297555943323901]

[0/24] Train loss=0.6644625663757324
[5/24] Train loss=0.7258800268173218
[10/24] Train loss=0.7388544678688049
[15/24] Train loss=0.6997256875038147
[20/24] Train loss=0.5739907622337341
Test set avg_accuracy=85.36% avg_sensitivity=82.39%, avg_specificity=86.36% avg_auc=92.38%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.698431 Test loss=0.334185 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.6662217974662781
[5/24] Train loss=0.7164085507392883
[10/24] Train loss=0.7391554713249207
[15/24] Train loss=0.6969692707061768
[20/24] Train loss=0.5714582204818726
Test set avg_accuracy=85.64% avg_sensitivity=81.77%, avg_specificity=86.94% avg_auc=92.44%
Best model saved!! Metric=20.789884859581036!!
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.694804 Test loss=0.329164 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.659595251083374
[5/24] Train loss=0.7325790524482727
[10/24] Train loss=0.736284613609314
[15/24] Train loss=0.6991260647773743
[20/24] Train loss=0.5847439169883728
Test set avg_accuracy=86.13% avg_sensitivity=80.48%, avg_specificity=88.03% avg_auc=92.44%
Best model saved!! Metric=21.083362610306708!!
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.695252 Test loss=0.322176 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.6644989252090454
[5/24] Train loss=0.7384129166603088
[10/24] Train loss=0.7244581580162048
[15/24] Train loss=0.6909583806991577
[20/24] Train loss=0.5595806241035461
Test set avg_accuracy=85.17% avg_sensitivity=83.17%, avg_specificity=85.84% avg_auc=92.32%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.693268 Test loss=0.337878 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.6602263450622559
[5/24] Train loss=0.7164197564125061
[10/24] Train loss=0.7354031801223755
[15/24] Train loss=0.7106288075447083
[20/24] Train loss=0.5603296756744385
Test set avg_accuracy=85.49% avg_sensitivity=82.34%, avg_specificity=86.55% avg_auc=92.41%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.690115 Test loss=0.330716 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.6567875742912292
[5/24] Train loss=0.7227062582969666
[10/24] Train loss=0.72833651304245
[15/24] Train loss=0.6867097616195679
[20/24] Train loss=0.5527888536453247
Test set avg_accuracy=85.96% avg_sensitivity=81.56%, avg_specificity=87.44% avg_auc=92.55%
Best model saved!! Metric=21.518740647976912!!
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.683990 Test loss=0.323477 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.6465867757797241
[5/24] Train loss=0.720917820930481
[10/24] Train loss=0.7112614512443542
[15/24] Train loss=0.6966754794120789
[20/24] Train loss=0.5611986517906189
Test set avg_accuracy=85.70% avg_sensitivity=81.87%, avg_specificity=86.99% avg_auc=92.43%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.685924 Test loss=0.327421 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.6609331369400024
[5/24] Train loss=0.7169129848480225
[10/24] Train loss=0.7171884179115295
[15/24] Train loss=0.6955981254577637
[20/24] Train loss=0.5671138167381287
Test set avg_accuracy=86.33% avg_sensitivity=80.32%, avg_specificity=88.35% avg_auc=92.61%
Best model saved!! Metric=21.6053750276769!!
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.683609 Test loss=0.316874 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.6576430797576904
[5/24] Train loss=0.7266882061958313
[10/24] Train loss=0.7182248830795288
[15/24] Train loss=0.694259524345398
[20/24] Train loss=0.5618336796760559
Test set avg_accuracy=85.87% avg_sensitivity=81.93%, avg_specificity=87.20% avg_auc=92.59%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.686251 Test loss=0.324016 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.6364921927452087
[5/24] Train loss=0.7076678276062012
[10/24] Train loss=0.7155551910400391
[15/24] Train loss=0.7020273208618164
[20/24] Train loss=0.5456246733665466
Test set avg_accuracy=85.89% avg_sensitivity=82.50%, avg_specificity=87.02% avg_auc=92.68%
Best model saved!! Metric=22.08421034154439!!
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.678576 Test loss=0.325441 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.6492843627929688
[5/24] Train loss=0.7407423257827759
[10/24] Train loss=0.7103898525238037
[15/24] Train loss=0.6770328879356384
[20/24] Train loss=0.5552152991294861
Test set avg_accuracy=86.04% avg_sensitivity=82.19%, avg_specificity=87.34% avg_auc=92.74%
Best model saved!! Metric=22.305376051110102!!
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.679284 Test loss=0.323077 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.6444065570831299
[5/24] Train loss=0.7094494700431824
[10/24] Train loss=0.7079059481620789
[15/24] Train loss=0.6695255041122437
[20/24] Train loss=0.5446867942810059
Test set avg_accuracy=86.21% avg_sensitivity=81.77%, avg_specificity=87.70% avg_auc=92.82%
Best model saved!! Metric=22.505769312327885!!
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.675662 Test loss=0.319509 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.6359724998474121
[5/24] Train loss=0.7092359662055969
[10/24] Train loss=0.7211065888404846
[15/24] Train loss=0.6718136072158813
[20/24] Train loss=0.5382649898529053
Test set avg_accuracy=86.25% avg_sensitivity=81.56%, avg_specificity=87.82% avg_auc=92.90%
Best model saved!! Metric=22.53603105630964!!
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.673955 Test loss=0.318181 Current lr=[0.000276307469034998]

[0/24] Train loss=0.6470890641212463
[5/24] Train loss=0.7132940292358398
[10/24] Train loss=0.7134690880775452
[15/24] Train loss=0.6804981827735901
[20/24] Train loss=0.5302087068557739
Test set avg_accuracy=86.48% avg_sensitivity=80.22%, avg_specificity=88.59% avg_auc=92.86%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.670869 Test loss=0.311754 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.6413131952285767
[5/24] Train loss=0.7179559469223022
[10/24] Train loss=0.7091638445854187
[15/24] Train loss=0.6837286353111267
[20/24] Train loss=0.5303019881248474
Test set avg_accuracy=87.01% avg_sensitivity=76.95%, avg_specificity=90.38% avg_auc=92.84%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.673876 Test loss=0.303668 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.6464138627052307
[5/24] Train loss=0.7177290916442871
[10/24] Train loss=0.7413560748100281
[15/24] Train loss=0.6700618863105774
[20/24] Train loss=0.5640403628349304
Test set avg_accuracy=86.45% avg_sensitivity=79.18%, avg_specificity=88.89% avg_auc=92.75%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.681436 Test loss=0.312293 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.6389264464378357
[5/24] Train loss=0.6726707816123962
[10/24] Train loss=0.7358963489532471
[15/24] Train loss=0.6809773445129395
[20/24] Train loss=0.5443879961967468
Test set avg_accuracy=86.29% avg_sensitivity=81.67%, avg_specificity=87.84% avg_auc=92.85%
Best model saved!! Metric=22.644896072569168!!
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.670995 Test loss=0.318288 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.619979977607727
[5/24] Train loss=0.6584286689758301
[10/24] Train loss=0.7370271682739258
[15/24] Train loss=0.6692193746566772
[20/24] Train loss=0.5611950159072876
Test set avg_accuracy=86.51% avg_sensitivity=81.51%, avg_specificity=88.19% avg_auc=92.89%
Best model saved!! Metric=23.10600102920955!!
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.665130 Test loss=0.316254 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.6309695839881897
[5/24] Train loss=0.654718279838562
[10/24] Train loss=0.7374049425125122
[15/24] Train loss=0.6628521084785461
[20/24] Train loss=0.5537829399108887
Test set avg_accuracy=86.50% avg_sensitivity=81.10%, avg_specificity=88.31% avg_auc=92.98%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.663126 Test loss=0.313213 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.6371722221374512
[5/24] Train loss=0.6596115231513977
[10/24] Train loss=0.7281069755554199
[15/24] Train loss=0.6624274849891663
[20/24] Train loss=0.5579427480697632
Test set avg_accuracy=86.42% avg_sensitivity=80.99%, avg_specificity=88.24% avg_auc=92.95%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.662609 Test loss=0.314262 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.6351923942565918
[5/24] Train loss=0.6532667875289917
[10/24] Train loss=0.736582338809967
[15/24] Train loss=0.6601088643074036
[20/24] Train loss=0.54519122838974
Test set avg_accuracy=86.09% avg_sensitivity=82.34%, avg_specificity=87.35% avg_auc=93.02%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.659505 Test loss=0.317415 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.6258881092071533
[5/24] Train loss=0.6657236814498901
[10/24] Train loss=0.7225965261459351
[15/24] Train loss=0.6499716639518738
[20/24] Train loss=0.5383579134941101
Test set avg_accuracy=86.48% avg_sensitivity=79.96%, avg_specificity=88.68% avg_auc=92.96%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.652432 Test loss=0.310539 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.6351122260093689
[5/24] Train loss=0.6627223491668701
[10/24] Train loss=0.7102931141853333
[15/24] Train loss=0.6551774740219116
[20/24] Train loss=0.5357086658477783
Test set avg_accuracy=86.21% avg_sensitivity=82.44%, avg_specificity=87.48% avg_auc=93.07%
Best model saved!! Metric=23.202015407048705!!
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.656132 Test loss=0.316943 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.6235982179641724
[5/24] Train loss=0.6505423188209534
[10/24] Train loss=0.7107736468315125
[15/24] Train loss=0.6523756980895996
[20/24] Train loss=0.5492122769355774
Test set avg_accuracy=86.48% avg_sensitivity=81.77%, avg_specificity=88.07% avg_auc=93.07%
Best model saved!! Metric=23.39720544834583!!
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.651172 Test loss=0.313334 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.6178943514823914
[5/24] Train loss=0.6494861841201782
[10/24] Train loss=0.7140368223190308
[15/24] Train loss=0.6550379991531372
[20/24] Train loss=0.5248057842254639
Test set avg_accuracy=86.35% avg_sensitivity=82.81%, avg_specificity=87.55% avg_auc=93.16%
Best model saved!! Metric=23.86315600387968!!
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.647104 Test loss=0.315233 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.6154825091362
[5/24] Train loss=0.6477369070053101
[10/24] Train loss=0.7039911150932312
[15/24] Train loss=0.6394281983375549
[20/24] Train loss=0.5324973464012146
Test set avg_accuracy=86.52% avg_sensitivity=82.65%, avg_specificity=87.82% avg_auc=93.22%
Best model saved!! Metric=24.22154850825048!!
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.647956 Test loss=0.311714 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.6186460256576538
[5/24] Train loss=0.6489678025245667
[10/24] Train loss=0.709240734577179
[15/24] Train loss=0.6329472064971924
[20/24] Train loss=0.5300220251083374
Test set avg_accuracy=86.78% avg_sensitivity=81.31%, avg_specificity=88.62% avg_auc=93.24%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.644552 Test loss=0.307224 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.6212120652198792
[5/24] Train loss=0.6396481990814209
[10/24] Train loss=0.714320182800293
[15/24] Train loss=0.6443091630935669
[20/24] Train loss=0.5306511521339417
Test set avg_accuracy=86.73% avg_sensitivity=81.87%, avg_specificity=88.36% avg_auc=93.21%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.646976 Test loss=0.309701 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.6211621761322021
[5/24] Train loss=0.6518564224243164
[10/24] Train loss=0.7060015201568604
[15/24] Train loss=0.6412318348884583
[20/24] Train loss=0.5171175003051758
Test set avg_accuracy=86.60% avg_sensitivity=82.08%, avg_specificity=88.12% avg_auc=93.25%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.646458 Test loss=0.309526 Current lr=[0.000224838296036774]

[0/24] Train loss=0.6175922155380249
[5/24] Train loss=0.66230708360672
[10/24] Train loss=0.6946836113929749
[15/24] Train loss=0.6436113715171814
[20/24] Train loss=0.5240105986595154
Test set avg_accuracy=86.46% avg_sensitivity=82.19%, avg_specificity=87.89% avg_auc=93.26%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.639293 Test loss=0.309849 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.6132225394248962
[5/24] Train loss=0.6435804963111877
[10/24] Train loss=0.6987978219985962
[15/24] Train loss=0.6364763379096985
[20/24] Train loss=0.5222682356834412
Test set avg_accuracy=86.48% avg_sensitivity=82.08%, avg_specificity=87.96% avg_auc=93.29%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.640230 Test loss=0.309198 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.6156113743782043
[5/24] Train loss=0.6526636481285095
[10/24] Train loss=0.6953969597816467
[15/24] Train loss=0.6360695362091064
[20/24] Train loss=0.5168478488922119
Test set avg_accuracy=86.54% avg_sensitivity=82.13%, avg_specificity=88.02% avg_auc=93.29%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.637046 Test loss=0.308717 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.6062853932380676
[5/24] Train loss=0.6384457945823669
[10/24] Train loss=0.6952682733535767
[15/24] Train loss=0.6320424675941467
[20/24] Train loss=0.5144919753074646
Test set avg_accuracy=86.61% avg_sensitivity=81.98%, avg_specificity=88.17% avg_auc=93.25%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.632311 Test loss=0.308358 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.6101754903793335
[5/24] Train loss=0.6312152147293091
[10/24] Train loss=0.6987388730049133
[15/24] Train loss=0.6197785139083862
[20/24] Train loss=0.5018808841705322
Test set avg_accuracy=86.48% avg_sensitivity=81.56%, avg_specificity=88.14% avg_auc=93.23%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.634540 Test loss=0.307399 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.6093614101409912
[5/24] Train loss=0.6413885354995728
[10/24] Train loss=0.6813608407974243
[15/24] Train loss=0.6271522641181946
[20/24] Train loss=0.5113207697868347
Test set avg_accuracy=86.72% avg_sensitivity=81.98%, avg_specificity=88.31% avg_auc=93.34%
Best model saved!! Metric=24.344729939861196!!
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.630759 Test loss=0.306880 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.6064707040786743
[5/24] Train loss=0.6334789991378784
[10/24] Train loss=0.6910193562507629
[15/24] Train loss=0.6275576949119568
[20/24] Train loss=0.5132226943969727
Test set avg_accuracy=86.93% avg_sensitivity=80.84%, avg_specificity=88.97% avg_auc=93.35%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.632809 Test loss=0.301723 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.5994437336921692
[5/24] Train loss=0.6340149641036987
[10/24] Train loss=0.6872458457946777
[15/24] Train loss=0.6210294961929321
[20/24] Train loss=0.49816471338272095
Test set avg_accuracy=86.90% avg_sensitivity=79.85%, avg_specificity=89.27% avg_auc=93.27%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.627518 Test loss=0.301157 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.5972170233726501
[5/24] Train loss=0.6203420162200928
[10/24] Train loss=0.6775118708610535
[15/24] Train loss=0.6364023685455322
[20/24] Train loss=0.5007826685905457
Test set avg_accuracy=87.14% avg_sensitivity=80.27%, avg_specificity=89.44% avg_auc=93.30%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.625732 Test loss=0.299791 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.6084781885147095
[5/24] Train loss=0.6266943216323853
[10/24] Train loss=0.6774802803993225
[15/24] Train loss=0.6213334798812866
[20/24] Train loss=0.5001767873764038
Test set avg_accuracy=86.86% avg_sensitivity=80.22%, avg_specificity=89.09% avg_auc=93.26%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.628811 Test loss=0.301019 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.616907000541687
[5/24] Train loss=0.624459981918335
[10/24] Train loss=0.6792768836021423
[15/24] Train loss=0.6149356961250305
[20/24] Train loss=0.49820148944854736
Test set avg_accuracy=86.78% avg_sensitivity=80.94%, avg_specificity=88.75% avg_auc=93.32%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.629169 Test loss=0.301641 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.5993312001228333
[5/24] Train loss=0.6382459402084351
[10/24] Train loss=0.6857581734657288
[15/24] Train loss=0.6269127726554871
[20/24] Train loss=0.5123804807662964
Test set avg_accuracy=85.48% avg_sensitivity=85.24%, avg_specificity=85.56% avg_auc=93.47%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.631070 Test loss=0.323123 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.6071487665176392
[5/24] Train loss=0.6348981261253357
[10/24] Train loss=0.6813488602638245
[15/24] Train loss=0.6318222284317017
[20/24] Train loss=0.5431088805198669
Test set avg_accuracy=84.64% avg_sensitivity=87.52%, avg_specificity=83.67% avg_auc=93.42%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.632555 Test loss=0.342409 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.6143346428871155
[5/24] Train loss=0.6463689208030701
[10/24] Train loss=0.6703283190727234
[15/24] Train loss=0.6219677329063416
[20/24] Train loss=0.503669261932373
Test set avg_accuracy=85.52% avg_sensitivity=85.66%, avg_specificity=85.48% avg_auc=93.47%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.620806 Test loss=0.326283 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.6039300560951233
[5/24] Train loss=0.6242879629135132
[10/24] Train loss=0.6611952185630798
[15/24] Train loss=0.6232264637947083
[20/24] Train loss=0.5076401233673096
Test set avg_accuracy=85.39% avg_sensitivity=85.86%, avg_specificity=85.23% avg_auc=93.52%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.615661 Test loss=0.325735 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.5968375205993652
[5/24] Train loss=0.6281306147575378
[10/24] Train loss=0.6585682034492493
[15/24] Train loss=0.6163409352302551
[20/24] Train loss=0.512543261051178
Test set avg_accuracy=85.40% avg_sensitivity=85.81%, avg_specificity=85.27% avg_auc=93.46%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.615589 Test loss=0.324615 Current lr=[0.000156543481933168]

[0/24] Train loss=0.6021453738212585
[5/24] Train loss=0.6185471415519714
[10/24] Train loss=0.6725665330886841
[15/24] Train loss=0.6119387745857239
[20/24] Train loss=0.5088227391242981
Test set avg_accuracy=85.38% avg_sensitivity=85.76%, avg_specificity=85.25% avg_auc=93.45%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.614805 Test loss=0.325813 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.6031025648117065
[5/24] Train loss=0.6133763790130615
[10/24] Train loss=0.6532508134841919
[15/24] Train loss=0.6036302447319031
[20/24] Train loss=0.507347047328949
Test set avg_accuracy=85.21% avg_sensitivity=86.28%, avg_specificity=84.85% avg_auc=93.56%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.608731 Test loss=0.327320 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.5867747068405151
[5/24] Train loss=0.604581892490387
[10/24] Train loss=0.6436861753463745
[15/24] Train loss=0.6019771099090576
[20/24] Train loss=0.4908754527568817
Test set avg_accuracy=85.20% avg_sensitivity=86.74%, avg_specificity=84.68% avg_auc=93.53%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.607120 Test loss=0.328985 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.6070552468299866
[5/24] Train loss=0.6139838099479675
[10/24] Train loss=0.6501656770706177
[15/24] Train loss=0.616445779800415
[20/24] Train loss=0.49591708183288574
Test set avg_accuracy=85.34% avg_sensitivity=86.07%, avg_specificity=85.09% avg_auc=93.52%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.609836 Test loss=0.325106 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.5921820402145386
[5/24] Train loss=0.606311023235321
[10/24] Train loss=0.6559416651725769
[15/24] Train loss=0.5971145033836365
[20/24] Train loss=0.49857568740844727
Test set avg_accuracy=85.16% avg_sensitivity=86.12%, avg_specificity=84.83% avg_auc=93.49%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.605693 Test loss=0.327646 Current lr=[0.000134135431043539]

[0/24] Train loss=0.590242862701416
[5/24] Train loss=0.6144908666610718
[10/24] Train loss=0.6494041681289673
[15/24] Train loss=0.5963234901428223
[20/24] Train loss=0.511648416519165
Test set avg_accuracy=85.17% avg_sensitivity=86.59%, avg_specificity=84.69% avg_auc=93.53%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.606469 Test loss=0.328308 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.5898820161819458
[5/24] Train loss=0.61356520652771
[10/24] Train loss=0.649576723575592
[15/24] Train loss=0.5953695178031921
[20/24] Train loss=0.48757314682006836
Test set avg_accuracy=85.17% avg_sensitivity=86.43%, avg_specificity=84.75% avg_auc=93.53%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.601970 Test loss=0.328034 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.5891367793083191
[5/24] Train loss=0.6112145781517029
[10/24] Train loss=0.6582395434379578
[15/24] Train loss=0.5956429839134216
[20/24] Train loss=0.4978095591068268
Test set avg_accuracy=85.13% avg_sensitivity=86.38%, avg_specificity=84.71% avg_auc=93.51%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.600884 Test loss=0.326696 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.5868943333625793
[5/24] Train loss=0.5991008877754211
[10/24] Train loss=0.651351809501648
[15/24] Train loss=0.5905052423477173
[20/24] Train loss=0.4903508126735687
Test set avg_accuracy=85.17% avg_sensitivity=85.66%, avg_specificity=85.01% avg_auc=93.48%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.596880 Test loss=0.324072 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.5859696269035339
[5/24] Train loss=0.5960682034492493
[10/24] Train loss=0.6416911482810974
[15/24] Train loss=0.600508987903595
[20/24] Train loss=0.4849983751773834
Test set avg_accuracy=85.10% avg_sensitivity=85.55%, avg_specificity=84.95% avg_auc=93.48%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.598220 Test loss=0.323327 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.5869828462600708
[5/24] Train loss=0.6024722456932068
[10/24] Train loss=0.6446729302406311
[15/24] Train loss=0.5947893261909485
[20/24] Train loss=0.4881595969200134
Test set avg_accuracy=85.13% avg_sensitivity=86.02%, avg_specificity=84.83% avg_auc=93.54%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.596663 Test loss=0.325968 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.5911886692047119
[5/24] Train loss=0.6086214780807495
[10/24] Train loss=0.654990553855896
[15/24] Train loss=0.5989002585411072
[20/24] Train loss=0.49098891019821167
Test set avg_accuracy=84.80% avg_sensitivity=86.54%, avg_specificity=84.22% avg_auc=93.51%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.598311 Test loss=0.332191 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.5947935581207275
[5/24] Train loss=0.6048572063446045
[10/24] Train loss=0.6445136666297913
[15/24] Train loss=0.600814163684845
[20/24] Train loss=0.482261061668396
Test set avg_accuracy=85.08% avg_sensitivity=85.45%, avg_specificity=84.95% avg_auc=93.49%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.595623 Test loss=0.323410 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.5862209796905518
[5/24] Train loss=0.6065335869789124
[10/24] Train loss=0.6381846070289612
[15/24] Train loss=0.5874441266059875
[20/24] Train loss=0.48437145352363586
Test set avg_accuracy=84.87% avg_sensitivity=86.48%, avg_specificity=84.33% avg_auc=93.51%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.594190 Test loss=0.330919 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.5848317742347717
[5/24] Train loss=0.6121239066123962
[10/24] Train loss=0.6384019255638123
[15/24] Train loss=0.5865275263786316
[20/24] Train loss=0.4739983081817627
Test set avg_accuracy=84.84% avg_sensitivity=86.48%, avg_specificity=84.29% avg_auc=93.53%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.591650 Test loss=0.328637 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.5867803692817688
[5/24] Train loss=0.6078728437423706
[10/24] Train loss=0.6346126794815063
[15/24] Train loss=0.5991215109825134
[20/24] Train loss=0.49280405044555664
Test set avg_accuracy=84.77% avg_sensitivity=86.79%, avg_specificity=84.08% avg_auc=93.52%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.594319 Test loss=0.331308 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.5820430517196655
[5/24] Train loss=0.5916029810905457
[10/24] Train loss=0.6367146372795105
[15/24] Train loss=0.5949832201004028
[20/24] Train loss=0.4730152189731598
Test set avg_accuracy=84.74% avg_sensitivity=87.05%, avg_specificity=83.96% avg_auc=93.57%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.592109 Test loss=0.333426 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.583022952079773
[5/24] Train loss=0.6051608920097351
[10/24] Train loss=0.633969783782959
[15/24] Train loss=0.5929148197174072
[20/24] Train loss=0.49020230770111084
Test set avg_accuracy=84.39% avg_sensitivity=87.88%, avg_specificity=83.21% avg_auc=93.61%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.591007 Test loss=0.340538 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.5847779512405396
[5/24] Train loss=0.6047844290733337
[10/24] Train loss=0.6365808248519897
[15/24] Train loss=0.5859444737434387
[20/24] Train loss=0.4927283823490143
Test set avg_accuracy=84.22% avg_sensitivity=88.87%, avg_specificity=82.66% avg_auc=93.65%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.590877 Test loss=0.349890 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.59331214427948
[5/24] Train loss=0.6018248796463013
[10/24] Train loss=0.632905125617981
[15/24] Train loss=0.597326934337616
[20/24] Train loss=0.5023689270019531
Test set avg_accuracy=84.08% avg_sensitivity=88.81%, avg_specificity=82.48% avg_auc=93.65%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.593074 Test loss=0.350372 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.5944496393203735
[5/24] Train loss=0.6163356900215149
[10/24] Train loss=0.6382737755775452
[15/24] Train loss=0.5962051153182983
[20/24] Train loss=0.5063536763191223
Test set avg_accuracy=84.84% avg_sensitivity=87.47%, avg_specificity=83.96% avg_auc=93.61%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.592732 Test loss=0.334278 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.5752549767494202
[5/24] Train loss=0.5933826565742493
[10/24] Train loss=0.6356644034385681
[15/24] Train loss=0.5875443816184998
[20/24] Train loss=0.5062887072563171
Test set avg_accuracy=85.53% avg_sensitivity=86.38%, avg_specificity=85.25% avg_auc=93.58%
Best model saved!! Metric=24.744979078940602!!
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.587896 Test loss=0.324040 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.5723980069160461
[5/24] Train loss=0.5977928638458252
[10/24] Train loss=0.6320857405662537
[15/24] Train loss=0.5846663117408752
[20/24] Train loss=0.49107465147972107
Test set avg_accuracy=85.89% avg_sensitivity=85.76%, avg_specificity=85.93% avg_auc=93.57%
Best model saved!! Metric=25.139104088854978!!
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.584609 Test loss=0.316051 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.5760028958320618
[5/24] Train loss=0.5941957235336304
[10/24] Train loss=0.6326042413711548
[15/24] Train loss=0.5798953175544739
[20/24] Train loss=0.4784402549266815
Test set avg_accuracy=85.60% avg_sensitivity=86.17%, avg_specificity=85.41% avg_auc=93.59%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.583535 Test loss=0.320380 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.5699602961540222
[5/24] Train loss=0.6039263606071472
[10/24] Train loss=0.6286705136299133
[15/24] Train loss=0.5896583795547485
[20/24] Train loss=0.4849722683429718
Test set avg_accuracy=85.64% avg_sensitivity=86.48%, avg_specificity=85.35% avg_auc=93.60%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.580601 Test loss=0.320408 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.5751403570175171
[5/24] Train loss=0.5831984281539917
[10/24] Train loss=0.6149258613586426
[15/24] Train loss=0.5825387239456177
[20/24] Train loss=0.4826261103153229
Test set avg_accuracy=85.65% avg_sensitivity=86.64%, avg_specificity=85.32% avg_auc=93.63%
Best model saved!! Metric=25.239229881058137!!
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.578881 Test loss=0.320297 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.566780686378479
[5/24] Train loss=0.5862963199615479
[10/24] Train loss=0.6272614002227783
[15/24] Train loss=0.5697747468948364
[20/24] Train loss=0.47817015647888184
Test set avg_accuracy=85.89% avg_sensitivity=85.86%, avg_specificity=85.89% avg_auc=93.62%
Best model saved!! Metric=25.25666669560468!!
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.578079 Test loss=0.314197 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.5647950172424316
[5/24] Train loss=0.5769370794296265
[10/24] Train loss=0.6296314597129822
[15/24] Train loss=0.575513482093811
[20/24] Train loss=0.47697749733924866
Test set avg_accuracy=85.69% avg_sensitivity=86.74%, avg_specificity=85.34% avg_auc=93.65%
Best model saved!! Metric=25.417951461208887!!
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.577446 Test loss=0.318755 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.5711431503295898
[5/24] Train loss=0.5792744159698486
[10/24] Train loss=0.6194204688072205
[15/24] Train loss=0.573004961013794
[20/24] Train loss=0.4744832217693329
Test set avg_accuracy=85.83% avg_sensitivity=85.97%, avg_specificity=85.79% avg_auc=93.64%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.576783 Test loss=0.315430 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.5751357078552246
[5/24] Train loss=0.5766530632972717
[10/24] Train loss=0.6252695918083191
[15/24] Train loss=0.5682927370071411
[20/24] Train loss=0.4698048532009125
Test set avg_accuracy=85.74% avg_sensitivity=86.54%, avg_specificity=85.48% avg_auc=93.64%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.573216 Test loss=0.318511 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.5678633451461792
[5/24] Train loss=0.5725075602531433
[10/24] Train loss=0.6246068477630615
[15/24] Train loss=0.5698817372322083
[20/24] Train loss=0.46742159128189087
Test set avg_accuracy=85.87% avg_sensitivity=86.22%, avg_specificity=85.75% avg_auc=93.64%
Best model saved!! Metric=25.49044536420439!!
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.573776 Test loss=0.314324 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.5604764819145203
[5/24] Train loss=0.5894237160682678
[10/24] Train loss=0.6172839403152466
[15/24] Train loss=0.5819274187088013
[20/24] Train loss=0.4684107005596161
Test set avg_accuracy=85.72% avg_sensitivity=86.59%, avg_specificity=85.42% avg_auc=93.64%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.575563 Test loss=0.318301 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.5599029660224915
[5/24] Train loss=0.5839246511459351
[10/24] Train loss=0.6089103817939758
[15/24] Train loss=0.5732352137565613
[20/24] Train loss=0.4726279079914093
Test set avg_accuracy=85.77% avg_sensitivity=86.48%, avg_specificity=85.53% avg_auc=93.66%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.574005 Test loss=0.320195 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.5601496696472168
[5/24] Train loss=0.5673353672027588
[10/24] Train loss=0.6080805063247681
[15/24] Train loss=0.5851725935935974
[20/24] Train loss=0.4654431939125061
Test set avg_accuracy=85.62% avg_sensitivity=86.43%, avg_specificity=85.35% avg_auc=93.65%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.573124 Test loss=0.320570 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.5653789639472961
[5/24] Train loss=0.5818741917610168
[10/24] Train loss=0.6184628009796143
[15/24] Train loss=0.567957878112793
[20/24] Train loss=0.47315001487731934
Test set avg_accuracy=85.57% avg_sensitivity=86.79%, avg_specificity=85.16% avg_auc=93.63%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.574032 Test loss=0.323613 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.5733568072319031
[5/24] Train loss=0.5850735306739807
[10/24] Train loss=0.629273533821106
[15/24] Train loss=0.5667014718055725
[20/24] Train loss=0.47155794501304626
Test set avg_accuracy=85.40% avg_sensitivity=87.36%, avg_specificity=84.75% avg_auc=93.63%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.573444 Test loss=0.327631 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.5799501538276672
[5/24] Train loss=0.5848923325538635
[10/24] Train loss=0.6168654561042786
[15/24] Train loss=0.5628756284713745
[20/24] Train loss=0.46797823905944824
Test set avg_accuracy=85.18% avg_sensitivity=87.62%, avg_specificity=84.36% avg_auc=93.62%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.574790 Test loss=0.332765 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.5710575580596924
[5/24] Train loss=0.564926266670227
[10/24] Train loss=0.6307236552238464
[15/24] Train loss=0.5764371752738953
[20/24] Train loss=0.4610050320625305
Test set avg_accuracy=85.07% avg_sensitivity=87.67%, avg_specificity=84.19% avg_auc=93.63%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.574824 Test loss=0.334395 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.567570686340332
[5/24] Train loss=0.574505627155304
[10/24] Train loss=0.62508624792099
[15/24] Train loss=0.5657638907432556
[20/24] Train loss=0.4739297926425934
Test set avg_accuracy=85.30% avg_sensitivity=87.62%, avg_specificity=84.52% avg_auc=93.65%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.575695 Test loss=0.330064 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.5837011933326721
[5/24] Train loss=0.573509931564331
[10/24] Train loss=0.6278015971183777
[15/24] Train loss=0.5716182589530945
[20/24] Train loss=0.46998369693756104
Test set avg_accuracy=85.55% avg_sensitivity=86.74%, avg_specificity=85.15% avg_auc=93.67%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.574466 Test loss=0.321784 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.5630096197128296
[5/24] Train loss=0.5686410665512085
[10/24] Train loss=0.6225272417068481
[15/24] Train loss=0.5689427852630615
[20/24] Train loss=0.4781194031238556
Test set avg_accuracy=85.78% avg_sensitivity=86.69%, avg_specificity=85.48% avg_auc=93.67%
Best model saved!! Metric=25.613418231540777!!
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.573166 Test loss=0.318834 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.5611221790313721
[5/24] Train loss=0.573003351688385
[10/24] Train loss=0.6258138418197632
[15/24] Train loss=0.5704540610313416
[20/24] Train loss=0.47959160804748535
Test set avg_accuracy=85.81% avg_sensitivity=86.33%, avg_specificity=85.63% avg_auc=93.66%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.570115 Test loss=0.317170 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.5575317740440369
[5/24] Train loss=0.5801389217376709
[10/24] Train loss=0.6211268305778503
[15/24] Train loss=0.5559186339378357
[20/24] Train loss=0.46651357412338257
Test set avg_accuracy=85.79% avg_sensitivity=86.22%, avg_specificity=85.65% avg_auc=93.66%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.569357 Test loss=0.317127 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.5609838366508484
[5/24] Train loss=0.5566192865371704
[10/24] Train loss=0.6142402291297913
[15/24] Train loss=0.5743916630744934
[20/24] Train loss=0.47381487488746643
Test set avg_accuracy=85.78% avg_sensitivity=86.17%, avg_specificity=85.65% avg_auc=93.66%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.571079 Test loss=0.316345 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.5581390857696533
[5/24] Train loss=0.5689626336097717
[10/24] Train loss=0.6146763563156128
[15/24] Train loss=0.5598907470703125
[20/24] Train loss=0.4671502411365509
Test set avg_accuracy=85.79% avg_sensitivity=86.17%, avg_specificity=85.67% avg_auc=93.66%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.567860 Test loss=0.316539 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.5548040270805359
[5/24] Train loss=0.5565600395202637
[10/24] Train loss=0.6134682297706604
[15/24] Train loss=0.5668627619743347
[20/24] Train loss=0.47749945521354675
Test set avg_accuracy=85.82% avg_sensitivity=86.12%, avg_specificity=85.72% avg_auc=93.65%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.567577 Test loss=0.315204 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.5606450438499451
[5/24] Train loss=0.5743324756622314
[10/24] Train loss=0.6104956269264221
[15/24] Train loss=0.5701957941055298
[20/24] Train loss=0.47768229246139526
Test set avg_accuracy=85.79% avg_sensitivity=86.17%, avg_specificity=85.67% avg_auc=93.66%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.568212 Test loss=0.315549 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.5548819303512573
[5/24] Train loss=0.5804857611656189
[10/24] Train loss=0.61634361743927
[15/24] Train loss=0.5703006386756897
[20/24] Train loss=0.45855513215065
Test set avg_accuracy=85.78% avg_sensitivity=86.17%, avg_specificity=85.65% avg_auc=93.66%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.568857 Test loss=0.316321 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.5573784112930298
[5/24] Train loss=0.5719245076179504
[10/24] Train loss=0.6280373334884644
[15/24] Train loss=0.5761457085609436
[20/24] Train loss=0.4757225215435028
Test set avg_accuracy=85.77% avg_sensitivity=86.17%, avg_specificity=85.63% avg_auc=93.66%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.570113 Test loss=0.316224 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.5652833580970764
[5/24] Train loss=0.5735825896263123
[10/24] Train loss=0.6174837946891785
[15/24] Train loss=0.5679014325141907
[20/24] Train loss=0.4702513515949249
Test set avg_accuracy=85.83% avg_sensitivity=86.17%, avg_specificity=85.72% avg_auc=93.65%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.569066 Test loss=0.315951 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.5540167689323425
[5/24] Train loss=0.576038122177124
[10/24] Train loss=0.6234511137008667
[15/24] Train loss=0.5592020153999329
[20/24] Train loss=0.47003284096717834
Test set avg_accuracy=85.83% avg_sensitivity=86.17%, avg_specificity=85.72% avg_auc=93.65%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.569135 Test loss=0.315911 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.5609791278839111
[5/24] Train loss=0.5603227615356445
[10/24] Train loss=0.618752121925354
[15/24] Train loss=0.5704129934310913
[20/24] Train loss=0.47661063075065613
Test set avg_accuracy=85.83% avg_sensitivity=86.17%, avg_specificity=85.72% avg_auc=93.65%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.568013 Test loss=0.315828 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.5565592646598816
[5/24] Train loss=0.5696970820426941
[10/24] Train loss=0.620042085647583
[15/24] Train loss=0.5715934038162231
[20/24] Train loss=0.46913519501686096
Test set avg_accuracy=85.83% avg_sensitivity=86.17%, avg_specificity=85.72% avg_auc=93.65%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.569092 Test loss=0.315839 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.5619218349456787
[5/24] Train loss=0.5726007223129272
[10/24] Train loss=0.6160138845443726
[15/24] Train loss=0.5688074827194214
[20/24] Train loss=0.4721030294895172
Test set avg_accuracy=85.83% avg_sensitivity=86.17%, avg_specificity=85.72% avg_auc=93.65%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.567117 Test loss=0.315840 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=85.78% sen=86.69%, spe=85.48%, auc=93.67%!
Fold[8] Avg_overlap=0.65%(±0.22012140929981622)
[0/23] Train loss=2.1810669898986816
[5/23] Train loss=1.6884870529174805
[10/23] Train loss=1.5472184419631958
[15/23] Train loss=1.5011297464370728
[20/23] Train loss=1.4616937637329102
Test set avg_accuracy=54.34% avg_sensitivity=53.80%, avg_specificity=54.51% avg_auc=56.38%
Best model saved!! Metric=-106.97261032920537!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=1.623392 Test loss=0.699634 Current lr=[1.23514552994466e-05]

[0/23] Train loss=1.4646660089492798
[5/23] Train loss=1.420755386352539
[10/23] Train loss=1.4200515747070312
[15/23] Train loss=1.405693531036377
[20/23] Train loss=1.4046971797943115
Test set avg_accuracy=53.67% avg_sensitivity=67.98%, avg_specificity=49.12% avg_auc=62.88%
Best model saved!! Metric=-92.35565759373227!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=1.418215 Test loss=0.687636 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=1.4094326496124268
[5/23] Train loss=1.3742597103118896
[10/23] Train loss=1.3780393600463867
[15/23] Train loss=1.3682644367218018
[20/23] Train loss=1.3652558326721191
Test set avg_accuracy=58.67% avg_sensitivity=69.43%, avg_specificity=55.24% avg_auc=67.38%
Best model saved!! Metric=-75.26507767401642!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=1.382169 Test loss=0.671361 Current lr=[1.515281266696464e-05]

[0/23] Train loss=1.392220139503479
[5/23] Train loss=1.3608630895614624
[10/23] Train loss=1.367640733718872
[15/23] Train loss=1.3393064737319946
[20/23] Train loss=1.3352763652801514
Test set avg_accuracy=64.58% avg_sensitivity=70.35%, avg_specificity=62.75% avg_auc=71.65%
Best model saved!! Metric=-56.666706577359236!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=1.354649 Test loss=0.658850 Current lr=[1.758904040319645e-05]

[0/23] Train loss=1.346178412437439
[5/23] Train loss=1.3357179164886475
[10/23] Train loss=1.333938717842102
[15/23] Train loss=1.3083786964416504
[20/23] Train loss=1.309064507484436
Test set avg_accuracy=65.74% avg_sensitivity=75.26%, avg_specificity=62.71% avg_auc=74.04%
Best model saved!! Metric=-48.247868374969634!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=1.331151 Test loss=0.652204 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=1.3039238452911377
[5/23] Train loss=1.2915561199188232
[10/23] Train loss=1.3051795959472656
[15/23] Train loss=1.289436936378479
[20/23] Train loss=1.2828840017318726
Test set avg_accuracy=68.65% avg_sensitivity=75.85%, avg_specificity=66.35% avg_auc=76.61%
Best model saved!! Metric=-38.546536204975155!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=1.295893 Test loss=0.639119 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=1.2918215990066528
[5/23] Train loss=1.2662465572357178
[10/23] Train loss=1.2763164043426514
[15/23] Train loss=1.247637152671814
[20/23] Train loss=1.2448493242263794
Test set avg_accuracy=70.98% avg_sensitivity=77.84%, avg_specificity=68.79% avg_auc=78.55%
Best model saved!! Metric=-29.837402771913276!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=1.267407 Test loss=0.622491 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=1.2384698390960693
[5/23] Train loss=1.2347438335418701
[10/23] Train loss=1.2482779026031494
[15/23] Train loss=1.2003685235977173
[20/23] Train loss=1.213732361793518
Test set avg_accuracy=72.46% avg_sensitivity=78.98%, avg_specificity=70.39% avg_auc=79.87%
Best model saved!! Metric=-24.308350932840114!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=1.230144 Test loss=0.603719 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=1.1943159103393555
[5/23] Train loss=1.1710792779922485
[10/23] Train loss=1.2129267454147339
[15/23] Train loss=1.1662236452102661
[20/23] Train loss=1.1572027206420898
Test set avg_accuracy=73.79% avg_sensitivity=81.99%, avg_specificity=71.18% avg_auc=81.45%
Best model saved!! Metric=-17.590829451922076!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=1.185522 Test loss=0.591503 Current lr=[3.955300715542903e-05]

[0/23] Train loss=1.1529018878936768
[5/23] Train loss=1.135733723640442
[10/23] Train loss=1.1789352893829346
[15/23] Train loss=1.110825777053833
[20/23] Train loss=1.1063225269317627
Test set avg_accuracy=74.27% avg_sensitivity=82.43%, avg_specificity=71.67% avg_auc=82.45%
Best model saved!! Metric=-15.183475286219434!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=1.142316 Test loss=0.575216 Current lr=[4.575212055041121e-05]

[0/23] Train loss=1.1128414869308472
[5/23] Train loss=1.0831412076950073
[10/23] Train loss=1.1212276220321655
[15/23] Train loss=1.0694541931152344
[20/23] Train loss=1.0872782468795776
Test set avg_accuracy=74.74% avg_sensitivity=84.15%, avg_specificity=71.74% avg_auc=83.28%
Best model saved!! Metric=-12.084862833504914!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=1.100799 Test loss=0.563936 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=1.0749026536941528
[5/23] Train loss=1.065373182296753
[10/23] Train loss=1.1039533615112305
[15/23] Train loss=1.0412318706512451
[20/23] Train loss=1.0289653539657593
Test set avg_accuracy=74.54% avg_sensitivity=85.61%, avg_specificity=71.02% avg_auc=83.82%
Best model saved!! Metric=-11.011441023034422!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=1.066062 Test loss=0.562586 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=1.042047142982483
[5/23] Train loss=1.0353562831878662
[10/23] Train loss=1.0862430334091187
[15/23] Train loss=0.9946445226669312
[20/23] Train loss=1.0146288871765137
Test set avg_accuracy=73.50% avg_sensitivity=88.36%, avg_specificity=68.77% avg_auc=84.46%
Best model saved!! Metric=-10.908362597559474!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=1.036645 Test loss=0.571189 Current lr=[6.744438065180833e-05]

[0/23] Train loss=1.028633952140808
[5/23] Train loss=1.0161200761795044
[10/23] Train loss=1.0526578426361084
[15/23] Train loss=0.9630006551742554
[20/23] Train loss=0.9599697589874268
Test set avg_accuracy=74.45% avg_sensitivity=88.30%, avg_specificity=70.04% avg_auc=84.97%
Best model saved!! Metric=-8.228989225559033!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=1.011453 Test loss=0.552238 Current lr=[7.558910265967854e-05]

[0/23] Train loss=1.000988245010376
[5/23] Train loss=0.9850361347198486
[10/23] Train loss=1.0362539291381836
[15/23] Train loss=0.963139533996582
[20/23] Train loss=0.9444810748100281
Test set avg_accuracy=75.57% avg_sensitivity=86.58%, avg_specificity=72.07% avg_auc=85.41%
Best model saved!! Metric=-6.3726752262569875!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.990739 Test loss=0.524555 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.9647979140281677
[5/23] Train loss=0.9737196564674377
[10/23] Train loss=1.0255826711654663
[15/23] Train loss=0.9319067001342773
[20/23] Train loss=0.9204258918762207
Test set avg_accuracy=74.93% avg_sensitivity=87.98%, avg_specificity=70.78% avg_auc=85.87%
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.971373 Test loss=0.529185 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.9634200930595398
[5/23] Train loss=0.9417024850845337
[10/23] Train loss=1.0110210180282593
[15/23] Train loss=0.9265903234481812
[20/23] Train loss=0.9135399460792542
Test set avg_accuracy=74.14% avg_sensitivity=88.89%, avg_specificity=69.44% avg_auc=86.24%
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.962947 Test loss=0.537109 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.9601626992225647
[5/23] Train loss=0.9313948750495911
[10/23] Train loss=0.9984618425369263
[15/23] Train loss=0.899040162563324
[20/23] Train loss=0.8805650472640991
Test set avg_accuracy=75.33% avg_sensitivity=87.71%, avg_specificity=71.38% avg_auc=86.45%
Best model saved!! Metric=-5.131709943016389!!
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.947359 Test loss=0.510507 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.9221037030220032
[5/23] Train loss=0.9404996633529663
[10/23] Train loss=1.0124404430389404
[15/23] Train loss=0.8837414383888245
[20/23] Train loss=0.8618414402008057
Test set avg_accuracy=75.85% avg_sensitivity=88.41%, avg_specificity=71.85% avg_auc=86.90%
Best model saved!! Metric=-2.9964393504486964!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.943712 Test loss=0.506183 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.9235928654670715
[5/23] Train loss=0.9153372049331665
[10/23] Train loss=0.9910798668861389
[15/23] Train loss=0.8754103183746338
[20/23] Train loss=0.8590713739395142
Test set avg_accuracy=75.85% avg_sensitivity=88.63%, avg_specificity=71.78% avg_auc=87.28%
Best model saved!! Metric=-2.470677866002262!!
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.934936 Test loss=0.502123 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.9042137861251831
[5/23] Train loss=0.9040272235870361
[10/23] Train loss=0.9770191311836243
[15/23] Train loss=0.8621825575828552
[20/23] Train loss=0.8470441699028015
Test set avg_accuracy=75.65% avg_sensitivity=89.00%, avg_specificity=71.40% avg_auc=87.74%
Best model saved!! Metric=-2.206432044333667!!
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.915357 Test loss=0.499186 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.8863401412963867
[5/23] Train loss=0.9076586961746216
[10/23] Train loss=0.9552690386772156
[15/23] Train loss=0.8326402306556702
[20/23] Train loss=0.8391683101654053
Test set avg_accuracy=78.33% avg_sensitivity=86.58%, avg_specificity=75.71% avg_auc=88.39%
Best model saved!! Metric=3.0102880896467212!!
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.902969 Test loss=0.450296 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.8663927912712097
[5/23] Train loss=0.8783066272735596
[10/23] Train loss=0.9385595321655273
[15/23] Train loss=0.8346484303474426
[20/23] Train loss=0.8352503776550293
Test set avg_accuracy=79.71% avg_sensitivity=83.13%, avg_specificity=78.63% avg_auc=88.85%
Best model saved!! Metric=4.318809878089226!!
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.889046 Test loss=0.414518 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.8304025530815125
[5/23] Train loss=0.8764731287956238
[10/23] Train loss=0.9307794570922852
[15/23] Train loss=0.8091580867767334
[20/23] Train loss=0.8009903430938721
Test set avg_accuracy=80.44% avg_sensitivity=81.73%, avg_specificity=80.03% avg_auc=89.07%
Best model saved!! Metric=5.274641514736089!!
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.872096 Test loss=0.404147 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.8197243213653564
[5/23] Train loss=0.8444215655326843
[10/23] Train loss=0.8839677572250366
[15/23] Train loss=0.7905850410461426
[20/23] Train loss=0.7854118943214417
Test set avg_accuracy=80.53% avg_sensitivity=82.91%, avg_specificity=79.78% avg_auc=89.15%
Best model saved!! Metric=6.373850464805329!!
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.851969 Test loss=0.408620 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.8167403340339661
[5/23] Train loss=0.8441177606582642
[10/23] Train loss=0.8890070915222168
[15/23] Train loss=0.7674808502197266
[20/23] Train loss=0.7661411762237549
Test set avg_accuracy=81.42% avg_sensitivity=82.37%, avg_specificity=81.12% avg_auc=89.60%
Best model saved!! Metric=8.50355990243088!!
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.841678 Test loss=0.397585 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.8337358236312866
[5/23] Train loss=0.8244161605834961
[10/23] Train loss=0.8940358757972717
[15/23] Train loss=0.7663249373435974
[20/23] Train loss=0.7650539875030518
Test set avg_accuracy=80.51% avg_sensitivity=86.63%, avg_specificity=78.56% avg_auc=89.87%
Best model saved!! Metric=9.566762328210487!!
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.835919 Test loss=0.421343 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.8122754693031311
[5/23] Train loss=0.8277252912521362
[10/23] Train loss=0.8762809634208679
[15/23] Train loss=0.7499703764915466
[20/23] Train loss=0.7478498816490173
Test set avg_accuracy=80.76% avg_sensitivity=86.79%, avg_specificity=78.83% avg_auc=90.36%
Best model saved!! Metric=10.742871880410604!!
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.823751 Test loss=0.417312 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.7877564430236816
[5/23] Train loss=0.815788209438324
[10/23] Train loss=0.8711729049682617
[15/23] Train loss=0.7261038422584534
[20/23] Train loss=0.7388617396354675
Test set avg_accuracy=79.22% avg_sensitivity=88.52%, avg_specificity=76.26% avg_auc=90.28%
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.818449 Test loss=0.443120 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.814734935760498
[5/23] Train loss=0.8130523562431335
[10/23] Train loss=0.8573448657989502
[15/23] Train loss=0.7382861971855164
[20/23] Train loss=0.7266259789466858
Test set avg_accuracy=81.56% avg_sensitivity=85.71%, avg_specificity=80.24% avg_auc=90.56%
Best model saved!! Metric=12.077373384773765!!
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.805829 Test loss=0.403180 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.7735849022865295
[5/23] Train loss=0.8133677840232849
[10/23] Train loss=0.871243953704834
[15/23] Train loss=0.7291749715805054
[20/23] Train loss=0.7173616886138916
Test set avg_accuracy=81.28% avg_sensitivity=85.23%, avg_specificity=80.02% avg_auc=90.38%
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.800843 Test loss=0.405432 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.7680546641349792
[5/23] Train loss=0.8046289086341858
[10/23] Train loss=0.85063636302948
[15/23] Train loss=0.734982430934906
[20/23] Train loss=0.731377363204956
Test set avg_accuracy=82.43% avg_sensitivity=83.45%, avg_specificity=82.11% avg_auc=90.52%
Best model saved!! Metric=12.518928085800255!!
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.794295 Test loss=0.384540 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.7625095248222351
[5/23] Train loss=0.8018659949302673
[10/23] Train loss=0.8463594317436218
[15/23] Train loss=0.7329173684120178
[20/23] Train loss=0.7406153082847595
Test set avg_accuracy=83.27% avg_sensitivity=81.67%, avg_specificity=83.78% avg_auc=90.42%
Best model saved!! Metric=13.137761690989066!!
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.789480 Test loss=0.373794 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.7841562628746033
[5/23] Train loss=0.8056507706642151
[10/23] Train loss=0.8144279718399048
[15/23] Train loss=0.7457023859024048
[20/23] Train loss=0.7365398406982422
Test set avg_accuracy=83.84% avg_sensitivity=79.51%, avg_specificity=85.22% avg_auc=90.59%
Best model saved!! Metric=13.168804521717561!!
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.785330 Test loss=0.359513 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.7567915916442871
[5/23] Train loss=0.7835337519645691
[10/23] Train loss=0.8566421270370483
[15/23] Train loss=0.7398189902305603
[20/23] Train loss=0.6877338886260986
Test set avg_accuracy=81.34% avg_sensitivity=85.98%, avg_specificity=79.86% avg_auc=91.00%
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.785927 Test loss=0.401564 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.7490127682685852
[5/23] Train loss=0.7850629687309265
[10/23] Train loss=0.8420510292053223
[15/23] Train loss=0.6925671100616455
[20/23] Train loss=0.6909008622169495
Test set avg_accuracy=81.07% avg_sensitivity=87.71%, avg_specificity=78.95% avg_auc=91.14%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.777138 Test loss=0.413015 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.7656825184822083
[5/23] Train loss=0.7648864388465881
[10/23] Train loss=0.8349276781082153
[15/23] Train loss=0.7003456354141235
[20/23] Train loss=0.6727159023284912
Test set avg_accuracy=81.81% avg_sensitivity=86.09%, avg_specificity=80.45% avg_auc=91.29%
Best model saved!! Metric=13.636463629453303!!
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.764590 Test loss=0.394044 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.7404136061668396
[5/23] Train loss=0.7625508308410645
[10/23] Train loss=0.8242470026016235
[15/23] Train loss=0.69526606798172
[20/23] Train loss=0.677567720413208
Test set avg_accuracy=81.63% avg_sensitivity=86.52%, avg_specificity=80.07% avg_auc=91.19%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.761692 Test loss=0.400908 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.7464063167572021
[5/23] Train loss=0.7686219811439514
[10/23] Train loss=0.8347449898719788
[15/23] Train loss=0.6867915391921997
[20/23] Train loss=0.6743565201759338
Test set avg_accuracy=82.24% avg_sensitivity=85.71%, avg_specificity=81.13% avg_auc=91.30%
Best model saved!! Metric=14.38822694820091!!
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.759977 Test loss=0.388746 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.731786847114563
[5/23] Train loss=0.764874279499054
[10/23] Train loss=0.8182536363601685
[15/23] Train loss=0.674698531627655
[20/23] Train loss=0.6604093313217163
Test set avg_accuracy=82.67% avg_sensitivity=85.55%, avg_specificity=81.75% avg_auc=91.44%
Best model saved!! Metric=15.412322323910914!!
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.751613 Test loss=0.380083 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.7240650653839111
[5/23] Train loss=0.768751859664917
[10/23] Train loss=0.8129994869232178
[15/23] Train loss=0.6846700310707092
[20/23] Train loss=0.6555693745613098
Test set avg_accuracy=82.98% avg_sensitivity=84.85%, avg_specificity=82.39% avg_auc=91.40%
Best model saved!! Metric=15.616098656291811!!
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.744858 Test loss=0.373217 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.7294297814369202
[5/23] Train loss=0.7658332586288452
[10/23] Train loss=0.812250554561615
[15/23] Train loss=0.6841219663619995
[20/23] Train loss=0.6728813648223877
Test set avg_accuracy=82.63% avg_sensitivity=84.69%, avg_specificity=81.97% avg_auc=91.24%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.747110 Test loss=0.378108 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.7342366576194763
[5/23] Train loss=0.7644474506378174
[10/23] Train loss=0.8184264302253723
[15/23] Train loss=0.690216600894928
[20/23] Train loss=0.6798067092895508
Test set avg_accuracy=83.54% avg_sensitivity=82.86%, avg_specificity=83.76% avg_auc=91.32%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.743817 Test loss=0.363077 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.7286766171455383
[5/23] Train loss=0.7451657652854919
[10/23] Train loss=0.8134069442749023
[15/23] Train loss=0.6894551515579224
[20/23] Train loss=0.6484123468399048
Test set avg_accuracy=84.11% avg_sensitivity=81.24%, avg_specificity=85.03% avg_auc=91.72%
Best model saved!! Metric=16.108590945285727!!
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.738035 Test loss=0.349882 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.7080513834953308
[5/23] Train loss=0.7398444414138794
[10/23] Train loss=0.8271846175193787
[15/23] Train loss=0.681410014629364
[20/23] Train loss=0.6432925462722778
Test set avg_accuracy=83.44% avg_sensitivity=84.37%, avg_specificity=83.14% avg_auc=91.76%
Best model saved!! Metric=16.70292114456926!!
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.738270 Test loss=0.364572 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.719073474407196
[5/23] Train loss=0.7349736094474792
[10/23] Train loss=0.808232307434082
[15/23] Train loss=0.6622777581214905
[20/23] Train loss=0.6336280107498169
Test set avg_accuracy=82.57% avg_sensitivity=86.79%, avg_specificity=81.22% avg_auc=91.77%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.732341 Test loss=0.385504 Current lr=[0.000299926900870094]

[0/23] Train loss=0.7320379018783569
[5/23] Train loss=0.7412342429161072
[10/23] Train loss=0.8074741363525391
[15/23] Train loss=0.6531149744987488
[20/23] Train loss=0.6267750263214111
Test set avg_accuracy=82.84% avg_sensitivity=86.42%, avg_specificity=81.70% avg_auc=91.83%
Best model saved!! Metric=16.787705855785518!!
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.725325 Test loss=0.378410 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.7301182746887207
[5/23] Train loss=0.7289689183235168
[10/23] Train loss=0.8218685388565063
[15/23] Train loss=0.6649986505508423
[20/23] Train loss=0.6322163343429565
Test set avg_accuracy=83.61% avg_sensitivity=84.04%, avg_specificity=83.47% avg_auc=91.86%
Best model saved!! Metric=16.979684776625433!!
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.720160 Test loss=0.359528 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.704627513885498
[5/23] Train loss=0.7295199036598206
[10/23] Train loss=0.8129791021347046
[15/23] Train loss=0.6669021844863892
[20/23] Train loss=0.6334080100059509
Test set avg_accuracy=83.35% avg_sensitivity=84.58%, avg_specificity=82.95% avg_auc=91.84%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.720136 Test loss=0.363278 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.705653965473175
[5/23] Train loss=0.7290573120117188
[10/23] Train loss=0.8089639544487
[15/23] Train loss=0.6554406881332397
[20/23] Train loss=0.6313474178314209
Test set avg_accuracy=83.35% avg_sensitivity=84.58%, avg_specificity=82.95% avg_auc=91.77%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.717065 Test loss=0.366874 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.712530791759491
[5/23] Train loss=0.7322909235954285
[10/23] Train loss=0.823333203792572
[15/23] Train loss=0.6580249071121216
[20/23] Train loss=0.6327917575836182
Test set avg_accuracy=83.59% avg_sensitivity=84.26%, avg_specificity=83.38% avg_auc=91.95%
Best model saved!! Metric=17.187970468979557!!
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.716185 Test loss=0.360623 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.7029988169670105
[5/23] Train loss=0.7260511517524719
[10/23] Train loss=0.8024475574493408
[15/23] Train loss=0.6528626084327698
[20/23] Train loss=0.6255313754081726
Test set avg_accuracy=83.74% avg_sensitivity=83.45%, avg_specificity=83.83% avg_auc=91.94%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.711130 Test loss=0.355836 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.7085402011871338
[5/23] Train loss=0.7165329456329346
[10/23] Train loss=0.8143390417098999
[15/23] Train loss=0.6424933671951294
[20/23] Train loss=0.6244580149650574
Test set avg_accuracy=83.82% avg_sensitivity=83.77%, avg_specificity=83.83% avg_auc=92.01%
Best model saved!! Metric=17.423641584387028!!
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.709605 Test loss=0.355279 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.697888195514679
[5/23] Train loss=0.726972222328186
[10/23] Train loss=0.7988235950469971
[15/23] Train loss=0.6476916074752808
[20/23] Train loss=0.632169246673584
Test set avg_accuracy=83.63% avg_sensitivity=84.37%, avg_specificity=83.40% avg_auc=92.01%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.710300 Test loss=0.359875 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.6894169449806213
[5/23] Train loss=0.7154214978218079
[10/23] Train loss=0.810906171798706
[15/23] Train loss=0.6349200010299683
[20/23] Train loss=0.6207202076911926
Test set avg_accuracy=83.27% avg_sensitivity=85.98%, avg_specificity=82.40% avg_auc=91.98%
Best model saved!! Metric=17.636462569024275!!
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.706322 Test loss=0.369996 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.6913052201271057
[5/23] Train loss=0.7154271006584167
[10/23] Train loss=0.8007423877716064
[15/23] Train loss=0.6357504725456238
[20/23] Train loss=0.6086238622665405
Test set avg_accuracy=83.65% avg_sensitivity=84.58%, avg_specificity=83.35% avg_auc=92.12%
Best model saved!! Metric=17.695438275318224!!
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.700982 Test loss=0.360156 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.6900595426559448
[5/23] Train loss=0.6983383297920227
[10/23] Train loss=0.7914060354232788
[15/23] Train loss=0.6306722164154053
[20/23] Train loss=0.6157549619674683
Test set avg_accuracy=84.02% avg_sensitivity=83.23%, avg_specificity=84.27% avg_auc=92.11%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.694134 Test loss=0.351646 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.6858007907867432
[5/23] Train loss=0.7141588926315308
[10/23] Train loss=0.7962571382522583
[15/23] Train loss=0.6342700719833374
[20/23] Train loss=0.6118775010108948
Test set avg_accuracy=83.68% avg_sensitivity=84.26%, avg_specificity=83.50% avg_auc=92.07%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.695458 Test loss=0.358713 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.6986744999885559
[5/23] Train loss=0.7089903950691223
[10/23] Train loss=0.7857789397239685
[15/23] Train loss=0.6201924681663513
[20/23] Train loss=0.6103457808494568
Test set avg_accuracy=83.57% avg_sensitivity=83.94%, avg_specificity=83.45% avg_auc=92.18%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.693078 Test loss=0.356023 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.6874619126319885
[5/23] Train loss=0.7042355537414551
[10/23] Train loss=0.7915339469909668
[15/23] Train loss=0.628430962562561
[20/23] Train loss=0.6043328642845154
Test set avg_accuracy=83.93% avg_sensitivity=83.23%, avg_specificity=84.15% avg_auc=92.24%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.688673 Test loss=0.348708 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.6903597116470337
[5/23] Train loss=0.7047972679138184
[10/23] Train loss=0.7840126156806946
[15/23] Train loss=0.6246063113212585
[20/23] Train loss=0.6042295694351196
Test set avg_accuracy=83.84% avg_sensitivity=83.13%, avg_specificity=84.07% avg_auc=92.27%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.686667 Test loss=0.350248 Current lr=[0.000283047938381597]

[0/23] Train loss=0.6802600026130676
[5/23] Train loss=0.700801432132721
[10/23] Train loss=0.7802433371543884
[15/23] Train loss=0.6070762872695923
[20/23] Train loss=0.6032572984695435
Test set avg_accuracy=83.79% avg_sensitivity=83.23%, avg_specificity=83.97% avg_auc=92.21%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.684183 Test loss=0.351977 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.684808611869812
[5/23] Train loss=0.7019243836402893
[10/23] Train loss=0.7911046743392944
[15/23] Train loss=0.6156893372535706
[20/23] Train loss=0.599273145198822
Test set avg_accuracy=83.95% avg_sensitivity=83.23%, avg_specificity=84.17% avg_auc=92.32%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.682418 Test loss=0.349805 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.685489296913147
[5/23] Train loss=0.7002191543579102
[10/23] Train loss=0.7912985682487488
[15/23] Train loss=0.6141946315765381
[20/23] Train loss=0.60203617811203
Test set avg_accuracy=84.13% avg_sensitivity=82.05%, avg_specificity=84.79% avg_auc=92.30%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.682455 Test loss=0.343244 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.6819118857383728
[5/23] Train loss=0.698494553565979
[10/23] Train loss=0.7734881639480591
[15/23] Train loss=0.6145089268684387
[20/23] Train loss=0.5925143361091614
Test set avg_accuracy=83.92% avg_sensitivity=82.91%, avg_specificity=84.24% avg_auc=92.32%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.681100 Test loss=0.348690 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.6817155480384827
[5/23] Train loss=0.6874653697013855
[10/23] Train loss=0.7902548909187317
[15/23] Train loss=0.6096835136413574
[20/23] Train loss=0.6101031303405762
Test set avg_accuracy=84.02% avg_sensitivity=82.91%, avg_specificity=84.38% avg_auc=92.30%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.679221 Test loss=0.346087 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.6727946996688843
[5/23] Train loss=0.684557318687439
[10/23] Train loss=0.7822486162185669
[15/23] Train loss=0.6088997721672058
[20/23] Train loss=0.5866825580596924
Test set avg_accuracy=83.83% avg_sensitivity=84.37%, avg_specificity=83.66% avg_auc=92.33%
Best model saved!! Metric=18.17676630120428!!
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.675625 Test loss=0.354778 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.6724073886871338
[5/23] Train loss=0.6832086443901062
[10/23] Train loss=0.7860944867134094
[15/23] Train loss=0.6075617671012878
[20/23] Train loss=0.5999169945716858
Test set avg_accuracy=83.70% avg_sensitivity=84.74%, avg_specificity=83.36% avg_auc=92.36%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.672703 Test loss=0.356606 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.6767129898071289
[5/23] Train loss=0.6776697635650635
[10/23] Train loss=0.7854744791984558
[15/23] Train loss=0.5933099985122681
[20/23] Train loss=0.5749709010124207
Test set avg_accuracy=84.27% avg_sensitivity=82.10%, avg_specificity=84.96% avg_auc=92.32%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.668586 Test loss=0.342992 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.6611051559448242
[5/23] Train loss=0.6732545495033264
[10/23] Train loss=0.7877219319343567
[15/23] Train loss=0.6020113825798035
[20/23] Train loss=0.5835649371147156
Test set avg_accuracy=83.97% avg_sensitivity=83.29%, avg_specificity=84.19% avg_auc=92.44%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.667183 Test loss=0.348129 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.6613361835479736
[5/23] Train loss=0.6717817783355713
[10/23] Train loss=0.7716094255447388
[15/23] Train loss=0.5994125604629517
[20/23] Train loss=0.5808476805686951
Test set avg_accuracy=84.32% avg_sensitivity=83.40%, avg_specificity=84.62% avg_auc=92.55%
Best model saved!! Metric=18.883831951883536!!
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.666114 Test loss=0.344508 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.6595404744148254
[5/23] Train loss=0.6855490207672119
[10/23] Train loss=0.7667250633239746
[15/23] Train loss=0.6000856161117554
[20/23] Train loss=0.5735002160072327
Test set avg_accuracy=84.26% avg_sensitivity=83.29%, avg_specificity=84.57% avg_auc=92.49%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.665058 Test loss=0.345392 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.6603788733482361
[5/23] Train loss=0.6725003123283386
[10/23] Train loss=0.7756662964820862
[15/23] Train loss=0.5827468037605286
[20/23] Train loss=0.5848725438117981
Test set avg_accuracy=84.35% avg_sensitivity=82.43%, avg_specificity=84.96% avg_auc=92.43%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.660361 Test loss=0.342168 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.6549601554870605
[5/23] Train loss=0.6665688753128052
[10/23] Train loss=0.7815628051757812
[15/23] Train loss=0.5962598919868469
[20/23] Train loss=0.5921292901039124
Test set avg_accuracy=84.70% avg_sensitivity=82.48%, avg_specificity=85.41% avg_auc=92.50%
Best model saved!! Metric=19.08347838917939!!
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.661575 Test loss=0.337956 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.653100311756134
[5/23] Train loss=0.6660502552986145
[10/23] Train loss=0.7842978835105896
[15/23] Train loss=0.6042395234107971
[20/23] Train loss=0.5763112902641296
Test set avg_accuracy=84.30% avg_sensitivity=83.72%, avg_specificity=84.48% avg_auc=92.47%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.660529 Test loss=0.346321 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.6516455411911011
[5/23] Train loss=0.664023756980896
[10/23] Train loss=0.7472311854362488
[15/23] Train loss=0.5996276140213013
[20/23] Train loss=0.5783324241638184
Test set avg_accuracy=84.64% avg_sensitivity=82.32%, avg_specificity=85.37% avg_auc=92.47%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.657708 Test loss=0.339861 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.6582808494567871
[5/23] Train loss=0.6761454343795776
[10/23] Train loss=0.7675489187240601
[15/23] Train loss=0.5840859413146973
[20/23] Train loss=0.5711250305175781
Test set avg_accuracy=84.23% avg_sensitivity=83.56%, avg_specificity=84.45% avg_auc=92.47%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.659118 Test loss=0.347199 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.6549111008644104
[5/23] Train loss=0.6704236268997192
[10/23] Train loss=0.7591187953948975
[15/23] Train loss=0.5879712700843811
[20/23] Train loss=0.5625060200691223
Test set avg_accuracy=84.70% avg_sensitivity=82.64%, avg_specificity=85.36% avg_auc=92.57%
Best model saved!! Metric=19.27231959089613!!
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.654731 Test loss=0.337378 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.6519972681999207
[5/23] Train loss=0.6724698543548584
[10/23] Train loss=0.7628822922706604
[15/23] Train loss=0.5790171027183533
[20/23] Train loss=0.5693004727363586
Test set avg_accuracy=84.78% avg_sensitivity=82.64%, avg_specificity=85.46% avg_auc=92.53%
Best model saved!! Metric=19.409174621089434!!
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.656343 Test loss=0.338867 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.6481428742408752
[5/23] Train loss=0.6651840806007385
[10/23] Train loss=0.7639633417129517
[15/23] Train loss=0.5905328392982483
[20/23] Train loss=0.5720190405845642
Test set avg_accuracy=84.47% avg_sensitivity=83.29%, avg_specificity=84.84% avg_auc=92.55%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.655732 Test loss=0.341557 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.6533540487289429
[5/23] Train loss=0.6619817614555359
[10/23] Train loss=0.7584511041641235
[15/23] Train loss=0.57912677526474
[20/23] Train loss=0.5685633420944214
Test set avg_accuracy=84.45% avg_sensitivity=83.88%, avg_specificity=84.64% avg_auc=92.56%
Best model saved!! Metric=19.52823808029568!!
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.651042 Test loss=0.346739 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.6549644470214844
[5/23] Train loss=0.6586035490036011
[10/23] Train loss=0.7506409287452698
[15/23] Train loss=0.5891790986061096
[20/23] Train loss=0.5673388838768005
Test set avg_accuracy=84.02% avg_sensitivity=85.39%, avg_specificity=83.59% avg_auc=92.60%
Best model saved!! Metric=19.60212403332254!!
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.655428 Test loss=0.354343 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.6536266803741455
[5/23] Train loss=0.6690018177032471
[10/23] Train loss=0.761566698551178
[15/23] Train loss=0.6144583821296692
[20/23] Train loss=0.5705985426902771
Test set avg_accuracy=81.91% avg_sensitivity=89.92%, avg_specificity=79.36% avg_auc=92.53%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.661575 Test loss=0.403789 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.6900122761726379
[5/23] Train loss=0.6575320959091187
[10/23] Train loss=0.748904287815094
[15/23] Train loss=0.635000467300415
[20/23] Train loss=0.5951603651046753
Test set avg_accuracy=81.91% avg_sensitivity=90.35%, avg_specificity=79.23% avg_auc=92.51%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.663293 Test loss=0.409035 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.6819225549697876
[5/23] Train loss=0.6883442401885986
[10/23] Train loss=0.7645418047904968
[15/23] Train loss=0.6023001670837402
[20/23] Train loss=0.5670654773712158
Test set avg_accuracy=83.05% avg_sensitivity=88.63%, avg_specificity=81.27% avg_auc=92.66%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.650196 Test loss=0.387438 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.6736571788787842
[5/23] Train loss=0.643653392791748
[10/23] Train loss=0.7466761469841003
[15/23] Train loss=0.5949938893318176
[20/23] Train loss=0.5641187429428101
Test set avg_accuracy=82.46% avg_sensitivity=89.38%, avg_specificity=80.26% avg_auc=92.58%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.646890 Test loss=0.397234 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.6783052682876587
[5/23] Train loss=0.6584095358848572
[10/23] Train loss=0.7451937794685364
[15/23] Train loss=0.6098484396934509
[20/23] Train loss=0.5731093883514404
Test set avg_accuracy=82.59% avg_sensitivity=89.22%, avg_specificity=80.48% avg_auc=92.63%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.647166 Test loss=0.394426 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.6680988669395447
[5/23] Train loss=0.6594312787055969
[10/23] Train loss=0.7399115562438965
[15/23] Train loss=0.5921903252601624
[20/23] Train loss=0.5564038753509521
Test set avg_accuracy=83.05% avg_sensitivity=88.14%, avg_specificity=81.42% avg_auc=92.63%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.644467 Test loss=0.384360 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.6627288460731506
[5/23] Train loss=0.6542099118232727
[10/23] Train loss=0.7445895075798035
[15/23] Train loss=0.5834276080131531
[20/23] Train loss=0.5571075081825256
Test set avg_accuracy=82.68% avg_sensitivity=88.52%, avg_specificity=80.82% avg_auc=92.68%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.639982 Test loss=0.387237 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.6701800227165222
[5/23] Train loss=0.6508469581604004
[10/23] Train loss=0.7363797426223755
[15/23] Train loss=0.5886168479919434
[20/23] Train loss=0.5590217709541321
Test set avg_accuracy=82.68% avg_sensitivity=88.89%, avg_specificity=80.70% avg_auc=92.73%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.640071 Test loss=0.388841 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.6678076982498169
[5/23] Train loss=0.6625204086303711
[10/23] Train loss=0.7324798703193665
[15/23] Train loss=0.5930039882659912
[20/23] Train loss=0.5841353535652161
Test set avg_accuracy=82.88% avg_sensitivity=88.57%, avg_specificity=81.06% avg_auc=92.72%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.642835 Test loss=0.385371 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.6696998476982117
[5/23] Train loss=0.6425017714500427
[10/23] Train loss=0.7338387966156006
[15/23] Train loss=0.5854766964912415
[20/23] Train loss=0.5455252528190613
Test set avg_accuracy=83.55% avg_sensitivity=87.01%, avg_specificity=82.45% avg_auc=92.73%
Best model saved!! Metric=19.746272706436613!!
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.636487 Test loss=0.370291 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.6495302319526672
[5/23] Train loss=0.6438749432563782
[10/23] Train loss=0.741970956325531
[15/23] Train loss=0.5714477300643921
[20/23] Train loss=0.5559086203575134
Test set avg_accuracy=83.02% avg_sensitivity=88.73%, avg_specificity=81.20% avg_auc=92.86%
Best model saved!! Metric=19.820018923838063!!
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.634749 Test loss=0.381173 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.6527271866798401
[5/23] Train loss=0.6416330933570862
[10/23] Train loss=0.7308449745178223
[15/23] Train loss=0.5800405144691467
[20/23] Train loss=0.5602355003356934
Test set avg_accuracy=83.05% avg_sensitivity=88.36%, avg_specificity=81.36% avg_auc=92.81%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.634029 Test loss=0.380538 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.6580199003219604
[5/23] Train loss=0.6391943097114563
[10/23] Train loss=0.7238136529922485
[15/23] Train loss=0.5838227868080139
[20/23] Train loss=0.5563743710517883
Test set avg_accuracy=83.23% avg_sensitivity=88.41%, avg_specificity=81.58% avg_auc=92.90%
Best model saved!! Metric=20.118848885007097!!
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.630805 Test loss=0.375861 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.6486096382141113
[5/23] Train loss=0.6465773582458496
[10/23] Train loss=0.7453298568725586
[15/23] Train loss=0.5751706957817078
[20/23] Train loss=0.5556159615516663
Test set avg_accuracy=83.72% avg_sensitivity=87.44%, avg_specificity=82.54% avg_auc=92.91%
Best model saved!! Metric=20.617323903709178!!
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.629050 Test loss=0.364443 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.6479578018188477
[5/23] Train loss=0.6324960589408875
[10/23] Train loss=0.723884642124176
[15/23] Train loss=0.572259783744812
[20/23] Train loss=0.5467389225959778
Test set avg_accuracy=83.33% avg_sensitivity=87.98%, avg_specificity=81.85% avg_auc=92.89%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.626413 Test loss=0.371336 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.6453438401222229
[5/23] Train loss=0.6386569142341614
[10/23] Train loss=0.7284902930259705
[15/23] Train loss=0.5654706954956055
[20/23] Train loss=0.5630953907966614
Test set avg_accuracy=83.12% avg_sensitivity=88.68%, avg_specificity=81.36% avg_auc=92.94%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.626329 Test loss=0.378994 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.6650965809822083
[5/23] Train loss=0.6336361765861511
[10/23] Train loss=0.7259904742240906
[15/23] Train loss=0.5639303922653198
[20/23] Train loss=0.5480689406394958
Test set avg_accuracy=83.15% avg_sensitivity=88.73%, avg_specificity=81.37% avg_auc=93.00%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.627784 Test loss=0.376831 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.6551461219787598
[5/23] Train loss=0.6261137127876282
[10/23] Train loss=0.7198925018310547
[15/23] Train loss=0.5606793761253357
[20/23] Train loss=0.5503078103065491
Test set avg_accuracy=83.37% avg_sensitivity=87.39%, avg_specificity=82.09% avg_auc=92.96%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.623639 Test loss=0.365884 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.6427435874938965
[5/23] Train loss=0.631397545337677
[10/23] Train loss=0.7299453020095825
[15/23] Train loss=0.5606500506401062
[20/23] Train loss=0.5400907397270203
Test set avg_accuracy=83.11% avg_sensitivity=88.19%, avg_specificity=81.49% avg_auc=93.02%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.622756 Test loss=0.373028 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.6489662528038025
[5/23] Train loss=0.6275597810745239
[10/23] Train loss=0.7298148274421692
[15/23] Train loss=0.5614278316497803
[20/23] Train loss=0.5431882739067078
Test set avg_accuracy=83.32% avg_sensitivity=88.03%, avg_specificity=81.82% avg_auc=93.05%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.621049 Test loss=0.369352 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.6413559317588806
[5/23] Train loss=0.6231479048728943
[10/23] Train loss=0.7255366444587708
[15/23] Train loss=0.5543867945671082
[20/23] Train loss=0.5473021268844604
Test set avg_accuracy=83.33% avg_sensitivity=88.25%, avg_specificity=81.77% avg_auc=93.07%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.618924 Test loss=0.369294 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.6538162231445312
[5/23] Train loss=0.6398463249206543
[10/23] Train loss=0.712187647819519
[15/23] Train loss=0.5547817945480347
[20/23] Train loss=0.5405727028846741
Test set avg_accuracy=82.70% avg_sensitivity=89.70%, avg_specificity=80.46% avg_auc=93.02%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.620162 Test loss=0.384580 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.6406064629554749
[5/23] Train loss=0.6252642869949341
[10/23] Train loss=0.7246867418289185
[15/23] Train loss=0.5602779388427734
[20/23] Train loss=0.5542351007461548
Test set avg_accuracy=83.05% avg_sensitivity=88.63%, avg_specificity=81.27% avg_auc=93.04%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.620645 Test loss=0.375413 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.6431152820587158
[5/23] Train loss=0.6317059397697449
[10/23] Train loss=0.7293190360069275
[15/23] Train loss=0.5638928413391113
[20/23] Train loss=0.5354675650596619
Test set avg_accuracy=82.67% avg_sensitivity=89.43%, avg_specificity=80.52% avg_auc=93.07%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.619172 Test loss=0.383596 Current lr=[0.000112073915556435]

[0/23] Train loss=0.640946626663208
[5/23] Train loss=0.6223561763763428
[10/23] Train loss=0.7251428365707397
[15/23] Train loss=0.5566819310188293
[20/23] Train loss=0.5342710018157959
Test set avg_accuracy=82.10% avg_sensitivity=90.84%, avg_specificity=79.31% avg_auc=93.08%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.621598 Test loss=0.396485 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.6556842923164368
[5/23] Train loss=0.6364489793777466
[10/23] Train loss=0.7307409048080444
[15/23] Train loss=0.5588813424110413
[20/23] Train loss=0.5441522002220154
Test set avg_accuracy=81.91% avg_sensitivity=90.94%, avg_specificity=79.04% avg_auc=93.10%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.624841 Test loss=0.400609 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.6618619561195374
[5/23] Train loss=0.6366381645202637
[10/23] Train loss=0.7294015288352966
[15/23] Train loss=0.5723717212677002
[20/23] Train loss=0.567055344581604
Test set avg_accuracy=82.02% avg_sensitivity=90.19%, avg_specificity=79.42% avg_auc=93.11%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.629485 Test loss=0.394571 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.6627317070960999
[5/23] Train loss=0.6452399492263794
[10/23] Train loss=0.7327797412872314
[15/23] Train loss=0.5916852355003357
[20/23] Train loss=0.5742923617362976
Test set avg_accuracy=83.52% avg_sensitivity=87.87%, avg_specificity=82.13% avg_auc=92.96%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.631143 Test loss=0.361710 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.6402548551559448
[5/23] Train loss=0.6227467060089111
[10/23] Train loss=0.74483323097229
[15/23] Train loss=0.5931551456451416
[20/23] Train loss=0.5721191167831421
Test set avg_accuracy=84.93% avg_sensitivity=85.82%, avg_specificity=84.65% avg_auc=92.97%
Best model saved!! Metric=22.374961541372144!!
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.625960 Test loss=0.338235 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.6344744563102722
[5/23] Train loss=0.6131443381309509
[10/23] Train loss=0.7197939157485962
[15/23] Train loss=0.5849465727806091
[20/23] Train loss=0.5485748648643494
Test set avg_accuracy=84.97% avg_sensitivity=84.96%, avg_specificity=84.98% avg_auc=93.14%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.614226 Test loss=0.334696 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.6189847588539124
[5/23] Train loss=0.6053929924964905
[10/23] Train loss=0.713982105255127
[15/23] Train loss=0.5767456889152527
[20/23] Train loss=0.5504910945892334
Test set avg_accuracy=84.96% avg_sensitivity=84.58%, avg_specificity=85.08% avg_auc=93.18%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.610735 Test loss=0.332380 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.6218794584274292
[5/23] Train loss=0.60406893491745
[10/23] Train loss=0.7092642188072205
[15/23] Train loss=0.5686029195785522
[20/23] Train loss=0.5473119616508484
Test set avg_accuracy=84.86% avg_sensitivity=84.96%, avg_specificity=84.82% avg_auc=93.16%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.606529 Test loss=0.334653 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.6184676289558411
[5/23] Train loss=0.6012848019599915
[10/23] Train loss=0.7090328335762024
[15/23] Train loss=0.5634979605674744
[20/23] Train loss=0.5490443110466003
Test set avg_accuracy=84.62% avg_sensitivity=85.93%, avg_specificity=84.21% avg_auc=93.15%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.607281 Test loss=0.340522 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.6134980320930481
[5/23] Train loss=0.5995398759841919
[10/23] Train loss=0.7037603855133057
[15/23] Train loss=0.569133460521698
[20/23] Train loss=0.5390446782112122
Test set avg_accuracy=85.04% avg_sensitivity=84.80%, avg_specificity=85.12% avg_auc=93.20%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.603386 Test loss=0.333150 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.6185191869735718
[5/23] Train loss=0.5999692678451538
[10/23] Train loss=0.7023360133171082
[15/23] Train loss=0.5628935694694519
[20/23] Train loss=0.5384880304336548
Test set avg_accuracy=84.95% avg_sensitivity=85.12%, avg_specificity=84.89% avg_auc=93.23%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.604560 Test loss=0.333736 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.6106914281845093
[5/23] Train loss=0.6064664125442505
[10/23] Train loss=0.6926077604293823
[15/23] Train loss=0.5646685361862183
[20/23] Train loss=0.5387693047523499
Test set avg_accuracy=84.73% avg_sensitivity=85.28%, avg_specificity=84.55% avg_auc=93.17%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.605012 Test loss=0.338010 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.6126572489738464
[5/23] Train loss=0.6000841856002808
[10/23] Train loss=0.6933145523071289
[15/23] Train loss=0.5595821738243103
[20/23] Train loss=0.5385105013847351
Test set avg_accuracy=85.08% avg_sensitivity=84.74%, avg_specificity=85.18% avg_auc=93.23%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.600458 Test loss=0.332033 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.6197795271873474
[5/23] Train loss=0.5958369374275208
[10/23] Train loss=0.7082372307777405
[15/23] Train loss=0.5445600152015686
[20/23] Train loss=0.5353479385375977
Test set avg_accuracy=84.86% avg_sensitivity=84.74%, avg_specificity=84.89% avg_auc=93.24%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.601764 Test loss=0.333258 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.6131490468978882
[5/23] Train loss=0.5929569602012634
[10/23] Train loss=0.7087095975875854
[15/23] Train loss=0.5640496611595154
[20/23] Train loss=0.539604127407074
Test set avg_accuracy=84.78% avg_sensitivity=84.96%, avg_specificity=84.72% avg_auc=93.25%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.601048 Test loss=0.333926 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.6167308688163757
[5/23] Train loss=0.5886500477790833
[10/23] Train loss=0.7046699523925781
[15/23] Train loss=0.552681565284729
[20/23] Train loss=0.5459858179092407
Test set avg_accuracy=84.70% avg_sensitivity=85.34%, avg_specificity=84.50% avg_auc=93.18%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.600515 Test loss=0.337536 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.6161506175994873
[5/23] Train loss=0.6005590558052063
[10/23] Train loss=0.7151014804840088
[15/23] Train loss=0.5635035037994385
[20/23] Train loss=0.5357269644737244
Test set avg_accuracy=85.21% avg_sensitivity=84.15%, avg_specificity=85.55% avg_auc=93.17%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.600027 Test loss=0.330465 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.6068474054336548
[5/23] Train loss=0.5830250978469849
[10/23] Train loss=0.698016881942749
[15/23] Train loss=0.5543777346611023
[20/23] Train loss=0.5342259407043457
Test set avg_accuracy=84.71% avg_sensitivity=85.34%, avg_specificity=84.52% avg_auc=93.25%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.598514 Test loss=0.335731 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.6041549444198608
[5/23] Train loss=0.5869415402412415
[10/23] Train loss=0.703323483467102
[15/23] Train loss=0.5499493479728699
[20/23] Train loss=0.5273059606552124
Test set avg_accuracy=84.74% avg_sensitivity=84.80%, avg_specificity=84.72% avg_auc=93.22%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.598407 Test loss=0.334491 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.6220664381980896
[5/23] Train loss=0.5968499183654785
[10/23] Train loss=0.7147067189216614
[15/23] Train loss=0.5554744601249695
[20/23] Train loss=0.5426204800605774
Test set avg_accuracy=84.95% avg_sensitivity=84.58%, avg_specificity=85.06% avg_auc=93.21%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.598175 Test loss=0.332283 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.609067440032959
[5/23] Train loss=0.5978254079818726
[10/23] Train loss=0.6995717883110046
[15/23] Train loss=0.5406333208084106
[20/23] Train loss=0.5325697660446167
Test set avg_accuracy=84.80% avg_sensitivity=84.85%, avg_specificity=84.79% avg_auc=93.24%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.595617 Test loss=0.334001 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.5974463224411011
[5/23] Train loss=0.5984757542610168
[10/23] Train loss=0.6965140104293823
[15/23] Train loss=0.5457990169525146
[20/23] Train loss=0.5369851589202881
Test set avg_accuracy=84.56% avg_sensitivity=85.88%, avg_specificity=84.14% avg_auc=93.25%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.595986 Test loss=0.338780 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.6068882346153259
[5/23] Train loss=0.5942987203598022
[10/23] Train loss=0.7150830030441284
[15/23] Train loss=0.547553300857544
[20/23] Train loss=0.5334854125976562
Test set avg_accuracy=84.80% avg_sensitivity=84.85%, avg_specificity=84.79% avg_auc=93.23%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.596677 Test loss=0.334592 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.6125767230987549
[5/23] Train loss=0.5952242016792297
[10/23] Train loss=0.6994863152503967
[15/23] Train loss=0.5404161214828491
[20/23] Train loss=0.5230206847190857
Test set avg_accuracy=84.67% avg_sensitivity=85.01%, avg_specificity=84.57% avg_auc=93.23%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.595671 Test loss=0.334224 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.6150625944137573
[5/23] Train loss=0.5779188871383667
[10/23] Train loss=0.7145351767539978
[15/23] Train loss=0.5477156043052673
[20/23] Train loss=0.5314117670059204
Test set avg_accuracy=84.80% avg_sensitivity=85.28%, avg_specificity=84.65% avg_auc=93.22%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.594937 Test loss=0.335735 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.6109254360198975
[5/23] Train loss=0.5860108733177185
[10/23] Train loss=0.6960777640342712
[15/23] Train loss=0.5397678017616272
[20/23] Train loss=0.533656656742096
Test set avg_accuracy=84.96% avg_sensitivity=85.07%, avg_specificity=84.93% avg_auc=93.20%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.594676 Test loss=0.332975 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.6056416034698486
[5/23] Train loss=0.5917602777481079
[10/23] Train loss=0.7088283896446228
[15/23] Train loss=0.5477827191352844
[20/23] Train loss=0.5297666788101196
Test set avg_accuracy=85.17% avg_sensitivity=84.58%, avg_specificity=85.36% avg_auc=93.18%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.593448 Test loss=0.329997 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.6058375239372253
[5/23] Train loss=0.5820223093032837
[10/23] Train loss=0.7075989246368408
[15/23] Train loss=0.5443894863128662
[20/23] Train loss=0.545819103717804
Test set avg_accuracy=85.48% avg_sensitivity=83.88%, avg_specificity=85.99% avg_auc=93.20%
Best model saved!! Metric=22.555648417406076!!
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.596372 Test loss=0.324462 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.6118730306625366
[5/23] Train loss=0.5911986231803894
[10/23] Train loss=0.6852623820304871
[15/23] Train loss=0.5473659038543701
[20/23] Train loss=0.53644198179245
Test set avg_accuracy=85.65% avg_sensitivity=83.56%, avg_specificity=86.32% avg_auc=93.22%
Best model saved!! Metric=22.74234576300759!!
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.592046 Test loss=0.322008 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.6062473654747009
[5/23] Train loss=0.5817819237709045
[10/23] Train loss=0.6988584399223328
[15/23] Train loss=0.5408275723457336
[20/23] Train loss=0.5293921232223511
Test set avg_accuracy=85.66% avg_sensitivity=83.40%, avg_specificity=86.39% avg_auc=93.22%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.590298 Test loss=0.321712 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.5937687158584595
[5/23] Train loss=0.5835341215133667
[10/23] Train loss=0.7151774168014526
[15/23] Train loss=0.5523618459701538
[20/23] Train loss=0.5350068807601929
Test set avg_accuracy=85.38% avg_sensitivity=83.88%, avg_specificity=85.85% avg_auc=93.21%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.593753 Test loss=0.326005 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.5977408289909363
[5/23] Train loss=0.5932677388191223
[10/23] Train loss=0.6932532787322998
[15/23] Train loss=0.5513017177581787
[20/23] Train loss=0.5263464450836182
Test set avg_accuracy=85.42% avg_sensitivity=83.72%, avg_specificity=85.96% avg_auc=93.22%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.591709 Test loss=0.325387 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.5960606336593628
[5/23] Train loss=0.581017017364502
[10/23] Train loss=0.6939249038696289
[15/23] Train loss=0.5388686656951904
[20/23] Train loss=0.5299617052078247
Test set avg_accuracy=85.42% avg_sensitivity=83.72%, avg_specificity=85.96% avg_auc=93.21%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.589947 Test loss=0.324694 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.612348735332489
[5/23] Train loss=0.5749415159225464
[10/23] Train loss=0.6911728382110596
[15/23] Train loss=0.5417259931564331
[20/23] Train loss=0.5295050144195557
Test set avg_accuracy=85.42% avg_sensitivity=83.77%, avg_specificity=85.94% avg_auc=93.23%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.590751 Test loss=0.325305 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.5954820513725281
[5/23] Train loss=0.5782393217086792
[10/23] Train loss=0.7032718658447266
[15/23] Train loss=0.5464884638786316
[20/23] Train loss=0.5382069945335388
Test set avg_accuracy=85.39% avg_sensitivity=83.88%, avg_specificity=85.87% avg_auc=93.24%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.590150 Test loss=0.326133 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.6071508526802063
[5/23] Train loss=0.5782250165939331
[10/23] Train loss=0.6905628442764282
[15/23] Train loss=0.548555850982666
[20/23] Train loss=0.5232008099555969
Test set avg_accuracy=85.42% avg_sensitivity=83.77%, avg_specificity=85.94% avg_auc=93.23%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.590329 Test loss=0.325417 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.5959410071372986
[5/23] Train loss=0.5809809565544128
[10/23] Train loss=0.7032132744789124
[15/23] Train loss=0.548893928527832
[20/23] Train loss=0.5281028747558594
Test set avg_accuracy=85.40% avg_sensitivity=83.83%, avg_specificity=85.91% avg_auc=93.23%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.590337 Test loss=0.326054 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.6067175269126892
[5/23] Train loss=0.574151873588562
[10/23] Train loss=0.6949723362922668
[15/23] Train loss=0.5502030849456787
[20/23] Train loss=0.5205037593841553
Test set avg_accuracy=85.39% avg_sensitivity=83.72%, avg_specificity=85.92% avg_auc=93.24%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.589177 Test loss=0.325558 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.5992838740348816
[5/23] Train loss=0.5884000062942505
[10/23] Train loss=0.6898271441459656
[15/23] Train loss=0.5338172912597656
[20/23] Train loss=0.5290712714195251
Test set avg_accuracy=85.44% avg_sensitivity=83.77%, avg_specificity=85.97% avg_auc=93.23%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.588582 Test loss=0.324936 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.6001570224761963
[5/23] Train loss=0.5726301670074463
[10/23] Train loss=0.6957024335861206
[15/23] Train loss=0.5341826677322388
[20/23] Train loss=0.5308271646499634
Test set avg_accuracy=85.40% avg_sensitivity=83.83%, avg_specificity=85.91% avg_auc=93.24%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.588803 Test loss=0.325581 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.6079110503196716
[5/23] Train loss=0.5967080593109131
[10/23] Train loss=0.6941920518875122
[15/23] Train loss=0.5440462827682495
[20/23] Train loss=0.5202485918998718
Test set avg_accuracy=85.38% avg_sensitivity=83.83%, avg_specificity=85.87% avg_auc=93.24%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.590747 Test loss=0.326255 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.600098729133606
[5/23] Train loss=0.5961630344390869
[10/23] Train loss=0.6913363337516785
[15/23] Train loss=0.5385658144950867
[20/23] Train loss=0.523481011390686
Test set avg_accuracy=85.36% avg_sensitivity=83.83%, avg_specificity=85.85% avg_auc=93.24%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.589580 Test loss=0.326238 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.5954213738441467
[5/23] Train loss=0.5917255282402039
[10/23] Train loss=0.71494060754776
[15/23] Train loss=0.54975825548172
[20/23] Train loss=0.5328047275543213
Test set avg_accuracy=85.38% avg_sensitivity=83.83%, avg_specificity=85.87% avg_auc=93.24%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.592381 Test loss=0.326169 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.5984624624252319
[5/23] Train loss=0.5730715990066528
[10/23] Train loss=0.7074663043022156
[15/23] Train loss=0.5469174385070801
[20/23] Train loss=0.5262843370437622
Test set avg_accuracy=85.38% avg_sensitivity=83.83%, avg_specificity=85.87% avg_auc=93.24%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.589030 Test loss=0.326158 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=85.65% sen=83.56%, spe=86.32%, auc=93.22%!
Fold[9] Avg_overlap=0.64%(±0.2342726707275286)
[0/24] Train loss=1.5848758220672607
[5/24] Train loss=1.4744079113006592
[10/24] Train loss=1.4630568027496338
[15/24] Train loss=1.4277275800704956
[20/24] Train loss=1.4213792085647583
Test set avg_accuracy=55.72% avg_sensitivity=54.29%, avg_specificity=56.13% avg_auc=57.70%
Best model saved!! Metric=-102.16802524107996!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=1.455509 Test loss=0.681459 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.4091845750808716
[5/24] Train loss=1.39814031124115
[10/24] Train loss=1.3977878093719482
[15/24] Train loss=1.3818039894104004
[20/24] Train loss=1.3875199556350708
Test set avg_accuracy=65.74% avg_sensitivity=55.62%, avg_specificity=68.68% avg_auc=66.29%
Best model saved!! Metric=-69.67114106651866!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=1.395233 Test loss=0.664974 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.364730954170227
[5/24] Train loss=1.363965630531311
[10/24] Train loss=1.372479796409607
[15/24] Train loss=1.358258605003357
[20/24] Train loss=1.3656584024429321
Test set avg_accuracy=68.53% avg_sensitivity=60.31%, avg_specificity=70.91% avg_auc=71.25%
Best model saved!! Metric=-54.99501081432966!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=1.364681 Test loss=0.655032 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.3492133617401123
[5/24] Train loss=1.3243534564971924
[10/24] Train loss=1.3445289134979248
[15/24] Train loss=1.3390138149261475
[20/24] Train loss=1.3404377698898315
Test set avg_accuracy=70.46% avg_sensitivity=62.11%, avg_specificity=72.88% avg_auc=73.86%
Best model saved!! Metric=-46.69945692399129!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=1.339265 Test loss=0.643332 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.317244529724121
[5/24] Train loss=1.3074207305908203
[10/24] Train loss=1.3297654390335083
[15/24] Train loss=1.3123016357421875
[20/24] Train loss=1.310524821281433
Test set avg_accuracy=72.84% avg_sensitivity=64.02%, avg_specificity=75.39% avg_auc=76.40%
Best model saved!! Metric=-37.34755229978373!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=1.318524 Test loss=0.630355 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.271661400794983
[5/24] Train loss=1.2888633012771606
[10/24] Train loss=1.3106188774108887
[15/24] Train loss=1.2768378257751465
[20/24] Train loss=1.2995343208312988
Test set avg_accuracy=73.23% avg_sensitivity=65.47%, avg_specificity=75.48% avg_auc=77.81%
Best model saved!! Metric=-34.01657852308668!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=1.294870 Test loss=0.614486 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.2545560598373413
[5/24] Train loss=1.2549188137054443
[10/24] Train loss=1.2769043445587158
[15/24] Train loss=1.2475332021713257
[20/24] Train loss=1.2517781257629395
Test set avg_accuracy=74.41% avg_sensitivity=67.73%, avg_specificity=76.35% avg_auc=79.37%
Best model saved!! Metric=-28.139889564320086!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=1.265566 Test loss=0.595848 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.2129809856414795
[5/24] Train loss=1.2271267175674438
[10/24] Train loss=1.235243558883667
[15/24] Train loss=1.212504506111145
[20/24] Train loss=1.2226041555404663
Test set avg_accuracy=76.63% avg_sensitivity=65.35%, avg_specificity=79.90% avg_auc=80.74%
Best model saved!! Metric=-23.383898076681433!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=1.230104 Test loss=0.565168 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.1618276834487915
[5/24] Train loss=1.1674500703811646
[10/24] Train loss=1.2121663093566895
[15/24] Train loss=1.1667228937149048
[20/24] Train loss=1.185733437538147
Test set avg_accuracy=76.84% avg_sensitivity=70.10%, avg_specificity=78.79% avg_auc=82.21%
Best model saved!! Metric=-18.058845251189013!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=1.190044 Test loss=0.550779 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.112687349319458
[5/24] Train loss=1.138787865638733
[10/24] Train loss=1.1899820566177368
[15/24] Train loss=1.1326175928115845
[20/24] Train loss=1.1428264379501343
Test set avg_accuracy=77.86% avg_sensitivity=72.65%, avg_specificity=79.38% avg_auc=83.67%
Best model saved!! Metric=-12.437159732761245!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=1.152942 Test loss=0.528022 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.0657336711883545
[5/24] Train loss=1.1032332181930542
[10/24] Train loss=1.141601324081421
[15/24] Train loss=1.0773345232009888
[20/24] Train loss=1.0935580730438232
Test set avg_accuracy=78.29% avg_sensitivity=77.23%, avg_specificity=78.60% avg_auc=84.81%
Best model saved!! Metric=-7.065830032672594!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=1.105946 Test loss=0.513389 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.0104233026504517
[5/24] Train loss=1.0542645454406738
[10/24] Train loss=1.1003090143203735
[15/24] Train loss=1.043666124343872
[20/24] Train loss=1.0489380359649658
Test set avg_accuracy=77.98% avg_sensitivity=79.32%, avg_specificity=77.59% avg_auc=85.74%
Best model saved!! Metric=-5.369096242988789!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=1.069901 Test loss=0.502305 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.9725937843322754
[5/24] Train loss=1.0124458074569702
[10/24] Train loss=1.0828250646591187
[15/24] Train loss=0.9995902180671692
[20/24] Train loss=1.0161542892456055
Test set avg_accuracy=78.84% avg_sensitivity=78.62%, avg_specificity=78.90% avg_auc=86.23%
Best model saved!! Metric=-3.4071926255583236!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=1.033631 Test loss=0.477172 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.9574166536331177
[5/24] Train loss=0.9848644733428955
[10/24] Train loss=1.0400750637054443
[15/24] Train loss=0.9772875905036926
[20/24] Train loss=0.9912009835243225
Test set avg_accuracy=79.21% avg_sensitivity=79.08%, avg_specificity=79.24% avg_auc=86.87%
Best model saved!! Metric=-1.6007516513155906!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=1.006626 Test loss=0.460356 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.9178458452224731
[5/24] Train loss=0.9814253449440002
[10/24] Train loss=1.0035600662231445
[15/24] Train loss=0.9416894912719727
[20/24] Train loss=0.9673467874526978
Test set avg_accuracy=79.02% avg_sensitivity=80.36%, avg_specificity=78.64% avg_auc=87.42%
Best model saved!! Metric=-0.5585921276863388!!
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.980083 Test loss=0.452431 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.8976630568504333
[5/24] Train loss=0.9460561871528625
[10/24] Train loss=0.9829407930374146
[15/24] Train loss=0.9248725175857544
[20/24] Train loss=0.9524449110031128
Test set avg_accuracy=79.14% avg_sensitivity=81.05%, avg_specificity=78.59% avg_auc=87.93%
Best model saved!! Metric=0.7107366828088146!!
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.960728 Test loss=0.440749 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.8671159744262695
[5/24] Train loss=0.9290302991867065
[10/24] Train loss=0.9665001630783081
[15/24] Train loss=0.8896360397338867
[20/24] Train loss=0.9223238229751587
Test set avg_accuracy=80.77% avg_sensitivity=76.36%, avg_specificity=82.05% avg_auc=88.13%
Best model saved!! Metric=1.302312799742353!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.938720 Test loss=0.408166 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.8439168334007263
[5/24] Train loss=0.9065036177635193
[10/24] Train loss=0.9496583938598633
[15/24] Train loss=0.8704090118408203
[20/24] Train loss=0.8911281228065491
Test set avg_accuracy=81.90% avg_sensitivity=74.74%, avg_specificity=83.98% avg_auc=88.44%
Best model saved!! Metric=3.0537002686717756!!
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.921659 Test loss=0.388226 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.8225836753845215
[5/24] Train loss=0.8883190751075745
[10/24] Train loss=0.9163996577262878
[15/24] Train loss=0.8489735722541809
[20/24] Train loss=0.8697208762168884
Test set avg_accuracy=82.34% avg_sensitivity=75.61%, avg_specificity=84.30% avg_auc=89.11%
Best model saved!! Metric=5.3535785386884385!!
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.898882 Test loss=0.377651 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.7985248565673828
[5/24] Train loss=0.8665401935577393
[10/24] Train loss=0.9131408929824829
[15/24] Train loss=0.8251170516014099
[20/24] Train loss=0.8316793441772461
Test set avg_accuracy=83.87% avg_sensitivity=72.48%, avg_specificity=87.17% avg_auc=89.57%
Best model saved!! Metric=7.0861950631989!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.876057 Test loss=0.356341 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.7799692153930664
[5/24] Train loss=0.8851699233055115
[10/24] Train loss=0.8697329163551331
[15/24] Train loss=0.789609968662262
[20/24] Train loss=0.8288291692733765
Test set avg_accuracy=83.97% avg_sensitivity=72.13%, avg_specificity=87.40% avg_auc=89.73%
Best model saved!! Metric=7.233668837933564!!
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.858283 Test loss=0.351040 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.7665482759475708
[5/24] Train loss=0.9014257192611694
[10/24] Train loss=0.8591572046279907
[15/24] Train loss=0.7639136910438538
[20/24] Train loss=0.804864764213562
Test set avg_accuracy=83.85% avg_sensitivity=73.64%, avg_specificity=86.82% avg_auc=89.82%
Best model saved!! Metric=8.125019761716345!!
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.849322 Test loss=0.353561 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.7633870244026184
[5/24] Train loss=0.8880696296691895
[10/24] Train loss=0.8348981738090515
[15/24] Train loss=0.7791668772697449
[20/24] Train loss=0.7821293473243713
Test set avg_accuracy=83.92% avg_sensitivity=74.16%, avg_specificity=86.75% avg_auc=89.99%
Best model saved!! Metric=8.812635022514925!!
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.835493 Test loss=0.353055 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.7612876296043396
[5/24] Train loss=0.8728523254394531
[10/24] Train loss=0.8443138599395752
[15/24] Train loss=0.768591582775116
[20/24] Train loss=0.7916465997695923
Test set avg_accuracy=84.28% avg_sensitivity=72.89%, avg_specificity=87.59% avg_auc=90.19%
Best model saved!! Metric=8.949842658584814!!
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.828604 Test loss=0.341668 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.745719313621521
[5/24] Train loss=0.8781266808509827
[10/24] Train loss=0.8344703912734985
[15/24] Train loss=0.7650946974754333
[20/24] Train loss=0.7630316615104675
Test set avg_accuracy=84.58% avg_sensitivity=68.95%, avg_specificity=89.12% avg_auc=89.89%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.830733 Test loss=0.336727 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.7533977627754211
[5/24] Train loss=0.8808018565177917
[10/24] Train loss=0.8353327512741089
[15/24] Train loss=0.7568278908729553
[20/24] Train loss=0.7664132118225098
Test set avg_accuracy=84.49% avg_sensitivity=72.13%, avg_specificity=88.08% avg_auc=90.37%
Best model saved!! Metric=9.070656807565044!!
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.819204 Test loss=0.334738 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.7232968807220459
[5/24] Train loss=0.8587226271629333
[10/24] Train loss=0.8040708899497986
[15/24] Train loss=0.7354459762573242
[20/24] Train loss=0.755365788936615
Test set avg_accuracy=83.95% avg_sensitivity=75.26%, avg_specificity=86.46% avg_auc=90.60%
Best model saved!! Metric=10.266692208705322!!
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.807973 Test loss=0.344918 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.7168297171592712
[5/24] Train loss=0.879759669303894
[10/24] Train loss=0.8217867612838745
[15/24] Train loss=0.7579530477523804
[20/24] Train loss=0.7398852705955505
Test set avg_accuracy=84.35% avg_sensitivity=73.41%, avg_specificity=87.52% avg_auc=90.68%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.798998 Test loss=0.332107 Current lr=[0.000210185142098938]

[0/24] Train loss=0.7089523077011108
[5/24] Train loss=0.8725990653038025
[10/24] Train loss=0.807837724685669
[15/24] Train loss=0.7436762452125549
[20/24] Train loss=0.7269413471221924
Test set avg_accuracy=84.97% avg_sensitivity=72.94%, avg_specificity=88.46% avg_auc=90.77%
Best model saved!! Metric=11.145444166591076!!
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.798218 Test loss=0.328183 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.6994932889938354
[5/24] Train loss=0.8714593648910522
[10/24] Train loss=0.7971794605255127
[15/24] Train loss=0.7332252860069275
[20/24] Train loss=0.7298517823219299
Test set avg_accuracy=85.20% avg_sensitivity=71.49%, avg_specificity=89.17% avg_auc=90.81%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.793379 Test loss=0.324073 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.7113500833511353
[5/24] Train loss=0.8726326823234558
[10/24] Train loss=0.7873014211654663
[15/24] Train loss=0.727030336856842
[20/24] Train loss=0.7080158591270447
Test set avg_accuracy=84.54% avg_sensitivity=74.22%, avg_specificity=87.54% avg_auc=90.82%
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.789592 Test loss=0.332803 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.7105245590209961
[5/24] Train loss=0.8476744890213013
[10/24] Train loss=0.785087525844574
[15/24] Train loss=0.6945812702178955
[20/24] Train loss=0.7103681564331055
Test set avg_accuracy=85.09% avg_sensitivity=72.54%, avg_specificity=88.73% avg_auc=91.00%
Best model saved!! Metric=11.36319990878475!!
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.775927 Test loss=0.324718 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.7016029357910156
[5/24] Train loss=0.8730101585388184
[10/24] Train loss=0.7751941084861755
[15/24] Train loss=0.7076554298400879
[20/24] Train loss=0.696785032749176
Test set avg_accuracy=85.52% avg_sensitivity=72.07%, avg_specificity=89.42% avg_auc=91.13%
Best model saved!! Metric=12.142146755549447!!
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.776244 Test loss=0.317855 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.6980424523353577
[5/24] Train loss=0.8502092361450195
[10/24] Train loss=0.7770206332206726
[15/24] Train loss=0.7018391489982605
[20/24] Train loss=0.699240505695343
Test set avg_accuracy=85.40% avg_sensitivity=72.60%, avg_specificity=89.12% avg_auc=91.19%
Best model saved!! Metric=12.301052408501533!!
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.763214 Test loss=0.317132 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.6939675807952881
[5/24] Train loss=0.8427891135215759
[10/24] Train loss=0.7712527513504028
[15/24] Train loss=0.701293408870697
[20/24] Train loss=0.6906654238700867
Test set avg_accuracy=85.66% avg_sensitivity=72.19%, avg_specificity=89.57% avg_auc=91.28%
Best model saved!! Metric=12.706740801119707!!
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.761819 Test loss=0.314097 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.7019821405410767
[5/24] Train loss=0.84568852186203
[10/24] Train loss=0.768259584903717
[15/24] Train loss=0.7005057334899902
[20/24] Train loss=0.6754453778266907
Test set avg_accuracy=85.34% avg_sensitivity=73.87%, avg_specificity=88.66% avg_auc=91.38%
Best model saved!! Metric=13.248617407641035!!
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.760037 Test loss=0.317817 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.6882614493370056
[5/24] Train loss=0.8404819965362549
[10/24] Train loss=0.767673671245575
[15/24] Train loss=0.7180685997009277
[20/24] Train loss=0.682809054851532
Test set avg_accuracy=84.91% avg_sensitivity=75.20%, avg_specificity=87.72% avg_auc=91.49%
Best model saved!! Metric=13.324125982141894!!
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.759085 Test loss=0.322988 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.6728832721710205
[5/24] Train loss=0.8353147506713867
[10/24] Train loss=0.7776719927787781
[15/24] Train loss=0.6974523663520813
[20/24] Train loss=0.6736985445022583
Test set avg_accuracy=84.51% avg_sensitivity=77.35%, avg_specificity=86.58% avg_auc=91.54%
Best model saved!! Metric=13.970953632072124!!
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.753249 Test loss=0.329936 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.6763823628425598
[5/24] Train loss=0.8106505870819092
[10/24] Train loss=0.7611648440361023
[15/24] Train loss=0.6908372640609741
[20/24] Train loss=0.6705000996589661
Test set avg_accuracy=85.12% avg_sensitivity=75.14%, avg_specificity=88.01% avg_auc=91.57%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.748093 Test loss=0.320321 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.6797689199447632
[5/24] Train loss=0.8068332076072693
[10/24] Train loss=0.7650360465049744
[15/24] Train loss=0.6729289293289185
[20/24] Train loss=0.6448794007301331
Test set avg_accuracy=85.87% avg_sensitivity=73.46%, avg_specificity=89.47% avg_auc=91.73%
Best model saved!! Metric=14.533001613219383!!
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.740780 Test loss=0.307261 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.6730777621269226
[5/24] Train loss=0.8419656157493591
[10/24] Train loss=0.7461587190628052
[15/24] Train loss=0.6872060298919678
[20/24] Train loss=0.6575122475624084
Test set avg_accuracy=85.83% avg_sensitivity=73.17%, avg_specificity=89.50% avg_auc=91.70%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.741162 Test loss=0.307921 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.6847313046455383
[5/24] Train loss=0.8272467851638794
[10/24] Train loss=0.7594776749610901
[15/24] Train loss=0.6806372404098511
[20/24] Train loss=0.6543930172920227
Test set avg_accuracy=84.70% avg_sensitivity=79.20%, avg_specificity=86.29% avg_auc=91.86%
Best model saved!! Metric=16.055654883453414!!
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.742401 Test loss=0.329951 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.6719772815704346
[5/24] Train loss=0.8024924397468567
[10/24] Train loss=0.756112813949585
[15/24] Train loss=0.6696183681488037
[20/24] Train loss=0.6522513031959534
Test set avg_accuracy=85.34% avg_sensitivity=76.83%, avg_specificity=87.81% avg_auc=91.86%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.730375 Test loss=0.316594 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.6706821918487549
[5/24] Train loss=0.7994598746299744
[10/24] Train loss=0.7516570091247559
[15/24] Train loss=0.6827632188796997
[20/24] Train loss=0.6577154994010925
Test set avg_accuracy=85.29% avg_sensitivity=77.46%, avg_specificity=87.55% avg_auc=91.92%
Best model saved!! Metric=16.21903061110136!!
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.729583 Test loss=0.318188 Current lr=[0.00029967723776099]

[0/24] Train loss=0.6782602071762085
[5/24] Train loss=0.79360431432724
[10/24] Train loss=0.7445670366287231
[15/24] Train loss=0.6675494313240051
[20/24] Train loss=0.6442041993141174
Test set avg_accuracy=85.57% avg_sensitivity=76.88%, avg_specificity=88.09% avg_auc=91.97%
Best model saved!! Metric=16.520153321888586!!
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.727071 Test loss=0.313319 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.6739233732223511
[5/24] Train loss=0.7884754538536072
[10/24] Train loss=0.7508879899978638
[15/24] Train loss=0.6715283989906311
[20/24] Train loss=0.6427375078201294
Test set avg_accuracy=85.86% avg_sensitivity=74.45%, avg_specificity=89.17% avg_auc=92.05%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.724481 Test loss=0.304809 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.6793245673179626
[5/24] Train loss=0.796099066734314
[10/24] Train loss=0.7454375624656677
[15/24] Train loss=0.6635679006576538
[20/24] Train loss=0.6301589012145996
Test set avg_accuracy=85.82% avg_sensitivity=76.30%, avg_specificity=88.58% avg_auc=92.13%
Best model saved!! Metric=16.83328098647665!!
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.722249 Test loss=0.307645 Current lr=[0.000299720220882401]

[0/24] Train loss=0.6651594638824463
[5/24] Train loss=0.8062986135482788
[10/24] Train loss=0.7491266131401062
[15/24] Train loss=0.6557170152664185
[20/24] Train loss=0.6331827640533447
Test set avg_accuracy=85.76% avg_sensitivity=77.29%, avg_specificity=88.21% avg_auc=92.15%
Best model saved!! Metric=17.404403534393936!!
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.718089 Test loss=0.309549 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.6533828973770142
[5/24] Train loss=0.7981616854667664
[10/24] Train loss=0.7410331964492798
[15/24] Train loss=0.6616331934928894
[20/24] Train loss=0.6381823420524597
Test set avg_accuracy=85.61% avg_sensitivity=77.64%, avg_specificity=87.92% avg_auc=92.17%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.715989 Test loss=0.311331 Current lr=[0.000298904600941902]

[0/24] Train loss=0.6668849587440491
[5/24] Train loss=0.8017171621322632
[10/24] Train loss=0.7423401474952698
[15/24] Train loss=0.6642323136329651
[20/24] Train loss=0.6284647583961487
Test set avg_accuracy=85.76% avg_sensitivity=77.11%, avg_specificity=88.26% avg_auc=92.25%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.716851 Test loss=0.307440 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.667959988117218
[5/24] Train loss=0.77199786901474
[10/24] Train loss=0.7395753264427185
[15/24] Train loss=0.6419768333435059
[20/24] Train loss=0.6238790154457092
Test set avg_accuracy=85.78% avg_sensitivity=76.88%, avg_specificity=88.36% avg_auc=92.24%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.710907 Test loss=0.307261 Current lr=[0.000297555943323901]

[0/24] Train loss=0.6546721458435059
[5/24] Train loss=0.7957183122634888
[10/24] Train loss=0.728218674659729
[15/24] Train loss=0.6378198266029358
[20/24] Train loss=0.6356227993965149
Test set avg_accuracy=85.85% avg_sensitivity=76.59%, avg_specificity=88.53% avg_auc=92.19%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.713123 Test loss=0.307209 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.6697142720222473
[5/24] Train loss=0.8004457354545593
[10/24] Train loss=0.7350649833679199
[15/24] Train loss=0.6449110507965088
[20/24] Train loss=0.6316623091697693
Test set avg_accuracy=85.46% avg_sensitivity=77.52%, avg_specificity=87.76% avg_auc=92.28%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.710332 Test loss=0.310388 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.6607747673988342
[5/24] Train loss=0.7946164011955261
[10/24] Train loss=0.7356102466583252
[15/24] Train loss=0.642408013343811
[20/24] Train loss=0.6119897365570068
Test set avg_accuracy=85.07% avg_sensitivity=79.55%, avg_specificity=86.66% avg_auc=92.08%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.710069 Test loss=0.325088 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.6568123698234558
[5/24] Train loss=0.7830981612205505
[10/24] Train loss=0.730280339717865
[15/24] Train loss=0.6361261010169983
[20/24] Train loss=0.6136234402656555
Test set avg_accuracy=85.40% avg_sensitivity=77.98%, avg_specificity=87.55% avg_auc=92.31%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.699940 Test loss=0.312325 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.6542225480079651
[5/24] Train loss=0.7903451919555664
[10/24] Train loss=0.7313899397850037
[15/24] Train loss=0.6223699450492859
[20/24] Train loss=0.607450008392334
Test set avg_accuracy=85.68% avg_sensitivity=77.98%, avg_specificity=87.91% avg_auc=92.38%
Best model saved!! Metric=17.948278759370965!!
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.702800 Test loss=0.308850 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.6498077511787415
[5/24] Train loss=0.7832447290420532
[10/24] Train loss=0.741938054561615
[15/24] Train loss=0.6311143040657043
[20/24] Train loss=0.6155029535293579
Test set avg_accuracy=85.59% avg_sensitivity=78.68%, avg_specificity=87.59% avg_auc=92.37%
Best model saved!! Metric=18.221805925016668!!
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.701148 Test loss=0.312969 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.6579081416130066
[5/24] Train loss=0.7590724229812622
[10/24] Train loss=0.7388482689857483
[15/24] Train loss=0.6227656602859497
[20/24] Train loss=0.6062590479850769
Test set avg_accuracy=85.42% avg_sensitivity=79.32%, avg_specificity=87.19% avg_auc=92.43%
Best model saved!! Metric=18.352235265009057!!
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.696463 Test loss=0.315673 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.6559348106384277
[5/24] Train loss=0.7637342214584351
[10/24] Train loss=0.7331727743148804
[15/24] Train loss=0.6226338148117065
[20/24] Train loss=0.6039882898330688
Test set avg_accuracy=85.61% avg_sensitivity=77.75%, avg_specificity=87.89% avg_auc=92.43%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.694705 Test loss=0.307400 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.6500564813613892
[5/24] Train loss=0.7861395478248596
[10/24] Train loss=0.7244218587875366
[15/24] Train loss=0.6236602067947388
[20/24] Train loss=0.6044175624847412
Test set avg_accuracy=85.79% avg_sensitivity=78.74%, avg_specificity=87.84% avg_auc=92.47%
Best model saved!! Metric=18.84509151300533!!
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.696338 Test loss=0.308713 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.6537833213806152
[5/24] Train loss=0.7724233269691467
[10/24] Train loss=0.7362870573997498
[15/24] Train loss=0.6220937967300415
[20/24] Train loss=0.6056320667266846
Test set avg_accuracy=85.76% avg_sensitivity=78.10%, avg_specificity=87.97% avg_auc=92.54%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.695436 Test loss=0.305643 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.6474720239639282
[5/24] Train loss=0.7820138931274414
[10/24] Train loss=0.7267301678657532
[15/24] Train loss=0.6374463438987732
[20/24] Train loss=0.6088930368423462
Test set avg_accuracy=85.85% avg_sensitivity=78.85%, avg_specificity=87.87% avg_auc=92.62%
Best model saved!! Metric=19.192067984188498!!
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.688935 Test loss=0.304873 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.6392905116081238
[5/24] Train loss=0.7634038925170898
[10/24] Train loss=0.7199145555496216
[15/24] Train loss=0.6220335960388184
[20/24] Train loss=0.6187754273414612
Test set avg_accuracy=86.00% avg_sensitivity=78.39%, avg_specificity=88.21% avg_auc=92.67%
Best model saved!! Metric=19.271609764235663!!
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.688461 Test loss=0.302839 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.644934356212616
[5/24] Train loss=0.7513403296470642
[10/24] Train loss=0.7210813164710999
[15/24] Train loss=0.6188438534736633
[20/24] Train loss=0.6074424982070923
Test set avg_accuracy=86.26% avg_sensitivity=78.04%, avg_specificity=88.65% avg_auc=92.68%
Best model saved!! Metric=19.633353678697418!!
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.687202 Test loss=0.299814 Current lr=[0.000276307469034998]

[0/24] Train loss=0.6450402736663818
[5/24] Train loss=0.7585030198097229
[10/24] Train loss=0.703041136264801
[15/24] Train loss=0.6162060499191284
[20/24] Train loss=0.5934800505638123
Test set avg_accuracy=85.65% avg_sensitivity=79.90%, avg_specificity=87.32% avg_auc=92.68%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.687020 Test loss=0.310726 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.6357699632644653
[5/24] Train loss=0.7593108415603638
[10/24] Train loss=0.7109538316726685
[15/24] Train loss=0.6122660636901855
[20/24] Train loss=0.5971516966819763
Test set avg_accuracy=85.55% avg_sensitivity=79.32%, avg_specificity=87.35% avg_auc=92.66%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.684703 Test loss=0.309765 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.6556118130683899
[5/24] Train loss=0.7661709189414978
[10/24] Train loss=0.716123640537262
[15/24] Train loss=0.6154707670211792
[20/24] Train loss=0.5982347130775452
Test set avg_accuracy=86.11% avg_sensitivity=78.56%, avg_specificity=88.29% avg_auc=92.73%
Best model saved!! Metric=19.69139626017666!!
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.683129 Test loss=0.302109 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.6435332298278809
[5/24] Train loss=0.7679380774497986
[10/24] Train loss=0.7086408138275146
[15/24] Train loss=0.6170123219490051
[20/24] Train loss=0.5897392630577087
Test set avg_accuracy=85.34% avg_sensitivity=80.01%, avg_specificity=86.88% avg_auc=92.71%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.683762 Test loss=0.313502 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.644039511680603
[5/24] Train loss=0.7444007992744446
[10/24] Train loss=0.7092297673225403
[15/24] Train loss=0.6291356682777405
[20/24] Train loss=0.6012027263641357
Test set avg_accuracy=85.66% avg_sensitivity=79.55%, avg_specificity=87.44% avg_auc=92.83%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.680259 Test loss=0.307277 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.6466623544692993
[5/24] Train loss=0.7573853135108948
[10/24] Train loss=0.7137366533279419
[15/24] Train loss=0.6150732636451721
[20/24] Train loss=0.5918834209442139
Test set avg_accuracy=85.56% avg_sensitivity=80.13%, avg_specificity=87.13% avg_auc=92.76%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.680690 Test loss=0.309872 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.638918936252594
[5/24] Train loss=0.739047646522522
[10/24] Train loss=0.71307772397995
[15/24] Train loss=0.6127538084983826
[20/24] Train loss=0.602859616279602
Test set avg_accuracy=86.07% avg_sensitivity=78.91%, avg_specificity=88.14% avg_auc=92.82%
Best model saved!! Metric=19.93750578782317!!
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.679166 Test loss=0.302306 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.6396268606185913
[5/24] Train loss=0.7516504526138306
[10/24] Train loss=0.7136428356170654
[15/24] Train loss=0.6168816685676575
[20/24] Train loss=0.5834740996360779
Test set avg_accuracy=86.51% avg_sensitivity=78.51%, avg_specificity=88.83% avg_auc=92.88%
Best model saved!! Metric=20.729225331474595!!
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.678959 Test loss=0.294937 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.6383617520332336
[5/24] Train loss=0.7949832081794739
[10/24] Train loss=0.7171720266342163
[15/24] Train loss=0.6415923237800598
[20/24] Train loss=0.588723361492157
Test set avg_accuracy=87.53% avg_sensitivity=75.49%, avg_specificity=91.01% avg_auc=92.66%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.687357 Test loss=0.287129 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.6535302996635437
[5/24] Train loss=0.74481600522995
[10/24] Train loss=0.7350790500640869
[15/24] Train loss=0.6123113036155701
[20/24] Train loss=0.5913378596305847
Test set avg_accuracy=87.41% avg_sensitivity=74.97%, avg_specificity=91.01% avg_auc=92.83%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.681355 Test loss=0.285249 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.6570990681648254
[5/24] Train loss=0.74399334192276
[10/24] Train loss=0.7331159114837646
[15/24] Train loss=0.6064580678939819
[20/24] Train loss=0.5814995169639587
Test set avg_accuracy=87.10% avg_sensitivity=76.88%, avg_specificity=90.06% avg_auc=92.84%
Best model saved!! Metric=20.879809868569765!!
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.676625 Test loss=0.290488 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.6424038410186768
[5/24] Train loss=0.7493210434913635
[10/24] Train loss=0.7252253890037537
[15/24] Train loss=0.6137442588806152
[20/24] Train loss=0.584904134273529
Test set avg_accuracy=87.41% avg_sensitivity=75.43%, avg_specificity=90.88% avg_auc=92.82%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.674177 Test loss=0.286761 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.6404122710227966
[5/24] Train loss=0.7195879817008972
[10/24] Train loss=0.7433004975318909
[15/24] Train loss=0.619795560836792
[20/24] Train loss=0.5881602764129639
Test set avg_accuracy=87.27% avg_sensitivity=77.06%, avg_specificity=90.23% avg_auc=92.85%
Best model saved!! Metric=21.39881685987899!!
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.672942 Test loss=0.289172 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.6409208178520203
[5/24] Train loss=0.7240767478942871
[10/24] Train loss=0.7297730445861816
[15/24] Train loss=0.6167696118354797
[20/24] Train loss=0.5825126767158508
Test set avg_accuracy=87.23% avg_sensitivity=77.17%, avg_specificity=90.14% avg_auc=92.93%
Best model saved!! Metric=21.470710274887495!!
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.670046 Test loss=0.288707 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.6368749141693115
[5/24] Train loss=0.7242340445518494
[10/24] Train loss=0.7293360829353333
[15/24] Train loss=0.5997616648674011
[20/24] Train loss=0.585028886795044
Test set avg_accuracy=86.89% avg_sensitivity=78.39%, avg_specificity=89.35% avg_auc=92.93%
Best model saved!! Metric=21.55963958987975!!
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.668386 Test loss=0.294681 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.6299950480461121
[5/24] Train loss=0.7099722027778625
[10/24] Train loss=0.7161396145820618
[15/24] Train loss=0.6110543608665466
[20/24] Train loss=0.596759557723999
Test set avg_accuracy=87.14% avg_sensitivity=77.11%, avg_specificity=90.04% avg_auc=92.90%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.662983 Test loss=0.290166 Current lr=[0.000224838296036774]

[0/24] Train loss=0.6392632126808167
[5/24] Train loss=0.7095257043838501
[10/24] Train loss=0.7186655402183533
[15/24] Train loss=0.6070341467857361
[20/24] Train loss=0.5846710801124573
Test set avg_accuracy=87.50% avg_sensitivity=77.00%, avg_specificity=90.54% avg_auc=92.96%
Best model saved!! Metric=22.002798395267533!!
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.663641 Test loss=0.286034 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.645428478717804
[5/24] Train loss=0.7047491073608398
[10/24] Train loss=0.7244940996170044
[15/24] Train loss=0.5978165864944458
[20/24] Train loss=0.5796563625335693
Test set avg_accuracy=86.93% avg_sensitivity=77.87%, avg_specificity=89.55% avg_auc=92.97%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.662882 Test loss=0.291182 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.626417875289917
[5/24] Train loss=0.7146339416503906
[10/24] Train loss=0.7156568169593811
[15/24] Train loss=0.601523756980896
[20/24] Train loss=0.5785961747169495
Test set avg_accuracy=86.85% avg_sensitivity=78.39%, avg_specificity=89.30% avg_auc=92.98%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.658808 Test loss=0.292974 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.624797523021698
[5/24] Train loss=0.7107425928115845
[10/24] Train loss=0.7173492312431335
[15/24] Train loss=0.5893459916114807
[20/24] Train loss=0.5775984525680542
Test set avg_accuracy=87.34% avg_sensitivity=77.75%, avg_specificity=90.12% avg_auc=93.08%
Best model saved!! Metric=22.29833674869637!!
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.657380 Test loss=0.287319 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.6287174820899963
[5/24] Train loss=0.7001466751098633
[10/24] Train loss=0.7189589738845825
[15/24] Train loss=0.5939794182777405
[20/24] Train loss=0.5825558304786682
Test set avg_accuracy=87.17% avg_sensitivity=77.87%, avg_specificity=89.87% avg_auc=93.08%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.658718 Test loss=0.288605 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.6223713159561157
[5/24] Train loss=0.7046591639518738
[10/24] Train loss=0.704974889755249
[15/24] Train loss=0.5923752188682556
[20/24] Train loss=0.5882678031921387
Test set avg_accuracy=87.57% avg_sensitivity=77.23%, avg_specificity=90.56% avg_auc=93.08%
Best model saved!! Metric=22.43667224499292!!
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.656653 Test loss=0.284543 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.6328508257865906
[5/24] Train loss=0.7108396291732788
[10/24] Train loss=0.7051222920417786
[15/24] Train loss=0.5950776934623718
[20/24] Train loss=0.5750719308853149
Test set avg_accuracy=87.16% avg_sensitivity=78.22%, avg_specificity=89.75% avg_auc=93.10%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.655129 Test loss=0.289145 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.6295889616012573
[5/24] Train loss=0.7007532119750977
[10/24] Train loss=0.701022744178772
[15/24] Train loss=0.599865198135376
[20/24] Train loss=0.5770791172981262
Test set avg_accuracy=87.49% avg_sensitivity=77.46%, avg_specificity=90.39% avg_auc=93.13%
Best model saved!! Metric=22.47461671697026!!
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.652691 Test loss=0.283922 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.6391493678092957
[5/24] Train loss=0.6818893551826477
[10/24] Train loss=0.7033244371414185
[15/24] Train loss=0.6026661396026611
[20/24] Train loss=0.5706738829612732
Test set avg_accuracy=87.30% avg_sensitivity=77.93%, avg_specificity=90.02% avg_auc=93.14%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.651947 Test loss=0.286476 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.628803014755249
[5/24] Train loss=0.6943153142929077
[10/24] Train loss=0.6987205743789673
[15/24] Train loss=0.5871824026107788
[20/24] Train loss=0.5740495324134827
Test set avg_accuracy=87.36% avg_sensitivity=78.10%, avg_specificity=90.04% avg_auc=93.23%
Best model saved!! Metric=22.724358803055637!!
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.652231 Test loss=0.285320 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.6243522763252258
[5/24] Train loss=0.6837035417556763
[10/24] Train loss=0.6963561773300171
[15/24] Train loss=0.5801380276679993
[20/24] Train loss=0.5667277574539185
Test set avg_accuracy=87.58% avg_sensitivity=76.88%, avg_specificity=90.68% avg_auc=93.22%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.651804 Test loss=0.281257 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.6249752640724182
[5/24] Train loss=0.6897040605545044
[10/24] Train loss=0.6868889331817627
[15/24] Train loss=0.5886572599411011
[20/24] Train loss=0.563316822052002
Test set avg_accuracy=87.58% avg_sensitivity=77.29%, avg_specificity=90.56% avg_auc=93.24%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.652397 Test loss=0.281778 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.6209477782249451
[5/24] Train loss=0.7071284055709839
[10/24] Train loss=0.7030594348907471
[15/24] Train loss=0.6005396842956543
[20/24] Train loss=0.5643380284309387
Test set avg_accuracy=85.60% avg_sensitivity=82.97%, avg_specificity=86.36% avg_auc=93.23%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.661064 Test loss=0.316642 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.6183491349220276
[5/24] Train loss=0.6912398338317871
[10/24] Train loss=0.7012135982513428
[15/24] Train loss=0.6129107475280762
[20/24] Train loss=0.6039175391197205
Test set avg_accuracy=84.71% avg_sensitivity=85.63%, avg_specificity=84.45% avg_auc=93.19%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.658788 Test loss=0.338547 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.6325713396072388
[5/24] Train loss=0.7121931910514832
[10/24] Train loss=0.6948815584182739
[15/24] Train loss=0.600084662437439
[20/24] Train loss=0.5840886235237122
Test set avg_accuracy=85.69% avg_sensitivity=83.37%, avg_specificity=86.36% avg_auc=93.24%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.647405 Test loss=0.316896 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.6231368184089661
[5/24] Train loss=0.6917211413383484
[10/24] Train loss=0.6880546808242798
[15/24] Train loss=0.5819799304008484
[20/24] Train loss=0.5764620900154114
Test set avg_accuracy=85.60% avg_sensitivity=83.37%, avg_specificity=86.24% avg_auc=93.25%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.643286 Test loss=0.318379 Current lr=[0.000156543481933168]

[0/24] Train loss=0.6263929605484009
[5/24] Train loss=0.6900789141654968
[10/24] Train loss=0.6973127126693726
[15/24] Train loss=0.5979627370834351
[20/24] Train loss=0.5894083976745605
Test set avg_accuracy=85.52% avg_sensitivity=83.66%, avg_specificity=86.06% avg_auc=93.29%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.645474 Test loss=0.319220 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.6112125515937805
[5/24] Train loss=0.7031205892562866
[10/24] Train loss=0.6839575171470642
[15/24] Train loss=0.5778692364692688
[20/24] Train loss=0.5806965231895447
Test set avg_accuracy=85.91% avg_sensitivity=83.08%, avg_specificity=86.73% avg_auc=93.26%
Best model saved!! Metric=22.98231325778113!!
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.642092 Test loss=0.312707 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.6215174794197083
[5/24] Train loss=0.6988485455513
[10/24] Train loss=0.700281023979187
[15/24] Train loss=0.5917093753814697
[20/24] Train loss=0.5727676153182983
Test set avg_accuracy=85.73% avg_sensitivity=84.18%, avg_specificity=86.18% avg_auc=93.35%
Best model saved!! Metric=23.441692711262718!!
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.641595 Test loss=0.319019 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.6250832676887512
[5/24] Train loss=0.6962339282035828
[10/24] Train loss=0.6834613084793091
[15/24] Train loss=0.58890700340271
[20/24] Train loss=0.573719322681427
Test set avg_accuracy=86.12% avg_sensitivity=83.02%, avg_specificity=87.02% avg_auc=93.36%
Best model saved!! Metric=23.52366516417615!!
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.639588 Test loss=0.311745 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.6158133149147034
[5/24] Train loss=0.6913530230522156
[10/24] Train loss=0.6788046956062317
[15/24] Train loss=0.5860927700996399
[20/24] Train loss=0.5767140984535217
Test set avg_accuracy=85.74% avg_sensitivity=83.66%, avg_specificity=86.35% avg_auc=93.38%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.636949 Test loss=0.315581 Current lr=[0.000134135431043539]

[0/24] Train loss=0.6155040264129639
[5/24] Train loss=0.6806207895278931
[10/24] Train loss=0.6687500476837158
[15/24] Train loss=0.5776463150978088
[20/24] Train loss=0.5745648145675659
Test set avg_accuracy=85.87% avg_sensitivity=83.72%, avg_specificity=86.50% avg_auc=93.37%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.635397 Test loss=0.315280 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.624858558177948
[5/24] Train loss=0.6837347149848938
[10/24] Train loss=0.6740388870239258
[15/24] Train loss=0.5687350630760193
[20/24] Train loss=0.5815519690513611
Test set avg_accuracy=86.02% avg_sensitivity=83.37%, avg_specificity=86.78% avg_auc=93.45%
Best model saved!! Metric=23.619019662283378!!
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.633604 Test loss=0.310736 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.6099976897239685
[5/24] Train loss=0.682743489742279
[10/24] Train loss=0.6719291806221008
[15/24] Train loss=0.5751448273658752
[20/24] Train loss=0.5670837759971619
Test set avg_accuracy=85.92% avg_sensitivity=83.55%, avg_specificity=86.61% avg_auc=93.42%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.633022 Test loss=0.312507 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.6208720803260803
[5/24] Train loss=0.6861302852630615
[10/24] Train loss=0.6815641522407532
[15/24] Train loss=0.5738278031349182
[20/24] Train loss=0.5652250647544861
Test set avg_accuracy=86.21% avg_sensitivity=82.97%, avg_specificity=87.15% avg_auc=93.42%
Best model saved!! Metric=23.753300327253058!!
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.630670 Test loss=0.308053 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.6135386228561401
[5/24] Train loss=0.6804249286651611
[10/24] Train loss=0.6694810390472412
[15/24] Train loss=0.571320652961731
[20/24] Train loss=0.5742983818054199
Test set avg_accuracy=86.13% avg_sensitivity=83.49%, avg_specificity=86.90% avg_auc=93.43%
Best model saved!! Metric=23.951959369919308!!
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.630499 Test loss=0.310822 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.6129993796348572
[5/24] Train loss=0.6831741333007812
[10/24] Train loss=0.6652356386184692
[15/24] Train loss=0.5702232718467712
[20/24] Train loss=0.5595035552978516
Test set avg_accuracy=86.11% avg_sensitivity=83.26%, avg_specificity=86.93% avg_auc=93.44%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.629248 Test loss=0.310461 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.6087902188301086
[5/24] Train loss=0.6841672658920288
[10/24] Train loss=0.6616328358650208
[15/24] Train loss=0.5656114220619202
[20/24] Train loss=0.565293550491333
Test set avg_accuracy=86.00% avg_sensitivity=83.60%, avg_specificity=86.70% avg_auc=93.42%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.626775 Test loss=0.312212 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.6093544363975525
[5/24] Train loss=0.6963598132133484
[10/24] Train loss=0.676120936870575
[15/24] Train loss=0.5661913752555847
[20/24] Train loss=0.559601902961731
Test set avg_accuracy=86.11% avg_sensitivity=82.85%, avg_specificity=87.05% avg_auc=93.40%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.627335 Test loss=0.309134 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.6029719710350037
[5/24] Train loss=0.6703657507896423
[10/24] Train loss=0.6627799272537231
[15/24] Train loss=0.5642310380935669
[20/24] Train loss=0.5612371563911438
Test set avg_accuracy=86.00% avg_sensitivity=83.08%, avg_specificity=86.85% avg_auc=93.43%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.620847 Test loss=0.310483 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.6064050793647766
[5/24] Train loss=0.6868440508842468
[10/24] Train loss=0.6765246391296387
[15/24] Train loss=0.5571749806404114
[20/24] Train loss=0.5618082284927368
Test set avg_accuracy=86.00% avg_sensitivity=83.72%, avg_specificity=86.66% avg_auc=93.40%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.625466 Test loss=0.314535 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.6056714653968811
[5/24] Train loss=0.6805758476257324
[10/24] Train loss=0.6693881154060364
[15/24] Train loss=0.5554125905036926
[20/24] Train loss=0.563058078289032
Test set avg_accuracy=85.79% avg_sensitivity=84.36%, avg_specificity=86.21% avg_auc=93.49%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.622607 Test loss=0.316771 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.6003624200820923
[5/24] Train loss=0.6834264397621155
[10/24] Train loss=0.6743639707565308
[15/24] Train loss=0.5511261224746704
[20/24] Train loss=0.5578166842460632
Test set avg_accuracy=85.85% avg_sensitivity=84.94%, avg_specificity=86.11% avg_auc=93.50%
Best model saved!! Metric=24.39230728503145!!
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.624058 Test loss=0.320556 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.6003035306930542
[5/24] Train loss=0.6675598621368408
[10/24] Train loss=0.6729155778884888
[15/24] Train loss=0.5647159218788147
[20/24] Train loss=0.5586584806442261
Test set avg_accuracy=85.59% avg_sensitivity=85.28%, avg_specificity=85.67% avg_auc=93.51%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.622591 Test loss=0.323734 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.6176923513412476
[5/24] Train loss=0.6836827993392944
[10/24] Train loss=0.6656734347343445
[15/24] Train loss=0.5569400787353516
[20/24] Train loss=0.5588130950927734
Test set avg_accuracy=84.99% avg_sensitivity=86.15%, avg_specificity=84.65% avg_auc=93.54%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.624112 Test loss=0.333835 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.6132680773735046
[5/24] Train loss=0.6958088278770447
[10/24] Train loss=0.6781482696533203
[15/24] Train loss=0.5563100576400757
[20/24] Train loss=0.5695743560791016
Test set avg_accuracy=85.00% avg_sensitivity=86.62%, avg_specificity=84.53% avg_auc=93.55%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.620724 Test loss=0.337639 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.6250782608985901
[5/24] Train loss=0.6779544949531555
[10/24] Train loss=0.6614746451377869
[15/24] Train loss=0.5749561190605164
[20/24] Train loss=0.5799024701118469
Test set avg_accuracy=85.30% avg_sensitivity=85.46%, avg_specificity=85.25% avg_auc=93.56%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.624396 Test loss=0.327528 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.6177099943161011
[5/24] Train loss=0.6609032154083252
[10/24] Train loss=0.6508917808532715
[15/24] Train loss=0.5781829953193665
[20/24] Train loss=0.5897943377494812
Test set avg_accuracy=86.16% avg_sensitivity=83.78%, avg_specificity=86.85% avg_auc=93.60%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.620881 Test loss=0.309367 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.6040715575218201
[5/24] Train loss=0.660794734954834
[10/24] Train loss=0.654025673866272
[15/24] Train loss=0.5578428506851196
[20/24] Train loss=0.5634177923202515
Test set avg_accuracy=86.20% avg_sensitivity=83.49%, avg_specificity=86.98% avg_auc=93.59%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.615854 Test loss=0.307121 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.6026667356491089
[5/24] Train loss=0.6641045212745667
[10/24] Train loss=0.6447787284851074
[15/24] Train loss=0.5575047731399536
[20/24] Train loss=0.5577670335769653
Test set avg_accuracy=86.32% avg_sensitivity=83.72%, avg_specificity=87.07% avg_auc=93.58%
Best model saved!! Metric=24.67895432572699!!
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.616054 Test loss=0.307660 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.602250337600708
[5/24] Train loss=0.6611891984939575
[10/24] Train loss=0.6468703150749207
[15/24] Train loss=0.5639625787734985
[20/24] Train loss=0.5534175038337708
Test set avg_accuracy=86.45% avg_sensitivity=83.37%, avg_specificity=87.34% avg_auc=93.61%
Best model saved!! Metric=24.75873744076837!!
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.613291 Test loss=0.304087 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.6002252101898193
[5/24] Train loss=0.6612450480461121
[10/24] Train loss=0.6524108052253723
[15/24] Train loss=0.5621021389961243
[20/24] Train loss=0.5726062059402466
Test set avg_accuracy=86.42% avg_sensitivity=83.43%, avg_specificity=87.29% avg_auc=93.63%
Best model saved!! Metric=24.7688507140021!!
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.614212 Test loss=0.304601 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.6072355508804321
[5/24] Train loss=0.6511431336402893
[10/24] Train loss=0.65342116355896
[15/24] Train loss=0.5469927191734314
[20/24] Train loss=0.5514490008354187
Test set avg_accuracy=86.34% avg_sensitivity=83.08%, avg_specificity=87.29% avg_auc=93.60%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.610604 Test loss=0.305162 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.5911640524864197
[5/24] Train loss=0.6498056054115295
[10/24] Train loss=0.6447837948799133
[15/24] Train loss=0.555466890335083
[20/24] Train loss=0.5606870055198669
Test set avg_accuracy=86.46% avg_sensitivity=83.14%, avg_specificity=87.42% avg_auc=93.62%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.610403 Test loss=0.302745 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.5965068936347961
[5/24] Train loss=0.6554442644119263
[10/24] Train loss=0.641891360282898
[15/24] Train loss=0.5651192665100098
[20/24] Train loss=0.5576302409172058
Test set avg_accuracy=86.38% avg_sensitivity=83.37%, avg_specificity=87.25% avg_auc=93.63%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.610862 Test loss=0.305226 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.5923460721969604
[5/24] Train loss=0.6590771079063416
[10/24] Train loss=0.6527884006500244
[15/24] Train loss=0.5560349822044373
[20/24] Train loss=0.5581637620925903
Test set avg_accuracy=86.55% avg_sensitivity=83.14%, avg_specificity=87.54% avg_auc=93.65%
Best model saved!! Metric=24.874114036318147!!
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.608668 Test loss=0.302531 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.5874484181404114
[5/24] Train loss=0.6648080348968506
[10/24] Train loss=0.6441103219985962
[15/24] Train loss=0.5586680173873901
[20/24] Train loss=0.5525712370872498
Test set avg_accuracy=86.42% avg_sensitivity=82.91%, avg_specificity=87.44% avg_auc=93.62%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.611095 Test loss=0.303735 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.5961831212043762
[5/24] Train loss=0.6570413708686829
[10/24] Train loss=0.6417530179023743
[15/24] Train loss=0.5502267479896545
[20/24] Train loss=0.550886332988739
Test set avg_accuracy=86.55% avg_sensitivity=82.85%, avg_specificity=87.62% avg_auc=93.63%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.606972 Test loss=0.301134 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.5841463804244995
[5/24] Train loss=0.6666233539581299
[10/24] Train loss=0.6430526375770569
[15/24] Train loss=0.5577442646026611
[20/24] Train loss=0.5570496916770935
Test set avg_accuracy=86.48% avg_sensitivity=83.20%, avg_specificity=87.44% avg_auc=93.65%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.607178 Test loss=0.302233 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.5944830775260925
[5/24] Train loss=0.656516432762146
[10/24] Train loss=0.6479517817497253
[15/24] Train loss=0.5447787046432495
[20/24] Train loss=0.5609091520309448
Test set avg_accuracy=86.60% avg_sensitivity=82.97%, avg_specificity=87.66% avg_auc=93.64%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.605837 Test loss=0.301137 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.585598886013031
[5/24] Train loss=0.6500322222709656
[10/24] Train loss=0.6359793543815613
[15/24] Train loss=0.5551778674125671
[20/24] Train loss=0.5645729303359985
Test set avg_accuracy=86.50% avg_sensitivity=83.43%, avg_specificity=87.39% avg_auc=93.63%
Best model saved!! Metric=24.94881383095202!!
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.607195 Test loss=0.304325 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.591840922832489
[5/24] Train loss=0.6397901177406311
[10/24] Train loss=0.6442514061927795
[15/24] Train loss=0.5547462701797485
[20/24] Train loss=0.5428333282470703
Test set avg_accuracy=86.39% avg_sensitivity=83.37%, avg_specificity=87.27% avg_auc=93.64%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.605514 Test loss=0.304849 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.5904204249382019
[5/24] Train loss=0.6412647366523743
[10/24] Train loss=0.6361125111579895
[15/24] Train loss=0.5518617033958435
[20/24] Train loss=0.554064154624939
Test set avg_accuracy=86.45% avg_sensitivity=83.43%, avg_specificity=87.32% avg_auc=93.63%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.605753 Test loss=0.304246 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.5831448435783386
[5/24] Train loss=0.6527070999145508
[10/24] Train loss=0.6462714076042175
[15/24] Train loss=0.5480554103851318
[20/24] Train loss=0.5472638010978699
Test set avg_accuracy=86.50% avg_sensitivity=83.66%, avg_specificity=87.32% avg_auc=93.63%
Best model saved!! Metric=25.11119237545948!!
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.605702 Test loss=0.305531 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.6025922298431396
[5/24] Train loss=0.6502591967582703
[10/24] Train loss=0.6446396708488464
[15/24] Train loss=0.551474928855896
[20/24] Train loss=0.5477436780929565
Test set avg_accuracy=86.56% avg_sensitivity=83.43%, avg_specificity=87.47% avg_auc=93.63%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.606314 Test loss=0.304524 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.5878523588180542
[5/24] Train loss=0.6443706154823303
[10/24] Train loss=0.6399627923965454
[15/24] Train loss=0.5525287985801697
[20/24] Train loss=0.553272008895874
Test set avg_accuracy=86.60% avg_sensitivity=83.31%, avg_specificity=87.55% avg_auc=93.63%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.605776 Test loss=0.303354 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.5934049487113953
[5/24] Train loss=0.6417263746261597
[10/24] Train loss=0.6372237205505371
[15/24] Train loss=0.5515788197517395
[20/24] Train loss=0.5571434497833252
Test set avg_accuracy=86.71% avg_sensitivity=82.97%, avg_specificity=87.79% avg_auc=93.64%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.607703 Test loss=0.299992 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.5902689695358276
[5/24] Train loss=0.6405084133148193
[10/24] Train loss=0.6424860954284668
[15/24] Train loss=0.5450466275215149
[20/24] Train loss=0.5584128499031067
Test set avg_accuracy=86.82% avg_sensitivity=82.56%, avg_specificity=88.06% avg_auc=93.64%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.603899 Test loss=0.297908 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.5944980978965759
[5/24] Train loss=0.6465008854866028
[10/24] Train loss=0.6505086421966553
[15/24] Train loss=0.5463100075721741
[20/24] Train loss=0.5468646883964539
Test set avg_accuracy=86.65% avg_sensitivity=82.79%, avg_specificity=87.77% avg_auc=93.65%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.604054 Test loss=0.299710 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.5888544321060181
[5/24] Train loss=0.6598303318023682
[10/24] Train loss=0.6360617876052856
[15/24] Train loss=0.5483362078666687
[20/24] Train loss=0.5499643087387085
Test set avg_accuracy=86.68% avg_sensitivity=83.02%, avg_specificity=87.74% avg_auc=93.64%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.603811 Test loss=0.300232 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.5876227617263794
[5/24] Train loss=0.642614483833313
[10/24] Train loss=0.6347154378890991
[15/24] Train loss=0.5533530116081238
[20/24] Train loss=0.553142249584198
Test set avg_accuracy=86.68% avg_sensitivity=82.79%, avg_specificity=87.81% avg_auc=93.65%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.601682 Test loss=0.299800 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.5914186835289001
[5/24] Train loss=0.6453734040260315
[10/24] Train loss=0.6404425501823425
[15/24] Train loss=0.5502640008926392
[20/24] Train loss=0.5434944033622742
Test set avg_accuracy=86.61% avg_sensitivity=82.79%, avg_specificity=87.72% avg_auc=93.65%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.600737 Test loss=0.299791 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.5883563160896301
[5/24] Train loss=0.6487434506416321
[10/24] Train loss=0.6443674564361572
[15/24] Train loss=0.5467649698257446
[20/24] Train loss=0.5489821434020996
Test set avg_accuracy=86.61% avg_sensitivity=82.91%, avg_specificity=87.69% avg_auc=93.65%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.602968 Test loss=0.299973 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.5791878700256348
[5/24] Train loss=0.6454994678497314
[10/24] Train loss=0.6449679136276245
[15/24] Train loss=0.5439615249633789
[20/24] Train loss=0.552933394908905
Test set avg_accuracy=86.64% avg_sensitivity=82.79%, avg_specificity=87.76% avg_auc=93.65%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.604750 Test loss=0.299622 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.5894688963890076
[5/24] Train loss=0.6298068165779114
[10/24] Train loss=0.6296489834785461
[15/24] Train loss=0.5387998819351196
[20/24] Train loss=0.5506128668785095
Test set avg_accuracy=86.69% avg_sensitivity=82.73%, avg_specificity=87.84% avg_auc=93.65%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.600663 Test loss=0.298984 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.5894349217414856
[5/24] Train loss=0.6513957977294922
[10/24] Train loss=0.6423850059509277
[15/24] Train loss=0.5562536120414734
[20/24] Train loss=0.5549513697624207
Test set avg_accuracy=86.69% avg_sensitivity=82.91%, avg_specificity=87.79% avg_auc=93.65%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.603644 Test loss=0.299596 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.5929703116416931
[5/24] Train loss=0.6507020592689514
[10/24] Train loss=0.6513720750808716
[15/24] Train loss=0.5366436839103699
[20/24] Train loss=0.5441035628318787
Test set avg_accuracy=86.68% avg_sensitivity=82.91%, avg_specificity=87.77% avg_auc=93.65%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.602022 Test loss=0.299753 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.5775759220123291
[5/24] Train loss=0.6429430842399597
[10/24] Train loss=0.644284188747406
[15/24] Train loss=0.5479387640953064
[20/24] Train loss=0.5588821768760681
Test set avg_accuracy=86.65% avg_sensitivity=82.79%, avg_specificity=87.77% avg_auc=93.65%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.603070 Test loss=0.299649 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.5992489457130432
[5/24] Train loss=0.6424136161804199
[10/24] Train loss=0.6422006487846375
[15/24] Train loss=0.5499643087387085
[20/24] Train loss=0.5491631627082825
Test set avg_accuracy=86.65% avg_sensitivity=82.79%, avg_specificity=87.77% avg_auc=93.65%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.601743 Test loss=0.299627 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.5965325832366943
[5/24] Train loss=0.6500211954116821
[10/24] Train loss=0.6371089220046997
[15/24] Train loss=0.5566617846488953
[20/24] Train loss=0.5489771366119385
Test set avg_accuracy=86.65% avg_sensitivity=82.79%, avg_specificity=87.77% avg_auc=93.65%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.601435 Test loss=0.299627 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=86.50% sen=83.66%, spe=87.32%, auc=93.63%!
Fold[10] Avg_overlap=0.64%(±0.232872478291193)
Final Avg Result: avg_acc=85.20%(±1.6910493116411478) avg_sen=85.09% (±2.248687503453629) avg_spe=85.23% (±2.394423510178422) avg_auc=92.90% (±1.0787242029174604) avg_overlap=0.63% (±0.015994022283158035)
