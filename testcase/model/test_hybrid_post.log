{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'HybridCNNRNN',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.947068989276886
[5/24] Train loss=0.7749770283699036
[10/24] Train loss=0.6999996304512024
[15/24] Train loss=0.6630908250808716
[20/24] Train loss=0.6421300768852234
Test set avg_accuracy=73.70% avg_sensitivity=0.05%, avg_specificity=100.00% avg_auc=50.82%
Best model saved!! Metric=-101.43325060778741!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.717968 Test loss=0.595626 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6205382347106934
[5/24] Train loss=0.5857149958610535
[10/24] Train loss=0.6076186299324036
[15/24] Train loss=0.6111261248588562
[20/24] Train loss=0.6146648526191711
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.52%
Best model saved!! Metric=-99.79700454141184!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.606342 Test loss=0.579182 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.5947872400283813
[5/24] Train loss=0.5730288028717041
[10/24] Train loss=0.5957696437835693
[15/24] Train loss=0.6018608212471008
[20/24] Train loss=0.600226640701294
Test set avg_accuracy=73.70% avg_sensitivity=0.05%, avg_specificity=100.00% avg_auc=55.44%
Best model saved!! Metric=-96.81138349922708!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.593085 Test loss=0.574195 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.5969448685646057
[5/24] Train loss=0.5775496363639832
[10/24] Train loss=0.5825607180595398
[15/24] Train loss=0.5968550443649292
[20/24] Train loss=0.5957780480384827
Test set avg_accuracy=73.70% avg_sensitivity=0.05%, avg_specificity=100.00% avg_auc=58.61%
Best model saved!! Metric=-93.64125930669451!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.590373 Test loss=0.568842 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5817493200302124
[5/24] Train loss=0.5682834982872009
[10/24] Train loss=0.5832363367080688
[15/24] Train loss=0.5955013632774353
[20/24] Train loss=0.5990728735923767
Test set avg_accuracy=73.70% avg_sensitivity=0.05%, avg_specificity=100.00% avg_auc=62.42%
Best model saved!! Metric=-89.83253645941127!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.582736 Test loss=0.562098 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5769608020782471
[5/24] Train loss=0.561261773109436
[10/24] Train loss=0.5786358714103699
[15/24] Train loss=0.5831697583198547
[20/24] Train loss=0.5777599811553955
Test set avg_accuracy=73.70% avg_sensitivity=0.05%, avg_specificity=100.00% avg_auc=65.87%
Best model saved!! Metric=-86.38027574296682!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.575737 Test loss=0.555604 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5694595575332642
[5/24] Train loss=0.5501499176025391
[10/24] Train loss=0.570023775100708
[15/24] Train loss=0.5760554075241089
[20/24] Train loss=0.5746132731437683
Test set avg_accuracy=73.70% avg_sensitivity=0.05%, avg_specificity=100.00% avg_auc=69.60%
Best model saved!! Metric=-82.65535664600303!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.568356 Test loss=0.548822 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5615668296813965
[5/24] Train loss=0.5436685085296631
[10/24] Train loss=0.5659276843070984
[15/24] Train loss=0.5662498474121094
[20/24] Train loss=0.5678308606147766
Test set avg_accuracy=73.70% avg_sensitivity=0.05%, avg_specificity=100.00% avg_auc=72.53%
Best model saved!! Metric=-79.72669777443896!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.559927 Test loss=0.541199 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5505922436714172
[5/24] Train loss=0.5345479249954224
[10/24] Train loss=0.5521486401557922
[15/24] Train loss=0.5576584935188293
[20/24] Train loss=0.5562981367111206
Test set avg_accuracy=73.57% avg_sensitivity=0.15%, avg_specificity=99.79% avg_auc=75.22%
Best model saved!! Metric=-77.27354806627146!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.551061 Test loss=0.532191 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.545102596282959
[5/24] Train loss=0.5210646986961365
[10/24] Train loss=0.5469807982444763
[15/24] Train loss=0.5429657697677612
[20/24] Train loss=0.5422607064247131
Test set avg_accuracy=73.22% avg_sensitivity=0.15%, avg_specificity=99.31% avg_auc=77.58%
Best model saved!! Metric=-75.7463834109797!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.541719 Test loss=0.520739 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5294629335403442
[5/24] Train loss=0.5037869811058044
[10/24] Train loss=0.5322834253311157
[15/24] Train loss=0.5339166522026062
[20/24] Train loss=0.5298706889152527
Test set avg_accuracy=72.92% avg_sensitivity=1.39%, avg_specificity=98.46% avg_auc=79.24%
Best model saved!! Metric=-73.9909897233551!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.529174 Test loss=0.507058 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5124720931053162
[5/24] Train loss=0.4942101538181305
[10/24] Train loss=0.5278196334838867
[15/24] Train loss=0.5153601169586182
[20/24] Train loss=0.5106585621833801
Test set avg_accuracy=72.75% avg_sensitivity=3.27%, avg_specificity=97.56% avg_auc=80.79%
Best model saved!! Metric=-71.63151113562898!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.515460 Test loss=0.491136 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4911124110221863
[5/24] Train loss=0.46826815605163574
[10/24] Train loss=0.5113409161567688
[15/24] Train loss=0.4992728531360626
[20/24] Train loss=0.4978196322917938
Test set avg_accuracy=72.90% avg_sensitivity=11.58%, avg_specificity=94.80% avg_auc=82.08%
Best model saved!! Metric=-64.63634786597467!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.497847 Test loss=0.473128 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4755738079547882
[5/24] Train loss=0.4595765173435211
[10/24] Train loss=0.49344268441200256
[15/24] Train loss=0.4823606014251709
[20/24] Train loss=0.4773242473602295
Test set avg_accuracy=75.03% avg_sensitivity=24.64%, avg_specificity=93.02% avg_auc=83.32%
Best model saved!! Metric=-49.99229722924678!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.482136 Test loss=0.455591 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.45732003450393677
[5/24] Train loss=0.43928223848342896
[10/24] Train loss=0.48914477229118347
[15/24] Train loss=0.4605647623538971
[20/24] Train loss=0.4594857096672058
Test set avg_accuracy=76.91% avg_sensitivity=38.64%, avg_specificity=90.58% avg_auc=84.03%
Best model saved!! Metric=-35.83166330762918!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.466811 Test loss=0.442921 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.44465988874435425
[5/24] Train loss=0.42787548899650574
[10/24] Train loss=0.46908649802207947
[15/24] Train loss=0.45055216550827026
[20/24] Train loss=0.4457322657108307
Test set avg_accuracy=78.85% avg_sensitivity=48.44%, avg_specificity=89.72% avg_auc=84.93%
Best model saved!! Metric=-24.058199591177818!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.454255 Test loss=0.431118 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4347195029258728
[5/24] Train loss=0.4150329828262329
[10/24] Train loss=0.4635866582393646
[15/24] Train loss=0.43726494908332825
[20/24] Train loss=0.4328524172306061
Test set avg_accuracy=79.77% avg_sensitivity=53.19%, avg_specificity=89.26% avg_auc=85.66%
Best model saved!! Metric=-18.131002206171217!!
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.442494 Test loss=0.420558 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4167105257511139
[5/24] Train loss=0.4126884341239929
[10/24] Train loss=0.45340171456336975
[15/24] Train loss=0.4319554567337036
[20/24] Train loss=0.42092427611351013
Test set avg_accuracy=79.97% avg_sensitivity=53.19%, avg_specificity=89.54% avg_auc=86.27%
Best model saved!! Metric=-17.023771021779567!!
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.432281 Test loss=0.408333 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4073506295681
[5/24] Train loss=0.39648279547691345
[10/24] Train loss=0.4470842182636261
[15/24] Train loss=0.42909473180770874
[20/24] Train loss=0.4068310558795929
Test set avg_accuracy=80.27% avg_sensitivity=47.75%, avg_specificity=91.89% avg_auc=86.82%
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.422937 Test loss=0.397356 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.39294105768203735
[5/24] Train loss=0.3809555470943451
[10/24] Train loss=0.431387722492218
[15/24] Train loss=0.4184859097003937
[20/24] Train loss=0.40270525217056274
Test set avg_accuracy=79.77% avg_sensitivity=43.69%, avg_specificity=92.65% avg_auc=87.15%
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.414688 Test loss=0.391246 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3806897699832916
[5/24] Train loss=0.3805508613586426
[10/24] Train loss=0.41534578800201416
[15/24] Train loss=0.39986535906791687
[20/24] Train loss=0.38896873593330383
Test set avg_accuracy=80.35% avg_sensitivity=44.29%, avg_specificity=93.23% avg_auc=87.52%
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.403808 Test loss=0.385477 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.37743857502937317
[5/24] Train loss=0.37556883692741394
[10/24] Train loss=0.4027000069618225
[15/24] Train loss=0.39267387986183167
[20/24] Train loss=0.386000394821167
Test set avg_accuracy=81.98% avg_sensitivity=53.19%, avg_specificity=92.26% avg_auc=88.05%
Best model saved!! Metric=-10.517428240370137!!
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.396360 Test loss=0.378622 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3703523278236389
[5/24] Train loss=0.3672802746295929
[10/24] Train loss=0.3945828676223755
[15/24] Train loss=0.37958773970603943
[20/24] Train loss=0.3794499933719635
Test set avg_accuracy=81.99% avg_sensitivity=49.63%, avg_specificity=93.55% avg_auc=88.35%
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.389205 Test loss=0.373787 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.36157286167144775
[5/24] Train loss=0.36004748940467834
[10/24] Train loss=0.3990948498249054
[15/24] Train loss=0.3733392655849457
[20/24] Train loss=0.36969587206840515
Test set avg_accuracy=82.16% avg_sensitivity=48.84%, avg_specificity=94.06% avg_auc=88.57%
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.384777 Test loss=0.370455 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3599521815776825
[5/24] Train loss=0.35829266905784607
[10/24] Train loss=0.3857887387275696
[15/24] Train loss=0.3722653388977051
[20/24] Train loss=0.3618618845939636
Test set avg_accuracy=82.19% avg_sensitivity=48.14%, avg_specificity=94.35% avg_auc=88.72%
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.380935 Test loss=0.368457 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.35277724266052246
[5/24] Train loss=0.3600876033306122
[10/24] Train loss=0.38096484541893005
[15/24] Train loss=0.36728206276893616
[20/24] Train loss=0.35851287841796875
Test set avg_accuracy=82.29% avg_sensitivity=47.15%, avg_specificity=94.84% avg_auc=88.81%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.377445 Test loss=0.367837 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3433135151863098
[5/24] Train loss=0.36141589283943176
[10/24] Train loss=0.3755614757537842
[15/24] Train loss=0.3636379837989807
[20/24] Train loss=0.35628417134284973
Test set avg_accuracy=82.19% avg_sensitivity=47.25%, avg_specificity=94.66% avg_auc=88.94%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.373027 Test loss=0.366316 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.34153610467910767
[5/24] Train loss=0.35340410470962524
[10/24] Train loss=0.3753705620765686
[15/24] Train loss=0.3662739098072052
[20/24] Train loss=0.358377605676651
Test set avg_accuracy=82.85% avg_sensitivity=50.62%, avg_specificity=94.36% avg_auc=89.07%
Best model saved!! Metric=-9.09752535548175!!
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.370387 Test loss=0.363052 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3406742215156555
[5/24] Train loss=0.3422520160675049
[10/24] Train loss=0.37184062600135803
[15/24] Train loss=0.3703479468822479
[20/24] Train loss=0.3553696870803833
Test set avg_accuracy=83.10% avg_sensitivity=52.50%, avg_specificity=94.03% avg_auc=89.22%
Best model saved!! Metric=-7.157218570092532!!
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.367218 Test loss=0.360569 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3393704891204834
[5/24] Train loss=0.34589770436286926
[10/24] Train loss=0.3685310482978821
[15/24] Train loss=0.3611913323402405
[20/24] Train loss=0.35726046562194824
Test set avg_accuracy=83.07% avg_sensitivity=52.70%, avg_specificity=93.92% avg_auc=89.29%
Best model saved!! Metric=-7.020413667003332!!
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.366088 Test loss=0.359780 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.34001168608665466
[5/24] Train loss=0.34584346413612366
[10/24] Train loss=0.36977025866508484
[15/24] Train loss=0.3587930202484131
[20/24] Train loss=0.3557473421096802
Test set avg_accuracy=83.12% avg_sensitivity=52.85%, avg_specificity=93.94% avg_auc=89.26%
Best model saved!! Metric=-6.831448105984521!!
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.364531 Test loss=0.359772 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3320881724357605
[5/24] Train loss=0.34418901801109314
[10/24] Train loss=0.3689148426055908
[15/24] Train loss=0.3593517541885376
[20/24] Train loss=0.34968599677085876
Test set avg_accuracy=83.28% avg_sensitivity=51.41%, avg_specificity=94.66% avg_auc=89.24%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.363537 Test loss=0.361428 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.33626788854599
[5/24] Train loss=0.3452626168727875
[10/24] Train loss=0.3714073598384857
[15/24] Train loss=0.35781553387641907
[20/24] Train loss=0.34619274735450745
Test set avg_accuracy=83.40% avg_sensitivity=51.76%, avg_specificity=94.70% avg_auc=89.32%
Best model saved!! Metric=-6.825706951102276!!
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.362302 Test loss=0.360146 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.33229154348373413
[5/24] Train loss=0.3356872797012329
[10/24] Train loss=0.36509063839912415
[15/24] Train loss=0.3552045226097107
[20/24] Train loss=0.345296174287796
Test set avg_accuracy=82.84% avg_sensitivity=46.41%, avg_specificity=95.85% avg_auc=89.20%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.361259 Test loss=0.365479 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.33568620681762695
[5/24] Train loss=0.33937570452690125
[10/24] Train loss=0.36677560210227966
[15/24] Train loss=0.3487091362476349
[20/24] Train loss=0.34440067410469055
Test set avg_accuracy=82.93% avg_sensitivity=49.04%, avg_specificity=95.03% avg_auc=89.17%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.359702 Test loss=0.364703 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.333603173494339
[5/24] Train loss=0.3354971706867218
[10/24] Train loss=0.36013495922088623
[15/24] Train loss=0.35265788435935974
[20/24] Train loss=0.3415495753288269
Test set avg_accuracy=83.23% avg_sensitivity=49.98%, avg_specificity=95.11% avg_auc=89.30%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.359262 Test loss=0.361847 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.32990947365760803
[5/24] Train loss=0.3374195992946625
[10/24] Train loss=0.36171984672546387
[15/24] Train loss=0.35351505875587463
[20/24] Train loss=0.3377353250980377
Test set avg_accuracy=82.93% avg_sensitivity=49.33%, avg_specificity=94.93% avg_auc=89.35%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.357457 Test loss=0.361459 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.33122479915618896
[5/24] Train loss=0.3358231484889984
[10/24] Train loss=0.361702561378479
[15/24] Train loss=0.3530213534832001
[20/24] Train loss=0.34171348810195923
Test set avg_accuracy=83.12% avg_sensitivity=50.32%, avg_specificity=94.84% avg_auc=89.45%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.356657 Test loss=0.359419 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3324030041694641
[5/24] Train loss=0.3388720452785492
[10/24] Train loss=0.36343005299568176
[15/24] Train loss=0.35252928733825684
[20/24] Train loss=0.34396207332611084
Test set avg_accuracy=83.33% avg_sensitivity=51.56%, avg_specificity=94.68% avg_auc=89.41%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.356882 Test loss=0.359819 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3265479505062103
[5/24] Train loss=0.3414500951766968
[10/24] Train loss=0.36366572976112366
[15/24] Train loss=0.356009304523468
[20/24] Train loss=0.3401060402393341
Test set avg_accuracy=83.28% avg_sensitivity=51.06%, avg_specificity=94.79% avg_auc=89.43%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.355915 Test loss=0.359681 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.32723110914230347
[5/24] Train loss=0.3389284312725067
[10/24] Train loss=0.3596722185611725
[15/24] Train loss=0.35605865716934204
[20/24] Train loss=0.339227557182312
Test set avg_accuracy=83.48% avg_sensitivity=51.51%, avg_specificity=94.89% avg_auc=89.48%
Best model saved!! Metric=-6.637009440638515!!
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.354424 Test loss=0.359087 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.32963791489601135
[5/24] Train loss=0.3370974361896515
[10/24] Train loss=0.3587447702884674
[15/24] Train loss=0.35588890314102173
[20/24] Train loss=0.3369024097919464
Test set avg_accuracy=82.97% avg_sensitivity=49.08%, avg_specificity=95.07% avg_auc=89.34%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.354441 Test loss=0.362371 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3266927897930145
[5/24] Train loss=0.33641842007637024
[10/24] Train loss=0.36031070351600647
[15/24] Train loss=0.35932472348213196
[20/24] Train loss=0.33851829171180725
Test set avg_accuracy=83.61% avg_sensitivity=52.10%, avg_specificity=94.86% avg_auc=89.52%
Best model saved!! Metric=-5.9149505094258075!!
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.353128 Test loss=0.358206 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3268709182739258
[5/24] Train loss=0.33565768599510193
[10/24] Train loss=0.3632526695728302
[15/24] Train loss=0.3566342890262604
[20/24] Train loss=0.34100762009620667
Test set avg_accuracy=83.29% avg_sensitivity=51.31%, avg_specificity=94.72% avg_auc=89.35%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.353869 Test loss=0.361010 Current lr=[0.00029967723776099]

[0/24] Train loss=0.32521170377731323
[5/24] Train loss=0.3353405296802521
[10/24] Train loss=0.3588809370994568
[15/24] Train loss=0.35376250743865967
[20/24] Train loss=0.3407807946205139
Test set avg_accuracy=83.27% avg_sensitivity=51.16%, avg_specificity=94.73% avg_auc=89.41%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.353421 Test loss=0.360340 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.32500579953193665
[5/24] Train loss=0.3410700559616089
[10/24] Train loss=0.3579164147377014
[15/24] Train loss=0.35578593611717224
[20/24] Train loss=0.34107789397239685
Test set avg_accuracy=83.12% avg_sensitivity=50.12%, avg_specificity=94.91% avg_auc=89.54%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.353690 Test loss=0.358399 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3267516493797302
[5/24] Train loss=0.3414289653301239
[10/24] Train loss=0.35678017139434814
[15/24] Train loss=0.358398973941803
[20/24] Train loss=0.3383614420890808
Test set avg_accuracy=82.99% avg_sensitivity=48.05%, avg_specificity=95.48% avg_auc=89.46%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.353826 Test loss=0.361778 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3257428705692291
[5/24] Train loss=0.33538809418678284
[10/24] Train loss=0.35656800866127014
[15/24] Train loss=0.35464078187942505
[20/24] Train loss=0.3396141231060028
Test set avg_accuracy=83.20% avg_sensitivity=50.07%, avg_specificity=95.03% avg_auc=89.49%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.353065 Test loss=0.359331 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.32115426659584045
[5/24] Train loss=0.33932048082351685
[10/24] Train loss=0.36222678422927856
[15/24] Train loss=0.3603593707084656
[20/24] Train loss=0.3407791256904602
Test set avg_accuracy=82.97% avg_sensitivity=49.43%, avg_specificity=94.95% avg_auc=89.42%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.353061 Test loss=0.360694 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3234489858150482
[5/24] Train loss=0.33550500869750977
[10/24] Train loss=0.3641493022441864
[15/24] Train loss=0.3562127649784088
[20/24] Train loss=0.3374955654144287
Test set avg_accuracy=82.94% avg_sensitivity=50.07%, avg_specificity=94.68% avg_auc=89.57%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.352623 Test loss=0.357940 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.326395183801651
[5/24] Train loss=0.33564165234565735
[10/24] Train loss=0.36317571997642517
[15/24] Train loss=0.3544742166996002
[20/24] Train loss=0.3375374674797058
Test set avg_accuracy=83.24% avg_sensitivity=51.16%, avg_specificity=94.70% avg_auc=89.48%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.351378 Test loss=0.358856 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3229288160800934
[5/24] Train loss=0.33692076802253723
[10/24] Train loss=0.35571300983428955
[15/24] Train loss=0.3522811532020569
[20/24] Train loss=0.3425567150115967
Test set avg_accuracy=83.23% avg_sensitivity=51.21%, avg_specificity=94.66% avg_auc=89.53%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.351500 Test loss=0.358173 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.32119205594062805
[5/24] Train loss=0.32985183596611023
[10/24] Train loss=0.3614719808101654
[15/24] Train loss=0.35723066329956055
[20/24] Train loss=0.3365938067436218
Test set avg_accuracy=83.45% avg_sensitivity=52.15%, avg_specificity=94.63% avg_auc=89.61%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.352081 Test loss=0.356501 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3207012116909027
[5/24] Train loss=0.335270494222641
[10/24] Train loss=0.3596822917461395
[15/24] Train loss=0.35489949584007263
[20/24] Train loss=0.33867838978767395
Test set avg_accuracy=83.14% avg_sensitivity=50.37%, avg_specificity=94.84% avg_auc=89.60%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.351504 Test loss=0.357766 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.32133305072784424
[5/24] Train loss=0.33786702156066895
[10/24] Train loss=0.3579384982585907
[15/24] Train loss=0.34977754950523376
[20/24] Train loss=0.3376765251159668
Test set avg_accuracy=83.29% avg_sensitivity=51.26%, avg_specificity=94.73% avg_auc=89.58%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.351603 Test loss=0.357982 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.32059425115585327
[5/24] Train loss=0.3340262770652771
[10/24] Train loss=0.3596813678741455
[15/24] Train loss=0.3552631139755249
[20/24] Train loss=0.34054192900657654
Test set avg_accuracy=82.38% avg_sensitivity=45.57%, avg_specificity=95.53% avg_auc=89.61%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.350691 Test loss=0.360555 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.325353741645813
[5/24] Train loss=0.33444151282310486
[10/24] Train loss=0.35544613003730774
[15/24] Train loss=0.34688347578048706
[20/24] Train loss=0.3394223153591156
Test set avg_accuracy=83.41% avg_sensitivity=51.81%, avg_specificity=94.70% avg_auc=89.45%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.351048 Test loss=0.358872 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.31999170780181885
[5/24] Train loss=0.3332090973854065
[10/24] Train loss=0.36147671937942505
[15/24] Train loss=0.35396960377693176
[20/24] Train loss=0.34246885776519775
Test set avg_accuracy=82.98% avg_sensitivity=49.38%, avg_specificity=94.98% avg_auc=89.65%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.350805 Test loss=0.357610 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3181935250759125
[5/24] Train loss=0.33543428778648376
[10/24] Train loss=0.3646613359451294
[15/24] Train loss=0.3515647351741791
[20/24] Train loss=0.3380696773529053
Test set avg_accuracy=83.32% avg_sensitivity=51.66%, avg_specificity=94.63% avg_auc=89.69%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.350857 Test loss=0.355237 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.31508293747901917
[5/24] Train loss=0.3368963301181793
[10/24] Train loss=0.3529249429702759
[15/24] Train loss=0.3515159487724304
[20/24] Train loss=0.33511883020401
Test set avg_accuracy=83.26% avg_sensitivity=51.46%, avg_specificity=94.61% avg_auc=89.60%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.349818 Test loss=0.357004 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.31913453340530396
[5/24] Train loss=0.33542928099632263
[10/24] Train loss=0.3597630560398102
[15/24] Train loss=0.35583364963531494
[20/24] Train loss=0.3347768783569336
Test set avg_accuracy=82.94% avg_sensitivity=49.73%, avg_specificity=94.80% avg_auc=89.54%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.349426 Test loss=0.359059 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.32191532850265503
[5/24] Train loss=0.3342784345149994
[10/24] Train loss=0.36053332686424255
[15/24] Train loss=0.3542156517505646
[20/24] Train loss=0.34021633863449097
Test set avg_accuracy=83.20% avg_sensitivity=51.01%, avg_specificity=94.70% avg_auc=89.65%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.351080 Test loss=0.356470 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3188117444515228
[5/24] Train loss=0.334416925907135
[10/24] Train loss=0.35862234234809875
[15/24] Train loss=0.3503718972206116
[20/24] Train loss=0.3360763192176819
Test set avg_accuracy=83.14% avg_sensitivity=51.01%, avg_specificity=94.61% avg_auc=89.57%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.349341 Test loss=0.357267 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3191419243812561
[5/24] Train loss=0.3322719931602478
[10/24] Train loss=0.3596712052822113
[15/24] Train loss=0.3509015440940857
[20/24] Train loss=0.3330143094062805
Test set avg_accuracy=83.12% avg_sensitivity=50.37%, avg_specificity=94.82% avg_auc=89.54%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.349251 Test loss=0.358464 Current lr=[0.000276307469034998]

[0/24] Train loss=0.31849661469459534
[5/24] Train loss=0.33679473400115967
[10/24] Train loss=0.3573807179927826
[15/24] Train loss=0.35531380772590637
[20/24] Train loss=0.3363719582557678
Test set avg_accuracy=83.27% avg_sensitivity=51.61%, avg_specificity=94.58% avg_auc=89.66%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.349484 Test loss=0.355550 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.31829333305358887
[5/24] Train loss=0.33216238021850586
[10/24] Train loss=0.3586897850036621
[15/24] Train loss=0.354411780834198
[20/24] Train loss=0.3352932929992676
Test set avg_accuracy=83.09% avg_sensitivity=50.07%, avg_specificity=94.88% avg_auc=89.69%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.350086 Test loss=0.356426 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3175552189350128
[5/24] Train loss=0.33326175808906555
[10/24] Train loss=0.3620506227016449
[15/24] Train loss=0.3553586006164551
[20/24] Train loss=0.33051639795303345
Test set avg_accuracy=83.07% avg_sensitivity=50.32%, avg_specificity=94.77% avg_auc=89.67%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.348851 Test loss=0.356549 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3196759819984436
[5/24] Train loss=0.3309005796909332
[10/24] Train loss=0.3563738167285919
[15/24] Train loss=0.3510529398918152
[20/24] Train loss=0.3325904905796051
Test set avg_accuracy=83.26% avg_sensitivity=51.26%, avg_specificity=94.68% avg_auc=89.74%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.348834 Test loss=0.354810 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3175436854362488
[5/24] Train loss=0.33250492811203003
[10/24] Train loss=0.3567100167274475
[15/24] Train loss=0.3474483788013458
[20/24] Train loss=0.3336049020290375
Test set avg_accuracy=83.15% avg_sensitivity=51.01%, avg_specificity=94.63% avg_auc=89.71%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.348917 Test loss=0.355409 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.31789204478263855
[5/24] Train loss=0.3313857614994049
[10/24] Train loss=0.3540665805339813
[15/24] Train loss=0.35342103242874146
[20/24] Train loss=0.33314478397369385
Test set avg_accuracy=83.53% avg_sensitivity=53.09%, avg_specificity=94.40% avg_auc=89.68%
Best model saved!! Metric=-5.304266302616099!!
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.349830 Test loss=0.354329 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.31690892577171326
[5/24] Train loss=0.3301834464073181
[10/24] Train loss=0.3555386960506439
[15/24] Train loss=0.35037219524383545
[20/24] Train loss=0.3308594524860382
Test set avg_accuracy=83.33% avg_sensitivity=51.16%, avg_specificity=94.82% avg_auc=89.76%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.348436 Test loss=0.354311 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3179793059825897
[5/24] Train loss=0.33061686158180237
[10/24] Train loss=0.3539796471595764
[15/24] Train loss=0.3517979383468628
[20/24] Train loss=0.32972267270088196
Test set avg_accuracy=83.20% avg_sensitivity=51.16%, avg_specificity=94.65% avg_auc=89.69%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.348465 Test loss=0.355706 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3187069594860077
[5/24] Train loss=0.3293601870536804
[10/24] Train loss=0.3584105968475342
[15/24] Train loss=0.34313568472862244
[20/24] Train loss=0.3304752707481384
Test set avg_accuracy=83.46% avg_sensitivity=52.70%, avg_specificity=94.45% avg_auc=89.76%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.347973 Test loss=0.352807 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3155970275402069
[5/24] Train loss=0.32979610562324524
[10/24] Train loss=0.3597263693809509
[15/24] Train loss=0.34944573044776917
[20/24] Train loss=0.3268386423587799
Test set avg_accuracy=83.18% avg_sensitivity=49.93%, avg_specificity=95.05% avg_auc=89.70%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.347659 Test loss=0.356057 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3187042474746704
[5/24] Train loss=0.3316565454006195
[10/24] Train loss=0.36006051301956177
[15/24] Train loss=0.3520123362541199
[20/24] Train loss=0.32808804512023926
Test set avg_accuracy=83.03% avg_sensitivity=50.37%, avg_specificity=94.70% avg_auc=89.66%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.348239 Test loss=0.356510 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.31840142607688904
[5/24] Train loss=0.328878253698349
[10/24] Train loss=0.3571992814540863
[15/24] Train loss=0.34807509183883667
[20/24] Train loss=0.32395389676094055
Test set avg_accuracy=83.32% avg_sensitivity=52.10%, avg_specificity=94.47% avg_auc=89.66%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.348347 Test loss=0.355063 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3160327970981598
[5/24] Train loss=0.32962220907211304
[10/24] Train loss=0.3562290668487549
[15/24] Train loss=0.3510601818561554
[20/24] Train loss=0.3243164122104645
Test set avg_accuracy=83.02% avg_sensitivity=50.27%, avg_specificity=94.72% avg_auc=89.67%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.347857 Test loss=0.356312 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3229779601097107
[5/24] Train loss=0.3322193920612335
[10/24] Train loss=0.3586772382259369
[15/24] Train loss=0.3476087152957916
[20/24] Train loss=0.33558064699172974
Test set avg_accuracy=82.80% avg_sensitivity=49.04%, avg_specificity=94.86% avg_auc=89.63%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.348582 Test loss=0.357465 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3130761981010437
[5/24] Train loss=0.33036988973617554
[10/24] Train loss=0.36201268434524536
[15/24] Train loss=0.3480931222438812
[20/24] Train loss=0.3304542899131775
Test set avg_accuracy=82.85% avg_sensitivity=48.39%, avg_specificity=95.16% avg_auc=89.61%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.349563 Test loss=0.357988 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.321029394865036
[5/24] Train loss=0.3307565748691559
[10/24] Train loss=0.361299604177475
[15/24] Train loss=0.34114009141921997
[20/24] Train loss=0.3349088728427887
Test set avg_accuracy=83.24% avg_sensitivity=51.11%, avg_specificity=94.72% avg_auc=89.50%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.350066 Test loss=0.357187 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3159317374229431
[5/24] Train loss=0.33233511447906494
[10/24] Train loss=0.3572559654712677
[15/24] Train loss=0.35303524136543274
[20/24] Train loss=0.3344506025314331
Test set avg_accuracy=83.78% avg_sensitivity=55.71%, avg_specificity=93.80% avg_auc=89.68%
Best model saved!! Metric=-3.026943318957393!!
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.349340 Test loss=0.352485 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.31417712569236755
[5/24] Train loss=0.3346015512943268
[10/24] Train loss=0.35680264234542847
[15/24] Train loss=0.3549623489379883
[20/24] Train loss=0.3302030563354492
Test set avg_accuracy=84.00% avg_sensitivity=56.16%, avg_specificity=93.94% avg_auc=89.62%
Best model saved!! Metric=-2.281541379999844!!
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.348260 Test loss=0.353141 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3142938017845154
[5/24] Train loss=0.33250144124031067
[10/24] Train loss=0.3606083393096924
[15/24] Train loss=0.3485456705093384
[20/24] Train loss=0.3325868844985962
Test set avg_accuracy=83.95% avg_sensitivity=56.85%, avg_specificity=93.62% avg_auc=89.68%
Best model saved!! Metric=-1.902600896350144!!
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.348889 Test loss=0.352347 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.31967273354530334
[5/24] Train loss=0.33229658007621765
[10/24] Train loss=0.3567160964012146
[15/24] Train loss=0.3577091097831726
[20/24] Train loss=0.3261568248271942
Test set avg_accuracy=84.06% avg_sensitivity=56.66%, avg_specificity=93.85% avg_auc=89.67%
Best model saved!! Metric=-1.7592392060865762!!
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.349225 Test loss=0.352468 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3141712546348572
[5/24] Train loss=0.33683350682258606
[10/24] Train loss=0.3601205050945282
[15/24] Train loss=0.355231374502182
[20/24] Train loss=0.32968923449516296
Test set avg_accuracy=83.96% avg_sensitivity=56.11%, avg_specificity=93.90% avg_auc=89.52%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.348530 Test loss=0.354431 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3152628242969513
[5/24] Train loss=0.3287160396575928
[10/24] Train loss=0.3570410907268524
[15/24] Train loss=0.35448795557022095
[20/24] Train loss=0.3286930322647095
Test set avg_accuracy=83.85% avg_sensitivity=55.76%, avg_specificity=93.89% avg_auc=89.63%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.348219 Test loss=0.352954 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3158304989337921
[5/24] Train loss=0.33390653133392334
[10/24] Train loss=0.35835349559783936
[15/24] Train loss=0.35407036542892456
[20/24] Train loss=0.3280426263809204
Test set avg_accuracy=83.70% avg_sensitivity=54.33%, avg_specificity=94.19% avg_auc=89.50%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.348292 Test loss=0.355065 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3180801570415497
[5/24] Train loss=0.3275495171546936
[10/24] Train loss=0.3577826917171478
[15/24] Train loss=0.3516991138458252
[20/24] Train loss=0.3282775282859802
Test set avg_accuracy=83.79% avg_sensitivity=55.71%, avg_specificity=93.82% avg_auc=89.56%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.347652 Test loss=0.353645 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.3153771758079529
[5/24] Train loss=0.3343510627746582
[10/24] Train loss=0.35817310214042664
[15/24] Train loss=0.35854488611221313
[20/24] Train loss=0.32352691888809204
Test set avg_accuracy=83.71% avg_sensitivity=54.97%, avg_specificity=93.97% avg_auc=89.55%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.348488 Test loss=0.353882 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3159627318382263
[5/24] Train loss=0.33445271849632263
[10/24] Train loss=0.3563651442527771
[15/24] Train loss=0.35369348526000977
[20/24] Train loss=0.32522299885749817
Test set avg_accuracy=83.68% avg_sensitivity=54.23%, avg_specificity=94.20% avg_auc=89.44%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.348938 Test loss=0.355890 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.31210532784461975
[5/24] Train loss=0.334775447845459
[10/24] Train loss=0.35714030265808105
[15/24] Train loss=0.34658512473106384
[20/24] Train loss=0.32264769077301025
Test set avg_accuracy=83.44% avg_sensitivity=52.55%, avg_specificity=94.47% avg_auc=89.39%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.349457 Test loss=0.357213 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.315766841173172
[5/24] Train loss=0.3408483564853668
[10/24] Train loss=0.358146995306015
[15/24] Train loss=0.3488467037677765
[20/24] Train loss=0.3257419764995575
Test set avg_accuracy=83.68% avg_sensitivity=53.04%, avg_specificity=94.63% avg_auc=89.48%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.350830 Test loss=0.356057 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.31681856513023376
[5/24] Train loss=0.3418939709663391
[10/24] Train loss=0.36022675037384033
[15/24] Train loss=0.3450283110141754
[20/24] Train loss=0.3287632167339325
Test set avg_accuracy=84.24% avg_sensitivity=60.07%, avg_specificity=92.88% avg_auc=89.58%
Best model saved!! Metric=0.7711400746489616!!
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.353273 Test loss=0.352644 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.31763261556625366
[5/24] Train loss=0.33875441551208496
[10/24] Train loss=0.36783215403556824
[15/24] Train loss=0.3430190980434418
[20/24] Train loss=0.3396907448768616
Test set avg_accuracy=84.49% avg_sensitivity=66.85%, avg_specificity=90.79% avg_auc=89.59%
Best model saved!! Metric=5.726611277409134!!
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.353467 Test loss=0.356373 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3221803307533264
[5/24] Train loss=0.326324999332428
[10/24] Train loss=0.3579406142234802
[15/24] Train loss=0.3445279598236084
[20/24] Train loss=0.3353193402290344
Test set avg_accuracy=84.08% avg_sensitivity=62.89%, avg_specificity=91.64% avg_auc=89.65%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.349645 Test loss=0.353175 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3211228847503662
[5/24] Train loss=0.3299573063850403
[10/24] Train loss=0.35726118087768555
[15/24] Train loss=0.3420010507106781
[20/24] Train loss=0.33405688405036926
Test set avg_accuracy=84.13% avg_sensitivity=63.24%, avg_specificity=91.59% avg_auc=89.64%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.348372 Test loss=0.353647 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3190154433250427
[5/24] Train loss=0.32977157831192017
[10/24] Train loss=0.36094003915786743
[15/24] Train loss=0.33971455693244934
[20/24] Train loss=0.334121972322464
Test set avg_accuracy=84.18% avg_sensitivity=62.74%, avg_specificity=91.84% avg_auc=89.64%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.349408 Test loss=0.352800 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3186139464378357
[5/24] Train loss=0.32625165581703186
[10/24] Train loss=0.35889893770217896
[15/24] Train loss=0.34412479400634766
[20/24] Train loss=0.33466625213623047
Test set avg_accuracy=84.10% avg_sensitivity=63.33%, avg_specificity=91.52% avg_auc=89.66%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.347074 Test loss=0.353687 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3201732039451599
[5/24] Train loss=0.33022186160087585
[10/24] Train loss=0.3593868315219879
[15/24] Train loss=0.34306788444519043
[20/24] Train loss=0.3336135447025299
Test set avg_accuracy=84.13% avg_sensitivity=62.94%, avg_specificity=91.69% avg_auc=89.64%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.347961 Test loss=0.352497 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3201518654823303
[5/24] Train loss=0.3323024809360504
[10/24] Train loss=0.3568984568119049
[15/24] Train loss=0.3434714674949646
[20/24] Train loss=0.33398592472076416
Test set avg_accuracy=84.32% avg_sensitivity=62.79%, avg_specificity=92.01% avg_auc=89.62%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.347600 Test loss=0.352739 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3200838565826416
[5/24] Train loss=0.3291252851486206
[10/24] Train loss=0.3587770462036133
[15/24] Train loss=0.34422749280929565
[20/24] Train loss=0.330502986907959
Test set avg_accuracy=84.13% avg_sensitivity=62.30%, avg_specificity=91.92% avg_auc=89.70%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.347253 Test loss=0.351551 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3188764452934265
[5/24] Train loss=0.32541704177856445
[10/24] Train loss=0.3609921932220459
[15/24] Train loss=0.3418266475200653
[20/24] Train loss=0.3304423689842224
Test set avg_accuracy=84.23% avg_sensitivity=63.09%, avg_specificity=91.78% avg_auc=89.71%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.347266 Test loss=0.351952 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3161848783493042
[5/24] Train loss=0.3297191262245178
[10/24] Train loss=0.3576778769493103
[15/24] Train loss=0.34512436389923096
[20/24] Train loss=0.3296845257282257
Test set avg_accuracy=84.14% avg_sensitivity=62.30%, avg_specificity=91.94% avg_auc=89.72%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.347155 Test loss=0.351058 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.31900057196617126
[5/24] Train loss=0.32771652936935425
[10/24] Train loss=0.35625019669532776
[15/24] Train loss=0.343814492225647
[20/24] Train loss=0.32918158173561096
Test set avg_accuracy=83.93% avg_sensitivity=61.06%, avg_specificity=92.10% avg_auc=89.67%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.347510 Test loss=0.351821 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3224317729473114
[5/24] Train loss=0.32267794013023376
[10/24] Train loss=0.3609761595726013
[15/24] Train loss=0.3453475534915924
[20/24] Train loss=0.3315766155719757
Test set avg_accuracy=84.27% avg_sensitivity=62.79%, avg_specificity=91.94% avg_auc=89.60%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.347087 Test loss=0.353660 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3248717784881592
[5/24] Train loss=0.330963671207428
[10/24] Train loss=0.35629478096961975
[15/24] Train loss=0.34638622403144836
[20/24] Train loss=0.3283803462982178
Test set avg_accuracy=84.11% avg_sensitivity=62.59%, avg_specificity=91.80% avg_auc=89.67%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.347911 Test loss=0.352700 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.32272854447364807
[5/24] Train loss=0.3335886597633362
[10/24] Train loss=0.35921230912208557
[15/24] Train loss=0.34754908084869385
[20/24] Train loss=0.3274604380130768
Test set avg_accuracy=84.28% avg_sensitivity=64.77%, avg_specificity=91.25% avg_auc=89.74%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.347753 Test loss=0.353687 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.32363149523735046
[5/24] Train loss=0.3369230329990387
[10/24] Train loss=0.36065948009490967
[15/24] Train loss=0.3504672646522522
[20/24] Train loss=0.3243204355239868
Test set avg_accuracy=84.36% avg_sensitivity=67.44%, avg_specificity=90.40% avg_auc=89.73%
Best model saved!! Metric=5.935893602290022!!
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.348139 Test loss=0.356477 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3266104459762573
[5/24] Train loss=0.33570411801338196
[10/24] Train loss=0.3642990291118622
[15/24] Train loss=0.3483678698539734
[20/24] Train loss=0.3336109220981598
Test set avg_accuracy=84.19% avg_sensitivity=69.72%, avg_specificity=89.36% avg_auc=89.63%
Best model saved!! Metric=6.904061181790837!!
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.349448 Test loss=0.364142 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3341827690601349
[5/24] Train loss=0.3392782211303711
[10/24] Train loss=0.3634834885597229
[15/24] Train loss=0.34324946999549866
[20/24] Train loss=0.3400190472602844
Test set avg_accuracy=83.82% avg_sensitivity=71.50%, avg_specificity=88.21% avg_auc=89.50%
Best model saved!! Metric=7.031373627135608!!
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.350977 Test loss=0.371059 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.34180933237075806
[5/24] Train loss=0.3440660238265991
[10/24] Train loss=0.35503771901130676
[15/24] Train loss=0.34216147661209106
[20/24] Train loss=0.3586100935935974
Test set avg_accuracy=84.35% avg_sensitivity=69.03%, avg_specificity=89.82% avg_auc=89.70%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.350293 Test loss=0.361545 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3291868269443512
[5/24] Train loss=0.3263869881629944
[10/24] Train loss=0.35690614581108093
[15/24] Train loss=0.3409149944782257
[20/24] Train loss=0.34624412655830383
Test set avg_accuracy=84.15% avg_sensitivity=65.76%, avg_specificity=90.72% avg_auc=89.78%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.347741 Test loss=0.355774 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.32134902477264404
[5/24] Train loss=0.3328862488269806
[10/24] Train loss=0.36408495903015137
[15/24] Train loss=0.3407626748085022
[20/24] Train loss=0.3448421061038971
Test set avg_accuracy=84.24% avg_sensitivity=65.96%, avg_specificity=90.78% avg_auc=89.80%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.346223 Test loss=0.355991 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3234526216983795
[5/24] Train loss=0.3282546103000641
[10/24] Train loss=0.3597201704978943
[15/24] Train loss=0.3395346403121948
[20/24] Train loss=0.34586164355278015
Test set avg_accuracy=84.09% avg_sensitivity=65.31%, avg_specificity=90.79% avg_auc=89.81%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.345983 Test loss=0.355944 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3255775272846222
[5/24] Train loss=0.3250191807746887
[10/24] Train loss=0.3573225736618042
[15/24] Train loss=0.3388310670852661
[20/24] Train loss=0.34524208307266235
Test set avg_accuracy=84.06% avg_sensitivity=64.67%, avg_specificity=90.99% avg_auc=89.79%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.345322 Test loss=0.354965 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3243243396282196
[5/24] Train loss=0.3294169306755066
[10/24] Train loss=0.3562321066856384
[15/24] Train loss=0.34009724855422974
[20/24] Train loss=0.3462693691253662
Test set avg_accuracy=84.13% avg_sensitivity=64.13%, avg_specificity=91.27% avg_auc=89.82%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.345196 Test loss=0.354164 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.32047879695892334
[5/24] Train loss=0.32666975259780884
[10/24] Train loss=0.3560430705547333
[15/24] Train loss=0.34011754393577576
[20/24] Train loss=0.3378407955169678
Test set avg_accuracy=84.11% avg_sensitivity=64.03%, avg_specificity=91.29% avg_auc=89.82%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.343639 Test loss=0.353752 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3207160532474518
[5/24] Train loss=0.3303706645965576
[10/24] Train loss=0.35481709241867065
[15/24] Train loss=0.33928000926971436
[20/24] Train loss=0.34069332480430603
Test set avg_accuracy=83.96% avg_sensitivity=63.58%, avg_specificity=91.24% avg_auc=89.83%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.343536 Test loss=0.353343 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.32111817598342896
[5/24] Train loss=0.3307324945926666
[10/24] Train loss=0.3570326268672943
[15/24] Train loss=0.3428710103034973
[20/24] Train loss=0.3440629541873932
Test set avg_accuracy=84.02% avg_sensitivity=63.53%, avg_specificity=91.34% avg_auc=89.85%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.344477 Test loss=0.352560 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3196242153644562
[5/24] Train loss=0.3283098042011261
[10/24] Train loss=0.3566610515117645
[15/24] Train loss=0.3373435437679291
[20/24] Train loss=0.34099024534225464
Test set avg_accuracy=84.15% avg_sensitivity=63.14%, avg_specificity=91.66% avg_auc=89.86%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.343314 Test loss=0.351411 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.31750452518463135
[5/24] Train loss=0.32561764121055603
[10/24] Train loss=0.3547007441520691
[15/24] Train loss=0.3413815498352051
[20/24] Train loss=0.33931148052215576
Test set avg_accuracy=84.15% avg_sensitivity=63.19%, avg_specificity=91.64% avg_auc=89.87%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.343076 Test loss=0.351121 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.31839728355407715
[5/24] Train loss=0.32500606775283813
[10/24] Train loss=0.3556574583053589
[15/24] Train loss=0.3390029966831207
[20/24] Train loss=0.337718665599823
Test set avg_accuracy=84.36% avg_sensitivity=62.49%, avg_specificity=92.17% avg_auc=89.87%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.343572 Test loss=0.350537 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3176802396774292
[5/24] Train loss=0.3267248868942261
[10/24] Train loss=0.35531553626060486
[15/24] Train loss=0.33947694301605225
[20/24] Train loss=0.3414221704006195
Test set avg_accuracy=84.21% avg_sensitivity=61.55%, avg_specificity=92.30% avg_auc=89.85%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.343090 Test loss=0.349890 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3136879503726959
[5/24] Train loss=0.32466673851013184
[10/24] Train loss=0.3584079146385193
[15/24] Train loss=0.34272074699401855
[20/24] Train loss=0.3384346067905426
Test set avg_accuracy=84.32% avg_sensitivity=61.65%, avg_specificity=92.42% avg_auc=89.88%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.342815 Test loss=0.349719 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3162587285041809
[5/24] Train loss=0.32873257994651794
[10/24] Train loss=0.3525266945362091
[15/24] Train loss=0.3435819149017334
[20/24] Train loss=0.34065723419189453
Test set avg_accuracy=84.28% avg_sensitivity=61.11%, avg_specificity=92.56% avg_auc=89.87%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.342408 Test loss=0.349525 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3155871331691742
[5/24] Train loss=0.3260081708431244
[10/24] Train loss=0.3545048236846924
[15/24] Train loss=0.34237444400787354
[20/24] Train loss=0.33804333209991455
Test set avg_accuracy=84.26% avg_sensitivity=60.27%, avg_specificity=92.83% avg_auc=89.88%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.342438 Test loss=0.349287 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3138331472873688
[5/24] Train loss=0.3309648931026459
[10/24] Train loss=0.3545849323272705
[15/24] Train loss=0.3391554057598114
[20/24] Train loss=0.337588906288147
Test set avg_accuracy=84.22% avg_sensitivity=60.07%, avg_specificity=92.84% avg_auc=89.88%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.342440 Test loss=0.348943 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3149012327194214
[5/24] Train loss=0.3283992409706116
[10/24] Train loss=0.3565075099468231
[15/24] Train loss=0.3442772328853607
[20/24] Train loss=0.3316853940486908
Test set avg_accuracy=84.23% avg_sensitivity=59.57%, avg_specificity=93.04% avg_auc=89.88%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.342520 Test loss=0.349006 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3129790127277374
[5/24] Train loss=0.32621076703071594
[10/24] Train loss=0.3558137118816376
[15/24] Train loss=0.33863091468811035
[20/24] Train loss=0.3304212689399719
Test set avg_accuracy=84.15% avg_sensitivity=59.38%, avg_specificity=93.00% avg_auc=89.88%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.341354 Test loss=0.348794 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.30975306034088135
[5/24] Train loss=0.32729005813598633
[10/24] Train loss=0.35383328795433044
[15/24] Train loss=0.3385443687438965
[20/24] Train loss=0.3279832899570465
Test set avg_accuracy=84.24% avg_sensitivity=60.07%, avg_specificity=92.88% avg_auc=89.88%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.342010 Test loss=0.348789 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.31350672245025635
[5/24] Train loss=0.33105507493019104
[10/24] Train loss=0.3546872138977051
[15/24] Train loss=0.3398784101009369
[20/24] Train loss=0.32664376497268677
Test set avg_accuracy=84.28% avg_sensitivity=61.16%, avg_specificity=92.54% avg_auc=89.89%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.342578 Test loss=0.349155 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.31431111693382263
[5/24] Train loss=0.32848700881004333
[10/24] Train loss=0.35220491886138916
[15/24] Train loss=0.3362651467323303
[20/24] Train loss=0.32502785325050354
Test set avg_accuracy=84.54% avg_sensitivity=63.73%, avg_specificity=91.98% avg_auc=89.88%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.342764 Test loss=0.350168 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.31727704405784607
[5/24] Train loss=0.33088788390159607
[10/24] Train loss=0.36133384704589844
[15/24] Train loss=0.3415353298187256
[20/24] Train loss=0.3222033381462097
Test set avg_accuracy=84.38% avg_sensitivity=65.02%, avg_specificity=91.29% avg_auc=89.86%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.342620 Test loss=0.352311 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.32156336307525635
[5/24] Train loss=0.3274648189544678
[10/24] Train loss=0.35942956805229187
[15/24] Train loss=0.3393416404724121
[20/24] Train loss=0.32415762543678284
Test set avg_accuracy=84.30% avg_sensitivity=65.66%, avg_specificity=90.95% avg_auc=89.85%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.342282 Test loss=0.353299 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.32094651460647583
[5/24] Train loss=0.3271242380142212
[10/24] Train loss=0.3547940254211426
[15/24] Train loss=0.3419843018054962
[20/24] Train loss=0.3252321779727936
Test set avg_accuracy=84.49% avg_sensitivity=65.02%, avg_specificity=91.45% avg_auc=89.88%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.341928 Test loss=0.351859 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.31894513964653015
[5/24] Train loss=0.32478293776512146
[10/24] Train loss=0.3565092980861664
[15/24] Train loss=0.34020474553108215
[20/24] Train loss=0.3250378370285034
Test set avg_accuracy=84.45% avg_sensitivity=64.18%, avg_specificity=91.69% avg_auc=89.90%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.340203 Test loss=0.350747 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.32049620151519775
[5/24] Train loss=0.32970112562179565
[10/24] Train loss=0.3592607378959656
[15/24] Train loss=0.33981266617774963
[20/24] Train loss=0.32573747634887695
Test set avg_accuracy=84.47% avg_sensitivity=64.23%, avg_specificity=91.69% avg_auc=89.92%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.341736 Test loss=0.350813 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.320151686668396
[5/24] Train loss=0.32487931847572327
[10/24] Train loss=0.353430837392807
[15/24] Train loss=0.33848658204078674
[20/24] Train loss=0.32650452852249146
Test set avg_accuracy=84.51% avg_sensitivity=64.13%, avg_specificity=91.78% avg_auc=89.92%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.340911 Test loss=0.350464 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.3156656324863434
[5/24] Train loss=0.3259968161582947
[10/24] Train loss=0.3518012464046478
[15/24] Train loss=0.3376065194606781
[20/24] Train loss=0.32700279355049133
Test set avg_accuracy=84.44% avg_sensitivity=63.24%, avg_specificity=92.01% avg_auc=89.92%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.340225 Test loss=0.349927 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.31404808163642883
[5/24] Train loss=0.323576956987381
[10/24] Train loss=0.3574453294277191
[15/24] Train loss=0.3408353328704834
[20/24] Train loss=0.32906872034072876
Test set avg_accuracy=84.54% avg_sensitivity=64.08%, avg_specificity=91.85% avg_auc=89.92%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.340753 Test loss=0.350278 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.31345808506011963
[5/24] Train loss=0.32854437828063965
[10/24] Train loss=0.3526039719581604
[15/24] Train loss=0.3348425626754761
[20/24] Train loss=0.32797709107398987
Test set avg_accuracy=84.39% avg_sensitivity=62.94%, avg_specificity=92.05% avg_auc=89.92%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.339547 Test loss=0.349759 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3116365671157837
[5/24] Train loss=0.32451698184013367
[10/24] Train loss=0.3585112988948822
[15/24] Train loss=0.33873581886291504
[20/24] Train loss=0.3269507586956024
Test set avg_accuracy=84.35% avg_sensitivity=62.84%, avg_specificity=92.03% avg_auc=89.92%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.339192 Test loss=0.349728 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.31800374388694763
[5/24] Train loss=0.32670146226882935
[10/24] Train loss=0.3551144003868103
[15/24] Train loss=0.3391507565975189
[20/24] Train loss=0.3306336998939514
Test set avg_accuracy=84.36% avg_sensitivity=62.94%, avg_specificity=92.01% avg_auc=89.91%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.340612 Test loss=0.349865 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.31469443440437317
[5/24] Train loss=0.32520484924316406
[10/24] Train loss=0.3558877110481262
[15/24] Train loss=0.3368738889694214
[20/24] Train loss=0.32510676980018616
Test set avg_accuracy=84.38% avg_sensitivity=62.84%, avg_specificity=92.07% avg_auc=89.92%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.341032 Test loss=0.349738 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3141307532787323
[5/24] Train loss=0.32730185985565186
[10/24] Train loss=0.3576759696006775
[15/24] Train loss=0.3390842080116272
[20/24] Train loss=0.32672742009162903
Test set avg_accuracy=84.39% avg_sensitivity=62.84%, avg_specificity=92.08% avg_auc=89.92%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.339937 Test loss=0.349646 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3154841363430023
[5/24] Train loss=0.3220290541648865
[10/24] Train loss=0.3579220771789551
[15/24] Train loss=0.34245872497558594
[20/24] Train loss=0.32510629296302795
Test set avg_accuracy=84.38% avg_sensitivity=62.79%, avg_specificity=92.08% avg_auc=89.92%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.340957 Test loss=0.349589 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.3165455758571625
[5/24] Train loss=0.32859110832214355
[10/24] Train loss=0.35465750098228455
[15/24] Train loss=0.3398541510105133
[20/24] Train loss=0.32533714175224304
Test set avg_accuracy=84.47% avg_sensitivity=62.79%, avg_specificity=92.21% avg_auc=89.92%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.340350 Test loss=0.349528 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.31516677141189575
[5/24] Train loss=0.3255441188812256
[10/24] Train loss=0.35344743728637695
[15/24] Train loss=0.3397218585014343
[20/24] Train loss=0.33160004019737244
Test set avg_accuracy=84.45% avg_sensitivity=62.79%, avg_specificity=92.19% avg_auc=89.92%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.340383 Test loss=0.349539 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3152330219745636
[5/24] Train loss=0.32587963342666626
[10/24] Train loss=0.35446155071258545
[15/24] Train loss=0.3408161699771881
[20/24] Train loss=0.32552459836006165
Test set avg_accuracy=84.45% avg_sensitivity=62.79%, avg_specificity=92.19% avg_auc=89.92%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.340177 Test loss=0.349546 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.31341978907585144
[5/24] Train loss=0.32527321577072144
[10/24] Train loss=0.35891470313072205
[15/24] Train loss=0.33735227584838867
[20/24] Train loss=0.3250710964202881
Test set avg_accuracy=84.47% avg_sensitivity=62.79%, avg_specificity=92.21% avg_auc=89.92%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.339565 Test loss=0.349544 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=83.82% sen=71.50%, spe=88.21%, auc=89.50%!
Fold[1] Avg_overlap=0.62%(0.27223829947484435)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'HybridCNNRNN',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.8058410882949829
[5/24] Train loss=0.7556361556053162
[10/24] Train loss=0.6585817337036133
[15/24] Train loss=0.6281548142433167
[20/24] Train loss=0.611405611038208
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.03%
Best model saved!! Metric=-101.935830760308!!
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.680263 Test loss=0.578831 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6004461646080017
[5/24] Train loss=0.6329644918441772
[10/24] Train loss=0.6165528893470764
[15/24] Train loss=0.5962501764297485
[20/24] Train loss=0.5844504833221436
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.05%
Best model saved!! Metric=-99.90993317519707!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.606167 Test loss=0.565152 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.5858858823776245
[5/24] Train loss=0.6147951483726501
[10/24] Train loss=0.6053219437599182
[15/24] Train loss=0.5888217091560364
[20/24] Train loss=0.582223653793335
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=53.67%
Best model saved!! Metric=-97.28911381879153!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.596316 Test loss=0.562120 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.5761218070983887
[5/24] Train loss=0.6080910563468933
[10/24] Train loss=0.5937709212303162
[15/24] Train loss=0.582950234413147
[20/24] Train loss=0.5809807181358337
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=57.29%
Best model saved!! Metric=-93.66863127545729!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.591029 Test loss=0.555922 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.576975405216217
[5/24] Train loss=0.608212411403656
[10/24] Train loss=0.5843547582626343
[15/24] Train loss=0.5765355825424194
[20/24] Train loss=0.5700249671936035
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=61.90%
Best model saved!! Metric=-89.06517684601239!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.582819 Test loss=0.547990 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5566830039024353
[5/24] Train loss=0.594452977180481
[10/24] Train loss=0.5802977085113525
[15/24] Train loss=0.5665538907051086
[20/24] Train loss=0.5614306330680847
Test set avg_accuracy=75.01% avg_sensitivity=0.00%, avg_specificity=99.97% avg_auc=67.00%
Best model saved!! Metric=-84.01713095159943!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.573671 Test loss=0.539087 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5519242286682129
[5/24] Train loss=0.5801720023155212
[10/24] Train loss=0.5591617226600647
[15/24] Train loss=0.5632346272468567
[20/24] Train loss=0.5463933348655701
Test set avg_accuracy=75.04% avg_sensitivity=0.10%, avg_specificity=99.97% avg_auc=70.96%
Best model saved!! Metric=-79.92920601559935!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.563659 Test loss=0.530065 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5469036102294922
[5/24] Train loss=0.5668957233428955
[10/24] Train loss=0.5467513203620911
[15/24] Train loss=0.5433098673820496
[20/24] Train loss=0.5306772589683533
Test set avg_accuracy=74.93% avg_sensitivity=0.16%, avg_specificity=99.81% avg_auc=73.81%
Best model saved!! Metric=-77.29250992485768!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.550854 Test loss=0.519829 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5335618853569031
[5/24] Train loss=0.5553253889083862
[10/24] Train loss=0.5369812250137329
[15/24] Train loss=0.5368008017539978
[20/24] Train loss=0.5190988183021545
Test set avg_accuracy=74.93% avg_sensitivity=0.16%, avg_specificity=99.81% avg_auc=75.91%
Best model saved!! Metric=-75.18960063293542!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.540625 Test loss=0.508932 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5181162357330322
[5/24] Train loss=0.5477992296218872
[10/24] Train loss=0.5240288972854614
[15/24] Train loss=0.5142300128936768
[20/24] Train loss=0.504318118095398
Test set avg_accuracy=74.58% avg_sensitivity=0.78%, avg_specificity=99.13% avg_auc=77.92%
Best model saved!! Metric=-73.57702969702845!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.525657 Test loss=0.496550 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5056684017181396
[5/24] Train loss=0.5207175612449646
[10/24] Train loss=0.5054914951324463
[15/24] Train loss=0.5014668703079224
[20/24] Train loss=0.48932114243507385
Test set avg_accuracy=74.69% avg_sensitivity=3.50%, avg_specificity=98.37% avg_auc=79.91%
Best model saved!! Metric=-69.53403284615372!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.512995 Test loss=0.482184 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4805710017681122
[5/24] Train loss=0.5028373003005981
[10/24] Train loss=0.49230730533599854
[15/24] Train loss=0.4851418435573578
[20/24] Train loss=0.4772695302963257
Test set avg_accuracy=74.05% avg_sensitivity=9.13%, avg_specificity=95.64% avg_auc=81.00%
Best model saved!! Metric=-66.17605307447268!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.497183 Test loss=0.469157 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4720601439476013
[5/24] Train loss=0.48674628138542175
[10/24] Train loss=0.4751719534397125
[15/24] Train loss=0.46528562903404236
[20/24] Train loss=0.4597840905189514
Test set avg_accuracy=75.44% avg_sensitivity=18.31%, avg_specificity=94.45% avg_auc=81.76%
Best model saved!! Metric=-56.03975941937219!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.482451 Test loss=0.456868 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4494664669036865
[5/24] Train loss=0.46324780583381653
[10/24] Train loss=0.4618303179740906
[15/24] Train loss=0.45258185267448425
[20/24] Train loss=0.44077321887016296
Test set avg_accuracy=76.22% avg_sensitivity=28.90%, avg_specificity=91.97% avg_auc=82.37%
Best model saved!! Metric=-46.538010773096424!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.466828 Test loss=0.447412 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4457956552505493
[5/24] Train loss=0.4581725001335144
[10/24] Train loss=0.443863183259964
[15/24] Train loss=0.43049588799476624
[20/24] Train loss=0.42822104692459106
Test set avg_accuracy=77.70% avg_sensitivity=41.42%, avg_specificity=89.76% avg_auc=82.91%
Best model saved!! Metric=-34.21383522896479!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.455741 Test loss=0.441570 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.42724141478538513
[5/24] Train loss=0.44447195529937744
[10/24] Train loss=0.44099321961402893
[15/24] Train loss=0.42277026176452637
[20/24] Train loss=0.424886018037796
Test set avg_accuracy=78.10% avg_sensitivity=41.99%, avg_specificity=90.11% avg_auc=83.25%
Best model saved!! Metric=-32.54855244065694!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.447192 Test loss=0.434391 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4209755063056946
[5/24] Train loss=0.4433766305446625
[10/24] Train loss=0.44409099221229553
[15/24] Train loss=0.4139290153980255
[20/24] Train loss=0.41353335976600647
Test set avg_accuracy=78.52% avg_sensitivity=47.37%, avg_specificity=88.88% avg_auc=83.17%
Best model saved!! Metric=-28.071133964853324!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.442307 Test loss=0.433049 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.41629520058631897
[5/24] Train loss=0.4396009147167206
[10/24] Train loss=0.4254026710987091
[15/24] Train loss=0.40200865268707275
[20/24] Train loss=0.4075600206851959
Test set avg_accuracy=78.71% avg_sensitivity=47.78%, avg_specificity=89.00% avg_auc=83.01%
Best model saved!! Metric=-27.49429308660963!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.434594 Test loss=0.431355 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4095330834388733
[5/24] Train loss=0.4187532067298889
[10/24] Train loss=0.41970735788345337
[15/24] Train loss=0.39544209837913513
[20/24] Train loss=0.39248427748680115
Test set avg_accuracy=78.50% avg_sensitivity=42.93%, avg_specificity=90.33% avg_auc=83.02%
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.426750 Test loss=0.426714 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4032125771045685
[5/24] Train loss=0.41697463393211365
[10/24] Train loss=0.410997211933136
[15/24] Train loss=0.3922746181488037
[20/24] Train loss=0.39022722840309143
Test set avg_accuracy=78.75% avg_sensitivity=41.21%, avg_specificity=91.24% avg_auc=83.68%
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.417998 Test loss=0.417932 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3866617977619171
[5/24] Train loss=0.39743664860725403
[10/24] Train loss=0.40467771887779236
[15/24] Train loss=0.38271594047546387
[20/24] Train loss=0.37919363379478455
Test set avg_accuracy=79.65% avg_sensitivity=41.73%, avg_specificity=92.26% avg_auc=84.47%
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.408260 Test loss=0.409403 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3763054609298706
[5/24] Train loss=0.3850269019603729
[10/24] Train loss=0.39447835087776184
[15/24] Train loss=0.3750115931034088
[20/24] Train loss=0.37544316053390503
Test set avg_accuracy=79.80% avg_sensitivity=38.03%, avg_specificity=93.70% avg_auc=84.68%
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.400191 Test loss=0.407833 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.36170515418052673
[5/24] Train loss=0.36829373240470886
[10/24] Train loss=0.38209712505340576
[15/24] Train loss=0.3636971414089203
[20/24] Train loss=0.3687748610973358
Test set avg_accuracy=80.62% avg_sensitivity=37.72%, avg_specificity=94.90% avg_auc=84.90%
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.391944 Test loss=0.405237 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3641502261161804
[5/24] Train loss=0.36643481254577637
[10/24] Train loss=0.38077861070632935
[15/24] Train loss=0.3541271388530731
[20/24] Train loss=0.3596733808517456
Test set avg_accuracy=80.62% avg_sensitivity=36.10%, avg_specificity=95.44% avg_auc=84.90%
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.387320 Test loss=0.406877 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3637646436691284
[5/24] Train loss=0.35361945629119873
[10/24] Train loss=0.3755469024181366
[15/24] Train loss=0.35016927123069763
[20/24] Train loss=0.35525456070899963
Test set avg_accuracy=80.27% avg_sensitivity=33.39%, avg_specificity=95.87% avg_auc=85.33%
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.379585 Test loss=0.407255 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.35606440901756287
[5/24] Train loss=0.35783281922340393
[10/24] Train loss=0.3662329614162445
[15/24] Train loss=0.3472250998020172
[20/24] Train loss=0.35205549001693726
Test set avg_accuracy=80.94% avg_sensitivity=36.36%, avg_specificity=95.77% avg_auc=85.68%
Best model saved!! Metric=-27.25904622227617!!
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.375402 Test loss=0.404111 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3528743386268616
[5/24] Train loss=0.3505096733570099
[10/24] Train loss=0.3631388247013092
[15/24] Train loss=0.3432161808013916
[20/24] Train loss=0.33322057127952576
Test set avg_accuracy=81.64% avg_sensitivity=41.11%, avg_specificity=95.12% avg_auc=86.12%
Best model saved!! Metric=-22.011764358806943!!
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.369856 Test loss=0.393593 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3450973331928253
[5/24] Train loss=0.3439938426017761
[10/24] Train loss=0.357391357421875
[15/24] Train loss=0.3360239863395691
[20/24] Train loss=0.32918062806129456
Test set avg_accuracy=81.99% avg_sensitivity=44.97%, avg_specificity=94.31% avg_auc=86.39%
Best model saved!! Metric=-18.3464581747309!!
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.363969 Test loss=0.387772 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3398778438568115
[5/24] Train loss=0.3464812636375427
[10/24] Train loss=0.3553899824619293
[15/24] Train loss=0.3296404778957367
[20/24] Train loss=0.32985228300094604
Test set avg_accuracy=81.98% avg_sensitivity=41.78%, avg_specificity=95.35% avg_auc=86.55%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.362159 Test loss=0.388700 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.33492833375930786
[5/24] Train loss=0.346094012260437
[10/24] Train loss=0.3535540997982025
[15/24] Train loss=0.325493723154068
[20/24] Train loss=0.325836181640625
Test set avg_accuracy=81.86% avg_sensitivity=40.22%, avg_specificity=95.71% avg_auc=86.62%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.359687 Test loss=0.389950 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.33510828018188477
[5/24] Train loss=0.35093989968299866
[10/24] Train loss=0.350852906703949
[15/24] Train loss=0.3275657892227173
[20/24] Train loss=0.31952574849128723
Test set avg_accuracy=81.97% avg_sensitivity=41.42%, avg_specificity=95.45% avg_auc=86.67%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.357366 Test loss=0.392206 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3348170816898346
[5/24] Train loss=0.35375672578811646
[10/24] Train loss=0.353818416595459
[15/24] Train loss=0.32806509733200073
[20/24] Train loss=0.3204507529735565
Test set avg_accuracy=81.89% avg_sensitivity=40.95%, avg_specificity=95.51% avg_auc=86.75%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.355400 Test loss=0.390936 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3321155309677124
[5/24] Train loss=0.3552628457546234
[10/24] Train loss=0.34800592064857483
[15/24] Train loss=0.32060182094573975
[20/24] Train loss=0.3128488063812256
Test set avg_accuracy=82.06% avg_sensitivity=40.69%, avg_specificity=95.82% avg_auc=86.72%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.354489 Test loss=0.391905 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.33176857233047485
[5/24] Train loss=0.36012330651283264
[10/24] Train loss=0.3431338667869568
[15/24] Train loss=0.3227766156196594
[20/24] Train loss=0.3209374248981476
Test set avg_accuracy=82.15% avg_sensitivity=41.84%, avg_specificity=95.56% avg_auc=86.88%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.353272 Test loss=0.390036 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3316291272640228
[5/24] Train loss=0.3534834384918213
[10/24] Train loss=0.34350529313087463
[15/24] Train loss=0.3187103569507599
[20/24] Train loss=0.31604233384132385
Test set avg_accuracy=81.98% avg_sensitivity=40.43%, avg_specificity=95.80% avg_auc=86.99%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.351070 Test loss=0.389447 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3314818739891052
[5/24] Train loss=0.3629530668258667
[10/24] Train loss=0.3421335816383362
[15/24] Train loss=0.3198028802871704
[20/24] Train loss=0.30867698788642883
Test set avg_accuracy=82.24% avg_sensitivity=41.78%, avg_specificity=95.70% avg_auc=87.12%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.350433 Test loss=0.387002 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3213820159435272
[5/24] Train loss=0.35344424843788147
[10/24] Train loss=0.33721861243247986
[15/24] Train loss=0.3165510892868042
[20/24] Train loss=0.31163716316223145
Test set avg_accuracy=82.07% avg_sensitivity=40.11%, avg_specificity=96.03% avg_auc=87.09%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.347685 Test loss=0.389429 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3250650465488434
[5/24] Train loss=0.3566693663597107
[10/24] Train loss=0.3404378890991211
[15/24] Train loss=0.3146054148674011
[20/24] Train loss=0.30692869424819946
Test set avg_accuracy=82.30% avg_sensitivity=41.26%, avg_specificity=95.96% avg_auc=87.19%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.347476 Test loss=0.388418 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3263903856277466
[5/24] Train loss=0.3517475128173828
[10/24] Train loss=0.3356874883174896
[15/24] Train loss=0.3170916736125946
[20/24] Train loss=0.30556628108024597
Test set avg_accuracy=82.54% avg_sensitivity=43.04%, avg_specificity=95.68% avg_auc=87.27%
Best model saved!! Metric=-17.475510345263054!!
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.346425 Test loss=0.385564 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3211531341075897
[5/24] Train loss=0.3535819351673126
[10/24] Train loss=0.34084877371788025
[15/24] Train loss=0.3154258131980896
[20/24] Train loss=0.3016304075717926
Test set avg_accuracy=82.36% avg_sensitivity=41.99%, avg_specificity=95.78% avg_auc=87.32%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.345950 Test loss=0.385545 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.32054030895233154
[5/24] Train loss=0.35918551683425903
[10/24] Train loss=0.3338199555873871
[15/24] Train loss=0.3129965662956238
[20/24] Train loss=0.30753669142723083
Test set avg_accuracy=82.42% avg_sensitivity=43.71%, avg_specificity=95.30% avg_auc=87.42%
Best model saved!! Metric=-17.146707916707058!!
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.344977 Test loss=0.380092 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.31846868991851807
[5/24] Train loss=0.3542340099811554
[10/24] Train loss=0.3346169888973236
[15/24] Train loss=0.3118245601654053
[20/24] Train loss=0.30613359808921814
Test set avg_accuracy=82.59% avg_sensitivity=43.45%, avg_specificity=95.61% avg_auc=87.45%
Best model saved!! Metric=-16.89638832658145!!
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.343691 Test loss=0.382093 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3176332116127014
[5/24] Train loss=0.351389080286026
[10/24] Train loss=0.3322078287601471
[15/24] Train loss=0.31303197145462036
[20/24] Train loss=0.3065459728240967
Test set avg_accuracy=82.66% avg_sensitivity=42.83%, avg_specificity=95.90% avg_auc=87.50%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.343545 Test loss=0.383015 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.31891563534736633
[5/24] Train loss=0.3533228039741516
[10/24] Train loss=0.3307649791240692
[15/24] Train loss=0.3113552927970886
[20/24] Train loss=0.30239760875701904
Test set avg_accuracy=82.53% avg_sensitivity=44.08%, avg_specificity=95.31% avg_auc=87.59%
Best model saved!! Metric=-16.490479190987408!!
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.342328 Test loss=0.377926 Current lr=[0.00029967723776099]

[0/24] Train loss=0.31732067465782166
[5/24] Train loss=0.3444981575012207
[10/24] Train loss=0.3332279324531555
[15/24] Train loss=0.31155434250831604
[20/24] Train loss=0.30060216784477234
Test set avg_accuracy=82.58% avg_sensitivity=42.62%, avg_specificity=95.87% avg_auc=87.58%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.340614 Test loss=0.381328 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3189004361629486
[5/24] Train loss=0.3485669493675232
[10/24] Train loss=0.3322184979915619
[15/24] Train loss=0.30727285146713257
[20/24] Train loss=0.30159029364585876
Test set avg_accuracy=82.88% avg_sensitivity=45.28%, avg_specificity=95.38% avg_auc=87.71%
Best model saved!! Metric=-14.744745014441307!!
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.340336 Test loss=0.375742 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3150789141654968
[5/24] Train loss=0.3480704724788666
[10/24] Train loss=0.33540138602256775
[15/24] Train loss=0.31006959080696106
[20/24] Train loss=0.2989758849143982
Test set avg_accuracy=82.77% avg_sensitivity=46.11%, avg_specificity=94.97% avg_auc=87.70%
Best model saved!! Metric=-14.44284419412358!!
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.340191 Test loss=0.374699 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3129063546657562
[5/24] Train loss=0.3430752754211426
[10/24] Train loss=0.3274734616279602
[15/24] Train loss=0.3056676387786865
[20/24] Train loss=0.30096715688705444
Test set avg_accuracy=82.88% avg_sensitivity=44.55%, avg_specificity=95.63% avg_auc=87.77%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.338174 Test loss=0.376038 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3159394860267639
[5/24] Train loss=0.35116928815841675
[10/24] Train loss=0.33419814705848694
[15/24] Train loss=0.308208167552948
[20/24] Train loss=0.2987132668495178
Test set avg_accuracy=82.77% avg_sensitivity=45.44%, avg_specificity=95.19% avg_auc=87.71%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.338978 Test loss=0.376562 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3118785321712494
[5/24] Train loss=0.3407699167728424
[10/24] Train loss=0.329470157623291
[15/24] Train loss=0.3079608976840973
[20/24] Train loss=0.2993074655532837
Test set avg_accuracy=82.85% avg_sensitivity=43.92%, avg_specificity=95.80% avg_auc=87.80%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.337864 Test loss=0.376804 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3156396448612213
[5/24] Train loss=0.35206320881843567
[10/24] Train loss=0.33090585470199585
[15/24] Train loss=0.30444541573524475
[20/24] Train loss=0.29745155572891235
Test set avg_accuracy=82.59% avg_sensitivity=44.34%, avg_specificity=95.31% avg_auc=87.74%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.338728 Test loss=0.376790 Current lr=[0.000297555943323901]

[0/24] Train loss=0.31280428171157837
[5/24] Train loss=0.3430624306201935
[10/24] Train loss=0.32879066467285156
[15/24] Train loss=0.3040972054004669
[20/24] Train loss=0.2959577441215515
Test set avg_accuracy=82.81% avg_sensitivity=45.28%, avg_specificity=95.30% avg_auc=87.82%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.336489 Test loss=0.374804 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3111855983734131
[5/24] Train loss=0.3475554287433624
[10/24] Train loss=0.3308089077472687
[15/24] Train loss=0.31208497285842896
[20/24] Train loss=0.2988986670970917
Test set avg_accuracy=83.05% avg_sensitivity=47.52%, avg_specificity=94.86% avg_auc=87.84%
Best model saved!! Metric=-12.73155612815362!!
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.337443 Test loss=0.372352 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3082166910171509
[5/24] Train loss=0.3391377627849579
[10/24] Train loss=0.32792413234710693
[15/24] Train loss=0.3062450587749481
[20/24] Train loss=0.29435011744499207
Test set avg_accuracy=82.92% avg_sensitivity=46.64%, avg_specificity=94.99% avg_auc=87.84%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.335100 Test loss=0.372853 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.31158143281936646
[5/24] Train loss=0.34788888692855835
[10/24] Train loss=0.3327728509902954
[15/24] Train loss=0.30556634068489075
[20/24] Train loss=0.29591402411460876
Test set avg_accuracy=82.77% avg_sensitivity=45.75%, avg_specificity=95.09% avg_auc=87.88%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.335631 Test loss=0.372511 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.30668583512306213
[5/24] Train loss=0.347708135843277
[10/24] Train loss=0.3293019235134125
[15/24] Train loss=0.3044256865978241
[20/24] Train loss=0.2946597635746002
Test set avg_accuracy=83.23% avg_sensitivity=47.89%, avg_specificity=94.99% avg_auc=87.79%
Best model saved!! Metric=-12.108986144002657!!
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.335907 Test loss=0.374583 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.31080809235572815
[5/24] Train loss=0.3433287739753723
[10/24] Train loss=0.3307015895843506
[15/24] Train loss=0.2992929518222809
[20/24] Train loss=0.2934350371360779
Test set avg_accuracy=83.31% avg_sensitivity=48.83%, avg_specificity=94.78% avg_auc=87.87%
Best model saved!! Metric=-11.215259375992005!!
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.334563 Test loss=0.370845 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3107036352157593
[5/24] Train loss=0.3379265367984772
[10/24] Train loss=0.32888180017471313
[15/24] Train loss=0.3052905797958374
[20/24] Train loss=0.2934094965457916
Test set avg_accuracy=83.07% avg_sensitivity=46.84%, avg_specificity=95.12% avg_auc=87.88%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.334618 Test loss=0.372075 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3079085946083069
[5/24] Train loss=0.34119120240211487
[10/24] Train loss=0.3288932144641876
[15/24] Train loss=0.3078116178512573
[20/24] Train loss=0.2932741940021515
Test set avg_accuracy=83.05% avg_sensitivity=46.32%, avg_specificity=95.26% avg_auc=87.95%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.333742 Test loss=0.372027 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.30760252475738525
[5/24] Train loss=0.3417263925075531
[10/24] Train loss=0.33129942417144775
[15/24] Train loss=0.30295687913894653
[20/24] Train loss=0.29702121019363403
Test set avg_accuracy=83.07% avg_sensitivity=46.32%, avg_specificity=95.30% avg_auc=87.98%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.334176 Test loss=0.372390 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.30567750334739685
[5/24] Train loss=0.33724072575569153
[10/24] Train loss=0.32568883895874023
[15/24] Train loss=0.3032887578010559
[20/24] Train loss=0.2925037443637848
Test set avg_accuracy=83.42% avg_sensitivity=48.67%, avg_specificity=94.99% avg_auc=87.94%
Best model saved!! Metric=-10.981065314156488!!
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.332999 Test loss=0.370664 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3075049817562103
[5/24] Train loss=0.33823803067207336
[10/24] Train loss=0.32320934534072876
[15/24] Train loss=0.302377313375473
[20/24] Train loss=0.29069456458091736
Test set avg_accuracy=83.41% avg_sensitivity=48.46%, avg_specificity=95.04% avg_auc=88.00%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.331742 Test loss=0.369897 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.30561894178390503
[5/24] Train loss=0.33898547291755676
[10/24] Train loss=0.3291613459587097
[15/24] Train loss=0.3026447892189026
[20/24] Train loss=0.29265108704566956
Test set avg_accuracy=83.14% avg_sensitivity=46.69%, avg_specificity=95.26% avg_auc=88.01%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.331974 Test loss=0.370714 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3065924048423767
[5/24] Train loss=0.3421919643878937
[10/24] Train loss=0.3227325677871704
[15/24] Train loss=0.2992117702960968
[20/24] Train loss=0.29136520624160767
Test set avg_accuracy=83.36% avg_sensitivity=47.63%, avg_specificity=95.25% avg_auc=87.99%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.331421 Test loss=0.371343 Current lr=[0.000276307469034998]

[0/24] Train loss=0.30596888065338135
[5/24] Train loss=0.3414483964443207
[10/24] Train loss=0.3288594186306
[15/24] Train loss=0.30294889211654663
[20/24] Train loss=0.2928923964500427
Test set avg_accuracy=83.29% avg_sensitivity=48.20%, avg_specificity=94.97% avg_auc=87.97%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.331789 Test loss=0.371287 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.30786585807800293
[5/24] Train loss=0.3342304229736328
[10/24] Train loss=0.32563117146492004
[15/24] Train loss=0.30443280935287476
[20/24] Train loss=0.2926848828792572
Test set avg_accuracy=83.33% avg_sensitivity=48.36%, avg_specificity=94.97% avg_auc=87.92%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.331135 Test loss=0.371811 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.30487456917762756
[5/24] Train loss=0.33511990308761597
[10/24] Train loss=0.3290599584579468
[15/24] Train loss=0.29738375544548035
[20/24] Train loss=0.28918036818504333
Test set avg_accuracy=83.32% avg_sensitivity=48.10%, avg_specificity=95.04% avg_auc=88.01%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.331174 Test loss=0.370510 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3054157793521881
[5/24] Train loss=0.3431554436683655
[10/24] Train loss=0.3287944197654724
[15/24] Train loss=0.30345097184181213
[20/24] Train loss=0.29061758518218994
Test set avg_accuracy=83.41% avg_sensitivity=49.30%, avg_specificity=94.76% avg_auc=88.04%
Best model saved!! Metric=-10.492247343636947!!
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.331539 Test loss=0.368501 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3005804121494293
[5/24] Train loss=0.3402186334133148
[10/24] Train loss=0.3204726576805115
[15/24] Train loss=0.3004167973995209
[20/24] Train loss=0.29217249155044556
Test set avg_accuracy=83.15% avg_sensitivity=47.42%, avg_specificity=95.04% avg_auc=88.03%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.330069 Test loss=0.370671 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.30490902066230774
[5/24] Train loss=0.3373284637928009
[10/24] Train loss=0.3281782567501068
[15/24] Train loss=0.30000758171081543
[20/24] Train loss=0.2935752272605896
Test set avg_accuracy=82.96% avg_sensitivity=45.38%, avg_specificity=95.45% avg_auc=87.98%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.329646 Test loss=0.372494 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.30565372109413147
[5/24] Train loss=0.34233877062797546
[10/24] Train loss=0.32606688141822815
[15/24] Train loss=0.29547545313835144
[20/24] Train loss=0.2932402193546295
Test set avg_accuracy=83.31% avg_sensitivity=47.21%, avg_specificity=95.31% avg_auc=88.02%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.330141 Test loss=0.370757 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.30732008814811707
[5/24] Train loss=0.339517742395401
[10/24] Train loss=0.3279075026512146
[15/24] Train loss=0.3008653223514557
[20/24] Train loss=0.29014959931373596
Test set avg_accuracy=83.39% avg_sensitivity=47.73%, avg_specificity=95.25% avg_auc=88.04%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.329093 Test loss=0.369707 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.30482786893844604
[5/24] Train loss=0.33431440591812134
[10/24] Train loss=0.3256628215312958
[15/24] Train loss=0.2950350046157837
[20/24] Train loss=0.2900983989238739
Test set avg_accuracy=83.05% avg_sensitivity=45.17%, avg_specificity=95.64% avg_auc=87.96%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.328944 Test loss=0.373559 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.30473148822784424
[5/24] Train loss=0.34289857745170593
[10/24] Train loss=0.3264370858669281
[15/24] Train loss=0.2996346950531006
[20/24] Train loss=0.29261744022369385
Test set avg_accuracy=82.79% avg_sensitivity=43.97%, avg_specificity=95.70% avg_auc=87.90%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.330710 Test loss=0.375643 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3090723156929016
[5/24] Train loss=0.33432185649871826
[10/24] Train loss=0.32310590147972107
[15/24] Train loss=0.2954505681991577
[20/24] Train loss=0.2894669473171234
Test set avg_accuracy=82.96% avg_sensitivity=42.98%, avg_specificity=96.25% avg_auc=87.96%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.328550 Test loss=0.374551 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.307010680437088
[5/24] Train loss=0.3311777710914612
[10/24] Train loss=0.3262692391872406
[15/24] Train loss=0.2968030869960785
[20/24] Train loss=0.29166725277900696
Test set avg_accuracy=83.07% avg_sensitivity=43.04%, avg_specificity=96.39% avg_auc=87.87%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.329671 Test loss=0.376791 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3082932233810425
[5/24] Train loss=0.32296743988990784
[10/24] Train loss=0.32777920365333557
[15/24] Train loss=0.2996014952659607
[20/24] Train loss=0.2884570062160492
Test set avg_accuracy=82.93% avg_sensitivity=44.65%, avg_specificity=95.66% avg_auc=87.98%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.328014 Test loss=0.372624 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3066234290599823
[5/24] Train loss=0.32479026913642883
[10/24] Train loss=0.3316684365272522
[15/24] Train loss=0.29954850673675537
[20/24] Train loss=0.28913190960884094
Test set avg_accuracy=83.03% avg_sensitivity=45.59%, avg_specificity=95.49% avg_auc=87.96%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.329008 Test loss=0.372308 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.30694544315338135
[5/24] Train loss=0.3274019956588745
[10/24] Train loss=0.3225850462913513
[15/24] Train loss=0.30074554681777954
[20/24] Train loss=0.29039549827575684
Test set avg_accuracy=83.14% avg_sensitivity=45.85%, avg_specificity=95.54% avg_auc=87.99%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.328450 Test loss=0.371310 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3041135370731354
[5/24] Train loss=0.3255431652069092
[10/24] Train loss=0.32529643177986145
[15/24] Train loss=0.3007037937641144
[20/24] Train loss=0.2861080765724182
Test set avg_accuracy=82.88% avg_sensitivity=44.44%, avg_specificity=95.66% avg_auc=87.94%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.328344 Test loss=0.372950 Current lr=[0.000224838296036774]

[0/24] Train loss=0.30641233921051025
[5/24] Train loss=0.32369622588157654
[10/24] Train loss=0.3228314220905304
[15/24] Train loss=0.3004132807254791
[20/24] Train loss=0.28767794370651245
Test set avg_accuracy=83.19% avg_sensitivity=46.79%, avg_specificity=95.30% avg_auc=87.94%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.328009 Test loss=0.371054 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3043021261692047
[5/24] Train loss=0.32101503014564514
[10/24] Train loss=0.3297615945339203
[15/24] Train loss=0.29694467782974243
[20/24] Train loss=0.2879055142402649
Test set avg_accuracy=83.20% avg_sensitivity=46.58%, avg_specificity=95.38% avg_auc=87.98%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.327593 Test loss=0.370411 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.306216299533844
[5/24] Train loss=0.325088769197464
[10/24] Train loss=0.32648590207099915
[15/24] Train loss=0.2982654869556427
[20/24] Train loss=0.2878383696079254
Test set avg_accuracy=83.53% avg_sensitivity=48.51%, avg_specificity=95.18% avg_auc=88.06%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.328228 Test loss=0.368289 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.30059999227523804
[5/24] Train loss=0.3296402096748352
[10/24] Train loss=0.3237950801849365
[15/24] Train loss=0.29876509308815
[20/24] Train loss=0.2888014018535614
Test set avg_accuracy=83.39% avg_sensitivity=46.79%, avg_specificity=95.56% avg_auc=87.95%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.327554 Test loss=0.370452 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3082708418369293
[5/24] Train loss=0.32518890500068665
[10/24] Train loss=0.3278146982192993
[15/24] Train loss=0.2998688519001007
[20/24] Train loss=0.29225751757621765
Test set avg_accuracy=83.63% avg_sensitivity=48.41%, avg_specificity=95.35% avg_auc=87.97%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.328460 Test loss=0.368191 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2999202609062195
[5/24] Train loss=0.318410187959671
[10/24] Train loss=0.326158732175827
[15/24] Train loss=0.2993728816509247
[20/24] Train loss=0.2852442264556885
Test set avg_accuracy=83.55% avg_sensitivity=47.63%, avg_specificity=95.51% avg_auc=87.87%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.326231 Test loss=0.370859 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.30184340476989746
[5/24] Train loss=0.32210126519203186
[10/24] Train loss=0.3272106349468231
[15/24] Train loss=0.2945821285247803
[20/24] Train loss=0.2861773371696472
Test set avg_accuracy=83.28% avg_sensitivity=47.31%, avg_specificity=95.25% avg_auc=88.01%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.325386 Test loss=0.369619 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3008595407009125
[5/24] Train loss=0.3254268169403076
[10/24] Train loss=0.32572323083877563
[15/24] Train loss=0.29900768399238586
[20/24] Train loss=0.28708869218826294
Test set avg_accuracy=83.54% avg_sensitivity=47.73%, avg_specificity=95.45% avg_auc=87.92%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.326965 Test loss=0.369733 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.30043795704841614
[5/24] Train loss=0.3175750970840454
[10/24] Train loss=0.32181864976882935
[15/24] Train loss=0.2970517873764038
[20/24] Train loss=0.2880692780017853
Test set avg_accuracy=83.40% avg_sensitivity=47.00%, avg_specificity=95.51% avg_auc=87.86%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.325931 Test loss=0.371576 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2991265058517456
[5/24] Train loss=0.3208877146244049
[10/24] Train loss=0.3251185417175293
[15/24] Train loss=0.29435762763023376
[20/24] Train loss=0.2891404926776886
Test set avg_accuracy=83.62% avg_sensitivity=47.63%, avg_specificity=95.59% avg_auc=87.90%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.325748 Test loss=0.370820 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3035871386528015
[5/24] Train loss=0.32254844903945923
[10/24] Train loss=0.32362988591194153
[15/24] Train loss=0.29772040247917175
[20/24] Train loss=0.28537940979003906
Test set avg_accuracy=83.41% avg_sensitivity=46.84%, avg_specificity=95.58% avg_auc=87.92%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.325708 Test loss=0.371788 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3011013865470886
[5/24] Train loss=0.3193320631980896
[10/24] Train loss=0.32690179347991943
[15/24] Train loss=0.29855480790138245
[20/24] Train loss=0.28592225909233093
Test set avg_accuracy=83.02% avg_sensitivity=44.81%, avg_specificity=95.73% avg_auc=87.83%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.326067 Test loss=0.374382 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3031576871871948
[5/24] Train loss=0.3163219690322876
[10/24] Train loss=0.32296836376190186
[15/24] Train loss=0.29804861545562744
[20/24] Train loss=0.28582122921943665
Test set avg_accuracy=83.02% avg_sensitivity=45.49%, avg_specificity=95.51% avg_auc=87.78%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.326161 Test loss=0.375329 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3024281859397888
[5/24] Train loss=0.31614217162132263
[10/24] Train loss=0.32012245059013367
[15/24] Train loss=0.29743465781211853
[20/24] Train loss=0.29141637682914734
Test set avg_accuracy=83.70% avg_sensitivity=49.61%, avg_specificity=95.04% avg_auc=87.87%
Best model saved!! Metric=-9.785537538296516!!
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.327474 Test loss=0.370821 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2975175082683563
[5/24] Train loss=0.31912487745285034
[10/24] Train loss=0.3255298435688019
[15/24] Train loss=0.2989926040172577
[20/24] Train loss=0.2826489210128784
Test set avg_accuracy=83.53% avg_sensitivity=55.61%, avg_specificity=92.82% avg_auc=88.08%
Best model saved!! Metric=-5.965668941246754!!
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.328931 Test loss=0.363742 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2989509701728821
[5/24] Train loss=0.3134777843952179
[10/24] Train loss=0.3235970437526703
[15/24] Train loss=0.3018997311592102
[20/24] Train loss=0.2811056971549988
Test set avg_accuracy=83.57% avg_sensitivity=57.38%, avg_specificity=92.28% avg_auc=88.14%
Best model saved!! Metric=-4.6334198501543895!!
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.327076 Test loss=0.363228 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2920982241630554
[5/24] Train loss=0.3191492259502411
[10/24] Train loss=0.32057058811187744
[15/24] Train loss=0.29709532856941223
[20/24] Train loss=0.2829349637031555
Test set avg_accuracy=83.65% avg_sensitivity=56.39%, avg_specificity=92.71% avg_auc=88.14%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.324428 Test loss=0.362937 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.294146329164505
[5/24] Train loss=0.3168332576751709
[10/24] Train loss=0.3203279674053192
[15/24] Train loss=0.29029449820518494
[20/24] Train loss=0.2825942635536194
Test set avg_accuracy=83.55% avg_sensitivity=56.81%, avg_specificity=92.45% avg_auc=88.19%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.323574 Test loss=0.362527 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2891400456428528
[5/24] Train loss=0.3163124620914459
[10/24] Train loss=0.3200208246707916
[15/24] Train loss=0.29410040378570557
[20/24] Train loss=0.28113213181495667
Test set avg_accuracy=83.75% avg_sensitivity=56.55%, avg_specificity=92.80% avg_auc=88.19%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.323792 Test loss=0.362439 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.2928156554698944
[5/24] Train loss=0.31869515776634216
[10/24] Train loss=0.3220711648464203
[15/24] Train loss=0.2993096113204956
[20/24] Train loss=0.2794671654701233
Test set avg_accuracy=83.66% avg_sensitivity=56.60%, avg_specificity=92.66% avg_auc=88.22%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.323911 Test loss=0.361868 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.28783825039863586
[5/24] Train loss=0.3161297142505646
[10/24] Train loss=0.32092931866645813
[15/24] Train loss=0.30025777220726013
[20/24] Train loss=0.28616422414779663
Test set avg_accuracy=83.49% avg_sensitivity=56.70%, avg_specificity=92.40% avg_auc=88.18%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.324049 Test loss=0.362209 Current lr=[0.000134135431043539]

[0/24] Train loss=0.2945067882537842
[5/24] Train loss=0.3186686336994171
[10/24] Train loss=0.32437676191329956
[15/24] Train loss=0.29805243015289307
[20/24] Train loss=0.2835225760936737
Test set avg_accuracy=83.63% avg_sensitivity=56.39%, avg_specificity=92.69% avg_auc=88.12%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.324152 Test loss=0.363110 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.2900933623313904
[5/24] Train loss=0.31470027565956116
[10/24] Train loss=0.3205130398273468
[15/24] Train loss=0.2929641902446747
[20/24] Train loss=0.28248700499534607
Test set avg_accuracy=83.54% avg_sensitivity=56.81%, avg_specificity=92.43% avg_auc=88.15%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.322466 Test loss=0.362741 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2944640517234802
[5/24] Train loss=0.32093650102615356
[10/24] Train loss=0.3230583369731903
[15/24] Train loss=0.2964353859424591
[20/24] Train loss=0.28482764959335327
Test set avg_accuracy=83.72% avg_sensitivity=57.28%, avg_specificity=92.52% avg_auc=88.12%
Best model saved!! Metric=-4.35651093480471!!
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.322784 Test loss=0.363214 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.2923963665962219
[5/24] Train loss=0.3177536129951477
[10/24] Train loss=0.3255857229232788
[15/24] Train loss=0.2992634177207947
[20/24] Train loss=0.28369706869125366
Test set avg_accuracy=83.75% avg_sensitivity=56.96%, avg_specificity=92.66% avg_auc=88.18%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.323058 Test loss=0.362139 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.2937178909778595
[5/24] Train loss=0.31503742933273315
[10/24] Train loss=0.31641000509262085
[15/24] Train loss=0.29453426599502563
[20/24] Train loss=0.2836250364780426
Test set avg_accuracy=83.87% avg_sensitivity=57.90%, avg_specificity=92.50% avg_auc=88.25%
Best model saved!! Metric=-3.4806839201391355!!
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.322426 Test loss=0.361516 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.29147157073020935
[5/24] Train loss=0.3193657100200653
[10/24] Train loss=0.3265324831008911
[15/24] Train loss=0.29638102650642395
[20/24] Train loss=0.27963924407958984
Test set avg_accuracy=83.83% avg_sensitivity=60.56%, avg_specificity=91.57% avg_auc=88.26%
Best model saved!! Metric=-1.7777005174325993!!
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.324297 Test loss=0.361766 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.29544559121131897
[5/24] Train loss=0.3243824541568756
[10/24] Train loss=0.3349478542804718
[15/24] Train loss=0.3007333278656006
[20/24] Train loss=0.2824946939945221
Test set avg_accuracy=83.84% avg_sensitivity=66.88%, avg_specificity=89.48% avg_auc=88.20%
Best model saved!! Metric=2.4027869249263034!!
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.327141 Test loss=0.367864 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3010411858558655
[5/24] Train loss=0.34813451766967773
[10/24] Train loss=0.3404657244682312
[15/24] Train loss=0.29783469438552856
[20/24] Train loss=0.2808663249015808
Test set avg_accuracy=83.62% avg_sensitivity=72.98%, avg_specificity=87.16% avg_auc=88.00%
Best model saved!! Metric=5.7569601250684315!!
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.330827 Test loss=0.383793 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.32717785239219666
[5/24] Train loss=0.34421879053115845
[10/24] Train loss=0.3228677213191986
[15/24] Train loss=0.3066186308860779
[20/24] Train loss=0.3038387596607208
Test set avg_accuracy=84.06% avg_sensitivity=67.76%, avg_specificity=89.48% avg_auc=88.15%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.331625 Test loss=0.369421 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.30337759852409363
[5/24] Train loss=0.3167708218097687
[10/24] Train loss=0.32641366124153137
[15/24] Train loss=0.310347318649292
[20/24] Train loss=0.2950606942176819
Test set avg_accuracy=83.85% avg_sensitivity=61.55%, avg_specificity=91.27% avg_auc=88.21%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.325305 Test loss=0.362969 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2976430654525757
[5/24] Train loss=0.3208288550376892
[10/24] Train loss=0.32374733686447144
[15/24] Train loss=0.3001249432563782
[20/24] Train loss=0.28931933641433716
Test set avg_accuracy=83.98% avg_sensitivity=65.05%, avg_specificity=90.28% avg_auc=88.24%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.323048 Test loss=0.364689 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.29603341221809387
[5/24] Train loss=0.3240876793861389
[10/24] Train loss=0.32294192910194397
[15/24] Train loss=0.30388134717941284
[20/24] Train loss=0.2886851727962494
Test set avg_accuracy=84.08% avg_sensitivity=65.05%, avg_specificity=90.40% avg_auc=88.22%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.324177 Test loss=0.365229 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.29903095960617065
[5/24] Train loss=0.3237575590610504
[10/24] Train loss=0.32194894552230835
[15/24] Train loss=0.30382877588272095
[20/24] Train loss=0.2938793897628784
Test set avg_accuracy=83.95% avg_sensitivity=62.44%, avg_specificity=91.10% avg_auc=88.22%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.324580 Test loss=0.364182 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.29947197437286377
[5/24] Train loss=0.3199992775917053
[10/24] Train loss=0.32237231731414795
[15/24] Train loss=0.3034428656101227
[20/24] Train loss=0.289171427488327
Test set avg_accuracy=83.95% avg_sensitivity=62.70%, avg_specificity=91.01% avg_auc=88.17%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.323466 Test loss=0.365218 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.301719605922699
[5/24] Train loss=0.3223215937614441
[10/24] Train loss=0.317644327878952
[15/24] Train loss=0.30097758769989014
[20/24] Train loss=0.29130473732948303
Test set avg_accuracy=84.02% avg_sensitivity=62.44%, avg_specificity=91.20% avg_auc=88.12%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.322797 Test loss=0.365673 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.30165722966194153
[5/24] Train loss=0.3161008954048157
[10/24] Train loss=0.32202035188674927
[15/24] Train loss=0.3019202649593353
[20/24] Train loss=0.2881564497947693
Test set avg_accuracy=84.08% avg_sensitivity=62.08%, avg_specificity=91.39% avg_auc=88.20%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.321189 Test loss=0.363849 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.30112549662590027
[5/24] Train loss=0.3156895339488983
[10/24] Train loss=0.32013341784477234
[15/24] Train loss=0.30415472388267517
[20/24] Train loss=0.2928314507007599
Test set avg_accuracy=84.01% avg_sensitivity=62.13%, avg_specificity=91.29% avg_auc=88.30%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.321110 Test loss=0.361938 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.2967146039009094
[5/24] Train loss=0.3133534789085388
[10/24] Train loss=0.3217456340789795
[15/24] Train loss=0.3041873872280121
[20/24] Train loss=0.29265648126602173
Test set avg_accuracy=83.95% avg_sensitivity=61.61%, avg_specificity=91.38% avg_auc=88.34%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.320786 Test loss=0.361110 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.2927612364292145
[5/24] Train loss=0.3158971071243286
[10/24] Train loss=0.3175540566444397
[15/24] Train loss=0.30217641592025757
[20/24] Train loss=0.2870219051837921
Test set avg_accuracy=83.82% avg_sensitivity=60.51%, avg_specificity=91.57% avg_auc=88.34%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.320059 Test loss=0.360616 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.29525598883628845
[5/24] Train loss=0.3157848119735718
[10/24] Train loss=0.32150301337242126
[15/24] Train loss=0.30089572072029114
[20/24] Train loss=0.2888147532939911
Test set avg_accuracy=83.82% avg_sensitivity=59.89%, avg_specificity=91.78% avg_auc=88.36%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.319767 Test loss=0.360219 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.29102709889411926
[5/24] Train loss=0.31486836075782776
[10/24] Train loss=0.3216840922832489
[15/24] Train loss=0.30208760499954224
[20/24] Train loss=0.2814101576805115
Test set avg_accuracy=83.97% avg_sensitivity=59.57%, avg_specificity=92.09% avg_auc=88.34%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.318594 Test loss=0.360186 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.29397979378700256
[5/24] Train loss=0.31150686740875244
[10/24] Train loss=0.3182864785194397
[15/24] Train loss=0.29530736804008484
[20/24] Train loss=0.28472578525543213
Test set avg_accuracy=83.84% avg_sensitivity=59.83%, avg_specificity=91.83% avg_auc=88.35%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.318568 Test loss=0.360250 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.2896776497364044
[5/24] Train loss=0.3132241368293762
[10/24] Train loss=0.3194974958896637
[15/24] Train loss=0.29931876063346863
[20/24] Train loss=0.28501877188682556
Test set avg_accuracy=83.93% avg_sensitivity=59.31%, avg_specificity=92.12% avg_auc=88.38%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.318731 Test loss=0.359582 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.2921055555343628
[5/24] Train loss=0.3181860148906708
[10/24] Train loss=0.31903815269470215
[15/24] Train loss=0.30087554454803467
[20/24] Train loss=0.28241467475891113
Test set avg_accuracy=83.96% avg_sensitivity=59.52%, avg_specificity=92.09% avg_auc=88.36%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.317241 Test loss=0.359958 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.29153940081596375
[5/24] Train loss=0.3159145414829254
[10/24] Train loss=0.322447270154953
[15/24] Train loss=0.29788675904273987
[20/24] Train loss=0.2844996154308319
Test set avg_accuracy=83.98% avg_sensitivity=59.36%, avg_specificity=92.17% avg_auc=88.38%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.318268 Test loss=0.359535 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.29154619574546814
[5/24] Train loss=0.3102797269821167
[10/24] Train loss=0.3183443248271942
[15/24] Train loss=0.2998422682285309
[20/24] Train loss=0.28226038813591003
Test set avg_accuracy=83.91% avg_sensitivity=59.42%, avg_specificity=92.05% avg_auc=88.38%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.317195 Test loss=0.359559 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.29098549485206604
[5/24] Train loss=0.3151715099811554
[10/24] Train loss=0.32018592953681946
[15/24] Train loss=0.2991202175617218
[20/24] Train loss=0.2833087742328644
Test set avg_accuracy=83.92% avg_sensitivity=59.31%, avg_specificity=92.10% avg_auc=88.38%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.316899 Test loss=0.359549 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.2923036515712738
[5/24] Train loss=0.3154711425304413
[10/24] Train loss=0.3209063410758972
[15/24] Train loss=0.301634818315506
[20/24] Train loss=0.27997323870658875
Test set avg_accuracy=83.98% avg_sensitivity=59.05%, avg_specificity=92.28% avg_auc=88.39%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.317080 Test loss=0.359413 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.29047682881355286
[5/24] Train loss=0.3162844479084015
[10/24] Train loss=0.3190610408782959
[15/24] Train loss=0.30415764451026917
[20/24] Train loss=0.2804917097091675
Test set avg_accuracy=84.00% avg_sensitivity=59.73%, avg_specificity=92.07% avg_auc=88.39%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.317531 Test loss=0.359522 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.29072827100753784
[5/24] Train loss=0.31839242577552795
[10/24] Train loss=0.3176303505897522
[15/24] Train loss=0.30014166235923767
[20/24] Train loss=0.2793757915496826
Test set avg_accuracy=83.79% avg_sensitivity=59.78%, avg_specificity=91.78% avg_auc=88.40%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.317813 Test loss=0.359535 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.2922457158565521
[5/24] Train loss=0.31751951575279236
[10/24] Train loss=0.31878167390823364
[15/24] Train loss=0.2985397279262543
[20/24] Train loss=0.27855902910232544
Test set avg_accuracy=83.85% avg_sensitivity=61.76%, avg_specificity=91.20% avg_auc=88.40%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.317675 Test loss=0.360125 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.2918258011341095
[5/24] Train loss=0.3114669620990753
[10/24] Train loss=0.319961279630661
[15/24] Train loss=0.2963530421257019
[20/24] Train loss=0.28037765622138977
Test set avg_accuracy=83.80% avg_sensitivity=62.91%, avg_specificity=90.75% avg_auc=88.39%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.316389 Test loss=0.360964 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.2945663630962372
[5/24] Train loss=0.30931150913238525
[10/24] Train loss=0.3199881315231323
[15/24] Train loss=0.2981557250022888
[20/24] Train loss=0.27774810791015625
Test set avg_accuracy=83.89% avg_sensitivity=63.48%, avg_specificity=90.68% avg_auc=88.39%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.317125 Test loss=0.361394 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.2957613170146942
[5/24] Train loss=0.30804669857025146
[10/24] Train loss=0.31872883439064026
[15/24] Train loss=0.2957773804664612
[20/24] Train loss=0.2794473171234131
Test set avg_accuracy=83.78% avg_sensitivity=62.18%, avg_specificity=90.96% avg_auc=88.38%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.316575 Test loss=0.360844 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.28966179490089417
[5/24] Train loss=0.3107348382472992
[10/24] Train loss=0.31653812527656555
[15/24] Train loss=0.29625049233436584
[20/24] Train loss=0.27603647112846375
Test set avg_accuracy=83.98% avg_sensitivity=61.87%, avg_specificity=91.34% avg_auc=88.37%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.315962 Test loss=0.360763 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.29002776741981506
[5/24] Train loss=0.3069296181201935
[10/24] Train loss=0.3176836669445038
[15/24] Train loss=0.2983073592185974
[20/24] Train loss=0.28192827105522156
Test set avg_accuracy=83.92% avg_sensitivity=61.03%, avg_specificity=91.53% avg_auc=88.38%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.315937 Test loss=0.360282 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.28638115525245667
[5/24] Train loss=0.30979740619659424
[10/24] Train loss=0.3167303502559662
[15/24] Train loss=0.2969602644443512
[20/24] Train loss=0.283618688583374
Test set avg_accuracy=84.09% avg_sensitivity=60.93%, avg_specificity=91.79% avg_auc=88.40%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.315250 Test loss=0.359827 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.2910597622394562
[5/24] Train loss=0.30933064222335815
[10/24] Train loss=0.3167913854122162
[15/24] Train loss=0.2908594310283661
[20/24] Train loss=0.2780928313732147
Test set avg_accuracy=84.01% avg_sensitivity=60.62%, avg_specificity=91.79% avg_auc=88.40%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.315369 Test loss=0.359659 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.2923494875431061
[5/24] Train loss=0.31008490920066833
[10/24] Train loss=0.32206690311431885
[15/24] Train loss=0.293905109167099
[20/24] Train loss=0.28022080659866333
Test set avg_accuracy=84.00% avg_sensitivity=60.46%, avg_specificity=91.83% avg_auc=88.40%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.315537 Test loss=0.359578 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.2900804579257965
[5/24] Train loss=0.30407580733299255
[10/24] Train loss=0.31680890917778015
[15/24] Train loss=0.29391568899154663
[20/24] Train loss=0.2808563709259033
Test set avg_accuracy=84.02% avg_sensitivity=60.56%, avg_specificity=91.83% avg_auc=88.40%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.314910 Test loss=0.359574 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.28976720571517944
[5/24] Train loss=0.3103129267692566
[10/24] Train loss=0.3163226544857025
[15/24] Train loss=0.29422444105148315
[20/24] Train loss=0.28102266788482666
Test set avg_accuracy=83.89% avg_sensitivity=59.83%, avg_specificity=91.90% avg_auc=88.40%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.315446 Test loss=0.359395 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.2898446023464203
[5/24] Train loss=0.30649057030677795
[10/24] Train loss=0.3149116039276123
[15/24] Train loss=0.2954394817352295
[20/24] Train loss=0.27958086133003235
Test set avg_accuracy=84.02% avg_sensitivity=60.35%, avg_specificity=91.90% avg_auc=88.40%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.314537 Test loss=0.359421 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.29153016209602356
[5/24] Train loss=0.30909645557403564
[10/24] Train loss=0.31570079922676086
[15/24] Train loss=0.29374194145202637
[20/24] Train loss=0.27839750051498413
Test set avg_accuracy=83.95% avg_sensitivity=60.04%, avg_specificity=91.90% avg_auc=88.40%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.315519 Test loss=0.359384 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.29098647832870483
[5/24] Train loss=0.3090580701828003
[10/24] Train loss=0.3140236735343933
[15/24] Train loss=0.2908264398574829
[20/24] Train loss=0.280816912651062
Test set avg_accuracy=83.95% avg_sensitivity=60.04%, avg_specificity=91.90% avg_auc=88.41%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.313897 Test loss=0.359371 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.29050353169441223
[5/24] Train loss=0.3131901025772095
[10/24] Train loss=0.32092899084091187
[15/24] Train loss=0.2972949147224426
[20/24] Train loss=0.2789490520954132
Test set avg_accuracy=83.89% avg_sensitivity=59.68%, avg_specificity=91.95% avg_auc=88.41%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.316358 Test loss=0.359302 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.28630074858665466
[5/24] Train loss=0.310185968875885
[10/24] Train loss=0.3155462443828583
[15/24] Train loss=0.2923572361469269
[20/24] Train loss=0.2806421220302582
Test set avg_accuracy=83.89% avg_sensitivity=59.68%, avg_specificity=91.95% avg_auc=88.41%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.315106 Test loss=0.359268 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.29409876465797424
[5/24] Train loss=0.31007036566734314
[10/24] Train loss=0.3184310495853424
[15/24] Train loss=0.2951837182044983
[20/24] Train loss=0.28149062395095825
Test set avg_accuracy=83.89% avg_sensitivity=59.68%, avg_specificity=91.95% avg_auc=88.41%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.315541 Test loss=0.359269 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.2921515703201294
[5/24] Train loss=0.31210723519325256
[10/24] Train loss=0.31580042839050293
[15/24] Train loss=0.293594092130661
[20/24] Train loss=0.277910053730011
Test set avg_accuracy=83.89% avg_sensitivity=59.68%, avg_specificity=91.95% avg_auc=88.41%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.315337 Test loss=0.359271 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.2880105674266815
[5/24] Train loss=0.31010159850120544
[10/24] Train loss=0.31565162539482117
[15/24] Train loss=0.29570090770721436
[20/24] Train loss=0.2787168622016907
Test set avg_accuracy=83.89% avg_sensitivity=59.68%, avg_specificity=91.95% avg_auc=88.41%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.314791 Test loss=0.359269 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=83.62% sen=72.98%, spe=87.16%, auc=88.00%!
Fold[2] Avg_overlap=0.65%(0.24537113960010684)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'HybridCNNRNN',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.8043196797370911
[5/24] Train loss=0.6907939910888672
[10/24] Train loss=0.6749296188354492
[15/24] Train loss=0.6388825178146362
[20/24] Train loss=0.6346140503883362
Test set avg_accuracy=72.46% avg_sensitivity=0.00%, avg_specificity=99.91% avg_auc=51.59%
Best model saved!! Metric=-102.03773514543467!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.662420 Test loss=0.595060 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.608681857585907
[5/24] Train loss=0.5849655270576477
[10/24] Train loss=0.6371779441833496
[15/24] Train loss=0.6154910326004028
[20/24] Train loss=0.6145613193511963
Test set avg_accuracy=72.51% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=56.73%
Best model saved!! Metric=-96.77878445396234!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.595801 Test loss=0.582786 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.5967794060707092
[5/24] Train loss=0.5646151304244995
[10/24] Train loss=0.6302570104598999
[15/24] Train loss=0.6080483198165894
[20/24] Train loss=0.600318431854248
Test set avg_accuracy=72.49% avg_sensitivity=0.00%, avg_specificity=99.95% avg_auc=60.43%
Best model saved!! Metric=-93.13644353620161!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.587114 Test loss=0.576290 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.5890364646911621
[5/24] Train loss=0.562846839427948
[10/24] Train loss=0.6235418915748596
[15/24] Train loss=0.5921186208724976
[20/24] Train loss=0.5921709537506104
Test set avg_accuracy=72.47% avg_sensitivity=0.00%, avg_specificity=99.93% avg_auc=64.80%
Best model saved!! Metric=-88.80143795858257!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.579448 Test loss=0.568910 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5758084654808044
[5/24] Train loss=0.5545562505722046
[10/24] Train loss=0.6125285625457764
[15/24] Train loss=0.5837022066116333
[20/24] Train loss=0.580237090587616
Test set avg_accuracy=72.47% avg_sensitivity=0.00%, avg_specificity=99.93% avg_auc=68.34%
Best model saved!! Metric=-85.25823937442745!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.570793 Test loss=0.561465 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5653676390647888
[5/24] Train loss=0.5444146990776062
[10/24] Train loss=0.602973997592926
[15/24] Train loss=0.5766183733940125
[20/24] Train loss=0.5750387907028198
Test set avg_accuracy=72.43% avg_sensitivity=0.00%, avg_specificity=99.87% avg_auc=72.10%
Best model saved!! Metric=-81.58785213096422!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.562662 Test loss=0.553861 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5597348809242249
[5/24] Train loss=0.539174497127533
[10/24] Train loss=0.6001706123352051
[15/24] Train loss=0.5659803152084351
[20/24] Train loss=0.5636470317840576
Test set avg_accuracy=72.40% avg_sensitivity=0.24%, avg_specificity=99.73% avg_auc=75.56%
Best model saved!! Metric=-78.07276962598664!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.553176 Test loss=0.545110 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5441875457763672
[5/24] Train loss=0.5273474454879761
[10/24] Train loss=0.5835856795310974
[15/24] Train loss=0.5540668964385986
[20/24] Train loss=0.5487325191497803
Test set avg_accuracy=72.38% avg_sensitivity=0.33%, avg_specificity=99.68% avg_auc=77.99%
Best model saved!! Metric=-75.62235227064845!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.544317 Test loss=0.534869 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5425189137458801
[5/24] Train loss=0.5181782841682434
[10/24] Train loss=0.5726377367973328
[15/24] Train loss=0.5420451760292053
[20/24] Train loss=0.5478188991546631
Test set avg_accuracy=72.28% avg_sensitivity=0.66%, avg_specificity=99.41% avg_auc=80.14%
Best model saved!! Metric=-73.50677368728749!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.534853 Test loss=0.523014 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5219635963439941
[5/24] Train loss=0.5057858824729919
[10/24] Train loss=0.5699904561042786
[15/24] Train loss=0.533386766910553
[20/24] Train loss=0.5233572721481323
Test set avg_accuracy=72.40% avg_sensitivity=1.71%, avg_specificity=99.17% avg_auc=81.86%
Best model saved!! Metric=-70.86272002036411!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.523138 Test loss=0.509447 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5084264874458313
[5/24] Train loss=0.49694859981536865
[10/24] Train loss=0.5559705495834351
[15/24] Train loss=0.522558331489563
[20/24] Train loss=0.5021803975105286
Test set avg_accuracy=72.25% avg_sensitivity=5.07%, avg_specificity=97.70% avg_auc=83.38%
Best model saved!! Metric=-67.59144443493125!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.508133 Test loss=0.492321 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4967416524887085
[5/24] Train loss=0.48024803400039673
[10/24] Train loss=0.5392299890518188
[15/24] Train loss=0.49822238087654114
[20/24] Train loss=0.4931083619594574
Test set avg_accuracy=72.33% avg_sensitivity=6.54%, avg_specificity=97.25% avg_auc=84.44%
Best model saved!! Metric=-65.44069357023635!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.493843 Test loss=0.475419 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.477777898311615
[5/24] Train loss=0.467193603515625
[10/24] Train loss=0.5189242362976074
[15/24] Train loss=0.4870716333389282
[20/24] Train loss=0.47396114468574524
Test set avg_accuracy=73.07% avg_sensitivity=14.03%, avg_specificity=95.44% avg_auc=85.24%
Best model saved!! Metric=-58.215565979874114!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.478757 Test loss=0.458019 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4576635956764221
[5/24] Train loss=0.4540228545665741
[10/24] Train loss=0.512642502784729
[15/24] Train loss=0.4628323018550873
[20/24] Train loss=0.4565246105194092
Test set avg_accuracy=74.79% avg_sensitivity=25.59%, avg_specificity=93.43% avg_auc=86.02%
Best model saved!! Metric=-46.16713854405086!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.463634 Test loss=0.441226 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.45503637194633484
[5/24] Train loss=0.429918110370636
[10/24] Train loss=0.49667614698410034
[15/24] Train loss=0.4669804871082306
[20/24] Train loss=0.43821874260902405
Test set avg_accuracy=77.25% avg_sensitivity=35.69%, avg_specificity=93.00% avg_auc=86.46%
Best model saved!! Metric=-33.59922137129481!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.452313 Test loss=0.429559 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.43904659152030945
[5/24] Train loss=0.4276106655597687
[10/24] Train loss=0.48276397585868835
[15/24] Train loss=0.4431101083755493
[20/24] Train loss=0.4281412661075592
Test set avg_accuracy=80.23% avg_sensitivity=49.57%, avg_specificity=91.85% avg_auc=86.93%
Best model saved!! Metric=-17.414705636789833!!
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.441458 Test loss=0.421120 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4323662519454956
[5/24] Train loss=0.42930349707603455
[10/24] Train loss=0.4718988835811615
[15/24] Train loss=0.4474446177482605
[20/24] Train loss=0.4164730906486511
Test set avg_accuracy=80.81% avg_sensitivity=53.55%, avg_specificity=91.13% avg_auc=87.22%
Best model saved!! Metric=-13.286720773028037!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.433680 Test loss=0.413622 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.425176203250885
[5/24] Train loss=0.4287358820438385
[10/24] Train loss=0.4669199287891388
[15/24] Train loss=0.44420143961906433
[20/24] Train loss=0.410072922706604
Test set avg_accuracy=81.33% avg_sensitivity=56.87%, avg_specificity=90.59% avg_auc=87.72%
Best model saved!! Metric=-9.48514344044348!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.428213 Test loss=0.407890 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.42119574546813965
[5/24] Train loss=0.4319881796836853
[10/24] Train loss=0.4589386284351349
[15/24] Train loss=0.4402652978897095
[20/24] Train loss=0.3982516825199127
Test set avg_accuracy=81.89% avg_sensitivity=57.73%, avg_specificity=91.04% avg_auc=88.07%
Best model saved!! Metric=-7.279863993132096!!
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.421890 Test loss=0.398764 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4047175645828247
[5/24] Train loss=0.4205205738544464
[10/24] Train loss=0.4521465599536896
[15/24] Train loss=0.4420320987701416
[20/24] Train loss=0.38815435767173767
Test set avg_accuracy=82.04% avg_sensitivity=56.59%, avg_specificity=91.69% avg_auc=88.39%
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.411863 Test loss=0.389719 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.39362502098083496
[5/24] Train loss=0.40270933508872986
[10/24] Train loss=0.44179022312164307
[15/24] Train loss=0.4367135167121887
[20/24] Train loss=0.3806593716144562
Test set avg_accuracy=80.78% avg_sensitivity=48.10%, avg_specificity=93.16% avg_auc=88.59%
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.402918 Test loss=0.383248 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3822620213031769
[5/24] Train loss=0.3919372856616974
[10/24] Train loss=0.42416682839393616
[15/24] Train loss=0.4139488935470581
[20/24] Train loss=0.3703552186489105
Test set avg_accuracy=80.87% avg_sensitivity=46.92%, avg_specificity=93.73% avg_auc=88.76%
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.392894 Test loss=0.380019 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.37126466631889343
[5/24] Train loss=0.37892189621925354
[10/24] Train loss=0.426484614610672
[15/24] Train loss=0.39834901690483093
[20/24] Train loss=0.36288371682167053
Test set avg_accuracy=82.25% avg_sensitivity=53.32%, avg_specificity=93.21% avg_auc=89.14%
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.385689 Test loss=0.373156 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.36404114961624146
[5/24] Train loss=0.3775011897087097
[10/24] Train loss=0.42043712735176086
[15/24] Train loss=0.3975682854652405
[20/24] Train loss=0.3634506165981293
Test set avg_accuracy=82.85% avg_sensitivity=55.97%, avg_specificity=93.03% avg_auc=89.53%
Best model saved!! Metric=-4.617576506355988!!
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.381977 Test loss=0.367288 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.36340975761413574
[5/24] Train loss=0.36817795038223267
[10/24] Train loss=0.4145490825176239
[15/24] Train loss=0.3820658028125763
[20/24] Train loss=0.3551141023635864
Test set avg_accuracy=81.98% avg_sensitivity=50.90%, avg_specificity=93.75% avg_auc=89.69%
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.374712 Test loss=0.364315 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3467797636985779
[5/24] Train loss=0.3678930997848511
[10/24] Train loss=0.41012510657310486
[15/24] Train loss=0.3928704261779785
[20/24] Train loss=0.3453679084777832
Test set avg_accuracy=82.06% avg_sensitivity=48.44%, avg_specificity=94.79% avg_auc=89.81%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.370708 Test loss=0.365248 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3450712263584137
[5/24] Train loss=0.3592238426208496
[10/24] Train loss=0.40095052123069763
[15/24] Train loss=0.39798504114151
[20/24] Train loss=0.3448396921157837
Test set avg_accuracy=83.09% avg_sensitivity=54.55%, avg_specificity=93.90% avg_auc=89.87%
Best model saved!! Metric=-4.6025681199852!!
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.366579 Test loss=0.360062 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.34268277883529663
[5/24] Train loss=0.35495319962501526
[10/24] Train loss=0.40051141381263733
[15/24] Train loss=0.3941410481929779
[20/24] Train loss=0.3434685468673706
Test set avg_accuracy=82.57% avg_sensitivity=50.81%, avg_specificity=94.60% avg_auc=89.76%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.364161 Test loss=0.363268 Current lr=[0.000210185142098938]

[0/24] Train loss=0.33779725432395935
[5/24] Train loss=0.35094505548477173
[10/24] Train loss=0.39335235953330994
[15/24] Train loss=0.3852144479751587
[20/24] Train loss=0.3393855094909668
Test set avg_accuracy=82.92% avg_sensitivity=50.47%, avg_specificity=95.21% avg_auc=89.99%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.361068 Test loss=0.360515 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3410518765449524
[5/24] Train loss=0.35115155577659607
[10/24] Train loss=0.3959423303604126
[15/24] Train loss=0.3769679665565491
[20/24] Train loss=0.34135928750038147
Test set avg_accuracy=82.90% avg_sensitivity=49.91%, avg_specificity=95.40% avg_auc=90.07%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.360124 Test loss=0.360236 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3343859612941742
[5/24] Train loss=0.3492964506149292
[10/24] Train loss=0.39770078659057617
[15/24] Train loss=0.37692713737487793
[20/24] Train loss=0.34174206852912903
Test set avg_accuracy=82.75% avg_sensitivity=49.10%, avg_specificity=95.49% avg_auc=90.06%
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.359683 Test loss=0.360137 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.32935526967048645
[5/24] Train loss=0.35046082735061646
[10/24] Train loss=0.3968420922756195
[15/24] Train loss=0.38471731543540955
[20/24] Train loss=0.34482353925704956
Test set avg_accuracy=82.96% avg_sensitivity=50.47%, avg_specificity=95.26% avg_auc=90.06%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.359427 Test loss=0.359907 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3311893045902252
[5/24] Train loss=0.3475095331668854
[10/24] Train loss=0.3956039547920227
[15/24] Train loss=0.38771510124206543
[20/24] Train loss=0.3415837287902832
Test set avg_accuracy=82.85% avg_sensitivity=50.43%, avg_specificity=95.13% avg_auc=90.02%
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.357174 Test loss=0.360065 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3307396173477173
[5/24] Train loss=0.34797632694244385
[10/24] Train loss=0.39601442217826843
[15/24] Train loss=0.38340073823928833
[20/24] Train loss=0.34182456135749817
Test set avg_accuracy=82.88% avg_sensitivity=49.00%, avg_specificity=95.71% avg_auc=90.02%
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.356455 Test loss=0.361247 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3342965841293335
[5/24] Train loss=0.3524979054927826
[10/24] Train loss=0.3929901421070099
[15/24] Train loss=0.3950636684894562
[20/24] Train loss=0.33868199586868286
Test set avg_accuracy=82.83% avg_sensitivity=50.19%, avg_specificity=95.19% avg_auc=90.22%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.355308 Test loss=0.358858 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3308178186416626
[5/24] Train loss=0.3480449914932251
[10/24] Train loss=0.39262208342552185
[15/24] Train loss=0.38435715436935425
[20/24] Train loss=0.33755773305892944
Test set avg_accuracy=82.85% avg_sensitivity=49.15%, avg_specificity=95.62% avg_auc=90.07%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.355549 Test loss=0.361247 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.326394647359848
[5/24] Train loss=0.34831756353378296
[10/24] Train loss=0.3953930735588074
[15/24] Train loss=0.37572216987609863
[20/24] Train loss=0.3325226306915283
Test set avg_accuracy=82.50% avg_sensitivity=46.35%, avg_specificity=96.19% avg_auc=90.02%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.352701 Test loss=0.364088 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3269785940647125
[5/24] Train loss=0.3480278551578522
[10/24] Train loss=0.3874431848526001
[15/24] Train loss=0.3722303807735443
[20/24] Train loss=0.3373939096927643
Test set avg_accuracy=82.14% avg_sensitivity=44.98%, avg_specificity=96.21% avg_auc=90.25%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.350951 Test loss=0.363342 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3283582925796509
[5/24] Train loss=0.3496028482913971
[10/24] Train loss=0.3890407085418701
[15/24] Train loss=0.37354105710983276
[20/24] Train loss=0.3351956009864807
Test set avg_accuracy=82.28% avg_sensitivity=44.88%, avg_specificity=96.45% avg_auc=90.32%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.350989 Test loss=0.364395 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3248964250087738
[5/24] Train loss=0.3474360406398773
[10/24] Train loss=0.38624176383018494
[15/24] Train loss=0.37657269835472107
[20/24] Train loss=0.32742026448249817
Test set avg_accuracy=82.01% avg_sensitivity=43.22%, avg_specificity=96.70% avg_auc=90.31%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.349969 Test loss=0.366586 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.33048951625823975
[5/24] Train loss=0.3525979220867157
[10/24] Train loss=0.3931294083595276
[15/24] Train loss=0.3832138776779175
[20/24] Train loss=0.3272658884525299
Test set avg_accuracy=82.29% avg_sensitivity=45.21%, avg_specificity=96.34% avg_auc=90.23%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.350147 Test loss=0.363648 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3246268332004547
[5/24] Train loss=0.34484991431236267
[10/24] Train loss=0.39079800248146057
[15/24] Train loss=0.37459737062454224
[20/24] Train loss=0.3301061987876892
Test set avg_accuracy=82.17% avg_sensitivity=44.27%, avg_specificity=96.54% avg_auc=90.17%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.348077 Test loss=0.364903 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3259660303592682
[5/24] Train loss=0.3481520414352417
[10/24] Train loss=0.3894293010234833
[15/24] Train loss=0.3764934539794922
[20/24] Train loss=0.3313605785369873
Test set avg_accuracy=82.47% avg_sensitivity=45.26%, avg_specificity=96.57% avg_auc=90.32%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.347790 Test loss=0.362549 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3224238157272339
[5/24] Train loss=0.3453960716724396
[10/24] Train loss=0.3863907754421234
[15/24] Train loss=0.37398040294647217
[20/24] Train loss=0.3236977159976959
Test set avg_accuracy=82.42% avg_sensitivity=46.11%, avg_specificity=96.18% avg_auc=90.30%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.347011 Test loss=0.362053 Current lr=[0.00029967723776099]

[0/24] Train loss=0.32434961199760437
[5/24] Train loss=0.3470439314842224
[10/24] Train loss=0.3892984092235565
[15/24] Train loss=0.37034162878990173
[20/24] Train loss=0.32502150535583496
Test set avg_accuracy=81.82% avg_sensitivity=41.94%, avg_specificity=96.93% avg_auc=90.28%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.347286 Test loss=0.368506 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.32532408833503723
[5/24] Train loss=0.3479733467102051
[10/24] Train loss=0.39097583293914795
[15/24] Train loss=0.3821937143802643
[20/24] Train loss=0.328371524810791
Test set avg_accuracy=82.29% avg_sensitivity=44.12%, avg_specificity=96.75% avg_auc=90.31%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.346822 Test loss=0.364177 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.31944167613983154
[5/24] Train loss=0.35142603516578674
[10/24] Train loss=0.38621586561203003
[15/24] Train loss=0.37045130133628845
[20/24] Train loss=0.3237314820289612
Test set avg_accuracy=82.51% avg_sensitivity=45.40%, avg_specificity=96.57% avg_auc=90.35%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.345043 Test loss=0.363323 Current lr=[0.000299720220882401]

[0/24] Train loss=0.32375407218933105
[5/24] Train loss=0.3478451073169708
[10/24] Train loss=0.39064541459083557
[15/24] Train loss=0.36871206760406494
[20/24] Train loss=0.3241179287433624
Test set avg_accuracy=82.62% avg_sensitivity=46.45%, avg_specificity=96.32% avg_auc=90.44%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.343784 Test loss=0.360952 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.32196244597435
[5/24] Train loss=0.34606489539146423
[10/24] Train loss=0.3884323835372925
[15/24] Train loss=0.36877310276031494
[20/24] Train loss=0.323087602853775
Test set avg_accuracy=82.76% avg_sensitivity=47.20%, avg_specificity=96.23% avg_auc=90.44%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.344396 Test loss=0.358986 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3190065324306488
[5/24] Train loss=0.3480525612831116
[10/24] Train loss=0.3870641887187958
[15/24] Train loss=0.37806370854377747
[20/24] Train loss=0.3253229260444641
Test set avg_accuracy=82.73% avg_sensitivity=47.77%, avg_specificity=95.98% avg_auc=90.46%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.344625 Test loss=0.358294 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3185286223888397
[5/24] Train loss=0.34520673751831055
[10/24] Train loss=0.38760027289390564
[15/24] Train loss=0.36786308884620667
[20/24] Train loss=0.3252861499786377
Test set avg_accuracy=82.62% avg_sensitivity=46.87%, avg_specificity=96.16% avg_auc=90.47%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.342551 Test loss=0.359877 Current lr=[0.000297555943323901]

[0/24] Train loss=0.318848192691803
[5/24] Train loss=0.34566083550453186
[10/24] Train loss=0.38698962330818176
[15/24] Train loss=0.3764268159866333
[20/24] Train loss=0.32296594977378845
Test set avg_accuracy=82.75% avg_sensitivity=45.92%, avg_specificity=96.70% avg_auc=90.43%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.342963 Test loss=0.361284 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.31867507100105286
[5/24] Train loss=0.3445338010787964
[10/24] Train loss=0.39011654257774353
[15/24] Train loss=0.3730506896972656
[20/24] Train loss=0.31903350353240967
Test set avg_accuracy=82.99% avg_sensitivity=47.30%, avg_specificity=96.52% avg_auc=90.47%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.342838 Test loss=0.359258 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.31981176137924194
[5/24] Train loss=0.3484090268611908
[10/24] Train loss=0.38811513781547546
[15/24] Train loss=0.37136417627334595
[20/24] Train loss=0.31903669238090515
Test set avg_accuracy=82.40% avg_sensitivity=44.45%, avg_specificity=96.77% avg_auc=90.43%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.341937 Test loss=0.362948 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.32088229060173035
[5/24] Train loss=0.34822899103164673
[10/24] Train loss=0.3833156228065491
[15/24] Train loss=0.36902952194213867
[20/24] Train loss=0.31628483533859253
Test set avg_accuracy=83.20% avg_sensitivity=49.29%, avg_specificity=96.05% avg_auc=90.60%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.340678 Test loss=0.355289 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3156838119029999
[5/24] Train loss=0.3471129238605499
[10/24] Train loss=0.3901591897010803
[15/24] Train loss=0.3676788806915283
[20/24] Train loss=0.3177344501018524
Test set avg_accuracy=83.18% avg_sensitivity=47.77%, avg_specificity=96.59% avg_auc=90.55%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.340529 Test loss=0.357775 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3183406889438629
[5/24] Train loss=0.34342506527900696
[10/24] Train loss=0.38803479075431824
[15/24] Train loss=0.36568713188171387
[20/24] Train loss=0.3168793022632599
Test set avg_accuracy=82.71% avg_sensitivity=45.73%, avg_specificity=96.71% avg_auc=90.59%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.339494 Test loss=0.360141 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3160102665424347
[5/24] Train loss=0.34420400857925415
[10/24] Train loss=0.38804134726524353
[15/24] Train loss=0.3663695156574249
[20/24] Train loss=0.31412118673324585
Test set avg_accuracy=83.39% avg_sensitivity=49.38%, avg_specificity=96.27% avg_auc=90.51%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.338554 Test loss=0.355567 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.31166064739227295
[5/24] Train loss=0.3450224697589874
[10/24] Train loss=0.3827507197856903
[15/24] Train loss=0.38039278984069824
[20/24] Train loss=0.31796005368232727
Test set avg_accuracy=83.24% avg_sensitivity=48.63%, avg_specificity=96.36% avg_auc=90.60%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.338663 Test loss=0.355682 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.31186535954475403
[5/24] Train loss=0.3448030650615692
[10/24] Train loss=0.3876782953739166
[15/24] Train loss=0.3649768531322479
[20/24] Train loss=0.31204596161842346
Test set avg_accuracy=83.49% avg_sensitivity=49.72%, avg_specificity=96.28% avg_auc=90.52%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.338159 Test loss=0.354933 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3159317672252655
[5/24] Train loss=0.34605759382247925
[10/24] Train loss=0.38530054688453674
[15/24] Train loss=0.36497893929481506
[20/24] Train loss=0.313894659280777
Test set avg_accuracy=83.09% avg_sensitivity=47.49%, avg_specificity=96.57% avg_auc=90.58%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.337691 Test loss=0.357374 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3159538805484772
[5/24] Train loss=0.3417239785194397
[10/24] Train loss=0.3834981620311737
[15/24] Train loss=0.3626432716846466
[20/24] Train loss=0.3129945397377014
Test set avg_accuracy=83.45% avg_sensitivity=49.34%, avg_specificity=96.37% avg_auc=90.66%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.336774 Test loss=0.354195 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.313032865524292
[5/24] Train loss=0.34189632534980774
[10/24] Train loss=0.3839341700077057
[15/24] Train loss=0.36486101150512695
[20/24] Train loss=0.3118895888328552
Test set avg_accuracy=83.49% avg_sensitivity=49.57%, avg_specificity=96.34% avg_auc=90.66%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.335445 Test loss=0.354394 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.31401151418685913
[5/24] Train loss=0.33755889534950256
[10/24] Train loss=0.3828422725200653
[15/24] Train loss=0.36099720001220703
[20/24] Train loss=0.3062635660171509
Test set avg_accuracy=83.07% avg_sensitivity=47.49%, avg_specificity=96.55% avg_auc=90.72%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.335457 Test loss=0.356266 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3129240870475769
[5/24] Train loss=0.339511901140213
[10/24] Train loss=0.3852188289165497
[15/24] Train loss=0.36276280879974365
[20/24] Train loss=0.30807578563690186
Test set avg_accuracy=83.09% avg_sensitivity=47.11%, avg_specificity=96.71% avg_auc=90.63%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.334644 Test loss=0.357538 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.31199946999549866
[5/24] Train loss=0.33785659074783325
[10/24] Train loss=0.38773322105407715
[15/24] Train loss=0.36570173501968384
[20/24] Train loss=0.3104550540447235
Test set avg_accuracy=83.44% avg_sensitivity=49.15%, avg_specificity=96.43% avg_auc=90.71%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.334863 Test loss=0.353323 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.31074264645576477
[5/24] Train loss=0.34010761976242065
[10/24] Train loss=0.3852090835571289
[15/24] Train loss=0.34980371594429016
[20/24] Train loss=0.30509865283966064
Test set avg_accuracy=83.09% avg_sensitivity=47.44%, avg_specificity=96.59% avg_auc=90.76%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.333558 Test loss=0.356222 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.31232884526252747
[5/24] Train loss=0.34423816204071045
[10/24] Train loss=0.3831179440021515
[15/24] Train loss=0.3638022840023041
[20/24] Train loss=0.3073756694793701
Test set avg_accuracy=83.18% avg_sensitivity=48.15%, avg_specificity=96.45% avg_auc=90.63%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.333832 Test loss=0.354992 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.31073179841041565
[5/24] Train loss=0.338602215051651
[10/24] Train loss=0.38617101311683655
[15/24] Train loss=0.35543209314346313
[20/24] Train loss=0.3091756999492645
Test set avg_accuracy=83.22% avg_sensitivity=48.20%, avg_specificity=96.48% avg_auc=90.81%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.332303 Test loss=0.352847 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.31266722083091736
[5/24] Train loss=0.34023916721343994
[10/24] Train loss=0.3807350993156433
[15/24] Train loss=0.3603196442127228
[20/24] Train loss=0.30236345529556274
Test set avg_accuracy=83.28% avg_sensitivity=48.06%, avg_specificity=96.62% avg_auc=90.78%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.331584 Test loss=0.353411 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3074243664741516
[5/24] Train loss=0.3408481180667877
[10/24] Train loss=0.3837486505508423
[15/24] Train loss=0.3502661883831024
[20/24] Train loss=0.30094975233078003
Test set avg_accuracy=83.78% avg_sensitivity=50.71%, avg_specificity=96.30% avg_auc=90.82%
Best model saved!! Metric=-4.389762786778064!!
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.331586 Test loss=0.350182 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3084850609302521
[5/24] Train loss=0.33612537384033203
[10/24] Train loss=0.3793814182281494
[15/24] Train loss=0.3581559658050537
[20/24] Train loss=0.3013308346271515
Test set avg_accuracy=83.20% avg_sensitivity=47.91%, avg_specificity=96.57% avg_auc=90.90%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.330999 Test loss=0.351917 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.30631905794143677
[5/24] Train loss=0.3381911814212799
[10/24] Train loss=0.386165589094162
[15/24] Train loss=0.35811832547187805
[20/24] Train loss=0.3014051020145416
Test set avg_accuracy=83.01% avg_sensitivity=47.20%, avg_specificity=96.57% avg_auc=90.90%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.332374 Test loss=0.352950 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3080138564109802
[5/24] Train loss=0.34348803758621216
[10/24] Train loss=0.38202813267707825
[15/24] Train loss=0.3551948070526123
[20/24] Train loss=0.30410999059677124
Test set avg_accuracy=83.27% avg_sensitivity=48.44%, avg_specificity=96.46% avg_auc=90.86%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.331153 Test loss=0.351311 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.30586695671081543
[5/24] Train loss=0.3394962549209595
[10/24] Train loss=0.38535240292549133
[15/24] Train loss=0.3496638238430023
[20/24] Train loss=0.30181431770324707
Test set avg_accuracy=83.63% avg_sensitivity=49.57%, avg_specificity=96.54% avg_auc=90.83%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.330201 Test loss=0.350971 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3141435980796814
[5/24] Train loss=0.3386872410774231
[10/24] Train loss=0.3821922540664673
[15/24] Train loss=0.3551403284072876
[20/24] Train loss=0.2990886867046356
Test set avg_accuracy=83.37% avg_sensitivity=48.53%, avg_specificity=96.57% avg_auc=90.99%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.329452 Test loss=0.348792 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.30912911891937256
[5/24] Train loss=0.33308547735214233
[10/24] Train loss=0.3844398558139801
[15/24] Train loss=0.34302976727485657
[20/24] Train loss=0.3042578399181366
Test set avg_accuracy=83.57% avg_sensitivity=49.10%, avg_specificity=96.62% avg_auc=90.88%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.329876 Test loss=0.350850 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3047846257686615
[5/24] Train loss=0.33135879039764404
[10/24] Train loss=0.3817717432975769
[15/24] Train loss=0.34808242321014404
[20/24] Train loss=0.29724422097206116
Test set avg_accuracy=83.98% avg_sensitivity=51.33%, avg_specificity=96.36% avg_auc=90.89%
Best model saved!! Metric=-3.4388383892637364!!
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.328440 Test loss=0.347398 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.29943278431892395
[5/24] Train loss=0.33068856596946716
[10/24] Train loss=0.3875410258769989
[15/24] Train loss=0.3424434959888458
[20/24] Train loss=0.30129843950271606
Test set avg_accuracy=83.92% avg_sensitivity=52.04%, avg_specificity=96.00% avg_auc=90.94%
Best model saved!! Metric=-3.1079144092066713!!
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.329101 Test loss=0.345380 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.30665305256843567
[5/24] Train loss=0.33480507135391235
[10/24] Train loss=0.3850034177303314
[15/24] Train loss=0.353040486574173
[20/24] Train loss=0.30106300115585327
Test set avg_accuracy=84.31% avg_sensitivity=54.55%, avg_specificity=95.58% avg_auc=91.04%
Best model saved!! Metric=-0.5160760709950338!!
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.329443 Test loss=0.341997 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3022926449775696
[5/24] Train loss=0.33663395047187805
[10/24] Train loss=0.3861299157142639
[15/24] Train loss=0.36192449927330017
[20/24] Train loss=0.3016863167285919
Test set avg_accuracy=84.51% avg_sensitivity=55.45%, avg_specificity=95.51% avg_auc=90.98%
Best model saved!! Metric=0.44763007472042915!!
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.328676 Test loss=0.341299 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3042507469654083
[5/24] Train loss=0.33053475618362427
[10/24] Train loss=0.3825755715370178
[15/24] Train loss=0.3567541837692261
[20/24] Train loss=0.299096018075943
Test set avg_accuracy=84.43% avg_sensitivity=54.93%, avg_specificity=95.60% avg_auc=91.02%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.327469 Test loss=0.341459 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3061569035053253
[5/24] Train loss=0.3359931409358978
[10/24] Train loss=0.3841931223869324
[15/24] Train loss=0.3579554557800293
[20/24] Train loss=0.3010266423225403
Test set avg_accuracy=84.52% avg_sensitivity=55.78%, avg_specificity=95.40% avg_auc=91.02%
Best model saved!! Metric=0.7264962031774331!!
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.328345 Test loss=0.340961 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.30623510479927063
[5/24] Train loss=0.3346601724624634
[10/24] Train loss=0.3838537037372589
[15/24] Train loss=0.3575693964958191
[20/24] Train loss=0.2958638370037079
Test set avg_accuracy=84.57% avg_sensitivity=55.78%, avg_specificity=95.48% avg_auc=91.00%
Best model saved!! Metric=0.8294869875645645!!
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.327950 Test loss=0.340735 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3048846125602722
[5/24] Train loss=0.3316889703273773
[10/24] Train loss=0.37882864475250244
[15/24] Train loss=0.3539252281188965
[20/24] Train loss=0.29739412665367126
Test set avg_accuracy=84.14% avg_sensitivity=52.65%, avg_specificity=96.07% avg_auc=90.99%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.326637 Test loss=0.344023 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.30430296063423157
[5/24] Train loss=0.3325548470020294
[10/24] Train loss=0.3822826147079468
[15/24] Train loss=0.35141146183013916
[20/24] Train loss=0.2979029417037964
Test set avg_accuracy=84.43% avg_sensitivity=54.03%, avg_specificity=95.94% avg_auc=90.92%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.326976 Test loss=0.343094 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.30400046706199646
[5/24] Train loss=0.33384203910827637
[10/24] Train loss=0.38502269983291626
[15/24] Train loss=0.36037924885749817
[20/24] Train loss=0.29506799578666687
Test set avg_accuracy=84.35% avg_sensitivity=52.94%, avg_specificity=96.25% avg_auc=90.95%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.327350 Test loss=0.344581 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3013286888599396
[5/24] Train loss=0.3351617753505707
[10/24] Train loss=0.38317814469337463
[15/24] Train loss=0.3502148687839508
[20/24] Train loss=0.29259350895881653
Test set avg_accuracy=84.27% avg_sensitivity=52.27%, avg_specificity=96.39% avg_auc=90.95%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.326460 Test loss=0.344817 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.3029257655143738
[5/24] Train loss=0.3349442481994629
[10/24] Train loss=0.3820967674255371
[15/24] Train loss=0.34866103529930115
[20/24] Train loss=0.29513269662857056
Test set avg_accuracy=84.24% avg_sensitivity=52.23%, avg_specificity=96.37% avg_auc=90.87%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.326108 Test loss=0.345568 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3038700222969055
[5/24] Train loss=0.32543057203292847
[10/24] Train loss=0.3792037069797516
[15/24] Train loss=0.34337785840034485
[20/24] Train loss=0.29326122999191284
Test set avg_accuracy=84.14% avg_sensitivity=52.89%, avg_specificity=95.98% avg_auc=90.88%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.324259 Test loss=0.343893 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.30330073833465576
[5/24] Train loss=0.3292462229728699
[10/24] Train loss=0.3783043920993805
[15/24] Train loss=0.34582704305648804
[20/24] Train loss=0.2944180369377136
Test set avg_accuracy=83.83% avg_sensitivity=50.33%, avg_specificity=96.52% avg_auc=90.76%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.325741 Test loss=0.349105 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3042502999305725
[5/24] Train loss=0.3373524844646454
[10/24] Train loss=0.3812059164047241
[15/24] Train loss=0.3477579355239868
[20/24] Train loss=0.2934707999229431
Test set avg_accuracy=84.24% avg_sensitivity=51.90%, avg_specificity=96.50% avg_auc=90.72%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.327337 Test loss=0.347766 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3060990869998932
[5/24] Train loss=0.33323025703430176
[10/24] Train loss=0.3804551362991333
[15/24] Train loss=0.3343169093132019
[20/24] Train loss=0.2965271770954132
Test set avg_accuracy=84.28% avg_sensitivity=54.55%, avg_specificity=95.55% avg_auc=90.89%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.326622 Test loss=0.342524 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.30469709634780884
[5/24] Train loss=0.3334449827671051
[10/24] Train loss=0.38607779145240784
[15/24] Train loss=0.33161428570747375
[20/24] Train loss=0.29435673356056213
Test set avg_accuracy=85.35% avg_sensitivity=61.14%, avg_specificity=94.52% avg_auc=90.98%
Best model saved!! Metric=5.993500097318076!!
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.327622 Test loss=0.336864 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.30823275446891785
[5/24] Train loss=0.3318910002708435
[10/24] Train loss=0.38369065523147583
[15/24] Train loss=0.32926565408706665
[20/24] Train loss=0.29732948541641235
Test set avg_accuracy=85.13% avg_sensitivity=65.73%, avg_specificity=92.48% avg_auc=90.95%
Best model saved!! Metric=8.291426606581169!!
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.327482 Test loss=0.336114 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.30531075596809387
[5/24] Train loss=0.3304125666618347
[10/24] Train loss=0.37942948937416077
[15/24] Train loss=0.3295331299304962
[20/24] Train loss=0.3007892370223999
Test set avg_accuracy=85.21% avg_sensitivity=65.26%, avg_specificity=92.76% avg_auc=90.99%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.326124 Test loss=0.335394 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3074559271335602
[5/24] Train loss=0.33193179965019226
[10/24] Train loss=0.38422656059265137
[15/24] Train loss=0.3336850106716156
[20/24] Train loss=0.2992471754550934
Test set avg_accuracy=85.18% avg_sensitivity=63.84%, avg_specificity=93.27% avg_auc=90.97%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.325500 Test loss=0.335836 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.30669939517974854
[5/24] Train loss=0.3278563916683197
[10/24] Train loss=0.38075119256973267
[15/24] Train loss=0.3307793140411377
[20/24] Train loss=0.29810208082199097
Test set avg_accuracy=85.51% avg_sensitivity=63.32%, avg_specificity=93.91% avg_auc=90.98%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.324072 Test loss=0.335402 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3051113188266754
[5/24] Train loss=0.3347453474998474
[10/24] Train loss=0.37716230750083923
[15/24] Train loss=0.3342582583427429
[20/24] Train loss=0.29403623938560486
Test set avg_accuracy=85.20% avg_sensitivity=63.93%, avg_specificity=93.25% avg_auc=90.98%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.324594 Test loss=0.335745 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.30548781156539917
[5/24] Train loss=0.33247363567352295
[10/24] Train loss=0.38435468077659607
[15/24] Train loss=0.33072739839553833
[20/24] Train loss=0.29572349786758423
Test set avg_accuracy=85.13% avg_sensitivity=63.46%, avg_specificity=93.34% avg_auc=90.99%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.323842 Test loss=0.335416 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3038308620452881
[5/24] Train loss=0.32769015431404114
[10/24] Train loss=0.3776470422744751
[15/24] Train loss=0.3316008150577545
[20/24] Train loss=0.29848170280456543
Test set avg_accuracy=85.03% avg_sensitivity=62.75%, avg_specificity=93.46% avg_auc=90.97%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.323266 Test loss=0.336055 Current lr=[0.000134135431043539]

[0/24] Train loss=0.30364954471588135
[5/24] Train loss=0.33300596475601196
[10/24] Train loss=0.3795672357082367
[15/24] Train loss=0.3309171199798584
[20/24] Train loss=0.2933241128921509
Test set avg_accuracy=85.40% avg_sensitivity=63.18%, avg_specificity=93.82% avg_auc=91.03%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.323883 Test loss=0.334503 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3015182614326477
[5/24] Train loss=0.3332396447658539
[10/24] Train loss=0.382631778717041
[15/24] Train loss=0.33914700150489807
[20/24] Train loss=0.2972920835018158
Test set avg_accuracy=85.16% avg_sensitivity=63.18%, avg_specificity=93.48% avg_auc=91.02%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.323316 Test loss=0.334872 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.30286651849746704
[5/24] Train loss=0.3304935097694397
[10/24] Train loss=0.38054049015045166
[15/24] Train loss=0.33393988013267517
[20/24] Train loss=0.2923828363418579
Test set avg_accuracy=85.35% avg_sensitivity=62.94%, avg_specificity=93.84% avg_auc=91.02%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.323673 Test loss=0.334600 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.30433952808380127
[5/24] Train loss=0.3315943479537964
[10/24] Train loss=0.38566693663597107
[15/24] Train loss=0.336654931306839
[20/24] Train loss=0.29194244742393494
Test set avg_accuracy=84.78% avg_sensitivity=62.46%, avg_specificity=93.23% avg_auc=90.95%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.322940 Test loss=0.335532 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3001388609409332
[5/24] Train loss=0.3332868814468384
[10/24] Train loss=0.382017582654953
[15/24] Train loss=0.34094685316085815
[20/24] Train loss=0.29493722319602966
Test set avg_accuracy=85.01% avg_sensitivity=64.36%, avg_specificity=92.84% avg_auc=90.88%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.324887 Test loss=0.336646 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3035389184951782
[5/24] Train loss=0.3332708179950714
[10/24] Train loss=0.38390886783599854
[15/24] Train loss=0.3433448374271393
[20/24] Train loss=0.2909359633922577
Test set avg_accuracy=85.07% avg_sensitivity=64.45%, avg_specificity=92.87% avg_auc=90.99%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.323455 Test loss=0.334820 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3029034435749054
[5/24] Train loss=0.33775749802589417
[10/24] Train loss=0.3894515037536621
[15/24] Train loss=0.3467191159725189
[20/24] Train loss=0.2914144694805145
Test set avg_accuracy=85.39% avg_sensitivity=66.49%, avg_specificity=92.55% avg_auc=91.03%
Best model saved!! Metric=9.459787830668688!!
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.324038 Test loss=0.334797 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.30489036440849304
[5/24] Train loss=0.34100282192230225
[10/24] Train loss=0.3924916982650757
[15/24] Train loss=0.34380272030830383
[20/24] Train loss=0.29175129532814026
Test set avg_accuracy=84.92% avg_sensitivity=69.10%, avg_specificity=90.92% avg_auc=90.90%
Best model saved!! Metric=9.835996861359533!!
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.325684 Test loss=0.339820 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3140682876110077
[5/24] Train loss=0.35425814986228943
[10/24] Train loss=0.393647164106369
[15/24] Train loss=0.3358212113380432
[20/24] Train loss=0.3031489849090576
Test set avg_accuracy=85.49% avg_sensitivity=74.36%, avg_specificity=89.71% avg_auc=90.78%
Best model saved!! Metric=14.344170958233718!!
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.329493 Test loss=0.347256 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.32683050632476807
[5/24] Train loss=0.34650900959968567
[10/24] Train loss=0.3847799003124237
[15/24] Train loss=0.3276108503341675
[20/24] Train loss=0.31724265217781067
Test set avg_accuracy=85.43% avg_sensitivity=66.45%, avg_specificity=92.62% avg_auc=91.03%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.330007 Test loss=0.334938 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.30748260021209717
[5/24] Train loss=0.3338533341884613
[10/24] Train loss=0.38598883152008057
[15/24] Train loss=0.32553791999816895
[20/24] Train loss=0.3057228922843933
Test set avg_accuracy=85.30% avg_sensitivity=63.93%, avg_specificity=93.39% avg_auc=91.05%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.323322 Test loss=0.334390 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.30117473006248474
[5/24] Train loss=0.330676794052124
[10/24] Train loss=0.3846268653869629
[15/24] Train loss=0.3272281885147095
[20/24] Train loss=0.30827972292900085
Test set avg_accuracy=85.21% avg_sensitivity=65.36%, avg_specificity=92.73% avg_auc=91.06%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.322545 Test loss=0.334844 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3050462603569031
[5/24] Train loss=0.3323865532875061
[10/24] Train loss=0.3835007846355438
[15/24] Train loss=0.32876381278038025
[20/24] Train loss=0.3059479594230652
Test set avg_accuracy=85.47% avg_sensitivity=65.21%, avg_specificity=93.14% avg_auc=91.09%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.322871 Test loss=0.333654 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3050180673599243
[5/24] Train loss=0.33462563157081604
[10/24] Train loss=0.3859633207321167
[15/24] Train loss=0.3259750306606293
[20/24] Train loss=0.3009624779224396
Test set avg_accuracy=85.23% avg_sensitivity=64.41%, avg_specificity=93.12% avg_auc=91.08%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.322048 Test loss=0.334191 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3036268353462219
[5/24] Train loss=0.33623969554901123
[10/24] Train loss=0.378481388092041
[15/24] Train loss=0.3246486783027649
[20/24] Train loss=0.3034191429615021
Test set avg_accuracy=85.03% avg_sensitivity=64.36%, avg_specificity=92.85% avg_auc=91.01%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.321902 Test loss=0.334797 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3015229403972626
[5/24] Train loss=0.3369230031967163
[10/24] Train loss=0.3887576162815094
[15/24] Train loss=0.3272485136985779
[20/24] Train loss=0.29927292466163635
Test set avg_accuracy=85.21% avg_sensitivity=65.59%, avg_specificity=92.64% avg_auc=90.84%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.323090 Test loss=0.337551 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.311191588640213
[5/24] Train loss=0.3378041088581085
[10/24] Train loss=0.38414573669433594
[15/24] Train loss=0.324202299118042
[20/24] Train loss=0.299240380525589
Test set avg_accuracy=84.86% avg_sensitivity=63.93%, avg_specificity=92.78% avg_auc=90.64%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.323510 Test loss=0.340194 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.31162089109420776
[5/24] Train loss=0.3357999622821808
[10/24] Train loss=0.38009244203567505
[15/24] Train loss=0.3241417706012726
[20/24] Train loss=0.3008272349834442
Test set avg_accuracy=85.00% avg_sensitivity=64.41%, avg_specificity=92.80% avg_auc=90.89%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.322518 Test loss=0.336471 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.30714863538742065
[5/24] Train loss=0.32903867959976196
[10/24] Train loss=0.37958407402038574
[15/24] Train loss=0.32683196663856506
[20/24] Train loss=0.2970832288265228
Test set avg_accuracy=85.31% avg_sensitivity=62.04%, avg_specificity=94.13% avg_auc=91.06%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.321576 Test loss=0.334402 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.30291947722435
[5/24] Train loss=0.32746076583862305
[10/24] Train loss=0.38648244738578796
[15/24] Train loss=0.319252610206604
[20/24] Train loss=0.303333580493927
Test set avg_accuracy=85.33% avg_sensitivity=61.61%, avg_specificity=94.31% avg_auc=91.10%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.320192 Test loss=0.334095 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.2991665005683899
[5/24] Train loss=0.32914793491363525
[10/24] Train loss=0.37759721279144287
[15/24] Train loss=0.32151347398757935
[20/24] Train loss=0.3026096522808075
Test set avg_accuracy=85.23% avg_sensitivity=61.66%, avg_specificity=94.17% avg_auc=91.07%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.319403 Test loss=0.334278 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3001515865325928
[5/24] Train loss=0.32801926136016846
[10/24] Train loss=0.37778159976005554
[15/24] Train loss=0.3239246904850006
[20/24] Train loss=0.2994190454483032
Test set avg_accuracy=85.29% avg_sensitivity=61.52%, avg_specificity=94.29% avg_auc=91.10%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.319525 Test loss=0.334055 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3000698387622833
[5/24] Train loss=0.32431572675704956
[10/24] Train loss=0.3806457817554474
[15/24] Train loss=0.3218403458595276
[20/24] Train loss=0.29819387197494507
Test set avg_accuracy=85.43% avg_sensitivity=61.80%, avg_specificity=94.38% avg_auc=91.13%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.318706 Test loss=0.333551 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.29781201481819153
[5/24] Train loss=0.33059579133987427
[10/24] Train loss=0.37754321098327637
[15/24] Train loss=0.3208553194999695
[20/24] Train loss=0.297957181930542
Test set avg_accuracy=85.20% avg_sensitivity=61.14%, avg_specificity=94.31% avg_auc=91.14%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.319350 Test loss=0.333767 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.2953944504261017
[5/24] Train loss=0.3253423273563385
[10/24] Train loss=0.376552015542984
[15/24] Train loss=0.327908992767334
[20/24] Train loss=0.29579126834869385
Test set avg_accuracy=85.27% avg_sensitivity=61.33%, avg_specificity=94.34% avg_auc=91.16%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.318230 Test loss=0.333410 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3018617033958435
[5/24] Train loss=0.321509450674057
[10/24] Train loss=0.37649938464164734
[15/24] Train loss=0.31874987483024597
[20/24] Train loss=0.29568663239479065
Test set avg_accuracy=85.20% avg_sensitivity=60.85%, avg_specificity=94.42% avg_auc=91.16%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.318496 Test loss=0.333425 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.29906612634658813
[5/24] Train loss=0.32805556058883667
[10/24] Train loss=0.3785977065563202
[15/24] Train loss=0.318742960691452
[20/24] Train loss=0.29142820835113525
Test set avg_accuracy=85.05% avg_sensitivity=60.24%, avg_specificity=94.45% avg_auc=91.15%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.317852 Test loss=0.333716 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.29904815554618835
[5/24] Train loss=0.3259527385234833
[10/24] Train loss=0.3750883638858795
[15/24] Train loss=0.321100652217865
[20/24] Train loss=0.2922208905220032
Test set avg_accuracy=85.17% avg_sensitivity=60.81%, avg_specificity=94.40% avg_auc=91.16%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.317788 Test loss=0.333426 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.2974761426448822
[5/24] Train loss=0.327972412109375
[10/24] Train loss=0.3802975118160248
[15/24] Train loss=0.3205728828907013
[20/24] Train loss=0.29166150093078613
Test set avg_accuracy=85.17% avg_sensitivity=60.81%, avg_specificity=94.40% avg_auc=91.16%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.318009 Test loss=0.333344 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.2994956076145172
[5/24] Train loss=0.3272528648376465
[10/24] Train loss=0.3733694553375244
[15/24] Train loss=0.32406237721443176
[20/24] Train loss=0.2911762595176697
Test set avg_accuracy=85.44% avg_sensitivity=62.80%, avg_specificity=94.02% avg_auc=91.17%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.317576 Test loss=0.332654 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.2998998165130615
[5/24] Train loss=0.32606881856918335
[10/24] Train loss=0.37919414043426514
[15/24] Train loss=0.32087206840515137
[20/24] Train loss=0.2907029092311859
Test set avg_accuracy=85.18% avg_sensitivity=63.74%, avg_specificity=93.30% avg_auc=91.15%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.317565 Test loss=0.332320 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3053068518638611
[5/24] Train loss=0.32595840096473694
[10/24] Train loss=0.3801352381706238
[15/24] Train loss=0.3226011097431183
[20/24] Train loss=0.29131826758384705
Test set avg_accuracy=85.10% avg_sensitivity=64.03%, avg_specificity=93.09% avg_auc=91.15%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.317576 Test loss=0.332293 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.2996143400669098
[5/24] Train loss=0.3240048289299011
[10/24] Train loss=0.3775752782821655
[15/24] Train loss=0.3226209282875061
[20/24] Train loss=0.2915962338447571
Test set avg_accuracy=85.07% avg_sensitivity=64.31%, avg_specificity=92.93% avg_auc=91.14%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.317695 Test loss=0.332518 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.3016541302204132
[5/24] Train loss=0.3233289122581482
[10/24] Train loss=0.38046979904174805
[15/24] Train loss=0.3223600685596466
[20/24] Train loss=0.2954001724720001
Test set avg_accuracy=84.80% avg_sensitivity=62.65%, avg_specificity=93.20% avg_auc=91.12%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.317645 Test loss=0.332817 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.30224737524986267
[5/24] Train loss=0.3248349130153656
[10/24] Train loss=0.3747900426387787
[15/24] Train loss=0.3256097435951233
[20/24] Train loss=0.2915947139263153
Test set avg_accuracy=84.86% avg_sensitivity=62.04%, avg_specificity=93.50% avg_auc=91.12%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.316940 Test loss=0.333005 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.2976807951927185
[5/24] Train loss=0.32619747519493103
[10/24] Train loss=0.37728166580200195
[15/24] Train loss=0.32351917028427124
[20/24] Train loss=0.29021328687667847
Test set avg_accuracy=85.18% avg_sensitivity=61.80%, avg_specificity=94.04% avg_auc=91.15%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.316935 Test loss=0.332719 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.2987155616283417
[5/24] Train loss=0.3228219449520111
[10/24] Train loss=0.3806256055831909
[15/24] Train loss=0.3299417793750763
[20/24] Train loss=0.29700323939323425
Test set avg_accuracy=85.22% avg_sensitivity=61.90%, avg_specificity=94.06% avg_auc=91.17%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.316360 Test loss=0.332503 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.30023062229156494
[5/24] Train loss=0.3227073550224304
[10/24] Train loss=0.3782503306865692
[15/24] Train loss=0.32442498207092285
[20/24] Train loss=0.2922537624835968
Test set avg_accuracy=85.13% avg_sensitivity=61.37%, avg_specificity=94.13% avg_auc=91.17%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.317093 Test loss=0.332660 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.2971014678478241
[5/24] Train loss=0.3223765790462494
[10/24] Train loss=0.3765672445297241
[15/24] Train loss=0.32281139492988586
[20/24] Train loss=0.2878643274307251
Test set avg_accuracy=85.22% avg_sensitivity=61.37%, avg_specificity=94.25% avg_auc=91.17%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.316342 Test loss=0.332650 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.2993219494819641
[5/24] Train loss=0.32265323400497437
[10/24] Train loss=0.3746112883090973
[15/24] Train loss=0.321821928024292
[20/24] Train loss=0.2930215001106262
Test set avg_accuracy=85.25% avg_sensitivity=61.56%, avg_specificity=94.22% avg_auc=91.18%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.316289 Test loss=0.332518 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.2999928295612335
[5/24] Train loss=0.31998732686042786
[10/24] Train loss=0.3775103986263275
[15/24] Train loss=0.32084348797798157
[20/24] Train loss=0.290419340133667
Test set avg_accuracy=85.21% avg_sensitivity=61.28%, avg_specificity=94.27% avg_auc=91.18%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.316512 Test loss=0.332686 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.2988644540309906
[5/24] Train loss=0.324314147233963
[10/24] Train loss=0.3757689893245697
[15/24] Train loss=0.3246757984161377
[20/24] Train loss=0.2911970317363739
Test set avg_accuracy=85.20% avg_sensitivity=61.18%, avg_specificity=94.29% avg_auc=91.18%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.316409 Test loss=0.332728 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.2969549894332886
[5/24] Train loss=0.3203498423099518
[10/24] Train loss=0.37546291947364807
[15/24] Train loss=0.3234190344810486
[20/24] Train loss=0.2900141477584839
Test set avg_accuracy=85.14% avg_sensitivity=61.18%, avg_specificity=94.22% avg_auc=91.18%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.316323 Test loss=0.332651 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.29849448800086975
[5/24] Train loss=0.32281842827796936
[10/24] Train loss=0.38326212763786316
[15/24] Train loss=0.31999486684799194
[20/24] Train loss=0.2928479015827179
Test set avg_accuracy=85.18% avg_sensitivity=61.14%, avg_specificity=94.29% avg_auc=91.18%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.316192 Test loss=0.332700 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.29989850521087646
[5/24] Train loss=0.32329899072647095
[10/24] Train loss=0.3771679103374481
[15/24] Train loss=0.3266962170600891
[20/24] Train loss=0.29217326641082764
Test set avg_accuracy=85.21% avg_sensitivity=61.14%, avg_specificity=94.33% avg_auc=91.19%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.316504 Test loss=0.332723 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.29752153158187866
[5/24] Train loss=0.32051989436149597
[10/24] Train loss=0.37455737590789795
[15/24] Train loss=0.3246050179004669
[20/24] Train loss=0.29463133215904236
Test set avg_accuracy=85.22% avg_sensitivity=61.14%, avg_specificity=94.34% avg_auc=91.19%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.316234 Test loss=0.332700 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.2938578128814697
[5/24] Train loss=0.3261221647262573
[10/24] Train loss=0.3780016005039215
[15/24] Train loss=0.32410722970962524
[20/24] Train loss=0.2928391396999359
Test set avg_accuracy=85.20% avg_sensitivity=61.04%, avg_specificity=94.34% avg_auc=91.19%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.316231 Test loss=0.332716 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.30032071471214294
[5/24] Train loss=0.325481116771698
[10/24] Train loss=0.38048461079597473
[15/24] Train loss=0.320164293050766
[20/24] Train loss=0.293312132358551
Test set avg_accuracy=85.20% avg_sensitivity=61.04%, avg_specificity=94.34% avg_auc=91.19%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.317073 Test loss=0.332724 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.2950512170791626
[5/24] Train loss=0.32578256726264954
[10/24] Train loss=0.37684938311576843
[15/24] Train loss=0.3194396197795868
[20/24] Train loss=0.29171547293663025
Test set avg_accuracy=85.17% avg_sensitivity=60.95%, avg_specificity=94.34% avg_auc=91.19%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.315838 Test loss=0.332726 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=85.49% sen=74.36%, spe=89.71%, auc=90.78%!
Fold[3] Avg_overlap=0.64%(0.23968236721220518)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'HybridCNNRNN',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.8871643543243408
[5/24] Train loss=0.7671882510185242
[10/24] Train loss=0.7212221026420593
[15/24] Train loss=0.6703721880912781
[20/24] Train loss=0.6452993154525757
Test set avg_accuracy=73.95% avg_sensitivity=0.10%, avg_specificity=99.96% avg_auc=51.89%
Best model saved!! Metric=-100.10158322804723!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.713896 Test loss=0.600143 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6340834498405457
[5/24] Train loss=0.609791100025177
[10/24] Train loss=0.6305580735206604
[15/24] Train loss=0.614464521408081
[20/24] Train loss=0.6102402210235596
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=55.01%
Best model saved!! Metric=-97.0399603152564!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.610505 Test loss=0.573808 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.5994719862937927
[5/24] Train loss=0.5755893588066101
[10/24] Train loss=0.6173587441444397
[15/24] Train loss=0.608848512172699
[20/24] Train loss=0.597273588180542
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=58.32%
Best model saved!! Metric=-93.73033673296408!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.593593 Test loss=0.568252 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.5961452722549438
[5/24] Train loss=0.5689456462860107
[10/24] Train loss=0.6168428063392639
[15/24] Train loss=0.602481484413147
[20/24] Train loss=0.596592366695404
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=60.56%
Best model saved!! Metric=-91.49001033866871!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.589140 Test loss=0.564940 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5934147238731384
[5/24] Train loss=0.5662988424301147
[10/24] Train loss=0.6062129735946655
[15/24] Train loss=0.5969184041023254
[20/24] Train loss=0.5982478260993958
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=63.46%
Best model saved!! Metric=-88.59962158340733!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.584840 Test loss=0.559328 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5830647945404053
[5/24] Train loss=0.5565287470817566
[10/24] Train loss=0.6003257036209106
[15/24] Train loss=0.5829948782920837
[20/24] Train loss=0.5811711549758911
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=67.75%
Best model saved!! Metric=-84.3035085024236!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.575684 Test loss=0.551284 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5740640759468079
[5/24] Train loss=0.5495646595954895
[10/24] Train loss=0.5904900431632996
[15/24] Train loss=0.5781628489494324
[20/24] Train loss=0.5701566338539124
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=71.23%
Best model saved!! Metric=-80.82290596164434!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.568686 Test loss=0.544279 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5594542622566223
[5/24] Train loss=0.5354604125022888
[10/24] Train loss=0.5899502038955688
[15/24] Train loss=0.5686355829238892
[20/24] Train loss=0.5653356313705444
Test set avg_accuracy=73.91% avg_sensitivity=0.00%, avg_specificity=99.95% avg_auc=74.41%
Best model saved!! Metric=-77.73596059042586!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.560180 Test loss=0.534942 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5553638339042664
[5/24] Train loss=0.5257630348205566
[10/24] Train loss=0.5779356956481934
[15/24] Train loss=0.5549389123916626
[20/24] Train loss=0.5518708229064941
Test set avg_accuracy=73.87% avg_sensitivity=0.05%, avg_specificity=99.88% avg_auc=77.47%
Best model saved!! Metric=-74.73950527968869!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.549509 Test loss=0.522856 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.541968584060669
[5/24] Train loss=0.518561840057373
[10/24] Train loss=0.563864529132843
[15/24] Train loss=0.5486545562744141
[20/24] Train loss=0.5374197959899902
Test set avg_accuracy=73.87% avg_sensitivity=0.40%, avg_specificity=99.75% avg_auc=79.89%
Best model saved!! Metric=-72.09210561273223!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.538308 Test loss=0.509070 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5282638072967529
[5/24] Train loss=0.507498025894165
[10/24] Train loss=0.55609530210495
[15/24] Train loss=0.5395227074623108
[20/24] Train loss=0.5268833637237549
Test set avg_accuracy=73.54% avg_sensitivity=1.45%, avg_specificity=98.94% avg_auc=81.77%
Best model saved!! Metric=-70.29816319829166!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.526764 Test loss=0.493330 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5149275660514832
[5/24] Train loss=0.4856520891189575
[10/24] Train loss=0.5457810759544373
[15/24] Train loss=0.5226196050643921
[20/24] Train loss=0.5131268501281738
Test set avg_accuracy=73.55% avg_sensitivity=3.00%, avg_specificity=98.42% avg_auc=82.95%
Best model saved!! Metric=-68.07714704935678!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.512162 Test loss=0.478035 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4990253150463104
[5/24] Train loss=0.4750928580760956
[10/24] Train loss=0.5285678505897522
[15/24] Train loss=0.4982766807079315
[20/24] Train loss=0.49262428283691406
Test set avg_accuracy=74.53% avg_sensitivity=9.85%, avg_specificity=97.32% avg_auc=84.18%
Best model saved!! Metric=-60.11576475640064!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.495877 Test loss=0.459274 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4793705940246582
[5/24] Train loss=0.45539456605911255
[10/24] Train loss=0.5162414908409119
[15/24] Train loss=0.4874195456504822
[20/24] Train loss=0.47821110486984253
Test set avg_accuracy=75.59% avg_sensitivity=16.59%, avg_specificity=96.37% avg_auc=85.08%
Best model saved!! Metric=-52.37378874710713!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.479717 Test loss=0.442346 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.46814554929733276
[5/24] Train loss=0.4372047185897827
[10/24] Train loss=0.5052992701530457
[15/24] Train loss=0.4682287871837616
[20/24] Train loss=0.46052947640419006
Test set avg_accuracy=77.29% avg_sensitivity=27.89%, avg_specificity=94.70% avg_auc=85.85%
Best model saved!! Metric=-40.27572977246188!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.465988 Test loss=0.427440 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4446675777435303
[5/24] Train loss=0.42337566614151
[10/24] Train loss=0.49359962344169617
[15/24] Train loss=0.455195814371109
[20/24] Train loss=0.4483925700187683
Test set avg_accuracy=78.97% avg_sensitivity=36.08%, avg_specificity=94.08% avg_auc=86.66%
Best model saved!! Metric=-30.203856959941184!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.453732 Test loss=0.414329 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.434320867061615
[5/24] Train loss=0.41625359654426575
[10/24] Train loss=0.48750823736190796
[15/24] Train loss=0.4457913041114807
[20/24] Train loss=0.4343728721141815
Test set avg_accuracy=81.30% avg_sensitivity=46.78%, avg_specificity=93.47% avg_auc=87.09%
Best model saved!! Metric=-17.36071363585244!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.441985 Test loss=0.404561 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4249984622001648
[5/24] Train loss=0.413301944732666
[10/24] Train loss=0.47768235206604004
[15/24] Train loss=0.438662052154541
[20/24] Train loss=0.41922709345817566
Test set avg_accuracy=81.21% avg_sensitivity=46.18%, avg_specificity=93.56% avg_auc=87.63%
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.432028 Test loss=0.394094 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.41420120000839233
[5/24] Train loss=0.3961561322212219
[10/24] Train loss=0.45475009083747864
[15/24] Train loss=0.4327741265296936
[20/24] Train loss=0.4089593291282654
Test set avg_accuracy=81.54% avg_sensitivity=44.93%, avg_specificity=94.44% avg_auc=88.25%
Best model saved!! Metric=-16.84923647553972!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.419650 Test loss=0.383049 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3934188485145569
[5/24] Train loss=0.3829489052295685
[10/24] Train loss=0.44548553228378296
[15/24] Train loss=0.41480299830436707
[20/24] Train loss=0.3928617238998413
Test set avg_accuracy=81.37% avg_sensitivity=45.38%, avg_specificity=94.05% avg_auc=88.61%
Best model saved!! Metric=-16.593565703253986!!
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.406179 Test loss=0.375718 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.38351869583129883
[5/24] Train loss=0.3698784410953522
[10/24] Train loss=0.4343975782394409
[15/24] Train loss=0.39789748191833496
[20/24] Train loss=0.3829596936702728
Test set avg_accuracy=82.41% avg_sensitivity=51.32%, avg_specificity=93.36% avg_auc=89.02%
Best model saved!! Metric=-9.882247509119857!!
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.393660 Test loss=0.367624 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.37724465131759644
[5/24] Train loss=0.36434051394462585
[10/24] Train loss=0.41626283526420593
[15/24] Train loss=0.38361263275146484
[20/24] Train loss=0.3721916377544403
Test set avg_accuracy=82.57% avg_sensitivity=51.67%, avg_specificity=93.45% avg_auc=89.22%
Best model saved!! Metric=-9.095660274145146!!
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.384649 Test loss=0.362790 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3587130904197693
[5/24] Train loss=0.3584795892238617
[10/24] Train loss=0.4091006815433502
[15/24] Train loss=0.37243643403053284
[20/24] Train loss=0.3625868558883667
Test set avg_accuracy=82.37% avg_sensitivity=49.28%, avg_specificity=94.03% avg_auc=89.43%
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.378558 Test loss=0.359875 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3539462387561798
[5/24] Train loss=0.3513931334018707
[10/24] Train loss=0.40961936116218567
[15/24] Train loss=0.3678338825702667
[20/24] Train loss=0.3528624475002289
Test set avg_accuracy=82.49% avg_sensitivity=48.78%, avg_specificity=94.37% avg_auc=89.56%
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.373252 Test loss=0.358815 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3514828681945801
[5/24] Train loss=0.34371423721313477
[10/24] Train loss=0.4061571955680847
[15/24] Train loss=0.37434253096580505
[20/24] Train loss=0.3521879315376282
Test set avg_accuracy=82.49% avg_sensitivity=47.13%, avg_specificity=94.95% avg_auc=89.62%
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.369592 Test loss=0.359671 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.34641650319099426
[5/24] Train loss=0.3469380736351013
[10/24] Train loss=0.3987564146518707
[15/24] Train loss=0.3706466257572174
[20/24] Train loss=0.3489925265312195
Test set avg_accuracy=82.33% avg_sensitivity=47.08%, avg_specificity=94.75% avg_auc=89.63%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.364657 Test loss=0.358341 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3386036157608032
[5/24] Train loss=0.34387636184692383
[10/24] Train loss=0.3955916166305542
[15/24] Train loss=0.37500977516174316
[20/24] Train loss=0.3535284101963043
Test set avg_accuracy=83.32% avg_sensitivity=52.52%, avg_specificity=94.17% avg_auc=89.83%
Best model saved!! Metric=-6.15926132463904!!
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.361361 Test loss=0.352150 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.34178411960601807
[5/24] Train loss=0.3374047875404358
[10/24] Train loss=0.39148345589637756
[15/24] Train loss=0.37030765414237976
[20/24] Train loss=0.34844306111335754
Test set avg_accuracy=83.28% avg_sensitivity=52.87%, avg_specificity=94.00% avg_auc=89.87%
Best model saved!! Metric=-5.977251054104023!!
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.358195 Test loss=0.351623 Current lr=[0.000210185142098938]

[0/24] Train loss=0.33318281173706055
[5/24] Train loss=0.3389413356781006
[10/24] Train loss=0.3855307400226593
[15/24] Train loss=0.3645930886268616
[20/24] Train loss=0.3464389443397522
Test set avg_accuracy=82.76% avg_sensitivity=47.78%, avg_specificity=95.09% avg_auc=89.97%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.355276 Test loss=0.354786 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.33040788769721985
[5/24] Train loss=0.341641366481781
[10/24] Train loss=0.3903837203979492
[15/24] Train loss=0.3574208617210388
[20/24] Train loss=0.338967502117157
Test set avg_accuracy=83.01% avg_sensitivity=50.47%, avg_specificity=94.47% avg_auc=90.01%
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.353155 Test loss=0.352743 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.33082470297813416
[5/24] Train loss=0.3428177833557129
[10/24] Train loss=0.38731682300567627
[15/24] Train loss=0.36460044980049133
[20/24] Train loss=0.34259894490242004
Test set avg_accuracy=83.33% avg_sensitivity=52.17%, avg_specificity=94.31% avg_auc=90.06%
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.352591 Test loss=0.350442 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3265714645385742
[5/24] Train loss=0.3424578011035919
[10/24] Train loss=0.3851722180843353
[15/24] Train loss=0.35999470949172974
[20/24] Train loss=0.3446338176727295
Test set avg_accuracy=83.05% avg_sensitivity=50.77%, avg_specificity=94.42% avg_auc=90.12%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.351051 Test loss=0.351337 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3270183801651001
[5/24] Train loss=0.34342244267463684
[10/24] Train loss=0.38604483008384705
[15/24] Train loss=0.36760571599006653
[20/24] Train loss=0.3381410241127014
Test set avg_accuracy=83.01% avg_sensitivity=49.43%, avg_specificity=94.84% avg_auc=90.10%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.349910 Test loss=0.353256 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.325919508934021
[5/24] Train loss=0.3465956747531891
[10/24] Train loss=0.386044979095459
[15/24] Train loss=0.3682821989059448
[20/24] Train loss=0.3419814705848694
Test set avg_accuracy=83.48% avg_sensitivity=52.22%, avg_specificity=94.49% avg_auc=90.13%
Best model saved!! Metric=-5.678107743677231!!
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.350114 Test loss=0.350334 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3235338032245636
[5/24] Train loss=0.3424862325191498
[10/24] Train loss=0.3836984634399414
[15/24] Train loss=0.3590506315231323
[20/24] Train loss=0.3408787250518799
Test set avg_accuracy=83.12% avg_sensitivity=50.32%, avg_specificity=94.68% avg_auc=90.16%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.349348 Test loss=0.351506 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.32474225759506226
[5/24] Train loss=0.33379927277565
[10/24] Train loss=0.3829375207424164
[15/24] Train loss=0.3650633990764618
[20/24] Train loss=0.3372418284416199
Test set avg_accuracy=83.42% avg_sensitivity=52.07%, avg_specificity=94.47% avg_auc=90.16%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.348126 Test loss=0.349685 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.32660341262817383
[5/24] Train loss=0.34298649430274963
[10/24] Train loss=0.3824421167373657
[15/24] Train loss=0.3682166039943695
[20/24] Train loss=0.33872848749160767
Test set avg_accuracy=83.68% avg_sensitivity=54.32%, avg_specificity=94.03% avg_auc=90.27%
Best model saved!! Metric=-3.6936770742611174!!
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.347429 Test loss=0.345564 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.31649819016456604
[5/24] Train loss=0.33207207918167114
[10/24] Train loss=0.3772674798965454
[15/24] Train loss=0.35760441422462463
[20/24] Train loss=0.3364242613315582
Test set avg_accuracy=83.48% avg_sensitivity=52.62%, avg_specificity=94.35% avg_auc=90.28%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.344588 Test loss=0.347216 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.31935393810272217
[5/24] Train loss=0.3368222415447235
[10/24] Train loss=0.3778916299343109
[15/24] Train loss=0.3610626757144928
[20/24] Train loss=0.33279433846473694
Test set avg_accuracy=83.54% avg_sensitivity=53.07%, avg_specificity=94.28% avg_auc=90.28%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.344188 Test loss=0.347257 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.32398322224617004
[5/24] Train loss=0.33922404050827026
[10/24] Train loss=0.37947842478752136
[15/24] Train loss=0.35507068037986755
[20/24] Train loss=0.3378516137599945
Test set avg_accuracy=83.20% avg_sensitivity=50.37%, avg_specificity=94.77% avg_auc=90.32%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.343869 Test loss=0.348481 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3190501630306244
[5/24] Train loss=0.3388478457927704
[10/24] Train loss=0.3809439539909363
[15/24] Train loss=0.3558691143989563
[20/24] Train loss=0.3281295597553253
Test set avg_accuracy=83.71% avg_sensitivity=54.42%, avg_specificity=94.03% avg_auc=90.31%
Best model saved!! Metric=-3.5286443290889906!!
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.343301 Test loss=0.344745 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3174892067909241
[5/24] Train loss=0.33237794041633606
[10/24] Train loss=0.3793376386165619
[15/24] Train loss=0.36135828495025635
[20/24] Train loss=0.33139684796333313
Test set avg_accuracy=83.85% avg_sensitivity=53.97%, avg_specificity=94.38% avg_auc=90.37%
Best model saved!! Metric=-3.417165443295275!!
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.341589 Test loss=0.345141 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.31568706035614014
[5/24] Train loss=0.3387197256088257
[10/24] Train loss=0.3765580952167511
[15/24] Train loss=0.35838180780410767
[20/24] Train loss=0.3371630609035492
Test set avg_accuracy=83.57% avg_sensitivity=52.97%, avg_specificity=94.35% avg_auc=90.31%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.341236 Test loss=0.346076 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.31379076838493347
[5/24] Train loss=0.3388342261314392
[10/24] Train loss=0.3745165169239044
[15/24] Train loss=0.36011815071105957
[20/24] Train loss=0.33196553587913513
Test set avg_accuracy=83.65% avg_sensitivity=53.27%, avg_specificity=94.35% avg_auc=90.31%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.341392 Test loss=0.346080 Current lr=[0.00029967723776099]

[0/24] Train loss=0.31452643871307373
[5/24] Train loss=0.33367258310317993
[10/24] Train loss=0.37605541944503784
[15/24] Train loss=0.3596498370170593
[20/24] Train loss=0.3322209119796753
Test set avg_accuracy=83.96% avg_sensitivity=54.92%, avg_specificity=94.19% avg_auc=90.34%
Best model saved!! Metric=-2.5868915009830857!!
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.339714 Test loss=0.344338 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3076528310775757
[5/24] Train loss=0.3333732485771179
[10/24] Train loss=0.3744935691356659
[15/24] Train loss=0.3513919413089752
[20/24] Train loss=0.3282313644886017
Test set avg_accuracy=83.95% avg_sensitivity=55.52%, avg_specificity=93.96% avg_auc=90.46%
Best model saved!! Metric=-2.1094241746280034!!
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.338233 Test loss=0.341209 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.31027039885520935
[5/24] Train loss=0.3288024067878723
[10/24] Train loss=0.369951993227005
[15/24] Train loss=0.35498836636543274
[20/24] Train loss=0.3276747763156891
Test set avg_accuracy=83.92% avg_sensitivity=54.17%, avg_specificity=94.40% avg_auc=90.43%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.336996 Test loss=0.343483 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3118942081928253
[5/24] Train loss=0.3302766978740692
[10/24] Train loss=0.3697474002838135
[15/24] Train loss=0.3563765585422516
[20/24] Train loss=0.3298516273498535
Test set avg_accuracy=84.02% avg_sensitivity=55.87%, avg_specificity=93.94% avg_auc=90.46%
Best model saved!! Metric=-1.699228020558948!!
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.337044 Test loss=0.341523 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3129168450832367
[5/24] Train loss=0.3345133662223816
[10/24] Train loss=0.3749825954437256
[15/24] Train loss=0.35172274708747864
[20/24] Train loss=0.32572421431541443
Test set avg_accuracy=84.14% avg_sensitivity=55.92%, avg_specificity=94.08% avg_auc=90.44%
Best model saved!! Metric=-1.4160379434006316!!
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.336429 Test loss=0.342563 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3078244626522064
[5/24] Train loss=0.3350469768047333
[10/24] Train loss=0.3755914270877838
[15/24] Train loss=0.34517034888267517
[20/24] Train loss=0.32704904675483704
Test set avg_accuracy=84.01% avg_sensitivity=55.87%, avg_specificity=93.92% avg_auc=90.35%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.335974 Test loss=0.343655 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3125436007976532
[5/24] Train loss=0.32965287566185
[10/24] Train loss=0.3745233118534088
[15/24] Train loss=0.35408782958984375
[20/24] Train loss=0.3287006616592407
Test set avg_accuracy=84.11% avg_sensitivity=56.22%, avg_specificity=93.94% avg_auc=90.42%
Best model saved!! Metric=-1.3045097262294831!!
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.335729 Test loss=0.342507 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3118639290332794
[5/24] Train loss=0.3323271572589874
[10/24] Train loss=0.36949217319488525
[15/24] Train loss=0.34648141264915466
[20/24] Train loss=0.3221835494041443
Test set avg_accuracy=84.43% avg_sensitivity=59.07%, avg_specificity=93.36% avg_auc=90.49%
Best model saved!! Metric=1.3507438837589305!!
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.334763 Test loss=0.339006 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.30827993154525757
[5/24] Train loss=0.33186933398246765
[10/24] Train loss=0.37234485149383545
[15/24] Train loss=0.3486582040786743
[20/24] Train loss=0.32162508368492126
Test set avg_accuracy=84.08% avg_sensitivity=56.72%, avg_specificity=93.71% avg_auc=90.51%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.334048 Test loss=0.340187 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.30784767866134644
[5/24] Train loss=0.3302217125892639
[10/24] Train loss=0.3708597421646118
[15/24] Train loss=0.3506159782409668
[20/24] Train loss=0.3323279917240143
Test set avg_accuracy=84.23% avg_sensitivity=57.42%, avg_specificity=93.68% avg_auc=90.47%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.334401 Test loss=0.340350 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3068174421787262
[5/24] Train loss=0.3284817636013031
[10/24] Train loss=0.3721306622028351
[15/24] Train loss=0.34376898407936096
[20/24] Train loss=0.325365275144577
Test set avg_accuracy=84.43% avg_sensitivity=57.07%, avg_specificity=94.07% avg_auc=90.49%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.332410 Test loss=0.340309 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.30715224146842957
[5/24] Train loss=0.32927587628364563
[10/24] Train loss=0.3712877035140991
[15/24] Train loss=0.350413978099823
[20/24] Train loss=0.32717442512512207
Test set avg_accuracy=84.52% avg_sensitivity=59.12%, avg_specificity=93.47% avg_auc=90.52%
Best model saved!! Metric=1.6214090435357775!!
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.333896 Test loss=0.338856 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3064451813697815
[5/24] Train loss=0.33246201276779175
[10/24] Train loss=0.3701121509075165
[15/24] Train loss=0.3450295329093933
[20/24] Train loss=0.3213067650794983
Test set avg_accuracy=84.65% avg_sensitivity=59.57%, avg_specificity=93.48% avg_auc=90.51%
Best model saved!! Metric=2.2138532425601483!!
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.331825 Test loss=0.338691 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3057183027267456
[5/24] Train loss=0.3245834410190582
[10/24] Train loss=0.3699215054512024
[15/24] Train loss=0.3458234965801239
[20/24] Train loss=0.31811073422431946
Test set avg_accuracy=84.61% avg_sensitivity=59.27%, avg_specificity=93.54% avg_auc=90.59%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.331037 Test loss=0.337144 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3041847050189972
[5/24] Train loss=0.3290851414203644
[10/24] Train loss=0.36647307872772217
[15/24] Train loss=0.3465355634689331
[20/24] Train loss=0.317943274974823
Test set avg_accuracy=84.51% avg_sensitivity=58.82%, avg_specificity=93.56% avg_auc=90.58%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.330283 Test loss=0.337818 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.30443301796913147
[5/24] Train loss=0.3268364667892456
[10/24] Train loss=0.3688986897468567
[15/24] Train loss=0.3457290232181549
[20/24] Train loss=0.3264620900154114
Test set avg_accuracy=84.54% avg_sensitivity=58.77%, avg_specificity=93.63% avg_auc=90.52%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.330823 Test loss=0.338886 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3021552264690399
[5/24] Train loss=0.32595914602279663
[10/24] Train loss=0.3728943467140198
[15/24] Train loss=0.34226810932159424
[20/24] Train loss=0.3149235248565674
Test set avg_accuracy=84.47% avg_sensitivity=57.32%, avg_specificity=94.03% avg_auc=90.62%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.330460 Test loss=0.338395 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.30009448528289795
[5/24] Train loss=0.32825881242752075
[10/24] Train loss=0.3700576424598694
[15/24] Train loss=0.3445048928260803
[20/24] Train loss=0.3203252851963043
Test set avg_accuracy=84.47% avg_sensitivity=58.27%, avg_specificity=93.70% avg_auc=90.52%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.330359 Test loss=0.339333 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.30453571677207947
[5/24] Train loss=0.3302557170391083
[10/24] Train loss=0.3744765520095825
[15/24] Train loss=0.343496710062027
[20/24] Train loss=0.321440726518631
Test set avg_accuracy=84.53% avg_sensitivity=58.07%, avg_specificity=93.85% avg_auc=90.64%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.330044 Test loss=0.337583 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.30691152811050415
[5/24] Train loss=0.3240862786769867
[10/24] Train loss=0.3684566617012024
[15/24] Train loss=0.34191039204597473
[20/24] Train loss=0.31718695163726807
Test set avg_accuracy=84.61% avg_sensitivity=59.32%, avg_specificity=93.52% avg_auc=90.65%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.327651 Test loss=0.336323 Current lr=[0.000276307469034998]

[0/24] Train loss=0.30371037125587463
[5/24] Train loss=0.32623279094696045
[10/24] Train loss=0.36971062421798706
[15/24] Train loss=0.34240293502807617
[20/24] Train loss=0.3103024363517761
Test set avg_accuracy=84.82% avg_sensitivity=61.17%, avg_specificity=93.15% avg_auc=90.59%
Best model saved!! Metric=3.7313054175170706!!
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.328920 Test loss=0.336572 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3042862117290497
[5/24] Train loss=0.3207882046699524
[10/24] Train loss=0.3683530390262604
[15/24] Train loss=0.34073248505592346
[20/24] Train loss=0.3178783059120178
Test set avg_accuracy=84.61% avg_sensitivity=58.82%, avg_specificity=93.70% avg_auc=90.63%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.326818 Test loss=0.337119 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3029107451438904
[5/24] Train loss=0.3270597755908966
[10/24] Train loss=0.3699108958244324
[15/24] Train loss=0.3367674648761749
[20/24] Train loss=0.32002565264701843
Test set avg_accuracy=84.58% avg_sensitivity=58.97%, avg_specificity=93.61% avg_auc=90.64%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.328202 Test loss=0.336752 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.30424994230270386
[5/24] Train loss=0.32349804043769836
[10/24] Train loss=0.36685431003570557
[15/24] Train loss=0.3367482125759125
[20/24] Train loss=0.3140996992588043
Test set avg_accuracy=84.71% avg_sensitivity=60.17%, avg_specificity=93.36% avg_auc=90.64%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.326856 Test loss=0.336105 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3047632873058319
[5/24] Train loss=0.3239183723926544
[10/24] Train loss=0.36433544754981995
[15/24] Train loss=0.33768582344055176
[20/24] Train loss=0.3143749535083771
Test set avg_accuracy=84.79% avg_sensitivity=60.37%, avg_specificity=93.40% avg_auc=90.66%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.327212 Test loss=0.335847 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2988797128200531
[5/24] Train loss=0.3223209083080292
[10/24] Train loss=0.37339141964912415
[15/24] Train loss=0.3397119641304016
[20/24] Train loss=0.3128208816051483
Test set avg_accuracy=84.34% avg_sensitivity=57.67%, avg_specificity=93.73% avg_auc=90.62%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.325834 Test loss=0.337933 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.30175724625587463
[5/24] Train loss=0.3233770430088043
[10/24] Train loss=0.36571264266967773
[15/24] Train loss=0.3325570523738861
[20/24] Train loss=0.3159244656562805
Test set avg_accuracy=84.86% avg_sensitivity=60.42%, avg_specificity=93.47% avg_auc=90.67%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.325388 Test loss=0.335557 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.30388471484184265
[5/24] Train loss=0.32030829787254333
[10/24] Train loss=0.367893785238266
[15/24] Train loss=0.33098846673965454
[20/24] Train loss=0.30914124846458435
Test set avg_accuracy=84.56% avg_sensitivity=58.52%, avg_specificity=93.73% avg_auc=90.75%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.325586 Test loss=0.334877 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.30443325638771057
[5/24] Train loss=0.31963202357292175
[10/24] Train loss=0.3634033501148224
[15/24] Train loss=0.33470410108566284
[20/24] Train loss=0.31395265460014343
Test set avg_accuracy=84.80% avg_sensitivity=60.47%, avg_specificity=93.38% avg_auc=90.70%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.325824 Test loss=0.334947 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.30349358916282654
[5/24] Train loss=0.3221065104007721
[10/24] Train loss=0.365267276763916
[15/24] Train loss=0.3327266573905945
[20/24] Train loss=0.31653136014938354
Test set avg_accuracy=84.58% avg_sensitivity=59.32%, avg_specificity=93.48% avg_auc=90.70%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.325577 Test loss=0.335112 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.29989033937454224
[5/24] Train loss=0.32070496678352356
[10/24] Train loss=0.36802172660827637
[15/24] Train loss=0.3345912992954254
[20/24] Train loss=0.3099270164966583
Test set avg_accuracy=84.86% avg_sensitivity=60.52%, avg_specificity=93.43% avg_auc=90.71%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.324441 Test loss=0.334847 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.301632821559906
[5/24] Train loss=0.3204202353954315
[10/24] Train loss=0.36738350987434387
[15/24] Train loss=0.3299952745437622
[20/24] Train loss=0.3083897829055786
Test set avg_accuracy=84.92% avg_sensitivity=59.17%, avg_specificity=94.00% avg_auc=90.76%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.322928 Test loss=0.334848 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2998720705509186
[5/24] Train loss=0.318405419588089
[10/24] Train loss=0.3655736446380615
[15/24] Train loss=0.33501970767974854
[20/24] Train loss=0.3095192015171051
Test set avg_accuracy=84.88% avg_sensitivity=61.97%, avg_specificity=92.96% avg_auc=90.79%
Best model saved!! Metric=4.596916180682996!!
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.323742 Test loss=0.332844 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.29794296622276306
[5/24] Train loss=0.3207925856113434
[10/24] Train loss=0.361255407333374
[15/24] Train loss=0.33192178606987
[20/24] Train loss=0.31458038091659546
Test set avg_accuracy=85.04% avg_sensitivity=59.87%, avg_specificity=93.91% avg_auc=90.80%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.323168 Test loss=0.333470 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3010501265525818
[5/24] Train loss=0.3151046931743622
[10/24] Train loss=0.3646981716156006
[15/24] Train loss=0.32887864112854004
[20/24] Train loss=0.31186774373054504
Test set avg_accuracy=85.04% avg_sensitivity=60.07%, avg_specificity=93.84% avg_auc=90.78%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.323082 Test loss=0.333903 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3006497323513031
[5/24] Train loss=0.31661245226860046
[10/24] Train loss=0.3669220805168152
[15/24] Train loss=0.3317171633243561
[20/24] Train loss=0.3101508617401123
Test set avg_accuracy=84.96% avg_sensitivity=59.57%, avg_specificity=93.91% avg_auc=90.81%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.323525 Test loss=0.333420 Current lr=[0.000224838296036774]

[0/24] Train loss=0.29836568236351013
[5/24] Train loss=0.31951791048049927
[10/24] Train loss=0.36719581484794617
[15/24] Train loss=0.32860809564590454
[20/24] Train loss=0.3072448968887329
Test set avg_accuracy=84.92% avg_sensitivity=59.32%, avg_specificity=93.94% avg_auc=90.75%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.322900 Test loss=0.334866 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2995481789112091
[5/24] Train loss=0.3226228952407837
[10/24] Train loss=0.36802154779434204
[15/24] Train loss=0.3304785490036011
[20/24] Train loss=0.3128145635128021
Test set avg_accuracy=84.77% avg_sensitivity=56.77%, avg_specificity=94.63% avg_auc=90.79%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.322922 Test loss=0.335010 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.29949724674224854
[5/24] Train loss=0.31689971685409546
[10/24] Train loss=0.36648988723754883
[15/24] Train loss=0.3256399929523468
[20/24] Train loss=0.31260135769844055
Test set avg_accuracy=85.12% avg_sensitivity=58.42%, avg_specificity=94.52% avg_auc=90.79%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.323199 Test loss=0.333957 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2969180643558502
[5/24] Train loss=0.3196522295475006
[10/24] Train loss=0.3681330680847168
[15/24] Train loss=0.33055925369262695
[20/24] Train loss=0.3067083954811096
Test set avg_accuracy=84.92% avg_sensitivity=58.82%, avg_specificity=94.12% avg_auc=90.79%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.322199 Test loss=0.333820 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2918417751789093
[5/24] Train loss=0.31437793374061584
[10/24] Train loss=0.37262263894081116
[15/24] Train loss=0.32490968704223633
[20/24] Train loss=0.30997079610824585
Test set avg_accuracy=85.16% avg_sensitivity=59.22%, avg_specificity=94.29% avg_auc=90.82%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.321462 Test loss=0.333461 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.30021679401397705
[5/24] Train loss=0.31378334760665894
[10/24] Train loss=0.3691878616809845
[15/24] Train loss=0.3285715878009796
[20/24] Train loss=0.30903932452201843
Test set avg_accuracy=84.86% avg_sensitivity=61.12%, avg_specificity=93.22% avg_auc=90.84%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.320368 Test loss=0.331827 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.29452434182167053
[5/24] Train loss=0.3137460947036743
[10/24] Train loss=0.3649177849292755
[15/24] Train loss=0.3330846428871155
[20/24] Train loss=0.30340030789375305
Test set avg_accuracy=85.23% avg_sensitivity=59.42%, avg_specificity=94.33% avg_auc=90.86%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.319640 Test loss=0.332627 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.29743534326553345
[5/24] Train loss=0.3130670189857483
[10/24] Train loss=0.36917048692703247
[15/24] Train loss=0.32966935634613037
[20/24] Train loss=0.3094809353351593
Test set avg_accuracy=84.99% avg_sensitivity=61.17%, avg_specificity=93.38% avg_auc=90.84%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.321004 Test loss=0.331792 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2989917993545532
[5/24] Train loss=0.3168218731880188
[10/24] Train loss=0.36321842670440674
[15/24] Train loss=0.328451931476593
[20/24] Train loss=0.30220744013786316
Test set avg_accuracy=84.96% avg_sensitivity=60.77%, avg_specificity=93.48% avg_auc=90.82%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.319313 Test loss=0.332076 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.29642564058303833
[5/24] Train loss=0.31573572754859924
[10/24] Train loss=0.36582329869270325
[15/24] Train loss=0.3366602659225464
[20/24] Train loss=0.30597561597824097
Test set avg_accuracy=84.87% avg_sensitivity=61.47%, avg_specificity=93.11% avg_auc=90.81%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.320061 Test loss=0.332033 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2984483242034912
[5/24] Train loss=0.3117658495903015
[10/24] Train loss=0.3686427175998688
[15/24] Train loss=0.3267773389816284
[20/24] Train loss=0.30580222606658936
Test set avg_accuracy=85.12% avg_sensitivity=60.42%, avg_specificity=93.82% avg_auc=90.85%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.319272 Test loss=0.331926 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2950342297554016
[5/24] Train loss=0.3143339455127716
[10/24] Train loss=0.3703349530696869
[15/24] Train loss=0.3264528810977936
[20/24] Train loss=0.30716121196746826
Test set avg_accuracy=84.99% avg_sensitivity=60.47%, avg_specificity=93.63% avg_auc=90.84%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.318710 Test loss=0.332031 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.29804834723472595
[5/24] Train loss=0.3158002197742462
[10/24] Train loss=0.3657504916191101
[15/24] Train loss=0.32693520188331604
[20/24] Train loss=0.30441227555274963
Test set avg_accuracy=85.04% avg_sensitivity=61.02%, avg_specificity=93.50% avg_auc=90.89%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.318620 Test loss=0.331133 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2981685698032379
[5/24] Train loss=0.3162359595298767
[10/24] Train loss=0.36502712965011597
[15/24] Train loss=0.3257114589214325
[20/24] Train loss=0.3019911050796509
Test set avg_accuracy=85.05% avg_sensitivity=61.07%, avg_specificity=93.50% avg_auc=90.89%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.318122 Test loss=0.330876 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.29712483286857605
[5/24] Train loss=0.31190571188926697
[10/24] Train loss=0.36656123399734497
[15/24] Train loss=0.3274977207183838
[20/24] Train loss=0.3030121624469757
Test set avg_accuracy=85.08% avg_sensitivity=60.72%, avg_specificity=93.66% avg_auc=90.86%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.318900 Test loss=0.331296 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2932814955711365
[5/24] Train loss=0.31244391202926636
[10/24] Train loss=0.36513927578926086
[15/24] Train loss=0.328748881816864
[20/24] Train loss=0.3017059564590454
Test set avg_accuracy=85.01% avg_sensitivity=61.17%, avg_specificity=93.41% avg_auc=90.85%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.318233 Test loss=0.331163 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2959885895252228
[5/24] Train loss=0.3106996715068817
[10/24] Train loss=0.3616200387477875
[15/24] Train loss=0.3246670663356781
[20/24] Train loss=0.3001178205013275
Test set avg_accuracy=85.29% avg_sensitivity=59.37%, avg_specificity=94.42% avg_auc=90.86%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.317536 Test loss=0.331956 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.29975610971450806
[5/24] Train loss=0.31341803073883057
[10/24] Train loss=0.36384448409080505
[15/24] Train loss=0.3319387435913086
[20/24] Train loss=0.29824137687683105
Test set avg_accuracy=84.66% avg_sensitivity=59.87%, avg_specificity=93.40% avg_auc=90.74%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.318734 Test loss=0.333171 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2990145981311798
[5/24] Train loss=0.31061261892318726
[10/24] Train loss=0.3674989640712738
[15/24] Train loss=0.3235792815685272
[20/24] Train loss=0.2962045967578888
Test set avg_accuracy=84.77% avg_sensitivity=59.67%, avg_specificity=93.61% avg_auc=90.78%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.320057 Test loss=0.332890 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.29322680830955505
[5/24] Train loss=0.3164948523044586
[10/24] Train loss=0.3667173683643341
[15/24] Train loss=0.3173564672470093
[20/24] Train loss=0.29807665944099426
Test set avg_accuracy=84.93% avg_sensitivity=62.87%, avg_specificity=92.71% avg_auc=90.81%
Best model saved!! Metric=5.323332183920144!!
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.320605 Test loss=0.331376 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.2959563434123993
[5/24] Train loss=0.319187194108963
[10/24] Train loss=0.36540254950523376
[15/24] Train loss=0.31930485367774963
[20/24] Train loss=0.3090665936470032
Test set avg_accuracy=84.92% avg_sensitivity=70.81%, avg_specificity=89.89% avg_auc=90.71%
Best model saved!! Metric=10.336988890492677!!
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.321740 Test loss=0.334158 Current lr=[0.000134135431043539]

[0/24] Train loss=0.30214524269104004
[5/24] Train loss=0.3120958209037781
[10/24] Train loss=0.3649962842464447
[15/24] Train loss=0.31697067618370056
[20/24] Train loss=0.30536723136901855
Test set avg_accuracy=84.78% avg_sensitivity=70.21%, avg_specificity=89.91% avg_auc=90.60%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.318985 Test loss=0.335825 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3046939969062805
[5/24] Train loss=0.31433022022247314
[10/24] Train loss=0.36692875623703003
[15/24] Train loss=0.3187374770641327
[20/24] Train loss=0.3003759980201721
Test set avg_accuracy=85.42% avg_sensitivity=68.22%, avg_specificity=91.48% avg_auc=90.78%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.318737 Test loss=0.332206 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2986655831336975
[5/24] Train loss=0.3130662441253662
[10/24] Train loss=0.3626904785633087
[15/24] Train loss=0.3141513466835022
[20/24] Train loss=0.30482223629951477
Test set avg_accuracy=85.40% avg_sensitivity=68.77%, avg_specificity=91.27% avg_auc=90.75%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.317230 Test loss=0.332707 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.29905807971954346
[5/24] Train loss=0.3133445084095001
[10/24] Train loss=0.36847764253616333
[15/24] Train loss=0.3163902461528778
[20/24] Train loss=0.30053141713142395
Test set avg_accuracy=84.96% avg_sensitivity=70.06%, avg_specificity=90.21% avg_auc=90.68%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.318589 Test loss=0.334002 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3025703728199005
[5/24] Train loss=0.31052425503730774
[10/24] Train loss=0.3706945478916168
[15/24] Train loss=0.317701518535614
[20/24] Train loss=0.30128613114356995
Test set avg_accuracy=85.13% avg_sensitivity=68.27%, avg_specificity=91.07% avg_auc=90.76%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.318529 Test loss=0.332352 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3013622462749481
[5/24] Train loss=0.3090895414352417
[10/24] Train loss=0.3717716634273529
[15/24] Train loss=0.32019585371017456
[20/24] Train loss=0.30143436789512634
Test set avg_accuracy=85.18% avg_sensitivity=69.87%, avg_specificity=90.58% avg_auc=90.85%
Best model saved!! Metric=10.474166419552617!!
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.318631 Test loss=0.331734 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.29773208498954773
[5/24] Train loss=0.31411030888557434
[10/24] Train loss=0.36405149102211
[15/24] Train loss=0.32133543491363525
[20/24] Train loss=0.30263596773147583
Test set avg_accuracy=85.25% avg_sensitivity=70.76%, avg_specificity=90.35% avg_auc=90.76%
Best model saved!! Metric=11.121102403186256!!
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.318647 Test loss=0.334382 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.30542412400245667
[5/24] Train loss=0.3172481060028076
[10/24] Train loss=0.3664924204349518
[15/24] Train loss=0.3248373568058014
[20/24] Train loss=0.301916241645813
Test set avg_accuracy=85.26% avg_sensitivity=71.71%, avg_specificity=90.03% avg_auc=90.78%
Best model saved!! Metric=11.791801968909013!!
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.318789 Test loss=0.334455 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.30329635739326477
[5/24] Train loss=0.3194095194339752
[10/24] Train loss=0.36904776096343994
[15/24] Train loss=0.31997594237327576
[20/24] Train loss=0.299329936504364
Test set avg_accuracy=85.04% avg_sensitivity=72.56%, avg_specificity=89.43% avg_auc=90.77%
Best model saved!! Metric=11.807879711397817!!
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.317809 Test loss=0.335214 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.30063745379447937
[5/24] Train loss=0.31943830847740173
[10/24] Train loss=0.3729913830757141
[15/24] Train loss=0.3225226104259491
[20/24] Train loss=0.29672491550445557
Test set avg_accuracy=84.97% avg_sensitivity=72.91%, avg_specificity=89.22% avg_auc=90.75%
Best model saved!! Metric=11.857597513919117!!
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.318417 Test loss=0.336519 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3039235472679138
[5/24] Train loss=0.31814634799957275
[10/24] Train loss=0.37189289927482605
[15/24] Train loss=0.3214772045612335
[20/24] Train loss=0.3009951412677765
Test set avg_accuracy=84.95% avg_sensitivity=75.71%, avg_specificity=88.20% avg_auc=90.67%
Best model saved!! Metric=13.53204826700491!!
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.318256 Test loss=0.340964 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3118690848350525
[5/24] Train loss=0.3300122022628784
[10/24] Train loss=0.3752301037311554
[15/24] Train loss=0.31912481784820557
[20/24] Train loss=0.3132306635379791
Test set avg_accuracy=84.17% avg_sensitivity=77.01%, avg_specificity=86.69% avg_auc=90.61%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.321298 Test loss=0.346425 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.31755581498146057
[5/24] Train loss=0.3278065621852875
[10/24] Train loss=0.37096643447875977
[15/24] Train loss=0.3160293996334076
[20/24] Train loss=0.32888883352279663
Test set avg_accuracy=84.99% avg_sensitivity=75.36%, avg_specificity=88.38% avg_auc=90.76%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.323277 Test loss=0.339779 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.30396220088005066
[5/24] Train loss=0.31002718210220337
[10/24] Train loss=0.364020437002182
[15/24] Train loss=0.3205234408378601
[20/24] Train loss=0.3219137489795685
Test set avg_accuracy=85.23% avg_sensitivity=69.37%, avg_specificity=90.83% avg_auc=90.90%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.320390 Test loss=0.330988 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.29952844977378845
[5/24] Train loss=0.3100793957710266
[10/24] Train loss=0.3623282313346863
[15/24] Train loss=0.3196015954017639
[20/24] Train loss=0.3133993446826935
Test set avg_accuracy=85.25% avg_sensitivity=69.17%, avg_specificity=90.91% avg_auc=90.92%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.316369 Test loss=0.331198 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.30105218291282654
[5/24] Train loss=0.3124184012413025
[10/24] Train loss=0.3678334057331085
[15/24] Train loss=0.31647607684135437
[20/24] Train loss=0.3123476207256317
Test set avg_accuracy=85.36% avg_sensitivity=71.46%, avg_specificity=90.26% avg_auc=90.90%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.316889 Test loss=0.333170 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3009392023086548
[5/24] Train loss=0.3176645338535309
[10/24] Train loss=0.37038174271583557
[15/24] Train loss=0.32113149762153625
[20/24] Train loss=0.31473198533058167
Test set avg_accuracy=84.95% avg_sensitivity=68.97%, avg_specificity=90.58% avg_auc=90.86%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.317951 Test loss=0.333699 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.30343401432037354
[5/24] Train loss=0.3163215219974518
[10/24] Train loss=0.3664558529853821
[15/24] Train loss=0.3166435956954956
[20/24] Train loss=0.30637112259864807
Test set avg_accuracy=84.79% avg_sensitivity=69.42%, avg_specificity=90.21% avg_auc=90.80%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.317871 Test loss=0.335305 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.30399182438850403
[5/24] Train loss=0.31649988889694214
[10/24] Train loss=0.36541691422462463
[15/24] Train loss=0.31857550144195557
[20/24] Train loss=0.3185890316963196
Test set avg_accuracy=84.88% avg_sensitivity=68.92%, avg_specificity=90.51% avg_auc=90.89%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.318466 Test loss=0.332932 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3010774850845337
[5/24] Train loss=0.3136571943759918
[10/24] Train loss=0.3621947169303894
[15/24] Train loss=0.3192296624183655
[20/24] Train loss=0.31183964014053345
Test set avg_accuracy=85.10% avg_sensitivity=68.47%, avg_specificity=90.97% avg_auc=90.98%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.317401 Test loss=0.329746 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.2924809157848358
[5/24] Train loss=0.310028612613678
[10/24] Train loss=0.3586347997188568
[15/24] Train loss=0.31498420238494873
[20/24] Train loss=0.3070460259914398
Test set avg_accuracy=85.38% avg_sensitivity=69.12%, avg_specificity=91.11% avg_auc=90.99%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.315052 Test loss=0.329542 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.2967434525489807
[5/24] Train loss=0.3121829926967621
[10/24] Train loss=0.36287927627563477
[15/24] Train loss=0.3125457167625427
[20/24] Train loss=0.30999311804771423
Test set avg_accuracy=85.22% avg_sensitivity=68.37%, avg_specificity=91.16% avg_auc=90.97%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.314813 Test loss=0.329996 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.29850706458091736
[5/24] Train loss=0.3075753152370453
[10/24] Train loss=0.36288774013519287
[15/24] Train loss=0.31547465920448303
[20/24] Train loss=0.30873286724090576
Test set avg_accuracy=85.42% avg_sensitivity=68.77%, avg_specificity=91.28% avg_auc=90.98%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.314854 Test loss=0.329527 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.2956215739250183
[5/24] Train loss=0.3085796535015106
[10/24] Train loss=0.3595044016838074
[15/24] Train loss=0.3162843883037567
[20/24] Train loss=0.3067234754562378
Test set avg_accuracy=85.30% avg_sensitivity=68.67%, avg_specificity=91.16% avg_auc=90.97%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.313920 Test loss=0.329488 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.29699498414993286
[5/24] Train loss=0.311926931142807
[10/24] Train loss=0.36001941561698914
[15/24] Train loss=0.3143652379512787
[20/24] Train loss=0.30513930320739746
Test set avg_accuracy=85.18% avg_sensitivity=67.77%, avg_specificity=91.32% avg_auc=90.99%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.313701 Test loss=0.329230 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.2955414056777954
[5/24] Train loss=0.30775490403175354
[10/24] Train loss=0.35941746830940247
[15/24] Train loss=0.3144909739494324
[20/24] Train loss=0.29973527789115906
Test set avg_accuracy=85.20% avg_sensitivity=67.92%, avg_specificity=91.28% avg_auc=91.00%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.313165 Test loss=0.329078 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.2957419753074646
[5/24] Train loss=0.3095052242279053
[10/24] Train loss=0.36220064759254456
[15/24] Train loss=0.3180699944496155
[20/24] Train loss=0.305688738822937
Test set avg_accuracy=85.34% avg_sensitivity=67.42%, avg_specificity=91.65% avg_auc=90.98%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.314153 Test loss=0.329170 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3003751337528229
[5/24] Train loss=0.30786076188087463
[10/24] Train loss=0.36092543601989746
[15/24] Train loss=0.3180910348892212
[20/24] Train loss=0.30602431297302246
Test set avg_accuracy=85.10% avg_sensitivity=67.87%, avg_specificity=91.18% avg_auc=90.99%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.313440 Test loss=0.329273 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.29986119270324707
[5/24] Train loss=0.3114764094352722
[10/24] Train loss=0.36226680874824524
[15/24] Train loss=0.3136870265007019
[20/24] Train loss=0.29981181025505066
Test set avg_accuracy=85.26% avg_sensitivity=68.12%, avg_specificity=91.30% avg_auc=90.98%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.313317 Test loss=0.329202 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.2951239347457886
[5/24] Train loss=0.31149616837501526
[10/24] Train loss=0.3596189022064209
[15/24] Train loss=0.31683090329170227
[20/24] Train loss=0.2996462285518646
Test set avg_accuracy=85.33% avg_sensitivity=68.87%, avg_specificity=91.13% avg_auc=90.96%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.312750 Test loss=0.329603 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.29693782329559326
[5/24] Train loss=0.30679550766944885
[10/24] Train loss=0.3603399991989136
[15/24] Train loss=0.3147754967212677
[20/24] Train loss=0.2997872233390808
Test set avg_accuracy=85.29% avg_sensitivity=69.02%, avg_specificity=91.02% avg_auc=90.96%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.312213 Test loss=0.329902 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.2966860234737396
[5/24] Train loss=0.3071129024028778
[10/24] Train loss=0.35956308245658875
[15/24] Train loss=0.30930325388908386
[20/24] Train loss=0.29886186122894287
Test set avg_accuracy=85.30% avg_sensitivity=69.12%, avg_specificity=91.00% avg_auc=90.98%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.312909 Test loss=0.329759 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.2977202236652374
[5/24] Train loss=0.30783310532569885
[10/24] Train loss=0.3582860231399536
[15/24] Train loss=0.31417137384414673
[20/24] Train loss=0.3056682050228119
Test set avg_accuracy=85.31% avg_sensitivity=69.72%, avg_specificity=90.81% avg_auc=90.97%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.312670 Test loss=0.330249 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.29789355397224426
[5/24] Train loss=0.308489590883255
[10/24] Train loss=0.3587753474712372
[15/24] Train loss=0.31836631894111633
[20/24] Train loss=0.305197536945343
Test set avg_accuracy=85.31% avg_sensitivity=68.97%, avg_specificity=91.07% avg_auc=90.96%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.313635 Test loss=0.330298 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.2959112823009491
[5/24] Train loss=0.3041321039199829
[10/24] Train loss=0.3595658838748932
[15/24] Train loss=0.3154803514480591
[20/24] Train loss=0.3032603859901428
Test set avg_accuracy=85.17% avg_sensitivity=68.17%, avg_specificity=91.16% avg_auc=90.96%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.312715 Test loss=0.329951 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.2979503273963928
[5/24] Train loss=0.3077632188796997
[10/24] Train loss=0.35647833347320557
[15/24] Train loss=0.31131017208099365
[20/24] Train loss=0.30475395917892456
Test set avg_accuracy=85.10% avg_sensitivity=67.57%, avg_specificity=91.28% avg_auc=90.97%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.312394 Test loss=0.329348 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.295416921377182
[5/24] Train loss=0.3056747019290924
[10/24] Train loss=0.35703152418136597
[15/24] Train loss=0.3119751513004303
[20/24] Train loss=0.3029857873916626
Test set avg_accuracy=85.26% avg_sensitivity=67.67%, avg_specificity=91.46% avg_auc=90.98%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.311879 Test loss=0.329024 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.2936130166053772
[5/24] Train loss=0.3061971068382263
[10/24] Train loss=0.35815292596817017
[15/24] Train loss=0.311605840921402
[20/24] Train loss=0.30448609590530396
Test set avg_accuracy=85.30% avg_sensitivity=66.92%, avg_specificity=91.78% avg_auc=90.98%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.311570 Test loss=0.328891 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.2960622310638428
[5/24] Train loss=0.30646780133247375
[10/24] Train loss=0.36070770025253296
[15/24] Train loss=0.31337645649909973
[20/24] Train loss=0.30174916982650757
Test set avg_accuracy=85.18% avg_sensitivity=66.92%, avg_specificity=91.62% avg_auc=90.98%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.312377 Test loss=0.328889 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.29270121455192566
[5/24] Train loss=0.3102130591869354
[10/24] Train loss=0.36070606112480164
[15/24] Train loss=0.31664925813674927
[20/24] Train loss=0.3023777902126312
Test set avg_accuracy=85.30% avg_sensitivity=66.87%, avg_specificity=91.79% avg_auc=90.98%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.311761 Test loss=0.328857 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.29481375217437744
[5/24] Train loss=0.3041129410266876
[10/24] Train loss=0.35713210701942444
[15/24] Train loss=0.31694257259368896
[20/24] Train loss=0.3001343011856079
Test set avg_accuracy=85.29% avg_sensitivity=67.12%, avg_specificity=91.69% avg_auc=90.98%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.312073 Test loss=0.328898 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.29698607325553894
[5/24] Train loss=0.3107787072658539
[10/24] Train loss=0.3598896861076355
[15/24] Train loss=0.3117751479148865
[20/24] Train loss=0.30017951130867004
Test set avg_accuracy=85.34% avg_sensitivity=67.02%, avg_specificity=91.79% avg_auc=90.98%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.311835 Test loss=0.328844 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.2933339774608612
[5/24] Train loss=0.3068491220474243
[10/24] Train loss=0.3606039881706238
[15/24] Train loss=0.31615394353866577
[20/24] Train loss=0.29918310046195984
Test set avg_accuracy=85.35% avg_sensitivity=66.62%, avg_specificity=91.95% avg_auc=90.98%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.311907 Test loss=0.328784 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.2946230173110962
[5/24] Train loss=0.30444344878196716
[10/24] Train loss=0.3641901910305023
[15/24] Train loss=0.31218305230140686
[20/24] Train loss=0.29746559262275696
Test set avg_accuracy=85.30% avg_sensitivity=66.87%, avg_specificity=91.79% avg_auc=90.98%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.311842 Test loss=0.328816 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.2922598421573639
[5/24] Train loss=0.30557379126548767
[10/24] Train loss=0.3609856367111206
[15/24] Train loss=0.3108552098274231
[20/24] Train loss=0.3045588433742523
Test set avg_accuracy=85.30% avg_sensitivity=66.97%, avg_specificity=91.76% avg_auc=90.98%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.311748 Test loss=0.328899 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.29339227080345154
[5/24] Train loss=0.30676785111427307
[10/24] Train loss=0.35381174087524414
[15/24] Train loss=0.3153860569000244
[20/24] Train loss=0.2998243570327759
Test set avg_accuracy=85.39% avg_sensitivity=66.87%, avg_specificity=91.92% avg_auc=90.98%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.311646 Test loss=0.328879 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.2937929928302765
[5/24] Train loss=0.3077060878276825
[10/24] Train loss=0.3613244295120239
[15/24] Train loss=0.3117951452732086
[20/24] Train loss=0.29966580867767334
Test set avg_accuracy=85.39% avg_sensitivity=66.87%, avg_specificity=91.92% avg_auc=90.98%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.312363 Test loss=0.328854 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.2939295470714569
[5/24] Train loss=0.3071850836277008
[10/24] Train loss=0.36002522706985474
[15/24] Train loss=0.3116304576396942
[20/24] Train loss=0.3026657700538635
Test set avg_accuracy=85.39% avg_sensitivity=66.82%, avg_specificity=91.94% avg_auc=90.98%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.311520 Test loss=0.328847 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.2938067615032196
[5/24] Train loss=0.3025608956813812
[10/24] Train loss=0.3604199290275574
[15/24] Train loss=0.3125014007091522
[20/24] Train loss=0.30576613545417786
Test set avg_accuracy=85.39% avg_sensitivity=66.82%, avg_specificity=91.94% avg_auc=90.98%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.310843 Test loss=0.328845 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=84.95% sen=75.71%, spe=88.20%, auc=90.67%!
Fold[4] Avg_overlap=0.65%(0.25575676579786083)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'HybridCNNRNN',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=1.0969496965408325
[5/24] Train loss=0.8637745380401611
[10/24] Train loss=0.7408958673477173
[15/24] Train loss=0.6586039662361145
[20/24] Train loss=0.6434109807014465
Test set avg_accuracy=74.56% avg_sensitivity=0.56%, avg_specificity=99.79% avg_auc=52.45%
Best model saved!! Metric=-98.63767265599496!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.765660 Test loss=0.591326 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6356953978538513
[5/24] Train loss=0.6094988584518433
[10/24] Train loss=0.612201452255249
[15/24] Train loss=0.5848494172096252
[20/24] Train loss=0.6140379309654236
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=55.06%
Best model saved!! Metric=-96.36954398956163!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.602241 Test loss=0.565915 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6085309386253357
[5/24] Train loss=0.5925003886222839
[10/24] Train loss=0.5908421874046326
[15/24] Train loss=0.5784697532653809
[20/24] Train loss=0.6089282035827637
Test set avg_accuracy=74.51% avg_sensitivity=0.00%, avg_specificity=99.91% avg_auc=60.05%
Best model saved!! Metric=-91.52880290921473!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.588054 Test loss=0.559991 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.603237509727478
[5/24] Train loss=0.5772031545639038
[10/24] Train loss=0.5950241684913635
[15/24] Train loss=0.5822008848190308
[20/24] Train loss=0.5927501320838928
Test set avg_accuracy=74.41% avg_sensitivity=0.00%, avg_specificity=99.79% avg_auc=63.26%
Best model saved!! Metric=-88.53200758366957!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.582725 Test loss=0.554611 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6006948351860046
[5/24] Train loss=0.5743002891540527
[10/24] Train loss=0.5872604846954346
[15/24] Train loss=0.5695023536682129
[20/24] Train loss=0.5926509499549866
Test set avg_accuracy=74.34% avg_sensitivity=0.05%, avg_specificity=99.67% avg_auc=66.65%
Best model saved!! Metric=-85.29522778090589!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.576410 Test loss=0.546676 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.593700647354126
[5/24] Train loss=0.5651857852935791
[10/24] Train loss=0.5858630537986755
[15/24] Train loss=0.5561303496360779
[20/24] Train loss=0.5807903409004211
Test set avg_accuracy=74.30% avg_sensitivity=0.20%, avg_specificity=99.56% avg_auc=70.60%
Best model saved!! Metric=-81.33221371846165!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.568831 Test loss=0.539530 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.582273542881012
[5/24] Train loss=0.5600306391716003
[10/24] Train loss=0.5746884942054749
[15/24] Train loss=0.5508826375007629
[20/24] Train loss=0.5703622102737427
Test set avg_accuracy=74.21% avg_sensitivity=0.36%, avg_specificity=99.39% avg_auc=72.80%
Best model saved!! Metric=-79.24406421867819!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.561625 Test loss=0.532563 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5774208307266235
[5/24] Train loss=0.5464705228805542
[10/24] Train loss=0.5763120055198669
[15/24] Train loss=0.5449532270431519
[20/24] Train loss=0.5622646808624268
Test set avg_accuracy=74.11% avg_sensitivity=0.56%, avg_specificity=99.20% avg_auc=75.62%
Best model saved!! Metric=-76.50715212248178!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.553475 Test loss=0.524302 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5659769773483276
[5/24] Train loss=0.5452354550361633
[10/24] Train loss=0.5595510005950928
[15/24] Train loss=0.5376324653625488
[20/24] Train loss=0.5574741363525391
Test set avg_accuracy=73.95% avg_sensitivity=1.23%, avg_specificity=98.74% avg_auc=77.50%
Best model saved!! Metric=-74.5796098703067!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.545446 Test loss=0.514932 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5555835366249084
[5/24] Train loss=0.5315151214599609
[10/24] Train loss=0.5608982443809509
[15/24] Train loss=0.5280770063400269
[20/24] Train loss=0.5443465709686279
Test set avg_accuracy=73.54% avg_sensitivity=1.08%, avg_specificity=98.25% avg_auc=79.02%
Best model saved!! Metric=-74.11142312968339!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.535850 Test loss=0.504799 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5397275686264038
[5/24] Train loss=0.5195158123970032
[10/24] Train loss=0.5412074327468872
[15/24] Train loss=0.516550600528717
[20/24] Train loss=0.5405876636505127
Test set avg_accuracy=73.61% avg_sensitivity=4.45%, avg_specificity=97.19% avg_auc=80.71%
Best model saved!! Metric=-70.03717926300698!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.523837 Test loss=0.493126 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.544361412525177
[5/24] Train loss=0.5003690719604492
[10/24] Train loss=0.534372866153717
[15/24] Train loss=0.5036051869392395
[20/24] Train loss=0.51590895652771
Test set avg_accuracy=73.37% avg_sensitivity=7.01%, avg_specificity=96.00% avg_auc=82.06%
Best model saved!! Metric=-67.54953280376452!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.511973 Test loss=0.479522 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5221856832504272
[5/24] Train loss=0.4921766519546509
[10/24] Train loss=0.523150622844696
[15/24] Train loss=0.4824645519256592
[20/24] Train loss=0.5052936673164368
Test set avg_accuracy=73.48% avg_sensitivity=11.88%, avg_specificity=94.48% avg_auc=83.22%
Best model saved!! Metric=-62.942405833093275!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.498197 Test loss=0.464670 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5067758560180664
[5/24] Train loss=0.4767225384712219
[10/24] Train loss=0.5132076740264893
[15/24] Train loss=0.46136435866355896
[20/24] Train loss=0.4983796179294586
Test set avg_accuracy=74.96% avg_sensitivity=23.35%, avg_specificity=92.56% avg_auc=84.25%
Best model saved!! Metric=-50.880606820160054!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.482970 Test loss=0.450134 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.48180392384529114
[5/24] Train loss=0.45688796043395996
[10/24] Train loss=0.504100501537323
[15/24] Train loss=0.45406392216682434
[20/24] Train loss=0.4802510440349579
Test set avg_accuracy=75.29% avg_sensitivity=30.67%, avg_specificity=90.50% avg_auc=84.94%
Best model saved!! Metric=-44.60163885830059!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.471907 Test loss=0.438775 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.47258374094963074
[5/24] Train loss=0.45422080159187317
[10/24] Train loss=0.5001365542411804
[15/24] Train loss=0.43435782194137573
[20/24] Train loss=0.4627605080604553
Test set avg_accuracy=76.35% avg_sensitivity=38.86%, avg_specificity=89.14% avg_auc=85.55%
Best model saved!! Metric=-36.08920918764887!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.461728 Test loss=0.428198 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4613252580165863
[5/24] Train loss=0.44458824396133423
[10/24] Train loss=0.4993096888065338
[15/24] Train loss=0.42619454860687256
[20/24] Train loss=0.4491828978061676
Test set avg_accuracy=77.73% avg_sensitivity=38.71%, avg_specificity=91.04% avg_auc=86.10%
Best model saved!! Metric=-32.41702612532767!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.452266 Test loss=0.415495 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4525129199028015
[5/24] Train loss=0.44233208894729614
[10/24] Train loss=0.48764923214912415
[15/24] Train loss=0.41856545209884644
[20/24] Train loss=0.43591567873954773
Test set avg_accuracy=77.38% avg_sensitivity=32.62%, avg_specificity=92.65% avg_auc=86.51%
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.443150 Test loss=0.404953 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4396250545978546
[5/24] Train loss=0.42832282185554504
[10/24] Train loss=0.473210871219635
[15/24] Train loss=0.410541296005249
[20/24] Train loss=0.42940327525138855
Test set avg_accuracy=77.86% avg_sensitivity=29.44%, avg_specificity=94.38% avg_auc=86.64%
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.431600 Test loss=0.399132 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.42752623558044434
[5/24] Train loss=0.4145803451538086
[10/24] Train loss=0.4529031217098236
[15/24] Train loss=0.39460787177085876
[20/24] Train loss=0.4239930510520935
Test set avg_accuracy=78.54% avg_sensitivity=31.34%, avg_specificity=94.64% avg_auc=86.90%
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.422341 Test loss=0.393777 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.42460310459136963
[5/24] Train loss=0.4030234217643738
[10/24] Train loss=0.44713887572288513
[15/24] Train loss=0.39224112033843994
[20/24] Train loss=0.4128047227859497
Test set avg_accuracy=80.47% avg_sensitivity=43.42%, avg_specificity=93.10% avg_auc=87.51%
Best model saved!! Metric=-21.497601212637903!!
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.415143 Test loss=0.386895 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.41966208815574646
[5/24] Train loss=0.41114288568496704
[10/24] Train loss=0.4444795250892639
[15/24] Train loss=0.38185814023017883
[20/24] Train loss=0.41333138942718506
Test set avg_accuracy=79.92% avg_sensitivity=36.76%, avg_specificity=94.64% avg_auc=87.76%
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.410169 Test loss=0.382325 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.41195395588874817
[5/24] Train loss=0.39883455634117126
[10/24] Train loss=0.4458814263343811
[15/24] Train loss=0.38327479362487793
[20/24] Train loss=0.40271902084350586
Test set avg_accuracy=80.36% avg_sensitivity=34.15%, avg_specificity=96.12% avg_auc=87.87%
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.406876 Test loss=0.380219 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.41049882769584656
[5/24] Train loss=0.39879846572875977
[10/24] Train loss=0.4331953823566437
[15/24] Train loss=0.36839279532432556
[20/24] Train loss=0.3929235637187958
Test set avg_accuracy=79.51% avg_sensitivity=26.73%, avg_specificity=97.50% avg_auc=88.01%
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.400692 Test loss=0.382770 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.4050942361354828
[5/24] Train loss=0.3895071744918823
[10/24] Train loss=0.427678644657135
[15/24] Train loss=0.36356982588768005
[20/24] Train loss=0.38508057594299316
Test set avg_accuracy=80.27% avg_sensitivity=28.78%, avg_specificity=97.83% avg_auc=88.71%
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.391202 Test loss=0.375129 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.4001033306121826
[5/24] Train loss=0.3832678496837616
[10/24] Train loss=0.4162883460521698
[15/24] Train loss=0.3512136936187744
[20/24] Train loss=0.3707852065563202
Test set avg_accuracy=79.96% avg_sensitivity=25.70%, avg_specificity=98.46% avg_auc=89.09%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.383067 Test loss=0.379282 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.4082939922809601
[5/24] Train loss=0.37563198804855347
[10/24] Train loss=0.4132413864135742
[15/24] Train loss=0.3472723066806793
[20/24] Train loss=0.36065948009490967
Test set avg_accuracy=80.59% avg_sensitivity=29.08%, avg_specificity=98.15% avg_auc=89.23%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.379666 Test loss=0.376926 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3936495780944824
[5/24] Train loss=0.37281322479248047
[10/24] Train loss=0.40833359956741333
[15/24] Train loss=0.34066042304039
[20/24] Train loss=0.3641102910041809
Test set avg_accuracy=81.08% avg_sensitivity=32.31%, avg_specificity=97.71% avg_auc=89.52%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.376177 Test loss=0.370877 Current lr=[0.000210185142098938]

[0/24] Train loss=0.39168283343315125
[5/24] Train loss=0.3768448531627655
[10/24] Train loss=0.4049251675605774
[15/24] Train loss=0.3334523141384125
[20/24] Train loss=0.3626576364040375
Test set avg_accuracy=81.74% avg_sensitivity=35.43%, avg_specificity=97.54% avg_auc=89.76%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.372797 Test loss=0.363487 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.38039007782936096
[5/24] Train loss=0.37250977754592896
[10/24] Train loss=0.40166544914245605
[15/24] Train loss=0.33776354789733887
[20/24] Train loss=0.3643433451652527
Test set avg_accuracy=81.67% avg_sensitivity=35.18%, avg_specificity=97.52% avg_auc=89.72%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.370252 Test loss=0.363444 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.38206160068511963
[5/24] Train loss=0.3738725483417511
[10/24] Train loss=0.399747371673584
[15/24] Train loss=0.33993518352508545
[20/24] Train loss=0.34946995973587036
Test set avg_accuracy=81.15% avg_sensitivity=32.87%, avg_specificity=97.61% avg_auc=89.67%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.368346 Test loss=0.367161 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3801714777946472
[5/24] Train loss=0.3657410442829132
[10/24] Train loss=0.40059468150138855
[15/24] Train loss=0.33776336908340454
[20/24] Train loss=0.34737682342529297
Test set avg_accuracy=81.38% avg_sensitivity=34.25%, avg_specificity=97.45% avg_auc=89.74%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.364946 Test loss=0.366863 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3841862678527832
[5/24] Train loss=0.3642843961715698
[10/24] Train loss=0.39713531732559204
[15/24] Train loss=0.3346274793148041
[20/24] Train loss=0.3491896986961365
Test set avg_accuracy=81.77% avg_sensitivity=36.56%, avg_specificity=97.19% avg_auc=89.99%
Best model saved!! Metric=-20.491338173773016!!
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.363555 Test loss=0.361639 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3725532591342926
[5/24] Train loss=0.3624761700630188
[10/24] Train loss=0.3931974172592163
[15/24] Train loss=0.3320555090904236
[20/24] Train loss=0.34134820103645325
Test set avg_accuracy=81.69% avg_sensitivity=36.41%, avg_specificity=97.14% avg_auc=90.02%
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.362717 Test loss=0.362273 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.37531614303588867
[5/24] Train loss=0.3585379719734192
[10/24] Train loss=0.39344021677970886
[15/24] Train loss=0.33278048038482666
[20/24] Train loss=0.3373144268989563
Test set avg_accuracy=82.21% avg_sensitivity=38.10%, avg_specificity=97.26% avg_auc=89.97%
Best model saved!! Metric=-18.463250499437585!!
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.360368 Test loss=0.362093 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3731839656829834
[5/24] Train loss=0.35689157247543335
[10/24] Train loss=0.3969113230705261
[15/24] Train loss=0.3302029073238373
[20/24] Train loss=0.33653566241264343
Test set avg_accuracy=82.27% avg_sensitivity=38.81%, avg_specificity=97.08% avg_auc=90.12%
Best model saved!! Metric=-17.714750742825267!!
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.359531 Test loss=0.358685 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.372108519077301
[5/24] Train loss=0.35975050926208496
[10/24] Train loss=0.39387837052345276
[15/24] Train loss=0.32996490597724915
[20/24] Train loss=0.34235715866088867
Test set avg_accuracy=82.99% avg_sensitivity=43.06%, avg_specificity=96.61% avg_auc=90.23%
Best model saved!! Metric=-13.100509728589103!!
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.359203 Test loss=0.353031 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3657943308353424
[5/24] Train loss=0.3624620735645294
[10/24] Train loss=0.39193734526634216
[15/24] Train loss=0.3288807272911072
[20/24] Train loss=0.3406289517879486
Test set avg_accuracy=82.81% avg_sensitivity=42.19%, avg_specificity=96.66% avg_auc=90.30%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.358313 Test loss=0.353071 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.36283695697784424
[5/24] Train loss=0.3581869304180145
[10/24] Train loss=0.3897424340248108
[15/24] Train loss=0.325476735830307
[20/24] Train loss=0.3289036750793457
Test set avg_accuracy=82.92% avg_sensitivity=42.86%, avg_specificity=96.58% avg_auc=90.38%
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.356331 Test loss=0.351199 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3603547513484955
[5/24] Train loss=0.3535913825035095
[10/24] Train loss=0.3931378126144409
[15/24] Train loss=0.3282047510147095
[20/24] Train loss=0.3424609303474426
Test set avg_accuracy=82.71% avg_sensitivity=41.73%, avg_specificity=96.68% avg_auc=90.40%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.356062 Test loss=0.351565 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.36561471223831177
[5/24] Train loss=0.36181387305259705
[10/24] Train loss=0.39263036847114563
[15/24] Train loss=0.3248079717159271
[20/24] Train loss=0.33453676104545593
Test set avg_accuracy=83.07% avg_sensitivity=43.88%, avg_specificity=96.44% avg_auc=90.40%
Best model saved!! Metric=-12.207709924830354!!
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.355449 Test loss=0.349675 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3600243926048279
[5/24] Train loss=0.3545064926147461
[10/24] Train loss=0.37712913751602173
[15/24] Train loss=0.3293246030807495
[20/24] Train loss=0.3319346308708191
Test set avg_accuracy=83.10% avg_sensitivity=44.14%, avg_specificity=96.39% avg_auc=90.31%
Best model saved!! Metric=-12.063731742180543!!
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.352968 Test loss=0.350212 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3654458522796631
[5/24] Train loss=0.3541615903377533
[10/24] Train loss=0.38517454266548157
[15/24] Train loss=0.3251994550228119
[20/24] Train loss=0.33413997292518616
Test set avg_accuracy=82.94% avg_sensitivity=42.86%, avg_specificity=96.61% avg_auc=90.36%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.353593 Test loss=0.351893 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3595972955226898
[5/24] Train loss=0.3548322319984436
[10/24] Train loss=0.3775375187397003
[15/24] Train loss=0.32575133442878723
[20/24] Train loss=0.3330824077129364
Test set avg_accuracy=82.85% avg_sensitivity=42.45%, avg_specificity=96.63% avg_auc=90.39%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.352936 Test loss=0.352291 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3648325800895691
[5/24] Train loss=0.35552123188972473
[10/24] Train loss=0.38056907057762146
[15/24] Train loss=0.32308274507522583
[20/24] Train loss=0.3308829665184021
Test set avg_accuracy=83.06% avg_sensitivity=42.70%, avg_specificity=96.82% avg_auc=90.53%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.352165 Test loss=0.349077 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.36083072423934937
[5/24] Train loss=0.3522913455963135
[10/24] Train loss=0.3837604522705078
[15/24] Train loss=0.3229348659515381
[20/24] Train loss=0.33073723316192627
Test set avg_accuracy=82.80% avg_sensitivity=42.04%, avg_specificity=96.70% avg_auc=90.52%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.351427 Test loss=0.350813 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.35799917578697205
[5/24] Train loss=0.3554287552833557
[10/24] Train loss=0.3792265057563782
[15/24] Train loss=0.32497814297676086
[20/24] Train loss=0.3326074481010437
Test set avg_accuracy=82.89% avg_sensitivity=42.50%, avg_specificity=96.66% avg_auc=90.40%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.351319 Test loss=0.352906 Current lr=[0.000299720220882401]

[0/24] Train loss=0.36462435126304626
[5/24] Train loss=0.3519435524940491
[10/24] Train loss=0.38261252641677856
[15/24] Train loss=0.32205730676651
[20/24] Train loss=0.3325638771057129
Test set avg_accuracy=82.92% avg_sensitivity=42.40%, avg_specificity=96.73% avg_auc=90.38%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.352000 Test loss=0.354174 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3625960648059845
[5/24] Train loss=0.35590994358062744
[10/24] Train loss=0.38376760482788086
[15/24] Train loss=0.3255982995033264
[20/24] Train loss=0.3306271433830261
Test set avg_accuracy=82.90% avg_sensitivity=42.60%, avg_specificity=96.65% avg_auc=90.41%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.352599 Test loss=0.352798 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3630371689796448
[5/24] Train loss=0.35094740986824036
[10/24] Train loss=0.3854544460773468
[15/24] Train loss=0.3229922652244568
[20/24] Train loss=0.3289843499660492
Test set avg_accuracy=83.29% avg_sensitivity=44.85%, avg_specificity=96.40% avg_auc=90.54%
Best model saved!! Metric=-10.905454312267892!!
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.352155 Test loss=0.347266 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.35724639892578125
[5/24] Train loss=0.35312318801879883
[10/24] Train loss=0.39103075861930847
[15/24] Train loss=0.32395532727241516
[20/24] Train loss=0.33453088998794556
Test set avg_accuracy=83.22% avg_sensitivity=44.09%, avg_specificity=96.56% avg_auc=90.52%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.352564 Test loss=0.348072 Current lr=[0.000297555943323901]

[0/24] Train loss=0.35559266805648804
[5/24] Train loss=0.35332190990448
[10/24] Train loss=0.38556548953056335
[15/24] Train loss=0.3186565637588501
[20/24] Train loss=0.3306916058063507
Test set avg_accuracy=84.18% avg_sensitivity=49.77%, avg_specificity=95.91% avg_auc=90.64%
Best model saved!! Metric=-5.493862864775288!!
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.351906 Test loss=0.340717 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3497351408004761
[5/24] Train loss=0.352072149515152
[10/24] Train loss=0.38118821382522583
[15/24] Train loss=0.31908026337623596
[20/24] Train loss=0.33600080013275146
Test set avg_accuracy=83.62% avg_sensitivity=47.47%, avg_specificity=95.95% avg_auc=90.62%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.350361 Test loss=0.342496 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.35198476910591125
[5/24] Train loss=0.35281842947006226
[10/24] Train loss=0.38651323318481445
[15/24] Train loss=0.32158082723617554
[20/24] Train loss=0.3302818536758423
Test set avg_accuracy=83.88% avg_sensitivity=48.44%, avg_specificity=95.97% avg_auc=90.63%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.351659 Test loss=0.341802 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.35203438997268677
[5/24] Train loss=0.3569786250591278
[10/24] Train loss=0.3842170238494873
[15/24] Train loss=0.32130706310272217
[20/24] Train loss=0.3315674662590027
Test set avg_accuracy=83.72% avg_sensitivity=47.26%, avg_specificity=96.16% avg_auc=90.66%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.350941 Test loss=0.341786 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3525952100753784
[5/24] Train loss=0.35145074129104614
[10/24] Train loss=0.38171425461769104
[15/24] Train loss=0.3213449716567993
[20/24] Train loss=0.3344627022743225
Test set avg_accuracy=83.40% avg_sensitivity=45.26%, avg_specificity=96.40% avg_auc=90.62%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.351144 Test loss=0.343306 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.35475337505340576
[5/24] Train loss=0.35500675439834595
[10/24] Train loss=0.380478173494339
[15/24] Train loss=0.322464257478714
[20/24] Train loss=0.33465632796287537
Test set avg_accuracy=83.28% avg_sensitivity=44.29%, avg_specificity=96.58% avg_auc=90.61%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.351272 Test loss=0.344687 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3531070053577423
[5/24] Train loss=0.35796093940734863
[10/24] Train loss=0.37502428889274597
[15/24] Train loss=0.3280699551105499
[20/24] Train loss=0.33182063698768616
Test set avg_accuracy=82.50% avg_sensitivity=39.17%, avg_specificity=97.28% avg_auc=90.35%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.351624 Test loss=0.351714 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.35552290081977844
[5/24] Train loss=0.35455358028411865
[10/24] Train loss=0.3831426799297333
[15/24] Train loss=0.3266560137271881
[20/24] Train loss=0.3300585150718689
Test set avg_accuracy=82.97% avg_sensitivity=43.16%, avg_specificity=96.54% avg_auc=90.50%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.353076 Test loss=0.346110 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.35898393392562866
[5/24] Train loss=0.3538934290409088
[10/24] Train loss=0.3781454861164093
[15/24] Train loss=0.31938114762306213
[20/24] Train loss=0.33618682622909546
Test set avg_accuracy=83.53% avg_sensitivity=46.54%, avg_specificity=96.14% avg_auc=90.60%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.351602 Test loss=0.341404 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3482300639152527
[5/24] Train loss=0.3534530997276306
[10/24] Train loss=0.3755699098110199
[15/24] Train loss=0.3190558850765228
[20/24] Train loss=0.3299950957298279
Test set avg_accuracy=84.00% avg_sensitivity=48.44%, avg_specificity=96.12% avg_auc=90.62%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.350561 Test loss=0.340044 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3484780490398407
[5/24] Train loss=0.35473981499671936
[10/24] Train loss=0.3784405291080475
[15/24] Train loss=0.32348087430000305
[20/24] Train loss=0.32813671231269836
Test set avg_accuracy=84.21% avg_sensitivity=49.46%, avg_specificity=96.05% avg_auc=90.69%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.350344 Test loss=0.338698 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3467089533805847
[5/24] Train loss=0.35552236437797546
[10/24] Train loss=0.3783538341522217
[15/24] Train loss=0.31607523560523987
[20/24] Train loss=0.3309749960899353
Test set avg_accuracy=84.02% avg_sensitivity=50.23%, avg_specificity=95.55% avg_auc=90.63%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.349440 Test loss=0.338852 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3468550741672516
[5/24] Train loss=0.35648879408836365
[10/24] Train loss=0.3806581199169159
[15/24] Train loss=0.32021564245224
[20/24] Train loss=0.3313540518283844
Test set avg_accuracy=84.00% avg_sensitivity=48.59%, avg_specificity=96.07% avg_auc=90.62%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.350336 Test loss=0.339457 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3476848006248474
[5/24] Train loss=0.35553044080734253
[10/24] Train loss=0.38045647740364075
[15/24] Train loss=0.3186207115650177
[20/24] Train loss=0.329449325799942
Test set avg_accuracy=84.06% avg_sensitivity=49.72%, avg_specificity=95.77% avg_auc=90.61%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.349745 Test loss=0.339169 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3470670282840729
[5/24] Train loss=0.3547673225402832
[10/24] Train loss=0.3763781487941742
[15/24] Train loss=0.3189775049686432
[20/24] Train loss=0.3317422866821289
Test set avg_accuracy=83.93% avg_sensitivity=48.39%, avg_specificity=96.05% avg_auc=90.57%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.348885 Test loss=0.340430 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3505168557167053
[5/24] Train loss=0.35601669549942017
[10/24] Train loss=0.3760618269443512
[15/24] Train loss=0.31514403223991394
[20/24] Train loss=0.32997927069664
Test set avg_accuracy=84.01% avg_sensitivity=49.36%, avg_specificity=95.83% avg_auc=90.55%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.349802 Test loss=0.339979 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.34953388571739197
[5/24] Train loss=0.35584408044815063
[10/24] Train loss=0.37806883454322815
[15/24] Train loss=0.3185650110244751
[20/24] Train loss=0.32760846614837646
Test set avg_accuracy=84.09% avg_sensitivity=49.92%, avg_specificity=95.74% avg_auc=90.62%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.349548 Test loss=0.338499 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3464644253253937
[5/24] Train loss=0.35572704672813416
[10/24] Train loss=0.3779516816139221
[15/24] Train loss=0.317902535200119
[20/24] Train loss=0.3263246715068817
Test set avg_accuracy=84.01% avg_sensitivity=49.92%, avg_specificity=95.63% avg_auc=90.68%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.349024 Test loss=0.338054 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.346435010433197
[5/24] Train loss=0.3556402027606964
[10/24] Train loss=0.37335434556007385
[15/24] Train loss=0.31326115131378174
[20/24] Train loss=0.33139994740486145
Test set avg_accuracy=84.19% avg_sensitivity=50.74%, avg_specificity=95.60% avg_auc=90.68%
Best model saved!! Metric=-4.784385375100911!!
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.347692 Test loss=0.337325 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.34816059470176697
[5/24] Train loss=0.3537137806415558
[10/24] Train loss=0.37511834502220154
[15/24] Train loss=0.31519758701324463
[20/24] Train loss=0.3273705840110779
Test set avg_accuracy=84.06% avg_sensitivity=49.51%, avg_specificity=95.84% avg_auc=90.66%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.348464 Test loss=0.338327 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3450118601322174
[5/24] Train loss=0.3552303910255432
[10/24] Train loss=0.3773457109928131
[15/24] Train loss=0.3183039426803589
[20/24] Train loss=0.3254162669181824
Test set avg_accuracy=84.32% avg_sensitivity=51.56%, avg_specificity=95.50% avg_auc=90.77%
Best model saved!! Metric=-3.846413384006432!!
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.348724 Test loss=0.335581 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.34330296516418457
[5/24] Train loss=0.3573291301727295
[10/24] Train loss=0.3807162940502167
[15/24] Train loss=0.32066449522972107
[20/24] Train loss=0.32758498191833496
Test set avg_accuracy=84.41% avg_sensitivity=52.18%, avg_specificity=95.41% avg_auc=90.66%
Best model saved!! Metric=-3.3446176266823002!!
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.349705 Test loss=0.336513 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.34507519006729126
[5/24] Train loss=0.3577841520309448
[10/24] Train loss=0.3713308870792389
[15/24] Train loss=0.3153926134109497
[20/24] Train loss=0.3248647153377533
Test set avg_accuracy=84.61% avg_sensitivity=53.35%, avg_specificity=95.27% avg_auc=90.74%
Best model saved!! Metric=-2.029771000507303!!
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.348613 Test loss=0.334520 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3408774733543396
[5/24] Train loss=0.35322725772857666
[10/24] Train loss=0.3753437101840973
[15/24] Train loss=0.32245680689811707
[20/24] Train loss=0.327534019947052
Test set avg_accuracy=84.97% avg_sensitivity=55.97%, avg_specificity=94.87% avg_auc=90.80%
Best model saved!! Metric=0.6098757647187583!!
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.350828 Test loss=0.333817 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3464328348636627
[5/24] Train loss=0.3515550196170807
[10/24] Train loss=0.3768700361251831
[15/24] Train loss=0.32573994994163513
[20/24] Train loss=0.33049312233924866
Test set avg_accuracy=84.97% avg_sensitivity=60.88%, avg_specificity=93.19% avg_auc=90.81%
Best model saved!! Metric=3.8568895103891165!!
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.351771 Test loss=0.334647 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3467440903186798
[5/24] Train loss=0.3478010892868042
[10/24] Train loss=0.37481799721717834
[15/24] Train loss=0.3301827907562256
[20/24] Train loss=0.3406965732574463
Test set avg_accuracy=85.29% avg_sensitivity=64.82%, avg_specificity=92.26% avg_auc=90.66%
Best model saved!! Metric=7.0374748663502515!!
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.351895 Test loss=0.338323 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3528338670730591
[5/24] Train loss=0.35120248794555664
[10/24] Train loss=0.37577149271965027
[15/24] Train loss=0.32241183519363403
[20/24] Train loss=0.34431758522987366
Test set avg_accuracy=85.20% avg_sensitivity=63.39%, avg_specificity=92.63% avg_auc=90.54%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.350084 Test loss=0.339240 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.35040798783302307
[5/24] Train loss=0.352957159280777
[10/24] Train loss=0.3777579069137573
[15/24] Train loss=0.3190624415874481
[20/24] Train loss=0.33572617173194885
Test set avg_accuracy=85.05% avg_sensitivity=61.75%, avg_specificity=93.00% avg_auc=90.61%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.348948 Test loss=0.337195 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.35030898451805115
[5/24] Train loss=0.35002225637435913
[10/24] Train loss=0.37709569931030273
[15/24] Train loss=0.32232943177223206
[20/24] Train loss=0.3368005156517029
Test set avg_accuracy=85.16% avg_sensitivity=61.65%, avg_specificity=93.17% avg_auc=90.51%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.348710 Test loss=0.337788 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3469541668891907
[5/24] Train loss=0.35130617022514343
[10/24] Train loss=0.3745471239089966
[15/24] Train loss=0.3197363018989563
[20/24] Train loss=0.34116142988204956
Test set avg_accuracy=85.07% avg_sensitivity=61.96%, avg_specificity=92.95% avg_auc=90.51%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.348346 Test loss=0.338300 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3498919606208801
[5/24] Train loss=0.35106927156448364
[10/24] Train loss=0.3808748424053192
[15/24] Train loss=0.3202696740627289
[20/24] Train loss=0.3329719603061676
Test set avg_accuracy=85.16% avg_sensitivity=62.06%, avg_specificity=93.03% avg_auc=90.63%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.347665 Test loss=0.335888 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3445889949798584
[5/24] Train loss=0.34911733865737915
[10/24] Train loss=0.37720179557800293
[15/24] Train loss=0.3170519173145294
[20/24] Train loss=0.3337225914001465
Test set avg_accuracy=85.18% avg_sensitivity=62.01%, avg_specificity=93.09% avg_auc=90.56%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.346021 Test loss=0.336781 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3463686406612396
[5/24] Train loss=0.3501223623752594
[10/24] Train loss=0.372043639421463
[15/24] Train loss=0.31767919659614563
[20/24] Train loss=0.3347238600254059
Test set avg_accuracy=85.16% avg_sensitivity=61.75%, avg_specificity=93.14% avg_auc=90.48%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.346773 Test loss=0.337914 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.35314109921455383
[5/24] Train loss=0.3486429452896118
[10/24] Train loss=0.3790549039840698
[15/24] Train loss=0.31741851568222046
[20/24] Train loss=0.330835223197937
Test set avg_accuracy=85.10% avg_sensitivity=60.06%, avg_specificity=93.64% avg_auc=90.51%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.347108 Test loss=0.336416 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3474366068840027
[5/24] Train loss=0.3478944003582001
[10/24] Train loss=0.3745836317539215
[15/24] Train loss=0.31842243671417236
[20/24] Train loss=0.32981786131858826
Test set avg_accuracy=84.86% avg_sensitivity=59.75%, avg_specificity=93.42% avg_auc=90.48%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.345317 Test loss=0.336891 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.34491661190986633
[5/24] Train loss=0.3493136167526245
[10/24] Train loss=0.3815322816371918
[15/24] Train loss=0.31404760479927063
[20/24] Train loss=0.33497264981269836
Test set avg_accuracy=85.01% avg_sensitivity=61.19%, avg_specificity=93.14% avg_auc=90.54%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.346234 Test loss=0.336407 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.34692955017089844
[5/24] Train loss=0.354792058467865
[10/24] Train loss=0.3747204542160034
[15/24] Train loss=0.31824231147766113
[20/24] Train loss=0.3312799632549286
Test set avg_accuracy=85.05% avg_sensitivity=61.29%, avg_specificity=93.16% avg_auc=90.74%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.346517 Test loss=0.333251 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.34114235639572144
[5/24] Train loss=0.3472035825252533
[10/24] Train loss=0.3754422664642334
[15/24] Train loss=0.3190864026546478
[20/24] Train loss=0.3313260078430176
Test set avg_accuracy=85.31% avg_sensitivity=62.98%, avg_specificity=92.93% avg_auc=90.94%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.346244 Test loss=0.331601 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3440195322036743
[5/24] Train loss=0.34877896308898926
[10/24] Train loss=0.37913668155670166
[15/24] Train loss=0.3192490041255951
[20/24] Train loss=0.3330449163913727
Test set avg_accuracy=85.12% avg_sensitivity=63.75%, avg_specificity=92.40% avg_auc=91.00%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.345837 Test loss=0.330871 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3418513834476471
[5/24] Train loss=0.3497539758682251
[10/24] Train loss=0.37754929065704346
[15/24] Train loss=0.3191034495830536
[20/24] Train loss=0.32433658838272095
Test set avg_accuracy=85.17% avg_sensitivity=63.54%, avg_specificity=92.54% avg_auc=90.98%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.345449 Test loss=0.330318 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.337679386138916
[5/24] Train loss=0.3482256531715393
[10/24] Train loss=0.3770594894886017
[15/24] Train loss=0.3153535723686218
[20/24] Train loss=0.32780686020851135
Test set avg_accuracy=85.22% avg_sensitivity=63.90%, avg_specificity=92.49% avg_auc=91.03%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.343081 Test loss=0.330231 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3371957540512085
[5/24] Train loss=0.3482206463813782
[10/24] Train loss=0.3744308650493622
[15/24] Train loss=0.3154899775981903
[20/24] Train loss=0.32554036378860474
Test set avg_accuracy=84.96% avg_sensitivity=62.78%, avg_specificity=92.53% avg_auc=90.96%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.342730 Test loss=0.330132 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.33836111426353455
[5/24] Train loss=0.34769487380981445
[10/24] Train loss=0.3764018714427948
[15/24] Train loss=0.31527113914489746
[20/24] Train loss=0.3247101902961731
Test set avg_accuracy=85.09% avg_sensitivity=63.13%, avg_specificity=92.58% avg_auc=90.97%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.342774 Test loss=0.330763 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3379804193973541
[5/24] Train loss=0.3495261073112488
[10/24] Train loss=0.37884005904197693
[15/24] Train loss=0.3125186562538147
[20/24] Train loss=0.3241950571537018
Test set avg_accuracy=85.08% avg_sensitivity=62.88%, avg_specificity=92.65% avg_auc=90.98%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.343421 Test loss=0.329786 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.33841484785079956
[5/24] Train loss=0.3462424874305725
[10/24] Train loss=0.3777806758880615
[15/24] Train loss=0.3123473525047302
[20/24] Train loss=0.32235631346702576
Test set avg_accuracy=84.99% avg_sensitivity=62.88%, avg_specificity=92.53% avg_auc=91.00%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.341973 Test loss=0.329502 Current lr=[0.000156543481933168]

[0/24] Train loss=0.33564767241477966
[5/24] Train loss=0.3477264642715454
[10/24] Train loss=0.37573695182800293
[15/24] Train loss=0.31158608198165894
[20/24] Train loss=0.3244345486164093
Test set avg_accuracy=85.08% avg_sensitivity=62.47%, avg_specificity=92.79% avg_auc=91.02%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.341169 Test loss=0.329013 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.34083741903305054
[5/24] Train loss=0.3452391028404236
[10/24] Train loss=0.3776567578315735
[15/24] Train loss=0.3109818994998932
[20/24] Train loss=0.3215889036655426
Test set avg_accuracy=85.01% avg_sensitivity=63.24%, avg_specificity=92.44% avg_auc=91.05%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.341392 Test loss=0.328679 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3351757824420929
[5/24] Train loss=0.3460180461406708
[10/24] Train loss=0.38145315647125244
[15/24] Train loss=0.30879631638526917
[20/24] Train loss=0.31809839606285095
Test set avg_accuracy=84.96% avg_sensitivity=62.78%, avg_specificity=92.53% avg_auc=91.03%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.341801 Test loss=0.328420 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3353177011013031
[5/24] Train loss=0.34392398595809937
[10/24] Train loss=0.3799605667591095
[15/24] Train loss=0.31151002645492554
[20/24] Train loss=0.3192542493343353
Test set avg_accuracy=84.96% avg_sensitivity=62.98%, avg_specificity=92.46% avg_auc=91.06%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.341829 Test loss=0.328328 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3320561349391937
[5/24] Train loss=0.345600962638855
[10/24] Train loss=0.3851430416107178
[15/24] Train loss=0.31420937180519104
[20/24] Train loss=0.31876805424690247
Test set avg_accuracy=85.00% avg_sensitivity=63.90%, avg_specificity=92.19% avg_auc=91.03%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.342523 Test loss=0.329397 Current lr=[0.000134135431043539]

[0/24] Train loss=0.33888664841651917
[5/24] Train loss=0.35260525345802307
[10/24] Train loss=0.3920309841632843
[15/24] Train loss=0.3137224316596985
[20/24] Train loss=0.31588244438171387
Test set avg_accuracy=84.95% avg_sensitivity=67.49%, avg_specificity=90.90% avg_auc=91.04%
Best model saved!! Metric=8.37487716343233!!
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.344884 Test loss=0.332873 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3411925137042999
[5/24] Train loss=0.35510990023612976
[10/24] Train loss=0.3923989236354828
[15/24] Train loss=0.3141508400440216
[20/24] Train loss=0.3226369023323059
Test set avg_accuracy=84.11% avg_sensitivity=71.22%, avg_specificity=88.51% avg_auc=90.98%
Best model saved!! Metric=8.82772329941777!!
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.345921 Test loss=0.341742 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.35111862421035767
[5/24] Train loss=0.3640478253364563
[10/24] Train loss=0.39273861050605774
[15/24] Train loss=0.31076666712760925
[20/24] Train loss=0.3443657159805298
Test set avg_accuracy=84.13% avg_sensitivity=73.73%, avg_specificity=87.67% avg_auc=90.81%
Best model saved!! Metric=10.34571099367193!!
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.348362 Test loss=0.350976 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3647536039352417
[5/24] Train loss=0.35815298557281494
[10/24] Train loss=0.381027489900589
[15/24] Train loss=0.3211616575717926
[20/24] Train loss=0.35743725299835205
Test set avg_accuracy=84.90% avg_sensitivity=69.18%, avg_specificity=90.26% avg_auc=91.01%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.348748 Test loss=0.337980 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3483959436416626
[5/24] Train loss=0.3444383442401886
[10/24] Train loss=0.37405505776405334
[15/24] Train loss=0.319650799036026
[20/24] Train loss=0.3455376625061035
Test set avg_accuracy=85.17% avg_sensitivity=66.15%, avg_specificity=91.65% avg_auc=91.07%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.342966 Test loss=0.332108 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3413344919681549
[5/24] Train loss=0.3435851037502289
[10/24] Train loss=0.3742888569831848
[15/24] Train loss=0.3175272047519684
[20/24] Train loss=0.3390744924545288
Test set avg_accuracy=85.03% avg_sensitivity=66.56%, avg_specificity=91.32% avg_auc=91.05%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.340913 Test loss=0.333697 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3420830965042114
[5/24] Train loss=0.3463057279586792
[10/24] Train loss=0.37830448150634766
[15/24] Train loss=0.31842294335365295
[20/24] Train loss=0.3425891697406769
Test set avg_accuracy=85.10% avg_sensitivity=66.87%, avg_specificity=91.32% avg_auc=91.03%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.342666 Test loss=0.334651 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.34230121970176697
[5/24] Train loss=0.34747055172920227
[10/24] Train loss=0.37388789653778076
[15/24] Train loss=0.316861093044281
[20/24] Train loss=0.34081515669822693
Test set avg_accuracy=85.14% avg_sensitivity=65.95%, avg_specificity=91.69% avg_auc=91.07%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.340723 Test loss=0.332012 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3392026722431183
[5/24] Train loss=0.35121428966522217
[10/24] Train loss=0.37306472659111023
[15/24] Train loss=0.31982576847076416
[20/24] Train loss=0.3455778956413269
Test set avg_accuracy=85.20% avg_sensitivity=65.34%, avg_specificity=91.97% avg_auc=91.12%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.340703 Test loss=0.330821 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.34051084518432617
[5/24] Train loss=0.3453546166419983
[10/24] Train loss=0.3756420314311981
[15/24] Train loss=0.31622034311294556
[20/24] Train loss=0.337825208902359
Test set avg_accuracy=85.31% avg_sensitivity=65.80%, avg_specificity=91.97% avg_auc=91.13%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.340168 Test loss=0.331415 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3404156565666199
[5/24] Train loss=0.3487481474876404
[10/24] Train loss=0.3751070499420166
[15/24] Train loss=0.31753599643707275
[20/24] Train loss=0.338853120803833
Test set avg_accuracy=85.42% avg_sensitivity=65.90%, avg_specificity=92.07% avg_auc=91.14%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.339959 Test loss=0.330927 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3405711054801941
[5/24] Train loss=0.3401744067668915
[10/24] Train loss=0.3743284046649933
[15/24] Train loss=0.3162098824977875
[20/24] Train loss=0.33600732684135437
Test set avg_accuracy=85.46% avg_sensitivity=64.72%, avg_specificity=92.53% avg_auc=91.16%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.338280 Test loss=0.329384 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3318140208721161
[5/24] Train loss=0.34393423795700073
[10/24] Train loss=0.37627938389778137
[15/24] Train loss=0.31226739287376404
[20/24] Train loss=0.338977187871933
Test set avg_accuracy=85.42% avg_sensitivity=64.87%, avg_specificity=92.42% avg_auc=91.18%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.338638 Test loss=0.330087 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3381398618221283
[5/24] Train loss=0.34143948554992676
[10/24] Train loss=0.3743723928928375
[15/24] Train loss=0.3115522563457489
[20/24] Train loss=0.3362322151660919
Test set avg_accuracy=85.49% avg_sensitivity=64.62%, avg_specificity=92.61% avg_auc=91.19%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.337854 Test loss=0.328808 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3320060074329376
[5/24] Train loss=0.3441897928714752
[10/24] Train loss=0.37230029702186584
[15/24] Train loss=0.31499895453453064
[20/24] Train loss=0.3334256708621979
Test set avg_accuracy=85.30% avg_sensitivity=63.90%, avg_specificity=92.60% avg_auc=91.21%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.337490 Test loss=0.328541 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.33436840772628784
[5/24] Train loss=0.34575483202934265
[10/24] Train loss=0.37577924132347107
[15/24] Train loss=0.315929651260376
[20/24] Train loss=0.33414772152900696
Test set avg_accuracy=85.39% avg_sensitivity=64.21%, avg_specificity=92.61% avg_auc=91.22%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.338174 Test loss=0.328418 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3319750130176544
[5/24] Train loss=0.3388842046260834
[10/24] Train loss=0.3723433315753937
[15/24] Train loss=0.314451664686203
[20/24] Train loss=0.3319339156150818
Test set avg_accuracy=85.31% avg_sensitivity=63.85%, avg_specificity=92.63% avg_auc=91.22%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.337211 Test loss=0.328154 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3361491560935974
[5/24] Train loss=0.3414069712162018
[10/24] Train loss=0.37319016456604004
[15/24] Train loss=0.3143356144428253
[20/24] Train loss=0.335312157869339
Test set avg_accuracy=85.20% avg_sensitivity=63.54%, avg_specificity=92.58% avg_auc=91.22%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.337015 Test loss=0.327639 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.33099016547203064
[5/24] Train loss=0.34244903922080994
[10/24] Train loss=0.3718143105506897
[15/24] Train loss=0.3124426305294037
[20/24] Train loss=0.3349401652812958
Test set avg_accuracy=85.14% avg_sensitivity=62.78%, avg_specificity=92.77% avg_auc=91.23%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.336354 Test loss=0.326988 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3318875730037689
[5/24] Train loss=0.3411242365837097
[10/24] Train loss=0.3712178170681
[15/24] Train loss=0.31653180718421936
[20/24] Train loss=0.331219881772995
Test set avg_accuracy=85.16% avg_sensitivity=62.16%, avg_specificity=93.00% avg_auc=91.21%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.335878 Test loss=0.327097 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.33365508913993835
[5/24] Train loss=0.34533095359802246
[10/24] Train loss=0.370430052280426
[15/24] Train loss=0.31469136476516724
[20/24] Train loss=0.33396345376968384
Test set avg_accuracy=85.23% avg_sensitivity=61.90%, avg_specificity=93.19% avg_auc=91.23%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.336565 Test loss=0.326855 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3329935371875763
[5/24] Train loss=0.3416714668273926
[10/24] Train loss=0.37246331572532654
[15/24] Train loss=0.3144966959953308
[20/24] Train loss=0.32814258337020874
Test set avg_accuracy=85.27% avg_sensitivity=61.29%, avg_specificity=93.45% avg_auc=91.24%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.335669 Test loss=0.326421 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.33107689023017883
[5/24] Train loss=0.3418816328048706
[10/24] Train loss=0.37034153938293457
[15/24] Train loss=0.31522220373153687
[20/24] Train loss=0.32587581872940063
Test set avg_accuracy=85.23% avg_sensitivity=60.93%, avg_specificity=93.52% avg_auc=91.24%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.335458 Test loss=0.326229 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.33143725991249084
[5/24] Train loss=0.3422965407371521
[10/24] Train loss=0.37185317277908325
[15/24] Train loss=0.3079826533794403
[20/24] Train loss=0.3267263174057007
Test set avg_accuracy=85.14% avg_sensitivity=60.47%, avg_specificity=93.56% avg_auc=91.24%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.334496 Test loss=0.325878 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.326198935508728
[5/24] Train loss=0.34446170926094055
[10/24] Train loss=0.37230926752090454
[15/24] Train loss=0.3128041625022888
[20/24] Train loss=0.32681798934936523
Test set avg_accuracy=84.95% avg_sensitivity=59.19%, avg_specificity=93.73% avg_auc=91.25%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.335127 Test loss=0.326030 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.327706903219223
[5/24] Train loss=0.34574440121650696
[10/24] Train loss=0.3697197139263153
[15/24] Train loss=0.31614965200424194
[20/24] Train loss=0.32269641757011414
Test set avg_accuracy=84.93% avg_sensitivity=58.17%, avg_specificity=94.06% avg_auc=91.26%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.335643 Test loss=0.326180 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3292829394340515
[5/24] Train loss=0.3407667279243469
[10/24] Train loss=0.3719026744365692
[15/24] Train loss=0.31470850110054016
[20/24] Train loss=0.32557743787765503
Test set avg_accuracy=85.13% avg_sensitivity=58.58%, avg_specificity=94.19% avg_auc=91.24%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.335603 Test loss=0.326071 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3294520676136017
[5/24] Train loss=0.34626543521881104
[10/24] Train loss=0.3694678544998169
[15/24] Train loss=0.32062944769859314
[20/24] Train loss=0.32166844606399536
Test set avg_accuracy=84.92% avg_sensitivity=59.09%, avg_specificity=93.73% avg_auc=91.24%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.335553 Test loss=0.325847 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3289571702480316
[5/24] Train loss=0.34515461325645447
[10/24] Train loss=0.37562790513038635
[15/24] Train loss=0.31832441687583923
[20/24] Train loss=0.3179242014884949
Test set avg_accuracy=85.30% avg_sensitivity=61.90%, avg_specificity=93.28% avg_auc=91.27%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.336929 Test loss=0.325836 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.32892099022865295
[5/24] Train loss=0.343312531709671
[10/24] Train loss=0.36580488085746765
[15/24] Train loss=0.3166951537132263
[20/24] Train loss=0.30994799733161926
Test set avg_accuracy=85.13% avg_sensitivity=64.00%, avg_specificity=92.33% avg_auc=91.24%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.335702 Test loss=0.327343 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.33148324489593506
[5/24] Train loss=0.3488549590110779
[10/24] Train loss=0.37064269185066223
[15/24] Train loss=0.30978667736053467
[20/24] Train loss=0.31306540966033936
Test set avg_accuracy=85.34% avg_sensitivity=66.46%, avg_specificity=91.78% avg_auc=91.23%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.335554 Test loss=0.329462 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.33853793144226074
[5/24] Train loss=0.33995988965034485
[10/24] Train loss=0.37301185727119446
[15/24] Train loss=0.3067505657672882
[20/24] Train loss=0.3166687786579132
Test set avg_accuracy=85.39% avg_sensitivity=66.77%, avg_specificity=91.74% avg_auc=91.20%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.335073 Test loss=0.330231 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.33611974120140076
[5/24] Train loss=0.3402305245399475
[10/24] Train loss=0.36791136860847473
[15/24] Train loss=0.3065802752971649
[20/24] Train loss=0.32079795002937317
Test set avg_accuracy=85.22% avg_sensitivity=64.82%, avg_specificity=92.18% avg_auc=91.23%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.334370 Test loss=0.328666 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.3309169411659241
[5/24] Train loss=0.3376704156398773
[10/24] Train loss=0.37124255299568176
[15/24] Train loss=0.30634424090385437
[20/24] Train loss=0.32127195596694946
Test set avg_accuracy=85.17% avg_sensitivity=64.26%, avg_specificity=92.30% avg_auc=91.22%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.332680 Test loss=0.327881 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.32937031984329224
[5/24] Train loss=0.33676964044570923
[10/24] Train loss=0.37107059359550476
[15/24] Train loss=0.30779018998146057
[20/24] Train loss=0.316532164812088
Test set avg_accuracy=85.20% avg_sensitivity=64.26%, avg_specificity=92.33% avg_auc=91.25%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.333111 Test loss=0.327467 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3339706063270569
[5/24] Train loss=0.3375363349914551
[10/24] Train loss=0.3695653975009918
[15/24] Train loss=0.30867108702659607
[20/24] Train loss=0.315292090177536
Test set avg_accuracy=85.21% avg_sensitivity=64.36%, avg_specificity=92.32% avg_auc=91.27%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.333372 Test loss=0.327442 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.3317277133464813
[5/24] Train loss=0.3395795226097107
[10/24] Train loss=0.37060311436653137
[15/24] Train loss=0.31191715598106384
[20/24] Train loss=0.3150998651981354
Test set avg_accuracy=85.13% avg_sensitivity=63.95%, avg_specificity=92.35% avg_auc=91.26%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.333457 Test loss=0.327013 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.3341224193572998
[5/24] Train loss=0.34167924523353577
[10/24] Train loss=0.37518349289894104
[15/24] Train loss=0.3051525354385376
[20/24] Train loss=0.3168758451938629
Test set avg_accuracy=85.17% avg_sensitivity=64.16%, avg_specificity=92.33% avg_auc=91.26%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.333107 Test loss=0.327151 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.33553892374038696
[5/24] Train loss=0.3359287977218628
[10/24] Train loss=0.36378055810928345
[15/24] Train loss=0.3093422055244446
[20/24] Train loss=0.318327397108078
Test set avg_accuracy=85.18% avg_sensitivity=63.70%, avg_specificity=92.51% avg_auc=91.28%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.333447 Test loss=0.326640 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.33322328329086304
[5/24] Train loss=0.34200185537338257
[10/24] Train loss=0.37106621265411377
[15/24] Train loss=0.30828413367271423
[20/24] Train loss=0.3163595497608185
Test set avg_accuracy=85.16% avg_sensitivity=63.49%, avg_specificity=92.54% avg_auc=91.28%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.333503 Test loss=0.326591 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.331463098526001
[5/24] Train loss=0.33965983986854553
[10/24] Train loss=0.37321412563323975
[15/24] Train loss=0.30474451184272766
[20/24] Train loss=0.31675881147384644
Test set avg_accuracy=85.04% avg_sensitivity=63.39%, avg_specificity=92.42% avg_auc=91.28%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.332819 Test loss=0.326657 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.3277067244052887
[5/24] Train loss=0.3406517803668976
[10/24] Train loss=0.3714272379875183
[15/24] Train loss=0.3121960461139679
[20/24] Train loss=0.3169221580028534
Test set avg_accuracy=85.07% avg_sensitivity=63.29%, avg_specificity=92.49% avg_auc=91.28%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.333131 Test loss=0.326509 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3297159671783447
[5/24] Train loss=0.3364536762237549
[10/24] Train loss=0.3662664294242859
[15/24] Train loss=0.30503952503204346
[20/24] Train loss=0.3184575140476227
Test set avg_accuracy=85.14% avg_sensitivity=63.29%, avg_specificity=92.60% avg_auc=91.28%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.332885 Test loss=0.326466 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3318735957145691
[5/24] Train loss=0.33905160427093506
[10/24] Train loss=0.37228327989578247
[15/24] Train loss=0.30713799595832825
[20/24] Train loss=0.31820952892303467
Test set avg_accuracy=85.14% avg_sensitivity=63.29%, avg_specificity=92.60% avg_auc=91.28%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.332462 Test loss=0.326402 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3264916241168976
[5/24] Train loss=0.33705002069473267
[10/24] Train loss=0.37365102767944336
[15/24] Train loss=0.309897780418396
[20/24] Train loss=0.3160407841205597
Test set avg_accuracy=85.14% avg_sensitivity=63.29%, avg_specificity=92.60% avg_auc=91.28%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.332484 Test loss=0.326342 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.33421212434768677
[5/24] Train loss=0.3366479277610779
[10/24] Train loss=0.3738982081413269
[15/24] Train loss=0.30595850944519043
[20/24] Train loss=0.317268967628479
Test set avg_accuracy=85.17% avg_sensitivity=63.29%, avg_specificity=92.63% avg_auc=91.28%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.332898 Test loss=0.326333 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.33266332745552063
[5/24] Train loss=0.3358364403247833
[10/24] Train loss=0.37245461344718933
[15/24] Train loss=0.3116183876991272
[20/24] Train loss=0.31527984142303467
Test set avg_accuracy=85.17% avg_sensitivity=63.29%, avg_specificity=92.63% avg_auc=91.28%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.333737 Test loss=0.326329 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3285631537437439
[5/24] Train loss=0.33854949474334717
[10/24] Train loss=0.3711008131504059
[15/24] Train loss=0.30686551332473755
[20/24] Train loss=0.3197599947452545
Test set avg_accuracy=85.17% avg_sensitivity=63.29%, avg_specificity=92.63% avg_auc=91.28%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.333284 Test loss=0.326326 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3299961984157562
[5/24] Train loss=0.3380666971206665
[10/24] Train loss=0.36974990367889404
[15/24] Train loss=0.3073540925979614
[20/24] Train loss=0.31877461075782776
Test set avg_accuracy=85.17% avg_sensitivity=63.29%, avg_specificity=92.63% avg_auc=91.28%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.331918 Test loss=0.326322 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=84.13% sen=73.73%, spe=87.67%, auc=90.81%!
Fold[5] Avg_overlap=0.64%(0.2517136576395018)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'HybridCNNRNN',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.8344998955726624
[5/24] Train loss=0.7098654508590698
[10/24] Train loss=0.6606459617614746
[15/24] Train loss=0.6164523363113403
[20/24] Train loss=0.6212843060493469
Test set avg_accuracy=72.85% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=51.65%
Best model saved!! Metric=-101.5185887871135!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.671788 Test loss=0.592177 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6110244989395142
[5/24] Train loss=0.5804378986358643
[10/24] Train loss=0.5873450636863708
[15/24] Train loss=0.5731166005134583
[20/24] Train loss=0.5979886651039124
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.95%
Best model saved!! Metric=-98.1839003656071!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.595203 Test loss=0.581538 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.596564531326294
[5/24] Train loss=0.5685409903526306
[10/24] Train loss=0.5878728628158569
[15/24] Train loss=0.5684818029403687
[20/24] Train loss=0.5861209034919739
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=58.52%
Best model saved!! Metric=-94.6176062687817!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.586931 Test loss=0.575927 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.595281720161438
[5/24] Train loss=0.5659078359603882
[10/24] Train loss=0.582444965839386
[15/24] Train loss=0.5658944249153137
[20/24] Train loss=0.5790124535560608
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=61.81%
Best model saved!! Metric=-91.32303937221863!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.581066 Test loss=0.570418 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5734081864356995
[5/24] Train loss=0.5597854852676392
[10/24] Train loss=0.5704768300056458
[15/24] Train loss=0.5499734282493591
[20/24] Train loss=0.5733255743980408
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=65.87%
Best model saved!! Metric=-87.26795101050152!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.571414 Test loss=0.562856 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5685544610023499
[5/24] Train loss=0.5488126277923584
[10/24] Train loss=0.5622254610061646
[15/24] Train loss=0.5452543497085571
[20/24] Train loss=0.5587646961212158
Test set avg_accuracy=72.85% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=69.86%
Best model saved!! Metric=-83.30542343319331!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.563703 Test loss=0.554385 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5600524544715881
[5/24] Train loss=0.5414098501205444
[10/24] Train loss=0.5582205653190613
[15/24] Train loss=0.5362317562103271
[20/24] Train loss=0.556581437587738
Test set avg_accuracy=72.84% avg_sensitivity=0.00%, avg_specificity=99.96% avg_auc=72.75%
Best model saved!! Metric=-80.44812474161235!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.555222 Test loss=0.545869 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5532079339027405
[5/24] Train loss=0.5274075269699097
[10/24] Train loss=0.5485466122627258
[15/24] Train loss=0.5289216637611389
[20/24] Train loss=0.543418288230896
Test set avg_accuracy=72.81% avg_sensitivity=0.10%, avg_specificity=99.89% avg_auc=75.36%
Best model saved!! Metric=-77.83574408440907!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.544959 Test loss=0.535712 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5392239093780518
[5/24] Train loss=0.5181591510772705
[10/24] Train loss=0.5384580492973328
[15/24] Train loss=0.5098797082901001
[20/24] Train loss=0.530916154384613
Test set avg_accuracy=72.66% avg_sensitivity=0.62%, avg_specificity=99.48% avg_auc=77.55%
Best model saved!! Metric=-75.68916844393925!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.532686 Test loss=0.523721 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5275344848632812
[5/24] Train loss=0.5092554688453674
[10/24] Train loss=0.5233940482139587
[15/24] Train loss=0.49755969643592834
[20/24] Train loss=0.5150704383850098
Test set avg_accuracy=72.98% avg_sensitivity=1.44%, avg_specificity=99.62% avg_auc=78.62%
Best model saved!! Metric=-73.33228335124325!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.520779 Test loss=0.512753 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5158568024635315
[5/24] Train loss=0.48797082901000977
[10/24] Train loss=0.5136246085166931
[15/24] Train loss=0.47658342123031616
[20/24] Train loss=0.5006465911865234
Test set avg_accuracy=73.02% avg_sensitivity=3.93%, avg_specificity=98.75% avg_auc=80.14%
Best model saved!! Metric=-70.15658911950177!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.507002 Test loss=0.498816 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.48993080854415894
[5/24] Train loss=0.4677240252494812
[10/24] Train loss=0.5066295862197876
[15/24] Train loss=0.45991238951683044
[20/24] Train loss=0.47906294465065
Test set avg_accuracy=73.39% avg_sensitivity=8.35%, avg_specificity=97.61% avg_auc=81.74%
Best model saved!! Metric=-64.91507319516224!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.491604 Test loss=0.481571 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4733802080154419
[5/24] Train loss=0.4592640697956085
[10/24] Train loss=0.48776304721832275
[15/24] Train loss=0.44977355003356934
[20/24] Train loss=0.466105192899704
Test set avg_accuracy=74.83% avg_sensitivity=16.51%, avg_specificity=96.55% avg_auc=83.22%
Best model saved!! Metric=-54.89460195825255!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.477176 Test loss=0.464228 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4661747217178345
[5/24] Train loss=0.4439360499382019
[10/24] Train loss=0.4821021556854248
[15/24] Train loss=0.4374377727508545
[20/24] Train loss=0.4552597999572754
Test set avg_accuracy=76.12% avg_sensitivity=25.38%, avg_specificity=95.01% avg_auc=84.61%
Best model saved!! Metric=-44.8716866857073!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.464026 Test loss=0.446668 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.45192965865135193
[5/24] Train loss=0.43019163608551025
[10/24] Train loss=0.45689335465431213
[15/24] Train loss=0.42415353655815125
[20/24] Train loss=0.44099780917167664
Test set avg_accuracy=77.58% avg_sensitivity=34.55%, avg_specificity=93.60% avg_auc=85.59%
Best model saved!! Metric=-34.68464546670298!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.449449 Test loss=0.431507 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4456654489040375
[5/24] Train loss=0.4211406707763672
[10/24] Train loss=0.44879356026649475
[15/24] Train loss=0.40905216336250305
[20/24] Train loss=0.4284191429615021
Test set avg_accuracy=78.80% avg_sensitivity=41.12%, avg_specificity=92.83% avg_auc=86.41%
Best model saved!! Metric=-26.83310817307582!!
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.438547 Test loss=0.418264 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4335233271121979
[5/24] Train loss=0.41152045130729675
[10/24] Train loss=0.4423791170120239
[15/24] Train loss=0.39584651589393616
[20/24] Train loss=0.40518707036972046
Test set avg_accuracy=79.54% avg_sensitivity=40.60%, avg_specificity=94.05% avg_auc=87.10%
Best model saved!! Metric=-24.70757206514505!!
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.426937 Test loss=0.405796 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.41463103890419006
[5/24] Train loss=0.39982855319976807
[10/24] Train loss=0.4319663941860199
[15/24] Train loss=0.38323652744293213
[20/24] Train loss=0.3985661268234253
Test set avg_accuracy=79.54% avg_sensitivity=38.92%, avg_specificity=94.67% avg_auc=87.73%
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.416293 Test loss=0.396356 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.40031400322914124
[5/24] Train loss=0.38579562306404114
[10/24] Train loss=0.4058954119682312
[15/24] Train loss=0.37628844380378723
[20/24] Train loss=0.38771551847457886
Test set avg_accuracy=80.61% avg_sensitivity=44.15%, avg_specificity=94.19% avg_auc=88.24%
Best model saved!! Metric=-18.81063710434676!!
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.406528 Test loss=0.386556 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.38891905546188354
[5/24] Train loss=0.37269359827041626
[10/24] Train loss=0.40175414085388184
[15/24] Train loss=0.37224650382995605
[20/24] Train loss=0.37348473072052
Test set avg_accuracy=82.02% avg_sensitivity=48.32%, avg_specificity=94.57% avg_auc=88.81%
Best model saved!! Metric=-12.286120732287756!!
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.397172 Test loss=0.377824 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3767271637916565
[5/24] Train loss=0.3672122657299042
[10/24] Train loss=0.3921188414096832
[15/24] Train loss=0.3657057285308838
[20/24] Train loss=0.3720704913139343
Test set avg_accuracy=82.84% avg_sensitivity=51.30%, avg_specificity=94.59% avg_auc=89.12%
Best model saved!! Metric=-8.163065253000397!!
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.393708 Test loss=0.370812 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.37106776237487793
[5/24] Train loss=0.3689485788345337
[10/24] Train loss=0.3853583037853241
[15/24] Train loss=0.37052252888679504
[20/24] Train loss=0.3644481301307678
Test set avg_accuracy=83.59% avg_sensitivity=57.53%, avg_specificity=93.30% avg_auc=89.30%
Best model saved!! Metric=-2.27349133909744!!
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.391432 Test loss=0.366548 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3733467161655426
[5/24] Train loss=0.3550666868686676
[10/24] Train loss=0.3799152970314026
[15/24] Train loss=0.35323864221572876
[20/24] Train loss=0.36618074774742126
Test set avg_accuracy=83.68% avg_sensitivity=57.73%, avg_specificity=93.35% avg_auc=89.64%
Best model saved!! Metric=-1.5940791405649506!!
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.384283 Test loss=0.361121 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3679598271846771
[5/24] Train loss=0.36361491680145264
[10/24] Train loss=0.37714138627052307
[15/24] Train loss=0.35285285115242004
[20/24] Train loss=0.35233989357948303
Test set avg_accuracy=83.74% avg_sensitivity=54.51%, avg_specificity=94.62% avg_auc=89.68%
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.381408 Test loss=0.359346 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3574223518371582
[5/24] Train loss=0.3584102690219879
[10/24] Train loss=0.3760828971862793
[15/24] Train loss=0.3550766706466675
[20/24] Train loss=0.354140967130661
Test set avg_accuracy=83.93% avg_sensitivity=56.67%, avg_specificity=94.09% avg_auc=89.79%
Best model saved!! Metric=-1.5244219991132226!!
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.379324 Test loss=0.356764 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3575628995895386
[5/24] Train loss=0.35054025053977966
[10/24] Train loss=0.37507104873657227
[15/24] Train loss=0.34591996669769287
[20/24] Train loss=0.3402702510356903
Test set avg_accuracy=84.04% avg_sensitivity=55.57%, avg_specificity=94.64% avg_auc=89.90%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.375300 Test loss=0.355590 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.35773926973342896
[5/24] Train loss=0.35077959299087524
[10/24] Train loss=0.36792775988578796
[15/24] Train loss=0.34198349714279175
[20/24] Train loss=0.33730730414390564
Test set avg_accuracy=84.23% avg_sensitivity=54.03%, avg_specificity=95.48% avg_auc=89.87%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.371908 Test loss=0.355318 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3465687334537506
[5/24] Train loss=0.34692081809043884
[10/24] Train loss=0.3629859387874603
[15/24] Train loss=0.3393060863018036
[20/24] Train loss=0.3351719081401825
Test set avg_accuracy=84.06% avg_sensitivity=51.68%, avg_specificity=96.12% avg_auc=90.04%
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.368390 Test loss=0.355128 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3456292748451233
[5/24] Train loss=0.3487733006477356
[10/24] Train loss=0.3675747215747833
[15/24] Train loss=0.3352830111980438
[20/24] Train loss=0.3314662575721741
Test set avg_accuracy=84.48% avg_sensitivity=52.40%, avg_specificity=96.43% avg_auc=90.04%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.368913 Test loss=0.354124 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3430122435092926
[5/24] Train loss=0.34433841705322266
[10/24] Train loss=0.3699682354927063
[15/24] Train loss=0.33572643995285034
[20/24] Train loss=0.33251333236694336
Test set avg_accuracy=84.47% avg_sensitivity=52.26%, avg_specificity=96.46% avg_auc=90.11%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.366564 Test loss=0.353873 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3448154330253601
[5/24] Train loss=0.3479713201522827
[10/24] Train loss=0.3634697496891022
[15/24] Train loss=0.33789515495300293
[20/24] Train loss=0.32673951983451843
Test set avg_accuracy=84.27% avg_sensitivity=51.01%, avg_specificity=96.66% avg_auc=90.02%
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.365479 Test loss=0.355245 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.34738972783088684
[5/24] Train loss=0.3457920253276825
[10/24] Train loss=0.36385422945022583
[15/24] Train loss=0.34124237298965454
[20/24] Train loss=0.33213889598846436
Test set avg_accuracy=84.69% avg_sensitivity=52.83%, avg_specificity=96.55% avg_auc=90.05%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.365257 Test loss=0.353687 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3422166109085083
[5/24] Train loss=0.34299778938293457
[10/24] Train loss=0.35896798968315125
[15/24] Train loss=0.33741602301597595
[20/24] Train loss=0.3267364799976349
Test set avg_accuracy=84.64% avg_sensitivity=52.06%, avg_specificity=96.77% avg_auc=90.20%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.362209 Test loss=0.352545 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.339786559343338
[5/24] Train loss=0.34614354372024536
[10/24] Train loss=0.35838815569877625
[15/24] Train loss=0.32972753047943115
[20/24] Train loss=0.32068711519241333
Test set avg_accuracy=83.71% avg_sensitivity=47.98%, avg_specificity=97.02% avg_auc=90.07%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.360423 Test loss=0.357342 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.342084139585495
[5/24] Train loss=0.34042346477508545
[10/24] Train loss=0.3607027232646942
[15/24] Train loss=0.33335843682289124
[20/24] Train loss=0.3213311731815338
Test set avg_accuracy=84.18% avg_sensitivity=49.90%, avg_specificity=96.94% avg_auc=90.13%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.360017 Test loss=0.355327 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3406287133693695
[5/24] Train loss=0.3458537459373474
[10/24] Train loss=0.3545990586280823
[15/24] Train loss=0.3266341984272003
[20/24] Train loss=0.3184523284435272
Test set avg_accuracy=83.84% avg_sensitivity=48.42%, avg_specificity=97.03% avg_auc=90.17%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.358008 Test loss=0.356696 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.33549201488494873
[5/24] Train loss=0.3415966033935547
[10/24] Train loss=0.3584098815917969
[15/24] Train loss=0.32462218403816223
[20/24] Train loss=0.3120439052581787
Test set avg_accuracy=84.00% avg_sensitivity=47.55%, avg_specificity=97.57% avg_auc=90.21%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.356316 Test loss=0.358291 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.33262306451797485
[5/24] Train loss=0.3419448435306549
[10/24] Train loss=0.35513848066329956
[15/24] Train loss=0.3286677300930023
[20/24] Train loss=0.32222774624824524
Test set avg_accuracy=83.97% avg_sensitivity=47.41%, avg_specificity=97.59% avg_auc=90.23%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.355426 Test loss=0.358667 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3329654335975647
[5/24] Train loss=0.3411003649234772
[10/24] Train loss=0.35442355275154114
[15/24] Train loss=0.3248327076435089
[20/24] Train loss=0.3178664743900299
Test set avg_accuracy=83.75% avg_sensitivity=46.50%, avg_specificity=97.62% avg_auc=90.28%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.353501 Test loss=0.359015 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.334642231464386
[5/24] Train loss=0.33732300996780396
[10/24] Train loss=0.3536929488182068
[15/24] Train loss=0.32279983162879944
[20/24] Train loss=0.31638720631599426
Test set avg_accuracy=83.89% avg_sensitivity=46.93%, avg_specificity=97.66% avg_auc=90.30%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.353126 Test loss=0.359290 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3351261019706726
[5/24] Train loss=0.33855313062667847
[10/24] Train loss=0.34826892614364624
[15/24] Train loss=0.324095755815506
[20/24] Train loss=0.31251564621925354
Test set avg_accuracy=84.00% avg_sensitivity=47.31%, avg_specificity=97.66% avg_auc=90.39%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.350369 Test loss=0.357825 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3330117464065552
[5/24] Train loss=0.3367481529712677
[10/24] Train loss=0.3474835157394409
[15/24] Train loss=0.32640302181243896
[20/24] Train loss=0.31276997923851013
Test set avg_accuracy=83.91% avg_sensitivity=46.64%, avg_specificity=97.78% avg_auc=90.38%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.348866 Test loss=0.357734 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.33071908354759216
[5/24] Train loss=0.3421132564544678
[10/24] Train loss=0.347705602645874
[15/24] Train loss=0.3253263831138611
[20/24] Train loss=0.310762494802475
Test set avg_accuracy=83.15% avg_sensitivity=43.76%, avg_specificity=97.82% avg_auc=90.35%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.347715 Test loss=0.361192 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3326764702796936
[5/24] Train loss=0.3409765064716339
[10/24] Train loss=0.34601616859436035
[15/24] Train loss=0.317818284034729
[20/24] Train loss=0.31028738617897034
Test set avg_accuracy=83.15% avg_sensitivity=43.81%, avg_specificity=97.80% avg_auc=90.38%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.346147 Test loss=0.360680 Current lr=[0.00029967723776099]

[0/24] Train loss=0.33321744203567505
[5/24] Train loss=0.3434644341468811
[10/24] Train loss=0.34450268745422363
[15/24] Train loss=0.3182331919670105
[20/24] Train loss=0.3113135099411011
Test set avg_accuracy=84.00% avg_sensitivity=47.31%, avg_specificity=97.66% avg_auc=90.53%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.346366 Test loss=0.355246 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3296443521976471
[5/24] Train loss=0.34255552291870117
[10/24] Train loss=0.35157135128974915
[15/24] Train loss=0.32015302777290344
[20/24] Train loss=0.3093186318874359
Test set avg_accuracy=83.52% avg_sensitivity=45.20%, avg_specificity=97.78% avg_auc=90.48%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.344603 Test loss=0.359729 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3293478786945343
[5/24] Train loss=0.34296420216560364
[10/24] Train loss=0.345563143491745
[15/24] Train loss=0.31594744324684143
[20/24] Train loss=0.30964305996894836
Test set avg_accuracy=83.06% avg_sensitivity=43.38%, avg_specificity=97.84% avg_auc=90.47%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.344369 Test loss=0.362874 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3362676203250885
[5/24] Train loss=0.34219393134117126
[10/24] Train loss=0.34250620007514954
[15/24] Train loss=0.31899797916412354
[20/24] Train loss=0.30749520659446716
Test set avg_accuracy=83.39% avg_sensitivity=45.06%, avg_specificity=97.66% avg_auc=90.69%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.342480 Test loss=0.358342 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3297324776649475
[5/24] Train loss=0.3459259867668152
[10/24] Train loss=0.34030628204345703
[15/24] Train loss=0.31984350085258484
[20/24] Train loss=0.30992138385772705
Test set avg_accuracy=83.40% avg_sensitivity=45.15%, avg_specificity=97.64% avg_auc=90.69%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.342412 Test loss=0.357342 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3284212350845337
[5/24] Train loss=0.34515586495399475
[10/24] Train loss=0.34057706594467163
[15/24] Train loss=0.31243765354156494
[20/24] Train loss=0.30541643500328064
Test set avg_accuracy=83.84% avg_sensitivity=46.64%, avg_specificity=97.69% avg_auc=90.74%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.340917 Test loss=0.357085 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3253236413002014
[5/24] Train loss=0.35357770323753357
[10/24] Train loss=0.33740267157554626
[15/24] Train loss=0.31378790736198425
[20/24] Train loss=0.30676689743995667
Test set avg_accuracy=83.80% avg_sensitivity=46.64%, avg_specificity=97.64% avg_auc=90.73%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.341507 Test loss=0.354872 Current lr=[0.000297555943323901]

[0/24] Train loss=0.32618415355682373
[5/24] Train loss=0.3496831953525543
[10/24] Train loss=0.3390410244464874
[15/24] Train loss=0.3092634975910187
[20/24] Train loss=0.3086262345314026
Test set avg_accuracy=84.27% avg_sensitivity=48.66%, avg_specificity=97.53% avg_auc=90.87%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.339535 Test loss=0.350969 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3229983150959015
[5/24] Train loss=0.34675905108451843
[10/24] Train loss=0.3369668424129486
[15/24] Train loss=0.308127224445343
[20/24] Train loss=0.3052506148815155
Test set avg_accuracy=84.36% avg_sensitivity=49.14%, avg_specificity=97.48% avg_auc=90.86%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.339290 Test loss=0.349993 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.32316291332244873
[5/24] Train loss=0.343445360660553
[10/24] Train loss=0.33775848150253296
[15/24] Train loss=0.31563326716423035
[20/24] Train loss=0.30238139629364014
Test set avg_accuracy=84.40% avg_sensitivity=49.23%, avg_specificity=97.50% avg_auc=90.84%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.338928 Test loss=0.349594 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.32649946212768555
[5/24] Train loss=0.3534769117832184
[10/24] Train loss=0.3374241590499878
[15/24] Train loss=0.3140627145767212
[20/24] Train loss=0.30245858430862427
Test set avg_accuracy=84.34% avg_sensitivity=49.38%, avg_specificity=97.36% avg_auc=90.92%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.338501 Test loss=0.347782 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3227965831756592
[5/24] Train loss=0.3485497236251831
[10/24] Train loss=0.3367464244365692
[15/24] Train loss=0.31175997853279114
[20/24] Train loss=0.3011227548122406
Test set avg_accuracy=84.49% avg_sensitivity=50.86%, avg_specificity=97.02% avg_auc=90.96%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.337399 Test loss=0.345397 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3198670744895935
[5/24] Train loss=0.3462583124637604
[10/24] Train loss=0.33800023794174194
[15/24] Train loss=0.310120165348053
[20/24] Train loss=0.30277884006500244
Test set avg_accuracy=84.82% avg_sensitivity=51.82%, avg_specificity=97.11% avg_auc=91.03%
Best model saved!! Metric=-1.2209349119790005!!
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.336819 Test loss=0.341977 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.32211795449256897
[5/24] Train loss=0.352468878030777
[10/24] Train loss=0.3358778953552246
[15/24] Train loss=0.3098335564136505
[20/24] Train loss=0.2989317774772644
Test set avg_accuracy=84.58% avg_sensitivity=51.58%, avg_specificity=96.87% avg_auc=91.04%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.336432 Test loss=0.343041 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3238409459590912
[5/24] Train loss=0.34258607029914856
[10/24] Train loss=0.3354876637458801
[15/24] Train loss=0.31323179602622986
[20/24] Train loss=0.30218347907066345
Test set avg_accuracy=84.40% avg_sensitivity=52.11%, avg_specificity=96.43% avg_auc=91.00%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.336115 Test loss=0.341497 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.31849539279937744
[5/24] Train loss=0.3463590741157532
[10/24] Train loss=0.336601585149765
[15/24] Train loss=0.3104965090751648
[20/24] Train loss=0.29554301500320435
Test set avg_accuracy=84.75% avg_sensitivity=53.12%, avg_specificity=96.53% avg_auc=91.11%
Best model saved!! Metric=-0.4810700783040076!!
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.334989 Test loss=0.339302 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.31992265582084656
[5/24] Train loss=0.3482649624347687
[10/24] Train loss=0.33727967739105225
[15/24] Train loss=0.314368337392807
[20/24] Train loss=0.29949256777763367
Test set avg_accuracy=84.95% avg_sensitivity=52.98%, avg_specificity=96.85% avg_auc=91.17%
Best model saved!! Metric=-0.05687871089256191!!
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.335054 Test loss=0.338526 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3197949230670929
[5/24] Train loss=0.3434222936630249
[10/24] Train loss=0.3348352909088135
[15/24] Train loss=0.3095465302467346
[20/24] Train loss=0.29564401507377625
Test set avg_accuracy=84.96% avg_sensitivity=54.03%, avg_specificity=96.48% avg_auc=91.20%
Best model saved!! Metric=0.6663294443419403!!
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.333676 Test loss=0.337548 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3219906985759735
[5/24] Train loss=0.34706294536590576
[10/24] Train loss=0.33668169379234314
[15/24] Train loss=0.30834251642227173
[20/24] Train loss=0.295461505651474
Test set avg_accuracy=84.49% avg_sensitivity=52.26%, avg_specificity=96.50% avg_auc=91.12%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.334799 Test loss=0.340400 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3192041516304016
[5/24] Train loss=0.3498018980026245
[10/24] Train loss=0.33471447229385376
[15/24] Train loss=0.3166801929473877
[20/24] Train loss=0.3002205193042755
Test set avg_accuracy=84.52% avg_sensitivity=51.10%, avg_specificity=96.96% avg_auc=91.10%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.334885 Test loss=0.342577 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3183935582637787
[5/24] Train loss=0.350606232881546
[10/24] Train loss=0.33789241313934326
[15/24] Train loss=0.31208541989326477
[20/24] Train loss=0.3003803789615631
Test set avg_accuracy=84.48% avg_sensitivity=52.74%, avg_specificity=96.30% avg_auc=91.17%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.333205 Test loss=0.338938 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3159085810184479
[5/24] Train loss=0.34520962834358215
[10/24] Train loss=0.33261141180992126
[15/24] Train loss=0.31314998865127563
[20/24] Train loss=0.2985071837902069
Test set avg_accuracy=84.61% avg_sensitivity=51.58%, avg_specificity=96.91% avg_auc=91.17%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.333644 Test loss=0.341072 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3154812455177307
[5/24] Train loss=0.34538203477859497
[10/24] Train loss=0.3344409465789795
[15/24] Train loss=0.3075462579727173
[20/24] Train loss=0.2988892197608948
Test set avg_accuracy=84.84% avg_sensitivity=54.46%, avg_specificity=96.16% avg_auc=91.21%
Best model saved!! Metric=0.6703426168815554!!
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.332232 Test loss=0.336107 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3187849521636963
[5/24] Train loss=0.344539999961853
[10/24] Train loss=0.3334878981113434
[15/24] Train loss=0.30848777294158936
[20/24] Train loss=0.2992248237133026
Test set avg_accuracy=84.53% avg_sensitivity=51.44%, avg_specificity=96.85% avg_auc=91.19%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.331630 Test loss=0.340828 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3182644546031952
[5/24] Train loss=0.349487841129303
[10/24] Train loss=0.33262407779693604
[15/24] Train loss=0.3147163987159729
[20/24] Train loss=0.2960118055343628
Test set avg_accuracy=84.74% avg_sensitivity=53.84%, avg_specificity=96.25% avg_auc=91.26%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.332487 Test loss=0.335803 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3129570782184601
[5/24] Train loss=0.3444991707801819
[10/24] Train loss=0.33908966183662415
[15/24] Train loss=0.30367738008499146
[20/24] Train loss=0.2942532002925873
Test set avg_accuracy=84.62% avg_sensitivity=51.58%, avg_specificity=96.93% avg_auc=91.24%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.330756 Test loss=0.339237 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.31389766931533813
[5/24] Train loss=0.3419431447982788
[10/24] Train loss=0.33813905715942383
[15/24] Train loss=0.3052297830581665
[20/24] Train loss=0.29653993248939514
Test set avg_accuracy=84.75% avg_sensitivity=52.78%, avg_specificity=96.66% avg_auc=91.23%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.330587 Test loss=0.337587 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3165212869644165
[5/24] Train loss=0.343902051448822
[10/24] Train loss=0.3345792889595032
[15/24] Train loss=0.3073820471763611
[20/24] Train loss=0.2946602404117584
Test set avg_accuracy=85.03% avg_sensitivity=55.18%, avg_specificity=96.14% avg_auc=91.27%
Best model saved!! Metric=1.615046494628487!!
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.330774 Test loss=0.334536 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3138945400714874
[5/24] Train loss=0.3358818292617798
[10/24] Train loss=0.3328278660774231
[15/24] Train loss=0.3021577298641205
[20/24] Train loss=0.2972964644432068
Test set avg_accuracy=84.53% avg_sensitivity=50.53%, avg_specificity=97.19% avg_auc=91.30%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.330404 Test loss=0.341253 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3158939480781555
[5/24] Train loss=0.3449553847312927
[10/24] Train loss=0.3313466012477875
[15/24] Train loss=0.3067901134490967
[20/24] Train loss=0.29843905568122864
Test set avg_accuracy=84.48% avg_sensitivity=51.73%, avg_specificity=96.68% avg_auc=91.20%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.331064 Test loss=0.339831 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3140348494052887
[5/24] Train loss=0.34286969900131226
[10/24] Train loss=0.3310343027114868
[15/24] Train loss=0.30635687708854675
[20/24] Train loss=0.29851362109184265
Test set avg_accuracy=84.10% avg_sensitivity=49.90%, avg_specificity=96.84% avg_auc=90.97%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.331502 Test loss=0.344540 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.31919151544570923
[5/24] Train loss=0.3391997516155243
[10/24] Train loss=0.33268827199935913
[15/24] Train loss=0.3071750998497009
[20/24] Train loss=0.2978897988796234
Test set avg_accuracy=83.42% avg_sensitivity=45.39%, avg_specificity=97.59% avg_auc=90.76%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.332240 Test loss=0.354081 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3209981322288513
[5/24] Train loss=0.33821266889572144
[10/24] Train loss=0.3420657515525818
[15/24] Train loss=0.30971747636795044
[20/24] Train loss=0.29530462622642517
Test set avg_accuracy=83.72% avg_sensitivity=47.22%, avg_specificity=97.32% avg_auc=90.87%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.333338 Test loss=0.350301 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.31767186522483826
[5/24] Train loss=0.33983251452445984
[10/24] Train loss=0.3398746848106384
[15/24] Train loss=0.3063424825668335
[20/24] Train loss=0.29928314685821533
Test set avg_accuracy=84.40% avg_sensitivity=51.92%, avg_specificity=96.50% avg_auc=91.08%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.332457 Test loss=0.339895 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3142729103565216
[5/24] Train loss=0.3371390402317047
[10/24] Train loss=0.34246915578842163
[15/24] Train loss=0.3092944025993347
[20/24] Train loss=0.29499971866607666
Test set avg_accuracy=84.57% avg_sensitivity=52.45%, avg_specificity=96.53% avg_auc=91.19%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.331970 Test loss=0.339009 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3175007104873657
[5/24] Train loss=0.33914288878440857
[10/24] Train loss=0.3369557857513428
[15/24] Train loss=0.3096347451210022
[20/24] Train loss=0.2914961576461792
Test set avg_accuracy=84.73% avg_sensitivity=53.26%, avg_specificity=96.44% avg_auc=91.15%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.331457 Test loss=0.338034 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3161641061306
[5/24] Train loss=0.3366779088973999
[10/24] Train loss=0.3399139642715454
[15/24] Train loss=0.30615732073783875
[20/24] Train loss=0.29527151584625244
Test set avg_accuracy=84.28% avg_sensitivity=51.06%, avg_specificity=96.66% avg_auc=91.11%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.331120 Test loss=0.341085 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3149535059928894
[5/24] Train loss=0.3412846624851227
[10/24] Train loss=0.3342757225036621
[15/24] Train loss=0.3102509379386902
[20/24] Train loss=0.29027077555656433
Test set avg_accuracy=84.17% avg_sensitivity=50.82%, avg_specificity=96.59% avg_auc=91.08%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.331503 Test loss=0.342491 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3161758482456207
[5/24] Train loss=0.3357439935207367
[10/24] Train loss=0.33838075399398804
[15/24] Train loss=0.30779045820236206
[20/24] Train loss=0.290310800075531
Test set avg_accuracy=83.88% avg_sensitivity=49.62%, avg_specificity=96.64% avg_auc=91.02%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.332145 Test loss=0.345015 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3184833228588104
[5/24] Train loss=0.3437308669090271
[10/24] Train loss=0.3326210081577301
[15/24] Train loss=0.30756741762161255
[20/24] Train loss=0.28901761770248413
Test set avg_accuracy=84.48% avg_sensitivity=52.45%, avg_specificity=96.41% avg_auc=91.01%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.333262 Test loss=0.341420 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3156551420688629
[5/24] Train loss=0.34217071533203125
[10/24] Train loss=0.33370450139045715
[15/24] Train loss=0.30514732003211975
[20/24] Train loss=0.2907818853855133
Test set avg_accuracy=85.04% avg_sensitivity=55.42%, avg_specificity=96.07% avg_auc=91.01%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.335341 Test loss=0.337912 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.314970999956131
[5/24] Train loss=0.34239763021469116
[10/24] Train loss=0.33820009231567383
[15/24] Train loss=0.3122488856315613
[20/24] Train loss=0.2997995615005493
Test set avg_accuracy=86.29% avg_sensitivity=67.32%, avg_specificity=93.35% avg_auc=91.17%
Best model saved!! Metric=12.136068313036162!!
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.337521 Test loss=0.330258 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3258785307407379
[5/24] Train loss=0.33486539125442505
[10/24] Train loss=0.3333253860473633
[15/24] Train loss=0.30498048663139343
[20/24] Train loss=0.30681532621383667
Test set avg_accuracy=86.42% avg_sensitivity=67.51%, avg_specificity=93.46% avg_auc=91.09%
Best model saved!! Metric=12.483613817559814!!
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.334311 Test loss=0.331213 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3281570374965668
[5/24] Train loss=0.33721038699150085
[10/24] Train loss=0.33311450481414795
[15/24] Train loss=0.30568939447402954
[20/24] Train loss=0.3041679859161377
Test set avg_accuracy=86.42% avg_sensitivity=66.89%, avg_specificity=93.69% avg_auc=91.14%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.332452 Test loss=0.330503 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.3191961944103241
[5/24] Train loss=0.3351501524448395
[10/24] Train loss=0.33200615644454956
[15/24] Train loss=0.3087015450000763
[20/24] Train loss=0.29882556200027466
Test set avg_accuracy=86.41% avg_sensitivity=66.22%, avg_specificity=93.92% avg_auc=91.05%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.331602 Test loss=0.331997 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.32246336340904236
[5/24] Train loss=0.336024671792984
[10/24] Train loss=0.3308335840702057
[15/24] Train loss=0.3057912290096283
[20/24] Train loss=0.3001503050327301
Test set avg_accuracy=86.29% avg_sensitivity=65.79%, avg_specificity=93.92% avg_auc=91.18%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.330483 Test loss=0.329640 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3225467801094055
[5/24] Train loss=0.33951130509376526
[10/24] Train loss=0.3285462558269501
[15/24] Train loss=0.3016659915447235
[20/24] Train loss=0.29791969060897827
Test set avg_accuracy=86.48% avg_sensitivity=67.23%, avg_specificity=93.66% avg_auc=91.18%
Best model saved!! Metric=12.54532235888945!!
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.329651 Test loss=0.329452 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3265098035335541
[5/24] Train loss=0.3326603174209595
[10/24] Train loss=0.33162450790405273
[15/24] Train loss=0.3055746555328369
[20/24] Train loss=0.30144307017326355
Test set avg_accuracy=86.42% avg_sensitivity=66.31%, avg_specificity=93.91% avg_auc=91.19%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.331043 Test loss=0.329534 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.32045286893844604
[5/24] Train loss=0.3312707841396332
[10/24] Train loss=0.3325255811214447
[15/24] Train loss=0.30295637249946594
[20/24] Train loss=0.2955625057220459
Test set avg_accuracy=86.09% avg_sensitivity=64.49%, avg_specificity=94.14% avg_auc=91.16%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.329407 Test loss=0.329723 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3219817578792572
[5/24] Train loss=0.3367651104927063
[10/24] Train loss=0.3275291323661804
[15/24] Train loss=0.30161964893341064
[20/24] Train loss=0.2971178889274597
Test set avg_accuracy=86.16% avg_sensitivity=65.40%, avg_specificity=93.89% avg_auc=91.22%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.329727 Test loss=0.328930 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.31742918491363525
[5/24] Train loss=0.33795174956321716
[10/24] Train loss=0.33069705963134766
[15/24] Train loss=0.305244117975235
[20/24] Train loss=0.298753947019577
Test set avg_accuracy=86.60% avg_sensitivity=67.75%, avg_specificity=93.62% avg_auc=91.37%
Best model saved!! Metric=13.350321210293501!!
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.330829 Test loss=0.326592 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3217393457889557
[5/24] Train loss=0.33347922563552856
[10/24] Train loss=0.33427751064300537
[15/24] Train loss=0.31286749243736267
[20/24] Train loss=0.30010783672332764
Test set avg_accuracy=86.56% avg_sensitivity=68.86%, avg_specificity=93.16% avg_auc=91.34%
Best model saved!! Metric=13.914230877141478!!
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.331415 Test loss=0.327972 Current lr=[0.000156543481933168]

[0/24] Train loss=0.32734692096710205
[5/24] Train loss=0.33392754197120667
[10/24] Train loss=0.3315011262893677
[15/24] Train loss=0.309184193611145
[20/24] Train loss=0.30110687017440796
Test set avg_accuracy=86.51% avg_sensitivity=69.67%, avg_specificity=92.78% avg_auc=91.28%
Best model saved!! Metric=14.245373017446411!!
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.330140 Test loss=0.328946 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3301070034503937
[5/24] Train loss=0.34132468700408936
[10/24] Train loss=0.3357997238636017
[15/24] Train loss=0.30666428804397583
[20/24] Train loss=0.30217331647872925
Test set avg_accuracy=86.97% avg_sensitivity=69.63%, avg_specificity=93.42% avg_auc=91.43%
Best model saved!! Metric=15.44789966353008!!
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.329000 Test loss=0.326356 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3225049078464508
[5/24] Train loss=0.34257254004478455
[10/24] Train loss=0.334829717874527
[15/24] Train loss=0.3037295639514923
[20/24] Train loss=0.29841744899749756
Test set avg_accuracy=86.61% avg_sensitivity=69.10%, avg_specificity=93.14% avg_auc=91.42%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.327104 Test loss=0.326221 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3276044726371765
[5/24] Train loss=0.33892613649368286
[10/24] Train loss=0.33097878098487854
[15/24] Train loss=0.30383747816085815
[20/24] Train loss=0.2946726977825165
Test set avg_accuracy=86.81% avg_sensitivity=68.47%, avg_specificity=93.64% avg_auc=91.48%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.327018 Test loss=0.325221 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3185289800167084
[5/24] Train loss=0.3405032157897949
[10/24] Train loss=0.3310684561729431
[15/24] Train loss=0.3064047396183014
[20/24] Train loss=0.2948565185070038
Test set avg_accuracy=86.45% avg_sensitivity=69.82%, avg_specificity=92.64% avg_auc=91.43%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.326056 Test loss=0.326292 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3257933259010315
[5/24] Train loss=0.3387395739555359
[10/24] Train loss=0.3339962959289551
[15/24] Train loss=0.30508753657341003
[20/24] Train loss=0.29488813877105713
Test set avg_accuracy=86.54% avg_sensitivity=68.76%, avg_specificity=93.16% avg_auc=91.47%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.326377 Test loss=0.325318 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.32251816987991333
[5/24] Train loss=0.3391595780849457
[10/24] Train loss=0.3331145644187927
[15/24] Train loss=0.30136948823928833
[20/24] Train loss=0.2927446663379669
Test set avg_accuracy=86.50% avg_sensitivity=69.91%, avg_specificity=92.67% avg_auc=91.46%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.325289 Test loss=0.325433 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3246035873889923
[5/24] Train loss=0.3373348116874695
[10/24] Train loss=0.33885741233825684
[15/24] Train loss=0.30045369267463684
[20/24] Train loss=0.29046550393104553
Test set avg_accuracy=86.46% avg_sensitivity=69.48%, avg_specificity=92.78% avg_auc=91.48%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.325602 Test loss=0.324903 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3201245665550232
[5/24] Train loss=0.3408375680446625
[10/24] Train loss=0.33535534143447876
[15/24] Train loss=0.30094313621520996
[20/24] Train loss=0.2915189862251282
Test set avg_accuracy=86.78% avg_sensitivity=71.02%, avg_specificity=92.66% avg_auc=91.53%
Best model saved!! Metric=15.985090414384047!!
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.325476 Test loss=0.324818 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3230431377887726
[5/24] Train loss=0.3431759178638458
[10/24] Train loss=0.34182968735694885
[15/24] Train loss=0.3055029511451721
[20/24] Train loss=0.2958065867424011
Test set avg_accuracy=86.67% avg_sensitivity=71.88%, avg_specificity=92.17% avg_auc=91.52%
Best model saved!! Metric=16.237490150399907!!
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.325285 Test loss=0.325576 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.32423630356788635
[5/24] Train loss=0.3405013382434845
[10/24] Train loss=0.3392369747161865
[15/24] Train loss=0.30105146765708923
[20/24] Train loss=0.2940491735935211
Test set avg_accuracy=86.65% avg_sensitivity=72.98%, avg_specificity=91.74% avg_auc=91.54%
Best model saved!! Metric=16.91908049395603!!
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.325012 Test loss=0.326303 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3290626108646393
[5/24] Train loss=0.34713214635849
[10/24] Train loss=0.3414838910102844
[15/24] Train loss=0.3007679283618927
[20/24] Train loss=0.2954219877719879
Test set avg_accuracy=86.52% avg_sensitivity=74.38%, avg_specificity=91.05% avg_auc=91.51%
Best model saved!! Metric=17.45811904522222!!
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.326043 Test loss=0.328526 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3348836302757263
[5/24] Train loss=0.34973710775375366
[10/24] Train loss=0.3424582779407501
[15/24] Train loss=0.2992461919784546
[20/24] Train loss=0.3032172620296478
Test set avg_accuracy=86.50% avg_sensitivity=75.43%, avg_specificity=90.62% avg_auc=91.51%
Best model saved!! Metric=18.054883084303654!!
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.327556 Test loss=0.330990 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3356643319129944
[5/24] Train loss=0.34836435317993164
[10/24] Train loss=0.3376467823982239
[15/24] Train loss=0.30292102694511414
[20/24] Train loss=0.31610971689224243
Test set avg_accuracy=86.77% avg_sensitivity=73.42%, avg_specificity=91.74% avg_auc=91.57%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.328905 Test loss=0.327267 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.32995977997779846
[5/24] Train loss=0.34371066093444824
[10/24] Train loss=0.33125391602516174
[15/24] Train loss=0.30745846033096313
[20/24] Train loss=0.3138614892959595
Test set avg_accuracy=87.45% avg_sensitivity=69.72%, avg_specificity=94.05% avg_auc=91.58%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.328119 Test loss=0.324056 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.319692462682724
[5/24] Train loss=0.34045201539993286
[10/24] Train loss=0.3342369794845581
[15/24] Train loss=0.30304378271102905
[20/24] Train loss=0.2973547875881195
Test set avg_accuracy=87.16% avg_sensitivity=67.75%, avg_specificity=94.39% avg_auc=91.56%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.324425 Test loss=0.323842 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3127230405807495
[5/24] Train loss=0.3348557949066162
[10/24] Train loss=0.3331882357597351
[15/24] Train loss=0.3000807464122772
[20/24] Train loss=0.2970429062843323
Test set avg_accuracy=87.12% avg_sensitivity=68.52%, avg_specificity=94.05% avg_auc=91.55%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.323354 Test loss=0.324548 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.31712737679481506
[5/24] Train loss=0.34378042817115784
[10/24] Train loss=0.33498910069465637
[15/24] Train loss=0.2999683916568756
[20/24] Train loss=0.29995429515838623
Test set avg_accuracy=87.21% avg_sensitivity=69.24%, avg_specificity=93.91% avg_auc=91.42%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.324000 Test loss=0.327154 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.32737550139427185
[5/24] Train loss=0.3422776758670807
[10/24] Train loss=0.33525338768959045
[15/24] Train loss=0.30081823468208313
[20/24] Train loss=0.30006298422813416
Test set avg_accuracy=87.17% avg_sensitivity=69.53%, avg_specificity=93.75% avg_auc=91.26%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.325138 Test loss=0.330374 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3288111090660095
[5/24] Train loss=0.34085020422935486
[10/24] Train loss=0.3320184051990509
[15/24] Train loss=0.2967102527618408
[20/24] Train loss=0.30235254764556885
Test set avg_accuracy=87.02% avg_sensitivity=68.57%, avg_specificity=93.89% avg_auc=91.33%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.324987 Test loss=0.328491 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3189104497432709
[5/24] Train loss=0.33593395352363586
[10/24] Train loss=0.33044904470443726
[15/24] Train loss=0.30145198106765747
[20/24] Train loss=0.3040277659893036
Test set avg_accuracy=87.23% avg_sensitivity=68.04%, avg_specificity=94.37% avg_auc=91.59%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.324293 Test loss=0.323810 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3188479542732239
[5/24] Train loss=0.3333435356616974
[10/24] Train loss=0.32510000467300415
[15/24] Train loss=0.3008502423763275
[20/24] Train loss=0.30582812428474426
Test set avg_accuracy=86.56% avg_sensitivity=65.16%, avg_specificity=94.53% avg_auc=91.64%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.323037 Test loss=0.322792 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3153790235519409
[5/24] Train loss=0.3355572521686554
[10/24] Train loss=0.33157452940940857
[15/24] Train loss=0.3005038797855377
[20/24] Train loss=0.29528242349624634
Test set avg_accuracy=86.48% avg_sensitivity=64.83%, avg_specificity=94.55% avg_auc=91.65%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.321354 Test loss=0.322680 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.31007304787635803
[5/24] Train loss=0.33489978313446045
[10/24] Train loss=0.3245721459388733
[15/24] Train loss=0.2981627881526947
[20/24] Train loss=0.2979031503200531
Test set avg_accuracy=86.55% avg_sensitivity=65.02%, avg_specificity=94.57% avg_auc=91.67%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.320674 Test loss=0.322297 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.30761614441871643
[5/24] Train loss=0.33382290601730347
[10/24] Train loss=0.3235463500022888
[15/24] Train loss=0.299439400434494
[20/24] Train loss=0.29852917790412903
Test set avg_accuracy=86.50% avg_sensitivity=65.12%, avg_specificity=94.46% avg_auc=91.66%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.320093 Test loss=0.322283 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.3118710219860077
[5/24] Train loss=0.3345356285572052
[10/24] Train loss=0.3282908797264099
[15/24] Train loss=0.29291045665740967
[20/24] Train loss=0.2967503070831299
Test set avg_accuracy=86.51% avg_sensitivity=64.54%, avg_specificity=94.69% avg_auc=91.67%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.319973 Test loss=0.322364 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.31263259053230286
[5/24] Train loss=0.3342498242855072
[10/24] Train loss=0.32469069957733154
[15/24] Train loss=0.29846808314323425
[20/24] Train loss=0.29768675565719604
Test set avg_accuracy=86.54% avg_sensitivity=64.35%, avg_specificity=94.80% avg_auc=91.69%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.320161 Test loss=0.321876 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.31414997577667236
[5/24] Train loss=0.3264461159706116
[10/24] Train loss=0.32839837670326233
[15/24] Train loss=0.3004586100578308
[20/24] Train loss=0.2960275113582611
Test set avg_accuracy=86.51% avg_sensitivity=64.40%, avg_specificity=94.75% avg_auc=91.67%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.319660 Test loss=0.322232 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3093098998069763
[5/24] Train loss=0.33004140853881836
[10/24] Train loss=0.32512131333351135
[15/24] Train loss=0.29624733328819275
[20/24] Train loss=0.2908840477466583
Test set avg_accuracy=86.52% avg_sensitivity=64.06%, avg_specificity=94.89% avg_auc=91.70%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.318764 Test loss=0.321822 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.30706244707107544
[5/24] Train loss=0.33138343691825867
[10/24] Train loss=0.32529744505882263
[15/24] Train loss=0.3005487322807312
[20/24] Train loss=0.2913707196712494
Test set avg_accuracy=86.48% avg_sensitivity=63.63%, avg_specificity=95.00% avg_auc=91.69%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.318342 Test loss=0.321959 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3130277395248413
[5/24] Train loss=0.3325965404510498
[10/24] Train loss=0.32760730385780334
[15/24] Train loss=0.29664722084999084
[20/24] Train loss=0.29453057050704956
Test set avg_accuracy=86.48% avg_sensitivity=63.63%, avg_specificity=95.00% avg_auc=91.70%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.319602 Test loss=0.321797 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3082803785800934
[5/24] Train loss=0.32854634523391724
[10/24] Train loss=0.32592642307281494
[15/24] Train loss=0.2966335415840149
[20/24] Train loss=0.2900908887386322
Test set avg_accuracy=86.64% avg_sensitivity=64.73%, avg_specificity=94.80% avg_auc=91.71%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.318691 Test loss=0.321398 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3079602122306824
[5/24] Train loss=0.33102309703826904
[10/24] Train loss=0.3252536952495575
[15/24] Train loss=0.29555436968803406
[20/24] Train loss=0.2872801125049591
Test set avg_accuracy=86.60% avg_sensitivity=64.30%, avg_specificity=94.91% avg_auc=91.72%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.318722 Test loss=0.321416 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.30623316764831543
[5/24] Train loss=0.3324243128299713
[10/24] Train loss=0.32825759053230286
[15/24] Train loss=0.2921223044395447
[20/24] Train loss=0.28990623354911804
Test set avg_accuracy=86.54% avg_sensitivity=63.72%, avg_specificity=95.03% avg_auc=91.71%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.318599 Test loss=0.321555 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.30999910831451416
[5/24] Train loss=0.3325226306915283
[10/24] Train loss=0.3222429156303406
[15/24] Train loss=0.2947273552417755
[20/24] Train loss=0.2931375801563263
Test set avg_accuracy=86.51% avg_sensitivity=64.59%, avg_specificity=94.67% avg_auc=91.70%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.318583 Test loss=0.321433 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.31445494294166565
[5/24] Train loss=0.3321641683578491
[10/24] Train loss=0.32277780771255493
[15/24] Train loss=0.29588782787323
[20/24] Train loss=0.2891952097415924
Test set avg_accuracy=86.85% avg_sensitivity=65.98%, avg_specificity=94.62% avg_auc=91.72%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.319096 Test loss=0.321205 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3049049973487854
[5/24] Train loss=0.332125186920166
[10/24] Train loss=0.32829394936561584
[15/24] Train loss=0.29366517066955566
[20/24] Train loss=0.2917875051498413
Test set avg_accuracy=86.76% avg_sensitivity=65.74%, avg_specificity=94.59% avg_auc=91.72%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.318061 Test loss=0.321234 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.3110863268375397
[5/24] Train loss=0.3280313014984131
[10/24] Train loss=0.3205662667751312
[15/24] Train loss=0.29456430673599243
[20/24] Train loss=0.2884283661842346
Test set avg_accuracy=86.72% avg_sensitivity=65.69%, avg_specificity=94.55% avg_auc=91.71%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.318376 Test loss=0.321297 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.31159085035324097
[5/24] Train loss=0.3317057490348816
[10/24] Train loss=0.3227258622646332
[15/24] Train loss=0.2924647033214569
[20/24] Train loss=0.29048779606819153
Test set avg_accuracy=86.67% avg_sensitivity=65.50%, avg_specificity=94.55% avg_auc=91.70%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.317362 Test loss=0.321502 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.308001846075058
[5/24] Train loss=0.32842525839805603
[10/24] Train loss=0.32987120747566223
[15/24] Train loss=0.2907540202140808
[20/24] Train loss=0.2895098030567169
Test set avg_accuracy=86.60% avg_sensitivity=64.68%, avg_specificity=94.76% avg_auc=91.69%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.317584 Test loss=0.321588 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3122498393058777
[5/24] Train loss=0.3293607831001282
[10/24] Train loss=0.3295237421989441
[15/24] Train loss=0.29401761293411255
[20/24] Train loss=0.29092440009117126
Test set avg_accuracy=86.58% avg_sensitivity=64.64%, avg_specificity=94.75% avg_auc=91.71%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.317684 Test loss=0.321390 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.3078085780143738
[5/24] Train loss=0.33176127076148987
[10/24] Train loss=0.32432323694229126
[15/24] Train loss=0.29510828852653503
[20/24] Train loss=0.2896961271762848
Test set avg_accuracy=86.46% avg_sensitivity=63.68%, avg_specificity=94.94% avg_auc=91.71%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.317356 Test loss=0.321452 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.3066781461238861
[5/24] Train loss=0.3333228528499603
[10/24] Train loss=0.3272028863430023
[15/24] Train loss=0.297211617231369
[20/24] Train loss=0.28879818320274353
Test set avg_accuracy=86.50% avg_sensitivity=63.87%, avg_specificity=94.92% avg_auc=91.72%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.317926 Test loss=0.321295 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3130946755409241
[5/24] Train loss=0.3302595317363739
[10/24] Train loss=0.32579168677330017
[15/24] Train loss=0.2933374345302582
[20/24] Train loss=0.2903996407985687
Test set avg_accuracy=86.47% avg_sensitivity=63.63%, avg_specificity=94.98% avg_auc=91.72%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.317877 Test loss=0.321361 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3081528842449188
[5/24] Train loss=0.3293096125125885
[10/24] Train loss=0.32402685284614563
[15/24] Train loss=0.292965829372406
[20/24] Train loss=0.2875339686870575
Test set avg_accuracy=86.48% avg_sensitivity=63.72%, avg_specificity=94.96% avg_auc=91.73%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.317247 Test loss=0.321240 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3136236071586609
[5/24] Train loss=0.3320685625076294
[10/24] Train loss=0.3264908194541931
[15/24] Train loss=0.29311105608940125
[20/24] Train loss=0.28739553689956665
Test set avg_accuracy=86.46% avg_sensitivity=63.48%, avg_specificity=95.01% avg_auc=91.72%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.317104 Test loss=0.321363 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.310031920671463
[5/24] Train loss=0.33099666237831116
[10/24] Train loss=0.32179197669029236
[15/24] Train loss=0.29094845056533813
[20/24] Train loss=0.290120393037796
Test set avg_accuracy=86.46% avg_sensitivity=63.63%, avg_specificity=94.96% avg_auc=91.73%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.317232 Test loss=0.321171 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3096890151500702
[5/24] Train loss=0.33098816871643066
[10/24] Train loss=0.32474130392074585
[15/24] Train loss=0.29584506154060364
[20/24] Train loss=0.28660595417022705
Test set avg_accuracy=86.46% avg_sensitivity=63.63%, avg_specificity=94.96% avg_auc=91.73%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.317487 Test loss=0.321146 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.31272026896476746
[5/24] Train loss=0.32779210805892944
[10/24] Train loss=0.3205660283565521
[15/24] Train loss=0.2958964407444
[20/24] Train loss=0.2894551455974579
Test set avg_accuracy=86.45% avg_sensitivity=63.53%, avg_specificity=94.98% avg_auc=91.73%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.317849 Test loss=0.321226 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3088458180427551
[5/24] Train loss=0.3274320662021637
[10/24] Train loss=0.3242628574371338
[15/24] Train loss=0.290989488363266
[20/24] Train loss=0.2895672023296356
Test set avg_accuracy=86.46% avg_sensitivity=63.48%, avg_specificity=95.01% avg_auc=91.73%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.317809 Test loss=0.321228 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.3101713955402374
[5/24] Train loss=0.3277159035205841
[10/24] Train loss=0.3283003866672516
[15/24] Train loss=0.2951619625091553
[20/24] Train loss=0.29249998927116394
Test set avg_accuracy=86.46% avg_sensitivity=63.48%, avg_specificity=95.01% avg_auc=91.73%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.318086 Test loss=0.321253 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3075619339942932
[5/24] Train loss=0.32601606845855713
[10/24] Train loss=0.3300917148590088
[15/24] Train loss=0.29547274112701416
[20/24] Train loss=0.29123276472091675
Test set avg_accuracy=86.46% avg_sensitivity=63.48%, avg_specificity=95.01% avg_auc=91.73%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.317812 Test loss=0.321254 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.30754420161247253
[5/24] Train loss=0.33125460147857666
[10/24] Train loss=0.3261984586715698
[15/24] Train loss=0.29464268684387207
[20/24] Train loss=0.2890361547470093
Test set avg_accuracy=86.46% avg_sensitivity=63.48%, avg_specificity=95.01% avg_auc=91.73%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.316544 Test loss=0.321259 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3095754086971283
[5/24] Train loss=0.32962608337402344
[10/24] Train loss=0.32573676109313965
[15/24] Train loss=0.29408061504364014
[20/24] Train loss=0.29279911518096924
Test set avg_accuracy=86.46% avg_sensitivity=63.48%, avg_specificity=95.01% avg_auc=91.73%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.318106 Test loss=0.321260 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=86.50% sen=75.43%, spe=90.62%, auc=91.51%!
Fold[6] Avg_overlap=0.65%(0.2561467314787987)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'HybridCNNRNN',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.8414534330368042
[5/24] Train loss=0.7205643057823181
[10/24] Train loss=0.6831330060958862
[15/24] Train loss=0.6320769190788269
[20/24] Train loss=0.6286618709564209
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.09%
Best model saved!! Metric=-104.52403402460311!!
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.687863 Test loss=0.613052 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6202401518821716
[5/24] Train loss=0.5772546529769897
[10/24] Train loss=0.6107639074325562
[15/24] Train loss=0.5887053608894348
[20/24] Train loss=0.5971391797065735
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.35%
Best model saved!! Metric=-101.26592392556609!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.599484 Test loss=0.591179 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6006723046302795
[5/24] Train loss=0.5674871206283569
[10/24] Train loss=0.592994749546051
[15/24] Train loss=0.568307638168335
[20/24] Train loss=0.5966766476631165
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=56.26%
Best model saved!! Metric=-97.3544989383368!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.587822 Test loss=0.584690 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.5940603613853455
[5/24] Train loss=0.5588712692260742
[10/24] Train loss=0.5890329480171204
[15/24] Train loss=0.5680427551269531
[20/24] Train loss=0.5811122059822083
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=60.20%
Best model saved!! Metric=-93.41610764334422!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.580950 Test loss=0.577666 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.582310140132904
[5/24] Train loss=0.5494145750999451
[10/24] Train loss=0.5864526629447937
[15/24] Train loss=0.5553312301635742
[20/24] Train loss=0.5762787461280823
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=64.79%
Best model saved!! Metric=-88.82265855207784!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.573332 Test loss=0.569818 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5775846242904663
[5/24] Train loss=0.5388599634170532
[10/24] Train loss=0.5750901699066162
[15/24] Train loss=0.5546398162841797
[20/24] Train loss=0.5677579045295715
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=69.11%
Best model saved!! Metric=-84.50343548028333!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.564991 Test loss=0.562065 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5686497688293457
[5/24] Train loss=0.5333516001701355
[10/24] Train loss=0.5679447650909424
[15/24] Train loss=0.5437167882919312
[20/24] Train loss=0.5614628791809082
Test set avg_accuracy=72.38% avg_sensitivity=0.05%, avg_specificity=99.98% avg_auc=72.48%
Best model saved!! Metric=-81.10335682466511!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.557224 Test loss=0.553283 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5605394244194031
[5/24] Train loss=0.5175778865814209
[10/24] Train loss=0.5602479577064514
[15/24] Train loss=0.5319968461990356
[20/24] Train loss=0.5500144958496094
Test set avg_accuracy=72.25% avg_sensitivity=0.28%, avg_specificity=99.71% avg_auc=75.77%
Best model saved!! Metric=-77.98527216895855!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.548181 Test loss=0.543108 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.556541919708252
[5/24] Train loss=0.507205605506897
[10/24] Train loss=0.543328583240509
[15/24] Train loss=0.5295833349227905
[20/24] Train loss=0.5363686084747314
Test set avg_accuracy=72.25% avg_sensitivity=1.18%, avg_specificity=99.37% avg_auc=77.88%
Best model saved!! Metric=-75.31594271192064!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.538082 Test loss=0.531980 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5381903648376465
[5/24] Train loss=0.49246418476104736
[10/24] Train loss=0.538068413734436
[15/24] Train loss=0.5102113485336304
[20/24] Train loss=0.5294119119644165
Test set avg_accuracy=71.77% avg_sensitivity=1.89%, avg_specificity=98.43% avg_auc=80.06%
Best model saved!! Metric=-73.84867583830699!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.526134 Test loss=0.518522 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5264018177986145
[5/24] Train loss=0.4874509572982788
[10/24] Train loss=0.5302543640136719
[15/24] Train loss=0.5020360350608826
[20/24] Train loss=0.508934497833252
Test set avg_accuracy=71.56% avg_sensitivity=2.50%, avg_specificity=97.91% avg_auc=81.42%
Best model saved!! Metric=-72.60774929692106!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.515342 Test loss=0.507147 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5149837732315063
[5/24] Train loss=0.4734204113483429
[10/24] Train loss=0.5146488547325134
[15/24] Train loss=0.48863691091537476
[20/24] Train loss=0.5035758018493652
Test set avg_accuracy=71.91% avg_sensitivity=5.33%, avg_specificity=97.32% avg_auc=82.66%
Best model saved!! Metric=-68.77425083060065!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.500730 Test loss=0.492517 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4998020529747009
[5/24] Train loss=0.45421668887138367
[10/24] Train loss=0.4986998438835144
[15/24] Train loss=0.47121188044548035
[20/24] Train loss=0.4750763475894928
Test set avg_accuracy=72.59% avg_sensitivity=10.47%, avg_specificity=96.29% avg_auc=83.45%
Best model saved!! Metric=-63.201817889837216!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.487751 Test loss=0.476671 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.48359414935112
[5/24] Train loss=0.43378862738609314
[10/24] Train loss=0.49879032373428345
[15/24] Train loss=0.46333834528923035
[20/24] Train loss=0.4724940359592438
Test set avg_accuracy=72.93% avg_sensitivity=16.36%, avg_specificity=94.51% avg_auc=84.37%
Best model saved!! Metric=-57.82708607266217!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.475573 Test loss=0.461933 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4609156548976898
[5/24] Train loss=0.4210476279258728
[10/24] Train loss=0.47924336791038513
[15/24] Train loss=0.44066518545150757
[20/24] Train loss=0.4514351785182953
Test set avg_accuracy=75.59% avg_sensitivity=28.76%, avg_specificity=93.45% avg_auc=84.94%
Best model saved!! Metric=-43.25699069074521!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.461467 Test loss=0.447294 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4530193507671356
[5/24] Train loss=0.4157203137874603
[10/24] Train loss=0.4764872193336487
[15/24] Train loss=0.43009334802627563
[20/24] Train loss=0.436625599861145
Test set avg_accuracy=77.54% avg_sensitivity=38.66%, avg_specificity=92.37% avg_auc=85.54%
Best model saved!! Metric=-31.88952012389342!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.452413 Test loss=0.437239 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.454179584980011
[5/24] Train loss=0.40724053978919983
[10/24] Train loss=0.46966490149497986
[15/24] Train loss=0.41773340106010437
[20/24] Train loss=0.4241199493408203
Test set avg_accuracy=78.65% avg_sensitivity=42.76%, avg_specificity=92.34% avg_auc=86.14%
Best model saved!! Metric=-26.117247276631907!!
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.444533 Test loss=0.427558 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.443174809217453
[5/24] Train loss=0.3964709937572479
[10/24] Train loss=0.4684849977493286
[15/24] Train loss=0.41619378328323364
[20/24] Train loss=0.4112247824668884
Test set avg_accuracy=79.30% avg_sensitivity=45.03%, avg_specificity=92.37% avg_auc=86.74%
Best model saved!! Metric=-22.563775979136928!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.437329 Test loss=0.416971 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4252614974975586
[5/24] Train loss=0.3930380344390869
[10/24] Train loss=0.46233299374580383
[15/24] Train loss=0.40334999561309814
[20/24] Train loss=0.40236714482307434
Test set avg_accuracy=79.30% avg_sensitivity=41.02%, avg_specificity=93.90% avg_auc=87.55%
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.427396 Test loss=0.405369 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.41510987281799316
[5/24] Train loss=0.3750244975090027
[10/24] Train loss=0.4356139600276947
[15/24] Train loss=0.38438162207603455
[20/24] Train loss=0.39495691657066345
Test set avg_accuracy=79.77% avg_sensitivity=39.51%, avg_specificity=95.13% avg_auc=88.22%
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.414534 Test loss=0.395512 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3939715623855591
[5/24] Train loss=0.3752215802669525
[10/24] Train loss=0.4312353730201721
[15/24] Train loss=0.37898382544517517
[20/24] Train loss=0.38438528776168823
Test set avg_accuracy=81.41% avg_sensitivity=43.99%, avg_specificity=95.68% avg_auc=89.27%
Best model saved!! Metric=-15.652888525062139!!
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.405546 Test loss=0.381590 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3939207196235657
[5/24] Train loss=0.3618139326572418
[10/24] Train loss=0.42208510637283325
[15/24] Train loss=0.3718390464782715
[20/24] Train loss=0.3698797821998596
Test set avg_accuracy=82.75% avg_sensitivity=50.40%, avg_specificity=95.09% avg_auc=89.85%
Best model saved!! Metric=-7.908213586987301!!
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.395739 Test loss=0.371083 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3809279203414917
[5/24] Train loss=0.3520553708076477
[10/24] Train loss=0.4154941737651825
[15/24] Train loss=0.37408900260925293
[20/24] Train loss=0.36208072304725647
Test set avg_accuracy=82.41% avg_sensitivity=47.10%, avg_specificity=95.88% avg_auc=90.22%
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.390709 Test loss=0.366211 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.37044402956962585
[5/24] Train loss=0.3477828800678253
[10/24] Train loss=0.41090846061706543
[15/24] Train loss=0.36434948444366455
[20/24] Train loss=0.3561214804649353
Test set avg_accuracy=82.30% avg_sensitivity=47.52%, avg_specificity=95.57% avg_auc=90.42%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.385090 Test loss=0.362227 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.36865150928497314
[5/24] Train loss=0.3471423089504242
[10/24] Train loss=0.40811866521835327
[15/24] Train loss=0.3620702922344208
[20/24] Train loss=0.34935668110847473
Test set avg_accuracy=82.64% avg_sensitivity=45.87%, avg_specificity=96.67% avg_auc=90.48%
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.380847 Test loss=0.362836 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3618845045566559
[5/24] Train loss=0.34482520818710327
[10/24] Train loss=0.4025062024593353
[15/24] Train loss=0.34943175315856934
[20/24] Train loss=0.3437860310077667
Test set avg_accuracy=81.73% avg_sensitivity=40.41%, avg_specificity=97.50% avg_auc=90.61%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.374028 Test loss=0.368491 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3569291830062866
[5/24] Train loss=0.3403511047363281
[10/24] Train loss=0.3931587338447571
[15/24] Train loss=0.34131935238838196
[20/24] Train loss=0.34452173113822937
Test set avg_accuracy=81.64% avg_sensitivity=40.08%, avg_specificity=97.50% avg_auc=90.74%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.369302 Test loss=0.370205 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.35521942377090454
[5/24] Train loss=0.3274627923965454
[10/24] Train loss=0.3864796757698059
[15/24] Train loss=0.3413139581680298
[20/24] Train loss=0.33165010809898376
Test set avg_accuracy=81.50% avg_sensitivity=38.43%, avg_specificity=97.93% avg_auc=90.84%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.363458 Test loss=0.374102 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3499310314655304
[5/24] Train loss=0.33080175518989563
[10/24] Train loss=0.38888660073280334
[15/24] Train loss=0.3453519940376282
[20/24] Train loss=0.3417097330093384
Test set avg_accuracy=80.35% avg_sensitivity=33.90%, avg_specificity=98.08% avg_auc=90.78%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.363356 Test loss=0.384830 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3534650206565857
[5/24] Train loss=0.326610267162323
[10/24] Train loss=0.384525328874588
[15/24] Train loss=0.3415912091732025
[20/24] Train loss=0.33539363741874695
Test set avg_accuracy=80.73% avg_sensitivity=34.79%, avg_specificity=98.26% avg_auc=90.92%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.361352 Test loss=0.382386 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.35683709383010864
[5/24] Train loss=0.33100783824920654
[10/24] Train loss=0.38451850414276123
[15/24] Train loss=0.33487969636917114
[20/24] Train loss=0.3378625512123108
Test set avg_accuracy=81.76% avg_sensitivity=39.18%, avg_specificity=98.00% avg_auc=91.01%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.359638 Test loss=0.373984 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3476015627384186
[5/24] Train loss=0.33933478593826294
[10/24] Train loss=0.37672725319862366
[15/24] Train loss=0.33800914883613586
[20/24] Train loss=0.3331452012062073
Test set avg_accuracy=82.42% avg_sensitivity=42.15%, avg_specificity=97.79% avg_auc=91.17%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.358827 Test loss=0.365325 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3455568850040436
[5/24] Train loss=0.32725486159324646
[10/24] Train loss=0.3807286024093628
[15/24] Train loss=0.329169362783432
[20/24] Train loss=0.3296980857849121
Test set avg_accuracy=83.16% avg_sensitivity=45.69%, avg_specificity=97.46% avg_auc=91.18%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.355578 Test loss=0.355382 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.34062284231185913
[5/24] Train loss=0.3300609886646271
[10/24] Train loss=0.38649412989616394
[15/24] Train loss=0.32687386870384216
[20/24] Train loss=0.3239416480064392
Test set avg_accuracy=84.17% avg_sensitivity=50.12%, avg_specificity=97.16% avg_auc=91.28%
Best model saved!! Metric=-3.2729465722765383!!
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.353032 Test loss=0.348478 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3430682420730591
[5/24] Train loss=0.32131698727607727
[10/24] Train loss=0.37640631198883057
[15/24] Train loss=0.32630178332328796
[20/24] Train loss=0.3297576308250427
Test set avg_accuracy=84.39% avg_sensitivity=53.61%, avg_specificity=96.13% avg_auc=91.04%
Best model saved!! Metric=-0.8307628135920169!!
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.353202 Test loss=0.347146 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.34385278820991516
[5/24] Train loss=0.3226682245731354
[10/24] Train loss=0.3861424922943115
[15/24] Train loss=0.3254784345626831
[20/24] Train loss=0.32679417729377747
Test set avg_accuracy=84.61% avg_sensitivity=54.22%, avg_specificity=96.20% avg_auc=91.11%
Best model saved!! Metric=0.14510516695700915!!
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.352778 Test loss=0.345047 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.344265341758728
[5/24] Train loss=0.3234008848667145
[10/24] Train loss=0.38038936257362366
[15/24] Train loss=0.32587820291519165
[20/24] Train loss=0.3248829245567322
Test set avg_accuracy=84.66% avg_sensitivity=53.61%, avg_specificity=96.51% avg_auc=91.24%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.350596 Test loss=0.344095 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.34317445755004883
[5/24] Train loss=0.3196295499801636
[10/24] Train loss=0.37791094183921814
[15/24] Train loss=0.3249507546424866
[20/24] Train loss=0.32634419202804565
Test set avg_accuracy=84.75% avg_sensitivity=53.84%, avg_specificity=96.55% avg_auc=91.44%
Best model saved!! Metric=0.5823641991806028!!
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.348869 Test loss=0.342608 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.34329402446746826
[5/24] Train loss=0.32508477568626404
[10/24] Train loss=0.37289488315582275
[15/24] Train loss=0.3188116252422333
[20/24] Train loss=0.32053443789482117
Test set avg_accuracy=84.91% avg_sensitivity=54.31%, avg_specificity=96.58% avg_auc=91.49%
Best model saved!! Metric=1.2912560025637845!!
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.348308 Test loss=0.339777 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.34101366996765137
[5/24] Train loss=0.32110387086868286
[10/24] Train loss=0.37847501039505005
[15/24] Train loss=0.31840208172798157
[20/24] Train loss=0.3290597200393677
Test set avg_accuracy=84.92% avg_sensitivity=54.36%, avg_specificity=96.58% avg_auc=91.51%
Best model saved!! Metric=1.3777122111978173!!
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.347470 Test loss=0.340661 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3407352566719055
[5/24] Train loss=0.3238779902458191
[10/24] Train loss=0.3796541690826416
[15/24] Train loss=0.32309645414352417
[20/24] Train loss=0.32369285821914673
Test set avg_accuracy=85.20% avg_sensitivity=55.82%, avg_specificity=96.40% avg_auc=91.64%
Best model saved!! Metric=3.063969660990182!!
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.347308 Test loss=0.337485 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.33566367626190186
[5/24] Train loss=0.3212715983390808
[10/24] Train loss=0.37192612886428833
[15/24] Train loss=0.3169516921043396
[20/24] Train loss=0.32005318999290466
Test set avg_accuracy=84.96% avg_sensitivity=55.35%, avg_specificity=96.26% avg_auc=91.79%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.345537 Test loss=0.334821 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3348858058452606
[5/24] Train loss=0.3186931908130646
[10/24] Train loss=0.3755095303058624
[15/24] Train loss=0.32322242856025696
[20/24] Train loss=0.31927385926246643
Test set avg_accuracy=84.95% avg_sensitivity=54.79%, avg_specificity=96.46% avg_auc=91.70%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.345171 Test loss=0.336837 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3350139260292053
[5/24] Train loss=0.31704020500183105
[10/24] Train loss=0.37056881189346313
[15/24] Train loss=0.31706544756889343
[20/24] Train loss=0.317342609167099
Test set avg_accuracy=85.17% avg_sensitivity=54.88%, avg_specificity=96.73% avg_auc=91.83%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.343553 Test loss=0.335484 Current lr=[0.00029967723776099]

[0/24] Train loss=0.33805447816848755
[5/24] Train loss=0.32208555936813354
[10/24] Train loss=0.3701086640357971
[15/24] Train loss=0.31637948751449585
[20/24] Train loss=0.32313525676727295
Test set avg_accuracy=85.43% avg_sensitivity=56.67%, avg_specificity=96.40% avg_auc=91.98%
Best model saved!! Metric=4.478518186784669!!
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.342563 Test loss=0.331462 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3354717195034027
[5/24] Train loss=0.3255693018436432
[10/24] Train loss=0.3683723211288452
[15/24] Train loss=0.3199351131916046
[20/24] Train loss=0.3129428029060364
Test set avg_accuracy=85.51% avg_sensitivity=57.47%, avg_specificity=96.20% avg_auc=92.07%
Best model saved!! Metric=5.259811183023025!!
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.342250 Test loss=0.328313 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3357062339782715
[5/24] Train loss=0.3186139762401581
[10/24] Train loss=0.3623792827129364
[15/24] Train loss=0.31679847836494446
[20/24] Train loss=0.31373751163482666
Test set avg_accuracy=85.69% avg_sensitivity=58.84%, avg_specificity=95.93% avg_auc=92.08%
Best model saved!! Metric=6.547819002987254!!
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.340748 Test loss=0.326888 Current lr=[0.000299720220882401]

[0/24] Train loss=0.33262133598327637
[5/24] Train loss=0.3241221010684967
[10/24] Train loss=0.36410072445869446
[15/24] Train loss=0.3092006742954254
[20/24] Train loss=0.31586501002311707
Test set avg_accuracy=85.62% avg_sensitivity=58.65%, avg_specificity=95.92% avg_auc=92.17%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.339490 Test loss=0.325500 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3302501142024994
[5/24] Train loss=0.3219367265701294
[10/24] Train loss=0.36556556820869446
[15/24] Train loss=0.31043505668640137
[20/24] Train loss=0.3095492422580719
Test set avg_accuracy=85.64% avg_sensitivity=58.51%, avg_specificity=95.99% avg_auc=92.17%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.339472 Test loss=0.326117 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3295067250728607
[5/24] Train loss=0.3208901286125183
[10/24] Train loss=0.35917261242866516
[15/24] Train loss=0.31021901965141296
[20/24] Train loss=0.31123119592666626
Test set avg_accuracy=85.29% avg_sensitivity=56.62%, avg_specificity=96.22% avg_auc=92.19%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.337838 Test loss=0.326680 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.33274683356285095
[5/24] Train loss=0.3178569972515106
[10/24] Train loss=0.36024802923202515
[15/24] Train loss=0.31188836693763733
[20/24] Train loss=0.3116705119609833
Test set avg_accuracy=85.33% avg_sensitivity=56.53%, avg_specificity=96.31% avg_auc=92.24%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.337247 Test loss=0.326445 Current lr=[0.000297555943323901]

[0/24] Train loss=0.32774999737739563
[5/24] Train loss=0.31591373682022095
[10/24] Train loss=0.3638927638530731
[15/24] Train loss=0.30779215693473816
[20/24] Train loss=0.31285321712493896
Test set avg_accuracy=85.83% avg_sensitivity=58.65%, avg_specificity=96.20% avg_auc=92.28%
Best model saved!! Metric=6.974175318233371!!
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.336614 Test loss=0.323988 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3280177116394043
[5/24] Train loss=0.3189048171043396
[10/24] Train loss=0.3589136600494385
[15/24] Train loss=0.30386874079704285
[20/24] Train loss=0.310820072889328
Test set avg_accuracy=85.76% avg_sensitivity=58.23%, avg_specificity=96.26% avg_auc=92.30%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.336532 Test loss=0.323719 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.33069586753845215
[5/24] Train loss=0.314166784286499
[10/24] Train loss=0.36141642928123474
[15/24] Train loss=0.3058364987373352
[20/24] Train loss=0.31046029925346375
Test set avg_accuracy=85.89% avg_sensitivity=59.92%, avg_specificity=95.79% avg_auc=92.30%
Best model saved!! Metric=7.901660739613007!!
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.335813 Test loss=0.322667 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.32967281341552734
[5/24] Train loss=0.31504571437835693
[10/24] Train loss=0.35583049058914185
[15/24] Train loss=0.3060484230518341
[20/24] Train loss=0.3131575882434845
Test set avg_accuracy=85.87% avg_sensitivity=59.64%, avg_specificity=95.88% avg_auc=92.36%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.335126 Test loss=0.321515 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.32507020235061646
[5/24] Train loss=0.3143877685070038
[10/24] Train loss=0.3597237467765808
[15/24] Train loss=0.3035518229007721
[20/24] Train loss=0.3105941116809845
Test set avg_accuracy=86.00% avg_sensitivity=60.07%, avg_specificity=95.90% avg_auc=92.35%
Best model saved!! Metric=8.32208032058844!!
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.334202 Test loss=0.321482 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.32875576615333557
[5/24] Train loss=0.31295472383499146
[10/24] Train loss=0.35758084058761597
[15/24] Train loss=0.3032369017601013
[20/24] Train loss=0.30595824122428894
Test set avg_accuracy=85.86% avg_sensitivity=58.89%, avg_specificity=96.15% avg_auc=92.34%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.333656 Test loss=0.322810 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.32841721177101135
[5/24] Train loss=0.3150903880596161
[10/24] Train loss=0.35955533385276794
[15/24] Train loss=0.30600687861442566
[20/24] Train loss=0.30728569626808167
Test set avg_accuracy=86.00% avg_sensitivity=59.83%, avg_specificity=95.99% avg_auc=92.34%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.333230 Test loss=0.321311 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.32483676075935364
[5/24] Train loss=0.30991247296333313
[10/24] Train loss=0.36155015230178833
[15/24] Train loss=0.3011954724788666
[20/24] Train loss=0.30804678797721863
Test set avg_accuracy=85.44% avg_sensitivity=56.62%, avg_specificity=96.44% avg_auc=92.46%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.333020 Test loss=0.322435 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3257734775543213
[5/24] Train loss=0.3123704493045807
[10/24] Train loss=0.36126652359962463
[15/24] Train loss=0.3033902645111084
[20/24] Train loss=0.3077225089073181
Test set avg_accuracy=85.89% avg_sensitivity=59.74%, avg_specificity=95.86% avg_auc=92.39%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.331833 Test loss=0.321537 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3250226080417633
[5/24] Train loss=0.3163164258003235
[10/24] Train loss=0.35551536083221436
[15/24] Train loss=0.3007691204547882
[20/24] Train loss=0.3063324987888336
Test set avg_accuracy=85.51% avg_sensitivity=56.81%, avg_specificity=96.46% avg_auc=92.45%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.331509 Test loss=0.322907 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.324201375246048
[5/24] Train loss=0.3121955394744873
[10/24] Train loss=0.3601093590259552
[15/24] Train loss=0.30209848284721375
[20/24] Train loss=0.30640336871147156
Test set avg_accuracy=85.46% avg_sensitivity=57.43%, avg_specificity=96.15% avg_auc=92.48%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.331147 Test loss=0.320751 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.32526731491088867
[5/24] Train loss=0.31192436814308167
[10/24] Train loss=0.35582390427589417
[15/24] Train loss=0.30350247025489807
[20/24] Train loss=0.30485987663269043
Test set avg_accuracy=86.15% avg_sensitivity=60.91%, avg_specificity=95.77% avg_auc=92.50%
Best model saved!! Metric=9.333048716655647!!
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.330482 Test loss=0.317648 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3223963677883148
[5/24] Train loss=0.3112438917160034
[10/24] Train loss=0.35490119457244873
[15/24] Train loss=0.2984813451766968
[20/24] Train loss=0.30631521344184875
Test set avg_accuracy=86.07% avg_sensitivity=60.63%, avg_specificity=95.77% avg_auc=92.44%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.330662 Test loss=0.319499 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3253045976161957
[5/24] Train loss=0.30785423517227173
[10/24] Train loss=0.36091870069503784
[15/24] Train loss=0.3025200664997101
[20/24] Train loss=0.3060707449913025
Test set avg_accuracy=85.59% avg_sensitivity=57.47%, avg_specificity=96.31% avg_auc=92.47%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.330464 Test loss=0.321698 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.32402002811431885
[5/24] Train loss=0.31456512212753296
[10/24] Train loss=0.35770323872566223
[15/24] Train loss=0.30141451954841614
[20/24] Train loss=0.2991091310977936
Test set avg_accuracy=86.18% avg_sensitivity=61.10%, avg_specificity=95.75% avg_auc=92.46%
Best model saved!! Metric=9.505937720884958!!
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.330086 Test loss=0.317866 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.32530757784843445
[5/24] Train loss=0.3123698830604553
[10/24] Train loss=0.35304462909698486
[15/24] Train loss=0.303030788898468
[20/24] Train loss=0.29945647716522217
Test set avg_accuracy=85.81% avg_sensitivity=59.17%, avg_specificity=95.97% avg_auc=92.52%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.329190 Test loss=0.318748 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3248763084411621
[5/24] Train loss=0.306924968957901
[10/24] Train loss=0.3568783104419708
[15/24] Train loss=0.2981317937374115
[20/24] Train loss=0.29365020990371704
Test set avg_accuracy=86.38% avg_sensitivity=62.19%, avg_specificity=95.61% avg_auc=92.46%
Best model saved!! Metric=10.64210677666621!!
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.328262 Test loss=0.316977 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.321270614862442
[5/24] Train loss=0.3104669153690338
[10/24] Train loss=0.3577073812484741
[15/24] Train loss=0.2996765375137329
[20/24] Train loss=0.2953783869743347
Test set avg_accuracy=86.08% avg_sensitivity=60.11%, avg_specificity=95.99% avg_auc=92.53%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.328434 Test loss=0.317554 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.32267260551452637
[5/24] Train loss=0.31009215116500854
[10/24] Train loss=0.3579426109790802
[15/24] Train loss=0.3000534176826477
[20/24] Train loss=0.2911824584007263
Test set avg_accuracy=86.24% avg_sensitivity=61.06%, avg_specificity=95.84% avg_auc=92.55%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.328352 Test loss=0.315892 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.32326439023017883
[5/24] Train loss=0.3112231194972992
[10/24] Train loss=0.36003419756889343
[15/24] Train loss=0.2951596677303314
[20/24] Train loss=0.29677900671958923
Test set avg_accuracy=85.69% avg_sensitivity=58.27%, avg_specificity=96.15% avg_auc=92.60%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.327985 Test loss=0.317890 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3260689079761505
[5/24] Train loss=0.3137735426425934
[10/24] Train loss=0.3553096055984497
[15/24] Train loss=0.2967689633369446
[20/24] Train loss=0.2941107153892517
Test set avg_accuracy=86.08% avg_sensitivity=59.88%, avg_specificity=96.08% avg_auc=92.57%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.328279 Test loss=0.317170 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3180854618549347
[5/24] Train loss=0.3111332058906555
[10/24] Train loss=0.3574744760990143
[15/24] Train loss=0.29713472723960876
[20/24] Train loss=0.2950693666934967
Test set avg_accuracy=85.92% avg_sensitivity=59.59%, avg_specificity=95.97% avg_auc=92.60%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.326872 Test loss=0.316882 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.32180410623550415
[5/24] Train loss=0.3119516670703888
[10/24] Train loss=0.3582729399204254
[15/24] Train loss=0.2998118996620178
[20/24] Train loss=0.29461970925331116
Test set avg_accuracy=85.60% avg_sensitivity=57.14%, avg_specificity=96.46% avg_auc=92.73%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.326216 Test loss=0.318203 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3178935647010803
[5/24] Train loss=0.312275767326355
[10/24] Train loss=0.3582301437854767
[15/24] Train loss=0.2959170639514923
[20/24] Train loss=0.29402652382850647
Test set avg_accuracy=85.95% avg_sensitivity=58.84%, avg_specificity=96.29% avg_auc=92.68%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.327472 Test loss=0.316492 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.31840142607688904
[5/24] Train loss=0.30934518575668335
[10/24] Train loss=0.3558773994445801
[15/24] Train loss=0.30310189723968506
[20/24] Train loss=0.28976741433143616
Test set avg_accuracy=85.59% avg_sensitivity=57.66%, avg_specificity=96.24% avg_auc=92.72%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.325165 Test loss=0.316477 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3178388178348541
[5/24] Train loss=0.3092617690563202
[10/24] Train loss=0.35425251722335815
[15/24] Train loss=0.29333847761154175
[20/24] Train loss=0.292890340089798
Test set avg_accuracy=85.22% avg_sensitivity=55.92%, avg_specificity=96.40% avg_auc=92.75%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.325058 Test loss=0.317913 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.31579166650772095
[5/24] Train loss=0.30597198009490967
[10/24] Train loss=0.3519023358821869
[15/24] Train loss=0.3009202778339386
[20/24] Train loss=0.286584734916687
Test set avg_accuracy=85.04% avg_sensitivity=55.40%, avg_specificity=96.35% avg_auc=92.71%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.325172 Test loss=0.317974 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.31591683626174927
[5/24] Train loss=0.30727484822273254
[10/24] Train loss=0.35600757598876953
[15/24] Train loss=0.29998838901519775
[20/24] Train loss=0.2850731611251831
Test set avg_accuracy=84.18% avg_sensitivity=50.68%, avg_specificity=96.96% avg_auc=92.57%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.326657 Test loss=0.327296 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3192440867424011
[5/24] Train loss=0.31169208884239197
[10/24] Train loss=0.3537932336330414
[15/24] Train loss=0.3018092215061188
[20/24] Train loss=0.2906285226345062
Test set avg_accuracy=83.42% avg_sensitivity=46.53%, avg_specificity=97.50% avg_auc=92.23%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.329296 Test loss=0.337052 Current lr=[0.000224838296036774]

[0/24] Train loss=0.32422155141830444
[5/24] Train loss=0.31014782190322876
[10/24] Train loss=0.3601495921611786
[15/24] Train loss=0.30411937832832336
[20/24] Train loss=0.2855627238750458
Test set avg_accuracy=83.97% avg_sensitivity=49.69%, avg_specificity=97.05% avg_auc=92.58%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.327251 Test loss=0.328478 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3206387162208557
[5/24] Train loss=0.30946630239486694
[10/24] Train loss=0.358598917722702
[15/24] Train loss=0.2920537292957306
[20/24] Train loss=0.28684720396995544
Test set avg_accuracy=84.67% avg_sensitivity=52.85%, avg_specificity=96.82% avg_auc=92.66%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.325205 Test loss=0.322632 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.31722167134284973
[5/24] Train loss=0.3128027021884918
[10/24] Train loss=0.35941222310066223
[15/24] Train loss=0.2960315942764282
[20/24] Train loss=0.28359007835388184
Test set avg_accuracy=84.58% avg_sensitivity=52.43%, avg_specificity=96.85% avg_auc=92.73%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.324961 Test loss=0.322253 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.31885042786598206
[5/24] Train loss=0.3116358518600464
[10/24] Train loss=0.3582991361618042
[15/24] Train loss=0.2977195382118225
[20/24] Train loss=0.2883155941963196
Test set avg_accuracy=84.56% avg_sensitivity=52.10%, avg_specificity=96.94% avg_auc=92.74%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.326570 Test loss=0.323993 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.31843793392181396
[5/24] Train loss=0.3101188540458679
[10/24] Train loss=0.3564006984233856
[15/24] Train loss=0.29803675413131714
[20/24] Train loss=0.2844194173812866
Test set avg_accuracy=84.49% avg_sensitivity=51.39%, avg_specificity=97.12% avg_auc=92.74%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.325456 Test loss=0.325379 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.31833943724632263
[5/24] Train loss=0.31479790806770325
[10/24] Train loss=0.3540147542953491
[15/24] Train loss=0.2946736812591553
[20/24] Train loss=0.2863772213459015
Test set avg_accuracy=84.49% avg_sensitivity=51.30%, avg_specificity=97.16% avg_auc=92.74%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.325693 Test loss=0.325324 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3191626965999603
[5/24] Train loss=0.31492623686790466
[10/24] Train loss=0.3553696870803833
[15/24] Train loss=0.30037760734558105
[20/24] Train loss=0.28462621569633484
Test set avg_accuracy=83.62% avg_sensitivity=47.67%, avg_specificity=97.34% avg_auc=92.58%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.326721 Test loss=0.334570 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3229374587535858
[5/24] Train loss=0.3128002882003784
[10/24] Train loss=0.35765981674194336
[15/24] Train loss=0.30774372816085815
[20/24] Train loss=0.284053236246109
Test set avg_accuracy=83.98% avg_sensitivity=49.17%, avg_specificity=97.27% avg_auc=92.55%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.327416 Test loss=0.331436 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.32191288471221924
[5/24] Train loss=0.31280410289764404
[10/24] Train loss=0.35593709349632263
[15/24] Train loss=0.2968534231185913
[20/24] Train loss=0.285178005695343
Test set avg_accuracy=84.39% avg_sensitivity=51.01%, avg_specificity=97.12% avg_auc=92.71%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.325240 Test loss=0.325798 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.32156044244766235
[5/24] Train loss=0.3101392388343811
[10/24] Train loss=0.35333549976348877
[15/24] Train loss=0.2969948649406433
[20/24] Train loss=0.285469651222229
Test set avg_accuracy=84.82% avg_sensitivity=52.81%, avg_specificity=97.03% avg_auc=92.76%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.323649 Test loss=0.322915 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3176842927932739
[5/24] Train loss=0.30838629603385925
[10/24] Train loss=0.352038711309433
[15/24] Train loss=0.29751187562942505
[20/24] Train loss=0.28099194169044495
Test set avg_accuracy=85.01% avg_sensitivity=53.70%, avg_specificity=96.96% avg_auc=92.74%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.323953 Test loss=0.321539 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3191119134426117
[5/24] Train loss=0.3099173903465271
[10/24] Train loss=0.35189253091812134
[15/24] Train loss=0.2976631224155426
[20/24] Train loss=0.28160104155540466
Test set avg_accuracy=85.14% avg_sensitivity=54.31%, avg_specificity=96.91% avg_auc=92.78%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.324533 Test loss=0.319796 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3168993890285492
[5/24] Train loss=0.3102681040763855
[10/24] Train loss=0.3490811884403229
[15/24] Train loss=0.3008786141872406
[20/24] Train loss=0.28673255443573
Test set avg_accuracy=85.78% avg_sensitivity=58.04%, avg_specificity=96.37% avg_auc=92.76%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.324162 Test loss=0.314472 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.31319892406463623
[5/24] Train loss=0.3105695843696594
[10/24] Train loss=0.3474794030189514
[15/24] Train loss=0.30047374963760376
[20/24] Train loss=0.28681614995002747
Test set avg_accuracy=86.48% avg_sensitivity=62.33%, avg_specificity=95.70% avg_auc=92.76%
Best model saved!! Metric=11.274531496183116!!
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.324441 Test loss=0.311052 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.31931281089782715
[5/24] Train loss=0.30474644899368286
[10/24] Train loss=0.35046401619911194
[15/24] Train loss=0.29773399233818054
[20/24] Train loss=0.2924627959728241
Test set avg_accuracy=86.52% avg_sensitivity=62.66%, avg_specificity=95.63% avg_auc=92.65%
Best model saved!! Metric=11.457708322811222!!
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.323613 Test loss=0.312053 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3212234079837799
[5/24] Train loss=0.30683812499046326
[10/24] Train loss=0.35008564591407776
[15/24] Train loss=0.29704591631889343
[20/24] Train loss=0.2903567850589752
Test set avg_accuracy=86.50% avg_sensitivity=63.08%, avg_specificity=95.43% avg_auc=92.70%
Best model saved!! Metric=11.714823489289877!!
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.323221 Test loss=0.310401 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3189167082309723
[5/24] Train loss=0.3021644055843353
[10/24] Train loss=0.3503251075744629
[15/24] Train loss=0.2913150191307068
[20/24] Train loss=0.2884407639503479
Test set avg_accuracy=86.45% avg_sensitivity=62.38%, avg_specificity=95.63% avg_auc=92.71%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.321154 Test loss=0.310909 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.32047533988952637
[5/24] Train loss=0.3085656762123108
[10/24] Train loss=0.3488350212574005
[15/24] Train loss=0.29399389028549194
[20/24] Train loss=0.29052481055259705
Test set avg_accuracy=86.55% avg_sensitivity=62.80%, avg_specificity=95.61% avg_auc=92.78%
Best model saved!! Metric=11.735848285422662!!
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.321137 Test loss=0.309565 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.31672218441963196
[5/24] Train loss=0.305754691362381
[10/24] Train loss=0.35276299715042114
[15/24] Train loss=0.2926303744316101
[20/24] Train loss=0.29038354754447937
Test set avg_accuracy=86.41% avg_sensitivity=61.76%, avg_specificity=95.81% avg_auc=92.71%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.321169 Test loss=0.311753 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.31807059049606323
[5/24] Train loss=0.3067290186882019
[10/24] Train loss=0.3533467650413513
[15/24] Train loss=0.2907472550868988
[20/24] Train loss=0.28653064370155334
Test set avg_accuracy=86.21% avg_sensitivity=60.77%, avg_specificity=95.92% avg_auc=92.87%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.320756 Test loss=0.309302 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3185243308544159
[5/24] Train loss=0.3082628846168518
[10/24] Train loss=0.35354456305503845
[15/24] Train loss=0.29516831040382385
[20/24] Train loss=0.2842960059642792
Test set avg_accuracy=86.39% avg_sensitivity=62.14%, avg_specificity=95.65% avg_auc=92.81%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.321598 Test loss=0.309303 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3151441216468811
[5/24] Train loss=0.30508098006248474
[10/24] Train loss=0.3552255630493164
[15/24] Train loss=0.2960709035396576
[20/24] Train loss=0.28665226697921753
Test set avg_accuracy=86.55% avg_sensitivity=62.75%, avg_specificity=95.63% avg_auc=92.92%
Best model saved!! Metric=11.848857427675242!!
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.321750 Test loss=0.306446 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.31356489658355713
[5/24] Train loss=0.29913872480392456
[10/24] Train loss=0.3536015748977661
[15/24] Train loss=0.29625996947288513
[20/24] Train loss=0.2899967432022095
Test set avg_accuracy=86.73% avg_sensitivity=63.98%, avg_specificity=95.41% avg_auc=92.91%
Best model saved!! Metric=13.035271941288556!!
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.321443 Test loss=0.306189 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.31862837076187134
[5/24] Train loss=0.3049474358558655
[10/24] Train loss=0.35669806599617004
[15/24] Train loss=0.2951694130897522
[20/24] Train loss=0.29010483622550964
Test set avg_accuracy=86.81% avg_sensitivity=64.36%, avg_specificity=95.38% avg_auc=92.87%
Best model saved!! Metric=13.415076943534388!!
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.320919 Test loss=0.306410 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3164317309856415
[5/24] Train loss=0.3077493906021118
[10/24] Train loss=0.3555600643157959
[15/24] Train loss=0.28912246227264404
[20/24] Train loss=0.2882976830005646
Test set avg_accuracy=86.54% avg_sensitivity=62.94%, avg_specificity=95.54% avg_auc=92.93%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.319430 Test loss=0.306035 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3181757628917694
[5/24] Train loss=0.307667076587677
[10/24] Train loss=0.354416161775589
[15/24] Train loss=0.29275059700012207
[20/24] Train loss=0.2849518358707428
Test set avg_accuracy=86.25% avg_sensitivity=61.95%, avg_specificity=95.52% avg_auc=92.96%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.318616 Test loss=0.306065 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.31852081418037415
[5/24] Train loss=0.30555060505867004
[10/24] Train loss=0.3563116788864136
[15/24] Train loss=0.28996649384498596
[20/24] Train loss=0.28434908390045166
Test set avg_accuracy=86.41% avg_sensitivity=62.89%, avg_specificity=95.38% avg_auc=92.96%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.318428 Test loss=0.305556 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3149487376213074
[5/24] Train loss=0.31149759888648987
[10/24] Train loss=0.35689032077789307
[15/24] Train loss=0.2900067865848541
[20/24] Train loss=0.2893262803554535
Test set avg_accuracy=86.88% avg_sensitivity=64.78%, avg_specificity=95.30% avg_auc=93.02%
Best model saved!! Metric=13.975675883639553!!
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.319129 Test loss=0.304241 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.31384336948394775
[5/24] Train loss=0.30734845995903015
[10/24] Train loss=0.3595983684062958
[15/24] Train loss=0.2915021479129791
[20/24] Train loss=0.28131601214408875
Test set avg_accuracy=86.80% avg_sensitivity=64.55%, avg_specificity=95.29% avg_auc=93.01%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.319212 Test loss=0.304239 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3151278793811798
[5/24] Train loss=0.30668410658836365
[10/24] Train loss=0.3644285500049591
[15/24] Train loss=0.2900664210319519
[20/24] Train loss=0.2833734154701233
Test set avg_accuracy=87.20% avg_sensitivity=66.81%, avg_specificity=94.98% avg_auc=92.99%
Best model saved!! Metric=15.982500843068166!!
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.319549 Test loss=0.304255 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.32117825746536255
[5/24] Train loss=0.3150992691516876
[10/24] Train loss=0.363397479057312
[15/24] Train loss=0.29418566823005676
[20/24] Train loss=0.28583264350891113
Test set avg_accuracy=87.51% avg_sensitivity=70.20%, avg_specificity=94.12% avg_auc=92.90%
Best model saved!! Metric=18.735865159243062!!
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.321103 Test loss=0.305795 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3248566687107086
[5/24] Train loss=0.3195839822292328
[10/24] Train loss=0.3708071708679199
[15/24] Train loss=0.2893624007701874
[20/24] Train loss=0.2968285381793976
Test set avg_accuracy=87.08% avg_sensitivity=72.56%, avg_specificity=92.62% avg_auc=92.73%
Best model saved!! Metric=18.995258208651805!!
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.324901 Test loss=0.311760 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3383321166038513
[5/24] Train loss=0.31741005182266235
[10/24] Train loss=0.35545364022254944
[15/24] Train loss=0.3027643859386444
[20/24] Train loss=0.32012152671813965
Test set avg_accuracy=87.24% avg_sensitivity=67.99%, avg_specificity=94.59% avg_auc=93.00%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.327193 Test loss=0.304556 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.31975263357162476
[5/24] Train loss=0.3056398332118988
[10/24] Train loss=0.35585206747055054
[15/24] Train loss=0.2997555434703827
[20/24] Train loss=0.29816049337387085
Test set avg_accuracy=86.35% avg_sensitivity=61.95%, avg_specificity=95.66% avg_auc=92.94%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.322525 Test loss=0.306827 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3152529299259186
[5/24] Train loss=0.3130004405975342
[10/24] Train loss=0.35713788866996765
[15/24] Train loss=0.2948775589466095
[20/24] Train loss=0.2900632917881012
Test set avg_accuracy=86.93% avg_sensitivity=65.72%, avg_specificity=95.02% avg_auc=92.86%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.319370 Test loss=0.307004 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.321912944316864
[5/24] Train loss=0.312064528465271
[10/24] Train loss=0.3635042905807495
[15/24] Train loss=0.2941907048225403
[20/24] Train loss=0.2988491952419281
Test set avg_accuracy=86.77% avg_sensitivity=65.49%, avg_specificity=94.89% avg_auc=92.66%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.322105 Test loss=0.310848 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3276863694190979
[5/24] Train loss=0.31130945682525635
[10/24] Train loss=0.35427412390708923
[15/24] Train loss=0.2992897927761078
[20/24] Train loss=0.3068167567253113
Test set avg_accuracy=86.88% avg_sensitivity=65.49%, avg_specificity=95.04% avg_auc=92.74%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.322000 Test loss=0.309711 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.32438743114471436
[5/24] Train loss=0.30796998739242554
[10/24] Train loss=0.3507358729839325
[15/24] Train loss=0.3033808171749115
[20/24] Train loss=0.3018104135990143
Test set avg_accuracy=86.33% avg_sensitivity=62.09%, avg_specificity=95.57% avg_auc=93.00%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.321221 Test loss=0.306338 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.317831426858902
[5/24] Train loss=0.29892319440841675
[10/24] Train loss=0.35184231400489807
[15/24] Train loss=0.2954499423503876
[20/24] Train loss=0.2969895303249359
Test set avg_accuracy=86.26% avg_sensitivity=61.43%, avg_specificity=95.74% avg_auc=93.05%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.318574 Test loss=0.306240 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3124746084213257
[5/24] Train loss=0.2979166507720947
[10/24] Train loss=0.34763115644454956
[15/24] Train loss=0.29645413160324097
[20/24] Train loss=0.29370373487472534
Test set avg_accuracy=86.24% avg_sensitivity=61.62%, avg_specificity=95.63% avg_auc=93.04%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.316547 Test loss=0.306046 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3099870979785919
[5/24] Train loss=0.3050040602684021
[10/24] Train loss=0.3471100330352783
[15/24] Train loss=0.2970258891582489
[20/24] Train loss=0.2956730127334595
Test set avg_accuracy=86.35% avg_sensitivity=62.28%, avg_specificity=95.54% avg_auc=93.04%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.316995 Test loss=0.305710 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.314358115196228
[5/24] Train loss=0.3023301959037781
[10/24] Train loss=0.3503783643245697
[15/24] Train loss=0.2962370216846466
[20/24] Train loss=0.29219290614128113
Test set avg_accuracy=86.12% avg_sensitivity=60.49%, avg_specificity=95.90% avg_auc=93.05%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.316630 Test loss=0.306582 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.31297358870506287
[5/24] Train loss=0.30121177434921265
[10/24] Train loss=0.34711623191833496
[15/24] Train loss=0.2934456765651703
[20/24] Train loss=0.28957146406173706
Test set avg_accuracy=86.18% avg_sensitivity=60.82%, avg_specificity=95.86% avg_auc=93.04%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.315658 Test loss=0.306761 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3117748498916626
[5/24] Train loss=0.30490219593048096
[10/24] Train loss=0.3448869287967682
[15/24] Train loss=0.295097291469574
[20/24] Train loss=0.2899513840675354
Test set avg_accuracy=86.12% avg_sensitivity=60.58%, avg_specificity=95.86% avg_auc=93.05%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.316236 Test loss=0.307146 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.31315556168556213
[5/24] Train loss=0.29651185870170593
[10/24] Train loss=0.351651668548584
[15/24] Train loss=0.29406899213790894
[20/24] Train loss=0.2899051606655121
Test set avg_accuracy=86.22% avg_sensitivity=61.34%, avg_specificity=95.72% avg_auc=93.06%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.315292 Test loss=0.306211 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3106614351272583
[5/24] Train loss=0.3045549988746643
[10/24] Train loss=0.3468341827392578
[15/24] Train loss=0.29628786444664
[20/24] Train loss=0.2890622019767761
Test set avg_accuracy=86.13% avg_sensitivity=60.73%, avg_specificity=95.83% avg_auc=93.05%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.315151 Test loss=0.306609 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.31154879927635193
[5/24] Train loss=0.2990652322769165
[10/24] Train loss=0.34408923983573914
[15/24] Train loss=0.2890196144580841
[20/24] Train loss=0.29284369945526123
Test set avg_accuracy=86.08% avg_sensitivity=60.49%, avg_specificity=95.84% avg_auc=93.06%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.314680 Test loss=0.306844 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.31159693002700806
[5/24] Train loss=0.29959118366241455
[10/24] Train loss=0.344074010848999
[15/24] Train loss=0.2923312783241272
[20/24] Train loss=0.28578925132751465
Test set avg_accuracy=86.25% avg_sensitivity=60.96%, avg_specificity=95.90% avg_auc=93.06%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.314412 Test loss=0.306779 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.31324276328086853
[5/24] Train loss=0.30399584770202637
[10/24] Train loss=0.34674015641212463
[15/24] Train loss=0.2931338846683502
[20/24] Train loss=0.2863791584968567
Test set avg_accuracy=86.11% avg_sensitivity=60.54%, avg_specificity=95.86% avg_auc=93.07%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.314903 Test loss=0.306790 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3140474557876587
[5/24] Train loss=0.3008953630924225
[10/24] Train loss=0.3480828106403351
[15/24] Train loss=0.2922236919403076
[20/24] Train loss=0.28396472334861755
Test set avg_accuracy=86.29% avg_sensitivity=61.53%, avg_specificity=95.74% avg_auc=93.07%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.314516 Test loss=0.305875 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3166090250015259
[5/24] Train loss=0.29815489053726196
[10/24] Train loss=0.34598979353904724
[15/24] Train loss=0.2910117506980896
[20/24] Train loss=0.28366780281066895
Test set avg_accuracy=86.39% avg_sensitivity=62.28%, avg_specificity=95.59% avg_auc=93.07%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.313976 Test loss=0.305227 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3083045482635498
[5/24] Train loss=0.3012688159942627
[10/24] Train loss=0.3457816541194916
[15/24] Train loss=0.28908997774124146
[20/24] Train loss=0.28152701258659363
Test set avg_accuracy=86.32% avg_sensitivity=62.05%, avg_specificity=95.57% avg_auc=93.07%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.313847 Test loss=0.305164 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.31142833828926086
[5/24] Train loss=0.3020550012588501
[10/24] Train loss=0.34451809525489807
[15/24] Train loss=0.2918131947517395
[20/24] Train loss=0.2852906584739685
Test set avg_accuracy=86.65% avg_sensitivity=63.51%, avg_specificity=95.48% avg_auc=93.06%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.314617 Test loss=0.304508 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.31813299655914307
[5/24] Train loss=0.3001590669155121
[10/24] Train loss=0.34538328647613525
[15/24] Train loss=0.2873675227165222
[20/24] Train loss=0.2849213480949402
Test set avg_accuracy=86.56% avg_sensitivity=63.22%, avg_specificity=95.47% avg_auc=93.06%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.314156 Test loss=0.304659 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.3154659569263458
[5/24] Train loss=0.30393317341804504
[10/24] Train loss=0.3453308939933777
[15/24] Train loss=0.2908359169960022
[20/24] Train loss=0.2842649519443512
Test set avg_accuracy=86.42% avg_sensitivity=62.66%, avg_specificity=95.48% avg_auc=93.04%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.314555 Test loss=0.305213 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.31254714727401733
[5/24] Train loss=0.3019844889640808
[10/24] Train loss=0.34838348627090454
[15/24] Train loss=0.2889416813850403
[20/24] Train loss=0.2853509187698364
Test set avg_accuracy=86.30% avg_sensitivity=62.00%, avg_specificity=95.57% avg_auc=93.04%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.313797 Test loss=0.305582 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.31445232033729553
[5/24] Train loss=0.2988463342189789
[10/24] Train loss=0.3477442264556885
[15/24] Train loss=0.28821954131126404
[20/24] Train loss=0.28687578439712524
Test set avg_accuracy=86.24% avg_sensitivity=61.39%, avg_specificity=95.72% avg_auc=93.07%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.313557 Test loss=0.305588 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.3136783838272095
[5/24] Train loss=0.30080217123031616
[10/24] Train loss=0.3456417918205261
[15/24] Train loss=0.2877974212169647
[20/24] Train loss=0.28905752301216125
Test set avg_accuracy=86.15% avg_sensitivity=60.77%, avg_specificity=95.83% avg_auc=93.09%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.313337 Test loss=0.306020 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.31130000948905945
[5/24] Train loss=0.29687801003456116
[10/24] Train loss=0.3467220366001129
[15/24] Train loss=0.2925935685634613
[20/24] Train loss=0.28333601355552673
Test set avg_accuracy=86.12% avg_sensitivity=60.87%, avg_specificity=95.75% avg_auc=93.09%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.312881 Test loss=0.305928 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.32042956352233887
[5/24] Train loss=0.29805323481559753
[10/24] Train loss=0.34377020597457886
[15/24] Train loss=0.2904433608055115
[20/24] Train loss=0.28442782163619995
Test set avg_accuracy=86.26% avg_sensitivity=61.34%, avg_specificity=95.77% avg_auc=93.08%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.313498 Test loss=0.305988 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.31151649355888367
[5/24] Train loss=0.29718488454818726
[10/24] Train loss=0.3481892943382263
[15/24] Train loss=0.2911987602710724
[20/24] Train loss=0.2861345410346985
Test set avg_accuracy=86.24% avg_sensitivity=61.10%, avg_specificity=95.83% avg_auc=93.09%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.312751 Test loss=0.306104 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3099443316459656
[5/24] Train loss=0.29911452531814575
[10/24] Train loss=0.3461928963661194
[15/24] Train loss=0.2898808419704437
[20/24] Train loss=0.2864561676979065
Test set avg_accuracy=86.17% avg_sensitivity=60.77%, avg_specificity=95.86% avg_auc=93.08%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.313022 Test loss=0.306171 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.312794953584671
[5/24] Train loss=0.2995474338531494
[10/24] Train loss=0.34762313961982727
[15/24] Train loss=0.28884586691856384
[20/24] Train loss=0.28662389516830444
Test set avg_accuracy=86.17% avg_sensitivity=60.68%, avg_specificity=95.90% avg_auc=93.09%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.312881 Test loss=0.306334 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.31288018822669983
[5/24] Train loss=0.3010489046573639
[10/24] Train loss=0.3430942893028259
[15/24] Train loss=0.28457579016685486
[20/24] Train loss=0.2823981046676636
Test set avg_accuracy=86.05% avg_sensitivity=60.25%, avg_specificity=95.90% avg_auc=93.09%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.312904 Test loss=0.306467 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.31164559721946716
[5/24] Train loss=0.2993641793727875
[10/24] Train loss=0.34634917974472046
[15/24] Train loss=0.29137834906578064
[20/24] Train loss=0.2895984351634979
Test set avg_accuracy=86.07% avg_sensitivity=60.25%, avg_specificity=95.92% avg_auc=93.09%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.312701 Test loss=0.306460 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3136192560195923
[5/24] Train loss=0.3016546070575714
[10/24] Train loss=0.3465263843536377
[15/24] Train loss=0.2884714901447296
[20/24] Train loss=0.28363561630249023
Test set avg_accuracy=86.08% avg_sensitivity=60.35%, avg_specificity=95.90% avg_auc=93.09%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.313325 Test loss=0.306405 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.31272807717323303
[5/24] Train loss=0.2996787428855896
[10/24] Train loss=0.3472129702568054
[15/24] Train loss=0.2856551706790924
[20/24] Train loss=0.2876777946949005
Test set avg_accuracy=86.05% avg_sensitivity=60.25%, avg_specificity=95.90% avg_auc=93.09%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.313156 Test loss=0.306472 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.31150951981544495
[5/24] Train loss=0.29890701174736023
[10/24] Train loss=0.34481483697891235
[15/24] Train loss=0.2878982722759247
[20/24] Train loss=0.27985769510269165
Test set avg_accuracy=86.05% avg_sensitivity=60.25%, avg_specificity=95.90% avg_auc=93.09%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.312626 Test loss=0.306481 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3057097792625427
[5/24] Train loss=0.29725778102874756
[10/24] Train loss=0.3477155864238739
[15/24] Train loss=0.2902202010154724
[20/24] Train loss=0.2815277576446533
Test set avg_accuracy=86.05% avg_sensitivity=60.25%, avg_specificity=95.90% avg_auc=93.09%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.312270 Test loss=0.306474 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3090973198413849
[5/24] Train loss=0.3028483986854553
[10/24] Train loss=0.35046008229255676
[15/24] Train loss=0.28901487588882446
[20/24] Train loss=0.2841547727584839
Test set avg_accuracy=86.05% avg_sensitivity=60.25%, avg_specificity=95.90% avg_auc=93.09%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.312966 Test loss=0.306478 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=87.08% sen=72.56%, spe=92.62%, auc=92.73%!
Fold[7] Avg_overlap=0.70%(0.21451540918281745)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'HybridCNNRNN',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.9072409868240356
[5/24] Train loss=0.7659039497375488
[10/24] Train loss=0.6981538534164429
[15/24] Train loss=0.6508800983428955
[20/24] Train loss=0.6140120029449463
Test set avg_accuracy=74.87% avg_sensitivity=0.57%, avg_specificity=99.83% avg_auc=50.07%
Best model saved!! Metric=-100.66060647791419!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.707157 Test loss=0.587233 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6265612840652466
[5/24] Train loss=0.5939485430717468
[10/24] Train loss=0.6122385263442993
[15/24] Train loss=0.5905764698982239
[20/24] Train loss=0.5779907703399658
Test set avg_accuracy=74.82% avg_sensitivity=0.00%, avg_specificity=99.95% avg_auc=51.98%
Best model saved!! Metric=-99.2570519721763!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.603668 Test loss=0.569234 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6162554621696472
[5/24] Train loss=0.5818546414375305
[10/24] Train loss=0.6009028553962708
[15/24] Train loss=0.5847496390342712
[20/24] Train loss=0.5696228742599487
Test set avg_accuracy=74.80% avg_sensitivity=0.00%, avg_specificity=99.93% avg_auc=55.07%
Best model saved!! Metric=-96.19243851718768!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.594091 Test loss=0.564667 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6054352521896362
[5/24] Train loss=0.5722444653511047
[10/24] Train loss=0.5986637473106384
[15/24] Train loss=0.5815669298171997
[20/24] Train loss=0.5639559030532837
Test set avg_accuracy=74.82% avg_sensitivity=0.05%, avg_specificity=99.93% avg_auc=58.05%
Best model saved!! Metric=-93.15449785225596!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.588922 Test loss=0.558971 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6027101874351501
[5/24] Train loss=0.5563305616378784
[10/24] Train loss=0.5836712121963501
[15/24] Train loss=0.5753617286682129
[20/24] Train loss=0.5581061840057373
Test set avg_accuracy=74.84% avg_sensitivity=0.10%, avg_specificity=99.95% avg_auc=61.54%
Best model saved!! Metric=-89.56925299540983!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.580095 Test loss=0.551333 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5883258581161499
[5/24] Train loss=0.5530964136123657
[10/24] Train loss=0.5785232782363892
[15/24] Train loss=0.5671295523643494
[20/24] Train loss=0.5456879138946533
Test set avg_accuracy=74.82% avg_sensitivity=0.10%, avg_specificity=99.91% avg_auc=65.12%
Best model saved!! Metric=-86.04200518359201!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.571422 Test loss=0.544583 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5777882933616638
[5/24] Train loss=0.5444236993789673
[10/24] Train loss=0.571004331111908
[15/24] Train loss=0.562102735042572
[20/24] Train loss=0.5352140665054321
Test set avg_accuracy=74.80% avg_sensitivity=0.10%, avg_specificity=99.90% avg_auc=69.03%
Best model saved!! Metric=-82.16883465534026!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.563664 Test loss=0.535798 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.569674015045166
[5/24] Train loss=0.5299807786941528
[10/24] Train loss=0.5684600472450256
[15/24] Train loss=0.5441948175430298
[20/24] Train loss=0.5276159048080444
Test set avg_accuracy=74.86% avg_sensitivity=0.36%, avg_specificity=99.88% avg_auc=72.77%
Best model saved!! Metric=-78.13741787523362!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.553319 Test loss=0.524930 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.565890908241272
[5/24] Train loss=0.5250601768493652
[10/24] Train loss=0.5510058403015137
[15/24] Train loss=0.5320770740509033
[20/24] Train loss=0.5051403045654297
Test set avg_accuracy=74.77% avg_sensitivity=0.57%, avg_specificity=99.69% avg_auc=75.91%
Best model saved!! Metric=-75.06889862732753!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.541205 Test loss=0.512444 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5422576069831848
[5/24] Train loss=0.5035709738731384
[10/24] Train loss=0.537733256816864
[15/24] Train loss=0.5122146606445312
[20/24] Train loss=0.4955156445503235
Test set avg_accuracy=75.04% avg_sensitivity=1.92%, avg_specificity=99.60% avg_auc=78.23%
Best model saved!! Metric=-71.21466590830894!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.526051 Test loss=0.498439 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5220152735710144
[5/24] Train loss=0.4822647273540497
[10/24] Train loss=0.531141996383667
[15/24] Train loss=0.49764302372932434
[20/24] Train loss=0.47558680176734924
Test set avg_accuracy=74.73% avg_sensitivity=4.14%, avg_specificity=98.43% avg_auc=79.84%
Best model saved!! Metric=-68.85380790463391!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.509958 Test loss=0.483689 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5028664469718933
[5/24] Train loss=0.46067240834236145
[10/24] Train loss=0.5144256353378296
[15/24] Train loss=0.48254287242889404
[20/24] Train loss=0.4552595913410187
Test set avg_accuracy=74.52% avg_sensitivity=8.29%, avg_specificity=96.76% avg_auc=81.33%
Best model saved!! Metric=-65.10460700262095!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.493389 Test loss=0.468554 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4870905876159668
[5/24] Train loss=0.4530462622642517
[10/24] Train loss=0.49907615780830383
[15/24] Train loss=0.45900341868400574
[20/24] Train loss=0.4441227912902832
Test set avg_accuracy=75.65% avg_sensitivity=14.45%, avg_specificity=96.21% avg_auc=82.56%
Best model saved!! Metric=-57.130747055916665!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.478078 Test loss=0.454150 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.47326451539993286
[5/24] Train loss=0.43348753452301025
[10/24] Train loss=0.48685258626937866
[15/24] Train loss=0.44772544503211975
[20/24] Train loss=0.43023157119750977
Test set avg_accuracy=77.23% avg_sensitivity=26.05%, avg_specificity=94.42% avg_auc=83.62%
Best model saved!! Metric=-44.683391983787025!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.463870 Test loss=0.440679 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4564071595668793
[5/24] Train loss=0.4155671000480652
[10/24] Train loss=0.47153133153915405
[15/24] Train loss=0.43053925037384033
[20/24] Train loss=0.4169396162033081
Test set avg_accuracy=78.91% avg_sensitivity=36.51%, avg_specificity=93.15% avg_auc=84.73%
Best model saved!! Metric=-32.70990966535148!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.450376 Test loss=0.428682 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4448398947715759
[5/24] Train loss=0.39963412284851074
[10/24] Train loss=0.4606468081474304
[15/24] Train loss=0.4203509986400604
[20/24] Train loss=0.40112197399139404
Test set avg_accuracy=79.53% avg_sensitivity=42.62%, avg_specificity=91.93% avg_auc=85.72%
Best model saved!! Metric=-26.19741107171589!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.437456 Test loss=0.418939 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4318590462207794
[5/24] Train loss=0.3941231369972229
[10/24] Train loss=0.4518961012363434
[15/24] Train loss=0.40821534395217896
[20/24] Train loss=0.393203467130661
Test set avg_accuracy=80.62% avg_sensitivity=46.56%, avg_specificity=92.07% avg_auc=86.53%
Best model saved!! Metric=-20.22121422013005!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.429208 Test loss=0.407222 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.41324880719184875
[5/24] Train loss=0.38816314935684204
[10/24] Train loss=0.4494558870792389
[15/24] Train loss=0.40274596214294434
[20/24] Train loss=0.3835796117782593
Test set avg_accuracy=81.05% avg_sensitivity=46.19%, avg_specificity=92.76% avg_auc=87.10%
Best model saved!! Metric=-18.887350378561983!!
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.420304 Test loss=0.394819 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3930533528327942
[5/24] Train loss=0.38412269949913025
[10/24] Train loss=0.4349510371685028
[15/24] Train loss=0.3985650837421417
[20/24] Train loss=0.37308263778686523
Test set avg_accuracy=80.65% avg_sensitivity=39.41%, avg_specificity=94.50% avg_auc=87.73%
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.408962 Test loss=0.382260 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3887130320072174
[5/24] Train loss=0.3607478439807892
[10/24] Train loss=0.413716584444046
[15/24] Train loss=0.38179489970207214
[20/24] Train loss=0.3617697060108185
Test set avg_accuracy=80.91% avg_sensitivity=36.10%, avg_specificity=95.96% avg_auc=88.34%
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.398667 Test loss=0.375743 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.38314443826675415
[5/24] Train loss=0.3530982434749603
[10/24] Train loss=0.4012695252895355
[15/24] Train loss=0.3622356653213501
[20/24] Train loss=0.3469250500202179
Test set avg_accuracy=81.93% avg_sensitivity=41.79%, avg_specificity=95.41% avg_auc=89.05%
Best model saved!! Metric=-17.82594547342378!!
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.387021 Test loss=0.365010 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3681771755218506
[5/24] Train loss=0.35000377893447876
[10/24] Train loss=0.3938014805316925
[15/24] Train loss=0.35802367329597473
[20/24] Train loss=0.33756428956985474
Test set avg_accuracy=81.82% avg_sensitivity=37.29%, avg_specificity=96.78% avg_auc=89.22%
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.380107 Test loss=0.363258 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.36772218346595764
[5/24] Train loss=0.34976229071617126
[10/24] Train loss=0.3896591365337372
[15/24] Train loss=0.3561784327030182
[20/24] Train loss=0.3368106484413147
Test set avg_accuracy=81.69% avg_sensitivity=34.75%, avg_specificity=97.46% avg_auc=89.33%
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.377757 Test loss=0.366036 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3671545088291168
[5/24] Train loss=0.3416951298713684
[10/24] Train loss=0.38774803280830383
[15/24] Train loss=0.35761556029319763
[20/24] Train loss=0.3289438784122467
Test set avg_accuracy=82.51% avg_sensitivity=39.25%, avg_specificity=97.04% avg_auc=89.70%
Best model saved!! Metric=-17.48992422211458!!
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.373132 Test loss=0.357807 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3613888919353485
[5/24] Train loss=0.3388325572013855
[10/24] Train loss=0.38138651847839355
[15/24] Train loss=0.35637062788009644
[20/24] Train loss=0.3253251016139984
Test set avg_accuracy=82.24% avg_sensitivity=37.86%, avg_specificity=97.15% avg_auc=89.83%
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.368010 Test loss=0.356962 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3534955382347107
[5/24] Train loss=0.3349287509918213
[10/24] Train loss=0.3788738548755646
[15/24] Train loss=0.3476080894470215
[20/24] Train loss=0.3199867606163025
Test set avg_accuracy=82.06% avg_sensitivity=35.89%, avg_specificity=97.56% avg_auc=90.05%
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.364016 Test loss=0.358335 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.36312538385391235
[5/24] Train loss=0.3430449664592743
[10/24] Train loss=0.37285903096199036
[15/24] Train loss=0.3439013361930847
[20/24] Train loss=0.3200470209121704
Test set avg_accuracy=81.99% avg_sensitivity=35.01%, avg_specificity=97.77% avg_auc=89.97%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.364380 Test loss=0.360386 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3605309724807739
[5/24] Train loss=0.34190648794174194
[10/24] Train loss=0.3743663430213928
[15/24] Train loss=0.34464436769485474
[20/24] Train loss=0.3249441683292389
Test set avg_accuracy=81.99% avg_sensitivity=34.65%, avg_specificity=97.90% avg_auc=90.15%
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.364231 Test loss=0.358037 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3557983636856079
[5/24] Train loss=0.34960564970970154
[10/24] Train loss=0.3664259612560272
[15/24] Train loss=0.3415133059024811
[20/24] Train loss=0.3156070113182068
Test set avg_accuracy=82.14% avg_sensitivity=35.73%, avg_specificity=97.72% avg_auc=90.11%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.360133 Test loss=0.356012 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.34828293323516846
[5/24] Train loss=0.3471561670303345
[10/24] Train loss=0.3674546182155609
[15/24] Train loss=0.3415258526802063
[20/24] Train loss=0.3218889534473419
Test set avg_accuracy=81.55% avg_sensitivity=32.68%, avg_specificity=97.96% avg_auc=90.14%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.361547 Test loss=0.361332 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3564068675041199
[5/24] Train loss=0.3445104658603668
[10/24] Train loss=0.3673759996891022
[15/24] Train loss=0.3396886885166168
[20/24] Train loss=0.31631577014923096
Test set avg_accuracy=81.69% avg_sensitivity=33.20%, avg_specificity=97.98% avg_auc=90.32%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.358874 Test loss=0.360412 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.35236358642578125
[5/24] Train loss=0.34346169233322144
[10/24] Train loss=0.36749544739723206
[15/24] Train loss=0.33479589223861694
[20/24] Train loss=0.3157401978969574
Test set avg_accuracy=82.40% avg_sensitivity=36.46%, avg_specificity=97.83% avg_auc=90.41%
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.356894 Test loss=0.353317 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.34946590662002563
[5/24] Train loss=0.34352368116378784
[10/24] Train loss=0.36184966564178467
[15/24] Train loss=0.3421081602573395
[20/24] Train loss=0.3050324320793152
Test set avg_accuracy=82.86% avg_sensitivity=40.24%, avg_specificity=97.18% avg_auc=90.26%
Best model saved!! Metric=-15.451481091083288!!
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.353916 Test loss=0.351345 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3451501429080963
[5/24] Train loss=0.34289979934692383
[10/24] Train loss=0.3659914433956146
[15/24] Train loss=0.34543898701667786
[20/24] Train loss=0.30485999584198
Test set avg_accuracy=83.72% avg_sensitivity=45.37%, avg_specificity=96.61% avg_auc=90.35%
Best model saved!! Metric=-9.949973025634009!!
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.353213 Test loss=0.345309 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3380759060382843
[5/24] Train loss=0.33717697858810425
[10/24] Train loss=0.3605477511882782
[15/24] Train loss=0.3429352045059204
[20/24] Train loss=0.3077499568462372
Test set avg_accuracy=83.53% avg_sensitivity=42.78%, avg_specificity=97.22% avg_auc=90.31%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.350848 Test loss=0.348859 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.34503206610679626
[5/24] Train loss=0.34020793437957764
[10/24] Train loss=0.36384135484695435
[15/24] Train loss=0.34180688858032227
[20/24] Train loss=0.3051012456417084
Test set avg_accuracy=82.62% avg_sensitivity=37.44%, avg_specificity=97.79% avg_auc=90.50%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.351126 Test loss=0.352933 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.34215325117111206
[5/24] Train loss=0.3349936306476593
[10/24] Train loss=0.3701731264591217
[15/24] Train loss=0.3404386639595032
[20/24] Train loss=0.3029538094997406
Test set avg_accuracy=83.16% avg_sensitivity=40.65%, avg_specificity=97.44% avg_auc=90.61%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.351072 Test loss=0.346618 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.34020930528640747
[5/24] Train loss=0.3301657438278198
[10/24] Train loss=0.36690667271614075
[15/24] Train loss=0.3422706723213196
[20/24] Train loss=0.30422791838645935
Test set avg_accuracy=83.01% avg_sensitivity=39.31%, avg_specificity=97.69% avg_auc=90.64%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.349905 Test loss=0.349601 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.34618398547172546
[5/24] Train loss=0.32971256971359253
[10/24] Train loss=0.36249563097953796
[15/24] Train loss=0.3445426821708679
[20/24] Train loss=0.3054508566856384
Test set avg_accuracy=83.20% avg_sensitivity=40.34%, avg_specificity=97.60% avg_auc=90.62%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.349375 Test loss=0.347410 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3492490351200104
[5/24] Train loss=0.32232698798179626
[10/24] Train loss=0.3666493892669678
[15/24] Train loss=0.34034162759780884
[20/24] Train loss=0.309604674577713
Test set avg_accuracy=82.81% avg_sensitivity=38.79%, avg_specificity=97.60% avg_auc=90.46%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.348687 Test loss=0.352305 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3449254035949707
[5/24] Train loss=0.32902097702026367
[10/24] Train loss=0.36196184158325195
[15/24] Train loss=0.3406379818916321
[20/24] Train loss=0.30387061834335327
Test set avg_accuracy=83.09% avg_sensitivity=40.03%, avg_specificity=97.55% avg_auc=90.67%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.348564 Test loss=0.347389 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.341179221868515
[5/24] Train loss=0.3315994441509247
[10/24] Train loss=0.356503427028656
[15/24] Train loss=0.33735257387161255
[20/24] Train loss=0.2956335246562958
Test set avg_accuracy=84.19% avg_sensitivity=46.45%, avg_specificity=96.87% avg_auc=90.58%
Best model saved!! Metric=-7.903509602571418!!
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.347435 Test loss=0.340703 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.33196020126342773
[5/24] Train loss=0.3265523314476013
[10/24] Train loss=0.3583870828151703
[15/24] Train loss=0.3350164592266083
[20/24] Train loss=0.29882171750068665
Test set avg_accuracy=83.97% avg_sensitivity=44.74%, avg_specificity=97.15% avg_auc=90.58%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.345348 Test loss=0.344282 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3405379056930542
[5/24] Train loss=0.333048939704895
[10/24] Train loss=0.36405956745147705
[15/24] Train loss=0.33294108510017395
[20/24] Train loss=0.2993171215057373
Test set avg_accuracy=83.71% avg_sensitivity=43.55%, avg_specificity=97.20% avg_auc=90.69%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.346505 Test loss=0.343629 Current lr=[0.00029967723776099]

[0/24] Train loss=0.33656665682792664
[5/24] Train loss=0.3329480290412903
[10/24] Train loss=0.3587741255760193
[15/24] Train loss=0.3320833742618561
[20/24] Train loss=0.29294243454933167
Test set avg_accuracy=83.95% avg_sensitivity=44.85%, avg_specificity=97.08% avg_auc=90.66%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.345779 Test loss=0.342379 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.32874879240989685
[5/24] Train loss=0.33008164167404175
[10/24] Train loss=0.35697951912879944
[15/24] Train loss=0.3354441523551941
[20/24] Train loss=0.2952771782875061
Test set avg_accuracy=83.97% avg_sensitivity=44.90%, avg_specificity=97.10% avg_auc=90.72%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.344346 Test loss=0.341102 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3381269574165344
[5/24] Train loss=0.3289855718612671
[10/24] Train loss=0.3601440489292145
[15/24] Train loss=0.33605051040649414
[20/24] Train loss=0.3001091182231903
Test set avg_accuracy=84.09% avg_sensitivity=45.42%, avg_specificity=97.08% avg_auc=90.54%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.344769 Test loss=0.343301 Current lr=[0.000299720220882401]

[0/24] Train loss=0.33902615308761597
[5/24] Train loss=0.32777008414268494
[10/24] Train loss=0.3531196713447571
[15/24] Train loss=0.33046725392341614
[20/24] Train loss=0.2950928807258606
Test set avg_accuracy=83.52% avg_sensitivity=42.15%, avg_specificity=97.41% avg_auc=90.73%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.343652 Test loss=0.343423 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.33667612075805664
[5/24] Train loss=0.32712140679359436
[10/24] Train loss=0.3541834056377411
[15/24] Train loss=0.33516019582748413
[20/24] Train loss=0.2942785918712616
Test set avg_accuracy=83.70% avg_sensitivity=43.19%, avg_specificity=97.30% avg_auc=90.77%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.342821 Test loss=0.341624 Current lr=[0.000298904600941902]

[0/24] Train loss=0.33473193645477295
[5/24] Train loss=0.31865194439888
[10/24] Train loss=0.35784563422203064
[15/24] Train loss=0.3337799608707428
[20/24] Train loss=0.2925418019294739
Test set avg_accuracy=84.08% avg_sensitivity=44.85%, avg_specificity=97.25% avg_auc=90.61%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.343038 Test loss=0.343069 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3332224190235138
[5/24] Train loss=0.3239627480506897
[10/24] Train loss=0.35183292627334595
[15/24] Train loss=0.3346082866191864
[20/24] Train loss=0.2908709645271301
Test set avg_accuracy=83.54% avg_sensitivity=42.21%, avg_specificity=97.43% avg_auc=90.71%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.341990 Test loss=0.344490 Current lr=[0.000297555943323901]

[0/24] Train loss=0.33539703488349915
[5/24] Train loss=0.32691648602485657
[10/24] Train loss=0.3537415862083435
[15/24] Train loss=0.3312915861606598
[20/24] Train loss=0.29295700788497925
Test set avg_accuracy=83.45% avg_sensitivity=42.00%, avg_specificity=97.37% avg_auc=90.74%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.342848 Test loss=0.343574 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.33457162976264954
[5/24] Train loss=0.32761555910110474
[10/24] Train loss=0.35436132550239563
[15/24] Train loss=0.33657771348953247
[20/24] Train loss=0.2950914800167084
Test set avg_accuracy=83.22% avg_sensitivity=40.39%, avg_specificity=97.60% avg_auc=90.75%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.342928 Test loss=0.346604 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.33470049500465393
[5/24] Train loss=0.3279745280742645
[10/24] Train loss=0.35308825969696045
[15/24] Train loss=0.33425694704055786
[20/24] Train loss=0.29719600081443787
Test set avg_accuracy=83.15% avg_sensitivity=40.45%, avg_specificity=97.50% avg_auc=90.73%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.341960 Test loss=0.345484 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3363580107688904
[5/24] Train loss=0.3252237141132355
[10/24] Train loss=0.3550753593444824
[15/24] Train loss=0.334781676530838
[20/24] Train loss=0.29255032539367676
Test set avg_accuracy=83.44% avg_sensitivity=41.69%, avg_specificity=97.46% avg_auc=90.65%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.341356 Test loss=0.345918 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3364565670490265
[5/24] Train loss=0.3268759548664093
[10/24] Train loss=0.35504835844039917
[15/24] Train loss=0.3467024564743042
[20/24] Train loss=0.2954169809818268
Test set avg_accuracy=83.19% avg_sensitivity=40.55%, avg_specificity=97.51% avg_auc=90.76%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.342489 Test loss=0.345849 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3351893723011017
[5/24] Train loss=0.33056530356407166
[10/24] Train loss=0.355252742767334
[15/24] Train loss=0.34151938557624817
[20/24] Train loss=0.29622283577919006
Test set avg_accuracy=83.22% avg_sensitivity=40.29%, avg_specificity=97.63% avg_auc=90.82%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.341557 Test loss=0.345221 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3298904001712799
[5/24] Train loss=0.33534926176071167
[10/24] Train loss=0.35773998498916626
[15/24] Train loss=0.34727296233177185
[20/24] Train loss=0.2972909212112427
Test set avg_accuracy=85.16% avg_sensitivity=51.27%, avg_specificity=96.54% avg_auc=90.74%
Best model saved!! Metric=-2.295114472996424!!
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.343617 Test loss=0.334538 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.33152055740356445
[5/24] Train loss=0.32554057240486145
[10/24] Train loss=0.34962931275367737
[15/24] Train loss=0.3434494137763977
[20/24] Train loss=0.2959870398044586
Test set avg_accuracy=84.74% avg_sensitivity=48.83%, avg_specificity=96.80% avg_auc=90.71%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.341095 Test loss=0.337500 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3282572031021118
[5/24] Train loss=0.32952532172203064
[10/24] Train loss=0.3516919016838074
[15/24] Train loss=0.34146443009376526
[20/24] Train loss=0.29788172245025635
Test set avg_accuracy=85.04% avg_sensitivity=50.65%, avg_specificity=96.59% avg_auc=90.76%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.341957 Test loss=0.335846 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.32811239361763
[5/24] Train loss=0.31951314210891724
[10/24] Train loss=0.35071423649787903
[15/24] Train loss=0.3371536433696747
[20/24] Train loss=0.292140394449234
Test set avg_accuracy=84.96% avg_sensitivity=50.96%, avg_specificity=96.38% avg_auc=90.67%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.340392 Test loss=0.336159 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.32944101095199585
[5/24] Train loss=0.33068233728408813
[10/24] Train loss=0.34612563252449036
[15/24] Train loss=0.338075190782547
[20/24] Train loss=0.293198823928833
Test set avg_accuracy=84.57% avg_sensitivity=48.73%, avg_specificity=96.61% avg_auc=90.67%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.340418 Test loss=0.337485 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3301805853843689
[5/24] Train loss=0.32606083154678345
[10/24] Train loss=0.34864282608032227
[15/24] Train loss=0.3313182294368744
[20/24] Train loss=0.29497915506362915
Test set avg_accuracy=85.04% avg_sensitivity=49.87%, avg_specificity=96.85% avg_auc=90.62%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.339853 Test loss=0.337663 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3278800845146179
[5/24] Train loss=0.32600852847099304
[10/24] Train loss=0.3505304455757141
[15/24] Train loss=0.33236294984817505
[20/24] Train loss=0.290653258562088
Test set avg_accuracy=85.00% avg_sensitivity=49.61%, avg_specificity=96.89% avg_auc=90.61%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.338268 Test loss=0.338439 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3305851221084595
[5/24] Train loss=0.3290036618709564
[10/24] Train loss=0.34680330753326416
[15/24] Train loss=0.3370381295681
[20/24] Train loss=0.28838762640953064
Test set avg_accuracy=85.10% avg_sensitivity=50.39%, avg_specificity=96.76% avg_auc=90.82%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.337957 Test loss=0.335036 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.32595932483673096
[5/24] Train loss=0.32692110538482666
[10/24] Train loss=0.3492930829524994
[15/24] Train loss=0.3397355079650879
[20/24] Train loss=0.2898313105106354
Test set avg_accuracy=85.10% avg_sensitivity=50.49%, avg_specificity=96.73% avg_auc=90.71%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.339219 Test loss=0.335937 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.32863932847976685
[5/24] Train loss=0.3225805461406708
[10/24] Train loss=0.3515269160270691
[15/24] Train loss=0.33323994278907776
[20/24] Train loss=0.28880444169044495
Test set avg_accuracy=85.12% avg_sensitivity=49.72%, avg_specificity=97.01% avg_auc=90.68%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.338281 Test loss=0.337314 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3257162868976593
[5/24] Train loss=0.32801613211631775
[10/24] Train loss=0.35007038712501526
[15/24] Train loss=0.33526915311813354
[20/24] Train loss=0.2907254099845886
Test set avg_accuracy=85.04% avg_sensitivity=49.51%, avg_specificity=96.97% avg_auc=90.64%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.338223 Test loss=0.338277 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3273341655731201
[5/24] Train loss=0.32550108432769775
[10/24] Train loss=0.3498292863368988
[15/24] Train loss=0.33778607845306396
[20/24] Train loss=0.2919379770755768
Test set avg_accuracy=84.88% avg_sensitivity=49.25%, avg_specificity=96.85% avg_auc=90.74%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.338675 Test loss=0.336714 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.32760146260261536
[5/24] Train loss=0.32845231890678406
[10/24] Train loss=0.3493649363517761
[15/24] Train loss=0.3373987674713135
[20/24] Train loss=0.2950606942176819
Test set avg_accuracy=84.86% avg_sensitivity=50.39%, avg_specificity=96.43% avg_auc=90.92%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.339898 Test loss=0.332425 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3236595392227173
[5/24] Train loss=0.3201143443584442
[10/24] Train loss=0.3474390208721161
[15/24] Train loss=0.33193209767341614
[20/24] Train loss=0.2959150969982147
Test set avg_accuracy=84.69% avg_sensitivity=49.15%, avg_specificity=96.63% avg_auc=90.91%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.339438 Test loss=0.333572 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.32784736156463623
[5/24] Train loss=0.3198864758014679
[10/24] Train loss=0.35159310698509216
[15/24] Train loss=0.3286680579185486
[20/24] Train loss=0.29575106501579285
Test set avg_accuracy=83.36% avg_sensitivity=40.39%, avg_specificity=97.79% avg_auc=90.83%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.338634 Test loss=0.345280 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3325178623199463
[5/24] Train loss=0.3302624225616455
[10/24] Train loss=0.35167989134788513
[15/24] Train loss=0.32911014556884766
[20/24] Train loss=0.2876998484134674
Test set avg_accuracy=83.35% avg_sensitivity=41.64%, avg_specificity=97.36% avg_auc=90.60%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.341398 Test loss=0.345506 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.33560341596603394
[5/24] Train loss=0.321448415517807
[10/24] Train loss=0.35302284359931946
[15/24] Train loss=0.32917913794517517
[20/24] Train loss=0.2888406813144684
Test set avg_accuracy=84.09% avg_sensitivity=45.73%, avg_specificity=96.97% avg_auc=90.95%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.339460 Test loss=0.335766 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.327343225479126
[5/24] Train loss=0.3156603276729584
[10/24] Train loss=0.3504178524017334
[15/24] Train loss=0.3282642364501953
[20/24] Train loss=0.29058128595352173
Test set avg_accuracy=83.87% avg_sensitivity=44.59%, avg_specificity=97.06% avg_auc=90.88%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.337379 Test loss=0.337907 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.32729658484458923
[5/24] Train loss=0.3178674876689911
[10/24] Train loss=0.35145241022109985
[15/24] Train loss=0.3284374475479126
[20/24] Train loss=0.27929937839508057
Test set avg_accuracy=84.02% avg_sensitivity=45.62%, avg_specificity=96.92% avg_auc=90.86%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.337158 Test loss=0.336794 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.32555264234542847
[5/24] Train loss=0.3208329975605011
[10/24] Train loss=0.3530508875846863
[15/24] Train loss=0.33073753118515015
[20/24] Train loss=0.2860967814922333
Test set avg_accuracy=84.13% avg_sensitivity=45.99%, avg_specificity=96.94% avg_auc=90.91%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.337809 Test loss=0.336030 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.32336318492889404
[5/24] Train loss=0.32001593708992004
[10/24] Train loss=0.35159265995025635
[15/24] Train loss=0.32983216643333435
[20/24] Train loss=0.2853524684906006
Test set avg_accuracy=84.23% avg_sensitivity=46.45%, avg_specificity=96.92% avg_auc=90.92%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.337074 Test loss=0.334833 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3232796788215637
[5/24] Train loss=0.3147759735584259
[10/24] Train loss=0.3536900281906128
[15/24] Train loss=0.3307019770145416
[20/24] Train loss=0.2833494544029236
Test set avg_accuracy=84.44% avg_sensitivity=47.59%, avg_specificity=96.82% avg_auc=90.89%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.337871 Test loss=0.334330 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.32602453231811523
[5/24] Train loss=0.31969138979911804
[10/24] Train loss=0.34773433208465576
[15/24] Train loss=0.330483078956604
[20/24] Train loss=0.28375956416130066
Test set avg_accuracy=84.14% avg_sensitivity=46.45%, avg_specificity=96.80% avg_auc=90.93%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.336708 Test loss=0.334824 Current lr=[0.000224838296036774]

[0/24] Train loss=0.32445159554481506
[5/24] Train loss=0.3227464258670807
[10/24] Train loss=0.349642276763916
[15/24] Train loss=0.3308473825454712
[20/24] Train loss=0.2830147445201874
Test set avg_accuracy=84.26% avg_sensitivity=47.02%, avg_specificity=96.76% avg_auc=90.83%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.335491 Test loss=0.335203 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3281378746032715
[5/24] Train loss=0.32207706570625305
[10/24] Train loss=0.3516071140766144
[15/24] Train loss=0.32733020186424255
[20/24] Train loss=0.27950191497802734
Test set avg_accuracy=84.14% avg_sensitivity=46.35%, avg_specificity=96.83% avg_auc=90.84%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.337205 Test loss=0.336341 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.32354483008384705
[5/24] Train loss=0.32258936762809753
[10/24] Train loss=0.3517502546310425
[15/24] Train loss=0.3319786489009857
[20/24] Train loss=0.2837563455104828
Test set avg_accuracy=84.38% avg_sensitivity=46.92%, avg_specificity=96.96% avg_auc=90.89%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.335854 Test loss=0.334800 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3226880729198456
[5/24] Train loss=0.3181401789188385
[10/24] Train loss=0.3518827557563782
[15/24] Train loss=0.3279957175254822
[20/24] Train loss=0.2824745178222656
Test set avg_accuracy=84.00% avg_sensitivity=45.11%, avg_specificity=97.06% avg_auc=90.78%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.335958 Test loss=0.337989 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3263340890407562
[5/24] Train loss=0.3190971910953522
[10/24] Train loss=0.3515889644622803
[15/24] Train loss=0.33266428112983704
[20/24] Train loss=0.27925801277160645
Test set avg_accuracy=84.02% avg_sensitivity=45.11%, avg_specificity=97.10% avg_auc=90.70%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.336285 Test loss=0.339484 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.33034345507621765
[5/24] Train loss=0.3188159465789795
[10/24] Train loss=0.34796467423439026
[15/24] Train loss=0.3325004577636719
[20/24] Train loss=0.2820647954940796
Test set avg_accuracy=83.85% avg_sensitivity=44.38%, avg_specificity=97.11% avg_auc=90.66%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.336503 Test loss=0.340854 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.33144915103912354
[5/24] Train loss=0.3153332769870758
[10/24] Train loss=0.3552097678184509
[15/24] Train loss=0.330405592918396
[20/24] Train loss=0.28779298067092896
Test set avg_accuracy=83.96% avg_sensitivity=44.74%, avg_specificity=97.13% avg_auc=90.82%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.336856 Test loss=0.338216 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3237929046154022
[5/24] Train loss=0.3153979778289795
[10/24] Train loss=0.350676566362381
[15/24] Train loss=0.32780638337135315
[20/24] Train loss=0.2826004922389984
Test set avg_accuracy=84.06% avg_sensitivity=45.05%, avg_specificity=97.16% avg_auc=90.87%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.335569 Test loss=0.337279 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.32244935631752014
[5/24] Train loss=0.3118021786212921
[10/24] Train loss=0.35349854826927185
[15/24] Train loss=0.33061227202415466
[20/24] Train loss=0.2847331166267395
Test set avg_accuracy=84.19% avg_sensitivity=46.19%, avg_specificity=96.96% avg_auc=90.88%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.334713 Test loss=0.335517 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3238165080547333
[5/24] Train loss=0.3124017119407654
[10/24] Train loss=0.3493098318576813
[15/24] Train loss=0.32914310693740845
[20/24] Train loss=0.283229261636734
Test set avg_accuracy=84.09% avg_sensitivity=45.73%, avg_specificity=96.97% avg_auc=90.76%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.335378 Test loss=0.337176 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.32510077953338623
[5/24] Train loss=0.31450045108795166
[10/24] Train loss=0.3486676514148712
[15/24] Train loss=0.32494932413101196
[20/24] Train loss=0.28372853994369507
Test set avg_accuracy=83.97% avg_sensitivity=44.85%, avg_specificity=97.11% avg_auc=90.78%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.335677 Test loss=0.338032 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3241591453552246
[5/24] Train loss=0.31462016701698303
[10/24] Train loss=0.3486092686653137
[15/24] Train loss=0.3242378234863281
[20/24] Train loss=0.281649649143219
Test set avg_accuracy=84.24% avg_sensitivity=46.61%, avg_specificity=96.89% avg_auc=90.84%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.335228 Test loss=0.335337 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3257696330547333
[5/24] Train loss=0.31792759895324707
[10/24] Train loss=0.3480244576931
[15/24] Train loss=0.3221553862094879
[20/24] Train loss=0.2822827696800232
Test set avg_accuracy=85.27% avg_sensitivity=53.13%, avg_specificity=96.07% avg_auc=90.90%
Best model saved!! Metric=-0.6272463736910368!!
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.337608 Test loss=0.329314 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3216426968574524
[5/24] Train loss=0.31489863991737366
[10/24] Train loss=0.3482416570186615
[15/24] Train loss=0.32634520530700684
[20/24] Train loss=0.2780649960041046
Test set avg_accuracy=85.36% avg_sensitivity=55.98%, avg_specificity=95.23% avg_auc=90.98%
Best model saved!! Metric=1.5574569909590679!!
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.335492 Test loss=0.326637 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.32151588797569275
[5/24] Train loss=0.3144003748893738
[10/24] Train loss=0.3444758355617523
[15/24] Train loss=0.3284095227718353
[20/24] Train loss=0.282142698764801
Test set avg_accuracy=85.51% avg_sensitivity=55.46%, avg_specificity=95.60% avg_auc=90.95%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.334987 Test loss=0.327213 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.31673604249954224
[5/24] Train loss=0.31318947672843933
[10/24] Train loss=0.3494991362094879
[15/24] Train loss=0.3245362639427185
[20/24] Train loss=0.28085607290267944
Test set avg_accuracy=85.18% avg_sensitivity=56.14%, avg_specificity=94.94% avg_auc=90.93%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.333710 Test loss=0.326603 Current lr=[0.000156543481933168]

[0/24] Train loss=0.31781381368637085
[5/24] Train loss=0.3119944930076599
[10/24] Train loss=0.3467514216899872
[15/24] Train loss=0.32014086842536926
[20/24] Train loss=0.2806968688964844
Test set avg_accuracy=85.21% avg_sensitivity=55.36%, avg_specificity=95.23% avg_auc=90.96%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.333040 Test loss=0.326724 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3184373378753662
[5/24] Train loss=0.30876070261001587
[10/24] Train loss=0.34358078241348267
[15/24] Train loss=0.3238314390182495
[20/24] Train loss=0.28038090467453003
Test set avg_accuracy=85.53% avg_sensitivity=56.19%, avg_specificity=95.39% avg_auc=90.95%
Best model saved!! Metric=2.0628860771990887!!
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.332330 Test loss=0.326427 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.31495070457458496
[5/24] Train loss=0.30688416957855225
[10/24] Train loss=0.3421710431575775
[15/24] Train loss=0.3194572627544403
[20/24] Train loss=0.27648821473121643
Test set avg_accuracy=85.59% avg_sensitivity=55.67%, avg_specificity=95.63% avg_auc=90.98%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.332456 Test loss=0.326299 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.32253775000572205
[5/24] Train loss=0.31263619661331177
[10/24] Train loss=0.339540958404541
[15/24] Train loss=0.32575348019599915
[20/24] Train loss=0.28026503324508667
Test set avg_accuracy=85.34% avg_sensitivity=57.22%, avg_specificity=94.78% avg_auc=90.97%
Best model saved!! Metric=2.3130566770001266!!
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.332764 Test loss=0.325778 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3161817193031311
[5/24] Train loss=0.3093317151069641
[10/24] Train loss=0.3459349572658539
[15/24] Train loss=0.31951871514320374
[20/24] Train loss=0.2785884439945221
Test set avg_accuracy=85.49% avg_sensitivity=55.67%, avg_specificity=95.51% avg_auc=90.91%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.331506 Test loss=0.326956 Current lr=[0.000134135431043539]

[0/24] Train loss=0.31780508160591125
[5/24] Train loss=0.3135111629962921
[10/24] Train loss=0.3458171486854553
[15/24] Train loss=0.32393017411231995
[20/24] Train loss=0.2812497019767761
Test set avg_accuracy=85.55% avg_sensitivity=57.85%, avg_specificity=94.85% avg_auc=91.00%
Best model saved!! Metric=3.244961686816225!!
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.332007 Test loss=0.325288 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.31922662258148193
[5/24] Train loss=0.3087952136993408
[10/24] Train loss=0.3434504568576813
[15/24] Train loss=0.32125532627105713
[20/24] Train loss=0.2772318422794342
Test set avg_accuracy=85.57% avg_sensitivity=55.67%, avg_specificity=95.62% avg_auc=91.04%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.331119 Test loss=0.324784 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3149152398109436
[5/24] Train loss=0.3092088997364044
[10/24] Train loss=0.3465408384799957
[15/24] Train loss=0.3202762305736542
[20/24] Train loss=0.2784489691257477
Test set avg_accuracy=85.39% avg_sensitivity=57.02%, avg_specificity=94.92% avg_auc=91.06%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.331525 Test loss=0.324108 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3154917061328888
[5/24] Train loss=0.3079223036766052
[10/24] Train loss=0.34708356857299805
[15/24] Train loss=0.3219882547855377
[20/24] Train loss=0.27972620725631714
Test set avg_accuracy=85.92% avg_sensitivity=58.52%, avg_specificity=95.13% avg_auc=91.15%
Best model saved!! Metric=4.718273489665577!!
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.331662 Test loss=0.323307 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.31521886587142944
[5/24] Train loss=0.30848804116249084
[10/24] Train loss=0.34792616963386536
[15/24] Train loss=0.3287512958049774
[20/24] Train loss=0.27947497367858887
Test set avg_accuracy=85.66% avg_sensitivity=58.10%, avg_specificity=94.92% avg_auc=91.14%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.331804 Test loss=0.323125 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3175453245639801
[5/24] Train loss=0.3077627420425415
[10/24] Train loss=0.3467877507209778
[15/24] Train loss=0.3279357850551605
[20/24] Train loss=0.2803913950920105
Test set avg_accuracy=85.69% avg_sensitivity=59.66%, avg_specificity=94.43% avg_auc=91.14%
Best model saved!! Metric=4.921855456761136!!
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.331149 Test loss=0.323171 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.31839051842689514
[5/24] Train loss=0.31275150179862976
[10/24] Train loss=0.34787410497665405
[15/24] Train loss=0.3237708508968353
[20/24] Train loss=0.2786642611026764
Test set avg_accuracy=85.61% avg_sensitivity=60.33%, avg_specificity=94.10% avg_auc=91.19%
Best model saved!! Metric=5.233359833234296!!
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.331371 Test loss=0.322795 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3187514841556549
[5/24] Train loss=0.3185572326183319
[10/24] Train loss=0.3526555001735687
[15/24] Train loss=0.32677316665649414
[20/24] Train loss=0.27803200483322144
Test set avg_accuracy=85.42% avg_sensitivity=62.04%, avg_specificity=93.27% avg_auc=91.17%
Best model saved!! Metric=5.891414397093989!!
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.331893 Test loss=0.323933 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3187187612056732
[5/24] Train loss=0.3203901946544647
[10/24] Train loss=0.3556816279888153
[15/24] Train loss=0.32228031754493713
[20/24] Train loss=0.2781369686126709
Test set avg_accuracy=85.69% avg_sensitivity=67.69%, avg_specificity=91.74% avg_auc=91.08%
Best model saved!! Metric=10.195381962935741!!
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.333030 Test loss=0.328769 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3218671977519989
[5/24] Train loss=0.3235260844230652
[10/24] Train loss=0.3580777049064636
[15/24] Train loss=0.32099971175193787
[20/24] Train loss=0.2775876522064209
Test set avg_accuracy=85.56% avg_sensitivity=72.35%, avg_specificity=90.00% avg_auc=90.64%
Best model saved!! Metric=12.542780119425842!!
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.334763 Test loss=0.339009 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3327086269855499
[5/24] Train loss=0.3257257044315338
[10/24] Train loss=0.352822482585907
[15/24] Train loss=0.32329851388931274
[20/24] Train loss=0.29952216148376465
Test set avg_accuracy=85.86% avg_sensitivity=69.45%, avg_specificity=91.37% avg_auc=91.07%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.337302 Test loss=0.331144 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.32792410254478455
[5/24] Train loss=0.3116804361343384
[10/24] Train loss=0.3502023220062256
[15/24] Train loss=0.3317027688026428
[20/24] Train loss=0.28812387585639954
Test set avg_accuracy=85.65% avg_sensitivity=60.80%, avg_specificity=94.00% avg_auc=91.27%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.333688 Test loss=0.322380 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.31508854031562805
[5/24] Train loss=0.3110146224498749
[10/24] Train loss=0.34838518500328064
[15/24] Train loss=0.3268488049507141
[20/24] Train loss=0.2839048206806183
Test set avg_accuracy=85.64% avg_sensitivity=61.83%, avg_specificity=93.63% avg_auc=91.27%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.330063 Test loss=0.323689 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3182052969932556
[5/24] Train loss=0.3169991970062256
[10/24] Train loss=0.35133132338523865
[15/24] Train loss=0.32580798864364624
[20/24] Train loss=0.2873115837574005
Test set avg_accuracy=85.85% avg_sensitivity=63.80%, avg_specificity=93.25% avg_auc=91.25%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.332913 Test loss=0.325434 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3217414319515228
[5/24] Train loss=0.3203371465206146
[10/24] Train loss=0.3508215844631195
[15/24] Train loss=0.3277019262313843
[20/24] Train loss=0.28745582699775696
Test set avg_accuracy=85.49% avg_sensitivity=67.63%, avg_specificity=91.49% avg_auc=90.98%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.334404 Test loss=0.334647 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.33045831322669983
[5/24] Train loss=0.3309992551803589
[10/24] Train loss=0.3532983958721161
[15/24] Train loss=0.32100749015808105
[20/24] Train loss=0.2992542088031769
Test set avg_accuracy=85.72% avg_sensitivity=66.49%, avg_specificity=92.17% avg_auc=91.02%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.336121 Test loss=0.332736 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.32639411091804504
[5/24] Train loss=0.31515389680862427
[10/24] Train loss=0.3476938009262085
[15/24] Train loss=0.3276936411857605
[20/24] Train loss=0.2937701642513275
Test set avg_accuracy=85.68% avg_sensitivity=60.75%, avg_specificity=94.05% avg_auc=91.28%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.333062 Test loss=0.323687 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.31932929158210754
[5/24] Train loss=0.31262463331222534
[10/24] Train loss=0.33980676531791687
[15/24] Train loss=0.32357057929039
[20/24] Train loss=0.28658440709114075
Test set avg_accuracy=85.57% avg_sensitivity=60.80%, avg_specificity=93.89% avg_auc=91.28%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.328750 Test loss=0.323421 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.319109708070755
[5/24] Train loss=0.3150203824043274
[10/24] Train loss=0.3437868356704712
[15/24] Train loss=0.32330000400543213
[20/24] Train loss=0.2866658568382263
Test set avg_accuracy=85.52% avg_sensitivity=61.06%, avg_specificity=93.74% avg_auc=91.25%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.329492 Test loss=0.324617 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.32232552766799927
[5/24] Train loss=0.3149978220462799
[10/24] Train loss=0.3406374752521515
[15/24] Train loss=0.3275660574436188
[20/24] Train loss=0.2854837477207184
Test set avg_accuracy=85.64% avg_sensitivity=59.87%, avg_specificity=94.29% avg_auc=91.28%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.329163 Test loss=0.322834 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.3144706189632416
[5/24] Train loss=0.30999496579170227
[10/24] Train loss=0.3405877649784088
[15/24] Train loss=0.32362791895866394
[20/24] Train loss=0.28450140357017517
Test set avg_accuracy=85.94% avg_sensitivity=59.61%, avg_specificity=94.78% avg_auc=91.29%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.327934 Test loss=0.322355 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.31777337193489075
[5/24] Train loss=0.31021848320961
[10/24] Train loss=0.34394633769989014
[15/24] Train loss=0.32002589106559753
[20/24] Train loss=0.2851637005805969
Test set avg_accuracy=85.89% avg_sensitivity=59.35%, avg_specificity=94.80% avg_auc=91.30%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.327498 Test loss=0.322136 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3162827789783478
[5/24] Train loss=0.30660033226013184
[10/24] Train loss=0.34148791432380676
[15/24] Train loss=0.32152441143989563
[20/24] Train loss=0.2833976447582245
Test set avg_accuracy=85.92% avg_sensitivity=59.40%, avg_specificity=94.83% avg_auc=91.33%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.327102 Test loss=0.321639 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3176831305027008
[5/24] Train loss=0.3126778304576874
[10/24] Train loss=0.341269314289093
[15/24] Train loss=0.32057318091392517
[20/24] Train loss=0.28644099831581116
Test set avg_accuracy=85.95% avg_sensitivity=59.19%, avg_specificity=94.94% avg_auc=91.31%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.326916 Test loss=0.321657 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.31708160042762756
[5/24] Train loss=0.31035181879997253
[10/24] Train loss=0.34076032042503357
[15/24] Train loss=0.31744417548179626
[20/24] Train loss=0.28268858790397644
Test set avg_accuracy=85.92% avg_sensitivity=58.05%, avg_specificity=95.29% avg_auc=91.33%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.325642 Test loss=0.321216 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3145311176776886
[5/24] Train loss=0.3082086741924286
[10/24] Train loss=0.3435766398906708
[15/24] Train loss=0.3198598325252533
[20/24] Train loss=0.28071439266204834
Test set avg_accuracy=85.86% avg_sensitivity=57.48%, avg_specificity=95.39% avg_auc=91.32%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.326235 Test loss=0.321369 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3132607936859131
[5/24] Train loss=0.3124459683895111
[10/24] Train loss=0.341227650642395
[15/24] Train loss=0.32281729578971863
[20/24] Train loss=0.28419914841651917
Test set avg_accuracy=86.04% avg_sensitivity=57.85%, avg_specificity=95.51% avg_auc=91.34%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.326565 Test loss=0.321001 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3117310702800751
[5/24] Train loss=0.3107217252254486
[10/24] Train loss=0.34005987644195557
[15/24] Train loss=0.32090315222740173
[20/24] Train loss=0.27669474482536316
Test set avg_accuracy=85.90% avg_sensitivity=57.90%, avg_specificity=95.30% avg_auc=91.32%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.325810 Test loss=0.321152 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3099697232246399
[5/24] Train loss=0.3096926510334015
[10/24] Train loss=0.33696043491363525
[15/24] Train loss=0.3250693082809448
[20/24] Train loss=0.27933230996131897
Test set avg_accuracy=86.03% avg_sensitivity=57.12%, avg_specificity=95.74% avg_auc=91.33%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.325803 Test loss=0.321024 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3188207447528839
[5/24] Train loss=0.313550740480423
[10/24] Train loss=0.34049034118652344
[15/24] Train loss=0.3218538165092468
[20/24] Train loss=0.2791266143321991
Test set avg_accuracy=85.91% avg_sensitivity=58.26%, avg_specificity=95.20% avg_auc=91.34%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.326502 Test loss=0.320693 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3125130534172058
[5/24] Train loss=0.31426915526390076
[10/24] Train loss=0.3413168787956238
[15/24] Train loss=0.3214796781539917
[20/24] Train loss=0.2781361937522888
Test set avg_accuracy=85.90% avg_sensitivity=59.24%, avg_specificity=94.85% avg_auc=91.36%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.326786 Test loss=0.320736 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3115638792514801
[5/24] Train loss=0.31624335050582886
[10/24] Train loss=0.33876046538352966
[15/24] Train loss=0.31758904457092285
[20/24] Train loss=0.2742374837398529
Test set avg_accuracy=86.05% avg_sensitivity=61.47%, avg_specificity=94.31% avg_auc=91.36%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.326316 Test loss=0.321399 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.3146383464336395
[5/24] Train loss=0.3087834119796753
[10/24] Train loss=0.3427030146121979
[15/24] Train loss=0.3217698037624359
[20/24] Train loss=0.2721157968044281
Test set avg_accuracy=85.74% avg_sensitivity=63.13%, avg_specificity=93.34% avg_auc=91.35%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.326493 Test loss=0.322202 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.31782567501068115
[5/24] Train loss=0.3124249279499054
[10/24] Train loss=0.34443458914756775
[15/24] Train loss=0.3172559142112732
[20/24] Train loss=0.2782258987426758
Test set avg_accuracy=85.74% avg_sensitivity=63.49%, avg_specificity=93.22% avg_auc=91.36%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.326497 Test loss=0.322731 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.31829914450645447
[5/24] Train loss=0.3091685473918915
[10/24] Train loss=0.3437667489051819
[15/24] Train loss=0.31902873516082764
[20/24] Train loss=0.2746506929397583
Test set avg_accuracy=85.81% avg_sensitivity=63.02%, avg_specificity=93.46% avg_auc=91.35%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.325956 Test loss=0.322400 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.31636595726013184
[5/24] Train loss=0.3083432614803314
[10/24] Train loss=0.3416807949542999
[15/24] Train loss=0.31826090812683105
[20/24] Train loss=0.27482983469963074
Test set avg_accuracy=86.02% avg_sensitivity=61.73%, avg_specificity=94.17% avg_auc=91.37%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.325809 Test loss=0.321389 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.3158526122570038
[5/24] Train loss=0.3075672686100006
[10/24] Train loss=0.3440976142883301
[15/24] Train loss=0.32001370191574097
[20/24] Train loss=0.28027021884918213
Test set avg_accuracy=86.08% avg_sensitivity=61.06%, avg_specificity=94.49% avg_auc=91.36%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.324990 Test loss=0.321017 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.31524884700775146
[5/24] Train loss=0.3121073544025421
[10/24] Train loss=0.34307578206062317
[15/24] Train loss=0.31428661942481995
[20/24] Train loss=0.27612540125846863
Test set avg_accuracy=86.03% avg_sensitivity=60.64%, avg_specificity=94.56% avg_auc=91.38%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.324711 Test loss=0.320783 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3143097758293152
[5/24] Train loss=0.3058716058731079
[10/24] Train loss=0.34122133255004883
[15/24] Train loss=0.32005029916763306
[20/24] Train loss=0.2769738435745239
Test set avg_accuracy=86.04% avg_sensitivity=60.59%, avg_specificity=94.59% avg_auc=91.38%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.325027 Test loss=0.320562 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3139377236366272
[5/24] Train loss=0.308775395154953
[10/24] Train loss=0.340854287147522
[15/24] Train loss=0.314741849899292
[20/24] Train loss=0.2727506458759308
Test set avg_accuracy=86.05% avg_sensitivity=60.64%, avg_specificity=94.59% avg_auc=91.37%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.323699 Test loss=0.320565 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3130008578300476
[5/24] Train loss=0.304854154586792
[10/24] Train loss=0.3427254557609558
[15/24] Train loss=0.3191540241241455
[20/24] Train loss=0.2757735848426819
Test set avg_accuracy=86.02% avg_sensitivity=60.28%, avg_specificity=94.66% avg_auc=91.38%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.324300 Test loss=0.320408 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.31393566727638245
[5/24] Train loss=0.3137757182121277
[10/24] Train loss=0.33738458156585693
[15/24] Train loss=0.319749653339386
[20/24] Train loss=0.2764033377170563
Test set avg_accuracy=86.08% avg_sensitivity=60.64%, avg_specificity=94.63% avg_auc=91.37%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.324686 Test loss=0.320527 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.31588584184646606
[5/24] Train loss=0.3113146722316742
[10/24] Train loss=0.3424421548843384
[15/24] Train loss=0.31841474771499634
[20/24] Train loss=0.2748815715312958
Test set avg_accuracy=86.07% avg_sensitivity=60.49%, avg_specificity=94.66% avg_auc=91.38%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.324513 Test loss=0.320428 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3123779594898224
[5/24] Train loss=0.308833509683609
[10/24] Train loss=0.3420853912830353
[15/24] Train loss=0.3191627264022827
[20/24] Train loss=0.2767735421657562
Test set avg_accuracy=86.07% avg_sensitivity=60.23%, avg_specificity=94.75% avg_auc=91.38%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.324245 Test loss=0.320326 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.315848171710968
[5/24] Train loss=0.3130500316619873
[10/24] Train loss=0.3405735492706299
[15/24] Train loss=0.3179868161678314
[20/24] Train loss=0.27771830558776855
Test set avg_accuracy=86.02% avg_sensitivity=60.28%, avg_specificity=94.66% avg_auc=91.38%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.324135 Test loss=0.320362 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.312381386756897
[5/24] Train loss=0.31021684408187866
[10/24] Train loss=0.34087952971458435
[15/24] Train loss=0.3155073821544647
[20/24] Train loss=0.28040534257888794
Test set avg_accuracy=86.02% avg_sensitivity=60.28%, avg_specificity=94.66% avg_auc=91.38%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.324052 Test loss=0.320366 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.31380054354667664
[5/24] Train loss=0.30754080414772034
[10/24] Train loss=0.3395249843597412
[15/24] Train loss=0.3211343586444855
[20/24] Train loss=0.2796759307384491
Test set avg_accuracy=86.02% avg_sensitivity=60.28%, avg_specificity=94.66% avg_auc=91.38%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.324126 Test loss=0.320341 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.31343093514442444
[5/24] Train loss=0.3076896071434021
[10/24] Train loss=0.3465290367603302
[15/24] Train loss=0.31578269600868225
[20/24] Train loss=0.2763417661190033
Test set avg_accuracy=86.07% avg_sensitivity=60.28%, avg_specificity=94.73% avg_auc=91.38%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.324100 Test loss=0.320334 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3138353228569031
[5/24] Train loss=0.3065800368785858
[10/24] Train loss=0.34049487113952637
[15/24] Train loss=0.31934797763824463
[20/24] Train loss=0.2776327133178711
Test set avg_accuracy=86.07% avg_sensitivity=60.28%, avg_specificity=94.73% avg_auc=91.38%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.323849 Test loss=0.320333 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=85.56% sen=72.35%, spe=90.00%, auc=90.64%!
Fold[8] Avg_overlap=0.65%(0.23472515001507)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'HybridCNNRNN',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/23] Train loss=1.1069445610046387
[5/23] Train loss=0.815147340297699
[10/23] Train loss=0.690869927406311
[15/23] Train loss=0.6321220993995667
[20/23] Train loss=0.6105383634567261
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.79%
Best model saved!! Metric=-97.36416837419841!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.749553 Test loss=0.574247 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.6234470009803772
[5/23] Train loss=0.5977391600608826
[10/23] Train loss=0.6080208420753479
[15/23] Train loss=0.5866841077804565
[20/23] Train loss=0.5846392512321472
Test set avg_accuracy=75.82% avg_sensitivity=0.00%, avg_specificity=99.97% avg_auc=55.84%
Best model saved!! Metric=-94.36958835952592!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.610947 Test loss=0.550609 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.5960327386856079
[5/23] Train loss=0.5648974776268005
[10/23] Train loss=0.587113082408905
[15/23] Train loss=0.5752679109573364
[20/23] Train loss=0.576041579246521
Test set avg_accuracy=75.83% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=61.32%
Best model saved!! Metric=-88.86748454665695!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.593537 Test loss=0.545594 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.591614305973053
[5/23] Train loss=0.5736206769943237
[10/23] Train loss=0.5898023247718811
[15/23] Train loss=0.5635337829589844
[20/23] Train loss=0.5647798776626587
Test set avg_accuracy=75.83% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=63.94%
Best model saved!! Metric=-86.24330907842933!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.584903 Test loss=0.537498 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.5775426626205444
[5/23] Train loss=0.5638235211372375
[10/23] Train loss=0.5762541890144348
[15/23] Train loss=0.5590367317199707
[20/23] Train loss=0.5589133501052856
Test set avg_accuracy=75.82% avg_sensitivity=0.00%, avg_specificity=99.97% avg_auc=67.42%
Best model saved!! Metric=-82.79433067527157!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.580264 Test loss=0.531087 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.565930962562561
[5/23] Train loss=0.5501925945281982
[10/23] Train loss=0.5697083473205566
[15/23] Train loss=0.55272376537323
[20/23] Train loss=0.551175594329834
Test set avg_accuracy=75.83% avg_sensitivity=0.32%, avg_specificity=99.88% avg_auc=71.23%
Best model saved!! Metric=-78.73529570545521!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.569184 Test loss=0.523351 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.5656707882881165
[5/23] Train loss=0.5453819036483765
[10/23] Train loss=0.5602343678474426
[15/23] Train loss=0.5437448024749756
[20/23] Train loss=0.5412533283233643
Test set avg_accuracy=75.70% avg_sensitivity=0.43%, avg_specificity=99.67% avg_auc=74.12%
Best model saved!! Metric=-76.07188512227711!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.562735 Test loss=0.515888 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.5467073917388916
[5/23] Train loss=0.5397462248802185
[10/23] Train loss=0.5577583312988281
[15/23] Train loss=0.5288005471229553
[20/23] Train loss=0.533622145652771
Test set avg_accuracy=75.62% avg_sensitivity=0.54%, avg_specificity=99.54% avg_auc=76.17%
Best model saved!! Metric=-74.12816914035838!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.553284 Test loss=0.507389 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.5315855741500854
[5/23] Train loss=0.5123257637023926
[10/23] Train loss=0.5464586615562439
[15/23] Train loss=0.5241045951843262
[20/23] Train loss=0.5171903967857361
Test set avg_accuracy=75.16% avg_sensitivity=1.40%, avg_specificity=98.64% avg_auc=78.12%
Best model saved!! Metric=-72.67406130340224!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.541407 Test loss=0.497634 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.524064838886261
[5/23] Train loss=0.5090667009353638
[10/23] Train loss=0.5400233268737793
[15/23] Train loss=0.5117009282112122
[20/23] Train loss=0.49975183606147766
Test set avg_accuracy=75.30% avg_sensitivity=4.96%, avg_specificity=97.70% avg_auc=79.55%
Best model saved!! Metric=-68.49514619339718!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.530474 Test loss=0.485226 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.5123759508132935
[5/23] Train loss=0.4900502860546112
[10/23] Train loss=0.5183574557304382
[15/23] Train loss=0.49548113346099854
[20/23] Train loss=0.4938717782497406
Test set avg_accuracy=75.20% avg_sensitivity=9.92%, avg_specificity=95.98% avg_auc=80.75%
Best model saved!! Metric=-64.15610751087422!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.516385 Test loss=0.472594 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.5021268725395203
[5/23] Train loss=0.48192429542541504
[10/23] Train loss=0.5123410820960999
[15/23] Train loss=0.48260343074798584
[20/23] Train loss=0.4753773808479309
Test set avg_accuracy=74.78% avg_sensitivity=12.83%, avg_specificity=94.51% avg_auc=81.68%
Best model saved!! Metric=-62.208622077312995!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.502306 Test loss=0.462459 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.48375728726387024
[5/23] Train loss=0.4670267403125763
[10/23] Train loss=0.5028219819068909
[15/23] Train loss=0.46773001551628113
[20/23] Train loss=0.46541160345077515
Test set avg_accuracy=76.86% avg_sensitivity=24.31%, avg_specificity=93.60% avg_auc=82.72%
Best model saved!! Metric=-48.507450399637136!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.489179 Test loss=0.453107 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.4736469089984894
[5/23] Train loss=0.4567239284515381
[10/23] Train loss=0.48605844378471375
[15/23] Train loss=0.45139390230178833
[20/23] Train loss=0.4451095461845398
Test set avg_accuracy=77.71% avg_sensitivity=34.45%, avg_specificity=91.48% avg_auc=83.40%
Best model saved!! Metric=-38.95846906824921!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.475984 Test loss=0.444557 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.465871125459671
[5/23] Train loss=0.4412747919559479
[10/23] Train loss=0.48026615381240845
[15/23] Train loss=0.44514140486717224
[20/23] Train loss=0.4315009117126465
Test set avg_accuracy=78.48% avg_sensitivity=43.88%, avg_specificity=89.49% avg_auc=83.94%
Best model saved!! Metric=-30.207037097422585!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.464318 Test loss=0.441781 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.46183428168296814
[5/23] Train loss=0.43514782190322876
[10/23] Train loss=0.4766921103000641
[15/23] Train loss=0.4331520199775696
[20/23] Train loss=0.4213554561138153
Test set avg_accuracy=78.88% avg_sensitivity=49.54%, avg_specificity=88.22% avg_auc=84.23%
Best model saved!! Metric=-25.127931134292737!!
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.457814 Test loss=0.438001 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.45595040917396545
[5/23] Train loss=0.4305788576602936
[10/23] Train loss=0.4730567932128906
[15/23] Train loss=0.41512739658355713
[20/23] Train loss=0.4204619824886322
Test set avg_accuracy=79.14% avg_sensitivity=52.13%, avg_specificity=87.74% avg_auc=84.59%
Best model saved!! Metric=-22.39567984828151!!
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.448884 Test loss=0.428953 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.44374603033065796
[5/23] Train loss=0.41765880584716797
[10/23] Train loss=0.46054428815841675
[15/23] Train loss=0.4114866554737091
[20/23] Train loss=0.4102603495121002
Test set avg_accuracy=79.27% avg_sensitivity=48.63%, avg_specificity=89.03% avg_auc=84.96%
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.440520 Test loss=0.415147 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.42375338077545166
[5/23] Train loss=0.4175255000591278
[10/23] Train loss=0.451376736164093
[15/23] Train loss=0.4003382623195648
[20/23] Train loss=0.3969205319881439
Test set avg_accuracy=79.48% avg_sensitivity=42.21%, avg_specificity=91.35% avg_auc=85.33%
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.431426 Test loss=0.402534 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.41534656286239624
[5/23] Train loss=0.3992999494075775
[10/23] Train loss=0.43359899520874023
[15/23] Train loss=0.3974059224128723
[20/23] Train loss=0.3899889588356018
Test set avg_accuracy=80.03% avg_sensitivity=46.95%, avg_specificity=90.56% avg_auc=85.78%
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.424870 Test loss=0.399485 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.40904438495635986
[5/23] Train loss=0.39531877636909485
[10/23] Train loss=0.4322495460510254
[15/23] Train loss=0.391836017370224
[20/23] Train loss=0.39036843180656433
Test set avg_accuracy=80.73% avg_sensitivity=48.52%, avg_specificity=90.99% avg_auc=86.13%
Best model saved!! Metric=-19.63485124108759!!
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.417330 Test loss=0.394606 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.40193378925323486
[5/23] Train loss=0.3977763056755066
[10/23] Train loss=0.4220927357673645
[15/23] Train loss=0.38613447546958923
[20/23] Train loss=0.39060449600219727
Test set avg_accuracy=81.20% avg_sensitivity=51.05%, avg_specificity=90.80% avg_auc=86.18%
Best model saved!! Metric=-16.776521980765743!!
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.414927 Test loss=0.392771 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.40430936217308044
[5/23] Train loss=0.38821399211883545
[10/23] Train loss=0.42242884635925293
[15/23] Train loss=0.390092134475708
[20/23] Train loss=0.3827528953552246
Test set avg_accuracy=81.29% avg_sensitivity=51.64%, avg_specificity=90.73% avg_auc=86.10%
Best model saved!! Metric=-16.23238862964613!!
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.411066 Test loss=0.390921 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.3912305533885956
[5/23] Train loss=0.38846075534820557
[10/23] Train loss=0.422868013381958
[15/23] Train loss=0.37811362743377686
[20/23] Train loss=0.376971572637558
Test set avg_accuracy=82.11% avg_sensitivity=49.70%, avg_specificity=92.43% avg_auc=86.32%
Best model saved!! Metric=-15.438340835868729!!
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.406692 Test loss=0.386275 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.38606417179107666
[5/23] Train loss=0.38017788529396057
[10/23] Train loss=0.4150947332382202
[15/23] Train loss=0.3647899329662323
[20/23] Train loss=0.3683321475982666
Test set avg_accuracy=81.93% avg_sensitivity=43.77%, avg_specificity=94.08% avg_auc=86.76%
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.401086 Test loss=0.379872 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.38096657395362854
[5/23] Train loss=0.3832520544528961
[10/23] Train loss=0.4166579246520996
[15/23] Train loss=0.35877567529678345
[20/23] Train loss=0.36414963006973267
Test set avg_accuracy=82.29% avg_sensitivity=44.74%, avg_specificity=94.25% avg_auc=87.32%
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.398351 Test loss=0.373689 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.38235488533973694
[5/23] Train loss=0.38201621174812317
[10/23] Train loss=0.41470369696617126
[15/23] Train loss=0.35592734813690186
[20/23] Train loss=0.3604036271572113
Test set avg_accuracy=82.81% avg_sensitivity=43.23%, avg_specificity=95.42% avg_auc=87.83%
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.392848 Test loss=0.368423 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.36675146222114563
[5/23] Train loss=0.3778356611728668
[10/23] Train loss=0.4041154980659485
[15/23] Train loss=0.3476487696170807
[20/23] Train loss=0.3533755838871002
Test set avg_accuracy=83.24% avg_sensitivity=44.26%, avg_specificity=95.66% avg_auc=88.45%
Best model saved!! Metric=-14.39044903505777!!
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.386212 Test loss=0.362340 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.357844740152359
[5/23] Train loss=0.36896198987960815
[10/23] Train loss=0.3948372006416321
[15/23] Train loss=0.3384944498538971
[20/23] Train loss=0.3404683470726013
Test set avg_accuracy=82.90% avg_sensitivity=43.18%, avg_specificity=95.55% avg_auc=88.75%
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.379576 Test loss=0.358656 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.3591679632663727
[5/23] Train loss=0.3645120859146118
[10/23] Train loss=0.39378175139427185
[15/23] Train loss=0.34711185097694397
[20/23] Train loss=0.33776023983955383
Test set avg_accuracy=82.94% avg_sensitivity=41.40%, avg_specificity=96.17% avg_auc=88.77%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.375865 Test loss=0.359023 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.3522813618183136
[5/23] Train loss=0.3575100302696228
[10/23] Train loss=0.39744699001312256
[15/23] Train loss=0.3361389636993408
[20/23] Train loss=0.32980531454086304
Test set avg_accuracy=83.28% avg_sensitivity=44.10%, avg_specificity=95.76% avg_auc=88.72%
Best model saved!! Metric=-14.138455470656965!!
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.371033 Test loss=0.356831 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.35527217388153076
[5/23] Train loss=0.3509713113307953
[10/23] Train loss=0.3898785710334778
[15/23] Train loss=0.3406171202659607
[20/23] Train loss=0.3318442106246948
Test set avg_accuracy=83.52% avg_sensitivity=44.91%, avg_specificity=95.81% avg_auc=89.21%
Best model saved!! Metric=-12.552790024929713!!
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.368625 Test loss=0.351557 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.34363454580307007
[5/23] Train loss=0.356183260679245
[10/23] Train loss=0.3847241997718811
[15/23] Train loss=0.3314443528652191
[20/23] Train loss=0.32694971561431885
Test set avg_accuracy=83.87% avg_sensitivity=49.60%, avg_specificity=94.78% avg_auc=89.27%
Best model saved!! Metric=-8.489028734975655!!
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.366173 Test loss=0.348794 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.3503303825855255
[5/23] Train loss=0.3567369282245636
[10/23] Train loss=0.3698960244655609
[15/23] Train loss=0.32755574584007263
[20/23] Train loss=0.32826152443885803
Test set avg_accuracy=83.76% avg_sensitivity=46.09%, avg_specificity=95.76% avg_auc=89.39%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.363437 Test loss=0.348447 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.3415403664112091
[5/23] Train loss=0.3546527326107025
[10/23] Train loss=0.37754181027412415
[15/23] Train loss=0.3311327397823334
[20/23] Train loss=0.324899822473526
Test set avg_accuracy=83.58% avg_sensitivity=48.89%, avg_specificity=94.63% avg_auc=89.26%
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.362583 Test loss=0.348595 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.34566834568977356
[5/23] Train loss=0.3537493348121643
[10/23] Train loss=0.3746509850025177
[15/23] Train loss=0.3214973211288452
[20/23] Train loss=0.32327455282211304
Test set avg_accuracy=83.74% avg_sensitivity=47.44%, avg_specificity=95.30% avg_auc=89.25%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.361170 Test loss=0.349088 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.3472421169281006
[5/23] Train loss=0.351275771856308
[10/23] Train loss=0.3725205361843109
[15/23] Train loss=0.32849669456481934
[20/23] Train loss=0.32437074184417725
Test set avg_accuracy=83.22% avg_sensitivity=44.04%, avg_specificity=95.69% avg_auc=89.26%
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.359320 Test loss=0.349802 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.3427025079727173
[5/23] Train loss=0.3502141535282135
[10/23] Train loss=0.3650507926940918
[15/23] Train loss=0.3286273777484894
[20/23] Train loss=0.32982179522514343
Test set avg_accuracy=83.26% avg_sensitivity=42.48%, avg_specificity=96.24% avg_auc=89.07%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.357356 Test loss=0.353549 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.3481568694114685
[5/23] Train loss=0.34849900007247925
[10/23] Train loss=0.37163245677948
[15/23] Train loss=0.3284750282764435
[20/23] Train loss=0.3339231610298157
Test set avg_accuracy=82.79% avg_sensitivity=39.89%, avg_specificity=96.45% avg_auc=88.93%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.357785 Test loss=0.357530 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.3471018671989441
[5/23] Train loss=0.3469494581222534
[10/23] Train loss=0.36727094650268555
[15/23] Train loss=0.3295590877532959
[20/23] Train loss=0.3274797797203064
Test set avg_accuracy=83.40% avg_sensitivity=43.13%, avg_specificity=96.22% avg_auc=89.44%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.357735 Test loss=0.350100 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.34013500809669495
[5/23] Train loss=0.3439098596572876
[10/23] Train loss=0.3717784583568573
[15/23] Train loss=0.33084776997566223
[20/23] Train loss=0.3151775896549225
Test set avg_accuracy=83.71% avg_sensitivity=47.28%, avg_specificity=95.31% avg_auc=89.48%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.356668 Test loss=0.346244 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.33850640058517456
[5/23] Train loss=0.35001325607299805
[10/23] Train loss=0.36920061707496643
[15/23] Train loss=0.324386864900589
[20/23] Train loss=0.3174477219581604
Test set avg_accuracy=84.31% avg_sensitivity=52.88%, avg_specificity=94.32% avg_auc=89.67%
Best model saved!! Metric=-4.819120975430799!!
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.357748 Test loss=0.342881 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.3379896879196167
[5/23] Train loss=0.35399502515792847
[10/23] Train loss=0.37099459767341614
[15/23] Train loss=0.3214038908481598
[20/23] Train loss=0.32024702429771423
Test set avg_accuracy=84.28% avg_sensitivity=54.50%, avg_specificity=93.77% avg_auc=89.58%
Best model saved!! Metric=-3.8696157499257637!!
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.356814 Test loss=0.343399 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.34027883410453796
[5/23] Train loss=0.3513377010822296
[10/23] Train loss=0.36409956216812134
[15/23] Train loss=0.3231939673423767
[20/23] Train loss=0.31687429547309875
Test set avg_accuracy=84.19% avg_sensitivity=52.08%, avg_specificity=94.42% avg_auc=89.72%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.354188 Test loss=0.341846 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.33583560585975647
[5/23] Train loss=0.3472777307033539
[10/23] Train loss=0.36543703079223633
[15/23] Train loss=0.32517746090888977
[20/23] Train loss=0.3148294687271118
Test set avg_accuracy=83.95% avg_sensitivity=50.73%, avg_specificity=94.52% avg_auc=89.69%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.354384 Test loss=0.342233 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.34054917097091675
[5/23] Train loss=0.34173500537872314
[10/23] Train loss=0.36471763253211975
[15/23] Train loss=0.3219256103038788
[20/23] Train loss=0.3115537464618683
Test set avg_accuracy=84.66% avg_sensitivity=54.88%, avg_specificity=94.15% avg_auc=89.73%
Best model saved!! Metric=-2.5824503695113137!!
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.353364 Test loss=0.341378 Current lr=[0.000299926900870094]

[0/23] Train loss=0.33922189474105835
[5/23] Train loss=0.34611818194389343
[10/23] Train loss=0.36290767788887024
[15/23] Train loss=0.3171289265155792
[20/23] Train loss=0.31210780143737793
Test set avg_accuracy=84.15% avg_sensitivity=51.54%, avg_specificity=94.54% avg_auc=89.78%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.351669 Test loss=0.341017 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.33887600898742676
[5/23] Train loss=0.34290361404418945
[10/23] Train loss=0.36781594157218933
[15/23] Train loss=0.3239052891731262
[20/23] Train loss=0.3156704306602478
Test set avg_accuracy=83.98% avg_sensitivity=50.40%, avg_specificity=94.68% avg_auc=89.72%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.352082 Test loss=0.341893 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.3331057131290436
[5/23] Train loss=0.3423970937728882
[10/23] Train loss=0.36541247367858887
[15/23] Train loss=0.3233361840248108
[20/23] Train loss=0.3104868233203888
Test set avg_accuracy=84.54% avg_sensitivity=54.45%, avg_specificity=94.13% avg_auc=89.77%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.351533 Test loss=0.340248 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.33210262656211853
[5/23] Train loss=0.34194430708885193
[10/23] Train loss=0.36280176043510437
[15/23] Train loss=0.32160067558288574
[20/23] Train loss=0.30969852209091187
Test set avg_accuracy=84.90% avg_sensitivity=56.01%, avg_specificity=94.09% avg_auc=89.90%
Best model saved!! Metric=-1.097836483771573!!
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.350157 Test loss=0.338736 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.3315764367580414
[5/23] Train loss=0.3432122468948364
[10/23] Train loss=0.36982738971710205
[15/23] Train loss=0.31653302907943726
[20/23] Train loss=0.3113301992416382
Test set avg_accuracy=84.87% avg_sensitivity=56.12%, avg_specificity=94.03% avg_auc=89.92%
Best model saved!! Metric=-1.0687851990136181!!
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.349906 Test loss=0.338406 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.3319093883037567
[5/23] Train loss=0.3439483940601349
[10/23] Train loss=0.36206749081611633
[15/23] Train loss=0.3186124861240387
[20/23] Train loss=0.30957257747650146
Test set avg_accuracy=84.57% avg_sensitivity=53.53%, avg_specificity=94.45% avg_auc=89.77%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.349422 Test loss=0.340234 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.3353255093097687
[5/23] Train loss=0.3420342206954956
[10/23] Train loss=0.3668575584888458
[15/23] Train loss=0.31663450598716736
[20/23] Train loss=0.3136664927005768
Test set avg_accuracy=84.64% avg_sensitivity=53.91%, avg_specificity=94.42% avg_auc=89.80%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.349722 Test loss=0.339770 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.3312890827655792
[5/23] Train loss=0.34697502851486206
[10/23] Train loss=0.3616880476474762
[15/23] Train loss=0.31710413098335266
[20/23] Train loss=0.3139232099056244
Test set avg_accuracy=84.92% avg_sensitivity=55.53%, avg_specificity=94.28% avg_auc=89.97%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.349733 Test loss=0.337709 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.32755333185195923
[5/23] Train loss=0.34250107407569885
[10/23] Train loss=0.36261141300201416
[15/23] Train loss=0.31542250514030457
[20/23] Train loss=0.31021055579185486
Test set avg_accuracy=85.01% avg_sensitivity=56.33%, avg_specificity=94.15% avg_auc=89.89%
Best model saved!! Metric=-0.6149976297001061!!
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.348490 Test loss=0.338389 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.3287525475025177
[5/23] Train loss=0.34492242336273193
[10/23] Train loss=0.3625919222831726
[15/23] Train loss=0.31809672713279724
[20/23] Train loss=0.30782562494277954
Test set avg_accuracy=85.22% avg_sensitivity=57.63%, avg_specificity=94.01% avg_auc=90.05%
Best model saved!! Metric=0.9098656713576219!!
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.348195 Test loss=0.336685 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.326621413230896
[5/23] Train loss=0.3392293155193329
[10/23] Train loss=0.3566890358924866
[15/23] Train loss=0.3162324130535126
[20/23] Train loss=0.3089948296546936
Test set avg_accuracy=84.71% avg_sensitivity=54.61%, avg_specificity=94.30% avg_auc=89.93%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.345755 Test loss=0.338058 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.32673200964927673
[5/23] Train loss=0.3446686863899231
[10/23] Train loss=0.3634880781173706
[15/23] Train loss=0.3179517686367035
[20/23] Train loss=0.3072357475757599
Test set avg_accuracy=85.08% avg_sensitivity=57.79%, avg_specificity=93.77% avg_auc=90.00%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.347315 Test loss=0.337607 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.32981473207473755
[5/23] Train loss=0.3438073694705963
[10/23] Train loss=0.3577490448951721
[15/23] Train loss=0.31409573554992676
[20/23] Train loss=0.3115404546260834
Test set avg_accuracy=84.77% avg_sensitivity=55.47%, avg_specificity=94.09% avg_auc=90.05%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.346424 Test loss=0.336902 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.32671859860420227
[5/23] Train loss=0.34147968888282776
[10/23] Train loss=0.3610813617706299
[15/23] Train loss=0.3152620792388916
[20/23] Train loss=0.3109251856803894
Test set avg_accuracy=84.86% avg_sensitivity=55.31%, avg_specificity=94.27% avg_auc=90.05%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.345562 Test loss=0.336895 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.3273107707500458
[5/23] Train loss=0.3422490060329437
[10/23] Train loss=0.35951390862464905
[15/23] Train loss=0.3167617917060852
[20/23] Train loss=0.3066786229610443
Test set avg_accuracy=84.99% avg_sensitivity=56.44%, avg_specificity=94.08% avg_auc=90.20%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.345374 Test loss=0.334756 Current lr=[0.000283047938381597]

[0/23] Train loss=0.327461838722229
[5/23] Train loss=0.3448479473590851
[10/23] Train loss=0.36009618639945984
[15/23] Train loss=0.3099042475223541
[20/23] Train loss=0.3080456852912903
Test set avg_accuracy=85.07% avg_sensitivity=56.98%, avg_specificity=94.01% avg_auc=90.08%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.344781 Test loss=0.335923 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.3274746835231781
[5/23] Train loss=0.343906968832016
[10/23] Train loss=0.36079707741737366
[15/23] Train loss=0.3138200044631958
[20/23] Train loss=0.30588459968566895
Test set avg_accuracy=84.92% avg_sensitivity=56.12%, avg_specificity=94.09% avg_auc=90.25%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.344315 Test loss=0.334039 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.32750070095062256
[5/23] Train loss=0.3454338014125824
[10/23] Train loss=0.3636085093021393
[15/23] Train loss=0.3153771758079529
[20/23] Train loss=0.30941322445869446
Test set avg_accuracy=85.12% avg_sensitivity=56.87%, avg_specificity=94.11% avg_auc=90.20%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.345213 Test loss=0.334319 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.3249133229255676
[5/23] Train loss=0.34470802545547485
[10/23] Train loss=0.3563176393508911
[15/23] Train loss=0.31446772813796997
[20/23] Train loss=0.304938405752182
Test set avg_accuracy=85.16% avg_sensitivity=57.36%, avg_specificity=94.01% avg_auc=90.21%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.343720 Test loss=0.334422 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.32747480273246765
[5/23] Train loss=0.3420325219631195
[10/23] Train loss=0.36119773983955383
[15/23] Train loss=0.31147971749305725
[20/23] Train loss=0.31079763174057007
Test set avg_accuracy=84.95% avg_sensitivity=56.39%, avg_specificity=94.04% avg_auc=90.17%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.344093 Test loss=0.334860 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.3255593478679657
[5/23] Train loss=0.342989444732666
[10/23] Train loss=0.35711079835891724
[15/23] Train loss=0.3096373379230499
[20/23] Train loss=0.305355429649353
Test set avg_accuracy=84.90% avg_sensitivity=55.69%, avg_specificity=94.20% avg_auc=90.13%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.343089 Test loss=0.335418 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.3262825012207031
[5/23] Train loss=0.3411463797092438
[10/23] Train loss=0.35739248991012573
[15/23] Train loss=0.31118661165237427
[20/23] Train loss=0.30822840332984924
Test set avg_accuracy=84.97% avg_sensitivity=56.17%, avg_specificity=94.15% avg_auc=90.20%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.342827 Test loss=0.334686 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.32433900237083435
[5/23] Train loss=0.3395675718784332
[10/23] Train loss=0.3592277467250824
[15/23] Train loss=0.3074072599411011
[20/23] Train loss=0.3026983439922333
Test set avg_accuracy=84.91% avg_sensitivity=55.85%, avg_specificity=94.16% avg_auc=90.25%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.342004 Test loss=0.333818 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.32059550285339355
[5/23] Train loss=0.34262925386428833
[10/23] Train loss=0.3569325804710388
[15/23] Train loss=0.31059154868125916
[20/23] Train loss=0.30214789509773254
Test set avg_accuracy=84.96% avg_sensitivity=56.33%, avg_specificity=94.08% avg_auc=90.36%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.341767 Test loss=0.332534 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.32208430767059326
[5/23] Train loss=0.34339430928230286
[10/23] Train loss=0.35488972067832947
[15/23] Train loss=0.3107447326183319
[20/23] Train loss=0.3071456551551819
Test set avg_accuracy=85.07% avg_sensitivity=56.77%, avg_specificity=94.08% avg_auc=90.32%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.341977 Test loss=0.332928 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.31914764642715454
[5/23] Train loss=0.3438898026943207
[10/23] Train loss=0.35227224230766296
[15/23] Train loss=0.31147316098213196
[20/23] Train loss=0.30957111716270447
Test set avg_accuracy=85.18% avg_sensitivity=57.41%, avg_specificity=94.03% avg_auc=90.35%
Best model saved!! Metric=0.9688562236579941!!
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.343170 Test loss=0.332199 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.32205238938331604
[5/23] Train loss=0.34690800309181213
[10/23] Train loss=0.35344743728637695
[15/23] Train loss=0.3085280954837799
[20/23] Train loss=0.309296190738678
Test set avg_accuracy=85.25% avg_sensitivity=58.11%, avg_specificity=93.89% avg_auc=90.35%
Best model saved!! Metric=1.5967821341326953!!
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.343173 Test loss=0.332628 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.3197733759880066
[5/23] Train loss=0.3443518579006195
[10/23] Train loss=0.35462576150894165
[15/23] Train loss=0.3135310709476471
[20/23] Train loss=0.3111523389816284
Test set avg_accuracy=85.55% avg_sensitivity=65.71%, avg_specificity=91.86% avg_auc=90.38%
Best model saved!! Metric=7.506024960089306!!
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.345057 Test loss=0.335782 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.3291977643966675
[5/23] Train loss=0.3333413898944855
[10/23] Train loss=0.3570663630962372
[15/23] Train loss=0.32571786642074585
[20/23] Train loss=0.296720951795578
Test set avg_accuracy=85.34% avg_sensitivity=70.73%, avg_specificity=89.99% avg_auc=90.36%
Best model saved!! Metric=10.420452289851895!!
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.344502 Test loss=0.343416 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.3409656584262848
[5/23] Train loss=0.32685670256614685
[10/23] Train loss=0.34608620405197144
[15/23] Train loss=0.32069817185401917
[20/23] Train loss=0.30000272393226624
Test set avg_accuracy=85.20% avg_sensitivity=69.76%, avg_specificity=90.11% avg_auc=90.34%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.341888 Test loss=0.342928 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.3417622447013855
[5/23] Train loss=0.3290046751499176
[10/23] Train loss=0.35262560844421387
[15/23] Train loss=0.31413981318473816
[20/23] Train loss=0.30037978291511536
Test set avg_accuracy=85.16% avg_sensitivity=69.22%, avg_specificity=90.23% avg_auc=90.39%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.340846 Test loss=0.341205 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.3364313244819641
[5/23] Train loss=0.32969504594802856
[10/23] Train loss=0.35060280561447144
[15/23] Train loss=0.3173905909061432
[20/23] Train loss=0.29571810364723206
Test set avg_accuracy=85.16% avg_sensitivity=69.06%, avg_specificity=90.28% avg_auc=90.41%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.339577 Test loss=0.340270 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.3371226489543915
[5/23] Train loss=0.3299694061279297
[10/23] Train loss=0.3525746762752533
[15/23] Train loss=0.3136415183544159
[20/23] Train loss=0.2951414883136749
Test set avg_accuracy=85.34% avg_sensitivity=69.16%, avg_specificity=90.49% avg_auc=90.43%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.340968 Test loss=0.339709 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.3336232006549835
[5/23] Train loss=0.3276897668838501
[10/23] Train loss=0.3548181354999542
[15/23] Train loss=0.3171136975288391
[20/23] Train loss=0.2960597574710846
Test set avg_accuracy=85.21% avg_sensitivity=69.38%, avg_specificity=90.25% avg_auc=90.44%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.339510 Test loss=0.340304 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.3351190686225891
[5/23] Train loss=0.3277652859687805
[10/23] Train loss=0.35188665986061096
[15/23] Train loss=0.31078141927719116
[20/23] Train loss=0.29878491163253784
Test set avg_accuracy=85.52% avg_sensitivity=70.08%, avg_specificity=90.44% avg_auc=90.45%
Best model saved!! Metric=10.485996504440322!!
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.338229 Test loss=0.339693 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.3385756313800812
[5/23] Train loss=0.32820606231689453
[10/23] Train loss=0.35004889965057373
[15/23] Train loss=0.3143647611141205
[20/23] Train loss=0.29738718271255493
Test set avg_accuracy=85.23% avg_sensitivity=69.76%, avg_specificity=90.16% avg_auc=90.44%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.338256 Test loss=0.340265 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.33717575669288635
[5/23] Train loss=0.3222707211971283
[10/23] Train loss=0.3484273850917816
[15/23] Train loss=0.3128589391708374
[20/23] Train loss=0.29749375581741333
Test set avg_accuracy=85.36% avg_sensitivity=70.08%, avg_specificity=90.23% avg_auc=90.49%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.336873 Test loss=0.338962 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.33575719594955444
[5/23] Train loss=0.32762613892555237
[10/23] Train loss=0.35037538409233093
[15/23] Train loss=0.31428584456443787
[20/23] Train loss=0.2944832742214203
Test set avg_accuracy=85.40% avg_sensitivity=69.65%, avg_specificity=90.42% avg_auc=90.52%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.337231 Test loss=0.338135 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.33336424827575684
[5/23] Train loss=0.3269670009613037
[10/23] Train loss=0.3542156517505646
[15/23] Train loss=0.31383925676345825
[20/23] Train loss=0.2950866222381592
Test set avg_accuracy=85.59% avg_sensitivity=69.60%, avg_specificity=90.68% avg_auc=90.52%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.335342 Test loss=0.337473 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.3320462107658386
[5/23] Train loss=0.32564201951026917
[10/23] Train loss=0.35347551107406616
[15/23] Train loss=0.3070357143878937
[20/23] Train loss=0.29605522751808167
Test set avg_accuracy=85.55% avg_sensitivity=69.81%, avg_specificity=90.56% avg_auc=90.58%
Best model saved!! Metric=10.499368550663434!!
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.335779 Test loss=0.336587 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.3341973125934601
[5/23] Train loss=0.32507842779159546
[10/23] Train loss=0.35132014751434326
[15/23] Train loss=0.3137563467025757
[20/23] Train loss=0.29368147253990173
Test set avg_accuracy=85.60% avg_sensitivity=69.49%, avg_specificity=90.73% avg_auc=90.57%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.335814 Test loss=0.335867 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.33009862899780273
[5/23] Train loss=0.32464349269866943
[10/23] Train loss=0.34757882356643677
[15/23] Train loss=0.30730023980140686
[20/23] Train loss=0.29161062836647034
Test set avg_accuracy=85.74% avg_sensitivity=69.70%, avg_specificity=90.85% avg_auc=90.58%
Best model saved!! Metric=10.8719631903393!!
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.334734 Test loss=0.335843 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.33154502511024475
[5/23] Train loss=0.32483890652656555
[10/23] Train loss=0.3518417477607727
[15/23] Train loss=0.30854323506355286
[20/23] Train loss=0.29235735535621643
Test set avg_accuracy=85.53% avg_sensitivity=67.82%, avg_specificity=91.18% avg_auc=90.61%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.334419 Test loss=0.333867 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.3285869061946869
[5/23] Train loss=0.32447510957717896
[10/23] Train loss=0.35078293085098267
[15/23] Train loss=0.30728983879089355
[20/23] Train loss=0.2897459864616394
Test set avg_accuracy=85.55% avg_sensitivity=68.79%, avg_specificity=90.88% avg_auc=90.56%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.333454 Test loss=0.335620 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.33165010809898376
[5/23] Train loss=0.328524112701416
[10/23] Train loss=0.3496423363685608
[15/23] Train loss=0.31051909923553467
[20/23] Train loss=0.29952284693717957
Test set avg_accuracy=85.52% avg_sensitivity=69.43%, avg_specificity=90.64% avg_auc=90.58%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.334984 Test loss=0.336979 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.33620110154151917
[5/23] Train loss=0.3207195997238159
[10/23] Train loss=0.35203489661216736
[15/23] Train loss=0.30751529335975647
[20/23] Train loss=0.29320579767227173
Test set avg_accuracy=85.95% avg_sensitivity=67.33%, avg_specificity=91.88% avg_auc=90.53%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.333283 Test loss=0.333390 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.3269430696964264
[5/23] Train loss=0.3250546455383301
[10/23] Train loss=0.3492107689380646
[15/23] Train loss=0.3044998347759247
[20/23] Train loss=0.29287999868392944
Test set avg_accuracy=85.39% avg_sensitivity=67.87%, avg_specificity=90.97% avg_auc=90.54%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.333451 Test loss=0.335577 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.3315708041191101
[5/23] Train loss=0.3246598541736603
[10/23] Train loss=0.34894874691963196
[15/23] Train loss=0.30337056517601013
[20/23] Train loss=0.2947225272655487
Test set avg_accuracy=85.85% avg_sensitivity=68.09%, avg_specificity=91.50% avg_auc=90.57%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.332802 Test loss=0.333977 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.326833575963974
[5/23] Train loss=0.32663169503211975
[10/23] Train loss=0.34818151593208313
[15/23] Train loss=0.30639755725860596
[20/23] Train loss=0.29642781615257263
Test set avg_accuracy=85.76% avg_sensitivity=67.82%, avg_specificity=91.47% avg_auc=90.65%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.332474 Test loss=0.332971 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.3259374797344208
[5/23] Train loss=0.3283843994140625
[10/23] Train loss=0.3527781367301941
[15/23] Train loss=0.30526983737945557
[20/23] Train loss=0.2906680405139923
Test set avg_accuracy=85.99% avg_sensitivity=68.63%, avg_specificity=91.52% avg_auc=90.80%
Best model saved!! Metric=10.931804218772271!!
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.332251 Test loss=0.330019 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.32250964641571045
[5/23] Train loss=0.3199045956134796
[10/23] Train loss=0.35011374950408936
[15/23] Train loss=0.30338120460510254
[20/23] Train loss=0.28858765959739685
Test set avg_accuracy=85.68% avg_sensitivity=68.95%, avg_specificity=91.00% avg_auc=90.82%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.330425 Test loss=0.330813 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.32620537281036377
[5/23] Train loss=0.32799258828163147
[10/23] Train loss=0.35371133685112
[15/23] Train loss=0.2999802529811859
[20/23] Train loss=0.2931957542896271
Test set avg_accuracy=86.02% avg_sensitivity=69.54%, avg_specificity=91.26% avg_auc=90.86%
Best model saved!! Metric=11.683679093448873!!
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.330663 Test loss=0.329736 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.3273032605648041
[5/23] Train loss=0.3233543038368225
[10/23] Train loss=0.35159721970558167
[15/23] Train loss=0.30005258321762085
[20/23] Train loss=0.2904909551143646
Test set avg_accuracy=86.04% avg_sensitivity=69.76%, avg_specificity=91.23% avg_auc=90.90%
Best model saved!! Metric=11.923096047877422!!
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.330260 Test loss=0.329054 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.3272892236709595
[5/23] Train loss=0.31928446888923645
[10/23] Train loss=0.3485502302646637
[15/23] Train loss=0.30233678221702576
[20/23] Train loss=0.28860074281692505
Test set avg_accuracy=85.90% avg_sensitivity=69.97%, avg_specificity=90.97% avg_auc=90.92%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.329257 Test loss=0.329042 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.3256877064704895
[5/23] Train loss=0.32101771235466003
[10/23] Train loss=0.3546302318572998
[15/23] Train loss=0.29923442006111145
[20/23] Train loss=0.28914299607276917
Test set avg_accuracy=85.91% avg_sensitivity=70.08%, avg_specificity=90.95% avg_auc=90.92%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.329288 Test loss=0.329240 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.32538968324661255
[5/23] Train loss=0.32089000940322876
[10/23] Train loss=0.3530321717262268
[15/23] Train loss=0.30085882544517517
[20/23] Train loss=0.28787320852279663
Test set avg_accuracy=85.92% avg_sensitivity=70.30%, avg_specificity=90.90% avg_auc=90.95%
Best model saved!! Metric=12.071008093242554!!
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.329160 Test loss=0.329517 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.32466208934783936
[5/23] Train loss=0.3237376809120178
[10/23] Train loss=0.35779157280921936
[15/23] Train loss=0.2998611032962799
[20/23] Train loss=0.290881484746933
Test set avg_accuracy=85.73% avg_sensitivity=70.94%, avg_specificity=90.44% avg_auc=90.95%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.329605 Test loss=0.331041 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.3294467031955719
[5/23] Train loss=0.3315924108028412
[10/23] Train loss=0.3577127754688263
[15/23] Train loss=0.30218803882598877
[20/23] Train loss=0.28687068819999695
Test set avg_accuracy=85.53% avg_sensitivity=74.18%, avg_specificity=89.15% avg_auc=90.87%
Best model saved!! Metric=13.733750051816415!!
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.331173 Test loss=0.338308 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.3383680582046509
[5/23] Train loss=0.331901878118515
[10/23] Train loss=0.3654022514820099
[15/23] Train loss=0.30039864778518677
[20/23] Train loss=0.2941835820674896
Test set avg_accuracy=85.20% avg_sensitivity=76.71%, avg_specificity=87.90% avg_auc=90.74%
Best model saved!! Metric=14.545247139010698!!
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.333386 Test loss=0.348151 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.3465043008327484
[5/23] Train loss=0.3348144590854645
[10/23] Train loss=0.3653971552848816
[15/23] Train loss=0.3040371537208557
[20/23] Train loss=0.2931084930896759
Test set avg_accuracy=85.47% avg_sensitivity=76.66%, avg_specificity=88.27% avg_auc=90.70%
Best model saved!! Metric=15.102103770692835!!
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.336021 Test loss=0.348912 Current lr=[0.000112073915556435]

[0/23] Train loss=0.34698501229286194
[5/23] Train loss=0.31994298100471497
[10/23] Train loss=0.3468015789985657
[15/23] Train loss=0.3186514377593994
[20/23] Train loss=0.3023354113101959
Test set avg_accuracy=86.38% avg_sensitivity=67.01%, avg_specificity=92.55% avg_auc=90.92%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.335050 Test loss=0.327516 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.3181021511554718
[5/23] Train loss=0.31939414143562317
[10/23] Train loss=0.35161393880844116
[15/23] Train loss=0.31536567211151123
[20/23] Train loss=0.2939899265766144
Test set avg_accuracy=86.30% avg_sensitivity=64.85%, avg_specificity=93.13% avg_auc=90.97%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.329935 Test loss=0.324790 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.3122287392616272
[5/23] Train loss=0.3195488750934601
[10/23] Train loss=0.3457977771759033
[15/23] Train loss=0.30922776460647583
[20/23] Train loss=0.2943725287914276
Test set avg_accuracy=86.33% avg_sensitivity=67.92%, avg_specificity=92.19% avg_auc=90.99%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.327597 Test loss=0.327413 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.3232007920742035
[5/23] Train loss=0.3260599374771118
[10/23] Train loss=0.34914660453796387
[15/23] Train loss=0.31190037727355957
[20/23] Train loss=0.2947217524051666
Test set avg_accuracy=86.33% avg_sensitivity=66.47%, avg_specificity=92.65% avg_auc=90.98%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.329174 Test loss=0.326074 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.31983324885368347
[5/23] Train loss=0.3172202706336975
[10/23] Train loss=0.35141366720199585
[15/23] Train loss=0.31360939145088196
[20/23] Train loss=0.296874463558197
Test set avg_accuracy=86.18% avg_sensitivity=64.85%, avg_specificity=92.98% avg_auc=90.98%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.328622 Test loss=0.325250 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.3156959116458893
[5/23] Train loss=0.3191284239292145
[10/23] Train loss=0.3478969633579254
[15/23] Train loss=0.31325507164001465
[20/23] Train loss=0.2934808135032654
Test set avg_accuracy=86.24% avg_sensitivity=65.34%, avg_specificity=92.89% avg_auc=90.93%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.327076 Test loss=0.326648 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.31635138392448425
[5/23] Train loss=0.31853145360946655
[10/23] Train loss=0.34960246086120605
[15/23] Train loss=0.3096465468406677
[20/23] Train loss=0.2943574786186218
Test set avg_accuracy=86.22% avg_sensitivity=65.12%, avg_specificity=92.94% avg_auc=90.90%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.327227 Test loss=0.326787 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.3218560814857483
[5/23] Train loss=0.32018816471099854
[10/23] Train loss=0.35276052355766296
[15/23] Train loss=0.30963337421417236
[20/23] Train loss=0.2885892391204834
Test set avg_accuracy=85.92% avg_sensitivity=64.74%, avg_specificity=92.67% avg_auc=90.76%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.327035 Test loss=0.328886 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.3219897150993347
[5/23] Train loss=0.32096853852272034
[10/23] Train loss=0.35246825218200684
[15/23] Train loss=0.3052317500114441
[20/23] Train loss=0.29167598485946655
Test set avg_accuracy=85.91% avg_sensitivity=63.72%, avg_specificity=92.98% avg_auc=90.71%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.327650 Test loss=0.329197 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.31935229897499084
[5/23] Train loss=0.32143256068229675
[10/23] Train loss=0.3473404049873352
[15/23] Train loss=0.3101904094219208
[20/23] Train loss=0.2907577157020569
Test set avg_accuracy=85.90% avg_sensitivity=62.48%, avg_specificity=93.36% avg_auc=90.85%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.325588 Test loss=0.325827 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.3146962523460388
[5/23] Train loss=0.31625238060951233
[10/23] Train loss=0.3423805832862854
[15/23] Train loss=0.3043919503688812
[20/23] Train loss=0.29135289788246155
Test set avg_accuracy=86.41% avg_sensitivity=65.01%, avg_specificity=93.22% avg_auc=91.06%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.325354 Test loss=0.323458 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.311729371547699
[5/23] Train loss=0.31621935963630676
[10/23] Train loss=0.3422805368900299
[15/23] Train loss=0.3073117136955261
[20/23] Train loss=0.29020896553993225
Test set avg_accuracy=86.11% avg_sensitivity=62.96%, avg_specificity=93.48% avg_auc=91.07%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.325104 Test loss=0.322860 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.31369292736053467
[5/23] Train loss=0.31941720843315125
[10/23] Train loss=0.3410498797893524
[15/23] Train loss=0.306292861700058
[20/23] Train loss=0.29059940576553345
Test set avg_accuracy=86.15% avg_sensitivity=62.91%, avg_specificity=93.55% avg_auc=91.12%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.323480 Test loss=0.321680 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.31492242217063904
[5/23] Train loss=0.3168368935585022
[10/23] Train loss=0.3473491072654724
[15/23] Train loss=0.30111071467399597
[20/23] Train loss=0.28923001885414124
Test set avg_accuracy=86.09% avg_sensitivity=62.59%, avg_specificity=93.58% avg_auc=91.11%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.323663 Test loss=0.321390 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.31056907773017883
[5/23] Train loss=0.3128947615623474
[10/23] Train loss=0.3481581509113312
[15/23] Train loss=0.3085930049419403
[20/23] Train loss=0.2937866449356079
Test set avg_accuracy=86.04% avg_sensitivity=62.32%, avg_specificity=93.60% avg_auc=91.14%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.323220 Test loss=0.321251 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.31455498933792114
[5/23] Train loss=0.3141138255596161
[10/23] Train loss=0.3483315408229828
[15/23] Train loss=0.3039272427558899
[20/23] Train loss=0.28747326135635376
Test set avg_accuracy=85.94% avg_sensitivity=61.83%, avg_specificity=93.61% avg_auc=91.14%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.323515 Test loss=0.320972 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.31384384632110596
[5/23] Train loss=0.31753262877464294
[10/23] Train loss=0.3455207943916321
[15/23] Train loss=0.3078996241092682
[20/23] Train loss=0.2912260890007019
Test set avg_accuracy=85.94% avg_sensitivity=61.13%, avg_specificity=93.84% avg_auc=91.14%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.323227 Test loss=0.320485 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.30856138467788696
[5/23] Train loss=0.3133774995803833
[10/23] Train loss=0.3421716094017029
[15/23] Train loss=0.3045681118965149
[20/23] Train loss=0.2871953547000885
Test set avg_accuracy=85.87% avg_sensitivity=60.92%, avg_specificity=93.82% avg_auc=91.15%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.322169 Test loss=0.320044 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.30979830026626587
[5/23] Train loss=0.3124416470527649
[10/23] Train loss=0.3449694514274597
[15/23] Train loss=0.3025265634059906
[20/23] Train loss=0.2840701937675476
Test set avg_accuracy=85.92% avg_sensitivity=60.97%, avg_specificity=93.87% avg_auc=91.17%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.322485 Test loss=0.320017 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.31135067343711853
[5/23] Train loss=0.3144233822822571
[10/23] Train loss=0.3489322066307068
[15/23] Train loss=0.3038196265697479
[20/23] Train loss=0.288679838180542
Test set avg_accuracy=85.90% avg_sensitivity=60.59%, avg_specificity=93.96% avg_auc=91.21%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.322139 Test loss=0.319324 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.30596283078193665
[5/23] Train loss=0.31788334250450134
[10/23] Train loss=0.3415870666503906
[15/23] Train loss=0.30121371150016785
[20/23] Train loss=0.2899070382118225
Test set avg_accuracy=85.82% avg_sensitivity=60.16%, avg_specificity=93.99% avg_auc=91.19%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.321297 Test loss=0.319240 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.3043043315410614
[5/23] Train loss=0.3153051435947418
[10/23] Train loss=0.3443983495235443
[15/23] Train loss=0.30317002534866333
[20/23] Train loss=0.28554409742355347
Test set avg_accuracy=85.86% avg_sensitivity=60.54%, avg_specificity=93.92% avg_auc=91.20%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.320962 Test loss=0.319198 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.3090426027774811
[5/23] Train loss=0.31462544202804565
[10/23] Train loss=0.34955304861068726
[15/23] Train loss=0.30502912402153015
[20/23] Train loss=0.2859800457954407
Test set avg_accuracy=85.95% avg_sensitivity=59.89%, avg_specificity=94.25% avg_auc=91.22%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.321997 Test loss=0.318971 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.3107162117958069
[5/23] Train loss=0.31763848662376404
[10/23] Train loss=0.347575843334198
[15/23] Train loss=0.3036290407180786
[20/23] Train loss=0.28377053141593933
Test set avg_accuracy=85.65% avg_sensitivity=58.49%, avg_specificity=94.30% avg_auc=91.23%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.321771 Test loss=0.318547 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.31006932258605957
[5/23] Train loss=0.31593063473701477
[10/23] Train loss=0.34975263476371765
[15/23] Train loss=0.3071192800998688
[20/23] Train loss=0.28824830055236816
Test set avg_accuracy=85.77% avg_sensitivity=59.25%, avg_specificity=94.21% avg_auc=91.23%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.321516 Test loss=0.318621 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.3108469247817993
[5/23] Train loss=0.3096063733100891
[10/23] Train loss=0.3431819975376129
[15/23] Train loss=0.30062922835350037
[20/23] Train loss=0.285221666097641
Test set avg_accuracy=85.98% avg_sensitivity=60.86%, avg_specificity=93.97% avg_auc=91.24%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.320700 Test loss=0.318693 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.30719929933547974
[5/23] Train loss=0.316586434841156
[10/23] Train loss=0.3458494246006012
[15/23] Train loss=0.3066864609718323
[20/23] Train loss=0.2854560315608978
Test set avg_accuracy=86.16% avg_sensitivity=63.34%, avg_specificity=93.42% avg_auc=91.24%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.320362 Test loss=0.319240 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.3077416718006134
[5/23] Train loss=0.3142896592617035
[10/23] Train loss=0.34494656324386597
[15/23] Train loss=0.30362194776535034
[20/23] Train loss=0.2864000201225281
Test set avg_accuracy=86.37% avg_sensitivity=64.69%, avg_specificity=93.27% avg_auc=91.25%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.321323 Test loss=0.319853 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.31400153040885925
[5/23] Train loss=0.31352585554122925
[10/23] Train loss=0.3382412791252136
[15/23] Train loss=0.30035513639450073
[20/23] Train loss=0.2822076976299286
Test set avg_accuracy=86.24% avg_sensitivity=64.26%, avg_specificity=93.24% avg_auc=91.24%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.320002 Test loss=0.319793 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.3128201365470886
[5/23] Train loss=0.31321966648101807
[10/23] Train loss=0.34239739179611206
[15/23] Train loss=0.3006400465965271
[20/23] Train loss=0.28086575865745544
Test set avg_accuracy=86.13% avg_sensitivity=63.23%, avg_specificity=93.42% avg_auc=91.25%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.319097 Test loss=0.318987 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.30868837237358093
[5/23] Train loss=0.31490853428840637
[10/23] Train loss=0.3463289439678192
[15/23] Train loss=0.3006090223789215
[20/23] Train loss=0.28800931572914124
Test set avg_accuracy=86.15% avg_sensitivity=63.02%, avg_specificity=93.51% avg_auc=91.26%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.320685 Test loss=0.318861 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.3126000463962555
[5/23] Train loss=0.3136422038078308
[10/23] Train loss=0.3432050347328186
[15/23] Train loss=0.2999110519886017
[20/23] Train loss=0.28403589129447937
Test set avg_accuracy=86.16% avg_sensitivity=63.02%, avg_specificity=93.53% avg_auc=91.27%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.320133 Test loss=0.318701 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.30949658155441284
[5/23] Train loss=0.3105000853538513
[10/23] Train loss=0.33755946159362793
[15/23] Train loss=0.29470789432525635
[20/23] Train loss=0.28505682945251465
Test set avg_accuracy=86.12% avg_sensitivity=62.80%, avg_specificity=93.55% avg_auc=91.27%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.319136 Test loss=0.318461 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.30964377522468567
[5/23] Train loss=0.309154212474823
[10/23] Train loss=0.3388359844684601
[15/23] Train loss=0.2959071099758148
[20/23] Train loss=0.28665754199028015
Test set avg_accuracy=86.15% avg_sensitivity=62.96%, avg_specificity=93.53% avg_auc=91.28%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.319341 Test loss=0.318419 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.30730149149894714
[5/23] Train loss=0.3108793795108795
[10/23] Train loss=0.3485163450241089
[15/23] Train loss=0.30064839124679565
[20/23] Train loss=0.2872343361377716
Test set avg_accuracy=86.12% avg_sensitivity=62.86%, avg_specificity=93.53% avg_auc=91.28%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.319500 Test loss=0.318326 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.3110944628715515
[5/23] Train loss=0.3093896210193634
[10/23] Train loss=0.34257394075393677
[15/23] Train loss=0.29578453302383423
[20/23] Train loss=0.28064653277397156
Test set avg_accuracy=86.07% avg_sensitivity=62.48%, avg_specificity=93.58% avg_auc=91.28%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.318878 Test loss=0.318212 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.30571526288986206
[5/23] Train loss=0.3095847964286804
[10/23] Train loss=0.34782907366752625
[15/23] Train loss=0.303103506565094
[20/23] Train loss=0.2843973636627197
Test set avg_accuracy=86.12% avg_sensitivity=62.80%, avg_specificity=93.55% avg_auc=91.28%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.320189 Test loss=0.318255 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.30741846561431885
[5/23] Train loss=0.3096214234828949
[10/23] Train loss=0.34782475233078003
[15/23] Train loss=0.3014017939567566
[20/23] Train loss=0.2833535075187683
Test set avg_accuracy=86.13% avg_sensitivity=62.48%, avg_specificity=93.67% avg_auc=91.29%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.319038 Test loss=0.318173 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.31329259276390076
[5/23] Train loss=0.3124381899833679
[10/23] Train loss=0.3417780101299286
[15/23] Train loss=0.295343279838562
[20/23] Train loss=0.2845820188522339
Test set avg_accuracy=86.04% avg_sensitivity=61.56%, avg_specificity=93.84% avg_auc=91.29%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.319007 Test loss=0.318096 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.3095988631248474
[5/23] Train loss=0.3097919225692749
[10/23] Train loss=0.34802305698394775
[15/23] Train loss=0.29727903008461
[20/23] Train loss=0.28509947657585144
Test set avg_accuracy=86.09% avg_sensitivity=61.67%, avg_specificity=93.87% avg_auc=91.29%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.319257 Test loss=0.318088 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.3088397681713104
[5/23] Train loss=0.31372445821762085
[10/23] Train loss=0.3424467146396637
[15/23] Train loss=0.2984429597854614
[20/23] Train loss=0.2830890715122223
Test set avg_accuracy=86.17% avg_sensitivity=62.16%, avg_specificity=93.82% avg_auc=91.29%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.319770 Test loss=0.318106 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.3055800795555115
[5/23] Train loss=0.31568464636802673
[10/23] Train loss=0.3416826128959656
[15/23] Train loss=0.29635170102119446
[20/23] Train loss=0.28598514199256897
Test set avg_accuracy=86.16% avg_sensitivity=62.05%, avg_specificity=93.84% avg_auc=91.29%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.319537 Test loss=0.318093 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.30975475907325745
[5/23] Train loss=0.313730388879776
[10/23] Train loss=0.34723180532455444
[15/23] Train loss=0.3011222183704376
[20/23] Train loss=0.28543198108673096
Test set avg_accuracy=86.16% avg_sensitivity=62.05%, avg_specificity=93.84% avg_auc=91.29%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.320279 Test loss=0.318090 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.30918195843696594
[5/23] Train loss=0.31050747632980347
[10/23] Train loss=0.3419700860977173
[15/23] Train loss=0.2998768091201782
[20/23] Train loss=0.2796984612941742
Test set avg_accuracy=86.16% avg_sensitivity=62.05%, avg_specificity=93.84% avg_auc=91.29%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.319516 Test loss=0.318087 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=85.47% sen=76.66%, spe=88.27%, auc=90.70%!
Fold[9] Avg_overlap=0.68%(0.24015028806018293)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'HybridCNNRNN',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.8360142111778259
[5/24] Train loss=0.725251317024231
[10/24] Train loss=0.6770521402359009
[15/24] Train loss=0.641309380531311
[20/24] Train loss=0.6313104033470154
Test set avg_accuracy=77.54% avg_sensitivity=0.06%, avg_specificity=100.00% avg_auc=52.24%
Best model saved!! Metric=-96.1583383145103!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.680485 Test loss=0.551975 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6201136112213135
[5/24] Train loss=0.6022151708602905
[10/24] Train loss=0.5998324155807495
[15/24] Train loss=0.5980899930000305
[20/24] Train loss=0.6057290434837341
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=55.59%
Best model saved!! Metric=-92.88376044305751!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.599650 Test loss=0.535185 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6027110815048218
[5/24] Train loss=0.5914083123207092
[10/24] Train loss=0.5877048969268799
[15/24] Train loss=0.5956448912620544
[20/24] Train loss=0.6000632643699646
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=59.64%
Best model saved!! Metric=-88.83143926769648!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.589596 Test loss=0.532407 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.5986735224723816
[5/24] Train loss=0.5811067223548889
[10/24] Train loss=0.585501492023468
[15/24] Train loss=0.5926821231842041
[20/24] Train loss=0.5958543419837952
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=61.93%
Best model saved!! Metric=-86.5450030091815!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.585041 Test loss=0.527333 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5940026640892029
[5/24] Train loss=0.5782331824302673
[10/24] Train loss=0.5797322988510132
[15/24] Train loss=0.586007833480835
[20/24] Train loss=0.5906329154968262
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=65.00%
Best model saved!! Metric=-83.47023239429744!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.579882 Test loss=0.522128 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5813727378845215
[5/24] Train loss=0.576465904712677
[10/24] Train loss=0.5769381523132324
[15/24] Train loss=0.5775536894798279
[20/24] Train loss=0.5880643725395203
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=68.61%
Best model saved!! Metric=-79.8642113780162!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.574340 Test loss=0.515442 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5771997570991516
[5/24] Train loss=0.5664908289909363
[10/24] Train loss=0.5649240016937256
[15/24] Train loss=0.568825364112854
[20/24] Train loss=0.5735195279121399
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=71.53%
Best model saved!! Metric=-76.94002066287332!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.566415 Test loss=0.508359 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5716680288314819
[5/24] Train loss=0.5595822334289551
[10/24] Train loss=0.5577104091644287
[15/24] Train loss=0.5597397089004517
[20/24] Train loss=0.564306378364563
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=74.53%
Best model saved!! Metric=-73.93911686235712!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.558315 Test loss=0.500394 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.555576503276825
[5/24] Train loss=0.5432262420654297
[10/24] Train loss=0.547480583190918
[15/24] Train loss=0.5515524744987488
[20/24] Train loss=0.557428777217865
Test set avg_accuracy=77.64% avg_sensitivity=0.87%, avg_specificity=99.90% avg_auc=76.79%
Best model saved!! Metric=-70.79736988726204!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.548198 Test loss=0.490237 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5449352264404297
[5/24] Train loss=0.5404403805732727
[10/24] Train loss=0.5475327968597412
[15/24] Train loss=0.542624294757843
[20/24] Train loss=0.546191394329071
Test set avg_accuracy=77.40% avg_sensitivity=1.22%, avg_specificity=99.48% avg_auc=78.53%
Best model saved!! Metric=-69.37913765902952!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.540543 Test loss=0.479056 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5369219779968262
[5/24] Train loss=0.5291897654533386
[10/24] Train loss=0.5380582213401794
[15/24] Train loss=0.525323212146759
[20/24] Train loss=0.5292514562606812
Test set avg_accuracy=77.38% avg_sensitivity=1.56%, avg_specificity=99.36% avg_auc=80.25%
Best model saved!! Metric=-67.4390570592435!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.526579 Test loss=0.465224 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5160478353500366
[5/24] Train loss=0.5104334950447083
[10/24] Train loss=0.5294859409332275
[15/24] Train loss=0.5132254362106323
[20/24] Train loss=0.5228502750396729
Test set avg_accuracy=76.89% avg_sensitivity=2.72%, avg_specificity=98.39% avg_auc=81.96%
Best model saved!! Metric=-66.04389072032777!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.515766 Test loss=0.450961 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4930621087551117
[5/24] Train loss=0.4932674169540405
[10/24] Train loss=0.5191408395767212
[15/24] Train loss=0.4975444972515106
[20/24] Train loss=0.5072485208511353
Test set avg_accuracy=76.72% avg_sensitivity=7.01%, avg_specificity=96.93% avg_auc=83.25%
Best model saved!! Metric=-62.09829053206683!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.501411 Test loss=0.436313 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.48621803522109985
[5/24] Train loss=0.47710302472114563
[10/24] Train loss=0.4980231821537018
[15/24] Train loss=0.48704588413238525
[20/24] Train loss=0.48911675810813904
Test set avg_accuracy=77.70% avg_sensitivity=16.74%, avg_specificity=95.36% avg_auc=84.63%
Best model saved!! Metric=-51.56371159005933!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.486807 Test loss=0.422051 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4610166847705841
[5/24] Train loss=0.47687655687332153
[10/24] Train loss=0.48532116413116455
[15/24] Train loss=0.4649500250816345
[20/24] Train loss=0.47408241033554077
Test set avg_accuracy=79.56% avg_sensitivity=28.10%, avg_specificity=94.47% avg_auc=85.49%
Best model saved!! Metric=-38.37916418976218!!
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.471247 Test loss=0.408737 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.44282686710357666
[5/24] Train loss=0.455585241317749
[10/24] Train loss=0.47879138588905334
[15/24] Train loss=0.44953787326812744
[20/24] Train loss=0.458214670419693
Test set avg_accuracy=79.95% avg_sensitivity=32.21%, avg_specificity=93.79% avg_auc=86.18%
Best model saved!! Metric=-33.87565812516147!!
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.459314 Test loss=0.395220 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4324212670326233
[5/24] Train loss=0.44913581013679504
[10/24] Train loss=0.4731595814228058
[15/24] Train loss=0.44063156843185425
[20/24] Train loss=0.4462096691131592
Test set avg_accuracy=80.85% avg_sensitivity=35.34%, avg_specificity=94.04% avg_auc=86.57%
Best model saved!! Metric=-29.202471690591224!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.448087 Test loss=0.384374 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.41917046904563904
[5/24] Train loss=0.4362861216068268
[10/24] Train loss=0.46492746472358704
[15/24] Train loss=0.427036851644516
[20/24] Train loss=0.43799281120300293
Test set avg_accuracy=80.64% avg_sensitivity=28.56%, avg_specificity=95.73% avg_auc=86.77%
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.437403 Test loss=0.376001 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4079320728778839
[5/24] Train loss=0.4159826636314392
[10/24] Train loss=0.4386323392391205
[15/24] Train loss=0.4139620363712311
[20/24] Train loss=0.42679470777511597
Test set avg_accuracy=81.50% avg_sensitivity=29.66%, avg_specificity=96.52% avg_auc=87.23%
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.427817 Test loss=0.369457 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.39402657747268677
[5/24] Train loss=0.40101513266563416
[10/24] Train loss=0.4306478202342987
[15/24] Train loss=0.4071703851222992
[20/24] Train loss=0.40781116485595703
Test set avg_accuracy=82.75% avg_sensitivity=37.37%, avg_specificity=95.90% avg_auc=87.72%
Best model saved!! Metric=-22.265359742341268!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.416219 Test loss=0.361368 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.38550257682800293
[5/24] Train loss=0.40327882766723633
[10/24] Train loss=0.4122573733329773
[15/24] Train loss=0.39382511377334595
[20/24] Train loss=0.41058477759361267
Test set avg_accuracy=83.05% avg_sensitivity=35.40%, avg_specificity=96.86% avg_auc=88.04%
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.409053 Test loss=0.356127 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3802548944950104
[5/24] Train loss=0.3933582007884979
[10/24] Train loss=0.40892836451530457
[15/24] Train loss=0.37943270802497864
[20/24] Train loss=0.39772531390190125
Test set avg_accuracy=83.07% avg_sensitivity=32.21%, avg_specificity=97.82% avg_auc=88.20%
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.401450 Test loss=0.355028 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.38090988993644714
[5/24] Train loss=0.3905389606952667
[10/24] Train loss=0.39569103717803955
[15/24] Train loss=0.3787718713283539
[20/24] Train loss=0.3868412673473358
Test set avg_accuracy=82.89% avg_sensitivity=29.37%, avg_specificity=98.40% avg_auc=88.39%
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.393478 Test loss=0.357012 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3791514039039612
[5/24] Train loss=0.3769420087337494
[10/24] Train loss=0.40067601203918457
[15/24] Train loss=0.3724128305912018
[20/24] Train loss=0.380059152841568
Test set avg_accuracy=83.55% avg_sensitivity=34.18%, avg_specificity=97.87% avg_auc=88.87%
Best model saved!! Metric=-21.5291324078217!!
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.386067 Test loss=0.346920 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3674895167350769
[5/24] Train loss=0.3835408389568329
[10/24] Train loss=0.3917902112007141
[15/24] Train loss=0.3641505539417267
[20/24] Train loss=0.369284987449646
Test set avg_accuracy=83.62% avg_sensitivity=32.33%, avg_specificity=98.49% avg_auc=88.84%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.380282 Test loss=0.351731 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.36887165904045105
[5/24] Train loss=0.3870175778865814
[10/24] Train loss=0.3867258131504059
[15/24] Train loss=0.36392125487327576
[20/24] Train loss=0.3682663142681122
Test set avg_accuracy=83.36% avg_sensitivity=30.13%, avg_specificity=98.79% avg_auc=89.07%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.378004 Test loss=0.352442 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.36863207817077637
[5/24] Train loss=0.3694445788860321
[10/24] Train loss=0.3775703012943268
[15/24] Train loss=0.356925904750824
[20/24] Train loss=0.36316850781440735
Test set avg_accuracy=84.14% avg_sensitivity=34.30%, avg_specificity=98.59% avg_auc=89.36%
Best model saved!! Metric=-19.607544531491143!!
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.373851 Test loss=0.344910 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.36230769753456116
[5/24] Train loss=0.38496699929237366
[10/24] Train loss=0.3775956630706787
[15/24] Train loss=0.34982746839523315
[20/24] Train loss=0.3566068112850189
Test set avg_accuracy=83.85% avg_sensitivity=32.85%, avg_specificity=98.64% avg_auc=89.55%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.370652 Test loss=0.344070 Current lr=[0.000210185142098938]

[0/24] Train loss=0.36011189222335815
[5/24] Train loss=0.3890320360660553
[10/24] Train loss=0.37018051743507385
[15/24] Train loss=0.3475884795188904
[20/24] Train loss=0.3586668074131012
Test set avg_accuracy=84.17% avg_sensitivity=34.82%, avg_specificity=98.47% avg_auc=89.56%
Best model saved!! Metric=-18.981980882659933!!
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.369971 Test loss=0.342036 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3506256937980652
[5/24] Train loss=0.38836225867271423
[10/24] Train loss=0.37138983607292175
[15/24] Train loss=0.34346500039100647
[20/24] Train loss=0.3527986705303192
Test set avg_accuracy=84.70% avg_sensitivity=38.88%, avg_specificity=97.98% avg_auc=89.85%
Best model saved!! Metric=-14.590130436288398!!
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.367393 Test loss=0.334340 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3423668146133423
[5/24] Train loss=0.3804372251033783
[10/24] Train loss=0.3625616133213043
[15/24] Train loss=0.3458641767501831
[20/24] Train loss=0.3486688733100891
Test set avg_accuracy=85.52% avg_sensitivity=43.97%, avg_specificity=97.56% avg_auc=90.00%
Best model saved!! Metric=-8.935604221329669!!
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.364242 Test loss=0.328620 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.34441378712654114
[5/24] Train loss=0.3747731149196625
[10/24] Train loss=0.3672330975532532
[15/24] Train loss=0.33862781524658203
[20/24] Train loss=0.3472652733325958
Test set avg_accuracy=85.85% avg_sensitivity=46.58%, avg_specificity=97.23% avg_auc=90.14%
Best model saved!! Metric=-6.199189672523779!!
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.361375 Test loss=0.325385 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3375985324382782
[5/24] Train loss=0.3761371076107025
[10/24] Train loss=0.36503347754478455
[15/24] Train loss=0.3460715711116791
[20/24] Train loss=0.34327432513237
Test set avg_accuracy=85.96% avg_sensitivity=47.05%, avg_specificity=97.25% avg_auc=90.20%
Best model saved!! Metric=-5.550026823468777!!
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.361128 Test loss=0.324535 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.33543840050697327
[5/24] Train loss=0.36870861053466797
[10/24] Train loss=0.37100088596343994
[15/24] Train loss=0.346243292093277
[20/24] Train loss=0.3406568169593811
Test set avg_accuracy=85.61% avg_sensitivity=44.26%, avg_specificity=97.60% avg_auc=90.19%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.357983 Test loss=0.325611 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.33530211448669434
[5/24] Train loss=0.36860060691833496
[10/24] Train loss=0.36787277460098267
[15/24] Train loss=0.3440501093864441
[20/24] Train loss=0.34289807081222534
Test set avg_accuracy=85.34% avg_sensitivity=40.79%, avg_specificity=98.25% avg_auc=90.20%
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.358397 Test loss=0.331882 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3444114029407501
[5/24] Train loss=0.37322312593460083
[10/24] Train loss=0.36816421151161194
[15/24] Train loss=0.3454093039035797
[20/24] Train loss=0.3370916545391083
Test set avg_accuracy=85.39% avg_sensitivity=42.29%, avg_specificity=97.88% avg_auc=90.17%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.358290 Test loss=0.328241 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.33821114897727966
[5/24] Train loss=0.3733263313770294
[10/24] Train loss=0.3663630485534668
[15/24] Train loss=0.3435877561569214
[20/24] Train loss=0.3360317349433899
Test set avg_accuracy=85.22% avg_sensitivity=40.27%, avg_specificity=98.25% avg_auc=90.22%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.357577 Test loss=0.330123 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.33707112073898315
[5/24] Train loss=0.3716563880443573
[10/24] Train loss=0.36467909812927246
[15/24] Train loss=0.3443703055381775
[20/24] Train loss=0.339649498462677
Test set avg_accuracy=85.22% avg_sensitivity=40.21%, avg_specificity=98.27% avg_auc=90.19%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.357792 Test loss=0.329330 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.33922260999679565
[5/24] Train loss=0.3727376461029053
[10/24] Train loss=0.3629637062549591
[15/24] Train loss=0.34341225028038025
[20/24] Train loss=0.34062960743904114
Test set avg_accuracy=85.35% avg_sensitivity=40.27%, avg_specificity=98.42% avg_auc=90.23%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.357014 Test loss=0.329365 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.33883753418922424
[5/24] Train loss=0.3718287944793701
[10/24] Train loss=0.3657797574996948
[15/24] Train loss=0.34011873602867126
[20/24] Train loss=0.32942619919776917
Test set avg_accuracy=85.23% avg_sensitivity=39.51%, avg_specificity=98.49% avg_auc=90.18%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.356646 Test loss=0.330902 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.33448776602745056
[5/24] Train loss=0.3780805766582489
[10/24] Train loss=0.3635704815387726
[15/24] Train loss=0.34669700264930725
[20/24] Train loss=0.330523818731308
Test set avg_accuracy=85.10% avg_sensitivity=39.28%, avg_specificity=98.39% avg_auc=90.26%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.356299 Test loss=0.330704 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3371838927268982
[5/24] Train loss=0.37203675508499146
[10/24] Train loss=0.36628639698028564
[15/24] Train loss=0.3473424017429352
[20/24] Train loss=0.3366004228591919
Test set avg_accuracy=85.33% avg_sensitivity=41.25%, avg_specificity=98.10% avg_auc=90.22%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.356642 Test loss=0.327779 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.33882224559783936
[5/24] Train loss=0.37948164343833923
[10/24] Train loss=0.36413562297821045
[15/24] Train loss=0.339164674282074
[20/24] Train loss=0.3337770104408264
Test set avg_accuracy=85.62% avg_sensitivity=42.35%, avg_specificity=98.17% avg_auc=90.32%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.356122 Test loss=0.327359 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.332040935754776
[5/24] Train loss=0.374624103307724
[10/24] Train loss=0.360427588224411
[15/24] Train loss=0.3472985625267029
[20/24] Train loss=0.3355998396873474
Test set avg_accuracy=85.49% avg_sensitivity=41.89%, avg_specificity=98.14% avg_auc=90.36%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.355357 Test loss=0.325782 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3367135524749756
[5/24] Train loss=0.3738057613372803
[10/24] Train loss=0.3606289327144623
[15/24] Train loss=0.34188157320022583
[20/24] Train loss=0.33522677421569824
Test set avg_accuracy=85.51% avg_sensitivity=42.53%, avg_specificity=97.97% avg_auc=90.37%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.355160 Test loss=0.325074 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3366488218307495
[5/24] Train loss=0.368419349193573
[10/24] Train loss=0.36272749304771423
[15/24] Train loss=0.344998300075531
[20/24] Train loss=0.3322792947292328
Test set avg_accuracy=85.49% avg_sensitivity=42.12%, avg_specificity=98.07% avg_auc=90.38%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.353853 Test loss=0.325720 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.33373600244522095
[5/24] Train loss=0.3666175305843353
[10/24] Train loss=0.36393648386001587
[15/24] Train loss=0.3396979570388794
[20/24] Train loss=0.3282035291194916
Test set avg_accuracy=85.42% avg_sensitivity=42.93%, avg_specificity=97.73% avg_auc=90.40%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.353417 Test loss=0.324385 Current lr=[0.000299720220882401]

[0/24] Train loss=0.33113062381744385
[5/24] Train loss=0.3720009922981262
[10/24] Train loss=0.3661973476409912
[15/24] Train loss=0.3410874605178833
[20/24] Train loss=0.33242490887641907
Test set avg_accuracy=85.49% avg_sensitivity=42.76%, avg_specificity=97.88% avg_auc=90.40%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.353817 Test loss=0.323806 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.32640886306762695
[5/24] Train loss=0.3680029511451721
[10/24] Train loss=0.360338419675827
[15/24] Train loss=0.3398538827896118
[20/24] Train loss=0.3348832130432129
Test set avg_accuracy=85.70% avg_sensitivity=45.37%, avg_specificity=97.40% avg_auc=90.45%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.352255 Test loss=0.320628 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3278760313987732
[5/24] Train loss=0.3686924874782562
[10/24] Train loss=0.3649410307407379
[15/24] Train loss=0.3421840965747833
[20/24] Train loss=0.33002594113349915
Test set avg_accuracy=85.34% avg_sensitivity=42.87%, avg_specificity=97.65% avg_auc=90.32%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.352558 Test loss=0.323836 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3285517692565918
[5/24] Train loss=0.3664722144603729
[10/24] Train loss=0.3617986738681793
[15/24] Train loss=0.3381770849227905
[20/24] Train loss=0.3305107355117798
Test set avg_accuracy=85.64% avg_sensitivity=42.82%, avg_specificity=98.05% avg_auc=90.41%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.351554 Test loss=0.324041 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3270469605922699
[5/24] Train loss=0.36865803599357605
[10/24] Train loss=0.3608867824077606
[15/24] Train loss=0.33506375551223755
[20/24] Train loss=0.33301842212677
Test set avg_accuracy=85.51% avg_sensitivity=43.34%, avg_specificity=97.73% avg_auc=90.37%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.353076 Test loss=0.323923 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.32897403836250305
[5/24] Train loss=0.37049633264541626
[10/24] Train loss=0.3623780310153961
[15/24] Train loss=0.3345159590244293
[20/24] Train loss=0.3304344117641449
Test set avg_accuracy=85.98% avg_sensitivity=46.41%, avg_specificity=97.45% avg_auc=90.45%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.352606 Test loss=0.320211 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3265956938266754
[5/24] Train loss=0.3661983013153076
[10/24] Train loss=0.36222150921821594
[15/24] Train loss=0.3390105068683624
[20/24] Train loss=0.3293500542640686
Test set avg_accuracy=85.81% avg_sensitivity=45.25%, avg_specificity=97.56% avg_auc=90.41%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.351694 Test loss=0.321275 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3285265862941742
[5/24] Train loss=0.36382099986076355
[10/24] Train loss=0.36134251952171326
[15/24] Train loss=0.3385655879974365
[20/24] Train loss=0.32616570591926575
Test set avg_accuracy=85.65% avg_sensitivity=43.80%, avg_specificity=97.78% avg_auc=90.42%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.350851 Test loss=0.322927 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.32633039355278015
[5/24] Train loss=0.36930930614471436
[10/24] Train loss=0.3626050651073456
[15/24] Train loss=0.3356472849845886
[20/24] Train loss=0.3293742537498474
Test set avg_accuracy=85.52% avg_sensitivity=42.70%, avg_specificity=97.93% avg_auc=90.42%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.351346 Test loss=0.323255 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.32612621784210205
[5/24] Train loss=0.3694608807563782
[10/24] Train loss=0.36440110206604004
[15/24] Train loss=0.33583736419677734
[20/24] Train loss=0.32883620262145996
Test set avg_accuracy=85.90% avg_sensitivity=45.08%, avg_specificity=97.73% avg_auc=90.42%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.351632 Test loss=0.322455 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.32854700088500977
[5/24] Train loss=0.3629342019557953
[10/24] Train loss=0.36374589800834656
[15/24] Train loss=0.3338571786880493
[20/24] Train loss=0.329513281583786
Test set avg_accuracy=85.69% avg_sensitivity=44.50%, avg_specificity=97.63% avg_auc=90.40%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.350293 Test loss=0.321934 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.328929603099823
[5/24] Train loss=0.36833828687667847
[10/24] Train loss=0.3606753647327423
[15/24] Train loss=0.337131142616272
[20/24] Train loss=0.3272250294685364
Test set avg_accuracy=85.78% avg_sensitivity=43.86%, avg_specificity=97.93% avg_auc=90.45%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.349750 Test loss=0.322777 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.326322466135025
[5/24] Train loss=0.3754723370075226
[10/24] Train loss=0.3590749204158783
[15/24] Train loss=0.3347986936569214
[20/24] Train loss=0.3243410289287567
Test set avg_accuracy=85.91% avg_sensitivity=46.12%, avg_specificity=97.45% avg_auc=90.41%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.351331 Test loss=0.321259 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3257055878639221
[5/24] Train loss=0.3674265444278717
[10/24] Train loss=0.3644460439682007
[15/24] Train loss=0.3332178592681885
[20/24] Train loss=0.327223539352417
Test set avg_accuracy=86.22% avg_sensitivity=47.28%, avg_specificity=97.51% avg_auc=90.43%
Best model saved!! Metric=-4.554114267304016!!
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.350379 Test loss=0.319759 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.32354941964149475
[5/24] Train loss=0.36755046248435974
[10/24] Train loss=0.3642851412296295
[15/24] Train loss=0.3377652168273926
[20/24] Train loss=0.3297107517719269
Test set avg_accuracy=85.99% avg_sensitivity=46.64%, avg_specificity=97.40% avg_auc=90.37%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.349581 Test loss=0.321722 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3222942054271698
[5/24] Train loss=0.3655877411365509
[10/24] Train loss=0.35997629165649414
[15/24] Train loss=0.3349505364894867
[20/24] Train loss=0.3311079740524292
Test set avg_accuracy=86.11% avg_sensitivity=46.70%, avg_specificity=97.53% avg_auc=90.49%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.350515 Test loss=0.320455 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.32460907101631165
[5/24] Train loss=0.3704893887042999
[10/24] Train loss=0.35887816548347473
[15/24] Train loss=0.33408910036087036
[20/24] Train loss=0.3280051052570343
Test set avg_accuracy=86.18% avg_sensitivity=46.23%, avg_specificity=97.77% avg_auc=90.49%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.349623 Test loss=0.320672 Current lr=[0.000276307469034998]

[0/24] Train loss=0.32469263672828674
[5/24] Train loss=0.3684847354888916
[10/24] Train loss=0.3556070625782013
[15/24] Train loss=0.33015239238739014
[20/24] Train loss=0.3256683647632599
Test set avg_accuracy=86.39% avg_sensitivity=48.44%, avg_specificity=97.40% avg_auc=90.46%
Best model saved!! Metric=-3.3165527807548827!!
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.350478 Test loss=0.319477 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3206922113895416
[5/24] Train loss=0.3658987283706665
[10/24] Train loss=0.35962677001953125
[15/24] Train loss=0.3297711908817291
[20/24] Train loss=0.3273647129535675
Test set avg_accuracy=86.29% avg_sensitivity=47.68%, avg_specificity=97.48% avg_auc=90.37%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.349702 Test loss=0.322193 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3277031183242798
[5/24] Train loss=0.3692224621772766
[10/24] Train loss=0.3580218255519867
[15/24] Train loss=0.3310732841491699
[20/24] Train loss=0.3282315731048584
Test set avg_accuracy=86.04% avg_sensitivity=44.61%, avg_specificity=98.05% avg_auc=90.41%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.350093 Test loss=0.323453 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.32430288195610046
[5/24] Train loss=0.37504446506500244
[10/24] Train loss=0.3567761778831482
[15/24] Train loss=0.3302823007106781
[20/24] Train loss=0.3299066126346588
Test set avg_accuracy=86.05% avg_sensitivity=44.96%, avg_specificity=97.97% avg_auc=90.32%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.351572 Test loss=0.325709 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.32298389077186584
[5/24] Train loss=0.37602999806404114
[10/24] Train loss=0.3582518994808197
[15/24] Train loss=0.335949182510376
[20/24] Train loss=0.3374563455581665
Test set avg_accuracy=84.91% avg_sensitivity=38.30%, avg_specificity=98.42% avg_auc=90.10%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.353003 Test loss=0.336412 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3380949795246124
[5/24] Train loss=0.37224170565605164
[10/24] Train loss=0.3680036664009094
[15/24] Train loss=0.33762431144714355
[20/24] Train loss=0.32828378677368164
Test set avg_accuracy=84.91% avg_sensitivity=38.18%, avg_specificity=98.45% avg_auc=90.18%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.352723 Test loss=0.332940 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.33420854806900024
[5/24] Train loss=0.35931557416915894
[10/24] Train loss=0.3671259880065918
[15/24] Train loss=0.33107954263687134
[20/24] Train loss=0.3281215727329254
Test set avg_accuracy=85.29% avg_sensitivity=39.80%, avg_specificity=98.47% avg_auc=90.33%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.349830 Test loss=0.328739 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3265072703361511
[5/24] Train loss=0.3591517508029938
[10/24] Train loss=0.3660185635089874
[15/24] Train loss=0.3275143504142761
[20/24] Train loss=0.3253629207611084
Test set avg_accuracy=85.43% avg_sensitivity=40.90%, avg_specificity=98.34% avg_auc=90.31%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.348813 Test loss=0.328919 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3291516900062561
[5/24] Train loss=0.36693429946899414
[10/24] Train loss=0.36495938897132874
[15/24] Train loss=0.3317989408969879
[20/24] Train loss=0.32582563161849976
Test set avg_accuracy=85.51% avg_sensitivity=41.02%, avg_specificity=98.40% avg_auc=90.38%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.349112 Test loss=0.327676 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3253095746040344
[5/24] Train loss=0.36087316274642944
[10/24] Train loss=0.3638204336166382
[15/24] Train loss=0.32851144671440125
[20/24] Train loss=0.325571209192276
Test set avg_accuracy=85.33% avg_sensitivity=40.50%, avg_specificity=98.32% avg_auc=90.23%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.349557 Test loss=0.330088 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3303358852863312
[5/24] Train loss=0.358989417552948
[10/24] Train loss=0.36845171451568604
[15/24] Train loss=0.32513052225112915
[20/24] Train loss=0.32306233048439026
Test set avg_accuracy=85.69% avg_sensitivity=43.05%, avg_specificity=98.05% avg_auc=90.30%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.348661 Test loss=0.327164 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.32508814334869385
[5/24] Train loss=0.36441051959991455
[10/24] Train loss=0.36527639627456665
[15/24] Train loss=0.3272140622138977
[20/24] Train loss=0.32631927728652954
Test set avg_accuracy=85.47% avg_sensitivity=41.54%, avg_specificity=98.20% avg_auc=90.30%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.349313 Test loss=0.328783 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.32568520307540894
[5/24] Train loss=0.35790467262268066
[10/24] Train loss=0.3726692497730255
[15/24] Train loss=0.3325141370296478
[20/24] Train loss=0.32389336824417114
Test set avg_accuracy=85.73% avg_sensitivity=43.40%, avg_specificity=98.00% avg_auc=90.31%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.348786 Test loss=0.326838 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3277997374534607
[5/24] Train loss=0.35786280035972595
[10/24] Train loss=0.3688981831073761
[15/24] Train loss=0.3322080969810486
[20/24] Train loss=0.32259562611579895
Test set avg_accuracy=85.87% avg_sensitivity=44.21%, avg_specificity=97.95% avg_auc=90.34%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.348438 Test loss=0.325908 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.32734471559524536
[5/24] Train loss=0.35384833812713623
[10/24] Train loss=0.371652752161026
[15/24] Train loss=0.32924938201904297
[20/24] Train loss=0.3217221796512604
Test set avg_accuracy=85.99% avg_sensitivity=45.37%, avg_specificity=97.77% avg_auc=90.34%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.349257 Test loss=0.323631 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3253658413887024
[5/24] Train loss=0.3559068739414215
[10/24] Train loss=0.36363935470581055
[15/24] Train loss=0.3321038782596588
[20/24] Train loss=0.3282720148563385
Test set avg_accuracy=85.74% avg_sensitivity=43.63%, avg_specificity=97.95% avg_auc=90.27%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.347380 Test loss=0.326776 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3254506587982178
[5/24] Train loss=0.3536171019077301
[10/24] Train loss=0.36722612380981445
[15/24] Train loss=0.3295750617980957
[20/24] Train loss=0.3248463571071625
Test set avg_accuracy=85.79% avg_sensitivity=44.73%, avg_specificity=97.70% avg_auc=90.32%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.348763 Test loss=0.324774 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3284103572368622
[5/24] Train loss=0.3578544855117798
[10/24] Train loss=0.3680035471916199
[15/24] Train loss=0.3270151913166046
[20/24] Train loss=0.3242075443267822
Test set avg_accuracy=86.11% avg_sensitivity=47.10%, avg_specificity=97.41% avg_auc=90.33%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.347267 Test loss=0.321270 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3204454481601715
[5/24] Train loss=0.3552649915218353
[10/24] Train loss=0.36109086871147156
[15/24] Train loss=0.32946860790252686
[20/24] Train loss=0.3173358738422394
Test set avg_accuracy=85.72% avg_sensitivity=44.38%, avg_specificity=97.70% avg_auc=90.19%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.346373 Test loss=0.326383 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3231007158756256
[5/24] Train loss=0.35719937086105347
[10/24] Train loss=0.36326637864112854
[15/24] Train loss=0.3229370415210724
[20/24] Train loss=0.32382968068122864
Test set avg_accuracy=85.85% avg_sensitivity=44.50%, avg_specificity=97.83% avg_auc=90.31%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.347101 Test loss=0.324266 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.32408398389816284
[5/24] Train loss=0.3528251051902771
[10/24] Train loss=0.3654504716396332
[15/24] Train loss=0.3302745223045349
[20/24] Train loss=0.3223985731601715
Test set avg_accuracy=86.05% avg_sensitivity=46.52%, avg_specificity=97.51% avg_auc=90.23%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.347727 Test loss=0.322425 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.32156094908714294
[5/24] Train loss=0.3564993441104889
[10/24] Train loss=0.361763596534729
[15/24] Train loss=0.3284047245979309
[20/24] Train loss=0.3244841396808624
Test set avg_accuracy=85.85% avg_sensitivity=45.02%, avg_specificity=97.68% avg_auc=90.30%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.346285 Test loss=0.324528 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.32428988814353943
[5/24] Train loss=0.3607219159603119
[10/24] Train loss=0.3663159906864166
[15/24] Train loss=0.33042216300964355
[20/24] Train loss=0.32304614782333374
Test set avg_accuracy=85.82% avg_sensitivity=45.13%, avg_specificity=97.62% avg_auc=90.19%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.348194 Test loss=0.326062 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3297880291938782
[5/24] Train loss=0.3580424189567566
[10/24] Train loss=0.3657474219799042
[15/24] Train loss=0.33104968070983887
[20/24] Train loss=0.32293644547462463
Test set avg_accuracy=85.90% avg_sensitivity=45.31%, avg_specificity=97.67% avg_auc=90.13%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.347865 Test loss=0.327694 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.32558774948120117
[5/24] Train loss=0.35075411200523376
[10/24] Train loss=0.3646497428417206
[15/24] Train loss=0.33757483959198
[20/24] Train loss=0.32182830572128296
Test set avg_accuracy=85.90% avg_sensitivity=44.73%, avg_specificity=97.83% avg_auc=90.12%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.347343 Test loss=0.329114 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3275924324989319
[5/24] Train loss=0.35647857189178467
[10/24] Train loss=0.36915093660354614
[15/24] Train loss=0.33017781376838684
[20/24] Train loss=0.32248455286026
Test set avg_accuracy=85.70% avg_sensitivity=44.32%, avg_specificity=97.70% avg_auc=90.00%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.348184 Test loss=0.331246 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3267214596271515
[5/24] Train loss=0.34806588292121887
[10/24] Train loss=0.3624539375305176
[15/24] Train loss=0.3276270627975464
[20/24] Train loss=0.3233872354030609
Test set avg_accuracy=85.83% avg_sensitivity=45.25%, avg_specificity=97.60% avg_auc=90.17%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.348066 Test loss=0.326420 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3210395276546478
[5/24] Train loss=0.346367210149765
[10/24] Train loss=0.3599991798400879
[15/24] Train loss=0.32589349150657654
[20/24] Train loss=0.32056060433387756
Test set avg_accuracy=85.72% avg_sensitivity=44.03%, avg_specificity=97.80% avg_auc=90.13%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.347557 Test loss=0.329445 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3257637619972229
[5/24] Train loss=0.35073214769363403
[10/24] Train loss=0.3637574017047882
[15/24] Train loss=0.3265204429626465
[20/24] Train loss=0.3197877109050751
Test set avg_accuracy=85.94% avg_sensitivity=45.77%, avg_specificity=97.58% avg_auc=90.24%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.348442 Test loss=0.324598 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3235843777656555
[5/24] Train loss=0.3480726480484009
[10/24] Train loss=0.3630448877811432
[15/24] Train loss=0.32989585399627686
[20/24] Train loss=0.31952574849128723
Test set avg_accuracy=86.25% avg_sensitivity=50.23%, avg_specificity=96.69% avg_auc=90.25%
Best model saved!! Metric=-2.576051290873906!!
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.348949 Test loss=0.319510 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.317070871591568
[5/24] Train loss=0.34877321124076843
[10/24] Train loss=0.3569645881652832
[15/24] Train loss=0.33359330892562866
[20/24] Train loss=0.3194960355758667
Test set avg_accuracy=86.77% avg_sensitivity=54.58%, avg_specificity=96.10% avg_auc=90.32%
Best model saved!! Metric=1.768005161692173!!
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.348624 Test loss=0.316438 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.314467191696167
[5/24] Train loss=0.34662821888923645
[10/24] Train loss=0.3564448356628418
[15/24] Train loss=0.33101561665534973
[20/24] Train loss=0.3217490017414093
Test set avg_accuracy=86.78% avg_sensitivity=56.26%, avg_specificity=95.63% avg_auc=90.32%
Best model saved!! Metric=2.993663944293594!!
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.346512 Test loss=0.315650 Current lr=[0.000156543481933168]

[0/24] Train loss=0.31639134883880615
[5/24] Train loss=0.34930306673049927
[10/24] Train loss=0.36071324348449707
[15/24] Train loss=0.3303285539150238
[20/24] Train loss=0.32303768396377563
Test set avg_accuracy=86.90% avg_sensitivity=56.08%, avg_specificity=95.83% avg_auc=90.30%
Best model saved!! Metric=3.117332184429152!!
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.346154 Test loss=0.316203 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3115634322166443
[5/24] Train loss=0.3569274842739105
[10/24] Train loss=0.3619447946548462
[15/24] Train loss=0.32510504126548767
[20/24] Train loss=0.32133427262306213
Test set avg_accuracy=86.85% avg_sensitivity=55.62%, avg_specificity=95.90% avg_auc=90.29%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.346103 Test loss=0.316288 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.31289413571357727
[5/24] Train loss=0.35167983174324036
[10/24] Train loss=0.3632628321647644
[15/24] Train loss=0.3252868950366974
[20/24] Train loss=0.3214911222457886
Test set avg_accuracy=86.84% avg_sensitivity=56.26%, avg_specificity=95.70% avg_auc=90.32%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.346222 Test loss=0.315569 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3151439130306244
[5/24] Train loss=0.35255083441734314
[10/24] Train loss=0.36323949694633484
[15/24] Train loss=0.3284209072589874
[20/24] Train loss=0.32447075843811035
Test set avg_accuracy=86.91% avg_sensitivity=56.37%, avg_specificity=95.77% avg_auc=90.38%
Best model saved!! Metric=3.4299364209956735!!
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.346518 Test loss=0.314677 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.31537383794784546
[5/24] Train loss=0.35264840722084045
[10/24] Train loss=0.36468011140823364
[15/24] Train loss=0.32486921548843384
[20/24] Train loss=0.31998857855796814
Test set avg_accuracy=86.91% avg_sensitivity=56.08%, avg_specificity=95.85% avg_auc=90.35%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.345210 Test loss=0.315261 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3119514286518097
[5/24] Train loss=0.3509535789489746
[10/24] Train loss=0.3569764494895935
[15/24] Train loss=0.3249931335449219
[20/24] Train loss=0.3231862485408783
Test set avg_accuracy=86.68% avg_sensitivity=56.55%, avg_specificity=95.41% avg_auc=90.34%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.345041 Test loss=0.314908 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.31847554445266724
[5/24] Train loss=0.35069867968559265
[10/24] Train loss=0.36284956336021423
[15/24] Train loss=0.32576215267181396
[20/24] Train loss=0.3244732916355133
Test set avg_accuracy=86.90% avg_sensitivity=56.43%, avg_specificity=95.73% avg_auc=90.38%
Best model saved!! Metric=3.446147034159651!!
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.345829 Test loss=0.314600 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3170037865638733
[5/24] Train loss=0.35076847672462463
[10/24] Train loss=0.3629799783229828
[15/24] Train loss=0.3298446536064148
[20/24] Train loss=0.31672194600105286
Test set avg_accuracy=86.97% avg_sensitivity=56.84%, avg_specificity=95.70% avg_auc=90.45%
Best model saved!! Metric=3.9564906982322725!!
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.346258 Test loss=0.313176 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.31622302532196045
[5/24] Train loss=0.3505633473396301
[10/24] Train loss=0.36191102862358093
[15/24] Train loss=0.3301461338996887
[20/24] Train loss=0.3209666609764099
Test set avg_accuracy=86.77% avg_sensitivity=56.20%, avg_specificity=95.63% avg_auc=90.41%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.345711 Test loss=0.313398 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.31587907671928406
[5/24] Train loss=0.3545103371143341
[10/24] Train loss=0.36143970489501953
[15/24] Train loss=0.3310824930667877
[20/24] Train loss=0.3263237774372101
Test set avg_accuracy=86.73% avg_sensitivity=57.24%, avg_specificity=95.28% avg_auc=90.37%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.346042 Test loss=0.313725 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.31756535172462463
[5/24] Train loss=0.3590152859687805
[10/24] Train loss=0.3691564202308655
[15/24] Train loss=0.3269031047821045
[20/24] Train loss=0.3199903070926666
Test set avg_accuracy=86.82% avg_sensitivity=57.71%, avg_specificity=95.26% avg_auc=90.44%
Best model saved!! Metric=4.236431481482917!!
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.346725 Test loss=0.312767 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.31469500064849854
[5/24] Train loss=0.3630085289478302
[10/24] Train loss=0.373873770236969
[15/24] Train loss=0.3264724612236023
[20/24] Train loss=0.32104912400245667
Test set avg_accuracy=86.90% avg_sensitivity=59.62%, avg_specificity=94.81% avg_auc=90.50%
Best model saved!! Metric=5.830061992836676!!
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.347013 Test loss=0.312712 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.31414225697517395
[5/24] Train loss=0.3686601221561432
[10/24] Train loss=0.379965215921402
[15/24] Train loss=0.3319270610809326
[20/24] Train loss=0.3214269280433655
Test set avg_accuracy=86.77% avg_sensitivity=64.54%, avg_specificity=93.21% avg_auc=90.53%
Best model saved!! Metric=9.053539371242337!!
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.349272 Test loss=0.316103 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.31956037878990173
[5/24] Train loss=0.3697277903556824
[10/24] Train loss=0.38484981656074524
[15/24] Train loss=0.32623594999313354
[20/24] Train loss=0.3243435025215149
Test set avg_accuracy=86.03% avg_sensitivity=68.83%, avg_specificity=91.01% avg_auc=90.33%
Best model saved!! Metric=10.206593723511858!!
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.350260 Test loss=0.325295 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3300442695617676
[5/24] Train loss=0.3751421868801117
[10/24] Train loss=0.37278392910957336
[15/24] Train loss=0.3304634392261505
[20/24] Train loss=0.3469593822956085
Test set avg_accuracy=86.65% avg_sensitivity=64.95%, avg_specificity=92.95% avg_auc=90.45%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.352553 Test loss=0.317829 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.320801317691803
[5/24] Train loss=0.35491621494293213
[10/24] Train loss=0.3632274270057678
[15/24] Train loss=0.33200252056121826
[20/24] Train loss=0.3337826728820801
Test set avg_accuracy=86.85% avg_sensitivity=58.52%, avg_specificity=95.06% avg_auc=90.49%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.347547 Test loss=0.313352 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.31093916296958923
[5/24] Train loss=0.3543527126312256
[10/24] Train loss=0.361270546913147
[15/24] Train loss=0.3307792842388153
[20/24] Train loss=0.3312889337539673
Test set avg_accuracy=86.84% avg_sensitivity=60.25%, avg_specificity=94.54% avg_auc=90.55%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.344585 Test loss=0.313862 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3141891658306122
[5/24] Train loss=0.34933581948280334
[10/24] Train loss=0.363433837890625
[15/24] Train loss=0.33075952529907227
[20/24] Train loss=0.33323419094085693
Test set avg_accuracy=86.98% avg_sensitivity=60.25%, avg_specificity=94.73% avg_auc=90.54%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.346020 Test loss=0.313683 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.31841737031936646
[5/24] Train loss=0.3522259593009949
[10/24] Train loss=0.36024221777915955
[15/24] Train loss=0.32852593064308167
[20/24] Train loss=0.3284362852573395
Test set avg_accuracy=86.94% avg_sensitivity=59.04%, avg_specificity=95.03% avg_auc=90.55%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.345121 Test loss=0.313132 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.31414154171943665
[5/24] Train loss=0.35580840706825256
[10/24] Train loss=0.3618225157260895
[15/24] Train loss=0.3277040719985962
[20/24] Train loss=0.3283461332321167
Test set avg_accuracy=86.99% avg_sensitivity=60.08%, avg_specificity=94.79% avg_auc=90.55%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.344166 Test loss=0.313286 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3148757517337799
[5/24] Train loss=0.35562223196029663
[10/24] Train loss=0.36384710669517517
[15/24] Train loss=0.3314802944660187
[20/24] Train loss=0.32838669419288635
Test set avg_accuracy=86.95% avg_sensitivity=58.98%, avg_specificity=95.06% avg_auc=90.48%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.345940 Test loss=0.314001 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3172290027141571
[5/24] Train loss=0.35679304599761963
[10/24] Train loss=0.36064982414245605
[15/24] Train loss=0.32891350984573364
[20/24] Train loss=0.3299442529678345
Test set avg_accuracy=87.03% avg_sensitivity=59.91%, avg_specificity=94.89% avg_auc=90.47%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.344696 Test loss=0.314495 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3181305229663849
[5/24] Train loss=0.3606702387332916
[10/24] Train loss=0.36242029070854187
[15/24] Train loss=0.3281362056732178
[20/24] Train loss=0.33352160453796387
Test set avg_accuracy=86.93% avg_sensitivity=59.04%, avg_specificity=95.01% avg_auc=90.48%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.345815 Test loss=0.313912 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.31490272283554077
[5/24] Train loss=0.35824909806251526
[10/24] Train loss=0.3585980236530304
[15/24] Train loss=0.32930517196655273
[20/24] Train loss=0.327452689409256
Test set avg_accuracy=86.97% avg_sensitivity=58.98%, avg_specificity=95.08% avg_auc=90.56%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.344089 Test loss=0.312493 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3125889003276825
[5/24] Train loss=0.3490806818008423
[10/24] Train loss=0.35622432827949524
[15/24] Train loss=0.33340030908584595
[20/24] Train loss=0.32451024651527405
Test set avg_accuracy=86.98% avg_sensitivity=57.01%, avg_specificity=95.67% avg_auc=90.57%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.343153 Test loss=0.312214 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.3145267069339752
[5/24] Train loss=0.34983643889427185
[10/24] Train loss=0.3584662973880768
[15/24] Train loss=0.32920172810554504
[20/24] Train loss=0.33191314339637756
Test set avg_accuracy=86.93% avg_sensitivity=57.65%, avg_specificity=95.41% avg_auc=90.58%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.342809 Test loss=0.311855 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.31680694222450256
[5/24] Train loss=0.3518998324871063
[10/24] Train loss=0.35917481780052185
[15/24] Train loss=0.3256220817565918
[20/24] Train loss=0.32012689113616943
Test set avg_accuracy=86.88% avg_sensitivity=56.95%, avg_specificity=95.55% avg_auc=90.57%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.342036 Test loss=0.311863 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3129812479019165
[5/24] Train loss=0.3481864035129547
[10/24] Train loss=0.35797902941703796
[15/24] Train loss=0.3264426589012146
[20/24] Train loss=0.3270432949066162
Test set avg_accuracy=87.03% avg_sensitivity=56.84%, avg_specificity=95.78% avg_auc=90.60%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.341611 Test loss=0.311620 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.31100860238075256
[5/24] Train loss=0.3492110073566437
[10/24] Train loss=0.358029305934906
[15/24] Train loss=0.33344340324401855
[20/24] Train loss=0.32794469594955444
Test set avg_accuracy=87.07% avg_sensitivity=56.37%, avg_specificity=95.97% avg_auc=90.59%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.342197 Test loss=0.311914 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.31338751316070557
[5/24] Train loss=0.3536129295825958
[10/24] Train loss=0.3583229184150696
[15/24] Train loss=0.32852479815483093
[20/24] Train loss=0.32626616954803467
Test set avg_accuracy=87.02% avg_sensitivity=55.97%, avg_specificity=96.02% avg_auc=90.61%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.341421 Test loss=0.311760 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.31173935532569885
[5/24] Train loss=0.35351473093032837
[10/24] Train loss=0.3607366979122162
[15/24] Train loss=0.330228328704834
[20/24] Train loss=0.32461637258529663
Test set avg_accuracy=87.04% avg_sensitivity=56.08%, avg_specificity=96.02% avg_auc=90.61%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.342347 Test loss=0.311847 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.31091800332069397
[5/24] Train loss=0.3495289087295532
[10/24] Train loss=0.3568984568119049
[15/24] Train loss=0.3305571973323822
[20/24] Train loss=0.32408541440963745
Test set avg_accuracy=86.90% avg_sensitivity=55.21%, avg_specificity=96.09% avg_auc=90.59%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.341426 Test loss=0.312191 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3094920217990875
[5/24] Train loss=0.35623425245285034
[10/24] Train loss=0.35794597864151
[15/24] Train loss=0.3339831829071045
[20/24] Train loss=0.32478830218315125
Test set avg_accuracy=86.81% avg_sensitivity=54.29%, avg_specificity=96.24% avg_auc=90.61%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.341457 Test loss=0.312287 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.31578534841537476
[5/24] Train loss=0.3523635268211365
[10/24] Train loss=0.3594033718109131
[15/24] Train loss=0.32887008786201477
[20/24] Train loss=0.3234623670578003
Test set avg_accuracy=86.73% avg_sensitivity=53.53%, avg_specificity=96.36% avg_auc=90.60%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.341219 Test loss=0.312465 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3108743131160736
[5/24] Train loss=0.3547617197036743
[10/24] Train loss=0.35841599106788635
[15/24] Train loss=0.3318510949611664
[20/24] Train loss=0.32161596417427063
Test set avg_accuracy=86.88% avg_sensitivity=53.94%, avg_specificity=96.42% avg_auc=90.60%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.342022 Test loss=0.312579 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3098711371421814
[5/24] Train loss=0.35023611783981323
[10/24] Train loss=0.35832661390304565
[15/24] Train loss=0.3325830399990082
[20/24] Train loss=0.31801658868789673
Test set avg_accuracy=86.93% avg_sensitivity=55.21%, avg_specificity=96.12% avg_auc=90.61%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.340816 Test loss=0.311885 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3112725615501404
[5/24] Train loss=0.3537338078022003
[10/24] Train loss=0.3568876087665558
[15/24] Train loss=0.3304312527179718
[20/24] Train loss=0.31755977869033813
Test set avg_accuracy=86.97% avg_sensitivity=56.72%, avg_specificity=95.73% avg_auc=90.65%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.341754 Test loss=0.310805 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.31005915999412537
[5/24] Train loss=0.35805851221084595
[10/24] Train loss=0.35631608963012695
[15/24] Train loss=0.32622990012168884
[20/24] Train loss=0.31662479043006897
Test set avg_accuracy=87.11% avg_sensitivity=58.92%, avg_specificity=95.28% avg_auc=90.67%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.342051 Test loss=0.310639 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.3162064254283905
[5/24] Train loss=0.35458582639694214
[10/24] Train loss=0.3578568398952484
[15/24] Train loss=0.3274911344051361
[20/24] Train loss=0.3167385160923004
Test set avg_accuracy=87.02% avg_sensitivity=59.15%, avg_specificity=95.10% avg_auc=90.68%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.341800 Test loss=0.310587 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.3113919496536255
[5/24] Train loss=0.34916719794273376
[10/24] Train loss=0.3499510586261749
[15/24] Train loss=0.32674428820610046
[20/24] Train loss=0.3177260458469391
Test set avg_accuracy=87.12% avg_sensitivity=59.04%, avg_specificity=95.26% avg_auc=90.68%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.340927 Test loss=0.310497 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3146132230758667
[5/24] Train loss=0.35144177079200745
[10/24] Train loss=0.35059064626693726
[15/24] Train loss=0.32502493262290955
[20/24] Train loss=0.31919699907302856
Test set avg_accuracy=87.02% avg_sensitivity=58.05%, avg_specificity=95.41% avg_auc=90.69%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.341269 Test loss=0.310338 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.31352540850639343
[5/24] Train loss=0.3474336862564087
[10/24] Train loss=0.35613495111465454
[15/24] Train loss=0.3249010443687439
[20/24] Train loss=0.3216456174850464
Test set avg_accuracy=87.04% avg_sensitivity=58.23%, avg_specificity=95.40% avg_auc=90.69%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.339961 Test loss=0.310180 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.31182214617729187
[5/24] Train loss=0.3497621715068817
[10/24] Train loss=0.3563254773616791
[15/24] Train loss=0.3224811255931854
[20/24] Train loss=0.31817883253097534
Test set avg_accuracy=87.04% avg_sensitivity=58.00%, avg_specificity=95.47% avg_auc=90.68%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.339885 Test loss=0.310340 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.311480849981308
[5/24] Train loss=0.3483710289001465
[10/24] Train loss=0.3550669848918915
[15/24] Train loss=0.3249749541282654
[20/24] Train loss=0.3171352446079254
Test set avg_accuracy=87.01% avg_sensitivity=57.59%, avg_specificity=95.53% avg_auc=90.68%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.340064 Test loss=0.310316 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3123776316642761
[5/24] Train loss=0.3461254835128784
[10/24] Train loss=0.3526521325111389
[15/24] Train loss=0.32471299171447754
[20/24] Train loss=0.3203528821468353
Test set avg_accuracy=87.02% avg_sensitivity=57.76%, avg_specificity=95.50% avg_auc=90.69%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.339559 Test loss=0.310262 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3115088939666748
[5/24] Train loss=0.34355130791664124
[10/24] Train loss=0.3568407893180847
[15/24] Train loss=0.3269381523132324
[20/24] Train loss=0.31523293256759644
Test set avg_accuracy=87.01% avg_sensitivity=57.59%, avg_specificity=95.53% avg_auc=90.68%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.339013 Test loss=0.310310 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.3130176365375519
[5/24] Train loss=0.3501189351081848
[10/24] Train loss=0.35391783714294434
[15/24] Train loss=0.32611915469169617
[20/24] Train loss=0.3195963203907013
Test set avg_accuracy=87.03% avg_sensitivity=57.53%, avg_specificity=95.58% avg_auc=90.68%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.340131 Test loss=0.310311 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.31043970584869385
[5/24] Train loss=0.3490930199623108
[10/24] Train loss=0.35378190875053406
[15/24] Train loss=0.32441750168800354
[20/24] Train loss=0.31977221369743347
Test set avg_accuracy=87.03% avg_sensitivity=57.59%, avg_specificity=95.57% avg_auc=90.68%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.339762 Test loss=0.310326 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3121386468410492
[5/24] Train loss=0.3434711992740631
[10/24] Train loss=0.35283204913139343
[15/24] Train loss=0.3202151954174042
[20/24] Train loss=0.3178715407848358
Test set avg_accuracy=87.01% avg_sensitivity=57.30%, avg_specificity=95.62% avg_auc=90.68%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.339263 Test loss=0.310309 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3092381954193115
[5/24] Train loss=0.35300517082214355
[10/24] Train loss=0.3567744791507721
[15/24] Train loss=0.32698214054107666
[20/24] Train loss=0.3183978497982025
Test set avg_accuracy=87.01% avg_sensitivity=57.30%, avg_specificity=95.62% avg_auc=90.68%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.340083 Test loss=0.310316 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.3118418753147125
[5/24] Train loss=0.3492529094219208
[10/24] Train loss=0.35850754380226135
[15/24] Train loss=0.32264426350593567
[20/24] Train loss=0.31929102540016174
Test set avg_accuracy=87.01% avg_sensitivity=57.30%, avg_specificity=95.62% avg_auc=90.68%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.339412 Test loss=0.310316 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.30800196528434753
[5/24] Train loss=0.3492531180381775
[10/24] Train loss=0.3566119074821472
[15/24] Train loss=0.32472389936447144
[20/24] Train loss=0.31841543316841125
Test set avg_accuracy=87.01% avg_sensitivity=57.30%, avg_specificity=95.62% avg_auc=90.68%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.339689 Test loss=0.310316 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3146468698978424
[5/24] Train loss=0.3467680513858795
[10/24] Train loss=0.3546881675720215
[15/24] Train loss=0.3254704475402832
[20/24] Train loss=0.3178836405277252
Test set avg_accuracy=86.99% avg_sensitivity=57.24%, avg_specificity=95.62% avg_auc=90.68%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.338788 Test loss=0.310319 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.31409430503845215
[5/24] Train loss=0.349864661693573
[10/24] Train loss=0.35707682371139526
[15/24] Train loss=0.326747328042984
[20/24] Train loss=0.31403759121894836
Test set avg_accuracy=86.99% avg_sensitivity=57.24%, avg_specificity=95.62% avg_auc=90.68%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.339344 Test loss=0.310320 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=86.03% sen=68.83%, spe=91.01%, auc=90.33%!
Fold[10] Avg_overlap=0.63%(0.2690344612464783)
Final Avg Result: avg_acc=85.26%(1.1446827464465994) avg_sen=73.41% (2.3000792880471654) avg_spe=89.35% (1.7330730181859944) avg_auc=90.57% (1.223307666869598) avg_overlap=0.65% (0.021356646173082146)
