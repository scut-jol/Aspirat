/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/24] Train loss=0.7172818183898926
[5/24] Train loss=0.7180209159851074
[10/24] Train loss=0.7178442478179932
[15/24] Train loss=0.7029316425323486
[20/24] Train loss=0.6912841796875
Test set avg_accuracy=60.62% avg_sensitivity=46.51%, avg_specificity=65.67% avg_auc=58.72%
Best model saved!! Metric=-94.4732499622492!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.707227 Test loss=0.684610 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6906241178512573
[5/24] Train loss=0.6849963068962097
[10/24] Train loss=0.69298255443573
[15/24] Train loss=0.6694705486297607
[20/24] Train loss=0.6609243154525757
Test set avg_accuracy=63.92% avg_sensitivity=66.30%, avg_specificity=63.07% avg_auc=70.02%
Best model saved!! Metric=-62.692550317598325!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.678664 Test loss=0.638925 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.662529706954956
[5/24] Train loss=0.6555172204971313
[10/24] Train loss=0.6630271077156067
[15/24] Train loss=0.639291524887085
[20/24] Train loss=0.6348260641098022
Test set avg_accuracy=67.34% avg_sensitivity=72.84%, avg_specificity=65.38% avg_auc=75.20%
Best model saved!! Metric=-45.24199716318033!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.652269 Test loss=0.611408 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6296101212501526
[5/24] Train loss=0.6253708004951477
[10/24] Train loss=0.6330994963645935
[15/24] Train loss=0.6074740886688232
[20/24] Train loss=0.6009257435798645
Test set avg_accuracy=69.14% avg_sensitivity=76.69%, avg_specificity=66.44% avg_auc=78.65%
Best model saved!! Metric=-35.068690528530226!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.623327 Test loss=0.583254 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6011995077133179
[5/24] Train loss=0.5973351001739502
[10/24] Train loss=0.6082826852798462
[15/24] Train loss=0.5753611326217651
[20/24] Train loss=0.5748202204704285
Test set avg_accuracy=71.64% avg_sensitivity=79.71%, avg_specificity=68.76% avg_auc=81.30%
Best model saved!! Metric=-24.587123244073382!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.594840 Test loss=0.555542 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5727560520172119
[5/24] Train loss=0.5689288973808289
[10/24] Train loss=0.5781905055046082
[15/24] Train loss=0.5518568158149719
[20/24] Train loss=0.5487462282180786
Test set avg_accuracy=73.18% avg_sensitivity=81.05%, avg_specificity=70.37% avg_auc=83.17%
Best model saved!! Metric=-18.241779343670316!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.567038 Test loss=0.532281 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5439661741256714
[5/24] Train loss=0.5360361337661743
[10/24] Train loss=0.5535470843315125
[15/24] Train loss=0.5207313895225525
[20/24] Train loss=0.5167051553726196
Test set avg_accuracy=76.45% avg_sensitivity=79.76%, avg_specificity=75.26% avg_auc=84.97%
Best model saved!! Metric=-9.556931126932241!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.537150 Test loss=0.497811 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5100330114364624
[5/24] Train loss=0.5022382140159607
[10/24] Train loss=0.5250681042671204
[15/24] Train loss=0.488057404756546
[20/24] Train loss=0.482666552066803
Test set avg_accuracy=78.80% avg_sensitivity=79.17%, avg_specificity=78.67% avg_auc=86.70%
Best model saved!! Metric=-2.6544025016076063!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.506245 Test loss=0.465768 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.47036752104759216
[5/24] Train loss=0.47846701741218567
[10/24] Train loss=0.49197956919670105
[15/24] Train loss=0.46239379048347473
[20/24] Train loss=0.4534662365913391
Test set avg_accuracy=80.68% avg_sensitivity=79.32%, avg_specificity=81.16% avg_auc=88.29%
Best model saved!! Metric=3.4493883382389754!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.476004 Test loss=0.438026 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4466738700866699
[5/24] Train loss=0.44272515177726746
[10/24] Train loss=0.46388593316078186
[15/24] Train loss=0.4298146665096283
[20/24] Train loss=0.4171946942806244
Test set avg_accuracy=82.42% avg_sensitivity=80.31%, avg_specificity=83.18% avg_auc=89.51%
Best model saved!! Metric=9.42061005257878!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.446573 Test loss=0.415946 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4149356782436371
[5/24] Train loss=0.419114887714386
[10/24] Train loss=0.4416271448135376
[15/24] Train loss=0.4165392816066742
[20/24] Train loss=0.3965035378932953
Test set avg_accuracy=83.57% avg_sensitivity=79.76%, avg_specificity=84.93% avg_auc=90.45%
Best model saved!! Metric=12.702942815518497!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.421093 Test loss=0.392797 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.3868151605129242
[5/24] Train loss=0.3862103521823883
[10/24] Train loss=0.4118553102016449
[15/24] Train loss=0.3916086256504059
[20/24] Train loss=0.3677676320075989
Test set avg_accuracy=85.21% avg_sensitivity=77.29%, avg_specificity=88.04% avg_auc=90.99%
Best model saved!! Metric=15.51914176562829!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.396126 Test loss=0.366113 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.36340397596359253
[5/24] Train loss=0.3676958978176117
[10/24] Train loss=0.3907119333744049
[15/24] Train loss=0.3780481517314911
[20/24] Train loss=0.3511969745159149
Test set avg_accuracy=85.79% avg_sensitivity=72.84%, avg_specificity=90.42% avg_auc=91.23%
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.375728 Test loss=0.348503 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3424627482891083
[5/24] Train loss=0.34210169315338135
[10/24] Train loss=0.37465038895606995
[15/24] Train loss=0.35629791021347046
[20/24] Train loss=0.33268046379089355
Test set avg_accuracy=86.24% avg_sensitivity=70.46%, avg_specificity=91.87% avg_auc=91.41%
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.357187 Test loss=0.336190 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.32851552963256836
[5/24] Train loss=0.32802996039390564
[10/24] Train loss=0.3575248122215271
[15/24] Train loss=0.3432544767856598
[20/24] Train loss=0.31332558393478394
Test set avg_accuracy=86.65% avg_sensitivity=71.75%, avg_specificity=91.98% avg_auc=92.06%
Best model saved!! Metric=16.44099669138076!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.341911 Test loss=0.326853 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.31055012345314026
[5/24] Train loss=0.31404879689216614
[10/24] Train loss=0.3465220630168915
[15/24] Train loss=0.328059583902359
[20/24] Train loss=0.306172251701355
Test set avg_accuracy=86.61% avg_sensitivity=71.15%, avg_specificity=92.14% avg_auc=92.21%
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.327751 Test loss=0.320846 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3008466362953186
[5/24] Train loss=0.2990832030773163
[10/24] Train loss=0.34220853447914124
[15/24] Train loss=0.3255215585231781
[20/24] Train loss=0.2960003614425659
Test set avg_accuracy=86.90% avg_sensitivity=72.34%, avg_specificity=92.10% avg_auc=92.54%
Best model saved!! Metric=17.878612129973888!!
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.317915 Test loss=0.315260 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.2927454113960266
[5/24] Train loss=0.2953476011753082
[10/24] Train loss=0.3309975266456604
[15/24] Train loss=0.3142450451850891
[20/24] Train loss=0.29060664772987366
Test set avg_accuracy=87.32% avg_sensitivity=74.67%, avg_specificity=91.84% avg_auc=92.89%
Best model saved!! Metric=20.70730890391056!!
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.309277 Test loss=0.307690 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.28064435720443726
[5/24] Train loss=0.28658491373062134
[10/24] Train loss=0.317157119512558
[15/24] Train loss=0.3065720796585083
[20/24] Train loss=0.27822527289390564
Test set avg_accuracy=86.95% avg_sensitivity=70.66%, avg_specificity=92.77% avg_auc=92.88%
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.299903 Test loss=0.304324 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2721165418624878
[5/24] Train loss=0.2759256362915039
[10/24] Train loss=0.313545286655426
[15/24] Train loss=0.2958616018295288
[20/24] Train loss=0.2639888823032379
Test set avg_accuracy=87.40% avg_sensitivity=75.51%, avg_specificity=91.64% avg_auc=93.31%
Best model saved!! Metric=21.855296826698932!!
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.292254 Test loss=0.298393 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2591729760169983
[5/24] Train loss=0.26538974046707153
[10/24] Train loss=0.3055456876754761
[15/24] Train loss=0.28558120131492615
[20/24] Train loss=0.2596994936466217
Test set avg_accuracy=87.49% avg_sensitivity=69.67%, avg_specificity=93.85% avg_auc=93.30%
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.283081 Test loss=0.294019 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.25778427720069885
[5/24] Train loss=0.2542925775051117
[10/24] Train loss=0.29961085319519043
[15/24] Train loss=0.27986642718315125
[20/24] Train loss=0.2526713013648987
Test set avg_accuracy=87.38% avg_sensitivity=74.47%, avg_specificity=92.00% avg_auc=93.37%
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.279094 Test loss=0.295213 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.25377926230430603
[5/24] Train loss=0.25017231702804565
[10/24] Train loss=0.3040386140346527
[15/24] Train loss=0.28127920627593994
[20/24] Train loss=0.249257892370224
Test set avg_accuracy=87.38% avg_sensitivity=75.36%, avg_specificity=91.68% avg_auc=93.53%
Best model saved!! Metric=21.951873584098493!!
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.272731 Test loss=0.291583 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2512000799179077
[5/24] Train loss=0.24460843205451965
[10/24] Train loss=0.29819920659065247
[15/24] Train loss=0.2794676721096039
[20/24] Train loss=0.24285444617271423
Test set avg_accuracy=86.90% avg_sensitivity=81.05%, avg_specificity=88.99% avg_auc=93.51%
Best model saved!! Metric=24.454161545332425!!
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.269297 Test loss=0.309802 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2536328434944153
[5/24] Train loss=0.24217543005943298
[10/24] Train loss=0.2907673120498657
[15/24] Train loss=0.2722511887550354
[20/24] Train loss=0.24572117626667023
Test set avg_accuracy=87.47% avg_sensitivity=78.23%, avg_specificity=90.78% avg_auc=93.75%
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.263778 Test loss=0.291256 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.24630185961723328
[5/24] Train loss=0.23462721705436707
[10/24] Train loss=0.2830302119255066
[15/24] Train loss=0.2636649012565613
[20/24] Train loss=0.24518202245235443
Test set avg_accuracy=87.62% avg_sensitivity=66.85%, avg_specificity=95.03% avg_auc=93.37%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.258911 Test loss=0.292193 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.23787137866020203
[5/24] Train loss=0.23173844814300537
[10/24] Train loss=0.2859232425689697
[15/24] Train loss=0.2601885199546814
[20/24] Train loss=0.23676921427249908
Test set avg_accuracy=87.86% avg_sensitivity=74.81%, avg_specificity=92.53% avg_auc=93.90%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.255815 Test loss=0.282940 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2417922168970108
[5/24] Train loss=0.22526352107524872
[10/24] Train loss=0.2765927016735077
[15/24] Train loss=0.2538232207298279
[20/24] Train loss=0.23379237949848175
Test set avg_accuracy=88.16% avg_sensitivity=70.26%, avg_specificity=94.56% avg_auc=93.71%
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.250028 Test loss=0.281285 Current lr=[0.000210185142098938]

[0/24] Train loss=0.23074255883693695
[5/24] Train loss=0.21953094005584717
[10/24] Train loss=0.27596378326416016
[15/24] Train loss=0.25520890951156616
[20/24] Train loss=0.23238298296928406
Test set avg_accuracy=87.38% avg_sensitivity=67.59%, avg_specificity=94.45% avg_auc=92.38%
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.246478 Test loss=0.304416 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.23882867395877838
[5/24] Train loss=0.21197627484798431
[10/24] Train loss=0.27969521284103394
[15/24] Train loss=0.2455662488937378
[20/24] Train loss=0.21930749714374542
Test set avg_accuracy=87.25% avg_sensitivity=73.33%, avg_specificity=92.22% avg_auc=93.20%
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.241756 Test loss=0.292664 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2278878390789032
[5/24] Train loss=0.2084806263446808
[10/24] Train loss=0.28128936886787415
[15/24] Train loss=0.24715079367160797
[20/24] Train loss=0.2234378308057785
Test set avg_accuracy=87.04% avg_sensitivity=64.67%, avg_specificity=95.03% avg_auc=92.31%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.237306 Test loss=0.308439 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2313116043806076
[5/24] Train loss=0.20790298283100128
[10/24] Train loss=0.2670254409313202
[15/24] Train loss=0.24287649989128113
[20/24] Train loss=0.2255910485982895
Test set avg_accuracy=86.72% avg_sensitivity=62.25%, avg_specificity=95.46% avg_auc=92.92%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.237452 Test loss=0.302148 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.22657808661460876
[5/24] Train loss=0.20333994925022125
[10/24] Train loss=0.25879812240600586
[15/24] Train loss=0.23840050399303436
[20/24] Train loss=0.21674643456935883
Test set avg_accuracy=87.67% avg_sensitivity=73.53%, avg_specificity=92.72% avg_auc=93.34%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.235226 Test loss=0.288338 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.21959133446216583
[5/24] Train loss=0.20766688883304596
[10/24] Train loss=0.2609269917011261
[15/24] Train loss=0.2431991994380951
[20/24] Train loss=0.2174164354801178
Test set avg_accuracy=87.19% avg_sensitivity=69.87%, avg_specificity=93.37% avg_auc=92.93%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.234551 Test loss=0.294275 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.21677665412425995
[5/24] Train loss=0.194135382771492
[10/24] Train loss=0.24436984956264496
[15/24] Train loss=0.23710303008556366
[20/24] Train loss=0.20892971754074097
Test set avg_accuracy=86.97% avg_sensitivity=61.50%, avg_specificity=96.06% avg_auc=92.24%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.225841 Test loss=0.315725 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.21532930433750153
[5/24] Train loss=0.19379878044128418
[10/24] Train loss=0.26021888852119446
[15/24] Train loss=0.23607763648033142
[20/24] Train loss=0.20364582538604736
Test set avg_accuracy=86.68% avg_sensitivity=67.89%, avg_specificity=93.39% avg_auc=92.64%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.226262 Test loss=0.301304 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.20615865290164948
[5/24] Train loss=0.19031739234924316
[10/24] Train loss=0.2514093518257141
[15/24] Train loss=0.22030285000801086
[20/24] Train loss=0.2231907993555069
Test set avg_accuracy=84.44% avg_sensitivity=46.76%, avg_specificity=97.90% avg_auc=89.74%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.225474 Test loss=0.380716 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.22850632667541504
[5/24] Train loss=0.18669657409191132
[10/24] Train loss=0.2528412342071533
[15/24] Train loss=0.2397662103176117
[20/24] Train loss=0.22411631047725677
Test set avg_accuracy=87.63% avg_sensitivity=70.21%, avg_specificity=93.85% avg_auc=92.95%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.226305 Test loss=0.298749 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.22069357335567474
[5/24] Train loss=0.18468870222568512
[10/24] Train loss=0.24932020902633667
[15/24] Train loss=0.23629425466060638
[20/24] Train loss=0.20123903453350067
Test set avg_accuracy=84.82% avg_sensitivity=49.83%, avg_specificity=97.31% avg_auc=89.33%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.220612 Test loss=0.377543 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.21676155924797058
[5/24] Train loss=0.18561850488185883
[10/24] Train loss=0.24597856402397156
[15/24] Train loss=0.22820957005023956
[20/24] Train loss=0.19687806069850922
Test set avg_accuracy=87.14% avg_sensitivity=70.06%, avg_specificity=93.23% avg_auc=92.45%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.218470 Test loss=0.302710 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.21041157841682434
[5/24] Train loss=0.18730485439300537
[10/24] Train loss=0.24374856054782867
[15/24] Train loss=0.22878481447696686
[20/24] Train loss=0.2006218433380127
Test set avg_accuracy=85.38% avg_sensitivity=53.69%, avg_specificity=96.70% avg_auc=89.55%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.217661 Test loss=0.359320 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.21070416271686554
[5/24] Train loss=0.18767857551574707
[10/24] Train loss=0.2462560534477234
[15/24] Train loss=0.22511076927185059
[20/24] Train loss=0.1978994905948639
Test set avg_accuracy=86.68% avg_sensitivity=72.39%, avg_specificity=91.78% avg_auc=92.37%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.213789 Test loss=0.309320 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.20845092833042145
[5/24] Train loss=0.17575450241565704
[10/24] Train loss=0.2341286838054657
[15/24] Train loss=0.2192772477865219
[20/24] Train loss=0.20867189764976501
Test set avg_accuracy=85.40% avg_sensitivity=69.82%, avg_specificity=90.97% avg_auc=91.20%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.209205 Test loss=0.326592 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.21145164966583252
[5/24] Train loss=0.18703030049800873
[10/24] Train loss=0.21538618206977844
[15/24] Train loss=0.2334863841533661
[20/24] Train loss=0.2001708447933197
Test set avg_accuracy=84.93% avg_sensitivity=53.14%, avg_specificity=96.29% avg_auc=89.88%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.212202 Test loss=0.367508 Current lr=[0.00029967723776099]

[0/24] Train loss=0.20605796575546265
[5/24] Train loss=0.18878263235092163
[10/24] Train loss=0.24538740515708923
[15/24] Train loss=0.21948553621768951
[20/24] Train loss=0.2010032832622528
Test set avg_accuracy=86.86% avg_sensitivity=73.82%, avg_specificity=91.52% avg_auc=92.24%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.213637 Test loss=0.310936 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.19625519216060638
[5/24] Train loss=0.1757589429616928
[10/24] Train loss=0.22688224911689758
[15/24] Train loss=0.2162064015865326
[20/24] Train loss=0.1994837522506714
Test set avg_accuracy=85.83% avg_sensitivity=64.28%, avg_specificity=93.53% avg_auc=89.87%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.210049 Test loss=0.348046 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2008354663848877
[5/24] Train loss=0.19195830821990967
[10/24] Train loss=0.220088392496109
[15/24] Train loss=0.223083958029747
[20/24] Train loss=0.19596683979034424
Test set avg_accuracy=85.87% avg_sensitivity=54.58%, avg_specificity=97.05% avg_auc=90.58%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.208750 Test loss=0.350859 Current lr=[0.000299720220882401]

[0/24] Train loss=0.1976163685321808
[5/24] Train loss=0.17272746562957764
[10/24] Train loss=0.22449705004692078
[15/24] Train loss=0.20928730070590973
[20/24] Train loss=0.19708840548992157
Test set avg_accuracy=87.49% avg_sensitivity=73.13%, avg_specificity=92.61% avg_auc=92.70%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.207837 Test loss=0.300670 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.20247508585453033
[5/24] Train loss=0.1805618405342102
[10/24] Train loss=0.20971791446208954
[15/24] Train loss=0.20763804018497467
[20/24] Train loss=0.187783345580101
Test set avg_accuracy=87.20% avg_sensitivity=72.88%, avg_specificity=92.31% avg_auc=92.70%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.200056 Test loss=0.300273 Current lr=[0.000298904600941902]

[0/24] Train loss=0.1942504346370697
[5/24] Train loss=0.17695479094982147
[10/24] Train loss=0.21102912724018097
[15/24] Train loss=0.20711252093315125
[20/24] Train loss=0.19147436320781708
Test set avg_accuracy=86.77% avg_sensitivity=68.88%, avg_specificity=93.16% avg_auc=90.03%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.199948 Test loss=0.334882 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.1857018917798996
[5/24] Train loss=0.16746000945568085
[10/24] Train loss=0.19730348885059357
[15/24] Train loss=0.20869974792003632
[20/24] Train loss=0.18843288719654083
Test set avg_accuracy=86.76% avg_sensitivity=77.04%, avg_specificity=90.23% avg_auc=92.68%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.197106 Test loss=0.310675 Current lr=[0.000297555943323901]

[0/24] Train loss=0.18065373599529266
[5/24] Train loss=0.1835251748561859
[10/24] Train loss=0.2122618407011032
[15/24] Train loss=0.2082364559173584
[20/24] Train loss=0.18819816410541534
Test set avg_accuracy=80.52% avg_sensitivity=81.25%, avg_specificity=80.26% avg_auc=88.69%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.200552 Test loss=0.433836 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2038954198360443
[5/24] Train loss=0.16517594456672668
[10/24] Train loss=0.20936429500579834
[15/24] Train loss=0.20596401393413544
[20/24] Train loss=0.1928560733795166
Test set avg_accuracy=82.60% avg_sensitivity=38.94%, avg_specificity=98.20% avg_auc=86.19%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.200061 Test loss=0.450132 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.19568902254104614
[5/24] Train loss=0.17522569000720978
[10/24] Train loss=0.20074562728405
[15/24] Train loss=0.2059081792831421
[20/24] Train loss=0.18502680957317352
Test set avg_accuracy=86.93% avg_sensitivity=64.62%, avg_specificity=94.89% avg_auc=91.03%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.194680 Test loss=0.324540 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.18710745871067047
[5/24] Train loss=0.17019206285476685
[10/24] Train loss=0.2128455489873886
[15/24] Train loss=0.2289726436138153
[20/24] Train loss=0.18206322193145752
Test set avg_accuracy=86.71% avg_sensitivity=81.59%, avg_specificity=88.53% avg_auc=92.88%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.197818 Test loss=0.316394 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.18960534036159515
[5/24] Train loss=0.1654144674539566
[10/24] Train loss=0.20611852407455444
[15/24] Train loss=0.22045771777629852
[20/24] Train loss=0.19600443542003632
Test set avg_accuracy=87.37% avg_sensitivity=77.09%, avg_specificity=91.04% avg_auc=92.98%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.195891 Test loss=0.297974 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.18413665890693665
[5/24] Train loss=0.1754675954580307
[10/24] Train loss=0.19459833204746246
[15/24] Train loss=0.23180441558361053
[20/24] Train loss=0.18572942912578583
Test set avg_accuracy=85.92% avg_sensitivity=80.31%, avg_specificity=87.93% avg_auc=92.04%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.192324 Test loss=0.337127 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.18969129025936127
[5/24] Train loss=0.1728104054927826
[10/24] Train loss=0.19668689370155334
[15/24] Train loss=0.22253641486167908
[20/24] Train loss=0.1922556757926941
Test set avg_accuracy=86.05% avg_sensitivity=69.03%, avg_specificity=92.14% avg_auc=91.83%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.192987 Test loss=0.324387 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.18444520235061646
[5/24] Train loss=0.16728906333446503
[10/24] Train loss=0.20247137546539307
[15/24] Train loss=0.21174298226833344
[20/24] Train loss=0.17565062642097473
Test set avg_accuracy=86.32% avg_sensitivity=79.91%, avg_specificity=88.60% avg_auc=92.63%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.190594 Test loss=0.320485 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18254828453063965
[5/24] Train loss=0.16185016930103302
[10/24] Train loss=0.20055602490901947
[15/24] Train loss=0.22538475692272186
[20/24] Train loss=0.19547413289546967
Test set avg_accuracy=83.68% avg_sensitivity=84.02%, avg_specificity=83.57% avg_auc=91.88%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.196154 Test loss=0.360702 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.1871986985206604
[5/24] Train loss=0.16379515826702118
[10/24] Train loss=0.19241636991500854
[15/24] Train loss=0.19982974231243134
[20/24] Train loss=0.1812695860862732
Test set avg_accuracy=83.31% avg_sensitivity=86.54%, avg_specificity=82.15% avg_auc=91.67%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.190004 Test loss=0.387546 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.1809738278388977
[5/24] Train loss=0.15915599465370178
[10/24] Train loss=0.19251850247383118
[15/24] Train loss=0.19576102495193481
[20/24] Train loss=0.19109021127223969
Test set avg_accuracy=85.12% avg_sensitivity=82.24%, avg_specificity=86.15% avg_auc=92.47%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.187931 Test loss=0.338363 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.18495836853981018
[5/24] Train loss=0.17910747230052948
[10/24] Train loss=0.21388386189937592
[15/24] Train loss=0.207382932305336
[20/24] Train loss=0.18422074615955353
Test set avg_accuracy=87.97% avg_sensitivity=75.26%, avg_specificity=92.51% avg_auc=93.05%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.189169 Test loss=0.297885 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.18036425113677979
[5/24] Train loss=0.16548293828964233
[10/24] Train loss=0.20654098689556122
[15/24] Train loss=0.19148960709571838
[20/24] Train loss=0.1787138730287552
Test set avg_accuracy=86.26% avg_sensitivity=77.39%, avg_specificity=89.43% avg_auc=92.81%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.187365 Test loss=0.312570 Current lr=[0.000276307469034998]

[0/24] Train loss=0.1784026175737381
[5/24] Train loss=0.15996266901493073
[10/24] Train loss=0.19149374961853027
[15/24] Train loss=0.19883230328559875
[20/24] Train loss=0.17597265541553497
Test set avg_accuracy=87.43% avg_sensitivity=69.37%, avg_specificity=93.89% avg_auc=92.01%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.184317 Test loss=0.309312 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.18158558011054993
[5/24] Train loss=0.15760833024978638
[10/24] Train loss=0.18782033026218414
[15/24] Train loss=0.19545046985149384
[20/24] Train loss=0.17435625195503235
Test set avg_accuracy=86.98% avg_sensitivity=73.53%, avg_specificity=91.78% avg_auc=91.74%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.180357 Test loss=0.317817 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.17522570490837097
[5/24] Train loss=0.16271407902240753
[10/24] Train loss=0.1825554221868515
[15/24] Train loss=0.19536951184272766
[20/24] Train loss=0.17584452033042908
Test set avg_accuracy=86.73% avg_sensitivity=78.03%, avg_specificity=89.84% avg_auc=92.54%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.179981 Test loss=0.318535 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.1721097081899643
[5/24] Train loss=0.16151610016822815
[10/24] Train loss=0.18080778419971466
[15/24] Train loss=0.21024996042251587
[20/24] Train loss=0.1772097498178482
Test set avg_accuracy=80.81% avg_sensitivity=81.64%, avg_specificity=80.51% avg_auc=89.00%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.182457 Test loss=0.436250 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.1749129742383957
[5/24] Train loss=0.16318053007125854
[10/24] Train loss=0.18745267391204834
[15/24] Train loss=0.19664907455444336
[20/24] Train loss=0.16950935125350952
Test set avg_accuracy=85.62% avg_sensitivity=77.93%, avg_specificity=88.37% avg_auc=91.20%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.181891 Test loss=0.344515 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.17755229771137238
[5/24] Train loss=0.16313423216342926
[10/24] Train loss=0.185212180018425
[15/24] Train loss=0.19922177493572235
[20/24] Train loss=0.17476139962673187
Test set avg_accuracy=79.11% avg_sensitivity=83.87%, avg_specificity=77.42% avg_auc=89.17%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.182591 Test loss=0.447105 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.1727495938539505
[5/24] Train loss=0.1591072827577591
[10/24] Train loss=0.17943274974822998
[15/24] Train loss=0.18478921055793762
[20/24] Train loss=0.18318967521190643
Test set avg_accuracy=78.40% avg_sensitivity=86.84%, avg_specificity=75.38% avg_auc=89.25%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.177359 Test loss=0.479653 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.180642768740654
[5/24] Train loss=0.16278713941574097
[10/24] Train loss=0.17953285574913025
[15/24] Train loss=0.19790969789028168
[20/24] Train loss=0.1792161762714386
Test set avg_accuracy=73.22% avg_sensitivity=87.28%, avg_specificity=68.19% avg_auc=86.54%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.178308 Test loss=0.572550 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.1789749562740326
[5/24] Train loss=0.15652987360954285
[10/24] Train loss=0.17742705345153809
[15/24] Train loss=0.19141149520874023
[20/24] Train loss=0.16963569819927216
Test set avg_accuracy=81.32% avg_sensitivity=86.54%, avg_specificity=79.45% avg_auc=90.61%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.180656 Test loss=0.426259 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.17569205164909363
[5/24] Train loss=0.16203835606575012
[10/24] Train loss=0.1776837408542633
[15/24] Train loss=0.18430107831954956
[20/24] Train loss=0.1713215857744217
Test set avg_accuracy=87.08% avg_sensitivity=79.37%, avg_specificity=89.84% avg_auc=92.19%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.177033 Test loss=0.317679 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.1669045239686966
[5/24] Train loss=0.16795295476913452
[10/24] Train loss=0.17591558396816254
[15/24] Train loss=0.1841925084590912
[20/24] Train loss=0.16557714343070984
Test set avg_accuracy=85.55% avg_sensitivity=83.33%, avg_specificity=86.34% avg_auc=92.49%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.174677 Test loss=0.337188 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.16864481568336487
[5/24] Train loss=0.1541631817817688
[10/24] Train loss=0.16696491837501526
[15/24] Train loss=0.17598751187324524
[20/24] Train loss=0.16097410023212433
Test set avg_accuracy=87.01% avg_sensitivity=78.48%, avg_specificity=90.05% avg_auc=92.97%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.171190 Test loss=0.307371 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.16037102043628693
[5/24] Train loss=0.14863857626914978
[10/24] Train loss=0.1650649756193161
[15/24] Train loss=0.18200400471687317
[20/24] Train loss=0.15866750478744507
Test set avg_accuracy=86.67% avg_sensitivity=80.46%, avg_specificity=88.88% avg_auc=92.90%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.169313 Test loss=0.317854 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.16502578556537628
[5/24] Train loss=0.1482313573360443
[10/24] Train loss=0.16446301341056824
[15/24] Train loss=0.17968373000621796
[20/24] Train loss=0.16362795233726501
Test set avg_accuracy=87.01% avg_sensitivity=75.36%, avg_specificity=91.16% avg_auc=91.80%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.169915 Test loss=0.322593 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.17182226479053497
[5/24] Train loss=0.15075233578681946
[10/24] Train loss=0.16906732320785522
[15/24] Train loss=0.1799430549144745
[20/24] Train loss=0.16599084436893463
Test set avg_accuracy=87.07% avg_sensitivity=67.94%, avg_specificity=93.90% avg_auc=90.98%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.170353 Test loss=0.323098 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17314130067825317
[5/24] Train loss=0.14756092429161072
[10/24] Train loss=0.1713363230228424
[15/24] Train loss=0.18177452683448792
[20/24] Train loss=0.1711452603340149
Test set avg_accuracy=87.70% avg_sensitivity=78.13%, avg_specificity=91.11% avg_auc=92.43%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.173245 Test loss=0.306649 Current lr=[0.000224838296036774]

[0/24] Train loss=0.16898317635059357
[5/24] Train loss=0.14987511932849884
[10/24] Train loss=0.16040116548538208
[15/24] Train loss=0.1803910732269287
[20/24] Train loss=0.15810522437095642
Test set avg_accuracy=85.43% avg_sensitivity=68.18%, avg_specificity=91.59% avg_auc=89.48%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.168631 Test loss=0.351990 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.16192859411239624
[5/24] Train loss=0.16631600260734558
[10/24] Train loss=0.17323021590709686
[15/24] Train loss=0.179212749004364
[20/24] Train loss=0.16944798827171326
Test set avg_accuracy=86.90% avg_sensitivity=66.11%, avg_specificity=94.33% avg_auc=90.95%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.179697 Test loss=0.327317 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.17179222404956818
[5/24] Train loss=0.15242017805576324
[10/24] Train loss=0.17632485926151276
[15/24] Train loss=0.1916613131761551
[20/24] Train loss=0.16363592445850372
Test set avg_accuracy=85.91% avg_sensitivity=80.55%, avg_specificity=87.82% avg_auc=92.00%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.171895 Test loss=0.335431 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1572219431400299
[5/24] Train loss=0.15090708434581757
[10/24] Train loss=0.19554248452186584
[15/24] Train loss=0.19108472764492035
[20/24] Train loss=0.16915147006511688
Test set avg_accuracy=86.38% avg_sensitivity=62.49%, avg_specificity=94.91% avg_auc=89.32%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.172063 Test loss=0.350367 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.1589439958333969
[5/24] Train loss=0.1514645665884018
[10/24] Train loss=0.1744730919599533
[15/24] Train loss=0.17782700061798096
[20/24] Train loss=0.16162815690040588
Test set avg_accuracy=85.62% avg_sensitivity=81.44%, avg_specificity=87.12% avg_auc=92.16%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.169269 Test loss=0.336188 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.16655191779136658
[5/24] Train loss=0.14840419590473175
[10/24] Train loss=0.1760966032743454
[15/24] Train loss=0.17362938821315765
[20/24] Train loss=0.16780275106430054
Test set avg_accuracy=86.88% avg_sensitivity=73.33%, avg_specificity=91.71% avg_auc=90.98%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.166623 Test loss=0.329343 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1635597050189972
[5/24] Train loss=0.15520066022872925
[10/24] Train loss=0.1722564399242401
[15/24] Train loss=0.18464629352092743
[20/24] Train loss=0.16799628734588623
Test set avg_accuracy=85.04% avg_sensitivity=55.71%, avg_specificity=95.51% avg_auc=86.94%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.169709 Test loss=0.410305 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1642943024635315
[5/24] Train loss=0.14912603795528412
[10/24] Train loss=0.15708030760288239
[15/24] Train loss=0.17235636711120605
[20/24] Train loss=0.16780197620391846
Test set avg_accuracy=87.71% avg_sensitivity=74.22%, avg_specificity=92.53% avg_auc=91.48%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.167403 Test loss=0.313612 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1644357144832611
[5/24] Train loss=0.1485823094844818
[10/24] Train loss=0.16236869990825653
[15/24] Train loss=0.17677778005599976
[20/24] Train loss=0.16062980890274048
Test set avg_accuracy=80.25% avg_sensitivity=88.32%, avg_specificity=77.36% avg_auc=90.05%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.164162 Test loss=0.464695 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.16026653349399567
[5/24] Train loss=0.14783911406993866
[10/24] Train loss=0.1657782942056656
[15/24] Train loss=0.17727939784526825
[20/24] Train loss=0.16832539439201355
Test set avg_accuracy=87.60% avg_sensitivity=71.25%, avg_specificity=93.44% avg_auc=91.59%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.164107 Test loss=0.312097 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.16662044823169708
[5/24] Train loss=0.14756782352924347
[10/24] Train loss=0.15818259119987488
[15/24] Train loss=0.17373807728290558
[20/24] Train loss=0.15836484730243683
Test set avg_accuracy=87.59% avg_sensitivity=70.26%, avg_specificity=93.78% avg_auc=90.57%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.162694 Test loss=0.328090 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.15870201587677002
[5/24] Train loss=0.15598061680793762
[10/24] Train loss=0.16515789926052094
[15/24] Train loss=0.17206063866615295
[20/24] Train loss=0.15519402921199799
Test set avg_accuracy=82.86% avg_sensitivity=40.28%, avg_specificity=98.07% avg_auc=83.06%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.162642 Test loss=0.480221 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.16313429176807404
[5/24] Train loss=0.14768043160438538
[10/24] Train loss=0.1574602723121643
[15/24] Train loss=0.17607101798057556
[20/24] Train loss=0.15345264971256256
Test set avg_accuracy=85.92% avg_sensitivity=80.50%, avg_specificity=87.86% avg_auc=91.62%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.163586 Test loss=0.348765 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15059001743793488
[5/24] Train loss=0.1488572359085083
[10/24] Train loss=0.16203458607196808
[15/24] Train loss=0.16981470584869385
[20/24] Train loss=0.15152913331985474
Test set avg_accuracy=87.04% avg_sensitivity=62.35%, avg_specificity=95.86% avg_auc=90.01%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.160014 Test loss=0.344344 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.14595875144004822
[5/24] Train loss=0.15029971301555634
[10/24] Train loss=0.15907585620880127
[15/24] Train loss=0.17529000341892242
[20/24] Train loss=0.150487020611763
Test set avg_accuracy=86.30% avg_sensitivity=60.27%, avg_specificity=95.60% avg_auc=87.51%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.160052 Test loss=0.369143 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15008488297462463
[5/24] Train loss=0.1503303349018097
[10/24] Train loss=0.15868321061134338
[15/24] Train loss=0.17254385352134705
[20/24] Train loss=0.15381473302841187
Test set avg_accuracy=87.41% avg_sensitivity=66.06%, avg_specificity=95.03% avg_auc=89.81%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.161043 Test loss=0.338607 Current lr=[0.000156543481933168]

[0/24] Train loss=0.15115328133106232
[5/24] Train loss=0.14730818569660187
[10/24] Train loss=0.15457388758659363
[15/24] Train loss=0.17825807631015778
[20/24] Train loss=0.17122523486614227
Test set avg_accuracy=87.23% avg_sensitivity=64.47%, avg_specificity=95.35% avg_auc=90.42%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.160154 Test loss=0.331525 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.15199537575244904
[5/24] Train loss=0.1498197615146637
[10/24] Train loss=0.15084734559059143
[15/24] Train loss=0.1715189665555954
[20/24] Train loss=0.15158073604106903
Test set avg_accuracy=85.38% avg_sensitivity=52.85%, avg_specificity=97.00% avg_auc=88.15%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.157904 Test loss=0.385359 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15071070194244385
[5/24] Train loss=0.14284572005271912
[10/24] Train loss=0.15799547731876373
[15/24] Train loss=0.17744843661785126
[20/24] Train loss=0.1528376340866089
Test set avg_accuracy=87.06% avg_sensitivity=67.10%, avg_specificity=94.19% avg_auc=90.30%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.157621 Test loss=0.328089 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.14546051621437073
[5/24] Train loss=0.1436653882265091
[10/24] Train loss=0.1545702964067459
[15/24] Train loss=0.16336137056350708
[20/24] Train loss=0.15135149657726288
Test set avg_accuracy=87.62% avg_sensitivity=65.46%, avg_specificity=95.53% avg_auc=89.86%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.155767 Test loss=0.337344 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.14661309123039246
[5/24] Train loss=0.14631958305835724
[10/24] Train loss=0.15077286958694458
[15/24] Train loss=0.18034526705741882
[20/24] Train loss=0.15602362155914307
Test set avg_accuracy=86.73% avg_sensitivity=60.71%, avg_specificity=96.02% avg_auc=88.02%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.156967 Test loss=0.363272 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1552239954471588
[5/24] Train loss=0.1379033476114273
[10/24] Train loss=0.1535211205482483
[15/24] Train loss=0.1614808291196823
[20/24] Train loss=0.1496199071407318
Test set avg_accuracy=86.89% avg_sensitivity=62.00%, avg_specificity=95.78% avg_auc=88.91%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.155175 Test loss=0.355766 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15127982199192047
[5/24] Train loss=0.14716829359531403
[10/24] Train loss=0.15481197834014893
[15/24] Train loss=0.16109338402748108
[20/24] Train loss=0.15001507103443146
Test set avg_accuracy=85.76% avg_sensitivity=56.26%, avg_specificity=96.29% avg_auc=87.97%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.155059 Test loss=0.378701 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.14482547342777252
[5/24] Train loss=0.14412257075309753
[10/24] Train loss=0.146548792719841
[15/24] Train loss=0.17051859200000763
[20/24] Train loss=0.15570439398288727
Test set avg_accuracy=87.86% avg_sensitivity=72.54%, avg_specificity=93.34% avg_auc=92.14%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.154260 Test loss=0.306816 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.14593078196048737
[5/24] Train loss=0.1422334462404251
[10/24] Train loss=0.14719119668006897
[15/24] Train loss=0.1715666800737381
[20/24] Train loss=0.14706408977508545
Test set avg_accuracy=87.19% avg_sensitivity=63.63%, avg_specificity=95.60% avg_auc=89.07%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.153281 Test loss=0.341261 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14667336642742157
[5/24] Train loss=0.14821721613407135
[10/24] Train loss=0.15584677457809448
[15/24] Train loss=0.15675561130046844
[20/24] Train loss=0.14802871644496918
Test set avg_accuracy=87.36% avg_sensitivity=76.05%, avg_specificity=91.39% avg_auc=92.12%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.151477 Test loss=0.316754 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1402590125799179
[5/24] Train loss=0.14188185334205627
[10/24] Train loss=0.14403454959392548
[15/24] Train loss=0.15990744531154633
[20/24] Train loss=0.1487012654542923
Test set avg_accuracy=88.14% avg_sensitivity=69.92%, avg_specificity=94.65% avg_auc=91.70%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.150298 Test loss=0.310169 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1441822350025177
[5/24] Train loss=0.1377677023410797
[10/24] Train loss=0.14409419894218445
[15/24] Train loss=0.15926679968833923
[20/24] Train loss=0.14691951870918274
Test set avg_accuracy=87.53% avg_sensitivity=75.51%, avg_specificity=91.82% avg_auc=92.21%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.148772 Test loss=0.317525 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.13921597599983215
[5/24] Train loss=0.13888487219810486
[10/24] Train loss=0.1462186872959137
[15/24] Train loss=0.1505586951971054
[20/24] Train loss=0.14733146131038666
Test set avg_accuracy=87.14% avg_sensitivity=75.85%, avg_specificity=91.16% avg_auc=91.19%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.145414 Test loss=0.328290 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.13997921347618103
[5/24] Train loss=0.14303195476531982
[10/24] Train loss=0.1381060630083084
[15/24] Train loss=0.15794235467910767
[20/24] Train loss=0.1442527323961258
Test set avg_accuracy=88.15% avg_sensitivity=73.68%, avg_specificity=93.32% avg_auc=92.64%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.144583 Test loss=0.303149 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.1399044692516327
[5/24] Train loss=0.1356382817029953
[10/24] Train loss=0.13949722051620483
[15/24] Train loss=0.1529122292995453
[20/24] Train loss=0.14708244800567627
Test set avg_accuracy=87.89% avg_sensitivity=71.40%, avg_specificity=93.78% avg_auc=91.66%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.143353 Test loss=0.311275 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.13605277240276337
[5/24] Train loss=0.12790068984031677
[10/24] Train loss=0.13759005069732666
[15/24] Train loss=0.1493469774723053
[20/24] Train loss=0.13833793997764587
Test set avg_accuracy=87.68% avg_sensitivity=74.37%, avg_specificity=92.44% avg_auc=92.25%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.141726 Test loss=0.308441 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.13618485629558563
[5/24] Train loss=0.1308746039867401
[10/24] Train loss=0.13586747646331787
[15/24] Train loss=0.1535700559616089
[20/24] Train loss=0.1415344625711441
Test set avg_accuracy=87.15% avg_sensitivity=77.88%, avg_specificity=90.46% avg_auc=92.61%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.140135 Test loss=0.315187 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13618846237659454
[5/24] Train loss=0.13297542929649353
[10/24] Train loss=0.13387960195541382
[15/24] Train loss=0.15207825601100922
[20/24] Train loss=0.14257358014583588
Test set avg_accuracy=87.92% avg_sensitivity=75.90%, avg_specificity=92.21% avg_auc=92.27%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.139680 Test loss=0.309042 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13402590155601501
[5/24] Train loss=0.13053518533706665
[10/24] Train loss=0.13451462984085083
[15/24] Train loss=0.14547960460186005
[20/24] Train loss=0.13585695624351501
Test set avg_accuracy=87.70% avg_sensitivity=75.95%, avg_specificity=91.89% avg_auc=92.51%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.138189 Test loss=0.305957 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13264200091362
[5/24] Train loss=0.1323411911725998
[10/24] Train loss=0.13463027775287628
[15/24] Train loss=0.14372779428958893
[20/24] Train loss=0.13501152396202087
Test set avg_accuracy=87.53% avg_sensitivity=70.91%, avg_specificity=93.46% avg_auc=92.10%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.137319 Test loss=0.310472 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13801226019859314
[5/24] Train loss=0.12816742062568665
[10/24] Train loss=0.1313532292842865
[15/24] Train loss=0.14432011544704437
[20/24] Train loss=0.13639310002326965
Test set avg_accuracy=87.51% avg_sensitivity=74.76%, avg_specificity=92.07% avg_auc=92.15%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.135986 Test loss=0.309238 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.12923982739448547
[5/24] Train loss=0.12644393742084503
[10/24] Train loss=0.12692280113697052
[15/24] Train loss=0.14492258429527283
[20/24] Train loss=0.1364227682352066
Test set avg_accuracy=87.80% avg_sensitivity=72.79%, avg_specificity=93.16% avg_auc=91.81%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.135026 Test loss=0.311381 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.12943050265312195
[5/24] Train loss=0.12392976135015488
[10/24] Train loss=0.13127946853637695
[15/24] Train loss=0.14654852449893951
[20/24] Train loss=0.13371825218200684
Test set avg_accuracy=87.68% avg_sensitivity=71.50%, avg_specificity=93.46% avg_auc=91.17%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.134591 Test loss=0.320318 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.12688255310058594
[5/24] Train loss=0.12484245747327805
[10/24] Train loss=0.13082179427146912
[15/24] Train loss=0.14815008640289307
[20/24] Train loss=0.13148726522922516
Test set avg_accuracy=87.12% avg_sensitivity=76.00%, avg_specificity=91.09% avg_auc=92.28%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.133907 Test loss=0.311148 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13077479600906372
[5/24] Train loss=0.12775559723377228
[10/24] Train loss=0.12708011269569397
[15/24] Train loss=0.14347659051418304
[20/24] Train loss=0.13378268480300903
Test set avg_accuracy=87.72% avg_sensitivity=74.57%, avg_specificity=92.42% avg_auc=91.95%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.133122 Test loss=0.311313 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.12934067845344543
[5/24] Train loss=0.1212024912238121
[10/24] Train loss=0.12928323447704315
[15/24] Train loss=0.14419494569301605
[20/24] Train loss=0.12950089573860168
Test set avg_accuracy=86.98% avg_sensitivity=77.73%, avg_specificity=90.28% avg_auc=92.33%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.132479 Test loss=0.319644 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.125726118683815
[5/24] Train loss=0.12331799417734146
[10/24] Train loss=0.12759755551815033
[15/24] Train loss=0.13708126544952393
[20/24] Train loss=0.13408246636390686
Test set avg_accuracy=87.40% avg_sensitivity=77.49%, avg_specificity=90.93% avg_auc=92.43%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.132212 Test loss=0.312425 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12336862832307816
[5/24] Train loss=0.12429001182317734
[10/24] Train loss=0.1290070116519928
[15/24] Train loss=0.14067932963371277
[20/24] Train loss=0.13205690681934357
Test set avg_accuracy=87.71% avg_sensitivity=75.90%, avg_specificity=91.92% avg_auc=91.92%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.131393 Test loss=0.313175 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12452404201030731
[5/24] Train loss=0.12030714750289917
[10/24] Train loss=0.12505128979682922
[15/24] Train loss=0.13852724432945251
[20/24] Train loss=0.13445217907428741
Test set avg_accuracy=87.75% avg_sensitivity=74.37%, avg_specificity=92.53% avg_auc=91.95%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.130624 Test loss=0.309883 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1241973340511322
[5/24] Train loss=0.12150111049413681
[10/24] Train loss=0.1256823092699051
[15/24] Train loss=0.13600362837314606
[20/24] Train loss=0.1292642056941986
Test set avg_accuracy=87.24% avg_sensitivity=77.83%, avg_specificity=90.60% avg_auc=91.98%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.129547 Test loss=0.317228 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12610433995723724
[5/24] Train loss=0.121889129281044
[10/24] Train loss=0.12558600306510925
[15/24] Train loss=0.13705836236476898
[20/24] Train loss=0.1286000907421112
Test set avg_accuracy=87.11% avg_sensitivity=79.02%, avg_specificity=90.00% avg_auc=91.95%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.129191 Test loss=0.319357 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1238039880990982
[5/24] Train loss=0.12047100812196732
[10/24] Train loss=0.12611430883407593
[15/24] Train loss=0.1342749297618866
[20/24] Train loss=0.1274997889995575
Test set avg_accuracy=86.69% avg_sensitivity=81.64%, avg_specificity=88.50% avg_auc=92.12%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.128512 Test loss=0.327418 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1268797367811203
[5/24] Train loss=0.1215134859085083
[10/24] Train loss=0.12682293355464935
[15/24] Train loss=0.13831743597984314
[20/24] Train loss=0.12750710546970367
Test set avg_accuracy=87.12% avg_sensitivity=78.38%, avg_specificity=90.25% avg_auc=91.79%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.129497 Test loss=0.318949 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12372823059558868
[5/24] Train loss=0.1253352016210556
[10/24] Train loss=0.12088396400213242
[15/24] Train loss=0.140680193901062
[20/24] Train loss=0.13110670447349548
Test set avg_accuracy=87.32% avg_sensitivity=76.25%, avg_specificity=91.27% avg_auc=91.77%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.129318 Test loss=0.318800 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12422779947519302
[5/24] Train loss=0.12348435074090958
[10/24] Train loss=0.12476474791765213
[15/24] Train loss=0.13324092328548431
[20/24] Train loss=0.12901221215724945
Test set avg_accuracy=87.53% avg_sensitivity=76.20%, avg_specificity=91.57% avg_auc=92.56%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.128615 Test loss=0.308562 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.11926644295454025
[5/24] Train loss=0.11927071213722229
[10/24] Train loss=0.12291167676448822
[15/24] Train loss=0.1296909600496292
[20/24] Train loss=0.13190339505672455
Test set avg_accuracy=87.51% avg_sensitivity=77.44%, avg_specificity=91.11% avg_auc=92.18%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.127187 Test loss=0.311092 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12124907970428467
[5/24] Train loss=0.11661536991596222
[10/24] Train loss=0.12204747647047043
[15/24] Train loss=0.13400141894817352
[20/24] Train loss=0.12455441057682037
Test set avg_accuracy=86.88% avg_sensitivity=80.31%, avg_specificity=89.22% avg_auc=92.41%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.126742 Test loss=0.321732 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12253822386264801
[5/24] Train loss=0.11659903079271317
[10/24] Train loss=0.11911951750516891
[15/24] Train loss=0.13329719007015228
[20/24] Train loss=0.1246558129787445
Test set avg_accuracy=87.93% avg_sensitivity=74.96%, avg_specificity=92.56% avg_auc=92.29%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.126111 Test loss=0.303856 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.11850451678037643
[5/24] Train loss=0.11641113460063934
[10/24] Train loss=0.1197301372885704
[15/24] Train loss=0.1310395449399948
[20/24] Train loss=0.12767763435840607
Test set avg_accuracy=87.66% avg_sensitivity=78.13%, avg_specificity=91.06% avg_auc=92.53%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.124523 Test loss=0.305797 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.11825758218765259
[5/24] Train loss=0.1161271333694458
[10/24] Train loss=0.11977850645780563
[15/24] Train loss=0.12928561866283417
[20/24] Train loss=0.1251215934753418
Test set avg_accuracy=87.62% avg_sensitivity=79.22%, avg_specificity=90.62% avg_auc=92.37%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.123257 Test loss=0.310107 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.11706475168466568
[5/24] Train loss=0.11699924618005753
[10/24] Train loss=0.11690540611743927
[15/24] Train loss=0.12938398122787476
[20/24] Train loss=0.12556663155555725
Test set avg_accuracy=87.92% avg_sensitivity=77.29%, avg_specificity=91.71% avg_auc=92.41%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.122927 Test loss=0.305242 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.11565724015235901
[5/24] Train loss=0.11815720051527023
[10/24] Train loss=0.11741533875465393
[15/24] Train loss=0.12607333064079285
[20/24] Train loss=0.1245165467262268
Test set avg_accuracy=87.77% avg_sensitivity=78.23%, avg_specificity=91.18% avg_auc=92.44%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.122697 Test loss=0.307576 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.11744789779186249
[5/24] Train loss=0.11443886905908585
[10/24] Train loss=0.11765718460083008
[15/24] Train loss=0.1276208460330963
[20/24] Train loss=0.12326604872941971
Test set avg_accuracy=87.67% avg_sensitivity=79.61%, avg_specificity=90.55% avg_auc=92.38%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.122134 Test loss=0.311715 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.11748053133487701
[5/24] Train loss=0.11766412109136581
[10/24] Train loss=0.1186639741063118
[15/24] Train loss=0.12410926073789597
[20/24] Train loss=0.12441954016685486
Test set avg_accuracy=87.89% avg_sensitivity=77.34%, avg_specificity=91.66% avg_auc=92.33%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.121708 Test loss=0.306447 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11715754121541977
[5/24] Train loss=0.11565858870744705
[10/24] Train loss=0.12016667425632477
[15/24] Train loss=0.12437950819730759
[20/24] Train loss=0.12340617924928665
Test set avg_accuracy=87.86% avg_sensitivity=78.43%, avg_specificity=91.24% avg_auc=92.35%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.121802 Test loss=0.308069 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.11497639119625092
[5/24] Train loss=0.11454445868730545
[10/24] Train loss=0.11693993210792542
[15/24] Train loss=0.1260356903076172
[20/24] Train loss=0.12199421226978302
Test set avg_accuracy=87.75% avg_sensitivity=78.77%, avg_specificity=90.95% avg_auc=92.38%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.121208 Test loss=0.309070 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11604882031679153
[5/24] Train loss=0.1125740334391594
[10/24] Train loss=0.11751822382211685
[15/24] Train loss=0.12670496106147766
[20/24] Train loss=0.12400858849287033
Test set avg_accuracy=87.81% avg_sensitivity=77.49%, avg_specificity=91.50% avg_auc=92.38%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.121187 Test loss=0.306305 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.11709776520729065
[5/24] Train loss=0.11380758881568909
[10/24] Train loss=0.1172904446721077
[15/24] Train loss=0.12547431886196136
[20/24] Train loss=0.12344220280647278
Test set avg_accuracy=87.86% avg_sensitivity=77.63%, avg_specificity=91.52% avg_auc=92.33%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.121229 Test loss=0.306806 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1176481619477272
[5/24] Train loss=0.11270030587911606
[10/24] Train loss=0.11755205690860748
[15/24] Train loss=0.12424127757549286
[20/24] Train loss=0.12380823493003845
Test set avg_accuracy=87.89% avg_sensitivity=77.63%, avg_specificity=91.55% avg_auc=92.31%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.120615 Test loss=0.307096 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11522980034351349
[5/24] Train loss=0.11397368460893631
[10/24] Train loss=0.12020415812730789
[15/24] Train loss=0.12507638335227966
[20/24] Train loss=0.12310054898262024
Test set avg_accuracy=87.92% avg_sensitivity=78.03%, avg_specificity=91.45% avg_auc=92.32%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.120629 Test loss=0.307844 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11631105095148087
[5/24] Train loss=0.11335165053606033
[10/24] Train loss=0.1169164851307869
[15/24] Train loss=0.1263970583677292
[20/24] Train loss=0.12151092290878296
Test set avg_accuracy=87.86% avg_sensitivity=78.13%, avg_specificity=91.34% avg_auc=92.32%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.121022 Test loss=0.308577 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11584796011447906
[5/24] Train loss=0.11552619189023972
[10/24] Train loss=0.11569179594516754
[15/24] Train loss=0.12181076407432556
[20/24] Train loss=0.12176433205604553
Test set avg_accuracy=87.92% avg_sensitivity=78.13%, avg_specificity=91.41% avg_auc=92.31%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.120520 Test loss=0.308386 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1142578125
[5/24] Train loss=0.11253509670495987
[10/24] Train loss=0.11681891232728958
[15/24] Train loss=0.12554986774921417
[20/24] Train loss=0.12287002056837082
Test set avg_accuracy=87.90% avg_sensitivity=78.08%, avg_specificity=91.41% avg_auc=92.32%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.120505 Test loss=0.308287 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11513260751962662
[5/24] Train loss=0.1138492152094841
[10/24] Train loss=0.11535762995481491
[15/24] Train loss=0.12569758296012878
[20/24] Train loss=0.12317486107349396
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=87.92% avg_sensitivity=78.18%, avg_specificity=91.39% avg_auc=92.32%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.120488 Test loss=0.308375 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=86.90% sen=81.05%, spe=88.99%, auc=93.51%!
Fold[1] Avg_overlap=0.71%(0.2111872074180655)
[0/24] Train loss=0.7151007652282715
[5/24] Train loss=0.7129551768302917
[10/24] Train loss=0.7104665637016296
[15/24] Train loss=0.704594612121582
[20/24] Train loss=0.695099949836731
Test set avg_accuracy=51.51% avg_sensitivity=58.89%, avg_specificity=49.05% avg_auc=55.69%
Best model saved!! Metric=-110.84768994240957!!
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.705395 Test loss=0.703986 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6822077631950378
[5/24] Train loss=0.6864619851112366
[10/24] Train loss=0.6772867441177368
[15/24] Train loss=0.6746695637702942
[20/24] Train loss=0.669931948184967
Test set avg_accuracy=65.21% avg_sensitivity=66.61%, avg_specificity=64.74% avg_auc=70.49%
Best model saved!! Metric=-58.95102079660049!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.676151 Test loss=0.631489 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6639843583106995
[5/24] Train loss=0.6485348343849182
[10/24] Train loss=0.6515742540359497
[15/24] Train loss=0.6409209370613098
[20/24] Train loss=0.6324144005775452
Test set avg_accuracy=71.28% avg_sensitivity=71.10%, avg_specificity=71.33% avg_auc=77.00%
Best model saved!! Metric=-35.29090769306717!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.650380 Test loss=0.588590 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.632269561290741
[5/24] Train loss=0.620483934879303
[10/24] Train loss=0.6162772178649902
[15/24] Train loss=0.6079891920089722
[20/24] Train loss=0.6059431433677673
Test set avg_accuracy=72.97% avg_sensitivity=72.77%, avg_specificity=73.03% avg_auc=79.59%
Best model saved!! Metric=-27.640396126817123!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.622173 Test loss=0.559770 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5967922806739807
[5/24] Train loss=0.5942389369010925
[10/24] Train loss=0.5879748463630676
[15/24] Train loss=0.5819305181503296
[20/24] Train loss=0.5728780031204224
Test set avg_accuracy=74.44% avg_sensitivity=74.60%, avg_specificity=74.39% avg_auc=81.42%
Best model saved!! Metric=-21.157361217666377!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.593071 Test loss=0.538492 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5703551173210144
[5/24] Train loss=0.5626572966575623
[10/24] Train loss=0.5524320006370544
[15/24] Train loss=0.5481683611869812
[20/24] Train loss=0.5439954400062561
Test set avg_accuracy=76.08% avg_sensitivity=75.43%, avg_specificity=76.30% avg_auc=82.99%
Best model saved!! Metric=-15.206696572206255!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.563567 Test loss=0.515276 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5396896600723267
[5/24] Train loss=0.5275155305862427
[10/24] Train loss=0.5237158536911011
[15/24] Train loss=0.5144009590148926
[20/24] Train loss=0.5184645056724548
Test set avg_accuracy=77.67% avg_sensitivity=76.06%, avg_specificity=78.21% avg_auc=84.65%
Best model saved!! Metric=-9.420844902372423!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.533873 Test loss=0.489033 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5018066167831421
[5/24] Train loss=0.49137651920318604
[10/24] Train loss=0.49907585978507996
[15/24] Train loss=0.48830148577690125
[20/24] Train loss=0.48153626918792725
Test set avg_accuracy=79.78% avg_sensitivity=76.00%, avg_specificity=81.03% avg_auc=85.88%
Best model saved!! Metric=-3.300280575680816!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.503809 Test loss=0.462923 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.47576600313186646
[5/24] Train loss=0.4594337046146393
[10/24] Train loss=0.46781331300735474
[15/24] Train loss=0.4548371732234955
[20/24] Train loss=0.4482436180114746
Test set avg_accuracy=81.26% avg_sensitivity=76.00%, avg_specificity=83.01% avg_auc=87.00%
Best model saved!! Metric=1.2796156432258528!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.474807 Test loss=0.438976 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.447299599647522
[5/24] Train loss=0.43119680881500244
[10/24] Train loss=0.43049129843711853
[15/24] Train loss=0.4265851676464081
[20/24] Train loss=0.41721948981285095
Test set avg_accuracy=82.73% avg_sensitivity=75.33%, avg_specificity=85.20% avg_auc=88.08%
Best model saved!! Metric=5.340664959214038!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.445022 Test loss=0.413789 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4160768687725067
[5/24] Train loss=0.40769338607788086
[10/24] Train loss=0.41196900606155396
[15/24] Train loss=0.4018322229385376
[20/24] Train loss=0.38929855823516846
Test set avg_accuracy=83.48% avg_sensitivity=75.22%, avg_specificity=86.22% avg_auc=88.91%
Best model saved!! Metric=7.827772270819565!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.418642 Test loss=0.397296 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.3860849440097809
[5/24] Train loss=0.3787185251712799
[10/24] Train loss=0.3880901038646698
[15/24] Train loss=0.37549981474876404
[20/24] Train loss=0.36492395401000977
Test set avg_accuracy=84.78% avg_sensitivity=73.50%, avg_specificity=88.53% avg_auc=89.60%
Best model saved!! Metric=10.412542244622188!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.395079 Test loss=0.374615 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3652906119823456
[5/24] Train loss=0.35908737778663635
[10/24] Train loss=0.3703877329826355
[15/24] Train loss=0.3590092658996582
[20/24] Train loss=0.3428783714771271
Test set avg_accuracy=85.20% avg_sensitivity=75.48%, avg_specificity=88.43% avg_auc=90.33%
Best model saved!! Metric=13.435839756830873!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.375899 Test loss=0.363920 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.35125046968460083
[5/24] Train loss=0.34185296297073364
[10/24] Train loss=0.35537582635879517
[15/24] Train loss=0.33697110414505005
[20/24] Train loss=0.33323779702186584
Test set avg_accuracy=85.18% avg_sensitivity=77.05%, avg_specificity=87.89% avg_auc=90.64%
Best model saved!! Metric=14.760114358888416!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.360082 Test loss=0.365348 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3320145905017853
[5/24] Train loss=0.32490408420562744
[10/24] Train loss=0.3359440565109253
[15/24] Train loss=0.32777732610702515
[20/24] Train loss=0.3129340708255768
Test set avg_accuracy=86.11% avg_sensitivity=73.24%, avg_specificity=90.39% avg_auc=91.16%
Best model saved!! Metric=14.895585598001844!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.343613 Test loss=0.336277 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3192056715488434
[5/24] Train loss=0.3109431564807892
[10/24] Train loss=0.33072391152381897
[15/24] Train loss=0.3122306168079376
[20/24] Train loss=0.29524245858192444
Test set avg_accuracy=86.04% avg_sensitivity=74.86%, avg_specificity=89.76% avg_auc=91.48%
Best model saved!! Metric=16.13870739135878!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.332122 Test loss=0.332759 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.30532509088516235
[5/24] Train loss=0.3024854063987732
[10/24] Train loss=0.3160038888454437
[15/24] Train loss=0.30204302072525024
[20/24] Train loss=0.28008246421813965
Test set avg_accuracy=86.58% avg_sensitivity=73.40%, avg_specificity=90.96% avg_auc=91.78%
Best model saved!! Metric=16.70870944838171!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.321079 Test loss=0.320266 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.295540988445282
[5/24] Train loss=0.2888248562812805
[10/24] Train loss=0.3085826635360718
[15/24] Train loss=0.3006296753883362
[20/24] Train loss=0.2726864516735077
Test set avg_accuracy=86.16% avg_sensitivity=76.58%, avg_specificity=89.35% avg_auc=91.75%
Best model saved!! Metric=17.83150752500798!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.311305 Test loss=0.327151 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.28084975481033325
[5/24] Train loss=0.28245291113853455
[10/24] Train loss=0.3027174770832062
[15/24] Train loss=0.2836267650127411
[20/24] Train loss=0.26045721769332886
Test set avg_accuracy=85.94% avg_sensitivity=76.00%, avg_specificity=89.24% avg_auc=91.98%
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.301837 Test loss=0.321280 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2755068838596344
[5/24] Train loss=0.2734299600124359
[10/24] Train loss=0.29428789019584656
[15/24] Train loss=0.2783372402191162
[20/24] Train loss=0.2592701017856598
Test set avg_accuracy=86.08% avg_sensitivity=77.52%, avg_specificity=88.93% avg_auc=92.10%
Best model saved!! Metric=18.623579510417855!!
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.294342 Test loss=0.323836 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2699752449989319
[5/24] Train loss=0.26642295718193054
[10/24] Train loss=0.2846163809299469
[15/24] Train loss=0.2633863687515259
[20/24] Train loss=0.2482386976480484
Test set avg_accuracy=86.93% avg_sensitivity=73.76%, avg_specificity=91.31% avg_auc=92.57%
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.286700 Test loss=0.301989 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.26229920983314514
[5/24] Train loss=0.2610582113265991
[10/24] Train loss=0.2817970812320709
[15/24] Train loss=0.2567846477031708
[20/24] Train loss=0.24499939382076263
Test set avg_accuracy=87.71% avg_sensitivity=68.13%, avg_specificity=94.22% avg_auc=92.79%
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.279558 Test loss=0.293270 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.25321507453918457
[5/24] Train loss=0.25296637415885925
[10/24] Train loss=0.2723478376865387
[15/24] Train loss=0.25718173384666443
[20/24] Train loss=0.24192281067371368
Test set avg_accuracy=87.60% avg_sensitivity=64.48%, avg_specificity=95.30% avg_auc=92.72%
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.273180 Test loss=0.292772 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2543904185295105
[5/24] Train loss=0.2528932988643646
[10/24] Train loss=0.2669515311717987
[15/24] Train loss=0.2520090639591217
[20/24] Train loss=0.2350165843963623
Test set avg_accuracy=87.67% avg_sensitivity=74.65%, avg_specificity=92.00% avg_auc=92.90%
Best model saved!! Metric=21.213956767590417!!
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.269393 Test loss=0.292056 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2429823875427246
[5/24] Train loss=0.2486487179994583
[10/24] Train loss=0.2625301480293274
[15/24] Train loss=0.24779266119003296
[20/24] Train loss=0.22705276310443878
Test set avg_accuracy=87.81% avg_sensitivity=72.98%, avg_specificity=92.75% avg_auc=92.75%
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.263041 Test loss=0.292205 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.24271096289157867
[5/24] Train loss=0.24413591623306274
[10/24] Train loss=0.2567121684551239
[15/24] Train loss=0.24369880557060242
[20/24] Train loss=0.22428418695926666
Test set avg_accuracy=87.07% avg_sensitivity=59.47%, avg_specificity=96.25% avg_auc=92.62%
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.258112 Test loss=0.296773 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2300480157136917
[5/24] Train loss=0.23843705654144287
[10/24] Train loss=0.26152798533439636
[15/24] Train loss=0.2361728698015213
[20/24] Train loss=0.23479591310024261
Test set avg_accuracy=87.60% avg_sensitivity=66.61%, avg_specificity=94.59% avg_auc=92.60%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.255265 Test loss=0.293265 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.23300132155418396
[5/24] Train loss=0.23061852157115936
[10/24] Train loss=0.2611478865146637
[15/24] Train loss=0.23022644221782684
[20/24] Train loss=0.21973870694637299
Test set avg_accuracy=85.65% avg_sensitivity=51.90%, avg_specificity=96.88% avg_auc=91.04%
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.249149 Test loss=0.330907 Current lr=[0.000210185142098938]

[0/24] Train loss=0.23315002024173737
[5/24] Train loss=0.22168956696987152
[10/24] Train loss=0.2490626573562622
[15/24] Train loss=0.22974753379821777
[20/24] Train loss=0.22273297607898712
Test set avg_accuracy=86.39% avg_sensitivity=59.52%, avg_specificity=95.33% avg_auc=91.71%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.248155 Test loss=0.314139 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.22024445235729218
[5/24] Train loss=0.23628602921962738
[10/24] Train loss=0.2514793276786804
[15/24] Train loss=0.23005835711956024
[20/24] Train loss=0.21235889196395874
Test set avg_accuracy=87.68% avg_sensitivity=68.54%, avg_specificity=94.05% avg_auc=92.81%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.245086 Test loss=0.287493 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.21769219636917114
[5/24] Train loss=0.22575747966766357
[10/24] Train loss=0.23896174132823944
[15/24] Train loss=0.22788864374160767
[20/24] Train loss=0.20921364426612854
Test set avg_accuracy=86.51% avg_sensitivity=62.86%, avg_specificity=94.38% avg_auc=91.38%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.242571 Test loss=0.316278 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2153085172176361
[5/24] Train loss=0.22237078845500946
[10/24] Train loss=0.24238711595535278
[15/24] Train loss=0.22025777399539948
[20/24] Train loss=0.2070036083459854
Test set avg_accuracy=86.05% avg_sensitivity=55.03%, avg_specificity=96.37% avg_auc=90.49%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.237556 Test loss=0.336089 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2138337343931198
[5/24] Train loss=0.21360690891742706
[10/24] Train loss=0.23786857724189758
[15/24] Train loss=0.23527346551418304
[20/24] Train loss=0.2147931307554245
Test set avg_accuracy=86.67% avg_sensitivity=67.29%, avg_specificity=93.11% avg_auc=92.09%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.235344 Test loss=0.301639 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2178858369588852
[5/24] Train loss=0.2090766429901123
[10/24] Train loss=0.23754864931106567
[15/24] Train loss=0.2295604795217514
[20/24] Train loss=0.20583060383796692
Test set avg_accuracy=86.74% avg_sensitivity=66.35%, avg_specificity=93.53% avg_auc=91.77%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.233904 Test loss=0.306286 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2081259787082672
[5/24] Train loss=0.2250988930463791
[10/24] Train loss=0.23547497391700745
[15/24] Train loss=0.2231554090976715
[20/24] Train loss=0.2163475751876831
Test set avg_accuracy=86.12% avg_sensitivity=64.63%, avg_specificity=93.27% avg_auc=90.44%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.228135 Test loss=0.332163 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.21317747235298157
[5/24] Train loss=0.21216487884521484
[10/24] Train loss=0.23414821922779083
[15/24] Train loss=0.22969064116477966
[20/24] Train loss=0.20072512328624725
Test set avg_accuracy=83.09% avg_sensitivity=38.13%, avg_specificity=98.04% avg_auc=86.89%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.229417 Test loss=0.449682 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.20919263362884521
[5/24] Train loss=0.20567664504051208
[10/24] Train loss=0.23167823255062103
[15/24] Train loss=0.2347632199525833
[20/24] Train loss=0.20444700121879578
Test set avg_accuracy=86.04% avg_sensitivity=77.36%, avg_specificity=88.93% avg_auc=91.90%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.228508 Test loss=0.317826 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.19937390089035034
[5/24] Train loss=0.20848533511161804
[10/24] Train loss=0.23206280171871185
[15/24] Train loss=0.21766529977321625
[20/24] Train loss=0.19995607435703278
Test set avg_accuracy=86.35% avg_sensitivity=67.97%, avg_specificity=92.47% avg_auc=91.39%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.221617 Test loss=0.312174 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.19844549894332886
[5/24] Train loss=0.2046036720275879
[10/24] Train loss=0.23665527999401093
[15/24] Train loss=0.22128386795520782
[20/24] Train loss=0.18933892250061035
Test set avg_accuracy=55.29% avg_sensitivity=90.71%, avg_specificity=43.50% avg_auc=80.58%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.222586 Test loss=0.800006 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.20998556911945343
[5/24] Train loss=0.2175796926021576
[10/24] Train loss=0.23585107922554016
[15/24] Train loss=0.22438015043735504
[20/24] Train loss=0.19083009660243988
Test set avg_accuracy=80.78% avg_sensitivity=83.41%, avg_specificity=79.91% avg_auc=89.39%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.225189 Test loss=0.445832 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.20242047309875488
[5/24] Train loss=0.20486928522586823
[10/24] Train loss=0.21769076585769653
[15/24] Train loss=0.22248664498329163
[20/24] Train loss=0.19758397340774536
Test set avg_accuracy=85.40% avg_sensitivity=77.31%, avg_specificity=88.10% avg_auc=91.35%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.215941 Test loss=0.335187 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.19782721996307373
[5/24] Train loss=0.19856348633766174
[10/24] Train loss=0.2263079732656479
[15/24] Train loss=0.21530231833457947
[20/24] Train loss=0.19818004965782166
Test set avg_accuracy=85.00% avg_sensitivity=72.87%, avg_specificity=89.03% avg_auc=89.87%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.221180 Test loss=0.351892 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.20550201833248138
[5/24] Train loss=0.20398534834384918
[10/24] Train loss=0.21745716035366058
[15/24] Train loss=0.2312634438276291
[20/24] Train loss=0.19081507623195648
Test set avg_accuracy=87.15% avg_sensitivity=68.02%, avg_specificity=93.51% avg_auc=91.67%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.220068 Test loss=0.308303 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.20184189081192017
[5/24] Train loss=0.19949543476104736
[10/24] Train loss=0.22882993519306183
[15/24] Train loss=0.21426557004451752
[20/24] Train loss=0.18384915590286255
Test set avg_accuracy=84.88% avg_sensitivity=79.19%, avg_specificity=86.78% avg_auc=90.40%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.216811 Test loss=0.354280 Current lr=[0.00029967723776099]

[0/24] Train loss=0.19328944385051727
[5/24] Train loss=0.20432505011558533
[10/24] Train loss=0.21233348548412323
[15/24] Train loss=0.20339776575565338
[20/24] Train loss=0.18531815707683563
Test set avg_accuracy=86.88% avg_sensitivity=73.34%, avg_specificity=91.38% avg_auc=91.88%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.207885 Test loss=0.311293 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.18946123123168945
[5/24] Train loss=0.19610996544361115
[10/24] Train loss=0.2027522176504135
[15/24] Train loss=0.19771869480609894
[20/24] Train loss=0.18955959379673004
Test set avg_accuracy=86.34% avg_sensitivity=66.67%, avg_specificity=92.89% avg_auc=90.50%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.207212 Test loss=0.327289 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.1916629821062088
[5/24] Train loss=0.18731960654258728
[10/24] Train loss=0.21845997869968414
[15/24] Train loss=0.20629820227622986
[20/24] Train loss=0.18519316613674164
Test set avg_accuracy=86.30% avg_sensitivity=71.62%, avg_specificity=91.19% avg_auc=90.75%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.205484 Test loss=0.333814 Current lr=[0.000299720220882401]

[0/24] Train loss=0.18581078946590424
[5/24] Train loss=0.199775829911232
[10/24] Train loss=0.21686527132987976
[15/24] Train loss=0.2040025144815445
[20/24] Train loss=0.18354377150535583
Test set avg_accuracy=85.92% avg_sensitivity=70.21%, avg_specificity=91.15% avg_auc=91.20%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.206014 Test loss=0.326617 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.18921135365962982
[5/24] Train loss=0.194030299782753
[10/24] Train loss=0.20753149688243866
[15/24] Train loss=0.20047912001609802
[20/24] Train loss=0.18594299256801605
Test set avg_accuracy=86.68% avg_sensitivity=60.09%, avg_specificity=95.52% avg_auc=91.13%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.205571 Test loss=0.325373 Current lr=[0.000298904600941902]

[0/24] Train loss=0.18106453120708466
[5/24] Train loss=0.1823001652956009
[10/24] Train loss=0.20365385711193085
[15/24] Train loss=0.20356719195842743
[20/24] Train loss=0.1753261387348175
Test set avg_accuracy=86.20% avg_sensitivity=79.55%, avg_specificity=88.41% avg_auc=92.10%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.200400 Test loss=0.325281 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.17725345492362976
[5/24] Train loss=0.19210365414619446
[10/24] Train loss=0.21101342141628265
[15/24] Train loss=0.18472866714000702
[20/24] Train loss=0.18129312992095947
Test set avg_accuracy=84.41% avg_sensitivity=79.50%, avg_specificity=86.05% avg_auc=90.18%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.200241 Test loss=0.359607 Current lr=[0.000297555943323901]

[0/24] Train loss=0.17186374962329865
[5/24] Train loss=0.18833769857883453
[10/24] Train loss=0.1992853879928589
[15/24] Train loss=0.19959799945354462
[20/24] Train loss=0.18463744223117828
Test set avg_accuracy=86.09% avg_sensitivity=66.15%, avg_specificity=92.73% avg_auc=90.65%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.200545 Test loss=0.335921 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.1912342607975006
[5/24] Train loss=0.18979181349277496
[10/24] Train loss=0.21630877256393433
[15/24] Train loss=0.20568715035915375
[20/24] Train loss=0.18543705344200134
Test set avg_accuracy=85.78% avg_sensitivity=59.62%, avg_specificity=94.48% avg_auc=89.37%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.202214 Test loss=0.361889 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.18497316539287567
[5/24] Train loss=0.18221116065979004
[10/24] Train loss=0.21165257692337036
[15/24] Train loss=0.18820255994796753
[20/24] Train loss=0.1711033284664154
Test set avg_accuracy=85.90% avg_sensitivity=76.63%, avg_specificity=88.98% avg_auc=91.47%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.198537 Test loss=0.336031 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.17258794605731964
[5/24] Train loss=0.17284001410007477
[10/24] Train loss=0.20030054450035095
[15/24] Train loss=0.19866357743740082
[20/24] Train loss=0.1828003227710724
Test set avg_accuracy=82.43% avg_sensitivity=33.44%, avg_specificity=98.73% avg_auc=84.35%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.199626 Test loss=0.473908 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.1901623010635376
[5/24] Train loss=0.19813401997089386
[10/24] Train loss=0.20694081485271454
[15/24] Train loss=0.19368650019168854
[20/24] Train loss=0.17734894156455994
Test set avg_accuracy=82.02% avg_sensitivity=78.14%, avg_specificity=83.31% avg_auc=88.82%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.200841 Test loss=0.413019 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.18957968056201935
[5/24] Train loss=0.19594471156597137
[10/24] Train loss=0.20985257625579834
[15/24] Train loss=0.18921679258346558
[20/24] Train loss=0.16859474778175354
Test set avg_accuracy=75.61% avg_sensitivity=84.40%, avg_specificity=72.69% avg_auc=86.72%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.196318 Test loss=0.544950 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.1750149428844452
[5/24] Train loss=0.191952645778656
[10/24] Train loss=0.2003134787082672
[15/24] Train loss=0.1929885596036911
[20/24] Train loss=0.17800498008728027
Test set avg_accuracy=81.67% avg_sensitivity=81.95%, avg_specificity=81.57% avg_auc=89.89%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.197920 Test loss=0.411639 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.17163315415382385
[5/24] Train loss=0.18411649763584137
[10/24] Train loss=0.2004711776971817
[15/24] Train loss=0.1935766637325287
[20/24] Train loss=0.1699841171503067
Test set avg_accuracy=83.59% avg_sensitivity=83.72%, avg_specificity=83.55% avg_auc=90.82%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.197173 Test loss=0.368823 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.17479264736175537
[5/24] Train loss=0.18995875120162964
[10/24] Train loss=0.1843479424715042
[15/24] Train loss=0.19268974661827087
[20/24] Train loss=0.16735564172267914
Test set avg_accuracy=82.08% avg_sensitivity=81.38%, avg_specificity=82.32% avg_auc=89.75%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.190898 Test loss=0.417022 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.17014162242412567
[5/24] Train loss=0.1795109510421753
[10/24] Train loss=0.18987180292606354
[15/24] Train loss=0.1862792819738388
[20/24] Train loss=0.16798904538154602
Test set avg_accuracy=84.36% avg_sensitivity=46.17%, avg_specificity=97.07% avg_auc=86.24%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.193237 Test loss=0.449325 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.1700468808412552
[5/24] Train loss=0.18591473996639252
[10/24] Train loss=0.1861497312784195
[15/24] Train loss=0.18447448313236237
[20/24] Train loss=0.17184807360172272
Test set avg_accuracy=86.76% avg_sensitivity=71.47%, avg_specificity=91.84% avg_auc=90.82%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.191553 Test loss=0.330100 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.16549022495746613
[5/24] Train loss=0.17704802751541138
[10/24] Train loss=0.1883193701505661
[15/24] Train loss=0.19431906938552856
[20/24] Train loss=0.1674136519432068
Test set avg_accuracy=85.33% avg_sensitivity=59.73%, avg_specificity=93.84% avg_auc=89.40%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.189058 Test loss=0.373675 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.17478114366531372
[5/24] Train loss=0.17494548857212067
[10/24] Train loss=0.18559987843036652
[15/24] Train loss=0.183934286236763
[20/24] Train loss=0.16047994792461395
Test set avg_accuracy=83.37% avg_sensitivity=79.97%, avg_specificity=84.50% avg_auc=89.39%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.185393 Test loss=0.402683 Current lr=[0.000276307469034998]

[0/24] Train loss=0.16671277582645416
[5/24] Train loss=0.1780722737312317
[10/24] Train loss=0.1874411404132843
[15/24] Train loss=0.20507077872753143
[20/24] Train loss=0.15632101893424988
Test set avg_accuracy=85.22% avg_sensitivity=65.15%, avg_specificity=91.90% avg_auc=88.84%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.187205 Test loss=0.371971 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.17487435042858124
[5/24] Train loss=0.1807391196489334
[10/24] Train loss=0.19190643727779388
[15/24] Train loss=0.17992880940437317
[20/24] Train loss=0.15806713700294495
Test set avg_accuracy=87.45% avg_sensitivity=66.61%, avg_specificity=94.38% avg_auc=91.32%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.185404 Test loss=0.317770 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.16733910143375397
[5/24] Train loss=0.17613865435123444
[10/24] Train loss=0.18076948821544647
[15/24] Train loss=0.18710583448410034
[20/24] Train loss=0.16004438698291779
Test set avg_accuracy=85.42% avg_sensitivity=51.75%, avg_specificity=96.62% avg_auc=87.53%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.185471 Test loss=0.396960 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.16816912591457367
[5/24] Train loss=0.1885678768157959
[10/24] Train loss=0.17910879850387573
[15/24] Train loss=0.1758943349123001
[20/24] Train loss=0.1528022140264511
Test set avg_accuracy=85.98% avg_sensitivity=55.40%, avg_specificity=96.15% avg_auc=87.62%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.182640 Test loss=0.383912 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.16342954337596893
[5/24] Train loss=0.16648252308368683
[10/24] Train loss=0.18028774857521057
[15/24] Train loss=0.1723979264497757
[20/24] Train loss=0.1557457149028778
Test set avg_accuracy=85.22% avg_sensitivity=70.32%, avg_specificity=90.18% avg_auc=88.60%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.179298 Test loss=0.365501 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.16770082712173462
[5/24] Train loss=0.1707751303911209
[10/24] Train loss=0.18066509068012238
[15/24] Train loss=0.17031314969062805
[20/24] Train loss=0.1564353108406067
Test set avg_accuracy=86.43% avg_sensitivity=72.87%, avg_specificity=90.94% avg_auc=90.00%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.178926 Test loss=0.336281 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.16719581186771393
[5/24] Train loss=0.1651035100221634
[10/24] Train loss=0.173444464802742
[15/24] Train loss=0.17593805491924286
[20/24] Train loss=0.15468017756938934
Test set avg_accuracy=86.13% avg_sensitivity=75.17%, avg_specificity=89.78% avg_auc=91.17%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.175756 Test loss=0.327098 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.16237950325012207
[5/24] Train loss=0.18545441329479218
[10/24] Train loss=0.1750001609325409
[15/24] Train loss=0.17471784353256226
[20/24] Train loss=0.15517829358577728
Test set avg_accuracy=85.43% avg_sensitivity=58.11%, avg_specificity=94.52% avg_auc=85.70%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.180691 Test loss=0.381998 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.16889512538909912
[5/24] Train loss=0.1649990677833557
[10/24] Train loss=0.16680291295051575
[15/24] Train loss=0.17269153892993927
[20/24] Train loss=0.15519225597381592
Test set avg_accuracy=85.48% avg_sensitivity=53.42%, avg_specificity=96.15% avg_auc=88.16%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.175919 Test loss=0.385483 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.16572289168834686
[5/24] Train loss=0.16454295814037323
[10/24] Train loss=0.17080152034759521
[15/24] Train loss=0.17974384129047394
[20/24] Train loss=0.162889301776886
Test set avg_accuracy=85.17% avg_sensitivity=51.33%, avg_specificity=96.43% avg_auc=87.13%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.177401 Test loss=0.389110 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.16474133729934692
[5/24] Train loss=0.17798127233982086
[10/24] Train loss=0.17346705496311188
[15/24] Train loss=0.17161865532398224
[20/24] Train loss=0.15843565762043
Test set avg_accuracy=84.69% avg_sensitivity=54.04%, avg_specificity=94.88% avg_auc=85.95%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.175961 Test loss=0.406723 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1669858694076538
[5/24] Train loss=0.16340813040733337
[10/24] Train loss=0.17876549065113068
[15/24] Train loss=0.16781477630138397
[20/24] Train loss=0.14823250472545624
Test set avg_accuracy=85.46% avg_sensitivity=55.97%, avg_specificity=95.26% avg_auc=87.34%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.176361 Test loss=0.383424 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.15969906747341156
[5/24] Train loss=0.16420966386795044
[10/24] Train loss=0.17492282390594482
[15/24] Train loss=0.17060859501361847
[20/24] Train loss=0.1584668904542923
Test set avg_accuracy=85.21% avg_sensitivity=70.84%, avg_specificity=89.99% avg_auc=89.21%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.174910 Test loss=0.365471 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.1587868183851242
[5/24] Train loss=0.17774182558059692
[10/24] Train loss=0.17067593336105347
[15/24] Train loss=0.1705949604511261
[20/24] Train loss=0.14653119444847107
Test set avg_accuracy=86.16% avg_sensitivity=60.82%, avg_specificity=94.59% avg_auc=88.89%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.174181 Test loss=0.357673 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.15828168392181396
[5/24] Train loss=0.16823391616344452
[10/24] Train loss=0.17603498697280884
[15/24] Train loss=0.16479212045669556
[20/24] Train loss=0.1568930298089981
Test set avg_accuracy=80.17% avg_sensitivity=84.14%, avg_specificity=78.85% avg_auc=89.11%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.176642 Test loss=0.444733 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17011965811252594
[5/24] Train loss=0.16308988630771637
[10/24] Train loss=0.17532886564731598
[15/24] Train loss=0.16831935942173004
[20/24] Train loss=0.1511014699935913
Test set avg_accuracy=86.61% avg_sensitivity=67.87%, avg_specificity=92.85% avg_auc=89.61%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.175950 Test loss=0.333138 Current lr=[0.000224838296036774]

[0/24] Train loss=0.16766241192817688
[5/24] Train loss=0.1747635304927826
[10/24] Train loss=0.1751299649477005
[15/24] Train loss=0.16727891564369202
[20/24] Train loss=0.15283262729644775
Test set avg_accuracy=83.50% avg_sensitivity=83.72%, avg_specificity=83.43% avg_auc=91.00%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.175519 Test loss=0.377954 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.16034802794456482
[5/24] Train loss=0.16421131789684296
[10/24] Train loss=0.16966822743415833
[15/24] Train loss=0.17157408595085144
[20/24] Train loss=0.15247999131679535
Test set avg_accuracy=85.42% avg_sensitivity=56.34%, avg_specificity=95.09% avg_auc=88.36%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.172258 Test loss=0.376451 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.1557641178369522
[5/24] Train loss=0.1607932150363922
[10/24] Train loss=0.17005521059036255
[15/24] Train loss=0.16254808008670807
[20/24] Train loss=0.14911805093288422
Test set avg_accuracy=86.76% avg_sensitivity=73.97%, avg_specificity=91.01% avg_auc=91.22%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.170682 Test loss=0.327395 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1546953022480011
[5/24] Train loss=0.17019875347614288
[10/24] Train loss=0.172110915184021
[15/24] Train loss=0.1639474332332611
[20/24] Train loss=0.14938995242118835
Test set avg_accuracy=86.28% avg_sensitivity=77.93%, avg_specificity=89.05% avg_auc=91.37%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.167687 Test loss=0.330801 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.15277688205242157
[5/24] Train loss=0.17236310243606567
[10/24] Train loss=0.16088885068893433
[15/24] Train loss=0.1639622449874878
[20/24] Train loss=0.1522764414548874
Test set avg_accuracy=86.21% avg_sensitivity=76.16%, avg_specificity=89.55% avg_auc=91.29%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.168346 Test loss=0.333643 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.15753556787967682
[5/24] Train loss=0.16866455972194672
[10/24] Train loss=0.17185276746749878
[15/24] Train loss=0.1647917926311493
[20/24] Train loss=0.14289268851280212
Test set avg_accuracy=85.69% avg_sensitivity=58.06%, avg_specificity=94.88% avg_auc=88.75%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.168492 Test loss=0.366052 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.14558035135269165
[5/24] Train loss=0.1678796410560608
[10/24] Train loss=0.16568057239055634
[15/24] Train loss=0.15563924610614777
[20/24] Train loss=0.14805655181407928
Test set avg_accuracy=85.61% avg_sensitivity=67.55%, avg_specificity=91.62% avg_auc=89.18%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.163965 Test loss=0.352528 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.15411421656608582
[5/24] Train loss=0.16151612997055054
[10/24] Train loss=0.15362396836280823
[15/24] Train loss=0.1672549992799759
[20/24] Train loss=0.13852687180042267
Test set avg_accuracy=85.61% avg_sensitivity=67.50%, avg_specificity=91.64% avg_auc=89.42%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.163105 Test loss=0.356465 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1542847454547882
[5/24] Train loss=0.1694117933511734
[10/24] Train loss=0.16554823517799377
[15/24] Train loss=0.1588808000087738
[20/24] Train loss=0.14110292494297028
Test set avg_accuracy=85.92% avg_sensitivity=79.50%, avg_specificity=88.06% avg_auc=91.89%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.165510 Test loss=0.331212 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.15528424084186554
[5/24] Train loss=0.17024704813957214
[10/24] Train loss=0.15882381796836853
[15/24] Train loss=0.16384506225585938
[20/24] Train loss=0.14548464119434357
Test set avg_accuracy=83.54% avg_sensitivity=77.20%, avg_specificity=85.65% avg_auc=89.39%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.163633 Test loss=0.385929 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1504615843296051
[5/24] Train loss=0.16656425595283508
[10/24] Train loss=0.15834788978099823
[15/24] Train loss=0.16679225862026215
[20/24] Train loss=0.14807647466659546
Test set avg_accuracy=73.72% avg_sensitivity=88.21%, avg_specificity=68.91% avg_auc=86.67%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.167986 Test loss=0.577050 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.15555812418460846
[5/24] Train loss=0.17473499476909637
[10/24] Train loss=0.1522884964942932
[15/24] Train loss=0.16339397430419922
[20/24] Train loss=0.14277419447898865
Test set avg_accuracy=83.78% avg_sensitivity=79.08%, avg_specificity=85.34% avg_auc=89.60%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.166203 Test loss=0.385222 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.15496112406253815
[5/24] Train loss=0.16093775629997253
[10/24] Train loss=0.16047579050064087
[15/24] Train loss=0.1684473305940628
[20/24] Train loss=0.14907945692539215
Test set avg_accuracy=79.41% avg_sensitivity=87.38%, avg_specificity=76.77% avg_auc=89.65%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.166966 Test loss=0.463951 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15796537697315216
[5/24] Train loss=0.16299518942832947
[10/24] Train loss=0.16228216886520386
[15/24] Train loss=0.16503319144248962
[20/24] Train loss=0.15172749757766724
Test set avg_accuracy=86.99% avg_sensitivity=67.29%, avg_specificity=93.55% avg_auc=89.88%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.166631 Test loss=0.334996 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.14519540965557098
[5/24] Train loss=0.15757635235786438
[10/24] Train loss=0.1595699042081833
[15/24] Train loss=0.15532812476158142
[20/24] Train loss=0.1412995308637619
Test set avg_accuracy=86.45% avg_sensitivity=71.78%, avg_specificity=91.32% avg_auc=90.89%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.160307 Test loss=0.331503 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.1534513235092163
[5/24] Train loss=0.16599901020526886
[10/24] Train loss=0.1671556830406189
[15/24] Train loss=0.1621602475643158
[20/24] Train loss=0.13827241957187653
Test set avg_accuracy=86.81% avg_sensitivity=71.73%, avg_specificity=91.83% avg_auc=90.35%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.160591 Test loss=0.334884 Current lr=[0.000156543481933168]

[0/24] Train loss=0.14083975553512573
[5/24] Train loss=0.15660220384597778
[10/24] Train loss=0.15463879704475403
[15/24] Train loss=0.1536707729101181
[20/24] Train loss=0.1454523652791977
Test set avg_accuracy=86.22% avg_sensitivity=63.95%, avg_specificity=93.63% avg_auc=89.99%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.157989 Test loss=0.343913 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1549094021320343
[5/24] Train loss=0.15906187891960144
[10/24] Train loss=0.15583910048007965
[15/24] Train loss=0.15754134953022003
[20/24] Train loss=0.14444926381111145
Test set avg_accuracy=87.25% avg_sensitivity=72.30%, avg_specificity=92.23% avg_auc=90.42%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.158595 Test loss=0.326993 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.14848703145980835
[5/24] Train loss=0.1605510413646698
[10/24] Train loss=0.153614342212677
[15/24] Train loss=0.16926495730876923
[20/24] Train loss=0.14582549035549164
Test set avg_accuracy=86.54% avg_sensitivity=70.27%, avg_specificity=91.95% avg_auc=90.08%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.161395 Test loss=0.340894 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.1413431614637375
[5/24] Train loss=0.15882626175880432
[10/24] Train loss=0.14879561960697174
[15/24] Train loss=0.15802514553070068
[20/24] Train loss=0.14061832427978516
Test set avg_accuracy=86.74% avg_sensitivity=74.07%, avg_specificity=90.96% avg_auc=91.01%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.159475 Test loss=0.333662 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.14307263493537903
[5/24] Train loss=0.15629176795482635
[10/24] Train loss=0.1611470729112625
[15/24] Train loss=0.1595555543899536
[20/24] Train loss=0.13557526469230652
Test set avg_accuracy=85.81% avg_sensitivity=57.17%, avg_specificity=95.33% avg_auc=87.34%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.158605 Test loss=0.378568 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1442352682352066
[5/24] Train loss=0.15480011701583862
[10/24] Train loss=0.14981192350387573
[15/24] Train loss=0.15289932489395142
[20/24] Train loss=0.13287284970283508
Test set avg_accuracy=85.14% avg_sensitivity=49.77%, avg_specificity=96.91% avg_auc=86.82%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.155659 Test loss=0.410251 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1429988592863083
[5/24] Train loss=0.1546766608953476
[10/24] Train loss=0.14698302745819092
[15/24] Train loss=0.15063726902008057
[20/24] Train loss=0.1382862776517868
Test set avg_accuracy=85.07% avg_sensitivity=49.97%, avg_specificity=96.74% avg_auc=86.67%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.153057 Test loss=0.394280 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.13940967619419098
[5/24] Train loss=0.15166260302066803
[10/24] Train loss=0.1498577743768692
[15/24] Train loss=0.15450122952461243
[20/24] Train loss=0.13316363096237183
Test set avg_accuracy=86.81% avg_sensitivity=63.12%, avg_specificity=94.69% avg_auc=89.11%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.153512 Test loss=0.348348 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.13976044952869415
[5/24] Train loss=0.15138311684131622
[10/24] Train loss=0.14967578649520874
[15/24] Train loss=0.14857913553714752
[20/24] Train loss=0.13750623166561127
Test set avg_accuracy=85.22% avg_sensitivity=53.00%, avg_specificity=95.94% avg_auc=85.26%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.152271 Test loss=0.415628 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14490154385566711
[5/24] Train loss=0.15676242113113403
[10/24] Train loss=0.14930866658687592
[15/24] Train loss=0.15008768439292908
[20/24] Train loss=0.1341768205165863
Test set avg_accuracy=86.51% avg_sensitivity=58.89%, avg_specificity=95.70% avg_auc=88.73%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.151891 Test loss=0.368622 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14607486128807068
[5/24] Train loss=0.14619439840316772
[10/24] Train loss=0.14752094447612762
[15/24] Train loss=0.14531204104423523
[20/24] Train loss=0.1402292549610138
Test set avg_accuracy=86.00% avg_sensitivity=54.88%, avg_specificity=96.36% avg_auc=86.51%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.151874 Test loss=0.400165 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1414019614458084
[5/24] Train loss=0.15363256633281708
[10/24] Train loss=0.1458628922700882
[15/24] Train loss=0.1503329873085022
[20/24] Train loss=0.1348179429769516
Test set avg_accuracy=86.99% avg_sensitivity=63.02%, avg_specificity=94.97% avg_auc=90.69%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.149804 Test loss=0.340769 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.13630515336990356
[5/24] Train loss=0.14906783401966095
[10/24] Train loss=0.1410405933856964
[15/24] Train loss=0.14022240042686462
[20/24] Train loss=0.13176412880420685
Test set avg_accuracy=86.71% avg_sensitivity=72.98%, avg_specificity=91.27% avg_auc=90.82%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.148542 Test loss=0.337518 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.137188121676445
[5/24] Train loss=0.1453440636396408
[10/24] Train loss=0.1505965292453766
[15/24] Train loss=0.14540758728981018
[20/24] Train loss=0.12945526838302612
Test set avg_accuracy=87.11% avg_sensitivity=68.28%, avg_specificity=93.37% avg_auc=90.85%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.146414 Test loss=0.329558 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14066293835639954
[5/24] Train loss=0.14449937641620636
[10/24] Train loss=0.14115890860557556
[15/24] Train loss=0.15091007947921753
[20/24] Train loss=0.13245470821857452
Test set avg_accuracy=85.21% avg_sensitivity=72.67%, avg_specificity=89.38% avg_auc=90.34%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.147867 Test loss=0.359737 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1389087587594986
[5/24] Train loss=0.1501951813697815
[10/24] Train loss=0.13727185130119324
[15/24] Train loss=0.14864248037338257
[20/24] Train loss=0.1302436888217926
Test set avg_accuracy=86.88% avg_sensitivity=69.22%, avg_specificity=92.75% avg_auc=90.40%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.147480 Test loss=0.331207 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1357109397649765
[5/24] Train loss=0.14479008316993713
[10/24] Train loss=0.1380874663591385
[15/24] Train loss=0.14936451613903046
[20/24] Train loss=0.13190503418445587
Test set avg_accuracy=86.63% avg_sensitivity=68.23%, avg_specificity=92.75% avg_auc=90.20%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.145545 Test loss=0.344336 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1352260708808899
[5/24] Train loss=0.14328613877296448
[10/24] Train loss=0.13892650604248047
[15/24] Train loss=0.13715925812721252
[20/24] Train loss=0.1288808137178421
Test set avg_accuracy=86.35% avg_sensitivity=67.92%, avg_specificity=92.49% avg_auc=90.16%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.145017 Test loss=0.339294 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13186009228229523
[5/24] Train loss=0.1493775099515915
[10/24] Train loss=0.13885559141635895
[15/24] Train loss=0.13890361785888672
[20/24] Train loss=0.1331653892993927
Test set avg_accuracy=86.61% avg_sensitivity=72.82%, avg_specificity=91.20% avg_auc=90.93%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.145614 Test loss=0.333025 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13224348425865173
[5/24] Train loss=0.14245206117630005
[10/24] Train loss=0.1391402631998062
[15/24] Train loss=0.13684166967868805
[20/24] Train loss=0.12605130672454834
Test set avg_accuracy=86.65% avg_sensitivity=70.06%, avg_specificity=92.17% avg_auc=90.75%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.142931 Test loss=0.333352 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13703738152980804
[5/24] Train loss=0.14151090383529663
[10/24] Train loss=0.13941192626953125
[15/24] Train loss=0.13233575224876404
[20/24] Train loss=0.12233775109052658
Test set avg_accuracy=86.51% avg_sensitivity=71.67%, avg_specificity=91.45% avg_auc=90.66%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.141117 Test loss=0.337716 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1362900286912918
[5/24] Train loss=0.1380416303873062
[10/24] Train loss=0.1392652988433838
[15/24] Train loss=0.1339544951915741
[20/24] Train loss=0.12276382744312286
Test set avg_accuracy=86.71% avg_sensitivity=69.07%, avg_specificity=92.57% avg_auc=90.59%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.138999 Test loss=0.330750 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1294442117214203
[5/24] Train loss=0.1373758763074875
[10/24] Train loss=0.12917460501194
[15/24] Train loss=0.12987715005874634
[20/24] Train loss=0.12292630225419998
Test set avg_accuracy=86.60% avg_sensitivity=73.29%, avg_specificity=91.03% avg_auc=90.71%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.136706 Test loss=0.339277 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13006162643432617
[5/24] Train loss=0.13684383034706116
[10/24] Train loss=0.13557098805904388
[15/24] Train loss=0.13318490982055664
[20/24] Train loss=0.12076817452907562
Test set avg_accuracy=86.85% avg_sensitivity=72.93%, avg_specificity=91.48% avg_auc=89.93%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.137087 Test loss=0.341671 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.12689724564552307
[5/24] Train loss=0.1389090120792389
[10/24] Train loss=0.13290022313594818
[15/24] Train loss=0.1298673003911972
[20/24] Train loss=0.12069462984800339
Test set avg_accuracy=86.39% avg_sensitivity=66.82%, avg_specificity=92.90% avg_auc=89.80%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.135017 Test loss=0.338890 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.12817628681659698
[5/24] Train loss=0.13792498409748077
[10/24] Train loss=0.12861475348472595
[15/24] Train loss=0.12751299142837524
[20/24] Train loss=0.12000980973243713
Test set avg_accuracy=87.12% avg_sensitivity=70.16%, avg_specificity=92.76% avg_auc=90.21%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.134115 Test loss=0.330119 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.12529534101486206
[5/24] Train loss=0.13750308752059937
[10/24] Train loss=0.1283433884382248
[15/24] Train loss=0.125192329287529
[20/24] Train loss=0.11878620088100433
Test set avg_accuracy=87.19% avg_sensitivity=70.74%, avg_specificity=92.66% avg_auc=90.75%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.132425 Test loss=0.324541 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12327326089143753
[5/24] Train loss=0.1339947134256363
[10/24] Train loss=0.12919224798679352
[15/24] Train loss=0.12461884319782257
[20/24] Train loss=0.11909817904233932
Test set avg_accuracy=86.93% avg_sensitivity=68.65%, avg_specificity=93.01% avg_auc=90.23%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.131596 Test loss=0.334684 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12142911553382874
[5/24] Train loss=0.13492262363433838
[10/24] Train loss=0.13327986001968384
[15/24] Train loss=0.12589651346206665
[20/24] Train loss=0.11887043714523315
Test set avg_accuracy=87.16% avg_sensitivity=70.06%, avg_specificity=92.85% avg_auc=90.44%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.131522 Test loss=0.329176 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12044961005449295
[5/24] Train loss=0.13588981330394745
[10/24] Train loss=0.13172516226768494
[15/24] Train loss=0.12433643639087677
[20/24] Train loss=0.1161070242524147
Test set avg_accuracy=86.64% avg_sensitivity=74.13%, avg_specificity=90.80% avg_auc=90.06%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.130923 Test loss=0.346474 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1227850615978241
[5/24] Train loss=0.13513585925102234
[10/24] Train loss=0.1273275464773178
[15/24] Train loss=0.12621329724788666
[20/24] Train loss=0.1178353875875473
Test set avg_accuracy=86.80% avg_sensitivity=70.32%, avg_specificity=92.28% avg_auc=89.97%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.131464 Test loss=0.339818 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12409164756536484
[5/24] Train loss=0.133063405752182
[10/24] Train loss=0.13117913901805878
[15/24] Train loss=0.12568528950214386
[20/24] Train loss=0.11880531907081604
Test set avg_accuracy=86.95% avg_sensitivity=73.50%, avg_specificity=91.43% avg_auc=90.12%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.130776 Test loss=0.338123 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12181539833545685
[5/24] Train loss=0.13528850674629211
[10/24] Train loss=0.12653188407421112
[15/24] Train loss=0.12257041782140732
[20/24] Train loss=0.1180495023727417
Test set avg_accuracy=87.08% avg_sensitivity=76.21%, avg_specificity=90.70% avg_auc=90.03%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.130338 Test loss=0.341970 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.11753200739622116
[5/24] Train loss=0.1352030485868454
[10/24] Train loss=0.12491197884082794
[15/24] Train loss=0.12208656221628189
[20/24] Train loss=0.11673738062381744
Test set avg_accuracy=86.80% avg_sensitivity=73.97%, avg_specificity=91.06% avg_auc=89.91%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.129444 Test loss=0.340752 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1183718740940094
[5/24] Train loss=0.13376717269420624
[10/24] Train loss=0.12441933155059814
[15/24] Train loss=0.12278586626052856
[20/24] Train loss=0.11517207324504852
Test set avg_accuracy=86.78% avg_sensitivity=74.60%, avg_specificity=90.84% avg_auc=90.30%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.128105 Test loss=0.337237 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.11921224743127823
[5/24] Train loss=0.13190658390522003
[10/24] Train loss=0.12464409321546555
[15/24] Train loss=0.11998342722654343
[20/24] Train loss=0.11450894922018051
Test set avg_accuracy=87.12% avg_sensitivity=72.40%, avg_specificity=92.02% avg_auc=90.21%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.128158 Test loss=0.328229 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.11626162379980087
[5/24] Train loss=0.13457489013671875
[10/24] Train loss=0.12367083877325058
[15/24] Train loss=0.12044956535100937
[20/24] Train loss=0.11714489758014679
Test set avg_accuracy=87.37% avg_sensitivity=73.34%, avg_specificity=92.04% avg_auc=90.23%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.127960 Test loss=0.325769 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.11643383651971817
[5/24] Train loss=0.13222847878932953
[10/24] Train loss=0.12577977776527405
[15/24] Train loss=0.12091702222824097
[20/24] Train loss=0.1156238317489624
Test set avg_accuracy=87.43% avg_sensitivity=73.34%, avg_specificity=92.12% avg_auc=90.00%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.127425 Test loss=0.328336 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.11522997915744781
[5/24] Train loss=0.1306883692741394
[10/24] Train loss=0.12759366631507874
[15/24] Train loss=0.11995929479598999
[20/24] Train loss=0.11565865576267242
Test set avg_accuracy=87.50% avg_sensitivity=73.50%, avg_specificity=92.16% avg_auc=90.30%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.126487 Test loss=0.327267 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.11445765942335129
[5/24] Train loss=0.13051430881023407
[10/24] Train loss=0.12236319482326508
[15/24] Train loss=0.12026336789131165
[20/24] Train loss=0.11221697181463242
Test set avg_accuracy=87.11% avg_sensitivity=72.67%, avg_specificity=91.91% avg_auc=90.32%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.125604 Test loss=0.328956 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.11536331474781036
[5/24] Train loss=0.1331772357225418
[10/24] Train loss=0.12434675544500351
[15/24] Train loss=0.12074907124042511
[20/24] Train loss=0.11208979785442352
Test set avg_accuracy=87.16% avg_sensitivity=74.54%, avg_specificity=91.36% avg_auc=90.22%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.125722 Test loss=0.330968 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.11518900096416473
[5/24] Train loss=0.12968681752681732
[10/24] Train loss=0.12203144282102585
[15/24] Train loss=0.1179121881723404
[20/24] Train loss=0.11246011406183243
Test set avg_accuracy=87.25% avg_sensitivity=72.25%, avg_specificity=92.24% avg_auc=90.17%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.125195 Test loss=0.326974 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1173265352845192
[5/24] Train loss=0.12853127717971802
[10/24] Train loss=0.12225639820098877
[15/24] Train loss=0.11843729764223099
[20/24] Train loss=0.11137047410011292
Test set avg_accuracy=87.37% avg_sensitivity=74.39%, avg_specificity=91.69% avg_auc=90.15%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.124936 Test loss=0.331355 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.11520485579967499
[5/24] Train loss=0.12989789247512817
[10/24] Train loss=0.12406919151544571
[15/24] Train loss=0.11924950778484344
[20/24] Train loss=0.1118135079741478
Test set avg_accuracy=87.14% avg_sensitivity=71.21%, avg_specificity=92.43% avg_auc=89.88%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.124647 Test loss=0.329021 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11467880010604858
[5/24] Train loss=0.12940281629562378
[10/24] Train loss=0.12238375842571259
[15/24] Train loss=0.11852730810642242
[20/24] Train loss=0.11252652853727341
Test set avg_accuracy=87.33% avg_sensitivity=74.70%, avg_specificity=91.53% avg_auc=89.99%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.124071 Test loss=0.332544 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.11664622277021408
[5/24] Train loss=0.12778568267822266
[10/24] Train loss=0.12002195417881012
[15/24] Train loss=0.11641393601894379
[20/24] Train loss=0.1131356805562973
Test set avg_accuracy=87.33% avg_sensitivity=73.24%, avg_specificity=92.02% avg_auc=89.91%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.123370 Test loss=0.330978 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1131519228219986
[5/24] Train loss=0.13072910904884338
[10/24] Train loss=0.12343151122331619
[15/24] Train loss=0.119055837392807
[20/24] Train loss=0.11244514584541321
Test set avg_accuracy=87.21% avg_sensitivity=72.56%, avg_specificity=92.09% avg_auc=89.85%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.123631 Test loss=0.330442 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.11321119964122772
[5/24] Train loss=0.1284404844045639
[10/24] Train loss=0.12283748388290405
[15/24] Train loss=0.11515390872955322
[20/24] Train loss=0.11168534308671951
Test set avg_accuracy=87.19% avg_sensitivity=73.55%, avg_specificity=91.72% avg_auc=89.89%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.123320 Test loss=0.331445 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1149299144744873
[5/24] Train loss=0.12796930968761444
[10/24] Train loss=0.12207256257534027
[15/24] Train loss=0.11582212895154953
[20/24] Train loss=0.11107936501502991
Test set avg_accuracy=87.16% avg_sensitivity=73.14%, avg_specificity=91.83% avg_auc=89.80%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.123195 Test loss=0.331912 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11425665020942688
[5/24] Train loss=0.12795431911945343
[10/24] Train loss=0.12125525623559952
[15/24] Train loss=0.11842000484466553
[20/24] Train loss=0.11166057735681534
Test set avg_accuracy=87.14% avg_sensitivity=72.72%, avg_specificity=91.93% avg_auc=89.78%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.123035 Test loss=0.332143 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11333317309617996
[5/24] Train loss=0.12424010783433914
[10/24] Train loss=0.12032272666692734
[15/24] Train loss=0.11898425966501236
[20/24] Train loss=0.11482832580804825
Test set avg_accuracy=87.25% avg_sensitivity=72.87%, avg_specificity=92.04% avg_auc=89.79%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.123105 Test loss=0.332113 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11445875465869904
[5/24] Train loss=0.1284269094467163
[10/24] Train loss=0.11969857662916183
[15/24] Train loss=0.11654169112443924
[20/24] Train loss=0.11192392557859421
Test set avg_accuracy=87.28% avg_sensitivity=73.29%, avg_specificity=91.93% avg_auc=89.80%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.123423 Test loss=0.332122 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11468437314033508
[5/24] Train loss=0.12932747602462769
[10/24] Train loss=0.12041580677032471
[15/24] Train loss=0.11691123992204666
[20/24] Train loss=0.11215250939130783
Test set avg_accuracy=87.24% avg_sensitivity=73.24%, avg_specificity=91.90% avg_auc=89.81%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.123184 Test loss=0.332046 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1155446246266365
[5/24] Train loss=0.12878353893756866
[10/24] Train loss=0.12147798389196396
[15/24] Train loss=0.11520896852016449
[20/24] Train loss=0.1129448339343071
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=87.24% avg_sensitivity=73.24%, avg_specificity=91.90% avg_auc=89.80%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.123302 Test loss=0.332148 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=87.67% sen=74.65%, spe=92.00%, auc=92.90%!
Fold[2] Avg_overlap=0.72%(0.20742661538483748)
[0/24] Train loss=0.756462037563324
[5/24] Train loss=0.7459912896156311
[10/24] Train loss=0.7424872517585754
[15/24] Train loss=0.7305940389633179
[20/24] Train loss=0.7223474383354187
Test set avg_accuracy=55.08% avg_sensitivity=50.00%, avg_specificity=57.00% avg_auc=56.43%
Best model saved!! Metric=-107.49144199311648!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.740350 Test loss=0.674792 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7301551103591919
[5/24] Train loss=0.7219889760017395
[10/24] Train loss=0.7137718796730042
[15/24] Train loss=0.7065075039863586
[20/24] Train loss=0.6984642148017883
Test set avg_accuracy=64.34% avg_sensitivity=60.00%, avg_specificity=65.98% avg_auc=67.96%
Best model saved!! Metric=-67.72168330202848!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.710807 Test loss=0.626167 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6963554620742798
[5/24] Train loss=0.6915536522865295
[10/24] Train loss=0.6854175925254822
[15/24] Train loss=0.674197793006897
[20/24] Train loss=0.6590580344200134
Test set avg_accuracy=69.44% avg_sensitivity=67.44%, avg_specificity=70.20% avg_auc=74.77%
Best model saved!! Metric=-44.154006122883814!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.682589 Test loss=0.594347 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6711405515670776
[5/24] Train loss=0.6682486534118652
[10/24] Train loss=0.6624953150749207
[15/24] Train loss=0.6467581987380981
[20/24] Train loss=0.6386116147041321
Test set avg_accuracy=71.51% avg_sensitivity=72.09%, avg_specificity=71.29% avg_auc=78.41%
Best model saved!! Metric=-32.699347898071636!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.656376 Test loss=0.571082 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6368653774261475
[5/24] Train loss=0.6388548612594604
[10/24] Train loss=0.6455544829368591
[15/24] Train loss=0.618833601474762
[20/24] Train loss=0.6053928136825562
Test set avg_accuracy=74.60% avg_sensitivity=75.12%, avg_specificity=74.40% avg_auc=81.42%
Best model saved!! Metric=-20.469137167239566!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.628025 Test loss=0.543765 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6051005721092224
[5/24] Train loss=0.6124778985977173
[10/24] Train loss=0.6107510328292847
[15/24] Train loss=0.5914050340652466
[20/24] Train loss=0.5747205018997192
Test set avg_accuracy=76.63% avg_sensitivity=76.49%, avg_specificity=76.68% avg_auc=83.46%
Best model saved!! Metric=-12.740234712909938!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.600185 Test loss=0.515034 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5754528641700745
[5/24] Train loss=0.5800253748893738
[10/24] Train loss=0.5890023708343506
[15/24] Train loss=0.5561310052871704
[20/24] Train loss=0.5362755656242371
Test set avg_accuracy=78.05% avg_sensitivity=77.77%, avg_specificity=78.15% avg_auc=84.84%
Best model saved!! Metric=-7.190781027976556!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.570797 Test loss=0.494187 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5444608330726624
[5/24] Train loss=0.5444948077201843
[10/24] Train loss=0.5604755878448486
[15/24] Train loss=0.5255179405212402
[20/24] Train loss=0.5049116015434265
Test set avg_accuracy=79.67% avg_sensitivity=77.68%, avg_specificity=80.43% avg_auc=86.16%
Best model saved!! Metric=-2.056663464388336!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.539450 Test loss=0.469216 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5104249119758606
[5/24] Train loss=0.5171849131584167
[10/24] Train loss=0.5218753218650818
[15/24] Train loss=0.4964796006679535
[20/24] Train loss=0.4730527102947235
Test set avg_accuracy=81.46% avg_sensitivity=76.87%, avg_specificity=83.20% avg_auc=87.42%
Best model saved!! Metric=2.9427241541659868!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.507811 Test loss=0.444290 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.48332419991493225
[5/24] Train loss=0.48903390765190125
[10/24] Train loss=0.4951539635658264
[15/24] Train loss=0.470093697309494
[20/24] Train loss=0.44160303473472595
Test set avg_accuracy=83.09% avg_sensitivity=75.55%, avg_specificity=85.94% avg_auc=88.46%
Best model saved!! Metric=7.031873327511974!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.477755 Test loss=0.418808 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4466572105884552
[5/24] Train loss=0.46375346183776855
[10/24] Train loss=0.467436820268631
[15/24] Train loss=0.4384537935256958
[20/24] Train loss=0.41409429907798767
Test set avg_accuracy=84.53% avg_sensitivity=75.02%, avg_specificity=88.13% avg_auc=89.43%
Best model saved!! Metric=11.120969809065159!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.446567 Test loss=0.400551 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.41849035024642944
[5/24] Train loss=0.4281824827194214
[10/24] Train loss=0.4460682272911072
[15/24] Train loss=0.41231226921081543
[20/24] Train loss=0.38379326462745667
Test set avg_accuracy=85.52% avg_sensitivity=74.31%, avg_specificity=89.77% avg_auc=90.20%
Best model saved!! Metric=13.803423716819694!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.419206 Test loss=0.379693 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3942123055458069
[5/24] Train loss=0.40781843662261963
[10/24] Train loss=0.4206000864505768
[15/24] Train loss=0.3887123167514801
[20/24] Train loss=0.36110061407089233
Test set avg_accuracy=85.56% avg_sensitivity=76.07%, avg_specificity=89.16% avg_auc=90.78%
Best model saved!! Metric=15.563333341310226!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.395511 Test loss=0.369107 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3737376034259796
[5/24] Train loss=0.3863002061843872
[10/24] Train loss=0.40544116497039795
[15/24] Train loss=0.3750913143157959
[20/24] Train loss=0.3423919081687927
Test set avg_accuracy=86.56% avg_sensitivity=72.70%, avg_specificity=91.81% avg_auc=90.95%
Best model saved!! Metric=16.024857585916422!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.374926 Test loss=0.349885 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3517344295978546
[5/24] Train loss=0.369470477104187
[10/24] Train loss=0.3881045877933502
[15/24] Train loss=0.36124134063720703
[20/24] Train loss=0.32096248865127563
Test set avg_accuracy=86.28% avg_sensitivity=77.82%, avg_specificity=89.48% avg_auc=91.74%
Best model saved!! Metric=19.317079045311587!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.357675 Test loss=0.351431 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3387660086154938
[5/24] Train loss=0.35060054063796997
[10/24] Train loss=0.3696545362472534
[15/24] Train loss=0.34148716926574707
[20/24] Train loss=0.3064371347427368
Test set avg_accuracy=86.89% avg_sensitivity=73.70%, avg_specificity=91.89% avg_auc=91.78%
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.342046 Test loss=0.330276 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3203373849391937
[5/24] Train loss=0.33074939250946045
[10/24] Train loss=0.3599882423877716
[15/24] Train loss=0.336874783039093
[20/24] Train loss=0.2956984341144562
Test set avg_accuracy=86.82% avg_sensitivity=75.45%, avg_specificity=91.13% avg_auc=92.12%
Best model saved!! Metric=19.52589555662388!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.328842 Test loss=0.326859 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.30639827251434326
[5/24] Train loss=0.3244822323322296
[10/24] Train loss=0.34653639793395996
[15/24] Train loss=0.32292577624320984
[20/24] Train loss=0.28336793184280396
Test set avg_accuracy=87.06% avg_sensitivity=76.92%, avg_specificity=90.90% avg_auc=92.63%
Best model saved!! Metric=21.50106203432688!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.317949 Test loss=0.320344 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3001967668533325
[5/24] Train loss=0.31099778413772583
[10/24] Train loss=0.3467530608177185
[15/24] Train loss=0.31566786766052246
[20/24] Train loss=0.2713908851146698
Test set avg_accuracy=87.10% avg_sensitivity=76.68%, avg_specificity=91.04% avg_auc=92.73%
Best model saved!! Metric=21.55019030644732!!
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.309279 Test loss=0.314347 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.29139629006385803
[5/24] Train loss=0.29944905638694763
[10/24] Train loss=0.3334938883781433
[15/24] Train loss=0.30894091725349426
[20/24] Train loss=0.259998083114624
Test set avg_accuracy=87.54% avg_sensitivity=76.16%, avg_specificity=91.85% avg_auc=93.02%
Best model saved!! Metric=22.570110684672457!!
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.298682 Test loss=0.306181 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.27732840180397034
[5/24] Train loss=0.2977071702480316
[10/24] Train loss=0.3263290822505951
[15/24] Train loss=0.3019622564315796
[20/24] Train loss=0.25864502787590027
Test set avg_accuracy=87.50% avg_sensitivity=75.26%, avg_specificity=92.14% avg_auc=93.02%
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.291171 Test loss=0.301579 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.270187646150589
[5/24] Train loss=0.29071319103240967
[10/24] Train loss=0.32383042573928833
[15/24] Train loss=0.29897528886795044
[20/24] Train loss=0.25591206550598145
Test set avg_accuracy=87.72% avg_sensitivity=74.69%, avg_specificity=92.66% avg_auc=93.26%
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.284844 Test loss=0.297671 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.266360878944397
[5/24] Train loss=0.272809237241745
[10/24] Train loss=0.3166857063770294
[15/24] Train loss=0.29091838002204895
[20/24] Train loss=0.24830199778079987
Test set avg_accuracy=88.01% avg_sensitivity=74.31%, avg_specificity=93.20% avg_auc=93.32%
Best model saved!! Metric=22.83671564566015!!
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.278486 Test loss=0.292969 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2603979706764221
[5/24] Train loss=0.26719367504119873
[10/24] Train loss=0.308590292930603
[15/24] Train loss=0.2865469753742218
[20/24] Train loss=0.2417164444923401
Test set avg_accuracy=87.97% avg_sensitivity=71.90%, avg_specificity=94.06% avg_auc=93.39%
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.272004 Test loss=0.289971 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.26257380843162537
[5/24] Train loss=0.2613815367221832
[10/24] Train loss=0.3057890832424164
[15/24] Train loss=0.2791294753551483
[20/24] Train loss=0.23573850095272064
Test set avg_accuracy=87.83% avg_sensitivity=64.12%, avg_specificity=96.80% avg_auc=93.01%
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.266172 Test loss=0.306993 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.25985056161880493
[5/24] Train loss=0.2550338804721832
[10/24] Train loss=0.30432337522506714
[15/24] Train loss=0.2761398255825043
[20/24] Train loss=0.23117457330226898
Test set avg_accuracy=87.97% avg_sensitivity=72.65%, avg_specificity=93.77% avg_auc=93.24%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.261817 Test loss=0.293064 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.25130975246429443
[5/24] Train loss=0.24993020296096802
[10/24] Train loss=0.2920760214328766
[15/24] Train loss=0.2725188732147217
[20/24] Train loss=0.2266373336315155
Test set avg_accuracy=87.85% avg_sensitivity=69.57%, avg_specificity=94.78% avg_auc=93.19%
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.256881 Test loss=0.292074 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2397679090499878
[5/24] Train loss=0.24081647396087646
[10/24] Train loss=0.28660792112350464
[15/24] Train loss=0.26511386036872864
[20/24] Train loss=0.22527791559696198
Test set avg_accuracy=88.06% avg_sensitivity=68.20%, avg_specificity=95.58% avg_auc=93.06%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.252383 Test loss=0.295240 Current lr=[0.000210185142098938]

[0/24] Train loss=0.25006115436553955
[5/24] Train loss=0.24051044881343842
[10/24] Train loss=0.29213955998420715
[15/24] Train loss=0.265432745218277
[20/24] Train loss=0.22156266868114471
Test set avg_accuracy=87.43% avg_sensitivity=64.93%, avg_specificity=95.96% avg_auc=93.49%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.251554 Test loss=0.297072 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.24143196642398834
[5/24] Train loss=0.22916057705879211
[10/24] Train loss=0.2858242690563202
[15/24] Train loss=0.24830253422260284
[20/24] Train loss=0.22173096239566803
Test set avg_accuracy=88.14% avg_sensitivity=70.28%, avg_specificity=94.90% avg_auc=93.34%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.243748 Test loss=0.292141 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2301405966281891
[5/24] Train loss=0.22532860934734344
[10/24] Train loss=0.2797703444957733
[15/24] Train loss=0.2622814178466797
[20/24] Train loss=0.21289648115634918
Test set avg_accuracy=88.41% avg_sensitivity=74.41%, avg_specificity=93.72% avg_auc=93.66%
Best model saved!! Metric=24.195737690417246!!
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.242237 Test loss=0.283095 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.23008224368095398
[5/24] Train loss=0.21746592223644257
[10/24] Train loss=0.27532336115837097
[15/24] Train loss=0.2511764168739319
[20/24] Train loss=0.21646739542484283
Test set avg_accuracy=85.69% avg_sensitivity=55.17%, avg_specificity=97.25% avg_auc=92.35%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.237429 Test loss=0.337016 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2321629375219345
[5/24] Train loss=0.2162245661020279
[10/24] Train loss=0.27572494745254517
[15/24] Train loss=0.25039413571357727
[20/24] Train loss=0.2162785679101944
Test set avg_accuracy=86.18% avg_sensitivity=58.58%, avg_specificity=96.64% avg_auc=92.17%
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.234986 Test loss=0.333779 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.22840487957000732
[5/24] Train loss=0.22313669323921204
[10/24] Train loss=0.2795337736606598
[15/24] Train loss=0.23481418192386627
[20/24] Train loss=0.2068854719400406
Test set avg_accuracy=87.04% avg_sensitivity=69.72%, avg_specificity=93.61% avg_auc=92.31%
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.236256 Test loss=0.311305 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.21944378316402435
[5/24] Train loss=0.22109785676002502
[10/24] Train loss=0.26513347029685974
[15/24] Train loss=0.24542364478111267
[20/24] Train loss=0.22668860852718353
Test set avg_accuracy=82.01% avg_sensitivity=40.62%, avg_specificity=97.68% avg_auc=89.21%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.234162 Test loss=0.434640 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.23172001540660858
[5/24] Train loss=0.20609503984451294
[10/24] Train loss=0.2621925473213196
[15/24] Train loss=0.23550598323345184
[20/24] Train loss=0.21268603205680847
Test set avg_accuracy=87.75% avg_sensitivity=75.83%, avg_specificity=92.26% avg_auc=93.09%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.228961 Test loss=0.296827 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.211206316947937
[5/24] Train loss=0.20383784174919128
[10/24] Train loss=0.26131629943847656
[15/24] Train loss=0.22958716750144958
[20/24] Train loss=0.20527732372283936
Test set avg_accuracy=87.20% avg_sensitivity=64.98%, avg_specificity=95.62% avg_auc=92.67%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.223442 Test loss=0.312380 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.20068852603435516
[5/24] Train loss=0.21290548145771027
[10/24] Train loss=0.25791171193122864
[15/24] Train loss=0.22962097823619843
[20/24] Train loss=0.20467960834503174
Test set avg_accuracy=87.43% avg_sensitivity=76.11%, avg_specificity=91.72% avg_auc=92.90%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.223177 Test loss=0.297259 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.21409544348716736
[5/24] Train loss=0.20326201617717743
[10/24] Train loss=0.2548021078109741
[15/24] Train loss=0.2278914600610733
[20/24] Train loss=0.1973220258951187
Test set avg_accuracy=85.76% avg_sensitivity=66.40%, avg_specificity=93.09% avg_auc=90.84%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.218665 Test loss=0.339221 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.210410013794899
[5/24] Train loss=0.19894219934940338
[10/24] Train loss=0.25017496943473816
[15/24] Train loss=0.22659307718276978
[20/24] Train loss=0.20415805280208588
Test set avg_accuracy=86.73% avg_sensitivity=61.14%, avg_specificity=96.43% avg_auc=91.28%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.213993 Test loss=0.334681 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.19048355519771576
[5/24] Train loss=0.19536639750003815
[10/24] Train loss=0.25219130516052246
[15/24] Train loss=0.2307092249393463
[20/24] Train loss=0.19912117719650269
Test set avg_accuracy=86.72% avg_sensitivity=60.76%, avg_specificity=96.55% avg_auc=91.96%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.213404 Test loss=0.339691 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.20394571125507355
[5/24] Train loss=0.1955668032169342
[10/24] Train loss=0.24913010001182556
[15/24] Train loss=0.2121993899345398
[20/24] Train loss=0.1965543031692505
Test set avg_accuracy=87.42% avg_sensitivity=73.51%, avg_specificity=92.69% avg_auc=91.92%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.210794 Test loss=0.309079 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.20225583016872406
[5/24] Train loss=0.1810295581817627
[10/24] Train loss=0.24306854605674744
[15/24] Train loss=0.2291775345802307
[20/24] Train loss=0.1900140643119812
Test set avg_accuracy=87.43% avg_sensitivity=76.45%, avg_specificity=91.60% avg_auc=92.90%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.207956 Test loss=0.300846 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.19626300036907196
[5/24] Train loss=0.17641621828079224
[10/24] Train loss=0.2546289265155792
[15/24] Train loss=0.2258027046918869
[20/24] Train loss=0.20210331678390503
Test set avg_accuracy=85.82% avg_sensitivity=59.86%, avg_specificity=95.66% avg_auc=90.66%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.209759 Test loss=0.348994 Current lr=[0.00029967723776099]

[0/24] Train loss=0.19291837513446808
[5/24] Train loss=0.18945510685443878
[10/24] Train loss=0.25171658396720886
[15/24] Train loss=0.21726733446121216
[20/24] Train loss=0.19151325523853302
Test set avg_accuracy=87.68% avg_sensitivity=76.97%, avg_specificity=91.74% avg_auc=93.02%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.208660 Test loss=0.295604 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.1966327428817749
[5/24] Train loss=0.17475640773773193
[10/24] Train loss=0.258687824010849
[15/24] Train loss=0.2155555933713913
[20/24] Train loss=0.19068770110607147
Test set avg_accuracy=84.95% avg_sensitivity=78.77%, avg_specificity=87.29% avg_auc=90.92%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.205273 Test loss=0.352595 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.19480250775814056
[5/24] Train loss=0.18012851476669312
[10/24] Train loss=0.25676319003105164
[15/24] Train loss=0.21802839636802673
[20/24] Train loss=0.1942959725856781
Test set avg_accuracy=76.55% avg_sensitivity=80.90%, avg_specificity=74.90% avg_auc=86.88%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.207141 Test loss=0.481868 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2025168240070343
[5/24] Train loss=0.1751144826412201
[10/24] Train loss=0.22403499484062195
[15/24] Train loss=0.22512783110141754
[20/24] Train loss=0.18970564007759094
Test set avg_accuracy=83.02% avg_sensitivity=44.17%, avg_specificity=97.74% avg_auc=88.72%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.204081 Test loss=0.437646 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.18831270933151245
[5/24] Train loss=0.18306267261505127
[10/24] Train loss=0.24381417036056519
[15/24] Train loss=0.21470093727111816
[20/24] Train loss=0.2023652195930481
Test set avg_accuracy=81.77% avg_sensitivity=84.17%, avg_specificity=80.86% avg_auc=90.08%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.203558 Test loss=0.415997 Current lr=[0.000298904600941902]

[0/24] Train loss=0.19741284847259521
[5/24] Train loss=0.1696394681930542
[10/24] Train loss=0.24600030481815338
[15/24] Train loss=0.21440427005290985
[20/24] Train loss=0.1829153299331665
Test set avg_accuracy=83.78% avg_sensitivity=81.56%, avg_specificity=84.61% avg_auc=90.88%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.202778 Test loss=0.373883 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.19008465111255646
[5/24] Train loss=0.19796325266361237
[10/24] Train loss=0.21936337649822235
[15/24] Train loss=0.21635958552360535
[20/24] Train loss=0.18005311489105225
Test set avg_accuracy=81.17% avg_sensitivity=37.01%, avg_specificity=97.90% avg_auc=85.20%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.199407 Test loss=0.503942 Current lr=[0.000297555943323901]

[0/24] Train loss=0.179592102766037
[5/24] Train loss=0.19295205175876617
[10/24] Train loss=0.2327832132577896
[15/24] Train loss=0.21195131540298462
[20/24] Train loss=0.18707740306854248
Test set avg_accuracy=86.76% avg_sensitivity=65.55%, avg_specificity=94.79% avg_auc=91.82%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.198000 Test loss=0.321886 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.17825175821781158
[5/24] Train loss=0.16913160681724548
[10/24] Train loss=0.22020579874515533
[15/24] Train loss=0.206422820687294
[20/24] Train loss=0.18819187581539154
Test set avg_accuracy=86.94% avg_sensitivity=80.43%, avg_specificity=89.41% avg_auc=93.02%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.192292 Test loss=0.303942 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.1847768872976303
[5/24] Train loss=0.16897770762443542
[10/24] Train loss=0.22150321304798126
[15/24] Train loss=0.2187541127204895
[20/24] Train loss=0.1796165555715561
Test set avg_accuracy=87.08% avg_sensitivity=65.02%, avg_specificity=95.44% avg_auc=90.95%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.193694 Test loss=0.325149 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.1829300969839096
[5/24] Train loss=0.16914303600788116
[10/24] Train loss=0.21481838822364807
[15/24] Train loss=0.21593962609767914
[20/24] Train loss=0.1936706304550171
Test set avg_accuracy=85.76% avg_sensitivity=57.58%, avg_specificity=96.43% avg_auc=88.94%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.191839 Test loss=0.368247 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.18374103307724
[5/24] Train loss=0.17909161746501923
[10/24] Train loss=0.23192401230335236
[15/24] Train loss=0.21269087493419647
[20/24] Train loss=0.1700897514820099
Test set avg_accuracy=85.43% avg_sensitivity=82.65%, avg_specificity=86.48% avg_auc=92.26%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.193421 Test loss=0.341348 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.18691585958003998
[5/24] Train loss=0.1660887449979782
[10/24] Train loss=0.21975527703762054
[15/24] Train loss=0.2135610431432724
[20/24] Train loss=0.18453355133533478
Test set avg_accuracy=86.54% avg_sensitivity=79.62%, avg_specificity=89.16% avg_auc=92.76%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.194637 Test loss=0.316876 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.19793522357940674
[5/24] Train loss=0.17845425009727478
[10/24] Train loss=0.23402202129364014
[15/24] Train loss=0.22756972908973694
[20/24] Train loss=0.18119461834430695
Test set avg_accuracy=87.10% avg_sensitivity=74.88%, avg_specificity=91.72% avg_auc=92.73%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.196352 Test loss=0.307915 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.1841713786125183
[5/24] Train loss=0.16053053736686707
[10/24] Train loss=0.22285334765911102
[15/24] Train loss=0.20196375250816345
[20/24] Train loss=0.17639310657978058
Test set avg_accuracy=86.82% avg_sensitivity=75.59%, avg_specificity=91.08% avg_auc=92.00%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.189519 Test loss=0.317120 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18329428136348724
[5/24] Train loss=0.16342367231845856
[10/24] Train loss=0.2529461085796356
[15/24] Train loss=0.2145691066980362
[20/24] Train loss=0.17053070664405823
Test set avg_accuracy=87.72% avg_sensitivity=77.73%, avg_specificity=91.51% avg_auc=93.31%
Best model saved!! Metric=24.269534584783372!!
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.195018 Test loss=0.291095 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.17821142077445984
[5/24] Train loss=0.16675205528736115
[10/24] Train loss=0.2103528082370758
[15/24] Train loss=0.20378628373146057
[20/24] Train loss=0.17234578728675842
Test set avg_accuracy=86.63% avg_sensitivity=67.35%, avg_specificity=93.93% avg_auc=91.52%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.185364 Test loss=0.323683 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.17745080590248108
[5/24] Train loss=0.1601148098707199
[10/24] Train loss=0.2298213392496109
[15/24] Train loss=0.20885595679283142
[20/24] Train loss=0.17564786970615387
Test set avg_accuracy=86.76% avg_sensitivity=67.49%, avg_specificity=94.06% avg_auc=91.43%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.185330 Test loss=0.319723 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.17403747141361237
[5/24] Train loss=0.15641671419143677
[10/24] Train loss=0.2036958783864975
[15/24] Train loss=0.21676430106163025
[20/24] Train loss=0.17624357342720032
Test set avg_accuracy=85.20% avg_sensitivity=78.96%, avg_specificity=87.56% avg_auc=91.91%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.181344 Test loss=0.334728 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.17260654270648956
[5/24] Train loss=0.1638200283050537
[10/24] Train loss=0.23898550868034363
[15/24] Train loss=0.20240359008312225
[20/24] Train loss=0.17862321436405182
Test set avg_accuracy=87.24% avg_sensitivity=67.35%, avg_specificity=94.78% avg_auc=91.85%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.182956 Test loss=0.319908 Current lr=[0.000276307469034998]

[0/24] Train loss=0.17839238047599792
[5/24] Train loss=0.1615011990070343
[10/24] Train loss=0.21176783740520477
[15/24] Train loss=0.2076883614063263
[20/24] Train loss=0.1888822764158249
Test set avg_accuracy=84.61% avg_sensitivity=85.69%, avg_specificity=84.20% avg_auc=92.31%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.183292 Test loss=0.350843 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.17719756066799164
[5/24] Train loss=0.1547168493270874
[10/24] Train loss=0.2098434865474701
[15/24] Train loss=0.19465984404087067
[20/24] Train loss=0.162186399102211
Test set avg_accuracy=86.88% avg_sensitivity=81.90%, avg_specificity=88.76% avg_auc=92.94%
Best model saved!! Metric=24.473611382916275!!
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.177605 Test loss=0.314234 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.1697622835636139
[5/24] Train loss=0.16287872195243835
[10/24] Train loss=0.20142744481563568
[15/24] Train loss=0.20395368337631226
[20/24] Train loss=0.17351239919662476
Test set avg_accuracy=85.21% avg_sensitivity=54.31%, avg_specificity=96.91% avg_auc=89.03%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.180081 Test loss=0.382214 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.18204648792743683
[5/24] Train loss=0.15877372026443481
[10/24] Train loss=0.20253337919712067
[15/24] Train loss=0.21260608732700348
[20/24] Train loss=0.15857437252998352
Test set avg_accuracy=87.46% avg_sensitivity=78.15%, avg_specificity=90.99% avg_auc=92.77%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.179780 Test loss=0.305963 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.16618217527866364
[5/24] Train loss=0.15484096109867096
[10/24] Train loss=0.20667637884616852
[15/24] Train loss=0.18890509009361267
[20/24] Train loss=0.16654089093208313
Test set avg_accuracy=87.70% avg_sensitivity=77.82%, avg_specificity=91.44% avg_auc=92.71%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.175769 Test loss=0.305715 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.1690763682126999
[5/24] Train loss=0.15308691561222076
[10/24] Train loss=0.1987476795911789
[15/24] Train loss=0.19945047795772552
[20/24] Train loss=0.1693553626537323
Test set avg_accuracy=82.86% avg_sensitivity=44.98%, avg_specificity=97.22% avg_auc=87.62%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.175471 Test loss=0.431522 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.18741975724697113
[5/24] Train loss=0.16306115686893463
[10/24] Train loss=0.20901305973529816
[15/24] Train loss=0.20524705946445465
[20/24] Train loss=0.16910392045974731
Test set avg_accuracy=86.99% avg_sensitivity=69.05%, avg_specificity=93.79% avg_auc=91.56%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.183527 Test loss=0.318456 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.16569405794143677
[5/24] Train loss=0.14646513760089874
[10/24] Train loss=0.215854212641716
[15/24] Train loss=0.1986655592918396
[20/24] Train loss=0.16530634462833405
Test set avg_accuracy=86.45% avg_sensitivity=63.08%, avg_specificity=95.30% avg_auc=90.11%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.175257 Test loss=0.343430 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.17181359231472015
[5/24] Train loss=0.15455926954746246
[10/24] Train loss=0.20080122351646423
[15/24] Train loss=0.20566755533218384
[20/24] Train loss=0.16000960767269135
Test set avg_accuracy=80.79% avg_sensitivity=33.93%, avg_specificity=98.55% avg_auc=81.79%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.174473 Test loss=0.562255 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.16755959391593933
[5/24] Train loss=0.14520923793315887
[10/24] Train loss=0.19735391438007355
[15/24] Train loss=0.19203011691570282
[20/24] Train loss=0.16552585363388062
Test set avg_accuracy=87.17% avg_sensitivity=67.25%, avg_specificity=94.72% avg_auc=91.38%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.174742 Test loss=0.320143 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.16141116619110107
[5/24] Train loss=0.14617478847503662
[10/24] Train loss=0.19104669988155365
[15/24] Train loss=0.18945123255252838
[20/24] Train loss=0.16400857269763947
Test set avg_accuracy=84.96% avg_sensitivity=64.17%, avg_specificity=92.84% avg_auc=87.97%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.169714 Test loss=0.376010 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1608370542526245
[5/24] Train loss=0.14614401757717133
[10/24] Train loss=0.20100940763950348
[15/24] Train loss=0.18684428930282593
[20/24] Train loss=0.1786240041255951
Test set avg_accuracy=87.73% avg_sensitivity=73.41%, avg_specificity=93.16% avg_auc=92.25%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.171689 Test loss=0.305972 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.1613328754901886
[5/24] Train loss=0.153215229511261
[10/24] Train loss=0.18954715132713318
[15/24] Train loss=0.1907912641763687
[20/24] Train loss=0.16209132969379425
Test set avg_accuracy=86.56% avg_sensitivity=67.06%, avg_specificity=93.95% avg_auc=90.53%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.171483 Test loss=0.341241 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.17425502836704254
[5/24] Train loss=0.1477820724248886
[10/24] Train loss=0.19487883150577545
[15/24] Train loss=0.1923171728849411
[20/24] Train loss=0.1587083637714386
Test set avg_accuracy=86.88% avg_sensitivity=70.14%, avg_specificity=93.21% avg_auc=90.99%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.169499 Test loss=0.330914 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.1590435802936554
[5/24] Train loss=0.14902856945991516
[10/24] Train loss=0.19542966783046722
[15/24] Train loss=0.19032558798789978
[20/24] Train loss=0.15760666131973267
Test set avg_accuracy=87.59% avg_sensitivity=76.87%, avg_specificity=91.65% avg_auc=91.99%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.166535 Test loss=0.315590 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.15390832722187042
[5/24] Train loss=0.14489518105983734
[10/24] Train loss=0.18990449607372284
[15/24] Train loss=0.19361740350723267
[20/24] Train loss=0.17425210773944855
Test set avg_accuracy=87.01% avg_sensitivity=68.29%, avg_specificity=94.09% avg_auc=91.13%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.166731 Test loss=0.330737 Current lr=[0.000224838296036774]

[0/24] Train loss=0.15426477789878845
[5/24] Train loss=0.1613936722278595
[10/24] Train loss=0.2088814526796341
[15/24] Train loss=0.18675187230110168
[20/24] Train loss=0.16464416682720184
Test set avg_accuracy=86.08% avg_sensitivity=77.44%, avg_specificity=89.35% avg_auc=91.42%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.175115 Test loss=0.330040 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.1638895720243454
[5/24] Train loss=0.16150349378585815
[10/24] Train loss=0.19184869527816772
[15/24] Train loss=0.18776585161685944
[20/24] Train loss=0.16239528357982635
Test set avg_accuracy=86.41% avg_sensitivity=79.34%, avg_specificity=89.08% avg_auc=91.70%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.169212 Test loss=0.330778 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.15508170425891876
[5/24] Train loss=0.15264545381069183
[10/24] Train loss=0.18697644770145416
[15/24] Train loss=0.18444864451885223
[20/24] Train loss=0.1524970829486847
Test set avg_accuracy=86.93% avg_sensitivity=77.58%, avg_specificity=90.47% avg_auc=91.98%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.166275 Test loss=0.322311 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.16026128828525543
[5/24] Train loss=0.15108829736709595
[10/24] Train loss=0.18382702767848969
[15/24] Train loss=0.1801002025604248
[20/24] Train loss=0.15558692812919617
Test set avg_accuracy=84.92% avg_sensitivity=86.54%, avg_specificity=84.31% avg_auc=92.32%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.166040 Test loss=0.362628 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.15802037715911865
[5/24] Train loss=0.1480942666530609
[10/24] Train loss=0.18039579689502716
[15/24] Train loss=0.17876069247722626
[20/24] Train loss=0.15910270810127258
Test set avg_accuracy=86.08% avg_sensitivity=60.90%, avg_specificity=95.62% avg_auc=88.68%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.161054 Test loss=0.364866 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.1643608957529068
[5/24] Train loss=0.14725342392921448
[10/24] Train loss=0.18585346639156342
[15/24] Train loss=0.182545468211174
[20/24] Train loss=0.1564643681049347
Test set avg_accuracy=83.85% avg_sensitivity=89.05%, avg_specificity=81.89% avg_auc=91.85%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.164663 Test loss=0.383608 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.16018597781658173
[5/24] Train loss=0.14802183210849762
[10/24] Train loss=0.18622736632823944
[15/24] Train loss=0.17998428642749786
[20/24] Train loss=0.16303162276744843
Test set avg_accuracy=85.12% avg_sensitivity=71.71%, avg_specificity=90.20% avg_auc=88.83%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.165377 Test loss=0.370010 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.16133630275726318
[5/24] Train loss=0.14332348108291626
[10/24] Train loss=0.1741996556520462
[15/24] Train loss=0.18668067455291748
[20/24] Train loss=0.15555723011493683
Test set avg_accuracy=87.79% avg_sensitivity=77.82%, avg_specificity=91.56% avg_auc=92.46%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.163445 Test loss=0.312441 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.15380452573299408
[5/24] Train loss=0.14157319068908691
[10/24] Train loss=0.18142129480838776
[15/24] Train loss=0.17366905510425568
[20/24] Train loss=0.14833511412143707
Test set avg_accuracy=83.85% avg_sensitivity=50.05%, avg_specificity=96.66% avg_auc=86.33%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.159248 Test loss=0.429137 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.1472126692533493
[5/24] Train loss=0.13407643139362335
[10/24] Train loss=0.1879173070192337
[15/24] Train loss=0.18859466910362244
[20/24] Train loss=0.16091826558113098
Test set avg_accuracy=86.38% avg_sensitivity=62.89%, avg_specificity=95.28% avg_auc=89.44%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.161121 Test loss=0.356127 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1565932035446167
[5/24] Train loss=0.1368934065103531
[10/24] Train loss=0.18099483847618103
[15/24] Train loss=0.18291233479976654
[20/24] Train loss=0.1548728197813034
Test set avg_accuracy=83.27% avg_sensitivity=43.36%, avg_specificity=98.38% avg_auc=84.36%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.162506 Test loss=0.459212 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.1663885861635208
[5/24] Train loss=0.14846692979335785
[10/24] Train loss=0.18002258241176605
[15/24] Train loss=0.17989253997802734
[20/24] Train loss=0.1584642231464386
Test set avg_accuracy=85.25% avg_sensitivity=55.69%, avg_specificity=96.45% avg_auc=87.91%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.163615 Test loss=0.400297 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.15644824504852295
[5/24] Train loss=0.1446157842874527
[10/24] Train loss=0.18634910881519318
[15/24] Train loss=0.17426353693008423
[20/24] Train loss=0.15344864130020142
Test set avg_accuracy=87.32% avg_sensitivity=72.51%, avg_specificity=92.93% avg_auc=91.71%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.159206 Test loss=0.324356 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15264911949634552
[5/24] Train loss=0.14188207685947418
[10/24] Train loss=0.1742376983165741
[15/24] Train loss=0.17909902334213257
[20/24] Train loss=0.16229726374149323
Test set avg_accuracy=86.52% avg_sensitivity=81.23%, avg_specificity=88.53% avg_auc=92.54%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.159921 Test loss=0.325657 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1549087017774582
[5/24] Train loss=0.14177291095256805
[10/24] Train loss=0.17827695608139038
[15/24] Train loss=0.17849722504615784
[20/24] Train loss=0.14659884572029114
Test set avg_accuracy=86.64% avg_sensitivity=69.57%, avg_specificity=93.11% avg_auc=90.56%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.157428 Test loss=0.342412 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.14978453516960144
[5/24] Train loss=0.1366124153137207
[10/24] Train loss=0.17267751693725586
[15/24] Train loss=0.17073863744735718
[20/24] Train loss=0.15431421995162964
Test set avg_accuracy=87.38% avg_sensitivity=74.41%, avg_specificity=92.30% avg_auc=91.98%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.156611 Test loss=0.319251 Current lr=[0.000156543481933168]

[0/24] Train loss=0.1550106555223465
[5/24] Train loss=0.14337918162345886
[10/24] Train loss=0.17339764535427094
[15/24] Train loss=0.17878727614879608
[20/24] Train loss=0.15814803540706635
Test set avg_accuracy=86.81% avg_sensitivity=67.30%, avg_specificity=94.20% avg_auc=90.36%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.157192 Test loss=0.335893 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1533922553062439
[5/24] Train loss=0.13717959821224213
[10/24] Train loss=0.17758536338806152
[15/24] Train loss=0.17369377613067627
[20/24] Train loss=0.1504717916250229
Test set avg_accuracy=87.67% avg_sensitivity=74.41%, avg_specificity=92.69% avg_auc=92.00%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.154977 Test loss=0.311950 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15171052515506744
[5/24] Train loss=0.1446806937456131
[10/24] Train loss=0.1873706877231598
[15/24] Train loss=0.17148084938526154
[20/24] Train loss=0.14335982501506805
Test set avg_accuracy=86.55% avg_sensitivity=62.37%, avg_specificity=95.71% avg_auc=90.03%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.157108 Test loss=0.360955 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15067937970161438
[5/24] Train loss=0.13473254442214966
[10/24] Train loss=0.17280936241149902
[15/24] Train loss=0.17502430081367493
[20/24] Train loss=0.15375681221485138
Test set avg_accuracy=86.89% avg_sensitivity=76.30%, avg_specificity=90.90% avg_auc=92.06%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.155032 Test loss=0.326503 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.150255024433136
[5/24] Train loss=0.13713668286800385
[10/24] Train loss=0.16833867132663727
[15/24] Train loss=0.174493670463562
[20/24] Train loss=0.1453482210636139
Test set avg_accuracy=86.33% avg_sensitivity=76.07%, avg_specificity=90.22% avg_auc=91.23%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.154437 Test loss=0.341965 Current lr=[0.000134135431043539]

[0/24] Train loss=0.14668680727481842
[5/24] Train loss=0.13727645576000214
[10/24] Train loss=0.16779613494873047
[15/24] Train loss=0.17123614251613617
[20/24] Train loss=0.14580880105495453
Test set avg_accuracy=86.42% avg_sensitivity=61.23%, avg_specificity=95.96% avg_auc=90.02%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.152214 Test loss=0.360452 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15093573927879333
[5/24] Train loss=0.14182962477207184
[10/24] Train loss=0.16564327478408813
[15/24] Train loss=0.18090125918388367
[20/24] Train loss=0.1496599167585373
Test set avg_accuracy=86.84% avg_sensitivity=64.83%, avg_specificity=95.17% avg_auc=90.94%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.152665 Test loss=0.330941 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1488879919052124
[5/24] Train loss=0.1499488800764084
[10/24] Train loss=0.16420716047286987
[15/24] Train loss=0.17429344356060028
[20/24] Train loss=0.1478387415409088
Test set avg_accuracy=85.55% avg_sensitivity=58.10%, avg_specificity=95.94% avg_auc=89.96%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.154112 Test loss=0.368353 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.154726043343544
[5/24] Train loss=0.1354788839817047
[10/24] Train loss=0.17010435461997986
[15/24] Train loss=0.17712751030921936
[20/24] Train loss=0.1464129537343979
Test set avg_accuracy=87.94% avg_sensitivity=75.73%, avg_specificity=92.57% avg_auc=92.74%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.153578 Test loss=0.303974 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14356102049350739
[5/24] Train loss=0.13453982770442963
[10/24] Train loss=0.15876303613185883
[15/24] Train loss=0.16851575672626495
[20/24] Train loss=0.13859915733337402
Test set avg_accuracy=87.33% avg_sensitivity=67.63%, avg_specificity=94.79% avg_auc=91.39%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.147544 Test loss=0.322551 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14130398631095886
[5/24] Train loss=0.13152103126049042
[10/24] Train loss=0.15789011120796204
[15/24] Train loss=0.16146190464496613
[20/24] Train loss=0.14146661758422852
Test set avg_accuracy=87.38% avg_sensitivity=68.82%, avg_specificity=94.42% avg_auc=91.96%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.144805 Test loss=0.318974 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.14035898447036743
[5/24] Train loss=0.13589048385620117
[10/24] Train loss=0.15835177898406982
[15/24] Train loss=0.16550374031066895
[20/24] Train loss=0.14062921702861786
Test set avg_accuracy=87.72% avg_sensitivity=74.64%, avg_specificity=92.68% avg_auc=92.34%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.144638 Test loss=0.308648 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1422295868396759
[5/24] Train loss=0.127492293715477
[10/24] Train loss=0.15573495626449585
[15/24] Train loss=0.16048318147659302
[20/24] Train loss=0.14094890654087067
Test set avg_accuracy=87.57% avg_sensitivity=76.40%, avg_specificity=91.80% avg_auc=92.14%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.143082 Test loss=0.313295 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.13794760406017303
[5/24] Train loss=0.12787450850009918
[10/24] Train loss=0.15541230142116547
[15/24] Train loss=0.15585356950759888
[20/24] Train loss=0.13875338435173035
Test set avg_accuracy=87.79% avg_sensitivity=72.65%, avg_specificity=93.52% avg_auc=92.06%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.141541 Test loss=0.318938 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.13983924686908722
[5/24] Train loss=0.13131944835186005
[10/24] Train loss=0.16787324845790863
[15/24] Train loss=0.15801690518856049
[20/24] Train loss=0.14161422848701477
Test set avg_accuracy=87.71% avg_sensitivity=71.71%, avg_specificity=93.77% avg_auc=92.34%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.141928 Test loss=0.314232 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1403742879629135
[5/24] Train loss=0.12510724365711212
[10/24] Train loss=0.15306761860847473
[15/24] Train loss=0.1563216596841812
[20/24] Train loss=0.1407439410686493
Test set avg_accuracy=86.94% avg_sensitivity=64.50%, avg_specificity=95.44% avg_auc=91.04%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.140930 Test loss=0.340415 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14482338726520538
[5/24] Train loss=0.12378325313329697
[10/24] Train loss=0.1505722850561142
[15/24] Train loss=0.15454928576946259
[20/24] Train loss=0.13632890582084656
Test set avg_accuracy=87.90% avg_sensitivity=72.23%, avg_specificity=93.84% avg_auc=92.28%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.139198 Test loss=0.306849 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13663719594478607
[5/24] Train loss=0.11966442316770554
[10/24] Train loss=0.1469801664352417
[15/24] Train loss=0.15186694264411926
[20/24] Train loss=0.1391194760799408
Test set avg_accuracy=87.62% avg_sensitivity=75.21%, avg_specificity=92.32% avg_auc=92.64%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.137338 Test loss=0.307872 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13985715806484222
[5/24] Train loss=0.12208166718482971
[10/24] Train loss=0.14793804287910461
[15/24] Train loss=0.15502490103244781
[20/24] Train loss=0.1394633948802948
Test set avg_accuracy=87.28% avg_sensitivity=73.18%, avg_specificity=92.62% avg_auc=92.62%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.137258 Test loss=0.310075 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13755887746810913
[5/24] Train loss=0.12323538959026337
[10/24] Train loss=0.14670169353485107
[15/24] Train loss=0.15132564306259155
[20/24] Train loss=0.1379546970129013
Test set avg_accuracy=87.60% avg_sensitivity=75.12%, avg_specificity=92.33% avg_auc=92.44%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.135199 Test loss=0.312579 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.131875678896904
[5/24] Train loss=0.11919081956148148
[10/24] Train loss=0.14438730478286743
[15/24] Train loss=0.1536080688238144
[20/24] Train loss=0.13345053791999817
Test set avg_accuracy=87.43% avg_sensitivity=72.46%, avg_specificity=93.11% avg_auc=91.91%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.134298 Test loss=0.317446 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.13330096006393433
[5/24] Train loss=0.12517647445201874
[10/24] Train loss=0.14745526015758514
[15/24] Train loss=0.14876265823841095
[20/24] Train loss=0.13386613130569458
Test set avg_accuracy=87.64% avg_sensitivity=71.80%, avg_specificity=93.64% avg_auc=92.14%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.134716 Test loss=0.312081 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13422861695289612
[5/24] Train loss=0.12053713202476501
[10/24] Train loss=0.14046812057495117
[15/24] Train loss=0.1514841765165329
[20/24] Train loss=0.13444381952285767
Test set avg_accuracy=87.55% avg_sensitivity=75.64%, avg_specificity=92.06% avg_auc=92.37%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.133670 Test loss=0.314235 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13022640347480774
[5/24] Train loss=0.1176876351237297
[10/24] Train loss=0.14236530661582947
[15/24] Train loss=0.14876213669776917
[20/24] Train loss=0.13234774768352509
Test set avg_accuracy=87.28% avg_sensitivity=77.25%, avg_specificity=91.08% avg_auc=92.63%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.132781 Test loss=0.314012 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13378547132015228
[5/24] Train loss=0.11962787806987762
[10/24] Train loss=0.14140568673610687
[15/24] Train loss=0.14499932527542114
[20/24] Train loss=0.13047610223293304
Test set avg_accuracy=87.29% avg_sensitivity=77.63%, avg_specificity=90.95% avg_auc=92.72%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.132266 Test loss=0.310847 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.12945514917373657
[5/24] Train loss=0.11791293323040009
[10/24] Train loss=0.14047063887119293
[15/24] Train loss=0.1433761864900589
[20/24] Train loss=0.13233119249343872
Test set avg_accuracy=87.54% avg_sensitivity=77.68%, avg_specificity=91.27% avg_auc=92.54%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.131796 Test loss=0.313525 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.12983083724975586
[5/24] Train loss=0.11754573881626129
[10/24] Train loss=0.14225159585475922
[15/24] Train loss=0.14611949026584625
[20/24] Train loss=0.13110998272895813
Test set avg_accuracy=87.49% avg_sensitivity=78.44%, avg_specificity=90.92% avg_auc=92.54%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.131107 Test loss=0.312659 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13010625541210175
[5/24] Train loss=0.1145734116435051
[10/24] Train loss=0.1399974822998047
[15/24] Train loss=0.1427832990884781
[20/24] Train loss=0.12950266897678375
Test set avg_accuracy=87.67% avg_sensitivity=74.31%, avg_specificity=92.73% avg_auc=92.28%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.129921 Test loss=0.313662 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12843747437000275
[5/24] Train loss=0.11417724192142487
[10/24] Train loss=0.13904322683811188
[15/24] Train loss=0.1444452702999115
[20/24] Train loss=0.12975570559501648
Test set avg_accuracy=87.38% avg_sensitivity=73.74%, avg_specificity=92.55% avg_auc=92.04%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.129582 Test loss=0.316188 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12631294131278992
[5/24] Train loss=0.11526092141866684
[10/24] Train loss=0.139638751745224
[15/24] Train loss=0.14707191288471222
[20/24] Train loss=0.13273444771766663
Test set avg_accuracy=87.33% avg_sensitivity=75.92%, avg_specificity=91.65% avg_auc=92.35%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.129842 Test loss=0.314723 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1287071704864502
[5/24] Train loss=0.11501362174749374
[10/24] Train loss=0.13464540243148804
[15/24] Train loss=0.14269320666790009
[20/24] Train loss=0.12814274430274963
Test set avg_accuracy=87.64% avg_sensitivity=74.45%, avg_specificity=92.64% avg_auc=92.56%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.128378 Test loss=0.311481 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12475314736366272
[5/24] Train loss=0.11530376225709915
[10/24] Train loss=0.13662275671958923
[15/24] Train loss=0.14030501246452332
[20/24] Train loss=0.12821419537067413
Test set avg_accuracy=87.38% avg_sensitivity=75.07%, avg_specificity=92.05% avg_auc=92.36%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.127786 Test loss=0.317926 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12697672843933105
[5/24] Train loss=0.11400704830884933
[10/24] Train loss=0.13711591064929962
[15/24] Train loss=0.1382739096879959
[20/24] Train loss=0.12637317180633545
Test set avg_accuracy=87.70% avg_sensitivity=76.40%, avg_specificity=91.97% avg_auc=92.57%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.126518 Test loss=0.308565 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1256140172481537
[5/24] Train loss=0.11458281427621841
[10/24] Train loss=0.13792048394680023
[15/24] Train loss=0.14144420623779297
[20/24] Train loss=0.12909460067749023
Test set avg_accuracy=87.70% avg_sensitivity=79.15%, avg_specificity=90.93% avg_auc=92.79%
Best model saved!! Metric=24.564244745356376!!
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.126831 Test loss=0.310826 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12606921792030334
[5/24] Train loss=0.11296314001083374
[10/24] Train loss=0.1351669281721115
[15/24] Train loss=0.13875523209571838
[20/24] Train loss=0.12452084571123123
Test set avg_accuracy=87.90% avg_sensitivity=78.82%, avg_specificity=91.35% avg_auc=92.87%
Best model saved!! Metric=24.936217072282673!!
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.126015 Test loss=0.307162 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12991221249103546
[5/24] Train loss=0.11505825817584991
[10/24] Train loss=0.13205379247665405
[15/24] Train loss=0.1422201693058014
[20/24] Train loss=0.12903374433517456
Test set avg_accuracy=87.75% avg_sensitivity=75.59%, avg_specificity=92.35% avg_auc=92.72%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.127132 Test loss=0.309984 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12220971286296844
[5/24] Train loss=0.1128976121544838
[10/24] Train loss=0.1340692639350891
[15/24] Train loss=0.13863621652126312
[20/24] Train loss=0.1307879537343979
Test set avg_accuracy=87.72% avg_sensitivity=75.45%, avg_specificity=92.37% avg_auc=92.45%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.126613 Test loss=0.308653 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1238868460059166
[5/24] Train loss=0.11375366151332855
[10/24] Train loss=0.13525591790676117
[15/24] Train loss=0.13736292719841003
[20/24] Train loss=0.12624959647655487
Test set avg_accuracy=87.36% avg_sensitivity=71.71%, avg_specificity=93.29% avg_auc=92.49%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.126195 Test loss=0.313397 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12236139923334122
[5/24] Train loss=0.11263681948184967
[10/24] Train loss=0.13259756565093994
[15/24] Train loss=0.13647468388080597
[20/24] Train loss=0.12676870822906494
Test set avg_accuracy=87.53% avg_sensitivity=75.69%, avg_specificity=92.01% avg_auc=92.46%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.125169 Test loss=0.312274 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12229660898447037
[5/24] Train loss=0.11070580780506134
[10/24] Train loss=0.13264790177345276
[15/24] Train loss=0.13436508178710938
[20/24] Train loss=0.12539945542812347
Test set avg_accuracy=87.84% avg_sensitivity=79.05%, avg_specificity=91.17% avg_auc=93.03%
Best model saved!! Metric=25.087743977624996!!
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.123793 Test loss=0.302931 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12014362961053848
[5/24] Train loss=0.11115872859954834
[10/24] Train loss=0.13049788773059845
[15/24] Train loss=0.13628843426704407
[20/24] Train loss=0.12542185187339783
Test set avg_accuracy=87.90% avg_sensitivity=78.48%, avg_specificity=91.47% avg_auc=92.84%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.122971 Test loss=0.304412 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.11865320801734924
[5/24] Train loss=0.11061818897724152
[10/24] Train loss=0.13180255889892578
[15/24] Train loss=0.13319945335388184
[20/24] Train loss=0.12632234394550323
Test set avg_accuracy=87.76% avg_sensitivity=76.11%, avg_specificity=92.17% avg_auc=92.89%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.122121 Test loss=0.305015 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.11800097674131393
[5/24] Train loss=0.10888992249965668
[10/24] Train loss=0.13073156774044037
[15/24] Train loss=0.13145121932029724
[20/24] Train loss=0.12435568869113922
Test set avg_accuracy=87.88% avg_sensitivity=76.82%, avg_specificity=92.06% avg_auc=92.85%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.121868 Test loss=0.305784 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.11731871217489243
[5/24] Train loss=0.10958969593048096
[10/24] Train loss=0.13154493272304535
[15/24] Train loss=0.13414612412452698
[20/24] Train loss=0.12399473786354065
Test set avg_accuracy=87.81% avg_sensitivity=77.16%, avg_specificity=91.85% avg_auc=92.91%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.121965 Test loss=0.304608 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11795825511217117
[5/24] Train loss=0.10927345603704453
[10/24] Train loss=0.12929828464984894
[15/24] Train loss=0.13366608321666718
[20/24] Train loss=0.12208598107099533
Test set avg_accuracy=87.75% avg_sensitivity=75.55%, avg_specificity=92.37% avg_auc=92.83%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.120973 Test loss=0.305644 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.11605649441480637
[5/24] Train loss=0.1103808805346489
[10/24] Train loss=0.12996640801429749
[15/24] Train loss=0.13202428817749023
[20/24] Train loss=0.12150871753692627
Test set avg_accuracy=87.72% avg_sensitivity=75.88%, avg_specificity=92.21% avg_auc=92.85%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.120905 Test loss=0.307054 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11832382529973984
[5/24] Train loss=0.11105611175298691
[10/24] Train loss=0.12980467081069946
[15/24] Train loss=0.1320752054452896
[20/24] Train loss=0.1204104796051979
Test set avg_accuracy=87.77% avg_sensitivity=76.97%, avg_specificity=91.87% avg_auc=92.92%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.120874 Test loss=0.304762 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.11826088279485703
[5/24] Train loss=0.10890238732099533
[10/24] Train loss=0.12911757826805115
[15/24] Train loss=0.13382773101329803
[20/24] Train loss=0.12168226391077042
Test set avg_accuracy=87.81% avg_sensitivity=76.30%, avg_specificity=92.17% avg_auc=92.90%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.121212 Test loss=0.305345 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11778994649648666
[5/24] Train loss=0.10969146341085434
[10/24] Train loss=0.12875303626060486
[15/24] Train loss=0.13221095502376556
[20/24] Train loss=0.12265126407146454
Test set avg_accuracy=87.81% avg_sensitivity=76.59%, avg_specificity=92.06% avg_auc=92.87%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.120654 Test loss=0.305792 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11688418686389923
[5/24] Train loss=0.10842342674732208
[10/24] Train loss=0.12691903114318848
[15/24] Train loss=0.13236387073993683
[20/24] Train loss=0.1244695633649826
Test set avg_accuracy=87.80% avg_sensitivity=76.49%, avg_specificity=92.08% avg_auc=92.86%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.120577 Test loss=0.305534 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11743267625570297
[5/24] Train loss=0.1084718331694603
[10/24] Train loss=0.13005778193473816
[15/24] Train loss=0.13176433742046356
[20/24] Train loss=0.12335008382797241
Test set avg_accuracy=87.75% avg_sensitivity=76.07%, avg_specificity=92.17% avg_auc=92.84%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.120486 Test loss=0.306254 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11753913015127182
[5/24] Train loss=0.10721341520547867
[10/24] Train loss=0.12674784660339355
[15/24] Train loss=0.13119137287139893
[20/24] Train loss=0.12177302688360214
Test set avg_accuracy=87.79% avg_sensitivity=76.30%, avg_specificity=92.14% avg_auc=92.86%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.120468 Test loss=0.306018 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11703068017959595
[5/24] Train loss=0.10785254836082458
[10/24] Train loss=0.1307002604007721
[15/24] Train loss=0.12906883656978607
[20/24] Train loss=0.12122558802366257
Test set avg_accuracy=87.73% avg_sensitivity=76.07%, avg_specificity=92.15% avg_auc=92.85%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.120388 Test loss=0.306157 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11815144121646881
[5/24] Train loss=0.10895317047834396
[10/24] Train loss=0.12723132967948914
[15/24] Train loss=0.13206689059734344
[20/24] Train loss=0.12174884974956512
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=87.76% avg_sensitivity=76.16%, avg_specificity=92.15% avg_auc=92.85%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.120115 Test loss=0.306176 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=87.84% sen=79.05%, spe=91.17%, auc=93.03%!
Fold[3] Avg_overlap=0.67%(0.23124596905003025)
[0/24] Train loss=0.7527593374252319
[5/24] Train loss=0.7518930435180664
[10/24] Train loss=0.7418765425682068
[15/24] Train loss=0.733170211315155
[20/24] Train loss=0.7153656482696533
Test set avg_accuracy=58.57% avg_sensitivity=56.12%, avg_specificity=59.43% avg_auc=60.30%
Best model saved!! Metric=-91.58084426129733!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.737034 Test loss=0.684482 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7188218832015991
[5/24] Train loss=0.7177563309669495
[10/24] Train loss=0.7151554226875305
[15/24] Train loss=0.7013951539993286
[20/24] Train loss=0.6938657760620117
Test set avg_accuracy=64.61% avg_sensitivity=67.32%, avg_specificity=63.66% avg_auc=71.36%
Best model saved!! Metric=-59.06051694256543!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.708427 Test loss=0.630364 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6866235733032227
[5/24] Train loss=0.6939865350723267
[10/24] Train loss=0.6940397024154663
[15/24] Train loss=0.6663634777069092
[20/24] Train loss=0.6567459106445312
Test set avg_accuracy=68.27% avg_sensitivity=74.71%, avg_specificity=66.00% avg_auc=76.97%
Best model saved!! Metric=-40.052073967555984!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.680196 Test loss=0.597437 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6608521342277527
[5/24] Train loss=0.663572371006012
[10/24] Train loss=0.6680482625961304
[15/24] Train loss=0.6384671330451965
[20/24] Train loss=0.6274968981742859
Test set avg_accuracy=71.00% avg_sensitivity=77.01%, avg_specificity=68.89% avg_auc=80.20%
Best model saved!! Metric=-28.904794132774924!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.651440 Test loss=0.564931 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6196103692054749
[5/24] Train loss=0.636667788028717
[10/24] Train loss=0.6426613330841064
[15/24] Train loss=0.6134911775588989
[20/24] Train loss=0.6000856757164001
Test set avg_accuracy=73.28% avg_sensitivity=78.11%, avg_specificity=71.58% avg_auc=82.27%
Best model saved!! Metric=-20.76068430666247!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.624059 Test loss=0.539408 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5994170308113098
[5/24] Train loss=0.6077367663383484
[10/24] Train loss=0.6132200360298157
[15/24] Train loss=0.5886531472206116
[20/24] Train loss=0.5735151767730713
Test set avg_accuracy=75.29% avg_sensitivity=80.06%, avg_specificity=73.60% avg_auc=84.08%
Best model saved!! Metric=-12.967231690821691!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.595665 Test loss=0.518542 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5695745348930359
[5/24] Train loss=0.5662661790847778
[10/24] Train loss=0.5849717855453491
[15/24] Train loss=0.5520350933074951
[20/24] Train loss=0.5442530512809753
Test set avg_accuracy=77.30% avg_sensitivity=79.71%, avg_specificity=76.46% avg_auc=85.61%
Best model saved!! Metric=-6.91843724683595!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.565484 Test loss=0.492789 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5366548895835876
[5/24] Train loss=0.5385827422142029
[10/24] Train loss=0.5526975393295288
[15/24] Train loss=0.5194340944290161
[20/24] Train loss=0.5152840614318848
Test set avg_accuracy=79.41% avg_sensitivity=79.66%, avg_specificity=79.33% avg_auc=86.95%
Best model saved!! Metric=-0.6519710442421456!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.533131 Test loss=0.463286 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5027368664741516
[5/24] Train loss=0.5027709603309631
[10/24] Train loss=0.5225643515586853
[15/24] Train loss=0.49200236797332764
[20/24] Train loss=0.48327434062957764
Test set avg_accuracy=81.37% avg_sensitivity=79.31%, avg_specificity=82.09% avg_auc=88.04%
Best model saved!! Metric=4.809885590996757!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.503199 Test loss=0.440862 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.47274404764175415
[5/24] Train loss=0.4693256616592407
[10/24] Train loss=0.49303820729255676
[15/24] Train loss=0.46145156025886536
[20/24] Train loss=0.45018094778060913
Test set avg_accuracy=82.94% avg_sensitivity=77.51%, avg_specificity=84.86% avg_auc=88.66%
Best model saved!! Metric=7.974605661654579!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.472118 Test loss=0.418112 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4438658058643341
[5/24] Train loss=0.4395267069339752
[10/24] Train loss=0.46219977736473083
[15/24] Train loss=0.4394434094429016
[20/24] Train loss=0.42053085565567017
Test set avg_accuracy=84.02% avg_sensitivity=75.36%, avg_specificity=87.08% avg_auc=89.39%
Best model saved!! Metric=9.855014227924102!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.443299 Test loss=0.396787 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4212696850299835
[5/24] Train loss=0.4109770953655243
[10/24] Train loss=0.4438086450099945
[15/24] Train loss=0.4107237756252289
[20/24] Train loss=0.3936100900173187
Test set avg_accuracy=84.77% avg_sensitivity=75.01%, avg_specificity=88.20% avg_auc=90.05%
Best model saved!! Metric=12.026989563360146!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.417320 Test loss=0.379363 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.38886409997940063
[5/24] Train loss=0.38249126076698303
[10/24] Train loss=0.41784048080444336
[15/24] Train loss=0.3901994228363037
[20/24] Train loss=0.3694448173046112
Test set avg_accuracy=85.69% avg_sensitivity=74.56%, avg_specificity=89.61% avg_auc=90.51%
Best model saved!! Metric=14.377208580650915!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.392950 Test loss=0.363909 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3672519028186798
[5/24] Train loss=0.35993674397468567
[10/24] Train loss=0.4001944363117218
[15/24] Train loss=0.37379392981529236
[20/24] Train loss=0.35481008887290955
Test set avg_accuracy=86.21% avg_sensitivity=74.26%, avg_specificity=90.42% avg_auc=90.85%
Best model saved!! Metric=15.743203942936304!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.374721 Test loss=0.352080 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.35279104113578796
[5/24] Train loss=0.3381272852420807
[10/24] Train loss=0.38298454880714417
[15/24] Train loss=0.35602810978889465
[20/24] Train loss=0.33802688121795654
Test set avg_accuracy=86.78% avg_sensitivity=73.46%, avg_specificity=91.48% avg_auc=91.14%
Best model saved!! Metric=16.868864135709245!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.357354 Test loss=0.339027 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3382338285446167
[5/24] Train loss=0.32474273443222046
[10/24] Train loss=0.36694058775901794
[15/24] Train loss=0.3442551791667938
[20/24] Train loss=0.3292495012283325
Test set avg_accuracy=87.02% avg_sensitivity=74.71%, avg_specificity=91.35% avg_auc=91.68%
Best model saved!! Metric=18.763964504667683!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.342819 Test loss=0.331921 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3229351341724396
[5/24] Train loss=0.31322652101516724
[10/24] Train loss=0.355425626039505
[15/24] Train loss=0.33072414994239807
[20/24] Train loss=0.31269600987434387
Test set avg_accuracy=87.20% avg_sensitivity=75.71%, avg_specificity=91.25% avg_auc=91.91%
Best model saved!! Metric=20.074464738295802!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.328567 Test loss=0.325278 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.31431347131729126
[5/24] Train loss=0.2988041639328003
[10/24] Train loss=0.34412115812301636
[15/24] Train loss=0.3203516900539398
[20/24] Train loss=0.3003336489200592
Test set avg_accuracy=87.62% avg_sensitivity=74.96%, avg_specificity=92.08% avg_auc=92.21%
Best model saved!! Metric=20.865156401620666!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.318388 Test loss=0.315381 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.291909396648407
[5/24] Train loss=0.2889048457145691
[10/24] Train loss=0.33187955617904663
[15/24] Train loss=0.3105044960975647
[20/24] Train loss=0.2928214967250824
Test set avg_accuracy=87.67% avg_sensitivity=76.81%, avg_specificity=91.49% avg_auc=92.44%
Best model saved!! Metric=22.41591811191276!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.308151 Test loss=0.313359 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.28518009185791016
[5/24] Train loss=0.275802880525589
[10/24] Train loss=0.32348009943962097
[15/24] Train loss=0.3000517785549164
[20/24] Train loss=0.2858935296535492
Test set avg_accuracy=87.88% avg_sensitivity=73.51%, avg_specificity=92.94% avg_auc=92.52%
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.298358 Test loss=0.302445 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.27783337235450745
[5/24] Train loss=0.2679268717765808
[10/24] Train loss=0.314352810382843
[15/24] Train loss=0.2991487681865692
[20/24] Train loss=0.27941399812698364
Test set avg_accuracy=87.86% avg_sensitivity=76.96%, avg_specificity=91.71% avg_auc=92.84%
Best model saved!! Metric=23.37629974137333!!
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.290365 Test loss=0.303076 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2730191946029663
[5/24] Train loss=0.2661076486110687
[10/24] Train loss=0.30553877353668213
[15/24] Train loss=0.2948070466518402
[20/24] Train loss=0.26983100175857544
Test set avg_accuracy=88.22% avg_sensitivity=77.01%, avg_specificity=92.16% avg_auc=92.97%
Best model saved!! Metric=24.359211472551053!!
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.283458 Test loss=0.298310 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2693411111831665
[5/24] Train loss=0.25226137042045593
[10/24] Train loss=0.2944292724132538
[15/24] Train loss=0.28781378269195557
[20/24] Train loss=0.2580619752407074
Test set avg_accuracy=87.96% avg_sensitivity=72.26%, avg_specificity=93.48% avg_auc=92.84%
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.277483 Test loss=0.292688 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.265525221824646
[5/24] Train loss=0.23977290093898773
[10/24] Train loss=0.29474201798439026
[15/24] Train loss=0.2769301235675812
[20/24] Train loss=0.25719156861305237
Test set avg_accuracy=87.85% avg_sensitivity=72.16%, avg_specificity=93.38% avg_auc=92.84%
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.270907 Test loss=0.295258 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.25951099395751953
[5/24] Train loss=0.2397918552160263
[10/24] Train loss=0.2942042946815491
[15/24] Train loss=0.2699729800224304
[20/24] Train loss=0.24613149464130402
Test set avg_accuracy=88.01% avg_sensitivity=71.36%, avg_specificity=93.87% avg_auc=93.02%
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.263368 Test loss=0.290347 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.25000184774398804
[5/24] Train loss=0.23930492997169495
[10/24] Train loss=0.2829084098339081
[15/24] Train loss=0.2683514356613159
[20/24] Train loss=0.24828343093395233
Test set avg_accuracy=87.53% avg_sensitivity=66.32%, avg_specificity=95.00% avg_auc=92.51%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.257884 Test loss=0.296639 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2521941363811493
[5/24] Train loss=0.2351054698228836
[10/24] Train loss=0.2813940644264221
[15/24] Train loss=0.25929734110832214
[20/24] Train loss=0.23702317476272583
Test set avg_accuracy=88.27% avg_sensitivity=74.96%, avg_specificity=92.96% avg_auc=93.27%
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.254760 Test loss=0.286615 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.24177522957324982
[5/24] Train loss=0.2233198583126068
[10/24] Train loss=0.27323564887046814
[15/24] Train loss=0.2548835277557373
[20/24] Train loss=0.2378695011138916
Test set avg_accuracy=87.23% avg_sensitivity=62.87%, avg_specificity=95.81% avg_auc=91.90%
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.249938 Test loss=0.309391 Current lr=[0.000210185142098938]

[0/24] Train loss=0.23612046241760254
[5/24] Train loss=0.21528728306293488
[10/24] Train loss=0.28176042437553406
[15/24] Train loss=0.25135815143585205
[20/24] Train loss=0.23492202162742615
Test set avg_accuracy=87.71% avg_sensitivity=65.97%, avg_specificity=95.37% avg_auc=92.79%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.245469 Test loss=0.293741 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.23597918450832367
[5/24] Train loss=0.21351580321788788
[10/24] Train loss=0.2735970616340637
[15/24] Train loss=0.24820078909397125
[20/24] Train loss=0.2307397425174713
Test set avg_accuracy=84.40% avg_sensitivity=46.23%, avg_specificity=97.85% avg_auc=88.30%
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.239912 Test loss=0.393049 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.24282297492027283
[5/24] Train loss=0.2040344625711441
[10/24] Train loss=0.2734563946723938
[15/24] Train loss=0.23360738158226013
[20/24] Train loss=0.2240387350320816
Test set avg_accuracy=88.36% avg_sensitivity=73.51%, avg_specificity=93.59% avg_auc=93.24%
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.238200 Test loss=0.284284 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2279082089662552
[5/24] Train loss=0.2104474902153015
[10/24] Train loss=0.26716887950897217
[15/24] Train loss=0.24173863232135773
[20/24] Train loss=0.22888807952404022
Test set avg_accuracy=87.41% avg_sensitivity=61.17%, avg_specificity=96.65% avg_auc=91.22%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.233573 Test loss=0.319970 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.22352950274944305
[5/24] Train loss=0.19782890379428864
[10/24] Train loss=0.26110342144966125
[15/24] Train loss=0.23609988391399384
[20/24] Train loss=0.2257099151611328
Test set avg_accuracy=87.27% avg_sensitivity=69.42%, avg_specificity=93.56% avg_auc=92.46%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.229784 Test loss=0.297931 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.22387652099132538
[5/24] Train loss=0.19787414371967316
[10/24] Train loss=0.26090750098228455
[15/24] Train loss=0.23470507562160492
[20/24] Train loss=0.22498087584972382
Test set avg_accuracy=87.46% avg_sensitivity=70.21%, avg_specificity=93.54% avg_auc=92.26%
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.227150 Test loss=0.300656 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.22924946248531342
[5/24] Train loss=0.18528474867343903
[10/24] Train loss=0.24826671183109283
[15/24] Train loss=0.23340946435928345
[20/24] Train loss=0.21250496804714203
Test set avg_accuracy=87.49% avg_sensitivity=63.07%, avg_specificity=96.09% avg_auc=92.28%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.225199 Test loss=0.305867 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.22169709205627441
[5/24] Train loss=0.20218110084533691
[10/24] Train loss=0.2501051425933838
[15/24] Train loss=0.22618377208709717
[20/24] Train loss=0.2190297693014145
Test set avg_accuracy=86.71% avg_sensitivity=58.07%, avg_specificity=96.80% avg_auc=91.20%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.222871 Test loss=0.332645 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.23119890689849854
[5/24] Train loss=0.18982286751270294
[10/24] Train loss=0.24659301340579987
[15/24] Train loss=0.22493407130241394
[20/24] Train loss=0.21985414624214172
Test set avg_accuracy=88.16% avg_sensitivity=72.51%, avg_specificity=93.68% avg_auc=92.85%
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.222627 Test loss=0.289462 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.21437448263168335
[5/24] Train loss=0.18349649012088776
[10/24] Train loss=0.237839937210083
[15/24] Train loss=0.2196008861064911
[20/24] Train loss=0.22518880665302277
Test set avg_accuracy=87.85% avg_sensitivity=70.56%, avg_specificity=93.94% avg_auc=92.73%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.216941 Test loss=0.291552 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.21852713823318481
[5/24] Train loss=0.17998982965946198
[10/24] Train loss=0.2419164776802063
[15/24] Train loss=0.22809360921382904
[20/24] Train loss=0.2147873193025589
Test set avg_accuracy=85.27% avg_sensitivity=52.67%, avg_specificity=96.76% avg_auc=89.29%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.220921 Test loss=0.372492 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.21520309150218964
[5/24] Train loss=0.17780835926532745
[10/24] Train loss=0.24854998290538788
[15/24] Train loss=0.22100363671779633
[20/24] Train loss=0.2031669020652771
Test set avg_accuracy=87.28% avg_sensitivity=67.62%, avg_specificity=94.21% avg_auc=91.04%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.214704 Test loss=0.314377 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.20711342990398407
[5/24] Train loss=0.18342915177345276
[10/24] Train loss=0.2531087398529053
[15/24] Train loss=0.2304389625787735
[20/24] Train loss=0.20484629273414612
Test set avg_accuracy=86.13% avg_sensitivity=72.56%, avg_specificity=90.91% avg_auc=90.83%
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.215603 Test loss=0.331704 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2123766988515854
[5/24] Train loss=0.18793195486068726
[10/24] Train loss=0.25541114807128906
[15/24] Train loss=0.21945175528526306
[20/24] Train loss=0.21152640879154205
Test set avg_accuracy=87.70% avg_sensitivity=74.56%, avg_specificity=92.32% avg_auc=93.26%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.217005 Test loss=0.283236 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.21427559852600098
[5/24] Train loss=0.16748765110969543
[10/24] Train loss=0.2397100329399109
[15/24] Train loss=0.21938097476959229
[20/24] Train loss=0.20572996139526367
Test set avg_accuracy=87.34% avg_sensitivity=64.12%, avg_specificity=95.53% avg_auc=92.00%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.206047 Test loss=0.310870 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.21165861189365387
[5/24] Train loss=0.17691247165203094
[10/24] Train loss=0.236167311668396
[15/24] Train loss=0.21531176567077637
[20/24] Train loss=0.2028868943452835
Test set avg_accuracy=85.92% avg_sensitivity=79.96%, avg_specificity=88.03% avg_auc=92.39%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.211443 Test loss=0.323222 Current lr=[0.00029967723776099]

[0/24] Train loss=0.19818229973316193
[5/24] Train loss=0.18001356720924377
[10/24] Train loss=0.23826085031032562
[15/24] Train loss=0.219353586435318
[20/24] Train loss=0.21868716180324554
Test set avg_accuracy=81.59% avg_sensitivity=88.06%, avg_specificity=79.31% avg_auc=91.73%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.211560 Test loss=0.397407 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.21380174160003662
[5/24] Train loss=0.18020904064178467
[10/24] Train loss=0.24461588263511658
[15/24] Train loss=0.22279806435108185
[20/24] Train loss=0.20159707963466644
Test set avg_accuracy=87.88% avg_sensitivity=74.76%, avg_specificity=92.50% avg_auc=92.72%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.215336 Test loss=0.289095 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2019604742527008
[5/24] Train loss=0.17088404297828674
[10/24] Train loss=0.23953035473823547
[15/24] Train loss=0.2157343029975891
[20/24] Train loss=0.1901879906654358
Test set avg_accuracy=87.03% avg_sensitivity=82.66%, avg_specificity=88.57% avg_auc=93.07%
Best model saved!! Metric=25.336313527401643!!
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.204506 Test loss=0.307620 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2169121503829956
[5/24] Train loss=0.16780664026737213
[10/24] Train loss=0.23463231325149536
[15/24] Train loss=0.22042635083198547
[20/24] Train loss=0.20549938082695007
Test set avg_accuracy=86.07% avg_sensitivity=78.16%, avg_specificity=88.85% avg_auc=91.99%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.206458 Test loss=0.320160 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19159024953842163
[5/24] Train loss=0.16905230283737183
[10/24] Train loss=0.21261247992515564
[15/24] Train loss=0.20382554829120636
[20/24] Train loss=0.19875961542129517
Test set avg_accuracy=88.31% avg_sensitivity=71.96%, avg_specificity=94.07% avg_auc=92.39%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.201144 Test loss=0.293612 Current lr=[0.000298904600941902]

[0/24] Train loss=0.19593119621276855
[5/24] Train loss=0.17336897552013397
[10/24] Train loss=0.23098355531692505
[15/24] Train loss=0.21591728925704956
[20/24] Train loss=0.2010822296142578
Test set avg_accuracy=87.06% avg_sensitivity=73.21%, avg_specificity=91.94% avg_auc=92.23%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.201995 Test loss=0.306828 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.1971818208694458
[5/24] Train loss=0.1621677130460739
[10/24] Train loss=0.22606396675109863
[15/24] Train loss=0.20425860583782196
[20/24] Train loss=0.18746045231819153
Test set avg_accuracy=86.72% avg_sensitivity=71.51%, avg_specificity=92.08% avg_auc=91.47%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.197082 Test loss=0.314160 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2026595175266266
[5/24] Train loss=0.16187362372875214
[10/24] Train loss=0.22765634953975677
[15/24] Train loss=0.20396512746810913
[20/24] Train loss=0.18885380029678345
Test set avg_accuracy=86.78% avg_sensitivity=78.41%, avg_specificity=89.73% avg_auc=92.29%
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.201190 Test loss=0.312734 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.20230333507061005
[5/24] Train loss=0.16331058740615845
[10/24] Train loss=0.214377760887146
[15/24] Train loss=0.2053365856409073
[20/24] Train loss=0.18212933838367462
Test set avg_accuracy=86.58% avg_sensitivity=59.67%, avg_specificity=96.06% avg_auc=89.27%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.194885 Test loss=0.342828 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.18517540395259857
[5/24] Train loss=0.1560445874929428
[10/24] Train loss=0.2064254879951477
[15/24] Train loss=0.21313834190368652
[20/24] Train loss=0.1873445361852646
Test set avg_accuracy=87.79% avg_sensitivity=70.46%, avg_specificity=93.89% avg_auc=92.03%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.191448 Test loss=0.305836 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.18722541630268097
[5/24] Train loss=0.16202223300933838
[10/24] Train loss=0.2074381560087204
[15/24] Train loss=0.21765674650669098
[20/24] Train loss=0.19252203404903412
Test set avg_accuracy=86.32% avg_sensitivity=57.77%, avg_specificity=96.37% avg_auc=88.75%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.191574 Test loss=0.362856 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.1897629052400589
[5/24] Train loss=0.1679259091615677
[10/24] Train loss=0.21771658957004547
[15/24] Train loss=0.2062157690525055
[20/24] Train loss=0.1903713196516037
Test set avg_accuracy=82.24% avg_sensitivity=36.13%, avg_specificity=98.49% avg_auc=83.84%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.191189 Test loss=0.485874 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.20146021246910095
[5/24] Train loss=0.164425328373909
[10/24] Train loss=0.21382443606853485
[15/24] Train loss=0.2038549780845642
[20/24] Train loss=0.18573501706123352
Test set avg_accuracy=86.63% avg_sensitivity=58.77%, avg_specificity=96.44% avg_auc=89.12%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.192007 Test loss=0.359884 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.17772644758224487
[5/24] Train loss=0.16839340329170227
[10/24] Train loss=0.21956346929073334
[15/24] Train loss=0.2219567596912384
[20/24] Train loss=0.1903996467590332
Test set avg_accuracy=78.48% avg_sensitivity=19.04%, avg_specificity=99.42% avg_auc=80.91%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.196754 Test loss=0.607196 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.21698781847953796
[5/24] Train loss=0.16128936409950256
[10/24] Train loss=0.21196196973323822
[15/24] Train loss=0.19890078902244568
[20/24] Train loss=0.18735648691654205
Test set avg_accuracy=82.99% avg_sensitivity=40.98%, avg_specificity=97.80% avg_auc=86.81%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.193136 Test loss=0.441427 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18707025051116943
[5/24] Train loss=0.164997860789299
[10/24] Train loss=0.20746411383152008
[15/24] Train loss=0.20007197558879852
[20/24] Train loss=0.1794755607843399
Test set avg_accuracy=87.08% avg_sensitivity=65.27%, avg_specificity=94.77% avg_auc=89.78%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.189804 Test loss=0.329170 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.1844848394393921
[5/24] Train loss=0.1702747344970703
[10/24] Train loss=0.2050989866256714
[15/24] Train loss=0.20397323369979858
[20/24] Train loss=0.172260120511055
Test set avg_accuracy=85.73% avg_sensitivity=52.37%, avg_specificity=97.48% avg_auc=88.50%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.188655 Test loss=0.381681 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.182783305644989
[5/24] Train loss=0.15378010272979736
[10/24] Train loss=0.1987285166978836
[15/24] Train loss=0.18905888497829437
[20/24] Train loss=0.17946986854076385
Test set avg_accuracy=83.67% avg_sensitivity=44.63%, avg_specificity=97.43% avg_auc=85.95%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.182094 Test loss=0.421099 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.1762894093990326
[5/24] Train loss=0.15864361822605133
[10/24] Train loss=0.19946308434009552
[15/24] Train loss=0.19734986126422882
[20/24] Train loss=0.1732511967420578
Test set avg_accuracy=85.52% avg_sensitivity=51.07%, avg_specificity=97.66% avg_auc=87.23%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.183552 Test loss=0.378253 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.17263248562812805
[5/24] Train loss=0.145658940076828
[10/24] Train loss=0.20249345898628235
[15/24] Train loss=0.20498302578926086
[20/24] Train loss=0.18290379643440247
Test set avg_accuracy=86.58% avg_sensitivity=63.82%, avg_specificity=94.59% avg_auc=90.55%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.182190 Test loss=0.328831 Current lr=[0.000276307469034998]

[0/24] Train loss=0.18295234441757202
[5/24] Train loss=0.1636083573102951
[10/24] Train loss=0.21037961542606354
[15/24] Train loss=0.2045300006866455
[20/24] Train loss=0.1734815537929535
Test set avg_accuracy=86.99% avg_sensitivity=64.32%, avg_specificity=94.98% avg_auc=90.54%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.187679 Test loss=0.322472 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.18477854132652283
[5/24] Train loss=0.15547330677509308
[10/24] Train loss=0.19314716756343842
[15/24] Train loss=0.19584456086158752
[20/24] Train loss=0.1806272715330124
Test set avg_accuracy=87.46% avg_sensitivity=66.82%, avg_specificity=94.73% avg_auc=91.36%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.181097 Test loss=0.316551 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.1790483146905899
[5/24] Train loss=0.14594589173793793
[10/24] Train loss=0.20385098457336426
[15/24] Train loss=0.19811537861824036
[20/24] Train loss=0.17677603662014008
Test set avg_accuracy=88.71% avg_sensitivity=75.91%, avg_specificity=93.22% avg_auc=92.89%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.181250 Test loss=0.284645 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.17521382868289948
[5/24] Train loss=0.1569543331861496
[10/24] Train loss=0.193242147564888
[15/24] Train loss=0.19352969527244568
[20/24] Train loss=0.17059741914272308
Test set avg_accuracy=86.81% avg_sensitivity=63.67%, avg_specificity=94.96% avg_auc=90.44%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.180588 Test loss=0.328218 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.18139995634555817
[5/24] Train loss=0.15292806923389435
[10/24] Train loss=0.20743972063064575
[15/24] Train loss=0.18516360223293304
[20/24] Train loss=0.17921485006809235
Test set avg_accuracy=86.65% avg_sensitivity=62.42%, avg_specificity=95.19% avg_auc=89.60%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.182982 Test loss=0.340668 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.1809481829404831
[5/24] Train loss=0.16095717251300812
[10/24] Train loss=0.20489057898521423
[15/24] Train loss=0.19144272804260254
[20/24] Train loss=0.17398659884929657
Test set avg_accuracy=87.70% avg_sensitivity=74.76%, avg_specificity=92.25% avg_auc=91.57%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.183310 Test loss=0.306878 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.18455804884433746
[5/24] Train loss=0.15478532016277313
[10/24] Train loss=0.18751253187656403
[15/24] Train loss=0.18706360459327698
[20/24] Train loss=0.17913682758808136
Test set avg_accuracy=86.42% avg_sensitivity=79.41%, avg_specificity=88.89% avg_auc=91.16%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.177891 Test loss=0.335464 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.1813206821680069
[5/24] Train loss=0.15693357586860657
[10/24] Train loss=0.20360629260540009
[15/24] Train loss=0.1870325207710266
[20/24] Train loss=0.17203834652900696
Test set avg_accuracy=87.28% avg_sensitivity=72.01%, avg_specificity=92.66% avg_auc=91.17%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.177438 Test loss=0.318996 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.1721026450395584
[5/24] Train loss=0.15021945536136627
[10/24] Train loss=0.20391856133937836
[15/24] Train loss=0.19102886319160461
[20/24] Train loss=0.1839144378900528
Test set avg_accuracy=84.78% avg_sensitivity=83.86%, avg_specificity=85.10% avg_auc=91.86%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.180754 Test loss=0.359796 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.18040251731872559
[5/24] Train loss=0.15284746885299683
[10/24] Train loss=0.19764231145381927
[15/24] Train loss=0.19570119678974152
[20/24] Train loss=0.16977663338184357
Test set avg_accuracy=86.97% avg_sensitivity=79.01%, avg_specificity=89.77% avg_auc=92.03%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.178948 Test loss=0.316537 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.17957516014575958
[5/24] Train loss=0.16069155931472778
[10/24] Train loss=0.18913546204566956
[15/24] Train loss=0.18943102657794952
[20/24] Train loss=0.17274050414562225
Test set avg_accuracy=83.91% avg_sensitivity=85.01%, avg_specificity=83.52% avg_auc=91.69%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.176212 Test loss=0.368422 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1785069853067398
[5/24] Train loss=0.15438948571681976
[10/24] Train loss=0.18716375529766083
[15/24] Train loss=0.1902107149362564
[20/24] Train loss=0.1752370297908783
Test set avg_accuracy=85.98% avg_sensitivity=81.96%, avg_specificity=87.39% avg_auc=92.66%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.173558 Test loss=0.322132 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.168057382106781
[5/24] Train loss=0.14805400371551514
[10/24] Train loss=0.186977818608284
[15/24] Train loss=0.18786020576953888
[20/24] Train loss=0.1770482212305069
Test set avg_accuracy=87.06% avg_sensitivity=71.81%, avg_specificity=92.43% avg_auc=90.53%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.172778 Test loss=0.319373 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.17039057612419128
[5/24] Train loss=0.14232999086380005
[10/24] Train loss=0.17722146213054657
[15/24] Train loss=0.178904190659523
[20/24] Train loss=0.17237292230129242
Test set avg_accuracy=83.48% avg_sensitivity=83.41%, avg_specificity=83.50% avg_auc=90.77%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.169723 Test loss=0.384079 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.1713402271270752
[5/24] Train loss=0.1438094824552536
[10/24] Train loss=0.17926743626594543
[15/24] Train loss=0.1826114058494568
[20/24] Train loss=0.17399823665618896
Test set avg_accuracy=87.30% avg_sensitivity=78.01%, avg_specificity=90.58% avg_auc=92.52%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.169084 Test loss=0.303206 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17269304394721985
[5/24] Train loss=0.143649622797966
[10/24] Train loss=0.17629551887512207
[15/24] Train loss=0.17666728794574738
[20/24] Train loss=0.17245525121688843
Test set avg_accuracy=87.84% avg_sensitivity=73.91%, avg_specificity=92.75% avg_auc=91.72%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.168890 Test loss=0.306706 Current lr=[0.000224838296036774]

[0/24] Train loss=0.16085435450077057
[5/24] Train loss=0.13995391130447388
[10/24] Train loss=0.18578673899173737
[15/24] Train loss=0.18684826791286469
[20/24] Train loss=0.1719750463962555
Test set avg_accuracy=88.06% avg_sensitivity=75.76%, avg_specificity=92.39% avg_auc=91.74%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.166518 Test loss=0.303917 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.163901686668396
[5/24] Train loss=0.13675110042095184
[10/24] Train loss=0.18610870838165283
[15/24] Train loss=0.1775410920381546
[20/24] Train loss=0.1679123491048813
Test set avg_accuracy=86.90% avg_sensitivity=80.21%, avg_specificity=89.26% avg_auc=92.14%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.167020 Test loss=0.317347 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.1614503562450409
[5/24] Train loss=0.13835342228412628
[10/24] Train loss=0.17112410068511963
[15/24] Train loss=0.179860919713974
[20/24] Train loss=0.16403555870056152
Test set avg_accuracy=88.31% avg_sensitivity=67.92%, avg_specificity=95.49% avg_auc=91.10%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.164340 Test loss=0.311071 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.16797330975532532
[5/24] Train loss=0.13962504267692566
[10/24] Train loss=0.1913285106420517
[15/24] Train loss=0.17832070589065552
[20/24] Train loss=0.1597440391778946
Test set avg_accuracy=87.97% avg_sensitivity=73.81%, avg_specificity=92.96% avg_auc=91.93%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.168894 Test loss=0.303458 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.16179676353931427
[5/24] Train loss=0.1462695449590683
[10/24] Train loss=0.17414742708206177
[15/24] Train loss=0.18105857074260712
[20/24] Train loss=0.1724771112203598
Test set avg_accuracy=87.04% avg_sensitivity=80.61%, avg_specificity=89.31% avg_auc=92.47%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.166363 Test loss=0.309211 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.16585618257522583
[5/24] Train loss=0.14083261787891388
[10/24] Train loss=0.17509675025939941
[15/24] Train loss=0.18250292539596558
[20/24] Train loss=0.16573552787303925
Test set avg_accuracy=86.71% avg_sensitivity=81.96%, avg_specificity=88.38% avg_auc=92.53%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.164297 Test loss=0.314936 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.16643130779266357
[5/24] Train loss=0.14446310698986053
[10/24] Train loss=0.18804344534873962
[15/24] Train loss=0.1797095537185669
[20/24] Train loss=0.1654479205608368
Test set avg_accuracy=88.29% avg_sensitivity=76.21%, avg_specificity=92.55% avg_auc=92.63%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.168597 Test loss=0.295353 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.17312683165073395
[5/24] Train loss=0.1364595741033554
[10/24] Train loss=0.17046362161636353
[15/24] Train loss=0.17777188122272491
[20/24] Train loss=0.16061946749687195
Test set avg_accuracy=88.20% avg_sensitivity=75.31%, avg_specificity=92.75% avg_auc=92.88%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.163004 Test loss=0.291091 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1572609692811966
[5/24] Train loss=0.13548584282398224
[10/24] Train loss=0.18131718039512634
[15/24] Train loss=0.17179016768932343
[20/24] Train loss=0.15909405052661896
Test set avg_accuracy=87.29% avg_sensitivity=80.91%, avg_specificity=89.54% avg_auc=92.77%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.160300 Test loss=0.305676 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.16081400215625763
[5/24] Train loss=0.13446581363677979
[10/24] Train loss=0.16722501814365387
[15/24] Train loss=0.1667625904083252
[20/24] Train loss=0.16197413206100464
Test set avg_accuracy=87.28% avg_sensitivity=78.66%, avg_specificity=90.32% avg_auc=91.94%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.159479 Test loss=0.317702 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.165427565574646
[5/24] Train loss=0.144548699259758
[10/24] Train loss=0.18549099564552307
[15/24] Train loss=0.17679163813591003
[20/24] Train loss=0.16292347013950348
Test set avg_accuracy=85.65% avg_sensitivity=84.51%, avg_specificity=86.05% avg_auc=92.70%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.162627 Test loss=0.337882 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.1632203757762909
[5/24] Train loss=0.14532388746738434
[10/24] Train loss=0.16807542741298676
[15/24] Train loss=0.1686602383852005
[20/24] Train loss=0.15778151154518127
Test set avg_accuracy=88.18% avg_sensitivity=72.86%, avg_specificity=93.57% avg_auc=92.88%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.162327 Test loss=0.290679 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1568833589553833
[5/24] Train loss=0.14621268212795258
[10/24] Train loss=0.1751152127981186
[15/24] Train loss=0.17213787138462067
[20/24] Train loss=0.16051605343818665
Test set avg_accuracy=87.72% avg_sensitivity=69.57%, avg_specificity=94.12% avg_auc=90.34%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.157654 Test loss=0.322979 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15761679410934448
[5/24] Train loss=0.14063051342964172
[10/24] Train loss=0.17739245295524597
[15/24] Train loss=0.16968470811843872
[20/24] Train loss=0.15400943160057068
Test set avg_accuracy=87.86% avg_sensitivity=78.96%, avg_specificity=91.00% avg_auc=92.13%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.159836 Test loss=0.313290 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.15936236083507538
[5/24] Train loss=0.13930948078632355
[10/24] Train loss=0.1821235716342926
[15/24] Train loss=0.16816817224025726
[20/24] Train loss=0.15653394162654877
Test set avg_accuracy=87.90% avg_sensitivity=70.31%, avg_specificity=94.10% avg_auc=90.71%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.160205 Test loss=0.311516 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.16156865656375885
[5/24] Train loss=0.1390799880027771
[10/24] Train loss=0.165116548538208
[15/24] Train loss=0.1632479429244995
[20/24] Train loss=0.16218888759613037
Test set avg_accuracy=86.60% avg_sensitivity=80.31%, avg_specificity=88.82% avg_auc=91.93%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.157595 Test loss=0.327011 Current lr=[0.000156543481933168]

[0/24] Train loss=0.16217657923698425
[5/24] Train loss=0.13334789872169495
[10/24] Train loss=0.16878561675548553
[15/24] Train loss=0.16447784006595612
[20/24] Train loss=0.1579238325357437
Test set avg_accuracy=87.63% avg_sensitivity=71.06%, avg_specificity=93.47% avg_auc=91.31%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.155635 Test loss=0.313679 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.15568962693214417
[5/24] Train loss=0.14260807633399963
[10/24] Train loss=0.16345848143100739
[15/24] Train loss=0.17372803390026093
[20/24] Train loss=0.1570018082857132
Test set avg_accuracy=88.29% avg_sensitivity=72.11%, avg_specificity=94.00% avg_auc=91.46%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.156100 Test loss=0.306764 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15476065874099731
[5/24] Train loss=0.1342116743326187
[10/24] Train loss=0.16682100296020508
[15/24] Train loss=0.1625334471464157
[20/24] Train loss=0.16676226258277893
Test set avg_accuracy=88.33% avg_sensitivity=72.66%, avg_specificity=93.85% avg_auc=91.37%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.156830 Test loss=0.307749 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.1555391252040863
[5/24] Train loss=0.13948625326156616
[10/24] Train loss=0.16480757296085358
[15/24] Train loss=0.17570385336875916
[20/24] Train loss=0.16161848604679108
Test set avg_accuracy=88.48% avg_sensitivity=67.67%, avg_specificity=95.81% avg_auc=91.66%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.155182 Test loss=0.305213 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15377533435821533
[5/24] Train loss=0.13382060825824738
[10/24] Train loss=0.1696249097585678
[15/24] Train loss=0.1644986867904663
[20/24] Train loss=0.15282505750656128
Test set avg_accuracy=87.67% avg_sensitivity=74.66%, avg_specificity=92.25% avg_auc=91.74%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.153869 Test loss=0.310453 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15174660086631775
[5/24] Train loss=0.1330738514661789
[10/24] Train loss=0.17696213722229004
[15/24] Train loss=0.16344141960144043
[20/24] Train loss=0.15959025919437408
Test set avg_accuracy=86.85% avg_sensitivity=57.02%, avg_specificity=97.36% avg_auc=88.97%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.154670 Test loss=0.365122 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1529119312763214
[5/24] Train loss=0.13160963356494904
[10/24] Train loss=0.15685676038265228
[15/24] Train loss=0.16131046414375305
[20/24] Train loss=0.1581730991601944
Test set avg_accuracy=87.58% avg_sensitivity=71.01%, avg_specificity=93.41% avg_auc=90.71%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.151423 Test loss=0.320577 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1496983915567398
[5/24] Train loss=0.12738409638404846
[10/24] Train loss=0.15655972063541412
[15/24] Train loss=0.16375716030597687
[20/24] Train loss=0.15160290896892548
Test set avg_accuracy=87.63% avg_sensitivity=63.32%, avg_specificity=96.20% avg_auc=89.86%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.149837 Test loss=0.337412 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15378178656101227
[5/24] Train loss=0.1292794644832611
[10/24] Train loss=0.15328902006149292
[15/24] Train loss=0.16473346948623657
[20/24] Train loss=0.15207545459270477
Test set avg_accuracy=86.08% avg_sensitivity=55.97%, avg_specificity=96.69% avg_auc=88.10%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.149800 Test loss=0.375194 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1488279104232788
[5/24] Train loss=0.13138973712921143
[10/24] Train loss=0.1545478254556656
[15/24] Train loss=0.15888457000255585
[20/24] Train loss=0.1499158889055252
Test set avg_accuracy=88.02% avg_sensitivity=66.07%, avg_specificity=95.76% avg_auc=90.49%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.149089 Test loss=0.328474 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14515866339206696
[5/24] Train loss=0.12948743999004364
[10/24] Train loss=0.15265865623950958
[15/24] Train loss=0.15615589916706085
[20/24] Train loss=0.1524060070514679
Test set avg_accuracy=88.29% avg_sensitivity=73.71%, avg_specificity=93.43% avg_auc=92.07%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.150706 Test loss=0.299796 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1503954380750656
[5/24] Train loss=0.12725190818309784
[10/24] Train loss=0.15775270760059357
[15/24] Train loss=0.15818656980991364
[20/24] Train loss=0.14779435098171234
Test set avg_accuracy=88.53% avg_sensitivity=68.02%, avg_specificity=95.76% avg_auc=91.36%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.146585 Test loss=0.305328 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.14668697118759155
[5/24] Train loss=0.12666940689086914
[10/24] Train loss=0.15049050748348236
[15/24] Train loss=0.15110912919044495
[20/24] Train loss=0.14816497266292572
Test set avg_accuracy=88.44% avg_sensitivity=75.46%, avg_specificity=93.01% avg_auc=92.59%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.143341 Test loss=0.292005 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14265652000904083
[5/24] Train loss=0.12645454704761505
[10/24] Train loss=0.1560477316379547
[15/24] Train loss=0.1478731781244278
[20/24] Train loss=0.14328475296497345
Test set avg_accuracy=88.63% avg_sensitivity=74.01%, avg_specificity=93.78% avg_auc=91.61%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.142143 Test loss=0.302646 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14393386244773865
[5/24] Train loss=0.12187450379133224
[10/24] Train loss=0.15047074854373932
[15/24] Train loss=0.1500893086194992
[20/24] Train loss=0.14785851538181305
Test set avg_accuracy=87.55% avg_sensitivity=77.46%, avg_specificity=91.11% avg_auc=91.92%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.140494 Test loss=0.313482 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.14139489829540253
[5/24] Train loss=0.12351714074611664
[10/24] Train loss=0.15024316310882568
[15/24] Train loss=0.15546925365924835
[20/24] Train loss=0.1452523171901703
Test set avg_accuracy=88.26% avg_sensitivity=68.87%, avg_specificity=95.09% avg_auc=90.76%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.141627 Test loss=0.313382 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14005503058433533
[5/24] Train loss=0.11922655254602432
[10/24] Train loss=0.14198608696460724
[15/24] Train loss=0.1477685570716858
[20/24] Train loss=0.13929107785224915
Test set avg_accuracy=88.26% avg_sensitivity=72.81%, avg_specificity=93.70% avg_auc=92.21%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.138198 Test loss=0.298342 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13547921180725098
[5/24] Train loss=0.12207864969968796
[10/24] Train loss=0.1460801512002945
[15/24] Train loss=0.14696012437343597
[20/24] Train loss=0.13797037303447723
Test set avg_accuracy=88.58% avg_sensitivity=77.36%, avg_specificity=92.53% avg_auc=92.34%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.137267 Test loss=0.299560 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13948644697666168
[5/24] Train loss=0.11930396407842636
[10/24] Train loss=0.1400911659002304
[15/24] Train loss=0.1430026739835739
[20/24] Train loss=0.14197228848934174
Test set avg_accuracy=87.80% avg_sensitivity=77.81%, avg_specificity=91.32% avg_auc=92.28%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.135804 Test loss=0.305766 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13662788271903992
[5/24] Train loss=0.11806149035692215
[10/24] Train loss=0.1380733847618103
[15/24] Train loss=0.13901424407958984
[20/24] Train loss=0.13807542622089386
Test set avg_accuracy=87.67% avg_sensitivity=77.01%, avg_specificity=91.42% avg_auc=92.15%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.135054 Test loss=0.304472 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13900169730186462
[5/24] Train loss=0.11868537962436676
[10/24] Train loss=0.14376594126224518
[15/24] Train loss=0.14107349514961243
[20/24] Train loss=0.13694584369659424
Test set avg_accuracy=88.58% avg_sensitivity=76.66%, avg_specificity=92.78% avg_auc=92.57%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.134737 Test loss=0.294182 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1313517689704895
[5/24] Train loss=0.11597465723752975
[10/24] Train loss=0.14335386455059052
[15/24] Train loss=0.14248345792293549
[20/24] Train loss=0.13673964142799377
Test set avg_accuracy=87.45% avg_sensitivity=80.01%, avg_specificity=90.07% avg_auc=92.14%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.133349 Test loss=0.316735 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13557401299476624
[5/24] Train loss=0.11722183227539062
[10/24] Train loss=0.13876397907733917
[15/24] Train loss=0.14099188148975372
[20/24] Train loss=0.1338910460472107
Test set avg_accuracy=87.79% avg_sensitivity=77.31%, avg_specificity=91.48% avg_auc=92.34%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.132733 Test loss=0.306309 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.132091224193573
[5/24] Train loss=0.11796572059392929
[10/24] Train loss=0.13512155413627625
[15/24] Train loss=0.13835054636001587
[20/24] Train loss=0.13546106219291687
Test set avg_accuracy=88.55% avg_sensitivity=74.86%, avg_specificity=93.38% avg_auc=92.33%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.131355 Test loss=0.298216 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13226626813411713
[5/24] Train loss=0.11170259118080139
[10/24] Train loss=0.13566134870052338
[15/24] Train loss=0.13732470571994781
[20/24] Train loss=0.13550356030464172
Test set avg_accuracy=88.19% avg_sensitivity=76.26%, avg_specificity=92.39% avg_auc=92.05%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.131109 Test loss=0.307414 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1303989440202713
[5/24] Train loss=0.11219551414251328
[10/24] Train loss=0.13907229900360107
[15/24] Train loss=0.14143581688404083
[20/24] Train loss=0.13237015902996063
Test set avg_accuracy=88.33% avg_sensitivity=70.36%, avg_specificity=94.66% avg_auc=91.77%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.130646 Test loss=0.302930 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13019083440303802
[5/24] Train loss=0.116726353764534
[10/24] Train loss=0.13331571221351624
[15/24] Train loss=0.13770771026611328
[20/24] Train loss=0.13319313526153564
Test set avg_accuracy=88.32% avg_sensitivity=73.01%, avg_specificity=93.71% avg_auc=91.51%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.130215 Test loss=0.307279 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1322513371706009
[5/24] Train loss=0.11242348700761795
[10/24] Train loss=0.13501879572868347
[15/24] Train loss=0.13679516315460205
[20/24] Train loss=0.12877003848552704
Test set avg_accuracy=88.14% avg_sensitivity=70.96%, avg_specificity=94.19% avg_auc=91.26%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.128898 Test loss=0.311553 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12965309619903564
[5/24] Train loss=0.11379335075616837
[10/24] Train loss=0.1311357617378235
[15/24] Train loss=0.1370898336172104
[20/24] Train loss=0.13081477582454681
Test set avg_accuracy=88.45% avg_sensitivity=72.66%, avg_specificity=94.01% avg_auc=92.25%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.128592 Test loss=0.294118 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1263321042060852
[5/24] Train loss=0.11507857590913773
[10/24] Train loss=0.1332426369190216
[15/24] Train loss=0.13605748116970062
[20/24] Train loss=0.13083235919475555
Test set avg_accuracy=88.20% avg_sensitivity=75.36%, avg_specificity=92.73% avg_auc=92.13%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.128735 Test loss=0.299595 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12700417637825012
[5/24] Train loss=0.11234813183546066
[10/24] Train loss=0.13330423831939697
[15/24] Train loss=0.13368496298789978
[20/24] Train loss=0.13264746963977814
Test set avg_accuracy=87.80% avg_sensitivity=77.01%, avg_specificity=91.60% avg_auc=91.99%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.127911 Test loss=0.303131 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13036325573921204
[5/24] Train loss=0.11300963163375854
[10/24] Train loss=0.1361074000597
[15/24] Train loss=0.13625359535217285
[20/24] Train loss=0.13129466772079468
Test set avg_accuracy=87.77% avg_sensitivity=79.86%, avg_specificity=90.56% avg_auc=92.18%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.127788 Test loss=0.311489 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12648309767246246
[5/24] Train loss=0.11235187202692032
[10/24] Train loss=0.13026875257492065
[15/24] Train loss=0.1365540474653244
[20/24] Train loss=0.12729056179523468
Test set avg_accuracy=88.12% avg_sensitivity=76.41%, avg_specificity=92.25% avg_auc=91.88%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.126733 Test loss=0.305688 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1280468851327896
[5/24] Train loss=0.11069393157958984
[10/24] Train loss=0.12724320590496063
[15/24] Train loss=0.13232651352882385
[20/24] Train loss=0.13027581572532654
Test set avg_accuracy=88.20% avg_sensitivity=78.51%, avg_specificity=91.62% avg_auc=92.42%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.125447 Test loss=0.300562 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12810258567333221
[5/24] Train loss=0.10964775830507278
[10/24] Train loss=0.1290305256843567
[15/24] Train loss=0.13352862000465393
[20/24] Train loss=0.1288374960422516
Test set avg_accuracy=88.45% avg_sensitivity=75.46%, avg_specificity=93.03% avg_auc=91.92%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.125490 Test loss=0.301642 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12593428790569305
[5/24] Train loss=0.11230097711086273
[10/24] Train loss=0.1278311312198639
[15/24] Train loss=0.13680891692638397
[20/24] Train loss=0.1276833862066269
Test set avg_accuracy=88.23% avg_sensitivity=75.71%, avg_specificity=92.64% avg_auc=91.97%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.125568 Test loss=0.303182 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12430447340011597
[5/24] Train loss=0.1099967435002327
[10/24] Train loss=0.13088826835155487
[15/24] Train loss=0.13162943720817566
[20/24] Train loss=0.12522371113300323
Test set avg_accuracy=88.27% avg_sensitivity=75.61%, avg_specificity=92.73% avg_auc=92.17%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.124625 Test loss=0.299250 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1241055279970169
[5/24] Train loss=0.11181603372097015
[10/24] Train loss=0.13201145827770233
[15/24] Train loss=0.13214796781539917
[20/24] Train loss=0.13041375577449799
Test set avg_accuracy=88.10% avg_sensitivity=77.01%, avg_specificity=92.01% avg_auc=92.62%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.125311 Test loss=0.295173 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12522409856319427
[5/24] Train loss=0.11018045246601105
[10/24] Train loss=0.129381462931633
[15/24] Train loss=0.13270433247089386
[20/24] Train loss=0.13084083795547485
Test set avg_accuracy=87.85% avg_sensitivity=76.86%, avg_specificity=91.72% avg_auc=92.14%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.124786 Test loss=0.304187 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12633737921714783
[5/24] Train loss=0.10718074440956116
[10/24] Train loss=0.12832139432430267
[15/24] Train loss=0.13200810551643372
[20/24] Train loss=0.12777656316757202
Test set avg_accuracy=87.72% avg_sensitivity=76.46%, avg_specificity=91.69% avg_auc=92.04%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.123847 Test loss=0.306512 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12383662164211273
[5/24] Train loss=0.10781797766685486
[10/24] Train loss=0.12669923901557922
[15/24] Train loss=0.13366085290908813
[20/24] Train loss=0.125934898853302
Test set avg_accuracy=87.62% avg_sensitivity=77.76%, avg_specificity=91.09% avg_auc=92.30%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.123142 Test loss=0.304544 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12259498238563538
[5/24] Train loss=0.10868670046329498
[10/24] Train loss=0.1259816735982895
[15/24] Train loss=0.1289234459400177
[20/24] Train loss=0.12692388892173767
Test set avg_accuracy=88.12% avg_sensitivity=76.61%, avg_specificity=92.18% avg_auc=92.42%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.122309 Test loss=0.298826 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.11985448747873306
[5/24] Train loss=0.10966435819864273
[10/24] Train loss=0.12214311957359314
[15/24] Train loss=0.12854166328907013
[20/24] Train loss=0.12583476305007935
Test set avg_accuracy=87.97% avg_sensitivity=76.56%, avg_specificity=91.99% avg_auc=92.21%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.121328 Test loss=0.301430 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1220630407333374
[5/24] Train loss=0.10789663344621658
[10/24] Train loss=0.12496855109930038
[15/24] Train loss=0.1299467831850052
[20/24] Train loss=0.12277258932590485
Test set avg_accuracy=87.81% avg_sensitivity=76.46%, avg_specificity=91.81% avg_auc=92.23%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.121491 Test loss=0.301637 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11823004484176636
[5/24] Train loss=0.10755589604377747
[10/24] Train loss=0.12366842478513718
[15/24] Train loss=0.12981224060058594
[20/24] Train loss=0.12373556196689606
Test set avg_accuracy=87.96% avg_sensitivity=76.51%, avg_specificity=91.99% avg_auc=92.33%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.120855 Test loss=0.300160 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12050020694732666
[5/24] Train loss=0.10690965503454208
[10/24] Train loss=0.12441474199295044
[15/24] Train loss=0.1287507712841034
[20/24] Train loss=0.1235056146979332
Test set avg_accuracy=88.14% avg_sensitivity=76.96%, avg_specificity=92.08% avg_auc=92.33%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.120761 Test loss=0.300353 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1192740797996521
[5/24] Train loss=0.10698021203279495
[10/24] Train loss=0.12440671026706696
[15/24] Train loss=0.13060355186462402
[20/24] Train loss=0.12309238314628601
Test set avg_accuracy=88.19% avg_sensitivity=77.41%, avg_specificity=91.99% avg_auc=92.33%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.120845 Test loss=0.299510 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.11987246572971344
[5/24] Train loss=0.10581576824188232
[10/24] Train loss=0.12434589862823486
[15/24] Train loss=0.12935897707939148
[20/24] Train loss=0.12374282628297806
Test set avg_accuracy=88.15% avg_sensitivity=76.56%, avg_specificity=92.23% avg_auc=92.33%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.120856 Test loss=0.299047 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11998944729566574
[5/24] Train loss=0.1070389449596405
[10/24] Train loss=0.12397002428770065
[15/24] Train loss=0.13123458623886108
[20/24] Train loss=0.1259557008743286
Test set avg_accuracy=88.02% avg_sensitivity=76.36%, avg_specificity=92.13% avg_auc=92.26%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.120746 Test loss=0.300710 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11924368143081665
[5/24] Train loss=0.10727601498365402
[10/24] Train loss=0.12213271111249924
[15/24] Train loss=0.12774139642715454
[20/24] Train loss=0.12225770205259323
Test set avg_accuracy=88.02% avg_sensitivity=76.66%, avg_specificity=92.02% avg_auc=92.27%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.120222 Test loss=0.301121 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11998868733644485
[5/24] Train loss=0.10961920022964478
[10/24] Train loss=0.12240645289421082
[15/24] Train loss=0.12803857028484344
[20/24] Train loss=0.1254558116197586
Test set avg_accuracy=88.11% avg_sensitivity=76.71%, avg_specificity=92.13% avg_auc=92.31%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.120303 Test loss=0.300314 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11957153677940369
[5/24] Train loss=0.10550901293754578
[10/24] Train loss=0.1232704371213913
[15/24] Train loss=0.12831932306289673
[20/24] Train loss=0.12273905426263809
Test set avg_accuracy=88.12% avg_sensitivity=76.51%, avg_specificity=92.22% avg_auc=92.31%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.120175 Test loss=0.299992 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11832670122385025
[5/24] Train loss=0.1053130179643631
[10/24] Train loss=0.12207755446434021
[15/24] Train loss=0.12871591746807098
[20/24] Train loss=0.12443030625581741
Test set avg_accuracy=88.16% avg_sensitivity=76.51%, avg_specificity=92.27% avg_auc=92.30%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.120293 Test loss=0.299871 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12188686430454254
[5/24] Train loss=0.10680442303419113
[10/24] Train loss=0.12417315691709518
[15/24] Train loss=0.12747295200824738
[20/24] Train loss=0.12363312393426895
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=88.12% avg_sensitivity=76.51%, avg_specificity=92.22% avg_auc=92.30%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.120420 Test loss=0.300086 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=87.03% sen=82.66%, spe=88.57%, auc=93.07%!
Fold[4] Avg_overlap=0.68%(0.23609087646074378)
[0/24] Train loss=0.7372556924819946
[5/24] Train loss=0.7267881035804749
[10/24] Train loss=0.7209845781326294
[15/24] Train loss=0.7064966559410095
[20/24] Train loss=0.7043803334236145
Test set avg_accuracy=60.62% avg_sensitivity=47.82%, avg_specificity=64.99% avg_auc=60.28%
Best model saved!! Metric=-92.27652403733235!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.717514 Test loss=0.652935 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7051153182983398
[5/24] Train loss=0.688058614730835
[10/24] Train loss=0.6983779072761536
[15/24] Train loss=0.6781445741653442
[20/24] Train loss=0.6696377396583557
Test set avg_accuracy=69.11% avg_sensitivity=60.93%, avg_specificity=71.91% avg_auc=72.67%
Best model saved!! Metric=-51.38261559618111!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.687851 Test loss=0.602131 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6661292910575867
[5/24] Train loss=0.658990740776062
[10/24] Train loss=0.670475959777832
[15/24] Train loss=0.6464738249778748
[20/24] Train loss=0.6461014151573181
Test set avg_accuracy=72.37% avg_sensitivity=66.87%, avg_specificity=74.24% avg_auc=76.99%
Best model saved!! Metric=-35.519442958335716!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.660574 Test loss=0.568009 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6465656757354736
[5/24] Train loss=0.6393005847930908
[10/24] Train loss=0.6395694017410278
[15/24] Train loss=0.616858720779419
[20/24] Train loss=0.6070943474769592
Test set avg_accuracy=74.17% avg_sensitivity=72.15%, avg_specificity=74.86% avg_auc=80.42%
Best model saved!! Metric=-24.413589575023536!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.633089 Test loss=0.541625 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6094728112220764
[5/24] Train loss=0.5994795560836792
[10/24] Train loss=0.6134092211723328
[15/24] Train loss=0.5825083255767822
[20/24] Train loss=0.5826079249382019
Test set avg_accuracy=74.96% avg_sensitivity=76.40%, avg_specificity=74.47% avg_auc=83.01%
Best model saved!! Metric=-17.16693693994462!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.602864 Test loss=0.519814 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5868984460830688
[5/24] Train loss=0.5721623301506042
[10/24] Train loss=0.59670490026474
[15/24] Train loss=0.5535430908203125
[20/24] Train loss=0.5537984371185303
Test set avg_accuracy=77.08% avg_sensitivity=77.21%, avg_specificity=77.04% avg_auc=84.86%
Best model saved!! Metric=-9.80731400858896!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.575633 Test loss=0.492114 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5536016821861267
[5/24] Train loss=0.5505129098892212
[10/24] Train loss=0.5619586110115051
[15/24] Train loss=0.5144846439361572
[20/24] Train loss=0.5216521620750427
Test set avg_accuracy=78.41% avg_sensitivity=79.57%, avg_specificity=78.02% avg_auc=86.64%
Best model saved!! Metric=-3.3661256104920056!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.547152 Test loss=0.471198 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5294866561889648
[5/24] Train loss=0.5170456767082214
[10/24] Train loss=0.530515730381012
[15/24] Train loss=0.4964749217033386
[20/24] Train loss=0.5006183385848999
Test set avg_accuracy=80.57% avg_sensitivity=79.21%, avg_specificity=81.04% avg_auc=88.02%
Best model saved!! Metric=2.8395020089038354!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.519111 Test loss=0.444667 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.499492347240448
[5/24] Train loss=0.4892862141132355
[10/24] Train loss=0.5083772540092468
[15/24] Train loss=0.46411606669425964
[20/24] Train loss=0.46725836396217346
Test set avg_accuracy=82.28% avg_sensitivity=78.08%, avg_specificity=83.71% avg_auc=89.08%
Best model saved!! Metric=7.149047898415944!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.491506 Test loss=0.420202 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.467516154050827
[5/24] Train loss=0.4596385061740875
[10/24] Train loss=0.4838653802871704
[15/24] Train loss=0.43872711062431335
[20/24] Train loss=0.4342342019081116
Test set avg_accuracy=83.83% avg_sensitivity=79.21%, avg_specificity=85.40% avg_auc=90.33%
Best model saved!! Metric=12.773237715605632!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.463658 Test loss=0.397930 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.44653162360191345
[5/24] Train loss=0.4280723035335541
[10/24] Train loss=0.45534199476242065
[15/24] Train loss=0.4109817147254944
[20/24] Train loss=0.40768179297447205
Test set avg_accuracy=84.62% avg_sensitivity=78.70%, avg_specificity=86.64% avg_auc=91.19%
Best model saved!! Metric=15.156830730025092!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.436452 Test loss=0.380214 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.41896551847457886
[5/24] Train loss=0.400253564119339
[10/24] Train loss=0.4283551573753357
[15/24] Train loss=0.3809564709663391
[20/24] Train loss=0.38466376066207886
Test set avg_accuracy=85.89% avg_sensitivity=77.52%, avg_specificity=88.74% avg_auc=91.78%
Best model saved!! Metric=17.92301240682579!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.411508 Test loss=0.359868 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3945235013961792
[5/24] Train loss=0.38414648175239563
[10/24] Train loss=0.4126085937023163
[15/24] Train loss=0.36758100986480713
[20/24] Train loss=0.36489152908325195
Test set avg_accuracy=86.97% avg_sensitivity=74.24%, avg_specificity=91.30% avg_auc=92.12%
Best model saved!! Metric=18.637325666090746!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.389756 Test loss=0.339097 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.37115541100502014
[5/24] Train loss=0.3551401197910309
[10/24] Train loss=0.38782167434692383
[15/24] Train loss=0.3438422679901123
[20/24] Train loss=0.3421321511268616
Test set avg_accuracy=87.15% avg_sensitivity=75.93%, avg_specificity=90.97% avg_auc=92.70%
Best model saved!! Metric=20.75479185618117!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.369469 Test loss=0.330811 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.35603803396224976
[5/24] Train loss=0.3458460569381714
[10/24] Train loss=0.36946865916252136
[15/24] Train loss=0.32708218693733215
[20/24] Train loss=0.3335334062576294
Test set avg_accuracy=87.30% avg_sensitivity=75.27%, avg_specificity=91.41% avg_auc=92.87%
Best model saved!! Metric=20.85160421246529!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.352960 Test loss=0.319338 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.33941683173179626
[5/24] Train loss=0.3276219964027405
[10/24] Train loss=0.3603500425815582
[15/24] Train loss=0.31887367367744446
[20/24] Train loss=0.3128996789455414
Test set avg_accuracy=87.33% avg_sensitivity=76.55%, avg_specificity=91.01% avg_auc=93.15%
Best model saved!! Metric=22.03390832064764!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.338927 Test loss=0.310570 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.32433968782424927
[5/24] Train loss=0.3187329173088074
[10/24] Train loss=0.3485336899757385
[15/24] Train loss=0.3036433756351471
[20/24] Train loss=0.30497610569000244
Test set avg_accuracy=87.02% avg_sensitivity=80.59%, avg_specificity=89.21% avg_auc=93.60%
Best model saved!! Metric=24.4215385237772!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.328047 Test loss=0.311453 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3155767619609833
[5/24] Train loss=0.30518803000450134
[10/24] Train loss=0.34161823987960815
[15/24] Train loss=0.2856658101081848
[20/24] Train loss=0.2911655008792877
Test set avg_accuracy=87.70% avg_sensitivity=77.01%, avg_specificity=91.34% avg_auc=93.62%
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.316818 Test loss=0.298008 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.30421507358551025
[5/24] Train loss=0.2930217981338501
[10/24] Train loss=0.3382051885128021
[15/24] Train loss=0.28019842505455017
[20/24] Train loss=0.2836182117462158
Test set avg_accuracy=88.19% avg_sensitivity=77.68%, avg_specificity=91.78% avg_auc=93.89%
Best model saved!! Metric=25.532916409426534!!
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.306102 Test loss=0.288565 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2939717471599579
[5/24] Train loss=0.29531389474868774
[10/24] Train loss=0.33011752367019653
[15/24] Train loss=0.28010907769203186
[20/24] Train loss=0.2820214629173279
Test set avg_accuracy=87.93% avg_sensitivity=80.18%, avg_specificity=90.57% avg_auc=94.09%
Best model saved!! Metric=26.773215310120676!!
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.300424 Test loss=0.292930 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.29647329449653625
[5/24] Train loss=0.28009289503097534
[10/24] Train loss=0.3174876570701599
[15/24] Train loss=0.269070029258728
[20/24] Train loss=0.27814769744873047
Test set avg_accuracy=88.10% avg_sensitivity=78.80%, avg_specificity=91.27% avg_auc=94.20%
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.293459 Test loss=0.282655 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2853819727897644
[5/24] Train loss=0.26289811730384827
[10/24] Train loss=0.31950828433036804
[15/24] Train loss=0.2579245865345001
[20/24] Train loss=0.2690585255622864
Test set avg_accuracy=88.70% avg_sensitivity=76.19%, avg_specificity=92.96% avg_auc=94.30%
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.284908 Test loss=0.274538 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.27980953454971313
[5/24] Train loss=0.26628515124320984
[10/24] Train loss=0.31163010001182556
[15/24] Train loss=0.2547147870063782
[20/24] Train loss=0.26118361949920654
Test set avg_accuracy=88.82% avg_sensitivity=68.36%, avg_specificity=95.79% avg_auc=93.52%
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.279346 Test loss=0.281841 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.27766138315200806
[5/24] Train loss=0.26045599579811096
[10/24] Train loss=0.3167344033718109
[15/24] Train loss=0.24841147661209106
[20/24] Train loss=0.2577505111694336
Test set avg_accuracy=88.65% avg_sensitivity=72.04%, avg_specificity=94.31% avg_auc=94.11%
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.274420 Test loss=0.270614 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2701384425163269
[5/24] Train loss=0.2548576593399048
[10/24] Train loss=0.3009628355503082
[15/24] Train loss=0.24187608063220978
[20/24] Train loss=0.25171947479248047
Test set avg_accuracy=88.88% avg_sensitivity=70.15%, avg_specificity=95.27% avg_auc=93.88%
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.268674 Test loss=0.273314 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2687492370605469
[5/24] Train loss=0.24289074540138245
[10/24] Train loss=0.29966700077056885
[15/24] Train loss=0.2377682477235794
[20/24] Train loss=0.2430095076560974
Test set avg_accuracy=88.79% avg_sensitivity=74.76%, avg_specificity=93.57% avg_auc=94.40%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.261142 Test loss=0.266210 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.25888296961784363
[5/24] Train loss=0.24169614911079407
[10/24] Train loss=0.29773929715156555
[15/24] Train loss=0.2249823659658432
[20/24] Train loss=0.2354148030281067
Test set avg_accuracy=88.62% avg_sensitivity=72.25%, avg_specificity=94.20% avg_auc=93.71%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.256427 Test loss=0.275619 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2548925280570984
[5/24] Train loss=0.23475366830825806
[10/24] Train loss=0.28608831763267517
[15/24] Train loss=0.22622545063495636
[20/24] Train loss=0.23862141370773315
Test set avg_accuracy=87.63% avg_sensitivity=59.45%, avg_specificity=97.24% avg_auc=92.47%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.251777 Test loss=0.303653 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2546820342540741
[5/24] Train loss=0.22896310687065125
[10/24] Train loss=0.2907800078392029
[15/24] Train loss=0.2191280871629715
[20/24] Train loss=0.2354411631822586
Test set avg_accuracy=86.69% avg_sensitivity=56.37%, avg_specificity=97.03% avg_auc=91.72%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.250245 Test loss=0.319253 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.25661101937294006
[5/24] Train loss=0.22370991110801697
[10/24] Train loss=0.28409233689308167
[15/24] Train loss=0.21762531995773315
[20/24] Train loss=0.2302541583776474
Test set avg_accuracy=86.71% avg_sensitivity=55.50%, avg_specificity=97.35% avg_auc=92.17%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.247287 Test loss=0.324223 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2539408504962921
[5/24] Train loss=0.2200945019721985
[10/24] Train loss=0.2759307324886322
[15/24] Train loss=0.21550846099853516
[20/24] Train loss=0.2295847088098526
Test set avg_accuracy=86.12% avg_sensitivity=52.02%, avg_specificity=97.75% avg_auc=90.71%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.241648 Test loss=0.352549 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.24457181990146637
[5/24] Train loss=0.21681548655033112
[10/24] Train loss=0.2731013894081116
[15/24] Train loss=0.21147623658180237
[20/24] Train loss=0.22815944254398346
Test set avg_accuracy=85.85% avg_sensitivity=52.74%, avg_specificity=97.14% avg_auc=91.11%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.238784 Test loss=0.347032 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2462112307548523
[5/24] Train loss=0.21110109984874725
[10/24] Train loss=0.2748982906341553
[15/24] Train loss=0.21725773811340332
[20/24] Train loss=0.22618679702281952
Test set avg_accuracy=88.37% avg_sensitivity=73.94%, avg_specificity=93.29% avg_auc=93.90%
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.235297 Test loss=0.270111 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.24081793427467346
[5/24] Train loss=0.2085358202457428
[10/24] Train loss=0.2649427056312561
[15/24] Train loss=0.20877483487129211
[20/24] Train loss=0.21614603698253632
Test set avg_accuracy=84.49% avg_sensitivity=45.16%, avg_specificity=97.90% avg_auc=89.16%
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.234094 Test loss=0.384359 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.24845744669437408
[5/24] Train loss=0.21118929982185364
[10/24] Train loss=0.25784432888031006
[15/24] Train loss=0.20424138009548187
[20/24] Train loss=0.221095010638237
Test set avg_accuracy=84.66% avg_sensitivity=47.77%, avg_specificity=97.24% avg_auc=88.39%
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.229688 Test loss=0.397029 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.22999967634677887
[5/24] Train loss=0.20188619196414948
[10/24] Train loss=0.2609180212020874
[15/24] Train loss=0.20810283720493317
[20/24] Train loss=0.21138843894004822
Test set avg_accuracy=84.19% avg_sensitivity=44.44%, avg_specificity=97.75% avg_auc=87.88%
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.226854 Test loss=0.404120 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.24412208795547485
[5/24] Train loss=0.2040438950061798
[10/24] Train loss=0.27211618423461914
[15/24] Train loss=0.20688368380069733
[20/24] Train loss=0.2112484872341156
Test set avg_accuracy=88.66% avg_sensitivity=76.45%, avg_specificity=92.82% avg_auc=93.88%
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.225453 Test loss=0.268887 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.21927128732204437
[5/24] Train loss=0.19490212202072144
[10/24] Train loss=0.2546829879283905
[15/24] Train loss=0.20229999721050262
[20/24] Train loss=0.20293830335140228
Test set avg_accuracy=87.30% avg_sensitivity=67.95%, avg_specificity=93.91% avg_auc=92.07%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.217272 Test loss=0.300899 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.22004202008247375
[5/24] Train loss=0.203179270029068
[10/24] Train loss=0.2527504861354828
[15/24] Train loss=0.20389312505722046
[20/24] Train loss=0.21287138760089874
Test set avg_accuracy=87.64% avg_sensitivity=81.16%, avg_specificity=89.86% avg_auc=94.64%
Best model saved!! Metric=27.298105847413993!!
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.221569 Test loss=0.264076 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.22986553609371185
[5/24] Train loss=0.19733338057994843
[10/24] Train loss=0.2553134858608246
[15/24] Train loss=0.20371538400650024
[20/24] Train loss=0.21170520782470703
Test set avg_accuracy=87.89% avg_sensitivity=61.50%, avg_specificity=96.89% avg_auc=92.29%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.222521 Test loss=0.299720 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.22602473199367523
[5/24] Train loss=0.18480578064918518
[10/24] Train loss=0.2573240101337433
[15/24] Train loss=0.1992734670639038
[20/24] Train loss=0.20325911045074463
Test set avg_accuracy=85.95% avg_sensitivity=51.87%, avg_specificity=97.57% avg_auc=89.81%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.217061 Test loss=0.362762 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.22005246579647064
[5/24] Train loss=0.18972457945346832
[10/24] Train loss=0.23637357354164124
[15/24] Train loss=0.1971343755722046
[20/24] Train loss=0.2089235782623291
Test set avg_accuracy=88.07% avg_sensitivity=61.65%, avg_specificity=97.08% avg_auc=92.18%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.215257 Test loss=0.305215 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2102760672569275
[5/24] Train loss=0.1842341423034668
[10/24] Train loss=0.25041237473487854
[15/24] Train loss=0.19522948563098907
[20/24] Train loss=0.20656907558441162
Test set avg_accuracy=87.67% avg_sensitivity=73.43%, avg_specificity=92.53% avg_auc=92.34%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.214123 Test loss=0.292684 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.21999144554138184
[5/24] Train loss=0.183634415268898
[10/24] Train loss=0.2561154365539551
[15/24] Train loss=0.2010251134634018
[20/24] Train loss=0.20419523119926453
Test set avg_accuracy=86.39% avg_sensitivity=80.85%, avg_specificity=88.28% avg_auc=93.27%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.214191 Test loss=0.307051 Current lr=[0.00029967723776099]

[0/24] Train loss=0.22754310071468353
[5/24] Train loss=0.17890171706676483
[10/24] Train loss=0.23684878647327423
[15/24] Train loss=0.19169627130031586
[20/24] Train loss=0.20407798886299133
Test set avg_accuracy=87.80% avg_sensitivity=77.32%, avg_specificity=91.37% avg_auc=93.37%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.210516 Test loss=0.286110 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.21157272160053253
[5/24] Train loss=0.17583730816841125
[10/24] Train loss=0.23381930589675903
[15/24] Train loss=0.1938597559928894
[20/24] Train loss=0.2020418643951416
Test set avg_accuracy=85.48% avg_sensitivity=54.02%, avg_specificity=96.21% avg_auc=88.53%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.208487 Test loss=0.363161 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.22745366394519806
[5/24] Train loss=0.1865462213754654
[10/24] Train loss=0.22145873308181763
[15/24] Train loss=0.18937169015407562
[20/24] Train loss=0.18600694835186005
Test set avg_accuracy=87.51% avg_sensitivity=79.62%, avg_specificity=90.20% avg_auc=93.48%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.209589 Test loss=0.287656 Current lr=[0.000299720220882401]

[0/24] Train loss=0.21656112372875214
[5/24] Train loss=0.17393480241298676
[10/24] Train loss=0.23326638340950012
[15/24] Train loss=0.19012479484081268
[20/24] Train loss=0.18374140560626984
Test set avg_accuracy=85.98% avg_sensitivity=85.56%, avg_specificity=86.12% avg_auc=93.82%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.204504 Test loss=0.310354 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2043372094631195
[5/24] Train loss=0.17027106881141663
[10/24] Train loss=0.22904928028583527
[15/24] Train loss=0.17461514472961426
[20/24] Train loss=0.18254761397838593
Test set avg_accuracy=85.57% avg_sensitivity=86.12%, avg_specificity=85.39% avg_auc=93.59%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.201427 Test loss=0.321490 Current lr=[0.000298904600941902]

[0/24] Train loss=0.20617683231830597
[5/24] Train loss=0.17245493829250336
[10/24] Train loss=0.2227955013513565
[15/24] Train loss=0.1838269978761673
[20/24] Train loss=0.19313926994800568
Test set avg_accuracy=86.85% avg_sensitivity=74.71%, avg_specificity=90.99% avg_auc=91.67%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.198962 Test loss=0.317357 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.20056164264678955
[5/24] Train loss=0.17416085302829742
[10/24] Train loss=0.22247105836868286
[15/24] Train loss=0.18463648855686188
[20/24] Train loss=0.2030210644006729
Test set avg_accuracy=81.07% avg_sensitivity=88.53%, avg_specificity=78.52% avg_auc=92.00%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.204901 Test loss=0.401364 Current lr=[0.000297555943323901]

[0/24] Train loss=0.20904916524887085
[5/24] Train loss=0.17252251505851746
[10/24] Train loss=0.211232990026474
[15/24] Train loss=0.19260793924331665
[20/24] Train loss=0.19264058768749237
Test set avg_accuracy=79.58% avg_sensitivity=89.14%, avg_specificity=76.32% avg_auc=91.14%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.201944 Test loss=0.429815 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.204057976603508
[5/24] Train loss=0.19268304109573364
[10/24] Train loss=0.21674810349941254
[15/24] Train loss=0.1779935508966446
[20/24] Train loss=0.18659944832324982
Test set avg_accuracy=88.95% avg_sensitivity=78.65%, avg_specificity=92.46% avg_auc=93.97%
Best model saved!! Metric=28.0206855655385!!
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.199214 Test loss=0.271726 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.18842434883117676
[5/24] Train loss=0.18360136449337006
[10/24] Train loss=0.21895161271095276
[15/24] Train loss=0.18507444858551025
[20/24] Train loss=0.18543589115142822
Test set avg_accuracy=85.09% avg_sensitivity=87.15%, avg_specificity=84.39% avg_auc=93.65%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.198082 Test loss=0.326106 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.20044054090976715
[5/24] Train loss=0.1806129813194275
[10/24] Train loss=0.22018694877624512
[15/24] Train loss=0.18264560401439667
[20/24] Train loss=0.1934375911951065
Test set avg_accuracy=88.26% avg_sensitivity=70.56%, avg_specificity=94.29% avg_auc=93.15%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.202656 Test loss=0.281227 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.19503489136695862
[5/24] Train loss=0.17586566507816315
[10/24] Train loss=0.2085740566253662
[15/24] Train loss=0.17822329699993134
[20/24] Train loss=0.17297127842903137
Test set avg_accuracy=88.76% avg_sensitivity=75.17%, avg_specificity=93.40% avg_auc=94.27%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.193866 Test loss=0.267599 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.19664366543293
[5/24] Train loss=0.16568589210510254
[10/24] Train loss=0.21413616836071014
[15/24] Train loss=0.1834462583065033
[20/24] Train loss=0.17944756150245667
Test set avg_accuracy=88.52% avg_sensitivity=80.90%, avg_specificity=91.11% avg_auc=94.51%
Best model saved!! Metric=29.035691329120226!!
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.189560 Test loss=0.268426 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.19832409918308258
[5/24] Train loss=0.17439858615398407
[10/24] Train loss=0.19963884353637695
[15/24] Train loss=0.1830550581216812
[20/24] Train loss=0.17655877768993378
Test set avg_accuracy=85.94% avg_sensitivity=52.18%, avg_specificity=97.45% avg_auc=89.85%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.189076 Test loss=0.372190 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.199588805437088
[5/24] Train loss=0.170777827501297
[10/24] Train loss=0.2099049985408783
[15/24] Train loss=0.1733807474374771
[20/24] Train loss=0.18025843799114227
Test set avg_accuracy=86.88% avg_sensitivity=57.25%, avg_specificity=96.98% avg_auc=90.42%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.190108 Test loss=0.344565 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.20179980993270874
[5/24] Train loss=0.17043855786323547
[10/24] Train loss=0.20205479860305786
[15/24] Train loss=0.17166730761528015
[20/24] Train loss=0.1707388013601303
Test set avg_accuracy=87.20% avg_sensitivity=83.56%, avg_specificity=88.44% avg_auc=93.97%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.186849 Test loss=0.297414 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.19018208980560303
[5/24] Train loss=0.17534033954143524
[10/24] Train loss=0.19225983321666718
[15/24] Train loss=0.17330607771873474
[20/24] Train loss=0.1825271099805832
Test set avg_accuracy=88.42% avg_sensitivity=77.88%, avg_specificity=92.02% avg_auc=93.93%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.186754 Test loss=0.279336 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.18785111606121063
[5/24] Train loss=0.1684277355670929
[10/24] Train loss=0.19141502678394318
[15/24] Train loss=0.1816691905260086
[20/24] Train loss=0.17930667102336884
Test set avg_accuracy=87.66% avg_sensitivity=78.70%, avg_specificity=90.71% avg_auc=92.79%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.186358 Test loss=0.299561 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.1979362964630127
[5/24] Train loss=0.1762763410806656
[10/24] Train loss=0.21908573806285858
[15/24] Train loss=0.16613101959228516
[20/24] Train loss=0.17201967537403107
Test set avg_accuracy=86.91% avg_sensitivity=84.18%, avg_specificity=87.85% avg_auc=93.94%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.189344 Test loss=0.302409 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.1932998150587082
[5/24] Train loss=0.15685100853443146
[10/24] Train loss=0.19742174446582794
[15/24] Train loss=0.17425179481506348
[20/24] Train loss=0.17570656538009644
Test set avg_accuracy=87.34% avg_sensitivity=59.86%, avg_specificity=96.72% avg_auc=92.00%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.184448 Test loss=0.320623 Current lr=[0.000276307469034998]

[0/24] Train loss=0.18903619050979614
[5/24] Train loss=0.16592350602149963
[10/24] Train loss=0.20112989842891693
[15/24] Train loss=0.17122456431388855
[20/24] Train loss=0.17576223611831665
Test set avg_accuracy=88.16% avg_sensitivity=70.61%, avg_specificity=94.15% avg_auc=93.48%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.186378 Test loss=0.280693 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.1894165426492691
[5/24] Train loss=0.16449111700057983
[10/24] Train loss=0.19030962884426117
[15/24] Train loss=0.16643711924552917
[20/24] Train loss=0.16888317465782166
Test set avg_accuracy=87.36% avg_sensitivity=62.62%, avg_specificity=95.79% avg_auc=91.32%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.179821 Test loss=0.313319 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.19514100253582
[5/24] Train loss=0.16340960562229156
[10/24] Train loss=0.19932153820991516
[15/24] Train loss=0.17930136620998383
[20/24] Train loss=0.17505773901939392
Test set avg_accuracy=88.10% avg_sensitivity=79.16%, avg_specificity=91.15% avg_auc=93.38%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.184111 Test loss=0.283734 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.1993124783039093
[5/24] Train loss=0.17120099067687988
[10/24] Train loss=0.1930830031633377
[15/24] Train loss=0.1805400401353836
[20/24] Train loss=0.18220457434654236
Test set avg_accuracy=87.58% avg_sensitivity=75.17%, avg_specificity=91.81% avg_auc=92.45%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.184638 Test loss=0.299308 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.18231262266635895
[5/24] Train loss=0.16393741965293884
[10/24] Train loss=0.19199088215827942
[15/24] Train loss=0.1707410216331482
[20/24] Train loss=0.17492824792861938
Test set avg_accuracy=87.45% avg_sensitivity=66.46%, avg_specificity=94.60% avg_auc=92.11%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.183855 Test loss=0.308452 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.19229918718338013
[5/24] Train loss=0.15963025391101837
[10/24] Train loss=0.18221820890903473
[15/24] Train loss=0.18020932376384735
[20/24] Train loss=0.16846133768558502
Test set avg_accuracy=84.87% avg_sensitivity=86.07%, avg_specificity=84.46% avg_auc=92.72%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.178438 Test loss=0.347377 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.18453150987625122
[5/24] Train loss=0.155138298869133
[10/24] Train loss=0.1902438998222351
[15/24] Train loss=0.16845323145389557
[20/24] Train loss=0.1703689843416214
Test set avg_accuracy=89.19% avg_sensitivity=73.17%, avg_specificity=94.66% avg_auc=93.52%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.179573 Test loss=0.271247 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.19495899975299835
[5/24] Train loss=0.16652515530586243
[10/24] Train loss=0.19015732407569885
[15/24] Train loss=0.16218523681163788
[20/24] Train loss=0.17900162935256958
Test set avg_accuracy=89.10% avg_sensitivity=72.56%, avg_specificity=94.74% avg_auc=93.44%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.181789 Test loss=0.272676 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.17921428382396698
[5/24] Train loss=0.15512476861476898
[10/24] Train loss=0.1737789809703827
[15/24] Train loss=0.16853174567222595
[20/24] Train loss=0.1658288985490799
Test set avg_accuracy=89.21% avg_sensitivity=71.43%, avg_specificity=95.27% avg_auc=93.55%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.173206 Test loss=0.273525 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1804925948381424
[5/24] Train loss=0.1556224673986435
[10/24] Train loss=0.1675807386636734
[15/24] Train loss=0.15733009576797485
[20/24] Train loss=0.16341239213943481
Test set avg_accuracy=87.17% avg_sensitivity=85.82%, avg_specificity=87.64% avg_auc=94.21%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.173977 Test loss=0.300097 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.18134112656116486
[5/24] Train loss=0.1620403379201889
[10/24] Train loss=0.16925697028636932
[15/24] Train loss=0.1579616367816925
[20/24] Train loss=0.1592538207769394
Test set avg_accuracy=86.35% avg_sensitivity=53.81%, avg_specificity=97.45% avg_auc=90.49%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.172677 Test loss=0.347875 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1815144568681717
[5/24] Train loss=0.15492340922355652
[10/24] Train loss=0.18091747164726257
[15/24] Train loss=0.15663571655750275
[20/24] Train loss=0.16576987504959106
Test set avg_accuracy=88.03% avg_sensitivity=70.20%, avg_specificity=94.12% avg_auc=92.57%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.171311 Test loss=0.295081 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.1948164701461792
[5/24] Train loss=0.14694100618362427
[10/24] Train loss=0.16990536451339722
[15/24] Train loss=0.1562286615371704
[20/24] Train loss=0.17145897448062897
Test set avg_accuracy=88.45% avg_sensitivity=72.20%, avg_specificity=93.99% avg_auc=93.55%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.168763 Test loss=0.276909 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.17796504497528076
[5/24] Train loss=0.15315963327884674
[10/24] Train loss=0.1745060235261917
[15/24] Train loss=0.1598234921693802
[20/24] Train loss=0.15982092916965485
Test set avg_accuracy=87.38% avg_sensitivity=60.37%, avg_specificity=96.60% avg_auc=88.66%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.169070 Test loss=0.350955 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.18730773031711578
[5/24] Train loss=0.1522725224494934
[10/24] Train loss=0.17102308571338654
[15/24] Train loss=0.15459421277046204
[20/24] Train loss=0.1573149710893631
Test set avg_accuracy=88.50% avg_sensitivity=71.07%, avg_specificity=94.45% avg_auc=93.28%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.168160 Test loss=0.279710 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17970937490463257
[5/24] Train loss=0.15400610864162445
[10/24] Train loss=0.1685868352651596
[15/24] Train loss=0.15563254058361053
[20/24] Train loss=0.1646452248096466
Test set avg_accuracy=88.54% avg_sensitivity=81.31%, avg_specificity=91.01% avg_auc=94.02%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.170417 Test loss=0.275558 Current lr=[0.000224838296036774]

[0/24] Train loss=0.17558613419532776
[5/24] Train loss=0.15592709183692932
[10/24] Train loss=0.17236509919166565
[15/24] Train loss=0.15624873340129852
[20/24] Train loss=0.16068845987319946
Test set avg_accuracy=86.78% avg_sensitivity=56.12%, avg_specificity=97.24% avg_auc=89.69%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.168570 Test loss=0.341300 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.17611923813819885
[5/24] Train loss=0.1566179394721985
[10/24] Train loss=0.17102587223052979
[15/24] Train loss=0.15450507402420044
[20/24] Train loss=0.1546100378036499
Test set avg_accuracy=87.21% avg_sensitivity=84.13%, avg_specificity=88.27% avg_auc=93.80%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.166179 Test loss=0.302112 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.17253094911575317
[5/24] Train loss=0.15500138700008392
[10/24] Train loss=0.17584852874279022
[15/24] Train loss=0.15903861820697784
[20/24] Train loss=0.15752843022346497
Test set avg_accuracy=87.60% avg_sensitivity=80.75%, avg_specificity=89.94% avg_auc=93.35%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.164661 Test loss=0.292433 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1723526418209076
[5/24] Train loss=0.1477450430393219
[10/24] Train loss=0.16709992289543152
[15/24] Train loss=0.1485213041305542
[20/24] Train loss=0.16314645111560822
Test set avg_accuracy=85.57% avg_sensitivity=84.69%, avg_specificity=85.87% avg_auc=92.37%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.163672 Test loss=0.339459 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.17607733607292175
[5/24] Train loss=0.1519506275653839
[10/24] Train loss=0.16848844289779663
[15/24] Train loss=0.15192671120166779
[20/24] Train loss=0.17248547077178955
Test set avg_accuracy=84.82% avg_sensitivity=82.28%, avg_specificity=85.68% avg_auc=91.46%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.166145 Test loss=0.350189 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.17796041071414948
[5/24] Train loss=0.16797423362731934
[10/24] Train loss=0.16622492671012878
[15/24] Train loss=0.15402981638908386
[20/24] Train loss=0.163484588265419
Test set avg_accuracy=87.75% avg_sensitivity=75.58%, avg_specificity=91.90% avg_auc=92.31%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.167304 Test loss=0.299341 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.17910411953926086
[5/24] Train loss=0.14998561143875122
[10/24] Train loss=0.15418706834316254
[15/24] Train loss=0.15390148758888245
[20/24] Train loss=0.15779803693294525
Test set avg_accuracy=87.90% avg_sensitivity=77.21%, avg_specificity=91.55% avg_auc=92.78%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.163892 Test loss=0.293690 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.17786084115505219
[5/24] Train loss=0.1448875516653061
[10/24] Train loss=0.16448861360549927
[15/24] Train loss=0.15865042805671692
[20/24] Train loss=0.15713492035865784
Test set avg_accuracy=82.07% avg_sensitivity=87.51%, avg_specificity=80.22% avg_auc=91.44%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.166132 Test loss=0.406126 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.17403364181518555
[5/24] Train loss=0.14978967607021332
[10/24] Train loss=0.17390763759613037
[15/24] Train loss=0.15768951177597046
[20/24] Train loss=0.1648344099521637
Test set avg_accuracy=79.34% avg_sensitivity=91.09%, avg_specificity=75.33% avg_auc=91.72%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.168511 Test loss=0.458423 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.16729159653186798
[5/24] Train loss=0.15263602137565613
[10/24] Train loss=0.16924597322940826
[15/24] Train loss=0.150081068277359
[20/24] Train loss=0.16094627976417542
Test set avg_accuracy=87.06% avg_sensitivity=67.74%, avg_specificity=93.64% avg_auc=90.11%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.166074 Test loss=0.322274 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1767227053642273
[5/24] Train loss=0.1463444083929062
[10/24] Train loss=0.1687077134847641
[15/24] Train loss=0.15454211831092834
[20/24] Train loss=0.15656767785549164
Test set avg_accuracy=87.32% avg_sensitivity=65.39%, avg_specificity=94.80% avg_auc=90.50%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.163806 Test loss=0.317606 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.17670562863349915
[5/24] Train loss=0.15037915110588074
[10/24] Train loss=0.1633184254169464
[15/24] Train loss=0.1525501310825348
[20/24] Train loss=0.15545572340488434
Test set avg_accuracy=85.96% avg_sensitivity=78.65%, avg_specificity=88.46% avg_auc=91.49%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.163183 Test loss=0.328889 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.17343531548976898
[5/24] Train loss=0.16253116726875305
[10/24] Train loss=0.1870192587375641
[15/24] Train loss=0.149334117770195
[20/24] Train loss=0.14838990569114685
Test set avg_accuracy=87.99% avg_sensitivity=73.99%, avg_specificity=92.77% avg_auc=92.33%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.161296 Test loss=0.294871 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.1736854910850525
[5/24] Train loss=0.15170437097549438
[10/24] Train loss=0.15450996160507202
[15/24] Train loss=0.1564328372478485
[20/24] Train loss=0.14612068235874176
Test set avg_accuracy=87.03% avg_sensitivity=80.65%, avg_specificity=89.21% avg_auc=92.70%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.161259 Test loss=0.316692 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.17650914192199707
[5/24] Train loss=0.1425313651561737
[10/24] Train loss=0.16962414979934692
[15/24] Train loss=0.14980828762054443
[20/24] Train loss=0.1518312245607376
Test set avg_accuracy=86.94% avg_sensitivity=82.74%, avg_specificity=88.37% avg_auc=93.32%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.159138 Test loss=0.306452 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.16791991889476776
[5/24] Train loss=0.15069147944450378
[10/24] Train loss=0.15618087351322174
[15/24] Train loss=0.15121915936470032
[20/24] Train loss=0.1486280858516693
Test set avg_accuracy=88.11% avg_sensitivity=69.12%, avg_specificity=94.59% avg_auc=91.00%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.157808 Test loss=0.306765 Current lr=[0.000156543481933168]

[0/24] Train loss=0.1700294315814972
[5/24] Train loss=0.1413860023021698
[10/24] Train loss=0.1544129103422165
[15/24] Train loss=0.1439872831106186
[20/24] Train loss=0.15135657787322998
Test set avg_accuracy=88.45% avg_sensitivity=70.25%, avg_specificity=94.66% avg_auc=92.58%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.157734 Test loss=0.292298 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.16314317286014557
[5/24] Train loss=0.1465947926044464
[10/24] Train loss=0.16213947534561157
[15/24] Train loss=0.1480734646320343
[20/24] Train loss=0.1516757309436798
Test set avg_accuracy=87.50% avg_sensitivity=65.03%, avg_specificity=95.16% avg_auc=90.79%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.157973 Test loss=0.326790 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.1628148853778839
[5/24] Train loss=0.1434299498796463
[10/24] Train loss=0.1468544602394104
[15/24] Train loss=0.14600986242294312
[20/24] Train loss=0.1427527815103531
Test set avg_accuracy=88.80% avg_sensitivity=67.13%, avg_specificity=96.19% avg_auc=92.58%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.153097 Test loss=0.291784 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.16519129276275635
[5/24] Train loss=0.14063388109207153
[10/24] Train loss=0.15341199934482574
[15/24] Train loss=0.13684320449829102
[20/24] Train loss=0.1430983692407608
Test set avg_accuracy=89.35% avg_sensitivity=74.04%, avg_specificity=94.57% avg_auc=93.31%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.152323 Test loss=0.274883 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15659521520137787
[5/24] Train loss=0.14339998364448547
[10/24] Train loss=0.14917975664138794
[15/24] Train loss=0.13839662075042725
[20/24] Train loss=0.13943317532539368
Test set avg_accuracy=88.44% avg_sensitivity=70.30%, avg_specificity=94.62% avg_auc=91.66%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.149703 Test loss=0.301653 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1630266159772873
[5/24] Train loss=0.14244380593299866
[10/24] Train loss=0.1490047127008438
[15/24] Train loss=0.1447639912366867
[20/24] Train loss=0.1491563618183136
Test set avg_accuracy=88.44% avg_sensitivity=67.59%, avg_specificity=95.55% avg_auc=91.61%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.151421 Test loss=0.303879 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1594986617565155
[5/24] Train loss=0.13511934876441956
[10/24] Train loss=0.14567604660987854
[15/24] Train loss=0.13864080607891083
[20/24] Train loss=0.14878547191619873
Test set avg_accuracy=88.67% avg_sensitivity=72.40%, avg_specificity=94.22% avg_auc=91.23%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.149837 Test loss=0.299808 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.16075623035430908
[5/24] Train loss=0.14331354200839996
[10/24] Train loss=0.15141619741916656
[15/24] Train loss=0.13994550704956055
[20/24] Train loss=0.14385145902633667
Test set avg_accuracy=87.81% avg_sensitivity=63.95%, avg_specificity=95.95% avg_auc=90.35%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.150295 Test loss=0.316388 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.16708385944366455
[5/24] Train loss=0.13666433095932007
[10/24] Train loss=0.14993277192115784
[15/24] Train loss=0.1398499459028244
[20/24] Train loss=0.1411876529455185
Test set avg_accuracy=87.89% avg_sensitivity=63.29%, avg_specificity=96.28% avg_auc=90.12%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.150265 Test loss=0.326052 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1659521460533142
[5/24] Train loss=0.13478301465511322
[10/24] Train loss=0.14578327536582947
[15/24] Train loss=0.14566177129745483
[20/24] Train loss=0.14807192981243134
Test set avg_accuracy=87.29% avg_sensitivity=61.80%, avg_specificity=95.98% avg_auc=89.45%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.150803 Test loss=0.336536 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16568589210510254
[5/24] Train loss=0.15161675214767456
[10/24] Train loss=0.1536395102739334
[15/24] Train loss=0.14165812730789185
[20/24] Train loss=0.14111176133155823
Test set avg_accuracy=88.45% avg_sensitivity=72.04%, avg_specificity=94.05% avg_auc=92.77%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.150740 Test loss=0.287646 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.16273465752601624
[5/24] Train loss=0.14082737267017365
[10/24] Train loss=0.14101894199848175
[15/24] Train loss=0.14244522154331207
[20/24] Train loss=0.14586932957172394
Test set avg_accuracy=88.67% avg_sensitivity=70.97%, avg_specificity=94.71% avg_auc=92.05%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.148594 Test loss=0.291372 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1587246060371399
[5/24] Train loss=0.13940833508968353
[10/24] Train loss=0.13888505101203918
[15/24] Train loss=0.13810314238071442
[20/24] Train loss=0.14354297518730164
Test set avg_accuracy=88.70% avg_sensitivity=75.93%, avg_specificity=93.05% avg_auc=93.83%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.147287 Test loss=0.273923 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1534471958875656
[5/24] Train loss=0.13798761367797852
[10/24] Train loss=0.13662846386432648
[15/24] Train loss=0.1433914303779602
[20/24] Train loss=0.13762302696704865
Test set avg_accuracy=88.75% avg_sensitivity=74.71%, avg_specificity=93.54% avg_auc=92.98%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.145536 Test loss=0.283401 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.151579812169075
[5/24] Train loss=0.13686807453632355
[10/24] Train loss=0.13620111346244812
[15/24] Train loss=0.13716727495193481
[20/24] Train loss=0.13480748236179352
Test set avg_accuracy=88.53% avg_sensitivity=80.18%, avg_specificity=91.37% avg_auc=93.99%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.143386 Test loss=0.277614 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1524180769920349
[5/24] Train loss=0.13292938470840454
[10/24] Train loss=0.1386159360408783
[15/24] Train loss=0.13250267505645752
[20/24] Train loss=0.13408929109573364
Test set avg_accuracy=88.65% avg_sensitivity=78.34%, avg_specificity=92.16% avg_auc=93.89%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.140905 Test loss=0.277807 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14979442954063416
[5/24] Train loss=0.13231007754802704
[10/24] Train loss=0.13402089476585388
[15/24] Train loss=0.128448948264122
[20/24] Train loss=0.13263867795467377
Test set avg_accuracy=89.09% avg_sensitivity=76.50%, avg_specificity=93.38% avg_auc=93.23%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.140701 Test loss=0.282746 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1569124460220337
[5/24] Train loss=0.13015814125537872
[10/24] Train loss=0.1460561901330948
[15/24] Train loss=0.1344873458147049
[20/24] Train loss=0.13812895119190216
Test set avg_accuracy=87.40% avg_sensitivity=83.21%, avg_specificity=88.82% avg_auc=93.62%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.141488 Test loss=0.304889 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.15055470168590546
[5/24] Train loss=0.13521409034729004
[10/24] Train loss=0.14089810848236084
[15/24] Train loss=0.14051002264022827
[20/24] Train loss=0.13588710129261017
Test set avg_accuracy=88.59% avg_sensitivity=72.91%, avg_specificity=93.94% avg_auc=93.11%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.142335 Test loss=0.288242 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15159855782985687
[5/24] Train loss=0.12964724004268646
[10/24] Train loss=0.1351739764213562
[15/24] Train loss=0.13554489612579346
[20/24] Train loss=0.13921687006950378
Test set avg_accuracy=88.61% avg_sensitivity=81.31%, avg_specificity=91.09% avg_auc=94.08%
Best model saved!! Metric=29.090922449035006!!
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.142367 Test loss=0.281072 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.15231432020664215
[5/24] Train loss=0.1351848691701889
[10/24] Train loss=0.13290360569953918
[15/24] Train loss=0.1284472495317459
[20/24] Train loss=0.13224412500858307
Test set avg_accuracy=88.23% avg_sensitivity=78.03%, avg_specificity=91.71% avg_auc=93.65%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.138973 Test loss=0.281371 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14945288002490997
[5/24] Train loss=0.12977926433086395
[10/24] Train loss=0.13375550508499146
[15/24] Train loss=0.1295018196105957
[20/24] Train loss=0.12984991073608398
Test set avg_accuracy=88.65% avg_sensitivity=72.40%, avg_specificity=94.19% avg_auc=92.51%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.136136 Test loss=0.293872 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.15025503933429718
[5/24] Train loss=0.12321537733078003
[10/24] Train loss=0.137691468000412
[15/24] Train loss=0.12493505328893661
[20/24] Train loss=0.1300569772720337
Test set avg_accuracy=88.93% avg_sensitivity=74.60%, avg_specificity=93.82% avg_auc=92.62%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.134756 Test loss=0.291710 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14782078564167023
[5/24] Train loss=0.12590262293815613
[10/24] Train loss=0.13043104112148285
[15/24] Train loss=0.1252979189157486
[20/24] Train loss=0.1287573277950287
Test set avg_accuracy=88.70% avg_sensitivity=71.33%, avg_specificity=94.62% avg_auc=92.17%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.133065 Test loss=0.295005 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14694879949092865
[5/24] Train loss=0.12432719767093658
[10/24] Train loss=0.1256178319454193
[15/24] Train loss=0.12342281639575958
[20/24] Train loss=0.12669458985328674
Test set avg_accuracy=88.85% avg_sensitivity=70.40%, avg_specificity=95.15% avg_auc=92.22%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.132888 Test loss=0.294454 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.14451710879802704
[5/24] Train loss=0.12405639886856079
[10/24] Train loss=0.12692466378211975
[15/24] Train loss=0.12530070543289185
[20/24] Train loss=0.13206326961517334
Test set avg_accuracy=88.75% avg_sensitivity=73.89%, avg_specificity=93.82% avg_auc=92.71%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.132843 Test loss=0.288110 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1469683051109314
[5/24] Train loss=0.12194168567657471
[10/24] Train loss=0.1263873428106308
[15/24] Train loss=0.1237877756357193
[20/24] Train loss=0.12550964951515198
Test set avg_accuracy=88.89% avg_sensitivity=71.17%, avg_specificity=94.94% avg_auc=92.31%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.132231 Test loss=0.290586 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1431272327899933
[5/24] Train loss=0.12147627770900726
[10/24] Train loss=0.12353339791297913
[15/24] Train loss=0.1208011656999588
[20/24] Train loss=0.1261681765317917
Test set avg_accuracy=88.70% avg_sensitivity=74.60%, avg_specificity=93.50% avg_auc=93.06%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.130940 Test loss=0.287955 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.14490588009357452
[5/24] Train loss=0.1266918033361435
[10/24] Train loss=0.12352652847766876
[15/24] Train loss=0.12512578070163727
[20/24] Train loss=0.1250072419643402
Test set avg_accuracy=88.67% avg_sensitivity=74.24%, avg_specificity=93.59% avg_auc=93.02%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.131078 Test loss=0.282930 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1421823501586914
[5/24] Train loss=0.126634880900383
[10/24] Train loss=0.1264675259590149
[15/24] Train loss=0.12195860594511032
[20/24] Train loss=0.12431235611438751
Test set avg_accuracy=89.06% avg_sensitivity=72.66%, avg_specificity=94.66% avg_auc=92.73%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.130110 Test loss=0.285069 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.14294078946113586
[5/24] Train loss=0.12236449867486954
[10/24] Train loss=0.12744198739528656
[15/24] Train loss=0.12507985532283783
[20/24] Train loss=0.1254497468471527
Test set avg_accuracy=88.80% avg_sensitivity=70.15%, avg_specificity=95.16% avg_auc=92.20%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.129323 Test loss=0.292753 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.14187467098236084
[5/24] Train loss=0.1230725571513176
[10/24] Train loss=0.12361326068639755
[15/24] Train loss=0.12271799892187119
[20/24] Train loss=0.1257675290107727
Test set avg_accuracy=88.93% avg_sensitivity=71.38%, avg_specificity=94.92% avg_auc=92.62%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.128982 Test loss=0.286520 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1397072821855545
[5/24] Train loss=0.12454614043235779
[10/24] Train loss=0.12329841405153275
[15/24] Train loss=0.12153512984514236
[20/24] Train loss=0.12400920689105988
Test set avg_accuracy=88.52% avg_sensitivity=73.63%, avg_specificity=93.59% avg_auc=92.73%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.128388 Test loss=0.289433 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.14094965159893036
[5/24] Train loss=0.12696585059165955
[10/24] Train loss=0.12142447382211685
[15/24] Train loss=0.11895647644996643
[20/24] Train loss=0.1259751319885254
Test set avg_accuracy=88.58% avg_sensitivity=75.83%, avg_specificity=92.93% avg_auc=92.91%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.128338 Test loss=0.285804 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.14280150830745697
[5/24] Train loss=0.12157012522220612
[10/24] Train loss=0.12438070774078369
[15/24] Train loss=0.11979538947343826
[20/24] Train loss=0.12350683659315109
Test set avg_accuracy=87.84% avg_sensitivity=79.98%, avg_specificity=90.52% avg_auc=93.05%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.127773 Test loss=0.296455 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13872617483139038
[5/24] Train loss=0.12425698339939117
[10/24] Train loss=0.1198001578450203
[15/24] Train loss=0.12334245443344116
[20/24] Train loss=0.12112622708082199
Test set avg_accuracy=88.50% avg_sensitivity=77.06%, avg_specificity=92.40% avg_auc=93.15%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.128462 Test loss=0.286491 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1379292756319046
[5/24] Train loss=0.12179733067750931
[10/24] Train loss=0.12323640286922455
[15/24] Train loss=0.11619522422552109
[20/24] Train loss=0.12274610996246338
Test set avg_accuracy=88.65% avg_sensitivity=76.60%, avg_specificity=92.75% avg_auc=93.13%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.127055 Test loss=0.285805 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1403016895055771
[5/24] Train loss=0.12146120518445969
[10/24] Train loss=0.12443878501653671
[15/24] Train loss=0.11743861436843872
[20/24] Train loss=0.12284551560878754
Test set avg_accuracy=88.61% avg_sensitivity=73.73%, avg_specificity=93.68% avg_auc=92.45%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.126550 Test loss=0.289931 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.14141759276390076
[5/24] Train loss=0.11907164752483368
[10/24] Train loss=0.12047628313302994
[15/24] Train loss=0.1146324872970581
[20/24] Train loss=0.11966218799352646
Test set avg_accuracy=88.45% avg_sensitivity=77.93%, avg_specificity=92.04% avg_auc=93.20%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.124936 Test loss=0.288612 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13746605813503265
[5/24] Train loss=0.12032686173915863
[10/24] Train loss=0.11954761296510696
[15/24] Train loss=0.11667277663946152
[20/24] Train loss=0.12064853310585022
Test set avg_accuracy=88.65% avg_sensitivity=75.58%, avg_specificity=93.10% avg_auc=92.74%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.125247 Test loss=0.289188 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1395266354084015
[5/24] Train loss=0.11685152351856232
[10/24] Train loss=0.12092003226280212
[15/24] Train loss=0.11684930324554443
[20/24] Train loss=0.12008196860551834
Test set avg_accuracy=88.75% avg_sensitivity=77.47%, avg_specificity=92.60% avg_auc=92.97%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.124287 Test loss=0.286539 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13717496395111084
[5/24] Train loss=0.11918915808200836
[10/24] Train loss=0.12182818353176117
[15/24] Train loss=0.1179787889122963
[20/24] Train loss=0.12015557289123535
Test set avg_accuracy=88.70% avg_sensitivity=76.75%, avg_specificity=92.77% avg_auc=92.94%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.124069 Test loss=0.286054 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.13594679534435272
[5/24] Train loss=0.11761883646249771
[10/24] Train loss=0.11790507286787033
[15/24] Train loss=0.11758460104465485
[20/24] Train loss=0.11807310581207275
Test set avg_accuracy=88.72% avg_sensitivity=75.68%, avg_specificity=93.17% avg_auc=92.57%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.123600 Test loss=0.288991 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1366947591304779
[5/24] Train loss=0.11796190589666367
[10/24] Train loss=0.12001891434192657
[15/24] Train loss=0.11702313274145126
[20/24] Train loss=0.11924180388450623
Test set avg_accuracy=88.54% avg_sensitivity=77.11%, avg_specificity=92.44% avg_auc=92.98%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.123011 Test loss=0.287088 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13448560237884521
[5/24] Train loss=0.11696790903806686
[10/24] Train loss=0.11906018853187561
[15/24] Train loss=0.11461751163005829
[20/24] Train loss=0.11970199644565582
Test set avg_accuracy=88.67% avg_sensitivity=76.86%, avg_specificity=92.70% avg_auc=92.84%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.123009 Test loss=0.287467 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1348084807395935
[5/24] Train loss=0.11599061638116837
[10/24] Train loss=0.11907791346311569
[15/24] Train loss=0.11555216461420059
[20/24] Train loss=0.11927689611911774
Test set avg_accuracy=88.70% avg_sensitivity=76.45%, avg_specificity=92.88% avg_auc=92.87%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.122469 Test loss=0.286916 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13472723960876465
[5/24] Train loss=0.11770781129598618
[10/24] Train loss=0.11683756858110428
[15/24] Train loss=0.11474287509918213
[20/24] Train loss=0.1186385527253151
Test set avg_accuracy=88.88% avg_sensitivity=76.24%, avg_specificity=93.19% avg_auc=92.86%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.122167 Test loss=0.287210 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13532884418964386
[5/24] Train loss=0.11753369867801666
[10/24] Train loss=0.11789392679929733
[15/24] Train loss=0.11461133509874344
[20/24] Train loss=0.11930505931377411
Test set avg_accuracy=88.58% avg_sensitivity=76.34%, avg_specificity=92.75% avg_auc=92.96%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.122564 Test loss=0.287095 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13462121784687042
[5/24] Train loss=0.11657373607158661
[10/24] Train loss=0.12031245231628418
[15/24] Train loss=0.11821034550666809
[20/24] Train loss=0.11968833208084106
Test set avg_accuracy=88.72% avg_sensitivity=76.60%, avg_specificity=92.86% avg_auc=92.98%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.122400 Test loss=0.286204 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13542434573173523
[5/24] Train loss=0.11529212445020676
[10/24] Train loss=0.11732560396194458
[15/24] Train loss=0.11471357196569443
[20/24] Train loss=0.1183665469288826
Test set avg_accuracy=88.79% avg_sensitivity=76.24%, avg_specificity=93.07% avg_auc=92.90%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.122473 Test loss=0.286734 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.13479192554950714
[5/24] Train loss=0.1164645254611969
[10/24] Train loss=0.12031649798154831
[15/24] Train loss=0.11381254345178604
[20/24] Train loss=0.11804478615522385
Test set avg_accuracy=88.78% avg_sensitivity=76.34%, avg_specificity=93.02% avg_auc=92.91%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.121842 Test loss=0.286784 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1353050172328949
[5/24] Train loss=0.11678100377321243
[10/24] Train loss=0.11870477348566055
[15/24] Train loss=0.11510094255208969
[20/24] Train loss=0.11836471408605576
Test set avg_accuracy=88.75% avg_sensitivity=76.34%, avg_specificity=92.98% avg_auc=92.90%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.122321 Test loss=0.286973 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13407768309116364
[5/24] Train loss=0.1174735575914383
[10/24] Train loss=0.11856246739625931
[15/24] Train loss=0.1151505708694458
[20/24] Train loss=0.11884552985429764
Test set avg_accuracy=88.76% avg_sensitivity=76.34%, avg_specificity=93.00% avg_auc=92.89%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.121992 Test loss=0.286847 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.13305190205574036
[5/24] Train loss=0.11674284934997559
[10/24] Train loss=0.11687617748975754
[15/24] Train loss=0.11522246152162552
[20/24] Train loss=0.11874938011169434
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=88.75% avg_sensitivity=76.34%, avg_specificity=92.98% avg_auc=92.90%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.121816 Test loss=0.286897 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=88.61% sen=81.31%, spe=91.09%, auc=94.08%!
Fold[5] Avg_overlap=0.70%(0.20296933331729222)
[0/24] Train loss=0.7357919216156006
[5/24] Train loss=0.7354730367660522
[10/24] Train loss=0.725843608379364
[15/24] Train loss=0.7166051864624023
[20/24] Train loss=0.7035753130912781
Test set avg_accuracy=60.68% avg_sensitivity=45.06%, avg_specificity=66.49% avg_auc=57.49%
Best model saved!! Metric=-96.2831609253159!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.722572 Test loss=0.677446 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6945953965187073
[5/24] Train loss=0.7007565498352051
[10/24] Train loss=0.6958613991737366
[15/24] Train loss=0.6809737682342529
[20/24] Train loss=0.6710054278373718
Test set avg_accuracy=67.72% avg_sensitivity=58.40%, avg_specificity=71.19% avg_auc=71.00%
Best model saved!! Metric=-57.6907910590841!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.691033 Test loss=0.612009 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6732193231582642
[5/24] Train loss=0.6696284413337708
[10/24] Train loss=0.6683351397514343
[15/24] Train loss=0.6550198197364807
[20/24] Train loss=0.6458535194396973
Test set avg_accuracy=71.56% avg_sensitivity=65.74%, avg_specificity=73.73% avg_auc=76.89%
Best model saved!! Metric=-38.08199037494565!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.662312 Test loss=0.572995 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6375665068626404
[5/24] Train loss=0.6350685358047485
[10/24] Train loss=0.6404573917388916
[15/24] Train loss=0.6211388111114502
[20/24] Train loss=0.6158375144004822
Test set avg_accuracy=74.71% avg_sensitivity=71.64%, avg_specificity=75.86% avg_auc=80.71%
Best model saved!! Metric=-23.07775102388966!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.635118 Test loss=0.542706 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6115955710411072
[5/24] Train loss=0.5980238914489746
[10/24] Train loss=0.6075720191001892
[15/24] Train loss=0.5865767598152161
[20/24] Train loss=0.5830864310264587
Test set avg_accuracy=76.90% avg_sensitivity=72.70%, avg_specificity=78.47% avg_auc=83.20%
Best model saved!! Metric=-14.732370223372683!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.603804 Test loss=0.512334 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5736615061759949
[5/24] Train loss=0.575273871421814
[10/24] Train loss=0.5857352018356323
[15/24] Train loss=0.5573086142539978
[20/24] Train loss=0.5491616129875183
Test set avg_accuracy=78.57% avg_sensitivity=75.91%, avg_specificity=79.56% avg_auc=85.42%
Best model saved!! Metric=-6.544529431782692!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.575503 Test loss=0.489044 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.548500657081604
[5/24] Train loss=0.5443713068962097
[10/24] Train loss=0.5545060038566589
[15/24] Train loss=0.5268979668617249
[20/24] Train loss=0.5209136605262756
Test set avg_accuracy=80.18% avg_sensitivity=75.72%, avg_specificity=81.84% avg_auc=87.30%
Best model saved!! Metric=-0.9532915371298571!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.546460 Test loss=0.458067 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5117459893226624
[5/24] Train loss=0.5146165490150452
[10/24] Train loss=0.5262088775634766
[15/24] Train loss=0.49873316287994385
[20/24] Train loss=0.4823402762413025
Test set avg_accuracy=82.02% avg_sensitivity=76.06%, avg_specificity=84.24% avg_auc=88.87%
Best model saved!! Metric=5.182330821399489!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.515456 Test loss=0.431829 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.49114108085632324
[5/24] Train loss=0.48317885398864746
[10/24] Train loss=0.4914294481277466
[15/24] Train loss=0.47468727827072144
[20/24] Train loss=0.454499214887619
Test set avg_accuracy=83.40% avg_sensitivity=76.82%, avg_specificity=85.85% avg_auc=89.74%
Best model saved!! Metric=9.813773241597715!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.484803 Test loss=0.412004 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4576985538005829
[5/24] Train loss=0.4557490944862366
[10/24] Train loss=0.462894082069397
[15/24] Train loss=0.4438519775867462
[20/24] Train loss=0.4262739419937134
Test set avg_accuracy=84.62% avg_sensitivity=77.02%, avg_specificity=87.46% avg_auc=90.84%
Best model saved!! Metric=13.928480588141753!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.456993 Test loss=0.387814 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4343473017215729
[5/24] Train loss=0.42917782068252563
[10/24] Train loss=0.4356347322463989
[15/24] Train loss=0.4197218120098114
[20/24] Train loss=0.403102844953537
Test set avg_accuracy=86.03% avg_sensitivity=74.57%, avg_specificity=90.30% avg_auc=91.64%
Best model saved!! Metric=16.535692956381197!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.432507 Test loss=0.362071 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4106753468513489
[5/24] Train loss=0.41104230284690857
[10/24] Train loss=0.4115679860115051
[15/24] Train loss=0.3997674584388733
[20/24] Train loss=0.37840017676353455
Test set avg_accuracy=86.56% avg_sensitivity=74.90%, avg_specificity=90.90% avg_auc=92.26%
Best model saved!! Metric=18.63278670053603!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.408914 Test loss=0.345390 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3883002698421478
[5/24] Train loss=0.38689419627189636
[10/24] Train loss=0.3949029743671417
[15/24] Train loss=0.3788326382637024
[20/24] Train loss=0.3564075529575348
Test set avg_accuracy=87.25% avg_sensitivity=76.06%, avg_specificity=91.42% avg_auc=92.72%
Best model saved!! Metric=21.454005908245165!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.387404 Test loss=0.330867 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.36906003952026367
[5/24] Train loss=0.37162071466445923
[10/24] Train loss=0.3742176294326782
[15/24] Train loss=0.35609498620033264
[20/24] Train loss=0.33933794498443604
Test set avg_accuracy=88.01% avg_sensitivity=74.62%, avg_specificity=92.99% avg_auc=93.04%
Best model saved!! Metric=22.660918159512775!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.370484 Test loss=0.315991 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.35607823729515076
[5/24] Train loss=0.3535664677619934
[10/24] Train loss=0.3571002185344696
[15/24] Train loss=0.34173861145973206
[20/24] Train loss=0.32196688652038574
Test set avg_accuracy=88.57% avg_sensitivity=78.36%, avg_specificity=92.37% avg_auc=93.45%
Best model saved!! Metric=26.747951213152902!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.353126 Test loss=0.310011 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.33770594000816345
[5/24] Train loss=0.3421693742275238
[10/24] Train loss=0.3435075879096985
[15/24] Train loss=0.33159294724464417
[20/24] Train loss=0.3139027953147888
Test set avg_accuracy=88.80% avg_sensitivity=78.55%, avg_specificity=92.62% avg_auc=93.67%
Best model saved!! Metric=27.64210650590381!!
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.341666 Test loss=0.301662 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3243054747581482
[5/24] Train loss=0.3267098665237427
[10/24] Train loss=0.32981017231941223
[15/24] Train loss=0.318149209022522
[20/24] Train loss=0.2920196056365967
Test set avg_accuracy=89.09% avg_sensitivity=78.69%, avg_specificity=92.96% avg_auc=93.71%
Best model saved!! Metric=28.45147399151071!!
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.328841 Test loss=0.293201 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3105953335762024
[5/24] Train loss=0.3201241195201874
[10/24] Train loss=0.32023027539253235
[15/24] Train loss=0.3118281066417694
[20/24] Train loss=0.2885187566280365
Test set avg_accuracy=88.95% avg_sensitivity=78.84%, avg_specificity=92.71% avg_auc=93.86%
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.317750 Test loss=0.288126 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.2988172173500061
[5/24] Train loss=0.3091793954372406
[10/24] Train loss=0.31603357195854187
[15/24] Train loss=0.30036357045173645
[20/24] Train loss=0.27673718333244324
Test set avg_accuracy=89.10% avg_sensitivity=78.12%, avg_specificity=93.19% avg_auc=93.88%
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.308012 Test loss=0.283884 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.29454532265663147
[5/24] Train loss=0.29867494106292725
[10/24] Train loss=0.3065548539161682
[15/24] Train loss=0.2979015111923218
[20/24] Train loss=0.26649805903434753
Test set avg_accuracy=89.18% avg_sensitivity=78.60%, avg_specificity=93.12% avg_auc=94.04%
Best model saved!! Metric=28.94029385578746!!
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.300816 Test loss=0.281325 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2847680449485779
[5/24] Train loss=0.2970331609249115
[10/24] Train loss=0.3011118173599243
[15/24] Train loss=0.28560277819633484
[20/24] Train loss=0.26128485798835754
Test set avg_accuracy=89.71% avg_sensitivity=78.17%, avg_specificity=94.01% avg_auc=94.18%
Best model saved!! Metric=30.071139258310836!!
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.292534 Test loss=0.276030 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.274054616689682
[5/24] Train loss=0.2866048216819763
[10/24] Train loss=0.29330992698669434
[15/24] Train loss=0.28107771277427673
[20/24] Train loss=0.2526454031467438
Test set avg_accuracy=89.70% avg_sensitivity=79.46%, avg_specificity=93.51% avg_auc=94.18%
Best model saved!! Metric=30.855211460995818!!
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.285059 Test loss=0.272822 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2751518189907074
[5/24] Train loss=0.28106528520584106
[10/24] Train loss=0.28424155712127686
[15/24] Train loss=0.2737681567668915
[20/24] Train loss=0.24154303967952728
Test set avg_accuracy=89.69% avg_sensitivity=76.34%, avg_specificity=94.66% avg_auc=94.05%
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.278394 Test loss=0.271021 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.26852279901504517
[5/24] Train loss=0.27504321932792664
[10/24] Train loss=0.28533250093460083
[15/24] Train loss=0.2665216326713562
[20/24] Train loss=0.24086789786815643
Test set avg_accuracy=89.78% avg_sensitivity=73.90%, avg_specificity=95.69% avg_auc=93.88%
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.273893 Test loss=0.270210 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.25585418939590454
[5/24] Train loss=0.26572561264038086
[10/24] Train loss=0.277538925409317
[15/24] Train loss=0.2638782858848572
[20/24] Train loss=0.23506028950214386
Test set avg_accuracy=89.74% avg_sensitivity=73.32%, avg_specificity=95.85% avg_auc=94.00%
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.267287 Test loss=0.269721 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2636679708957672
[5/24] Train loss=0.26424190402030945
[10/24] Train loss=0.27406617999076843
[15/24] Train loss=0.2612702250480652
[20/24] Train loss=0.22905205190181732
Test set avg_accuracy=89.34% avg_sensitivity=70.68%, avg_specificity=96.28% avg_auc=93.56%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.261980 Test loss=0.278251 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2511773705482483
[5/24] Train loss=0.2559579610824585
[10/24] Train loss=0.2621249854564667
[15/24] Train loss=0.24944598972797394
[20/24] Train loss=0.21925048530101776
Test set avg_accuracy=88.27% avg_sensitivity=64.49%, avg_specificity=97.12% avg_auc=93.48%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.256758 Test loss=0.294297 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.24886152148246765
[5/24] Train loss=0.25287824869155884
[10/24] Train loss=0.27193981409072876
[15/24] Train loss=0.24940615892410278
[20/24] Train loss=0.2128068208694458
Test set avg_accuracy=89.15% avg_sensitivity=70.73%, avg_specificity=96.02% avg_auc=93.72%
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.255500 Test loss=0.273724 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2415691465139389
[5/24] Train loss=0.25058668851852417
[10/24] Train loss=0.25984787940979004
[15/24] Train loss=0.2426380217075348
[20/24] Train loss=0.21552996337413788
Test set avg_accuracy=88.78% avg_sensitivity=66.65%, avg_specificity=97.02% avg_auc=93.13%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.247343 Test loss=0.289776 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.24015383422374725
[5/24] Train loss=0.24200816452503204
[10/24] Train loss=0.2608162760734558
[15/24] Train loss=0.2514500617980957
[20/24] Train loss=0.21049384772777557
Test set avg_accuracy=88.58% avg_sensitivity=67.37%, avg_specificity=96.48% avg_auc=93.50%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.243654 Test loss=0.283284 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.22808988392353058
[5/24] Train loss=0.23361966013908386
[10/24] Train loss=0.25304436683654785
[15/24] Train loss=0.24856171011924744
[20/24] Train loss=0.21567107737064362
Test set avg_accuracy=88.85% avg_sensitivity=68.19%, avg_specificity=96.55% avg_auc=93.22%
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.237175 Test loss=0.283533 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.22790300846099854
[5/24] Train loss=0.23697851598262787
[10/24] Train loss=0.24785766005516052
[15/24] Train loss=0.2407904714345932
[20/24] Train loss=0.20363283157348633
Test set avg_accuracy=87.41% avg_sensitivity=71.07%, avg_specificity=93.50% avg_auc=91.78%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.233870 Test loss=0.306484 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.22988663613796234
[5/24] Train loss=0.21313126385211945
[10/24] Train loss=0.24551473557949066
[15/24] Train loss=0.24006937444210052
[20/24] Train loss=0.2121506929397583
Test set avg_accuracy=87.47% avg_sensitivity=59.93%, avg_specificity=97.73% avg_auc=92.34%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.231206 Test loss=0.314559 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.22911693155765533
[5/24] Train loss=0.2246677577495575
[10/24] Train loss=0.2454996407032013
[15/24] Train loss=0.23569944500923157
[20/24] Train loss=0.21429726481437683
Test set avg_accuracy=79.86% avg_sensitivity=27.54%, avg_specificity=99.34% avg_auc=87.58%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.231773 Test loss=0.485614 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2342405468225479
[5/24] Train loss=0.21103450655937195
[10/24] Train loss=0.25190991163253784
[15/24] Train loss=0.23362672328948975
[20/24] Train loss=0.19961579144001007
Test set avg_accuracy=80.65% avg_sensitivity=30.95%, avg_specificity=99.16% avg_auc=87.16%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.227588 Test loss=0.486949 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.22692623734474182
[5/24] Train loss=0.22801707684993744
[10/24] Train loss=0.23753955960273743
[15/24] Train loss=0.23064716160297394
[20/24] Train loss=0.19756782054901123
Test set avg_accuracy=75.85% avg_sensitivity=11.71%, avg_specificity=99.73% avg_auc=82.58%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.224476 Test loss=0.642441 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.21982209384441376
[5/24] Train loss=0.225816011428833
[10/24] Train loss=0.2311873584985733
[15/24] Train loss=0.2366216480731964
[20/24] Train loss=0.19960834085941315
Test set avg_accuracy=78.24% avg_sensitivity=21.40%, avg_specificity=99.41% avg_auc=86.49%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.225884 Test loss=0.568769 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.21046613156795502
[5/24] Train loss=0.20827244222164154
[10/24] Train loss=0.23213651776313782
[15/24] Train loss=0.2279997020959854
[20/24] Train loss=0.19712607562541962
Test set avg_accuracy=88.32% avg_sensitivity=65.16%, avg_specificity=96.94% avg_auc=93.23%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.227637 Test loss=0.292394 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2078830897808075
[5/24] Train loss=0.20535379648208618
[10/24] Train loss=0.2252841591835022
[15/24] Train loss=0.21943750977516174
[20/24] Train loss=0.1890016794204712
Test set avg_accuracy=88.96% avg_sensitivity=81.05%, avg_specificity=91.90% avg_auc=93.94%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.220466 Test loss=0.275830 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.20549391210079193
[5/24] Train loss=0.2043417990207672
[10/24] Train loss=0.2324453443288803
[15/24] Train loss=0.21526305377483368
[20/24] Train loss=0.194152370095253
Test set avg_accuracy=89.11% avg_sensitivity=71.55%, avg_specificity=95.66% avg_auc=93.71%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.213282 Test loss=0.275825 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.20776167511940002
[5/24] Train loss=0.20882479846477509
[10/24] Train loss=0.2281980961561203
[15/24] Train loss=0.2102409452199936
[20/24] Train loss=0.19669783115386963
Test set avg_accuracy=88.68% avg_sensitivity=66.17%, avg_specificity=97.07% avg_auc=92.74%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.215767 Test loss=0.296211 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2042188048362732
[5/24] Train loss=0.2008349895477295
[10/24] Train loss=0.23082098364830017
[15/24] Train loss=0.2066381424665451
[20/24] Train loss=0.1882990300655365
Test set avg_accuracy=86.93% avg_sensitivity=84.64%, avg_specificity=87.78% avg_auc=93.48%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.212017 Test loss=0.314558 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.19717353582382202
[5/24] Train loss=0.20020999014377594
[10/24] Train loss=0.22899304330348969
[15/24] Train loss=0.21643653512001038
[20/24] Train loss=0.18123869597911835
Test set avg_accuracy=89.38% avg_sensitivity=72.31%, avg_specificity=95.73% avg_auc=92.85%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.209114 Test loss=0.279087 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.18888626992702484
[5/24] Train loss=0.20746785402297974
[10/24] Train loss=0.22887125611305237
[15/24] Train loss=0.21118643879890442
[20/24] Train loss=0.19295042753219604
Test set avg_accuracy=87.23% avg_sensitivity=63.05%, avg_specificity=96.23% avg_auc=88.92%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.209238 Test loss=0.348017 Current lr=[0.00029967723776099]

[0/24] Train loss=0.21218423545360565
[5/24] Train loss=0.20027391612529755
[10/24] Train loss=0.21969227492809296
[15/24] Train loss=0.21150796115398407
[20/24] Train loss=0.19515560567378998
Test set avg_accuracy=88.70% avg_sensitivity=66.31%, avg_specificity=97.03% avg_auc=92.74%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.210275 Test loss=0.294082 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.1948261559009552
[5/24] Train loss=0.20070484280586243
[10/24] Train loss=0.21352693438529968
[15/24] Train loss=0.2052275836467743
[20/24] Train loss=0.18748074769973755
Test set avg_accuracy=89.22% avg_sensitivity=74.23%, avg_specificity=94.80% avg_auc=93.55%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.207852 Test loss=0.281859 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.20310764014720917
[5/24] Train loss=0.18088261783123016
[10/24] Train loss=0.22368082404136658
[15/24] Train loss=0.202839195728302
[20/24] Train loss=0.184809148311615
Test set avg_accuracy=87.30% avg_sensitivity=78.65%, avg_specificity=90.53% avg_auc=92.53%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.207252 Test loss=0.308645 Current lr=[0.000299720220882401]

[0/24] Train loss=0.20026153326034546
[5/24] Train loss=0.18957895040512085
[10/24] Train loss=0.2065221518278122
[15/24] Train loss=0.20843903720378876
[20/24] Train loss=0.1822822540998459
Test set avg_accuracy=88.22% avg_sensitivity=65.21%, avg_specificity=96.78% avg_auc=91.86%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.202904 Test loss=0.311665 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19567281007766724
[5/24] Train loss=0.18216286599636078
[10/24] Train loss=0.21116280555725098
[15/24] Train loss=0.19157250225543976
[20/24] Train loss=0.18152938783168793
Test set avg_accuracy=86.69% avg_sensitivity=83.30%, avg_specificity=87.96% avg_auc=93.28%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.196109 Test loss=0.319858 Current lr=[0.000298904600941902]

[0/24] Train loss=0.20453190803527832
[5/24] Train loss=0.18446128070354462
[10/24] Train loss=0.20683924853801727
[15/24] Train loss=0.1904870867729187
[20/24] Train loss=0.17269833385944366
Test set avg_accuracy=89.28% avg_sensitivity=78.12%, avg_specificity=93.44% avg_auc=93.61%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.197361 Test loss=0.267920 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.19528427720069885
[5/24] Train loss=0.1924228072166443
[10/24] Train loss=0.1954386681318283
[15/24] Train loss=0.20140688121318817
[20/24] Train loss=0.16094468533992767
Test set avg_accuracy=87.53% avg_sensitivity=81.53%, avg_specificity=89.76% avg_auc=93.04%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.196988 Test loss=0.299190 Current lr=[0.000297555943323901]

[0/24] Train loss=0.20373159646987915
[5/24] Train loss=0.19505511224269867
[10/24] Train loss=0.20211614668369293
[15/24] Train loss=0.1990046352148056
[20/24] Train loss=0.18490161001682281
Test set avg_accuracy=88.80% avg_sensitivity=77.83%, avg_specificity=92.89% avg_auc=93.66%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.195550 Test loss=0.272740 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.18537765741348267
[5/24] Train loss=0.17798204720020294
[10/24] Train loss=0.18500010669231415
[15/24] Train loss=0.18393352627754211
[20/24] Train loss=0.17032040655612946
Test set avg_accuracy=88.97% avg_sensitivity=71.64%, avg_specificity=95.43% avg_auc=93.13%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.189675 Test loss=0.284426 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.188425675034523
[5/24] Train loss=0.16897070407867432
[10/24] Train loss=0.1826881617307663
[15/24] Train loss=0.18660934269428253
[20/24] Train loss=0.17256054282188416
Test set avg_accuracy=88.78% avg_sensitivity=77.54%, avg_specificity=92.96% avg_auc=93.06%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.187891 Test loss=0.282660 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.1947987973690033
[5/24] Train loss=0.16873958706855774
[10/24] Train loss=0.18503981828689575
[15/24] Train loss=0.18667903542518616
[20/24] Train loss=0.17465190589427948
Test set avg_accuracy=88.79% avg_sensitivity=75.91%, avg_specificity=93.58% avg_auc=92.85%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.186600 Test loss=0.288920 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.1801062971353531
[5/24] Train loss=0.17210808396339417
[10/24] Train loss=0.1944199651479721
[15/24] Train loss=0.1993119865655899
[20/24] Train loss=0.16298870742321014
Test set avg_accuracy=76.85% avg_sensitivity=86.23%, avg_specificity=73.36% avg_auc=88.49%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.187511 Test loss=0.504386 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.19647622108459473
[5/24] Train loss=0.1842881292104721
[10/24] Train loss=0.18493475019931793
[15/24] Train loss=0.19167116284370422
[20/24] Train loss=0.17596137523651123
Test set avg_accuracy=89.13% avg_sensitivity=80.09%, avg_specificity=92.49% avg_auc=93.47%
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.193590 Test loss=0.280204 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.18418921530246735
[5/24] Train loss=0.17539715766906738
[10/24] Train loss=0.19202248752117157
[15/24] Train loss=0.18140478432178497
[20/24] Train loss=0.16483379900455475
Test set avg_accuracy=86.86% avg_sensitivity=73.61%, avg_specificity=91.80% avg_auc=90.35%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.185939 Test loss=0.330239 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.19949166476726532
[5/24] Train loss=0.16558223962783813
[10/24] Train loss=0.18428590893745422
[15/24] Train loss=0.18024632334709167
[20/24] Train loss=0.17329713702201843
Test set avg_accuracy=81.88% avg_sensitivity=36.37%, avg_specificity=98.82% avg_auc=88.41%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.191529 Test loss=0.483126 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.20645903050899506
[5/24] Train loss=0.17983976006507874
[10/24] Train loss=0.18511715531349182
[15/24] Train loss=0.18598061800003052
[20/24] Train loss=0.16676145792007446
Test set avg_accuracy=88.97% avg_sensitivity=82.10%, avg_specificity=91.53% avg_auc=93.75%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.188739 Test loss=0.276484 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.1832507848739624
[5/24] Train loss=0.16349729895591736
[10/24] Train loss=0.1844107061624527
[15/24] Train loss=0.1791045218706131
[20/24] Train loss=0.17373670637607574
Test set avg_accuracy=87.77% avg_sensitivity=83.88%, avg_specificity=89.22% avg_auc=93.20%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.181201 Test loss=0.297057 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.19081175327301025
[5/24] Train loss=0.17100399732589722
[10/24] Train loss=0.1833014339208603
[15/24] Train loss=0.1883220076560974
[20/24] Train loss=0.15827853977680206
Test set avg_accuracy=89.18% avg_sensitivity=79.13%, avg_specificity=92.92% avg_auc=93.18%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.181112 Test loss=0.279442 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.18118731677532196
[5/24] Train loss=0.17079539597034454
[10/24] Train loss=0.18306255340576172
[15/24] Train loss=0.1810428649187088
[20/24] Train loss=0.16346582770347595
Test set avg_accuracy=89.32% avg_sensitivity=74.28%, avg_specificity=94.92% avg_auc=92.68%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.182306 Test loss=0.285524 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.18196915090084076
[5/24] Train loss=0.1836286336183548
[10/24] Train loss=0.18235896527767181
[15/24] Train loss=0.1866232007741928
[20/24] Train loss=0.16346187889575958
Test set avg_accuracy=85.81% avg_sensitivity=84.31%, avg_specificity=86.37% avg_auc=92.24%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.182747 Test loss=0.335959 Current lr=[0.000276307469034998]

[0/24] Train loss=0.17404821515083313
[5/24] Train loss=0.16008777916431427
[10/24] Train loss=0.18318060040473938
[15/24] Train loss=0.17920176684856415
[20/24] Train loss=0.16584764420986176
Test set avg_accuracy=87.99% avg_sensitivity=83.40%, avg_specificity=89.71% avg_auc=93.29%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.178387 Test loss=0.297647 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.18676619231700897
[5/24] Train loss=0.17073512077331543
[10/24] Train loss=0.18011440336704254
[15/24] Train loss=0.18840891122817993
[20/24] Train loss=0.16075484454631805
Test set avg_accuracy=86.97% avg_sensitivity=60.08%, avg_specificity=96.98% avg_auc=91.24%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.180020 Test loss=0.334117 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.16479390859603882
[5/24] Train loss=0.17089565098285675
[10/24] Train loss=0.17779916524887085
[15/24] Train loss=0.17265841364860535
[20/24] Train loss=0.16043737530708313
Test set avg_accuracy=88.83% avg_sensitivity=79.61%, avg_specificity=92.26% avg_auc=92.90%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.178539 Test loss=0.283150 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.17702825367450714
[5/24] Train loss=0.1641266942024231
[10/24] Train loss=0.17037631571292877
[15/24] Train loss=0.17664751410484314
[20/24] Train loss=0.1583828330039978
Test set avg_accuracy=89.35% avg_sensitivity=74.76%, avg_specificity=94.78% avg_auc=93.22%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.175201 Test loss=0.275877 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.16910606622695923
[5/24] Train loss=0.17320574820041656
[10/24] Train loss=0.18440134823322296
[15/24] Train loss=0.19099119305610657
[20/24] Train loss=0.17208227515220642
Test set avg_accuracy=84.27% avg_sensitivity=88.05%, avg_specificity=82.86% avg_auc=92.77%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.179204 Test loss=0.360413 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.19326859712600708
[5/24] Train loss=0.17258960008621216
[10/24] Train loss=0.17101114988327026
[15/24] Train loss=0.1813376247882843
[20/24] Train loss=0.15511371195316315
Test set avg_accuracy=86.91% avg_sensitivity=86.28%, avg_specificity=87.15% avg_auc=93.46%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.177888 Test loss=0.309997 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.17813827097415924
[5/24] Train loss=0.1567816436290741
[10/24] Train loss=0.18126478791236877
[15/24] Train loss=0.1659066379070282
[20/24] Train loss=0.15955913066864014
Test set avg_accuracy=88.57% avg_sensitivity=80.66%, avg_specificity=91.51% avg_auc=93.13%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.172925 Test loss=0.288759 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.17665734887123108
[5/24] Train loss=0.16416360437870026
[10/24] Train loss=0.17300285398960114
[15/24] Train loss=0.17415228486061096
[20/24] Train loss=0.16598215699195862
Test set avg_accuracy=88.75% avg_sensitivity=79.51%, avg_specificity=92.19% avg_auc=93.43%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.174957 Test loss=0.281332 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.17257291078567505
[5/24] Train loss=0.15693777799606323
[10/24] Train loss=0.17423216998577118
[15/24] Train loss=0.17983460426330566
[20/24] Train loss=0.15792694687843323
Test set avg_accuracy=88.97% avg_sensitivity=81.09%, avg_specificity=91.90% avg_auc=93.63%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.173948 Test loss=0.282423 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.16591180860996246
[5/24] Train loss=0.16301390528678894
[10/24] Train loss=0.1799098551273346
[15/24] Train loss=0.17072941362857819
[20/24] Train loss=0.15501226484775543
Test set avg_accuracy=88.95% avg_sensitivity=72.12%, avg_specificity=95.21% avg_auc=92.43%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.172245 Test loss=0.286819 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.177703395485878
[5/24] Train loss=0.1561020463705063
[10/24] Train loss=0.17617036402225494
[15/24] Train loss=0.17295147478580475
[20/24] Train loss=0.1494389921426773
Test set avg_accuracy=81.68% avg_sensitivity=36.04%, avg_specificity=98.68% avg_auc=86.38%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.168662 Test loss=0.488587 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.17230990529060364
[5/24] Train loss=0.15739619731903076
[10/24] Train loss=0.1624378263950348
[15/24] Train loss=0.17074981331825256
[20/24] Train loss=0.15309740602970123
Test set avg_accuracy=88.41% avg_sensitivity=80.76%, avg_specificity=91.26% avg_auc=93.62%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.170405 Test loss=0.286076 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.1644422560930252
[5/24] Train loss=0.15220972895622253
[10/24] Train loss=0.16500572860240936
[15/24] Train loss=0.16561788320541382
[20/24] Train loss=0.14845840632915497
Test set avg_accuracy=88.62% avg_sensitivity=70.73%, avg_specificity=95.28% avg_auc=91.27%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.168324 Test loss=0.305018 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.1638491153717041
[5/24] Train loss=0.153791144490242
[10/24] Train loss=0.17356961965560913
[15/24] Train loss=0.17298524081707
[20/24] Train loss=0.15200670063495636
Test set avg_accuracy=89.11% avg_sensitivity=78.69%, avg_specificity=92.99% avg_auc=93.31%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.169961 Test loss=0.283120 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.1642274558544159
[5/24] Train loss=0.15769840776920319
[10/24] Train loss=0.17263616621494293
[15/24] Train loss=0.1691657453775406
[20/24] Train loss=0.1468183696269989
Test set avg_accuracy=88.71% avg_sensitivity=76.73%, avg_specificity=93.17% avg_auc=92.25%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.167440 Test loss=0.293366 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.16899952292442322
[5/24] Train loss=0.1519935429096222
[10/24] Train loss=0.16571006178855896
[15/24] Train loss=0.16107706725597382
[20/24] Train loss=0.1501399129629135
Test set avg_accuracy=88.44% avg_sensitivity=67.23%, avg_specificity=96.34% avg_auc=91.21%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.164837 Test loss=0.310159 Current lr=[0.000224838296036774]

[0/24] Train loss=0.15888139605522156
[5/24] Train loss=0.15728461742401123
[10/24] Train loss=0.15440508723258972
[15/24] Train loss=0.17581674456596375
[20/24] Train loss=0.15081855654716492
Test set avg_accuracy=88.09% avg_sensitivity=70.87%, avg_specificity=94.50% avg_auc=91.92%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.167313 Test loss=0.303401 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.17255768179893494
[5/24] Train loss=0.1526152640581131
[10/24] Train loss=0.1611810028553009
[15/24] Train loss=0.168515145778656
[20/24] Train loss=0.14792786538600922
Test set avg_accuracy=88.63% avg_sensitivity=77.54%, avg_specificity=92.76% avg_auc=92.20%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.166226 Test loss=0.297645 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.1675225794315338
[5/24] Train loss=0.15115417540073395
[10/24] Train loss=0.16244633495807648
[15/24] Train loss=0.1657218039035797
[20/24] Train loss=0.15385745465755463
Test set avg_accuracy=88.16% avg_sensitivity=78.31%, avg_specificity=91.83% avg_auc=92.88%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.168741 Test loss=0.297088 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.16210265457630157
[5/24] Train loss=0.15177759528160095
[10/24] Train loss=0.1622186303138733
[15/24] Train loss=0.16115237772464752
[20/24] Train loss=0.14899805188179016
Test set avg_accuracy=89.39% avg_sensitivity=79.80%, avg_specificity=92.96% avg_auc=93.23%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.164136 Test loss=0.276132 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.1619534194469452
[5/24] Train loss=0.15097609162330627
[10/24] Train loss=0.16036835312843323
[15/24] Train loss=0.1620582640171051
[20/24] Train loss=0.1487051099538803
Test set avg_accuracy=87.25% avg_sensitivity=73.08%, avg_specificity=92.53% avg_auc=91.69%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.165474 Test loss=0.313292 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.16899991035461426
[5/24] Train loss=0.15741078555583954
[10/24] Train loss=0.17082294821739197
[15/24] Train loss=0.1644943654537201
[20/24] Train loss=0.15113766491413116
Test set avg_accuracy=89.32% avg_sensitivity=79.99%, avg_specificity=92.80% avg_auc=93.41%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.167780 Test loss=0.273205 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.15801790356636047
[5/24] Train loss=0.1506427824497223
[10/24] Train loss=0.15494416654109955
[15/24] Train loss=0.16817428171634674
[20/24] Train loss=0.14693893492221832
Test set avg_accuracy=88.98% avg_sensitivity=81.00%, avg_specificity=91.96% avg_auc=93.22%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.162112 Test loss=0.281785 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1620372235774994
[5/24] Train loss=0.14488491415977478
[10/24] Train loss=0.15377730131149292
[15/24] Train loss=0.16738538444042206
[20/24] Train loss=0.14496354758739471
Test set avg_accuracy=89.08% avg_sensitivity=83.69%, avg_specificity=91.08% avg_auc=93.40%
Best model saved!! Metric=31.247938683209654!!
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.159958 Test loss=0.280625 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1558355689048767
[5/24] Train loss=0.1495327204465866
[10/24] Train loss=0.14841236174106598
[15/24] Train loss=0.1738894134759903
[20/24] Train loss=0.14050507545471191
Test set avg_accuracy=88.84% avg_sensitivity=82.53%, avg_specificity=91.19% avg_auc=93.25%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.159139 Test loss=0.285081 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.16378308832645416
[5/24] Train loss=0.14409145712852478
[10/24] Train loss=0.16000211238861084
[15/24] Train loss=0.15839777886867523
[20/24] Train loss=0.1482953131198883
Test set avg_accuracy=89.34% avg_sensitivity=74.28%, avg_specificity=94.94% avg_auc=92.79%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.161254 Test loss=0.285828 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.16616928577423096
[5/24] Train loss=0.1637660264968872
[10/24] Train loss=0.15592855215072632
[15/24] Train loss=0.16357067227363586
[20/24] Train loss=0.14807434380054474
Test set avg_accuracy=88.87% avg_sensitivity=83.97%, avg_specificity=90.69% avg_auc=93.09%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.162247 Test loss=0.289481 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.15332700312137604
[5/24] Train loss=0.14128491282463074
[10/24] Train loss=0.15455220639705658
[15/24] Train loss=0.16554273664951324
[20/24] Train loss=0.15046235918998718
Test set avg_accuracy=89.47% avg_sensitivity=81.14%, avg_specificity=92.57% avg_auc=93.53%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.159867 Test loss=0.273951 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.16386768221855164
[5/24] Train loss=0.15406003594398499
[10/24] Train loss=0.16709131002426147
[15/24] Train loss=0.17302551865577698
[20/24] Train loss=0.14237044751644135
Test set avg_accuracy=89.39% avg_sensitivity=74.52%, avg_specificity=94.92% avg_auc=92.58%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.161270 Test loss=0.284367 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.16253766417503357
[5/24] Train loss=0.14552167057991028
[10/24] Train loss=0.15230262279510498
[15/24] Train loss=0.15433000028133392
[20/24] Train loss=0.14395174384117126
Test set avg_accuracy=88.42% avg_sensitivity=67.37%, avg_specificity=96.27% avg_auc=91.04%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.160547 Test loss=0.317313 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1620270162820816
[5/24] Train loss=0.14525306224822998
[10/24] Train loss=0.14928416907787323
[15/24] Train loss=0.15879806876182556
[20/24] Train loss=0.14006228744983673
Test set avg_accuracy=86.91% avg_sensitivity=62.86%, avg_specificity=95.87% avg_auc=89.97%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.155810 Test loss=0.347584 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15931908786296844
[5/24] Train loss=0.14747856557369232
[10/24] Train loss=0.14438985288143158
[15/24] Train loss=0.15252773463726044
[20/24] Train loss=0.1428905576467514
Test set avg_accuracy=88.33% avg_sensitivity=67.47%, avg_specificity=96.10% avg_auc=91.18%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.159435 Test loss=0.312711 Current lr=[0.000156543481933168]

[0/24] Train loss=0.16125839948654175
[5/24] Train loss=0.14343948662281036
[10/24] Train loss=0.149835005402565
[15/24] Train loss=0.15964557230472565
[20/24] Train loss=0.14091931283473969
Test set avg_accuracy=88.95% avg_sensitivity=74.23%, avg_specificity=94.42% avg_auc=92.46%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.158004 Test loss=0.291600 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.15536417067050934
[5/24] Train loss=0.15781477093696594
[10/24] Train loss=0.14750754833221436
[15/24] Train loss=0.15411625802516937
[20/24] Train loss=0.145937979221344
Test set avg_accuracy=88.61% avg_sensitivity=69.58%, avg_specificity=95.69% avg_auc=91.85%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.157652 Test loss=0.298672 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15339674055576324
[5/24] Train loss=0.14416614174842834
[10/24] Train loss=0.1481611281633377
[15/24] Train loss=0.15638868510723114
[20/24] Train loss=0.1430584043264389
Test set avg_accuracy=89.18% avg_sensitivity=79.27%, avg_specificity=92.87% avg_auc=93.28%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.155254 Test loss=0.279002 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15823788940906525
[5/24] Train loss=0.14729684591293335
[10/24] Train loss=0.15419510006904602
[15/24] Train loss=0.14778824150562286
[20/24] Train loss=0.1425735205411911
Test set avg_accuracy=88.74% avg_sensitivity=69.34%, avg_specificity=95.96% avg_auc=91.54%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.155069 Test loss=0.307107 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1558138132095337
[5/24] Train loss=0.14566893875598907
[10/24] Train loss=0.14996443688869476
[15/24] Train loss=0.16337040066719055
[20/24] Train loss=0.14318712055683136
Test set avg_accuracy=88.85% avg_sensitivity=72.41%, avg_specificity=94.98% avg_auc=91.67%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.154910 Test loss=0.300291 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16000287234783173
[5/24] Train loss=0.14923308789730072
[10/24] Train loss=0.15128189325332642
[15/24] Train loss=0.14556536078453064
[20/24] Train loss=0.13950949907302856
Test set avg_accuracy=89.24% avg_sensitivity=73.94%, avg_specificity=94.94% avg_auc=92.13%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.154418 Test loss=0.290060 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.14974667131900787
[5/24] Train loss=0.14606310427188873
[10/24] Train loss=0.14133238792419434
[15/24] Train loss=0.15178988873958588
[20/24] Train loss=0.1362798810005188
Test set avg_accuracy=89.23% avg_sensitivity=71.16%, avg_specificity=95.96% avg_auc=92.30%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.151075 Test loss=0.293912 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.15136703848838806
[5/24] Train loss=0.14301876723766327
[10/24] Train loss=0.14725448191165924
[15/24] Train loss=0.15127530694007874
[20/24] Train loss=0.14496740698814392
Test set avg_accuracy=89.66% avg_sensitivity=73.46%, avg_specificity=95.69% avg_auc=92.25%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.152057 Test loss=0.287866 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.14586852490901947
[5/24] Train loss=0.1393376737833023
[10/24] Train loss=0.14568966627120972
[15/24] Train loss=0.16410911083221436
[20/24] Train loss=0.14693604409694672
Test set avg_accuracy=89.60% avg_sensitivity=72.02%, avg_specificity=96.14% avg_auc=92.55%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.153325 Test loss=0.285187 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14778773486614227
[5/24] Train loss=0.14330807328224182
[10/24] Train loss=0.15462535619735718
[15/24] Train loss=0.15265855193138123
[20/24] Train loss=0.13324975967407227
Test set avg_accuracy=89.54% avg_sensitivity=76.87%, avg_specificity=94.26% avg_auc=93.20%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.154468 Test loss=0.274972 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15492449700832367
[5/24] Train loss=0.1428583860397339
[10/24] Train loss=0.1452595740556717
[15/24] Train loss=0.14095905423164368
[20/24] Train loss=0.134865403175354
Test set avg_accuracy=89.10% avg_sensitivity=79.03%, avg_specificity=92.85% avg_auc=92.92%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.149974 Test loss=0.286680 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15701812505722046
[5/24] Train loss=0.1459624320268631
[10/24] Train loss=0.13901224732398987
[15/24] Train loss=0.14752823114395142
[20/24] Train loss=0.1378265768289566
Test set avg_accuracy=89.97% avg_sensitivity=79.03%, avg_specificity=94.05% avg_auc=93.41%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.148654 Test loss=0.269902 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15281808376312256
[5/24] Train loss=0.13920946419239044
[10/24] Train loss=0.13430042564868927
[15/24] Train loss=0.1388636827468872
[20/24] Train loss=0.1362970769405365
Test set avg_accuracy=89.87% avg_sensitivity=80.85%, avg_specificity=93.23% avg_auc=93.62%
Best model saved!! Metric=31.574612185573088!!
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.146088 Test loss=0.269646 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14716747403144836
[5/24] Train loss=0.14031252264976501
[10/24] Train loss=0.13669216632843018
[15/24] Train loss=0.14073777198791504
[20/24] Train loss=0.13411280512809753
Test set avg_accuracy=88.93% avg_sensitivity=81.57%, avg_specificity=91.67% avg_auc=92.81%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.145109 Test loss=0.285216 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14839020371437073
[5/24] Train loss=0.13110196590423584
[10/24] Train loss=0.13381050527095795
[15/24] Train loss=0.13789883255958557
[20/24] Train loss=0.1324579268693924
Test set avg_accuracy=89.30% avg_sensitivity=76.78%, avg_specificity=93.96% avg_auc=92.93%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.142627 Test loss=0.279167 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.14157748222351074
[5/24] Train loss=0.1320551335811615
[10/24] Train loss=0.132699653506279
[15/24] Train loss=0.14072221517562866
[20/24] Train loss=0.12950390577316284
Test set avg_accuracy=89.56% avg_sensitivity=80.04%, avg_specificity=93.10% avg_auc=93.12%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.140920 Test loss=0.274727 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14110006392002106
[5/24] Train loss=0.13393418490886688
[10/24] Train loss=0.1326962411403656
[15/24] Train loss=0.13362079858779907
[20/24] Train loss=0.12856470048427582
Test set avg_accuracy=89.23% avg_sensitivity=75.00%, avg_specificity=94.53% avg_auc=92.74%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.138784 Test loss=0.279922 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13816380500793457
[5/24] Train loss=0.12720999121665955
[10/24] Train loss=0.13314703106880188
[15/24] Train loss=0.1379956156015396
[20/24] Train loss=0.12722355127334595
Test set avg_accuracy=89.35% avg_sensitivity=83.16%, avg_specificity=91.65% avg_auc=93.09%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.138261 Test loss=0.279576 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14411316812038422
[5/24] Train loss=0.12692658603191376
[10/24] Train loss=0.12965106964111328
[15/24] Train loss=0.13225200772285461
[20/24] Train loss=0.1282978057861328
Test set avg_accuracy=89.18% avg_sensitivity=77.74%, avg_specificity=93.44% avg_auc=92.74%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.136684 Test loss=0.279987 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1360825151205063
[5/24] Train loss=0.12628105282783508
[10/24] Train loss=0.1281241625547409
[15/24] Train loss=0.13232490420341492
[20/24] Train loss=0.12740159034729004
Test set avg_accuracy=89.11% avg_sensitivity=80.61%, avg_specificity=92.28% avg_auc=92.96%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.135491 Test loss=0.279518 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13737784326076508
[5/24] Train loss=0.12779922783374786
[10/24] Train loss=0.12828625738620758
[15/24] Train loss=0.13234256207942963
[20/24] Train loss=0.1267222762107849
Test set avg_accuracy=89.19% avg_sensitivity=79.75%, avg_specificity=92.71% avg_auc=93.04%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.134692 Test loss=0.281158 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.13763339817523956
[5/24] Train loss=0.1223907321691513
[10/24] Train loss=0.12908726930618286
[15/24] Train loss=0.13076075911521912
[20/24] Train loss=0.12483880668878555
Test set avg_accuracy=89.52% avg_sensitivity=79.08%, avg_specificity=93.41% avg_auc=92.68%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.134124 Test loss=0.279346 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13416051864624023
[5/24] Train loss=0.12157797068357468
[10/24] Train loss=0.12389372289180756
[15/24] Train loss=0.13046205043792725
[20/24] Train loss=0.12809543311595917
Test set avg_accuracy=89.00% avg_sensitivity=80.47%, avg_specificity=92.17% avg_auc=92.92%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.133118 Test loss=0.284889 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13619886338710785
[5/24] Train loss=0.1265319138765335
[10/24] Train loss=0.1267748922109604
[15/24] Train loss=0.12904909253120422
[20/24] Train loss=0.12763197720050812
Test set avg_accuracy=89.23% avg_sensitivity=76.73%, avg_specificity=93.89% avg_auc=92.55%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.133911 Test loss=0.282205 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13416236639022827
[5/24] Train loss=0.12445352226495743
[10/24] Train loss=0.12307839840650558
[15/24] Train loss=0.12608924508094788
[20/24] Train loss=0.12372726202011108
Test set avg_accuracy=89.05% avg_sensitivity=75.82%, avg_specificity=93.98% avg_auc=92.79%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.131877 Test loss=0.284161 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.13227885961532593
[5/24] Train loss=0.12175441533327103
[10/24] Train loss=0.12192096561193466
[15/24] Train loss=0.12940050661563873
[20/24] Train loss=0.12062083184719086
Test set avg_accuracy=89.62% avg_sensitivity=78.21%, avg_specificity=93.87% avg_auc=92.95%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.130765 Test loss=0.275064 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1324436068534851
[5/24] Train loss=0.12121456116437912
[10/24] Train loss=0.127955362200737
[15/24] Train loss=0.1283901184797287
[20/24] Train loss=0.12227840721607208
Test set avg_accuracy=89.47% avg_sensitivity=79.89%, avg_specificity=93.03% avg_auc=92.85%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.130457 Test loss=0.275880 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1313982754945755
[5/24] Train loss=0.12206849455833435
[10/24] Train loss=0.12266530841588974
[15/24] Train loss=0.12417618930339813
[20/24] Train loss=0.1260911226272583
Test set avg_accuracy=89.67% avg_sensitivity=78.26%, avg_specificity=93.92% avg_auc=92.86%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.130045 Test loss=0.275185 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12798959016799927
[5/24] Train loss=0.12180282175540924
[10/24] Train loss=0.11932884156703949
[15/24] Train loss=0.12842759490013123
[20/24] Train loss=0.12448997795581818
Test set avg_accuracy=89.83% avg_sensitivity=76.87%, avg_specificity=94.66% avg_auc=92.62%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.129522 Test loss=0.276957 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12975531816482544
[5/24] Train loss=0.12078753113746643
[10/24] Train loss=0.11988426744937897
[15/24] Train loss=0.12657015025615692
[20/24] Train loss=0.12108069658279419
Test set avg_accuracy=89.45% avg_sensitivity=77.64%, avg_specificity=93.85% avg_auc=92.74%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.127848 Test loss=0.278226 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1295752376317978
[5/24] Train loss=0.11854470521211624
[10/24] Train loss=0.11968168616294861
[15/24] Train loss=0.12210094928741455
[20/24] Train loss=0.12378732115030289
Test set avg_accuracy=89.28% avg_sensitivity=80.13%, avg_specificity=92.69% avg_auc=92.81%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.127056 Test loss=0.277749 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12652145326137543
[5/24] Train loss=0.12195385992527008
[10/24] Train loss=0.11790461838245392
[15/24] Train loss=0.12202739715576172
[20/24] Train loss=0.122298963367939
Test set avg_accuracy=89.73% avg_sensitivity=80.76%, avg_specificity=93.07% avg_auc=92.96%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.126404 Test loss=0.275521 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12702473998069763
[5/24] Train loss=0.11893195658922195
[10/24] Train loss=0.11833134293556213
[15/24] Train loss=0.1188608929514885
[20/24] Train loss=0.11864566057920456
Test set avg_accuracy=89.49% avg_sensitivity=79.41%, avg_specificity=93.25% avg_auc=92.88%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.126090 Test loss=0.275951 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1269051879644394
[5/24] Train loss=0.11836446821689606
[10/24] Train loss=0.11595793813467026
[15/24] Train loss=0.12364890426397324
[20/24] Train loss=0.11912029981613159
Test set avg_accuracy=89.44% avg_sensitivity=82.05%, avg_specificity=92.19% avg_auc=92.95%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.125678 Test loss=0.277612 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12637870013713837
[5/24] Train loss=0.11965204030275345
[10/24] Train loss=0.1178460344672203
[15/24] Train loss=0.120723195374012
[20/24] Train loss=0.11747921258211136
Test set avg_accuracy=89.22% avg_sensitivity=79.46%, avg_specificity=92.85% avg_auc=92.85%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.124784 Test loss=0.280692 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12577229738235474
[5/24] Train loss=0.12186890840530396
[10/24] Train loss=0.1172383651137352
[15/24] Train loss=0.12095434218645096
[20/24] Train loss=0.11830637603998184
Test set avg_accuracy=89.75% avg_sensitivity=78.79%, avg_specificity=93.83% avg_auc=93.03%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.124977 Test loss=0.273311 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12597976624965668
[5/24] Train loss=0.11954948306083679
[10/24] Train loss=0.11534488946199417
[15/24] Train loss=0.11998537927865982
[20/24] Train loss=0.12249364703893661
Test set avg_accuracy=89.69% avg_sensitivity=78.12%, avg_specificity=94.00% avg_auc=92.85%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.124336 Test loss=0.274346 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12308020144701004
[5/24] Train loss=0.1187991052865982
[10/24] Train loss=0.120032399892807
[15/24] Train loss=0.1193244606256485
[20/24] Train loss=0.11709506064653397
Test set avg_accuracy=89.65% avg_sensitivity=78.50%, avg_specificity=93.80% avg_auc=92.76%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.124734 Test loss=0.276534 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12305974960327148
[5/24] Train loss=0.11689609289169312
[10/24] Train loss=0.11571824550628662
[15/24] Train loss=0.11929091811180115
[20/24] Train loss=0.11754430085420609
Test set avg_accuracy=89.83% avg_sensitivity=78.21%, avg_specificity=94.16% avg_auc=92.79%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.123624 Test loss=0.274527 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12062181532382965
[5/24] Train loss=0.11750523000955582
[10/24] Train loss=0.11508409678936005
[15/24] Train loss=0.11801401525735855
[20/24] Train loss=0.11780540645122528
Test set avg_accuracy=89.57% avg_sensitivity=78.31%, avg_specificity=93.76% avg_auc=92.93%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.123236 Test loss=0.274667 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12162352353334427
[5/24] Train loss=0.1172747015953064
[10/24] Train loss=0.11625120788812637
[15/24] Train loss=0.12054183334112167
[20/24] Train loss=0.1176561713218689
Test set avg_accuracy=89.83% avg_sensitivity=80.23%, avg_specificity=93.41% avg_auc=93.09%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.122494 Test loss=0.271634 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12423068284988403
[5/24] Train loss=0.11483078449964523
[10/24] Train loss=0.11675605922937393
[15/24] Train loss=0.11726788431406021
[20/24] Train loss=0.11796653270721436
Test set avg_accuracy=89.74% avg_sensitivity=78.07%, avg_specificity=94.09% avg_auc=92.94%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.122214 Test loss=0.271058 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12079326808452606
[5/24] Train loss=0.11585723608732224
[10/24] Train loss=0.1147499531507492
[15/24] Train loss=0.11600975692272186
[20/24] Train loss=0.11513780802488327
Test set avg_accuracy=89.77% avg_sensitivity=79.61%, avg_specificity=93.55% avg_auc=93.02%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.121257 Test loss=0.271625 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12142518162727356
[5/24] Train loss=0.11586819589138031
[10/24] Train loss=0.1155005469918251
[15/24] Train loss=0.11578810214996338
[20/24] Train loss=0.11593443155288696
Test set avg_accuracy=89.83% avg_sensitivity=80.04%, avg_specificity=93.48% avg_auc=93.07%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.120618 Test loss=0.271008 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12016274780035019
[5/24] Train loss=0.11698390543460846
[10/24] Train loss=0.11474619805812836
[15/24] Train loss=0.11653721332550049
[20/24] Train loss=0.114956334233284
Test set avg_accuracy=89.78% avg_sensitivity=78.93%, avg_specificity=93.82% avg_auc=93.07%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.120816 Test loss=0.271627 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12326901406049728
[5/24] Train loss=0.11606132984161377
[10/24] Train loss=0.11269821226596832
[15/24] Train loss=0.11784166097640991
[20/24] Train loss=0.11620485782623291
Test set avg_accuracy=89.87% avg_sensitivity=79.22%, avg_specificity=93.83% avg_auc=92.96%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.120282 Test loss=0.274270 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11903133988380432
[5/24] Train loss=0.11450904607772827
[10/24] Train loss=0.11459273844957352
[15/24] Train loss=0.11543450504541397
[20/24] Train loss=0.11552714556455612
Test set avg_accuracy=89.86% avg_sensitivity=79.85%, avg_specificity=93.58% avg_auc=92.98%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.120247 Test loss=0.273847 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1204162985086441
[5/24] Train loss=0.11474408209323883
[10/24] Train loss=0.1157638356089592
[15/24] Train loss=0.11568248271942139
[20/24] Train loss=0.11471857875585556
Test set avg_accuracy=89.77% avg_sensitivity=79.70%, avg_specificity=93.51% avg_auc=93.02%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.120282 Test loss=0.273522 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12150079756975174
[5/24] Train loss=0.11334522813558578
[10/24] Train loss=0.11360425502061844
[15/24] Train loss=0.11749421060085297
[20/24] Train loss=0.1168515756726265
Test set avg_accuracy=89.83% avg_sensitivity=79.51%, avg_specificity=93.67% avg_auc=92.98%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.120063 Test loss=0.274213 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1182803362607956
[5/24] Train loss=0.11512719839811325
[10/24] Train loss=0.11356598883867264
[15/24] Train loss=0.1157568171620369
[20/24] Train loss=0.11471910029649734
Test set avg_accuracy=89.78% avg_sensitivity=79.22%, avg_specificity=93.71% avg_auc=92.99%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.119883 Test loss=0.273905 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11958710849285126
[5/24] Train loss=0.11654023081064224
[10/24] Train loss=0.1144261434674263
[15/24] Train loss=0.11611557751893997
[20/24] Train loss=0.11659111082553864
Test set avg_accuracy=89.83% avg_sensitivity=79.27%, avg_specificity=93.76% avg_auc=93.00%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.119540 Test loss=0.273631 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11933983862400055
[5/24] Train loss=0.11240581423044205
[10/24] Train loss=0.1146981492638588
[15/24] Train loss=0.11639375239610672
[20/24] Train loss=0.11700109392404556
Test set avg_accuracy=89.87% avg_sensitivity=79.41%, avg_specificity=93.76% avg_auc=93.02%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.119464 Test loss=0.273426 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11984249949455261
[5/24] Train loss=0.11420808732509613
[10/24] Train loss=0.11340616643428802
[15/24] Train loss=0.11691006273031235
[20/24] Train loss=0.11398521810770035
Test set avg_accuracy=89.84% avg_sensitivity=79.32%, avg_specificity=93.76% avg_auc=93.01%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.119683 Test loss=0.273581 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12096135318279266
[5/24] Train loss=0.11496253311634064
[10/24] Train loss=0.11274533718824387
[15/24] Train loss=0.11442367732524872
[20/24] Train loss=0.11660846322774887
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=89.83% avg_sensitivity=79.37%, avg_specificity=93.73% avg_auc=93.00%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.119894 Test loss=0.273636 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=89.87% sen=80.85%, spe=93.23%, auc=93.62%!
Fold[6] Avg_overlap=0.73%(0.23323389547043186)
[0/24] Train loss=0.7313635945320129
[5/24] Train loss=0.7225193977355957
[10/24] Train loss=0.7153009176254272
[15/24] Train loss=0.6999590992927551
[20/24] Train loss=0.7020741701126099
Test set avg_accuracy=57.59% avg_sensitivity=47.19%, avg_specificity=61.56% avg_auc=56.36%
Best model saved!! Metric=-103.29978755882632!!
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.715543 Test loss=0.675141 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7015802264213562
[5/24] Train loss=0.6909557580947876
[10/24] Train loss=0.6922314167022705
[15/24] Train loss=0.6762393116950989
[20/24] Train loss=0.6699284315109253
Test set avg_accuracy=65.05% avg_sensitivity=60.30%, avg_specificity=66.86% avg_auc=68.77%
Best model saved!! Metric=-65.00772631735651!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.687331 Test loss=0.625950 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6693118214607239
[5/24] Train loss=0.6656275987625122
[10/24] Train loss=0.6684170961380005
[15/24] Train loss=0.646797776222229
[20/24] Train loss=0.6427737474441528
Test set avg_accuracy=68.55% avg_sensitivity=65.82%, avg_specificity=69.60% avg_auc=75.06%
Best model saved!! Metric=-46.97079114454165!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.660593 Test loss=0.589744 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6448121070861816
[5/24] Train loss=0.6356132626533508
[10/24] Train loss=0.6415196061134338
[15/24] Train loss=0.620971143245697
[20/24] Train loss=0.6098836660385132
Test set avg_accuracy=71.41% avg_sensitivity=70.86%, avg_specificity=71.61% avg_auc=79.04%
Best model saved!! Metric=-33.078304569095025!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.633771 Test loss=0.561116 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6094402074813843
[5/24] Train loss=0.6146852374076843
[10/24] Train loss=0.612417995929718
[15/24] Train loss=0.5909844636917114
[20/24] Train loss=0.5842874646186829
Test set avg_accuracy=74.86% avg_sensitivity=73.36%, avg_specificity=75.43% avg_auc=81.76%
Best model saved!! Metric=-20.59159409413158!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.606003 Test loss=0.532322 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5859740972518921
[5/24] Train loss=0.5848585367202759
[10/24] Train loss=0.5885576009750366
[15/24] Train loss=0.5579813122749329
[20/24] Train loss=0.5456873774528503
Test set avg_accuracy=78.01% avg_sensitivity=74.68%, avg_specificity=79.28% avg_auc=84.07%
Best model saved!! Metric=-9.96231905945153!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.577713 Test loss=0.501574 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5508421659469604
[5/24] Train loss=0.5536168813705444
[10/24] Train loss=0.5596234798431396
[15/24] Train loss=0.5228146314620972
[20/24] Train loss=0.5134454965591431
Test set avg_accuracy=79.49% avg_sensitivity=75.06%, avg_specificity=81.18% avg_auc=86.17%
Best model saved!! Metric=-4.097829461760924!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.548269 Test loss=0.470736 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5291888117790222
[5/24] Train loss=0.5208253264427185
[10/24] Train loss=0.5312274098396301
[15/24] Train loss=0.4960418939590454
[20/24] Train loss=0.4881298542022705
Test set avg_accuracy=81.33% avg_sensitivity=76.00%, avg_specificity=83.36% avg_auc=88.21%
Best model saved!! Metric=2.9008731776008716!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.519702 Test loss=0.437470 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.4971030056476593
[5/24] Train loss=0.48868006467819214
[10/24] Train loss=0.49918031692504883
[15/24] Train loss=0.46963080763816833
[20/24] Train loss=0.4567524194717407
Test set avg_accuracy=83.36% avg_sensitivity=76.76%, avg_specificity=85.88% avg_auc=89.88%
Best model saved!! Metric=9.87001500856951!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.489953 Test loss=0.409815 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4653787314891815
[5/24] Train loss=0.4549660086631775
[10/24] Train loss=0.47511059045791626
[15/24] Train loss=0.43692755699157715
[20/24] Train loss=0.4248233437538147
Test set avg_accuracy=84.80% avg_sensitivity=73.27%, avg_specificity=89.21% avg_auc=90.63%
Best model saved!! Metric=11.912250202920518!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.459386 Test loss=0.381592 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.43585723638534546
[5/24] Train loss=0.42755401134490967
[10/24] Train loss=0.44104477763175964
[15/24] Train loss=0.41027915477752686
[20/24] Train loss=0.39620137214660645
Test set avg_accuracy=86.12% avg_sensitivity=73.27%, avg_specificity=91.02% avg_auc=91.71%
Best model saved!! Metric=16.119258701489812!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.430867 Test loss=0.360045 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4077467918395996
[5/24] Train loss=0.4032396972179413
[10/24] Train loss=0.4171186685562134
[15/24] Train loss=0.3866996467113495
[20/24] Train loss=0.3709755837917328
Test set avg_accuracy=86.97% avg_sensitivity=72.56%, avg_specificity=92.46% avg_auc=92.57%
Best model saved!! Metric=18.555967725089985!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.407018 Test loss=0.339945 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.39412641525268555
[5/24] Train loss=0.375550240278244
[10/24] Train loss=0.39656391739845276
[15/24] Train loss=0.3701556622982025
[20/24] Train loss=0.34969544410705566
Test set avg_accuracy=87.25% avg_sensitivity=70.25%, avg_specificity=93.74% avg_auc=92.88%
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.385881 Test loss=0.328922 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.366786926984787
[5/24] Train loss=0.3546489477157593
[10/24] Train loss=0.37863099575042725
[15/24] Train loss=0.3487880527973175
[20/24] Train loss=0.33510154485702515
Test set avg_accuracy=87.54% avg_sensitivity=69.68%, avg_specificity=94.35% avg_auc=93.17%
Best model saved!! Metric=18.744668574445996!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.366577 Test loss=0.318435 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3535279631614685
[5/24] Train loss=0.33900320529937744
[10/24] Train loss=0.36184513568878174
[15/24] Train loss=0.3302004635334015
[20/24] Train loss=0.32109755277633667
Test set avg_accuracy=87.93% avg_sensitivity=70.01%, avg_specificity=94.77% avg_auc=93.68%
Best model saved!! Metric=20.386421693965218!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.350876 Test loss=0.307443 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3404792845249176
[5/24] Train loss=0.3185807168483734
[10/24] Train loss=0.3540562391281128
[15/24] Train loss=0.31464043259620667
[20/24] Train loss=0.30706503987312317
Test set avg_accuracy=88.62% avg_sensitivity=74.68%, avg_specificity=93.94% avg_auc=94.32%
Best model saved!! Metric=25.5628179097736!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.336155 Test loss=0.296755 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3227740228176117
[5/24] Train loss=0.3107697367668152
[10/24] Train loss=0.3379564583301544
[15/24] Train loss=0.31720077991485596
[20/24] Train loss=0.29450544714927673
Test set avg_accuracy=87.98% avg_sensitivity=67.23%, avg_specificity=95.90% avg_auc=94.12%
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.324518 Test loss=0.298771 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3132149577140808
[5/24] Train loss=0.29656749963760376
[10/24] Train loss=0.33136382699012756
[15/24] Train loss=0.30244943499565125
[20/24] Train loss=0.27883243560791016
Test set avg_accuracy=88.76% avg_sensitivity=73.64%, avg_specificity=94.53% avg_auc=94.62%
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.314735 Test loss=0.283749 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3033505976200104
[5/24] Train loss=0.28422820568084717
[10/24] Train loss=0.3172438144683838
[15/24] Train loss=0.2940179109573364
[20/24] Train loss=0.27640262246131897
Test set avg_accuracy=88.55% avg_sensitivity=70.25%, avg_specificity=95.54% avg_auc=94.72%
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.306535 Test loss=0.283007 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.29412123560905457
[5/24] Train loss=0.2786078453063965
[10/24] Train loss=0.31437116861343384
[15/24] Train loss=0.28740376234054565
[20/24] Train loss=0.2669079601764679
Test set avg_accuracy=88.89% avg_sensitivity=72.04%, avg_specificity=95.32% avg_auc=94.77%
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.298558 Test loss=0.276797 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2915128469467163
[5/24] Train loss=0.2706983685493469
[10/24] Train loss=0.30778688192367554
[15/24] Train loss=0.2770678699016571
[20/24] Train loss=0.2623051404953003
Test set avg_accuracy=89.00% avg_sensitivity=73.93%, avg_specificity=94.75% avg_auc=94.99%
Best model saved!! Metric=26.665802609251088!!
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.291213 Test loss=0.269479 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.285308301448822
[5/24] Train loss=0.25666573643684387
[10/24] Train loss=0.3017808496952057
[15/24] Train loss=0.26876258850097656
[20/24] Train loss=0.25533270835876465
Test set avg_accuracy=88.68% avg_sensitivity=70.20%, avg_specificity=95.74% avg_auc=94.80%
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.284757 Test loss=0.272443 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.27826040983200073
[5/24] Train loss=0.25180137157440186
[10/24] Train loss=0.29788774251937866
[15/24] Train loss=0.26776790618896484
[20/24] Train loss=0.24482223391532898
Test set avg_accuracy=89.54% avg_sensitivity=76.76%, avg_specificity=94.42% avg_auc=95.19%
Best model saved!! Metric=29.909159962752028!!
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.278638 Test loss=0.263662 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.27902641892433167
[5/24] Train loss=0.24990785121917725
[10/24] Train loss=0.2839638888835907
[15/24] Train loss=0.2581152021884918
[20/24] Train loss=0.24275250732898712
Test set avg_accuracy=88.78% avg_sensitivity=71.19%, avg_specificity=95.48% avg_auc=94.78%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.273217 Test loss=0.269609 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2694929838180542
[5/24] Train loss=0.2454325556755066
[10/24] Train loss=0.2807537913322449
[15/24] Train loss=0.25474539399147034
[20/24] Train loss=0.23736952245235443
Test set avg_accuracy=88.31% avg_sensitivity=66.95%, avg_specificity=96.46% avg_auc=94.77%
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.269029 Test loss=0.275460 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2607021927833557
[5/24] Train loss=0.2371281087398529
[10/24] Train loss=0.2742132544517517
[15/24] Train loss=0.24574361741542816
[20/24] Train loss=0.2307097166776657
Test set avg_accuracy=88.74% avg_sensitivity=69.68%, avg_specificity=96.01% avg_auc=94.44%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.260838 Test loss=0.275719 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.25724655389785767
[5/24] Train loss=0.22803597152233124
[10/24] Train loss=0.26761335134506226
[15/24] Train loss=0.24286049604415894
[20/24] Train loss=0.22891457378864288
Test set avg_accuracy=88.63% avg_sensitivity=69.97%, avg_specificity=95.75% avg_auc=94.62%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.256319 Test loss=0.270042 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.25964635610580444
[5/24] Train loss=0.22527511417865753
[10/24] Train loss=0.26839762926101685
[15/24] Train loss=0.24133068323135376
[20/24] Train loss=0.22461749613285065
Test set avg_accuracy=86.97% avg_sensitivity=60.07%, avg_specificity=97.23% avg_auc=93.28%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.251710 Test loss=0.310353 Current lr=[0.000210185142098938]

[0/24] Train loss=0.252666175365448
[5/24] Train loss=0.23247990012168884
[10/24] Train loss=0.26147764921188354
[15/24] Train loss=0.23471607267856598
[20/24] Train loss=0.22830350697040558
Test set avg_accuracy=86.03% avg_sensitivity=55.16%, avg_specificity=97.81% avg_auc=93.20%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.248867 Test loss=0.330126 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2419080287218094
[5/24] Train loss=0.2164633423089981
[10/24] Train loss=0.2572491765022278
[15/24] Train loss=0.23634381592273712
[20/24] Train loss=0.22366242110729218
Test set avg_accuracy=88.16% avg_sensitivity=65.72%, avg_specificity=96.73% avg_auc=94.96%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.244714 Test loss=0.275014 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.25226640701293945
[5/24] Train loss=0.21847417950630188
[10/24] Train loss=0.25974032282829285
[15/24] Train loss=0.23472818732261658
[20/24] Train loss=0.21984703838825226
Test set avg_accuracy=84.40% avg_sensitivity=48.47%, avg_specificity=98.11% avg_auc=90.42%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.243800 Test loss=0.379449 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2379029542207718
[5/24] Train loss=0.21215090155601501
[10/24] Train loss=0.25333237648010254
[15/24] Train loss=0.23516137897968292
[20/24] Train loss=0.2197660654783249
Test set avg_accuracy=87.36% avg_sensitivity=61.43%, avg_specificity=97.25% avg_auc=93.84%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.239017 Test loss=0.298452 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2335992455482483
[5/24] Train loss=0.20602701604366302
[10/24] Train loss=0.2501296401023865
[15/24] Train loss=0.2341429442167282
[20/24] Train loss=0.2160763442516327
Test set avg_accuracy=86.58% avg_sensitivity=57.99%, avg_specificity=97.48% avg_auc=92.40%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.235598 Test loss=0.323465 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.23147346079349518
[5/24] Train loss=0.19974590837955475
[10/24] Train loss=0.254177451133728
[15/24] Train loss=0.22285901010036469
[20/24] Train loss=0.21368108689785004
Test set avg_accuracy=88.72% avg_sensitivity=69.68%, avg_specificity=95.99% avg_auc=94.66%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.233679 Test loss=0.268499 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2381640076637268
[5/24] Train loss=0.19644932448863983
[10/24] Train loss=0.25212031602859497
[15/24] Train loss=0.231813445687294
[20/24] Train loss=0.21123363077640533
Test set avg_accuracy=85.62% avg_sensitivity=52.85%, avg_specificity=98.13% avg_auc=91.35%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.229903 Test loss=0.361847 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.23961403965950012
[5/24] Train loss=0.2011936753988266
[10/24] Train loss=0.23848047852516174
[15/24] Train loss=0.21950846910476685
[20/24] Train loss=0.20899246633052826
Test set avg_accuracy=85.57% avg_sensitivity=52.66%, avg_specificity=98.13% avg_auc=92.26%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.229579 Test loss=0.344674 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.22303125262260437
[5/24] Train loss=0.19777968525886536
[10/24] Train loss=0.2386772483587265
[15/24] Train loss=0.21958112716674805
[20/24] Train loss=0.2102891355752945
Test set avg_accuracy=86.13% avg_sensitivity=55.68%, avg_specificity=97.75% avg_auc=92.92%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.224574 Test loss=0.329508 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2203231006860733
[5/24] Train loss=0.18153977394104004
[10/24] Train loss=0.23361140489578247
[15/24] Train loss=0.22459502518177032
[20/24] Train loss=0.21387255191802979
Test set avg_accuracy=87.08% avg_sensitivity=58.79%, avg_specificity=97.88% avg_auc=91.89%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.221555 Test loss=0.331071 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.22512418031692505
[5/24] Train loss=0.19685648381710052
[10/24] Train loss=0.22531959414482117
[15/24] Train loss=0.2176014631986618
[20/24] Train loss=0.2049320638179779
Test set avg_accuracy=87.60% avg_sensitivity=63.46%, avg_specificity=96.82% avg_auc=92.96%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.220561 Test loss=0.308442 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2142055332660675
[5/24] Train loss=0.17437292635440826
[10/24] Train loss=0.24335147440433502
[15/24] Train loss=0.2155689299106598
[20/24] Train loss=0.19904112815856934
Test set avg_accuracy=78.05% avg_sensitivity=21.78%, avg_specificity=99.51% avg_auc=84.10%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.218689 Test loss=0.563519 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2131577581167221
[5/24] Train loss=0.18473921716213226
[10/24] Train loss=0.2243613749742508
[15/24] Train loss=0.21935220062732697
[20/24] Train loss=0.20737199485301971
Test set avg_accuracy=83.37% avg_sensitivity=44.04%, avg_specificity=98.38% avg_auc=89.67%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.217213 Test loss=0.435166 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.21832457184791565
[5/24] Train loss=0.19373156130313873
[10/24] Train loss=0.22328926622867584
[15/24] Train loss=0.21753385663032532
[20/24] Train loss=0.20054900646209717
Test set avg_accuracy=84.78% avg_sensitivity=50.12%, avg_specificity=98.00% avg_auc=90.11%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.216889 Test loss=0.366181 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.22115705907344818
[5/24] Train loss=0.1713120937347412
[10/24] Train loss=0.23708024621009827
[15/24] Train loss=0.21609386801719666
[20/24] Train loss=0.2027478665113449
Test set avg_accuracy=82.94% avg_sensitivity=85.95%, avg_specificity=81.80% avg_auc=92.58%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.218045 Test loss=0.363447 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.21703815460205078
[5/24] Train loss=0.1880284547805786
[10/24] Train loss=0.20915016531944275
[15/24] Train loss=0.2296896129846573
[20/24] Train loss=0.19797445833683014
Test set avg_accuracy=88.68% avg_sensitivity=73.60%, avg_specificity=94.44% avg_auc=93.74%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.215403 Test loss=0.279766 Current lr=[0.00029967723776099]

[0/24] Train loss=0.20839571952819824
[5/24] Train loss=0.18262842297554016
[10/24] Train loss=0.21853618323802948
[15/24] Train loss=0.22621740400791168
[20/24] Train loss=0.1909734159708023
Test set avg_accuracy=87.43% avg_sensitivity=66.71%, avg_specificity=95.34% avg_auc=93.20%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.207123 Test loss=0.296072 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.20191705226898193
[5/24] Train loss=0.17016255855560303
[10/24] Train loss=0.21032804250717163
[15/24] Train loss=0.22012390196323395
[20/24] Train loss=0.20169629156589508
Test set avg_accuracy=87.75% avg_sensitivity=65.11%, avg_specificity=96.38% avg_auc=92.47%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.211275 Test loss=0.304758 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.22051754593849182
[5/24] Train loss=0.1795370876789093
[10/24] Train loss=0.22579032182693481
[15/24] Train loss=0.21445173025131226
[20/24] Train loss=0.1972827911376953
Test set avg_accuracy=84.38% avg_sensitivity=47.15%, avg_specificity=98.58% avg_auc=90.83%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.214297 Test loss=0.398843 Current lr=[0.000299720220882401]

[0/24] Train loss=0.20127242803573608
[5/24] Train loss=0.16999435424804688
[10/24] Train loss=0.21816572546958923
[15/24] Train loss=0.21107977628707886
[20/24] Train loss=0.1955009400844574
Test set avg_accuracy=87.90% avg_sensitivity=64.31%, avg_specificity=96.91% avg_auc=93.62%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.206703 Test loss=0.303401 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19873833656311035
[5/24] Train loss=0.171851247549057
[10/24] Train loss=0.20409339666366577
[15/24] Train loss=0.20629948377609253
[20/24] Train loss=0.19115343689918518
Test set avg_accuracy=88.63% avg_sensitivity=72.75%, avg_specificity=94.69% avg_auc=94.24%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.203615 Test loss=0.271244 Current lr=[0.000298904600941902]

[0/24] Train loss=0.20239436626434326
[5/24] Train loss=0.16124039888381958
[10/24] Train loss=0.20499901473522186
[15/24] Train loss=0.21194367110729218
[20/24] Train loss=0.1966746747493744
Test set avg_accuracy=87.71% avg_sensitivity=79.30%, avg_specificity=90.92% avg_auc=93.95%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.199574 Test loss=0.285158 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.19903035461902618
[5/24] Train loss=0.1709831953048706
[10/24] Train loss=0.20393666625022888
[15/24] Train loss=0.21820767223834991
[20/24] Train loss=0.1939542144536972
Test set avg_accuracy=86.63% avg_sensitivity=59.22%, avg_specificity=97.09% avg_auc=92.92%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.204106 Test loss=0.321277 Current lr=[0.000297555943323901]

[0/24] Train loss=0.20776695013046265
[5/24] Train loss=0.1809672713279724
[10/24] Train loss=0.21010181307792664
[15/24] Train loss=0.21181944012641907
[20/24] Train loss=0.19573622941970825
Test set avg_accuracy=89.13% avg_sensitivity=76.43%, avg_specificity=93.97% avg_auc=94.86%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.204688 Test loss=0.261944 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.19890862703323364
[5/24] Train loss=0.16499656438827515
[10/24] Train loss=0.21010726690292358
[15/24] Train loss=0.2052551507949829
[20/24] Train loss=0.19417038559913635
Test set avg_accuracy=88.12% avg_sensitivity=75.06%, avg_specificity=93.11% avg_auc=94.26%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.198262 Test loss=0.272830 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.18981294333934784
[5/24] Train loss=0.17084698379039764
[10/24] Train loss=0.19709782302379608
[15/24] Train loss=0.22024820744991302
[20/24] Train loss=0.18780197203159332
Test set avg_accuracy=87.21% avg_sensitivity=82.04%, avg_specificity=89.19% avg_auc=94.32%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.200649 Test loss=0.285068 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.19706876575946808
[5/24] Train loss=0.15873833000659943
[10/24] Train loss=0.20272210240364075
[15/24] Train loss=0.21659165620803833
[20/24] Train loss=0.19422413408756256
Test set avg_accuracy=86.95% avg_sensitivity=61.20%, avg_specificity=96.78% avg_auc=92.26%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.201435 Test loss=0.318358 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.19534851610660553
[5/24] Train loss=0.15673524141311646
[10/24] Train loss=0.1953464299440384
[15/24] Train loss=0.20977310836315155
[20/24] Train loss=0.20009225606918335
Test set avg_accuracy=81.47% avg_sensitivity=88.68%, avg_specificity=78.72% avg_auc=91.99%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.194377 Test loss=0.404860 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.19005511701107025
[5/24] Train loss=0.16498172283172607
[10/24] Train loss=0.19484843313694
[15/24] Train loss=0.201904758810997
[20/24] Train loss=0.17579710483551025
Test set avg_accuracy=87.80% avg_sensitivity=64.92%, avg_specificity=96.53% avg_auc=92.33%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.191561 Test loss=0.312740 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.19239014387130737
[5/24] Train loss=0.15556228160858154
[10/24] Train loss=0.20681314170360565
[15/24] Train loss=0.1941542625427246
[20/24] Train loss=0.17760461568832397
Test set avg_accuracy=89.24% avg_sensitivity=75.67%, avg_specificity=94.42% avg_auc=95.00%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.191036 Test loss=0.259934 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.1935957670211792
[5/24] Train loss=0.1645868718624115
[10/24] Train loss=0.1966308057308197
[15/24] Train loss=0.19523631036281586
[20/24] Train loss=0.18601228296756744
Test set avg_accuracy=88.01% avg_sensitivity=68.22%, avg_specificity=95.56% avg_auc=92.58%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.189679 Test loss=0.294216 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18582764267921448
[5/24] Train loss=0.16748902201652527
[10/24] Train loss=0.19923649728298187
[15/24] Train loss=0.2066693753004074
[20/24] Train loss=0.18156926333904266
Test set avg_accuracy=88.16% avg_sensitivity=72.61%, avg_specificity=94.10% avg_auc=93.14%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.192863 Test loss=0.286016 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.18155509233474731
[5/24] Train loss=0.1654115468263626
[10/24] Train loss=0.18561331927776337
[15/24] Train loss=0.19406798481941223
[20/24] Train loss=0.18203717470169067
Test set avg_accuracy=88.27% avg_sensitivity=83.17%, avg_specificity=90.21% avg_auc=94.62%
Best model saved!! Metric=30.273652791289564!!
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.187553 Test loss=0.274338 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.18015918135643005
[5/24] Train loss=0.16170088946819305
[10/24] Train loss=0.19485129415988922
[15/24] Train loss=0.2014918476343155
[20/24] Train loss=0.1731906682252884
Test set avg_accuracy=88.40% avg_sensitivity=74.68%, avg_specificity=93.63% avg_auc=94.23%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.184677 Test loss=0.273265 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.17796847224235535
[5/24] Train loss=0.1488914042711258
[10/24] Train loss=0.18983674049377441
[15/24] Train loss=0.19799859821796417
[20/24] Train loss=0.17596660554409027
Test set avg_accuracy=88.58% avg_sensitivity=71.90%, avg_specificity=94.95% avg_auc=93.90%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.182090 Test loss=0.278370 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.1701240986585617
[5/24] Train loss=0.1545896679162979
[10/24] Train loss=0.19802385568618774
[15/24] Train loss=0.20220710337162018
[20/24] Train loss=0.1795879453420639
Test set avg_accuracy=88.23% avg_sensitivity=68.93%, avg_specificity=95.59% avg_auc=92.95%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.187855 Test loss=0.295655 Current lr=[0.000276307469034998]

[0/24] Train loss=0.1800212562084198
[5/24] Train loss=0.15765200555324554
[10/24] Train loss=0.18818524479866028
[15/24] Train loss=0.193288654088974
[20/24] Train loss=0.18550245463848114
Test set avg_accuracy=89.08% avg_sensitivity=80.91%, avg_specificity=92.19% avg_auc=94.74%
Best model saved!! Metric=30.91267537601756!!
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.185006 Test loss=0.267491 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.18046660721302032
[5/24] Train loss=0.1488420069217682
[10/24] Train loss=0.19565965235233307
[15/24] Train loss=0.18199992179870605
[20/24] Train loss=0.17706795036792755
Test set avg_accuracy=88.35% avg_sensitivity=80.53%, avg_specificity=91.33% avg_auc=94.43%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.183781 Test loss=0.273366 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.1873144507408142
[5/24] Train loss=0.15320195257663727
[10/24] Train loss=0.18249468505382538
[15/24] Train loss=0.18052813410758972
[20/24] Train loss=0.18278586864471436
Test set avg_accuracy=88.27% avg_sensitivity=70.49%, avg_specificity=95.05% avg_auc=93.58%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.181610 Test loss=0.285467 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.18452590703964233
[5/24] Train loss=0.1534046232700348
[10/24] Train loss=0.19469089806079865
[15/24] Train loss=0.1916511058807373
[20/24] Train loss=0.17893218994140625
Test set avg_accuracy=88.76% avg_sensitivity=75.77%, avg_specificity=93.72% avg_auc=93.76%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.185401 Test loss=0.277059 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.18581944704055786
[5/24] Train loss=0.1508629024028778
[10/24] Train loss=0.19653798639774323
[15/24] Train loss=0.19758981466293335
[20/24] Train loss=0.1694551557302475
Test set avg_accuracy=86.63% avg_sensitivity=80.20%, avg_specificity=89.08% avg_auc=92.68%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.188850 Test loss=0.319362 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.18455252051353455
[5/24] Train loss=0.15406949818134308
[10/24] Train loss=0.17970634996891022
[15/24] Train loss=0.1865004003047943
[20/24] Train loss=0.18362094461917877
Test set avg_accuracy=86.13% avg_sensitivity=56.72%, avg_specificity=97.36% avg_auc=88.68%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.181075 Test loss=0.372281 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.18768779933452606
[5/24] Train loss=0.1455049365758896
[10/24] Train loss=0.18508708477020264
[15/24] Train loss=0.18944574892520905
[20/24] Train loss=0.18185903131961823
Test set avg_accuracy=86.04% avg_sensitivity=60.02%, avg_specificity=95.97% avg_auc=89.57%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.184844 Test loss=0.355811 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.18504628539085388
[5/24] Train loss=0.14744289219379425
[10/24] Train loss=0.18431690335273743
[15/24] Train loss=0.18050257861614227
[20/24] Train loss=0.1702984869480133
Test set avg_accuracy=85.36% avg_sensitivity=53.98%, avg_specificity=97.34% avg_auc=90.00%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.179261 Test loss=0.361995 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.1906977742910385
[5/24] Train loss=0.14739304780960083
[10/24] Train loss=0.18457947671413422
[15/24] Train loss=0.18817174434661865
[20/24] Train loss=0.17746073007583618
Test set avg_accuracy=85.25% avg_sensitivity=51.86%, avg_specificity=97.99% avg_auc=86.63%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.178386 Test loss=0.417820 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.176957905292511
[5/24] Train loss=0.1650657057762146
[10/24] Train loss=0.1859593242406845
[15/24] Train loss=0.182607501745224
[20/24] Train loss=0.17011819779872894
Test set avg_accuracy=82.58% avg_sensitivity=40.92%, avg_specificity=98.47% avg_auc=83.49%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.178544 Test loss=0.486128 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.17691349983215332
[5/24] Train loss=0.1521366834640503
[10/24] Train loss=0.1869225949048996
[15/24] Train loss=0.18136268854141235
[20/24] Train loss=0.17755703628063202
Test set avg_accuracy=88.01% avg_sensitivity=69.40%, avg_specificity=95.11% avg_auc=92.56%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.178424 Test loss=0.297287 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.18014441430568695
[5/24] Train loss=0.15342220664024353
[10/24] Train loss=0.18269036710262299
[15/24] Train loss=0.1807812750339508
[20/24] Train loss=0.16503646969795227
Test set avg_accuracy=86.56% avg_sensitivity=61.34%, avg_specificity=96.19% avg_auc=89.48%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.176236 Test loss=0.342930 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.17810207605361938
[5/24] Train loss=0.1550387144088745
[10/24] Train loss=0.1843901425600052
[15/24] Train loss=0.1782682090997696
[20/24] Train loss=0.17709510028362274
Test set avg_accuracy=82.40% avg_sensitivity=41.02%, avg_specificity=98.18% avg_auc=81.42%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.179224 Test loss=0.455179 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.18387988209724426
[5/24] Train loss=0.15276296436786652
[10/24] Train loss=0.17781874537467957
[15/24] Train loss=0.18714913725852966
[20/24] Train loss=0.16682954132556915
Test set avg_accuracy=87.62% avg_sensitivity=64.07%, avg_specificity=96.60% avg_auc=91.55%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.177101 Test loss=0.321652 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.16776596009731293
[5/24] Train loss=0.14290323853492737
[10/24] Train loss=0.17424751818180084
[15/24] Train loss=0.1818874627351761
[20/24] Train loss=0.1642986387014389
Test set avg_accuracy=86.74% avg_sensitivity=58.37%, avg_specificity=97.57% avg_auc=89.71%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.170393 Test loss=0.355058 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.16895167529582977
[5/24] Train loss=0.14232245087623596
[10/24] Train loss=0.17916543781757355
[15/24] Train loss=0.1767657846212387
[20/24] Train loss=0.1645018607378006
Test set avg_accuracy=85.48% avg_sensitivity=56.25%, avg_specificity=96.64% avg_auc=88.57%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.169121 Test loss=0.387985 Current lr=[0.000224838296036774]

[0/24] Train loss=0.17193756997585297
[5/24] Train loss=0.14936742186546326
[10/24] Train loss=0.17288728058338165
[15/24] Train loss=0.1690930426120758
[20/24] Train loss=0.17616455256938934
Test set avg_accuracy=88.14% avg_sensitivity=69.59%, avg_specificity=95.21% avg_auc=91.54%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.168055 Test loss=0.312451 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.17154812812805176
[5/24] Train loss=0.14143699407577515
[10/24] Train loss=0.17378318309783936
[15/24] Train loss=0.16806472837924957
[20/24] Train loss=0.15799231827259064
Test set avg_accuracy=87.28% avg_sensitivity=65.87%, avg_specificity=95.45% avg_auc=91.51%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.165104 Test loss=0.315473 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.17866478860378265
[5/24] Train loss=0.14625629782676697
[10/24] Train loss=0.16214199364185333
[15/24] Train loss=0.1670047491788864
[20/24] Train loss=0.16037814319133759
Test set avg_accuracy=86.56% avg_sensitivity=58.79%, avg_specificity=97.16% avg_auc=89.40%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.166920 Test loss=0.364444 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1631726622581482
[5/24] Train loss=0.14090660214424133
[10/24] Train loss=0.17248240113258362
[15/24] Train loss=0.16967082023620605
[20/24] Train loss=0.1590050607919693
Test set avg_accuracy=87.97% avg_sensitivity=68.22%, avg_specificity=95.50% avg_auc=92.02%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.165174 Test loss=0.307155 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.16157199442386627
[5/24] Train loss=0.13389292359352112
[10/24] Train loss=0.16362130641937256
[15/24] Train loss=0.15616777539253235
[20/24] Train loss=0.15880361199378967
Test set avg_accuracy=87.17% avg_sensitivity=63.51%, avg_specificity=96.20% avg_auc=90.62%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.162997 Test loss=0.329748 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.16183218359947205
[5/24] Train loss=0.13849611580371857
[10/24] Train loss=0.17083072662353516
[15/24] Train loss=0.15751667320728302
[20/24] Train loss=0.16093358397483826
Test set avg_accuracy=87.58% avg_sensitivity=75.62%, avg_specificity=92.14% avg_auc=92.26%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.162052 Test loss=0.305702 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.16687718033790588
[5/24] Train loss=0.13652080297470093
[10/24] Train loss=0.16792838275432587
[15/24] Train loss=0.1584496647119522
[20/24] Train loss=0.16166366636753082
Test set avg_accuracy=85.57% avg_sensitivity=54.60%, avg_specificity=97.39% avg_auc=89.46%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.165247 Test loss=0.385942 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.16732248663902283
[5/24] Train loss=0.14164192974567413
[10/24] Train loss=0.1679481863975525
[15/24] Train loss=0.16788142919540405
[20/24] Train loss=0.15799455344676971
Test set avg_accuracy=86.73% avg_sensitivity=81.90%, avg_specificity=88.58% avg_auc=93.58%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.161988 Test loss=0.302480 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1607706993818283
[5/24] Train loss=0.13718345761299133
[10/24] Train loss=0.16253508627414703
[15/24] Train loss=0.17346875369548798
[20/24] Train loss=0.15554960072040558
Test set avg_accuracy=87.93% avg_sensitivity=67.75%, avg_specificity=95.63% avg_auc=92.52%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.160693 Test loss=0.305216 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.16230833530426025
[5/24] Train loss=0.13796532154083252
[10/24] Train loss=0.1569223552942276
[15/24] Train loss=0.1560351699590683
[20/24] Train loss=0.15385690331459045
Test set avg_accuracy=88.85% avg_sensitivity=75.25%, avg_specificity=94.05% avg_auc=93.15%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.160385 Test loss=0.281168 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.16156326234340668
[5/24] Train loss=0.14967744052410126
[10/24] Train loss=0.1648922711610794
[15/24] Train loss=0.16280780732631683
[20/24] Train loss=0.14876201748847961
Test set avg_accuracy=88.93% avg_sensitivity=72.14%, avg_specificity=95.34% avg_auc=93.43%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.159360 Test loss=0.282259 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.15814556181430817
[5/24] Train loss=0.1329764425754547
[10/24] Train loss=0.16344375908374786
[15/24] Train loss=0.1527366042137146
[20/24] Train loss=0.1490374207496643
Test set avg_accuracy=88.87% avg_sensitivity=72.14%, avg_specificity=95.25% avg_auc=93.66%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.157195 Test loss=0.278689 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.16705717146396637
[5/24] Train loss=0.1344558745622635
[10/24] Train loss=0.15850889682769775
[15/24] Train loss=0.1580769270658493
[20/24] Train loss=0.15486063063144684
Test set avg_accuracy=88.09% avg_sensitivity=67.14%, avg_specificity=96.08% avg_auc=90.67%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.155214 Test loss=0.325846 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15861715376377106
[5/24] Train loss=0.13783934712409973
[10/24] Train loss=0.1467621922492981
[15/24] Train loss=0.15126970410346985
[20/24] Train loss=0.14927704632282257
Test set avg_accuracy=87.71% avg_sensitivity=64.73%, avg_specificity=96.47% avg_auc=91.80%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.152353 Test loss=0.320851 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.14996087551116943
[5/24] Train loss=0.13228566944599152
[10/24] Train loss=0.1533895581960678
[15/24] Train loss=0.15155687928199768
[20/24] Train loss=0.14301654696464539
Test set avg_accuracy=87.02% avg_sensitivity=60.40%, avg_specificity=97.18% avg_auc=88.90%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.151084 Test loss=0.352939 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15740802884101868
[5/24] Train loss=0.13023161888122559
[10/24] Train loss=0.15384510159492493
[15/24] Train loss=0.145675390958786
[20/24] Train loss=0.14216136932373047
Test set avg_accuracy=88.41% avg_sensitivity=68.13%, avg_specificity=96.15% avg_auc=91.62%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.148935 Test loss=0.310923 Current lr=[0.000156543481933168]

[0/24] Train loss=0.1487409919500351
[5/24] Train loss=0.13073012232780457
[10/24] Train loss=0.14997245371341705
[15/24] Train loss=0.13970911502838135
[20/24] Train loss=0.14364682137966156
Test set avg_accuracy=89.06% avg_sensitivity=75.81%, avg_specificity=94.12% avg_auc=94.20%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.147762 Test loss=0.267903 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.14649365842342377
[5/24] Train loss=0.12597614526748657
[10/24] Train loss=0.15589000284671783
[15/24] Train loss=0.1414726823568344
[20/24] Train loss=0.146234393119812
Test set avg_accuracy=88.79% avg_sensitivity=73.55%, avg_specificity=94.60% avg_auc=92.90%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.147523 Test loss=0.288310 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.1530374437570572
[5/24] Train loss=0.1300448775291443
[10/24] Train loss=0.1466732919216156
[15/24] Train loss=0.13987323641777039
[20/24] Train loss=0.14522810280323029
Test set avg_accuracy=85.36% avg_sensitivity=52.19%, avg_specificity=98.02% avg_auc=86.42%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.146277 Test loss=0.388915 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.1582217961549759
[5/24] Train loss=0.12848226726055145
[10/24] Train loss=0.15540358424186707
[15/24] Train loss=0.13938535749912262
[20/24] Train loss=0.1445963829755783
Test set avg_accuracy=89.10% avg_sensitivity=71.24%, avg_specificity=95.92% avg_auc=93.22%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.148674 Test loss=0.288915 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15037193894386292
[5/24] Train loss=0.12496215850114822
[10/24] Train loss=0.14900963008403778
[15/24] Train loss=0.14163857698440552
[20/24] Train loss=0.14138749241828918
Test set avg_accuracy=88.01% avg_sensitivity=65.68%, avg_specificity=96.53% avg_auc=91.22%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.146421 Test loss=0.309936 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15172730386257172
[5/24] Train loss=0.1298743188381195
[10/24] Train loss=0.14733034372329712
[15/24] Train loss=0.14339151978492737
[20/24] Train loss=0.14166606962680817
Test set avg_accuracy=88.80% avg_sensitivity=70.44%, avg_specificity=95.81% avg_auc=93.03%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.146485 Test loss=0.288363 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1471647173166275
[5/24] Train loss=0.13165588676929474
[10/24] Train loss=0.147131085395813
[15/24] Train loss=0.14489862322807312
[20/24] Train loss=0.1400122344493866
Test set avg_accuracy=88.59% avg_sensitivity=71.15%, avg_specificity=95.25% avg_auc=92.37%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.147256 Test loss=0.298544 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.14532117545604706
[5/24] Train loss=0.12713830173015594
[10/24] Train loss=0.14473934471607208
[15/24] Train loss=0.14070279896259308
[20/24] Train loss=0.14430193603038788
Test set avg_accuracy=88.55% avg_sensitivity=75.29%, avg_specificity=93.61% avg_auc=93.06%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.145409 Test loss=0.286766 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.14518801867961884
[5/24] Train loss=0.1313311755657196
[10/24] Train loss=0.14711980521678925
[15/24] Train loss=0.13579463958740234
[20/24] Train loss=0.14582151174545288
Test set avg_accuracy=87.97% avg_sensitivity=65.72%, avg_specificity=96.46% avg_auc=91.55%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.146999 Test loss=0.317283 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1471254676580429
[5/24] Train loss=0.12208037823438644
[10/24] Train loss=0.1392882764339447
[15/24] Train loss=0.13903862237930298
[20/24] Train loss=0.14682357013225555
Test set avg_accuracy=88.82% avg_sensitivity=74.96%, avg_specificity=94.10% avg_auc=93.84%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.146480 Test loss=0.277038 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14933966100215912
[5/24] Train loss=0.12520310282707214
[10/24] Train loss=0.13818243145942688
[15/24] Train loss=0.13441486656665802
[20/24] Train loss=0.1397424340248108
Test set avg_accuracy=88.68% avg_sensitivity=71.05%, avg_specificity=95.41% avg_auc=92.38%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.141891 Test loss=0.295497 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.14291493594646454
[5/24] Train loss=0.12334837019443512
[10/24] Train loss=0.1444542557001114
[15/24] Train loss=0.1423766016960144
[20/24] Train loss=0.14251954853534698
Test set avg_accuracy=89.22% avg_sensitivity=76.00%, avg_specificity=94.26% avg_auc=94.37%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.141462 Test loss=0.269283 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.14359919726848602
[5/24] Train loss=0.128431037068367
[10/24] Train loss=0.1388653814792633
[15/24] Train loss=0.13604116439819336
[20/24] Train loss=0.1403529942035675
Test set avg_accuracy=88.93% avg_sensitivity=71.95%, avg_specificity=95.41% avg_auc=93.01%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.142456 Test loss=0.288884 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14328904449939728
[5/24] Train loss=0.1257060021162033
[10/24] Train loss=0.14042127132415771
[15/24] Train loss=0.13812825083732605
[20/24] Train loss=0.13794958591461182
Test set avg_accuracy=89.00% avg_sensitivity=74.02%, avg_specificity=94.71% avg_auc=93.30%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.140867 Test loss=0.282671 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14108054339885712
[5/24] Train loss=0.12600158154964447
[10/24] Train loss=0.13598203659057617
[15/24] Train loss=0.13754208385944366
[20/24] Train loss=0.14435189962387085
Test set avg_accuracy=89.34% avg_sensitivity=74.40%, avg_specificity=95.04% avg_auc=93.84%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.141042 Test loss=0.275462 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.14243419468402863
[5/24] Train loss=0.12193522602319717
[10/24] Train loss=0.13709647953510284
[15/24] Train loss=0.1317359358072281
[20/24] Train loss=0.13744550943374634
Test set avg_accuracy=88.93% avg_sensitivity=77.84%, avg_specificity=93.16% avg_auc=93.84%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.139116 Test loss=0.280262 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1394997090101242
[5/24] Train loss=0.12481428682804108
[10/24] Train loss=0.13537119328975677
[15/24] Train loss=0.12736716866493225
[20/24] Train loss=0.13936959207057953
Test set avg_accuracy=89.05% avg_sensitivity=73.08%, avg_specificity=95.14% avg_auc=93.29%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.139195 Test loss=0.285173 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14070889353752136
[5/24] Train loss=0.12415187060832977
[10/24] Train loss=0.13758042454719543
[15/24] Train loss=0.12790141999721527
[20/24] Train loss=0.1373327523469925
Test set avg_accuracy=88.82% avg_sensitivity=72.28%, avg_specificity=95.13% avg_auc=93.15%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.138686 Test loss=0.289645 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14067037403583527
[5/24] Train loss=0.12527787685394287
[10/24] Train loss=0.1350487470626831
[15/24] Train loss=0.13036271929740906
[20/24] Train loss=0.1347581297159195
Test set avg_accuracy=89.14% avg_sensitivity=80.25%, avg_specificity=92.53% avg_auc=94.52%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.138314 Test loss=0.269837 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14013011753559113
[5/24] Train loss=0.1198342815041542
[10/24] Train loss=0.13688364624977112
[15/24] Train loss=0.13043297827243805
[20/24] Train loss=0.1355486959218979
Test set avg_accuracy=88.48% avg_sensitivity=71.05%, avg_specificity=95.13% avg_auc=93.23%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.136748 Test loss=0.290906 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14234499633312225
[5/24] Train loss=0.1168922707438469
[10/24] Train loss=0.13491731882095337
[15/24] Train loss=0.12567439675331116
[20/24] Train loss=0.13202685117721558
Test set avg_accuracy=88.14% avg_sensitivity=73.74%, avg_specificity=93.63% avg_auc=92.35%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.133937 Test loss=0.296817 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.13653990626335144
[5/24] Train loss=0.11465157568454742
[10/24] Train loss=0.12702135741710663
[15/24] Train loss=0.1248680055141449
[20/24] Train loss=0.13133302330970764
Test set avg_accuracy=88.75% avg_sensitivity=71.90%, avg_specificity=95.18% avg_auc=92.84%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.131257 Test loss=0.293670 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13610106706619263
[5/24] Train loss=0.11526020616292953
[10/24] Train loss=0.1288796365261078
[15/24] Train loss=0.12655805051326752
[20/24] Train loss=0.13007467985153198
Test set avg_accuracy=88.57% avg_sensitivity=72.80%, avg_specificity=94.59% avg_auc=92.24%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.130364 Test loss=0.296244 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13161928951740265
[5/24] Train loss=0.11730179935693741
[10/24] Train loss=0.12514634430408478
[15/24] Train loss=0.12511752545833588
[20/24] Train loss=0.12525661289691925
Test set avg_accuracy=88.89% avg_sensitivity=76.52%, avg_specificity=93.61% avg_auc=93.99%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.129863 Test loss=0.277392 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1327628493309021
[5/24] Train loss=0.11381073296070099
[10/24] Train loss=0.12592823803424835
[15/24] Train loss=0.12160678207874298
[20/24] Train loss=0.13021135330200195
Test set avg_accuracy=88.76% avg_sensitivity=73.55%, avg_specificity=94.57% avg_auc=93.67%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.129674 Test loss=0.280170 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1326199620962143
[5/24] Train loss=0.11405167728662491
[10/24] Train loss=0.12499872595071793
[15/24] Train loss=0.1208273321390152
[20/24] Train loss=0.13035932183265686
Test set avg_accuracy=89.24% avg_sensitivity=77.23%, avg_specificity=93.83% avg_auc=94.21%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.128473 Test loss=0.270108 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.12932869791984558
[5/24] Train loss=0.11246450990438461
[10/24] Train loss=0.1249418631196022
[15/24] Train loss=0.12120894342660904
[20/24] Train loss=0.12858836352825165
Test set avg_accuracy=89.05% avg_sensitivity=73.27%, avg_specificity=95.07% avg_auc=93.12%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.127801 Test loss=0.287905 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12967224419116974
[5/24] Train loss=0.11266303807497025
[10/24] Train loss=0.12729236483573914
[15/24] Train loss=0.11840919405221939
[20/24] Train loss=0.1273912638425827
Test set avg_accuracy=88.75% avg_sensitivity=75.95%, avg_specificity=93.63% avg_auc=93.19%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.127240 Test loss=0.284678 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1316230446100235
[5/24] Train loss=0.11107923835515976
[10/24] Train loss=0.12535981833934784
[15/24] Train loss=0.11968902498483658
[20/24] Train loss=0.12492886185646057
Test set avg_accuracy=89.14% avg_sensitivity=77.51%, avg_specificity=93.58% avg_auc=93.93%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.127432 Test loss=0.277326 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1289592683315277
[5/24] Train loss=0.11161240190267563
[10/24] Train loss=0.12559357285499573
[15/24] Train loss=0.11907272785902023
[20/24] Train loss=0.1260983943939209
Test set avg_accuracy=88.48% avg_sensitivity=70.49%, avg_specificity=95.34% avg_auc=92.64%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.126337 Test loss=0.301954 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1307452768087387
[5/24] Train loss=0.11230958998203278
[10/24] Train loss=0.12334656715393066
[15/24] Train loss=0.11964825540781021
[20/24] Train loss=0.12626874446868896
Test set avg_accuracy=88.45% avg_sensitivity=74.35%, avg_specificity=93.83% avg_auc=93.13%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.126172 Test loss=0.289535 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12930071353912354
[5/24] Train loss=0.11136186867952347
[10/24] Train loss=0.12091363966464996
[15/24] Train loss=0.11987461149692535
[20/24] Train loss=0.125641867518425
Test set avg_accuracy=88.88% avg_sensitivity=76.14%, avg_specificity=93.74% avg_auc=93.34%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.125828 Test loss=0.282606 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1284104883670807
[5/24] Train loss=0.11330608278512955
[10/24] Train loss=0.1217576116323471
[15/24] Train loss=0.12330077588558197
[20/24] Train loss=0.1238468736410141
Test set avg_accuracy=88.98% avg_sensitivity=73.97%, avg_specificity=94.71% avg_auc=93.54%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.125578 Test loss=0.281969 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12811283767223358
[5/24] Train loss=0.11118592321872711
[10/24] Train loss=0.11866086721420288
[15/24] Train loss=0.12057343125343323
[20/24] Train loss=0.12846994400024414
Test set avg_accuracy=89.05% avg_sensitivity=77.23%, avg_specificity=93.56% avg_auc=93.51%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.126036 Test loss=0.281407 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12672238051891327
[5/24] Train loss=0.11566983163356781
[10/24] Train loss=0.12234416604042053
[15/24] Train loss=0.1190253496170044
[20/24] Train loss=0.12571007013320923
Test set avg_accuracy=89.21% avg_sensitivity=79.35%, avg_specificity=92.97% avg_auc=94.00%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.126091 Test loss=0.276365 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12639197707176208
[5/24] Train loss=0.11157583445310593
[10/24] Train loss=0.12352639436721802
[15/24] Train loss=0.11565177142620087
[20/24] Train loss=0.12818840146064758
Test set avg_accuracy=88.91% avg_sensitivity=77.89%, avg_specificity=93.11% avg_auc=93.93%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.125675 Test loss=0.277328 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12636886537075043
[5/24] Train loss=0.11142513900995255
[10/24] Train loss=0.12350401282310486
[15/24] Train loss=0.11403854936361313
[20/24] Train loss=0.12388978898525238
Test set avg_accuracy=89.47% avg_sensitivity=75.29%, avg_specificity=94.87% avg_auc=93.40%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.124278 Test loss=0.281374 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1281018704175949
[5/24] Train loss=0.10986004769802094
[10/24] Train loss=0.1197328120470047
[15/24] Train loss=0.11973477154970169
[20/24] Train loss=0.1219155341386795
Test set avg_accuracy=89.44% avg_sensitivity=77.13%, avg_specificity=94.14% avg_auc=94.07%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.123255 Test loss=0.271314 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1247531920671463
[5/24] Train loss=0.10882705450057983
[10/24] Train loss=0.11788645386695862
[15/24] Train loss=0.11451239138841629
[20/24] Train loss=0.12113713473081589
Test set avg_accuracy=89.44% avg_sensitivity=77.79%, avg_specificity=93.88% avg_auc=94.15%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.122269 Test loss=0.272369 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12225420027971268
[5/24] Train loss=0.10936084389686584
[10/24] Train loss=0.1178826093673706
[15/24] Train loss=0.11554749310016632
[20/24] Train loss=0.1227496862411499
Test set avg_accuracy=89.45% avg_sensitivity=76.43%, avg_specificity=94.42% avg_auc=93.90%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.121850 Test loss=0.275992 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12301415205001831
[5/24] Train loss=0.10940644145011902
[10/24] Train loss=0.11907954514026642
[15/24] Train loss=0.11541791260242462
[20/24] Train loss=0.11993943154811859
Test set avg_accuracy=89.43% avg_sensitivity=74.82%, avg_specificity=95.00% avg_auc=93.76%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.121140 Test loss=0.278163 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12180464714765549
[5/24] Train loss=0.10954423248767853
[10/24] Train loss=0.11667033284902573
[15/24] Train loss=0.1148541048169136
[20/24] Train loss=0.12175110727548599
Test set avg_accuracy=89.41% avg_sensitivity=76.52%, avg_specificity=94.33% avg_auc=93.77%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.120913 Test loss=0.277633 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12075973302125931
[5/24] Train loss=0.10758823156356812
[10/24] Train loss=0.1184837818145752
[15/24] Train loss=0.11430443823337555
[20/24] Train loss=0.119597427546978
Test set avg_accuracy=89.38% avg_sensitivity=76.19%, avg_specificity=94.41% avg_auc=94.01%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.120419 Test loss=0.274933 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1222928911447525
[5/24] Train loss=0.10701163858175278
[10/24] Train loss=0.11819471418857574
[15/24] Train loss=0.11425745487213135
[20/24] Train loss=0.12044158577919006
Test set avg_accuracy=89.43% avg_sensitivity=76.10%, avg_specificity=94.51% avg_auc=93.64%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.120348 Test loss=0.278435 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12309801578521729
[5/24] Train loss=0.1100647896528244
[10/24] Train loss=0.12129556387662888
[15/24] Train loss=0.11574780941009521
[20/24] Train loss=0.12153276801109314
Test set avg_accuracy=89.38% avg_sensitivity=76.90%, avg_specificity=94.14% avg_auc=93.91%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.120524 Test loss=0.275672 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.11885792762041092
[5/24] Train loss=0.10704749077558517
[10/24] Train loss=0.11757248640060425
[15/24] Train loss=0.11245935410261154
[20/24] Train loss=0.11945607513189316
Test set avg_accuracy=89.41% avg_sensitivity=76.38%, avg_specificity=94.39% avg_auc=93.81%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.119728 Test loss=0.277660 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12158694863319397
[5/24] Train loss=0.10821016877889633
[10/24] Train loss=0.11671239882707596
[15/24] Train loss=0.11359194666147232
[20/24] Train loss=0.11885952949523926
Test set avg_accuracy=89.36% avg_sensitivity=77.18%, avg_specificity=94.01% avg_auc=94.00%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.119492 Test loss=0.274624 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12068980932235718
[5/24] Train loss=0.1073467805981636
[10/24] Train loss=0.11640467494726181
[15/24] Train loss=0.11361747235059738
[20/24] Train loss=0.11778588593006134
Test set avg_accuracy=89.40% avg_sensitivity=76.71%, avg_specificity=94.24% avg_auc=93.91%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.119141 Test loss=0.275716 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12092641741037369
[5/24] Train loss=0.10730268806219101
[10/24] Train loss=0.11657915264368057
[15/24] Train loss=0.11190160363912582
[20/24] Train loss=0.11826349049806595
Test set avg_accuracy=89.47% avg_sensitivity=76.33%, avg_specificity=94.48% avg_auc=93.88%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.119416 Test loss=0.276276 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12104961276054382
[5/24] Train loss=0.1077820435166359
[10/24] Train loss=0.11723246425390244
[15/24] Train loss=0.11380535364151001
[20/24] Train loss=0.12096323072910309
Test set avg_accuracy=89.30% avg_sensitivity=76.38%, avg_specificity=94.23% avg_auc=93.89%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.119388 Test loss=0.276289 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1211966872215271
[5/24] Train loss=0.10886621475219727
[10/24] Train loss=0.11791952699422836
[15/24] Train loss=0.11131390184164047
[20/24] Train loss=0.12011486291885376
Test set avg_accuracy=89.35% avg_sensitivity=76.66%, avg_specificity=94.19% avg_auc=93.88%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.118953 Test loss=0.276341 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.119737409055233
[5/24] Train loss=0.10813864320516586
[10/24] Train loss=0.11702148616313934
[15/24] Train loss=0.11444411426782608
[20/24] Train loss=0.1184639185667038
Test set avg_accuracy=89.47% avg_sensitivity=76.43%, avg_specificity=94.44% avg_auc=93.84%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.119488 Test loss=0.276811 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12038406729698181
[5/24] Train loss=0.10762538015842438
[10/24] Train loss=0.1167464479804039
[15/24] Train loss=0.10993816703557968
[20/24] Train loss=0.11983255296945572
Test set avg_accuracy=89.43% avg_sensitivity=76.52%, avg_specificity=94.35% avg_auc=93.85%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.119323 Test loss=0.276645 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12181367725133896
[5/24] Train loss=0.10997079312801361
[10/24] Train loss=0.11998791992664337
[15/24] Train loss=0.11183615773916245
[20/24] Train loss=0.1168380156159401
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=89.44% avg_sensitivity=76.43%, avg_specificity=94.41% avg_auc=93.84%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.119142 Test loss=0.276756 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=89.08% sen=80.91%, spe=92.19%, auc=94.74%!
Fold[7] Avg_overlap=0.72%(0.22469735514155495)
[0/24] Train loss=0.7561353445053101
[5/24] Train loss=0.755459189414978
[10/24] Train loss=0.7519772052764893
[15/24] Train loss=0.7417136430740356
[20/24] Train loss=0.7316998839378357
Test set avg_accuracy=55.53% avg_sensitivity=50.03%, avg_specificity=57.38% avg_auc=55.82%
Best model saved!! Metric=-107.23339844538782!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.743199 Test loss=0.684621 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7162197232246399
[5/24] Train loss=0.7184284925460815
[10/24] Train loss=0.717505693435669
[15/24] Train loss=0.7008897066116333
[20/24] Train loss=0.700018584728241
Test set avg_accuracy=62.71% avg_sensitivity=65.10%, avg_specificity=61.91% avg_auc=67.38%
Best model saved!! Metric=-68.90940452286196!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.711695 Test loss=0.647008 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.689049243927002
[5/24] Train loss=0.6883459091186523
[10/24] Train loss=0.6922891139984131
[15/24] Train loss=0.6677314043045044
[20/24] Train loss=0.669922947883606
Test set avg_accuracy=68.26% avg_sensitivity=72.04%, avg_specificity=66.99% avg_auc=75.22%
Best model saved!! Metric=-43.50862747752842!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.681443 Test loss=0.610604 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.65792316198349
[5/24] Train loss=0.6592347621917725
[10/24] Train loss=0.6560590863227844
[15/24] Train loss=0.6386888027191162
[20/24] Train loss=0.6292376518249512
Test set avg_accuracy=71.00% avg_sensitivity=76.80%, avg_specificity=69.06% avg_auc=79.56%
Best model saved!! Metric=-29.577983959843323!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.650814 Test loss=0.587613 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6216294169425964
[5/24] Train loss=0.6257059574127197
[10/24] Train loss=0.6207602620124817
[15/24] Train loss=0.605872392654419
[20/24] Train loss=0.6015892624855042
Test set avg_accuracy=73.16% avg_sensitivity=79.80%, avg_specificity=70.93% avg_auc=82.33%
Best model saved!! Metric=-19.77246999672404!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.618660 Test loss=0.560660 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5832365155220032
[5/24] Train loss=0.5907511115074158
[10/24] Train loss=0.5916945338249207
[15/24] Train loss=0.5720301866531372
[20/24] Train loss=0.571778416633606
Test set avg_accuracy=75.46% avg_sensitivity=80.53%, avg_specificity=73.75% avg_auc=84.62%
Best model saved!! Metric=-11.640686493490477!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.588741 Test loss=0.528728 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5555722117424011
[5/24] Train loss=0.5652006268501282
[10/24] Train loss=0.5749716758728027
[15/24] Train loss=0.5428245663642883
[20/24] Train loss=0.5284197330474854
Test set avg_accuracy=77.46% avg_sensitivity=82.60%, avg_specificity=75.73% avg_auc=86.42%
Best model saved!! Metric=-3.7817548323255608!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.558878 Test loss=0.504151 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5208672285079956
[5/24] Train loss=0.5370029807090759
[10/24] Train loss=0.5397117733955383
[15/24] Train loss=0.5117803812026978
[20/24] Train loss=0.49617189168930054
Test set avg_accuracy=80.70% avg_sensitivity=82.65%, avg_specificity=80.05% avg_auc=88.51%
Best model saved!! Metric=5.911089567093342!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.527273 Test loss=0.461413 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.49547603726387024
[5/24] Train loss=0.49910324811935425
[10/24] Train loss=0.5066091418266296
[15/24] Train loss=0.47993847727775574
[20/24] Train loss=0.46506476402282715
Test set avg_accuracy=83.46% avg_sensitivity=80.79%, avg_specificity=84.36% avg_auc=89.76%
Best model saved!! Metric=12.369629853124522!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.497323 Test loss=0.425943 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.467578649520874
[5/24] Train loss=0.4670945703983307
[10/24] Train loss=0.47754842042922974
[15/24] Train loss=0.45541346073150635
[20/24] Train loss=0.43798187375068665
Test set avg_accuracy=84.74% avg_sensitivity=81.62%, avg_specificity=85.79% avg_auc=91.12%
Best model saved!! Metric=17.262647124221587!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.470059 Test loss=0.404619 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.43799740076065063
[5/24] Train loss=0.4445165991783142
[10/24] Train loss=0.4512832760810852
[15/24] Train loss=0.4366210699081421
[20/24] Train loss=0.40041089057922363
Test set avg_accuracy=86.24% avg_sensitivity=82.13%, avg_specificity=87.62% avg_auc=91.96%
Best model saved!! Metric=21.945583342440713!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.443050 Test loss=0.381428 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.415381520986557
[5/24] Train loss=0.4162159264087677
[10/24] Train loss=0.432168185710907
[15/24] Train loss=0.4081292152404785
[20/24] Train loss=0.3777613639831543
Test set avg_accuracy=87.77% avg_sensitivity=79.65%, avg_specificity=90.50% avg_auc=92.66%
Best model saved!! Metric=24.58590149639538!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.416859 Test loss=0.350185 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.39377927780151367
[5/24] Train loss=0.3877296447753906
[10/24] Train loss=0.4026014506816864
[15/24] Train loss=0.3841284513473511
[20/24] Train loss=0.3571111857891083
Test set avg_accuracy=88.49% avg_sensitivity=77.32%, avg_specificity=92.24% avg_auc=92.92%
Best model saved!! Metric=24.969483244325858!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.393059 Test loss=0.328498 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3778112530708313
[5/24] Train loss=0.3689860999584198
[10/24] Train loss=0.38787946105003357
[15/24] Train loss=0.36570632457733154
[20/24] Train loss=0.3329491913318634
Test set avg_accuracy=89.06% avg_sensitivity=76.80%, avg_specificity=93.18% avg_auc=93.46%
Best model saved!! Metric=26.505402595628496!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.375127 Test loss=0.313180 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3536681532859802
[5/24] Train loss=0.35461682081222534
[10/24] Train loss=0.37369227409362793
[15/24] Train loss=0.35325726866722107
[20/24] Train loss=0.3215833902359009
Test set avg_accuracy=89.06% avg_sensitivity=74.21%, avg_specificity=94.05% avg_auc=93.52%
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.358952 Test loss=0.302952 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.341204971075058
[5/24] Train loss=0.3328000009059906
[10/24] Train loss=0.3581683933734894
[15/24] Train loss=0.33551692962646484
[20/24] Train loss=0.3035481870174408
Test set avg_accuracy=89.31% avg_sensitivity=77.11%, avg_specificity=93.41% avg_auc=93.85%
Best model saved!! Metric=27.67643642188864!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.343841 Test loss=0.296106 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3248683214187622
[5/24] Train loss=0.3174552321434021
[10/24] Train loss=0.34327584505081177
[15/24] Train loss=0.3288285732269287
[20/24] Train loss=0.28798413276672363
Test set avg_accuracy=89.47% avg_sensitivity=75.61%, avg_specificity=94.12% avg_auc=94.08%
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.330496 Test loss=0.285610 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3138519525527954
[5/24] Train loss=0.3127400279045105
[10/24] Train loss=0.3329920768737793
[15/24] Train loss=0.3235909938812256
[20/24] Train loss=0.2774882912635803
Test set avg_accuracy=89.53% avg_sensitivity=75.50%, avg_specificity=94.24% avg_auc=94.31%
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.321295 Test loss=0.276970 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.29836663603782654
[5/24] Train loss=0.3037598431110382
[10/24] Train loss=0.31205347180366516
[15/24] Train loss=0.31081637740135193
[20/24] Train loss=0.2681475877761841
Test set avg_accuracy=89.52% avg_sensitivity=77.21%, avg_specificity=93.65% avg_auc=94.42%
Best model saved!! Metric=28.805020763232804!!
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.309786 Test loss=0.273703 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2944101393222809
[5/24] Train loss=0.2892787456512451
[10/24] Train loss=0.30578505992889404
[15/24] Train loss=0.30643230676651
[20/24] Train loss=0.2564440071582794
Test set avg_accuracy=89.79% avg_sensitivity=76.90%, avg_specificity=94.12% avg_auc=94.62%
Best model saved!! Metric=29.43253330602728!!
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.301869 Test loss=0.266200 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.28759291768074036
[5/24] Train loss=0.2785426676273346
[10/24] Train loss=0.3010213375091553
[15/24] Train loss=0.3015879988670349
[20/24] Train loss=0.24947009980678558
Test set avg_accuracy=89.91% avg_sensitivity=76.07%, avg_specificity=94.56% avg_auc=94.81%
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.293458 Test loss=0.261409 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.28073740005493164
[5/24] Train loss=0.27433186769485474
[10/24] Train loss=0.29738256335258484
[15/24] Train loss=0.29172202944755554
[20/24] Train loss=0.2400393784046173
Test set avg_accuracy=89.74% avg_sensitivity=73.23%, avg_specificity=95.29% avg_auc=94.73%
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.287930 Test loss=0.259026 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2711578905582428
[5/24] Train loss=0.25915759801864624
[10/24] Train loss=0.28647953271865845
[15/24] Train loss=0.28637823462486267
[20/24] Train loss=0.23405028879642487
Test set avg_accuracy=90.21% avg_sensitivity=74.47%, avg_specificity=95.49% avg_auc=94.90%
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.279387 Test loss=0.253567 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.26971110701560974
[5/24] Train loss=0.2606572210788727
[10/24] Train loss=0.28035199642181396
[15/24] Train loss=0.2764028012752533
[20/24] Train loss=0.2312198430299759
Test set avg_accuracy=89.44% avg_sensitivity=71.41%, avg_specificity=95.49% avg_auc=94.48%
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.273246 Test loss=0.258772 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2691504955291748
[5/24] Train loss=0.2560126483440399
[10/24] Train loss=0.27460551261901855
[15/24] Train loss=0.2712175250053406
[20/24] Train loss=0.22615675628185272
Test set avg_accuracy=89.67% avg_sensitivity=78.25%, avg_specificity=93.51% avg_auc=94.46%
Best model saved!! Metric=29.897042449462162!!
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.268181 Test loss=0.264614 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2562388777732849
[5/24] Train loss=0.2508178651332855
[10/24] Train loss=0.2701478600502014
[15/24] Train loss=0.2666580379009247
[20/24] Train loss=0.21968330442905426
Test set avg_accuracy=89.53% avg_sensitivity=70.27%, avg_specificity=96.00% avg_auc=94.54%
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.261332 Test loss=0.255839 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.25647392868995667
[5/24] Train loss=0.24106214940547943
[10/24] Train loss=0.2603286802768707
[15/24] Train loss=0.2612859904766083
[20/24] Train loss=0.21618534624576569
Test set avg_accuracy=87.54% avg_sensitivity=59.97%, avg_specificity=96.80% avg_auc=93.40%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.254062 Test loss=0.292023 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2519914209842682
[5/24] Train loss=0.23204942047595978
[10/24] Train loss=0.2590812146663666
[15/24] Train loss=0.25738558173179626
[20/24] Train loss=0.21368257701396942
Test set avg_accuracy=88.96% avg_sensitivity=66.86%, avg_specificity=96.38% avg_auc=94.30%
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.250418 Test loss=0.262146 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2501572370529175
[5/24] Train loss=0.22176499664783478
[10/24] Train loss=0.2554086148738861
[15/24] Train loss=0.25531238317489624
[20/24] Train loss=0.20947766304016113
Test set avg_accuracy=89.40% avg_sensitivity=70.02%, avg_specificity=95.91% avg_auc=94.30%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.247466 Test loss=0.256719 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2438950091600418
[5/24] Train loss=0.22585104405879974
[10/24] Train loss=0.25444015860557556
[15/24] Train loss=0.25353488326072693
[20/24] Train loss=0.20789264142513275
Test set avg_accuracy=88.71% avg_sensitivity=66.60%, avg_specificity=96.14% avg_auc=94.03%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.243782 Test loss=0.266063 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.23796628415584564
[5/24] Train loss=0.2179497480392456
[10/24] Train loss=0.2498392015695572
[15/24] Train loss=0.24199187755584717
[20/24] Train loss=0.20347672700881958
Test set avg_accuracy=89.35% avg_sensitivity=73.02%, avg_specificity=94.83% avg_auc=94.17%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.235387 Test loss=0.262109 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.231390580534935
[5/24] Train loss=0.2129192352294922
[10/24] Train loss=0.25852060317993164
[15/24] Train loss=0.24242132902145386
[20/24] Train loss=0.20244655013084412
Test set avg_accuracy=88.83% avg_sensitivity=70.64%, avg_specificity=94.94% avg_auc=93.19%
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.237953 Test loss=0.275955 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2420036792755127
[5/24] Train loss=0.1995282620191574
[10/24] Train loss=0.24301570653915405
[15/24] Train loss=0.23807622492313385
[20/24] Train loss=0.19862724840641022
Test set avg_accuracy=87.72% avg_sensitivity=62.09%, avg_specificity=96.33% avg_auc=91.68%
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.232883 Test loss=0.308346 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.22923867404460907
[5/24] Train loss=0.21467038989067078
[10/24] Train loss=0.24847877025604248
[15/24] Train loss=0.24191488325595856
[20/24] Train loss=0.19257311522960663
Test set avg_accuracy=89.36% avg_sensitivity=71.93%, avg_specificity=95.22% avg_auc=94.18%
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.233975 Test loss=0.262158 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.22147472202777863
[5/24] Train loss=0.1940833479166031
[10/24] Train loss=0.24093413352966309
[15/24] Train loss=0.24125464260578156
[20/24] Train loss=0.18759292364120483
Test set avg_accuracy=89.19% avg_sensitivity=75.45%, avg_specificity=93.81% avg_auc=93.80%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.228584 Test loss=0.263798 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.21303240954875946
[5/24] Train loss=0.19548740983009338
[10/24] Train loss=0.22113734483718872
[15/24] Train loss=0.240345299243927
[20/24] Train loss=0.1893109381198883
Test set avg_accuracy=89.67% avg_sensitivity=76.23%, avg_specificity=94.19% avg_auc=93.77%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.224039 Test loss=0.259358 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.22882001101970673
[5/24] Train loss=0.19398601353168488
[10/24] Train loss=0.2319066822528839
[15/24] Train loss=0.2268654853105545
[20/24] Train loss=0.1915399134159088
Test set avg_accuracy=85.91% avg_sensitivity=83.43%, avg_specificity=86.75% avg_auc=92.68%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.223706 Test loss=0.342904 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.22182396054267883
[5/24] Train loss=0.19825191795825958
[10/24] Train loss=0.24102330207824707
[15/24] Train loss=0.2325247973203659
[20/24] Train loss=0.19272035360336304
Test set avg_accuracy=87.53% avg_sensitivity=79.29%, avg_specificity=90.29% avg_auc=93.21%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.224543 Test loss=0.300770 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.21959803998470306
[5/24] Train loss=0.20062075555324554
[10/24] Train loss=0.2199093997478485
[15/24] Train loss=0.2271871566772461
[20/24] Train loss=0.18547046184539795
Test set avg_accuracy=84.04% avg_sensitivity=84.31%, avg_specificity=83.95% avg_auc=92.37%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.219061 Test loss=0.356258 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.21579116582870483
[5/24] Train loss=0.1899639517068863
[10/24] Train loss=0.2261456549167633
[15/24] Train loss=0.2328813374042511
[20/24] Train loss=0.18262195587158203
Test set avg_accuracy=89.09% avg_sensitivity=74.00%, avg_specificity=94.16% avg_auc=92.75%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.218186 Test loss=0.275046 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.21376636624336243
[5/24] Train loss=0.1982312947511673
[10/24] Train loss=0.22676265239715576
[15/24] Train loss=0.2269824743270874
[20/24] Train loss=0.1844339519739151
Test set avg_accuracy=81.21% avg_sensitivity=87.88%, avg_specificity=78.97% avg_auc=91.66%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.219932 Test loss=0.409870 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.21488285064697266
[5/24] Train loss=0.19629831612110138
[10/24] Train loss=0.22681330144405365
[15/24] Train loss=0.22318688035011292
[20/24] Train loss=0.1786033660173416
Test set avg_accuracy=87.20% avg_sensitivity=70.90%, avg_specificity=92.68% avg_auc=92.29%
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.218475 Test loss=0.297146 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2144828736782074
[5/24] Train loss=0.1869228631258011
[10/24] Train loss=0.2450140416622162
[15/24] Train loss=0.24766087532043457
[20/24] Train loss=0.18317511677742004
Test set avg_accuracy=87.50% avg_sensitivity=84.15%, avg_specificity=88.62% avg_auc=94.08%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.218856 Test loss=0.285338 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2106451839208603
[5/24] Train loss=0.17740978300571442
[10/24] Train loss=0.2152961790561676
[15/24] Train loss=0.21732743084430695
[20/24] Train loss=0.18342629075050354
Test set avg_accuracy=86.55% avg_sensitivity=85.24%, avg_specificity=86.99% avg_auc=93.96%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.210963 Test loss=0.302620 Current lr=[0.00029967723776099]

[0/24] Train loss=0.21078069508075714
[5/24] Train loss=0.17399455606937408
[10/24] Train loss=0.21749185025691986
[15/24] Train loss=0.21929897367954254
[20/24] Train loss=0.17601391673088074
Test set avg_accuracy=82.92% avg_sensitivity=78.61%, avg_specificity=84.36% avg_auc=90.06%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.210173 Test loss=0.377978 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.20312249660491943
[5/24] Train loss=0.18483340740203857
[10/24] Train loss=0.22530852258205414
[15/24] Train loss=0.23004783689975739
[20/24] Train loss=0.1781245917081833
Test set avg_accuracy=88.53% avg_sensitivity=76.95%, avg_specificity=92.42% avg_auc=93.23%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.209029 Test loss=0.281144 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.20620571076869965
[5/24] Train loss=0.17999039590358734
[10/24] Train loss=0.23450541496276855
[15/24] Train loss=0.22252415120601654
[20/24] Train loss=0.1724092662334442
Test set avg_accuracy=88.36% avg_sensitivity=78.51%, avg_specificity=91.67% avg_auc=93.76%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.211645 Test loss=0.275582 Current lr=[0.000299720220882401]

[0/24] Train loss=0.19592607021331787
[5/24] Train loss=0.17456668615341187
[10/24] Train loss=0.20709730684757233
[15/24] Train loss=0.23233339190483093
[20/24] Train loss=0.18605808913707733
Test set avg_accuracy=88.15% avg_sensitivity=76.54%, avg_specificity=92.05% avg_auc=92.79%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.207724 Test loss=0.285390 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.21162132918834686
[5/24] Train loss=0.19559861719608307
[10/24] Train loss=0.22295796871185303
[15/24] Train loss=0.1999448835849762
[20/24] Train loss=0.16663648188114166
Test set avg_accuracy=89.64% avg_sensitivity=76.80%, avg_specificity=93.95% avg_auc=93.52%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.206491 Test loss=0.265794 Current lr=[0.000298904600941902]

[0/24] Train loss=0.20479699969291687
[5/24] Train loss=0.17412003874778748
[10/24] Train loss=0.20906966924667358
[15/24] Train loss=0.2071073204278946
[20/24] Train loss=0.17518189549446106
Test set avg_accuracy=86.09% avg_sensitivity=65.77%, avg_specificity=92.92% avg_auc=90.03%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.202644 Test loss=0.330367 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.19678395986557007
[5/24] Train loss=0.17809852957725525
[10/24] Train loss=0.22359797358512878
[15/24] Train loss=0.20812922716140747
[20/24] Train loss=0.1836690753698349
Test set avg_accuracy=84.96% avg_sensitivity=46.61%, avg_specificity=97.84% avg_auc=89.55%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.205895 Test loss=0.391472 Current lr=[0.000297555943323901]

[0/24] Train loss=0.194984570145607
[5/24] Train loss=0.17504677176475525
[10/24] Train loss=0.22037553787231445
[15/24] Train loss=0.22284762561321259
[20/24] Train loss=0.17836789786815643
Test set avg_accuracy=85.47% avg_sensitivity=50.39%, avg_specificity=97.25% avg_auc=89.44%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.206297 Test loss=0.365860 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.20441696047782898
[5/24] Train loss=0.17156383395195007
[10/24] Train loss=0.20175538957118988
[15/24] Train loss=0.20869052410125732
[20/24] Train loss=0.17218925058841705
Test set avg_accuracy=88.12% avg_sensitivity=82.08%, avg_specificity=90.15% avg_auc=93.62%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.200284 Test loss=0.286258 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.19780868291854858
[5/24] Train loss=0.1723312884569168
[10/24] Train loss=0.21774792671203613
[15/24] Train loss=0.21781031787395477
[20/24] Train loss=0.16967393457889557
Test set avg_accuracy=87.46% avg_sensitivity=67.48%, avg_specificity=94.17% avg_auc=89.09%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.198078 Test loss=0.333102 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.1995874047279358
[5/24] Train loss=0.16881771385669708
[10/24] Train loss=0.20646102726459503
[15/24] Train loss=0.20502504706382751
[20/24] Train loss=0.17322604358196259
Test set avg_accuracy=83.80% avg_sensitivity=68.15%, avg_specificity=89.06% avg_auc=88.84%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.197479 Test loss=0.365947 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.1972757875919342
[5/24] Train loss=0.16093719005584717
[10/24] Train loss=0.2116377353668213
[15/24] Train loss=0.20554949343204498
[20/24] Train loss=0.17034442722797394
Test set avg_accuracy=87.92% avg_sensitivity=65.92%, avg_specificity=95.30% avg_auc=90.84%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.193722 Test loss=0.317304 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.19838157296180725
[5/24] Train loss=0.16130201518535614
[10/24] Train loss=0.20699657499790192
[15/24] Train loss=0.2064879685640335
[20/24] Train loss=0.15598617494106293
Test set avg_accuracy=89.36% avg_sensitivity=76.75%, avg_specificity=93.60% avg_auc=93.86%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.191387 Test loss=0.264440 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.1917857527732849
[5/24] Train loss=0.1633027344942093
[10/24] Train loss=0.20063260197639465
[15/24] Train loss=0.2064109593629837
[20/24] Train loss=0.16642040014266968
Test set avg_accuracy=89.19% avg_sensitivity=69.24%, avg_specificity=95.89% avg_auc=93.25%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.188625 Test loss=0.276810 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.18970808386802673
[5/24] Train loss=0.16136839985847473
[10/24] Train loss=0.1893768161535263
[15/24] Train loss=0.2165268212556839
[20/24] Train loss=0.15985789895057678
Test set avg_accuracy=87.17% avg_sensitivity=57.48%, avg_specificity=97.15% avg_auc=90.85%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.189780 Test loss=0.325051 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.19270455837249756
[5/24] Train loss=0.164724662899971
[10/24] Train loss=0.1894233524799347
[15/24] Train loss=0.20708110928535461
[20/24] Train loss=0.17613954842090607
Test set avg_accuracy=80.77% avg_sensitivity=79.65%, avg_specificity=81.14% avg_auc=88.38%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.190420 Test loss=0.429278 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.1885984241962433
[5/24] Train loss=0.1557169407606125
[10/24] Train loss=0.19446390867233276
[15/24] Train loss=0.19435296952724457
[20/24] Train loss=0.16161015629768372
Test set avg_accuracy=89.04% avg_sensitivity=71.21%, avg_specificity=95.03% avg_auc=93.37%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.186812 Test loss=0.272516 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.1797662079334259
[5/24] Train loss=0.1649015247821808
[10/24] Train loss=0.1928108036518097
[15/24] Train loss=0.20393027365207672
[20/24] Train loss=0.1602650135755539
Test set avg_accuracy=88.24% avg_sensitivity=68.57%, avg_specificity=94.85% avg_auc=92.40%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.187511 Test loss=0.288746 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.18648718297481537
[5/24] Train loss=0.180889293551445
[10/24] Train loss=0.18775656819343567
[15/24] Train loss=0.19685626029968262
[20/24] Train loss=0.16372831165790558
Test set avg_accuracy=88.32% avg_sensitivity=67.17%, avg_specificity=95.43% avg_auc=92.88%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.189807 Test loss=0.287894 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.1957220435142517
[5/24] Train loss=0.16263771057128906
[10/24] Train loss=0.19217605888843536
[15/24] Train loss=0.20782554149627686
[20/24] Train loss=0.15848256647586823
Test set avg_accuracy=71.37% avg_sensitivity=91.71%, avg_specificity=64.53% avg_auc=88.71%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.184851 Test loss=0.573644 Current lr=[0.000276307469034998]

[0/24] Train loss=0.1959226280450821
[5/24] Train loss=0.16224820911884308
[10/24] Train loss=0.18605385720729828
[15/24] Train loss=0.1985117644071579
[20/24] Train loss=0.15689007937908173
Test set avg_accuracy=88.84% avg_sensitivity=76.18%, avg_specificity=93.09% avg_auc=93.40%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.184977 Test loss=0.275538 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.18751320242881775
[5/24] Train loss=0.1636997014284134
[10/24] Train loss=0.20120014250278473
[15/24] Train loss=0.18932858109474182
[20/24] Train loss=0.15997301042079926
Test set avg_accuracy=82.58% avg_sensitivity=82.91%, avg_specificity=82.47% avg_auc=90.76%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.187403 Test loss=0.389788 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.1891806721687317
[5/24] Train loss=0.15951618552207947
[10/24] Train loss=0.1974928230047226
[15/24] Train loss=0.1910722553730011
[20/24] Train loss=0.15700767934322357
Test set avg_accuracy=89.01% avg_sensitivity=69.50%, avg_specificity=95.56% avg_auc=92.02%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.189180 Test loss=0.288955 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.174954354763031
[5/24] Train loss=0.15617282688617706
[10/24] Train loss=0.1826685220003128
[15/24] Train loss=0.1924668699502945
[20/24] Train loss=0.17162516713142395
Test set avg_accuracy=87.94% avg_sensitivity=78.40%, avg_specificity=91.15% avg_auc=92.75%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.182358 Test loss=0.296900 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.176089808344841
[5/24] Train loss=0.16496041417121887
[10/24] Train loss=0.1887657195329666
[15/24] Train loss=0.19427718222141266
[20/24] Train loss=0.1749221831560135
Test set avg_accuracy=88.97% avg_sensitivity=75.50%, avg_specificity=93.49% avg_auc=93.57%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.185003 Test loss=0.268439 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.1791384220123291
[5/24] Train loss=0.15626944601535797
[10/24] Train loss=0.18358854949474335
[15/24] Train loss=0.1868124157190323
[20/24] Train loss=0.15770642459392548
Test set avg_accuracy=88.83% avg_sensitivity=73.43%, avg_specificity=94.00% avg_auc=93.47%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.181075 Test loss=0.274899 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.18386568129062653
[5/24] Train loss=0.15797440707683563
[10/24] Train loss=0.18669109046459198
[15/24] Train loss=0.19628170132637024
[20/24] Train loss=0.15510119497776031
Test set avg_accuracy=89.14% avg_sensitivity=75.40%, avg_specificity=93.76% avg_auc=93.63%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.181402 Test loss=0.267561 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.18246525526046753
[5/24] Train loss=0.16858884692192078
[10/24] Train loss=0.1912374645471573
[15/24] Train loss=0.18600644171237946
[20/24] Train loss=0.15714329481124878
Test set avg_accuracy=85.04% avg_sensitivity=88.92%, avg_specificity=83.74% avg_auc=93.41%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.181059 Test loss=0.343045 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.1806287169456482
[5/24] Train loss=0.1594591736793518
[10/24] Train loss=0.18610189855098724
[15/24] Train loss=0.17905481159687042
[20/24] Train loss=0.1514933556318283
Test set avg_accuracy=88.55% avg_sensitivity=82.34%, avg_specificity=90.64% avg_auc=93.84%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.176692 Test loss=0.281094 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1756874918937683
[5/24] Train loss=0.1504000723361969
[10/24] Train loss=0.19469580054283142
[15/24] Train loss=0.1854468137025833
[20/24] Train loss=0.14565280079841614
Test set avg_accuracy=83.98% avg_sensitivity=76.18%, avg_specificity=86.61% avg_auc=89.03%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.176947 Test loss=0.379870 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.1789531111717224
[5/24] Train loss=0.1487133800983429
[10/24] Train loss=0.18996700644493103
[15/24] Train loss=0.1932976245880127
[20/24] Train loss=0.1490653157234192
Test set avg_accuracy=86.28% avg_sensitivity=53.18%, avg_specificity=97.39% avg_auc=87.54%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.177509 Test loss=0.379018 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.18199819326400757
[5/24] Train loss=0.15565651655197144
[10/24] Train loss=0.1844691038131714
[15/24] Train loss=0.1871114820241928
[20/24] Train loss=0.15418031811714172
Test set avg_accuracy=88.74% avg_sensitivity=69.03%, avg_specificity=95.36% avg_auc=93.09%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.177447 Test loss=0.282032 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.1788029670715332
[5/24] Train loss=0.14556962251663208
[10/24] Train loss=0.17423827946186066
[15/24] Train loss=0.1784496009349823
[20/24] Train loss=0.1582278609275818
Test set avg_accuracy=89.04% avg_sensitivity=79.80%, avg_specificity=92.14% avg_auc=93.15%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.173381 Test loss=0.278376 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.17274445295333862
[5/24] Train loss=0.15958617627620697
[10/24] Train loss=0.18905745446681976
[15/24] Train loss=0.176503986120224
[20/24] Train loss=0.1496843695640564
Test set avg_accuracy=86.54% avg_sensitivity=75.76%, avg_specificity=90.15% avg_auc=91.21%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.176042 Test loss=0.322197 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.17376406490802765
[5/24] Train loss=0.15315258502960205
[10/24] Train loss=0.18157829344272614
[15/24] Train loss=0.1714002639055252
[20/24] Train loss=0.14999504387378693
Test set avg_accuracy=87.80% avg_sensitivity=71.00%, avg_specificity=93.44% avg_auc=91.92%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.173547 Test loss=0.301779 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17207767069339752
[5/24] Train loss=0.1435265690088272
[10/24] Train loss=0.19343510270118713
[15/24] Train loss=0.1760135442018509
[20/24] Train loss=0.14043456315994263
Test set avg_accuracy=87.99% avg_sensitivity=82.08%, avg_specificity=89.98% avg_auc=92.88%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.171641 Test loss=0.300848 Current lr=[0.000224838296036774]

[0/24] Train loss=0.17630067467689514
[5/24] Train loss=0.14899009466171265
[10/24] Train loss=0.1829654723405838
[15/24] Train loss=0.17419761419296265
[20/24] Train loss=0.1491774320602417
Test set avg_accuracy=88.24% avg_sensitivity=79.80%, avg_specificity=91.08% avg_auc=92.09%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.173748 Test loss=0.300674 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.16692963242530823
[5/24] Train loss=0.1433430165052414
[10/24] Train loss=0.17397309839725494
[15/24] Train loss=0.17376455664634705
[20/24] Train loss=0.14860622584819794
Test set avg_accuracy=88.39% avg_sensitivity=76.44%, avg_specificity=92.40% avg_auc=93.32%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.168935 Test loss=0.278590 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.17153429985046387
[5/24] Train loss=0.14031872153282166
[10/24] Train loss=0.1676470935344696
[15/24] Train loss=0.1745537966489792
[20/24] Train loss=0.14082521200180054
Test set avg_accuracy=88.09% avg_sensitivity=73.95%, avg_specificity=92.83% avg_auc=91.95%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.167636 Test loss=0.295800 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.16568562388420105
[5/24] Train loss=0.13799941539764404
[10/24] Train loss=0.16818031668663025
[15/24] Train loss=0.18118144571781158
[20/24] Train loss=0.14951904118061066
Test set avg_accuracy=89.24% avg_sensitivity=71.05%, avg_specificity=95.36% avg_auc=92.53%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.167369 Test loss=0.279794 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.16755804419517517
[5/24] Train loss=0.1471080183982849
[10/24] Train loss=0.16902799904346466
[15/24] Train loss=0.16823995113372803
[20/24] Train loss=0.14017581939697266
Test set avg_accuracy=88.29% avg_sensitivity=79.23%, avg_specificity=91.34% avg_auc=93.40%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.167386 Test loss=0.283963 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.17363539338111877
[5/24] Train loss=0.1445600837469101
[10/24] Train loss=0.1750366985797882
[15/24] Train loss=0.16941851377487183
[20/24] Train loss=0.15271829068660736
Test set avg_accuracy=89.10% avg_sensitivity=72.76%, avg_specificity=94.59% avg_auc=92.90%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.165194 Test loss=0.281046 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.170396089553833
[5/24] Train loss=0.1425398290157318
[10/24] Train loss=0.1666957587003708
[15/24] Train loss=0.16390912234783173
[20/24] Train loss=0.1413123607635498
Test set avg_accuracy=89.13% avg_sensitivity=77.42%, avg_specificity=93.06% avg_auc=93.87%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.163982 Test loss=0.269741 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.16894735395908356
[5/24] Train loss=0.14273686707019806
[10/24] Train loss=0.17096859216690063
[15/24] Train loss=0.1769128441810608
[20/24] Train loss=0.14120684564113617
Test set avg_accuracy=88.07% avg_sensitivity=68.31%, avg_specificity=94.71% avg_auc=91.63%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.164608 Test loss=0.300483 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.16912031173706055
[5/24] Train loss=0.1505361795425415
[10/24] Train loss=0.16446417570114136
[15/24] Train loss=0.16910099983215332
[20/24] Train loss=0.1406799554824829
Test set avg_accuracy=87.25% avg_sensitivity=65.56%, avg_specificity=94.54% avg_auc=91.90%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.165916 Test loss=0.309785 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.16376592218875885
[5/24] Train loss=0.14023467898368835
[10/24] Train loss=0.17038071155548096
[15/24] Train loss=0.16314463317394257
[20/24] Train loss=0.1401144415140152
Test set avg_accuracy=85.85% avg_sensitivity=54.58%, avg_specificity=96.35% avg_auc=85.01%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.163204 Test loss=0.396351 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1676672399044037
[5/24] Train loss=0.14544416964054108
[10/24] Train loss=0.16166219115257263
[15/24] Train loss=0.1639869511127472
[20/24] Train loss=0.13993395864963531
Test set avg_accuracy=88.35% avg_sensitivity=69.39%, avg_specificity=94.71% avg_auc=92.24%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.163089 Test loss=0.298455 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.1606902778148651
[5/24] Train loss=0.14374443888664246
[10/24] Train loss=0.17138491570949554
[15/24] Train loss=0.17059428989887238
[20/24] Train loss=0.14145226776599884
Test set avg_accuracy=88.40% avg_sensitivity=70.90%, avg_specificity=94.28% avg_auc=92.02%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.165006 Test loss=0.294425 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.16494783759117126
[5/24] Train loss=0.15498803555965424
[10/24] Train loss=0.1698618084192276
[15/24] Train loss=0.17277775704860687
[20/24] Train loss=0.14058324694633484
Test set avg_accuracy=85.92% avg_sensitivity=54.01%, avg_specificity=96.64% avg_auc=85.19%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.165131 Test loss=0.396797 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.16203522682189941
[5/24] Train loss=0.1488882154226303
[10/24] Train loss=0.15933005511760712
[15/24] Train loss=0.16809244453907013
[20/24] Train loss=0.14151982963085175
Test set avg_accuracy=87.58% avg_sensitivity=71.36%, avg_specificity=93.02% avg_auc=91.99%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.162300 Test loss=0.308392 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.17008216679096222
[5/24] Train loss=0.14052309095859528
[10/24] Train loss=0.16101790964603424
[15/24] Train loss=0.16086448729038239
[20/24] Train loss=0.13885211944580078
Test set avg_accuracy=88.79% avg_sensitivity=70.69%, avg_specificity=94.87% avg_auc=91.47%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.160642 Test loss=0.298641 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15862517058849335
[5/24] Train loss=0.14757032692432404
[10/24] Train loss=0.15734215080738068
[15/24] Train loss=0.16794142127037048
[20/24] Train loss=0.1339351087808609
Test set avg_accuracy=88.44% avg_sensitivity=64.63%, avg_specificity=96.43% avg_auc=90.87%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.158815 Test loss=0.312143 Current lr=[0.000156543481933168]

[0/24] Train loss=0.15845035016536713
[5/24] Train loss=0.1490594446659088
[10/24] Train loss=0.15350572764873505
[15/24] Train loss=0.16454662382602692
[20/24] Train loss=0.1312192976474762
Test set avg_accuracy=86.39% avg_sensitivity=56.76%, avg_specificity=96.35% avg_auc=89.21%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.155196 Test loss=0.352794 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.16666145622730255
[5/24] Train loss=0.13138911128044128
[10/24] Train loss=0.15117423236370087
[15/24] Train loss=0.1589314192533493
[20/24] Train loss=0.1333238184452057
Test set avg_accuracy=88.84% avg_sensitivity=74.37%, avg_specificity=93.70% avg_auc=92.74%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.154606 Test loss=0.286883 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15685001015663147
[5/24] Train loss=0.13684988021850586
[10/24] Train loss=0.14860332012176514
[15/24] Train loss=0.16682325303554535
[20/24] Train loss=0.13266026973724365
Test set avg_accuracy=88.23% avg_sensitivity=65.77%, avg_specificity=95.77% avg_auc=90.69%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.154750 Test loss=0.313590 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.1600894033908844
[5/24] Train loss=0.1409883201122284
[10/24] Train loss=0.15724344551563263
[15/24] Train loss=0.15851682424545288
[20/24] Train loss=0.1296849250793457
Test set avg_accuracy=87.19% avg_sensitivity=61.16%, avg_specificity=95.93% avg_auc=88.45%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.156900 Test loss=0.345395 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1552964299917221
[5/24] Train loss=0.13734623789787292
[10/24] Train loss=0.1479579508304596
[15/24] Train loss=0.15976180136203766
[20/24] Train loss=0.1353999525308609
Test set avg_accuracy=88.93% avg_sensitivity=71.83%, avg_specificity=94.68% avg_auc=93.25%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.153863 Test loss=0.276593 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1550644189119339
[5/24] Train loss=0.13465234637260437
[10/24] Train loss=0.15521050989627838
[15/24] Train loss=0.16046079993247986
[20/24] Train loss=0.1335754096508026
Test set avg_accuracy=89.79% avg_sensitivity=76.80%, avg_specificity=94.16% avg_auc=93.82%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.151914 Test loss=0.262887 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1545751541852951
[5/24] Train loss=0.13578663766384125
[10/24] Train loss=0.1539192646741867
[15/24] Train loss=0.16317126154899597
[20/24] Train loss=0.13283269107341766
Test set avg_accuracy=89.49% avg_sensitivity=69.24%, avg_specificity=96.30% avg_auc=92.65%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.153056 Test loss=0.282859 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.15423686802387238
[5/24] Train loss=0.13676732778549194
[10/24] Train loss=0.15069088339805603
[15/24] Train loss=0.16275927424430847
[20/24] Train loss=0.13189822435379028
Test set avg_accuracy=89.58% avg_sensitivity=73.17%, avg_specificity=95.09% avg_auc=93.13%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.152048 Test loss=0.274739 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.14668068289756775
[5/24] Train loss=0.13334691524505615
[10/24] Train loss=0.14492854475975037
[15/24] Train loss=0.15136128664016724
[20/24] Train loss=0.1345798820257187
Test set avg_accuracy=89.62% avg_sensitivity=76.59%, avg_specificity=94.00% avg_auc=93.48%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.149352 Test loss=0.267439 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.15011362731456757
[5/24] Train loss=0.13525642454624176
[10/24] Train loss=0.14346382021903992
[15/24] Train loss=0.1522042602300644
[20/24] Train loss=0.13189935684204102
Test set avg_accuracy=89.45% avg_sensitivity=71.26%, avg_specificity=95.56% avg_auc=93.32%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.148518 Test loss=0.272629 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15442849695682526
[5/24] Train loss=0.13750407099723816
[10/24] Train loss=0.14884313941001892
[15/24] Train loss=0.1505890041589737
[20/24] Train loss=0.1314363032579422
Test set avg_accuracy=88.65% avg_sensitivity=81.46%, avg_specificity=91.06% avg_auc=93.94%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.148892 Test loss=0.279064 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15035483241081238
[5/24] Train loss=0.1342162787914276
[10/24] Train loss=0.14314451813697815
[15/24] Train loss=0.15205031633377075
[20/24] Train loss=0.13384263217449188
Test set avg_accuracy=89.08% avg_sensitivity=70.07%, avg_specificity=95.46% avg_auc=93.03%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.149900 Test loss=0.276722 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1471518874168396
[5/24] Train loss=0.13392311334609985
[10/24] Train loss=0.14233410358428955
[15/24] Train loss=0.1514958143234253
[20/24] Train loss=0.1313178986310959
Test set avg_accuracy=89.24% avg_sensitivity=75.14%, avg_specificity=93.98% avg_auc=93.90%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.147808 Test loss=0.266722 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.15566757321357727
[5/24] Train loss=0.13564686477184296
[10/24] Train loss=0.150442436337471
[15/24] Train loss=0.1479494869709015
[20/24] Train loss=0.12486633658409119
Test set avg_accuracy=86.69% avg_sensitivity=82.19%, avg_specificity=88.21% avg_auc=92.15%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.145387 Test loss=0.330676 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.1443776786327362
[5/24] Train loss=0.13031654059886932
[10/24] Train loss=0.14100879430770874
[15/24] Train loss=0.14690221846103668
[20/24] Train loss=0.13150179386138916
Test set avg_accuracy=89.27% avg_sensitivity=78.77%, avg_specificity=92.80% avg_auc=93.70%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.143900 Test loss=0.274695 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.14610666036605835
[5/24] Train loss=0.13207262754440308
[10/24] Train loss=0.1379966139793396
[15/24] Train loss=0.1434362232685089
[20/24] Train loss=0.12243721634149551
Test set avg_accuracy=88.32% avg_sensitivity=79.29%, avg_specificity=91.36% avg_auc=93.51%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.142886 Test loss=0.286038 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14177803695201874
[5/24] Train loss=0.1311044692993164
[10/24] Train loss=0.13697946071624756
[15/24] Train loss=0.140705406665802
[20/24] Train loss=0.12572945654392242
Test set avg_accuracy=88.66% avg_sensitivity=77.21%, avg_specificity=92.50% avg_auc=93.18%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.141935 Test loss=0.285775 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13993898034095764
[5/24] Train loss=0.1320021152496338
[10/24] Train loss=0.1340164840221405
[15/24] Train loss=0.14278164505958557
[20/24] Train loss=0.12214098125696182
Test set avg_accuracy=89.30% avg_sensitivity=74.99%, avg_specificity=94.10% avg_auc=93.06%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.139990 Test loss=0.278852 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14609333872795105
[5/24] Train loss=0.1294746994972229
[10/24] Train loss=0.13609804213047028
[15/24] Train loss=0.1379157155752182
[20/24] Train loss=0.12011647969484329
Test set avg_accuracy=88.50% avg_sensitivity=75.87%, avg_specificity=92.75% avg_auc=92.79%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.137793 Test loss=0.294421 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13364249467849731
[5/24] Train loss=0.12428133189678192
[10/24] Train loss=0.1342923492193222
[15/24] Train loss=0.13924206793308258
[20/24] Train loss=0.12116679549217224
Test set avg_accuracy=88.89% avg_sensitivity=74.68%, avg_specificity=93.67% avg_auc=93.30%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.137164 Test loss=0.274963 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13656404614448547
[5/24] Train loss=0.12643969058990479
[10/24] Train loss=0.13047263026237488
[15/24] Train loss=0.13873235881328583
[20/24] Train loss=0.12138639390468597
Test set avg_accuracy=89.26% avg_sensitivity=72.24%, avg_specificity=94.97% avg_auc=92.92%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.136124 Test loss=0.281142 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1338105946779251
[5/24] Train loss=0.12256869673728943
[10/24] Train loss=0.13504146039485931
[15/24] Train loss=0.1376982033252716
[20/24] Train loss=0.12090563029050827
Test set avg_accuracy=88.24% avg_sensitivity=71.31%, avg_specificity=93.93% avg_auc=92.08%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.134869 Test loss=0.297160 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13649730384349823
[5/24] Train loss=0.12431775033473969
[10/24] Train loss=0.13228142261505127
[15/24] Train loss=0.13717296719551086
[20/24] Train loss=0.11905710399150848
Test set avg_accuracy=88.82% avg_sensitivity=75.82%, avg_specificity=93.18% avg_auc=93.01%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.133974 Test loss=0.282297 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13353407382965088
[5/24] Train loss=0.12070205062627792
[10/24] Train loss=0.12805983424186707
[15/24] Train loss=0.13214175403118134
[20/24] Train loss=0.11626115441322327
Test set avg_accuracy=88.35% avg_sensitivity=68.77%, avg_specificity=94.92% avg_auc=91.56%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.132699 Test loss=0.308762 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13295476138591766
[5/24] Train loss=0.11893915385007858
[10/24] Train loss=0.13069042563438416
[15/24] Train loss=0.13324066996574402
[20/24] Train loss=0.11648669093847275
Test set avg_accuracy=88.49% avg_sensitivity=70.07%, avg_specificity=94.68% avg_auc=92.36%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.132288 Test loss=0.297289 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.13399028778076172
[5/24] Train loss=0.12226264178752899
[10/24] Train loss=0.1313236951828003
[15/24] Train loss=0.13440704345703125
[20/24] Train loss=0.11897214502096176
Test set avg_accuracy=88.57% avg_sensitivity=75.71%, avg_specificity=92.89% avg_auc=93.15%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.131497 Test loss=0.282846 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13083955645561218
[5/24] Train loss=0.11805079132318497
[10/24] Train loss=0.12616439163684845
[15/24] Train loss=0.13360778987407684
[20/24] Train loss=0.1172720342874527
Test set avg_accuracy=88.95% avg_sensitivity=77.21%, avg_specificity=92.89% avg_auc=93.48%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.129863 Test loss=0.276718 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1269851177930832
[5/24] Train loss=0.11833745986223221
[10/24] Train loss=0.125763937830925
[15/24] Train loss=0.13366913795471191
[20/24] Train loss=0.11368169635534286
Test set avg_accuracy=88.80% avg_sensitivity=78.20%, avg_specificity=92.36% avg_auc=93.31%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.128567 Test loss=0.285192 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12880000472068787
[5/24] Train loss=0.11769586056470871
[10/24] Train loss=0.12288759648799896
[15/24] Train loss=0.13234972953796387
[20/24] Train loss=0.11488139629364014
Test set avg_accuracy=89.06% avg_sensitivity=75.71%, avg_specificity=93.55% avg_auc=93.16%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.128814 Test loss=0.281171 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12862041592597961
[5/24] Train loss=0.1164473295211792
[10/24] Train loss=0.12555639445781708
[15/24] Train loss=0.13293564319610596
[20/24] Train loss=0.11642535775899887
Test set avg_accuracy=89.35% avg_sensitivity=77.27%, avg_specificity=93.41% avg_auc=93.54%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.127968 Test loss=0.276550 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12994301319122314
[5/24] Train loss=0.1183321550488472
[10/24] Train loss=0.12404361367225647
[15/24] Train loss=0.13365039229393005
[20/24] Train loss=0.11464208364486694
Test set avg_accuracy=89.21% avg_sensitivity=73.33%, avg_specificity=94.54% avg_auc=93.23%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.127554 Test loss=0.281294 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1288130134344101
[5/24] Train loss=0.11505335569381714
[10/24] Train loss=0.12441614270210266
[15/24] Train loss=0.13181070983409882
[20/24] Train loss=0.11369998008012772
Test set avg_accuracy=89.47% avg_sensitivity=76.85%, avg_specificity=93.70% avg_auc=93.50%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.126804 Test loss=0.274065 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1246846616268158
[5/24] Train loss=0.11643034964799881
[10/24] Train loss=0.1210462749004364
[15/24] Train loss=0.12922711670398712
[20/24] Train loss=0.1170700266957283
Test set avg_accuracy=88.79% avg_sensitivity=72.24%, avg_specificity=94.35% avg_auc=92.98%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.126638 Test loss=0.283693 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12481442093849182
[5/24] Train loss=0.12012921273708344
[10/24] Train loss=0.12642180919647217
[15/24] Train loss=0.12898540496826172
[20/24] Train loss=0.11139239370822906
Test set avg_accuracy=89.24% avg_sensitivity=72.92%, avg_specificity=94.73% avg_auc=93.23%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.127127 Test loss=0.275280 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12499264627695084
[5/24] Train loss=0.11746270954608917
[10/24] Train loss=0.11950120329856873
[15/24] Train loss=0.1300201416015625
[20/24] Train loss=0.11370203644037247
Test set avg_accuracy=88.98% avg_sensitivity=80.63%, avg_specificity=91.79% avg_auc=93.78%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.126401 Test loss=0.275469 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12641537189483643
[5/24] Train loss=0.11804366856813431
[10/24] Train loss=0.12176280468702316
[15/24] Train loss=0.12862145900726318
[20/24] Train loss=0.11426164209842682
Test set avg_accuracy=89.19% avg_sensitivity=75.40%, avg_specificity=93.83% avg_auc=93.15%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.126076 Test loss=0.275418 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12366954982280731
[5/24] Train loss=0.11601954698562622
[10/24] Train loss=0.12075715512037277
[15/24] Train loss=0.12874548137187958
[20/24] Train loss=0.1138794794678688
Test set avg_accuracy=88.75% avg_sensitivity=72.55%, avg_specificity=94.19% avg_auc=92.94%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.125169 Test loss=0.280764 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12379100173711777
[5/24] Train loss=0.11742404848337173
[10/24] Train loss=0.11925110220909119
[15/24] Train loss=0.12541642785072327
[20/24] Train loss=0.11405104398727417
Test set avg_accuracy=89.15% avg_sensitivity=78.09%, avg_specificity=92.87% avg_auc=93.40%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.124798 Test loss=0.276278 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12147901207208633
[5/24] Train loss=0.11506595462560654
[10/24] Train loss=0.12089048326015472
[15/24] Train loss=0.12909667193889618
[20/24] Train loss=0.11144932359457016
Test set avg_accuracy=88.71% avg_sensitivity=77.37%, avg_specificity=92.52% avg_auc=93.30%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.124221 Test loss=0.284610 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12534014880657196
[5/24] Train loss=0.11230842024087906
[10/24] Train loss=0.11884123831987381
[15/24] Train loss=0.12838609516620636
[20/24] Train loss=0.10993774235248566
Test set avg_accuracy=88.97% avg_sensitivity=75.19%, avg_specificity=93.60% avg_auc=93.22%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.123949 Test loss=0.280322 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12181950360536575
[5/24] Train loss=0.11329162865877151
[10/24] Train loss=0.11865738779306412
[15/24] Train loss=0.12811215221881866
[20/24] Train loss=0.1091417744755745
Test set avg_accuracy=89.11% avg_sensitivity=77.73%, avg_specificity=92.94% avg_auc=93.52%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.122766 Test loss=0.275717 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12310253083705902
[5/24] Train loss=0.11328332126140594
[10/24] Train loss=0.1192493811249733
[15/24] Train loss=0.1219448521733284
[20/24] Train loss=0.10791650414466858
Test set avg_accuracy=89.23% avg_sensitivity=75.82%, avg_specificity=93.74% avg_auc=93.36%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.122102 Test loss=0.276110 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12119168788194656
[5/24] Train loss=0.11326586455106735
[10/24] Train loss=0.11593973636627197
[15/24] Train loss=0.12487929314374924
[20/24] Train loss=0.10843665152788162
Test set avg_accuracy=89.28% avg_sensitivity=77.32%, avg_specificity=93.30% avg_auc=93.43%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.121651 Test loss=0.275686 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.11989931017160416
[5/24] Train loss=0.11132125556468964
[10/24] Train loss=0.11770287156105042
[15/24] Train loss=0.12233326584100723
[20/24] Train loss=0.11363716423511505
Test set avg_accuracy=89.18% avg_sensitivity=76.70%, avg_specificity=93.37% avg_auc=93.45%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.120962 Test loss=0.275427 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.120794877409935
[5/24] Train loss=0.11042202264070511
[10/24] Train loss=0.11639063060283661
[15/24] Train loss=0.12289291620254517
[20/24] Train loss=0.11076559126377106
Test set avg_accuracy=89.35% avg_sensitivity=77.27%, avg_specificity=93.41% avg_auc=93.41%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.121203 Test loss=0.275809 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12122631818056107
[5/24] Train loss=0.11230713129043579
[10/24] Train loss=0.1156935915350914
[15/24] Train loss=0.12335402518510818
[20/24] Train loss=0.11029130965471268
Test set avg_accuracy=89.19% avg_sensitivity=76.13%, avg_specificity=93.58% avg_auc=93.28%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.120819 Test loss=0.276823 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12130071967840195
[5/24] Train loss=0.11092019081115723
[10/24] Train loss=0.11457148939371109
[15/24] Train loss=0.12062788754701614
[20/24] Train loss=0.11007904261350632
Test set avg_accuracy=89.18% avg_sensitivity=76.49%, avg_specificity=93.44% avg_auc=93.38%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.120439 Test loss=0.275504 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12255027890205383
[5/24] Train loss=0.11139786243438721
[10/24] Train loss=0.11541473865509033
[15/24] Train loss=0.12269844114780426
[20/24] Train loss=0.11126077175140381
Test set avg_accuracy=89.13% avg_sensitivity=76.39%, avg_specificity=93.41% avg_auc=93.32%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.120293 Test loss=0.276535 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1224609911441803
[5/24] Train loss=0.11141945421695709
[10/24] Train loss=0.11483967304229736
[15/24] Train loss=0.12408069521188736
[20/24] Train loss=0.11037102341651917
Test set avg_accuracy=89.27% avg_sensitivity=76.90%, avg_specificity=93.42% avg_auc=93.36%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.120690 Test loss=0.275739 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12186244875192642
[5/24] Train loss=0.11047840118408203
[10/24] Train loss=0.1144331619143486
[15/24] Train loss=0.1223946288228035
[20/24] Train loss=0.10944004356861115
Test set avg_accuracy=89.28% avg_sensitivity=76.59%, avg_specificity=93.55% avg_auc=93.39%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.119671 Test loss=0.275184 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12178389728069305
[5/24] Train loss=0.10995109379291534
[10/24] Train loss=0.11569197475910187
[15/24] Train loss=0.12250978499650955
[20/24] Train loss=0.10705309361219406
Test set avg_accuracy=89.31% avg_sensitivity=76.59%, avg_specificity=93.58% avg_auc=93.39%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.120027 Test loss=0.275309 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12031237781047821
[5/24] Train loss=0.11088495701551437
[10/24] Train loss=0.11571212112903595
[15/24] Train loss=0.12224674224853516
[20/24] Train loss=0.10754024982452393
Test set avg_accuracy=89.24% avg_sensitivity=76.59%, avg_specificity=93.49% avg_auc=93.40%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.120340 Test loss=0.275256 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12034014612436295
[5/24] Train loss=0.11217696964740753
[10/24] Train loss=0.11405277997255325
[15/24] Train loss=0.12145007401704788
[20/24] Train loss=0.10978589951992035
Test set avg_accuracy=89.28% avg_sensitivity=76.54%, avg_specificity=93.56% avg_auc=93.40%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.119644 Test loss=0.275035 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12136723846197128
[5/24] Train loss=0.11052889376878738
[10/24] Train loss=0.11650516837835312
[15/24] Train loss=0.12042597681283951
[20/24] Train loss=0.10832184553146362
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=89.27% avg_sensitivity=76.59%, avg_specificity=93.53% avg_auc=93.40%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.120457 Test loss=0.275113 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=89.67% sen=78.25%, spe=93.51%, auc=94.46%!
Fold[8] Avg_overlap=0.71%(0.22528890778073624)
[0/23] Train loss=0.7345878481864929
[5/23] Train loss=0.7222955226898193
[10/23] Train loss=0.7201340198516846
[15/23] Train loss=0.714280366897583
[20/23] Train loss=0.703433632850647
Test set avg_accuracy=60.52% avg_sensitivity=46.25%, avg_specificity=65.06% avg_auc=58.01%
Best model saved!! Metric=-96.15614918694013!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.718389 Test loss=0.672538 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.7026084065437317
[5/23] Train loss=0.7025259733200073
[10/23] Train loss=0.6930080652236938
[15/23] Train loss=0.6905498504638672
[20/23] Train loss=0.6759368777275085
Test set avg_accuracy=63.40% avg_sensitivity=58.98%, avg_specificity=64.81% avg_auc=68.04%
Best model saved!! Metric=-70.7816349176625!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.691443 Test loss=0.639688 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.6679785251617432
[5/23] Train loss=0.6668411493301392
[10/23] Train loss=0.6676620841026306
[15/23] Train loss=0.6654026508331299
[20/23] Train loss=0.6472111344337463
Test set avg_accuracy=67.27% avg_sensitivity=62.53%, avg_specificity=68.77% avg_auc=72.47%
Best model saved!! Metric=-54.96039677157202!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.664950 Test loss=0.605711 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.6548799276351929
[5/23] Train loss=0.6475040316581726
[10/23] Train loss=0.6434685587882996
[15/23] Train loss=0.6206740140914917
[20/23] Train loss=0.6217472553253174
Test set avg_accuracy=70.17% avg_sensitivity=66.95%, avg_specificity=71.19% avg_auc=76.51%
Best model saved!! Metric=-41.17537939861144!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.641808 Test loss=0.581693 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.6156119704246521
[5/23] Train loss=0.6164140105247498
[10/23] Train loss=0.6216536164283752
[15/23] Train loss=0.601027250289917
[20/23] Train loss=0.5943456292152405
Test set avg_accuracy=72.37% avg_sensitivity=73.58%, avg_specificity=71.98% avg_auc=79.64%
Best model saved!! Metric=-28.4198847675154!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.612116 Test loss=0.560184 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.5886188745498657
[5/23] Train loss=0.5910280346870422
[10/23] Train loss=0.596295952796936
[15/23] Train loss=0.5722193121910095
[20/23] Train loss=0.5682021975517273
Test set avg_accuracy=73.95% avg_sensitivity=76.06%, avg_specificity=73.27% avg_auc=81.82%
Best model saved!! Metric=-20.89941523966661!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.584196 Test loss=0.538420 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.5634464621543884
[5/23] Train loss=0.5658679008483887
[10/23] Train loss=0.5683865547180176
[15/23] Train loss=0.5426715016365051
[20/23] Train loss=0.538003146648407
Test set avg_accuracy=76.03% avg_sensitivity=77.68%, avg_specificity=75.50% avg_auc=84.02%
Best model saved!! Metric=-12.766129914847554!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.557020 Test loss=0.507528 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.530612051486969
[5/23] Train loss=0.5312218070030212
[10/23] Train loss=0.5355587005615234
[15/23] Train loss=0.5197582244873047
[20/23] Train loss=0.5087478756904602
Test set avg_accuracy=78.03% avg_sensitivity=78.87%, avg_specificity=77.77% avg_auc=86.43%
Best model saved!! Metric=-4.897982997707544!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.528453 Test loss=0.476792 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.5050003528594971
[5/23] Train loss=0.5015566945075989
[10/23] Train loss=0.5045446753501892
[15/23] Train loss=0.48459550738334656
[20/23] Train loss=0.47900819778442383
Test set avg_accuracy=81.29% avg_sensitivity=77.57%, avg_specificity=82.47% avg_auc=88.12%
Best model saved!! Metric=3.456840110679863!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.497799 Test loss=0.443061 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.47444501519203186
[5/23] Train loss=0.47306719422340393
[10/23] Train loss=0.47827619314193726
[15/23] Train loss=0.4587591290473938
[20/23] Train loss=0.4460146129131317
Test set avg_accuracy=83.78% avg_sensitivity=75.31%, avg_specificity=86.47% avg_auc=89.79%
Best model saved!! Metric=9.34574655890782!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.468496 Test loss=0.410742 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.4402864873409271
[5/23] Train loss=0.4455154538154602
[10/23] Train loss=0.4508175849914551
[15/23] Train loss=0.4288891553878784
[20/23] Train loss=0.417352557182312
Test set avg_accuracy=85.61% avg_sensitivity=73.53%, avg_specificity=89.46% avg_auc=90.78%
Best model saved!! Metric=13.382907986814033!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.440289 Test loss=0.382977 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.4173766076564789
[5/23] Train loss=0.41588103771209717
[10/23] Train loss=0.42370903491973877
[15/23] Train loss=0.40397390723228455
[20/23] Train loss=0.3866356611251831
Test set avg_accuracy=86.86% avg_sensitivity=71.37%, avg_specificity=91.79% avg_auc=91.31%
Best model saved!! Metric=15.342346576404893!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.414366 Test loss=0.357137 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.3919927179813385
[5/23] Train loss=0.3888833522796631
[10/23] Train loss=0.4056515097618103
[15/23] Train loss=0.3824220299720764
[20/23] Train loss=0.3671196401119232
Test set avg_accuracy=87.41% avg_sensitivity=65.28%, avg_specificity=94.45% avg_auc=91.67%
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.392362 Test loss=0.337996 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.37470999360084534
[5/23] Train loss=0.3690232038497925
[10/23] Train loss=0.38891100883483887
[15/23] Train loss=0.3653450310230255
[20/23] Train loss=0.3446684777736664
Test set avg_accuracy=88.32% avg_sensitivity=68.25%, avg_specificity=94.71% avg_auc=92.26%
Best model saved!! Metric=17.53667472713235!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.372786 Test loss=0.323231 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.35042816400527954
[5/23] Train loss=0.34477055072784424
[10/23] Train loss=0.3712071180343628
[15/23] Train loss=0.3389541208744049
[20/23] Train loss=0.325618177652359
Test set avg_accuracy=88.50% avg_sensitivity=72.24%, avg_specificity=93.68% avg_auc=92.73%
Best model saved!! Metric=21.15024018115021!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.354534 Test loss=0.311701 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.3397482633590698
[5/23] Train loss=0.3215872645378113
[10/23] Train loss=0.35650280117988586
[15/23] Train loss=0.332743376493454
[20/23] Train loss=0.30848968029022217
Test set avg_accuracy=88.41% avg_sensitivity=72.61%, avg_specificity=93.44% avg_auc=92.98%
Best model saved!! Metric=21.444448858881984!!
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.340353 Test loss=0.305586 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.32483401894569397
[5/23] Train loss=0.3117334842681885
[10/23] Train loss=0.34722113609313965
[15/23] Train loss=0.31461232900619507
[20/23] Train loss=0.2942500412464142
Test set avg_accuracy=88.63% avg_sensitivity=71.05%, avg_specificity=94.23% avg_auc=93.01%
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.327331 Test loss=0.297121 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.30640721321105957
[5/23] Train loss=0.30036598443984985
[10/23] Train loss=0.33930593729019165
[15/23] Train loss=0.3009469509124756
[20/23] Train loss=0.28783121705055237
Test set avg_accuracy=88.78% avg_sensitivity=71.97%, avg_specificity=94.13% avg_auc=93.04%
Best model saved!! Metric=21.912693564449015!!
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.317681 Test loss=0.291822 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.30103951692581177
[5/23] Train loss=0.2880127727985382
[10/23] Train loss=0.3275187015533447
[15/23] Train loss=0.2929719388484955
[20/23] Train loss=0.27684271335601807
Test set avg_accuracy=89.04% avg_sensitivity=72.88%, avg_specificity=94.18% avg_auc=93.51%
Best model saved!! Metric=23.60848845723001!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.308086 Test loss=0.280848 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.2890382409095764
[5/23] Train loss=0.2768973112106323
[10/23] Train loss=0.32412034273147583
[15/23] Train loss=0.2852715253829956
[20/23] Train loss=0.26593610644340515
Test set avg_accuracy=89.36% avg_sensitivity=67.55%, avg_specificity=96.31% avg_auc=93.20%
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.298765 Test loss=0.280884 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.28406110405921936
[5/23] Train loss=0.26679787039756775
[10/23] Train loss=0.31285712122917175
[15/23] Train loss=0.2732788324356079
[20/23] Train loss=0.25923481583595276
Test set avg_accuracy=89.23% avg_sensitivity=66.31%, avg_specificity=96.53% avg_auc=93.30%
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.293088 Test loss=0.277524 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.2817082107067108
[5/23] Train loss=0.266633003950119
[10/23] Train loss=0.3063295781612396
[15/23] Train loss=0.26924267411231995
[20/23] Train loss=0.2577085494995117
Test set avg_accuracy=89.65% avg_sensitivity=71.81%, avg_specificity=95.33% avg_auc=94.00%
Best model saved!! Metric=24.78758352686164!!
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.285934 Test loss=0.264664 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.2703849971294403
[5/23] Train loss=0.2609821557998657
[10/23] Train loss=0.3015872538089752
[15/23] Train loss=0.2614828050136566
[20/23] Train loss=0.2496529072523117
Test set avg_accuracy=89.58% avg_sensitivity=65.34%, avg_specificity=97.30% avg_auc=93.64%
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.279317 Test loss=0.271561 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.2617587149143219
[5/23] Train loss=0.2520921230316162
[10/23] Train loss=0.2970779538154602
[15/23] Train loss=0.25468042492866516
[20/23] Train loss=0.23648309707641602
Test set avg_accuracy=90.05% avg_sensitivity=71.81%, avg_specificity=95.86% avg_auc=94.28%
Best model saved!! Metric=25.99920224406064!!
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.273397 Test loss=0.260847 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.26341456174850464
[5/23] Train loss=0.2524997889995575
[10/23] Train loss=0.292765736579895
[15/23] Train loss=0.24968162178993225
[20/23] Train loss=0.23434121906757355
Test set avg_accuracy=90.14% avg_sensitivity=74.02%, avg_specificity=95.28% avg_auc=94.33%
Best model saved!! Metric=27.773033777797707!!
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.268782 Test loss=0.258663 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.26035284996032715
[5/23] Train loss=0.2341214269399643
[10/23] Train loss=0.2798444330692291
[15/23] Train loss=0.24613727629184723
[20/23] Train loss=0.230207160115242
Test set avg_accuracy=90.17% avg_sensitivity=71.11%, avg_specificity=96.24% avg_auc=94.30%
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.262036 Test loss=0.256121 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.25162434577941895
[5/23] Train loss=0.235622838139534
[10/23] Train loss=0.27643489837646484
[15/23] Train loss=0.2402227520942688
[20/23] Train loss=0.22051574289798737
Test set avg_accuracy=90.01% avg_sensitivity=74.50%, avg_specificity=94.95% avg_auc=94.73%
Best model saved!! Metric=28.19803060856094!!
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.257500 Test loss=0.250221 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.24637331068515778
[5/23] Train loss=0.22280240058898926
[10/23] Train loss=0.2677854597568512
[15/23] Train loss=0.23907636106014252
[20/23] Train loss=0.22355055809020996
Test set avg_accuracy=90.52% avg_sensitivity=74.29%, avg_specificity=95.69% avg_auc=94.53%
Best model saved!! Metric=29.025924549510464!!
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.252184 Test loss=0.247408 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.24051959812641144
[5/23] Train loss=0.22052185237407684
[10/23] Train loss=0.26593518257141113
[15/23] Train loss=0.23339693248271942
[20/23] Train loss=0.21404998004436493
Test set avg_accuracy=90.08% avg_sensitivity=68.14%, avg_specificity=97.06% avg_auc=93.83%
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.247537 Test loss=0.260576 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.23346984386444092
[5/23] Train loss=0.21380501985549927
[10/23] Train loss=0.2616199254989624
[15/23] Train loss=0.22817860543727875
[20/23] Train loss=0.21519576013088226
Test set avg_accuracy=89.36% avg_sensitivity=68.95%, avg_specificity=95.86% avg_auc=93.73%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.243926 Test loss=0.266007 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.231728658080101
[5/23] Train loss=0.21282416582107544
[10/23] Train loss=0.26734820008277893
[15/23] Train loss=0.2291790395975113
[20/23] Train loss=0.20849622786045074
Test set avg_accuracy=89.78% avg_sensitivity=79.03%, avg_specificity=93.20% avg_auc=94.40%
Best model saved!! Metric=30.410345334738892!!
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.241127 Test loss=0.255508 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.2276274412870407
[5/23] Train loss=0.22183012962341309
[10/23] Train loss=0.2581325173377991
[15/23] Train loss=0.2252856343984604
[20/23] Train loss=0.1967407912015915
Test set avg_accuracy=90.09% avg_sensitivity=77.74%, avg_specificity=94.03% avg_auc=94.69%
Best model saved!! Metric=30.540917359078634!!
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.236134 Test loss=0.246751 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.2172282189130783
[5/23] Train loss=0.200006365776062
[10/23] Train loss=0.2538105547428131
[15/23] Train loss=0.22415898740291595
[20/23] Train loss=0.21455025672912598
Test set avg_accuracy=88.05% avg_sensitivity=57.04%, avg_specificity=97.92% avg_auc=92.10%
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.234331 Test loss=0.297362 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.2240654081106186
[5/23] Train loss=0.2156527042388916
[10/23] Train loss=0.2571108639240265
[15/23] Train loss=0.2194652408361435
[20/23] Train loss=0.20914524793624878
Test set avg_accuracy=90.05% avg_sensitivity=69.38%, avg_specificity=96.64% avg_auc=93.93%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.234020 Test loss=0.255689 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.22898094356060028
[5/23] Train loss=0.19092166423797607
[10/23] Train loss=0.25441038608551025
[15/23] Train loss=0.2210344523191452
[20/23] Train loss=0.19916263222694397
Test set avg_accuracy=89.24% avg_sensitivity=63.99%, avg_specificity=97.29% avg_auc=92.80%
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.227958 Test loss=0.276294 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.2250102013349533
[5/23] Train loss=0.18640512228012085
[10/23] Train loss=0.24484553933143616
[15/23] Train loss=0.22847223281860352
[20/23] Train loss=0.19940243661403656
Test set avg_accuracy=84.15% avg_sensitivity=36.39%, avg_specificity=99.36% avg_auc=86.32%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.228860 Test loss=0.420214 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.21551565825939178
[5/23] Train loss=0.19814419746398926
[10/23] Train loss=0.25203999876976013
[15/23] Train loss=0.22172477841377258
[20/23] Train loss=0.19386792182922363
Test set avg_accuracy=89.58% avg_sensitivity=75.74%, avg_specificity=93.99% avg_auc=94.34%
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.226424 Test loss=0.253210 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.21303240954875946
[5/23] Train loss=0.17850320041179657
[10/23] Train loss=0.23225650191307068
[15/23] Train loss=0.21930332481861115
[20/23] Train loss=0.1930566281080246
Test set avg_accuracy=89.86% avg_sensitivity=76.60%, avg_specificity=94.08% avg_auc=94.08%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.220462 Test loss=0.255906 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.2053183913230896
[5/23] Train loss=0.18829359114170074
[10/23] Train loss=0.23082362115383148
[15/23] Train loss=0.23086164891719818
[20/23] Train loss=0.1989445835351944
Test set avg_accuracy=89.36% avg_sensitivity=65.66%, avg_specificity=96.91% avg_auc=94.48%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.221227 Test loss=0.257615 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.21060089766979218
[5/23] Train loss=0.17916056513786316
[10/23] Train loss=0.22737257182598114
[15/23] Train loss=0.21030041575431824
[20/23] Train loss=0.19377313554286957
Test set avg_accuracy=90.35% avg_sensitivity=76.66%, avg_specificity=94.71% avg_auc=94.77%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.218256 Test loss=0.240656 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.2101384401321411
[5/23] Train loss=0.1751447468996048
[10/23] Train loss=0.2304454743862152
[15/23] Train loss=0.20417992770671844
[20/23] Train loss=0.1924894154071808
Test set avg_accuracy=80.79% avg_sensitivity=88.89%, avg_specificity=78.21% avg_auc=91.38%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.215063 Test loss=0.413594 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.2152782529592514
[5/23] Train loss=0.18098734319210052
[10/23] Train loss=0.24029125273227692
[15/23] Train loss=0.2267676740884781
[20/23] Train loss=0.1869247853755951
Test set avg_accuracy=88.78% avg_sensitivity=74.07%, avg_specificity=93.46% avg_auc=93.12%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.220012 Test loss=0.274361 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.20815971493721008
[5/23] Train loss=0.1800168752670288
[10/23] Train loss=0.2149479240179062
[15/23] Train loss=0.21098464727401733
[20/23] Train loss=0.19661010801792145
Test set avg_accuracy=87.17% avg_sensitivity=85.34%, avg_specificity=87.76% avg_auc=94.19%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.213597 Test loss=0.297511 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.2102544903755188
[5/23] Train loss=0.18760433793067932
[10/23] Train loss=0.19754964113235474
[15/23] Train loss=0.2090686857700348
[20/23] Train loss=0.18926605582237244
Test set avg_accuracy=89.01% avg_sensitivity=77.30%, avg_specificity=92.74% avg_auc=93.76%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.207634 Test loss=0.268656 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.19530290365219116
[5/23] Train loss=0.16815686225891113
[10/23] Train loss=0.20942702889442444
[15/23] Train loss=0.21013805270195007
[20/23] Train loss=0.19586960971355438
Test set avg_accuracy=89.54% avg_sensitivity=75.63%, avg_specificity=93.97% avg_auc=94.07%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.206730 Test loss=0.254536 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.21745824813842773
[5/23] Train loss=0.1624772697687149
[10/23] Train loss=0.20614024996757507
[15/23] Train loss=0.20510947704315186
[20/23] Train loss=0.1800709217786789
Test set avg_accuracy=90.23% avg_sensitivity=75.53%, avg_specificity=94.92% avg_auc=94.73%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.204697 Test loss=0.240080 Current lr=[0.000299926900870094]

[0/23] Train loss=0.19777105748653412
[5/23] Train loss=0.1636877804994583
[10/23] Train loss=0.21104250848293304
[15/23] Train loss=0.2149639129638672
[20/23] Train loss=0.18372602760791779
Test set avg_accuracy=86.88% avg_sensitivity=83.13%, avg_specificity=88.07% avg_auc=93.76%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.199397 Test loss=0.299163 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.18702758848667145
[5/23] Train loss=0.16933251917362213
[10/23] Train loss=0.19348323345184326
[15/23] Train loss=0.19909420609474182
[20/23] Train loss=0.17690671980381012
Test set avg_accuracy=89.36% avg_sensitivity=66.36%, avg_specificity=96.69% avg_auc=93.18%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.199528 Test loss=0.272109 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.18663044273853302
[5/23] Train loss=0.15473264455795288
[10/23] Train loss=0.1905352920293808
[15/23] Train loss=0.20559284090995789
[20/23] Train loss=0.18459820747375488
Test set avg_accuracy=89.88% avg_sensitivity=68.19%, avg_specificity=96.79% avg_auc=93.13%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.200659 Test loss=0.267503 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.18374109268188477
[5/23] Train loss=0.17189647257328033
[10/23] Train loss=0.1852685958147049
[15/23] Train loss=0.2113962471485138
[20/23] Train loss=0.17365136742591858
Test set avg_accuracy=87.23% avg_sensitivity=79.14%, avg_specificity=89.80% avg_auc=93.29%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.200659 Test loss=0.290075 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.18717512488365173
[5/23] Train loss=0.17013731598854065
[10/23] Train loss=0.18758772313594818
[15/23] Train loss=0.21074210107326508
[20/23] Train loss=0.17516030371189117
Test set avg_accuracy=88.48% avg_sensitivity=76.33%, avg_specificity=92.34% avg_auc=93.22%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.199166 Test loss=0.281119 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.19021479785442352
[5/23] Train loss=0.15406879782676697
[10/23] Train loss=0.18992745876312256
[15/23] Train loss=0.20158593356609344
[20/23] Train loss=0.17410069704055786
Test set avg_accuracy=89.71% avg_sensitivity=68.84%, avg_specificity=96.36% avg_auc=93.29%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.192507 Test loss=0.268047 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.18642368912696838
[5/23] Train loss=0.17125572264194489
[10/23] Train loss=0.1826159507036209
[15/23] Train loss=0.20065519213676453
[20/23] Train loss=0.17177176475524902
Test set avg_accuracy=87.86% avg_sensitivity=74.88%, avg_specificity=92.00% avg_auc=92.90%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.193035 Test loss=0.286876 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.17997309565544128
[5/23] Train loss=0.1594444066286087
[10/23] Train loss=0.1969042420387268
[15/23] Train loss=0.19788387417793274
[20/23] Train loss=0.17416176199913025
Test set avg_accuracy=85.34% avg_sensitivity=82.37%, avg_specificity=86.28% avg_auc=92.66%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.196894 Test loss=0.328717 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.19820089638233185
[5/23] Train loss=0.16217830777168274
[10/23] Train loss=0.1819075345993042
[15/23] Train loss=0.21264539659023285
[20/23] Train loss=0.1770983189344406
Test set avg_accuracy=88.63% avg_sensitivity=73.75%, avg_specificity=93.37% avg_auc=92.57%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.192522 Test loss=0.282161 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.18449440598487854
[5/23] Train loss=0.16489923000335693
[10/23] Train loss=0.21046383678913116
[15/23] Train loss=0.1967373937368393
[20/23] Train loss=0.18020759522914886
Test set avg_accuracy=89.53% avg_sensitivity=74.07%, avg_specificity=94.45% avg_auc=93.15%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.195389 Test loss=0.270940 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.1850314885377884
[5/23] Train loss=0.16820910573005676
[10/23] Train loss=0.18447506427764893
[15/23] Train loss=0.19302798807621002
[20/23] Train loss=0.15993274748325348
Test set avg_accuracy=87.90% avg_sensitivity=55.74%, avg_specificity=98.15% avg_auc=91.00%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.188189 Test loss=0.327951 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.17461109161376953
[5/23] Train loss=0.15747058391571045
[10/23] Train loss=0.17502476274967194
[15/23] Train loss=0.19672781229019165
[20/23] Train loss=0.16752630472183228
Test set avg_accuracy=87.47% avg_sensitivity=52.83%, avg_specificity=98.51% avg_auc=89.27%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.181524 Test loss=0.354426 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.18153299391269684
[5/23] Train loss=0.1593136489391327
[10/23] Train loss=0.2054756134748459
[15/23] Train loss=0.19817639887332916
[20/23] Train loss=0.16557897627353668
Test set avg_accuracy=89.62% avg_sensitivity=73.48%, avg_specificity=94.76% avg_auc=93.20%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.189547 Test loss=0.264931 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.18436390161514282
[5/23] Train loss=0.16382277011871338
[10/23] Train loss=0.17471837997436523
[15/23] Train loss=0.17618237435817719
[20/23] Train loss=0.16446273028850555
Test set avg_accuracy=86.41% avg_sensitivity=50.73%, avg_specificity=97.77% avg_auc=87.48%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.182834 Test loss=0.363417 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.177545964717865
[5/23] Train loss=0.15746991336345673
[10/23] Train loss=0.1723908931016922
[15/23] Train loss=0.1951068937778473
[20/23] Train loss=0.17054656147956848
Test set avg_accuracy=87.15% avg_sensitivity=65.82%, avg_specificity=93.94% avg_auc=89.85%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.181875 Test loss=0.319214 Current lr=[0.000283047938381597]

[0/23] Train loss=0.19176022708415985
[5/23] Train loss=0.15678295493125916
[10/23] Train loss=0.18243321776390076
[15/23] Train loss=0.18764148652553558
[20/23] Train loss=0.1760251820087433
Test set avg_accuracy=88.44% avg_sensitivity=76.66%, avg_specificity=92.19% avg_auc=93.55%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.184994 Test loss=0.274569 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.18399006128311157
[5/23] Train loss=0.15974397957324982
[10/23] Train loss=0.17234961688518524
[15/23] Train loss=0.1824854612350464
[20/23] Train loss=0.1694040447473526
Test set avg_accuracy=86.38% avg_sensitivity=83.07%, avg_specificity=87.43% avg_auc=92.71%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.181205 Test loss=0.317960 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.1764751821756363
[5/23] Train loss=0.1564370095729828
[10/23] Train loss=0.18957892060279846
[15/23] Train loss=0.17172007262706757
[20/23] Train loss=0.15766246616840363
Test set avg_accuracy=88.61% avg_sensitivity=70.19%, avg_specificity=94.47% avg_auc=91.29%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.179989 Test loss=0.299185 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.16964639723300934
[5/23] Train loss=0.15015345811843872
[10/23] Train loss=0.18551436066627502
[15/23] Train loss=0.19649896025657654
[20/23] Train loss=0.16135628521442413
Test set avg_accuracy=88.50% avg_sensitivity=75.04%, avg_specificity=92.79% avg_auc=93.21%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.181307 Test loss=0.276140 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.17740261554718018
[5/23] Train loss=0.1531965434551239
[10/23] Train loss=0.17843444645404816
[15/23] Train loss=0.1787497103214264
[20/23] Train loss=0.1499207317829132
Test set avg_accuracy=88.92% avg_sensitivity=70.13%, avg_specificity=94.90% avg_auc=93.29%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.175814 Test loss=0.272455 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.1679724007844925
[5/23] Train loss=0.1405874341726303
[10/23] Train loss=0.17050427198410034
[15/23] Train loss=0.1679738312959671
[20/23] Train loss=0.15849211812019348
Test set avg_accuracy=89.04% avg_sensitivity=71.86%, avg_specificity=94.51% avg_auc=92.25%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.172598 Test loss=0.282951 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.17487645149230957
[5/23] Train loss=0.14555762708187103
[10/23] Train loss=0.17589357495307922
[15/23] Train loss=0.17219364643096924
[20/23] Train loss=0.15567877888679504
Test set avg_accuracy=87.50% avg_sensitivity=75.36%, avg_specificity=91.36% avg_auc=92.43%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.172703 Test loss=0.296291 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.1716424524784088
[5/23] Train loss=0.15296421945095062
[10/23] Train loss=0.16911302506923676
[15/23] Train loss=0.1741623878479004
[20/23] Train loss=0.162308007478714
Test set avg_accuracy=87.47% avg_sensitivity=61.02%, avg_specificity=95.90% avg_auc=88.99%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.173987 Test loss=0.328049 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.1677362471818924
[5/23] Train loss=0.14743398129940033
[10/23] Train loss=0.16518501937389374
[15/23] Train loss=0.17918695509433746
[20/23] Train loss=0.16521768271923065
Test set avg_accuracy=88.57% avg_sensitivity=62.26%, avg_specificity=96.94% avg_auc=90.81%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.171501 Test loss=0.303578 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.16678376495838165
[5/23] Train loss=0.1564759612083435
[10/23] Train loss=0.1763419806957245
[15/23] Train loss=0.16704051196575165
[20/23] Train loss=0.164481982588768
Test set avg_accuracy=87.93% avg_sensitivity=56.39%, avg_specificity=97.97% avg_auc=89.95%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.176117 Test loss=0.332641 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.15874090790748596
[5/23] Train loss=0.1477448046207428
[10/23] Train loss=0.16013209521770477
[15/23] Train loss=0.16281233727931976
[20/23] Train loss=0.15701277554035187
Test set avg_accuracy=84.35% avg_sensitivity=37.74%, avg_specificity=99.19% avg_auc=82.79%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.169567 Test loss=0.466932 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.18701297044754028
[5/23] Train loss=0.14994415640830994
[10/23] Train loss=0.1740075796842575
[15/23] Train loss=0.16724613308906555
[20/23] Train loss=0.15367773175239563
Test set avg_accuracy=87.84% avg_sensitivity=59.84%, avg_specificity=96.76% avg_auc=89.23%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.173806 Test loss=0.325003 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.1677703857421875
[5/23] Train loss=0.1485358029603958
[10/23] Train loss=0.1706308126449585
[15/23] Train loss=0.16337735950946808
[20/23] Train loss=0.15202035009860992
Test set avg_accuracy=88.06% avg_sensitivity=68.73%, avg_specificity=94.21% avg_auc=91.09%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.169776 Test loss=0.303089 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.16633804142475128
[5/23] Train loss=0.13862244784832
[10/23] Train loss=0.17025357484817505
[15/23] Train loss=0.1701209843158722
[20/23] Train loss=0.14937597513198853
Test set avg_accuracy=88.22% avg_sensitivity=59.46%, avg_specificity=97.37% avg_auc=89.57%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.169011 Test loss=0.325281 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.1737297922372818
[5/23] Train loss=0.14405208826065063
[10/23] Train loss=0.15857838094234467
[15/23] Train loss=0.16113030910491943
[20/23] Train loss=0.15171340107917786
Test set avg_accuracy=88.46% avg_sensitivity=68.63%, avg_specificity=94.78% avg_auc=91.31%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.168172 Test loss=0.297295 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.16110916435718536
[5/23] Train loss=0.14587444067001343
[10/23] Train loss=0.168130561709404
[15/23] Train loss=0.1625738888978958
[20/23] Train loss=0.1467902511358261
Test set avg_accuracy=84.79% avg_sensitivity=79.30%, avg_specificity=86.54% avg_auc=91.70%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.167135 Test loss=0.344029 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.16244329512119293
[5/23] Train loss=0.1457364857196808
[10/23] Train loss=0.15866391360759735
[15/23] Train loss=0.1656552255153656
[20/23] Train loss=0.15491726994514465
Test set avg_accuracy=88.55% avg_sensitivity=68.41%, avg_specificity=94.97% avg_auc=91.51%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.170913 Test loss=0.294389 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.16592681407928467
[5/23] Train loss=0.14478354156017303
[10/23] Train loss=0.1688503921031952
[15/23] Train loss=0.16100908815860748
[20/23] Train loss=0.1483893245458603
Test set avg_accuracy=86.95% avg_sensitivity=56.33%, avg_specificity=96.70% avg_auc=88.38%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.169509 Test loss=0.348063 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.16832174360752106
[5/23] Train loss=0.1451101005077362
[10/23] Train loss=0.1699148267507553
[15/23] Train loss=0.16547906398773193
[20/23] Train loss=0.15264002978801727
Test set avg_accuracy=88.79% avg_sensitivity=65.12%, avg_specificity=96.33% avg_auc=92.11%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.169888 Test loss=0.286033 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.15671807527542114
[5/23] Train loss=0.14223943650722504
[10/23] Train loss=0.16199758648872375
[15/23] Train loss=0.16468545794487
[20/23] Train loss=0.1583881825208664
Test set avg_accuracy=88.18% avg_sensitivity=60.05%, avg_specificity=97.13% avg_auc=90.73%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.167613 Test loss=0.308219 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.1607239842414856
[5/23] Train loss=0.14297430217266083
[10/23] Train loss=0.17461098730564117
[15/23] Train loss=0.1758367270231247
[20/23] Train loss=0.15535102784633636
Test set avg_accuracy=87.17% avg_sensitivity=79.57%, avg_specificity=89.60% avg_auc=92.35%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.169462 Test loss=0.307662 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.16303826868534088
[5/23] Train loss=0.13968761265277863
[10/23] Train loss=0.16575394570827484
[15/23] Train loss=0.16074883937835693
[20/23] Train loss=0.15581895411014557
Test set avg_accuracy=87.64% avg_sensitivity=82.48%, avg_specificity=89.29% avg_auc=93.20%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.166192 Test loss=0.298742 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.16828817129135132
[5/23] Train loss=0.1429564654827118
[10/23] Train loss=0.18461565673351288
[15/23] Train loss=0.16671068966388702
[20/23] Train loss=0.1477295160293579
Test set avg_accuracy=87.25% avg_sensitivity=76.98%, avg_specificity=90.52% avg_auc=91.86%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.169077 Test loss=0.306799 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.16833043098449707
[5/23] Train loss=0.14604972302913666
[10/23] Train loss=0.1686324179172516
[15/23] Train loss=0.1562204509973526
[20/23] Train loss=0.1524457037448883
Test set avg_accuracy=88.09% avg_sensitivity=75.63%, avg_specificity=92.05% avg_auc=92.72%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.169182 Test loss=0.291091 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.1663433462381363
[5/23] Train loss=0.15037743747234344
[10/23] Train loss=0.16212035715579987
[15/23] Train loss=0.164459228515625
[20/23] Train loss=0.14669638872146606
Test set avg_accuracy=88.06% avg_sensitivity=64.80%, avg_specificity=95.47% avg_auc=90.70%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.166292 Test loss=0.307909 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.16150517761707306
[5/23] Train loss=0.14178067445755005
[10/23] Train loss=0.1475604623556137
[15/23] Train loss=0.15871798992156982
[20/23] Train loss=0.1391058713197708
Test set avg_accuracy=89.17% avg_sensitivity=69.00%, avg_specificity=95.59% avg_auc=92.36%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.163009 Test loss=0.283436 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.15495377779006958
[5/23] Train loss=0.1366870403289795
[10/23] Train loss=0.15422649681568146
[15/23] Train loss=0.15652339160442352
[20/23] Train loss=0.13880851864814758
Test set avg_accuracy=89.54% avg_sensitivity=70.73%, avg_specificity=95.54% avg_auc=91.89%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.159529 Test loss=0.283670 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.15629270672798157
[5/23] Train loss=0.1393122375011444
[10/23] Train loss=0.148333340883255
[15/23] Train loss=0.14960406720638275
[20/23] Train loss=0.14182744920253754
Test set avg_accuracy=88.76% avg_sensitivity=66.52%, avg_specificity=95.85% avg_auc=91.72%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.156251 Test loss=0.290902 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.1511305272579193
[5/23] Train loss=0.1376136690378189
[10/23] Train loss=0.16081540286540985
[15/23] Train loss=0.1502106636762619
[20/23] Train loss=0.1450567990541458
Test set avg_accuracy=88.03% avg_sensitivity=66.36%, avg_specificity=94.94% avg_auc=90.93%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.155799 Test loss=0.304529 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.15922649204730988
[5/23] Train loss=0.14237593114376068
[10/23] Train loss=0.15260210633277893
[15/23] Train loss=0.14780423045158386
[20/23] Train loss=0.13551954925060272
Test set avg_accuracy=87.45% avg_sensitivity=59.08%, avg_specificity=96.48% avg_auc=89.62%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.155770 Test loss=0.323467 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.15770982205867767
[5/23] Train loss=0.13936026394367218
[10/23] Train loss=0.14970624446868896
[15/23] Train loss=0.14897260069847107
[20/23] Train loss=0.13758954405784607
Test set avg_accuracy=89.24% avg_sensitivity=65.93%, avg_specificity=96.67% avg_auc=91.13%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.152049 Test loss=0.290011 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.15183483064174652
[5/23] Train loss=0.1355820745229721
[10/23] Train loss=0.13989487290382385
[15/23] Train loss=0.14366979897022247
[20/23] Train loss=0.13604354858398438
Test set avg_accuracy=88.98% avg_sensitivity=75.09%, avg_specificity=93.41% avg_auc=92.03%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.149895 Test loss=0.288297 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.15479902923107147
[5/23] Train loss=0.13668543100357056
[10/23] Train loss=0.14551308751106262
[15/23] Train loss=0.140555739402771
[20/23] Train loss=0.137811079621315
Test set avg_accuracy=88.28% avg_sensitivity=69.33%, avg_specificity=94.32% avg_auc=91.04%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.151991 Test loss=0.299982 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.1532353162765503
[5/23] Train loss=0.13645188510417938
[10/23] Train loss=0.14312322437763214
[15/23] Train loss=0.1464158445596695
[20/23] Train loss=0.13053648173809052
Test set avg_accuracy=88.42% avg_sensitivity=60.75%, avg_specificity=97.24% avg_auc=90.78%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.150817 Test loss=0.308613 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.14560288190841675
[5/23] Train loss=0.13194411993026733
[10/23] Train loss=0.1612621396780014
[15/23] Train loss=0.1486452966928482
[20/23] Train loss=0.1396114081144333
Test set avg_accuracy=87.34% avg_sensitivity=58.71%, avg_specificity=96.46% avg_auc=89.83%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.151792 Test loss=0.330270 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.14868520200252533
[5/23] Train loss=0.13316293060779572
[10/23] Train loss=0.13998903334140778
[15/23] Train loss=0.14894737303256989
[20/23] Train loss=0.13696525990962982
Test set avg_accuracy=87.98% avg_sensitivity=59.68%, avg_specificity=97.00% avg_auc=90.37%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.150492 Test loss=0.319100 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.1458691656589508
[5/23] Train loss=0.13879933953285217
[10/23] Train loss=0.1424817591905594
[15/23] Train loss=0.14695115387439728
[20/23] Train loss=0.1344018429517746
Test set avg_accuracy=88.23% avg_sensitivity=58.33%, avg_specificity=97.75% avg_auc=89.86%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.150889 Test loss=0.323244 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.1542634665966034
[5/23] Train loss=0.1355527937412262
[10/23] Train loss=0.14553052186965942
[15/23] Train loss=0.13896135985851288
[20/23] Train loss=0.13876375555992126
Test set avg_accuracy=90.31% avg_sensitivity=73.80%, avg_specificity=95.57% avg_auc=91.91%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.151227 Test loss=0.277522 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.15402744710445404
[5/23] Train loss=0.13434754312038422
[10/23] Train loss=0.146590456366539
[15/23] Train loss=0.14344638586044312
[20/23] Train loss=0.13312935829162598
Test set avg_accuracy=89.77% avg_sensitivity=72.88%, avg_specificity=95.14% avg_auc=92.49%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.150368 Test loss=0.277990 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.14435984194278717
[5/23] Train loss=0.1326887011528015
[10/23] Train loss=0.1382651925086975
[15/23] Train loss=0.1496340036392212
[20/23] Train loss=0.13441208004951477
Test set avg_accuracy=89.74% avg_sensitivity=68.03%, avg_specificity=96.65% avg_auc=91.30%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.149487 Test loss=0.285692 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.1495906561613083
[5/23] Train loss=0.1427723914384842
[10/23] Train loss=0.1416432112455368
[15/23] Train loss=0.14994390308856964
[20/23] Train loss=0.13356582820415497
Test set avg_accuracy=88.96% avg_sensitivity=67.60%, avg_specificity=95.76% avg_auc=91.44%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.152059 Test loss=0.298205 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.14933764934539795
[5/23] Train loss=0.13428008556365967
[10/23] Train loss=0.13965778052806854
[15/23] Train loss=0.14339867234230042
[20/23] Train loss=0.14443625509738922
Test set avg_accuracy=89.34% avg_sensitivity=76.82%, avg_specificity=93.32% avg_auc=92.13%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.151150 Test loss=0.288025 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.14582616090774536
[5/23] Train loss=0.13819950819015503
[10/23] Train loss=0.13253141939640045
[15/23] Train loss=0.1450950801372528
[20/23] Train loss=0.1289207637310028
Test set avg_accuracy=88.76% avg_sensitivity=73.21%, avg_specificity=93.72% avg_auc=91.87%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.147011 Test loss=0.294631 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.14209869503974915
[5/23] Train loss=0.1314772665500641
[10/23] Train loss=0.14173783361911774
[15/23] Train loss=0.14652040600776672
[20/23] Train loss=0.13253217935562134
Test set avg_accuracy=88.96% avg_sensitivity=66.95%, avg_specificity=95.97% avg_auc=91.58%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.146121 Test loss=0.297243 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.14663051068782806
[5/23] Train loss=0.13465914130210876
[10/23] Train loss=0.13992027938365936
[15/23] Train loss=0.1429271399974823
[20/23] Train loss=0.1284477412700653
Test set avg_accuracy=89.49% avg_sensitivity=75.20%, avg_specificity=94.04% avg_auc=92.57%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.145943 Test loss=0.281236 Current lr=[0.000112073915556435]

[0/23] Train loss=0.14710243046283722
[5/23] Train loss=0.1329023540019989
[10/23] Train loss=0.13448262214660645
[15/23] Train loss=0.13249355554580688
[20/23] Train loss=0.1333141177892685
Test set avg_accuracy=89.08% avg_sensitivity=68.89%, avg_specificity=95.50% avg_auc=91.33%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.143317 Test loss=0.298926 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.14147134125232697
[5/23] Train loss=0.1283917874097824
[10/23] Train loss=0.13420772552490234
[15/23] Train loss=0.13834264874458313
[20/23] Train loss=0.12826550006866455
Test set avg_accuracy=89.32% avg_sensitivity=72.72%, avg_specificity=94.61% avg_auc=92.75%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.141867 Test loss=0.277836 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.14121012389659882
[5/23] Train loss=0.13218125700950623
[10/23] Train loss=0.13280338048934937
[15/23] Train loss=0.14121340215206146
[20/23] Train loss=0.12296203523874283
Test set avg_accuracy=88.95% avg_sensitivity=74.99%, avg_specificity=93.39% avg_auc=92.35%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.139988 Test loss=0.287226 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.14241068065166473
[5/23] Train loss=0.12762801349163055
[10/23] Train loss=0.13096655905246735
[15/23] Train loss=0.131587952375412
[20/23] Train loss=0.1254528909921646
Test set avg_accuracy=88.63% avg_sensitivity=76.06%, avg_specificity=92.64% avg_auc=92.28%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.138978 Test loss=0.294147 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.13594020903110504
[5/23] Train loss=0.12695668637752533
[10/23] Train loss=0.13849323987960815
[15/23] Train loss=0.1352977156639099
[20/23] Train loss=0.12294740974903107
Test set avg_accuracy=88.01% avg_sensitivity=77.68%, avg_specificity=91.30% avg_auc=92.64%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.138519 Test loss=0.302781 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.13542068004608154
[5/23] Train loss=0.12838980555534363
[10/23] Train loss=0.12927614152431488
[15/23] Train loss=0.13168635964393616
[20/23] Train loss=0.12432274222373962
Test set avg_accuracy=88.80% avg_sensitivity=74.18%, avg_specificity=93.46% avg_auc=92.15%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.136032 Test loss=0.290827 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.13752473890781403
[5/23] Train loss=0.1253671944141388
[10/23] Train loss=0.12873761355876923
[15/23] Train loss=0.13361530005931854
[20/23] Train loss=0.12216745316982269
Test set avg_accuracy=88.79% avg_sensitivity=75.80%, avg_specificity=92.93% avg_auc=92.07%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.137558 Test loss=0.290701 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.1383189857006073
[5/23] Train loss=0.1281493455171585
[10/23] Train loss=0.12882690131664276
[15/23] Train loss=0.13293053209781647
[20/23] Train loss=0.11977115273475647
Test set avg_accuracy=89.05% avg_sensitivity=76.55%, avg_specificity=93.03% avg_auc=92.38%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.135754 Test loss=0.285889 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.13795341551303864
[5/23] Train loss=0.1203945130109787
[10/23] Train loss=0.12329834699630737
[15/23] Train loss=0.1281096488237381
[20/23] Train loss=0.1216650903224945
Test set avg_accuracy=88.23% avg_sensitivity=74.45%, avg_specificity=92.62% avg_auc=92.20%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.133531 Test loss=0.296783 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.13343456387519836
[5/23] Train loss=0.12075155973434448
[10/23] Train loss=0.12679752707481384
[15/23] Train loss=0.12268548458814621
[20/23] Train loss=0.1265663355588913
Test set avg_accuracy=88.79% avg_sensitivity=75.09%, avg_specificity=93.15% avg_auc=91.64%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.132832 Test loss=0.297739 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.13206027448177338
[5/23] Train loss=0.12166149169206619
[10/23] Train loss=0.12455125153064728
[15/23] Train loss=0.12996256351470947
[20/23] Train loss=0.12096605449914932
Test set avg_accuracy=88.54% avg_sensitivity=75.15%, avg_specificity=92.81% avg_auc=92.16%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.132449 Test loss=0.296126 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.13409024477005005
[5/23] Train loss=0.12466362863779068
[10/23] Train loss=0.12244651466608047
[15/23] Train loss=0.12646058201789856
[20/23] Train loss=0.11901263147592545
Test set avg_accuracy=89.26% avg_sensitivity=75.20%, avg_specificity=93.73% avg_auc=91.73%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.131875 Test loss=0.289941 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.12991845607757568
[5/23] Train loss=0.12204138189554214
[10/23] Train loss=0.1271931380033493
[15/23] Train loss=0.12766341865062714
[20/23] Train loss=0.12119720876216888
Test set avg_accuracy=88.95% avg_sensitivity=67.01%, avg_specificity=95.93% avg_auc=91.01%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.132232 Test loss=0.300374 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.13508765399456024
[5/23] Train loss=0.11916273832321167
[10/23] Train loss=0.12461790442466736
[15/23] Train loss=0.12579743564128876
[20/23] Train loss=0.12001445144414902
Test set avg_accuracy=89.00% avg_sensitivity=67.06%, avg_specificity=95.98% avg_auc=90.32%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.132060 Test loss=0.302329 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.13388049602508545
[5/23] Train loss=0.1177440956234932
[10/23] Train loss=0.1267080307006836
[15/23] Train loss=0.1263582408428192
[20/23] Train loss=0.11797824501991272
Test set avg_accuracy=89.05% avg_sensitivity=68.03%, avg_specificity=95.74% avg_auc=90.99%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.130389 Test loss=0.304215 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.13110433518886566
[5/23] Train loss=0.11883122473955154
[10/23] Train loss=0.12436805665493011
[15/23] Train loss=0.12843802571296692
[20/23] Train loss=0.11641194671392441
Test set avg_accuracy=88.53% avg_sensitivity=62.48%, avg_specificity=96.82% avg_auc=89.40%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.130242 Test loss=0.322307 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.1308540403842926
[5/23] Train loss=0.11801294982433319
[10/23] Train loss=0.12068904936313629
[15/23] Train loss=0.128449946641922
[20/23] Train loss=0.1143534854054451
Test set avg_accuracy=88.52% avg_sensitivity=65.61%, avg_specificity=95.81% avg_auc=90.84%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.128893 Test loss=0.301508 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.1298585683107376
[5/23] Train loss=0.1188102588057518
[10/23] Train loss=0.11943251639604568
[15/23] Train loss=0.12916558980941772
[20/23] Train loss=0.11625216901302338
Test set avg_accuracy=88.89% avg_sensitivity=70.46%, avg_specificity=94.76% avg_auc=91.05%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.128110 Test loss=0.297211 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.1282133013010025
[5/23] Train loss=0.11588039994239807
[10/23] Train loss=0.11867652833461761
[15/23] Train loss=0.1264505833387375
[20/23] Train loss=0.11740120500326157
Test set avg_accuracy=88.82% avg_sensitivity=73.26%, avg_specificity=93.77% avg_auc=91.94%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.128234 Test loss=0.292035 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.1267690658569336
[5/23] Train loss=0.11425814777612686
[10/23] Train loss=0.11924593895673752
[15/23] Train loss=0.12250789999961853
[20/23] Train loss=0.11541108042001724
Test set avg_accuracy=88.75% avg_sensitivity=72.99%, avg_specificity=93.77% avg_auc=91.29%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.127321 Test loss=0.300884 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.12624883651733398
[5/23] Train loss=0.11499015241861343
[10/23] Train loss=0.11779593676328659
[15/23] Train loss=0.12230841815471649
[20/23] Train loss=0.11490582674741745
Test set avg_accuracy=88.53% avg_sensitivity=74.72%, avg_specificity=92.93% avg_auc=91.45%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.126065 Test loss=0.299773 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.12720374763011932
[5/23] Train loss=0.1145266592502594
[10/23] Train loss=0.11358696967363358
[15/23] Train loss=0.12347143888473511
[20/23] Train loss=0.11377044022083282
Test set avg_accuracy=88.71% avg_sensitivity=74.07%, avg_specificity=93.37% avg_auc=91.40%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.125082 Test loss=0.296743 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.1260201632976532
[5/23] Train loss=0.11311183869838715
[10/23] Train loss=0.11858032643795013
[15/23] Train loss=0.11996393650770187
[20/23] Train loss=0.11147657781839371
Test set avg_accuracy=88.70% avg_sensitivity=70.24%, avg_specificity=94.58% avg_auc=91.35%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.124948 Test loss=0.298462 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.12394159287214279
[5/23] Train loss=0.11543086916208267
[10/23] Train loss=0.11438526958227158
[15/23] Train loss=0.12242747098207474
[20/23] Train loss=0.11114466190338135
Test set avg_accuracy=89.09% avg_sensitivity=72.88%, avg_specificity=94.25% avg_auc=91.79%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.124442 Test loss=0.290635 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.12023958563804626
[5/23] Train loss=0.11779581010341644
[10/23] Train loss=0.11611291021108627
[15/23] Train loss=0.12051752209663391
[20/23] Train loss=0.11327685415744781
Test set avg_accuracy=89.09% avg_sensitivity=71.59%, avg_specificity=94.66% avg_auc=91.13%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.124276 Test loss=0.293682 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.1196751743555069
[5/23] Train loss=0.11507294327020645
[10/23] Train loss=0.1149698793888092
[15/23] Train loss=0.12062264233827591
[20/23] Train loss=0.11530296504497528
Test set avg_accuracy=89.17% avg_sensitivity=75.58%, avg_specificity=93.49% avg_auc=91.91%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.124306 Test loss=0.289740 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.12358572334051132
[5/23] Train loss=0.11300494521856308
[10/23] Train loss=0.1173899918794632
[15/23] Train loss=0.11655300855636597
[20/23] Train loss=0.11297492682933807
Test set avg_accuracy=89.32% avg_sensitivity=74.45%, avg_specificity=94.06% avg_auc=91.98%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.123749 Test loss=0.286456 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.12017867714166641
[5/23] Train loss=0.11270426213741302
[10/23] Train loss=0.11426236480474472
[15/23] Train loss=0.11803417652845383
[20/23] Train loss=0.11221776157617569
Test set avg_accuracy=89.24% avg_sensitivity=74.23%, avg_specificity=94.03% avg_auc=92.10%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.121897 Test loss=0.285737 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.12052997946739197
[5/23] Train loss=0.11155685037374496
[10/23] Train loss=0.11231353133916855
[15/23] Train loss=0.11905825883150101
[20/23] Train loss=0.10918085277080536
Test set avg_accuracy=89.21% avg_sensitivity=73.37%, avg_specificity=94.25% avg_auc=91.69%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.121422 Test loss=0.289716 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.11942300200462341
[5/23] Train loss=0.11198244988918304
[10/23] Train loss=0.11361661553382874
[15/23] Train loss=0.11662360280752182
[20/23] Train loss=0.10863401740789413
Test set avg_accuracy=89.08% avg_sensitivity=76.39%, avg_specificity=93.12% avg_auc=92.07%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.120316 Test loss=0.286084 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.11979398876428604
[5/23] Train loss=0.1120452880859375
[10/23] Train loss=0.11463645845651627
[15/23] Train loss=0.11769403517246246
[20/23] Train loss=0.11093925684690475
Test set avg_accuracy=89.01% avg_sensitivity=74.50%, avg_specificity=93.63% avg_auc=91.96%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.120748 Test loss=0.285583 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.11959671229124069
[5/23] Train loss=0.11019723862409592
[10/23] Train loss=0.11383699625730515
[15/23] Train loss=0.11732757091522217
[20/23] Train loss=0.11118534952402115
Test set avg_accuracy=89.05% avg_sensitivity=73.37%, avg_specificity=94.04% avg_auc=91.74%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.120173 Test loss=0.288253 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.12136955559253693
[5/23] Train loss=0.10992445051670074
[10/23] Train loss=0.11170139163732529
[15/23] Train loss=0.1166801005601883
[20/23] Train loss=0.11334582418203354
Test set avg_accuracy=89.11% avg_sensitivity=74.12%, avg_specificity=93.89% avg_auc=91.73%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.119891 Test loss=0.288471 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.11893735080957413
[5/23] Train loss=0.11136138439178467
[10/23] Train loss=0.1144881621003151
[15/23] Train loss=0.11616359651088715
[20/23] Train loss=0.10788515210151672
Test set avg_accuracy=89.24% avg_sensitivity=74.61%, avg_specificity=93.91% avg_auc=91.84%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.120202 Test loss=0.285677 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.11888358741998672
[5/23] Train loss=0.11049941927194595
[10/23] Train loss=0.11293184757232666
[15/23] Train loss=0.11434049904346466
[20/23] Train loss=0.10655896365642548
Test set avg_accuracy=88.95% avg_sensitivity=75.09%, avg_specificity=93.36% avg_auc=92.02%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.118979 Test loss=0.287370 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.11645451188087463
[5/23] Train loss=0.10998382419347763
[10/23] Train loss=0.11170271784067154
[15/23] Train loss=0.11663521826267242
[20/23] Train loss=0.11218190938234329
Test set avg_accuracy=89.26% avg_sensitivity=74.23%, avg_specificity=94.04% avg_auc=91.87%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.118948 Test loss=0.288248 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.11614564806222916
[5/23] Train loss=0.11014541238546371
[10/23] Train loss=0.11222970485687256
[15/23] Train loss=0.1141362264752388
[20/23] Train loss=0.10764772444963455
Test set avg_accuracy=89.24% avg_sensitivity=74.07%, avg_specificity=94.08% avg_auc=91.76%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.118890 Test loss=0.287470 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.11733656376600266
[5/23] Train loss=0.10868790745735168
[10/23] Train loss=0.11414735019207001
[15/23] Train loss=0.11523497849702835
[20/23] Train loss=0.10841941088438034
Test set avg_accuracy=89.27% avg_sensitivity=74.66%, avg_specificity=93.92% avg_auc=91.81%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.118418 Test loss=0.287005 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.11669839918613434
[5/23] Train loss=0.10898913443088531
[10/23] Train loss=0.11323173344135284
[15/23] Train loss=0.11383313685655594
[20/23] Train loss=0.1087111383676529
Test set avg_accuracy=89.26% avg_sensitivity=74.82%, avg_specificity=93.85% avg_auc=91.84%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.118579 Test loss=0.286751 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.11567050963640213
[5/23] Train loss=0.11100594699382782
[10/23] Train loss=0.11330536007881165
[15/23] Train loss=0.11240646988153458
[20/23] Train loss=0.10796630382537842
Test set avg_accuracy=89.30% avg_sensitivity=74.99%, avg_specificity=93.85% avg_auc=91.91%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.118842 Test loss=0.286202 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.11793842166662216
[5/23] Train loss=0.10937481373548508
[10/23] Train loss=0.11029356718063354
[15/23] Train loss=0.11681844294071198
[20/23] Train loss=0.1106853112578392
Test set avg_accuracy=89.28% avg_sensitivity=74.34%, avg_specificity=94.04% avg_auc=91.87%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.118637 Test loss=0.286079 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.1178835928440094
[5/23] Train loss=0.11209665983915329
[10/23] Train loss=0.11319198459386826
[15/23] Train loss=0.11655522137880325
[20/23] Train loss=0.10654028505086899
Test set avg_accuracy=89.27% avg_sensitivity=74.23%, avg_specificity=94.06% avg_auc=91.86%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.118578 Test loss=0.286198 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.11867040395736694
[5/23] Train loss=0.1119353324174881
[10/23] Train loss=0.11097393929958344
[15/23] Train loss=0.112779401242733
[20/23] Train loss=0.10794991254806519
Test set avg_accuracy=89.31% avg_sensitivity=74.50%, avg_specificity=94.03% avg_auc=91.88%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.118409 Test loss=0.286219 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.11746974289417267
[5/23] Train loss=0.1099894642829895
[10/23] Train loss=0.11236713081598282
[15/23] Train loss=0.11688481271266937
[20/23] Train loss=0.10814614593982697
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=89.26% avg_sensitivity=74.29%, avg_specificity=94.03% avg_auc=91.87%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.118853 Test loss=0.286164 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=90.09% sen=77.74%, spe=94.03%, auc=94.69%!
Fold[9] Avg_overlap=0.69%(0.25364870740045253)
[0/24] Train loss=0.7278289794921875
[5/24] Train loss=0.7224718928337097
[10/24] Train loss=0.7120429277420044
[15/24] Train loss=0.714741051197052
[20/24] Train loss=0.7012637853622437
Test set avg_accuracy=60.38% avg_sensitivity=43.28%, avg_specificity=65.33% avg_auc=57.39%
Best model saved!! Metric=-99.62285941060071!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.713966 Test loss=0.666703 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6977489590644836
[5/24] Train loss=0.6808024048805237
[10/24] Train loss=0.6905921101570129
[15/24] Train loss=0.6857455968856812
[20/24] Train loss=0.672705888748169
Test set avg_accuracy=68.31% avg_sensitivity=50.93%, avg_specificity=73.35% avg_auc=69.51%
Best model saved!! Metric=-63.90767973828383!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.683492 Test loss=0.593119 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6652951836585999
[5/24] Train loss=0.6557348966598511
[10/24] Train loss=0.6582490801811218
[15/24] Train loss=0.6492176651954651
[20/24] Train loss=0.6457915306091309
Test set avg_accuracy=74.60% avg_sensitivity=57.59%, avg_specificity=79.53% avg_auc=75.95%
Best model saved!! Metric=-38.33868779855841!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.655271 Test loss=0.548800 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.633427083492279
[5/24] Train loss=0.6284209489822388
[10/24] Train loss=0.6400561332702637
[15/24] Train loss=0.6183473467826843
[20/24] Train loss=0.616475522518158
Test set avg_accuracy=76.98% avg_sensitivity=62.11%, avg_specificity=81.29% avg_auc=79.82%
Best model saved!! Metric=-25.804136455648816!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.628563 Test loss=0.513800 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5974451899528503
[5/24] Train loss=0.5996365547180176
[10/24] Train loss=0.6100400686264038
[15/24] Train loss=0.5901122689247131
[20/24] Train loss=0.586044430732727
Test set avg_accuracy=78.35% avg_sensitivity=66.28%, avg_specificity=81.84% avg_auc=82.37%
Best model saved!! Metric=-17.162361942273606!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.601968 Test loss=0.483499 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5735799074172974
[5/24] Train loss=0.5748544335365295
[10/24] Train loss=0.592013955116272
[15/24] Train loss=0.5675248503684998
[20/24] Train loss=0.5631575584411621
Test set avg_accuracy=79.71% avg_sensitivity=68.54%, avg_specificity=82.95% avg_auc=84.37%
Best model saved!! Metric=-10.424737866143971!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.574197 Test loss=0.455306 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5502217411994934
[5/24] Train loss=0.5467449426651001
[10/24] Train loss=0.5625127553939819
[15/24] Train loss=0.5335648059844971
[20/24] Train loss=0.5273786187171936
Test set avg_accuracy=81.71% avg_sensitivity=71.03%, avg_specificity=84.80% avg_auc=86.52%
Best model saved!! Metric=-1.9433346680398103!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.547386 Test loss=0.429075 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.515030026435852
[5/24] Train loss=0.5172612071037292
[10/24] Train loss=0.529288113117218
[15/24] Train loss=0.5060123205184937
[20/24] Train loss=0.4981662333011627
Test set avg_accuracy=84.31% avg_sensitivity=68.95%, avg_specificity=88.76% avg_auc=87.76%
Best model saved!! Metric=3.777917175792396!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.518412 Test loss=0.400348 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.49070626497268677
[5/24] Train loss=0.4893743097782135
[10/24] Train loss=0.49981310963630676
[15/24] Train loss=0.47730061411857605
[20/24] Train loss=0.46728065609931946
Test set avg_accuracy=85.65% avg_sensitivity=71.38%, avg_specificity=89.79% avg_auc=89.27%
Best model saved!! Metric=10.083898668843645!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.490423 Test loss=0.380037 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.466357946395874
[5/24] Train loss=0.4623655676841736
[10/24] Train loss=0.4679584205150604
[15/24] Train loss=0.45022958517074585
[20/24] Train loss=0.4415135383605957
Test set avg_accuracy=86.84% avg_sensitivity=69.58%, avg_specificity=91.84% avg_auc=90.11%
Best model saved!! Metric=12.361801491645437!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.460959 Test loss=0.359723 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4340914189815521
[5/24] Train loss=0.43045586347579956
[10/24] Train loss=0.44050800800323486
[15/24] Train loss=0.4204263985157013
[20/24] Train loss=0.4122018814086914
Test set avg_accuracy=87.54% avg_sensitivity=71.03%, avg_specificity=92.32% avg_auc=90.93%
Best model saved!! Metric=15.824310817440278!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.433809 Test loss=0.344501 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4164379835128784
[5/24] Train loss=0.40785670280456543
[10/24] Train loss=0.4116694927215576
[15/24] Train loss=0.39605486392974854
[20/24] Train loss=0.38766005635261536
Test set avg_accuracy=88.03% avg_sensitivity=69.87%, avg_specificity=93.30% avg_auc=91.57%
Best model saved!! Metric=16.777551598230644!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.409205 Test loss=0.325747 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4002856910228729
[5/24] Train loss=0.38443222641944885
[10/24] Train loss=0.3894357681274414
[15/24] Train loss=0.37406808137893677
[20/24] Train loss=0.3654400706291199
Test set avg_accuracy=88.58% avg_sensitivity=72.94%, avg_specificity=93.11% avg_auc=92.35%
Best model saved!! Metric=20.985782042110728!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.387261 Test loss=0.312846 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.38127830624580383
[5/24] Train loss=0.3611736297607422
[10/24] Train loss=0.3676716387271881
[15/24] Train loss=0.35483890771865845
[20/24] Train loss=0.34523195028305054
Test set avg_accuracy=89.02% avg_sensitivity=69.70%, avg_specificity=94.63% avg_auc=92.46%
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.368501 Test loss=0.298959 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3593936562538147
[5/24] Train loss=0.34441810846328735
[10/24] Train loss=0.3493708372116089
[15/24] Train loss=0.34332597255706787
[20/24] Train loss=0.32969558238983154
Test set avg_accuracy=89.24% avg_sensitivity=66.28%, avg_specificity=95.90% avg_auc=92.31%
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.352796 Test loss=0.289111 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3449288010597229
[5/24] Train loss=0.3312546908855438
[10/24] Train loss=0.342787504196167
[15/24] Train loss=0.32801541686058044
[20/24] Train loss=0.31314215064048767
Test set avg_accuracy=89.52% avg_sensitivity=68.02%, avg_specificity=95.75% avg_auc=93.02%
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.338808 Test loss=0.278177 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3325611352920532
[5/24] Train loss=0.3249478340148926
[10/24] Train loss=0.32526129484176636
[15/24] Train loss=0.31326448917388916
[20/24] Train loss=0.30753403902053833
Test set avg_accuracy=89.70% avg_sensitivity=68.08%, avg_specificity=95.97% avg_auc=93.25%
Best model saved!! Metric=20.9954842278555!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.325968 Test loss=0.272178 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.32064127922058105
[5/24] Train loss=0.3101770579814911
[10/24] Train loss=0.318558007478714
[15/24] Train loss=0.304385244846344
[20/24] Train loss=0.29025739431381226
Test set avg_accuracy=89.79% avg_sensitivity=68.77%, avg_specificity=95.89% avg_auc=93.61%
Best model saved!! Metric=22.054858475945295!!
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.316707 Test loss=0.265651 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.31346336007118225
[5/24] Train loss=0.30359238386154175
[10/24] Train loss=0.3096311390399933
[15/24] Train loss=0.296470046043396
[20/24] Train loss=0.28694477677345276
Test set avg_accuracy=89.91% avg_sensitivity=69.99%, avg_specificity=95.68% avg_auc=93.51%
Best model saved!! Metric=23.09355175742718!!
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.307355 Test loss=0.261978 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3053535521030426
[5/24] Train loss=0.2908024191856384
[10/24] Train loss=0.3012973368167877
[15/24] Train loss=0.28985312581062317
[20/24] Train loss=0.275493323802948
Test set avg_accuracy=90.10% avg_sensitivity=75.03%, avg_specificity=94.47% avg_auc=94.27%
Best model saved!! Metric=27.879982101415322!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.298770 Test loss=0.255189 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2948901057243347
[5/24] Train loss=0.2871273458003998
[10/24] Train loss=0.29096829891204834
[15/24] Train loss=0.27287960052490234
[20/24] Train loss=0.27184930443763733
Test set avg_accuracy=90.25% avg_sensitivity=72.48%, avg_specificity=95.40% avg_auc=93.74%
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.290188 Test loss=0.255446 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2925448715686798
[5/24] Train loss=0.27409568428993225
[10/24] Train loss=0.2865183651447296
[15/24] Train loss=0.2732689380645752
[20/24] Train loss=0.2608778774738312
Test set avg_accuracy=90.38% avg_sensitivity=73.06%, avg_specificity=95.40% avg_auc=94.30%
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.283747 Test loss=0.247471 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.29394328594207764
[5/24] Train loss=0.2715204954147339
[10/24] Train loss=0.2786335349082947
[15/24] Train loss=0.2687622308731079
[20/24] Train loss=0.2573680877685547
Test set avg_accuracy=90.46% avg_sensitivity=70.97%, avg_specificity=96.10% avg_auc=94.04%
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.276516 Test loss=0.249601 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2814992666244507
[5/24] Train loss=0.26654326915740967
[10/24] Train loss=0.2745232582092285
[15/24] Train loss=0.26708075404167175
[20/24] Train loss=0.2572850286960602
Test set avg_accuracy=90.35% avg_sensitivity=70.39%, avg_specificity=96.14% avg_auc=93.79%
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.272705 Test loss=0.250957 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2794516384601593
[5/24] Train loss=0.25721266865730286
[10/24] Train loss=0.2667590081691742
[15/24] Train loss=0.25557461380958557
[20/24] Train loss=0.2442859411239624
Test set avg_accuracy=90.29% avg_sensitivity=69.12%, avg_specificity=96.42% avg_auc=93.23%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.266378 Test loss=0.257521 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.272957444190979
[5/24] Train loss=0.2493342161178589
[10/24] Train loss=0.26341742277145386
[15/24] Train loss=0.25186941027641296
[20/24] Train loss=0.24439069628715515
Test set avg_accuracy=89.80% avg_sensitivity=63.15%, avg_specificity=97.53% avg_auc=93.65%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.261566 Test loss=0.259137 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.276750773191452
[5/24] Train loss=0.24267181754112244
[10/24] Train loss=0.2601903975009918
[15/24] Train loss=0.24946631491184235
[20/24] Train loss=0.23583276569843292
Test set avg_accuracy=89.90% avg_sensitivity=64.14%, avg_specificity=97.36% avg_auc=93.90%
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.258356 Test loss=0.257883 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2753314673900604
[5/24] Train loss=0.23663315176963806
[10/24] Train loss=0.25453048944473267
[15/24] Train loss=0.247117280960083
[20/24] Train loss=0.23497188091278076
Test set avg_accuracy=89.64% avg_sensitivity=63.09%, avg_specificity=97.33% avg_auc=93.11%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.253059 Test loss=0.266010 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2721007168292999
[5/24] Train loss=0.2407984882593155
[10/24] Train loss=0.24594223499298096
[15/24] Train loss=0.2465440183877945
[20/24] Train loss=0.24140852689743042
Test set avg_accuracy=90.25% avg_sensitivity=71.26%, avg_specificity=95.75% avg_auc=93.99%
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.249647 Test loss=0.252357 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2690538465976715
[5/24] Train loss=0.24323394894599915
[10/24] Train loss=0.24904006719589233
[15/24] Train loss=0.24090000987052917
[20/24] Train loss=0.23268133401870728
Test set avg_accuracy=90.36% avg_sensitivity=68.02%, avg_specificity=96.84% avg_auc=93.43%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.249253 Test loss=0.256472 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2562234699726105
[5/24] Train loss=0.2236458957195282
[10/24] Train loss=0.2458321750164032
[15/24] Train loss=0.24027539789676666
[20/24] Train loss=0.24141143262386322
Test set avg_accuracy=89.41% avg_sensitivity=60.66%, avg_specificity=97.75% avg_auc=92.27%
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.242194 Test loss=0.279208 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2512156069278717
[5/24] Train loss=0.22173598408699036
[10/24] Train loss=0.24619361758232117
[15/24] Train loss=0.23900988698005676
[20/24] Train loss=0.23086948692798615
Test set avg_accuracy=88.70% avg_sensitivity=56.78%, avg_specificity=97.95% avg_auc=92.12%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.240933 Test loss=0.290670 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2576703429222107
[5/24] Train loss=0.21297504007816315
[10/24] Train loss=0.2429024875164032
[15/24] Train loss=0.23156845569610596
[20/24] Train loss=0.22886228561401367
Test set avg_accuracy=87.67% avg_sensitivity=49.30%, avg_specificity=98.79% avg_auc=92.08%
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.239007 Test loss=0.309306 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.26419156789779663
[5/24] Train loss=0.21430976688861847
[10/24] Train loss=0.23077422380447388
[15/24] Train loss=0.23352250456809998
[20/24] Train loss=0.22197256982326508
Test set avg_accuracy=90.08% avg_sensitivity=69.99%, avg_specificity=95.90% avg_auc=93.64%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.238769 Test loss=0.261449 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.25728946924209595
[5/24] Train loss=0.21006065607070923
[10/24] Train loss=0.23514536023139954
[15/24] Train loss=0.23629851639270782
[20/24] Train loss=0.21970273554325104
Test set avg_accuracy=90.18% avg_sensitivity=68.95%, avg_specificity=96.34% avg_auc=93.02%
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.233587 Test loss=0.259002 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2546893358230591
[5/24] Train loss=0.21900108456611633
[10/24] Train loss=0.22634410858154297
[15/24] Train loss=0.23338785767555237
[20/24] Train loss=0.22013084590435028
Test set avg_accuracy=87.45% avg_sensitivity=77.23%, avg_specificity=90.41% avg_auc=91.44%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.233350 Test loss=0.310972 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2397119402885437
[5/24] Train loss=0.22851385176181793
[10/24] Train loss=0.24004113674163818
[15/24] Train loss=0.2401416301727295
[20/24] Train loss=0.21553561091423035
Test set avg_accuracy=87.55% avg_sensitivity=50.93%, avg_specificity=98.17% avg_auc=89.01%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.230329 Test loss=0.344866 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2329893261194229
[5/24] Train loss=0.20957139134407043
[10/24] Train loss=0.2175332009792328
[15/24] Train loss=0.22351078689098358
[20/24] Train loss=0.21895749866962433
Test set avg_accuracy=88.40% avg_sensitivity=54.46%, avg_specificity=98.24% avg_auc=92.40%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.226625 Test loss=0.299467 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2346448451280594
[5/24] Train loss=0.21759669482707977
[10/24] Train loss=0.2310001105070114
[15/24] Train loss=0.22459301352500916
[20/24] Train loss=0.21867088973522186
Test set avg_accuracy=88.46% avg_sensitivity=54.23%, avg_specificity=98.39% avg_auc=92.02%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.225493 Test loss=0.303283 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.25034764409065247
[5/24] Train loss=0.1937127709388733
[10/24] Train loss=0.23050253093242645
[15/24] Train loss=0.2252224087715149
[20/24] Train loss=0.20933762192726135
Test set avg_accuracy=89.52% avg_sensitivity=63.33%, avg_specificity=97.11% avg_auc=92.53%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.224173 Test loss=0.272806 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.23486626148223877
[5/24] Train loss=0.19393771886825562
[10/24] Train loss=0.2252916395664215
[15/24] Train loss=0.22733518481254578
[20/24] Train loss=0.20403863489627838
Test set avg_accuracy=87.77% avg_sensitivity=51.10%, avg_specificity=98.40% avg_auc=90.66%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.220988 Test loss=0.319918 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.23012542724609375
[5/24] Train loss=0.19981707632541656
[10/24] Train loss=0.2259097546339035
[15/24] Train loss=0.22834716737270355
[20/24] Train loss=0.2082313597202301
Test set avg_accuracy=89.01% avg_sensitivity=71.21%, avg_specificity=94.17% avg_auc=92.39%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.222362 Test loss=0.276670 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.21883071959018707
[5/24] Train loss=0.1822061836719513
[10/24] Train loss=0.20664896070957184
[15/24] Train loss=0.22065027058124542
[20/24] Train loss=0.21532152593135834
Test set avg_accuracy=90.01% avg_sensitivity=66.86%, avg_specificity=96.72% avg_auc=93.93%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.219190 Test loss=0.255401 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2266794592142105
[5/24] Train loss=0.1813964694738388
[10/24] Train loss=0.20734062790870667
[15/24] Train loss=0.23226210474967957
[20/24] Train loss=0.21406373381614685
Test set avg_accuracy=89.79% avg_sensitivity=69.93%, avg_specificity=95.55% avg_auc=93.47%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.215413 Test loss=0.257596 Current lr=[0.00029967723776099]

[0/24] Train loss=0.22919048368930817
[5/24] Train loss=0.18563158810138702
[10/24] Train loss=0.22164352238178253
[15/24] Train loss=0.22938872873783112
[20/24] Train loss=0.21581339836120605
Test set avg_accuracy=89.54% avg_sensitivity=72.13%, avg_specificity=94.59% avg_auc=93.11%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.214808 Test loss=0.264205 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.21700507402420044
[5/24] Train loss=0.18541961908340454
[10/24] Train loss=0.20842519402503967
[15/24] Train loss=0.227399080991745
[20/24] Train loss=0.20256851613521576
Test set avg_accuracy=88.80% avg_sensitivity=64.25%, avg_specificity=95.92% avg_auc=91.79%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.212343 Test loss=0.284182 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.21210166811943054
[5/24] Train loss=0.1830051988363266
[10/24] Train loss=0.20648422837257385
[15/24] Train loss=0.2124226689338684
[20/24] Train loss=0.20955048501491547
Test set avg_accuracy=88.37% avg_sensitivity=75.03%, avg_specificity=92.24% avg_auc=92.43%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.206358 Test loss=0.279765 Current lr=[0.000299720220882401]

[0/24] Train loss=0.21847732365131378
[5/24] Train loss=0.18362648785114288
[10/24] Train loss=0.20072005689144135
[15/24] Train loss=0.23012642562389374
[20/24] Train loss=0.2083420753479004
Test set avg_accuracy=88.65% avg_sensitivity=58.29%, avg_specificity=97.45% avg_auc=90.81%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.213689 Test loss=0.306825 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.22010745108127594
[5/24] Train loss=0.18459022045135498
[10/24] Train loss=0.20306742191314697
[15/24] Train loss=0.2219998985528946
[20/24] Train loss=0.2021416872739792
Test set avg_accuracy=88.87% avg_sensitivity=75.55%, avg_specificity=92.73% avg_auc=93.66%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.208730 Test loss=0.264584 Current lr=[0.000298904600941902]

[0/24] Train loss=0.21402055025100708
[5/24] Train loss=0.18459290266036987
[10/24] Train loss=0.19026537239551544
[15/24] Train loss=0.21330732107162476
[20/24] Train loss=0.20248191058635712
Test set avg_accuracy=89.61% avg_sensitivity=71.09%, avg_specificity=94.98% avg_auc=92.78%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.205274 Test loss=0.268629 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.20911423861980438
[5/24] Train loss=0.17103473842144012
[10/24] Train loss=0.21246373653411865
[15/24] Train loss=0.21584098041057587
[20/24] Train loss=0.20114876329898834
Test set avg_accuracy=88.03% avg_sensitivity=77.35%, avg_specificity=91.13% avg_auc=91.23%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.204929 Test loss=0.304520 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2088589072227478
[5/24] Train loss=0.1788678914308548
[10/24] Train loss=0.20089347660541534
[15/24] Train loss=0.21604780852794647
[20/24] Train loss=0.1976146548986435
Test set avg_accuracy=87.20% avg_sensitivity=75.90%, avg_specificity=90.48% avg_auc=91.87%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.206623 Test loss=0.319836 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.20664899051189423
[5/24] Train loss=0.18983907997608185
[10/24] Train loss=0.18874336779117584
[15/24] Train loss=0.20891349017620087
[20/24] Train loss=0.19479721784591675
Test set avg_accuracy=89.40% avg_sensitivity=71.78%, avg_specificity=94.51% avg_auc=92.41%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.202474 Test loss=0.272647 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.20797841250896454
[5/24] Train loss=0.18424923717975616
[10/24] Train loss=0.21553027629852295
[15/24] Train loss=0.22042180597782135
[20/24] Train loss=0.19451777637004852
Test set avg_accuracy=90.21% avg_sensitivity=71.61%, avg_specificity=95.60% avg_auc=93.77%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.206739 Test loss=0.252273 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.20861715078353882
[5/24] Train loss=0.1741212010383606
[10/24] Train loss=0.1934552639722824
[15/24] Train loss=0.20981179177761078
[20/24] Train loss=0.191552996635437
Test set avg_accuracy=88.48% avg_sensitivity=79.37%, avg_specificity=91.12% avg_auc=93.83%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.203287 Test loss=0.271244 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.20803986489772797
[5/24] Train loss=0.18971021473407745
[10/24] Train loss=0.19045498967170715
[15/24] Train loss=0.21231691539287567
[20/24] Train loss=0.20327797532081604
Test set avg_accuracy=89.11% avg_sensitivity=78.97%, avg_specificity=92.06% avg_auc=93.29%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.202042 Test loss=0.268897 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.20625202357769012
[5/24] Train loss=0.17399805784225464
[10/24] Train loss=0.18936288356781006
[15/24] Train loss=0.2056308537721634
[20/24] Train loss=0.194945827126503
Test set avg_accuracy=88.88% avg_sensitivity=67.50%, avg_specificity=95.08% avg_auc=91.88%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.196855 Test loss=0.279798 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2045598179101944
[5/24] Train loss=0.17290902137756348
[10/24] Train loss=0.20096828043460846
[15/24] Train loss=0.2009490430355072
[20/24] Train loss=0.20299579203128815
Test set avg_accuracy=90.03% avg_sensitivity=74.10%, avg_specificity=94.64% avg_auc=93.16%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.197585 Test loss=0.259813 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.20725926756858826
[5/24] Train loss=0.17822615802288055
[10/24] Train loss=0.18755319714546204
[15/24] Train loss=0.20862779021263123
[20/24] Train loss=0.18659910559654236
Test set avg_accuracy=87.79% avg_sensitivity=83.37%, avg_specificity=89.07% avg_auc=93.60%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.195410 Test loss=0.295602 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.20302778482437134
[5/24] Train loss=0.16909626126289368
[10/24] Train loss=0.19151107966899872
[15/24] Train loss=0.2076033502817154
[20/24] Train loss=0.1939598172903061
Test set avg_accuracy=87.85% avg_sensitivity=53.82%, avg_specificity=97.72% avg_auc=89.14%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.196990 Test loss=0.327161 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.21185341477394104
[5/24] Train loss=0.17136512696743011
[10/24] Train loss=0.20584645867347717
[15/24] Train loss=0.20641185343265533
[20/24] Train loss=0.18648429214954376
Test set avg_accuracy=88.98% avg_sensitivity=67.03%, avg_specificity=95.35% avg_auc=90.97%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.195904 Test loss=0.294742 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2009788453578949
[5/24] Train loss=0.1655694991350174
[10/24] Train loss=0.1824718862771988
[15/24] Train loss=0.2064153552055359
[20/24] Train loss=0.19947659969329834
Test set avg_accuracy=90.16% avg_sensitivity=69.87%, avg_specificity=96.04% avg_auc=92.76%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.191814 Test loss=0.264429 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.19950568675994873
[5/24] Train loss=0.16824376583099365
[10/24] Train loss=0.19139690697193146
[15/24] Train loss=0.20345841348171234
[20/24] Train loss=0.17837396264076233
Test set avg_accuracy=87.27% avg_sensitivity=80.30%, avg_specificity=89.28% avg_auc=92.43%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.191546 Test loss=0.306098 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.20077575743198395
[5/24] Train loss=0.16591820120811462
[10/24] Train loss=0.1906978338956833
[15/24] Train loss=0.2005528062582016
[20/24] Train loss=0.17749162018299103
Test set avg_accuracy=90.04% avg_sensitivity=73.64%, avg_specificity=94.79% avg_auc=93.88%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.193211 Test loss=0.253603 Current lr=[0.000276307469034998]

[0/24] Train loss=0.19412292540073395
[5/24] Train loss=0.1758592575788498
[10/24] Train loss=0.1869460493326187
[15/24] Train loss=0.19741849601268768
[20/24] Train loss=0.18087691068649292
Test set avg_accuracy=89.53% avg_sensitivity=65.59%, avg_specificity=96.47% avg_auc=91.78%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.188002 Test loss=0.285639 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.20452649891376495
[5/24] Train loss=0.1702543944120407
[10/24] Train loss=0.1858818531036377
[15/24] Train loss=0.19876134395599365
[20/24] Train loss=0.20779061317443848
Test set avg_accuracy=88.93% avg_sensitivity=69.18%, avg_specificity=94.66% avg_auc=92.12%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.189782 Test loss=0.277560 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.20181183516979218
[5/24] Train loss=0.16360920667648315
[10/24] Train loss=0.1813720166683197
[15/24] Train loss=0.19791074097156525
[20/24] Train loss=0.17248640954494476
Test set avg_accuracy=88.52% avg_sensitivity=64.48%, avg_specificity=95.48% avg_auc=91.10%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.188808 Test loss=0.300615 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2019912153482437
[5/24] Train loss=0.17237210273742676
[10/24] Train loss=0.1763722449541092
[15/24] Train loss=0.20213022828102112
[20/24] Train loss=0.18008767068386078
Test set avg_accuracy=89.47% avg_sensitivity=69.81%, avg_specificity=95.16% avg_auc=91.44%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.189375 Test loss=0.291660 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.19946472346782684
[5/24] Train loss=0.17160101234912872
[10/24] Train loss=0.16878999769687653
[15/24] Train loss=0.18874388933181763
[20/24] Train loss=0.17482367157936096
Test set avg_accuracy=90.01% avg_sensitivity=68.66%, avg_specificity=96.20% avg_auc=91.81%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.184345 Test loss=0.271374 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.18557290732860565
[5/24] Train loss=0.1759810447692871
[10/24] Train loss=0.19173316657543182
[15/24] Train loss=0.20032766461372375
[20/24] Train loss=0.1783120185136795
Test set avg_accuracy=88.98% avg_sensitivity=60.60%, avg_specificity=97.21% avg_auc=91.04%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.188920 Test loss=0.295029 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.19725488126277924
[5/24] Train loss=0.16490492224693298
[10/24] Train loss=0.17385366559028625
[15/24] Train loss=0.18465319275856018
[20/24] Train loss=0.18006983399391174
Test set avg_accuracy=82.41% avg_sensitivity=82.62%, avg_specificity=82.35% avg_auc=89.81%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.182273 Test loss=0.406648 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.20471151173114777
[5/24] Train loss=0.17153578996658325
[10/24] Train loss=0.17945219576358795
[15/24] Train loss=0.19285263121128082
[20/24] Train loss=0.16913242638111115
Test set avg_accuracy=89.83% avg_sensitivity=71.96%, avg_specificity=95.01% avg_auc=91.89%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.182080 Test loss=0.274696 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.19289684295654297
[5/24] Train loss=0.16541869938373566
[10/24] Train loss=0.1738068014383316
[15/24] Train loss=0.1849973499774933
[20/24] Train loss=0.169088214635849
Test set avg_accuracy=88.35% avg_sensitivity=76.59%, avg_specificity=91.75% avg_auc=92.20%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.176587 Test loss=0.288551 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.18147045373916626
[5/24] Train loss=0.16535033285617828
[10/24] Train loss=0.1685008406639099
[15/24] Train loss=0.19038955867290497
[20/24] Train loss=0.1774882972240448
Test set avg_accuracy=89.71% avg_sensitivity=65.59%, avg_specificity=96.71% avg_auc=91.62%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.180369 Test loss=0.280679 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.18601301312446594
[5/24] Train loss=0.16606982052326202
[10/24] Train loss=0.1765727698802948
[15/24] Train loss=0.19624300301074982
[20/24] Train loss=0.18165414035320282
Test set avg_accuracy=89.44% avg_sensitivity=65.82%, avg_specificity=96.29% avg_auc=91.71%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.180206 Test loss=0.284665 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.18779529631137848
[5/24] Train loss=0.15387879312038422
[10/24] Train loss=0.17805558443069458
[15/24] Train loss=0.19300390779972076
[20/24] Train loss=0.1704675555229187
Test set avg_accuracy=86.81% avg_sensitivity=47.74%, avg_specificity=98.14% avg_auc=87.21%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.179416 Test loss=0.357389 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.18362835049629211
[5/24] Train loss=0.16453222930431366
[10/24] Train loss=0.17081080377101898
[15/24] Train loss=0.1863698810338974
[20/24] Train loss=0.18021969497203827
Test set avg_accuracy=87.98% avg_sensitivity=81.58%, avg_specificity=89.84% avg_auc=93.31%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.183428 Test loss=0.289935 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.1811814159154892
[5/24] Train loss=0.1673206239938736
[10/24] Train loss=0.1838577687740326
[15/24] Train loss=0.18855610489845276
[20/24] Train loss=0.17032085359096527
Test set avg_accuracy=90.05% avg_sensitivity=71.67%, avg_specificity=95.38% avg_auc=92.54%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.181171 Test loss=0.263295 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.19716203212738037
[5/24] Train loss=0.1683742254972458
[10/24] Train loss=0.20140697062015533
[15/24] Train loss=0.19533681869506836
[20/24] Train loss=0.1779232770204544
Test set avg_accuracy=87.81% avg_sensitivity=80.24%, avg_specificity=90.01% avg_auc=92.75%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.186733 Test loss=0.296281 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.20574447512626648
[5/24] Train loss=0.16090017557144165
[10/24] Train loss=0.1679067760705948
[15/24] Train loss=0.18661455810070038
[20/24] Train loss=0.1719963252544403
Test set avg_accuracy=88.53% avg_sensitivity=77.11%, avg_specificity=91.84% avg_auc=93.36%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.182928 Test loss=0.274258 Current lr=[0.000224838296036774]

[0/24] Train loss=0.18839885294437408
[5/24] Train loss=0.16313526034355164
[10/24] Train loss=0.1907012015581131
[15/24] Train loss=0.18141378462314606
[20/24] Train loss=0.16836176812648773
Test set avg_accuracy=85.31% avg_sensitivity=83.78%, avg_specificity=85.76% avg_auc=91.46%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.178195 Test loss=0.352698 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.18048955500125885
[5/24] Train loss=0.16058777272701263
[10/24] Train loss=0.16941344738006592
[15/24] Train loss=0.1779264211654663
[20/24] Train loss=0.1682261824607849
Test set avg_accuracy=87.86% avg_sensitivity=78.91%, avg_specificity=90.46% avg_auc=92.28%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.176127 Test loss=0.295947 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.18016797304153442
[5/24] Train loss=0.1544262319803238
[10/24] Train loss=0.1665271818637848
[15/24] Train loss=0.1862976998090744
[20/24] Train loss=0.17031772434711456
Test set avg_accuracy=87.16% avg_sensitivity=79.43%, avg_specificity=89.40% avg_auc=91.60%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.175654 Test loss=0.320616 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1848365217447281
[5/24] Train loss=0.1565932333469391
[10/24] Train loss=0.16169951856136322
[15/24] Train loss=0.18047983944416046
[20/24] Train loss=0.16351939737796783
Test set avg_accuracy=88.50% avg_sensitivity=79.08%, avg_specificity=91.23% avg_auc=93.04%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.173069 Test loss=0.281977 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.1744702309370041
[5/24] Train loss=0.14941023290157318
[10/24] Train loss=0.15457159280776978
[15/24] Train loss=0.17386415600776672
[20/24] Train loss=0.16764409840106964
Test set avg_accuracy=89.36% avg_sensitivity=75.03%, avg_specificity=93.52% avg_auc=92.37%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.169768 Test loss=0.282364 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.178728848695755
[5/24] Train loss=0.15479828417301178
[10/24] Train loss=0.16747406125068665
[15/24] Train loss=0.17389120161533356
[20/24] Train loss=0.16332973539829254
Test set avg_accuracy=89.11% avg_sensitivity=73.12%, avg_specificity=93.75% avg_auc=91.63%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.169214 Test loss=0.285065 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.18048106133937836
[5/24] Train loss=0.15098701417446136
[10/24] Train loss=0.1656026542186737
[15/24] Train loss=0.17178630828857422
[20/24] Train loss=0.1641751527786255
Test set avg_accuracy=88.41% avg_sensitivity=79.49%, avg_specificity=91.00% avg_auc=92.65%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.168216 Test loss=0.289540 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.17279112339019775
[5/24] Train loss=0.1582915484905243
[10/24] Train loss=0.15938398241996765
[15/24] Train loss=0.1820918172597885
[20/24] Train loss=0.15820297598838806
Test set avg_accuracy=90.29% avg_sensitivity=76.13%, avg_specificity=94.39% avg_auc=93.60%
Best model saved!! Metric=28.40842897655361!!
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.168502 Test loss=0.257654 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.17459909617900848
[5/24] Train loss=0.16184015572071075
[10/24] Train loss=0.15792806446552277
[15/24] Train loss=0.17692561447620392
[20/24] Train loss=0.16041606664657593
Test set avg_accuracy=89.47% avg_sensitivity=67.56%, avg_specificity=95.82% avg_auc=91.21%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.166232 Test loss=0.285688 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.16314883530139923
[5/24] Train loss=0.15050555765628815
[10/24] Train loss=0.15560954809188843
[15/24] Train loss=0.1748460829257965
[20/24] Train loss=0.1607702523469925
Test set avg_accuracy=89.83% avg_sensitivity=69.18%, avg_specificity=95.82% avg_auc=91.46%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.166122 Test loss=0.280251 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1699080765247345
[5/24] Train loss=0.1575353443622589
[10/24] Train loss=0.16303874552249908
[15/24] Train loss=0.17422184348106384
[20/24] Train loss=0.15558873116970062
Test set avg_accuracy=88.58% avg_sensitivity=66.69%, avg_specificity=94.93% avg_auc=90.33%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.168324 Test loss=0.303539 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.17567425966262817
[5/24] Train loss=0.15641477704048157
[10/24] Train loss=0.15877924859523773
[15/24] Train loss=0.1657296121120453
[20/24] Train loss=0.1614750623703003
Test set avg_accuracy=89.06% avg_sensitivity=71.38%, avg_specificity=94.19% avg_auc=92.02%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.164205 Test loss=0.282493 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.17363859713077545
[5/24] Train loss=0.15379194915294647
[10/24] Train loss=0.1562049686908722
[15/24] Train loss=0.16855473816394806
[20/24] Train loss=0.15865246951580048
Test set avg_accuracy=81.97% avg_sensitivity=88.70%, avg_specificity=80.01% avg_auc=90.88%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.163626 Test loss=0.425243 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.17117908596992493
[5/24] Train loss=0.1575942188501358
[10/24] Train loss=0.1541202813386917
[15/24] Train loss=0.1610686331987381
[20/24] Train loss=0.15813155472278595
Test set avg_accuracy=88.27% avg_sensitivity=63.79%, avg_specificity=95.36% avg_auc=89.59%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.160689 Test loss=0.310821 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.17043496668338776
[5/24] Train loss=0.15408280491828918
[10/24] Train loss=0.1522863507270813
[15/24] Train loss=0.17034092545509338
[20/24] Train loss=0.16650617122650146
Test set avg_accuracy=88.67% avg_sensitivity=80.19%, avg_specificity=91.13% avg_auc=93.00%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.163678 Test loss=0.282978 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15890748798847198
[5/24] Train loss=0.15166570246219635
[10/24] Train loss=0.15405553579330444
[15/24] Train loss=0.16545619070529938
[20/24] Train loss=0.15748555958271027
Test set avg_accuracy=89.79% avg_sensitivity=72.65%, avg_specificity=94.76% avg_auc=92.46%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.160947 Test loss=0.271984 Current lr=[0.000156543481933168]

[0/24] Train loss=0.16295909881591797
[5/24] Train loss=0.1501752734184265
[10/24] Train loss=0.1573229730129242
[15/24] Train loss=0.16943210363388062
[20/24] Train loss=0.16505832970142365
Test set avg_accuracy=88.89% avg_sensitivity=75.90%, avg_specificity=92.66% avg_auc=92.55%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.165067 Test loss=0.283268 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.16248856484889984
[5/24] Train loss=0.1544186919927597
[10/24] Train loss=0.1523962765932083
[15/24] Train loss=0.16839544475078583
[20/24] Train loss=0.14936599135398865
Test set avg_accuracy=89.86% avg_sensitivity=72.54%, avg_specificity=94.88% avg_auc=92.14%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.161144 Test loss=0.273749 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.1641988754272461
[5/24] Train loss=0.15141159296035767
[10/24] Train loss=0.14940856397151947
[15/24] Train loss=0.16836178302764893
[20/24] Train loss=0.14762023091316223
Test set avg_accuracy=89.62% avg_sensitivity=73.58%, avg_specificity=94.27% avg_auc=92.57%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.158622 Test loss=0.273600 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15643714368343353
[5/24] Train loss=0.14806517958641052
[10/24] Train loss=0.14242923259735107
[15/24] Train loss=0.1641257107257843
[20/24] Train loss=0.15188676118850708
Test set avg_accuracy=88.89% avg_sensitivity=74.57%, avg_specificity=93.05% avg_auc=91.87%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.154544 Test loss=0.285416 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15847007930278778
[5/24] Train loss=0.14348654448986053
[10/24] Train loss=0.13821402192115784
[15/24] Train loss=0.16026908159255981
[20/24] Train loss=0.1522817313671112
Test set avg_accuracy=88.01% avg_sensitivity=80.59%, avg_specificity=90.16% avg_auc=92.93%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.153084 Test loss=0.296101 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15555506944656372
[5/24] Train loss=0.14371952414512634
[10/24] Train loss=0.13935303688049316
[15/24] Train loss=0.16569072008132935
[20/24] Train loss=0.14781247079372406
Test set avg_accuracy=89.90% avg_sensitivity=67.44%, avg_specificity=96.41% avg_auc=91.10%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.154582 Test loss=0.285616 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.16233474016189575
[5/24] Train loss=0.14179299771785736
[10/24] Train loss=0.13852329552173615
[15/24] Train loss=0.1617376059293747
[20/24] Train loss=0.14480839669704437
Test set avg_accuracy=89.77% avg_sensitivity=68.89%, avg_specificity=95.82% avg_auc=91.66%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.151210 Test loss=0.278434 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.15445001423358917
[5/24] Train loss=0.14098374545574188
[10/24] Train loss=0.14176389575004578
[15/24] Train loss=0.15681347250938416
[20/24] Train loss=0.15044468641281128
Test set avg_accuracy=90.29% avg_sensitivity=74.57%, avg_specificity=94.84% avg_auc=92.84%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.151702 Test loss=0.264586 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.16051185131072998
[5/24] Train loss=0.14476178586483002
[10/24] Train loss=0.13348831236362457
[15/24] Train loss=0.15722768008708954
[20/24] Train loss=0.14495553076267242
Test set avg_accuracy=89.67% avg_sensitivity=73.99%, avg_specificity=94.22% avg_auc=92.80%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.149871 Test loss=0.272488 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.15640047192573547
[5/24] Train loss=0.14635352790355682
[10/24] Train loss=0.14565782248973846
[15/24] Train loss=0.16075338423252106
[20/24] Train loss=0.14719171822071075
Test set avg_accuracy=89.77% avg_sensitivity=69.47%, avg_specificity=95.65% avg_auc=92.63%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.150993 Test loss=0.269942 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15273766219615936
[5/24] Train loss=0.1373494565486908
[10/24] Train loss=0.1435392200946808
[15/24] Train loss=0.15577425062656403
[20/24] Train loss=0.14734430611133575
Test set avg_accuracy=90.10% avg_sensitivity=74.45%, avg_specificity=94.64% avg_auc=92.28%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.148988 Test loss=0.266446 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15049324929714203
[5/24] Train loss=0.1441098302602768
[10/24] Train loss=0.13610343635082245
[15/24] Train loss=0.15908096730709076
[20/24] Train loss=0.14200857281684875
Test set avg_accuracy=89.67% avg_sensitivity=66.57%, avg_specificity=96.37% avg_auc=91.01%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.148779 Test loss=0.291669 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15804733335971832
[5/24] Train loss=0.1398976594209671
[10/24] Train loss=0.13898669183254242
[15/24] Train loss=0.16119369864463806
[20/24] Train loss=0.14166288077831268
Test set avg_accuracy=89.82% avg_sensitivity=69.06%, avg_specificity=95.83% avg_auc=92.58%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.149638 Test loss=0.272679 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.15536178648471832
[5/24] Train loss=0.13617387413978577
[10/24] Train loss=0.13324971497058868
[15/24] Train loss=0.15421171486377716
[20/24] Train loss=0.13961854577064514
Test set avg_accuracy=90.01% avg_sensitivity=72.42%, avg_specificity=95.11% avg_auc=92.69%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.149737 Test loss=0.265951 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15273705124855042
[5/24] Train loss=0.1481229066848755
[10/24] Train loss=0.13872331380844116
[15/24] Train loss=0.15110225975513458
[20/24] Train loss=0.14477309584617615
Test set avg_accuracy=90.17% avg_sensitivity=75.26%, avg_specificity=94.49% avg_auc=93.44%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.150538 Test loss=0.260650 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.15669673681259155
[5/24] Train loss=0.1473887413740158
[10/24] Train loss=0.14028453826904297
[15/24] Train loss=0.15606462955474854
[20/24] Train loss=0.14106875658035278
Test set avg_accuracy=89.91% avg_sensitivity=72.89%, avg_specificity=94.84% avg_auc=92.66%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.148458 Test loss=0.272399 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14976483583450317
[5/24] Train loss=0.1408114731311798
[10/24] Train loss=0.1341053694486618
[15/24] Train loss=0.14832983911037445
[20/24] Train loss=0.14223739504814148
Test set avg_accuracy=90.27% avg_sensitivity=73.29%, avg_specificity=95.20% avg_auc=92.96%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.145090 Test loss=0.263024 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.15302814543247223
[5/24] Train loss=0.1347101628780365
[10/24] Train loss=0.1389683485031128
[15/24] Train loss=0.14428465068340302
[20/24] Train loss=0.13445740938186646
Test set avg_accuracy=90.17% avg_sensitivity=76.01%, avg_specificity=94.27% avg_auc=93.47%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.144127 Test loss=0.264513 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14652866125106812
[5/24] Train loss=0.13755500316619873
[10/24] Train loss=0.1286022812128067
[15/24] Train loss=0.14837177097797394
[20/24] Train loss=0.13424749672412872
Test set avg_accuracy=89.82% avg_sensitivity=69.24%, avg_specificity=95.78% avg_auc=91.72%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.141577 Test loss=0.280222 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14797285199165344
[5/24] Train loss=0.13518449664115906
[10/24] Train loss=0.1322486400604248
[15/24] Train loss=0.1465529501438141
[20/24] Train loss=0.13781839609146118
Test set avg_accuracy=89.65% avg_sensitivity=67.03%, avg_specificity=96.20% avg_auc=91.14%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.141857 Test loss=0.291017 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1454189270734787
[5/24] Train loss=0.12956631183624268
[10/24] Train loss=0.1351119428873062
[15/24] Train loss=0.14262942969799042
[20/24] Train loss=0.1357782483100891
Test set avg_accuracy=89.47% avg_sensitivity=64.77%, avg_specificity=96.62% avg_auc=89.37%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.140048 Test loss=0.299332 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14763572812080383
[5/24] Train loss=0.12864680588245392
[10/24] Train loss=0.13030403852462769
[15/24] Train loss=0.14182621240615845
[20/24] Train loss=0.13449451327323914
Test set avg_accuracy=89.52% avg_sensitivity=63.96%, avg_specificity=96.93% avg_auc=89.13%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.139827 Test loss=0.306547 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1533796638250351
[5/24] Train loss=0.13260681927204132
[10/24] Train loss=0.12755508720874786
[15/24] Train loss=0.14591506123542786
[20/24] Train loss=0.13136929273605347
Test set avg_accuracy=89.51% avg_sensitivity=66.28%, avg_specificity=96.24% avg_auc=90.82%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.138812 Test loss=0.292315 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14302261173725128
[5/24] Train loss=0.13066324591636658
[10/24] Train loss=0.1253431886434555
[15/24] Train loss=0.13760219514369965
[20/24] Train loss=0.13149075210094452
Test set avg_accuracy=90.18% avg_sensitivity=72.07%, avg_specificity=95.43% avg_auc=92.85%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.135405 Test loss=0.264588 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14192000031471252
[5/24] Train loss=0.13246729969978333
[10/24] Train loss=0.12002531439065933
[15/24] Train loss=0.13686519861221313
[20/24] Train loss=0.13034477829933167
Test set avg_accuracy=90.13% avg_sensitivity=73.06%, avg_specificity=95.08% avg_auc=92.93%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.134913 Test loss=0.264085 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.13996019959449768
[5/24] Train loss=0.12880146503448486
[10/24] Train loss=0.12312163412570953
[15/24] Train loss=0.13451123237609863
[20/24] Train loss=0.13219361007213593
Test set avg_accuracy=90.13% avg_sensitivity=74.45%, avg_specificity=94.68% avg_auc=92.57%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.133059 Test loss=0.268987 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13995787501335144
[5/24] Train loss=0.12805308401584625
[10/24] Train loss=0.1212114691734314
[15/24] Train loss=0.13642963767051697
[20/24] Train loss=0.13152997195720673
Test set avg_accuracy=90.00% avg_sensitivity=70.34%, avg_specificity=95.70% avg_auc=92.33%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.132492 Test loss=0.269842 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13672573864459991
[5/24] Train loss=0.1273617148399353
[10/24] Train loss=0.12584316730499268
[15/24] Train loss=0.13748908042907715
[20/24] Train loss=0.12871919572353363
Test set avg_accuracy=90.20% avg_sensitivity=74.91%, avg_specificity=94.63% avg_auc=92.61%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.132641 Test loss=0.266617 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13900147378444672
[5/24] Train loss=0.12402983009815216
[10/24] Train loss=0.12259446084499359
[15/24] Train loss=0.13444681465625763
[20/24] Train loss=0.12831833958625793
Test set avg_accuracy=89.95% avg_sensitivity=75.26%, avg_specificity=94.21% avg_auc=92.70%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.131495 Test loss=0.266912 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13667510449886322
[5/24] Train loss=0.12254828214645386
[10/24] Train loss=0.12355123460292816
[15/24] Train loss=0.13342244923114777
[20/24] Train loss=0.1300494372844696
Test set avg_accuracy=89.82% avg_sensitivity=72.77%, avg_specificity=94.76% avg_auc=92.56%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.130630 Test loss=0.269054 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13788336515426636
[5/24] Train loss=0.12274394929409027
[10/24] Train loss=0.11915753036737442
[15/24] Train loss=0.13423271477222443
[20/24] Train loss=0.12745100259780884
Test set avg_accuracy=89.77% avg_sensitivity=72.02%, avg_specificity=94.91% avg_auc=92.56%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.130347 Test loss=0.270063 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13970330357551575
[5/24] Train loss=0.1269056349992752
[10/24] Train loss=0.1174820140004158
[15/24] Train loss=0.1318575143814087
[20/24] Train loss=0.12612953782081604
Test set avg_accuracy=89.66% avg_sensitivity=70.74%, avg_specificity=95.15% avg_auc=92.07%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.130374 Test loss=0.277533 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13782046735286713
[5/24] Train loss=0.1239389106631279
[10/24] Train loss=0.1189463660120964
[15/24] Train loss=0.12934669852256775
[20/24] Train loss=0.1252928525209427
Test set avg_accuracy=90.04% avg_sensitivity=70.16%, avg_specificity=95.80% avg_auc=91.71%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.130268 Test loss=0.275916 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1344335377216339
[5/24] Train loss=0.1245826929807663
[10/24] Train loss=0.11779533326625824
[15/24] Train loss=0.1318444311618805
[20/24] Train loss=0.1256692111492157
Test set avg_accuracy=89.96% avg_sensitivity=72.71%, avg_specificity=94.96% avg_auc=92.64%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.129372 Test loss=0.266803 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1340102255344391
[5/24] Train loss=0.1242382600903511
[10/24] Train loss=0.11828739196062088
[15/24] Train loss=0.13146470487117767
[20/24] Train loss=0.12550759315490723
Test set avg_accuracy=89.93% avg_sensitivity=74.28%, avg_specificity=94.47% avg_auc=92.51%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.128846 Test loss=0.269737 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13206225633621216
[5/24] Train loss=0.12441390752792358
[10/24] Train loss=0.12306153029203415
[15/24] Train loss=0.12854592502117157
[20/24] Train loss=0.12588727474212646
Test set avg_accuracy=90.25% avg_sensitivity=72.83%, avg_specificity=95.30% avg_auc=92.26%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.128924 Test loss=0.270938 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13346529006958008
[5/24] Train loss=0.12165159732103348
[10/24] Train loss=0.11926677078008652
[15/24] Train loss=0.12838028371334076
[20/24] Train loss=0.12538127601146698
Test set avg_accuracy=90.34% avg_sensitivity=73.35%, avg_specificity=95.26% avg_auc=92.75%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.127809 Test loss=0.265471 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13215506076812744
[5/24] Train loss=0.11937794089317322
[10/24] Train loss=0.12004417181015015
[15/24] Train loss=0.12777438759803772
[20/24] Train loss=0.12266204506158829
Test set avg_accuracy=90.07% avg_sensitivity=73.52%, avg_specificity=94.86% avg_auc=92.61%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.126946 Test loss=0.266037 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13263677060604095
[5/24] Train loss=0.12048555165529251
[10/24] Train loss=0.11690372228622437
[15/24] Train loss=0.12515224516391754
[20/24] Train loss=0.1249549463391304
Test set avg_accuracy=90.12% avg_sensitivity=72.13%, avg_specificity=95.33% avg_auc=92.37%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.125748 Test loss=0.269216 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12969215214252472
[5/24] Train loss=0.11978436261415482
[10/24] Train loss=0.1158052533864975
[15/24] Train loss=0.12643791735172272
[20/24] Train loss=0.12444110214710236
Test set avg_accuracy=90.03% avg_sensitivity=72.07%, avg_specificity=95.23% avg_auc=92.42%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.125499 Test loss=0.268045 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.13059602677822113
[5/24] Train loss=0.11902949959039688
[10/24] Train loss=0.11678948998451233
[15/24] Train loss=0.1288357973098755
[20/24] Train loss=0.12408243119716644
Test set avg_accuracy=90.17% avg_sensitivity=72.07%, avg_specificity=95.41% avg_auc=92.30%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.125285 Test loss=0.270132 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12797608971595764
[5/24] Train loss=0.12231800705194473
[10/24] Train loss=0.11603926122188568
[15/24] Train loss=0.12682093679904938
[20/24] Train loss=0.12234070152044296
Test set avg_accuracy=90.20% avg_sensitivity=72.94%, avg_specificity=95.20% avg_auc=92.47%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.124516 Test loss=0.267452 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12938658893108368
[5/24] Train loss=0.1210162490606308
[10/24] Train loss=0.11747098714113235
[15/24] Train loss=0.12567701935768127
[20/24] Train loss=0.12282494455575943
Test set avg_accuracy=90.13% avg_sensitivity=72.07%, avg_specificity=95.36% avg_auc=92.05%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.124713 Test loss=0.271248 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13056553900241852
[5/24] Train loss=0.11743996292352676
[10/24] Train loss=0.11364750564098358
[15/24] Train loss=0.12305783480405807
[20/24] Train loss=0.11937513947486877
Test set avg_accuracy=90.14% avg_sensitivity=71.61%, avg_specificity=95.52% avg_auc=92.12%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.123846 Test loss=0.270859 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1288408637046814
[5/24] Train loss=0.11824377626180649
[10/24] Train loss=0.11410637199878693
[15/24] Train loss=0.12517383694648743
[20/24] Train loss=0.12218112498521805
Test set avg_accuracy=90.27% avg_sensitivity=72.60%, avg_specificity=95.40% avg_auc=92.45%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.123971 Test loss=0.267624 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12721575796604156
[5/24] Train loss=0.11700325459241867
[10/24] Train loss=0.11350564658641815
[15/24] Train loss=0.1253158450126648
[20/24] Train loss=0.12312691658735275
Test set avg_accuracy=90.31% avg_sensitivity=73.12%, avg_specificity=95.30% avg_auc=92.55%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.123831 Test loss=0.266372 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12828534841537476
[5/24] Train loss=0.11954283714294434
[10/24] Train loss=0.11436782777309418
[15/24] Train loss=0.12347914278507233
[20/24] Train loss=0.12173373252153397
Test set avg_accuracy=90.33% avg_sensitivity=73.23%, avg_specificity=95.28% avg_auc=92.57%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.123660 Test loss=0.266162 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12868376076221466
[5/24] Train loss=0.11971701681613922
[10/24] Train loss=0.11417872458696365
[15/24] Train loss=0.12559747695922852
[20/24] Train loss=0.12209858745336533
Test set avg_accuracy=90.30% avg_sensitivity=72.48%, avg_specificity=95.47% avg_auc=92.31%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.123228 Test loss=0.269707 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1279776245355606
[5/24] Train loss=0.11815249919891357
[10/24] Train loss=0.11354672908782959
[15/24] Train loss=0.12176041305065155
[20/24] Train loss=0.12098085880279541
Test set avg_accuracy=90.22% avg_sensitivity=72.25%, avg_specificity=95.43% avg_auc=92.28%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.123007 Test loss=0.269731 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12749990820884705
[5/24] Train loss=0.11895901709794998
[10/24] Train loss=0.11400210857391357
[15/24] Train loss=0.1230475902557373
[20/24] Train loss=0.12006067484617233
Test set avg_accuracy=90.33% avg_sensitivity=72.60%, avg_specificity=95.47% avg_auc=92.30%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.123399 Test loss=0.269285 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12619942426681519
[5/24] Train loss=0.12032239139080048
[10/24] Train loss=0.113908551633358
[15/24] Train loss=0.12315312027931213
[20/24] Train loss=0.12289295345544815
Test set avg_accuracy=90.36% avg_sensitivity=72.89%, avg_specificity=95.43% avg_auc=92.37%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.123277 Test loss=0.268704 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12752309441566467
[5/24] Train loss=0.11843980848789215
[10/24] Train loss=0.11397001892328262
[15/24] Train loss=0.12364685535430908
[20/24] Train loss=0.12048080563545227
Test set avg_accuracy=90.38% avg_sensitivity=72.77%, avg_specificity=95.48% avg_auc=92.37%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.122966 Test loss=0.268697 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1261790692806244
[5/24] Train loss=0.11850202828645706
[10/24] Train loss=0.11656476557254791
[15/24] Train loss=0.12431488931179047
[20/24] Train loss=0.11756571382284164
Test set avg_accuracy=90.34% avg_sensitivity=72.71%, avg_specificity=95.45% avg_auc=92.37%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.122999 Test loss=0.268676 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.127132385969162
[5/24] Train loss=0.12098871171474457
[10/24] Train loss=0.1155739277601242
[15/24] Train loss=0.12243044376373291
[20/24] Train loss=0.12047331035137177
Test set avg_accuracy=90.38% avg_sensitivity=72.89%, avg_specificity=95.45% avg_auc=92.38%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.123467 Test loss=0.268526 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=90.29% sen=76.13%, spe=94.39%, auc=93.60%!
Fold[10] Avg_overlap=0.71%(0.2509960923923268)
Final Avg Result: avg_acc=88.70%(1.27998095769022) avg_sen=79.26% (2.5530427975777075) avg_spe=91.92% (1.9971504005354295) avg_auc=93.77% (0.6884385997430916) avg_overlap=0.70% (0.019230935273387022)
