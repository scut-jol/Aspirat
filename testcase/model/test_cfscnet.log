/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/24] Train loss=1.5081186294555664
[5/24] Train loss=1.4841570854187012
[10/24] Train loss=1.4509303569793701
[15/24] Train loss=1.4214730262756348
[20/24] Train loss=1.4247629642486572
Test set avg_accuracy=70.64% avg_sensitivity=35.97%, avg_specificity=83.02% avg_auc=60.10%
Best model saved!! Metric=-76.2677338074376!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=1.447526 Test loss=0.685771 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.409332036972046
[5/24] Train loss=1.405203104019165
[10/24] Train loss=1.3979737758636475
[15/24] Train loss=1.3537023067474365
[20/24] Train loss=1.3320903778076172
Test set avg_accuracy=71.61% avg_sensitivity=76.74%, avg_specificity=69.78% avg_auc=72.60%
Best model saved!! Metric=-35.261281929787!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=1.376841 Test loss=0.639462 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3347705602645874
[5/24] Train loss=1.31314218044281
[10/24] Train loss=1.3207314014434814
[15/24] Train loss=1.265379786491394
[20/24] Train loss=1.2713245153427124
Test set avg_accuracy=71.81% avg_sensitivity=83.57%, avg_specificity=67.61% avg_auc=77.76%
Best model saved!! Metric=-25.252720331850057!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=1.300026 Test loss=0.609992 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.2402780055999756
[5/24] Train loss=1.2286200523376465
[10/24] Train loss=1.2405898571014404
[15/24] Train loss=1.1897233724594116
[20/24] Train loss=1.1571040153503418
Test set avg_accuracy=71.84% avg_sensitivity=85.30%, avg_specificity=67.03% avg_auc=81.03%
Best model saved!! Metric=-20.806842904620538!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=1.221836 Test loss=0.584967 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.1486036777496338
[5/24] Train loss=1.1380537748336792
[10/24] Train loss=1.180809736251831
[15/24] Train loss=1.108169436454773
[20/24] Train loss=1.0880292654037476
Test set avg_accuracy=71.78% avg_sensitivity=87.43%, avg_specificity=66.20% avg_auc=83.12%
Best model saved!! Metric=-17.464727893463746!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=1.148182 Test loss=0.578401 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.0633333921432495
[5/24] Train loss=1.0760605335235596
[10/24] Train loss=1.1200627088546753
[15/24] Train loss=1.0396020412445068
[20/24] Train loss=1.0330723524093628
Test set avg_accuracy=72.01% avg_sensitivity=88.22%, avg_specificity=66.21% avg_auc=85.05%
Best model saved!! Metric=-14.511775424154195!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=1.081677 Test loss=0.566177 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.0096685886383057
[5/24] Train loss=1.0035961866378784
[10/24] Train loss=1.0688222646713257
[15/24] Train loss=0.9836781024932861
[20/24] Train loss=0.9744032025337219
Test set avg_accuracy=75.39% avg_sensitivity=85.90%, avg_specificity=71.64% avg_auc=86.49%
Best model saved!! Metric=-6.582135480408937!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=1.020107 Test loss=0.527239 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9407703876495361
[5/24] Train loss=0.9526423811912537
[10/24] Train loss=1.0069010257720947
[15/24] Train loss=0.9321046471595764
[20/24] Train loss=0.9075560569763184
Test set avg_accuracy=77.20% avg_sensitivity=86.54%, avg_specificity=73.86% avg_auc=88.44%
Best model saved!! Metric=0.05121288207161001!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.960100 Test loss=0.501286 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.8854203224182129
[5/24] Train loss=0.8960047960281372
[10/24] Train loss=0.9391620755195618
[15/24] Train loss=0.8853975534439087
[20/24] Train loss=0.8560231924057007
Test set avg_accuracy=78.75% avg_sensitivity=86.64%, avg_specificity=75.93% avg_auc=89.72%
Best model saved!! Metric=5.040484285037152!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.906109 Test loss=0.476905 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8222323656082153
[5/24] Train loss=0.8436813354492188
[10/24] Train loss=0.9185468554496765
[15/24] Train loss=0.8397144675254822
[20/24] Train loss=0.8200849890708923
Test set avg_accuracy=79.67% avg_sensitivity=87.14%, avg_specificity=77.01% avg_auc=90.50%
Best model saved!! Metric=8.318074306897287!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.860918 Test loss=0.463232 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.7866779565811157
[5/24] Train loss=0.7969790697097778
[10/24] Train loss=0.8677974343299866
[15/24] Train loss=0.8110196590423584
[20/24] Train loss=0.7564972043037415
Test set avg_accuracy=82.20% avg_sensitivity=86.15%, avg_specificity=80.79% avg_auc=91.22%
Best model saved!! Metric=14.358959541791165!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.820400 Test loss=0.429609 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.7471975684165955
[5/24] Train loss=0.7718521356582642
[10/24] Train loss=0.8402911424636841
[15/24] Train loss=0.777599573135376
[20/24] Train loss=0.7043524980545044
Test set avg_accuracy=82.58% avg_sensitivity=87.18%, avg_specificity=80.93% avg_auc=91.84%
Best model saved!! Metric=16.535067648226473!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.783252 Test loss=0.423178 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7220638394355774
[5/24] Train loss=0.7312725186347961
[10/24] Train loss=0.8037177324295044
[15/24] Train loss=0.7623733878135681
[20/24] Train loss=0.7006340622901917
Test set avg_accuracy=84.56% avg_sensitivity=83.97%, avg_specificity=84.77% avg_auc=92.13%
Best model saved!! Metric=19.421687851661503!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.754715 Test loss=0.384390 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.6922909617424011
[5/24] Train loss=0.7025530338287354
[10/24] Train loss=0.7920757532119751
[15/24] Train loss=0.7382354140281677
[20/24] Train loss=0.6867237687110901
Test set avg_accuracy=85.33% avg_sensitivity=83.23%, avg_specificity=86.08% avg_auc=92.44%
Best model saved!! Metric=21.061993647193887!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.730924 Test loss=0.365996 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.6625939011573792
[5/24] Train loss=0.6807506680488586
[10/24] Train loss=0.7516217827796936
[15/24] Train loss=0.719687819480896
[20/24] Train loss=0.6552473306655884
Test set avg_accuracy=85.74% avg_sensitivity=80.80%, avg_specificity=87.51% avg_auc=92.57%
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.710371 Test loss=0.349434 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.6495791673660278
[5/24] Train loss=0.6592534780502319
[10/24] Train loss=0.77164626121521
[15/24] Train loss=0.7173522114753723
[20/24] Train loss=0.639059841632843
Test set avg_accuracy=85.31% avg_sensitivity=84.96%, avg_specificity=85.44% avg_auc=93.03%
Best model saved!! Metric=22.73588997689835!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.695165 Test loss=0.363749 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6207648515701294
[5/24] Train loss=0.6332834362983704
[10/24] Train loss=0.7431301474571228
[15/24] Train loss=0.6940397024154663
[20/24] Train loss=0.6028932332992554
Test set avg_accuracy=85.73% avg_sensitivity=85.11%, avg_specificity=85.95% avg_auc=93.21%
Best model saved!! Metric=23.998743251595442!!
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.674950 Test loss=0.354429 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.61586993932724
[5/24] Train loss=0.6202824711799622
[10/24] Train loss=0.7418627738952637
[15/24] Train loss=0.6710004806518555
[20/24] Train loss=0.6049609184265137
Test set avg_accuracy=85.25% avg_sensitivity=85.11%, avg_specificity=85.30% avg_auc=93.35%
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.662257 Test loss=0.353110 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5865920186042786
[5/24] Train loss=0.6156331896781921
[10/24] Train loss=0.7132731676101685
[15/24] Train loss=0.6726511120796204
[20/24] Train loss=0.6046850681304932
Test set avg_accuracy=85.56% avg_sensitivity=85.90%, avg_specificity=85.44% avg_auc=93.53%
Best model saved!! Metric=24.424816114190662!!
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.648286 Test loss=0.354982 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5932829976081848
[5/24] Train loss=0.6022017598152161
[10/24] Train loss=0.6976542472839355
[15/24] Train loss=0.6461795568466187
[20/24] Train loss=0.5794838666915894
Test set avg_accuracy=84.43% avg_sensitivity=87.48%, avg_specificity=83.34% avg_auc=93.68%
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.636351 Test loss=0.372638 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5893755555152893
[5/24] Train loss=0.582987904548645
[10/24] Train loss=0.6892490983009338
[15/24] Train loss=0.6442912220954895
[20/24] Train loss=0.5708147883415222
Test set avg_accuracy=84.53% avg_sensitivity=87.88%, avg_specificity=83.34% avg_auc=93.86%
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.623250 Test loss=0.369922 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5714182257652283
[5/24] Train loss=0.5719936490058899
[10/24] Train loss=0.6828346848487854
[15/24] Train loss=0.6140645742416382
[20/24] Train loss=0.5380005240440369
Test set avg_accuracy=84.86% avg_sensitivity=87.18%, avg_specificity=84.03% avg_auc=93.83%
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.609919 Test loss=0.360371 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5649679899215698
[5/24] Train loss=0.5530376434326172
[10/24] Train loss=0.6722539663314819
[15/24] Train loss=0.61664879322052
[20/24] Train loss=0.5395624041557312
Test set avg_accuracy=86.88% avg_sensitivity=83.87%, avg_specificity=87.95% avg_auc=94.02%
Best model saved!! Metric=26.717240150447168!!
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.597205 Test loss=0.317660 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.550383985042572
[5/24] Train loss=0.5335060954093933
[10/24] Train loss=0.655832052230835
[15/24] Train loss=0.6098840236663818
[20/24] Train loss=0.5213098526000977
Test set avg_accuracy=84.48% avg_sensitivity=87.28%, avg_specificity=83.48% avg_auc=94.04%
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.585218 Test loss=0.363962 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.536091148853302
[5/24] Train loss=0.5341815948486328
[10/24] Train loss=0.6520602107048035
[15/24] Train loss=0.6028168797492981
[20/24] Train loss=0.5091781616210938
Test set avg_accuracy=86.37% avg_sensitivity=84.66%, avg_specificity=86.98% avg_auc=93.99%
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.575197 Test loss=0.321484 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5207145810127258
[5/24] Train loss=0.5091521739959717
[10/24] Train loss=0.6376396417617798
[15/24] Train loss=0.5838937163352966
[20/24] Train loss=0.5178158283233643
Test set avg_accuracy=85.61% avg_sensitivity=85.75%, avg_specificity=85.56% avg_auc=93.69%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.561621 Test loss=0.347312 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5335790514945984
[5/24] Train loss=0.4945043921470642
[10/24] Train loss=0.6194960474967957
[15/24] Train loss=0.5766343474388123
[20/24] Train loss=0.5051125288009644
Test set avg_accuracy=85.86% avg_sensitivity=83.72%, avg_specificity=86.62% avg_auc=93.94%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.553892 Test loss=0.328079 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.5168463587760925
[5/24] Train loss=0.5079264640808105
[10/24] Train loss=0.6115331053733826
[15/24] Train loss=0.5527612566947937
[20/24] Train loss=0.48975685238838196
Test set avg_accuracy=83.87% avg_sensitivity=87.98%, avg_specificity=82.40% avg_auc=93.65%
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.546106 Test loss=0.380508 Current lr=[0.000210185142098938]

[0/24] Train loss=0.515860378742218
[5/24] Train loss=0.4711940884590149
[10/24] Train loss=0.5912689566612244
[15/24] Train loss=0.5611300468444824
[20/24] Train loss=0.47825291752815247
Test set avg_accuracy=83.83% avg_sensitivity=87.14%, avg_specificity=82.65% avg_auc=93.74%
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.533597 Test loss=0.373260 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.5037314295768738
[5/24] Train loss=0.4690137505531311
[10/24] Train loss=0.5705059170722961
[15/24] Train loss=0.5495787858963013
[20/24] Train loss=0.46671220660209656
Test set avg_accuracy=85.53% avg_sensitivity=82.09%, avg_specificity=86.76% avg_auc=92.63%
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.523841 Test loss=0.357414 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.4878109097480774
[5/24] Train loss=0.4822665750980377
[10/24] Train loss=0.5541960597038269
[15/24] Train loss=0.5195759534835815
[20/24] Train loss=0.466907799243927
Test set avg_accuracy=83.70% avg_sensitivity=88.62%, avg_specificity=81.94% avg_auc=92.95%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.518495 Test loss=0.389174 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.5051424503326416
[5/24] Train loss=0.4531600773334503
[10/24] Train loss=0.531875729560852
[15/24] Train loss=0.5190333724021912
[20/24] Train loss=0.44580867886543274
Test set avg_accuracy=78.91% avg_sensitivity=90.80%, avg_specificity=74.66% avg_auc=92.52%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.502339 Test loss=0.484652 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.4782540798187256
[5/24] Train loss=0.46783819794654846
[10/24] Train loss=0.5329724550247192
[15/24] Train loss=0.5620827078819275
[20/24] Train loss=0.4393003284931183
Test set avg_accuracy=84.04% avg_sensitivity=86.44%, avg_specificity=83.18% avg_auc=93.61%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.496317 Test loss=0.365095 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.475650429725647
[5/24] Train loss=0.4443504512310028
[10/24] Train loss=0.521611213684082
[15/24] Train loss=0.4961472451686859
[20/24] Train loss=0.42738407850265503
Test set avg_accuracy=84.49% avg_sensitivity=87.53%, avg_specificity=83.41% avg_auc=93.81%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.482040 Test loss=0.363590 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.4609479606151581
[5/24] Train loss=0.41150960326194763
[10/24] Train loss=0.5286214351654053
[15/24] Train loss=0.527792751789093
[20/24] Train loss=0.42848533391952515
Test set avg_accuracy=86.69% avg_sensitivity=82.43%, avg_specificity=88.21% avg_auc=93.00%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.479423 Test loss=0.330696 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.45689353346824646
[5/24] Train loss=0.39395275712013245
[10/24] Train loss=0.5027097463607788
[15/24] Train loss=0.5237957835197449
[20/24] Train loss=0.43308618664741516
Test set avg_accuracy=84.35% avg_sensitivity=83.92%, avg_specificity=84.50% avg_auc=92.74%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.471451 Test loss=0.357253 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.497764527797699
[5/24] Train loss=0.45614543557167053
[10/24] Train loss=0.5196232795715332
[15/24] Train loss=0.5251646041870117
[20/24] Train loss=0.43625983595848083
Test set avg_accuracy=86.95% avg_sensitivity=72.49%, avg_specificity=92.12% avg_auc=92.35%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.479166 Test loss=0.306189 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.45379209518432617
[5/24] Train loss=0.4552716910839081
[10/24] Train loss=0.5071039199829102
[15/24] Train loss=0.4961003363132477
[20/24] Train loss=0.3997812569141388
Test set avg_accuracy=84.30% avg_sensitivity=84.56%, avg_specificity=84.20% avg_auc=93.34%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.464551 Test loss=0.367942 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4526408612728119
[5/24] Train loss=0.39825302362442017
[10/24] Train loss=0.4891810417175293
[15/24] Train loss=0.4964313805103302
[20/24] Train loss=0.41095539927482605
Test set avg_accuracy=79.48% avg_sensitivity=89.21%, avg_specificity=76.00% avg_auc=92.58%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.456765 Test loss=0.472084 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.4517308473587036
[5/24] Train loss=0.4149268567562103
[10/24] Train loss=0.48054683208465576
[15/24] Train loss=0.5169576406478882
[20/24] Train loss=0.38815322518348694
Test set avg_accuracy=83.48% avg_sensitivity=84.61%, avg_specificity=83.07% avg_auc=92.85%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.456749 Test loss=0.373318 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.42757049202919006
[5/24] Train loss=0.4028117060661316
[10/24] Train loss=0.46431663632392883
[15/24] Train loss=0.4848116934299469
[20/24] Train loss=0.4302629828453064
Test set avg_accuracy=81.42% avg_sensitivity=89.61%, avg_specificity=78.49% avg_auc=93.04%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.445002 Test loss=0.435872 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.43724945187568665
[5/24] Train loss=0.4047032296657562
[10/24] Train loss=0.4493658244609833
[15/24] Train loss=0.47857674956321716
[20/24] Train loss=0.40382906794548035
Test set avg_accuracy=79.74% avg_sensitivity=89.36%, avg_specificity=76.30% avg_auc=92.21%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.434875 Test loss=0.473737 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4483749568462372
[5/24] Train loss=0.38438042998313904
[10/24] Train loss=0.5054863691329956
[15/24] Train loss=0.48028337955474854
[20/24] Train loss=0.39335668087005615
Test set avg_accuracy=85.09% avg_sensitivity=85.65%, avg_specificity=84.89% avg_auc=93.21%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.440755 Test loss=0.366003 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.41708457469940186
[5/24] Train loss=0.3670893907546997
[10/24] Train loss=0.4529902935028076
[15/24] Train loss=0.4621769189834595
[20/24] Train loss=0.37352991104125977
Test set avg_accuracy=83.32% avg_sensitivity=84.96%, avg_specificity=82.74% avg_auc=91.90%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.421080 Test loss=0.390796 Current lr=[0.00029967723776099]

[0/24] Train loss=0.4347677528858185
[5/24] Train loss=0.37847453355789185
[10/24] Train loss=0.48921048641204834
[15/24] Train loss=0.47604766488075256
[20/24] Train loss=0.4094255268573761
Test set avg_accuracy=86.68% avg_sensitivity=75.11%, avg_specificity=90.81% avg_auc=92.04%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.442026 Test loss=0.327791 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.4351826310157776
[5/24] Train loss=0.38739240169525146
[10/24] Train loss=0.4387266933917999
[15/24] Train loss=0.448627769947052
[20/24] Train loss=0.35615670680999756
Test set avg_accuracy=79.27% avg_sensitivity=86.39%, avg_specificity=76.73% avg_auc=90.27%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.418509 Test loss=0.475150 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.42470356822013855
[5/24] Train loss=0.3814369738101959
[10/24] Train loss=0.4550674259662628
[15/24] Train loss=0.4519900679588318
[20/24] Train loss=0.36611509323120117
Test set avg_accuracy=87.36% avg_sensitivity=78.77%, avg_specificity=90.42% avg_auc=92.64%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.424297 Test loss=0.317520 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3999783992767334
[5/24] Train loss=0.3608154356479645
[10/24] Train loss=0.4190824627876282
[15/24] Train loss=0.45573753118515015
[20/24] Train loss=0.3862353563308716
Test set avg_accuracy=86.52% avg_sensitivity=73.58%, avg_specificity=91.15% avg_auc=89.77%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.417470 Test loss=0.368701 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3958093822002411
[5/24] Train loss=0.40259039402008057
[10/24] Train loss=0.4377758800983429
[15/24] Train loss=0.46178755164146423
[20/24] Train loss=0.37087276577949524
Test set avg_accuracy=87.43% avg_sensitivity=81.20%, avg_specificity=89.66% avg_auc=93.33%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.421899 Test loss=0.315945 Current lr=[0.000298904600941902]

[0/24] Train loss=0.4036940038204193
[5/24] Train loss=0.36480435729026794
[10/24] Train loss=0.44324731826782227
[15/24] Train loss=0.43168315291404724
[20/24] Train loss=0.36454692482948303
Test set avg_accuracy=83.35% avg_sensitivity=85.90%, avg_specificity=82.44% avg_auc=92.18%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.408429 Test loss=0.388471 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3609190881252289
[5/24] Train loss=0.35456952452659607
[10/24] Train loss=0.41615569591522217
[15/24] Train loss=0.44919779896736145
[20/24] Train loss=0.373877614736557
Test set avg_accuracy=74.38% avg_sensitivity=90.99%, avg_specificity=68.44% avg_auc=90.57%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.394463 Test loss=0.605856 Current lr=[0.000297555943323901]

[0/24] Train loss=0.38513675332069397
[5/24] Train loss=0.36278438568115234
[10/24] Train loss=0.40977129340171814
[15/24] Train loss=0.4450465142726898
[20/24] Train loss=0.3947206139564514
Test set avg_accuracy=76.91% avg_sensitivity=90.20%, avg_specificity=72.17% avg_auc=90.81%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.397764 Test loss=0.539828 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.40039917826652527
[5/24] Train loss=0.334884911775589
[10/24] Train loss=0.40065258741378784
[15/24] Train loss=0.4135488271713257
[20/24] Train loss=0.3543628752231598
Test set avg_accuracy=86.28% avg_sensitivity=72.49%, avg_specificity=91.20% avg_auc=90.77%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.377765 Test loss=0.343345 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3722563087940216
[5/24] Train loss=0.3700447082519531
[10/24] Train loss=0.44615429639816284
[15/24] Train loss=0.44225993752479553
[20/24] Train loss=0.3515806496143341
Test set avg_accuracy=85.83% avg_sensitivity=71.05%, avg_specificity=91.11% avg_auc=90.19%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.394568 Test loss=0.354959 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3779074549674988
[5/24] Train loss=0.3238058388233185
[10/24] Train loss=0.3814704418182373
[15/24] Train loss=0.40391528606414795
[20/24] Train loss=0.32966217398643494
Test set avg_accuracy=84.56% avg_sensitivity=86.39%, avg_specificity=83.90% avg_auc=92.68%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.365566 Test loss=0.396542 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3669852018356323
[5/24] Train loss=0.3287527561187744
[10/24] Train loss=0.3817216455936432
[15/24] Train loss=0.4034821391105652
[20/24] Train loss=0.3341497778892517
Test set avg_accuracy=82.84% avg_sensitivity=87.58%, avg_specificity=81.15% avg_auc=92.90%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.360781 Test loss=0.435131 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.34056931734085083
[5/24] Train loss=0.3148975074291229
[10/24] Train loss=0.3779585063457489
[15/24] Train loss=0.3829624354839325
[20/24] Train loss=0.34133726358413696
Test set avg_accuracy=83.57% avg_sensitivity=85.75%, avg_specificity=82.79% avg_auc=91.82%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.362621 Test loss=0.448168 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.36688125133514404
[5/24] Train loss=0.3194545805454254
[10/24] Train loss=0.3512926697731018
[15/24] Train loss=0.39258989691734314
[20/24] Train loss=0.3270379900932312
Test set avg_accuracy=84.82% avg_sensitivity=77.29%, avg_specificity=87.51% avg_auc=90.90%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.366964 Test loss=0.367627 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.36418065428733826
[5/24] Train loss=0.31813928484916687
[10/24] Train loss=0.40470659732818604
[15/24] Train loss=0.4089120626449585
[20/24] Train loss=0.3421895503997803
Test set avg_accuracy=83.19% avg_sensitivity=86.05%, avg_specificity=82.17% avg_auc=92.51%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.361739 Test loss=0.427337 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.32891419529914856
[5/24] Train loss=0.3350844979286194
[10/24] Train loss=0.3832460045814514
[15/24] Train loss=0.39817240834236145
[20/24] Train loss=0.34414762258529663
Test set avg_accuracy=83.37% avg_sensitivity=85.35%, avg_specificity=82.66% avg_auc=91.54%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.356004 Test loss=0.434222 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3405173718929291
[5/24] Train loss=0.30537644028663635
[10/24] Train loss=0.3944925367832184
[15/24] Train loss=0.37054672837257385
[20/24] Train loss=0.3122800290584564
Test set avg_accuracy=76.16% avg_sensitivity=92.43%, avg_specificity=70.35% avg_auc=92.21%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.348780 Test loss=0.596217 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.33942803740501404
[5/24] Train loss=0.280633807182312
[10/24] Train loss=0.3595542013645172
[15/24] Train loss=0.3752473294734955
[20/24] Train loss=0.3139965534210205
Test set avg_accuracy=82.02% avg_sensitivity=88.97%, avg_specificity=79.54% avg_auc=92.78%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.350321 Test loss=0.434008 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3198999762535095
[5/24] Train loss=0.30796054005622864
[10/24] Train loss=0.327545166015625
[15/24] Train loss=0.3909062445163727
[20/24] Train loss=0.3520107865333557
Test set avg_accuracy=78.07% avg_sensitivity=91.09%, avg_specificity=73.42% avg_auc=91.09%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.350758 Test loss=0.551530 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3246085047721863
[5/24] Train loss=0.2985500395298004
[10/24] Train loss=0.3434140384197235
[15/24] Train loss=0.3754638731479645
[20/24] Train loss=0.3246132731437683
Test set avg_accuracy=86.45% avg_sensitivity=84.31%, avg_specificity=87.21% avg_auc=93.14%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.350903 Test loss=0.349429 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3505397439002991
[5/24] Train loss=0.2827964425086975
[10/24] Train loss=0.38187479972839355
[15/24] Train loss=0.35128670930862427
[20/24] Train loss=0.3036356270313263
Test set avg_accuracy=85.10% avg_sensitivity=82.04%, avg_specificity=86.20% avg_auc=91.88%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.338861 Test loss=0.392530 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.32136762142181396
[5/24] Train loss=0.2852153182029724
[10/24] Train loss=0.36738651990890503
[15/24] Train loss=0.3531113564968109
[20/24] Train loss=0.3046441972255707
Test set avg_accuracy=86.12% avg_sensitivity=78.33%, avg_specificity=88.90% avg_auc=91.38%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.341259 Test loss=0.373212 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.33172672986984253
[5/24] Train loss=0.298907607793808
[10/24] Train loss=0.3460967540740967
[15/24] Train loss=0.34208738803863525
[20/24] Train loss=0.2948707938194275
Test set avg_accuracy=85.95% avg_sensitivity=84.96%, avg_specificity=86.31% avg_auc=92.57%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.330067 Test loss=0.370839 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3226120173931122
[5/24] Train loss=0.2968607246875763
[10/24] Train loss=0.32347410917282104
[15/24] Train loss=0.3462878167629242
[20/24] Train loss=0.3030185103416443
Test set avg_accuracy=86.48% avg_sensitivity=85.40%, avg_specificity=86.87% avg_auc=92.98%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.319001 Test loss=0.352753 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3012656569480896
[5/24] Train loss=0.28207653760910034
[10/24] Train loss=0.35752615332603455
[15/24] Train loss=0.3923380672931671
[20/24] Train loss=0.31621041893959045
Test set avg_accuracy=86.51% avg_sensitivity=72.88%, avg_specificity=91.38% avg_auc=90.37%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.331984 Test loss=0.364404 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.32785019278526306
[5/24] Train loss=0.2747536897659302
[10/24] Train loss=0.30155301094055176
[15/24] Train loss=0.330645889043808
[20/24] Train loss=0.29473477602005005
Test set avg_accuracy=86.86% avg_sensitivity=77.49%, avg_specificity=90.21% avg_auc=91.94%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.312323 Test loss=0.338473 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.28216949105262756
[5/24] Train loss=0.25101205706596375
[10/24] Train loss=0.30154910683631897
[15/24] Train loss=0.3123209774494171
[20/24] Train loss=0.2976747155189514
Test set avg_accuracy=86.80% avg_sensitivity=76.50%, avg_specificity=90.48% avg_auc=91.37%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.297223 Test loss=0.351997 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3021833002567291
[5/24] Train loss=0.2596118748188019
[10/24] Train loss=0.3090379536151886
[15/24] Train loss=0.3319782018661499
[20/24] Train loss=0.2963404357433319
Test set avg_accuracy=86.91% avg_sensitivity=74.52%, avg_specificity=91.34% avg_auc=92.02%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.312471 Test loss=0.337759 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.28971874713897705
[5/24] Train loss=0.29050183296203613
[10/24] Train loss=0.3386905789375305
[15/24] Train loss=0.33320552110671997
[20/24] Train loss=0.2879103124141693
Test set avg_accuracy=86.63% avg_sensitivity=72.54%, avg_specificity=91.66% avg_auc=91.49%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.304316 Test loss=0.342804 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.30554115772247314
[5/24] Train loss=0.276067316532135
[10/24] Train loss=0.2813378870487213
[15/24] Train loss=0.3320082426071167
[20/24] Train loss=0.2832658886909485
Test set avg_accuracy=86.69% avg_sensitivity=81.99%, avg_specificity=88.37% avg_auc=92.29%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.302396 Test loss=0.372167 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.2922497093677521
[5/24] Train loss=0.24869433045387268
[10/24] Train loss=0.30397507548332214
[15/24] Train loss=0.33714690804481506
[20/24] Train loss=0.28533822298049927
Test set avg_accuracy=87.49% avg_sensitivity=69.67%, avg_specificity=93.85% avg_auc=91.28%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.301788 Test loss=0.333622 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.296221524477005
[5/24] Train loss=0.2631123661994934
[10/24] Train loss=0.2925652861595154
[15/24] Train loss=0.3189062178134918
[20/24] Train loss=0.2751079499721527
Test set avg_accuracy=86.15% avg_sensitivity=64.42%, avg_specificity=93.90% avg_auc=90.35%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.298549 Test loss=0.359325 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.28772780299186707
[5/24] Train loss=0.2547023296356201
[10/24] Train loss=0.28656527400016785
[15/24] Train loss=0.29685622453689575
[20/24] Train loss=0.2873787581920624
Test set avg_accuracy=84.73% avg_sensitivity=51.95%, avg_specificity=96.43% avg_auc=88.34%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.295887 Test loss=0.385139 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2944025695323944
[5/24] Train loss=0.26937851309776306
[10/24] Train loss=0.2986368238925934
[15/24] Train loss=0.3052557110786438
[20/24] Train loss=0.26657021045684814
Test set avg_accuracy=87.16% avg_sensitivity=66.95%, avg_specificity=94.38% avg_auc=90.21%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.293713 Test loss=0.353111 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3226234018802643
[5/24] Train loss=0.2922290861606598
[10/24] Train loss=0.276937872171402
[15/24] Train loss=0.311947762966156
[20/24] Train loss=0.3010315001010895
Test set avg_accuracy=85.52% avg_sensitivity=82.19%, avg_specificity=86.71% avg_auc=92.11%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.300109 Test loss=0.380495 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2928329408168793
[5/24] Train loss=0.2486441731452942
[10/24] Train loss=0.2828100919723511
[15/24] Train loss=0.30768588185310364
[20/24] Train loss=0.2963693141937256
Test set avg_accuracy=86.77% avg_sensitivity=65.26%, avg_specificity=94.45% avg_auc=89.72%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.287626 Test loss=0.367002 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2763920724391937
[5/24] Train loss=0.2793256938457489
[10/24] Train loss=0.28599855303764343
[15/24] Train loss=0.3120978772640228
[20/24] Train loss=0.2747819721698761
Test set avg_accuracy=86.82% avg_sensitivity=63.43%, avg_specificity=95.18% avg_auc=89.37%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.291658 Test loss=0.350924 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.29071441292762756
[5/24] Train loss=0.25094395875930786
[10/24] Train loss=0.30208820104599
[15/24] Train loss=0.2890818119049072
[20/24] Train loss=0.27724477648735046
Test set avg_accuracy=86.60% avg_sensitivity=67.39%, avg_specificity=93.46% avg_auc=89.81%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.287639 Test loss=0.372927 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2721012830734253
[5/24] Train loss=0.24437148869037628
[10/24] Train loss=0.293124258518219
[15/24] Train loss=0.3122219741344452
[20/24] Train loss=0.2667769193649292
Test set avg_accuracy=85.00% avg_sensitivity=57.74%, avg_specificity=94.73% avg_auc=86.02%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.278603 Test loss=0.406089 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.28565675020217896
[5/24] Train loss=0.24091531336307526
[10/24] Train loss=0.29370221495628357
[15/24] Train loss=0.29722607135772705
[20/24] Train loss=0.25869524478912354
Test set avg_accuracy=87.24% avg_sensitivity=69.97%, avg_specificity=93.41% avg_auc=90.78%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.282161 Test loss=0.334579 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.25875502824783325
[5/24] Train loss=0.24370864033699036
[10/24] Train loss=0.3080672323703766
[15/24] Train loss=0.29889193177223206
[20/24] Train loss=0.25985297560691833
Test set avg_accuracy=86.35% avg_sensitivity=80.01%, avg_specificity=88.62% avg_auc=92.45%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.274871 Test loss=0.363063 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2740376889705658
[5/24] Train loss=0.25159022212028503
[10/24] Train loss=0.26442161202430725
[15/24] Train loss=0.28094717860221863
[20/24] Train loss=0.266919881105423
Test set avg_accuracy=85.68% avg_sensitivity=76.55%, avg_specificity=88.94% avg_auc=91.18%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.270487 Test loss=0.383183 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2579777240753174
[5/24] Train loss=0.24131639301776886
[10/24] Train loss=0.26017528772354126
[15/24] Train loss=0.27951228618621826
[20/24] Train loss=0.2530343234539032
Test set avg_accuracy=86.88% avg_sensitivity=78.08%, avg_specificity=90.02% avg_auc=91.89%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.267036 Test loss=0.372937 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.26070424914360046
[5/24] Train loss=0.23188424110412598
[10/24] Train loss=0.25549525022506714
[15/24] Train loss=0.28080034255981445
[20/24] Train loss=0.24703006446361542
Test set avg_accuracy=86.18% avg_sensitivity=80.85%, avg_specificity=88.09% avg_auc=92.35%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.269468 Test loss=0.381345 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.275379478931427
[5/24] Train loss=0.23234869539737701
[10/24] Train loss=0.29721149802207947
[15/24] Train loss=0.26523569226264954
[20/24] Train loss=0.2739735543727875
Test set avg_accuracy=86.05% avg_sensitivity=83.82%, avg_specificity=86.85% avg_auc=92.90%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.267379 Test loss=0.382928 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.24676431715488434
[5/24] Train loss=0.2266511172056198
[10/24] Train loss=0.24664045870304108
[15/24] Train loss=0.2735436260700226
[20/24] Train loss=0.23840327560901642
Test set avg_accuracy=86.90% avg_sensitivity=70.86%, avg_specificity=92.63% avg_auc=90.90%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.253961 Test loss=0.345225 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2496347427368164
[5/24] Train loss=0.22436301410198212
[10/24] Train loss=0.24949443340301514
[15/24] Train loss=0.2657291293144226
[20/24] Train loss=0.24134141206741333
Test set avg_accuracy=86.09% avg_sensitivity=69.57%, avg_specificity=92.00% avg_auc=88.98%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.247004 Test loss=0.378968 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2616334855556488
[5/24] Train loss=0.2461124211549759
[10/24] Train loss=0.25555238127708435
[15/24] Train loss=0.26469388604164124
[20/24] Train loss=0.2389005422592163
Test set avg_accuracy=86.13% avg_sensitivity=78.82%, avg_specificity=88.74% avg_auc=91.69%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.252434 Test loss=0.379240 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.24884529411792755
[5/24] Train loss=0.21725712716579437
[10/24] Train loss=0.23872284591197968
[15/24] Train loss=0.25588127970695496
[20/24] Train loss=0.2550378441810608
Test set avg_accuracy=87.08% avg_sensitivity=66.40%, avg_specificity=94.47% avg_auc=91.28%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.247304 Test loss=0.340746 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.23341278731822968
[5/24] Train loss=0.22174327075481415
[10/24] Train loss=0.25084972381591797
[15/24] Train loss=0.25851011276245117
[20/24] Train loss=0.2636414170265198
Test set avg_accuracy=84.95% avg_sensitivity=73.38%, avg_specificity=89.08% avg_auc=89.36%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.247539 Test loss=0.443226 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2435029298067093
[5/24] Train loss=0.24282148480415344
[10/24] Train loss=0.24021343886852264
[15/24] Train loss=0.25452920794487
[20/24] Train loss=0.23986929655075073
Test set avg_accuracy=86.76% avg_sensitivity=76.55%, avg_specificity=90.40% avg_auc=92.27%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.248147 Test loss=0.355620 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2372630387544632
[5/24] Train loss=0.21404346823692322
[10/24] Train loss=0.23724126815795898
[15/24] Train loss=0.24932855367660522
[20/24] Train loss=0.240999236702919
Test set avg_accuracy=86.94% avg_sensitivity=82.04%, avg_specificity=88.69% avg_auc=92.59%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.237913 Test loss=0.352125 Current lr=[0.000156543481933168]

[0/24] Train loss=0.22771696746349335
[5/24] Train loss=0.22761061787605286
[10/24] Train loss=0.24013811349868774
[15/24] Train loss=0.245298370718956
[20/24] Train loss=0.2368217408657074
Test set avg_accuracy=87.57% avg_sensitivity=76.84%, avg_specificity=91.39% avg_auc=92.24%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.235395 Test loss=0.337699 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.22831173241138458
[5/24] Train loss=0.2170773595571518
[10/24] Train loss=0.23095597326755524
[15/24] Train loss=0.23936545848846436
[20/24] Train loss=0.21951349079608917
Test set avg_accuracy=85.96% avg_sensitivity=82.78%, avg_specificity=87.10% avg_auc=92.76%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.227456 Test loss=0.376119 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2070976346731186
[5/24] Train loss=0.21866220235824585
[10/24] Train loss=0.2310446947813034
[15/24] Train loss=0.24146753549575806
[20/24] Train loss=0.2368154078722
Test set avg_accuracy=87.72% avg_sensitivity=81.89%, avg_specificity=89.80% avg_auc=93.32%
Best model saved!! Metric=26.73254301001751!!
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.229344 Test loss=0.341699 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.2223021686077118
[5/24] Train loss=0.21719229221343994
[10/24] Train loss=0.22201135754585266
[15/24] Train loss=0.2458832561969757
[20/24] Train loss=0.21289531886577606
Test set avg_accuracy=87.17% avg_sensitivity=77.78%, avg_specificity=90.53% avg_auc=91.93%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.224940 Test loss=0.344171 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.21598641574382782
[5/24] Train loss=0.20673467218875885
[10/24] Train loss=0.21652983129024506
[15/24] Train loss=0.21896547079086304
[20/24] Train loss=0.2231830358505249
Test set avg_accuracy=87.20% avg_sensitivity=78.57%, avg_specificity=90.28% avg_auc=92.47%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.217195 Test loss=0.336128 Current lr=[0.000134135431043539]

[0/24] Train loss=0.2141258716583252
[5/24] Train loss=0.19204823672771454
[10/24] Train loss=0.21948984265327454
[15/24] Train loss=0.21869659423828125
[20/24] Train loss=0.2172205150127411
Test set avg_accuracy=87.20% avg_sensitivity=81.00%, avg_specificity=89.42% avg_auc=92.89%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.213850 Test loss=0.344514 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.20226193964481354
[5/24] Train loss=0.19513671100139618
[10/24] Train loss=0.20688652992248535
[15/24] Train loss=0.2191767394542694
[20/24] Train loss=0.21084530651569366
Test set avg_accuracy=87.02% avg_sensitivity=79.37%, avg_specificity=89.75% avg_auc=92.93%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.210136 Test loss=0.341920 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.20053981244564056
[5/24] Train loss=0.19523020088672638
[10/24] Train loss=0.20366886258125305
[15/24] Train loss=0.22002968192100525
[20/24] Train loss=0.19912514090538025
Test set avg_accuracy=87.49% avg_sensitivity=78.23%, avg_specificity=90.79% avg_auc=92.92%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.208776 Test loss=0.330864 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.2003408521413803
[5/24] Train loss=0.18783722817897797
[10/24] Train loss=0.21760143339633942
[15/24] Train loss=0.21819116175174713
[20/24] Train loss=0.2050783783197403
Test set avg_accuracy=87.21% avg_sensitivity=79.91%, avg_specificity=89.82% avg_auc=92.68%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.205677 Test loss=0.345854 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.19665458798408508
[5/24] Train loss=0.18959082663059235
[10/24] Train loss=0.20223075151443481
[15/24] Train loss=0.21603314578533173
[20/24] Train loss=0.213271826505661
Test set avg_accuracy=84.93% avg_sensitivity=82.93%, avg_specificity=85.65% avg_auc=92.29%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.205844 Test loss=0.401359 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1972631961107254
[5/24] Train loss=0.18596090376377106
[10/24] Train loss=0.19330719113349915
[15/24] Train loss=0.21994289755821228
[20/24] Train loss=0.21218837797641754
Test set avg_accuracy=87.24% avg_sensitivity=82.09%, avg_specificity=89.08% avg_auc=92.90%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.204130 Test loss=0.352271 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.19142940640449524
[5/24] Train loss=0.19383706152439117
[10/24] Train loss=0.20333167910575867
[15/24] Train loss=0.22134067118167877
[20/24] Train loss=0.20362547039985657
Test set avg_accuracy=86.11% avg_sensitivity=82.93%, avg_specificity=87.24% avg_auc=92.60%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.204154 Test loss=0.385305 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.19301491975784302
[5/24] Train loss=0.20103296637535095
[10/24] Train loss=0.20179051160812378
[15/24] Train loss=0.211612731218338
[20/24] Train loss=0.2016712874174118
Test set avg_accuracy=86.76% avg_sensitivity=83.67%, avg_specificity=87.86% avg_auc=92.64%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.205428 Test loss=0.393486 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.19983302056789398
[5/24] Train loss=0.20090368390083313
[10/24] Train loss=0.1915777623653412
[15/24] Train loss=0.2144065946340561
[20/24] Train loss=0.20665603876113892
Test set avg_accuracy=87.57% avg_sensitivity=72.64%, avg_specificity=92.90% avg_auc=91.90%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.202563 Test loss=0.333150 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.19536831974983215
[5/24] Train loss=0.17397436499595642
[10/24] Train loss=0.19879887998104095
[15/24] Train loss=0.20465156435966492
[20/24] Train loss=0.19554510712623596
Test set avg_accuracy=87.47% avg_sensitivity=77.44%, avg_specificity=91.06% avg_auc=92.36%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.198290 Test loss=0.338360 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.19621500372886658
[5/24] Train loss=0.17921623587608337
[10/24] Train loss=0.20020844042301178
[15/24] Train loss=0.2265411615371704
[20/24] Train loss=0.20410729944705963
Test set avg_accuracy=86.99% avg_sensitivity=79.86%, avg_specificity=89.54% avg_auc=92.52%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.199934 Test loss=0.365361 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.18585361540317535
[5/24] Train loss=0.18558458983898163
[10/24] Train loss=0.19137437641620636
[15/24] Train loss=0.21400891244411469
[20/24] Train loss=0.2051352709531784
Test set avg_accuracy=87.98% avg_sensitivity=79.32%, avg_specificity=91.08% avg_auc=93.35%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.198478 Test loss=0.326144 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.18826399743556976
[5/24] Train loss=0.1750590205192566
[10/24] Train loss=0.18780864775180817
[15/24] Train loss=0.20239223539829254
[20/24] Train loss=0.20095887780189514
Test set avg_accuracy=87.57% avg_sensitivity=79.86%, avg_specificity=90.32% avg_auc=92.49%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.192951 Test loss=0.359188 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1868678480386734
[5/24] Train loss=0.16945308446884155
[10/24] Train loss=0.18582145869731903
[15/24] Train loss=0.20184968411922455
[20/24] Train loss=0.2002742886543274
Test set avg_accuracy=87.60% avg_sensitivity=82.48%, avg_specificity=89.43% avg_auc=93.16%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.190498 Test loss=0.357089 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1805713176727295
[5/24] Train loss=0.17382848262786865
[10/24] Train loss=0.18698063492774963
[15/24] Train loss=0.1941462904214859
[20/24] Train loss=0.19470536708831787
Test set avg_accuracy=88.40% avg_sensitivity=78.72%, avg_specificity=91.85% avg_auc=92.80%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.186505 Test loss=0.328679 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.18283618986606598
[5/24] Train loss=0.17025670409202576
[10/24] Train loss=0.1800963133573532
[15/24] Train loss=0.1867707371711731
[20/24] Train loss=0.18667225539684296
Test set avg_accuracy=88.15% avg_sensitivity=78.28%, avg_specificity=91.68% avg_auc=92.70%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.183775 Test loss=0.337779 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.18503224849700928
[5/24] Train loss=0.17693403363227844
[10/24] Train loss=0.18104340136051178
[15/24] Train loss=0.18965299427509308
[20/24] Train loss=0.18450093269348145
Test set avg_accuracy=88.05% avg_sensitivity=76.10%, avg_specificity=92.31% avg_auc=92.66%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.182216 Test loss=0.327934 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1765241026878357
[5/24] Train loss=0.17168104648590088
[10/24] Train loss=0.17940957844257355
[15/24] Train loss=0.18971070647239685
[20/24] Train loss=0.17997974157333374
Test set avg_accuracy=87.84% avg_sensitivity=79.02%, avg_specificity=90.99% avg_auc=93.29%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.182354 Test loss=0.333519 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.17105166614055634
[5/24] Train loss=0.1659405678510666
[10/24] Train loss=0.17444933950901031
[15/24] Train loss=0.18516075611114502
[20/24] Train loss=0.19123266637325287
Test set avg_accuracy=87.60% avg_sensitivity=77.49%, avg_specificity=91.22% avg_auc=92.70%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.180900 Test loss=0.342467 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.17032738029956818
[5/24] Train loss=0.17687036097049713
[10/24] Train loss=0.18014301359653473
[15/24] Train loss=0.1839689165353775
[20/24] Train loss=0.18217049539089203
Test set avg_accuracy=87.16% avg_sensitivity=82.83%, avg_specificity=88.71% avg_auc=93.28%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.178511 Test loss=0.357878 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1661784052848816
[5/24] Train loss=0.16732442378997803
[10/24] Train loss=0.17384643852710724
[15/24] Train loss=0.18044522404670715
[20/24] Train loss=0.18263310194015503
Test set avg_accuracy=87.55% avg_sensitivity=79.22%, avg_specificity=90.53% avg_auc=92.92%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.176688 Test loss=0.345027 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.17234209179878235
[5/24] Train loss=0.1669793576002121
[10/24] Train loss=0.17362560331821442
[15/24] Train loss=0.1733713299036026
[20/24] Train loss=0.17777037620544434
Test set avg_accuracy=87.46% avg_sensitivity=78.97%, avg_specificity=90.49% avg_auc=92.74%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.175015 Test loss=0.350690 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.17098969221115112
[5/24] Train loss=0.164498433470726
[10/24] Train loss=0.16805587708950043
[15/24] Train loss=0.18568889796733856
[20/24] Train loss=0.17488737404346466
Test set avg_accuracy=87.70% avg_sensitivity=80.01%, avg_specificity=90.44% avg_auc=92.87%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.175113 Test loss=0.346243 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.17114131152629852
[5/24] Train loss=0.15917082130908966
[10/24] Train loss=0.17330163717269897
[15/24] Train loss=0.18344679474830627
[20/24] Train loss=0.17702379822731018
Test set avg_accuracy=87.71% avg_sensitivity=79.22%, avg_specificity=90.74% avg_auc=93.11%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.175227 Test loss=0.336302 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.16897837817668915
[5/24] Train loss=0.1609756499528885
[10/24] Train loss=0.16384418308734894
[15/24] Train loss=0.1789151281118393
[20/24] Train loss=0.1771230399608612
Test set avg_accuracy=87.73% avg_sensitivity=81.69%, avg_specificity=89.89% avg_auc=92.95%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.174863 Test loss=0.352622 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.17045588791370392
[5/24] Train loss=0.16523362696170807
[10/24] Train loss=0.17034804821014404
[15/24] Train loss=0.1802154928445816
[20/24] Train loss=0.18857355415821075
Test set avg_accuracy=87.73% avg_sensitivity=82.14%, avg_specificity=89.73% avg_auc=93.09%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.175764 Test loss=0.350118 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.16579797863960266
[5/24] Train loss=0.16283540427684784
[10/24] Train loss=0.17340204119682312
[15/24] Train loss=0.1731153428554535
[20/24] Train loss=0.18637758493423462
Test set avg_accuracy=87.21% avg_sensitivity=82.73%, avg_specificity=88.81% avg_auc=93.13%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.176485 Test loss=0.358291 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.17429079115390778
[5/24] Train loss=0.1554328352212906
[10/24] Train loss=0.1809069663286209
[15/24] Train loss=0.18047106266021729
[20/24] Train loss=0.18132950365543365
Test set avg_accuracy=87.38% avg_sensitivity=81.05%, avg_specificity=89.64% avg_auc=93.11%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.176019 Test loss=0.347926 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.17543728649616241
[5/24] Train loss=0.1591300070285797
[10/24] Train loss=0.17198985815048218
[15/24] Train loss=0.1787271499633789
[20/24] Train loss=0.1733221560716629
Test set avg_accuracy=87.45% avg_sensitivity=79.12%, avg_specificity=90.42% avg_auc=93.12%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.173193 Test loss=0.336616 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.17199739813804626
[5/24] Train loss=0.1590331494808197
[10/24] Train loss=0.16172683238983154
[15/24] Train loss=0.1778496950864792
[20/24] Train loss=0.1720786839723587
Test set avg_accuracy=87.84% avg_sensitivity=81.00%, avg_specificity=90.28% avg_auc=93.23%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.169969 Test loss=0.342206 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.16323637962341309
[5/24] Train loss=0.16182760894298553
[10/24] Train loss=0.16351868212223053
[15/24] Train loss=0.16883237659931183
[20/24] Train loss=0.17042036354541779
Test set avg_accuracy=87.62% avg_sensitivity=81.49%, avg_specificity=89.80% avg_auc=93.31%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.166518 Test loss=0.347492 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.15806512534618378
[5/24] Train loss=0.15281255543231964
[10/24] Train loss=0.16075685620307922
[15/24] Train loss=0.16968682408332825
[20/24] Train loss=0.16635355353355408
Test set avg_accuracy=87.75% avg_sensitivity=81.15%, avg_specificity=90.10% avg_auc=93.25%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.164147 Test loss=0.341308 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1591070294380188
[5/24] Train loss=0.1552152782678604
[10/24] Train loss=0.16230858862400055
[15/24] Train loss=0.16856147348880768
[20/24] Train loss=0.16622808575630188
Test set avg_accuracy=87.94% avg_sensitivity=81.15%, avg_specificity=90.37% avg_auc=93.28%
Best model saved!! Metric=26.741338444328164!!
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.164800 Test loss=0.338713 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.15751998126506805
[5/24] Train loss=0.1511269062757492
[10/24] Train loss=0.15849632024765015
[15/24] Train loss=0.16959205269813538
[20/24] Train loss=0.17388460040092468
Test set avg_accuracy=87.96% avg_sensitivity=80.85%, avg_specificity=90.49% avg_auc=93.23%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.163002 Test loss=0.341034 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.15769927203655243
[5/24] Train loss=0.15578825771808624
[10/24] Train loss=0.1595931202173233
[15/24] Train loss=0.1698715090751648
[20/24] Train loss=0.16461600363254547
Test set avg_accuracy=87.84% avg_sensitivity=81.35%, avg_specificity=90.16% avg_auc=93.22%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.163469 Test loss=0.342528 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.15800318121910095
[5/24] Train loss=0.15011917054653168
[10/24] Train loss=0.15990044176578522
[15/24] Train loss=0.16535726189613342
[20/24] Train loss=0.16781394183635712
Test set avg_accuracy=87.98% avg_sensitivity=80.70%, avg_specificity=90.58% avg_auc=93.23%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.162177 Test loss=0.335524 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.16025419533252716
[5/24] Train loss=0.15029828250408173
[10/24] Train loss=0.16081400215625763
[15/24] Train loss=0.16457614302635193
[20/24] Train loss=0.1666785031557083
Test set avg_accuracy=87.89% avg_sensitivity=81.40%, avg_specificity=90.21% avg_auc=93.27%
Best model saved!! Metric=26.768660792931954!!
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.162355 Test loss=0.339908 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.15570135414600372
[5/24] Train loss=0.1522788107395172
[10/24] Train loss=0.15577290952205658
[15/24] Train loss=0.16684432327747345
[20/24] Train loss=0.17219099402427673
Test set avg_accuracy=87.66% avg_sensitivity=81.00%, avg_specificity=90.03% avg_auc=93.28%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.161897 Test loss=0.343110 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1580834835767746
[5/24] Train loss=0.15098750591278076
[10/24] Train loss=0.15419915318489075
[15/24] Train loss=0.16724397242069244
[20/24] Train loss=0.16311153769493103
Test set avg_accuracy=88.10% avg_sensitivity=80.80%, avg_specificity=90.71% avg_auc=93.21%
Best model saved!! Metric=26.8129146983744!!
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.161382 Test loss=0.338196 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1523994505405426
[5/24] Train loss=0.14956888556480408
[10/24] Train loss=0.15810582041740417
[15/24] Train loss=0.1614813208580017
[20/24] Train loss=0.16847433149814606
Test set avg_accuracy=88.01% avg_sensitivity=80.46%, avg_specificity=90.71% avg_auc=93.25%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.160650 Test loss=0.336453 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.15588678419589996
[5/24] Train loss=0.14843061566352844
[10/24] Train loss=0.15888594090938568
[15/24] Train loss=0.1642872542142868
[20/24] Train loss=0.16211377084255219
Test set avg_accuracy=88.01% avg_sensitivity=80.50%, avg_specificity=90.69% avg_auc=93.26%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.160846 Test loss=0.337207 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.15441837906837463
[5/24] Train loss=0.14647266268730164
[10/24] Train loss=0.15904110670089722
[15/24] Train loss=0.16737963259220123
[20/24] Train loss=0.16514137387275696
Test set avg_accuracy=88.11% avg_sensitivity=80.75%, avg_specificity=90.74% avg_auc=93.24%
Best model saved!! Metric=26.840283901917388!!
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.160321 Test loss=0.338138 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.15723572671413422
[5/24] Train loss=0.15264202654361725
[10/24] Train loss=0.1573823094367981
[15/24] Train loss=0.16556724905967712
[20/24] Train loss=0.16201983392238617
Test set avg_accuracy=87.98% avg_sensitivity=80.70%, avg_specificity=90.58% avg_auc=93.26%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.160527 Test loss=0.338341 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1559959501028061
[5/24] Train loss=0.14898866415023804
[10/24] Train loss=0.15649040043354034
[15/24] Train loss=0.16309592127799988
[20/24] Train loss=0.16607651114463806
Test set avg_accuracy=88.06% avg_sensitivity=80.70%, avg_specificity=90.69% avg_auc=93.27%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.160292 Test loss=0.338213 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.15513630211353302
[5/24] Train loss=0.14644251763820648
[10/24] Train loss=0.15594738721847534
[15/24] Train loss=0.16200730204582214
[20/24] Train loss=0.1613895297050476
Test set avg_accuracy=88.03% avg_sensitivity=80.50%, avg_specificity=90.72% avg_auc=93.25%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.160133 Test loss=0.337941 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.15913620591163635
[5/24] Train loss=0.1502712070941925
[10/24] Train loss=0.15735583007335663
[15/24] Train loss=0.16527199745178223
[20/24] Train loss=0.1671675145626068
Test set avg_accuracy=88.03% avg_sensitivity=80.46%, avg_specificity=90.74% avg_auc=93.25%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.160230 Test loss=0.337736 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.15475420653820038
[5/24] Train loss=0.15184898674488068
[10/24] Train loss=0.15699532628059387
[15/24] Train loss=0.16397500038146973
[20/24] Train loss=0.1693171113729477
Test set avg_accuracy=88.07% avg_sensitivity=80.70%, avg_specificity=90.71% avg_auc=93.25%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.160050 Test loss=0.338214 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1517268866300583
[5/24] Train loss=0.14788495004177094
[10/24] Train loss=0.1611221730709076
[15/24] Train loss=0.1655663549900055
[20/24] Train loss=0.16452853381633759
Test set avg_accuracy=88.06% avg_sensitivity=80.65%, avg_specificity=90.71% avg_auc=93.24%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.160418 Test loss=0.338278 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.15556201338768005
[5/24] Train loss=0.1482667773962021
[10/24] Train loss=0.154298797249794
[15/24] Train loss=0.16899897158145905
[20/24] Train loss=0.16402357816696167
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=88.06% avg_sensitivity=80.65%, avg_specificity=90.71% avg_auc=93.25%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.159797 Test loss=0.338137 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=88.11% sen=80.75%, spe=90.74%, auc=93.24%!
Fold[1] Avg_overlap=0.70%(0.22852548650842777)
[0/24] Train loss=1.4810880422592163
[5/24] Train loss=1.4774765968322754
[10/24] Train loss=1.4456063508987427
[15/24] Train loss=1.438697338104248
[20/24] Train loss=1.3928231000900269
Test set avg_accuracy=57.12% avg_sensitivity=60.04%, avg_specificity=56.15% avg_auc=56.82%
Best model saved!! Metric=-95.86774987249011!!
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=1.445253 Test loss=0.701534 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.3999395370483398
[5/24] Train loss=1.3874132633209229
[10/24] Train loss=1.3551485538482666
[15/24] Train loss=1.3467336893081665
[20/24] Train loss=1.357312798500061
Test set avg_accuracy=72.01% avg_sensitivity=77.52%, avg_specificity=70.17% avg_auc=73.10%
Best model saved!! Metric=-33.20195216230415!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=1.370905 Test loss=0.625384 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3220034837722778
[5/24] Train loss=1.3033339977264404
[10/24] Train loss=1.2801907062530518
[15/24] Train loss=1.2585227489471436
[20/24] Train loss=1.2513967752456665
Test set avg_accuracy=72.32% avg_sensitivity=79.81%, avg_specificity=69.82% avg_auc=78.28%
Best model saved!! Metric=-25.766145358544364!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=1.296279 Test loss=0.594356 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.2312324047088623
[5/24] Train loss=1.2079083919525146
[10/24] Train loss=1.204171061515808
[15/24] Train loss=1.1800222396850586
[20/24] Train loss=1.1737017631530762
Test set avg_accuracy=73.23% avg_sensitivity=82.11%, avg_specificity=70.28% avg_auc=80.84%
Best model saved!! Metric=-19.550627916282068!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=1.218292 Test loss=0.576218 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.1523661613464355
[5/24] Train loss=1.1282451152801514
[10/24] Train loss=1.1297012567520142
[15/24] Train loss=1.1220563650131226
[20/24] Train loss=1.1031715869903564
Test set avg_accuracy=73.36% avg_sensitivity=83.83%, avg_specificity=69.88% avg_auc=82.71%
Best model saved!! Metric=-16.222329234313293!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=1.148288 Test loss=0.563256 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.0783956050872803
[5/24] Train loss=1.0552377700805664
[10/24] Train loss=1.0517351627349854
[15/24] Train loss=1.0435484647750854
[20/24] Train loss=1.0296053886413574
Test set avg_accuracy=74.91% avg_sensitivity=83.72%, avg_specificity=71.98% avg_auc=84.50%
Best model saved!! Metric=-10.892691335548236!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=1.077319 Test loss=0.537983 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.9999087452888489
[5/24] Train loss=0.9845488667488098
[10/24] Train loss=0.9922376275062561
[15/24] Train loss=0.9661972522735596
[20/24] Train loss=0.9853536486625671
Test set avg_accuracy=76.65% avg_sensitivity=85.76%, avg_specificity=73.62% avg_auc=86.13%
Best model saved!! Metric=-3.8310686372550578!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=1.018749 Test loss=0.517129 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9580391645431519
[5/24] Train loss=0.9187584519386292
[10/24] Train loss=0.9409843683242798
[15/24] Train loss=0.9156056046485901
[20/24] Train loss=0.9205285906791687
Test set avg_accuracy=79.21% avg_sensitivity=83.46%, avg_specificity=77.79% avg_auc=87.56%
Best model saved!! Metric=2.0217918463029463!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.962953 Test loss=0.482452 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.9013687968254089
[5/24] Train loss=0.8767123818397522
[10/24] Train loss=0.8827347755432129
[15/24] Train loss=0.8602452874183655
[20/24] Train loss=0.8491284847259521
Test set avg_accuracy=80.10% avg_sensitivity=86.07%, avg_specificity=78.12% avg_auc=88.85%
Best model saved!! Metric=7.149174976562932!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.908644 Test loss=0.468819 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8504930138587952
[5/24] Train loss=0.8142044544219971
[10/24] Train loss=0.8306350708007812
[15/24] Train loss=0.8209559321403503
[20/24] Train loss=0.8096005916595459
Test set avg_accuracy=81.25% avg_sensitivity=87.43%, avg_specificity=79.19% avg_auc=89.67%
Best model saved!! Metric=11.546050995725722!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.862758 Test loss=0.454241 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.8043903708457947
[5/24] Train loss=0.7687996029853821
[10/24] Train loss=0.8132204413414001
[15/24] Train loss=0.7773575782775879
[20/24] Train loss=0.7641429305076599
Test set avg_accuracy=81.30% avg_sensitivity=89.15%, avg_specificity=78.69% avg_auc=90.36%
Best model saved!! Metric=13.499462672381327!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.820240 Test loss=0.451592 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.7535000443458557
[5/24] Train loss=0.7306416034698486
[10/24] Train loss=0.7710257768630981
[15/24] Train loss=0.7484698295593262
[20/24] Train loss=0.7217214107513428
Test set avg_accuracy=82.88% avg_sensitivity=88.63%, avg_specificity=80.96% avg_auc=90.95%
Best model saved!! Metric=17.421052645536065!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.785030 Test loss=0.426570 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7277622818946838
[5/24] Train loss=0.7121658325195312
[10/24] Train loss=0.7598375082015991
[15/24] Train loss=0.7167166471481323
[20/24] Train loss=0.693557620048523
Test set avg_accuracy=83.71% avg_sensitivity=88.42%, avg_specificity=82.14% avg_auc=91.43%
Best model saved!! Metric=19.707954789888518!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.756788 Test loss=0.410833 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.6882567405700684
[5/24] Train loss=0.6733315587043762
[10/24] Train loss=0.7268293499946594
[15/24] Train loss=0.6831580400466919
[20/24] Train loss=0.6779191493988037
Test set avg_accuracy=83.68% avg_sensitivity=89.36%, avg_specificity=81.80% avg_auc=91.75%
Best model saved!! Metric=20.58750218357673!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.728969 Test loss=0.414483 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.6808436512947083
[5/24] Train loss=0.6521286964416504
[10/24] Train loss=0.7111096978187561
[15/24] Train loss=0.6782113909721375
[20/24] Train loss=0.6483255624771118
Test set avg_accuracy=82.99% avg_sensitivity=90.04%, avg_specificity=80.65% avg_auc=91.93%
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.709576 Test loss=0.416540 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.6341787576675415
[5/24] Train loss=0.6416978240013123
[10/24] Train loss=0.7002497911453247
[15/24] Train loss=0.6459670066833496
[20/24] Train loss=0.6169803738594055
Test set avg_accuracy=84.60% avg_sensitivity=87.69%, avg_specificity=83.57% avg_auc=92.15%
Best model saved!! Metric=22.000867208374757!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.690343 Test loss=0.385320 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6244136095046997
[5/24] Train loss=0.6115937829017639
[10/24] Train loss=0.6747439503669739
[15/24] Train loss=0.6252379417419434
[20/24] Train loss=0.5997878313064575
Test set avg_accuracy=84.44% avg_sensitivity=88.63%, avg_specificity=83.05% avg_auc=92.31%
Best model saved!! Metric=22.428622651693942!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.671852 Test loss=0.387254 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.6147683262825012
[5/24] Train loss=0.5835069417953491
[10/24] Train loss=0.648905873298645
[15/24] Train loss=0.6225795149803162
[20/24] Train loss=0.57160884141922
Test set avg_accuracy=83.18% avg_sensitivity=90.98%, avg_specificity=80.58% avg_auc=92.33%
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.654916 Test loss=0.414530 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.6001742482185364
[5/24] Train loss=0.5799625515937805
[10/24] Train loss=0.64862060546875
[15/24] Train loss=0.6158867478370667
[20/24] Train loss=0.5566688179969788
Test set avg_accuracy=84.02% avg_sensitivity=89.36%, avg_specificity=82.25% avg_auc=92.48%
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.643435 Test loss=0.389088 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.578785240650177
[5/24] Train loss=0.5571250915527344
[10/24] Train loss=0.6418803334236145
[15/24] Train loss=0.5971669554710388
[20/24] Train loss=0.5635024905204773
Test set avg_accuracy=85.29% avg_sensitivity=89.67%, avg_specificity=83.83% avg_auc=92.79%
Best model saved!! Metric=25.572927218947314!!
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.631661 Test loss=0.375153 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5789589285850525
[5/24] Train loss=0.5324240922927856
[10/24] Train loss=0.6267916560173035
[15/24] Train loss=0.5675380229949951
[20/24] Train loss=0.5353022813796997
Test set avg_accuracy=86.25% avg_sensitivity=87.79%, avg_specificity=85.74% avg_auc=92.73%
Best model saved!! Metric=26.5148489441802!!
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.619006 Test loss=0.357292 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5648813247680664
[5/24] Train loss=0.5369650721549988
[10/24] Train loss=0.6208446621894836
[15/24] Train loss=0.5678510665893555
[20/24] Train loss=0.5214138031005859
Test set avg_accuracy=83.23% avg_sensitivity=90.04%, avg_specificity=80.96% avg_auc=92.72%
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.605106 Test loss=0.411490 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5599443912506104
[5/24] Train loss=0.537152886390686
[10/24] Train loss=0.5927231311798096
[15/24] Train loss=0.5449661612510681
[20/24] Train loss=0.5040411353111267
Test set avg_accuracy=85.77% avg_sensitivity=88.63%, avg_specificity=84.82% avg_auc=92.95%
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.593617 Test loss=0.367925 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5520946383476257
[5/24] Train loss=0.5214124321937561
[10/24] Train loss=0.5741918087005615
[15/24] Train loss=0.5410690307617188
[20/24] Train loss=0.5090715885162354
Test set avg_accuracy=85.17% avg_sensitivity=89.36%, avg_specificity=83.78% avg_auc=92.63%
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.581021 Test loss=0.382662 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5458141565322876
[5/24] Train loss=0.5151904821395874
[10/24] Train loss=0.55380779504776
[15/24] Train loss=0.5205091834068298
[20/24] Train loss=0.49572792649269104
Test set avg_accuracy=86.42% avg_sensitivity=88.05%, avg_specificity=85.88% avg_auc=92.95%
Best model saved!! Metric=27.299041239240594!!
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.569276 Test loss=0.352997 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5191975831985474
[5/24] Train loss=0.5271166563034058
[10/24] Train loss=0.549854040145874
[15/24] Train loss=0.5311409831047058
[20/24] Train loss=0.5038669109344482
Test set avg_accuracy=87.57% avg_sensitivity=86.28%, avg_specificity=87.99% avg_auc=92.65%
Best model saved!! Metric=28.485833431685492!!
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.559753 Test loss=0.336036 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5159873962402344
[5/24] Train loss=0.5058424472808838
[10/24] Train loss=0.5619134306907654
[15/24] Train loss=0.5061609745025635
[20/24] Train loss=0.4954054057598114
Test set avg_accuracy=88.09% avg_sensitivity=85.55%, avg_specificity=88.93% avg_auc=92.71%
Best model saved!! Metric=29.2763344624005!!
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.556022 Test loss=0.332161 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.5230874419212341
[5/24] Train loss=0.5180365443229675
[10/24] Train loss=0.5316957235336304
[15/24] Train loss=0.525046169757843
[20/24] Train loss=0.4554285407066345
Test set avg_accuracy=87.55% avg_sensitivity=85.55%, avg_specificity=88.22% avg_auc=92.94%
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.542212 Test loss=0.331519 Current lr=[0.000210185142098938]

[0/24] Train loss=0.504084050655365
[5/24] Train loss=0.47942519187927246
[10/24] Train loss=0.5204060673713684
[15/24] Train loss=0.5146623849868774
[20/24] Train loss=0.47607526183128357
Test set avg_accuracy=86.84% avg_sensitivity=84.87%, avg_specificity=87.49% avg_auc=92.74%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.527131 Test loss=0.333587 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.49220725893974304
[5/24] Train loss=0.4633503258228302
[10/24] Train loss=0.5404755473136902
[15/24] Train loss=0.5048747658729553
[20/24] Train loss=0.45136162638664246
Test set avg_accuracy=86.80% avg_sensitivity=87.17%, avg_specificity=86.67% avg_auc=92.86%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.521041 Test loss=0.333879 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.45939645171165466
[5/24] Train loss=0.46002766489982605
[10/24] Train loss=0.49772027134895325
[15/24] Train loss=0.4902418255805969
[20/24] Train loss=0.4731203317642212
Test set avg_accuracy=88.29% avg_sensitivity=67.81%, avg_specificity=95.11% avg_auc=91.71%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.514813 Test loss=0.306550 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.4931749999523163
[5/24] Train loss=0.4580926299095154
[10/24] Train loss=0.5138338804244995
[15/24] Train loss=0.4977225959300995
[20/24] Train loss=0.45640692114830017
Test set avg_accuracy=85.17% avg_sensitivity=87.53%, avg_specificity=84.38% avg_auc=92.53%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.512480 Test loss=0.362334 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.4419388771057129
[5/24] Train loss=0.44619226455688477
[10/24] Train loss=0.5209920406341553
[15/24] Train loss=0.4844093918800354
[20/24] Train loss=0.440899521112442
Test set avg_accuracy=87.66% avg_sensitivity=77.67%, avg_specificity=90.98% avg_auc=92.58%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.506685 Test loss=0.303991 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.4563983380794525
[5/24] Train loss=0.45308181643486023
[10/24] Train loss=0.5213391780853271
[15/24] Train loss=0.4768390953540802
[20/24] Train loss=0.4308360517024994
Test set avg_accuracy=55.79% avg_sensitivity=96.14%, avg_specificity=42.37% avg_auc=86.22%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.502905 Test loss=0.869987 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.4902244210243225
[5/24] Train loss=0.4688897728919983
[10/24] Train loss=0.49367424845695496
[15/24] Train loss=0.4770069718360901
[20/24] Train loss=0.41453656554222107
Test set avg_accuracy=83.78% avg_sensitivity=90.25%, avg_specificity=81.62% avg_auc=92.47%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.496980 Test loss=0.395705 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4392918646335602
[5/24] Train loss=0.499332457780838
[10/24] Train loss=0.5010393857955933
[15/24] Train loss=0.481933057308197
[20/24] Train loss=0.4157143831253052
Test set avg_accuracy=78.72% avg_sensitivity=92.23%, avg_specificity=74.23% avg_auc=90.98%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.483237 Test loss=0.507891 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4496981203556061
[5/24] Train loss=0.4342193901538849
[10/24] Train loss=0.5035696029663086
[15/24] Train loss=0.46603700518608093
[20/24] Train loss=0.3991313874721527
Test set avg_accuracy=80.91% avg_sensitivity=92.49%, avg_specificity=77.06% avg_auc=92.76%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.467601 Test loss=0.436316 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.42596858739852905
[5/24] Train loss=0.4209686815738678
[10/24] Train loss=0.4460602104663849
[15/24] Train loss=0.47073468565940857
[20/24] Train loss=0.40712910890579224
Test set avg_accuracy=86.99% avg_sensitivity=64.37%, avg_specificity=94.52% avg_auc=87.94%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.462980 Test loss=0.372818 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4385235905647278
[5/24] Train loss=0.3969023525714874
[10/24] Train loss=0.46152740716934204
[15/24] Train loss=0.4535241723060608
[20/24] Train loss=0.3773981034755707
Test set avg_accuracy=85.46% avg_sensitivity=87.53%, avg_specificity=84.76% avg_auc=92.13%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.451220 Test loss=0.368339 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.4042398929595947
[5/24] Train loss=0.40333718061447144
[10/24] Train loss=0.4667600095272064
[15/24] Train loss=0.45795491337776184
[20/24] Train loss=0.4159946143627167
Test set avg_accuracy=83.15% avg_sensitivity=89.72%, avg_specificity=80.96% avg_auc=91.45%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.457122 Test loss=0.443558 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4199182391166687
[5/24] Train loss=0.40192270278930664
[10/24] Train loss=0.4451974332332611
[15/24] Train loss=0.444912850856781
[20/24] Train loss=0.42478132247924805
Test set avg_accuracy=87.40% avg_sensitivity=82.79%, avg_specificity=88.93% avg_auc=92.62%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.457757 Test loss=0.324035 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.4058424234390259
[5/24] Train loss=0.42951610684394836
[10/24] Train loss=0.450672447681427
[15/24] Train loss=0.433027982711792
[20/24] Train loss=0.39756035804748535
Test set avg_accuracy=79.84% avg_sensitivity=92.70%, avg_specificity=75.57% avg_auc=91.97%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.445012 Test loss=0.491829 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4049336910247803
[5/24] Train loss=0.42508694529533386
[10/24] Train loss=0.4860462546348572
[15/24] Train loss=0.43063464760780334
[20/24] Train loss=0.3796027898788452
Test set avg_accuracy=72.23% avg_sensitivity=95.57%, avg_specificity=64.46% avg_auc=89.35%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.455980 Test loss=0.620574 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.4095741808414459
[5/24] Train loss=0.42164346575737
[10/24] Train loss=0.48807960748672485
[15/24] Train loss=0.4092118740081787
[20/24] Train loss=0.38150694966316223
Test set avg_accuracy=73.58% avg_sensitivity=95.25%, avg_specificity=66.37% avg_auc=89.39%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.439370 Test loss=0.640007 Current lr=[0.00029967723776099]

[0/24] Train loss=0.38917049765586853
[5/24] Train loss=0.39173078536987305
[10/24] Train loss=0.4286944270133972
[15/24] Train loss=0.4181812107563019
[20/24] Train loss=0.358180433511734
Test set avg_accuracy=71.68% avg_sensitivity=96.30%, avg_specificity=63.49% avg_auc=89.72%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.421765 Test loss=0.654839 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.4082358181476593
[5/24] Train loss=0.3726103603839874
[10/24] Train loss=0.43124377727508545
[15/24] Train loss=0.39372196793556213
[20/24] Train loss=0.3553489148616791
Test set avg_accuracy=85.14% avg_sensitivity=88.73%, avg_specificity=83.95% avg_auc=91.90%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.408888 Test loss=0.382207 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.37951210141181946
[5/24] Train loss=0.3545506000518799
[10/24] Train loss=0.40940433740615845
[15/24] Train loss=0.3990912437438965
[20/24] Train loss=0.36788907647132874
Test set avg_accuracy=87.67% avg_sensitivity=73.81%, avg_specificity=92.28% avg_auc=91.31%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.403242 Test loss=0.320961 Current lr=[0.000299720220882401]

[0/24] Train loss=0.366250216960907
[5/24] Train loss=0.3544055223464966
[10/24] Train loss=0.4680896997451782
[15/24] Train loss=0.4140200614929199
[20/24] Train loss=0.40265142917633057
Test set avg_accuracy=84.77% avg_sensitivity=84.66%, avg_specificity=84.80% avg_auc=90.74%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.416444 Test loss=0.405566 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.41011863946914673
[5/24] Train loss=0.36754679679870605
[10/24] Train loss=0.3920685648918152
[15/24] Train loss=0.39951497316360474
[20/24] Train loss=0.3420984148979187
Test set avg_accuracy=87.42% avg_sensitivity=81.27%, avg_specificity=89.47% avg_auc=91.20%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.410815 Test loss=0.355268 Current lr=[0.000298904600941902]

[0/24] Train loss=0.38440001010894775
[5/24] Train loss=0.3680833876132965
[10/24] Train loss=0.39195194840431213
[15/24] Train loss=0.390567809343338
[20/24] Train loss=0.3278244435787201
Test set avg_accuracy=75.73% avg_sensitivity=92.75%, avg_specificity=70.07% avg_auc=88.98%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.394497 Test loss=0.594919 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3950226604938507
[5/24] Train loss=0.4259396493434906
[10/24] Train loss=0.4255457818508148
[15/24] Train loss=0.388445109128952
[20/24] Train loss=0.3473603129386902
Test set avg_accuracy=81.74% avg_sensitivity=92.91%, avg_specificity=78.03% avg_auc=91.73%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.402116 Test loss=0.483419 Current lr=[0.000297555943323901]

[0/24] Train loss=0.380612850189209
[5/24] Train loss=0.3654826283454895
[10/24] Train loss=0.3962368071079254
[15/24] Train loss=0.39444372057914734
[20/24] Train loss=0.33294153213500977
Test set avg_accuracy=82.16% avg_sensitivity=90.87%, avg_specificity=79.26% avg_auc=91.43%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.388840 Test loss=0.473078 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3699095845222473
[5/24] Train loss=0.3734673261642456
[10/24] Train loss=0.4037359952926636
[15/24] Train loss=0.3874874711036682
[20/24] Train loss=0.3228200078010559
Test set avg_accuracy=88.18% avg_sensitivity=74.18%, avg_specificity=92.83% avg_auc=91.11%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.397049 Test loss=0.335775 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.36764052510261536
[5/24] Train loss=0.35440635681152344
[10/24] Train loss=0.39809948205947876
[15/24] Train loss=0.4000624418258667
[20/24] Train loss=0.3297363221645355
Test set avg_accuracy=87.70% avg_sensitivity=71.73%, avg_specificity=93.01% avg_auc=91.77%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.391868 Test loss=0.323519 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3423362970352173
[5/24] Train loss=0.375060111284256
[10/24] Train loss=0.4144599437713623
[15/24] Train loss=0.38531848788261414
[20/24] Train loss=0.33449193835258484
Test set avg_accuracy=78.26% avg_sensitivity=93.48%, avg_specificity=73.19% avg_auc=89.85%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.389788 Test loss=0.555249 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3567478358745575
[5/24] Train loss=0.3357767164707184
[10/24] Train loss=0.37377989292144775
[15/24] Train loss=0.3998703062534332
[20/24] Train loss=0.3317612409591675
Test set avg_accuracy=83.33% avg_sensitivity=90.56%, avg_specificity=80.93% avg_auc=91.69%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.376272 Test loss=0.456332 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3646446466445923
[5/24] Train loss=0.3407304286956787
[10/24] Train loss=0.3782860040664673
[15/24] Train loss=0.37107864022254944
[20/24] Train loss=0.32731103897094727
Test set avg_accuracy=86.69% avg_sensitivity=86.28%, avg_specificity=86.83% avg_auc=91.82%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.362908 Test loss=0.368845 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3568650186061859
[5/24] Train loss=0.32666176557540894
[10/24] Train loss=0.3727612793445587
[15/24] Train loss=0.35036009550094604
[20/24] Train loss=0.31941160559654236
Test set avg_accuracy=83.82% avg_sensitivity=89.10%, avg_specificity=82.06% avg_auc=91.99%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.360129 Test loss=0.441364 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.33803731203079224
[5/24] Train loss=0.30552127957344055
[10/24] Train loss=0.3622300624847412
[15/24] Train loss=0.3646813929080963
[20/24] Train loss=0.3015702962875366
Test set avg_accuracy=87.42% avg_sensitivity=75.48%, avg_specificity=91.39% avg_auc=91.35%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.347940 Test loss=0.349731 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3307274580001831
[5/24] Train loss=0.3294626474380493
[10/24] Train loss=0.38030192255973816
[15/24] Train loss=0.37950053811073303
[20/24] Train loss=0.3193776607513428
Test set avg_accuracy=84.38% avg_sensitivity=87.69%, avg_specificity=83.27% avg_auc=91.64%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.365399 Test loss=0.412285 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3514325022697449
[5/24] Train loss=0.34364041686058044
[10/24] Train loss=0.39085158705711365
[15/24] Train loss=0.3505479395389557
[20/24] Train loss=0.31043967604637146
Test set avg_accuracy=72.96% avg_sensitivity=94.73%, avg_specificity=65.71% avg_auc=87.42%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.378659 Test loss=0.666313 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3375231623649597
[5/24] Train loss=0.36001265048980713
[10/24] Train loss=0.3601703941822052
[15/24] Train loss=0.36004990339279175
[20/24] Train loss=0.31209757924079895
Test set avg_accuracy=87.71% avg_sensitivity=79.19%, avg_specificity=90.54% avg_auc=89.38%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.362664 Test loss=0.379693 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.34478238224983215
[5/24] Train loss=0.3281579613685608
[10/24] Train loss=0.35124656558036804
[15/24] Train loss=0.3197444975376129
[20/24] Train loss=0.2867857813835144
Test set avg_accuracy=87.89% avg_sensitivity=81.32%, avg_specificity=90.07% avg_auc=92.11%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.337117 Test loss=0.337453 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.32097378373146057
[5/24] Train loss=0.32393133640289307
[10/24] Train loss=0.3421720564365387
[15/24] Train loss=0.34101831912994385
[20/24] Train loss=0.287510484457016
Test set avg_accuracy=87.71% avg_sensitivity=61.50%, avg_specificity=96.43% avg_auc=90.53%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.343345 Test loss=0.346596 Current lr=[0.000276307469034998]

[0/24] Train loss=0.32186204195022583
[5/24] Train loss=0.3067571222782135
[10/24] Train loss=0.30046120285987854
[15/24] Train loss=0.32361993193626404
[20/24] Train loss=0.2680022120475769
Test set avg_accuracy=87.33% avg_sensitivity=70.21%, avg_specificity=93.02% avg_auc=89.41%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.322080 Test loss=0.356105 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.31293073296546936
[5/24] Train loss=0.29641827940940857
[10/24] Train loss=0.32538357377052307
[15/24] Train loss=0.32299837470054626
[20/24] Train loss=0.2967524230480194
Test set avg_accuracy=85.43% avg_sensitivity=87.27%, avg_specificity=84.82% avg_auc=91.84%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.327027 Test loss=0.385910 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.32136186957359314
[5/24] Train loss=0.30954065918922424
[10/24] Train loss=0.33121874928474426
[15/24] Train loss=0.31997308135032654
[20/24] Train loss=0.2820050120353699
Test set avg_accuracy=82.33% avg_sensitivity=90.25%, avg_specificity=79.70% avg_auc=91.85%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.327396 Test loss=0.490079 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.30765578150749207
[5/24] Train loss=0.30931517481803894
[10/24] Train loss=0.3276785612106323
[15/24] Train loss=0.31496697664260864
[20/24] Train loss=0.276951402425766
Test set avg_accuracy=84.71% avg_sensitivity=88.73%, avg_specificity=83.38% avg_auc=91.96%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.330302 Test loss=0.417636 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3128182888031006
[5/24] Train loss=0.29514750838279724
[10/24] Train loss=0.31750017404556274
[15/24] Train loss=0.32126376032829285
[20/24] Train loss=0.2784927487373352
Test set avg_accuracy=87.42% avg_sensitivity=81.59%, avg_specificity=89.36% avg_auc=92.13%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.325187 Test loss=0.339564 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2987823784351349
[5/24] Train loss=0.31913381814956665
[10/24] Train loss=0.3160383999347687
[15/24] Train loss=0.30603912472724915
[20/24] Train loss=0.27419471740722656
Test set avg_accuracy=87.81% avg_sensitivity=77.73%, avg_specificity=91.17% avg_auc=90.97%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.317056 Test loss=0.346403 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3015102744102478
[5/24] Train loss=0.29907652735710144
[10/24] Train loss=0.2982150614261627
[15/24] Train loss=0.30831846594810486
[20/24] Train loss=0.2753307521343231
Test set avg_accuracy=87.41% avg_sensitivity=82.11%, avg_specificity=89.17% avg_auc=92.04%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.306725 Test loss=0.342327 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.29420801997184753
[5/24] Train loss=0.32595643401145935
[10/24] Train loss=0.3219796121120453
[15/24] Train loss=0.3043116331100464
[20/24] Train loss=0.2809842526912689
Test set avg_accuracy=87.55% avg_sensitivity=78.14%, avg_specificity=90.68% avg_auc=91.52%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.307329 Test loss=0.337170 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2986694872379303
[5/24] Train loss=0.29558607935905457
[10/24] Train loss=0.3088947534561157
[15/24] Train loss=0.2998895049095154
[20/24] Train loss=0.2569108009338379
Test set avg_accuracy=87.64% avg_sensitivity=82.37%, avg_specificity=89.40% avg_auc=91.87%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.306224 Test loss=0.357927 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2961921989917755
[5/24] Train loss=0.2753812372684479
[10/24] Train loss=0.3111565411090851
[15/24] Train loss=0.2834869623184204
[20/24] Train loss=0.2698141932487488
Test set avg_accuracy=87.98% avg_sensitivity=82.84%, avg_specificity=89.69% avg_auc=91.83%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.308639 Test loss=0.353693 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.304714173078537
[5/24] Train loss=0.3086283802986145
[10/24] Train loss=0.3075474500656128
[15/24] Train loss=0.3006250560283661
[20/24] Train loss=0.27252718806266785
Test set avg_accuracy=86.55% avg_sensitivity=85.03%, avg_specificity=87.06% avg_auc=90.90%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.306216 Test loss=0.393214 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.28716936707496643
[5/24] Train loss=0.2695983052253723
[10/24] Train loss=0.2910211980342865
[15/24] Train loss=0.27571678161621094
[20/24] Train loss=0.2677266597747803
Test set avg_accuracy=88.01% avg_sensitivity=82.68%, avg_specificity=89.78% avg_auc=92.13%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.297512 Test loss=0.356425 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.27691587805747986
[5/24] Train loss=0.27874985337257385
[10/24] Train loss=0.28695985674858093
[15/24] Train loss=0.28778260946273804
[20/24] Train loss=0.2542029321193695
Test set avg_accuracy=85.95% avg_sensitivity=87.06%, avg_specificity=85.58% avg_auc=92.28%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.295036 Test loss=0.397957 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.27677828073501587
[5/24] Train loss=0.2842005491256714
[10/24] Train loss=0.27792155742645264
[15/24] Train loss=0.2905632257461548
[20/24] Train loss=0.2574722170829773
Test set avg_accuracy=86.15% avg_sensitivity=88.68%, avg_specificity=85.30% avg_auc=92.15%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.293202 Test loss=0.403615 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.28821414709091187
[5/24] Train loss=0.25755298137664795
[10/24] Train loss=0.28889384865760803
[15/24] Train loss=0.2752569615840912
[20/24] Train loss=0.25757721066474915
Test set avg_accuracy=85.76% avg_sensitivity=86.96%, avg_specificity=85.35% avg_auc=91.84%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.288947 Test loss=0.398781 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2730964422225952
[5/24] Train loss=0.2747650742530823
[10/24] Train loss=0.2955062985420227
[15/24] Train loss=0.2733337879180908
[20/24] Train loss=0.26237186789512634
Test set avg_accuracy=88.12% avg_sensitivity=72.87%, avg_specificity=93.20% avg_auc=90.65%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.278222 Test loss=0.351389 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2824511229991913
[5/24] Train loss=0.28776463866233826
[10/24] Train loss=0.2677026391029358
[15/24] Train loss=0.28730034828186035
[20/24] Train loss=0.25216230750083923
Test set avg_accuracy=87.89% avg_sensitivity=76.42%, avg_specificity=91.71% avg_auc=91.85%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.293092 Test loss=0.331079 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2724519371986389
[5/24] Train loss=0.33961227536201477
[10/24] Train loss=0.3154798746109009
[15/24] Train loss=0.26437681913375854
[20/24] Train loss=0.2607252895832062
Test set avg_accuracy=84.86% avg_sensitivity=86.49%, avg_specificity=84.31% avg_auc=91.52%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.290972 Test loss=0.437423 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.26526975631713867
[5/24] Train loss=0.2699705958366394
[10/24] Train loss=0.2742115259170532
[15/24] Train loss=0.26824337244033813
[20/24] Train loss=0.24284838140010834
Test set avg_accuracy=87.58% avg_sensitivity=70.74%, avg_specificity=93.18% avg_auc=91.01%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.277443 Test loss=0.348191 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2530372738838196
[5/24] Train loss=0.2882520258426666
[10/24] Train loss=0.2859187722206116
[15/24] Train loss=0.2482738047838211
[20/24] Train loss=0.24260354042053223
Test set avg_accuracy=87.84% avg_sensitivity=72.98%, avg_specificity=92.78% avg_auc=90.29%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.276743 Test loss=0.354551 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.25658613443374634
[5/24] Train loss=0.2647458612918854
[10/24] Train loss=0.26805153489112854
[15/24] Train loss=0.24836936593055725
[20/24] Train loss=0.25616654753685
Test set avg_accuracy=87.27% avg_sensitivity=75.64%, avg_specificity=91.13% avg_auc=90.94%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.274316 Test loss=0.353905 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2576819956302643
[5/24] Train loss=0.2545032203197479
[10/24] Train loss=0.27946022152900696
[15/24] Train loss=0.2868964672088623
[20/24] Train loss=0.2722463011741638
Test set avg_accuracy=87.92% avg_sensitivity=74.02%, avg_specificity=92.54% avg_auc=90.60%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.286069 Test loss=0.365655 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.26967689394950867
[5/24] Train loss=0.2954470217227936
[10/24] Train loss=0.2758563756942749
[15/24] Train loss=0.2612876892089844
[20/24] Train loss=0.26026561856269836
Test set avg_accuracy=87.32% avg_sensitivity=81.59%, avg_specificity=89.22% avg_auc=91.13%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.282672 Test loss=0.407288 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.27081817388534546
[5/24] Train loss=0.2665943503379822
[10/24] Train loss=0.2730467617511749
[15/24] Train loss=0.27929776906967163
[20/24] Train loss=0.24388909339904785
Test set avg_accuracy=88.02% avg_sensitivity=75.38%, avg_specificity=92.23% avg_auc=91.08%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.290119 Test loss=0.348986 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2647073566913605
[5/24] Train loss=0.2711701989173889
[10/24] Train loss=0.29557955265045166
[15/24] Train loss=0.2795301079750061
[20/24] Train loss=0.24211174249649048
Test set avg_accuracy=87.43% avg_sensitivity=69.54%, avg_specificity=93.39% avg_auc=89.56%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.283419 Test loss=0.362874 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2592608332633972
[5/24] Train loss=0.26121723651885986
[10/24] Train loss=0.26137620210647583
[15/24] Train loss=0.2589557468891144
[20/24] Train loss=0.23007884621620178
Test set avg_accuracy=87.59% avg_sensitivity=75.95%, avg_specificity=91.46% avg_auc=91.31%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.265299 Test loss=0.343531 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.24886448681354523
[5/24] Train loss=0.2622765004634857
[10/24] Train loss=0.2562839686870575
[15/24] Train loss=0.2574100196361542
[20/24] Train loss=0.22329482436180115
Test set avg_accuracy=88.41% avg_sensitivity=71.52%, avg_specificity=94.03% avg_auc=91.58%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.259516 Test loss=0.329113 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.23169457912445068
[5/24] Train loss=0.24906274676322937
[10/24] Train loss=0.25244227051734924
[15/24] Train loss=0.2520698308944702
[20/24] Train loss=0.22010894119739532
Test set avg_accuracy=87.49% avg_sensitivity=60.88%, avg_specificity=96.34% avg_auc=89.77%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.250762 Test loss=0.358339 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.24244795739650726
[5/24] Train loss=0.2547846734523773
[10/24] Train loss=0.2538062632083893
[15/24] Train loss=0.24136963486671448
[20/24] Train loss=0.21999476850032806
Test set avg_accuracy=88.55% avg_sensitivity=77.88%, avg_specificity=92.10% avg_auc=92.29%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.252281 Test loss=0.336470 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.23221418261528015
[5/24] Train loss=0.24004897475242615
[10/24] Train loss=0.24202260375022888
[15/24] Train loss=0.2458154559135437
[20/24] Train loss=0.20407241582870483
Test set avg_accuracy=88.16% avg_sensitivity=80.02%, avg_specificity=90.87% avg_auc=91.74%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.244971 Test loss=0.358918 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.22403301298618317
[5/24] Train loss=0.23177126049995422
[10/24] Train loss=0.2371755689382553
[15/24] Train loss=0.23496253788471222
[20/24] Train loss=0.2081374078989029
Test set avg_accuracy=87.51% avg_sensitivity=81.17%, avg_specificity=89.62% avg_auc=91.64%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.238172 Test loss=0.368006 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2281918078660965
[5/24] Train loss=0.23346467316150665
[10/24] Train loss=0.22952453792095184
[15/24] Train loss=0.23200751841068268
[20/24] Train loss=0.20452582836151123
Test set avg_accuracy=88.84% avg_sensitivity=73.14%, avg_specificity=94.07% avg_auc=91.32%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.233718 Test loss=0.333648 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2139969766139984
[5/24] Train loss=0.22492749989032745
[10/24] Train loss=0.22413115203380585
[15/24] Train loss=0.22077889740467072
[20/24] Train loss=0.2010611593723297
Test set avg_accuracy=88.16% avg_sensitivity=81.59%, avg_specificity=90.35% avg_auc=92.05%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.227204 Test loss=0.358225 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2198023945093155
[5/24] Train loss=0.24431844055652618
[10/24] Train loss=0.22302794456481934
[15/24] Train loss=0.23146983981132507
[20/24] Train loss=0.20220200717449188
Test set avg_accuracy=88.22% avg_sensitivity=78.61%, avg_specificity=91.41% avg_auc=91.53%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.228596 Test loss=0.344003 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.21656902134418488
[5/24] Train loss=0.22987201809883118
[10/24] Train loss=0.23473037779331207
[15/24] Train loss=0.2239624708890915
[20/24] Train loss=0.196726456284523
Test set avg_accuracy=88.05% avg_sensitivity=78.35%, avg_specificity=91.27% avg_auc=91.20%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.228937 Test loss=0.357495 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.22395798563957214
[5/24] Train loss=0.2285468727350235
[10/24] Train loss=0.23099423944950104
[15/24] Train loss=0.2116556614637375
[20/24] Train loss=0.20355835556983948
Test set avg_accuracy=87.72% avg_sensitivity=78.20%, avg_specificity=90.89% avg_auc=91.33%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.227641 Test loss=0.363404 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.22739629447460175
[5/24] Train loss=0.21642911434173584
[10/24] Train loss=0.21941912174224854
[15/24] Train loss=0.21848075091838837
[20/24] Train loss=0.20914937555789948
Test set avg_accuracy=88.83% avg_sensitivity=74.96%, avg_specificity=93.44% avg_auc=91.07%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.227657 Test loss=0.337566 Current lr=[0.000134135431043539]

[0/24] Train loss=0.20239144563674927
[5/24] Train loss=0.22879159450531006
[10/24] Train loss=0.229657381772995
[15/24] Train loss=0.22220434248447418
[20/24] Train loss=0.20365509390830994
Test set avg_accuracy=87.58% avg_sensitivity=78.87%, avg_specificity=90.47% avg_auc=92.02%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.225998 Test loss=0.361427 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.21129797399044037
[5/24] Train loss=0.23573949933052063
[10/24] Train loss=0.22443117201328278
[15/24] Train loss=0.20952428877353668
[20/24] Train loss=0.19292882084846497
Test set avg_accuracy=87.88% avg_sensitivity=78.56%, avg_specificity=90.98% avg_auc=91.05%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.229405 Test loss=0.378364 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.21865136921405792
[5/24] Train loss=0.2372971624135971
[10/24] Train loss=0.2127416431903839
[15/24] Train loss=0.20736458897590637
[20/24] Train loss=0.19583255052566528
Test set avg_accuracy=87.97% avg_sensitivity=76.79%, avg_specificity=91.69% avg_auc=90.99%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.222005 Test loss=0.358376 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.21261940896511078
[5/24] Train loss=0.2126339077949524
[10/24] Train loss=0.22507064044475555
[15/24] Train loss=0.20707334578037262
[20/24] Train loss=0.18789663910865784
Test set avg_accuracy=88.22% avg_sensitivity=73.45%, avg_specificity=93.13% avg_auc=91.11%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.217758 Test loss=0.355540 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.20085564255714417
[5/24] Train loss=0.21247416734695435
[10/24] Train loss=0.2104445844888687
[15/24] Train loss=0.20658259093761444
[20/24] Train loss=0.17930833995342255
Test set avg_accuracy=88.14% avg_sensitivity=78.30%, avg_specificity=91.41% avg_auc=91.36%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.209923 Test loss=0.353555 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.19953463971614838
[5/24] Train loss=0.20516210794448853
[10/24] Train loss=0.19995000958442688
[15/24] Train loss=0.1975312978029251
[20/24] Train loss=0.17704182863235474
Test set avg_accuracy=87.63% avg_sensitivity=82.26%, avg_specificity=89.42% avg_auc=92.15%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.206955 Test loss=0.364072 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.19564145803451538
[5/24] Train loss=0.19798290729522705
[10/24] Train loss=0.20030145347118378
[15/24] Train loss=0.18691235780715942
[20/24] Train loss=0.17493802309036255
Test set avg_accuracy=88.35% avg_sensitivity=77.93%, avg_specificity=91.81% avg_auc=91.76%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.203271 Test loss=0.350753 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1869588941335678
[5/24] Train loss=0.20307333767414093
[10/24] Train loss=0.20010387897491455
[15/24] Train loss=0.1896243393421173
[20/24] Train loss=0.17530584335327148
Test set avg_accuracy=88.32% avg_sensitivity=76.32%, avg_specificity=92.31% avg_auc=91.16%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.201100 Test loss=0.350440 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.18803635239601135
[5/24] Train loss=0.196919783949852
[10/24] Train loss=0.1927945613861084
[15/24] Train loss=0.1939619481563568
[20/24] Train loss=0.18057027459144592
Test set avg_accuracy=87.97% avg_sensitivity=75.43%, avg_specificity=92.14% avg_auc=91.75%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.199462 Test loss=0.351572 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.18925562500953674
[5/24] Train loss=0.2029830664396286
[10/24] Train loss=0.18938682973384857
[15/24] Train loss=0.19117946922779083
[20/24] Train loss=0.177492156624794
Test set avg_accuracy=88.89% avg_sensitivity=77.36%, avg_specificity=92.73% avg_auc=91.48%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.200688 Test loss=0.351491 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1904381513595581
[5/24] Train loss=0.19424235820770264
[10/24] Train loss=0.19446907937526703
[15/24] Train loss=0.18940593302249908
[20/24] Train loss=0.17770057916641235
Test set avg_accuracy=87.55% avg_sensitivity=80.91%, avg_specificity=89.76% avg_auc=91.80%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.197815 Test loss=0.373311 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.17645263671875
[5/24] Train loss=0.19052036106586456
[10/24] Train loss=0.19573974609375
[15/24] Train loss=0.18327981233596802
[20/24] Train loss=0.17080320417881012
Test set avg_accuracy=88.01% avg_sensitivity=78.98%, avg_specificity=91.01% avg_auc=91.35%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.193574 Test loss=0.364613 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.18282954394817352
[5/24] Train loss=0.18825386464595795
[10/24] Train loss=0.1882176399230957
[15/24] Train loss=0.1817627102136612
[20/24] Train loss=0.16753554344177246
Test set avg_accuracy=87.53% avg_sensitivity=80.75%, avg_specificity=89.78% avg_auc=91.72%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.189877 Test loss=0.378141 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.17743661999702454
[5/24] Train loss=0.19029004871845245
[10/24] Train loss=0.18279893696308136
[15/24] Train loss=0.18422770500183105
[20/24] Train loss=0.1670723855495453
Test set avg_accuracy=87.06% avg_sensitivity=81.64%, avg_specificity=88.86% avg_auc=91.12%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.189947 Test loss=0.406905 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1738968789577484
[5/24] Train loss=0.19741006195545197
[10/24] Train loss=0.1858600378036499
[15/24] Train loss=0.18861424922943115
[20/24] Train loss=0.16984015703201294
Test set avg_accuracy=87.57% avg_sensitivity=81.22%, avg_specificity=89.68% avg_auc=91.92%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.191012 Test loss=0.382706 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.18145520985126495
[5/24] Train loss=0.189011812210083
[10/24] Train loss=0.18206603825092316
[15/24] Train loss=0.18905380368232727
[20/24] Train loss=0.16583780944347382
Test set avg_accuracy=87.50% avg_sensitivity=83.41%, avg_specificity=88.86% avg_auc=91.74%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.190672 Test loss=0.397851 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1754148304462433
[5/24] Train loss=0.18831564486026764
[10/24] Train loss=0.18234069645404816
[15/24] Train loss=0.1888461410999298
[20/24] Train loss=0.1631058305501938
Test set avg_accuracy=87.79% avg_sensitivity=81.17%, avg_specificity=89.99% avg_auc=91.99%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.189414 Test loss=0.366795 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.17530322074890137
[5/24] Train loss=0.1826988011598587
[10/24] Train loss=0.1842290312051773
[15/24] Train loss=0.17297154664993286
[20/24] Train loss=0.16016478836536407
Test set avg_accuracy=88.67% avg_sensitivity=74.02%, avg_specificity=93.55% avg_auc=91.45%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.183298 Test loss=0.341260 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.16702872514724731
[5/24] Train loss=0.1851736605167389
[10/24] Train loss=0.1809379607439041
[15/24] Train loss=0.17322108149528503
[20/24] Train loss=0.16349317133426666
Test set avg_accuracy=88.06% avg_sensitivity=81.01%, avg_specificity=90.40% avg_auc=92.11%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.181429 Test loss=0.361219 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.16726195812225342
[5/24] Train loss=0.1882590353488922
[10/24] Train loss=0.17709997296333313
[15/24] Train loss=0.16791945695877075
[20/24] Train loss=0.16750741004943848
Test set avg_accuracy=87.77% avg_sensitivity=79.97%, avg_specificity=90.37% avg_auc=91.89%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.178994 Test loss=0.365913 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.16824503242969513
[5/24] Train loss=0.17868834733963013
[10/24] Train loss=0.17393194139003754
[15/24] Train loss=0.16827087104320526
[20/24] Train loss=0.15676216781139374
Test set avg_accuracy=87.47% avg_sensitivity=81.22%, avg_specificity=89.55% avg_auc=92.08%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.179459 Test loss=0.371641 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.16275349259376526
[5/24] Train loss=0.18146924674510956
[10/24] Train loss=0.17622259259223938
[15/24] Train loss=0.1759004294872284
[20/24] Train loss=0.16579516232013702
Test set avg_accuracy=87.89% avg_sensitivity=79.24%, avg_specificity=90.77% avg_auc=91.79%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.180635 Test loss=0.363331 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1669009029865265
[5/24] Train loss=0.18593376874923706
[10/24] Train loss=0.16896089911460876
[15/24] Train loss=0.1728394329547882
[20/24] Train loss=0.15927474200725555
Test set avg_accuracy=88.03% avg_sensitivity=81.32%, avg_specificity=90.27% avg_auc=91.67%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.178589 Test loss=0.364251 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.16154836118221283
[5/24] Train loss=0.1787785440683365
[10/24] Train loss=0.1792752891778946
[15/24] Train loss=0.16634589433670044
[20/24] Train loss=0.15837183594703674
Test set avg_accuracy=88.33% avg_sensitivity=78.82%, avg_specificity=91.50% avg_auc=91.11%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.177204 Test loss=0.357378 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.167137011885643
[5/24] Train loss=0.1803778111934662
[10/24] Train loss=0.17346081137657166
[15/24] Train loss=0.16371524333953857
[20/24] Train loss=0.1609819233417511
Test set avg_accuracy=87.89% avg_sensitivity=79.86%, avg_specificity=90.56% avg_auc=91.32%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.176786 Test loss=0.363709 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.16410891711711884
[5/24] Train loss=0.18186433613300323
[10/24] Train loss=0.1756759136915207
[15/24] Train loss=0.16737154126167297
[20/24] Train loss=0.15723799169063568
Test set avg_accuracy=88.42% avg_sensitivity=79.66%, avg_specificity=91.34% avg_auc=91.58%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.176329 Test loss=0.353353 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.16270597279071808
[5/24] Train loss=0.18735605478286743
[10/24] Train loss=0.17736223340034485
[15/24] Train loss=0.159123495221138
[20/24] Train loss=0.16622723639011383
Test set avg_accuracy=87.64% avg_sensitivity=80.59%, avg_specificity=89.99% avg_auc=91.56%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.177679 Test loss=0.362499 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.16139990091323853
[5/24] Train loss=0.1724572479724884
[10/24] Train loss=0.18011678755283356
[15/24] Train loss=0.1648501455783844
[20/24] Train loss=0.1564943492412567
Test set avg_accuracy=87.49% avg_sensitivity=81.06%, avg_specificity=89.62% avg_auc=91.76%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.176206 Test loss=0.366652 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.17291073501110077
[5/24] Train loss=0.17458856105804443
[10/24] Train loss=0.17544981837272644
[15/24] Train loss=0.17041245102882385
[20/24] Train loss=0.15096786618232727
Test set avg_accuracy=87.79% avg_sensitivity=80.91%, avg_specificity=90.07% avg_auc=91.57%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.174539 Test loss=0.365436 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.16827012598514557
[5/24] Train loss=0.18389204144477844
[10/24] Train loss=0.16702710092067719
[15/24] Train loss=0.17090272903442383
[20/24] Train loss=0.15469659864902496
Test set avg_accuracy=88.10% avg_sensitivity=79.86%, avg_specificity=90.84% avg_auc=91.74%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.174890 Test loss=0.355561 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.15977147221565247
[5/24] Train loss=0.17648537456989288
[10/24] Train loss=0.16965898871421814
[15/24] Train loss=0.16231690347194672
[20/24] Train loss=0.15350733697414398
Test set avg_accuracy=88.01% avg_sensitivity=80.96%, avg_specificity=90.35% avg_auc=91.68%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.170102 Test loss=0.359875 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1547190248966217
[5/24] Train loss=0.16708588600158691
[10/24] Train loss=0.16808921098709106
[15/24] Train loss=0.15594130754470825
[20/24] Train loss=0.1502193659543991
Test set avg_accuracy=88.01% avg_sensitivity=81.06%, avg_specificity=90.32% avg_auc=91.60%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.167255 Test loss=0.360653 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.15375611186027527
[5/24] Train loss=0.16861605644226074
[10/24] Train loss=0.16700896620750427
[15/24] Train loss=0.15898004174232483
[20/24] Train loss=0.1486053317785263
Test set avg_accuracy=87.98% avg_sensitivity=80.44%, avg_specificity=90.49% avg_auc=91.74%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.165953 Test loss=0.356801 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.15656983852386475
[5/24] Train loss=0.17022311687469482
[10/24] Train loss=0.16842684149742126
[15/24] Train loss=0.15261024236679077
[20/24] Train loss=0.14860990643501282
Test set avg_accuracy=87.84% avg_sensitivity=81.85%, avg_specificity=89.83% avg_auc=91.83%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.165292 Test loss=0.359947 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.15430492162704468
[5/24] Train loss=0.172966867685318
[10/24] Train loss=0.16142156720161438
[15/24] Train loss=0.15774810314178467
[20/24] Train loss=0.15160854160785675
Test set avg_accuracy=88.11% avg_sensitivity=79.76%, avg_specificity=90.89% avg_auc=91.89%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.166026 Test loss=0.353826 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.15349361300468445
[5/24] Train loss=0.16773545742034912
[10/24] Train loss=0.16728475689888
[15/24] Train loss=0.1586565375328064
[20/24] Train loss=0.14542606472969055
Test set avg_accuracy=88.01% avg_sensitivity=80.28%, avg_specificity=90.58% avg_auc=91.90%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.164998 Test loss=0.356837 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.14986084401607513
[5/24] Train loss=0.17019326984882355
[10/24] Train loss=0.1646319031715393
[15/24] Train loss=0.15293824672698975
[20/24] Train loss=0.14595527946949005
Test set avg_accuracy=88.49% avg_sensitivity=78.98%, avg_specificity=91.65% avg_auc=91.65%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.164055 Test loss=0.351578 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.15392176806926727
[5/24] Train loss=0.16857154667377472
[10/24] Train loss=0.16403135657310486
[15/24] Train loss=0.1544298529624939
[20/24] Train loss=0.1453910619020462
Test set avg_accuracy=88.05% avg_sensitivity=81.43%, avg_specificity=90.25% avg_auc=91.68%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.163388 Test loss=0.355867 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1511543095111847
[5/24] Train loss=0.17052988708019257
[10/24] Train loss=0.16469696164131165
[15/24] Train loss=0.15746121108531952
[20/24] Train loss=0.14489829540252686
Test set avg_accuracy=88.24% avg_sensitivity=80.75%, avg_specificity=90.73% avg_auc=91.61%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.163498 Test loss=0.357319 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.14811868965625763
[5/24] Train loss=0.16914111375808716
[10/24] Train loss=0.15977723896503448
[15/24] Train loss=0.15380825102329254
[20/24] Train loss=0.147930309176445
Test set avg_accuracy=87.97% avg_sensitivity=80.13%, avg_specificity=90.58% avg_auc=91.74%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.163514 Test loss=0.355000 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.15177905559539795
[5/24] Train loss=0.16808795928955078
[10/24] Train loss=0.16074325144290924
[15/24] Train loss=0.15330804884433746
[20/24] Train loss=0.14659972488880157
Test set avg_accuracy=87.92% avg_sensitivity=80.59%, avg_specificity=90.35% avg_auc=91.79%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.162977 Test loss=0.355697 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.15184012055397034
[5/24] Train loss=0.16607171297073364
[10/24] Train loss=0.16215796768665314
[15/24] Train loss=0.1578683704137802
[20/24] Train loss=0.1445125937461853
Test set avg_accuracy=87.94% avg_sensitivity=80.33%, avg_specificity=90.47% avg_auc=91.76%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.162572 Test loss=0.356018 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.14718672633171082
[5/24] Train loss=0.16845674812793732
[10/24] Train loss=0.162506103515625
[15/24] Train loss=0.1526775062084198
[20/24] Train loss=0.14880527555942535
Test set avg_accuracy=88.03% avg_sensitivity=79.86%, avg_specificity=90.75% avg_auc=91.70%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.162478 Test loss=0.355313 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1509193778038025
[5/24] Train loss=0.16689197719097137
[10/24] Train loss=0.15803319215774536
[15/24] Train loss=0.1509084850549698
[20/24] Train loss=0.1506708860397339
Test set avg_accuracy=87.84% avg_sensitivity=80.02%, avg_specificity=90.44% avg_auc=91.70%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.162029 Test loss=0.355243 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.14896690845489502
[5/24] Train loss=0.16434422135353088
[10/24] Train loss=0.16054590046405792
[15/24] Train loss=0.15274538099765778
[20/24] Train loss=0.14556777477264404
Test set avg_accuracy=87.84% avg_sensitivity=80.39%, avg_specificity=90.32% avg_auc=91.69%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.162578 Test loss=0.356299 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.15027844905853271
[5/24] Train loss=0.16538244485855103
[10/24] Train loss=0.16284474730491638
[15/24] Train loss=0.15328173339366913
[20/24] Train loss=0.14376750588417053
Test set avg_accuracy=87.76% avg_sensitivity=79.76%, avg_specificity=90.42% avg_auc=91.69%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.161919 Test loss=0.355690 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.14969636499881744
[5/24] Train loss=0.16554643213748932
[10/24] Train loss=0.15814346075057983
[15/24] Train loss=0.1493443101644516
[20/24] Train loss=0.14394649863243103
Test set avg_accuracy=87.76% avg_sensitivity=79.76%, avg_specificity=90.42% avg_auc=91.68%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.162015 Test loss=0.355760 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.14878064393997192
[5/24] Train loss=0.16327576339244843
[10/24] Train loss=0.16169437766075134
[15/24] Train loss=0.15184079110622406
[20/24] Train loss=0.14465612173080444
Test set avg_accuracy=87.84% avg_sensitivity=80.18%, avg_specificity=90.39% avg_auc=91.68%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.162641 Test loss=0.356061 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1494494527578354
[5/24] Train loss=0.16971290111541748
[10/24] Train loss=0.1616869866847992
[15/24] Train loss=0.15274274349212646
[20/24] Train loss=0.1438138782978058
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=87.76% avg_sensitivity=79.86%, avg_specificity=90.39% avg_auc=91.69%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.162993 Test loss=0.355944 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=88.09% sen=85.55%, spe=88.93%, auc=92.71%!
Fold[2] Avg_overlap=0.68%(0.2300318579979622)
[0/24] Train loss=1.5317823886871338
[5/24] Train loss=1.4909666776657104
[10/24] Train loss=1.4991743564605713
[15/24] Train loss=1.4512642621994019
[20/24] Train loss=1.43392014503479
Test set avg_accuracy=58.37% avg_sensitivity=43.79%, avg_specificity=63.90% avg_auc=57.59%
Best model saved!! Metric=-102.35083372242832!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=1.470541 Test loss=0.672886 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.436979055404663
[5/24] Train loss=1.4072787761688232
[10/24] Train loss=1.406943440437317
[15/24] Train loss=1.3513927459716797
[20/24] Train loss=1.3573980331420898
Test set avg_accuracy=71.81% avg_sensitivity=59.48%, avg_specificity=76.48% avg_auc=69.75%
Best model saved!! Metric=-48.484789643195434!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=1.390419 Test loss=0.622190 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3572884798049927
[5/24] Train loss=1.3404086828231812
[10/24] Train loss=1.3478589057922363
[15/24] Train loss=1.2831884622573853
[20/24] Train loss=1.2717937231063843
Test set avg_accuracy=74.40% avg_sensitivity=76.78%, avg_specificity=73.50% avg_auc=77.17%
Best model saved!! Metric=-24.15158879271712!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=1.321402 Test loss=0.594587 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.2572818994522095
[5/24] Train loss=1.2679067850112915
[10/24] Train loss=1.2970905303955078
[15/24] Train loss=1.2300654649734497
[20/24] Train loss=1.1828731298446655
Test set avg_accuracy=75.62% avg_sensitivity=82.09%, avg_specificity=73.18% avg_auc=81.17%
Best model saved!! Metric=-13.937113386711133!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=1.246926 Test loss=0.571878 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.1741122007369995
[5/24] Train loss=1.2064697742462158
[10/24] Train loss=1.2243136167526245
[15/24] Train loss=1.1440880298614502
[20/24] Train loss=1.1172969341278076
Test set avg_accuracy=75.99% avg_sensitivity=85.88%, avg_specificity=72.24% avg_auc=83.72%
Best model saved!! Metric=-8.166533984389403!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=1.176450 Test loss=0.549677 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.1053128242492676
[5/24] Train loss=1.1268305778503418
[10/24] Train loss=1.1675928831100464
[15/24] Train loss=1.0772138833999634
[20/24] Train loss=1.057753324508667
Test set avg_accuracy=76.68% avg_sensitivity=86.16%, avg_specificity=73.09% avg_auc=85.41%
Best model saved!! Metric=-4.65904317465349!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=1.111234 Test loss=0.528978 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.0433765649795532
[5/24] Train loss=1.0634783506393433
[10/24] Train loss=1.1124051809310913
[15/24] Train loss=1.0298130512237549
[20/24] Train loss=0.9872376918792725
Test set avg_accuracy=77.77% avg_sensitivity=86.02%, avg_specificity=74.65% avg_auc=86.93%
Best model saved!! Metric=-0.6253304426854953!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=1.052254 Test loss=0.505603 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9931395053863525
[5/24] Train loss=1.0236390829086304
[10/24] Train loss=1.0747383832931519
[15/24] Train loss=0.9928379654884338
[20/24] Train loss=0.930724024772644
Test set avg_accuracy=79.00% avg_sensitivity=86.11%, avg_specificity=76.30% avg_auc=88.14%
Best model saved!! Metric=3.5547188314529024!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=1.000917 Test loss=0.482352 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.9450930953025818
[5/24] Train loss=0.9614405632019043
[10/24] Train loss=0.991032063961029
[15/24] Train loss=0.9243977069854736
[20/24] Train loss=0.8797466158866882
Test set avg_accuracy=81.38% avg_sensitivity=84.98%, avg_specificity=80.02% avg_auc=89.22%
Best model saved!! Metric=9.597001070321426!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.943444 Test loss=0.451437 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8961652517318726
[5/24] Train loss=0.908078670501709
[10/24] Train loss=0.9473493695259094
[15/24] Train loss=0.8846811056137085
[20/24] Train loss=0.810425341129303
Test set avg_accuracy=82.08% avg_sensitivity=86.02%, avg_specificity=80.59% avg_auc=90.38%
Best model saved!! Metric=13.077402781204896!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.894634 Test loss=0.433388 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.8462560176849365
[5/24] Train loss=0.8707637786865234
[10/24] Train loss=0.8935684561729431
[15/24] Train loss=0.8574756979942322
[20/24] Train loss=0.7724659442901611
Test set avg_accuracy=82.84% avg_sensitivity=86.64%, avg_specificity=81.40% avg_auc=91.04%
Best model saved!! Metric=15.917089574806923!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.850566 Test loss=0.424911 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.792170524597168
[5/24] Train loss=0.8342621326446533
[10/24] Train loss=0.862855851650238
[15/24] Train loss=0.8081430196762085
[20/24] Train loss=0.7328316569328308
Test set avg_accuracy=83.20% avg_sensitivity=87.11%, avg_specificity=81.72% avg_auc=91.58%
Best model saved!! Metric=17.614741054183284!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.812714 Test loss=0.417234 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7549492716789246
[5/24] Train loss=0.8083555698394775
[10/24] Train loss=0.8459508419036865
[15/24] Train loss=0.7954137921333313
[20/24] Train loss=0.6942377090454102
Test set avg_accuracy=83.84% avg_sensitivity=86.97%, avg_specificity=82.66% avg_auc=91.96%
Best model saved!! Metric=19.42121679575048!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.777885 Test loss=0.406304 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.7358282208442688
[5/24] Train loss=0.7772113084793091
[10/24] Train loss=0.8272292017936707
[15/24] Train loss=0.7577576041221619
[20/24] Train loss=0.665263831615448
Test set avg_accuracy=84.52% avg_sensitivity=87.01%, avg_specificity=83.57% avg_auc=92.25%
Best model saved!! Metric=21.356802430682606!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.751253 Test loss=0.395641 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.703362762928009
[5/24] Train loss=0.7516158223152161
[10/24] Train loss=0.7780187129974365
[15/24] Train loss=0.7379099726676941
[20/24] Train loss=0.6414225697517395
Test set avg_accuracy=85.07% avg_sensitivity=86.54%, avg_specificity=84.51% avg_auc=92.53%
Best model saved!! Metric=22.64372014427181!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.724782 Test loss=0.386977 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.673593282699585
[5/24] Train loss=0.7285258173942566
[10/24] Train loss=0.7740398049354553
[15/24] Train loss=0.710022509098053
[20/24] Train loss=0.6287465691566467
Test set avg_accuracy=85.49% avg_sensitivity=86.07%, avg_specificity=85.28% avg_auc=92.78%
Best model saved!! Metric=23.624285314934752!!
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.706362 Test loss=0.373434 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6519634127616882
[5/24] Train loss=0.6994293332099915
[10/24] Train loss=0.7396844029426575
[15/24] Train loss=0.7156341075897217
[20/24] Train loss=0.5973478555679321
Test set avg_accuracy=85.25% avg_sensitivity=85.45%, avg_specificity=85.17% avg_auc=92.70%
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.684576 Test loss=0.371844 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.6419252157211304
[5/24] Train loss=0.6902292370796204
[10/24] Train loss=0.7440714836120605
[15/24] Train loss=0.6992632746696472
[20/24] Train loss=0.577182412147522
Test set avg_accuracy=84.79% avg_sensitivity=87.82%, avg_specificity=83.64% avg_auc=92.84%
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.674115 Test loss=0.384313 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.6226068139076233
[5/24] Train loss=0.6737013459205627
[10/24] Train loss=0.7190514206886292
[15/24] Train loss=0.6768191456794739
[20/24] Train loss=0.5634147524833679
Test set avg_accuracy=85.01% avg_sensitivity=87.68%, avg_specificity=84.00% avg_auc=93.11%
Best model saved!! Metric=23.801056774010775!!
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.656343 Test loss=0.375064 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.6087514162063599
[5/24] Train loss=0.6474127173423767
[10/24] Train loss=0.703161895275116
[15/24] Train loss=0.6631827354431152
[20/24] Train loss=0.5530540347099304
Test set avg_accuracy=86.35% avg_sensitivity=86.49%, avg_specificity=86.30% avg_auc=93.24%
Best model saved!! Metric=26.385772170082916!!
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.643250 Test loss=0.350823 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5919281244277954
[5/24] Train loss=0.6110725998878479
[10/24] Train loss=0.6940861344337463
[15/24] Train loss=0.655900239944458
[20/24] Train loss=0.5397080183029175
Test set avg_accuracy=86.59% avg_sensitivity=84.74%, avg_specificity=87.29% avg_auc=93.31%
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.627412 Test loss=0.342508 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5891301035881042
[5/24] Train loss=0.6121326684951782
[10/24] Train loss=0.7017422318458557
[15/24] Train loss=0.6422133445739746
[20/24] Train loss=0.5159527063369751
Test set avg_accuracy=87.33% avg_sensitivity=77.39%, avg_specificity=91.10% avg_auc=93.31%
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.617397 Test loss=0.306882 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5775901675224304
[5/24] Train loss=0.578511655330658
[10/24] Train loss=0.6831007599830627
[15/24] Train loss=0.6233125925064087
[20/24] Train loss=0.5226845145225525
Test set avg_accuracy=87.36% avg_sensitivity=81.37%, avg_specificity=89.62% avg_auc=93.40%
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.602092 Test loss=0.316003 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5694798827171326
[5/24] Train loss=0.5751469135284424
[10/24] Train loss=0.6660456657409668
[15/24] Train loss=0.6057591438293457
[20/24] Train loss=0.515781581401825
Test set avg_accuracy=87.17% avg_sensitivity=82.70%, avg_specificity=88.87% avg_auc=93.48%
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.594896 Test loss=0.319167 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5439245104789734
[5/24] Train loss=0.5535815358161926
[10/24] Train loss=0.6583486795425415
[15/24] Train loss=0.6024079918861389
[20/24] Train loss=0.5011907815933228
Test set avg_accuracy=85.59% avg_sensitivity=88.39%, avg_specificity=84.52% avg_auc=93.52%
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.583929 Test loss=0.363173 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5552248954772949
[5/24] Train loss=0.561795175075531
[10/24] Train loss=0.646425187587738
[15/24] Train loss=0.586404025554657
[20/24] Train loss=0.4909655749797821
Test set avg_accuracy=88.24% avg_sensitivity=77.39%, avg_specificity=92.35% avg_auc=93.70%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.571763 Test loss=0.290583 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5428361892700195
[5/24] Train loss=0.524516761302948
[10/24] Train loss=0.6632626056671143
[15/24] Train loss=0.570280909538269
[20/24] Train loss=0.500045895576477
Test set avg_accuracy=87.53% avg_sensitivity=81.37%, avg_specificity=89.86% avg_auc=93.36%
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.560175 Test loss=0.319905 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.5255646109580994
[5/24] Train loss=0.5247186422348022
[10/24] Train loss=0.6310751438140869
[15/24] Train loss=0.5512058734893799
[20/24] Train loss=0.4828740060329437
Test set avg_accuracy=88.74% avg_sensitivity=76.49%, avg_specificity=93.38% avg_auc=93.42%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.554707 Test loss=0.290831 Current lr=[0.000210185142098938]

[0/24] Train loss=0.5325793027877808
[5/24] Train loss=0.5030670762062073
[10/24] Train loss=0.6051271557807922
[15/24] Train loss=0.5499904751777649
[20/24] Train loss=0.45615869760513306
Test set avg_accuracy=88.62% avg_sensitivity=76.92%, avg_specificity=93.05% avg_auc=93.64%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.537626 Test loss=0.289390 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.5229253768920898
[5/24] Train loss=0.49953749775886536
[10/24] Train loss=0.6115662455558777
[15/24] Train loss=0.533380925655365
[20/24] Train loss=0.457953542470932
Test set avg_accuracy=85.83% avg_sensitivity=85.26%, avg_specificity=86.05% avg_auc=93.64%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.529508 Test loss=0.329632 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.5212056636810303
[5/24] Train loss=0.47317105531692505
[10/24] Train loss=0.6176958680152893
[15/24] Train loss=0.5227407217025757
[20/24] Train loss=0.4584338963031769
Test set avg_accuracy=86.22% avg_sensitivity=59.91%, avg_specificity=96.19% avg_auc=91.76%
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.525649 Test loss=0.327793 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.4967907667160034
[5/24] Train loss=0.512021005153656
[10/24] Train loss=0.5943949222564697
[15/24] Train loss=0.5230892300605774
[20/24] Train loss=0.4507731795310974
Test set avg_accuracy=86.64% avg_sensitivity=61.90%, avg_specificity=96.01% avg_auc=91.78%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.512838 Test loss=0.323778 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.488808274269104
[5/24] Train loss=0.48418954014778137
[10/24] Train loss=0.5789438486099243
[15/24] Train loss=0.5308913588523865
[20/24] Train loss=0.4307115972042084
Test set avg_accuracy=88.41% avg_sensitivity=76.16%, avg_specificity=93.05% avg_auc=93.31%
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.506434 Test loss=0.296817 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.48392316699028015
[5/24] Train loss=0.48654884099960327
[10/24] Train loss=0.5933239459991455
[15/24] Train loss=0.5103079080581665
[20/24] Train loss=0.43801501393318176
Test set avg_accuracy=86.95% avg_sensitivity=86.07%, avg_specificity=87.29% avg_auc=93.44%
Best model saved!! Metric=27.74785301994436!!
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.500068 Test loss=0.332001 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.47765490412712097
[5/24] Train loss=0.42415758967399597
[10/24] Train loss=0.5834186673164368
[15/24] Train loss=0.4932596683502197
[20/24] Train loss=0.4128516912460327
Test set avg_accuracy=87.20% avg_sensitivity=84.08%, avg_specificity=88.38% avg_auc=93.48%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.489644 Test loss=0.320872 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.48789140582084656
[5/24] Train loss=0.43861550092697144
[10/24] Train loss=0.5897658467292786
[15/24] Train loss=0.49408891797065735
[20/24] Train loss=0.41091102361679077
Test set avg_accuracy=79.21% avg_sensitivity=91.80%, avg_specificity=74.43% avg_auc=92.00%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.493512 Test loss=0.472756 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4618408679962158
[5/24] Train loss=0.44225436449050903
[10/24] Train loss=0.5775318741798401
[15/24] Train loss=0.5135733485221863
[20/24] Train loss=0.4147123098373413
Test set avg_accuracy=88.36% avg_sensitivity=73.93%, avg_specificity=93.82% avg_auc=92.20%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.474651 Test loss=0.319131 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.4448862671852112
[5/24] Train loss=0.42620202898979187
[10/24] Train loss=0.5350791215896606
[15/24] Train loss=0.4760574996471405
[20/24] Train loss=0.4062877595424652
Test set avg_accuracy=88.19% avg_sensitivity=70.33%, avg_specificity=94.96% avg_auc=92.10%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.466730 Test loss=0.320964 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4629419147968292
[5/24] Train loss=0.40598395466804504
[10/24] Train loss=0.4942965507507324
[15/24] Train loss=0.47177425026893616
[20/24] Train loss=0.4116562604904175
Test set avg_accuracy=88.36% avg_sensitivity=75.69%, avg_specificity=93.16% avg_auc=92.23%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.446168 Test loss=0.319407 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.42320457100868225
[5/24] Train loss=0.38602161407470703
[10/24] Train loss=0.5163869857788086
[15/24] Train loss=0.4998350143432617
[20/24] Train loss=0.4019252359867096
Test set avg_accuracy=86.33% avg_sensitivity=85.17%, avg_specificity=86.77% avg_auc=92.77%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.444241 Test loss=0.359942 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4161375164985657
[5/24] Train loss=0.39741501212120056
[10/24] Train loss=0.474129319190979
[15/24] Train loss=0.4509584605693817
[20/24] Train loss=0.4022101163864136
Test set avg_accuracy=85.81% avg_sensitivity=86.30%, avg_specificity=85.62% avg_auc=92.71%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.436485 Test loss=0.354014 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.42771288752555847
[5/24] Train loss=0.37654566764831543
[10/24] Train loss=0.47252580523490906
[15/24] Train loss=0.4586200714111328
[20/24] Train loss=0.3931376039981842
Test set avg_accuracy=88.06% avg_sensitivity=79.86%, avg_specificity=91.17% avg_auc=93.23%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.436412 Test loss=0.309851 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4140597879886627
[5/24] Train loss=0.37220194935798645
[10/24] Train loss=0.48348721861839294
[15/24] Train loss=0.4838491678237915
[20/24] Train loss=0.37009528279304504
Test set avg_accuracy=83.71% avg_sensitivity=48.86%, avg_specificity=96.91% avg_auc=87.19%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.429696 Test loss=0.444592 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3983619809150696
[5/24] Train loss=0.3681770861148834
[10/24] Train loss=0.43443867564201355
[15/24] Train loss=0.454761266708374
[20/24] Train loss=0.40191659331321716
Test set avg_accuracy=83.40% avg_sensitivity=91.33%, avg_specificity=80.39% avg_auc=93.06%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.421561 Test loss=0.403699 Current lr=[0.00029967723776099]

[0/24] Train loss=0.39713168144226074
[5/24] Train loss=0.40230855345726013
[10/24] Train loss=0.5331873893737793
[15/24] Train loss=0.4760788083076477
[20/24] Train loss=0.3727545738220215
Test set avg_accuracy=78.46% avg_sensitivity=92.99%, avg_specificity=72.96% avg_auc=92.01%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.422854 Test loss=0.519852 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.4081251919269562
[5/24] Train loss=0.3368135392665863
[10/24] Train loss=0.4850834906101227
[15/24] Train loss=0.4542113244533539
[20/24] Train loss=0.3971050977706909
Test set avg_accuracy=80.99% avg_sensitivity=88.58%, avg_specificity=78.11% avg_auc=91.71%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.418628 Test loss=0.470172 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.4020969569683075
[5/24] Train loss=0.3522007167339325
[10/24] Train loss=0.5158141255378723
[15/24] Train loss=0.4119431674480438
[20/24] Train loss=0.3614254295825958
Test set avg_accuracy=84.58% avg_sensitivity=88.91%, avg_specificity=82.94% avg_auc=92.79%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.405574 Test loss=0.391834 Current lr=[0.000299720220882401]

[0/24] Train loss=0.40084394812583923
[5/24] Train loss=0.35720446705818176
[10/24] Train loss=0.4547251760959625
[15/24] Train loss=0.43183350563049316
[20/24] Train loss=0.3478650450706482
Test set avg_accuracy=87.37% avg_sensitivity=82.51%, avg_specificity=89.21% avg_auc=93.31%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.397399 Test loss=0.317330 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3837440013885498
[5/24] Train loss=0.3297271728515625
[10/24] Train loss=0.44597581028938293
[15/24] Train loss=0.4439958930015564
[20/24] Train loss=0.3740836977958679
Test set avg_accuracy=87.30% avg_sensitivity=84.31%, avg_specificity=88.44% avg_auc=92.07%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.393068 Test loss=0.347411 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3760649561882019
[5/24] Train loss=0.35690435767173767
[10/24] Train loss=0.43589138984680176
[15/24] Train loss=0.4085811376571655
[20/24] Train loss=0.3265325129032135
Test set avg_accuracy=86.91% avg_sensitivity=79.81%, avg_specificity=89.61% avg_auc=93.17%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.392607 Test loss=0.317672 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.35918134450912476
[5/24] Train loss=0.33484798669815063
[10/24] Train loss=0.4215051829814911
[15/24] Train loss=0.41338396072387695
[20/24] Train loss=0.3579214811325073
Test set avg_accuracy=83.41% avg_sensitivity=90.38%, avg_specificity=80.77% avg_auc=92.59%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.391124 Test loss=0.421148 Current lr=[0.000297555943323901]

[0/24] Train loss=0.38436657190322876
[5/24] Train loss=0.32516786456108093
[10/24] Train loss=0.4379412531852722
[15/24] Train loss=0.39934319257736206
[20/24] Train loss=0.36265766620635986
Test set avg_accuracy=87.57% avg_sensitivity=83.70%, avg_specificity=89.03% avg_auc=93.51%
Best model saved!! Metric=27.799509877694774!!
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.375780 Test loss=0.317673 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3653992712497711
[5/24] Train loss=0.3616524040699005
[10/24] Train loss=0.4343041181564331
[15/24] Train loss=0.4219033420085907
[20/24] Train loss=0.37693291902542114
Test set avg_accuracy=86.47% avg_sensitivity=69.38%, avg_specificity=92.94% avg_auc=90.80%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.388109 Test loss=0.347119 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.36449992656707764
[5/24] Train loss=0.33238986134529114
[10/24] Train loss=0.4291422665119171
[15/24] Train loss=0.4015417993068695
[20/24] Train loss=0.35729557275772095
Test set avg_accuracy=88.07% avg_sensitivity=79.24%, avg_specificity=91.42% avg_auc=93.08%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.380233 Test loss=0.306130 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.36071860790252686
[5/24] Train loss=0.30757632851600647
[10/24] Train loss=0.4020181894302368
[15/24] Train loss=0.38034161925315857
[20/24] Train loss=0.3191649913787842
Test set avg_accuracy=86.25% avg_sensitivity=64.45%, avg_specificity=94.51% avg_auc=89.42%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.365059 Test loss=0.368975 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.36906659603118896
[5/24] Train loss=0.33049502968788147
[10/24] Train loss=0.38961127400398254
[15/24] Train loss=0.39893072843551636
[20/24] Train loss=0.3493298590183258
Test set avg_accuracy=84.82% avg_sensitivity=57.68%, avg_specificity=95.10% avg_auc=87.11%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.369276 Test loss=0.405341 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3706597089767456
[5/24] Train loss=0.3177148401737213
[10/24] Train loss=0.406145304441452
[15/24] Train loss=0.38689106702804565
[20/24] Train loss=0.315466046333313
Test set avg_accuracy=82.15% avg_sensitivity=89.38%, avg_specificity=79.41% avg_auc=91.86%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.365587 Test loss=0.457117 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.35511264204978943
[5/24] Train loss=0.3206402361392975
[10/24] Train loss=0.40339988470077515
[15/24] Train loss=0.41446542739868164
[20/24] Train loss=0.34297576546669006
Test set avg_accuracy=86.60% avg_sensitivity=69.05%, avg_specificity=93.25% avg_auc=90.78%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.368148 Test loss=0.354783 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.343258798122406
[5/24] Train loss=0.3004249036312103
[10/24] Train loss=0.41358280181884766
[15/24] Train loss=0.3800804615020752
[20/24] Train loss=0.33773505687713623
Test set avg_accuracy=87.70% avg_sensitivity=77.54%, avg_specificity=91.54% avg_auc=92.54%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.360094 Test loss=0.324839 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3601323068141937
[5/24] Train loss=0.30246374011039734
[10/24] Train loss=0.3828790485858917
[15/24] Train loss=0.406883180141449
[20/24] Train loss=0.318573534488678
Test set avg_accuracy=85.98% avg_sensitivity=86.16%, avg_specificity=85.91% avg_auc=92.94%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.354915 Test loss=0.358258 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3431055247783661
[5/24] Train loss=0.3004491329193115
[10/24] Train loss=0.41831615567207336
[15/24] Train loss=0.37414100766181946
[20/24] Train loss=0.34038567543029785
Test set avg_accuracy=85.56% avg_sensitivity=85.36%, avg_specificity=85.64% avg_auc=92.04%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.345661 Test loss=0.380180 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.33777642250061035
[5/24] Train loss=0.30906373262405396
[10/24] Train loss=0.3755249083042145
[15/24] Train loss=0.34750962257385254
[20/24] Train loss=0.3265862464904785
Test set avg_accuracy=87.04% avg_sensitivity=84.22%, avg_specificity=88.11% avg_auc=93.03%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.343846 Test loss=0.335150 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.31806132197380066
[5/24] Train loss=0.3160446286201477
[10/24] Train loss=0.3547365069389343
[15/24] Train loss=0.3420475721359253
[20/24] Train loss=0.33493056893348694
Test set avg_accuracy=87.76% avg_sensitivity=82.18%, avg_specificity=89.87% avg_auc=91.84%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.338470 Test loss=0.353150 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.30919960141181946
[5/24] Train loss=0.2898760437965393
[10/24] Train loss=0.3668883144855499
[15/24] Train loss=0.33353888988494873
[20/24] Train loss=0.32570546865463257
Test set avg_accuracy=86.18% avg_sensitivity=84.41%, avg_specificity=86.86% avg_auc=92.31%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.332802 Test loss=0.362436 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3107294738292694
[5/24] Train loss=0.2667696177959442
[10/24] Train loss=0.35454580187797546
[15/24] Train loss=0.3748118579387665
[20/24] Train loss=0.3120749294757843
Test set avg_accuracy=86.89% avg_sensitivity=83.55%, avg_specificity=88.15% avg_auc=92.38%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.328713 Test loss=0.364379 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.325236439704895
[5/24] Train loss=0.291719526052475
[10/24] Train loss=0.34907111525535583
[15/24] Train loss=0.34585094451904297
[20/24] Train loss=0.31889376044273376
Test set avg_accuracy=81.30% avg_sensitivity=89.43%, avg_specificity=78.22% avg_auc=90.45%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.328345 Test loss=0.487392 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3542701303958893
[5/24] Train loss=0.29925239086151123
[10/24] Train loss=0.37964504957199097
[15/24] Train loss=0.38158589601516724
[20/24] Train loss=0.3074631989002228
Test set avg_accuracy=86.20% avg_sensitivity=77.01%, avg_specificity=89.68% avg_auc=91.96%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.343599 Test loss=0.350443 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.317496120929718
[5/24] Train loss=0.29183706641197205
[10/24] Train loss=0.3672965466976166
[15/24] Train loss=0.35322198271751404
[20/24] Train loss=0.29815277457237244
Test set avg_accuracy=86.60% avg_sensitivity=69.43%, avg_specificity=93.11% avg_auc=91.19%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.320032 Test loss=0.338628 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3164185583591461
[5/24] Train loss=0.2693040072917938
[10/24] Train loss=0.3392842710018158
[15/24] Train loss=0.34520360827445984
[20/24] Train loss=0.2843015789985657
Test set avg_accuracy=87.49% avg_sensitivity=81.04%, avg_specificity=89.93% avg_auc=91.96%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.317020 Test loss=0.357244 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.31181782484054565
[5/24] Train loss=0.2770518660545349
[10/24] Train loss=0.3895219564437866
[15/24] Train loss=0.34132081270217896
[20/24] Train loss=0.29259052872657776
Test set avg_accuracy=86.99% avg_sensitivity=69.62%, avg_specificity=93.57% avg_auc=90.92%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.316232 Test loss=0.344924 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.29482871294021606
[5/24] Train loss=0.26120293140411377
[10/24] Train loss=0.35155901312828064
[15/24] Train loss=0.3218061029911041
[20/24] Train loss=0.2741873562335968
Test set avg_accuracy=86.50% avg_sensitivity=82.61%, avg_specificity=87.97% avg_auc=92.71%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.305277 Test loss=0.355449 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.30373695492744446
[5/24] Train loss=0.2647988498210907
[10/24] Train loss=0.3342902362346649
[15/24] Train loss=0.3141334652900696
[20/24] Train loss=0.2843872904777527
Test set avg_accuracy=87.51% avg_sensitivity=77.96%, avg_specificity=91.13% avg_auc=91.79%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.302500 Test loss=0.349159 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.29001185297966003
[5/24] Train loss=0.26248103380203247
[10/24] Train loss=0.3317500352859497
[15/24] Train loss=0.30613958835601807
[20/24] Train loss=0.29513806104660034
Test set avg_accuracy=88.19% avg_sensitivity=76.26%, avg_specificity=92.71% avg_auc=91.95%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.300505 Test loss=0.326777 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.28250783681869507
[5/24] Train loss=0.24971941113471985
[10/24] Train loss=0.313841313123703
[15/24] Train loss=0.3152790367603302
[20/24] Train loss=0.289083868265152
Test set avg_accuracy=81.78% avg_sensitivity=89.43%, avg_specificity=78.89% avg_auc=91.96%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.300578 Test loss=0.469117 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.30788901448249817
[5/24] Train loss=0.29286080598831177
[10/24] Train loss=0.3487963080406189
[15/24] Train loss=0.31139668822288513
[20/24] Train loss=0.26382336020469666
Test set avg_accuracy=87.98% avg_sensitivity=79.48%, avg_specificity=91.20% avg_auc=92.32%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.300957 Test loss=0.334958 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2911711037158966
[5/24] Train loss=0.24480418860912323
[10/24] Train loss=0.31182152032852173
[15/24] Train loss=0.28613218665122986
[20/24] Train loss=0.28326088190078735
Test set avg_accuracy=84.51% avg_sensitivity=87.54%, avg_specificity=83.36% avg_auc=92.44%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.300902 Test loss=0.422904 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2902657985687256
[5/24] Train loss=0.27036017179489136
[10/24] Train loss=0.3187231421470642
[15/24] Train loss=0.31723010540008545
[20/24] Train loss=0.3237670361995697
Test set avg_accuracy=88.48% avg_sensitivity=79.43%, avg_specificity=91.90% avg_auc=91.90%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.299633 Test loss=0.331597 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2893519103527069
[5/24] Train loss=0.24541115760803223
[10/24] Train loss=0.3251528739929199
[15/24] Train loss=0.3068363070487976
[20/24] Train loss=0.2817994952201843
Test set avg_accuracy=87.53% avg_sensitivity=84.31%, avg_specificity=88.74% avg_auc=92.41%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.294611 Test loss=0.350157 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2780073881149292
[5/24] Train loss=0.2716800272464752
[10/24] Train loss=0.3078497052192688
[15/24] Train loss=0.318255752325058
[20/24] Train loss=0.2860189974308014
Test set avg_accuracy=85.13% avg_sensitivity=88.15%, avg_specificity=83.99% avg_auc=91.99%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.289681 Test loss=0.426447 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.28011396527290344
[5/24] Train loss=0.24412904679775238
[10/24] Train loss=0.34189966320991516
[15/24] Train loss=0.30220484733581543
[20/24] Train loss=0.27324309945106506
Test set avg_accuracy=88.10% avg_sensitivity=78.39%, avg_specificity=91.78% avg_auc=91.69%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.291397 Test loss=0.352265 Current lr=[0.000224838296036774]

[0/24] Train loss=0.28758350014686584
[5/24] Train loss=0.2842843234539032
[10/24] Train loss=0.32110822200775146
[15/24] Train loss=0.3451802432537079
[20/24] Train loss=0.2902076244354248
Test set avg_accuracy=87.66% avg_sensitivity=80.38%, avg_specificity=90.41% avg_auc=91.89%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.301282 Test loss=0.342649 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.28814101219177246
[5/24] Train loss=0.25616469979286194
[10/24] Train loss=0.33561867475509644
[15/24] Train loss=0.2912042737007141
[20/24] Train loss=0.28950390219688416
Test set avg_accuracy=87.03% avg_sensitivity=81.66%, avg_specificity=89.07% avg_auc=91.97%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.295771 Test loss=0.372429 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2905864119529724
[5/24] Train loss=0.2701789140701294
[10/24] Train loss=0.32114434242248535
[15/24] Train loss=0.2938663065433502
[20/24] Train loss=0.24905195832252502
Test set avg_accuracy=85.56% avg_sensitivity=81.14%, avg_specificity=87.24% avg_auc=91.56%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.289365 Test loss=0.400856 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.26182883977890015
[5/24] Train loss=0.24950218200683594
[10/24] Train loss=0.29489099979400635
[15/24] Train loss=0.29521238803863525
[20/24] Train loss=0.24962058663368225
Test set avg_accuracy=87.49% avg_sensitivity=73.51%, avg_specificity=92.78% avg_auc=91.82%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.273325 Test loss=0.346227 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.261531263589859
[5/24] Train loss=0.2368355542421341
[10/24] Train loss=0.3066363036632538
[15/24] Train loss=0.29197707772254944
[20/24] Train loss=0.2567800283432007
Test set avg_accuracy=86.00% avg_sensitivity=68.29%, avg_specificity=92.71% avg_auc=90.11%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.269287 Test loss=0.370173 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2451627552509308
[5/24] Train loss=0.24029526114463806
[10/24] Train loss=0.2672061324119568
[15/24] Train loss=0.2859824299812317
[20/24] Train loss=0.25318285822868347
Test set avg_accuracy=85.34% avg_sensitivity=59.95%, avg_specificity=94.96% avg_auc=87.57%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.265327 Test loss=0.407752 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2522191107273102
[5/24] Train loss=0.24211753904819489
[10/24] Train loss=0.2746790647506714
[15/24] Train loss=0.28778940439224243
[20/24] Train loss=0.2507501542568207
Test set avg_accuracy=87.36% avg_sensitivity=70.00%, avg_specificity=93.93% avg_auc=90.72%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.264052 Test loss=0.340253 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.24465949833393097
[5/24] Train loss=0.2532944977283478
[10/24] Train loss=0.28337612748146057
[15/24] Train loss=0.27230533957481384
[20/24] Train loss=0.24491560459136963
Test set avg_accuracy=86.71% avg_sensitivity=78.77%, avg_specificity=89.71% avg_auc=91.99%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.263064 Test loss=0.359533 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.26372501254081726
[5/24] Train loss=0.24558693170547485
[10/24] Train loss=0.2707478702068329
[15/24] Train loss=0.2835560739040375
[20/24] Train loss=0.24644365906715393
Test set avg_accuracy=87.43% avg_sensitivity=79.48%, avg_specificity=90.45% avg_auc=92.51%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.263363 Test loss=0.337802 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.24637779593467712
[5/24] Train loss=0.22105199098587036
[10/24] Train loss=0.2727571129798889
[15/24] Train loss=0.2835756540298462
[20/24] Train loss=0.2334890365600586
Test set avg_accuracy=88.03% avg_sensitivity=70.85%, avg_specificity=94.54% avg_auc=91.85%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.253671 Test loss=0.323568 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2395276129245758
[5/24] Train loss=0.21961671113967896
[10/24] Train loss=0.26051923632621765
[15/24] Train loss=0.25489795207977295
[20/24] Train loss=0.24126312136650085
Test set avg_accuracy=88.19% avg_sensitivity=73.98%, avg_specificity=93.57% avg_auc=91.66%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.245770 Test loss=0.327218 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.23028039932250977
[5/24] Train loss=0.23571322858333588
[10/24] Train loss=0.2565303444862366
[15/24] Train loss=0.26605260372161865
[20/24] Train loss=0.2488715499639511
Test set avg_accuracy=88.11% avg_sensitivity=79.34%, avg_specificity=91.44% avg_auc=92.38%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.249898 Test loss=0.325494 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.23495829105377197
[5/24] Train loss=0.21777856349945068
[10/24] Train loss=0.26270461082458496
[15/24] Train loss=0.2918662130832672
[20/24] Train loss=0.2577749788761139
Test set avg_accuracy=87.03% avg_sensitivity=67.77%, avg_specificity=94.33% avg_auc=89.55%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.252112 Test loss=0.375267 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2568647563457489
[5/24] Train loss=0.23961685597896576
[10/24] Train loss=0.27126216888427734
[15/24] Train loss=0.26093485951423645
[20/24] Train loss=0.24629606306552887
Test set avg_accuracy=88.28% avg_sensitivity=79.38%, avg_specificity=91.65% avg_auc=92.84%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.254048 Test loss=0.316099 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.23436155915260315
[5/24] Train loss=0.21896347403526306
[10/24] Train loss=0.2682684063911438
[15/24] Train loss=0.2611662447452545
[20/24] Train loss=0.22710466384887695
Test set avg_accuracy=88.28% avg_sensitivity=71.94%, avg_specificity=94.47% avg_auc=91.69%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.244038 Test loss=0.339962 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2246493399143219
[5/24] Train loss=0.22653056681156158
[10/24] Train loss=0.24195395410060883
[15/24] Train loss=0.24470070004463196
[20/24] Train loss=0.22471968829631805
Test set avg_accuracy=87.90% avg_sensitivity=81.23%, avg_specificity=90.43% avg_auc=92.11%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.234363 Test loss=0.350872 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2333373874425888
[5/24] Train loss=0.21178916096687317
[10/24] Train loss=0.2411998212337494
[15/24] Train loss=0.24071484804153442
[20/24] Train loss=0.22031401097774506
Test set avg_accuracy=88.07% avg_sensitivity=79.81%, avg_specificity=91.20% avg_auc=92.71%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.227608 Test loss=0.338338 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.22400473058223724
[5/24] Train loss=0.19655318558216095
[10/24] Train loss=0.22769829630851746
[15/24] Train loss=0.23641765117645264
[20/24] Train loss=0.21763068437576294
Test set avg_accuracy=87.45% avg_sensitivity=83.93%, avg_specificity=88.78% avg_auc=92.71%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.219913 Test loss=0.372938 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.212993785738945
[5/24] Train loss=0.19549338519573212
[10/24] Train loss=0.2259300798177719
[15/24] Train loss=0.22695346176624298
[20/24] Train loss=0.2160583883523941
Test set avg_accuracy=88.54% avg_sensitivity=79.62%, avg_specificity=91.92% avg_auc=92.81%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.218236 Test loss=0.329349 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.20979689061641693
[5/24] Train loss=0.18755342066287994
[10/24] Train loss=0.2228306084871292
[15/24] Train loss=0.22203917801380157
[20/24] Train loss=0.2224760800600052
Test set avg_accuracy=87.27% avg_sensitivity=84.12%, avg_specificity=88.46% avg_auc=91.97%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.217537 Test loss=0.405899 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.21613022685050964
[5/24] Train loss=0.1939680427312851
[10/24] Train loss=0.22412943840026855
[15/24] Train loss=0.23037025332450867
[20/24] Train loss=0.2131432294845581
Test set avg_accuracy=87.67% avg_sensitivity=84.41%, avg_specificity=88.90% avg_auc=92.65%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.216710 Test loss=0.365394 Current lr=[0.000134135431043539]

[0/24] Train loss=0.20789258182048798
[5/24] Train loss=0.18823207914829254
[10/24] Train loss=0.24000944197177887
[15/24] Train loss=0.2283967286348343
[20/24] Train loss=0.2052190899848938
Test set avg_accuracy=88.06% avg_sensitivity=79.76%, avg_specificity=91.20% avg_auc=92.60%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.214443 Test loss=0.340076 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1983284056186676
[5/24] Train loss=0.20913049578666687
[10/24] Train loss=0.22106505930423737
[15/24] Train loss=0.231248140335083
[20/24] Train loss=0.2122730016708374
Test set avg_accuracy=87.90% avg_sensitivity=81.47%, avg_specificity=90.34% avg_auc=92.86%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.215769 Test loss=0.334885 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.20291033387184143
[5/24] Train loss=0.19401897490024567
[10/24] Train loss=0.21180376410484314
[15/24] Train loss=0.22900795936584473
[20/24] Train loss=0.20917139947414398
Test set avg_accuracy=88.01% avg_sensitivity=81.75%, avg_specificity=90.38% avg_auc=92.89%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.208874 Test loss=0.346794 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.2097969502210617
[5/24] Train loss=0.18847030401229858
[10/24] Train loss=0.20977415144443512
[15/24] Train loss=0.21768829226493835
[20/24] Train loss=0.20553675293922424
Test set avg_accuracy=87.51% avg_sensitivity=85.40%, avg_specificity=88.31% avg_auc=92.75%
Best model saved!! Metric=27.982657597651325!!
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.206140 Test loss=0.377242 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.19352440536022186
[5/24] Train loss=0.19024305045604706
[10/24] Train loss=0.21766842901706696
[15/24] Train loss=0.22379504144191742
[20/24] Train loss=0.19983375072479248
Test set avg_accuracy=86.41% avg_sensitivity=86.40%, avg_specificity=86.41% avg_auc=92.29%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.205494 Test loss=0.421513 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1978396773338318
[5/24] Train loss=0.19038313627243042
[10/24] Train loss=0.20958569645881653
[15/24] Train loss=0.22679951786994934
[20/24] Train loss=0.2005409598350525
Test set avg_accuracy=87.10% avg_sensitivity=82.94%, avg_specificity=88.67% avg_auc=92.67%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.203141 Test loss=0.369625 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.18924422562122345
[5/24] Train loss=0.19139589369297028
[10/24] Train loss=0.21857239305973053
[15/24] Train loss=0.22149713337421417
[20/24] Train loss=0.20343120396137238
Test set avg_accuracy=87.75% avg_sensitivity=80.14%, avg_specificity=90.63% avg_auc=92.51%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.202781 Test loss=0.355442 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.20060768723487854
[5/24] Train loss=0.18079887330532074
[10/24] Train loss=0.21336394548416138
[15/24] Train loss=0.21409972012043
[20/24] Train loss=0.20125500857830048
Test set avg_accuracy=87.55% avg_sensitivity=83.93%, avg_specificity=88.92% avg_auc=92.89%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.201981 Test loss=0.371724 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.19034746289253235
[5/24] Train loss=0.18605321645736694
[10/24] Train loss=0.20965805649757385
[15/24] Train loss=0.21578124165534973
[20/24] Train loss=0.19812916219234467
Test set avg_accuracy=87.67% avg_sensitivity=76.11%, avg_specificity=92.05% avg_auc=92.36%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.197823 Test loss=0.343969 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.1913314163684845
[5/24] Train loss=0.18245118856430054
[10/24] Train loss=0.21061329543590546
[15/24] Train loss=0.2186105102300644
[20/24] Train loss=0.1916331797838211
Test set avg_accuracy=87.53% avg_sensitivity=79.43%, avg_specificity=90.59% avg_auc=92.35%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.197024 Test loss=0.344208 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.19386865198612213
[5/24] Train loss=0.17889608442783356
[10/24] Train loss=0.19942286610603333
[15/24] Train loss=0.20686452090740204
[20/24] Train loss=0.19114063680171967
Test set avg_accuracy=87.77% avg_sensitivity=83.18%, avg_specificity=89.52% avg_auc=92.72%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.192468 Test loss=0.364010 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.179625004529953
[5/24] Train loss=0.16828423738479614
[10/24] Train loss=0.19009068608283997
[15/24] Train loss=0.2045670598745346
[20/24] Train loss=0.1933511197566986
Test set avg_accuracy=87.75% avg_sensitivity=79.43%, avg_specificity=90.90% avg_auc=92.31%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.188153 Test loss=0.356542 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.17799979448318481
[5/24] Train loss=0.174801304936409
[10/24] Train loss=0.19337451457977295
[15/24] Train loss=0.20718154311180115
[20/24] Train loss=0.18819701671600342
Test set avg_accuracy=86.97% avg_sensitivity=84.60%, avg_specificity=87.86% avg_auc=92.62%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.187741 Test loss=0.378079 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.17727792263031006
[5/24] Train loss=0.17164936661720276
[10/24] Train loss=0.19509738683700562
[15/24] Train loss=0.2001786082983017
[20/24] Train loss=0.20094484090805054
Test set avg_accuracy=87.60% avg_sensitivity=82.51%, avg_specificity=89.53% avg_auc=92.84%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.187112 Test loss=0.350544 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1765541136264801
[5/24] Train loss=0.17090213298797607
[10/24] Train loss=0.19829528033733368
[15/24] Train loss=0.20335744321346283
[20/24] Train loss=0.19025619328022003
Test set avg_accuracy=87.51% avg_sensitivity=78.48%, avg_specificity=90.93% avg_auc=92.22%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.186839 Test loss=0.348430 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1717192381620407
[5/24] Train loss=0.187351793050766
[10/24] Train loss=0.19611410796642303
[15/24] Train loss=0.19789279997348785
[20/24] Train loss=0.1846173107624054
Test set avg_accuracy=87.79% avg_sensitivity=77.39%, avg_specificity=91.72% avg_auc=92.23%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.186067 Test loss=0.354279 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1816839575767517
[5/24] Train loss=0.1777566522359848
[10/24] Train loss=0.18420284986495972
[15/24] Train loss=0.1934918761253357
[20/24] Train loss=0.1839091181755066
Test set avg_accuracy=88.03% avg_sensitivity=80.24%, avg_specificity=90.99% avg_auc=92.78%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.183693 Test loss=0.338955 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.17277111113071442
[5/24] Train loss=0.1603139042854309
[10/24] Train loss=0.18959428369998932
[15/24] Train loss=0.19284303486347198
[20/24] Train loss=0.17974507808685303
Test set avg_accuracy=87.38% avg_sensitivity=79.67%, avg_specificity=90.31% avg_auc=92.39%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.181047 Test loss=0.357409 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1703208088874817
[5/24] Train loss=0.15856711566448212
[10/24] Train loss=0.19133269786834717
[15/24] Train loss=0.1948728710412979
[20/24] Train loss=0.17868098616600037
Test set avg_accuracy=88.26% avg_sensitivity=78.91%, avg_specificity=91.80% avg_auc=92.66%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.178143 Test loss=0.339229 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.17768053710460663
[5/24] Train loss=0.1637166440486908
[10/24] Train loss=0.18247391283512115
[15/24] Train loss=0.18995903432369232
[20/24] Train loss=0.1809791773557663
Test set avg_accuracy=87.60% avg_sensitivity=81.04%, avg_specificity=90.09% avg_auc=92.66%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.177726 Test loss=0.351422 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1679690033197403
[5/24] Train loss=0.16038981080055237
[10/24] Train loss=0.18243424594402313
[15/24] Train loss=0.1887127012014389
[20/24] Train loss=0.1822526752948761
Test set avg_accuracy=88.01% avg_sensitivity=81.37%, avg_specificity=90.52% avg_auc=92.61%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.177685 Test loss=0.350763 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.17524541914463043
[5/24] Train loss=0.16040076315402985
[10/24] Train loss=0.1832653135061264
[15/24] Train loss=0.18410909175872803
[20/24] Train loss=0.1773185282945633
Test set avg_accuracy=88.28% avg_sensitivity=82.32%, avg_specificity=90.54% avg_auc=92.84%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.176734 Test loss=0.343626 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1701946258544922
[5/24] Train loss=0.1604304015636444
[10/24] Train loss=0.18305853009223938
[15/24] Train loss=0.1876085102558136
[20/24] Train loss=0.175774946808815
Test set avg_accuracy=87.92% avg_sensitivity=81.47%, avg_specificity=90.36% avg_auc=92.74%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.173862 Test loss=0.346589 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1631826013326645
[5/24] Train loss=0.15418711304664612
[10/24] Train loss=0.17392192780971527
[15/24] Train loss=0.18754233419895172
[20/24] Train loss=0.17161427438259125
Test set avg_accuracy=88.02% avg_sensitivity=79.81%, avg_specificity=91.13% avg_auc=92.72%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.171693 Test loss=0.335251 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.16830454766750336
[5/24] Train loss=0.15775635838508606
[10/24] Train loss=0.17329975962638855
[15/24] Train loss=0.18572090566158295
[20/24] Train loss=0.17240047454833984
Test set avg_accuracy=88.66% avg_sensitivity=79.95%, avg_specificity=91.96% avg_auc=92.66%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.170473 Test loss=0.336477 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1626112461090088
[5/24] Train loss=0.1506350338459015
[10/24] Train loss=0.17371897399425507
[15/24] Train loss=0.17669883370399475
[20/24] Train loss=0.1693435162305832
Test set avg_accuracy=88.41% avg_sensitivity=79.00%, avg_specificity=91.97% avg_auc=92.51%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.167788 Test loss=0.333088 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.15965348482131958
[5/24] Train loss=0.15659703314304352
[10/24] Train loss=0.17107881605625153
[15/24] Train loss=0.17695510387420654
[20/24] Train loss=0.17320525646209717
Test set avg_accuracy=88.28% avg_sensitivity=80.85%, avg_specificity=91.10% avg_auc=92.75%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.168728 Test loss=0.337481 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.15821930766105652
[5/24] Train loss=0.15254908800125122
[10/24] Train loss=0.1713697463274002
[15/24] Train loss=0.17750009894371033
[20/24] Train loss=0.17109936475753784
Test set avg_accuracy=87.96% avg_sensitivity=82.46%, avg_specificity=90.04% avg_auc=92.90%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.165792 Test loss=0.344250 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.15888544917106628
[5/24] Train loss=0.15562713146209717
[10/24] Train loss=0.17258311808109283
[15/24] Train loss=0.17671436071395874
[20/24] Train loss=0.1698165237903595
Test set avg_accuracy=87.92% avg_sensitivity=81.23%, avg_specificity=90.45% avg_auc=93.06%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.166642 Test loss=0.337830 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.15950794517993927
[5/24] Train loss=0.14975255727767944
[10/24] Train loss=0.17307323217391968
[15/24] Train loss=0.17703823745250702
[20/24] Train loss=0.1741400957107544
Test set avg_accuracy=88.29% avg_sensitivity=81.99%, avg_specificity=90.68% avg_auc=92.94%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.166785 Test loss=0.339686 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.15666279196739197
[5/24] Train loss=0.154110386967659
[10/24] Train loss=0.17758981883525848
[15/24] Train loss=0.17393329739570618
[20/24] Train loss=0.17628321051597595
Test set avg_accuracy=88.41% avg_sensitivity=79.95%, avg_specificity=91.62% avg_auc=92.72%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.167073 Test loss=0.334185 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.16329623758792877
[5/24] Train loss=0.1472204625606537
[10/24] Train loss=0.1772528886795044
[15/24] Train loss=0.17450562119483948
[20/24] Train loss=0.16723546385765076
Test set avg_accuracy=87.96% avg_sensitivity=81.04%, avg_specificity=90.57% avg_auc=92.98%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.165957 Test loss=0.340739 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.16441574692726135
[5/24] Train loss=0.14852453768253326
[10/24] Train loss=0.16939693689346313
[15/24] Train loss=0.17460662126541138
[20/24] Train loss=0.1643325239419937
Test set avg_accuracy=88.32% avg_sensitivity=81.23%, avg_specificity=91.01% avg_auc=92.97%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.164798 Test loss=0.336755 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1596432328224182
[5/24] Train loss=0.14744892716407776
[10/24] Train loss=0.16822320222854614
[15/24] Train loss=0.170359268784523
[20/24] Train loss=0.1602604240179062
Test set avg_accuracy=88.32% avg_sensitivity=81.28%, avg_specificity=90.99% avg_auc=93.00%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.162010 Test loss=0.337536 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.151475727558136
[5/24] Train loss=0.14774467051029205
[10/24] Train loss=0.16572612524032593
[15/24] Train loss=0.17062343657016754
[20/24] Train loss=0.16240331530570984
Test set avg_accuracy=88.22% avg_sensitivity=81.18%, avg_specificity=90.88% avg_auc=92.94%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.160709 Test loss=0.336772 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.15481939911842346
[5/24] Train loss=0.14740075170993805
[10/24] Train loss=0.1668369323015213
[15/24] Train loss=0.1708933264017105
[20/24] Train loss=0.15888260304927826
Test set avg_accuracy=88.39% avg_sensitivity=80.47%, avg_specificity=91.38% avg_auc=92.90%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.160398 Test loss=0.335271 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.15489016473293304
[5/24] Train loss=0.14393065869808197
[10/24] Train loss=0.16661037504673004
[15/24] Train loss=0.17000672221183777
[20/24] Train loss=0.1662714183330536
Test set avg_accuracy=88.39% avg_sensitivity=80.43%, avg_specificity=91.40% avg_auc=92.90%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.159919 Test loss=0.335952 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.15370342135429382
[5/24] Train loss=0.14799915254116058
[10/24] Train loss=0.16473938524723053
[15/24] Train loss=0.16820093989372253
[20/24] Train loss=0.16393141448497772
Test set avg_accuracy=88.45% avg_sensitivity=81.28%, avg_specificity=91.17% avg_auc=92.95%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.159493 Test loss=0.337973 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.15393562614917755
[5/24] Train loss=0.14609242975711823
[10/24] Train loss=0.16711106896400452
[15/24] Train loss=0.16802354156970978
[20/24] Train loss=0.16519945859909058
Test set avg_accuracy=88.49% avg_sensitivity=81.28%, avg_specificity=91.22% avg_auc=92.98%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.159667 Test loss=0.335225 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1529814451932907
[5/24] Train loss=0.14437758922576904
[10/24] Train loss=0.1699780374765396
[15/24] Train loss=0.16962698101997375
[20/24] Train loss=0.16195952892303467
Test set avg_accuracy=88.46% avg_sensitivity=81.47%, avg_specificity=91.11% avg_auc=92.98%
Best model saved!! Metric=28.02551891444803!!
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.159086 Test loss=0.336814 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.15349552035331726
[5/24] Train loss=0.14532847702503204
[10/24] Train loss=0.1665782481431961
[15/24] Train loss=0.17045751214027405
[20/24] Train loss=0.15955200791358948
Test set avg_accuracy=88.57% avg_sensitivity=81.61%, avg_specificity=91.20% avg_auc=92.99%
Best model saved!! Metric=28.37101310585369!!
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.159453 Test loss=0.336025 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.15260037779808044
[5/24] Train loss=0.14517724514007568
[10/24] Train loss=0.16836361587047577
[15/24] Train loss=0.16795845329761505
[20/24] Train loss=0.16185224056243896
Test set avg_accuracy=88.29% avg_sensitivity=80.66%, avg_specificity=91.18% avg_auc=92.97%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.158794 Test loss=0.336891 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.15370160341262817
[5/24] Train loss=0.1458437591791153
[10/24] Train loss=0.16666123270988464
[15/24] Train loss=0.168769970536232
[20/24] Train loss=0.16322287917137146
Test set avg_accuracy=88.50% avg_sensitivity=80.95%, avg_specificity=91.36% avg_auc=92.93%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.158685 Test loss=0.337071 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.15232741832733154
[5/24] Train loss=0.14297828078269958
[10/24] Train loss=0.1649542897939682
[15/24] Train loss=0.16593539714813232
[20/24] Train loss=0.1619357168674469
Test set avg_accuracy=88.44% avg_sensitivity=80.85%, avg_specificity=91.31% avg_auc=92.92%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.158164 Test loss=0.337342 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1541028469800949
[5/24] Train loss=0.14516884088516235
[10/24] Train loss=0.16592445969581604
[15/24] Train loss=0.16945642232894897
[20/24] Train loss=0.16078127920627594
Test set avg_accuracy=88.44% avg_sensitivity=80.85%, avg_specificity=91.31% avg_auc=92.93%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.158373 Test loss=0.337208 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.14988073706626892
[5/24] Train loss=0.1399046629667282
[10/24] Train loss=0.164041206240654
[15/24] Train loss=0.1627175211906433
[20/24] Train loss=0.16398531198501587
Test set avg_accuracy=88.39% avg_sensitivity=80.66%, avg_specificity=91.31% avg_auc=92.93%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.157696 Test loss=0.337254 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.15197058022022247
[5/24] Train loss=0.14444929361343384
[10/24] Train loss=0.1661251336336136
[15/24] Train loss=0.16787411272525787
[20/24] Train loss=0.16102644801139832
Test set avg_accuracy=88.45% avg_sensitivity=81.00%, avg_specificity=91.27% avg_auc=92.96%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.158130 Test loss=0.337015 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1518583446741104
[5/24] Train loss=0.14580775797367096
[10/24] Train loss=0.16608919203281403
[15/24] Train loss=0.16927863657474518
[20/24] Train loss=0.16393515467643738
Test set avg_accuracy=88.45% avg_sensitivity=81.00%, avg_specificity=91.27% avg_auc=92.95%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.158714 Test loss=0.337263 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.15154041349887848
[5/24] Train loss=0.14288996160030365
[10/24] Train loss=0.16517360508441925
[15/24] Train loss=0.1671389937400818
[20/24] Train loss=0.16084539890289307
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=88.52% avg_sensitivity=81.23%, avg_specificity=91.27% avg_auc=92.96%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.157994 Test loss=0.337488 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=88.57% sen=81.61%, spe=91.20%, auc=92.99%!
Fold[3] Avg_overlap=0.69%(0.2394717116815835)
[0/24] Train loss=1.4640986919403076
[5/24] Train loss=1.4560527801513672
[10/24] Train loss=1.4539004564285278
[15/24] Train loss=1.4291539192199707
[20/24] Train loss=1.3855739831924438
Test set avg_accuracy=62.70% avg_sensitivity=68.32%, avg_specificity=60.71% avg_auc=61.18%
Best model saved!! Metric=-73.09297437434765!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=1.440284 Test loss=0.684231 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.3913780450820923
[5/24] Train loss=1.3938523530960083
[10/24] Train loss=1.3831181526184082
[15/24] Train loss=1.3499892950057983
[20/24] Train loss=1.330909013748169
Test set avg_accuracy=68.37% avg_sensitivity=77.06%, avg_specificity=65.31% avg_auc=73.24%
Best model saved!! Metric=-42.014663146421384!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=1.368999 Test loss=0.632331 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3108266592025757
[5/24] Train loss=1.3229241371154785
[10/24] Train loss=1.3271678686141968
[15/24] Train loss=1.2838901281356812
[20/24] Train loss=1.2689799070358276
Test set avg_accuracy=71.13% avg_sensitivity=79.71%, avg_specificity=68.11% avg_auc=79.00%
Best model saved!! Metric=-28.049961318232633!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=1.301507 Test loss=0.598320 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.2405540943145752
[5/24] Train loss=1.2605006694793701
[10/24] Train loss=1.2860400676727295
[15/24] Train loss=1.2099305391311646
[20/24] Train loss=1.187933087348938
Test set avg_accuracy=72.45% avg_sensitivity=85.01%, avg_specificity=68.02% avg_auc=81.90%
Best model saved!! Metric=-18.61880160300639!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=1.235035 Test loss=0.575359 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.1780798435211182
[5/24] Train loss=1.1856364011764526
[10/24] Train loss=1.2218003273010254
[15/24] Train loss=1.152527928352356
[20/24] Train loss=1.1156656742095947
Test set avg_accuracy=73.91% avg_sensitivity=86.66%, avg_specificity=69.41% avg_auc=83.89%
Best model saved!! Metric=-12.130231143122757!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=1.164312 Test loss=0.557838 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.093495488166809
[5/24] Train loss=1.1113121509552002
[10/24] Train loss=1.1725434064865112
[15/24] Train loss=1.0987476110458374
[20/24] Train loss=1.0556639432907104
Test set avg_accuracy=74.44% avg_sensitivity=89.11%, avg_specificity=69.27% avg_auc=85.72%
Best model saved!! Metric=-7.463234884005217!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=1.102772 Test loss=0.543686 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.0288020372390747
[5/24] Train loss=1.0545923709869385
[10/24] Train loss=1.125266671180725
[15/24] Train loss=1.0440603494644165
[20/24] Train loss=0.9885678887367249
Test set avg_accuracy=77.08% avg_sensitivity=88.16%, avg_specificity=73.18% avg_auc=87.18%
Best model saved!! Metric=-0.4016566949840694!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=1.042856 Test loss=0.515176 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9738455414772034
[5/24] Train loss=0.9770147204399109
[10/24] Train loss=1.0518746376037598
[15/24] Train loss=0.9727998971939087
[20/24] Train loss=0.9481943845748901
Test set avg_accuracy=78.37% avg_sensitivity=88.26%, avg_specificity=74.89% avg_auc=88.40%
Best model saved!! Metric=3.921379221547639!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.983816 Test loss=0.492773 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.9152628779411316
[5/24] Train loss=0.9268934726715088
[10/24] Train loss=1.0133675336837769
[15/24] Train loss=0.9100273847579956
[20/24] Train loss=0.8941288590431213
Test set avg_accuracy=80.91% avg_sensitivity=88.21%, avg_specificity=78.34% avg_auc=89.43%
Best model saved!! Metric=10.884193923629383!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.932178 Test loss=0.465469 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8552895784378052
[5/24] Train loss=0.8587998151779175
[10/24] Train loss=0.9555162191390991
[15/24] Train loss=0.8747479319572449
[20/24] Train loss=0.8370398879051208
Test set avg_accuracy=81.80% avg_sensitivity=87.41%, avg_specificity=79.82% avg_auc=90.16%
Best model saved!! Metric=13.187615269942498!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.882336 Test loss=0.446558 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.828230619430542
[5/24] Train loss=0.8201265335083008
[10/24] Train loss=0.8896375298500061
[15/24] Train loss=0.8360412120819092
[20/24] Train loss=0.801497757434845
Test set avg_accuracy=83.12% avg_sensitivity=85.06%, avg_specificity=82.44% avg_auc=90.66%
Best model saved!! Metric=15.28502018360426!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.841208 Test loss=0.416587 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.7785695195198059
[5/24] Train loss=0.7774803638458252
[10/24] Train loss=0.8586943745613098
[15/24] Train loss=0.8054242730140686
[20/24] Train loss=0.7589400410652161
Test set avg_accuracy=84.05% avg_sensitivity=85.51%, avg_specificity=83.54% avg_auc=91.18%
Best model saved!! Metric=18.274710801597564!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.805477 Test loss=0.401914 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7614421248435974
[5/24] Train loss=0.7370157241821289
[10/24] Train loss=0.8438576459884644
[15/24] Train loss=0.7679982781410217
[20/24] Train loss=0.7401948571205139
Test set avg_accuracy=85.31% avg_sensitivity=83.96%, avg_specificity=85.79% avg_auc=91.54%
Best model saved!! Metric=20.595848464876553!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.774746 Test loss=0.374943 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.7279759049415588
[5/24] Train loss=0.7084519863128662
[10/24] Train loss=0.8092532753944397
[15/24] Train loss=0.7384969592094421
[20/24] Train loss=0.7010690569877625
Test set avg_accuracy=85.66% avg_sensitivity=84.46%, avg_specificity=86.09% avg_auc=91.86%
Best model saved!! Metric=22.074026737814194!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.745651 Test loss=0.363019 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.6985533833503723
[5/24] Train loss=0.6718820929527283
[10/24] Train loss=0.7913777828216553
[15/24] Train loss=0.7150927782058716
[20/24] Train loss=0.6824578046798706
Test set avg_accuracy=85.99% avg_sensitivity=84.01%, avg_specificity=86.69% avg_auc=92.17%
Best model saved!! Metric=22.857885051465274!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.722027 Test loss=0.356325 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.671567976474762
[5/24] Train loss=0.6558683514595032
[10/24] Train loss=0.758350133895874
[15/24] Train loss=0.6929103136062622
[20/24] Train loss=0.651790976524353
Test set avg_accuracy=85.94% avg_sensitivity=85.26%, avg_specificity=86.18% avg_auc=92.54%
Best model saved!! Metric=23.908516780745046!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.698190 Test loss=0.356367 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6546192765235901
[5/24] Train loss=0.6520795822143555
[10/24] Train loss=0.7374566793441772
[15/24] Train loss=0.6853013634681702
[20/24] Train loss=0.6394782066345215
Test set avg_accuracy=85.46% avg_sensitivity=86.76%, avg_specificity=85.00% avg_auc=92.74%
Best model saved!! Metric=23.94980278490246!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.681050 Test loss=0.359203 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.6254543662071228
[5/24] Train loss=0.6306933164596558
[10/24] Train loss=0.7287211418151855
[15/24] Train loss=0.6873804330825806
[20/24] Train loss=0.6036974787712097
Test set avg_accuracy=85.14% avg_sensitivity=88.11%, avg_specificity=84.10% avg_auc=93.04%
Best model saved!! Metric=24.391873553752916!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.664099 Test loss=0.363337 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.6209419965744019
[5/24] Train loss=0.6138672232627869
[10/24] Train loss=0.6899072527885437
[15/24] Train loss=0.6628233194351196
[20/24] Train loss=0.6113606095314026
Test set avg_accuracy=85.60% avg_sensitivity=87.06%, avg_specificity=85.09% avg_auc=93.07%
Best model saved!! Metric=24.81152725577475!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.650470 Test loss=0.353426 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5950688123703003
[5/24] Train loss=0.6094710230827332
[10/24] Train loss=0.6819271445274353
[15/24] Train loss=0.6477496027946472
[20/24] Train loss=0.5848878622055054
Test set avg_accuracy=85.96% avg_sensitivity=87.16%, avg_specificity=85.54% avg_auc=93.15%
Best model saved!! Metric=25.81072900801975!!
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.632240 Test loss=0.349248 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5992059111595154
[5/24] Train loss=0.5906795859336853
[10/24] Train loss=0.6873682141304016
[15/24] Train loss=0.6290757060050964
[20/24] Train loss=0.564370334148407
Test set avg_accuracy=84.65% avg_sensitivity=88.21%, avg_specificity=83.39% avg_auc=93.25%
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.622388 Test loss=0.365935 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5702288746833801
[5/24] Train loss=0.5660844445228577
[10/24] Train loss=0.6611495018005371
[15/24] Train loss=0.6088249087333679
[20/24] Train loss=0.550590991973877
Test set avg_accuracy=86.07% avg_sensitivity=87.41%, avg_specificity=85.60% avg_auc=93.49%
Best model saved!! Metric=26.561702047868934!!
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.603409 Test loss=0.344980 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5709754228591919
[5/24] Train loss=0.5620695948600769
[10/24] Train loss=0.6614214777946472
[15/24] Train loss=0.5985170602798462
[20/24] Train loss=0.5437866449356079
Test set avg_accuracy=85.05% avg_sensitivity=89.06%, avg_specificity=83.64% avg_auc=93.60%
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.595208 Test loss=0.360403 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5592344403266907
[5/24] Train loss=0.5247133374214172
[10/24] Train loss=0.6311962604522705
[15/24] Train loss=0.5894432663917542
[20/24] Train loss=0.5436559915542603
Test set avg_accuracy=87.23% avg_sensitivity=86.16%, avg_specificity=87.60% avg_auc=93.57%
Best model saved!! Metric=28.561657058725217!!
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.578877 Test loss=0.329271 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5641730427742004
[5/24] Train loss=0.5240107774734497
[10/24] Train loss=0.6320782899856567
[15/24] Train loss=0.573373019695282
[20/24] Train loss=0.5234273076057434
Test set avg_accuracy=81.72% avg_sensitivity=90.85%, avg_specificity=78.50% avg_auc=93.08%
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.564801 Test loss=0.423213 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5430727005004883
[5/24] Train loss=0.5098593235015869
[10/24] Train loss=0.6013447642326355
[15/24] Train loss=0.5736788511276245
[20/24] Train loss=0.5045130252838135
Test set avg_accuracy=83.45% avg_sensitivity=90.40%, avg_specificity=81.00% avg_auc=93.45%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.555759 Test loss=0.392136 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5265210866928101
[5/24] Train loss=0.4769378900527954
[10/24] Train loss=0.6259664297103882
[15/24] Train loss=0.5556961297988892
[20/24] Train loss=0.501133143901825
Test set avg_accuracy=86.52% avg_sensitivity=87.96%, avg_specificity=86.02% avg_auc=93.45%
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.540100 Test loss=0.347618 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.5228610038757324
[5/24] Train loss=0.49885156750679016
[10/24] Train loss=0.6025126576423645
[15/24] Train loss=0.5531531572341919
[20/24] Train loss=0.4894968867301941
Test set avg_accuracy=86.85% avg_sensitivity=84.31%, avg_specificity=87.74% avg_auc=93.44%
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.534125 Test loss=0.317069 Current lr=[0.000210185142098938]

[0/24] Train loss=0.5093654990196228
[5/24] Train loss=0.4804334342479706
[10/24] Train loss=0.624194324016571
[15/24] Train loss=0.5384044051170349
[20/24] Train loss=0.48598572611808777
Test set avg_accuracy=87.32% avg_sensitivity=81.46%, avg_specificity=89.38% avg_auc=92.33%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.525619 Test loss=0.318324 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.5102149248123169
[5/24] Train loss=0.45674461126327515
[10/24] Train loss=0.5900536775588989
[15/24] Train loss=0.5255967378616333
[20/24] Train loss=0.4701201915740967
Test set avg_accuracy=87.98% avg_sensitivity=86.41%, avg_specificity=88.54% avg_auc=93.40%
Best model saved!! Metric=30.320739225523937!!
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.514953 Test loss=0.323445 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.47218164801597595
[5/24] Train loss=0.4755675196647644
[10/24] Train loss=0.6024429202079773
[15/24] Train loss=0.5270673036575317
[20/24] Train loss=0.4695715308189392
Test set avg_accuracy=82.04% avg_sensitivity=91.05%, avg_specificity=78.87% avg_auc=92.57%
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.513937 Test loss=0.439488 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.5035961866378784
[5/24] Train loss=0.49871140718460083
[10/24] Train loss=0.5778840184211731
[15/24] Train loss=0.5091255307197571
[20/24] Train loss=0.4809822738170624
Test set avg_accuracy=86.94% avg_sensitivity=88.81%, avg_specificity=86.28% avg_auc=92.23%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.497895 Test loss=0.384489 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.47542545199394226
[5/24] Train loss=0.4305165410041809
[10/24] Train loss=0.5350845456123352
[15/24] Train loss=0.5037577748298645
[20/24] Train loss=0.46117958426475525
Test set avg_accuracy=87.28% avg_sensitivity=81.11%, avg_specificity=89.45% avg_auc=92.68%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.482325 Test loss=0.319112 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.4651906490325928
[5/24] Train loss=0.4277970790863037
[10/24] Train loss=0.5195381045341492
[15/24] Train loss=0.49333733320236206
[20/24] Train loss=0.44822758436203003
Test set avg_accuracy=85.61% avg_sensitivity=88.71%, avg_specificity=84.52% avg_auc=93.04%
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.477586 Test loss=0.359041 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.43994754552841187
[5/24] Train loss=0.42584922909736633
[10/24] Train loss=0.5216692090034485
[15/24] Train loss=0.5118899345397949
[20/24] Train loss=0.44447022676467896
Test set avg_accuracy=87.41% avg_sensitivity=85.86%, avg_specificity=87.96% avg_auc=93.64%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.477908 Test loss=0.318443 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4513379633426666
[5/24] Train loss=0.4059401750564575
[10/24] Train loss=0.48557761311531067
[15/24] Train loss=0.4861281216144562
[20/24] Train loss=0.43513160943984985
Test set avg_accuracy=86.91% avg_sensitivity=78.61%, avg_specificity=89.84% avg_auc=91.88%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.463688 Test loss=0.331816 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4453049600124359
[5/24] Train loss=0.3966952860355377
[10/24] Train loss=0.5224575400352478
[15/24] Train loss=0.5023151636123657
[20/24] Train loss=0.47173136472702026
Test set avg_accuracy=88.11% avg_sensitivity=77.36%, avg_specificity=91.90% avg_auc=92.16%
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.464055 Test loss=0.311141 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.4276403784751892
[5/24] Train loss=0.4021143317222595
[10/24] Train loss=0.48643797636032104
[15/24] Train loss=0.4847294092178345
[20/24] Train loss=0.4199381172657013
Test set avg_accuracy=87.38% avg_sensitivity=87.11%, avg_specificity=87.48% avg_auc=92.38%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.460766 Test loss=0.347525 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4517204463481903
[5/24] Train loss=0.390828937292099
[10/24] Train loss=0.48854732513427734
[15/24] Train loss=0.47406694293022156
[20/24] Train loss=0.46298524737358093
Test set avg_accuracy=81.80% avg_sensitivity=91.80%, avg_specificity=78.27% avg_auc=92.55%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.451803 Test loss=0.437328 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.45550867915153503
[5/24] Train loss=0.3777385354042053
[10/24] Train loss=0.4880754053592682
[15/24] Train loss=0.42734494805336
[20/24] Train loss=0.406360387802124
Test set avg_accuracy=84.62% avg_sensitivity=87.46%, avg_specificity=83.62% avg_auc=92.75%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.436363 Test loss=0.365068 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4449889361858368
[5/24] Train loss=0.399054616689682
[10/24] Train loss=0.464680939912796
[15/24] Train loss=0.47191286087036133
[20/24] Train loss=0.3987117409706116
Test set avg_accuracy=86.29% avg_sensitivity=85.86%, avg_specificity=86.44% avg_auc=93.14%
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.430134 Test loss=0.349303 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.4195106625556946
[5/24] Train loss=0.37476834654808044
[10/24] Train loss=0.4802968502044678
[15/24] Train loss=0.44640523195266724
[20/24] Train loss=0.4109433591365814
Test set avg_accuracy=86.41% avg_sensitivity=82.31%, avg_specificity=87.85% avg_auc=90.38%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.426630 Test loss=0.399068 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.43431195616722107
[5/24] Train loss=0.3883434534072876
[10/24] Train loss=0.46430251002311707
[15/24] Train loss=0.44227373600006104
[20/24] Train loss=0.39195716381073
Test set avg_accuracy=85.34% avg_sensitivity=87.91%, avg_specificity=84.43% avg_auc=93.15%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.426532 Test loss=0.366023 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.39228907227516174
[5/24] Train loss=0.3691059947013855
[10/24] Train loss=0.4487411379814148
[15/24] Train loss=0.4334123730659485
[20/24] Train loss=0.4343418478965759
Test set avg_accuracy=87.88% avg_sensitivity=79.91%, avg_specificity=90.68% avg_auc=92.64%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.422502 Test loss=0.314929 Current lr=[0.00029967723776099]

[0/24] Train loss=0.40448197722435
[5/24] Train loss=0.41238969564437866
[10/24] Train loss=0.49028700590133667
[15/24] Train loss=0.4111348092556
[20/24] Train loss=0.3919685482978821
Test set avg_accuracy=87.55% avg_sensitivity=70.86%, avg_specificity=93.43% avg_auc=89.42%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.418674 Test loss=0.361383 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.4279751777648926
[5/24] Train loss=0.37899094820022583
[10/24] Train loss=0.46086135506629944
[15/24] Train loss=0.44033294916152954
[20/24] Train loss=0.3910185694694519
Test set avg_accuracy=84.77% avg_sensitivity=52.57%, avg_specificity=96.11% avg_auc=88.50%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.418898 Test loss=0.380668 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.416935533285141
[5/24] Train loss=0.4491365849971771
[10/24] Train loss=0.46447187662124634
[15/24] Train loss=0.4387001097202301
[20/24] Train loss=0.39273837208747864
Test set avg_accuracy=88.12% avg_sensitivity=68.37%, avg_specificity=95.09% avg_auc=90.82%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.424189 Test loss=0.327475 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3974483013153076
[5/24] Train loss=0.3536006212234497
[10/24] Train loss=0.46717655658721924
[15/24] Train loss=0.42319735884666443
[20/24] Train loss=0.39450788497924805
Test set avg_accuracy=88.14% avg_sensitivity=76.61%, avg_specificity=92.20% avg_auc=90.93%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.416241 Test loss=0.341884 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3981955349445343
[5/24] Train loss=0.3363650441169739
[10/24] Train loss=0.4312710762023926
[15/24] Train loss=0.4306454658508301
[20/24] Train loss=0.409232497215271
Test set avg_accuracy=84.88% avg_sensitivity=86.26%, avg_specificity=84.40% avg_auc=91.22%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.399732 Test loss=0.429222 Current lr=[0.000298904600941902]

[0/24] Train loss=0.39551323652267456
[5/24] Train loss=0.32034680247306824
[10/24] Train loss=0.4403362274169922
[15/24] Train loss=0.39699187874794006
[20/24] Train loss=0.3896302878856659
Test set avg_accuracy=88.02% avg_sensitivity=79.81%, avg_specificity=90.91% avg_auc=91.83%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.394700 Test loss=0.332304 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.38441601395606995
[5/24] Train loss=0.3376550078392029
[10/24] Train loss=0.39965784549713135
[15/24] Train loss=0.3805065453052521
[20/24] Train loss=0.37084439396858215
Test set avg_accuracy=85.92% avg_sensitivity=86.91%, avg_specificity=85.58% avg_auc=92.43%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.379456 Test loss=0.375855 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3675987422466278
[5/24] Train loss=0.3195752501487732
[10/24] Train loss=0.37461110949516296
[15/24] Train loss=0.3856649100780487
[20/24] Train loss=0.37351325154304504
Test set avg_accuracy=85.69% avg_sensitivity=54.42%, avg_specificity=96.71% avg_auc=88.25%
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.372879 Test loss=0.365601 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.37918633222579956
[5/24] Train loss=0.35931113362312317
[10/24] Train loss=0.38913390040397644
[15/24] Train loss=0.3753294050693512
[20/24] Train loss=0.3584713935852051
Test set avg_accuracy=86.58% avg_sensitivity=58.92%, avg_specificity=96.32% avg_auc=87.98%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.369989 Test loss=0.382619 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.35689231753349304
[5/24] Train loss=0.3485438823699951
[10/24] Train loss=0.37454530596733093
[15/24] Train loss=0.3666982650756836
[20/24] Train loss=0.38028019666671753
Test set avg_accuracy=86.52% avg_sensitivity=63.82%, avg_specificity=94.52% avg_auc=88.85%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.368418 Test loss=0.374389 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.34080493450164795
[5/24] Train loss=0.34941044449806213
[10/24] Train loss=0.38772884011268616
[15/24] Train loss=0.3712754249572754
[20/24] Train loss=0.3699203133583069
Test set avg_accuracy=83.27% avg_sensitivity=41.63%, avg_specificity=97.94% avg_auc=85.46%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.369494 Test loss=0.429525 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3747240900993347
[5/24] Train loss=0.3032955229282379
[10/24] Train loss=0.38121283054351807
[15/24] Train loss=0.3647971749305725
[20/24] Train loss=0.3371473550796509
Test set avg_accuracy=87.41% avg_sensitivity=69.82%, avg_specificity=93.61% avg_auc=90.40%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.363639 Test loss=0.335686 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.37119060754776
[5/24] Train loss=0.3143293857574463
[10/24] Train loss=0.3753224313259125
[15/24] Train loss=0.3939879238605499
[20/24] Train loss=0.3422353267669678
Test set avg_accuracy=86.50% avg_sensitivity=68.62%, avg_specificity=92.80% avg_auc=90.85%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.366002 Test loss=0.346158 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3660995662212372
[5/24] Train loss=0.33490878343582153
[10/24] Train loss=0.36469677090644836
[15/24] Train loss=0.3764704167842865
[20/24] Train loss=0.3585505485534668
Test set avg_accuracy=86.91% avg_sensitivity=62.42%, avg_specificity=95.54% avg_auc=90.03%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.368917 Test loss=0.346849 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.37002673745155334
[5/24] Train loss=0.3265112638473511
[10/24] Train loss=0.40981271862983704
[15/24] Train loss=0.40444087982177734
[20/24] Train loss=0.3594810962677002
Test set avg_accuracy=86.18% avg_sensitivity=60.22%, avg_specificity=95.33% avg_auc=89.35%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.366580 Test loss=0.355562 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3708983361721039
[5/24] Train loss=0.3471238315105438
[10/24] Train loss=0.38673484325408936
[15/24] Train loss=0.35748064517974854
[20/24] Train loss=0.3353770673274994
Test set avg_accuracy=87.90% avg_sensitivity=70.31%, avg_specificity=94.10% avg_auc=90.47%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.358284 Test loss=0.336400 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3702961206436157
[5/24] Train loss=0.3293297290802002
[10/24] Train loss=0.37288209795951843
[15/24] Train loss=0.3673095405101776
[20/24] Train loss=0.3432718515396118
Test set avg_accuracy=87.76% avg_sensitivity=69.82%, avg_specificity=94.08% avg_auc=91.30%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.351529 Test loss=0.327827 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3550797402858734
[5/24] Train loss=0.31599298119544983
[10/24] Train loss=0.33118778467178345
[15/24] Train loss=0.35270074009895325
[20/24] Train loss=0.3602965474128723
Test set avg_accuracy=86.38% avg_sensitivity=60.37%, avg_specificity=95.54% avg_auc=89.06%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.347716 Test loss=0.364323 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3472821116447449
[5/24] Train loss=0.2859365940093994
[10/24] Train loss=0.339616596698761
[15/24] Train loss=0.34634965658187866
[20/24] Train loss=0.3503152132034302
Test set avg_accuracy=87.51% avg_sensitivity=83.41%, avg_specificity=88.96% avg_auc=92.86%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.338124 Test loss=0.334540 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3315524160861969
[5/24] Train loss=0.29180675745010376
[10/24] Train loss=0.3505759537220001
[15/24] Train loss=0.35135212540626526
[20/24] Train loss=0.3293595314025879
Test set avg_accuracy=87.38% avg_sensitivity=79.21%, avg_specificity=90.26% avg_auc=92.00%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.336486 Test loss=0.339460 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3368688225746155
[5/24] Train loss=0.32170236110687256
[10/24] Train loss=0.3362208306789398
[15/24] Train loss=0.33735835552215576
[20/24] Train loss=0.3142123818397522
Test set avg_accuracy=85.76% avg_sensitivity=83.36%, avg_specificity=86.60% avg_auc=91.76%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.331974 Test loss=0.401118 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3688395321369171
[5/24] Train loss=0.3073861300945282
[10/24] Train loss=0.3493727743625641
[15/24] Train loss=0.3361190855503082
[20/24] Train loss=0.31369221210479736
Test set avg_accuracy=88.37% avg_sensitivity=72.61%, avg_specificity=93.92% avg_auc=91.89%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.329664 Test loss=0.321107 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.33723631501197815
[5/24] Train loss=0.3034284710884094
[10/24] Train loss=0.36272960901260376
[15/24] Train loss=0.33129578828811646
[20/24] Train loss=0.2995900511741638
Test set avg_accuracy=88.16% avg_sensitivity=77.96%, avg_specificity=91.76% avg_auc=92.14%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.324369 Test loss=0.333643 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.33091527223587036
[5/24] Train loss=0.2868379056453705
[10/24] Train loss=0.33462488651275635
[15/24] Train loss=0.3232267498970032
[20/24] Train loss=0.3426617383956909
Test set avg_accuracy=82.81% avg_sensitivity=88.66%, avg_specificity=80.75% avg_auc=92.38%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.323992 Test loss=0.439721 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3172317147254944
[5/24] Train loss=0.2644363343715668
[10/24] Train loss=0.3113318383693695
[15/24] Train loss=0.32079002261161804
[20/24] Train loss=0.28864040970802307
Test set avg_accuracy=87.29% avg_sensitivity=80.71%, avg_specificity=89.61% avg_auc=92.06%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.309546 Test loss=0.347161 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.31974753737449646
[5/24] Train loss=0.2746303677558899
[10/24] Train loss=0.31326785683631897
[15/24] Train loss=0.31501972675323486
[20/24] Train loss=0.3132694363594055
Test set avg_accuracy=88.63% avg_sensitivity=80.06%, avg_specificity=91.65% avg_auc=92.92%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.313204 Test loss=0.311456 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3146923780441284
[5/24] Train loss=0.25942835211753845
[10/24] Train loss=0.31591010093688965
[15/24] Train loss=0.32491838932037354
[20/24] Train loss=0.30926525592803955
Test set avg_accuracy=87.50% avg_sensitivity=82.71%, avg_specificity=89.19% avg_auc=92.23%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.308392 Test loss=0.351504 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.31669268012046814
[5/24] Train loss=0.2638857364654541
[10/24] Train loss=0.2992512881755829
[15/24] Train loss=0.3249574899673462
[20/24] Train loss=0.2988089919090271
Test set avg_accuracy=86.74% avg_sensitivity=84.61%, avg_specificity=87.50% avg_auc=92.50%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.306302 Test loss=0.356161 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.28554677963256836
[5/24] Train loss=0.26747891306877136
[10/24] Train loss=0.2920911908149719
[15/24] Train loss=0.3230234980583191
[20/24] Train loss=0.3095690906047821
Test set avg_accuracy=87.66% avg_sensitivity=77.76%, avg_specificity=91.14% avg_auc=91.49%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.305150 Test loss=0.339674 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.287946879863739
[5/24] Train loss=0.2678757905960083
[10/24] Train loss=0.31232988834381104
[15/24] Train loss=0.3269272744655609
[20/24] Train loss=0.28174060583114624
Test set avg_accuracy=87.57% avg_sensitivity=87.11%, avg_specificity=87.73% avg_auc=92.99%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.303503 Test loss=0.356198 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.2938143014907837
[5/24] Train loss=0.25575071573257446
[10/24] Train loss=0.3087376356124878
[15/24] Train loss=0.2914179563522339
[20/24] Train loss=0.2918071150779724
Test set avg_accuracy=86.97% avg_sensitivity=86.21%, avg_specificity=87.23% avg_auc=92.76%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.288994 Test loss=0.373318 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.30268415808677673
[5/24] Train loss=0.25369739532470703
[10/24] Train loss=0.2763446867465973
[15/24] Train loss=0.2884417474269867
[20/24] Train loss=0.3073478937149048
Test set avg_accuracy=85.22% avg_sensitivity=85.96%, avg_specificity=84.96% avg_auc=91.98%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.286633 Test loss=0.433562 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.28645554184913635
[5/24] Train loss=0.24780404567718506
[10/24] Train loss=0.29358333349227905
[15/24] Train loss=0.31214433908462524
[20/24] Train loss=0.2987811267375946
Test set avg_accuracy=83.27% avg_sensitivity=88.51%, avg_specificity=81.42% avg_auc=91.38%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.289189 Test loss=0.507154 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.30215558409690857
[5/24] Train loss=0.27199357748031616
[10/24] Train loss=0.2800750732421875
[15/24] Train loss=0.29840371012687683
[20/24] Train loss=0.3098437488079071
Test set avg_accuracy=86.78% avg_sensitivity=86.21%, avg_specificity=86.99% avg_auc=92.97%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.287428 Test loss=0.366015 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2965182363986969
[5/24] Train loss=0.254337877035141
[10/24] Train loss=0.28361010551452637
[15/24] Train loss=0.29267123341560364
[20/24] Train loss=0.301003098487854
Test set avg_accuracy=86.77% avg_sensitivity=83.91%, avg_specificity=87.78% avg_auc=92.35%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.283521 Test loss=0.357420 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2666785717010498
[5/24] Train loss=0.2430947721004486
[10/24] Train loss=0.2810685932636261
[15/24] Train loss=0.28498804569244385
[20/24] Train loss=0.27532050013542175
Test set avg_accuracy=83.89% avg_sensitivity=88.46%, avg_specificity=82.29% avg_auc=92.11%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.280831 Test loss=0.435360 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2748849391937256
[5/24] Train loss=0.23747055232524872
[10/24] Train loss=0.2817862927913666
[15/24] Train loss=0.30417266488075256
[20/24] Train loss=0.2539345920085907
Test set avg_accuracy=87.58% avg_sensitivity=81.31%, avg_specificity=89.79% avg_auc=91.68%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.272973 Test loss=0.352945 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.26722902059555054
[5/24] Train loss=0.2519482672214508
[10/24] Train loss=0.26907217502593994
[15/24] Train loss=0.2766031324863434
[20/24] Train loss=0.2641087472438812
Test set avg_accuracy=87.20% avg_sensitivity=83.26%, avg_specificity=88.59% avg_auc=92.07%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.266686 Test loss=0.367287 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.25850850343704224
[5/24] Train loss=0.23543231189250946
[10/24] Train loss=0.29952991008758545
[15/24] Train loss=0.26941001415252686
[20/24] Train loss=0.27498888969421387
Test set avg_accuracy=87.38% avg_sensitivity=83.66%, avg_specificity=88.70% avg_auc=92.59%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.268311 Test loss=0.355549 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2655869722366333
[5/24] Train loss=0.24582579731941223
[10/24] Train loss=0.2872573435306549
[15/24] Train loss=0.28287720680236816
[20/24] Train loss=0.2662601172924042
Test set avg_accuracy=88.15% avg_sensitivity=78.11%, avg_specificity=91.69% avg_auc=91.21%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.269701 Test loss=0.356044 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2565222680568695
[5/24] Train loss=0.2272644191980362
[10/24] Train loss=0.2620712220668793
[15/24] Train loss=0.2711082696914673
[20/24] Train loss=0.2899472117424011
Test set avg_accuracy=85.27% avg_sensitivity=86.96%, avg_specificity=84.68% avg_auc=91.31%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.264171 Test loss=0.446702 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.26280340552330017
[5/24] Train loss=0.24056032299995422
[10/24] Train loss=0.2639997601509094
[15/24] Train loss=0.2740224599838257
[20/24] Train loss=0.2551821172237396
Test set avg_accuracy=87.06% avg_sensitivity=75.21%, avg_specificity=91.23% avg_auc=91.16%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.263834 Test loss=0.357176 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.27023911476135254
[5/24] Train loss=0.2141689658164978
[10/24] Train loss=0.270052045583725
[15/24] Train loss=0.2772611975669861
[20/24] Train loss=0.2664732038974762
Test set avg_accuracy=87.94% avg_sensitivity=82.06%, avg_specificity=90.02% avg_auc=92.87%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.265449 Test loss=0.341246 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2601284980773926
[5/24] Train loss=0.22545763850212097
[10/24] Train loss=0.262592613697052
[15/24] Train loss=0.27220889925956726
[20/24] Train loss=0.24537943303585052
Test set avg_accuracy=88.31% avg_sensitivity=81.56%, avg_specificity=90.68% avg_auc=91.77%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.259707 Test loss=0.358692 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.24834337830543518
[5/24] Train loss=0.23959121108055115
[10/24] Train loss=0.2454383820295334
[15/24] Train loss=0.260545939207077
[20/24] Train loss=0.25496378540992737
Test set avg_accuracy=87.76% avg_sensitivity=81.36%, avg_specificity=90.02% avg_auc=92.15%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.254424 Test loss=0.357540 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2636891305446625
[5/24] Train loss=0.21861422061920166
[10/24] Train loss=0.24969477951526642
[15/24] Train loss=0.2613767385482788
[20/24] Train loss=0.25954705476760864
Test set avg_accuracy=87.16% avg_sensitivity=83.61%, avg_specificity=88.41% avg_auc=91.99%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.248701 Test loss=0.393449 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2479579746723175
[5/24] Train loss=0.22988678514957428
[10/24] Train loss=0.25425922870635986
[15/24] Train loss=0.2472100704908371
[20/24] Train loss=0.25029653310775757
Test set avg_accuracy=87.89% avg_sensitivity=79.01%, avg_specificity=91.02% avg_auc=92.04%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.252543 Test loss=0.354729 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.26134079694747925
[5/24] Train loss=0.22555987536907196
[10/24] Train loss=0.24395789206027985
[15/24] Train loss=0.27599895000457764
[20/24] Train loss=0.2542751729488373
Test set avg_accuracy=88.36% avg_sensitivity=75.46%, avg_specificity=92.90% avg_auc=91.66%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.252578 Test loss=0.346044 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.24274902045726776
[5/24] Train loss=0.24797287583351135
[10/24] Train loss=0.245921790599823
[15/24] Train loss=0.2599383592605591
[20/24] Train loss=0.2494090497493744
Test set avg_accuracy=87.34% avg_sensitivity=67.37%, avg_specificity=94.38% avg_auc=90.34%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.253894 Test loss=0.363523 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2647881805896759
[5/24] Train loss=0.22342538833618164
[10/24] Train loss=0.267241895198822
[15/24] Train loss=0.27643927931785583
[20/24] Train loss=0.27352699637413025
Test set avg_accuracy=87.89% avg_sensitivity=84.91%, avg_specificity=88.94% avg_auc=92.75%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.255736 Test loss=0.354769 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2654561698436737
[5/24] Train loss=0.2234565019607544
[10/24] Train loss=0.24761395156383514
[15/24] Train loss=0.29515737295150757
[20/24] Train loss=0.2543475925922394
Test set avg_accuracy=87.29% avg_sensitivity=82.26%, avg_specificity=89.06% avg_auc=92.35%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.257867 Test loss=0.352390 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2518687844276428
[5/24] Train loss=0.21682600677013397
[10/24] Train loss=0.2545700967311859
[15/24] Train loss=0.2610434591770172
[20/24] Train loss=0.2732830047607422
Test set avg_accuracy=86.98% avg_sensitivity=81.46%, avg_specificity=88.92% avg_auc=92.13%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.254285 Test loss=0.369083 Current lr=[0.000156543481933168]

[0/24] Train loss=0.23717640340328217
[5/24] Train loss=0.23688174784183502
[10/24] Train loss=0.2626988887786865
[15/24] Train loss=0.24498292803764343
[20/24] Train loss=0.24389345943927765
Test set avg_accuracy=88.63% avg_sensitivity=76.96%, avg_specificity=92.75% avg_auc=91.40%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.247991 Test loss=0.344630 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.23457588255405426
[5/24] Train loss=0.2309504896402359
[10/24] Train loss=0.2569473385810852
[15/24] Train loss=0.2477487325668335
[20/24] Train loss=0.24498385190963745
Test set avg_accuracy=87.93% avg_sensitivity=80.31%, avg_specificity=90.61% avg_auc=92.60%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.242435 Test loss=0.341548 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2341083586215973
[5/24] Train loss=0.22094683349132538
[10/24] Train loss=0.24202725291252136
[15/24] Train loss=0.24000301957130432
[20/24] Train loss=0.22855955362319946
Test set avg_accuracy=88.19% avg_sensitivity=76.71%, avg_specificity=92.23% avg_auc=90.16%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.233902 Test loss=0.361035 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.2271023839712143
[5/24] Train loss=0.2092016339302063
[10/24] Train loss=0.2523709833621979
[15/24] Train loss=0.26371321082115173
[20/24] Train loss=0.23270615935325623
Test set avg_accuracy=88.45% avg_sensitivity=79.41%, avg_specificity=91.64% avg_auc=91.69%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.238080 Test loss=0.349452 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.2321043461561203
[5/24] Train loss=0.22684918344020844
[10/24] Train loss=0.2343587428331375
[15/24] Train loss=0.26901933550834656
[20/24] Train loss=0.24072346091270447
Test set avg_accuracy=89.01% avg_sensitivity=75.16%, avg_specificity=93.89% avg_auc=92.11%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.246511 Test loss=0.329868 Current lr=[0.000134135431043539]

[0/24] Train loss=0.22327041625976562
[5/24] Train loss=0.20002201199531555
[10/24] Train loss=0.2359677404165268
[15/24] Train loss=0.22864870727062225
[20/24] Train loss=0.2310686856508255
Test set avg_accuracy=88.72% avg_sensitivity=78.26%, avg_specificity=92.41% avg_auc=91.80%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.229232 Test loss=0.343326 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.23008885979652405
[5/24] Train loss=0.20301245152950287
[10/24] Train loss=0.2210022360086441
[15/24] Train loss=0.23302985727787018
[20/24] Train loss=0.2324790507555008
Test set avg_accuracy=87.75% avg_sensitivity=84.41%, avg_specificity=88.92% avg_auc=92.84%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.225088 Test loss=0.354612 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.22634485363960266
[5/24] Train loss=0.1937909573316574
[10/24] Train loss=0.2336271107196808
[15/24] Train loss=0.22281165421009064
[20/24] Train loss=0.23749633133411407
Test set avg_accuracy=88.79% avg_sensitivity=80.61%, avg_specificity=91.67% avg_auc=92.24%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.222071 Test loss=0.336297 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.22443389892578125
[5/24] Train loss=0.19183000922203064
[10/24] Train loss=0.20721286535263062
[15/24] Train loss=0.23101307451725006
[20/24] Train loss=0.21882745623588562
Test set avg_accuracy=88.35% avg_sensitivity=78.81%, avg_specificity=91.71% avg_auc=92.49%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.213871 Test loss=0.331151 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.20991086959838867
[5/24] Train loss=0.19152522087097168
[10/24] Train loss=0.2079000473022461
[15/24] Train loss=0.22183659672737122
[20/24] Train loss=0.21019180119037628
Test set avg_accuracy=88.14% avg_sensitivity=85.06%, avg_specificity=89.22% avg_auc=92.49%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.210665 Test loss=0.361650 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.20879606902599335
[5/24] Train loss=0.19043205678462982
[10/24] Train loss=0.210151806473732
[15/24] Train loss=0.2151547521352768
[20/24] Train loss=0.20614413917064667
Test set avg_accuracy=87.99% avg_sensitivity=85.81%, avg_specificity=88.77% avg_auc=93.19%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.209628 Test loss=0.348972 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.20688487589359283
[5/24] Train loss=0.1857789158821106
[10/24] Train loss=0.21285204589366913
[15/24] Train loss=0.21348102390766144
[20/24] Train loss=0.21603044867515564
Test set avg_accuracy=87.15% avg_sensitivity=84.36%, avg_specificity=88.13% avg_auc=92.61%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.205844 Test loss=0.371834 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.20567958056926727
[5/24] Train loss=0.179518461227417
[10/24] Train loss=0.20776867866516113
[15/24] Train loss=0.21341648697853088
[20/24] Train loss=0.2027159333229065
Test set avg_accuracy=88.01% avg_sensitivity=83.46%, avg_specificity=89.61% avg_auc=92.96%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.201747 Test loss=0.346322 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.20634564757347107
[5/24] Train loss=0.17692601680755615
[10/24] Train loss=0.20693916082382202
[15/24] Train loss=0.2097514122724533
[20/24] Train loss=0.21058395504951477
Test set avg_accuracy=86.54% avg_sensitivity=82.91%, avg_specificity=87.81% avg_auc=92.19%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.199729 Test loss=0.381975 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.1956029236316681
[5/24] Train loss=0.17438282072544098
[10/24] Train loss=0.20878389477729797
[15/24] Train loss=0.21731461584568024
[20/24] Train loss=0.20221702754497528
Test set avg_accuracy=88.16% avg_sensitivity=78.26%, avg_specificity=91.65% avg_auc=92.26%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.198025 Test loss=0.339184 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.19884632527828217
[5/24] Train loss=0.17780184745788574
[10/24] Train loss=0.19951318204402924
[15/24] Train loss=0.21326342225074768
[20/24] Train loss=0.2063632756471634
Test set avg_accuracy=88.29% avg_sensitivity=79.96%, avg_specificity=91.23% avg_auc=92.81%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.197216 Test loss=0.330479 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.19248004257678986
[5/24] Train loss=0.17268607020378113
[10/24] Train loss=0.19335748255252838
[15/24] Train loss=0.20782913267612457
[20/24] Train loss=0.20574647188186646
Test set avg_accuracy=88.03% avg_sensitivity=79.86%, avg_specificity=90.91% avg_auc=92.84%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.194873 Test loss=0.331935 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.19087925553321838
[5/24] Train loss=0.1759580820798874
[10/24] Train loss=0.20172251760959625
[15/24] Train loss=0.20603883266448975
[20/24] Train loss=0.2046886533498764
Test set avg_accuracy=88.59% avg_sensitivity=76.06%, avg_specificity=93.01% avg_auc=92.02%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.194548 Test loss=0.332100 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.19898450374603271
[5/24] Train loss=0.16560368239879608
[10/24] Train loss=0.19183924794197083
[15/24] Train loss=0.2005225121974945
[20/24] Train loss=0.19787894189357758
Test set avg_accuracy=88.66% avg_sensitivity=79.86%, avg_specificity=91.76% avg_auc=92.36%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.191833 Test loss=0.336477 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.193065345287323
[5/24] Train loss=0.16666093468666077
[10/24] Train loss=0.19277244806289673
[15/24] Train loss=0.20172838866710663
[20/24] Train loss=0.19988785684108734
Test set avg_accuracy=88.42% avg_sensitivity=79.71%, avg_specificity=91.49% avg_auc=92.28%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.190172 Test loss=0.342394 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.18699488043785095
[5/24] Train loss=0.16474895179271698
[10/24] Train loss=0.1920616179704666
[15/24] Train loss=0.19828613102436066
[20/24] Train loss=0.1953428089618683
Test set avg_accuracy=88.40% avg_sensitivity=81.01%, avg_specificity=91.00% avg_auc=92.58%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.187579 Test loss=0.331593 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.18949854373931885
[5/24] Train loss=0.1643746793270111
[10/24] Train loss=0.1860787719488144
[15/24] Train loss=0.19430255889892578
[20/24] Train loss=0.19486981630325317
Test set avg_accuracy=88.45% avg_sensitivity=79.66%, avg_specificity=91.55% avg_auc=92.72%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.186988 Test loss=0.335673 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.18659678101539612
[5/24] Train loss=0.16515937447547913
[10/24] Train loss=0.19327034056186676
[15/24] Train loss=0.19445830583572388
[20/24] Train loss=0.19065795838832855
Test set avg_accuracy=88.45% avg_sensitivity=81.66%, avg_specificity=90.84% avg_auc=92.43%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.185399 Test loss=0.340183 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1813681423664093
[5/24] Train loss=0.1600942313671112
[10/24] Train loss=0.18345557153224945
[15/24] Train loss=0.19588668644428253
[20/24] Train loss=0.18929634988307953
Test set avg_accuracy=88.82% avg_sensitivity=79.66%, avg_specificity=92.04% avg_auc=92.38%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.182545 Test loss=0.322926 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.18237169086933136
[5/24] Train loss=0.16708333790302277
[10/24] Train loss=0.18265801668167114
[15/24] Train loss=0.18999440968036652
[20/24] Train loss=0.18929460644721985
Test set avg_accuracy=88.20% avg_sensitivity=81.26%, avg_specificity=90.65% avg_auc=92.74%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.182212 Test loss=0.334340 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.17477290332317352
[5/24] Train loss=0.15495187044143677
[10/24] Train loss=0.1800779104232788
[15/24] Train loss=0.18770895898342133
[20/24] Train loss=0.18510869145393372
Test set avg_accuracy=88.70% avg_sensitivity=81.96%, avg_specificity=91.07% avg_auc=92.94%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.179083 Test loss=0.336572 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.17627796530723572
[5/24] Train loss=0.1624743491411209
[10/24] Train loss=0.18383900821208954
[15/24] Train loss=0.19251735508441925
[20/24] Train loss=0.18310537934303284
Test set avg_accuracy=87.98% avg_sensitivity=82.76%, avg_specificity=89.82% avg_auc=92.76%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.179359 Test loss=0.345613 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.18171505630016327
[5/24] Train loss=0.15782321989536285
[10/24] Train loss=0.17412984371185303
[15/24] Train loss=0.18402713537216187
[20/24] Train loss=0.18240995705127716
Test set avg_accuracy=88.66% avg_sensitivity=77.41%, avg_specificity=92.62% avg_auc=92.02%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.178406 Test loss=0.336993 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.17563144862651825
[5/24] Train loss=0.1574823260307312
[10/24] Train loss=0.18061019480228424
[15/24] Train loss=0.19010597467422485
[20/24] Train loss=0.18317364156246185
Test set avg_accuracy=88.54% avg_sensitivity=79.66%, avg_specificity=91.67% avg_auc=92.09%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.176990 Test loss=0.340449 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1726338416337967
[5/24] Train loss=0.1515238881111145
[10/24] Train loss=0.17402000725269318
[15/24] Train loss=0.18547847867012024
[20/24] Train loss=0.1826886534690857
Test set avg_accuracy=88.44% avg_sensitivity=78.81%, avg_specificity=91.83% avg_auc=92.49%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.175191 Test loss=0.333025 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.17674857378005981
[5/24] Train loss=0.15595993399620056
[10/24] Train loss=0.17518244683742523
[15/24] Train loss=0.18806298077106476
[20/24] Train loss=0.17724955081939697
Test set avg_accuracy=88.52% avg_sensitivity=79.36%, avg_specificity=91.74% avg_auc=92.32%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.176157 Test loss=0.336509 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.17264927923679352
[5/24] Train loss=0.16365453600883484
[10/24] Train loss=0.18723104894161224
[15/24] Train loss=0.18522775173187256
[20/24] Train loss=0.18354231119155884
Test set avg_accuracy=88.16% avg_sensitivity=83.81%, avg_specificity=89.70% avg_auc=92.67%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.177713 Test loss=0.349459 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.17588432133197784
[5/24] Train loss=0.15439140796661377
[10/24] Train loss=0.17994019389152527
[15/24] Train loss=0.18250063061714172
[20/24] Train loss=0.17665639519691467
Test set avg_accuracy=87.72% avg_sensitivity=84.91%, avg_specificity=88.71% avg_auc=92.77%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.175131 Test loss=0.362535 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1771695911884308
[5/24] Train loss=0.16231903433799744
[10/24] Train loss=0.17237062752246857
[15/24] Train loss=0.18718867003917694
[20/24] Train loss=0.18339262902736664
Test set avg_accuracy=87.67% avg_sensitivity=81.41%, avg_specificity=89.87% avg_auc=92.72%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.175225 Test loss=0.343501 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.17449969053268433
[5/24] Train loss=0.15709295868873596
[10/24] Train loss=0.17473545670509338
[15/24] Train loss=0.18314139544963837
[20/24] Train loss=0.18308599293231964
Test set avg_accuracy=88.53% avg_sensitivity=80.81%, avg_specificity=91.25% avg_auc=92.79%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.175376 Test loss=0.332085 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.17309874296188354
[5/24] Train loss=0.15843795239925385
[10/24] Train loss=0.18432104587554932
[15/24] Train loss=0.18025469779968262
[20/24] Train loss=0.17370308935642242
Test set avg_accuracy=88.06% avg_sensitivity=81.31%, avg_specificity=90.44% avg_auc=92.55%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.173948 Test loss=0.341395 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.17350970208644867
[5/24] Train loss=0.15355762839317322
[10/24] Train loss=0.17519813776016235
[15/24] Train loss=0.18359169363975525
[20/24] Train loss=0.17183895409107208
Test set avg_accuracy=88.05% avg_sensitivity=81.76%, avg_specificity=90.26% avg_auc=92.73%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.172319 Test loss=0.335501 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.17271408438682556
[5/24] Train loss=0.15142501890659332
[10/24] Train loss=0.17440646886825562
[15/24] Train loss=0.1794779896736145
[20/24] Train loss=0.1713618040084839
Test set avg_accuracy=88.31% avg_sensitivity=82.51%, avg_specificity=90.35% avg_auc=92.87%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.169919 Test loss=0.336468 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1708175390958786
[5/24] Train loss=0.15010496973991394
[10/24] Train loss=0.1683717668056488
[15/24] Train loss=0.1793341189622879
[20/24] Train loss=0.1741439253091812
Test set avg_accuracy=88.57% avg_sensitivity=81.76%, avg_specificity=90.97% avg_auc=92.78%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.167645 Test loss=0.330568 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.16857154667377472
[5/24] Train loss=0.14824368059635162
[10/24] Train loss=0.1675191968679428
[15/24] Train loss=0.17582006752490997
[20/24] Train loss=0.17268235981464386
Test set avg_accuracy=88.37% avg_sensitivity=82.16%, avg_specificity=90.56% avg_auc=92.85%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.166763 Test loss=0.334637 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.17006032168865204
[5/24] Train loss=0.14874039590358734
[10/24] Train loss=0.16636528074741364
[15/24] Train loss=0.17809605598449707
[20/24] Train loss=0.1700807362794876
Test set avg_accuracy=88.11% avg_sensitivity=81.06%, avg_specificity=90.60% avg_auc=92.74%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.166048 Test loss=0.333512 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.16347351670265198
[5/24] Train loss=0.14796505868434906
[10/24] Train loss=0.16520898044109344
[15/24] Train loss=0.17608900368213654
[20/24] Train loss=0.168073371052742
Test set avg_accuracy=88.46% avg_sensitivity=81.36%, avg_specificity=90.97% avg_auc=92.75%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.164971 Test loss=0.333700 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1700163334608078
[5/24] Train loss=0.14673441648483276
[10/24] Train loss=0.16904330253601074
[15/24] Train loss=0.17397621273994446
[20/24] Train loss=0.16828766465187073
Test set avg_accuracy=88.39% avg_sensitivity=81.41%, avg_specificity=90.84% avg_auc=92.77%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.165193 Test loss=0.334401 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.164668008685112
[5/24] Train loss=0.14631612598896027
[10/24] Train loss=0.1652361899614334
[15/24] Train loss=0.17421072721481323
[20/24] Train loss=0.16490715742111206
Test set avg_accuracy=88.42% avg_sensitivity=81.51%, avg_specificity=90.86% avg_auc=92.69%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.164358 Test loss=0.334769 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.16520678997039795
[5/24] Train loss=0.14736846089363098
[10/24] Train loss=0.16827774047851562
[15/24] Train loss=0.17572171986103058
[20/24] Train loss=0.16873985528945923
Test set avg_accuracy=88.39% avg_sensitivity=81.01%, avg_specificity=90.98% avg_auc=92.62%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.163750 Test loss=0.335030 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1619626134634018
[5/24] Train loss=0.14549392461776733
[10/24] Train loss=0.16716648638248444
[15/24] Train loss=0.1734728366136551
[20/24] Train loss=0.17232230305671692
Test set avg_accuracy=88.37% avg_sensitivity=81.41%, avg_specificity=90.83% avg_auc=92.68%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.163829 Test loss=0.334950 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.16647595167160034
[5/24] Train loss=0.14482556283473969
[10/24] Train loss=0.16412970423698425
[15/24] Train loss=0.17435064911842346
[20/24] Train loss=0.17072418332099915
Test set avg_accuracy=88.44% avg_sensitivity=81.66%, avg_specificity=90.83% avg_auc=92.72%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.164425 Test loss=0.334470 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.16265907883644104
[5/24] Train loss=0.14749237895011902
[10/24] Train loss=0.16481836140155792
[15/24] Train loss=0.17465242743492126
[20/24] Train loss=0.1709461659193039
Test set avg_accuracy=88.35% avg_sensitivity=81.41%, avg_specificity=90.79% avg_auc=92.67%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.163708 Test loss=0.334971 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.16488949954509735
[5/24] Train loss=0.14627666771411896
[10/24] Train loss=0.16682876646518707
[15/24] Train loss=0.16958819329738617
[20/24] Train loss=0.16825717687606812
Test set avg_accuracy=88.32% avg_sensitivity=81.26%, avg_specificity=90.81% avg_auc=92.66%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.163952 Test loss=0.334951 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.16570143401622772
[5/24] Train loss=0.14642076194286346
[10/24] Train loss=0.16490359604358673
[15/24] Train loss=0.1743917614221573
[20/24] Train loss=0.16958075761795044
Test set avg_accuracy=88.42% avg_sensitivity=81.21%, avg_specificity=90.97% avg_auc=92.67%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.164337 Test loss=0.334221 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.16457615792751312
[5/24] Train loss=0.14325018227100372
[10/24] Train loss=0.16552585363388062
[15/24] Train loss=0.1748242825269699
[20/24] Train loss=0.17129698395729065
Test set avg_accuracy=88.31% avg_sensitivity=81.11%, avg_specificity=90.84% avg_auc=92.68%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.163575 Test loss=0.334660 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1619863510131836
[5/24] Train loss=0.14388936758041382
[10/24] Train loss=0.1668763905763626
[15/24] Train loss=0.1735752522945404
[20/24] Train loss=0.16872723400592804
Test set avg_accuracy=88.32% avg_sensitivity=81.26%, avg_specificity=90.81% avg_auc=92.70%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.163658 Test loss=0.334475 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1649131178855896
[5/24] Train loss=0.14724434912204742
[10/24] Train loss=0.1660863608121872
[15/24] Train loss=0.17290998995304108
[20/24] Train loss=0.17253565788269043
Test set avg_accuracy=88.28% avg_sensitivity=81.16%, avg_specificity=90.79% avg_auc=92.69%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.164396 Test loss=0.334519 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.16432054340839386
[5/24] Train loss=0.14356566965579987
[10/24] Train loss=0.16321320831775665
[15/24] Train loss=0.17330937087535858
[20/24] Train loss=0.16605964303016663
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=88.29% avg_sensitivity=81.16%, avg_specificity=90.81% avg_auc=92.68%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.162667 Test loss=0.334102 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=87.98% sen=86.41%, spe=88.54%, auc=93.40%!
Fold[4] Avg_overlap=0.68%(0.21012880454274085)
[0/24] Train loss=1.481307029724121
[5/24] Train loss=1.4488106966018677
[10/24] Train loss=1.4396029710769653
[15/24] Train loss=1.4276014566421509
[20/24] Train loss=1.40712308883667
Test set avg_accuracy=69.28% avg_sensitivity=38.66%, avg_specificity=79.73% avg_auc=61.69%
Best model saved!! Metric=-76.6406712910716!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=1.444656 Test loss=0.651145 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.398764967918396
[5/24] Train loss=1.3887293338775635
[10/24] Train loss=1.3909577131271362
[15/24] Train loss=1.359802007675171
[20/24] Train loss=1.339260220527649
Test set avg_accuracy=73.79% avg_sensitivity=71.58%, avg_specificity=74.54% avg_auc=75.31%
Best model saved!! Metric=-30.777050836893494!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=1.371514 Test loss=0.597889 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3322802782058716
[5/24] Train loss=1.3135918378829956
[10/24] Train loss=1.3368494510650635
[15/24] Train loss=1.2612088918685913
[20/24] Train loss=1.2540181875228882
Test set avg_accuracy=73.68% avg_sensitivity=79.93%, avg_specificity=71.56% avg_auc=79.69%
Best model saved!! Metric=-21.140444486962977!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=1.298677 Test loss=0.567452 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.2541797161102295
[5/24] Train loss=1.2261312007904053
[10/24] Train loss=1.245998501777649
[15/24] Train loss=1.1749176979064941
[20/24] Train loss=1.157607913017273
Test set avg_accuracy=73.84% avg_sensitivity=83.72%, avg_specificity=70.47% avg_auc=82.70%
Best model saved!! Metric=-15.271211429820681!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=1.217888 Test loss=0.552269 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.176082730293274
[5/24] Train loss=1.163210391998291
[10/24] Train loss=1.1858618259429932
[15/24] Train loss=1.0949000120162964
[20/24] Train loss=1.0996569395065308
Test set avg_accuracy=74.31% avg_sensitivity=85.56%, avg_specificity=70.47% avg_auc=85.09%
Best model saved!! Metric=-10.571159231334178!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=1.147147 Test loss=0.537206 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.1134353876113892
[5/24] Train loss=1.081800103187561
[10/24] Train loss=1.1286059617996216
[15/24] Train loss=1.02534818649292
[20/24] Train loss=1.0398536920547485
Test set avg_accuracy=75.64% avg_sensitivity=86.64%, avg_specificity=71.89% avg_auc=87.05%
Best model saved!! Metric=-4.787714343174926!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=1.082516 Test loss=0.514456 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.0440376996994019
[5/24] Train loss=1.0292452573776245
[10/24] Train loss=1.0854777097702026
[15/24] Train loss=0.9552016258239746
[20/24] Train loss=0.9904091954231262
Test set avg_accuracy=76.35% avg_sensitivity=86.94%, avg_specificity=72.74% avg_auc=88.74%
Best model saved!! Metric=-1.2165365473559575!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=1.027912 Test loss=0.493313 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9877931475639343
[5/24] Train loss=0.9673246145248413
[10/24] Train loss=1.023370623588562
[15/24] Train loss=0.9077503085136414
[20/24] Train loss=0.9291460514068604
Test set avg_accuracy=78.85% avg_sensitivity=86.38%, avg_specificity=76.29% avg_auc=89.92%
Best model saved!! Metric=5.438251307730994!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.974372 Test loss=0.460251 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.9425556659698486
[5/24] Train loss=0.9149465560913086
[10/24] Train loss=0.9774869680404663
[15/24] Train loss=0.8529946804046631
[20/24] Train loss=0.8814641237258911
Test set avg_accuracy=80.14% avg_sensitivity=86.74%, avg_specificity=77.89% avg_auc=90.94%
Best model saved!! Metric=9.710868051867536!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.924447 Test loss=0.439324 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8929536938667297
[5/24] Train loss=0.8658640384674072
[10/24] Train loss=0.9424448609352112
[15/24] Train loss=0.8097239136695862
[20/24] Train loss=0.8331000208854675
Test set avg_accuracy=81.90% avg_sensitivity=86.02%, avg_specificity=80.50% avg_auc=91.76%
Best model saved!! Metric=14.182963852169507!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.880433 Test loss=0.416055 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.8526446223258972
[5/24] Train loss=0.8238754272460938
[10/24] Train loss=0.8885481953620911
[15/24] Train loss=0.7770640850067139
[20/24] Train loss=0.7817270159721375
Test set avg_accuracy=82.68% avg_sensitivity=87.97%, avg_specificity=80.88% avg_auc=92.57%
Best model saved!! Metric=18.10061349915567!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.839759 Test loss=0.408889 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.8079518675804138
[5/24] Train loss=0.7939171195030212
[10/24] Train loss=0.8738214373588562
[15/24] Train loss=0.7393624782562256
[20/24] Train loss=0.745309054851532
Test set avg_accuracy=83.61% avg_sensitivity=87.51%, avg_specificity=82.28% avg_auc=92.98%
Best model saved!! Metric=20.36608297671752!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.806621 Test loss=0.393091 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7727813124656677
[5/24] Train loss=0.7424076199531555
[10/24] Train loss=0.836384654045105
[15/24] Train loss=0.7035406827926636
[20/24] Train loss=0.731661856174469
Test set avg_accuracy=84.26% avg_sensitivity=86.99%, avg_specificity=83.32% avg_auc=93.34%
Best model saved!! Metric=21.91438451257666!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.772786 Test loss=0.378218 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.7421199083328247
[5/24] Train loss=0.7033522129058838
[10/24] Train loss=0.8045229911804199
[15/24] Train loss=0.6828830242156982
[20/24] Train loss=0.6855312585830688
Test set avg_accuracy=84.62% avg_sensitivity=85.87%, avg_specificity=84.20% avg_auc=93.48%
Best model saved!! Metric=22.163963873118647!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.741597 Test loss=0.364566 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.7231553196907043
[5/24] Train loss=0.6803327202796936
[10/24] Train loss=0.8040297031402588
[15/24] Train loss=0.648801863193512
[20/24] Train loss=0.6605864763259888
Test set avg_accuracy=83.84% avg_sensitivity=88.22%, avg_specificity=82.35% avg_auc=93.68%
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.720427 Test loss=0.367907 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.6898079514503479
[5/24] Train loss=0.6543572545051575
[10/24] Train loss=0.7724635601043701
[15/24] Train loss=0.6356561183929443
[20/24] Train loss=0.6377881765365601
Test set avg_accuracy=83.83% avg_sensitivity=88.48%, avg_specificity=82.24% avg_auc=93.88%
Best model saved!! Metric=22.42796115308984!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.699226 Test loss=0.368329 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6732921600341797
[5/24] Train loss=0.6337807178497314
[10/24] Train loss=0.770437479019165
[15/24] Train loss=0.6225610375404358
[20/24] Train loss=0.6273776292800903
Test set avg_accuracy=85.04% avg_sensitivity=85.82%, avg_specificity=84.77% avg_auc=93.83%
Best model saved!! Metric=23.462329154632513!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.681681 Test loss=0.342235 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.6520955562591553
[5/24] Train loss=0.6157864928245544
[10/24] Train loss=0.7557066082954407
[15/24] Train loss=0.5947529673576355
[20/24] Train loss=0.6109394431114197
Test set avg_accuracy=83.12% avg_sensitivity=90.53%, avg_specificity=80.60% avg_auc=94.23%
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.667039 Test loss=0.382186 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.6435201168060303
[5/24] Train loss=0.6062646508216858
[10/24] Train loss=0.7387934923171997
[15/24] Train loss=0.5851595401763916
[20/24] Train loss=0.5917031764984131
Test set avg_accuracy=83.63% avg_sensitivity=90.02%, avg_specificity=81.46% avg_auc=94.21%
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.653096 Test loss=0.375866 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.6300628781318665
[5/24] Train loss=0.5801544785499573
[10/24] Train loss=0.707629919052124
[15/24] Train loss=0.5697548389434814
[20/24] Train loss=0.5656742453575134
Test set avg_accuracy=84.38% avg_sensitivity=88.74%, avg_specificity=82.89% avg_auc=94.33%
Best model saved!! Metric=24.32497278009832!!
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.638948 Test loss=0.357426 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.6077238917350769
[5/24] Train loss=0.5743881464004517
[10/24] Train loss=0.7055915594100952
[15/24] Train loss=0.5713245868682861
[20/24] Train loss=0.5739002823829651
Test set avg_accuracy=84.78% avg_sensitivity=89.35%, avg_specificity=83.22% avg_auc=94.35%
Best model saved!! Metric=25.695065938384545!!
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.626373 Test loss=0.357358 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5892490744590759
[5/24] Train loss=0.5509620308876038
[10/24] Train loss=0.684738039970398
[15/24] Train loss=0.5477240681648254
[20/24] Train loss=0.5493772625923157
Test set avg_accuracy=85.99% avg_sensitivity=86.99%, avg_specificity=85.65% avg_auc=94.39%
Best model saved!! Metric=27.019250567464965!!
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.610234 Test loss=0.335138 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5818951725959778
[5/24] Train loss=0.5484874844551086
[10/24] Train loss=0.6950125098228455
[15/24] Train loss=0.5323463678359985
[20/24] Train loss=0.554227352142334
Test set avg_accuracy=84.05% avg_sensitivity=90.32%, avg_specificity=81.91% avg_auc=94.47%
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.605393 Test loss=0.372318 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5889626145362854
[5/24] Train loss=0.5489640831947327
[10/24] Train loss=0.6915452480316162
[15/24] Train loss=0.5297675132751465
[20/24] Train loss=0.535109281539917
Test set avg_accuracy=85.25% avg_sensitivity=88.17%, avg_specificity=84.25% avg_auc=94.53%
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.595390 Test loss=0.339361 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5556125640869141
[5/24] Train loss=0.5198072195053101
[10/24] Train loss=0.6619998216629028
[15/24] Train loss=0.5174272656440735
[20/24] Train loss=0.5319483876228333
Test set avg_accuracy=83.72% avg_sensitivity=91.14%, avg_specificity=81.19% avg_auc=94.33%
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.583111 Test loss=0.390625 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.553531289100647
[5/24] Train loss=0.5049554705619812
[10/24] Train loss=0.6443994641304016
[15/24] Train loss=0.5105752944946289
[20/24] Train loss=0.5166505575180054
Test set avg_accuracy=83.50% avg_sensitivity=90.83%, avg_specificity=81.00% avg_auc=94.53%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.570113 Test loss=0.387497 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.539750337600708
[5/24] Train loss=0.5167645215988159
[10/24] Train loss=0.6240219473838806
[15/24] Train loss=0.49703848361968994
[20/24] Train loss=0.5190560817718506
Test set avg_accuracy=81.46% avg_sensitivity=92.63%, avg_specificity=77.65% avg_auc=94.62%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.558456 Test loss=0.416365 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.5243940353393555
[5/24] Train loss=0.510746955871582
[10/24] Train loss=0.6408686637878418
[15/24] Train loss=0.4872358441352844
[20/24] Train loss=0.518574595451355
Test set avg_accuracy=81.38% avg_sensitivity=92.42%, avg_specificity=77.61% avg_auc=94.27%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.550674 Test loss=0.443454 Current lr=[0.000210185142098938]

[0/24] Train loss=0.5410875082015991
[5/24] Train loss=0.48545777797698975
[10/24] Train loss=0.6133074760437012
[15/24] Train loss=0.4911074638366699
[20/24] Train loss=0.5150150656700134
Test set avg_accuracy=80.48% avg_sensitivity=92.78%, avg_specificity=76.29% avg_auc=94.30%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.538797 Test loss=0.457398 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.5149139761924744
[5/24] Train loss=0.48486489057540894
[10/24] Train loss=0.6108908653259277
[15/24] Train loss=0.45619919896125793
[20/24] Train loss=0.4923122525215149
Test set avg_accuracy=83.79% avg_sensitivity=90.99%, avg_specificity=81.33% avg_auc=94.52%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.527638 Test loss=0.363679 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.4971548616886139
[5/24] Train loss=0.44006529450416565
[10/24] Train loss=0.6050130724906921
[15/24] Train loss=0.46528521180152893
[20/24] Train loss=0.47189804911613464
Test set avg_accuracy=82.25% avg_sensitivity=91.96%, avg_specificity=78.94% avg_auc=94.20%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.517802 Test loss=0.399170 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.4975240230560303
[5/24] Train loss=0.4706641435623169
[10/24] Train loss=0.6014004349708557
[15/24] Train loss=0.4681432545185089
[20/24] Train loss=0.4635266959667206
Test set avg_accuracy=83.41% avg_sensitivity=90.48%, avg_specificity=81.00% avg_auc=94.27%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.517292 Test loss=0.383272 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.5000115036964417
[5/24] Train loss=0.4616284966468811
[10/24] Train loss=0.6055153012275696
[15/24] Train loss=0.45720571279525757
[20/24] Train loss=0.46210777759552
Test set avg_accuracy=81.67% avg_sensitivity=92.06%, avg_specificity=78.12% avg_auc=94.30%
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.508454 Test loss=0.434553 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.49492505192756653
[5/24] Train loss=0.4435715675354004
[10/24] Train loss=0.5603606700897217
[15/24] Train loss=0.430997371673584
[20/24] Train loss=0.4703522324562073
Test set avg_accuracy=82.63% avg_sensitivity=91.55%, avg_specificity=79.59% avg_auc=94.31%
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.493575 Test loss=0.416809 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.4955635964870453
[5/24] Train loss=0.4117729067802429
[10/24] Train loss=0.5096449851989746
[15/24] Train loss=0.4310119152069092
[20/24] Train loss=0.4699404835700989
Test set avg_accuracy=83.42% avg_sensitivity=87.66%, avg_specificity=81.98% avg_auc=93.94%
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.486286 Test loss=0.363318 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4652293026447296
[5/24] Train loss=0.41090500354766846
[10/24] Train loss=0.5257641673088074
[15/24] Train loss=0.42889297008514404
[20/24] Train loss=0.4200326204299927
Test set avg_accuracy=80.22% avg_sensitivity=91.76%, avg_specificity=76.29% avg_auc=93.16%
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.476844 Test loss=0.466746 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.46329042315483093
[5/24] Train loss=0.4317704141139984
[10/24] Train loss=0.5189988017082214
[15/24] Train loss=0.43035510182380676
[20/24] Train loss=0.4189758896827698
Test set avg_accuracy=82.23% avg_sensitivity=91.60%, avg_specificity=79.03% avg_auc=93.58%
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.471744 Test loss=0.407617 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.4640163779258728
[5/24] Train loss=0.3867727518081665
[10/24] Train loss=0.527375340461731
[15/24] Train loss=0.43412891030311584
[20/24] Train loss=0.4260401725769043
Test set avg_accuracy=85.48% avg_sensitivity=86.28%, avg_specificity=85.21% avg_auc=93.76%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.475700 Test loss=0.343085 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4625331163406372
[5/24] Train loss=0.4167204201221466
[10/24] Train loss=0.502153217792511
[15/24] Train loss=0.4162171483039856
[20/24] Train loss=0.41201937198638916
Test set avg_accuracy=82.64% avg_sensitivity=89.91%, avg_specificity=80.16% avg_auc=93.33%
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.464476 Test loss=0.441016 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.4601805806159973
[5/24] Train loss=0.3856838643550873
[10/24] Train loss=0.5000812411308289
[15/24] Train loss=0.4063706398010254
[20/24] Train loss=0.3942951261997223
Test set avg_accuracy=85.18% avg_sensitivity=88.27%, avg_specificity=84.13% avg_auc=94.33%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.447119 Test loss=0.340020 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.41688084602355957
[5/24] Train loss=0.38660305738449097
[10/24] Train loss=0.5031434297561646
[15/24] Train loss=0.3969449996948242
[20/24] Train loss=0.38609254360198975
Test set avg_accuracy=84.74% avg_sensitivity=88.99%, avg_specificity=83.29% avg_auc=93.95%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.438465 Test loss=0.383091 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.42721864581108093
[5/24] Train loss=0.38516342639923096
[10/24] Train loss=0.4910750985145569
[15/24] Train loss=0.42310798168182373
[20/24] Train loss=0.3827023208141327
Test set avg_accuracy=86.85% avg_sensitivity=77.73%, avg_specificity=89.96% avg_auc=93.08%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.436383 Test loss=0.305078 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4370713233947754
[5/24] Train loss=0.37399521470069885
[10/24] Train loss=0.48337486386299133
[15/24] Train loss=0.39679262042045593
[20/24] Train loss=0.3800223469734192
Test set avg_accuracy=87.97% avg_sensitivity=70.66%, avg_specificity=93.87% avg_auc=91.47%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.430523 Test loss=0.316227 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.45467862486839294
[5/24] Train loss=0.36848706007003784
[10/24] Train loss=0.46838611364364624
[15/24] Train loss=0.3935272991657257
[20/24] Train loss=0.3834473788738251
Test set avg_accuracy=88.18% avg_sensitivity=78.24%, avg_specificity=91.57% avg_auc=94.01%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.428353 Test loss=0.284483 Current lr=[0.00029967723776099]

[0/24] Train loss=0.40511974692344666
[5/24] Train loss=0.35712602734565735
[10/24] Train loss=0.45679280161857605
[15/24] Train loss=0.3968481123447418
[20/24] Train loss=0.3665708601474762
Test set avg_accuracy=84.74% avg_sensitivity=88.58%, avg_specificity=83.43% avg_auc=93.63%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.420544 Test loss=0.367881 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.4224588871002197
[5/24] Train loss=0.3862057626247406
[10/24] Train loss=0.44741472601890564
[15/24] Train loss=0.40147459506988525
[20/24] Train loss=0.37995079159736633
Test set avg_accuracy=84.10% avg_sensitivity=90.73%, avg_specificity=81.84% avg_auc=94.15%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.419656 Test loss=0.381622 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.4163965880870819
[5/24] Train loss=0.33871349692344666
[10/24] Train loss=0.44815149903297424
[15/24] Train loss=0.38111573457717896
[20/24] Train loss=0.37114641070365906
Test set avg_accuracy=84.38% avg_sensitivity=88.17%, avg_specificity=83.08% avg_auc=93.56%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.408944 Test loss=0.371537 Current lr=[0.000299720220882401]

[0/24] Train loss=0.42454004287719727
[5/24] Train loss=0.342383474111557
[10/24] Train loss=0.453008234500885
[15/24] Train loss=0.3657684922218323
[20/24] Train loss=0.3385660648345947
Test set avg_accuracy=82.41% avg_sensitivity=91.09%, avg_specificity=79.45% avg_auc=93.38%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.410172 Test loss=0.423686 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.41765567660331726
[5/24] Train loss=0.4055631458759308
[10/24] Train loss=0.4917798638343811
[15/24] Train loss=0.4064840078353882
[20/24] Train loss=0.35490357875823975
Test set avg_accuracy=82.21% avg_sensitivity=90.53%, avg_specificity=79.38% avg_auc=93.46%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.422041 Test loss=0.416895 Current lr=[0.000298904600941902]

[0/24] Train loss=0.39318951964378357
[5/24] Train loss=0.337685227394104
[10/24] Train loss=0.4223017692565918
[15/24] Train loss=0.37420958280563354
[20/24] Train loss=0.36477699875831604
Test set avg_accuracy=66.59% avg_sensitivity=95.44%, avg_specificity=56.75% avg_auc=92.32%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.405221 Test loss=0.744535 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3973245918750763
[5/24] Train loss=0.34018269181251526
[10/24] Train loss=0.4170023500919342
[15/24] Train loss=0.367697149515152
[20/24] Train loss=0.368236243724823
Test set avg_accuracy=76.89% avg_sensitivity=92.83%, avg_specificity=71.45% avg_auc=92.56%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.406215 Test loss=0.550665 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3885495960712433
[5/24] Train loss=0.3427012264728546
[10/24] Train loss=0.39289915561676025
[15/24] Train loss=0.34181007742881775
[20/24] Train loss=0.3433677852153778
Test set avg_accuracy=71.46% avg_sensitivity=93.91%, avg_specificity=63.80% avg_auc=91.27%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.383334 Test loss=0.691709 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3878267705440521
[5/24] Train loss=0.31611496210098267
[10/24] Train loss=0.4334713816642761
[15/24] Train loss=0.3418416976928711
[20/24] Train loss=0.3571685254573822
Test set avg_accuracy=81.20% avg_sensitivity=91.71%, avg_specificity=77.61% avg_auc=92.95%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.391927 Test loss=0.461444 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3828422427177429
[5/24] Train loss=0.33214762806892395
[10/24] Train loss=0.41450560092926025
[15/24] Train loss=0.36730390787124634
[20/24] Train loss=0.35879385471343994
Test set avg_accuracy=77.68% avg_sensitivity=91.96%, avg_specificity=72.81% avg_auc=92.08%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.388216 Test loss=0.556455 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.36296623945236206
[5/24] Train loss=0.3083970844745636
[10/24] Train loss=0.37691304087638855
[15/24] Train loss=0.34559541940689087
[20/24] Train loss=0.3356397747993469
Test set avg_accuracy=79.92% avg_sensitivity=89.96%, avg_specificity=76.50% avg_auc=91.34%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.370074 Test loss=0.508259 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.39728549122810364
[5/24] Train loss=0.34741300344467163
[10/24] Train loss=0.3600979447364807
[15/24] Train loss=0.34359440207481384
[20/24] Train loss=0.31957557797431946
Test set avg_accuracy=84.28% avg_sensitivity=88.84%, avg_specificity=82.73% avg_auc=93.67%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.378371 Test loss=0.383105 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.36600738763809204
[5/24] Train loss=0.3197406530380249
[10/24] Train loss=0.3569115400314331
[15/24] Train loss=0.3192366361618042
[20/24] Train loss=0.3092353940010071
Test set avg_accuracy=85.36% avg_sensitivity=81.72%, avg_specificity=86.61% avg_auc=92.49%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.361029 Test loss=0.366815 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3832912743091583
[5/24] Train loss=0.2959774136543274
[10/24] Train loss=0.3755747675895691
[15/24] Train loss=0.33665117621421814
[20/24] Train loss=0.31001633405685425
Test set avg_accuracy=84.83% avg_sensitivity=84.54%, avg_specificity=84.93% avg_auc=92.33%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.356159 Test loss=0.386110 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.36520451307296753
[5/24] Train loss=0.3234465420246124
[10/24] Train loss=0.3755630552768707
[15/24] Train loss=0.3055139183998108
[20/24] Train loss=0.2938906252384186
Test set avg_accuracy=86.97% avg_sensitivity=80.03%, avg_specificity=89.33% avg_auc=92.99%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.365516 Test loss=0.318235 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3558567464351654
[5/24] Train loss=0.33211392164230347
[10/24] Train loss=0.3807523250579834
[15/24] Train loss=0.3433312177658081
[20/24] Train loss=0.3043466806411743
Test set avg_accuracy=71.35% avg_sensitivity=92.47%, avg_specificity=64.15% avg_auc=90.08%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.360109 Test loss=0.763014 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3575344383716583
[5/24] Train loss=0.3191894590854645
[10/24] Train loss=0.34904271364212036
[15/24] Train loss=0.34666767716407776
[20/24] Train loss=0.3068505525588989
Test set avg_accuracy=86.58% avg_sensitivity=77.47%, avg_specificity=89.68% avg_auc=92.96%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.362566 Test loss=0.317602 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.37079936265945435
[5/24] Train loss=0.295436292886734
[10/24] Train loss=0.360912024974823
[15/24] Train loss=0.3205660581588745
[20/24] Train loss=0.3131207823753357
Test set avg_accuracy=81.97% avg_sensitivity=90.07%, avg_specificity=79.20% avg_auc=93.56%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.347959 Test loss=0.455496 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3342944383621216
[5/24] Train loss=0.3090377449989319
[10/24] Train loss=0.3421439230442047
[15/24] Train loss=0.30880120396614075
[20/24] Train loss=0.3060089647769928
Test set avg_accuracy=86.17% avg_sensitivity=73.22%, avg_specificity=90.59% avg_auc=91.61%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.339908 Test loss=0.334828 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3952697813510895
[5/24] Train loss=0.2921431362628937
[10/24] Train loss=0.3425751030445099
[15/24] Train loss=0.3214552700519562
[20/24] Train loss=0.3003692328929901
Test set avg_accuracy=87.58% avg_sensitivity=75.42%, avg_specificity=91.72% avg_auc=93.06%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.344856 Test loss=0.303674 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3210804760456085
[5/24] Train loss=0.2964712977409363
[10/24] Train loss=0.32128584384918213
[15/24] Train loss=0.31847459077835083
[20/24] Train loss=0.32131093740463257
Test set avg_accuracy=87.21% avg_sensitivity=78.29%, avg_specificity=90.26% avg_auc=92.73%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.338641 Test loss=0.323972 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3792639672756195
[5/24] Train loss=0.29101306200027466
[10/24] Train loss=0.3348781168460846
[15/24] Train loss=0.33135634660720825
[20/24] Train loss=0.3174584209918976
Test set avg_accuracy=87.20% avg_sensitivity=69.48%, avg_specificity=93.24% avg_auc=90.87%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.346280 Test loss=0.349043 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.34984520077705383
[5/24] Train loss=0.30963587760925293
[10/24] Train loss=0.347394198179245
[15/24] Train loss=0.3098805844783783
[20/24] Train loss=0.29788878560066223
Test set avg_accuracy=88.28% avg_sensitivity=71.53%, avg_specificity=93.99% avg_auc=91.65%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.339062 Test loss=0.322663 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.36417317390441895
[5/24] Train loss=0.31209221482276917
[10/24] Train loss=0.3431897759437561
[15/24] Train loss=0.3023685812950134
[20/24] Train loss=0.29313886165618896
Test set avg_accuracy=88.54% avg_sensitivity=70.61%, avg_specificity=94.66% avg_auc=92.34%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.339219 Test loss=0.300096 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.34850895404815674
[5/24] Train loss=0.3287181258201599
[10/24] Train loss=0.32308128476142883
[15/24] Train loss=0.3175657391548157
[20/24] Train loss=0.2924394905567169
Test set avg_accuracy=88.06% avg_sensitivity=71.43%, avg_specificity=93.73% avg_auc=91.33%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.331792 Test loss=0.323015 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.33843475580215454
[5/24] Train loss=0.30629482865333557
[10/24] Train loss=0.32268136739730835
[15/24] Train loss=0.29526135325431824
[20/24] Train loss=0.3003571629524231
Test set avg_accuracy=87.70% avg_sensitivity=74.50%, avg_specificity=92.19% avg_auc=92.34%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.329434 Test loss=0.320995 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.362016499042511
[5/24] Train loss=0.2621404528617859
[10/24] Train loss=0.3152415156364441
[15/24] Train loss=0.2935698926448822
[20/24] Train loss=0.3018857538700104
Test set avg_accuracy=88.27% avg_sensitivity=67.90%, avg_specificity=95.22% avg_auc=91.93%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.314916 Test loss=0.309227 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.363616943359375
[5/24] Train loss=0.2753562927246094
[10/24] Train loss=0.3000675141811371
[15/24] Train loss=0.30329805612564087
[20/24] Train loss=0.30897319316864014
Test set avg_accuracy=88.11% avg_sensitivity=73.22%, avg_specificity=93.19% avg_auc=91.45%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.322729 Test loss=0.326435 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.34540867805480957
[5/24] Train loss=0.27261093258857727
[10/24] Train loss=0.3233591914176941
[15/24] Train loss=0.2957850992679596
[20/24] Train loss=0.28602492809295654
Test set avg_accuracy=87.66% avg_sensitivity=83.46%, avg_specificity=89.09% avg_auc=93.84%
Best model saved!! Metric=28.042729151987174!!
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.324973 Test loss=0.319438 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3313589096069336
[5/24] Train loss=0.29462748765945435
[10/24] Train loss=0.32102981209754944
[15/24] Train loss=0.29109448194503784
[20/24] Train loss=0.3095053434371948
Test set avg_accuracy=88.49% avg_sensitivity=75.78%, avg_specificity=92.82% avg_auc=92.81%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.321187 Test loss=0.302988 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.36284294724464417
[5/24] Train loss=0.26359301805496216
[10/24] Train loss=0.3220416307449341
[15/24] Train loss=0.29115983843803406
[20/24] Train loss=0.28786298632621765
Test set avg_accuracy=87.84% avg_sensitivity=73.22%, avg_specificity=92.82% avg_auc=93.07%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.324699 Test loss=0.299264 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3291708827018738
[5/24] Train loss=0.26478320360183716
[10/24] Train loss=0.3134992718696594
[15/24] Train loss=0.2794469892978668
[20/24] Train loss=0.28361791372299194
Test set avg_accuracy=85.96% avg_sensitivity=82.54%, avg_specificity=87.13% avg_auc=92.80%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.301444 Test loss=0.407715 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.33752012252807617
[5/24] Train loss=0.2790125012397766
[10/24] Train loss=0.3593684136867523
[15/24] Train loss=0.2954544425010681
[20/24] Train loss=0.2642521262168884
Test set avg_accuracy=87.68% avg_sensitivity=79.83%, avg_specificity=90.36% avg_auc=93.88%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.306621 Test loss=0.329023 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3128950595855713
[5/24] Train loss=0.2617209553718567
[10/24] Train loss=0.2842932939529419
[15/24] Train loss=0.2639309763908386
[20/24] Train loss=0.2631266713142395
Test set avg_accuracy=86.98% avg_sensitivity=84.69%, avg_specificity=87.76% avg_auc=93.59%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.293246 Test loss=0.360683 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3060664236545563
[5/24] Train loss=0.2624121904373169
[10/24] Train loss=0.31349724531173706
[15/24] Train loss=0.2784512937068939
[20/24] Train loss=0.27387842535972595
Test set avg_accuracy=87.77% avg_sensitivity=82.59%, avg_specificity=89.54% avg_auc=93.74%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.294505 Test loss=0.321082 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3116822838783264
[5/24] Train loss=0.2609598636627197
[10/24] Train loss=0.27979403734207153
[15/24] Train loss=0.2659178078174591
[20/24] Train loss=0.24695461988449097
Test set avg_accuracy=87.68% avg_sensitivity=64.87%, avg_specificity=95.46% avg_auc=91.18%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.280137 Test loss=0.330411 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3129735589027405
[5/24] Train loss=0.2571919858455658
[10/24] Train loss=0.27539166808128357
[15/24] Train loss=0.24738016724586487
[20/24] Train loss=0.24296049773693085
Test set avg_accuracy=87.67% avg_sensitivity=75.01%, avg_specificity=91.99% avg_auc=93.54%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.276722 Test loss=0.305280 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3106381893157959
[5/24] Train loss=0.25131282210350037
[10/24] Train loss=0.25409260392189026
[15/24] Train loss=0.2579849362373352
[20/24] Train loss=0.24539446830749512
Test set avg_accuracy=78.31% avg_sensitivity=93.65%, avg_specificity=73.07% avg_auc=92.40%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.276950 Test loss=0.609983 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3079933822154999
[5/24] Train loss=0.2555263638496399
[10/24] Train loss=0.27453500032424927
[15/24] Train loss=0.25986456871032715
[20/24] Train loss=0.2555401921272278
Test set avg_accuracy=88.15% avg_sensitivity=73.07%, avg_specificity=93.29% avg_auc=92.39%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.276818 Test loss=0.318314 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.27945953607559204
[5/24] Train loss=0.23110590875148773
[10/24] Train loss=0.26585936546325684
[15/24] Train loss=0.2530363202095032
[20/24] Train loss=0.25624749064445496
Test set avg_accuracy=87.88% avg_sensitivity=81.57%, avg_specificity=90.03% avg_auc=93.31%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.265536 Test loss=0.317778 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3106817305088043
[5/24] Train loss=0.24424324929714203
[10/24] Train loss=0.2784000039100647
[15/24] Train loss=0.25855982303619385
[20/24] Train loss=0.2375289350748062
Test set avg_accuracy=87.51% avg_sensitivity=72.56%, avg_specificity=92.61% avg_auc=92.59%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.269501 Test loss=0.308509 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2874923050403595
[5/24] Train loss=0.23595839738845825
[10/24] Train loss=0.2706596851348877
[15/24] Train loss=0.2458765208721161
[20/24] Train loss=0.22569450736045837
Test set avg_accuracy=88.37% avg_sensitivity=70.35%, avg_specificity=94.52% avg_auc=92.60%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.260113 Test loss=0.309287 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2882232964038849
[5/24] Train loss=0.23892806470394135
[10/24] Train loss=0.25618162751197815
[15/24] Train loss=0.23271290957927704
[20/24] Train loss=0.23212221264839172
Test set avg_accuracy=88.57% avg_sensitivity=73.17%, avg_specificity=93.82% avg_auc=92.62%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.252892 Test loss=0.311873 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2802366018295288
[5/24] Train loss=0.24068857729434967
[10/24] Train loss=0.25871583819389343
[15/24] Train loss=0.22460997104644775
[20/24] Train loss=0.2367885708808899
Test set avg_accuracy=88.71% avg_sensitivity=72.04%, avg_specificity=94.39% avg_auc=92.61%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.253920 Test loss=0.305015 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.262479305267334
[5/24] Train loss=0.23831896483898163
[10/24] Train loss=0.2510141134262085
[15/24] Train loss=0.21380066871643066
[20/24] Train loss=0.21311402320861816
Test set avg_accuracy=88.06% avg_sensitivity=80.95%, avg_specificity=90.48% avg_auc=93.52%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.249454 Test loss=0.325228 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2579578459262848
[5/24] Train loss=0.2306852787733078
[10/24] Train loss=0.24417555332183838
[15/24] Train loss=0.21638187766075134
[20/24] Train loss=0.23161093890666962
Test set avg_accuracy=88.23% avg_sensitivity=68.77%, avg_specificity=94.87% avg_auc=91.84%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.246497 Test loss=0.320101 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2673397958278656
[5/24] Train loss=0.21783415973186493
[10/24] Train loss=0.241410031914711
[15/24] Train loss=0.2204924076795578
[20/24] Train loss=0.22587500512599945
Test set avg_accuracy=87.72% avg_sensitivity=66.36%, avg_specificity=95.01% avg_auc=91.03%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.244743 Test loss=0.335485 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.25247839093208313
[5/24] Train loss=0.23241397738456726
[10/24] Train loss=0.23158280551433563
[15/24] Train loss=0.22246596217155457
[20/24] Train loss=0.21938855946063995
Test set avg_accuracy=88.57% avg_sensitivity=72.61%, avg_specificity=94.01% avg_auc=92.18%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.240622 Test loss=0.318181 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2565285265445709
[5/24] Train loss=0.22158890962600708
[10/24] Train loss=0.2520194947719574
[15/24] Train loss=0.2227097600698471
[20/24] Train loss=0.2516215741634369
Test set avg_accuracy=85.21% avg_sensitivity=83.61%, avg_specificity=85.75% avg_auc=92.82%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.241415 Test loss=0.398174 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.24624820053577423
[5/24] Train loss=0.2212415635585785
[10/24] Train loss=0.233002170920372
[15/24] Train loss=0.22298191487789154
[20/24] Train loss=0.22262850403785706
Test set avg_accuracy=88.53% avg_sensitivity=77.62%, avg_specificity=92.25% avg_auc=92.20%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.240759 Test loss=0.321939 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2659999430179596
[5/24] Train loss=0.22816960513591766
[10/24] Train loss=0.23731142282485962
[15/24] Train loss=0.21523477137088776
[20/24] Train loss=0.22995877265930176
Test set avg_accuracy=87.64% avg_sensitivity=69.12%, avg_specificity=93.96% avg_auc=92.09%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.243799 Test loss=0.313390 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.26246342062950134
[5/24] Train loss=0.22773677110671997
[10/24] Train loss=0.23356257379055023
[15/24] Train loss=0.2183893322944641
[20/24] Train loss=0.21723805367946625
Test set avg_accuracy=87.86% avg_sensitivity=74.60%, avg_specificity=92.39% avg_auc=93.17%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.242364 Test loss=0.317010 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2504797875881195
[5/24] Train loss=0.2245912253856659
[10/24] Train loss=0.23901823163032532
[15/24] Train loss=0.2350461781024933
[20/24] Train loss=0.22574934363365173
Test set avg_accuracy=87.41% avg_sensitivity=76.50%, avg_specificity=91.13% avg_auc=91.51%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.244272 Test loss=0.352997 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.24587956070899963
[5/24] Train loss=0.23896387219429016
[10/24] Train loss=0.23674599826335907
[15/24] Train loss=0.22112582623958588
[20/24] Train loss=0.22467124462127686
Test set avg_accuracy=87.71% avg_sensitivity=76.19%, avg_specificity=91.64% avg_auc=93.15%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.243524 Test loss=0.312290 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2430873066186905
[5/24] Train loss=0.21767474710941315
[10/24] Train loss=0.2506263852119446
[15/24] Train loss=0.21817733347415924
[20/24] Train loss=0.2163294553756714
Test set avg_accuracy=87.55% avg_sensitivity=71.22%, avg_specificity=93.12% avg_auc=91.87%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.238765 Test loss=0.327138 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.26838868856430054
[5/24] Train loss=0.2677270770072937
[10/24] Train loss=0.2623250186443329
[15/24] Train loss=0.21536122262477875
[20/24] Train loss=0.22821013629436493
Test set avg_accuracy=87.46% avg_sensitivity=68.36%, avg_specificity=93.98% avg_auc=90.47%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.241504 Test loss=0.335524 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.23865078389644623
[5/24] Train loss=0.22306281328201294
[10/24] Train loss=0.2336024045944214
[15/24] Train loss=0.21046900749206543
[20/24] Train loss=0.22543856501579285
Test set avg_accuracy=87.62% avg_sensitivity=71.27%, avg_specificity=93.19% avg_auc=91.77%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.234825 Test loss=0.323892 Current lr=[0.000134135431043539]

[0/24] Train loss=0.24793747067451477
[5/24] Train loss=0.2164248377084732
[10/24] Train loss=0.22586590051651
[15/24] Train loss=0.2198537290096283
[20/24] Train loss=0.20991066098213196
Test set avg_accuracy=88.09% avg_sensitivity=78.03%, avg_specificity=91.51% avg_auc=93.24%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.228197 Test loss=0.321796 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.24068903923034668
[5/24] Train loss=0.2097282111644745
[10/24] Train loss=0.2194381207227707
[15/24] Train loss=0.20471695065498352
[20/24] Train loss=0.2277596890926361
Test set avg_accuracy=88.10% avg_sensitivity=70.87%, avg_specificity=93.98% avg_auc=92.43%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.225927 Test loss=0.315834 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.24116170406341553
[5/24] Train loss=0.2107897847890854
[10/24] Train loss=0.21839547157287598
[15/24] Train loss=0.21349406242370605
[20/24] Train loss=0.2104882150888443
Test set avg_accuracy=87.12% avg_sensitivity=81.67%, avg_specificity=88.98% avg_auc=93.23%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.230115 Test loss=0.348126 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.2364705204963684
[5/24] Train loss=0.2626635432243347
[10/24] Train loss=0.24044296145439148
[15/24] Train loss=0.22065071761608124
[20/24] Train loss=0.22417768836021423
Test set avg_accuracy=87.58% avg_sensitivity=78.75%, avg_specificity=90.59% avg_auc=92.96%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.231825 Test loss=0.335835 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.23987644910812378
[5/24] Train loss=0.21671061217784882
[10/24] Train loss=0.22692370414733887
[15/24] Train loss=0.20615039765834808
[20/24] Train loss=0.21802644431591034
Test set avg_accuracy=88.01% avg_sensitivity=76.50%, avg_specificity=91.93% avg_auc=93.32%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.225436 Test loss=0.308413 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.23986230790615082
[5/24] Train loss=0.20798026025295258
[10/24] Train loss=0.21836835145950317
[15/24] Train loss=0.1982911229133606
[20/24] Train loss=0.20983529090881348
Test set avg_accuracy=88.01% avg_sensitivity=75.27%, avg_specificity=92.35% avg_auc=92.89%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.217698 Test loss=0.327332 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.23401334881782532
[5/24] Train loss=0.20690962672233582
[10/24] Train loss=0.225600928068161
[15/24] Train loss=0.1971154510974884
[20/24] Train loss=0.20907536149024963
Test set avg_accuracy=86.59% avg_sensitivity=83.31%, avg_specificity=87.71% avg_auc=93.27%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.215728 Test loss=0.364400 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.23162375390529633
[5/24] Train loss=0.19259010255336761
[10/24] Train loss=0.21366117894649506
[15/24] Train loss=0.20711073279380798
[20/24] Train loss=0.21121937036514282
Test set avg_accuracy=88.61% avg_sensitivity=78.34%, avg_specificity=92.11% avg_auc=93.38%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.213641 Test loss=0.308942 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.22697360813617706
[5/24] Train loss=0.2026611864566803
[10/24] Train loss=0.19897130131721497
[15/24] Train loss=0.19255289435386658
[20/24] Train loss=0.19672714173793793
Test set avg_accuracy=87.42% avg_sensitivity=82.13%, avg_specificity=89.23% avg_auc=93.32%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.207438 Test loss=0.345497 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.2179446816444397
[5/24] Train loss=0.20500990748405457
[10/24] Train loss=0.19973066449165344
[15/24] Train loss=0.18541201949119568
[20/24] Train loss=0.18883593380451202
Test set avg_accuracy=88.78% avg_sensitivity=75.22%, avg_specificity=93.40% avg_auc=93.26%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.200798 Test loss=0.311048 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.21442541480064392
[5/24] Train loss=0.1909613460302353
[10/24] Train loss=0.1894688606262207
[15/24] Train loss=0.18182764947414398
[20/24] Train loss=0.1951545774936676
Test set avg_accuracy=87.92% avg_sensitivity=79.72%, avg_specificity=90.71% avg_auc=93.33%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.198236 Test loss=0.325390 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.21248824894428253
[5/24] Train loss=0.18147549033164978
[10/24] Train loss=0.19969098269939423
[15/24] Train loss=0.18649636209011078
[20/24] Train loss=0.18760176002979279
Test set avg_accuracy=88.07% avg_sensitivity=79.01%, avg_specificity=91.16% avg_auc=93.29%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.195615 Test loss=0.326737 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.21485765278339386
[5/24] Train loss=0.1788673996925354
[10/24] Train loss=0.18897683918476105
[15/24] Train loss=0.17502525448799133
[20/24] Train loss=0.18353988230228424
Test set avg_accuracy=88.22% avg_sensitivity=79.93%, avg_specificity=91.04% avg_auc=93.17%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.191914 Test loss=0.325812 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.20209506154060364
[5/24] Train loss=0.1774444282054901
[10/24] Train loss=0.18392881751060486
[15/24] Train loss=0.17876167595386505
[20/24] Train loss=0.1819225698709488
Test set avg_accuracy=87.92% avg_sensitivity=80.39%, avg_specificity=90.48% avg_auc=93.36%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.191064 Test loss=0.331051 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.2088000774383545
[5/24] Train loss=0.178045853972435
[10/24] Train loss=0.18062227964401245
[15/24] Train loss=0.18274882435798645
[20/24] Train loss=0.18956208229064941
Test set avg_accuracy=87.54% avg_sensitivity=81.46%, avg_specificity=89.61% avg_auc=93.27%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.189755 Test loss=0.346025 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.20120251178741455
[5/24] Train loss=0.17636558413505554
[10/24] Train loss=0.1917654424905777
[15/24] Train loss=0.16899923980236053
[20/24] Train loss=0.18011529743671417
Test set avg_accuracy=87.43% avg_sensitivity=81.52%, avg_specificity=89.45% avg_auc=93.29%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.188308 Test loss=0.350495 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.19758813083171844
[5/24] Train loss=0.18426045775413513
[10/24] Train loss=0.1840750277042389
[15/24] Train loss=0.17551112174987793
[20/24] Train loss=0.18205958604812622
Test set avg_accuracy=88.44% avg_sensitivity=76.65%, avg_specificity=92.46% avg_auc=93.26%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.187087 Test loss=0.316153 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.19626694917678833
[5/24] Train loss=0.1713787168264389
[10/24] Train loss=0.1902838498353958
[15/24] Train loss=0.17038118839263916
[20/24] Train loss=0.175227552652359
Test set avg_accuracy=88.12% avg_sensitivity=77.37%, avg_specificity=91.79% avg_auc=92.93%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.183884 Test loss=0.325632 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.19909535348415375
[5/24] Train loss=0.17366182804107666
[10/24] Train loss=0.18318906426429749
[15/24] Train loss=0.17194955050945282
[20/24] Train loss=0.17905071377754211
Test set avg_accuracy=88.48% avg_sensitivity=76.70%, avg_specificity=92.49% avg_auc=93.19%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.181464 Test loss=0.316613 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.19171525537967682
[5/24] Train loss=0.17109562456607819
[10/24] Train loss=0.176537424325943
[15/24] Train loss=0.16753748059272766
[20/24] Train loss=0.1766924262046814
Test set avg_accuracy=88.40% avg_sensitivity=76.40%, avg_specificity=92.49% avg_auc=93.24%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.181102 Test loss=0.317388 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1941039115190506
[5/24] Train loss=0.1712283194065094
[10/24] Train loss=0.17520689964294434
[15/24] Train loss=0.16765370965003967
[20/24] Train loss=0.17669892311096191
Test set avg_accuracy=88.10% avg_sensitivity=77.11%, avg_specificity=91.85% avg_auc=92.87%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.179377 Test loss=0.320955 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.19731885194778442
[5/24] Train loss=0.1725786030292511
[10/24] Train loss=0.17508596181869507
[15/24] Train loss=0.17501485347747803
[20/24] Train loss=0.17269198596477509
Test set avg_accuracy=88.33% avg_sensitivity=77.88%, avg_specificity=91.90% avg_auc=93.19%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.179290 Test loss=0.319373 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.18907541036605835
[5/24] Train loss=0.17188525199890137
[10/24] Train loss=0.17641960084438324
[15/24] Train loss=0.16638518869876862
[20/24] Train loss=0.17213450372219086
Test set avg_accuracy=88.87% avg_sensitivity=77.88%, avg_specificity=92.61% avg_auc=93.00%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.178479 Test loss=0.315676 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.19140690565109253
[5/24] Train loss=0.17477399110794067
[10/24] Train loss=0.17343461513519287
[15/24] Train loss=0.17345571517944336
[20/24] Train loss=0.1762038618326187
Test set avg_accuracy=88.05% avg_sensitivity=79.52%, avg_specificity=90.96% avg_auc=93.15%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.178490 Test loss=0.324925 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.190585196018219
[5/24] Train loss=0.16778366267681122
[10/24] Train loss=0.1693870574235916
[15/24] Train loss=0.1692885458469391
[20/24] Train loss=0.17111706733703613
Test set avg_accuracy=87.68% avg_sensitivity=81.46%, avg_specificity=89.80% avg_auc=93.18%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.176888 Test loss=0.337425 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.18708649277687073
[5/24] Train loss=0.17071247100830078
[10/24] Train loss=0.16829100251197815
[15/24] Train loss=0.16918981075286865
[20/24] Train loss=0.16790181398391724
Test set avg_accuracy=87.41% avg_sensitivity=81.62%, avg_specificity=89.38% avg_auc=93.48%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.175569 Test loss=0.340940 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.18967978656291962
[5/24] Train loss=0.1727799028158188
[10/24] Train loss=0.1661182940006256
[15/24] Train loss=0.1650654524564743
[20/24] Train loss=0.16897423565387726
Test set avg_accuracy=87.24% avg_sensitivity=79.93%, avg_specificity=89.73% avg_auc=93.53%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.175978 Test loss=0.330203 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.18675413727760315
[5/24] Train loss=0.1661306768655777
[10/24] Train loss=0.17490121722221375
[15/24] Train loss=0.16033348441123962
[20/24] Train loss=0.17470043897628784
Test set avg_accuracy=87.57% avg_sensitivity=78.39%, avg_specificity=90.69% avg_auc=93.44%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.175551 Test loss=0.321443 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1815534383058548
[5/24] Train loss=0.15959078073501587
[10/24] Train loss=0.176526740193367
[15/24] Train loss=0.16090285778045654
[20/24] Train loss=0.166591078042984
Test set avg_accuracy=87.64% avg_sensitivity=77.73%, avg_specificity=91.02% avg_auc=93.15%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.172894 Test loss=0.319155 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1873241513967514
[5/24] Train loss=0.16401037573814392
[10/24] Train loss=0.17011256515979767
[15/24] Train loss=0.1655573844909668
[20/24] Train loss=0.1686309278011322
Test set avg_accuracy=87.57% avg_sensitivity=79.37%, avg_specificity=90.36% avg_auc=93.11%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.172988 Test loss=0.327419 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.18252314627170563
[5/24] Train loss=0.15984386205673218
[10/24] Train loss=0.16388754546642303
[15/24] Train loss=0.1603047102689743
[20/24] Train loss=0.1669876128435135
Test set avg_accuracy=87.17% avg_sensitivity=78.96%, avg_specificity=89.98% avg_auc=93.37%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.168933 Test loss=0.327341 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1816181242465973
[5/24] Train loss=0.1591571718454361
[10/24] Train loss=0.1646718531847
[15/24] Train loss=0.16234980523586273
[20/24] Train loss=0.16440579295158386
Test set avg_accuracy=87.42% avg_sensitivity=79.37%, avg_specificity=90.17% avg_auc=93.45%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.167568 Test loss=0.322609 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.17727836966514587
[5/24] Train loss=0.1577194184064865
[10/24] Train loss=0.16469307243824005
[15/24] Train loss=0.15631695091724396
[20/24] Train loss=0.16520513594150543
Test set avg_accuracy=87.75% avg_sensitivity=77.68%, avg_specificity=91.18% avg_auc=93.23%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.166063 Test loss=0.321085 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.18000365793704987
[5/24] Train loss=0.15824788808822632
[10/24] Train loss=0.16542865335941315
[15/24] Train loss=0.15633580088615417
[20/24] Train loss=0.16688260436058044
Test set avg_accuracy=87.63% avg_sensitivity=78.65%, avg_specificity=90.69% avg_auc=93.35%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.166543 Test loss=0.319725 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1744713932275772
[5/24] Train loss=0.16134968400001526
[10/24] Train loss=0.16014863550662994
[15/24] Train loss=0.15450893342494965
[20/24] Train loss=0.15897074341773987
Test set avg_accuracy=87.58% avg_sensitivity=78.29%, avg_specificity=90.75% avg_auc=93.31%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.165164 Test loss=0.320597 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.18125490844249725
[5/24] Train loss=0.15690484642982483
[10/24] Train loss=0.1605793982744217
[15/24] Train loss=0.15652145445346832
[20/24] Train loss=0.16289250552654266
Test set avg_accuracy=87.54% avg_sensitivity=78.34%, avg_specificity=90.68% avg_auc=93.27%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.164936 Test loss=0.323457 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1829322725534439
[5/24] Train loss=0.15682440996170044
[10/24] Train loss=0.16393525898456573
[15/24] Train loss=0.15767315030097961
[20/24] Train loss=0.15894751250743866
Test set avg_accuracy=87.60% avg_sensitivity=78.14%, avg_specificity=90.83% avg_auc=93.38%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.164198 Test loss=0.320846 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.17427381873130798
[5/24] Train loss=0.15480457246303558
[10/24] Train loss=0.1617116630077362
[15/24] Train loss=0.1503564417362213
[20/24] Train loss=0.1596866101026535
Test set avg_accuracy=87.76% avg_sensitivity=77.42%, avg_specificity=91.29% avg_auc=93.26%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.163703 Test loss=0.320066 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.17163115739822388
[5/24] Train loss=0.15427245199680328
[10/24] Train loss=0.15877598524093628
[15/24] Train loss=0.15446777641773224
[20/24] Train loss=0.15971948206424713
Test set avg_accuracy=87.54% avg_sensitivity=78.19%, avg_specificity=90.73% avg_auc=93.30%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.163775 Test loss=0.320822 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.17622466385364532
[5/24] Train loss=0.15762732923030853
[10/24] Train loss=0.16579318046569824
[15/24] Train loss=0.15159085392951965
[20/24] Train loss=0.1609582006931305
Test set avg_accuracy=87.49% avg_sensitivity=78.49%, avg_specificity=90.55% avg_auc=93.31%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.163881 Test loss=0.322111 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.17579369246959686
[5/24] Train loss=0.15649500489234924
[10/24] Train loss=0.1590738594532013
[15/24] Train loss=0.1530522108078003
[20/24] Train loss=0.15957804024219513
Test set avg_accuracy=87.60% avg_sensitivity=77.73%, avg_specificity=90.97% avg_auc=93.27%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.163188 Test loss=0.319612 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.17091971635818481
[5/24] Train loss=0.15619489550590515
[10/24] Train loss=0.16242440044879913
[15/24] Train loss=0.15104015171527863
[20/24] Train loss=0.1614944338798523
Test set avg_accuracy=87.58% avg_sensitivity=77.47%, avg_specificity=91.02% avg_auc=93.23%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.163406 Test loss=0.320384 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.17286932468414307
[5/24] Train loss=0.15740910172462463
[10/24] Train loss=0.16096264123916626
[15/24] Train loss=0.15737847983837128
[20/24] Train loss=0.15820325911045074
Test set avg_accuracy=87.64% avg_sensitivity=77.98%, avg_specificity=90.94% avg_auc=93.28%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.162491 Test loss=0.320956 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.17288453876972198
[5/24] Train loss=0.15705199539661407
[10/24] Train loss=0.16078317165374756
[15/24] Train loss=0.15253254771232605
[20/24] Train loss=0.1567830890417099
Test set avg_accuracy=87.72% avg_sensitivity=78.19%, avg_specificity=90.97% avg_auc=93.31%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.162793 Test loss=0.319997 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.17452648282051086
[5/24] Train loss=0.15715977549552917
[10/24] Train loss=0.15922564268112183
[15/24] Train loss=0.15458974242210388
[20/24] Train loss=0.16370436549186707
Test set avg_accuracy=87.67% avg_sensitivity=77.88%, avg_specificity=91.01% avg_auc=93.30%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.163381 Test loss=0.319957 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1746029108762741
[5/24] Train loss=0.1535404920578003
[10/24] Train loss=0.1642070859670639
[15/24] Train loss=0.1510719358921051
[20/24] Train loss=0.15875883400440216
Test set avg_accuracy=87.76% avg_sensitivity=78.14%, avg_specificity=91.04% avg_auc=93.31%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.162518 Test loss=0.319876 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.17467136681079865
[5/24] Train loss=0.15476948022842407
[10/24] Train loss=0.16032098233699799
[15/24] Train loss=0.1525295376777649
[20/24] Train loss=0.15915517508983612
Test set avg_accuracy=87.71% avg_sensitivity=77.98%, avg_specificity=91.02% avg_auc=93.31%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.163235 Test loss=0.319827 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1741035282611847
[5/24] Train loss=0.15600140392780304
[10/24] Train loss=0.15771928429603577
[15/24] Train loss=0.15458723902702332
[20/24] Train loss=0.16182029247283936
Test set avg_accuracy=87.73% avg_sensitivity=78.08%, avg_specificity=91.02% avg_auc=93.31%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.162853 Test loss=0.319720 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.17608094215393066
[5/24] Train loss=0.15503829717636108
[10/24] Train loss=0.15675319731235504
[15/24] Train loss=0.1551026701927185
[20/24] Train loss=0.16000258922576904
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=87.73% avg_sensitivity=78.14%, avg_specificity=91.01% avg_auc=93.31%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.163292 Test loss=0.320093 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=87.66% sen=83.46%, spe=89.09%, auc=93.84%!
Fold[5] Avg_overlap=0.63%(0.2133200127157723)
[0/24] Train loss=1.4560514688491821
[5/24] Train loss=1.4647808074951172
[10/24] Train loss=1.4322490692138672
[15/24] Train loss=1.4188635349273682
[20/24] Train loss=1.3848881721496582
Test set avg_accuracy=59.61% avg_sensitivity=65.88%, avg_specificity=57.27% avg_auc=58.19%
Best model saved!! Metric=-85.04435559177176!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=1.430584 Test loss=0.678931 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.377267837524414
[5/24] Train loss=1.36045241355896
[10/24] Train loss=1.368288278579712
[15/24] Train loss=1.3233110904693604
[20/24] Train loss=1.307672142982483
Test set avg_accuracy=72.36% avg_sensitivity=74.81%, avg_specificity=71.44% avg_auc=72.52%
Best model saved!! Metric=-34.87153918108608!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=1.356487 Test loss=0.605980 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.2792540788650513
[5/24] Train loss=1.305932641029358
[10/24] Train loss=1.3046585321426392
[15/24] Train loss=1.2279397249221802
[20/24] Train loss=1.2415335178375244
Test set avg_accuracy=74.83% avg_sensitivity=79.65%, avg_specificity=73.03% avg_auc=79.07%
Best model saved!! Metric=-19.411954975694385!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=1.282146 Test loss=0.573700 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.219761610031128
[5/24] Train loss=1.237862467765808
[10/24] Train loss=1.2212172746658325
[15/24] Train loss=1.1778366565704346
[20/24] Train loss=1.1583763360977173
Test set avg_accuracy=74.82% avg_sensitivity=83.49%, avg_specificity=71.59% avg_auc=82.67%
Best model saved!! Metric=-13.43224158976777!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=1.213569 Test loss=0.548478 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.131334662437439
[5/24] Train loss=1.1324448585510254
[10/24] Train loss=1.1476260423660278
[15/24] Train loss=1.0912824869155884
[20/24] Train loss=1.0982608795166016
Test set avg_accuracy=75.90% avg_sensitivity=84.02%, avg_specificity=72.87% avg_auc=84.84%
Best model saved!! Metric=-8.36297746050785!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=1.136619 Test loss=0.522494 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.0539458990097046
[5/24] Train loss=1.0384007692337036
[10/24] Train loss=1.094496726989746
[15/24] Train loss=1.0187411308288574
[20/24] Train loss=1.0068095922470093
Test set avg_accuracy=76.88% avg_sensitivity=85.56%, avg_specificity=73.64% avg_auc=86.93%
Best model saved!! Metric=-2.996321577381167!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=1.069308 Test loss=0.502391 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.0017273426055908
[5/24] Train loss=0.9921082258224487
[10/24] Train loss=1.0325464010238647
[15/24] Train loss=0.96347576379776
[20/24] Train loss=0.964505672454834
Test set avg_accuracy=78.68% avg_sensitivity=85.08%, avg_specificity=76.30% avg_auc=88.52%
Best model saved!! Metric=2.586937187248054!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=1.010758 Test loss=0.468227 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9549568891525269
[5/24] Train loss=0.9420779347419739
[10/24] Train loss=0.9886931777000427
[15/24] Train loss=0.9200524091720581
[20/24] Train loss=0.8946974873542786
Test set avg_accuracy=80.92% avg_sensitivity=87.28%, avg_specificity=78.56% avg_auc=90.06%
Best model saved!! Metric=10.820378040142216!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.957209 Test loss=0.444686 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.8893870711326599
[5/24] Train loss=0.9062772393226624
[10/24] Train loss=0.9295933842658997
[15/24] Train loss=0.8845585584640503
[20/24] Train loss=0.8547731041908264
Test set avg_accuracy=82.66% avg_sensitivity=86.28%, avg_specificity=81.31% avg_auc=91.12%
Best model saved!! Metric=15.356566684936723!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.908287 Test loss=0.421564 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8674198389053345
[5/24] Train loss=0.8638743758201599
[10/24] Train loss=0.8884273171424866
[15/24] Train loss=0.8256596922874451
[20/24] Train loss=0.8084388971328735
Test set avg_accuracy=83.87% avg_sensitivity=86.76%, avg_specificity=82.79% avg_auc=91.92%
Best model saved!! Metric=19.329965443938576!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.867845 Test loss=0.399260 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.8449005484580994
[5/24] Train loss=0.8261159062385559
[10/24] Train loss=0.8543056845664978
[15/24] Train loss=0.8008501529693604
[20/24] Train loss=0.774059534072876
Test set avg_accuracy=84.80% avg_sensitivity=86.80%, avg_specificity=84.06% avg_auc=92.51%
Best model saved!! Metric=22.1779848854371!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.832575 Test loss=0.386263 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.7969297170639038
[5/24] Train loss=0.7860611081123352
[10/24] Train loss=0.8123418688774109
[15/24] Train loss=0.7631467580795288
[20/24] Train loss=0.7226555943489075
Test set avg_accuracy=85.43% avg_sensitivity=87.00%, avg_specificity=84.85% avg_auc=93.09%
Best model saved!! Metric=24.36347194844754!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.798056 Test loss=0.370617 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7442468404769897
[5/24] Train loss=0.7692798376083374
[10/24] Train loss=0.7784350514411926
[15/24] Train loss=0.7489848136901855
[20/24] Train loss=0.7030889391899109
Test set avg_accuracy=85.90% avg_sensitivity=86.56%, avg_specificity=85.65% avg_auc=93.46%
Best model saved!! Metric=25.572858425832692!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.768939 Test loss=0.354316 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.7162525653839111
[5/24] Train loss=0.734940230846405
[10/24] Train loss=0.7565039992332458
[15/24] Train loss=0.7253024578094482
[20/24] Train loss=0.6678951978683472
Test set avg_accuracy=85.03% avg_sensitivity=88.82%, avg_specificity=83.61% avg_auc=93.70%
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.744819 Test loss=0.370503 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.6998854875564575
[5/24] Train loss=0.7185009121894836
[10/24] Train loss=0.7304617762565613
[15/24] Train loss=0.7050220370292664
[20/24] Train loss=0.650601863861084
Test set avg_accuracy=85.79% avg_sensitivity=88.24%, avg_specificity=84.88% avg_auc=93.97%
Best model saved!! Metric=26.885919447163616!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.719957 Test loss=0.349223 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.6878668665885925
[5/24] Train loss=0.6933565139770508
[10/24] Train loss=0.7080410122871399
[15/24] Train loss=0.6885048151016235
[20/24] Train loss=0.6240448355674744
Test set avg_accuracy=87.08% avg_sensitivity=87.09%, avg_specificity=87.08% avg_auc=94.05%
Best model saved!! Metric=29.30966959765155!!
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.699948 Test loss=0.330413 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6605660915374756
[5/24] Train loss=0.6880856156349182
[10/24] Train loss=0.6897145509719849
[15/24] Train loss=0.6854140162467957
[20/24] Train loss=0.5995370149612427
Test set avg_accuracy=86.46% avg_sensitivity=87.38%, avg_specificity=86.12% avg_auc=94.19%
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.682605 Test loss=0.334831 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.64359050989151
[5/24] Train loss=0.6697114706039429
[10/24] Train loss=0.696482241153717
[15/24] Train loss=0.64689040184021
[20/24] Train loss=0.5790982842445374
Test set avg_accuracy=86.13% avg_sensitivity=88.58%, avg_specificity=85.22% avg_auc=94.27%
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.667919 Test loss=0.342610 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.632304847240448
[5/24] Train loss=0.6700000762939453
[10/24] Train loss=0.6718270182609558
[15/24] Train loss=0.6547184586524963
[20/24] Train loss=0.5717518925666809
Test set avg_accuracy=85.25% avg_sensitivity=89.20%, avg_specificity=83.77% avg_auc=94.38%
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.654104 Test loss=0.353638 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.6237670183181763
[5/24] Train loss=0.6305526494979858
[10/24] Train loss=0.6450183987617493
[15/24] Train loss=0.6311597228050232
[20/24] Train loss=0.5543410181999207
Test set avg_accuracy=85.98% avg_sensitivity=88.63%, avg_specificity=84.99% avg_auc=94.20%
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.636121 Test loss=0.347945 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5959327816963196
[5/24] Train loss=0.6256251335144043
[10/24] Train loss=0.6540663242340088
[15/24] Train loss=0.6375527381896973
[20/24] Train loss=0.5594267845153809
Test set avg_accuracy=87.71% avg_sensitivity=87.48%, avg_specificity=87.79% avg_auc=94.39%
Best model saved!! Metric=31.365102495293!!
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.625646 Test loss=0.322667 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.6057856678962708
[5/24] Train loss=0.6060052514076233
[10/24] Train loss=0.6272213459014893
[15/24] Train loss=0.6112688779830933
[20/24] Train loss=0.5284411311149597
Test set avg_accuracy=89.39% avg_sensitivity=82.92%, avg_specificity=91.80% avg_auc=94.18%
Best model saved!! Metric=32.2851131490675!!
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.608969 Test loss=0.280215 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5868827104568481
[5/24] Train loss=0.5927218198776245
[10/24] Train loss=0.6306854486465454
[15/24] Train loss=0.6143144369125366
[20/24] Train loss=0.5096569061279297
Test set avg_accuracy=89.34% avg_sensitivity=78.55%, avg_specificity=93.35% avg_auc=93.91%
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.596279 Test loss=0.273276 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5669459700584412
[5/24] Train loss=0.5939929485321045
[10/24] Train loss=0.6126059293746948
[15/24] Train loss=0.58412766456604
[20/24] Train loss=0.5026017427444458
Test set avg_accuracy=89.23% avg_sensitivity=84.55%, avg_specificity=90.98% avg_auc=94.42%
Best model saved!! Metric=33.18050375059396!!
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.585003 Test loss=0.286444 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5568647384643555
[5/24] Train loss=0.584231972694397
[10/24] Train loss=0.6150257587432861
[15/24] Train loss=0.5969260334968567
[20/24] Train loss=0.49701279401779175
Test set avg_accuracy=89.36% avg_sensitivity=83.78%, avg_specificity=91.44% avg_auc=94.40%
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.574192 Test loss=0.275343 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5376611948013306
[5/24] Train loss=0.5585817694664001
[10/24] Train loss=0.598281741142273
[15/24] Train loss=0.5567505955696106
[20/24] Train loss=0.4712091088294983
Test set avg_accuracy=89.34% avg_sensitivity=79.13%, avg_specificity=93.14% avg_auc=93.88%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.561189 Test loss=0.272897 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5280009508132935
[5/24] Train loss=0.5469509363174438
[10/24] Train loss=0.5959445238113403
[15/24] Train loss=0.5544149279594421
[20/24] Train loss=0.473187118768692
Test set avg_accuracy=89.11% avg_sensitivity=73.94%, avg_specificity=94.76% avg_auc=93.73%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.552818 Test loss=0.274494 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.5278290510177612
[5/24] Train loss=0.5348581075668335
[10/24] Train loss=0.566489577293396
[15/24] Train loss=0.5395679473876953
[20/24] Train loss=0.4581110179424286
Test set avg_accuracy=88.70% avg_sensitivity=70.59%, avg_specificity=95.44% avg_auc=92.99%
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.546062 Test loss=0.285914 Current lr=[0.000210185142098938]

[0/24] Train loss=0.5071258544921875
[5/24] Train loss=0.5293735861778259
[10/24] Train loss=0.5660102963447571
[15/24] Train loss=0.5580673217773438
[20/24] Train loss=0.44540268182754517
Test set avg_accuracy=87.70% avg_sensitivity=65.21%, avg_specificity=96.07% avg_auc=92.44%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.532403 Test loss=0.303880 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.5076935291290283
[5/24] Train loss=0.5056267976760864
[10/24] Train loss=0.5640836358070374
[15/24] Train loss=0.529527485370636
[20/24] Train loss=0.436128705739975
Test set avg_accuracy=89.06% avg_sensitivity=73.18%, avg_specificity=94.98% avg_auc=93.44%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.516263 Test loss=0.275624 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.4885038435459137
[5/24] Train loss=0.5457121729850769
[10/24] Train loss=0.5329792499542236
[15/24] Train loss=0.5135676860809326
[20/24] Train loss=0.4296107292175293
Test set avg_accuracy=87.83% avg_sensitivity=65.31%, avg_specificity=96.21% avg_auc=92.37%
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.517016 Test loss=0.300345 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.5252125263214111
[5/24] Train loss=0.5056998133659363
[10/24] Train loss=0.536652147769928
[15/24] Train loss=0.515099823474884
[20/24] Train loss=0.4167761206626892
Test set avg_accuracy=87.71% avg_sensitivity=65.40%, avg_specificity=96.02% avg_auc=91.94%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.506796 Test loss=0.309182 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.463966965675354
[5/24] Train loss=0.4884999990463257
[10/24] Train loss=0.5151219964027405
[15/24] Train loss=0.5307429432868958
[20/24] Train loss=0.42676615715026855
Test set avg_accuracy=89.44% avg_sensitivity=82.29%, avg_specificity=92.10% avg_auc=93.97%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.497480 Test loss=0.276911 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.45962896943092346
[5/24] Train loss=0.4625486433506012
[10/24] Train loss=0.519714891910553
[15/24] Train loss=0.5027860403060913
[20/24] Train loss=0.42726966738700867
Test set avg_accuracy=89.49% avg_sensitivity=79.22%, avg_specificity=93.32% avg_auc=93.21%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.486218 Test loss=0.288295 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.45472007989883423
[5/24] Train loss=0.46187669038772583
[10/24] Train loss=0.5113110542297363
[15/24] Train loss=0.4921438992023468
[20/24] Train loss=0.4084629714488983
Test set avg_accuracy=87.10% avg_sensitivity=61.37%, avg_specificity=96.68% avg_auc=91.33%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.475194 Test loss=0.322084 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4871686100959778
[5/24] Train loss=0.4449130594730377
[10/24] Train loss=0.5017460584640503
[15/24] Train loss=0.4870445132255554
[20/24] Train loss=0.391676664352417
Test set avg_accuracy=89.38% avg_sensitivity=78.60%, avg_specificity=93.39% avg_auc=92.71%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.467254 Test loss=0.290812 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4339033365249634
[5/24] Train loss=0.4377307593822479
[10/24] Train loss=0.5032423138618469
[15/24] Train loss=0.48539596796035767
[20/24] Train loss=0.3930475413799286
Test set avg_accuracy=86.80% avg_sensitivity=85.46%, avg_specificity=87.29% avg_auc=92.10%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.453904 Test loss=0.361424 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.45013079047203064
[5/24] Train loss=0.44377070665359497
[10/24] Train loss=0.5058402419090271
[15/24] Train loss=0.48208919167518616
[20/24] Train loss=0.4053735136985779
Test set avg_accuracy=89.60% avg_sensitivity=79.75%, avg_specificity=93.26% avg_auc=93.61%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.461580 Test loss=0.275802 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.42863819003105164
[5/24] Train loss=0.4821608066558838
[10/24] Train loss=0.5425710082054138
[15/24] Train loss=0.465526819229126
[20/24] Train loss=0.39091619849205017
Test set avg_accuracy=89.10% avg_sensitivity=80.61%, avg_specificity=92.26% avg_auc=93.26%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.474374 Test loss=0.290803 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.4431167244911194
[5/24] Train loss=0.45768460631370544
[10/24] Train loss=0.47512680292129517
[15/24] Train loss=0.43188926577568054
[20/24] Train loss=0.39055705070495605
Test set avg_accuracy=85.85% avg_sensitivity=86.76%, avg_specificity=85.51% avg_auc=93.54%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.455150 Test loss=0.344629 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4331505000591278
[5/24] Train loss=0.42630714178085327
[10/24] Train loss=0.4535389542579651
[15/24] Train loss=0.44335463643074036
[20/24] Train loss=0.36776962876319885
Test set avg_accuracy=88.79% avg_sensitivity=72.50%, avg_specificity=94.85% avg_auc=92.22%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.435484 Test loss=0.298129 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.41085004806518555
[5/24] Train loss=0.4119456708431244
[10/24] Train loss=0.46212419867515564
[15/24] Train loss=0.45203709602355957
[20/24] Train loss=0.40609869360923767
Test set avg_accuracy=81.11% avg_sensitivity=89.54%, avg_specificity=77.97% avg_auc=92.53%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.440188 Test loss=0.448016 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4216192364692688
[5/24] Train loss=0.43546634912490845
[10/24] Train loss=0.44917941093444824
[15/24] Train loss=0.4279695153236389
[20/24] Train loss=0.37202030420303345
Test set avg_accuracy=87.93% avg_sensitivity=84.88%, avg_specificity=89.06% avg_auc=93.70%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.424111 Test loss=0.305851 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.4189871549606323
[5/24] Train loss=0.40741854906082153
[10/24] Train loss=0.43124791979789734
[15/24] Train loss=0.4373714029788971
[20/24] Train loss=0.3652249276638031
Test set avg_accuracy=87.01% avg_sensitivity=85.22%, avg_specificity=87.67% avg_auc=93.23%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.419859 Test loss=0.330076 Current lr=[0.00029967723776099]

[0/24] Train loss=0.41390323638916016
[5/24] Train loss=0.40498584508895874
[10/24] Train loss=0.49167680740356445
[15/24] Train loss=0.43669602274894714
[20/24] Train loss=0.3490273058414459
Test set avg_accuracy=89.75% avg_sensitivity=81.67%, avg_specificity=92.76% avg_auc=93.26%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.424932 Test loss=0.288525 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3848082423210144
[5/24] Train loss=0.3998349606990814
[10/24] Train loss=0.4379619061946869
[15/24] Train loss=0.4233502149581909
[20/24] Train loss=0.3398936092853546
Test set avg_accuracy=84.82% avg_sensitivity=87.67%, avg_specificity=83.76% avg_auc=93.41%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.410018 Test loss=0.396718 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.4191511273384094
[5/24] Train loss=0.3750244379043579
[10/24] Train loss=0.4318104684352875
[15/24] Train loss=0.41407880187034607
[20/24] Train loss=0.32855337858200073
Test set avg_accuracy=87.30% avg_sensitivity=85.27%, avg_specificity=88.06% avg_auc=93.44%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.405755 Test loss=0.327782 Current lr=[0.000299720220882401]

[0/24] Train loss=0.40290746092796326
[5/24] Train loss=0.35919439792633057
[10/24] Train loss=0.4260138273239136
[15/24] Train loss=0.4125800132751465
[20/24] Train loss=0.34657689929008484
Test set avg_accuracy=87.08% avg_sensitivity=84.69%, avg_specificity=87.97% avg_auc=92.74%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.402113 Test loss=0.345866 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.39547300338745117
[5/24] Train loss=0.36635294556617737
[10/24] Train loss=0.4060959815979004
[15/24] Train loss=0.41975662112236023
[20/24] Train loss=0.3634381890296936
Test set avg_accuracy=88.50% avg_sensitivity=80.28%, avg_specificity=91.57% avg_auc=91.02%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.403456 Test loss=0.332039 Current lr=[0.000298904600941902]

[0/24] Train loss=0.400316447019577
[5/24] Train loss=0.36624574661254883
[10/24] Train loss=0.4243313670158386
[15/24] Train loss=0.4149949550628662
[20/24] Train loss=0.35875552892684937
Test set avg_accuracy=81.52% avg_sensitivity=89.49%, avg_specificity=78.56% avg_auc=92.97%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.394659 Test loss=0.450331 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.39540696144104004
[5/24] Train loss=0.3730817437171936
[10/24] Train loss=0.41404974460601807
[15/24] Train loss=0.3909626305103302
[20/24] Train loss=0.3325687348842621
Test set avg_accuracy=81.28% avg_sensitivity=90.45%, avg_specificity=77.86% avg_auc=92.90%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.387585 Test loss=0.434369 Current lr=[0.000297555943323901]

[0/24] Train loss=0.38027241826057434
[5/24] Train loss=0.3536997437477112
[10/24] Train loss=0.4556910991668701
[15/24] Train loss=0.4090295135974884
[20/24] Train loss=0.35647279024124146
Test set avg_accuracy=88.23% avg_sensitivity=80.95%, avg_specificity=90.94% avg_auc=92.73%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.386646 Test loss=0.303996 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.38550928235054016
[5/24] Train loss=0.3448464274406433
[10/24] Train loss=0.425397664308548
[15/24] Train loss=0.4058935344219208
[20/24] Train loss=0.351749449968338
Test set avg_accuracy=87.01% avg_sensitivity=85.89%, avg_specificity=87.42% avg_auc=93.20%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.386586 Test loss=0.333504 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.37160125374794006
[5/24] Train loss=0.33121562004089355
[10/24] Train loss=0.3805639147758484
[15/24] Train loss=0.389043927192688
[20/24] Train loss=0.35153111815452576
Test set avg_accuracy=76.76% avg_sensitivity=92.99%, avg_specificity=70.71% avg_auc=92.49%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.375172 Test loss=0.553934 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3609164357185364
[5/24] Train loss=0.3144436776638031
[10/24] Train loss=0.3770381808280945
[15/24] Train loss=0.3640901744365692
[20/24] Train loss=0.33178776502609253
Test set avg_accuracy=75.01% avg_sensitivity=90.69%, avg_specificity=69.17% avg_auc=91.68%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.358092 Test loss=0.619816 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3840285837650299
[5/24] Train loss=0.33721932768821716
[10/24] Train loss=0.39076265692710876
[15/24] Train loss=0.38851478695869446
[20/24] Train loss=0.3472362756729126
Test set avg_accuracy=87.36% avg_sensitivity=83.11%, avg_specificity=88.94% avg_auc=93.13%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.380514 Test loss=0.325008 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3682381510734558
[5/24] Train loss=0.3557816743850708
[10/24] Train loss=0.38257598876953125
[15/24] Train loss=0.35008490085601807
[20/24] Train loss=0.3428226709365845
Test set avg_accuracy=81.37% avg_sensitivity=89.20%, avg_specificity=78.45% avg_auc=91.73%
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.372431 Test loss=0.507752 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.36387455463409424
[5/24] Train loss=0.33891481161117554
[10/24] Train loss=0.408122718334198
[15/24] Train loss=0.3633216917514801
[20/24] Train loss=0.32328227162361145
Test set avg_accuracy=87.50% avg_sensitivity=85.56%, avg_specificity=88.22% avg_auc=92.23%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.373593 Test loss=0.334607 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.34490928053855896
[5/24] Train loss=0.3311993479728699
[10/24] Train loss=0.3706144392490387
[15/24] Train loss=0.35832101106643677
[20/24] Train loss=0.31110480427742004
Test set avg_accuracy=80.17% avg_sensitivity=89.40%, avg_specificity=76.73% avg_auc=92.25%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.351923 Test loss=0.480374 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3226355016231537
[5/24] Train loss=0.3073483109474182
[10/24] Train loss=0.3653131127357483
[15/24] Train loss=0.3384353518486023
[20/24] Train loss=0.31707465648651123
Test set avg_accuracy=79.61% avg_sensitivity=89.88%, avg_specificity=75.79% avg_auc=92.59%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.346713 Test loss=0.504075 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3632742166519165
[5/24] Train loss=0.3146520256996155
[10/24] Train loss=0.3368057310581207
[15/24] Train loss=0.3560987114906311
[20/24] Train loss=0.30602532625198364
Test set avg_accuracy=84.60% avg_sensitivity=87.76%, avg_specificity=83.42% avg_auc=93.21%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.341863 Test loss=0.372199 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3303907513618469
[5/24] Train loss=0.3004790246486664
[10/24] Train loss=0.34202131628990173
[15/24] Train loss=0.3325903117656708
[20/24] Train loss=0.2998582422733307
Test set avg_accuracy=88.65% avg_sensitivity=80.95%, avg_specificity=91.51% avg_auc=93.12%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.344411 Test loss=0.297839 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3369152247905731
[5/24] Train loss=0.30661556124687195
[10/24] Train loss=0.36145052313804626
[15/24] Train loss=0.3387323021888733
[20/24] Train loss=0.30651697516441345
Test set avg_accuracy=88.75% avg_sensitivity=79.99%, avg_specificity=92.01% avg_auc=92.66%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.337266 Test loss=0.297117 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3516705334186554
[5/24] Train loss=0.3057805597782135
[10/24] Train loss=0.3289029598236084
[15/24] Train loss=0.3386535942554474
[20/24] Train loss=0.28840377926826477
Test set avg_accuracy=88.37% avg_sensitivity=79.65%, avg_specificity=91.62% avg_auc=92.49%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.337242 Test loss=0.310504 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3127087950706482
[5/24] Train loss=0.3063001036643982
[10/24] Train loss=0.32924705743789673
[15/24] Train loss=0.3354146480560303
[20/24] Train loss=0.29432499408721924
Test set avg_accuracy=85.65% avg_sensitivity=86.32%, avg_specificity=85.40% avg_auc=92.25%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.334117 Test loss=0.374209 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.36186185479164124
[5/24] Train loss=0.2865026295185089
[10/24] Train loss=0.31665506958961487
[15/24] Train loss=0.35398516058921814
[20/24] Train loss=0.3106810450553894
Test set avg_accuracy=88.97% avg_sensitivity=82.20%, avg_specificity=91.49% avg_auc=92.71%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.333913 Test loss=0.309722 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.34117528796195984
[5/24] Train loss=0.3095816373825073
[10/24] Train loss=0.3292738199234009
[15/24] Train loss=0.33734965324401855
[20/24] Train loss=0.29480138421058655
Test set avg_accuracy=88.87% avg_sensitivity=82.87%, avg_specificity=91.10% avg_auc=93.15%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.329049 Test loss=0.314548 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3419213891029358
[5/24] Train loss=0.2700963020324707
[10/24] Train loss=0.32228854298591614
[15/24] Train loss=0.330437034368515
[20/24] Train loss=0.2699888348579407
Test set avg_accuracy=88.82% avg_sensitivity=79.99%, avg_specificity=92.10% avg_auc=92.89%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.320301 Test loss=0.292062 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3045031428337097
[5/24] Train loss=0.2943345308303833
[10/24] Train loss=0.3090042173862457
[15/24] Train loss=0.3202759623527527
[20/24] Train loss=0.2814697325229645
Test set avg_accuracy=87.97% avg_sensitivity=84.74%, avg_specificity=89.17% avg_auc=92.81%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.318073 Test loss=0.338000 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3034780025482178
[5/24] Train loss=0.28035345673561096
[10/24] Train loss=0.31199678778648376
[15/24] Train loss=0.2975418269634247
[20/24] Train loss=0.2776809632778168
Test set avg_accuracy=88.40% avg_sensitivity=84.26%, avg_specificity=89.94% avg_auc=92.42%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.303706 Test loss=0.336500 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.29121699929237366
[5/24] Train loss=0.28513064980506897
[10/24] Train loss=0.31806355714797974
[15/24] Train loss=0.32515349984169006
[20/24] Train loss=0.2664852440357208
Test set avg_accuracy=89.18% avg_sensitivity=75.77%, avg_specificity=94.17% avg_auc=91.95%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.304995 Test loss=0.306887 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3026790916919708
[5/24] Train loss=0.26552996039390564
[10/24] Train loss=0.2955840528011322
[15/24] Train loss=0.3013692796230316
[20/24] Train loss=0.2721291184425354
Test set avg_accuracy=89.24% avg_sensitivity=80.81%, avg_specificity=92.39% avg_auc=93.05%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.299868 Test loss=0.306768 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2942067086696625
[5/24] Train loss=0.27800917625427246
[10/24] Train loss=0.301301509141922
[15/24] Train loss=0.33545851707458496
[20/24] Train loss=0.27651527523994446
Test set avg_accuracy=85.60% avg_sensitivity=86.66%, avg_specificity=85.20% avg_auc=92.26%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.304752 Test loss=0.387314 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3215499818325043
[5/24] Train loss=0.26587820053100586
[10/24] Train loss=0.2876364290714264
[15/24] Train loss=0.3029484450817108
[20/24] Train loss=0.2589053511619568
Test set avg_accuracy=88.46% avg_sensitivity=76.68%, avg_specificity=92.85% avg_auc=92.01%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.296213 Test loss=0.321180 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.28588762879371643
[5/24] Train loss=0.28820422291755676
[10/24] Train loss=0.29347458481788635
[15/24] Train loss=0.28776970505714417
[20/24] Train loss=0.26738277077674866
Test set avg_accuracy=87.89% avg_sensitivity=73.61%, avg_specificity=93.21% avg_auc=92.28%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.291908 Test loss=0.313724 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2821035087108612
[5/24] Train loss=0.29229554533958435
[10/24] Train loss=0.28967782855033875
[15/24] Train loss=0.31757745146751404
[20/24] Train loss=0.28285160660743713
Test set avg_accuracy=88.33% avg_sensitivity=71.55%, avg_specificity=94.59% avg_auc=91.69%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.304544 Test loss=0.313913 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3027151823043823
[5/24] Train loss=0.2622314691543579
[10/24] Train loss=0.2853940427303314
[15/24] Train loss=0.3163555860519409
[20/24] Train loss=0.25961676239967346
Test set avg_accuracy=88.57% avg_sensitivity=80.95%, avg_specificity=91.40% avg_auc=93.25%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.292116 Test loss=0.316265 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2866743803024292
[5/24] Train loss=0.26000651717185974
[10/24] Train loss=0.2632567286491394
[15/24] Train loss=0.28401678800582886
[20/24] Train loss=0.26331713795661926
Test set avg_accuracy=87.99% avg_sensitivity=84.88%, avg_specificity=89.15% avg_auc=93.58%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.283851 Test loss=0.334473 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.29791074991226196
[5/24] Train loss=0.26901811361312866
[10/24] Train loss=0.2765868008136749
[15/24] Train loss=0.29551348090171814
[20/24] Train loss=0.27362990379333496
Test set avg_accuracy=88.66% avg_sensitivity=75.72%, avg_specificity=93.48% avg_auc=91.81%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.287929 Test loss=0.327415 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3002297282218933
[5/24] Train loss=0.2871902585029602
[10/24] Train loss=0.2882387936115265
[15/24] Train loss=0.28247129917144775
[20/24] Train loss=0.2669760584831238
Test set avg_accuracy=87.14% avg_sensitivity=85.36%, avg_specificity=87.79% avg_auc=92.41%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.284286 Test loss=0.399126 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2927090525627136
[5/24] Train loss=0.27136656641960144
[10/24] Train loss=0.2907582223415375
[15/24] Train loss=0.2781350016593933
[20/24] Train loss=0.2964077293872833
Test set avg_accuracy=84.99% avg_sensitivity=87.09%, avg_specificity=84.20% avg_auc=91.05%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.289814 Test loss=0.485360 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3038838803768158
[5/24] Train loss=0.2755487561225891
[10/24] Train loss=0.3020894527435303
[15/24] Train loss=0.3001840114593506
[20/24] Train loss=0.26519742608070374
Test set avg_accuracy=87.99% avg_sensitivity=82.05%, avg_specificity=90.21% avg_auc=92.35%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.292977 Test loss=0.348056 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.28819793462753296
[5/24] Train loss=0.25309497117996216
[10/24] Train loss=0.29252707958221436
[15/24] Train loss=0.27952107787132263
[20/24] Train loss=0.2578522861003876
Test set avg_accuracy=88.65% avg_sensitivity=78.69%, avg_specificity=92.35% avg_auc=92.15%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.286139 Test loss=0.332619 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.29543837904930115
[5/24] Train loss=0.25594133138656616
[10/24] Train loss=0.273065447807312
[15/24] Train loss=0.28877562284469604
[20/24] Train loss=0.2598344087600708
Test set avg_accuracy=88.26% avg_sensitivity=81.14%, avg_specificity=90.90% avg_auc=92.27%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.278163 Test loss=0.338196 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2690928280353546
[5/24] Train loss=0.26442641019821167
[10/24] Train loss=0.26993077993392944
[15/24] Train loss=0.30798783898353577
[20/24] Train loss=0.25685903429985046
Test set avg_accuracy=88.76% avg_sensitivity=81.00%, avg_specificity=91.65% avg_auc=92.93%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.279424 Test loss=0.318693 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2844788432121277
[5/24] Train loss=0.27634546160697937
[10/24] Train loss=0.2547038793563843
[15/24] Train loss=0.27035996317863464
[20/24] Train loss=0.24547837674617767
Test set avg_accuracy=88.35% avg_sensitivity=78.89%, avg_specificity=91.87% avg_auc=92.04%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.277253 Test loss=0.339818 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.26437148451805115
[5/24] Train loss=0.2711530327796936
[10/24] Train loss=0.26869839429855347
[15/24] Train loss=0.2767845094203949
[20/24] Train loss=0.2507556080818176
Test set avg_accuracy=88.80% avg_sensitivity=77.02%, avg_specificity=93.19% avg_auc=91.96%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.276931 Test loss=0.323286 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.28414836525917053
[5/24] Train loss=0.27378544211387634
[10/24] Train loss=0.29665523767471313
[15/24] Train loss=0.27740007638931274
[20/24] Train loss=0.24478651583194733
Test set avg_accuracy=87.46% avg_sensitivity=68.47%, avg_specificity=94.53% avg_auc=89.63%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.279091 Test loss=0.361371 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.28804346919059753
[5/24] Train loss=0.24759584665298462
[10/24] Train loss=0.2446039468050003
[15/24] Train loss=0.2716458737850189
[20/24] Train loss=0.23722709715366364
Test set avg_accuracy=88.48% avg_sensitivity=69.72%, avg_specificity=95.46% avg_auc=91.28%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.272535 Test loss=0.331213 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.25867411494255066
[5/24] Train loss=0.25349748134613037
[10/24] Train loss=0.24650175869464874
[15/24] Train loss=0.25381389260292053
[20/24] Train loss=0.2686595916748047
Test set avg_accuracy=89.27% avg_sensitivity=77.26%, avg_specificity=93.75% avg_auc=92.25%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.262972 Test loss=0.314697 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2506135404109955
[5/24] Train loss=0.23704460263252258
[10/24] Train loss=0.24837173521518707
[15/24] Train loss=0.23421622812747955
[20/24] Train loss=0.23217234015464783
Test set avg_accuracy=88.54% avg_sensitivity=72.84%, avg_specificity=94.39% avg_auc=91.54%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.250312 Test loss=0.318145 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.25307270884513855
[5/24] Train loss=0.22918514907360077
[10/24] Train loss=0.24874600768089294
[15/24] Train loss=0.23385246098041534
[20/24] Train loss=0.23569504916667938
Test set avg_accuracy=88.79% avg_sensitivity=77.50%, avg_specificity=92.99% avg_auc=92.40%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.248704 Test loss=0.312853 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.25882449746131897
[5/24] Train loss=0.24134191870689392
[10/24] Train loss=0.24026983976364136
[15/24] Train loss=0.25544363260269165
[20/24] Train loss=0.23853440582752228
Test set avg_accuracy=88.87% avg_sensitivity=74.76%, avg_specificity=94.12% avg_auc=92.24%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.251218 Test loss=0.315797 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2550405263900757
[5/24] Train loss=0.2289961874485016
[10/24] Train loss=0.2326551228761673
[15/24] Train loss=0.2481584995985031
[20/24] Train loss=0.23357760906219482
Test set avg_accuracy=88.53% avg_sensitivity=74.23%, avg_specificity=93.85% avg_auc=91.57%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.246685 Test loss=0.329403 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2459443211555481
[5/24] Train loss=0.23040859401226044
[10/24] Train loss=0.2379269301891327
[15/24] Train loss=0.25885865092277527
[20/24] Train loss=0.2302391678094864
Test set avg_accuracy=87.85% avg_sensitivity=69.24%, avg_specificity=94.78% avg_auc=90.84%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.245338 Test loss=0.343865 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.26254788041114807
[5/24] Train loss=0.235150545835495
[10/24] Train loss=0.234867125749588
[15/24] Train loss=0.23543913662433624
[20/24] Train loss=0.22223836183547974
Test set avg_accuracy=87.76% avg_sensitivity=67.85%, avg_specificity=95.18% avg_auc=90.55%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.241854 Test loss=0.337319 Current lr=[0.000156543481933168]

[0/24] Train loss=0.24385350942611694
[5/24] Train loss=0.2456648349761963
[10/24] Train loss=0.22181175649166107
[15/24] Train loss=0.22896866500377655
[20/24] Train loss=0.2305140644311905
Test set avg_accuracy=89.09% avg_sensitivity=74.14%, avg_specificity=94.66% avg_auc=91.36%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.240359 Test loss=0.324461 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.23357929289340973
[5/24] Train loss=0.2269349992275238
[10/24] Train loss=0.2169666737318039
[15/24] Train loss=0.23573997616767883
[20/24] Train loss=0.21723441779613495
Test set avg_accuracy=88.72% avg_sensitivity=77.16%, avg_specificity=93.03% avg_auc=91.69%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.232663 Test loss=0.322905 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2438487708568573
[5/24] Train loss=0.21655899286270142
[10/24] Train loss=0.21097101271152496
[15/24] Train loss=0.23414400219917297
[20/24] Train loss=0.22151662409305573
Test set avg_accuracy=88.55% avg_sensitivity=79.37%, avg_specificity=91.98% avg_auc=92.50%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.229926 Test loss=0.318940 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.23165035247802734
[5/24] Train loss=0.20737825334072113
[10/24] Train loss=0.21964292228221893
[15/24] Train loss=0.20858678221702576
[20/24] Train loss=0.22181165218353271
Test set avg_accuracy=89.08% avg_sensitivity=78.26%, avg_specificity=93.10% avg_auc=92.40%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.227473 Test loss=0.310642 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.23555685579776764
[5/24] Train loss=0.21015208959579468
[10/24] Train loss=0.2057686448097229
[15/24] Train loss=0.20831343531608582
[20/24] Train loss=0.20497074723243713
Test set avg_accuracy=87.93% avg_sensitivity=84.31%, avg_specificity=89.28% avg_auc=92.80%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.221589 Test loss=0.343192 Current lr=[0.000134135431043539]

[0/24] Train loss=0.23628543317317963
[5/24] Train loss=0.19430041313171387
[10/24] Train loss=0.21029679477214813
[15/24] Train loss=0.21038256585597992
[20/24] Train loss=0.20434440672397614
Test set avg_accuracy=89.13% avg_sensitivity=82.58%, avg_specificity=91.57% avg_auc=93.03%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.219700 Test loss=0.312206 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.22634240984916687
[5/24] Train loss=0.20999063551425934
[10/24] Train loss=0.21435996890068054
[15/24] Train loss=0.20883618295192719
[20/24] Train loss=0.2086910605430603
Test set avg_accuracy=88.39% avg_sensitivity=81.24%, avg_specificity=91.05% avg_auc=92.65%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.218444 Test loss=0.328822 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.22207006812095642
[5/24] Train loss=0.2126002162694931
[10/24] Train loss=0.20978502929210663
[15/24] Train loss=0.22383053600788116
[20/24] Train loss=0.20803217589855194
Test set avg_accuracy=89.36% avg_sensitivity=79.85%, avg_specificity=92.91% avg_auc=92.70%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.222698 Test loss=0.304979 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.21861296892166138
[5/24] Train loss=0.21606670320034027
[10/24] Train loss=0.23669303953647614
[15/24] Train loss=0.19954164326190948
[20/24] Train loss=0.21796225011348724
Test set avg_accuracy=86.52% avg_sensitivity=85.65%, avg_specificity=86.85% avg_auc=92.99%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.222880 Test loss=0.372825 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.22537288069725037
[5/24] Train loss=0.22474882006645203
[10/24] Train loss=0.20593269169330597
[15/24] Train loss=0.20329631865024567
[20/24] Train loss=0.20553189516067505
Test set avg_accuracy=89.91% avg_sensitivity=78.93%, avg_specificity=94.00% avg_auc=92.91%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.218259 Test loss=0.294851 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.2215484082698822
[5/24] Train loss=0.2074132114648819
[10/24] Train loss=0.2062802016735077
[15/24] Train loss=0.20566001534461975
[20/24] Train loss=0.20594556629657745
Test set avg_accuracy=88.24% avg_sensitivity=85.51%, avg_specificity=89.26% avg_auc=93.04%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.214234 Test loss=0.342280 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.21747030317783356
[5/24] Train loss=0.21301047503948212
[10/24] Train loss=0.19929051399230957
[15/24] Train loss=0.19786538183689117
[20/24] Train loss=0.21542982757091522
Test set avg_accuracy=89.67% avg_sensitivity=78.12%, avg_specificity=93.98% avg_auc=92.44%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.215480 Test loss=0.310693 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.23617364466190338
[5/24] Train loss=0.21201980113983154
[10/24] Train loss=0.195763498544693
[15/24] Train loss=0.19753988087177277
[20/24] Train loss=0.2083466351032257
Test set avg_accuracy=89.36% avg_sensitivity=82.53%, avg_specificity=91.90% avg_auc=92.59%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.212441 Test loss=0.334911 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.2089216709136963
[5/24] Train loss=0.19774127006530762
[10/24] Train loss=0.20476296544075012
[15/24] Train loss=0.19375137984752655
[20/24] Train loss=0.1889675408601761
Test set avg_accuracy=89.10% avg_sensitivity=83.25%, avg_specificity=91.28% avg_auc=92.68%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.207231 Test loss=0.325028 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.20412935316562653
[5/24] Train loss=0.18667662143707275
[10/24] Train loss=0.19429300725460052
[15/24] Train loss=0.18405745923519135
[20/24] Train loss=0.192823126912117
Test set avg_accuracy=89.71% avg_sensitivity=82.39%, avg_specificity=92.44% avg_auc=92.69%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.199332 Test loss=0.311604 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.19897760450839996
[5/24] Train loss=0.18694862723350525
[10/24] Train loss=0.19393445551395416
[15/24] Train loss=0.19049325585365295
[20/24] Train loss=0.19758737087249756
Test set avg_accuracy=89.62% avg_sensitivity=81.33%, avg_specificity=92.71% avg_auc=92.60%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.198187 Test loss=0.311255 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.20132866501808167
[5/24] Train loss=0.1951468139886856
[10/24] Train loss=0.18522454798221588
[15/24] Train loss=0.18781939148902893
[20/24] Train loss=0.1915360540151596
Test set avg_accuracy=88.78% avg_sensitivity=83.40%, avg_specificity=90.78% avg_auc=93.01%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.196593 Test loss=0.327524 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.19450774788856506
[5/24] Train loss=0.1841578632593155
[10/24] Train loss=0.1866515874862671
[15/24] Train loss=0.19007258117198944
[20/24] Train loss=0.18749317526817322
Test set avg_accuracy=89.31% avg_sensitivity=84.07%, avg_specificity=91.26% avg_auc=93.13%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.194733 Test loss=0.321664 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.20659476518630981
[5/24] Train loss=0.18504318594932556
[10/24] Train loss=0.18558736145496368
[15/24] Train loss=0.1878570318222046
[20/24] Train loss=0.1797686517238617
Test set avg_accuracy=89.05% avg_sensitivity=82.25%, avg_specificity=91.58% avg_auc=92.82%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.195490 Test loss=0.321154 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.19219517707824707
[5/24] Train loss=0.17990811169147491
[10/24] Train loss=0.18776126205921173
[15/24] Train loss=0.1840752363204956
[20/24] Train loss=0.19371448457241058
Test set avg_accuracy=89.15% avg_sensitivity=82.73%, avg_specificity=91.55% avg_auc=93.21%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.192113 Test loss=0.313718 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1917244791984558
[5/24] Train loss=0.19157814979553223
[10/24] Train loss=0.18035607039928436
[15/24] Train loss=0.17454522848129272
[20/24] Train loss=0.1830877661705017
Test set avg_accuracy=89.64% avg_sensitivity=80.76%, avg_specificity=92.94% avg_auc=92.47%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.190114 Test loss=0.315302 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.19490769505500793
[5/24] Train loss=0.17796018719673157
[10/24] Train loss=0.18080216646194458
[15/24] Train loss=0.17378439009189606
[20/24] Train loss=0.18505914509296417
Test set avg_accuracy=89.66% avg_sensitivity=79.75%, avg_specificity=93.35% avg_auc=92.64%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.186931 Test loss=0.309882 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1886344701051712
[5/24] Train loss=0.1801629364490509
[10/24] Train loss=0.18183434009552002
[15/24] Train loss=0.17474010586738586
[20/24] Train loss=0.18185687065124512
Test set avg_accuracy=89.36% avg_sensitivity=81.29%, avg_specificity=92.37% avg_auc=92.55%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.183480 Test loss=0.315922 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1867722123861313
[5/24] Train loss=0.17814117670059204
[10/24] Train loss=0.17568382620811462
[15/24] Train loss=0.17278587818145752
[20/24] Train loss=0.17965127527713776
Test set avg_accuracy=89.75% avg_sensitivity=81.96%, avg_specificity=92.66% avg_auc=92.75%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.183981 Test loss=0.305778 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.18912780284881592
[5/24] Train loss=0.17216381430625916
[10/24] Train loss=0.17616520822048187
[15/24] Train loss=0.1696418821811676
[20/24] Train loss=0.17821846902370453
Test set avg_accuracy=89.30% avg_sensitivity=82.49%, avg_specificity=91.83% avg_auc=92.61%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.183008 Test loss=0.318092 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.18526378273963928
[5/24] Train loss=0.16560877859592438
[10/24] Train loss=0.17358818650245667
[15/24] Train loss=0.17005404829978943
[20/24] Train loss=0.17514850199222565
Test set avg_accuracy=89.28% avg_sensitivity=82.63%, avg_specificity=91.76% avg_auc=92.00%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.181502 Test loss=0.322943 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.18219108879566193
[5/24] Train loss=0.17370262742042542
[10/24] Train loss=0.1740216463804245
[15/24] Train loss=0.17608577013015747
[20/24] Train loss=0.16994597017765045
Test set avg_accuracy=89.58% avg_sensitivity=83.21%, avg_specificity=91.96% avg_auc=92.15%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.179905 Test loss=0.320732 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.17574143409729004
[5/24] Train loss=0.1728498935699463
[10/24] Train loss=0.16589133441448212
[15/24] Train loss=0.16997046768665314
[20/24] Train loss=0.17046022415161133
Test set avg_accuracy=89.69% avg_sensitivity=82.97%, avg_specificity=92.19% avg_auc=92.37%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.178801 Test loss=0.314315 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1805315613746643
[5/24] Train loss=0.17107677459716797
[10/24] Train loss=0.16950011253356934
[15/24] Train loss=0.17340947687625885
[20/24] Train loss=0.16748137772083282
Test set avg_accuracy=89.52% avg_sensitivity=81.86%, avg_specificity=92.37% avg_auc=92.44%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.177917 Test loss=0.312843 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.17363578081130981
[5/24] Train loss=0.17746150493621826
[10/24] Train loss=0.1687731146812439
[15/24] Train loss=0.1721964329481125
[20/24] Train loss=0.1716783493757248
Test set avg_accuracy=89.64% avg_sensitivity=80.52%, avg_specificity=93.03% avg_auc=92.37%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.177371 Test loss=0.310467 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1732805371284485
[5/24] Train loss=0.17824292182922363
[10/24] Train loss=0.16889891028404236
[15/24] Train loss=0.16506615281105042
[20/24] Train loss=0.16755521297454834
Test set avg_accuracy=89.65% avg_sensitivity=83.01%, avg_specificity=92.12% avg_auc=92.79%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.177525 Test loss=0.307493 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.16961219906806946
[5/24] Train loss=0.1694827526807785
[10/24] Train loss=0.17536361515522003
[15/24] Train loss=0.16727584600448608
[20/24] Train loss=0.17284204065799713
Test set avg_accuracy=89.28% avg_sensitivity=82.49%, avg_specificity=91.82% avg_auc=92.45%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.177439 Test loss=0.311814 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.18009786307811737
[5/24] Train loss=0.1666782796382904
[10/24] Train loss=0.1842508167028427
[15/24] Train loss=0.1619410216808319
[20/24] Train loss=0.17602939903736115
Test set avg_accuracy=88.62% avg_sensitivity=82.49%, avg_specificity=90.90% avg_auc=93.04%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.179555 Test loss=0.312532 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.18480193614959717
[5/24] Train loss=0.163552388548851
[10/24] Train loss=0.17973607778549194
[15/24] Train loss=0.16827231645584106
[20/24] Train loss=0.16728515923023224
Test set avg_accuracy=89.66% avg_sensitivity=81.29%, avg_specificity=92.78% avg_auc=92.89%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.178175 Test loss=0.301899 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.17734254896640778
[5/24] Train loss=0.1680659055709839
[10/24] Train loss=0.16515083611011505
[15/24] Train loss=0.1707966923713684
[20/24] Train loss=0.17473356425762177
Test set avg_accuracy=89.69% avg_sensitivity=82.39%, avg_specificity=92.41% avg_auc=93.19%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.174344 Test loss=0.303185 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1683702915906906
[5/24] Train loss=0.16637122631072998
[10/24] Train loss=0.16141237318515778
[15/24] Train loss=0.1623430848121643
[20/24] Train loss=0.15909510850906372
Test set avg_accuracy=89.31% avg_sensitivity=83.59%, avg_specificity=91.44% avg_auc=93.06%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.170373 Test loss=0.307893 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1680333912372589
[5/24] Train loss=0.16205991804599762
[10/24] Train loss=0.1621013730764389
[15/24] Train loss=0.1623016595840454
[20/24] Train loss=0.1631316840648651
Test set avg_accuracy=89.91% avg_sensitivity=82.58%, avg_specificity=92.64% avg_auc=93.02%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.168867 Test loss=0.300654 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1633778065443039
[5/24] Train loss=0.16346639394760132
[10/24] Train loss=0.15786811709403992
[15/24] Train loss=0.160299152135849
[20/24] Train loss=0.16040943562984467
Test set avg_accuracy=89.75% avg_sensitivity=83.25%, avg_specificity=92.17% avg_auc=92.75%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.168199 Test loss=0.304314 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.16501079499721527
[5/24] Train loss=0.16076606512069702
[10/24] Train loss=0.1621825248003006
[15/24] Train loss=0.1574651598930359
[20/24] Train loss=0.16284456849098206
Test set avg_accuracy=89.93% avg_sensitivity=82.58%, avg_specificity=92.67% avg_auc=92.85%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.167834 Test loss=0.302177 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.16446176171302795
[5/24] Train loss=0.16110362112522125
[10/24] Train loss=0.15807121992111206
[15/24] Train loss=0.15656226873397827
[20/24] Train loss=0.15707406401634216
Test set avg_accuracy=89.83% avg_sensitivity=82.58%, avg_specificity=92.53% avg_auc=92.88%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.165667 Test loss=0.302677 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1704150289297104
[5/24] Train loss=0.16050416231155396
[10/24] Train loss=0.15775662660598755
[15/24] Train loss=0.1573762595653534
[20/24] Train loss=0.16388389468193054
Test set avg_accuracy=89.88% avg_sensitivity=82.15%, avg_specificity=92.76% avg_auc=92.82%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.167002 Test loss=0.301782 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.16354632377624512
[5/24] Train loss=0.15713539719581604
[10/24] Train loss=0.15906423330307007
[15/24] Train loss=0.15792851150035858
[20/24] Train loss=0.15430757403373718
Test set avg_accuracy=89.66% avg_sensitivity=82.87%, avg_specificity=92.19% avg_auc=92.84%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.165745 Test loss=0.306300 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1648576855659485
[5/24] Train loss=0.16233104467391968
[10/24] Train loss=0.1575978547334671
[15/24] Train loss=0.15168564021587372
[20/24] Train loss=0.1566135585308075
Test set avg_accuracy=89.96% avg_sensitivity=82.53%, avg_specificity=92.73% avg_auc=92.77%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.165168 Test loss=0.303763 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1609625518321991
[5/24] Train loss=0.15904299914836884
[10/24] Train loss=0.15964195132255554
[15/24] Train loss=0.15717415511608124
[20/24] Train loss=0.154673770070076
Test set avg_accuracy=89.96% avg_sensitivity=82.39%, avg_specificity=92.78% avg_auc=92.78%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.164431 Test loss=0.303893 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1629706174135208
[5/24] Train loss=0.16134025156497955
[10/24] Train loss=0.15744812786579132
[15/24] Train loss=0.1549445539712906
[20/24] Train loss=0.1542070508003235
Test set avg_accuracy=89.80% avg_sensitivity=82.77%, avg_specificity=92.42% avg_auc=92.83%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.165233 Test loss=0.305293 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.16654285788536072
[5/24] Train loss=0.1581456959247589
[10/24] Train loss=0.15756170451641083
[15/24] Train loss=0.15357421338558197
[20/24] Train loss=0.15586712956428528
Test set avg_accuracy=89.82% avg_sensitivity=82.34%, avg_specificity=92.60% avg_auc=92.82%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.164262 Test loss=0.304733 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.16303521394729614
[5/24] Train loss=0.1581704318523407
[10/24] Train loss=0.1583104282617569
[15/24] Train loss=0.15938429534435272
[20/24] Train loss=0.1581525355577469
Test set avg_accuracy=89.92% avg_sensitivity=82.44%, avg_specificity=92.71% avg_auc=92.81%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.164222 Test loss=0.304490 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.16217727959156036
[5/24] Train loss=0.15537895262241364
[10/24] Train loss=0.15674054622650146
[15/24] Train loss=0.1546761393547058
[20/24] Train loss=0.15637251734733582
Test set avg_accuracy=89.84% avg_sensitivity=82.39%, avg_specificity=92.62% avg_auc=92.78%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.163606 Test loss=0.304542 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.16282296180725098
[5/24] Train loss=0.15655460953712463
[10/24] Train loss=0.15779076516628265
[15/24] Train loss=0.15742038190364838
[20/24] Train loss=0.15182186663150787
Test set avg_accuracy=89.79% avg_sensitivity=82.44%, avg_specificity=92.53% avg_auc=92.79%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.164382 Test loss=0.304603 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.16393974423408508
[5/24] Train loss=0.15728463232517242
[10/24] Train loss=0.16227023303508759
[15/24] Train loss=0.1562906950712204
[20/24] Train loss=0.15617863833904266
Test set avg_accuracy=89.84% avg_sensitivity=82.34%, avg_specificity=92.64% avg_auc=92.80%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.164437 Test loss=0.304037 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.15817129611968994
[5/24] Train loss=0.1557372510433197
[10/24] Train loss=0.15449164807796478
[15/24] Train loss=0.1521047055721283
[20/24] Train loss=0.15741701424121857
Test set avg_accuracy=89.87% avg_sensitivity=82.49%, avg_specificity=92.62% avg_auc=92.80%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.163508 Test loss=0.304028 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.16242045164108276
[5/24] Train loss=0.15939538180828094
[10/24] Train loss=0.15685711801052094
[15/24] Train loss=0.1530108004808426
[20/24] Train loss=0.15490660071372986
Test set avg_accuracy=89.84% avg_sensitivity=82.49%, avg_specificity=92.58% avg_auc=92.80%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.163670 Test loss=0.304203 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.16512168943881989
[5/24] Train loss=0.16183288395404816
[10/24] Train loss=0.15726572275161743
[15/24] Train loss=0.15413197875022888
[20/24] Train loss=0.1552741974592209
Test set avg_accuracy=89.91% avg_sensitivity=82.49%, avg_specificity=92.67% avg_auc=92.80%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.163758 Test loss=0.303801 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1608598530292511
[5/24] Train loss=0.15995833277702332
[10/24] Train loss=0.15815195441246033
[15/24] Train loss=0.15412528812885284
[20/24] Train loss=0.1551801562309265
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=89.91% avg_sensitivity=82.49%, avg_specificity=92.67% avg_auc=92.80%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.162997 Test loss=0.304133 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=89.23% sen=84.55%, spe=90.98%, auc=94.42%!
Fold[6] Avg_overlap=0.69%(0.23419945161122785)
[0/24] Train loss=1.4870960712432861
[5/24] Train loss=1.465675711631775
[10/24] Train loss=1.4565150737762451
[15/24] Train loss=1.4162448644638062
[20/24] Train loss=1.3992735147476196
Test set avg_accuracy=65.83% avg_sensitivity=43.61%, avg_specificity=74.31% avg_auc=57.23%
Best model saved!! Metric=-85.01557010608163!!
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=1.448322 Test loss=0.674761 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.4196174144744873
[5/24] Train loss=1.3981724977493286
[10/24] Train loss=1.385035753250122
[15/24] Train loss=1.3549236059188843
[20/24] Train loss=1.3314998149871826
Test set avg_accuracy=70.38% avg_sensitivity=72.37%, avg_specificity=69.62% avg_auc=70.80%
Best model saved!! Metric=-42.82939962676642!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=1.377835 Test loss=0.623535 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.322561502456665
[5/24] Train loss=1.3200359344482422
[10/24] Train loss=1.3302299976348877
[15/24] Train loss=1.2750219106674194
[20/24] Train loss=1.2581340074539185
Test set avg_accuracy=74.13% avg_sensitivity=80.39%, avg_specificity=71.74% avg_auc=77.31%
Best model saved!! Metric=-22.431743804210896!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=1.308556 Test loss=0.591540 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.269575595855713
[5/24] Train loss=1.243351697921753
[10/24] Train loss=1.2517449855804443
[15/24] Train loss=1.1976755857467651
[20/24] Train loss=1.172534465789795
Test set avg_accuracy=75.73% avg_sensitivity=82.27%, avg_specificity=73.23% avg_auc=80.96%
Best model saved!! Metric=-13.801537648850072!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=1.236001 Test loss=0.564946 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.1839699745178223
[5/24] Train loss=1.1823580265045166
[10/24] Train loss=1.2031134366989136
[15/24] Train loss=1.1204824447631836
[20/24] Train loss=1.1090409755706787
Test set avg_accuracy=77.07% avg_sensitivity=84.82%, avg_specificity=74.11% avg_auc=83.86%
Best model saved!! Metric=-6.137774356021964!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=1.166592 Test loss=0.539741 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.1090620756149292
[5/24] Train loss=1.0964428186416626
[10/24] Train loss=1.1415027379989624
[15/24] Train loss=1.038055658340454
[20/24] Train loss=1.0346523523330688
Test set avg_accuracy=79.01% avg_sensitivity=84.96%, avg_specificity=76.74% avg_auc=86.24%
Best model saved!! Metric=0.9526359136472564!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=1.098796 Test loss=0.511495 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.0400930643081665
[5/24] Train loss=1.0252364873886108
[10/24] Train loss=1.0740524530410767
[15/24] Train loss=0.9772553443908691
[20/24] Train loss=0.9625823497772217
Test set avg_accuracy=80.39% avg_sensitivity=86.19%, avg_specificity=78.18% avg_auc=88.45%
Best model saved!! Metric=7.202758422115636!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=1.040289 Test loss=0.482590 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9816609621047974
[5/24] Train loss=0.9790672659873962
[10/24] Train loss=1.0281480550765991
[15/24] Train loss=0.9239993691444397
[20/24] Train loss=0.9120548367500305
Test set avg_accuracy=82.07% avg_sensitivity=85.34%, avg_specificity=80.82% avg_auc=90.21%
Best model saved!! Metric=12.436795266540486!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.982645 Test loss=0.448913 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.933442234992981
[5/24] Train loss=0.9052509665489197
[10/24] Train loss=0.9584149122238159
[15/24] Train loss=0.869177520275116
[20/24] Train loss=0.8557153344154358
Test set avg_accuracy=84.19% avg_sensitivity=86.04%, avg_specificity=83.49% avg_auc=91.59%
Best model saved!! Metric=19.31490026881707!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.929489 Test loss=0.419868 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8966778516769409
[5/24] Train loss=0.8550521731376648
[10/24] Train loss=0.9096630811691284
[15/24] Train loss=0.8282225728034973
[20/24] Train loss=0.8012030720710754
Test set avg_accuracy=85.78% avg_sensitivity=86.66%, avg_specificity=85.45% avg_auc=92.67%
Best model saved!! Metric=24.55534748530168!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.881270 Test loss=0.390404 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.8377929329872131
[5/24] Train loss=0.8157978057861328
[10/24] Train loss=0.8691951036453247
[15/24] Train loss=0.7927089333534241
[20/24] Train loss=0.7514058351516724
Test set avg_accuracy=86.28% avg_sensitivity=88.26%, avg_specificity=85.52% avg_auc=93.43%
Best model saved!! Metric=27.48918422832088!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.838937 Test loss=0.379811 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.7928142547607422
[5/24] Train loss=0.7751064896583557
[10/24] Train loss=0.8178986310958862
[15/24] Train loss=0.7583450675010681
[20/24] Train loss=0.7151371240615845
Test set avg_accuracy=87.36% avg_sensitivity=87.22%, avg_specificity=87.41% avg_auc=94.01%
Best model saved!! Metric=29.994348491338116!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.799000 Test loss=0.353607 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7584679126739502
[5/24] Train loss=0.7343779802322388
[10/24] Train loss=0.7963097095489502
[15/24] Train loss=0.725398063659668
[20/24] Train loss=0.6885440349578857
Test set avg_accuracy=88.28% avg_sensitivity=84.16%, avg_specificity=89.85% avg_auc=94.28%
Best model saved!! Metric=30.574605432220437!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.769266 Test loss=0.329143 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.7315146327018738
[5/24] Train loss=0.6990432739257812
[10/24] Train loss=0.7782014012336731
[15/24] Train loss=0.7074152231216431
[20/24] Train loss=0.6525952816009521
Test set avg_accuracy=88.70% avg_sensitivity=84.25%, avg_specificity=90.39% avg_auc=94.62%
Best model saved!! Metric=31.969420950700794!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.742570 Test loss=0.317845 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.7113749384880066
[5/24] Train loss=0.7000241875648499
[10/24] Train loss=0.7609195113182068
[15/24] Train loss=0.6938531994819641
[20/24] Train loss=0.6559065580368042
Test set avg_accuracy=88.91% avg_sensitivity=84.58%, avg_specificity=90.56% avg_auc=94.86%
Best model saved!! Metric=32.90640860039477!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.722929 Test loss=0.309405 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.6739805340766907
[5/24] Train loss=0.6618493795394897
[10/24] Train loss=0.7417110800743103
[15/24] Train loss=0.667506754398346
[20/24] Train loss=0.6209027767181396
Test set avg_accuracy=88.84% avg_sensitivity=85.43%, avg_specificity=90.14% avg_auc=95.17%
Best model saved!! Metric=33.58190890817602!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.699349 Test loss=0.304994 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6736412644386292
[5/24] Train loss=0.6444754004478455
[10/24] Train loss=0.7048934698104858
[15/24] Train loss=0.650028645992279
[20/24] Train loss=0.5921353697776794
Test set avg_accuracy=89.02% avg_sensitivity=82.98%, avg_specificity=91.33% avg_auc=95.14%
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.682966 Test loss=0.289295 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.641828715801239
[5/24] Train loss=0.6192262172698975
[10/24] Train loss=0.7078378200531006
[15/24] Train loss=0.6406200528144836
[20/24] Train loss=0.5834035277366638
Test set avg_accuracy=88.76% avg_sensitivity=86.85%, avg_specificity=89.49% avg_auc=95.32%
Best model saved!! Metric=34.426948462701006!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.667086 Test loss=0.304453 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.636644721031189
[5/24] Train loss=0.6134436726570129
[10/24] Train loss=0.6818623542785645
[15/24] Train loss=0.6321955323219299
[20/24] Train loss=0.5582873225212097
Test set avg_accuracy=89.06% avg_sensitivity=83.64%, avg_specificity=91.13% avg_auc=95.27%
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.653948 Test loss=0.285149 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.625027596950531
[5/24] Train loss=0.5917354822158813
[10/24] Train loss=0.7039456367492676
[15/24] Train loss=0.6144867539405823
[20/24] Train loss=0.5598856806755066
Test set avg_accuracy=88.89% avg_sensitivity=86.70%, avg_specificity=89.73% avg_auc=95.19%
Best model saved!! Metric=34.51102698067827!!
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.639306 Test loss=0.298517 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.6136110424995422
[5/24] Train loss=0.5948941707611084
[10/24] Train loss=0.6449676156044006
[15/24] Train loss=0.6111710667610168
[20/24] Train loss=0.5404072999954224
Test set avg_accuracy=89.23% avg_sensitivity=84.16%, avg_specificity=91.17% avg_auc=95.20%
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.630970 Test loss=0.284057 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.6006944179534912
[5/24] Train loss=0.5706637501716614
[10/24] Train loss=0.6584076285362244
[15/24] Train loss=0.5996935367584229
[20/24] Train loss=0.5322858691215515
Test set avg_accuracy=89.05% avg_sensitivity=82.18%, avg_specificity=91.67% avg_auc=95.19%
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.617020 Test loss=0.282109 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.594982385635376
[5/24] Train loss=0.552324116230011
[10/24] Train loss=0.6471933126449585
[15/24] Train loss=0.5909191370010376
[20/24] Train loss=0.52174973487854
Test set avg_accuracy=88.44% avg_sensitivity=85.90%, avg_specificity=89.40% avg_auc=95.09%
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.606894 Test loss=0.307201 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5785704851150513
[5/24] Train loss=0.5391445159912109
[10/24] Train loss=0.6225107908248901
[15/24] Train loss=0.5726066827774048
[20/24] Train loss=0.5143256187438965
Test set avg_accuracy=89.19% avg_sensitivity=79.92%, avg_specificity=92.73% avg_auc=94.95%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.593401 Test loss=0.268976 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5734396576881409
[5/24] Train loss=0.5338397026062012
[10/24] Train loss=0.6177000999450684
[15/24] Train loss=0.5634915828704834
[20/24] Train loss=0.5024136900901794
Test set avg_accuracy=89.38% avg_sensitivity=81.47%, avg_specificity=92.39% avg_auc=95.01%
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.582657 Test loss=0.268218 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5620168447494507
[5/24] Train loss=0.516274094581604
[10/24] Train loss=0.6170480847358704
[15/24] Train loss=0.5511325597763062
[20/24] Train loss=0.49750733375549316
Test set avg_accuracy=89.15% avg_sensitivity=83.92%, avg_specificity=91.15% avg_auc=95.49%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.571886 Test loss=0.269070 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5353540182113647
[5/24] Train loss=0.49773040413856506
[10/24] Train loss=0.6003533005714417
[15/24] Train loss=0.5447304248809814
[20/24] Train loss=0.48597580194473267
Test set avg_accuracy=89.36% avg_sensitivity=84.72%, avg_specificity=91.13% avg_auc=94.20%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.562938 Test loss=0.300873 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.535651445388794
[5/24] Train loss=0.49414733052253723
[10/24] Train loss=0.6153175830841064
[15/24] Train loss=0.5336757898330688
[20/24] Train loss=0.49327751994132996
Test set avg_accuracy=88.75% avg_sensitivity=84.30%, avg_specificity=90.45% avg_auc=95.39%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.553124 Test loss=0.268647 Current lr=[0.000210185142098938]

[0/24] Train loss=0.5142057538032532
[5/24] Train loss=0.4781377613544464
[10/24] Train loss=0.5956908464431763
[15/24] Train loss=0.5246266722679138
[20/24] Train loss=0.4826936423778534
Test set avg_accuracy=88.65% avg_sensitivity=69.68%, avg_specificity=95.88% avg_auc=94.24%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.545252 Test loss=0.272557 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.5464820265769958
[5/24] Train loss=0.4774300754070282
[10/24] Train loss=0.558732807636261
[15/24] Train loss=0.5194274187088013
[20/24] Train loss=0.47308340668678284
Test set avg_accuracy=88.36% avg_sensitivity=69.97%, avg_specificity=95.38% avg_auc=94.01%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.535360 Test loss=0.276888 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.504804253578186
[5/24] Train loss=0.46915197372436523
[10/24] Train loss=0.585608959197998
[15/24] Train loss=0.5480693578720093
[20/24] Train loss=0.4380381405353546
Test set avg_accuracy=89.24% avg_sensitivity=85.29%, avg_specificity=90.75% avg_auc=95.49%
Best model saved!! Metric=34.773501857861575!!
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.523084 Test loss=0.271922 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.5036382675170898
[5/24] Train loss=0.4412561357021332
[10/24] Train loss=0.5340417623519897
[15/24] Train loss=0.5315614342689514
[20/24] Train loss=0.4592622220516205
Test set avg_accuracy=89.39% avg_sensitivity=81.09%, avg_specificity=92.55% avg_auc=95.23%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.512709 Test loss=0.261182 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.5075958967208862
[5/24] Train loss=0.42670825123786926
[10/24] Train loss=0.5583851337432861
[15/24] Train loss=0.526066780090332
[20/24] Train loss=0.46036916971206665
Test set avg_accuracy=87.84% avg_sensitivity=63.60%, avg_specificity=97.09% avg_auc=92.97%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.506726 Test loss=0.302202 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.47785985469818115
[5/24] Train loss=0.4633694887161255
[10/24] Train loss=0.5262359976768494
[15/24] Train loss=0.4791799783706665
[20/24] Train loss=0.44796594977378845
Test set avg_accuracy=88.35% avg_sensitivity=72.09%, avg_specificity=94.55% avg_auc=93.66%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.497400 Test loss=0.284262 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.46970611810684204
[5/24] Train loss=0.402410089969635
[10/24] Train loss=0.5046021938323975
[15/24] Train loss=0.4947779178619385
[20/24] Train loss=0.44181686639785767
Test set avg_accuracy=85.29% avg_sensitivity=89.67%, avg_specificity=83.61% avg_auc=92.52%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.479862 Test loss=0.421522 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4501418471336365
[5/24] Train loss=0.41399911046028137
[10/24] Train loss=0.49192696809768677
[15/24] Train loss=0.5069004893302917
[20/24] Train loss=0.4321731925010681
Test set avg_accuracy=88.71% avg_sensitivity=79.59%, avg_specificity=92.19% avg_auc=94.64%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.479666 Test loss=0.267997 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4308302104473114
[5/24] Train loss=0.4043373465538025
[10/24] Train loss=0.49543994665145874
[15/24] Train loss=0.48177969455718994
[20/24] Train loss=0.41406869888305664
Test set avg_accuracy=89.21% avg_sensitivity=76.94%, avg_specificity=93.88% avg_auc=93.80%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.469424 Test loss=0.278724 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.418654203414917
[5/24] Train loss=0.39162394404411316
[10/24] Train loss=0.4840683937072754
[15/24] Train loss=0.5071695446968079
[20/24] Train loss=0.39427468180656433
Test set avg_accuracy=88.57% avg_sensitivity=74.92%, avg_specificity=93.78% avg_auc=93.71%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.456664 Test loss=0.283514 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.42191118001937866
[5/24] Train loss=0.39044222235679626
[10/24] Train loss=0.4927941560745239
[15/24] Train loss=0.48682737350463867
[20/24] Train loss=0.42031511664390564
Test set avg_accuracy=88.15% avg_sensitivity=72.61%, avg_specificity=94.08% avg_auc=93.29%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.450694 Test loss=0.288279 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.4349226951599121
[5/24] Train loss=0.3956213891506195
[10/24] Train loss=0.4800702631473541
[15/24] Train loss=0.4490126967430115
[20/24] Train loss=0.4017164707183838
Test set avg_accuracy=88.44% avg_sensitivity=85.95%, avg_specificity=89.39% avg_auc=93.79%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.443006 Test loss=0.319796 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4268317222595215
[5/24] Train loss=0.36061224341392517
[10/24] Train loss=0.47115883231163025
[15/24] Train loss=0.48748451471328735
[20/24] Train loss=0.42745572328567505
Test set avg_accuracy=83.50% avg_sensitivity=91.28%, avg_specificity=80.54% avg_auc=93.55%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.446342 Test loss=0.452403 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.43761855363845825
[5/24] Train loss=0.4326225519180298
[10/24] Train loss=0.4941960275173187
[15/24] Train loss=0.4449273943901062
[20/24] Train loss=0.4015917181968689
Test set avg_accuracy=88.10% avg_sensitivity=87.60%, avg_specificity=88.29% avg_auc=95.03%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.449662 Test loss=0.298880 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4226159453392029
[5/24] Train loss=0.3626613914966583
[10/24] Train loss=0.44009295105934143
[15/24] Train loss=0.468075692653656
[20/24] Train loss=0.3942444920539856
Test set avg_accuracy=79.34% avg_sensitivity=91.75%, avg_specificity=74.60% avg_auc=93.21%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.431149 Test loss=0.516923 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.4408799111843109
[5/24] Train loss=0.35676926374435425
[10/24] Train loss=0.4678654074668884
[15/24] Train loss=0.41735056042671204
[20/24] Train loss=0.4026876389980316
Test set avg_accuracy=85.53% avg_sensitivity=56.62%, avg_specificity=96.56% avg_auc=89.41%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.426352 Test loss=0.378770 Current lr=[0.00029967723776099]

[0/24] Train loss=0.4513724148273468
[5/24] Train loss=0.3530328571796417
[10/24] Train loss=0.45936304330825806
[15/24] Train loss=0.44775640964508057
[20/24] Train loss=0.38947585225105286
Test set avg_accuracy=87.88% avg_sensitivity=70.39%, avg_specificity=94.55% avg_auc=92.55%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.416691 Test loss=0.308037 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.4023061990737915
[5/24] Train loss=0.36082181334495544
[10/24] Train loss=0.4150019586086273
[15/24] Train loss=0.4136514961719513
[20/24] Train loss=0.3762546181678772
Test set avg_accuracy=87.20% avg_sensitivity=65.91%, avg_specificity=95.32% avg_auc=90.71%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.408833 Test loss=0.338387 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.4199121594429016
[5/24] Train loss=0.3609214127063751
[10/24] Train loss=0.411397248506546
[15/24] Train loss=0.41210442781448364
[20/24] Train loss=0.3756329119205475
Test set avg_accuracy=82.08% avg_sensitivity=38.71%, avg_specificity=98.63% avg_auc=85.36%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.403658 Test loss=0.486972 Current lr=[0.000299720220882401]

[0/24] Train loss=0.39904722571372986
[5/24] Train loss=0.34356367588043213
[10/24] Train loss=0.4248153865337372
[15/24] Train loss=0.39059898257255554
[20/24] Train loss=0.350398451089859
Test set avg_accuracy=87.25% avg_sensitivity=67.28%, avg_specificity=94.87% avg_auc=91.99%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.394869 Test loss=0.322922 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.39038917422294617
[5/24] Train loss=0.3207697570323944
[10/24] Train loss=0.40387827157974243
[15/24] Train loss=0.42063650488853455
[20/24] Train loss=0.35732603073120117
Test set avg_accuracy=88.62% avg_sensitivity=83.50%, avg_specificity=90.57% avg_auc=94.87%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.389425 Test loss=0.283440 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3851425349712372
[5/24] Train loss=0.3331650495529175
[10/24] Train loss=0.4018881618976593
[15/24] Train loss=0.4320242702960968
[20/24] Train loss=0.3827259838581085
Test set avg_accuracy=85.53% avg_sensitivity=60.44%, avg_specificity=95.11% avg_auc=90.11%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.401667 Test loss=0.341333 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.37470611929893494
[5/24] Train loss=0.32814860343933105
[10/24] Train loss=0.4181557595729828
[15/24] Train loss=0.39509692788124084
[20/24] Train loss=0.37197479605674744
Test set avg_accuracy=87.50% avg_sensitivity=87.27%, avg_specificity=87.59% avg_auc=94.94%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.381823 Test loss=0.309470 Current lr=[0.000297555943323901]

[0/24] Train loss=0.37225550413131714
[5/24] Train loss=0.3286176323890686
[10/24] Train loss=0.3986606299877167
[15/24] Train loss=0.3892572522163391
[20/24] Train loss=0.34404176473617554
Test set avg_accuracy=86.82% avg_sensitivity=88.35%, avg_specificity=86.24% avg_auc=94.28%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.385047 Test loss=0.327406 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.388437956571579
[5/24] Train loss=0.3374538719654083
[10/24] Train loss=0.37077200412750244
[15/24] Train loss=0.38486960530281067
[20/24] Train loss=0.3690270185470581
Test set avg_accuracy=88.71% avg_sensitivity=73.46%, avg_specificity=94.53% avg_auc=93.66%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.382956 Test loss=0.282576 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.38846826553344727
[5/24] Train loss=0.30641114711761475
[10/24] Train loss=0.40508541464805603
[15/24] Train loss=0.37710702419281006
[20/24] Train loss=0.33778104186058044
Test set avg_accuracy=86.22% avg_sensitivity=61.57%, avg_specificity=95.63% avg_auc=91.64%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.387215 Test loss=0.324299 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3646484315395355
[5/24] Train loss=0.3412923812866211
[10/24] Train loss=0.40456780791282654
[15/24] Train loss=0.362664133310318
[20/24] Train loss=0.33213895559310913
Test set avg_accuracy=88.59% avg_sensitivity=72.14%, avg_specificity=94.87% avg_auc=92.98%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.369575 Test loss=0.293916 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3635343015193939
[5/24] Train loss=0.30420300364494324
[10/24] Train loss=0.4122856855392456
[15/24] Train loss=0.3629832863807678
[20/24] Train loss=0.3289458155632019
Test set avg_accuracy=89.48% avg_sensitivity=85.57%, avg_specificity=90.97% avg_auc=95.33%
Best model saved!! Metric=35.34912214575478!!
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.365493 Test loss=0.275948 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.35189566016197205
[5/24] Train loss=0.3358197808265686
[10/24] Train loss=0.3620767295360565
[15/24] Train loss=0.35765573382377625
[20/24] Train loss=0.32325196266174316
Test set avg_accuracy=86.51% avg_sensitivity=86.61%, avg_specificity=86.47% avg_auc=94.43%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.356862 Test loss=0.333286 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.34661853313446045
[5/24] Train loss=0.2974299490451813
[10/24] Train loss=0.33942654728889465
[15/24] Train loss=0.37330642342567444
[20/24] Train loss=0.3515286445617676
Test set avg_accuracy=89.41% avg_sensitivity=83.55%, avg_specificity=91.65% avg_auc=95.22%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.353515 Test loss=0.271905 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3658778965473175
[5/24] Train loss=0.3007737100124359
[10/24] Train loss=0.3764568567276001
[15/24] Train loss=0.36475902795791626
[20/24] Train loss=0.3236313760280609
Test set avg_accuracy=78.06% avg_sensitivity=90.99%, avg_specificity=73.12% avg_auc=92.48%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.356375 Test loss=0.523116 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.37501260638237
[5/24] Train loss=0.2936607003211975
[10/24] Train loss=0.36223605275154114
[15/24] Train loss=0.3850765526294708
[20/24] Train loss=0.32412824034690857
Test set avg_accuracy=88.66% avg_sensitivity=79.16%, avg_specificity=92.28% avg_auc=94.34%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.356396 Test loss=0.284689 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3690117299556732
[5/24] Train loss=0.32325759530067444
[10/24] Train loss=0.4176318645477295
[15/24] Train loss=0.36257290840148926
[20/24] Train loss=0.323690265417099
Test set avg_accuracy=77.70% avg_sensitivity=91.70%, avg_specificity=72.35% avg_auc=92.53%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.355202 Test loss=0.544979 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3725019097328186
[5/24] Train loss=0.3229396641254425
[10/24] Train loss=0.35784196853637695
[15/24] Train loss=0.3668498694896698
[20/24] Train loss=0.31489577889442444
Test set avg_accuracy=87.98% avg_sensitivity=69.26%, avg_specificity=95.13% avg_auc=92.06%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.348963 Test loss=0.319283 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.34293437004089355
[5/24] Train loss=0.2755590081214905
[10/24] Train loss=0.3345876932144165
[15/24] Train loss=0.35696840286254883
[20/24] Train loss=0.33347272872924805
Test set avg_accuracy=87.46% avg_sensitivity=65.82%, avg_specificity=95.72% avg_auc=90.95%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.327247 Test loss=0.328326 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.31506502628326416
[5/24] Train loss=0.26881715655326843
[10/24] Train loss=0.3428684175014496
[15/24] Train loss=0.3587794899940491
[20/24] Train loss=0.3181314170360565
Test set avg_accuracy=88.71% avg_sensitivity=72.65%, avg_specificity=94.84% avg_auc=93.49%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.331687 Test loss=0.277468 Current lr=[0.000276307469034998]

[0/24] Train loss=0.337514191865921
[5/24] Train loss=0.2850997745990753
[10/24] Train loss=0.34207582473754883
[15/24] Train loss=0.3328588008880615
[20/24] Train loss=0.30709317326545715
Test set avg_accuracy=88.98% avg_sensitivity=74.35%, avg_specificity=94.57% avg_auc=92.48%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.331302 Test loss=0.307406 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.319292277097702
[5/24] Train loss=0.27188199758529663
[10/24] Train loss=0.3093913495540619
[15/24] Train loss=0.3368898034095764
[20/24] Train loss=0.29988086223602295
Test set avg_accuracy=88.52% avg_sensitivity=81.71%, avg_specificity=91.11% avg_auc=93.43%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.321874 Test loss=0.309230 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3285702168941498
[5/24] Train loss=0.27841758728027344
[10/24] Train loss=0.34169596433639526
[15/24] Train loss=0.3270561397075653
[20/24] Train loss=0.29395851492881775
Test set avg_accuracy=88.16% avg_sensitivity=79.07%, avg_specificity=91.64% avg_auc=92.34%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.321995 Test loss=0.326247 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.32915809750556946
[5/24] Train loss=0.3097744882106781
[10/24] Train loss=0.34067314863204956
[15/24] Train loss=0.3197506368160248
[20/24] Train loss=0.31492140889167786
Test set avg_accuracy=88.76% avg_sensitivity=70.25%, avg_specificity=95.83% avg_auc=93.05%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.329154 Test loss=0.292742 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3065245449542999
[5/24] Train loss=0.26812198758125305
[10/24] Train loss=0.32413390278816223
[15/24] Train loss=0.32313302159309387
[20/24] Train loss=0.31013718247413635
Test set avg_accuracy=88.85% avg_sensitivity=78.97%, avg_specificity=92.62% avg_auc=94.07%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.319094 Test loss=0.285545 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3185475766658783
[5/24] Train loss=0.2744773328304291
[10/24] Train loss=0.3102664351463318
[15/24] Train loss=0.30999282002449036
[20/24] Train loss=0.2988632917404175
Test set avg_accuracy=84.13% avg_sensitivity=47.76%, avg_specificity=98.00% avg_auc=86.60%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.309172 Test loss=0.437000 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.32875654101371765
[5/24] Train loss=0.27399691939353943
[10/24] Train loss=0.35902854800224304
[15/24] Train loss=0.3300352096557617
[20/24] Train loss=0.29941412806510925
Test set avg_accuracy=87.01% avg_sensitivity=62.80%, avg_specificity=96.24% avg_auc=88.89%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.317750 Test loss=0.387908 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.31286153197288513
[5/24] Train loss=0.2655119001865387
[10/24] Train loss=0.3351672887802124
[15/24] Train loss=0.33448630571365356
[20/24] Train loss=0.28918173909187317
Test set avg_accuracy=86.35% avg_sensitivity=65.25%, avg_specificity=94.41% avg_auc=89.05%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.317660 Test loss=0.389472 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3035864531993866
[5/24] Train loss=0.263209730386734
[10/24] Train loss=0.30286937952041626
[15/24] Train loss=0.3053658604621887
[20/24] Train loss=0.2825375497341156
Test set avg_accuracy=84.18% avg_sensitivity=48.75%, avg_specificity=97.70% avg_auc=84.56%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.306551 Test loss=0.456799 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3062076270580292
[5/24] Train loss=0.2478397935628891
[10/24] Train loss=0.31741613149642944
[15/24] Train loss=0.27128612995147705
[20/24] Train loss=0.2864810526371002
Test set avg_accuracy=83.29% avg_sensitivity=43.75%, avg_specificity=98.38% avg_auc=84.91%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.298534 Test loss=0.454996 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.288481205701828
[5/24] Train loss=0.2598280608654022
[10/24] Train loss=0.2995651066303253
[15/24] Train loss=0.2868921458721161
[20/24] Train loss=0.2707426846027374
Test set avg_accuracy=84.87% avg_sensitivity=52.95%, avg_specificity=97.05% avg_auc=86.22%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.295709 Test loss=0.416376 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.305545449256897
[5/24] Train loss=0.23998834192752838
[10/24] Train loss=0.30370256304740906
[15/24] Train loss=0.3087252974510193
[20/24] Train loss=0.2814593017101288
Test set avg_accuracy=85.70% avg_sensitivity=61.34%, avg_specificity=95.00% avg_auc=86.07%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.311418 Test loss=0.422323 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.31318923830986023
[5/24] Train loss=0.25238168239593506
[10/24] Train loss=0.29096248745918274
[15/24] Train loss=0.29446810483932495
[20/24] Train loss=0.2936701476573944
Test set avg_accuracy=88.09% avg_sensitivity=68.79%, avg_specificity=95.45% avg_auc=91.23%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.302191 Test loss=0.322055 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.30361300706863403
[5/24] Train loss=0.2338244765996933
[10/24] Train loss=0.284106969833374
[15/24] Train loss=0.2625339925289154
[20/24] Train loss=0.2770959734916687
Test set avg_accuracy=87.58% avg_sensitivity=70.77%, avg_specificity=93.99% avg_auc=90.60%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.283695 Test loss=0.343489 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.27806147933006287
[5/24] Train loss=0.25666218996047974
[10/24] Train loss=0.33770060539245605
[15/24] Train loss=0.27896648645401
[20/24] Train loss=0.269080251455307
Test set avg_accuracy=88.05% avg_sensitivity=67.99%, avg_specificity=95.70% avg_auc=91.71%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.292022 Test loss=0.324981 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2908337414264679
[5/24] Train loss=0.24925217032432556
[10/24] Train loss=0.30936944484710693
[15/24] Train loss=0.30005526542663574
[20/24] Train loss=0.2652459740638733
Test set avg_accuracy=88.39% avg_sensitivity=71.57%, avg_specificity=94.80% avg_auc=92.08%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.291095 Test loss=0.321401 Current lr=[0.000224838296036774]

[0/24] Train loss=0.29915013909339905
[5/24] Train loss=0.24643994867801666
[10/24] Train loss=0.2795965373516083
[15/24] Train loss=0.2740432918071747
[20/24] Train loss=0.25809383392333984
Test set avg_accuracy=89.34% avg_sensitivity=77.09%, avg_specificity=94.01% avg_auc=93.79%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.279606 Test loss=0.287449 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2750129699707031
[5/24] Train loss=0.2303878366947174
[10/24] Train loss=0.27529603242874146
[15/24] Train loss=0.27380427718162537
[20/24] Train loss=0.2515040934085846
Test set avg_accuracy=88.84% avg_sensitivity=73.08%, avg_specificity=94.86% avg_auc=92.64%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.273162 Test loss=0.307092 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2650177478790283
[5/24] Train loss=0.2419266551733017
[10/24] Train loss=0.2678454518318176
[15/24] Train loss=0.2401404231786728
[20/24] Train loss=0.2439376413822174
Test set avg_accuracy=88.88% avg_sensitivity=83.40%, avg_specificity=90.97% avg_auc=94.25%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.260695 Test loss=0.296969 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2741784453392029
[5/24] Train loss=0.22407935559749603
[10/24] Train loss=0.27079227566719055
[15/24] Train loss=0.25542616844177246
[20/24] Train loss=0.26760926842689514
Test set avg_accuracy=89.09% avg_sensitivity=75.15%, avg_specificity=94.41% avg_auc=93.33%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.266955 Test loss=0.300369 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.26967743039131165
[5/24] Train loss=0.21798592805862427
[10/24] Train loss=0.2606906294822693
[15/24] Train loss=0.2547646462917328
[20/24] Train loss=0.2563522458076477
Test set avg_accuracy=87.50% avg_sensitivity=66.24%, avg_specificity=95.61% avg_auc=91.95%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.264799 Test loss=0.327523 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2682439982891083
[5/24] Train loss=0.2231336086988449
[10/24] Train loss=0.27229824662208557
[15/24] Train loss=0.24385866522789001
[20/24] Train loss=0.2587885558605194
Test set avg_accuracy=89.66% avg_sensitivity=82.32%, avg_specificity=92.46% avg_auc=92.76%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.267708 Test loss=0.342871 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2948683500289917
[5/24] Train loss=0.2380283772945404
[10/24] Train loss=0.2867163419723511
[15/24] Train loss=0.2658334970474243
[20/24] Train loss=0.2667042016983032
Test set avg_accuracy=89.32% avg_sensitivity=77.46%, avg_specificity=93.85% avg_auc=94.25%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.266357 Test loss=0.282915 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2608488202095032
[5/24] Train loss=0.21749630570411682
[10/24] Train loss=0.25398358702659607
[15/24] Train loss=0.2605849504470825
[20/24] Train loss=0.24952423572540283
Test set avg_accuracy=88.16% avg_sensitivity=80.95%, avg_specificity=90.92% avg_auc=92.80%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.259078 Test loss=0.326098 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.27392441034317017
[5/24] Train loss=0.23201148211956024
[10/24] Train loss=0.268843412399292
[15/24] Train loss=0.25756824016571045
[20/24] Train loss=0.24990035593509674
Test set avg_accuracy=89.49% avg_sensitivity=81.00%, avg_specificity=92.73% avg_auc=94.00%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.260771 Test loss=0.295434 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.26076528429985046
[5/24] Train loss=0.2105562537908554
[10/24] Train loss=0.25717130303382874
[15/24] Train loss=0.23560702800750732
[20/24] Train loss=0.2514738440513611
Test set avg_accuracy=88.40% avg_sensitivity=76.05%, avg_specificity=93.11% avg_auc=92.95%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.250603 Test loss=0.314036 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2461027055978775
[5/24] Train loss=0.20900343358516693
[10/24] Train loss=0.2576195001602173
[15/24] Train loss=0.23574982583522797
[20/24] Train loss=0.2368534356355667
Test set avg_accuracy=88.68% avg_sensitivity=82.56%, avg_specificity=91.02% avg_auc=94.40%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.249118 Test loss=0.323471 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.27358362078666687
[5/24] Train loss=0.21254204213619232
[10/24] Train loss=0.23195268213748932
[15/24] Train loss=0.23920130729675293
[20/24] Train loss=0.2324371188879013
Test set avg_accuracy=89.00% avg_sensitivity=80.58%, avg_specificity=92.21% avg_auc=93.37%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.244340 Test loss=0.315313 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.26258325576782227
[5/24] Train loss=0.19709813594818115
[10/24] Train loss=0.23212692141532898
[15/24] Train loss=0.23270903527736664
[20/24] Train loss=0.22682124376296997
Test set avg_accuracy=88.91% avg_sensitivity=76.10%, avg_specificity=93.79% avg_auc=92.89%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.240250 Test loss=0.308540 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.24714435636997223
[5/24] Train loss=0.19888871908187866
[10/24] Train loss=0.23044931888580322
[15/24] Train loss=0.22793328762054443
[20/24] Train loss=0.21841931343078613
Test set avg_accuracy=89.05% avg_sensitivity=74.49%, avg_specificity=94.60% avg_auc=91.58%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.236905 Test loss=0.328594 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.24270465970039368
[5/24] Train loss=0.20829737186431885
[10/24] Train loss=0.23863142728805542
[15/24] Train loss=0.2377953678369522
[20/24] Train loss=0.2316640317440033
Test set avg_accuracy=89.30% avg_sensitivity=79.77%, avg_specificity=92.93% avg_auc=93.35%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.240204 Test loss=0.310238 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.255175918340683
[5/24] Train loss=0.20248359441757202
[10/24] Train loss=0.22049281001091003
[15/24] Train loss=0.2391115128993988
[20/24] Train loss=0.21861611306667328
Test set avg_accuracy=88.63% avg_sensitivity=81.52%, avg_specificity=91.35% avg_auc=93.99%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.231796 Test loss=0.321923 Current lr=[0.000156543481933168]

[0/24] Train loss=0.23770616948604584
[5/24] Train loss=0.19739675521850586
[10/24] Train loss=0.23184512555599213
[15/24] Train loss=0.21099857985973358
[20/24] Train loss=0.23310983180999756
Test set avg_accuracy=89.38% avg_sensitivity=78.64%, avg_specificity=93.47% avg_auc=94.01%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.232503 Test loss=0.295090 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.22355052828788757
[5/24] Train loss=0.1917138546705246
[10/24] Train loss=0.22584976255893707
[15/24] Train loss=0.22316420078277588
[20/24] Train loss=0.22654566168785095
Test set avg_accuracy=89.38% avg_sensitivity=76.57%, avg_specificity=94.26% avg_auc=93.74%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.222982 Test loss=0.297940 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.22239544987678528
[5/24] Train loss=0.19621331989765167
[10/24] Train loss=0.22018851339817047
[15/24] Train loss=0.221030592918396
[20/24] Train loss=0.22025465965270996
Test set avg_accuracy=89.08% avg_sensitivity=73.36%, avg_specificity=95.07% avg_auc=93.44%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.227778 Test loss=0.300251 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.24414286017417908
[5/24] Train loss=0.2036224603652954
[10/24] Train loss=0.22715674340724945
[15/24] Train loss=0.22947131097316742
[20/24] Train loss=0.22043476998806
Test set avg_accuracy=89.47% avg_sensitivity=77.09%, avg_specificity=94.19% avg_auc=94.43%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.228002 Test loss=0.285631 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.22172188758850098
[5/24] Train loss=0.20473216474056244
[10/24] Train loss=0.2159552425146103
[15/24] Train loss=0.21019987761974335
[20/24] Train loss=0.2161765843629837
Test set avg_accuracy=89.36% avg_sensitivity=78.36%, avg_specificity=93.56% avg_auc=94.16%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.220066 Test loss=0.286865 Current lr=[0.000134135431043539]

[0/24] Train loss=0.21805600821971893
[5/24] Train loss=0.2005826234817505
[10/24] Train loss=0.23323871195316315
[15/24] Train loss=0.2075018286705017
[20/24] Train loss=0.2525920569896698
Test set avg_accuracy=89.39% avg_sensitivity=77.23%, avg_specificity=94.03% avg_auc=93.88%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.226460 Test loss=0.288393 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.22093752026557922
[5/24] Train loss=0.20213229954242706
[10/24] Train loss=0.2225414663553238
[15/24] Train loss=0.20865556597709656
[20/24] Train loss=0.22332599759101868
Test set avg_accuracy=88.78% avg_sensitivity=76.66%, avg_specificity=93.40% avg_auc=94.11%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.222902 Test loss=0.296151 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.22668682038784027
[5/24] Train loss=0.19288796186447144
[10/24] Train loss=0.19885095953941345
[15/24] Train loss=0.20776157081127167
[20/24] Train loss=0.21547354757785797
Test set avg_accuracy=88.85% avg_sensitivity=76.90%, avg_specificity=93.42% avg_auc=93.84%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.217925 Test loss=0.302082 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.22712144255638123
[5/24] Train loss=0.2054293304681778
[10/24] Train loss=0.22200191020965576
[15/24] Train loss=0.20858697593212128
[20/24] Train loss=0.24556013941764832
Test set avg_accuracy=89.10% avg_sensitivity=80.48%, avg_specificity=92.39% avg_auc=94.27%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.228639 Test loss=0.295111 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.21327194571495056
[5/24] Train loss=0.19097433984279633
[10/24] Train loss=0.21217992901802063
[15/24] Train loss=0.2192702740430832
[20/24] Train loss=0.22499743103981018
Test set avg_accuracy=88.12% avg_sensitivity=80.95%, avg_specificity=90.86% avg_auc=93.97%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.221390 Test loss=0.317446 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.221909761428833
[5/24] Train loss=0.20466062426567078
[10/24] Train loss=0.22649797797203064
[15/24] Train loss=0.21569879353046417
[20/24] Train loss=0.20423175394535065
Test set avg_accuracy=88.68% avg_sensitivity=73.64%, avg_specificity=94.42% avg_auc=92.75%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.221383 Test loss=0.306969 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.22249218821525574
[5/24] Train loss=0.20212116837501526
[10/24] Train loss=0.2146177440881729
[15/24] Train loss=0.18931923806667328
[20/24] Train loss=0.19968193769454956
Test set avg_accuracy=89.08% avg_sensitivity=77.51%, avg_specificity=93.49% avg_auc=93.44%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.215151 Test loss=0.300964 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.22042743861675262
[5/24] Train loss=0.1865871250629425
[10/24] Train loss=0.20262600481510162
[15/24] Train loss=0.19788871705532074
[20/24] Train loss=0.1957872211933136
Test set avg_accuracy=88.92% avg_sensitivity=82.18%, avg_specificity=91.49% avg_auc=94.04%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.205041 Test loss=0.305295 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.20066997408866882
[5/24] Train loss=0.17676818370819092
[10/24] Train loss=0.19216474890708923
[15/24] Train loss=0.18650056421756744
[20/24] Train loss=0.19815309345722198
Test set avg_accuracy=88.87% avg_sensitivity=76.61%, avg_specificity=93.54% avg_auc=93.35%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.201023 Test loss=0.294952 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.2010221928358078
[5/24] Train loss=0.1756133735179901
[10/24] Train loss=0.1905386745929718
[15/24] Train loss=0.18525715172290802
[20/24] Train loss=0.18983225524425507
Test set avg_accuracy=88.62% avg_sensitivity=84.44%, avg_specificity=90.21% avg_auc=94.63%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.196657 Test loss=0.305960 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2030346393585205
[5/24] Train loss=0.17355112731456757
[10/24] Train loss=0.1934986412525177
[15/24] Train loss=0.1845463514328003
[20/24] Train loss=0.19701457023620605
Test set avg_accuracy=88.80% avg_sensitivity=80.72%, avg_specificity=91.89% avg_auc=94.17%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.197261 Test loss=0.306228 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.19103021919727325
[5/24] Train loss=0.16704997420310974
[10/24] Train loss=0.18866759538650513
[15/24] Train loss=0.18053632974624634
[20/24] Train loss=0.1896318644285202
Test set avg_accuracy=89.21% avg_sensitivity=82.56%, avg_specificity=91.74% avg_auc=94.20%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.195292 Test loss=0.308652 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.2054491490125656
[5/24] Train loss=0.16855207085609436
[10/24] Train loss=0.18491196632385254
[15/24] Train loss=0.1896486133337021
[20/24] Train loss=0.1821945309638977
Test set avg_accuracy=89.06% avg_sensitivity=78.31%, avg_specificity=93.16% avg_auc=93.81%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.194343 Test loss=0.298901 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.20144231617450714
[5/24] Train loss=0.1696251630783081
[10/24] Train loss=0.19109755754470825
[15/24] Train loss=0.18344908952713013
[20/24] Train loss=0.17983503639698029
Test set avg_accuracy=89.54% avg_sensitivity=78.41%, avg_specificity=93.79% avg_auc=93.49%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.191813 Test loss=0.300205 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.19943195581436157
[5/24] Train loss=0.16720719635486603
[10/24] Train loss=0.18836034834384918
[15/24] Train loss=0.18487265706062317
[20/24] Train loss=0.18943318724632263
Test set avg_accuracy=89.71% avg_sensitivity=78.93%, avg_specificity=93.83% avg_auc=94.46%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.191050 Test loss=0.283204 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1875447779893875
[5/24] Train loss=0.16837573051452637
[10/24] Train loss=0.17999973893165588
[15/24] Train loss=0.17974816262722015
[20/24] Train loss=0.1856633573770523
Test set avg_accuracy=89.71% avg_sensitivity=80.06%, avg_specificity=93.40% avg_auc=94.15%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.187862 Test loss=0.291054 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.19225464761257172
[5/24] Train loss=0.15967747569084167
[10/24] Train loss=0.18261852860450745
[15/24] Train loss=0.17504872381687164
[20/24] Train loss=0.1806885153055191
Test set avg_accuracy=89.67% avg_sensitivity=76.47%, avg_specificity=94.71% avg_auc=93.47%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.187016 Test loss=0.287158 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1829325407743454
[5/24] Train loss=0.16378657519817352
[10/24] Train loss=0.17705632746219635
[15/24] Train loss=0.17185889184474945
[20/24] Train loss=0.1759980022907257
Test set avg_accuracy=89.87% avg_sensitivity=77.65%, avg_specificity=94.53% avg_auc=93.75%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.182953 Test loss=0.283337 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.18520356714725494
[5/24] Train loss=0.15774521231651306
[10/24] Train loss=0.17168381810188293
[15/24] Train loss=0.17295299470424652
[20/24] Train loss=0.17907147109508514
Test set avg_accuracy=89.52% avg_sensitivity=77.60%, avg_specificity=94.06% avg_auc=93.87%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.180807 Test loss=0.290355 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.18084341287612915
[5/24] Train loss=0.15931673347949982
[10/24] Train loss=0.17153966426849365
[15/24] Train loss=0.16964073479175568
[20/24] Train loss=0.18491056561470032
Test set avg_accuracy=89.92% avg_sensitivity=79.35%, avg_specificity=93.96% avg_auc=94.10%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.179233 Test loss=0.290115 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.18202967941761017
[5/24] Train loss=0.15990974009037018
[10/24] Train loss=0.18352989852428436
[15/24] Train loss=0.17543472349643707
[20/24] Train loss=0.18152861297130585
Test set avg_accuracy=90.20% avg_sensitivity=77.98%, avg_specificity=94.86% avg_auc=93.80%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.180402 Test loss=0.287538 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.18243056535720825
[5/24] Train loss=0.16223585605621338
[10/24] Train loss=0.17263633012771606
[15/24] Train loss=0.17430929839611053
[20/24] Train loss=0.17815855145454407
Test set avg_accuracy=89.96% avg_sensitivity=81.38%, avg_specificity=93.24% avg_auc=94.56%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.179083 Test loss=0.285380 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1809227615594864
[5/24] Train loss=0.15738819539546967
[10/24] Train loss=0.17905116081237793
[15/24] Train loss=0.16724826395511627
[20/24] Train loss=0.17668551206588745
Test set avg_accuracy=89.56% avg_sensitivity=76.28%, avg_specificity=94.62% avg_auc=93.49%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.176816 Test loss=0.294111 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.18059039115905762
[5/24] Train loss=0.15809500217437744
[10/24] Train loss=0.17337419092655182
[15/24] Train loss=0.1605796068906784
[20/24] Train loss=0.16939835250377655
Test set avg_accuracy=89.48% avg_sensitivity=76.10%, avg_specificity=94.59% avg_auc=93.17%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.175647 Test loss=0.302211 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.17950929701328278
[5/24] Train loss=0.15132147073745728
[10/24] Train loss=0.17226840555667877
[15/24] Train loss=0.16749970614910126
[20/24] Train loss=0.16800738871097565
Test set avg_accuracy=89.71% avg_sensitivity=76.52%, avg_specificity=94.75% avg_auc=93.34%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.174967 Test loss=0.295678 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.18412844836711884
[5/24] Train loss=0.15343359112739563
[10/24] Train loss=0.17101086676120758
[15/24] Train loss=0.1672080159187317
[20/24] Train loss=0.16818107664585114
Test set avg_accuracy=89.60% avg_sensitivity=77.98%, avg_specificity=94.03% avg_auc=93.52%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.175750 Test loss=0.299704 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.18087619543075562
[5/24] Train loss=0.15395000576972961
[10/24] Train loss=0.16900044679641724
[15/24] Train loss=0.17037542164325714
[20/24] Train loss=0.1736908257007599
Test set avg_accuracy=89.66% avg_sensitivity=79.02%, avg_specificity=93.72% avg_auc=93.86%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.176361 Test loss=0.299683 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.17772968113422394
[5/24] Train loss=0.1569702923297882
[10/24] Train loss=0.16671448945999146
[15/24] Train loss=0.17847685515880585
[20/24] Train loss=0.1717376410961151
Test set avg_accuracy=89.09% avg_sensitivity=80.72%, avg_specificity=92.28% avg_auc=94.29%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.176546 Test loss=0.297603 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1757417470216751
[5/24] Train loss=0.16078171133995056
[10/24] Train loss=0.1692723035812378
[15/24] Train loss=0.17137277126312256
[20/24] Train loss=0.18003547191619873
Test set avg_accuracy=89.28% avg_sensitivity=80.48%, avg_specificity=92.64% avg_auc=94.21%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.178454 Test loss=0.294955 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.17417863011360168
[5/24] Train loss=0.15424521267414093
[10/24] Train loss=0.17520996928215027
[15/24] Train loss=0.16238591074943542
[20/24] Train loss=0.17647883296012878
Test set avg_accuracy=89.30% avg_sensitivity=78.93%, avg_specificity=93.25% avg_auc=93.95%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.175311 Test loss=0.290853 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1817941814661026
[5/24] Train loss=0.15453490614891052
[10/24] Train loss=0.16602563858032227
[15/24] Train loss=0.16286173462867737
[20/24] Train loss=0.1666291356086731
Test set avg_accuracy=89.52% avg_sensitivity=77.89%, avg_specificity=93.96% avg_auc=93.85%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.172170 Test loss=0.287185 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1707795113325119
[5/24] Train loss=0.14820244908332825
[10/24] Train loss=0.1619863063097
[15/24] Train loss=0.1601548045873642
[20/24] Train loss=0.1642085462808609
Test set avg_accuracy=89.51% avg_sensitivity=78.74%, avg_specificity=93.61% avg_auc=94.05%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.168552 Test loss=0.285766 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.16843318939208984
[5/24] Train loss=0.1471434086561203
[10/24] Train loss=0.1602206826210022
[15/24] Train loss=0.16186994314193726
[20/24] Train loss=0.1620003879070282
Test set avg_accuracy=89.67% avg_sensitivity=78.36%, avg_specificity=93.99% avg_auc=93.66%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.166704 Test loss=0.291535 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1664748340845108
[5/24] Train loss=0.14733435213565826
[10/24] Train loss=0.16066046059131622
[15/24] Train loss=0.15662997961044312
[20/24] Train loss=0.16100922226905823
Test set avg_accuracy=89.54% avg_sensitivity=78.50%, avg_specificity=93.76% avg_auc=93.87%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.165799 Test loss=0.287179 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1700841635465622
[5/24] Train loss=0.14785073697566986
[10/24] Train loss=0.16097219288349152
[15/24] Train loss=0.15592865645885468
[20/24] Train loss=0.16269460320472717
Test set avg_accuracy=89.52% avg_sensitivity=79.26%, avg_specificity=93.43% avg_auc=94.01%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.166253 Test loss=0.288401 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.16729508340358734
[5/24] Train loss=0.14652074873447418
[10/24] Train loss=0.16265596449375153
[15/24] Train loss=0.15477319061756134
[20/24] Train loss=0.15939223766326904
Test set avg_accuracy=89.66% avg_sensitivity=78.08%, avg_specificity=94.08% avg_auc=93.84%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.165036 Test loss=0.289866 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.16714732348918915
[5/24] Train loss=0.1463516354560852
[10/24] Train loss=0.16013126075267792
[15/24] Train loss=0.15331687033176422
[20/24] Train loss=0.15901486575603485
Test set avg_accuracy=89.54% avg_sensitivity=78.03%, avg_specificity=93.94% avg_auc=93.80%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.163614 Test loss=0.290239 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.16401828825473785
[5/24] Train loss=0.14559631049633026
[10/24] Train loss=0.15881933271884918
[15/24] Train loss=0.15667010843753815
[20/24] Train loss=0.16103295981884003
Test set avg_accuracy=89.56% avg_sensitivity=78.26%, avg_specificity=93.87% avg_auc=93.71%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.163629 Test loss=0.290821 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.16295690834522247
[5/24] Train loss=0.1454121619462967
[10/24] Train loss=0.159597709774971
[15/24] Train loss=0.16080375015735626
[20/24] Train loss=0.15637178719043732
Test set avg_accuracy=89.61% avg_sensitivity=78.45%, avg_specificity=93.87% avg_auc=93.78%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.163902 Test loss=0.290553 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.16493651270866394
[5/24] Train loss=0.14430002868175507
[10/24] Train loss=0.16172586381435394
[15/24] Train loss=0.15357626974582672
[20/24] Train loss=0.1596338003873825
Test set avg_accuracy=89.70% avg_sensitivity=78.45%, avg_specificity=93.99% avg_auc=93.72%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.163364 Test loss=0.291037 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.16326992213726044
[5/24] Train loss=0.1461155116558075
[10/24] Train loss=0.15534526109695435
[15/24] Train loss=0.1574627161026001
[20/24] Train loss=0.160651296377182
Test set avg_accuracy=89.66% avg_sensitivity=78.45%, avg_specificity=93.94% avg_auc=93.76%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.162824 Test loss=0.291140 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.16543732583522797
[5/24] Train loss=0.14468619227409363
[10/24] Train loss=0.15504665672779083
[15/24] Train loss=0.15590980648994446
[20/24] Train loss=0.16104918718338013
Test set avg_accuracy=89.67% avg_sensitivity=78.60%, avg_specificity=93.90% avg_auc=93.79%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.163466 Test loss=0.291185 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.16519808769226074
[5/24] Train loss=0.1459961235523224
[10/24] Train loss=0.15443576872348785
[15/24] Train loss=0.1516680121421814
[20/24] Train loss=0.15948370099067688
Test set avg_accuracy=89.67% avg_sensitivity=78.22%, avg_specificity=94.05% avg_auc=93.70%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.162956 Test loss=0.290433 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1647399663925171
[5/24] Train loss=0.14531339704990387
[10/24] Train loss=0.15424910187721252
[15/24] Train loss=0.15788528323173523
[20/24] Train loss=0.16389955580234528
Test set avg_accuracy=89.66% avg_sensitivity=78.41%, avg_specificity=93.96% avg_auc=93.76%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.163135 Test loss=0.290069 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.16513444483280182
[5/24] Train loss=0.1450498402118683
[10/24] Train loss=0.15679813921451569
[15/24] Train loss=0.15408164262771606
[20/24] Train loss=0.15962675213813782
Test set avg_accuracy=89.62% avg_sensitivity=78.55%, avg_specificity=93.85% avg_auc=93.79%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.162623 Test loss=0.290132 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1685040146112442
[5/24] Train loss=0.14668360352516174
[10/24] Train loss=0.15612272918224335
[15/24] Train loss=0.15481142699718475
[20/24] Train loss=0.16323983669281006
Test set avg_accuracy=89.62% avg_sensitivity=78.50%, avg_specificity=93.87% avg_auc=93.78%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.163019 Test loss=0.290210 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.16444902122020721
[5/24] Train loss=0.14642007648944855
[10/24] Train loss=0.15942421555519104
[15/24] Train loss=0.15525811910629272
[20/24] Train loss=0.15892164409160614
Test set avg_accuracy=89.64% avg_sensitivity=78.55%, avg_specificity=93.87% avg_auc=93.77%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.162771 Test loss=0.290192 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.16102157533168793
[5/24] Train loss=0.14811109006404877
[10/24] Train loss=0.15572988986968994
[15/24] Train loss=0.15541554987430573
[20/24] Train loss=0.15840598940849304
Test set avg_accuracy=89.64% avg_sensitivity=78.55%, avg_specificity=93.87% avg_auc=93.77%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.162211 Test loss=0.290296 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1628798544406891
[5/24] Train loss=0.14471036195755005
[10/24] Train loss=0.15554583072662354
[15/24] Train loss=0.15274104475975037
[20/24] Train loss=0.16201621294021606
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=89.67% avg_sensitivity=78.60%, avg_specificity=93.90% avg_auc=93.77%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.162368 Test loss=0.290012 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=89.48% sen=85.57%, spe=90.97%, auc=95.33%!
Fold[7] Avg_overlap=0.73%(0.20753283264142816)
[0/24] Train loss=1.4859949350357056
[5/24] Train loss=1.4725850820541382
[10/24] Train loss=1.479153037071228
[15/24] Train loss=1.431032657623291
[20/24] Train loss=1.4230494499206543
Test set avg_accuracy=57.72% avg_sensitivity=60.80%, avg_specificity=56.69% avg_auc=56.30%
Best model saved!! Metric=-94.49754828987928!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=1.450309 Test loss=0.686031 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.3866381645202637
[5/24] Train loss=1.3796558380126953
[10/24] Train loss=1.3832306861877441
[15/24] Train loss=1.3688392639160156
[20/24] Train loss=1.3237656354904175
Test set avg_accuracy=63.48% avg_sensitivity=84.77%, avg_specificity=56.32% avg_auc=68.70%
Best model saved!! Metric=-52.724998233458805!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=1.373996 Test loss=0.656730 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3319288492202759
[5/24] Train loss=1.309460997581482
[10/24] Train loss=1.3106387853622437
[15/24] Train loss=1.264490008354187
[20/24] Train loss=1.2769687175750732
Test set avg_accuracy=67.66% avg_sensitivity=86.17%, avg_specificity=61.44% avg_auc=76.79%
Best model saved!! Metric=-33.94900465487479!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=1.302615 Test loss=0.623873 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.247548222541809
[5/24] Train loss=1.2447706460952759
[10/24] Train loss=1.2524018287658691
[15/24] Train loss=1.1919522285461426
[20/24] Train loss=1.1588504314422607
Test set avg_accuracy=69.04% avg_sensitivity=88.56%, avg_specificity=62.48% avg_auc=81.17%
Best model saved!! Metric=-24.75913424444954!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=1.227652 Test loss=0.603145 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.14862859249115
[5/24] Train loss=1.1556938886642456
[10/24] Train loss=1.1727298498153687
[15/24] Train loss=1.0959999561309814
[20/24] Train loss=1.0883538722991943
Test set avg_accuracy=71.15% avg_sensitivity=90.52%, avg_specificity=64.64% avg_auc=83.90%
Best model saved!! Metric=-15.797118580759062!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=1.149098 Test loss=0.583819 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.079596996307373
[5/24] Train loss=1.07882821559906
[10/24] Train loss=1.1105413436889648
[15/24] Train loss=1.0395503044128418
[20/24] Train loss=1.0029925107955933
Test set avg_accuracy=71.69% avg_sensitivity=92.49%, avg_specificity=64.71% avg_auc=86.12%
Best model saved!! Metric=-10.991808164210767!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=1.081230 Test loss=0.568409 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.01472008228302
[5/24] Train loss=1.0137479305267334
[10/24] Train loss=1.0558289289474487
[15/24] Train loss=0.9891876578330994
[20/24] Train loss=0.9396859407424927
Test set avg_accuracy=75.36% avg_sensitivity=91.20%, avg_specificity=70.05% avg_auc=88.09%
Best model saved!! Metric=-1.3033508103481637!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=1.023594 Test loss=0.527196 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9588626027107239
[5/24] Train loss=0.9586707353591919
[10/24] Train loss=0.9955416917800903
[15/24] Train loss=0.9358720779418945
[20/24] Train loss=0.9009402990341187
Test set avg_accuracy=77.32% avg_sensitivity=90.94%, avg_specificity=72.74% avg_auc=90.00%
Best model saved!! Metric=4.997068416581101!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.971695 Test loss=0.488538 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.9032493829727173
[5/24] Train loss=0.9302552342414856
[10/24] Train loss=0.9504629373550415
[15/24] Train loss=0.8998433351516724
[20/24] Train loss=0.8345965147018433
Test set avg_accuracy=79.48% avg_sensitivity=91.25%, avg_specificity=75.53% avg_auc=91.17%
Best model saved!! Metric=11.420344647409323!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.926275 Test loss=0.473326 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8720552325248718
[5/24] Train loss=0.8709061145782471
[10/24] Train loss=0.9134271740913391
[15/24] Train loss=0.8643589019775391
[20/24] Train loss=0.7878179550170898
Test set avg_accuracy=81.58% avg_sensitivity=90.99%, avg_specificity=78.41% avg_auc=92.20%
Best model saved!! Metric=17.174282205743225!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.880703 Test loss=0.438677 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.8379524946212769
[5/24] Train loss=0.835752010345459
[10/24] Train loss=0.8499940633773804
[15/24] Train loss=0.827991783618927
[20/24] Train loss=0.7443687915802002
Test set avg_accuracy=83.68% avg_sensitivity=89.69%, avg_specificity=81.67% avg_auc=93.02%
Best model saved!! Metric=22.063822337472175!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.841670 Test loss=0.404805 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.7951400279998779
[5/24] Train loss=0.792426347732544
[10/24] Train loss=0.8489091396331787
[15/24] Train loss=0.7936936020851135
[20/24] Train loss=0.7162318229675293
Test set avg_accuracy=84.87% avg_sensitivity=89.07%, avg_specificity=83.46% avg_auc=93.57%
Best model saved!! Metric=24.97491845385295!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.807273 Test loss=0.382992 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7659000754356384
[5/24] Train loss=0.7548772692680359
[10/24] Train loss=0.8168723583221436
[15/24] Train loss=0.7741639614105225
[20/24] Train loss=0.6824973225593567
Test set avg_accuracy=85.98% avg_sensitivity=88.56%, avg_specificity=85.11% avg_auc=93.93%
Best model saved!! Metric=27.569125149537413!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.773890 Test loss=0.368723 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.730262815952301
[5/24] Train loss=0.7401342391967773
[10/24] Train loss=0.7695102095603943
[15/24] Train loss=0.7527192831039429
[20/24] Train loss=0.6671869158744812
Test set avg_accuracy=87.03% avg_sensitivity=85.45%, avg_specificity=87.56% avg_auc=94.14%
Best model saved!! Metric=28.185486356959032!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.749200 Test loss=0.334346 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.707038938999176
[5/24] Train loss=0.69878089427948
[10/24] Train loss=0.7491384744644165
[15/24] Train loss=0.7208303213119507
[20/24] Train loss=0.6120001077651978
Test set avg_accuracy=88.19% avg_sensitivity=83.43%, avg_specificity=89.79% avg_auc=94.25%
Best model saved!! Metric=29.659073394557538!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.723282 Test loss=0.311657 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.6824852824211121
[5/24] Train loss=0.6938607692718506
[10/24] Train loss=0.7286917567253113
[15/24] Train loss=0.706561803817749
[20/24] Train loss=0.6068055629730225
Test set avg_accuracy=87.43% avg_sensitivity=86.59%, avg_specificity=87.72% avg_auc=94.47%
Best model saved!! Metric=30.20980447256801!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.703397 Test loss=0.321336 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6522443890571594
[5/24] Train loss=0.6643014550209045
[10/24] Train loss=0.7016473412513733
[15/24] Train loss=0.692662239074707
[20/24] Train loss=0.5833938717842102
Test set avg_accuracy=87.43% avg_sensitivity=88.04%, avg_specificity=87.23% avg_auc=94.56%
Best model saved!! Metric=31.262183924054796!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.686104 Test loss=0.326241 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.637363612651825
[5/24] Train loss=0.6509222984313965
[10/24] Train loss=0.6864053606987
[15/24] Train loss=0.6749985218048096
[20/24] Train loss=0.5647972226142883
Test set avg_accuracy=88.02% avg_sensitivity=86.85%, avg_specificity=88.42% avg_auc=94.60%
Best model saved!! Metric=31.877775557946464!!
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.667149 Test loss=0.311073 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.6253021359443665
[5/24] Train loss=0.6120426654815674
[10/24] Train loss=0.6715205311775208
[15/24] Train loss=0.6782095432281494
[20/24] Train loss=0.5438059568405151
Test set avg_accuracy=87.37% avg_sensitivity=88.50%, avg_specificity=86.99% avg_auc=94.70%
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.649103 Test loss=0.325746 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.6154731512069702
[5/24] Train loss=0.6209365725517273
[10/24] Train loss=0.6500417590141296
[15/24] Train loss=0.6533945202827454
[20/24] Train loss=0.5403620600700378
Test set avg_accuracy=87.72% avg_sensitivity=88.61%, avg_specificity=87.42% avg_auc=94.93%
Best model saved!! Metric=32.6809626600358!!
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.639128 Test loss=0.323344 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5859012007713318
[5/24] Train loss=0.5946770906448364
[10/24] Train loss=0.6375694870948792
[15/24] Train loss=0.6702100038528442
[20/24] Train loss=0.5168607831001282
Test set avg_accuracy=87.84% avg_sensitivity=88.76%, avg_specificity=87.53% avg_auc=95.03%
Best model saved!! Metric=33.15674268404129!!
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.623956 Test loss=0.321733 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5884080529212952
[5/24] Train loss=0.5836421251296997
[10/24] Train loss=0.6271790266036987
[15/24] Train loss=0.6471110582351685
[20/24] Train loss=0.5132136344909668
Test set avg_accuracy=88.59% avg_sensitivity=87.78%, avg_specificity=88.87% avg_auc=95.13%
Best model saved!! Metric=34.373932156732906!!
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.612131 Test loss=0.309118 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5783166289329529
[5/24] Train loss=0.5689284205436707
[10/24] Train loss=0.6157546043395996
[15/24] Train loss=0.6055342555046082
[20/24] Train loss=0.49113547801971436
Test set avg_accuracy=89.26% avg_sensitivity=85.71%, avg_specificity=90.45% avg_auc=95.15%
Best model saved!! Metric=34.566393038943175!!
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.595446 Test loss=0.284593 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5616232752799988
[5/24] Train loss=0.5373343229293823
[10/24] Train loss=0.6002717614173889
[15/24] Train loss=0.6111186146736145
[20/24] Train loss=0.4915769696235657
Test set avg_accuracy=86.50% avg_sensitivity=90.16%, avg_specificity=85.27% avg_auc=95.00%
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.582163 Test loss=0.349501 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5497629046440125
[5/24] Train loss=0.5215252041816711
[10/24] Train loss=0.5825212597846985
[15/24] Train loss=0.5851759910583496
[20/24] Train loss=0.47722381353378296
Test set avg_accuracy=89.32% avg_sensitivity=84.46%, avg_specificity=90.95% avg_auc=94.97%
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.565834 Test loss=0.276437 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5250856280326843
[5/24] Train loss=0.5126597881317139
[10/24] Train loss=0.5952609181404114
[15/24] Train loss=0.5949589014053345
[20/24] Train loss=0.4686238169670105
Test set avg_accuracy=89.24% avg_sensitivity=87.36%, avg_specificity=89.88% avg_auc=95.07%
Best model saved!! Metric=35.55280299396931!!
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.555761 Test loss=0.289555 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5248602032661438
[5/24] Train loss=0.504714846611023
[10/24] Train loss=0.570652186870575
[15/24] Train loss=0.5787534117698669
[20/24] Train loss=0.4599018692970276
Test set avg_accuracy=88.05% avg_sensitivity=87.31%, avg_specificity=88.29% avg_auc=94.74%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.545654 Test loss=0.314933 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.5195257067680359
[5/24] Train loss=0.4859127402305603
[10/24] Train loss=0.5511602163314819
[15/24] Train loss=0.5590370297431946
[20/24] Train loss=0.43378809094429016
Test set avg_accuracy=88.48% avg_sensitivity=85.76%, avg_specificity=89.39% avg_auc=94.65%
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.529408 Test loss=0.297103 Current lr=[0.000210185142098938]

[0/24] Train loss=0.5036478042602539
[5/24] Train loss=0.4832361340522766
[10/24] Train loss=0.5669942498207092
[15/24] Train loss=0.5741896033287048
[20/24] Train loss=0.4488599896430969
Test set avg_accuracy=88.57% avg_sensitivity=85.60%, avg_specificity=89.56% avg_auc=94.03%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.526294 Test loss=0.325258 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.5005743503570557
[5/24] Train loss=0.45294278860092163
[10/24] Train loss=0.5365036129951477
[15/24] Train loss=0.5224547386169434
[20/24] Train loss=0.4207005500793457
Test set avg_accuracy=88.62% avg_sensitivity=80.74%, avg_specificity=91.27% avg_auc=93.59%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.507398 Test loss=0.296903 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.5015367269515991
[5/24] Train loss=0.45077770948410034
[10/24] Train loss=0.5451964139938354
[15/24] Train loss=0.5275794863700867
[20/24] Train loss=0.4391798973083496
Test set avg_accuracy=86.93% avg_sensitivity=83.64%, avg_specificity=88.03% avg_auc=92.82%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.512879 Test loss=0.367434 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.47484275698661804
[5/24] Train loss=0.4387524127960205
[10/24] Train loss=0.5295085310935974
[15/24] Train loss=0.5163744688034058
[20/24] Train loss=0.4288020431995392
Test set avg_accuracy=88.36% avg_sensitivity=83.38%, avg_specificity=90.03% avg_auc=94.02%
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.494851 Test loss=0.309206 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.474045991897583
[5/24] Train loss=0.45277005434036255
[10/24] Train loss=0.5252971053123474
[15/24] Train loss=0.492416113615036
[20/24] Train loss=0.40683087706565857
Test set avg_accuracy=75.96% avg_sensitivity=93.32%, avg_specificity=70.13% avg_auc=92.11%
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.490116 Test loss=0.574274 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.47391456365585327
[5/24] Train loss=0.43164801597595215
[10/24] Train loss=0.5109505653381348
[15/24] Train loss=0.5048644542694092
[20/24] Train loss=0.40646955370903015
Test set avg_accuracy=75.62% avg_sensitivity=93.06%, avg_specificity=69.77% avg_auc=92.94%
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.476343 Test loss=0.544286 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.4608617424964905
[5/24] Train loss=0.40507957339286804
[10/24] Train loss=0.5036531686782837
[15/24] Train loss=0.4878823757171631
[20/24] Train loss=0.3872394561767578
Test set avg_accuracy=78.75% avg_sensitivity=92.91%, avg_specificity=74.00% avg_auc=92.28%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.474106 Test loss=0.546413 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.48247817158699036
[5/24] Train loss=0.4107950031757355
[10/24] Train loss=0.49084576964378357
[15/24] Train loss=0.48069536685943604
[20/24] Train loss=0.38048702478408813
Test set avg_accuracy=80.03% avg_sensitivity=92.59%, avg_specificity=75.80% avg_auc=93.68%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.461809 Test loss=0.492422 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.45082777738571167
[5/24] Train loss=0.4095900356769562
[10/24] Train loss=0.48307982087135315
[15/24] Train loss=0.5003244280815125
[20/24] Train loss=0.3930903971195221
Test set avg_accuracy=88.57% avg_sensitivity=78.72%, avg_specificity=91.88% avg_auc=93.26%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.455668 Test loss=0.291864 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.43865934014320374
[5/24] Train loss=0.39454150199890137
[10/24] Train loss=0.4527064859867096
[15/24] Train loss=0.4588091969490051
[20/24] Train loss=0.3949829339981079
Test set avg_accuracy=88.20% avg_sensitivity=77.01%, avg_specificity=91.96% avg_auc=91.50%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.439520 Test loss=0.319947 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4529954791069031
[5/24] Train loss=0.3819434642791748
[10/24] Train loss=0.48108765482902527
[15/24] Train loss=0.47323286533355713
[20/24] Train loss=0.37559473514556885
Test set avg_accuracy=87.49% avg_sensitivity=78.25%, avg_specificity=90.59% avg_auc=90.80%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.439381 Test loss=0.340177 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.46604958176612854
[5/24] Train loss=0.3696410655975342
[10/24] Train loss=0.46259990334510803
[15/24] Train loss=0.49137839674949646
[20/24] Train loss=0.3890722393989563
Test set avg_accuracy=88.59% avg_sensitivity=78.25%, avg_specificity=92.07% avg_auc=91.48%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.437766 Test loss=0.321098 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4723614752292633
[5/24] Train loss=0.42330050468444824
[10/24] Train loss=0.4548106789588928
[15/24] Train loss=0.4661072790622711
[20/24] Train loss=0.3802247643470764
Test set avg_accuracy=88.28% avg_sensitivity=68.77%, avg_specificity=94.83% avg_auc=89.63%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.446168 Test loss=0.329690 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.45529571175575256
[5/24] Train loss=0.38676363229751587
[10/24] Train loss=0.4425884485244751
[15/24] Train loss=0.4487653374671936
[20/24] Train loss=0.35917335748672485
Test set avg_accuracy=88.35% avg_sensitivity=84.00%, avg_specificity=89.81% avg_auc=93.53%
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.430858 Test loss=0.303678 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.42560911178588867
[5/24] Train loss=0.39433974027633667
[10/24] Train loss=0.47322481870651245
[15/24] Train loss=0.43604591488838196
[20/24] Train loss=0.350405752658844
Test set avg_accuracy=86.50% avg_sensitivity=81.82%, avg_specificity=88.07% avg_auc=92.11%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.423265 Test loss=0.354856 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.4237852990627289
[5/24] Train loss=0.43129757046699524
[10/24] Train loss=0.4548134207725525
[15/24] Train loss=0.4555659890174866
[20/24] Train loss=0.36154067516326904
Test set avg_accuracy=87.67% avg_sensitivity=83.48%, avg_specificity=89.08% avg_auc=94.04%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.436541 Test loss=0.294662 Current lr=[0.00029967723776099]

[0/24] Train loss=0.4422951340675354
[5/24] Train loss=0.35930702090263367
[10/24] Train loss=0.44594287872314453
[15/24] Train loss=0.43801411986351013
[20/24] Train loss=0.3448634147644043
Test set avg_accuracy=80.79% avg_sensitivity=89.02%, avg_specificity=78.03% avg_auc=91.99%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.418196 Test loss=0.484816 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.42919623851776123
[5/24] Train loss=0.374136358499527
[10/24] Train loss=0.4275251030921936
[15/24] Train loss=0.44118377566337585
[20/24] Train loss=0.35831090807914734
Test set avg_accuracy=87.14% avg_sensitivity=85.40%, avg_specificity=87.72% avg_auc=93.52%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.409877 Test loss=0.356320 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3954581022262573
[5/24] Train loss=0.3316281735897064
[10/24] Train loss=0.41765010356903076
[15/24] Train loss=0.41591310501098633
[20/24] Train loss=0.32842332124710083
Test set avg_accuracy=80.42% avg_sensitivity=92.54%, avg_specificity=76.34% avg_auc=93.12%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.402248 Test loss=0.493782 Current lr=[0.000299720220882401]

[0/24] Train loss=0.4067970812320709
[5/24] Train loss=0.3495579659938812
[10/24] Train loss=0.4101705253124237
[15/24] Train loss=0.44599905610084534
[20/24] Train loss=0.3570396602153778
Test set avg_accuracy=88.27% avg_sensitivity=85.91%, avg_specificity=89.06% avg_auc=93.46%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.403503 Test loss=0.328482 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.39858829975128174
[5/24] Train loss=0.3396171033382416
[10/24] Train loss=0.41608697175979614
[15/24] Train loss=0.4408712685108185
[20/24] Train loss=0.3199698328971863
Test set avg_accuracy=85.86% avg_sensitivity=81.05%, avg_specificity=87.48% avg_auc=90.83%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.404650 Test loss=0.439861 Current lr=[0.000298904600941902]

[0/24] Train loss=0.4073159694671631
[5/24] Train loss=0.3298734128475189
[10/24] Train loss=0.41164401173591614
[15/24] Train loss=0.42937713861465454
[20/24] Train loss=0.3318483531475067
Test set avg_accuracy=88.72% avg_sensitivity=77.37%, avg_specificity=92.54% avg_auc=92.49%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.391804 Test loss=0.314357 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3800860345363617
[5/24] Train loss=0.33614465594291687
[10/24] Train loss=0.39813801646232605
[15/24] Train loss=0.4079391062259674
[20/24] Train loss=0.33140668272972107
Test set avg_accuracy=86.80% avg_sensitivity=86.64%, avg_specificity=86.85% avg_auc=93.14%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.383361 Test loss=0.358908 Current lr=[0.000297555943323901]

[0/24] Train loss=0.37589031457901
[5/24] Train loss=0.36173215508461
[10/24] Train loss=0.3761829435825348
[15/24] Train loss=0.3886447250843048
[20/24] Train loss=0.32700222730636597
Test set avg_accuracy=87.66% avg_sensitivity=69.91%, avg_specificity=93.62% avg_auc=90.11%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.378646 Test loss=0.338242 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3785087466239929
[5/24] Train loss=0.36537426710128784
[10/24] Train loss=0.40206408500671387
[15/24] Train loss=0.3933412730693817
[20/24] Train loss=0.31133249402046204
Test set avg_accuracy=88.31% avg_sensitivity=82.81%, avg_specificity=90.15% avg_auc=93.59%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.378693 Test loss=0.309217 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3887665271759033
[5/24] Train loss=0.33304139971733093
[10/24] Train loss=0.35748419165611267
[15/24] Train loss=0.39747005701065063
[20/24] Train loss=0.305134117603302
Test set avg_accuracy=82.03% avg_sensitivity=89.44%, avg_specificity=79.54% avg_auc=92.24%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.370777 Test loss=0.509340 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.37090232968330383
[5/24] Train loss=0.3040734827518463
[10/24] Train loss=0.3573192059993744
[15/24] Train loss=0.3674967586994171
[20/24] Train loss=0.31754550337791443
Test set avg_accuracy=88.06% avg_sensitivity=72.29%, avg_specificity=93.36% avg_auc=91.57%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.353175 Test loss=0.330578 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.37459370493888855
[5/24] Train loss=0.3101159632205963
[10/24] Train loss=0.35241615772247314
[15/24] Train loss=0.38750332593917847
[20/24] Train loss=0.31800660490989685
Test set avg_accuracy=86.15% avg_sensitivity=82.50%, avg_specificity=87.37% avg_auc=92.11%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.347676 Test loss=0.368066 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.33651480078697205
[5/24] Train loss=0.3126518428325653
[10/24] Train loss=0.3661736249923706
[15/24] Train loss=0.3799150288105011
[20/24] Train loss=0.3011668920516968
Test set avg_accuracy=88.59% avg_sensitivity=76.90%, avg_specificity=92.52% avg_auc=93.62%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.358080 Test loss=0.290745 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3527519404888153
[5/24] Train loss=0.38428518176078796
[10/24] Train loss=0.35602694749832153
[15/24] Train loss=0.4029445946216583
[20/24] Train loss=0.30342939496040344
Test set avg_accuracy=87.53% avg_sensitivity=84.00%, avg_specificity=88.71% avg_auc=93.22%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.373249 Test loss=0.329742 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.37222614884376526
[5/24] Train loss=0.3242994248867035
[10/24] Train loss=0.3970901668071747
[15/24] Train loss=0.38021770119667053
[20/24] Train loss=0.3343125879764557
Test set avg_accuracy=88.31% avg_sensitivity=78.30%, avg_specificity=91.67% avg_auc=93.41%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.361154 Test loss=0.311410 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.389846533536911
[5/24] Train loss=0.32049891352653503
[10/24] Train loss=0.37279632687568665
[15/24] Train loss=0.4038713574409485
[20/24] Train loss=0.30741751194000244
Test set avg_accuracy=88.41% avg_sensitivity=77.63%, avg_specificity=92.03% avg_auc=92.56%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.363942 Test loss=0.309222 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.36867213249206543
[5/24] Train loss=0.31917399168014526
[10/24] Train loss=0.3670887053012848
[15/24] Train loss=0.33992400765419006
[20/24] Train loss=0.29613497853279114
Test set avg_accuracy=88.52% avg_sensitivity=79.49%, avg_specificity=91.55% avg_auc=92.72%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.345218 Test loss=0.314294 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3479969799518585
[5/24] Train loss=0.3069242835044861
[10/24] Train loss=0.3473784923553467
[15/24] Train loss=0.3652980923652649
[20/24] Train loss=0.3118787407875061
Test set avg_accuracy=86.64% avg_sensitivity=76.70%, avg_specificity=89.98% avg_auc=92.12%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.344842 Test loss=0.350290 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.33610308170318604
[5/24] Train loss=0.310007244348526
[10/24] Train loss=0.3901538550853729
[15/24] Train loss=0.3770657479763031
[20/24] Train loss=0.2951424717903137
Test set avg_accuracy=84.78% avg_sensitivity=83.74%, avg_specificity=85.13% avg_auc=92.46%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.350837 Test loss=0.412146 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3413482904434204
[5/24] Train loss=0.29539698362350464
[10/24] Train loss=0.353770911693573
[15/24] Train loss=0.335286408662796
[20/24] Train loss=0.30529993772506714
Test set avg_accuracy=86.12% avg_sensitivity=85.50%, avg_specificity=86.33% avg_auc=93.68%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.342858 Test loss=0.353379 Current lr=[0.000276307469034998]

[0/24] Train loss=0.331500768661499
[5/24] Train loss=0.30164065957069397
[10/24] Train loss=0.31456372141838074
[15/24] Train loss=0.3212270140647888
[20/24] Train loss=0.2959144115447998
Test set avg_accuracy=88.18% avg_sensitivity=72.19%, avg_specificity=93.55% avg_auc=91.94%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.330372 Test loss=0.319138 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.31521379947662354
[5/24] Train loss=0.27459651231765747
[10/24] Train loss=0.32086271047592163
[15/24] Train loss=0.30647826194763184
[20/24] Train loss=0.2842753231525421
Test set avg_accuracy=88.28% avg_sensitivity=81.62%, avg_specificity=90.52% avg_auc=93.29%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.317796 Test loss=0.315128 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3484790325164795
[5/24] Train loss=0.26921623945236206
[10/24] Train loss=0.3357958197593689
[15/24] Train loss=0.36240604519844055
[20/24] Train loss=0.30952122807502747
Test set avg_accuracy=84.28% avg_sensitivity=89.38%, avg_specificity=82.57% avg_auc=91.81%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.327839 Test loss=0.438200 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3180878758430481
[5/24] Train loss=0.28205597400665283
[10/24] Train loss=0.3189008831977844
[15/24] Train loss=0.3344791531562805
[20/24] Train loss=0.271675705909729
Test set avg_accuracy=87.83% avg_sensitivity=81.77%, avg_specificity=89.86% avg_auc=92.86%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.315763 Test loss=0.319355 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3233984708786011
[5/24] Train loss=0.26018333435058594
[10/24] Train loss=0.31970641016960144
[15/24] Train loss=0.3250616192817688
[20/24] Train loss=0.27112969756126404
Test set avg_accuracy=87.83% avg_sensitivity=74.16%, avg_specificity=92.42% avg_auc=91.57%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.308784 Test loss=0.323429 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.30889761447906494
[5/24] Train loss=0.2777380347251892
[10/24] Train loss=0.306871622800827
[15/24] Train loss=0.30916157364845276
[20/24] Train loss=0.2661750018596649
Test set avg_accuracy=84.64% avg_sensitivity=87.83%, avg_specificity=83.56% avg_auc=91.55%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.303850 Test loss=0.433815 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.30799081921577454
[5/24] Train loss=0.255202054977417
[10/24] Train loss=0.28438520431518555
[15/24] Train loss=0.29930028319358826
[20/24] Train loss=0.24845226109027863
Test set avg_accuracy=81.00% avg_sensitivity=90.89%, avg_specificity=77.68% avg_auc=92.52%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.297861 Test loss=0.529661 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.30395105481147766
[5/24] Train loss=0.25500601530075073
[10/24] Train loss=0.29589226841926575
[15/24] Train loss=0.30278781056404114
[20/24] Train loss=0.260979026556015
Test set avg_accuracy=84.83% avg_sensitivity=84.26%, avg_specificity=85.02% avg_auc=92.64%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.305057 Test loss=0.396686 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3206893503665924
[5/24] Train loss=0.25772160291671753
[10/24] Train loss=0.2845837473869324
[15/24] Train loss=0.30827072262763977
[20/24] Train loss=0.25024956464767456
Test set avg_accuracy=87.76% avg_sensitivity=63.59%, avg_specificity=95.88% avg_auc=89.62%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.305218 Test loss=0.347975 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.29280397295951843
[5/24] Train loss=0.2612656056880951
[10/24] Train loss=0.30056920647621155
[15/24] Train loss=0.29692715406417847
[20/24] Train loss=0.2552207112312317
Test set avg_accuracy=88.55% avg_sensitivity=77.68%, avg_specificity=92.21% avg_auc=92.18%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.299125 Test loss=0.311560 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.28117796778678894
[5/24] Train loss=0.2751378118991852
[10/24] Train loss=0.27937012910842896
[15/24] Train loss=0.30048713088035583
[20/24] Train loss=0.25126755237579346
Test set avg_accuracy=88.48% avg_sensitivity=83.64%, avg_specificity=90.10% avg_auc=93.01%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.294530 Test loss=0.331830 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3063894212245941
[5/24] Train loss=0.2574584186077118
[10/24] Train loss=0.2943146526813507
[15/24] Train loss=0.3073630928993225
[20/24] Train loss=0.26637953519821167
Test set avg_accuracy=86.82% avg_sensitivity=81.62%, avg_specificity=88.57% avg_auc=91.87%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.290892 Test loss=0.379980 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.30894002318382263
[5/24] Train loss=0.2296840399503708
[10/24] Train loss=0.27956831455230713
[15/24] Train loss=0.26674532890319824
[20/24] Train loss=0.23797830939292908
Test set avg_accuracy=85.74% avg_sensitivity=87.52%, avg_specificity=85.15% avg_auc=92.71%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.286956 Test loss=0.437123 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.30078810453414917
[5/24] Train loss=0.23860318958759308
[10/24] Train loss=0.2956372797489166
[15/24] Train loss=0.2788284420967102
[20/24] Train loss=0.24368849396705627
Test set avg_accuracy=88.15% avg_sensitivity=84.05%, avg_specificity=89.53% avg_auc=93.20%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.284904 Test loss=0.344654 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3014664351940155
[5/24] Train loss=0.24247482419013977
[10/24] Train loss=0.2792925536632538
[15/24] Train loss=0.2652283012866974
[20/24] Train loss=0.2505853474140167
Test set avg_accuracy=88.82% avg_sensitivity=77.58%, avg_specificity=92.59% avg_auc=92.21%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.285505 Test loss=0.312679 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3005733788013458
[5/24] Train loss=0.24002188444137573
[10/24] Train loss=0.30884331464767456
[15/24] Train loss=0.2709529995918274
[20/24] Train loss=0.2484705150127411
Test set avg_accuracy=81.24% avg_sensitivity=86.79%, avg_specificity=79.37% avg_auc=91.54%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.280601 Test loss=0.516779 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2844736874103546
[5/24] Train loss=0.250889390707016
[10/24] Train loss=0.26890966296195984
[15/24] Train loss=0.2887248396873474
[20/24] Train loss=0.2314782291650772
Test set avg_accuracy=87.10% avg_sensitivity=84.41%, avg_specificity=88.00% avg_auc=92.04%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.277787 Test loss=0.379974 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.281028687953949
[5/24] Train loss=0.22431838512420654
[10/24] Train loss=0.25734177231788635
[15/24] Train loss=0.26221251487731934
[20/24] Train loss=0.20903505384922028
Test set avg_accuracy=88.27% avg_sensitivity=76.90%, avg_specificity=92.09% avg_auc=92.53%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.263347 Test loss=0.318632 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2536221146583557
[5/24] Train loss=0.23031508922576904
[10/24] Train loss=0.2586767375469208
[15/24] Train loss=0.2747889757156372
[20/24] Train loss=0.22616486251354218
Test set avg_accuracy=87.14% avg_sensitivity=62.56%, avg_specificity=95.39% avg_auc=88.37%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.259010 Test loss=0.361438 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.27305781841278076
[5/24] Train loss=0.23944319784641266
[10/24] Train loss=0.2641604244709015
[15/24] Train loss=0.26497402787208557
[20/24] Train loss=0.21602806448936462
Test set avg_accuracy=88.66% avg_sensitivity=70.53%, avg_specificity=94.75% avg_auc=91.30%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.259352 Test loss=0.330723 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2638765573501587
[5/24] Train loss=0.2247607409954071
[10/24] Train loss=0.25284671783447266
[15/24] Train loss=0.2510097324848175
[20/24] Train loss=0.22577206790447235
Test set avg_accuracy=87.03% avg_sensitivity=61.32%, avg_specificity=95.67% avg_auc=88.12%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.258368 Test loss=0.367665 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2858131527900696
[5/24] Train loss=0.2244836986064911
[10/24] Train loss=0.25063246488571167
[15/24] Train loss=0.2643798589706421
[20/24] Train loss=0.23121009767055511
Test set avg_accuracy=87.50% avg_sensitivity=63.39%, avg_specificity=95.60% avg_auc=88.80%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.261394 Test loss=0.358089 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2716647684574127
[5/24] Train loss=0.20942403376102448
[10/24] Train loss=0.2534225583076477
[15/24] Train loss=0.2529345452785492
[20/24] Train loss=0.21822595596313477
Test set avg_accuracy=88.33% avg_sensitivity=70.48%, avg_specificity=94.33% avg_auc=89.84%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.257763 Test loss=0.332225 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.25512728095054626
[5/24] Train loss=0.2274594008922577
[10/24] Train loss=0.24305304884910583
[15/24] Train loss=0.2754165828227997
[20/24] Train loss=0.23459811508655548
Test set avg_accuracy=87.89% avg_sensitivity=66.70%, avg_specificity=95.01% avg_auc=90.21%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.256275 Test loss=0.358195 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.26922857761383057
[5/24] Train loss=0.21637997031211853
[10/24] Train loss=0.23205991089344025
[15/24] Train loss=0.2502443492412567
[20/24] Train loss=0.21972225606441498
Test set avg_accuracy=88.93% avg_sensitivity=80.22%, avg_specificity=91.86% avg_auc=92.00%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.255189 Test loss=0.322992 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2656443119049072
[5/24] Train loss=0.22064721584320068
[10/24] Train loss=0.25001639127731323
[15/24] Train loss=0.2532326877117157
[20/24] Train loss=0.20598451793193817
Test set avg_accuracy=88.26% avg_sensitivity=71.41%, avg_specificity=93.91% avg_auc=91.64%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.250130 Test loss=0.319744 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.26583924889564514
[5/24] Train loss=0.21159541606903076
[10/24] Train loss=0.23506106436252594
[15/24] Train loss=0.23455068469047546
[20/24] Train loss=0.23770301043987274
Test set avg_accuracy=88.49% avg_sensitivity=81.82%, avg_specificity=90.73% avg_auc=92.68%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.245405 Test loss=0.341221 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.26081520318984985
[5/24] Train loss=0.22233210504055023
[10/24] Train loss=0.25997209548950195
[15/24] Train loss=0.25208935141563416
[20/24] Train loss=0.22380255162715912
Test set avg_accuracy=88.29% avg_sensitivity=78.87%, avg_specificity=91.46% avg_auc=91.90%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.257418 Test loss=0.371875 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.25583550333976746
[5/24] Train loss=0.21316027641296387
[10/24] Train loss=0.2438083291053772
[15/24] Train loss=0.24824263155460358
[20/24] Train loss=0.2077590376138687
Test set avg_accuracy=87.71% avg_sensitivity=85.24%, avg_specificity=88.54% avg_auc=93.60%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.246689 Test loss=0.358176 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.25555357336997986
[5/24] Train loss=0.2044505923986435
[10/24] Train loss=0.22029881179332733
[15/24] Train loss=0.2441920042037964
[20/24] Train loss=0.19845476746559143
Test set avg_accuracy=88.35% avg_sensitivity=75.87%, avg_specificity=92.54% avg_auc=91.90%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.236426 Test loss=0.328593 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.23617394268512726
[5/24] Train loss=0.19111023843288422
[10/24] Train loss=0.2211206704378128
[15/24] Train loss=0.23450031876564026
[20/24] Train loss=0.20505236089229584
Test set avg_accuracy=89.21% avg_sensitivity=75.40%, avg_specificity=93.84% avg_auc=91.86%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.230354 Test loss=0.320606 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.24280314147472382
[5/24] Train loss=0.2033349722623825
[10/24] Train loss=0.2196515053510666
[15/24] Train loss=0.2169155478477478
[20/24] Train loss=0.20081934332847595
Test set avg_accuracy=89.01% avg_sensitivity=80.99%, avg_specificity=91.70% avg_auc=93.25%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.225096 Test loss=0.311021 Current lr=[0.000156543481933168]

[0/24] Train loss=0.23985178768634796
[5/24] Train loss=0.1957864612340927
[10/24] Train loss=0.20979608595371246
[15/24] Train loss=0.23086553812026978
[20/24] Train loss=0.19566024839878082
Test set avg_accuracy=89.02% avg_sensitivity=81.36%, avg_specificity=91.60% avg_auc=93.02%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.222362 Test loss=0.321839 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.23371024429798126
[5/24] Train loss=0.18588648736476898
[10/24] Train loss=0.20956656336784363
[15/24] Train loss=0.20961156487464905
[20/24] Train loss=0.20175617933273315
Test set avg_accuracy=89.58% avg_sensitivity=80.84%, avg_specificity=92.52% avg_auc=93.15%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.217108 Test loss=0.307741 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.23524627089500427
[5/24] Train loss=0.2136252522468567
[10/24] Train loss=0.2145274430513382
[15/24] Train loss=0.2034660130739212
[20/24] Train loss=0.1891339123249054
Test set avg_accuracy=89.02% avg_sensitivity=81.67%, avg_specificity=91.49% avg_auc=93.03%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.216308 Test loss=0.324056 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.22270818054676056
[5/24] Train loss=0.18480025231838226
[10/24] Train loss=0.19880175590515137
[15/24] Train loss=0.20722530782222748
[20/24] Train loss=0.17578436434268951
Test set avg_accuracy=88.91% avg_sensitivity=78.20%, avg_specificity=92.50% avg_auc=92.58%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.210576 Test loss=0.316716 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.21259480714797974
[5/24] Train loss=0.18313999474048615
[10/24] Train loss=0.1987520307302475
[15/24] Train loss=0.2051466405391693
[20/24] Train loss=0.18133099377155304
Test set avg_accuracy=88.24% avg_sensitivity=81.72%, avg_specificity=90.43% avg_auc=92.84%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.207874 Test loss=0.348266 Current lr=[0.000134135431043539]

[0/24] Train loss=0.2181873768568039
[5/24] Train loss=0.19000722467899323
[10/24] Train loss=0.22112026810646057
[15/24] Train loss=0.20149412751197815
[20/24] Train loss=0.175088569521904
Test set avg_accuracy=88.82% avg_sensitivity=79.75%, avg_specificity=91.86% avg_auc=93.01%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.206576 Test loss=0.316332 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.22324591875076294
[5/24] Train loss=0.18333378434181213
[10/24] Train loss=0.19710010290145874
[15/24] Train loss=0.1973167210817337
[20/24] Train loss=0.18217672407627106
Test set avg_accuracy=86.67% avg_sensitivity=85.09%, avg_specificity=87.20% avg_auc=93.30%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.203850 Test loss=0.367728 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.21153272688388824
[5/24] Train loss=0.17573226988315582
[10/24] Train loss=0.19721411168575287
[15/24] Train loss=0.20263397693634033
[20/24] Train loss=0.1676909178495407
Test set avg_accuracy=88.96% avg_sensitivity=77.06%, avg_specificity=92.96% avg_auc=92.95%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.199266 Test loss=0.309589 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.2051953673362732
[5/24] Train loss=0.17508618533611298
[10/24] Train loss=0.1841847151517868
[15/24] Train loss=0.19681616127490997
[20/24] Train loss=0.18322309851646423
Test set avg_accuracy=88.32% avg_sensitivity=77.84%, avg_specificity=91.84% avg_auc=92.94%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.199414 Test loss=0.321768 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.20349769294261932
[5/24] Train loss=0.17650023102760315
[10/24] Train loss=0.19248303771018982
[15/24] Train loss=0.20314204692840576
[20/24] Train loss=0.17872510850429535
Test set avg_accuracy=88.65% avg_sensitivity=79.39%, avg_specificity=91.76% avg_auc=93.55%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.201631 Test loss=0.313740 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.21907399594783783
[5/24] Train loss=0.2024039626121521
[10/24] Train loss=0.19167008996009827
[15/24] Train loss=0.20904040336608887
[20/24] Train loss=0.18019305169582367
Test set avg_accuracy=88.78% avg_sensitivity=75.25%, avg_specificity=93.32% avg_auc=92.25%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.203946 Test loss=0.312402 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.2013738453388214
[5/24] Train loss=0.17867758870124817
[10/24] Train loss=0.19089403748512268
[15/24] Train loss=0.21740999817848206
[20/24] Train loss=0.17252697050571442
Test set avg_accuracy=89.61% avg_sensitivity=77.94%, avg_specificity=93.53% avg_auc=92.56%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.205089 Test loss=0.303007 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.20989380776882172
[5/24] Train loss=0.19061359763145447
[10/24] Train loss=0.20070825517177582
[15/24] Train loss=0.19606320559978485
[20/24] Train loss=0.174029141664505
Test set avg_accuracy=88.88% avg_sensitivity=69.03%, avg_specificity=95.55% avg_auc=91.57%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.204568 Test loss=0.328677 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.2209726721048355
[5/24] Train loss=0.1742078959941864
[10/24] Train loss=0.19682012498378754
[15/24] Train loss=0.18869566917419434
[20/24] Train loss=0.17420513927936554
Test set avg_accuracy=89.15% avg_sensitivity=74.37%, avg_specificity=94.12% avg_auc=92.12%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.198595 Test loss=0.312140 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.203771710395813
[5/24] Train loss=0.16945214569568634
[10/24] Train loss=0.1831427961587906
[15/24] Train loss=0.19221144914627075
[20/24] Train loss=0.16581875085830688
Test set avg_accuracy=89.61% avg_sensitivity=74.78%, avg_specificity=94.59% avg_auc=92.46%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.192649 Test loss=0.297950 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.20505023002624512
[5/24] Train loss=0.17321452498435974
[10/24] Train loss=0.19527685642242432
[15/24] Train loss=0.18793927133083344
[20/24] Train loss=0.1633831411600113
Test set avg_accuracy=89.57% avg_sensitivity=79.29%, avg_specificity=93.02% avg_auc=91.60%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.189769 Test loss=0.318108 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.19678698480129242
[5/24] Train loss=0.17769905924797058
[10/24] Train loss=0.17470736801624298
[15/24] Train loss=0.17788507044315338
[20/24] Train loss=0.16614040732383728
Test set avg_accuracy=89.93% avg_sensitivity=77.21%, avg_specificity=94.21% avg_auc=92.15%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.187514 Test loss=0.305109 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.19105349481105804
[5/24] Train loss=0.16341769695281982
[10/24] Train loss=0.1798492819070816
[15/24] Train loss=0.1861700415611267
[20/24] Train loss=0.16517843306064606
Test set avg_accuracy=89.06% avg_sensitivity=81.05%, avg_specificity=91.76% avg_auc=93.45%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.186150 Test loss=0.317675 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.18571844696998596
[5/24] Train loss=0.15871602296829224
[10/24] Train loss=0.17830471694469452
[15/24] Train loss=0.17451436817646027
[20/24] Train loss=0.15796615183353424
Test set avg_accuracy=89.27% avg_sensitivity=79.96%, avg_specificity=92.40% avg_auc=92.64%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.181046 Test loss=0.313039 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.18781524896621704
[5/24] Train loss=0.15544594824314117
[10/24] Train loss=0.16748610138893127
[15/24] Train loss=0.17290855944156647
[20/24] Train loss=0.15841661393642426
Test set avg_accuracy=89.26% avg_sensitivity=79.60%, avg_specificity=92.50% avg_auc=93.10%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.179656 Test loss=0.313604 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.18657857179641724
[5/24] Train loss=0.15897729992866516
[10/24] Train loss=0.1736462116241455
[15/24] Train loss=0.17959944903850555
[20/24] Train loss=0.15611162781715393
Test set avg_accuracy=89.54% avg_sensitivity=79.65%, avg_specificity=92.87% avg_auc=93.15%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.179525 Test loss=0.305426 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.18879258632659912
[5/24] Train loss=0.16176638007164001
[10/24] Train loss=0.17031820118427277
[15/24] Train loss=0.17574994266033173
[20/24] Train loss=0.15422815084457397
Test set avg_accuracy=89.56% avg_sensitivity=81.05%, avg_specificity=92.42% avg_auc=92.93%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.176071 Test loss=0.309000 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.18275579810142517
[5/24] Train loss=0.15532691776752472
[10/24] Train loss=0.17255844175815582
[15/24] Train loss=0.17268416285514832
[20/24] Train loss=0.15103748440742493
Test set avg_accuracy=89.96% avg_sensitivity=77.52%, avg_specificity=94.14% avg_auc=92.55%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.175351 Test loss=0.305028 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.18895037472248077
[5/24] Train loss=0.15800058841705322
[10/24] Train loss=0.16853006184101105
[15/24] Train loss=0.17300918698310852
[20/24] Train loss=0.15261539816856384
Test set avg_accuracy=89.38% avg_sensitivity=76.33%, avg_specificity=93.76% avg_auc=91.89%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.176246 Test loss=0.309093 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.17804346978664398
[5/24] Train loss=0.15674912929534912
[10/24] Train loss=0.16786694526672363
[15/24] Train loss=0.1780659407377243
[20/24] Train loss=0.1498575657606125
Test set avg_accuracy=89.80% avg_sensitivity=77.32%, avg_specificity=94.00% avg_auc=91.82%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.174032 Test loss=0.312999 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.18275541067123413
[5/24] Train loss=0.1552528738975525
[10/24] Train loss=0.1672377586364746
[15/24] Train loss=0.1739923059940338
[20/24] Train loss=0.15391793847084045
Test set avg_accuracy=89.80% avg_sensitivity=79.29%, avg_specificity=93.34% avg_auc=92.41%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.173494 Test loss=0.315996 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1848752796649933
[5/24] Train loss=0.16133660078048706
[10/24] Train loss=0.165571928024292
[15/24] Train loss=0.17601487040519714
[20/24] Train loss=0.15111370384693146
Test set avg_accuracy=89.17% avg_sensitivity=78.56%, avg_specificity=92.73% avg_auc=92.24%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.174717 Test loss=0.326227 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1824415624141693
[5/24] Train loss=0.16336384415626526
[10/24] Train loss=0.16355931758880615
[15/24] Train loss=0.17415133118629456
[20/24] Train loss=0.154690682888031
Test set avg_accuracy=89.02% avg_sensitivity=82.86%, avg_specificity=91.09% avg_auc=93.33%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.177256 Test loss=0.328329 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1787729561328888
[5/24] Train loss=0.156227245926857
[10/24] Train loss=0.17628586292266846
[15/24] Train loss=0.17747311294078827
[20/24] Train loss=0.15908358991146088
Test set avg_accuracy=88.19% avg_sensitivity=84.52%, avg_specificity=89.42% avg_auc=93.36%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.177402 Test loss=0.350673 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.18306487798690796
[5/24] Train loss=0.1533919870853424
[10/24] Train loss=0.1680479347705841
[15/24] Train loss=0.17724479734897614
[20/24] Train loss=0.15073391795158386
Test set avg_accuracy=88.61% avg_sensitivity=82.70%, avg_specificity=90.59% avg_auc=92.61%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.175488 Test loss=0.338187 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.178853377699852
[5/24] Train loss=0.1601039320230484
[10/24] Train loss=0.16752533614635468
[15/24] Train loss=0.16867253184318542
[20/24] Train loss=0.1591266691684723
Test set avg_accuracy=89.30% avg_sensitivity=82.50%, avg_specificity=91.58% avg_auc=92.96%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.174789 Test loss=0.320743 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.17677715420722961
[5/24] Train loss=0.16566811501979828
[10/24] Train loss=0.17355424165725708
[15/24] Train loss=0.16532079875469208
[20/24] Train loss=0.1629854291677475
Test set avg_accuracy=88.74% avg_sensitivity=81.77%, avg_specificity=91.08% avg_auc=93.40%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.177103 Test loss=0.320153 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1836153119802475
[5/24] Train loss=0.1529533416032791
[10/24] Train loss=0.17352962493896484
[15/24] Train loss=0.16690662503242493
[20/24] Train loss=0.15471290051937103
Test set avg_accuracy=88.68% avg_sensitivity=80.27%, avg_specificity=91.51% avg_auc=93.01%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.173197 Test loss=0.319106 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.18457897007465363
[5/24] Train loss=0.1512058973312378
[10/24] Train loss=0.16222801804542542
[15/24] Train loss=0.17167985439300537
[20/24] Train loss=0.15122845768928528
Test set avg_accuracy=89.14% avg_sensitivity=81.10%, avg_specificity=91.84% avg_auc=92.96%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.170725 Test loss=0.312901 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1709747016429901
[5/24] Train loss=0.15329620242118835
[10/24] Train loss=0.1571280062198639
[15/24] Train loss=0.1656259149312973
[20/24] Train loss=0.14435727894306183
Test set avg_accuracy=89.38% avg_sensitivity=82.39%, avg_specificity=91.72% avg_auc=92.90%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.166345 Test loss=0.312320 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.17277969419956207
[5/24] Train loss=0.14469927549362183
[10/24] Train loss=0.15795375406742096
[15/24] Train loss=0.16465210914611816
[20/24] Train loss=0.14324995875358582
Test set avg_accuracy=89.64% avg_sensitivity=81.05%, avg_specificity=92.52% avg_auc=92.97%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.163701 Test loss=0.307494 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.17063689231872559
[5/24] Train loss=0.14437034726142883
[10/24] Train loss=0.1555996984243393
[15/24] Train loss=0.15959814190864563
[20/24] Train loss=0.14145487546920776
Test set avg_accuracy=89.04% avg_sensitivity=81.72%, avg_specificity=91.49% avg_auc=93.26%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.163186 Test loss=0.315557 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.16778020560741425
[5/24] Train loss=0.1473851352930069
[10/24] Train loss=0.1567656397819519
[15/24] Train loss=0.16013553738594055
[20/24] Train loss=0.1397351324558258
Test set avg_accuracy=89.28% avg_sensitivity=82.19%, avg_specificity=91.67% avg_auc=93.29%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.162219 Test loss=0.311510 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1673596054315567
[5/24] Train loss=0.14636549353599548
[10/24] Train loss=0.15593186020851135
[15/24] Train loss=0.15688982605934143
[20/24] Train loss=0.14280492067337036
Test set avg_accuracy=89.61% avg_sensitivity=81.20%, avg_specificity=92.43% avg_auc=93.07%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.161060 Test loss=0.306982 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.16728724539279938
[5/24] Train loss=0.14685150980949402
[10/24] Train loss=0.15478681027889252
[15/24] Train loss=0.15803910791873932
[20/24] Train loss=0.14424268901348114
Test set avg_accuracy=89.45% avg_sensitivity=81.41%, avg_specificity=92.16% avg_auc=92.97%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.159782 Test loss=0.310386 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1641746610403061
[5/24] Train loss=0.14409713447093964
[10/24] Train loss=0.150887593626976
[15/24] Train loss=0.15842050313949585
[20/24] Train loss=0.14015501737594604
Test set avg_accuracy=89.48% avg_sensitivity=81.25%, avg_specificity=92.24% avg_auc=93.06%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.160065 Test loss=0.310232 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.16590745747089386
[5/24] Train loss=0.1454559713602066
[10/24] Train loss=0.15535376965999603
[15/24] Train loss=0.15483739972114563
[20/24] Train loss=0.14135241508483887
Test set avg_accuracy=89.39% avg_sensitivity=81.10%, avg_specificity=92.17% avg_auc=93.00%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.160393 Test loss=0.310259 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.16383442282676697
[5/24] Train loss=0.14266431331634521
[10/24] Train loss=0.15306724607944489
[15/24] Train loss=0.15459193289279938
[20/24] Train loss=0.1400209367275238
Test set avg_accuracy=89.31% avg_sensitivity=81.87%, avg_specificity=91.81% avg_auc=93.11%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.159893 Test loss=0.313279 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.16364027559757233
[5/24] Train loss=0.1439722776412964
[10/24] Train loss=0.1524581015110016
[15/24] Train loss=0.15504099428653717
[20/24] Train loss=0.14072644710540771
Test set avg_accuracy=89.65% avg_sensitivity=81.51%, avg_specificity=92.38% avg_auc=92.91%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.159436 Test loss=0.311035 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.16477353870868683
[5/24] Train loss=0.1400911509990692
[10/24] Train loss=0.15145987272262573
[15/24] Train loss=0.15769556164741516
[20/24] Train loss=0.14048680663108826
Test set avg_accuracy=89.56% avg_sensitivity=81.67%, avg_specificity=92.21% avg_auc=93.00%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.159267 Test loss=0.311657 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.16302882134914398
[5/24] Train loss=0.14116966724395752
[10/24] Train loss=0.15286430716514587
[15/24] Train loss=0.154982790350914
[20/24] Train loss=0.14065371453762054
Test set avg_accuracy=89.26% avg_sensitivity=81.41%, avg_specificity=91.89% avg_auc=93.00%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.158433 Test loss=0.312117 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1648872047662735
[5/24] Train loss=0.1455303132534027
[10/24] Train loss=0.15263059735298157
[15/24] Train loss=0.15718775987625122
[20/24] Train loss=0.14147572219371796
Test set avg_accuracy=89.34% avg_sensitivity=81.62%, avg_specificity=91.93% avg_auc=93.02%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.158540 Test loss=0.313491 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1665637493133545
[5/24] Train loss=0.14297276735305786
[10/24] Train loss=0.15007732808589935
[15/24] Train loss=0.15633542835712433
[20/24] Train loss=0.1411973088979721
Test set avg_accuracy=89.35% avg_sensitivity=81.56%, avg_specificity=91.96% avg_auc=93.01%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.158152 Test loss=0.312219 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1620103269815445
[5/24] Train loss=0.14135313034057617
[10/24] Train loss=0.15238085389137268
[15/24] Train loss=0.15545539557933807
[20/24] Train loss=0.13945455849170685
Test set avg_accuracy=89.49% avg_sensitivity=81.41%, avg_specificity=92.21% avg_auc=92.96%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.157547 Test loss=0.310014 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.16513420641422272
[5/24] Train loss=0.14348948001861572
[10/24] Train loss=0.14897064864635468
[15/24] Train loss=0.15618693828582764
[20/24] Train loss=0.1404249221086502
Test set avg_accuracy=89.47% avg_sensitivity=81.56%, avg_specificity=92.12% avg_auc=92.98%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.157964 Test loss=0.310375 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.16225191950798035
[5/24] Train loss=0.13975611329078674
[10/24] Train loss=0.15198852121829987
[15/24] Train loss=0.15613578259944916
[20/24] Train loss=0.13941842317581177
Test set avg_accuracy=89.47% avg_sensitivity=81.51%, avg_specificity=92.14% avg_auc=92.97%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.158028 Test loss=0.309911 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.166790172457695
[5/24] Train loss=0.14289024472236633
[10/24] Train loss=0.15219564735889435
[15/24] Train loss=0.15643498301506042
[20/24] Train loss=0.14108648896217346
Test set avg_accuracy=89.44% avg_sensitivity=81.67%, avg_specificity=92.05% avg_auc=92.97%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.158122 Test loss=0.309963 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1650274097919464
[5/24] Train loss=0.14273010194301605
[10/24] Train loss=0.14918044209480286
[15/24] Train loss=0.15588563680648804
[20/24] Train loss=0.13944846391677856
Test set avg_accuracy=89.40% avg_sensitivity=81.56%, avg_specificity=92.03% avg_auc=92.98%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.157893 Test loss=0.310150 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.16402187943458557
[5/24] Train loss=0.14239127933979034
[10/24] Train loss=0.1519489735364914
[15/24] Train loss=0.1567281186580658
[20/24] Train loss=0.14129866659641266
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=89.47% avg_sensitivity=81.56%, avg_specificity=92.12% avg_auc=92.97%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.158240 Test loss=0.309854 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=89.24% sen=87.36%, spe=89.88%, auc=95.07%!
Fold[8] Avg_overlap=0.68%(0.22229208950683316)
[0/23] Train loss=1.4828077554702759
[5/23] Train loss=1.4801660776138306
[10/23] Train loss=1.481148600578308
[15/23] Train loss=1.44765043258667
[20/23] Train loss=1.4169255495071411
Test set avg_accuracy=67.90% avg_sensitivity=54.72%, avg_specificity=72.10% avg_auc=59.10%
Best model saved!! Metric=-72.17772570629393!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=1.461936 Test loss=0.672231 Current lr=[1.23514552994466e-05]

[0/23] Train loss=1.4215199947357178
[5/23] Train loss=1.3892643451690674
[10/23] Train loss=1.4117004871368408
[15/23] Train loss=1.3759050369262695
[20/23] Train loss=1.3509949445724487
Test set avg_accuracy=72.53% avg_sensitivity=72.72%, avg_specificity=72.46% avg_auc=68.96%
Best model saved!! Metric=-39.324153259469625!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=1.394537 Test loss=0.638380 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=1.3348901271820068
[5/23] Train loss=1.3517072200775146
[10/23] Train loss=1.343133568763733
[15/23] Train loss=1.2943675518035889
[20/23] Train loss=1.2903316020965576
Test set avg_accuracy=72.98% avg_sensitivity=78.60%, avg_specificity=71.19% avg_auc=74.42%
Best model saved!! Metric=-28.806755710169313!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=1.330013 Test loss=0.611351 Current lr=[1.515281266696464e-05]

[0/23] Train loss=1.2815355062484741
[5/23] Train loss=1.2819287776947021
[10/23] Train loss=1.2865145206451416
[15/23] Train loss=1.2390048503875732
[20/23] Train loss=1.2025632858276367
Test set avg_accuracy=71.88% avg_sensitivity=84.20%, avg_specificity=67.95% avg_auc=78.29%
Best model saved!! Metric=-23.684612692757085!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=1.265204 Test loss=0.598005 Current lr=[1.758904040319645e-05]

[0/23] Train loss=1.2094823122024536
[5/23] Train loss=1.1952406167984009
[10/23] Train loss=1.2303760051727295
[15/23] Train loss=1.1571615934371948
[20/23] Train loss=1.1507917642593384
Test set avg_accuracy=72.21% avg_sensitivity=85.98%, avg_specificity=67.83% avg_auc=81.34%
Best model saved!! Metric=-18.637201597680914!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=1.196104 Test loss=0.578326 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=1.1278746128082275
[5/23] Train loss=1.1321403980255127
[10/23] Train loss=1.1644333600997925
[15/23] Train loss=1.0744885206222534
[20/23] Train loss=1.0799319744110107
Test set avg_accuracy=71.78% avg_sensitivity=86.36%, avg_specificity=67.14% avg_auc=83.75%
Best model saved!! Metric=-16.966457599468242!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=1.128112 Test loss=0.565895 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=1.061854600906372
[5/23] Train loss=1.073641300201416
[10/23] Train loss=1.0949392318725586
[15/23] Train loss=1.02149498462677
[20/23] Train loss=1.0210187435150146
Test set avg_accuracy=73.79% avg_sensitivity=86.15%, avg_specificity=69.85% avg_auc=86.14%
Best model saved!! Metric=-10.072654469563759!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=1.063960 Test loss=0.529616 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=1.0112520456314087
[5/23] Train loss=0.9913367629051208
[10/23] Train loss=1.036996841430664
[15/23] Train loss=0.9656211137771606
[20/23] Train loss=0.9623826146125793
Test set avg_accuracy=75.70% avg_sensitivity=87.55%, avg_specificity=71.93% avg_auc=88.33%
Best model saved!! Metric=-2.486965579919726!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=1.007729 Test loss=0.499196 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.9512418508529663
[5/23] Train loss=0.9511544108390808
[10/23] Train loss=0.9786590933799744
[15/23] Train loss=0.917746365070343
[20/23] Train loss=0.9034512042999268
Test set avg_accuracy=79.21% avg_sensitivity=84.37%, avg_specificity=77.56% avg_auc=90.17%
Best model saved!! Metric=5.306058863692456!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.951281 Test loss=0.460264 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.8843703269958496
[5/23] Train loss=0.91649329662323
[10/23] Train loss=0.9273341298103333
[15/23] Train loss=0.8742578029632568
[20/23] Train loss=0.8506478071212769
Test set avg_accuracy=81.24% avg_sensitivity=83.88%, avg_specificity=80.39% avg_auc=91.26%
Best model saved!! Metric=10.771062898142915!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.899564 Test loss=0.435322 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.8488124012947083
[5/23] Train loss=0.8368124961853027
[10/23] Train loss=0.8973768949508667
[15/23] Train loss=0.8252522349357605
[20/23] Train loss=0.812463641166687
Test set avg_accuracy=82.92% avg_sensitivity=82.75%, avg_specificity=82.97% avg_auc=91.97%
Best model saved!! Metric=14.608519101218917!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.853680 Test loss=0.408601 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.8054276704788208
[5/23] Train loss=0.7950397729873657
[10/23] Train loss=0.8526448607444763
[15/23] Train loss=0.7939607501029968
[20/23] Train loss=0.7578325271606445
Test set avg_accuracy=84.38% avg_sensitivity=82.53%, avg_specificity=84.96% avg_auc=92.70%
Best model saved!! Metric=18.56990299966452!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.813269 Test loss=0.384308 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.7735995650291443
[5/23] Train loss=0.7662804126739502
[10/23] Train loss=0.8298459053039551
[15/23] Train loss=0.7579920291900635
[20/23] Train loss=0.7251733541488647
Test set avg_accuracy=85.62% avg_sensitivity=80.86%, avg_specificity=87.14% avg_auc=92.92%
Best model saved!! Metric=20.554144060247793!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.776909 Test loss=0.361002 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.7255870699882507
[5/23] Train loss=0.7330366969108582
[10/23] Train loss=0.8121618032455444
[15/23] Train loss=0.7164474725723267
[20/23] Train loss=0.692750096321106
Test set avg_accuracy=86.41% avg_sensitivity=79.73%, avg_specificity=88.53% avg_auc=93.09%
Best model saved!! Metric=21.762746188239646!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.750664 Test loss=0.342074 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.7031276822090149
[5/23] Train loss=0.6861307621002197
[10/23] Train loss=0.774085283279419
[15/23] Train loss=0.6918358206748962
[20/23] Train loss=0.6679624915122986
Test set avg_accuracy=86.05% avg_sensitivity=82.05%, avg_specificity=87.33% avg_auc=93.38%
Best model saved!! Metric=22.812037430011657!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.723548 Test loss=0.346039 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.693368136882782
[5/23] Train loss=0.6739431023597717
[10/23] Train loss=0.7613810896873474
[15/23] Train loss=0.666508138179779
[20/23] Train loss=0.6236936450004578
Test set avg_accuracy=87.64% avg_sensitivity=79.78%, avg_specificity=90.15% avg_auc=93.50%
Best model saved!! Metric=25.07424382372392!!
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.697390 Test loss=0.316486 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.6561030149459839
[5/23] Train loss=0.6619191765785217
[10/23] Train loss=0.7521160244941711
[15/23] Train loss=0.6555644273757935
[20/23] Train loss=0.5991822481155396
Test set avg_accuracy=86.35% avg_sensitivity=81.46%, avg_specificity=87.91% avg_auc=93.49%
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.682884 Test loss=0.333391 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.65565025806427
[5/23] Train loss=0.6224961876869202
[10/23] Train loss=0.732728898525238
[15/23] Train loss=0.629747211933136
[20/23] Train loss=0.601196825504303
Test set avg_accuracy=87.77% avg_sensitivity=79.73%, avg_specificity=90.33% avg_auc=93.61%
Best model saved!! Metric=25.44702587615538!!
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.667993 Test loss=0.307935 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.6268576979637146
[5/23] Train loss=0.6025418639183044
[10/23] Train loss=0.7161763906478882
[15/23] Train loss=0.625723659992218
[20/23] Train loss=0.5810694098472595
Test set avg_accuracy=86.13% avg_sensitivity=83.72%, avg_specificity=86.90% avg_auc=93.92%
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.651064 Test loss=0.333056 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.6168349385261536
[5/23] Train loss=0.5816693902015686
[10/23] Train loss=0.6967102289199829
[15/23] Train loss=0.5951082706451416
[20/23] Train loss=0.5494378805160522
Test set avg_accuracy=88.82% avg_sensitivity=80.16%, avg_specificity=91.57% avg_auc=93.76%
Best model saved!! Metric=28.307046834089135!!
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.632738 Test loss=0.300488 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.591663122177124
[5/23] Train loss=0.5790759325027466
[10/23] Train loss=0.7037314176559448
[15/23] Train loss=0.6003855466842651
[20/23] Train loss=0.5466673970222473
Test set avg_accuracy=89.48% avg_sensitivity=80.22%, avg_specificity=92.43% avg_auc=94.02%
Best model saved!! Metric=30.139129879419556!!
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.624537 Test loss=0.288071 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.5881368517875671
[5/23] Train loss=0.568491518497467
[10/23] Train loss=0.7156288623809814
[15/23] Train loss=0.5836281180381775
[20/23] Train loss=0.5443331599235535
Test set avg_accuracy=90.17% avg_sensitivity=75.74%, avg_specificity=94.76% avg_auc=93.85%
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.615327 Test loss=0.269986 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.5818855166435242
[5/23] Train loss=0.531316876411438
[10/23] Train loss=0.6724845767021179
[15/23] Train loss=0.5665536522865295
[20/23] Train loss=0.5231797695159912
Test set avg_accuracy=89.61% avg_sensitivity=78.44%, avg_specificity=93.17% avg_auc=93.86%
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.597716 Test loss=0.278618 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.5679428577423096
[5/23] Train loss=0.5406190752983093
[10/23] Train loss=0.6760160326957703
[15/23] Train loss=0.5647410750389099
[20/23] Train loss=0.5119606256484985
Test set avg_accuracy=90.14% avg_sensitivity=75.85%, avg_specificity=94.70% avg_auc=93.82%
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.587258 Test loss=0.270306 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.5582550168037415
[5/23] Train loss=0.5271391272544861
[10/23] Train loss=0.6401646137237549
[15/23] Train loss=0.5364554524421692
[20/23] Train loss=0.5049318671226501
Test set avg_accuracy=89.65% avg_sensitivity=79.68%, avg_specificity=92.82% avg_auc=94.29%
Best model saved!! Metric=30.43984455435951!!
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.575342 Test loss=0.271033 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.531609058380127
[5/23] Train loss=0.5036700367927551
[10/23] Train loss=0.6283343434333801
[15/23] Train loss=0.539242684841156
[20/23] Train loss=0.4965366721153259
Test set avg_accuracy=87.43% avg_sensitivity=82.86%, avg_specificity=88.89% avg_auc=94.32%
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.563700 Test loss=0.298704 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.5366654396057129
[5/23] Train loss=0.509486734867096
[10/23] Train loss=0.6261048316955566
[15/23] Train loss=0.5142542123794556
[20/23] Train loss=0.4950043559074402
Test set avg_accuracy=89.24% avg_sensitivity=82.59%, avg_specificity=91.36% avg_auc=94.49%
Best model saved!! Metric=31.684642204014963!!
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.555235 Test loss=0.278570 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.5115626454353333
[5/23] Train loss=0.497455358505249
[10/23] Train loss=0.6022395491600037
[15/23] Train loss=0.5122925043106079
[20/23] Train loss=0.4654756486415863
Test set avg_accuracy=89.84% avg_sensitivity=81.19%, avg_specificity=92.60% avg_auc=94.51%
Best model saved!! Metric=32.14250871961873!!
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.543876 Test loss=0.267270 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.4992073178291321
[5/23] Train loss=0.4963708817958832
[10/23] Train loss=0.5947327017784119
[15/23] Train loss=0.5280981063842773
[20/23] Train loss=0.47667354345321655
Test set avg_accuracy=84.15% avg_sensitivity=88.30%, avg_specificity=82.83% avg_auc=94.40%
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.533226 Test loss=0.377628 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.5104287266731262
[5/23] Train loss=0.455746591091156
[10/23] Train loss=0.5485122799873352
[15/23] Train loss=0.49607959389686584
[20/23] Train loss=0.45693519711494446
Test set avg_accuracy=86.16% avg_sensitivity=86.52%, avg_specificity=86.04% avg_auc=94.68%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.519101 Test loss=0.324910 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.4807403087615967
[5/23] Train loss=0.45462122559547424
[10/23] Train loss=0.5466552972793579
[15/23] Train loss=0.4877431392669678
[20/23] Train loss=0.45732271671295166
Test set avg_accuracy=89.26% avg_sensitivity=81.35%, avg_specificity=91.78% avg_auc=94.30%
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.509946 Test loss=0.277437 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.4877247214317322
[5/23] Train loss=0.4446389079093933
[10/23] Train loss=0.5477074384689331
[15/23] Train loss=0.49459320306777954
[20/23] Train loss=0.44367098808288574
Test set avg_accuracy=89.78% avg_sensitivity=71.97%, avg_specificity=95.45% avg_auc=93.25%
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.505785 Test loss=0.269089 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.4880882799625397
[5/23] Train loss=0.4459784924983978
[10/23] Train loss=0.49405887722969055
[15/23] Train loss=0.4629831314086914
[20/23] Train loss=0.45444080233573914
Test set avg_accuracy=89.27% avg_sensitivity=79.41%, avg_specificity=92.41% avg_auc=93.47%
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.489833 Test loss=0.284002 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.4732713997364044
[5/23] Train loss=0.46262094378471375
[10/23] Train loss=0.5255439281463623
[15/23] Train loss=0.48072540760040283
[20/23] Train loss=0.42430779337882996
Test set avg_accuracy=87.85% avg_sensitivity=84.85%, avg_specificity=88.81% avg_auc=94.92%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.486596 Test loss=0.286834 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.4663807153701782
[5/23] Train loss=0.4232136011123657
[10/23] Train loss=0.48568105697631836
[15/23] Train loss=0.472138375043869
[20/23] Train loss=0.4381418824195862
Test set avg_accuracy=83.88% avg_sensitivity=87.71%, avg_specificity=82.66% avg_auc=93.46%
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.474278 Test loss=0.386621 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.45690643787384033
[5/23] Train loss=0.4157368540763855
[10/23] Train loss=0.4971959888935089
[15/23] Train loss=0.4690147042274475
[20/23] Train loss=0.40179356932640076
Test set avg_accuracy=85.99% avg_sensitivity=87.28%, avg_specificity=85.58% avg_auc=94.09%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.469211 Test loss=0.348176 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.4512486755847931
[5/23] Train loss=0.38024258613586426
[10/23] Train loss=0.48444658517837524
[15/23] Train loss=0.4584168791770935
[20/23] Train loss=0.41671302914619446
Test set avg_accuracy=81.69% avg_sensitivity=88.89%, avg_specificity=79.40% avg_auc=93.25%
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.461854 Test loss=0.423858 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.4494498074054718
[5/23] Train loss=0.37985628843307495
[10/23] Train loss=0.4508485198020935
[15/23] Train loss=0.4541235864162445
[20/23] Train loss=0.4063923954963684
Test set avg_accuracy=88.95% avg_sensitivity=81.29%, avg_specificity=91.38% avg_auc=93.06%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.452603 Test loss=0.288634 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.43135058879852295
[5/23] Train loss=0.36973631381988525
[10/23] Train loss=0.45647838711738586
[15/23] Train loss=0.448845237493515
[20/23] Train loss=0.3841298520565033
Test set avg_accuracy=86.00% avg_sensitivity=85.93%, avg_specificity=86.03% avg_auc=94.10%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.456211 Test loss=0.336320 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.4250938594341278
[5/23] Train loss=0.3697570860385895
[10/23] Train loss=0.4299176037311554
[15/23] Train loss=0.451111376285553
[20/23] Train loss=0.39238810539245605
Test set avg_accuracy=83.70% avg_sensitivity=87.39%, avg_specificity=82.52% avg_auc=93.84%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.437477 Test loss=0.368181 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.42067858576774597
[5/23] Train loss=0.38067856431007385
[10/23] Train loss=0.452902615070343
[15/23] Train loss=0.4406949579715729
[20/23] Train loss=0.36631351709365845
Test set avg_accuracy=66.64% avg_sensitivity=95.63%, avg_specificity=57.41% avg_auc=91.06%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.433963 Test loss=0.774128 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.4110882580280304
[5/23] Train loss=0.3519837260246277
[10/23] Train loss=0.42795825004577637
[15/23] Train loss=0.4407273232936859
[20/23] Train loss=0.3803253769874573
Test set avg_accuracy=85.60% avg_sensitivity=84.58%, avg_specificity=85.92% avg_auc=93.26%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.442197 Test loss=0.331471 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.40531110763549805
[5/23] Train loss=0.3862468898296356
[10/23] Train loss=0.4376736879348755
[15/23] Train loss=0.41722938418388367
[20/23] Train loss=0.3848107159137726
Test set avg_accuracy=89.11% avg_sensitivity=74.56%, avg_specificity=93.75% avg_auc=92.99%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.431470 Test loss=0.274562 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.401483952999115
[5/23] Train loss=0.3428686559200287
[10/23] Train loss=0.4248093068599701
[15/23] Train loss=0.4112207591533661
[20/23] Train loss=0.3985265791416168
Test set avg_accuracy=88.68% avg_sensitivity=71.59%, avg_specificity=94.13% avg_auc=90.87%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.413498 Test loss=0.306652 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.4032950699329376
[5/23] Train loss=0.33484020829200745
[10/23] Train loss=0.4364386200904846
[15/23] Train loss=0.40420758724212646
[20/23] Train loss=0.3637569546699524
Test set avg_accuracy=89.71% avg_sensitivity=79.03%, avg_specificity=93.12% avg_auc=93.97%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.412109 Test loss=0.259233 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.37364357709884644
[5/23] Train loss=0.3503526747226715
[10/23] Train loss=0.40595975518226624
[15/23] Train loss=0.39151787757873535
[20/23] Train loss=0.3573927879333496
Test set avg_accuracy=89.78% avg_sensitivity=74.39%, avg_specificity=94.68% avg_auc=91.73%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.397992 Test loss=0.292162 Current lr=[0.000299926900870094]

[0/23] Train loss=0.3738164007663727
[5/23] Train loss=0.30986958742141724
[10/23] Train loss=0.3929312825202942
[15/23] Train loss=0.39496302604675293
[20/23] Train loss=0.3480754494667053
Test set avg_accuracy=88.44% avg_sensitivity=81.78%, avg_specificity=90.56% avg_auc=93.29%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.392102 Test loss=0.298626 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.3707067668437958
[5/23] Train loss=0.32292965054512024
[10/23] Train loss=0.3982642590999603
[15/23] Train loss=0.40091657638549805
[20/23] Train loss=0.34763893485069275
Test set avg_accuracy=87.94% avg_sensitivity=76.77%, avg_specificity=91.50% avg_auc=90.51%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.390524 Test loss=0.339675 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.3775308132171631
[5/23] Train loss=0.3292027413845062
[10/23] Train loss=0.3930394649505615
[15/23] Train loss=0.36519619822502136
[20/23] Train loss=0.3638182580471039
Test set avg_accuracy=85.04% avg_sensitivity=86.25%, avg_specificity=84.65% avg_auc=91.50%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.388636 Test loss=0.403572 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.3573230803012848
[5/23] Train loss=0.32246771454811096
[10/23] Train loss=0.3673880994319916
[15/23] Train loss=0.34209516644477844
[20/23] Train loss=0.3435010015964508
Test set avg_accuracy=89.34% avg_sensitivity=67.28%, avg_specificity=96.36% avg_auc=91.19%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.377360 Test loss=0.300296 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.3581756055355072
[5/23] Train loss=0.32986488938331604
[10/23] Train loss=0.38080108165740967
[15/23] Train loss=0.36058682203292847
[20/23] Train loss=0.3331789970397949
Test set avg_accuracy=89.90% avg_sensitivity=77.30%, avg_specificity=93.91% avg_auc=91.90%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.373286 Test loss=0.303092 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.3720283806324005
[5/23] Train loss=0.2979965806007385
[10/23] Train loss=0.37074580788612366
[15/23] Train loss=0.3632473051548004
[20/23] Train loss=0.31057390570640564
Test set avg_accuracy=89.26% avg_sensitivity=68.73%, avg_specificity=95.79% avg_auc=89.73%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.365483 Test loss=0.312321 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.36965715885162354
[5/23] Train loss=0.29501885175704956
[10/23] Train loss=0.38556769490242004
[15/23] Train loss=0.36473867297172546
[20/23] Train loss=0.3362044394016266
Test set avg_accuracy=86.98% avg_sensitivity=83.18%, avg_specificity=88.19% avg_auc=93.40%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.369989 Test loss=0.323682 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.37046027183532715
[5/23] Train loss=0.2897924482822418
[10/23] Train loss=0.34932056069374084
[15/23] Train loss=0.36446118354797363
[20/23] Train loss=0.33950772881507874
Test set avg_accuracy=86.30% avg_sensitivity=81.78%, avg_specificity=87.74% avg_auc=91.83%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.361797 Test loss=0.372655 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.33292365074157715
[5/23] Train loss=0.31990325450897217
[10/23] Train loss=0.343843936920166
[15/23] Train loss=0.34643059968948364
[20/23] Train loss=0.335362046957016
Test set avg_accuracy=89.00% avg_sensitivity=65.18%, avg_specificity=96.58% avg_auc=91.25%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.349378 Test loss=0.297567 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.33917683362960815
[5/23] Train loss=0.2798035442829132
[10/23] Train loss=0.3496854305267334
[15/23] Train loss=0.3360954225063324
[20/23] Train loss=0.30153176188468933
Test set avg_accuracy=89.36% avg_sensitivity=67.87%, avg_specificity=96.21% avg_auc=91.90%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.343565 Test loss=0.291535 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.342422753572464
[5/23] Train loss=0.30684635043144226
[10/23] Train loss=0.3381766080856323
[15/23] Train loss=0.33910229802131653
[20/23] Train loss=0.289333313703537
Test set avg_accuracy=89.52% avg_sensitivity=71.64%, avg_specificity=95.21% avg_auc=91.57%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.345510 Test loss=0.285749 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.314559668302536
[5/23] Train loss=0.28570693731307983
[10/23] Train loss=0.33258262276649475
[15/23] Train loss=0.35046789050102234
[20/23] Train loss=0.313760370016098
Test set avg_accuracy=88.89% avg_sensitivity=68.89%, avg_specificity=95.26% avg_auc=90.14%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.347568 Test loss=0.307699 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.31291452050209045
[5/23] Train loss=0.2716382145881653
[10/23] Train loss=0.33745846152305603
[15/23] Train loss=0.35667434334754944
[20/23] Train loss=0.31938663125038147
Test set avg_accuracy=86.32% avg_sensitivity=80.81%, avg_specificity=88.07% avg_auc=92.58%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.349204 Test loss=0.348580 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.33670124411582947
[5/23] Train loss=0.29617980122566223
[10/23] Train loss=0.34967169165611267
[15/23] Train loss=0.34928616881370544
[20/23] Train loss=0.30241701006889343
Test set avg_accuracy=87.28% avg_sensitivity=80.70%, avg_specificity=89.37% avg_auc=91.06%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.347326 Test loss=0.343293 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.3099208474159241
[5/23] Train loss=0.2830415368080139
[10/23] Train loss=0.3283422589302063
[15/23] Train loss=0.31514379382133484
[20/23] Train loss=0.3054182827472687
Test set avg_accuracy=87.23% avg_sensitivity=52.56%, avg_specificity=98.27% avg_auc=86.11%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.330259 Test loss=0.364503 Current lr=[0.000283047938381597]

[0/23] Train loss=0.32763341069221497
[5/23] Train loss=0.2864235043525696
[10/23] Train loss=0.32078084349632263
[15/23] Train loss=0.337967187166214
[20/23] Train loss=0.3273147940635681
Test set avg_accuracy=88.24% avg_sensitivity=63.83%, avg_specificity=96.02% avg_auc=90.40%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.351525 Test loss=0.315661 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.32139939069747925
[5/23] Train loss=0.30688026547431946
[10/23] Train loss=0.33679360151290894
[15/23] Train loss=0.3071816861629486
[20/23] Train loss=0.3052583336830139
Test set avg_accuracy=88.88% avg_sensitivity=76.66%, avg_specificity=92.77% avg_auc=91.35%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.331290 Test loss=0.315236 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.3272075951099396
[5/23] Train loss=0.2698642909526825
[10/23] Train loss=0.31202831864356995
[15/23] Train loss=0.3016811013221741
[20/23] Train loss=0.328354150056839
Test set avg_accuracy=88.01% avg_sensitivity=78.44%, avg_specificity=91.06% avg_auc=92.13%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.332508 Test loss=0.325439 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.31676235795021057
[5/23] Train loss=0.2860513925552368
[10/23] Train loss=0.3283557891845703
[15/23] Train loss=0.3231629729270935
[20/23] Train loss=0.2905159294605255
Test set avg_accuracy=89.19% avg_sensitivity=68.36%, avg_specificity=95.83% avg_auc=88.58%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.335164 Test loss=0.349695 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.3095853328704834
[5/23] Train loss=0.2672179639339447
[10/23] Train loss=0.2918432354927063
[15/23] Train loss=0.3104074001312256
[20/23] Train loss=0.30108073353767395
Test set avg_accuracy=88.46% avg_sensitivity=81.08%, avg_specificity=90.82% avg_auc=92.21%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.317424 Test loss=0.325967 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.30985841155052185
[5/23] Train loss=0.25813204050064087
[10/23] Train loss=0.30279555916786194
[15/23] Train loss=0.2985902428627014
[20/23] Train loss=0.2896501123905182
Test set avg_accuracy=86.98% avg_sensitivity=82.48%, avg_specificity=88.41% avg_auc=92.13%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.312736 Test loss=0.358174 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.28032436966896057
[5/23] Train loss=0.2474389225244522
[10/23] Train loss=0.31019100546836853
[15/23] Train loss=0.32409098744392395
[20/23] Train loss=0.3100631535053253
Test set avg_accuracy=89.44% avg_sensitivity=72.56%, avg_specificity=94.82% avg_auc=91.63%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.317332 Test loss=0.302368 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.29763707518577576
[5/23] Train loss=0.2692505419254303
[10/23] Train loss=0.34398436546325684
[15/23] Train loss=0.3125377595424652
[20/23] Train loss=0.272754430770874
Test set avg_accuracy=86.91% avg_sensitivity=82.10%, avg_specificity=88.45% avg_auc=92.26%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.316036 Test loss=0.347581 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.3141569495201111
[5/23] Train loss=0.2638399600982666
[10/23] Train loss=0.3284788429737091
[15/23] Train loss=0.30133289098739624
[20/23] Train loss=0.28731733560562134
Test set avg_accuracy=89.47% avg_sensitivity=76.06%, avg_specificity=93.73% avg_auc=91.81%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.319349 Test loss=0.313345 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.3001385033130646
[5/23] Train loss=0.2781367301940918
[10/23] Train loss=0.32391899824142456
[15/23] Train loss=0.30297237634658813
[20/23] Train loss=0.27077752351760864
Test set avg_accuracy=87.33% avg_sensitivity=81.24%, avg_specificity=89.27% avg_auc=91.49%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.315269 Test loss=0.376205 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.28952643275260925
[5/23] Train loss=0.28239116072654724
[10/23] Train loss=0.30141061544418335
[15/23] Train loss=0.29423531889915466
[20/23] Train loss=0.27578407526016235
Test set avg_accuracy=75.49% avg_sensitivity=92.18%, avg_specificity=70.18% avg_auc=91.80%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.305304 Test loss=0.625830 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.28818970918655396
[5/23] Train loss=0.28264644742012024
[10/23] Train loss=0.3064703643321991
[15/23] Train loss=0.29444488883018494
[20/23] Train loss=0.2589050233364105
Test set avg_accuracy=87.27% avg_sensitivity=81.02%, avg_specificity=89.25% avg_auc=92.81%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.305269 Test loss=0.339786 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.2898702919483185
[5/23] Train loss=0.2578202784061432
[10/23] Train loss=0.27420875430107117
[15/23] Train loss=0.29069527983665466
[20/23] Train loss=0.2643541991710663
Test set avg_accuracy=86.37% avg_sensitivity=84.80%, avg_specificity=86.87% avg_auc=93.19%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.298323 Test loss=0.370362 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.2910565137863159
[5/23] Train loss=0.23125088214874268
[10/23] Train loss=0.28235843777656555
[15/23] Train loss=0.28209659457206726
[20/23] Train loss=0.2602227032184601
Test set avg_accuracy=88.02% avg_sensitivity=81.19%, avg_specificity=90.20% avg_auc=92.69%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.290695 Test loss=0.326521 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.27678561210632324
[5/23] Train loss=0.2359323352575302
[10/23] Train loss=0.2866044342517853
[15/23] Train loss=0.2645398676395416
[20/23] Train loss=0.2629760503768921
Test set avg_accuracy=87.99% avg_sensitivity=71.05%, avg_specificity=93.39% avg_auc=89.71%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.285925 Test loss=0.341700 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.27278316020965576
[5/23] Train loss=0.2420363575220108
[10/23] Train loss=0.26063022017478943
[15/23] Train loss=0.2720305919647217
[20/23] Train loss=0.26330244541168213
Test set avg_accuracy=88.66% avg_sensitivity=65.18%, avg_specificity=96.14% avg_auc=90.01%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.282070 Test loss=0.323221 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.2592061161994934
[5/23] Train loss=0.2478674054145813
[10/23] Train loss=0.26378554105758667
[15/23] Train loss=0.2920316159725189
[20/23] Train loss=0.2443561851978302
Test set avg_accuracy=88.26% avg_sensitivity=76.17%, avg_specificity=92.10% avg_auc=90.80%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.275121 Test loss=0.337875 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.2751297652721405
[5/23] Train loss=0.2526615858078003
[10/23] Train loss=0.2851799428462982
[15/23] Train loss=0.26061171293258667
[20/23] Train loss=0.23891323804855347
Test set avg_accuracy=89.06% avg_sensitivity=72.99%, avg_specificity=94.18% avg_auc=91.60%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.278048 Test loss=0.311016 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.26542922854423523
[5/23] Train loss=0.23668433725833893
[10/23] Train loss=0.268806517124176
[15/23] Train loss=0.2526405453681946
[20/23] Train loss=0.233505517244339
Test set avg_accuracy=87.12% avg_sensitivity=51.91%, avg_specificity=98.33% avg_auc=86.98%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.272534 Test loss=0.374582 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.26240500807762146
[5/23] Train loss=0.2505568861961365
[10/23] Train loss=0.28083333373069763
[15/23] Train loss=0.2651071548461914
[20/23] Train loss=0.23692195117473602
Test set avg_accuracy=89.30% avg_sensitivity=72.88%, avg_specificity=94.52% avg_auc=91.21%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.277255 Test loss=0.333111 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.25410687923431396
[5/23] Train loss=0.24193641543388367
[10/23] Train loss=0.2543238699436188
[15/23] Train loss=0.27116280794143677
[20/23] Train loss=0.24286676943302155
Test set avg_accuracy=89.13% avg_sensitivity=62.32%, avg_specificity=97.67% avg_auc=88.69%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.271453 Test loss=0.327821 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.26128655672073364
[5/23] Train loss=0.2401641607284546
[10/23] Train loss=0.24678991734981537
[15/23] Train loss=0.2517422139644623
[20/23] Train loss=0.2426852583885193
Test set avg_accuracy=89.35% avg_sensitivity=68.89%, avg_specificity=95.86% avg_auc=91.08%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.269428 Test loss=0.297420 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.2607458531856537
[5/23] Train loss=0.24669474363327026
[10/23] Train loss=0.2548823356628418
[15/23] Train loss=0.24139264225959778
[20/23] Train loss=0.22035308182239532
Test set avg_accuracy=87.32% avg_sensitivity=60.32%, avg_specificity=95.91% avg_auc=87.74%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.262884 Test loss=0.348693 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.24215184152126312
[5/23] Train loss=0.23455046117305756
[10/23] Train loss=0.2548998296260834
[15/23] Train loss=0.2618030607700348
[20/23] Train loss=0.23405088484287262
Test set avg_accuracy=88.44% avg_sensitivity=67.92%, avg_specificity=94.97% avg_auc=90.17%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.265384 Test loss=0.339419 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.2664048671722412
[5/23] Train loss=0.2604140043258667
[10/23] Train loss=0.2812166213989258
[15/23] Train loss=0.2530010938644409
[20/23] Train loss=0.2467053234577179
Test set avg_accuracy=87.72% avg_sensitivity=57.14%, avg_specificity=97.46% avg_auc=90.00%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.277821 Test loss=0.337960 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.24425068497657776
[5/23] Train loss=0.24624896049499512
[10/23] Train loss=0.2636987566947937
[15/23] Train loss=0.2521819770336151
[20/23] Train loss=0.2521149516105652
Test set avg_accuracy=88.44% avg_sensitivity=72.18%, avg_specificity=93.61% avg_auc=91.01%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.269145 Test loss=0.349036 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.283181756734848
[5/23] Train loss=0.22161923348903656
[10/23] Train loss=0.24315877258777618
[15/23] Train loss=0.2506135106086731
[20/23] Train loss=0.2504671514034271
Test set avg_accuracy=88.63% avg_sensitivity=73.85%, avg_specificity=93.34% avg_auc=90.67%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.263565 Test loss=0.358709 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.249813511967659
[5/23] Train loss=0.21952557563781738
[10/23] Train loss=0.26983118057250977
[15/23] Train loss=0.25360414385795593
[20/23] Train loss=0.22579112648963928
Test set avg_accuracy=89.92% avg_sensitivity=69.65%, avg_specificity=96.38% avg_auc=91.97%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.259747 Test loss=0.285358 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.25437015295028687
[5/23] Train loss=0.23194584250450134
[10/23] Train loss=0.2386302500963211
[15/23] Train loss=0.2387467473745346
[20/23] Train loss=0.22340820729732513
Test set avg_accuracy=88.91% avg_sensitivity=73.91%, avg_specificity=93.68% avg_auc=91.53%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.254390 Test loss=0.327358 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.2414221614599228
[5/23] Train loss=0.22350214421749115
[10/23] Train loss=0.24586965143680573
[15/23] Train loss=0.23201559484004974
[20/23] Train loss=0.23137319087982178
Test set avg_accuracy=88.84% avg_sensitivity=78.06%, avg_specificity=92.27% avg_auc=92.39%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.244684 Test loss=0.326149 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.24407584965229034
[5/23] Train loss=0.23139603435993195
[10/23] Train loss=0.23889103531837463
[15/23] Train loss=0.23320522904396057
[20/23] Train loss=0.21596884727478027
Test set avg_accuracy=88.55% avg_sensitivity=78.17%, avg_specificity=91.86% avg_auc=92.40%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.246497 Test loss=0.339189 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.23302878439426422
[5/23] Train loss=0.20866653323173523
[10/23] Train loss=0.23102670907974243
[15/23] Train loss=0.2304464727640152
[20/23] Train loss=0.21601036190986633
Test set avg_accuracy=90.09% avg_sensitivity=77.36%, avg_specificity=94.15% avg_auc=93.37%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.244375 Test loss=0.285118 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.24409085512161255
[5/23] Train loss=0.22162172198295593
[10/23] Train loss=0.22604647278785706
[15/23] Train loss=0.2271878868341446
[20/23] Train loss=0.20612864196300507
Test set avg_accuracy=88.68% avg_sensitivity=75.85%, avg_specificity=92.77% avg_auc=92.51%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.238438 Test loss=0.298208 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.23640379309654236
[5/23] Train loss=0.223586305975914
[10/23] Train loss=0.23048977553844452
[15/23] Train loss=0.22364048659801483
[20/23] Train loss=0.20445474982261658
Test set avg_accuracy=88.49% avg_sensitivity=81.08%, avg_specificity=90.85% avg_auc=93.11%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.239437 Test loss=0.332523 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.23690180480480194
[5/23] Train loss=0.2189173549413681
[10/23] Train loss=0.21535708010196686
[15/23] Train loss=0.2186422049999237
[20/23] Train loss=0.21140894293785095
Test set avg_accuracy=89.78% avg_sensitivity=78.54%, avg_specificity=93.36% avg_auc=93.08%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.234964 Test loss=0.295397 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.22347934544086456
[5/23] Train loss=0.20715992152690887
[10/23] Train loss=0.22204600274562836
[15/23] Train loss=0.23186331987380981
[20/23] Train loss=0.22118449211120605
Test set avg_accuracy=88.42% avg_sensitivity=79.89%, avg_specificity=91.14% avg_auc=93.24%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.236060 Test loss=0.316320 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.21553552150726318
[5/23] Train loss=0.21319898962974548
[10/23] Train loss=0.21467502415180206
[15/23] Train loss=0.23289696872234344
[20/23] Train loss=0.21150463819503784
Test set avg_accuracy=89.54% avg_sensitivity=80.11%, avg_specificity=92.55% avg_auc=92.68%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.233718 Test loss=0.316273 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.23058192431926727
[5/23] Train loss=0.21591699123382568
[10/23] Train loss=0.2179427593946457
[15/23] Train loss=0.22147397696971893
[20/23] Train loss=0.2032691091299057
Test set avg_accuracy=90.04% avg_sensitivity=76.06%, avg_specificity=94.49% avg_auc=92.84%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.227012 Test loss=0.292752 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.21916301548480988
[5/23] Train loss=0.2196023315191269
[10/23] Train loss=0.21782246232032776
[15/23] Train loss=0.21171468496322632
[20/23] Train loss=0.18791761994361877
Test set avg_accuracy=89.52% avg_sensitivity=80.27%, avg_specificity=92.46% avg_auc=93.52%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.220491 Test loss=0.306450 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.21342818439006805
[5/23] Train loss=0.20171323418617249
[10/23] Train loss=0.20359234511852264
[15/23] Train loss=0.210525780916214
[20/23] Train loss=0.19365954399108887
Test set avg_accuracy=88.98% avg_sensitivity=80.86%, avg_specificity=91.57% avg_auc=92.96%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.220379 Test loss=0.308319 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.22585752606391907
[5/23] Train loss=0.2076999396085739
[10/23] Train loss=0.20592500269412994
[15/23] Train loss=0.21595558524131775
[20/23] Train loss=0.19267478585243225
Test set avg_accuracy=89.49% avg_sensitivity=74.93%, avg_specificity=94.13% avg_auc=91.12%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.219360 Test loss=0.325193 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.20903348922729492
[5/23] Train loss=0.20457157492637634
[10/23] Train loss=0.20999643206596375
[15/23] Train loss=0.20061151683330536
[20/23] Train loss=0.193167045712471
Test set avg_accuracy=87.68% avg_sensitivity=81.13%, avg_specificity=89.77% avg_auc=92.45%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.218607 Test loss=0.352171 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.20402374863624573
[5/23] Train loss=0.19209080934524536
[10/23] Train loss=0.19890096783638
[15/23] Train loss=0.19612742960453033
[20/23] Train loss=0.18008607625961304
Test set avg_accuracy=88.85% avg_sensitivity=77.74%, avg_specificity=92.39% avg_auc=91.85%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.208568 Test loss=0.328561 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.2015540897846222
[5/23] Train loss=0.19664987921714783
[10/23] Train loss=0.19904382526874542
[15/23] Train loss=0.22763419151306152
[20/23] Train loss=0.18806813657283783
Test set avg_accuracy=88.70% avg_sensitivity=79.08%, avg_specificity=91.76% avg_auc=92.78%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.210159 Test loss=0.321435 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.1994907706975937
[5/23] Train loss=0.19655050337314606
[10/23] Train loss=0.20309972763061523
[15/23] Train loss=0.19123311340808868
[20/23] Train loss=0.18676164746284485
Test set avg_accuracy=88.53% avg_sensitivity=77.90%, avg_specificity=91.91% avg_auc=92.48%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.206523 Test loss=0.327179 Current lr=[0.000112073915556435]

[0/23] Train loss=0.20556217432022095
[5/23] Train loss=0.1970164179801941
[10/23] Train loss=0.20549261569976807
[15/23] Train loss=0.19326022267341614
[20/23] Train loss=0.1756564825773239
Test set avg_accuracy=88.67% avg_sensitivity=75.85%, avg_specificity=92.76% avg_auc=92.43%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.206637 Test loss=0.315156 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.19881606101989746
[5/23] Train loss=0.17992636561393738
[10/23] Train loss=0.20218679308891296
[15/23] Train loss=0.1911652684211731
[20/23] Train loss=0.18629097938537598
Test set avg_accuracy=89.38% avg_sensitivity=74.23%, avg_specificity=94.20% avg_auc=91.69%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.201906 Test loss=0.308117 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.19913135468959808
[5/23] Train loss=0.1813282072544098
[10/23] Train loss=0.19655060768127441
[15/23] Train loss=0.19029265642166138
[20/23] Train loss=0.1749289184808731
Test set avg_accuracy=88.65% avg_sensitivity=75.31%, avg_specificity=92.89% avg_auc=92.08%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.201057 Test loss=0.319537 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.20543433725833893
[5/23] Train loss=0.18088398873806
[10/23] Train loss=0.19207824766635895
[15/23] Train loss=0.18666858971118927
[20/23] Train loss=0.17237816751003265
Test set avg_accuracy=88.24% avg_sensitivity=74.50%, avg_specificity=92.62% avg_auc=91.96%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.195432 Test loss=0.328415 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.190632164478302
[5/23] Train loss=0.1828300505876541
[10/23] Train loss=0.19197967648506165
[15/23] Train loss=0.1944308876991272
[20/23] Train loss=0.17001499235630035
Test set avg_accuracy=88.03% avg_sensitivity=75.58%, avg_specificity=92.00% avg_auc=92.27%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.193552 Test loss=0.329092 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.1838492453098297
[5/23] Train loss=0.17515075206756592
[10/23] Train loss=0.1907293051481247
[15/23] Train loss=0.17718036472797394
[20/23] Train loss=0.17441973090171814
Test set avg_accuracy=88.74% avg_sensitivity=73.85%, avg_specificity=93.48% avg_auc=92.24%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.191545 Test loss=0.318801 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.1862410455942154
[5/23] Train loss=0.17787374556064606
[10/23] Train loss=0.18258719146251678
[15/23] Train loss=0.19378846883773804
[20/23] Train loss=0.16961267590522766
Test set avg_accuracy=89.48% avg_sensitivity=73.42%, avg_specificity=94.59% avg_auc=92.69%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.192203 Test loss=0.301936 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.1754956841468811
[5/23] Train loss=0.17781703174114227
[10/23] Train loss=0.18318863213062286
[15/23] Train loss=0.18657803535461426
[20/23] Train loss=0.16541463136672974
Test set avg_accuracy=89.44% avg_sensitivity=74.39%, avg_specificity=94.23% avg_auc=92.37%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.190187 Test loss=0.306928 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.18819975852966309
[5/23] Train loss=0.17686967551708221
[10/23] Train loss=0.17700517177581787
[15/23] Train loss=0.17670930922031403
[20/23] Train loss=0.16546650230884552
Test set avg_accuracy=89.57% avg_sensitivity=72.08%, avg_specificity=95.14% avg_auc=91.64%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.186894 Test loss=0.300536 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.17702730000019073
[5/23] Train loss=0.169198676943779
[10/23] Train loss=0.1681315302848816
[15/23] Train loss=0.18383565545082092
[20/23] Train loss=0.16849932074546814
Test set avg_accuracy=89.17% avg_sensitivity=72.72%, avg_specificity=94.40% avg_auc=92.03%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.185024 Test loss=0.309125 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.17987528443336487
[5/23] Train loss=0.16793499886989594
[10/23] Train loss=0.17257018387317657
[15/23] Train loss=0.17254821956157684
[20/23] Train loss=0.16561976075172424
Test set avg_accuracy=89.56% avg_sensitivity=75.04%, avg_specificity=94.18% avg_auc=92.08%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.182733 Test loss=0.307209 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.17507867515087128
[5/23] Train loss=0.1631869375705719
[10/23] Train loss=0.17638510465621948
[15/23] Train loss=0.17410311102867126
[20/23] Train loss=0.16559338569641113
Test set avg_accuracy=89.10% avg_sensitivity=78.76%, avg_specificity=92.39% avg_auc=92.65%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.182552 Test loss=0.310735 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.17537792026996613
[5/23] Train loss=0.1674479842185974
[10/23] Train loss=0.17653311789035797
[15/23] Train loss=0.17226554453372955
[20/23] Train loss=0.15941108763217926
Test set avg_accuracy=89.62% avg_sensitivity=77.63%, avg_specificity=93.44% avg_auc=92.16%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.180505 Test loss=0.317669 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.179445281624794
[5/23] Train loss=0.16194964945316315
[10/23] Train loss=0.17544060945510864
[15/23] Train loss=0.1667294204235077
[20/23] Train loss=0.15790461003780365
Test set avg_accuracy=89.34% avg_sensitivity=77.57%, avg_specificity=93.08% avg_auc=92.54%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.179718 Test loss=0.310056 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.1856488436460495
[5/23] Train loss=0.16165010631084442
[10/23] Train loss=0.16873392462730408
[15/23] Train loss=0.18063746392726898
[20/23] Train loss=0.15912924706935883
Test set avg_accuracy=89.67% avg_sensitivity=73.42%, avg_specificity=94.85% avg_auc=92.20%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.179596 Test loss=0.299089 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.1697228103876114
[5/23] Train loss=0.1604030430316925
[10/23] Train loss=0.16857920587062836
[15/23] Train loss=0.18233834207057953
[20/23] Train loss=0.16094240546226501
Test set avg_accuracy=90.09% avg_sensitivity=75.47%, avg_specificity=94.75% avg_auc=92.54%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.178533 Test loss=0.293923 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.1661306619644165
[5/23] Train loss=0.1619586944580078
[10/23] Train loss=0.15798382461071014
[15/23] Train loss=0.17284314334392548
[20/23] Train loss=0.1579856425523758
Test set avg_accuracy=89.87% avg_sensitivity=74.82%, avg_specificity=94.66% avg_auc=92.85%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.176477 Test loss=0.290319 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.16755829751491547
[5/23] Train loss=0.17453929781913757
[10/23] Train loss=0.1602095067501068
[15/23] Train loss=0.1701820194721222
[20/23] Train loss=0.15861038863658905
Test set avg_accuracy=88.93% avg_sensitivity=76.39%, avg_specificity=92.93% avg_auc=92.72%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.177932 Test loss=0.307112 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.1610911786556244
[5/23] Train loss=0.169269859790802
[10/23] Train loss=0.16765333712100983
[15/23] Train loss=0.16922420263290405
[20/23] Train loss=0.16259999573230743
Test set avg_accuracy=88.44% avg_sensitivity=80.43%, avg_specificity=90.99% avg_auc=92.83%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.177400 Test loss=0.327334 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.17082074284553528
[5/23] Train loss=0.16428761184215546
[10/23] Train loss=0.16735124588012695
[15/23] Train loss=0.1670338362455368
[20/23] Train loss=0.16296949982643127
Test set avg_accuracy=87.97% avg_sensitivity=79.89%, avg_specificity=90.54% avg_auc=92.87%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.177847 Test loss=0.335972 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.17741870880126953
[5/23] Train loss=0.16637596487998962
[10/23] Train loss=0.17111067473888397
[15/23] Train loss=0.16444070637226105
[20/23] Train loss=0.15631751716136932
Test set avg_accuracy=88.78% avg_sensitivity=77.14%, avg_specificity=92.48% avg_auc=92.67%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.175662 Test loss=0.311153 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.17121413350105286
[5/23] Train loss=0.15706275403499603
[10/23] Train loss=0.16814014315605164
[15/23] Train loss=0.16321071982383728
[20/23] Train loss=0.15237224102020264
Test set avg_accuracy=89.00% avg_sensitivity=74.77%, avg_specificity=93.53% avg_auc=92.61%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.172123 Test loss=0.299050 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.16504183411598206
[5/23] Train loss=0.15755106508731842
[10/23] Train loss=0.15999045968055725
[15/23] Train loss=0.16342459619045258
[20/23] Train loss=0.15133318305015564
Test set avg_accuracy=89.28% avg_sensitivity=74.39%, avg_specificity=94.03% avg_auc=92.74%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.169977 Test loss=0.291991 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.158956378698349
[5/23] Train loss=0.1530599296092987
[10/23] Train loss=0.15601755678653717
[15/23] Train loss=0.16018185019493103
[20/23] Train loss=0.1477649062871933
Test set avg_accuracy=88.55% avg_sensitivity=79.95%, avg_specificity=91.30% avg_auc=93.14%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.166353 Test loss=0.317002 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.15668825805187225
[5/23] Train loss=0.15157516300678253
[10/23] Train loss=0.15816420316696167
[15/23] Train loss=0.15341578423976898
[20/23] Train loss=0.14641056954860687
Test set avg_accuracy=89.00% avg_sensitivity=76.55%, avg_specificity=92.96% avg_auc=92.93%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.164023 Test loss=0.300559 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.1585915982723236
[5/23] Train loss=0.15015561878681183
[10/23] Train loss=0.15312300622463226
[15/23] Train loss=0.16083315014839172
[20/23] Train loss=0.14378423988819122
Test set avg_accuracy=89.21% avg_sensitivity=77.41%, avg_specificity=92.96% avg_auc=92.82%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.163022 Test loss=0.300757 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.1576012372970581
[5/23] Train loss=0.1522836834192276
[10/23] Train loss=0.15233838558197021
[15/23] Train loss=0.15727129578590393
[20/23] Train loss=0.14524897933006287
Test set avg_accuracy=89.53% avg_sensitivity=77.95%, avg_specificity=93.22% avg_auc=92.91%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.162462 Test loss=0.301344 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.15887391567230225
[5/23] Train loss=0.14734269678592682
[10/23] Train loss=0.15196886658668518
[15/23] Train loss=0.15485775470733643
[20/23] Train loss=0.14476977288722992
Test set avg_accuracy=89.36% avg_sensitivity=77.20%, avg_specificity=93.24% avg_auc=92.87%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.162468 Test loss=0.299839 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.15378916263580322
[5/23] Train loss=0.1496555358171463
[10/23] Train loss=0.15084998309612274
[15/23] Train loss=0.15261028707027435
[20/23] Train loss=0.14395448565483093
Test set avg_accuracy=89.39% avg_sensitivity=77.36%, avg_specificity=93.22% avg_auc=92.96%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.160838 Test loss=0.297772 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.1540748029947281
[5/23] Train loss=0.14855444431304932
[10/23] Train loss=0.15199819207191467
[15/23] Train loss=0.15392139554023743
[20/23] Train loss=0.1475808471441269
Test set avg_accuracy=89.15% avg_sensitivity=78.54%, avg_specificity=92.53% avg_auc=93.08%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.160309 Test loss=0.307278 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.15279620885849
[5/23] Train loss=0.14708545804023743
[10/23] Train loss=0.15076880156993866
[15/23] Train loss=0.15418730676174164
[20/23] Train loss=0.14620369672775269
Test set avg_accuracy=89.22% avg_sensitivity=77.90%, avg_specificity=92.82% avg_auc=93.02%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.160796 Test loss=0.306010 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.15408866107463837
[5/23] Train loss=0.14766031503677368
[10/23] Train loss=0.14891856908798218
[15/23] Train loss=0.15227830410003662
[20/23] Train loss=0.14707441627979279
Test set avg_accuracy=89.60% avg_sensitivity=77.79%, avg_specificity=93.36% avg_auc=92.97%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.160243 Test loss=0.300074 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.15343894064426422
[5/23] Train loss=0.1487354040145874
[10/23] Train loss=0.15216824412345886
[15/23] Train loss=0.15126989781856537
[20/23] Train loss=0.1458750069141388
Test set avg_accuracy=89.09% avg_sensitivity=78.38%, avg_specificity=92.50% avg_auc=93.10%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.160765 Test loss=0.304579 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.15396319329738617
[5/23] Train loss=0.1476077288389206
[10/23] Train loss=0.1505800038576126
[15/23] Train loss=0.1530633270740509
[20/23] Train loss=0.14404428005218506
Test set avg_accuracy=89.35% avg_sensitivity=77.84%, avg_specificity=93.01% avg_auc=93.01%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.159754 Test loss=0.300862 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.152440145611763
[5/23] Train loss=0.14913032948970795
[10/23] Train loss=0.14856496453285217
[15/23] Train loss=0.1551111936569214
[20/23] Train loss=0.14482419192790985
Test set avg_accuracy=89.30% avg_sensitivity=78.44%, avg_specificity=92.76% avg_auc=93.00%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.159099 Test loss=0.303858 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.15362924337387085
[5/23] Train loss=0.14634588360786438
[10/23] Train loss=0.14729632437229156
[15/23] Train loss=0.152445450425148
[20/23] Train loss=0.14322157204151154
Test set avg_accuracy=89.45% avg_sensitivity=78.01%, avg_specificity=93.10% avg_auc=92.98%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.159484 Test loss=0.304355 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.15687638521194458
[5/23] Train loss=0.1452348828315735
[10/23] Train loss=0.15199817717075348
[15/23] Train loss=0.14869104325771332
[20/23] Train loss=0.14232920110225677
Test set avg_accuracy=89.38% avg_sensitivity=78.22%, avg_specificity=92.93% avg_auc=93.01%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.158563 Test loss=0.303738 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.15512637794017792
[5/23] Train loss=0.14856667816638947
[10/23] Train loss=0.14689777791500092
[15/23] Train loss=0.15260258316993713
[20/23] Train loss=0.14336878061294556
Test set avg_accuracy=89.39% avg_sensitivity=78.38%, avg_specificity=92.89% avg_auc=93.01%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.158715 Test loss=0.303870 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.15195895731449127
[5/23] Train loss=0.1483037769794464
[10/23] Train loss=0.15081293880939484
[15/23] Train loss=0.15299226343631744
[20/23] Train loss=0.14887747168540955
Test set avg_accuracy=89.23% avg_sensitivity=78.22%, avg_specificity=92.74% avg_auc=93.00%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.158634 Test loss=0.302529 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.15293000638484955
[5/23] Train loss=0.14700505137443542
[10/23] Train loss=0.1497376561164856
[15/23] Train loss=0.1509990096092224
[20/23] Train loss=0.140664204955101
Test set avg_accuracy=89.15% avg_sensitivity=78.06%, avg_specificity=92.69% avg_auc=93.01%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.158512 Test loss=0.303462 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.15036968886852264
[5/23] Train loss=0.14632031321525574
[10/23] Train loss=0.14811065793037415
[15/23] Train loss=0.14919158816337585
[20/23] Train loss=0.14019882678985596
Test set avg_accuracy=89.27% avg_sensitivity=78.54%, avg_specificity=92.69% avg_auc=93.00%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.157735 Test loss=0.303744 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.15148405730724335
[5/23] Train loss=0.1467796266078949
[10/23] Train loss=0.15069763362407684
[15/23] Train loss=0.15125460922718048
[20/23] Train loss=0.14380675554275513
Test set avg_accuracy=89.17% avg_sensitivity=78.01%, avg_specificity=92.72% avg_auc=92.99%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.159409 Test loss=0.303369 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.15318280458450317
[5/23] Train loss=0.14816755056381226
[10/23] Train loss=0.15108774602413177
[15/23] Train loss=0.14885610342025757
[20/23] Train loss=0.1398555189371109
Test set avg_accuracy=89.28% avg_sensitivity=78.01%, avg_specificity=92.88% avg_auc=92.99%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.158628 Test loss=0.303313 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.15074624121189117
[5/23] Train loss=0.1476292461156845
[10/23] Train loss=0.14836744964122772
[15/23] Train loss=0.15316921472549438
[20/23] Train loss=0.14090892672538757
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=89.26% avg_sensitivity=78.38%, avg_specificity=92.72% avg_auc=92.99%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.158901 Test loss=0.303806 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=89.84% sen=81.19%, spe=92.60%, auc=94.51%!
Fold[9] Avg_overlap=0.69%(0.2380065127280506)
[0/24] Train loss=1.498773455619812
[5/24] Train loss=1.479537010192871
[10/24] Train loss=1.463078498840332
[15/24] Train loss=1.4505008459091187
[20/24] Train loss=1.4292635917663574
Test set avg_accuracy=69.14% avg_sensitivity=26.65%, avg_specificity=81.46% avg_auc=58.15%
Best model saved!! Metric=-90.59647822982184!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=1.460165 Test loss=0.659616 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.4061323404312134
[5/24] Train loss=1.3997479677200317
[10/24] Train loss=1.3921383619308472
[15/24] Train loss=1.3594516515731812
[20/24] Train loss=1.3278284072875977
Test set avg_accuracy=74.65% avg_sensitivity=56.60%, avg_specificity=79.88% avg_auc=71.25%
Best model saved!! Metric=-43.61945566782079!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=1.379316 Test loss=0.589503 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3206154108047485
[5/24] Train loss=1.3091621398925781
[10/24] Train loss=1.3209272623062134
[15/24] Train loss=1.2851102352142334
[20/24] Train loss=1.272987723350525
Test set avg_accuracy=78.45% avg_sensitivity=68.54%, avg_specificity=81.32% avg_auc=78.47%
Best model saved!! Metric=-19.21512863608281!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=1.307672 Test loss=0.544473 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.2498106956481934
[5/24] Train loss=1.2404628992080688
[10/24] Train loss=1.2440873384475708
[15/24] Train loss=1.217597484588623
[20/24] Train loss=1.199992299079895
Test set avg_accuracy=79.97% avg_sensitivity=76.83%, avg_specificity=80.89% avg_auc=81.86%
Best model saved!! Metric=-6.455965793352874!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=1.234449 Test loss=0.516663 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.1550307273864746
[5/24] Train loss=1.16000497341156
[10/24] Train loss=1.1969918012619019
[15/24] Train loss=1.146851897239685
[20/24] Train loss=1.136918067932129
Test set avg_accuracy=80.57% avg_sensitivity=80.48%, avg_specificity=80.60% avg_auc=84.58%
Best model saved!! Metric=0.23325348610624985!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=1.169217 Test loss=0.492480 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.1051174402236938
[5/24] Train loss=1.1028735637664795
[10/24] Train loss=1.1369835138320923
[15/24] Train loss=1.084830403327942
[20/24] Train loss=1.07878839969635
Test set avg_accuracy=81.48% avg_sensitivity=80.30%, avg_specificity=81.83% avg_auc=86.72%
Best model saved!! Metric=4.337692691330702!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=1.107319 Test loss=0.464900 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.029788613319397
[5/24] Train loss=1.043786644935608
[10/24] Train loss=1.0866305828094482
[15/24] Train loss=1.0144613981246948
[20/24] Train loss=1.021677851676941
Test set avg_accuracy=82.54% avg_sensitivity=81.29%, avg_specificity=82.90% avg_auc=88.50%
Best model saved!! Metric=9.223071731065048!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=1.048667 Test loss=0.440887 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9791617393493652
[5/24] Train loss=0.9996352791786194
[10/24] Train loss=1.0225450992584229
[15/24] Train loss=0.9568234086036682
[20/24] Train loss=0.9556759595870972
Test set avg_accuracy=84.34% avg_sensitivity=80.42%, avg_specificity=85.47% avg_auc=89.67%
Best model saved!! Metric=13.895419990519258!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.992458 Test loss=0.410113 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.9339049458503723
[5/24] Train loss=0.9386362433433533
[10/24] Train loss=0.9541581273078918
[15/24] Train loss=0.8987773060798645
[20/24] Train loss=0.9086207747459412
Test set avg_accuracy=85.94% avg_sensitivity=81.29%, avg_specificity=87.29% avg_auc=90.62%
Best model saved!! Metric=19.124708147749985!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.939162 Test loss=0.389342 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.9012685418128967
[5/24] Train loss=0.8943494558334351
[10/24] Train loss=0.9216658473014832
[15/24] Train loss=0.8518701195716858
[20/24] Train loss=0.8561269044876099
Test set avg_accuracy=86.50% avg_sensitivity=82.04%, avg_specificity=87.79% avg_auc=91.53%
Best model saved!! Metric=21.85731103489212!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.892731 Test loss=0.374574 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.8577601313591003
[5/24] Train loss=0.8351405262947083
[10/24] Train loss=0.8551273941993713
[15/24] Train loss=0.8219027519226074
[20/24] Train loss=0.8092973232269287
Test set avg_accuracy=87.45% avg_sensitivity=80.48%, avg_specificity=89.47% avg_auc=92.09%
Best model saved!! Metric=23.483828530157794!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.850199 Test loss=0.351448 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.8160130977630615
[5/24] Train loss=0.8086037635803223
[10/24] Train loss=0.8090567588806152
[15/24] Train loss=0.7731143236160278
[20/24] Train loss=0.7860800623893738
Test set avg_accuracy=87.66% avg_sensitivity=82.27%, avg_specificity=89.22% avg_auc=92.83%
Best model saved!! Metric=25.977216342577776!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.811003 Test loss=0.347953 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7888427376747131
[5/24] Train loss=0.7566871643066406
[10/24] Train loss=0.7768700122833252
[15/24] Train loss=0.7461920380592346
[20/24] Train loss=0.7211361527442932
Test set avg_accuracy=88.06% avg_sensitivity=83.60%, avg_specificity=89.35% avg_auc=93.42%
Best model saved!! Metric=28.43468267926025!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.777689 Test loss=0.332824 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.7481423020362854
[5/24] Train loss=0.7309229969978333
[10/24] Train loss=0.7462825179100037
[15/24] Train loss=0.7185189723968506
[20/24] Train loss=0.6990181803703308
Test set avg_accuracy=88.92% avg_sensitivity=81.69%, avg_specificity=91.01% avg_auc=93.56%
Best model saved!! Metric=29.185354453953536!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.750547 Test loss=0.314216 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.7257714867591858
[5/24] Train loss=0.7128673195838928
[10/24] Train loss=0.7338188290596008
[15/24] Train loss=0.682876467704773
[20/24] Train loss=0.6840285062789917
Test set avg_accuracy=89.21% avg_sensitivity=81.05%, avg_specificity=91.57% avg_auc=93.67%
Best model saved!! Metric=29.501603757144224!!
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.723283 Test loss=0.300451 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.706265926361084
[5/24] Train loss=0.6895080804824829
[10/24] Train loss=0.7154039740562439
[15/24] Train loss=0.6773257851600647
[20/24] Train loss=0.6514953970909119
Test set avg_accuracy=89.24% avg_sensitivity=81.98%, avg_specificity=91.35% avg_auc=94.06%
Best model saved!! Metric=30.636743326962232!!
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.705257 Test loss=0.293169 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6801673173904419
[5/24] Train loss=0.66474848985672
[10/24] Train loss=0.6969475746154785
[15/24] Train loss=0.6535816788673401
[20/24] Train loss=0.6280233860015869
Test set avg_accuracy=89.56% avg_sensitivity=83.02%, avg_specificity=91.45% avg_auc=94.28%
Best model saved!! Metric=32.30930351805263!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.686250 Test loss=0.288050 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.6625407338142395
[5/24] Train loss=0.6571271419525146
[10/24] Train loss=0.6726526021957397
[15/24] Train loss=0.6404281854629517
[20/24] Train loss=0.6265729665756226
Test set avg_accuracy=89.10% avg_sensitivity=83.31%, avg_specificity=90.78% avg_auc=94.28%
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.669711 Test loss=0.289190 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.6497963666915894
[5/24] Train loss=0.6363519430160522
[10/24] Train loss=0.657103955745697
[15/24] Train loss=0.6175375580787659
[20/24] Train loss=0.6027263402938843
Test set avg_accuracy=89.48% avg_sensitivity=82.62%, avg_specificity=91.47% avg_auc=94.37%
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.651479 Test loss=0.280970 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.6442618370056152
[5/24] Train loss=0.6224865317344666
[10/24] Train loss=0.6517161130905151
[15/24] Train loss=0.612613320350647
[20/24] Train loss=0.5926923155784607
Test set avg_accuracy=88.76% avg_sensitivity=85.57%, avg_specificity=89.69% avg_auc=94.62%
Best model saved!! Metric=32.64634026453841!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.639770 Test loss=0.292987 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.6169674396514893
[5/24] Train loss=0.6000295877456665
[10/24] Train loss=0.639244019985199
[15/24] Train loss=0.615323007106781
[20/24] Train loss=0.5842927694320679
Test set avg_accuracy=89.24% avg_sensitivity=85.05%, avg_specificity=90.46% avg_auc=94.55%
Best model saved!! Metric=33.303086216111225!!
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.625203 Test loss=0.287082 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.6301738023757935
[5/24] Train loss=0.5957833528518677
[10/24] Train loss=0.625584065914154
[15/24] Train loss=0.5841295719146729
[20/24] Train loss=0.561749279499054
Test set avg_accuracy=89.99% avg_sensitivity=82.91%, avg_specificity=92.04% avg_auc=94.69%
Best model saved!! Metric=33.625003556825135!!
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.610426 Test loss=0.270921 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.6022905707359314
[5/24] Train loss=0.5606745481491089
[10/24] Train loss=0.6166778206825256
[15/24] Train loss=0.5694617033004761
[20/24] Train loss=0.568943202495575
Test set avg_accuracy=88.11% avg_sensitivity=85.69%, avg_specificity=88.81% avg_auc=94.59%
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.600504 Test loss=0.308520 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.6044256091117859
[5/24] Train loss=0.5459831357002258
[10/24] Train loss=0.6111474633216858
[15/24] Train loss=0.5834429264068604
[20/24] Train loss=0.5542062520980835
Test set avg_accuracy=88.89% avg_sensitivity=84.53%, avg_specificity=90.16% avg_auc=94.52%
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.589115 Test loss=0.291333 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5999901294708252
[5/24] Train loss=0.533974289894104
[10/24] Train loss=0.5828385353088379
[15/24] Train loss=0.5519830584526062
[20/24] Train loss=0.5332322120666504
Test set avg_accuracy=89.67% avg_sensitivity=83.08%, avg_specificity=91.59% avg_auc=94.53%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.576991 Test loss=0.275174 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5711452960968018
[5/24] Train loss=0.5133986473083496
[10/24] Train loss=0.5636838674545288
[15/24] Train loss=0.5385445952415466
[20/24] Train loss=0.5219365358352661
Test set avg_accuracy=89.67% avg_sensitivity=82.33%, avg_specificity=91.80% avg_auc=94.37%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.559420 Test loss=0.270507 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5718087553977966
[5/24] Train loss=0.5057584643363953
[10/24] Train loss=0.5674745440483093
[15/24] Train loss=0.5387011766433716
[20/24] Train loss=0.49837252497673035
Test set avg_accuracy=89.97% avg_sensitivity=83.02%, avg_specificity=91.99% avg_auc=94.34%
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.556872 Test loss=0.266910 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.5755435824394226
[5/24] Train loss=0.48938125371932983
[10/24] Train loss=0.5673576593399048
[15/24] Train loss=0.5218456387519836
[20/24] Train loss=0.4892630875110626
Test set avg_accuracy=90.82% avg_sensitivity=79.08%, avg_specificity=94.22% avg_auc=93.88%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.544024 Test loss=0.257629 Current lr=[0.000210185142098938]

[0/24] Train loss=0.5415265560150146
[5/24] Train loss=0.49025988578796387
[10/24] Train loss=0.5410300493240356
[15/24] Train loss=0.5362105369567871
[20/24] Train loss=0.495591938495636
Test set avg_accuracy=90.12% avg_sensitivity=68.54%, avg_specificity=96.37% avg_auc=92.56%
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.537163 Test loss=0.271409 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.5569784045219421
[5/24] Train loss=0.49681907892227173
[10/24] Train loss=0.5435386896133423
[15/24] Train loss=0.5149927139282227
[20/24] Train loss=0.48170021176338196
Test set avg_accuracy=89.53% avg_sensitivity=78.85%, avg_specificity=92.63% avg_auc=94.04%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.532495 Test loss=0.259084 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.516281247138977
[5/24] Train loss=0.4636644721031189
[10/24] Train loss=0.5548822283744812
[15/24] Train loss=0.5116485953330994
[20/24] Train loss=0.47678637504577637
Test set avg_accuracy=89.44% avg_sensitivity=81.23%, avg_specificity=91.82% avg_auc=94.22%
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.519278 Test loss=0.264281 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.5239135026931763
[5/24] Train loss=0.5049773454666138
[10/24] Train loss=0.5108842849731445
[15/24] Train loss=0.5043965578079224
[20/24] Train loss=0.47514915466308594
Test set avg_accuracy=90.21% avg_sensitivity=70.39%, avg_specificity=95.95% avg_auc=93.28%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.509428 Test loss=0.257904 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.5172722339630127
[5/24] Train loss=0.4628300070762634
[10/24] Train loss=0.518048882484436
[15/24] Train loss=0.5093097686767578
[20/24] Train loss=0.4656664729118347
Test set avg_accuracy=89.66% avg_sensitivity=76.19%, avg_specificity=93.57% avg_auc=92.53%
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.507014 Test loss=0.277668 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.5294156074523926
[5/24] Train loss=0.4691997170448303
[10/24] Train loss=0.5286563634872437
[15/24] Train loss=0.4807931184768677
[20/24] Train loss=0.45969006419181824
Test set avg_accuracy=89.96% avg_sensitivity=66.80%, avg_specificity=96.67% avg_auc=92.26%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.496731 Test loss=0.274444 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.5001071095466614
[5/24] Train loss=0.4380401372909546
[10/24] Train loss=0.5060214400291443
[15/24] Train loss=0.4919885993003845
[20/24] Train loss=0.442917138338089
Test set avg_accuracy=90.55% avg_sensitivity=78.16%, avg_specificity=94.14% avg_auc=94.11%
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.480874 Test loss=0.259504 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.498086541891098
[5/24] Train loss=0.46581321954727173
[10/24] Train loss=0.4803619980812073
[15/24] Train loss=0.48919999599456787
[20/24] Train loss=0.44064390659332275
Test set avg_accuracy=90.14% avg_sensitivity=71.26%, avg_specificity=95.62% avg_auc=91.41%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.474312 Test loss=0.283178 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.505260169506073
[5/24] Train loss=0.4556174874305725
[10/24] Train loss=0.5042150020599365
[15/24] Train loss=0.46752384305000305
[20/24] Train loss=0.4367862045764923
Test set avg_accuracy=90.35% avg_sensitivity=75.67%, avg_specificity=94.61% avg_auc=92.60%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.471572 Test loss=0.274736 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.493133008480072
[5/24] Train loss=0.420444130897522
[10/24] Train loss=0.4817926287651062
[15/24] Train loss=0.48000121116638184
[20/24] Train loss=0.4283750057220459
Test set avg_accuracy=90.53% avg_sensitivity=80.94%, avg_specificity=93.32% avg_auc=93.48%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.469912 Test loss=0.273121 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.49551141262054443
[5/24] Train loss=0.4276783764362335
[10/24] Train loss=0.47130122780799866
[15/24] Train loss=0.46599113941192627
[20/24] Train loss=0.4159080684185028
Test set avg_accuracy=90.55% avg_sensitivity=80.07%, avg_specificity=93.58% avg_auc=93.72%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.462167 Test loss=0.268919 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.4615820050239563
[5/24] Train loss=0.40043842792510986
[10/24] Train loss=0.4483841061592102
[15/24] Train loss=0.46096840500831604
[20/24] Train loss=0.39834335446357727
Test set avg_accuracy=88.71% avg_sensitivity=82.68%, avg_specificity=90.46% avg_auc=93.54%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.447519 Test loss=0.288585 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4664434492588043
[5/24] Train loss=0.3938048183917999
[10/24] Train loss=0.486572802066803
[15/24] Train loss=0.4681483805179596
[20/24] Train loss=0.4101102650165558
Test set avg_accuracy=89.14% avg_sensitivity=82.97%, avg_specificity=90.93% avg_auc=93.74%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.451980 Test loss=0.284204 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.47382858395576477
[5/24] Train loss=0.37309330701828003
[10/24] Train loss=0.431098997592926
[15/24] Train loss=0.4434606730937958
[20/24] Train loss=0.41631317138671875
Test set avg_accuracy=90.01% avg_sensitivity=69.81%, avg_specificity=95.87% avg_auc=91.22%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.435694 Test loss=0.286173 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4666094183921814
[5/24] Train loss=0.35950663685798645
[10/24] Train loss=0.4343620538711548
[15/24] Train loss=0.43587812781333923
[20/24] Train loss=0.41360604763031006
Test set avg_accuracy=89.52% avg_sensitivity=73.29%, avg_specificity=94.22% avg_auc=93.01%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.431106 Test loss=0.273736 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.4399142861366272
[5/24] Train loss=0.4058709144592285
[10/24] Train loss=0.4227064847946167
[15/24] Train loss=0.45186135172843933
[20/24] Train loss=0.39569416642189026
Test set avg_accuracy=90.33% avg_sensitivity=73.17%, avg_specificity=95.30% avg_auc=92.13%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.424551 Test loss=0.271435 Current lr=[0.00029967723776099]

[0/24] Train loss=0.5040238499641418
[5/24] Train loss=0.37027469277381897
[10/24] Train loss=0.41233834624290466
[15/24] Train loss=0.4459276795387268
[20/24] Train loss=0.3736984133720398
Test set avg_accuracy=89.31% avg_sensitivity=83.14%, avg_specificity=91.10% avg_auc=93.73%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.420780 Test loss=0.289328 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.40775343775749207
[5/24] Train loss=0.36516064405441284
[10/24] Train loss=0.4296286404132843
[15/24] Train loss=0.4163477122783661
[20/24] Train loss=0.4173394739627838
Test set avg_accuracy=87.88% avg_sensitivity=83.14%, avg_specificity=89.25% avg_auc=93.71%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.421973 Test loss=0.303468 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.4441859722137451
[5/24] Train loss=0.3855796754360199
[10/24] Train loss=0.40890955924987793
[15/24] Train loss=0.42234981060028076
[20/24] Train loss=0.3718845844268799
Test set avg_accuracy=82.08% avg_sensitivity=89.80%, avg_specificity=79.85% avg_auc=93.73%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.417984 Test loss=0.454215 Current lr=[0.000299720220882401]

[0/24] Train loss=0.4273839592933655
[5/24] Train loss=0.357427716255188
[10/24] Train loss=0.40330684185028076
[15/24] Train loss=0.40963706374168396
[20/24] Train loss=0.3529989719390869
Test set avg_accuracy=86.59% avg_sensitivity=84.88%, avg_specificity=87.08% avg_auc=93.57%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.400145 Test loss=0.364442 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.4053570032119751
[5/24] Train loss=0.3554738461971283
[10/24] Train loss=0.40708211064338684
[15/24] Train loss=0.4052768349647522
[20/24] Train loss=0.36259132623672485
Test set avg_accuracy=89.38% avg_sensitivity=71.78%, avg_specificity=94.47% avg_auc=91.43%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.396599 Test loss=0.296463 Current lr=[0.000298904600941902]

[0/24] Train loss=0.4192744493484497
[5/24] Train loss=0.36656227707862854
[10/24] Train loss=0.4110668897628784
[15/24] Train loss=0.428210586309433
[20/24] Train loss=0.3478970527648926
Test set avg_accuracy=87.90% avg_sensitivity=79.32%, avg_specificity=90.39% avg_auc=92.23%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.405653 Test loss=0.301569 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.42576372623443604
[5/24] Train loss=0.32440775632858276
[10/24] Train loss=0.37177592515945435
[15/24] Train loss=0.423693984746933
[20/24] Train loss=0.37848103046417236
Test set avg_accuracy=83.91% avg_sensitivity=87.78%, avg_specificity=82.78% avg_auc=93.47%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.392358 Test loss=0.411801 Current lr=[0.000297555943323901]

[0/24] Train loss=0.4013029932975769
[5/24] Train loss=0.3668636083602905
[10/24] Train loss=0.37964993715286255
[15/24] Train loss=0.4107963442802429
[20/24] Train loss=0.3598841428756714
Test set avg_accuracy=85.94% avg_sensitivity=43.63%, avg_specificity=98.20% avg_auc=85.62%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.392676 Test loss=0.402604 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.4313499927520752
[5/24] Train loss=0.3349096477031708
[10/24] Train loss=0.3765449821949005
[15/24] Train loss=0.4179460108280182
[20/24] Train loss=0.3506060540676117
Test set avg_accuracy=88.66% avg_sensitivity=75.67%, avg_specificity=92.43% avg_auc=92.23%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.380723 Test loss=0.295012 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3679896891117096
[5/24] Train loss=0.34770330786705017
[10/24] Train loss=0.3463532626628876
[15/24] Train loss=0.40622109174728394
[20/24] Train loss=0.3485805094242096
Test set avg_accuracy=89.77% avg_sensitivity=75.43%, avg_specificity=93.92% avg_auc=92.50%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.368781 Test loss=0.282765 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.37499892711639404
[5/24] Train loss=0.3242304027080536
[10/24] Train loss=0.3625323176383972
[15/24] Train loss=0.3993782103061676
[20/24] Train loss=0.3798368573188782
Test set avg_accuracy=89.88% avg_sensitivity=74.80%, avg_specificity=94.26% avg_auc=92.52%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.376045 Test loss=0.289405 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.4213031232357025
[5/24] Train loss=0.32717421650886536
[10/24] Train loss=0.4135904014110565
[15/24] Train loss=0.40489262342453003
[20/24] Train loss=0.3563982844352722
Test set avg_accuracy=89.54% avg_sensitivity=68.08%, avg_specificity=95.77% avg_auc=90.43%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.394573 Test loss=0.320958 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.40740644931793213
[5/24] Train loss=0.34356486797332764
[10/24] Train loss=0.3445044457912445
[15/24] Train loss=0.3946872651576996
[20/24] Train loss=0.3652111291885376
Test set avg_accuracy=89.97% avg_sensitivity=75.72%, avg_specificity=94.10% avg_auc=92.69%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.373082 Test loss=0.290085 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3655185401439667
[5/24] Train loss=0.32824739813804626
[10/24] Train loss=0.35204508900642395
[15/24] Train loss=0.388601690530777
[20/24] Train loss=0.32606595754623413
Test set avg_accuracy=86.99% avg_sensitivity=81.05%, avg_specificity=88.71% avg_auc=93.28%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.362579 Test loss=0.324885 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.35992196202278137
[5/24] Train loss=0.30775994062423706
[10/24] Train loss=0.3313212990760803
[15/24] Train loss=0.384308397769928
[20/24] Train loss=0.3329508900642395
Test set avg_accuracy=83.61% avg_sensitivity=85.81%, avg_specificity=82.97% avg_auc=90.71%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.364845 Test loss=0.421671 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3528636395931244
[5/24] Train loss=0.34889909625053406
[10/24] Train loss=0.3533833920955658
[15/24] Train loss=0.3687487840652466
[20/24] Train loss=0.3295997083187103
Test set avg_accuracy=89.70% avg_sensitivity=69.64%, avg_specificity=95.52% avg_auc=91.78%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.362137 Test loss=0.281441 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3731582760810852
[5/24] Train loss=0.3207751512527466
[10/24] Train loss=0.3434179425239563
[15/24] Train loss=0.3594813644886017
[20/24] Train loss=0.3148690462112427
Test set avg_accuracy=86.61% avg_sensitivity=84.47%, avg_specificity=87.24% avg_auc=92.76%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.356515 Test loss=0.373865 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.36114731431007385
[5/24] Train loss=0.3147098124027252
[10/24] Train loss=0.36110949516296387
[15/24] Train loss=0.38318899273872375
[20/24] Train loss=0.33902788162231445
Test set avg_accuracy=89.00% avg_sensitivity=82.56%, avg_specificity=90.86% avg_auc=93.34%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.360566 Test loss=0.309862 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.34688514471054077
[5/24] Train loss=0.31414833664894104
[10/24] Train loss=0.3522462248802185
[15/24] Train loss=0.34214353561401367
[20/24] Train loss=0.31564268469810486
Test set avg_accuracy=89.97% avg_sensitivity=77.23%, avg_specificity=93.67% avg_auc=93.38%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.346851 Test loss=0.270647 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3468146324157715
[5/24] Train loss=0.2835472822189331
[10/24] Train loss=0.3304917812347412
[15/24] Train loss=0.34958794713020325
[20/24] Train loss=0.32500791549682617
Test set avg_accuracy=83.36% avg_sensitivity=86.67%, avg_specificity=82.40% avg_auc=92.65%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.346166 Test loss=0.427413 Current lr=[0.000276307469034998]

[0/24] Train loss=0.34593355655670166
[5/24] Train loss=0.317264586687088
[10/24] Train loss=0.3451935052871704
[15/24] Train loss=0.3436431288719177
[20/24] Train loss=0.29971304535865784
Test set avg_accuracy=89.17% avg_sensitivity=79.03%, avg_specificity=92.11% avg_auc=93.44%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.346111 Test loss=0.283503 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3498590588569641
[5/24] Train loss=0.29194363951683044
[10/24] Train loss=0.31395575404167175
[15/24] Train loss=0.3406210243701935
[20/24] Train loss=0.3094232976436615
Test set avg_accuracy=89.70% avg_sensitivity=71.49%, avg_specificity=94.98% avg_auc=91.06%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.331990 Test loss=0.294118 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3494797348976135
[5/24] Train loss=0.3040219843387604
[10/24] Train loss=0.35864633321762085
[15/24] Train loss=0.35879480838775635
[20/24] Train loss=0.3206997811794281
Test set avg_accuracy=89.45% avg_sensitivity=75.55%, avg_specificity=93.48% avg_auc=92.77%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.338420 Test loss=0.286733 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3502762019634247
[5/24] Train loss=0.2832714319229126
[10/24] Train loss=0.3160471022129059
[15/24] Train loss=0.3233387768268585
[20/24] Train loss=0.29685384035110474
Test set avg_accuracy=89.53% avg_sensitivity=74.57%, avg_specificity=93.87% avg_auc=91.80%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.328831 Test loss=0.298976 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3323512077331543
[5/24] Train loss=0.29296356439590454
[10/24] Train loss=0.3006645143032074
[15/24] Train loss=0.33384737372398376
[20/24] Train loss=0.27347368001937866
Test set avg_accuracy=86.64% avg_sensitivity=80.24%, avg_specificity=88.50% avg_auc=92.54%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.314137 Test loss=0.344763 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.35167187452316284
[5/24] Train loss=0.27054715156555176
[10/24] Train loss=0.2953588664531708
[15/24] Train loss=0.30834105610847473
[20/24] Train loss=0.2969115972518921
Test set avg_accuracy=89.18% avg_sensitivity=73.87%, avg_specificity=93.62% avg_auc=92.07%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.314585 Test loss=0.298413 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3267494738101959
[5/24] Train loss=0.2673906087875366
[10/24] Train loss=0.2963111996650696
[15/24] Train loss=0.30669501423835754
[20/24] Train loss=0.2965600788593292
Test set avg_accuracy=89.05% avg_sensitivity=79.43%, avg_specificity=91.84% avg_auc=92.93%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.314854 Test loss=0.300172 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3369499444961548
[5/24] Train loss=0.251132607460022
[10/24] Train loss=0.3045176565647125
[15/24] Train loss=0.3329330384731293
[20/24] Train loss=0.27079135179519653
Test set avg_accuracy=90.62% avg_sensitivity=73.12%, avg_specificity=95.70% avg_auc=92.17%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.309182 Test loss=0.277842 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3407215476036072
[5/24] Train loss=0.25349509716033936
[10/24] Train loss=0.27829304337501526
[15/24] Train loss=0.29929476976394653
[20/24] Train loss=0.27007368206977844
Test set avg_accuracy=89.95% avg_sensitivity=78.10%, avg_specificity=93.38% avg_auc=93.11%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.303652 Test loss=0.282193 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.31093159317970276
[5/24] Train loss=0.2531019151210785
[10/24] Train loss=0.2762081027030945
[15/24] Train loss=0.3063167631626129
[20/24] Train loss=0.2726844251155853
Test set avg_accuracy=89.13% avg_sensitivity=77.06%, avg_specificity=92.63% avg_auc=92.24%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.298111 Test loss=0.306181 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.32306328415870667
[5/24] Train loss=0.26106780767440796
[10/24] Train loss=0.3133580684661865
[15/24] Train loss=0.29693758487701416
[20/24] Train loss=0.28297683596611023
Test set avg_accuracy=88.27% avg_sensitivity=82.33%, avg_specificity=89.99% avg_auc=92.67%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.302190 Test loss=0.334350 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2946583032608032
[5/24] Train loss=0.2614802122116089
[10/24] Train loss=0.3146899342536926
[15/24] Train loss=0.35991165041923523
[20/24] Train loss=0.28110453486442566
Test set avg_accuracy=88.61% avg_sensitivity=78.97%, avg_specificity=91.40% avg_auc=91.54%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.305376 Test loss=0.328725 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3034239113330841
[5/24] Train loss=0.254372775554657
[10/24] Train loss=0.27145832777023315
[15/24] Train loss=0.3136146068572998
[20/24] Train loss=0.27687719464302063
Test set avg_accuracy=89.99% avg_sensitivity=74.97%, avg_specificity=94.34% avg_auc=92.97%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.294340 Test loss=0.276661 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.29215842485427856
[5/24] Train loss=0.25870704650878906
[10/24] Train loss=0.278126984834671
[15/24] Train loss=0.27624353766441345
[20/24] Train loss=0.2632450461387634
Test set avg_accuracy=89.35% avg_sensitivity=81.69%, avg_specificity=91.57% avg_auc=93.47%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.282837 Test loss=0.307673 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2892790138721466
[5/24] Train loss=0.2704201340675354
[10/24] Train loss=0.2511998414993286
[15/24] Train loss=0.2855948209762573
[20/24] Train loss=0.26526713371276855
Test set avg_accuracy=89.09% avg_sensitivity=78.68%, avg_specificity=92.11% avg_auc=93.48%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.284157 Test loss=0.291362 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3116985857486725
[5/24] Train loss=0.24728506803512573
[10/24] Train loss=0.25804266333580017
[15/24] Train loss=0.296714723110199
[20/24] Train loss=0.24988970160484314
Test set avg_accuracy=89.96% avg_sensitivity=67.61%, avg_specificity=96.44% avg_auc=89.78%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.276165 Test loss=0.312487 Current lr=[0.000224838296036774]

[0/24] Train loss=0.28543004393577576
[5/24] Train loss=0.2431192845106125
[10/24] Train loss=0.25611039996147156
[15/24] Train loss=0.266752690076828
[20/24] Train loss=0.2629721164703369
Test set avg_accuracy=88.71% avg_sensitivity=80.59%, avg_specificity=91.06% avg_auc=93.22%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.273841 Test loss=0.307499 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2655322551727295
[5/24] Train loss=0.23626792430877686
[10/24] Train loss=0.24085447192192078
[15/24] Train loss=0.27787452936172485
[20/24] Train loss=0.25871989130973816
Test set avg_accuracy=90.21% avg_sensitivity=71.26%, avg_specificity=95.70% avg_auc=92.06%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.268834 Test loss=0.282031 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.28333139419555664
[5/24] Train loss=0.2561904489994049
[10/24] Train loss=0.2600005269050598
[15/24] Train loss=0.28628039360046387
[20/24] Train loss=0.23414625227451324
Test set avg_accuracy=89.82% avg_sensitivity=75.96%, avg_specificity=93.84% avg_auc=92.92%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.268583 Test loss=0.286658 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.27185264229774475
[5/24] Train loss=0.2429848164319992
[10/24] Train loss=0.24774080514907837
[15/24] Train loss=0.27235883474349976
[20/24] Train loss=0.2327061891555786
Test set avg_accuracy=89.61% avg_sensitivity=74.68%, avg_specificity=93.94% avg_auc=92.67%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.265783 Test loss=0.292770 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.28017765283584595
[5/24] Train loss=0.23770911991596222
[10/24] Train loss=0.23531009256839752
[15/24] Train loss=0.2662734091281891
[20/24] Train loss=0.24993906915187836
Test set avg_accuracy=89.53% avg_sensitivity=72.60%, avg_specificity=94.44% avg_auc=92.34%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.268593 Test loss=0.292184 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.28244706988334656
[5/24] Train loss=0.2504323422908783
[10/24] Train loss=0.25474947690963745
[15/24] Train loss=0.2764536440372467
[20/24] Train loss=0.25937753915786743
Test set avg_accuracy=89.21% avg_sensitivity=79.55%, avg_specificity=92.01% avg_auc=93.37%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.270646 Test loss=0.301897 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2837924659252167
[5/24] Train loss=0.23835216462612152
[10/24] Train loss=0.24852889776229858
[15/24] Train loss=0.273297518491745
[20/24] Train loss=0.27883976697921753
Test set avg_accuracy=88.07% avg_sensitivity=82.21%, avg_specificity=89.77% avg_auc=93.11%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.270421 Test loss=0.352023 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2806764841079712
[5/24] Train loss=0.23232661187648773
[10/24] Train loss=0.23923398554325104
[15/24] Train loss=0.2672928273677826
[20/24] Train loss=0.24626214802265167
Test set avg_accuracy=90.29% avg_sensitivity=78.68%, avg_specificity=93.65% avg_auc=93.30%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.261698 Test loss=0.288326 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.27375903725624084
[5/24] Train loss=0.2268088459968567
[10/24] Train loss=0.2619200646877289
[15/24] Train loss=0.280328631401062
[20/24] Train loss=0.2573188841342926
Test set avg_accuracy=89.54% avg_sensitivity=65.01%, avg_specificity=96.66% avg_auc=91.67%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.263178 Test loss=0.298796 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.26416343450546265
[5/24] Train loss=0.24419435858726501
[10/24] Train loss=0.22410091757774353
[15/24] Train loss=0.2546745538711548
[20/24] Train loss=0.23643891513347626
Test set avg_accuracy=90.29% avg_sensitivity=78.85%, avg_specificity=93.60% avg_auc=93.23%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.252948 Test loss=0.299646 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2510320246219635
[5/24] Train loss=0.23255431652069092
[10/24] Train loss=0.23269851505756378
[15/24] Train loss=0.2620956301689148
[20/24] Train loss=0.24067716300487518
Test set avg_accuracy=88.44% avg_sensitivity=82.27%, avg_specificity=90.23% avg_auc=93.26%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.251971 Test loss=0.330423 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2651263177394867
[5/24] Train loss=0.22798338532447815
[10/24] Train loss=0.2452821582555771
[15/24] Train loss=0.25289851427078247
[20/24] Train loss=0.24763068556785583
Test set avg_accuracy=89.49% avg_sensitivity=82.85%, avg_specificity=91.42% avg_auc=93.80%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.255488 Test loss=0.307142 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2523598372936249
[5/24] Train loss=0.2506685256958008
[10/24] Train loss=0.2400207668542862
[15/24] Train loss=0.29330986738204956
[20/24] Train loss=0.22849512100219727
Test set avg_accuracy=89.43% avg_sensitivity=75.61%, avg_specificity=93.43% avg_auc=93.01%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.256492 Test loss=0.298901 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2651166319847107
[5/24] Train loss=0.23033824563026428
[10/24] Train loss=0.24157929420471191
[15/24] Train loss=0.27576905488967896
[20/24] Train loss=0.2338128536939621
Test set avg_accuracy=90.44% avg_sensitivity=79.03%, avg_specificity=93.75% avg_auc=93.65%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.254030 Test loss=0.280464 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.24909307062625885
[5/24] Train loss=0.23350730538368225
[10/24] Train loss=0.22758905589580536
[15/24] Train loss=0.24810709059238434
[20/24] Train loss=0.2345944494009018
Test set avg_accuracy=86.32% avg_sensitivity=85.57%, avg_specificity=86.53% avg_auc=93.36%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.247659 Test loss=0.404105 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2579140365123749
[5/24] Train loss=0.24319739639759064
[10/24] Train loss=0.22269202768802643
[15/24] Train loss=0.26668787002563477
[20/24] Train loss=0.23317107558250427
Test set avg_accuracy=89.97% avg_sensitivity=74.97%, avg_specificity=94.32% avg_auc=93.37%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.250590 Test loss=0.282642 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2526349425315857
[5/24] Train loss=0.2217293530702591
[10/24] Train loss=0.217062845826149
[15/24] Train loss=0.24166160821914673
[20/24] Train loss=0.23332157731056213
Test set avg_accuracy=87.85% avg_sensitivity=82.33%, avg_specificity=89.45% avg_auc=93.36%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.241565 Test loss=0.337886 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.26241499185562134
[5/24] Train loss=0.22216303646564484
[10/24] Train loss=0.22683237493038177
[15/24] Train loss=0.2498902678489685
[20/24] Train loss=0.2587689757347107
Test set avg_accuracy=88.57% avg_sensitivity=78.62%, avg_specificity=91.45% avg_auc=93.50%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.241854 Test loss=0.306441 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.24403376877307892
[5/24] Train loss=0.22933265566825867
[10/24] Train loss=0.22748073935508728
[15/24] Train loss=0.2582851052284241
[20/24] Train loss=0.25144386291503906
Test set avg_accuracy=89.79% avg_sensitivity=82.04%, avg_specificity=92.04% avg_auc=94.34%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.247819 Test loss=0.282821 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.23891893029212952
[5/24] Train loss=0.2432825118303299
[10/24] Train loss=0.22590956091880798
[15/24] Train loss=0.249337300658226
[20/24] Train loss=0.24525070190429688
Test set avg_accuracy=90.17% avg_sensitivity=77.52%, avg_specificity=93.84% avg_auc=93.12%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.242435 Test loss=0.283019 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.24035795032978058
[5/24] Train loss=0.2170809805393219
[10/24] Train loss=0.23818421363830566
[15/24] Train loss=0.2514084279537201
[20/24] Train loss=0.22462782263755798
Test set avg_accuracy=90.12% avg_sensitivity=79.49%, avg_specificity=93.20% avg_auc=93.73%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.233953 Test loss=0.291255 Current lr=[0.000134135431043539]

[0/24] Train loss=0.22864840924739838
[5/24] Train loss=0.2237955778837204
[10/24] Train loss=0.20751585066318512
[15/24] Train loss=0.2509639859199524
[20/24] Train loss=0.21868138015270233
Test set avg_accuracy=90.39% avg_sensitivity=72.83%, avg_specificity=95.48% avg_auc=93.07%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.231850 Test loss=0.281360 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.242351233959198
[5/24] Train loss=0.2167387157678604
[10/24] Train loss=0.209688201546669
[15/24] Train loss=0.23762962222099304
[20/24] Train loss=0.21318592131137848
Test set avg_accuracy=90.36% avg_sensitivity=78.27%, avg_specificity=93.87% avg_auc=93.45%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.226631 Test loss=0.286757 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.22918297350406647
[5/24] Train loss=0.21050851047039032
[10/24] Train loss=0.2012336552143097
[15/24] Train loss=0.22524604201316833
[20/24] Train loss=0.21588043868541718
Test set avg_accuracy=90.23% avg_sensitivity=76.36%, avg_specificity=94.26% avg_auc=93.25%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.222367 Test loss=0.277458 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.22059133648872375
[5/24] Train loss=0.20150166749954224
[10/24] Train loss=0.2130196988582611
[15/24] Train loss=0.21040701866149902
[20/24] Train loss=0.2015436887741089
Test set avg_accuracy=89.96% avg_sensitivity=81.17%, avg_specificity=92.51% avg_auc=93.52%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.220293 Test loss=0.297224 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.22507725656032562
[5/24] Train loss=0.21853549778461456
[10/24] Train loss=0.202157124876976
[15/24] Train loss=0.21867069602012634
[20/24] Train loss=0.20459601283073425
Test set avg_accuracy=90.31% avg_sensitivity=69.99%, avg_specificity=96.20% avg_auc=91.70%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.219869 Test loss=0.294702 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.2313208132982254
[5/24] Train loss=0.19740402698516846
[10/24] Train loss=0.20833125710487366
[15/24] Train loss=0.2189018428325653
[20/24] Train loss=0.2102707028388977
Test set avg_accuracy=89.53% avg_sensitivity=79.37%, avg_specificity=92.48% avg_auc=93.62%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.213172 Test loss=0.299073 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.2160886526107788
[5/24] Train loss=0.20414648950099945
[10/24] Train loss=0.19316916167736053
[15/24] Train loss=0.20399712026119232
[20/24] Train loss=0.2085620015859604
Test set avg_accuracy=89.87% avg_sensitivity=69.58%, avg_specificity=95.75% avg_auc=91.90%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.209322 Test loss=0.296884 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.2231936752796173
[5/24] Train loss=0.19888462126255035
[10/24] Train loss=0.19891564548015594
[15/24] Train loss=0.2192453145980835
[20/24] Train loss=0.1987852156162262
Test set avg_accuracy=89.88% avg_sensitivity=70.10%, avg_specificity=95.62% avg_auc=92.69%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.208070 Test loss=0.284735 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.21084918081760406
[5/24] Train loss=0.18986496329307556
[10/24] Train loss=0.18886080384254456
[15/24] Train loss=0.20767906308174133
[20/24] Train loss=0.2003045231103897
Test set avg_accuracy=89.67% avg_sensitivity=68.48%, avg_specificity=95.82% avg_auc=91.71%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.207945 Test loss=0.296966 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.213182270526886
[5/24] Train loss=0.18749533593654633
[10/24] Train loss=0.1879015564918518
[15/24] Train loss=0.21042370796203613
[20/24] Train loss=0.2032342106103897
Test set avg_accuracy=89.01% avg_sensitivity=59.85%, avg_specificity=97.46% avg_auc=89.26%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.208440 Test loss=0.327631 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.21222034096717834
[5/24] Train loss=0.19306311011314392
[10/24] Train loss=0.1828662008047104
[15/24] Train loss=0.2071075439453125
[20/24] Train loss=0.18564212322235107
Test set avg_accuracy=90.17% avg_sensitivity=69.64%, avg_specificity=96.12% avg_auc=92.32%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.204467 Test loss=0.288579 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.20137213170528412
[5/24] Train loss=0.19001883268356323
[10/24] Train loss=0.17877376079559326
[15/24] Train loss=0.2073102444410324
[20/24] Train loss=0.19602595269680023
Test set avg_accuracy=90.30% avg_sensitivity=76.48%, avg_specificity=94.31% avg_auc=93.07%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.199912 Test loss=0.286991 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.19772568345069885
[5/24] Train loss=0.19387243688106537
[10/24] Train loss=0.17792926728725433
[15/24] Train loss=0.200002983212471
[20/24] Train loss=0.19828318059444427
Test set avg_accuracy=90.20% avg_sensitivity=78.51%, avg_specificity=93.58% avg_auc=93.80%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.197699 Test loss=0.289024 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1974683403968811
[5/24] Train loss=0.17749468982219696
[10/24] Train loss=0.1793259084224701
[15/24] Train loss=0.20012010633945465
[20/24] Train loss=0.19162188470363617
Test set avg_accuracy=90.17% avg_sensitivity=79.78%, avg_specificity=93.18% avg_auc=93.68%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.194704 Test loss=0.296055 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.19795680046081543
[5/24] Train loss=0.18056386709213257
[10/24] Train loss=0.1753416806459427
[15/24] Train loss=0.1922992765903473
[20/24] Train loss=0.1981792449951172
Test set avg_accuracy=90.43% avg_sensitivity=78.51%, avg_specificity=93.89% avg_auc=93.31%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.192803 Test loss=0.289089 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.18532449007034302
[5/24] Train loss=0.1840202808380127
[10/24] Train loss=0.17414414882659912
[15/24] Train loss=0.18915532529354095
[20/24] Train loss=0.18999196588993073
Test set avg_accuracy=90.21% avg_sensitivity=74.10%, avg_specificity=94.88% avg_auc=92.93%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.188379 Test loss=0.284082 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.18889902532100677
[5/24] Train loss=0.17589029669761658
[10/24] Train loss=0.16992691159248352
[15/24] Train loss=0.18570023775100708
[20/24] Train loss=0.18041469156742096
Test set avg_accuracy=90.27% avg_sensitivity=77.23%, avg_specificity=94.05% avg_auc=92.85%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.185828 Test loss=0.292970 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.18796305358409882
[5/24] Train loss=0.17285221815109253
[10/24] Train loss=0.16901811957359314
[15/24] Train loss=0.18624967336654663
[20/24] Train loss=0.18130812048912048
Test set avg_accuracy=90.38% avg_sensitivity=75.61%, avg_specificity=94.66% avg_auc=93.10%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.182834 Test loss=0.282670 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1920972615480423
[5/24] Train loss=0.17560964822769165
[10/24] Train loss=0.1658799648284912
[15/24] Train loss=0.18062646687030792
[20/24] Train loss=0.1771913319826126
Test set avg_accuracy=90.07% avg_sensitivity=79.55%, avg_specificity=93.11% avg_auc=93.59%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.182875 Test loss=0.298622 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1836443692445755
[5/24] Train loss=0.1735941618680954
[10/24] Train loss=0.16759884357452393
[15/24] Train loss=0.181998610496521
[20/24] Train loss=0.18396267294883728
Test set avg_accuracy=90.23% avg_sensitivity=77.11%, avg_specificity=94.04% avg_auc=92.97%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.183170 Test loss=0.293527 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.18650847673416138
[5/24] Train loss=0.1765844225883484
[10/24] Train loss=0.16084563732147217
[15/24] Train loss=0.1858721822500229
[20/24] Train loss=0.17748335003852844
Test set avg_accuracy=90.03% avg_sensitivity=76.25%, avg_specificity=94.02% avg_auc=92.96%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.181547 Test loss=0.294024 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.18314139544963837
[5/24] Train loss=0.17372135818004608
[10/24] Train loss=0.1559796780347824
[15/24] Train loss=0.1753239780664444
[20/24] Train loss=0.17447508871555328
Test set avg_accuracy=90.12% avg_sensitivity=78.85%, avg_specificity=93.38% avg_auc=92.94%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.180523 Test loss=0.296068 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.17810262739658356
[5/24] Train loss=0.18497076630592346
[10/24] Train loss=0.1625090092420578
[15/24] Train loss=0.18749912083148956
[20/24] Train loss=0.18131929636001587
Test set avg_accuracy=90.46% avg_sensitivity=75.72%, avg_specificity=94.73% avg_auc=92.19%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.184901 Test loss=0.291763 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1802876740694046
[5/24] Train loss=0.18258239328861237
[10/24] Train loss=0.1649501919746399
[15/24] Train loss=0.18285644054412842
[20/24] Train loss=0.18771059811115265
Test set avg_accuracy=89.78% avg_sensitivity=78.04%, avg_specificity=93.18% avg_auc=93.06%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.186258 Test loss=0.301271 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.18492631614208221
[5/24] Train loss=0.17501574754714966
[10/24] Train loss=0.1834828108549118
[15/24] Train loss=0.17270073294639587
[20/24] Train loss=0.18698324263095856
Test set avg_accuracy=89.92% avg_sensitivity=73.41%, avg_specificity=94.71% avg_auc=92.41%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.187140 Test loss=0.291987 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.19174960255622864
[5/24] Train loss=0.16993844509124756
[10/24] Train loss=0.17869584262371063
[15/24] Train loss=0.17703372240066528
[20/24] Train loss=0.17766675353050232
Test set avg_accuracy=89.48% avg_sensitivity=77.40%, avg_specificity=92.98% avg_auc=93.49%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.185773 Test loss=0.286005 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1918303519487381
[5/24] Train loss=0.16889254748821259
[10/24] Train loss=0.16626909375190735
[15/24] Train loss=0.18505644798278809
[20/24] Train loss=0.17606939375400543
Test set avg_accuracy=89.91% avg_sensitivity=78.04%, avg_specificity=93.35% avg_auc=93.56%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.180926 Test loss=0.286997 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.17645001411437988
[5/24] Train loss=0.168080136179924
[10/24] Train loss=0.1547020822763443
[15/24] Train loss=0.18176905810832977
[20/24] Train loss=0.17491155862808228
Test set avg_accuracy=89.92% avg_sensitivity=77.06%, avg_specificity=93.65% avg_auc=93.53%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.176492 Test loss=0.286595 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.17103959619998932
[5/24] Train loss=0.16791006922721863
[10/24] Train loss=0.15878282487392426
[15/24] Train loss=0.17252227663993835
[20/24] Train loss=0.16780318319797516
Test set avg_accuracy=89.97% avg_sensitivity=73.64%, avg_specificity=94.71% avg_auc=92.77%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.173030 Test loss=0.282752 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.17413929104804993
[5/24] Train loss=0.16939537227153778
[10/24] Train loss=0.15365824103355408
[15/24] Train loss=0.17047885060310364
[20/24] Train loss=0.16721074283123016
Test set avg_accuracy=90.07% avg_sensitivity=75.72%, avg_specificity=94.22% avg_auc=93.37%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.171622 Test loss=0.279716 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.17371214926242828
[5/24] Train loss=0.16781474649906158
[10/24] Train loss=0.15366511046886444
[15/24] Train loss=0.1650230586528778
[20/24] Train loss=0.16852302849292755
Test set avg_accuracy=90.01% avg_sensitivity=75.14%, avg_specificity=94.32% avg_auc=93.13%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.171543 Test loss=0.284167 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1745511144399643
[5/24] Train loss=0.16358116269111633
[10/24] Train loss=0.14981910586357117
[15/24] Train loss=0.165265753865242
[20/24] Train loss=0.16667114198207855
Test set avg_accuracy=89.87% avg_sensitivity=75.09%, avg_specificity=94.16% avg_auc=93.13%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.170568 Test loss=0.282521 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.17632164061069489
[5/24] Train loss=0.1615600883960724
[10/24] Train loss=0.1531895399093628
[15/24] Train loss=0.16652920842170715
[20/24] Train loss=0.1644785851240158
Test set avg_accuracy=89.91% avg_sensitivity=74.22%, avg_specificity=94.46% avg_auc=93.10%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.168599 Test loss=0.283930 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1722419261932373
[5/24] Train loss=0.16317963600158691
[10/24] Train loss=0.15299519896507263
[15/24] Train loss=0.16588091850280762
[20/24] Train loss=0.16963523626327515
Test set avg_accuracy=90.07% avg_sensitivity=75.72%, avg_specificity=94.22% avg_auc=93.12%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.169034 Test loss=0.283608 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1723816692829132
[5/24] Train loss=0.16341137886047363
[10/24] Train loss=0.1522616147994995
[15/24] Train loss=0.1670607328414917
[20/24] Train loss=0.16349107027053833
Test set avg_accuracy=89.91% avg_sensitivity=74.62%, avg_specificity=94.34% avg_auc=93.16%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.168214 Test loss=0.280928 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.17050088942050934
[5/24] Train loss=0.16181987524032593
[10/24] Train loss=0.15178123116493225
[15/24] Train loss=0.16402098536491394
[20/24] Train loss=0.167644664645195
Test set avg_accuracy=89.86% avg_sensitivity=75.26%, avg_specificity=94.09% avg_auc=93.12%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.168269 Test loss=0.283506 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.17092807590961456
[5/24] Train loss=0.16348674893379211
[10/24] Train loss=0.15002673864364624
[15/24] Train loss=0.16380508244037628
[20/24] Train loss=0.1686754822731018
Test set avg_accuracy=89.97% avg_sensitivity=74.74%, avg_specificity=94.39% avg_auc=92.92%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.167677 Test loss=0.283461 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1712353527545929
[5/24] Train loss=0.16237704455852509
[10/24] Train loss=0.14852416515350342
[15/24] Train loss=0.16380631923675537
[20/24] Train loss=0.16274824738502502
Test set avg_accuracy=89.96% avg_sensitivity=75.55%, avg_specificity=94.14% avg_auc=93.15%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.167754 Test loss=0.283278 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.16841615736484528
[5/24] Train loss=0.1611320525407791
[10/24] Train loss=0.14793728291988373
[15/24] Train loss=0.16090737283229828
[20/24] Train loss=0.16648422181606293
Test set avg_accuracy=90.00% avg_sensitivity=75.90%, avg_specificity=94.09% avg_auc=93.26%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.166963 Test loss=0.282333 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.17085355520248413
[5/24] Train loss=0.15770645439624786
[10/24] Train loss=0.14915531873703003
[15/24] Train loss=0.16555637121200562
[20/24] Train loss=0.1675601750612259
Test set avg_accuracy=90.01% avg_sensitivity=75.38%, avg_specificity=94.26% avg_auc=93.18%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.166390 Test loss=0.281353 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.17320126295089722
[5/24] Train loss=0.15959502756595612
[10/24] Train loss=0.153882697224617
[15/24] Train loss=0.1637234091758728
[20/24] Train loss=0.16243277490139008
Test set avg_accuracy=90.10% avg_sensitivity=75.61%, avg_specificity=94.31% avg_auc=93.27%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.166495 Test loss=0.281214 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1670791357755661
[5/24] Train loss=0.15755490958690643
[10/24] Train loss=0.14855550229549408
[15/24] Train loss=0.16322028636932373
[20/24] Train loss=0.1650552898645401
Test set avg_accuracy=90.03% avg_sensitivity=75.32%, avg_specificity=94.29% avg_auc=93.17%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.165981 Test loss=0.282590 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1674817055463791
[5/24] Train loss=0.16063538193702698
[10/24] Train loss=0.15004862844944
[15/24] Train loss=0.16132469475269318
[20/24] Train loss=0.16206830739974976
Test set avg_accuracy=90.04% avg_sensitivity=75.38%, avg_specificity=94.29% avg_auc=93.19%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.165914 Test loss=0.282093 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.16880522668361664
[5/24] Train loss=0.16020183265209198
[10/24] Train loss=0.14812931418418884
[15/24] Train loss=0.16128553450107574
[20/24] Train loss=0.16249138116836548
Test set avg_accuracy=90.00% avg_sensitivity=75.38%, avg_specificity=94.24% avg_auc=93.23%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.166079 Test loss=0.281604 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1665439009666443
[5/24] Train loss=0.16019408404827118
[10/24] Train loss=0.15138743817806244
[15/24] Train loss=0.16525684297084808
[20/24] Train loss=0.1636432409286499
Test set avg_accuracy=90.03% avg_sensitivity=75.49%, avg_specificity=94.24% avg_auc=93.21%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.166264 Test loss=0.281868 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1705905944108963
[5/24] Train loss=0.1588934361934662
[10/24] Train loss=0.14955683052539825
[15/24] Train loss=0.16508617997169495
[20/24] Train loss=0.16497917473316193
Test set avg_accuracy=90.04% avg_sensitivity=75.49%, avg_specificity=94.26% avg_auc=93.17%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.165963 Test loss=0.282046 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1674143224954605
[5/24] Train loss=0.15809190273284912
[10/24] Train loss=0.15181545913219452
[15/24] Train loss=0.16083528101444244
[20/24] Train loss=0.16019360721111298
Test set avg_accuracy=90.04% avg_sensitivity=75.49%, avg_specificity=94.26% avg_auc=93.18%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.165558 Test loss=0.281871 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1691572219133377
[5/24] Train loss=0.15769259631633759
[10/24] Train loss=0.15113523602485657
[15/24] Train loss=0.16092722117900848
[20/24] Train loss=0.16143977642059326
Test set avg_accuracy=89.99% avg_sensitivity=75.38%, avg_specificity=94.22% avg_auc=93.18%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.165919 Test loss=0.281713 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.17097687721252441
[5/24] Train loss=0.15888096392154694
[10/24] Train loss=0.1514255851507187
[15/24] Train loss=0.16204412281513214
[20/24] Train loss=0.1633298695087433
Test set avg_accuracy=90.03% avg_sensitivity=75.49%, avg_specificity=94.24% avg_auc=93.18%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.165972 Test loss=0.281729 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=89.99% sen=82.91%, spe=92.04%, auc=94.69%!
Fold[10] Avg_overlap=0.68%(0.22728113290116445)
Final Avg Result: avg_acc=88.82%(0.8403129745412087) avg_sen=83.94% (2.3070494087874263) avg_spe=90.50% (1.3535043417321038) avg_auc=94.02% (0.9114645093603227) avg_overlap=0.68% (0.023997523966400883)
