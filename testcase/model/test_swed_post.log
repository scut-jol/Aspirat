{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 1,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'SwEDModel',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.7057393193244934
[5/24] Train loss=0.7041506171226501
[10/24] Train loss=0.7027460932731628
[15/24] Train loss=0.7015008926391602
[20/24] Train loss=0.7001416683197021
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.62%
Best model saved!! Metric=-102.69265604092143!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.702756 Test loss=0.699688 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6990993022918701
[5/24] Train loss=0.6981713175773621
[10/24] Train loss=0.697309136390686
[15/24] Train loss=0.69666588306427
[20/24] Train loss=0.6955376267433167
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.01%
Best model saved!! Metric=-102.30959565159533!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.697410 Test loss=0.695387 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6945545077323914
[5/24] Train loss=0.6935766935348511
[10/24] Train loss=0.6928761601448059
[15/24] Train loss=0.6927659511566162
[20/24] Train loss=0.6915407180786133
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.93%
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.693103 Test loss=0.691537 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6905001401901245
[5/24] Train loss=0.6893383264541626
[10/24] Train loss=0.6893846392631531
[15/24] Train loss=0.6894568204879761
[20/24] Train loss=0.6885779500007629
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.98%
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.689570 Test loss=0.688593 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6876260638237
[5/24] Train loss=0.6862736344337463
[10/24] Train loss=0.6865572333335876
[15/24] Train loss=0.6868548393249512
[20/24] Train loss=0.6858309507369995
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.02%
Best model saved!! Metric=-102.29084484116598!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.686761 Test loss=0.686008 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.684766948223114
[5/24] Train loss=0.683273196220398
[10/24] Train loss=0.683395266532898
[15/24] Train loss=0.6839569211006165
[20/24] Train loss=0.682455837726593
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.08%
Best model saved!! Metric=-102.23676958488232!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.683641 Test loss=0.682523 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6810247302055359
[5/24] Train loss=0.6789907217025757
[10/24] Train loss=0.6788419485092163
[15/24] Train loss=0.6797145009040833
[20/24] Train loss=0.6776185631752014
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.16%
Best model saved!! Metric=-102.15390577959485!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.679153 Test loss=0.677604 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6758219599723816
[5/24] Train loss=0.6731046438217163
[10/24] Train loss=0.6729044914245605
[15/24] Train loss=0.6739504933357239
[20/24] Train loss=0.6712788343429565
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.12%
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.673125 Test loss=0.671002 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.668814480304718
[5/24] Train loss=0.6652754545211792
[10/24] Train loss=0.6648437976837158
[15/24] Train loss=0.6660056710243225
[20/24] Train loss=0.662336528301239
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.27%
Best model saved!! Metric=-102.04685259820444!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.664885 Test loss=0.661779 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6589736938476562
[5/24] Train loss=0.6540591716766357
[10/24] Train loss=0.6530719995498657
[15/24] Train loss=0.6550106406211853
[20/24] Train loss=0.6497042775154114
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.52%
Best model saved!! Metric=-101.79099956049009!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.653179 Test loss=0.648645 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6446834206581116
[5/24] Train loss=0.6378551125526428
[10/24] Train loss=0.6363731622695923
[15/24] Train loss=0.6392232775688171
[20/24] Train loss=0.6319541335105896
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.90%
Best model saved!! Metric=-101.41387612629643!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.636402 Test loss=0.630212 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6244875192642212
[5/24] Train loss=0.614859938621521
[10/24] Train loss=0.6138094663619995
[15/24] Train loss=0.6186360120773315
[20/24] Train loss=0.6096735596656799
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.33%
Best model saved!! Metric=-100.98370481759827!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.614008 Test loss=0.607947 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5995957255363464
[5/24] Train loss=0.5876560807228088
[10/24] Train loss=0.590069591999054
[15/24] Train loss=0.5975285172462463
[20/24] Train loss=0.58978670835495
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.20%
Best model saved!! Metric=-100.1179323782031!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.590485 Test loss=0.588760 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5774035453796387
[5/24] Train loss=0.5641217827796936
[10/24] Train loss=0.5726253390312195
[15/24] Train loss=0.5829105973243713
[20/24] Train loss=0.5769365429878235
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=53.52%
Best model saved!! Metric=-98.79851623533355!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.573080 Test loss=0.577870 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.564799427986145
[5/24] Train loss=0.551374077796936
[10/24] Train loss=0.565364420413971
[15/24] Train loss=0.5776686072349548
[20/24] Train loss=0.5695677995681763
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=57.66%
Best model saved!! Metric=-94.65748565861563!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.564389 Test loss=0.572693 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.558673620223999
[5/24] Train loss=0.5462959408760071
[10/24] Train loss=0.5620368123054504
[15/24] Train loss=0.5735124349594116
[20/24] Train loss=0.5638214349746704
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=62.58%
Best model saved!! Metric=-89.73346338288017!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.559232 Test loss=0.568871 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5534838438034058
[5/24] Train loss=0.5398051738739014
[10/24] Train loss=0.5586484670639038
[15/24] Train loss=0.5708904266357422
[20/24] Train loss=0.5549620389938354
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=67.58%
Best model saved!! Metric=-84.7368467478117!!
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.553665 Test loss=0.563823 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5484412312507629
[5/24] Train loss=0.5360113978385925
[10/24] Train loss=0.5533412098884583
[15/24] Train loss=0.5626397728919983
[20/24] Train loss=0.5373679399490356
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=72.07%
Best model saved!! Metric=-80.24060438573943!!
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.544139 Test loss=0.560221 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5358646512031555
[5/24] Train loss=0.5239435434341431
[10/24] Train loss=0.5406957268714905
[15/24] Train loss=0.5490720868110657
[20/24] Train loss=0.5149633884429932
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=74.60%
Best model saved!! Metric=-77.7156934378805!!
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.529055 Test loss=0.607858 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5179703831672668
[5/24] Train loss=0.5076195597648621
[10/24] Train loss=0.5179364681243896
[15/24] Train loss=0.5319337844848633
[20/24] Train loss=0.4924065172672272
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=68.55%
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.511155 Test loss=0.666664 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.4986949563026428
[5/24] Train loss=0.49640652537345886
[10/24] Train loss=0.5003580451011658
[15/24] Train loss=0.5160378813743591
[20/24] Train loss=0.47879666090011597
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=63.09%
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.495376 Test loss=0.659802 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.47742757201194763
[5/24] Train loss=0.4830910563468933
[10/24] Train loss=0.4889172613620758
[15/24] Train loss=0.5142699480056763
[20/24] Train loss=0.4713650047779083
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=66.31%
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.485591 Test loss=0.649142 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.47542786598205566
[5/24] Train loss=0.4841172695159912
[10/24] Train loss=0.49360671639442444
[15/24] Train loss=0.5082892179489136
[20/24] Train loss=0.4648457169532776
Test set avg_accuracy=71.72% avg_sensitivity=5.24%, avg_specificity=95.46% avg_auc=68.22%
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.483510 Test loss=0.634608 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.46255558729171753
[5/24] Train loss=0.47677576541900635
[10/24] Train loss=0.4773232042789459
[15/24] Train loss=0.5054572224617004
[20/24] Train loss=0.4596658945083618
Test set avg_accuracy=45.64% avg_sensitivity=77.34%, avg_specificity=34.32% avg_auc=66.09%
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.476372 Test loss=0.654251 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.45725882053375244
[5/24] Train loss=0.48105108737945557
[10/24] Train loss=0.4703470468521118
[15/24] Train loss=0.49335184693336487
[20/24] Train loss=0.4521922767162323
Test set avg_accuracy=44.32% avg_sensitivity=86.59%, avg_specificity=29.23% avg_auc=67.62%
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.468415 Test loss=0.651507 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.4643484950065613
[5/24] Train loss=0.4629155099391937
[10/24] Train loss=0.45865240693092346
[15/24] Train loss=0.48337504267692566
[20/24] Train loss=0.4306841194629669
Test set avg_accuracy=59.31% avg_sensitivity=83.28%, avg_specificity=50.75% avg_auc=64.58%
Best model saved!! Metric=-68.08490827294114!!
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.455702 Test loss=0.651224 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.4218941628932953
[5/24] Train loss=0.4527445137500763
[10/24] Train loss=0.44631636142730713
[15/24] Train loss=0.4732275903224945
[20/24] Train loss=0.41128256916999817
Test set avg_accuracy=65.12% avg_sensitivity=71.60%, avg_specificity=62.80% avg_auc=62.88%
Best model saved!! Metric=-63.5995028372514!!
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.441720 Test loss=0.685792 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.40935155749320984
[5/24] Train loss=0.4336964190006256
[10/24] Train loss=0.4418913722038269
[15/24] Train loss=0.46221742033958435
[20/24] Train loss=0.397032231092453
Test set avg_accuracy=70.40% avg_sensitivity=67.49%, avg_specificity=71.44% avg_auc=64.16%
Best model saved!! Metric=-52.50549138543842!!
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.428747 Test loss=0.672320 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3993220329284668
[5/24] Train loss=0.42265620827674866
[10/24] Train loss=0.43038949370384216
[15/24] Train loss=0.4572880268096924
[20/24] Train loss=0.3897744119167328
Test set avg_accuracy=70.96% avg_sensitivity=70.36%, avg_specificity=71.18% avg_auc=66.95%
Best model saved!! Metric=-46.54612721998987!!
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.424079 Test loss=0.650935 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.39067429304122925
[5/24] Train loss=0.42456918954849243
[10/24] Train loss=0.4237695634365082
[15/24] Train loss=0.45728635787963867
[20/24] Train loss=0.38857603073120117
Test set avg_accuracy=67.53% avg_sensitivity=72.09%, avg_specificity=65.90% avg_auc=65.52%
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.417464 Test loss=0.682048 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.4005405008792877
[5/24] Train loss=0.4157601296901703
[10/24] Train loss=0.41736936569213867
[15/24] Train loss=0.4835026264190674
[20/24] Train loss=0.3748621940612793
Test set avg_accuracy=68.79% avg_sensitivity=74.22%, avg_specificity=66.85% avg_auc=69.64%
Best model saved!! Metric=-46.49769321982784!!
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.415710 Test loss=0.629295 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.37277960777282715
[5/24] Train loss=0.42840683460235596
[10/24] Train loss=0.41716697812080383
[15/24] Train loss=0.4606098234653473
[20/24] Train loss=0.3803616464138031
Test set avg_accuracy=71.46% avg_sensitivity=67.49%, avg_specificity=72.88% avg_auc=70.12%
Best model saved!! Metric=-44.059216052471626!!
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.419447 Test loss=0.623654 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.40327417850494385
[5/24] Train loss=0.42642807960510254
[10/24] Train loss=0.4078848659992218
[15/24] Train loss=0.453630656003952
[20/24] Train loss=0.37239864468574524
Test set avg_accuracy=67.06% avg_sensitivity=78.72%, avg_specificity=62.89% avg_auc=72.61%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.415006 Test loss=0.616276 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.37061840295791626
[5/24] Train loss=0.41875582933425903
[10/24] Train loss=0.4045458436012268
[15/24] Train loss=0.45079582929611206
[20/24] Train loss=0.3691791594028473
Test set avg_accuracy=68.02% avg_sensitivity=76.89%, avg_specificity=64.85% avg_auc=70.27%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.405705 Test loss=0.632031 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3635401725769043
[5/24] Train loss=0.4046582579612732
[10/24] Train loss=0.39788293838500977
[15/24] Train loss=0.44738882780075073
[20/24] Train loss=0.36811038851737976
Test set avg_accuracy=64.10% avg_sensitivity=82.93%, avg_specificity=57.38% avg_auc=73.04%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.401868 Test loss=0.617369 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3675081729888916
[5/24] Train loss=0.4118978679180145
[10/24] Train loss=0.394026517868042
[15/24] Train loss=0.45384272933006287
[20/24] Train loss=0.3689371943473816
Test set avg_accuracy=71.60% avg_sensitivity=73.18%, avg_specificity=71.04% avg_auc=72.23%
Best model saved!! Metric=-37.95375378975456!!
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.403553 Test loss=0.599065 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.36845001578330994
[5/24] Train loss=0.41175171732902527
[10/24] Train loss=0.3996795117855072
[15/24] Train loss=0.44690921902656555
[20/24] Train loss=0.3648585081100464
Test set avg_accuracy=68.53% avg_sensitivity=76.05%, avg_specificity=65.84% avg_auc=74.56%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.405193 Test loss=0.592475 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.36255642771720886
[5/24] Train loss=0.4294675290584564
[10/24] Train loss=0.39786848425865173
[15/24] Train loss=0.44361841678619385
[20/24] Train loss=0.36854231357574463
Test set avg_accuracy=64.15% avg_sensitivity=85.75%, avg_specificity=56.44% avg_auc=74.85%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.405665 Test loss=0.611203 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3635173439979553
[5/24] Train loss=0.4030904471874237
[10/24] Train loss=0.395487904548645
[15/24] Train loss=0.4718199074268341
[20/24] Train loss=0.3681029975414276
Test set avg_accuracy=74.01% avg_sensitivity=67.89%, avg_specificity=76.20% avg_auc=72.55%
Best model saved!! Metric=-35.354632889421325!!
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.406172 Test loss=0.593565 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.385073184967041
[5/24] Train loss=0.4096158742904663
[10/24] Train loss=0.39482244849205017
[15/24] Train loss=0.44925591349601746
[20/24] Train loss=0.38658902049064636
Test set avg_accuracy=67.23% avg_sensitivity=82.88%, avg_specificity=61.64% avg_auc=77.51%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.404583 Test loss=0.586298 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.377023845911026
[5/24] Train loss=0.42192041873931885
[10/24] Train loss=0.39446818828582764
[15/24] Train loss=0.46535998582839966
[20/24] Train loss=0.3758350610733032
Test set avg_accuracy=70.74% avg_sensitivity=74.72%, avg_specificity=69.32% avg_auc=75.36%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.402609 Test loss=0.578051 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3698330819606781
[5/24] Train loss=0.40118229389190674
[10/24] Train loss=0.3921785056591034
[15/24] Train loss=0.470662385225296
[20/24] Train loss=0.3608752191066742
Test set avg_accuracy=66.98% avg_sensitivity=82.19%, avg_specificity=61.55% avg_auc=77.79%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.400060 Test loss=0.579024 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3732932507991791
[5/24] Train loss=0.41028261184692383
[10/24] Train loss=0.39433103799819946
[15/24] Train loss=0.4492473304271698
[20/24] Train loss=0.3607560098171234
Test set avg_accuracy=68.45% avg_sensitivity=81.30%, avg_specificity=63.86% avg_auc=74.14%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.401145 Test loss=0.598381 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.36001256108283997
[5/24] Train loss=0.39651748538017273
[10/24] Train loss=0.3957500755786896
[15/24] Train loss=0.4426490366458893
[20/24] Train loss=0.3599487543106079
Test set avg_accuracy=64.64% avg_sensitivity=84.12%, avg_specificity=57.68% avg_auc=75.09%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.392909 Test loss=0.600012 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3563777506351471
[5/24] Train loss=0.39590883255004883
[10/24] Train loss=0.39075809717178345
[15/24] Train loss=0.4497204124927521
[20/24] Train loss=0.3590509295463562
Test set avg_accuracy=73.93% avg_sensitivity=68.93%, avg_specificity=75.72% avg_auc=78.54%
Best model saved!! Metric=-28.879338714770014!!
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.393585 Test loss=0.553960 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3649834394454956
[5/24] Train loss=0.40960434079170227
[10/24] Train loss=0.40159595012664795
[15/24] Train loss=0.4525038003921509
[20/24] Train loss=0.3611333966255188
Test set avg_accuracy=72.34% avg_sensitivity=76.79%, avg_specificity=70.75% avg_auc=77.52%
Best model saved!! Metric=-28.58605796529531!!
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.401826 Test loss=0.565595 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.36787736415863037
[5/24] Train loss=0.40250372886657715
[10/24] Train loss=0.39266106486320496
[15/24] Train loss=0.44274312257766724
[20/24] Train loss=0.36720356345176697
Test set avg_accuracy=72.03% avg_sensitivity=71.75%, avg_specificity=72.13% avg_auc=74.71%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.400268 Test loss=0.579685 Current lr=[0.000299720220882401]

[0/24] Train loss=0.35756808519363403
[5/24] Train loss=0.3986264765262604
[10/24] Train loss=0.39640289545059204
[15/24] Train loss=0.4515831768512726
[20/24] Train loss=0.3607933819293976
Test set avg_accuracy=62.98% avg_sensitivity=86.79%, avg_specificity=54.48% avg_auc=77.27%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.395261 Test loss=0.601969 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.356620192527771
[5/24] Train loss=0.38928985595703125
[10/24] Train loss=0.38263800740242004
[15/24] Train loss=0.4432440996170044
[20/24] Train loss=0.3518296182155609
Test set avg_accuracy=73.24% avg_sensitivity=68.13%, avg_specificity=75.07% avg_auc=74.57%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.388465 Test loss=0.568172 Current lr=[0.000298904600941902]

[0/24] Train loss=0.35545021295547485
[5/24] Train loss=0.3906344175338745
[10/24] Train loss=0.38450008630752563
[15/24] Train loss=0.44041502475738525
[20/24] Train loss=0.3533797860145569
Test set avg_accuracy=69.67% avg_sensitivity=77.14%, avg_specificity=67.01% avg_auc=76.37%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.391031 Test loss=0.572290 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3577723801136017
[5/24] Train loss=0.388278990983963
[10/24] Train loss=0.39209020137786865
[15/24] Train loss=0.4373866617679596
[20/24] Train loss=0.35218846797943115
Test set avg_accuracy=73.76% avg_sensitivity=68.38%, avg_specificity=75.68% avg_auc=75.83%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.390040 Test loss=0.565099 Current lr=[0.000297555943323901]

[0/24] Train loss=0.36261555552482605
[5/24] Train loss=0.3952968120574951
[10/24] Train loss=0.38482967019081116
[15/24] Train loss=0.43130379915237427
[20/24] Train loss=0.3501580059528351
Test set avg_accuracy=64.06% avg_sensitivity=86.59%, avg_specificity=56.02% avg_auc=72.05%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.388051 Test loss=0.635692 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.35691529512405396
[5/24] Train loss=0.3853667676448822
[10/24] Train loss=0.38447970151901245
[15/24] Train loss=0.44739818572998047
[20/24] Train loss=0.35540685057640076
Test set avg_accuracy=65.16% avg_sensitivity=85.35%, avg_specificity=57.94% avg_auc=78.84%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.386752 Test loss=0.575080 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.35238268971443176
[5/24] Train loss=0.3952902555465698
[10/24] Train loss=0.39174044132232666
[15/24] Train loss=0.4409160912036896
[20/24] Train loss=0.3697001338005066
Test set avg_accuracy=71.05% avg_sensitivity=80.11%, avg_specificity=67.82% avg_auc=79.50%
Best model saved!! Metric=-27.51461246129176!!
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.390794 Test loss=0.559584 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.35221773386001587
[5/24] Train loss=0.3921295702457428
[10/24] Train loss=0.3788513243198395
[15/24] Train loss=0.43279406428337097
[20/24] Train loss=0.34815123677253723
Test set avg_accuracy=69.51% avg_sensitivity=77.63%, avg_specificity=66.60% avg_auc=77.01%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.382992 Test loss=0.565202 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3504120707511902
[5/24] Train loss=0.382768839597702
[10/24] Train loss=0.3838975429534912
[15/24] Train loss=0.4613017141819
[20/24] Train loss=0.35327404737472534
Test set avg_accuracy=75.40% avg_sensitivity=69.82%, avg_specificity=77.40% avg_auc=79.09%
Best model saved!! Metric=-24.294890973908593!!
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.390254 Test loss=0.537464 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3658676743507385
[5/24] Train loss=0.39196181297302246
[10/24] Train loss=0.3829007148742676
[15/24] Train loss=0.4439486563205719
[20/24] Train loss=0.3605307340621948
Test set avg_accuracy=67.15% avg_sensitivity=83.03%, avg_specificity=61.48% avg_auc=74.84%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.391780 Test loss=0.596632 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3711027204990387
[5/24] Train loss=0.38851967453956604
[10/24] Train loss=0.3846870958805084
[15/24] Train loss=0.4474503993988037
[20/24] Train loss=0.3484274744987488
Test set avg_accuracy=67.06% avg_sensitivity=81.99%, avg_specificity=61.72% avg_auc=76.40%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.391893 Test loss=0.585773 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.4061753451824188
[5/24] Train loss=0.39911773800849915
[10/24] Train loss=0.39582133293151855
[15/24] Train loss=0.46243688464164734
[20/24] Train loss=0.35060814023017883
Test set avg_accuracy=76.64% avg_sensitivity=60.91%, avg_specificity=82.26% avg_auc=77.87%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.393645 Test loss=0.534061 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3579670488834381
[5/24] Train loss=0.39023762941360474
[10/24] Train loss=0.3801794946193695
[15/24] Train loss=0.45561856031417847
[20/24] Train loss=0.3502269387245178
Test set avg_accuracy=73.84% avg_sensitivity=73.97%, avg_specificity=73.79% avg_auc=78.44%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.389065 Test loss=0.549205 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.35413336753845215
[5/24] Train loss=0.39134836196899414
[10/24] Train loss=0.3776337504386902
[15/24] Train loss=0.43525952100753784
[20/24] Train loss=0.34592464566230774
Test set avg_accuracy=70.90% avg_sensitivity=79.52%, avg_specificity=67.82% avg_auc=79.71%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.383105 Test loss=0.546465 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3496437966823578
[5/24] Train loss=0.3821057379245758
[10/24] Train loss=0.3879697024822235
[15/24] Train loss=0.43466976284980774
[20/24] Train loss=0.3522449731826782
Test set avg_accuracy=60.94% avg_sensitivity=89.86%, avg_specificity=50.61% avg_auc=75.00%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.385747 Test loss=0.621376 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.35438549518585205
[5/24] Train loss=0.3866981267929077
[10/24] Train loss=0.38211381435394287
[15/24] Train loss=0.47994640469551086
[20/24] Train loss=0.35209810733795166
Test set avg_accuracy=75.73% avg_sensitivity=74.96%, avg_specificity=76.00% avg_auc=81.70%
Best model saved!! Metric=-17.60140867849644!!
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.384076 Test loss=0.527866 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3568837642669678
[5/24] Train loss=0.3866782784461975
[10/24] Train loss=0.38214895129203796
[15/24] Train loss=0.4307280480861664
[20/24] Train loss=0.33579006791114807
Test set avg_accuracy=67.50% avg_sensitivity=84.81%, avg_specificity=61.32% avg_auc=78.37%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.380161 Test loss=0.569431 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3446628749370575
[5/24] Train loss=0.3761713206768036
[10/24] Train loss=0.3723164200782776
[15/24] Train loss=0.4194488227367401
[20/24] Train loss=0.33604031801223755
Test set avg_accuracy=68.68% avg_sensitivity=80.55%, avg_specificity=64.45% avg_auc=78.50%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.374513 Test loss=0.558271 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.35190922021865845
[5/24] Train loss=0.38178959488868713
[10/24] Train loss=0.37969526648521423
[15/24] Train loss=0.4603588879108429
[20/24] Train loss=0.3413478136062622
Test set avg_accuracy=75.49% avg_sensitivity=74.96%, avg_specificity=75.68% avg_auc=79.83%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.381317 Test loss=0.534514 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3505306541919708
[5/24] Train loss=0.3815527856349945
[10/24] Train loss=0.3815978467464447
[15/24] Train loss=0.424057275056839
[20/24] Train loss=0.3409118950366974
Test set avg_accuracy=71.55% avg_sensitivity=77.09%, avg_specificity=69.57% avg_auc=78.00%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.377977 Test loss=0.554508 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.34470170736312866
[5/24] Train loss=0.37581145763397217
[10/24] Train loss=0.3735905885696411
[15/24] Train loss=0.45146456360816956
[20/24] Train loss=0.3431282937526703
Test set avg_accuracy=74.83% avg_sensitivity=74.37%, avg_specificity=75.00% avg_auc=81.13%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.375687 Test loss=0.526662 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.36271047592163086
[5/24] Train loss=0.3806024193763733
[10/24] Train loss=0.38273295760154724
[15/24] Train loss=0.43660682439804077
[20/24] Train loss=0.34177809953689575
Test set avg_accuracy=71.38% avg_sensitivity=80.41%, avg_specificity=68.16% avg_auc=76.95%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.379025 Test loss=0.568147 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3431274890899658
[5/24] Train loss=0.3772839307785034
[10/24] Train loss=0.3716370463371277
[15/24] Train loss=0.44687819480895996
[20/24] Train loss=0.3441125452518463
Test set avg_accuracy=70.23% avg_sensitivity=77.83%, avg_specificity=67.52% avg_auc=77.20%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.376933 Test loss=0.566505 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.34379783272743225
[5/24] Train loss=0.37538567185401917
[10/24] Train loss=0.37457093596458435
[15/24] Train loss=0.4291309714317322
[20/24] Train loss=0.34143486618995667
Test set avg_accuracy=73.42% avg_sensitivity=75.31%, avg_specificity=72.75% avg_auc=78.70%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.376930 Test loss=0.543382 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.34521669149398804
[5/24] Train loss=0.3708050549030304
[10/24] Train loss=0.3778633177280426
[15/24] Train loss=0.41985514760017395
[20/24] Train loss=0.34185343980789185
Test set avg_accuracy=71.72% avg_sensitivity=78.82%, avg_specificity=69.18% avg_auc=77.06%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.372628 Test loss=0.564608 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.34748125076293945
[5/24] Train loss=0.3740844428539276
[10/24] Train loss=0.38842788338661194
[15/24] Train loss=0.42485225200653076
[20/24] Train loss=0.3400591015815735
Test set avg_accuracy=73.57% avg_sensitivity=79.32%, avg_specificity=71.51% avg_auc=81.21%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.376913 Test loss=0.535323 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.35800960659980774
[5/24] Train loss=0.3709477484226227
[10/24] Train loss=0.3766201138496399
[15/24] Train loss=0.42102980613708496
[20/24] Train loss=0.33862119913101196
Test set avg_accuracy=70.13% avg_sensitivity=80.90%, avg_specificity=66.28% avg_auc=77.66%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.374032 Test loss=0.566621 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.34159189462661743
[5/24] Train loss=0.3668361306190491
[10/24] Train loss=0.3705340325832367
[15/24] Train loss=0.4283757507801056
[20/24] Train loss=0.33755868673324585
Test set avg_accuracy=65.22% avg_sensitivity=87.78%, avg_specificity=57.17% avg_auc=78.11%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.368854 Test loss=0.587987 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.34187549352645874
[5/24] Train loss=0.37159448862075806
[10/24] Train loss=0.3738386034965515
[15/24] Train loss=0.416267991065979
[20/24] Train loss=0.3370472490787506
Test set avg_accuracy=69.30% avg_sensitivity=82.09%, avg_specificity=64.73% avg_auc=78.58%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.369853 Test loss=0.564740 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3391788601875305
[5/24] Train loss=0.3693079650402069
[10/24] Train loss=0.3751794695854187
[15/24] Train loss=0.4161491096019745
[20/24] Train loss=0.34106898307800293
Test set avg_accuracy=72.50% avg_sensitivity=81.15%, avg_specificity=69.41% avg_auc=82.01%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.368951 Test loss=0.536003 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3492054343223572
[5/24] Train loss=0.37022826075553894
[10/24] Train loss=0.38009515404701233
[15/24] Train loss=0.41547390818595886
[20/24] Train loss=0.3398208022117615
Test set avg_accuracy=68.07% avg_sensitivity=83.23%, avg_specificity=62.66% avg_auc=79.45%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.371947 Test loss=0.565170 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3622659742832184
[5/24] Train loss=0.3779512047767639
[10/24] Train loss=0.3775746822357178
[15/24] Train loss=0.4176405072212219
[20/24] Train loss=0.3475179076194763
Test set avg_accuracy=75.14% avg_sensitivity=75.85%, avg_specificity=74.89% avg_auc=80.86%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.373231 Test loss=0.530723 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3496071696281433
[5/24] Train loss=0.3690555691719055
[10/24] Train loss=0.37032103538513184
[15/24] Train loss=0.4318990707397461
[20/24] Train loss=0.33729371428489685
Test set avg_accuracy=67.76% avg_sensitivity=85.60%, avg_specificity=61.39% avg_auc=81.19%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.370670 Test loss=0.559551 Current lr=[0.000224838296036774]

[0/24] Train loss=0.34177166223526
[5/24] Train loss=0.3700042963027954
[10/24] Train loss=0.3770904242992401
[15/24] Train loss=0.4285787343978882
[20/24] Train loss=0.34971946477890015
Test set avg_accuracy=70.36% avg_sensitivity=83.28%, avg_specificity=65.75% avg_auc=80.65%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.372400 Test loss=0.549942 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.35054242610931396
[5/24] Train loss=0.3743617832660675
[10/24] Train loss=0.3774813711643219
[15/24] Train loss=0.4253283143043518
[20/24] Train loss=0.3467910587787628
Test set avg_accuracy=73.84% avg_sensitivity=76.45%, avg_specificity=72.91% avg_auc=78.70%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.375298 Test loss=0.543586 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.34166109561920166
[5/24] Train loss=0.36969345808029175
[10/24] Train loss=0.37265893816947937
[15/24] Train loss=0.41920551657676697
[20/24] Train loss=0.34530138969421387
Test set avg_accuracy=68.54% avg_sensitivity=85.25%, avg_specificity=62.57% avg_auc=80.12%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.372895 Test loss=0.562575 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.33691325783729553
[5/24] Train loss=0.3705299198627472
[10/24] Train loss=0.3736030161380768
[15/24] Train loss=0.4312773644924164
[20/24] Train loss=0.3366478681564331
Test set avg_accuracy=71.13% avg_sensitivity=79.86%, avg_specificity=68.02% avg_auc=80.42%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.368657 Test loss=0.537681 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3383234441280365
[5/24] Train loss=0.3645213842391968
[10/24] Train loss=0.3727351427078247
[15/24] Train loss=0.41802912950515747
[20/24] Train loss=0.3324163854122162
Test set avg_accuracy=66.52% avg_sensitivity=84.81%, avg_specificity=59.99% avg_auc=77.96%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.366025 Test loss=0.577243 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3361079692840576
[5/24] Train loss=0.3627196252346039
[10/24] Train loss=0.37182751297950745
[15/24] Train loss=0.4264068603515625
[20/24] Train loss=0.3308697044849396
Test set avg_accuracy=68.55% avg_sensitivity=85.75%, avg_specificity=62.41% avg_auc=80.93%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.366679 Test loss=0.556932 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.335835337638855
[5/24] Train loss=0.36459624767303467
[10/24] Train loss=0.3705441653728485
[15/24] Train loss=0.4090668559074402
[20/24] Train loss=0.3323427140712738
Test set avg_accuracy=65.72% avg_sensitivity=85.35%, avg_specificity=58.70% avg_auc=78.10%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.365790 Test loss=0.579666 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.33375072479248047
[5/24] Train loss=0.36090826988220215
[10/24] Train loss=0.37199079990386963
[15/24] Train loss=0.4264048933982849
[20/24] Train loss=0.3346441984176636
Test set avg_accuracy=72.73% avg_sensitivity=80.01%, avg_specificity=70.14% avg_auc=79.38%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.365980 Test loss=0.545441 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.33965906500816345
[5/24] Train loss=0.36235642433166504
[10/24] Train loss=0.368459016084671
[15/24] Train loss=0.40240752696990967
[20/24] Train loss=0.3326356112957001
Test set avg_accuracy=67.90% avg_sensitivity=85.16%, avg_specificity=61.74% avg_auc=78.99%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.362517 Test loss=0.568649 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.326313853263855
[5/24] Train loss=0.35138097405433655
[10/24] Train loss=0.36856308579444885
[15/24] Train loss=0.40036675333976746
[20/24] Train loss=0.327580064535141
Test set avg_accuracy=63.85% avg_sensitivity=88.08%, avg_specificity=55.20% avg_auc=77.57%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.358897 Test loss=0.599443 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3398361802101135
[5/24] Train loss=0.36466461420059204
[10/24] Train loss=0.3752317428588867
[15/24] Train loss=0.4503994584083557
[20/24] Train loss=0.34298834204673767
Test set avg_accuracy=80.74% avg_sensitivity=49.28%, avg_specificity=91.98% avg_auc=85.87%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.371332 Test loss=0.417638 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.363508403301239
[5/24] Train loss=0.3825675845146179
[10/24] Train loss=0.38748660683631897
[15/24] Train loss=0.42525148391723633
[20/24] Train loss=0.33643656969070435
Test set avg_accuracy=78.92% avg_sensitivity=66.65%, avg_specificity=83.30% avg_auc=83.26%
Best model saved!! Metric=-13.870285266914294!!
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.381682 Test loss=0.486046 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.34125885367393494
[5/24] Train loss=0.3661769926548004
[10/24] Train loss=0.3711428642272949
[15/24] Train loss=0.4349692463874817
[20/24] Train loss=0.34118232131004333
Test set avg_accuracy=66.22% avg_sensitivity=87.09%, avg_specificity=58.77% avg_auc=79.44%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.372293 Test loss=0.572392 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3359326422214508
[5/24] Train loss=0.3613591492176056
[10/24] Train loss=0.3762918710708618
[15/24] Train loss=0.4217974543571472
[20/24] Train loss=0.3445543348789215
Test set avg_accuracy=73.02% avg_sensitivity=80.26%, avg_specificity=70.44% avg_auc=79.64%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.367849 Test loss=0.543988 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3452605605125427
[5/24] Train loss=0.36391517519950867
[10/24] Train loss=0.3763750195503235
[15/24] Train loss=0.41250383853912354
[20/24] Train loss=0.33977434039115906
Test set avg_accuracy=75.34% avg_sensitivity=74.27%, avg_specificity=75.72% avg_auc=79.56%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.369090 Test loss=0.528052 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3440261483192444
[5/24] Train loss=0.3609825074672699
[10/24] Train loss=0.36859384179115295
[15/24] Train loss=0.4136247932910919
[20/24] Train loss=0.33829265832901
Test set avg_accuracy=69.90% avg_sensitivity=81.94%, avg_specificity=65.59% avg_auc=79.06%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.365236 Test loss=0.554645 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3369969129562378
[5/24] Train loss=0.35643741488456726
[10/24] Train loss=0.36817237734794617
[15/24] Train loss=0.41983944177627563
[20/24] Train loss=0.3374316394329071
Test set avg_accuracy=70.83% avg_sensitivity=84.07%, avg_specificity=66.11% avg_auc=81.45%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.363732 Test loss=0.537489 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.33432090282440186
[5/24] Train loss=0.35422664880752563
[10/24] Train loss=0.366303414106369
[15/24] Train loss=0.406956285238266
[20/24] Train loss=0.3380429744720459
Test set avg_accuracy=66.55% avg_sensitivity=85.80%, avg_specificity=59.67% avg_auc=78.69%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.361234 Test loss=0.573507 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.331297904253006
[5/24] Train loss=0.35493794083595276
[10/24] Train loss=0.36641862988471985
[15/24] Train loss=0.40886372327804565
[20/24] Train loss=0.33283281326293945
Test set avg_accuracy=65.27% avg_sensitivity=85.90%, avg_specificity=57.91% avg_auc=78.39%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.359107 Test loss=0.580202 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.33093249797821045
[5/24] Train loss=0.3524729013442993
[10/24] Train loss=0.36878493428230286
[15/24] Train loss=0.41674333810806274
[20/24] Train loss=0.3361738920211792
Test set avg_accuracy=65.56% avg_sensitivity=86.69%, avg_specificity=58.01% avg_auc=79.37%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.361514 Test loss=0.575100 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3258267939090729
[5/24] Train loss=0.35024574398994446
[10/24] Train loss=0.3684140741825104
[15/24] Train loss=0.40068894624710083
[20/24] Train loss=0.33185502886772156
Test set avg_accuracy=68.37% avg_sensitivity=82.93%, avg_specificity=63.17% avg_auc=77.67%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.358690 Test loss=0.573386 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3257049322128296
[5/24] Train loss=0.35465845465660095
[10/24] Train loss=0.3649350702762604
[15/24] Train loss=0.4028799533843994
[20/24] Train loss=0.3337414264678955
Test set avg_accuracy=70.60% avg_sensitivity=80.46%, avg_specificity=67.08% avg_auc=78.57%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.360354 Test loss=0.558120 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3277769982814789
[5/24] Train loss=0.35938653349876404
[10/24] Train loss=0.36815282702445984
[15/24] Train loss=0.416734516620636
[20/24] Train loss=0.33407169580459595
Test set avg_accuracy=70.56% avg_sensitivity=84.31%, avg_specificity=65.65% avg_auc=80.25%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.362263 Test loss=0.548935 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3316143751144409
[5/24] Train loss=0.363613098859787
[10/24] Train loss=0.37050938606262207
[15/24] Train loss=0.40717753767967224
[20/24] Train loss=0.3312780261039734
Test set avg_accuracy=70.44% avg_sensitivity=82.53%, avg_specificity=66.12% avg_auc=79.09%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.362283 Test loss=0.559774 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3390423059463501
[5/24] Train loss=0.35845616459846497
[10/24] Train loss=0.3731560707092285
[15/24] Train loss=0.4126904308795929
[20/24] Train loss=0.3386545181274414
Test set avg_accuracy=67.75% avg_sensitivity=85.65%, avg_specificity=61.35% avg_auc=79.18%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.364538 Test loss=0.566592 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.34104591608047485
[5/24] Train loss=0.360349178314209
[10/24] Train loss=0.37673091888427734
[15/24] Train loss=0.4041820764541626
[20/24] Train loss=0.33775681257247925
Test set avg_accuracy=71.97% avg_sensitivity=82.78%, avg_specificity=68.10% avg_auc=81.24%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.366700 Test loss=0.541101 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3378460109233856
[5/24] Train loss=0.3651595115661621
[10/24] Train loss=0.37285634875297546
[15/24] Train loss=0.426372230052948
[20/24] Train loss=0.3395514488220215
Test set avg_accuracy=75.99% avg_sensitivity=71.45%, avg_specificity=77.61% avg_auc=79.93%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.366297 Test loss=0.518406 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.33133992552757263
[5/24] Train loss=0.3551350235939026
[10/24] Train loss=0.37601161003112793
[15/24] Train loss=0.4056773781776428
[20/24] Train loss=0.33862027525901794
Test set avg_accuracy=76.13% avg_sensitivity=72.54%, avg_specificity=77.42% avg_auc=80.30%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.362198 Test loss=0.513827 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3304824233055115
[5/24] Train loss=0.3556665778160095
[10/24] Train loss=0.3653244972229004
[15/24] Train loss=0.4028855860233307
[20/24] Train loss=0.33680033683776855
Test set avg_accuracy=71.56% avg_sensitivity=80.65%, avg_specificity=68.32% avg_auc=79.99%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.358341 Test loss=0.540541 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.32445088028907776
[5/24] Train loss=0.3482983410358429
[10/24] Train loss=0.36387941241264343
[15/24] Train loss=0.4155157804489136
[20/24] Train loss=0.3338561952114105
Test set avg_accuracy=69.97% avg_sensitivity=81.64%, avg_specificity=65.81% avg_auc=78.93%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.357501 Test loss=0.555333 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.32803091406822205
[5/24] Train loss=0.3554151952266693
[10/24] Train loss=0.37000855803489685
[15/24] Train loss=0.40532058477401733
[20/24] Train loss=0.3336407542228699
Test set avg_accuracy=69.92% avg_sensitivity=82.93%, avg_specificity=65.28% avg_auc=79.88%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.357873 Test loss=0.549337 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3290674388408661
[5/24] Train loss=0.3485811650753021
[10/24] Train loss=0.36350366473197937
[15/24] Train loss=0.4019468426704407
[20/24] Train loss=0.33469247817993164
Test set avg_accuracy=67.15% avg_sensitivity=85.01%, avg_specificity=60.77% avg_auc=78.07%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.356038 Test loss=0.579417 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.32870012521743774
[5/24] Train loss=0.34467896819114685
[10/24] Train loss=0.3621753752231598
[15/24] Train loss=0.40029916167259216
[20/24] Train loss=0.33328017592430115
Test set avg_accuracy=66.09% avg_sensitivity=85.21%, avg_specificity=59.27% avg_auc=78.02%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.354426 Test loss=0.582744 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.32714933156967163
[5/24] Train loss=0.34475842118263245
[10/24] Train loss=0.3638690412044525
[15/24] Train loss=0.39815014600753784
[20/24] Train loss=0.33198532462120056
Test set avg_accuracy=66.02% avg_sensitivity=85.95%, avg_specificity=58.90% avg_auc=78.93%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.353255 Test loss=0.575096 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3307408094406128
[5/24] Train loss=0.34072640538215637
[10/24] Train loss=0.3634980022907257
[15/24] Train loss=0.39890506863594055
[20/24] Train loss=0.33118772506713867
Test set avg_accuracy=65.62% avg_sensitivity=85.55%, avg_specificity=58.51% avg_auc=79.13%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.352919 Test loss=0.575297 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3274539113044739
[5/24] Train loss=0.34489309787750244
[10/24] Train loss=0.36253786087036133
[15/24] Train loss=0.3960559666156769
[20/24] Train loss=0.3307935893535614
Test set avg_accuracy=67.03% avg_sensitivity=85.45%, avg_specificity=60.45% avg_auc=79.43%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.352228 Test loss=0.567089 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.32589948177337646
[5/24] Train loss=0.34720683097839355
[10/24] Train loss=0.36311689019203186
[15/24] Train loss=0.40473777055740356
[20/24] Train loss=0.3331226408481598
Test set avg_accuracy=65.07% avg_sensitivity=86.74%, avg_specificity=57.32% avg_auc=79.18%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.353066 Test loss=0.577703 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.32700634002685547
[5/24] Train loss=0.34553706645965576
[10/24] Train loss=0.36240699887275696
[15/24] Train loss=0.3957270681858063
[20/24] Train loss=0.33215612173080444
Test set avg_accuracy=64.77% avg_sensitivity=86.49%, avg_specificity=57.01% avg_auc=79.38%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.352397 Test loss=0.575465 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.32209187746047974
[5/24] Train loss=0.34194889664649963
[10/24] Train loss=0.36285001039505005
[15/24] Train loss=0.39422842860221863
[20/24] Train loss=0.333301842212677
Test set avg_accuracy=64.82% avg_sensitivity=86.54%, avg_specificity=57.06% avg_auc=79.38%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.352495 Test loss=0.576618 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3247881233692169
[5/24] Train loss=0.34273022413253784
[10/24] Train loss=0.36370065808296204
[15/24] Train loss=0.3952423334121704
[20/24] Train loss=0.33269453048706055
Test set avg_accuracy=66.56% avg_sensitivity=85.30%, avg_specificity=59.87% avg_auc=79.68%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.352711 Test loss=0.566018 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.32201874256134033
[5/24] Train loss=0.34240520000457764
[10/24] Train loss=0.36089658737182617
[15/24] Train loss=0.3945411741733551
[20/24] Train loss=0.3268683850765228
Test set avg_accuracy=66.33% avg_sensitivity=86.29%, avg_specificity=59.20% avg_auc=78.51%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.349753 Test loss=0.580668 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.3208102285861969
[5/24] Train loss=0.34208184480667114
[10/24] Train loss=0.36159592866897583
[15/24] Train loss=0.3910893201828003
[20/24] Train loss=0.33162084221839905
Test set avg_accuracy=66.60% avg_sensitivity=86.10%, avg_specificity=59.64% avg_auc=79.04%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.349583 Test loss=0.572616 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3198303282260895
[5/24] Train loss=0.339354932308197
[10/24] Train loss=0.35971537232398987
[15/24] Train loss=0.3919476568698883
[20/24] Train loss=0.3300762474536896
Test set avg_accuracy=67.41% avg_sensitivity=84.76%, avg_specificity=61.21% avg_auc=78.13%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.348876 Test loss=0.577290 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3190179467201233
[5/24] Train loss=0.33958181738853455
[10/24] Train loss=0.36141136288642883
[15/24] Train loss=0.390958309173584
[20/24] Train loss=0.3279349207878113
Test set avg_accuracy=65.73% avg_sensitivity=85.90%, avg_specificity=58.53% avg_auc=78.34%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.348341 Test loss=0.583159 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3195914030075073
[5/24] Train loss=0.3405693471431732
[10/24] Train loss=0.36201992630958557
[15/24] Train loss=0.3909613788127899
[20/24] Train loss=0.3297106921672821
Test set avg_accuracy=66.08% avg_sensitivity=85.90%, avg_specificity=59.00% avg_auc=78.47%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.348325 Test loss=0.578906 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3192419111728668
[5/24] Train loss=0.3365119993686676
[10/24] Train loss=0.36012697219848633
[15/24] Train loss=0.390129417181015
[20/24] Train loss=0.32756292819976807
Test set avg_accuracy=66.86% avg_sensitivity=85.70%, avg_specificity=60.13% avg_auc=78.44%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.347929 Test loss=0.578334 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3192618787288666
[5/24] Train loss=0.3357565104961395
[10/24] Train loss=0.3607282042503357
[15/24] Train loss=0.3884980082511902
[20/24] Train loss=0.32602590322494507
Test set avg_accuracy=65.69% avg_sensitivity=86.54%, avg_specificity=58.24% avg_auc=78.15%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.347082 Test loss=0.585695 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.32017937302589417
[5/24] Train loss=0.33695492148399353
[10/24] Train loss=0.36012446880340576
[15/24] Train loss=0.38964512944221497
[20/24] Train loss=0.32538938522338867
Test set avg_accuracy=66.32% avg_sensitivity=86.74%, avg_specificity=59.02% avg_auc=78.70%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.347557 Test loss=0.577765 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3194476068019867
[5/24] Train loss=0.3397543132305145
[10/24] Train loss=0.3616074323654175
[15/24] Train loss=0.389583021402359
[20/24] Train loss=0.3235674798488617
Test set avg_accuracy=66.82% avg_sensitivity=85.06%, avg_specificity=60.31% avg_auc=77.97%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.347595 Test loss=0.584811 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3187952935695648
[5/24] Train loss=0.3392407298088074
[10/24] Train loss=0.36003100872039795
[15/24] Train loss=0.3883093595504761
[20/24] Train loss=0.32381129264831543
Test set avg_accuracy=65.57% avg_sensitivity=86.99%, avg_specificity=57.93% avg_auc=78.09%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.348260 Test loss=0.590171 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3196622431278229
[5/24] Train loss=0.3418703079223633
[10/24] Train loss=0.3612428605556488
[15/24] Train loss=0.3883305490016937
[20/24] Train loss=0.324735552072525
Test set avg_accuracy=65.29% avg_sensitivity=87.09%, avg_specificity=57.50% avg_auc=77.97%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.348748 Test loss=0.592166 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.32028886675834656
[5/24] Train loss=0.338150292634964
[10/24] Train loss=0.36201155185699463
[15/24] Train loss=0.38879266381263733
[20/24] Train loss=0.3232588469982147
Test set avg_accuracy=65.59% avg_sensitivity=86.39%, avg_specificity=58.16% avg_auc=77.97%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.347919 Test loss=0.590448 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3216647505760193
[5/24] Train loss=0.33568766713142395
[10/24] Train loss=0.36223042011260986
[15/24] Train loss=0.39236870408058167
[20/24] Train loss=0.32365089654922485
Test set avg_accuracy=66.04% avg_sensitivity=86.19%, avg_specificity=58.84% avg_auc=78.37%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.347006 Test loss=0.582696 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.319305956363678
[5/24] Train loss=0.33546844124794006
[10/24] Train loss=0.3600265681743622
[15/24] Train loss=0.3890864849090576
[20/24] Train loss=0.3237810432910919
Test set avg_accuracy=66.93% avg_sensitivity=86.05%, avg_specificity=60.10% avg_auc=78.93%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.345901 Test loss=0.573826 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.31662365794181824
[5/24] Train loss=0.3338266909122467
[10/24] Train loss=0.3587929904460907
[15/24] Train loss=0.3880469799041748
[20/24] Train loss=0.32328757643699646
Test set avg_accuracy=65.68% avg_sensitivity=86.84%, avg_specificity=58.12% avg_auc=78.93%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.344537 Test loss=0.579574 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.3152172267436981
[5/24] Train loss=0.33181554079055786
[10/24] Train loss=0.35849177837371826
[15/24] Train loss=0.3849688470363617
[20/24] Train loss=0.3231431543827057
Test set avg_accuracy=65.60% avg_sensitivity=86.74%, avg_specificity=58.05% avg_auc=78.92%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.343554 Test loss=0.579910 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3143470585346222
[5/24] Train loss=0.3308136761188507
[10/24] Train loss=0.35778549313545227
[15/24] Train loss=0.3829455077648163
[20/24] Train loss=0.3223040997982025
Test set avg_accuracy=65.81% avg_sensitivity=87.14%, avg_specificity=58.19% avg_auc=78.61%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.342803 Test loss=0.584052 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.3139490783214569
[5/24] Train loss=0.33018064498901367
[10/24] Train loss=0.35749876499176025
[15/24] Train loss=0.3823395073413849
[20/24] Train loss=0.322491854429245
Test set avg_accuracy=65.34% avg_sensitivity=87.38%, avg_specificity=57.47% avg_auc=78.76%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.342434 Test loss=0.584439 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.31367582082748413
[5/24] Train loss=0.3297222852706909
[10/24] Train loss=0.3572486340999603
[15/24] Train loss=0.38170719146728516
[20/24] Train loss=0.32228654623031616
Test set avg_accuracy=65.27% avg_sensitivity=87.43%, avg_specificity=57.36% avg_auc=78.66%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.342159 Test loss=0.586008 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3134806454181671
[5/24] Train loss=0.3293232023715973
[10/24] Train loss=0.3572884500026703
[15/24] Train loss=0.3816007077693939
[20/24] Train loss=0.32202398777008057
Test set avg_accuracy=65.43% avg_sensitivity=87.93%, avg_specificity=57.40% avg_auc=78.60%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.341919 Test loss=0.586759 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3135117292404175
[5/24] Train loss=0.3290628492832184
[10/24] Train loss=0.35724619030952454
[15/24] Train loss=0.3815065026283264
[20/24] Train loss=0.32206347584724426
Test set avg_accuracy=64.87% avg_sensitivity=87.73%, avg_specificity=56.71% avg_auc=78.56%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.341789 Test loss=0.588133 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3132854104042053
[5/24] Train loss=0.328877717256546
[10/24] Train loss=0.3572177290916443
[15/24] Train loss=0.38131219148635864
[20/24] Train loss=0.32185491919517517
Test set avg_accuracy=64.79% avg_sensitivity=87.93%, avg_specificity=56.53% avg_auc=78.53%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.341672 Test loss=0.588661 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.31325623393058777
[5/24] Train loss=0.32875826954841614
[10/24] Train loss=0.3571547865867615
[15/24] Train loss=0.3811393082141876
[20/24] Train loss=0.3217748701572418
Test set avg_accuracy=64.78% avg_sensitivity=87.93%, avg_specificity=56.51% avg_auc=78.52%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.341596 Test loss=0.589023 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3131846487522125
[5/24] Train loss=0.32865023612976074
[10/24] Train loss=0.3571142256259918
[15/24] Train loss=0.38106176257133484
[20/24] Train loss=0.3216930627822876
Test set avg_accuracy=64.78% avg_sensitivity=87.93%, avg_specificity=56.51% avg_auc=78.51%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.341530 Test loss=0.589344 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3131348490715027
[5/24] Train loss=0.32857680320739746
[10/24] Train loss=0.3570845425128937
[15/24] Train loss=0.38098976016044617
[20/24] Train loss=0.3216298520565033
Test set avg_accuracy=64.71% avg_sensitivity=87.93%, avg_specificity=56.42% avg_auc=78.51%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.341480 Test loss=0.589503 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3130894601345062
[5/24] Train loss=0.32852399349212646
[10/24] Train loss=0.35705137252807617
[15/24] Train loss=0.3809378445148468
[20/24] Train loss=0.3215826749801636
Test set avg_accuracy=64.69% avg_sensitivity=87.93%, avg_specificity=56.39% avg_auc=78.51%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.341440 Test loss=0.589563 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.31305667757987976
[5/24] Train loss=0.3284885585308075
[10/24] Train loss=0.3570236265659332
[15/24] Train loss=0.3809014558792114
[20/24] Train loss=0.3215486705303192
Test set avg_accuracy=64.62% avg_sensitivity=87.93%, avg_specificity=56.30% avg_auc=78.51%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.341410 Test loss=0.589626 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.31303590536117554
[5/24] Train loss=0.3284669518470764
[10/24] Train loss=0.3570059537887573
[15/24] Train loss=0.3808765113353729
[20/24] Train loss=0.32152876257896423
Test set avg_accuracy=64.62% avg_sensitivity=87.93%, avg_specificity=56.30% avg_auc=78.50%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.341392 Test loss=0.589694 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3130232095718384
[5/24] Train loss=0.3284539580345154
[10/24] Train loss=0.35699743032455444
[15/24] Train loss=0.38086166977882385
[20/24] Train loss=0.3215189278125763
Test set avg_accuracy=64.62% avg_sensitivity=87.93%, avg_specificity=56.30% avg_auc=78.50%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.341382 Test loss=0.589737 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.31301742792129517
[5/24] Train loss=0.3284485638141632
[10/24] Train loss=0.35699400305747986
[15/24] Train loss=0.3808554410934448
[20/24] Train loss=0.3215155005455017
Test set avg_accuracy=64.62% avg_sensitivity=87.93%, avg_specificity=56.30% avg_auc=78.50%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.341378 Test loss=0.589753 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=78.92% sen=66.65%, spe=83.30%, auc=83.26%!
Fold[1] Avg_overlap=0.59%(0.27205995805954686)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 1,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'SwEDModel',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.6985064148902893
[5/24] Train loss=0.6969960927963257
[10/24] Train loss=0.696628749370575
[15/24] Train loss=0.6956082582473755
[20/24] Train loss=0.6952837705612183
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.91%
Best model saved!! Metric=-100.04974997459307!!
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.696218 Test loss=0.694882 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6938815116882324
[5/24] Train loss=0.6937340497970581
[10/24] Train loss=0.6928922533988953
[15/24] Train loss=0.6919212937355042
[20/24] Train loss=0.6913524270057678
Test set avg_accuracy=47.34% avg_sensitivity=47.26%, avg_specificity=47.37% avg_auc=51.07%
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.692496 Test loss=0.691035 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6898981928825378
[5/24] Train loss=0.6907313466072083
[10/24] Train loss=0.6895709037780762
[15/24] Train loss=0.68863844871521
[20/24] Train loss=0.6879492402076721
Test set avg_accuracy=64.48% avg_sensitivity=22.90%, avg_specificity=78.31% avg_auc=51.16%
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.689185 Test loss=0.687738 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6865185499191284
[5/24] Train loss=0.6880146861076355
[10/24] Train loss=0.68643718957901
[15/24] Train loss=0.6854808926582336
[20/24] Train loss=0.6844309568405151
Test set avg_accuracy=64.48% avg_sensitivity=22.90%, avg_specificity=78.31% avg_auc=51.21%
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.686039 Test loss=0.684340 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.682877242565155
[5/24] Train loss=0.685137152671814
[10/24] Train loss=0.6829422116279602
[15/24] Train loss=0.6819635033607483
[20/24] Train loss=0.6805264949798584
Test set avg_accuracy=64.48% avg_sensitivity=22.90%, avg_specificity=78.31% avg_auc=51.13%
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.682602 Test loss=0.680638 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6790647506713867
[5/24] Train loss=0.6819971799850464
[10/24] Train loss=0.679303765296936
[15/24] Train loss=0.6780978441238403
[20/24] Train loss=0.6762453317642212
Test set avg_accuracy=64.48% avg_sensitivity=22.90%, avg_specificity=78.31% avg_auc=51.36%
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.678907 Test loss=0.676486 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6748860478401184
[5/24] Train loss=0.6783352494239807
[10/24] Train loss=0.6749312281608582
[15/24] Train loss=0.6733136177062988
[20/24] Train loss=0.6708260774612427
Test set avg_accuracy=64.48% avg_sensitivity=22.90%, avg_specificity=78.31% avg_auc=51.61%
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.674402 Test loss=0.671085 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.669317364692688
[5/24] Train loss=0.6736406087875366
[10/24] Train loss=0.6690340042114258
[15/24] Train loss=0.6667636632919312
[20/24] Train loss=0.6632207036018372
Test set avg_accuracy=64.48% avg_sensitivity=22.90%, avg_specificity=78.31% avg_auc=51.55%
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.668307 Test loss=0.663469 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6613706946372986
[5/24] Train loss=0.6668211817741394
[10/24] Train loss=0.660339891910553
[15/24] Train loss=0.6570066213607788
[20/24] Train loss=0.6516529321670532
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.71%
Best model saved!! Metric=-99.25558711438478!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.659313 Test loss=0.651979 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6491894125938416
[5/24] Train loss=0.6566156148910522
[10/24] Train loss=0.6468971371650696
[15/24] Train loss=0.641732394695282
[20/24] Train loss=0.6329708695411682
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.84%
Best model saved!! Metric=-99.1232017455591!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.645370 Test loss=0.633864 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.629740834236145
[5/24] Train loss=0.640718936920166
[10/24] Train loss=0.6254063248634338
[15/24] Train loss=0.617634117603302
[20/24] Train loss=0.6034119725227356
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.97%
Best model saved!! Metric=-98.9887706966982!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.623293 Test loss=0.606015 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5993649363517761
[5/24] Train loss=0.6182851195335388
[10/24] Train loss=0.5952860116958618
[15/24] Train loss=0.585685133934021
[20/24] Train loss=0.5698103904724121
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.49%
Best model saved!! Metric=-98.47592957389503!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.594645 Test loss=0.576957 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5689879655838013
[5/24] Train loss=0.6013952493667603
[10/24] Train loss=0.5745912194252014
[15/24] Train loss=0.5669278502464294
[20/24] Train loss=0.5531275272369385
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.70%
Best model saved!! Metric=-96.26160313350773!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.575791 Test loss=0.564517 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5562558770179749
[5/24] Train loss=0.5940202474594116
[10/24] Train loss=0.5663526058197021
[15/24] Train loss=0.5597672462463379
[20/24] Train loss=0.5446626543998718
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=56.30%
Best model saved!! Metric=-94.66430267081293!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.567951 Test loss=0.559555 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5496931076049805
[5/24] Train loss=0.5910370349884033
[10/24] Train loss=0.5615048408508301
[15/24] Train loss=0.5557263493537903
[20/24] Train loss=0.5390276908874512
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=59.13%
Best model saved!! Metric=-91.83347525026429!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.564295 Test loss=0.557908 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5459991693496704
[5/24] Train loss=0.5885252952575684
[10/24] Train loss=0.5596358180046082
[15/24] Train loss=0.5514557957649231
[20/24] Train loss=0.5333551168441772
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=61.65%
Best model saved!! Metric=-89.30979401464457!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.560458 Test loss=0.554660 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5408687591552734
[5/24] Train loss=0.5844748616218567
[10/24] Train loss=0.553295910358429
[15/24] Train loss=0.545574963092804
[20/24] Train loss=0.5271431803703308
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=66.29%
Best model saved!! Metric=-84.66652123796612!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.554550 Test loss=0.550717 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5293400287628174
[5/24] Train loss=0.5774286985397339
[10/24] Train loss=0.5429790616035461
[15/24] Train loss=0.5357415676116943
[20/24] Train loss=0.5150461196899414
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=69.47%
Best model saved!! Metric=-81.49064371590741!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.545195 Test loss=0.550919 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5107434988021851
[5/24] Train loss=0.5655577778816223
[10/24] Train loss=0.5262672901153564
[15/24] Train loss=0.5159596800804138
[20/24] Train loss=0.5006576180458069
Test set avg_accuracy=74.47% avg_sensitivity=7.67%, avg_specificity=96.69% avg_auc=67.93%
Best model saved!! Metric=-79.25222123244913!!
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.530492 Test loss=0.599225 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.48428353667259216
[5/24] Train loss=0.5519922375679016
[10/24] Train loss=0.5027873516082764
[15/24] Train loss=0.49697044491767883
[20/24] Train loss=0.48200127482414246
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=57.07%
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.514315 Test loss=0.652838 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.46264269948005676
[5/24] Train loss=0.5340058207511902
[10/24] Train loss=0.4877709150314331
[15/24] Train loss=0.47876885533332825
[20/24] Train loss=0.4792656898498535
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.26%
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.499331 Test loss=0.650735 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.448950856924057
[5/24] Train loss=0.5264343619346619
[10/24] Train loss=0.4762972593307495
[15/24] Train loss=0.47519659996032715
[20/24] Train loss=0.46946853399276733
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.98%
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.491043 Test loss=0.644281 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.4415040910243988
[5/24] Train loss=0.514941394329071
[10/24] Train loss=0.4733183681964874
[15/24] Train loss=0.4622832238674164
[20/24] Train loss=0.46096011996269226
Test set avg_accuracy=53.89% avg_sensitivity=58.84%, avg_specificity=52.25% avg_auc=55.66%
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.484805 Test loss=0.665566 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.4497808516025543
[5/24] Train loss=0.5146715641021729
[10/24] Train loss=0.46670427918434143
[15/24] Train loss=0.4653318524360657
[20/24] Train loss=0.4640945792198181
Test set avg_accuracy=59.47% avg_sensitivity=60.88%, avg_specificity=59.00% avg_auc=59.98%
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.483544 Test loss=0.647271 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.43140584230422974
[5/24] Train loss=0.5074521899223328
[10/24] Train loss=0.46134886145591736
[15/24] Train loss=0.4527907967567444
[20/24] Train loss=0.4523158669471741
Test set avg_accuracy=46.22% avg_sensitivity=83.99%, avg_specificity=33.66% avg_auc=57.36%
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.472904 Test loss=0.670493 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.42360517382621765
[5/24] Train loss=0.49833205342292786
[10/24] Train loss=0.4542957544326782
[15/24] Train loss=0.445033997297287
[20/24] Train loss=0.43693822622299194
Test set avg_accuracy=47.58% avg_sensitivity=80.28%, avg_specificity=36.70% avg_auc=57.85%
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.465799 Test loss=0.658333 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.4084397852420807
[5/24] Train loss=0.48777857422828674
[10/24] Train loss=0.43914565443992615
[15/24] Train loss=0.4266716539859772
[20/24] Train loss=0.4080237150192261
Test set avg_accuracy=45.85% avg_sensitivity=82.94%, avg_specificity=33.51% avg_auc=60.56%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.447717 Test loss=0.671105 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3943400979042053
[5/24] Train loss=0.47167348861694336
[10/24] Train loss=0.430761456489563
[15/24] Train loss=0.42233806848526
[20/24] Train loss=0.3921804428100586
Test set avg_accuracy=52.46% avg_sensitivity=77.57%, avg_specificity=44.11% avg_auc=62.23%
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.437039 Test loss=0.659672 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3699820935726166
[5/24] Train loss=0.44841527938842773
[10/24] Train loss=0.4205568730831146
[15/24] Train loss=0.41298753023147583
[20/24] Train loss=0.38812577724456787
Test set avg_accuracy=48.36% avg_sensitivity=83.83%, avg_specificity=36.56% avg_auc=65.85%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.428964 Test loss=0.659245 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.36853066086769104
[5/24] Train loss=0.45881956815719604
[10/24] Train loss=0.4103962182998657
[15/24] Train loss=0.412875771522522
[20/24] Train loss=0.38150709867477417
Test set avg_accuracy=46.26% avg_sensitivity=85.34%, avg_specificity=33.26% avg_auc=63.90%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.422129 Test loss=0.673822 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3628571331501007
[5/24] Train loss=0.44387343525886536
[10/24] Train loss=0.4170299768447876
[15/24] Train loss=0.4059756398200989
[20/24] Train loss=0.3791996240615845
Test set avg_accuracy=53.89% avg_sensitivity=76.00%, avg_specificity=46.54% avg_auc=65.24%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.419679 Test loss=0.646751 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3528660535812378
[5/24] Train loss=0.4328061044216156
[10/24] Train loss=0.408195823431015
[15/24] Train loss=0.4176928997039795
[20/24] Train loss=0.3865591287612915
Test set avg_accuracy=51.00% avg_sensitivity=81.43%, avg_specificity=40.88% avg_auc=66.38%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.417503 Test loss=0.658301 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.35283297300338745
[5/24] Train loss=0.4357421100139618
[10/24] Train loss=0.3939753472805023
[15/24] Train loss=0.3930562436580658
[20/24] Train loss=0.3551377058029175
Test set avg_accuracy=55.52% avg_sensitivity=77.00%, avg_specificity=48.38% avg_auc=67.43%
Best model saved!! Metric=-77.67916836838279!!
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.412834 Test loss=0.636916 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.35375767946243286
[5/24] Train loss=0.4311559498310089
[10/24] Train loss=0.38968729972839355
[15/24] Train loss=0.391457200050354
[20/24] Train loss=0.3647560179233551
Test set avg_accuracy=55.10% avg_sensitivity=79.50%, avg_specificity=46.99% avg_auc=66.94%
Best model saved!! Metric=-77.47137310094588!!
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.409694 Test loss=0.646336 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.35643377900123596
[5/24] Train loss=0.42318055033683777
[10/24] Train loss=0.3937402367591858
[15/24] Train loss=0.38771188259124756
[20/24] Train loss=0.368588924407959
Test set avg_accuracy=57.60% avg_sensitivity=77.36%, avg_specificity=51.03% avg_auc=72.64%
Best model saved!! Metric=-67.3609681567726!!
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.408902 Test loss=0.618942 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3580305874347687
[5/24] Train loss=0.4342000186443329
[10/24] Train loss=0.4074056148529053
[15/24] Train loss=0.3938964903354645
[20/24] Train loss=0.36390769481658936
Test set avg_accuracy=55.87% avg_sensitivity=76.21%, avg_specificity=49.11% avg_auc=67.96%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.413576 Test loss=0.634894 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3753901720046997
[5/24] Train loss=0.42948395013809204
[10/24] Train loss=0.3974801301956177
[15/24] Train loss=0.389547735452652
[20/24] Train loss=0.3680492639541626
Test set avg_accuracy=52.30% avg_sensitivity=82.37%, avg_specificity=42.30% avg_auc=69.37%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.410513 Test loss=0.651139 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3542258143424988
[5/24] Train loss=0.429436057806015
[10/24] Train loss=0.38065725564956665
[15/24] Train loss=0.3879127502441406
[20/24] Train loss=0.35454288125038147
Test set avg_accuracy=59.95% avg_sensitivity=73.03%, avg_specificity=55.60% avg_auc=67.91%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.407933 Test loss=0.620472 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.344648540019989
[5/24] Train loss=0.42769870162010193
[10/24] Train loss=0.3834123909473419
[15/24] Train loss=0.3857633173465729
[20/24] Train loss=0.3558467924594879
Test set avg_accuracy=57.49% avg_sensitivity=79.13%, avg_specificity=50.29% avg_auc=70.69%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.402971 Test loss=0.627540 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.34823834896087646
[5/24] Train loss=0.42187100648880005
[10/24] Train loss=0.38074198365211487
[15/24] Train loss=0.3858240246772766
[20/24] Train loss=0.36790692806243896
Test set avg_accuracy=50.95% avg_sensitivity=83.88%, avg_specificity=40.00% avg_auc=67.55%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.401924 Test loss=0.660908 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3462752103805542
[5/24] Train loss=0.4107262194156647
[10/24] Train loss=0.3787935674190521
[15/24] Train loss=0.3864407539367676
[20/24] Train loss=0.3466910123825073
Test set avg_accuracy=59.08% avg_sensitivity=78.20%, avg_specificity=52.72% avg_auc=71.40%
Best model saved!! Metric=-64.61442666781873!!
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.398166 Test loss=0.620112 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.35749661922454834
[5/24] Train loss=0.4234701693058014
[10/24] Train loss=0.39350536465644836
[15/24] Train loss=0.39924517273902893
[20/24] Train loss=0.35722917318344116
Test set avg_accuracy=67.84% avg_sensitivity=67.45%, avg_specificity=67.97% avg_auc=74.66%
Best model saved!! Metric=-48.08626691968607!!
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.408021 Test loss=0.578312 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.34589701890945435
[5/24] Train loss=0.4184218645095825
[10/24] Train loss=0.3882354199886322
[15/24] Train loss=0.3852092921733856
[20/24] Train loss=0.353592187166214
Test set avg_accuracy=65.07% avg_sensitivity=70.84%, avg_specificity=63.14% avg_auc=69.52%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.401797 Test loss=0.607114 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3501826822757721
[5/24] Train loss=0.4222238063812256
[10/24] Train loss=0.38888779282569885
[15/24] Train loss=0.3886701166629791
[20/24] Train loss=0.3440811336040497
Test set avg_accuracy=61.60% avg_sensitivity=77.00%, avg_specificity=56.48% avg_auc=73.07%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.404358 Test loss=0.603858 Current lr=[0.00029967723776099]

[0/24] Train loss=0.34947729110717773
[5/24] Train loss=0.4148435890674591
[10/24] Train loss=0.3792136013507843
[15/24] Train loss=0.3903406262397766
[20/24] Train loss=0.3568555414676666
Test set avg_accuracy=62.93% avg_sensitivity=70.47%, avg_specificity=60.42% avg_auc=68.26%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.401729 Test loss=0.616165 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3437049388885498
[5/24] Train loss=0.40957993268966675
[10/24] Train loss=0.37651413679122925
[15/24] Train loss=0.39108943939208984
[20/24] Train loss=0.35616201162338257
Test set avg_accuracy=63.23% avg_sensitivity=75.74%, avg_specificity=59.07% avg_auc=74.74%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.400391 Test loss=0.593676 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.37402990460395813
[5/24] Train loss=0.4201470911502838
[10/24] Train loss=0.38429948687553406
[15/24] Train loss=0.3909069895744324
[20/24] Train loss=0.35476648807525635
Test set avg_accuracy=60.95% avg_sensitivity=74.23%, avg_specificity=56.53% avg_auc=68.61%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.407695 Test loss=0.623682 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3573281764984131
[5/24] Train loss=0.4087584316730499
[10/24] Train loss=0.38839614391326904
[15/24] Train loss=0.3969057500362396
[20/24] Train loss=0.3595629334449768
Test set avg_accuracy=64.53% avg_sensitivity=69.64%, avg_specificity=62.83% avg_auc=70.54%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.402203 Test loss=0.594985 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.354682058095932
[5/24] Train loss=0.4112216532230377
[10/24] Train loss=0.3799055814743042
[15/24] Train loss=0.37892821431159973
[20/24] Train loss=0.344136506319046
Test set avg_accuracy=61.88% avg_sensitivity=76.73%, avg_specificity=56.93% avg_auc=70.67%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.395389 Test loss=0.616780 Current lr=[0.000298904600941902]

[0/24] Train loss=0.33904439210891724
[5/24] Train loss=0.4009947180747986
[10/24] Train loss=0.377262145280838
[15/24] Train loss=0.3789660930633545
[20/24] Train loss=0.3462618887424469
Test set avg_accuracy=61.16% avg_sensitivity=77.93%, avg_specificity=55.58% avg_auc=71.51%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.393327 Test loss=0.616645 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3466135263442993
[5/24] Train loss=0.4051818549633026
[10/24] Train loss=0.3764469027519226
[15/24] Train loss=0.3874647915363312
[20/24] Train loss=0.3548867702484131
Test set avg_accuracy=66.39% avg_sensitivity=69.12%, avg_specificity=65.49% avg_auc=75.45%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.396073 Test loss=0.578249 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3551177382469177
[5/24] Train loss=0.4135311245918274
[10/24] Train loss=0.3870912194252014
[15/24] Train loss=0.3829532265663147
[20/24] Train loss=0.3438754677772522
Test set avg_accuracy=62.94% avg_sensitivity=73.40%, avg_specificity=59.47% avg_auc=71.87%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.398212 Test loss=0.601018 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.33703118562698364
[5/24] Train loss=0.40049421787261963
[10/24] Train loss=0.37414371967315674
[15/24] Train loss=0.38260316848754883
[20/24] Train loss=0.3400954008102417
Test set avg_accuracy=58.41% avg_sensitivity=81.17%, avg_specificity=50.84% avg_auc=71.19%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.389040 Test loss=0.628816 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3333408236503601
[5/24] Train loss=0.4014717936515808
[10/24] Train loss=0.37419331073760986
[15/24] Train loss=0.40076443552970886
[20/24] Train loss=0.351917028427124
Test set avg_accuracy=65.27% avg_sensitivity=72.61%, avg_specificity=62.83% avg_auc=72.72%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.392817 Test loss=0.588061 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3448124825954437
[5/24] Train loss=0.39801695942878723
[10/24] Train loss=0.3865281045436859
[15/24] Train loss=0.4038725793361664
[20/24] Train loss=0.35917434096336365
Test set avg_accuracy=68.20% avg_sensitivity=68.75%, avg_specificity=68.02% avg_auc=74.36%
Best model saved!! Metric=-46.66558769066576!!
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.398459 Test loss=0.575155 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.35684168338775635
[5/24] Train loss=0.4063524007797241
[10/24] Train loss=0.3836430311203003
[15/24] Train loss=0.3813910484313965
[20/24] Train loss=0.34303534030914307
Test set avg_accuracy=61.24% avg_sensitivity=79.66%, avg_specificity=55.11% avg_auc=74.06%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.394864 Test loss=0.603898 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.341166615486145
[5/24] Train loss=0.3969095051288605
[10/24] Train loss=0.3672032952308655
[15/24] Train loss=0.38259464502334595
[20/24] Train loss=0.3673975467681885
Test set avg_accuracy=60.81% avg_sensitivity=76.73%, avg_specificity=55.51% avg_auc=71.50%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.391254 Test loss=0.610513 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3390962779521942
[5/24] Train loss=0.39941999316215515
[10/24] Train loss=0.36539125442504883
[15/24] Train loss=0.37600043416023254
[20/24] Train loss=0.3398187756538391
Test set avg_accuracy=63.65% avg_sensitivity=74.33%, avg_specificity=60.09% avg_auc=71.51%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.392438 Test loss=0.600048 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3448399305343628
[5/24] Train loss=0.3943382501602173
[10/24] Train loss=0.37371447682380676
[15/24] Train loss=0.37730711698532104
[20/24] Train loss=0.34791749715805054
Test set avg_accuracy=62.99% avg_sensitivity=72.35%, avg_specificity=59.88% avg_auc=72.10%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.391795 Test loss=0.591314 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3472214639186859
[5/24] Train loss=0.39530229568481445
[10/24] Train loss=0.38235533237457275
[15/24] Train loss=0.38099515438079834
[20/24] Train loss=0.36988452076911926
Test set avg_accuracy=63.07% avg_sensitivity=74.96%, avg_specificity=59.12% avg_auc=71.65%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.397417 Test loss=0.606027 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3611784875392914
[5/24] Train loss=0.40671923756599426
[10/24] Train loss=0.3746618330478668
[15/24] Train loss=0.3938277065753937
[20/24] Train loss=0.3453059196472168
Test set avg_accuracy=64.05% avg_sensitivity=73.92%, avg_specificity=60.77% avg_auc=74.12%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.397979 Test loss=0.591899 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.35685545206069946
[5/24] Train loss=0.4062455892562866
[10/24] Train loss=0.40584415197372437
[15/24] Train loss=0.3889193534851074
[20/24] Train loss=0.36042386293411255
Test set avg_accuracy=61.17% avg_sensitivity=79.13%, avg_specificity=55.20% avg_auc=74.48%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.403228 Test loss=0.602940 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.35352927446365356
[5/24] Train loss=0.40175870060920715
[10/24] Train loss=0.37318772077560425
[15/24] Train loss=0.38103461265563965
[20/24] Train loss=0.3447191119194031
Test set avg_accuracy=69.22% avg_sensitivity=66.09%, avg_specificity=70.26% avg_auc=73.20%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.392938 Test loss=0.570214 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.34198659658432007
[5/24] Train loss=0.4034258723258972
[10/24] Train loss=0.3743668496608734
[15/24] Train loss=0.3757460415363312
[20/24] Train loss=0.339056134223938
Test set avg_accuracy=67.33% avg_sensitivity=68.60%, avg_specificity=66.91% avg_auc=69.91%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.389010 Test loss=0.601799 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3329775035381317
[5/24] Train loss=0.3973914682865143
[10/24] Train loss=0.36924082040786743
[15/24] Train loss=0.3756694495677948
[20/24] Train loss=0.3495299518108368
Test set avg_accuracy=71.67% avg_sensitivity=65.21%, avg_specificity=73.82% avg_auc=72.07%
Best model saved!! Metric=-43.23782279541091!!
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.386080 Test loss=0.571166 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.33857542276382446
[5/24] Train loss=0.4028646647930145
[10/24] Train loss=0.3795880079269409
[15/24] Train loss=0.39832401275634766
[20/24] Train loss=0.3412489891052246
Test set avg_accuracy=74.18% avg_sensitivity=64.37%, avg_specificity=77.44% avg_auc=70.51%
Best model saved!! Metric=-39.49478253083274!!
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.394105 Test loss=0.587037 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3373821973800659
[5/24] Train loss=0.3955797255039215
[10/24] Train loss=0.37834808230400085
[15/24] Train loss=0.3810417354106903
[20/24] Train loss=0.3480994701385498
Test set avg_accuracy=66.35% avg_sensitivity=76.16%, avg_specificity=63.09% avg_auc=75.84%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.391737 Test loss=0.581577 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.34073978662490845
[5/24] Train loss=0.38756367564201355
[10/24] Train loss=0.36611995100975037
[15/24] Train loss=0.37319695949554443
[20/24] Train loss=0.3340054750442505
Test set avg_accuracy=64.18% avg_sensitivity=77.10%, avg_specificity=59.88% avg_auc=73.37%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.385960 Test loss=0.594519 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.35070374608039856
[5/24] Train loss=0.38767823576927185
[10/24] Train loss=0.36903634667396545
[15/24] Train loss=0.3647453486919403
[20/24] Train loss=0.34530195593833923
Test set avg_accuracy=58.22% avg_sensitivity=83.88%, avg_specificity=49.68% avg_auc=74.28%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.382966 Test loss=0.620347 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.338032990694046
[5/24] Train loss=0.3911817669868469
[10/24] Train loss=0.36113694310188293
[15/24] Train loss=0.37013766169548035
[20/24] Train loss=0.3416006565093994
Test set avg_accuracy=62.38% avg_sensitivity=77.93%, avg_specificity=57.21% avg_auc=72.03%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.384459 Test loss=0.612904 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3389754891395569
[5/24] Train loss=0.38807883858680725
[10/24] Train loss=0.3706713616847992
[15/24] Train loss=0.3708210289478302
[20/24] Train loss=0.35045403242111206
Test set avg_accuracy=61.12% avg_sensitivity=78.66%, avg_specificity=55.28% avg_auc=71.67%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.387773 Test loss=0.618895 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3509257137775421
[5/24] Train loss=0.4001903831958771
[10/24] Train loss=0.3729439377784729
[15/24] Train loss=0.37239953875541687
[20/24] Train loss=0.33947667479515076
Test set avg_accuracy=68.02% avg_sensitivity=66.56%, avg_specificity=68.51% avg_auc=72.56%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.389382 Test loss=0.575823 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3328670561313629
[5/24] Train loss=0.38350197672843933
[10/24] Train loss=0.362765908241272
[15/24] Train loss=0.369498074054718
[20/24] Train loss=0.33387845754623413
Test set avg_accuracy=63.58% avg_sensitivity=77.00%, avg_specificity=59.12% avg_auc=71.73%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.382456 Test loss=0.605079 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.34013012051582336
[5/24] Train loss=0.39995408058166504
[10/24] Train loss=0.37225547432899475
[15/24] Train loss=0.3825518488883972
[20/24] Train loss=0.3437475264072418
Test set avg_accuracy=63.42% avg_sensitivity=77.15%, avg_specificity=58.86% avg_auc=72.48%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.386436 Test loss=0.606816 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3393198847770691
[5/24] Train loss=0.38338905572891235
[10/24] Train loss=0.36560600996017456
[15/24] Train loss=0.3791996240615845
[20/24] Train loss=0.3279130458831787
Test set avg_accuracy=61.90% avg_sensitivity=79.66%, avg_specificity=56.00% avg_auc=72.30%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.381092 Test loss=0.612953 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.33664488792419434
[5/24] Train loss=0.3850366771221161
[10/24] Train loss=0.35795605182647705
[15/24] Train loss=0.37215977907180786
[20/24] Train loss=0.33626484870910645
Test set avg_accuracy=65.17% avg_sensitivity=75.53%, avg_specificity=61.72% avg_auc=72.68%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.376959 Test loss=0.595712 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.32996827363967896
[5/24] Train loss=0.38494300842285156
[10/24] Train loss=0.3566839396953583
[15/24] Train loss=0.3633213937282562
[20/24] Train loss=0.3373335003852844
Test set avg_accuracy=64.05% avg_sensitivity=75.80%, avg_specificity=60.14% avg_auc=71.36%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.376944 Test loss=0.605972 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.32993870973587036
[5/24] Train loss=0.4233872890472412
[10/24] Train loss=0.3796288073062897
[15/24] Train loss=0.38960906863212585
[20/24] Train loss=0.33306193351745605
Test set avg_accuracy=70.30% avg_sensitivity=70.01%, avg_specificity=70.40% avg_auc=76.37%
Best model saved!! Metric=-38.9229484382104!!
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.386284 Test loss=0.554025 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3420194685459137
[5/24] Train loss=0.38779184222221375
[10/24] Train loss=0.3738393485546112
[15/24] Train loss=0.3724246919155121
[20/24] Train loss=0.33163583278656006
Test set avg_accuracy=61.13% avg_sensitivity=81.22%, avg_specificity=54.45% avg_auc=71.66%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.380867 Test loss=0.617612 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3271997272968292
[5/24] Train loss=0.38246360421180725
[10/24] Train loss=0.3580896258354187
[15/24] Train loss=0.36694926023483276
[20/24] Train loss=0.32755595445632935
Test set avg_accuracy=60.98% avg_sensitivity=82.06%, avg_specificity=53.96% avg_auc=73.12%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.375928 Test loss=0.615101 Current lr=[0.000224838296036774]

[0/24] Train loss=0.32666218280792236
[5/24] Train loss=0.3980090618133545
[10/24] Train loss=0.35823601484298706
[15/24] Train loss=0.36760827898979187
[20/24] Train loss=0.3201802372932434
Test set avg_accuracy=61.50% avg_sensitivity=77.52%, avg_specificity=56.17% avg_auc=72.98%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.374742 Test loss=0.602516 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.33292722702026367
[5/24] Train loss=0.3795011639595032
[10/24] Train loss=0.36023321747779846
[15/24] Train loss=0.36510899662971497
[20/24] Train loss=0.3318058252334595
Test set avg_accuracy=63.10% avg_sensitivity=77.88%, avg_specificity=58.18% avg_auc=72.81%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.373861 Test loss=0.603989 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3284509778022766
[5/24] Train loss=0.3849535286426544
[10/24] Train loss=0.3572998344898224
[15/24] Train loss=0.38431206345558167
[20/24] Train loss=0.33767005801200867
Test set avg_accuracy=64.88% avg_sensitivity=77.41%, avg_specificity=60.71% avg_auc=73.60%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.379460 Test loss=0.594723 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.33819204568862915
[5/24] Train loss=0.3811550736427307
[10/24] Train loss=0.3605053722858429
[15/24] Train loss=0.3639732301235199
[20/24] Train loss=0.3265700340270996
Test set avg_accuracy=62.46% avg_sensitivity=79.86%, avg_specificity=56.67% avg_auc=71.48%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.375887 Test loss=0.616821 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3249815106391907
[5/24] Train loss=0.3820064067840576
[10/24] Train loss=0.35642650723457336
[15/24] Train loss=0.36141908168792725
[20/24] Train loss=0.3301841616630554
Test set avg_accuracy=60.13% avg_sensitivity=81.59%, avg_specificity=52.99% avg_auc=72.12%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.372116 Test loss=0.619828 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.32049936056137085
[5/24] Train loss=0.3829343020915985
[10/24] Train loss=0.35878297686576843
[15/24] Train loss=0.371042400598526
[20/24] Train loss=0.33549806475639343
Test set avg_accuracy=71.84% avg_sensitivity=68.75%, avg_specificity=72.86% avg_auc=71.08%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.375771 Test loss=0.598465 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3316061198711395
[5/24] Train loss=0.3736506700515747
[10/24] Train loss=0.35638099908828735
[15/24] Train loss=0.37574344873428345
[20/24] Train loss=0.33237242698669434
Test set avg_accuracy=63.55% avg_sensitivity=75.17%, avg_specificity=59.69% avg_auc=69.18%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.374443 Test loss=0.627627 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3338465690612793
[5/24] Train loss=0.3834104835987091
[10/24] Train loss=0.36577078700065613
[15/24] Train loss=0.36046192049980164
[20/24] Train loss=0.32725897431373596
Test set avg_accuracy=61.63% avg_sensitivity=80.44%, avg_specificity=55.37% avg_auc=73.10%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.375630 Test loss=0.612656 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.32332220673561096
[5/24] Train loss=0.37480592727661133
[10/24] Train loss=0.3562295436859131
[15/24] Train loss=0.363257497549057
[20/24] Train loss=0.32328030467033386
Test set avg_accuracy=59.53% avg_sensitivity=81.32%, avg_specificity=52.28% avg_auc=70.63%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.371848 Test loss=0.638212 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.32100871205329895
[5/24] Train loss=0.37696754932403564
[10/24] Train loss=0.3599119484424591
[15/24] Train loss=0.3585776686668396
[20/24] Train loss=0.3340691328048706
Test set avg_accuracy=65.34% avg_sensitivity=77.10%, avg_specificity=61.43% avg_auc=74.70%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.373682 Test loss=0.590310 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.33294206857681274
[5/24] Train loss=0.38534030318260193
[10/24] Train loss=0.3592064082622528
[15/24] Train loss=0.3694852292537689
[20/24] Train loss=0.32571253180503845
Test set avg_accuracy=64.60% avg_sensitivity=77.88%, avg_specificity=60.18% avg_auc=74.25%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.376023 Test loss=0.593494 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3292001783847809
[5/24] Train loss=0.37990960478782654
[10/24] Train loss=0.3601509928703308
[15/24] Train loss=0.363964706659317
[20/24] Train loss=0.3230329155921936
Test set avg_accuracy=62.17% avg_sensitivity=82.11%, avg_specificity=55.54% avg_auc=72.80%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.373802 Test loss=0.620347 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3216942250728607
[5/24] Train loss=0.37976133823394775
[10/24] Train loss=0.356365829706192
[15/24] Train loss=0.36821669340133667
[20/24] Train loss=0.3248904049396515
Test set avg_accuracy=62.38% avg_sensitivity=81.59%, avg_specificity=56.00% avg_auc=72.41%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.371552 Test loss=0.619877 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3213237226009369
[5/24] Train loss=0.37530526518821716
[10/24] Train loss=0.3584151268005371
[15/24] Train loss=0.3612622320652008
[20/24] Train loss=0.3177810311317444
Test set avg_accuracy=57.08% avg_sensitivity=86.70%, avg_specificity=47.23% avg_auc=71.65%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.370984 Test loss=0.651212 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.33186036348342896
[5/24] Train loss=0.37489280104637146
[10/24] Train loss=0.3672325909137726
[15/24] Train loss=0.366110622882843
[20/24] Train loss=0.33018192648887634
Test set avg_accuracy=62.92% avg_sensitivity=80.23%, avg_specificity=57.16% avg_auc=71.52%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.375624 Test loss=0.625396 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3214941620826721
[5/24] Train loss=0.3717564344406128
[10/24] Train loss=0.3516196012496948
[15/24] Train loss=0.36318686604499817
[20/24] Train loss=0.32725557684898376
Test set avg_accuracy=60.66% avg_sensitivity=79.08%, avg_specificity=54.54% avg_auc=68.73%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.370637 Test loss=0.649092 Current lr=[0.000156543481933168]

[0/24] Train loss=0.33270740509033203
[5/24] Train loss=0.3779469430446625
[10/24] Train loss=0.3547635078430176
[15/24] Train loss=0.3612149655818939
[20/24] Train loss=0.32285526394844055
Test set avg_accuracy=57.99% avg_sensitivity=83.67%, avg_specificity=49.45% avg_auc=69.31%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.371422 Test loss=0.660827 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3361058533191681
[5/24] Train loss=0.3771421015262604
[10/24] Train loss=0.3563215434551239
[15/24] Train loss=0.3598572015762329
[20/24] Train loss=0.32025015354156494
Test set avg_accuracy=56.91% avg_sensitivity=85.71%, avg_specificity=47.34% avg_auc=69.70%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.372101 Test loss=0.659446 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3301425576210022
[5/24] Train loss=0.3639160394668579
[10/24] Train loss=0.3542822003364563
[15/24] Train loss=0.36119794845581055
[20/24] Train loss=0.3197634220123291
Test set avg_accuracy=60.16% avg_sensitivity=81.22%, avg_specificity=53.15% avg_auc=69.29%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.367415 Test loss=0.647692 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.32561129331588745
[5/24] Train loss=0.36677446961402893
[10/24] Train loss=0.35970625281333923
[15/24] Train loss=0.36249053478240967
[20/24] Train loss=0.3181762993335724
Test set avg_accuracy=60.31% avg_sensitivity=82.84%, avg_specificity=52.82% avg_auc=71.46%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.364652 Test loss=0.633375 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.32025277614593506
[5/24] Train loss=0.3643856942653656
[10/24] Train loss=0.34845200181007385
[15/24] Train loss=0.35972362756729126
[20/24] Train loss=0.32047075033187866
Test set avg_accuracy=60.13% avg_sensitivity=81.01%, avg_specificity=53.18% avg_auc=69.67%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.364377 Test loss=0.642090 Current lr=[0.000134135431043539]

[0/24] Train loss=0.32246315479278564
[5/24] Train loss=0.36216089129447937
[10/24] Train loss=0.3523057997226715
[15/24] Train loss=0.3573748469352722
[20/24] Train loss=0.3220835030078888
Test set avg_accuracy=59.22% avg_sensitivity=82.68%, avg_specificity=51.41% avg_auc=69.31%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.364490 Test loss=0.660181 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3194388449192047
[5/24] Train loss=0.363768070936203
[10/24] Train loss=0.3555314540863037
[15/24] Train loss=0.3579098582267761
[20/24] Train loss=0.32055675983428955
Test set avg_accuracy=60.89% avg_sensitivity=81.90%, avg_specificity=53.90% avg_auc=71.40%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.363795 Test loss=0.637597 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3207935392856598
[5/24] Train loss=0.35777562856674194
[10/24] Train loss=0.35043370723724365
[15/24] Train loss=0.35723236203193665
[20/24] Train loss=0.3144408166408539
Test set avg_accuracy=58.48% avg_sensitivity=85.34%, avg_specificity=49.54% avg_auc=69.93%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.360775 Test loss=0.656829 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3125689923763275
[5/24] Train loss=0.36200761795043945
[10/24] Train loss=0.34554415941238403
[15/24] Train loss=0.3566148579120636
[20/24] Train loss=0.31636399030685425
Test set avg_accuracy=58.46% avg_sensitivity=83.78%, avg_specificity=50.04% avg_auc=70.40%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.359883 Test loss=0.654469 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.315656840801239
[5/24] Train loss=0.36201211810112
[10/24] Train loss=0.3631734848022461
[15/24] Train loss=0.3647003173828125
[20/24] Train loss=0.31570965051651
Test set avg_accuracy=64.13% avg_sensitivity=75.85%, avg_specificity=60.23% avg_auc=70.87%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.364909 Test loss=0.618648 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.32023900747299194
[5/24] Train loss=0.36004021763801575
[10/24] Train loss=0.34897202253341675
[15/24] Train loss=0.3560069501399994
[20/24] Train loss=0.3161466121673584
Test set avg_accuracy=62.77% avg_sensitivity=77.10%, avg_specificity=58.01% avg_auc=70.29%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.360674 Test loss=0.628055 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3159312605857849
[5/24] Train loss=0.3597443401813507
[10/24] Train loss=0.3480568528175354
[15/24] Train loss=0.35364431142807007
[20/24] Train loss=0.31745168566703796
Test set avg_accuracy=59.82% avg_sensitivity=82.84%, avg_specificity=52.16% avg_auc=70.12%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.358428 Test loss=0.645975 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3142702877521515
[5/24] Train loss=0.3566882014274597
[10/24] Train loss=0.3477610945701599
[15/24] Train loss=0.3539416790008545
[20/24] Train loss=0.31813886761665344
Test set avg_accuracy=58.49% avg_sensitivity=84.82%, avg_specificity=49.73% avg_auc=71.11%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.357898 Test loss=0.648501 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3130219280719757
[5/24] Train loss=0.3575301766395569
[10/24] Train loss=0.34434980154037476
[15/24] Train loss=0.3534967303276062
[20/24] Train loss=0.3131007254123688
Test set avg_accuracy=60.62% avg_sensitivity=82.52%, avg_specificity=53.34% avg_auc=70.21%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.355650 Test loss=0.644948 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3104885220527649
[5/24] Train loss=0.35410022735595703
[10/24] Train loss=0.3424869775772095
[15/24] Train loss=0.3512152433395386
[20/24] Train loss=0.3116109073162079
Test set avg_accuracy=59.71% avg_sensitivity=83.78%, avg_specificity=51.71% avg_auc=71.25%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.353485 Test loss=0.644166 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.30886319279670715
[5/24] Train loss=0.3534890115261078
[10/24] Train loss=0.3412506878376007
[15/24] Train loss=0.35016998648643494
[20/24] Train loss=0.310467928647995
Test set avg_accuracy=59.77% avg_sensitivity=83.36%, avg_specificity=51.92% avg_auc=70.76%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.352930 Test loss=0.647139 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3080328702926636
[5/24] Train loss=0.354022741317749
[10/24] Train loss=0.3409462869167328
[15/24] Train loss=0.35003936290740967
[20/24] Train loss=0.31092390418052673
Test set avg_accuracy=60.79% avg_sensitivity=83.05%, avg_specificity=53.39% avg_auc=71.09%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.352585 Test loss=0.640407 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.307727187871933
[5/24] Train loss=0.35143592953681946
[10/24] Train loss=0.34028151631355286
[15/24] Train loss=0.35004401206970215
[20/24] Train loss=0.3107006847858429
Test set avg_accuracy=60.46% avg_sensitivity=82.06%, avg_specificity=53.27% avg_auc=70.11%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.352006 Test loss=0.646346 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3078664541244507
[5/24] Train loss=0.3526715636253357
[10/24] Train loss=0.3403952419757843
[15/24] Train loss=0.3488566279411316
[20/24] Train loss=0.3115696310997009
Test set avg_accuracy=60.30% avg_sensitivity=82.32%, avg_specificity=52.98% avg_auc=70.38%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.352042 Test loss=0.645435 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3077287971973419
[5/24] Train loss=0.3505423665046692
[10/24] Train loss=0.34101882576942444
[15/24] Train loss=0.3490864634513855
[20/24] Train loss=0.3102392554283142
Test set avg_accuracy=60.40% avg_sensitivity=83.36%, avg_specificity=52.77% avg_auc=69.84%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.351650 Test loss=0.652554 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.30647024512290955
[5/24] Train loss=0.35023602843284607
[10/24] Train loss=0.34194687008857727
[15/24] Train loss=0.34861305356025696
[20/24] Train loss=0.3095926344394684
Test set avg_accuracy=60.35% avg_sensitivity=83.67%, avg_specificity=52.59% avg_auc=70.41%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.350691 Test loss=0.644704 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.30720254778862
[5/24] Train loss=0.3502466380596161
[10/24] Train loss=0.34136930108070374
[15/24] Train loss=0.34683552384376526
[20/24] Train loss=0.30877307057380676
Test set avg_accuracy=59.78% avg_sensitivity=84.04%, avg_specificity=51.71% avg_auc=70.09%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.350320 Test loss=0.651042 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.30752718448638916
[5/24] Train loss=0.3502505421638489
[10/24] Train loss=0.3424451947212219
[15/24] Train loss=0.3476904034614563
[20/24] Train loss=0.30724629759788513
Test set avg_accuracy=59.79% avg_sensitivity=82.42%, avg_specificity=52.26% avg_auc=69.47%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.350269 Test loss=0.653264 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.30646491050720215
[5/24] Train loss=0.35095205903053284
[10/24] Train loss=0.34067875146865845
[15/24] Train loss=0.3472321927547455
[20/24] Train loss=0.30628281831741333
Test set avg_accuracy=59.92% avg_sensitivity=83.46%, avg_specificity=52.09% avg_auc=69.37%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.349980 Test loss=0.656155 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.30637505650520325
[5/24] Train loss=0.3526180386543274
[10/24] Train loss=0.3402787744998932
[15/24] Train loss=0.3474130928516388
[20/24] Train loss=0.30500128865242004
Test set avg_accuracy=59.90% avg_sensitivity=82.79%, avg_specificity=52.28% avg_auc=69.23%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.350035 Test loss=0.657509 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.3060878813266754
[5/24] Train loss=0.35082685947418213
[10/24] Train loss=0.3401026725769043
[15/24] Train loss=0.34710434079170227
[20/24] Train loss=0.30432188510894775
Test set avg_accuracy=59.74% avg_sensitivity=83.88%, avg_specificity=51.71% avg_auc=69.33%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.349586 Test loss=0.659373 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3043190836906433
[5/24] Train loss=0.3486874997615814
[10/24] Train loss=0.3401157855987549
[15/24] Train loss=0.34669139981269836
[20/24] Train loss=0.3036468029022217
Test set avg_accuracy=59.75% avg_sensitivity=83.99%, avg_specificity=51.69% avg_auc=69.35%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.348274 Test loss=0.661210 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.30381834506988525
[5/24] Train loss=0.3482499122619629
[10/24] Train loss=0.33823221921920776
[15/24] Train loss=0.3463283181190491
[20/24] Train loss=0.30488482117652893
Test set avg_accuracy=59.64% avg_sensitivity=84.72%, avg_specificity=51.29% avg_auc=69.67%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.347855 Test loss=0.661430 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.30206263065338135
[5/24] Train loss=0.3468815088272095
[10/24] Train loss=0.33912354707717896
[15/24] Train loss=0.34606701135635376
[20/24] Train loss=0.30335554480552673
Test set avg_accuracy=59.64% avg_sensitivity=83.67%, avg_specificity=51.64% avg_auc=69.63%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.347587 Test loss=0.658994 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.30352896451950073
[5/24] Train loss=0.34783923625946045
[10/24] Train loss=0.33759650588035583
[15/24] Train loss=0.3471502363681793
[20/24] Train loss=0.3024176359176636
Test set avg_accuracy=59.82% avg_sensitivity=83.67%, avg_specificity=51.88% avg_auc=69.33%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.347639 Test loss=0.660854 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3032047748565674
[5/24] Train loss=0.3472375273704529
[10/24] Train loss=0.33764103055000305
[15/24] Train loss=0.3465713560581207
[20/24] Train loss=0.3017074465751648
Test set avg_accuracy=59.60% avg_sensitivity=84.04%, avg_specificity=51.47% avg_auc=69.37%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.347023 Test loss=0.663698 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3020138442516327
[5/24] Train loss=0.34788140654563904
[10/24] Train loss=0.3371434807777405
[15/24] Train loss=0.3463524580001831
[20/24] Train loss=0.30115261673927307
Test set avg_accuracy=59.93% avg_sensitivity=82.58%, avg_specificity=52.40% avg_auc=69.23%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.347029 Test loss=0.661163 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.30181190371513367
[5/24] Train loss=0.3459669351577759
[10/24] Train loss=0.33783674240112305
[15/24] Train loss=0.3460085988044739
[20/24] Train loss=0.30166321992874146
Test set avg_accuracy=59.40% avg_sensitivity=83.88%, avg_specificity=51.26% avg_auc=69.43%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.346594 Test loss=0.663076 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.302460253238678
[5/24] Train loss=0.3455168306827545
[10/24] Train loss=0.3380463421344757
[15/24] Train loss=0.34645816683769226
[20/24] Train loss=0.29990464448928833
Test set avg_accuracy=59.65% avg_sensitivity=83.78%, avg_specificity=51.62% avg_auc=69.72%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.346659 Test loss=0.659725 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.30099576711654663
[5/24] Train loss=0.3464611768722534
[10/24] Train loss=0.33738982677459717
[15/24] Train loss=0.34502533078193665
[20/24] Train loss=0.29979950189590454
Test set avg_accuracy=59.70% avg_sensitivity=84.09%, avg_specificity=51.59% avg_auc=69.34%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.345869 Test loss=0.665629 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3004177212715149
[5/24] Train loss=0.3456174433231354
[10/24] Train loss=0.3365541994571686
[15/24] Train loss=0.34534144401550293
[20/24] Train loss=0.2990778684616089
Test set avg_accuracy=59.44% avg_sensitivity=83.93%, avg_specificity=51.29% avg_auc=69.20%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.345634 Test loss=0.666356 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.2999975383281708
[5/24] Train loss=0.34585297107696533
[10/24] Train loss=0.3361459970474243
[15/24] Train loss=0.34453490376472473
[20/24] Train loss=0.29814413189888
Test set avg_accuracy=59.08% avg_sensitivity=84.25%, avg_specificity=50.70% avg_auc=69.15%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.345063 Test loss=0.669367 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.2994440793991089
[5/24] Train loss=0.3451382517814636
[10/24] Train loss=0.33556538820266724
[15/24] Train loss=0.3447824716567993
[20/24] Train loss=0.29892706871032715
Test set avg_accuracy=59.00% avg_sensitivity=83.72%, avg_specificity=50.77% avg_auc=69.14%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.344708 Test loss=0.668993 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.29887738823890686
[5/24] Train loss=0.3466440439224243
[10/24] Train loss=0.33551958203315735
[15/24] Train loss=0.34472760558128357
[20/24] Train loss=0.29873743653297424
Test set avg_accuracy=59.11% avg_sensitivity=83.78%, avg_specificity=50.91% avg_auc=69.27%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.344726 Test loss=0.668950 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.2988285422325134
[5/24] Train loss=0.34475937485694885
[10/24] Train loss=0.3351629376411438
[15/24] Train loss=0.34467387199401855
[20/24] Train loss=0.2981134057044983
Test set avg_accuracy=59.19% avg_sensitivity=83.78%, avg_specificity=51.02% avg_auc=69.15%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.344341 Test loss=0.670066 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.2989500164985657
[5/24] Train loss=0.3433491885662079
[10/24] Train loss=0.33549964427948
[15/24] Train loss=0.3443770706653595
[20/24] Train loss=0.29806211590766907
Test set avg_accuracy=58.92% avg_sensitivity=84.40%, avg_specificity=50.44% avg_auc=69.39%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.343912 Test loss=0.670608 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.2981749475002289
[5/24] Train loss=0.3433530032634735
[10/24] Train loss=0.33513954281806946
[15/24] Train loss=0.34404775500297546
[20/24] Train loss=0.29766586422920227
Test set avg_accuracy=58.89% avg_sensitivity=84.30%, avg_specificity=50.44% avg_auc=69.36%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.343564 Test loss=0.670928 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.2980867326259613
[5/24] Train loss=0.34339478611946106
[10/24] Train loss=0.3349148631095886
[15/24] Train loss=0.3438448905944824
[20/24] Train loss=0.29716742038726807
Test set avg_accuracy=58.92% avg_sensitivity=83.78%, avg_specificity=50.65% avg_auc=69.16%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.343283 Test loss=0.671977 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.2976573407649994
[5/24] Train loss=0.342569500207901
[10/24] Train loss=0.33479630947113037
[15/24] Train loss=0.34376758337020874
[20/24] Train loss=0.2964589595794678
Test set avg_accuracy=59.01% avg_sensitivity=84.04%, avg_specificity=50.69% avg_auc=69.13%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.343064 Test loss=0.672047 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.29734209179878235
[5/24] Train loss=0.3424462080001831
[10/24] Train loss=0.33460965752601624
[15/24] Train loss=0.343666672706604
[20/24] Train loss=0.29628005623817444
Test set avg_accuracy=58.76% avg_sensitivity=84.09%, avg_specificity=50.34% avg_auc=69.13%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.342894 Test loss=0.673031 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.29711446166038513
[5/24] Train loss=0.3423003554344177
[10/24] Train loss=0.3346039950847626
[15/24] Train loss=0.343645304441452
[20/24] Train loss=0.2961753308773041
Test set avg_accuracy=58.75% avg_sensitivity=84.09%, avg_specificity=50.32% avg_auc=69.15%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.342789 Test loss=0.673177 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.29700446128845215
[5/24] Train loss=0.3420971632003784
[10/24] Train loss=0.3344727158546448
[15/24] Train loss=0.3436413109302521
[20/24] Train loss=0.2959379255771637
Test set avg_accuracy=58.74% avg_sensitivity=84.09%, avg_specificity=50.30% avg_auc=69.11%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.342692 Test loss=0.673604 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.2968187630176544
[5/24] Train loss=0.34202292561531067
[10/24] Train loss=0.33440133929252625
[15/24] Train loss=0.3435927629470825
[20/24] Train loss=0.295885294675827
Test set avg_accuracy=58.74% avg_sensitivity=84.14%, avg_specificity=50.29% avg_auc=69.12%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.342618 Test loss=0.673836 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.29674163460731506
[5/24] Train loss=0.3419131636619568
[10/24] Train loss=0.3343575596809387
[15/24] Train loss=0.3435765206813812
[20/24] Train loss=0.2957852780818939
Test set avg_accuracy=58.68% avg_sensitivity=84.14%, avg_specificity=50.22% avg_auc=69.10%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.342558 Test loss=0.674118 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.29665520787239075
[5/24] Train loss=0.3418627083301544
[10/24] Train loss=0.3343247175216675
[15/24] Train loss=0.34355980157852173
[20/24] Train loss=0.29572829604148865
Test set avg_accuracy=58.68% avg_sensitivity=84.14%, avg_specificity=50.22% avg_auc=69.10%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.342516 Test loss=0.674324 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.29660576581954956
[5/24] Train loss=0.34181565046310425
[10/24] Train loss=0.33429840207099915
[15/24] Train loss=0.34354332089424133
[20/24] Train loss=0.29569220542907715
Test set avg_accuracy=58.68% avg_sensitivity=84.14%, avg_specificity=50.22% avg_auc=69.09%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.342487 Test loss=0.674440 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.2965737283229828
[5/24] Train loss=0.3417871594429016
[10/24] Train loss=0.33428409695625305
[15/24] Train loss=0.3435344994068146
[20/24] Train loss=0.29566729068756104
Test set avg_accuracy=58.68% avg_sensitivity=84.14%, avg_specificity=50.22% avg_auc=69.09%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.342469 Test loss=0.674505 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.29655513167381287
[5/24] Train loss=0.3417731523513794
[10/24] Train loss=0.33427679538726807
[15/24] Train loss=0.3435298502445221
[20/24] Train loss=0.2956550717353821
Test set avg_accuracy=58.68% avg_sensitivity=84.14%, avg_specificity=50.22% avg_auc=69.09%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.342459 Test loss=0.674537 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.29654696583747864
[5/24] Train loss=0.3417668640613556
[10/24] Train loss=0.3342740535736084
[15/24] Train loss=0.3435278832912445
[20/24] Train loss=0.2956516146659851
Test set avg_accuracy=58.68% avg_sensitivity=84.14%, avg_specificity=50.22% avg_auc=69.09%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.342455 Test loss=0.674545 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=70.30% sen=70.01%, spe=70.40%, auc=76.37%!
Fold[2] Avg_overlap=0.57%(0.2515083848785467)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 1,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'SwEDModel',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.6781398057937622
[5/24] Train loss=0.675126314163208
[10/24] Train loss=0.678265392780304
[15/24] Train loss=0.6756312251091003
[20/24] Train loss=0.6739699840545654
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.41%
Best model saved!! Metric=-104.06511185550272!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.674297 Test loss=0.673487 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6707150936126709
[5/24] Train loss=0.6674318313598633
[10/24] Train loss=0.6725176572799683
[15/24] Train loss=0.6699447631835938
[20/24] Train loss=0.6679548025131226
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.64%
Best model saved!! Metric=-103.8296340504026!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.667389 Test loss=0.667864 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6643486618995667
[5/24] Train loss=0.6608250141143799
[10/24] Train loss=0.6675950288772583
[15/24] Train loss=0.6648341417312622
[20/24] Train loss=0.6623538136482239
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.77%
Best model saved!! Metric=-103.70770462142033!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.661290 Test loss=0.662470 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6580536961555481
[5/24] Train loss=0.6542308926582336
[10/24] Train loss=0.6624143719673157
[15/24] Train loss=0.6593753695487976
[20/24] Train loss=0.6562204360961914
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.99%
Best model saved!! Metric=-103.48332213909713!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.654881 Test loss=0.656482 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6511908769607544
[5/24] Train loss=0.6468026638031006
[10/24] Train loss=0.6567355394363403
[15/24] Train loss=0.6531810760498047
[20/24] Train loss=0.6492975354194641
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.16%
Best model saved!! Metric=-103.31322930936437!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.647693 Test loss=0.649742 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6434556841850281
[5/24] Train loss=0.6381829977035522
[10/24] Train loss=0.6500841379165649
[15/24] Train loss=0.6457987427711487
[20/24] Train loss=0.6408718228340149
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.33%
Best model saved!! Metric=-103.14627618369964!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.639176 Test loss=0.641518 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6340509653091431
[5/24] Train loss=0.6271921396255493
[10/24] Train loss=0.6419225335121155
[15/24] Train loss=0.6364881992340088
[20/24] Train loss=0.6304467916488647
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.51%
Best model saved!! Metric=-102.96460729059422!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.628464 Test loss=0.631280 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6223912835121155
[5/24] Train loss=0.6135047078132629
[10/24] Train loss=0.6323186755180359
[15/24] Train loss=0.6252982020378113
[20/24] Train loss=0.6182248592376709
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.69%
Best model saved!! Metric=-102.78808615077104!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.615423 Test loss=0.619425 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6085942983627319
[5/24] Train loss=0.5972015261650085
[10/24] Train loss=0.6219534277915955
[15/24] Train loss=0.6127004027366638
[20/24] Train loss=0.6049476861953735
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.18%
Best model saved!! Metric=-102.29068980780303!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.600455 Test loss=0.607068 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5937693119049072
[5/24] Train loss=0.5797932744026184
[10/24] Train loss=0.6128058433532715
[15/24] Train loss=0.6005919575691223
[20/24] Train loss=0.5931366086006165
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.36%
Best model saved!! Metric=-102.11671276423007!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.585554 Test loss=0.596835 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5806604623794556
[5/24] Train loss=0.5645174980163574
[10/24] Train loss=0.6074041128158569
[15/24] Train loss=0.5917541980743408
[20/24] Train loss=0.5848544836044312
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.99%
Best model saved!! Metric=-101.48748288513846!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.573757 Test loss=0.590589 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5720734596252441
[5/24] Train loss=0.5547586679458618
[10/24] Train loss=0.605666995048523
[15/24] Train loss=0.5869846940040588
[20/24] Train loss=0.5796990990638733
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.92%
Best model saved!! Metric=-100.55230203307894!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.566890 Test loss=0.587679 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5678209066390991
[5/24] Train loss=0.5499927997589111
[10/24] Train loss=0.6043051481246948
[15/24] Train loss=0.5843997001647949
[20/24] Train loss=0.5757578015327454
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.81%
Best model saved!! Metric=-98.66799459734077!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.563333 Test loss=0.585897 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5657087564468384
[5/24] Train loss=0.54696124792099
[10/24] Train loss=0.6030562520027161
[15/24] Train loss=0.5827775001525879
[20/24] Train loss=0.5722485184669495
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=57.52%
Best model saved!! Metric=-95.94955543017068!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.560777 Test loss=0.584369 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5642563700675964
[5/24] Train loss=0.5454227924346924
[10/24] Train loss=0.604411244392395
[15/24] Train loss=0.5821200013160706
[20/24] Train loss=0.5685594081878662
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=59.76%
Best model saved!! Metric=-93.7109634470519!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.558410 Test loss=0.582742 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5612228512763977
[5/24] Train loss=0.5435858964920044
[10/24] Train loss=0.6023669838905334
[15/24] Train loss=0.5806606411933899
[20/24] Train loss=0.5638983845710754
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=62.65%
Best model saved!! Metric=-90.82371626129881!!
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.555776 Test loss=0.580786 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5589415431022644
[5/24] Train loss=0.5398458242416382
[10/24] Train loss=0.5979085564613342
[15/24] Train loss=0.5773963332176208
[20/24] Train loss=0.5581012964248657
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=65.43%
Best model saved!! Metric=-88.04167043353159!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.551079 Test loss=0.576690 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5511004328727722
[5/24] Train loss=0.534704327583313
[10/24] Train loss=0.5953773260116577
[15/24] Train loss=0.573645830154419
[20/24] Train loss=0.5472065806388855
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=68.89%
Best model saved!! Metric=-84.58407771015739!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.544085 Test loss=0.569730 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5424603223800659
[5/24] Train loss=0.5284561514854431
[10/24] Train loss=0.5977584719657898
[15/24] Train loss=0.5669431090354919
[20/24] Train loss=0.5346373319625854
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=70.37%
Best model saved!! Metric=-83.10409864151785!!
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.537053 Test loss=0.568417 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5300186276435852
[5/24] Train loss=0.519749104976654
[10/24] Train loss=0.5932864546775818
[15/24] Train loss=0.5635687708854675
[20/24] Train loss=0.5212976336479187
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=72.06%
Best model saved!! Metric=-81.41176411413264!!
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.524247 Test loss=0.573343 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5076472163200378
[5/24] Train loss=0.5064151883125305
[10/24] Train loss=0.5639296770095825
[15/24] Train loss=0.5522584319114685
[20/24] Train loss=0.5042014122009277
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=58.98%
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.508706 Test loss=0.682468 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5008410215377808
[5/24] Train loss=0.4974619150161743
[10/24] Train loss=0.5625042915344238
[15/24] Train loss=0.5416337847709656
[20/24] Train loss=0.491853803396225
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=63.00%
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.499598 Test loss=0.656564 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.4789515733718872
[5/24] Train loss=0.5025987029075623
[10/24] Train loss=0.5441540479660034
[15/24] Train loss=0.5377956628799438
[20/24] Train loss=0.4845372140407562
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=60.48%
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.490447 Test loss=0.655880 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.47681036591529846
[5/24] Train loss=0.48227459192276
[10/24] Train loss=0.5419506430625916
[15/24] Train loss=0.5310758352279663
[20/24] Train loss=0.4809286892414093
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=58.61%
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.483832 Test loss=0.661064 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.469610333442688
[5/24] Train loss=0.48808375000953674
[10/24] Train loss=0.5362222194671631
[15/24] Train loss=0.5265258550643921
[20/24] Train loss=0.4724319577217102
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=57.41%
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.477769 Test loss=0.670487 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.460778146982193
[5/24] Train loss=0.47697770595550537
[10/24] Train loss=0.5372928380966187
[15/24] Train loss=0.5236873626708984
[20/24] Train loss=0.4727328419685364
Test set avg_accuracy=34.79% avg_sensitivity=86.82%, avg_specificity=15.08% avg_auc=58.71%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.475754 Test loss=0.667317 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.4603100121021271
[5/24] Train loss=0.4750480055809021
[10/24] Train loss=0.5425333976745605
[15/24] Train loss=0.5137356519699097
[20/24] Train loss=0.4679609537124634
Test set avg_accuracy=34.11% avg_sensitivity=90.05%, avg_specificity=12.93% avg_auc=59.89%
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.472334 Test loss=0.662346 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.46051111817359924
[5/24] Train loss=0.4727065861225128
[10/24] Train loss=0.5375535488128662
[15/24] Train loss=0.5171300768852234
[20/24] Train loss=0.46814724802970886
Test set avg_accuracy=32.36% avg_sensitivity=93.18%, avg_specificity=9.32% avg_auc=60.53%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.473231 Test loss=0.663587 Current lr=[0.000210185142098938]

[0/24] Train loss=0.4600190818309784
[5/24] Train loss=0.4714755713939667
[10/24] Train loss=0.5342294573783875
[15/24] Train loss=0.5163589715957642
[20/24] Train loss=0.4693969190120697
Test set avg_accuracy=47.47% avg_sensitivity=80.66%, avg_specificity=34.90% avg_auc=64.68%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.472053 Test loss=0.644243 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.4642181694507599
[5/24] Train loss=0.47472360730171204
[10/24] Train loss=0.5406856536865234
[15/24] Train loss=0.5133774876594543
[20/24] Train loss=0.47457823157310486
Test set avg_accuracy=47.45% avg_sensitivity=83.03%, avg_specificity=33.97% avg_auc=66.07%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.472791 Test loss=0.643581 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.46034321188926697
[5/24] Train loss=0.47861090302467346
[10/24] Train loss=0.527049720287323
[15/24] Train loss=0.5254547595977783
[20/24] Train loss=0.47691577672958374
Test set avg_accuracy=55.81% avg_sensitivity=69.62%, avg_specificity=50.57% avg_auc=68.09%
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.473763 Test loss=0.627401 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.4687996804714203
[5/24] Train loss=0.4745523929595947
[10/24] Train loss=0.5313351154327393
[15/24] Train loss=0.5252556204795837
[20/24] Train loss=0.4657209813594818
Test set avg_accuracy=42.36% avg_sensitivity=91.33%, avg_specificity=23.81% avg_auc=64.64%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.472006 Test loss=0.653491 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.46315690875053406
[5/24] Train loss=0.48045817017555237
[10/24] Train loss=0.5344178676605225
[15/24] Train loss=0.5110312700271606
[20/24] Train loss=0.4779154360294342
Test set avg_accuracy=57.68% avg_sensitivity=71.37%, avg_specificity=52.50% avg_auc=68.02%
Best model saved!! Metric=-76.43009952854804!!
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.469555 Test loss=0.623794 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.46124815940856934
[5/24] Train loss=0.481975257396698
[10/24] Train loss=0.5397137999534607
[15/24] Train loss=0.5162657499313354
[20/24] Train loss=0.4662798047065735
Test set avg_accuracy=50.65% avg_sensitivity=83.98%, avg_specificity=38.03% avg_auc=64.84%
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.468719 Test loss=0.647368 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.45225685834884644
[5/24] Train loss=0.47137367725372314
[10/24] Train loss=0.5360866785049438
[15/24] Train loss=0.5127118825912476
[20/24] Train loss=0.4590078890323639
Test set avg_accuracy=49.71% avg_sensitivity=83.70%, avg_specificity=36.84% avg_auc=65.86%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.466862 Test loss=0.644115 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.45327621698379517
[5/24] Train loss=0.471618115901947
[10/24] Train loss=0.5287181735038757
[15/24] Train loss=0.5109321475028992
[20/24] Train loss=0.460274338722229
Test set avg_accuracy=40.92% avg_sensitivity=91.28%, avg_specificity=21.85% avg_auc=63.10%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.467243 Test loss=0.665190 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4547441601753235
[5/24] Train loss=0.4726792275905609
[10/24] Train loss=0.5230253338813782
[15/24] Train loss=0.5062768459320068
[20/24] Train loss=0.4565400779247284
Test set avg_accuracy=31.08% avg_sensitivity=97.68%, avg_specificity=5.85% avg_auc=61.33%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.465107 Test loss=0.680919 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.4545230269432068
[5/24] Train loss=0.48269450664520264
[10/24] Train loss=0.5336720943450928
[15/24] Train loss=0.5293623208999634
[20/24] Train loss=0.4701111614704132
Test set avg_accuracy=41.86% avg_sensitivity=89.19%, avg_specificity=23.93% avg_auc=65.32%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.471447 Test loss=0.654608 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.45741283893585205
[5/24] Train loss=0.4822691082954407
[10/24] Train loss=0.5273436307907104
[15/24] Train loss=0.5102970004081726
[20/24] Train loss=0.4628530740737915
Test set avg_accuracy=44.90% avg_sensitivity=86.59%, avg_specificity=29.10% avg_auc=64.43%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.468927 Test loss=0.653790 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.4519869089126587
[5/24] Train loss=0.47166407108306885
[10/24] Train loss=0.5382965207099915
[15/24] Train loss=0.5109174251556396
[20/24] Train loss=0.46024349331855774
Test set avg_accuracy=37.66% avg_sensitivity=92.89%, avg_specificity=16.73% avg_auc=63.40%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.467830 Test loss=0.668133 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.45726898312568665
[5/24] Train loss=0.470525324344635
[10/24] Train loss=0.5497058629989624
[15/24] Train loss=0.5161689519882202
[20/24] Train loss=0.46207767724990845
Test set avg_accuracy=47.93% avg_sensitivity=81.75%, avg_specificity=35.12% avg_auc=67.33%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.468033 Test loss=0.641196 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.463606595993042
[5/24] Train loss=0.46884724497795105
[10/24] Train loss=0.5309869050979614
[15/24] Train loss=0.5092593431472778
[20/24] Train loss=0.4620142877101898
Test set avg_accuracy=49.39% avg_sensitivity=85.21%, avg_specificity=35.82% avg_auc=66.71%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.467954 Test loss=0.644584 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.45812925696372986
[5/24] Train loss=0.46703219413757324
[10/24] Train loss=0.5230434536933899
[15/24] Train loss=0.5079666972160339
[20/24] Train loss=0.46087807416915894
Test set avg_accuracy=46.72% avg_sensitivity=88.20%, avg_specificity=31.01% avg_auc=65.52%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.466284 Test loss=0.652420 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.4589551091194153
[5/24] Train loss=0.4667007625102997
[10/24] Train loss=0.5259738564491272
[15/24] Train loss=0.5031216144561768
[20/24] Train loss=0.45578131079673767
Test set avg_accuracy=48.01% avg_sensitivity=86.35%, avg_specificity=33.48% avg_auc=65.50%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.467369 Test loss=0.651759 Current lr=[0.00029967723776099]

[0/24] Train loss=0.46267202496528625
[5/24] Train loss=0.46706900000572205
[10/24] Train loss=0.5332780480384827
[15/24] Train loss=0.5077195763587952
[20/24] Train loss=0.45612776279449463
Test set avg_accuracy=53.37% avg_sensitivity=77.25%, avg_specificity=44.33% avg_auc=68.23%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.464719 Test loss=0.632330 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.4528128504753113
[5/24] Train loss=0.4672306478023529
[10/24] Train loss=0.5595699548721313
[15/24] Train loss=0.5078423619270325
[20/24] Train loss=0.46041059494018555
Test set avg_accuracy=33.76% avg_sensitivity=96.54%, avg_specificity=9.98% avg_auc=61.46%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.467540 Test loss=0.682063 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.45914456248283386
[5/24] Train loss=0.46951404213905334
[10/24] Train loss=0.5364532470703125
[15/24] Train loss=0.5204939246177673
[20/24] Train loss=0.46155720949172974
Test set avg_accuracy=47.59% avg_sensitivity=85.78%, avg_specificity=33.12% avg_auc=65.86%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.470163 Test loss=0.648912 Current lr=[0.000299720220882401]

[0/24] Train loss=0.46507906913757324
[5/24] Train loss=0.4713418781757355
[10/24] Train loss=0.5480026602745056
[15/24] Train loss=0.5152942538261414
[20/24] Train loss=0.4562801718711853
Test set avg_accuracy=52.15% avg_sensitivity=76.21%, avg_specificity=43.03% avg_auc=66.28%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.467561 Test loss=0.638730 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.45493754744529724
[5/24] Train loss=0.4748552441596985
[10/24] Train loss=0.5207937955856323
[15/24] Train loss=0.5041141510009766
[20/24] Train loss=0.45657873153686523
Test set avg_accuracy=53.45% avg_sensitivity=81.90%, avg_specificity=42.68% avg_auc=68.78%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.468968 Test loss=0.631591 Current lr=[0.000298904600941902]

[0/24] Train loss=0.45896267890930176
[5/24] Train loss=0.47477293014526367
[10/24] Train loss=0.5319115519523621
[15/24] Train loss=0.5022839903831482
[20/24] Train loss=0.4587844908237457
Test set avg_accuracy=40.17% avg_sensitivity=93.55%, avg_specificity=19.95% avg_auc=62.04%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.466145 Test loss=0.673744 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.4527026116847992
[5/24] Train loss=0.4731202721595764
[10/24] Train loss=0.518909215927124
[15/24] Train loss=0.5043002367019653
[20/24] Train loss=0.455933541059494
Test set avg_accuracy=45.57% avg_sensitivity=90.14%, avg_specificity=28.69% avg_auc=65.07%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.465732 Test loss=0.657706 Current lr=[0.000297555943323901]

[0/24] Train loss=0.456287145614624
[5/24] Train loss=0.4654264748096466
[10/24] Train loss=0.5445056557655334
[15/24] Train loss=0.5269109606742859
[20/24] Train loss=0.45518532395362854
Test set avg_accuracy=46.22% avg_sensitivity=88.96%, avg_specificity=30.04% avg_auc=65.10%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.465397 Test loss=0.657148 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.45575183629989624
[5/24] Train loss=0.4682188928127289
[10/24] Train loss=0.5314111113548279
[15/24] Train loss=0.5203829407691956
[20/24] Train loss=0.4643348753452301
Test set avg_accuracy=65.76% avg_sensitivity=47.25%, avg_specificity=72.76% avg_auc=71.12%
Best model saved!! Metric=-69.11043530600061!!
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.470640 Test loss=0.597984 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.46066102385520935
[5/24] Train loss=0.47046613693237305
[10/24] Train loss=0.525060772895813
[15/24] Train loss=0.5154748558998108
[20/24] Train loss=0.45526188611984253
Test set avg_accuracy=46.73% avg_sensitivity=86.54%, avg_specificity=31.65% avg_auc=64.70%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.465823 Test loss=0.655501 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.45196211338043213
[5/24] Train loss=0.4743822515010834
[10/24] Train loss=0.5220997333526611
[15/24] Train loss=0.5169912576675415
[20/24] Train loss=0.45712876319885254
Test set avg_accuracy=45.33% avg_sensitivity=88.86%, avg_specificity=28.83% avg_auc=64.77%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.465757 Test loss=0.657370 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.4662466049194336
[5/24] Train loss=0.47112756967544556
[10/24] Train loss=0.5360735654830933
[15/24] Train loss=0.5122190713882446
[20/24] Train loss=0.4533153176307678
Test set avg_accuracy=52.32% avg_sensitivity=82.89%, avg_specificity=40.74% avg_auc=67.79%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.464713 Test loss=0.637921 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.4692736864089966
[5/24] Train loss=0.4661107063293457
[10/24] Train loss=0.5239362716674805
[15/24] Train loss=0.5086439251899719
[20/24] Train loss=0.4512653350830078
Test set avg_accuracy=49.05% avg_sensitivity=85.83%, avg_specificity=35.12% avg_auc=65.10%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.463569 Test loss=0.654523 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.45047619938850403
[5/24] Train loss=0.46945929527282715
[10/24] Train loss=0.5304706692695618
[15/24] Train loss=0.5042360424995422
[20/24] Train loss=0.4598104655742645
Test set avg_accuracy=42.86% avg_sensitivity=90.85%, avg_specificity=24.69% avg_auc=64.98%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.464384 Test loss=0.658811 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.4611392319202423
[5/24] Train loss=0.46697312593460083
[10/24] Train loss=0.5427314639091492
[15/24] Train loss=0.5358982086181641
[20/24] Train loss=0.4629627466201782
Test set avg_accuracy=51.48% avg_sensitivity=80.28%, avg_specificity=40.57% avg_auc=68.35%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.470223 Test loss=0.635330 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.45943713188171387
[5/24] Train loss=0.4742359519004822
[10/24] Train loss=0.5460385680198669
[15/24] Train loss=0.5077420473098755
[20/24] Train loss=0.4501851201057434
Test set avg_accuracy=50.86% avg_sensitivity=85.64%, avg_specificity=37.68% avg_auc=66.46%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.465771 Test loss=0.646203 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.45566654205322266
[5/24] Train loss=0.46681883931159973
[10/24] Train loss=0.5450094938278198
[15/24] Train loss=0.5188046097755432
[20/24] Train loss=0.45069366693496704
Test set avg_accuracy=53.75% avg_sensitivity=79.24%, avg_specificity=44.09% avg_auc=66.21%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.465122 Test loss=0.638287 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.45358800888061523
[5/24] Train loss=0.4735977351665497
[10/24] Train loss=0.5229532718658447
[15/24] Train loss=0.5090754628181458
[20/24] Train loss=0.4544607102870941
Test set avg_accuracy=56.41% avg_sensitivity=77.63%, avg_specificity=48.37% avg_auc=69.77%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.468663 Test loss=0.624775 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.4573633372783661
[5/24] Train loss=0.47468918561935425
[10/24] Train loss=0.5216869711875916
[15/24] Train loss=0.5199517011642456
[20/24] Train loss=0.45180386304855347
Test set avg_accuracy=55.26% avg_sensitivity=75.07%, avg_specificity=47.76% avg_auc=67.80%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.467825 Test loss=0.630371 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.4500138759613037
[5/24] Train loss=0.4677234888076782
[10/24] Train loss=0.5206921696662903
[15/24] Train loss=0.5228991508483887
[20/24] Train loss=0.45268887281417847
Test set avg_accuracy=50.17% avg_sensitivity=87.06%, avg_specificity=36.19% avg_auc=66.75%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.464430 Test loss=0.646235 Current lr=[0.000276307469034998]

[0/24] Train loss=0.4519834816455841
[5/24] Train loss=0.4763256311416626
[10/24] Train loss=0.525620698928833
[15/24] Train loss=0.5239416360855103
[20/24] Train loss=0.45928359031677246
Test set avg_accuracy=55.04% avg_sensitivity=77.11%, avg_specificity=46.68% avg_auc=68.74%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.467243 Test loss=0.628702 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.4574013352394104
[5/24] Train loss=0.47321200370788574
[10/24] Train loss=0.5297072529792786
[15/24] Train loss=0.5177691578865051
[20/24] Train loss=0.4459082782268524
Test set avg_accuracy=55.89% avg_sensitivity=76.49%, avg_specificity=48.08% avg_auc=68.40%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.464306 Test loss=0.628902 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.4488818347454071
[5/24] Train loss=0.4650859534740448
[10/24] Train loss=0.5235254168510437
[15/24] Train loss=0.503781259059906
[20/24] Train loss=0.4455607831478119
Test set avg_accuracy=50.83% avg_sensitivity=85.59%, avg_specificity=37.67% avg_auc=65.39%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.460020 Test loss=0.651201 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.44654783606529236
[5/24] Train loss=0.4635137617588043
[10/24] Train loss=0.5214853286743164
[15/24] Train loss=0.5008819699287415
[20/24] Train loss=0.4499461352825165
Test set avg_accuracy=46.04% avg_sensitivity=89.81%, avg_specificity=29.46% avg_auc=64.08%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.460075 Test loss=0.661000 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.44941478967666626
[5/24] Train loss=0.46706509590148926
[10/24] Train loss=0.518697202205658
[15/24] Train loss=0.5076630115509033
[20/24] Train loss=0.44935324788093567
Test set avg_accuracy=52.93% avg_sensitivity=84.17%, avg_specificity=41.10% avg_auc=67.25%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.460078 Test loss=0.639207 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.45127561688423157
[5/24] Train loss=0.4623371362686157
[10/24] Train loss=0.5263885855674744
[15/24] Train loss=0.514259397983551
[20/24] Train loss=0.4540305435657501
Test set avg_accuracy=44.23% avg_sensitivity=89.62%, avg_specificity=27.04% avg_auc=63.82%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.462595 Test loss=0.664536 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.45420098304748535
[5/24] Train loss=0.4691711664199829
[10/24] Train loss=0.5273486971855164
[15/24] Train loss=0.5074619054794312
[20/24] Train loss=0.4484414756298065
Test set avg_accuracy=53.61% avg_sensitivity=82.70%, avg_specificity=42.59% avg_auc=68.01%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.462382 Test loss=0.635212 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.4509889781475067
[5/24] Train loss=0.47656750679016113
[10/24] Train loss=0.5307812094688416
[15/24] Train loss=0.4989474415779114
[20/24] Train loss=0.4420543313026428
Test set avg_accuracy=53.97% avg_sensitivity=80.47%, avg_specificity=43.93% avg_auc=67.00%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.461143 Test loss=0.634258 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.4448588788509369
[5/24] Train loss=0.45980533957481384
[10/24] Train loss=0.5184605121612549
[15/24] Train loss=0.5048556327819824
[20/24] Train loss=0.44834691286087036
Test set avg_accuracy=33.67% avg_sensitivity=98.44%, avg_specificity=9.14% avg_auc=59.87%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.458205 Test loss=0.695476 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.44892600178718567
[5/24] Train loss=0.4660521447658539
[10/24] Train loss=0.5141698122024536
[15/24] Train loss=0.49876710772514343
[20/24] Train loss=0.44829580187797546
Test set avg_accuracy=46.86% avg_sensitivity=89.34%, avg_specificity=30.77% avg_auc=64.85%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.458893 Test loss=0.658296 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.4490559697151184
[5/24] Train loss=0.4643472731113434
[10/24] Train loss=0.5219920873641968
[15/24] Train loss=0.49929386377334595
[20/24] Train loss=0.44163843989372253
Test set avg_accuracy=52.72% avg_sensitivity=86.26%, avg_specificity=40.02% avg_auc=66.43%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.458436 Test loss=0.645266 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.448440819978714
[5/24] Train loss=0.4591336250305176
[10/24] Train loss=0.5135587453842163
[15/24] Train loss=0.4949652850627899
[20/24] Train loss=0.4503917098045349
Test set avg_accuracy=42.79% avg_sensitivity=92.32%, avg_specificity=24.02% avg_auc=63.45%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.456779 Test loss=0.670361 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.44933179020881653
[5/24] Train loss=0.4652303159236908
[10/24] Train loss=0.5279778838157654
[15/24] Train loss=0.5058841705322266
[20/24] Train loss=0.446503609418869
Test set avg_accuracy=44.09% avg_sensitivity=91.28%, avg_specificity=26.21% avg_auc=64.64%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.460252 Test loss=0.663334 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.4502955675125122
[5/24] Train loss=0.46429580450057983
[10/24] Train loss=0.52277672290802
[15/24] Train loss=0.5060886144638062
[20/24] Train loss=0.44685855507850647
Test set avg_accuracy=52.25% avg_sensitivity=85.40%, avg_specificity=39.69% avg_auc=66.57%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.457986 Test loss=0.643533 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.4458114504814148
[5/24] Train loss=0.4596526622772217
[10/24] Train loss=0.5236853957176208
[15/24] Train loss=0.5127863883972168
[20/24] Train loss=0.4454684555530548
Test set avg_accuracy=49.64% avg_sensitivity=88.44%, avg_specificity=34.94% avg_auc=66.10%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.460684 Test loss=0.652561 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.4529912769794464
[5/24] Train loss=0.4640865623950958
[10/24] Train loss=0.5196181535720825
[15/24] Train loss=0.49623727798461914
[20/24] Train loss=0.44263535737991333
Test set avg_accuracy=52.03% avg_sensitivity=90.00%, avg_specificity=37.65% avg_auc=66.48%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.457228 Test loss=0.648150 Current lr=[0.000224838296036774]

[0/24] Train loss=0.4472655951976776
[5/24] Train loss=0.4582657217979431
[10/24] Train loss=0.5222159624099731
[15/24] Train loss=0.5000459551811218
[20/24] Train loss=0.4403795897960663
Test set avg_accuracy=46.82% avg_sensitivity=90.52%, avg_specificity=30.27% avg_auc=65.03%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.455914 Test loss=0.658825 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.4470193088054657
[5/24] Train loss=0.461144357919693
[10/24] Train loss=0.5186599493026733
[15/24] Train loss=0.5013375282287598
[20/24] Train loss=0.4403916299343109
Test set avg_accuracy=58.02% avg_sensitivity=73.93%, avg_specificity=51.99% avg_auc=68.05%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.456701 Test loss=0.620359 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.44524773955345154
[5/24] Train loss=0.4563951790332794
[10/24] Train loss=0.5148844718933105
[15/24] Train loss=0.4984019100666046
[20/24] Train loss=0.4434981942176819
Test set avg_accuracy=50.59% avg_sensitivity=87.77%, avg_specificity=36.50% avg_auc=66.05%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.456106 Test loss=0.649606 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.44847235083580017
[5/24] Train loss=0.46318191289901733
[10/24] Train loss=0.5143634080886841
[15/24] Train loss=0.5163593292236328
[20/24] Train loss=0.4453013837337494
Test set avg_accuracy=50.46% avg_sensitivity=87.20%, avg_specificity=36.54% avg_auc=66.44%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.458387 Test loss=0.646718 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.4472827911376953
[5/24] Train loss=0.4615074098110199
[10/24] Train loss=0.519347608089447
[15/24] Train loss=0.4991733133792877
[20/24] Train loss=0.4409962594509125
Test set avg_accuracy=52.53% avg_sensitivity=84.31%, avg_specificity=40.48% avg_auc=66.93%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.456923 Test loss=0.641372 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.44620248675346375
[5/24] Train loss=0.45603957772254944
[10/24] Train loss=0.5148918032646179
[15/24] Train loss=0.5032640695571899
[20/24] Train loss=0.43812817335128784
Test set avg_accuracy=47.51% avg_sensitivity=91.09%, avg_specificity=31.01% avg_auc=65.89%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.455745 Test loss=0.654914 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.44364574551582336
[5/24] Train loss=0.456020325422287
[10/24] Train loss=0.5145807266235352
[15/24] Train loss=0.4894019365310669
[20/24] Train loss=0.437913179397583
Test set avg_accuracy=46.64% avg_sensitivity=91.00%, avg_specificity=29.84% avg_auc=64.96%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.454038 Test loss=0.659997 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.44301488995552063
[5/24] Train loss=0.4588315486907959
[10/24] Train loss=0.5134875178337097
[15/24] Train loss=0.504236102104187
[20/24] Train loss=0.4396006464958191
Test set avg_accuracy=55.77% avg_sensitivity=80.52%, avg_specificity=46.39% avg_auc=68.64%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.454731 Test loss=0.629695 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.4477553367614746
[5/24] Train loss=0.46258431673049927
[10/24] Train loss=0.5196887254714966
[15/24] Train loss=0.5166811347007751
[20/24] Train loss=0.4443385601043701
Test set avg_accuracy=55.73% avg_sensitivity=78.82%, avg_specificity=46.98% avg_auc=67.89%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.457260 Test loss=0.627830 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.4424223303794861
[5/24] Train loss=0.45718538761138916
[10/24] Train loss=0.5150020718574524
[15/24] Train loss=0.5001676678657532
[20/24] Train loss=0.4382571280002594
Test set avg_accuracy=49.82% avg_sensitivity=90.00%, avg_specificity=34.60% avg_auc=66.33%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.454350 Test loss=0.650562 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.44676369428634644
[5/24] Train loss=0.45983535051345825
[10/24] Train loss=0.5143239498138428
[15/24] Train loss=0.5037775039672852
[20/24] Train loss=0.44085797667503357
Test set avg_accuracy=54.64% avg_sensitivity=82.42%, avg_specificity=44.11% avg_auc=68.18%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.458747 Test loss=0.634018 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.45537906885147095
[5/24] Train loss=0.46013087034225464
[10/24] Train loss=0.5356127023696899
[15/24] Train loss=0.4901076555252075
[20/24] Train loss=0.45235031843185425
Test set avg_accuracy=56.64% avg_sensitivity=77.16%, avg_specificity=48.87% avg_auc=69.15%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.457028 Test loss=0.622234 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.4450775384902954
[5/24] Train loss=0.4558102488517761
[10/24] Train loss=0.5237336754798889
[15/24] Train loss=0.48722007870674133
[20/24] Train loss=0.44069331884384155
Test set avg_accuracy=56.88% avg_sensitivity=77.20%, avg_specificity=49.17% avg_auc=68.73%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.453068 Test loss=0.624869 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.4470957815647125
[5/24] Train loss=0.4524695873260498
[10/24] Train loss=0.5247003436088562
[15/24] Train loss=0.4901060461997986
[20/24] Train loss=0.43979281187057495
Test set avg_accuracy=57.15% avg_sensitivity=75.69%, avg_specificity=50.13% avg_auc=68.86%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.451907 Test loss=0.622498 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.4461212456226349
[5/24] Train loss=0.4488322138786316
[10/24] Train loss=0.5221921801567078
[15/24] Train loss=0.4937439560890198
[20/24] Train loss=0.4407866299152374
Test set avg_accuracy=56.67% avg_sensitivity=77.54%, avg_specificity=48.76% avg_auc=69.22%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.452481 Test loss=0.623259 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.4452427923679352
[5/24] Train loss=0.4493555426597595
[10/24] Train loss=0.521510124206543
[15/24] Train loss=0.48701944947242737
[20/24] Train loss=0.45123055577278137
Test set avg_accuracy=57.92% avg_sensitivity=73.32%, avg_specificity=52.08% avg_auc=69.04%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.451465 Test loss=0.617386 Current lr=[0.000156543481933168]

[0/24] Train loss=0.44741320610046387
[5/24] Train loss=0.4539199471473694
[10/24] Train loss=0.5300061702728271
[15/24] Train loss=0.4927120506763458
[20/24] Train loss=0.4418303966522217
Test set avg_accuracy=57.73% avg_sensitivity=72.75%, avg_specificity=52.05% avg_auc=68.93%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.452504 Test loss=0.617568 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.44531527161598206
[5/24] Train loss=0.4644644260406494
[10/24] Train loss=0.5265494585037231
[15/24] Train loss=0.4938499629497528
[20/24] Train loss=0.4465023875236511
Test set avg_accuracy=64.65% avg_sensitivity=53.36%, avg_specificity=68.92% avg_auc=69.77%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.457252 Test loss=0.598311 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.4522024095058441
[5/24] Train loss=0.4570077955722809
[10/24] Train loss=0.5296677350997925
[15/24] Train loss=0.4878128170967102
[20/24] Train loss=0.44385188817977905
Test set avg_accuracy=58.45% avg_sensitivity=66.92%, avg_specificity=55.24% avg_auc=69.20%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.454135 Test loss=0.609749 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.44465965032577515
[5/24] Train loss=0.4480223059654236
[10/24] Train loss=0.5204815864562988
[15/24] Train loss=0.48764657974243164
[20/24] Train loss=0.4374210238456726
Test set avg_accuracy=54.62% avg_sensitivity=82.37%, avg_specificity=44.11% avg_auc=67.41%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.449494 Test loss=0.630672 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.43940597772598267
[5/24] Train loss=0.4492225646972656
[10/24] Train loss=0.5211751461029053
[15/24] Train loss=0.4848615825176239
[20/24] Train loss=0.4479014575481415
Test set avg_accuracy=57.85% avg_sensitivity=72.09%, avg_specificity=52.46% avg_auc=68.82%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.451167 Test loss=0.616891 Current lr=[0.000134135431043539]

[0/24] Train loss=0.4467724859714508
[5/24] Train loss=0.4512682855129242
[10/24] Train loss=0.5245183706283569
[15/24] Train loss=0.48894408345222473
[20/24] Train loss=0.44035425782203674
Test set avg_accuracy=59.61% avg_sensitivity=67.11%, avg_specificity=56.77% avg_auc=68.20%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.453293 Test loss=0.611529 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.44699278473854065
[5/24] Train loss=0.4466259777545929
[10/24] Train loss=0.5152794122695923
[15/24] Train loss=0.4866602122783661
[20/24] Train loss=0.44398653507232666
Test set avg_accuracy=57.37% avg_sensitivity=74.55%, avg_specificity=50.86% avg_auc=68.47%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.449210 Test loss=0.621646 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.4420047998428345
[5/24] Train loss=0.4500877857208252
[10/24] Train loss=0.5234696865081787
[15/24] Train loss=0.4830459952354431
[20/24] Train loss=0.43545129895210266
Test set avg_accuracy=57.42% avg_sensitivity=73.03%, avg_specificity=51.51% avg_auc=67.66%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.448470 Test loss=0.620466 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.4405025839805603
[5/24] Train loss=0.4450170397758484
[10/24] Train loss=0.5157430171966553
[15/24] Train loss=0.4798162281513214
[20/24] Train loss=0.43550896644592285
Test set avg_accuracy=55.73% avg_sensitivity=78.01%, avg_specificity=47.29% avg_auc=67.17%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.447090 Test loss=0.626921 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.43788760900497437
[5/24] Train loss=0.4440402388572693
[10/24] Train loss=0.5159575343132019
[15/24] Train loss=0.47905847430229187
[20/24] Train loss=0.4335395395755768
Test set avg_accuracy=55.30% avg_sensitivity=79.48%, avg_specificity=46.14% avg_auc=67.11%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.445815 Test loss=0.628305 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.43831127882003784
[5/24] Train loss=0.4552328586578369
[10/24] Train loss=0.5162782073020935
[15/24] Train loss=0.48139894008636475
[20/24] Train loss=0.43902891874313354
Test set avg_accuracy=54.18% avg_sensitivity=83.74%, avg_specificity=42.98% avg_auc=67.16%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.447439 Test loss=0.635047 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.43822401762008667
[5/24] Train loss=0.4549361765384674
[10/24] Train loss=0.5150173306465149
[15/24] Train loss=0.4766930341720581
[20/24] Train loss=0.43597573041915894
Test set avg_accuracy=55.55% avg_sensitivity=76.64%, avg_specificity=47.56% avg_auc=66.67%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.448100 Test loss=0.629935 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.4403078854084015
[5/24] Train loss=0.44510069489479065
[10/24] Train loss=0.5144946575164795
[15/24] Train loss=0.4797339141368866
[20/24] Train loss=0.43800088763237
Test set avg_accuracy=52.84% avg_sensitivity=84.17%, avg_specificity=40.97% avg_auc=66.86%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.446839 Test loss=0.636317 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.4390718638896942
[5/24] Train loss=0.4474572241306305
[10/24] Train loss=0.5138862133026123
[15/24] Train loss=0.48116928339004517
[20/24] Train loss=0.44506940245628357
Test set avg_accuracy=55.48% avg_sensitivity=77.35%, avg_specificity=47.20% avg_auc=67.49%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.447357 Test loss=0.627836 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.43890929222106934
[5/24] Train loss=0.449885755777359
[10/24] Train loss=0.5190551280975342
[15/24] Train loss=0.477182537317276
[20/24] Train loss=0.435153990983963
Test set avg_accuracy=57.34% avg_sensitivity=76.82%, avg_specificity=49.96% avg_auc=67.73%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.447960 Test loss=0.624620 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.44153258204460144
[5/24] Train loss=0.4434480369091034
[10/24] Train loss=0.5146345496177673
[15/24] Train loss=0.4761603772640228
[20/24] Train loss=0.4422258734703064
Test set avg_accuracy=53.52% avg_sensitivity=84.60%, avg_specificity=41.74% avg_auc=66.77%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.445305 Test loss=0.638694 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.4362347424030304
[5/24] Train loss=0.44645828008651733
[10/24] Train loss=0.5118309259414673
[15/24] Train loss=0.4726698100566864
[20/24] Train loss=0.43172508478164673
Test set avg_accuracy=53.61% avg_sensitivity=84.17%, avg_specificity=42.03% avg_auc=66.44%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.443824 Test loss=0.640512 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.4390426278114319
[5/24] Train loss=0.4444882273674011
[10/24] Train loss=0.5095462799072266
[15/24] Train loss=0.4714796543121338
[20/24] Train loss=0.43298035860061646
Test set avg_accuracy=53.33% avg_sensitivity=84.55%, avg_specificity=41.51% avg_auc=66.05%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.443748 Test loss=0.643564 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.43468615412712097
[5/24] Train loss=0.44335034489631653
[10/24] Train loss=0.5089849233627319
[15/24] Train loss=0.470208078622818
[20/24] Train loss=0.4309913218021393
Test set avg_accuracy=52.06% avg_sensitivity=85.50%, avg_specificity=39.39% avg_auc=65.58%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.442200 Test loss=0.652198 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.43689867854118347
[5/24] Train loss=0.4468569755554199
[10/24] Train loss=0.5104684829711914
[15/24] Train loss=0.4694315195083618
[20/24] Train loss=0.43138250708580017
Test set avg_accuracy=52.43% avg_sensitivity=85.50%, avg_specificity=39.91% avg_auc=65.46%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.443226 Test loss=0.652086 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.4358760416507721
[5/24] Train loss=0.4425411522388458
[10/24] Train loss=0.50674968957901
[15/24] Train loss=0.4751299023628235
[20/24] Train loss=0.434038907289505
Test set avg_accuracy=49.69% avg_sensitivity=89.00%, avg_specificity=34.79% avg_auc=64.82%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.442765 Test loss=0.661102 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.43647369742393494
[5/24] Train loss=0.4424627125263214
[10/24] Train loss=0.5076965689659119
[15/24] Train loss=0.4761177897453308
[20/24] Train loss=0.4342035949230194
Test set avg_accuracy=50.65% avg_sensitivity=88.44%, avg_specificity=36.34% avg_auc=65.53%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.443167 Test loss=0.656438 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.43491771817207336
[5/24] Train loss=0.4410965144634247
[10/24] Train loss=0.5092960596084595
[15/24] Train loss=0.4723578095436096
[20/24] Train loss=0.430214524269104
Test set avg_accuracy=52.20% avg_sensitivity=85.07%, avg_specificity=39.75% avg_auc=65.79%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.442102 Test loss=0.651195 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.440228670835495
[5/24] Train loss=0.44033530354499817
[10/24] Train loss=0.5072438716888428
[15/24] Train loss=0.4714447855949402
[20/24] Train loss=0.4307170510292053
Test set avg_accuracy=50.04% avg_sensitivity=89.34%, avg_specificity=35.15% avg_auc=65.12%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.442780 Test loss=0.663785 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.4356566369533539
[5/24] Train loss=0.44315701723098755
[10/24] Train loss=0.5073258280754089
[15/24] Train loss=0.4709095060825348
[20/24] Train loss=0.4320576786994934
Test set avg_accuracy=50.36% avg_sensitivity=86.92%, avg_specificity=36.52% avg_auc=64.99%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.441879 Test loss=0.661163 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.43838223814964294
[5/24] Train loss=0.4401872158050537
[10/24] Train loss=0.5055350661277771
[15/24] Train loss=0.48787590861320496
[20/24] Train loss=0.4313795864582062
Test set avg_accuracy=50.82% avg_sensitivity=86.92%, avg_specificity=37.15% avg_auc=65.58%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.442939 Test loss=0.657767 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.4407224655151367
[5/24] Train loss=0.4455445408821106
[10/24] Train loss=0.5080409049987793
[15/24] Train loss=0.4827631115913391
[20/24] Train loss=0.43103110790252686
Test set avg_accuracy=50.49% avg_sensitivity=87.01%, avg_specificity=36.66% avg_auc=65.77%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.446178 Test loss=0.657780 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.4416027069091797
[5/24] Train loss=0.4421873986721039
[10/24] Train loss=0.50691819190979
[15/24] Train loss=0.4771836996078491
[20/24] Train loss=0.43227896094322205
Test set avg_accuracy=51.51% avg_sensitivity=86.02%, avg_specificity=38.44% avg_auc=65.95%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.444832 Test loss=0.651356 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.43522724509239197
[5/24] Train loss=0.45141884684562683
[10/24] Train loss=0.5075448155403137
[15/24] Train loss=0.4729829430580139
[20/24] Train loss=0.43313905596733093
Test set avg_accuracy=53.61% avg_sensitivity=85.92%, avg_specificity=41.36% avg_auc=67.30%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.444496 Test loss=0.635614 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.43856120109558105
[5/24] Train loss=0.4403981864452362
[10/24] Train loss=0.5115826725959778
[15/24] Train loss=0.4665350317955017
[20/24] Train loss=0.43120673298835754
Test set avg_accuracy=53.82% avg_sensitivity=83.89%, avg_specificity=42.42% avg_auc=65.87%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.441964 Test loss=0.644473 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.4341294765472412
[5/24] Train loss=0.4413130283355713
[10/24] Train loss=0.5069260597229004
[15/24] Train loss=0.4719732105731964
[20/24] Train loss=0.43056008219718933
Test set avg_accuracy=50.46% avg_sensitivity=88.44%, avg_specificity=36.07% avg_auc=65.07%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.441827 Test loss=0.665334 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.4338836371898651
[5/24] Train loss=0.445531964302063
[10/24] Train loss=0.5078002214431763
[15/24] Train loss=0.47046881914138794
[20/24] Train loss=0.4316745400428772
Test set avg_accuracy=51.18% avg_sensitivity=87.25%, avg_specificity=37.52% avg_auc=65.84%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.442534 Test loss=0.655112 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.43443816900253296
[5/24] Train loss=0.4392896294593811
[10/24] Train loss=0.5136148929595947
[15/24] Train loss=0.4642949104309082
[20/24] Train loss=0.4298880100250244
Test set avg_accuracy=52.11% avg_sensitivity=86.64%, avg_specificity=39.03% avg_auc=65.69%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.440722 Test loss=0.653365 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.4330388009548187
[5/24] Train loss=0.4382084012031555
[10/24] Train loss=0.5088796615600586
[15/24] Train loss=0.46386247873306274
[20/24] Train loss=0.42853954434394836
Test set avg_accuracy=51.91% avg_sensitivity=86.26%, avg_specificity=38.90% avg_auc=65.10%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.439244 Test loss=0.660777 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.43123364448547363
[5/24] Train loss=0.4397508203983307
[10/24] Train loss=0.5057930946350098
[15/24] Train loss=0.4729607403278351
[20/24] Train loss=0.42861273884773254
Test set avg_accuracy=51.74% avg_sensitivity=87.30%, avg_specificity=38.28% avg_auc=65.53%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.440011 Test loss=0.658485 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.43432188034057617
[5/24] Train loss=0.43979620933532715
[10/24] Train loss=0.5092579126358032
[15/24] Train loss=0.46546950936317444
[20/24] Train loss=0.4309379458427429
Test set avg_accuracy=50.47% avg_sensitivity=89.05%, avg_specificity=35.85% avg_auc=64.56%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.440281 Test loss=0.669285 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.4315842390060425
[5/24] Train loss=0.44171613454818726
[10/24] Train loss=0.5081306099891663
[15/24] Train loss=0.46811869740486145
[20/24] Train loss=0.42968711256980896
Test set avg_accuracy=51.59% avg_sensitivity=88.20%, avg_specificity=37.72% avg_auc=65.15%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.440172 Test loss=0.662189 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.4332432746887207
[5/24] Train loss=0.4371943473815918
[10/24] Train loss=0.5091894268989563
[15/24] Train loss=0.4658838212490082
[20/24] Train loss=0.42774665355682373
Test set avg_accuracy=52.02% avg_sensitivity=87.44%, avg_specificity=38.60% avg_auc=65.29%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.439152 Test loss=0.660108 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.4309515953063965
[5/24] Train loss=0.4374518096446991
[10/24] Train loss=0.5058451294898987
[15/24] Train loss=0.4637409746646881
[20/24] Train loss=0.4286867082118988
Test set avg_accuracy=51.45% avg_sensitivity=88.53%, avg_specificity=37.40% avg_auc=64.96%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.438654 Test loss=0.665306 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.4309890568256378
[5/24] Train loss=0.4385305643081665
[10/24] Train loss=0.5077341198921204
[15/24] Train loss=0.4629853069782257
[20/24] Train loss=0.42863962054252625
Test set avg_accuracy=50.68% avg_sensitivity=89.24%, avg_specificity=36.07% avg_auc=64.96%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.438664 Test loss=0.666380 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.43203914165496826
[5/24] Train loss=0.4369989037513733
[10/24] Train loss=0.5067486763000488
[15/24] Train loss=0.4623253047466278
[20/24] Train loss=0.4275403916835785
Test set avg_accuracy=51.58% avg_sensitivity=88.15%, avg_specificity=37.72% avg_auc=65.02%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.438107 Test loss=0.664409 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.43063852190971375
[5/24] Train loss=0.4380515515804291
[10/24] Train loss=0.506524384021759
[15/24] Train loss=0.46208539605140686
[20/24] Train loss=0.4284207820892334
Test set avg_accuracy=51.18% avg_sensitivity=88.91%, avg_specificity=36.89% avg_auc=64.89%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.438163 Test loss=0.666589 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.4314125180244446
[5/24] Train loss=0.4369184076786041
[10/24] Train loss=0.5066131949424744
[15/24] Train loss=0.46226638555526733
[20/24] Train loss=0.427737832069397
Test set avg_accuracy=51.25% avg_sensitivity=88.91%, avg_specificity=36.98% avg_auc=64.87%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.437792 Test loss=0.666959 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.43063998222351074
[5/24] Train loss=0.4369587302207947
[10/24] Train loss=0.5063655972480774
[15/24] Train loss=0.46242088079452515
[20/24] Train loss=0.4277273416519165
Test set avg_accuracy=51.25% avg_sensitivity=89.24%, avg_specificity=36.86% avg_auc=64.84%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.437679 Test loss=0.667409 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.43063339591026306
[5/24] Train loss=0.4369871914386749
[10/24] Train loss=0.5064030885696411
[15/24] Train loss=0.4615829586982727
[20/24] Train loss=0.4276859760284424
Test set avg_accuracy=51.22% avg_sensitivity=89.24%, avg_specificity=36.82% avg_auc=64.84%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.437571 Test loss=0.667637 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.43059223890304565
[5/24] Train loss=0.4369339346885681
[10/24] Train loss=0.5062601566314697
[15/24] Train loss=0.4615750312805176
[20/24] Train loss=0.4276806712150574
Test set avg_accuracy=51.04% avg_sensitivity=89.24%, avg_specificity=36.57% avg_auc=64.80%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.437512 Test loss=0.668291 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.43055084347724915
[5/24] Train loss=0.4368952214717865
[10/24] Train loss=0.5062603950500488
[15/24] Train loss=0.4615509510040283
[20/24] Train loss=0.42764270305633545
Test set avg_accuracy=50.92% avg_sensitivity=89.24%, avg_specificity=36.41% avg_auc=64.78%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.437457 Test loss=0.668571 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.4304993152618408
[5/24] Train loss=0.43687132000923157
[10/24] Train loss=0.5062366127967834
[15/24] Train loss=0.46154850721359253
[20/24] Train loss=0.42762282490730286
Test set avg_accuracy=50.92% avg_sensitivity=89.24%, avg_specificity=36.41% avg_auc=64.78%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.437418 Test loss=0.668680 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.43047845363616943
[5/24] Train loss=0.43684127926826477
[10/24] Train loss=0.5061862468719482
[15/24] Train loss=0.46154358983039856
[20/24] Train loss=0.4276067614555359
Test set avg_accuracy=50.92% avg_sensitivity=89.24%, avg_specificity=36.41% avg_auc=64.77%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.437386 Test loss=0.668769 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.430460125207901
[5/24] Train loss=0.436825156211853
[10/24] Train loss=0.5061564445495605
[15/24] Train loss=0.4615340828895569
[20/24] Train loss=0.42759329080581665
Test set avg_accuracy=50.92% avg_sensitivity=89.24%, avg_specificity=36.41% avg_auc=64.77%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.437364 Test loss=0.668834 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.4304456412792206
[5/24] Train loss=0.43681350350379944
[10/24] Train loss=0.5061348080635071
[15/24] Train loss=0.4615251123905182
[20/24] Train loss=0.42758405208587646
Test set avg_accuracy=50.92% avg_sensitivity=89.24%, avg_specificity=36.41% avg_auc=64.77%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.437348 Test loss=0.668880 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.4304357171058655
[5/24] Train loss=0.4368049204349518
[10/24] Train loss=0.5061185956001282
[15/24] Train loss=0.4615185856819153
[20/24] Train loss=0.4275784194469452
Test set avg_accuracy=50.92% avg_sensitivity=89.24%, avg_specificity=36.41% avg_auc=64.77%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.437339 Test loss=0.668908 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.43042999505996704
[5/24] Train loss=0.43679919838905334
[10/24] Train loss=0.5061080455780029
[15/24] Train loss=0.4615148901939392
[20/24] Train loss=0.42757534980773926
Test set avg_accuracy=50.92% avg_sensitivity=89.24%, avg_specificity=36.41% avg_auc=64.76%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.437333 Test loss=0.668920 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.4304271340370178
[5/24] Train loss=0.4367961287498474
[10/24] Train loss=0.5061027407646179
[15/24] Train loss=0.46151331067085266
[20/24] Train loss=0.4275742471218109
Test set avg_accuracy=50.92% avg_sensitivity=89.24%, avg_specificity=36.41% avg_auc=64.76%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.437331 Test loss=0.668924 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=65.76% sen=47.25%, spe=72.76%, auc=71.12%!
Fold[3] Avg_overlap=0.15%(0.2359060824046111)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 1,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'SwEDModel',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.7029736638069153
[5/24] Train loss=0.7020360827445984
[10/24] Train loss=0.6995874047279358
[15/24] Train loss=0.6978639364242554
[20/24] Train loss=0.6984338760375977
Test set avg_accuracy=39.79% avg_sensitivity=75.56%, avg_specificity=27.19% avg_auc=50.53%
Best model saved!! Metric=-132.9267684457648!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.699513 Test loss=0.697017 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6976032853126526
[5/24] Train loss=0.6965892314910889
[10/24] Train loss=0.6950407028198242
[15/24] Train loss=0.693782389163971
[20/24] Train loss=0.6941249966621399
Test set avg_accuracy=39.79% avg_sensitivity=75.56%, avg_specificity=27.19% avg_auc=50.54%
Best model saved!! Metric=-132.91436049231942!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.694737 Test loss=0.692759 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6932234764099121
[5/24] Train loss=0.6921064257621765
[10/24] Train loss=0.6911876797676086
[15/24] Train loss=0.6902015805244446
[20/24] Train loss=0.6902238130569458
Test set avg_accuracy=39.79% avg_sensitivity=75.56%, avg_specificity=27.19% avg_auc=50.72%
Best model saved!! Metric=-132.73993634675884!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.690609 Test loss=0.688791 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6890818476676941
[5/24] Train loss=0.6877385973930359
[10/24] Train loss=0.6874195337295532
[15/24] Train loss=0.6867066025733948
[20/24] Train loss=0.6863397359848022
Test set avg_accuracy=39.79% avg_sensitivity=75.56%, avg_specificity=27.19% avg_auc=50.75%
Best model saved!! Metric=-132.7113056541812!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.686567 Test loss=0.684887 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6849683523178101
[5/24] Train loss=0.6833910346031189
[10/24] Train loss=0.6837566494941711
[15/24] Train loss=0.6830846071243286
[20/24] Train loss=0.6824604272842407
Test set avg_accuracy=59.41% avg_sensitivity=43.73%, avg_specificity=64.94% avg_auc=50.78%
Best model saved!! Metric=-107.13363776502858!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.682533 Test loss=0.680876 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6809115409851074
[5/24] Train loss=0.6788156628608704
[10/24] Train loss=0.67982417345047
[15/24] Train loss=0.6790202856063843
[20/24] Train loss=0.6777828335762024
Test set avg_accuracy=70.94% avg_sensitivity=8.15%, avg_specificity=93.06% avg_auc=50.81%
Best model saved!! Metric=-103.04391517373027!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.678033 Test loss=0.675905 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6758013367652893
[5/24] Train loss=0.6729512214660645
[10/24] Train loss=0.6746217012405396
[15/24] Train loss=0.6735698580741882
[20/24] Train loss=0.6715689897537231
Test set avg_accuracy=73.98% avg_sensitivity=0.50%, avg_specificity=99.88% avg_auc=50.55%
Best model saved!! Metric=-101.08752768222114!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.672094 Test loss=0.669425 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6692211031913757
[5/24] Train loss=0.665021538734436
[10/24] Train loss=0.6678460240364075
[15/24] Train loss=0.6663243174552917
[20/24] Train loss=0.6631919145584106
Test set avg_accuracy=73.93% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=50.51%
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.664242 Test loss=0.660694 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6603749394416809
[5/24] Train loss=0.6541433334350586
[10/24] Train loss=0.6583811640739441
[15/24] Train loss=0.6560958027839661
[20/24] Train loss=0.6505709886550903
Test set avg_accuracy=73.93% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=50.60%
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.653076 Test loss=0.647307 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6468077898025513
[5/24] Train loss=0.6369245052337646
[10/24] Train loss=0.6433874368667603
[15/24] Train loss=0.6401111483573914
[20/24] Train loss=0.6313993334770203
Test set avg_accuracy=73.93% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=50.87%
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.635662 Test loss=0.627327 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6266730427742004
[5/24] Train loss=0.6113375425338745
[10/24] Train loss=0.6229575872421265
[15/24] Train loss=0.6188650727272034
[20/24] Train loss=0.606389582157135
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.76%
Best model saved!! Metric=-100.29384490668141!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.611465 Test loss=0.601890 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6009412407875061
[5/24] Train loss=0.5791670680046082
[10/24] Train loss=0.6019483804702759
[15/24] Train loss=0.597270131111145
[20/24] Train loss=0.5829529166221619
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.81%
Best model saved!! Metric=-99.24199365322733!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.584858 Test loss=0.579530 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5787509083747864
[5/24] Train loss=0.5521970987319946
[10/24] Train loss=0.5935835838317871
[15/24] Train loss=0.585953950881958
[20/24] Train loss=0.572043240070343
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=55.70%
Best model saved!! Metric=-96.35282369339299!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.568465 Test loss=0.570431 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5698854923248291
[5/24] Train loss=0.543820321559906
[10/24] Train loss=0.5912063717842102
[15/24] Train loss=0.5834779143333435
[20/24] Train loss=0.5675193071365356
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=58.21%
Best model saved!! Metric=-93.84676469612637!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.563507 Test loss=0.567730 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5668572783470154
[5/24] Train loss=0.5414726734161377
[10/24] Train loss=0.5903112292289734
[15/24] Train loss=0.5822939872741699
[20/24] Train loss=0.5644713640213013
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=60.55%
Best model saved!! Metric=-91.504468684421!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.560939 Test loss=0.566170 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5641829371452332
[5/24] Train loss=0.5394769906997681
[10/24] Train loss=0.590060830116272
[15/24] Train loss=0.5802746415138245
[20/24] Train loss=0.5605647563934326
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=62.78%
Best model saved!! Metric=-89.27607064537045!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.558019 Test loss=0.563188 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5604246854782104
[5/24] Train loss=0.5359721779823303
[10/24] Train loss=0.5889664888381958
[15/24] Train loss=0.5771771669387817
[20/24] Train loss=0.5531700253486633
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=65.70%
Best model saved!! Metric=-86.35879359099394!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.553643 Test loss=0.558542 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5538036823272705
[5/24] Train loss=0.5303894877433777
[10/24] Train loss=0.5883185267448425
[15/24] Train loss=0.5717943906784058
[20/24] Train loss=0.5433859825134277
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=69.86%
Best model saved!! Metric=-82.19469321469856!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.546186 Test loss=0.551246 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.539419949054718
[5/24] Train loss=0.5170884728431702
[10/24] Train loss=0.5779394507408142
[15/24] Train loss=0.5624538064002991
[20/24] Train loss=0.5285619497299194
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=72.63%
Best model saved!! Metric=-79.42027482431635!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.533779 Test loss=0.558224 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5198168158531189
[5/24] Train loss=0.5016156435012817
[10/24] Train loss=0.5627785921096802
[15/24] Train loss=0.55169677734375
[20/24] Train loss=0.5073503255844116
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=67.53%
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.516479 Test loss=0.641900 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.4987697899341583
[5/24] Train loss=0.4952199459075928
[10/24] Train loss=0.5390514731407166
[15/24] Train loss=0.5420448780059814
[20/24] Train loss=0.49601930379867554
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=69.22%
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.503463 Test loss=0.623542 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.49114444851875305
[5/24] Train loss=0.48553267121315
[10/24] Train loss=0.527301013469696
[15/24] Train loss=0.5317909121513367
[20/24] Train loss=0.48733845353126526
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=63.93%
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.493234 Test loss=0.632937 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.4843021035194397
[5/24] Train loss=0.48258206248283386
[10/24] Train loss=0.5235407948493958
[15/24] Train loss=0.5283685326576233
[20/24] Train loss=0.4841863512992859
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=62.30%
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.487634 Test loss=0.639216 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.4765467643737793
[5/24] Train loss=0.4795709252357483
[10/24] Train loss=0.5151116847991943
[15/24] Train loss=0.5272324085235596
[20/24] Train loss=0.47882571816444397
Test set avg_accuracy=69.54% avg_sensitivity=15.44%, avg_specificity=88.61% avg_auc=63.90%
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.483137 Test loss=0.632205 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.4730066657066345
[5/24] Train loss=0.47399425506591797
[10/24] Train loss=0.5101445317268372
[15/24] Train loss=0.518423318862915
[20/24] Train loss=0.4719464182853699
Test set avg_accuracy=68.29% avg_sensitivity=21.44%, avg_specificity=84.80% avg_auc=67.30%
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.477336 Test loss=0.614851 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.4704526960849762
[5/24] Train loss=0.4700997769832611
[10/24] Train loss=0.5056032538414001
[15/24] Train loss=0.5187592506408691
[20/24] Train loss=0.46724408864974976
Test set avg_accuracy=66.58% avg_sensitivity=29.94%, avg_specificity=79.49% avg_auc=66.23%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.474879 Test loss=0.618831 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.46419355273246765
[5/24] Train loss=0.4678250253200531
[10/24] Train loss=0.49864107370376587
[15/24] Train loss=0.5106167793273926
[20/24] Train loss=0.47244876623153687
Test set avg_accuracy=59.65% avg_sensitivity=55.52%, avg_specificity=61.10% avg_auc=68.55%
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.471059 Test loss=0.618746 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.4539443552494049
[5/24] Train loss=0.46279361844062805
[10/24] Train loss=0.49652865529060364
[15/24] Train loss=0.5082093477249146
[20/24] Train loss=0.4521438777446747
Test set avg_accuracy=71.85% avg_sensitivity=34.23%, avg_specificity=85.10% avg_auc=67.27%
Best model saved!! Metric=-67.5452646115422!!
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.465810 Test loss=0.609529 Current lr=[0.000210185142098938]

[0/24] Train loss=0.444207102060318
[5/24] Train loss=0.4514405131340027
[10/24] Train loss=0.4854426383972168
[15/24] Train loss=0.5018894076347351
[20/24] Train loss=0.4355860650539398
Test set avg_accuracy=76.91% avg_sensitivity=30.33%, avg_specificity=93.33% avg_auc=70.38%
Best model saved!! Metric=-55.04906792633464!!
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.453659 Test loss=0.585675 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.4309775233268738
[5/24] Train loss=0.4301053583621979
[10/24] Train loss=0.4707717001438141
[15/24] Train loss=0.4881039559841156
[20/24] Train loss=0.439435213804245
Test set avg_accuracy=77.38% avg_sensitivity=37.88%, avg_specificity=91.30% avg_auc=72.08%
Best model saved!! Metric=-47.35935541938597!!
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.436907 Test loss=0.554054 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.4305160641670227
[5/24] Train loss=0.43531617522239685
[10/24] Train loss=0.47073084115982056
[15/24] Train loss=0.5041443705558777
[20/24] Train loss=0.4135228097438812
Test set avg_accuracy=78.09% avg_sensitivity=43.33%, avg_specificity=90.33% avg_auc=76.28%
Best model saved!! Metric=-37.97444699343739!!
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.440495 Test loss=0.540919 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.40976032614707947
[5/24] Train loss=0.4220491349697113
[10/24] Train loss=0.4554659426212311
[15/24] Train loss=0.4856223165988922
[20/24] Train loss=0.39388948678970337
Test set avg_accuracy=77.41% avg_sensitivity=43.18%, avg_specificity=89.47% avg_auc=68.40%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.427582 Test loss=0.589400 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3957216441631317
[5/24] Train loss=0.41043534874916077
[10/24] Train loss=0.4519314169883728
[15/24] Train loss=0.4775623083114624
[20/24] Train loss=0.3895953595638275
Test set avg_accuracy=70.12% avg_sensitivity=68.52%, avg_specificity=70.68% avg_auc=71.11%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.419208 Test loss=0.604195 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3893585801124573
[5/24] Train loss=0.40431100130081177
[10/24] Train loss=0.442325621843338
[15/24] Train loss=0.4765491187572479
[20/24] Train loss=0.3846462368965149
Test set avg_accuracy=76.98% avg_sensitivity=57.72%, avg_specificity=83.76% avg_auc=71.04%
Best model saved!! Metric=-36.49611312608354!!
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.412455 Test loss=0.581972 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.40389546751976013
[5/24] Train loss=0.4145026206970215
[10/24] Train loss=0.45397064089775085
[15/24] Train loss=0.5018131136894226
[20/24] Train loss=0.40697750449180603
Test set avg_accuracy=77.76% avg_sensitivity=30.58%, avg_specificity=94.38% avg_auc=72.07%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.424078 Test loss=0.538656 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4001430869102478
[5/24] Train loss=0.40776029229164124
[10/24] Train loss=0.4420236647129059
[15/24] Train loss=0.4902471899986267
[20/24] Train loss=0.3903254568576813
Test set avg_accuracy=73.16% avg_sensitivity=63.77%, avg_specificity=76.47% avg_auc=73.72%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.418018 Test loss=0.582186 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.38615041971206665
[5/24] Train loss=0.4029182195663452
[10/24] Train loss=0.44115954637527466
[15/24] Train loss=0.4822571575641632
[20/24] Train loss=0.3776504099369049
Test set avg_accuracy=71.46% avg_sensitivity=65.92%, avg_specificity=73.41% avg_auc=75.17%
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.412610 Test loss=0.580282 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.38452696800231934
[5/24] Train loss=0.3974526524543762
[10/24] Train loss=0.4397428631782532
[15/24] Train loss=0.49510458111763
[20/24] Train loss=0.380771666765213
Test set avg_accuracy=78.84% avg_sensitivity=59.32%, avg_specificity=85.72% avg_auc=75.53%
Best model saved!! Metric=-26.592574531347843!!
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.410597 Test loss=0.553313 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3751292824745178
[5/24] Train loss=0.4159358739852905
[10/24] Train loss=0.4428860545158386
[15/24] Train loss=0.4722360074520111
[20/24] Train loss=0.36789876222610474
Test set avg_accuracy=71.15% avg_sensitivity=66.77%, avg_specificity=72.69% avg_auc=75.40%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.408717 Test loss=0.575916 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.38106659054756165
[5/24] Train loss=0.3914075493812561
[10/24] Train loss=0.427295446395874
[15/24] Train loss=0.46461784839630127
[20/24] Train loss=0.3694400489330292
Test set avg_accuracy=68.58% avg_sensitivity=70.36%, avg_specificity=67.95% avg_auc=73.97%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.402226 Test loss=0.592989 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3688320219516754
[5/24] Train loss=0.3951779305934906
[10/24] Train loss=0.4382064640522003
[15/24] Train loss=0.46934187412261963
[20/24] Train loss=0.36725378036499023
Test set avg_accuracy=66.22% avg_sensitivity=74.01%, avg_specificity=63.48% avg_auc=75.04%
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.405068 Test loss=0.596737 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3676249384880066
[5/24] Train loss=0.40138086676597595
[10/24] Train loss=0.4364669919013977
[15/24] Train loss=0.5067750215530396
[20/24] Train loss=0.39398255944252014
Test set avg_accuracy=66.50% avg_sensitivity=71.01%, avg_specificity=64.91% avg_auc=74.98%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.411233 Test loss=0.594133 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.38316068053245544
[5/24] Train loss=0.4150347113609314
[10/24] Train loss=0.4398549199104309
[15/24] Train loss=0.4640820324420929
[20/24] Train loss=0.3680673837661743
Test set avg_accuracy=69.73% avg_sensitivity=70.06%, avg_specificity=69.61% avg_auc=76.84%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.404760 Test loss=0.573005 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3734460771083832
[5/24] Train loss=0.39111730456352234
[10/24] Train loss=0.4318835437297821
[15/24] Train loss=0.4761609137058258
[20/24] Train loss=0.36638179421424866
Test set avg_accuracy=70.05% avg_sensitivity=68.87%, avg_specificity=70.47% avg_auc=75.60%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.401055 Test loss=0.576594 Current lr=[0.00029967723776099]

[0/24] Train loss=0.374848335981369
[5/24] Train loss=0.39796438813209534
[10/24] Train loss=0.4216586649417877
[15/24] Train loss=0.4602815806865692
[20/24] Train loss=0.35797789692878723
Test set avg_accuracy=58.68% avg_sensitivity=82.76%, avg_specificity=50.20% avg_auc=74.59%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.400940 Test loss=0.630076 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.37126705050468445
[5/24] Train loss=0.40012386441230774
[10/24] Train loss=0.4267769753932953
[15/24] Train loss=0.4619898200035095
[20/24] Train loss=0.36010438203811646
Test set avg_accuracy=65.23% avg_sensitivity=76.11%, avg_specificity=61.40% avg_auc=73.73%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.401117 Test loss=0.608850 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.37623804807662964
[5/24] Train loss=0.3972012400627136
[10/24] Train loss=0.42649394273757935
[15/24] Train loss=0.45422258973121643
[20/24] Train loss=0.353834331035614
Test set avg_accuracy=64.90% avg_sensitivity=80.06%, avg_specificity=59.55% avg_auc=73.49%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.396483 Test loss=0.613471 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3609250485897064
[5/24] Train loss=0.398995578289032
[10/24] Train loss=0.4336681365966797
[15/24] Train loss=0.4538528323173523
[20/24] Train loss=0.3541199564933777
Test set avg_accuracy=63.50% avg_sensitivity=79.51%, avg_specificity=57.86% avg_auc=70.87%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.400846 Test loss=0.629257 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.38448742032051086
[5/24] Train loss=0.38912948966026306
[10/24] Train loss=0.43713808059692383
[15/24] Train loss=0.45607632398605347
[20/24] Train loss=0.3541775643825531
Test set avg_accuracy=66.61% avg_sensitivity=75.01%, avg_specificity=63.66% avg_auc=74.28%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.400507 Test loss=0.599237 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3621302545070648
[5/24] Train loss=0.39007824659347534
[10/24] Train loss=0.42294466495513916
[15/24] Train loss=0.44858935475349426
[20/24] Train loss=0.36442726850509644
Test set avg_accuracy=63.12% avg_sensitivity=80.91%, avg_specificity=56.86% avg_auc=74.56%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.392691 Test loss=0.615245 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3558112680912018
[5/24] Train loss=0.3859247863292694
[10/24] Train loss=0.4162377119064331
[15/24] Train loss=0.4514155983924866
[20/24] Train loss=0.3726441562175751
Test set avg_accuracy=71.00% avg_sensitivity=69.67%, avg_specificity=71.47% avg_auc=77.34%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.390815 Test loss=0.559519 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3627018928527832
[5/24] Train loss=0.3874693214893341
[10/24] Train loss=0.4217672049999237
[15/24] Train loss=0.44443464279174805
[20/24] Train loss=0.35028305649757385
Test set avg_accuracy=59.95% avg_sensitivity=82.61%, avg_specificity=51.96% avg_auc=75.57%
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.391245 Test loss=0.623961 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.36852312088012695
[5/24] Train loss=0.39628589153289795
[10/24] Train loss=0.41707947850227356
[15/24] Train loss=0.4474280774593353
[20/24] Train loss=0.36131006479263306
Test set avg_accuracy=68.06% avg_sensitivity=77.01%, avg_specificity=64.91% avg_auc=76.81%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.391718 Test loss=0.582363 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3581784665584564
[5/24] Train loss=0.3882697820663452
[10/24] Train loss=0.42294758558273315
[15/24] Train loss=0.45584556460380554
[20/24] Train loss=0.37751421332359314
Test set avg_accuracy=67.63% avg_sensitivity=74.66%, avg_specificity=65.15% avg_auc=77.19%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.394811 Test loss=0.581094 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.37196874618530273
[5/24] Train loss=0.3869125545024872
[10/24] Train loss=0.42172855138778687
[15/24] Train loss=0.4365764260292053
[20/24] Train loss=0.3431745171546936
Test set avg_accuracy=67.11% avg_sensitivity=77.41%, avg_specificity=63.48% avg_auc=75.41%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.392363 Test loss=0.596218 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.361040323972702
[5/24] Train loss=0.38203325867652893
[10/24] Train loss=0.4098825454711914
[15/24] Train loss=0.46454763412475586
[20/24] Train loss=0.35037004947662354
Test set avg_accuracy=75.96% avg_sensitivity=65.97%, avg_specificity=79.49% avg_auc=78.22%
Best model saved!! Metric=-26.362364758532422!!
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.395203 Test loss=0.542764 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3636802136898041
[5/24] Train loss=0.3787536919116974
[10/24] Train loss=0.41751158237457275
[15/24] Train loss=0.4518372118473053
[20/24] Train loss=0.3522544503211975
Test set avg_accuracy=73.85% avg_sensitivity=68.02%, avg_specificity=75.91% avg_auc=79.37%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.392296 Test loss=0.544528 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.37890392541885376
[5/24] Train loss=0.3983626961708069
[10/24] Train loss=0.43725350499153137
[15/24] Train loss=0.46297571063041687
[20/24] Train loss=0.3547155261039734
Test set avg_accuracy=65.98% avg_sensitivity=77.71%, avg_specificity=61.84% avg_auc=76.38%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.398065 Test loss=0.598186 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.36615872383117676
[5/24] Train loss=0.3770512342453003
[10/24] Train loss=0.4148643910884857
[15/24] Train loss=0.4567490816116333
[20/24] Train loss=0.35052961111068726
Test set avg_accuracy=72.06% avg_sensitivity=71.01%, avg_specificity=72.42% avg_auc=78.77%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.389836 Test loss=0.554448 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3686327040195465
[5/24] Train loss=0.38822630047798157
[10/24] Train loss=0.43612080812454224
[15/24] Train loss=0.4476998448371887
[20/24] Train loss=0.3520551919937134
Test set avg_accuracy=63.83% avg_sensitivity=79.96%, avg_specificity=58.14% avg_auc=76.12%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.389020 Test loss=0.606998 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.363458514213562
[5/24] Train loss=0.38241565227508545
[10/24] Train loss=0.4164009094238281
[15/24] Train loss=0.43738794326782227
[20/24] Train loss=0.3391415774822235
Test set avg_accuracy=69.53% avg_sensitivity=74.66%, avg_specificity=67.72% avg_auc=78.26%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.385252 Test loss=0.568852 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.356704980134964
[5/24] Train loss=0.36993199586868286
[10/24] Train loss=0.41601136326789856
[15/24] Train loss=0.45224279165267944
[20/24] Train loss=0.3405515253543854
Test set avg_accuracy=75.59% avg_sensitivity=67.97%, avg_specificity=78.27% avg_auc=81.69%
Best model saved!! Metric=-22.48489009025488!!
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.386418 Test loss=0.521717 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3709804117679596
[5/24] Train loss=0.3798047602176666
[10/24] Train loss=0.408841073513031
[15/24] Train loss=0.46260690689086914
[20/24] Train loss=0.350517600774765
Test set avg_accuracy=70.94% avg_sensitivity=73.06%, avg_specificity=70.19% avg_auc=78.75%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.387362 Test loss=0.555642 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.364845335483551
[5/24] Train loss=0.37299400568008423
[10/24] Train loss=0.40942907333374023
[15/24] Train loss=0.4328533411026001
[20/24] Train loss=0.33718937635421753
Test set avg_accuracy=67.25% avg_sensitivity=77.26%, avg_specificity=63.73% avg_auc=77.99%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.383384 Test loss=0.577882 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3622815012931824
[5/24] Train loss=0.3879753351211548
[10/24] Train loss=0.412126362323761
[15/24] Train loss=0.47791481018066406
[20/24] Train loss=0.34255412220954895
Test set avg_accuracy=72.40% avg_sensitivity=73.56%, avg_specificity=71.98% avg_auc=80.29%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.385984 Test loss=0.539928 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.36351537704467773
[5/24] Train loss=0.37372273206710815
[10/24] Train loss=0.4043866693973541
[15/24] Train loss=0.4484667181968689
[20/24] Train loss=0.340483695268631
Test set avg_accuracy=72.27% avg_sensitivity=75.61%, avg_specificity=71.09% avg_auc=80.37%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.385410 Test loss=0.545095 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.35517701506614685
[5/24] Train loss=0.3710014820098877
[10/24] Train loss=0.4108242988586426
[15/24] Train loss=0.4646288752555847
[20/24] Train loss=0.3449208736419678
Test set avg_accuracy=71.42% avg_sensitivity=71.56%, avg_specificity=71.37% avg_auc=80.14%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.383989 Test loss=0.542131 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.37201038002967834
[5/24] Train loss=0.3732525110244751
[10/24] Train loss=0.4111179709434509
[15/24] Train loss=0.43478918075561523
[20/24] Train loss=0.3372364640235901
Test set avg_accuracy=68.19% avg_sensitivity=77.71%, avg_specificity=64.84% avg_auc=77.93%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.381566 Test loss=0.573446 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3556000590324402
[5/24] Train loss=0.3711038827896118
[10/24] Train loss=0.40584343671798706
[15/24] Train loss=0.4245835244655609
[20/24] Train loss=0.33781686425209045
Test set avg_accuracy=73.74% avg_sensitivity=71.36%, avg_specificity=74.57% avg_auc=79.60%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.379238 Test loss=0.535087 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3536865711212158
[5/24] Train loss=0.37341243028640747
[10/24] Train loss=0.4085821509361267
[15/24] Train loss=0.4242292642593384
[20/24] Train loss=0.3404043912887573
Test set avg_accuracy=66.56% avg_sensitivity=80.46%, avg_specificity=61.67% avg_auc=78.93%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.378292 Test loss=0.580423 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3706708550453186
[5/24] Train loss=0.37736475467681885
[10/24] Train loss=0.415825217962265
[15/24] Train loss=0.433208167552948
[20/24] Train loss=0.33793067932128906
Test set avg_accuracy=69.78% avg_sensitivity=73.86%, avg_specificity=68.34% avg_auc=77.77%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.378836 Test loss=0.566886 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3533823788166046
[5/24] Train loss=0.3693266808986664
[10/24] Train loss=0.40930503606796265
[15/24] Train loss=0.43183037638664246
[20/24] Train loss=0.3520065248012543
Test set avg_accuracy=72.68% avg_sensitivity=74.91%, avg_specificity=71.90% avg_auc=81.42%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.380981 Test loss=0.532956 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.35838446021080017
[5/24] Train loss=0.373324990272522
[10/24] Train loss=0.4186520576477051
[15/24] Train loss=0.44220444560050964
[20/24] Train loss=0.347522497177124
Test set avg_accuracy=76.55% avg_sensitivity=64.17%, avg_specificity=80.91% avg_auc=82.29%
Best model saved!! Metric=-22.07757233663608!!
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.385529 Test loss=0.503801 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3600958287715912
[5/24] Train loss=0.3667154908180237
[10/24] Train loss=0.4093721807003021
[15/24] Train loss=0.4510570466518402
[20/24] Train loss=0.33637169003486633
Test set avg_accuracy=72.51% avg_sensitivity=74.71%, avg_specificity=71.74% avg_auc=79.66%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.383093 Test loss=0.547238 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3632555305957794
[5/24] Train loss=0.3663325607776642
[10/24] Train loss=0.40933528542518616
[15/24] Train loss=0.43120524287223816
[20/24] Train loss=0.3361569344997406
Test set avg_accuracy=68.12% avg_sensitivity=77.31%, avg_specificity=64.89% avg_auc=78.43%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.377336 Test loss=0.571672 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.35718706250190735
[5/24] Train loss=0.3660770356655121
[10/24] Train loss=0.41354289650917053
[15/24] Train loss=0.4112744927406311
[20/24] Train loss=0.3310735821723938
Test set avg_accuracy=72.89% avg_sensitivity=75.26%, avg_specificity=72.05% avg_auc=80.70%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.373253 Test loss=0.532209 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3511926233768463
[5/24] Train loss=0.35929611325263977
[10/24] Train loss=0.4057353436946869
[15/24] Train loss=0.42310741543769836
[20/24] Train loss=0.3343641459941864
Test set avg_accuracy=70.44% avg_sensitivity=78.21%, avg_specificity=67.71% avg_auc=81.50%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.372431 Test loss=0.539410 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.35917535424232483
[5/24] Train loss=0.36508429050445557
[10/24] Train loss=0.40042588114738464
[15/24] Train loss=0.4131552577018738
[20/24] Train loss=0.33286404609680176
Test set avg_accuracy=75.72% avg_sensitivity=73.06%, avg_specificity=76.65% avg_auc=82.73%
Best model saved!! Metric=-17.839031499641294!!
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.371640 Test loss=0.505541 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.36151260137557983
[5/24] Train loss=0.36451107263565063
[10/24] Train loss=0.40164878964424133
[15/24] Train loss=0.41879841685295105
[20/24] Train loss=0.33275705575942993
Test set avg_accuracy=71.74% avg_sensitivity=76.01%, avg_specificity=70.24% avg_auc=79.17%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.373014 Test loss=0.547212 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.35332223773002625
[5/24] Train loss=0.36965787410736084
[10/24] Train loss=0.40699124336242676
[15/24] Train loss=0.43884357810020447
[20/24] Train loss=0.3413826823234558
Test set avg_accuracy=76.07% avg_sensitivity=71.36%, avg_specificity=77.72% avg_auc=82.83%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.375509 Test loss=0.504963 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3535674512386322
[5/24] Train loss=0.36701729893684387
[10/24] Train loss=0.4098187983036041
[15/24] Train loss=0.4237123131752014
[20/24] Train loss=0.33780959248542786
Test set avg_accuracy=71.89% avg_sensitivity=76.21%, avg_specificity=70.36% avg_auc=80.63%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.373859 Test loss=0.540368 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.35236772894859314
[5/24] Train loss=0.36395692825317383
[10/24] Train loss=0.4038937985897064
[15/24] Train loss=0.4176793098449707
[20/24] Train loss=0.33670932054519653
Test set avg_accuracy=73.57% avg_sensitivity=75.76%, avg_specificity=72.79% avg_auc=81.82%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.373023 Test loss=0.521259 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3562758266925812
[5/24] Train loss=0.36635085940361023
[10/24] Train loss=0.4083590507507324
[15/24] Train loss=0.41140684485435486
[20/24] Train loss=0.3373972177505493
Test set avg_accuracy=73.20% avg_sensitivity=74.56%, avg_specificity=72.72% avg_auc=80.89%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.373149 Test loss=0.529322 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.356492817401886
[5/24] Train loss=0.363378643989563
[10/24] Train loss=0.4071408808231354
[15/24] Train loss=0.41829797625541687
[20/24] Train loss=0.33084312081336975
Test set avg_accuracy=74.31% avg_sensitivity=74.41%, avg_specificity=74.27% avg_auc=80.72%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.370571 Test loss=0.524684 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3518458306789398
[5/24] Train loss=0.36498552560806274
[10/24] Train loss=0.4106753170490265
[15/24] Train loss=0.41187745332717896
[20/24] Train loss=0.3314324915409088
Test set avg_accuracy=73.83% avg_sensitivity=75.71%, avg_specificity=73.16% avg_auc=81.15%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.371004 Test loss=0.523446 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3495239317417145
[5/24] Train loss=0.36256951093673706
[10/24] Train loss=0.41299936175346375
[15/24] Train loss=0.4247379004955292
[20/24] Train loss=0.3344179093837738
Test set avg_accuracy=70.90% avg_sensitivity=76.01%, avg_specificity=69.10% avg_auc=80.17%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.372023 Test loss=0.545773 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.35772666335105896
[5/24] Train loss=0.3633032739162445
[10/24] Train loss=0.39854544401168823
[15/24] Train loss=0.41305163502693176
[20/24] Train loss=0.3297237455844879
Test set avg_accuracy=71.78% avg_sensitivity=75.21%, avg_specificity=70.58% avg_auc=79.99%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.368734 Test loss=0.539918 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3593568205833435
[5/24] Train loss=0.3585185408592224
[10/24] Train loss=0.40297114849090576
[15/24] Train loss=0.40656036138534546
[20/24] Train loss=0.32990413904190063
Test set avg_accuracy=71.90% avg_sensitivity=76.31%, avg_specificity=70.35% avg_auc=80.08%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.365440 Test loss=0.543202 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.35459354519844055
[5/24] Train loss=0.35740926861763
[10/24] Train loss=0.401787132024765
[15/24] Train loss=0.41394370794296265
[20/24] Train loss=0.33459582924842834
Test set avg_accuracy=77.46% avg_sensitivity=70.61%, avg_specificity=79.87% avg_auc=83.24%
Best model saved!! Metric=-14.807196261962147!!
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.366118 Test loss=0.488386 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.36458149552345276
[5/24] Train loss=0.36097562313079834
[10/24] Train loss=0.40818464756011963
[15/24] Train loss=0.42430415749549866
[20/24] Train loss=0.3324640989303589
Test set avg_accuracy=73.85% avg_sensitivity=75.21%, avg_specificity=73.38% avg_auc=81.25%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.370422 Test loss=0.532455 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3479970693588257
[5/24] Train loss=0.35502561926841736
[10/24] Train loss=0.40389952063560486
[15/24] Train loss=0.4264357089996338
[20/24] Train loss=0.3383951485157013
Test set avg_accuracy=74.02% avg_sensitivity=70.36%, avg_specificity=75.31% avg_auc=80.16%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.368553 Test loss=0.523159 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3547142744064331
[5/24] Train loss=0.3551110625267029
[10/24] Train loss=0.4015921354293823
[15/24] Train loss=0.432938814163208
[20/24] Train loss=0.3309885263442993
Test set avg_accuracy=75.12% avg_sensitivity=72.81%, avg_specificity=75.93% avg_auc=82.00%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.369181 Test loss=0.507752 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.36362311244010925
[5/24] Train loss=0.36189958453178406
[10/24] Train loss=0.3998505771160126
[15/24] Train loss=0.40813130140304565
[20/24] Train loss=0.32536447048187256
Test set avg_accuracy=73.15% avg_sensitivity=71.31%, avg_specificity=73.80% avg_auc=79.52%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.365595 Test loss=0.531049 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3458927869796753
[5/24] Train loss=0.3584274351596832
[10/24] Train loss=0.40017664432525635
[15/24] Train loss=0.4176604449748993
[20/24] Train loss=0.33452117443084717
Test set avg_accuracy=77.64% avg_sensitivity=64.72%, avg_specificity=82.20% avg_auc=79.73%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.363495 Test loss=0.510096 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3469476103782654
[5/24] Train loss=0.36031103134155273
[10/24] Train loss=0.41266578435897827
[15/24] Train loss=0.4285862147808075
[20/24] Train loss=0.33292925357818604
Test set avg_accuracy=74.54% avg_sensitivity=74.31%, avg_specificity=74.63% avg_auc=82.09%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.366269 Test loss=0.509029 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.34663307666778564
[5/24] Train loss=0.35455259680747986
[10/24] Train loss=0.4110528230667114
[15/24] Train loss=0.42027854919433594
[20/24] Train loss=0.329456627368927
Test set avg_accuracy=75.00% avg_sensitivity=72.06%, avg_specificity=76.03% avg_auc=80.55%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.365294 Test loss=0.518816 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3413093686103821
[5/24] Train loss=0.3511464297771454
[10/24] Train loss=0.392257958650589
[15/24] Train loss=0.40673619508743286
[20/24] Train loss=0.32698994874954224
Test set avg_accuracy=72.04% avg_sensitivity=76.51%, avg_specificity=70.47% avg_auc=80.51%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.360818 Test loss=0.534235 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3493647575378418
[5/24] Train loss=0.3485419452190399
[10/24] Train loss=0.3869897425174713
[15/24] Train loss=0.4028187096118927
[20/24] Train loss=0.3219693601131439
Test set avg_accuracy=71.15% avg_sensitivity=76.16%, avg_specificity=69.38% avg_auc=78.83%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.358636 Test loss=0.550191 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.33924365043640137
[5/24] Train loss=0.349232941865921
[10/24] Train loss=0.39211422204971313
[15/24] Train loss=0.40666455030441284
[20/24] Train loss=0.3232056498527527
Test set avg_accuracy=71.46% avg_sensitivity=76.51%, avg_specificity=69.68% avg_auc=79.70%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.358806 Test loss=0.545862 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.33927202224731445
[5/24] Train loss=0.35116416215896606
[10/24] Train loss=0.38995158672332764
[15/24] Train loss=0.41041529178619385
[20/24] Train loss=0.3261529803276062
Test set avg_accuracy=72.68% avg_sensitivity=74.91%, avg_specificity=71.90% avg_auc=80.92%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.359449 Test loss=0.528414 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3411850333213806
[5/24] Train loss=0.35293930768966675
[10/24] Train loss=0.39867478609085083
[15/24] Train loss=0.39950260519981384
[20/24] Train loss=0.3253155052661896
Test set avg_accuracy=72.34% avg_sensitivity=72.46%, avg_specificity=72.30% avg_auc=79.44%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.359623 Test loss=0.538599 Current lr=[0.000134135431043539]

[0/24] Train loss=0.34249457716941833
[5/24] Train loss=0.351553350687027
[10/24] Train loss=0.3922378718852997
[15/24] Train loss=0.40068137645721436
[20/24] Train loss=0.323371022939682
Test set avg_accuracy=72.01% avg_sensitivity=76.31%, avg_specificity=70.49% avg_auc=80.73%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.358216 Test loss=0.535384 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.34036216139793396
[5/24] Train loss=0.3455331325531006
[10/24] Train loss=0.3875040113925934
[15/24] Train loss=0.3954556882381439
[20/24] Train loss=0.323154479265213
Test set avg_accuracy=73.18% avg_sensitivity=75.16%, avg_specificity=72.48% avg_auc=79.94%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.356665 Test loss=0.534544 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3405938744544983
[5/24] Train loss=0.3432930111885071
[10/24] Train loss=0.38765496015548706
[15/24] Train loss=0.39562591910362244
[20/24] Train loss=0.3251189589500427
Test set avg_accuracy=72.94% avg_sensitivity=73.76%, avg_specificity=72.65% avg_auc=79.80%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.355765 Test loss=0.531930 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3345416784286499
[5/24] Train loss=0.34547367691993713
[10/24] Train loss=0.38822242617607117
[15/24] Train loss=0.3970068693161011
[20/24] Train loss=0.32577309012413025
Test set avg_accuracy=72.03% avg_sensitivity=73.91%, avg_specificity=71.37% avg_auc=79.92%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.355614 Test loss=0.536068 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3411896526813507
[5/24] Train loss=0.3433450162410736
[10/24] Train loss=0.3871455788612366
[15/24] Train loss=0.40076392889022827
[20/24] Train loss=0.3285091817378998
Test set avg_accuracy=74.79% avg_sensitivity=69.17%, avg_specificity=76.77% avg_auc=79.91%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.358322 Test loss=0.524628 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.33837607502937317
[5/24] Train loss=0.3536037504673004
[10/24] Train loss=0.38636672496795654
[15/24] Train loss=0.42932984232902527
[20/24] Train loss=0.3279353678226471
Test set avg_accuracy=76.45% avg_sensitivity=69.02%, avg_specificity=79.06% avg_auc=80.56%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.359688 Test loss=0.511997 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.34354010224342346
[5/24] Train loss=0.34946209192276
[10/24] Train loss=0.3885113596916199
[15/24] Train loss=0.41022080183029175
[20/24] Train loss=0.33308008313179016
Test set avg_accuracy=75.74% avg_sensitivity=69.52%, avg_specificity=77.94% avg_auc=79.28%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.358048 Test loss=0.524142 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3375111520290375
[5/24] Train loss=0.33913734555244446
[10/24] Train loss=0.3864968717098236
[15/24] Train loss=0.45705804228782654
[20/24] Train loss=0.33077535033226013
Test set avg_accuracy=74.18% avg_sensitivity=73.56%, avg_specificity=74.40% avg_auc=81.53%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.357423 Test loss=0.513861 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.33484315872192383
[5/24] Train loss=0.3435156047344208
[10/24] Train loss=0.39114910364151
[15/24] Train loss=0.4078996777534485
[20/24] Train loss=0.327355295419693
Test set avg_accuracy=73.58% avg_sensitivity=73.01%, avg_specificity=73.78% avg_auc=79.53%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.355866 Test loss=0.530978 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3367123007774353
[5/24] Train loss=0.3402896523475647
[10/24] Train loss=0.38517194986343384
[15/24] Train loss=0.3948447108268738
[20/24] Train loss=0.32415571808815
Test set avg_accuracy=71.16% avg_sensitivity=75.86%, avg_specificity=69.50% avg_auc=78.51%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.352334 Test loss=0.552720 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.33028367161750793
[5/24] Train loss=0.34093916416168213
[10/24] Train loss=0.3856731653213501
[15/24] Train loss=0.3969639539718628
[20/24] Train loss=0.32260602712631226
Test set avg_accuracy=72.97% avg_sensitivity=74.86%, avg_specificity=72.30% avg_auc=78.96%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.351313 Test loss=0.540568 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3316470682621002
[5/24] Train loss=0.3367028832435608
[10/24] Train loss=0.3828095495700836
[15/24] Train loss=0.3984086513519287
[20/24] Train loss=0.3261050283908844
Test set avg_accuracy=71.98% avg_sensitivity=75.81%, avg_specificity=70.63% avg_auc=79.21%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.351313 Test loss=0.543927 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3286775052547455
[5/24] Train loss=0.33654314279556274
[10/24] Train loss=0.38516759872436523
[15/24] Train loss=0.39423054456710815
[20/24] Train loss=0.32592999935150146
Test set avg_accuracy=73.06% avg_sensitivity=74.91%, avg_specificity=72.41% avg_auc=79.90%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.351219 Test loss=0.530582 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3285396695137024
[5/24] Train loss=0.3327602744102478
[10/24] Train loss=0.3861398994922638
[15/24] Train loss=0.3916545510292053
[20/24] Train loss=0.32393521070480347
Test set avg_accuracy=71.69% avg_sensitivity=76.76%, avg_specificity=69.91% avg_auc=79.85%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.349847 Test loss=0.540866 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.32951343059539795
[5/24] Train loss=0.3346700072288513
[10/24] Train loss=0.3887772560119629
[15/24] Train loss=0.38761451840400696
[20/24] Train loss=0.32294055819511414
Test set avg_accuracy=73.23% avg_sensitivity=76.11%, avg_specificity=72.21% avg_auc=80.30%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.349245 Test loss=0.528297 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3235933184623718
[5/24] Train loss=0.329977422952652
[10/24] Train loss=0.38505131006240845
[15/24] Train loss=0.3891325891017914
[20/24] Train loss=0.32084542512893677
Test set avg_accuracy=72.40% avg_sensitivity=77.01%, avg_specificity=70.77% avg_auc=80.26%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.346679 Test loss=0.535331 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3248744308948517
[5/24] Train loss=0.33084750175476074
[10/24] Train loss=0.3833087980747223
[15/24] Train loss=0.3845503628253937
[20/24] Train loss=0.32052284479141235
Test set avg_accuracy=71.20% avg_sensitivity=76.41%, avg_specificity=69.36% avg_auc=79.43%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.346002 Test loss=0.543012 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.323246031999588
[5/24] Train loss=0.33062994480133057
[10/24] Train loss=0.38331010937690735
[15/24] Train loss=0.3824661374092102
[20/24] Train loss=0.32233473658561707
Test set avg_accuracy=71.13% avg_sensitivity=77.86%, avg_specificity=68.76% avg_auc=79.95%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.346207 Test loss=0.541528 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3222086727619171
[5/24] Train loss=0.3303600549697876
[10/24] Train loss=0.3824363052845001
[15/24] Train loss=0.3825119733810425
[20/24] Train loss=0.32027843594551086
Test set avg_accuracy=71.15% avg_sensitivity=77.81%, avg_specificity=68.80% avg_auc=80.13%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.346451 Test loss=0.539896 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3215830326080322
[5/24] Train loss=0.32809558510780334
[10/24] Train loss=0.3818618059158325
[15/24] Train loss=0.38035890460014343
[20/24] Train loss=0.3197266161441803
Test set avg_accuracy=71.28% avg_sensitivity=77.36%, avg_specificity=69.13% avg_auc=79.46%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.344767 Test loss=0.544793 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.31976571679115295
[5/24] Train loss=0.330899178981781
[10/24] Train loss=0.38375237584114075
[15/24] Train loss=0.3836885988712311
[20/24] Train loss=0.31952419877052307
Test set avg_accuracy=71.04% avg_sensitivity=76.66%, avg_specificity=69.06% avg_auc=78.50%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.346006 Test loss=0.552791 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.32143840193748474
[5/24] Train loss=0.3306325078010559
[10/24] Train loss=0.3803698420524597
[15/24] Train loss=0.39100393652915955
[20/24] Train loss=0.31920892000198364
Test set avg_accuracy=70.60% avg_sensitivity=78.31%, avg_specificity=67.88% avg_auc=79.60%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.346021 Test loss=0.550151 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.32217416167259216
[5/24] Train loss=0.33187252283096313
[10/24] Train loss=0.3812629282474518
[15/24] Train loss=0.3839855194091797
[20/24] Train loss=0.3196238875389099
Test set avg_accuracy=70.56% avg_sensitivity=78.26%, avg_specificity=67.85% avg_auc=79.41%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.345714 Test loss=0.551578 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.32250094413757324
[5/24] Train loss=0.3303960859775543
[10/24] Train loss=0.3811378479003906
[15/24] Train loss=0.3786602318286896
[20/24] Train loss=0.3176555037498474
Test set avg_accuracy=69.97% avg_sensitivity=79.16%, avg_specificity=66.74% avg_auc=78.88%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.344722 Test loss=0.561571 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3219060003757477
[5/24] Train loss=0.32788151502609253
[10/24] Train loss=0.3783780038356781
[15/24] Train loss=0.37485647201538086
[20/24] Train loss=0.31654563546180725
Test set avg_accuracy=70.03% avg_sensitivity=78.66%, avg_specificity=66.98% avg_auc=79.31%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.342616 Test loss=0.556299 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3218754529953003
[5/24] Train loss=0.32388028502464294
[10/24] Train loss=0.3785095512866974
[15/24] Train loss=0.3775487542152405
[20/24] Train loss=0.31745973229408264
Test set avg_accuracy=69.86% avg_sensitivity=78.31%, avg_specificity=66.88% avg_auc=79.37%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.341358 Test loss=0.553799 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3197154104709625
[5/24] Train loss=0.3259350657463074
[10/24] Train loss=0.37671414017677307
[15/24] Train loss=0.3815491497516632
[20/24] Train loss=0.31637150049209595
Test set avg_accuracy=69.88% avg_sensitivity=78.76%, avg_specificity=66.75% avg_auc=79.27%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.341066 Test loss=0.556837 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3182651102542877
[5/24] Train loss=0.3211590051651001
[10/24] Train loss=0.3791993260383606
[15/24] Train loss=0.37748268246650696
[20/24] Train loss=0.31714847683906555
Test set avg_accuracy=69.14% avg_sensitivity=79.41%, avg_specificity=65.52% avg_auc=78.62%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.340594 Test loss=0.567639 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.31832316517829895
[5/24] Train loss=0.3224406838417053
[10/24] Train loss=0.3779027462005615
[15/24] Train loss=0.3761439323425293
[20/24] Train loss=0.31721776723861694
Test set avg_accuracy=69.15% avg_sensitivity=79.76%, avg_specificity=65.42% avg_auc=79.15%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.340374 Test loss=0.563245 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3185265362262726
[5/24] Train loss=0.3210901916027069
[10/24] Train loss=0.38020575046539307
[15/24] Train loss=0.37505292892456055
[20/24] Train loss=0.3174278140068054
Test set avg_accuracy=68.50% avg_sensitivity=80.26%, avg_specificity=64.36% avg_auc=78.95%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.340446 Test loss=0.567076 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3194250762462616
[5/24] Train loss=0.3203890323638916
[10/24] Train loss=0.3804289996623993
[15/24] Train loss=0.3742887079715729
[20/24] Train loss=0.3166540265083313
Test set avg_accuracy=68.97% avg_sensitivity=80.01%, avg_specificity=65.08% avg_auc=79.47%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.340411 Test loss=0.559406 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3191583752632141
[5/24] Train loss=0.31962600350379944
[10/24] Train loss=0.37909770011901855
[15/24] Train loss=0.3799877464771271
[20/24] Train loss=0.31654420495033264
Test set avg_accuracy=69.05% avg_sensitivity=80.01%, avg_specificity=65.19% avg_auc=79.23%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.340408 Test loss=0.563069 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.3195517361164093
[5/24] Train loss=0.3179372549057007
[10/24] Train loss=0.3792532682418823
[15/24] Train loss=0.3787737488746643
[20/24] Train loss=0.3168209195137024
Test set avg_accuracy=69.19% avg_sensitivity=80.06%, avg_specificity=65.36% avg_auc=79.46%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.339752 Test loss=0.558486 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.3167547881603241
[5/24] Train loss=0.31809622049331665
[10/24] Train loss=0.3774837553501129
[15/24] Train loss=0.37428221106529236
[20/24] Train loss=0.31672245264053345
Test set avg_accuracy=69.73% avg_sensitivity=79.56%, avg_specificity=66.26% avg_auc=79.58%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.338956 Test loss=0.555681 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.3161386251449585
[5/24] Train loss=0.3158455491065979
[10/24] Train loss=0.3760240077972412
[15/24] Train loss=0.37383270263671875
[20/24] Train loss=0.3168579339981079
Test set avg_accuracy=69.51% avg_sensitivity=80.16%, avg_specificity=65.75% avg_auc=79.43%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.337844 Test loss=0.558296 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.31449607014656067
[5/24] Train loss=0.3159925043582916
[10/24] Train loss=0.3764115273952484
[15/24] Train loss=0.37173929810523987
[20/24] Train loss=0.315973699092865
Test set avg_accuracy=69.27% avg_sensitivity=80.31%, avg_specificity=65.38% avg_auc=79.12%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.337289 Test loss=0.562557 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.31487855315208435
[5/24] Train loss=0.3152863383293152
[10/24] Train loss=0.3749757409095764
[15/24] Train loss=0.3713894784450531
[20/24] Train loss=0.3160041868686676
Test set avg_accuracy=69.53% avg_sensitivity=79.11%, avg_specificity=66.16% avg_auc=79.20%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.336869 Test loss=0.558936 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.31399786472320557
[5/24] Train loss=0.31479910016059875
[10/24] Train loss=0.3745746910572052
[15/24] Train loss=0.37121304869651794
[20/24] Train loss=0.31605973839759827
Test set avg_accuracy=69.19% avg_sensitivity=80.01%, avg_specificity=65.38% avg_auc=79.21%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.336451 Test loss=0.561128 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3138270974159241
[5/24] Train loss=0.31427863240242004
[10/24] Train loss=0.3747917115688324
[15/24] Train loss=0.3712612986564636
[20/24] Train loss=0.3159502148628235
Test set avg_accuracy=69.22% avg_sensitivity=80.11%, avg_specificity=65.38% avg_auc=79.20%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.336309 Test loss=0.561629 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3136991262435913
[5/24] Train loss=0.3140510618686676
[10/24] Train loss=0.3744570016860962
[15/24] Train loss=0.37112295627593994
[20/24] Train loss=0.31586724519729614
Test set avg_accuracy=69.22% avg_sensitivity=80.11%, avg_specificity=65.38% avg_auc=79.17%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.336162 Test loss=0.561742 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3134957253932953
[5/24] Train loss=0.31384074687957764
[10/24] Train loss=0.3744216859340668
[15/24] Train loss=0.37102076411247253
[20/24] Train loss=0.3158571720123291
Test set avg_accuracy=69.24% avg_sensitivity=80.31%, avg_specificity=65.35% avg_auc=79.17%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.336050 Test loss=0.562113 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.3133848011493683
[5/24] Train loss=0.31373196840286255
[10/24] Train loss=0.37430885434150696
[15/24] Train loss=0.370987206697464
[20/24] Train loss=0.3158172369003296
Test set avg_accuracy=69.19% avg_sensitivity=80.51%, avg_specificity=65.21% avg_auc=79.16%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.335964 Test loss=0.562213 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.31326016783714294
[5/24] Train loss=0.3135986924171448
[10/24] Train loss=0.37424686551094055
[15/24] Train loss=0.37094026803970337
[20/24] Train loss=0.3157934844493866
Test set avg_accuracy=69.18% avg_sensitivity=80.51%, avg_specificity=65.19% avg_auc=79.16%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.335894 Test loss=0.562382 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.31318703293800354
[5/24] Train loss=0.31352606415748596
[10/24] Train loss=0.3741866648197174
[15/24] Train loss=0.3709069490432739
[20/24] Train loss=0.31577640771865845
Test set avg_accuracy=69.21% avg_sensitivity=80.51%, avg_specificity=65.22% avg_auc=79.15%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.335842 Test loss=0.562470 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3131244480609894
[5/24] Train loss=0.3134632706642151
[10/24] Train loss=0.37415340542793274
[15/24] Train loss=0.37088707089424133
[20/24] Train loss=0.31576254963874817
Test set avg_accuracy=69.22% avg_sensitivity=80.51%, avg_specificity=65.24% avg_auc=79.15%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.335803 Test loss=0.562536 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.31307998299598694
[5/24] Train loss=0.31341859698295593
[10/24] Train loss=0.3741261065006256
[15/24] Train loss=0.3708697259426117
[20/24] Train loss=0.3157535791397095
Test set avg_accuracy=69.22% avg_sensitivity=80.51%, avg_specificity=65.24% avg_auc=79.14%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.335776 Test loss=0.562601 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.31305181980133057
[5/24] Train loss=0.31339031457901
[10/24] Train loss=0.37410643696784973
[15/24] Train loss=0.3708555996417999
[20/24] Train loss=0.3157476484775543
Test set avg_accuracy=69.21% avg_sensitivity=80.51%, avg_specificity=65.22% avg_auc=79.14%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.335758 Test loss=0.562650 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.31303656101226807
[5/24] Train loss=0.313373863697052
[10/24] Train loss=0.37409478425979614
[15/24] Train loss=0.37084630131721497
[20/24] Train loss=0.3157445788383484
Test set avg_accuracy=69.21% avg_sensitivity=80.51%, avg_specificity=65.22% avg_auc=79.14%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.335749 Test loss=0.562680 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.31302979588508606
[5/24] Train loss=0.3133663833141327
[10/24] Train loss=0.37408968806266785
[15/24] Train loss=0.3708418607711792
[20/24] Train loss=0.31574365496635437
Test set avg_accuracy=69.19% avg_sensitivity=80.51%, avg_specificity=65.21% avg_auc=79.14%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.335744 Test loss=0.562693 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=77.46% sen=70.61%, spe=79.87%, auc=83.24%!
Fold[4] Avg_overlap=0.57%(0.2606662455240776)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 1,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'SwEDModel',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.6860675811767578
[5/24] Train loss=0.6841302514076233
[10/24] Train loss=0.6834901571273804
[15/24] Train loss=0.6828011274337769
[20/24] Train loss=0.6827253103256226
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.29%
Best model saved!! Metric=-101.14022849968073!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.683375 Test loss=0.681336 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6830157041549683
[5/24] Train loss=0.6810973882675171
[10/24] Train loss=0.680457592010498
[15/24] Train loss=0.6796536445617676
[20/24] Train loss=0.6799664497375488
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.46%
Best model saved!! Metric=-100.97165643989726!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.680277 Test loss=0.678224 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.680206835269928
[5/24] Train loss=0.6782785654067993
[10/24] Train loss=0.677552342414856
[15/24] Train loss=0.676567792892456
[20/24] Train loss=0.6772940754890442
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.61%
Best model saved!! Metric=-100.82087633423451!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.677320 Test loss=0.675257 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.67751544713974
[5/24] Train loss=0.6756319403648376
[10/24] Train loss=0.6747993230819702
[15/24] Train loss=0.6735783219337463
[20/24] Train loss=0.6746874451637268
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.75%
Best model saved!! Metric=-100.67564839113908!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.674475 Test loss=0.672361 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6749677658081055
[5/24] Train loss=0.6729398369789124
[10/24] Train loss=0.6719843745231628
[15/24] Train loss=0.6704384088516235
[20/24] Train loss=0.671801745891571
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.73%
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.671509 Test loss=0.669127 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6721256375312805
[5/24] Train loss=0.6697808504104614
[10/24] Train loss=0.6685885190963745
[15/24] Train loss=0.6666565537452698
[20/24] Train loss=0.668201744556427
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.90%
Best model saved!! Metric=-100.53357650824697!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.667939 Test loss=0.665010 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6686549782752991
[5/24] Train loss=0.6657332181930542
[10/24] Train loss=0.6641969680786133
[15/24] Train loss=0.6617920398712158
[20/24] Train loss=0.6635406613349915
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.05%
Best model saved!! Metric=-100.37592101930842!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.663335 Test loss=0.659632 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6640971302986145
[5/24] Train loss=0.6605356931686401
[10/24] Train loss=0.658578097820282
[15/24] Train loss=0.655531108379364
[20/24] Train loss=0.6576818227767944
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.25%
Best model saved!! Metric=-100.18015587989774!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.657431 Test loss=0.652760 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6582857370376587
[5/24] Train loss=0.6538894772529602
[10/24] Train loss=0.6511805057525635
[15/24] Train loss=0.6471758484840393
[20/24] Train loss=0.6498761177062988
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.47%
Best model saved!! Metric=-99.96056382705402!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.649638 Test loss=0.643429 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6506100296974182
[5/24] Train loss=0.6447834968566895
[10/24] Train loss=0.6409935355186462
[15/24] Train loss=0.6355764269828796
[20/24] Train loss=0.6391294598579407
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.85%
Best model saved!! Metric=-99.58183660265519!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.638917 Test loss=0.630622 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6403335928916931
[5/24] Train loss=0.6323676109313965
[10/24] Train loss=0.6271628737449646
[15/24] Train loss=0.6195250153541565
[20/24] Train loss=0.6245571374893188
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.15%
Best model saved!! Metric=-99.2834011591514!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.624194 Test loss=0.613087 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6268593668937683
[5/24] Train loss=0.6153658032417297
[10/24] Train loss=0.6091156601905823
[15/24] Train loss=0.599018394947052
[20/24] Train loss=0.6074864864349365
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.81%
Best model saved!! Metric=-98.6210800208168!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.605207 Test loss=0.593359 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.6126612424850464
[5/24] Train loss=0.5965848565101624
[10/24] Train loss=0.5912044644355774
[15/24] Train loss=0.5782135128974915
[20/24] Train loss=0.5922898650169373
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=53.44%
Best model saved!! Metric=-97.99443666786853!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.586080 Test loss=0.576194 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.6011196374893188
[5/24] Train loss=0.5799536108970642
[10/24] Train loss=0.5783634781837463
[15/24] Train loss=0.5638443231582642
[20/24] Train loss=0.5820425748825073
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.72%
Best model saved!! Metric=-96.71351431866181!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.571812 Test loss=0.567060 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5945691466331482
[5/24] Train loss=0.5711071491241455
[10/24] Train loss=0.5730335712432861
[15/24] Train loss=0.5575361251831055
[20/24] Train loss=0.5773189663887024
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=58.13%
Best model saved!! Metric=-93.29483056742767!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.565328 Test loss=0.563978 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5921805500984192
[5/24] Train loss=0.5675480365753174
[10/24] Train loss=0.5707387328147888
[15/24] Train loss=0.5538879036903381
[20/24] Train loss=0.5749145746231079
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=61.33%
Best model saved!! Metric=-90.09997675157652!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.563020 Test loss=0.562501 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5911554098129272
[5/24] Train loss=0.5659555196762085
[10/24] Train loss=0.5696182250976562
[15/24] Train loss=0.5509412288665771
[20/24] Train loss=0.5713254809379578
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=62.88%
Best model saved!! Metric=-88.54582720743053!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.560404 Test loss=0.560119 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5894668698310852
[5/24] Train loss=0.563669741153717
[10/24] Train loss=0.5682199001312256
[15/24] Train loss=0.5471466183662415
[20/24] Train loss=0.564450204372406
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=66.19%
Best model saved!! Metric=-85.2429655012501!!
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.556809 Test loss=0.555805 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5837144255638123
[5/24] Train loss=0.5589573383331299
[10/24] Train loss=0.5640923380851746
[15/24] Train loss=0.5392775535583496
[20/24] Train loss=0.5543407797813416
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=69.89%
Best model saved!! Metric=-81.54205576019098!!
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.550934 Test loss=0.549760 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5793236494064331
[5/24] Train loss=0.550256609916687
[10/24] Train loss=0.5534023642539978
[15/24] Train loss=0.5228957533836365
[20/24] Train loss=0.5396116375923157
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=73.07%
Best model saved!! Metric=-78.35979936311173!!
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.538898 Test loss=0.550173 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5646652579307556
[5/24] Train loss=0.5357629060745239
[10/24] Train loss=0.5352662801742554
[15/24] Train loss=0.5039678812026978
[20/24] Train loss=0.5213735103607178
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=72.42%
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.523998 Test loss=0.621751 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5502309799194336
[5/24] Train loss=0.5266863107681274
[10/24] Train loss=0.5199462175369263
[15/24] Train loss=0.4858505427837372
[20/24] Train loss=0.5093344449996948
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=72.50%
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.511157 Test loss=0.626022 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5484952926635742
[5/24] Train loss=0.5186985731124878
[10/24] Train loss=0.5115492939949036
[15/24] Train loss=0.4795171618461609
[20/24] Train loss=0.4982171952724457
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=62.75%
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.501763 Test loss=0.644459 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5294053554534912
[5/24] Train loss=0.509631872177124
[10/24] Train loss=0.4985627830028534
[15/24] Train loss=0.46726056933403015
[20/24] Train loss=0.49217990040779114
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=67.70%
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.492248 Test loss=0.617968 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.510504424571991
[5/24] Train loss=0.5031813979148865
[10/24] Train loss=0.4925847053527832
[15/24] Train loss=0.4624606668949127
[20/24] Train loss=0.48301267623901367
Test set avg_accuracy=74.48% avg_sensitivity=0.67%, avg_specificity=99.65% avg_auc=63.40%
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.484837 Test loss=0.631671 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5102327466011047
[5/24] Train loss=0.4995975196361542
[10/24] Train loss=0.48868855834007263
[15/24] Train loss=0.4564945101737976
[20/24] Train loss=0.4876212477684021
Test set avg_accuracy=74.02% avg_sensitivity=4.51%, avg_specificity=97.73% avg_auc=64.49%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.479561 Test loss=0.628250 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.4953290522098541
[5/24] Train loss=0.4974544048309326
[10/24] Train loss=0.4874323010444641
[15/24] Train loss=0.4536418318748474
[20/24] Train loss=0.4753359854221344
Test set avg_accuracy=61.54% avg_sensitivity=34.82%, avg_specificity=70.65% avg_auc=65.37%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.475525 Test loss=0.626565 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.4929566979408264
[5/24] Train loss=0.5002626180648804
[10/24] Train loss=0.48498010635375977
[15/24] Train loss=0.45145323872566223
[20/24] Train loss=0.4723430275917053
Test set avg_accuracy=70.34% avg_sensitivity=16.33%, avg_specificity=88.76% avg_auc=67.09%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.473708 Test loss=0.611023 Current lr=[0.000210185142098938]

[0/24] Train loss=0.49257892370224
[5/24] Train loss=0.49507156014442444
[10/24] Train loss=0.4845992624759674
[15/24] Train loss=0.4516993463039398
[20/24] Train loss=0.47096940875053406
Test set avg_accuracy=58.27% avg_sensitivity=60.16%, avg_specificity=57.62% avg_auc=67.51%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.471241 Test loss=0.622006 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.49376222491264343
[5/24] Train loss=0.49407172203063965
[10/24] Train loss=0.4918854534626007
[15/24] Train loss=0.44764062762260437
[20/24] Train loss=0.46906325221061707
Test set avg_accuracy=75.52% avg_sensitivity=18.79%, avg_specificity=94.87% avg_auc=70.83%
Best model saved!! Metric=-65.99125173974464!!
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.470722 Test loss=0.588942 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.5028276443481445
[5/24] Train loss=0.5020251274108887
[10/24] Train loss=0.48794060945510864
[15/24] Train loss=0.44880545139312744
[20/24] Train loss=0.4689030349254608
Test set avg_accuracy=75.29% avg_sensitivity=22.22%, avg_specificity=93.38% avg_auc=71.18%
Best model saved!! Metric=-63.92799256002394!!
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.472086 Test loss=0.582585 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.4959442615509033
[5/24] Train loss=0.49367737770080566
[10/24] Train loss=0.4779176414012909
[15/24] Train loss=0.445342093706131
[20/24] Train loss=0.46173977851867676
Test set avg_accuracy=73.75% avg_sensitivity=34.25%, avg_specificity=87.22% avg_auc=70.46%
Best model saved!! Metric=-60.31787782488624!!
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.467184 Test loss=0.596122 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.48291322588920593
[5/24] Train loss=0.4867655038833618
[10/24] Train loss=0.47091835737228394
[15/24] Train loss=0.4478890895843506
[20/24] Train loss=0.4575043022632599
Test set avg_accuracy=76.72% avg_sensitivity=22.32%, avg_specificity=95.27% avg_auc=71.07%
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.461173 Test loss=0.570222 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.47013404965400696
[5/24] Train loss=0.4822889566421509
[10/24] Train loss=0.46458595991134644
[15/24] Train loss=0.42825236916542053
[20/24] Train loss=0.4491000175476074
Test set avg_accuracy=76.42% avg_sensitivity=16.08%, avg_specificity=97.00% avg_auc=69.21%
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.452931 Test loss=0.566993 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.45592227578163147
[5/24] Train loss=0.4663558304309845
[10/24] Train loss=0.46176716685295105
[15/24] Train loss=0.4252687096595764
[20/24] Train loss=0.432524710893631
Test set avg_accuracy=77.62% avg_sensitivity=34.41%, avg_specificity=92.35% avg_auc=72.80%
Best model saved!! Metric=-48.82712408593276!!
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.444019 Test loss=0.562891 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.45277783274650574
[5/24] Train loss=0.460793137550354
[10/24] Train loss=0.45051220059394836
[15/24] Train loss=0.41883090138435364
[20/24] Train loss=0.42396464943885803
Test set avg_accuracy=77.54% avg_sensitivity=20.58%, avg_specificity=96.96% avg_auc=69.21%
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.434551 Test loss=0.563912 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.44268476963043213
[5/24] Train loss=0.44879743456840515
[10/24] Train loss=0.44521841406822205
[15/24] Train loss=0.397518515586853
[20/24] Train loss=0.40308019518852234
Test set avg_accuracy=75.64% avg_sensitivity=57.25%, avg_specificity=81.91% avg_auc=73.88%
Best model saved!! Metric=-37.3240351870035!!
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.424525 Test loss=0.580506 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.44052019715309143
[5/24] Train loss=0.4443108141422272
[10/24] Train loss=0.4331899583339691
[15/24] Train loss=0.40138354897499084
[20/24] Train loss=0.39804455637931824
Test set avg_accuracy=78.58% avg_sensitivity=30.57%, avg_specificity=94.95% avg_auc=75.69%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.421062 Test loss=0.531217 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.42467138171195984
[5/24] Train loss=0.44031208753585815
[10/24] Train loss=0.43934300541877747
[15/24] Train loss=0.3991331160068512
[20/24] Train loss=0.3983176052570343
Test set avg_accuracy=77.83% avg_sensitivity=27.91%, avg_specificity=94.85% avg_auc=73.25%
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.421758 Test loss=0.537426 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.42989230155944824
[5/24] Train loss=0.4385071396827698
[10/24] Train loss=0.4278736114501953
[15/24] Train loss=0.41857773065567017
[20/24] Train loss=0.40668052434921265
Test set avg_accuracy=77.03% avg_sensitivity=14.23%, avg_specificity=98.45% avg_auc=70.33%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.422017 Test loss=0.539095 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4373655617237091
[5/24] Train loss=0.43097591400146484
[10/24] Train loss=0.4350202679634094
[15/24] Train loss=0.3945784568786621
[20/24] Train loss=0.3995879292488098
Test set avg_accuracy=78.57% avg_sensitivity=34.51%, avg_specificity=93.59% avg_auc=75.46%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.418731 Test loss=0.537653 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.43372321128845215
[5/24] Train loss=0.431817889213562
[10/24] Train loss=0.4268885850906372
[15/24] Train loss=0.3933206796646118
[20/24] Train loss=0.3848482370376587
Test set avg_accuracy=78.68% avg_sensitivity=29.34%, avg_specificity=95.51% avg_auc=73.53%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.415753 Test loss=0.541618 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4154490828514099
[5/24] Train loss=0.4253992736339569
[10/24] Train loss=0.4215075969696045
[15/24] Train loss=0.39401742815971375
[20/24] Train loss=0.38115522265434265
Test set avg_accuracy=78.74% avg_sensitivity=35.89%, avg_specificity=93.35% avg_auc=72.66%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.410274 Test loss=0.553413 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.41167935729026794
[5/24] Train loss=0.42194944620132446
[10/24] Train loss=0.41721415519714355
[15/24] Train loss=0.38706615567207336
[20/24] Train loss=0.3821413516998291
Test set avg_accuracy=77.75% avg_sensitivity=47.00%, avg_specificity=88.23% avg_auc=76.84%
Best model saved!! Metric=-36.17234117476272!!
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.408405 Test loss=0.541514 Current lr=[0.00029967723776099]

[0/24] Train loss=0.4011712372303009
[5/24] Train loss=0.4186636805534363
[10/24] Train loss=0.41294220089912415
[15/24] Train loss=0.3901815712451935
[20/24] Train loss=0.3771508038043976
Test set avg_accuracy=78.03% avg_sensitivity=25.45%, avg_specificity=95.97% avg_auc=70.39%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.404232 Test loss=0.557692 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.40492483973503113
[5/24] Train loss=0.4273878037929535
[10/24] Train loss=0.4163084328174591
[15/24] Train loss=0.389350563287735
[20/24] Train loss=0.37771785259246826
Test set avg_accuracy=77.98% avg_sensitivity=29.39%, avg_specificity=94.55% avg_auc=74.61%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.405102 Test loss=0.534244 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.41236698627471924
[5/24] Train loss=0.4182291328907013
[10/24] Train loss=0.41229677200317383
[15/24] Train loss=0.38162726163864136
[20/24] Train loss=0.3757331371307373
Test set avg_accuracy=76.98% avg_sensitivity=55.56%, avg_specificity=84.28% avg_auc=71.15%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.404252 Test loss=0.583456 Current lr=[0.000299720220882401]

[0/24] Train loss=0.40261924266815186
[5/24] Train loss=0.423201322555542
[10/24] Train loss=0.4198921322822571
[15/24] Train loss=0.38089463114738464
[20/24] Train loss=0.37766051292419434
Test set avg_accuracy=77.02% avg_sensitivity=44.34%, avg_specificity=88.16% avg_auc=73.60%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.406179 Test loss=0.560610 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.40377047657966614
[5/24] Train loss=0.4224989116191864
[10/24] Train loss=0.415022611618042
[15/24] Train loss=0.385408490896225
[20/24] Train loss=0.3694242537021637
Test set avg_accuracy=77.77% avg_sensitivity=57.40%, avg_specificity=84.72% avg_auc=73.89%
Best model saved!! Metric=-32.21300807079139!!
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.404022 Test loss=0.564061 Current lr=[0.000298904600941902]

[0/24] Train loss=0.4025779068470001
[5/24] Train loss=0.4117048382759094
[10/24] Train loss=0.4032641351222992
[15/24] Train loss=0.38048145174980164
[20/24] Train loss=0.36861181259155273
Test set avg_accuracy=78.22% avg_sensitivity=31.85%, avg_specificity=94.03% avg_auc=76.87%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.395808 Test loss=0.529390 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.39960983395576477
[5/24] Train loss=0.41290414333343506
[10/24] Train loss=0.4028378427028656
[15/24] Train loss=0.378301739692688
[20/24] Train loss=0.36457395553588867
Test set avg_accuracy=77.11% avg_sensitivity=57.25%, avg_specificity=83.88% avg_auc=75.10%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.397003 Test loss=0.554858 Current lr=[0.000297555943323901]

[0/24] Train loss=0.40490272641181946
[5/24] Train loss=0.41192007064819336
[10/24] Train loss=0.40750154852867126
[15/24] Train loss=0.37868526577949524
[20/24] Train loss=0.3644958734512329
Test set avg_accuracy=75.38% avg_sensitivity=57.55%, avg_specificity=81.46% avg_auc=72.37%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.396917 Test loss=0.574129 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3876519799232483
[5/24] Train loss=0.41808658838272095
[10/24] Train loss=0.39839962124824524
[15/24] Train loss=0.3793811798095703
[20/24] Train loss=0.3685172200202942
Test set avg_accuracy=78.80% avg_sensitivity=47.57%, avg_specificity=89.45% avg_auc=78.85%
Best model saved!! Metric=-31.328915159178536!!
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.395326 Test loss=0.523108 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3906349241733551
[5/24] Train loss=0.4110301434993744
[10/24] Train loss=0.408774197101593
[15/24] Train loss=0.3742171823978424
[20/24] Train loss=0.36912456154823303
Test set avg_accuracy=76.33% avg_sensitivity=50.95%, avg_specificity=84.98% avg_auc=74.66%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.395977 Test loss=0.554677 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.4035702645778656
[5/24] Train loss=0.4097837209701538
[10/24] Train loss=0.4025785028934479
[15/24] Train loss=0.3861842751502991
[20/24] Train loss=0.368048757314682
Test set avg_accuracy=76.29% avg_sensitivity=44.75%, avg_specificity=87.04% avg_auc=75.15%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.391709 Test loss=0.549868 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.39312389492988586
[5/24] Train loss=0.40767502784729004
[10/24] Train loss=0.4066677689552307
[15/24] Train loss=0.3712599575519562
[20/24] Train loss=0.3612390160560608
Test set avg_accuracy=71.90% avg_sensitivity=71.89%, avg_specificity=71.91% avg_auc=77.22%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.395930 Test loss=0.565494 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.4202998876571655
[5/24] Train loss=0.4176647961139679
[10/24] Train loss=0.4081251919269562
[15/24] Train loss=0.3788873851299286
[20/24] Train loss=0.3765529692173004
Test set avg_accuracy=75.07% avg_sensitivity=51.00%, avg_specificity=83.27% avg_auc=76.42%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.398646 Test loss=0.548177 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.40526360273361206
[5/24] Train loss=0.40761497616767883
[10/24] Train loss=0.4014541208744049
[15/24] Train loss=0.37281155586242676
[20/24] Train loss=0.36655646562576294
Test set avg_accuracy=63.80% avg_sensitivity=78.14%, avg_specificity=58.91% avg_auc=77.31%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.394097 Test loss=0.585965 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.39024618268013
[5/24] Train loss=0.4097185432910919
[10/24] Train loss=0.40483933687210083
[15/24] Train loss=0.369871586561203
[20/24] Train loss=0.3701011836528778
Test set avg_accuracy=75.79% avg_sensitivity=53.92%, avg_specificity=83.25% avg_auc=77.87%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.392602 Test loss=0.535867 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.38954004645347595
[5/24] Train loss=0.4051905572414398
[10/24] Train loss=0.39787283539772034
[15/24] Train loss=0.3861927092075348
[20/24] Train loss=0.37277108430862427
Test set avg_accuracy=74.57% avg_sensitivity=60.88%, avg_specificity=79.24% avg_auc=77.13%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.394588 Test loss=0.557787 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.39814072847366333
[5/24] Train loss=0.4107673764228821
[10/24] Train loss=0.39795756340026855
[15/24] Train loss=0.3681419789791107
[20/24] Train loss=0.3735399842262268
Test set avg_accuracy=76.30% avg_sensitivity=54.07%, avg_specificity=83.88% avg_auc=73.87%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.393692 Test loss=0.562166 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.39135462045669556
[5/24] Train loss=0.40973713994026184
[10/24] Train loss=0.39376357197761536
[15/24] Train loss=0.3763657808303833
[20/24] Train loss=0.3675450086593628
Test set avg_accuracy=74.49% avg_sensitivity=55.40%, avg_specificity=81.00% avg_auc=76.22%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.390123 Test loss=0.554276 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.39320114254951477
[5/24] Train loss=0.4173116385936737
[10/24] Train loss=0.3999846577644348
[15/24] Train loss=0.36602917313575745
[20/24] Train loss=0.3603692054748535
Test set avg_accuracy=72.29% avg_sensitivity=67.90%, avg_specificity=73.79% avg_auc=78.14%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.390027 Test loss=0.555513 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.39138081669807434
[5/24] Train loss=0.40516364574432373
[10/24] Train loss=0.39594173431396484
[15/24] Train loss=0.3812969923019409
[20/24] Train loss=0.36455634236335754
Test set avg_accuracy=71.52% avg_sensitivity=68.71%, avg_specificity=72.48% avg_auc=72.93%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.388524 Test loss=0.595605 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3873719274997711
[5/24] Train loss=0.42687711119651794
[10/24] Train loss=0.40664979815483093
[15/24] Train loss=0.37453022599220276
[20/24] Train loss=0.3625243306159973
Test set avg_accuracy=77.40% avg_sensitivity=54.94%, avg_specificity=85.05% avg_auc=75.69%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.393819 Test loss=0.543302 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.39447271823883057
[5/24] Train loss=0.40495002269744873
[10/24] Train loss=0.3926328718662262
[15/24] Train loss=0.3742421567440033
[20/24] Train loss=0.36544033885002136
Test set avg_accuracy=72.41% avg_sensitivity=61.39%, avg_specificity=76.17% avg_auc=74.53%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.388086 Test loss=0.568120 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3947005867958069
[5/24] Train loss=0.40510281920433044
[10/24] Train loss=0.3907761573791504
[15/24] Train loss=0.3643423318862915
[20/24] Train loss=0.3664323389530182
Test set avg_accuracy=69.78% avg_sensitivity=73.12%, avg_specificity=68.64% avg_auc=77.04%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.385101 Test loss=0.567209 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3834192156791687
[5/24] Train loss=0.4135386347770691
[10/24] Train loss=0.4017479717731476
[15/24] Train loss=0.37891480326652527
[20/24] Train loss=0.36105650663375854
Test set avg_accuracy=74.54% avg_sensitivity=57.71%, avg_specificity=80.29% avg_auc=78.77%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.388563 Test loss=0.540790 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.4016105830669403
[5/24] Train loss=0.41452449560165405
[10/24] Train loss=0.4028233289718628
[15/24] Train loss=0.3640371561050415
[20/24] Train loss=0.3495974540710449
Test set avg_accuracy=71.84% avg_sensitivity=69.18%, avg_specificity=72.74% avg_auc=75.09%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.386943 Test loss=0.575133 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.39637434482574463
[5/24] Train loss=0.4136216342449188
[10/24] Train loss=0.3972988724708557
[15/24] Train loss=0.3587348759174347
[20/24] Train loss=0.34986892342567444
Test set avg_accuracy=71.81% avg_sensitivity=71.74%, avg_specificity=71.84% avg_auc=77.84%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.384080 Test loss=0.554235 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.37875354290008545
[5/24] Train loss=0.4038543999195099
[10/24] Train loss=0.38773614168167114
[15/24] Train loss=0.36105087399482727
[20/24] Train loss=0.3714359998703003
Test set avg_accuracy=66.77% avg_sensitivity=78.75%, avg_specificity=62.69% avg_auc=78.64%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.385440 Test loss=0.574910 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3917037546634674
[5/24] Train loss=0.40770819783210754
[10/24] Train loss=0.39380693435668945
[15/24] Train loss=0.3741585612297058
[20/24] Train loss=0.37179499864578247
Test set avg_accuracy=73.52% avg_sensitivity=68.92%, avg_specificity=75.08% avg_auc=78.97%
Best model saved!! Metric=-29.509781105823123!!
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.385247 Test loss=0.547286 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3883230686187744
[5/24] Train loss=0.40669506788253784
[10/24] Train loss=0.39648011326789856
[15/24] Train loss=0.38320785760879517
[20/24] Train loss=0.36757898330688477
Test set avg_accuracy=74.24% avg_sensitivity=63.80%, avg_specificity=77.81% avg_auc=75.66%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.389008 Test loss=0.564062 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.4121891260147095
[5/24] Train loss=0.4086923897266388
[10/24] Train loss=0.4062403440475464
[15/24] Train loss=0.38351669907569885
[20/24] Train loss=0.35543322563171387
Test set avg_accuracy=73.15% avg_sensitivity=70.15%, avg_specificity=74.17% avg_auc=77.41%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.389889 Test loss=0.558794 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.38844186067581177
[5/24] Train loss=0.4002940356731415
[10/24] Train loss=0.3910137414932251
[15/24] Train loss=0.37675315141677856
[20/24] Train loss=0.3510245680809021
Test set avg_accuracy=74.09% avg_sensitivity=63.70%, avg_specificity=77.63% avg_auc=77.72%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.384005 Test loss=0.549495 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3868427574634552
[5/24] Train loss=0.3933814465999603
[10/24] Train loss=0.3889665901660919
[15/24] Train loss=0.36212271451950073
[20/24] Train loss=0.350632905960083
Test set avg_accuracy=73.78% avg_sensitivity=66.31%, avg_specificity=76.32% avg_auc=75.28%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.380535 Test loss=0.562736 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.39179718494415283
[5/24] Train loss=0.41070112586021423
[10/24] Train loss=0.3933628499507904
[15/24] Train loss=0.3609303832054138
[20/24] Train loss=0.3549163341522217
Test set avg_accuracy=77.24% avg_sensitivity=58.63%, avg_specificity=83.59% avg_auc=78.49%
Best model saved!! Metric=-28.052897706389132!!
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.383216 Test loss=0.520080 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3881438076496124
[5/24] Train loss=0.4008486270904541
[10/24] Train loss=0.3913532793521881
[15/24] Train loss=0.3615608811378479
[20/24] Train loss=0.3500436246395111
Test set avg_accuracy=70.77% avg_sensitivity=71.94%, avg_specificity=70.37% avg_auc=77.07%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.381853 Test loss=0.562071 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.38491225242614746
[5/24] Train loss=0.402641624212265
[10/24] Train loss=0.3894880414009094
[15/24] Train loss=0.36098501086235046
[20/24] Train loss=0.34954220056533813
Test set avg_accuracy=68.98% avg_sensitivity=77.57%, avg_specificity=66.06% avg_auc=77.52%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.376729 Test loss=0.566032 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.38839244842529297
[5/24] Train loss=0.39752185344696045
[10/24] Train loss=0.38649195432662964
[15/24] Train loss=0.3656870722770691
[20/24] Train loss=0.3635748028755188
Test set avg_accuracy=73.92% avg_sensitivity=64.82%, avg_specificity=77.02% avg_auc=77.84%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.382782 Test loss=0.547039 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3886055052280426
[5/24] Train loss=0.3999268114566803
[10/24] Train loss=0.38953375816345215
[15/24] Train loss=0.3642379939556122
[20/24] Train loss=0.35892802476882935
Test set avg_accuracy=73.28% avg_sensitivity=65.85%, avg_specificity=75.82% avg_auc=76.16%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.382003 Test loss=0.558945 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.38235095143318176
[5/24] Train loss=0.4010772407054901
[10/24] Train loss=0.38632622361183167
[15/24] Train loss=0.3603459596633911
[20/24] Train loss=0.34751713275909424
Test set avg_accuracy=72.94% avg_sensitivity=68.41%, avg_specificity=74.49% avg_auc=77.56%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.381140 Test loss=0.550205 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.37989917397499084
[5/24] Train loss=0.39845922589302063
[10/24] Train loss=0.39290130138397217
[15/24] Train loss=0.36720192432403564
[20/24] Train loss=0.3544284403324127
Test set avg_accuracy=63.95% avg_sensitivity=82.39%, avg_specificity=57.66% avg_auc=78.00%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.381354 Test loss=0.584320 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3889347314834595
[5/24] Train loss=0.4032001197338104
[10/24] Train loss=0.39147818088531494
[15/24] Train loss=0.36039280891418457
[20/24] Train loss=0.3452296257019043
Test set avg_accuracy=72.68% avg_sensitivity=68.77%, avg_specificity=74.02% avg_auc=76.25%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.378324 Test loss=0.562095 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.38193279504776
[5/24] Train loss=0.3982887268066406
[10/24] Train loss=0.3866754174232483
[15/24] Train loss=0.36113131046295166
[20/24] Train loss=0.3446369767189026
Test set avg_accuracy=69.51% avg_sensitivity=76.45%, avg_specificity=67.14% avg_auc=77.75%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.375987 Test loss=0.562573 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3827577233314514
[5/24] Train loss=0.3961722254753113
[10/24] Train loss=0.3976951539516449
[15/24] Train loss=0.3607584238052368
[20/24] Train loss=0.347076416015625
Test set avg_accuracy=74.73% avg_sensitivity=65.64%, avg_specificity=77.82% avg_auc=75.76%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.377143 Test loss=0.560070 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3797077238559723
[5/24] Train loss=0.38857245445251465
[10/24] Train loss=0.38824936747550964
[15/24] Train loss=0.3624400794506073
[20/24] Train loss=0.3528073728084564
Test set avg_accuracy=65.48% avg_sensitivity=82.85%, avg_specificity=59.56% avg_auc=78.03%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.379402 Test loss=0.582960 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.39647600054740906
[5/24] Train loss=0.3934467136859894
[10/24] Train loss=0.3898751735687256
[15/24] Train loss=0.35454368591308594
[20/24] Train loss=0.35016384720802307
Test set avg_accuracy=63.76% avg_sensitivity=81.67%, avg_specificity=57.66% avg_auc=76.76%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.378702 Test loss=0.592687 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.3853070139884949
[5/24] Train loss=0.38971075415611267
[10/24] Train loss=0.3891914188861847
[15/24] Train loss=0.35938960313796997
[20/24] Train loss=0.3449416756629944
Test set avg_accuracy=63.67% avg_sensitivity=83.36%, avg_specificity=56.96% avg_auc=76.22%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.378520 Test loss=0.601642 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.38286274671554565
[5/24] Train loss=0.4002690315246582
[10/24] Train loss=0.39434078335762024
[15/24] Train loss=0.3539848327636719
[20/24] Train loss=0.3514496386051178
Test set avg_accuracy=74.13% avg_sensitivity=73.37%, avg_specificity=74.38% avg_auc=79.54%
Best model saved!! Metric=-24.573887702097366!!
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.380143 Test loss=0.542464 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3845927119255066
[5/24] Train loss=0.3871110677719116
[10/24] Train loss=0.387648344039917
[15/24] Train loss=0.36011654138565063
[20/24] Train loss=0.34875762462615967
Test set avg_accuracy=70.27% avg_sensitivity=77.32%, avg_specificity=67.87% avg_auc=78.04%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.372869 Test loss=0.559312 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3749092221260071
[5/24] Train loss=0.38434189558029175
[10/24] Train loss=0.385129451751709
[15/24] Train loss=0.35227134823799133
[20/24] Train loss=0.350057989358902
Test set avg_accuracy=72.88% avg_sensitivity=70.56%, avg_specificity=73.67% avg_auc=77.31%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.376899 Test loss=0.553720 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3729213774204254
[5/24] Train loss=0.39046862721443176
[10/24] Train loss=0.3898373246192932
[15/24] Train loss=0.35590270161628723
[20/24] Train loss=0.34854191541671753
Test set avg_accuracy=72.66% avg_sensitivity=72.81%, avg_specificity=72.60% avg_auc=77.69%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.373968 Test loss=0.554218 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.37305504083633423
[5/24] Train loss=0.3978317677974701
[10/24] Train loss=0.3893786668777466
[15/24] Train loss=0.35383734107017517
[20/24] Train loss=0.3510361611843109
Test set avg_accuracy=76.46% avg_sensitivity=63.49%, avg_specificity=80.88% avg_auc=76.93%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.375305 Test loss=0.539660 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3698650598526001
[5/24] Train loss=0.3880845606327057
[10/24] Train loss=0.38903743028640747
[15/24] Train loss=0.3693697452545166
[20/24] Train loss=0.35864099860191345
Test set avg_accuracy=70.91% avg_sensitivity=76.04%, avg_specificity=69.16% avg_auc=78.61%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.379494 Test loss=0.557665 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3811950385570526
[5/24] Train loss=0.3932379186153412
[10/24] Train loss=0.3859100639820099
[15/24] Train loss=0.3620281219482422
[20/24] Train loss=0.342245489358902
Test set avg_accuracy=70.92% avg_sensitivity=73.02%, avg_specificity=70.21% avg_auc=75.59%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.375647 Test loss=0.573378 Current lr=[0.000156543481933168]

[0/24] Train loss=0.36981233954429626
[5/24] Train loss=0.38506078720092773
[10/24] Train loss=0.386614054441452
[15/24] Train loss=0.3542713522911072
[20/24] Train loss=0.3464704155921936
Test set avg_accuracy=66.63% avg_sensitivity=78.70%, avg_specificity=62.51% avg_auc=77.02%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.372473 Test loss=0.575557 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3747794032096863
[5/24] Train loss=0.38886308670043945
[10/24] Train loss=0.38852107524871826
[15/24] Train loss=0.3564698100090027
[20/24] Train loss=0.34562626481056213
Test set avg_accuracy=69.66% avg_sensitivity=74.24%, avg_specificity=68.10% avg_auc=75.43%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.371945 Test loss=0.577881 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.36966806650161743
[5/24] Train loss=0.3904742896556854
[10/24] Train loss=0.3869517743587494
[15/24] Train loss=0.3587227761745453
[20/24] Train loss=0.3541114926338196
Test set avg_accuracy=70.30% avg_sensitivity=71.33%, avg_specificity=69.95% avg_auc=76.08%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.371031 Test loss=0.570074 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.36690619587898254
[5/24] Train loss=0.3840695917606354
[10/24] Train loss=0.38930442929267883
[15/24] Train loss=0.3622569739818573
[20/24] Train loss=0.34843653440475464
Test set avg_accuracy=73.03% avg_sensitivity=64.82%, avg_specificity=75.83% avg_auc=75.51%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.370931 Test loss=0.557948 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.36859437823295593
[5/24] Train loss=0.3800513446331024
[10/24] Train loss=0.3845766484737396
[15/24] Train loss=0.35282400250434875
[20/24] Train loss=0.3476288616657257
Test set avg_accuracy=69.87% avg_sensitivity=75.17%, avg_specificity=68.06% avg_auc=75.24%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.371759 Test loss=0.581646 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3749733567237854
[5/24] Train loss=0.3906519114971161
[10/24] Train loss=0.39128515124320984
[15/24] Train loss=0.3546047508716583
[20/24] Train loss=0.3480572998523712
Test set avg_accuracy=75.74% avg_sensitivity=60.47%, avg_specificity=80.95% avg_auc=75.75%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.372361 Test loss=0.547338 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3795255720615387
[5/24] Train loss=0.38584449887275696
[10/24] Train loss=0.3927711546421051
[15/24] Train loss=0.3550838232040405
[20/24] Train loss=0.3537847101688385
Test set avg_accuracy=74.65% avg_sensitivity=58.88%, avg_specificity=80.02% avg_auc=74.55%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.372211 Test loss=0.554159 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.37349072098731995
[5/24] Train loss=0.39582040905952454
[10/24] Train loss=0.38607534766197205
[15/24] Train loss=0.350452184677124
[20/24] Train loss=0.34279710054397583
Test set avg_accuracy=71.50% avg_sensitivity=75.27%, avg_specificity=70.21% avg_auc=77.46%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.367759 Test loss=0.555309 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3713025748729706
[5/24] Train loss=0.3860504925251007
[10/24] Train loss=0.38493794202804565
[15/24] Train loss=0.35460737347602844
[20/24] Train loss=0.34676656126976013
Test set avg_accuracy=71.11% avg_sensitivity=70.15%, avg_specificity=71.43% avg_auc=74.99%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.373370 Test loss=0.573651 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3672216236591339
[5/24] Train loss=0.38348013162612915
[10/24] Train loss=0.3843652904033661
[15/24] Train loss=0.35051214694976807
[20/24] Train loss=0.3655337393283844
Test set avg_accuracy=71.39% avg_sensitivity=68.61%, avg_specificity=72.34% avg_auc=74.84%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.370031 Test loss=0.571542 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3678583800792694
[5/24] Train loss=0.3848430812358856
[10/24] Train loss=0.3862256705760956
[15/24] Train loss=0.3523690104484558
[20/24] Train loss=0.3443063199520111
Test set avg_accuracy=72.60% avg_sensitivity=67.69%, avg_specificity=74.28% avg_auc=75.85%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.366035 Test loss=0.555452 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3601768910884857
[5/24] Train loss=0.3804323077201843
[10/24] Train loss=0.3821176290512085
[15/24] Train loss=0.3485647737979889
[20/24] Train loss=0.35100632905960083
Test set avg_accuracy=69.32% avg_sensitivity=78.14%, avg_specificity=66.32% avg_auc=74.73%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.364318 Test loss=0.584239 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.36798346042633057
[5/24] Train loss=0.3786561191082001
[10/24] Train loss=0.38479089736938477
[15/24] Train loss=0.3487868309020996
[20/24] Train loss=0.3433976173400879
Test set avg_accuracy=71.34% avg_sensitivity=72.66%, avg_specificity=70.89% avg_auc=76.49%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.365484 Test loss=0.558556 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.36102232336997986
[5/24] Train loss=0.3799888789653778
[10/24] Train loss=0.379341721534729
[15/24] Train loss=0.3465185761451721
[20/24] Train loss=0.3412041664123535
Test set avg_accuracy=69.86% avg_sensitivity=74.60%, avg_specificity=68.24% avg_auc=75.64%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.361629 Test loss=0.571038 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3605310916900635
[5/24] Train loss=0.3820688724517822
[10/24] Train loss=0.3815227746963501
[15/24] Train loss=0.34721794724464417
[20/24] Train loss=0.3426435887813568
Test set avg_accuracy=70.57% avg_sensitivity=75.37%, avg_specificity=68.94% avg_auc=77.24%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.360511 Test loss=0.553108 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3604944944381714
[5/24] Train loss=0.37504804134368896
[10/24] Train loss=0.380084365606308
[15/24] Train loss=0.3455651104450226
[20/24] Train loss=0.33879318833351135
Test set avg_accuracy=70.65% avg_sensitivity=70.10%, avg_specificity=70.84% avg_auc=74.91%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.357776 Test loss=0.570836 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.35886892676353455
[5/24] Train loss=0.3762296736240387
[10/24] Train loss=0.3805347979068756
[15/24] Train loss=0.3435724973678589
[20/24] Train loss=0.3384569585323334
Test set avg_accuracy=70.61% avg_sensitivity=70.56%, avg_specificity=70.63% avg_auc=74.85%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.357335 Test loss=0.573877 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3572850525379181
[5/24] Train loss=0.374931663274765
[10/24] Train loss=0.37945234775543213
[15/24] Train loss=0.3441159725189209
[20/24] Train loss=0.3366321921348572
Test set avg_accuracy=71.24% avg_sensitivity=70.97%, avg_specificity=71.33% avg_auc=74.01%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.357168 Test loss=0.584665 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3568305969238281
[5/24] Train loss=0.3759491741657257
[10/24] Train loss=0.3796790540218353
[15/24] Train loss=0.34349653124809265
[20/24] Train loss=0.33814746141433716
Test set avg_accuracy=70.23% avg_sensitivity=73.84%, avg_specificity=69.01% avg_auc=75.55%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.356716 Test loss=0.570735 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.35785749554634094
[5/24] Train loss=0.37215495109558105
[10/24] Train loss=0.37839943170547485
[15/24] Train loss=0.3438897728919983
[20/24] Train loss=0.3364710807800293
Test set avg_accuracy=68.74% avg_sensitivity=78.19%, avg_specificity=65.51% avg_auc=74.92%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.357393 Test loss=0.585844 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.35626062750816345
[5/24] Train loss=0.3728199303150177
[10/24] Train loss=0.37805184721946716
[15/24] Train loss=0.3435499370098114
[20/24] Train loss=0.33464115858078003
Test set avg_accuracy=70.65% avg_sensitivity=74.60%, avg_specificity=69.30% avg_auc=74.47%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.355417 Test loss=0.583597 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.35530638694763184
[5/24] Train loss=0.371947318315506
[10/24] Train loss=0.3782808184623718
[15/24] Train loss=0.3432752788066864
[20/24] Train loss=0.3347846567630768
Test set avg_accuracy=70.35% avg_sensitivity=75.27%, avg_specificity=68.67% avg_auc=74.76%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.354480 Test loss=0.581432 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.35447782278060913
[5/24] Train loss=0.37110331654548645
[10/24] Train loss=0.377206951379776
[15/24] Train loss=0.34287071228027344
[20/24] Train loss=0.3331591486930847
Test set avg_accuracy=70.65% avg_sensitivity=74.14%, avg_specificity=69.46% avg_auc=74.24%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.353829 Test loss=0.585810 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.35477983951568604
[5/24] Train loss=0.37066295742988586
[10/24] Train loss=0.3775463402271271
[15/24] Train loss=0.3417086601257324
[20/24] Train loss=0.33355072140693665
Test set avg_accuracy=69.40% avg_sensitivity=76.55%, avg_specificity=66.96% avg_auc=75.13%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.353528 Test loss=0.579401 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.35568419098854065
[5/24] Train loss=0.3700680434703827
[10/24] Train loss=0.37800028920173645
[15/24] Train loss=0.34141218662261963
[20/24] Train loss=0.3331005275249481
Test set avg_accuracy=69.95% avg_sensitivity=75.83%, avg_specificity=67.94% avg_auc=74.23%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.353351 Test loss=0.588608 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.3554745614528656
[5/24] Train loss=0.3710767924785614
[10/24] Train loss=0.37816259264945984
[15/24] Train loss=0.34050217270851135
[20/24] Train loss=0.33480891585350037
Test set avg_accuracy=70.46% avg_sensitivity=75.17%, avg_specificity=68.85% avg_auc=74.70%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.353522 Test loss=0.582103 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3539402484893799
[5/24] Train loss=0.3714396357536316
[10/24] Train loss=0.37958815693855286
[15/24] Train loss=0.3407321274280548
[20/24] Train loss=0.33271336555480957
Test set avg_accuracy=68.85% avg_sensitivity=77.88%, avg_specificity=65.78% avg_auc=74.67%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.353404 Test loss=0.588703 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3535921275615692
[5/24] Train loss=0.3695564568042755
[10/24] Train loss=0.37771904468536377
[15/24] Train loss=0.3395933508872986
[20/24] Train loss=0.33182311058044434
Test set avg_accuracy=70.39% avg_sensitivity=75.17%, avg_specificity=68.76% avg_auc=74.74%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.352476 Test loss=0.580761 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.35338321328163147
[5/24] Train loss=0.3733035922050476
[10/24] Train loss=0.37826934456825256
[15/24] Train loss=0.3389599621295929
[20/24] Train loss=0.3310999870300293
Test set avg_accuracy=68.58% avg_sensitivity=77.32%, avg_specificity=65.60% avg_auc=74.49%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.352415 Test loss=0.592865 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3525027632713318
[5/24] Train loss=0.36975908279418945
[10/24] Train loss=0.37771594524383545
[15/24] Train loss=0.33974334597587585
[20/24] Train loss=0.33117443323135376
Test set avg_accuracy=69.73% avg_sensitivity=75.93%, avg_specificity=67.61% avg_auc=74.61%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.351910 Test loss=0.584480 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3525124788284302
[5/24] Train loss=0.3707145154476166
[10/24] Train loss=0.37726449966430664
[15/24] Train loss=0.339255690574646
[20/24] Train loss=0.33080360293388367
Test set avg_accuracy=68.88% avg_sensitivity=77.16%, avg_specificity=66.06% avg_auc=74.50%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.351779 Test loss=0.592271 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3530830442905426
[5/24] Train loss=0.36848896741867065
[10/24] Train loss=0.3782869279384613
[15/24] Train loss=0.3398574888706207
[20/24] Train loss=0.3313056230545044
Test set avg_accuracy=69.04% avg_sensitivity=77.32%, avg_specificity=66.21% avg_auc=74.58%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.351207 Test loss=0.589128 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3520076870918274
[5/24] Train loss=0.36820414662361145
[10/24] Train loss=0.3779570460319519
[15/24] Train loss=0.3396953344345093
[20/24] Train loss=0.33043092489242554
Test set avg_accuracy=69.22% avg_sensitivity=76.55%, avg_specificity=66.72% avg_auc=74.35%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.350947 Test loss=0.591455 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.35164597630500793
[5/24] Train loss=0.36840420961380005
[10/24] Train loss=0.37795692682266235
[15/24] Train loss=0.339671790599823
[20/24] Train loss=0.3304291069507599
Test set avg_accuracy=69.41% avg_sensitivity=76.40%, avg_specificity=67.03% avg_auc=74.46%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.350715 Test loss=0.589279 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3513372540473938
[5/24] Train loss=0.3675038814544678
[10/24] Train loss=0.377352774143219
[15/24] Train loss=0.3404163420200348
[20/24] Train loss=0.3302079141139984
Test set avg_accuracy=68.98% avg_sensitivity=77.11%, avg_specificity=66.21% avg_auc=74.73%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.350356 Test loss=0.587950 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3503051996231079
[5/24] Train loss=0.3673418164253235
[10/24] Train loss=0.3764255940914154
[15/24] Train loss=0.34014037251472473
[20/24] Train loss=0.3298896253108978
Test set avg_accuracy=69.18% avg_sensitivity=76.40%, avg_specificity=66.72% avg_auc=74.80%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.349987 Test loss=0.585640 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.34979933500289917
[5/24] Train loss=0.36690187454223633
[10/24] Train loss=0.37653982639312744
[15/24] Train loss=0.33935073018074036
[20/24] Train loss=0.3309561014175415
Test set avg_accuracy=68.96% avg_sensitivity=77.73%, avg_specificity=65.97% avg_auc=75.09%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.349951 Test loss=0.584452 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.3495558798313141
[5/24] Train loss=0.36680394411087036
[10/24] Train loss=0.37677085399627686
[15/24] Train loss=0.33809223771095276
[20/24] Train loss=0.331605464220047
Test set avg_accuracy=68.87% avg_sensitivity=77.11%, avg_specificity=66.06% avg_auc=75.01%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.349824 Test loss=0.584357 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.34968021512031555
[5/24] Train loss=0.36585119366645813
[10/24] Train loss=0.3782726228237152
[15/24] Train loss=0.33770912885665894
[20/24] Train loss=0.33128395676612854
Test set avg_accuracy=68.58% avg_sensitivity=78.08%, avg_specificity=65.34% avg_auc=74.93%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.350036 Test loss=0.586601 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.35034456849098206
[5/24] Train loss=0.3674677014350891
[10/24] Train loss=0.37608784437179565
[15/24] Train loss=0.3381251096725464
[20/24] Train loss=0.3295638859272003
Test set avg_accuracy=69.14% avg_sensitivity=76.45%, avg_specificity=66.65% avg_auc=74.61%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.349693 Test loss=0.588252 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.34941565990448
[5/24] Train loss=0.3662013113498688
[10/24] Train loss=0.37572965025901794
[15/24] Train loss=0.3371926248073578
[20/24] Train loss=0.32904213666915894
Test set avg_accuracy=69.01% avg_sensitivity=76.45%, avg_specificity=66.47% avg_auc=74.56%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.348709 Test loss=0.588807 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.348514199256897
[5/24] Train loss=0.36518606543540955
[10/24] Train loss=0.37584778666496277
[15/24] Train loss=0.3375239968299866
[20/24] Train loss=0.32906636595726013
Test set avg_accuracy=68.65% avg_sensitivity=78.24%, avg_specificity=65.37% avg_auc=74.92%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.348487 Test loss=0.586618 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.34857237339019775
[5/24] Train loss=0.36513423919677734
[10/24] Train loss=0.37582501769065857
[15/24] Train loss=0.3373522162437439
[20/24] Train loss=0.32857152819633484
Test set avg_accuracy=68.95% avg_sensitivity=77.11%, avg_specificity=66.16% avg_auc=74.59%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.348378 Test loss=0.589549 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.34829217195510864
[5/24] Train loss=0.3650656044483185
[10/24] Train loss=0.37536418437957764
[15/24] Train loss=0.3371405005455017
[20/24] Train loss=0.328377902507782
Test set avg_accuracy=68.70% avg_sensitivity=77.16%, avg_specificity=65.81% avg_auc=74.58%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.348133 Test loss=0.590936 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3479015529155731
[5/24] Train loss=0.3646116554737091
[10/24] Train loss=0.37542495131492615
[15/24] Train loss=0.3371139168739319
[20/24] Train loss=0.3283858895301819
Test set avg_accuracy=68.66% avg_sensitivity=77.73%, avg_specificity=65.57% avg_auc=74.61%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.347980 Test loss=0.591213 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.347763329744339
[5/24] Train loss=0.36442381143569946
[10/24] Train loss=0.37532860040664673
[15/24] Train loss=0.3371192514896393
[20/24] Train loss=0.3281742334365845
Test set avg_accuracy=68.68% avg_sensitivity=77.16%, avg_specificity=65.79% avg_auc=74.60%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.347897 Test loss=0.590982 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.3476114571094513
[5/24] Train loss=0.3642820417881012
[10/24] Train loss=0.37523317337036133
[15/24] Train loss=0.3370611369609833
[20/24] Train loss=0.3281751573085785
Test set avg_accuracy=68.89% avg_sensitivity=78.03%, avg_specificity=65.78% avg_auc=74.62%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.347796 Test loss=0.590938 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3475340008735657
[5/24] Train loss=0.36416712403297424
[10/24] Train loss=0.3751952052116394
[15/24] Train loss=0.33703383803367615
[20/24] Train loss=0.32808178663253784
Test set avg_accuracy=68.89% avg_sensitivity=78.03%, avg_specificity=65.78% avg_auc=74.61%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.347741 Test loss=0.591177 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3474375605583191
[5/24] Train loss=0.36408349871635437
[10/24] Train loss=0.3751586675643921
[15/24] Train loss=0.3370126485824585
[20/24] Train loss=0.32804977893829346
Test set avg_accuracy=68.88% avg_sensitivity=78.03%, avg_specificity=65.76% avg_auc=74.61%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.347690 Test loss=0.591293 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3473767340183258
[5/24] Train loss=0.36402609944343567
[10/24] Train loss=0.37511807680130005
[15/24] Train loss=0.3369925916194916
[20/24] Train loss=0.3280203938484192
Test set avg_accuracy=68.88% avg_sensitivity=78.03%, avg_specificity=65.76% avg_auc=74.61%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.347653 Test loss=0.591366 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.34733518958091736
[5/24] Train loss=0.3639867603778839
[10/24] Train loss=0.3750985562801361
[15/24] Train loss=0.3369808495044708
[20/24] Train loss=0.3279988467693329
Test set avg_accuracy=68.88% avg_sensitivity=78.03%, avg_specificity=65.76% avg_auc=74.61%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.347628 Test loss=0.591429 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3473113477230072
[5/24] Train loss=0.363959938287735
[10/24] Train loss=0.37508535385131836
[15/24] Train loss=0.3369733393192291
[20/24] Train loss=0.32798701524734497
Test set avg_accuracy=68.88% avg_sensitivity=78.03%, avg_specificity=65.76% avg_auc=74.60%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.347611 Test loss=0.591464 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3472979664802551
[5/24] Train loss=0.3639449179172516
[10/24] Train loss=0.3750764727592468
[15/24] Train loss=0.33696940541267395
[20/24] Train loss=0.327981561422348
Test set avg_accuracy=68.88% avg_sensitivity=78.03%, avg_specificity=65.76% avg_auc=74.61%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.347602 Test loss=0.591479 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3472917973995209
[5/24] Train loss=0.36393871903419495
[10/24] Train loss=0.3750722408294678
[15/24] Train loss=0.33696800470352173
[20/24] Train loss=0.32798007130622864
Test set avg_accuracy=68.88% avg_sensitivity=78.03%, avg_specificity=65.76% avg_auc=74.61%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.347599 Test loss=0.591482 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=74.13% sen=73.37%, spe=74.38%, auc=79.54%!
Fold[5] Avg_overlap=0.58%(0.24767962784530267)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 1,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'SwEDModel',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.701848030090332
[5/24] Train loss=0.7003790140151978
[10/24] Train loss=0.6988927721977234
[15/24] Train loss=0.7001960277557373
[20/24] Train loss=0.6974183917045593
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.08%
Best model saved!! Metric=-104.05713601240168!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.699361 Test loss=0.698366 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.698401927947998
[5/24] Train loss=0.6973592638969421
[10/24] Train loss=0.6958515644073486
[15/24] Train loss=0.696955144405365
[20/24] Train loss=0.6945359706878662
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=48.94%
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.696381 Test loss=0.695718 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6953685283660889
[5/24] Train loss=0.694401741027832
[10/24] Train loss=0.6927887201309204
[15/24] Train loss=0.6937090158462524
[20/24] Train loss=0.6915075182914734
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.05%
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.693379 Test loss=0.692870 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6920725703239441
[5/24] Train loss=0.69110107421875
[10/24] Train loss=0.6894289255142212
[15/24] Train loss=0.6901372075080872
[20/24] Train loss=0.6881959438323975
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.22%
Best model saved!! Metric=-103.91857134666157!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.690069 Test loss=0.689701 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6884294748306274
[5/24] Train loss=0.6873223781585693
[10/24] Train loss=0.6856322884559631
[15/24] Train loss=0.686103343963623
[20/24] Train loss=0.6843384504318237
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.42%
Best model saved!! Metric=-103.71560127206757!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.686329 Test loss=0.686116 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6843287348747253
[5/24] Train loss=0.682981014251709
[10/24] Train loss=0.6810535192489624
[15/24] Train loss=0.6812449097633362
[20/24] Train loss=0.6795477867126465
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.66%
Best model saved!! Metric=-103.47072180647726!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.681880 Test loss=0.681745 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6792467832565308
[5/24] Train loss=0.6777064204216003
[10/24] Train loss=0.6754928827285767
[15/24] Train loss=0.6751696467399597
[20/24] Train loss=0.6736648678779602
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.74%
Best model saved!! Metric=-103.39427307493196!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.676425 Test loss=0.676267 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6728159189224243
[5/24] Train loss=0.6709400415420532
[10/24] Train loss=0.6680667400360107
[15/24] Train loss=0.6668145656585693
[20/24] Train loss=0.6653053760528564
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.95%
Best model saved!! Metric=-103.1812061598473!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.669077 Test loss=0.668540 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6638491749763489
[5/24] Train loss=0.6612645387649536
[10/24] Train loss=0.657447874546051
[15/24] Train loss=0.6548534035682678
[20/24] Train loss=0.6533563733100891
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.08%
Best model saved!! Metric=-103.05961104598066!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.658605 Test loss=0.657614 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6510511636734009
[5/24] Train loss=0.6473071575164795
[10/24] Train loss=0.642002522945404
[15/24] Train loss=0.6368970274925232
[20/24] Train loss=0.6354925036430359
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.40%
Best model saved!! Metric=-102.73686800495464!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.643313 Test loss=0.642073 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6324493288993835
[5/24] Train loss=0.626618504524231
[10/24] Train loss=0.6202413439750671
[15/24] Train loss=0.6108443140983582
[20/24] Train loss=0.6107398867607117
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.66%
Best model saved!! Metric=-102.47622374850056!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.621476 Test loss=0.621602 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6080814599990845
[5/24] Train loss=0.5984206795692444
[10/24] Train loss=0.5932109951972961
[15/24] Train loss=0.579720675945282
[20/24] Train loss=0.5859938263893127
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.49%
Best model saved!! Metric=-101.64838143859727!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.595743 Test loss=0.601451 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5858010649681091
[5/24] Train loss=0.5724232196807861
[10/24] Train loss=0.5737906694412231
[15/24] Train loss=0.5582579374313354
[20/24] Train loss=0.5720928311347961
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=53.03%
Best model saved!! Metric=-100.10625733432207!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.576727 Test loss=0.587851 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5726561546325684
[5/24] Train loss=0.5592279434204102
[10/24] Train loss=0.5650743842124939
[15/24] Train loss=0.5469959378242493
[20/24] Train loss=0.5646545886993408
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=55.19%
Best model saved!! Metric=-97.94790440468628!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.566662 Test loss=0.580941 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5657539367675781
[5/24] Train loss=0.5517767071723938
[10/24] Train loss=0.5607179403305054
[15/24] Train loss=0.5422999262809753
[20/24] Train loss=0.5618547797203064
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=58.92%
Best model saved!! Metric=-94.21839305918175!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.562098 Test loss=0.578513 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5642630457878113
[5/24] Train loss=0.5487890243530273
[10/24] Train loss=0.5593334436416626
[15/24] Train loss=0.5398378372192383
[20/24] Train loss=0.5592267513275146
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=60.55%
Best model saved!! Metric=-92.58217326138266!!
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.560180 Test loss=0.576601 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.561532735824585
[5/24] Train loss=0.5458798408508301
[10/24] Train loss=0.5581221580505371
[15/24] Train loss=0.5356753468513489
[20/24] Train loss=0.5546996593475342
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=62.40%
Best model saved!! Metric=-90.73644080784786!!
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.557499 Test loss=0.573842 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5571392774581909
[5/24] Train loss=0.5409757494926453
[10/24] Train loss=0.5555997490882874
[15/24] Train loss=0.5277630686759949
[20/24] Train loss=0.5487158894538879
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=65.33%
Best model saved!! Metric=-87.80575032287024!!
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.553127 Test loss=0.568105 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5535160303115845
[5/24] Train loss=0.5339142084121704
[10/24] Train loss=0.5484033226966858
[15/24] Train loss=0.5157672166824341
[20/24] Train loss=0.5332282781600952
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=68.57%
Best model saved!! Metric=-84.56901624217922!!
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.545664 Test loss=0.559269 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5432989001274109
[5/24] Train loss=0.5205076932907104
[10/24] Train loss=0.5359170436859131
[15/24] Train loss=0.5016947984695435
[20/24] Train loss=0.5187042951583862
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=71.84%
Best model saved!! Metric=-81.29943634620194!!
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.533861 Test loss=0.551482 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5270774364471436
[5/24] Train loss=0.5171463489532471
[10/24] Train loss=0.5199659466743469
[15/24] Train loss=0.47616177797317505
[20/24] Train loss=0.4966149628162384
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=73.38%
Best model saved!! Metric=-79.75810541198653!!
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.519708 Test loss=0.552259 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5145028233528137
[5/24] Train loss=0.5058940649032593
[10/24] Train loss=0.499886155128479
[15/24] Train loss=0.46279075741767883
[20/24] Train loss=0.48575425148010254
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=71.63%
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.507096 Test loss=0.633300 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5122748017311096
[5/24] Train loss=0.48674485087394714
[10/24] Train loss=0.49041229486465454
[15/24] Train loss=0.45935505628585815
[20/24] Train loss=0.47684791684150696
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=73.89%
Best model saved!! Metric=-79.24441846943502!!
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.497919 Test loss=0.602459 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.4943397641181946
[5/24] Train loss=0.48290663957595825
[10/24] Train loss=0.504395067691803
[15/24] Train loss=0.4563339352607727
[20/24] Train loss=0.47089624404907227
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=73.27%
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.490397 Test loss=0.600182 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.4902094602584839
[5/24] Train loss=0.4866846203804016
[10/24] Train loss=0.486583948135376
[15/24] Train loss=0.446261465549469
[20/24] Train loss=0.4701243042945862
Test set avg_accuracy=71.85% avg_sensitivity=8.45%, avg_specificity=95.46% avg_auc=73.63%
Best model saved!! Metric=-76.61236154966508!!
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.488135 Test loss=0.601303 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.47629696130752563
[5/24] Train loss=0.4778875410556793
[10/24] Train loss=0.48404091596603394
[15/24] Train loss=0.44341471791267395
[20/24] Train loss=0.46654725074768066
Test set avg_accuracy=67.07% avg_sensitivity=23.27%, avg_specificity=83.38% avg_auc=66.17%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.482398 Test loss=0.623778 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.4774843454360962
[5/24] Train loss=0.47599342465400696
[10/24] Train loss=0.4868527054786682
[15/24] Train loss=0.4492485225200653
[20/24] Train loss=0.4615551829338074
Test set avg_accuracy=65.66% avg_sensitivity=24.81%, avg_specificity=80.88% avg_auc=66.37%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.478519 Test loss=0.624695 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.4810449779033661
[5/24] Train loss=0.479133278131485
[10/24] Train loss=0.47923892736434937
[15/24] Train loss=0.44169291853904724
[20/24] Train loss=0.46090948581695557
Test set avg_accuracy=62.59% avg_sensitivity=37.43%, avg_specificity=71.96% avg_auc=65.40%
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.476222 Test loss=0.629533 Current lr=[0.000210185142098938]

[0/24] Train loss=0.4735550880432129
[5/24] Train loss=0.46956685185432434
[10/24] Train loss=0.4757882356643677
[15/24] Train loss=0.4423305094242096
[20/24] Train loss=0.4568830728530884
Test set avg_accuracy=64.84% avg_sensitivity=40.64%, avg_specificity=73.86% avg_auc=69.48%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.473077 Test loss=0.613504 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.479243665933609
[5/24] Train loss=0.46854138374328613
[10/24] Train loss=0.4745221436023712
[15/24] Train loss=0.44582581520080566
[20/24] Train loss=0.4595620334148407
Test set avg_accuracy=63.40% avg_sensitivity=50.34%, avg_specificity=68.26% avg_auc=70.01%
Best model saved!! Metric=-73.99350821389763!!
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.473697 Test loss=0.618711 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.4654267132282257
[5/24] Train loss=0.47058260440826416
[10/24] Train loss=0.47362521290779114
[15/24] Train loss=0.4493817985057831
[20/24] Train loss=0.4551229178905487
Test set avg_accuracy=63.48% avg_sensitivity=55.57%, avg_specificity=66.42% avg_auc=71.78%
Best model saved!! Metric=-68.7505470408154!!
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.473771 Test loss=0.608494 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.4589388966560364
[5/24] Train loss=0.47514232993125916
[10/24] Train loss=0.4796806275844574
[15/24] Train loss=0.4372110068798065
[20/24] Train loss=0.45102259516716003
Test set avg_accuracy=52.66% avg_sensitivity=71.11%, avg_specificity=45.78% avg_auc=67.60%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.470899 Test loss=0.646232 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.4569120407104492
[5/24] Train loss=0.4717053472995758
[10/24] Train loss=0.47362375259399414
[15/24] Train loss=0.4379209876060486
[20/24] Train loss=0.45171934366226196
Test set avg_accuracy=50.34% avg_sensitivity=79.61%, avg_specificity=39.44% avg_auc=64.78%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.469215 Test loss=0.651938 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.4709925055503845
[5/24] Train loss=0.47440576553344727
[10/24] Train loss=0.47407257556915283
[15/24] Train loss=0.43649017810821533
[20/24] Train loss=0.4582746624946594
Test set avg_accuracy=50.69% avg_sensitivity=79.65%, avg_specificity=39.90% avg_auc=66.17%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.468566 Test loss=0.649097 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.46050015091896057
[5/24] Train loss=0.476563960313797
[10/24] Train loss=0.4747224748134613
[15/24] Train loss=0.4359147250652313
[20/24] Train loss=0.44727572798728943
Test set avg_accuracy=48.93% avg_sensitivity=81.38%, avg_specificity=36.85% avg_auc=65.05%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.468001 Test loss=0.654719 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4597201347351074
[5/24] Train loss=0.47051337361335754
[10/24] Train loss=0.481822669506073
[15/24] Train loss=0.4389251172542572
[20/24] Train loss=0.4566538333892822
Test set avg_accuracy=58.71% avg_sensitivity=69.91%, avg_specificity=54.54% avg_auc=69.25%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.469440 Test loss=0.626869 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4700043499469757
[5/24] Train loss=0.4688851237297058
[10/24] Train loss=0.47507378458976746
[15/24] Train loss=0.4367339611053467
[20/24] Train loss=0.4474387764930725
Test set avg_accuracy=53.98% avg_sensitivity=76.44%, avg_specificity=45.62% avg_auc=68.35%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.469041 Test loss=0.639933 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.45221084356307983
[5/24] Train loss=0.46740445494651794
[10/24] Train loss=0.47357815504074097
[15/24] Train loss=0.43945080041885376
[20/24] Train loss=0.44927921891212463
Test set avg_accuracy=62.23% avg_sensitivity=63.24%, avg_specificity=61.85% avg_auc=70.98%
Best model saved!! Metric=-67.70383524091446!!
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.467906 Test loss=0.619109 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.45501700043678284
[5/24] Train loss=0.47209593653678894
[10/24] Train loss=0.4717278778553009
[15/24] Train loss=0.43491536378860474
[20/24] Train loss=0.45119890570640564
Test set avg_accuracy=53.31% avg_sensitivity=73.75%, avg_specificity=45.69% avg_auc=67.04%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.468344 Test loss=0.645258 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.45373526215553284
[5/24] Train loss=0.4669331908226013
[10/24] Train loss=0.47002819180488586
[15/24] Train loss=0.43312424421310425
[20/24] Train loss=0.4452632963657379
Test set avg_accuracy=61.28% avg_sensitivity=67.37%, avg_specificity=59.01% avg_auc=70.80%
Best model saved!! Metric=-67.54245598520694!!
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.465790 Test loss=0.622377 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.45057612657546997
[5/24] Train loss=0.46414512395858765
[10/24] Train loss=0.4698707163333893
[15/24] Train loss=0.4354468584060669
[20/24] Train loss=0.44419923424720764
Test set avg_accuracy=51.37% avg_sensitivity=80.37%, avg_specificity=40.56% avg_auc=68.16%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.465667 Test loss=0.640505 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.45527467131614685
[5/24] Train loss=0.4644206464290619
[10/24] Train loss=0.4707583487033844
[15/24] Train loss=0.43504393100738525
[20/24] Train loss=0.4496003985404968
Test set avg_accuracy=49.38% avg_sensitivity=82.25%, avg_specificity=37.13% avg_auc=67.37%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.467724 Test loss=0.645596 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.45365220308303833
[5/24] Train loss=0.45921555161476135
[10/24] Train loss=0.4707775115966797
[15/24] Train loss=0.4442669749259949
[20/24] Train loss=0.45517829060554504
Test set avg_accuracy=61.61% avg_sensitivity=67.37%, avg_specificity=59.47% avg_auc=72.51%
Best model saved!! Metric=-65.03404112971197!!
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.466514 Test loss=0.608504 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.4671906530857086
[5/24] Train loss=0.460586816072464
[10/24] Train loss=0.4680554270744324
[15/24] Train loss=0.42915043234825134
[20/24] Train loss=0.44223931431770325
Test set avg_accuracy=57.71% avg_sensitivity=70.15%, avg_specificity=53.07% avg_auc=69.49%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.463985 Test loss=0.629686 Current lr=[0.00029967723776099]

[0/24] Train loss=0.4503699243068695
[5/24] Train loss=0.46991071105003357
[10/24] Train loss=0.4695776104927063
[15/24] Train loss=0.4299298822879791
[20/24] Train loss=0.4497845470905304
Test set avg_accuracy=55.68% avg_sensitivity=78.65%, avg_specificity=47.12% avg_auc=69.51%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.463893 Test loss=0.632245 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.44781821966171265
[5/24] Train loss=0.47821006178855896
[10/24] Train loss=0.4743432402610779
[15/24] Train loss=0.42841270565986633
[20/24] Train loss=0.4446188807487488
Test set avg_accuracy=61.72% avg_sensitivity=66.94%, avg_specificity=59.77% avg_auc=72.64%
Best model saved!! Metric=-64.93083484192849!!
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.464768 Test loss=0.606050 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.45564723014831543
[5/24] Train loss=0.46921199560165405
[10/24] Train loss=0.475712388753891
[15/24] Train loss=0.4373699426651001
[20/24] Train loss=0.4471627175807953
Test set avg_accuracy=64.95% avg_sensitivity=51.30%, avg_specificity=70.03% avg_auc=69.79%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.468856 Test loss=0.615203 Current lr=[0.000299720220882401]

[0/24] Train loss=0.44946837425231934
[5/24] Train loss=0.4605060815811157
[10/24] Train loss=0.47559070587158203
[15/24] Train loss=0.43371427059173584
[20/24] Train loss=0.4467427730560303
Test set avg_accuracy=58.19% avg_sensitivity=69.10%, avg_specificity=54.13% avg_auc=68.54%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.464979 Test loss=0.627712 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.45230942964553833
[5/24] Train loss=0.4595370888710022
[10/24] Train loss=0.46875208616256714
[15/24] Train loss=0.4286108911037445
[20/24] Train loss=0.4457137882709503
Test set avg_accuracy=61.68% avg_sensitivity=63.44%, avg_specificity=61.03% avg_auc=71.09%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.461617 Test loss=0.612182 Current lr=[0.000298904600941902]

[0/24] Train loss=0.4494233727455139
[5/24] Train loss=0.4581261873245239
[10/24] Train loss=0.4662769138813019
[15/24] Train loss=0.42995238304138184
[20/24] Train loss=0.4383082389831543
Test set avg_accuracy=62.68% avg_sensitivity=61.61%, avg_specificity=63.08% avg_auc=71.95%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.460521 Test loss=0.608481 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.4431650936603546
[5/24] Train loss=0.45568570494651794
[10/24] Train loss=0.4675212800502777
[15/24] Train loss=0.42857277393341064
[20/24] Train loss=0.4418432116508484
Test set avg_accuracy=59.02% avg_sensitivity=73.61%, avg_specificity=53.59% avg_auc=70.69%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.459550 Test loss=0.619518 Current lr=[0.000297555943323901]

[0/24] Train loss=0.45701295137405396
[5/24] Train loss=0.45828014612197876
[10/24] Train loss=0.46584805846214294
[15/24] Train loss=0.4297211766242981
[20/24] Train loss=0.45238813757896423
Test set avg_accuracy=61.41% avg_sensitivity=58.40%, avg_specificity=62.53% avg_auc=73.01%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.465438 Test loss=0.610867 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.4534895718097687
[5/24] Train loss=0.4637720286846161
[10/24] Train loss=0.4654434025287628
[15/24] Train loss=0.4388132393360138
[20/24] Train loss=0.44743502140045166
Test set avg_accuracy=60.90% avg_sensitivity=70.25%, avg_specificity=57.42% avg_auc=70.59%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.462610 Test loss=0.616392 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.45886990427970886
[5/24] Train loss=0.46306782960891724
[10/24] Train loss=0.4693492352962494
[15/24] Train loss=0.42927229404449463
[20/24] Train loss=0.43849387764930725
Test set avg_accuracy=54.14% avg_sensitivity=79.22%, avg_specificity=44.80% avg_auc=69.88%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.462877 Test loss=0.630655 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.44811198115348816
[5/24] Train loss=0.45311370491981506
[10/24] Train loss=0.4647124707698822
[15/24] Train loss=0.4277046024799347
[20/24] Train loss=0.44344645738601685
Test set avg_accuracy=62.33% avg_sensitivity=63.58%, avg_specificity=61.87% avg_auc=69.99%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.460218 Test loss=0.615215 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.4427310824394226
[5/24] Train loss=0.4511973261833191
[10/24] Train loss=0.4653818607330322
[15/24] Train loss=0.4253089725971222
[20/24] Train loss=0.4373123347759247
Test set avg_accuracy=61.32% avg_sensitivity=72.50%, avg_specificity=57.15% avg_auc=72.90%
Best model saved!! Metric=-62.13036088994768!!
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.457865 Test loss=0.606722 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.4597110450267792
[5/24] Train loss=0.45604580640792847
[10/24] Train loss=0.4665399193763733
[15/24] Train loss=0.43751439452171326
[20/24] Train loss=0.44210419058799744
Test set avg_accuracy=65.26% avg_sensitivity=62.52%, avg_specificity=66.28% avg_auc=75.42%
Best model saved!! Metric=-56.519395551822264!!
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.461736 Test loss=0.578245 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.4466153085231781
[5/24] Train loss=0.4570358395576477
[10/24] Train loss=0.46313053369522095
[15/24] Train loss=0.42788025736808777
[20/24] Train loss=0.4588160812854767
Test set avg_accuracy=67.80% avg_sensitivity=52.06%, avg_specificity=73.66% avg_auc=73.46%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.462645 Test loss=0.586775 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.451821893453598
[5/24] Train loss=0.463458389043808
[10/24] Train loss=0.4676363170146942
[15/24] Train loss=0.43028879165649414
[20/24] Train loss=0.44284453988075256
Test set avg_accuracy=50.30% avg_sensitivity=85.08%, avg_specificity=37.35% avg_auc=67.69%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.462817 Test loss=0.643654 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.4455377161502838
[5/24] Train loss=0.45454102754592896
[10/24] Train loss=0.46430811285972595
[15/24] Train loss=0.4302695691585541
[20/24] Train loss=0.4394623637199402
Test set avg_accuracy=66.09% avg_sensitivity=57.01%, avg_specificity=69.48% avg_auc=70.52%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.459206 Test loss=0.603001 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.44444337487220764
[5/24] Train loss=0.4563054144382477
[10/24] Train loss=0.46775445342063904
[15/24] Train loss=0.42709171772003174
[20/24] Train loss=0.4376432001590729
Test set avg_accuracy=54.90% avg_sensitivity=79.89%, avg_specificity=45.59% avg_auc=69.54%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.457099 Test loss=0.630706 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.4503677487373352
[5/24] Train loss=0.4524156153202057
[10/24] Train loss=0.46751895546913147
[15/24] Train loss=0.4243822991847992
[20/24] Train loss=0.4410127103328705
Test set avg_accuracy=59.67% avg_sensitivity=72.46%, avg_specificity=54.91% avg_auc=71.20%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.457795 Test loss=0.615136 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.4444984793663025
[5/24] Train loss=0.45130568742752075
[10/24] Train loss=0.46065255999565125
[15/24] Train loss=0.42777127027511597
[20/24] Train loss=0.4418657422065735
Test set avg_accuracy=63.62% avg_sensitivity=64.54%, avg_specificity=63.28% avg_auc=71.60%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.460046 Test loss=0.602316 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.44395318627357483
[5/24] Train loss=0.4577813446521759
[10/24] Train loss=0.4612398147583008
[15/24] Train loss=0.4326738715171814
[20/24] Train loss=0.4438397288322449
Test set avg_accuracy=66.69% avg_sensitivity=63.53%, avg_specificity=67.87% avg_auc=75.98%
Best model saved!! Metric=-51.929562475676114!!
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.459636 Test loss=0.563946 Current lr=[0.000276307469034998]

[0/24] Train loss=0.44730472564697266
[5/24] Train loss=0.45263007283210754
[10/24] Train loss=0.4638065993785858
[15/24] Train loss=0.4275659918785095
[20/24] Train loss=0.4372130334377289
Test set avg_accuracy=58.23% avg_sensitivity=74.76%, avg_specificity=52.07% avg_auc=71.92%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.456410 Test loss=0.612944 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.4443207383155823
[5/24] Train loss=0.4516911506652832
[10/24] Train loss=0.458006888628006
[15/24] Train loss=0.4235096871852875
[20/24] Train loss=0.4331974983215332
Test set avg_accuracy=64.52% avg_sensitivity=58.97%, avg_specificity=66.58% avg_auc=69.00%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.454318 Test loss=0.605831 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.44045284390449524
[5/24] Train loss=0.4485272467136383
[10/24] Train loss=0.4640599191188812
[15/24] Train loss=0.42553144693374634
[20/24] Train loss=0.4336467385292053
Test set avg_accuracy=59.47% avg_sensitivity=75.29%, avg_specificity=53.57% avg_auc=71.08%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.454047 Test loss=0.611926 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.44792959094047546
[5/24] Train loss=0.4497479498386383
[10/24] Train loss=0.46249252557754517
[15/24] Train loss=0.4253047704696655
[20/24] Train loss=0.44513171911239624
Test set avg_accuracy=55.62% avg_sensitivity=80.57%, avg_specificity=46.34% avg_auc=70.05%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.455224 Test loss=0.629385 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.4445696473121643
[5/24] Train loss=0.45518964529037476
[10/24] Train loss=0.46520963311195374
[15/24] Train loss=0.4236918091773987
[20/24] Train loss=0.4367334246635437
Test set avg_accuracy=65.89% avg_sensitivity=66.36%, avg_specificity=65.71% avg_auc=74.36%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.458116 Test loss=0.584571 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.44132450222969055
[5/24] Train loss=0.45002761483192444
[10/24] Train loss=0.46101105213165283
[15/24] Train loss=0.42953500151634216
[20/24] Train loss=0.4395720362663269
Test set avg_accuracy=61.78% avg_sensitivity=67.75%, avg_specificity=59.56% avg_auc=71.43%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.454339 Test loss=0.602576 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.4460841119289398
[5/24] Train loss=0.4534923732280731
[10/24] Train loss=0.4642341732978821
[15/24] Train loss=0.42292284965515137
[20/24] Train loss=0.43585050106048584
Test set avg_accuracy=54.86% avg_sensitivity=76.01%, avg_specificity=46.98% avg_auc=70.88%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.459065 Test loss=0.625344 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.4463779032230377
[5/24] Train loss=0.46294620633125305
[10/24] Train loss=0.4629276692867279
[15/24] Train loss=0.4236038029193878
[20/24] Train loss=0.441806823015213
Test set avg_accuracy=61.54% avg_sensitivity=69.10%, avg_specificity=58.72% avg_auc=72.45%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.458061 Test loss=0.606266 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.4453466534614563
[5/24] Train loss=0.45005857944488525
[10/24] Train loss=0.4644441306591034
[15/24] Train loss=0.4255902171134949
[20/24] Train loss=0.43724730610847473
Test set avg_accuracy=56.00% avg_sensitivity=80.47%, avg_specificity=46.89% avg_auc=69.54%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.455747 Test loss=0.628675 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.440643846988678
[5/24] Train loss=0.45179203152656555
[10/24] Train loss=0.4589720070362091
[15/24] Train loss=0.42358720302581787
[20/24] Train loss=0.43053558468818665
Test set avg_accuracy=62.34% avg_sensitivity=65.64%, avg_specificity=61.12% avg_auc=72.47%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.454979 Test loss=0.599280 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.4387534558773041
[5/24] Train loss=0.4546014070510864
[10/24] Train loss=0.4661392271518707
[15/24] Train loss=0.41974133253097534
[20/24] Train loss=0.4336250424385071
Test set avg_accuracy=61.67% avg_sensitivity=67.56%, avg_specificity=59.47% avg_auc=71.67%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.454035 Test loss=0.604283 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.44232380390167236
[5/24] Train loss=0.446154922246933
[10/24] Train loss=0.4629587233066559
[15/24] Train loss=0.421204149723053
[20/24] Train loss=0.4325670599937439
Test set avg_accuracy=54.19% avg_sensitivity=81.14%, avg_specificity=44.16% avg_auc=69.05%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.451821 Test loss=0.635036 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.4429740607738495
[5/24] Train loss=0.4485318958759308
[10/24] Train loss=0.4622824490070343
[15/24] Train loss=0.4209238290786743
[20/24] Train loss=0.4418671429157257
Test set avg_accuracy=68.44% avg_sensitivity=60.41%, avg_specificity=71.43% avg_auc=77.45%
Best model saved!! Metric=-48.27762126841355!!
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.455672 Test loss=0.554620 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.44387882947921753
[5/24] Train loss=0.4616212546825409
[10/24] Train loss=0.4646751284599304
[15/24] Train loss=0.4247947931289673
[20/24] Train loss=0.43204087018966675
Test set avg_accuracy=66.68% avg_sensitivity=64.49%, avg_specificity=67.49% avg_auc=74.16%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.456830 Test loss=0.583245 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.4474084973335266
[5/24] Train loss=0.44888588786125183
[10/24] Train loss=0.46275007724761963
[15/24] Train loss=0.42770323157310486
[20/24] Train loss=0.4326260983943939
Test set avg_accuracy=63.68% avg_sensitivity=65.40%, avg_specificity=63.05% avg_auc=72.62%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.453535 Test loss=0.595102 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.44545847177505493
[5/24] Train loss=0.44886013865470886
[10/24] Train loss=0.46351176500320435
[15/24] Train loss=0.4307364821434021
[20/24] Train loss=0.43147605657577515
Test set avg_accuracy=60.33% avg_sensitivity=72.70%, avg_specificity=55.72% avg_auc=73.71%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.456048 Test loss=0.598788 Current lr=[0.000224838296036774]

[0/24] Train loss=0.44210684299468994
[5/24] Train loss=0.4482972025871277
[10/24] Train loss=0.4617407023906708
[15/24] Train loss=0.4288610816001892
[20/24] Train loss=0.4349045753479004
Test set avg_accuracy=56.88% avg_sensitivity=77.78%, avg_specificity=49.09% avg_auc=70.78%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.452440 Test loss=0.620435 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.4394157826900482
[5/24] Train loss=0.44428586959838867
[10/24] Train loss=0.4585637152194977
[15/24] Train loss=0.4171801209449768
[20/24] Train loss=0.43566370010375977
Test set avg_accuracy=59.15% avg_sensitivity=68.52%, avg_specificity=55.66% avg_auc=72.53%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.451669 Test loss=0.603377 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.43891412019729614
[5/24] Train loss=0.4450412094593048
[10/24] Train loss=0.4586188793182373
[15/24] Train loss=0.42183059453964233
[20/24] Train loss=0.42985999584198
Test set avg_accuracy=58.70% avg_sensitivity=74.42%, avg_specificity=52.84% avg_auc=71.60%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.451534 Test loss=0.611053 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.44094690680503845
[5/24] Train loss=0.44711676239967346
[10/24] Train loss=0.45899972319602966
[15/24] Train loss=0.4203394055366516
[20/24] Train loss=0.4359899163246155
Test set avg_accuracy=61.35% avg_sensitivity=65.98%, avg_specificity=59.63% avg_auc=71.64%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.451260 Test loss=0.598916 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.43849363923072815
[5/24] Train loss=0.443190336227417
[10/24] Train loss=0.4600505530834198
[15/24] Train loss=0.4231211543083191
[20/24] Train loss=0.4363759756088257
Test set avg_accuracy=63.31% avg_sensitivity=69.72%, avg_specificity=60.92% avg_auc=74.57%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.451449 Test loss=0.584747 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.44305965304374695
[5/24] Train loss=0.4471955895423889
[10/24] Train loss=0.46315598487854004
[15/24] Train loss=0.4219186305999756
[20/24] Train loss=0.4335441291332245
Test set avg_accuracy=76.68% avg_sensitivity=43.43%, avg_specificity=89.06% avg_auc=79.11%
Best model saved!! Metric=-37.71661181717063!!
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.454757 Test loss=0.513977 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.4425182640552521
[5/24] Train loss=0.4445663094520569
[10/24] Train loss=0.45929187536239624
[15/24] Train loss=0.41746821999549866
[20/24] Train loss=0.4383133053779602
Test set avg_accuracy=60.33% avg_sensitivity=73.22%, avg_specificity=55.52% avg_auc=71.54%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.450670 Test loss=0.604048 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.4337103068828583
[5/24] Train loss=0.4456780254840851
[10/24] Train loss=0.45954152941703796
[15/24] Train loss=0.4185067117214203
[20/24] Train loss=0.4302726089954376
Test set avg_accuracy=58.29% avg_sensitivity=74.71%, avg_specificity=52.18% avg_auc=71.01%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.451119 Test loss=0.609885 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.44950151443481445
[5/24] Train loss=0.4475270211696625
[10/24] Train loss=0.464051216840744
[15/24] Train loss=0.41938909888267517
[20/24] Train loss=0.4282864034175873
Test set avg_accuracy=55.51% avg_sensitivity=80.85%, avg_specificity=46.07% avg_auc=69.86%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.451810 Test loss=0.625991 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.44217607378959656
[5/24] Train loss=0.46498236060142517
[10/24] Train loss=0.45945921540260315
[15/24] Train loss=0.4281308650970459
[20/24] Train loss=0.43249812722206116
Test set avg_accuracy=70.31% avg_sensitivity=48.32%, avg_specificity=78.50% avg_auc=76.58%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.455868 Test loss=0.550725 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.44395479559898376
[5/24] Train loss=0.4497615694999695
[10/24] Train loss=0.4680521488189697
[15/24] Train loss=0.4206772446632385
[20/24] Train loss=0.43430158495903015
Test set avg_accuracy=64.02% avg_sensitivity=67.23%, avg_specificity=62.83% avg_auc=74.93%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.453752 Test loss=0.583527 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.45081618428230286
[5/24] Train loss=0.45090001821517944
[10/24] Train loss=0.46280115842819214
[15/24] Train loss=0.4209575951099396
[20/24] Train loss=0.42787402868270874
Test set avg_accuracy=67.84% avg_sensitivity=62.48%, avg_specificity=69.84% avg_auc=76.88%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.453865 Test loss=0.557308 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.4542931616306305
[5/24] Train loss=0.4541853964328766
[10/24] Train loss=0.4658171534538269
[15/24] Train loss=0.4176206588745117
[20/24] Train loss=0.42793920636177063
Test set avg_accuracy=59.99% avg_sensitivity=69.87%, avg_specificity=56.31% avg_auc=71.48%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.452931 Test loss=0.604572 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.44679123163223267
[5/24] Train loss=0.4460197389125824
[10/24] Train loss=0.459625780582428
[15/24] Train loss=0.4216228127479553
[20/24] Train loss=0.42866846919059753
Test set avg_accuracy=57.47% avg_sensitivity=78.36%, avg_specificity=49.70% avg_auc=71.03%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.450953 Test loss=0.614708 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.4386501610279083
[5/24] Train loss=0.4474087059497833
[10/24] Train loss=0.4597633481025696
[15/24] Train loss=0.42473605275154114
[20/24] Train loss=0.4259158670902252
Test set avg_accuracy=57.24% avg_sensitivity=76.49%, avg_specificity=50.07% avg_auc=71.96%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.448702 Test loss=0.608481 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.43985193967819214
[5/24] Train loss=0.4474967420101166
[10/24] Train loss=0.46154043078422546
[15/24] Train loss=0.417982816696167
[20/24] Train loss=0.42661720514297485
Test set avg_accuracy=62.07% avg_sensitivity=68.71%, avg_specificity=59.60% avg_auc=73.10%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.450383 Test loss=0.591868 Current lr=[0.000156543481933168]

[0/24] Train loss=0.44528743624687195
[5/24] Train loss=0.4553985893726349
[10/24] Train loss=0.46707311272621155
[15/24] Train loss=0.4185206890106201
[20/24] Train loss=0.4283061623573303
Test set avg_accuracy=64.43% avg_sensitivity=64.54%, avg_specificity=64.39% avg_auc=73.04%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.451557 Test loss=0.589262 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.4377697706222534
[5/24] Train loss=0.4425964951515198
[10/24] Train loss=0.4559461176395416
[15/24] Train loss=0.4156349301338196
[20/24] Train loss=0.4273199439048767
Test set avg_accuracy=64.92% avg_sensitivity=67.37%, avg_specificity=64.01% avg_auc=74.90%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.446963 Test loss=0.575666 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.44358694553375244
[5/24] Train loss=0.4493459165096283
[10/24] Train loss=0.46681538224220276
[15/24] Train loss=0.42792627215385437
[20/24] Train loss=0.4300849139690399
Test set avg_accuracy=67.21% avg_sensitivity=59.02%, avg_specificity=70.26% avg_auc=73.41%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.452255 Test loss=0.576254 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.4380997121334076
[5/24] Train loss=0.44802215695381165
[10/24] Train loss=0.4629743695259094
[15/24] Train loss=0.4217469394207001
[20/24] Train loss=0.4283856153488159
Test set avg_accuracy=58.23% avg_sensitivity=75.14%, avg_specificity=51.93% avg_auc=69.72%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.449024 Test loss=0.614868 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.4363471567630768
[5/24] Train loss=0.4447607100009918
[10/24] Train loss=0.4585633873939514
[15/24] Train loss=0.4162592887878418
[20/24] Train loss=0.43047910928726196
Test set avg_accuracy=69.69% avg_sensitivity=45.63%, avg_specificity=78.65% avg_auc=76.97%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.450336 Test loss=0.546658 Current lr=[0.000134135431043539]

[0/24] Train loss=0.44687265157699585
[5/24] Train loss=0.4528885781764984
[10/24] Train loss=0.46892791986465454
[15/24] Train loss=0.42784830927848816
[20/24] Train loss=0.4332975149154663
Test set avg_accuracy=68.88% avg_sensitivity=40.64%, avg_specificity=79.40% avg_auc=73.46%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.453672 Test loss=0.569089 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.44138631224632263
[5/24] Train loss=0.4487016797065735
[10/24] Train loss=0.46400824189186096
[15/24] Train loss=0.4225294589996338
[20/24] Train loss=0.42790523171424866
Test set avg_accuracy=63.09% avg_sensitivity=64.88%, avg_specificity=62.42% avg_auc=71.50%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.447577 Test loss=0.593945 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.4322407841682434
[5/24] Train loss=0.4430549740791321
[10/24] Train loss=0.45553600788116455
[15/24] Train loss=0.4129292368888855
[20/24] Train loss=0.42586588859558105
Test set avg_accuracy=63.31% avg_sensitivity=64.20%, avg_specificity=62.97% avg_auc=72.97%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.444848 Test loss=0.584175 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.44329601526260376
[5/24] Train loss=0.4418103098869324
[10/24] Train loss=0.46142715215682983
[15/24] Train loss=0.4157405495643616
[20/24] Train loss=0.426209032535553
Test set avg_accuracy=66.48% avg_sensitivity=60.12%, avg_specificity=68.85% avg_auc=72.25%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.447276 Test loss=0.584622 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.439433753490448
[5/24] Train loss=0.44556930661201477
[10/24] Train loss=0.45811858773231506
[15/24] Train loss=0.42966723442077637
[20/24] Train loss=0.430536150932312
Test set avg_accuracy=67.97% avg_sensitivity=57.01%, avg_specificity=72.05% avg_auc=73.03%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.447936 Test loss=0.571488 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.4355252981185913
[5/24] Train loss=0.44581472873687744
[10/24] Train loss=0.4594746530056
[15/24] Train loss=0.41421687602996826
[20/24] Train loss=0.42717182636260986
Test set avg_accuracy=63.11% avg_sensitivity=66.60%, avg_specificity=61.81% avg_auc=70.91%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.445500 Test loss=0.596151 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.434221476316452
[5/24] Train loss=0.44806766510009766
[10/24] Train loss=0.4584789574146271
[15/24] Train loss=0.43455901741981506
[20/24] Train loss=0.42740607261657715
Test set avg_accuracy=65.48% avg_sensitivity=60.70%, avg_specificity=67.26% avg_auc=72.03%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.446717 Test loss=0.584668 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.4360678493976593
[5/24] Train loss=0.44667848944664
[10/24] Train loss=0.45507916808128357
[15/24] Train loss=0.4152396619319916
[20/24] Train loss=0.42501300573349
Test set avg_accuracy=58.67% avg_sensitivity=74.33%, avg_specificity=52.84% avg_auc=70.51%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.445941 Test loss=0.610207 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.4379684627056122
[5/24] Train loss=0.44117751717567444
[10/24] Train loss=0.4532724618911743
[15/24] Train loss=0.41802752017974854
[20/24] Train loss=0.4246227443218231
Test set avg_accuracy=61.35% avg_sensitivity=71.45%, avg_specificity=57.59% avg_auc=71.46%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.444619 Test loss=0.598924 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.43542608618736267
[5/24] Train loss=0.4405295252799988
[10/24] Train loss=0.45101696252822876
[15/24] Train loss=0.4149744510650635
[20/24] Train loss=0.42541155219078064
Test set avg_accuracy=57.30% avg_sensitivity=80.71%, avg_specificity=48.59% avg_auc=69.69%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.441460 Test loss=0.620670 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.429490327835083
[5/24] Train loss=0.44048047065734863
[10/24] Train loss=0.4504990577697754
[15/24] Train loss=0.4129219949245453
[20/24] Train loss=0.4247156083583832
Test set avg_accuracy=60.30% avg_sensitivity=75.10%, avg_specificity=54.79% avg_auc=70.56%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.441048 Test loss=0.608627 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.42813944816589355
[5/24] Train loss=0.4376603662967682
[10/24] Train loss=0.45021578669548035
[15/24] Train loss=0.41055524349212646
[20/24] Train loss=0.42409053444862366
Test set avg_accuracy=59.02% avg_sensitivity=77.69%, avg_specificity=52.07% avg_auc=70.09%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.439339 Test loss=0.613522 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.4287189841270447
[5/24] Train loss=0.4393070340156555
[10/24] Train loss=0.45133498311042786
[15/24] Train loss=0.4100586175918579
[20/24] Train loss=0.4237995445728302
Test set avg_accuracy=59.90% avg_sensitivity=74.57%, avg_specificity=54.43% avg_auc=70.43%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.439070 Test loss=0.607193 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.42800021171569824
[5/24] Train loss=0.443280428647995
[10/24] Train loss=0.4515770971775055
[15/24] Train loss=0.41418617963790894
[20/24] Train loss=0.42420944571495056
Test set avg_accuracy=60.56% avg_sensitivity=72.55%, avg_specificity=56.09% avg_auc=71.62%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.441812 Test loss=0.599333 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.4309096038341522
[5/24] Train loss=0.4379729926586151
[10/24] Train loss=0.45204514265060425
[15/24] Train loss=0.41022077202796936
[20/24] Train loss=0.4234353303909302
Test set avg_accuracy=58.78% avg_sensitivity=74.57%, avg_specificity=52.89% avg_auc=70.17%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.440353 Test loss=0.610102 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.43142327666282654
[5/24] Train loss=0.43894484639167786
[10/24] Train loss=0.45136532187461853
[15/24] Train loss=0.4124394655227661
[20/24] Train loss=0.42282265424728394
Test set avg_accuracy=60.47% avg_sensitivity=74.14%, avg_specificity=55.38% avg_auc=70.64%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.439042 Test loss=0.603940 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.42863425612449646
[5/24] Train loss=0.44083061814308167
[10/24] Train loss=0.45284420251846313
[15/24] Train loss=0.4111112356185913
[20/24] Train loss=0.4234991669654846
Test set avg_accuracy=59.88% avg_sensitivity=77.02%, avg_specificity=53.50% avg_auc=70.49%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.439360 Test loss=0.609037 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.42942073941230774
[5/24] Train loss=0.4375399351119995
[10/24] Train loss=0.4486325681209564
[15/24] Train loss=0.40975940227508545
[20/24] Train loss=0.4223785698413849
Test set avg_accuracy=59.28% avg_sensitivity=78.21%, avg_specificity=52.23% avg_auc=70.27%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.438456 Test loss=0.610793 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.42748627066612244
[5/24] Train loss=0.4458019435405731
[10/24] Train loss=0.4523199200630188
[15/24] Train loss=0.40954717993736267
[20/24] Train loss=0.42315319180488586
Test set avg_accuracy=61.20% avg_sensitivity=75.00%, avg_specificity=56.06% avg_auc=70.84%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.439642 Test loss=0.603069 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.42775073647499084
[5/24] Train loss=0.44120630621910095
[10/24] Train loss=0.4496382176876068
[15/24] Train loss=0.40920788049697876
[20/24] Train loss=0.4223743677139282
Test set avg_accuracy=58.46% avg_sensitivity=78.74%, avg_specificity=50.91% avg_auc=69.75%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.438548 Test loss=0.613893 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.42722761631011963
[5/24] Train loss=0.43811824917793274
[10/24] Train loss=0.4505901336669922
[15/24] Train loss=0.4110318720340729
[20/24] Train loss=0.4207912087440491
Test set avg_accuracy=57.96% avg_sensitivity=79.22%, avg_specificity=50.04% avg_auc=70.40%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.439968 Test loss=0.616946 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.42759573459625244
[5/24] Train loss=0.43876752257347107
[10/24] Train loss=0.4498912990093231
[15/24] Train loss=0.4099205732345581
[20/24] Train loss=0.42378440499305725
Test set avg_accuracy=60.86% avg_sensitivity=75.24%, avg_specificity=55.50% avg_auc=70.24%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.438745 Test loss=0.606411 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.4264355003833771
[5/24] Train loss=0.4393966495990753
[10/24] Train loss=0.44986769556999207
[15/24] Train loss=0.40845590829849243
[20/24] Train loss=0.42304906249046326
Test set avg_accuracy=56.51% avg_sensitivity=80.33%, avg_specificity=47.64% avg_auc=69.58%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.437366 Test loss=0.618869 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.42438796162605286
[5/24] Train loss=0.4383319318294525
[10/24] Train loss=0.44754210114479065
[15/24] Train loss=0.408063679933548
[20/24] Train loss=0.4236793518066406
Test set avg_accuracy=56.22% avg_sensitivity=80.85%, avg_specificity=47.05% avg_auc=68.89%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.436867 Test loss=0.623535 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.42637568712234497
[5/24] Train loss=0.4376813471317291
[10/24] Train loss=0.44915714859962463
[15/24] Train loss=0.40877875685691833
[20/24] Train loss=0.42337262630462646
Test set avg_accuracy=57.57% avg_sensitivity=79.75%, avg_specificity=49.30% avg_auc=69.91%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.437086 Test loss=0.615217 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.42912131547927856
[5/24] Train loss=0.4375128746032715
[10/24] Train loss=0.45137616991996765
[15/24] Train loss=0.4077012538909912
[20/24] Train loss=0.4211602210998535
Test set avg_accuracy=57.57% avg_sensitivity=79.03%, avg_specificity=49.57% avg_auc=69.21%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.436676 Test loss=0.620272 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.427074134349823
[5/24] Train loss=0.4381456673145294
[10/24] Train loss=0.44823771715164185
[15/24] Train loss=0.40728959441185
[20/24] Train loss=0.42175185680389404
Test set avg_accuracy=56.15% avg_sensitivity=81.48%, avg_specificity=46.71% avg_auc=69.35%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.436180 Test loss=0.623723 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.4259217381477356
[5/24] Train loss=0.4366167187690735
[10/24] Train loss=0.4493619501590729
[15/24] Train loss=0.40707504749298096
[20/24] Train loss=0.4234047532081604
Test set avg_accuracy=56.58% avg_sensitivity=80.28%, avg_specificity=47.75% avg_auc=69.24%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.436226 Test loss=0.620829 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.4255233705043793
[5/24] Train loss=0.44030484557151794
[10/24] Train loss=0.44907882809638977
[15/24] Train loss=0.40756794810295105
[20/24] Train loss=0.42317506670951843
Test set avg_accuracy=55.53% avg_sensitivity=81.86%, avg_specificity=45.73% avg_auc=68.72%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.436413 Test loss=0.628268 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.42618846893310547
[5/24] Train loss=0.4383431375026703
[10/24] Train loss=0.44909796118736267
[15/24] Train loss=0.4076121151447296
[20/24] Train loss=0.42424121499061584
Test set avg_accuracy=55.79% avg_sensitivity=81.67%, avg_specificity=46.16% avg_auc=69.20%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.436928 Test loss=0.625050 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.4266662895679474
[5/24] Train loss=0.43907785415649414
[10/24] Train loss=0.4514783024787903
[15/24] Train loss=0.40685534477233887
[20/24] Train loss=0.4238441288471222
Test set avg_accuracy=54.86% avg_sensitivity=81.48%, avg_specificity=44.94% avg_auc=68.99%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.437011 Test loss=0.627092 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.4269774854183197
[5/24] Train loss=0.4363713562488556
[10/24] Train loss=0.4490935206413269
[15/24] Train loss=0.40642693638801575
[20/24] Train loss=0.42263633012771606
Test set avg_accuracy=57.04% avg_sensitivity=79.99%, avg_specificity=48.50% avg_auc=69.48%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.435881 Test loss=0.619264 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.4257851541042328
[5/24] Train loss=0.4369415044784546
[10/24] Train loss=0.44821855425834656
[15/24] Train loss=0.4051709771156311
[20/24] Train loss=0.4205057919025421
Test set avg_accuracy=55.34% avg_sensitivity=81.67%, avg_specificity=45.53% avg_auc=68.95%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.434593 Test loss=0.626461 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.4231945872306824
[5/24] Train loss=0.4359971582889557
[10/24] Train loss=0.4481199383735657
[15/24] Train loss=0.4050785005092621
[20/24] Train loss=0.4210491478443146
Test set avg_accuracy=54.40% avg_sensitivity=82.25%, avg_specificity=44.03% avg_auc=68.56%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.433729 Test loss=0.630157 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.42358464002609253
[5/24] Train loss=0.4359915554523468
[10/24] Train loss=0.44789138436317444
[15/24] Train loss=0.4047945439815521
[20/24] Train loss=0.42148780822753906
Test set avg_accuracy=54.06% avg_sensitivity=82.53%, avg_specificity=43.46% avg_auc=68.41%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.433598 Test loss=0.632535 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.42356592416763306
[5/24] Train loss=0.4359709322452545
[10/24] Train loss=0.44802120327949524
[15/24] Train loss=0.4047391414642334
[20/24] Train loss=0.4209051728248596
Test set avg_accuracy=54.28% avg_sensitivity=82.53%, avg_specificity=43.76% avg_auc=68.51%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.433435 Test loss=0.631638 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.42331549525260925
[5/24] Train loss=0.43589717149734497
[10/24] Train loss=0.447436660528183
[15/24] Train loss=0.40461966395378113
[20/24] Train loss=0.4204899072647095
Test set avg_accuracy=54.30% avg_sensitivity=82.53%, avg_specificity=43.78% avg_auc=68.53%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.433207 Test loss=0.631288 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.4229690134525299
[5/24] Train loss=0.4356825649738312
[10/24] Train loss=0.44723787903785706
[15/24] Train loss=0.40450936555862427
[20/24] Train loss=0.42062148451805115
Test set avg_accuracy=54.28% avg_sensitivity=82.53%, avg_specificity=43.76% avg_auc=68.49%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.433020 Test loss=0.631645 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.42302268743515015
[5/24] Train loss=0.43557626008987427
[10/24] Train loss=0.4472711682319641
[15/24] Train loss=0.4044020175933838
[20/24] Train loss=0.4206049144268036
Test set avg_accuracy=54.06% avg_sensitivity=82.53%, avg_specificity=43.46% avg_auc=68.51%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.432938 Test loss=0.631805 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.4229644238948822
[5/24] Train loss=0.435547798871994
[10/24] Train loss=0.44717058539390564
[15/24] Train loss=0.4043032228946686
[20/24] Train loss=0.4205724895000458
Test set avg_accuracy=54.04% avg_sensitivity=82.53%, avg_specificity=43.42% avg_auc=68.51%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.432844 Test loss=0.632007 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.4228188395500183
[5/24] Train loss=0.4354798495769501
[10/24] Train loss=0.44717180728912354
[15/24] Train loss=0.40425753593444824
[20/24] Train loss=0.4205535054206848
Test set avg_accuracy=54.04% avg_sensitivity=82.53%, avg_specificity=43.42% avg_auc=68.51%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.432771 Test loss=0.631972 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.42281317710876465
[5/24] Train loss=0.43542101979255676
[10/24] Train loss=0.44711142778396606
[15/24] Train loss=0.404208779335022
[20/24] Train loss=0.42051079869270325
Test set avg_accuracy=54.02% avg_sensitivity=82.53%, avg_specificity=43.41% avg_auc=68.52%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.432718 Test loss=0.632037 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.42275023460388184
[5/24] Train loss=0.43534377217292786
[10/24] Train loss=0.44709843397140503
[15/24] Train loss=0.4041820168495178
[20/24] Train loss=0.42048901319503784
Test set avg_accuracy=54.02% avg_sensitivity=82.53%, avg_specificity=43.41% avg_auc=68.52%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.432673 Test loss=0.632052 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.4227335751056671
[5/24] Train loss=0.4353114068508148
[10/24] Train loss=0.4470721185207367
[15/24] Train loss=0.4041644036769867
[20/24] Train loss=0.4204614460468292
Test set avg_accuracy=54.02% avg_sensitivity=82.53%, avg_specificity=43.41% avg_auc=68.52%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.432640 Test loss=0.632049 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.4227043390274048
[5/24] Train loss=0.4352800250053406
[10/24] Train loss=0.44706109166145325
[15/24] Train loss=0.40414807200431824
[20/24] Train loss=0.42043718695640564
Test set avg_accuracy=54.02% avg_sensitivity=82.53%, avg_specificity=43.41% avg_auc=68.53%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.432616 Test loss=0.632022 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.4226834177970886
[5/24] Train loss=0.43525463342666626
[10/24] Train loss=0.4470508098602295
[15/24] Train loss=0.4041379690170288
[20/24] Train loss=0.4204230308532715
Test set avg_accuracy=54.02% avg_sensitivity=82.53%, avg_specificity=43.41% avg_auc=68.53%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.432600 Test loss=0.632012 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.42267221212387085
[5/24] Train loss=0.43523719906806946
[10/24] Train loss=0.44704267382621765
[15/24] Train loss=0.4041324853897095
[20/24] Train loss=0.4204137325286865
Test set avg_accuracy=54.02% avg_sensitivity=82.53%, avg_specificity=43.41% avg_auc=68.53%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.432590 Test loss=0.632006 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.42266446352005005
[5/24] Train loss=0.43522632122039795
[10/24] Train loss=0.44703811407089233
[15/24] Train loss=0.4041299521923065
[20/24] Train loss=0.42040878534317017
Test set avg_accuracy=54.02% avg_sensitivity=82.53%, avg_specificity=43.41% avg_auc=68.53%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.432584 Test loss=0.632000 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.4226604700088501
[5/24] Train loss=0.4352208077907562
[10/24] Train loss=0.4470359683036804
[15/24] Train loss=0.4041292667388916
[20/24] Train loss=0.4204070568084717
Test set avg_accuracy=54.02% avg_sensitivity=82.53%, avg_specificity=43.41% avg_auc=68.54%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.432582 Test loss=0.631996 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=76.68% sen=43.43%, spe=89.06%, auc=79.11%!
Fold[6] Avg_overlap=0.27%(0.3073788268519329)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 1,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'SwEDModel',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.7018166184425354
[5/24] Train loss=0.7017323970794678
[10/24] Train loss=0.6985541582107544
[15/24] Train loss=0.6987565159797668
[20/24] Train loss=0.6983160376548767
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.66%
Best model saved!! Metric=-102.95701971774494!!
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.699448 Test loss=0.696765 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6971127986907959
[5/24] Train loss=0.6968730688095093
[10/24] Train loss=0.6942129135131836
[15/24] Train loss=0.6937425136566162
[20/24] Train loss=0.693562924861908
Test set avg_accuracy=70.09% avg_sensitivity=12.35%, avg_specificity=92.12% avg_auc=50.81%
Best model saved!! Metric=-100.62346208571161!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.694817 Test loss=0.692569 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6926715970039368
[5/24] Train loss=0.6923133134841919
[10/24] Train loss=0.6902883052825928
[15/24] Train loss=0.6893450021743774
[20/24] Train loss=0.6894831657409668
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.93%
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.690628 Test loss=0.688886 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6887454986572266
[5/24] Train loss=0.6876310110092163
[10/24] Train loss=0.6863723397254944
[15/24] Train loss=0.684917151927948
[20/24] Train loss=0.6854446530342102
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.91%
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.686507 Test loss=0.685312 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.684903621673584
[5/24] Train loss=0.6832045316696167
[10/24] Train loss=0.6824383735656738
[15/24] Train loss=0.6803925037384033
[20/24] Train loss=0.6809963583946228
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.85%
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.682305 Test loss=0.681144 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6802414655685425
[5/24] Train loss=0.6776946187019348
[10/24] Train loss=0.6774181723594666
[15/24] Train loss=0.6746559739112854
[20/24] Train loss=0.6753435730934143
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.81%
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.677064 Test loss=0.676229 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6747076511383057
[5/24] Train loss=0.6713255643844604
[10/24] Train loss=0.6713812947273254
[15/24] Train loss=0.6677086353302002
[20/24] Train loss=0.6684144139289856
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.78%
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.670712 Test loss=0.669899 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6677476167678833
[5/24] Train loss=0.6628543138504028
[10/24] Train loss=0.6635785102844238
[15/24] Train loss=0.6585262417793274
[20/24] Train loss=0.6589654684066772
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.81%
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.662421 Test loss=0.661441 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6585017442703247
[5/24] Train loss=0.6511518955230713
[10/24] Train loss=0.6525144577026367
[15/24] Train loss=0.6449721455574036
[20/24] Train loss=0.6451369524002075
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.95%
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.650612 Test loss=0.649072 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.644935131072998
[5/24] Train loss=0.6336089372634888
[10/24] Train loss=0.6361986994743347
[15/24] Train loss=0.6247933506965637
[20/24] Train loss=0.6249328851699829
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.27%
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.633122 Test loss=0.631602 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6254834532737732
[5/24] Train loss=0.608225405216217
[10/24] Train loss=0.6135613918304443
[15/24] Train loss=0.5971959829330444
[20/24] Train loss=0.599277138710022
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.64%
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.609052 Test loss=0.610904 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6013137102127075
[5/24] Train loss=0.5754887461662292
[10/24] Train loss=0.5886397361755371
[15/24] Train loss=0.5690514445304871
[20/24] Train loss=0.5782654285430908
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.51%
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.583307 Test loss=0.595019 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5839508175849915
[5/24] Train loss=0.5470495223999023
[10/24] Train loss=0.5745181441307068
[15/24] Train loss=0.5538129210472107
[20/24] Train loss=0.5683030486106873
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.44%
Best model saved!! Metric=-99.18039658476633!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.568163 Test loss=0.587489 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5776651501655579
[5/24] Train loss=0.5381148457527161
[10/24] Train loss=0.5693514943122864
[15/24] Train loss=0.5475380420684814
[20/24] Train loss=0.5619254112243652
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=57.07%
Best model saved!! Metric=-96.54691336133797!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.562179 Test loss=0.584094 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5753980278968811
[5/24] Train loss=0.5318238735198975
[10/24] Train loss=0.5675981044769287
[15/24] Train loss=0.5429083704948425
[20/24] Train loss=0.5580363869667053
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=59.22%
Best model saved!! Metric=-94.40186422532422!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.559156 Test loss=0.582458 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5736725926399231
[5/24] Train loss=0.5268592238426208
[10/24] Train loss=0.5667166113853455
[15/24] Train loss=0.5384501814842224
[20/24] Train loss=0.5517339110374451
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=61.07%
Best model saved!! Metric=-92.54885608895434!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.556695 Test loss=0.580090 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5720422267913818
[5/24] Train loss=0.5223831534385681
[10/24] Train loss=0.5648898482322693
[15/24] Train loss=0.5333451628684998
[20/24] Train loss=0.545035719871521
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=63.73%
Best model saved!! Metric=-89.88641769184966!!
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.553157 Test loss=0.577140 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5660412907600403
[5/24] Train loss=0.5185584425926208
[10/24] Train loss=0.5600971579551697
[15/24] Train loss=0.5252473950386047
[20/24] Train loss=0.5320703983306885
Test set avg_accuracy=72.32% avg_sensitivity=0.00%, avg_specificity=99.91% avg_auc=68.22%
Best model saved!! Metric=-85.55683637963772!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.546564 Test loss=0.569877 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5592026114463806
[5/24] Train loss=0.5065538883209229
[10/24] Train loss=0.5500348806381226
[15/24] Train loss=0.5071190595626831
[20/24] Train loss=0.5148834586143494
Test set avg_accuracy=72.93% avg_sensitivity=5.75%, avg_specificity=98.56% avg_auc=70.31%
Best model saved!! Metric=-78.45241011150351!!
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.534502 Test loss=0.574558 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5508696436882019
[5/24] Train loss=0.497840017080307
[10/24] Train loss=0.5355322957038879
[15/24] Train loss=0.48166924715042114
[20/24] Train loss=0.49761202931404114
Test set avg_accuracy=66.30% avg_sensitivity=49.17%, avg_specificity=72.84% avg_auc=68.04%
Best model saved!! Metric=-69.64716962912271!!
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.520476 Test loss=0.626898 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5452011227607727
[5/24] Train loss=0.5055766701698303
[10/24] Train loss=0.5238310098648071
[15/24] Train loss=0.4677243232727051
[20/24] Train loss=0.4815163016319275
Test set avg_accuracy=35.53% avg_sensitivity=93.54%, avg_specificity=13.40% avg_auc=61.24%
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.510685 Test loss=0.661672 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5290035605430603
[5/24] Train loss=0.4869135916233063
[10/24] Train loss=0.5085241198539734
[15/24] Train loss=0.4558502435684204
[20/24] Train loss=0.4722895324230194
Test set avg_accuracy=31.35% avg_sensitivity=95.10%, avg_specificity=7.03% avg_auc=59.19%
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.500690 Test loss=0.666681 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5227821469306946
[5/24] Train loss=0.4772232174873352
[10/24] Train loss=0.5028570890426636
[15/24] Train loss=0.4509563744068146
[20/24] Train loss=0.4636974036693573
Test set avg_accuracy=41.32% avg_sensitivity=75.29%, avg_specificity=28.35% avg_auc=59.45%
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.494754 Test loss=0.660766 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.49638938903808594
[5/24] Train loss=0.4865550100803375
[10/24] Train loss=0.49323174357414246
[15/24] Train loss=0.44524821639060974
[20/24] Train loss=0.45861583948135376
Test set avg_accuracy=41.63% avg_sensitivity=73.69%, avg_specificity=29.39% avg_auc=61.23%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.485248 Test loss=0.657709 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.4912414252758026
[5/24] Train loss=0.46816325187683105
[10/24] Train loss=0.483720988035202
[15/24] Train loss=0.44077107310295105
[20/24] Train loss=0.44635245203971863
Test set avg_accuracy=57.53% avg_sensitivity=51.82%, avg_specificity=59.70% avg_auc=63.39%
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.479375 Test loss=0.634959 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.4764890670776367
[5/24] Train loss=0.4587271809577942
[10/24] Train loss=0.4803220331668854
[15/24] Train loss=0.428404837846756
[20/24] Train loss=0.44064199924468994
Test set avg_accuracy=49.38% avg_sensitivity=84.25%, avg_specificity=36.07% avg_auc=63.00%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.472037 Test loss=0.649611 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.4820728600025177
[5/24] Train loss=0.44997453689575195
[10/24] Train loss=0.4665814936161041
[15/24] Train loss=0.42435964941978455
[20/24] Train loss=0.4341657757759094
Test set avg_accuracy=54.31% avg_sensitivity=83.22%, avg_specificity=43.28% avg_auc=63.41%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.464086 Test loss=0.637673 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.47410154342651367
[5/24] Train loss=0.440896213054657
[10/24] Train loss=0.4610920250415802
[15/24] Train loss=0.41369739174842834
[20/24] Train loss=0.43022018671035767
Test set avg_accuracy=53.11% avg_sensitivity=86.61%, avg_specificity=40.33% avg_auc=66.31%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.456801 Test loss=0.635969 Current lr=[0.000210185142098938]

[0/24] Train loss=0.46721383929252625
[5/24] Train loss=0.43647506833076477
[10/24] Train loss=0.4538777768611908
[15/24] Train loss=0.39644575119018555
[20/24] Train loss=0.3927285671234131
Test set avg_accuracy=57.30% avg_sensitivity=85.62%, avg_specificity=46.50% avg_auc=64.20%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.441769 Test loss=0.650739 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.4411099851131439
[5/24] Train loss=0.40879422426223755
[10/24] Train loss=0.436068594455719
[15/24] Train loss=0.3921504020690918
[20/24] Train loss=0.3794141411781311
Test set avg_accuracy=55.12% avg_sensitivity=84.25%, avg_specificity=44.00% avg_auc=63.35%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.424259 Test loss=0.688171 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.41258853673934937
[5/24] Train loss=0.4120270907878876
[10/24] Train loss=0.4225979745388031
[15/24] Train loss=0.3746057152748108
[20/24] Train loss=0.37625718116760254
Test set avg_accuracy=73.02% avg_sensitivity=68.08%, avg_specificity=74.91% avg_auc=65.16%
Best model saved!! Metric=-44.83084663074665!!
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.414825 Test loss=0.658697 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.41287538409233093
[5/24] Train loss=0.39779379963874817
[10/24] Train loss=0.42942965030670166
[15/24] Train loss=0.37835201621055603
[20/24] Train loss=0.37107053399086
Test set avg_accuracy=77.46% avg_sensitivity=41.35%, avg_specificity=91.24% avg_auc=69.64%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.412742 Test loss=0.572485 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.41295126080513
[5/24] Train loss=0.39850446581840515
[10/24] Train loss=0.4174273908138275
[15/24] Train loss=0.3705523610115051
[20/24] Train loss=0.3454643785953522
Test set avg_accuracy=68.68% avg_sensitivity=78.74%, avg_specificity=64.85% avg_auc=69.92%
Best model saved!! Metric=-43.8130836230812!!
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.407706 Test loss=0.624032 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3910263776779175
[5/24] Train loss=0.39708277583122253
[10/24] Train loss=0.42333096265792847
[15/24] Train loss=0.3782607316970825
[20/24] Train loss=0.3559713661670685
Test set avg_accuracy=76.64% avg_sensitivity=62.05%, avg_specificity=82.21% avg_auc=67.35%
Best model saved!! Metric=-37.75179376542909!!
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.405582 Test loss=0.623927 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.4079781174659729
[5/24] Train loss=0.3962482213973999
[10/24] Train loss=0.4054092764854431
[15/24] Train loss=0.3683728873729706
[20/24] Train loss=0.3509604334831238
Test set avg_accuracy=59.06% avg_sensitivity=86.61%, avg_specificity=48.55% avg_auc=70.64%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.405298 Test loss=0.635066 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.40157079696655273
[5/24] Train loss=0.39348968863487244
[10/24] Train loss=0.4152616858482361
[15/24] Train loss=0.3714371919631958
[20/24] Train loss=0.34685224294662476
Test set avg_accuracy=64.64% avg_sensitivity=81.94%, avg_specificity=58.03% avg_auc=75.81%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.406762 Test loss=0.590801 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.39957863092422485
[5/24] Train loss=0.40565308928489685
[10/24] Train loss=0.3996293544769287
[15/24] Train loss=0.3718360960483551
[20/24] Train loss=0.3553183376789093
Test set avg_accuracy=60.85% avg_sensitivity=84.82%, avg_specificity=51.70% avg_auc=72.61%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.399001 Test loss=0.619991 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.39663901925086975
[5/24] Train loss=0.3822766840457916
[10/24] Train loss=0.3934643566608429
[15/24] Train loss=0.3683702051639557
[20/24] Train loss=0.35034799575805664
Test set avg_accuracy=55.95% avg_sensitivity=90.10%, avg_specificity=42.92% avg_auc=72.00%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.393865 Test loss=0.649902 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4024500250816345
[5/24] Train loss=0.38560977578163147
[10/24] Train loss=0.39272424578666687
[15/24] Train loss=0.367682546377182
[20/24] Train loss=0.33592334389686584
Test set avg_accuracy=63.71% avg_sensitivity=83.12%, avg_specificity=56.31% avg_auc=74.23%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.392483 Test loss=0.605104 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3889784812927246
[5/24] Train loss=0.3788261115550995
[10/24] Train loss=0.39358046650886536
[15/24] Train loss=0.3668697774410248
[20/24] Train loss=0.35043877363204956
Test set avg_accuracy=51.58% avg_sensitivity=94.01%, avg_specificity=35.38% avg_auc=72.77%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.391597 Test loss=0.667629 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4031903147697449
[5/24] Train loss=0.39603012800216675
[10/24] Train loss=0.39328402280807495
[15/24] Train loss=0.3745787441730499
[20/24] Train loss=0.3440631330013275
Test set avg_accuracy=65.18% avg_sensitivity=81.61%, avg_specificity=58.91% avg_auc=72.85%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.395035 Test loss=0.602630 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.38311418890953064
[5/24] Train loss=0.381094366312027
[10/24] Train loss=0.4074746072292328
[15/24] Train loss=0.3629951775074005
[20/24] Train loss=0.34472042322158813
Test set avg_accuracy=64.21% avg_sensitivity=81.85%, avg_specificity=57.47% avg_auc=75.03%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.391986 Test loss=0.594935 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3794421851634979
[5/24] Train loss=0.37958842515945435
[10/24] Train loss=0.41173404455184937
[15/24] Train loss=0.3632730543613434
[20/24] Train loss=0.3382002115249634
Test set avg_accuracy=71.59% avg_sensitivity=68.93%, avg_specificity=72.60% avg_auc=76.67%
Best model saved!! Metric=-36.20818707721229!!
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.388376 Test loss=0.554453 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.38080987334251404
[5/24] Train loss=0.3808603584766388
[10/24] Train loss=0.3886110484600067
[15/24] Train loss=0.355020672082901
[20/24] Train loss=0.33484211564064026
Test set avg_accuracy=64.78% avg_sensitivity=82.84%, avg_specificity=57.89% avg_auc=75.23%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.386075 Test loss=0.594767 Current lr=[0.00029967723776099]

[0/24] Train loss=0.38452690839767456
[5/24] Train loss=0.38546717166900635
[10/24] Train loss=0.40756845474243164
[15/24] Train loss=0.36141636967658997
[20/24] Train loss=0.3333791196346283
Test set avg_accuracy=67.01% avg_sensitivity=81.38%, avg_specificity=61.52% avg_auc=77.53%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.393112 Test loss=0.583710 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.37650859355926514
[5/24] Train loss=0.39154231548309326
[10/24] Train loss=0.3896651268005371
[15/24] Train loss=0.3579498529434204
[20/24] Train loss=0.33290544152259827
Test set avg_accuracy=69.57% avg_sensitivity=79.82%, avg_specificity=65.66% avg_auc=77.70%
Best model saved!! Metric=-33.247038111786196!!
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.385158 Test loss=0.568474 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.37528082728385925
[5/24] Train loss=0.37151485681533813
[10/24] Train loss=0.38272666931152344
[15/24] Train loss=0.35307201743125916
[20/24] Train loss=0.3250638246536255
Test set avg_accuracy=63.87% avg_sensitivity=84.35%, avg_specificity=56.05% avg_auc=74.36%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.378859 Test loss=0.601456 Current lr=[0.000299720220882401]

[0/24] Train loss=0.388091117143631
[5/24] Train loss=0.36951708793640137
[10/24] Train loss=0.37717515230178833
[15/24] Train loss=0.3658693730831146
[20/24] Train loss=0.34996938705444336
Test set avg_accuracy=65.00% avg_sensitivity=84.68%, avg_specificity=57.49% avg_auc=76.27%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.384626 Test loss=0.596321 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.40848737955093384
[5/24] Train loss=0.3877907991409302
[10/24] Train loss=0.3919864892959595
[15/24] Train loss=0.3626624047756195
[20/24] Train loss=0.3359030485153198
Test set avg_accuracy=75.18% avg_sensitivity=65.30%, avg_specificity=78.95% avg_auc=77.34%
Best model saved!! Metric=-29.22512543769892!!
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.390549 Test loss=0.545651 Current lr=[0.000298904600941902]

[0/24] Train loss=0.38113585114479065
[5/24] Train loss=0.3777936100959778
[10/24] Train loss=0.3826051950454712
[15/24] Train loss=0.3506590723991394
[20/24] Train loss=0.3327745497226715
Test set avg_accuracy=64.92% avg_sensitivity=83.26%, avg_specificity=57.92% avg_auc=76.60%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.382458 Test loss=0.588653 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3766195476055145
[5/24] Train loss=0.3712324798107147
[10/24] Train loss=0.3819431960582733
[15/24] Train loss=0.34868693351745605
[20/24] Train loss=0.34327560663223267
Test set avg_accuracy=63.87% avg_sensitivity=85.95%, avg_specificity=55.44% avg_auc=78.01%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.381882 Test loss=0.592831 Current lr=[0.000297555943323901]

[0/24] Train loss=0.37616077065467834
[5/24] Train loss=0.3675454556941986
[10/24] Train loss=0.38083696365356445
[15/24] Train loss=0.4022819995880127
[20/24] Train loss=0.35085830092430115
Test set avg_accuracy=80.00% avg_sensitivity=42.90%, avg_specificity=94.15% avg_auc=82.57%
Best model saved!! Metric=-26.368706055710803!!
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.393395 Test loss=0.488361 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.39995718002319336
[5/24] Train loss=0.3916202187538147
[10/24] Train loss=0.3954443037509918
[15/24] Train loss=0.3586510419845581
[20/24] Train loss=0.3283350169658661
Test set avg_accuracy=80.59% avg_sensitivity=60.91%, avg_specificity=88.09% avg_auc=80.71%
Best model saved!! Metric=-15.69767477919877!!
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.390644 Test loss=0.520943 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.38597604632377625
[5/24] Train loss=0.375539630651474
[10/24] Train loss=0.38571640849113464
[15/24] Train loss=0.35602131485939026
[20/24] Train loss=0.3408623933792114
Test set avg_accuracy=68.45% avg_sensitivity=79.59%, avg_specificity=64.20% avg_auc=76.88%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.385438 Test loss=0.573085 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.38053444027900696
[5/24] Train loss=0.37311527132987976
[10/24] Train loss=0.38384810090065
[15/24] Train loss=0.3667006492614746
[20/24] Train loss=0.3439825177192688
Test set avg_accuracy=71.98% avg_sensitivity=70.20%, avg_specificity=72.66% avg_auc=76.45%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.386752 Test loss=0.556325 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.38057106733322144
[5/24] Train loss=0.38405755162239075
[10/24] Train loss=0.38373565673828125
[15/24] Train loss=0.34980618953704834
[20/24] Train loss=0.33967670798301697
Test set avg_accuracy=63.10% avg_sensitivity=86.33%, avg_specificity=54.24% avg_auc=76.05%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.384796 Test loss=0.599997 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3818608224391937
[5/24] Train loss=0.36753955483436584
[10/24] Train loss=0.3739511966705322
[15/24] Train loss=0.356040894985199
[20/24] Train loss=0.32869774103164673
Test set avg_accuracy=79.96% avg_sensitivity=56.86%, avg_specificity=88.77% avg_auc=81.00%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.378893 Test loss=0.507298 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3805052638053894
[5/24] Train loss=0.37956148386001587
[10/24] Train loss=0.38519060611724854
[15/24] Train loss=0.35707807540893555
[20/24] Train loss=0.33760902285575867
Test set avg_accuracy=67.43% avg_sensitivity=83.03%, avg_specificity=61.49% avg_auc=77.13%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.385351 Test loss=0.583889 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3977569043636322
[5/24] Train loss=0.37334275245666504
[10/24] Train loss=0.3955781161785126
[15/24] Train loss=0.3654175102710724
[20/24] Train loss=0.32326871156692505
Test set avg_accuracy=79.11% avg_sensitivity=62.47%, avg_specificity=85.47% avg_auc=77.98%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.384141 Test loss=0.529847 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3737207055091858
[5/24] Train loss=0.3681459128856659
[10/24] Train loss=0.3804503381252289
[15/24] Train loss=0.34905973076820374
[20/24] Train loss=0.32688215374946594
Test set avg_accuracy=69.38% avg_sensitivity=77.56%, avg_specificity=66.25% avg_auc=77.22%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.376275 Test loss=0.565594 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3860405683517456
[5/24] Train loss=0.3632016181945801
[10/24] Train loss=0.39257121086120605
[15/24] Train loss=0.3608175814151764
[20/24] Train loss=0.33499109745025635
Test set avg_accuracy=67.29% avg_sensitivity=79.82%, avg_specificity=62.51% avg_auc=77.58%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.382542 Test loss=0.572589 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.4057213068008423
[5/24] Train loss=0.39582201838493347
[10/24] Train loss=0.389729380607605
[15/24] Train loss=0.3537129759788513
[20/24] Train loss=0.3263286054134369
Test set avg_accuracy=67.10% avg_sensitivity=80.81%, avg_specificity=61.86% avg_auc=79.03%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.385335 Test loss=0.572014 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.38410818576812744
[5/24] Train loss=0.37628716230392456
[10/24] Train loss=0.37921205163002014
[15/24] Train loss=0.34699228405952454
[20/24] Train loss=0.34177812933921814
Test set avg_accuracy=66.45% avg_sensitivity=84.02%, avg_specificity=59.74% avg_auc=78.10%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.379866 Test loss=0.584452 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.37310120463371277
[5/24] Train loss=0.3649104833602905
[10/24] Train loss=0.3730635643005371
[15/24] Train loss=0.3432815968990326
[20/24] Train loss=0.33258235454559326
Test set avg_accuracy=63.78% avg_sensitivity=85.24%, avg_specificity=55.59% avg_auc=74.75%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.374727 Test loss=0.604716 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3691231608390808
[5/24] Train loss=0.36166805028915405
[10/24] Train loss=0.3678983747959137
[15/24] Train loss=0.34260767698287964
[20/24] Train loss=0.3308022618293762
Test set avg_accuracy=62.94% avg_sensitivity=88.07%, avg_specificity=53.35% avg_auc=77.10%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.371769 Test loss=0.607733 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3711250126361847
[5/24] Train loss=0.3712845742702484
[10/24] Train loss=0.373238205909729
[15/24] Train loss=0.34925317764282227
[20/24] Train loss=0.33026403188705444
Test set avg_accuracy=69.99% avg_sensitivity=79.96%, avg_specificity=66.18% avg_auc=81.45%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.375755 Test loss=0.547354 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3768582046031952
[5/24] Train loss=0.3695121109485626
[10/24] Train loss=0.3808208107948303
[15/24] Train loss=0.360153466463089
[20/24] Train loss=0.3394835293292999
Test set avg_accuracy=65.59% avg_sensitivity=80.62%, avg_specificity=59.85% avg_auc=72.56%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.380643 Test loss=0.609700 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.36612531542778015
[5/24] Train loss=0.3630586564540863
[10/24] Train loss=0.37265366315841675
[15/24] Train loss=0.3451710641384125
[20/24] Train loss=0.32091224193573
Test set avg_accuracy=69.08% avg_sensitivity=80.62%, avg_specificity=64.67% avg_auc=73.71%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.373245 Test loss=0.599367 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.36504772305488586
[5/24] Train loss=0.36539340019226074
[10/24] Train loss=0.3754785656929016
[15/24] Train loss=0.3430732488632202
[20/24] Train loss=0.33234816789627075
Test set avg_accuracy=70.01% avg_sensitivity=79.54%, avg_specificity=66.38% avg_auc=79.46%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.371768 Test loss=0.556338 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.37175416946411133
[5/24] Train loss=0.37012413144111633
[10/24] Train loss=0.37097030878067017
[15/24] Train loss=0.3482339084148407
[20/24] Train loss=0.32738691568374634
Test set avg_accuracy=74.41% avg_sensitivity=68.22%, avg_specificity=76.78% avg_auc=77.35%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.375978 Test loss=0.548681 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.37685632705688477
[5/24] Train loss=0.36731430888175964
[10/24] Train loss=0.370418518781662
[15/24] Train loss=0.3524566888809204
[20/24] Train loss=0.33178725838661194
Test set avg_accuracy=72.46% avg_sensitivity=74.35%, avg_specificity=71.74% avg_auc=81.12%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.381496 Test loss=0.542770 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.378000408411026
[5/24] Train loss=0.378037691116333
[10/24] Train loss=0.3748458921909332
[15/24] Train loss=0.3501179814338684
[20/24] Train loss=0.3184780776500702
Test set avg_accuracy=67.54% avg_sensitivity=79.77%, avg_specificity=62.87% avg_auc=76.20%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.379610 Test loss=0.578064 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.36628469824790955
[5/24] Train loss=0.3624853789806366
[10/24] Train loss=0.3783298134803772
[15/24] Train loss=0.3442329168319702
[20/24] Train loss=0.31790125370025635
Test set avg_accuracy=68.87% avg_sensitivity=79.87%, avg_specificity=64.67% avg_auc=76.98%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.369526 Test loss=0.571838 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3649221360683441
[5/24] Train loss=0.3591960668563843
[10/24] Train loss=0.3708868622779846
[15/24] Train loss=0.3427368104457855
[20/24] Train loss=0.32759153842926025
Test set avg_accuracy=79.21% avg_sensitivity=67.04%, avg_specificity=83.85% avg_auc=77.47%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.369571 Test loss=0.531169 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.35947689414024353
[5/24] Train loss=0.35968032479286194
[10/24] Train loss=0.37992700934410095
[15/24] Train loss=0.3404678404331207
[20/24] Train loss=0.3189392387866974
Test set avg_accuracy=69.92% avg_sensitivity=79.77%, avg_specificity=66.16% avg_auc=78.22%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.369758 Test loss=0.560117 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3726542890071869
[5/24] Train loss=0.36111292243003845
[10/24] Train loss=0.37606096267700195
[15/24] Train loss=0.3432338833808899
[20/24] Train loss=0.3233928382396698
Test set avg_accuracy=69.02% avg_sensitivity=82.70%, avg_specificity=63.81% avg_auc=78.40%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.369565 Test loss=0.571141 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.37284958362579346
[5/24] Train loss=0.368673712015152
[10/24] Train loss=0.3739815652370453
[15/24] Train loss=0.3422326445579529
[20/24] Train loss=0.3226539194583893
Test set avg_accuracy=66.00% avg_sensitivity=84.72%, avg_specificity=58.86% avg_auc=78.39%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.369587 Test loss=0.580145 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3586762845516205
[5/24] Train loss=0.3557805120944977
[10/24] Train loss=0.367872953414917
[15/24] Train loss=0.34325748682022095
[20/24] Train loss=0.318684846162796
Test set avg_accuracy=71.18% avg_sensitivity=77.27%, avg_specificity=68.86% avg_auc=74.92%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.366163 Test loss=0.581861 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.36544644832611084
[5/24] Train loss=0.3572385311126709
[10/24] Train loss=0.36860522627830505
[15/24] Train loss=0.3400130867958069
[20/24] Train loss=0.3182240426540375
Test set avg_accuracy=68.85% avg_sensitivity=81.42%, avg_specificity=64.06% avg_auc=75.98%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.365988 Test loss=0.584168 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3571983873844147
[5/24] Train loss=0.35780584812164307
[10/24] Train loss=0.3651505410671234
[15/24] Train loss=0.340538889169693
[20/24] Train loss=0.31686046719551086
Test set avg_accuracy=67.86% avg_sensitivity=84.68%, avg_specificity=61.45% avg_auc=78.79%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.365279 Test loss=0.576514 Current lr=[0.000224838296036774]

[0/24] Train loss=0.35771313309669495
[5/24] Train loss=0.3570653200149536
[10/24] Train loss=0.36997783184051514
[15/24] Train loss=0.34010201692581177
[20/24] Train loss=0.31900614500045776
Test set avg_accuracy=69.75% avg_sensitivity=79.73%, avg_specificity=65.95% avg_auc=77.21%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.366923 Test loss=0.571140 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.35658907890319824
[5/24] Train loss=0.3604239523410797
[10/24] Train loss=0.3710660934448242
[15/24] Train loss=0.34321215748786926
[20/24] Train loss=0.3140372037887573
Test set avg_accuracy=65.91% avg_sensitivity=85.95%, avg_specificity=58.27% avg_auc=77.98%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.365110 Test loss=0.588401 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3581402599811554
[5/24] Train loss=0.35299137234687805
[10/24] Train loss=0.3647229075431824
[15/24] Train loss=0.33701348304748535
[20/24] Train loss=0.3143906891345978
Test set avg_accuracy=66.50% avg_sensitivity=85.81%, avg_specificity=59.13% avg_auc=78.34%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.360847 Test loss=0.583701 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.35818997025489807
[5/24] Train loss=0.35560858249664307
[10/24] Train loss=0.3668607771396637
[15/24] Train loss=0.3416458070278168
[20/24] Train loss=0.31139254570007324
Test set avg_accuracy=72.88% avg_sensitivity=78.88%, avg_specificity=70.59% avg_auc=80.01%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.361320 Test loss=0.544446 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3574736416339874
[5/24] Train loss=0.35023897886276245
[10/24] Train loss=0.367005854845047
[15/24] Train loss=0.34355640411376953
[20/24] Train loss=0.31451255083084106
Test set avg_accuracy=67.86% avg_sensitivity=82.56%, avg_specificity=62.26% avg_auc=75.64%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.361435 Test loss=0.592819 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.35010409355163574
[5/24] Train loss=0.34923991560935974
[10/24] Train loss=0.35979533195495605
[15/24] Train loss=0.3365384042263031
[20/24] Train loss=0.3115213215351105
Test set avg_accuracy=67.97% avg_sensitivity=83.69%, avg_specificity=61.97% avg_auc=77.02%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.358769 Test loss=0.587353 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.34844255447387695
[5/24] Train loss=0.35329219698905945
[10/24] Train loss=0.36234748363494873
[15/24] Train loss=0.33506420254707336
[20/24] Train loss=0.3085506856441498
Test set avg_accuracy=69.24% avg_sensitivity=83.22%, avg_specificity=63.91% avg_auc=78.70%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.358546 Test loss=0.567047 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.35507088899612427
[5/24] Train loss=0.3457261919975281
[10/24] Train loss=0.36053261160850525
[15/24] Train loss=0.33477523922920227
[20/24] Train loss=0.31486785411834717
Test set avg_accuracy=77.47% avg_sensitivity=73.36%, avg_specificity=79.04% avg_auc=79.92%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.359479 Test loss=0.525001 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.35600900650024414
[5/24] Train loss=0.3566789925098419
[10/24] Train loss=0.3746512234210968
[15/24] Train loss=0.34023842215538025
[20/24] Train loss=0.3140205144882202
Test set avg_accuracy=69.34% avg_sensitivity=81.52%, avg_specificity=64.69% avg_auc=77.17%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.365648 Test loss=0.577137 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3608880639076233
[5/24] Train loss=0.35715511441230774
[10/24] Train loss=0.3641400933265686
[15/24] Train loss=0.3342622220516205
[20/24] Train loss=0.30960795283317566
Test set avg_accuracy=72.68% avg_sensitivity=77.46%, avg_specificity=70.86% avg_auc=80.50%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.361097 Test loss=0.538516 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3545868396759033
[5/24] Train loss=0.3547821342945099
[10/24] Train loss=0.36873868107795715
[15/24] Train loss=0.34257739782333374
[20/24] Train loss=0.31866052746772766
Test set avg_accuracy=66.84% avg_sensitivity=82.51%, avg_specificity=60.86% avg_auc=76.88%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.362091 Test loss=0.586579 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3528662621974945
[5/24] Train loss=0.35021859407424927
[10/24] Train loss=0.3680169880390167
[15/24] Train loss=0.3439728021621704
[20/24] Train loss=0.30993419885635376
Test set avg_accuracy=70.38% avg_sensitivity=82.89%, avg_specificity=65.61% avg_auc=81.09%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.361694 Test loss=0.548112 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.364247590303421
[5/24] Train loss=0.356143057346344
[10/24] Train loss=0.36961621046066284
[15/24] Train loss=0.33598124980926514
[20/24] Train loss=0.31378623843193054
Test set avg_accuracy=65.94% avg_sensitivity=86.89%, avg_specificity=57.94% avg_auc=78.21%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.361714 Test loss=0.589426 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3556758761405945
[5/24] Train loss=0.34641605615615845
[10/24] Train loss=0.36051586270332336
[15/24] Train loss=0.33703264594078064
[20/24] Train loss=0.3139416575431824
Test set avg_accuracy=68.89% avg_sensitivity=84.39%, avg_specificity=62.98% avg_auc=79.42%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.357824 Test loss=0.565147 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3514876365661621
[5/24] Train loss=0.34654420614242554
[10/24] Train loss=0.35900768637657166
[15/24] Train loss=0.3355008065700531
[20/24] Train loss=0.3123052716255188
Test set avg_accuracy=69.06% avg_sensitivity=83.92%, avg_specificity=63.39% avg_auc=80.19%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.357558 Test loss=0.558822 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.36723071336746216
[5/24] Train loss=0.35083067417144775
[10/24] Train loss=0.3694692850112915
[15/24] Train loss=0.3527647852897644
[20/24] Train loss=0.32008546590805054
Test set avg_accuracy=75.61% avg_sensitivity=74.68%, avg_specificity=75.97% avg_auc=81.28%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.371147 Test loss=0.519651 Current lr=[0.000156543481933168]

[0/24] Train loss=0.36642229557037354
[5/24] Train loss=0.3543901741504669
[10/24] Train loss=0.3712386190891266
[15/24] Train loss=0.33940088748931885
[20/24] Train loss=0.3104085624217987
Test set avg_accuracy=74.64% avg_sensitivity=76.05%, avg_specificity=74.10% avg_auc=76.67%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.364786 Test loss=0.565292 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3584161400794983
[5/24] Train loss=0.35340291261672974
[10/24] Train loss=0.36819541454315186
[15/24] Train loss=0.3337724208831787
[20/24] Train loss=0.3067156970500946
Test set avg_accuracy=67.67% avg_sensitivity=84.91%, avg_specificity=61.09% avg_auc=78.38%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.362394 Test loss=0.577879 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.36069539189338684
[5/24] Train loss=0.3548860549926758
[10/24] Train loss=0.37199726700782776
[15/24] Train loss=0.33867257833480835
[20/24] Train loss=0.3160002529621124
Test set avg_accuracy=71.16% avg_sensitivity=80.72%, avg_specificity=67.51% avg_auc=79.76%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.365359 Test loss=0.554301 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.36254000663757324
[5/24] Train loss=0.35171809792518616
[10/24] Train loss=0.3788948953151703
[15/24] Train loss=0.3360457420349121
[20/24] Train loss=0.3156149089336395
Test set avg_accuracy=69.97% avg_sensitivity=81.94%, avg_specificity=65.41% avg_auc=79.24%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.365989 Test loss=0.563412 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.36484357714653015
[5/24] Train loss=0.35640600323677063
[10/24] Train loss=0.3728230595588684
[15/24] Train loss=0.33748698234558105
[20/24] Train loss=0.3165763318538666
Test set avg_accuracy=67.33% avg_sensitivity=84.49%, avg_specificity=60.78% avg_auc=78.22%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.366098 Test loss=0.580357 Current lr=[0.000134135431043539]

[0/24] Train loss=0.36312225461006165
[5/24] Train loss=0.3535035252571106
[10/24] Train loss=0.3692835569381714
[15/24] Train loss=0.3421616554260254
[20/24] Train loss=0.32427263259887695
Test set avg_accuracy=66.35% avg_sensitivity=83.92%, avg_specificity=59.65% avg_auc=76.06%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.368916 Test loss=0.597308 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3706344664096832
[5/24] Train loss=0.35205787420272827
[10/24] Train loss=0.3641777038574219
[15/24] Train loss=0.34720805287361145
[20/24] Train loss=0.33001118898391724
Test set avg_accuracy=72.23% avg_sensitivity=79.49%, avg_specificity=69.45% avg_auc=80.45%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.373110 Test loss=0.548948 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3622252345085144
[5/24] Train loss=0.34890544414520264
[10/24] Train loss=0.3721170723438263
[15/24] Train loss=0.33824610710144043
[20/24] Train loss=0.32048913836479187
Test set avg_accuracy=70.99% avg_sensitivity=81.47%, avg_specificity=66.99% avg_auc=80.03%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.365255 Test loss=0.550470 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3588038384914398
[5/24] Train loss=0.34109726548194885
[10/24] Train loss=0.3581996560096741
[15/24] Train loss=0.3354736864566803
[20/24] Train loss=0.311350017786026
Test set avg_accuracy=68.27% avg_sensitivity=82.84%, avg_specificity=62.71% avg_auc=76.66%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.357707 Test loss=0.585582 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3482564091682434
[5/24] Train loss=0.352044939994812
[10/24] Train loss=0.36161544919013977
[15/24] Train loss=0.33323192596435547
[20/24] Train loss=0.32287663221359253
Test set avg_accuracy=71.67% avg_sensitivity=80.15%, avg_specificity=68.43% avg_auc=76.90%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.358688 Test loss=0.570071 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.35716259479522705
[5/24] Train loss=0.34086307883262634
[10/24] Train loss=0.3637751340866089
[15/24] Train loss=0.33139878511428833
[20/24] Train loss=0.3225509524345398
Test set avg_accuracy=69.19% avg_sensitivity=83.26%, avg_specificity=63.82% avg_auc=77.19%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.358429 Test loss=0.579590 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3490143120288849
[5/24] Train loss=0.3425692617893219
[10/24] Train loss=0.3634690046310425
[15/24] Train loss=0.33494338393211365
[20/24] Train loss=0.3115006387233734
Test set avg_accuracy=68.72% avg_sensitivity=82.46%, avg_specificity=63.48% avg_auc=77.71%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.355964 Test loss=0.575323 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.34509292244911194
[5/24] Train loss=0.3412066698074341
[10/24] Train loss=0.35731056332588196
[15/24] Train loss=0.3308523893356323
[20/24] Train loss=0.30924192070961
Test set avg_accuracy=70.60% avg_sensitivity=82.89%, avg_specificity=65.91% avg_auc=78.29%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.351042 Test loss=0.563809 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3454827070236206
[5/24] Train loss=0.3318397104740143
[10/24] Train loss=0.3565216660499573
[15/24] Train loss=0.3285209834575653
[20/24] Train loss=0.3092278242111206
Test set avg_accuracy=68.11% avg_sensitivity=86.23%, avg_specificity=61.20% avg_auc=76.86%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.349881 Test loss=0.589819 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.34339168667793274
[5/24] Train loss=0.3305076062679291
[10/24] Train loss=0.3539631962776184
[15/24] Train loss=0.32790154218673706
[20/24] Train loss=0.3075963854789734
Test set avg_accuracy=67.90% avg_sensitivity=85.76%, avg_specificity=61.09% avg_auc=77.25%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.348603 Test loss=0.587288 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.34044840931892395
[5/24] Train loss=0.3322827219963074
[10/24] Train loss=0.3557192385196686
[15/24] Train loss=0.3283356726169586
[20/24] Train loss=0.3060862421989441
Test set avg_accuracy=67.85% avg_sensitivity=86.09%, avg_specificity=60.89% avg_auc=77.13%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.348077 Test loss=0.589655 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.34124115109443665
[5/24] Train loss=0.32979729771614075
[10/24] Train loss=0.3547225594520569
[15/24] Train loss=0.3255532681941986
[20/24] Train loss=0.30471205711364746
Test set avg_accuracy=65.68% avg_sensitivity=87.74%, avg_specificity=57.26% avg_auc=76.83%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.346487 Test loss=0.601812 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3401850461959839
[5/24] Train loss=0.3311479687690735
[10/24] Train loss=0.3564647138118744
[15/24] Train loss=0.32544654607772827
[20/24] Train loss=0.304859459400177
Test set avg_accuracy=66.69% avg_sensitivity=87.65%, avg_specificity=58.70% avg_auc=77.36%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.346519 Test loss=0.596323 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3394298851490021
[5/24] Train loss=0.32787013053894043
[10/24] Train loss=0.35366472601890564
[15/24] Train loss=0.32474857568740845
[20/24] Train loss=0.302918404340744
Test set avg_accuracy=63.63% avg_sensitivity=89.39%, avg_specificity=53.80% avg_auc=77.22%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.346825 Test loss=0.612225 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3407754898071289
[5/24] Train loss=0.3346750736236572
[10/24] Train loss=0.3585908114910126
[15/24] Train loss=0.32346639037132263
[20/24] Train loss=0.30181753635406494
Test set avg_accuracy=66.09% avg_sensitivity=87.69%, avg_specificity=57.85% avg_auc=77.95%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.347328 Test loss=0.595005 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.34160116314888
[5/24] Train loss=0.3323639929294586
[10/24] Train loss=0.35493624210357666
[15/24] Train loss=0.32445210218429565
[20/24] Train loss=0.303344190120697
Test set avg_accuracy=65.43% avg_sensitivity=88.21%, avg_specificity=56.74% avg_auc=77.81%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.347967 Test loss=0.600487 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.34238460659980774
[5/24] Train loss=0.3311644494533539
[10/24] Train loss=0.3536792993545532
[15/24] Train loss=0.32446232438087463
[20/24] Train loss=0.3067115843296051
Test set avg_accuracy=66.65% avg_sensitivity=87.88%, avg_specificity=58.55% avg_auc=77.48%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.347986 Test loss=0.597798 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3426387906074524
[5/24] Train loss=0.3303107023239136
[10/24] Train loss=0.3515167534351349
[15/24] Train loss=0.32544034719467163
[20/24] Train loss=0.3031950294971466
Test set avg_accuracy=68.78% avg_sensitivity=85.05%, avg_specificity=62.57% avg_auc=77.19%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.346857 Test loss=0.589747 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.34071964025497437
[5/24] Train loss=0.3309348225593567
[10/24] Train loss=0.3508654534816742
[15/24] Train loss=0.3234192430973053
[20/24] Train loss=0.3011162579059601
Test set avg_accuracy=68.24% avg_sensitivity=84.87%, avg_specificity=61.90% avg_auc=77.76%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.345134 Test loss=0.584961 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.33628544211387634
[5/24] Train loss=0.32572951912879944
[10/24] Train loss=0.35335955023765564
[15/24] Train loss=0.32350224256515503
[20/24] Train loss=0.30462247133255005
Test set avg_accuracy=69.08% avg_sensitivity=84.06%, avg_specificity=63.36% avg_auc=77.04%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.345198 Test loss=0.587837 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.33667075634002686
[5/24] Train loss=0.32583823800086975
[10/24] Train loss=0.3538530468940735
[15/24] Train loss=0.32386523485183716
[20/24] Train loss=0.3038078248500824
Test set avg_accuracy=67.19% avg_sensitivity=86.23%, avg_specificity=59.92% avg_auc=77.20%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.345066 Test loss=0.592869 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.33446866273880005
[5/24] Train loss=0.3258448839187622
[10/24] Train loss=0.3532225489616394
[15/24] Train loss=0.3270614743232727
[20/24] Train loss=0.30096572637557983
Test set avg_accuracy=68.83% avg_sensitivity=83.88%, avg_specificity=63.09% avg_auc=77.87%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.344159 Test loss=0.580107 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.33413591980934143
[5/24] Train loss=0.3220070004463196
[10/24] Train loss=0.35000619292259216
[15/24] Train loss=0.3240872621536255
[20/24] Train loss=0.2977673411369324
Test set avg_accuracy=67.21% avg_sensitivity=86.42%, avg_specificity=59.88% avg_auc=76.94%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.342558 Test loss=0.596047 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3359995484352112
[5/24] Train loss=0.32171544432640076
[10/24] Train loss=0.3499079942703247
[15/24] Train loss=0.3258698284626007
[20/24] Train loss=0.2967927157878876
Test set avg_accuracy=67.96% avg_sensitivity=85.62%, avg_specificity=61.22% avg_auc=77.15%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.341901 Test loss=0.590881 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3352271318435669
[5/24] Train loss=0.32582888007164
[10/24] Train loss=0.3508605360984802
[15/24] Train loss=0.32288801670074463
[20/24] Train loss=0.2975344955921173
Test set avg_accuracy=66.88% avg_sensitivity=86.66%, avg_specificity=59.33% avg_auc=76.80%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.342750 Test loss=0.601539 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3358946144580841
[5/24] Train loss=0.32229921221733093
[10/24] Train loss=0.35045135021209717
[15/24] Train loss=0.3235171139240265
[20/24] Train loss=0.2970074415206909
Test set avg_accuracy=66.35% avg_sensitivity=86.61%, avg_specificity=58.63% avg_auc=77.26%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.342015 Test loss=0.598832 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.33436521887779236
[5/24] Train loss=0.3225983679294586
[10/24] Train loss=0.3484112024307251
[15/24] Train loss=0.32508203387260437
[20/24] Train loss=0.29689568281173706
Test set avg_accuracy=66.07% avg_sensitivity=86.61%, avg_specificity=58.23% avg_auc=76.96%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.342022 Test loss=0.602137 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3341136574745178
[5/24] Train loss=0.31897076964378357
[10/24] Train loss=0.3488905429840088
[15/24] Train loss=0.3230848014354706
[20/24] Train loss=0.2964245676994324
Test set avg_accuracy=65.08% avg_sensitivity=88.12%, avg_specificity=56.29% avg_auc=76.76%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.340800 Test loss=0.610149 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3322583734989166
[5/24] Train loss=0.32315129041671753
[10/24] Train loss=0.34842735528945923
[15/24] Train loss=0.323323518037796
[20/24] Train loss=0.29576221108436584
Test set avg_accuracy=64.93% avg_sensitivity=88.21%, avg_specificity=56.05% avg_auc=76.74%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.340679 Test loss=0.612625 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3310115933418274
[5/24] Train loss=0.32668909430503845
[10/24] Train loss=0.3501257300376892
[15/24] Train loss=0.32337310910224915
[20/24] Train loss=0.29831141233444214
Test set avg_accuracy=64.93% avg_sensitivity=88.31%, avg_specificity=56.02% avg_auc=76.60%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.342423 Test loss=0.613744 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.33268702030181885
[5/24] Train loss=0.3245660960674286
[10/24] Train loss=0.3508327007293701
[15/24] Train loss=0.3235272765159607
[20/24] Train loss=0.2982378304004669
Test set avg_accuracy=64.67% avg_sensitivity=88.12%, avg_specificity=55.73% avg_auc=76.96%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.342669 Test loss=0.611528 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.33235952258110046
[5/24] Train loss=0.3237236738204956
[10/24] Train loss=0.3528297543525696
[15/24] Train loss=0.3244059383869171
[20/24] Train loss=0.29925858974456787
Test set avg_accuracy=63.72% avg_sensitivity=89.01%, avg_specificity=54.07% avg_auc=77.21%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.344034 Test loss=0.614350 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.3356117010116577
[5/24] Train loss=0.32066041231155396
[10/24] Train loss=0.3515135943889618
[15/24] Train loss=0.32242321968078613
[20/24] Train loss=0.2973984479904175
Test set avg_accuracy=65.34% avg_sensitivity=87.36%, avg_specificity=56.93% avg_auc=77.06%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.341739 Test loss=0.603409 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.334002286195755
[5/24] Train loss=0.32077544927597046
[10/24] Train loss=0.34759920835494995
[15/24] Train loss=0.32165902853012085
[20/24] Train loss=0.2958206832408905
Test set avg_accuracy=66.29% avg_sensitivity=86.75%, avg_specificity=58.48% avg_auc=77.41%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.339949 Test loss=0.597450 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.3312796354293823
[5/24] Train loss=0.31732383370399475
[10/24] Train loss=0.34681621193885803
[15/24] Train loss=0.3207175135612488
[20/24] Train loss=0.29506009817123413
Test set avg_accuracy=64.84% avg_sensitivity=87.98%, avg_specificity=56.02% avg_auc=77.10%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.338227 Test loss=0.608344 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.33009853959083557
[5/24] Train loss=0.3163169026374817
[10/24] Train loss=0.34659066796302795
[15/24] Train loss=0.32032787799835205
[20/24] Train loss=0.294674813747406
Test set avg_accuracy=64.73% avg_sensitivity=88.26%, avg_specificity=55.75% avg_auc=77.01%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.337820 Test loss=0.610949 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.32990652322769165
[5/24] Train loss=0.3161066472530365
[10/24] Train loss=0.3460509777069092
[15/24] Train loss=0.32001370191574097
[20/24] Train loss=0.294278085231781
Test set avg_accuracy=64.93% avg_sensitivity=88.26%, avg_specificity=56.04% avg_auc=77.04%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.337355 Test loss=0.609743 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.32923364639282227
[5/24] Train loss=0.3157380521297455
[10/24] Train loss=0.3457399606704712
[15/24] Train loss=0.31947314739227295
[20/24] Train loss=0.2944561243057251
Test set avg_accuracy=64.65% avg_sensitivity=88.35%, avg_specificity=55.60% avg_auc=76.89%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.337023 Test loss=0.612686 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3289427161216736
[5/24] Train loss=0.315477579832077
[10/24] Train loss=0.3457533121109009
[15/24] Train loss=0.31941384077072144
[20/24] Train loss=0.2942925989627838
Test set avg_accuracy=64.35% avg_sensitivity=88.40%, avg_specificity=55.17% avg_auc=76.83%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.336867 Test loss=0.614150 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3287917673587799
[5/24] Train loss=0.31512489914894104
[10/24] Train loss=0.34565475583076477
[15/24] Train loss=0.31926852464675903
[20/24] Train loss=0.2941991984844208
Test set avg_accuracy=64.23% avg_sensitivity=88.40%, avg_specificity=55.01% avg_auc=76.75%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.336694 Test loss=0.615620 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.32860425114631653
[5/24] Train loss=0.31496164202690125
[10/24] Train loss=0.3455701470375061
[15/24] Train loss=0.31917688250541687
[20/24] Train loss=0.2940897047519684
Test set avg_accuracy=64.18% avg_sensitivity=88.45%, avg_specificity=54.92% avg_auc=76.71%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.336594 Test loss=0.616468 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.32847923040390015
[5/24] Train loss=0.3147953748703003
[10/24] Train loss=0.3455069065093994
[15/24] Train loss=0.3190819025039673
[20/24] Train loss=0.29402321577072144
Test set avg_accuracy=64.17% avg_sensitivity=88.45%, avg_specificity=54.90% avg_auc=76.70%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.336498 Test loss=0.616910 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3283957242965698
[5/24] Train loss=0.3146718442440033
[10/24] Train loss=0.3454507887363434
[15/24] Train loss=0.3190166652202606
[20/24] Train loss=0.29397013783454895
Test set avg_accuracy=63.83% avg_sensitivity=88.45%, avg_specificity=54.43% avg_auc=76.68%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.336424 Test loss=0.617427 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.32832756638526917
[5/24] Train loss=0.31457552313804626
[10/24] Train loss=0.34541088342666626
[15/24] Train loss=0.3189627528190613
[20/24] Train loss=0.29392555356025696
Test set avg_accuracy=63.82% avg_sensitivity=88.45%, avg_specificity=54.42% avg_auc=76.66%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.336371 Test loss=0.617792 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.32827386260032654
[5/24] Train loss=0.31450238823890686
[10/24] Train loss=0.34537607431411743
[15/24] Train loss=0.31891772150993347
[20/24] Train loss=0.29389435052871704
Test set avg_accuracy=63.80% avg_sensitivity=88.45%, avg_specificity=54.40% avg_auc=76.64%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.336332 Test loss=0.618051 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.3282355070114136
[5/24] Train loss=0.31445199251174927
[10/24] Train loss=0.34535130858421326
[15/24] Train loss=0.31888872385025024
[20/24] Train loss=0.29387399554252625
Test set avg_accuracy=63.79% avg_sensitivity=88.45%, avg_specificity=54.38% avg_auc=76.63%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.336305 Test loss=0.618240 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3282117247581482
[5/24] Train loss=0.3144190013408661
[10/24] Train loss=0.3453362286090851
[15/24] Train loss=0.31887194514274597
[20/24] Train loss=0.29386192560195923
Test set avg_accuracy=63.79% avg_sensitivity=88.45%, avg_specificity=54.38% avg_auc=76.62%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.336289 Test loss=0.618360 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3281990885734558
[5/24] Train loss=0.31440043449401855
[10/24] Train loss=0.34532809257507324
[15/24] Train loss=0.3188632130622864
[20/24] Train loss=0.29385611414909363
Test set avg_accuracy=63.79% avg_sensitivity=88.45%, avg_specificity=54.38% avg_auc=76.62%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.336280 Test loss=0.618428 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.32819369435310364
[5/24] Train loss=0.314392626285553
[10/24] Train loss=0.34532469511032104
[15/24] Train loss=0.3188600242137909
[20/24] Train loss=0.2938544750213623
Test set avg_accuracy=63.79% avg_sensitivity=88.45%, avg_specificity=54.38% avg_auc=76.62%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.336276 Test loss=0.618451 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=80.59% sen=60.91%, spe=88.09%, auc=80.71%!
Fold[7] Avg_overlap=0.54%(0.29608777872444897)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 1,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'SwEDModel',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.7011741995811462
[5/24] Train loss=0.7000065445899963
[10/24] Train loss=0.6996169090270996
[15/24] Train loss=0.698865532875061
[20/24] Train loss=0.6979718804359436
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.20%
Best model saved!! Metric=-101.93883282421403!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.699346 Test loss=0.696993 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6972628831863403
[5/24] Train loss=0.6958552002906799
[10/24] Train loss=0.6956994533538818
[15/24] Train loss=0.6950458288192749
[20/24] Train loss=0.6937358379364014
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.33%
Best model saved!! Metric=-101.81548261690983!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.695412 Test loss=0.693009 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6935864090919495
[5/24] Train loss=0.6917498707771301
[10/24] Train loss=0.6917833089828491
[15/24] Train loss=0.6911397576332092
[20/24] Train loss=0.6893633604049683
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.38%
Best model saved!! Metric=-101.76819994716583!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.691430 Test loss=0.688838 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.689688503742218
[5/24] Train loss=0.687376081943512
[10/24] Train loss=0.6876391172409058
[15/24] Train loss=0.6869063973426819
[20/24] Train loss=0.6847155690193176
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.50%
Best model saved!! Metric=-101.6424941639161!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.687219 Test loss=0.684457 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6855448484420776
[5/24] Train loss=0.6827064752578735
[10/24] Train loss=0.683239221572876
[15/24] Train loss=0.6824372410774231
[20/24] Train loss=0.6794494986534119
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.62%
Best model saved!! Metric=-101.52183282628584!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.682673 Test loss=0.679385 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6808104515075684
[5/24] Train loss=0.6772491335868835
[10/24] Train loss=0.6777618527412415
[15/24] Train loss=0.6770226955413818
[20/24] Train loss=0.6729808449745178
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.87%
Best model saved!! Metric=-101.27248407772724!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.677173 Test loss=0.673300 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6751026511192322
[5/24] Train loss=0.6706034541130066
[10/24] Train loss=0.6711573600769043
[15/24] Train loss=0.6706934571266174
[20/24] Train loss=0.6652132868766785
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.98%
Best model saved!! Metric=-101.16194315912108!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.670592 Test loss=0.665916 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6682611107826233
[5/24] Train loss=0.6624572277069092
[10/24] Train loss=0.6632038354873657
[15/24] Train loss=0.6624082922935486
[20/24] Train loss=0.6547447443008423
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.25%
Best model saved!! Metric=-100.89749260148915!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.662203 Test loss=0.655611 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6588733792304993
[5/24] Train loss=0.6508631706237793
[10/24] Train loss=0.6515897512435913
[15/24] Train loss=0.6503803730010986
[20/24] Train loss=0.6392592191696167
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.44%
Best model saved!! Metric=-100.70672247768674!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.650108 Test loss=0.640753 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6455076336860657
[5/24] Train loss=0.633954644203186
[10/24] Train loss=0.6350952386856079
[15/24] Train loss=0.6331450343132019
[20/24] Train loss=0.6169601678848267
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.65%
Best model saved!! Metric=-100.49307669379385!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.632836 Test loss=0.620227 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6272504925727844
[5/24] Train loss=0.6105225086212158
[10/24] Train loss=0.6139061450958252
[15/24] Train loss=0.6105724573135376
[20/24] Train loss=0.588554322719574
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.91%
Best model saved!! Metric=-100.22828383449487!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.610517 Test loss=0.596453 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6065242290496826
[5/24] Train loss=0.58396315574646
[10/24] Train loss=0.5930944085121155
[15/24] Train loss=0.5880268216133118
[20/24] Train loss=0.5611453056335449
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.50%
Best model saved!! Metric=-99.6413896104842!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.588274 Test loss=0.576953 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5910022854804993
[5/24] Train loss=0.5622008442878723
[10/24] Train loss=0.5800044536590576
[15/24] Train loss=0.574194610118866
[20/24] Train loss=0.54523766040802
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.78%
Best model saved!! Metric=-98.35854655372671!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.573674 Test loss=0.567080 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5828445553779602
[5/24] Train loss=0.553544282913208
[10/24] Train loss=0.5725907683372498
[15/24] Train loss=0.5667291283607483
[20/24] Train loss=0.5386198163032532
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=55.25%
Best model saved!! Metric=-95.89002456998765!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.566324 Test loss=0.563247 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5794016122817993
[5/24] Train loss=0.5478411912918091
[10/24] Train loss=0.5695022940635681
[15/24] Train loss=0.5644882917404175
[20/24] Train loss=0.5302555561065674
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=59.81%
Best model saved!! Metric=-91.33455237789948!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.562805 Test loss=0.560624 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5764321684837341
[5/24] Train loss=0.5430091023445129
[10/24] Train loss=0.5671433806419373
[15/24] Train loss=0.5619128346443176
[20/24] Train loss=0.5284223556518555
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=61.78%
Best model saved!! Metric=-89.35859348508686!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.560101 Test loss=0.558983 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5730433464050293
[5/24] Train loss=0.5382993817329407
[10/24] Train loss=0.5643795132637024
[15/24] Train loss=0.5595213174819946
[20/24] Train loss=0.5174643993377686
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=64.77%
Best model saved!! Metric=-86.36994411828638!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.555995 Test loss=0.554064 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5665364861488342
[5/24] Train loss=0.5344396829605103
[10/24] Train loss=0.558807909488678
[15/24] Train loss=0.5544664859771729
[20/24] Train loss=0.5052026510238647
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=69.81%
Best model saved!! Metric=-81.33614588223894!!
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.548720 Test loss=0.546683 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5553703308105469
[5/24] Train loss=0.5192403793334961
[10/24] Train loss=0.5507075190544128
[15/24] Train loss=0.5444629192352295
[20/24] Train loss=0.48796218633651733
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=71.65%
Best model saved!! Metric=-79.49493674303665!!
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.537398 Test loss=0.552780 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5398985743522644
[5/24] Train loss=0.5196393728256226
[10/24] Train loss=0.5362356901168823
[15/24] Train loss=0.5282554030418396
[20/24] Train loss=0.4706456959247589
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=72.37%
Best model saved!! Metric=-78.77000937179365!!
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.524836 Test loss=0.602295 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5232214331626892
[5/24] Train loss=0.4980425238609314
[10/24] Train loss=0.5219689011573792
[15/24] Train loss=0.5274021625518799
[20/24] Train loss=0.4590255320072174
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=66.84%
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.515123 Test loss=0.652192 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5120532512664795
[5/24] Train loss=0.48450902104377747
[10/24] Train loss=0.5103875398635864
[15/24] Train loss=0.5124109983444214
[20/24] Train loss=0.4542560875415802
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=57.64%
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.503464 Test loss=0.660063 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.4993697702884674
[5/24] Train loss=0.4860537350177765
[10/24] Train loss=0.5004460215568542
[15/24] Train loss=0.5011515021324158
[20/24] Train loss=0.4528643488883972
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=57.75%
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.495011 Test loss=0.649180 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.49171850085258484
[5/24] Train loss=0.4726831018924713
[10/24] Train loss=0.49576103687286377
[15/24] Train loss=0.49485698342323303
[20/24] Train loss=0.44244107604026794
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=61.28%
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.487987 Test loss=0.642368 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.4851028323173523
[5/24] Train loss=0.46524038910865784
[10/24] Train loss=0.48854684829711914
[15/24] Train loss=0.48823919892311096
[20/24] Train loss=0.43420514464378357
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=64.33%
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.481150 Test loss=0.633486 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.47936931252479553
[5/24] Train loss=0.4640953838825226
[10/24] Train loss=0.4860573709011078
[15/24] Train loss=0.48794737458229065
[20/24] Train loss=0.4323403835296631
Test set avg_accuracy=61.97% avg_sensitivity=35.99%, avg_specificity=70.69% avg_auc=65.00%
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.478218 Test loss=0.636868 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.4765010178089142
[5/24] Train loss=0.4600960314273834
[10/24] Train loss=0.48302194476127625
[15/24] Train loss=0.4865868091583252
[20/24] Train loss=0.4262489974498749
Test set avg_accuracy=55.55% avg_sensitivity=64.79%, avg_specificity=52.44% avg_auc=67.13%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.475764 Test loss=0.634782 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.47749045491218567
[5/24] Train loss=0.46675926446914673
[10/24] Train loss=0.48640814423561096
[15/24] Train loss=0.49006083607673645
[20/24] Train loss=0.43193623423576355
Test set avg_accuracy=63.62% avg_sensitivity=51.06%, avg_specificity=67.84% avg_auc=70.06%
Best model saved!! Metric=-73.4198559643941!!
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.473380 Test loss=0.614538 Current lr=[0.000210185142098938]

[0/24] Train loss=0.46658676862716675
[5/24] Train loss=0.4832288920879364
[10/24] Train loss=0.4833594262599945
[15/24] Train loss=0.48589393496513367
[20/24] Train loss=0.427927702665329
Test set avg_accuracy=48.85% avg_sensitivity=77.99%, avg_specificity=39.07% avg_auc=67.27%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.473265 Test loss=0.641707 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.4687681794166565
[5/24] Train loss=0.45254671573638916
[10/24] Train loss=0.47504425048828125
[15/24] Train loss=0.4790060818195343
[20/24] Train loss=0.4240383803844452
Test set avg_accuracy=49.65% avg_sensitivity=78.66%, avg_specificity=39.90% avg_auc=68.28%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.467112 Test loss=0.642535 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.46259957551956177
[5/24] Train loss=0.4387359321117401
[10/24] Train loss=0.46947571635246277
[15/24] Train loss=0.4693434536457062
[20/24] Train loss=0.4132820665836334
Test set avg_accuracy=52.73% avg_sensitivity=78.46%, avg_specificity=44.09% avg_auc=71.68%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.460378 Test loss=0.629699 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.4813237190246582
[5/24] Train loss=0.45109835267066956
[10/24] Train loss=0.4822627604007721
[15/24] Train loss=0.4800167977809906
[20/24] Train loss=0.40339210629463196
Test set avg_accuracy=72.77% avg_sensitivity=42.00%, avg_specificity=83.11% avg_auc=74.91%
Best model saved!! Metric=-53.21136160360202!!
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.462786 Test loss=0.572652 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.4428696632385254
[5/24] Train loss=0.4365679621696472
[10/24] Train loss=0.454054057598114
[15/24] Train loss=0.4647962152957916
[20/24] Train loss=0.3783889412879944
Test set avg_accuracy=63.12% avg_sensitivity=74.94%, avg_specificity=59.16% avg_auc=68.64%
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.445273 Test loss=0.613527 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.4327039420604706
[5/24] Train loss=0.4458087086677551
[10/24] Train loss=0.4513542950153351
[15/24] Train loss=0.4517846405506134
[20/24] Train loss=0.3806213438510895
Test set avg_accuracy=70.22% avg_sensitivity=69.29%, avg_specificity=70.53% avg_auc=72.09%
Best model saved!! Metric=-43.86874575749549!!
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.439667 Test loss=0.594278 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.41646966338157654
[5/24] Train loss=0.4032457172870636
[10/24] Train loss=0.4365279972553253
[15/24] Train loss=0.4699305593967438
[20/24] Train loss=0.37660327553749084
Test set avg_accuracy=61.81% avg_sensitivity=77.52%, avg_specificity=56.53% avg_auc=70.58%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.429175 Test loss=0.616899 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4153619408607483
[5/24] Train loss=0.4019780158996582
[10/24] Train loss=0.424460232257843
[15/24] Train loss=0.44716691970825195
[20/24] Train loss=0.3592984676361084
Test set avg_accuracy=58.11% avg_sensitivity=83.48%, avg_specificity=49.59% avg_auc=70.52%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.421502 Test loss=0.627199 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4072010815143585
[5/24] Train loss=0.4018748998641968
[10/24] Train loss=0.42981454730033875
[15/24] Train loss=0.452109158039093
[20/24] Train loss=0.3717655837535858
Test set avg_accuracy=66.59% avg_sensitivity=74.05%, avg_specificity=64.08% avg_auc=75.07%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.424060 Test loss=0.593845 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.40685319900512695
[5/24] Train loss=0.40382087230682373
[10/24] Train loss=0.4192400872707367
[15/24] Train loss=0.43401390314102173
[20/24] Train loss=0.3571258783340454
Test set avg_accuracy=57.29% avg_sensitivity=85.14%, avg_specificity=47.94% avg_auc=70.44%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.415057 Test loss=0.630963 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4097032845020294
[5/24] Train loss=0.4180904030799866
[10/24] Train loss=0.416032612323761
[15/24] Train loss=0.4525218605995178
[20/24] Train loss=0.35448795557022095
Test set avg_accuracy=65.56% avg_sensitivity=75.76%, avg_specificity=62.13% avg_auc=75.83%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.418286 Test loss=0.592652 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.4037030041217804
[5/24] Train loss=0.40132588148117065
[10/24] Train loss=0.43085816502571106
[15/24] Train loss=0.4386235177516937
[20/24] Train loss=0.3707181513309479
Test set avg_accuracy=60.23% avg_sensitivity=80.63%, avg_specificity=53.38% avg_auc=73.46%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.417246 Test loss=0.614585 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.41289642453193665
[5/24] Train loss=0.4469875395298004
[10/24] Train loss=0.4194042980670929
[15/24] Train loss=0.432522177696228
[20/24] Train loss=0.3493449091911316
Test set avg_accuracy=68.48% avg_sensitivity=72.55%, avg_specificity=67.11% avg_auc=77.02%
Best model saved!! Metric=-40.84051000282602!!
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.420392 Test loss=0.580106 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.40036600828170776
[5/24] Train loss=0.3925218880176544
[10/24] Train loss=0.40859857201576233
[15/24] Train loss=0.4343354403972626
[20/24] Train loss=0.3461253046989441
Test set avg_accuracy=66.35% avg_sensitivity=74.16%, avg_specificity=63.73% avg_auc=76.48%
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.411036 Test loss=0.581790 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.39465099573135376
[5/24] Train loss=0.38659775257110596
[10/24] Train loss=0.4143308103084564
[15/24] Train loss=0.42814135551452637
[20/24] Train loss=0.34597569704055786
Test set avg_accuracy=63.06% avg_sensitivity=76.49%, avg_specificity=58.55% avg_auc=74.54%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.406126 Test loss=0.603403 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3949175179004669
[5/24] Train loss=0.3874616324901581
[10/24] Train loss=0.3965655565261841
[15/24] Train loss=0.4194730222225189
[20/24] Train loss=0.34257447719573975
Test set avg_accuracy=59.92% avg_sensitivity=81.87%, avg_specificity=52.55% avg_auc=72.84%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.402716 Test loss=0.618953 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3910812437534332
[5/24] Train loss=0.3881886303424835
[10/24] Train loss=0.396491140127182
[15/24] Train loss=0.4958849251270294
[20/24] Train loss=0.34464868903160095
Test set avg_accuracy=77.93% avg_sensitivity=55.67%, avg_specificity=85.41% avg_auc=80.97%
Best model saved!! Metric=-26.025211372827634!!
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.409271 Test loss=0.533666 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.435226708650589
[5/24] Train loss=0.4198742210865021
[10/24] Train loss=0.4249041974544525
[15/24] Train loss=0.4372159540653229
[20/24] Train loss=0.3436078429222107
Test set avg_accuracy=72.29% avg_sensitivity=64.89%, avg_specificity=74.78% avg_auc=74.80%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.421481 Test loss=0.577977 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.4065042734146118
[5/24] Train loss=0.39017730951309204
[10/24] Train loss=0.4063728153705597
[15/24] Train loss=0.4228908121585846
[20/24] Train loss=0.35069355368614197
Test set avg_accuracy=64.40% avg_sensitivity=79.18%, avg_specificity=59.44% avg_auc=80.07%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.406402 Test loss=0.593090 Current lr=[0.000299720220882401]

[0/24] Train loss=0.4016795754432678
[5/24] Train loss=0.390909343957901
[10/24] Train loss=0.40460675954818726
[15/24] Train loss=0.44028469920158386
[20/24] Train loss=0.339908629655838
Test set avg_accuracy=71.60% avg_sensitivity=66.08%, avg_specificity=73.46% avg_auc=77.10%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.408676 Test loss=0.569071 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3918192982673645
[5/24] Train loss=0.38894546031951904
[10/24] Train loss=0.396142840385437
[15/24] Train loss=0.43114757537841797
[20/24] Train loss=0.34546002745628357
Test set avg_accuracy=69.71% avg_sensitivity=70.59%, avg_specificity=69.42% avg_auc=75.86%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.405391 Test loss=0.577627 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3950894773006439
[5/24] Train loss=0.3910495638847351
[10/24] Train loss=0.3950710892677307
[15/24] Train loss=0.42949074506759644
[20/24] Train loss=0.3581286668777466
Test set avg_accuracy=66.80% avg_sensitivity=77.37%, avg_specificity=63.25% avg_auc=78.27%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.406342 Test loss=0.585871 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3925051689147949
[5/24] Train loss=0.38175201416015625
[10/24] Train loss=0.40206003189086914
[15/24] Train loss=0.4437235891819
[20/24] Train loss=0.33931392431259155
Test set avg_accuracy=70.90% avg_sensitivity=69.81%, avg_specificity=71.26% avg_auc=76.65%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.402826 Test loss=0.574029 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3861845135688782
[5/24] Train loss=0.37850141525268555
[10/24] Train loss=0.39904725551605225
[15/24] Train loss=0.4175058603286743
[20/24] Train loss=0.3321266174316406
Test set avg_accuracy=66.84% avg_sensitivity=71.36%, avg_specificity=65.32% avg_auc=74.98%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.398421 Test loss=0.583114 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.38131532073020935
[5/24] Train loss=0.37679988145828247
[10/24] Train loss=0.38693007826805115
[15/24] Train loss=0.43522027134895325
[20/24] Train loss=0.34277015924453735
Test set avg_accuracy=67.94% avg_sensitivity=74.88%, avg_specificity=65.61% avg_auc=79.83%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.396225 Test loss=0.572483 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.38250425457954407
[5/24] Train loss=0.3797962963581085
[10/24] Train loss=0.39939171075820923
[15/24] Train loss=0.47590160369873047
[20/24] Train loss=0.3371831476688385
Test set avg_accuracy=76.26% avg_sensitivity=62.45%, avg_specificity=80.90% avg_auc=81.60%
Best model saved!! Metric=-24.783953314513433!!
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.402386 Test loss=0.532222 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.38810038566589355
[5/24] Train loss=0.3841041624546051
[10/24] Train loss=0.3949041962623596
[15/24] Train loss=0.42357632517814636
[20/24] Train loss=0.3276137411594391
Test set avg_accuracy=61.77% avg_sensitivity=82.60%, avg_specificity=54.77% avg_auc=76.95%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.395314 Test loss=0.598794 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3795201778411865
[5/24] Train loss=0.3851780891418457
[10/24] Train loss=0.3851511776447296
[15/24] Train loss=0.41857123374938965
[20/24] Train loss=0.3430773615837097
Test set avg_accuracy=64.88% avg_sensitivity=80.79%, avg_specificity=59.54% avg_auc=79.73%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.394476 Test loss=0.588295 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.38481464982032776
[5/24] Train loss=0.3939325511455536
[10/24] Train loss=0.39345836639404297
[15/24] Train loss=0.4315437078475952
[20/24] Train loss=0.32755592465400696
Test set avg_accuracy=72.73% avg_sensitivity=65.61%, avg_specificity=75.13% avg_auc=76.04%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.395625 Test loss=0.564039 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.38330352306365967
[5/24] Train loss=0.389055460691452
[10/24] Train loss=0.3864503502845764
[15/24] Train loss=0.4303548336029053
[20/24] Train loss=0.3275602459907532
Test set avg_accuracy=67.28% avg_sensitivity=74.37%, avg_specificity=64.90% avg_auc=77.74%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.393343 Test loss=0.574308 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.38039374351501465
[5/24] Train loss=0.3796558082103729
[10/24] Train loss=0.39004117250442505
[15/24] Train loss=0.42341896891593933
[20/24] Train loss=0.3212149441242218
Test set avg_accuracy=74.39% avg_sensitivity=63.34%, avg_specificity=78.10% avg_auc=76.79%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.394987 Test loss=0.555936 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3874302804470062
[5/24] Train loss=0.38511064648628235
[10/24] Train loss=0.4165682792663574
[15/24] Train loss=0.4650753438472748
[20/24] Train loss=0.3343494236469269
Test set avg_accuracy=69.87% avg_sensitivity=73.23%, avg_specificity=68.74% avg_auc=80.94%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.403560 Test loss=0.566039 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3916075825691223
[5/24] Train loss=0.3821313977241516
[10/24] Train loss=0.39038538932800293
[15/24] Train loss=0.4217820167541504
[20/24] Train loss=0.3327403962612152
Test set avg_accuracy=62.53% avg_sensitivity=77.99%, avg_specificity=57.33% avg_auc=73.31%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.392963 Test loss=0.605082 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.38062676787376404
[5/24] Train loss=0.3827911615371704
[10/24] Train loss=0.38490742444992065
[15/24] Train loss=0.4261174201965332
[20/24] Train loss=0.3291953504085541
Test set avg_accuracy=63.19% avg_sensitivity=82.70%, avg_specificity=56.64% avg_auc=77.95%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.390853 Test loss=0.592437 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.38285067677497864
[5/24] Train loss=0.38235175609588623
[10/24] Train loss=0.386055052280426
[15/24] Train loss=0.43464088439941406
[20/24] Train loss=0.339045912027359
Test set avg_accuracy=74.27% avg_sensitivity=65.51%, avg_specificity=77.21% avg_auc=80.88%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.395740 Test loss=0.539064 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.383166640996933
[5/24] Train loss=0.3764519691467285
[10/24] Train loss=0.38748759031295776
[15/24] Train loss=0.424815833568573
[20/24] Train loss=0.3421300947666168
Test set avg_accuracy=69.44% avg_sensitivity=74.31%, avg_specificity=67.80% avg_auc=78.43%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.393690 Test loss=0.573508 Current lr=[0.000276307469034998]

[0/24] Train loss=0.38469573855400085
[5/24] Train loss=0.3879495859146118
[10/24] Train loss=0.3974495828151703
[15/24] Train loss=0.42529264092445374
[20/24] Train loss=0.3354351818561554
Test set avg_accuracy=62.10% avg_sensitivity=82.65%, avg_specificity=55.19% avg_auc=79.74%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.396998 Test loss=0.596610 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.40704792737960815
[5/24] Train loss=0.38049712777137756
[10/24] Train loss=0.38515806198120117
[15/24] Train loss=0.4191884696483612
[20/24] Train loss=0.3221586048603058
Test set avg_accuracy=66.65% avg_sensitivity=73.12%, avg_specificity=64.48% avg_auc=76.42%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.394960 Test loss=0.581444 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3818782567977905
[5/24] Train loss=0.381703644990921
[10/24] Train loss=0.38577449321746826
[15/24] Train loss=0.4049464166164398
[20/24] Train loss=0.3244158625602722
Test set avg_accuracy=60.53% avg_sensitivity=83.89%, avg_specificity=52.69% avg_auc=76.63%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.388095 Test loss=0.602428 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3753630518913269
[5/24] Train loss=0.38193565607070923
[10/24] Train loss=0.3906359374523163
[15/24] Train loss=0.45038923621177673
[20/24] Train loss=0.33792543411254883
Test set avg_accuracy=70.51% avg_sensitivity=73.69%, avg_specificity=69.44% avg_auc=80.80%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.393665 Test loss=0.563155 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3865082561969757
[5/24] Train loss=0.38265928626060486
[10/24] Train loss=0.3908853232860565
[15/24] Train loss=0.4375767111778259
[20/24] Train loss=0.32456374168395996
Test set avg_accuracy=69.77% avg_sensitivity=71.72%, avg_specificity=69.11% avg_auc=76.32%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.392669 Test loss=0.571736 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3821779489517212
[5/24] Train loss=0.3695788085460663
[10/24] Train loss=0.3892609775066376
[15/24] Train loss=0.41935473680496216
[20/24] Train loss=0.3257061839103699
Test set avg_accuracy=58.57% avg_sensitivity=85.34%, avg_specificity=49.57% avg_auc=73.53%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.388853 Test loss=0.619415 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3778444528579712
[5/24] Train loss=0.37404462695121765
[10/24] Train loss=0.3843718469142914
[15/24] Train loss=0.4127699136734009
[20/24] Train loss=0.3214857578277588
Test set avg_accuracy=63.52% avg_sensitivity=79.34%, avg_specificity=58.20% avg_auc=75.79%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.386254 Test loss=0.592037 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3727940022945404
[5/24] Train loss=0.36151671409606934
[10/24] Train loss=0.3809543251991272
[15/24] Train loss=0.42351460456848145
[20/24] Train loss=0.34117254614830017
Test set avg_accuracy=71.69% avg_sensitivity=71.21%, avg_specificity=71.86% avg_auc=80.71%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.387741 Test loss=0.547531 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.38091516494750977
[5/24] Train loss=0.37062692642211914
[10/24] Train loss=0.39086395502090454
[15/24] Train loss=0.40956035256385803
[20/24] Train loss=0.33908480405807495
Test set avg_accuracy=58.98% avg_sensitivity=88.71%, avg_specificity=49.00% avg_auc=79.39%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.389295 Test loss=0.603002 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.39713993668556213
[5/24] Train loss=0.39364922046661377
[10/24] Train loss=0.38202762603759766
[15/24] Train loss=0.42272767424583435
[20/24] Train loss=0.32923221588134766
Test set avg_accuracy=68.12% avg_sensitivity=77.01%, avg_specificity=65.14% avg_auc=79.25%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.392379 Test loss=0.564721 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.37873587012290955
[5/24] Train loss=0.38559460639953613
[10/24] Train loss=0.38840362429618835
[15/24] Train loss=0.41101616621017456
[20/24] Train loss=0.3152373135089874
Test set avg_accuracy=63.96% avg_sensitivity=81.77%, avg_specificity=57.98% avg_auc=77.33%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.386114 Test loss=0.591258 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3779374063014984
[5/24] Train loss=0.3694162666797638
[10/24] Train loss=0.38081908226013184
[15/24] Train loss=0.4446898400783539
[20/24] Train loss=0.34088850021362305
Test set avg_accuracy=65.91% avg_sensitivity=79.75%, avg_specificity=61.26% avg_auc=77.23%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.390373 Test loss=0.582323 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3868173062801361
[5/24] Train loss=0.37544575333595276
[10/24] Train loss=0.3806462287902832
[15/24] Train loss=0.39485862851142883
[20/24] Train loss=0.3125271499156952
Test set avg_accuracy=63.46% avg_sensitivity=83.43%, avg_specificity=56.76% avg_auc=78.01%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.383241 Test loss=0.589494 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.37599411606788635
[5/24] Train loss=0.3685482144355774
[10/24] Train loss=0.3917732834815979
[15/24] Train loss=0.41270333528518677
[20/24] Train loss=0.3141058683395386
Test set avg_accuracy=65.47% avg_sensitivity=80.27%, avg_specificity=60.50% avg_auc=77.38%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.386577 Test loss=0.583451 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.37869343161582947
[5/24] Train loss=0.36479535698890686
[10/24] Train loss=0.37796422839164734
[15/24] Train loss=0.3895139992237091
[20/24] Train loss=0.3144195079803467
Test set avg_accuracy=67.23% avg_sensitivity=78.97%, avg_specificity=63.28% avg_auc=78.23%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.379206 Test loss=0.572152 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3757683038711548
[5/24] Train loss=0.3805442452430725
[10/24] Train loss=0.3859758973121643
[15/24] Train loss=0.4212290644645691
[20/24] Train loss=0.33030205965042114
Test set avg_accuracy=74.80% avg_sensitivity=66.34%, avg_specificity=77.65% avg_auc=79.20%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.390761 Test loss=0.539276 Current lr=[0.000224838296036774]

[0/24] Train loss=0.37448427081108093
[5/24] Train loss=0.36460787057876587
[10/24] Train loss=0.37738367915153503
[15/24] Train loss=0.39454615116119385
[20/24] Train loss=0.3152923882007599
Test set avg_accuracy=64.40% avg_sensitivity=83.32%, avg_specificity=58.04% avg_auc=77.92%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.379480 Test loss=0.583768 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3710421621799469
[5/24] Train loss=0.36196961998939514
[10/24] Train loss=0.3745517432689667
[15/24] Train loss=0.3954939842224121
[20/24] Train loss=0.3250539302825928
Test set avg_accuracy=73.07% avg_sensitivity=71.88%, avg_specificity=73.47% avg_auc=82.69%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.381669 Test loss=0.526731 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.38554391264915466
[5/24] Train loss=0.38123819231987
[10/24] Train loss=0.37759968638420105
[15/24] Train loss=0.39442306756973267
[20/24] Train loss=0.31520000100135803
Test set avg_accuracy=70.48% avg_sensitivity=77.42%, avg_specificity=68.15% avg_auc=82.09%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.382668 Test loss=0.551298 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.37131935358047485
[5/24] Train loss=0.3684503734111786
[10/24] Train loss=0.3767707943916321
[15/24] Train loss=0.419085830450058
[20/24] Train loss=0.319539874792099
Test set avg_accuracy=67.73% avg_sensitivity=77.73%, avg_specificity=64.38% avg_auc=79.48%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.383376 Test loss=0.560524 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.37534213066101074
[5/24] Train loss=0.3604028820991516
[10/24] Train loss=0.3708277642726898
[15/24] Train loss=0.4061189293861389
[20/24] Train loss=0.31360894441604614
Test set avg_accuracy=64.43% avg_sensitivity=83.07%, avg_specificity=58.17% avg_auc=77.95%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.377549 Test loss=0.582578 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.36925846338272095
[5/24] Train loss=0.36163997650146484
[10/24] Train loss=0.37644049525260925
[15/24] Train loss=0.3847386837005615
[20/24] Train loss=0.3095162808895111
Test set avg_accuracy=62.81% avg_sensitivity=83.69%, avg_specificity=55.80% avg_auc=79.07%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.374480 Test loss=0.588990 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3747188448905945
[5/24] Train loss=0.3661156892776489
[10/24] Train loss=0.3723066449165344
[15/24] Train loss=0.39881759881973267
[20/24] Train loss=0.31113889813423157
Test set avg_accuracy=67.80% avg_sensitivity=78.51%, avg_specificity=64.20% avg_auc=78.63%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.377422 Test loss=0.565070 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.36962419748306274
[5/24] Train loss=0.35440707206726074
[10/24] Train loss=0.3726392388343811
[15/24] Train loss=0.39907604455947876
[20/24] Train loss=0.3188458979129791
Test set avg_accuracy=65.62% avg_sensitivity=81.77%, avg_specificity=60.20% avg_auc=80.04%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.378141 Test loss=0.571573 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.37642791867256165
[5/24] Train loss=0.3723640441894531
[10/24] Train loss=0.37816235423088074
[15/24] Train loss=0.38880494236946106
[20/24] Train loss=0.3116409480571747
Test set avg_accuracy=65.81% avg_sensitivity=77.42%, avg_specificity=61.91% avg_auc=76.48%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.377142 Test loss=0.579855 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.36366477608680725
[5/24] Train loss=0.36209604144096375
[10/24] Train loss=0.3730999231338501
[15/24] Train loss=0.40802431106567383
[20/24] Train loss=0.3216259479522705
Test set avg_accuracy=67.77% avg_sensitivity=75.82%, avg_specificity=65.07% avg_auc=76.45%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.379826 Test loss=0.576691 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.38427236676216125
[5/24] Train loss=0.36183440685272217
[10/24] Train loss=0.3777135908603668
[15/24] Train loss=0.39124637842178345
[20/24] Train loss=0.30956679582595825
Test set avg_accuracy=65.43% avg_sensitivity=80.32%, avg_specificity=60.43% avg_auc=78.60%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.379296 Test loss=0.571601 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3691146969795227
[5/24] Train loss=0.3564721643924713
[10/24] Train loss=0.37085872888565063
[15/24] Train loss=0.3983432650566101
[20/24] Train loss=0.3140210509300232
Test set avg_accuracy=62.12% avg_sensitivity=85.19%, avg_specificity=54.37% avg_auc=78.25%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.375082 Test loss=0.592199 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3702710270881653
[5/24] Train loss=0.3574245572090149
[10/24] Train loss=0.3722688853740692
[15/24] Train loss=0.39306965470314026
[20/24] Train loss=0.31316059827804565
Test set avg_accuracy=63.92% avg_sensitivity=82.70%, avg_specificity=57.61% avg_auc=79.11%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.375942 Test loss=0.581163 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3682977259159088
[5/24] Train loss=0.35642555356025696
[10/24] Train loss=0.37416374683380127
[15/24] Train loss=0.4146736264228821
[20/24] Train loss=0.310924232006073
Test set avg_accuracy=64.58% avg_sensitivity=82.96%, avg_specificity=58.41% avg_auc=79.50%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.377493 Test loss=0.575353 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3678962290287018
[5/24] Train loss=0.35132020711898804
[10/24] Train loss=0.3724682629108429
[15/24] Train loss=0.3924661874771118
[20/24] Train loss=0.3093980848789215
Test set avg_accuracy=62.75% avg_sensitivity=83.38%, avg_specificity=55.82% avg_auc=77.85%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.374905 Test loss=0.590934 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3706519603729248
[5/24] Train loss=0.3543298840522766
[10/24] Train loss=0.369547963142395
[15/24] Train loss=0.3981117904186249
[20/24] Train loss=0.31174030900001526
Test set avg_accuracy=67.14% avg_sensitivity=81.41%, avg_specificity=62.34% avg_auc=80.26%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.374552 Test loss=0.559648 Current lr=[0.000156543481933168]

[0/24] Train loss=0.37150728702545166
[5/24] Train loss=0.3592057228088379
[10/24] Train loss=0.3710373342037201
[15/24] Train loss=0.40406444668769836
[20/24] Train loss=0.31422159075737
Test set avg_accuracy=71.56% avg_sensitivity=78.25%, avg_specificity=69.32% avg_auc=82.45%
Best model saved!! Metric=-24.424570905718497!!
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.375624 Test loss=0.530723 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3689299523830414
[5/24] Train loss=0.359780877828598
[10/24] Train loss=0.3723207712173462
[15/24] Train loss=0.43457674980163574
[20/24] Train loss=0.3251712918281555
Test set avg_accuracy=74.22% avg_sensitivity=73.90%, avg_specificity=74.33% avg_auc=82.59%
Best model saved!! Metric=-20.969911275295317!!
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.379514 Test loss=0.522365 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3686091899871826
[5/24] Train loss=0.36085599660873413
[10/24] Train loss=0.3824004828929901
[15/24] Train loss=0.410469114780426
[20/24] Train loss=0.3153909742832184
Test set avg_accuracy=72.84% avg_sensitivity=76.18%, avg_specificity=71.72% avg_auc=81.29%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.378544 Test loss=0.539362 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.36862343549728394
[5/24] Train loss=0.3559536337852478
[10/24] Train loss=0.37619704008102417
[15/24] Train loss=0.4013988673686981
[20/24] Train loss=0.32790878415107727
Test set avg_accuracy=64.14% avg_sensitivity=81.72%, avg_specificity=58.24% avg_auc=78.36%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.377588 Test loss=0.579588 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.37754833698272705
[5/24] Train loss=0.3550615608692169
[10/24] Train loss=0.3743937611579895
[15/24] Train loss=0.39788028597831726
[20/24] Train loss=0.3082042932510376
Test set avg_accuracy=70.27% avg_sensitivity=77.16%, avg_specificity=67.96% avg_auc=79.85%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.375321 Test loss=0.547280 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3664492666721344
[5/24] Train loss=0.3548981547355652
[10/24] Train loss=0.37453338503837585
[15/24] Train loss=0.38862839341163635
[20/24] Train loss=0.3148241937160492
Test set avg_accuracy=68.82% avg_sensitivity=76.70%, avg_specificity=66.17% avg_auc=79.66%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.372834 Test loss=0.553517 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3730778694152832
[5/24] Train loss=0.35179126262664795
[10/24] Train loss=0.3755638897418976
[15/24] Train loss=0.3970230221748352
[20/24] Train loss=0.3173486292362213
Test set avg_accuracy=69.97% avg_sensitivity=78.40%, avg_specificity=67.14% avg_auc=81.59%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.373984 Test loss=0.548416 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3675138056278229
[5/24] Train loss=0.35267406702041626
[10/24] Train loss=0.3712237775325775
[15/24] Train loss=0.42198997735977173
[20/24] Train loss=0.31053245067596436
Test set avg_accuracy=68.41% avg_sensitivity=79.18%, avg_specificity=64.79% avg_auc=79.79%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.371040 Test loss=0.555766 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3678913116455078
[5/24] Train loss=0.3469199240207672
[10/24] Train loss=0.3668420612812042
[15/24] Train loss=0.3980652093887329
[20/24] Train loss=0.3074668347835541
Test set avg_accuracy=66.11% avg_sensitivity=81.72%, avg_specificity=60.86% avg_auc=80.01%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.370669 Test loss=0.568154 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.36841127276420593
[5/24] Train loss=0.3515397608280182
[10/24] Train loss=0.37184640765190125
[15/24] Train loss=0.38648954033851624
[20/24] Train loss=0.31317877769470215
Test set avg_accuracy=73.12% avg_sensitivity=76.49%, avg_specificity=72.00% avg_auc=80.73%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.370715 Test loss=0.542343 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.37796956300735474
[5/24] Train loss=0.35386982560157776
[10/24] Train loss=0.3748190701007843
[15/24] Train loss=0.39587339758872986
[20/24] Train loss=0.31404444575309753
Test set avg_accuracy=72.81% avg_sensitivity=76.13%, avg_specificity=71.70% avg_auc=81.19%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.371823 Test loss=0.538687 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3648855984210968
[5/24] Train loss=0.3555745482444763
[10/24] Train loss=0.3756735622882843
[15/24] Train loss=0.39422065019607544
[20/24] Train loss=0.3124712109565735
Test set avg_accuracy=70.34% avg_sensitivity=75.71%, avg_specificity=68.53% avg_auc=79.98%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.369468 Test loss=0.543768 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.364473432302475
[5/24] Train loss=0.3470211327075958
[10/24] Train loss=0.37358057498931885
[15/24] Train loss=0.3971170485019684
[20/24] Train loss=0.3125340938568115
Test set avg_accuracy=69.79% avg_sensitivity=79.75%, avg_specificity=66.45% avg_auc=81.02%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.369224 Test loss=0.548900 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3655109107494354
[5/24] Train loss=0.35165759921073914
[10/24] Train loss=0.3692115843296051
[15/24] Train loss=0.38349592685699463
[20/24] Train loss=0.30824223160743713
Test set avg_accuracy=71.35% avg_sensitivity=76.23%, avg_specificity=69.72% avg_auc=80.71%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.366390 Test loss=0.539760 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3685168921947479
[5/24] Train loss=0.34623438119888306
[10/24] Train loss=0.3681422770023346
[15/24] Train loss=0.40176188945770264
[20/24] Train loss=0.32252636551856995
Test set avg_accuracy=73.27% avg_sensitivity=74.68%, avg_specificity=72.80% avg_auc=81.25%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.370704 Test loss=0.531692 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3698144853115082
[5/24] Train loss=0.356081485748291
[10/24] Train loss=0.3703848123550415
[15/24] Train loss=0.4183656573295593
[20/24] Train loss=0.31479671597480774
Test set avg_accuracy=69.78% avg_sensitivity=77.63%, avg_specificity=67.14% avg_auc=80.51%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.372241 Test loss=0.546612 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3642180860042572
[5/24] Train loss=0.3504811227321625
[10/24] Train loss=0.3709377348423004
[15/24] Train loss=0.3946312963962555
[20/24] Train loss=0.3087603449821472
Test set avg_accuracy=70.09% avg_sensitivity=79.34%, avg_specificity=66.99% avg_auc=81.30%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.366812 Test loss=0.543534 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.366382896900177
[5/24] Train loss=0.3467969000339508
[10/24] Train loss=0.3690274655818939
[15/24] Train loss=0.3889866769313812
[20/24] Train loss=0.31178373098373413
Test set avg_accuracy=69.17% avg_sensitivity=78.51%, avg_specificity=66.03% avg_auc=80.48%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.367128 Test loss=0.547941 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.36180830001831055
[5/24] Train loss=0.345103919506073
[10/24] Train loss=0.36825188994407654
[15/24] Train loss=0.38914236426353455
[20/24] Train loss=0.3056352138519287
Test set avg_accuracy=68.42% avg_sensitivity=79.39%, avg_specificity=64.74% avg_auc=80.00%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.364201 Test loss=0.554596 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.36128801107406616
[5/24] Train loss=0.34518149495124817
[10/24] Train loss=0.3661433756351471
[15/24] Train loss=0.3764110207557678
[20/24] Train loss=0.3084070086479187
Test set avg_accuracy=68.52% avg_sensitivity=78.97%, avg_specificity=65.00% avg_auc=80.12%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.362157 Test loss=0.552301 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.36085596680641174
[5/24] Train loss=0.342698872089386
[10/24] Train loss=0.36760473251342773
[15/24] Train loss=0.3861638009548187
[20/24] Train loss=0.30589988827705383
Test set avg_accuracy=69.02% avg_sensitivity=76.54%, avg_specificity=66.50% avg_auc=79.49%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.362102 Test loss=0.551096 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.35886150598526
[5/24] Train loss=0.3448711931705475
[10/24] Train loss=0.36883655190467834
[15/24] Train loss=0.37446659803390503
[20/24] Train loss=0.30630406737327576
Test set avg_accuracy=67.53% avg_sensitivity=80.48%, avg_specificity=63.18% avg_auc=79.88%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.361789 Test loss=0.559493 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3595546782016754
[5/24] Train loss=0.3440331518650055
[10/24] Train loss=0.3667353391647339
[15/24] Train loss=0.37945786118507385
[20/24] Train loss=0.305343896150589
Test set avg_accuracy=68.82% avg_sensitivity=77.16%, avg_specificity=66.01% avg_auc=78.99%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.361357 Test loss=0.555999 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3577239513397217
[5/24] Train loss=0.34335029125213623
[10/24] Train loss=0.3675878942012787
[15/24] Train loss=0.3733363151550293
[20/24] Train loss=0.3103010058403015
Test set avg_accuracy=69.93% avg_sensitivity=76.39%, avg_specificity=67.77% avg_auc=78.66%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.361368 Test loss=0.555577 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.35644179582595825
[5/24] Train loss=0.3420935571193695
[10/24] Train loss=0.3675701320171356
[15/24] Train loss=0.3784809410572052
[20/24] Train loss=0.30581408739089966
Test set avg_accuracy=69.15% avg_sensitivity=76.39%, avg_specificity=66.72% avg_auc=79.02%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.361084 Test loss=0.555523 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.358193039894104
[5/24] Train loss=0.3448927104473114
[10/24] Train loss=0.3692706227302551
[15/24] Train loss=0.37128743529319763
[20/24] Train loss=0.30766764283180237
Test set avg_accuracy=70.23% avg_sensitivity=76.28%, avg_specificity=68.20% avg_auc=78.58%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.360374 Test loss=0.554002 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3576430678367615
[5/24] Train loss=0.3427477777004242
[10/24] Train loss=0.3676002621650696
[15/24] Train loss=0.3764151334762573
[20/24] Train loss=0.3077987730503082
Test set avg_accuracy=70.99% avg_sensitivity=75.56%, avg_specificity=69.46% avg_auc=77.96%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.360604 Test loss=0.556009 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.35485824942588806
[5/24] Train loss=0.3447880744934082
[10/24] Train loss=0.36977294087409973
[15/24] Train loss=0.37591221928596497
[20/24] Train loss=0.3060341775417328
Test set avg_accuracy=69.91% avg_sensitivity=76.54%, avg_specificity=67.68% avg_auc=78.86%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.360470 Test loss=0.553995 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3578788936138153
[5/24] Train loss=0.34129971265792847
[10/24] Train loss=0.36839938163757324
[15/24] Train loss=0.37654909491539
[20/24] Train loss=0.30481746792793274
Test set avg_accuracy=69.92% avg_sensitivity=76.49%, avg_specificity=67.72% avg_auc=78.13%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.359884 Test loss=0.560357 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3580551743507385
[5/24] Train loss=0.34130918979644775
[10/24] Train loss=0.3682694137096405
[15/24] Train loss=0.37456750869750977
[20/24] Train loss=0.3039690852165222
Test set avg_accuracy=69.54% avg_sensitivity=76.23%, avg_specificity=67.30% avg_auc=78.22%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.359884 Test loss=0.559648 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3595755398273468
[5/24] Train loss=0.34003210067749023
[10/24] Train loss=0.3675704598426819
[15/24] Train loss=0.3805748224258423
[20/24] Train loss=0.30866503715515137
Test set avg_accuracy=68.95% avg_sensitivity=76.85%, avg_specificity=66.29% avg_auc=78.36%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.360190 Test loss=0.561526 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3575589060783386
[5/24] Train loss=0.34032371640205383
[10/24] Train loss=0.3693491220474243
[15/24] Train loss=0.37518489360809326
[20/24] Train loss=0.3031065762042999
Test set avg_accuracy=70.34% avg_sensitivity=75.56%, avg_specificity=68.59% avg_auc=77.28%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.360144 Test loss=0.562939 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.36173880100250244
[5/24] Train loss=0.34232357144355774
[10/24] Train loss=0.36778900027275085
[15/24] Train loss=0.3725660443305969
[20/24] Train loss=0.30394938588142395
Test set avg_accuracy=67.97% avg_sensitivity=77.63%, avg_specificity=64.72% avg_auc=78.28%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.360198 Test loss=0.562470 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3571522831916809
[5/24] Train loss=0.3424818813800812
[10/24] Train loss=0.3674421012401581
[15/24] Train loss=0.3799408972263336
[20/24] Train loss=0.30737027525901794
Test set avg_accuracy=67.75% avg_sensitivity=79.03%, avg_specificity=63.96% avg_auc=78.57%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.359448 Test loss=0.564149 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3605157136917114
[5/24] Train loss=0.3420330882072449
[10/24] Train loss=0.36848270893096924
[15/24] Train loss=0.3722502589225769
[20/24] Train loss=0.3026654124259949
Test set avg_accuracy=68.18% avg_sensitivity=77.11%, avg_specificity=65.18% avg_auc=77.86%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.359528 Test loss=0.564621 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.35800278186798096
[5/24] Train loss=0.34180280566215515
[10/24] Train loss=0.367180198431015
[15/24] Train loss=0.37505432963371277
[20/24] Train loss=0.3079681694507599
Test set avg_accuracy=68.01% avg_sensitivity=77.84%, avg_specificity=64.71% avg_auc=78.17%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.358958 Test loss=0.564115 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.35872721672058105
[5/24] Train loss=0.34122928977012634
[10/24] Train loss=0.36833685636520386
[15/24] Train loss=0.37951329350471497
[20/24] Train loss=0.30109649896621704
Test set avg_accuracy=67.25% avg_sensitivity=78.46%, avg_specificity=63.49% avg_auc=78.96%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.358754 Test loss=0.563499 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.3567214608192444
[5/24] Train loss=0.34285396337509155
[10/24] Train loss=0.3652240037918091
[15/24] Train loss=0.3705418109893799
[20/24] Train loss=0.3034702241420746
Test set avg_accuracy=67.86% avg_sensitivity=78.51%, avg_specificity=64.29% avg_auc=78.41%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.357935 Test loss=0.564093 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.3553731441497803
[5/24] Train loss=0.3398607075214386
[10/24] Train loss=0.3652697503566742
[15/24] Train loss=0.37200644612312317
[20/24] Train loss=0.3014588952064514
Test set avg_accuracy=67.72% avg_sensitivity=79.44%, avg_specificity=63.79% avg_auc=79.01%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.356878 Test loss=0.562926 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.35480615496635437
[5/24] Train loss=0.3407822549343109
[10/24] Train loss=0.3650512993335724
[15/24] Train loss=0.37071332335472107
[20/24] Train loss=0.3031701147556305
Test set avg_accuracy=67.33% avg_sensitivity=79.54%, avg_specificity=63.23% avg_auc=78.74%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.356351 Test loss=0.566149 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3532412648200989
[5/24] Train loss=0.33902236819267273
[10/24] Train loss=0.3646338880062103
[15/24] Train loss=0.3669217526912689
[20/24] Train loss=0.3015623986721039
Test set avg_accuracy=67.72% avg_sensitivity=79.13%, avg_specificity=63.89% avg_auc=78.90%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.355452 Test loss=0.563006 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.3533053994178772
[5/24] Train loss=0.33878016471862793
[10/24] Train loss=0.364675372838974
[15/24] Train loss=0.3659616708755493
[20/24] Train loss=0.3019355237483978
Test set avg_accuracy=67.36% avg_sensitivity=79.18%, avg_specificity=63.38% avg_auc=78.86%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.355188 Test loss=0.564730 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.3532126247882843
[5/24] Train loss=0.33868733048439026
[10/24] Train loss=0.3646319806575775
[15/24] Train loss=0.36597782373428345
[20/24] Train loss=0.3017009198665619
Test set avg_accuracy=67.40% avg_sensitivity=79.18%, avg_specificity=63.44% avg_auc=78.83%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.355050 Test loss=0.564466 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3531263768672943
[5/24] Train loss=0.33843857049942017
[10/24] Train loss=0.36458322405815125
[15/24] Train loss=0.3659649193286896
[20/24] Train loss=0.3016815781593323
Test set avg_accuracy=67.54% avg_sensitivity=79.18%, avg_specificity=63.63% avg_auc=78.82%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.354951 Test loss=0.564525 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3530089259147644
[5/24] Train loss=0.3383239209651947
[10/24] Train loss=0.36448976397514343
[15/24] Train loss=0.3658851683139801
[20/24] Train loss=0.3016579747200012
Test set avg_accuracy=67.46% avg_sensitivity=79.18%, avg_specificity=63.52% avg_auc=78.80%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.354851 Test loss=0.564760 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.352968692779541
[5/24] Train loss=0.33827975392341614
[10/24] Train loss=0.36448028683662415
[15/24] Train loss=0.36583590507507324
[20/24] Train loss=0.30158764123916626
Test set avg_accuracy=67.38% avg_sensitivity=79.18%, avg_specificity=63.42% avg_auc=78.78%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.354780 Test loss=0.564899 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.35291871428489685
[5/24] Train loss=0.33819442987442017
[10/24] Train loss=0.3644568920135498
[15/24] Train loss=0.36580440402030945
[20/24] Train loss=0.301533967256546
Test set avg_accuracy=67.38% avg_sensitivity=79.18%, avg_specificity=63.42% avg_auc=78.77%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.354722 Test loss=0.565041 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.35287606716156006
[5/24] Train loss=0.3381252586841583
[10/24] Train loss=0.3644397258758545
[15/24] Train loss=0.3657696545124054
[20/24] Train loss=0.301485151052475
Test set avg_accuracy=67.38% avg_sensitivity=79.18%, avg_specificity=63.42% avg_auc=78.75%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.354672 Test loss=0.565147 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.35284602642059326
[5/24] Train loss=0.3380691111087799
[10/24] Train loss=0.3644287884235382
[15/24] Train loss=0.36572808027267456
[20/24] Train loss=0.3014477789402008
Test set avg_accuracy=67.36% avg_sensitivity=79.18%, avg_specificity=63.38% avg_auc=78.75%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.354634 Test loss=0.565205 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.35282278060913086
[5/24] Train loss=0.33803069591522217
[10/24] Train loss=0.36441317200660706
[15/24] Train loss=0.3656989336013794
[20/24] Train loss=0.3014223873615265
Test set avg_accuracy=67.37% avg_sensitivity=79.23%, avg_specificity=63.38% avg_auc=78.74%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.354605 Test loss=0.565259 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.35280686616897583
[5/24] Train loss=0.33800485730171204
[10/24] Train loss=0.36440062522888184
[15/24] Train loss=0.36567753553390503
[20/24] Train loss=0.3014034926891327
Test set avg_accuracy=67.37% avg_sensitivity=79.23%, avg_specificity=63.38% avg_auc=78.74%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.354584 Test loss=0.565306 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3527964949607849
[5/24] Train loss=0.3379877805709839
[10/24] Train loss=0.36439159512519836
[15/24] Train loss=0.36566293239593506
[20/24] Train loss=0.30139094591140747
Test set avg_accuracy=67.37% avg_sensitivity=79.23%, avg_specificity=63.38% avg_auc=78.74%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.354571 Test loss=0.565338 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.352790504693985
[5/24] Train loss=0.3379780054092407
[10/24] Train loss=0.3643854856491089
[15/24] Train loss=0.3656540811061859
[20/24] Train loss=0.30138322710990906
Test set avg_accuracy=67.37% avg_sensitivity=79.23%, avg_specificity=63.38% avg_auc=78.73%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.354563 Test loss=0.565358 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.35278764367103577
[5/24] Train loss=0.3379732370376587
[10/24] Train loss=0.36438217759132385
[15/24] Train loss=0.3656500577926636
[20/24] Train loss=0.3013801872730255
Test set avg_accuracy=67.37% avg_sensitivity=79.23%, avg_specificity=63.38% avg_auc=78.73%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.354560 Test loss=0.565366 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=74.22% sen=73.90%, spe=74.33%, auc=82.59%!
Fold[8] Avg_overlap=0.57%(0.23604405965732864)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 1,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'SwEDModel',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/23] Train loss=0.6813361048698425
[5/23] Train loss=0.6811361908912659
[10/23] Train loss=0.6798556447029114
[15/23] Train loss=0.6799697875976562
[20/23] Train loss=0.6788312196731567
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.02%
Best model saved!! Metric=-100.13224444744901!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.680656 Test loss=0.678792 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.6783044338226318
[5/23] Train loss=0.6782395243644714
[10/23] Train loss=0.676861584186554
[15/23] Train loss=0.6769464015960693
[20/23] Train loss=0.675571084022522
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.15%
Best model saved!! Metric=-99.99919029615856!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.677765 Test loss=0.675649 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.6751434803009033
[5/23] Train loss=0.6751534938812256
[10/23] Train loss=0.6737123131752014
[15/23] Train loss=0.6736263036727905
[20/23] Train loss=0.6720860600471497
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.15%
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.674679 Test loss=0.672150 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.6717101335525513
[5/23] Train loss=0.671671450138092
[10/23] Train loss=0.6700013279914856
[15/23] Train loss=0.6696428060531616
[20/23] Train loss=0.6677291989326477
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.24%
Best model saved!! Metric=-99.9164675771414!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.671055 Test loss=0.667788 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.667323112487793
[5/23] Train loss=0.6671434044837952
[10/23] Train loss=0.665218710899353
[15/23] Train loss=0.6644265651702881
[20/23] Train loss=0.6622458696365356
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.46%
Best model saved!! Metric=-99.69778937300688!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.666396 Test loss=0.662210 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.6618016958236694
[5/23] Train loss=0.6613903641700745
[10/23] Train loss=0.6589615345001221
[15/23] Train loss=0.6575689315795898
[20/23] Train loss=0.6549845337867737
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.47%
Best model saved!! Metric=-99.68432847970146!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.660332 Test loss=0.654695 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.6544649004936218
[5/23] Train loss=0.6536558270454407
[10/23] Train loss=0.650888204574585
[15/23] Train loss=0.6487993001937866
[20/23] Train loss=0.6454911828041077
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.86%
Best model saved!! Metric=-99.28943704835365!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.652520 Test loss=0.645177 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.6451945304870605
[5/23] Train loss=0.6439007520675659
[10/23] Train loss=0.6407940983772278
[15/23] Train loss=0.6374606490135193
[20/23] Train loss=0.6331398487091064
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.22%
Best model saved!! Metric=-98.92982435559657!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.642630 Test loss=0.633124 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.6334057450294495
[5/23] Train loss=0.6313155889511108
[10/23] Train loss=0.6280888915061951
[15/23] Train loss=0.623084545135498
[20/23] Train loss=0.6174569725990295
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.47%
Best model saved!! Metric=-98.68006439816797!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.630240 Test loss=0.618202 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.6186907887458801
[5/23] Train loss=0.6156628727912903
[10/23] Train loss=0.6126559376716614
[15/23] Train loss=0.6055249571800232
[20/23] Train loss=0.5982362627983093
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.82%
Best model saved!! Metric=-98.33768849728531!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.615327 Test loss=0.600787 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.6017564535140991
[5/23] Train loss=0.5971575975418091
[10/23] Train loss=0.5957750678062439
[15/23] Train loss=0.5853874087333679
[20/23] Train loss=0.5777124166488647
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.49%
Best model saved!! Metric=-97.66350550965186!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.599303 Test loss=0.583078 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.5859605669975281
[5/23] Train loss=0.5788269639015198
[10/23] Train loss=0.583244264125824
[15/23] Train loss=0.5691889524459839
[20/23] Train loss=0.5624866485595703
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=53.48%
Best model saved!! Metric=-96.67697334394728!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.586433 Test loss=0.570243 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.5756179094314575
[5/23] Train loss=0.5668712854385376
[10/23] Train loss=0.5751492381095886
[15/23] Train loss=0.5586060881614685
[20/23] Train loss=0.5524763464927673
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.71%
Best model saved!! Metric=-95.44366584652123!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.577305 Test loss=0.561549 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.5676947832107544
[5/23] Train loss=0.5585979223251343
[10/23] Train loss=0.5689261555671692
[15/23] Train loss=0.5508055686950684
[20/23] Train loss=0.5432136058807373
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=57.01%
Best model saved!! Metric=-93.13911834122871!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.570304 Test loss=0.554458 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.5619903802871704
[5/23] Train loss=0.5493608713150024
[10/23] Train loss=0.5645706653594971
[15/23] Train loss=0.5455616116523743
[20/23] Train loss=0.5370697975158691
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=60.58%
Best model saved!! Metric=-89.5744526077396!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.565651 Test loss=0.550154 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.5589393973350525
[5/23] Train loss=0.546332836151123
[10/23] Train loss=0.5622686147689819
[15/23] Train loss=0.5394761562347412
[20/23] Train loss=0.5300764441490173
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=65.50%
Best model saved!! Metric=-84.6509955319787!!
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.561914 Test loss=0.547956 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.5556483268737793
[5/23] Train loss=0.5412447452545166
[10/23] Train loss=0.5599321126937866
[15/23] Train loss=0.5331867933273315
[20/23] Train loss=0.5226508378982544
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=69.65%
Best model saved!! Metric=-80.50681728735506!!
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.556744 Test loss=0.542852 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.5470802783966064
[5/23] Train loss=0.5356371402740479
[10/23] Train loss=0.5548434257507324
[15/23] Train loss=0.5211766958236694
[20/23] Train loss=0.5083916783332825
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=74.14%
Best model saved!! Metric=-76.008889172875!!
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.547576 Test loss=0.541867 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.5325121879577637
[5/23] Train loss=0.5231434106826782
[10/23] Train loss=0.5417823791503906
[15/23] Train loss=0.5028170347213745
[20/23] Train loss=0.4866221249103546
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=74.35%
Best model saved!! Metric=-75.80762822635535!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.532952 Test loss=0.621342 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.5136582255363464
[5/23] Train loss=0.5146165490150452
[10/23] Train loss=0.5255205631256104
[15/23] Train loss=0.4792328178882599
[20/23] Train loss=0.47644680738449097
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.68%
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.515476 Test loss=0.680283 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.5085278749465942
[5/23] Train loss=0.5027890205383301
[10/23] Train loss=0.5143923163414001
[15/23] Train loss=0.46701598167419434
[20/23] Train loss=0.47062987089157104
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=53.72%
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.506090 Test loss=0.661876 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.49099037051200867
[5/23] Train loss=0.4961962401866913
[10/23] Train loss=0.4979448616504669
[15/23] Train loss=0.4567367732524872
[20/23] Train loss=0.4643304646015167
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=53.36%
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.495390 Test loss=0.650301 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.4786590337753296
[5/23] Train loss=0.48731422424316406
[10/23] Train loss=0.4889284074306488
[15/23] Train loss=0.45334506034851074
[20/23] Train loss=0.46550416946411133
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.38%
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.487303 Test loss=0.650070 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.47641900181770325
[5/23] Train loss=0.4899691343307495
[10/23] Train loss=0.4896003305912018
[15/23] Train loss=0.4515964090824127
[20/23] Train loss=0.4592057466506958
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=56.29%
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.485165 Test loss=0.652386 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.4674091339111328
[5/23] Train loss=0.4893184006214142
[10/23] Train loss=0.4857616722583771
[15/23] Train loss=0.4483042061328888
[20/23] Train loss=0.4603261649608612
Test set avg_accuracy=73.91% avg_sensitivity=5.77%, avg_specificity=95.61% avg_auc=59.13%
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.483482 Test loss=0.648797 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.4677058458328247
[5/23] Train loss=0.4880003333091736
[10/23] Train loss=0.4845287501811981
[15/23] Train loss=0.44330477714538574
[20/23] Train loss=0.4578813910484314
Test set avg_accuracy=46.56% avg_sensitivity=52.94%, avg_specificity=44.53% avg_auc=57.31%
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.477789 Test loss=0.660676 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.45829853415489197
[5/23] Train loss=0.4827718436717987
[10/23] Train loss=0.4777766168117523
[15/23] Train loss=0.44008320569992065
[20/23] Train loss=0.45061761140823364
Test set avg_accuracy=36.74% avg_sensitivity=84.69%, avg_specificity=21.48% avg_auc=57.70%
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.472963 Test loss=0.670165 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.4538423418998718
[5/23] Train loss=0.47641921043395996
[10/23] Train loss=0.4707377254962921
[15/23] Train loss=0.4377896785736084
[20/23] Train loss=0.43652066588401794
Test set avg_accuracy=40.64% avg_sensitivity=77.47%, avg_specificity=28.91% avg_auc=59.83%
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.468278 Test loss=0.659996 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.44749730825424194
[5/23] Train loss=0.47101378440856934
[10/23] Train loss=0.4629650413990021
[15/23] Train loss=0.4300173223018646
[20/23] Train loss=0.4330424666404724
Test set avg_accuracy=34.88% avg_sensitivity=90.35%, avg_specificity=17.22% avg_auc=61.36%
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.462809 Test loss=0.675879 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.443042516708374
[5/23] Train loss=0.46384382247924805
[10/23] Train loss=0.46304795145988464
[15/23] Train loss=0.4207989573478699
[20/23] Train loss=0.4078119099140167
Test set avg_accuracy=37.85% avg_sensitivity=91.37%, avg_specificity=20.81% avg_auc=64.78%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.453273 Test loss=0.668187 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.4290663003921509
[5/23] Train loss=0.461527019739151
[10/23] Train loss=0.447336345911026
[15/23] Train loss=0.40795066952705383
[20/23] Train loss=0.39769890904426575
Test set avg_accuracy=40.57% avg_sensitivity=89.54%, avg_specificity=24.98% avg_auc=67.70%
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.440257 Test loss=0.666769 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.4194681942462921
[5/23] Train loss=0.4344857633113861
[10/23] Train loss=0.43212535977363586
[15/23] Train loss=0.39135316014289856
[20/23] Train loss=0.39171525835990906
Test set avg_accuracy=35.99% avg_sensitivity=93.32%, avg_specificity=17.73% avg_auc=66.07%
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.427556 Test loss=0.705318 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.4264019727706909
[5/23] Train loss=0.43942537903785706
[10/23] Train loss=0.41790786385536194
[15/23] Train loss=0.38622772693634033
[20/23] Train loss=0.37519699335098267
Test set avg_accuracy=35.81% avg_sensitivity=94.23%, avg_specificity=17.20% avg_auc=65.97%
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.417713 Test loss=0.699512 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.3997827172279358
[5/23] Train loss=0.4200674295425415
[10/23] Train loss=0.4059753715991974
[15/23] Train loss=0.38509970903396606
[20/23] Train loss=0.3783712685108185
Test set avg_accuracy=52.27% avg_sensitivity=81.67%, avg_specificity=42.90% avg_auc=69.00%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.414455 Test loss=0.640336 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.40043923258781433
[5/23] Train loss=0.4306304454803467
[10/23] Train loss=0.40389764308929443
[15/23] Train loss=0.38358965516090393
[20/23] Train loss=0.36363640427589417
Test set avg_accuracy=48.72% avg_sensitivity=83.94%, avg_specificity=37.51% avg_auc=70.30%
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.414459 Test loss=0.649503 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.3888716697692871
[5/23] Train loss=0.4178706705570221
[10/23] Train loss=0.39989981055259705
[15/23] Train loss=0.3758511245250702
[20/23] Train loss=0.3713347613811493
Test set avg_accuracy=43.79% avg_sensitivity=89.60%, avg_specificity=29.20% avg_auc=69.63%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.407958 Test loss=0.674085 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.390304297208786
[5/23] Train loss=0.425628125667572
[10/23] Train loss=0.40124234557151794
[15/23] Train loss=0.3877173960208893
[20/23] Train loss=0.37212464213371277
Test set avg_accuracy=59.02% avg_sensitivity=81.73%, avg_specificity=51.79% avg_auc=73.02%
Best model saved!! Metric=-60.440546859635845!!
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.410178 Test loss=0.621728 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.387513130903244
[5/23] Train loss=0.42364805936813354
[10/23] Train loss=0.3970038890838623
[15/23] Train loss=0.3779227137565613
[20/23] Train loss=0.38055548071861267
Test set avg_accuracy=54.45% avg_sensitivity=85.50%, avg_specificity=44.57% avg_auc=72.40%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.411411 Test loss=0.633975 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.3981916010379791
[5/23] Train loss=0.4268864393234253
[10/23] Train loss=0.39435020089149475
[15/23] Train loss=0.3781132996082306
[20/23] Train loss=0.3524772822856903
Test set avg_accuracy=50.60% avg_sensitivity=86.47%, avg_specificity=39.18% avg_auc=70.64%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.405901 Test loss=0.644787 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.38281500339508057
[5/23] Train loss=0.40894120931625366
[10/23] Train loss=0.3918771743774414
[15/23] Train loss=0.3757779002189636
[20/23] Train loss=0.35323742032051086
Test set avg_accuracy=56.33% avg_sensitivity=83.02%, avg_specificity=47.83% avg_auc=69.22%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.400446 Test loss=0.641441 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.3859100043773651
[5/23] Train loss=0.407304972410202
[10/23] Train loss=0.3908224403858185
[15/23] Train loss=0.3689034879207611
[20/23] Train loss=0.3478943705558777
Test set avg_accuracy=44.22% avg_sensitivity=89.16%, avg_specificity=29.91% avg_auc=70.79%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.398121 Test loss=0.671275 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.3770734369754791
[5/23] Train loss=0.40629515051841736
[10/23] Train loss=0.38765087723731995
[15/23] Train loss=0.37410998344421387
[20/23] Train loss=0.35880541801452637
Test set avg_accuracy=58.61% avg_sensitivity=79.57%, avg_specificity=51.93% avg_auc=72.89%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.400278 Test loss=0.624101 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.37998855113983154
[5/23] Train loss=0.40360110998153687
[10/23] Train loss=0.40156805515289307
[15/23] Train loss=0.3740326166152954
[20/23] Train loss=0.3553145229816437
Test set avg_accuracy=56.09% avg_sensitivity=85.44%, avg_specificity=46.75% avg_auc=73.81%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.398294 Test loss=0.633745 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.376005083322525
[5/23] Train loss=0.40275701880455017
[10/23] Train loss=0.3956359028816223
[15/23] Train loss=0.4015166163444519
[20/23] Train loss=0.3482419550418854
Test set avg_accuracy=57.21% avg_sensitivity=83.94%, avg_specificity=48.70% avg_auc=73.76%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.400501 Test loss=0.630154 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.3763243556022644
[5/23] Train loss=0.4065929055213928
[10/23] Train loss=0.3926948308944702
[15/23] Train loss=0.37105536460876465
[20/23] Train loss=0.3566564619541168
Test set avg_accuracy=63.42% avg_sensitivity=74.72%, avg_specificity=59.83% avg_auc=73.05%
Best model saved!! Metric=-54.97693679529672!!
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.396433 Test loss=0.603701 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.3750844895839691
[5/23] Train loss=0.40076637268066406
[10/23] Train loss=0.3868608772754669
[15/23] Train loss=0.36359962821006775
[20/23] Train loss=0.34314286708831787
Test set avg_accuracy=54.02% avg_sensitivity=85.12%, avg_specificity=44.12% avg_auc=69.99%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.389844 Test loss=0.646967 Current lr=[0.000299926900870094]

[0/23] Train loss=0.3719220757484436
[5/23] Train loss=0.3946458697319031
[10/23] Train loss=0.38909128308296204
[15/23] Train loss=0.36257949471473694
[20/23] Train loss=0.3583971858024597
Test set avg_accuracy=66.63% avg_sensitivity=73.37%, avg_specificity=64.48% avg_auc=72.42%
Best model saved!! Metric=-49.101303899920566!!
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.392376 Test loss=0.593900 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.3754403293132782
[5/23] Train loss=0.40637025237083435
[10/23] Train loss=0.39398452639579773
[15/23] Train loss=0.3739740550518036
[20/23] Train loss=0.3487156629562378
Test set avg_accuracy=61.97% avg_sensitivity=80.81%, avg_specificity=55.97% avg_auc=75.48%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.396190 Test loss=0.608414 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.3776589632034302
[5/23] Train loss=0.4046935737133026
[10/23] Train loss=0.393924742937088
[15/23] Train loss=0.3679918348789215
[20/23] Train loss=0.3481549620628357
Test set avg_accuracy=65.85% avg_sensitivity=70.13%, avg_specificity=64.48% avg_auc=73.39%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.394345 Test loss=0.589883 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.37350916862487793
[5/23] Train loss=0.3947492241859436
[10/23] Train loss=0.3866663873195648
[15/23] Train loss=0.3659107983112335
[20/23] Train loss=0.3485725224018097
Test set avg_accuracy=63.10% avg_sensitivity=75.31%, avg_specificity=59.21% avg_auc=73.38%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.390712 Test loss=0.596393 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.37134578824043274
[5/23] Train loss=0.40385597944259644
[10/23] Train loss=0.3840218782424927
[15/23] Train loss=0.3666325509548187
[20/23] Train loss=0.34557008743286133
Test set avg_accuracy=65.04% avg_sensitivity=72.94%, avg_specificity=62.52% avg_auc=75.17%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.394176 Test loss=0.587502 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.3692818880081177
[5/23] Train loss=0.40460410714149475
[10/23] Train loss=0.38300496339797974
[15/23] Train loss=0.376033753156662
[20/23] Train loss=0.349190354347229
Test set avg_accuracy=58.16% avg_sensitivity=84.15%, avg_specificity=49.89% avg_auc=75.04%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.393863 Test loss=0.621636 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.36816444993019104
[5/23] Train loss=0.3999694287776947
[10/23] Train loss=0.38236168026924133
[15/23] Train loss=0.36712247133255005
[20/23] Train loss=0.34054070711135864
Test set avg_accuracy=61.17% avg_sensitivity=80.70%, avg_specificity=54.95% avg_auc=74.36%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.390453 Test loss=0.607852 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.37052226066589355
[5/23] Train loss=0.390974223613739
[10/23] Train loss=0.3809410333633423
[15/23] Train loss=0.3748908042907715
[20/23] Train loss=0.33563411235809326
Test set avg_accuracy=61.69% avg_sensitivity=80.00%, avg_specificity=55.86% avg_auc=75.37%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.393626 Test loss=0.607276 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.36892205476760864
[5/23] Train loss=0.38761764764785767
[10/23] Train loss=0.37782418727874756
[15/23] Train loss=0.3848317265510559
[20/23] Train loss=0.3414689600467682
Test set avg_accuracy=60.81% avg_sensitivity=79.14%, avg_specificity=54.97% avg_auc=74.74%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.387167 Test loss=0.608053 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.37126657366752625
[5/23] Train loss=0.4083329439163208
[10/23] Train loss=0.391533225774765
[15/23] Train loss=0.36457711458206177
[20/23] Train loss=0.3359035849571228
Test set avg_accuracy=56.59% avg_sensitivity=83.99%, avg_specificity=47.86% avg_auc=74.35%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.391290 Test loss=0.623209 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.3663066327571869
[5/23] Train loss=0.3865484893321991
[10/23] Train loss=0.39097362756729126
[15/23] Train loss=0.37048131227493286
[20/23] Train loss=0.3332684338092804
Test set avg_accuracy=58.66% avg_sensitivity=83.02%, avg_specificity=50.90% avg_auc=74.53%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.383998 Test loss=0.621898 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.3646884858608246
[5/23] Train loss=0.38245946168899536
[10/23] Train loss=0.3753852844238281
[15/23] Train loss=0.3643780052661896
[20/23] Train loss=0.3389700651168823
Test set avg_accuracy=58.01% avg_sensitivity=83.23%, avg_specificity=49.97% avg_auc=74.25%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.385259 Test loss=0.623562 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.3646247386932373
[5/23] Train loss=0.3932722806930542
[10/23] Train loss=0.3684711158275604
[15/23] Train loss=0.3844090700149536
[20/23] Train loss=0.3551482558250427
Test set avg_accuracy=57.57% avg_sensitivity=84.37%, avg_specificity=49.03% avg_auc=74.75%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.390971 Test loss=0.620787 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.39992937445640564
[5/23] Train loss=0.39960798621177673
[10/23] Train loss=0.3850647211074829
[15/23] Train loss=0.3654515743255615
[20/23] Train loss=0.330476850271225
Test set avg_accuracy=57.60% avg_sensitivity=84.53%, avg_specificity=49.03% avg_auc=73.29%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.387267 Test loss=0.630892 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.36225059628486633
[5/23] Train loss=0.3840191662311554
[10/23] Train loss=0.3645345866680145
[15/23] Train loss=0.3646277189254761
[20/23] Train loss=0.33673766255378723
Test set avg_accuracy=58.62% avg_sensitivity=84.10%, avg_specificity=50.51% avg_auc=74.60%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.381861 Test loss=0.621176 Current lr=[0.000283047938381597]

[0/23] Train loss=0.36882853507995605
[5/23] Train loss=0.39114248752593994
[10/23] Train loss=0.3619919717311859
[15/23] Train loss=0.35691308975219727
[20/23] Train loss=0.3246287405490875
Test set avg_accuracy=62.41% avg_sensitivity=80.22%, avg_specificity=56.74% avg_auc=71.93%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.377383 Test loss=0.620592 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.3613405227661133
[5/23] Train loss=0.3810444176197052
[10/23] Train loss=0.37819960713386536
[15/23] Train loss=0.37450942397117615
[20/23] Train loss=0.3345838487148285
Test set avg_accuracy=60.16% avg_sensitivity=82.86%, avg_specificity=52.93% avg_auc=74.82%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.380448 Test loss=0.622801 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.36603909730911255
[5/23] Train loss=0.38938531279563904
[10/23] Train loss=0.3642943203449249
[15/23] Train loss=0.36279934644699097
[20/23] Train loss=0.33281630277633667
Test set avg_accuracy=57.96% avg_sensitivity=82.37%, avg_specificity=50.18% avg_auc=71.96%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.378632 Test loss=0.634694 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.3594224452972412
[5/23] Train loss=0.3768588900566101
[10/23] Train loss=0.3612990975379944
[15/23] Train loss=0.35459208488464355
[20/23] Train loss=0.32685336470603943
Test set avg_accuracy=60.29% avg_sensitivity=81.02%, avg_specificity=53.68% avg_auc=73.65%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.375129 Test loss=0.616742 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.3594724237918854
[5/23] Train loss=0.3868274390697479
[10/23] Train loss=0.365489661693573
[15/23] Train loss=0.3615342676639557
[20/23] Train loss=0.33394941687583923
Test set avg_accuracy=60.09% avg_sensitivity=83.72%, avg_specificity=52.57% avg_auc=76.37%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.379738 Test loss=0.614109 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.3620263636112213
[5/23] Train loss=0.3916333019733429
[10/23] Train loss=0.38364091515541077
[15/23] Train loss=0.386095255613327
[20/23] Train loss=0.3399879038333893
Test set avg_accuracy=62.46% avg_sensitivity=80.86%, avg_specificity=56.60% avg_auc=75.84%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.391670 Test loss=0.605851 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.36557403206825256
[5/23] Train loss=0.39238640666007996
[10/23] Train loss=0.37264204025268555
[15/23] Train loss=0.35941919684410095
[20/23] Train loss=0.32817235589027405
Test set avg_accuracy=56.58% avg_sensitivity=84.47%, avg_specificity=47.69% avg_auc=73.21%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.381394 Test loss=0.634470 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.3671363890171051
[5/23] Train loss=0.3826301097869873
[10/23] Train loss=0.3727363646030426
[15/23] Train loss=0.36195889115333557
[20/23] Train loss=0.3306456506252289
Test set avg_accuracy=59.82% avg_sensitivity=82.53%, avg_specificity=52.58% avg_auc=74.50%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.379644 Test loss=0.619955 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.367181658744812
[5/23] Train loss=0.3898162841796875
[10/23] Train loss=0.3706614077091217
[15/23] Train loss=0.3585619032382965
[20/23] Train loss=0.3310806155204773
Test set avg_accuracy=58.76% avg_sensitivity=81.67%, avg_specificity=51.47% avg_auc=72.55%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.379676 Test loss=0.627187 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.35716700553894043
[5/23] Train loss=0.38387617468833923
[10/23] Train loss=0.3657442033290863
[15/23] Train loss=0.36170294880867004
[20/23] Train loss=0.32407867908477783
Test set avg_accuracy=58.32% avg_sensitivity=82.43%, avg_specificity=50.64% avg_auc=74.08%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.374779 Test loss=0.629365 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.35572656989097595
[5/23] Train loss=0.379984587430954
[10/23] Train loss=0.3634921610355377
[15/23] Train loss=0.35421842336654663
[20/23] Train loss=0.3216632306575775
Test set avg_accuracy=56.48% avg_sensitivity=83.72%, avg_specificity=47.81% avg_auc=72.27%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.372386 Test loss=0.641360 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.35661667585372925
[5/23] Train loss=0.3775121867656708
[10/23] Train loss=0.36170247197151184
[15/23] Train loss=0.35459938645362854
[20/23] Train loss=0.333684504032135
Test set avg_accuracy=58.87% avg_sensitivity=85.39%, avg_specificity=50.42% avg_auc=75.32%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.375186 Test loss=0.622880 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.3711552917957306
[5/23] Train loss=0.39549413323402405
[10/23] Train loss=0.374923974275589
[15/23] Train loss=0.3561939597129822
[20/23] Train loss=0.33018580079078674
Test set avg_accuracy=59.08% avg_sensitivity=85.01%, avg_specificity=50.82% avg_auc=76.57%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.380587 Test loss=0.616369 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.3663131892681122
[5/23] Train loss=0.39720618724823
[10/23] Train loss=0.3755035102367401
[15/23] Train loss=0.37334802746772766
[20/23] Train loss=0.3236539363861084
Test set avg_accuracy=58.72% avg_sensitivity=82.59%, avg_specificity=51.12% avg_auc=72.68%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.379725 Test loss=0.632072 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.36323055624961853
[5/23] Train loss=0.3714681565761566
[10/23] Train loss=0.37066450715065
[15/23] Train loss=0.3542932868003845
[20/23] Train loss=0.3241302967071533
Test set avg_accuracy=56.51% avg_sensitivity=84.69%, avg_specificity=47.54% avg_auc=72.18%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.372450 Test loss=0.637871 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.366604208946228
[5/23] Train loss=0.38885095715522766
[10/23] Train loss=0.38077372312545776
[15/23] Train loss=0.35727235674858093
[20/23] Train loss=0.3365318477153778
Test set avg_accuracy=59.60% avg_sensitivity=81.99%, avg_specificity=52.46% avg_auc=72.53%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.375011 Test loss=0.627901 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.35795536637306213
[5/23] Train loss=0.37286341190338135
[10/23] Train loss=0.36210525035858154
[15/23] Train loss=0.3514300286769867
[20/23] Train loss=0.3225988447666168
Test set avg_accuracy=57.06% avg_sensitivity=86.42%, avg_specificity=47.71% avg_auc=73.24%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.368763 Test loss=0.634934 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.35896843671798706
[5/23] Train loss=0.38403668999671936
[10/23] Train loss=0.36304953694343567
[15/23] Train loss=0.35525721311569214
[20/23] Train loss=0.33038419485092163
Test set avg_accuracy=64.75% avg_sensitivity=81.62%, avg_specificity=59.38% avg_auc=78.26%
Best model saved!! Metric=-41.99082676469851!!
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.374953 Test loss=0.586861 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.36315321922302246
[5/23] Train loss=0.38306525349617004
[10/23] Train loss=0.37632715702056885
[15/23] Train loss=0.35924842953681946
[20/23] Train loss=0.3287245035171509
Test set avg_accuracy=63.52% avg_sensitivity=78.98%, avg_specificity=58.59% avg_auc=73.90%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.379188 Test loss=0.606847 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.3597238063812256
[5/23] Train loss=0.3879384696483612
[10/23] Train loss=0.3704976737499237
[15/23] Train loss=0.35454362630844116
[20/23] Train loss=0.3251693546772003
Test set avg_accuracy=53.57% avg_sensitivity=86.95%, avg_specificity=42.94% avg_auc=71.72%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.375770 Test loss=0.654197 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.36717188358306885
[5/23] Train loss=0.37968841195106506
[10/23] Train loss=0.36268532276153564
[15/23] Train loss=0.3572337031364441
[20/23] Train loss=0.32769566774368286
Test set avg_accuracy=51.84% avg_sensitivity=88.30%, avg_specificity=40.22% avg_auc=70.71%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.370611 Test loss=0.673977 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.3658939301967621
[5/23] Train loss=0.38708677887916565
[10/23] Train loss=0.36850932240486145
[15/23] Train loss=0.36111366748809814
[20/23] Train loss=0.32833075523376465
Test set avg_accuracy=57.67% avg_sensitivity=84.80%, avg_specificity=49.03% avg_auc=73.36%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.373888 Test loss=0.638655 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.3557785451412201
[5/23] Train loss=0.3700452446937561
[10/23] Train loss=0.35967352986335754
[15/23] Train loss=0.351325124502182
[20/23] Train loss=0.31938642263412476
Test set avg_accuracy=55.10% avg_sensitivity=87.44%, avg_specificity=44.81% avg_auc=69.99%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.366472 Test loss=0.670563 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.3606106638908386
[5/23] Train loss=0.3756999671459198
[10/23] Train loss=0.36009207367897034
[15/23] Train loss=0.3528747856616974
[20/23] Train loss=0.3172680735588074
Test set avg_accuracy=56.50% avg_sensitivity=85.61%, avg_specificity=47.23% avg_auc=71.12%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.365611 Test loss=0.662894 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.35658520460128784
[5/23] Train loss=0.36321699619293213
[10/23] Train loss=0.3538663387298584
[15/23] Train loss=0.3461931347846985
[20/23] Train loss=0.32208120822906494
Test set avg_accuracy=51.37% avg_sensitivity=90.35%, avg_specificity=38.95% avg_auc=71.95%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.363235 Test loss=0.674817 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.352711945772171
[5/23] Train loss=0.3673146665096283
[10/23] Train loss=0.35509350895881653
[15/23] Train loss=0.3498350977897644
[20/23] Train loss=0.31936952471733093
Test set avg_accuracy=52.79% avg_sensitivity=86.58%, avg_specificity=42.03% avg_auc=69.86%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.360952 Test loss=0.683814 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.3504801094532013
[5/23] Train loss=0.36425477266311646
[10/23] Train loss=0.3591771423816681
[15/23] Train loss=0.3445407748222351
[20/23] Train loss=0.31518465280532837
Test set avg_accuracy=51.65% avg_sensitivity=88.79%, avg_specificity=39.83% avg_auc=71.46%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.360588 Test loss=0.681626 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.3483554422855377
[5/23] Train loss=0.3579714894294739
[10/23] Train loss=0.3523590862751007
[15/23] Train loss=0.35205239057540894
[20/23] Train loss=0.31751522421836853
Test set avg_accuracy=58.50% avg_sensitivity=84.42%, avg_specificity=50.25% avg_auc=72.60%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.360596 Test loss=0.646869 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.35594645142555237
[5/23] Train loss=0.36218300461769104
[10/23] Train loss=0.3600342571735382
[15/23] Train loss=0.35738325119018555
[20/23] Train loss=0.3206700384616852
Test set avg_accuracy=58.27% avg_sensitivity=84.42%, avg_specificity=49.94% avg_auc=72.36%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.363517 Test loss=0.646543 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.3516038954257965
[5/23] Train loss=0.36383548378944397
[10/23] Train loss=0.36753955483436584
[15/23] Train loss=0.3485659658908844
[20/23] Train loss=0.3158537745475769
Test set avg_accuracy=59.92% avg_sensitivity=80.81%, avg_specificity=53.27% avg_auc=70.47%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.364608 Test loss=0.650031 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.34771856665611267
[5/23] Train loss=0.3615168333053589
[10/23] Train loss=0.3610862195491791
[15/23] Train loss=0.3461971580982208
[20/23] Train loss=0.31770387291908264
Test set avg_accuracy=53.75% avg_sensitivity=86.52%, avg_specificity=43.31% avg_auc=70.07%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.362451 Test loss=0.676011 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.34869903326034546
[5/23] Train loss=0.3642962872982025
[10/23] Train loss=0.3582976162433624
[15/23] Train loss=0.3432471752166748
[20/23] Train loss=0.3200605809688568
Test set avg_accuracy=52.38% avg_sensitivity=88.89%, avg_specificity=40.76% avg_auc=70.69%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.363585 Test loss=0.677423 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.3542966842651367
[5/23] Train loss=0.36422988772392273
[10/23] Train loss=0.36616870760917664
[15/23] Train loss=0.35538768768310547
[20/23] Train loss=0.31303128600120544
Test set avg_accuracy=61.71% avg_sensitivity=84.31%, avg_specificity=54.51% avg_auc=77.01%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.368462 Test loss=0.610385 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.35957980155944824
[5/23] Train loss=0.3732336163520813
[10/23] Train loss=0.3606470823287964
[15/23] Train loss=0.35444650053977966
[20/23] Train loss=0.3140328824520111
Test set avg_accuracy=61.00% avg_sensitivity=81.02%, avg_specificity=54.63% avg_auc=71.16%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.363230 Test loss=0.641830 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.3476860225200653
[5/23] Train loss=0.35511159896850586
[10/23] Train loss=0.35868772864341736
[15/23] Train loss=0.34871745109558105
[20/23] Train loss=0.3158637583255768
Test set avg_accuracy=57.85% avg_sensitivity=83.77%, avg_specificity=49.60% avg_auc=69.44%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.359104 Test loss=0.669489 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.3480130732059479
[5/23] Train loss=0.3615771532058716
[10/23] Train loss=0.35838207602500916
[15/23] Train loss=0.3461064100265503
[20/23] Train loss=0.312981516122818
Test set avg_accuracy=55.69% avg_sensitivity=88.41%, avg_specificity=45.27% avg_auc=73.01%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.358219 Test loss=0.658822 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.35356974601745605
[5/23] Train loss=0.3601926863193512
[10/23] Train loss=0.353584349155426
[15/23] Train loss=0.35157960653305054
[20/23] Train loss=0.3143255412578583
Test set avg_accuracy=60.44% avg_sensitivity=82.64%, avg_specificity=53.37% avg_auc=73.66%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.362817 Test loss=0.629805 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.36159548163414
[5/23] Train loss=0.3611391484737396
[10/23] Train loss=0.36204156279563904
[15/23] Train loss=0.3515651822090149
[20/23] Train loss=0.3141222894191742
Test set avg_accuracy=66.61% avg_sensitivity=75.42%, avg_specificity=63.81% avg_auc=75.70%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.366578 Test loss=0.583637 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.3513225317001343
[5/23] Train loss=0.36560818552970886
[10/23] Train loss=0.3647567927837372
[15/23] Train loss=0.35373052954673767
[20/23] Train loss=0.321721613407135
Test set avg_accuracy=65.09% avg_sensitivity=76.01%, avg_specificity=61.61% avg_auc=75.72%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.365610 Test loss=0.588227 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.3563077747821808
[5/23] Train loss=0.36070188879966736
[10/23] Train loss=0.3623553514480591
[15/23] Train loss=0.3486821949481964
[20/23] Train loss=0.31025323271751404
Test set avg_accuracy=62.98% avg_sensitivity=78.87%, avg_specificity=57.92% avg_auc=71.05%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.360085 Test loss=0.637159 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.3457406759262085
[5/23] Train loss=0.3533494770526886
[10/23] Train loss=0.35694655776023865
[15/23] Train loss=0.3438239097595215
[20/23] Train loss=0.30781662464141846
Test set avg_accuracy=61.07% avg_sensitivity=80.81%, avg_specificity=54.78% avg_auc=73.43%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.355968 Test loss=0.623542 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.3469446897506714
[5/23] Train loss=0.35400164127349854
[10/23] Train loss=0.35676246881484985
[15/23] Train loss=0.344410240650177
[20/23] Train loss=0.3081582486629486
Test set avg_accuracy=62.98% avg_sensitivity=78.22%, avg_specificity=58.13% avg_auc=71.14%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.354820 Test loss=0.636019 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.3421512842178345
[5/23] Train loss=0.35006964206695557
[10/23] Train loss=0.3563956320285797
[15/23] Train loss=0.3446342349052429
[20/23] Train loss=0.30646002292633057
Test set avg_accuracy=60.18% avg_sensitivity=81.56%, avg_specificity=53.37% avg_auc=73.90%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.356491 Test loss=0.630502 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.35246410965919495
[5/23] Train loss=0.35217392444610596
[10/23] Train loss=0.357972651720047
[15/23] Train loss=0.344502717256546
[20/23] Train loss=0.3076249361038208
Test set avg_accuracy=60.04% avg_sensitivity=80.97%, avg_specificity=53.37% avg_auc=71.29%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.355657 Test loss=0.652214 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.34450674057006836
[5/23] Train loss=0.348455548286438
[10/23] Train loss=0.3582320809364319
[15/23] Train loss=0.34113365411758423
[20/23] Train loss=0.3091566860675812
Test set avg_accuracy=59.70% avg_sensitivity=83.13%, avg_specificity=52.24% avg_auc=72.05%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.353324 Test loss=0.644778 Current lr=[0.000112073915556435]

[0/23] Train loss=0.34658950567245483
[5/23] Train loss=0.35124462842941284
[10/23] Train loss=0.3547664284706116
[15/23] Train loss=0.3443498909473419
[20/23] Train loss=0.3102773427963257
Test set avg_accuracy=60.66% avg_sensitivity=81.83%, avg_specificity=53.92% avg_auc=74.34%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.355164 Test loss=0.623557 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.34914106130599976
[5/23] Train loss=0.3568897545337677
[10/23] Train loss=0.36606255173683167
[15/23] Train loss=0.3436841368675232
[20/23] Train loss=0.3063592314720154
Test set avg_accuracy=63.19% avg_sensitivity=79.84%, avg_specificity=57.89% avg_auc=74.53%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.357719 Test loss=0.614821 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.34777241945266724
[5/23] Train loss=0.3468136787414551
[10/23] Train loss=0.354046106338501
[15/23] Train loss=0.34073686599731445
[20/23] Train loss=0.31095582246780396
Test set avg_accuracy=62.17% avg_sensitivity=79.30%, avg_specificity=56.72% avg_auc=72.95%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.355151 Test loss=0.631780 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.3466651439666748
[5/23] Train loss=0.3503802418708801
[10/23] Train loss=0.358006089925766
[15/23] Train loss=0.3420622646808624
[20/23] Train loss=0.30785930156707764
Test set avg_accuracy=63.14% avg_sensitivity=78.98%, avg_specificity=58.09% avg_auc=73.93%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.354680 Test loss=0.617312 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.3495105803012848
[5/23] Train loss=0.3469722867012024
[10/23] Train loss=0.36214500665664673
[15/23] Train loss=0.3410770893096924
[20/23] Train loss=0.3098960518836975
Test set avg_accuracy=60.30% avg_sensitivity=81.94%, avg_specificity=53.41% avg_auc=73.41%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.355302 Test loss=0.633075 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.35714107751846313
[5/23] Train loss=0.35316115617752075
[10/23] Train loss=0.3587005138397217
[15/23] Train loss=0.3423881530761719
[20/23] Train loss=0.30943694710731506
Test set avg_accuracy=59.19% avg_sensitivity=84.47%, avg_specificity=51.14% avg_auc=73.63%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.356405 Test loss=0.647492 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.35274067521095276
[5/23] Train loss=0.34847497940063477
[10/23] Train loss=0.35602453351020813
[15/23] Train loss=0.33757027983665466
[20/23] Train loss=0.3097892999649048
Test set avg_accuracy=56.46% avg_sensitivity=88.30%, avg_specificity=46.32% avg_auc=72.11%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.354344 Test loss=0.669532 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.353829562664032
[5/23] Train loss=0.3425985276699066
[10/23] Train loss=0.3552868068218231
[15/23] Train loss=0.3381054103374481
[20/23] Train loss=0.30784302949905396
Test set avg_accuracy=56.41% avg_sensitivity=87.87%, avg_specificity=46.39% avg_auc=72.73%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.353351 Test loss=0.666678 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.3492686152458191
[5/23] Train loss=0.34172430634498596
[10/23] Train loss=0.3524283766746521
[15/23] Train loss=0.33757737278938293
[20/23] Train loss=0.31134456396102905
Test set avg_accuracy=56.93% avg_sensitivity=85.39%, avg_specificity=47.86% avg_auc=71.94%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.352009 Test loss=0.664702 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.34409040212631226
[5/23] Train loss=0.3390624523162842
[10/23] Train loss=0.3509257733821869
[15/23] Train loss=0.33405801653862
[20/23] Train loss=0.30531981587409973
Test set avg_accuracy=60.21% avg_sensitivity=81.89%, avg_specificity=53.30% avg_auc=72.99%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.348653 Test loss=0.641079 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.34075331687927246
[5/23] Train loss=0.33693036437034607
[10/23] Train loss=0.35071861743927
[15/23] Train loss=0.3330824673175812
[20/23] Train loss=0.3044416606426239
Test set avg_accuracy=58.01% avg_sensitivity=84.42%, avg_specificity=49.60% avg_auc=72.06%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.346733 Test loss=0.658880 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.34054034948349
[5/23] Train loss=0.33593815565109253
[10/23] Train loss=0.3508854806423187
[15/23] Train loss=0.33145129680633545
[20/23] Train loss=0.3022671639919281
Test set avg_accuracy=57.73% avg_sensitivity=84.10%, avg_specificity=49.34% avg_auc=71.83%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.345730 Test loss=0.664667 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.3395722508430481
[5/23] Train loss=0.340061217546463
[10/23] Train loss=0.35227110981941223
[15/23] Train loss=0.3310251832008362
[20/23] Train loss=0.2995794713497162
Test set avg_accuracy=56.76% avg_sensitivity=84.42%, avg_specificity=47.95% avg_auc=70.86%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.345261 Test loss=0.676714 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.339111864566803
[5/23] Train loss=0.33847010135650635
[10/23] Train loss=0.3501991033554077
[15/23] Train loss=0.33227863907814026
[20/23] Train loss=0.29963019490242004
Test set avg_accuracy=57.53% avg_sensitivity=83.83%, avg_specificity=49.15% avg_auc=71.36%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.344525 Test loss=0.669787 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.33783450722694397
[5/23] Train loss=0.3341521620750427
[10/23] Train loss=0.3509677052497864
[15/23] Train loss=0.331754595041275
[20/23] Train loss=0.30067408084869385
Test set avg_accuracy=58.02% avg_sensitivity=84.47%, avg_specificity=49.60% avg_auc=71.59%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.344701 Test loss=0.664759 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.3373717665672302
[5/23] Train loss=0.33699876070022583
[10/23] Train loss=0.3511127829551697
[15/23] Train loss=0.33133745193481445
[20/23] Train loss=0.3014968931674957
Test set avg_accuracy=58.22% avg_sensitivity=84.26%, avg_specificity=49.92% avg_auc=71.49%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.344152 Test loss=0.665134 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.3375408351421356
[5/23] Train loss=0.3361366093158722
[10/23] Train loss=0.3511800169944763
[15/23] Train loss=0.32954758405685425
[20/23] Train loss=0.2980147898197174
Test set avg_accuracy=58.01% avg_sensitivity=83.88%, avg_specificity=49.77% avg_auc=70.74%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.343276 Test loss=0.674728 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.33709919452667236
[5/23] Train loss=0.3338335156440735
[10/23] Train loss=0.35091090202331543
[15/23] Train loss=0.3288644850254059
[20/23] Train loss=0.2999950349330902
Test set avg_accuracy=57.59% avg_sensitivity=84.26%, avg_specificity=49.10% avg_auc=70.48%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.343658 Test loss=0.678762 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.33573922514915466
[5/23] Train loss=0.3340572118759155
[10/23] Train loss=0.3508782982826233
[15/23] Train loss=0.3279609680175781
[20/23] Train loss=0.29698774218559265
Test set avg_accuracy=58.27% avg_sensitivity=83.99%, avg_specificity=50.08% avg_auc=70.86%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.342668 Test loss=0.676167 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.33470356464385986
[5/23] Train loss=0.33265045285224915
[10/23] Train loss=0.3498518168926239
[15/23] Train loss=0.32966887950897217
[20/23] Train loss=0.29745447635650635
Test set avg_accuracy=57.03% avg_sensitivity=84.20%, avg_specificity=48.38% avg_auc=70.85%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.341851 Test loss=0.678829 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.33465975522994995
[5/23] Train loss=0.33454450964927673
[10/23] Train loss=0.35162582993507385
[15/23] Train loss=0.3283746838569641
[20/23] Train loss=0.2966930866241455
Test set avg_accuracy=58.02% avg_sensitivity=83.77%, avg_specificity=49.82% avg_auc=71.14%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.341544 Test loss=0.672103 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.3343007564544678
[5/23] Train loss=0.3309157192707062
[10/23] Train loss=0.35011833906173706
[15/23] Train loss=0.3289739787578583
[20/23] Train loss=0.2961677312850952
Test set avg_accuracy=57.34% avg_sensitivity=84.15%, avg_specificity=48.81% avg_auc=70.03%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.341187 Test loss=0.691033 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.334121435880661
[5/23] Train loss=0.3334445357322693
[10/23] Train loss=0.35112661123275757
[15/23] Train loss=0.32723721861839294
[20/23] Train loss=0.2946311831474304
Test set avg_accuracy=58.40% avg_sensitivity=83.94%, avg_specificity=50.27% avg_auc=70.54%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.340552 Test loss=0.678552 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.33339062333106995
[5/23] Train loss=0.3285190463066101
[10/23] Train loss=0.3504025340080261
[15/23] Train loss=0.32703065872192383
[20/23] Train loss=0.2938380539417267
Test set avg_accuracy=59.10% avg_sensitivity=83.77%, avg_specificity=51.24% avg_auc=70.76%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.339776 Test loss=0.675662 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.3326951563358307
[5/23] Train loss=0.32894793152809143
[10/23] Train loss=0.3505748212337494
[15/23] Train loss=0.3264249265193939
[20/23] Train loss=0.2932146191596985
Test set avg_accuracy=57.73% avg_sensitivity=84.04%, avg_specificity=49.36% avg_auc=70.59%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.339544 Test loss=0.682704 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.3327065706253052
[5/23] Train loss=0.3288138806819916
[10/23] Train loss=0.3507709801197052
[15/23] Train loss=0.3254297375679016
[20/23] Train loss=0.2941645681858063
Test set avg_accuracy=56.89% avg_sensitivity=84.15%, avg_specificity=48.21% avg_auc=70.88%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.339408 Test loss=0.681011 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.33182233572006226
[5/23] Train loss=0.32787618041038513
[10/23] Train loss=0.34778785705566406
[15/23] Train loss=0.3249560594558716
[20/23] Train loss=0.29287055134773254
Test set avg_accuracy=56.71% avg_sensitivity=84.20%, avg_specificity=47.95% avg_auc=70.86%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.338455 Test loss=0.682901 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.3311343789100647
[5/23] Train loss=0.32725319266319275
[10/23] Train loss=0.34893399477005005
[15/23] Train loss=0.32432663440704346
[20/23] Train loss=0.2947838008403778
Test set avg_accuracy=56.12% avg_sensitivity=84.47%, avg_specificity=47.09% avg_auc=71.31%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.338327 Test loss=0.681090 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.33222171664237976
[5/23] Train loss=0.3262955844402313
[10/23] Train loss=0.34908851981163025
[15/23] Train loss=0.3230762779712677
[20/23] Train loss=0.29321083426475525
Test set avg_accuracy=56.90% avg_sensitivity=84.20%, avg_specificity=48.21% avg_auc=70.88%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.337881 Test loss=0.683188 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.33143267035484314
[5/23] Train loss=0.32664617896080017
[10/23] Train loss=0.34771648049354553
[15/23] Train loss=0.3228881061077118
[20/23] Train loss=0.29243117570877075
Test set avg_accuracy=56.89% avg_sensitivity=84.20%, avg_specificity=48.19% avg_auc=70.80%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.337131 Test loss=0.684464 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.33014577627182007
[5/23] Train loss=0.3262409567832947
[10/23] Train loss=0.3470136523246765
[15/23] Train loss=0.32238155603408813
[20/23] Train loss=0.2916010320186615
Test set avg_accuracy=56.84% avg_sensitivity=84.20%, avg_specificity=48.12% avg_auc=70.50%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.336294 Test loss=0.688938 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.32999929785728455
[5/23] Train loss=0.3247579038143158
[10/23] Train loss=0.3470402956008911
[15/23] Train loss=0.32209810614585876
[20/23] Train loss=0.2912730574607849
Test set avg_accuracy=56.43% avg_sensitivity=84.26%, avg_specificity=47.57% avg_auc=70.59%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.336006 Test loss=0.689629 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.32988524436950684
[5/23] Train loss=0.3246660530567169
[10/23] Train loss=0.34698283672332764
[15/23] Train loss=0.3219178020954132
[20/23] Train loss=0.29100272059440613
Test set avg_accuracy=56.61% avg_sensitivity=84.15%, avg_specificity=47.85% avg_auc=70.44%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.335781 Test loss=0.690987 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.32954418659210205
[5/23] Train loss=0.32439568638801575
[10/23] Train loss=0.3467406630516052
[15/23] Train loss=0.32170429825782776
[20/23] Train loss=0.29080650210380554
Test set avg_accuracy=56.63% avg_sensitivity=84.15%, avg_specificity=47.86% avg_auc=70.40%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.335570 Test loss=0.691466 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.32942473888397217
[5/23] Train loss=0.3241024911403656
[10/23] Train loss=0.34675467014312744
[15/23] Train loss=0.3215634822845459
[20/23] Train loss=0.2906765639781952
Test set avg_accuracy=56.51% avg_sensitivity=84.15%, avg_specificity=47.71% avg_auc=70.40%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.335439 Test loss=0.691555 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.3293187618255615
[5/23] Train loss=0.3239164352416992
[10/23] Train loss=0.34668102860450745
[15/23] Train loss=0.3214433789253235
[20/23] Train loss=0.290569931268692
Test set avg_accuracy=56.52% avg_sensitivity=84.15%, avg_specificity=47.73% avg_auc=70.38%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.335309 Test loss=0.692061 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.32916170358657837
[5/23] Train loss=0.32373595237731934
[10/23] Train loss=0.3466133177280426
[15/23] Train loss=0.3213399052619934
[20/23] Train loss=0.2904338240623474
Test set avg_accuracy=56.50% avg_sensitivity=84.04%, avg_specificity=47.73% avg_auc=70.36%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.335215 Test loss=0.692371 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.3290765881538391
[5/23] Train loss=0.3236262798309326
[10/23] Train loss=0.34653961658477783
[15/23] Train loss=0.32126402854919434
[20/23] Train loss=0.2903524339199066
Test set avg_accuracy=56.50% avg_sensitivity=84.04%, avg_specificity=47.73% avg_auc=70.34%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.335136 Test loss=0.692608 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.3289964199066162
[5/23] Train loss=0.3235310912132263
[10/23] Train loss=0.34651413559913635
[15/23] Train loss=0.3212171196937561
[20/23] Train loss=0.2902968227863312
Test set avg_accuracy=56.50% avg_sensitivity=84.04%, avg_specificity=47.73% avg_auc=70.33%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.335079 Test loss=0.692931 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.3289434015750885
[5/23] Train loss=0.3234492838382721
[10/23] Train loss=0.34649142622947693
[15/23] Train loss=0.3211834132671356
[20/23] Train loss=0.290251225233078
Test set avg_accuracy=56.43% avg_sensitivity=84.04%, avg_specificity=47.64% avg_auc=70.32%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.335036 Test loss=0.693124 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.32890835404396057
[5/23] Train loss=0.3233955502510071
[10/23] Train loss=0.34647348523139954
[15/23] Train loss=0.3211591839790344
[20/23] Train loss=0.29022035002708435
Test set avg_accuracy=56.43% avg_sensitivity=84.04%, avg_specificity=47.64% avg_auc=70.32%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.335007 Test loss=0.693232 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.3288845419883728
[5/23] Train loss=0.3233650028705597
[10/23] Train loss=0.34646061062812805
[15/23] Train loss=0.3211458921432495
[20/23] Train loss=0.29020291566848755
Test set avg_accuracy=56.43% avg_sensitivity=84.04%, avg_specificity=47.64% avg_auc=70.31%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.334988 Test loss=0.693303 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.32887032628059387
[5/23] Train loss=0.3233492076396942
[10/23] Train loss=0.34645214676856995
[15/23] Train loss=0.32113948464393616
[20/23] Train loss=0.2901947796344757
Test set avg_accuracy=56.43% avg_sensitivity=84.04%, avg_specificity=47.64% avg_auc=70.31%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.334978 Test loss=0.693343 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.3288636803627014
[5/23] Train loss=0.32334253191947937
[10/23] Train loss=0.34644827246665955
[15/23] Train loss=0.321137398481369
[20/23] Train loss=0.29019230604171753
Test set avg_accuracy=56.43% avg_sensitivity=84.04%, avg_specificity=47.64% avg_auc=70.31%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.334974 Test loss=0.693360 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=64.75% sen=81.62%, spe=59.38%, auc=78.26%!
Fold[9] Avg_overlap=0.48%(0.23617966665562473)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 1,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'SwEDModel',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.690251350402832
[5/24] Train loss=0.6892591714859009
[10/24] Train loss=0.6892430782318115
[15/24] Train loss=0.6887490153312683
[20/24] Train loss=0.6882522702217102
Test set avg_accuracy=64.90% avg_sensitivity=19.47%, avg_specificity=78.07% avg_auc=49.73%
Best model saved!! Metric=-113.8418755440351!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.688819 Test loss=0.686385 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6878349184989929
[5/24] Train loss=0.6869786977767944
[10/24] Train loss=0.6864984631538391
[15/24] Train loss=0.6862664818763733
[20/24] Train loss=0.6856731176376343
Test set avg_accuracy=64.90% avg_sensitivity=19.47%, avg_specificity=78.07% avg_auc=49.91%
Best model saved!! Metric=-113.66565001272146!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.686254 Test loss=0.683413 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6852793097496033
[5/24] Train loss=0.6845279335975647
[10/24] Train loss=0.683703601360321
[15/24] Train loss=0.683753252029419
[20/24] Train loss=0.6831172108650208
Test set avg_accuracy=64.90% avg_sensitivity=19.47%, avg_specificity=78.07% avg_auc=49.90%
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.683598 Test loss=0.680151 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.682546854019165
[5/24] Train loss=0.6816364526748657
[10/24] Train loss=0.6804315447807312
[15/24] Train loss=0.6803800463676453
[20/24] Train loss=0.6796593070030212
Test set avg_accuracy=64.90% avg_sensitivity=19.47%, avg_specificity=78.07% avg_auc=50.18%
Best model saved!! Metric=-113.39309888590952!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.680342 Test loss=0.675575 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6786219477653503
[5/24] Train loss=0.6776203513145447
[10/24] Train loss=0.6758624315261841
[15/24] Train loss=0.6758705973625183
[20/24] Train loss=0.6750121712684631
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.52%
Best model saved!! Metric=-97.94956817487241!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.675860 Test loss=0.669604 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6735568642616272
[5/24] Train loss=0.6724333763122559
[10/24] Train loss=0.6700618267059326
[15/24] Train loss=0.6701170802116394
[20/24] Train loss=0.6691815853118896
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.81%
Best model saved!! Metric=-97.66034325193095!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.670120 Test loss=0.661983 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6672717332839966
[5/24] Train loss=0.6658188700675964
[10/24] Train loss=0.6625797152519226
[15/24] Train loss=0.6627563834190369
[20/24] Train loss=0.6614289879798889
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.07%
Best model saved!! Metric=-97.40045681473828!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.662706 Test loss=0.651844 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6591247916221619
[5/24] Train loss=0.6571273803710938
[10/24] Train loss=0.652738094329834
[15/24] Train loss=0.6528711915016174
[20/24] Train loss=0.650995671749115
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.47%
Best model saved!! Metric=-97.00528735992616!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.652836 Test loss=0.638097 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6482420563697815
[5/24] Train loss=0.6453429460525513
[10/24] Train loss=0.639481782913208
[15/24] Train loss=0.6393128037452698
[20/24] Train loss=0.6367550492286682
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.87%
Best model saved!! Metric=-96.60526708085342!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.639405 Test loss=0.618682 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6333504319190979
[5/24] Train loss=0.6286470890045166
[10/24] Train loss=0.6203418970108032
[15/24] Train loss=0.6197788715362549
[20/24] Train loss=0.616230309009552
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.50%
Best model saved!! Metric=-95.97286458679994!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.620155 Test loss=0.590865 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.613329291343689
[5/24] Train loss=0.6062889695167542
[10/24] Train loss=0.5965771079063416
[15/24] Train loss=0.5976064205169678
[20/24] Train loss=0.5951539874076843
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=53.12%
Best model saved!! Metric=-95.35547191505741!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.597060 Test loss=0.561411 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5954756736755371
[5/24] Train loss=0.5860899686813354
[10/24] Train loss=0.5781298279762268
[15/24] Train loss=0.5816622972488403
[20/24] Train loss=0.5823095440864563
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=53.51%
Best model saved!! Metric=-94.96783413121364!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.579014 Test loss=0.542354 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5872346758842468
[5/24] Train loss=0.5758732557296753
[10/24] Train loss=0.5692868232727051
[15/24] Train loss=0.5738599300384521
[20/24] Train loss=0.576742947101593
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=56.10%
Best model saved!! Metric=-92.37283776860201!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.570489 Test loss=0.536688 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5844735503196716
[5/24] Train loss=0.5731740593910217
[10/24] Train loss=0.566245973110199
[15/24] Train loss=0.570110023021698
[20/24] Train loss=0.5746082663536072
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=58.21%
Best model saved!! Metric=-90.26563873670392!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.567242 Test loss=0.534369 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.583584725856781
[5/24] Train loss=0.5714242458343506
[10/24] Train loss=0.5647296905517578
[15/24] Train loss=0.5681206583976746
[20/24] Train loss=0.572771430015564
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=59.57%
Best model saved!! Metric=-88.9027322746081!!
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.565617 Test loss=0.533153 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5818451642990112
[5/24] Train loss=0.5698015093803406
[10/24] Train loss=0.563238263130188
[15/24] Train loss=0.564976155757904
[20/24] Train loss=0.5704929232597351
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=61.95%
Best model saved!! Metric=-86.52391141121781!!
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.563638 Test loss=0.531906 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5785505175590515
[5/24] Train loss=0.5670527815818787
[10/24] Train loss=0.5610470175743103
[15/24] Train loss=0.5605456233024597
[20/24] Train loss=0.5663723349571228
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=65.26%
Best model saved!! Metric=-83.21890909722381!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.560156 Test loss=0.529230 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5708213448524475
[5/24] Train loss=0.5616899132728577
[10/24] Train loss=0.5575405955314636
[15/24] Train loss=0.5538451075553894
[20/24] Train loss=0.5568907856941223
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=70.86%
Best model saved!! Metric=-77.61095242204202!!
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.553429 Test loss=0.524517 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5586380362510681
[5/24] Train loss=0.5501238703727722
[10/24] Train loss=0.5493367910385132
[15/24] Train loss=0.5391785502433777
[20/24] Train loss=0.5420148968696594
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=74.11%
Best model saved!! Metric=-74.36088557116405!!
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.542117 Test loss=0.535487 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5384904742240906
[5/24] Train loss=0.5354335904121399
[10/24] Train loss=0.5356469750404358
[15/24] Train loss=0.5223914980888367
[20/24] Train loss=0.5228673219680786
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=67.82%
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.527807 Test loss=0.637860 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5185248255729675
[5/24] Train loss=0.5242389440536499
[10/24] Train loss=0.5202605128288269
[15/24] Train loss=0.5067093372344971
[20/24] Train loss=0.5066149234771729
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.28%
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.512922 Test loss=0.660889 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.4958505928516388
[5/24] Train loss=0.5166391730308533
[10/24] Train loss=0.5065644383430481
[15/24] Train loss=0.49754151701927185
[20/24] Train loss=0.5048097372055054
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.10%
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.501758 Test loss=0.650387 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.48704010248184204
[5/24] Train loss=0.5082056522369385
[10/24] Train loss=0.4986814856529236
[15/24] Train loss=0.4926464259624481
[20/24] Train loss=0.49063512682914734
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=55.67%
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.493885 Test loss=0.642059 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.4881381392478943
[5/24] Train loss=0.5069836974143982
[10/24] Train loss=0.4924423396587372
[15/24] Train loss=0.4906371235847473
[20/24] Train loss=0.4876560568809509
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=59.01%
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.490032 Test loss=0.640332 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.48665353655815125
[5/24] Train loss=0.5042377710342407
[10/24] Train loss=0.4925926923751831
[15/24] Train loss=0.4838241934776306
[20/24] Train loss=0.48128989338874817
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=58.46%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.484244 Test loss=0.651602 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.4777696132659912
[5/24] Train loss=0.49745631217956543
[10/24] Train loss=0.4866787791252136
[15/24] Train loss=0.4770689606666565
[20/24] Train loss=0.4772266745567322
Test set avg_accuracy=51.07% avg_sensitivity=62.46%, avg_specificity=47.77% avg_auc=60.92%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.480151 Test loss=0.651128 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.47246673703193665
[5/24] Train loss=0.4951489269733429
[10/24] Train loss=0.4867011308670044
[15/24] Train loss=0.47656646370887756
[20/24] Train loss=0.479591429233551
Test set avg_accuracy=51.00% avg_sensitivity=69.12%, avg_specificity=45.75% avg_auc=63.92%
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.477710 Test loss=0.644688 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.4694056212902069
[5/24] Train loss=0.49443671107292175
[10/24] Train loss=0.4810258448123932
[15/24] Train loss=0.47211501002311707
[20/24] Train loss=0.47132232785224915
Test set avg_accuracy=41.74% avg_sensitivity=84.70%, avg_specificity=29.29% avg_auc=62.44%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.475074 Test loss=0.653078 Current lr=[0.000210185142098938]

[0/24] Train loss=0.46173128485679626
[5/24] Train loss=0.5089802145957947
[10/24] Train loss=0.48767614364624023
[15/24] Train loss=0.47532278299331665
[20/24] Train loss=0.4676690101623535
Test set avg_accuracy=47.88% avg_sensitivity=82.50%, avg_specificity=37.84% avg_auc=64.65%
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.473775 Test loss=0.647877 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.4694577753543854
[5/24] Train loss=0.49966540932655334
[10/24] Train loss=0.4804121255874634
[15/24] Train loss=0.46576598286628723
[20/24] Train loss=0.46188852190971375
Test set avg_accuracy=50.39% avg_sensitivity=81.11%, avg_specificity=41.48% avg_auc=65.03%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.471445 Test loss=0.642439 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.45767393708229065
[5/24] Train loss=0.48447152972221375
[10/24] Train loss=0.4664241373538971
[15/24] Train loss=0.45188531279563904
[20/24] Train loss=0.44287532567977905
Test set avg_accuracy=57.17% avg_sensitivity=77.64%, avg_specificity=51.24% avg_auc=67.22%
Best model saved!! Metric=-72.72408012393166!!
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.458644 Test loss=0.630234 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.43402501940727234
[5/24] Train loss=0.4650873839855194
[10/24] Train loss=0.4533803164958954
[15/24] Train loss=0.43590667843818665
[20/24] Train loss=0.41639444231987
Test set avg_accuracy=48.50% avg_sensitivity=88.01%, avg_specificity=37.05% avg_auc=67.35%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.441536 Test loss=0.648319 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.40919187664985657
[5/24] Train loss=0.441463440656662
[10/24] Train loss=0.4348306953907013
[15/24] Train loss=0.42194682359695435
[20/24] Train loss=0.4028729200363159
Test set avg_accuracy=54.99% avg_sensitivity=87.20%, avg_specificity=45.65% avg_auc=72.27%
Best model saved!! Metric=-65.89389782343629!!
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.425978 Test loss=0.628163 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.4020419716835022
[5/24] Train loss=0.4451669156551361
[10/24] Train loss=0.42709460854530334
[15/24] Train loss=0.4254765808582306
[20/24] Train loss=0.3974395990371704
Test set avg_accuracy=63.93% avg_sensitivity=75.26%, avg_specificity=60.65% avg_auc=73.32%
Best model saved!! Metric=-52.841104875615194!!
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.424794 Test loss=0.595077 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.40346595644950867
[5/24] Train loss=0.4415115714073181
[10/24] Train loss=0.44440093636512756
[15/24] Train loss=0.42273515462875366
[20/24] Train loss=0.3914206326007843
Test set avg_accuracy=64.52% avg_sensitivity=76.07%, avg_specificity=61.17% avg_auc=77.26%
Best model saved!! Metric=-46.98287606225915!!
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.426789 Test loss=0.581882 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3905836343765259
[5/24] Train loss=0.43189913034439087
[10/24] Train loss=0.41057851910591125
[15/24] Train loss=0.4052202105522156
[20/24] Train loss=0.3848892152309418
Test set avg_accuracy=61.35% avg_sensitivity=81.46%, avg_specificity=55.53% avg_auc=73.06%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.413311 Test loss=0.612778 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3919934034347534
[5/24] Train loss=0.4276725947856903
[10/24] Train loss=0.408673495054245
[15/24] Train loss=0.40905338525772095
[20/24] Train loss=0.38006269931793213
Test set avg_accuracy=65.31% avg_sensitivity=80.53%, avg_specificity=60.90% avg_auc=77.52%
Best model saved!! Metric=-41.73831698195239!!
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.413905 Test loss=0.581917 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.38687291741371155
[5/24] Train loss=0.4247361719608307
[10/24] Train loss=0.3953515589237213
[15/24] Train loss=0.4220571219921112
[20/24] Train loss=0.3807145655155182
Test set avg_accuracy=67.06% avg_sensitivity=77.81%, avg_specificity=63.94% avg_auc=78.05%
Best model saved!! Metric=-39.14289411455057!!
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.407449 Test loss=0.576355 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.38550543785095215
[5/24] Train loss=0.4157842993736267
[10/24] Train loss=0.39988818764686584
[15/24] Train loss=0.42039287090301514
[20/24] Train loss=0.40274983644485474
Test set avg_accuracy=61.99% avg_sensitivity=84.13%, avg_specificity=55.58% avg_auc=77.01%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.410434 Test loss=0.599224 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.4197940528392792
[5/24] Train loss=0.4320753216743469
[10/24] Train loss=0.3920467495918274
[15/24] Train loss=0.4028228223323822
[20/24] Train loss=0.3759382367134094
Test set avg_accuracy=64.74% avg_sensitivity=81.23%, avg_specificity=59.96% avg_auc=76.81%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.408552 Test loss=0.589422 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.38824018836021423
[5/24] Train loss=0.4136277139186859
[10/24] Train loss=0.39694610238075256
[15/24] Train loss=0.40297967195510864
[20/24] Train loss=0.37677109241485596
Test set avg_accuracy=68.75% avg_sensitivity=72.71%, avg_specificity=67.60% avg_auc=76.85%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.405563 Test loss=0.569421 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3960206210613251
[5/24] Train loss=0.41582536697387695
[10/24] Train loss=0.39031723141670227
[15/24] Train loss=0.40043729543685913
[20/24] Train loss=0.3800766170024872
Test set avg_accuracy=56.61% avg_sensitivity=86.85%, avg_specificity=47.85% avg_auc=72.60%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.400817 Test loss=0.642048 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.38771867752075195
[5/24] Train loss=0.4157421290874481
[10/24] Train loss=0.3831348121166229
[15/24] Train loss=0.4045271873474121
[20/24] Train loss=0.3882737159729004
Test set avg_accuracy=66.29% avg_sensitivity=79.84%, avg_specificity=62.36% avg_auc=78.19%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.403019 Test loss=0.578372 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.38929882645606995
[5/24] Train loss=0.4183698296546936
[10/24] Train loss=0.3905113935470581
[15/24] Train loss=0.3994182050228119
[20/24] Train loss=0.3634124994277954
Test set avg_accuracy=66.30% avg_sensitivity=82.27%, avg_specificity=61.67% avg_auc=77.63%
Best model saved!! Metric=-38.12741536098241!!
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.400429 Test loss=0.581812 Current lr=[0.00029967723776099]

[0/24] Train loss=0.39235594868659973
[5/24] Train loss=0.4095804989337921
[10/24] Train loss=0.38632717728614807
[15/24] Train loss=0.3917064964771271
[20/24] Train loss=0.3649559020996094
Test set avg_accuracy=66.41% avg_sensitivity=78.91%, avg_specificity=62.78% avg_auc=77.38%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.398413 Test loss=0.581381 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3756028413772583
[5/24] Train loss=0.4102034270763397
[10/24] Train loss=0.3856092095375061
[15/24] Train loss=0.39426183700561523
[20/24] Train loss=0.3616032600402832
Test set avg_accuracy=75.13% avg_sensitivity=62.17%, avg_specificity=78.89% avg_auc=77.45%
Best model saved!! Metric=-32.36776998713128!!
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.393866 Test loss=0.537760 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3830767273902893
[5/24] Train loss=0.4069039225578308
[10/24] Train loss=0.38194236159324646
[15/24] Train loss=0.38861599564552307
[20/24] Train loss=0.3622586131095886
Test set avg_accuracy=66.47% avg_sensitivity=82.10%, avg_specificity=61.94% avg_auc=77.77%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.388663 Test loss=0.579578 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3826485276222229
[5/24] Train loss=0.42428717017173767
[10/24] Train loss=0.396330863237381
[15/24] Train loss=0.38818615674972534
[20/24] Train loss=0.35839810967445374
Test set avg_accuracy=67.70% avg_sensitivity=79.55%, avg_specificity=64.26% avg_auc=78.46%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.396389 Test loss=0.567757 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3901500403881073
[5/24] Train loss=0.4222368597984314
[10/24] Train loss=0.39634808897972107
[15/24] Train loss=0.39301130175590515
[20/24] Train loss=0.3584247827529907
Test set avg_accuracy=70.53% avg_sensitivity=76.48%, avg_specificity=68.81% avg_auc=78.16%
Best model saved!! Metric=-32.01751922477665!!
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.398794 Test loss=0.560233 Current lr=[0.000298904600941902]

[0/24] Train loss=0.37105870246887207
[5/24] Train loss=0.41053691506385803
[10/24] Train loss=0.3789544403553009
[15/24] Train loss=0.3901781737804413
[20/24] Train loss=0.36217665672302246
Test set avg_accuracy=69.36% avg_sensitivity=79.14%, avg_specificity=66.53% avg_auc=80.33%
Best model saved!! Metric=-30.64370403373688!!
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.390862 Test loss=0.554540 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3810112774372101
[5/24] Train loss=0.42235875129699707
[10/24] Train loss=0.39062628149986267
[15/24] Train loss=0.38887476921081543
[20/24] Train loss=0.35757315158843994
Test set avg_accuracy=72.07% avg_sensitivity=75.43%, avg_specificity=71.10% avg_auc=79.93%
Best model saved!! Metric=-27.467059378881387!!
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.394349 Test loss=0.547774 Current lr=[0.000297555943323901]

[0/24] Train loss=0.38379308581352234
[5/24] Train loss=0.40735527873039246
[10/24] Train loss=0.37854087352752686
[15/24] Train loss=0.38697391748428345
[20/24] Train loss=0.3634871244430542
Test set avg_accuracy=71.22% avg_sensitivity=75.78%, avg_specificity=69.90% avg_auc=77.54%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.391431 Test loss=0.560537 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3854660987854004
[5/24] Train loss=0.40907028317451477
[10/24] Train loss=0.3839106559753418
[15/24] Train loss=0.390889436006546
[20/24] Train loss=0.363657683134079
Test set avg_accuracy=67.17% avg_sensitivity=81.52%, avg_specificity=63.02% avg_auc=80.41%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.393577 Test loss=0.568197 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.37164372205734253
[5/24] Train loss=0.40341639518737793
[10/24] Train loss=0.37537410855293274
[15/24] Train loss=0.3974267542362213
[20/24] Train loss=0.3729983866214752
Test set avg_accuracy=66.84% avg_sensitivity=80.13%, avg_specificity=62.98% avg_auc=78.93%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.387929 Test loss=0.569894 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.37662017345428467
[5/24] Train loss=0.4105175733566284
[10/24] Train loss=0.37522363662719727
[15/24] Train loss=0.386455237865448
[20/24] Train loss=0.3615390956401825
Test set avg_accuracy=72.51% avg_sensitivity=75.78%, avg_specificity=71.57% avg_auc=80.71%
Best model saved!! Metric=-25.428702327352852!!
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.387367 Test loss=0.540646 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.36869096755981445
[5/24] Train loss=0.4026433229446411
[10/24] Train loss=0.380994975566864
[15/24] Train loss=0.3824262320995331
[20/24] Train loss=0.3581850826740265
Test set avg_accuracy=70.21% avg_sensitivity=76.83%, avg_specificity=68.29% avg_auc=78.52%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.385443 Test loss=0.561667 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.372345507144928
[5/24] Train loss=0.4055742621421814
[10/24] Train loss=0.3889768123626709
[15/24] Train loss=0.3815031349658966
[20/24] Train loss=0.368278831243515
Test set avg_accuracy=72.58% avg_sensitivity=77.58%, avg_specificity=71.13% avg_auc=82.91%
Best model saved!! Metric=-21.80969066361807!!
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.390351 Test loss=0.537791 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.38968634605407715
[5/24] Train loss=0.4081471860408783
[10/24] Train loss=0.37409907579421997
[15/24] Train loss=0.40285468101501465
[20/24] Train loss=0.36004093289375305
Test set avg_accuracy=72.75% avg_sensitivity=72.42%, avg_specificity=72.84% avg_auc=78.63%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.388560 Test loss=0.548205 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.37276217341423035
[5/24] Train loss=0.39633429050445557
[10/24] Train loss=0.38523733615875244
[15/24] Train loss=0.38742995262145996
[20/24] Train loss=0.3599289655685425
Test set avg_accuracy=71.21% avg_sensitivity=76.07%, avg_specificity=69.80% avg_auc=80.05%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.386986 Test loss=0.551411 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3658490478992462
[5/24] Train loss=0.4064771831035614
[10/24] Train loss=0.3767259418964386
[15/24] Train loss=0.3802076280117035
[20/24] Train loss=0.36263006925582886
Test set avg_accuracy=78.14% avg_sensitivity=66.63%, avg_specificity=81.47% avg_auc=83.37%
Best model saved!! Metric=-16.388147928253673!!
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.383954 Test loss=0.507545 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3801143765449524
[5/24] Train loss=0.41972339153289795
[10/24] Train loss=0.38787421584129333
[15/24] Train loss=0.3850621283054352
[20/24] Train loss=0.3537667989730835
Test set avg_accuracy=69.66% avg_sensitivity=79.55%, avg_specificity=66.80% avg_auc=80.01%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.391064 Test loss=0.559972 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3748030960559845
[5/24] Train loss=0.41428402066230774
[10/24] Train loss=0.37817105650901794
[15/24] Train loss=0.3790269196033478
[20/24] Train loss=0.35782384872436523
Test set avg_accuracy=72.36% avg_sensitivity=76.07%, avg_specificity=71.28% avg_auc=80.66%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.388139 Test loss=0.540861 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3713275194168091
[5/24] Train loss=0.3966493606567383
[10/24] Train loss=0.3697618544101715
[15/24] Train loss=0.37521058320999146
[20/24] Train loss=0.3554150462150574
Test set avg_accuracy=66.54% avg_sensitivity=81.52%, avg_specificity=62.19% avg_auc=78.97%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.381029 Test loss=0.570451 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3660862147808075
[5/24] Train loss=0.4003603756427765
[10/24] Train loss=0.37569403648376465
[15/24] Train loss=0.3833378553390503
[20/24] Train loss=0.35637030005455017
Test set avg_accuracy=68.54% avg_sensitivity=80.53%, avg_specificity=65.07% avg_auc=81.31%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.380725 Test loss=0.557474 Current lr=[0.000276307469034998]

[0/24] Train loss=0.35860756039619446
[5/24] Train loss=0.39561396837234497
[10/24] Train loss=0.3812468349933624
[15/24] Train loss=0.37352436780929565
[20/24] Train loss=0.36317384243011475
Test set avg_accuracy=68.07% avg_sensitivity=81.11%, avg_specificity=64.29% avg_auc=82.21%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.384455 Test loss=0.554585 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.36728379130363464
[5/24] Train loss=0.3975812792778015
[10/24] Train loss=0.3693329989910126
[15/24] Train loss=0.38514432311058044
[20/24] Train loss=0.35489147901535034
Test set avg_accuracy=70.64% avg_sensitivity=79.90%, avg_specificity=67.95% avg_auc=80.99%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.380481 Test loss=0.550552 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3946410119533539
[5/24] Train loss=0.40290147066116333
[10/24] Train loss=0.37574419379234314
[15/24] Train loss=0.3740694522857666
[20/24] Train loss=0.3524962365627289
Test set avg_accuracy=73.45% avg_sensitivity=74.97%, avg_specificity=73.01% avg_auc=81.50%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.384614 Test loss=0.526390 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3694072961807251
[5/24] Train loss=0.3957556486129761
[10/24] Train loss=0.36744755506515503
[15/24] Train loss=0.3856537342071533
[20/24] Train loss=0.35703954100608826
Test set avg_accuracy=74.15% avg_sensitivity=72.60%, avg_specificity=74.61% avg_auc=82.73%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.382415 Test loss=0.521191 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.37221255898475647
[5/24] Train loss=0.40562909841537476
[10/24] Train loss=0.3814656138420105
[15/24] Train loss=0.3711681663990021
[20/24] Train loss=0.35523727536201477
Test set avg_accuracy=75.47% avg_sensitivity=67.73%, avg_specificity=77.71% avg_auc=82.82%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.384931 Test loss=0.513377 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.36424893140792847
[5/24] Train loss=0.39598119258880615
[10/24] Train loss=0.37515687942504883
[15/24] Train loss=0.3717547655105591
[20/24] Train loss=0.3544268012046814
Test set avg_accuracy=68.72% avg_sensitivity=78.97%, avg_specificity=65.75% avg_auc=81.92%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.379462 Test loss=0.550858 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.36708706617355347
[5/24] Train loss=0.3972131311893463
[10/24] Train loss=0.3731513023376465
[15/24] Train loss=0.3710366189479828
[20/24] Train loss=0.35389474034309387
Test set avg_accuracy=68.65% avg_sensitivity=80.24%, avg_specificity=65.28% avg_auc=81.28%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.379128 Test loss=0.556280 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3625431954860687
[5/24] Train loss=0.40064483880996704
[10/24] Train loss=0.3839084804058075
[15/24] Train loss=0.3721543252468109
[20/24] Train loss=0.3539622128009796
Test set avg_accuracy=73.65% avg_sensitivity=73.99%, avg_specificity=73.55% avg_auc=82.23%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.381861 Test loss=0.523874 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3635152280330658
[5/24] Train loss=0.387117475271225
[10/24] Train loss=0.36420542001724243
[15/24] Train loss=0.37564951181411743
[20/24] Train loss=0.35419371724128723
Test set avg_accuracy=68.41% avg_sensitivity=80.30%, avg_specificity=64.96% avg_auc=81.94%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.377108 Test loss=0.552836 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.36086931824684143
[5/24] Train loss=0.39901989698410034
[10/24] Train loss=0.3905829191207886
[15/24] Train loss=0.3732372522354126
[20/24] Train loss=0.3607226312160492
Test set avg_accuracy=74.51% avg_sensitivity=70.74%, avg_specificity=75.60% avg_auc=82.99%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.388039 Test loss=0.517895 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3708258271217346
[5/24] Train loss=0.389627069234848
[10/24] Train loss=0.3678903877735138
[15/24] Train loss=0.3693893551826477
[20/24] Train loss=0.35058528184890747
Test set avg_accuracy=70.60% avg_sensitivity=78.10%, avg_specificity=68.42% avg_auc=80.08%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.377328 Test loss=0.549990 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.36569133400917053
[5/24] Train loss=0.39702358841896057
[10/24] Train loss=0.3807130753993988
[15/24] Train loss=0.37023064494132996
[20/24] Train loss=0.3538081645965576
Test set avg_accuracy=70.46% avg_sensitivity=81.29%, avg_specificity=67.32% avg_auc=82.25%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.381885 Test loss=0.546831 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.35716381669044495
[5/24] Train loss=0.3937252163887024
[10/24] Train loss=0.36755359172821045
[15/24] Train loss=0.3703865110874176
[20/24] Train loss=0.3505346477031708
Test set avg_accuracy=69.19% avg_sensitivity=81.63%, avg_specificity=65.59% avg_auc=82.64%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.376802 Test loss=0.551255 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.37293556332588196
[5/24] Train loss=0.39454904198646545
[10/24] Train loss=0.3829786479473114
[15/24] Train loss=0.37057697772979736
[20/24] Train loss=0.35452914237976074
Test set avg_accuracy=69.90% avg_sensitivity=80.48%, avg_specificity=66.83% avg_auc=81.13%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.378542 Test loss=0.552707 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3669120967388153
[5/24] Train loss=0.39434656500816345
[10/24] Train loss=0.37781399488449097
[15/24] Train loss=0.3740200996398926
[20/24] Train loss=0.34998369216918945
Test set avg_accuracy=71.90% avg_sensitivity=77.98%, avg_specificity=70.14% avg_auc=82.74%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.376917 Test loss=0.530023 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.35984838008880615
[5/24] Train loss=0.38109856843948364
[10/24] Train loss=0.36202770471572876
[15/24] Train loss=0.37290191650390625
[20/24] Train loss=0.35503441095352173
Test set avg_accuracy=69.17% avg_sensitivity=78.45%, avg_specificity=66.48% avg_auc=78.85%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.369825 Test loss=0.560826 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3730907738208771
[5/24] Train loss=0.3884700536727905
[10/24] Train loss=0.36387765407562256
[15/24] Train loss=0.3636098802089691
[20/24] Train loss=0.34890231490135193
Test set avg_accuracy=66.91% avg_sensitivity=81.46%, avg_specificity=62.70% avg_auc=78.53%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.370436 Test loss=0.576124 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.35326510667800903
[5/24] Train loss=0.3845973312854767
[10/24] Train loss=0.3617796003818512
[15/24] Train loss=0.36297330260276794
[20/24] Train loss=0.3502841591835022
Test set avg_accuracy=71.85% avg_sensitivity=80.01%, avg_specificity=69.48% avg_auc=82.35%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.370767 Test loss=0.538593 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3594564199447632
[5/24] Train loss=0.38323721289634705
[10/24] Train loss=0.3673464059829712
[15/24] Train loss=0.3699425160884857
[20/24] Train loss=0.35370931029319763
Test set avg_accuracy=68.82% avg_sensitivity=80.48%, avg_specificity=65.44% avg_auc=79.68%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.373191 Test loss=0.562887 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3628973960876465
[5/24] Train loss=0.3892832100391388
[10/24] Train loss=0.3628474473953247
[15/24] Train loss=0.37312638759613037
[20/24] Train loss=0.35256674885749817
Test set avg_accuracy=68.91% avg_sensitivity=81.52%, avg_specificity=65.25% avg_auc=81.71%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.373218 Test loss=0.558464 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3657967746257782
[5/24] Train loss=0.400359570980072
[10/24] Train loss=0.3744294047355652
[15/24] Train loss=0.372914582490921
[20/24] Train loss=0.3468692898750305
Test set avg_accuracy=74.92% avg_sensitivity=75.32%, avg_specificity=74.81% avg_auc=84.19%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.376418 Test loss=0.515716 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3693278133869171
[5/24] Train loss=0.3847753703594208
[10/24] Train loss=0.36525118350982666
[15/24] Train loss=0.3743971586227417
[20/24] Train loss=0.3488527536392212
Test set avg_accuracy=65.46% avg_sensitivity=83.72%, avg_specificity=60.16% avg_auc=80.57%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.370161 Test loss=0.573982 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.35679328441619873
[5/24] Train loss=0.38186612725257874
[10/24] Train loss=0.3613835275173187
[15/24] Train loss=0.3614596128463745
[20/24] Train loss=0.3504651188850403
Test set avg_accuracy=68.42% avg_sensitivity=79.78%, avg_specificity=65.13% avg_auc=80.15%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.368660 Test loss=0.557760 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.35312938690185547
[5/24] Train loss=0.39076367020606995
[10/24] Train loss=0.3717118203639984
[15/24] Train loss=0.3823331296443939
[20/24] Train loss=0.35713472962379456
Test set avg_accuracy=71.95% avg_sensitivity=78.45%, avg_specificity=70.07% avg_auc=82.27%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.375257 Test loss=0.539709 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.3575551509857178
[5/24] Train loss=0.3871666193008423
[10/24] Train loss=0.3693757653236389
[15/24] Train loss=0.3685047924518585
[20/24] Train loss=0.34994781017303467
Test set avg_accuracy=69.73% avg_sensitivity=80.07%, avg_specificity=66.73% avg_auc=80.89%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.375450 Test loss=0.556941 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3618966042995453
[5/24] Train loss=0.38645175099372864
[10/24] Train loss=0.3625134229660034
[15/24] Train loss=0.3628747761249542
[20/24] Train loss=0.3478826582431793
Test set avg_accuracy=74.06% avg_sensitivity=75.96%, avg_specificity=73.51% avg_auc=80.90%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.371519 Test loss=0.532363 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3519866466522217
[5/24] Train loss=0.3796141445636749
[10/24] Train loss=0.35805898904800415
[15/24] Train loss=0.3731786906719208
[20/24] Train loss=0.34593576192855835
Test set avg_accuracy=66.88% avg_sensitivity=81.52%, avg_specificity=62.63% avg_auc=78.78%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.367769 Test loss=0.580478 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3591042459011078
[5/24] Train loss=0.38773420453071594
[10/24] Train loss=0.36329561471939087
[15/24] Train loss=0.36122816801071167
[20/24] Train loss=0.3462676405906677
Test set avg_accuracy=71.85% avg_sensitivity=80.94%, avg_specificity=69.21% avg_auc=82.56%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.368514 Test loss=0.539238 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3617997169494629
[5/24] Train loss=0.381855845451355
[10/24] Train loss=0.36317646503448486
[15/24] Train loss=0.36140525341033936
[20/24] Train loss=0.349382609128952
Test set avg_accuracy=73.05% avg_sensitivity=78.16%, avg_specificity=71.57% avg_auc=82.65%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.370455 Test loss=0.529672 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3670082688331604
[5/24] Train loss=0.37731292843818665
[10/24] Train loss=0.362380713224411
[15/24] Train loss=0.3623620569705963
[20/24] Train loss=0.34541240334510803
Test set avg_accuracy=71.90% avg_sensitivity=79.95%, avg_specificity=69.57% avg_auc=82.33%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.369805 Test loss=0.539107 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.35611167550086975
[5/24] Train loss=0.37676095962524414
[10/24] Train loss=0.36704331636428833
[15/24] Train loss=0.36187994480133057
[20/24] Train loss=0.34412461519241333
Test set avg_accuracy=67.92% avg_sensitivity=80.07%, avg_specificity=64.39% avg_auc=76.50%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.368574 Test loss=0.589775 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3488336205482483
[5/24] Train loss=0.37496891617774963
[10/24] Train loss=0.35621657967567444
[15/24] Train loss=0.3710121214389801
[20/24] Train loss=0.3426242470741272
Test set avg_accuracy=67.42% avg_sensitivity=81.69%, avg_specificity=63.29% avg_auc=80.09%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.364950 Test loss=0.567020 Current lr=[0.000156543481933168]

[0/24] Train loss=0.35065850615501404
[5/24] Train loss=0.38167238235473633
[10/24] Train loss=0.3616860508918762
[15/24] Train loss=0.35920971632003784
[20/24] Train loss=0.34311068058013916
Test set avg_accuracy=70.46% avg_sensitivity=79.49%, avg_specificity=67.84% avg_auc=79.90%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.365882 Test loss=0.558620 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3519900441169739
[5/24] Train loss=0.3729785978794098
[10/24] Train loss=0.3554268181324005
[15/24] Train loss=0.3686458170413971
[20/24] Train loss=0.3479044735431671
Test set avg_accuracy=72.86% avg_sensitivity=77.93%, avg_specificity=71.40% avg_auc=81.99%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.365602 Test loss=0.530586 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3551809787750244
[5/24] Train loss=0.38177406787872314
[10/24] Train loss=0.3636215329170227
[15/24] Train loss=0.35859110951423645
[20/24] Train loss=0.3428872525691986
Test set avg_accuracy=72.46% avg_sensitivity=78.16%, avg_specificity=70.81% avg_auc=81.66%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.364780 Test loss=0.535669 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.35543233156204224
[5/24] Train loss=0.38358330726623535
[10/24] Train loss=0.3622905910015106
[15/24] Train loss=0.37441325187683105
[20/24] Train loss=0.3430231809616089
Test set avg_accuracy=72.15% avg_sensitivity=78.97%, avg_specificity=70.17% avg_auc=80.08%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.368005 Test loss=0.553755 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.35723745822906494
[5/24] Train loss=0.37241145968437195
[10/24] Train loss=0.3614237308502197
[15/24] Train loss=0.35973185300827026
[20/24] Train loss=0.3457189202308655
Test set avg_accuracy=73.80% avg_sensitivity=76.07%, avg_specificity=73.14% avg_auc=79.42%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.367299 Test loss=0.546604 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3580065071582794
[5/24] Train loss=0.3783104717731476
[10/24] Train loss=0.3599744141101837
[15/24] Train loss=0.3608613908290863
[20/24] Train loss=0.34201738238334656
Test set avg_accuracy=75.23% avg_sensitivity=75.72%, avg_specificity=75.09% avg_auc=81.77%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.364042 Test loss=0.521502 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3532807230949402
[5/24] Train loss=0.3735329508781433
[10/24] Train loss=0.3550068140029907
[15/24] Train loss=0.35766705870628357
[20/24] Train loss=0.3448377847671509
Test set avg_accuracy=71.54% avg_sensitivity=77.69%, avg_specificity=69.75% avg_auc=79.26%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.362549 Test loss=0.550637 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3529532253742218
[5/24] Train loss=0.37713339924812317
[10/24] Train loss=0.36453425884246826
[15/24] Train loss=0.3616119623184204
[20/24] Train loss=0.3451704978942871
Test set avg_accuracy=73.14% avg_sensitivity=76.65%, avg_specificity=72.12% avg_auc=81.10%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.364270 Test loss=0.530629 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.351366251707077
[5/24] Train loss=0.36882367730140686
[10/24] Train loss=0.35516485571861267
[15/24] Train loss=0.3588114082813263
[20/24] Train loss=0.3402884900569916
Test set avg_accuracy=70.44% avg_sensitivity=80.53%, avg_specificity=67.52% avg_auc=80.85%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.361046 Test loss=0.554654 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3477022051811218
[5/24] Train loss=0.3697524070739746
[10/24] Train loss=0.36374905705451965
[15/24] Train loss=0.357724666595459
[20/24] Train loss=0.3422427773475647
Test set avg_accuracy=75.33% avg_sensitivity=73.93%, avg_specificity=75.73% avg_auc=81.00%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.361284 Test loss=0.518851 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3512313961982727
[5/24] Train loss=0.37117472290992737
[10/24] Train loss=0.360034704208374
[15/24] Train loss=0.3541472256183624
[20/24] Train loss=0.33770936727523804
Test set avg_accuracy=73.01% avg_sensitivity=76.54%, avg_specificity=71.99% avg_auc=81.83%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.356232 Test loss=0.522802 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.34529903531074524
[5/24] Train loss=0.3713456094264984
[10/24] Train loss=0.3547997772693634
[15/24] Train loss=0.35245123505592346
[20/24] Train loss=0.3392982482910156
Test set avg_accuracy=71.37% avg_sensitivity=77.87%, avg_specificity=69.48% avg_auc=82.13%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.354805 Test loss=0.529702 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3447336256504059
[5/24] Train loss=0.3699972629547119
[10/24] Train loss=0.3552372455596924
[15/24] Train loss=0.3484310209751129
[20/24] Train loss=0.3374224603176117
Test set avg_accuracy=72.53% avg_sensitivity=76.77%, avg_specificity=71.30% avg_auc=81.59%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.353111 Test loss=0.528116 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.34313544631004333
[5/24] Train loss=0.3686758279800415
[10/24] Train loss=0.35447585582733154
[15/24] Train loss=0.3494718074798584
[20/24] Train loss=0.33675310015678406
Test set avg_accuracy=73.92% avg_sensitivity=75.43%, avg_specificity=73.48% avg_auc=82.36%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.353867 Test loss=0.512906 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.343391090631485
[5/24] Train loss=0.3683595359325409
[10/24] Train loss=0.3540964722633362
[15/24] Train loss=0.3479050397872925
[20/24] Train loss=0.3364863991737366
Test set avg_accuracy=71.63% avg_sensitivity=78.51%, avg_specificity=69.63% avg_auc=82.38%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.353103 Test loss=0.528585 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.344378799200058
[5/24] Train loss=0.367102712392807
[10/24] Train loss=0.3564015328884125
[15/24] Train loss=0.349137544631958
[20/24] Train loss=0.33663901686668396
Test set avg_accuracy=72.75% avg_sensitivity=76.42%, avg_specificity=71.68% avg_auc=80.76%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.352317 Test loss=0.532590 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.34108203649520874
[5/24] Train loss=0.36847755312919617
[10/24] Train loss=0.353439599275589
[15/24] Train loss=0.34549951553344727
[20/24] Train loss=0.33720093965530396
Test set avg_accuracy=73.44% avg_sensitivity=76.48%, avg_specificity=72.56% avg_auc=81.44%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.351389 Test loss=0.521831 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.34300366044044495
[5/24] Train loss=0.36622610688209534
[10/24] Train loss=0.36391907930374146
[15/24] Train loss=0.3504611551761627
[20/24] Train loss=0.33977335691452026
Test set avg_accuracy=74.95% avg_sensitivity=74.62%, avg_specificity=75.04% avg_auc=80.37%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.354961 Test loss=0.524472 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.34297239780426025
[5/24] Train loss=0.36803749203681946
[10/24] Train loss=0.355618953704834
[15/24] Train loss=0.35226985812187195
[20/24] Train loss=0.3360349237918854
Test set avg_accuracy=74.21% avg_sensitivity=75.78%, avg_specificity=73.75% avg_auc=81.85%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.353260 Test loss=0.514929 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3410971462726593
[5/24] Train loss=0.3648071587085724
[10/24] Train loss=0.3576313555240631
[15/24] Train loss=0.34726524353027344
[20/24] Train loss=0.3351345956325531
Test set avg_accuracy=73.41% avg_sensitivity=77.00%, avg_specificity=72.37% avg_auc=80.78%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.351105 Test loss=0.526820 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3409578502178192
[5/24] Train loss=0.36561644077301025
[10/24] Train loss=0.35645002126693726
[15/24] Train loss=0.34557780623435974
[20/24] Train loss=0.3351847529411316
Test set avg_accuracy=73.67% avg_sensitivity=76.42%, avg_specificity=72.88% avg_auc=81.26%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.350160 Test loss=0.519983 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.34070175886154175
[5/24] Train loss=0.36474311351776123
[10/24] Train loss=0.353839248418808
[15/24] Train loss=0.34607765078544617
[20/24] Train loss=0.33264440298080444
Test set avg_accuracy=73.63% avg_sensitivity=77.17%, avg_specificity=72.61% avg_auc=81.11%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.349282 Test loss=0.522038 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3395175337791443
[5/24] Train loss=0.36902910470962524
[10/24] Train loss=0.3547624945640564
[15/24] Train loss=0.34560441970825195
[20/24] Train loss=0.3318001329898834
Test set avg_accuracy=73.55% avg_sensitivity=76.88%, avg_specificity=72.59% avg_auc=80.65%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.349188 Test loss=0.527140 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.33856767416000366
[5/24] Train loss=0.36341896653175354
[10/24] Train loss=0.35162368416786194
[15/24] Train loss=0.34469953179359436
[20/24] Train loss=0.3319675922393799
Test set avg_accuracy=73.03% avg_sensitivity=78.56%, avg_specificity=71.43% avg_auc=81.28%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.348321 Test loss=0.529352 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3396656811237335
[5/24] Train loss=0.36616218090057373
[10/24] Train loss=0.3545583188533783
[15/24] Train loss=0.3461076021194458
[20/24] Train loss=0.3331254720687866
Test set avg_accuracy=71.94% avg_sensitivity=78.22%, avg_specificity=70.12% avg_auc=79.85%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.348542 Test loss=0.545071 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.33720386028289795
[5/24] Train loss=0.36379387974739075
[10/24] Train loss=0.3526720404624939
[15/24] Train loss=0.34453240036964417
[20/24] Train loss=0.33017876744270325
Test set avg_accuracy=73.10% avg_sensitivity=76.36%, avg_specificity=72.15% avg_auc=79.36%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.347256 Test loss=0.537992 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.33771201968193054
[5/24] Train loss=0.36366382241249084
[10/24] Train loss=0.35100799798965454
[15/24] Train loss=0.34369000792503357
[20/24] Train loss=0.32906654477119446
Test set avg_accuracy=72.58% avg_sensitivity=77.87%, avg_specificity=71.04% avg_auc=80.25%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.346377 Test loss=0.537546 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3364940881729126
[5/24] Train loss=0.36459028720855713
[10/24] Train loss=0.35087549686431885
[15/24] Train loss=0.3432910740375519
[20/24] Train loss=0.32915791869163513
Test set avg_accuracy=72.55% avg_sensitivity=76.94%, avg_specificity=71.28% avg_auc=79.69%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.346441 Test loss=0.540558 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.336273729801178
[5/24] Train loss=0.36108699440956116
[10/24] Train loss=0.35074907541275024
[15/24] Train loss=0.3429332375526428
[20/24] Train loss=0.3273809254169464
Test set avg_accuracy=72.06% avg_sensitivity=77.35%, avg_specificity=70.52% avg_auc=79.57%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.345981 Test loss=0.543213 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3356145918369293
[5/24] Train loss=0.3612539768218994
[10/24] Train loss=0.3515418469905853
[15/24] Train loss=0.3423745334148407
[20/24] Train loss=0.32752978801727295
Test set avg_accuracy=71.90% avg_sensitivity=77.98%, avg_specificity=70.14% avg_auc=79.46%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.344969 Test loss=0.547880 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.33499789237976074
[5/24] Train loss=0.359679251909256
[10/24] Train loss=0.35064488649368286
[15/24] Train loss=0.34187522530555725
[20/24] Train loss=0.3278869688510895
Test set avg_accuracy=72.84% avg_sensitivity=76.77%, avg_specificity=71.70% avg_auc=79.71%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.345062 Test loss=0.536755 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3350955545902252
[5/24] Train loss=0.3579336702823639
[10/24] Train loss=0.3509286940097809
[15/24] Train loss=0.34273695945739746
[20/24] Train loss=0.3263338506221771
Test set avg_accuracy=71.78% avg_sensitivity=77.87%, avg_specificity=70.02% avg_auc=79.11%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.344708 Test loss=0.552335 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3357219099998474
[5/24] Train loss=0.3582165539264679
[10/24] Train loss=0.3492656946182251
[15/24] Train loss=0.34191253781318665
[20/24] Train loss=0.32665035128593445
Test set avg_accuracy=72.16% avg_sensitivity=76.83%, avg_specificity=70.81% avg_auc=79.63%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.344352 Test loss=0.542284 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3358505964279175
[5/24] Train loss=0.36082226037979126
[10/24] Train loss=0.3493484854698181
[15/24] Train loss=0.3416678309440613
[20/24] Train loss=0.3266066312789917
Test set avg_accuracy=72.04% avg_sensitivity=77.29%, avg_specificity=70.52% avg_auc=79.69%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.344499 Test loss=0.543531 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.33647704124450684
[5/24] Train loss=0.360954612493515
[10/24] Train loss=0.3493262529373169
[15/24] Train loss=0.34193530678749084
[20/24] Train loss=0.3253098130226135
Test set avg_accuracy=72.02% avg_sensitivity=77.98%, avg_specificity=70.29% avg_auc=79.57%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.344112 Test loss=0.545949 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.33457499742507935
[5/24] Train loss=0.35887768864631653
[10/24] Train loss=0.3486647605895996
[15/24] Train loss=0.3419959843158722
[20/24] Train loss=0.3250900208950043
Test set avg_accuracy=71.89% avg_sensitivity=78.16%, avg_specificity=70.07% avg_auc=80.11%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.343356 Test loss=0.544457 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3344307541847229
[5/24] Train loss=0.36045876145362854
[10/24] Train loss=0.34860774874687195
[15/24] Train loss=0.34108060598373413
[20/24] Train loss=0.3275641202926636
Test set avg_accuracy=71.37% avg_sensitivity=78.39%, avg_specificity=69.33% avg_auc=79.59%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.343883 Test loss=0.550684 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.33293700218200684
[5/24] Train loss=0.35759982466697693
[10/24] Train loss=0.3494262993335724
[15/24] Train loss=0.34365129470825195
[20/24] Train loss=0.32766616344451904
Test set avg_accuracy=70.78% avg_sensitivity=79.66%, avg_specificity=68.21% avg_auc=80.49%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.343917 Test loss=0.549516 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.33402886986732483
[5/24] Train loss=0.36002010107040405
[10/24] Train loss=0.35098204016685486
[15/24] Train loss=0.3414151072502136
[20/24] Train loss=0.327068954706192
Test set avg_accuracy=70.61% avg_sensitivity=80.01%, avg_specificity=67.89% avg_auc=80.08%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.343932 Test loss=0.553293 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.3336368799209595
[5/24] Train loss=0.3583095073699951
[10/24] Train loss=0.3488088548183441
[15/24] Train loss=0.3407018482685089
[20/24] Train loss=0.3268502652645111
Test set avg_accuracy=71.15% avg_sensitivity=79.90%, avg_specificity=68.61% avg_auc=80.51%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.342796 Test loss=0.544838 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.33328479528427124
[5/24] Train loss=0.3577944040298462
[10/24] Train loss=0.34850913286209106
[15/24] Train loss=0.3399103581905365
[20/24] Train loss=0.32578304409980774
Test set avg_accuracy=70.78% avg_sensitivity=80.07%, avg_specificity=68.09% avg_auc=80.10%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.342212 Test loss=0.550516 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.33291009068489075
[5/24] Train loss=0.3571966290473938
[10/24] Train loss=0.3484236001968384
[15/24] Train loss=0.340104877948761
[20/24] Train loss=0.32482555508613586
Test set avg_accuracy=70.77% avg_sensitivity=79.84%, avg_specificity=68.14% avg_auc=79.84%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.341556 Test loss=0.551331 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.33215034008026123
[5/24] Train loss=0.3574204444885254
[10/24] Train loss=0.3471679091453552
[15/24] Train loss=0.33964258432388306
[20/24] Train loss=0.3245624005794525
Test set avg_accuracy=70.87% avg_sensitivity=79.90%, avg_specificity=68.26% avg_auc=79.94%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.341129 Test loss=0.550903 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3318372964859009
[5/24] Train loss=0.3572532832622528
[10/24] Train loss=0.34722253680229187
[15/24] Train loss=0.33949366211891174
[20/24] Train loss=0.32445278763771057
Test set avg_accuracy=71.05% avg_sensitivity=79.84%, avg_specificity=68.51% avg_auc=79.97%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.341007 Test loss=0.550289 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3318372070789337
[5/24] Train loss=0.35692843794822693
[10/24] Train loss=0.3470803201198578
[15/24] Train loss=0.3394264578819275
[20/24] Train loss=0.3241482675075531
Test set avg_accuracy=70.99% avg_sensitivity=79.84%, avg_specificity=68.42% avg_auc=79.84%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.340864 Test loss=0.551143 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3316553831100464
[5/24] Train loss=0.356891393661499
[10/24] Train loss=0.3468411862850189
[15/24] Train loss=0.3392554223537445
[20/24] Train loss=0.32411426305770874
Test set avg_accuracy=71.00% avg_sensitivity=79.90%, avg_specificity=68.42% avg_auc=79.84%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.340746 Test loss=0.551401 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.33158472180366516
[5/24] Train loss=0.35678592324256897
[10/24] Train loss=0.34682849049568176
[15/24] Train loss=0.3392028212547302
[20/24] Train loss=0.32396435737609863
Test set avg_accuracy=71.00% avg_sensitivity=79.90%, avg_specificity=68.42% avg_auc=79.80%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.340674 Test loss=0.551771 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3314942419528961
[5/24] Train loss=0.35665592551231384
[10/24] Train loss=0.3467786908149719
[15/24] Train loss=0.3391372263431549
[20/24] Train loss=0.3238855004310608
Test set avg_accuracy=71.00% avg_sensitivity=79.90%, avg_specificity=68.42% avg_auc=79.79%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.340606 Test loss=0.551959 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.33144611120224
[5/24] Train loss=0.35660186409950256
[10/24] Train loss=0.34670236706733704
[15/24] Train loss=0.33910638093948364
[20/24] Train loss=0.3238178491592407
Test set avg_accuracy=70.98% avg_sensitivity=79.78%, avg_specificity=68.42% avg_auc=79.77%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.340557 Test loss=0.552088 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3314078450202942
[5/24] Train loss=0.35656145215034485
[10/24] Train loss=0.3466631770133972
[15/24] Train loss=0.3390836715698242
[20/24] Train loss=0.3237706124782562
Test set avg_accuracy=70.98% avg_sensitivity=79.78%, avg_specificity=68.42% avg_auc=79.75%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.340522 Test loss=0.552228 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.3313823938369751
[5/24] Train loss=0.35651934146881104
[10/24] Train loss=0.3466324806213379
[15/24] Train loss=0.33906564116477966
[20/24] Train loss=0.32373833656311035
Test set avg_accuracy=70.98% avg_sensitivity=79.78%, avg_specificity=68.42% avg_auc=79.75%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.340496 Test loss=0.552310 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.331365168094635
[5/24] Train loss=0.3564893305301666
[10/24] Train loss=0.34661105275154114
[15/24] Train loss=0.3390553891658783
[20/24] Train loss=0.3237174153327942
Test set avg_accuracy=70.98% avg_sensitivity=79.78%, avg_specificity=68.42% avg_auc=79.74%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.340479 Test loss=0.552361 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.33135467767715454
[5/24] Train loss=0.35647183656692505
[10/24] Train loss=0.3465970754623413
[15/24] Train loss=0.33904993534088135
[20/24] Train loss=0.32370665669441223
Test set avg_accuracy=70.98% avg_sensitivity=79.78%, avg_specificity=68.42% avg_auc=79.74%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.340470 Test loss=0.552394 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3313494622707367
[5/24] Train loss=0.3564627766609192
[10/24] Train loss=0.3465903401374817
[15/24] Train loss=0.33904770016670227
[20/24] Train loss=0.32370325922966003
Test set avg_accuracy=70.98% avg_sensitivity=79.78%, avg_specificity=68.42% avg_auc=79.74%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.340465 Test loss=0.552406 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=78.14% sen=66.63%, spe=81.47%, auc=83.37%!
Fold[10] Avg_overlap=0.52%(0.2586062664814744)
Final Avg Result: avg_acc=74.09%(5.487529758999283) avg_sen=65.44% (11.937979001942644) avg_spe=77.31% (8.953656023497564) avg_auc=79.76% (3.8754524138946627) avg_overlap=0.48% (0.1512024093345515)
