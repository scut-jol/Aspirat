{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.9436137080192566
[5/24] Train loss=0.8866365551948547
[10/24] Train loss=0.8316959738731384
[15/24] Train loss=0.7983245253562927
[20/24] Train loss=0.7577526569366455
Test set avg_accuracy=61.51% avg_sensitivity=25.83%, avg_specificity=74.25% avg_auc=50.68%
Best model saved!! Metric=50.67941850016425!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.830369 Test loss=0.703155 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7349425554275513
[5/24] Train loss=0.6942873597145081
[10/24] Train loss=0.6896010041236877
[15/24] Train loss=0.6927685737609863
[20/24] Train loss=0.6715230941772461
Test set avg_accuracy=68.71% avg_sensitivity=10.69%, avg_specificity=89.43% avg_auc=52.09%
Best model saved!! Metric=52.09369914186953!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.692226 Test loss=0.629042 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6545365452766418
[5/24] Train loss=0.6415855288505554
[10/24] Train loss=0.6284211874008179
[15/24] Train loss=0.6525595784187317
[20/24] Train loss=0.6541789174079895
Test set avg_accuracy=72.12% avg_sensitivity=4.21%, avg_specificity=96.38% avg_auc=53.69%
Best model saved!! Metric=53.69033349162299!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.644811 Test loss=0.610237 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.626171886920929
[5/24] Train loss=0.6189471483230591
[10/24] Train loss=0.6229892373085022
[15/24] Train loss=0.6314646601676941
[20/24] Train loss=0.6312445402145386
Test set avg_accuracy=72.58% avg_sensitivity=3.12%, avg_specificity=97.38% avg_auc=55.66%
Best model saved!! Metric=55.662058371198555!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.625093 Test loss=0.596710 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6055314540863037
[5/24] Train loss=0.5923160910606384
[10/24] Train loss=0.6051108241081238
[15/24] Train loss=0.6181379556655884
[20/24] Train loss=0.6139639019966125
Test set avg_accuracy=72.75% avg_sensitivity=3.61%, avg_specificity=97.44% avg_auc=57.37%
Best model saved!! Metric=57.36708805641138!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.609219 Test loss=0.583354 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6042722463607788
[5/24] Train loss=0.5783902406692505
[10/24] Train loss=0.5936437845230103
[15/24] Train loss=0.5993085503578186
[20/24] Train loss=0.6012353301048279
Test set avg_accuracy=73.02% avg_sensitivity=3.36%, avg_specificity=97.90% avg_auc=58.74%
Best model saved!! Metric=58.740120412641986!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.598858 Test loss=0.574247 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5945659875869751
[5/24] Train loss=0.5694678425788879
[10/24] Train loss=0.5840944647789001
[15/24] Train loss=0.5866551399230957
[20/24] Train loss=0.5841085314750671
Test set avg_accuracy=73.27% avg_sensitivity=2.82%, avg_specificity=98.43% avg_auc=60.02%
Best model saved!! Metric=60.017706815668205!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.587907 Test loss=0.567459 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5889533162117004
[5/24] Train loss=0.5548526048660278
[10/24] Train loss=0.5732430815696716
[15/24] Train loss=0.5825310349464417
[20/24] Train loss=0.5955680012702942
Test set avg_accuracy=73.52% avg_sensitivity=2.87%, avg_specificity=98.75% avg_auc=61.27%
Best model saved!! Metric=61.2678992858079!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.581909 Test loss=0.561420 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5736992359161377
[5/24] Train loss=0.5448830723762512
[10/24] Train loss=0.5729763507843018
[15/24] Train loss=0.5739238858222961
[20/24] Train loss=0.5833385586738586
Test set avg_accuracy=73.61% avg_sensitivity=2.82%, avg_specificity=98.89% avg_auc=62.59%
Best model saved!! Metric=62.592382388175615!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.572869 Test loss=0.555810 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5820428729057312
[5/24] Train loss=0.5444976687431335
[10/24] Train loss=0.5628564953804016
[15/24] Train loss=0.5614915490150452
[20/24] Train loss=0.5785033106803894
Test set avg_accuracy=73.80% avg_sensitivity=3.51%, avg_specificity=98.90% avg_auc=64.01%
Best model saved!! Metric=64.00554821135455!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.567192 Test loss=0.550290 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5724371671676636
[5/24] Train loss=0.5383853316307068
[10/24] Train loss=0.558688759803772
[15/24] Train loss=0.5672728419303894
[20/24] Train loss=0.5737200975418091
Test set avg_accuracy=73.82% avg_sensitivity=4.35%, avg_specificity=98.62% avg_auc=65.49%
Best model saved!! Metric=65.48698027488189!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.560178 Test loss=0.544643 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.557709276676178
[5/24] Train loss=0.5263255834579468
[10/24] Train loss=0.5572522282600403
[15/24] Train loss=0.5515641570091248
[20/24] Train loss=0.5648145079612732
Test set avg_accuracy=73.76% avg_sensitivity=5.74%, avg_specificity=98.06% avg_auc=67.15%
Best model saved!! Metric=67.14523567219929!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.552278 Test loss=0.538101 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5541960000991821
[5/24] Train loss=0.5212574005126953
[10/24] Train loss=0.5470322370529175
[15/24] Train loss=0.5366731286048889
[20/24] Train loss=0.5487737059593201
Test set avg_accuracy=73.93% avg_sensitivity=8.07%, avg_specificity=97.46% avg_auc=69.02%
Best model saved!! Metric=69.01907074148723!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.544190 Test loss=0.530006 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5485829710960388
[5/24] Train loss=0.5107278823852539
[10/24] Train loss=0.5321081280708313
[15/24] Train loss=0.5299380421638489
[20/24] Train loss=0.5464490056037903
Test set avg_accuracy=74.04% avg_sensitivity=11.68%, avg_specificity=96.31% avg_auc=70.83%
Best model saved!! Metric=70.8328367654734!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.534963 Test loss=0.520934 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5333214998245239
[5/24] Train loss=0.49762117862701416
[10/24] Train loss=0.5277726650238037
[15/24] Train loss=0.5166297554969788
[20/24] Train loss=0.5262203812599182
Test set avg_accuracy=74.31% avg_sensitivity=18.36%, avg_specificity=94.29% avg_auc=72.70%
Best model saved!! Metric=72.70377330659285!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.521732 Test loss=0.510202 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5106789469718933
[5/24] Train loss=0.4887712001800537
[10/24] Train loss=0.5140148997306824
[15/24] Train loss=0.500563383102417
[20/24] Train loss=0.5135409832000732
Test set avg_accuracy=74.84% avg_sensitivity=28.06%, avg_specificity=91.55% avg_auc=74.32%
Best model saved!! Metric=74.32424291362324!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.509432 Test loss=0.500203 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4998612403869629
[5/24] Train loss=0.4737277626991272
[10/24] Train loss=0.4976620674133301
[15/24] Train loss=0.48376572132110596
[20/24] Train loss=0.4994145929813385
Test set avg_accuracy=74.90% avg_sensitivity=36.52%, avg_specificity=88.60% avg_auc=75.75%
Best model saved!! Metric=75.75021384842438!!
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.496916 Test loss=0.492727 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4884611666202545
[5/24] Train loss=0.4639657437801361
[10/24] Train loss=0.4908643662929535
[15/24] Train loss=0.47827017307281494
[20/24] Train loss=0.48000001907348633
Test set avg_accuracy=75.14% avg_sensitivity=38.10%, avg_specificity=88.37% avg_auc=77.11%
Best model saved!! Metric=77.1133571085507!!
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.485683 Test loss=0.481973 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.47338494658470154
[5/24] Train loss=0.45966988801956177
[10/24] Train loss=0.4850839674472809
[15/24] Train loss=0.47391220927238464
[20/24] Train loss=0.4606505334377289
Test set avg_accuracy=75.91% avg_sensitivity=38.10%, avg_specificity=89.42% avg_auc=78.48%
Best model saved!! Metric=78.47640418825517!!
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.474132 Test loss=0.469647 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4549378454685211
[5/24] Train loss=0.43734946846961975
[10/24] Train loss=0.466801255941391
[15/24] Train loss=0.465772420167923
[20/24] Train loss=0.44339123368263245
Test set avg_accuracy=76.74% avg_sensitivity=36.42%, avg_specificity=91.15% avg_auc=79.55%
Best model saved!! Metric=79.55383913334796!!
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.462288 Test loss=0.460017 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.4422387182712555
[5/24] Train loss=0.43071454763412476
[10/24] Train loss=0.45806679129600525
[15/24] Train loss=0.45092546939849854
[20/24] Train loss=0.43869441747665405
Test set avg_accuracy=77.46% avg_sensitivity=36.07%, avg_specificity=92.24% avg_auc=80.43%
Best model saved!! Metric=80.42668083375136!!
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.450837 Test loss=0.453086 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.42991191148757935
[5/24] Train loss=0.4181676506996155
[10/24] Train loss=0.444720596075058
[15/24] Train loss=0.43034127354621887
[20/24] Train loss=0.4275168776512146
Test set avg_accuracy=78.06% avg_sensitivity=41.37%, avg_specificity=91.16% avg_auc=81.25%
Best model saved!! Metric=81.25312422427211!!
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.438150 Test loss=0.445287 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.41746804118156433
[5/24] Train loss=0.41045376658439636
[10/24] Train loss=0.4396335482597351
[15/24] Train loss=0.41824889183044434
[20/24] Train loss=0.42601850628852844
Test set avg_accuracy=78.20% avg_sensitivity=46.61%, avg_specificity=89.49% avg_auc=81.97%
Best model saved!! Metric=81.97090122541726!!
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.427873 Test loss=0.438749 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.41005706787109375
[5/24] Train loss=0.40152037143707275
[10/24] Train loss=0.43185585737228394
[15/24] Train loss=0.40582290291786194
[20/24] Train loss=0.4224567711353302
Test set avg_accuracy=78.53% avg_sensitivity=46.36%, avg_specificity=90.02% avg_auc=82.56%
Best model saved!! Metric=82.56352126667169!!
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.419510 Test loss=0.432551 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.40137016773223877
[5/24] Train loss=0.3990285098552704
[10/24] Train loss=0.42445847392082214
[15/24] Train loss=0.4040371775627136
[20/24] Train loss=0.40809890627861023
Test set avg_accuracy=79.36% avg_sensitivity=42.26%, avg_specificity=92.61% avg_auc=83.00%
Best model saved!! Metric=83.00387021273973!!
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.412616 Test loss=0.428681 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.39650192856788635
[5/24] Train loss=0.39105722308158875
[10/24] Train loss=0.41359472274780273
[15/24] Train loss=0.39360418915748596
[20/24] Train loss=0.39659643173217773
Test set avg_accuracy=79.57% avg_sensitivity=40.82%, avg_specificity=93.41% avg_auc=83.40%
Best model saved!! Metric=83.39720004802025!!
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.405681 Test loss=0.426312 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.39379599690437317
[5/24] Train loss=0.38658174872398376
[10/24] Train loss=0.4113748073577881
[15/24] Train loss=0.39202553033828735
[20/24] Train loss=0.3885648846626282
Test set avg_accuracy=79.86% avg_sensitivity=41.02%, avg_specificity=93.73% avg_auc=83.72%
Best model saved!! Metric=83.72133244159511!!
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.399328 Test loss=0.423269 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.38336145877838135
[5/24] Train loss=0.37574467062950134
[10/24] Train loss=0.40567630529403687
[15/24] Train loss=0.38740718364715576
[20/24] Train loss=0.38549429178237915
Test set avg_accuracy=80.07% avg_sensitivity=42.80%, avg_specificity=93.37% avg_auc=84.01%
Best model saved!! Metric=84.01259299007357!!
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.392729 Test loss=0.418914 Current lr=[0.000210185142098938]

[0/24] Train loss=0.37780579924583435
[5/24] Train loss=0.3717951476573944
[10/24] Train loss=0.4062771797180176
[15/24] Train loss=0.3833431899547577
[20/24] Train loss=0.38014939427375793
Test set avg_accuracy=80.27% avg_sensitivity=42.85%, avg_specificity=93.64% avg_auc=84.30%
Best model saved!! Metric=84.29688482980305!!
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.387721 Test loss=0.416122 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.37207281589508057
[5/24] Train loss=0.3625292479991913
[10/24] Train loss=0.3999064266681671
[15/24] Train loss=0.37647509574890137
[20/24] Train loss=0.377112478017807
Test set avg_accuracy=80.56% avg_sensitivity=42.80%, avg_specificity=94.04% avg_auc=84.51%
Best model saved!! Metric=84.50999441366622!!
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.382600 Test loss=0.414606 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3686082363128662
[5/24] Train loss=0.3589625358581543
[10/24] Train loss=0.39863356947898865
[15/24] Train loss=0.3702370524406433
[20/24] Train loss=0.37171876430511475
Test set avg_accuracy=80.68% avg_sensitivity=43.94%, avg_specificity=93.80% avg_auc=84.67%
Best model saved!! Metric=84.66939160374648!!
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.378260 Test loss=0.412008 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.36519432067871094
[5/24] Train loss=0.35219651460647583
[10/24] Train loss=0.39285966753959656
[15/24] Train loss=0.3637195825576782
[20/24] Train loss=0.36780691146850586
Test set avg_accuracy=80.73% avg_sensitivity=43.59%, avg_specificity=93.99% avg_auc=84.81%
Best model saved!! Metric=84.80637875552853!!
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.373449 Test loss=0.410825 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3614794611930847
[5/24] Train loss=0.34981435537338257
[10/24] Train loss=0.38743147253990173
[15/24] Train loss=0.3598763346672058
[20/24] Train loss=0.3627086281776428
Test set avg_accuracy=80.89% avg_sensitivity=44.04%, avg_specificity=94.04% avg_auc=84.98%
Best model saved!! Metric=84.97905321566563!!
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.369034 Test loss=0.408675 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.35768190026283264
[5/24] Train loss=0.3414202630519867
[10/24] Train loss=0.38753342628479004
[15/24] Train loss=0.35877925157546997
[20/24] Train loss=0.35805457830429077
Test set avg_accuracy=81.08% avg_sensitivity=43.25%, avg_specificity=94.59% avg_auc=85.14%
Best model saved!! Metric=85.13850723963151!!
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.365155 Test loss=0.407812 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.35423165559768677
[5/24] Train loss=0.34133315086364746
[10/24] Train loss=0.3801414966583252
[15/24] Train loss=0.35423851013183594
[20/24] Train loss=0.3551490306854248
Test set avg_accuracy=81.11% avg_sensitivity=43.99%, avg_specificity=94.36% avg_auc=85.23%
Best model saved!! Metric=85.22501278543835!!
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.361294 Test loss=0.406397 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.34999755024909973
[5/24] Train loss=0.3361305594444275
[10/24] Train loss=0.37510454654693604
[15/24] Train loss=0.34931591153144836
[20/24] Train loss=0.35065823793411255
Test set avg_accuracy=81.21% avg_sensitivity=45.08%, avg_specificity=94.12% avg_auc=85.41%
Best model saved!! Metric=85.41258646729223!!
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.356969 Test loss=0.403783 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3437228798866272
[5/24] Train loss=0.3309646248817444
[10/24] Train loss=0.37094125151634216
[15/24] Train loss=0.34249576926231384
[20/24] Train loss=0.3457890748977661
Test set avg_accuracy=81.29% avg_sensitivity=43.79%, avg_specificity=94.68% avg_auc=85.47%
Best model saved!! Metric=85.47043461921602!!
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.353647 Test loss=0.405604 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.34066882729530334
[5/24] Train loss=0.3276844918727875
[10/24] Train loss=0.3625152111053467
[15/24] Train loss=0.34107255935668945
[20/24] Train loss=0.3458147346973419
Test set avg_accuracy=81.38% avg_sensitivity=44.93%, avg_specificity=94.40% avg_auc=85.63%
Best model saved!! Metric=85.63363530779789!!
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.348352 Test loss=0.402228 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.33841779828071594
[5/24] Train loss=0.3232695758342743
[10/24] Train loss=0.36337175965309143
[15/24] Train loss=0.3371132016181946
[20/24] Train loss=0.33887648582458496
Test set avg_accuracy=81.59% avg_sensitivity=45.72%, avg_specificity=94.40% avg_auc=85.80%
Best model saved!! Metric=85.79666986656017!!
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.345885 Test loss=0.400153 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3321194052696228
[5/24] Train loss=0.3189472556114197
[10/24] Train loss=0.3623538315296173
[15/24] Train loss=0.3339100182056427
[20/24] Train loss=0.3360360562801361
Test set avg_accuracy=81.71% avg_sensitivity=45.62%, avg_specificity=94.59% avg_auc=85.87%
Best model saved!! Metric=85.86814940736683!!
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.341874 Test loss=0.400165 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3262655436992645
[5/24] Train loss=0.31214168667793274
[10/24] Train loss=0.3565278649330139
[15/24] Train loss=0.3292202949523926
[20/24] Train loss=0.3316686153411865
Test set avg_accuracy=81.85% avg_sensitivity=46.56%, avg_specificity=94.45% avg_auc=85.93%
Best model saved!! Metric=85.93126999514463!!
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.337294 Test loss=0.399089 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.32426899671554565
[5/24] Train loss=0.31530246138572693
[10/24] Train loss=0.35575708746910095
[15/24] Train loss=0.32836800813674927
[20/24] Train loss=0.3285544216632843
Test set avg_accuracy=81.90% avg_sensitivity=46.02%, avg_specificity=94.72% avg_auc=86.02%
Best model saved!! Metric=86.01925759381591!!
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.333908 Test loss=0.398627 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.32273146510124207
[5/24] Train loss=0.30926215648651123
[10/24] Train loss=0.3456428050994873
[15/24] Train loss=0.32349520921707153
[20/24] Train loss=0.32888051867485046
Test set avg_accuracy=82.15% avg_sensitivity=47.20%, avg_specificity=94.63% avg_auc=86.14%
Best model saved!! Metric=86.14201878683437!!
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.331297 Test loss=0.396646 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3155917525291443
[5/24] Train loss=0.3040534257888794
[10/24] Train loss=0.345441073179245
[15/24] Train loss=0.3192288875579834
[20/24] Train loss=0.3215334713459015
Test set avg_accuracy=82.25% avg_sensitivity=47.85%, avg_specificity=94.54% avg_auc=86.24%
Best model saved!! Metric=86.24428917815492!!
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.327742 Test loss=0.395164 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3073437511920929
[5/24] Train loss=0.3033052086830139
[10/24] Train loss=0.3391619324684143
[15/24] Train loss=0.31896471977233887
[20/24] Train loss=0.32064154744148254
Test set avg_accuracy=82.45% avg_sensitivity=48.64%, avg_specificity=94.52% avg_auc=86.39%
Best model saved!! Metric=86.39151954486725!!
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.324359 Test loss=0.392819 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3087829649448395
[5/24] Train loss=0.300675630569458
[10/24] Train loss=0.3340133726596832
[15/24] Train loss=0.3092135787010193
[20/24] Train loss=0.31785812973976135
Test set avg_accuracy=82.33% avg_sensitivity=46.66%, avg_specificity=95.07% avg_auc=86.39%
Best model saved!! Metric=86.39344315330486!!
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.321137 Test loss=0.395402 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3066770136356354
[5/24] Train loss=0.2966153621673584
[10/24] Train loss=0.33527326583862305
[15/24] Train loss=0.3102657198905945
[20/24] Train loss=0.315003365278244
Test set avg_accuracy=82.45% avg_sensitivity=47.75%, avg_specificity=94.84% avg_auc=86.53%
Best model saved!! Metric=86.53178557466795!!
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.317815 Test loss=0.392430 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3018180727958679
[5/24] Train loss=0.29266396164894104
[10/24] Train loss=0.33397144079208374
[15/24] Train loss=0.30444350838661194
[20/24] Train loss=0.31476762890815735
Test set avg_accuracy=82.45% avg_sensitivity=47.85%, avg_specificity=94.80% avg_auc=86.63%
Best model saved!! Metric=86.62920759835825!!
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.315873 Test loss=0.391628 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.29949820041656494
[5/24] Train loss=0.29104501008987427
[10/24] Train loss=0.323480486869812
[15/24] Train loss=0.3020201623439789
[20/24] Train loss=0.3081454932689667
Test set avg_accuracy=82.64% avg_sensitivity=48.94%, avg_specificity=94.68% avg_auc=86.78%
Best model saved!! Metric=86.77755278359692!!
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.312376 Test loss=0.389963 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2936018109321594
[5/24] Train loss=0.2865644097328186
[10/24] Train loss=0.32240357995033264
[15/24] Train loss=0.30007827281951904
[20/24] Train loss=0.30552786588668823
Test set avg_accuracy=82.59% avg_sensitivity=48.79%, avg_specificity=94.66% avg_auc=86.84%
Best model saved!! Metric=86.83589932497958!!
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.308582 Test loss=0.388999 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.288751482963562
[5/24] Train loss=0.2858637869358063
[10/24] Train loss=0.31918349862098694
[15/24] Train loss=0.3020704388618469
[20/24] Train loss=0.3022376000881195
Test set avg_accuracy=82.66% avg_sensitivity=50.32%, avg_specificity=94.20% avg_auc=87.00%
Best model saved!! Metric=87.00347185091964!!
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.306980 Test loss=0.386097 Current lr=[0.000297555943323901]

[0/24] Train loss=0.28597986698150635
[5/24] Train loss=0.2791779339313507
[10/24] Train loss=0.31877055764198303
[15/24] Train loss=0.2933720350265503
[20/24] Train loss=0.30147331953048706
Test set avg_accuracy=82.70% avg_sensitivity=50.22%, avg_specificity=94.29% avg_auc=87.02%
Best model saved!! Metric=87.01687153242254!!
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.304236 Test loss=0.386665 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.284881055355072
[5/24] Train loss=0.28222891688346863
[10/24] Train loss=0.313888818025589
[15/24] Train loss=0.2907860279083252
[20/24] Train loss=0.2995387315750122
Test set avg_accuracy=82.67% avg_sensitivity=49.48%, avg_specificity=94.52% avg_auc=87.11%
Best model saved!! Metric=87.11357220294872!!
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.301886 Test loss=0.385946 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.28448957204818726
[5/24] Train loss=0.27459225058555603
[10/24] Train loss=0.3086153268814087
[15/24] Train loss=0.2884519100189209
[20/24] Train loss=0.293763130903244
Test set avg_accuracy=82.66% avg_sensitivity=49.63%, avg_specificity=94.45% avg_auc=87.22%
Best model saved!! Metric=87.22365069579105!!
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.298596 Test loss=0.385327 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2799496650695801
[5/24] Train loss=0.27247753739356995
[10/24] Train loss=0.3042915463447571
[15/24] Train loss=0.2851561903953552
[20/24] Train loss=0.28893473744392395
Test set avg_accuracy=82.70% avg_sensitivity=49.73%, avg_specificity=94.47% avg_auc=87.32%
Best model saved!! Metric=87.32032513529305!!
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.295754 Test loss=0.384413 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.27807456254959106
[5/24] Train loss=0.27661848068237305
[10/24] Train loss=0.30495497584342957
[15/24] Train loss=0.28279581665992737
[20/24] Train loss=0.28914687037467957
Test set avg_accuracy=82.72% avg_sensitivity=49.78%, avg_specificity=94.49% avg_auc=87.32%
Best model saved!! Metric=87.32449586813277!!
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.295219 Test loss=0.384100 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.2759091854095459
[5/24] Train loss=0.27049505710601807
[10/24] Train loss=0.3084167242050171
[15/24] Train loss=0.27938953042030334
[20/24] Train loss=0.2856864035129547
Test set avg_accuracy=82.92% avg_sensitivity=51.86%, avg_specificity=94.01% avg_auc=87.49%
Best model saved!! Metric=87.49129895069781!!
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.294099 Test loss=0.381025 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2712141275405884
[5/24] Train loss=0.27358514070510864
[10/24] Train loss=0.307079017162323
[15/24] Train loss=0.27514368295669556
[20/24] Train loss=0.29103681445121765
Test set avg_accuracy=83.40% avg_sensitivity=58.44%, avg_specificity=92.31% avg_auc=87.71%
Best model saved!! Metric=87.70731143456683!!
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.293481 Test loss=0.374186 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2668026387691498
[5/24] Train loss=0.2704848051071167
[10/24] Train loss=0.30811136960983276
[15/24] Train loss=0.2772790789604187
[20/24] Train loss=0.3065590560436249
Test set avg_accuracy=83.02% avg_sensitivity=63.83%, avg_specificity=89.87% avg_auc=87.91%
Best model saved!! Metric=87.91026961208426!!
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.293290 Test loss=0.373524 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.26994338631629944
[5/24] Train loss=0.26244083046913147
[10/24] Train loss=0.2995087504386902
[15/24] Train loss=0.2743598222732544
[20/24] Train loss=0.30334874987602234
Test set avg_accuracy=83.10% avg_sensitivity=64.52%, avg_specificity=89.73% avg_auc=87.98%
Best model saved!! Metric=87.98165297246905!!
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.290932 Test loss=0.373322 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.26570236682891846
[5/24] Train loss=0.2604917287826538
[10/24] Train loss=0.29365599155426025
[15/24] Train loss=0.27008476853370667
[20/24] Train loss=0.29822906851768494
Test set avg_accuracy=83.24% avg_sensitivity=63.29%, avg_specificity=90.37% avg_auc=88.03%
Best model saved!! Metric=88.02874640449167!!
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.287184 Test loss=0.371768 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2639382779598236
[5/24] Train loss=0.25690534710884094
[10/24] Train loss=0.3000611364841461
[15/24] Train loss=0.2677682340145111
[20/24] Train loss=0.2927686870098114
Test set avg_accuracy=83.26% avg_sensitivity=62.54%, avg_specificity=90.65% avg_auc=88.00%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.285002 Test loss=0.371771 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2586585581302643
[5/24] Train loss=0.256703644990921
[10/24] Train loss=0.2944297194480896
[15/24] Train loss=0.26660552620887756
[20/24] Train loss=0.2902757525444031
Test set avg_accuracy=83.14% avg_sensitivity=61.21%, avg_specificity=90.97% avg_auc=88.00%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.282628 Test loss=0.371301 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.26457512378692627
[5/24] Train loss=0.2561284899711609
[10/24] Train loss=0.2905104458332062
[15/24] Train loss=0.2657732367515564
[20/24] Train loss=0.2847610116004944
Test set avg_accuracy=83.28% avg_sensitivity=60.47%, avg_specificity=91.43% avg_auc=88.01%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.281629 Test loss=0.371244 Current lr=[0.000276307469034998]

[0/24] Train loss=0.26178768277168274
[5/24] Train loss=0.25290927290916443
[10/24] Train loss=0.29259052872657776
[15/24] Train loss=0.2648935616016388
[20/24] Train loss=0.28213566541671753
Test set avg_accuracy=83.57% avg_sensitivity=60.51%, avg_specificity=91.80% avg_auc=88.11%
Best model saved!! Metric=88.1111730260433!!
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.279994 Test loss=0.370176 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.25637078285217285
[5/24] Train loss=0.2591647207736969
[10/24] Train loss=0.29128971695899963
[15/24] Train loss=0.2653462290763855
[20/24] Train loss=0.2804703116416931
Test set avg_accuracy=83.50% avg_sensitivity=60.51%, avg_specificity=91.71% avg_auc=88.14%
Best model saved!! Metric=88.1407441339342!!
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.279169 Test loss=0.369810 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2572099566459656
[5/24] Train loss=0.25296688079833984
[10/24] Train loss=0.28594180941581726
[15/24] Train loss=0.25861021876335144
[20/24] Train loss=0.28437596559524536
Test set avg_accuracy=83.57% avg_sensitivity=60.81%, avg_specificity=91.69% avg_auc=88.14%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.277795 Test loss=0.369978 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.25707516074180603
[5/24] Train loss=0.2539396286010742
[10/24] Train loss=0.2905709147453308
[15/24] Train loss=0.2604662775993347
[20/24] Train loss=0.28259265422821045
Test set avg_accuracy=83.54% avg_sensitivity=61.26%, avg_specificity=91.50% avg_auc=88.16%
Best model saved!! Metric=88.15978785746655!!
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.276028 Test loss=0.369746 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2554682195186615
[5/24] Train loss=0.25456503033638
[10/24] Train loss=0.2875303328037262
[15/24] Train loss=0.2567061483860016
[20/24] Train loss=0.2794511318206787
Test set avg_accuracy=83.45% avg_sensitivity=62.94%, avg_specificity=90.78% avg_auc=88.26%
Best model saved!! Metric=88.2550807963634!!
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.275540 Test loss=0.368978 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2554374933242798
[5/24] Train loss=0.24942614138126373
[10/24] Train loss=0.2886461615562439
[15/24] Train loss=0.25689831376075745
[20/24] Train loss=0.2813495397567749
Test set avg_accuracy=83.61% avg_sensitivity=62.54%, avg_specificity=91.13% avg_auc=88.27%
Best model saved!! Metric=88.27394527456406!!
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.275337 Test loss=0.368798 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.25452736020088196
[5/24] Train loss=0.25084924697875977
[10/24] Train loss=0.2892052233219147
[15/24] Train loss=0.2573433816432953
[20/24] Train loss=0.2821460962295532
Test set avg_accuracy=83.54% avg_sensitivity=63.58%, avg_specificity=90.67% avg_auc=88.32%
Best model saved!! Metric=88.31857299031665!!
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.273798 Test loss=0.368124 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.25197988748550415
[5/24] Train loss=0.24814648926258087
[10/24] Train loss=0.2866578698158264
[15/24] Train loss=0.2554829716682434
[20/24] Train loss=0.2769628167152405
Test set avg_accuracy=83.46% avg_sensitivity=63.04%, avg_specificity=90.76% avg_auc=88.37%
Best model saved!! Metric=88.37338708711384!!
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.272770 Test loss=0.367277 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.24907024204730988
[5/24] Train loss=0.24718987941741943
[10/24] Train loss=0.2841578722000122
[15/24] Train loss=0.2549981474876404
[20/24] Train loss=0.2792646884918213
Test set avg_accuracy=83.59% avg_sensitivity=63.24%, avg_specificity=90.86% avg_auc=88.39%
Best model saved!! Metric=88.39091815492026!!
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.272320 Test loss=0.366759 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.24848394095897675
[5/24] Train loss=0.25081369280815125
[10/24] Train loss=0.28439807891845703
[15/24] Train loss=0.2529577612876892
[20/24] Train loss=0.28059089183807373
Test set avg_accuracy=83.59% avg_sensitivity=63.33%, avg_specificity=90.83% avg_auc=88.43%
Best model saved!! Metric=88.42647867999189!!
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.271826 Test loss=0.366714 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.2516741156578064
[5/24] Train loss=0.24542291462421417
[10/24] Train loss=0.2834809720516205
[15/24] Train loss=0.2533046305179596
[20/24] Train loss=0.2747592628002167
Test set avg_accuracy=83.54% avg_sensitivity=63.63%, avg_specificity=90.65% avg_auc=88.44%
Best model saved!! Metric=88.44416713394321!!
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.270325 Test loss=0.366794 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2512224614620209
[5/24] Train loss=0.2500709593296051
[10/24] Train loss=0.281454861164093
[15/24] Train loss=0.255088210105896
[20/24] Train loss=0.27482372522354126
Test set avg_accuracy=83.62% avg_sensitivity=63.38%, avg_specificity=90.85% avg_auc=88.45%
Best model saved!! Metric=88.45169543787405!!
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.270239 Test loss=0.366486 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2485361099243164
[5/24] Train loss=0.24493739008903503
[10/24] Train loss=0.28035980463027954
[15/24] Train loss=0.25010839104652405
[20/24] Train loss=0.2695789337158203
Test set avg_accuracy=83.55% avg_sensitivity=62.10%, avg_specificity=91.22% avg_auc=88.45%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.269223 Test loss=0.366821 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.24825872480869293
[5/24] Train loss=0.24548615515232086
[10/24] Train loss=0.28075215220451355
[15/24] Train loss=0.24888461828231812
[20/24] Train loss=0.27021318674087524
Test set avg_accuracy=83.58% avg_sensitivity=61.36%, avg_specificity=91.52% avg_auc=88.46%
Best model saved!! Metric=88.46173317644848!!
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.267634 Test loss=0.366528 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.24723027646541595
[5/24] Train loss=0.2430981546640396
[10/24] Train loss=0.2829255163669586
[15/24] Train loss=0.2499275952577591
[20/24] Train loss=0.26891928911209106
Test set avg_accuracy=83.63% avg_sensitivity=61.85%, avg_specificity=91.41% avg_auc=88.51%
Best model saved!! Metric=88.50913700892353!!
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.267787 Test loss=0.365906 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.24832315742969513
[5/24] Train loss=0.24730642139911652
[10/24] Train loss=0.2779923379421234
[15/24] Train loss=0.2498735934495926
[20/24] Train loss=0.26721441745758057
Test set avg_accuracy=83.66% avg_sensitivity=61.80%, avg_specificity=91.46% avg_auc=88.53%
Best model saved!! Metric=88.53387723653363!!
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.267785 Test loss=0.366259 Current lr=[0.000224838296036774]

[0/24] Train loss=0.24440795183181763
[5/24] Train loss=0.24197371304035187
[10/24] Train loss=0.28021636605262756
[15/24] Train loss=0.24831657111644745
[20/24] Train loss=0.273824542760849
Test set avg_accuracy=83.78% avg_sensitivity=62.79%, avg_specificity=91.27% avg_auc=88.51%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.266479 Test loss=0.366387 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.24856092035770416
[5/24] Train loss=0.23882098495960236
[10/24] Train loss=0.27600589394569397
[15/24] Train loss=0.24921230971813202
[20/24] Train loss=0.269674152135849
Test set avg_accuracy=83.58% avg_sensitivity=61.36%, avg_specificity=91.52% avg_auc=88.51%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.266380 Test loss=0.366607 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.24299021065235138
[5/24] Train loss=0.24122688174247742
[10/24] Train loss=0.2787657678127289
[15/24] Train loss=0.24945928156375885
[20/24] Train loss=0.27407947182655334
Test set avg_accuracy=83.67% avg_sensitivity=62.54%, avg_specificity=91.22% avg_auc=88.55%
Best model saved!! Metric=88.5463500885166!!
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.265162 Test loss=0.365982 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.24155984818935394
[5/24] Train loss=0.2423342764377594
[10/24] Train loss=0.2771819531917572
[15/24] Train loss=0.24962861835956573
[20/24] Train loss=0.26788318157196045
Test set avg_accuracy=83.71% avg_sensitivity=62.10%, avg_specificity=91.43% avg_auc=88.54%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.265223 Test loss=0.366623 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.24554045498371124
[5/24] Train loss=0.23820388317108154
[10/24] Train loss=0.27990415692329407
[15/24] Train loss=0.24877730011940002
[20/24] Train loss=0.26680490374565125
Test set avg_accuracy=83.66% avg_sensitivity=61.01%, avg_specificity=91.75% avg_auc=88.53%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.264950 Test loss=0.366690 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.24231401085853577
[5/24] Train loss=0.24114038050174713
[10/24] Train loss=0.2761163115501404
[15/24] Train loss=0.2495034784078598
[20/24] Train loss=0.2643447518348694
Test set avg_accuracy=83.59% avg_sensitivity=61.11%, avg_specificity=91.62% avg_auc=88.54%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.263725 Test loss=0.366908 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.24509358406066895
[5/24] Train loss=0.23868289589881897
[10/24] Train loss=0.27560895681381226
[15/24] Train loss=0.24888312816619873
[20/24] Train loss=0.2635806202888489
Test set avg_accuracy=83.54% avg_sensitivity=60.91%, avg_specificity=91.62% avg_auc=88.57%
Best model saved!! Metric=88.56945962079207!!
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.263946 Test loss=0.366857 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.24081625044345856
[5/24] Train loss=0.23867115378379822
[10/24] Train loss=0.27318474650382996
[15/24] Train loss=0.2470921277999878
[20/24] Train loss=0.2643216848373413
Test set avg_accuracy=83.65% avg_sensitivity=62.25%, avg_specificity=91.29% avg_auc=88.60%
Best model saved!! Metric=88.6045523592664!!
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.263231 Test loss=0.366415 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.24441546201705933
[5/24] Train loss=0.24050843715667725
[10/24] Train loss=0.2746528685092926
[15/24] Train loss=0.2463148683309555
[20/24] Train loss=0.26366496086120605
Test set avg_accuracy=83.65% avg_sensitivity=61.50%, avg_specificity=91.55% avg_auc=88.61%
Best model saved!! Metric=88.60988600084343!!
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.263686 Test loss=0.366442 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.24146988987922668
[5/24] Train loss=0.23798786103725433
[10/24] Train loss=0.27304989099502563
[15/24] Train loss=0.24665679037570953
[20/24] Train loss=0.2603175640106201
Test set avg_accuracy=83.63% avg_sensitivity=60.42%, avg_specificity=91.92% avg_auc=88.59%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.262807 Test loss=0.367400 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.24136769771575928
[5/24] Train loss=0.23990245163440704
[10/24] Train loss=0.27429118752479553
[15/24] Train loss=0.2460995316505432
[20/24] Train loss=0.2607494592666626
Test set avg_accuracy=83.44% avg_sensitivity=59.77%, avg_specificity=91.89% avg_auc=88.58%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.262115 Test loss=0.368124 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2386235147714615
[5/24] Train loss=0.23969419300556183
[10/24] Train loss=0.2735069990158081
[15/24] Train loss=0.24777191877365112
[20/24] Train loss=0.2596922814846039
Test set avg_accuracy=83.50% avg_sensitivity=60.02%, avg_specificity=91.89% avg_auc=88.61%
Best model saved!! Metric=88.61257030898135!!
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.262644 Test loss=0.367887 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.23801378905773163
[5/24] Train loss=0.24001669883728027
[10/24] Train loss=0.27088335156440735
[15/24] Train loss=0.25015774369239807
[20/24] Train loss=0.2584240138530731
Test set avg_accuracy=83.55% avg_sensitivity=60.22%, avg_specificity=91.89% avg_auc=88.66%
Best model saved!! Metric=88.65767892684333!!
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.263042 Test loss=0.367098 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.23934249579906464
[5/24] Train loss=0.23816174268722534
[10/24] Train loss=0.27228474617004395
[15/24] Train loss=0.2496253401041031
[20/24] Train loss=0.2566981911659241
Test set avg_accuracy=83.46% avg_sensitivity=59.62%, avg_specificity=91.98% avg_auc=88.67%
Best model saved!! Metric=88.67148518922056!!
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.263935 Test loss=0.367160 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.23650811612606049
[5/24] Train loss=0.23834261298179626
[10/24] Train loss=0.27441316843032837
[15/24] Train loss=0.25207412242889404
[20/24] Train loss=0.258991539478302
Test set avg_accuracy=83.63% avg_sensitivity=60.66%, avg_specificity=91.84% avg_auc=88.69%
Best model saved!! Metric=88.68571114798415!!
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.264638 Test loss=0.366156 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.23886115849018097
[5/24] Train loss=0.23950542509555817
[10/24] Train loss=0.2824190855026245
[15/24] Train loss=0.26246318221092224
[20/24] Train loss=0.2573322355747223
Test set avg_accuracy=83.40% avg_sensitivity=66.35%, avg_specificity=89.49% avg_auc=88.80%
Best model saved!! Metric=88.80170473677211!!
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.269329 Test loss=0.365048 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2402840107679367
[5/24] Train loss=0.2554270029067993
[10/24] Train loss=0.2963510751724243
[15/24] Train loss=0.2605116367340088
[20/24] Train loss=0.26665592193603516
Test set avg_accuracy=82.21% avg_sensitivity=73.53%, avg_specificity=85.32% avg_auc=88.95%
Best model saved!! Metric=88.95001931914929!!
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.273021 Test loss=0.377446 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2539675235748291
[5/24] Train loss=0.25354957580566406
[10/24] Train loss=0.27805647253990173
[15/24] Train loss=0.24961180984973907
[20/24] Train loss=0.27845674753189087
Test set avg_accuracy=83.11% avg_sensitivity=68.98%, avg_specificity=88.16% avg_auc=88.88%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.270008 Test loss=0.367019 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2437848448753357
[5/24] Train loss=0.24198979139328003
[10/24] Train loss=0.2723170220851898
[15/24] Train loss=0.245722234249115
[20/24] Train loss=0.26636284589767456
Test set avg_accuracy=83.36% avg_sensitivity=68.09%, avg_specificity=88.81% avg_auc=88.94%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.263404 Test loss=0.364220 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.23865067958831787
[5/24] Train loss=0.24408774077892303
[10/24] Train loss=0.27938589453697205
[15/24] Train loss=0.24483062326908112
[20/24] Train loss=0.2664515972137451
Test set avg_accuracy=83.11% avg_sensitivity=69.37%, avg_specificity=88.02% avg_auc=88.96%
Best model saved!! Metric=88.96375126029142!!
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.262312 Test loss=0.366354 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.24258621037006378
[5/24] Train loss=0.2455073446035385
[10/24] Train loss=0.27802667021751404
[15/24] Train loss=0.2449638843536377
[20/24] Train loss=0.2696738839149475
Test set avg_accuracy=83.26% avg_sensitivity=68.53%, avg_specificity=88.51% avg_auc=88.97%
Best model saved!! Metric=88.97095604825773!!
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.262699 Test loss=0.364239 Current lr=[0.000134135431043539]

[0/24] Train loss=0.23633049428462982
[5/24] Train loss=0.23882128298282623
[10/24] Train loss=0.27848997712135315
[15/24] Train loss=0.24602490663528442
[20/24] Train loss=0.268101304769516
Test set avg_accuracy=83.32% avg_sensitivity=68.23%, avg_specificity=88.71% avg_auc=88.96%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.261710 Test loss=0.363967 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.2412300854921341
[5/24] Train loss=0.24111676216125488
[10/24] Train loss=0.2759615480899811
[15/24] Train loss=0.24451816082000732
[20/24] Train loss=0.2655239403247833
Test set avg_accuracy=83.46% avg_sensitivity=67.49%, avg_specificity=89.17% avg_auc=88.94%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.261058 Test loss=0.363223 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.23803851008415222
[5/24] Train loss=0.23970235884189606
[10/24] Train loss=0.27196183800697327
[15/24] Train loss=0.24639703333377838
[20/24] Train loss=0.2623049318790436
Test set avg_accuracy=83.42% avg_sensitivity=66.90%, avg_specificity=89.33% avg_auc=88.93%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.260124 Test loss=0.362574 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.23862817883491516
[5/24] Train loss=0.23936539888381958
[10/24] Train loss=0.27882981300354004
[15/24] Train loss=0.24408076703548431
[20/24] Train loss=0.266987681388855
Test set avg_accuracy=83.44% avg_sensitivity=67.54%, avg_specificity=89.11% avg_auc=88.94%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.260801 Test loss=0.363327 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.23778992891311646
[5/24] Train loss=0.2388819307088852
[10/24] Train loss=0.2714154124259949
[15/24] Train loss=0.24267682433128357
[20/24] Train loss=0.26432377099990845
Test set avg_accuracy=83.62% avg_sensitivity=66.75%, avg_specificity=89.64% avg_auc=88.93%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.260102 Test loss=0.362351 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.238298237323761
[5/24] Train loss=0.23780637979507446
[10/24] Train loss=0.2710290849208832
[15/24] Train loss=0.24250145256519318
[20/24] Train loss=0.2623242437839508
Test set avg_accuracy=83.62% avg_sensitivity=66.01%, avg_specificity=89.91% avg_auc=88.91%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.259433 Test loss=0.362127 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.23495261371135712
[5/24] Train loss=0.23262743651866913
[10/24] Train loss=0.27168408036231995
[15/24] Train loss=0.2466498464345932
[20/24] Train loss=0.26121586561203003
Test set avg_accuracy=83.55% avg_sensitivity=66.75%, avg_specificity=89.56% avg_auc=88.93%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.258182 Test loss=0.362525 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.2396174520254135
[5/24] Train loss=0.2360917031764984
[10/24] Train loss=0.2722843885421753
[15/24] Train loss=0.24519389867782593
[20/24] Train loss=0.26163560152053833
Test set avg_accuracy=83.61% avg_sensitivity=65.86%, avg_specificity=89.95% avg_auc=88.92%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.258522 Test loss=0.362020 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.23509937524795532
[5/24] Train loss=0.23756124079227448
[10/24] Train loss=0.2752220928668976
[15/24] Train loss=0.244858980178833
[20/24] Train loss=0.26197779178619385
Test set avg_accuracy=83.65% avg_sensitivity=65.91%, avg_specificity=89.98% avg_auc=88.91%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.258688 Test loss=0.362058 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.235480397939682
[5/24] Train loss=0.23584364354610443
[10/24] Train loss=0.27231231331825256
[15/24] Train loss=0.24374130368232727
[20/24] Train loss=0.2607239782810211
Test set avg_accuracy=83.55% avg_sensitivity=66.06%, avg_specificity=89.80% avg_auc=88.91%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.257568 Test loss=0.362315 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2353750616312027
[5/24] Train loss=0.2358812391757965
[10/24] Train loss=0.27057674527168274
[15/24] Train loss=0.24194473028182983
[20/24] Train loss=0.25796544551849365
Test set avg_accuracy=83.68% avg_sensitivity=65.91%, avg_specificity=90.03% avg_auc=88.88%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.257940 Test loss=0.362460 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.2337961345911026
[5/24] Train loss=0.23504017293453217
[10/24] Train loss=0.27706676721572876
[15/24] Train loss=0.24393299221992493
[20/24] Train loss=0.2583759129047394
Test set avg_accuracy=83.58% avg_sensitivity=65.81%, avg_specificity=89.93% avg_auc=88.89%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.257612 Test loss=0.362674 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.23343749344348907
[5/24] Train loss=0.23699097335338593
[10/24] Train loss=0.2763136923313141
[15/24] Train loss=0.24305610358715057
[20/24] Train loss=0.2609042227268219
Test set avg_accuracy=83.71% avg_sensitivity=65.07%, avg_specificity=90.37% avg_auc=88.87%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.257005 Test loss=0.362402 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.23490594327449799
[5/24] Train loss=0.2354055792093277
[10/24] Train loss=0.27261772751808167
[15/24] Train loss=0.23914219439029694
[20/24] Train loss=0.26003703474998474
Test set avg_accuracy=83.71% avg_sensitivity=64.97%, avg_specificity=90.40% avg_auc=88.86%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.257576 Test loss=0.362478 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.23690436780452728
[5/24] Train loss=0.23705703020095825
[10/24] Train loss=0.2689191401004791
[15/24] Train loss=0.241964653134346
[20/24] Train loss=0.2607291638851166
Test set avg_accuracy=83.72% avg_sensitivity=65.31%, avg_specificity=90.30% avg_auc=88.88%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.256833 Test loss=0.362212 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.2359144240617752
[5/24] Train loss=0.23926827311515808
[10/24] Train loss=0.2706242501735687
[15/24] Train loss=0.24341607093811035
[20/24] Train loss=0.2610677480697632
Test set avg_accuracy=83.75% avg_sensitivity=64.42%, avg_specificity=90.65% avg_auc=88.85%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.257423 Test loss=0.362441 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.23391087353229523
[5/24] Train loss=0.23459932208061218
[10/24] Train loss=0.27037253975868225
[15/24] Train loss=0.24511632323265076
[20/24] Train loss=0.260977566242218
Test set avg_accuracy=83.75% avg_sensitivity=65.31%, avg_specificity=90.33% avg_auc=88.86%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.257460 Test loss=0.362660 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.23403267562389374
[5/24] Train loss=0.23563332855701447
[10/24] Train loss=0.27365678548812866
[15/24] Train loss=0.23918133974075317
[20/24] Train loss=0.2572362422943115
Test set avg_accuracy=83.71% avg_sensitivity=64.82%, avg_specificity=90.46% avg_auc=88.85%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.256801 Test loss=0.362622 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.2351198047399521
[5/24] Train loss=0.2354552000761032
[10/24] Train loss=0.2695968449115753
[15/24] Train loss=0.24030007421970367
[20/24] Train loss=0.2560471296310425
Test set avg_accuracy=83.72% avg_sensitivity=63.98%, avg_specificity=90.78% avg_auc=88.82%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.256735 Test loss=0.362877 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.2326907366514206
[5/24] Train loss=0.23680582642555237
[10/24] Train loss=0.26783424615859985
[15/24] Train loss=0.24251794815063477
[20/24] Train loss=0.25687113404273987
Test set avg_accuracy=83.58% avg_sensitivity=64.08%, avg_specificity=90.55% avg_auc=88.82%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.256473 Test loss=0.362957 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.23427020013332367
[5/24] Train loss=0.2384369820356369
[10/24] Train loss=0.2680751383304596
[15/24] Train loss=0.24061758816242218
[20/24] Train loss=0.25386661291122437
Test set avg_accuracy=83.78% avg_sensitivity=65.71%, avg_specificity=90.23% avg_auc=88.84%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.256980 Test loss=0.363224 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.2326793372631073
[5/24] Train loss=0.2366405576467514
[10/24] Train loss=0.2684570848941803
[15/24] Train loss=0.24222445487976074
[20/24] Train loss=0.2548149824142456
Test set avg_accuracy=83.71% avg_sensitivity=66.50%, avg_specificity=89.86% avg_auc=88.86%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.256787 Test loss=0.363426 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.23394662141799927
[5/24] Train loss=0.23520100116729736
[10/24] Train loss=0.2695046365261078
[15/24] Train loss=0.24191288650035858
[20/24] Train loss=0.2535538673400879
Test set avg_accuracy=83.44% avg_sensitivity=66.90%, avg_specificity=89.34% avg_auc=88.86%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.257604 Test loss=0.364144 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.2348545491695404
[5/24] Train loss=0.23971901834011078
[10/24] Train loss=0.2711230516433716
[15/24] Train loss=0.2412070333957672
[20/24] Train loss=0.2551385164260864
Test set avg_accuracy=83.31% avg_sensitivity=68.04%, avg_specificity=88.76% avg_auc=88.90%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.258032 Test loss=0.365269 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.23589220643043518
[5/24] Train loss=0.23553305864334106
[10/24] Train loss=0.26923099160194397
[15/24] Train loss=0.24369218945503235
[20/24] Train loss=0.25243934988975525
Test set avg_accuracy=83.14% avg_sensitivity=68.53%, avg_specificity=88.35% avg_auc=88.89%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.257819 Test loss=0.366516 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.24052058160305023
[5/24] Train loss=0.23755478858947754
[10/24] Train loss=0.2747374475002289
[15/24] Train loss=0.24565230309963226
[20/24] Train loss=0.25475257635116577
Test set avg_accuracy=83.16% avg_sensitivity=68.83%, avg_specificity=88.28% avg_auc=88.89%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.258428 Test loss=0.366765 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.2383359968662262
[5/24] Train loss=0.23178641498088837
[10/24] Train loss=0.2714766263961792
[15/24] Train loss=0.24175235629081726
[20/24] Train loss=0.2621161937713623
Test set avg_accuracy=83.36% avg_sensitivity=68.18%, avg_specificity=88.78% avg_auc=88.89%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.257529 Test loss=0.365365 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.23798349499702454
[5/24] Train loss=0.23428460955619812
[10/24] Train loss=0.26892033219337463
[15/24] Train loss=0.2441072165966034
[20/24] Train loss=0.25912752747535706
Test set avg_accuracy=83.46% avg_sensitivity=67.14%, avg_specificity=89.29% avg_auc=88.87%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.256941 Test loss=0.364142 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.23553934693336487
[5/24] Train loss=0.2320566624403
[10/24] Train loss=0.27142226696014404
[15/24] Train loss=0.24015481770038605
[20/24] Train loss=0.25873374938964844
Test set avg_accuracy=83.50% avg_sensitivity=67.05%, avg_specificity=89.38% avg_auc=88.87%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.256958 Test loss=0.363970 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.2333398461341858
[5/24] Train loss=0.2316352128982544
[10/24] Train loss=0.2705238461494446
[15/24] Train loss=0.24155178666114807
[20/24] Train loss=0.25495317578315735
Test set avg_accuracy=83.48% avg_sensitivity=67.14%, avg_specificity=89.31% avg_auc=88.87%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.256699 Test loss=0.364075 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.23542746901512146
[5/24] Train loss=0.23446378111839294
[10/24] Train loss=0.2738257348537445
[15/24] Train loss=0.24135349690914154
[20/24] Train loss=0.25576746463775635
Test set avg_accuracy=83.54% avg_sensitivity=66.95%, avg_specificity=89.47% avg_auc=88.86%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.255754 Test loss=0.363715 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.23342271149158478
[5/24] Train loss=0.2325347363948822
[10/24] Train loss=0.2703007757663727
[15/24] Train loss=0.23903466761112213
[20/24] Train loss=0.2598612606525421
Test set avg_accuracy=83.52% avg_sensitivity=67.00%, avg_specificity=89.42% avg_auc=88.87%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.256790 Test loss=0.363843 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.23550239205360413
[5/24] Train loss=0.23190923035144806
[10/24] Train loss=0.26930344104766846
[15/24] Train loss=0.2392810881137848
[20/24] Train loss=0.25943419337272644
Test set avg_accuracy=83.59% avg_sensitivity=66.65%, avg_specificity=89.64% avg_auc=88.86%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.255512 Test loss=0.363598 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.23380862176418304
[5/24] Train loss=0.23378293216228485
[10/24] Train loss=0.27129969000816345
[15/24] Train loss=0.24359473586082458
[20/24] Train loss=0.2580491602420807
Test set avg_accuracy=83.58% avg_sensitivity=66.80%, avg_specificity=89.57% avg_auc=88.86%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.256382 Test loss=0.363648 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.234201118350029
[5/24] Train loss=0.2308102399110794
[10/24] Train loss=0.2703312337398529
[15/24] Train loss=0.24180489778518677
[20/24] Train loss=0.2592618465423584
Test set avg_accuracy=83.59% avg_sensitivity=66.80%, avg_specificity=89.59% avg_auc=88.86%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.256160 Test loss=0.363670 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.23429185152053833
[5/24] Train loss=0.2346266210079193
[10/24] Train loss=0.26709693670272827
[15/24] Train loss=0.23997217416763306
[20/24] Train loss=0.2571534812450409
Test set avg_accuracy=83.61% avg_sensitivity=66.45%, avg_specificity=89.73% avg_auc=88.86%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.255907 Test loss=0.363492 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.23557636141777039
[5/24] Train loss=0.23204796016216278
[10/24] Train loss=0.2721681296825409
[15/24] Train loss=0.24128684401512146
[20/24] Train loss=0.2523883283138275
Test set avg_accuracy=83.63% avg_sensitivity=66.60%, avg_specificity=89.72% avg_auc=88.86%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.255180 Test loss=0.363556 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.234601691365242
[5/24] Train loss=0.2341342568397522
[10/24] Train loss=0.26869991421699524
[15/24] Train loss=0.2434382438659668
[20/24] Train loss=0.2583242356777191
Test set avg_accuracy=83.59% avg_sensitivity=66.40%, avg_specificity=89.73% avg_auc=88.86%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.256475 Test loss=0.363466 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.23433639109134674
[5/24] Train loss=0.23377294838428497
[10/24] Train loss=0.27023056149482727
[15/24] Train loss=0.2413942515850067
[20/24] Train loss=0.2579641342163086
Test set avg_accuracy=83.61% avg_sensitivity=66.45%, avg_specificity=89.73% avg_auc=88.86%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.256206 Test loss=0.363435 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.23569481074810028
[5/24] Train loss=0.236817866563797
[10/24] Train loss=0.27263763546943665
[15/24] Train loss=0.2391418218612671
[20/24] Train loss=0.25599128007888794
Test set avg_accuracy=83.59% avg_sensitivity=66.40%, avg_specificity=89.73% avg_auc=88.86%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.256203 Test loss=0.363392 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.2307136356830597
[5/24] Train loss=0.23642362654209137
[10/24] Train loss=0.27191323041915894
[15/24] Train loss=0.2418440580368042
[20/24] Train loss=0.25897327065467834
Test set avg_accuracy=83.61% avg_sensitivity=66.45%, avg_specificity=89.73% avg_auc=88.86%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.255613 Test loss=0.363464 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.23616378009319305
[5/24] Train loss=0.2335946261882782
[10/24] Train loss=0.2683503031730652
[15/24] Train loss=0.24023985862731934
[20/24] Train loss=0.25964176654815674
Test set avg_accuracy=83.59% avg_sensitivity=66.40%, avg_specificity=89.73% avg_auc=88.86%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.256849 Test loss=0.363463 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.2343866378068924
[5/24] Train loss=0.23294079303741455
[10/24] Train loss=0.2710684537887573
[15/24] Train loss=0.241700679063797
[20/24] Train loss=0.2568173110485077
Test set avg_accuracy=83.55% avg_sensitivity=66.20%, avg_specificity=89.75% avg_auc=88.85%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.255874 Test loss=0.363357 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.23371516168117523
[5/24] Train loss=0.2340223342180252
[10/24] Train loss=0.26867443323135376
[15/24] Train loss=0.2458394169807434
[20/24] Train loss=0.256080687046051
Test set avg_accuracy=83.55% avg_sensitivity=66.20%, avg_specificity=89.75% avg_auc=88.85%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.255718 Test loss=0.363372 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.23412099480628967
[5/24] Train loss=0.2334626019001007
[10/24] Train loss=0.2681657373905182
[15/24] Train loss=0.24092377722263336
[20/24] Train loss=0.255039244890213
Test set avg_accuracy=83.58% avg_sensitivity=66.30%, avg_specificity=89.75% avg_auc=88.85%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.255591 Test loss=0.363391 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.23504699766635895
[5/24] Train loss=0.23497848212718964
[10/24] Train loss=0.26868516206741333
[15/24] Train loss=0.24098260700702667
[20/24] Train loss=0.2557951807975769
Test set avg_accuracy=83.57% avg_sensitivity=66.25%, avg_specificity=89.75% avg_auc=88.85%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.255829 Test loss=0.363386 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.23363706469535828
[5/24] Train loss=0.23239295184612274
[10/24] Train loss=0.26959192752838135
[15/24] Train loss=0.2428002804517746
[20/24] Train loss=0.254629909992218
Test set avg_accuracy=83.57% avg_sensitivity=66.25%, avg_specificity=89.75% avg_auc=88.85%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.255455 Test loss=0.363382 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.23593354225158691
[5/24] Train loss=0.23403441905975342
[10/24] Train loss=0.27198928594589233
[15/24] Train loss=0.24098753929138184
[20/24] Train loss=0.2556515634059906
Test set avg_accuracy=83.57% avg_sensitivity=66.25%, avg_specificity=89.75% avg_auc=88.85%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.256151 Test loss=0.363379 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.23136107623577118
[5/24] Train loss=0.23432421684265137
[10/24] Train loss=0.2687036693096161
[15/24] Train loss=0.24398738145828247
[20/24] Train loss=0.25881803035736084
Test set avg_accuracy=83.57% avg_sensitivity=66.25%, avg_specificity=89.75% avg_auc=88.85%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.255953 Test loss=0.363378 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=83.26% sen=68.53%, spe=88.51%, auc=88.97%!
Fold[1] Avg_jsc=0.59%(±0.28063625721154467)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=1.0235021114349365
[5/24] Train loss=0.8916173577308655
[10/24] Train loss=0.807421863079071
[15/24] Train loss=0.7295482754707336
[20/24] Train loss=0.6746613383293152
Test set avg_accuracy=70.49% avg_sensitivity=9.70%, avg_specificity=90.72% avg_auc=49.85%
Best model saved!! Metric=49.852100048960544!!
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.801421 Test loss=0.605214 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6381765007972717
[5/24] Train loss=0.6653302907943726
[10/24] Train loss=0.6374319195747375
[15/24] Train loss=0.61188143491745
[20/24] Train loss=0.6117011308670044
Test set avg_accuracy=75.04% avg_sensitivity=0.16%, avg_specificity=99.95% avg_auc=51.05%
Best model saved!! Metric=51.04969183097505!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.634981 Test loss=0.585150 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6055193543434143
[5/24] Train loss=0.6649508476257324
[10/24] Train loss=0.6211657524108887
[15/24] Train loss=0.6180614233016968
[20/24] Train loss=0.6048303246498108
Test set avg_accuracy=75.03% avg_sensitivity=0.10%, avg_specificity=99.95% avg_auc=51.37%
Best model saved!! Metric=51.36635585907654!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.623349 Test loss=0.574224 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6110629439353943
[5/24] Train loss=0.643393337726593
[10/24] Train loss=0.6257504820823669
[15/24] Train loss=0.6120249032974243
[20/24] Train loss=0.5968629717826843
Test set avg_accuracy=75.04% avg_sensitivity=0.16%, avg_specificity=99.95% avg_auc=52.19%
Best model saved!! Metric=52.19269292143114!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.616768 Test loss=0.565909 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5970262289047241
[5/24] Train loss=0.6459124684333801
[10/24] Train loss=0.6207014918327332
[15/24] Train loss=0.6010395288467407
[20/24] Train loss=0.5902373194694519
Test set avg_accuracy=75.04% avg_sensitivity=0.16%, avg_specificity=99.95% avg_auc=52.82%
Best model saved!! Metric=52.82463154451287!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.610324 Test loss=0.563430 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5895271897315979
[5/24] Train loss=0.6402757167816162
[10/24] Train loss=0.6030721068382263
[15/24] Train loss=0.5991210341453552
[20/24] Train loss=0.5917231440544128
Test set avg_accuracy=75.05% avg_sensitivity=0.21%, avg_specificity=99.95% avg_auc=53.72%
Best model saved!! Metric=53.720227548412694!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.605828 Test loss=0.561975 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5821877121925354
[5/24] Train loss=0.6371288895606995
[10/24] Train loss=0.60981285572052
[15/24] Train loss=0.5946345329284668
[20/24] Train loss=0.5877810716629028
Test set avg_accuracy=75.05% avg_sensitivity=0.16%, avg_specificity=99.97% avg_auc=54.82%
Best model saved!! Metric=54.81917863050049!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.601747 Test loss=0.559909 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5839885473251343
[5/24] Train loss=0.6163926720619202
[10/24] Train loss=0.603054404258728
[15/24] Train loss=0.5872822403907776
[20/24] Train loss=0.5842936038970947
Test set avg_accuracy=75.05% avg_sensitivity=0.16%, avg_specificity=99.97% avg_auc=55.82%
Best model saved!! Metric=55.81765604714333!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.599308 Test loss=0.558492 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5783728957176208
[5/24] Train loss=0.6273708939552307
[10/24] Train loss=0.5922449827194214
[15/24] Train loss=0.5838323831558228
[20/24] Train loss=0.5756827592849731
Test set avg_accuracy=75.05% avg_sensitivity=0.16%, avg_specificity=99.97% avg_auc=56.91%
Best model saved!! Metric=56.911624178525955!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.595573 Test loss=0.556677 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.577055811882019
[5/24] Train loss=0.6214533448219299
[10/24] Train loss=0.592714786529541
[15/24] Train loss=0.5889532566070557
[20/24] Train loss=0.5736702084541321
Test set avg_accuracy=75.05% avg_sensitivity=0.16%, avg_specificity=99.97% avg_auc=58.25%
Best model saved!! Metric=58.2467879429067!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.592632 Test loss=0.554621 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.572525680065155
[5/24] Train loss=0.6119517087936401
[10/24] Train loss=0.592850923538208
[15/24] Train loss=0.5820002555847168
[20/24] Train loss=0.5712056756019592
Test set avg_accuracy=75.07% avg_sensitivity=0.21%, avg_specificity=99.97% avg_auc=59.33%
Best model saved!! Metric=59.32635937474967!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.588371 Test loss=0.553146 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5740381479263306
[5/24] Train loss=0.6179164052009583
[10/24] Train loss=0.5815885066986084
[15/24] Train loss=0.578357458114624
[20/24] Train loss=0.5615774989128113
Test set avg_accuracy=75.10% avg_sensitivity=0.31%, avg_specificity=99.98% avg_auc=60.72%
Best model saved!! Metric=60.72302931540956!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.583496 Test loss=0.550883 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5657405853271484
[5/24] Train loss=0.6013986468315125
[10/24] Train loss=0.5823780298233032
[15/24] Train loss=0.57207190990448
[20/24] Train loss=0.5568515062332153
Test set avg_accuracy=75.10% avg_sensitivity=0.31%, avg_specificity=99.98% avg_auc=61.78%
Best model saved!! Metric=61.7803471881087!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.579819 Test loss=0.548291 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5552018284797668
[5/24] Train loss=0.5994104146957397
[10/24] Train loss=0.5765511989593506
[15/24] Train loss=0.5661612749099731
[20/24] Train loss=0.5548145174980164
Test set avg_accuracy=75.14% avg_sensitivity=0.47%, avg_specificity=99.98% avg_auc=63.89%
Best model saved!! Metric=63.89481095155711!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.574843 Test loss=0.544131 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5547386407852173
[5/24] Train loss=0.591590940952301
[10/24] Train loss=0.5642841458320618
[15/24] Train loss=0.5600845813751221
[20/24] Train loss=0.5447259545326233
Test set avg_accuracy=75.04% avg_sensitivity=0.78%, avg_specificity=99.74% avg_auc=67.39%
Best model saved!! Metric=67.39010421291512!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.568664 Test loss=0.535857 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5469900369644165
[5/24] Train loss=0.5795571804046631
[10/24] Train loss=0.5522762537002563
[15/24] Train loss=0.5524120330810547
[20/24] Train loss=0.5322920680046082
Test set avg_accuracy=74.91% avg_sensitivity=2.14%, avg_specificity=99.12% avg_auc=70.01%
Best model saved!! Metric=70.00627100499281!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.561713 Test loss=0.525949 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5354772210121155
[5/24] Train loss=0.5794437527656555
[10/24] Train loss=0.5424278378486633
[15/24] Train loss=0.5434021353721619
[20/24] Train loss=0.5249751210212708
Test set avg_accuracy=74.69% avg_sensitivity=5.84%, avg_specificity=97.59% avg_auc=72.34%
Best model saved!! Metric=72.33974472990732!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.552909 Test loss=0.514124 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5210809707641602
[5/24] Train loss=0.5720465183258057
[10/24] Train loss=0.5275442004203796
[15/24] Train loss=0.534003734588623
[20/24] Train loss=0.509184718132019
Test set avg_accuracy=74.73% avg_sensitivity=8.24%, avg_specificity=96.84% avg_auc=74.40%
Best model saved!! Metric=74.40495829392458!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.541877 Test loss=0.500699 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5031026601791382
[5/24] Train loss=0.5571140646934509
[10/24] Train loss=0.5156957507133484
[15/24] Train loss=0.5265679955482483
[20/24] Train loss=0.5073975324630737
Test set avg_accuracy=74.92% avg_sensitivity=6.10%, avg_specificity=97.81% avg_auc=76.17%
Best model saved!! Metric=76.17385601001334!!
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.529653 Test loss=0.492013 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4913786053657532
[5/24] Train loss=0.5332558751106262
[10/24] Train loss=0.5065186619758606
[15/24] Train loss=0.5063026547431946
[20/24] Train loss=0.4887675344944
Test set avg_accuracy=75.44% avg_sensitivity=11.32%, avg_specificity=96.77% avg_auc=77.77%
Best model saved!! Metric=77.77016078773525!!
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.515336 Test loss=0.477736 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.4736141562461853
[5/24] Train loss=0.5123004913330078
[10/24] Train loss=0.49257057905197144
[15/24] Train loss=0.4942965507507324
[20/24] Train loss=0.47318321466445923
Test set avg_accuracy=76.13% avg_sensitivity=16.48%, avg_specificity=95.97% avg_auc=79.15%
Best model saved!! Metric=79.14645539317743!!
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.501272 Test loss=0.465297 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.4721747040748596
[5/24] Train loss=0.49734562635421753
[10/24] Train loss=0.47408348321914673
[15/24] Train loss=0.4884905219078064
[20/24] Train loss=0.4614218771457672
Test set avg_accuracy=76.81% avg_sensitivity=21.13%, avg_specificity=95.33% avg_auc=80.22%
Best model saved!! Metric=80.21560381369068!!
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.489866 Test loss=0.455669 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.45125851035118103
[5/24] Train loss=0.4901224970817566
[10/24] Train loss=0.4644549489021301
[15/24] Train loss=0.48093554377555847
[20/24] Train loss=0.4429986774921417
Test set avg_accuracy=77.50% avg_sensitivity=30.73%, avg_specificity=93.06% avg_auc=81.16%
Best model saved!! Metric=81.16037307772834!!
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.477820 Test loss=0.442484 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.4367462992668152
[5/24] Train loss=0.4854773283004761
[10/24] Train loss=0.45255938172340393
[15/24] Train loss=0.4637833833694458
[20/24] Train loss=0.4339737892150879
Test set avg_accuracy=78.10% avg_sensitivity=35.84%, avg_specificity=92.16% avg_auc=82.00%
Best model saved!! Metric=81.99659005051834!!
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.466044 Test loss=0.434087 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.4228166937828064
[5/24] Train loss=0.45977842807769775
[10/24] Train loss=0.44166356325149536
[15/24] Train loss=0.4515610635280609
[20/24] Train loss=0.41505879163742065
Test set avg_accuracy=79.08% avg_sensitivity=42.31%, avg_specificity=91.31% avg_auc=82.77%
Best model saved!! Metric=82.77001550824603!!
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.452923 Test loss=0.426753 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.4072597026824951
[5/24] Train loss=0.4441443979740143
[10/24] Train loss=0.430228054523468
[15/24] Train loss=0.4411265254020691
[20/24] Train loss=0.4076421558856964
Test set avg_accuracy=79.61% avg_sensitivity=44.39%, avg_specificity=91.32% avg_auc=83.46%
Best model saved!! Metric=83.46229716652498!!
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.442123 Test loss=0.420291 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.39756935834884644
[5/24] Train loss=0.42094337940216064
[10/24] Train loss=0.42102208733558655
[15/24] Train loss=0.4283084571361542
[20/24] Train loss=0.4006653130054474
Test set avg_accuracy=80.13% avg_sensitivity=46.01%, avg_specificity=91.48% avg_auc=84.16%
Best model saved!! Metric=84.16205551378204!!
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.431857 Test loss=0.413564 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.39362016320228577
[5/24] Train loss=0.4120607376098633
[10/24] Train loss=0.4096454083919525
[15/24] Train loss=0.41942083835601807
[20/24] Train loss=0.3869665265083313
Test set avg_accuracy=80.68% avg_sensitivity=47.37%, avg_specificity=91.76% avg_auc=84.84%
Best model saved!! Metric=84.83945620755722!!
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.423770 Test loss=0.406643 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3805590569972992
[5/24] Train loss=0.40000802278518677
[10/24] Train loss=0.39568591117858887
[15/24] Train loss=0.40657109022140503
[20/24] Train loss=0.37854495644569397
Test set avg_accuracy=81.12% avg_sensitivity=48.88%, avg_specificity=91.84% avg_auc=85.46%
Best model saved!! Metric=85.4627459488973!!
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.413550 Test loss=0.399560 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.36763742566108704
[5/24] Train loss=0.394885390996933
[10/24] Train loss=0.3853321671485901
[15/24] Train loss=0.3929336667060852
[20/24] Train loss=0.3655150830745697
Test set avg_accuracy=81.26% avg_sensitivity=48.72%, avg_specificity=92.09% avg_auc=86.06%
Best model saved!! Metric=86.05669919026373!!
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.403130 Test loss=0.392725 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3599545955657959
[5/24] Train loss=0.380204975605011
[10/24] Train loss=0.3751305639743805
[15/24] Train loss=0.3772590756416321
[20/24] Train loss=0.3594365119934082
Test set avg_accuracy=81.46% avg_sensitivity=48.83%, avg_specificity=92.31% avg_auc=86.53%
Best model saved!! Metric=86.52579353603124!!
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.394021 Test loss=0.386950 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.34863585233688354
[5/24] Train loss=0.36664074659347534
[10/24] Train loss=0.36583220958709717
[15/24] Train loss=0.36736103892326355
[20/24] Train loss=0.350006639957428
Test set avg_accuracy=81.68% avg_sensitivity=47.57%, avg_specificity=93.02% avg_auc=86.87%
Best model saved!! Metric=86.87199320110093!!
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.385414 Test loss=0.383498 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3413007855415344
[5/24] Train loss=0.3563207685947418
[10/24] Train loss=0.3566029369831085
[15/24] Train loss=0.34850701689720154
[20/24] Train loss=0.3437061607837677
Test set avg_accuracy=81.90% avg_sensitivity=46.95%, avg_specificity=93.53% avg_auc=87.17%
Best model saved!! Metric=87.17327842221223!!
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.377613 Test loss=0.380791 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3383888304233551
[5/24] Train loss=0.35140591859817505
[10/24] Train loss=0.34672337770462036
[15/24] Train loss=0.3429502844810486
[20/24] Train loss=0.3347647488117218
Test set avg_accuracy=82.04% avg_sensitivity=45.85%, avg_specificity=94.08% avg_auc=87.38%
Best model saved!! Metric=87.38428669716902!!
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.370310 Test loss=0.380520 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.33020448684692383
[5/24] Train loss=0.34689685702323914
[10/24] Train loss=0.3466132879257202
[15/24] Train loss=0.3361546993255615
[20/24] Train loss=0.33016711473464966
Test set avg_accuracy=82.14% avg_sensitivity=45.80%, avg_specificity=94.22% avg_auc=87.56%
Best model saved!! Metric=87.55874428193961!!
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.363795 Test loss=0.379241 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.32462871074676514
[5/24] Train loss=0.34320467710494995
[10/24] Train loss=0.33981993794441223
[15/24] Train loss=0.3266158103942871
[20/24] Train loss=0.32354772090911865
Test set avg_accuracy=82.30% avg_sensitivity=46.79%, avg_specificity=94.12% avg_auc=87.70%
Best model saved!! Metric=87.69720785494066!!
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.357006 Test loss=0.378767 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.32089725136756897
[5/24] Train loss=0.33872556686401367
[10/24] Train loss=0.33911818265914917
[15/24] Train loss=0.31872841715812683
[20/24] Train loss=0.32233068346977234
Test set avg_accuracy=82.38% avg_sensitivity=46.95%, avg_specificity=94.17% avg_auc=87.80%
Best model saved!! Metric=87.80121167619855!!
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.352797 Test loss=0.378726 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3145259618759155
[5/24] Train loss=0.3368704617023468
[10/24] Train loss=0.3377756178379059
[15/24] Train loss=0.30800655484199524
[20/24] Train loss=0.31267794966697693
Test set avg_accuracy=82.64% avg_sensitivity=48.20%, avg_specificity=94.10% avg_auc=87.92%
Best model saved!! Metric=87.9194175858423!!
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.347580 Test loss=0.375955 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.30922406911849976
[5/24] Train loss=0.3314135670661926
[10/24] Train loss=0.32805946469306946
[15/24] Train loss=0.31081631779670715
[20/24] Train loss=0.306822270154953
Test set avg_accuracy=82.72% avg_sensitivity=49.24%, avg_specificity=93.86% avg_auc=87.93%
Best model saved!! Metric=87.93310372837858!!
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.342890 Test loss=0.375736 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3036572337150574
[5/24] Train loss=0.32605212926864624
[10/24] Train loss=0.3226383924484253
[15/24] Train loss=0.30455300211906433
[20/24] Train loss=0.30408427119255066
Test set avg_accuracy=82.57% avg_sensitivity=48.30%, avg_specificity=93.96% avg_auc=87.95%
Best model saved!! Metric=87.95405837121689!!
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.338171 Test loss=0.377082 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.30102407932281494
[5/24] Train loss=0.32053759694099426
[10/24] Train loss=0.3278300166130066
[15/24] Train loss=0.3025035262107849
[20/24] Train loss=0.3020179867744446
Test set avg_accuracy=82.71% avg_sensitivity=49.50%, avg_specificity=93.75% avg_auc=87.95%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.335435 Test loss=0.376126 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.30229994654655457
[5/24] Train loss=0.31243476271629333
[10/24] Train loss=0.314503937959671
[15/24] Train loss=0.2955668568611145
[20/24] Train loss=0.2945818305015564
Test set avg_accuracy=82.72% avg_sensitivity=49.09%, avg_specificity=93.91% avg_auc=87.99%
Best model saved!! Metric=87.98931467093834!!
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.330107 Test loss=0.377217 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.29442840814590454
[5/24] Train loss=0.31554171442985535
[10/24] Train loss=0.3147431015968323
[15/24] Train loss=0.2960163950920105
[20/24] Train loss=0.2910596430301666
Test set avg_accuracy=82.80% avg_sensitivity=50.03%, avg_specificity=93.70% avg_auc=88.00%
Best model saved!! Metric=87.99596765689348!!
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.327577 Test loss=0.375440 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.29520004987716675
[5/24] Train loss=0.3117230236530304
[10/24] Train loss=0.3102714717388153
[15/24] Train loss=0.29231026768684387
[20/24] Train loss=0.2887900173664093
Test set avg_accuracy=82.85% avg_sensitivity=50.81%, avg_specificity=93.51% avg_auc=88.02%
Best model saved!! Metric=88.01988219960569!!
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.323995 Test loss=0.374049 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2889624238014221
[5/24] Train loss=0.31000056862831116
[10/24] Train loss=0.3067004680633545
[15/24] Train loss=0.2897671163082123
[20/24] Train loss=0.2865147888660431
Test set avg_accuracy=82.70% avg_sensitivity=51.12%, avg_specificity=93.20% avg_auc=87.99%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.321802 Test loss=0.374262 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2863496243953705
[5/24] Train loss=0.3044695258140564
[10/24] Train loss=0.30777081847190857
[15/24] Train loss=0.28813865780830383
[20/24] Train loss=0.2803560495376587
Test set avg_accuracy=82.77% avg_sensitivity=50.50%, avg_specificity=93.51% avg_auc=87.96%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.318178 Test loss=0.375829 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2811335325241089
[5/24] Train loss=0.30132347345352173
[10/24] Train loss=0.30186837911605835
[15/24] Train loss=0.2846076488494873
[20/24] Train loss=0.276779443025589
Test set avg_accuracy=82.76% avg_sensitivity=52.22%, avg_specificity=92.92% avg_auc=87.95%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.315549 Test loss=0.373798 Current lr=[0.000299720220882401]

[0/24] Train loss=0.28062355518341064
[5/24] Train loss=0.3000935912132263
[10/24] Train loss=0.30025994777679443
[15/24] Train loss=0.2831616997718811
[20/24] Train loss=0.2789751887321472
Test set avg_accuracy=82.79% avg_sensitivity=52.01%, avg_specificity=93.02% avg_auc=87.95%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.312983 Test loss=0.374624 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.28054580092430115
[5/24] Train loss=0.29472434520721436
[10/24] Train loss=0.29541128873825073
[15/24] Train loss=0.2808176875114441
[20/24] Train loss=0.27873554825782776
Test set avg_accuracy=82.81% avg_sensitivity=52.48%, avg_specificity=92.90% avg_auc=87.92%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.311113 Test loss=0.374233 Current lr=[0.000298904600941902]

[0/24] Train loss=0.27258968353271484
[5/24] Train loss=0.2946673333644867
[10/24] Train loss=0.2945844233036041
[15/24] Train loss=0.28049787878990173
[20/24] Train loss=0.2735506296157837
Test set avg_accuracy=82.79% avg_sensitivity=51.64%, avg_specificity=93.15% avg_auc=87.88%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.308621 Test loss=0.376039 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2712608873844147
[5/24] Train loss=0.29328855872154236
[10/24] Train loss=0.2934843897819519
[15/24] Train loss=0.27868643403053284
[20/24] Train loss=0.27103468775749207
Test set avg_accuracy=82.81% avg_sensitivity=51.33%, avg_specificity=93.28% avg_auc=87.84%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.307404 Test loss=0.377317 Current lr=[0.000297555943323901]

[0/24] Train loss=0.27332520484924316
[5/24] Train loss=0.2892397940158844
[10/24] Train loss=0.2899807095527649
[15/24] Train loss=0.27185195684432983
[20/24] Train loss=0.275987833738327
Test set avg_accuracy=82.89% avg_sensitivity=53.26%, avg_specificity=92.75% avg_auc=87.86%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.303998 Test loss=0.374960 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2687404155731201
[5/24] Train loss=0.285174697637558
[10/24] Train loss=0.2893756926059723
[15/24] Train loss=0.2735447883605957
[20/24] Train loss=0.2713024318218231
Test set avg_accuracy=82.92% avg_sensitivity=52.58%, avg_specificity=93.01% avg_auc=87.83%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.302119 Test loss=0.376295 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.26626670360565186
[5/24] Train loss=0.2865070402622223
[10/24] Train loss=0.28754016757011414
[15/24] Train loss=0.2699033319950104
[20/24] Train loss=0.26792532205581665
Test set avg_accuracy=82.99% avg_sensitivity=52.32%, avg_specificity=93.20% avg_auc=87.81%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.300523 Test loss=0.376610 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2662097215652466
[5/24] Train loss=0.2818583846092224
[10/24] Train loss=0.2831067442893982
[15/24] Train loss=0.2703334391117096
[20/24] Train loss=0.2656939625740051
Test set avg_accuracy=83.14% avg_sensitivity=53.21%, avg_specificity=93.09% avg_auc=87.82%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.298110 Test loss=0.376606 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2619972229003906
[5/24] Train loss=0.28179246187210083
[10/24] Train loss=0.28543907403945923
[15/24] Train loss=0.2640932500362396
[20/24] Train loss=0.2632848918437958
Test set avg_accuracy=83.11% avg_sensitivity=53.26%, avg_specificity=93.04% avg_auc=87.85%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.296369 Test loss=0.376191 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.25970256328582764
[5/24] Train loss=0.2816441059112549
[10/24] Train loss=0.2826647460460663
[15/24] Train loss=0.2622895836830139
[20/24] Train loss=0.26149237155914307
Test set avg_accuracy=83.11% avg_sensitivity=53.21%, avg_specificity=93.06% avg_auc=87.79%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.294514 Test loss=0.376974 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.25863268971443176
[5/24] Train loss=0.27764785289764404
[10/24] Train loss=0.2844164967536926
[15/24] Train loss=0.2651232182979584
[20/24] Train loss=0.26236850023269653
Test set avg_accuracy=83.18% avg_sensitivity=53.89%, avg_specificity=92.92% avg_auc=87.80%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.292819 Test loss=0.376203 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2612081468105316
[5/24] Train loss=0.27640458941459656
[10/24] Train loss=0.2772860527038574
[15/24] Train loss=0.2636786103248596
[20/24] Train loss=0.2572271525859833
Test set avg_accuracy=83.19% avg_sensitivity=53.42%, avg_specificity=93.09% avg_auc=87.80%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.291412 Test loss=0.376439 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2591516375541687
[5/24] Train loss=0.273843377828598
[10/24] Train loss=0.27623024582862854
[15/24] Train loss=0.25875306129455566
[20/24] Train loss=0.2567570209503174
Test set avg_accuracy=83.15% avg_sensitivity=53.05%, avg_specificity=93.16% avg_auc=87.79%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.289507 Test loss=0.377355 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.257678359746933
[5/24] Train loss=0.2692197859287262
[10/24] Train loss=0.27398911118507385
[15/24] Train loss=0.2623974084854126
[20/24] Train loss=0.25648945569992065
Test set avg_accuracy=83.24% avg_sensitivity=53.31%, avg_specificity=93.20% avg_auc=87.78%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.288039 Test loss=0.378067 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2576553225517273
[5/24] Train loss=0.26992690563201904
[10/24] Train loss=0.2740235924720764
[15/24] Train loss=0.26225048303604126
[20/24] Train loss=0.2564936578273773
Test set avg_accuracy=83.28% avg_sensitivity=54.46%, avg_specificity=92.87% avg_auc=87.79%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.286941 Test loss=0.376553 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2585124969482422
[5/24] Train loss=0.2704388201236725
[10/24] Train loss=0.27238786220550537
[15/24] Train loss=0.25985315442085266
[20/24] Train loss=0.25027230381965637
Test set avg_accuracy=83.28% avg_sensitivity=54.04%, avg_specificity=93.01% avg_auc=87.78%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.285936 Test loss=0.376884 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.25417208671569824
[5/24] Train loss=0.2638132572174072
[10/24] Train loss=0.2700978219509125
[15/24] Train loss=0.2557433247566223
[20/24] Train loss=0.2507210373878479
Test set avg_accuracy=83.33% avg_sensitivity=52.79%, avg_specificity=93.49% avg_auc=87.79%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.284056 Test loss=0.378796 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2526143193244934
[5/24] Train loss=0.26679345965385437
[10/24] Train loss=0.2704616189002991
[15/24] Train loss=0.25750732421875
[20/24] Train loss=0.2524818480014801
Test set avg_accuracy=83.39% avg_sensitivity=53.31%, avg_specificity=93.39% avg_auc=87.75%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.283495 Test loss=0.378392 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.2554923892021179
[5/24] Train loss=0.2629096806049347
[10/24] Train loss=0.266114741563797
[15/24] Train loss=0.2583679258823395
[20/24] Train loss=0.25029075145721436
Test set avg_accuracy=83.22% avg_sensitivity=53.99%, avg_specificity=92.94% avg_auc=87.73%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.282091 Test loss=0.378081 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2577158510684967
[5/24] Train loss=0.26305973529815674
[10/24] Train loss=0.2699175477027893
[15/24] Train loss=0.2571013271808624
[20/24] Train loss=0.24798959493637085
Test set avg_accuracy=83.33% avg_sensitivity=54.51%, avg_specificity=92.92% avg_auc=87.76%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.280852 Test loss=0.377213 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2490270733833313
[5/24] Train loss=0.25637131929397583
[10/24] Train loss=0.2661575973033905
[15/24] Train loss=0.2571375072002411
[20/24] Train loss=0.24942292273044586
Test set avg_accuracy=83.33% avg_sensitivity=53.83%, avg_specificity=93.15% avg_auc=87.67%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.279793 Test loss=0.378742 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.25053852796554565
[5/24] Train loss=0.25802499055862427
[10/24] Train loss=0.2670375406742096
[15/24] Train loss=0.25740450620651245
[20/24] Train loss=0.248528391122818
Test set avg_accuracy=83.46% avg_sensitivity=55.50%, avg_specificity=92.76% avg_auc=87.70%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.279263 Test loss=0.377047 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.24798260629177094
[5/24] Train loss=0.2570943534374237
[10/24] Train loss=0.2685590982437134
[15/24] Train loss=0.25238192081451416
[20/24] Train loss=0.247446671128273
Test set avg_accuracy=83.26% avg_sensitivity=57.43%, avg_specificity=91.84% avg_auc=87.76%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.279021 Test loss=0.374627 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.25088006258010864
[5/24] Train loss=0.25653544068336487
[10/24] Train loss=0.26805174350738525
[15/24] Train loss=0.26135316491127014
[20/24] Train loss=0.25071096420288086
Test set avg_accuracy=83.09% avg_sensitivity=59.31%, avg_specificity=90.99% avg_auc=87.75%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.279397 Test loss=0.374977 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.247477188706398
[5/24] Train loss=0.25331392884254456
[10/24] Train loss=0.2678322494029999
[15/24] Train loss=0.26673802733421326
[20/24] Train loss=0.24728582799434662
Test set avg_accuracy=83.24% avg_sensitivity=58.06%, avg_specificity=91.62% avg_auc=87.76%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.279984 Test loss=0.375295 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2498471438884735
[5/24] Train loss=0.2633155584335327
[10/24] Train loss=0.2763843536376953
[15/24] Train loss=0.2525133788585663
[20/24] Train loss=0.26076602935791016
Test set avg_accuracy=83.05% avg_sensitivity=50.55%, avg_specificity=93.86% avg_auc=87.64%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.279862 Test loss=0.386591 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.25162744522094727
[5/24] Train loss=0.25659307837486267
[10/24] Train loss=0.26221764087677
[15/24] Train loss=0.2513941824436188
[20/24] Train loss=0.24736139178276062
Test set avg_accuracy=83.19% avg_sensitivity=52.43%, avg_specificity=93.42% avg_auc=87.67%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.274940 Test loss=0.383227 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.24432647228240967
[5/24] Train loss=0.2565101087093353
[10/24] Train loss=0.261094331741333
[15/24] Train loss=0.2531491816043854
[20/24] Train loss=0.24819450080394745
Test set avg_accuracy=83.32% avg_sensitivity=54.15%, avg_specificity=93.02% avg_auc=87.81%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.273744 Test loss=0.378928 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.24511881172657013
[5/24] Train loss=0.25357019901275635
[10/24] Train loss=0.26088064908981323
[15/24] Train loss=0.25033465027809143
[20/24] Train loss=0.24433422088623047
Test set avg_accuracy=83.32% avg_sensitivity=54.04%, avg_specificity=93.06% avg_auc=87.74%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.271843 Test loss=0.379949 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2439398318529129
[5/24] Train loss=0.2512299120426178
[10/24] Train loss=0.259962797164917
[15/24] Train loss=0.25027996301651
[20/24] Train loss=0.24108822643756866
Test set avg_accuracy=83.26% avg_sensitivity=55.14%, avg_specificity=92.61% avg_auc=87.77%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.271723 Test loss=0.378649 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.24238567054271698
[5/24] Train loss=0.24753409624099731
[10/24] Train loss=0.26068612933158875
[15/24] Train loss=0.24858248233795166
[20/24] Train loss=0.24129821360111237
Test set avg_accuracy=83.37% avg_sensitivity=53.99%, avg_specificity=93.15% avg_auc=87.73%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.270714 Test loss=0.380389 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.23943883180618286
[5/24] Train loss=0.24716626107692719
[10/24] Train loss=0.26270708441734314
[15/24] Train loss=0.24845531582832336
[20/24] Train loss=0.23892949521541595
Test set avg_accuracy=83.31% avg_sensitivity=54.20%, avg_specificity=92.99% avg_auc=87.76%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.269507 Test loss=0.379424 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2440476268529892
[5/24] Train loss=0.2500384747982025
[10/24] Train loss=0.25565430521965027
[15/24] Train loss=0.25061842799186707
[20/24] Train loss=0.24282950162887573
Test set avg_accuracy=83.29% avg_sensitivity=53.47%, avg_specificity=93.22% avg_auc=87.72%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.269782 Test loss=0.381438 Current lr=[0.000224838296036774]

[0/24] Train loss=0.24175478518009186
[5/24] Train loss=0.24640224874019623
[10/24] Train loss=0.2597756087779999
[15/24] Train loss=0.25005000829696655
[20/24] Train loss=0.23849138617515564
Test set avg_accuracy=83.31% avg_sensitivity=53.83%, avg_specificity=93.11% avg_auc=87.72%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.268186 Test loss=0.381015 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.24208742380142212
[5/24] Train loss=0.24612344801425934
[10/24] Train loss=0.25747552514076233
[15/24] Train loss=0.2508428394794464
[20/24] Train loss=0.24243807792663574
Test set avg_accuracy=83.32% avg_sensitivity=54.77%, avg_specificity=92.82% avg_auc=87.69%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.268336 Test loss=0.380242 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.23645755648612976
[5/24] Train loss=0.24454830586910248
[10/24] Train loss=0.2550065219402313
[15/24] Train loss=0.25121793150901794
[20/24] Train loss=0.24077875912189484
Test set avg_accuracy=83.41% avg_sensitivity=53.68%, avg_specificity=93.30% avg_auc=87.67%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.267680 Test loss=0.382773 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.24197998642921448
[5/24] Train loss=0.24290671944618225
[10/24] Train loss=0.25920847058296204
[15/24] Train loss=0.24635566771030426
[20/24] Train loss=0.24146437644958496
Test set avg_accuracy=83.31% avg_sensitivity=51.49%, avg_specificity=93.89% avg_auc=87.57%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.267796 Test loss=0.387426 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.24099282920360565
[5/24] Train loss=0.24351410567760468
[10/24] Train loss=0.2590528130531311
[15/24] Train loss=0.24764537811279297
[20/24] Train loss=0.2355414479970932
Test set avg_accuracy=83.22% avg_sensitivity=53.21%, avg_specificity=93.20% avg_auc=87.58%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.266594 Test loss=0.384175 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.24091997742652893
[5/24] Train loss=0.2460438311100006
[10/24] Train loss=0.2613889276981354
[15/24] Train loss=0.24651913344860077
[20/24] Train loss=0.24318405985832214
Test set avg_accuracy=83.22% avg_sensitivity=51.33%, avg_specificity=93.82% avg_auc=87.57%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.266477 Test loss=0.388303 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2394581288099289
[5/24] Train loss=0.2424578219652176
[10/24] Train loss=0.2575845420360565
[15/24] Train loss=0.24706533551216125
[20/24] Train loss=0.23875215649604797
Test set avg_accuracy=83.22% avg_sensitivity=51.96%, avg_specificity=93.61% avg_auc=87.59%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.266364 Test loss=0.386795 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.24069419503211975
[5/24] Train loss=0.24101302027702332
[10/24] Train loss=0.25918880105018616
[15/24] Train loss=0.24845412373542786
[20/24] Train loss=0.24385614693164825
Test set avg_accuracy=83.14% avg_sensitivity=50.44%, avg_specificity=94.01% avg_auc=87.56%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.266833 Test loss=0.388998 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.23972569406032562
[5/24] Train loss=0.24129998683929443
[10/24] Train loss=0.26418763399124146
[15/24] Train loss=0.24751625955104828
[20/24] Train loss=0.23837178945541382
Test set avg_accuracy=83.24% avg_sensitivity=52.01%, avg_specificity=93.63% avg_auc=87.56%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.266423 Test loss=0.386890 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.23411914706230164
[5/24] Train loss=0.24121326208114624
[10/24] Train loss=0.26323145627975464
[15/24] Train loss=0.24670976400375366
[20/24] Train loss=0.2363893836736679
Test set avg_accuracy=83.23% avg_sensitivity=53.94%, avg_specificity=92.97% avg_auc=87.57%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.267536 Test loss=0.382879 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2351282835006714
[5/24] Train loss=0.24214555323123932
[10/24] Train loss=0.2668529748916626
[15/24] Train loss=0.2547574043273926
[20/24] Train loss=0.23894338309764862
Test set avg_accuracy=83.01% avg_sensitivity=61.19%, avg_specificity=90.27% avg_auc=87.64%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.269505 Test loss=0.378503 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.24294500052928925
[5/24] Train loss=0.2485465705394745
[10/24] Train loss=0.25901758670806885
[15/24] Train loss=0.24581730365753174
[20/24] Train loss=0.23570208251476288
Test set avg_accuracy=83.15% avg_sensitivity=60.25%, avg_specificity=90.77% avg_auc=87.70%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.268938 Test loss=0.377183 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.23160280287265778
[5/24] Train loss=0.2519749402999878
[10/24] Train loss=0.25458505749702454
[15/24] Train loss=0.24527230858802795
[20/24] Train loss=0.23626761138439178
Test set avg_accuracy=83.23% avg_sensitivity=58.53%, avg_specificity=91.45% avg_auc=87.69%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.265709 Test loss=0.377977 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.23207369446754456
[5/24] Train loss=0.24594756960868835
[10/24] Train loss=0.25059205293655396
[15/24] Train loss=0.24383693933486938
[20/24] Train loss=0.2321224957704544
Test set avg_accuracy=83.33% avg_sensitivity=58.95%, avg_specificity=91.45% avg_auc=87.68%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.264180 Test loss=0.378179 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2308184951543808
[5/24] Train loss=0.24457409977912903
[10/24] Train loss=0.2546161115169525
[15/24] Train loss=0.24535101652145386
[20/24] Train loss=0.23024018108844757
Test set avg_accuracy=83.28% avg_sensitivity=58.37%, avg_specificity=91.57% avg_auc=87.67%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.263883 Test loss=0.378947 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2327767014503479
[5/24] Train loss=0.2447960078716278
[10/24] Train loss=0.252731055021286
[15/24] Train loss=0.242014542222023
[20/24] Train loss=0.2338523417711258
Test set avg_accuracy=83.18% avg_sensitivity=57.64%, avg_specificity=91.67% avg_auc=87.69%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.263842 Test loss=0.379341 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2312285453081131
[5/24] Train loss=0.24329589307308197
[10/24] Train loss=0.2543954849243164
[15/24] Train loss=0.24410513043403625
[20/24] Train loss=0.23646263778209686
Test set avg_accuracy=83.20% avg_sensitivity=58.74%, avg_specificity=91.34% avg_auc=87.73%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.264182 Test loss=0.378878 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.23006267845630646
[5/24] Train loss=0.24189284443855286
[10/24] Train loss=0.2518382966518402
[15/24] Train loss=0.2411874234676361
[20/24] Train loss=0.23492038249969482
Test set avg_accuracy=83.20% avg_sensitivity=58.48%, avg_specificity=91.43% avg_auc=87.77%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.263250 Test loss=0.379216 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.22857528924942017
[5/24] Train loss=0.2419065535068512
[10/24] Train loss=0.25817474722862244
[15/24] Train loss=0.24192026257514954
[20/24] Train loss=0.23315978050231934
Test set avg_accuracy=83.18% avg_sensitivity=57.22%, avg_specificity=91.81% avg_auc=87.78%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.264710 Test loss=0.380174 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.23097023367881775
[5/24] Train loss=0.246177077293396
[10/24] Train loss=0.2550066113471985
[15/24] Train loss=0.24280788004398346
[20/24] Train loss=0.2414242923259735
Test set avg_accuracy=83.14% avg_sensitivity=58.22%, avg_specificity=91.43% avg_auc=87.81%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.264056 Test loss=0.380053 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.22933055460453033
[5/24] Train loss=0.24469751119613647
[10/24] Train loss=0.2540045380592346
[15/24] Train loss=0.24263380467891693
[20/24] Train loss=0.23829302191734314
Test set avg_accuracy=83.16% avg_sensitivity=58.63%, avg_specificity=91.32% avg_auc=87.84%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.264096 Test loss=0.380457 Current lr=[0.000134135431043539]

[0/24] Train loss=0.23104746639728546
[5/24] Train loss=0.24085615575313568
[10/24] Train loss=0.25686708092689514
[15/24] Train loss=0.24347200989723206
[20/24] Train loss=0.23255906999111176
Test set avg_accuracy=83.14% avg_sensitivity=59.94%, avg_specificity=90.86% avg_auc=87.87%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.264125 Test loss=0.380213 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.2299158275127411
[5/24] Train loss=0.24875454604625702
[10/24] Train loss=0.2547009587287903
[15/24] Train loss=0.2482834905385971
[20/24] Train loss=0.23693887889385223
Test set avg_accuracy=83.09% avg_sensitivity=62.13%, avg_specificity=90.06% avg_auc=87.89%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.264575 Test loss=0.380127 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.22879058122634888
[5/24] Train loss=0.25438472628593445
[10/24] Train loss=0.25918054580688477
[15/24] Train loss=0.24535465240478516
[20/24] Train loss=0.2353954166173935
Test set avg_accuracy=83.12% avg_sensitivity=65.83%, avg_specificity=88.88% avg_auc=87.90%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.265894 Test loss=0.382326 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.23701320588588715
[5/24] Train loss=0.2609691619873047
[10/24] Train loss=0.2600686550140381
[15/24] Train loss=0.2438885122537613
[20/24] Train loss=0.23141293227672577
Test set avg_accuracy=82.84% avg_sensitivity=68.60%, avg_specificity=87.58% avg_auc=87.93%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.267697 Test loss=0.386173 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.23994162678718567
[5/24] Train loss=0.25779053568840027
[10/24] Train loss=0.25153565406799316
[15/24] Train loss=0.24604594707489014
[20/24] Train loss=0.2379433810710907
Test set avg_accuracy=83.12% avg_sensitivity=64.95%, avg_specificity=89.17% avg_auc=87.92%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.266448 Test loss=0.380729 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.23382006585597992
[5/24] Train loss=0.2443985491991043
[10/24] Train loss=0.2545207738876343
[15/24] Train loss=0.24559332430362701
[20/24] Train loss=0.23296049237251282
Test set avg_accuracy=83.10% avg_sensitivity=60.77%, avg_specificity=90.53% avg_auc=87.90%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.262968 Test loss=0.379150 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.22949881851673126
[5/24] Train loss=0.23957231640815735
[10/24] Train loss=0.2563130557537079
[15/24] Train loss=0.24033895134925842
[20/24] Train loss=0.23303107917308807
Test set avg_accuracy=83.14% avg_sensitivity=61.92%, avg_specificity=90.20% avg_auc=87.90%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.261127 Test loss=0.379380 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.22609524428844452
[5/24] Train loss=0.242969810962677
[10/24] Train loss=0.25446242094039917
[15/24] Train loss=0.2435738444328308
[20/24] Train loss=0.23160326480865479
Test set avg_accuracy=83.10% avg_sensitivity=61.97%, avg_specificity=90.13% avg_auc=87.89%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.260427 Test loss=0.379972 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.22754178941249847
[5/24] Train loss=0.23901405930519104
[10/24] Train loss=0.25564175844192505
[15/24] Train loss=0.24139292538166046
[20/24] Train loss=0.23253223299980164
Test set avg_accuracy=83.01% avg_sensitivity=61.50%, avg_specificity=90.16% avg_auc=87.87%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.259817 Test loss=0.380425 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.230172798037529
[5/24] Train loss=0.240106463432312
[10/24] Train loss=0.2560792565345764
[15/24] Train loss=0.23758564889431
[20/24] Train loss=0.2321823537349701
Test set avg_accuracy=83.06% avg_sensitivity=61.09%, avg_specificity=90.37% avg_auc=87.87%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.259176 Test loss=0.380182 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2268717885017395
[5/24] Train loss=0.23646055161952972
[10/24] Train loss=0.2557006776332855
[15/24] Train loss=0.23905138671398163
[20/24] Train loss=0.22655580937862396
Test set avg_accuracy=82.99% avg_sensitivity=60.82%, avg_specificity=90.37% avg_auc=87.85%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.258805 Test loss=0.380726 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.2250628024339676
[5/24] Train loss=0.2369745969772339
[10/24] Train loss=0.2531944811344147
[15/24] Train loss=0.24286943674087524
[20/24] Train loss=0.23058278858661652
Test set avg_accuracy=82.96% avg_sensitivity=60.51%, avg_specificity=90.42% avg_auc=87.84%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.258816 Test loss=0.381026 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.2284637838602066
[5/24] Train loss=0.24126775562763214
[10/24] Train loss=0.25239840149879456
[15/24] Train loss=0.24096421897411346
[20/24] Train loss=0.23085440695285797
Test set avg_accuracy=82.92% avg_sensitivity=60.30%, avg_specificity=90.44% avg_auc=87.82%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.259629 Test loss=0.381018 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.22409655153751373
[5/24] Train loss=0.23904234170913696
[10/24] Train loss=0.2509818971157074
[15/24] Train loss=0.23925668001174927
[20/24] Train loss=0.22951699793338776
Test set avg_accuracy=82.92% avg_sensitivity=60.09%, avg_specificity=90.51% avg_auc=87.82%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.258357 Test loss=0.381359 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.22986766695976257
[5/24] Train loss=0.23755192756652832
[10/24] Train loss=0.25058749318122864
[15/24] Train loss=0.24000297486782074
[20/24] Train loss=0.22983156144618988
Test set avg_accuracy=82.99% avg_sensitivity=60.20%, avg_specificity=90.58% avg_auc=87.81%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.258532 Test loss=0.381699 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.22595730423927307
[5/24] Train loss=0.23992758989334106
[10/24] Train loss=0.25214338302612305
[15/24] Train loss=0.24119189381599426
[20/24] Train loss=0.2297780066728592
Test set avg_accuracy=82.88% avg_sensitivity=59.89%, avg_specificity=90.53% avg_auc=87.80%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.257602 Test loss=0.382024 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.22638371586799622
[5/24] Train loss=0.24025607109069824
[10/24] Train loss=0.2523774206638336
[15/24] Train loss=0.24116066098213196
[20/24] Train loss=0.23162759840488434
Test set avg_accuracy=82.89% avg_sensitivity=59.73%, avg_specificity=90.60% avg_auc=87.79%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.257418 Test loss=0.381929 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.2241242229938507
[5/24] Train loss=0.23409925401210785
[10/24] Train loss=0.2495589405298233
[15/24] Train loss=0.24179263412952423
[20/24] Train loss=0.23175953328609467
Test set avg_accuracy=82.85% avg_sensitivity=59.83%, avg_specificity=90.51% avg_auc=87.79%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.257505 Test loss=0.382154 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.22507868707180023
[5/24] Train loss=0.23760893940925598
[10/24] Train loss=0.25434303283691406
[15/24] Train loss=0.23796308040618896
[20/24] Train loss=0.2321927845478058
Test set avg_accuracy=82.93% avg_sensitivity=59.00%, avg_specificity=90.89% avg_auc=87.76%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.257108 Test loss=0.382696 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.22556205093860626
[5/24] Train loss=0.23569463193416595
[10/24] Train loss=0.2558683454990387
[15/24] Train loss=0.23914280533790588
[20/24] Train loss=0.23068998754024506
Test set avg_accuracy=82.86% avg_sensitivity=59.68%, avg_specificity=90.58% avg_auc=87.78%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.257514 Test loss=0.382460 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.22367937862873077
[5/24] Train loss=0.23875631392002106
[10/24] Train loss=0.2543817162513733
[15/24] Train loss=0.23596858978271484
[20/24] Train loss=0.2327209860086441
Test set avg_accuracy=82.81% avg_sensitivity=59.78%, avg_specificity=90.47% avg_auc=87.78%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.256840 Test loss=0.382243 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.22796256840229034
[5/24] Train loss=0.2381373643875122
[10/24] Train loss=0.25091278553009033
[15/24] Train loss=0.2360880970954895
[20/24] Train loss=0.2326408475637436
Test set avg_accuracy=82.83% avg_sensitivity=59.47%, avg_specificity=90.60% avg_auc=87.77%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.257249 Test loss=0.382490 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.22288285195827484
[5/24] Train loss=0.23759599030017853
[10/24] Train loss=0.2560025453567505
[15/24] Train loss=0.23728711903095245
[20/24] Train loss=0.231215238571167
Test set avg_accuracy=82.86% avg_sensitivity=60.25%, avg_specificity=90.39% avg_auc=87.78%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.257558 Test loss=0.382100 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.22770743072032928
[5/24] Train loss=0.23696526885032654
[10/24] Train loss=0.2502868175506592
[15/24] Train loss=0.23814904689788818
[20/24] Train loss=0.22783967852592468
Test set avg_accuracy=82.86% avg_sensitivity=60.62%, avg_specificity=90.27% avg_auc=87.77%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.256303 Test loss=0.382225 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.2239687442779541
[5/24] Train loss=0.23751437664031982
[10/24] Train loss=0.2514829635620117
[15/24] Train loss=0.23686222732067108
[20/24] Train loss=0.23255696892738342
Test set avg_accuracy=82.92% avg_sensitivity=60.56%, avg_specificity=90.35% avg_auc=87.78%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.256384 Test loss=0.382308 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.2225300371646881
[5/24] Train loss=0.2367614507675171
[10/24] Train loss=0.25059667229652405
[15/24] Train loss=0.24057145416736603
[20/24] Train loss=0.22656674683094025
Test set avg_accuracy=82.93% avg_sensitivity=60.41%, avg_specificity=90.42% avg_auc=87.77%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.257114 Test loss=0.382380 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.22509531676769257
[5/24] Train loss=0.23329219222068787
[10/24] Train loss=0.2556666433811188
[15/24] Train loss=0.23619672656059265
[20/24] Train loss=0.2290159910917282
Test set avg_accuracy=82.89% avg_sensitivity=60.15%, avg_specificity=90.46% avg_auc=87.77%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.255660 Test loss=0.382740 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.22402365505695343
[5/24] Train loss=0.2350110113620758
[10/24] Train loss=0.2526261508464813
[15/24] Train loss=0.237237811088562
[20/24] Train loss=0.23313675820827484
Test set avg_accuracy=82.83% avg_sensitivity=60.25%, avg_specificity=90.33% avg_auc=87.77%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.256388 Test loss=0.382777 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.22783222794532776
[5/24] Train loss=0.23223374783992767
[10/24] Train loss=0.2551308870315552
[15/24] Train loss=0.23769621551036835
[20/24] Train loss=0.229904443025589
Test set avg_accuracy=82.81% avg_sensitivity=59.15%, avg_specificity=90.68% avg_auc=87.76%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.256939 Test loss=0.382827 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.22361412644386292
[5/24] Train loss=0.23469731211662292
[10/24] Train loss=0.25420987606048584
[15/24] Train loss=0.23723380267620087
[20/24] Train loss=0.23116600513458252
Test set avg_accuracy=82.88% avg_sensitivity=58.53%, avg_specificity=90.98% avg_auc=87.75%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.256467 Test loss=0.383217 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.22658784687519073
[5/24] Train loss=0.23386354744434357
[10/24] Train loss=0.25073766708374023
[15/24] Train loss=0.24054668843746185
[20/24] Train loss=0.2321721464395523
Test set avg_accuracy=82.90% avg_sensitivity=58.32%, avg_specificity=91.08% avg_auc=87.74%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.257024 Test loss=0.383491 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.22430047392845154
[5/24] Train loss=0.23669208586215973
[10/24] Train loss=0.25107720494270325
[15/24] Train loss=0.23932942748069763
[20/24] Train loss=0.23043766617774963
Test set avg_accuracy=82.94% avg_sensitivity=58.63%, avg_specificity=91.03% avg_auc=87.75%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.255754 Test loss=0.383330 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.22633467614650726
[5/24] Train loss=0.2337452620267868
[10/24] Train loss=0.24831293523311615
[15/24] Train loss=0.2375536561012268
[20/24] Train loss=0.22756923735141754
Test set avg_accuracy=82.89% avg_sensitivity=58.95%, avg_specificity=90.86% avg_auc=87.75%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.255803 Test loss=0.383158 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.21949566900730133
[5/24] Train loss=0.23675163090229034
[10/24] Train loss=0.25155648589134216
[15/24] Train loss=0.2336868792772293
[20/24] Train loss=0.23088482022285461
Test set avg_accuracy=82.93% avg_sensitivity=58.63%, avg_specificity=91.01% avg_auc=87.75%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.255158 Test loss=0.383490 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.2234499156475067
[5/24] Train loss=0.2376524657011032
[10/24] Train loss=0.24861444532871246
[15/24] Train loss=0.23600386083126068
[20/24] Train loss=0.22906817495822906
Test set avg_accuracy=82.94% avg_sensitivity=58.79%, avg_specificity=90.98% avg_auc=87.75%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.255416 Test loss=0.383407 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.2275979369878769
[5/24] Train loss=0.2349083125591278
[10/24] Train loss=0.25229009985923767
[15/24] Train loss=0.23596885800361633
[20/24] Train loss=0.23134104907512665
Test set avg_accuracy=82.84% avg_sensitivity=58.22%, avg_specificity=91.03% avg_auc=87.74%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.256037 Test loss=0.383677 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.22291052341461182
[5/24] Train loss=0.236210897564888
[10/24] Train loss=0.25213560461997986
[15/24] Train loss=0.2392045110464096
[20/24] Train loss=0.22779527306556702
Test set avg_accuracy=82.90% avg_sensitivity=58.63%, avg_specificity=90.98% avg_auc=87.74%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.256099 Test loss=0.383496 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.2241247594356537
[5/24] Train loss=0.23548324406147003
[10/24] Train loss=0.24827566742897034
[15/24] Train loss=0.2402053028345108
[20/24] Train loss=0.22892113029956818
Test set avg_accuracy=82.93% avg_sensitivity=58.74%, avg_specificity=90.98% avg_auc=87.75%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.255963 Test loss=0.383488 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.22392316162586212
[5/24] Train loss=0.23730383813381195
[10/24] Train loss=0.24813860654830933
[15/24] Train loss=0.23582276701927185
[20/24] Train loss=0.23183581233024597
Test set avg_accuracy=82.92% avg_sensitivity=58.53%, avg_specificity=91.03% avg_auc=87.74%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.255753 Test loss=0.383534 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.22658665478229523
[5/24] Train loss=0.23296380043029785
[10/24] Train loss=0.25428757071495056
[15/24] Train loss=0.23822537064552307
[20/24] Train loss=0.2316095381975174
Test set avg_accuracy=82.89% avg_sensitivity=58.42%, avg_specificity=91.03% avg_auc=87.74%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.256105 Test loss=0.383536 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.22287620604038239
[5/24] Train loss=0.23641520738601685
[10/24] Train loss=0.2508491575717926
[15/24] Train loss=0.23708593845367432
[20/24] Train loss=0.2285228818655014
Test set avg_accuracy=82.88% avg_sensitivity=58.42%, avg_specificity=91.01% avg_auc=87.74%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.255583 Test loss=0.383519 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.2232484668493271
[5/24] Train loss=0.23412591218948364
[10/24] Train loss=0.2530844807624817
[15/24] Train loss=0.2378399819135666
[20/24] Train loss=0.23176588118076324
Test set avg_accuracy=82.89% avg_sensitivity=58.42%, avg_specificity=91.03% avg_auc=87.74%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.255715 Test loss=0.383562 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.2222020924091339
[5/24] Train loss=0.23164483904838562
[10/24] Train loss=0.25024089217185974
[15/24] Train loss=0.23785963654518127
[20/24] Train loss=0.22862768173217773
Test set avg_accuracy=82.88% avg_sensitivity=58.32%, avg_specificity=91.05% avg_auc=87.74%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.255615 Test loss=0.383599 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.22169403731822968
[5/24] Train loss=0.23546898365020752
[10/24] Train loss=0.24888809025287628
[15/24] Train loss=0.23727039992809296
[20/24] Train loss=0.23096950352191925
Test set avg_accuracy=82.86% avg_sensitivity=58.42%, avg_specificity=90.99% avg_auc=87.74%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.255299 Test loss=0.383501 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.22538195550441742
[5/24] Train loss=0.2372606098651886
[10/24] Train loss=0.2511507272720337
[15/24] Train loss=0.2426808774471283
[20/24] Train loss=0.22738823294639587
Test set avg_accuracy=82.88% avg_sensitivity=58.48%, avg_specificity=90.99% avg_auc=87.74%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.255590 Test loss=0.383483 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.22316327691078186
[5/24] Train loss=0.23805928230285645
[10/24] Train loss=0.2565881311893463
[15/24] Train loss=0.24066850543022156
[20/24] Train loss=0.22784757614135742
Test set avg_accuracy=82.86% avg_sensitivity=58.37%, avg_specificity=91.01% avg_auc=87.74%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.256286 Test loss=0.383493 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.2212127149105072
[5/24] Train loss=0.23478709161281586
[10/24] Train loss=0.250750869512558
[15/24] Train loss=0.23712344467639923
[20/24] Train loss=0.22847449779510498
Test set avg_accuracy=82.88% avg_sensitivity=58.42%, avg_specificity=91.01% avg_auc=87.74%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.255451 Test loss=0.383488 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.22511470317840576
[5/24] Train loss=0.23441436886787415
[10/24] Train loss=0.25132036209106445
[15/24] Train loss=0.23794639110565186
[20/24] Train loss=0.22991661727428436
Test set avg_accuracy=82.88% avg_sensitivity=58.42%, avg_specificity=91.01% avg_auc=87.74%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.255530 Test loss=0.383481 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.22556214034557343
[5/24] Train loss=0.23614312708377838
[10/24] Train loss=0.24778679013252258
[15/24] Train loss=0.23607967793941498
[20/24] Train loss=0.2298009693622589
Test set avg_accuracy=82.89% avg_sensitivity=58.48%, avg_specificity=91.01% avg_auc=87.74%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.255909 Test loss=0.383479 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=82.85% sen=50.81%, spe=93.51%, auc=88.02%!
Fold[2] Avg_jsc=0.51%(±0.28803910472323624)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.8553515076637268
[5/24] Train loss=0.8031914830207825
[10/24] Train loss=0.7954442501068115
[15/24] Train loss=0.7315928339958191
[20/24] Train loss=0.7048332691192627
Test set avg_accuracy=66.21% avg_sensitivity=13.89%, avg_specificity=86.03% avg_auc=52.11%
Best model saved!! Metric=52.106430862695376!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.752953 Test loss=0.656296 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6817443370819092
[5/24] Train loss=0.6555889248847961
[10/24] Train loss=0.6827085018157959
[15/24] Train loss=0.6443349719047546
[20/24] Train loss=0.6229943633079529
Test set avg_accuracy=71.25% avg_sensitivity=3.74%, avg_specificity=96.82% avg_auc=57.50%
Best model saved!! Metric=57.502965276064224!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.638345 Test loss=0.596683 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6094846129417419
[5/24] Train loss=0.5845960378646851
[10/24] Train loss=0.6455754637718201
[15/24] Train loss=0.6112082600593567
[20/24] Train loss=0.6061108112335205
Test set avg_accuracy=72.25% avg_sensitivity=2.99%, avg_specificity=98.49% avg_auc=63.13%
Best model saved!! Metric=63.132994971368284!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.595955 Test loss=0.574303 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.5830265879631042
[5/24] Train loss=0.567935585975647
[10/24] Train loss=0.6323802471160889
[15/24] Train loss=0.5932736992835999
[20/24] Train loss=0.5828164219856262
Test set avg_accuracy=72.54% avg_sensitivity=4.41%, avg_specificity=98.35% avg_auc=67.95%
Best model saved!! Metric=67.9517047146613!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.574954 Test loss=0.552638 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5677464604377747
[5/24] Train loss=0.5541155934333801
[10/24] Train loss=0.6071139574050903
[15/24] Train loss=0.5657138228416443
[20/24] Train loss=0.562006413936615
Test set avg_accuracy=72.84% avg_sensitivity=6.97%, avg_specificity=97.79% avg_auc=71.59%
Best model saved!! Metric=71.59001761297404!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.557782 Test loss=0.533616 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5480507612228394
[5/24] Train loss=0.5381515026092529
[10/24] Train loss=0.588310956954956
[15/24] Train loss=0.551574170589447
[20/24] Train loss=0.5382552146911621
Test set avg_accuracy=73.20% avg_sensitivity=8.91%, avg_specificity=97.56% avg_auc=74.81%
Best model saved!! Metric=74.81006917559368!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.540010 Test loss=0.518215 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5323871374130249
[5/24] Train loss=0.5289751291275024
[10/24] Train loss=0.5766539573669434
[15/24] Train loss=0.5440927743911743
[20/24] Train loss=0.5238491892814636
Test set avg_accuracy=73.58% avg_sensitivity=13.32%, avg_specificity=96.41% avg_auc=77.36%
Best model saved!! Metric=77.36352072289772!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.526069 Test loss=0.502284 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5099770426750183
[5/24] Train loss=0.5148077607154846
[10/24] Train loss=0.5634679794311523
[15/24] Train loss=0.5179994702339172
[20/24] Train loss=0.4980389177799225
Test set avg_accuracy=74.21% avg_sensitivity=19.95%, avg_specificity=94.76% avg_auc=79.47%
Best model saved!! Metric=79.46575680481932!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.508656 Test loss=0.484099 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.48494163155555725
[5/24] Train loss=0.49359527230262756
[10/24] Train loss=0.5523902177810669
[15/24] Train loss=0.49599072337150574
[20/24] Train loss=0.4793456196784973
Test set avg_accuracy=75.46% avg_sensitivity=30.05%, avg_specificity=92.66% avg_auc=81.14%
Best model saved!! Metric=81.13632612080627!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.491099 Test loss=0.466450 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.47497886419296265
[5/24] Train loss=0.4868406057357788
[10/24] Train loss=0.5348013639450073
[15/24] Train loss=0.47759026288986206
[20/24] Train loss=0.45507335662841797
Test set avg_accuracy=76.81% avg_sensitivity=38.91%, avg_specificity=91.17% avg_auc=82.60%
Best model saved!! Metric=82.60214674074894!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.474053 Test loss=0.449764 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.45021823048591614
[5/24] Train loss=0.47475820779800415
[10/24] Train loss=0.5297884345054626
[15/24] Train loss=0.46045851707458496
[20/24] Train loss=0.43015387654304504
Test set avg_accuracy=77.70% avg_sensitivity=43.13%, avg_specificity=90.79% avg_auc=83.96%
Best model saved!! Metric=83.95791605333244!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.458382 Test loss=0.434411 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4306802451610565
[5/24] Train loss=0.4580843150615692
[10/24] Train loss=0.5052689909934998
[15/24] Train loss=0.44551119208335876
[20/24] Train loss=0.4224340617656708
Test set avg_accuracy=78.53% avg_sensitivity=44.64%, avg_specificity=91.36% avg_auc=85.05%
Best model saved!! Metric=85.05020548469713!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.443641 Test loss=0.422083 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4133358895778656
[5/24] Train loss=0.4500027000904083
[10/24] Train loss=0.4895434081554413
[15/24] Train loss=0.43346405029296875
[20/24] Train loss=0.40411028265953064
Test set avg_accuracy=79.43% avg_sensitivity=47.63%, avg_specificity=91.47% avg_auc=85.93%
Best model saved!! Metric=85.92645094318753!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.428168 Test loss=0.411134 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.40379998087882996
[5/24] Train loss=0.42481932044029236
[10/24] Train loss=0.47824257612228394
[15/24] Train loss=0.41524437069892883
[20/24] Train loss=0.40024471282958984
Test set avg_accuracy=80.09% avg_sensitivity=52.42%, avg_specificity=90.57% avg_auc=86.61%
Best model saved!! Metric=86.60589907000094!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.416961 Test loss=0.400834 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3876281976699829
[5/24] Train loss=0.41772693395614624
[10/24] Train loss=0.46167969703674316
[15/24] Train loss=0.4060510993003845
[20/24] Train loss=0.3815729320049286
Test set avg_accuracy=80.70% avg_sensitivity=55.07%, avg_specificity=90.41% avg_auc=87.11%
Best model saved!! Metric=87.10790711921517!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.406708 Test loss=0.393391 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.38351550698280334
[5/24] Train loss=0.4203528165817261
[10/24] Train loss=0.4560297131538391
[15/24] Train loss=0.3955628573894501
[20/24] Train loss=0.3801513612270355
Test set avg_accuracy=81.47% avg_sensitivity=59.05%, avg_specificity=89.96% avg_auc=87.49%
Best model saved!! Metric=87.48769218987977!!
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.399213 Test loss=0.388019 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.37575921416282654
[5/24] Train loss=0.41114696860313416
[10/24] Train loss=0.44533294439315796
[15/24] Train loss=0.39210638403892517
[20/24] Train loss=0.37970948219299316
Test set avg_accuracy=81.65% avg_sensitivity=61.09%, avg_specificity=89.44% avg_auc=87.75%
Best model saved!! Metric=87.74784092166057!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.394492 Test loss=0.384720 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.36205950379371643
[5/24] Train loss=0.4082130193710327
[10/24] Train loss=0.44052213430404663
[15/24] Train loss=0.38924866914749146
[20/24] Train loss=0.3630029857158661
Test set avg_accuracy=81.65% avg_sensitivity=62.70%, avg_specificity=88.83% avg_auc=87.94%
Best model saved!! Metric=87.93866090345198!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.389075 Test loss=0.382621 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.36408674716949463
[5/24] Train loss=0.4070672392845154
[10/24] Train loss=0.43834516406059265
[15/24] Train loss=0.38541433215141296
[20/24] Train loss=0.36106669902801514
Test set avg_accuracy=81.76% avg_sensitivity=63.18%, avg_specificity=88.80% avg_auc=88.11%
Best model saved!! Metric=88.11049375888092!!
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.385346 Test loss=0.380284 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.35975393652915955
[5/24] Train loss=0.4110427796840668
[10/24] Train loss=0.43790146708488464
[15/24] Train loss=0.38434532284736633
[20/24] Train loss=0.35578274726867676
Test set avg_accuracy=81.82% avg_sensitivity=63.36%, avg_specificity=88.82% avg_auc=88.26%
Best model saved!! Metric=88.25923404834634!!
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.383795 Test loss=0.377864 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.35727712512016296
[5/24] Train loss=0.4076768755912781
[10/24] Train loss=0.4334200620651245
[15/24] Train loss=0.3858022689819336
[20/24] Train loss=0.35330337285995483
Test set avg_accuracy=82.04% avg_sensitivity=64.03%, avg_specificity=88.87% avg_auc=88.38%
Best model saved!! Metric=88.38492856960528!!
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.380477 Test loss=0.376396 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3507483899593353
[5/24] Train loss=0.40076112747192383
[10/24] Train loss=0.4308147728443146
[15/24] Train loss=0.3768138587474823
[20/24] Train loss=0.3429545760154724
Test set avg_accuracy=82.19% avg_sensitivity=63.41%, avg_specificity=89.30% avg_auc=88.50%
Best model saved!! Metric=88.49876198660735!!
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.376986 Test loss=0.374214 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3478558361530304
[5/24] Train loss=0.4033960700035095
[10/24] Train loss=0.42858174443244934
[15/24] Train loss=0.38046011328697205
[20/24] Train loss=0.3379717767238617
Test set avg_accuracy=82.23% avg_sensitivity=62.09%, avg_specificity=89.86% avg_auc=88.61%
Best model saved!! Metric=88.61484595029226!!
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.374253 Test loss=0.371781 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3422730267047882
[5/24] Train loss=0.39715102314949036
[10/24] Train loss=0.4215531349182129
[15/24] Train loss=0.3795595169067383
[20/24] Train loss=0.33544713258743286
Test set avg_accuracy=82.04% avg_sensitivity=60.05%, avg_specificity=90.38% avg_auc=88.72%
Best model saved!! Metric=88.71588656223676!!
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.370162 Test loss=0.370051 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3379265367984772
[5/24] Train loss=0.38778167963027954
[10/24] Train loss=0.4171607196331024
[15/24] Train loss=0.37870505452156067
[20/24] Train loss=0.32667258381843567
Test set avg_accuracy=82.30% avg_sensitivity=57.63%, avg_specificity=91.65% avg_auc=88.83%
Best model saved!! Metric=88.82541883992614!!
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.365760 Test loss=0.369145 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3377879858016968
[5/24] Train loss=0.38091951608657837
[10/24] Train loss=0.40869981050491333
[15/24] Train loss=0.3693382441997528
[20/24] Train loss=0.32731059193611145
Test set avg_accuracy=82.28% avg_sensitivity=56.35%, avg_specificity=92.10% avg_auc=88.90%
Best model saved!! Metric=88.90380082874574!!
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.362304 Test loss=0.368935 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.33259081840515137
[5/24] Train loss=0.37512704730033875
[10/24] Train loss=0.40528810024261475
[15/24] Train loss=0.36153581738471985
[20/24] Train loss=0.32719549536705017
Test set avg_accuracy=82.47% avg_sensitivity=56.49%, avg_specificity=92.32% avg_auc=89.01%
Best model saved!! Metric=89.00516051630689!!
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.358221 Test loss=0.367272 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3326283395290375
[5/24] Train loss=0.3659207820892334
[10/24] Train loss=0.40321651101112366
[15/24] Train loss=0.3551553785800934
[20/24] Train loss=0.3323383629322052
Test set avg_accuracy=82.70% avg_sensitivity=57.68%, avg_specificity=92.17% avg_auc=89.12%
Best model saved!! Metric=89.12479685519072!!
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.356024 Test loss=0.364617 Current lr=[0.000210185142098938]

[0/24] Train loss=0.32715240120887756
[5/24] Train loss=0.36084872484207153
[10/24] Train loss=0.39765313267707825
[15/24] Train loss=0.3479745388031006
[20/24] Train loss=0.3321261405944824
Test set avg_accuracy=82.77% avg_sensitivity=58.53%, avg_specificity=91.96% avg_auc=89.26%
Best model saved!! Metric=89.25512435440368!!
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.352426 Test loss=0.361749 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3245965540409088
[5/24] Train loss=0.359152227640152
[10/24] Train loss=0.39634159207344055
[15/24] Train loss=0.34396445751190186
[20/24] Train loss=0.330504834651947
Test set avg_accuracy=83.09% avg_sensitivity=58.96%, avg_specificity=92.23% avg_auc=89.39%
Best model saved!! Metric=89.39472206386615!!
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.350212 Test loss=0.359485 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.32517337799072266
[5/24] Train loss=0.35419920086860657
[10/24] Train loss=0.39110642671585083
[15/24] Train loss=0.3406248986721039
[20/24] Train loss=0.32206466794013977
Test set avg_accuracy=83.03% avg_sensitivity=57.25%, avg_specificity=92.80% avg_auc=89.50%
Best model saved!! Metric=89.49584350830023!!
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.347035 Test loss=0.358932 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.32215747237205505
[5/24] Train loss=0.34956082701683044
[10/24] Train loss=0.39043956995010376
[15/24] Train loss=0.33847302198410034
[20/24] Train loss=0.31992873549461365
Test set avg_accuracy=83.32% avg_sensitivity=57.73%, avg_specificity=93.02% avg_auc=89.61%
Best model saved!! Metric=89.6079879517047!!
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.344417 Test loss=0.356788 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.32003921270370483
[5/24] Train loss=0.3452645242214203
[10/24] Train loss=0.38212642073631287
[15/24] Train loss=0.3355151116847992
[20/24] Train loss=0.3168257474899292
Test set avg_accuracy=83.58% avg_sensitivity=57.87%, avg_specificity=93.32% avg_auc=89.71%
Best model saved!! Metric=89.7060335071941!!
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.341534 Test loss=0.355117 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3167822062969208
[5/24] Train loss=0.34055808186531067
[10/24] Train loss=0.38151732087135315
[15/24] Train loss=0.3328966498374939
[20/24] Train loss=0.3137893080711365
Test set avg_accuracy=83.70% avg_sensitivity=58.15%, avg_specificity=93.38% avg_auc=89.81%
Best model saved!! Metric=89.81460430369192!!
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.339562 Test loss=0.353128 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.31276068091392517
[5/24] Train loss=0.3409040570259094
[10/24] Train loss=0.3778596520423889
[15/24] Train loss=0.33111459016799927
[20/24] Train loss=0.31360238790512085
Test set avg_accuracy=84.01% avg_sensitivity=59.48%, avg_specificity=93.30% avg_auc=89.92%
Best model saved!! Metric=89.9159810086193!!
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.335680 Test loss=0.350803 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.31102463603019714
[5/24] Train loss=0.33901482820510864
[10/24] Train loss=0.37148523330688477
[15/24] Train loss=0.3264569044113159
[20/24] Train loss=0.3100149929523468
Test set avg_accuracy=84.10% avg_sensitivity=59.95%, avg_specificity=93.25% avg_auc=90.00%
Best model saved!! Metric=89.99537127638756!!
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.332932 Test loss=0.349154 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3073146343231201
[5/24] Train loss=0.3344308137893677
[10/24] Train loss=0.36843493580818176
[15/24] Train loss=0.3234842121601105
[20/24] Train loss=0.3064654767513275
Test set avg_accuracy=84.24% avg_sensitivity=60.33%, avg_specificity=93.30% avg_auc=90.08%
Best model saved!! Metric=90.07966679996937!!
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.330425 Test loss=0.347642 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3056410253047943
[5/24] Train loss=0.33341890573501587
[10/24] Train loss=0.3668549060821533
[15/24] Train loss=0.3241329491138458
[20/24] Train loss=0.30191466212272644
Test set avg_accuracy=84.43% avg_sensitivity=60.47%, avg_specificity=93.50% avg_auc=90.17%
Best model saved!! Metric=90.16543007138786!!
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.327354 Test loss=0.346355 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.30355194211006165
[5/24] Train loss=0.3315862715244293
[10/24] Train loss=0.3619205355644226
[15/24] Train loss=0.31900307536125183
[20/24] Train loss=0.2979714274406433
Test set avg_accuracy=84.43% avg_sensitivity=60.28%, avg_specificity=93.57% avg_auc=90.24%
Best model saved!! Metric=90.2354778051001!!
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.324531 Test loss=0.345146 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.30406469106674194
[5/24] Train loss=0.3294956088066101
[10/24] Train loss=0.35901403427124023
[15/24] Train loss=0.31938624382019043
[20/24] Train loss=0.2963941693305969
Test set avg_accuracy=84.57% avg_sensitivity=60.71%, avg_specificity=93.61% avg_auc=90.30%
Best model saved!! Metric=90.29719128370502!!
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.322197 Test loss=0.344046 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2983151972293854
[5/24] Train loss=0.32730597257614136
[10/24] Train loss=0.35769420862197876
[15/24] Train loss=0.31760847568511963
[20/24] Train loss=0.2958660423755646
Test set avg_accuracy=84.47% avg_sensitivity=60.57%, avg_specificity=93.52% avg_auc=90.32%
Best model saved!! Metric=90.3231342585108!!
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.319990 Test loss=0.343452 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2951575815677643
[5/24] Train loss=0.32197239995002747
[10/24] Train loss=0.3537946343421936
[15/24] Train loss=0.31678780913352966
[20/24] Train loss=0.2926214337348938
Test set avg_accuracy=84.61% avg_sensitivity=60.52%, avg_specificity=93.73% avg_auc=90.39%
Best model saved!! Metric=90.38816612352906!!
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.318010 Test loss=0.342700 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2969784140586853
[5/24] Train loss=0.3189619779586792
[10/24] Train loss=0.3498113751411438
[15/24] Train loss=0.31247252225875854
[20/24] Train loss=0.2897407114505768
Test set avg_accuracy=84.62% avg_sensitivity=60.66%, avg_specificity=93.70% avg_auc=90.40%
Best model saved!! Metric=90.39915083342552!!
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.315908 Test loss=0.342245 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2923972010612488
[5/24] Train loss=0.3190705478191376
[10/24] Train loss=0.3472873270511627
[15/24] Train loss=0.3099512755870819
[20/24] Train loss=0.28838154673576355
Test set avg_accuracy=84.70% avg_sensitivity=61.14%, avg_specificity=93.63% avg_auc=90.44%
Best model saved!! Metric=90.43688684302329!!
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.313718 Test loss=0.341332 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2921611964702606
[5/24] Train loss=0.3170265853404999
[10/24] Train loss=0.345950722694397
[15/24] Train loss=0.31120017170906067
[20/24] Train loss=0.2867167294025421
Test set avg_accuracy=84.75% avg_sensitivity=61.56%, avg_specificity=93.54% avg_auc=90.44%
Best model saved!! Metric=90.4409284675011!!
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.311894 Test loss=0.340976 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.29085761308670044
[5/24] Train loss=0.31498682498931885
[10/24] Train loss=0.3440157175064087
[15/24] Train loss=0.3076627254486084
[20/24] Train loss=0.2832832336425781
Test set avg_accuracy=84.75% avg_sensitivity=61.23%, avg_specificity=93.66% avg_auc=90.45%
Best model saved!! Metric=90.44860329966733!!
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.310002 Test loss=0.341200 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2868860065937042
[5/24] Train loss=0.31513991951942444
[10/24] Train loss=0.3447837233543396
[15/24] Train loss=0.30701690912246704
[20/24] Train loss=0.28088149428367615
Test set avg_accuracy=84.80% avg_sensitivity=61.52%, avg_specificity=93.63% avg_auc=90.46%
Best model saved!! Metric=90.4640380508309!!
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.308174 Test loss=0.340614 Current lr=[0.000299720220882401]

[0/24] Train loss=0.28702205419540405
[5/24] Train loss=0.31001389026641846
[10/24] Train loss=0.33975183963775635
[15/24] Train loss=0.3038313388824463
[20/24] Train loss=0.28046125173568726
Test set avg_accuracy=84.78% avg_sensitivity=60.81%, avg_specificity=93.86% avg_auc=90.48%
Best model saved!! Metric=90.48053638738331!!
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.306149 Test loss=0.340759 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.28195586800575256
[5/24] Train loss=0.3079144060611725
[10/24] Train loss=0.3431728184223175
[15/24] Train loss=0.3014548122882843
[20/24] Train loss=0.27956992387771606
Test set avg_accuracy=84.80% avg_sensitivity=60.85%, avg_specificity=93.88% avg_auc=90.49%
Best model saved!! Metric=90.49038944242598!!
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.305066 Test loss=0.340501 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2840269207954407
[5/24] Train loss=0.308450847864151
[10/24] Train loss=0.33633220195770264
[15/24] Train loss=0.30244216322898865
[20/24] Train loss=0.27454957365989685
Test set avg_accuracy=84.78% avg_sensitivity=61.00%, avg_specificity=93.79% avg_auc=90.50%
Best model saved!! Metric=90.504939290546!!
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.303365 Test loss=0.340103 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.28209200501441956
[5/24] Train loss=0.3084057569503784
[10/24] Train loss=0.3324939012527466
[15/24] Train loss=0.30282774567604065
[20/24] Train loss=0.27685269713401794
Test set avg_accuracy=84.86% avg_sensitivity=62.18%, avg_specificity=93.45% avg_auc=90.49%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.302111 Test loss=0.339441 Current lr=[0.000297555943323901]

[0/24] Train loss=0.28043144941329956
[5/24] Train loss=0.3041146397590637
[10/24] Train loss=0.3319036066532135
[15/24] Train loss=0.303178995847702
[20/24] Train loss=0.27253860235214233
Test set avg_accuracy=84.82% avg_sensitivity=61.28%, avg_specificity=93.73% avg_auc=90.50%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.300885 Test loss=0.339805 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2801830470561981
[5/24] Train loss=0.30609244108200073
[10/24] Train loss=0.3314261734485626
[15/24] Train loss=0.2987361252307892
[20/24] Train loss=0.27277153730392456
Test set avg_accuracy=84.88% avg_sensitivity=62.65%, avg_specificity=93.30% avg_auc=90.51%
Best model saved!! Metric=90.50664102716823!!
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.300325 Test loss=0.338985 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2746230661869049
[5/24] Train loss=0.304385781288147
[10/24] Train loss=0.33370476961135864
[15/24] Train loss=0.3003729283809662
[20/24] Train loss=0.2742515206336975
Test set avg_accuracy=84.83% avg_sensitivity=62.37%, avg_specificity=93.34% avg_auc=90.48%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.299222 Test loss=0.339269 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.27422118186950684
[5/24] Train loss=0.3045536279678345
[10/24] Train loss=0.3315308690071106
[15/24] Train loss=0.2974543869495392
[20/24] Train loss=0.27225226163864136
Test set avg_accuracy=84.92% avg_sensitivity=62.09%, avg_specificity=93.57% avg_auc=90.48%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.297335 Test loss=0.339580 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.276312917470932
[5/24] Train loss=0.3002541959285736
[10/24] Train loss=0.33229008316993713
[15/24] Train loss=0.2963677644729614
[20/24] Train loss=0.27125072479248047
Test set avg_accuracy=84.80% avg_sensitivity=61.66%, avg_specificity=93.57% avg_auc=90.49%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.296532 Test loss=0.339462 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.27474498748779297
[5/24] Train loss=0.299606055021286
[10/24] Train loss=0.3279305398464203
[15/24] Train loss=0.29817524552345276
[20/24] Train loss=0.2691970765590668
Test set avg_accuracy=84.91% avg_sensitivity=61.94%, avg_specificity=93.61% avg_auc=90.47%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.295237 Test loss=0.339803 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.275684118270874
[5/24] Train loss=0.2972387969493866
[10/24] Train loss=0.3260749876499176
[15/24] Train loss=0.29516762495040894
[20/24] Train loss=0.26897886395454407
Test set avg_accuracy=84.88% avg_sensitivity=61.94%, avg_specificity=93.57% avg_auc=90.46%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.293904 Test loss=0.339830 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.27196699380874634
[5/24] Train loss=0.2974638342857361
[10/24] Train loss=0.3299918472766876
[15/24] Train loss=0.2967248558998108
[20/24] Train loss=0.2647188603878021
Test set avg_accuracy=84.90% avg_sensitivity=62.37%, avg_specificity=93.43% avg_auc=90.47%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.293468 Test loss=0.339403 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2698797583580017
[5/24] Train loss=0.2939819395542145
[10/24] Train loss=0.3271986246109009
[15/24] Train loss=0.2961257994174957
[20/24] Train loss=0.2662082314491272
Test set avg_accuracy=84.88% avg_sensitivity=61.56%, avg_specificity=93.72% avg_auc=90.44%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.291772 Test loss=0.340455 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.26819413900375366
[5/24] Train loss=0.2960118055343628
[10/24] Train loss=0.3215860426425934
[15/24] Train loss=0.29184889793395996
[20/24] Train loss=0.26602768898010254
Test set avg_accuracy=84.93% avg_sensitivity=62.46%, avg_specificity=93.45% avg_auc=90.42%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.290722 Test loss=0.340000 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.26902931928634644
[5/24] Train loss=0.2945561110973358
[10/24] Train loss=0.32066434621810913
[15/24] Train loss=0.2909461557865143
[20/24] Train loss=0.27044761180877686
Test set avg_accuracy=84.95% avg_sensitivity=62.94%, avg_specificity=93.29% avg_auc=90.42%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.291017 Test loss=0.339685 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.26851925253868103
[5/24] Train loss=0.29372960329055786
[10/24] Train loss=0.3215613067150116
[15/24] Train loss=0.29092302918434143
[20/24] Train loss=0.264799565076828
Test set avg_accuracy=85.04% avg_sensitivity=62.46%, avg_specificity=93.59% avg_auc=90.42%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.289214 Test loss=0.339986 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.26719534397125244
[5/24] Train loss=0.2910405695438385
[10/24] Train loss=0.32340070605278015
[15/24] Train loss=0.28959619998931885
[20/24] Train loss=0.2650718092918396
Test set avg_accuracy=85.00% avg_sensitivity=63.13%, avg_specificity=93.29% avg_auc=90.38%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.288521 Test loss=0.340279 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2670651376247406
[5/24] Train loss=0.2927921414375305
[10/24] Train loss=0.32150912284851074
[15/24] Train loss=0.29048457741737366
[20/24] Train loss=0.26440995931625366
Test set avg_accuracy=84.95% avg_sensitivity=62.94%, avg_specificity=93.29% avg_auc=90.36%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.288774 Test loss=0.340542 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.2668774425983429
[5/24] Train loss=0.2910114526748657
[10/24] Train loss=0.31876927614212036
[15/24] Train loss=0.28806212544441223
[20/24] Train loss=0.26454129815101624
Test set avg_accuracy=84.97% avg_sensitivity=62.70%, avg_specificity=93.41% avg_auc=90.36%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.287093 Test loss=0.340948 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.265418142080307
[5/24] Train loss=0.29314500093460083
[10/24] Train loss=0.31854864954948425
[15/24] Train loss=0.28826525807380676
[20/24] Train loss=0.26375386118888855
Test set avg_accuracy=84.87% avg_sensitivity=62.37%, avg_specificity=93.39% avg_auc=90.36%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.286632 Test loss=0.340945 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.26194238662719727
[5/24] Train loss=0.2925689220428467
[10/24] Train loss=0.3150245249271393
[15/24] Train loss=0.2897220849990845
[20/24] Train loss=0.26157814264297485
Test set avg_accuracy=84.95% avg_sensitivity=62.46%, avg_specificity=93.46% avg_auc=90.35%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.286134 Test loss=0.341090 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2671884596347809
[5/24] Train loss=0.29008573293685913
[10/24] Train loss=0.31697604060173035
[15/24] Train loss=0.290960431098938
[20/24] Train loss=0.25875258445739746
Test set avg_accuracy=84.93% avg_sensitivity=62.42%, avg_specificity=93.46% avg_auc=90.35%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.285894 Test loss=0.341028 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2631445527076721
[5/24] Train loss=0.2896827459335327
[10/24] Train loss=0.3171105980873108
[15/24] Train loss=0.28863850235939026
[20/24] Train loss=0.262878954410553
Test set avg_accuracy=84.87% avg_sensitivity=62.23%, avg_specificity=93.45% avg_auc=90.35%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.285104 Test loss=0.341237 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.26323944330215454
[5/24] Train loss=0.28938090801239014
[10/24] Train loss=0.31546151638031006
[15/24] Train loss=0.28863584995269775
[20/24] Train loss=0.2628917396068573
Test set avg_accuracy=84.86% avg_sensitivity=62.46%, avg_specificity=93.34% avg_auc=90.37%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.284638 Test loss=0.340795 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.2611745595932007
[5/24] Train loss=0.28753477334976196
[10/24] Train loss=0.3134666085243225
[15/24] Train loss=0.28838053345680237
[20/24] Train loss=0.25814780592918396
Test set avg_accuracy=84.91% avg_sensitivity=62.51%, avg_specificity=93.39% avg_auc=90.33%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.283269 Test loss=0.341453 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.259735643863678
[5/24] Train loss=0.28817683458328247
[10/24] Train loss=0.31519395112991333
[15/24] Train loss=0.28785836696624756
[20/24] Train loss=0.2599288821220398
Test set avg_accuracy=84.88% avg_sensitivity=62.51%, avg_specificity=93.36% avg_auc=90.36%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.282961 Test loss=0.340813 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2631152868270874
[5/24] Train loss=0.2848600745201111
[10/24] Train loss=0.315311998128891
[15/24] Train loss=0.2886737287044525
[20/24] Train loss=0.25743919610977173
Test set avg_accuracy=84.91% avg_sensitivity=62.13%, avg_specificity=93.54% avg_auc=90.36%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.283064 Test loss=0.341237 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.2616959810256958
[5/24] Train loss=0.288969486951828
[10/24] Train loss=0.3152621388435364
[15/24] Train loss=0.28779515624046326
[20/24] Train loss=0.25982245802879333
Test set avg_accuracy=84.83% avg_sensitivity=61.85%, avg_specificity=93.54% avg_auc=90.37%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.282318 Test loss=0.341196 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.25787314772605896
[5/24] Train loss=0.28306448459625244
[10/24] Train loss=0.31313976645469666
[15/24] Train loss=0.28658947348594666
[20/24] Train loss=0.2601090967655182
Test set avg_accuracy=84.84% avg_sensitivity=61.85%, avg_specificity=93.55% avg_auc=90.35%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.281778 Test loss=0.341561 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2582201361656189
[5/24] Train loss=0.28255611658096313
[10/24] Train loss=0.3103749752044678
[15/24] Train loss=0.287285178899765
[20/24] Train loss=0.2588300108909607
Test set avg_accuracy=84.71% avg_sensitivity=62.32%, avg_specificity=93.20% avg_auc=90.36%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.281267 Test loss=0.341071 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2573329508304596
[5/24] Train loss=0.28760677576065063
[10/24] Train loss=0.31208422780036926
[15/24] Train loss=0.2842158377170563
[20/24] Train loss=0.2545296847820282
Test set avg_accuracy=84.75% avg_sensitivity=61.18%, avg_specificity=93.68% avg_auc=90.30%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.281195 Test loss=0.343443 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.25457966327667236
[5/24] Train loss=0.28323474526405334
[10/24] Train loss=0.3083409070968628
[15/24] Train loss=0.28389936685562134
[20/24] Train loss=0.2586989998817444
Test set avg_accuracy=84.78% avg_sensitivity=61.99%, avg_specificity=93.41% avg_auc=90.32%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.279758 Test loss=0.342014 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2549246847629547
[5/24] Train loss=0.2844047248363495
[10/24] Train loss=0.31099218130111694
[15/24] Train loss=0.2861371338367462
[20/24] Train loss=0.2571655213832855
Test set avg_accuracy=84.78% avg_sensitivity=61.56%, avg_specificity=93.57% avg_auc=90.29%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.280629 Test loss=0.342878 Current lr=[0.000224838296036774]

[0/24] Train loss=0.25643190741539
[5/24] Train loss=0.282410204410553
[10/24] Train loss=0.3123665153980255
[15/24] Train loss=0.2901206910610199
[20/24] Train loss=0.25730371475219727
Test set avg_accuracy=84.74% avg_sensitivity=61.28%, avg_specificity=93.63% avg_auc=90.28%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.280444 Test loss=0.343632 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.25447338819503784
[5/24] Train loss=0.28140532970428467
[10/24] Train loss=0.30955150723457336
[15/24] Train loss=0.2805675268173218
[20/24] Train loss=0.2539549469947815
Test set avg_accuracy=84.75% avg_sensitivity=61.80%, avg_specificity=93.45% avg_auc=90.29%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.279174 Test loss=0.342716 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.25535571575164795
[5/24] Train loss=0.28295981884002686
[10/24] Train loss=0.3082987070083618
[15/24] Train loss=0.28828972578048706
[20/24] Train loss=0.25334715843200684
Test set avg_accuracy=84.79% avg_sensitivity=61.52%, avg_specificity=93.61% avg_auc=90.28%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.279775 Test loss=0.343328 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2557919919490814
[5/24] Train loss=0.2815627455711365
[10/24] Train loss=0.3109021782875061
[15/24] Train loss=0.2854241728782654
[20/24] Train loss=0.2546376585960388
Test set avg_accuracy=84.79% avg_sensitivity=61.61%, avg_specificity=93.57% avg_auc=90.28%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.280798 Test loss=0.343261 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.25451844930648804
[5/24] Train loss=0.27897530794143677
[10/24] Train loss=0.30883821845054626
[15/24] Train loss=0.2883557677268982
[20/24] Train loss=0.2537839412689209
Test set avg_accuracy=84.82% avg_sensitivity=61.33%, avg_specificity=93.72% avg_auc=90.28%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.279506 Test loss=0.343457 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2545367479324341
[5/24] Train loss=0.2825765013694763
[10/24] Train loss=0.30839890241622925
[15/24] Train loss=0.28908759355545044
[20/24] Train loss=0.25092950463294983
Test set avg_accuracy=84.61% avg_sensitivity=62.42%, avg_specificity=93.02% avg_auc=90.28%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.280318 Test loss=0.342768 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.253476083278656
[5/24] Train loss=0.2810239791870117
[10/24] Train loss=0.3133546710014343
[15/24] Train loss=0.29337307810783386
[20/24] Train loss=0.2539955675601959
Test set avg_accuracy=84.34% avg_sensitivity=64.55%, avg_specificity=91.83% avg_auc=90.28%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.281901 Test loss=0.341618 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2563638389110565
[5/24] Train loss=0.2882440388202667
[10/24] Train loss=0.31399834156036377
[15/24] Train loss=0.29226788878440857
[20/24] Train loss=0.25266334414482117
Test set avg_accuracy=84.28% avg_sensitivity=69.00%, avg_specificity=90.07% avg_auc=90.30%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.282966 Test loss=0.342662 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.25370675325393677
[5/24] Train loss=0.2932618260383606
[10/24] Train loss=0.31770259141921997
[15/24] Train loss=0.28652435541152954
[20/24] Train loss=0.2613215744495392
Test set avg_accuracy=84.02% avg_sensitivity=72.23%, avg_specificity=88.49% avg_auc=90.31%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.283448 Test loss=0.346218 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2585386037826538
[5/24] Train loss=0.29143911600112915
[10/24] Train loss=0.31402385234832764
[15/24] Train loss=0.277475506067276
[20/24] Train loss=0.264920175075531
Test set avg_accuracy=84.31% avg_sensitivity=70.47%, avg_specificity=89.55% avg_auc=90.30%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.282476 Test loss=0.343949 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.25242117047309875
[5/24] Train loss=0.288056343793869
[10/24] Train loss=0.3093029260635376
[15/24] Train loss=0.2783249616622925
[20/24] Train loss=0.2665955424308777
Test set avg_accuracy=84.27% avg_sensitivity=69.24%, avg_specificity=89.96% avg_auc=90.29%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.281045 Test loss=0.342855 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.25776803493499756
[5/24] Train loss=0.2876708507537842
[10/24] Train loss=0.3067556619644165
[15/24] Train loss=0.2759940028190613
[20/24] Train loss=0.2626463770866394
Test set avg_accuracy=84.32% avg_sensitivity=68.82%, avg_specificity=90.20% avg_auc=90.30%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.279054 Test loss=0.342461 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2514398992061615
[5/24] Train loss=0.28631913661956787
[10/24] Train loss=0.3071066439151764
[15/24] Train loss=0.2750470042228699
[20/24] Train loss=0.2582334280014038
Test set avg_accuracy=84.36% avg_sensitivity=68.82%, avg_specificity=90.25% avg_auc=90.30%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.278518 Test loss=0.342228 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2513527274131775
[5/24] Train loss=0.2861628234386444
[10/24] Train loss=0.3095186948776245
[15/24] Train loss=0.27559322118759155
[20/24] Train loss=0.2634553611278534
Test set avg_accuracy=84.45% avg_sensitivity=68.44%, avg_specificity=90.52% avg_auc=90.32%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.278182 Test loss=0.341490 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2514493465423584
[5/24] Train loss=0.2859771251678467
[10/24] Train loss=0.3099609911441803
[15/24] Train loss=0.27695539593696594
[20/24] Train loss=0.2596452832221985
Test set avg_accuracy=84.38% avg_sensitivity=67.68%, avg_specificity=90.70% avg_auc=90.32%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.277412 Test loss=0.341331 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.24898399412631989
[5/24] Train loss=0.2852500081062317
[10/24] Train loss=0.30557242035865784
[15/24] Train loss=0.2784225344657898
[20/24] Train loss=0.25791603326797485
Test set avg_accuracy=84.45% avg_sensitivity=67.44%, avg_specificity=90.90% avg_auc=90.34%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.276949 Test loss=0.340947 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2518218755722046
[5/24] Train loss=0.28471800684928894
[10/24] Train loss=0.3036898970603943
[15/24] Train loss=0.27723929286003113
[20/24] Train loss=0.2583630084991455
Test set avg_accuracy=84.43% avg_sensitivity=67.68%, avg_specificity=90.77% avg_auc=90.33%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.276867 Test loss=0.341114 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2487061619758606
[5/24] Train loss=0.2841458320617676
[10/24] Train loss=0.3108425438404083
[15/24] Train loss=0.2736114263534546
[20/24] Train loss=0.2566882371902466
Test set avg_accuracy=84.61% avg_sensitivity=67.25%, avg_specificity=91.18% avg_auc=90.33%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.276332 Test loss=0.340849 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.25280603766441345
[5/24] Train loss=0.28091487288475037
[10/24] Train loss=0.309270441532135
[15/24] Train loss=0.27739208936691284
[20/24] Train loss=0.2580541968345642
Test set avg_accuracy=84.61% avg_sensitivity=67.25%, avg_specificity=91.18% avg_auc=90.31%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.275631 Test loss=0.341064 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.24834325909614563
[5/24] Train loss=0.28046661615371704
[10/24] Train loss=0.3107675015926361
[15/24] Train loss=0.2737184762954712
[20/24] Train loss=0.2610609531402588
Test set avg_accuracy=84.57% avg_sensitivity=67.20%, avg_specificity=91.15% avg_auc=90.30%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.275411 Test loss=0.341108 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.24807296693325043
[5/24] Train loss=0.2836073637008667
[10/24] Train loss=0.308333158493042
[15/24] Train loss=0.27681612968444824
[20/24] Train loss=0.2591671645641327
Test set avg_accuracy=84.52% avg_sensitivity=66.07%, avg_specificity=91.51% avg_auc=90.29%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.275443 Test loss=0.340989 Current lr=[0.000134135431043539]

[0/24] Train loss=0.25163334608078003
[5/24] Train loss=0.2793780565261841
[10/24] Train loss=0.3087407946586609
[15/24] Train loss=0.27630162239074707
[20/24] Train loss=0.26070699095726013
Test set avg_accuracy=84.54% avg_sensitivity=66.87%, avg_specificity=91.24% avg_auc=90.28%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.275945 Test loss=0.341332 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.24797271192073822
[5/24] Train loss=0.27956193685531616
[10/24] Train loss=0.3111943304538727
[15/24] Train loss=0.27518993616104126
[20/24] Train loss=0.25941038131713867
Test set avg_accuracy=84.69% avg_sensitivity=65.92%, avg_specificity=91.80% avg_auc=90.27%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.274983 Test loss=0.341388 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.24761901795864105
[5/24] Train loss=0.2821788787841797
[10/24] Train loss=0.30575019121170044
[15/24] Train loss=0.27516594529151917
[20/24] Train loss=0.2584523558616638
Test set avg_accuracy=84.64% avg_sensitivity=66.21%, avg_specificity=91.62% avg_auc=90.29%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.274695 Test loss=0.340968 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.2444092035293579
[5/24] Train loss=0.2800300419330597
[10/24] Train loss=0.31064125895500183
[15/24] Train loss=0.2736157178878784
[20/24] Train loss=0.25824281573295593
Test set avg_accuracy=84.66% avg_sensitivity=65.97%, avg_specificity=91.74% avg_auc=90.31%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.273815 Test loss=0.340593 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.24637813866138458
[5/24] Train loss=0.27757972478866577
[10/24] Train loss=0.30704861879348755
[15/24] Train loss=0.2731693983078003
[20/24] Train loss=0.2551538050174713
Test set avg_accuracy=84.84% avg_sensitivity=65.78%, avg_specificity=92.06% avg_auc=90.29%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.273773 Test loss=0.340933 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.2512662708759308
[5/24] Train loss=0.2812238931655884
[10/24] Train loss=0.30781427025794983
[15/24] Train loss=0.2751718759536743
[20/24] Train loss=0.254637748003006
Test set avg_accuracy=84.84% avg_sensitivity=65.88%, avg_specificity=92.03% avg_auc=90.30%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.274590 Test loss=0.340779 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.24853567779064178
[5/24] Train loss=0.27900734543800354
[10/24] Train loss=0.3092564046382904
[15/24] Train loss=0.27543964982032776
[20/24] Train loss=0.25684449076652527
Test set avg_accuracy=84.79% avg_sensitivity=65.55%, avg_specificity=92.08% avg_auc=90.28%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.273316 Test loss=0.340909 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.24748767912387848
[5/24] Train loss=0.27881789207458496
[10/24] Train loss=0.3084362745285034
[15/24] Train loss=0.2738615870475769
[20/24] Train loss=0.2557663917541504
Test set avg_accuracy=84.75% avg_sensitivity=64.79%, avg_specificity=92.32% avg_auc=90.29%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.273128 Test loss=0.340998 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.24804730713367462
[5/24] Train loss=0.27438297867774963
[10/24] Train loss=0.30622947216033936
[15/24] Train loss=0.2746271789073944
[20/24] Train loss=0.2564128339290619
Test set avg_accuracy=84.84% avg_sensitivity=65.02%, avg_specificity=92.35% avg_auc=90.28%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.272702 Test loss=0.340989 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.2460235208272934
[5/24] Train loss=0.2765074670314789
[10/24] Train loss=0.3068043291568756
[15/24] Train loss=0.2739299237728119
[20/24] Train loss=0.25725623965263367
Test set avg_accuracy=84.84% avg_sensitivity=64.88%, avg_specificity=92.41% avg_auc=90.30%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.273152 Test loss=0.340763 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2466908097267151
[5/24] Train loss=0.27502360939979553
[10/24] Train loss=0.3086835443973541
[15/24] Train loss=0.2736309766769409
[20/24] Train loss=0.2529938817024231
Test set avg_accuracy=84.82% avg_sensitivity=64.83%, avg_specificity=92.39% avg_auc=90.30%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.272494 Test loss=0.340770 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.24814820289611816
[5/24] Train loss=0.27856290340423584
[10/24] Train loss=0.30791720747947693
[15/24] Train loss=0.26931923627853394
[20/24] Train loss=0.25685393810272217
Test set avg_accuracy=84.78% avg_sensitivity=65.02%, avg_specificity=92.26% avg_auc=90.29%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.272511 Test loss=0.340765 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.24493549764156342
[5/24] Train loss=0.2752000391483307
[10/24] Train loss=0.3102920651435852
[15/24] Train loss=0.2736031115055084
[20/24] Train loss=0.2565661668777466
Test set avg_accuracy=84.86% avg_sensitivity=64.88%, avg_specificity=92.42% avg_auc=90.30%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.271797 Test loss=0.340658 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.24727781116962433
[5/24] Train loss=0.2766708433628082
[10/24] Train loss=0.302512526512146
[15/24] Train loss=0.27418163418769836
[20/24] Train loss=0.2563498020172119
Test set avg_accuracy=84.87% avg_sensitivity=64.64%, avg_specificity=92.53% avg_auc=90.30%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.271861 Test loss=0.340668 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.246468648314476
[5/24] Train loss=0.2756405770778656
[10/24] Train loss=0.30700889229774475
[15/24] Train loss=0.27181825041770935
[20/24] Train loss=0.2531575858592987
Test set avg_accuracy=84.84% avg_sensitivity=64.98%, avg_specificity=92.37% avg_auc=90.30%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.272133 Test loss=0.340625 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.2481071949005127
[5/24] Train loss=0.2746460735797882
[10/24] Train loss=0.3073469400405884
[15/24] Train loss=0.27293115854263306
[20/24] Train loss=0.25509366393089294
Test set avg_accuracy=84.84% avg_sensitivity=64.41%, avg_specificity=92.59% avg_auc=90.30%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.272461 Test loss=0.340797 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.24780677258968353
[5/24] Train loss=0.2772235870361328
[10/24] Train loss=0.30741044878959656
[15/24] Train loss=0.273436039686203
[20/24] Train loss=0.2523566484451294
Test set avg_accuracy=84.88% avg_sensitivity=64.45%, avg_specificity=92.62% avg_auc=90.30%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.271443 Test loss=0.340677 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.24483872950077057
[5/24] Train loss=0.2740584909915924
[10/24] Train loss=0.30607402324676514
[15/24] Train loss=0.2756095826625824
[20/24] Train loss=0.250413715839386
Test set avg_accuracy=84.90% avg_sensitivity=64.64%, avg_specificity=92.57% avg_auc=90.30%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.270782 Test loss=0.340732 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.24666616320610046
[5/24] Train loss=0.2771255671977997
[10/24] Train loss=0.30932673811912537
[15/24] Train loss=0.27191728353500366
[20/24] Train loss=0.2550191879272461
Test set avg_accuracy=84.91% avg_sensitivity=64.69%, avg_specificity=92.57% avg_auc=90.31%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.271632 Test loss=0.340625 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.2434367835521698
[5/24] Train loss=0.2746044993400574
[10/24] Train loss=0.30858588218688965
[15/24] Train loss=0.27119871973991394
[20/24] Train loss=0.2529520094394684
Test set avg_accuracy=84.84% avg_sensitivity=64.55%, avg_specificity=92.53% avg_auc=90.30%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.271013 Test loss=0.340634 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.24839158356189728
[5/24] Train loss=0.2750777006149292
[10/24] Train loss=0.30643585324287415
[15/24] Train loss=0.2695535123348236
[20/24] Train loss=0.25291910767555237
Test set avg_accuracy=84.95% avg_sensitivity=65.02%, avg_specificity=92.50% avg_auc=90.31%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.270909 Test loss=0.340525 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.24756324291229248
[5/24] Train loss=0.2775820195674896
[10/24] Train loss=0.3052688539028168
[15/24] Train loss=0.2679480016231537
[20/24] Train loss=0.25326281785964966
Test set avg_accuracy=84.82% avg_sensitivity=65.78%, avg_specificity=92.03% avg_auc=90.32%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.270918 Test loss=0.340403 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.24516546726226807
[5/24] Train loss=0.27343642711639404
[10/24] Train loss=0.3085383474826813
[15/24] Train loss=0.27329033613204956
[20/24] Train loss=0.2512105107307434
Test set avg_accuracy=84.82% avg_sensitivity=66.02%, avg_specificity=91.94% avg_auc=90.31%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.271125 Test loss=0.340442 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.24425706267356873
[5/24] Train loss=0.2801428437232971
[10/24] Train loss=0.3090451657772064
[15/24] Train loss=0.27263516187667847
[20/24] Train loss=0.25108960270881653
Test set avg_accuracy=84.78% avg_sensitivity=66.64%, avg_specificity=91.65% avg_auc=90.31%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.271075 Test loss=0.340621 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.2458701729774475
[5/24] Train loss=0.27375853061676025
[10/24] Train loss=0.3057183027267456
[15/24] Train loss=0.2707025408744812
[20/24] Train loss=0.25188905000686646
Test set avg_accuracy=84.79% avg_sensitivity=66.59%, avg_specificity=91.69% avg_auc=90.31%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.270327 Test loss=0.340624 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.246860533952713
[5/24] Train loss=0.27439653873443604
[10/24] Train loss=0.30435675382614136
[15/24] Train loss=0.27428576350212097
[20/24] Train loss=0.25260815024375916
Test set avg_accuracy=84.80% avg_sensitivity=66.21%, avg_specificity=91.85% avg_auc=90.31%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.270219 Test loss=0.340590 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.2421712428331375
[5/24] Train loss=0.2764175236225128
[10/24] Train loss=0.30401700735092163
[15/24] Train loss=0.2704969644546509
[20/24] Train loss=0.25125420093536377
Test set avg_accuracy=84.71% avg_sensitivity=66.26%, avg_specificity=91.71% avg_auc=90.31%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.270562 Test loss=0.340561 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.2423408031463623
[5/24] Train loss=0.27321726083755493
[10/24] Train loss=0.3073733150959015
[15/24] Train loss=0.2724575698375702
[20/24] Train loss=0.2536299228668213
Test set avg_accuracy=84.90% avg_sensitivity=65.88%, avg_specificity=92.10% avg_auc=90.30%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.269784 Test loss=0.340644 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.24592556059360504
[5/24] Train loss=0.2725786864757538
[10/24] Train loss=0.3089449107646942
[15/24] Train loss=0.27187860012054443
[20/24] Train loss=0.2539370656013489
Test set avg_accuracy=84.86% avg_sensitivity=65.88%, avg_specificity=92.05% avg_auc=90.29%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.271010 Test loss=0.340743 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.24338959157466888
[5/24] Train loss=0.2737005352973938
[10/24] Train loss=0.30753225088119507
[15/24] Train loss=0.27168598771095276
[20/24] Train loss=0.25211507081985474
Test set avg_accuracy=84.78% avg_sensitivity=65.92%, avg_specificity=91.92% avg_auc=90.29%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.270532 Test loss=0.340762 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.24203699827194214
[5/24] Train loss=0.2700023651123047
[10/24] Train loss=0.30984818935394287
[15/24] Train loss=0.2732641398906708
[20/24] Train loss=0.2529524862766266
Test set avg_accuracy=84.86% avg_sensitivity=65.78%, avg_specificity=92.08% avg_auc=90.29%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.270331 Test loss=0.340759 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.24341906607151031
[5/24] Train loss=0.2697986364364624
[10/24] Train loss=0.30659663677215576
[15/24] Train loss=0.27348271012306213
[20/24] Train loss=0.25653207302093506
Test set avg_accuracy=84.87% avg_sensitivity=65.73%, avg_specificity=92.12% avg_auc=90.29%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.269904 Test loss=0.340758 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.2430194616317749
[5/24] Train loss=0.2747368812561035
[10/24] Train loss=0.3088144361972809
[15/24] Train loss=0.2721029222011566
[20/24] Train loss=0.25015386939048767
Test set avg_accuracy=84.87% avg_sensitivity=65.83%, avg_specificity=92.08% avg_auc=90.29%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.269970 Test loss=0.340814 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.24555644392967224
[5/24] Train loss=0.27552086114883423
[10/24] Train loss=0.3069290816783905
[15/24] Train loss=0.27018266916275024
[20/24] Train loss=0.25367268919944763
Test set avg_accuracy=84.86% avg_sensitivity=65.50%, avg_specificity=92.19% avg_auc=90.28%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.270178 Test loss=0.340854 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.24613095819950104
[5/24] Train loss=0.27143728733062744
[10/24] Train loss=0.3097730875015259
[15/24] Train loss=0.27109402418136597
[20/24] Train loss=0.2517169117927551
Test set avg_accuracy=84.87% avg_sensitivity=65.83%, avg_specificity=92.08% avg_auc=90.29%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.270206 Test loss=0.340835 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.2429502010345459
[5/24] Train loss=0.2722698450088501
[10/24] Train loss=0.3059230446815491
[15/24] Train loss=0.27516233921051025
[20/24] Train loss=0.2523183822631836
Test set avg_accuracy=84.87% avg_sensitivity=65.64%, avg_specificity=92.15% avg_auc=90.29%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.269336 Test loss=0.340821 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.24697212874889374
[5/24] Train loss=0.2737247943878174
[10/24] Train loss=0.3055686354637146
[15/24] Train loss=0.27338340878486633
[20/24] Train loss=0.25347408652305603
Test set avg_accuracy=84.86% avg_sensitivity=65.64%, avg_specificity=92.14% avg_auc=90.29%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.269724 Test loss=0.340847 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.24234576523303986
[5/24] Train loss=0.2703963816165924
[10/24] Train loss=0.3059263825416565
[15/24] Train loss=0.27139076590538025
[20/24] Train loss=0.25267717242240906
Test set avg_accuracy=84.87% avg_sensitivity=65.59%, avg_specificity=92.17% avg_auc=90.28%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.269475 Test loss=0.340869 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.24233107268810272
[5/24] Train loss=0.2709047496318817
[10/24] Train loss=0.30712899565696716
[15/24] Train loss=0.26966845989227295
[20/24] Train loss=0.2501161992549896
Test set avg_accuracy=84.88% avg_sensitivity=65.64%, avg_specificity=92.17% avg_auc=90.29%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.269557 Test loss=0.340854 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.2440466433763504
[5/24] Train loss=0.2740245461463928
[10/24] Train loss=0.3036322295665741
[15/24] Train loss=0.27134737372398376
[20/24] Train loss=0.2531982660293579
Test set avg_accuracy=84.88% avg_sensitivity=65.64%, avg_specificity=92.17% avg_auc=90.29%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.269078 Test loss=0.340859 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.24759827554225922
[5/24] Train loss=0.2701183557510376
[10/24] Train loss=0.3058241605758667
[15/24] Train loss=0.2741374969482422
[20/24] Train loss=0.25078216195106506
Test set avg_accuracy=84.86% avg_sensitivity=65.64%, avg_specificity=92.14% avg_auc=90.28%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.270165 Test loss=0.340873 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.2463299036026001
[5/24] Train loss=0.27105340361595154
[10/24] Train loss=0.30661049485206604
[15/24] Train loss=0.27308058738708496
[20/24] Train loss=0.25350433588027954
Test set avg_accuracy=84.87% avg_sensitivity=65.59%, avg_specificity=92.17% avg_auc=90.28%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.270507 Test loss=0.340892 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.2436685860157013
[5/24] Train loss=0.27357178926467896
[10/24] Train loss=0.30678126215934753
[15/24] Train loss=0.27269527316093445
[20/24] Train loss=0.2504890561103821
Test set avg_accuracy=84.86% avg_sensitivity=65.45%, avg_specificity=92.21% avg_auc=90.28%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.269539 Test loss=0.340909 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.24034138023853302
[5/24] Train loss=0.2704654335975647
[10/24] Train loss=0.30721166729927063
[15/24] Train loss=0.2740898132324219
[20/24] Train loss=0.2533298134803772
Test set avg_accuracy=84.86% avg_sensitivity=65.45%, avg_specificity=92.21% avg_auc=90.28%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.269764 Test loss=0.340915 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.24625572562217712
[5/24] Train loss=0.2722042202949524
[10/24] Train loss=0.3055747151374817
[15/24] Train loss=0.2699664533138275
[20/24] Train loss=0.2521321773529053
Test set avg_accuracy=84.86% avg_sensitivity=65.45%, avg_specificity=92.21% avg_auc=90.28%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.269388 Test loss=0.340912 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.24177218973636627
[5/24] Train loss=0.26919111609458923
[10/24] Train loss=0.3070482611656189
[15/24] Train loss=0.270929217338562
[20/24] Train loss=0.25181517004966736
Test set avg_accuracy=84.86% avg_sensitivity=65.45%, avg_specificity=92.21% avg_auc=90.28%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.269542 Test loss=0.340909 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.24282608926296234
[5/24] Train loss=0.27444589138031006
[10/24] Train loss=0.3094680905342102
[15/24] Train loss=0.2708152234554291
[20/24] Train loss=0.25572678446769714
Test set avg_accuracy=84.86% avg_sensitivity=65.45%, avg_specificity=92.21% avg_auc=90.28%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.270001 Test loss=0.340908 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.24117855727672577
[5/24] Train loss=0.2717811167240143
[10/24] Train loss=0.3081848621368408
[15/24] Train loss=0.2710656523704529
[20/24] Train loss=0.2516312003135681
Test set avg_accuracy=84.86% avg_sensitivity=65.45%, avg_specificity=92.21% avg_auc=90.28%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.269656 Test loss=0.340909 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.24462153017520905
[5/24] Train loss=0.2689441740512848
[10/24] Train loss=0.3097485303878784
[15/24] Train loss=0.27216023206710815
[20/24] Train loss=0.25124335289001465
Test set avg_accuracy=84.86% avg_sensitivity=65.45%, avg_specificity=92.21% avg_auc=90.28%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.269956 Test loss=0.340909 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=84.88% sen=62.65%, spe=93.30%, auc=90.51%!
Fold[3] Avg_jsc=0.57%(±0.2703932804175086)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=1.0085371732711792
[5/24] Train loss=0.914625346660614
[10/24] Train loss=0.8371331095695496
[15/24] Train loss=0.7787699103355408
[20/24] Train loss=0.706088662147522
Test set avg_accuracy=66.26% avg_sensitivity=18.74%, avg_specificity=83.01% avg_auc=51.92%
Best model saved!! Metric=51.92444277949069!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.827813 Test loss=0.644180 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6866528391838074
[5/24] Train loss=0.6311441659927368
[10/24] Train loss=0.6528908014297485
[15/24] Train loss=0.641418993473053
[20/24] Train loss=0.6338731050491333
Test set avg_accuracy=73.45% avg_sensitivity=1.75%, avg_specificity=98.71% avg_auc=52.81%
Best model saved!! Metric=52.806463470149055!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.639222 Test loss=0.593805 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6297246813774109
[5/24] Train loss=0.5873762369155884
[10/24] Train loss=0.642427384853363
[15/24] Train loss=0.6362776756286621
[20/24] Train loss=0.6326596736907959
Test set avg_accuracy=73.62% avg_sensitivity=0.85%, avg_specificity=99.26% avg_auc=53.98%
Best model saved!! Metric=53.98146586154009!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.615216 Test loss=0.591868 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6127308011054993
[5/24] Train loss=0.5795122981071472
[10/24] Train loss=0.6357132792472839
[15/24] Train loss=0.6197942495346069
[20/24] Train loss=0.6197987198829651
Test set avg_accuracy=73.55% avg_sensitivity=0.95%, avg_specificity=99.14% avg_auc=55.06%
Best model saved!! Metric=55.056628227530894!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.605877 Test loss=0.578550 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6008382439613342
[5/24] Train loss=0.577002227306366
[10/24] Train loss=0.6299160122871399
[15/24] Train loss=0.6118040680885315
[20/24] Train loss=0.6000324487686157
Test set avg_accuracy=73.62% avg_sensitivity=1.15%, avg_specificity=99.15% avg_auc=56.18%
Best model saved!! Metric=56.18050281075345!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.598075 Test loss=0.572583 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6023032665252686
[5/24] Train loss=0.5700374841690063
[10/24] Train loss=0.6255449056625366
[15/24] Train loss=0.6022828817367554
[20/24] Train loss=0.5995115041732788
Test set avg_accuracy=73.76% avg_sensitivity=1.10%, avg_specificity=99.37% avg_auc=57.50%
Best model saved!! Metric=57.499446262077626!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.592713 Test loss=0.568840 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5928069353103638
[5/24] Train loss=0.5667206048965454
[10/24] Train loss=0.6200404167175293
[15/24] Train loss=0.5960422158241272
[20/24] Train loss=0.5928950309753418
Test set avg_accuracy=73.88% avg_sensitivity=1.25%, avg_specificity=99.47% avg_auc=58.76%
Best model saved!! Metric=58.76021753166383!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.586650 Test loss=0.564904 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5892228484153748
[5/24] Train loss=0.5592315793037415
[10/24] Train loss=0.6105402708053589
[15/24] Train loss=0.5939251780509949
[20/24] Train loss=0.5910159945487976
Test set avg_accuracy=74.01% avg_sensitivity=1.45%, avg_specificity=99.58% avg_auc=59.94%
Best model saved!! Metric=59.94368109130854!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.582282 Test loss=0.561543 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5813795924186707
[5/24] Train loss=0.5645774006843567
[10/24] Train loss=0.6078296899795532
[15/24] Train loss=0.5902616381645203
[20/24] Train loss=0.5875905752182007
Test set avg_accuracy=73.95% avg_sensitivity=1.55%, avg_specificity=99.45% avg_auc=61.29%
Best model saved!! Metric=61.29474002213544!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.577379 Test loss=0.557836 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5823153257369995
[5/24] Train loss=0.555439293384552
[10/24] Train loss=0.5937409996986389
[15/24] Train loss=0.58604496717453
[20/24] Train loss=0.5823531746864319
Test set avg_accuracy=73.96% avg_sensitivity=1.85%, avg_specificity=99.37% avg_auc=62.61%
Best model saved!! Metric=62.61235907842874!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.573259 Test loss=0.554332 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5742204189300537
[5/24] Train loss=0.5489193201065063
[10/24] Train loss=0.6008056998252869
[15/24] Train loss=0.5757320523262024
[20/24] Train loss=0.5655626654624939
Test set avg_accuracy=73.87% avg_sensitivity=2.05%, avg_specificity=99.17% avg_auc=64.15%
Best model saved!! Metric=64.15468969160428!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.567616 Test loss=0.550112 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5677950382232666
[5/24] Train loss=0.5432206392288208
[10/24] Train loss=0.596966564655304
[15/24] Train loss=0.5704767107963562
[20/24] Train loss=0.5608023405075073
Test set avg_accuracy=74.01% avg_sensitivity=3.00%, avg_specificity=99.03% avg_auc=65.57%
Best model saved!! Metric=65.57239077238982!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.562338 Test loss=0.545632 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5617521405220032
[5/24] Train loss=0.5366520285606384
[10/24] Train loss=0.5905851125717163
[15/24] Train loss=0.5608833432197571
[20/24] Train loss=0.5565146207809448
Test set avg_accuracy=74.05% avg_sensitivity=3.85%, avg_specificity=98.78% avg_auc=67.19%
Best model saved!! Metric=67.19052430115282!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.555566 Test loss=0.540188 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5531858205795288
[5/24] Train loss=0.5290140509605408
[10/24] Train loss=0.5836848020553589
[15/24] Train loss=0.553031861782074
[20/24] Train loss=0.545894205570221
Test set avg_accuracy=74.00% avg_sensitivity=5.40%, avg_specificity=98.17% avg_auc=68.82%
Best model saved!! Metric=68.82378937314228!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.548601 Test loss=0.533304 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5449360609054565
[5/24] Train loss=0.5257114768028259
[10/24] Train loss=0.5725917220115662
[15/24] Train loss=0.5460441708564758
[20/24] Train loss=0.5308578014373779
Test set avg_accuracy=74.44% avg_sensitivity=8.20%, avg_specificity=97.78% avg_auc=70.44%
Best model saved!! Metric=70.44485329091046!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.539575 Test loss=0.525190 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5295804142951965
[5/24] Train loss=0.5130841732025146
[10/24] Train loss=0.5623100996017456
[15/24] Train loss=0.5292470455169678
[20/24] Train loss=0.5195519328117371
Test set avg_accuracy=74.75% avg_sensitivity=11.94%, avg_specificity=96.88% avg_auc=72.39%
Best model saved!! Metric=72.39403277758902!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.527962 Test loss=0.513826 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5173530578613281
[5/24] Train loss=0.5098526477813721
[10/24] Train loss=0.5474212765693665
[15/24] Train loss=0.5191567540168762
[20/24] Train loss=0.49961256980895996
Test set avg_accuracy=75.29% avg_sensitivity=20.99%, avg_specificity=94.42% avg_auc=74.80%
Best model saved!! Metric=74.80218334220811!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.515943 Test loss=0.498758 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5017315745353699
[5/24] Train loss=0.49884769320487976
[10/24] Train loss=0.5415616631507874
[15/24] Train loss=0.5129277110099792
[20/24] Train loss=0.4792737066745758
Test set avg_accuracy=75.68% avg_sensitivity=21.24%, avg_specificity=94.86% avg_auc=77.43%
Best model saved!! Metric=77.43108107858379!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.500371 Test loss=0.482760 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4761347770690918
[5/24] Train loss=0.48076552152633667
[10/24] Train loss=0.5127319693565369
[15/24] Train loss=0.48706337809562683
[20/24] Train loss=0.4574628472328186
Test set avg_accuracy=76.25% avg_sensitivity=23.59%, avg_specificity=94.81% avg_auc=79.33%
Best model saved!! Metric=79.3328023433256!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.482563 Test loss=0.470985 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4675150215625763
[5/24] Train loss=0.4678764045238495
[10/24] Train loss=0.5078819394111633
[15/24] Train loss=0.46553581953048706
[20/24] Train loss=0.43957358598709106
Test set avg_accuracy=76.89% avg_sensitivity=32.23%, avg_specificity=92.62% avg_auc=80.87%
Best model saved!! Metric=80.87434535945621!!
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.464325 Test loss=0.454652 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.45256394147872925
[5/24] Train loss=0.44799432158470154
[10/24] Train loss=0.4918896555900574
[15/24] Train loss=0.4490756094455719
[20/24] Train loss=0.4267429709434509
Test set avg_accuracy=77.24% avg_sensitivity=30.73%, avg_specificity=93.63% avg_auc=81.92%
Best model saved!! Metric=81.91750224553158!!
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.451357 Test loss=0.449177 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.44207364320755005
[5/24] Train loss=0.4280592203140259
[10/24] Train loss=0.48134610056877136
[15/24] Train loss=0.4384540915489197
[20/24] Train loss=0.41262388229370117
Test set avg_accuracy=77.53% avg_sensitivity=30.73%, avg_specificity=94.01% avg_auc=82.68%
Best model saved!! Metric=82.67776219303624!!
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.442387 Test loss=0.444564 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.43438035249710083
[5/24] Train loss=0.4175167381763458
[10/24] Train loss=0.4714801013469696
[15/24] Train loss=0.43194684386253357
[20/24] Train loss=0.4088635742664337
Test set avg_accuracy=77.92% avg_sensitivity=31.63%, avg_specificity=94.22% avg_auc=83.23%
Best model saved!! Metric=83.2317949143055!!
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.435033 Test loss=0.440727 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.428952693939209
[5/24] Train loss=0.4072940945625305
[10/24] Train loss=0.4673779308795929
[15/24] Train loss=0.4237816035747528
[20/24] Train loss=0.3977378308773041
Test set avg_accuracy=78.11% avg_sensitivity=32.33%, avg_specificity=94.24% avg_auc=83.73%
Best model saved!! Metric=83.73457222788501!!
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.429338 Test loss=0.436307 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.41873791813850403
[5/24] Train loss=0.405258446931839
[10/24] Train loss=0.45938578248023987
[15/24] Train loss=0.4184521436691284
[20/24] Train loss=0.3910260796546936
Test set avg_accuracy=78.41% avg_sensitivity=32.53%, avg_specificity=94.58% avg_auc=84.24%
Best model saved!! Metric=84.24328511919424!!
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.423419 Test loss=0.433652 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.4207056164741516
[5/24] Train loss=0.39757040143013
[10/24] Train loss=0.4566485285758972
[15/24] Train loss=0.41489464044570923
[20/24] Train loss=0.384789377450943
Test set avg_accuracy=78.70% avg_sensitivity=32.48%, avg_specificity=94.98% avg_auc=84.61%
Best model saved!! Metric=84.60671935558896!!
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.419713 Test loss=0.431896 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.42058292031288147
[5/24] Train loss=0.39739668369293213
[10/24] Train loss=0.4496102035045624
[15/24] Train loss=0.4032507836818695
[20/24] Train loss=0.3803616464138031
Test set avg_accuracy=79.17% avg_sensitivity=35.28%, avg_specificity=94.63% avg_auc=85.03%
Best model saved!! Metric=85.02677697953276!!
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.415015 Test loss=0.424509 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.4108577370643616
[5/24] Train loss=0.3904642164707184
[10/24] Train loss=0.4465472400188446
[15/24] Train loss=0.40737485885620117
[20/24] Train loss=0.3711377680301666
Test set avg_accuracy=79.35% avg_sensitivity=33.98%, avg_specificity=95.33% avg_auc=85.39%
Best model saved!! Metric=85.38870202159!!
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.410048 Test loss=0.425194 Current lr=[0.000210185142098938]

[0/24] Train loss=0.4108641743659973
[5/24] Train loss=0.38565006852149963
[10/24] Train loss=0.4454140067100525
[15/24] Train loss=0.39774858951568604
[20/24] Train loss=0.36353132128715515
Test set avg_accuracy=79.30% avg_sensitivity=34.03%, avg_specificity=95.25% avg_auc=85.70%
Best model saved!! Metric=85.69597926868579!!
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.406166 Test loss=0.421605 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.4092809557914734
[5/24] Train loss=0.37525132298469543
[10/24] Train loss=0.43545687198638916
[15/24] Train loss=0.392555832862854
[20/24] Train loss=0.3653210699558258
Test set avg_accuracy=79.56% avg_sensitivity=34.93%, avg_specificity=95.28% avg_auc=86.03%
Best model saved!! Metric=86.02941881762061!!
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.401449 Test loss=0.417972 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.4063631594181061
[5/24] Train loss=0.3786589205265045
[10/24] Train loss=0.4343450665473938
[15/24] Train loss=0.3930824398994446
[20/24] Train loss=0.36516880989074707
Test set avg_accuracy=79.77% avg_sensitivity=35.63%, avg_specificity=95.32% avg_auc=86.31%
Best model saved!! Metric=86.31027856383483!!
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.399006 Test loss=0.414171 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.39899465441703796
[5/24] Train loss=0.37249869108200073
[10/24] Train loss=0.4301553964614868
[15/24] Train loss=0.38753369450569153
[20/24] Train loss=0.3636244535446167
Test set avg_accuracy=80.48% avg_sensitivity=39.08%, avg_specificity=95.07% avg_auc=86.56%
Best model saved!! Metric=86.55811203396364!!
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.393938 Test loss=0.406306 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3895886242389679
[5/24] Train loss=0.36813217401504517
[10/24] Train loss=0.42369544506073
[15/24] Train loss=0.3809061646461487
[20/24] Train loss=0.3588210940361023
Test set avg_accuracy=80.78% avg_sensitivity=42.73%, avg_specificity=94.19% avg_auc=86.85%
Best model saved!! Metric=86.84873974352847!!
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.387783 Test loss=0.397615 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.380709171295166
[5/24] Train loss=0.3630066514015198
[10/24] Train loss=0.4197971820831299
[15/24] Train loss=0.3793809413909912
[20/24] Train loss=0.35548102855682373
Test set avg_accuracy=80.76% avg_sensitivity=42.23%, avg_specificity=94.33% avg_auc=87.04%
Best model saved!! Metric=87.03703263705354!!
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.383922 Test loss=0.396422 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.37752559781074524
[5/24] Train loss=0.35825860500335693
[10/24] Train loss=0.41994911432266235
[15/24] Train loss=0.38545775413513184
[20/24] Train loss=0.3590923547744751
Test set avg_accuracy=81.04% avg_sensitivity=43.98%, avg_specificity=94.10% avg_auc=87.27%
Best model saved!! Metric=87.26835296913966!!
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.381092 Test loss=0.391603 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3721459209918976
[5/24] Train loss=0.35525140166282654
[10/24] Train loss=0.41543376445770264
[15/24] Train loss=0.38404491543769836
[20/24] Train loss=0.36344924569129944
Test set avg_accuracy=80.96% avg_sensitivity=41.43%, avg_specificity=94.89% avg_auc=87.41%
Best model saved!! Metric=87.41268122762003!!
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.377144 Test loss=0.394743 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.374808132648468
[5/24] Train loss=0.36073851585388184
[10/24] Train loss=0.40904501080513
[15/24] Train loss=0.3747260868549347
[20/24] Train loss=0.349770724773407
Test set avg_accuracy=81.39% avg_sensitivity=45.43%, avg_specificity=94.07% avg_auc=87.58%
Best model saved!! Metric=87.57537941717644!!
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.374018 Test loss=0.386674 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3641098141670227
[5/24] Train loss=0.3478293716907501
[10/24] Train loss=0.40734344720840454
[15/24] Train loss=0.3788188397884369
[20/24] Train loss=0.3611716628074646
Test set avg_accuracy=81.24% avg_sensitivity=43.68%, avg_specificity=94.47% avg_auc=87.59%
Best model saved!! Metric=87.59060336005619!!
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.370165 Test loss=0.389725 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.36682093143463135
[5/24] Train loss=0.3528180420398712
[10/24] Train loss=0.39940690994262695
[15/24] Train loss=0.36881062388420105
[20/24] Train loss=0.3521224558353424
Test set avg_accuracy=81.45% avg_sensitivity=45.18%, avg_specificity=94.22% avg_auc=87.69%
Best model saved!! Metric=87.69315817527054!!
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.367613 Test loss=0.386997 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.36050674319267273
[5/24] Train loss=0.3502495586872101
[10/24] Train loss=0.39576029777526855
[15/24] Train loss=0.3695434629917145
[20/24] Train loss=0.3532094359397888
Test set avg_accuracy=81.29% avg_sensitivity=44.28%, avg_specificity=94.33% avg_auc=87.74%
Best model saved!! Metric=87.73785320757476!!
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.363801 Test loss=0.387894 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3623894453048706
[5/24] Train loss=0.3456435799598694
[10/24] Train loss=0.3915434181690216
[15/24] Train loss=0.3595581352710724
[20/24] Train loss=0.34701308608055115
Test set avg_accuracy=81.46% avg_sensitivity=44.83%, avg_specificity=94.37% avg_auc=87.82%
Best model saved!! Metric=87.82169049301726!!
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.362247 Test loss=0.386098 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.35667547583580017
[5/24] Train loss=0.34786632657051086
[10/24] Train loss=0.38917219638824463
[15/24] Train loss=0.3624288737773895
[20/24] Train loss=0.35165488719940186
Test set avg_accuracy=81.47% avg_sensitivity=45.83%, avg_specificity=94.03% avg_auc=87.86%
Best model saved!! Metric=87.86144874384432!!
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.358927 Test loss=0.383904 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.35377994179725647
[5/24] Train loss=0.3391709625720978
[10/24] Train loss=0.3831310570240021
[15/24] Train loss=0.35639891028404236
[20/24] Train loss=0.35205140709877014
Test set avg_accuracy=81.58% avg_sensitivity=45.83%, avg_specificity=94.17% avg_auc=87.88%
Best model saved!! Metric=87.88173266773902!!
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.356757 Test loss=0.384199 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3471730649471283
[5/24] Train loss=0.3378019630908966
[10/24] Train loss=0.3814029395580292
[15/24] Train loss=0.35392987728118896
[20/24] Train loss=0.34771424531936646
Test set avg_accuracy=81.71% avg_sensitivity=47.38%, avg_specificity=93.80% avg_auc=87.98%
Best model saved!! Metric=87.9824042900191!!
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.352860 Test loss=0.381789 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3475123345851898
[5/24] Train loss=0.33653584122657776
[10/24] Train loss=0.37720954418182373
[15/24] Train loss=0.35514554381370544
[20/24] Train loss=0.3481478691101074
Test set avg_accuracy=81.95% avg_sensitivity=48.98%, avg_specificity=93.57% avg_auc=87.99%
Best model saved!! Metric=87.99094025799215!!
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.351133 Test loss=0.380481 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3462696075439453
[5/24] Train loss=0.32832908630371094
[10/24] Train loss=0.37498199939727783
[15/24] Train loss=0.3470803201198578
[20/24] Train loss=0.339813768863678
Test set avg_accuracy=82.11% avg_sensitivity=50.07%, avg_specificity=93.40% avg_auc=88.10%
Best model saved!! Metric=88.10194304150971!!
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.348447 Test loss=0.378597 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.33496221899986267
[5/24] Train loss=0.32583004236221313
[10/24] Train loss=0.3714021146297455
[15/24] Train loss=0.343138724565506
[20/24] Train loss=0.33262962102890015
Test set avg_accuracy=81.94% avg_sensitivity=48.48%, avg_specificity=93.73% avg_auc=88.16%
Best model saved!! Metric=88.15719363420949!!
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.344342 Test loss=0.381153 Current lr=[0.000299720220882401]

[0/24] Train loss=0.34072816371917725
[5/24] Train loss=0.33157798647880554
[10/24] Train loss=0.3640872538089752
[15/24] Train loss=0.345753937959671
[20/24] Train loss=0.3373076021671295
Test set avg_accuracy=82.51% avg_sensitivity=52.72%, avg_specificity=93.01% avg_auc=88.27%
Best model saved!! Metric=88.2651032293327!!
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.344328 Test loss=0.374664 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.331176221370697
[5/24] Train loss=0.32040077447891235
[10/24] Train loss=0.36713945865631104
[15/24] Train loss=0.33705776929855347
[20/24] Train loss=0.32489001750946045
Test set avg_accuracy=82.37% avg_sensitivity=50.77%, avg_specificity=93.50% avg_auc=88.26%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.340669 Test loss=0.378158 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3352314531803131
[5/24] Train loss=0.3287539780139923
[10/24] Train loss=0.36396220326423645
[15/24] Train loss=0.3354877233505249
[20/24] Train loss=0.32617390155792236
Test set avg_accuracy=82.08% avg_sensitivity=48.83%, avg_specificity=93.80% avg_auc=88.34%
Best model saved!! Metric=88.34145174287305!!
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.339005 Test loss=0.378993 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.332657128572464
[5/24] Train loss=0.32778289914131165
[10/24] Train loss=0.36316123604774475
[15/24] Train loss=0.3329090178012848
[20/24] Train loss=0.32193487882614136
Test set avg_accuracy=82.55% avg_sensitivity=52.27%, avg_specificity=93.22% avg_auc=88.42%
Best model saved!! Metric=88.42364343448985!!
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.337779 Test loss=0.374884 Current lr=[0.000297555943323901]

[0/24] Train loss=0.33066949248313904
[5/24] Train loss=0.32488003373146057
[10/24] Train loss=0.35907506942749023
[15/24] Train loss=0.3334149122238159
[20/24] Train loss=0.3224935829639435
Test set avg_accuracy=82.28% avg_sensitivity=49.88%, avg_specificity=93.70% avg_auc=88.47%
Best model saved!! Metric=88.47041525900195!!
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.335632 Test loss=0.376753 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3312491774559021
[5/24] Train loss=0.3243181109428406
[10/24] Train loss=0.3530806601047516
[15/24] Train loss=0.3239591419696808
[20/24] Train loss=0.3212122619152069
Test set avg_accuracy=82.64% avg_sensitivity=53.12%, avg_specificity=93.04% avg_auc=88.52%
Best model saved!! Metric=88.51714308367916!!
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.333087 Test loss=0.373323 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3223884403705597
[5/24] Train loss=0.3150593340396881
[10/24] Train loss=0.35164472460746765
[15/24] Train loss=0.32808801531791687
[20/24] Train loss=0.31692254543304443
Test set avg_accuracy=82.19% avg_sensitivity=48.98%, avg_specificity=93.89% avg_auc=88.49%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.330653 Test loss=0.378947 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3324087858200073
[5/24] Train loss=0.3173413872718811
[10/24] Train loss=0.3525959253311157
[15/24] Train loss=0.3301207721233368
[20/24] Train loss=0.3112351894378662
Test set avg_accuracy=82.36% avg_sensitivity=50.47%, avg_specificity=93.59% avg_auc=88.55%
Best model saved!! Metric=88.54952696217484!!
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.330271 Test loss=0.376983 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3239995241165161
[5/24] Train loss=0.3152408003807068
[10/24] Train loss=0.34915781021118164
[15/24] Train loss=0.322113573551178
[20/24] Train loss=0.3115626275539398
Test set avg_accuracy=82.08% avg_sensitivity=47.03%, avg_specificity=94.44% avg_auc=88.53%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.328513 Test loss=0.382549 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.32840651273727417
[5/24] Train loss=0.31534361839294434
[10/24] Train loss=0.34396427869796753
[15/24] Train loss=0.32319530844688416
[20/24] Train loss=0.3118208050727844
Test set avg_accuracy=82.01% avg_sensitivity=46.13%, avg_specificity=94.65% avg_auc=88.52%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.328980 Test loss=0.384835 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3266166150569916
[5/24] Train loss=0.31014496088027954
[10/24] Train loss=0.3499816060066223
[15/24] Train loss=0.3209947347640991
[20/24] Train loss=0.31166860461235046
Test set avg_accuracy=82.21% avg_sensitivity=47.18%, avg_specificity=94.56% avg_auc=88.56%
Best model saved!! Metric=88.5597613237755!!
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.331371 Test loss=0.382785 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3294035494327545
[5/24] Train loss=0.29277199506759644
[10/24] Train loss=0.36172205209732056
[15/24] Train loss=0.3208334147930145
[20/24] Train loss=0.3295554518699646
Test set avg_accuracy=82.88% avg_sensitivity=58.32%, avg_specificity=91.53% avg_auc=88.61%
Best model saved!! Metric=88.60706994627357!!
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.332160 Test loss=0.368648 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.31147176027297974
[5/24] Train loss=0.3009871244430542
[10/24] Train loss=0.344515323638916
[15/24] Train loss=0.3219608962535858
[20/24] Train loss=0.32411402463912964
Test set avg_accuracy=83.07% avg_sensitivity=60.82%, avg_specificity=90.91% avg_auc=88.66%
Best model saved!! Metric=88.66379453344291!!
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.327296 Test loss=0.367503 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3095853328704834
[5/24] Train loss=0.29214543104171753
[10/24] Train loss=0.3427835702896118
[15/24] Train loss=0.32083818316459656
[20/24] Train loss=0.320661336183548
Test set avg_accuracy=82.85% avg_sensitivity=60.02%, avg_specificity=90.90% avg_auc=88.65%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.322604 Test loss=0.367922 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.30443817377090454
[5/24] Train loss=0.29341402649879456
[10/24] Train loss=0.343919575214386
[15/24] Train loss=0.32006099820137024
[20/24] Train loss=0.3226088285446167
Test set avg_accuracy=82.99% avg_sensitivity=60.82%, avg_specificity=90.81% avg_auc=88.68%
Best model saved!! Metric=88.68070806998333!!
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.321483 Test loss=0.367729 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.30078405141830444
[5/24] Train loss=0.2917470335960388
[10/24] Train loss=0.34010323882102966
[15/24] Train loss=0.3228406310081482
[20/24] Train loss=0.32478058338165283
Test set avg_accuracy=82.97% avg_sensitivity=59.87%, avg_specificity=91.11% avg_auc=88.70%
Best model saved!! Metric=88.70138799239227!!
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.320075 Test loss=0.367394 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3022187352180481
[5/24] Train loss=0.2903679311275482
[10/24] Train loss=0.33505403995513916
[15/24] Train loss=0.31460338830947876
[20/24] Train loss=0.3132391571998596
Test set avg_accuracy=82.99% avg_sensitivity=58.82%, avg_specificity=91.51% avg_auc=88.68%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.317168 Test loss=0.368350 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3014644682407379
[5/24] Train loss=0.289141982793808
[10/24] Train loss=0.3325299024581909
[15/24] Train loss=0.3148125410079956
[20/24] Train loss=0.31455206871032715
Test set avg_accuracy=82.96% avg_sensitivity=57.87%, avg_specificity=91.79% avg_auc=88.68%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.315636 Test loss=0.369426 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3045256435871124
[5/24] Train loss=0.29326337575912476
[10/24] Train loss=0.3280288875102997
[15/24] Train loss=0.31292563676834106
[20/24] Train loss=0.31990134716033936
Test set avg_accuracy=83.01% avg_sensitivity=58.67%, avg_specificity=91.58% avg_auc=88.64%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.315951 Test loss=0.369863 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.29931414127349854
[5/24] Train loss=0.29178309440612793
[10/24] Train loss=0.330470472574234
[15/24] Train loss=0.31120115518569946
[20/24] Train loss=0.32076722383499146
Test set avg_accuracy=83.14% avg_sensitivity=61.47%, avg_specificity=90.77% avg_auc=88.68%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.315542 Test loss=0.368587 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.29743489623069763
[5/24] Train loss=0.2906690239906311
[10/24] Train loss=0.32557404041290283
[15/24] Train loss=0.3198431134223938
[20/24] Train loss=0.31835129857063293
Test set avg_accuracy=83.15% avg_sensitivity=64.22%, avg_specificity=89.82% avg_auc=88.62%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.313754 Test loss=0.370737 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.299407035112381
[5/24] Train loss=0.29056429862976074
[10/24] Train loss=0.3254522681236267
[15/24] Train loss=0.3091657757759094
[20/24] Train loss=0.31423836946487427
Test set avg_accuracy=83.12% avg_sensitivity=64.37%, avg_specificity=89.73% avg_auc=88.66%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.312075 Test loss=0.370875 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.296527624130249
[5/24] Train loss=0.28782567381858826
[10/24] Train loss=0.3247796297073364
[15/24] Train loss=0.3115036189556122
[20/24] Train loss=0.31004786491394043
Test set avg_accuracy=83.26% avg_sensitivity=62.07%, avg_specificity=90.72% avg_auc=88.72%
Best model saved!! Metric=88.71696393395132!!
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.311027 Test loss=0.368468 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.2982455790042877
[5/24] Train loss=0.28932830691337585
[10/24] Train loss=0.32125937938690186
[15/24] Train loss=0.3096509873867035
[20/24] Train loss=0.3148050606250763
Test set avg_accuracy=83.12% avg_sensitivity=61.57%, avg_specificity=90.72% avg_auc=88.68%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.309610 Test loss=0.369279 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3030288517475128
[5/24] Train loss=0.2852301299571991
[10/24] Train loss=0.3227190375328064
[15/24] Train loss=0.3134530484676361
[20/24] Train loss=0.31090247631073
Test set avg_accuracy=83.05% avg_sensitivity=63.42%, avg_specificity=89.96% avg_auc=88.62%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.310400 Test loss=0.371503 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.29976293444633484
[5/24] Train loss=0.2862655222415924
[10/24] Train loss=0.3229012191295624
[15/24] Train loss=0.3079082667827606
[20/24] Train loss=0.3046087324619293
Test set avg_accuracy=83.07% avg_sensitivity=64.32%, avg_specificity=89.68% avg_auc=88.62%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.308401 Test loss=0.372448 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2953779399394989
[5/24] Train loss=0.28755608201026917
[10/24] Train loss=0.31519395112991333
[15/24] Train loss=0.30797940492630005
[20/24] Train loss=0.30583256483078003
Test set avg_accuracy=83.02% avg_sensitivity=62.77%, avg_specificity=90.16% avg_auc=88.63%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.306534 Test loss=0.371483 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.2938128709793091
[5/24] Train loss=0.27966228127479553
[10/24] Train loss=0.3198684751987457
[15/24] Train loss=0.30654844641685486
[20/24] Train loss=0.3048804700374603
Test set avg_accuracy=82.94% avg_sensitivity=65.12%, avg_specificity=89.22% avg_auc=88.60%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.304234 Test loss=0.374143 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2926994562149048
[5/24] Train loss=0.28343603014945984
[10/24] Train loss=0.3203396499156952
[15/24] Train loss=0.309268593788147
[20/24] Train loss=0.2985404431819916
Test set avg_accuracy=82.99% avg_sensitivity=62.97%, avg_specificity=90.05% avg_auc=88.64%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.304899 Test loss=0.372342 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.292938768863678
[5/24] Train loss=0.2819939851760864
[10/24] Train loss=0.3158152401447296
[15/24] Train loss=0.3026464581489563
[20/24] Train loss=0.3040192425251007
Test set avg_accuracy=82.99% avg_sensitivity=62.17%, avg_specificity=90.33% avg_auc=88.54%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.303058 Test loss=0.373360 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2885682284832001
[5/24] Train loss=0.28794771432876587
[10/24] Train loss=0.3144198954105377
[15/24] Train loss=0.3000745475292206
[20/24] Train loss=0.2993289530277252
Test set avg_accuracy=83.02% avg_sensitivity=63.07%, avg_specificity=90.05% avg_auc=88.57%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.304027 Test loss=0.373536 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.29328444600105286
[5/24] Train loss=0.2842260003089905
[10/24] Train loss=0.3139022886753082
[15/24] Train loss=0.30583974719047546
[20/24] Train loss=0.3021768033504486
Test set avg_accuracy=83.06% avg_sensitivity=63.97%, avg_specificity=89.79% avg_auc=88.62%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.302572 Test loss=0.373365 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2878175377845764
[5/24] Train loss=0.28975608944892883
[10/24] Train loss=0.3183726668357849
[15/24] Train loss=0.304058700799942
[20/24] Train loss=0.2982281446456909
Test set avg_accuracy=83.16% avg_sensitivity=63.57%, avg_specificity=90.07% avg_auc=88.64%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.302528 Test loss=0.373096 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2870939075946808
[5/24] Train loss=0.28277647495269775
[10/24] Train loss=0.3136594891548157
[15/24] Train loss=0.29952675104141235
[20/24] Train loss=0.2986968755722046
Test set avg_accuracy=83.11% avg_sensitivity=63.87%, avg_specificity=89.89% avg_auc=88.63%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.300780 Test loss=0.373856 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2914223372936249
[5/24] Train loss=0.2775197923183441
[10/24] Train loss=0.3142373561859131
[15/24] Train loss=0.29815733432769775
[20/24] Train loss=0.30127376317977905
Test set avg_accuracy=83.01% avg_sensitivity=63.77%, avg_specificity=89.79% avg_auc=88.67%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.300865 Test loss=0.373691 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2957766652107239
[5/24] Train loss=0.28226396441459656
[10/24] Train loss=0.3188529312610626
[15/24] Train loss=0.29733583331108093
[20/24] Train loss=0.29503539204597473
Test set avg_accuracy=83.10% avg_sensitivity=63.22%, avg_specificity=90.10% avg_auc=88.69%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.300717 Test loss=0.372412 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.291350781917572
[5/24] Train loss=0.27976858615875244
[10/24] Train loss=0.314287394285202
[15/24] Train loss=0.29927000403404236
[20/24] Train loss=0.29081428050994873
Test set avg_accuracy=83.02% avg_sensitivity=63.47%, avg_specificity=89.91% avg_auc=88.65%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.300010 Test loss=0.373809 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.29168760776519775
[5/24] Train loss=0.27539122104644775
[10/24] Train loss=0.32040053606033325
[15/24] Train loss=0.2962498962879181
[20/24] Train loss=0.29677411913871765
Test set avg_accuracy=82.99% avg_sensitivity=63.92%, avg_specificity=89.72% avg_auc=88.65%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.299546 Test loss=0.374268 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2909606695175171
[5/24] Train loss=0.27994126081466675
[10/24] Train loss=0.3138953149318695
[15/24] Train loss=0.29598572850227356
[20/24] Train loss=0.2964770495891571
Test set avg_accuracy=83.01% avg_sensitivity=65.67%, avg_specificity=89.12% avg_auc=88.69%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.300386 Test loss=0.374845 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2906866669654846
[5/24] Train loss=0.2808435559272766
[10/24] Train loss=0.3143383264541626
[15/24] Train loss=0.29272785782814026
[20/24] Train loss=0.2954663932323456
Test set avg_accuracy=82.97% avg_sensitivity=64.67%, avg_specificity=89.42% avg_auc=88.68%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.300036 Test loss=0.374977 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2907470762729645
[5/24] Train loss=0.27964314818382263
[10/24] Train loss=0.32156410813331604
[15/24] Train loss=0.2993963360786438
[20/24] Train loss=0.29749852418899536
Test set avg_accuracy=82.79% avg_sensitivity=67.87%, avg_specificity=88.04% avg_auc=88.68%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.302600 Test loss=0.377931 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.29082414507865906
[5/24] Train loss=0.277923583984375
[10/24] Train loss=0.32565996050834656
[15/24] Train loss=0.295279324054718
[20/24] Train loss=0.31584489345550537
Test set avg_accuracy=82.03% avg_sensitivity=74.26%, avg_specificity=84.77% avg_auc=88.62%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.304553 Test loss=0.395199 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2889012098312378
[5/24] Train loss=0.2906505763530731
[10/24] Train loss=0.30549171566963196
[15/24] Train loss=0.30114883184432983
[20/24] Train loss=0.33261045813560486
Test set avg_accuracy=81.65% avg_sensitivity=75.66%, avg_specificity=83.76% avg_auc=88.67%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.306879 Test loss=0.400156 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3028303384780884
[5/24] Train loss=0.3105635941028595
[10/24] Train loss=0.3221891224384308
[15/24] Train loss=0.2996468245983124
[20/24] Train loss=0.30214518308639526
Test set avg_accuracy=82.59% avg_sensitivity=69.82%, avg_specificity=87.09% avg_auc=88.79%
Best model saved!! Metric=88.78996406005484!!
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.303937 Test loss=0.378529 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2912256717681885
[5/24] Train loss=0.292095810174942
[10/24] Train loss=0.3188437521457672
[15/24] Train loss=0.2956916391849518
[20/24] Train loss=0.2983623445034027
Test set avg_accuracy=82.45% avg_sensitivity=70.81%, avg_specificity=86.55% avg_auc=88.73%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.300216 Test loss=0.383440 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.29316407442092896
[5/24] Train loss=0.2931690514087677
[10/24] Train loss=0.31250521540641785
[15/24] Train loss=0.29478079080581665
[20/24] Train loss=0.2984972894191742
Test set avg_accuracy=82.41% avg_sensitivity=70.26%, avg_specificity=86.69% avg_auc=88.70%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.298601 Test loss=0.382637 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.288447767496109
[5/24] Train loss=0.28771156072616577
[10/24] Train loss=0.31784310936927795
[15/24] Train loss=0.2942575216293335
[20/24] Train loss=0.3012906014919281
Test set avg_accuracy=82.42% avg_sensitivity=69.82%, avg_specificity=86.86% avg_auc=88.71%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.297859 Test loss=0.382534 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2915319502353668
[5/24] Train loss=0.28984734416007996
[10/24] Train loss=0.30753451585769653
[15/24] Train loss=0.2956053614616394
[20/24] Train loss=0.2981717884540558
Test set avg_accuracy=82.40% avg_sensitivity=68.52%, avg_specificity=87.29% avg_auc=88.71%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.297346 Test loss=0.380377 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2834421992301941
[5/24] Train loss=0.28620675206184387
[10/24] Train loss=0.3133600652217865
[15/24] Train loss=0.29673030972480774
[20/24] Train loss=0.29807594418525696
Test set avg_accuracy=82.36% avg_sensitivity=68.37%, avg_specificity=87.29% avg_auc=88.69%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.295916 Test loss=0.380908 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2886165380477905
[5/24] Train loss=0.28821709752082825
[10/24] Train loss=0.303999662399292
[15/24] Train loss=0.2921784818172455
[20/24] Train loss=0.2955971658229828
Test set avg_accuracy=82.25% avg_sensitivity=69.27%, avg_specificity=86.83% avg_auc=88.62%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.296054 Test loss=0.384188 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2919168770313263
[5/24] Train loss=0.28397032618522644
[10/24] Train loss=0.3042418658733368
[15/24] Train loss=0.2968748211860657
[20/24] Train loss=0.29953673481941223
Test set avg_accuracy=82.17% avg_sensitivity=69.32%, avg_specificity=86.71% avg_auc=88.61%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.294957 Test loss=0.384816 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.28699296712875366
[5/24] Train loss=0.28918737173080444
[10/24] Train loss=0.30878424644470215
[15/24] Train loss=0.29486554861068726
[20/24] Train loss=0.28947240114212036
Test set avg_accuracy=82.36% avg_sensitivity=67.02%, avg_specificity=87.76% avg_auc=88.66%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.295226 Test loss=0.378859 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.28681543469429016
[5/24] Train loss=0.2821570932865143
[10/24] Train loss=0.30985936522483826
[15/24] Train loss=0.2939932644367218
[20/24] Train loss=0.2935706675052643
Test set avg_accuracy=82.04% avg_sensitivity=68.92%, avg_specificity=86.67% avg_auc=88.60%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.293904 Test loss=0.384363 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.2869652807712555
[5/24] Train loss=0.2867501676082611
[10/24] Train loss=0.30819493532180786
[15/24] Train loss=0.2928445339202881
[20/24] Train loss=0.2975045144557953
Test set avg_accuracy=82.16% avg_sensitivity=68.57%, avg_specificity=86.95% avg_auc=88.62%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.293552 Test loss=0.382964 Current lr=[0.000134135431043539]

[0/24] Train loss=0.2861955165863037
[5/24] Train loss=0.28172725439071655
[10/24] Train loss=0.3096007704734802
[15/24] Train loss=0.2894652783870697
[20/24] Train loss=0.2990720272064209
Test set avg_accuracy=82.07% avg_sensitivity=69.62%, avg_specificity=86.46% avg_auc=88.63%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.292536 Test loss=0.385244 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.288472980260849
[5/24] Train loss=0.27924421429634094
[10/24] Train loss=0.30828598141670227
[15/24] Train loss=0.28895488381385803
[20/24] Train loss=0.2916959524154663
Test set avg_accuracy=82.19% avg_sensitivity=67.92%, avg_specificity=87.22% avg_auc=88.61%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.291493 Test loss=0.382663 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.28188356757164
[5/24] Train loss=0.2817833125591278
[10/24] Train loss=0.30545738339424133
[15/24] Train loss=0.29537448287010193
[20/24] Train loss=0.29199039936065674
Test set avg_accuracy=82.06% avg_sensitivity=68.77%, avg_specificity=86.74% avg_auc=88.58%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.292451 Test loss=0.385079 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.2827226221561432
[5/24] Train loss=0.2810533940792084
[10/24] Train loss=0.3046727776527405
[15/24] Train loss=0.28988128900527954
[20/24] Train loss=0.293033242225647
Test set avg_accuracy=82.03% avg_sensitivity=68.52%, avg_specificity=86.79% avg_auc=88.59%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.291062 Test loss=0.384982 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.290485143661499
[5/24] Train loss=0.2787051796913147
[10/24] Train loss=0.3069925904273987
[15/24] Train loss=0.2945556938648224
[20/24] Train loss=0.29075512290000916
Test set avg_accuracy=82.15% avg_sensitivity=68.57%, avg_specificity=86.93% avg_auc=88.59%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.292336 Test loss=0.384299 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.28376179933547974
[5/24] Train loss=0.2795836925506592
[10/24] Train loss=0.30032801628112793
[15/24] Train loss=0.2926737666130066
[20/24] Train loss=0.28746670484542847
Test set avg_accuracy=82.10% avg_sensitivity=68.72%, avg_specificity=86.81% avg_auc=88.58%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.290904 Test loss=0.385068 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.2877340614795685
[5/24] Train loss=0.2817475199699402
[10/24] Train loss=0.30928200483322144
[15/24] Train loss=0.2859666347503662
[20/24] Train loss=0.2937852442264557
Test set avg_accuracy=82.03% avg_sensitivity=69.17%, avg_specificity=86.56% avg_auc=88.60%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.291568 Test loss=0.386251 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.29219725728034973
[5/24] Train loss=0.28127190470695496
[10/24] Train loss=0.30601200461387634
[15/24] Train loss=0.286093145608902
[20/24] Train loss=0.2956332564353943
Test set avg_accuracy=81.81% avg_sensitivity=70.16%, avg_specificity=85.91% avg_auc=88.59%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.290927 Test loss=0.390642 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.2902725040912628
[5/24] Train loss=0.27973392605781555
[10/24] Train loss=0.3065343499183655
[15/24] Train loss=0.2881520390510559
[20/24] Train loss=0.2933207154273987
Test set avg_accuracy=81.84% avg_sensitivity=70.21%, avg_specificity=85.93% avg_auc=88.60%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.290640 Test loss=0.390284 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.2902163863182068
[5/24] Train loss=0.28218773007392883
[10/24] Train loss=0.29943689703941345
[15/24] Train loss=0.2868650555610657
[20/24] Train loss=0.29644662141799927
Test set avg_accuracy=81.81% avg_sensitivity=70.86%, avg_specificity=85.67% avg_auc=88.62%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.291445 Test loss=0.391786 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2944311201572418
[5/24] Train loss=0.2808036804199219
[10/24] Train loss=0.29990947246551514
[15/24] Train loss=0.28817394375801086
[20/24] Train loss=0.2979613244533539
Test set avg_accuracy=81.89% avg_sensitivity=69.72%, avg_specificity=86.18% avg_auc=88.62%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.291337 Test loss=0.388326 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.2885494530200958
[5/24] Train loss=0.27596625685691833
[10/24] Train loss=0.30234649777412415
[15/24] Train loss=0.28264471888542175
[20/24] Train loss=0.2947083115577698
Test set avg_accuracy=81.99% avg_sensitivity=68.92%, avg_specificity=86.60% avg_auc=88.63%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.290726 Test loss=0.384975 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.2863900363445282
[5/24] Train loss=0.27106329798698425
[10/24] Train loss=0.30202940106391907
[15/24] Train loss=0.2900499403476715
[20/24] Train loss=0.29788902401924133
Test set avg_accuracy=82.32% avg_sensitivity=66.67%, avg_specificity=87.83% avg_auc=88.60%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.290164 Test loss=0.379603 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.2910512685775757
[5/24] Train loss=0.2706370949745178
[10/24] Train loss=0.309323251247406
[15/24] Train loss=0.2847277522087097
[20/24] Train loss=0.29351475834846497
Test set avg_accuracy=82.29% avg_sensitivity=67.02%, avg_specificity=87.67% avg_auc=88.63%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.290438 Test loss=0.379762 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.28554850816726685
[5/24] Train loss=0.27197712659835815
[10/24] Train loss=0.2977215647697449
[15/24] Train loss=0.2921549379825592
[20/24] Train loss=0.28774377703666687
Test set avg_accuracy=82.36% avg_sensitivity=66.67%, avg_specificity=87.89% avg_auc=88.61%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.288633 Test loss=0.379277 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.2899712920188904
[5/24] Train loss=0.2718770503997803
[10/24] Train loss=0.30261626839637756
[15/24] Train loss=0.2856341600418091
[20/24] Train loss=0.2860904335975647
Test set avg_accuracy=82.36% avg_sensitivity=66.97%, avg_specificity=87.78% avg_auc=88.57%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.288239 Test loss=0.380767 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.28906697034835815
[5/24] Train loss=0.26855865120887756
[10/24] Train loss=0.3026617169380188
[15/24] Train loss=0.28778332471847534
[20/24] Train loss=0.29146188497543335
Test set avg_accuracy=82.34% avg_sensitivity=67.27%, avg_specificity=87.66% avg_auc=88.57%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.288743 Test loss=0.381583 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.28663039207458496
[5/24] Train loss=0.27448543906211853
[10/24] Train loss=0.30695655941963196
[15/24] Train loss=0.29040592908859253
[20/24] Train loss=0.29602566361427307
Test set avg_accuracy=82.29% avg_sensitivity=66.82%, avg_specificity=87.74% avg_auc=88.57%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.288323 Test loss=0.380787 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.2844257354736328
[5/24] Train loss=0.2680983245372772
[10/24] Train loss=0.30196699500083923
[15/24] Train loss=0.2858060300350189
[20/24] Train loss=0.2939217984676361
Test set avg_accuracy=82.34% avg_sensitivity=66.67%, avg_specificity=87.87% avg_auc=88.58%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.288283 Test loss=0.380229 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.28652575612068176
[5/24] Train loss=0.2721933126449585
[10/24] Train loss=0.3001655638217926
[15/24] Train loss=0.28682437539100647
[20/24] Train loss=0.2899334132671356
Test set avg_accuracy=82.32% avg_sensitivity=66.97%, avg_specificity=87.73% avg_auc=88.57%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.287782 Test loss=0.380878 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.28223440051078796
[5/24] Train loss=0.2729358673095703
[10/24] Train loss=0.2989055812358856
[15/24] Train loss=0.288783460855484
[20/24] Train loss=0.289228230714798
Test set avg_accuracy=82.33% avg_sensitivity=66.62%, avg_specificity=87.87% avg_auc=88.54%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.286921 Test loss=0.380580 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.2860592007637024
[5/24] Train loss=0.27143773436546326
[10/24] Train loss=0.30446258187294006
[15/24] Train loss=0.2870689630508423
[20/24] Train loss=0.29388898611068726
Test set avg_accuracy=82.32% avg_sensitivity=66.92%, avg_specificity=87.74% avg_auc=88.56%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.288597 Test loss=0.381110 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.2944161891937256
[5/24] Train loss=0.26699158549308777
[10/24] Train loss=0.29545462131500244
[15/24] Train loss=0.28494149446487427
[20/24] Train loss=0.28995585441589355
Test set avg_accuracy=82.27% avg_sensitivity=66.57%, avg_specificity=87.80% avg_auc=88.54%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.287215 Test loss=0.381181 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.28970959782600403
[5/24] Train loss=0.2709861993789673
[10/24] Train loss=0.30106762051582336
[15/24] Train loss=0.28631818294525146
[20/24] Train loss=0.28598085045814514
Test set avg_accuracy=82.29% avg_sensitivity=66.07%, avg_specificity=88.01% avg_auc=88.52%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.287560 Test loss=0.380287 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.2891741693019867
[5/24] Train loss=0.2688068151473999
[10/24] Train loss=0.30278584361076355
[15/24] Train loss=0.28068891167640686
[20/24] Train loss=0.2922384440898895
Test set avg_accuracy=82.46% avg_sensitivity=65.77%, avg_specificity=88.34% avg_auc=88.54%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.288079 Test loss=0.379202 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.2828625738620758
[5/24] Train loss=0.274715781211853
[10/24] Train loss=0.3005310297012329
[15/24] Train loss=0.28343474864959717
[20/24] Train loss=0.289183109998703
Test set avg_accuracy=82.49% avg_sensitivity=65.77%, avg_specificity=88.38% avg_auc=88.53%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.287636 Test loss=0.379151 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.28890883922576904
[5/24] Train loss=0.26998254656791687
[10/24] Train loss=0.30166757106781006
[15/24] Train loss=0.28472667932510376
[20/24] Train loss=0.2905269265174866
Test set avg_accuracy=82.55% avg_sensitivity=65.47%, avg_specificity=88.57% avg_auc=88.53%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.288501 Test loss=0.378694 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.2878471612930298
[5/24] Train loss=0.26928961277008057
[10/24] Train loss=0.3060687184333801
[15/24] Train loss=0.2847822904586792
[20/24] Train loss=0.28709518909454346
Test set avg_accuracy=82.66% avg_sensitivity=65.32%, avg_specificity=88.77% avg_auc=88.53%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.287167 Test loss=0.378294 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.2858005166053772
[5/24] Train loss=0.27296972274780273
[10/24] Train loss=0.3027316629886627
[15/24] Train loss=0.2834431529045105
[20/24] Train loss=0.28807368874549866
Test set avg_accuracy=82.51% avg_sensitivity=65.42%, avg_specificity=88.54% avg_auc=88.52%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.287863 Test loss=0.378516 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.2845868468284607
[5/24] Train loss=0.27565452456474304
[10/24] Train loss=0.3010007441043854
[15/24] Train loss=0.28478676080703735
[20/24] Train loss=0.28955692052841187
Test set avg_accuracy=82.63% avg_sensitivity=65.17%, avg_specificity=88.78% avg_auc=88.54%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.286459 Test loss=0.378007 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.28663983941078186
[5/24] Train loss=0.26982709765434265
[10/24] Train loss=0.3025878369808197
[15/24] Train loss=0.28600114583969116
[20/24] Train loss=0.28997015953063965
Test set avg_accuracy=82.43% avg_sensitivity=65.52%, avg_specificity=88.40% avg_auc=88.54%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.287925 Test loss=0.379005 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.28456512093544006
[5/24] Train loss=0.27315622568130493
[10/24] Train loss=0.3003320097923279
[15/24] Train loss=0.28320619463920593
[20/24] Train loss=0.2853410840034485
Test set avg_accuracy=82.30% avg_sensitivity=67.27%, avg_specificity=87.60% avg_auc=88.54%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.286961 Test loss=0.382051 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.28929561376571655
[5/24] Train loss=0.2692509889602661
[10/24] Train loss=0.2964470088481903
[15/24] Train loss=0.2852165102958679
[20/24] Train loss=0.2849430739879608
Test set avg_accuracy=82.20% avg_sensitivity=68.27%, avg_specificity=87.11% avg_auc=88.52%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.287173 Test loss=0.385088 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.28744980692863464
[5/24] Train loss=0.2661365568637848
[10/24] Train loss=0.2982708811759949
[15/24] Train loss=0.28409385681152344
[20/24] Train loss=0.2841332256793976
Test set avg_accuracy=82.19% avg_sensitivity=67.82%, avg_specificity=87.25% avg_auc=88.51%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.286450 Test loss=0.384150 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.2813798189163208
[5/24] Train loss=0.2716270089149475
[10/24] Train loss=0.2981889247894287
[15/24] Train loss=0.2847200632095337
[20/24] Train loss=0.28405964374542236
Test set avg_accuracy=82.25% avg_sensitivity=67.17%, avg_specificity=87.57% avg_auc=88.51%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.286576 Test loss=0.383075 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.2821265161037445
[5/24] Train loss=0.26850569248199463
[10/24] Train loss=0.2986055612564087
[15/24] Train loss=0.2835831344127655
[20/24] Train loss=0.2826958894729614
Test set avg_accuracy=82.20% avg_sensitivity=67.82%, avg_specificity=87.27% avg_auc=88.50%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.286207 Test loss=0.384289 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.28548675775527954
[5/24] Train loss=0.2670542597770691
[10/24] Train loss=0.2984461486339569
[15/24] Train loss=0.2846694886684418
[20/24] Train loss=0.28340646624565125
Test set avg_accuracy=82.23% avg_sensitivity=67.02%, avg_specificity=87.59% avg_auc=88.50%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.286425 Test loss=0.382954 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.2836446166038513
[5/24] Train loss=0.27263376116752625
[10/24] Train loss=0.29993194341659546
[15/24] Train loss=0.28427037596702576
[20/24] Train loss=0.2853013873100281
Test set avg_accuracy=82.24% avg_sensitivity=67.67%, avg_specificity=87.37% avg_auc=88.50%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.286204 Test loss=0.384104 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.2835997939109802
[5/24] Train loss=0.2708742320537567
[10/24] Train loss=0.29819387197494507
[15/24] Train loss=0.28906741738319397
[20/24] Train loss=0.2866351008415222
Test set avg_accuracy=82.20% avg_sensitivity=67.42%, avg_specificity=87.41% avg_auc=88.50%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.286510 Test loss=0.383528 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.2837499678134918
[5/24] Train loss=0.268619179725647
[10/24] Train loss=0.30019813776016235
[15/24] Train loss=0.2798587381839752
[20/24] Train loss=0.2809266149997711
Test set avg_accuracy=82.20% avg_sensitivity=67.52%, avg_specificity=87.37% avg_auc=88.50%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.286317 Test loss=0.383782 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.2872106730937958
[5/24] Train loss=0.2624502182006836
[10/24] Train loss=0.3027295470237732
[15/24] Train loss=0.28585532307624817
[20/24] Train loss=0.2903347611427307
Test set avg_accuracy=82.17% avg_sensitivity=67.32%, avg_specificity=87.41% avg_auc=88.50%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.286084 Test loss=0.383485 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.2872016727924347
[5/24] Train loss=0.2679489850997925
[10/24] Train loss=0.30414018034935
[15/24] Train loss=0.2854256331920624
[20/24] Train loss=0.28886765241622925
Test set avg_accuracy=82.20% avg_sensitivity=67.47%, avg_specificity=87.39% avg_auc=88.50%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.286475 Test loss=0.383953 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.28437381982803345
[5/24] Train loss=0.274028480052948
[10/24] Train loss=0.30348795652389526
[15/24] Train loss=0.2858211100101471
[20/24] Train loss=0.28346964716911316
Test set avg_accuracy=82.21% avg_sensitivity=67.57%, avg_specificity=87.37% avg_auc=88.50%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.286590 Test loss=0.384112 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.2886907756328583
[5/24] Train loss=0.264728844165802
[10/24] Train loss=0.29737672209739685
[15/24] Train loss=0.2839067876338959
[20/24] Train loss=0.28525298833847046
Test set avg_accuracy=82.17% avg_sensitivity=67.32%, avg_specificity=87.41% avg_auc=88.50%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.286727 Test loss=0.383705 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.29169127345085144
[5/24] Train loss=0.26697516441345215
[10/24] Train loss=0.2961505651473999
[15/24] Train loss=0.2852793335914612
[20/24] Train loss=0.28545692563056946
Test set avg_accuracy=82.16% avg_sensitivity=67.17%, avg_specificity=87.44% avg_auc=88.50%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.286794 Test loss=0.383533 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.283005952835083
[5/24] Train loss=0.2736574411392212
[10/24] Train loss=0.3019683063030243
[15/24] Train loss=0.28160789608955383
[20/24] Train loss=0.2850651741027832
Test set avg_accuracy=82.16% avg_sensitivity=67.27%, avg_specificity=87.41% avg_auc=88.50%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.285669 Test loss=0.383674 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.28577908873558044
[5/24] Train loss=0.26780468225479126
[10/24] Train loss=0.3008606731891632
[15/24] Train loss=0.2849811315536499
[20/24] Train loss=0.2826825976371765
Test set avg_accuracy=82.17% avg_sensitivity=67.32%, avg_specificity=87.41% avg_auc=88.50%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.286086 Test loss=0.383722 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.28217971324920654
[5/24] Train loss=0.26502954959869385
[10/24] Train loss=0.30033570528030396
[15/24] Train loss=0.2856321334838867
[20/24] Train loss=0.28322291374206543
Test set avg_accuracy=82.17% avg_sensitivity=67.32%, avg_specificity=87.41% avg_auc=88.50%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.286066 Test loss=0.383743 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.2863886058330536
[5/24] Train loss=0.2724934220314026
[10/24] Train loss=0.3041670322418213
[15/24] Train loss=0.28072085976600647
[20/24] Train loss=0.2859840989112854
Test set avg_accuracy=82.17% avg_sensitivity=67.32%, avg_specificity=87.41% avg_auc=88.50%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.287204 Test loss=0.383743 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=82.59% sen=69.82%, spe=87.09%, auc=88.79%!
Fold[4] Avg_jsc=0.55%(±0.2730257645683974)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.9210914969444275
[5/24] Train loss=0.8221067190170288
[10/24] Train loss=0.7646868824958801
[15/24] Train loss=0.7167934775352478
[20/24] Train loss=0.6928541660308838
Test set avg_accuracy=70.90% avg_sensitivity=7.17%, avg_specificity=92.63% avg_auc=50.74%
Best model saved!! Metric=50.73867454948582!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.760845 Test loss=0.619492 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6980149745941162
[5/24] Train loss=0.6481810212135315
[10/24] Train loss=0.6404038667678833
[15/24] Train loss=0.618302583694458
[20/24] Train loss=0.6356704831123352
Test set avg_accuracy=74.30% avg_sensitivity=0.51%, avg_specificity=99.46% avg_auc=53.33%
Best model saved!! Metric=53.33242406613028!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.633755 Test loss=0.576820 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6587667465209961
[5/24] Train loss=0.6210599541664124
[10/24] Train loss=0.6261328458786011
[15/24] Train loss=0.5997169613838196
[20/24] Train loss=0.6379407644271851
Test set avg_accuracy=74.31% avg_sensitivity=0.15%, avg_specificity=99.60% avg_auc=55.02%
Best model saved!! Metric=55.01958411351947!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.615326 Test loss=0.575553 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6417569518089294
[5/24] Train loss=0.6108347773551941
[10/24] Train loss=0.6144434213638306
[15/24] Train loss=0.6065720319747925
[20/24] Train loss=0.6223494410514832
Test set avg_accuracy=74.34% avg_sensitivity=0.15%, avg_specificity=99.63% avg_auc=55.54%
Best model saved!! Metric=55.543038602907814!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.606647 Test loss=0.568648 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6360422372817993
[5/24] Train loss=0.6066542863845825
[10/24] Train loss=0.6042453050613403
[15/24] Train loss=0.5933119654655457
[20/24] Train loss=0.6186122298240662
Test set avg_accuracy=74.32% avg_sensitivity=0.20%, avg_specificity=99.60% avg_auc=56.67%
Best model saved!! Metric=56.66525493322161!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.603596 Test loss=0.563098 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6390692591667175
[5/24] Train loss=0.599615216255188
[10/24] Train loss=0.6054919362068176
[15/24] Train loss=0.5813563466072083
[20/24] Train loss=0.6169918775558472
Test set avg_accuracy=74.30% avg_sensitivity=0.15%, avg_specificity=99.58% avg_auc=58.40%
Best model saved!! Metric=58.39568787405014!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.598184 Test loss=0.560484 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6219761967658997
[5/24] Train loss=0.5837098956108093
[10/24] Train loss=0.5988615155220032
[15/24] Train loss=0.5786958932876587
[20/24] Train loss=0.6080242395401001
Test set avg_accuracy=74.31% avg_sensitivity=0.20%, avg_specificity=99.58% avg_auc=60.01%
Best model saved!! Metric=60.010763685209014!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.592458 Test loss=0.557387 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.608781099319458
[5/24] Train loss=0.586368978023529
[10/24] Train loss=0.5975800156593323
[15/24] Train loss=0.5780367851257324
[20/24] Train loss=0.5939411520957947
Test set avg_accuracy=74.30% avg_sensitivity=0.20%, avg_specificity=99.56% avg_auc=61.59%
Best model saved!! Metric=61.59185596992926!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.586527 Test loss=0.554166 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.621634840965271
[5/24] Train loss=0.5842450857162476
[10/24] Train loss=0.5891757011413574
[15/24] Train loss=0.5795823931694031
[20/24] Train loss=0.5939735770225525
Test set avg_accuracy=74.18% avg_sensitivity=0.31%, avg_specificity=99.37% avg_auc=63.60%
Best model saved!! Metric=63.597143309541295!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.583485 Test loss=0.550189 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6020216941833496
[5/24] Train loss=0.5770410895347595
[10/24] Train loss=0.5860381126403809
[15/24] Train loss=0.5695068836212158
[20/24] Train loss=0.5879520177841187
Test set avg_accuracy=74.18% avg_sensitivity=0.72%, avg_specificity=99.23% avg_auc=65.40%
Best model saved!! Metric=65.3988737067194!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.576987 Test loss=0.545560 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5979305505752563
[5/24] Train loss=0.5668371915817261
[10/24] Train loss=0.5828446745872498
[15/24] Train loss=0.5606772303581238
[20/24] Train loss=0.5782889723777771
Test set avg_accuracy=74.08% avg_sensitivity=1.18%, avg_specificity=98.93% avg_auc=67.45%
Best model saved!! Metric=67.4495394700197!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.570449 Test loss=0.539898 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5869097709655762
[5/24] Train loss=0.5640595555305481
[10/24] Train loss=0.5784763097763062
[15/24] Train loss=0.5561331510543823
[20/24] Train loss=0.564841628074646
Test set avg_accuracy=73.95% avg_sensitivity=2.46%, avg_specificity=98.32% avg_auc=70.00%
Best model saved!! Metric=70.00141530971725!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.564160 Test loss=0.531618 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5816872715950012
[5/24] Train loss=0.5464527010917664
[10/24] Train loss=0.5617508292198181
[15/24] Train loss=0.5333478450775146
[20/24] Train loss=0.5548118352890015
Test set avg_accuracy=74.13% avg_sensitivity=6.25%, avg_specificity=97.28% avg_auc=72.99%
Best model saved!! Metric=72.99194775495491!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.552235 Test loss=0.519154 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5653361082077026
[5/24] Train loss=0.5315732955932617
[10/24] Train loss=0.5583703517913818
[15/24] Train loss=0.5196916460990906
[20/24] Train loss=0.5298892259597778
Test set avg_accuracy=74.87% avg_sensitivity=16.23%, avg_specificity=94.87% avg_auc=75.53%
Best model saved!! Metric=75.53020693830778!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.536684 Test loss=0.503037 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5449613332748413
[5/24] Train loss=0.5101110339164734
[10/24] Train loss=0.5374120473861694
[15/24] Train loss=0.4996148645877838
[20/24] Train loss=0.5058967471122742
Test set avg_accuracy=75.38% avg_sensitivity=24.42%, avg_specificity=92.75% avg_auc=77.77%
Best model saved!! Metric=77.77444737430544!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.520568 Test loss=0.485185 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5186893939971924
[5/24] Train loss=0.49281641840934753
[10/24] Train loss=0.5224213600158691
[15/24] Train loss=0.471265584230423
[20/24] Train loss=0.4853564202785492
Test set avg_accuracy=76.55% avg_sensitivity=30.21%, avg_specificity=92.35% avg_auc=80.03%
Best model saved!! Metric=80.03345781442742!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.503279 Test loss=0.464705 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.49189698696136475
[5/24] Train loss=0.4732752740383148
[10/24] Train loss=0.5085074305534363
[15/24] Train loss=0.4638826549053192
[20/24] Train loss=0.4640559256076813
Test set avg_accuracy=77.46% avg_sensitivity=33.74%, avg_specificity=92.37% avg_auc=81.98%
Best model saved!! Metric=81.9780513447186!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.486116 Test loss=0.445975 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4855922758579254
[5/24] Train loss=0.45421332120895386
[10/24] Train loss=0.4813956320285797
[15/24] Train loss=0.4432850182056427
[20/24] Train loss=0.44074034690856934
Test set avg_accuracy=78.29% avg_sensitivity=36.00%, avg_specificity=92.72% avg_auc=83.60%
Best model saved!! Metric=83.60445946836388!!
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.468460 Test loss=0.429901 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4653249680995941
[5/24] Train loss=0.4362260699272156
[10/24] Train loss=0.459440141916275
[15/24] Train loss=0.4204389154911041
[20/24] Train loss=0.4147707223892212
Test set avg_accuracy=79.38% avg_sensitivity=38.76%, avg_specificity=93.23% avg_auc=85.02%
Best model saved!! Metric=85.02165566918268!!
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.450801 Test loss=0.414136 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4520910382270813
[5/24] Train loss=0.4203587472438812
[10/24] Train loss=0.43972131609916687
[15/24] Train loss=0.40439513325691223
[20/24] Train loss=0.39953184127807617
Test set avg_accuracy=80.70% avg_sensitivity=45.16%, avg_specificity=92.82% avg_auc=86.20%
Best model saved!! Metric=86.20406066037118!!
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.433874 Test loss=0.397717 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.43109506368637085
[5/24] Train loss=0.4085277020931244
[10/24] Train loss=0.4179532527923584
[15/24] Train loss=0.38134336471557617
[20/24] Train loss=0.38934943079948425
Test set avg_accuracy=82.19% avg_sensitivity=51.46%, avg_specificity=92.67% avg_auc=87.24%
Best model saved!! Metric=87.23921711467969!!
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.419530 Test loss=0.382716 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.4143125116825104
[5/24] Train loss=0.39508962631225586
[10/24] Train loss=0.406377375125885
[15/24] Train loss=0.368611603975296
[20/24] Train loss=0.3764731287956238
Test set avg_accuracy=83.29% avg_sensitivity=56.17%, avg_specificity=92.54% avg_auc=88.02%
Best model saved!! Metric=88.02426250338516!!
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.406201 Test loss=0.371221 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3971043527126312
[5/24] Train loss=0.37947529554367065
[10/24] Train loss=0.4012306332588196
[15/24] Train loss=0.3547970652580261
[20/24] Train loss=0.3646685779094696
Test set avg_accuracy=83.52% avg_sensitivity=56.94%, avg_specificity=92.58% avg_auc=88.61%
Best model saved!! Metric=88.60546931822213!!
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.395859 Test loss=0.362747 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3854680359363556
[5/24] Train loss=0.3682567775249481
[10/24] Train loss=0.38409265875816345
[15/24] Train loss=0.337164968252182
[20/24] Train loss=0.35130685567855835
Test set avg_accuracy=83.57% avg_sensitivity=53.66%, avg_specificity=93.77% avg_auc=88.98%
Best model saved!! Metric=88.98359751702998!!
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.384290 Test loss=0.359261 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3799135386943817
[5/24] Train loss=0.36054524779319763
[10/24] Train loss=0.3751986622810364
[15/24] Train loss=0.3344755470752716
[20/24] Train loss=0.3414374887943268
Test set avg_accuracy=83.61% avg_sensitivity=52.33%, avg_specificity=94.27% avg_auc=89.23%
Best model saved!! Metric=89.23201432368535!!
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.376750 Test loss=0.356885 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.37494733929634094
[5/24] Train loss=0.3485015332698822
[10/24] Train loss=0.3685203492641449
[15/24] Train loss=0.3234115242958069
[20/24] Train loss=0.3372294306755066
Test set avg_accuracy=83.87% avg_sensitivity=54.02%, avg_specificity=94.05% avg_auc=89.44%
Best model saved!! Metric=89.4429070944389!!
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.369179 Test loss=0.352704 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3657257854938507
[5/24] Train loss=0.3441586494445801
[10/24] Train loss=0.3698095977306366
[15/24] Train loss=0.3166479766368866
[20/24] Train loss=0.3334067761898041
Test set avg_accuracy=83.63% avg_sensitivity=51.82%, avg_specificity=94.48% avg_auc=89.48%
Best model saved!! Metric=89.47520083227006!!
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.363553 Test loss=0.355058 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3703902065753937
[5/24] Train loss=0.3381059765815735
[10/24] Train loss=0.36075082421302795
[15/24] Train loss=0.3119543194770813
[20/24] Train loss=0.3298764228820801
Test set avg_accuracy=83.48% avg_sensitivity=52.23%, avg_specificity=94.13% avg_auc=89.55%
Best model saved!! Metric=89.55175987907194!!
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.359462 Test loss=0.352856 Current lr=[0.000210185142098938]

[0/24] Train loss=0.36052194237709045
[5/24] Train loss=0.3349796235561371
[10/24] Train loss=0.35668304562568665
[15/24] Train loss=0.3045189678668976
[20/24] Train loss=0.3262728154659271
Test set avg_accuracy=83.67% avg_sensitivity=53.46%, avg_specificity=93.98% avg_auc=89.63%
Best model saved!! Metric=89.63417507157686!!
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.354619 Test loss=0.350965 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.35648536682128906
[5/24] Train loss=0.3304963707923889
[10/24] Train loss=0.3568730354309082
[15/24] Train loss=0.29885467886924744
[20/24] Train loss=0.31662288308143616
Test set avg_accuracy=83.50% avg_sensitivity=52.64%, avg_specificity=94.03% avg_auc=89.66%
Best model saved!! Metric=89.66360779165996!!
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.350445 Test loss=0.351517 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3544314205646515
[5/24] Train loss=0.32627299427986145
[10/24] Train loss=0.35027170181274414
[15/24] Train loss=0.29608646035194397
[20/24] Train loss=0.31719401478767395
Test set avg_accuracy=83.55% avg_sensitivity=53.20%, avg_specificity=93.91% avg_auc=89.73%
Best model saved!! Metric=89.73186988699248!!
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.346967 Test loss=0.350681 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.34911033511161804
[5/24] Train loss=0.3233872652053833
[10/24] Train loss=0.3488013446331024
[15/24] Train loss=0.2929680049419403
[20/24] Train loss=0.31639164686203003
Test set avg_accuracy=83.62% avg_sensitivity=53.10%, avg_specificity=94.03% avg_auc=89.74%
Best model saved!! Metric=89.7393621772202!!
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.342776 Test loss=0.350971 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.350796639919281
[5/24] Train loss=0.3234771192073822
[10/24] Train loss=0.3474957346916199
[15/24] Train loss=0.28777065873146057
[20/24] Train loss=0.31338396668434143
Test set avg_accuracy=83.66% avg_sensitivity=52.84%, avg_specificity=94.17% avg_auc=89.76%
Best model saved!! Metric=89.76043089073048!!
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.339863 Test loss=0.351118 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3445467948913574
[5/24] Train loss=0.3191365599632263
[10/24] Train loss=0.3424762189388275
[15/24] Train loss=0.28526800870895386
[20/24] Train loss=0.30990132689476013
Test set avg_accuracy=83.74% avg_sensitivity=52.48%, avg_specificity=94.39% avg_auc=89.76%
Best model saved!! Metric=89.76152612408717!!
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.336671 Test loss=0.351900 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.344345360994339
[5/24] Train loss=0.3141058087348938
[10/24] Train loss=0.33941930532455444
[15/24] Train loss=0.28175273537635803
[20/24] Train loss=0.3089459538459778
Test set avg_accuracy=83.78% avg_sensitivity=53.25%, avg_specificity=94.19% avg_auc=89.80%
Best model saved!! Metric=89.79502685378081!!
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.334343 Test loss=0.349970 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.33578938245773315
[5/24] Train loss=0.3151051998138428
[10/24] Train loss=0.336551696062088
[15/24] Train loss=0.28379836678504944
[20/24] Train loss=0.3061884045600891
Test set avg_accuracy=84.00% avg_sensitivity=55.61%, avg_specificity=93.68% avg_auc=89.86%
Best model saved!! Metric=89.86141140621615!!
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.331538 Test loss=0.346477 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3327201008796692
[5/24] Train loss=0.31207945942878723
[10/24] Train loss=0.3357919454574585
[15/24] Train loss=0.280722051858902
[20/24] Train loss=0.30732089281082153
Test set avg_accuracy=83.72% avg_sensitivity=53.15%, avg_specificity=94.15% avg_auc=89.84%
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.329275 Test loss=0.349383 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3338586986064911
[5/24] Train loss=0.3102176785469055
[10/24] Train loss=0.33315199613571167
[15/24] Train loss=0.2778222858905792
[20/24] Train loss=0.30466094613075256
Test set avg_accuracy=83.83% avg_sensitivity=54.74%, avg_specificity=93.75% avg_auc=89.89%
Best model saved!! Metric=89.88506844672037!!
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.326339 Test loss=0.346547 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3313292860984802
[5/24] Train loss=0.30773794651031494
[10/24] Train loss=0.32873010635375977
[15/24] Train loss=0.276978075504303
[20/24] Train loss=0.30075159668922424
Test set avg_accuracy=83.71% avg_sensitivity=53.66%, avg_specificity=93.96% avg_auc=89.89%
Best model saved!! Metric=89.88800098991214!!
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.323580 Test loss=0.347602 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.33002281188964844
[5/24] Train loss=0.30653640627861023
[10/24] Train loss=0.32724612951278687
[15/24] Train loss=0.2724545896053314
[20/24] Train loss=0.3019411265850067
Test set avg_accuracy=83.79% avg_sensitivity=53.97%, avg_specificity=93.96% avg_auc=89.91%
Best model saved!! Metric=89.90562307110407!!
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.321937 Test loss=0.346979 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3253639340400696
[5/24] Train loss=0.30304697155952454
[10/24] Train loss=0.3253835439682007
[15/24] Train loss=0.27201297879219055
[20/24] Train loss=0.29782170057296753
Test set avg_accuracy=83.71% avg_sensitivity=53.30%, avg_specificity=94.08% avg_auc=89.89%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.319403 Test loss=0.347972 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.32398176193237305
[5/24] Train loss=0.29931196570396423
[10/24] Train loss=0.32362812757492065
[15/24] Train loss=0.26952892541885376
[20/24] Train loss=0.29853472113609314
Test set avg_accuracy=84.02% avg_sensitivity=55.30%, avg_specificity=93.82% avg_auc=89.92%
Best model saved!! Metric=89.92325409297645!!
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.316831 Test loss=0.345734 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.32098883390426636
[5/24] Train loss=0.29720747470855713
[10/24] Train loss=0.3230341672897339
[15/24] Train loss=0.2681749165058136
[20/24] Train loss=0.29544252157211304
Test set avg_accuracy=84.01% avg_sensitivity=55.04%, avg_specificity=93.89% avg_auc=89.97%
Best model saved!! Metric=89.96891414809933!!
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.315244 Test loss=0.344879 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.32003718614578247
[5/24] Train loss=0.2973243296146393
[10/24] Train loss=0.31680288910865784
[15/24] Train loss=0.26618048548698425
[20/24] Train loss=0.2920800447463989
Test set avg_accuracy=84.09% avg_sensitivity=55.66%, avg_specificity=93.78% avg_auc=89.96%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.312958 Test loss=0.344741 Current lr=[0.00029967723776099]

[0/24] Train loss=0.31811854243278503
[5/24] Train loss=0.2961958348751068
[10/24] Train loss=0.3188278377056122
[15/24] Train loss=0.2639552354812622
[20/24] Train loss=0.2948143780231476
Test set avg_accuracy=84.17% avg_sensitivity=56.32%, avg_specificity=93.66% avg_auc=89.99%
Best model saved!! Metric=89.99004097603262!!
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.311514 Test loss=0.343550 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.31352952122688293
[5/24] Train loss=0.2904048562049866
[10/24] Train loss=0.3155108392238617
[15/24] Train loss=0.26366347074508667
[20/24] Train loss=0.29224178194999695
Test set avg_accuracy=84.32% avg_sensitivity=57.19%, avg_specificity=93.57% avg_auc=90.02%
Best model saved!! Metric=90.01545486024779!!
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.309104 Test loss=0.342835 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3111228048801422
[5/24] Train loss=0.28953471779823303
[10/24] Train loss=0.31538864970207214
[15/24] Train loss=0.2659785747528076
[20/24] Train loss=0.28935787081718445
Test set avg_accuracy=84.34% avg_sensitivity=57.25%, avg_specificity=93.57% avg_auc=89.98%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.307193 Test loss=0.343285 Current lr=[0.000299720220882401]

[0/24] Train loss=0.30885031819343567
[5/24] Train loss=0.2892529368400574
[10/24] Train loss=0.3123738169670105
[15/24] Train loss=0.262031227350235
[20/24] Train loss=0.2890840470790863
Test set avg_accuracy=84.45% avg_sensitivity=57.25%, avg_specificity=93.73% avg_auc=89.99%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.305797 Test loss=0.343291 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.30560609698295593
[5/24] Train loss=0.2852165997028351
[10/24] Train loss=0.3119022250175476
[15/24] Train loss=0.260597288608551
[20/24] Train loss=0.2879409193992615
Test set avg_accuracy=84.54% avg_sensitivity=58.42%, avg_specificity=93.45% avg_auc=90.02%
Best model saved!! Metric=90.02445365513346!!
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.304131 Test loss=0.341611 Current lr=[0.000298904600941902]

[0/24] Train loss=0.30056461691856384
[5/24] Train loss=0.2822456359863281
[10/24] Train loss=0.3091180920600891
[15/24] Train loss=0.2576562464237213
[20/24] Train loss=0.28527697920799255
Test set avg_accuracy=84.65% avg_sensitivity=58.32%, avg_specificity=93.63% avg_auc=90.03%
Best model saved!! Metric=90.02966160150298!!
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.302085 Test loss=0.342015 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.30108293890953064
[5/24] Train loss=0.28352090716362
[10/24] Train loss=0.309964120388031
[15/24] Train loss=0.256250262260437
[20/24] Train loss=0.28630149364471436
Test set avg_accuracy=84.64% avg_sensitivity=58.53%, avg_specificity=93.54% avg_auc=90.06%
Best model saved!! Metric=90.06354231011626!!
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.301144 Test loss=0.341218 Current lr=[0.000297555943323901]

[0/24] Train loss=0.29761242866516113
[5/24] Train loss=0.2779817283153534
[10/24] Train loss=0.3057817220687866
[15/24] Train loss=0.2569746971130371
[20/24] Train loss=0.284975528717041
Test set avg_accuracy=84.73% avg_sensitivity=59.24%, avg_specificity=93.42% avg_auc=90.06%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.299396 Test loss=0.340765 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2956409752368927
[5/24] Train loss=0.2807159423828125
[10/24] Train loss=0.3083609938621521
[15/24] Train loss=0.2544783353805542
[20/24] Train loss=0.2861056923866272
Test set avg_accuracy=84.58% avg_sensitivity=58.17%, avg_specificity=93.59% avg_auc=90.03%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.298333 Test loss=0.341996 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2982584238052368
[5/24] Train loss=0.2752896547317505
[10/24] Train loss=0.3049754500389099
[15/24] Train loss=0.2559680938720703
[20/24] Train loss=0.28336772322654724
Test set avg_accuracy=84.60% avg_sensitivity=58.68%, avg_specificity=93.43% avg_auc=90.02%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.296517 Test loss=0.341569 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.29258662462234497
[5/24] Train loss=0.2740325629711151
[10/24] Train loss=0.30482998490333557
[15/24] Train loss=0.2540012300014496
[20/24] Train loss=0.28110426664352417
Test set avg_accuracy=84.74% avg_sensitivity=59.14%, avg_specificity=93.47% avg_auc=90.03%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.294884 Test loss=0.341425 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2952127754688263
[5/24] Train loss=0.27011001110076904
[10/24] Train loss=0.303796648979187
[15/24] Train loss=0.2520716190338135
[20/24] Train loss=0.2832774817943573
Test set avg_accuracy=84.67% avg_sensitivity=58.93%, avg_specificity=93.45% avg_auc=90.00%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.294264 Test loss=0.341925 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.2926476001739502
[5/24] Train loss=0.2735503017902374
[10/24] Train loss=0.3043982684612274
[15/24] Train loss=0.25126656889915466
[20/24] Train loss=0.28413763642311096
Test set avg_accuracy=84.73% avg_sensitivity=59.55%, avg_specificity=93.31% avg_auc=90.02%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.293261 Test loss=0.341389 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2901332676410675
[5/24] Train loss=0.27022236585617065
[10/24] Train loss=0.30411437153816223
[15/24] Train loss=0.2507178783416748
[20/24] Train loss=0.280444860458374
Test set avg_accuracy=84.75% avg_sensitivity=60.22%, avg_specificity=93.12% avg_auc=90.03%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.291734 Test loss=0.340891 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2891051471233368
[5/24] Train loss=0.2705343961715698
[10/24] Train loss=0.3013436794281006
[15/24] Train loss=0.24946647882461548
[20/24] Train loss=0.2760569155216217
Test set avg_accuracy=84.79% avg_sensitivity=60.68%, avg_specificity=93.02% avg_auc=90.05%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.291006 Test loss=0.340424 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.285780668258667
[5/24] Train loss=0.26838991045951843
[10/24] Train loss=0.30005213618278503
[15/24] Train loss=0.2500942349433899
[20/24] Train loss=0.2755894064903259
Test set avg_accuracy=84.73% avg_sensitivity=60.16%, avg_specificity=93.10% avg_auc=90.07%
Best model saved!! Metric=90.06592053111933!!
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.290101 Test loss=0.340417 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.28545013070106506
[5/24] Train loss=0.2693692445755005
[10/24] Train loss=0.3001600503921509
[15/24] Train loss=0.24987660348415375
[20/24] Train loss=0.2740613520145416
Test set avg_accuracy=84.69% avg_sensitivity=60.16%, avg_specificity=93.05% avg_auc=90.05%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.289087 Test loss=0.340728 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2856849730014801
[5/24] Train loss=0.2666116952896118
[10/24] Train loss=0.2956019341945648
[15/24] Train loss=0.24910327792167664
[20/24] Train loss=0.2743089199066162
Test set avg_accuracy=84.79% avg_sensitivity=61.50%, avg_specificity=92.74% avg_auc=90.04%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.287764 Test loss=0.340135 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2798638939857483
[5/24] Train loss=0.26417291164398193
[10/24] Train loss=0.3003486692905426
[15/24] Train loss=0.24750494956970215
[20/24] Train loss=0.27291184663772583
Test set avg_accuracy=84.64% avg_sensitivity=60.22%, avg_specificity=92.96% avg_auc=90.02%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.286579 Test loss=0.341128 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.28351807594299316
[5/24] Train loss=0.2677161395549774
[10/24] Train loss=0.2968803942203522
[15/24] Train loss=0.24586331844329834
[20/24] Train loss=0.2730627954006195
Test set avg_accuracy=84.66% avg_sensitivity=60.73%, avg_specificity=92.82% avg_auc=90.04%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.285762 Test loss=0.340594 Current lr=[0.000276307469034998]

[0/24] Train loss=0.28176409006118774
[5/24] Train loss=0.26266366243362427
[10/24] Train loss=0.29750940203666687
[15/24] Train loss=0.24632996320724487
[20/24] Train loss=0.2718949317932129
Test set avg_accuracy=84.64% avg_sensitivity=61.44%, avg_specificity=92.54% avg_auc=90.03%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.285754 Test loss=0.340622 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.2801024913787842
[5/24] Train loss=0.2608465552330017
[10/24] Train loss=0.2951095700263977
[15/24] Train loss=0.24670809507369995
[20/24] Train loss=0.27530428767204285
Test set avg_accuracy=84.61% avg_sensitivity=62.06%, avg_specificity=92.30% avg_auc=89.97%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.285106 Test loss=0.341045 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.28019359707832336
[5/24] Train loss=0.26042550802230835
[10/24] Train loss=0.29224517941474915
[15/24] Train loss=0.24571681022644043
[20/24] Train loss=0.2704417407512665
Test set avg_accuracy=84.61% avg_sensitivity=62.26%, avg_specificity=92.23% avg_auc=89.98%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.285071 Test loss=0.340865 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2773556411266327
[5/24] Train loss=0.2600997984409332
[10/24] Train loss=0.29319265484809875
[15/24] Train loss=0.24435289204120636
[20/24] Train loss=0.27240127325057983
Test set avg_accuracy=84.61% avg_sensitivity=63.65%, avg_specificity=91.76% avg_auc=90.04%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.284257 Test loss=0.339889 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.27498507499694824
[5/24] Train loss=0.26078101992607117
[10/24] Train loss=0.29405567049980164
[15/24] Train loss=0.24653837084770203
[20/24] Train loss=0.2748652994632721
Test set avg_accuracy=84.64% avg_sensitivity=66.15%, avg_specificity=90.94% avg_auc=90.07%
Best model saved!! Metric=90.0690274175801!!
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.285203 Test loss=0.340431 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.27691155672073364
[5/24] Train loss=0.2612400949001312
[10/24] Train loss=0.29528382420539856
[15/24] Train loss=0.2475154995918274
[20/24] Train loss=0.2795468866825104
Test set avg_accuracy=84.49% avg_sensitivity=67.79%, avg_specificity=90.19% avg_auc=90.16%
Best model saved!! Metric=90.15522004758051!!
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.285360 Test loss=0.340884 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.27669233083724976
[5/24] Train loss=0.26162320375442505
[10/24] Train loss=0.2937712073326111
[15/24] Train loss=0.2431771159172058
[20/24] Train loss=0.2777416408061981
Test set avg_accuracy=84.62% avg_sensitivity=67.33%, avg_specificity=90.52% avg_auc=90.15%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.284675 Test loss=0.339946 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.2747715711593628
[5/24] Train loss=0.2648361325263977
[10/24] Train loss=0.291597455739975
[15/24] Train loss=0.2428295910358429
[20/24] Train loss=0.2749735713005066
Test set avg_accuracy=84.61% avg_sensitivity=66.41%, avg_specificity=90.82% avg_auc=90.13%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.283534 Test loss=0.339630 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2742375135421753
[5/24] Train loss=0.26413169503211975
[10/24] Train loss=0.29066717624664307
[15/24] Train loss=0.24035216867923737
[20/24] Train loss=0.271686851978302
Test set avg_accuracy=84.53% avg_sensitivity=64.62%, avg_specificity=91.32% avg_auc=90.08%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.281355 Test loss=0.339750 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.27305352687835693
[5/24] Train loss=0.256875216960907
[10/24] Train loss=0.2914089858531952
[15/24] Train loss=0.24125097692012787
[20/24] Train loss=0.2704414427280426
Test set avg_accuracy=84.52% avg_sensitivity=64.52%, avg_specificity=91.34% avg_auc=90.09%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.280852 Test loss=0.339747 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.27226966619491577
[5/24] Train loss=0.2588863968849182
[10/24] Train loss=0.2917553782463074
[15/24] Train loss=0.24042832851409912
[20/24] Train loss=0.2682681977748871
Test set avg_accuracy=84.52% avg_sensitivity=64.16%, avg_specificity=91.46% avg_auc=90.09%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.279162 Test loss=0.339642 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2747194468975067
[5/24] Train loss=0.2551804482936859
[10/24] Train loss=0.290479451417923
[15/24] Train loss=0.23869161307811737
[20/24] Train loss=0.26884952187538147
Test set avg_accuracy=84.49% avg_sensitivity=63.85%, avg_specificity=91.53% avg_auc=90.07%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.278530 Test loss=0.339928 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2732289731502533
[5/24] Train loss=0.25845932960510254
[10/24] Train loss=0.2893936336040497
[15/24] Train loss=0.23846016824245453
[20/24] Train loss=0.2691206634044647
Test set avg_accuracy=84.44% avg_sensitivity=63.49%, avg_specificity=91.58% avg_auc=90.03%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.279298 Test loss=0.340372 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2702319622039795
[5/24] Train loss=0.2550720274448395
[10/24] Train loss=0.2871878445148468
[15/24] Train loss=0.24199910461902618
[20/24] Train loss=0.26517370343208313
Test set avg_accuracy=84.44% avg_sensitivity=63.54%, avg_specificity=91.57% avg_auc=90.08%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.278827 Test loss=0.339615 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2714577317237854
[5/24] Train loss=0.2557072639465332
[10/24] Train loss=0.291817307472229
[15/24] Train loss=0.24048958718776703
[20/24] Train loss=0.2646436095237732
Test set avg_accuracy=84.43% avg_sensitivity=63.49%, avg_specificity=91.57% avg_auc=90.11%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.277802 Test loss=0.339159 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.27030354738235474
[5/24] Train loss=0.25707435607910156
[10/24] Train loss=0.2888912856578827
[15/24] Train loss=0.24119146168231964
[20/24] Train loss=0.2619487941265106
Test set avg_accuracy=84.40% avg_sensitivity=63.03%, avg_specificity=91.69% avg_auc=90.09%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.276501 Test loss=0.339546 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2732740640640259
[5/24] Train loss=0.2564566731452942
[10/24] Train loss=0.2854839563369751
[15/24] Train loss=0.23961807787418365
[20/24] Train loss=0.26102516055107117
Test set avg_accuracy=84.31% avg_sensitivity=63.03%, avg_specificity=91.57% avg_auc=90.07%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.276997 Test loss=0.340101 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2690182626247406
[5/24] Train loss=0.25125357508659363
[10/24] Train loss=0.28653183579444885
[15/24] Train loss=0.23865637183189392
[20/24] Train loss=0.2672599256038666
Test set avg_accuracy=84.39% avg_sensitivity=63.03%, avg_specificity=91.67% avg_auc=90.12%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.276302 Test loss=0.339572 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2695440351963043
[5/24] Train loss=0.2527296841144562
[10/24] Train loss=0.2884773910045624
[15/24] Train loss=0.23860564827919006
[20/24] Train loss=0.2625645399093628
Test set avg_accuracy=84.39% avg_sensitivity=62.88%, avg_specificity=91.72% avg_auc=90.03%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.276626 Test loss=0.340900 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2697185277938843
[5/24] Train loss=0.2553539276123047
[10/24] Train loss=0.2878890335559845
[15/24] Train loss=0.23999881744384766
[20/24] Train loss=0.26076266169548035
Test set avg_accuracy=84.41% avg_sensitivity=63.03%, avg_specificity=91.71% avg_auc=90.08%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.276238 Test loss=0.340188 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2694140076637268
[5/24] Train loss=0.24838200211524963
[10/24] Train loss=0.2848877012729645
[15/24] Train loss=0.2364870011806488
[20/24] Train loss=0.2638487219810486
Test set avg_accuracy=84.35% avg_sensitivity=62.57%, avg_specificity=91.78% avg_auc=90.08%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.275445 Test loss=0.340388 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2702373266220093
[5/24] Train loss=0.2508801817893982
[10/24] Train loss=0.28708136081695557
[15/24] Train loss=0.23911577463150024
[20/24] Train loss=0.2650669813156128
Test set avg_accuracy=84.38% avg_sensitivity=63.08%, avg_specificity=91.64% avg_auc=90.10%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.275721 Test loss=0.339835 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.26897382736206055
[5/24] Train loss=0.2505849599838257
[10/24] Train loss=0.2864900827407837
[15/24] Train loss=0.2413337528705597
[20/24] Train loss=0.2637034058570862
Test set avg_accuracy=84.30% avg_sensitivity=62.88%, avg_specificity=91.60% avg_auc=90.09%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.275586 Test loss=0.340124 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.26672184467315674
[5/24] Train loss=0.24968981742858887
[10/24] Train loss=0.28789764642715454
[15/24] Train loss=0.24055062234401703
[20/24] Train loss=0.26391732692718506
Test set avg_accuracy=84.28% avg_sensitivity=62.93%, avg_specificity=91.57% avg_auc=90.06%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.275308 Test loss=0.340454 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.270932674407959
[5/24] Train loss=0.25060728192329407
[10/24] Train loss=0.2868575155735016
[15/24] Train loss=0.24301056563854218
[20/24] Train loss=0.2624894082546234
Test set avg_accuracy=84.36% avg_sensitivity=63.75%, avg_specificity=91.39% avg_auc=90.14%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.276272 Test loss=0.339216 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.26615121960639954
[5/24] Train loss=0.2536699175834656
[10/24] Train loss=0.2894163429737091
[15/24] Train loss=0.24451996386051178
[20/24] Train loss=0.2617737054824829
Test set avg_accuracy=84.35% avg_sensitivity=65.54%, avg_specificity=90.76% avg_auc=90.12%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.276200 Test loss=0.339641 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.26772475242614746
[5/24] Train loss=0.2559821605682373
[10/24] Train loss=0.2930826246738434
[15/24] Train loss=0.245735764503479
[20/24] Train loss=0.2600700259208679
Test set avg_accuracy=84.31% avg_sensitivity=68.25%, avg_specificity=89.79% avg_auc=90.22%
Best model saved!! Metric=90.21659781895677!!
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.276837 Test loss=0.340107 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.26674124598503113
[5/24] Train loss=0.2597452402114868
[10/24] Train loss=0.29685351252555847
[15/24] Train loss=0.24381031095981598
[20/24] Train loss=0.26186028122901917
Test set avg_accuracy=84.08% avg_sensitivity=71.63%, avg_specificity=88.32% avg_auc=90.24%
Best model saved!! Metric=90.23954854570445!!
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.278950 Test loss=0.344748 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.27029794454574585
[5/24] Train loss=0.26586052775382996
[10/24] Train loss=0.2942776083946228
[15/24] Train loss=0.23852139711380005
[20/24] Train loss=0.2688101530075073
Test set avg_accuracy=84.02% avg_sensitivity=71.99%, avg_specificity=88.13% avg_auc=90.25%
Best model saved!! Metric=90.25096579465529!!
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.279279 Test loss=0.345982 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2725277543067932
[5/24] Train loss=0.25657400488853455
[10/24] Train loss=0.28873059153556824
[15/24] Train loss=0.24096804857254028
[20/24] Train loss=0.2742269039154053
Test set avg_accuracy=84.31% avg_sensitivity=70.30%, avg_specificity=89.09% avg_auc=90.26%
Best model saved!! Metric=90.25808257630356!!
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.277599 Test loss=0.342256 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2682710886001587
[5/24] Train loss=0.2526276707649231
[10/24] Train loss=0.28665024042129517
[15/24] Train loss=0.23964856564998627
[20/24] Train loss=0.2719680964946747
Test set avg_accuracy=84.48% avg_sensitivity=68.61%, avg_specificity=89.89% avg_auc=90.26%
Best model saved!! Metric=90.26167672984957!!
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.275003 Test loss=0.339785 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.26467257738113403
[5/24] Train loss=0.25382035970687866
[10/24] Train loss=0.2838298976421356
[15/24] Train loss=0.23958620429039001
[20/24] Train loss=0.26873743534088135
Test set avg_accuracy=84.52% avg_sensitivity=68.61%, avg_specificity=89.94% avg_auc=90.29%
Best model saved!! Metric=90.28547682124119!!
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.273927 Test loss=0.339352 Current lr=[0.000156543481933168]

[0/24] Train loss=0.26446831226348877
[5/24] Train loss=0.25399571657180786
[10/24] Train loss=0.2842617630958557
[15/24] Train loss=0.23854286968708038
[20/24] Train loss=0.2693978548049927
Test set avg_accuracy=84.54% avg_sensitivity=68.36%, avg_specificity=90.06% avg_auc=90.29%
Best model saved!! Metric=90.28899050866303!!
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.273580 Test loss=0.338811 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2655392289161682
[5/24] Train loss=0.24868638813495636
[10/24] Train loss=0.28591564297676086
[15/24] Train loss=0.24007557332515717
[20/24] Train loss=0.2654488980770111
Test set avg_accuracy=84.64% avg_sensitivity=67.79%, avg_specificity=90.38% avg_auc=90.28%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.272792 Test loss=0.338209 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2668628692626953
[5/24] Train loss=0.25070202350616455
[10/24] Train loss=0.28355535864830017
[15/24] Train loss=0.23853185772895813
[20/24] Train loss=0.2683982849121094
Test set avg_accuracy=84.56% avg_sensitivity=67.69%, avg_specificity=90.31% avg_auc=90.30%
Best model saved!! Metric=90.30131970702105!!
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.272084 Test loss=0.337793 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.26365387439727783
[5/24] Train loss=0.25006401538848877
[10/24] Train loss=0.28610959649086
[15/24] Train loss=0.23895354568958282
[20/24] Train loss=0.2683164179325104
Test set avg_accuracy=84.54% avg_sensitivity=67.03%, avg_specificity=90.52% avg_auc=90.29%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.272202 Test loss=0.337701 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.265336811542511
[5/24] Train loss=0.2460126429796219
[10/24] Train loss=0.28509119153022766
[15/24] Train loss=0.23628167808055878
[20/24] Train loss=0.26503807306289673
Test set avg_accuracy=84.58% avg_sensitivity=66.87%, avg_specificity=90.62% avg_auc=90.30%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.271770 Test loss=0.337422 Current lr=[0.000134135431043539]

[0/24] Train loss=0.2664835453033447
[5/24] Train loss=0.24644075334072113
[10/24] Train loss=0.28511011600494385
[15/24] Train loss=0.24037964642047882
[20/24] Train loss=0.2670876383781433
Test set avg_accuracy=84.61% avg_sensitivity=66.51%, avg_specificity=90.78% avg_auc=90.30%
Best model saved!! Metric=90.3015834570947!!
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.271232 Test loss=0.337143 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.26405033469200134
[5/24] Train loss=0.24822764098644257
[10/24] Train loss=0.2874630391597748
[15/24] Train loss=0.2370537519454956
[20/24] Train loss=0.26636460423469543
Test set avg_accuracy=84.65% avg_sensitivity=66.26%, avg_specificity=90.92% avg_auc=90.30%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.270459 Test loss=0.336885 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2650167942047119
[5/24] Train loss=0.2461465299129486
[10/24] Train loss=0.2825700342655182
[15/24] Train loss=0.236597940325737
[20/24] Train loss=0.26424214243888855
Test set avg_accuracy=84.67% avg_sensitivity=66.46%, avg_specificity=90.89% avg_auc=90.31%
Best model saved!! Metric=90.30951831100532!!
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.270333 Test loss=0.336940 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.26440927386283875
[5/24] Train loss=0.24616537988185883
[10/24] Train loss=0.28491827845573425
[15/24] Train loss=0.23522327840328217
[20/24] Train loss=0.2664754092693329
Test set avg_accuracy=84.62% avg_sensitivity=66.00%, avg_specificity=90.97% avg_auc=90.30%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.270619 Test loss=0.336879 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.2640696167945862
[5/24] Train loss=0.24901258945465088
[10/24] Train loss=0.2864076793193817
[15/24] Train loss=0.2370426207780838
[20/24] Train loss=0.2654450237751007
Test set avg_accuracy=84.60% avg_sensitivity=65.49%, avg_specificity=91.11% avg_auc=90.29%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.270828 Test loss=0.336809 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.2647458016872406
[5/24] Train loss=0.25049513578414917
[10/24] Train loss=0.2865869104862213
[15/24] Train loss=0.23549295961856842
[20/24] Train loss=0.26410871744155884
Test set avg_accuracy=84.69% avg_sensitivity=65.54%, avg_specificity=91.22% avg_auc=90.30%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.270313 Test loss=0.336633 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.26450926065444946
[5/24] Train loss=0.24488386511802673
[10/24] Train loss=0.2852725088596344
[15/24] Train loss=0.23231065273284912
[20/24] Train loss=0.264695942401886
Test set avg_accuracy=84.67% avg_sensitivity=65.18%, avg_specificity=91.32% avg_auc=90.31%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.269466 Test loss=0.336378 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.2665717601776123
[5/24] Train loss=0.24476979672908783
[10/24] Train loss=0.28624409437179565
[15/24] Train loss=0.23573362827301025
[20/24] Train loss=0.2668471038341522
Test set avg_accuracy=84.65% avg_sensitivity=65.13%, avg_specificity=91.30% avg_auc=90.30%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.270169 Test loss=0.336406 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.2671053111553192
[5/24] Train loss=0.24561886489391327
[10/24] Train loss=0.28765711188316345
[15/24] Train loss=0.23536184430122375
[20/24] Train loss=0.2644956111907959
Test set avg_accuracy=84.66% avg_sensitivity=65.49%, avg_specificity=91.20% avg_auc=90.32%
Best model saved!! Metric=90.31588407549475!!
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.269948 Test loss=0.336284 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.26574915647506714
[5/24] Train loss=0.24617190659046173
[10/24] Train loss=0.2836463451385498
[15/24] Train loss=0.23578369617462158
[20/24] Train loss=0.2609771490097046
Test set avg_accuracy=84.78% avg_sensitivity=64.82%, avg_specificity=91.58% avg_auc=90.30%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.269952 Test loss=0.336163 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2651193141937256
[5/24] Train loss=0.24442312121391296
[10/24] Train loss=0.2857176661491394
[15/24] Train loss=0.23748967051506042
[20/24] Train loss=0.26574116945266724
Test set avg_accuracy=84.71% avg_sensitivity=65.13%, avg_specificity=91.39% avg_auc=90.32%
Best model saved!! Metric=90.31902225433714!!
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.269831 Test loss=0.335982 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.26413044333457947
[5/24] Train loss=0.24570460617542267
[10/24] Train loss=0.28299492597579956
[15/24] Train loss=0.2390507310628891
[20/24] Train loss=0.2630921006202698
Test set avg_accuracy=84.79% avg_sensitivity=64.87%, avg_specificity=91.58% avg_auc=90.32%
Best model saved!! Metric=90.31922788998779!!
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.269133 Test loss=0.335845 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.26563772559165955
[5/24] Train loss=0.24524804949760437
[10/24] Train loss=0.28600725531578064
[15/24] Train loss=0.23511947691440582
[20/24] Train loss=0.2646498382091522
Test set avg_accuracy=84.77% avg_sensitivity=65.18%, avg_specificity=91.44% avg_auc=90.33%
Best model saved!! Metric=90.3327819615692!!
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.269067 Test loss=0.335692 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.2658023238182068
[5/24] Train loss=0.24101419746875763
[10/24] Train loss=0.2864629924297333
[15/24] Train loss=0.2364213913679123
[20/24] Train loss=0.2625179886817932
Test set avg_accuracy=84.86% avg_sensitivity=64.72%, avg_specificity=91.72% avg_auc=90.32%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.269535 Test loss=0.335760 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.2661409378051758
[5/24] Train loss=0.2435472011566162
[10/24] Train loss=0.28600436449050903
[15/24] Train loss=0.23808352649211884
[20/24] Train loss=0.26249539852142334
Test set avg_accuracy=84.80% avg_sensitivity=64.26%, avg_specificity=91.81% avg_auc=90.31%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.269255 Test loss=0.335934 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.2642443776130676
[5/24] Train loss=0.24446366727352142
[10/24] Train loss=0.28375065326690674
[15/24] Train loss=0.2342471182346344
[20/24] Train loss=0.26476752758026123
Test set avg_accuracy=84.86% avg_sensitivity=63.90%, avg_specificity=92.00% avg_auc=90.31%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.268952 Test loss=0.335823 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.2631647288799286
[5/24] Train loss=0.24485157430171967
[10/24] Train loss=0.28608110547065735
[15/24] Train loss=0.23689615726470947
[20/24] Train loss=0.2621642053127289
Test set avg_accuracy=84.88% avg_sensitivity=64.00%, avg_specificity=92.00% avg_auc=90.32%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.269474 Test loss=0.335789 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.2621733546257019
[5/24] Train loss=0.24596525728702545
[10/24] Train loss=0.2867416441440582
[15/24] Train loss=0.23453058302402496
[20/24] Train loss=0.26311975717544556
Test set avg_accuracy=84.84% avg_sensitivity=64.21%, avg_specificity=91.88% avg_auc=90.31%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.268971 Test loss=0.335761 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.26499801874160767
[5/24] Train loss=0.24621325731277466
[10/24] Train loss=0.28514939546585083
[15/24] Train loss=0.2327403873205185
[20/24] Train loss=0.2628161609172821
Test set avg_accuracy=84.80% avg_sensitivity=64.26%, avg_specificity=91.81% avg_auc=90.32%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.268863 Test loss=0.335753 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.26311665773391724
[5/24] Train loss=0.2441554069519043
[10/24] Train loss=0.28657251596450806
[15/24] Train loss=0.23437689244747162
[20/24] Train loss=0.26019906997680664
Test set avg_accuracy=84.80% avg_sensitivity=64.57%, avg_specificity=91.71% avg_auc=90.34%
Best model saved!! Metric=90.3352942927792!!
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.268685 Test loss=0.335575 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.2653524875640869
[5/24] Train loss=0.25002026557922363
[10/24] Train loss=0.2873302102088928
[15/24] Train loss=0.23534218966960907
[20/24] Train loss=0.2588042616844177
Test set avg_accuracy=84.84% avg_sensitivity=65.08%, avg_specificity=91.58% avg_auc=90.36%
Best model saved!! Metric=90.36263489363408!!
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.269411 Test loss=0.335356 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.2639937996864319
[5/24] Train loss=0.2454984188079834
[10/24] Train loss=0.28754499554634094
[15/24] Train loss=0.2323860377073288
[20/24] Train loss=0.2589830160140991
Test set avg_accuracy=84.86% avg_sensitivity=65.95%, avg_specificity=91.30% avg_auc=90.37%
Best model saved!! Metric=90.36862961988429!!
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.268829 Test loss=0.335478 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.26284846663475037
[5/24] Train loss=0.24447302520275116
[10/24] Train loss=0.28647953271865845
[15/24] Train loss=0.23731745779514313
[20/24] Train loss=0.26036888360977173
Test set avg_accuracy=84.82% avg_sensitivity=66.82%, avg_specificity=90.96% avg_auc=90.38%
Best model saved!! Metric=90.38423557763188!!
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.268481 Test loss=0.335602 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.2621634304523468
[5/24] Train loss=0.2430000752210617
[10/24] Train loss=0.28251972794532776
[15/24] Train loss=0.23274178802967072
[20/24] Train loss=0.2598305940628052
Test set avg_accuracy=84.80% avg_sensitivity=66.87%, avg_specificity=90.92% avg_auc=90.39%
Best model saved!! Metric=90.39255935114262!!
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.268518 Test loss=0.335586 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.26291191577911377
[5/24] Train loss=0.24134458601474762
[10/24] Train loss=0.2852866053581238
[15/24] Train loss=0.23247674107551575
[20/24] Train loss=0.25947296619415283
Test set avg_accuracy=84.78% avg_sensitivity=66.87%, avg_specificity=90.89% avg_auc=90.39%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.268379 Test loss=0.335581 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.2647613286972046
[5/24] Train loss=0.24436333775520325
[10/24] Train loss=0.2880450189113617
[15/24] Train loss=0.23356032371520996
[20/24] Train loss=0.26303887367248535
Test set avg_accuracy=84.92% avg_sensitivity=66.00%, avg_specificity=91.37% avg_auc=90.39%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.268328 Test loss=0.335187 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.2618024945259094
[5/24] Train loss=0.24101592600345612
[10/24] Train loss=0.28548991680145264
[15/24] Train loss=0.23755991458892822
[20/24] Train loss=0.2601723074913025
Test set avg_accuracy=84.92% avg_sensitivity=65.95%, avg_specificity=91.39% avg_auc=90.38%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.267733 Test loss=0.335322 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.2615088224411011
[5/24] Train loss=0.24560469388961792
[10/24] Train loss=0.28507182002067566
[15/24] Train loss=0.23147138953208923
[20/24] Train loss=0.2609289288520813
Test set avg_accuracy=84.91% avg_sensitivity=65.75%, avg_specificity=91.44% avg_auc=90.38%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.268285 Test loss=0.335280 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.2634672522544861
[5/24] Train loss=0.24578996002674103
[10/24] Train loss=0.2848646938800812
[15/24] Train loss=0.2328147441148758
[20/24] Train loss=0.26306626200675964
Test set avg_accuracy=84.97% avg_sensitivity=66.05%, avg_specificity=91.43% avg_auc=90.38%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.268345 Test loss=0.335293 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.2648026645183563
[5/24] Train loss=0.24251961708068848
[10/24] Train loss=0.2799933850765228
[15/24] Train loss=0.23509207367897034
[20/24] Train loss=0.26078319549560547
Test set avg_accuracy=84.91% avg_sensitivity=65.49%, avg_specificity=91.53% avg_auc=90.38%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.268049 Test loss=0.335163 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.2648785412311554
[5/24] Train loss=0.2447301298379898
[10/24] Train loss=0.2860923409461975
[15/24] Train loss=0.23435723781585693
[20/24] Train loss=0.2591826021671295
Test set avg_accuracy=84.95% avg_sensitivity=65.54%, avg_specificity=91.57% avg_auc=90.38%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.268045 Test loss=0.335115 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.262546569108963
[5/24] Train loss=0.24419990181922913
[10/24] Train loss=0.2829498052597046
[15/24] Train loss=0.2322976440191269
[20/24] Train loss=0.2597390413284302
Test set avg_accuracy=84.95% avg_sensitivity=65.54%, avg_specificity=91.57% avg_auc=90.38%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.267061 Test loss=0.335124 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.2641589343547821
[5/24] Train loss=0.24287593364715576
[10/24] Train loss=0.28596341609954834
[15/24] Train loss=0.2340051829814911
[20/24] Train loss=0.26093345880508423
Test set avg_accuracy=84.97% avg_sensitivity=65.59%, avg_specificity=91.58% avg_auc=90.38%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.267842 Test loss=0.335083 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.2646958529949188
[5/24] Train loss=0.2425684779882431
[10/24] Train loss=0.2835793197154999
[15/24] Train loss=0.2309676706790924
[20/24] Train loss=0.2587190568447113
Test set avg_accuracy=84.96% avg_sensitivity=65.54%, avg_specificity=91.58% avg_auc=90.38%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.267663 Test loss=0.335080 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.26337456703186035
[5/24] Train loss=0.24114947021007538
[10/24] Train loss=0.28470054268836975
[15/24] Train loss=0.23448671400547028
[20/24] Train loss=0.26087498664855957
Test set avg_accuracy=84.96% avg_sensitivity=65.34%, avg_specificity=91.65% avg_auc=90.38%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.267807 Test loss=0.335018 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.26540422439575195
[5/24] Train loss=0.24584755301475525
[10/24] Train loss=0.28507786989212036
[15/24] Train loss=0.23417888581752777
[20/24] Train loss=0.2612210810184479
Test set avg_accuracy=84.95% avg_sensitivity=65.28%, avg_specificity=91.65% avg_auc=90.38%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.267738 Test loss=0.335046 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.2666096091270447
[5/24] Train loss=0.24649836122989655
[10/24] Train loss=0.2842404842376709
[15/24] Train loss=0.23471713066101074
[20/24] Train loss=0.26326775550842285
Test set avg_accuracy=84.97% avg_sensitivity=65.39%, avg_specificity=91.65% avg_auc=90.38%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.268392 Test loss=0.335003 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.2629295289516449
[5/24] Train loss=0.24276098608970642
[10/24] Train loss=0.2840835154056549
[15/24] Train loss=0.23389270901679993
[20/24] Train loss=0.2621839940547943
Test set avg_accuracy=85.00% avg_sensitivity=65.44%, avg_specificity=91.67% avg_auc=90.38%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.267728 Test loss=0.335011 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.2637591063976288
[5/24] Train loss=0.2440260648727417
[10/24] Train loss=0.28542962670326233
[15/24] Train loss=0.23451678454875946
[20/24] Train loss=0.26268336176872253
Test set avg_accuracy=84.92% avg_sensitivity=65.08%, avg_specificity=91.69% avg_auc=90.38%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.267563 Test loss=0.335010 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.26233309507369995
[5/24] Train loss=0.24329683184623718
[10/24] Train loss=0.2854827046394348
[15/24] Train loss=0.2316894680261612
[20/24] Train loss=0.2595555782318115
Test set avg_accuracy=84.92% avg_sensitivity=65.08%, avg_specificity=91.69% avg_auc=90.38%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.267815 Test loss=0.335013 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.2659622132778168
[5/24] Train loss=0.2442837357521057
[10/24] Train loss=0.2846825420856476
[15/24] Train loss=0.2325160950422287
[20/24] Train loss=0.2598918080329895
Test set avg_accuracy=84.93% avg_sensitivity=65.13%, avg_specificity=91.69% avg_auc=90.38%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.267912 Test loss=0.335021 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.26099422574043274
[5/24] Train loss=0.2411116361618042
[10/24] Train loss=0.2859257757663727
[15/24] Train loss=0.23253725469112396
[20/24] Train loss=0.25951331853866577
Test set avg_accuracy=84.93% avg_sensitivity=65.34%, avg_specificity=91.62% avg_auc=90.38%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.267445 Test loss=0.335024 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.2629356384277344
[5/24] Train loss=0.2443319708108902
[10/24] Train loss=0.28250065445899963
[15/24] Train loss=0.23312745988368988
[20/24] Train loss=0.2612873315811157
Test set avg_accuracy=84.96% avg_sensitivity=65.28%, avg_specificity=91.67% avg_auc=90.38%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.267508 Test loss=0.335017 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.2653407156467438
[5/24] Train loss=0.24261733889579773
[10/24] Train loss=0.2834046185016632
[15/24] Train loss=0.23294906318187714
[20/24] Train loss=0.260240763425827
Test set avg_accuracy=84.91% avg_sensitivity=65.03%, avg_specificity=91.69% avg_auc=90.38%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.267988 Test loss=0.335007 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.2607964873313904
[5/24] Train loss=0.24235300719738007
[10/24] Train loss=0.2822932004928589
[15/24] Train loss=0.23362112045288086
[20/24] Train loss=0.2603771388530731
Test set avg_accuracy=84.90% avg_sensitivity=64.98%, avg_specificity=91.69% avg_auc=90.38%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.267392 Test loss=0.335000 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.2651282250881195
[5/24] Train loss=0.23744326829910278
[10/24] Train loss=0.28488820791244507
[15/24] Train loss=0.23371033370494843
[20/24] Train loss=0.25929850339889526
Test set avg_accuracy=84.92% avg_sensitivity=64.98%, avg_specificity=91.72% avg_auc=90.38%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.267142 Test loss=0.334997 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.26230588555336
[5/24] Train loss=0.24226535856723785
[10/24] Train loss=0.2855856120586395
[15/24] Train loss=0.2348289042711258
[20/24] Train loss=0.2592611014842987
Test set avg_accuracy=84.95% avg_sensitivity=64.98%, avg_specificity=91.76% avg_auc=90.38%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.267313 Test loss=0.334996 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.2641408145427704
[5/24] Train loss=0.24434952437877655
[10/24] Train loss=0.2849833071231842
[15/24] Train loss=0.23335734009742737
[20/24] Train loss=0.2618342339992523
Test set avg_accuracy=84.95% avg_sensitivity=64.98%, avg_specificity=91.76% avg_auc=90.38%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.267940 Test loss=0.334996 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.25984540581703186
[5/24] Train loss=0.2449655681848526
[10/24] Train loss=0.2818090617656708
[15/24] Train loss=0.23493652045726776
[20/24] Train loss=0.25986894965171814
Test set avg_accuracy=84.95% avg_sensitivity=64.98%, avg_specificity=91.76% avg_auc=90.38%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.267168 Test loss=0.334996 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=84.80% sen=66.87%, spe=90.92%, auc=90.39%!
Fold[5] Avg_jsc=0.56%(±0.2685151013846872)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.8923979997634888
[5/24] Train loss=0.8117527365684509
[10/24] Train loss=0.7599461078643799
[15/24] Train loss=0.7069775462150574
[20/24] Train loss=0.69415682554245
Test set avg_accuracy=66.80% avg_sensitivity=11.52%, avg_specificity=87.38% avg_auc=50.29%
Best model saved!! Metric=50.28963998139609!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.762124 Test loss=0.642852 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6614742279052734
[5/24] Train loss=0.636006772518158
[10/24] Train loss=0.6383520364761353
[15/24] Train loss=0.6166051626205444
[20/24] Train loss=0.6316214203834534
Test set avg_accuracy=71.42% avg_sensitivity=1.87%, avg_specificity=97.32% avg_auc=52.73%
Best model saved!! Metric=52.7323465211647!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.639016 Test loss=0.612272 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6251856684684753
[5/24] Train loss=0.6066610813140869
[10/24] Train loss=0.6064708828926086
[15/24] Train loss=0.5942235589027405
[20/24] Train loss=0.6085336208343506
Test set avg_accuracy=72.12% avg_sensitivity=1.34%, avg_specificity=98.48% avg_auc=55.62%
Best model saved!! Metric=55.62282971522022!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.614021 Test loss=0.599297 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.606117308139801
[5/24] Train loss=0.5939528942108154
[10/24] Train loss=0.5868890285491943
[15/24] Train loss=0.5801347494125366
[20/24] Train loss=0.5919045805931091
Test set avg_accuracy=72.33% avg_sensitivity=1.44%, avg_specificity=98.73% avg_auc=58.08%
Best model saved!! Metric=58.08053788763292!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.598884 Test loss=0.584832 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5914044976234436
[5/24] Train loss=0.5823491215705872
[10/24] Train loss=0.5917819738388062
[15/24] Train loss=0.5790513753890991
[20/24] Train loss=0.5934771299362183
Test set avg_accuracy=72.49% avg_sensitivity=1.54%, avg_specificity=98.91% avg_auc=60.39%
Best model saved!! Metric=60.38651048390747!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.591340 Test loss=0.575478 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5934270620346069
[5/24] Train loss=0.575772762298584
[10/24] Train loss=0.5848152041435242
[15/24] Train loss=0.570770263671875
[20/24] Train loss=0.5831866264343262
Test set avg_accuracy=72.64% avg_sensitivity=1.63%, avg_specificity=99.09% avg_auc=62.68%
Best model saved!! Metric=62.67923928388662!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.581542 Test loss=0.569271 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5807150602340698
[5/24] Train loss=0.5654681324958801
[10/24] Train loss=0.5682605504989624
[15/24] Train loss=0.5545490384101868
[20/24] Train loss=0.5656192898750305
Test set avg_accuracy=72.66% avg_sensitivity=1.39%, avg_specificity=99.20% avg_auc=65.11%
Best model saved!! Metric=65.1094180241165!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.574179 Test loss=0.562156 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5744837522506714
[5/24] Train loss=0.563895046710968
[10/24] Train loss=0.5657645463943481
[15/24] Train loss=0.5514426231384277
[20/24] Train loss=0.5661753416061401
Test set avg_accuracy=72.63% avg_sensitivity=1.44%, avg_specificity=99.14% avg_auc=67.72%
Best model saved!! Metric=67.72191011814033!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.568100 Test loss=0.555009 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5614830851554871
[5/24] Train loss=0.5527543425559998
[10/24] Train loss=0.5638131499290466
[15/24] Train loss=0.5412375926971436
[20/24] Train loss=0.5528035759925842
Test set avg_accuracy=72.77% avg_sensitivity=2.16%, avg_specificity=99.07% avg_auc=70.36%
Best model saved!! Metric=70.35927774020105!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.559180 Test loss=0.546425 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5532174110412598
[5/24] Train loss=0.5443403124809265
[10/24] Train loss=0.5529346466064453
[15/24] Train loss=0.5297808647155762
[20/24] Train loss=0.5354620814323425
Test set avg_accuracy=72.80% avg_sensitivity=3.31%, avg_specificity=98.68% avg_auc=72.97%
Best model saved!! Metric=72.96629910451529!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.552643 Test loss=0.535668 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5434569120407104
[5/24] Train loss=0.5327773094177246
[10/24] Train loss=0.5413107872009277
[15/24] Train loss=0.5062007308006287
[20/24] Train loss=0.529533326625824
Test set avg_accuracy=73.15% avg_sensitivity=7.25%, avg_specificity=97.69% avg_auc=75.32%
Best model saved!! Metric=75.32075797217371!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.539476 Test loss=0.522686 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5302891731262207
[5/24] Train loss=0.5145458579063416
[10/24] Train loss=0.5300355553627014
[15/24] Train loss=0.4909915030002594
[20/24] Train loss=0.5128845572471619
Test set avg_accuracy=73.33% avg_sensitivity=11.61%, avg_specificity=96.32% avg_auc=77.30%
Best model saved!! Metric=77.29780937576744!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.527518 Test loss=0.507356 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5088133811950684
[5/24] Train loss=0.5123474597930908
[10/24] Train loss=0.5179117918014526
[15/24] Train loss=0.4761786162853241
[20/24] Train loss=0.4879361689090729
Test set avg_accuracy=73.76% avg_sensitivity=14.54%, avg_specificity=95.82% avg_auc=78.99%
Best model saved!! Metric=78.99256941138377!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.513000 Test loss=0.493894 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.49210017919540405
[5/24] Train loss=0.491304486989975
[10/24] Train loss=0.495516836643219
[15/24] Train loss=0.45582258701324463
[20/24] Train loss=0.4754922389984131
Test set avg_accuracy=75.04% avg_sensitivity=22.79%, avg_specificity=94.50% avg_auc=80.81%
Best model saved!! Metric=80.80742396886177!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.494073 Test loss=0.472835 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.46491193771362305
[5/24] Train loss=0.4564826488494873
[10/24] Train loss=0.4802330732345581
[15/24] Train loss=0.42432674765586853
[20/24] Train loss=0.45072177052497864
Test set avg_accuracy=77.50% avg_sensitivity=37.86%, avg_specificity=92.26% avg_auc=82.28%
Best model saved!! Metric=82.2799591907573!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.475828 Test loss=0.450575 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4470750689506531
[5/24] Train loss=0.45955413579940796
[10/24] Train loss=0.4625345468521118
[15/24] Train loss=0.42092955112457275
[20/24] Train loss=0.4452582597732544
Test set avg_accuracy=78.66% avg_sensitivity=49.42%, avg_specificity=89.55% avg_auc=83.42%
Best model saved!! Metric=83.42191828136085!!
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.460958 Test loss=0.435691 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4394189715385437
[5/24] Train loss=0.43918225169181824
[10/24] Train loss=0.4538522958755493
[15/24] Train loss=0.397145539522171
[20/24] Train loss=0.4212583005428314
Test set avg_accuracy=79.52% avg_sensitivity=56.05%, avg_specificity=88.26% avg_auc=84.33%
Best model saved!! Metric=84.33266615583656!!
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.448851 Test loss=0.425225 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4290332496166229
[5/24] Train loss=0.43794190883636475
[10/24] Train loss=0.4521569311618805
[15/24] Train loss=0.39086082577705383
[20/24] Train loss=0.4065187871456146
Test set avg_accuracy=80.07% avg_sensitivity=56.91%, avg_specificity=88.69% avg_auc=84.94%
Best model saved!! Metric=84.93559116122155!!
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.438642 Test loss=0.416856 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4173342287540436
[5/24] Train loss=0.4361446499824524
[10/24] Train loss=0.447601318359375
[15/24] Train loss=0.38883453607559204
[20/24] Train loss=0.391017347574234
Test set avg_accuracy=80.18% avg_sensitivity=56.19%, avg_specificity=89.12% avg_auc=85.37%
Best model saved!! Metric=85.36691275232242!!
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.431722 Test loss=0.410643 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.40536627173423767
[5/24] Train loss=0.4191147983074188
[10/24] Train loss=0.43388631939888
[15/24] Train loss=0.3824751675128937
[20/24] Train loss=0.3909282684326172
Test set avg_accuracy=80.65% avg_sensitivity=55.61%, avg_specificity=89.97% avg_auc=85.67%
Best model saved!! Metric=85.67257048152025!!
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.424776 Test loss=0.406327 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.39457806944847107
[5/24] Train loss=0.41352301836013794
[10/24] Train loss=0.4278499186038971
[15/24] Train loss=0.37994468212127686
[20/24] Train loss=0.3817097544670105
Test set avg_accuracy=80.91% avg_sensitivity=54.22%, avg_specificity=90.85% avg_auc=85.95%
Best model saved!! Metric=85.94911672582143!!
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.418744 Test loss=0.403167 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.38579046726226807
[5/24] Train loss=0.4020053446292877
[10/24] Train loss=0.4203764796257019
[15/24] Train loss=0.37094834446907043
[20/24] Train loss=0.3749006390571594
Test set avg_accuracy=80.92% avg_sensitivity=50.77%, avg_specificity=92.16% avg_auc=86.09%
Best model saved!! Metric=86.08536190506243!!
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.411112 Test loss=0.403966 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3822769224643707
[5/24] Train loss=0.3920005261898041
[10/24] Train loss=0.4064193069934845
[15/24] Train loss=0.36638498306274414
[20/24] Train loss=0.3773074746131897
Test set avg_accuracy=81.12% avg_sensitivity=51.10%, avg_specificity=92.30% avg_auc=86.25%
Best model saved!! Metric=86.25476588020781!!
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.406159 Test loss=0.401862 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3774303197860718
[5/24] Train loss=0.38285815715789795
[10/24] Train loss=0.39965760707855225
[15/24] Train loss=0.35527127981185913
[20/24] Train loss=0.37270841002464294
Test set avg_accuracy=81.58% avg_sensitivity=53.74%, avg_specificity=91.94% avg_auc=86.54%
Best model saved!! Metric=86.53607114486766!!
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.400522 Test loss=0.396894 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.37429189682006836
[5/24] Train loss=0.3729361593723297
[10/24] Train loss=0.39454832673072815
[15/24] Train loss=0.35116690397262573
[20/24] Train loss=0.3704110085964203
Test set avg_accuracy=81.39% avg_sensitivity=49.71%, avg_specificity=93.19% avg_auc=86.76%
Best model saved!! Metric=86.75606650760965!!
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.397803 Test loss=0.397051 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3740798532962799
[5/24] Train loss=0.369714617729187
[10/24] Train loss=0.3968782126903534
[15/24] Train loss=0.350400447845459
[20/24] Train loss=0.3668171167373657
Test set avg_accuracy=81.43% avg_sensitivity=48.85%, avg_specificity=93.57% avg_auc=87.00%
Best model saved!! Metric=87.00489896128164!!
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.398535 Test loss=0.394337 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3719879388809204
[5/24] Train loss=0.3713625371456146
[10/24] Train loss=0.38819149136543274
[15/24] Train loss=0.3442721962928772
[20/24] Train loss=0.36415547132492065
Test set avg_accuracy=81.76% avg_sensitivity=50.43%, avg_specificity=93.42% avg_auc=87.22%
Best model saved!! Metric=87.22064979235236!!
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.395092 Test loss=0.390435 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3720541000366211
[5/24] Train loss=0.37317514419555664
[10/24] Train loss=0.3908575773239136
[15/24] Train loss=0.34284842014312744
[20/24] Train loss=0.36572349071502686
Test set avg_accuracy=81.67% avg_sensitivity=48.66%, avg_specificity=93.96% avg_auc=87.34%
Best model saved!! Metric=87.34010549076046!!
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.393154 Test loss=0.390448 Current lr=[0.000210185142098938]

[0/24] Train loss=0.366751104593277
[5/24] Train loss=0.37065985798835754
[10/24] Train loss=0.3909488916397095
[15/24] Train loss=0.3405473232269287
[20/24] Train loss=0.3553926646709442
Test set avg_accuracy=81.51% avg_sensitivity=45.25%, avg_specificity=95.01% avg_auc=87.54%
Best model saved!! Metric=87.53842373013902!!
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.390395 Test loss=0.392113 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.37095966935157776
[5/24] Train loss=0.36716049909591675
[10/24] Train loss=0.3882462978363037
[15/24] Train loss=0.33824974298477173
[20/24] Train loss=0.35211968421936035
Test set avg_accuracy=81.80% avg_sensitivity=46.69%, avg_specificity=94.87% avg_auc=87.64%
Best model saved!! Metric=87.64357664303677!!
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.388241 Test loss=0.389796 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3695426881313324
[5/24] Train loss=0.36535388231277466
[10/24] Train loss=0.3827956020832062
[15/24] Train loss=0.33518651127815247
[20/24] Train loss=0.35403430461883545
Test set avg_accuracy=81.26% avg_sensitivity=42.08%, avg_specificity=95.85% avg_auc=87.76%
Best model saved!! Metric=87.75618964190214!!
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.386081 Test loss=0.396543 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.371169775724411
[5/24] Train loss=0.3628571927547455
[10/24] Train loss=0.3782760798931122
[15/24] Train loss=0.3340182900428772
[20/24] Train loss=0.3470368981361389
Test set avg_accuracy=81.50% avg_sensitivity=42.99%, avg_specificity=95.84% avg_auc=87.81%
Best model saved!! Metric=87.8116343727834!!
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.383388 Test loss=0.394155 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3701564371585846
[5/24] Train loss=0.36445727944374084
[10/24] Train loss=0.3800513744354248
[15/24] Train loss=0.33412617444992065
[20/24] Train loss=0.34341248869895935
Test set avg_accuracy=81.12% avg_sensitivity=40.36%, avg_specificity=96.30% avg_auc=87.94%
Best model saved!! Metric=87.94474117103113!!
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.380925 Test loss=0.398827 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3792564570903778
[5/24] Train loss=0.36235642433166504
[10/24] Train loss=0.3731544613838196
[15/24] Train loss=0.33541038632392883
[20/24] Train loss=0.3417625427246094
Test set avg_accuracy=81.22% avg_sensitivity=40.26%, avg_specificity=96.48% avg_auc=88.06%
Best model saved!! Metric=88.05596076303473!!
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.379034 Test loss=0.397911 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.37466052174568176
[5/24] Train loss=0.3565719723701477
[10/24] Train loss=0.37424758076667786
[15/24] Train loss=0.32766419649124146
[20/24] Train loss=0.33814385533332825
Test set avg_accuracy=81.24% avg_sensitivity=40.07%, avg_specificity=96.57% avg_auc=88.16%
Best model saved!! Metric=88.15880276424484!!
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.375364 Test loss=0.398103 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.37893691658973694
[5/24] Train loss=0.3525039255619049
[10/24] Train loss=0.3718068301677704
[15/24] Train loss=0.3299158811569214
[20/24] Train loss=0.34056442975997925
Test set avg_accuracy=81.50% avg_sensitivity=41.07%, avg_specificity=96.55% avg_auc=88.23%
Best model saved!! Metric=88.22531757671712!!
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.372287 Test loss=0.395821 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3787256181240082
[5/24] Train loss=0.3498106896877289
[10/24] Train loss=0.3748857378959656
[15/24] Train loss=0.3282991647720337
[20/24] Train loss=0.34377697110176086
Test set avg_accuracy=81.16% avg_sensitivity=38.68%, avg_specificity=96.98% avg_auc=88.27%
Best model saved!! Metric=88.26878329599288!!
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.371542 Test loss=0.402683 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3799268305301666
[5/24] Train loss=0.35108262300491333
[10/24] Train loss=0.3780915439128876
[15/24] Train loss=0.3320663273334503
[20/24] Train loss=0.3344571590423584
Test set avg_accuracy=81.72% avg_sensitivity=41.65%, avg_specificity=96.64% avg_auc=88.42%
Best model saved!! Metric=88.42036881293055!!
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.369416 Test loss=0.394014 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.37383291125297546
[5/24] Train loss=0.3476533889770508
[10/24] Train loss=0.3723834753036499
[15/24] Train loss=0.32212889194488525
[20/24] Train loss=0.33358681201934814
Test set avg_accuracy=80.91% avg_sensitivity=37.14%, avg_specificity=97.21% avg_auc=88.43%
Best model saved!! Metric=88.42847200975746!!
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.366007 Test loss=0.408125 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3873614966869354
[5/24] Train loss=0.3478529155254364
[10/24] Train loss=0.37312793731689453
[15/24] Train loss=0.32113462686538696
[20/24] Train loss=0.33320847153663635
Test set avg_accuracy=81.77% avg_sensitivity=41.36%, avg_specificity=96.82% avg_auc=88.62%
Best model saved!! Metric=88.61552294688144!!
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.366647 Test loss=0.393232 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3699226975440979
[5/24] Train loss=0.3423081934452057
[10/24] Train loss=0.3715459108352661
[15/24] Train loss=0.3255632519721985
[20/24] Train loss=0.33029913902282715
Test set avg_accuracy=81.95% avg_sensitivity=42.08%, avg_specificity=96.80% avg_auc=88.61%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.362934 Test loss=0.392076 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.37097683548927307
[5/24] Train loss=0.34257516264915466
[10/24] Train loss=0.374542772769928
[15/24] Train loss=0.31818848848342896
[20/24] Train loss=0.3280712366104126
Test set avg_accuracy=81.65% avg_sensitivity=40.69%, avg_specificity=96.91% avg_auc=88.64%
Best model saved!! Metric=88.6371743458105!!
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.361296 Test loss=0.396579 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.37604498863220215
[5/24] Train loss=0.34235721826553345
[10/24] Train loss=0.36226269602775574
[15/24] Train loss=0.31638476252555847
[20/24] Train loss=0.32558563351631165
Test set avg_accuracy=81.67% avg_sensitivity=40.07%, avg_specificity=97.16% avg_auc=88.66%
Best model saved!! Metric=88.65822122053181!!
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.361326 Test loss=0.398305 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.37964218854904175
[5/24] Train loss=0.3396108150482178
[10/24] Train loss=0.36971285939216614
[15/24] Train loss=0.3191791772842407
[20/24] Train loss=0.32825231552124023
Test set avg_accuracy=82.19% avg_sensitivity=43.57%, avg_specificity=96.57% avg_auc=88.75%
Best model saved!! Metric=88.74853542220312!!
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.359908 Test loss=0.388553 Current lr=[0.00029967723776099]

[0/24] Train loss=0.36434707045555115
[5/24] Train loss=0.33524057269096375
[10/24] Train loss=0.3591110110282898
[15/24] Train loss=0.31705254316329956
[20/24] Train loss=0.3269192576408386
Test set avg_accuracy=82.16% avg_sensitivity=43.04%, avg_specificity=96.73% avg_auc=88.81%
Best model saved!! Metric=88.8064754232184!!
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.357047 Test loss=0.388343 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.360513836145401
[5/24] Train loss=0.3349635899066925
[10/24] Train loss=0.35468581318855286
[15/24] Train loss=0.314893513917923
[20/24] Train loss=0.3236337900161743
Test set avg_accuracy=82.08% avg_sensitivity=42.66%, avg_specificity=96.77% avg_auc=88.78%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.353681 Test loss=0.390241 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3671072721481323
[5/24] Train loss=0.3302229046821594
[10/24] Train loss=0.35850274562835693
[15/24] Train loss=0.3092699944972992
[20/24] Train loss=0.32222235202789307
Test set avg_accuracy=82.03% avg_sensitivity=41.75%, avg_specificity=97.03% avg_auc=88.81%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.353308 Test loss=0.393513 Current lr=[0.000299720220882401]

[0/24] Train loss=0.36617952585220337
[5/24] Train loss=0.3296109139919281
[10/24] Train loss=0.35592177510261536
[15/24] Train loss=0.3071567416191101
[20/24] Train loss=0.32882824540138245
Test set avg_accuracy=82.37% avg_sensitivity=43.86%, avg_specificity=96.71% avg_auc=88.85%
Best model saved!! Metric=88.84502348812353!!
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.351178 Test loss=0.385425 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3629375100135803
[5/24] Train loss=0.32701677083969116
[10/24] Train loss=0.3560533821582794
[15/24] Train loss=0.31072700023651123
[20/24] Train loss=0.31927382946014404
Test set avg_accuracy=82.75% avg_sensitivity=45.68%, avg_specificity=96.55% avg_auc=88.98%
Best model saved!! Metric=88.98483150152497!!
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.348948 Test loss=0.381409 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3521997034549713
[5/24] Train loss=0.3307119607925415
[10/24] Train loss=0.35108479857444763
[15/24] Train loss=0.30902475118637085
[20/24] Train loss=0.32364803552627563
Test set avg_accuracy=82.75% avg_sensitivity=45.63%, avg_specificity=96.57% avg_auc=88.99%
Best model saved!! Metric=88.98772121298597!!
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.349349 Test loss=0.381205 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.351130872964859
[5/24] Train loss=0.3278811275959015
[10/24] Train loss=0.34757018089294434
[15/24] Train loss=0.3046320378780365
[20/24] Train loss=0.3175910413265228
Test set avg_accuracy=83.06% avg_sensitivity=46.88%, avg_specificity=96.53% avg_auc=89.03%
Best model saved!! Metric=89.02514597759024!!
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.346871 Test loss=0.379068 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3484683930873871
[5/24] Train loss=0.3210875988006592
[10/24] Train loss=0.34839820861816406
[15/24] Train loss=0.30620497465133667
[20/24] Train loss=0.3202451765537262
Test set avg_accuracy=82.84% avg_sensitivity=45.54%, avg_specificity=96.73% avg_auc=89.03%
Best model saved!! Metric=89.03110118414716!!
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.345862 Test loss=0.382099 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.35447850823402405
[5/24] Train loss=0.3215094804763794
[10/24] Train loss=0.34510448575019836
[15/24] Train loss=0.30763325095176697
[20/24] Train loss=0.3187699615955353
Test set avg_accuracy=83.07% avg_sensitivity=48.42%, avg_specificity=95.98% avg_auc=88.97%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.344478 Test loss=0.375080 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3458256721496582
[5/24] Train loss=0.3243851065635681
[10/24] Train loss=0.3396347165107727
[15/24] Train loss=0.29951295256614685
[20/24] Train loss=0.3110354542732239
Test set avg_accuracy=83.14% avg_sensitivity=48.08%, avg_specificity=96.19% avg_auc=89.01%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.342159 Test loss=0.377188 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.34823906421661377
[5/24] Train loss=0.32172712683677673
[10/24] Train loss=0.3412841558456421
[15/24] Train loss=0.3015230894088745
[20/24] Train loss=0.3138978183269501
Test set avg_accuracy=83.15% avg_sensitivity=48.42%, avg_specificity=96.09% avg_auc=89.04%
Best model saved!! Metric=89.03865559304082!!
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.340962 Test loss=0.374964 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.34921276569366455
[5/24] Train loss=0.31879374384880066
[10/24] Train loss=0.338945597410202
[15/24] Train loss=0.305065393447876
[20/24] Train loss=0.31054720282554626
Test set avg_accuracy=83.32% avg_sensitivity=48.61%, avg_specificity=96.25% avg_auc=89.05%
Best model saved!! Metric=89.05187795230759!!
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.341025 Test loss=0.376166 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3491564691066742
[5/24] Train loss=0.31610533595085144
[10/24] Train loss=0.3405006527900696
[15/24] Train loss=0.2987421154975891
[20/24] Train loss=0.30835413932800293
Test set avg_accuracy=83.29% avg_sensitivity=48.75%, avg_specificity=96.16% avg_auc=89.10%
Best model saved!! Metric=89.10159470913553!!
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.338809 Test loss=0.375852 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.34539568424224854
[5/24] Train loss=0.31750670075416565
[10/24] Train loss=0.33325251936912537
[15/24] Train loss=0.3004051446914673
[20/24] Train loss=0.3201683759689331
Test set avg_accuracy=83.52% avg_sensitivity=50.38%, avg_specificity=95.85% avg_auc=89.03%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.337958 Test loss=0.371538 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.34070658683776855
[5/24] Train loss=0.31055542826652527
[10/24] Train loss=0.33521538972854614
[15/24] Train loss=0.2969817519187927
[20/24] Train loss=0.30714741349220276
Test set avg_accuracy=83.57% avg_sensitivity=50.14%, avg_specificity=96.02% avg_auc=89.12%
Best model saved!! Metric=89.11955893913805!!
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.336760 Test loss=0.372342 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.33940327167510986
[5/24] Train loss=0.306497186422348
[10/24] Train loss=0.3388381600379944
[15/24] Train loss=0.2962922155857086
[20/24] Train loss=0.3091197609901428
Test set avg_accuracy=83.49% avg_sensitivity=49.71%, avg_specificity=96.07% avg_auc=89.16%
Best model saved!! Metric=89.15533305253685!!
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.336071 Test loss=0.372674 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3449361324310303
[5/24] Train loss=0.31372806429862976
[10/24] Train loss=0.33650487661361694
[15/24] Train loss=0.2987235486507416
[20/24] Train loss=0.316454142332077
Test set avg_accuracy=83.75% avg_sensitivity=52.21%, avg_specificity=95.50% avg_auc=89.15%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.337107 Test loss=0.367882 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.33609142899513245
[5/24] Train loss=0.30875036120414734
[10/24] Train loss=0.3305351436138153
[15/24] Train loss=0.29652315378189087
[20/24] Train loss=0.3068760633468628
Test set avg_accuracy=83.95% avg_sensitivity=54.56%, avg_specificity=94.89% avg_auc=89.13%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.334914 Test loss=0.364917 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.32659855484962463
[5/24] Train loss=0.30598145723342896
[10/24] Train loss=0.33567190170288086
[15/24] Train loss=0.30190837383270264
[20/24] Train loss=0.3107261061668396
Test set avg_accuracy=83.98% avg_sensitivity=54.56%, avg_specificity=94.94% avg_auc=89.17%
Best model saved!! Metric=89.173365881031!!
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.331990 Test loss=0.364015 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.32873231172561646
[5/24] Train loss=0.30572256445884705
[10/24] Train loss=0.32916802167892456
[15/24] Train loss=0.29041630029678345
[20/24] Train loss=0.30969393253326416
Test set avg_accuracy=83.78% avg_sensitivity=52.78%, avg_specificity=95.32% avg_auc=89.26%
Best model saved!! Metric=89.26372724416534!!
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.331924 Test loss=0.366110 Current lr=[0.000276307469034998]

[0/24] Train loss=0.34086328744888306
[5/24] Train loss=0.30883175134658813
[10/24] Train loss=0.3273662030696869
[15/24] Train loss=0.2954443097114563
[20/24] Train loss=0.3082961440086365
Test set avg_accuracy=84.15% avg_sensitivity=56.19%, avg_specificity=94.57% avg_auc=89.25%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.331698 Test loss=0.361292 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3321511149406433
[5/24] Train loss=0.30040469765663147
[10/24] Train loss=0.32477954030036926
[15/24] Train loss=0.2971735894680023
[20/24] Train loss=0.3075932264328003
Test set avg_accuracy=84.01% avg_sensitivity=55.52%, avg_specificity=94.62% avg_auc=89.22%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.329717 Test loss=0.362243 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3263578414916992
[5/24] Train loss=0.2999114692211151
[10/24] Train loss=0.32771411538124084
[15/24] Train loss=0.2920210659503937
[20/24] Train loss=0.30663180351257324
Test set avg_accuracy=83.95% avg_sensitivity=53.84%, avg_specificity=95.16% avg_auc=89.23%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.328336 Test loss=0.364558 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3342459499835968
[5/24] Train loss=0.3051548898220062
[10/24] Train loss=0.32054978609085083
[15/24] Train loss=0.2889639139175415
[20/24] Train loss=0.3112806975841522
Test set avg_accuracy=84.13% avg_sensitivity=57.15%, avg_specificity=94.17% avg_auc=89.21%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.328765 Test loss=0.360437 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3279324471950531
[5/24] Train loss=0.30638477206230164
[10/24] Train loss=0.3179570436477661
[15/24] Train loss=0.29309770464897156
[20/24] Train loss=0.3048303425312042
Test set avg_accuracy=84.10% avg_sensitivity=58.59%, avg_specificity=93.60% avg_auc=89.25%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.327186 Test loss=0.358779 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3263084292411804
[5/24] Train loss=0.30404385924339294
[10/24] Train loss=0.3218790292739868
[15/24] Train loss=0.2869226038455963
[20/24] Train loss=0.30365923047065735
Test set avg_accuracy=83.91% avg_sensitivity=55.81%, avg_specificity=94.37% avg_auc=89.21%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.327673 Test loss=0.360666 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3269680440425873
[5/24] Train loss=0.30184444785118103
[10/24] Train loss=0.3232252597808838
[15/24] Train loss=0.2856631875038147
[20/24] Train loss=0.3056671917438507
Test set avg_accuracy=84.15% avg_sensitivity=57.44%, avg_specificity=94.10% avg_auc=89.24%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.326459 Test loss=0.360230 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3270621597766876
[5/24] Train loss=0.2986392378807068
[10/24] Train loss=0.3216143548488617
[15/24] Train loss=0.28979018330574036
[20/24] Train loss=0.3076508343219757
Test set avg_accuracy=83.93% avg_sensitivity=58.16%, avg_specificity=93.53% avg_auc=89.22%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.326808 Test loss=0.359063 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3279073238372803
[5/24] Train loss=0.2978781461715698
[10/24] Train loss=0.31086185574531555
[15/24] Train loss=0.2894607186317444
[20/24] Train loss=0.3006938099861145
Test set avg_accuracy=83.87% avg_sensitivity=56.05%, avg_specificity=94.23% avg_auc=89.20%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.324435 Test loss=0.362391 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.33091261982917786
[5/24] Train loss=0.30019742250442505
[10/24] Train loss=0.3136247396469116
[15/24] Train loss=0.2896365225315094
[20/24] Train loss=0.2956180274486542
Test set avg_accuracy=83.89% avg_sensitivity=58.25%, avg_specificity=93.44% avg_auc=89.21%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.324231 Test loss=0.359843 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3235103189945221
[5/24] Train loss=0.2915390729904175
[10/24] Train loss=0.3168553411960602
[15/24] Train loss=0.2863471508026123
[20/24] Train loss=0.29507771134376526
Test set avg_accuracy=84.01% avg_sensitivity=58.59%, avg_specificity=93.48% avg_auc=89.21%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.323463 Test loss=0.359246 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.32572272419929504
[5/24] Train loss=0.296421617269516
[10/24] Train loss=0.3117350935935974
[15/24] Train loss=0.2866460084915161
[20/24] Train loss=0.29833847284317017
Test set avg_accuracy=84.02% avg_sensitivity=59.12%, avg_specificity=93.30% avg_auc=89.30%
Best model saved!! Metric=89.29571986571159!!
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.322327 Test loss=0.358169 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3290051221847534
[5/24] Train loss=0.29820716381073
[10/24] Train loss=0.3115670084953308
[15/24] Train loss=0.28687426447868347
[20/24] Train loss=0.2977583706378937
Test set avg_accuracy=83.87% avg_sensitivity=57.44%, avg_specificity=93.71% avg_auc=89.28%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.323032 Test loss=0.359250 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3239254951477051
[5/24] Train loss=0.2996884286403656
[10/24] Train loss=0.3069101572036743
[15/24] Train loss=0.28250595927238464
[20/24] Train loss=0.2991151511669159
Test set avg_accuracy=84.01% avg_sensitivity=58.35%, avg_specificity=93.57% avg_auc=89.23%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.322432 Test loss=0.359698 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3216991722583771
[5/24] Train loss=0.2948986887931824
[10/24] Train loss=0.31697091460227966
[15/24] Train loss=0.2857730984687805
[20/24] Train loss=0.2905389964580536
Test set avg_accuracy=83.87% avg_sensitivity=57.68%, avg_specificity=93.62% avg_auc=89.23%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.322630 Test loss=0.360752 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3198094666004181
[5/24] Train loss=0.2974694073200226
[10/24] Train loss=0.31693726778030396
[15/24] Train loss=0.2793789505958557
[20/24] Train loss=0.2887945771217346
Test set avg_accuracy=83.92% avg_sensitivity=59.26%, avg_specificity=93.10% avg_auc=89.28%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.323176 Test loss=0.358310 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3244021236896515
[5/24] Train loss=0.2951046824455261
[10/24] Train loss=0.32622194290161133
[15/24] Train loss=0.28429487347602844
[20/24] Train loss=0.2954338788986206
Test set avg_accuracy=83.87% avg_sensitivity=68.52%, avg_specificity=89.58% avg_auc=89.16%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.327948 Test loss=0.360102 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.31440597772598267
[5/24] Train loss=0.30073124170303345
[10/24] Train loss=0.3143070936203003
[15/24] Train loss=0.2898149788379669
[20/24] Train loss=0.3200705349445343
Test set avg_accuracy=83.05% avg_sensitivity=73.66%, avg_specificity=86.54% avg_auc=89.07%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.329402 Test loss=0.372154 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3165942132472992
[5/24] Train loss=0.3005363643169403
[10/24] Train loss=0.31650641560554504
[15/24] Train loss=0.2828204929828644
[20/24] Train loss=0.31439778208732605
Test set avg_accuracy=83.32% avg_sensitivity=72.02%, avg_specificity=87.53% avg_auc=89.02%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.324695 Test loss=0.368943 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3143695890903473
[5/24] Train loss=0.2991746962070465
[10/24] Train loss=0.314727246761322
[15/24] Train loss=0.2828511893749237
[20/24] Train loss=0.3045027554035187
Test set avg_accuracy=83.40% avg_sensitivity=71.74%, avg_specificity=87.74% avg_auc=89.00%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.322283 Test loss=0.369034 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.30797499418258667
[5/24] Train loss=0.2938005030155182
[10/24] Train loss=0.31835806369781494
[15/24] Train loss=0.2808092534542084
[20/24] Train loss=0.3058887720108032
Test set avg_accuracy=83.24% avg_sensitivity=71.40%, avg_specificity=87.65% avg_auc=89.00%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.322854 Test loss=0.369023 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3109339773654938
[5/24] Train loss=0.2974577248096466
[10/24] Train loss=0.31362733244895935
[15/24] Train loss=0.28567594289779663
[20/24] Train loss=0.3018272817134857
Test set avg_accuracy=83.05% avg_sensitivity=71.45%, avg_specificity=87.37% avg_auc=88.97%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.321957 Test loss=0.370643 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3079085946083069
[5/24] Train loss=0.29806482791900635
[10/24] Train loss=0.31569451093673706
[15/24] Train loss=0.2832781672477722
[20/24] Train loss=0.3053533136844635
Test set avg_accuracy=82.89% avg_sensitivity=71.79%, avg_specificity=87.03% avg_auc=88.91%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.322290 Test loss=0.373068 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.30875372886657715
[5/24] Train loss=0.2972066104412079
[10/24] Train loss=0.31514301896095276
[15/24] Train loss=0.282130628824234
[20/24] Train loss=0.29949647188186646
Test set avg_accuracy=82.93% avg_sensitivity=71.50%, avg_specificity=87.19% avg_auc=88.95%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.320016 Test loss=0.371894 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.3039810359477997
[5/24] Train loss=0.2970649302005768
[10/24] Train loss=0.31532570719718933
[15/24] Train loss=0.2833006978034973
[20/24] Train loss=0.2944015860557556
Test set avg_accuracy=82.93% avg_sensitivity=71.88%, avg_specificity=87.04% avg_auc=88.91%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.318368 Test loss=0.372634 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3089021146297455
[5/24] Train loss=0.29855647683143616
[10/24] Train loss=0.3120940029621124
[15/24] Train loss=0.279680073261261
[20/24] Train loss=0.2989684045314789
Test set avg_accuracy=82.94% avg_sensitivity=71.93%, avg_specificity=87.04% avg_auc=88.89%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.319167 Test loss=0.373521 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.30853185057640076
[5/24] Train loss=0.2964802086353302
[10/24] Train loss=0.3134596645832062
[15/24] Train loss=0.2862524092197418
[20/24] Train loss=0.29528704285621643
Test set avg_accuracy=83.02% avg_sensitivity=71.31%, avg_specificity=87.38% avg_auc=88.91%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.319546 Test loss=0.371746 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.30400213599205017
[5/24] Train loss=0.2910867929458618
[10/24] Train loss=0.30939018726348877
[15/24] Train loss=0.28164443373680115
[20/24] Train loss=0.2972874343395233
Test set avg_accuracy=82.83% avg_sensitivity=73.08%, avg_specificity=86.45% avg_auc=88.94%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.318063 Test loss=0.375025 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3063003718852997
[5/24] Train loss=0.29955464601516724
[10/24] Train loss=0.3121446371078491
[15/24] Train loss=0.2896367013454437
[20/24] Train loss=0.2964453399181366
Test set avg_accuracy=82.88% avg_sensitivity=71.07%, avg_specificity=87.28% avg_auc=88.95%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.317850 Test loss=0.371043 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3113774061203003
[5/24] Train loss=0.2990373373031616
[10/24] Train loss=0.3171802759170532
[15/24] Train loss=0.2873057723045349
[20/24] Train loss=0.2878471612930298
Test set avg_accuracy=83.15% avg_sensitivity=70.39%, avg_specificity=87.90% avg_auc=88.99%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.317686 Test loss=0.369513 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3061392307281494
[5/24] Train loss=0.29797637462615967
[10/24] Train loss=0.3186239004135132
[15/24] Train loss=0.2794789671897888
[20/24] Train loss=0.2943542003631592
Test set avg_accuracy=82.99% avg_sensitivity=71.35%, avg_specificity=87.33% avg_auc=88.94%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.316419 Test loss=0.372129 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3095913827419281
[5/24] Train loss=0.29571405053138733
[10/24] Train loss=0.3092566430568695
[15/24] Train loss=0.2846374213695526
[20/24] Train loss=0.28966811299324036
Test set avg_accuracy=82.85% avg_sensitivity=72.41%, avg_specificity=86.74% avg_auc=88.91%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.316660 Test loss=0.374388 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3039071559906006
[5/24] Train loss=0.2950403094291687
[10/24] Train loss=0.3122786581516266
[15/24] Train loss=0.2834585905075073
[20/24] Train loss=0.28903189301490784
Test set avg_accuracy=83.01% avg_sensitivity=71.55%, avg_specificity=87.28% avg_auc=89.01%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.314613 Test loss=0.370472 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.304164320230484
[5/24] Train loss=0.2971453368663788
[10/24] Train loss=0.3117893636226654
[15/24] Train loss=0.2873561382293701
[20/24] Train loss=0.2897000014781952
Test set avg_accuracy=83.11% avg_sensitivity=71.64%, avg_specificity=87.38% avg_auc=89.03%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.314736 Test loss=0.369896 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.30967020988464355
[5/24] Train loss=0.2887551188468933
[10/24] Train loss=0.3128415048122406
[15/24] Train loss=0.2826332151889801
[20/24] Train loss=0.2846796214580536
Test set avg_accuracy=83.06% avg_sensitivity=72.22%, avg_specificity=87.10% avg_auc=88.96%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.314470 Test loss=0.372367 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3060871958732605
[5/24] Train loss=0.2936209440231323
[10/24] Train loss=0.31499773263931274
[15/24] Train loss=0.284945011138916
[20/24] Train loss=0.28801602125167847
Test set avg_accuracy=83.05% avg_sensitivity=71.83%, avg_specificity=87.22% avg_auc=89.00%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.315494 Test loss=0.370249 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.30618321895599365
[5/24] Train loss=0.2959122061729431
[10/24] Train loss=0.3093288838863373
[15/24] Train loss=0.2835095226764679
[20/24] Train loss=0.2889515161514282
Test set avg_accuracy=83.07% avg_sensitivity=74.38%, avg_specificity=86.31% avg_auc=89.05%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.315562 Test loss=0.374851 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3043287992477417
[5/24] Train loss=0.29891616106033325
[10/24] Train loss=0.31960228085517883
[15/24] Train loss=0.285663366317749
[20/24] Train loss=0.2827281355857849
Test set avg_accuracy=83.02% avg_sensitivity=74.90%, avg_specificity=86.04% avg_auc=89.03%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.315178 Test loss=0.377047 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3050346076488495
[5/24] Train loss=0.30132752656936646
[10/24] Train loss=0.3141731917858124
[15/24] Train loss=0.2847934365272522
[20/24] Train loss=0.29022306203842163
Test set avg_accuracy=82.85% avg_sensitivity=75.43%, avg_specificity=85.61% avg_auc=89.02%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.315493 Test loss=0.379381 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.31023386120796204
[5/24] Train loss=0.3002493679523468
[10/24] Train loss=0.31800705194473267
[15/24] Train loss=0.2821573317050934
[20/24] Train loss=0.29140493273735046
Test set avg_accuracy=82.45% avg_sensitivity=76.54%, avg_specificity=84.65% avg_auc=88.95%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.316076 Test loss=0.385337 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3077699840068817
[5/24] Train loss=0.29998552799224854
[10/24] Train loss=0.3138696849346161
[15/24] Train loss=0.2760186195373535
[20/24] Train loss=0.29764115810394287
Test set avg_accuracy=82.54% avg_sensitivity=76.63%, avg_specificity=84.74% avg_auc=88.94%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.316962 Test loss=0.385716 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.30714449286460876
[5/24] Train loss=0.2984905540943146
[10/24] Train loss=0.3035930097103119
[15/24] Train loss=0.2823871076107025
[20/24] Train loss=0.30462586879730225
Test set avg_accuracy=82.80% avg_sensitivity=75.14%, avg_specificity=85.65% avg_auc=89.01%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.316988 Test loss=0.377568 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3038589358329773
[5/24] Train loss=0.28717726469039917
[10/24] Train loss=0.30795231461524963
[15/24] Train loss=0.2886345684528351
[20/24] Train loss=0.2986929416656494
Test set avg_accuracy=83.41% avg_sensitivity=68.76%, avg_specificity=88.87% avg_auc=89.10%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.316583 Test loss=0.363484 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.30600568652153015
[5/24] Train loss=0.2871781885623932
[10/24] Train loss=0.30580514669418335
[15/24] Train loss=0.2843068838119507
[20/24] Train loss=0.2982640862464905
Test set avg_accuracy=83.44% avg_sensitivity=67.13%, avg_specificity=89.51% avg_auc=89.15%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.314477 Test loss=0.361034 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3057462275028229
[5/24] Train loss=0.28690096735954285
[10/24] Train loss=0.3066960573196411
[15/24] Train loss=0.28111639618873596
[20/24] Train loss=0.29031139612197876
Test set avg_accuracy=83.36% avg_sensitivity=68.62%, avg_specificity=88.85% avg_auc=89.08%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.312102 Test loss=0.363806 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3073471188545227
[5/24] Train loss=0.285502165555954
[10/24] Train loss=0.3000107407569885
[15/24] Train loss=0.28139838576316833
[20/24] Train loss=0.2962428033351898
Test set avg_accuracy=83.37% avg_sensitivity=69.15%, avg_specificity=88.67% avg_auc=89.09%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.311790 Test loss=0.364742 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.2984998822212219
[5/24] Train loss=0.2816973328590393
[10/24] Train loss=0.30161044001579285
[15/24] Train loss=0.2862150967121124
[20/24] Train loss=0.2908252477645874
Test set avg_accuracy=83.28% avg_sensitivity=68.57%, avg_specificity=88.76% avg_auc=89.11%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.311069 Test loss=0.363889 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3008565306663513
[5/24] Train loss=0.2836894989013672
[10/24] Train loss=0.30044639110565186
[15/24] Train loss=0.28390753269195557
[20/24] Train loss=0.2972899079322815
Test set avg_accuracy=83.37% avg_sensitivity=67.66%, avg_specificity=89.22% avg_auc=89.07%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.310118 Test loss=0.363564 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3067494034767151
[5/24] Train loss=0.28741946816444397
[10/24] Train loss=0.30720046162605286
[15/24] Train loss=0.28605183959007263
[20/24] Train loss=0.28900599479675293
Test set avg_accuracy=83.36% avg_sensitivity=67.80%, avg_specificity=89.15% avg_auc=89.10%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.311333 Test loss=0.363115 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.31017646193504333
[5/24] Train loss=0.2853478193283081
[10/24] Train loss=0.3014027774333954
[15/24] Train loss=0.28467118740081787
[20/24] Train loss=0.28928142786026
Test set avg_accuracy=83.19% avg_sensitivity=68.47%, avg_specificity=88.67% avg_auc=89.08%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.310923 Test loss=0.364165 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.30597764253616333
[5/24] Train loss=0.2854588031768799
[10/24] Train loss=0.3042839765548706
[15/24] Train loss=0.2752453684806824
[20/24] Train loss=0.2907744348049164
Test set avg_accuracy=83.22% avg_sensitivity=67.75%, avg_specificity=88.97% avg_auc=89.05%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.309940 Test loss=0.363956 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3045818507671356
[5/24] Train loss=0.282013475894928
[10/24] Train loss=0.3021032512187958
[15/24] Train loss=0.2829689383506775
[20/24] Train loss=0.2898266613483429
Test set avg_accuracy=83.12% avg_sensitivity=68.04%, avg_specificity=88.74% avg_auc=89.04%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.309910 Test loss=0.364725 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.2999598979949951
[5/24] Train loss=0.2838323712348938
[10/24] Train loss=0.30288252234458923
[15/24] Train loss=0.2795070707798004
[20/24] Train loss=0.28780052065849304
Test set avg_accuracy=83.22% avg_sensitivity=67.37%, avg_specificity=89.12% avg_auc=89.05%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.310087 Test loss=0.363724 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.30569154024124146
[5/24] Train loss=0.2821292579174042
[10/24] Train loss=0.2983877956867218
[15/24] Train loss=0.28089457750320435
[20/24] Train loss=0.28648748993873596
Test set avg_accuracy=83.18% avg_sensitivity=67.66%, avg_specificity=88.96% avg_auc=89.05%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.308904 Test loss=0.364153 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3012539744377136
[5/24] Train loss=0.28762611746788025
[10/24] Train loss=0.3020079731941223
[15/24] Train loss=0.2833014726638794
[20/24] Train loss=0.289718896150589
Test set avg_accuracy=83.14% avg_sensitivity=68.38%, avg_specificity=88.63% avg_auc=89.01%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.309067 Test loss=0.365538 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3079105019569397
[5/24] Train loss=0.28240835666656494
[10/24] Train loss=0.30814921855926514
[15/24] Train loss=0.2844293415546417
[20/24] Train loss=0.2850404977798462
Test set avg_accuracy=83.20% avg_sensitivity=67.37%, avg_specificity=89.10% avg_auc=89.06%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.309287 Test loss=0.363689 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3027195632457733
[5/24] Train loss=0.28430983424186707
[10/24] Train loss=0.30097222328186035
[15/24] Train loss=0.2819488048553467
[20/24] Train loss=0.2855941951274872
Test set avg_accuracy=83.16% avg_sensitivity=67.42%, avg_specificity=89.03% avg_auc=89.04%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.308908 Test loss=0.364247 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.30240046977996826
[5/24] Train loss=0.2877030074596405
[10/24] Train loss=0.30567458271980286
[15/24] Train loss=0.2795969247817993
[20/24] Train loss=0.28304609656333923
Test set avg_accuracy=83.12% avg_sensitivity=67.27%, avg_specificity=89.03% avg_auc=89.03%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.308648 Test loss=0.364367 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3051626980304718
[5/24] Train loss=0.28568294644355774
[10/24] Train loss=0.3017037808895111
[15/24] Train loss=0.28233277797698975
[20/24] Train loss=0.2863219678401947
Test set avg_accuracy=83.12% avg_sensitivity=67.99%, avg_specificity=88.76% avg_auc=89.00%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.308568 Test loss=0.365471 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3021952211856842
[5/24] Train loss=0.2800809442996979
[10/24] Train loss=0.3007105588912964
[15/24] Train loss=0.2823134958744049
[20/24] Train loss=0.2863686680793762
Test set avg_accuracy=83.12% avg_sensitivity=67.99%, avg_specificity=88.76% avg_auc=88.99%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.308037 Test loss=0.365697 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.30755406618118286
[5/24] Train loss=0.28450170159339905
[10/24] Train loss=0.3069082796573639
[15/24] Train loss=0.28503546118736267
[20/24] Train loss=0.28474462032318115
Test set avg_accuracy=83.14% avg_sensitivity=67.27%, avg_specificity=89.05% avg_auc=89.02%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.308875 Test loss=0.364598 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.30425864458084106
[5/24] Train loss=0.28309208154678345
[10/24] Train loss=0.30251815915107727
[15/24] Train loss=0.27972641587257385
[20/24] Train loss=0.290099561214447
Test set avg_accuracy=83.12% avg_sensitivity=67.90%, avg_specificity=88.80% avg_auc=89.02%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.308864 Test loss=0.365341 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3036361038684845
[5/24] Train loss=0.2841971814632416
[10/24] Train loss=0.3070787489414215
[15/24] Train loss=0.2792733609676361
[20/24] Train loss=0.2870180308818817
Test set avg_accuracy=83.20% avg_sensitivity=68.91%, avg_specificity=88.53% avg_auc=89.01%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.308332 Test loss=0.366175 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3038461208343506
[5/24] Train loss=0.28298136591911316
[10/24] Train loss=0.3005393445491791
[15/24] Train loss=0.27965661883354187
[20/24] Train loss=0.27992087602615356
Test set avg_accuracy=83.07% avg_sensitivity=69.82%, avg_specificity=88.01% avg_auc=89.00%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.308510 Test loss=0.368263 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.2986260950565338
[5/24] Train loss=0.283866286277771
[10/24] Train loss=0.3070400059223175
[15/24] Train loss=0.28045666217803955
[20/24] Train loss=0.2854986786842346
Test set avg_accuracy=83.02% avg_sensitivity=70.73%, avg_specificity=87.60% avg_auc=88.97%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.309471 Test loss=0.370107 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3046437203884125
[5/24] Train loss=0.2870236337184906
[10/24] Train loss=0.30352160334587097
[15/24] Train loss=0.2776433527469635
[20/24] Train loss=0.28136834502220154
Test set avg_accuracy=83.03% avg_sensitivity=70.83%, avg_specificity=87.58% avg_auc=88.97%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.308764 Test loss=0.370244 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.2997656762599945
[5/24] Train loss=0.27877452969551086
[10/24] Train loss=0.3006850779056549
[15/24] Train loss=0.2720789313316345
[20/24] Train loss=0.2857730984687805
Test set avg_accuracy=82.83% avg_sensitivity=71.26%, avg_specificity=87.13% avg_auc=88.94%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.306945 Test loss=0.371697 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.30054908990859985
[5/24] Train loss=0.2794709801673889
[10/24] Train loss=0.3024761378765106
[15/24] Train loss=0.28351491689682007
[20/24] Train loss=0.2867165803909302
Test set avg_accuracy=82.86% avg_sensitivity=71.11%, avg_specificity=87.24% avg_auc=88.93%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.307500 Test loss=0.371687 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.2954670786857605
[5/24] Train loss=0.27965065836906433
[10/24] Train loss=0.30247342586517334
[15/24] Train loss=0.27972689270973206
[20/24] Train loss=0.2824237644672394
Test set avg_accuracy=83.01% avg_sensitivity=69.96%, avg_specificity=87.87% avg_auc=88.96%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.306925 Test loss=0.369068 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.3023224472999573
[5/24] Train loss=0.2798149287700653
[10/24] Train loss=0.3044222593307495
[15/24] Train loss=0.2808612883090973
[20/24] Train loss=0.2826825678348541
Test set avg_accuracy=83.01% avg_sensitivity=70.44%, avg_specificity=87.69% avg_auc=88.96%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.308402 Test loss=0.369825 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.30111050605773926
[5/24] Train loss=0.2785891890525818
[10/24] Train loss=0.3095047175884247
[15/24] Train loss=0.2798219919204712
[20/24] Train loss=0.28623631596565247
Test set avg_accuracy=83.05% avg_sensitivity=69.87%, avg_specificity=87.96% avg_auc=88.96%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.307878 Test loss=0.368955 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.3029871881008148
[5/24] Train loss=0.2809951901435852
[10/24] Train loss=0.3055590093135834
[15/24] Train loss=0.2776491045951843
[20/24] Train loss=0.28445541858673096
Test set avg_accuracy=83.01% avg_sensitivity=69.91%, avg_specificity=87.88% avg_auc=88.95%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.307421 Test loss=0.369387 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.2987004518508911
[5/24] Train loss=0.2776114344596863
[10/24] Train loss=0.2999628782272339
[15/24] Train loss=0.28145894408226013
[20/24] Train loss=0.2869541049003601
Test set avg_accuracy=83.09% avg_sensitivity=69.48%, avg_specificity=88.15% avg_auc=88.96%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.306723 Test loss=0.368209 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.3011825680732727
[5/24] Train loss=0.2784665524959564
[10/24] Train loss=0.30318158864974976
[15/24] Train loss=0.27458471059799194
[20/24] Train loss=0.28393232822418213
Test set avg_accuracy=83.11% avg_sensitivity=69.96%, avg_specificity=88.01% avg_auc=88.96%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.306512 Test loss=0.368995 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.30587324500083923
[5/24] Train loss=0.2778078615665436
[10/24] Train loss=0.30069586634635925
[15/24] Train loss=0.27575722336769104
[20/24] Train loss=0.2900146543979645
Test set avg_accuracy=83.03% avg_sensitivity=69.39%, avg_specificity=88.12% avg_auc=88.96%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.308179 Test loss=0.368359 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.29878124594688416
[5/24] Train loss=0.28259068727493286
[10/24] Train loss=0.30124983191490173
[15/24] Train loss=0.2825729250907898
[20/24] Train loss=0.28469353914260864
Test set avg_accuracy=83.10% avg_sensitivity=70.01%, avg_specificity=87.97% avg_auc=88.96%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.307319 Test loss=0.369013 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.298645555973053
[5/24] Train loss=0.27877163887023926
[10/24] Train loss=0.30405381321907043
[15/24] Train loss=0.28359872102737427
[20/24] Train loss=0.2875087559223175
Test set avg_accuracy=83.07% avg_sensitivity=69.72%, avg_specificity=88.05% avg_auc=88.96%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.307913 Test loss=0.368553 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3046126961708069
[5/24] Train loss=0.27831125259399414
[10/24] Train loss=0.3048161566257477
[15/24] Train loss=0.2848369777202606
[20/24] Train loss=0.2866210341453552
Test set avg_accuracy=83.07% avg_sensitivity=69.82%, avg_specificity=88.01% avg_auc=88.96%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.307842 Test loss=0.368849 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.2979232966899872
[5/24] Train loss=0.2839019298553467
[10/24] Train loss=0.30287832021713257
[15/24] Train loss=0.27993151545524597
[20/24] Train loss=0.28405946493148804
Test set avg_accuracy=83.09% avg_sensitivity=69.82%, avg_specificity=88.03% avg_auc=88.96%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.307898 Test loss=0.368872 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.30286943912506104
[5/24] Train loss=0.28155380487442017
[10/24] Train loss=0.3085409998893738
[15/24] Train loss=0.2800988554954529
[20/24] Train loss=0.2826540470123291
Test set avg_accuracy=83.09% avg_sensitivity=69.82%, avg_specificity=88.03% avg_auc=88.96%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.307540 Test loss=0.368757 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3005238473415375
[5/24] Train loss=0.2842038571834564
[10/24] Train loss=0.3033389747142792
[15/24] Train loss=0.2803104817867279
[20/24] Train loss=0.2849370241165161
Test set avg_accuracy=83.06% avg_sensitivity=69.63%, avg_specificity=88.06% avg_auc=88.96%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.307067 Test loss=0.368525 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.30001300573349
[5/24] Train loss=0.2828215956687927
[10/24] Train loss=0.3078141510486603
[15/24] Train loss=0.283622682094574
[20/24] Train loss=0.2853016257286072
Test set avg_accuracy=83.09% avg_sensitivity=69.67%, avg_specificity=88.08% avg_auc=88.96%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.307157 Test loss=0.368515 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.3000621199607849
[5/24] Train loss=0.27519893646240234
[10/24] Train loss=0.30915096402168274
[15/24] Train loss=0.28452539443969727
[20/24] Train loss=0.289722740650177
Test set avg_accuracy=83.07% avg_sensitivity=69.63%, avg_specificity=88.08% avg_auc=88.96%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.305850 Test loss=0.368485 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3050903379917145
[5/24] Train loss=0.28175386786460876
[10/24] Train loss=0.29835620522499084
[15/24] Train loss=0.2812952697277069
[20/24] Train loss=0.2860550582408905
Test set avg_accuracy=83.07% avg_sensitivity=69.58%, avg_specificity=88.10% avg_auc=88.96%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.309126 Test loss=0.368494 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3024584650993347
[5/24] Train loss=0.27844321727752686
[10/24] Train loss=0.30280664563179016
[15/24] Train loss=0.27931952476501465
[20/24] Train loss=0.283706396818161
Test set avg_accuracy=83.06% avg_sensitivity=69.58%, avg_specificity=88.08% avg_auc=88.96%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.306076 Test loss=0.368505 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.2987653315067291
[5/24] Train loss=0.2832067012786865
[10/24] Train loss=0.2999478578567505
[15/24] Train loss=0.27675577998161316
[20/24] Train loss=0.2859456241130829
Test set avg_accuracy=83.06% avg_sensitivity=69.58%, avg_specificity=88.08% avg_auc=88.96%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.307613 Test loss=0.368503 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=84.02% sen=59.12%, spe=93.30%, auc=89.30%!
Fold[6] Avg_jsc=0.54%(±0.2925500040647391)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.9746363759040833
[5/24] Train loss=0.8825429677963257
[10/24] Train loss=0.8042081594467163
[15/24] Train loss=0.7682657837867737
[20/24] Train loss=0.7436698079109192
Test set avg_accuracy=65.46% avg_sensitivity=19.75%, avg_specificity=82.89% avg_auc=53.97%
Best model saved!! Metric=53.96600642255267!!
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.814967 Test loss=0.701495 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.727042019367218
[5/24] Train loss=0.6681731343269348
[10/24] Train loss=0.6607736349105835
[15/24] Train loss=0.6385695338249207
[20/24] Train loss=0.6401981711387634
Test set avg_accuracy=70.90% avg_sensitivity=10.51%, avg_specificity=93.94% avg_auc=60.39%
Best model saved!! Metric=60.38913158141811!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.665255 Test loss=0.625029 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.638637900352478
[5/24] Train loss=0.5787433385848999
[10/24] Train loss=0.6112313866615295
[15/24] Train loss=0.5762208700180054
[20/24] Train loss=0.5868018269538879
Test set avg_accuracy=72.42% avg_sensitivity=15.28%, avg_specificity=94.23% avg_auc=66.84%
Best model saved!! Metric=66.8353046853525!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.606454 Test loss=0.575930 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.5909649133682251
[5/24] Train loss=0.5479762554168701
[10/24] Train loss=0.5731747150421143
[15/24] Train loss=0.539876401424408
[20/24] Train loss=0.5600928068161011
Test set avg_accuracy=72.68% avg_sensitivity=18.62%, avg_specificity=93.31% avg_auc=71.43%
Best model saved!! Metric=71.42747734028664!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.573408 Test loss=0.545976 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5644316077232361
[5/24] Train loss=0.5199769735336304
[10/24] Train loss=0.5460970401763916
[15/24] Train loss=0.5169851779937744
[20/24] Train loss=0.5259548425674438
Test set avg_accuracy=73.16% avg_sensitivity=22.87%, avg_specificity=92.35% avg_auc=74.67%
Best model saved!! Metric=74.66880293765249!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.546977 Test loss=0.522785 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.546144962310791
[5/24] Train loss=0.4924713671207428
[10/24] Train loss=0.533442497253418
[15/24] Train loss=0.4904932379722595
[20/24] Train loss=0.5112116932868958
Test set avg_accuracy=73.91% avg_sensitivity=26.87%, avg_specificity=91.85% avg_auc=77.17%
Best model saved!! Metric=77.16934595317522!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.526455 Test loss=0.502587 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5255818367004395
[5/24] Train loss=0.4707086682319641
[10/24] Train loss=0.5244359374046326
[15/24] Train loss=0.47507116198539734
[20/24] Train loss=0.483743280172348
Test set avg_accuracy=74.56% avg_sensitivity=30.27%, avg_specificity=91.46% avg_auc=79.17%
Best model saved!! Metric=79.17257071478485!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.508749 Test loss=0.484690 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5086120963096619
[5/24] Train loss=0.4644946753978729
[10/24] Train loss=0.5108938813209534
[15/24] Train loss=0.4573895037174225
[20/24] Train loss=0.47636109590530396
Test set avg_accuracy=75.69% avg_sensitivity=35.03%, avg_specificity=91.20% avg_auc=80.83%
Best model saved!! Metric=80.82721386008002!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.495040 Test loss=0.468536 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.49225693941116333
[5/24] Train loss=0.44192761182785034
[10/24] Train loss=0.4904509484767914
[15/24] Train loss=0.43756231665611267
[20/24] Train loss=0.45536571741104126
Test set avg_accuracy=76.84% avg_sensitivity=40.31%, avg_specificity=90.77% avg_auc=82.29%
Best model saved!! Metric=82.2874146176471!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.477672 Test loss=0.452811 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.47552481293678284
[5/24] Train loss=0.42479175329208374
[10/24] Train loss=0.4768352806568146
[15/24] Train loss=0.42040058970451355
[20/24] Train loss=0.4400431513786316
Test set avg_accuracy=78.06% avg_sensitivity=45.92%, avg_specificity=90.32% avg_auc=83.57%
Best model saved!! Metric=83.57208629659512!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.463328 Test loss=0.438281 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4582606852054596
[5/24] Train loss=0.41553303599357605
[10/24] Train loss=0.47360002994537354
[15/24] Train loss=0.4170694649219513
[20/24] Train loss=0.4237830638885498
Test set avg_accuracy=79.28% avg_sensitivity=50.02%, avg_specificity=90.45% avg_auc=84.76%
Best model saved!! Metric=84.75689909596927!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.450155 Test loss=0.424352 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4469236731529236
[5/24] Train loss=0.4042855501174927
[10/24] Train loss=0.45615261793136597
[15/24] Train loss=0.39249974489212036
[20/24] Train loss=0.3991728723049164
Test set avg_accuracy=80.14% avg_sensitivity=50.78%, avg_specificity=91.35% avg_auc=85.76%
Best model saved!! Metric=85.75549637301253!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.436910 Test loss=0.412778 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4193897545337677
[5/24] Train loss=0.40100952982902527
[10/24] Train loss=0.44212210178375244
[15/24] Train loss=0.3862970173358917
[20/24] Train loss=0.39750075340270996
Test set avg_accuracy=80.49% avg_sensitivity=49.13%, avg_specificity=92.46% avg_auc=86.60%
Best model saved!! Metric=86.59528970397618!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.425644 Test loss=0.404143 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4094269275665283
[5/24] Train loss=0.3853861093521118
[10/24] Train loss=0.42882204055786133
[15/24] Train loss=0.37604543566703796
[20/24] Train loss=0.3878723978996277
Test set avg_accuracy=81.15% avg_sensitivity=49.60%, avg_specificity=93.18% avg_auc=87.31%
Best model saved!! Metric=87.30739275454027!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.413707 Test loss=0.396472 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.39749279618263245
[5/24] Train loss=0.3679933547973633
[10/24] Train loss=0.4217546880245209
[15/24] Train loss=0.36465486884117126
[20/24] Train loss=0.3836418092250824
Test set avg_accuracy=82.02% avg_sensitivity=56.67%, avg_specificity=91.69% avg_auc=87.90%
Best model saved!! Metric=87.8975558491783!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.404176 Test loss=0.383078 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3839958608150482
[5/24] Train loss=0.3623538315296173
[10/24] Train loss=0.41724351048469543
[15/24] Train loss=0.35421520471572876
[20/24] Train loss=0.37096959352493286
Test set avg_accuracy=82.28% avg_sensitivity=58.89%, avg_specificity=91.20% avg_auc=88.36%
Best model saved!! Metric=88.36440501655592!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.395482 Test loss=0.375919 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3765147924423218
[5/24] Train loss=0.35634976625442505
[10/24] Train loss=0.4038293659687042
[15/24] Train loss=0.3491033613681793
[20/24] Train loss=0.3701353073120117
Test set avg_accuracy=82.55% avg_sensitivity=61.72%, avg_specificity=90.50% avg_auc=88.76%
Best model saved!! Metric=88.75821742994592!!
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.388338 Test loss=0.369729 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.37496644258499146
[5/24] Train loss=0.34914669394493103
[10/24] Train loss=0.4013131558895111
[15/24] Train loss=0.3454720973968506
[20/24] Train loss=0.35649144649505615
Test set avg_accuracy=82.79% avg_sensitivity=64.55%, avg_specificity=89.75% avg_auc=89.07%
Best model saved!! Metric=89.07002410980438!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.383515 Test loss=0.365175 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.37106940150260925
[5/24] Train loss=0.3516392707824707
[10/24] Train loss=0.3977932035923004
[15/24] Train loss=0.339497447013855
[20/24] Train loss=0.34849613904953003
Test set avg_accuracy=83.03% avg_sensitivity=64.88%, avg_specificity=89.96% avg_auc=89.38%
Best model saved!! Metric=89.37964261309332!!
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.378472 Test loss=0.360467 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3569905161857605
[5/24] Train loss=0.34586212038993835
[10/24] Train loss=0.39225509762763977
[15/24] Train loss=0.3330305218696594
[20/24] Train loss=0.3389483094215393
Test set avg_accuracy=83.36% avg_sensitivity=63.79%, avg_specificity=90.83% avg_auc=89.64%
Best model saved!! Metric=89.63777959786573!!
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.372717 Test loss=0.356546 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3571540117263794
[5/24] Train loss=0.3399791717529297
[10/24] Train loss=0.3937740623950958
[15/24] Train loss=0.3300604224205017
[20/24] Train loss=0.3335324823856354
Test set avg_accuracy=83.74% avg_sensitivity=61.39%, avg_specificity=92.26% avg_auc=89.80%
Best model saved!! Metric=89.79627821698215!!
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.369004 Test loss=0.355614 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3480352461338043
[5/24] Train loss=0.33400219678878784
[10/24] Train loss=0.382221519947052
[15/24] Train loss=0.32415783405303955
[20/24] Train loss=0.32279616594314575
Test set avg_accuracy=84.00% avg_sensitivity=60.11%, avg_specificity=93.11% avg_auc=89.96%
Best model saved!! Metric=89.9636313180312!!
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.363193 Test loss=0.354496 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.348091721534729
[5/24] Train loss=0.3271147608757019
[10/24] Train loss=0.3792901635169983
[15/24] Train loss=0.31990522146224976
[20/24] Train loss=0.3291669487953186
Test set avg_accuracy=84.30% avg_sensitivity=60.87%, avg_specificity=93.24% avg_auc=90.11%
Best model saved!! Metric=90.1107904329867!!
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.358400 Test loss=0.352025 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3443458378314972
[5/24] Train loss=0.31981411576271057
[10/24] Train loss=0.3780082166194916
[15/24] Train loss=0.31257542967796326
[20/24] Train loss=0.3281814157962799
Test set avg_accuracy=84.49% avg_sensitivity=61.48%, avg_specificity=93.27% avg_auc=90.26%
Best model saved!! Metric=90.25722015575238!!
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.355118 Test loss=0.349210 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3412941098213196
[5/24] Train loss=0.31803667545318604
[10/24] Train loss=0.3707849979400635
[15/24] Train loss=0.31283697485923767
[20/24] Train loss=0.3221335709095001
Test set avg_accuracy=84.69% avg_sensitivity=61.53%, avg_specificity=93.52% avg_auc=90.39%
Best model saved!! Metric=90.38614446596152!!
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.352238 Test loss=0.346892 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3359251320362091
[5/24] Train loss=0.3094729781150818
[10/24] Train loss=0.369891494512558
[15/24] Train loss=0.30499014258384705
[20/24] Train loss=0.3176199793815613
Test set avg_accuracy=84.75% avg_sensitivity=60.63%, avg_specificity=93.96% avg_auc=90.49%
Best model saved!! Metric=90.4877420129647!!
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.348541 Test loss=0.346409 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3302456736564636
[5/24] Train loss=0.3100632429122925
[10/24] Train loss=0.36745765805244446
[15/24] Train loss=0.30038073658943176
[20/24] Train loss=0.3163524270057678
Test set avg_accuracy=84.84% avg_sensitivity=60.49%, avg_specificity=94.14% avg_auc=90.57%
Best model saved!! Metric=90.56616015467864!!
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.345803 Test loss=0.345390 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.33185210824012756
[5/24] Train loss=0.3074289560317993
[10/24] Train loss=0.3644743859767914
[15/24] Train loss=0.29957321286201477
[20/24] Train loss=0.3107069432735443
Test set avg_accuracy=84.75% avg_sensitivity=60.21%, avg_specificity=94.12% avg_auc=90.61%
Best model saved!! Metric=90.60601380468013!!
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.342839 Test loss=0.344403 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3316560387611389
[5/24] Train loss=0.3042134642601013
[10/24] Train loss=0.36287426948547363
[15/24] Train loss=0.29791656136512756
[20/24] Train loss=0.30183643102645874
Test set avg_accuracy=84.69% avg_sensitivity=59.50%, avg_specificity=94.30% avg_auc=90.67%
Best model saved!! Metric=90.67065830783217!!
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.339474 Test loss=0.344182 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3251721262931824
[5/24] Train loss=0.30257442593574524
[10/24] Train loss=0.36268115043640137
[15/24] Train loss=0.28832125663757324
[20/24] Train loss=0.3013526499271393
Test set avg_accuracy=84.47% avg_sensitivity=57.90%, avg_specificity=94.60% avg_auc=90.67%
Best model saved!! Metric=90.67226975569346!!
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.336777 Test loss=0.346106 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3252175748348236
[5/24] Train loss=0.3037731349468231
[10/24] Train loss=0.3599241375923157
[15/24] Train loss=0.2881406843662262
[20/24] Train loss=0.2974225580692291
Test set avg_accuracy=84.49% avg_sensitivity=57.14%, avg_specificity=94.93% avg_auc=90.71%
Best model saved!! Metric=90.70594477534253!!
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.334064 Test loss=0.346589 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.32479894161224365
[5/24] Train loss=0.2989800274372101
[10/24] Train loss=0.35733041167259216
[15/24] Train loss=0.286058247089386
[20/24] Train loss=0.2934361696243286
Test set avg_accuracy=84.54% avg_sensitivity=56.39%, avg_specificity=95.29% avg_auc=90.70%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.331677 Test loss=0.348357 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.32559388875961304
[5/24] Train loss=0.29596492648124695
[10/24] Train loss=0.35451769828796387
[15/24] Train loss=0.2807742953300476
[20/24] Train loss=0.29615190625190735
Test set avg_accuracy=84.58% avg_sensitivity=56.58%, avg_specificity=95.27% avg_auc=90.74%
Best model saved!! Metric=90.73801258778256!!
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.328531 Test loss=0.347229 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3225667476654053
[5/24] Train loss=0.29614752531051636
[10/24] Train loss=0.3537274897098541
[15/24] Train loss=0.28411442041397095
[20/24] Train loss=0.28876158595085144
Test set avg_accuracy=84.48% avg_sensitivity=56.20%, avg_specificity=95.27% avg_auc=90.74%
Best model saved!! Metric=90.74269002723263!!
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.326597 Test loss=0.347725 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3202432692050934
[5/24] Train loss=0.2921737730503082
[10/24] Train loss=0.3475498557090759
[15/24] Train loss=0.27751415967941284
[20/24] Train loss=0.2865004241466522
Test set avg_accuracy=84.43% avg_sensitivity=55.87%, avg_specificity=95.32% avg_auc=90.73%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.323103 Test loss=0.347998 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.319627583026886
[5/24] Train loss=0.2877601087093353
[10/24] Train loss=0.34434548020362854
[15/24] Train loss=0.2805596888065338
[20/24] Train loss=0.28343695402145386
Test set avg_accuracy=84.43% avg_sensitivity=56.01%, avg_specificity=95.27% avg_auc=90.74%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.321252 Test loss=0.347511 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.315146803855896
[5/24] Train loss=0.28722846508026123
[10/24] Train loss=0.344714492559433
[15/24] Train loss=0.27506205439567566
[20/24] Train loss=0.28641247749328613
Test set avg_accuracy=84.51% avg_sensitivity=56.95%, avg_specificity=95.02% avg_auc=90.80%
Best model saved!! Metric=90.79746229190802!!
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.317905 Test loss=0.344892 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.312002956867218
[5/24] Train loss=0.2801094055175781
[10/24] Train loss=0.34650710225105286
[15/24] Train loss=0.27745795249938965
[20/24] Train loss=0.2831055819988251
Test set avg_accuracy=84.45% avg_sensitivity=56.20%, avg_specificity=95.23% avg_auc=90.80%
Best model saved!! Metric=90.79755558625789!!
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.315123 Test loss=0.346309 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3075392246246338
[5/24] Train loss=0.2806790769100189
[10/24] Train loss=0.3383389413356781
[15/24] Train loss=0.2702367901802063
[20/24] Train loss=0.2799230217933655
Test set avg_accuracy=84.41% avg_sensitivity=56.15%, avg_specificity=95.20% avg_auc=90.77%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.312845 Test loss=0.346663 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.30850228667259216
[5/24] Train loss=0.27849623560905457
[10/24] Train loss=0.33639630675315857
[15/24] Train loss=0.27050334215164185
[20/24] Train loss=0.27821674942970276
Test set avg_accuracy=84.47% avg_sensitivity=56.25%, avg_specificity=95.23% avg_auc=90.77%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.310188 Test loss=0.346410 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3066576421260834
[5/24] Train loss=0.279608815908432
[10/24] Train loss=0.3361683189868927
[15/24] Train loss=0.2662353515625
[20/24] Train loss=0.27579283714294434
Test set avg_accuracy=84.31% avg_sensitivity=54.97%, avg_specificity=95.50% avg_auc=90.71%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.308114 Test loss=0.349716 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.30823570489883423
[5/24] Train loss=0.2764468789100647
[10/24] Train loss=0.3312782347202301
[15/24] Train loss=0.26474976539611816
[20/24] Train loss=0.2740936279296875
Test set avg_accuracy=84.30% avg_sensitivity=54.88%, avg_specificity=95.52% avg_auc=90.67%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.305706 Test loss=0.350260 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.30226099491119385
[5/24] Train loss=0.27382463216781616
[10/24] Train loss=0.3313576579093933
[15/24] Train loss=0.26707929372787476
[20/24] Train loss=0.27117496728897095
Test set avg_accuracy=84.28% avg_sensitivity=55.40%, avg_specificity=95.30% avg_auc=90.72%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.304164 Test loss=0.347849 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2989610731601715
[5/24] Train loss=0.27070701122283936
[10/24] Train loss=0.32806557416915894
[15/24] Train loss=0.2628713846206665
[20/24] Train loss=0.2708841860294342
Test set avg_accuracy=84.30% avg_sensitivity=55.07%, avg_specificity=95.45% avg_auc=90.72%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.301714 Test loss=0.348466 Current lr=[0.00029967723776099]

[0/24] Train loss=0.300031840801239
[5/24] Train loss=0.26728445291519165
[10/24] Train loss=0.3246018588542938
[15/24] Train loss=0.26172560453414917
[20/24] Train loss=0.2679240107536316
Test set avg_accuracy=84.26% avg_sensitivity=55.30%, avg_specificity=95.30% avg_auc=90.73%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.299020 Test loss=0.347017 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2970150113105774
[5/24] Train loss=0.2674332559108734
[10/24] Train loss=0.3241420388221741
[15/24] Train loss=0.2612732946872711
[20/24] Train loss=0.2698899507522583
Test set avg_accuracy=84.30% avg_sensitivity=56.29%, avg_specificity=94.98% avg_auc=90.74%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.297297 Test loss=0.345499 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.295923113822937
[5/24] Train loss=0.2643698453903198
[10/24] Train loss=0.32165008783340454
[15/24] Train loss=0.26087337732315063
[20/24] Train loss=0.2677866220474243
Test set avg_accuracy=84.22% avg_sensitivity=55.87%, avg_specificity=95.04% avg_auc=90.68%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.295620 Test loss=0.346718 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2928215265274048
[5/24] Train loss=0.26569849252700806
[10/24] Train loss=0.3185931146144867
[15/24] Train loss=0.2580244541168213
[20/24] Train loss=0.26536139845848083
Test set avg_accuracy=84.27% avg_sensitivity=56.01%, avg_specificity=95.05% avg_auc=90.67%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.293039 Test loss=0.346262 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.29345449805259705
[5/24] Train loss=0.2622090280056
[10/24] Train loss=0.3189956843852997
[15/24] Train loss=0.2560954689979553
[20/24] Train loss=0.2674883008003235
Test set avg_accuracy=84.39% avg_sensitivity=57.33%, avg_specificity=94.71% avg_auc=90.68%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.291283 Test loss=0.344885 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2849281430244446
[5/24] Train loss=0.2606363296508789
[10/24] Train loss=0.3170475661754608
[15/24] Train loss=0.2554500997066498
[20/24] Train loss=0.265854150056839
Test set avg_accuracy=84.65% avg_sensitivity=58.89%, avg_specificity=94.48% avg_auc=90.68%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.289327 Test loss=0.343071 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.28064844012260437
[5/24] Train loss=0.2614738643169403
[10/24] Train loss=0.3147207796573639
[15/24] Train loss=0.2548674941062927
[20/24] Train loss=0.2633552849292755
Test set avg_accuracy=84.52% avg_sensitivity=58.23%, avg_specificity=94.55% avg_auc=90.64%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.287939 Test loss=0.343576 Current lr=[0.000297555943323901]

[0/24] Train loss=0.28302139043807983
[5/24] Train loss=0.25900524854660034
[10/24] Train loss=0.31321221590042114
[15/24] Train loss=0.2526855170726776
[20/24] Train loss=0.262587308883667
Test set avg_accuracy=84.34% avg_sensitivity=57.99%, avg_specificity=94.39% avg_auc=90.62%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.286370 Test loss=0.344136 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2822292149066925
[5/24] Train loss=0.25651681423187256
[10/24] Train loss=0.3154144883155823
[15/24] Train loss=0.25244659185409546
[20/24] Train loss=0.26327061653137207
Test set avg_accuracy=84.51% avg_sensitivity=59.03%, avg_specificity=94.23% avg_auc=90.58%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.285050 Test loss=0.343715 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.28405484557151794
[5/24] Train loss=0.2548316717147827
[10/24] Train loss=0.3122788369655609
[15/24] Train loss=0.24828842282295227
[20/24] Train loss=0.261833518743515
Test set avg_accuracy=84.58% avg_sensitivity=59.78%, avg_specificity=94.05% avg_auc=90.60%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.283997 Test loss=0.342379 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2792845666408539
[5/24] Train loss=0.25130319595336914
[10/24] Train loss=0.3108621835708618
[15/24] Train loss=0.24850058555603027
[20/24] Train loss=0.2628267705440521
Test set avg_accuracy=84.62% avg_sensitivity=60.63%, avg_specificity=93.78% avg_auc=90.61%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.282359 Test loss=0.341496 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.27421244978904724
[5/24] Train loss=0.2520503103733063
[10/24] Train loss=0.30533474683761597
[15/24] Train loss=0.24787099659442902
[20/24] Train loss=0.26034629344940186
Test set avg_accuracy=84.66% avg_sensitivity=61.81%, avg_specificity=93.38% avg_auc=90.57%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.280878 Test loss=0.341083 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.2763490676879883
[5/24] Train loss=0.24963200092315674
[10/24] Train loss=0.3075304329395294
[15/24] Train loss=0.2487424910068512
[20/24] Train loss=0.26410990953445435
Test set avg_accuracy=84.69% avg_sensitivity=63.22%, avg_specificity=92.88% avg_auc=90.60%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.281063 Test loss=0.339301 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2739158272743225
[5/24] Train loss=0.2514553368091583
[10/24] Train loss=0.30289575457572937
[15/24] Train loss=0.24495193362236023
[20/24] Train loss=0.26608073711395264
Test set avg_accuracy=84.60% avg_sensitivity=64.07%, avg_specificity=92.43% avg_auc=90.59%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.279293 Test loss=0.339088 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2725394368171692
[5/24] Train loss=0.24924807250499725
[10/24] Train loss=0.30584919452667236
[15/24] Train loss=0.24522370100021362
[20/24] Train loss=0.26560157537460327
Test set avg_accuracy=84.82% avg_sensitivity=66.01%, avg_specificity=91.99% avg_auc=90.58%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.278639 Test loss=0.338793 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.27007681131362915
[5/24] Train loss=0.24838373064994812
[10/24] Train loss=0.30591803789138794
[15/24] Train loss=0.24614113569259644
[20/24] Train loss=0.2683205008506775
Test set avg_accuracy=84.88% avg_sensitivity=67.23%, avg_specificity=91.62% avg_auc=90.56%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.277429 Test loss=0.339331 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2695157527923584
[5/24] Train loss=0.2495049089193344
[10/24] Train loss=0.30400678515434265
[15/24] Train loss=0.24480366706848145
[20/24] Train loss=0.2666670083999634
Test set avg_accuracy=84.82% avg_sensitivity=67.47%, avg_specificity=91.44% avg_auc=90.53%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.276415 Test loss=0.339684 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.272334486246109
[5/24] Train loss=0.2519928216934204
[10/24] Train loss=0.3021692931652069
[15/24] Train loss=0.24265319108963013
[20/24] Train loss=0.2653597295284271
Test set avg_accuracy=84.88% avg_sensitivity=67.61%, avg_specificity=91.47% avg_auc=90.50%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.276924 Test loss=0.340237 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2704111635684967
[5/24] Train loss=0.2529364228248596
[10/24] Train loss=0.30479782819747925
[15/24] Train loss=0.23795530200004578
[20/24] Train loss=0.2606852352619171
Test set avg_accuracy=84.86% avg_sensitivity=66.15%, avg_specificity=91.99% avg_auc=90.46%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.275349 Test loss=0.340786 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2665804624557495
[5/24] Train loss=0.2483547031879425
[10/24] Train loss=0.30302998423576355
[15/24] Train loss=0.23852837085723877
[20/24] Train loss=0.25566986203193665
Test set avg_accuracy=84.84% avg_sensitivity=65.25%, avg_specificity=92.32% avg_auc=90.38%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.273239 Test loss=0.342291 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2660367488861084
[5/24] Train loss=0.24429665505886078
[10/24] Train loss=0.30796536803245544
[15/24] Train loss=0.2378057986497879
[20/24] Train loss=0.2588508427143097
Test set avg_accuracy=84.77% avg_sensitivity=64.59%, avg_specificity=92.46% avg_auc=90.32%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.273249 Test loss=0.343580 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.2662838399410248
[5/24] Train loss=0.24585849046707153
[10/24] Train loss=0.30455106496810913
[15/24] Train loss=0.23681145906448364
[20/24] Train loss=0.2551542818546295
Test set avg_accuracy=84.64% avg_sensitivity=64.36%, avg_specificity=92.37% avg_auc=90.23%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.270565 Test loss=0.345232 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.26601654291152954
[5/24] Train loss=0.24326665699481964
[10/24] Train loss=0.30159127712249756
[15/24] Train loss=0.23381461203098297
[20/24] Train loss=0.25679612159729004
Test set avg_accuracy=84.23% avg_sensitivity=62.33%, avg_specificity=92.59% avg_auc=90.12%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.269152 Test loss=0.347470 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2685289978981018
[5/24] Train loss=0.23758761584758759
[10/24] Train loss=0.30125200748443604
[15/24] Train loss=0.2323979288339615
[20/24] Train loss=0.2553202509880066
Test set avg_accuracy=84.38% avg_sensitivity=63.65%, avg_specificity=92.28% avg_auc=90.09%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.267720 Test loss=0.347235 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2693125307559967
[5/24] Train loss=0.24160736799240112
[10/24] Train loss=0.29837265610694885
[15/24] Train loss=0.23211683332920074
[20/24] Train loss=0.2523155212402344
Test set avg_accuracy=84.28% avg_sensitivity=63.65%, avg_specificity=92.16% avg_auc=90.09%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.267315 Test loss=0.347690 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2671760618686676
[5/24] Train loss=0.23738335072994232
[10/24] Train loss=0.29906371235847473
[15/24] Train loss=0.22941628098487854
[20/24] Train loss=0.24853019416332245
Test set avg_accuracy=84.18% avg_sensitivity=62.75%, avg_specificity=92.35% avg_auc=90.03%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.265287 Test loss=0.349425 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.26194342970848083
[5/24] Train loss=0.24007700383663177
[10/24] Train loss=0.2953699231147766
[15/24] Train loss=0.2305486798286438
[20/24] Train loss=0.24854707717895508
Test set avg_accuracy=84.19% avg_sensitivity=62.61%, avg_specificity=92.43% avg_auc=90.00%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.265027 Test loss=0.349607 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.26290637254714966
[5/24] Train loss=0.23855718970298767
[10/24] Train loss=0.2913239896297455
[15/24] Train loss=0.2286241352558136
[20/24] Train loss=0.2474684864282608
Test set avg_accuracy=84.26% avg_sensitivity=62.75%, avg_specificity=92.46% avg_auc=89.96%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.263805 Test loss=0.350181 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.25706496834754944
[5/24] Train loss=0.23426447808742523
[10/24] Train loss=0.29570382833480835
[15/24] Train loss=0.23085130751132965
[20/24] Train loss=0.24839523434638977
Test set avg_accuracy=84.31% avg_sensitivity=63.46%, avg_specificity=92.26% avg_auc=89.96%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.263285 Test loss=0.350048 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2596510946750641
[5/24] Train loss=0.23564974963665009
[10/24] Train loss=0.29105305671691895
[15/24] Train loss=0.22801730036735535
[20/24] Train loss=0.24773567914962769
Test set avg_accuracy=84.18% avg_sensitivity=62.47%, avg_specificity=92.46% avg_auc=89.87%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.261757 Test loss=0.352062 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.26194992661476135
[5/24] Train loss=0.23403888940811157
[10/24] Train loss=0.29203155636787415
[15/24] Train loss=0.22754107415676117
[20/24] Train loss=0.2516409754753113
Test set avg_accuracy=84.06% avg_sensitivity=62.47%, avg_specificity=92.30% avg_auc=89.82%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.261976 Test loss=0.352904 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2600284218788147
[5/24] Train loss=0.23558016121387482
[10/24] Train loss=0.2936115562915802
[15/24] Train loss=0.2283761203289032
[20/24] Train loss=0.2481137365102768
Test set avg_accuracy=84.09% avg_sensitivity=62.66%, avg_specificity=92.26% avg_auc=89.81%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.261898 Test loss=0.353038 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2599537968635559
[5/24] Train loss=0.23472675681114197
[10/24] Train loss=0.29200270771980286
[15/24] Train loss=0.2270522564649582
[20/24] Train loss=0.24651719629764557
Test set avg_accuracy=84.06% avg_sensitivity=62.28%, avg_specificity=92.37% avg_auc=89.73%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.260049 Test loss=0.354555 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2591753602027893
[5/24] Train loss=0.23514021933078766
[10/24] Train loss=0.29476702213287354
[15/24] Train loss=0.22822795808315277
[20/24] Train loss=0.2451544553041458
Test set avg_accuracy=83.98% avg_sensitivity=62.89%, avg_specificity=92.03% avg_auc=89.72%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.260551 Test loss=0.354610 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.256542831659317
[5/24] Train loss=0.23257912695407867
[10/24] Train loss=0.2879171669483185
[15/24] Train loss=0.2264588475227356
[20/24] Train loss=0.24736803770065308
Test set avg_accuracy=84.05% avg_sensitivity=63.65%, avg_specificity=91.83% avg_auc=89.77%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.259522 Test loss=0.353825 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2541228234767914
[5/24] Train loss=0.23052741587162018
[10/24] Train loss=0.28691792488098145
[15/24] Train loss=0.22582712769508362
[20/24] Train loss=0.24235118925571442
Test set avg_accuracy=83.93% avg_sensitivity=61.90%, avg_specificity=92.34% avg_auc=89.72%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.258805 Test loss=0.355547 Current lr=[0.000224838296036774]

[0/24] Train loss=0.25502821803092957
[5/24] Train loss=0.23087464272975922
[10/24] Train loss=0.29126378893852234
[15/24] Train loss=0.22106994688510895
[20/24] Train loss=0.24700689315795898
Test set avg_accuracy=83.91% avg_sensitivity=62.23%, avg_specificity=92.17% avg_auc=89.69%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.257983 Test loss=0.355773 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2560340166091919
[5/24] Train loss=0.23339223861694336
[10/24] Train loss=0.2854089140892029
[15/24] Train loss=0.2245548665523529
[20/24] Train loss=0.24600982666015625
Test set avg_accuracy=83.95% avg_sensitivity=64.07%, avg_specificity=91.53% avg_auc=89.66%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.257770 Test loss=0.355560 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.25333380699157715
[5/24] Train loss=0.22995975613594055
[10/24] Train loss=0.2849990427494049
[15/24] Train loss=0.22137026488780975
[20/24] Train loss=0.24762164056301117
Test set avg_accuracy=83.92% avg_sensitivity=64.26%, avg_specificity=91.42% avg_auc=89.69%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.257492 Test loss=0.355665 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.251851886510849
[5/24] Train loss=0.23328185081481934
[10/24] Train loss=0.2859991192817688
[15/24] Train loss=0.22312654554843903
[20/24] Train loss=0.2448185384273529
Test set avg_accuracy=83.79% avg_sensitivity=63.88%, avg_specificity=91.38% avg_auc=89.65%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.257201 Test loss=0.356346 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.25720199942588806
[5/24] Train loss=0.22788125276565552
[10/24] Train loss=0.2849183678627014
[15/24] Train loss=0.22399792075157166
[20/24] Train loss=0.24278727173805237
Test set avg_accuracy=83.92% avg_sensitivity=64.03%, avg_specificity=91.51% avg_auc=89.69%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.256240 Test loss=0.355979 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.25229620933532715
[5/24] Train loss=0.2330886274576187
[10/24] Train loss=0.2868621349334717
[15/24] Train loss=0.22335034608840942
[20/24] Train loss=0.24128492176532745
Test set avg_accuracy=83.88% avg_sensitivity=63.84%, avg_specificity=91.53% avg_auc=89.67%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.256941 Test loss=0.356019 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2551472783088684
[5/24] Train loss=0.22845056653022766
[10/24] Train loss=0.2871283292770386
[15/24] Train loss=0.22417883574962616
[20/24] Train loss=0.24088141322135925
Test set avg_accuracy=83.96% avg_sensitivity=63.55%, avg_specificity=91.74% avg_auc=89.67%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.257566 Test loss=0.356313 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2561025321483612
[5/24] Train loss=0.23045264184474945
[10/24] Train loss=0.2874356806278229
[15/24] Train loss=0.22361938655376434
[20/24] Train loss=0.23930761218070984
Test set avg_accuracy=83.63% avg_sensitivity=59.83%, avg_specificity=92.71% avg_auc=89.55%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.257470 Test loss=0.361554 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2580545246601105
[5/24] Train loss=0.22777335345745087
[10/24] Train loss=0.29361066222190857
[15/24] Train loss=0.22229531407356262
[20/24] Train loss=0.24097828567028046
Test set avg_accuracy=83.57% avg_sensitivity=59.74%, avg_specificity=92.66% avg_auc=89.52%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.256537 Test loss=0.361966 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.25696200132369995
[5/24] Train loss=0.2258339822292328
[10/24] Train loss=0.28494733572006226
[15/24] Train loss=0.22268715500831604
[20/24] Train loss=0.2335851937532425
Test set avg_accuracy=83.54% avg_sensitivity=60.49%, avg_specificity=92.34% avg_auc=89.53%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.254657 Test loss=0.361723 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.25262510776519775
[5/24] Train loss=0.2253655195236206
[10/24] Train loss=0.28226205706596375
[15/24] Train loss=0.22127076983451843
[20/24] Train loss=0.2409925013780594
Test set avg_accuracy=83.45% avg_sensitivity=60.58%, avg_specificity=92.17% avg_auc=89.52%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.254135 Test loss=0.361857 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2567412555217743
[5/24] Train loss=0.22342266142368317
[10/24] Train loss=0.27991101145744324
[15/24] Train loss=0.2216552197933197
[20/24] Train loss=0.2374790608882904
Test set avg_accuracy=83.48% avg_sensitivity=60.73%, avg_specificity=92.16% avg_auc=89.53%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.254265 Test loss=0.362536 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2601062059402466
[5/24] Train loss=0.22825966775417328
[10/24] Train loss=0.28001007437705994
[15/24] Train loss=0.22073432803153992
[20/24] Train loss=0.23880718648433685
Test set avg_accuracy=83.42% avg_sensitivity=60.35%, avg_specificity=92.23% avg_auc=89.52%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.254164 Test loss=0.363609 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2548762261867523
[5/24] Train loss=0.22115984559059143
[10/24] Train loss=0.2788388431072235
[15/24] Train loss=0.2214459478855133
[20/24] Train loss=0.23797141015529633
Test set avg_accuracy=83.45% avg_sensitivity=61.76%, avg_specificity=91.73% avg_auc=89.51%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.252788 Test loss=0.362571 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.25125059485435486
[5/24] Train loss=0.22455966472625732
[10/24] Train loss=0.2777247428894043
[15/24] Train loss=0.22059397399425507
[20/24] Train loss=0.24137304723262787
Test set avg_accuracy=83.45% avg_sensitivity=61.29%, avg_specificity=91.91% avg_auc=89.54%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.253170 Test loss=0.363212 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2515842020511627
[5/24] Train loss=0.22299768030643463
[10/24] Train loss=0.28143709897994995
[15/24] Train loss=0.22219054400920868
[20/24] Train loss=0.23428769409656525
Test set avg_accuracy=83.26% avg_sensitivity=60.21%, avg_specificity=92.05% avg_auc=89.51%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.252792 Test loss=0.365754 Current lr=[0.000156543481933168]

[0/24] Train loss=0.24912521243095398
[5/24] Train loss=0.22508017718791962
[10/24] Train loss=0.2799994945526123
[15/24] Train loss=0.22317242622375488
[20/24] Train loss=0.23579661548137665
Test set avg_accuracy=83.22% avg_sensitivity=60.54%, avg_specificity=91.87% avg_auc=89.50%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.253068 Test loss=0.366023 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2544839084148407
[5/24] Train loss=0.2247096300125122
[10/24] Train loss=0.2809940576553345
[15/24] Train loss=0.22044643759727478
[20/24] Train loss=0.2346845269203186
Test set avg_accuracy=83.11% avg_sensitivity=60.35%, avg_specificity=91.80% avg_auc=89.48%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.253163 Test loss=0.367089 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.25377127528190613
[5/24] Train loss=0.2272963970899582
[10/24] Train loss=0.2758508622646332
[15/24] Train loss=0.22328828275203705
[20/24] Train loss=0.23425428569316864
Test set avg_accuracy=83.20% avg_sensitivity=60.44%, avg_specificity=91.89% avg_auc=89.54%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.253573 Test loss=0.365833 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.2520328462123871
[5/24] Train loss=0.2273402065038681
[10/24] Train loss=0.2761366665363312
[15/24] Train loss=0.22372303903102875
[20/24] Train loss=0.24023693799972534
Test set avg_accuracy=83.22% avg_sensitivity=61.57%, avg_specificity=91.47% avg_auc=89.55%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.254702 Test loss=0.365359 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.25634217262268066
[5/24] Train loss=0.22748379409313202
[10/24] Train loss=0.28541597723960876
[15/24] Train loss=0.22628381848335266
[20/24] Train loss=0.23813118040561676
Test set avg_accuracy=83.18% avg_sensitivity=63.04%, avg_specificity=90.86% avg_auc=89.63%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.255982 Test loss=0.362299 Current lr=[0.000134135431043539]

[0/24] Train loss=0.2550719380378723
[5/24] Train loss=0.23271842300891876
[10/24] Train loss=0.28590795397758484
[15/24] Train loss=0.2318158745765686
[20/24] Train loss=0.23680417239665985
Test set avg_accuracy=83.32% avg_sensitivity=68.18%, avg_specificity=89.10% avg_auc=89.74%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.258435 Test loss=0.361774 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.2512941360473633
[5/24] Train loss=0.24056096374988556
[10/24] Train loss=0.29435595870018005
[15/24] Train loss=0.22635391354560852
[20/24] Train loss=0.24477040767669678
Test set avg_accuracy=83.54% avg_sensitivity=71.19%, avg_specificity=88.25% avg_auc=89.82%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.260654 Test loss=0.363163 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2604769468307495
[5/24] Train loss=0.23736049234867096
[10/24] Train loss=0.28457528352737427
[15/24] Train loss=0.2305985540151596
[20/24] Train loss=0.25772663950920105
Test set avg_accuracy=83.61% avg_sensitivity=65.91%, avg_specificity=90.36% avg_auc=89.72%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.259971 Test loss=0.358101 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.25465765595436096
[5/24] Train loss=0.2268039733171463
[10/24] Train loss=0.2775390148162842
[15/24] Train loss=0.22396832704544067
[20/24] Train loss=0.24049115180969238
Test set avg_accuracy=83.55% avg_sensitivity=64.21%, avg_specificity=90.93% avg_auc=89.54%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.254081 Test loss=0.361136 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.2543545961380005
[5/24] Train loss=0.22381669282913208
[10/24] Train loss=0.2775707244873047
[15/24] Train loss=0.22494499385356903
[20/24] Train loss=0.2460756003856659
Test set avg_accuracy=83.53% avg_sensitivity=65.35%, avg_specificity=90.47% avg_auc=89.57%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.252934 Test loss=0.361095 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.25168606638908386
[5/24] Train loss=0.22889643907546997
[10/24] Train loss=0.2830754220485687
[15/24] Train loss=0.22190353274345398
[20/24] Train loss=0.24276605248451233
Test set avg_accuracy=83.45% avg_sensitivity=64.69%, avg_specificity=90.61% avg_auc=89.53%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.251635 Test loss=0.361850 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.25427934527397156
[5/24] Train loss=0.22157876193523407
[10/24] Train loss=0.27809691429138184
[15/24] Train loss=0.22462718188762665
[20/24] Train loss=0.24487382173538208
Test set avg_accuracy=83.45% avg_sensitivity=64.12%, avg_specificity=90.83% avg_auc=89.50%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.251867 Test loss=0.362421 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.25589028000831604
[5/24] Train loss=0.22560715675354004
[10/24] Train loss=0.277499258518219
[15/24] Train loss=0.2208535224199295
[20/24] Train loss=0.24159404635429382
Test set avg_accuracy=83.42% avg_sensitivity=64.03%, avg_specificity=90.83% avg_auc=89.44%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.251211 Test loss=0.363113 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.24881862103939056
[5/24] Train loss=0.2219209223985672
[10/24] Train loss=0.28236326575279236
[15/24] Train loss=0.22352370619773865
[20/24] Train loss=0.2401312291622162
Test set avg_accuracy=83.46% avg_sensitivity=63.13%, avg_specificity=91.22% avg_auc=89.40%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.250534 Test loss=0.364096 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.25394418835639954
[5/24] Train loss=0.22191159427165985
[10/24] Train loss=0.2759408950805664
[15/24] Train loss=0.22078199684619904
[20/24] Train loss=0.23956018686294556
Test set avg_accuracy=83.53% avg_sensitivity=64.59%, avg_specificity=90.75% avg_auc=89.37%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.249967 Test loss=0.364954 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2538548409938812
[5/24] Train loss=0.2209433615207672
[10/24] Train loss=0.27392661571502686
[15/24] Train loss=0.22216959297657013
[20/24] Train loss=0.23683086037635803
Test set avg_accuracy=83.48% avg_sensitivity=63.13%, avg_specificity=91.24% avg_auc=89.34%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.249553 Test loss=0.365566 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.251729279756546
[5/24] Train loss=0.2225193977355957
[10/24] Train loss=0.2830810546875
[15/24] Train loss=0.2232205867767334
[20/24] Train loss=0.23488803207874298
Test set avg_accuracy=83.45% avg_sensitivity=63.84%, avg_specificity=90.93% avg_auc=89.31%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.248972 Test loss=0.366040 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.2483959048986435
[5/24] Train loss=0.224106103181839
[10/24] Train loss=0.27462685108184814
[15/24] Train loss=0.21600937843322754
[20/24] Train loss=0.23858246207237244
Test set avg_accuracy=83.44% avg_sensitivity=63.22%, avg_specificity=91.15% avg_auc=89.28%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.248700 Test loss=0.366248 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.24747538566589355
[5/24] Train loss=0.222152978181839
[10/24] Train loss=0.27657872438430786
[15/24] Train loss=0.21969319880008698
[20/24] Train loss=0.23487181961536407
Test set avg_accuracy=83.41% avg_sensitivity=62.89%, avg_specificity=91.24% avg_auc=89.26%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.248365 Test loss=0.366949 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.24786587059497833
[5/24] Train loss=0.21948347985744476
[10/24] Train loss=0.27410680055618286
[15/24] Train loss=0.21771953999996185
[20/24] Train loss=0.2380610555410385
Test set avg_accuracy=83.40% avg_sensitivity=63.04%, avg_specificity=91.17% avg_auc=89.22%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.247595 Test loss=0.367518 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.24849463999271393
[5/24] Train loss=0.22023867070674896
[10/24] Train loss=0.2735517621040344
[15/24] Train loss=0.21556371450424194
[20/24] Train loss=0.24089770019054413
Test set avg_accuracy=83.37% avg_sensitivity=62.99%, avg_specificity=91.15% avg_auc=89.20%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.247761 Test loss=0.368138 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.25065815448760986
[5/24] Train loss=0.22066359221935272
[10/24] Train loss=0.27692490816116333
[15/24] Train loss=0.21882019937038422
[20/24] Train loss=0.23449254035949707
Test set avg_accuracy=83.33% avg_sensitivity=62.23%, avg_specificity=91.38% avg_auc=89.16%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.247654 Test loss=0.369020 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.24781867861747742
[5/24] Train loss=0.22249121963977814
[10/24] Train loss=0.2788330018520355
[15/24] Train loss=0.22068609297275543
[20/24] Train loss=0.2361377477645874
Test set avg_accuracy=83.39% avg_sensitivity=63.08%, avg_specificity=91.13% avg_auc=89.19%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.248449 Test loss=0.367979 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.24725785851478577
[5/24] Train loss=0.22002717852592468
[10/24] Train loss=0.278613805770874
[15/24] Train loss=0.22054512798786163
[20/24] Train loss=0.2356313019990921
Test set avg_accuracy=83.33% avg_sensitivity=62.47%, avg_specificity=91.29% avg_auc=89.17%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.247910 Test loss=0.368694 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.24609240889549255
[5/24] Train loss=0.21468794345855713
[10/24] Train loss=0.27167436480522156
[15/24] Train loss=0.21516543626785278
[20/24] Train loss=0.23601719737052917
Test set avg_accuracy=83.33% avg_sensitivity=62.42%, avg_specificity=91.31% avg_auc=89.19%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.246556 Test loss=0.368566 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.2474532425403595
[5/24] Train loss=0.2161204069852829
[10/24] Train loss=0.27708691358566284
[15/24] Train loss=0.21939699351787567
[20/24] Train loss=0.23518727719783783
Test set avg_accuracy=83.41% avg_sensitivity=62.80%, avg_specificity=91.28% avg_auc=89.19%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.247207 Test loss=0.368484 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.24731312692165375
[5/24] Train loss=0.21961764991283417
[10/24] Train loss=0.2731921076774597
[15/24] Train loss=0.2215752750635147
[20/24] Train loss=0.22927355766296387
Test set avg_accuracy=83.36% avg_sensitivity=63.27%, avg_specificity=91.02% avg_auc=89.18%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.247104 Test loss=0.368445 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.24643343687057495
[5/24] Train loss=0.21877029538154602
[10/24] Train loss=0.2784910202026367
[15/24] Train loss=0.2172146588563919
[20/24] Train loss=0.23025520145893097
Test set avg_accuracy=83.41% avg_sensitivity=63.65%, avg_specificity=90.95% avg_auc=89.19%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.247757 Test loss=0.368009 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.24540367722511292
[5/24] Train loss=0.2196359783411026
[10/24] Train loss=0.2721439599990845
[15/24] Train loss=0.21424706280231476
[20/24] Train loss=0.2311619222164154
Test set avg_accuracy=83.31% avg_sensitivity=64.21%, avg_specificity=90.59% avg_auc=89.22%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.246696 Test loss=0.367661 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.24800004065036774
[5/24] Train loss=0.21674135327339172
[10/24] Train loss=0.2727016806602478
[15/24] Train loss=0.21679902076721191
[20/24] Train loss=0.23100139200687408
Test set avg_accuracy=83.19% avg_sensitivity=65.30%, avg_specificity=90.02% avg_auc=89.24%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.247542 Test loss=0.367613 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.24905599653720856
[5/24] Train loss=0.218632310628891
[10/24] Train loss=0.27267372608184814
[15/24] Train loss=0.21757133305072784
[20/24] Train loss=0.23145736753940582
Test set avg_accuracy=83.22% avg_sensitivity=66.24%, avg_specificity=89.69% avg_auc=89.28%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.248080 Test loss=0.367472 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.248115673661232
[5/24] Train loss=0.21752549707889557
[10/24] Train loss=0.27309808135032654
[15/24] Train loss=0.21667493879795074
[20/24] Train loss=0.23467418551445007
Test set avg_accuracy=83.27% avg_sensitivity=66.76%, avg_specificity=89.57% avg_auc=89.28%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.247781 Test loss=0.367647 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.24817055463790894
[5/24] Train loss=0.21903899312019348
[10/24] Train loss=0.27084821462631226
[15/24] Train loss=0.21574026346206665
[20/24] Train loss=0.2347864955663681
Test set avg_accuracy=83.14% avg_sensitivity=66.53%, avg_specificity=89.48% avg_auc=89.28%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.247188 Test loss=0.367688 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.24735042452812195
[5/24] Train loss=0.21949711441993713
[10/24] Train loss=0.27400436997413635
[15/24] Train loss=0.21274439990520477
[20/24] Train loss=0.23738500475883484
Test set avg_accuracy=83.20% avg_sensitivity=65.21%, avg_specificity=90.07% avg_auc=89.22%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.247715 Test loss=0.367650 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.24795027077198029
[5/24] Train loss=0.21585586667060852
[10/24] Train loss=0.27240315079689026
[15/24] Train loss=0.21879494190216064
[20/24] Train loss=0.2371489703655243
Test set avg_accuracy=83.28% avg_sensitivity=64.59%, avg_specificity=90.41% avg_auc=89.18%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.246850 Test loss=0.368110 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.2431858777999878
[5/24] Train loss=0.21704551577568054
[10/24] Train loss=0.2756037712097168
[15/24] Train loss=0.2206435650587082
[20/24] Train loss=0.23773424327373505
Test set avg_accuracy=83.24% avg_sensitivity=64.50%, avg_specificity=90.39% avg_auc=89.18%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.246981 Test loss=0.368294 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.24900251626968384
[5/24] Train loss=0.22024810314178467
[10/24] Train loss=0.2726673185825348
[15/24] Train loss=0.21615661680698395
[20/24] Train loss=0.23211289942264557
Test set avg_accuracy=83.26% avg_sensitivity=64.45%, avg_specificity=90.43% avg_auc=89.18%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.246073 Test loss=0.368311 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.2475672960281372
[5/24] Train loss=0.22060668468475342
[10/24] Train loss=0.27039000391960144
[15/24] Train loss=0.21926359832286835
[20/24] Train loss=0.23410452902317047
Test set avg_accuracy=83.32% avg_sensitivity=64.21%, avg_specificity=90.61% avg_auc=89.16%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.246647 Test loss=0.368480 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.24648688733577728
[5/24] Train loss=0.21702799201011658
[10/24] Train loss=0.2717197835445404
[15/24] Train loss=0.2147141396999359
[20/24] Train loss=0.2345857471227646
Test set avg_accuracy=83.29% avg_sensitivity=64.21%, avg_specificity=90.57% avg_auc=89.16%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.245872 Test loss=0.368645 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.24634484946727753
[5/24] Train loss=0.21901923418045044
[10/24] Train loss=0.2769036889076233
[15/24] Train loss=0.2136860489845276
[20/24] Train loss=0.23128721117973328
Test set avg_accuracy=83.26% avg_sensitivity=64.26%, avg_specificity=90.50% avg_auc=89.16%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.246246 Test loss=0.368641 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.2428392469882965
[5/24] Train loss=0.21582207083702087
[10/24] Train loss=0.2779920697212219
[15/24] Train loss=0.21627742052078247
[20/24] Train loss=0.23781494796276093
Test set avg_accuracy=83.31% avg_sensitivity=64.07%, avg_specificity=90.65% avg_auc=89.14%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.245652 Test loss=0.368898 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.24760842323303223
[5/24] Train loss=0.21593694388866425
[10/24] Train loss=0.2739512324333191
[15/24] Train loss=0.21842671930789948
[20/24] Train loss=0.23398618400096893
Test set avg_accuracy=83.35% avg_sensitivity=63.88%, avg_specificity=90.77% avg_auc=89.13%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.245816 Test loss=0.369122 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.24378786981105804
[5/24] Train loss=0.21844938397407532
[10/24] Train loss=0.276082843542099
[15/24] Train loss=0.21842694282531738
[20/24] Train loss=0.23316816985607147
Test set avg_accuracy=83.29% avg_sensitivity=64.17%, avg_specificity=90.59% avg_auc=89.14%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.245989 Test loss=0.369043 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.2502210736274719
[5/24] Train loss=0.21681231260299683
[10/24] Train loss=0.27402442693710327
[15/24] Train loss=0.21529561281204224
[20/24] Train loss=0.2312721312046051
Test set avg_accuracy=83.28% avg_sensitivity=64.03%, avg_specificity=90.63% avg_auc=89.13%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.246133 Test loss=0.369220 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.24542692303657532
[5/24] Train loss=0.21254852414131165
[10/24] Train loss=0.2761610150337219
[15/24] Train loss=0.21446560323238373
[20/24] Train loss=0.23573854565620422
Test set avg_accuracy=83.35% avg_sensitivity=63.74%, avg_specificity=90.83% avg_auc=89.11%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.245420 Test loss=0.369454 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.24551033973693848
[5/24] Train loss=0.2155875265598297
[10/24] Train loss=0.27256327867507935
[15/24] Train loss=0.21760961413383484
[20/24] Train loss=0.2344096601009369
Test set avg_accuracy=83.29% avg_sensitivity=63.84%, avg_specificity=90.72% avg_auc=89.12%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.245851 Test loss=0.369421 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.24254845082759857
[5/24] Train loss=0.21733100712299347
[10/24] Train loss=0.2694920003414154
[15/24] Train loss=0.21516214311122894
[20/24] Train loss=0.2316695749759674
Test set avg_accuracy=83.32% avg_sensitivity=63.93%, avg_specificity=90.72% avg_auc=89.12%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.245317 Test loss=0.369345 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.2464168220758438
[5/24] Train loss=0.21839193999767303
[10/24] Train loss=0.27465084195137024
[15/24] Train loss=0.21672853827476501
[20/24] Train loss=0.23357902467250824
Test set avg_accuracy=83.32% avg_sensitivity=63.88%, avg_specificity=90.74% avg_auc=89.12%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.246064 Test loss=0.369383 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.24282099306583405
[5/24] Train loss=0.21309733390808105
[10/24] Train loss=0.27531135082244873
[15/24] Train loss=0.21328440308570862
[20/24] Train loss=0.23425088822841644
Test set avg_accuracy=83.28% avg_sensitivity=63.60%, avg_specificity=90.79% avg_auc=89.11%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.245334 Test loss=0.369457 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.24085062742233276
[5/24] Train loss=0.21331247687339783
[10/24] Train loss=0.2738233208656311
[15/24] Train loss=0.21141475439071655
[20/24] Train loss=0.23711368441581726
Test set avg_accuracy=83.28% avg_sensitivity=63.60%, avg_specificity=90.79% avg_auc=89.11%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.245083 Test loss=0.369471 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.2462758868932724
[5/24] Train loss=0.21555310487747192
[10/24] Train loss=0.2752174437046051
[15/24] Train loss=0.2156103551387787
[20/24] Train loss=0.23139354586601257
Test set avg_accuracy=83.28% avg_sensitivity=63.60%, avg_specificity=90.79% avg_auc=89.11%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.245666 Test loss=0.369473 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.2475040704011917
[5/24] Train loss=0.2124125063419342
[10/24] Train loss=0.27259203791618347
[15/24] Train loss=0.21856220066547394
[20/24] Train loss=0.22829042375087738
Test set avg_accuracy=83.28% avg_sensitivity=63.60%, avg_specificity=90.79% avg_auc=89.11%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.245113 Test loss=0.369478 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.24369998276233673
[5/24] Train loss=0.218501016497612
[10/24] Train loss=0.27347761392593384
[15/24] Train loss=0.21377427875995636
[20/24] Train loss=0.2317679226398468
Test set avg_accuracy=83.29% avg_sensitivity=63.65%, avg_specificity=90.79% avg_auc=89.11%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.245244 Test loss=0.369477 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.2435363084077835
[5/24] Train loss=0.21843090653419495
[10/24] Train loss=0.2761114537715912
[15/24] Train loss=0.2178148329257965
[20/24] Train loss=0.23161627352237701
Test set avg_accuracy=83.29% avg_sensitivity=63.65%, avg_specificity=90.79% avg_auc=89.11%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.245387 Test loss=0.369478 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=84.45% sen=56.20%, spe=95.23%, auc=90.80%!
Fold[7] Avg_jsc=0.54%(±0.30884635908358365)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=1.283553123474121
[5/24] Train loss=1.1627318859100342
[10/24] Train loss=1.018101692199707
[15/24] Train loss=0.9125180840492249
[20/24] Train loss=0.8326408863067627
Test set avg_accuracy=61.97% avg_sensitivity=27.19%, avg_specificity=73.65% avg_auc=49.31%
Best model saved!! Metric=49.30597886611492!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=1.005902 Test loss=0.740693 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7849469780921936
[5/24] Train loss=0.7312392592430115
[10/24] Train loss=0.6971699595451355
[15/24] Train loss=0.6716784238815308
[20/24] Train loss=0.6352699398994446
Test set avg_accuracy=74.09% avg_sensitivity=0.73%, avg_specificity=98.73% avg_auc=48.94%
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.698648 Test loss=0.597609 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6668219566345215
[5/24] Train loss=0.6170205473899841
[10/24] Train loss=0.6394933462142944
[15/24] Train loss=0.6314491033554077
[20/24] Train loss=0.604159951210022
Test set avg_accuracy=74.82% avg_sensitivity=0.00%, avg_specificity=99.95% avg_auc=48.50%
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.632912 Test loss=0.586308 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.644355058670044
[5/24] Train loss=0.5991501212120056
[10/24] Train loss=0.6416059136390686
[15/24] Train loss=0.6140320301055908
[20/24] Train loss=0.5950740575790405
Test set avg_accuracy=74.82% avg_sensitivity=0.00%, avg_specificity=99.95% avg_auc=48.90%
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.621492 Test loss=0.580094 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6407890915870667
[5/24] Train loss=0.5976948738098145
[10/24] Train loss=0.6200013756752014
[15/24] Train loss=0.6117679476737976
[20/24] Train loss=0.593119204044342
Test set avg_accuracy=74.80% avg_sensitivity=0.00%, avg_specificity=99.93% avg_auc=49.26%
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.616030 Test loss=0.572372 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6375595927238464
[5/24] Train loss=0.5915151238441467
[10/24] Train loss=0.6168894171714783
[15/24] Train loss=0.6013624668121338
[20/24] Train loss=0.5911744832992554
Test set avg_accuracy=74.80% avg_sensitivity=0.00%, avg_specificity=99.93% avg_auc=50.47%
Best model saved!! Metric=50.470110803950405!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.610149 Test loss=0.569416 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6274769306182861
[5/24] Train loss=0.5853174328804016
[10/24] Train loss=0.6064627766609192
[15/24] Train loss=0.6089715361595154
[20/24] Train loss=0.5818746089935303
Test set avg_accuracy=74.80% avg_sensitivity=0.00%, avg_specificity=99.93% avg_auc=51.05%
Best model saved!! Metric=51.04845649422379!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.604789 Test loss=0.567953 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6226154565811157
[5/24] Train loss=0.575384795665741
[10/24] Train loss=0.6111642122268677
[15/24] Train loss=0.599898099899292
[20/24] Train loss=0.5831443667411804
Test set avg_accuracy=74.82% avg_sensitivity=0.00%, avg_specificity=99.95% avg_auc=51.89%
Best model saved!! Metric=51.886262344141265!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.601630 Test loss=0.566144 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.612683892250061
[5/24] Train loss=0.5840982794761658
[10/24] Train loss=0.6067201495170593
[15/24] Train loss=0.5960848927497864
[20/24] Train loss=0.5755123496055603
Test set avg_accuracy=74.82% avg_sensitivity=0.00%, avg_specificity=99.95% avg_auc=52.92%
Best model saved!! Metric=52.9196981007392!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.597603 Test loss=0.564456 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6118346452713013
[5/24] Train loss=0.5770522952079773
[10/24] Train loss=0.6005688905715942
[15/24] Train loss=0.5963179469108582
[20/24] Train loss=0.5744049549102783
Test set avg_accuracy=74.83% avg_sensitivity=0.00%, avg_specificity=99.97% avg_auc=53.80%
Best model saved!! Metric=53.80260669925799!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.596379 Test loss=0.563038 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6068564653396606
[5/24] Train loss=0.575860321521759
[10/24] Train loss=0.5908600091934204
[15/24] Train loss=0.5806037783622742
[20/24] Train loss=0.5694190263748169
Test set avg_accuracy=74.83% avg_sensitivity=0.00%, avg_specificity=99.97% avg_auc=55.00%
Best model saved!! Metric=55.00074360533195!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.591367 Test loss=0.561549 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6028684377670288
[5/24] Train loss=0.5721718072891235
[10/24] Train loss=0.587665855884552
[15/24] Train loss=0.5853751301765442
[20/24] Train loss=0.560077965259552
Test set avg_accuracy=74.84% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=56.22%
Best model saved!! Metric=56.222305655751356!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.587572 Test loss=0.560138 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.6020400524139404
[5/24] Train loss=0.5727124810218811
[10/24] Train loss=0.5866222977638245
[15/24] Train loss=0.5758926272392273
[20/24] Train loss=0.560343861579895
Test set avg_accuracy=74.84% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=57.29%
Best model saved!! Metric=57.29168759135739!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.584879 Test loss=0.558582 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.595115602016449
[5/24] Train loss=0.5623276233673096
[10/24] Train loss=0.5891343951225281
[15/24] Train loss=0.5767878293991089
[20/24] Train loss=0.5627050399780273
Test set avg_accuracy=74.84% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=58.94%
Best model saved!! Metric=58.93686146664193!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.581597 Test loss=0.556977 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.595984160900116
[5/24] Train loss=0.5590673685073853
[10/24] Train loss=0.5786651372909546
[15/24] Train loss=0.5720866322517395
[20/24] Train loss=0.5523999929428101
Test set avg_accuracy=74.84% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=60.08%
Best model saved!! Metric=60.07957703044116!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.577876 Test loss=0.555250 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5970986485481262
[5/24] Train loss=0.5593876242637634
[10/24] Train loss=0.5786728262901306
[15/24] Train loss=0.5712286829948425
[20/24] Train loss=0.5506770014762878
Test set avg_accuracy=74.84% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=61.68%
Best model saved!! Metric=61.676846688217864!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.576070 Test loss=0.552961 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5867293477058411
[5/24] Train loss=0.547205924987793
[10/24] Train loss=0.5765965580940247
[15/24] Train loss=0.5610416531562805
[20/24] Train loss=0.5460236072540283
Test set avg_accuracy=74.79% avg_sensitivity=0.00%, avg_specificity=99.91% avg_auc=63.82%
Best model saved!! Metric=63.81796163140615!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.568590 Test loss=0.547820 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5867429375648499
[5/24] Train loss=0.544637143611908
[10/24] Train loss=0.5682387351989746
[15/24] Train loss=0.549515426158905
[20/24] Train loss=0.5301753878593445
Test set avg_accuracy=74.86% avg_sensitivity=0.47%, avg_specificity=99.84% avg_auc=66.48%
Best model saved!! Metric=66.4815910613865!!
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.561958 Test loss=0.539896 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5718036890029907
[5/24] Train loss=0.5338823795318604
[10/24] Train loss=0.5600553154945374
[15/24] Train loss=0.5296611189842224
[20/24] Train loss=0.5224467515945435
Test set avg_accuracy=75.22% avg_sensitivity=3.47%, avg_specificity=99.32% avg_auc=69.87%
Best model saved!! Metric=69.86836429076581!!
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.549807 Test loss=0.525884 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5476783514022827
[5/24] Train loss=0.5159859657287598
[10/24] Train loss=0.5510801076889038
[15/24] Train loss=0.5158534049987793
[20/24] Train loss=0.49621954560279846
Test set avg_accuracy=75.51% avg_sensitivity=5.39%, avg_specificity=99.06% avg_auc=72.36%
Best model saved!! Metric=72.36214453435669!!
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.533706 Test loss=0.515253 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5276028513908386
[5/24] Train loss=0.49273595213890076
[10/24] Train loss=0.5303094387054443
[15/24] Train loss=0.4880737066268921
[20/24] Train loss=0.4578312039375305
Test set avg_accuracy=75.92% avg_sensitivity=14.29%, avg_specificity=96.63% avg_auc=75.80%
Best model saved!! Metric=75.79724535435834!!
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.509528 Test loss=0.491378 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.49985170364379883
[5/24] Train loss=0.467619389295578
[10/24] Train loss=0.5121725797653198
[15/24] Train loss=0.4700767695903778
[20/24] Train loss=0.44074898958206177
Test set avg_accuracy=76.37% avg_sensitivity=12.43%, avg_specificity=97.84% avg_auc=77.41%
Best model saved!! Metric=77.40823860660161!!
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.488751 Test loss=0.494103 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5083141326904297
[5/24] Train loss=0.4570105969905853
[10/24] Train loss=0.4889180362224579
[15/24] Train loss=0.450288861989975
[20/24] Train loss=0.4137403666973114
Test set avg_accuracy=76.51% avg_sensitivity=16.00%, avg_specificity=96.83% avg_auc=78.77%
Best model saved!! Metric=78.77323406344779!!
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.473487 Test loss=0.479894 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.49423402547836304
[5/24] Train loss=0.43851062655448914
[10/24] Train loss=0.47624871134757996
[15/24] Train loss=0.43497374653816223
[20/24] Train loss=0.4041920304298401
Test set avg_accuracy=77.32% avg_sensitivity=20.09%, avg_specificity=96.54% avg_auc=79.81%
Best model saved!! Metric=79.80655271684383!!
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.459585 Test loss=0.471046 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.4830736517906189
[5/24] Train loss=0.4434855580329895
[10/24] Train loss=0.47140562534332275
[15/24] Train loss=0.4279308617115021
[20/24] Train loss=0.39712533354759216
Test set avg_accuracy=77.81% avg_sensitivity=20.71%, avg_specificity=96.99% avg_auc=80.65%
Best model saved!! Metric=80.65400156503925!!
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.452385 Test loss=0.466891 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.4784998297691345
[5/24] Train loss=0.41682684421539307
[10/24] Train loss=0.4532562494277954
[15/24] Train loss=0.41666150093078613
[20/24] Train loss=0.3773501217365265
Test set avg_accuracy=78.10% avg_sensitivity=22.27%, avg_specificity=96.85% avg_auc=81.48%
Best model saved!! Metric=81.47826397926228!!
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.441781 Test loss=0.461298 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.47801172733306885
[5/24] Train loss=0.4083935022354126
[10/24] Train loss=0.44832906126976013
[15/24] Train loss=0.40162044763565063
[20/24] Train loss=0.37636497616767883
Test set avg_accuracy=78.48% avg_sensitivity=25.17%, avg_specificity=96.38% avg_auc=82.18%
Best model saved!! Metric=82.18250461949611!!
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.433278 Test loss=0.453502 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.4643642008304596
[5/24] Train loss=0.40502384305000305
[10/24] Train loss=0.43113675713539124
[15/24] Train loss=0.39590442180633545
[20/24] Train loss=0.36353304982185364
Test set avg_accuracy=79.08% avg_sensitivity=28.90%, avg_specificity=95.93% avg_auc=82.79%
Best model saved!! Metric=82.7927294044969!!
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.426848 Test loss=0.443113 Current lr=[0.000210185142098938]

[0/24] Train loss=0.447940468788147
[5/24] Train loss=0.4071788191795349
[10/24] Train loss=0.42732536792755127
[15/24] Train loss=0.3864346444606781
[20/24] Train loss=0.36070170998573303
Test set avg_accuracy=79.36% avg_sensitivity=31.12%, avg_specificity=95.56% avg_auc=83.31%
Best model saved!! Metric=83.31226226361031!!
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.420992 Test loss=0.437010 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.44336822628974915
[5/24] Train loss=0.4011670649051666
[10/24] Train loss=0.4268702268600464
[15/24] Train loss=0.3865225315093994
[20/24] Train loss=0.3549291789531708
Test set avg_accuracy=79.47% avg_sensitivity=30.81%, avg_specificity=95.81% avg_auc=83.60%
Best model saved!! Metric=83.60103875944831!!
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.416290 Test loss=0.437391 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.4339626431465149
[5/24] Train loss=0.3994412124156952
[10/24] Train loss=0.41767480969429016
[15/24] Train loss=0.37817394733428955
[20/24] Train loss=0.34789344668388367
Test set avg_accuracy=79.15% avg_sensitivity=28.43%, avg_specificity=96.19% avg_auc=83.67%
Best model saved!! Metric=83.66603554046146!!
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.410453 Test loss=0.445097 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.4397302567958832
[5/24] Train loss=0.3936863839626312
[10/24] Train loss=0.4182026982307434
[15/24] Train loss=0.3728555142879486
[20/24] Train loss=0.33812400698661804
Test set avg_accuracy=79.43% avg_sensitivity=28.95%, avg_specificity=96.38% avg_auc=84.00%
Best model saved!! Metric=84.0045899050374!!
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.407383 Test loss=0.442095 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.4369294047355652
[5/24] Train loss=0.3763962984085083
[10/24] Train loss=0.41088351607322693
[15/24] Train loss=0.36666733026504517
[20/24] Train loss=0.32927656173706055
Test set avg_accuracy=79.51% avg_sensitivity=28.64%, avg_specificity=96.59% avg_auc=84.25%
Best model saved!! Metric=84.24785379106754!!
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.401920 Test loss=0.444629 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.43594107031822205
[5/24] Train loss=0.37636712193489075
[10/24] Train loss=0.40651267766952515
[15/24] Train loss=0.3591044843196869
[20/24] Train loss=0.3296468257904053
Test set avg_accuracy=79.64% avg_sensitivity=29.47%, avg_specificity=96.49% avg_auc=84.62%
Best model saved!! Metric=84.61918804423149!!
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.398861 Test loss=0.439043 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.4382520914077759
[5/24] Train loss=0.36339282989501953
[10/24] Train loss=0.40921685099601746
[15/24] Train loss=0.36318349838256836
[20/24] Train loss=0.321601539850235
Test set avg_accuracy=79.62% avg_sensitivity=29.62%, avg_specificity=96.42% avg_auc=84.73%
Best model saved!! Metric=84.73227370549391!!
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.395838 Test loss=0.438267 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4315655529499054
[5/24] Train loss=0.36538317799568176
[10/24] Train loss=0.40431228280067444
[15/24] Train loss=0.3554054796695709
[20/24] Train loss=0.32091763615608215
Test set avg_accuracy=79.69% avg_sensitivity=29.62%, avg_specificity=96.50% avg_auc=84.96%
Best model saved!! Metric=84.95629663466116!!
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.392706 Test loss=0.438991 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4294047951698303
[5/24] Train loss=0.3626983165740967
[10/24] Train loss=0.40450531244277954
[15/24] Train loss=0.35458654165267944
[20/24] Train loss=0.31912100315093994
Test set avg_accuracy=80.08% avg_sensitivity=31.90%, avg_specificity=96.26% avg_auc=85.24%
Best model saved!! Metric=85.23947469665542!!
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.391295 Test loss=0.430858 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.42046740651130676
[5/24] Train loss=0.35235852003097534
[10/24] Train loss=0.39999061822891235
[15/24] Train loss=0.3466651439666748
[20/24] Train loss=0.31762638688087463
Test set avg_accuracy=80.42% avg_sensitivity=33.61%, avg_specificity=96.14% avg_auc=85.40%
Best model saved!! Metric=85.3983432058839!!
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.386174 Test loss=0.425817 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.41345179080963135
[5/24] Train loss=0.3578580319881439
[10/24] Train loss=0.3924221992492676
[15/24] Train loss=0.3457837402820587
[20/24] Train loss=0.31136706471443176
Test set avg_accuracy=80.25% avg_sensitivity=32.21%, avg_specificity=96.38% avg_auc=85.49%
Best model saved!! Metric=85.48842709591537!!
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.382720 Test loss=0.429914 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.4146864116191864
[5/24] Train loss=0.3568214178085327
[10/24] Train loss=0.38917237520217896
[15/24] Train loss=0.3426084816455841
[20/24] Train loss=0.3098253309726715
Test set avg_accuracy=80.69% avg_sensitivity=34.23%, avg_specificity=96.30% avg_auc=85.62%
Best model saved!! Metric=85.6239920679696!!
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.380932 Test loss=0.425992 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4115840494632721
[5/24] Train loss=0.3529997766017914
[10/24] Train loss=0.3908194303512573
[15/24] Train loss=0.34129005670547485
[20/24] Train loss=0.311529278755188
Test set avg_accuracy=80.43% avg_sensitivity=32.63%, avg_specificity=96.49% avg_auc=85.74%
Best model saved!! Metric=85.73718132052595!!
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.379358 Test loss=0.430061 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.4156661033630371
[5/24] Train loss=0.35239100456237793
[10/24] Train loss=0.38749417662620544
[15/24] Train loss=0.33939096331596375
[20/24] Train loss=0.30855581164360046
Test set avg_accuracy=81.02% avg_sensitivity=35.47%, avg_specificity=96.31% avg_auc=85.95%
Best model saved!! Metric=85.95493022045399!!
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.378765 Test loss=0.420093 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4031243920326233
[5/24] Train loss=0.3459557890892029
[10/24] Train loss=0.3876948952674866
[15/24] Train loss=0.3360089659690857
[20/24] Train loss=0.3021853268146515
Test set avg_accuracy=81.43% avg_sensitivity=38.11%, avg_specificity=95.98% avg_auc=85.97%
Best model saved!! Metric=85.9739189550359!!
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.373718 Test loss=0.415583 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3984623849391937
[5/24] Train loss=0.34740614891052246
[10/24] Train loss=0.38350093364715576
[15/24] Train loss=0.33509477972984314
[20/24] Train loss=0.30857253074645996
Test set avg_accuracy=81.21% avg_sensitivity=36.41%, avg_specificity=96.26% avg_auc=86.21%
Best model saved!! Metric=86.2110844666296!!
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.372685 Test loss=0.416542 Current lr=[0.00029967723776099]

[0/24] Train loss=0.39526236057281494
[5/24] Train loss=0.34387341141700745
[10/24] Train loss=0.37680259346961975
[15/24] Train loss=0.3336196839809418
[20/24] Train loss=0.3070186376571655
Test set avg_accuracy=81.47% avg_sensitivity=38.27%, avg_specificity=95.98% avg_auc=86.27%
Best model saved!! Metric=86.27337436209157!!
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.369585 Test loss=0.413629 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.39371243119239807
[5/24] Train loss=0.3456170856952667
[10/24] Train loss=0.37646886706352234
[15/24] Train loss=0.33173835277557373
[20/24] Train loss=0.30561724305152893
Test set avg_accuracy=81.47% avg_sensitivity=38.58%, avg_specificity=95.88% avg_auc=86.30%
Best model saved!! Metric=86.30191601556535!!
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.368317 Test loss=0.412760 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3947420120239258
[5/24] Train loss=0.34752434492111206
[10/24] Train loss=0.3737994134426117
[15/24] Train loss=0.32972508668899536
[20/24] Train loss=0.30832844972610474
Test set avg_accuracy=81.30% avg_sensitivity=37.08%, avg_specificity=96.16% avg_auc=86.37%
Best model saved!! Metric=86.36742174510974!!
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.368192 Test loss=0.413824 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3927817642688751
[5/24] Train loss=0.3395955264568329
[10/24] Train loss=0.3769732117652893
[15/24] Train loss=0.3260263502597809
[20/24] Train loss=0.3058788776397705
Test set avg_accuracy=81.54% avg_sensitivity=39.88%, avg_specificity=95.53% avg_auc=86.43%
Best model saved!! Metric=86.42722544951641!!
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.366230 Test loss=0.408775 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.38520869612693787
[5/24] Train loss=0.3387455940246582
[10/24] Train loss=0.37551379203796387
[15/24] Train loss=0.32772037386894226
[20/24] Train loss=0.30431681871414185
Test set avg_accuracy=81.81% avg_sensitivity=42.26%, avg_specificity=95.09% avg_auc=86.57%
Best model saved!! Metric=86.57275770563841!!
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.363412 Test loss=0.401575 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3804763853549957
[5/24] Train loss=0.34028905630111694
[10/24] Train loss=0.3739449381828308
[15/24] Train loss=0.3232608437538147
[20/24] Train loss=0.2984752058982849
Test set avg_accuracy=81.63% avg_sensitivity=39.46%, avg_specificity=95.79% avg_auc=86.61%
Best model saved!! Metric=86.6114468019521!!
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.361983 Test loss=0.407037 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3770352602005005
[5/24] Train loss=0.34043973684310913
[10/24] Train loss=0.3686271607875824
[15/24] Train loss=0.31888291239738464
[20/24] Train loss=0.29785579442977905
Test set avg_accuracy=81.60% avg_sensitivity=39.88%, avg_specificity=95.62% avg_auc=86.55%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.361128 Test loss=0.408710 Current lr=[0.000297555943323901]

[0/24] Train loss=0.38264185190200806
[5/24] Train loss=0.33960554003715515
[10/24] Train loss=0.3700769543647766
[15/24] Train loss=0.31728091835975647
[20/24] Train loss=0.29993999004364014
Test set avg_accuracy=81.74% avg_sensitivity=40.96%, avg_specificity=95.44% avg_auc=86.68%
Best model saved!! Metric=86.6826185248798!!
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.360012 Test loss=0.404523 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3747091293334961
[5/24] Train loss=0.3369830846786499
[10/24] Train loss=0.36393436789512634
[15/24] Train loss=0.31963905692100525
[20/24] Train loss=0.29989075660705566
Test set avg_accuracy=81.84% avg_sensitivity=42.21%, avg_specificity=95.15% avg_auc=86.69%
Best model saved!! Metric=86.69399555133943!!
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.357448 Test loss=0.400309 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.375925213098526
[5/24] Train loss=0.33096134662628174
[10/24] Train loss=0.37260890007019043
[15/24] Train loss=0.3193538188934326
[20/24] Train loss=0.2998846769332886
Test set avg_accuracy=81.76% avg_sensitivity=41.48%, avg_specificity=95.29% avg_auc=86.77%
Best model saved!! Metric=86.76723009220797!!
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.355565 Test loss=0.400957 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3741163909435272
[5/24] Train loss=0.33425551652908325
[10/24] Train loss=0.3662201166152954
[15/24] Train loss=0.3124009370803833
[20/24] Train loss=0.2956836223602295
Test set avg_accuracy=81.99% avg_sensitivity=41.64%, avg_specificity=95.55% avg_auc=86.85%
Best model saved!! Metric=86.85196777067661!!
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.354395 Test loss=0.401927 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3739897608757019
[5/24] Train loss=0.3329371213912964
[10/24] Train loss=0.36428695917129517
[15/24] Train loss=0.3145821988582611
[20/24] Train loss=0.2898034453392029
Test set avg_accuracy=82.07% avg_sensitivity=43.03%, avg_specificity=95.18% avg_auc=86.92%
Best model saved!! Metric=86.9168609603958!!
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.354262 Test loss=0.397102 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.37039220333099365
[5/24] Train loss=0.32828211784362793
[10/24] Train loss=0.3701326251029968
[15/24] Train loss=0.31142309308052063
[20/24] Train loss=0.29213789105415344
Test set avg_accuracy=82.15% avg_sensitivity=42.67%, avg_specificity=95.41% avg_auc=87.04%
Best model saved!! Metric=87.03734213925391!!
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.353862 Test loss=0.396115 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3665190637111664
[5/24] Train loss=0.3267112374305725
[10/24] Train loss=0.35968416929244995
[15/24] Train loss=0.31228718161582947
[20/24] Train loss=0.29011771082878113
Test set avg_accuracy=82.38% avg_sensitivity=44.74%, avg_specificity=95.03% avg_auc=87.23%
Best model saved!! Metric=87.23400795887409!!
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.351606 Test loss=0.390098 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.366767019033432
[5/24] Train loss=0.32612961530685425
[10/24] Train loss=0.3599354028701782
[15/24] Train loss=0.3123612105846405
[20/24] Train loss=0.29635509848594666
Test set avg_accuracy=82.86% avg_sensitivity=47.85%, avg_specificity=94.63% avg_auc=87.40%
Best model saved!! Metric=87.39962341411862!!
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.350664 Test loss=0.382195 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3648318946361542
[5/24] Train loss=0.32112595438957214
[10/24] Train loss=0.3532392680644989
[15/24] Train loss=0.3088308572769165
[20/24] Train loss=0.2873426079750061
Test set avg_accuracy=82.66% avg_sensitivity=47.02%, avg_specificity=94.63% avg_auc=87.36%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.348982 Test loss=0.384501 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3517385721206665
[5/24] Train loss=0.3214438259601593
[10/24] Train loss=0.3499256372451782
[15/24] Train loss=0.30935347080230713
[20/24] Train loss=0.29213854670524597
Test set avg_accuracy=82.77% avg_sensitivity=46.40%, avg_specificity=94.99% avg_auc=87.48%
Best model saved!! Metric=87.48308196530522!!
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.347471 Test loss=0.384351 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.36546650528907776
[5/24] Train loss=0.3231528401374817
[10/24] Train loss=0.35326439142227173
[15/24] Train loss=0.3075502812862396
[20/24] Train loss=0.2938312590122223
Test set avg_accuracy=82.88% avg_sensitivity=47.13%, avg_specificity=94.89% avg_auc=87.42%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.346811 Test loss=0.383836 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3559802174568176
[5/24] Train loss=0.3191416561603546
[10/24] Train loss=0.3546465337276459
[15/24] Train loss=0.3056637644767761
[20/24] Train loss=0.2921707034111023
Test set avg_accuracy=82.92% avg_sensitivity=48.68%, avg_specificity=94.42% avg_auc=87.55%
Best model saved!! Metric=87.54763285335734!!
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.345375 Test loss=0.379828 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.35165733098983765
[5/24] Train loss=0.31942376494407654
[10/24] Train loss=0.3479852080345154
[15/24] Train loss=0.3090423047542572
[20/24] Train loss=0.2893151044845581
Test set avg_accuracy=83.05% avg_sensitivity=50.08%, avg_specificity=94.12% avg_auc=87.57%
Best model saved!! Metric=87.57391801821028!!
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.343327 Test loss=0.377310 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3527694344520569
[5/24] Train loss=0.31562918424606323
[10/24] Train loss=0.35043442249298096
[15/24] Train loss=0.3054664731025696
[20/24] Train loss=0.28404510021209717
Test set avg_accuracy=83.09% avg_sensitivity=50.85%, avg_specificity=93.91% avg_auc=87.60%
Best model saved!! Metric=87.60176606041139!!
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.342124 Test loss=0.376335 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.35286739468574524
[5/24] Train loss=0.31803151965141296
[10/24] Train loss=0.35194170475006104
[15/24] Train loss=0.3046380579471588
[20/24] Train loss=0.28719332814216614
Test set avg_accuracy=82.96% avg_sensitivity=48.06%, avg_specificity=94.68% avg_auc=87.48%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.341757 Test loss=0.382371 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.35394516587257385
[5/24] Train loss=0.3159157633781433
[10/24] Train loss=0.3493680953979492
[15/24] Train loss=0.3039924204349518
[20/24] Train loss=0.2869373857975006
Test set avg_accuracy=83.02% avg_sensitivity=49.61%, avg_specificity=94.24% avg_auc=87.46%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.341015 Test loss=0.379936 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3524526059627533
[5/24] Train loss=0.3143364191055298
[10/24] Train loss=0.34806114435195923
[15/24] Train loss=0.29694417119026184
[20/24] Train loss=0.2834920287132263
Test set avg_accuracy=83.23% avg_sensitivity=52.36%, avg_specificity=93.60% avg_auc=87.57%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.339199 Test loss=0.375683 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.34607744216918945
[5/24] Train loss=0.31407350301742554
[10/24] Train loss=0.3407232463359833
[15/24] Train loss=0.2982235252857208
[20/24] Train loss=0.28160691261291504
Test set avg_accuracy=83.20% avg_sensitivity=50.75%, avg_specificity=94.10% avg_auc=87.57%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.337132 Test loss=0.378226 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.34461385011672974
[5/24] Train loss=0.3213130533695221
[10/24] Train loss=0.3446981906890869
[15/24] Train loss=0.29726043343544006
[20/24] Train loss=0.28471988439559937
Test set avg_accuracy=83.18% avg_sensitivity=51.32%, avg_specificity=93.88% avg_auc=87.51%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.337297 Test loss=0.378190 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3471738398075104
[5/24] Train loss=0.3169483244419098
[10/24] Train loss=0.3449440002441406
[15/24] Train loss=0.2992543578147888
[20/24] Train loss=0.2862843871116638
Test set avg_accuracy=83.06% avg_sensitivity=50.96%, avg_specificity=93.84% avg_auc=87.46%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.336293 Test loss=0.379702 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.34278908371925354
[5/24] Train loss=0.31392791867256165
[10/24] Train loss=0.34309181571006775
[15/24] Train loss=0.29397910833358765
[20/24] Train loss=0.29044482111930847
Test set avg_accuracy=83.53% avg_sensitivity=54.95%, avg_specificity=93.13% avg_auc=87.46%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.336153 Test loss=0.377003 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3352142870426178
[5/24] Train loss=0.3088673949241638
[10/24] Train loss=0.34143275022506714
[15/24] Train loss=0.294590562582016
[20/24] Train loss=0.2837674021720886
Test set avg_accuracy=83.37% avg_sensitivity=55.10%, avg_specificity=92.87% avg_auc=87.52%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.333886 Test loss=0.375949 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.33144596219062805
[5/24] Train loss=0.3091256618499756
[10/24] Train loss=0.340958833694458
[15/24] Train loss=0.2941822111606598
[20/24] Train loss=0.27728068828582764
Test set avg_accuracy=83.16% avg_sensitivity=52.62%, avg_specificity=93.42% avg_auc=87.51%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.332913 Test loss=0.378977 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.34047770500183105
[5/24] Train loss=0.30561563372612
[10/24] Train loss=0.3367795944213867
[15/24] Train loss=0.29033100605010986
[20/24] Train loss=0.2835690379142761
Test set avg_accuracy=83.29% avg_sensitivity=52.98%, avg_specificity=93.48% avg_auc=87.55%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.332922 Test loss=0.378364 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3369161784648895
[5/24] Train loss=0.3058343827724457
[10/24] Train loss=0.3417583703994751
[15/24] Train loss=0.29277995228767395
[20/24] Train loss=0.2863956093788147
Test set avg_accuracy=83.40% avg_sensitivity=54.84%, avg_specificity=92.99% avg_auc=87.64%
Best model saved!! Metric=87.63615837000991!!
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.332869 Test loss=0.375043 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3407337963581085
[5/24] Train loss=0.3065245449542999
[10/24] Train loss=0.3359765410423279
[15/24] Train loss=0.2917267084121704
[20/24] Train loss=0.2852703630924225
Test set avg_accuracy=83.46% avg_sensitivity=57.07%, avg_specificity=92.33% avg_auc=87.69%
Best model saved!! Metric=87.68850350125061!!
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.331382 Test loss=0.373557 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3334260582923889
[5/24] Train loss=0.3042868971824646
[10/24] Train loss=0.33648568391799927
[15/24] Train loss=0.29203909635543823
[20/24] Train loss=0.28408971428871155
Test set avg_accuracy=83.35% avg_sensitivity=57.48%, avg_specificity=92.03% avg_auc=87.67%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.329517 Test loss=0.373276 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3296862840652466
[5/24] Train loss=0.3075540065765381
[10/24] Train loss=0.33435070514678955
[15/24] Train loss=0.2946341335773468
[20/24] Train loss=0.28039607405662537
Test set avg_accuracy=83.11% avg_sensitivity=55.98%, avg_specificity=92.22% avg_auc=87.55%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.329737 Test loss=0.376785 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3367749750614166
[5/24] Train loss=0.31128111481666565
[10/24] Train loss=0.3373568654060364
[15/24] Train loss=0.2904641628265381
[20/24] Train loss=0.28188350796699524
Test set avg_accuracy=83.07% avg_sensitivity=57.02%, avg_specificity=91.82% avg_auc=87.55%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.329623 Test loss=0.377108 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3294306993484497
[5/24] Train loss=0.3028494417667389
[10/24] Train loss=0.33888372778892517
[15/24] Train loss=0.2853524684906006
[20/24] Train loss=0.2805873453617096
Test set avg_accuracy=83.10% avg_sensitivity=57.28%, avg_specificity=91.77% avg_auc=87.66%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.327607 Test loss=0.375308 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3262166380882263
[5/24] Train loss=0.3025287091732025
[10/24] Train loss=0.3316887617111206
[15/24] Train loss=0.29157957434654236
[20/24] Train loss=0.2773829698562622
Test set avg_accuracy=83.23% avg_sensitivity=58.47%, avg_specificity=91.55% avg_auc=87.64%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.327938 Test loss=0.375653 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.324981689453125
[5/24] Train loss=0.3038754165172577
[10/24] Train loss=0.33646300435066223
[15/24] Train loss=0.2901485562324524
[20/24] Train loss=0.28244224190711975
Test set avg_accuracy=83.11% avg_sensitivity=58.16%, avg_specificity=91.49% avg_auc=87.67%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.327733 Test loss=0.374711 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3335922062397003
[5/24] Train loss=0.30410367250442505
[10/24] Train loss=0.3323998749256134
[15/24] Train loss=0.28963392972946167
[20/24] Train loss=0.2772752642631531
Test set avg_accuracy=83.01% avg_sensitivity=57.69%, avg_specificity=91.51% avg_auc=87.59%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.326315 Test loss=0.376478 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3297707438468933
[5/24] Train loss=0.3057299554347992
[10/24] Train loss=0.33640342950820923
[15/24] Train loss=0.2873552441596985
[20/24] Train loss=0.27805987000465393
Test set avg_accuracy=82.96% avg_sensitivity=58.73%, avg_specificity=91.09% avg_auc=87.60%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.325441 Test loss=0.377329 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.32901936769485474
[5/24] Train loss=0.3028380870819092
[10/24] Train loss=0.3298678398132324
[15/24] Train loss=0.2891644835472107
[20/24] Train loss=0.27335405349731445
Test set avg_accuracy=82.77% avg_sensitivity=59.55%, avg_specificity=90.57% avg_auc=87.60%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.325661 Test loss=0.377092 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3215242624282837
[5/24] Train loss=0.3064793348312378
[10/24] Train loss=0.330553263425827
[15/24] Train loss=0.2898595929145813
[20/24] Train loss=0.2742607891559601
Test set avg_accuracy=82.92% avg_sensitivity=59.66%, avg_specificity=90.73% avg_auc=87.65%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.324250 Test loss=0.375937 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.32611894607543945
[5/24] Train loss=0.3049865961074829
[10/24] Train loss=0.33005258440971375
[15/24] Train loss=0.2863406538963318
[20/24] Train loss=0.28399989008903503
Test set avg_accuracy=83.06% avg_sensitivity=62.14%, avg_specificity=90.09% avg_auc=87.78%
Best model saved!! Metric=87.77880358180862!!
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.325583 Test loss=0.374394 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.32461410760879517
[5/24] Train loss=0.3027549982070923
[10/24] Train loss=0.3327925503253937
[15/24] Train loss=0.2899152338504791
[20/24] Train loss=0.2768721580505371
Test set avg_accuracy=82.89% avg_sensitivity=60.85%, avg_specificity=90.29% avg_auc=87.82%
Best model saved!! Metric=87.81858263869366!!
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.324418 Test loss=0.373017 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3186858594417572
[5/24] Train loss=0.2994096875190735
[10/24] Train loss=0.3338075578212738
[15/24] Train loss=0.2885819375514984
[20/24] Train loss=0.272123783826828
Test set avg_accuracy=83.05% avg_sensitivity=65.35%, avg_specificity=88.99% avg_auc=87.89%
Best model saved!! Metric=87.88989848863903!!
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.323381 Test loss=0.375407 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3221176862716675
[5/24] Train loss=0.3059845268726349
[10/24] Train loss=0.3357105851173401
[15/24] Train loss=0.2906816005706787
[20/24] Train loss=0.27340635657310486
Test set avg_accuracy=82.92% avg_sensitivity=64.53%, avg_specificity=89.09% avg_auc=87.94%
Best model saved!! Metric=87.94291471130593!!
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.324014 Test loss=0.373417 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3209286034107208
[5/24] Train loss=0.3034079074859619
[10/24] Train loss=0.33604148030281067
[15/24] Train loss=0.2896791100502014
[20/24] Train loss=0.2760431170463562
Test set avg_accuracy=82.98% avg_sensitivity=67.01%, avg_specificity=88.35% avg_auc=88.05%
Best model saved!! Metric=88.04553314790792!!
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.323427 Test loss=0.374628 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.32126280665397644
[5/24] Train loss=0.30419981479644775
[10/24] Train loss=0.33024320006370544
[15/24] Train loss=0.2847766876220703
[20/24] Train loss=0.28081145882606506
Test set avg_accuracy=82.88% avg_sensitivity=69.29%, avg_specificity=87.44% avg_auc=88.08%
Best model saved!! Metric=88.07667359166959!!
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.323669 Test loss=0.379186 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.31826063990592957
[5/24] Train loss=0.3037097454071045
[10/24] Train loss=0.3303632140159607
[15/24] Train loss=0.29297348856925964
[20/24] Train loss=0.2808622419834137
Test set avg_accuracy=82.76% avg_sensitivity=70.48%, avg_specificity=86.88% avg_auc=88.06%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.322362 Test loss=0.382196 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.31529924273490906
[5/24] Train loss=0.3053291141986847
[10/24] Train loss=0.3268575966358185
[15/24] Train loss=0.2848323583602905
[20/24] Train loss=0.27678579092025757
Test set avg_accuracy=82.68% avg_sensitivity=69.39%, avg_specificity=87.15% avg_auc=88.03%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.322021 Test loss=0.380576 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.31426170468330383
[5/24] Train loss=0.3041142523288727
[10/24] Train loss=0.33598601818084717
[15/24] Train loss=0.2875962555408478
[20/24] Train loss=0.2733224332332611
Test set avg_accuracy=83.06% avg_sensitivity=66.86%, avg_specificity=88.50% avg_auc=88.07%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.321450 Test loss=0.374201 Current lr=[0.000156543481933168]

[0/24] Train loss=0.317392498254776
[5/24] Train loss=0.3040049970149994
[10/24] Train loss=0.3312988877296448
[15/24] Train loss=0.2843637466430664
[20/24] Train loss=0.27195727825164795
Test set avg_accuracy=83.09% avg_sensitivity=63.65%, avg_specificity=89.62% avg_auc=88.07%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.319578 Test loss=0.370191 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.310641884803772
[5/24] Train loss=0.2989294230937958
[10/24] Train loss=0.33078649640083313
[15/24] Train loss=0.28275179862976074
[20/24] Train loss=0.2751069664955139
Test set avg_accuracy=82.89% avg_sensitivity=67.43%, avg_specificity=88.08% avg_auc=88.09%
Best model saved!! Metric=88.09321667091992!!
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.317719 Test loss=0.375799 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3134482800960541
[5/24] Train loss=0.29573410749435425
[10/24] Train loss=0.3253321647644043
[15/24] Train loss=0.27963200211524963
[20/24] Train loss=0.26677170395851135
Test set avg_accuracy=82.83% avg_sensitivity=66.70%, avg_specificity=88.24% avg_auc=88.10%
Best model saved!! Metric=88.0965360962963!!
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.317227 Test loss=0.375083 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.31072402000427246
[5/24] Train loss=0.2995985150337219
[10/24] Train loss=0.33138105273246765
[15/24] Train loss=0.2811245918273926
[20/24] Train loss=0.273005872964859
Test set avg_accuracy=82.77% avg_sensitivity=66.08%, avg_specificity=88.38% avg_auc=88.13%
Best model saved!! Metric=88.1253930276213!!
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.317407 Test loss=0.373409 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.31122833490371704
[5/24] Train loss=0.30047377943992615
[10/24] Train loss=0.33191004395484924
[15/24] Train loss=0.2840132415294647
[20/24] Train loss=0.26637324690818787
Test set avg_accuracy=82.90% avg_sensitivity=65.04%, avg_specificity=88.90% avg_auc=88.16%
Best model saved!! Metric=88.15864132901685!!
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.316387 Test loss=0.371190 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3106163442134857
[5/24] Train loss=0.29414889216423035
[10/24] Train loss=0.32975009083747864
[15/24] Train loss=0.2845990061759949
[20/24] Train loss=0.2689090967178345
Test set avg_accuracy=82.80% avg_sensitivity=65.67%, avg_specificity=88.55% avg_auc=88.12%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.316368 Test loss=0.373237 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.31333085894584656
[5/24] Train loss=0.299533873796463
[10/24] Train loss=0.33211830258369446
[15/24] Train loss=0.28518912196159363
[20/24] Train loss=0.273145854473114
Test set avg_accuracy=82.75% avg_sensitivity=65.20%, avg_specificity=88.64% avg_auc=88.15%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.316017 Test loss=0.372421 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3155512511730194
[5/24] Train loss=0.2937289774417877
[10/24] Train loss=0.3328479826450348
[15/24] Train loss=0.2825869619846344
[20/24] Train loss=0.2715872526168823
Test set avg_accuracy=82.84% avg_sensitivity=66.39%, avg_specificity=88.36% avg_auc=88.18%
Best model saved!! Metric=88.18106208820772!!
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.316174 Test loss=0.373058 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3121432065963745
[5/24] Train loss=0.29582852125167847
[10/24] Train loss=0.3296529948711395
[15/24] Train loss=0.2842034697532654
[20/24] Train loss=0.26577743887901306
Test set avg_accuracy=82.80% avg_sensitivity=66.29%, avg_specificity=88.35% avg_auc=88.19%
Best model saved!! Metric=88.18568316071268!!
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.315241 Test loss=0.372995 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3088908791542053
[5/24] Train loss=0.3004007935523987
[10/24] Train loss=0.33063846826553345
[15/24] Train loss=0.2829597592353821
[20/24] Train loss=0.26785019040107727
Test set avg_accuracy=82.80% avg_sensitivity=69.03%, avg_specificity=87.42% avg_auc=88.20%
Best model saved!! Metric=88.19806006835765!!
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.316420 Test loss=0.377069 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.31580454111099243
[5/24] Train loss=0.3051682412624359
[10/24] Train loss=0.3334715664386749
[15/24] Train loss=0.28893187642097473
[20/24] Train loss=0.2704748213291168
Test set avg_accuracy=82.37% avg_sensitivity=70.79%, avg_specificity=86.26% avg_auc=88.17%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.318330 Test loss=0.383389 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.31492799520492554
[5/24] Train loss=0.3052417039871216
[10/24] Train loss=0.340641051530838
[15/24] Train loss=0.27941882610321045
[20/24] Train loss=0.269305557012558
Test set avg_accuracy=81.97% avg_sensitivity=74.57%, avg_specificity=84.45% avg_auc=88.14%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.319743 Test loss=0.397515 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.31860294938087463
[5/24] Train loss=0.31291595101356506
[10/24] Train loss=0.3437759578227997
[15/24] Train loss=0.2832677960395813
[20/24] Train loss=0.27743446826934814
Test set avg_accuracy=81.28% avg_sensitivity=76.80%, avg_specificity=82.78% avg_auc=88.16%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.322340 Test loss=0.407361 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3226453363895416
[5/24] Train loss=0.30836114287376404
[10/24] Train loss=0.3269408345222473
[15/24] Train loss=0.2814444899559021
[20/24] Train loss=0.28644806146621704
Test set avg_accuracy=82.76% avg_sensitivity=69.91%, avg_specificity=87.08% avg_auc=88.25%
Best model saved!! Metric=88.24709928612987!!
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.320187 Test loss=0.378631 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3125557601451874
[5/24] Train loss=0.29777833819389343
[10/24] Train loss=0.3266817331314087
[15/24] Train loss=0.2809028625488281
[20/24] Train loss=0.2800787389278412
Test set avg_accuracy=82.81% avg_sensitivity=68.62%, avg_specificity=87.58% avg_auc=88.21%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.316458 Test loss=0.376720 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.31330904364585876
[5/24] Train loss=0.2942187488079071
[10/24] Train loss=0.3242913782596588
[15/24] Train loss=0.2772060036659241
[20/24] Train loss=0.2815937101840973
Test set avg_accuracy=82.49% avg_sensitivity=70.22%, avg_specificity=86.61% avg_auc=88.17%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.314897 Test loss=0.381927 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3154667317867279
[5/24] Train loss=0.2932795584201813
[10/24] Train loss=0.32131069898605347
[15/24] Train loss=0.27835986018180847
[20/24] Train loss=0.2790098786354065
Test set avg_accuracy=82.84% avg_sensitivity=68.41%, avg_specificity=87.68% avg_auc=88.14%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.315238 Test loss=0.377314 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.30598825216293335
[5/24] Train loss=0.2972625195980072
[10/24] Train loss=0.3174636662006378
[15/24] Train loss=0.2794136703014374
[20/24] Train loss=0.2764083743095398
Test set avg_accuracy=82.79% avg_sensitivity=68.72%, avg_specificity=87.51% avg_auc=88.15%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.313375 Test loss=0.378076 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.30865874886512756
[5/24] Train loss=0.29031556844711304
[10/24] Train loss=0.3239053189754486
[15/24] Train loss=0.2720967233181
[20/24] Train loss=0.27553144097328186
Test set avg_accuracy=82.94% avg_sensitivity=68.25%, avg_specificity=87.88% avg_auc=88.15%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.313504 Test loss=0.376936 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3107868432998657
[5/24] Train loss=0.293768972158432
[10/24] Train loss=0.3225003182888031
[15/24] Train loss=0.278841108083725
[20/24] Train loss=0.2763897180557251
Test set avg_accuracy=82.75% avg_sensitivity=68.67%, avg_specificity=87.48% avg_auc=88.13%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.313491 Test loss=0.378456 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3044404089450836
[5/24] Train loss=0.29577887058258057
[10/24] Train loss=0.3238239884376526
[15/24] Train loss=0.2822396755218506
[20/24] Train loss=0.2678258717060089
Test set avg_accuracy=83.02% avg_sensitivity=67.94%, avg_specificity=88.08% avg_auc=88.14%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.312539 Test loss=0.375865 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.30703526735305786
[5/24] Train loss=0.29287073016166687
[10/24] Train loss=0.3216625452041626
[15/24] Train loss=0.27559563517570496
[20/24] Train loss=0.2714192569255829
Test set avg_accuracy=82.81% avg_sensitivity=68.00%, avg_specificity=87.79% avg_auc=88.11%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.311850 Test loss=0.377542 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.30660101771354675
[5/24] Train loss=0.29174715280532837
[10/24] Train loss=0.3211905360221863
[15/24] Train loss=0.28194934129714966
[20/24] Train loss=0.27107152342796326
Test set avg_accuracy=82.97% avg_sensitivity=67.69%, avg_specificity=88.10% avg_auc=88.12%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.312268 Test loss=0.376264 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.307591050863266
[5/24] Train loss=0.28938156366348267
[10/24] Train loss=0.31986185908317566
[15/24] Train loss=0.27756690979003906
[20/24] Train loss=0.2688647508621216
Test set avg_accuracy=82.83% avg_sensitivity=67.17%, avg_specificity=88.08% avg_auc=88.11%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.311690 Test loss=0.376510 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3085223138332367
[5/24] Train loss=0.2947729229927063
[10/24] Train loss=0.32683971524238586
[15/24] Train loss=0.2763996720314026
[20/24] Train loss=0.27138715982437134
Test set avg_accuracy=82.89% avg_sensitivity=67.27%, avg_specificity=88.14% avg_auc=88.11%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.312089 Test loss=0.376378 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.306364506483078
[5/24] Train loss=0.289980947971344
[10/24] Train loss=0.32141566276550293
[15/24] Train loss=0.2794731855392456
[20/24] Train loss=0.26645612716674805
Test set avg_accuracy=82.96% avg_sensitivity=66.34%, avg_specificity=88.54% avg_auc=88.12%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.310896 Test loss=0.374606 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.30996808409690857
[5/24] Train loss=0.2919522821903229
[10/24] Train loss=0.3243914544582367
[15/24] Train loss=0.27879780530929565
[20/24] Train loss=0.2672255337238312
Test set avg_accuracy=82.94% avg_sensitivity=65.98%, avg_specificity=88.64% avg_auc=88.12%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.311668 Test loss=0.374251 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3139312267303467
[5/24] Train loss=0.29272666573524475
[10/24] Train loss=0.3222144544124603
[15/24] Train loss=0.27705761790275574
[20/24] Train loss=0.27033668756484985
Test set avg_accuracy=82.98% avg_sensitivity=66.39%, avg_specificity=88.55% avg_auc=88.11%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.311412 Test loss=0.374839 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3084839880466461
[5/24] Train loss=0.2919217050075531
[10/24] Train loss=0.31944510340690613
[15/24] Train loss=0.27610743045806885
[20/24] Train loss=0.27023860812187195
Test set avg_accuracy=83.06% avg_sensitivity=66.34%, avg_specificity=88.68% avg_auc=88.10%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.310620 Test loss=0.374563 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3072885572910309
[5/24] Train loss=0.29843026399612427
[10/24] Train loss=0.3227477967739105
[15/24] Train loss=0.28005048632621765
[20/24] Train loss=0.2696155905723572
Test set avg_accuracy=83.12% avg_sensitivity=65.87%, avg_specificity=88.92% avg_auc=88.11%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.312705 Test loss=0.373519 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3054092228412628
[5/24] Train loss=0.295209676027298
[10/24] Train loss=0.31916743516921997
[15/24] Train loss=0.27917659282684326
[20/24] Train loss=0.2663307189941406
Test set avg_accuracy=82.93% avg_sensitivity=66.65%, avg_specificity=88.40% avg_auc=88.12%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.311607 Test loss=0.375127 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3075255751609802
[5/24] Train loss=0.2951306700706482
[10/24] Train loss=0.3199608027935028
[15/24] Train loss=0.27761179208755493
[20/24] Train loss=0.26740729808807373
Test set avg_accuracy=82.83% avg_sensitivity=68.20%, avg_specificity=87.74% avg_auc=88.13%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.312650 Test loss=0.377691 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3058680295944214
[5/24] Train loss=0.2962082624435425
[10/24] Train loss=0.32034990191459656
[15/24] Train loss=0.2719876170158386
[20/24] Train loss=0.26054275035858154
Test set avg_accuracy=82.29% avg_sensitivity=70.74%, avg_specificity=86.17% avg_auc=88.12%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.311953 Test loss=0.385323 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3061521649360657
[5/24] Train loss=0.2984493374824524
[10/24] Train loss=0.3260815441608429
[15/24] Train loss=0.27659252285957336
[20/24] Train loss=0.26899346709251404
Test set avg_accuracy=81.86% avg_sensitivity=72.45%, avg_specificity=85.02% avg_auc=88.11%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.313668 Test loss=0.393056 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3090926706790924
[5/24] Train loss=0.29010170698165894
[10/24] Train loss=0.3225875496864319
[15/24] Train loss=0.2774606943130493
[20/24] Train loss=0.2677931487560272
Test set avg_accuracy=81.86% avg_sensitivity=73.17%, avg_specificity=84.78% avg_auc=88.09%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.311587 Test loss=0.394802 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.30730652809143066
[5/24] Train loss=0.29158443212509155
[10/24] Train loss=0.32191798090934753
[15/24] Train loss=0.2766028642654419
[20/24] Train loss=0.2650136947631836
Test set avg_accuracy=81.86% avg_sensitivity=71.88%, avg_specificity=85.21% avg_auc=88.09%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.311598 Test loss=0.391618 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3090652823448181
[5/24] Train loss=0.2885396480560303
[10/24] Train loss=0.3174764811992645
[15/24] Train loss=0.27941006422042847
[20/24] Train loss=0.26765501499176025
Test set avg_accuracy=82.21% avg_sensitivity=70.74%, avg_specificity=86.07% avg_auc=88.10%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.311473 Test loss=0.386380 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.3060620129108429
[5/24] Train loss=0.28849291801452637
[10/24] Train loss=0.3181722164154053
[15/24] Train loss=0.2815234363079071
[20/24] Train loss=0.26680243015289307
Test set avg_accuracy=82.23% avg_sensitivity=70.79%, avg_specificity=86.07% avg_auc=88.09%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.311159 Test loss=0.386036 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.30502408742904663
[5/24] Train loss=0.2914831340312958
[10/24] Train loss=0.3207626938819885
[15/24] Train loss=0.27719366550445557
[20/24] Train loss=0.2704305350780487
Test set avg_accuracy=82.17% avg_sensitivity=70.95%, avg_specificity=85.95% avg_auc=88.08%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.310305 Test loss=0.387339 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.3022293150424957
[5/24] Train loss=0.2858586013317108
[10/24] Train loss=0.3215377926826477
[15/24] Train loss=0.2718278467655182
[20/24] Train loss=0.26712408661842346
Test set avg_accuracy=82.32% avg_sensitivity=70.12%, avg_specificity=86.42% avg_auc=88.09%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.309635 Test loss=0.384040 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.30546054244041443
[5/24] Train loss=0.29363036155700684
[10/24] Train loss=0.3205735683441162
[15/24] Train loss=0.27388477325439453
[20/24] Train loss=0.26488277316093445
Test set avg_accuracy=82.28% avg_sensitivity=70.69%, avg_specificity=86.17% avg_auc=88.09%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.310201 Test loss=0.386051 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.30537351965904236
[5/24] Train loss=0.28863725066185
[10/24] Train loss=0.3188053071498871
[15/24] Train loss=0.2780827283859253
[20/24] Train loss=0.2641858756542206
Test set avg_accuracy=82.25% avg_sensitivity=70.33%, avg_specificity=86.26% avg_auc=88.09%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.309518 Test loss=0.384991 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.309433251619339
[5/24] Train loss=0.2880852520465851
[10/24] Train loss=0.3208996057510376
[15/24] Train loss=0.27368661761283875
[20/24] Train loss=0.2648041546344757
Test set avg_accuracy=82.29% avg_sensitivity=70.22%, avg_specificity=86.35% avg_auc=88.09%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.308833 Test loss=0.384755 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3008181154727936
[5/24] Train loss=0.2874704599380493
[10/24] Train loss=0.3202831745147705
[15/24] Train loss=0.27536287903785706
[20/24] Train loss=0.2660667896270752
Test set avg_accuracy=82.32% avg_sensitivity=70.22%, avg_specificity=86.38% avg_auc=88.09%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.308644 Test loss=0.384799 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.31225863099098206
[5/24] Train loss=0.28583237528800964
[10/24] Train loss=0.314405232667923
[15/24] Train loss=0.27540913224220276
[20/24] Train loss=0.264862596988678
Test set avg_accuracy=82.40% avg_sensitivity=69.91%, avg_specificity=86.59% avg_auc=88.09%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.309359 Test loss=0.383693 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.309132844209671
[5/24] Train loss=0.28859439492225647
[10/24] Train loss=0.32043400406837463
[15/24] Train loss=0.27067458629608154
[20/24] Train loss=0.26396268606185913
Test set avg_accuracy=82.38% avg_sensitivity=70.07%, avg_specificity=86.52% avg_auc=88.09%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.309383 Test loss=0.384059 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.3032309114933014
[5/24] Train loss=0.2911919951438904
[10/24] Train loss=0.3246575891971588
[15/24] Train loss=0.27874574065208435
[20/24] Train loss=0.2655446231365204
Test set avg_accuracy=82.38% avg_sensitivity=69.96%, avg_specificity=86.55% avg_auc=88.09%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.310357 Test loss=0.383786 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.30347031354904175
[5/24] Train loss=0.28315961360931396
[10/24] Train loss=0.31848007440567017
[15/24] Train loss=0.27310043573379517
[20/24] Train loss=0.269991010427475
Test set avg_accuracy=82.37% avg_sensitivity=70.07%, avg_specificity=86.50% avg_auc=88.09%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.308954 Test loss=0.384167 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3054788410663605
[5/24] Train loss=0.2879004180431366
[10/24] Train loss=0.3220371603965759
[15/24] Train loss=0.27704501152038574
[20/24] Train loss=0.27012455463409424
Test set avg_accuracy=82.34% avg_sensitivity=70.12%, avg_specificity=86.45% avg_auc=88.08%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.309740 Test loss=0.384453 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.30887529253959656
[5/24] Train loss=0.2850223481655121
[10/24] Train loss=0.3129837214946747
[15/24] Train loss=0.2744596004486084
[20/24] Train loss=0.26893994212150574
Test set avg_accuracy=82.37% avg_sensitivity=69.91%, avg_specificity=86.55% avg_auc=88.09%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.309368 Test loss=0.383896 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.302903950214386
[5/24] Train loss=0.2890874445438385
[10/24] Train loss=0.3169606328010559
[15/24] Train loss=0.27467718720436096
[20/24] Train loss=0.2685185670852661
Test set avg_accuracy=82.38% avg_sensitivity=69.81%, avg_specificity=86.61% avg_auc=88.09%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.309448 Test loss=0.383641 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3041634261608124
[5/24] Train loss=0.2933826744556427
[10/24] Train loss=0.32398533821105957
[15/24] Train loss=0.27601346373558044
[20/24] Train loss=0.2659249007701874
Test set avg_accuracy=82.41% avg_sensitivity=69.81%, avg_specificity=86.64% avg_auc=88.09%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.309690 Test loss=0.383564 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3041701912879944
[5/24] Train loss=0.289819598197937
[10/24] Train loss=0.31922152638435364
[15/24] Train loss=0.272527277469635
[20/24] Train loss=0.2688332498073578
Test set avg_accuracy=82.41% avg_sensitivity=69.81%, avg_specificity=86.64% avg_auc=88.09%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.308819 Test loss=0.383539 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3073974847793579
[5/24] Train loss=0.2862792909145355
[10/24] Train loss=0.3174830973148346
[15/24] Train loss=0.2775290906429291
[20/24] Train loss=0.2655848264694214
Test set avg_accuracy=82.41% avg_sensitivity=69.81%, avg_specificity=86.64% avg_auc=88.09%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.309320 Test loss=0.383534 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=82.76% sen=69.91%, spe=87.08%, auc=88.25%!
Fold[8] Avg_jsc=0.56%(±0.25986236981550637)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/23] Train loss=1.2490123510360718
[5/23] Train loss=1.1117675304412842
[10/23] Train loss=1.0016409158706665
[15/23] Train loss=0.8925236463546753
[20/23] Train loss=0.8147916793823242
Test set avg_accuracy=60.65% avg_sensitivity=29.38%, avg_specificity=70.61% avg_auc=50.23%
Best model saved!! Metric=50.23353192276991!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.989866 Test loss=0.747873 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.7909355163574219
[5/23] Train loss=0.715345561504364
[10/23] Train loss=0.6931854486465454
[15/23] Train loss=0.6660020351409912
[20/23] Train loss=0.6579023003578186
Test set avg_accuracy=73.23% avg_sensitivity=4.74%, avg_specificity=95.04% avg_auc=50.50%
Best model saved!! Metric=50.49820575408073!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.709665 Test loss=0.611004 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.6539373397827148
[5/23] Train loss=0.635270893573761
[10/23] Train loss=0.6613328456878662
[15/23] Train loss=0.6331494450569153
[20/23] Train loss=0.6174156665802002
Test set avg_accuracy=74.93% avg_sensitivity=2.21%, avg_specificity=98.09% avg_auc=51.23%
Best model saved!! Metric=51.225598371181015!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.658527 Test loss=0.594613 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.6439627408981323
[5/23] Train loss=0.626716136932373
[10/23] Train loss=0.6363621354103088
[15/23] Train loss=0.615480363368988
[20/23] Train loss=0.6040297150611877
Test set avg_accuracy=75.05% avg_sensitivity=2.26%, avg_specificity=98.23% avg_auc=52.77%
Best model saved!! Metric=52.76578091921844!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.638619 Test loss=0.575523 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.6261464357376099
[5/23] Train loss=0.6042926907539368
[10/23] Train loss=0.6218345761299133
[15/23] Train loss=0.5994083285331726
[20/23] Train loss=0.5931318998336792
Test set avg_accuracy=75.12% avg_sensitivity=2.37%, avg_specificity=98.28% avg_auc=54.50%
Best model saved!! Metric=54.50180118690929!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.624578 Test loss=0.563705 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.6205801963806152
[5/23] Train loss=0.5941540002822876
[10/23] Train loss=0.6161602139472961
[15/23] Train loss=0.5900000929832458
[20/23] Train loss=0.582441508769989
Test set avg_accuracy=75.46% avg_sensitivity=2.21%, avg_specificity=98.78% avg_auc=56.21%
Best model saved!! Metric=56.20528209340259!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.614388 Test loss=0.555905 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.6079169511795044
[5/23] Train loss=0.5782262086868286
[10/23] Train loss=0.5953536033630371
[15/23] Train loss=0.5810122489929199
[20/23] Train loss=0.5893318057060242
Test set avg_accuracy=75.53% avg_sensitivity=1.94%, avg_specificity=98.97% avg_auc=57.94%
Best model saved!! Metric=57.943454067998566!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.605696 Test loss=0.549380 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.5912810564041138
[5/23] Train loss=0.5682265162467957
[10/23] Train loss=0.5919579267501831
[15/23] Train loss=0.5708186030387878
[20/23] Train loss=0.5765331387519836
Test set avg_accuracy=75.65% avg_sensitivity=1.83%, avg_specificity=99.16% avg_auc=59.68%
Best model saved!! Metric=59.6775077218514!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.596535 Test loss=0.543740 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.5891153216362
[5/23] Train loss=0.5700219869613647
[10/23] Train loss=0.5843525528907776
[15/23] Train loss=0.5607811212539673
[20/23] Train loss=0.5612157583236694
Test set avg_accuracy=75.72% avg_sensitivity=1.89%, avg_specificity=99.23% avg_auc=61.55%
Best model saved!! Metric=61.54680425251322!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.589885 Test loss=0.538542 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.5777743458747864
[5/23] Train loss=0.5609942674636841
[10/23] Train loss=0.5836148858070374
[15/23] Train loss=0.5606825947761536
[20/23] Train loss=0.5582472681999207
Test set avg_accuracy=75.77% avg_sensitivity=2.43%, avg_specificity=99.12% avg_auc=63.44%
Best model saved!! Metric=63.4426847749384!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.583097 Test loss=0.533181 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.5683020353317261
[5/23] Train loss=0.5591219067573547
[10/23] Train loss=0.5779728293418884
[15/23] Train loss=0.5566662549972534
[20/23] Train loss=0.5545405149459839
Test set avg_accuracy=75.78% avg_sensitivity=2.53%, avg_specificity=99.11% avg_auc=65.50%
Best model saved!! Metric=65.5023680344273!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.576561 Test loss=0.527544 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.5566713213920593
[5/23] Train loss=0.5516284108161926
[10/23] Train loss=0.5685746669769287
[15/23] Train loss=0.5496081113815308
[20/23] Train loss=0.5423067808151245
Test set avg_accuracy=75.78% avg_sensitivity=3.07%, avg_specificity=98.94% avg_auc=67.51%
Best model saved!! Metric=67.51208079312379!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.568757 Test loss=0.520966 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.5531695485115051
[5/23] Train loss=0.5450153350830078
[10/23] Train loss=0.5605389475822449
[15/23] Train loss=0.530005693435669
[20/23] Train loss=0.5321990251541138
Test set avg_accuracy=75.90% avg_sensitivity=4.80%, avg_specificity=98.54% avg_auc=69.37%
Best model saved!! Metric=69.36626447485627!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.558611 Test loss=0.513432 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.5418965816497803
[5/23] Train loss=0.5234140157699585
[10/23] Train loss=0.5573916435241699
[15/23] Train loss=0.527895450592041
[20/23] Train loss=0.5150147080421448
Test set avg_accuracy=76.15% avg_sensitivity=7.22%, avg_specificity=98.09% avg_auc=71.28%
Best model saved!! Metric=71.2757632196939!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.549605 Test loss=0.504196 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.5246354937553406
[5/23] Train loss=0.5162578821182251
[10/23] Train loss=0.5524975061416626
[15/23] Train loss=0.5069250464439392
[20/23] Train loss=0.5058780908584595
Test set avg_accuracy=76.50% avg_sensitivity=10.24%, avg_specificity=97.60% avg_auc=73.15%
Best model saved!! Metric=73.14526798005623!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.538067 Test loss=0.494132 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.5052060484886169
[5/23] Train loss=0.5033670663833618
[10/23] Train loss=0.542243480682373
[15/23] Train loss=0.49362313747406006
[20/23] Train loss=0.49297648668289185
Test set avg_accuracy=77.04% avg_sensitivity=15.96%, avg_specificity=96.50% avg_auc=75.20%
Best model saved!! Metric=75.20222574413198!!
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.526597 Test loss=0.481718 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.4909708797931671
[5/23] Train loss=0.483478844165802
[10/23] Train loss=0.536758303642273
[15/23] Train loss=0.4822406470775604
[20/23] Train loss=0.4776970446109772
Test set avg_accuracy=77.60% avg_sensitivity=22.75%, avg_specificity=95.07% avg_auc=77.12%
Best model saved!! Metric=77.1225755700288!!
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.513015 Test loss=0.469214 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.47995346784591675
[5/23] Train loss=0.47476890683174133
[10/23] Train loss=0.5232676863670349
[15/23] Train loss=0.4646031856536865
[20/23] Train loss=0.47091954946517944
Test set avg_accuracy=78.85% avg_sensitivity=35.20%, avg_specificity=92.76% avg_auc=78.92%
Best model saved!! Metric=78.92471570861724!!
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.500029 Test loss=0.460050 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.46824273467063904
[5/23] Train loss=0.4538571834564209
[10/23] Train loss=0.5195409655570984
[15/23] Train loss=0.45201176404953003
[20/23] Train loss=0.4528083801269531
Test set avg_accuracy=79.60% avg_sensitivity=41.51%, avg_specificity=91.73% avg_auc=80.59%
Best model saved!! Metric=80.59014148051318!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.486748 Test loss=0.448313 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.4541585445404053
[5/23] Train loss=0.44431599974632263
[10/23] Train loss=0.5146167874336243
[15/23] Train loss=0.43994295597076416
[20/23] Train loss=0.4466240704059601
Test set avg_accuracy=80.26% avg_sensitivity=40.49%, avg_specificity=92.93% avg_auc=81.74%
Best model saved!! Metric=81.73710768946012!!
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.472186 Test loss=0.431882 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.4271547496318817
[5/23] Train loss=0.42469578981399536
[10/23] Train loss=0.4889461100101471
[15/23] Train loss=0.42941197752952576
[20/23] Train loss=0.42825549840927124
Test set avg_accuracy=80.77% avg_sensitivity=40.65%, avg_specificity=93.55% avg_auc=82.70%
Best model saved!! Metric=82.69837002417779!!
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.455978 Test loss=0.421670 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.40438807010650635
[5/23] Train loss=0.41016003489494324
[10/23] Train loss=0.462634414434433
[15/23] Train loss=0.42112720012664795
[20/23] Train loss=0.4137391448020935
Test set avg_accuracy=81.09% avg_sensitivity=45.55%, avg_specificity=92.41% avg_auc=83.74%
Best model saved!! Metric=83.73633492590493!!
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.441400 Test loss=0.411122 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.39768993854522705
[5/23] Train loss=0.39867103099823
[10/23] Train loss=0.455816388130188
[15/23] Train loss=0.40746551752090454
[20/23] Train loss=0.41118913888931274
Test set avg_accuracy=81.41% avg_sensitivity=43.72%, avg_specificity=93.41% avg_auc=84.40%
Best model saved!! Metric=84.40136506136993!!
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.431813 Test loss=0.403438 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.3906956613063812
[5/23] Train loss=0.398649662733078
[10/23] Train loss=0.4498010277748108
[15/23] Train loss=0.40275052189826965
[20/23] Train loss=0.4055083692073822
Test set avg_accuracy=81.55% avg_sensitivity=39.68%, avg_specificity=94.88% avg_auc=84.84%
Best model saved!! Metric=84.83897597260622!!
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.424705 Test loss=0.401681 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.3891753852367401
[5/23] Train loss=0.38793420791625977
[10/23] Train loss=0.45113515853881836
[15/23] Train loss=0.3953772187232971
[20/23] Train loss=0.39135268330574036
Test set avg_accuracy=81.94% avg_sensitivity=43.45%, avg_specificity=94.20% avg_auc=85.53%
Best model saved!! Metric=85.5327834526798!!
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.417204 Test loss=0.392524 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.37949132919311523
[5/23] Train loss=0.37635549902915955
[10/23] Train loss=0.4486176371574402
[15/23] Train loss=0.38853222131729126
[20/23] Train loss=0.3834896385669708
Test set avg_accuracy=82.50% avg_sensitivity=50.51%, avg_specificity=92.69% avg_auc=86.09%
Best model saved!! Metric=86.09340258898928!!
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.408295 Test loss=0.385797 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.37762150168418884
[5/23] Train loss=0.3764074444770813
[10/23] Train loss=0.4509703516960144
[15/23] Train loss=0.37848106026649475
[20/23] Train loss=0.37761953473091125
Test set avg_accuracy=82.67% avg_sensitivity=52.72%, avg_specificity=92.21% avg_auc=86.45%
Best model saved!! Metric=86.44523211827448!!
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.404128 Test loss=0.382810 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.3833841383457184
[5/23] Train loss=0.37588006258010864
[10/23] Train loss=0.4513736665248871
[15/23] Train loss=0.37656259536743164
[20/23] Train loss=0.37794923782348633
Test set avg_accuracy=82.68% avg_sensitivity=53.48%, avg_specificity=91.98% avg_auc=86.64%
Best model saved!! Metric=86.63647490253693!!
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.400090 Test loss=0.380083 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.37200623750686646
[5/23] Train loss=0.3743312954902649
[10/23] Train loss=0.460183322429657
[15/23] Train loss=0.376028835773468
[20/23] Train loss=0.371724396944046
Test set avg_accuracy=82.99% avg_sensitivity=50.35%, avg_specificity=93.39% avg_auc=86.71%
Best model saved!! Metric=86.70651411913053!!
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.397047 Test loss=0.377697 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.36982202529907227
[5/23] Train loss=0.36729103326797485
[10/23] Train loss=0.4595508277416229
[15/23] Train loss=0.37568017840385437
[20/23] Train loss=0.37180641293525696
Test set avg_accuracy=82.98% avg_sensitivity=50.19%, avg_specificity=93.42% avg_auc=86.82%
Best model saved!! Metric=86.81717200930093!!
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.394046 Test loss=0.376047 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.3652723431587219
[5/23] Train loss=0.36311420798301697
[10/23] Train loss=0.46095845103263855
[15/23] Train loss=0.37641119956970215
[20/23] Train loss=0.37039515376091003
Test set avg_accuracy=83.03% avg_sensitivity=49.76%, avg_specificity=93.63% avg_auc=86.95%
Best model saved!! Metric=86.94828268338674!!
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.390905 Test loss=0.374651 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.36614128947257996
[5/23] Train loss=0.3612678349018097
[10/23] Train loss=0.45354095101356506
[15/23] Train loss=0.3709353506565094
[20/23] Train loss=0.36569178104400635
Test set avg_accuracy=83.10% avg_sensitivity=50.03%, avg_specificity=93.63% avg_auc=87.00%
Best model saved!! Metric=87.00300544867716!!
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.387200 Test loss=0.373592 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.3608398735523224
[5/23] Train loss=0.3563149571418762
[10/23] Train loss=0.4435078799724579
[15/23] Train loss=0.37049970030784607
[20/23] Train loss=0.3665637671947479
Test set avg_accuracy=83.26% avg_sensitivity=49.76%, avg_specificity=93.92% avg_auc=87.07%
Best model saved!! Metric=87.0723690755758!!
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.385078 Test loss=0.372966 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.3580678403377533
[5/23] Train loss=0.34867337346076965
[10/23] Train loss=0.4456290602684021
[15/23] Train loss=0.3675641715526581
[20/23] Train loss=0.3658437430858612
Test set avg_accuracy=83.28% avg_sensitivity=49.43%, avg_specificity=94.06% avg_auc=87.07%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.382841 Test loss=0.372803 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.3569163680076599
[5/23] Train loss=0.3434852063655853
[10/23] Train loss=0.4360704720020294
[15/23] Train loss=0.36503487825393677
[20/23] Train loss=0.3673105537891388
Test set avg_accuracy=83.31% avg_sensitivity=50.19%, avg_specificity=93.85% avg_auc=87.13%
Best model saved!! Metric=87.12829494580244!!
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.379895 Test loss=0.371755 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.35574570298194885
[5/23] Train loss=0.33988243341445923
[10/23] Train loss=0.436815470457077
[15/23] Train loss=0.3594309687614441
[20/23] Train loss=0.3589246869087219
Test set avg_accuracy=83.45% avg_sensitivity=49.87%, avg_specificity=94.15% avg_auc=87.18%
Best model saved!! Metric=87.18230510278451!!
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.378233 Test loss=0.371354 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.3531038463115692
[5/23] Train loss=0.3382265269756317
[10/23] Train loss=0.42687830328941345
[15/23] Train loss=0.36625075340270996
[20/23] Train loss=0.36046701669692993
Test set avg_accuracy=83.24% avg_sensitivity=49.27%, avg_specificity=94.06% avg_auc=87.10%
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.374499 Test loss=0.372153 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.35222673416137695
[5/23] Train loss=0.3358229994773865
[10/23] Train loss=0.42214804887771606
[15/23] Train loss=0.35626840591430664
[20/23] Train loss=0.358185350894928
Test set avg_accuracy=83.29% avg_sensitivity=51.05%, avg_specificity=93.56% avg_auc=87.21%
Best model saved!! Metric=87.21447427784781!!
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.372777 Test loss=0.370245 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.3462102711200714
[5/23] Train loss=0.3386417031288147
[10/23] Train loss=0.41757941246032715
[15/23] Train loss=0.35447239875793457
[20/23] Train loss=0.35660305619239807
Test set avg_accuracy=83.35% avg_sensitivity=51.05%, avg_specificity=93.63% avg_auc=87.15%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.370810 Test loss=0.370791 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.3437742292881012
[5/23] Train loss=0.33487653732299805
[10/23] Train loss=0.41756471991539
[15/23] Train loss=0.35501399636268616
[20/23] Train loss=0.3576013445854187
Test set avg_accuracy=83.26% avg_sensitivity=50.13%, avg_specificity=93.80% avg_auc=87.18%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.370284 Test loss=0.370964 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.34480318427085876
[5/23] Train loss=0.3320208489894867
[10/23] Train loss=0.41384851932525635
[15/23] Train loss=0.3492307960987091
[20/23] Train loss=0.3595469295978546
Test set avg_accuracy=83.15% avg_sensitivity=49.54%, avg_specificity=93.85% avg_auc=87.17%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.367590 Test loss=0.371502 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.3444159924983978
[5/23] Train loss=0.33084824681282043
[10/23] Train loss=0.4144245386123657
[15/23] Train loss=0.35060596466064453
[20/23] Train loss=0.3547961115837097
Test set avg_accuracy=83.10% avg_sensitivity=49.70%, avg_specificity=93.73% avg_auc=87.15%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.366837 Test loss=0.371648 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.3472968637943268
[5/23] Train loss=0.32797566056251526
[10/23] Train loss=0.40727871656417847
[15/23] Train loss=0.3473983407020569
[20/23] Train loss=0.35645923018455505
Test set avg_accuracy=82.99% avg_sensitivity=48.36%, avg_specificity=94.03% avg_auc=87.15%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.364711 Test loss=0.372456 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.3417062759399414
[5/23] Train loss=0.3249363303184509
[10/23] Train loss=0.4142208397388458
[15/23] Train loss=0.34804779291152954
[20/23] Train loss=0.3542304039001465
Test set avg_accuracy=82.90% avg_sensitivity=46.09%, avg_specificity=94.63% avg_auc=87.06%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.363394 Test loss=0.375259 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.3423768877983093
[5/23] Train loss=0.32170960307121277
[10/23] Train loss=0.413093239068985
[15/23] Train loss=0.34794357419013977
[20/23] Train loss=0.3521493375301361
Test set avg_accuracy=82.83% avg_sensitivity=46.42%, avg_specificity=94.42% avg_auc=87.18%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.362580 Test loss=0.373547 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.3456117510795593
[5/23] Train loss=0.3241208493709564
[10/23] Train loss=0.41270768642425537
[15/23] Train loss=0.3468468487262726
[20/23] Train loss=0.34648481011390686
Test set avg_accuracy=83.15% avg_sensitivity=48.09%, avg_specificity=94.32% avg_auc=87.28%
Best model saved!! Metric=87.27810001966614!!
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.360905 Test loss=0.371383 Current lr=[0.000299926900870094]

[0/23] Train loss=0.3361261487007141
[5/23] Train loss=0.3309972882270813
[10/23] Train loss=0.4195173978805542
[15/23] Train loss=0.34401488304138184
[20/23] Train loss=0.35046395659446716
Test set avg_accuracy=83.14% avg_sensitivity=49.38%, avg_specificity=93.89% avg_auc=87.34%
Best model saved!! Metric=87.34185532663142!!
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.361238 Test loss=0.369865 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.33811330795288086
[5/23] Train loss=0.3306031823158264
[10/23] Train loss=0.4286935329437256
[15/23] Train loss=0.34023597836494446
[20/23] Train loss=0.3402584195137024
Test set avg_accuracy=83.41% avg_sensitivity=54.99%, avg_specificity=92.46% avg_auc=87.55%
Best model saved!! Metric=87.54615179945166!!
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.360494 Test loss=0.366887 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.33972400426864624
[5/23] Train loss=0.339216023683548
[10/23] Train loss=0.4197726249694824
[15/23] Train loss=0.33492031693458557
[20/23] Train loss=0.3431042730808258
Test set avg_accuracy=83.54% avg_sensitivity=58.11%, avg_specificity=91.64% avg_auc=87.63%
Best model saved!! Metric=87.62791666184656!!
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.359443 Test loss=0.367112 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.33719009160995483
[5/23] Train loss=0.33581602573394775
[10/23] Train loss=0.40865787863731384
[15/23] Train loss=0.329008013010025
[20/23] Train loss=0.34024763107299805
Test set avg_accuracy=83.54% avg_sensitivity=57.04%, avg_specificity=91.98% avg_auc=87.57%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.356128 Test loss=0.366927 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.33791935443878174
[5/23] Train loss=0.32999229431152344
[10/23] Train loss=0.4110390543937683
[15/23] Train loss=0.3353036344051361
[20/23] Train loss=0.33677202463150024
Test set avg_accuracy=83.54% avg_sensitivity=56.23%, avg_specificity=92.24% avg_auc=87.62%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.354669 Test loss=0.366235 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.33421456813812256
[5/23] Train loss=0.3311569392681122
[10/23] Train loss=0.4091312289237976
[15/23] Train loss=0.3322623670101166
[20/23] Train loss=0.3402436077594757
Test set avg_accuracy=83.48% avg_sensitivity=56.23%, avg_specificity=92.15% avg_auc=87.59%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.353707 Test loss=0.366654 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.3359508812427521
[5/23] Train loss=0.32965749502182007
[10/23] Train loss=0.4099189043045044
[15/23] Train loss=0.3344694972038269
[20/23] Train loss=0.3367146849632263
Test set avg_accuracy=83.44% avg_sensitivity=55.09%, avg_specificity=92.46% avg_auc=87.54%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.352823 Test loss=0.366668 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.33547747135162354
[5/23] Train loss=0.32435014843940735
[10/23] Train loss=0.40433841943740845
[15/23] Train loss=0.3290582597255707
[20/23] Train loss=0.33296406269073486
Test set avg_accuracy=83.58% avg_sensitivity=55.15%, avg_specificity=92.64% avg_auc=87.54%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.350744 Test loss=0.366717 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.3364183008670807
[5/23] Train loss=0.3194189667701721
[10/23] Train loss=0.3969633877277374
[15/23] Train loss=0.3266202509403229
[20/23] Train loss=0.3332863450050354
Test set avg_accuracy=83.52% avg_sensitivity=55.36%, avg_specificity=92.48% avg_auc=87.61%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.349607 Test loss=0.366231 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.33161503076553345
[5/23] Train loss=0.318881630897522
[10/23] Train loss=0.3976341784000397
[15/23] Train loss=0.3256438076496124
[20/23] Train loss=0.3308781683444977
Test set avg_accuracy=83.49% avg_sensitivity=55.20%, avg_specificity=92.50% avg_auc=87.59%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.347810 Test loss=0.366266 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.3308095932006836
[5/23] Train loss=0.31876808404922485
[10/23] Train loss=0.39496031403541565
[15/23] Train loss=0.32990142703056335
[20/23] Train loss=0.3332563042640686
Test set avg_accuracy=83.50% avg_sensitivity=54.56%, avg_specificity=92.72% avg_auc=87.62%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.347348 Test loss=0.365880 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.33092546463012695
[5/23] Train loss=0.32543542981147766
[10/23] Train loss=0.40139588713645935
[15/23] Train loss=0.3293081223964691
[20/23] Train loss=0.32920408248901367
Test set avg_accuracy=83.55% avg_sensitivity=55.69%, avg_specificity=92.43% avg_auc=87.66%
Best model saved!! Metric=87.6579665212915!!
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.346731 Test loss=0.365517 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.3306235373020172
[5/23] Train loss=0.3239816129207611
[10/23] Train loss=0.3948105573654175
[15/23] Train loss=0.3259356915950775
[20/23] Train loss=0.3267636299133301
Test set avg_accuracy=83.53% avg_sensitivity=55.58%, avg_specificity=92.43% avg_auc=87.63%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.345202 Test loss=0.366160 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.3300233781337738
[5/23] Train loss=0.31811657547950745
[10/23] Train loss=0.3895626664161682
[15/23] Train loss=0.32348811626434326
[20/23] Train loss=0.3269326984882355
Test set avg_accuracy=83.65% avg_sensitivity=54.77%, avg_specificity=92.84% avg_auc=87.64%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.343138 Test loss=0.365451 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.3303740918636322
[5/23] Train loss=0.3207303285598755
[10/23] Train loss=0.39227837324142456
[15/23] Train loss=0.32367947697639465
[20/23] Train loss=0.32659292221069336
Test set avg_accuracy=83.59% avg_sensitivity=55.47%, avg_specificity=92.55% avg_auc=87.72%
Best model saved!! Metric=87.72000046273267!!
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.342489 Test loss=0.364587 Current lr=[0.000283047938381597]

[0/23] Train loss=0.3285001218318939
[5/23] Train loss=0.3217085003852844
[10/23] Train loss=0.38675597310066223
[15/23] Train loss=0.32074087858200073
[20/23] Train loss=0.3254998028278351
Test set avg_accuracy=83.76% avg_sensitivity=56.50%, avg_specificity=92.45% avg_auc=87.74%
Best model saved!! Metric=87.7395601725993!!
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.342626 Test loss=0.364617 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.3265056908130646
[5/23] Train loss=0.31792256236076355
[10/23] Train loss=0.3839033246040344
[15/23] Train loss=0.3236285150051117
[20/23] Train loss=0.3262713849544525
Test set avg_accuracy=83.59% avg_sensitivity=54.61%, avg_specificity=92.82% avg_auc=87.78%
Best model saved!! Metric=87.77819372303136!!
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.341186 Test loss=0.363867 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.3244827091693878
[5/23] Train loss=0.3189810514450073
[10/23] Train loss=0.389424592256546
[15/23] Train loss=0.31986671686172485
[20/23] Train loss=0.3260723948478699
Test set avg_accuracy=83.50% avg_sensitivity=53.75%, avg_specificity=92.98% avg_auc=87.79%
Best model saved!! Metric=87.7853845886885!!
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.340841 Test loss=0.363852 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.3235761225223541
[5/23] Train loss=0.3179011940956116
[10/23] Train loss=0.3872467279434204
[15/23] Train loss=0.32090455293655396
[20/23] Train loss=0.3258558511734009
Test set avg_accuracy=83.54% avg_sensitivity=54.50%, avg_specificity=92.79% avg_auc=87.83%
Best model saved!! Metric=87.82619298265911!!
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.339804 Test loss=0.363250 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.3222498297691345
[5/23] Train loss=0.3158420920372009
[10/23] Train loss=0.3844703435897827
[15/23] Train loss=0.3198544383049011
[20/23] Train loss=0.3290932774543762
Test set avg_accuracy=83.62% avg_sensitivity=54.23%, avg_specificity=92.98% avg_auc=87.81%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.338984 Test loss=0.363791 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.32241290807724
[5/23] Train loss=0.31606242060661316
[10/23] Train loss=0.3848445415496826
[15/23] Train loss=0.3158402144908905
[20/23] Train loss=0.32139837741851807
Test set avg_accuracy=83.70% avg_sensitivity=55.31%, avg_specificity=92.74% avg_auc=87.88%
Best model saved!! Metric=87.88103143111647!!
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.338040 Test loss=0.362772 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.31527140736579895
[5/23] Train loss=0.31795960664749146
[10/23] Train loss=0.3852059245109558
[15/23] Train loss=0.3198692500591278
[20/23] Train loss=0.3232150673866272
Test set avg_accuracy=83.75% avg_sensitivity=54.99%, avg_specificity=92.91% avg_auc=87.92%
Best model saved!! Metric=87.92350103536434!!
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.338095 Test loss=0.362094 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.31694597005844116
[5/23] Train loss=0.3156721889972687
[10/23] Train loss=0.3813786506652832
[15/23] Train loss=0.3140232264995575
[20/23] Train loss=0.3244786858558655
Test set avg_accuracy=83.65% avg_sensitivity=52.88%, avg_specificity=93.44% avg_auc=87.86%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.335964 Test loss=0.363371 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.3189294934272766
[5/23] Train loss=0.31473860144615173
[10/23] Train loss=0.37851646542549133
[15/23] Train loss=0.31398805975914
[20/23] Train loss=0.3234963119029999
Test set avg_accuracy=83.96% avg_sensitivity=56.12%, avg_specificity=92.82% avg_auc=87.93%
Best model saved!! Metric=87.93076593824833!!
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.335299 Test loss=0.362167 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.31887900829315186
[5/23] Train loss=0.31765204668045044
[10/23] Train loss=0.37394049763679504
[15/23] Train loss=0.31178584694862366
[20/23] Train loss=0.32130852341651917
Test set avg_accuracy=83.88% avg_sensitivity=55.09%, avg_specificity=93.05% avg_auc=87.91%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.334678 Test loss=0.362536 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.3165709674358368
[5/23] Train loss=0.31405889987945557
[10/23] Train loss=0.36990103125572205
[15/23] Train loss=0.31449082493782043
[20/23] Train loss=0.3216099441051483
Test set avg_accuracy=84.05% avg_sensitivity=56.06%, avg_specificity=92.96% avg_auc=87.94%
Best model saved!! Metric=87.94281086959037!!
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.333261 Test loss=0.362067 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.317218154668808
[5/23] Train loss=0.31477999687194824
[10/23] Train loss=0.3712666630744934
[15/23] Train loss=0.3104552626609802
[20/23] Train loss=0.3192746043205261
Test set avg_accuracy=84.01% avg_sensitivity=55.90%, avg_specificity=92.96% avg_auc=87.96%
Best model saved!! Metric=87.95582753953472!!
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.332975 Test loss=0.361794 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.32040849328041077
[5/23] Train loss=0.3113233149051666
[10/23] Train loss=0.3687858581542969
[15/23] Train loss=0.3139899969100952
[20/23] Train loss=0.3218642771244049
Test set avg_accuracy=83.98% avg_sensitivity=53.80%, avg_specificity=93.60% avg_auc=87.89%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.332963 Test loss=0.363004 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.31428059935569763
[5/23] Train loss=0.31417879462242126
[10/23] Train loss=0.37410134077072144
[15/23] Train loss=0.31043773889541626
[20/23] Train loss=0.322576642036438
Test set avg_accuracy=84.14% avg_sensitivity=54.93%, avg_specificity=93.44% avg_auc=87.95%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.332101 Test loss=0.362069 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.31174007058143616
[5/23] Train loss=0.31520023941993713
[10/23] Train loss=0.3702886700630188
[15/23] Train loss=0.3087775409221649
[20/23] Train loss=0.3232155740261078
Test set avg_accuracy=84.02% avg_sensitivity=52.72%, avg_specificity=93.99% avg_auc=87.74%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.331461 Test loss=0.365345 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.30949127674102783
[5/23] Train loss=0.31085488200187683
[10/23] Train loss=0.3723786473274231
[15/23] Train loss=0.3127785325050354
[20/23] Train loss=0.32232892513275146
Test set avg_accuracy=84.17% avg_sensitivity=54.88%, avg_specificity=93.49% avg_auc=87.82%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.330938 Test loss=0.363771 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.3123641908168793
[5/23] Train loss=0.3196355402469635
[10/23] Train loss=0.37007924914360046
[15/23] Train loss=0.30935174226760864
[20/23] Train loss=0.32701417803764343
Test set avg_accuracy=83.89% avg_sensitivity=50.89%, avg_specificity=94.40% avg_auc=87.61%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.333057 Test loss=0.367572 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.3092222809791565
[5/23] Train loss=0.31989753246307373
[10/23] Train loss=0.36308056116104126
[15/23] Train loss=0.3079666197299957
[20/23] Train loss=0.32863950729370117
Test set avg_accuracy=83.93% avg_sensitivity=51.05%, avg_specificity=94.40% avg_auc=87.55%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.331801 Test loss=0.368678 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.3110094964504242
[5/23] Train loss=0.3177601993083954
[10/23] Train loss=0.3623984754085541
[15/23] Train loss=0.31009700894355774
[20/23] Train loss=0.3270677924156189
Test set avg_accuracy=84.19% avg_sensitivity=55.42%, avg_specificity=93.36% avg_auc=87.75%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.332506 Test loss=0.363931 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.31357619166374207
[5/23] Train loss=0.3195315897464752
[10/23] Train loss=0.3675329387187958
[15/23] Train loss=0.3120753765106201
[20/23] Train loss=0.3218000829219818
Test set avg_accuracy=84.27% avg_sensitivity=60.59%, avg_specificity=91.81% avg_auc=87.96%
Best model saved!! Metric=87.96419374616798!!
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.334832 Test loss=0.362616 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.3149535655975342
[5/23] Train loss=0.31404033303260803
[10/23] Train loss=0.3676421642303467
[15/23] Train loss=0.32138630747795105
[20/23] Train loss=0.31432098150253296
Test set avg_accuracy=83.83% avg_sensitivity=66.15%, avg_specificity=89.46% avg_auc=88.15%
Best model saved!! Metric=88.15210485522252!!
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.334728 Test loss=0.369028 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.32533788681030273
[5/23] Train loss=0.3042803108692169
[10/23] Train loss=0.365906298160553
[15/23] Train loss=0.31458503007888794
[20/23] Train loss=0.31517818570137024
Test set avg_accuracy=83.89% avg_sensitivity=64.04%, avg_specificity=90.21% avg_auc=88.12%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.331123 Test loss=0.365303 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.32275524735450745
[5/23] Train loss=0.3041703701019287
[10/23] Train loss=0.36115413904190063
[15/23] Train loss=0.3169631361961365
[20/23] Train loss=0.3124006986618042
Test set avg_accuracy=84.06% avg_sensitivity=64.96%, avg_specificity=90.15% avg_auc=88.22%
Best model saved!! Metric=88.22481866663581!!
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.328847 Test loss=0.364962 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.32249629497528076
[5/23] Train loss=0.30511176586151123
[10/23] Train loss=0.35960763692855835
[15/23] Train loss=0.31321844458580017
[20/23] Train loss=0.3153460621833801
Test set avg_accuracy=84.13% avg_sensitivity=64.04%, avg_specificity=90.52% avg_auc=88.23%
Best model saved!! Metric=88.22568397672454!!
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.328820 Test loss=0.363411 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.3138156235218048
[5/23] Train loss=0.3004412055015564
[10/23] Train loss=0.3595815896987915
[15/23] Train loss=0.3088946044445038
[20/23] Train loss=0.3054775297641754
Test set avg_accuracy=84.09% avg_sensitivity=63.72%, avg_specificity=90.58% avg_auc=88.21%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.327001 Test loss=0.363414 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.31492140889167786
[5/23] Train loss=0.30087143182754517
[10/23] Train loss=0.36349865794181824
[15/23] Train loss=0.31279414892196655
[20/23] Train loss=0.31080228090286255
Test set avg_accuracy=84.13% avg_sensitivity=63.83%, avg_specificity=90.59% avg_auc=88.24%
Best model saved!! Metric=88.23862660944206!!
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.327923 Test loss=0.363487 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.31901392340660095
[5/23] Train loss=0.30268678069114685
[10/23] Train loss=0.3692147135734558
[15/23] Train loss=0.31041234731674194
[20/23] Train loss=0.30596068501472473
Test set avg_accuracy=83.95% avg_sensitivity=63.88%, avg_specificity=90.33% avg_auc=88.24%
Best model saved!! Metric=88.2402970743727!!
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.327291 Test loss=0.364231 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.3184630870819092
[5/23] Train loss=0.30344727635383606
[10/23] Train loss=0.3577006161212921
[15/23] Train loss=0.30654487013816833
[20/23] Train loss=0.3109796941280365
Test set avg_accuracy=84.02% avg_sensitivity=62.86%, avg_specificity=90.76% avg_auc=88.21%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.325331 Test loss=0.363126 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.3166024386882782
[5/23] Train loss=0.2994205057621002
[10/23] Train loss=0.359701544046402
[15/23] Train loss=0.30553480982780457
[20/23] Train loss=0.3139897286891937
Test set avg_accuracy=83.97% avg_sensitivity=63.34%, avg_specificity=90.54% avg_auc=88.22%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.325317 Test loss=0.363712 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.3129637539386749
[5/23] Train loss=0.2987990081310272
[10/23] Train loss=0.3587592542171478
[15/23] Train loss=0.3044307827949524
[20/23] Train loss=0.3144998848438263
Test set avg_accuracy=83.96% avg_sensitivity=62.64%, avg_specificity=90.75% avg_auc=88.25%
Best model saved!! Metric=88.25455386786669!!
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.325340 Test loss=0.362467 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.31495198607444763
[5/23] Train loss=0.29950419068336487
[10/23] Train loss=0.3602275252342224
[15/23] Train loss=0.3076947033405304
[20/23] Train loss=0.30840688943862915
Test set avg_accuracy=84.05% avg_sensitivity=63.45%, avg_specificity=90.61% avg_auc=88.23%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.324808 Test loss=0.363565 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.3166967034339905
[5/23] Train loss=0.2991584837436676
[10/23] Train loss=0.36190345883369446
[15/23] Train loss=0.30588001012802124
[20/23] Train loss=0.3126613199710846
Test set avg_accuracy=83.93% avg_sensitivity=62.96%, avg_specificity=90.61% avg_auc=88.23%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.324723 Test loss=0.363566 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.314559668302536
[5/23] Train loss=0.3013310730457306
[10/23] Train loss=0.3596281409263611
[15/23] Train loss=0.31132587790489197
[20/23] Train loss=0.3072405457496643
Test set avg_accuracy=84.04% avg_sensitivity=62.75%, avg_specificity=90.82% avg_auc=88.31%
Best model saved!! Metric=88.314130698842!!
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.323110 Test loss=0.361388 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.3121098279953003
[5/23] Train loss=0.2962804436683655
[10/23] Train loss=0.3659539818763733
[15/23] Train loss=0.3072476089000702
[20/23] Train loss=0.3149849772453308
Test set avg_accuracy=83.91% avg_sensitivity=63.29%, avg_specificity=90.47% avg_auc=88.33%
Best model saved!! Metric=88.32522240088844!!
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.324486 Test loss=0.362399 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.30593931674957275
[5/23] Train loss=0.2987472414970398
[10/23] Train loss=0.361865371465683
[15/23] Train loss=0.30139270424842834
[20/23] Train loss=0.3065345883369446
Test set avg_accuracy=83.95% avg_sensitivity=62.86%, avg_specificity=90.66% avg_auc=88.33%
Best model saved!! Metric=88.32865124995662!!
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.322245 Test loss=0.361674 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.3080218732357025
[5/23] Train loss=0.2988467812538147
[10/23] Train loss=0.35955893993377686
[15/23] Train loss=0.3076268136501312
[20/23] Train loss=0.3091050088405609
Test set avg_accuracy=83.84% avg_sensitivity=63.07%, avg_specificity=90.45% avg_auc=88.35%
Best model saved!! Metric=88.35069583424915!!
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.322176 Test loss=0.361750 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.30760830640792847
[5/23] Train loss=0.3001176416873932
[10/23] Train loss=0.3609899580478668
[15/23] Train loss=0.3086281716823578
[20/23] Train loss=0.3110019266605377
Test set avg_accuracy=83.87% avg_sensitivity=63.61%, avg_specificity=90.32% avg_auc=88.37%
Best model saved!! Metric=88.36691924158117!!
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.322425 Test loss=0.362185 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.30784672498703003
[5/23] Train loss=0.2967384457588196
[10/23] Train loss=0.3649616837501526
[15/23] Train loss=0.30515801906585693
[20/23] Train loss=0.3113454580307007
Test set avg_accuracy=83.71% avg_sensitivity=63.99%, avg_specificity=89.99% avg_auc=88.39%
Best model saved!! Metric=88.389232210821!!
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.322337 Test loss=0.363147 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.30729660391807556
[5/23] Train loss=0.30574482679367065
[10/23] Train loss=0.3677475154399872
[15/23] Train loss=0.30844637751579285
[20/23] Train loss=0.3184916377067566
Test set avg_accuracy=83.67% avg_sensitivity=65.18%, avg_specificity=89.56% avg_auc=88.41%
Best model saved!! Metric=88.41059195076527!!
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.324008 Test loss=0.365034 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.3174755871295929
[5/23] Train loss=0.30461516976356506
[10/23] Train loss=0.3728827238082886
[15/23] Train loss=0.3017680048942566
[20/23] Train loss=0.3077314794063568
Test set avg_accuracy=83.46% avg_sensitivity=66.68%, avg_specificity=88.81% avg_auc=88.47%
Best model saved!! Metric=88.46922017977164!!
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.324809 Test loss=0.367906 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.31603094935417175
[5/23] Train loss=0.3047446608543396
[10/23] Train loss=0.36786970496177673
[15/23] Train loss=0.3057507872581482
[20/23] Train loss=0.3134543001651764
Test set avg_accuracy=82.92% avg_sensitivity=70.78%, avg_specificity=86.78% avg_auc=88.54%
Best model saved!! Metric=88.53954629061926!!
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.325351 Test loss=0.377637 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.329242467880249
[5/23] Train loss=0.30898797512054443
[10/23] Train loss=0.37113654613494873
[15/23] Train loss=0.30083104968070984
[20/23] Train loss=0.3113464415073395
Test set avg_accuracy=82.72% avg_sensitivity=71.75%, avg_specificity=86.21% avg_auc=88.53%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.327238 Test loss=0.381395 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.3282375633716583
[5/23] Train loss=0.3037099242210388
[10/23] Train loss=0.36306941509246826
[15/23] Train loss=0.30320414900779724
[20/23] Train loss=0.311969131231308
Test set avg_accuracy=83.44% avg_sensitivity=67.33%, avg_specificity=88.57% avg_auc=88.54%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.325821 Test loss=0.368440 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.3129331171512604
[5/23] Train loss=0.30220380425453186
[10/23] Train loss=0.3562803566455841
[15/23] Train loss=0.31141164898872375
[20/23] Train loss=0.31575465202331543
Test set avg_accuracy=83.62% avg_sensitivity=63.56%, avg_specificity=90.01% avg_auc=88.48%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.323612 Test loss=0.362494 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.30635327100753784
[5/23] Train loss=0.30165961384773254
[10/23] Train loss=0.3536933958530426
[15/23] Train loss=0.30706337094306946
[20/23] Train loss=0.31308579444885254
Test set avg_accuracy=83.62% avg_sensitivity=63.56%, avg_specificity=90.01% avg_auc=88.49%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.321634 Test loss=0.362932 Current lr=[0.000112073915556435]

[0/23] Train loss=0.3065054714679718
[5/23] Train loss=0.2974514067173004
[10/23] Train loss=0.35643312335014343
[15/23] Train loss=0.3025842308998108
[20/23] Train loss=0.31268998980522156
Test set avg_accuracy=83.58% avg_sensitivity=63.83%, avg_specificity=89.87% avg_auc=88.52%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.321353 Test loss=0.362979 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.3113463521003723
[5/23] Train loss=0.2987419664859772
[10/23] Train loss=0.35215792059898376
[15/23] Train loss=0.30779045820236206
[20/23] Train loss=0.31368809938430786
Test set avg_accuracy=83.54% avg_sensitivity=63.61%, avg_specificity=89.89% avg_auc=88.54%
Best model saved!! Metric=88.54138333931027!!
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.320837 Test loss=0.362204 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.30508238077163696
[5/23] Train loss=0.2963607907295227
[10/23] Train loss=0.3520824909210205
[15/23] Train loss=0.3077170252799988
[20/23] Train loss=0.3084299862384796
Test set avg_accuracy=83.59% avg_sensitivity=63.07%, avg_specificity=90.13% avg_auc=88.53%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.320596 Test loss=0.361134 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.30114638805389404
[5/23] Train loss=0.2951272130012512
[10/23] Train loss=0.3526223301887512
[15/23] Train loss=0.3053753077983856
[20/23] Train loss=0.30643993616104126
Test set avg_accuracy=83.52% avg_sensitivity=63.02%, avg_specificity=90.04% avg_auc=88.53%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.320020 Test loss=0.361326 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.30546870827674866
[5/23] Train loss=0.2947137951850891
[10/23] Train loss=0.3587989807128906
[15/23] Train loss=0.30422309041023254
[20/23] Train loss=0.3112250864505768
Test set avg_accuracy=83.61% avg_sensitivity=63.18%, avg_specificity=90.11% avg_auc=88.55%
Best model saved!! Metric=88.5530395752114!!
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.319067 Test loss=0.360969 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.3017011284828186
[5/23] Train loss=0.2954329550266266
[10/23] Train loss=0.35257282853126526
[15/23] Train loss=0.3065067529678345
[20/23] Train loss=0.3110063672065735
Test set avg_accuracy=83.54% avg_sensitivity=62.91%, avg_specificity=90.11% avg_auc=88.56%
Best model saved!! Metric=88.55566789676435!!
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.318493 Test loss=0.360894 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.30494576692581177
[5/23] Train loss=0.2909582853317261
[10/23] Train loss=0.35495465993881226
[15/23] Train loss=0.30479103326797485
[20/23] Train loss=0.30586087703704834
Test set avg_accuracy=83.63% avg_sensitivity=62.59%, avg_specificity=90.33% avg_auc=88.57%
Best model saved!! Metric=88.56838841780133!!
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.317835 Test loss=0.359470 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.30635663866996765
[5/23] Train loss=0.2954252362251282
[10/23] Train loss=0.34631621837615967
[15/23] Train loss=0.30277523398399353
[20/23] Train loss=0.30841949582099915
Test set avg_accuracy=83.53% avg_sensitivity=62.75%, avg_specificity=90.15% avg_auc=88.58%
Best model saved!! Metric=88.58085906319772!!
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.317773 Test loss=0.360130 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.29955825209617615
[5/23] Train loss=0.293552041053772
[10/23] Train loss=0.3553712069988251
[15/23] Train loss=0.30124372243881226
[20/23] Train loss=0.30482688546180725
Test set avg_accuracy=83.57% avg_sensitivity=62.75%, avg_specificity=90.20% avg_auc=88.58%
Best model saved!! Metric=88.58105341091817!!
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.317395 Test loss=0.360014 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.3023940622806549
[5/23] Train loss=0.2934458553791046
[10/23] Train loss=0.3549833595752716
[15/23] Train loss=0.30118781328201294
[20/23] Train loss=0.3077067732810974
Test set avg_accuracy=83.65% avg_sensitivity=62.64%, avg_specificity=90.33% avg_auc=88.58%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.317567 Test loss=0.359891 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.30058133602142334
[5/23] Train loss=0.2970746159553528
[10/23] Train loss=0.3508070707321167
[15/23] Train loss=0.2984378933906555
[20/23] Train loss=0.3102209270000458
Test set avg_accuracy=83.61% avg_sensitivity=61.67%, avg_specificity=90.59% avg_auc=88.56%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.316445 Test loss=0.359092 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.30064019560813904
[5/23] Train loss=0.3014814555644989
[10/23] Train loss=0.356881707906723
[15/23] Train loss=0.3032597303390503
[20/23] Train loss=0.305015504360199
Test set avg_accuracy=83.61% avg_sensitivity=62.53%, avg_specificity=90.32% avg_auc=88.56%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.317975 Test loss=0.360070 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.3097611963748932
[5/23] Train loss=0.2965764105319977
[10/23] Train loss=0.3508782982826233
[15/23] Train loss=0.3006633520126343
[20/23] Train loss=0.3055252134799957
Test set avg_accuracy=83.59% avg_sensitivity=61.99%, avg_specificity=90.47% avg_auc=88.56%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.316853 Test loss=0.359644 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.30073466897010803
[5/23] Train loss=0.29597657918930054
[10/23] Train loss=0.3495578169822693
[15/23] Train loss=0.2970321476459503
[20/23] Train loss=0.31081080436706543
Test set avg_accuracy=83.54% avg_sensitivity=62.26%, avg_specificity=90.32% avg_auc=88.55%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.316814 Test loss=0.359933 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.30235907435417175
[5/23] Train loss=0.29774367809295654
[10/23] Train loss=0.3508543074131012
[15/23] Train loss=0.3029940128326416
[20/23] Train loss=0.3049767017364502
Test set avg_accuracy=83.53% avg_sensitivity=62.10%, avg_specificity=90.35% avg_auc=88.54%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.317588 Test loss=0.359890 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.2995765209197998
[5/23] Train loss=0.29479002952575684
[10/23] Train loss=0.36152034997940063
[15/23] Train loss=0.2996605634689331
[20/23] Train loss=0.305282860994339
Test set avg_accuracy=83.59% avg_sensitivity=62.21%, avg_specificity=90.40% avg_auc=88.55%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.315931 Test loss=0.359393 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.2988867163658142
[5/23] Train loss=0.29822829365730286
[10/23] Train loss=0.3548218309879303
[15/23] Train loss=0.29857146739959717
[20/23] Train loss=0.3072269856929779
Test set avg_accuracy=83.54% avg_sensitivity=61.67%, avg_specificity=90.51% avg_auc=88.55%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.316444 Test loss=0.359041 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.29809603095054626
[5/23] Train loss=0.30052468180656433
[10/23] Train loss=0.3519280254840851
[15/23] Train loss=0.30054622888565063
[20/23] Train loss=0.3095247447490692
Test set avg_accuracy=83.57% avg_sensitivity=60.81%, avg_specificity=90.82% avg_auc=88.53%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.316684 Test loss=0.358436 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.2995588779449463
[5/23] Train loss=0.2981111705303192
[10/23] Train loss=0.35019582509994507
[15/23] Train loss=0.2986416518688202
[20/23] Train loss=0.3128102421760559
Test set avg_accuracy=83.59% avg_sensitivity=60.49%, avg_specificity=90.95% avg_auc=88.51%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.317191 Test loss=0.358198 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.3002256453037262
[5/23] Train loss=0.3008045256137848
[10/23] Train loss=0.35459455847740173
[15/23] Train loss=0.29798901081085205
[20/23] Train loss=0.3134307265281677
Test set avg_accuracy=83.53% avg_sensitivity=60.22%, avg_specificity=90.95% avg_auc=88.51%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.316929 Test loss=0.358161 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.3017371892929077
[5/23] Train loss=0.29571616649627686
[10/23] Train loss=0.355020135641098
[15/23] Train loss=0.29765087366104126
[20/23] Train loss=0.3036460280418396
Test set avg_accuracy=83.72% avg_sensitivity=59.35%, avg_specificity=91.48% avg_auc=88.48%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.316118 Test loss=0.357594 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.30057665705680847
[5/23] Train loss=0.29601672291755676
[10/23] Train loss=0.3510127663612366
[15/23] Train loss=0.30372944474220276
[20/23] Train loss=0.30894795060157776
Test set avg_accuracy=83.71% avg_sensitivity=59.14%, avg_specificity=91.54% avg_auc=88.48%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.316153 Test loss=0.357649 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.29710206389427185
[5/23] Train loss=0.2957102060317993
[10/23] Train loss=0.3540966212749481
[15/23] Train loss=0.300579696893692
[20/23] Train loss=0.31089386343955994
Test set avg_accuracy=83.66% avg_sensitivity=58.98%, avg_specificity=91.52% avg_auc=88.47%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.315731 Test loss=0.357745 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.29472067952156067
[5/23] Train loss=0.29110443592071533
[10/23] Train loss=0.3530001640319824
[15/23] Train loss=0.2996312379837036
[20/23] Train loss=0.30873551964759827
Test set avg_accuracy=83.75% avg_sensitivity=59.25%, avg_specificity=91.55% avg_auc=88.48%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.315332 Test loss=0.357707 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.3006528317928314
[5/23] Train loss=0.29740995168685913
[10/23] Train loss=0.35416319966316223
[15/23] Train loss=0.3003852069377899
[20/23] Train loss=0.307212233543396
Test set avg_accuracy=83.59% avg_sensitivity=60.05%, avg_specificity=91.09% avg_auc=88.50%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.315306 Test loss=0.358079 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.30221280455589294
[5/23] Train loss=0.2971632778644562
[10/23] Train loss=0.3555978536605835
[15/23] Train loss=0.30400627851486206
[20/23] Train loss=0.3040626049041748
Test set avg_accuracy=83.52% avg_sensitivity=60.27%, avg_specificity=90.92% avg_auc=88.51%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.315748 Test loss=0.358364 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.29989880323410034
[5/23] Train loss=0.2966981828212738
[10/23] Train loss=0.3510984480381012
[15/23] Train loss=0.30174073576927185
[20/23] Train loss=0.3078499138355255
Test set avg_accuracy=83.54% avg_sensitivity=60.38%, avg_specificity=90.92% avg_auc=88.51%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.315779 Test loss=0.358279 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.2970166802406311
[5/23] Train loss=0.29603514075279236
[10/23] Train loss=0.3534618318080902
[15/23] Train loss=0.30250513553619385
[20/23] Train loss=0.3073435127735138
Test set avg_accuracy=83.63% avg_sensitivity=60.32%, avg_specificity=91.06% avg_auc=88.51%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.315532 Test loss=0.358141 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.30022960901260376
[5/23] Train loss=0.2964473366737366
[10/23] Train loss=0.3488267958164215
[15/23] Train loss=0.3046564757823944
[20/23] Train loss=0.30626606941223145
Test set avg_accuracy=83.52% avg_sensitivity=60.38%, avg_specificity=90.88% avg_auc=88.52%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.314958 Test loss=0.358307 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.3012419044971466
[5/23] Train loss=0.2976423501968384
[10/23] Train loss=0.3533201515674591
[15/23] Train loss=0.29781121015548706
[20/23] Train loss=0.30402904748916626
Test set avg_accuracy=83.54% avg_sensitivity=60.38%, avg_specificity=90.92% avg_auc=88.52%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.315359 Test loss=0.358261 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.2961302399635315
[5/23] Train loss=0.29725077748298645
[10/23] Train loss=0.3538258969783783
[15/23] Train loss=0.3005369305610657
[20/23] Train loss=0.303032249212265
Test set avg_accuracy=83.55% avg_sensitivity=60.38%, avg_specificity=90.94% avg_auc=88.51%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.315087 Test loss=0.358255 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.29887357354164124
[5/23] Train loss=0.29431408643722534
[10/23] Train loss=0.3521154224872589
[15/23] Train loss=0.3003665506839752
[20/23] Train loss=0.30668121576309204
Test set avg_accuracy=83.50% avg_sensitivity=60.49%, avg_specificity=90.83% avg_auc=88.52%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.315147 Test loss=0.358458 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.2997741103172302
[5/23] Train loss=0.2969232201576233
[10/23] Train loss=0.35400569438934326
[15/23] Train loss=0.2955191731452942
[20/23] Train loss=0.3091745674610138
Test set avg_accuracy=83.52% avg_sensitivity=60.49%, avg_specificity=90.85% avg_auc=88.52%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.315289 Test loss=0.358413 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.2986415922641754
[5/23] Train loss=0.29551687836647034
[10/23] Train loss=0.35226571559906006
[15/23] Train loss=0.3012562394142151
[20/23] Train loss=0.301822304725647
Test set avg_accuracy=83.50% avg_sensitivity=60.54%, avg_specificity=90.82% avg_auc=88.52%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.314861 Test loss=0.358513 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.2966609299182892
[5/23] Train loss=0.29967615008354187
[10/23] Train loss=0.3549107611179352
[15/23] Train loss=0.29791438579559326
[20/23] Train loss=0.3085173964500427
Test set avg_accuracy=83.50% avg_sensitivity=60.32%, avg_specificity=90.88% avg_auc=88.52%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.315329 Test loss=0.358359 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.29508155584335327
[5/23] Train loss=0.29872462153434753
[10/23] Train loss=0.34990203380584717
[15/23] Train loss=0.30142977833747864
[20/23] Train loss=0.31052330136299133
Test set avg_accuracy=83.52% avg_sensitivity=60.49%, avg_specificity=90.85% avg_auc=88.52%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.315180 Test loss=0.358425 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.2985546290874481
[5/23] Train loss=0.2974143624305725
[10/23] Train loss=0.3505817949771881
[15/23] Train loss=0.2982708215713501
[20/23] Train loss=0.3084193766117096
Test set avg_accuracy=83.50% avg_sensitivity=60.59%, avg_specificity=90.80% avg_auc=88.52%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.315362 Test loss=0.358483 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.2951042950153351
[5/23] Train loss=0.2994564175605774
[10/23] Train loss=0.34999075531959534
[15/23] Train loss=0.3038807213306427
[20/23] Train loss=0.30638688802719116
Test set avg_accuracy=83.50% avg_sensitivity=60.49%, avg_specificity=90.83% avg_auc=88.52%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.315296 Test loss=0.358455 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.2976459562778473
[5/23] Train loss=0.29610466957092285
[10/23] Train loss=0.34675753116607666
[15/23] Train loss=0.29395025968551636
[20/23] Train loss=0.30637040734291077
Test set avg_accuracy=83.50% avg_sensitivity=60.43%, avg_specificity=90.85% avg_auc=88.52%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.315260 Test loss=0.358414 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.29843923449516296
[5/23] Train loss=0.29859068989753723
[10/23] Train loss=0.35002556443214417
[15/23] Train loss=0.29960882663726807
[20/23] Train loss=0.3068365454673767
Test set avg_accuracy=83.53% avg_sensitivity=60.49%, avg_specificity=90.87% avg_auc=88.52%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.315115 Test loss=0.358425 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.29712381958961487
[5/23] Train loss=0.2908177971839905
[10/23] Train loss=0.3511369526386261
[15/23] Train loss=0.30614200234413147
[20/23] Train loss=0.3001795709133148
Test set avg_accuracy=83.50% avg_sensitivity=60.54%, avg_specificity=90.82% avg_auc=88.52%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.314652 Test loss=0.358449 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.2937307059764862
[5/23] Train loss=0.29369407892227173
[10/23] Train loss=0.35060209035873413
[15/23] Train loss=0.30041664838790894
[20/23] Train loss=0.30559661984443665
Test set avg_accuracy=83.50% avg_sensitivity=60.54%, avg_specificity=90.82% avg_auc=88.52%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.314836 Test loss=0.358476 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.29302147030830383
[5/23] Train loss=0.2957330048084259
[10/23] Train loss=0.3547496199607849
[15/23] Train loss=0.2969210147857666
[20/23] Train loss=0.30092960596084595
Test set avg_accuracy=83.50% avg_sensitivity=60.54%, avg_specificity=90.82% avg_auc=88.52%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.314583 Test loss=0.358478 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.3012182116508484
[5/23] Train loss=0.29632437229156494
[10/23] Train loss=0.35019293427467346
[15/23] Train loss=0.2980480492115021
[20/23] Train loss=0.3088345229625702
Test set avg_accuracy=83.50% avg_sensitivity=60.54%, avg_specificity=90.82% avg_auc=88.52%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.314677 Test loss=0.358478 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=83.57% sen=62.75%, spe=90.20%, auc=88.58%!
Fold[9] Avg_jsc=0.53%(±0.2846506333254465)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 2,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=0.9402055144309998
[5/24] Train loss=0.8555262684822083
[10/24] Train loss=0.7722063064575195
[15/24] Train loss=0.7241597175598145
[20/24] Train loss=0.6881067752838135
Test set avg_accuracy=73.53% avg_sensitivity=6.95%, avg_specificity=92.83% avg_auc=50.17%
Best model saved!! Metric=50.172362387419035!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.766864 Test loss=0.583387 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6723847985267639
[5/24] Train loss=0.6589444875717163
[10/24] Train loss=0.648424506187439
[15/24] Train loss=0.6442994475364685
[20/24] Train loss=0.6407056450843811
Test set avg_accuracy=77.41% avg_sensitivity=0.75%, avg_specificity=99.63% avg_auc=50.69%
Best model saved!! Metric=50.69046155714476!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.644477 Test loss=0.545713 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6488988399505615
[5/24] Train loss=0.6350120902061462
[10/24] Train loss=0.6166630983352661
[15/24] Train loss=0.6321021318435669
[20/24] Train loss=0.6435443162918091
Test set avg_accuracy=77.50% avg_sensitivity=0.00%, avg_specificity=99.97% avg_auc=51.05%
Best model saved!! Metric=51.046128662737225!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.625706 Test loss=0.538105 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6414095163345337
[5/24] Train loss=0.6180678606033325
[10/24] Train loss=0.6132727861404419
[15/24] Train loss=0.617276668548584
[20/24] Train loss=0.6231198906898499
Test set avg_accuracy=77.50% avg_sensitivity=0.00%, avg_specificity=99.97% avg_auc=52.29%
Best model saved!! Metric=52.294692877141124!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.615885 Test loss=0.534753 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6362186670303345
[5/24] Train loss=0.623989999294281
[10/24] Train loss=0.6041122674942017
[15/24] Train loss=0.6263949871063232
[20/24] Train loss=0.6200827360153198
Test set avg_accuracy=77.50% avg_sensitivity=0.00%, avg_specificity=99.97% avg_auc=53.51%
Best model saved!! Metric=53.513310428230966!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.611123 Test loss=0.532355 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6242578029632568
[5/24] Train loss=0.6083518266677856
[10/24] Train loss=0.5961584448814392
[15/24] Train loss=0.6196749806404114
[20/24] Train loss=0.6138215065002441
Test set avg_accuracy=77.53% avg_sensitivity=0.06%, avg_specificity=99.98% avg_auc=54.27%
Best model saved!! Metric=54.27083207643303!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.604669 Test loss=0.530863 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6202671527862549
[5/24] Train loss=0.6124320030212402
[10/24] Train loss=0.5936803221702576
[15/24] Train loss=0.6043902039527893
[20/24] Train loss=0.6113110184669495
Test set avg_accuracy=77.53% avg_sensitivity=0.06%, avg_specificity=99.98% avg_auc=55.44%
Best model saved!! Metric=55.44255670453002!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.601367 Test loss=0.529176 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6180753111839294
[5/24] Train loss=0.608863115310669
[10/24] Train loss=0.5835696458816528
[15/24] Train loss=0.6068025231361389
[20/24] Train loss=0.6043252348899841
Test set avg_accuracy=77.53% avg_sensitivity=0.06%, avg_specificity=99.98% avg_auc=56.08%
Best model saved!! Metric=56.077314062116244!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.597834 Test loss=0.528033 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6157759428024292
[5/24] Train loss=0.5983961820602417
[10/24] Train loss=0.5900878310203552
[15/24] Train loss=0.6033354997634888
[20/24] Train loss=0.6047888994216919
Test set avg_accuracy=77.53% avg_sensitivity=0.06%, avg_specificity=99.98% avg_auc=56.97%
Best model saved!! Metric=56.96645506628454!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.594179 Test loss=0.526815 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6059243679046631
[5/24] Train loss=0.5883551836013794
[10/24] Train loss=0.58655846118927
[15/24] Train loss=0.59360671043396
[20/24] Train loss=0.5989212989807129
Test set avg_accuracy=77.53% avg_sensitivity=0.06%, avg_specificity=99.98% avg_auc=57.81%
Best model saved!! Metric=57.805326545617596!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.590452 Test loss=0.525748 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6124350428581238
[5/24] Train loss=0.5901220440864563
[10/24] Train loss=0.5797070860862732
[15/24] Train loss=0.6053089499473572
[20/24] Train loss=0.596614420413971
Test set avg_accuracy=77.53% avg_sensitivity=0.12%, avg_specificity=99.97% avg_auc=58.38%
Best model saved!! Metric=58.37639068314786!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.588927 Test loss=0.524548 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6002709865570068
[5/24] Train loss=0.5886709094047546
[10/24] Train loss=0.5716405510902405
[15/24] Train loss=0.5987333059310913
[20/24] Train loss=0.5985219478607178
Test set avg_accuracy=77.50% avg_sensitivity=0.17%, avg_specificity=99.92% avg_auc=58.94%
Best model saved!! Metric=58.94206393473953!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.584136 Test loss=0.523208 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.6029078960418701
[5/24] Train loss=0.5853397846221924
[10/24] Train loss=0.5768043994903564
[15/24] Train loss=0.5957924723625183
[20/24] Train loss=0.5885175466537476
Test set avg_accuracy=77.49% avg_sensitivity=0.35%, avg_specificity=99.85% avg_auc=59.74%
Best model saved!! Metric=59.73607623685802!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.581831 Test loss=0.521513 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5970001816749573
[5/24] Train loss=0.5891900658607483
[10/24] Train loss=0.5710519552230835
[15/24] Train loss=0.5857943296432495
[20/24] Train loss=0.5870131850242615
Test set avg_accuracy=77.38% avg_sensitivity=0.41%, avg_specificity=99.70% avg_auc=60.73%
Best model saved!! Metric=60.729201008426514!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.578779 Test loss=0.519805 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5990467667579651
[5/24] Train loss=0.581656277179718
[10/24] Train loss=0.5694706439971924
[15/24] Train loss=0.5809862017631531
[20/24] Train loss=0.5816137790679932
Test set avg_accuracy=77.37% avg_sensitivity=0.46%, avg_specificity=99.66% avg_auc=61.91%
Best model saved!! Metric=61.90907521589817!!
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.574719 Test loss=0.517123 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5911700129508972
[5/24] Train loss=0.5814486742019653
[10/24] Train loss=0.5635277032852173
[15/24] Train loss=0.5809161067008972
[20/24] Train loss=0.5721491575241089
Test set avg_accuracy=77.37% avg_sensitivity=0.64%, avg_specificity=99.61% avg_auc=63.19%
Best model saved!! Metric=63.19270938142601!!
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.570909 Test loss=0.514170 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5787457227706909
[5/24] Train loss=0.575621485710144
[10/24] Train loss=0.5582308769226074
[15/24] Train loss=0.5717155933380127
[20/24] Train loss=0.5760162472724915
Test set avg_accuracy=77.34% avg_sensitivity=0.81%, avg_specificity=99.53% avg_auc=64.69%
Best model saved!! Metric=64.68534741632548!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.565213 Test loss=0.510382 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5751309990882874
[5/24] Train loss=0.5651078820228577
[10/24] Train loss=0.550171971321106
[15/24] Train loss=0.5674778819084167
[20/24] Train loss=0.5658833980560303
Test set avg_accuracy=77.25% avg_sensitivity=1.22%, avg_specificity=99.29% avg_auc=66.76%
Best model saved!! Metric=66.76464326152882!!
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.559706 Test loss=0.504779 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.574329137802124
[5/24] Train loss=0.5629083514213562
[10/24] Train loss=0.5461572408676147
[15/24] Train loss=0.5606526136398315
[20/24] Train loss=0.5590118169784546
Test set avg_accuracy=77.45% avg_sensitivity=2.90%, avg_specificity=99.06% avg_auc=69.07%
Best model saved!! Metric=69.07373291799509!!
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.552275 Test loss=0.496304 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5680595636367798
[5/24] Train loss=0.557626485824585
[10/24] Train loss=0.5347467064857483
[15/24] Train loss=0.5431151986122131
[20/24] Train loss=0.5464590191841125
Test set avg_accuracy=77.71% avg_sensitivity=6.08%, avg_specificity=98.47% avg_auc=72.72%
Best model saved!! Metric=72.71959199751203!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.542336 Test loss=0.483000 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5536170601844788
[5/24] Train loss=0.5358418226242065
[10/24] Train loss=0.5314508080482483
[15/24] Train loss=0.5229889750480652
[20/24] Train loss=0.529005765914917
Test set avg_accuracy=77.80% avg_sensitivity=8.23%, avg_specificity=97.97% avg_auc=74.63%
Best model saved!! Metric=74.62603404782358!!
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.527248 Test loss=0.470335 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5434839129447937
[5/24] Train loss=0.5315986275672913
[10/24] Train loss=0.5151967406272888
[15/24] Train loss=0.5040655136108398
[20/24] Train loss=0.5151565670967102
Test set avg_accuracy=77.97% avg_sensitivity=11.18%, avg_specificity=97.33% avg_auc=77.21%
Best model saved!! Metric=77.21279811891164!!
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.515491 Test loss=0.454841 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5239285826683044
[5/24] Train loss=0.5218627452850342
[10/24] Train loss=0.5038415789604187
[15/24] Train loss=0.4938177466392517
[20/24] Train loss=0.5035762190818787
Test set avg_accuracy=78.35% avg_sensitivity=10.31%, avg_specificity=98.07% avg_auc=78.28%
Best model saved!! Metric=78.28282572725387!!
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.506280 Test loss=0.450219 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5198305249214172
[5/24] Train loss=0.5165717601776123
[10/24] Train loss=0.4923875331878662
[15/24] Train loss=0.48973608016967773
[20/24] Train loss=0.4868079125881195
Test set avg_accuracy=78.44% avg_sensitivity=10.66%, avg_specificity=98.09% avg_auc=79.25%
Best model saved!! Metric=79.24630549158067!!
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.495928 Test loss=0.446100 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5191699862480164
[5/24] Train loss=0.4952057898044586
[10/24] Train loss=0.48476314544677734
[15/24] Train loss=0.4765253961086273
[20/24] Train loss=0.47763168811798096
Test set avg_accuracy=79.11% avg_sensitivity=17.67%, avg_specificity=96.93% avg_auc=80.57%
Best model saved!! Metric=80.57448744740967!!
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.482196 Test loss=0.431059 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.49749892950057983
[5/24] Train loss=0.505329966545105
[10/24] Train loss=0.4677002727985382
[15/24] Train loss=0.46133387088775635
[20/24] Train loss=0.472025066614151
Test set avg_accuracy=79.56% avg_sensitivity=19.87%, avg_specificity=96.86% avg_auc=81.86%
Best model saved!! Metric=81.85792699611663!!
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.474991 Test loss=0.420439 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.487799733877182
[5/24] Train loss=0.5024631023406982
[10/24] Train loss=0.4495883882045746
[15/24] Train loss=0.4539187252521515
[20/24] Train loss=0.4606086015701294
Test set avg_accuracy=80.05% avg_sensitivity=20.51%, avg_specificity=97.31% avg_auc=82.98%
Best model saved!! Metric=82.98397019093078!!
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.463854 Test loss=0.414489 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.48154181241989136
[5/24] Train loss=0.4880831837654114
[10/24] Train loss=0.4413128197193146
[15/24] Train loss=0.45580267906188965
[20/24] Train loss=0.4409637153148651
Test set avg_accuracy=80.56% avg_sensitivity=23.12%, avg_specificity=97.21% avg_auc=84.20%
Best model saved!! Metric=84.20333215136051!!
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.451919 Test loss=0.405007 Current lr=[0.000210185142098938]

[0/24] Train loss=0.4737122654914856
[5/24] Train loss=0.4636117219924927
[10/24] Train loss=0.4303538203239441
[15/24] Train loss=0.4357936978340149
[20/24] Train loss=0.43479350209236145
Test set avg_accuracy=81.33% avg_sensitivity=28.74%, avg_specificity=96.57% avg_auc=85.10%
Best model saved!! Metric=85.09581569942756!!
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.438932 Test loss=0.393443 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.45933565497398376
[5/24] Train loss=0.46275055408477783
[10/24] Train loss=0.4123656153678894
[15/24] Train loss=0.4285925030708313
[20/24] Train loss=0.42526137828826904
Test set avg_accuracy=81.90% avg_sensitivity=31.98%, avg_specificity=96.37% avg_auc=85.68%
Best model saved!! Metric=85.67706316211076!!
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.430519 Test loss=0.386128 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.44497111439704895
[5/24] Train loss=0.45647236704826355
[10/24] Train loss=0.40856707096099854
[15/24] Train loss=0.42415687441825867
[20/24] Train loss=0.4148094356060028
Test set avg_accuracy=82.17% avg_sensitivity=33.26%, avg_specificity=96.36% avg_auc=85.99%
Best model saved!! Metric=85.98833817085877!!
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.424411 Test loss=0.382813 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.44393739104270935
[5/24] Train loss=0.45773744583129883
[10/24] Train loss=0.4025094211101532
[15/24] Train loss=0.42178255319595337
[20/24] Train loss=0.4151350259780884
Test set avg_accuracy=82.21% avg_sensitivity=32.27%, avg_specificity=96.69% avg_auc=86.15%
Best model saved!! Metric=86.14867323874697!!
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.418864 Test loss=0.384497 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.44494208693504333
[5/24] Train loss=0.44340306520462036
[10/24] Train loss=0.40219444036483765
[15/24] Train loss=0.4205039143562317
[20/24] Train loss=0.41025933623313904
Test set avg_accuracy=82.45% avg_sensitivity=34.01%, avg_specificity=96.49% avg_auc=86.45%
Best model saved!! Metric=86.45415353165306!!
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.413689 Test loss=0.377516 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.4283583164215088
[5/24] Train loss=0.43799522519111633
[10/24] Train loss=0.3973352611064911
[15/24] Train loss=0.415878564119339
[20/24] Train loss=0.4045152962207794
Test set avg_accuracy=82.68% avg_sensitivity=36.27%, avg_specificity=96.14% avg_auc=86.61%
Best model saved!! Metric=86.61119957526824!!
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.409071 Test loss=0.373270 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.4229573905467987
[5/24] Train loss=0.43996763229370117
[10/24] Train loss=0.38763031363487244
[15/24] Train loss=0.40151578187942505
[20/24] Train loss=0.4005444645881653
Test set avg_accuracy=82.70% avg_sensitivity=36.67%, avg_specificity=96.04% avg_auc=86.82%
Best model saved!! Metric=86.81671493812547!!
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.404178 Test loss=0.370967 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4189995229244232
[5/24] Train loss=0.4416995644569397
[10/24] Train loss=0.3846047818660736
[15/24] Train loss=0.40252846479415894
[20/24] Train loss=0.3927788734436035
Test set avg_accuracy=82.64% avg_sensitivity=35.40%, avg_specificity=96.34% avg_auc=86.79%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.402548 Test loss=0.373286 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.42540881037712097
[5/24] Train loss=0.4379420578479767
[10/24] Train loss=0.3872564435005188
[15/24] Train loss=0.40268513560295105
[20/24] Train loss=0.3992502987384796
Test set avg_accuracy=82.55% avg_sensitivity=35.11%, avg_specificity=96.31% avg_auc=86.83%
Best model saved!! Metric=86.83283894173601!!
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.400654 Test loss=0.373674 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.4152946174144745
[5/24] Train loss=0.4310019314289093
[10/24] Train loss=0.3821943402290344
[15/24] Train loss=0.3991420865058899
[20/24] Train loss=0.39037153124809265
Test set avg_accuracy=82.66% avg_sensitivity=35.40%, avg_specificity=96.36% avg_auc=86.92%
Best model saved!! Metric=86.92121444010102!!
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.397892 Test loss=0.373019 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4187506437301636
[5/24] Train loss=0.4218938648700714
[10/24] Train loss=0.38765305280685425
[15/24] Train loss=0.3963972330093384
[20/24] Train loss=0.39049625396728516
Test set avg_accuracy=82.73% avg_sensitivity=35.86%, avg_specificity=96.32% avg_auc=86.94%
Best model saved!! Metric=86.94011173340921!!
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.392997 Test loss=0.372849 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.41708171367645264
[5/24] Train loss=0.4213744103908539
[10/24] Train loss=0.37616071105003357
[15/24] Train loss=0.3955909013748169
[20/24] Train loss=0.3862532377243042
Test set avg_accuracy=82.84% avg_sensitivity=36.38%, avg_specificity=96.31% avg_auc=87.08%
Best model saved!! Metric=87.0765235285898!!
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.391817 Test loss=0.369282 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.40996021032333374
[5/24] Train loss=0.41700541973114014
[10/24] Train loss=0.3745959997177124
[15/24] Train loss=0.3904220163822174
[20/24] Train loss=0.38868942856788635
Test set avg_accuracy=83.20% avg_sensitivity=39.28%, avg_specificity=95.94% avg_auc=87.17%
Best model saved!! Metric=87.16686952226632!!
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.387744 Test loss=0.365008 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3970198631286621
[5/24] Train loss=0.4094923436641693
[10/24] Train loss=0.36894461512565613
[15/24] Train loss=0.3796105682849884
[20/24] Train loss=0.3823327124118805
Test set avg_accuracy=83.55% avg_sensitivity=42.18%, avg_specificity=95.55% avg_auc=87.28%
Best model saved!! Metric=87.28077874753177!!
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.383639 Test loss=0.361136 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3944985568523407
[5/24] Train loss=0.40775853395462036
[10/24] Train loss=0.36562711000442505
[15/24] Train loss=0.384114533662796
[20/24] Train loss=0.3775734007358551
Test set avg_accuracy=83.72% avg_sensitivity=44.03%, avg_specificity=95.23% avg_auc=87.36%
Best model saved!! Metric=87.35917040298527!!
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.380693 Test loss=0.358506 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.379108190536499
[5/24] Train loss=0.41493523120880127
[10/24] Train loss=0.356523722410202
[15/24] Train loss=0.37932658195495605
[20/24] Train loss=0.37687647342681885
Test set avg_accuracy=83.89% avg_sensitivity=45.02%, avg_specificity=95.16% avg_auc=87.45%
Best model saved!! Metric=87.44612519855781!!
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.378696 Test loss=0.357239 Current lr=[0.00029967723776099]

[0/24] Train loss=0.38958731293678284
[5/24] Train loss=0.4055445194244385
[10/24] Train loss=0.36086755990982056
[15/24] Train loss=0.374592661857605
[20/24] Train loss=0.37234121561050415
Test set avg_accuracy=83.66% avg_sensitivity=41.43%, avg_specificity=95.90% avg_auc=87.50%
Best model saved!! Metric=87.49960590093768!!
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.377381 Test loss=0.359443 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3822551369667053
[5/24] Train loss=0.40972793102264404
[10/24] Train loss=0.35711702704429626
[15/24] Train loss=0.3722262382507324
[20/24] Train loss=0.37184983491897583
Test set avg_accuracy=83.36% avg_sensitivity=39.22%, avg_specificity=96.15% avg_auc=87.53%
Best model saved!! Metric=87.53200960161548!!
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.375548 Test loss=0.361422 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.38157883286476135
[5/24] Train loss=0.40509092807769775
[10/24] Train loss=0.3591288924217224
[15/24] Train loss=0.37127941846847534
[20/24] Train loss=0.3636763393878937
Test set avg_accuracy=83.16% avg_sensitivity=37.60%, avg_specificity=96.37% avg_auc=87.58%
Best model saved!! Metric=87.58018699562619!!
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.373952 Test loss=0.363093 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3927866518497467
[5/24] Train loss=0.38903912901878357
[10/24] Train loss=0.3572853207588196
[15/24] Train loss=0.3699050843715668
[20/24] Train loss=0.3691556453704834
Test set avg_accuracy=83.52% avg_sensitivity=40.15%, avg_specificity=96.09% avg_auc=87.59%
Best model saved!! Metric=87.58564599745208!!
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.370489 Test loss=0.361503 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3871440887451172
[5/24] Train loss=0.3833825886249542
[10/24] Train loss=0.3578512966632843
[15/24] Train loss=0.3687345087528229
[20/24] Train loss=0.3564339280128479
Test set avg_accuracy=83.65% avg_sensitivity=41.48%, avg_specificity=95.87% avg_auc=87.64%
Best model saved!! Metric=87.6373556867619!!
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.367978 Test loss=0.358811 Current lr=[0.000298904600941902]

[0/24] Train loss=0.37585195899009705
[5/24] Train loss=0.39254412055015564
[10/24] Train loss=0.34939444065093994
[15/24] Train loss=0.3606983423233032
[20/24] Train loss=0.36048370599746704
Test set avg_accuracy=83.72% avg_sensitivity=42.35%, avg_specificity=95.72% avg_auc=87.67%
Best model saved!! Metric=87.66679148092113!!
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.365483 Test loss=0.358100 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3743971884250641
[5/24] Train loss=0.3875739574432373
[10/24] Train loss=0.3504297435283661
[15/24] Train loss=0.3618334233760834
[20/24] Train loss=0.35874229669570923
Test set avg_accuracy=83.88% avg_sensitivity=41.77%, avg_specificity=96.09% avg_auc=87.68%
Best model saved!! Metric=87.67791383223485!!
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.364512 Test loss=0.359199 Current lr=[0.000297555943323901]

[0/24] Train loss=0.38042908906936646
[5/24] Train loss=0.3851741552352905
[10/24] Train loss=0.3488762080669403
[15/24] Train loss=0.3590559959411621
[20/24] Train loss=0.35944902896881104
Test set avg_accuracy=83.82% avg_sensitivity=41.83%, avg_specificity=95.99% avg_auc=87.72%
Best model saved!! Metric=87.71963481321261!!
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.362997 Test loss=0.358790 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.37537285685539246
[5/24] Train loss=0.3731894791126251
[10/24] Train loss=0.35268473625183105
[15/24] Train loss=0.35839730501174927
[20/24] Train loss=0.3543173670768738
Test set avg_accuracy=83.79% avg_sensitivity=42.41%, avg_specificity=95.78% avg_auc=87.75%
Best model saved!! Metric=87.74656491580292!!
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.359781 Test loss=0.357708 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.36632558703422546
[5/24] Train loss=0.38173967599868774
[10/24] Train loss=0.34404993057250977
[15/24] Train loss=0.35796061158180237
[20/24] Train loss=0.3520139157772064
Test set avg_accuracy=84.23% avg_sensitivity=44.79%, avg_specificity=95.67% avg_auc=87.80%
Best model saved!! Metric=87.79760317708067!!
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.359390 Test loss=0.355264 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3704206645488739
[5/24] Train loss=0.3740493357181549
[10/24] Train loss=0.34015122056007385
[15/24] Train loss=0.35393062233924866
[20/24] Train loss=0.3549152612686157
Test set avg_accuracy=84.41% avg_sensitivity=47.22%, avg_specificity=95.20% avg_auc=87.83%
Best model saved!! Metric=87.83423979361275!!
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.355497 Test loss=0.352509 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3613763153553009
[5/24] Train loss=0.36577510833740234
[10/24] Train loss=0.33880415558815
[15/24] Train loss=0.35525375604629517
[20/24] Train loss=0.34838515520095825
Test set avg_accuracy=84.45% avg_sensitivity=49.65%, avg_specificity=94.54% avg_auc=87.85%
Best model saved!! Metric=87.84707477295028!!
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.351956 Test loss=0.350383 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.360916405916214
[5/24] Train loss=0.369926780462265
[10/24] Train loss=0.3341807723045349
[15/24] Train loss=0.35237810015678406
[20/24] Train loss=0.350946307182312
Test set avg_accuracy=84.44% avg_sensitivity=52.03%, avg_specificity=93.84% avg_auc=87.90%
Best model saved!! Metric=87.90432131081435!!
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.350114 Test loss=0.348230 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3509814739227295
[5/24] Train loss=0.35596296191215515
[10/24] Train loss=0.33168840408325195
[15/24] Train loss=0.35056716203689575
[20/24] Train loss=0.34296494722366333
Test set avg_accuracy=84.43% avg_sensitivity=52.32%, avg_specificity=93.74% avg_auc=87.90%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.346849 Test loss=0.348186 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3549218475818634
[5/24] Train loss=0.3554105758666992
[10/24] Train loss=0.33394578099250793
[15/24] Train loss=0.3515179455280304
[20/24] Train loss=0.34695422649383545
Test set avg_accuracy=84.58% avg_sensitivity=51.27%, avg_specificity=94.24% avg_auc=87.87%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.345383 Test loss=0.348991 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3485596179962158
[5/24] Train loss=0.3566649258136749
[10/24] Train loss=0.3257277309894562
[15/24] Train loss=0.34972524642944336
[20/24] Train loss=0.3556819558143616
Test set avg_accuracy=84.60% avg_sensitivity=53.48%, avg_specificity=93.62% avg_auc=87.91%
Best model saved!! Metric=87.91329314625726!!
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.346438 Test loss=0.347522 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.34319964051246643
[5/24] Train loss=0.3573911190032959
[10/24] Train loss=0.3261650800704956
[15/24] Train loss=0.34663093090057373
[20/24] Train loss=0.34732598066329956
Test set avg_accuracy=84.64% avg_sensitivity=54.87%, avg_specificity=93.27% avg_auc=87.88%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.343648 Test loss=0.347914 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.342897891998291
[5/24] Train loss=0.351070761680603
[10/24] Train loss=0.323218435049057
[15/24] Train loss=0.3478127121925354
[20/24] Train loss=0.3424895405769348
Test set avg_accuracy=84.48% avg_sensitivity=52.43%, avg_specificity=93.77% avg_auc=87.88%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.341224 Test loss=0.348739 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3469129800796509
[5/24] Train loss=0.3520594537258148
[10/24] Train loss=0.32539433240890503
[15/24] Train loss=0.35085710883140564
[20/24] Train loss=0.33757108449935913
Test set avg_accuracy=84.56% avg_sensitivity=52.61%, avg_specificity=93.82% avg_auc=87.85%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.339928 Test loss=0.348877 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.34109753370285034
[5/24] Train loss=0.3433416783809662
[10/24] Train loss=0.32232528924942017
[15/24] Train loss=0.3477848768234253
[20/24] Train loss=0.3439701199531555
Test set avg_accuracy=84.58% avg_sensitivity=56.32%, avg_specificity=92.78% avg_auc=87.88%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.338768 Test loss=0.348385 Current lr=[0.000276307469034998]

[0/24] Train loss=0.33937951922416687
[5/24] Train loss=0.34858545660972595
[10/24] Train loss=0.32084786891937256
[15/24] Train loss=0.3459395468235016
[20/24] Train loss=0.33652281761169434
Test set avg_accuracy=84.43% avg_sensitivity=55.21%, avg_specificity=92.90% avg_auc=87.88%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.336099 Test loss=0.348065 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3363546133041382
[5/24] Train loss=0.3436487913131714
[10/24] Train loss=0.32241594791412354
[15/24] Train loss=0.3478892743587494
[20/24] Train loss=0.3342999517917633
Test set avg_accuracy=84.58% avg_sensitivity=53.53%, avg_specificity=93.58% avg_auc=87.88%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.335773 Test loss=0.348396 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3374520242214203
[5/24] Train loss=0.34943073987960815
[10/24] Train loss=0.31846895813941956
[15/24] Train loss=0.3459837734699249
[20/24] Train loss=0.3331845700740814
Test set avg_accuracy=84.57% avg_sensitivity=53.30%, avg_specificity=93.63% avg_auc=87.87%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.333409 Test loss=0.348662 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.33363690972328186
[5/24] Train loss=0.34680473804473877
[10/24] Train loss=0.3152221143245697
[15/24] Train loss=0.3379843533039093
[20/24] Train loss=0.3389222025871277
Test set avg_accuracy=84.75% avg_sensitivity=55.74%, avg_specificity=93.16% avg_auc=87.93%
Best model saved!! Metric=87.92952418911928!!
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.332486 Test loss=0.347298 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.33579760789871216
[5/24] Train loss=0.3421732187271118
[10/24] Train loss=0.3149196207523346
[15/24] Train loss=0.3374323844909668
[20/24] Train loss=0.3335097134113312
Test set avg_accuracy=84.47% avg_sensitivity=56.72%, avg_specificity=92.51% avg_auc=87.86%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.331583 Test loss=0.348813 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3307524621486664
[5/24] Train loss=0.3417450487613678
[10/24] Train loss=0.31507426500320435
[15/24] Train loss=0.33746030926704407
[20/24] Train loss=0.33195361495018005
Test set avg_accuracy=84.45% avg_sensitivity=56.78%, avg_specificity=92.48% avg_auc=87.84%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.329299 Test loss=0.349269 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.32656940817832947
[5/24] Train loss=0.33573922514915466
[10/24] Train loss=0.31231337785720825
[15/24] Train loss=0.3333394229412079
[20/24] Train loss=0.33456289768218994
Test set avg_accuracy=84.58% avg_sensitivity=56.89%, avg_specificity=92.61% avg_auc=87.88%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.328145 Test loss=0.348432 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3334231972694397
[5/24] Train loss=0.3421870768070221
[10/24] Train loss=0.30519193410873413
[15/24] Train loss=0.33814433217048645
[20/24] Train loss=0.32526877522468567
Test set avg_accuracy=84.54% avg_sensitivity=58.52%, avg_specificity=92.09% avg_auc=87.92%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.326695 Test loss=0.348505 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.32455089688301086
[5/24] Train loss=0.3385104537010193
[10/24] Train loss=0.305258572101593
[15/24] Train loss=0.3351779282093048
[20/24] Train loss=0.32297560572624207
Test set avg_accuracy=84.44% avg_sensitivity=58.63%, avg_specificity=91.92% avg_auc=87.95%
Best model saved!! Metric=87.947662476826!!
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.324411 Test loss=0.348416 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.32878413796424866
[5/24] Train loss=0.3343455493450165
[10/24] Train loss=0.3089086711406708
[15/24] Train loss=0.3253926634788513
[20/24] Train loss=0.3210498094558716
Test set avg_accuracy=84.64% avg_sensitivity=56.95%, avg_specificity=92.66% avg_auc=87.99%
Best model saved!! Metric=87.99337796805247!!
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.323247 Test loss=0.346784 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.32450205087661743
[5/24] Train loss=0.34164777398109436
[10/24] Train loss=0.3019461929798126
[15/24] Train loss=0.3339306116104126
[20/24] Train loss=0.32417625188827515
Test set avg_accuracy=84.60% avg_sensitivity=57.88%, avg_specificity=92.34% avg_auc=87.94%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.323127 Test loss=0.347769 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.32395946979522705
[5/24] Train loss=0.33522385358810425
[10/24] Train loss=0.3045538663864136
[15/24] Train loss=0.3365333080291748
[20/24] Train loss=0.3254069685935974
Test set avg_accuracy=84.49% avg_sensitivity=59.44%, avg_specificity=91.75% avg_auc=87.92%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.322745 Test loss=0.348695 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.32352137565612793
[5/24] Train loss=0.33086538314819336
[10/24] Train loss=0.30458393692970276
[15/24] Train loss=0.3335689902305603
[20/24] Train loss=0.3215872645378113
Test set avg_accuracy=84.62% avg_sensitivity=57.71%, avg_specificity=92.43% avg_auc=87.86%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.320726 Test loss=0.348657 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3204113245010376
[5/24] Train loss=0.33931174874305725
[10/24] Train loss=0.2989840805530548
[15/24] Train loss=0.3344554305076599
[20/24] Train loss=0.3201482892036438
Test set avg_accuracy=84.80% avg_sensitivity=57.18%, avg_specificity=92.81% avg_auc=87.91%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.320240 Test loss=0.347275 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3212893009185791
[5/24] Train loss=0.34056055545806885
[10/24] Train loss=0.3016817271709442
[15/24] Train loss=0.3301612436771393
[20/24] Train loss=0.31718909740448
Test set avg_accuracy=84.73% avg_sensitivity=58.46%, avg_specificity=92.34% avg_auc=87.91%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.320796 Test loss=0.347828 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3170763850212097
[5/24] Train loss=0.33619385957717896
[10/24] Train loss=0.30439937114715576
[15/24] Train loss=0.3268117308616638
[20/24] Train loss=0.31857410073280334
Test set avg_accuracy=84.65% avg_sensitivity=51.33%, avg_specificity=94.31% avg_auc=87.80%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.320664 Test loss=0.350533 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3209383487701416
[5/24] Train loss=0.34736132621765137
[10/24] Train loss=0.30255696177482605
[15/24] Train loss=0.3323710560798645
[20/24] Train loss=0.3241063058376312
Test set avg_accuracy=84.24% avg_sensitivity=48.38%, avg_specificity=94.64% avg_auc=87.78%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.323745 Test loss=0.352012 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3293416500091553
[5/24] Train loss=0.32513388991355896
[10/24] Train loss=0.3138701915740967
[15/24] Train loss=0.32695505023002625
[20/24] Train loss=0.31882792711257935
Test set avg_accuracy=84.47% avg_sensitivity=56.60%, avg_specificity=92.54% avg_auc=87.73%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.319930 Test loss=0.349622 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.31419169902801514
[5/24] Train loss=0.31870850920677185
[10/24] Train loss=0.30666643381118774
[15/24] Train loss=0.32186609506607056
[20/24] Train loss=0.3135383725166321
Test set avg_accuracy=84.54% avg_sensitivity=53.77%, avg_specificity=93.47% avg_auc=87.73%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.315493 Test loss=0.350619 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3195321559906006
[5/24] Train loss=0.32276275753974915
[10/24] Train loss=0.3019717335700989
[15/24] Train loss=0.3198930323123932
[20/24] Train loss=0.316141277551651
Test set avg_accuracy=84.71% avg_sensitivity=52.49%, avg_specificity=94.05% avg_auc=87.84%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.314895 Test loss=0.349410 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.32785582542419434
[5/24] Train loss=0.3225230574607849
[10/24] Train loss=0.3072311282157898
[15/24] Train loss=0.31981781125068665
[20/24] Train loss=0.32071566581726074
Test set avg_accuracy=84.67% avg_sensitivity=55.27%, avg_specificity=93.20% avg_auc=87.82%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.315576 Test loss=0.348902 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3160921335220337
[5/24] Train loss=0.31554776430130005
[10/24] Train loss=0.3033764660358429
[15/24] Train loss=0.3206101655960083
[20/24] Train loss=0.3207969069480896
Test set avg_accuracy=84.73% avg_sensitivity=54.40%, avg_specificity=93.52% avg_auc=87.79%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.313963 Test loss=0.349543 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3181300461292267
[5/24] Train loss=0.32326701283454895
[10/24] Train loss=0.29947543144226074
[15/24] Train loss=0.3235858678817749
[20/24] Train loss=0.31988540291786194
Test set avg_accuracy=84.78% avg_sensitivity=58.00%, avg_specificity=92.54% avg_auc=87.85%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.312799 Test loss=0.348605 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3144448399543762
[5/24] Train loss=0.3095035254955292
[10/24] Train loss=0.2940669655799866
[15/24] Train loss=0.31744298338890076
[20/24] Train loss=0.3145349621772766
Test set avg_accuracy=84.88% avg_sensitivity=55.74%, avg_specificity=93.33% avg_auc=87.80%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.309394 Test loss=0.349497 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.31832966208457947
[5/24] Train loss=0.3110743761062622
[10/24] Train loss=0.2967347502708435
[15/24] Train loss=0.3179348111152649
[20/24] Train loss=0.310356080532074
Test set avg_accuracy=84.93% avg_sensitivity=56.32%, avg_specificity=93.23% avg_auc=87.86%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.310110 Test loss=0.348586 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.31368836760520935
[5/24] Train loss=0.3138898015022278
[10/24] Train loss=0.2951170802116394
[15/24] Train loss=0.31971654295921326
[20/24] Train loss=0.3144131004810333
Test set avg_accuracy=84.88% avg_sensitivity=55.10%, avg_specificity=93.52% avg_auc=87.88%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.309100 Test loss=0.348608 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.31378716230392456
[5/24] Train loss=0.3172784447669983
[10/24] Train loss=0.29811933636665344
[15/24] Train loss=0.31829455494880676
[20/24] Train loss=0.31047242879867554
Test set avg_accuracy=84.83% avg_sensitivity=56.49%, avg_specificity=93.05% avg_auc=87.91%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.308746 Test loss=0.347571 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.30888813734054565
[5/24] Train loss=0.3135105073451996
[10/24] Train loss=0.2954590916633606
[15/24] Train loss=0.3171595335006714
[20/24] Train loss=0.31488534808158875
Test set avg_accuracy=84.82% avg_sensitivity=59.04%, avg_specificity=92.29% avg_auc=87.94%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.307628 Test loss=0.347299 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.30912381410598755
[5/24] Train loss=0.3124677240848541
[10/24] Train loss=0.298045814037323
[15/24] Train loss=0.31364259123802185
[20/24] Train loss=0.306851327419281
Test set avg_accuracy=84.93% avg_sensitivity=58.92%, avg_specificity=92.48% avg_auc=87.88%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.306702 Test loss=0.348060 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3078421950340271
[5/24] Train loss=0.31297093629837036
[10/24] Train loss=0.2919805943965912
[15/24] Train loss=0.30795836448669434
[20/24] Train loss=0.3094416856765747
Test set avg_accuracy=84.88% avg_sensitivity=57.88%, avg_specificity=92.71% avg_auc=87.82%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.305648 Test loss=0.349120 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3114655017852783
[5/24] Train loss=0.3065447509288788
[10/24] Train loss=0.2894970178604126
[15/24] Train loss=0.31411129236221313
[20/24] Train loss=0.3125147223472595
Test set avg_accuracy=84.87% avg_sensitivity=60.37%, avg_specificity=91.97% avg_auc=87.83%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.305508 Test loss=0.349614 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.307338148355484
[5/24] Train loss=0.3039776682853699
[10/24] Train loss=0.2891629934310913
[15/24] Train loss=0.30736708641052246
[20/24] Train loss=0.3129933774471283
Test set avg_accuracy=84.92% avg_sensitivity=58.52%, avg_specificity=92.58% avg_auc=87.86%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.303987 Test loss=0.348530 Current lr=[0.000156543481933168]

[0/24] Train loss=0.31325656175613403
[5/24] Train loss=0.3031953275203705
[10/24] Train loss=0.28958600759506226
[15/24] Train loss=0.30896833539009094
[20/24] Train loss=0.31121429800987244
Test set avg_accuracy=84.84% avg_sensitivity=60.31%, avg_specificity=91.95% avg_auc=87.83%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.303981 Test loss=0.349696 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3053264021873474
[5/24] Train loss=0.3009873926639557
[10/24] Train loss=0.28554385900497437
[15/24] Train loss=0.31054195761680603
[20/24] Train loss=0.3093348443508148
Test set avg_accuracy=84.87% avg_sensitivity=60.72%, avg_specificity=91.87% avg_auc=87.87%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.302534 Test loss=0.349513 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3043482303619385
[5/24] Train loss=0.3029734492301941
[10/24] Train loss=0.28678953647613525
[15/24] Train loss=0.3112545311450958
[20/24] Train loss=0.31108933687210083
Test set avg_accuracy=84.77% avg_sensitivity=60.66%, avg_specificity=91.75% avg_auc=87.87%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.303141 Test loss=0.349324 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3072887361049652
[5/24] Train loss=0.2996208965778351
[10/24] Train loss=0.2856909930706024
[15/24] Train loss=0.3097521662712097
[20/24] Train loss=0.30433255434036255
Test set avg_accuracy=84.47% avg_sensitivity=61.82%, avg_specificity=91.03% avg_auc=87.90%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.302844 Test loss=0.350278 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.30482974648475647
[5/24] Train loss=0.30328240990638733
[10/24] Train loss=0.2881675064563751
[15/24] Train loss=0.31286534667015076
[20/24] Train loss=0.31329020857810974
Test set avg_accuracy=84.28% avg_sensitivity=63.04%, avg_specificity=90.44% avg_auc=87.84%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.303589 Test loss=0.352547 Current lr=[0.000134135431043539]

[0/24] Train loss=0.30931228399276733
[5/24] Train loss=0.300529420375824
[10/24] Train loss=0.28722643852233887
[15/24] Train loss=0.3122718036174774
[20/24] Train loss=0.31247884035110474
Test set avg_accuracy=83.74% avg_sensitivity=66.45%, avg_specificity=88.75% avg_auc=87.85%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.302833 Test loss=0.359261 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.30771008133888245
[5/24] Train loss=0.31280651688575745
[10/24] Train loss=0.28773313760757446
[15/24] Train loss=0.311024010181427
[20/24] Train loss=0.3137204051017761
Test set avg_accuracy=83.65% avg_sensitivity=67.79%, avg_specificity=88.24% avg_auc=87.82%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.305069 Test loss=0.362114 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.31661632657051086
[5/24] Train loss=0.32033997774124146
[10/24] Train loss=0.29965922236442566
[15/24] Train loss=0.31072768568992615
[20/24] Train loss=0.30844828486442566
Test set avg_accuracy=84.44% avg_sensitivity=62.34%, avg_specificity=90.85% avg_auc=87.88%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.304551 Test loss=0.350961 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.30297282338142395
[5/24] Train loss=0.31285983324050903
[10/24] Train loss=0.2938019633293152
[15/24] Train loss=0.3068724572658539
[20/24] Train loss=0.3056381046772003
Test set avg_accuracy=84.41% avg_sensitivity=63.33%, avg_specificity=90.53% avg_auc=87.84%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.300983 Test loss=0.352339 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.29839855432510376
[5/24] Train loss=0.318904846906662
[10/24] Train loss=0.29421699047088623
[15/24] Train loss=0.31687572598457336
[20/24] Train loss=0.3037532866001129
Test set avg_accuracy=84.45% avg_sensitivity=62.80%, avg_specificity=90.73% avg_auc=87.78%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.301496 Test loss=0.352536 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.2999301850795746
[5/24] Train loss=0.31065160036087036
[10/24] Train loss=0.2963687777519226
[15/24] Train loss=0.3111095726490021
[20/24] Train loss=0.3024013936519623
Test set avg_accuracy=84.57% avg_sensitivity=62.40%, avg_specificity=91.00% avg_auc=87.76%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.300354 Test loss=0.352031 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.30683186650276184
[5/24] Train loss=0.3081386685371399
[10/24] Train loss=0.2912842035293579
[15/24] Train loss=0.31016841530799866
[20/24] Train loss=0.3039974868297577
Test set avg_accuracy=84.61% avg_sensitivity=63.56%, avg_specificity=90.71% avg_auc=87.75%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.299926 Test loss=0.353295 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.30330491065979004
[5/24] Train loss=0.3056083023548126
[10/24] Train loss=0.2940050959587097
[15/24] Train loss=0.3139357268810272
[20/24] Train loss=0.29957669973373413
Test set avg_accuracy=84.54% avg_sensitivity=63.15%, avg_specificity=90.75% avg_auc=87.78%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.299885 Test loss=0.352925 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3071404695510864
[5/24] Train loss=0.31474992632865906
[10/24] Train loss=0.2899220883846283
[15/24] Train loss=0.3158183693885803
[20/24] Train loss=0.2969716787338257
Test set avg_accuracy=84.39% avg_sensitivity=63.62%, avg_specificity=90.41% avg_auc=87.78%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.300569 Test loss=0.354287 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.30411645770072937
[5/24] Train loss=0.30956944823265076
[10/24] Train loss=0.2926672101020813
[15/24] Train loss=0.30705776810646057
[20/24] Train loss=0.3026631772518158
Test set avg_accuracy=84.04% avg_sensitivity=65.24%, avg_specificity=89.49% avg_auc=87.73%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.300828 Test loss=0.358267 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.30708637833595276
[5/24] Train loss=0.3200809955596924
[10/24] Train loss=0.29045069217681885
[15/24] Train loss=0.31005948781967163
[20/24] Train loss=0.3059006929397583
Test set avg_accuracy=83.45% avg_sensitivity=67.67%, avg_specificity=88.02% avg_auc=87.65%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.302666 Test loss=0.366394 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.31105005741119385
[5/24] Train loss=0.3203743100166321
[10/24] Train loss=0.2967165410518646
[15/24] Train loss=0.30219829082489014
[20/24] Train loss=0.3118642270565033
Test set avg_accuracy=83.09% avg_sensitivity=70.68%, avg_specificity=86.68% avg_auc=87.51%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.304156 Test loss=0.379084 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.32772576808929443
[5/24] Train loss=0.32766851782798767
[10/24] Train loss=0.28804099559783936
[15/24] Train loss=0.3147886395454407
[20/24] Train loss=0.33170610666275024
Test set avg_accuracy=83.68% avg_sensitivity=66.11%, avg_specificity=88.78% avg_auc=87.56%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.308441 Test loss=0.362997 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3121291697025299
[5/24] Train loss=0.29839304089546204
[10/24] Train loss=0.29015952348709106
[15/24] Train loss=0.326038658618927
[20/24] Train loss=0.3105512261390686
Test set avg_accuracy=84.75% avg_sensitivity=58.40%, avg_specificity=92.39% avg_auc=87.65%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.306924 Test loss=0.350354 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3071787357330322
[5/24] Train loss=0.30106374621391296
[10/24] Train loss=0.2836185097694397
[15/24] Train loss=0.3112536370754242
[20/24] Train loss=0.3033107817173004
Test set avg_accuracy=84.47% avg_sensitivity=61.99%, avg_specificity=90.98% avg_auc=87.63%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.300235 Test loss=0.353892 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.30929046869277954
[5/24] Train loss=0.29917484521865845
[10/24] Train loss=0.277598112821579
[15/24] Train loss=0.3147110044956207
[20/24] Train loss=0.3059375286102295
Test set avg_accuracy=84.39% avg_sensitivity=62.40%, avg_specificity=90.76% avg_auc=87.68%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.299270 Test loss=0.353916 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.30683910846710205
[5/24] Train loss=0.29667943716049194
[10/24] Train loss=0.2800762951374054
[15/24] Train loss=0.3115639388561249
[20/24] Train loss=0.29954245686531067
Test set avg_accuracy=84.48% avg_sensitivity=61.76%, avg_specificity=91.06% avg_auc=87.71%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.298434 Test loss=0.352992 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.30362099409103394
[5/24] Train loss=0.29663240909576416
[10/24] Train loss=0.2788461744785309
[15/24] Train loss=0.31025582551956177
[20/24] Train loss=0.30090874433517456
Test set avg_accuracy=84.61% avg_sensitivity=61.94%, avg_specificity=91.18% avg_auc=87.72%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.296795 Test loss=0.352879 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3023739755153656
[5/24] Train loss=0.2994890511035919
[10/24] Train loss=0.2788841128349304
[15/24] Train loss=0.308305561542511
[20/24] Train loss=0.3002654016017914
Test set avg_accuracy=84.51% avg_sensitivity=62.46%, avg_specificity=90.90% avg_auc=87.71%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.295341 Test loss=0.353864 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.30115243792533875
[5/24] Train loss=0.292657732963562
[10/24] Train loss=0.2777465283870697
[15/24] Train loss=0.30789586901664734
[20/24] Train loss=0.30364006757736206
Test set avg_accuracy=84.61% avg_sensitivity=61.94%, avg_specificity=91.18% avg_auc=87.68%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.295877 Test loss=0.353688 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.29991090297698975
[5/24] Train loss=0.2949824929237366
[10/24] Train loss=0.2746599316596985
[15/24] Train loss=0.3081202805042267
[20/24] Train loss=0.30017250776290894
Test set avg_accuracy=84.58% avg_sensitivity=62.46%, avg_specificity=91.00% avg_auc=87.68%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.295091 Test loss=0.354394 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.2984481453895569
[5/24] Train loss=0.29033568501472473
[10/24] Train loss=0.2798258066177368
[15/24] Train loss=0.3117898106575012
[20/24] Train loss=0.30153173208236694
Test set avg_accuracy=84.48% avg_sensitivity=62.46%, avg_specificity=90.86% avg_auc=87.69%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.294779 Test loss=0.354499 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.30138328671455383
[5/24] Train loss=0.29038843512535095
[10/24] Train loss=0.27714958786964417
[15/24] Train loss=0.30494290590286255
[20/24] Train loss=0.30098041892051697
Test set avg_accuracy=84.48% avg_sensitivity=62.11%, avg_specificity=90.96% avg_auc=87.68%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.294590 Test loss=0.354778 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.2989116609096527
[5/24] Train loss=0.29468080401420593
[10/24] Train loss=0.2827402949333191
[15/24] Train loss=0.3047468960285187
[20/24] Train loss=0.3020228147506714
Test set avg_accuracy=84.48% avg_sensitivity=62.11%, avg_specificity=90.96% avg_auc=87.69%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.295143 Test loss=0.354473 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3023689389228821
[5/24] Train loss=0.29589444398880005
[10/24] Train loss=0.27929288148880005
[15/24] Train loss=0.3076382577419281
[20/24] Train loss=0.2979857325553894
Test set avg_accuracy=84.36% avg_sensitivity=63.09%, avg_specificity=90.53% avg_auc=87.67%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.294284 Test loss=0.356049 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.2990177273750305
[5/24] Train loss=0.2934744358062744
[10/24] Train loss=0.2773251235485077
[15/24] Train loss=0.302570104598999
[20/24] Train loss=0.30502626299858093
Test set avg_accuracy=84.23% avg_sensitivity=63.15%, avg_specificity=90.34% avg_auc=87.65%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.293726 Test loss=0.356633 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.2959184944629669
[5/24] Train loss=0.29187461733818054
[10/24] Train loss=0.27508217096328735
[15/24] Train loss=0.30371204018592834
[20/24] Train loss=0.29123637080192566
Test set avg_accuracy=84.28% avg_sensitivity=62.92%, avg_specificity=90.48% avg_auc=87.64%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.292833 Test loss=0.356297 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.2973290979862213
[5/24] Train loss=0.29197561740875244
[10/24] Train loss=0.27943193912506104
[15/24] Train loss=0.3034665584564209
[20/24] Train loss=0.28924795985221863
Test set avg_accuracy=84.34% avg_sensitivity=63.27%, avg_specificity=90.44% avg_auc=87.67%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.293184 Test loss=0.356209 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.293906033039093
[5/24] Train loss=0.2887975573539734
[10/24] Train loss=0.2792280316352844
[15/24] Train loss=0.29982230067253113
[20/24] Train loss=0.2958676517009735
Test set avg_accuracy=84.26% avg_sensitivity=64.02%, avg_specificity=90.12% avg_auc=87.64%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.292061 Test loss=0.357746 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.29482021927833557
[5/24] Train loss=0.2934441864490509
[10/24] Train loss=0.2761809229850769
[15/24] Train loss=0.30586063861846924
[20/24] Train loss=0.29445573687553406
Test set avg_accuracy=84.27% avg_sensitivity=64.77%, avg_specificity=89.92% avg_auc=87.63%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.292549 Test loss=0.358747 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.2924386262893677
[5/24] Train loss=0.29574182629585266
[10/24] Train loss=0.2742907404899597
[15/24] Train loss=0.30566176772117615
[20/24] Train loss=0.29216402769088745
Test set avg_accuracy=84.22% avg_sensitivity=64.77%, avg_specificity=89.86% avg_auc=87.65%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.292590 Test loss=0.358327 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.2947902977466583
[5/24] Train loss=0.29197797179222107
[10/24] Train loss=0.2766270339488983
[15/24] Train loss=0.3010612428188324
[20/24] Train loss=0.3006771206855774
Test set avg_accuracy=84.26% avg_sensitivity=63.79%, avg_specificity=90.19% avg_auc=87.65%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.291999 Test loss=0.357485 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.2952083349227905
[5/24] Train loss=0.2893831431865692
[10/24] Train loss=0.2738679349422455
[15/24] Train loss=0.3079732358455658
[20/24] Train loss=0.30231064558029175
Test set avg_accuracy=84.44% avg_sensitivity=62.86%, avg_specificity=90.70% avg_auc=87.66%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.293429 Test loss=0.356071 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.2939893901348114
[5/24] Train loss=0.290486603975296
[10/24] Train loss=0.27201229333877563
[15/24] Train loss=0.3023589551448822
[20/24] Train loss=0.3069773018360138
Test set avg_accuracy=84.61% avg_sensitivity=61.82%, avg_specificity=91.22% avg_auc=87.67%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.292977 Test loss=0.354599 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.2909385859966278
[5/24] Train loss=0.29240551590919495
[10/24] Train loss=0.2803196609020233
[15/24] Train loss=0.2983519434928894
[20/24] Train loss=0.295389324426651
Test set avg_accuracy=84.51% avg_sensitivity=62.22%, avg_specificity=90.96% avg_auc=87.66%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.292041 Test loss=0.355050 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.296165406703949
[5/24] Train loss=0.29136642813682556
[10/24] Train loss=0.27352169156074524
[15/24] Train loss=0.3005041182041168
[20/24] Train loss=0.2955473065376282
Test set avg_accuracy=84.49% avg_sensitivity=62.34%, avg_specificity=90.91% avg_auc=87.65%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.291030 Test loss=0.355421 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.2944334149360657
[5/24] Train loss=0.29337847232818604
[10/24] Train loss=0.27536457777023315
[15/24] Train loss=0.3015793561935425
[20/24] Train loss=0.2951847314834595
Test set avg_accuracy=84.44% avg_sensitivity=61.82%, avg_specificity=91.00% avg_auc=87.65%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.291710 Test loss=0.355157 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.2935616374015808
[5/24] Train loss=0.28869518637657166
[10/24] Train loss=0.2736222743988037
[15/24] Train loss=0.30312487483024597
[20/24] Train loss=0.2960498034954071
Test set avg_accuracy=84.48% avg_sensitivity=61.99%, avg_specificity=91.00% avg_auc=87.66%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.291260 Test loss=0.355172 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.2972380816936493
[5/24] Train loss=0.29939505457878113
[10/24] Train loss=0.2781263589859009
[15/24] Train loss=0.30892235040664673
[20/24] Train loss=0.29606178402900696
Test set avg_accuracy=84.49% avg_sensitivity=62.05%, avg_specificity=91.00% avg_auc=87.66%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.292111 Test loss=0.355257 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.29439577460289
[5/24] Train loss=0.28942084312438965
[10/24] Train loss=0.27612796425819397
[15/24] Train loss=0.30205607414245605
[20/24] Train loss=0.2933517396450043
Test set avg_accuracy=84.56% avg_sensitivity=61.99%, avg_specificity=91.10% avg_auc=87.65%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.291674 Test loss=0.355176 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.29420992732048035
[5/24] Train loss=0.28721508383750916
[10/24] Train loss=0.27815401554107666
[15/24] Train loss=0.30075934529304504
[20/24] Train loss=0.2946217954158783
Test set avg_accuracy=84.48% avg_sensitivity=61.99%, avg_specificity=91.00% avg_auc=87.65%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.292378 Test loss=0.355320 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.2961546778678894
[5/24] Train loss=0.2917728126049042
[10/24] Train loss=0.2734052538871765
[15/24] Train loss=0.30497339367866516
[20/24] Train loss=0.29749852418899536
Test set avg_accuracy=84.52% avg_sensitivity=61.99%, avg_specificity=91.05% avg_auc=87.66%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.292384 Test loss=0.355190 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.29220473766326904
[5/24] Train loss=0.2891837954521179
[10/24] Train loss=0.27554887533187866
[15/24] Train loss=0.3028256893157959
[20/24] Train loss=0.2960532009601593
Test set avg_accuracy=84.51% avg_sensitivity=62.11%, avg_specificity=91.00% avg_auc=87.66%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.291989 Test loss=0.355345 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.2930213510990143
[5/24] Train loss=0.2942216694355011
[10/24] Train loss=0.2693866491317749
[15/24] Train loss=0.3030807375907898
[20/24] Train loss=0.2946345806121826
Test set avg_accuracy=84.51% avg_sensitivity=62.28%, avg_specificity=90.95% avg_auc=87.66%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.290859 Test loss=0.355494 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.29213201999664307
[5/24] Train loss=0.2909519672393799
[10/24] Train loss=0.27373063564300537
[15/24] Train loss=0.30198606848716736
[20/24] Train loss=0.29471781849861145
Test set avg_accuracy=84.52% avg_sensitivity=62.05%, avg_specificity=91.03% avg_auc=87.66%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.290723 Test loss=0.355344 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.29419437050819397
[5/24] Train loss=0.2947865426540375
[10/24] Train loss=0.27702099084854126
[15/24] Train loss=0.2943214774131775
[20/24] Train loss=0.2996002435684204
Test set avg_accuracy=84.52% avg_sensitivity=61.99%, avg_specificity=91.05% avg_auc=87.65%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.291829 Test loss=0.355287 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.2930259108543396
[5/24] Train loss=0.29531633853912354
[10/24] Train loss=0.27061590552330017
[15/24] Train loss=0.30077776312828064
[20/24] Train loss=0.2961118519306183
Test set avg_accuracy=84.52% avg_sensitivity=61.99%, avg_specificity=91.05% avg_auc=87.65%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.291749 Test loss=0.355286 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.2993110418319702
[5/24] Train loss=0.2964393198490143
[10/24] Train loss=0.2803763747215271
[15/24] Train loss=0.3025375008583069
[20/24] Train loss=0.29267948865890503
Test set avg_accuracy=84.52% avg_sensitivity=61.99%, avg_specificity=91.05% avg_auc=87.65%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.291884 Test loss=0.355296 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.2969294786453247
[5/24] Train loss=0.293251097202301
[10/24] Train loss=0.2764466404914856
[15/24] Train loss=0.3014724850654602
[20/24] Train loss=0.29508984088897705
Test set avg_accuracy=84.52% avg_sensitivity=61.99%, avg_specificity=91.05% avg_auc=87.65%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.291675 Test loss=0.355296 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=84.64% sen=56.95%, spe=92.66%, auc=87.99%!
Fold[10] Avg_jsc=0.51%(±0.28553239879545095)
Final Avg Result: avg_acc=83.78%(±0.8910422204062434) avg_sen=62.36% (±6.518491046397004) avg_spe=91.18% (±2.881659837300597) avg_auc=89.16% (±1.055922805388703) avg_jsc=0.55% (±0.026126025274284283)
