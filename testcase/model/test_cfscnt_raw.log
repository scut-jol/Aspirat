[0/24] Train loss=0.7709717154502869
[5/24] Train loss=0.7591386437416077
[10/24] Train loss=0.7563673257827759
[15/24] Train loss=0.7498064637184143
[20/24] Train loss=0.7425552010536194
Test set avg_accuracy=55.31% avg_sensitivity=46.96%, avg_specificity=58.30% avg_auc=52.12%
Best model saved!! Metric=-113.31193495095104!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.751708 Test loss=0.691173 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7439862489700317
[5/24] Train loss=0.743011474609375
[10/24] Train loss=0.7396421432495117
[15/24] Train loss=0.7334606647491455
[20/24] Train loss=0.7248850464820862
Test set avg_accuracy=60.74% avg_sensitivity=41.76%, avg_specificity=67.52% avg_auc=55.48%
Best model saved!! Metric=-100.49949510128519!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.734744 Test loss=0.689718 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7221241593360901
[5/24] Train loss=0.7244904041290283
[10/24] Train loss=0.7220126390457153
[15/24] Train loss=0.7198042273521423
[20/24] Train loss=0.7037229537963867
Test set avg_accuracy=60.44% avg_sensitivity=44.29%, avg_specificity=66.21% avg_auc=57.25%
Best model saved!! Metric=-97.81279950410322!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.717507 Test loss=0.683684 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.7061061859130859
[5/24] Train loss=0.7037718892097473
[10/24] Train loss=0.7091622948646545
[15/24] Train loss=0.6960335373878479
[20/24] Train loss=0.6835325956344604
Test set avg_accuracy=61.08% avg_sensitivity=44.43%, avg_specificity=67.03% avg_auc=59.06%
Best model saved!! Metric=-94.39662030026207!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.700065 Test loss=0.671401 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6895302534103394
[5/24] Train loss=0.6835047602653503
[10/24] Train loss=0.6919399499893188
[15/24] Train loss=0.6813863515853882
[20/24] Train loss=0.6618243455886841
Test set avg_accuracy=65.31% avg_sensitivity=40.82%, avg_specificity=74.06% avg_auc=61.77%
Best model saved!! Metric=-84.04153165157786!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.682243 Test loss=0.654122 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6729899644851685
[5/24] Train loss=0.6668745279312134
[10/24] Train loss=0.6689138412475586
[15/24] Train loss=0.6594798564910889
[20/24] Train loss=0.6421911120414734
Test set avg_accuracy=66.68% avg_sensitivity=42.50%, avg_specificity=75.31% avg_auc=64.39%
Best model saved!! Metric=-77.1136599450414!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.661767 Test loss=0.633004 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6429162621498108
[5/24] Train loss=0.6341948509216309
[10/24] Train loss=0.6531690359115601
[15/24] Train loss=0.6385592222213745
[20/24] Train loss=0.616348147392273
Test set avg_accuracy=71.38% avg_sensitivity=41.71%, avg_specificity=81.98% avg_auc=68.79%
Best model saved!! Metric=-62.13915081826442!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.637098 Test loss=0.593909 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6052044034004211
[5/24] Train loss=0.610334038734436
[10/24] Train loss=0.6211086511611938
[15/24] Train loss=0.6063523888587952
[20/24] Train loss=0.5836170315742493
Test set avg_accuracy=73.88% avg_sensitivity=47.65%, avg_specificity=83.25% avg_auc=73.80%
Best model saved!! Metric=-47.426895316547544!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.607716 Test loss=0.558150 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.576045572757721
[5/24] Train loss=0.5750933885574341
[10/24] Train loss=0.5872306227684021
[15/24] Train loss=0.5841947793960571
[20/24] Train loss=0.5494627952575684
Test set avg_accuracy=75.04% avg_sensitivity=51.66%, avg_specificity=83.39% avg_auc=76.39%
Best model saved!! Metric=-39.527756531027705!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.578668 Test loss=0.529269 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5405926704406738
[5/24] Train loss=0.55320143699646
[10/24] Train loss=0.5672404170036316
[15/24] Train loss=0.5559669137001038
[20/24] Train loss=0.5256553888320923
Test set avg_accuracy=76.17% avg_sensitivity=54.77%, avg_specificity=83.81% avg_auc=78.43%
Best model saved!! Metric=-32.80867583227106!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.550093 Test loss=0.503276 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5122056603431702
[5/24] Train loss=0.5274997353553772
[10/24] Train loss=0.5312198400497437
[15/24] Train loss=0.5283925533294678
[20/24] Train loss=0.4944456219673157
Test set avg_accuracy=77.15% avg_sensitivity=54.68%, avg_specificity=85.17% avg_auc=79.35%
Best model saved!! Metric=-29.647034045940266!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.524049 Test loss=0.486281 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4874243140220642
[5/24] Train loss=0.4998072683811188
[10/24] Train loss=0.5114945769309998
[15/24] Train loss=0.5104649066925049
[20/24] Train loss=0.47686338424682617
Test set avg_accuracy=77.96% avg_sensitivity=57.84%, avg_specificity=85.14% avg_auc=81.59%
Best model saved!! Metric=-23.47064082944852!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.502698 Test loss=0.464950 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.46651867032051086
[5/24] Train loss=0.4788164794445038
[10/24] Train loss=0.49092552065849304
[15/24] Train loss=0.49260213971138
[20/24] Train loss=0.4520587623119354
Test set avg_accuracy=78.32% avg_sensitivity=56.36%, avg_specificity=86.16% avg_auc=82.26%
Best model saved!! Metric=-22.897232312863053!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.484222 Test loss=0.453706 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4453953802585602
[5/24] Train loss=0.4586217701435089
[10/24] Train loss=0.4771614670753479
[15/24] Train loss=0.47693660855293274
[20/24] Train loss=0.43957921862602234
Test set avg_accuracy=79.06% avg_sensitivity=56.46%, avg_specificity=87.14% avg_auc=83.19%
Best model saved!! Metric=-20.15299249753363!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.467077 Test loss=0.440144 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4333120286464691
[5/24] Train loss=0.44487830996513367
[10/24] Train loss=0.4660450220108032
[15/24] Train loss=0.46068060398101807
[20/24] Train loss=0.42245274782180786
Test set avg_accuracy=79.49% avg_sensitivity=56.36%, avg_specificity=87.75% avg_auc=84.40%
Best model saved!! Metric=-17.99308041362542!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.452994 Test loss=0.426547 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.41556093096733093
[5/24] Train loss=0.4369456171989441
[10/24] Train loss=0.44693875312805176
[15/24] Train loss=0.4548789858818054
[20/24] Train loss=0.4142073094844818
Test set avg_accuracy=79.97% avg_sensitivity=56.36%, avg_specificity=88.41% avg_auc=84.91%
Best model saved!! Metric=-16.34510447764093!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.440558 Test loss=0.416033 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4033206105232239
[5/24] Train loss=0.4163239896297455
[10/24] Train loss=0.4401451349258423
[15/24] Train loss=0.43697547912597656
[20/24] Train loss=0.40238451957702637
Test set avg_accuracy=81.02% avg_sensitivity=59.52%, avg_specificity=88.69% avg_auc=86.01%
Best model saved!! Metric=-10.760700958597482!!
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.427250 Test loss=0.404827 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.38859787583351135
[5/24] Train loss=0.40588346123695374
[10/24] Train loss=0.42122682929039
[15/24] Train loss=0.43426406383514404
[20/24] Train loss=0.3912873864173889
Test set avg_accuracy=81.32% avg_sensitivity=61.95%, avg_specificity=88.23% avg_auc=86.74%
Best model saved!! Metric=-7.769171130030294!!
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.415589 Test loss=0.396949 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.37986651062965393
[5/24] Train loss=0.39708489179611206
[10/24] Train loss=0.4155620038509369
[15/24] Train loss=0.4275760352611542
[20/24] Train loss=0.38419368863105774
Test set avg_accuracy=82.46% avg_sensitivity=64.67%, avg_specificity=88.81% avg_auc=87.33%
Best model saved!! Metric=-2.7212368752797573!!
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.406630 Test loss=0.388873 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3700917363166809
[5/24] Train loss=0.38502031564712524
[10/24] Train loss=0.4048998951911926
[15/24] Train loss=0.41184261441230774
[20/24] Train loss=0.3752502202987671
Test set avg_accuracy=82.24% avg_sensitivity=65.22%, avg_specificity=88.32% avg_auc=87.65%
Best model saved!! Metric=-2.5713652163489797!!
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.395559 Test loss=0.386820 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3609001338481903
[5/24] Train loss=0.3848992884159088
[10/24] Train loss=0.38762763142585754
[15/24] Train loss=0.4080314338207245
[20/24] Train loss=0.366242378950119
Test set avg_accuracy=82.01% avg_sensitivity=68.28%, avg_specificity=86.91% avg_auc=87.53%
Best model saved!! Metric=-1.2753392025723542!!
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.388195 Test loss=0.390977 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3550797402858734
[5/24] Train loss=0.3671097755432129
[10/24] Train loss=0.38860833644866943
[15/24] Train loss=0.3939782679080963
[20/24] Train loss=0.36104464530944824
Test set avg_accuracy=81.63% avg_sensitivity=70.06%, avg_specificity=85.76% avg_auc=87.68%
Best model saved!! Metric=-0.8707386009459555!!
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.381132 Test loss=0.391412 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.34207361936569214
[5/24] Train loss=0.3727171719074249
[10/24] Train loss=0.3797594904899597
[15/24] Train loss=0.38581883907318115
[20/24] Train loss=0.354449599981308
Test set avg_accuracy=83.12% avg_sensitivity=68.09%, avg_specificity=88.50% avg_auc=88.20%
Best model saved!! Metric=1.9031769070981852!!
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.373374 Test loss=0.376810 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.337802529335022
[5/24] Train loss=0.3600698709487915
[10/24] Train loss=0.37332189083099365
[15/24] Train loss=0.376509428024292
[20/24] Train loss=0.34179192781448364
Test set avg_accuracy=82.46% avg_sensitivity=68.58%, avg_specificity=87.42% avg_auc=88.01%
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.365235 Test loss=0.379837 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3296031951904297
[5/24] Train loss=0.34865349531173706
[10/24] Train loss=0.3701331615447998
[15/24] Train loss=0.3758273720741272
[20/24] Train loss=0.32326236367225647
Test set avg_accuracy=82.12% avg_sensitivity=68.78%, avg_specificity=86.89% avg_auc=87.48%
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.359399 Test loss=0.387812 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3229305148124695
[5/24] Train loss=0.3454928994178772
[10/24] Train loss=0.36556801199913025
[15/24] Train loss=0.3658697307109833
[20/24] Train loss=0.3212708830833435
Test set avg_accuracy=83.62% avg_sensitivity=60.56%, avg_specificity=91.85% avg_auc=88.88%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.354081 Test loss=0.363685 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.31076279282569885
[5/24] Train loss=0.34510114789009094
[10/24] Train loss=0.36846187710762024
[15/24] Train loss=0.37708646059036255
[20/24] Train loss=0.32717135548591614
Test set avg_accuracy=81.65% avg_sensitivity=70.81%, avg_specificity=85.53% avg_auc=87.59%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.349746 Test loss=0.391239 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.32118716835975647
[5/24] Train loss=0.34711068868637085
[10/24] Train loss=0.3697364330291748
[15/24] Train loss=0.35774946212768555
[20/24] Train loss=0.31992751359939575
Test set avg_accuracy=83.37% avg_sensitivity=69.77%, avg_specificity=88.23% avg_auc=89.00%
Best model saved!! Metric=4.374285953496781!!
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.344271 Test loss=0.365907 Current lr=[0.000210185142098938]

[0/24] Train loss=0.31022828817367554
[5/24] Train loss=0.34073346853256226
[10/24] Train loss=0.35842767357826233
[15/24] Train loss=0.3512630760669708
[20/24] Train loss=0.31918007135391235
Test set avg_accuracy=84.01% avg_sensitivity=68.04%, avg_specificity=89.72% avg_auc=89.38%
Best model saved!! Metric=5.139256200037735!!
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.339027 Test loss=0.356951 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.31303340196609497
[5/24] Train loss=0.3399319648742676
[10/24] Train loss=0.3547484874725342
[15/24] Train loss=0.35541561245918274
[20/24] Train loss=0.3094486892223358
Test set avg_accuracy=81.88% avg_sensitivity=70.21%, avg_specificity=86.04% avg_auc=87.59%
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.336445 Test loss=0.388574 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3048688471317291
[5/24] Train loss=0.33558735251426697
[10/24] Train loss=0.34898626804351807
[15/24] Train loss=0.34363821148872375
[20/24] Train loss=0.30978190898895264
Test set avg_accuracy=83.91% avg_sensitivity=60.96%, avg_specificity=92.10% avg_auc=88.31%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.330865 Test loss=0.369768 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3002564311027527
[5/24] Train loss=0.3249165117740631
[10/24] Train loss=0.3458996117115021
[15/24] Train loss=0.34544578194618225
[20/24] Train loss=0.3003379702568054
Test set avg_accuracy=84.39% avg_sensitivity=63.43%, avg_specificity=91.87% avg_auc=90.25%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.325460 Test loss=0.343888 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2843417823314667
[5/24] Train loss=0.3168054223060608
[10/24] Train loss=0.34423232078552246
[15/24] Train loss=0.33539390563964844
[20/24] Train loss=0.2937537133693695
Test set avg_accuracy=84.24% avg_sensitivity=62.39%, avg_specificity=92.05% avg_auc=90.08%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.322211 Test loss=0.347380 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.28498923778533936
[5/24] Train loss=0.31123313307762146
[10/24] Train loss=0.3421162962913513
[15/24] Train loss=0.3293858468532562
[20/24] Train loss=0.28796765208244324
Test set avg_accuracy=84.10% avg_sensitivity=58.88%, avg_specificity=93.11% avg_auc=90.33%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.316765 Test loss=0.346573 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.28786298632621765
[5/24] Train loss=0.31258732080459595
[10/24] Train loss=0.3425729274749756
[15/24] Train loss=0.3229578733444214
[20/24] Train loss=0.2869066596031189
Test set avg_accuracy=83.27% avg_sensitivity=53.19%, avg_specificity=94.01% avg_auc=89.39%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.315265 Test loss=0.364889 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.29520803689956665
[5/24] Train loss=0.31534820795059204
[10/24] Train loss=0.34799933433532715
[15/24] Train loss=0.32756680250167847
[20/24] Train loss=0.28827497363090515
Test set avg_accuracy=84.91% avg_sensitivity=66.25%, avg_specificity=91.57% avg_auc=90.62%
Best model saved!! Metric=7.354722819709721!!
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.314293 Test loss=0.337914 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2799570560455322
[5/24] Train loss=0.30103519558906555
[10/24] Train loss=0.34447282552719116
[15/24] Train loss=0.33045879006385803
[20/24] Train loss=0.2841232419013977
Test set avg_accuracy=85.09% avg_sensitivity=67.00%, avg_specificity=91.55% avg_auc=90.97%
Best model saved!! Metric=8.61076397257618!!
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.310011 Test loss=0.331455 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2763005793094635
[5/24] Train loss=0.2982783019542694
[10/24] Train loss=0.32410383224487305
[15/24] Train loss=0.31935131549835205
[20/24] Train loss=0.27801913022994995
Test set avg_accuracy=84.87% avg_sensitivity=65.17%, avg_specificity=91.91% avg_auc=90.85%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.305562 Test loss=0.334877 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.28145521879196167
[5/24] Train loss=0.302996963262558
[10/24] Train loss=0.3317892253398895
[15/24] Train loss=0.318838894367218
[20/24] Train loss=0.28054100275039673
Test set avg_accuracy=84.57% avg_sensitivity=55.67%, avg_specificity=94.89% avg_auc=90.66%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.303105 Test loss=0.347228 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2739083170890808
[5/24] Train loss=0.30223092436790466
[10/24] Train loss=0.3322671949863434
[15/24] Train loss=0.3180386424064636
[20/24] Train loss=0.26939356327056885
Test set avg_accuracy=85.34% avg_sensitivity=66.25%, avg_specificity=92.15% avg_auc=90.56%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.301133 Test loss=0.336422 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2633391320705414
[5/24] Train loss=0.2896142601966858
[10/24] Train loss=0.3206680417060852
[15/24] Train loss=0.3069116175174713
[20/24] Train loss=0.27345457673072815
Test set avg_accuracy=85.27% avg_sensitivity=61.45%, avg_specificity=93.78% avg_auc=91.24%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.298214 Test loss=0.328192 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2745552062988281
[5/24] Train loss=0.2980160117149353
[10/24] Train loss=0.3217850625514984
[15/24] Train loss=0.30869677662849426
[20/24] Train loss=0.2734919488430023
Test set avg_accuracy=85.42% avg_sensitivity=57.64%, avg_specificity=95.33% avg_auc=91.46%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.295422 Test loss=0.331121 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2670344114303589
[5/24] Train loss=0.2829782962799072
[10/24] Train loss=0.3250676989555359
[15/24] Train loss=0.30840566754341125
[20/24] Train loss=0.2631337344646454
Test set avg_accuracy=85.56% avg_sensitivity=62.10%, avg_specificity=93.94% avg_auc=91.58%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.291850 Test loss=0.324435 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.260229229927063
[5/24] Train loss=0.2871457040309906
[10/24] Train loss=0.32375338673591614
[15/24] Train loss=0.30945271253585815
[20/24] Train loss=0.26468363404273987
Test set avg_accuracy=85.33% avg_sensitivity=68.18%, avg_specificity=91.45% avg_auc=91.02%
Best model saved!! Metric=9.97973569112753!!
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.289290 Test loss=0.332673 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2558174133300781
[5/24] Train loss=0.2808457016944885
[10/24] Train loss=0.31361880898475647
[15/24] Train loss=0.3089974820613861
[20/24] Train loss=0.2654340863227844
Test set avg_accuracy=84.60% avg_sensitivity=64.47%, avg_specificity=91.78% avg_auc=90.79%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.286775 Test loss=0.336923 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.25537940859794617
[5/24] Train loss=0.279006689786911
[10/24] Train loss=0.32655033469200134
[15/24] Train loss=0.31411921977996826
[20/24] Train loss=0.2634274363517761
Test set avg_accuracy=84.30% avg_sensitivity=56.16%, avg_specificity=94.35% avg_auc=90.18%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.286035 Test loss=0.347060 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.26303011178970337
[5/24] Train loss=0.2867879569530487
[10/24] Train loss=0.3227350413799286
[15/24] Train loss=0.2985880374908447
[20/24] Train loss=0.25804638862609863
Test set avg_accuracy=85.81% avg_sensitivity=62.74%, avg_specificity=94.04% avg_auc=91.48%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.289139 Test loss=0.324392 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2577025592327118
[5/24] Train loss=0.2787429988384247
[10/24] Train loss=0.30720749497413635
[15/24] Train loss=0.3035919964313507
[20/24] Train loss=0.2612905204296112
Test set avg_accuracy=85.22% avg_sensitivity=66.60%, avg_specificity=91.87% avg_auc=90.76%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.283469 Test loss=0.331752 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.25517216324806213
[5/24] Train loss=0.2873285412788391
[10/24] Train loss=0.3145446181297302
[15/24] Train loss=0.2989260256290436
[20/24] Train loss=0.2609994113445282
Test set avg_accuracy=86.07% avg_sensitivity=68.13%, avg_specificity=92.47% avg_auc=91.58%
Best model saved!! Metric=12.25435710927573!!
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.282909 Test loss=0.320450 Current lr=[0.000298904600941902]

[0/24] Train loss=0.250046968460083
[5/24] Train loss=0.2719585597515106
[10/24] Train loss=0.2954075336456299
[15/24] Train loss=0.3131825625896454
[20/24] Train loss=0.2596019506454468
Test set avg_accuracy=84.84% avg_sensitivity=73.28%, avg_specificity=88.97% avg_auc=91.17%
Best model saved!! Metric=12.267279001326344!!
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.281600 Test loss=0.336205 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2483382672071457
[5/24] Train loss=0.2737691402435303
[10/24] Train loss=0.3158945143222809
[15/24] Train loss=0.29422464966773987
[20/24] Train loss=0.2501763701438904
Test set avg_accuracy=85.08% avg_sensitivity=59.48%, avg_specificity=94.22% avg_auc=89.86%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.278809 Test loss=0.346003 Current lr=[0.000297555943323901]

[0/24] Train loss=0.25489744544029236
[5/24] Train loss=0.2892976999282837
[10/24] Train loss=0.3079279363155365
[15/24] Train loss=0.2952120304107666
[20/24] Train loss=0.24517643451690674
Test set avg_accuracy=84.83% avg_sensitivity=57.74%, avg_specificity=94.50% avg_auc=90.14%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.279611 Test loss=0.344265 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.26188960671424866
[5/24] Train loss=0.27614423632621765
[10/24] Train loss=0.29372987151145935
[15/24] Train loss=0.291920006275177
[20/24] Train loss=0.2507651150226593
Test set avg_accuracy=83.76% avg_sensitivity=51.11%, avg_specificity=95.42% avg_auc=89.21%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.275352 Test loss=0.359828 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.25271889567375183
[5/24] Train loss=0.2689647078514099
[10/24] Train loss=0.29440760612487793
[15/24] Train loss=0.2928489148616791
[20/24] Train loss=0.24057474732398987
Test set avg_accuracy=85.96% avg_sensitivity=68.38%, avg_specificity=92.24% avg_auc=90.44%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.271240 Test loss=0.330071 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.25588542222976685
[5/24] Train loss=0.27560609579086304
[10/24] Train loss=0.2924492657184601
[15/24] Train loss=0.294994056224823
[20/24] Train loss=0.25643670558929443
Test set avg_accuracy=86.41% avg_sensitivity=65.96%, avg_specificity=93.71% avg_auc=90.32%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.272995 Test loss=0.333153 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.24879108369350433
[5/24] Train loss=0.27201366424560547
[10/24] Train loss=0.29677271842956543
[15/24] Train loss=0.2913840115070343
[20/24] Train loss=0.2472265064716339
Test set avg_accuracy=85.96% avg_sensitivity=61.80%, avg_specificity=94.59% avg_auc=90.86%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.271281 Test loss=0.329857 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.2503012418746948
[5/24] Train loss=0.26366162300109863
[10/24] Train loss=0.28582772612571716
[15/24] Train loss=0.2885779142379761
[20/24] Train loss=0.254203200340271
Test set avg_accuracy=83.15% avg_sensitivity=48.69%, avg_specificity=95.46% avg_auc=88.07%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.267587 Test loss=0.381242 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.24901705980300903
[5/24] Train loss=0.2640579044818878
[10/24] Train loss=0.2908709645271301
[15/24] Train loss=0.28583553433418274
[20/24] Train loss=0.24689577519893646
Test set avg_accuracy=84.53% avg_sensitivity=57.84%, avg_specificity=94.06% avg_auc=89.47%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.268359 Test loss=0.352559 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.24416711926460266
[5/24] Train loss=0.2654722332954407
[10/24] Train loss=0.29215818643569946
[15/24] Train loss=0.2826739251613617
[20/24] Train loss=0.23735448718070984
Test set avg_accuracy=83.96% avg_sensitivity=49.53%, avg_specificity=96.25% avg_auc=88.43%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.266878 Test loss=0.371787 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2390560656785965
[5/24] Train loss=0.2546144723892212
[10/24] Train loss=0.2949341833591461
[15/24] Train loss=0.2945147752761841
[20/24] Train loss=0.24162602424621582
Test set avg_accuracy=85.51% avg_sensitivity=63.14%, avg_specificity=93.50% avg_auc=90.46%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.262908 Test loss=0.333033 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.23778407275676727
[5/24] Train loss=0.258160799741745
[10/24] Train loss=0.2773955464363098
[15/24] Train loss=0.2811748683452606
[20/24] Train loss=0.2437954992055893
Test set avg_accuracy=85.66% avg_sensitivity=67.59%, avg_specificity=92.12% avg_auc=90.57%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.259458 Test loss=0.330863 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.23027443885803223
[5/24] Train loss=0.26419395208358765
[10/24] Train loss=0.2838095426559448
[15/24] Train loss=0.2773222029209137
[20/24] Train loss=0.2417486011981964
Test set avg_accuracy=86.02% avg_sensitivity=66.60%, avg_specificity=92.95% avg_auc=89.98%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.260637 Test loss=0.336052 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2502126395702362
[5/24] Train loss=0.26370716094970703
[10/24] Train loss=0.28335392475128174
[15/24] Train loss=0.276753693819046
[20/24] Train loss=0.23123058676719666
Test set avg_accuracy=84.73% avg_sensitivity=61.06%, avg_specificity=93.18% avg_auc=89.24%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.259219 Test loss=0.347618 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2374221533536911
[5/24] Train loss=0.2648705244064331
[10/24] Train loss=0.2750784158706665
[15/24] Train loss=0.2803844213485718
[20/24] Train loss=0.2339606136083603
Test set avg_accuracy=85.23% avg_sensitivity=60.47%, avg_specificity=94.08% avg_auc=89.60%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.257373 Test loss=0.344088 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2421284317970276
[5/24] Train loss=0.2527587115764618
[10/24] Train loss=0.2739478051662445
[15/24] Train loss=0.29079657793045044
[20/24] Train loss=0.23775912821292877
Test set avg_accuracy=84.21% avg_sensitivity=61.26%, avg_specificity=92.40% avg_auc=87.90%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.257607 Test loss=0.368207 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.23962947726249695
[5/24] Train loss=0.2559582591056824
[10/24] Train loss=0.277527391910553
[15/24] Train loss=0.2734777331352234
[20/24] Train loss=0.22898544371128082
Test set avg_accuracy=85.05% avg_sensitivity=60.76%, avg_specificity=93.73% avg_auc=88.62%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.254507 Test loss=0.354164 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2284483015537262
[5/24] Train loss=0.2399795949459076
[10/24] Train loss=0.2780471742153168
[15/24] Train loss=0.2660396099090576
[20/24] Train loss=0.24181315302848816
Test set avg_accuracy=83.28% avg_sensitivity=47.60%, avg_specificity=96.02% avg_auc=87.58%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.255146 Test loss=0.386689 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2346283197402954
[5/24] Train loss=0.24881413578987122
[10/24] Train loss=0.2715511918067932
[15/24] Train loss=0.2713208794593811
[20/24] Train loss=0.23143412172794342
Test set avg_accuracy=86.13% avg_sensitivity=68.58%, avg_specificity=92.40% avg_auc=89.95%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.250516 Test loss=0.336205 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.22416093945503235
[5/24] Train loss=0.24439027905464172
[10/24] Train loss=0.2764945924282074
[15/24] Train loss=0.2582590579986572
[20/24] Train loss=0.23264281451702118
Test set avg_accuracy=84.62% avg_sensitivity=65.81%, avg_specificity=91.34% avg_auc=88.91%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.247632 Test loss=0.355991 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2258223444223404
[5/24] Train loss=0.24901843070983887
[10/24] Train loss=0.26629406213760376
[15/24] Train loss=0.26518142223358154
[20/24] Train loss=0.23380914330482483
Test set avg_accuracy=84.97% avg_sensitivity=62.35%, avg_specificity=93.06% avg_auc=89.16%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.246921 Test loss=0.348077 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.23616306483745575
[5/24] Train loss=0.24397164583206177
[10/24] Train loss=0.27367937564849854
[15/24] Train loss=0.26272913813591003
[20/24] Train loss=0.2369922250509262
Test set avg_accuracy=84.65% avg_sensitivity=61.75%, avg_specificity=92.83% avg_auc=88.07%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.244915 Test loss=0.367004 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.22313404083251953
[5/24] Train loss=0.23790757358074188
[10/24] Train loss=0.2671491503715515
[15/24] Train loss=0.27300137281417847
[20/24] Train loss=0.2289903163909912
Test set avg_accuracy=84.28% avg_sensitivity=55.67%, avg_specificity=94.50% avg_auc=87.67%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.243592 Test loss=0.375831 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.22526004910469055
[5/24] Train loss=0.23753125965595245
[10/24] Train loss=0.263227641582489
[15/24] Train loss=0.2721502184867859
[20/24] Train loss=0.22560353577136993
Test set avg_accuracy=85.12% avg_sensitivity=59.77%, avg_specificity=94.17% avg_auc=88.71%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.244613 Test loss=0.351256 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.22317366302013397
[5/24] Train loss=0.2471153885126114
[10/24] Train loss=0.2648056745529175
[15/24] Train loss=0.26026883721351624
[20/24] Train loss=0.22948098182678223
Test set avg_accuracy=85.18% avg_sensitivity=75.75%, avg_specificity=88.55% avg_auc=90.69%
Best model saved!! Metric=14.172818332295165!!
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.245987 Test loss=0.341453 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.21902453899383545
[5/24] Train loss=0.2430763989686966
[10/24] Train loss=0.26454979181289673
[15/24] Train loss=0.26046958565711975
[20/24] Train loss=0.2196234166622162
Test set avg_accuracy=84.64% avg_sensitivity=63.88%, avg_specificity=92.05% avg_auc=88.13%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.241079 Test loss=0.360722 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.22526879608631134
[5/24] Train loss=0.23896454274654388
[10/24] Train loss=0.2706315517425537
[15/24] Train loss=0.25612300634384155
[20/24] Train loss=0.22421297430992126
Test set avg_accuracy=83.42% avg_sensitivity=64.87%, avg_specificity=90.05% avg_auc=86.13%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.239556 Test loss=0.392886 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.21892224252223969
[5/24] Train loss=0.23606130480766296
[10/24] Train loss=0.2517133355140686
[15/24] Train loss=0.25855937600135803
[20/24] Train loss=0.22386017441749573
Test set avg_accuracy=84.09% avg_sensitivity=66.95%, avg_specificity=90.21% avg_auc=87.79%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.240233 Test loss=0.367305 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.22011317312717438
[5/24] Train loss=0.22671033442020416
[10/24] Train loss=0.251498818397522
[15/24] Train loss=0.2515423595905304
[20/24] Train loss=0.2276376485824585
Test set avg_accuracy=84.00% avg_sensitivity=73.63%, avg_specificity=87.70% avg_auc=89.09%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.235855 Test loss=0.365498 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2210410237312317
[5/24] Train loss=0.22847039997577667
[10/24] Train loss=0.2652779221534729
[15/24] Train loss=0.2602742612361908
[20/24] Train loss=0.22144798934459686
Test set avg_accuracy=84.06% avg_sensitivity=78.97%, avg_specificity=85.88% avg_auc=90.47%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.235881 Test loss=0.365148 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.21790477633476257
[5/24] Train loss=0.21860432624816895
[10/24] Train loss=0.2580927014350891
[15/24] Train loss=0.2423737347126007
[20/24] Train loss=0.2267715185880661
Test set avg_accuracy=85.73% avg_sensitivity=71.94%, avg_specificity=90.65% avg_auc=90.55%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.231581 Test loss=0.338033 Current lr=[0.000224838296036774]

[0/24] Train loss=0.20765891671180725
[5/24] Train loss=0.22095979750156403
[10/24] Train loss=0.2767593562602997
[15/24] Train loss=0.2482619732618332
[20/24] Train loss=0.2164272665977478
Test set avg_accuracy=84.73% avg_sensitivity=75.36%, avg_specificity=88.07% avg_auc=90.31%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.231282 Test loss=0.349069 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.20635949075222015
[5/24] Train loss=0.22066040337085724
[10/24] Train loss=0.2570340931415558
[15/24] Train loss=0.24668818712234497
[20/24] Train loss=0.2183438092470169
Test set avg_accuracy=84.95% avg_sensitivity=73.28%, avg_specificity=89.11% avg_auc=89.50%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.227929 Test loss=0.357216 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2004571110010147
[5/24] Train loss=0.21468432247638702
[10/24] Train loss=0.24568124115467072
[15/24] Train loss=0.24385510385036469
[20/24] Train loss=0.22187411785125732
Test set avg_accuracy=84.48% avg_sensitivity=71.90%, avg_specificity=88.97% avg_auc=89.75%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.223853 Test loss=0.353510 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.20053339004516602
[5/24] Train loss=0.20685890316963196
[10/24] Train loss=0.25572407245635986
[15/24] Train loss=0.24061304330825806
[20/24] Train loss=0.2310023307800293
Test set avg_accuracy=85.61% avg_sensitivity=73.38%, avg_specificity=89.98% avg_auc=90.20%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.225076 Test loss=0.343612 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.19146639108657837
[5/24] Train loss=0.20241746306419373
[10/24] Train loss=0.2431367039680481
[15/24] Train loss=0.23066578805446625
[20/24] Train loss=0.21298088133335114
Test set avg_accuracy=85.55% avg_sensitivity=62.69%, avg_specificity=93.71% avg_auc=88.57%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.220043 Test loss=0.361355 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2059810310602188
[5/24] Train loss=0.217475026845932
[10/24] Train loss=0.23975400626659393
[15/24] Train loss=0.2352740466594696
[20/24] Train loss=0.20338287949562073
Test set avg_accuracy=84.96% avg_sensitivity=73.33%, avg_specificity=89.11% avg_auc=89.59%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.218691 Test loss=0.356636 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.19377830624580383
[5/24] Train loss=0.2092922329902649
[10/24] Train loss=0.24019913375377655
[15/24] Train loss=0.22862355411052704
[20/24] Train loss=0.21408303081989288
Test set avg_accuracy=85.34% avg_sensitivity=68.58%, avg_specificity=91.32% avg_auc=89.36%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.219751 Test loss=0.350450 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1938464641571045
[5/24] Train loss=0.20594392716884613
[10/24] Train loss=0.24053998291492462
[15/24] Train loss=0.23862236738204956
[20/24] Train loss=0.21960540115833282
Test set avg_accuracy=83.63% avg_sensitivity=75.11%, avg_specificity=86.68% avg_auc=88.89%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.219552 Test loss=0.377631 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.19074507057666779
[5/24] Train loss=0.19832247495651245
[10/24] Train loss=0.25407543778419495
[15/24] Train loss=0.23572027683258057
[20/24] Train loss=0.2199295312166214
Test set avg_accuracy=85.07% avg_sensitivity=75.46%, avg_specificity=88.50% avg_auc=90.32%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.217722 Test loss=0.351858 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.18996484577655792
[5/24] Train loss=0.1990184634923935
[10/24] Train loss=0.23797300457954407
[15/24] Train loss=0.22425919771194458
[20/24] Train loss=0.2074936181306839
Test set avg_accuracy=85.56% avg_sensitivity=70.91%, avg_specificity=90.79% avg_auc=90.49%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.213738 Test loss=0.340545 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.19574451446533203
[5/24] Train loss=0.20062695443630219
[10/24] Train loss=0.23821309208869934
[15/24] Train loss=0.22361961007118225
[20/24] Train loss=0.20125921070575714
Test set avg_accuracy=84.83% avg_sensitivity=73.87%, avg_specificity=88.74% avg_auc=89.95%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.211809 Test loss=0.351724 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.1975955367088318
[5/24] Train loss=0.19208091497421265
[10/24] Train loss=0.23327460885047913
[15/24] Train loss=0.217881977558136
[20/24] Train loss=0.19870367646217346
Test set avg_accuracy=84.77% avg_sensitivity=68.13%, avg_specificity=90.71% avg_auc=89.88%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.207310 Test loss=0.349943 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.18824170529842377
[5/24] Train loss=0.20119401812553406
[10/24] Train loss=0.22269462049007416
[15/24] Train loss=0.22456517815589905
[20/24] Train loss=0.20644697546958923
Test set avg_accuracy=85.09% avg_sensitivity=75.46%, avg_specificity=88.53% avg_auc=90.05%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.205563 Test loss=0.356641 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.18541063368320465
[5/24] Train loss=0.1912471204996109
[10/24] Train loss=0.2308506816625595
[15/24] Train loss=0.21734122931957245
[20/24] Train loss=0.20770838856697083
Test set avg_accuracy=84.88% avg_sensitivity=69.77%, avg_specificity=90.28% avg_auc=89.15%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.204372 Test loss=0.356646 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.19170109927654266
[5/24] Train loss=0.18382906913757324
[10/24] Train loss=0.21265171468257904
[15/24] Train loss=0.21650737524032593
[20/24] Train loss=0.20116835832595825
Test set avg_accuracy=85.12% avg_sensitivity=71.15%, avg_specificity=90.10% avg_auc=89.81%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.198618 Test loss=0.351898 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.17544512450695038
[5/24] Train loss=0.17333543300628662
[10/24] Train loss=0.22329629957675934
[15/24] Train loss=0.214142307639122
[20/24] Train loss=0.19582416117191315
Test set avg_accuracy=84.92% avg_sensitivity=72.24%, avg_specificity=89.45% avg_auc=90.06%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.196445 Test loss=0.349462 Current lr=[0.000156543481933168]

[0/24] Train loss=0.18550467491149902
[5/24] Train loss=0.18915079534053802
[10/24] Train loss=0.20977900922298431
[15/24] Train loss=0.20382247865200043
[20/24] Train loss=0.19574759900569916
Test set avg_accuracy=85.13% avg_sensitivity=71.60%, avg_specificity=89.96% avg_auc=89.97%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.195693 Test loss=0.350259 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.18379329144954681
[5/24] Train loss=0.18740391731262207
[10/24] Train loss=0.22632886469364166
[15/24] Train loss=0.1952894628047943
[20/24] Train loss=0.20264983177185059
Test set avg_accuracy=85.00% avg_sensitivity=76.00%, avg_specificity=88.21% avg_auc=89.90%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.194877 Test loss=0.355955 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.180238276720047
[5/24] Train loss=0.17257821559906006
[10/24] Train loss=0.2162596434354782
[15/24] Train loss=0.20499393343925476
[20/24] Train loss=0.20037168264389038
Test set avg_accuracy=84.67% avg_sensitivity=72.04%, avg_specificity=89.19% avg_auc=89.94%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.194539 Test loss=0.354530 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.1728045642375946
[5/24] Train loss=0.1771335005760193
[10/24] Train loss=0.2125900834798813
[15/24] Train loss=0.2127644270658493
[20/24] Train loss=0.1881624311208725
Test set avg_accuracy=84.34% avg_sensitivity=72.64%, avg_specificity=88.51% avg_auc=89.14%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.192298 Test loss=0.368012 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.17856499552726746
[5/24] Train loss=0.17129330337047577
[10/24] Train loss=0.21993184089660645
[15/24] Train loss=0.21740685403347015
[20/24] Train loss=0.18485048413276672
Test set avg_accuracy=84.83% avg_sensitivity=71.30%, avg_specificity=89.66% avg_auc=89.56%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.193582 Test loss=0.364963 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1770787388086319
[5/24] Train loss=0.18290893733501434
[10/24] Train loss=0.21634811162948608
[15/24] Train loss=0.20107556879520416
[20/24] Train loss=0.19110020995140076
Test set avg_accuracy=84.93% avg_sensitivity=75.90%, avg_specificity=88.16% avg_auc=90.00%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.192058 Test loss=0.357767 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.17462413012981415
[5/24] Train loss=0.1711089164018631
[10/24] Train loss=0.20780040323734283
[15/24] Train loss=0.20198559761047363
[20/24] Train loss=0.1895020455121994
Test set avg_accuracy=84.91% avg_sensitivity=71.99%, avg_specificity=89.52% avg_auc=89.69%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.188945 Test loss=0.356277 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.17379093170166016
[5/24] Train loss=0.17506390810012817
[10/24] Train loss=0.20392966270446777
[15/24] Train loss=0.19582144916057587
[20/24] Train loss=0.18171213567256927
Test set avg_accuracy=83.92% avg_sensitivity=74.67%, avg_specificity=87.22% avg_auc=89.47%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.186016 Test loss=0.372787 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.17251664400100708
[5/24] Train loss=0.166688472032547
[10/24] Train loss=0.1991739720106125
[15/24] Train loss=0.19752757251262665
[20/24] Train loss=0.18396595120429993
Test set avg_accuracy=84.40% avg_sensitivity=74.37%, avg_specificity=87.98% avg_auc=89.46%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.183738 Test loss=0.364725 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1679587960243225
[5/24] Train loss=0.16588707268238068
[10/24] Train loss=0.20575489103794098
[15/24] Train loss=0.20131292939186096
[20/24] Train loss=0.18999409675598145
Test set avg_accuracy=84.62% avg_sensitivity=74.22%, avg_specificity=88.34% avg_auc=89.39%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.187210 Test loss=0.366185 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.17681872844696045
[5/24] Train loss=0.17126013338565826
[10/24] Train loss=0.20614252984523773
[15/24] Train loss=0.19470526278018951
[20/24] Train loss=0.18711712956428528
Test set avg_accuracy=85.21% avg_sensitivity=73.03%, avg_specificity=89.56% avg_auc=89.78%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.185819 Test loss=0.355547 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.16631142795085907
[5/24] Train loss=0.16589492559432983
[10/24] Train loss=0.20846864581108093
[15/24] Train loss=0.19459868967533112
[20/24] Train loss=0.18619650602340698
Test set avg_accuracy=84.35% avg_sensitivity=74.42%, avg_specificity=87.90% avg_auc=89.56%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.182680 Test loss=0.371316 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.16561686992645264
[5/24] Train loss=0.16959407925605774
[10/24] Train loss=0.20557905733585358
[15/24] Train loss=0.19813328981399536
[20/24] Train loss=0.17924058437347412
Test set avg_accuracy=84.93% avg_sensitivity=73.92%, avg_specificity=88.87% avg_auc=89.59%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.180714 Test loss=0.364435 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.15624171495437622
[5/24] Train loss=0.16848182678222656
[10/24] Train loss=0.19801762700080872
[15/24] Train loss=0.19027474522590637
[20/24] Train loss=0.18284223973751068
Test set avg_accuracy=84.38% avg_sensitivity=76.40%, avg_specificity=87.22% avg_auc=89.59%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.178971 Test loss=0.372727 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.17026813328266144
[5/24] Train loss=0.17179051041603088
[10/24] Train loss=0.20043933391571045
[15/24] Train loss=0.19983042776584625
[20/24] Train loss=0.17958536744117737
Test set avg_accuracy=84.23% avg_sensitivity=70.16%, avg_specificity=89.26% avg_auc=88.86%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.183105 Test loss=0.376763 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1553412228822708
[5/24] Train loss=0.16341689229011536
[10/24] Train loss=0.20702208578586578
[15/24] Train loss=0.19068863987922668
[20/24] Train loss=0.18131078779697418
Test set avg_accuracy=85.09% avg_sensitivity=74.52%, avg_specificity=88.87% avg_auc=89.88%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.178218 Test loss=0.352399 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.16517941653728485
[5/24] Train loss=0.16701143980026245
[10/24] Train loss=0.2003241926431656
[15/24] Train loss=0.18086566030979156
[20/24] Train loss=0.1760048270225525
Test set avg_accuracy=84.38% avg_sensitivity=65.31%, avg_specificity=91.18% avg_auc=88.77%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.174807 Test loss=0.367686 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.15704406797885895
[5/24] Train loss=0.1556306630373001
[10/24] Train loss=0.19505645334720612
[15/24] Train loss=0.17820334434509277
[20/24] Train loss=0.17648831009864807
Test set avg_accuracy=84.91% avg_sensitivity=67.74%, avg_specificity=91.04% avg_auc=89.33%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.171614 Test loss=0.359389 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.15587322413921356
[5/24] Train loss=0.15665662288665771
[10/24] Train loss=0.19249796867370605
[15/24] Train loss=0.17463146150112152
[20/24] Train loss=0.1747773289680481
Test set avg_accuracy=84.71% avg_sensitivity=67.64%, avg_specificity=90.81% avg_auc=88.85%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.170104 Test loss=0.365318 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15810468792915344
[5/24] Train loss=0.15555889904499054
[10/24] Train loss=0.1914573758840561
[15/24] Train loss=0.17557235062122345
[20/24] Train loss=0.17372271418571472
Test set avg_accuracy=84.69% avg_sensitivity=67.59%, avg_specificity=90.79% avg_auc=89.11%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.169288 Test loss=0.362963 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.158090278506279
[5/24] Train loss=0.15177024900913239
[10/24] Train loss=0.19641812145709991
[15/24] Train loss=0.17070794105529785
[20/24] Train loss=0.16747385263442993
Test set avg_accuracy=84.27% avg_sensitivity=67.49%, avg_specificity=90.26% avg_auc=88.82%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.167749 Test loss=0.366444 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.15522652864456177
[5/24] Train loss=0.15291471779346466
[10/24] Train loss=0.1887693852186203
[15/24] Train loss=0.1711171269416809
[20/24] Train loss=0.16582269966602325
Test set avg_accuracy=84.91% avg_sensitivity=70.66%, avg_specificity=90.00% avg_auc=89.22%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.166407 Test loss=0.363617 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.15879042446613312
[5/24] Train loss=0.15068195760250092
[10/24] Train loss=0.1836950033903122
[15/24] Train loss=0.1726299375295639
[20/24] Train loss=0.16801567375659943
Test set avg_accuracy=85.05% avg_sensitivity=72.49%, avg_specificity=89.54% avg_auc=89.34%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.165633 Test loss=0.364055 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.15009991824626923
[5/24] Train loss=0.1498587280511856
[10/24] Train loss=0.1790805608034134
[15/24] Train loss=0.17458286881446838
[20/24] Train loss=0.164761021733284
Test set avg_accuracy=84.43% avg_sensitivity=73.13%, avg_specificity=88.46% avg_auc=89.56%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.163387 Test loss=0.365534 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.15183517336845398
[5/24] Train loss=0.15051476657390594
[10/24] Train loss=0.1801234781742096
[15/24] Train loss=0.17643508315086365
[20/24] Train loss=0.16937491297721863
Test set avg_accuracy=84.56% avg_sensitivity=73.48%, avg_specificity=88.51% avg_auc=89.58%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.162568 Test loss=0.362221 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.15299092233181
[5/24] Train loss=0.14846815168857574
[10/24] Train loss=0.17893420159816742
[15/24] Train loss=0.16976530849933624
[20/24] Train loss=0.16536979377269745
Test set avg_accuracy=84.41% avg_sensitivity=73.13%, avg_specificity=88.44% avg_auc=89.63%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.160934 Test loss=0.361891 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14949975907802582
[5/24] Train loss=0.14984026551246643
[10/24] Train loss=0.17851561307907104
[15/24] Train loss=0.1741052269935608
[20/24] Train loss=0.16458798944950104
Test set avg_accuracy=84.70% avg_sensitivity=73.82%, avg_specificity=88.58% avg_auc=89.67%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.160851 Test loss=0.360791 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.14700502157211304
[5/24] Train loss=0.14402486383914948
[10/24] Train loss=0.17206008732318878
[15/24] Train loss=0.17070317268371582
[20/24] Train loss=0.16539046168327332
Test set avg_accuracy=84.47% avg_sensitivity=73.48%, avg_specificity=88.39% avg_auc=89.71%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.159330 Test loss=0.361615 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.145987868309021
[5/24] Train loss=0.14590895175933838
[10/24] Train loss=0.17202700674533844
[15/24] Train loss=0.1646464318037033
[20/24] Train loss=0.16970375180244446
Test set avg_accuracy=84.82% avg_sensitivity=72.39%, avg_specificity=89.26% avg_auc=89.80%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.159314 Test loss=0.358144 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.14151239395141602
[5/24] Train loss=0.14323070645332336
[10/24] Train loss=0.17173238098621368
[15/24] Train loss=0.16286946833133698
[20/24] Train loss=0.16448631882667542
Test set avg_accuracy=84.23% avg_sensitivity=71.75%, avg_specificity=88.69% avg_auc=89.51%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.157186 Test loss=0.365174 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1455613523721695
[5/24] Train loss=0.14388948678970337
[10/24] Train loss=0.17452828586101532
[15/24] Train loss=0.16165785491466522
[20/24] Train loss=0.15855100750923157
Test set avg_accuracy=84.00% avg_sensitivity=70.36%, avg_specificity=88.87% avg_auc=89.11%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.157526 Test loss=0.369651 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.14840467274188995
[5/24] Train loss=0.14944925904273987
[10/24] Train loss=0.17435933649539948
[15/24] Train loss=0.16328266263008118
[20/24] Train loss=0.16080813109874725
Test set avg_accuracy=84.61% avg_sensitivity=74.67%, avg_specificity=88.16% avg_auc=89.59%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.155968 Test loss=0.365729 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13879132270812988
[5/24] Train loss=0.1442272961139679
[10/24] Train loss=0.16810983419418335
[15/24] Train loss=0.16138382256031036
[20/24] Train loss=0.16099679470062256
Test set avg_accuracy=84.47% avg_sensitivity=71.85%, avg_specificity=88.97% avg_auc=89.46%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.154397 Test loss=0.363029 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1463879644870758
[5/24] Train loss=0.1399172693490982
[10/24] Train loss=0.16980524361133575
[15/24] Train loss=0.1622847020626068
[20/24] Train loss=0.15893568098545074
Test set avg_accuracy=84.43% avg_sensitivity=72.74%, avg_specificity=88.60% avg_auc=89.58%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.153479 Test loss=0.364354 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.14186277985572815
[5/24] Train loss=0.14190448820590973
[10/24] Train loss=0.16810742020606995
[15/24] Train loss=0.16057826578617096
[20/24] Train loss=0.15719197690486908
Test set avg_accuracy=84.41% avg_sensitivity=71.60%, avg_specificity=88.99% avg_auc=89.52%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.152722 Test loss=0.364690 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.14147083461284637
[5/24] Train loss=0.13948331773281097
[10/24] Train loss=0.1730084866285324
[15/24] Train loss=0.15919451415538788
[20/24] Train loss=0.15390390157699585
Test set avg_accuracy=84.27% avg_sensitivity=72.04%, avg_specificity=88.64% avg_auc=89.61%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.151910 Test loss=0.363836 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.143363356590271
[5/24] Train loss=0.14075867831707
[10/24] Train loss=0.16920194029808044
[15/24] Train loss=0.1604694426059723
[20/24] Train loss=0.15889304876327515
Test set avg_accuracy=84.18% avg_sensitivity=71.25%, avg_specificity=88.80% avg_auc=89.32%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.152804 Test loss=0.367042 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13831841945648193
[5/24] Train loss=0.14057643711566925
[10/24] Train loss=0.17193451523780823
[15/24] Train loss=0.16118130087852478
[20/24] Train loss=0.1593552678823471
Test set avg_accuracy=84.26% avg_sensitivity=71.85%, avg_specificity=88.69% avg_auc=89.35%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.152466 Test loss=0.368343 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13707494735717773
[5/24] Train loss=0.13797977566719055
[10/24] Train loss=0.16449590027332306
[15/24] Train loss=0.15811552107334137
[20/24] Train loss=0.15764722228050232
Test set avg_accuracy=84.52% avg_sensitivity=71.70%, avg_specificity=89.10% avg_auc=89.50%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.150562 Test loss=0.363983 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13827306032180786
[5/24] Train loss=0.13830339908599854
[10/24] Train loss=0.16727690398693085
[15/24] Train loss=0.15687479078769684
[20/24] Train loss=0.1582821011543274
Test set avg_accuracy=84.32% avg_sensitivity=72.69%, avg_specificity=88.48% avg_auc=89.63%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.150349 Test loss=0.362886 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1382659524679184
[5/24] Train loss=0.14272181689739227
[10/24] Train loss=0.1642054170370102
[15/24] Train loss=0.155309796333313
[20/24] Train loss=0.15543141961097717
Test set avg_accuracy=84.40% avg_sensitivity=71.70%, avg_specificity=88.94% avg_auc=89.42%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.150428 Test loss=0.364160 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.14187774062156677
[5/24] Train loss=0.1439857929944992
[10/24] Train loss=0.16953495144844055
[15/24] Train loss=0.16079527139663696
[20/24] Train loss=0.15277992188930511
Test set avg_accuracy=84.41% avg_sensitivity=72.29%, avg_specificity=88.74% avg_auc=89.49%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.150900 Test loss=0.364929 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.13914470374584198
[5/24] Train loss=0.14186519384384155
[10/24] Train loss=0.16795261204242706
[15/24] Train loss=0.15415997803211212
[20/24] Train loss=0.15694206953048706
Test set avg_accuracy=84.45% avg_sensitivity=71.85%, avg_specificity=88.96% avg_auc=89.46%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.149806 Test loss=0.364681 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13885267078876495
[5/24] Train loss=0.13620996475219727
[10/24] Train loss=0.1641554981470108
[15/24] Train loss=0.16442331671714783
[20/24] Train loss=0.15408578515052795
Test set avg_accuracy=84.48% avg_sensitivity=71.80%, avg_specificity=89.01% avg_auc=89.50%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.149899 Test loss=0.363950 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1357278823852539
[5/24] Train loss=0.13831965625286102
[10/24] Train loss=0.16543374955654144
[15/24] Train loss=0.1617061346769333
[20/24] Train loss=0.15332986414432526
Test set avg_accuracy=84.49% avg_sensitivity=72.44%, avg_specificity=88.80% avg_auc=89.54%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.149645 Test loss=0.363997 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1379661113023758
[5/24] Train loss=0.13901512324810028
[10/24] Train loss=0.1644768863916397
[15/24] Train loss=0.15433408319950104
[20/24] Train loss=0.15612734854221344
Test set avg_accuracy=84.43% avg_sensitivity=71.99%, avg_specificity=88.87% avg_auc=89.51%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.149354 Test loss=0.363963 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1398080438375473
[5/24] Train loss=0.1436803936958313
[10/24] Train loss=0.1662379503250122
[15/24] Train loss=0.159371018409729
[20/24] Train loss=0.1564256101846695
Test set avg_accuracy=84.53% avg_sensitivity=72.29%, avg_specificity=88.90% avg_auc=89.49%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.149685 Test loss=0.364203 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13834300637245178
[5/24] Train loss=0.13672250509262085
[10/24] Train loss=0.16826483607292175
[15/24] Train loss=0.15813983976840973
[20/24] Train loss=0.15820547938346863
Test set avg_accuracy=84.54% avg_sensitivity=72.24%, avg_specificity=88.94% avg_auc=89.45%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.149353 Test loss=0.365029 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13980208337306976
[5/24] Train loss=0.1410987377166748
[10/24] Train loss=0.16718432307243347
[15/24] Train loss=0.1544986218214035
[20/24] Train loss=0.1542702317237854
Test set avg_accuracy=84.62% avg_sensitivity=72.29%, avg_specificity=89.03% avg_auc=89.48%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.149388 Test loss=0.365160 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13832159340381622
[5/24] Train loss=0.13699840009212494
[10/24] Train loss=0.16269637644290924
[15/24] Train loss=0.15864214301109314
[20/24] Train loss=0.15583057701587677
Test set avg_accuracy=84.45% avg_sensitivity=72.29%, avg_specificity=88.80% avg_auc=89.49%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.148831 Test loss=0.364922 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.13795408606529236
[5/24] Train loss=0.1360657811164856
[10/24] Train loss=0.16341841220855713
[15/24] Train loss=0.155072420835495
[20/24] Train loss=0.15854041278362274
Test set avg_accuracy=84.43% avg_sensitivity=72.24%, avg_specificity=88.78% avg_auc=89.47%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.148856 Test loss=0.365041 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1361890435218811
[5/24] Train loss=0.14357663691043854
[10/24] Train loss=0.16465158760547638
[15/24] Train loss=0.1551152914762497
[20/24] Train loss=0.15441296994686127
Test set avg_accuracy=84.45% avg_sensitivity=72.29%, avg_specificity=88.80% avg_auc=89.49%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.149056 Test loss=0.364820 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13674351572990417
[5/24] Train loss=0.13859745860099792
[10/24] Train loss=0.1618441492319107
[15/24] Train loss=0.15386871993541718
[20/24] Train loss=0.15543918311595917
Test set avg_accuracy=84.41% avg_sensitivity=71.94%, avg_specificity=88.87% avg_auc=89.48%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.148412 Test loss=0.365047 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.136651873588562
[5/24] Train loss=0.14107631146907806
[10/24] Train loss=0.16976453363895416
[15/24] Train loss=0.15544022619724274
[20/24] Train loss=0.16072961688041687
Test set avg_accuracy=84.48% avg_sensitivity=72.19%, avg_specificity=88.87% avg_auc=89.47%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.149359 Test loss=0.365124 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=85.18% sen=75.75%, spe=88.55%, auc=90.69%!
Fold[1] Avg_overlap=0.66%(±0.25693902446743616)
[0/24] Train loss=0.7331224679946899
[5/24] Train loss=0.7281700372695923
[10/24] Train loss=0.7256253957748413
[15/24] Train loss=0.7224552631378174
[20/24] Train loss=0.7045663595199585
Test set avg_accuracy=57.51% avg_sensitivity=34.74%, avg_specificity=65.09% avg_auc=49.06%
Best model saved!! Metric=-119.60009613041407!!
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.724152 Test loss=0.681582 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7161031365394592
[5/24] Train loss=0.7098165154457092
[10/24] Train loss=0.7026237845420837
[15/24] Train loss=0.704151451587677
[20/24] Train loss=0.6947885155677795
Test set avg_accuracy=65.04% avg_sensitivity=27.49%, avg_specificity=77.53% avg_auc=52.08%
Best model saved!! Metric=-103.85758060242402!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.706830 Test loss=0.658980 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6909099817276001
[5/24] Train loss=0.7053077816963196
[10/24] Train loss=0.6847622394561768
[15/24] Train loss=0.6869363784790039
[20/24] Train loss=0.6733314394950867
Test set avg_accuracy=69.64% avg_sensitivity=27.23%, avg_specificity=83.74% avg_auc=56.50%
Best model saved!! Metric=-88.8895924506396!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.690906 Test loss=0.639336 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6846733689308167
[5/24] Train loss=0.6755004525184631
[10/24] Train loss=0.6665501594543457
[15/24] Train loss=0.6724483966827393
[20/24] Train loss=0.653410792350769
Test set avg_accuracy=70.90% avg_sensitivity=28.48%, avg_specificity=85.01% avg_auc=59.97%
Best model saved!! Metric=-81.64570469974507!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.674106 Test loss=0.621200 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6539413332939148
[5/24] Train loss=0.654076337814331
[10/24] Train loss=0.6503337621688843
[15/24] Train loss=0.6468201279640198
[20/24] Train loss=0.6349205374717712
Test set avg_accuracy=73.19% avg_sensitivity=30.88%, avg_specificity=87.26% avg_auc=63.57%
Best model saved!! Metric=-71.09425187543488!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.654396 Test loss=0.600897 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6356046199798584
[5/24] Train loss=0.637874186038971
[10/24] Train loss=0.625465452671051
[15/24] Train loss=0.6259062886238098
[20/24] Train loss=0.6088728904724121
Test set avg_accuracy=73.61% avg_sensitivity=35.05%, avg_specificity=86.43% avg_auc=67.44%
Best model saved!! Metric=-63.463666546635714!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.633183 Test loss=0.576639 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6063562035560608
[5/24] Train loss=0.6073124408721924
[10/24] Train loss=0.6022456288337708
[15/24] Train loss=0.6028569936752319
[20/24] Train loss=0.5780416131019592
Test set avg_accuracy=74.23% avg_sensitivity=39.59%, avg_specificity=85.75% avg_auc=70.90%
Best model saved!! Metric=-55.525238223145614!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.606468 Test loss=0.548411 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5714768171310425
[5/24] Train loss=0.5822551846504211
[10/24] Train loss=0.5733444094657898
[15/24] Train loss=0.5741097927093506
[20/24] Train loss=0.5564844012260437
Test set avg_accuracy=75.05% avg_sensitivity=44.60%, avg_specificity=85.18% avg_auc=74.29%
Best model saved!! Metric=-46.87725779204957!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.579591 Test loss=0.523246 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.543100118637085
[5/24] Train loss=0.5515950918197632
[10/24] Train loss=0.5436513423919678
[15/24] Train loss=0.5459207892417908
[20/24] Train loss=0.5364426970481873
Test set avg_accuracy=75.99% avg_sensitivity=47.68%, avg_specificity=85.41% avg_auc=76.66%
Best model saved!! Metric=-40.26007200126163!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.553834 Test loss=0.496264 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.515333890914917
[5/24] Train loss=0.5248281359672546
[10/24] Train loss=0.5222039222717285
[15/24] Train loss=0.5249937772750854
[20/24] Train loss=0.5142576098442078
Test set avg_accuracy=77.21% avg_sensitivity=50.55%, avg_specificity=86.08% avg_auc=78.07%
Best model saved!! Metric=-34.08874059716976!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.530362 Test loss=0.485413 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4907369315624237
[5/24] Train loss=0.4996771216392517
[10/24] Train loss=0.4993472695350647
[15/24] Train loss=0.5020641684532166
[20/24] Train loss=0.49148377776145935
Test set avg_accuracy=77.71% avg_sensitivity=48.41%, avg_specificity=87.45% avg_auc=78.37%
Best model saved!! Metric=-34.06089350189737!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.509023 Test loss=0.473786 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.47173961997032166
[5/24] Train loss=0.4868388772010803
[10/24] Train loss=0.4789457321166992
[15/24] Train loss=0.4844551384449005
[20/24] Train loss=0.47626060247421265
Test set avg_accuracy=78.26% avg_sensitivity=49.71%, avg_specificity=87.75% avg_auc=80.01%
Best model saved!! Metric=-30.275100543533107!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.492245 Test loss=0.460919 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.45442163944244385
[5/24] Train loss=0.4716668128967285
[10/24] Train loss=0.46320396661758423
[15/24] Train loss=0.47233888506889343
[20/24] Train loss=0.45764219760894775
Test set avg_accuracy=78.67% avg_sensitivity=49.61%, avg_specificity=88.34% avg_auc=80.47%
Best model saved!! Metric=-28.909328857355995!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.475592 Test loss=0.452569 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4364483058452606
[5/24] Train loss=0.4547255337238312
[10/24] Train loss=0.45162734389305115
[15/24] Train loss=0.4540315568447113
[20/24] Train loss=0.4447362422943115
Test set avg_accuracy=79.11% avg_sensitivity=50.65%, avg_specificity=88.58% avg_auc=81.54%
Best model saved!! Metric=-26.110359190751623!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.461246 Test loss=0.441892 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.42403820157051086
[5/24] Train loss=0.44587045907974243
[10/24] Train loss=0.43985292315483093
[15/24] Train loss=0.4448639750480652
[20/24] Train loss=0.4307384192943573
Test set avg_accuracy=79.28% avg_sensitivity=53.16%, avg_specificity=87.98% avg_auc=82.68%
Best model saved!! Metric=-22.90081860282475!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.448956 Test loss=0.430442 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.41008812189102173
[5/24] Train loss=0.4275210201740265
[10/24] Train loss=0.4332554042339325
[15/24] Train loss=0.4342953562736511
[20/24] Train loss=0.4167160987854004
Test set avg_accuracy=79.47% avg_sensitivity=53.68%, avg_specificity=88.04% avg_auc=83.01%
Best model saved!! Metric=-21.805660323819616!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.436973 Test loss=0.426816 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3954713046550751
[5/24] Train loss=0.4199829399585724
[10/24] Train loss=0.42358845472335815
[15/24] Train loss=0.42513272166252136
[20/24] Train loss=0.4044763743877411
Test set avg_accuracy=79.88% avg_sensitivity=51.90%, avg_specificity=89.19% avg_auc=82.97%
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.426157 Test loss=0.425043 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.37954002618789673
[5/24] Train loss=0.4120335578918457
[10/24] Train loss=0.4104940593242645
[15/24] Train loss=0.41228634119033813
[20/24] Train loss=0.38941892981529236
Test set avg_accuracy=79.82% avg_sensitivity=53.63%, avg_specificity=88.53% avg_auc=83.65%
Best model saved!! Metric=-20.374847726672414!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.416021 Test loss=0.419312 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.37078213691711426
[5/24] Train loss=0.4063144326210022
[10/24] Train loss=0.39812779426574707
[15/24] Train loss=0.40648436546325684
[20/24] Train loss=0.38482630252838135
Test set avg_accuracy=80.42% avg_sensitivity=55.87%, avg_specificity=88.58% avg_auc=84.36%
Best model saved!! Metric=-16.777180434681654!!
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.407718 Test loss=0.412133 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.36019256711006165
[5/24] Train loss=0.39063727855682373
[10/24] Train loss=0.39584919810295105
[15/24] Train loss=0.3934529423713684
[20/24] Train loss=0.37240704894065857
Test set avg_accuracy=80.64% avg_sensitivity=57.49%, avg_specificity=88.34% avg_auc=84.96%
Best model saved!! Metric=-14.579712931547967!!
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.398147 Test loss=0.406090 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3531164228916168
[5/24] Train loss=0.38796424865722656
[10/24] Train loss=0.3939443826675415
[15/24] Train loss=0.3873211145401001
[20/24] Train loss=0.36151519417762756
Test set avg_accuracy=80.89% avg_sensitivity=58.69%, avg_specificity=88.27% avg_auc=85.34%
Best model saved!! Metric=-12.821039291335701!!
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.390580 Test loss=0.401294 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3478209972381592
[5/24] Train loss=0.3744519054889679
[10/24] Train loss=0.38279300928115845
[15/24] Train loss=0.378559947013855
[20/24] Train loss=0.36408767104148865
Test set avg_accuracy=81.25% avg_sensitivity=60.15%, avg_specificity=88.27% avg_auc=85.99%
Best model saved!! Metric=-10.347083765438008!!
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.383602 Test loss=0.394927 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3405323028564453
[5/24] Train loss=0.3624410927295685
[10/24] Train loss=0.376674622297287
[15/24] Train loss=0.37454333901405334
[20/24] Train loss=0.350286602973938
Test set avg_accuracy=81.29% avg_sensitivity=63.02%, avg_specificity=87.37% avg_auc=86.28%
Best model saved!! Metric=-8.046422418042894!!
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.375271 Test loss=0.394653 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3331686854362488
[5/24] Train loss=0.3648862838745117
[10/24] Train loss=0.3745317757129669
[15/24] Train loss=0.3600958287715912
[20/24] Train loss=0.3360339403152466
Test set avg_accuracy=82.33% avg_sensitivity=59.47%, avg_specificity=89.94% avg_auc=86.91%
Best model saved!! Metric=-7.360079511470104!!
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.368242 Test loss=0.384690 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3225312829017639
[5/24] Train loss=0.35824376344680786
[10/24] Train loss=0.37321168184280396
[15/24] Train loss=0.34425950050354004
[20/24] Train loss=0.3331935405731201
Test set avg_accuracy=82.70% avg_sensitivity=59.26%, avg_specificity=90.49% avg_auc=87.42%
Best model saved!! Metric=-6.136296985836438!!
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.359727 Test loss=0.377907 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.31528887152671814
[5/24] Train loss=0.3507290184497833
[10/24] Train loss=0.36330366134643555
[15/24] Train loss=0.3380398154258728
[20/24] Train loss=0.3215745687484741
Test set avg_accuracy=82.85% avg_sensitivity=49.77%, avg_specificity=93.86% avg_auc=87.53%
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.352448 Test loss=0.383616 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3144916594028473
[5/24] Train loss=0.3449305593967438
[10/24] Train loss=0.370593398809433
[15/24] Train loss=0.33835622668266296
[20/24] Train loss=0.3220367133617401
Test set avg_accuracy=83.06% avg_sensitivity=54.77%, avg_specificity=92.47% avg_auc=87.94%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.348917 Test loss=0.376349 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.30491772294044495
[5/24] Train loss=0.3339026868343353
[10/24] Train loss=0.36625635623931885
[15/24] Train loss=0.3378561735153198
[20/24] Train loss=0.3278200626373291
Test set avg_accuracy=82.86% avg_sensitivity=61.09%, avg_specificity=90.11% avg_auc=88.22%
Best model saved!! Metric=-3.717081345131483!!
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.344281 Test loss=0.368302 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3057616055011749
[5/24] Train loss=0.3489713966846466
[10/24] Train loss=0.3457000255584717
[15/24] Train loss=0.33320072293281555
[20/24] Train loss=0.3101370930671692
Test set avg_accuracy=83.35% avg_sensitivity=60.77%, avg_specificity=90.86% avg_auc=88.55%
Best model saved!! Metric=-2.4740821949881777!!
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.338885 Test loss=0.361507 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3053339123725891
[5/24] Train loss=0.34060701727867126
[10/24] Train loss=0.35913634300231934
[15/24] Train loss=0.31434664130210876
[20/24] Train loss=0.3024858832359314
Test set avg_accuracy=83.15% avg_sensitivity=62.75%, avg_specificity=89.94% avg_auc=88.28%
Best model saved!! Metric=-1.875960495146451!!
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.335138 Test loss=0.369543 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.28074270486831665
[5/24] Train loss=0.3386070430278778
[10/24] Train loss=0.3518874943256378
[15/24] Train loss=0.3200277090072632
[20/24] Train loss=0.30391207337379456
Test set avg_accuracy=83.83% avg_sensitivity=57.28%, avg_specificity=92.66% avg_auc=88.75%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.330811 Test loss=0.360912 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.29591089487075806
[5/24] Train loss=0.32952776551246643
[10/24] Train loss=0.333835631608963
[15/24] Train loss=0.32158273458480835
[20/24] Train loss=0.28935548663139343
Test set avg_accuracy=83.63% avg_sensitivity=60.51%, avg_specificity=91.32% avg_auc=88.65%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.324771 Test loss=0.362839 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.28748342394828796
[5/24] Train loss=0.32903507351875305
[10/24] Train loss=0.33422011137008667
[15/24] Train loss=0.31061139702796936
[20/24] Train loss=0.2999352216720581
Test set avg_accuracy=83.11% avg_sensitivity=65.26%, avg_specificity=89.05% avg_auc=88.33%
Best model saved!! Metric=-0.24426361065717117!!
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.321878 Test loss=0.370350 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.295725017786026
[5/24] Train loss=0.317497193813324
[10/24] Train loss=0.32347846031188965
[15/24] Train loss=0.3131328821182251
[20/24] Train loss=0.28605741262435913
Test set avg_accuracy=83.66% avg_sensitivity=57.38%, avg_specificity=92.40% avg_auc=88.60%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.319369 Test loss=0.361297 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2892792820930481
[5/24] Train loss=0.31366851925849915
[10/24] Train loss=0.33015570044517517
[15/24] Train loss=0.30986687541007996
[20/24] Train loss=0.28520235419273376
Test set avg_accuracy=84.10% avg_sensitivity=58.22%, avg_specificity=92.71% avg_auc=88.53%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.317367 Test loss=0.362601 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.27422720193862915
[5/24] Train loss=0.3293061852455139
[10/24] Train loss=0.3359854221343994
[15/24] Train loss=0.3040797710418701
[20/24] Train loss=0.2820110321044922
Test set avg_accuracy=83.10% avg_sensitivity=64.21%, avg_specificity=89.38% avg_auc=88.37%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.313254 Test loss=0.369141 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2733425199985504
[5/24] Train loss=0.32164135575294495
[10/24] Train loss=0.3204838037490845
[15/24] Train loss=0.315254807472229
[20/24] Train loss=0.28181561827659607
Test set avg_accuracy=83.54% avg_sensitivity=59.15%, avg_specificity=91.65% avg_auc=88.98%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.310050 Test loss=0.360310 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2603788375854492
[5/24] Train loss=0.3138365149497986
[10/24] Train loss=0.3114272654056549
[15/24] Train loss=0.3056700527667999
[20/24] Train loss=0.28785333037376404
Test set avg_accuracy=83.84% avg_sensitivity=55.29%, avg_specificity=93.34% avg_auc=88.51%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.306797 Test loss=0.365488 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.27191615104675293
[5/24] Train loss=0.31103888154029846
[10/24] Train loss=0.3260703384876251
[15/24] Train loss=0.29509633779525757
[20/24] Train loss=0.2760268449783325
Test set avg_accuracy=83.75% avg_sensitivity=61.92%, avg_specificity=91.01% avg_auc=88.72%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.306405 Test loss=0.361155 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.26398083567619324
[5/24] Train loss=0.31805527210235596
[10/24] Train loss=0.32060950994491577
[15/24] Train loss=0.29683759808540344
[20/24] Train loss=0.28030383586883545
Test set avg_accuracy=83.33% avg_sensitivity=59.73%, avg_specificity=91.19% avg_auc=88.99%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.301840 Test loss=0.361222 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2633837163448334
[5/24] Train loss=0.3045055568218231
[10/24] Train loss=0.30234694480895996
[15/24] Train loss=0.28821253776550293
[20/24] Train loss=0.25941959023475647
Test set avg_accuracy=83.91% avg_sensitivity=55.40%, avg_specificity=93.39% avg_auc=88.98%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.296234 Test loss=0.356107 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.26537811756134033
[5/24] Train loss=0.2968764901161194
[10/24] Train loss=0.30301177501678467
[15/24] Train loss=0.28687289357185364
[20/24] Train loss=0.2609734535217285
Test set avg_accuracy=84.10% avg_sensitivity=61.50%, avg_specificity=91.62% avg_auc=89.55%
Best model saved!! Metric=0.7732984704140264!!
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.294112 Test loss=0.348575 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.259412556886673
[5/24] Train loss=0.30440956354141235
[10/24] Train loss=0.2995348870754242
[15/24] Train loss=0.28561529517173767
[20/24] Train loss=0.2565231919288635
Test set avg_accuracy=84.26% avg_sensitivity=68.70%, avg_specificity=89.43% avg_auc=89.48%
Best model saved!! Metric=5.872305183571058!!
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.293480 Test loss=0.352976 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.24719250202178955
[5/24] Train loss=0.30018484592437744
[10/24] Train loss=0.30548566579818726
[15/24] Train loss=0.27497395873069763
[20/24] Train loss=0.25175759196281433
Test set avg_accuracy=83.37% avg_sensitivity=69.01%, avg_specificity=88.15% avg_auc=89.21%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.288291 Test loss=0.361950 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2474789321422577
[5/24] Train loss=0.29466432332992554
[10/24] Train loss=0.2980247735977173
[15/24] Train loss=0.27186670899391174
[20/24] Train loss=0.25208061933517456
Test set avg_accuracy=84.75% avg_sensitivity=61.61%, avg_specificity=92.45% avg_auc=89.89%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.284848 Test loss=0.344540 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.24721688032150269
[5/24] Train loss=0.2932138741016388
[10/24] Train loss=0.2919437289237976
[15/24] Train loss=0.27208995819091797
[20/24] Train loss=0.24915675818920135
Test set avg_accuracy=84.56% avg_sensitivity=62.86%, avg_specificity=91.78% avg_auc=89.26%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.283765 Test loss=0.349857 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2585698366165161
[5/24] Train loss=0.2969427704811096
[10/24] Train loss=0.2933701276779175
[15/24] Train loss=0.28472456336021423
[20/24] Train loss=0.25110113620758057
Test set avg_accuracy=84.79% avg_sensitivity=58.74%, avg_specificity=93.46% avg_auc=89.03%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.286860 Test loss=0.353154 Current lr=[0.000299720220882401]

[0/24] Train loss=0.24800479412078857
[5/24] Train loss=0.29013583064079285
[10/24] Train loss=0.29785990715026855
[15/24] Train loss=0.278543621301651
[20/24] Train loss=0.24556832015514374
Test set avg_accuracy=84.58% avg_sensitivity=66.51%, avg_specificity=90.60% avg_auc=90.11%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.282355 Test loss=0.340657 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2467895746231079
[5/24] Train loss=0.289305180311203
[10/24] Train loss=0.2886401414871216
[15/24] Train loss=0.2699800729751587
[20/24] Train loss=0.24174600839614868
Test set avg_accuracy=84.48% avg_sensitivity=58.95%, avg_specificity=92.97% avg_auc=89.50%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.282085 Test loss=0.348864 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2528384029865265
[5/24] Train loss=0.27132555842399597
[10/24] Train loss=0.28166383504867554
[15/24] Train loss=0.2631217837333679
[20/24] Train loss=0.2432631552219391
Test set avg_accuracy=84.21% avg_sensitivity=64.06%, avg_specificity=90.91% avg_auc=89.19%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.276850 Test loss=0.353421 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2320598065853119
[5/24] Train loss=0.28727176785469055
[10/24] Train loss=0.2865908741950989
[15/24] Train loss=0.2629753351211548
[20/24] Train loss=0.2441316545009613
Test set avg_accuracy=84.04% avg_sensitivity=64.53%, avg_specificity=90.53% avg_auc=89.08%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.274832 Test loss=0.357269 Current lr=[0.000297555943323901]

[0/24] Train loss=0.24566954374313354
[5/24] Train loss=0.2828671634197235
[10/24] Train loss=0.2894446849822998
[15/24] Train loss=0.2576490044593811
[20/24] Train loss=0.23501044511795044
Test set avg_accuracy=83.85% avg_sensitivity=64.27%, avg_specificity=90.37% avg_auc=88.53%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.275033 Test loss=0.359495 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.24036017060279846
[5/24] Train loss=0.26551178097724915
[10/24] Train loss=0.2775753140449524
[15/24] Train loss=0.2576490044593811
[20/24] Train loss=0.25034642219543457
Test set avg_accuracy=84.19% avg_sensitivity=64.53%, avg_specificity=90.73% avg_auc=89.19%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.272711 Test loss=0.353201 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.24546408653259277
[5/24] Train loss=0.28157317638397217
[10/24] Train loss=0.27681484818458557
[15/24] Train loss=0.2633752226829529
[20/24] Train loss=0.23550549149513245
Test set avg_accuracy=83.45% avg_sensitivity=57.96%, avg_specificity=91.93% avg_auc=88.37%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.267429 Test loss=0.365496 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.22593159973621368
[5/24] Train loss=0.2674017548561096
[10/24] Train loss=0.27513179183006287
[15/24] Train loss=0.25058865547180176
[20/24] Train loss=0.22491279244422913
Test set avg_accuracy=84.13% avg_sensitivity=56.03%, avg_specificity=93.48% avg_auc=88.85%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.266005 Test loss=0.358838 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.22227133810520172
[5/24] Train loss=0.26059040427207947
[10/24] Train loss=0.2718093693256378
[15/24] Train loss=0.25394004583358765
[20/24] Train loss=0.2254852056503296
Test set avg_accuracy=84.52% avg_sensitivity=62.75%, avg_specificity=91.76% avg_auc=89.15%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.262725 Test loss=0.349977 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.24245241284370422
[5/24] Train loss=0.26813071966171265
[10/24] Train loss=0.2844894826412201
[15/24] Train loss=0.2466074824333191
[20/24] Train loss=0.23533818125724792
Test set avg_accuracy=83.28% avg_sensitivity=48.41%, avg_specificity=94.88% avg_auc=87.05%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.265185 Test loss=0.385101 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2325897216796875
[5/24] Train loss=0.2579268515110016
[10/24] Train loss=0.2623555064201355
[15/24] Train loss=0.25387832522392273
[20/24] Train loss=0.2231678068637848
Test set avg_accuracy=84.10% avg_sensitivity=60.35%, avg_specificity=92.00% avg_auc=88.82%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.260115 Test loss=0.362222 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.21927879750728607
[5/24] Train loss=0.276202529668808
[10/24] Train loss=0.2708636224269867
[15/24] Train loss=0.24630410969257355
[20/24] Train loss=0.2161591649055481
Test set avg_accuracy=83.55% avg_sensitivity=68.96%, avg_specificity=88.41% avg_auc=88.61%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.256071 Test loss=0.370838 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.22950030863285065
[5/24] Train loss=0.2751670777797699
[10/24] Train loss=0.2678024470806122
[15/24] Train loss=0.24613556265830994
[20/24] Train loss=0.22690443694591522
Test set avg_accuracy=84.26% avg_sensitivity=53.73%, avg_specificity=94.41% avg_auc=87.32%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.256149 Test loss=0.387564 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.238463893532753
[5/24] Train loss=0.26551857590675354
[10/24] Train loss=0.26726335287094116
[15/24] Train loss=0.23070132732391357
[20/24] Train loss=0.2263152301311493
Test set avg_accuracy=83.84% avg_sensitivity=57.49%, avg_specificity=92.61% avg_auc=87.36%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.254558 Test loss=0.374919 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.22829675674438477
[5/24] Train loss=0.2641816735267639
[10/24] Train loss=0.27213332056999207
[15/24] Train loss=0.2333877831697464
[20/24] Train loss=0.21336165070533752
Test set avg_accuracy=85.01% avg_sensitivity=61.09%, avg_specificity=92.97% avg_auc=89.00%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.253123 Test loss=0.354063 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.221693754196167
[5/24] Train loss=0.2568505108356476
[10/24] Train loss=0.26336002349853516
[15/24] Train loss=0.23358117043972015
[20/24] Train loss=0.21500760316848755
Test set avg_accuracy=83.09% avg_sensitivity=69.22%, avg_specificity=87.70% avg_auc=87.39%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.248661 Test loss=0.386021 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.21233685314655304
[5/24] Train loss=0.26081228256225586
[10/24] Train loss=0.26997196674346924
[15/24] Train loss=0.22889851033687592
[20/24] Train loss=0.20823059976100922
Test set avg_accuracy=83.87% avg_sensitivity=66.46%, avg_specificity=89.66% avg_auc=88.19%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.247758 Test loss=0.373608 Current lr=[0.000276307469034998]

[0/24] Train loss=0.21751293540000916
[5/24] Train loss=0.2542304992675781
[10/24] Train loss=0.2640274465084076
[15/24] Train loss=0.23425577580928802
[20/24] Train loss=0.22334058582782745
Test set avg_accuracy=84.24% avg_sensitivity=62.13%, avg_specificity=91.60% avg_auc=87.05%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.249194 Test loss=0.375870 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.22351065278053284
[5/24] Train loss=0.2522786557674408
[10/24] Train loss=0.24497103691101074
[15/24] Train loss=0.22875677049160004
[20/24] Train loss=0.2211451381444931
Test set avg_accuracy=84.30% avg_sensitivity=63.28%, avg_specificity=91.29% avg_auc=88.54%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.246042 Test loss=0.364157 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.21402963995933533
[5/24] Train loss=0.2528340816497803
[10/24] Train loss=0.27101677656173706
[15/24] Train loss=0.23461444675922394
[20/24] Train loss=0.21794188022613525
Test set avg_accuracy=84.19% avg_sensitivity=60.82%, avg_specificity=91.97% avg_auc=87.71%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.244528 Test loss=0.374205 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.22185158729553223
[5/24] Train loss=0.25431862473487854
[10/24] Train loss=0.26951199769973755
[15/24] Train loss=0.24284984171390533
[20/24] Train loss=0.21766088902950287
Test set avg_accuracy=84.30% avg_sensitivity=57.17%, avg_specificity=93.32% avg_auc=86.94%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.243577 Test loss=0.399732 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.22258634865283966
[5/24] Train loss=0.2411268651485443
[10/24] Train loss=0.2568984925746918
[15/24] Train loss=0.2277691513299942
[20/24] Train loss=0.19667355716228485
Test set avg_accuracy=84.17% avg_sensitivity=60.88%, avg_specificity=91.91% avg_auc=88.12%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.238347 Test loss=0.364149 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.21075987815856934
[5/24] Train loss=0.2670205533504486
[10/24] Train loss=0.259379506111145
[15/24] Train loss=0.2341545969247818
[20/24] Train loss=0.1950981467962265
Test set avg_accuracy=83.82% avg_sensitivity=67.50%, avg_specificity=89.24% avg_auc=86.72%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.239132 Test loss=0.394824 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.20744484663009644
[5/24] Train loss=0.24963873624801636
[10/24] Train loss=0.25559788942337036
[15/24] Train loss=0.214867502450943
[20/24] Train loss=0.20074637234210968
Test set avg_accuracy=84.41% avg_sensitivity=68.91%, avg_specificity=89.57% avg_auc=88.07%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.233945 Test loss=0.372569 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.20613285899162292
[5/24] Train loss=0.2577000856399536
[10/24] Train loss=0.2537521421909332
[15/24] Train loss=0.23115941882133484
[20/24] Train loss=0.19548289477825165
Test set avg_accuracy=84.66% avg_sensitivity=57.69%, avg_specificity=93.63% avg_auc=88.19%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.234238 Test loss=0.371260 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.20996150374412537
[5/24] Train loss=0.23926831781864166
[10/24] Train loss=0.253805011510849
[15/24] Train loss=0.21561883389949799
[20/24] Train loss=0.19991429150104523
Test set avg_accuracy=84.13% avg_sensitivity=58.22%, avg_specificity=92.75% avg_auc=86.82%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.234253 Test loss=0.390406 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2074710726737976
[5/24] Train loss=0.2473517656326294
[10/24] Train loss=0.2421240657567978
[15/24] Train loss=0.21326234936714172
[20/24] Train loss=0.19065940380096436
Test set avg_accuracy=82.97% avg_sensitivity=57.69%, avg_specificity=91.38% avg_auc=84.95%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.231965 Test loss=0.402336 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.22926907241344452
[5/24] Train loss=0.25026872754096985
[10/24] Train loss=0.24976873397827148
[15/24] Train loss=0.22301244735717773
[20/24] Train loss=0.21973633766174316
Test set avg_accuracy=84.09% avg_sensitivity=66.25%, avg_specificity=90.02% avg_auc=86.78%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.235035 Test loss=0.380890 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.19872091710567474
[5/24] Train loss=0.2321070283651352
[10/24] Train loss=0.24814607203006744
[15/24] Train loss=0.22489313781261444
[20/24] Train loss=0.19558978080749512
Test set avg_accuracy=83.93% avg_sensitivity=57.64%, avg_specificity=92.68% avg_auc=84.96%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.230012 Test loss=0.394603 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.19571959972381592
[5/24] Train loss=0.2347564548254013
[10/24] Train loss=0.24808429181575775
[15/24] Train loss=0.21272532641887665
[20/24] Train loss=0.2052159458398819
Test set avg_accuracy=81.97% avg_sensitivity=42.78%, avg_specificity=95.00% avg_auc=82.93%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.229173 Test loss=0.435212 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.21019361913204193
[5/24] Train loss=0.24228177964687347
[10/24] Train loss=0.2531084418296814
[15/24] Train loss=0.20956946909427643
[20/24] Train loss=0.20237024128437042
Test set avg_accuracy=84.15% avg_sensitivity=59.89%, avg_specificity=92.23% avg_auc=86.35%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.230418 Test loss=0.390698 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2072145938873291
[5/24] Train loss=0.23413877189159393
[10/24] Train loss=0.24169974029064178
[15/24] Train loss=0.2120463103055954
[20/24] Train loss=0.20129089057445526
Test set avg_accuracy=84.01% avg_sensitivity=62.86%, avg_specificity=91.05% avg_auc=86.26%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.222739 Test loss=0.387879 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.20212648808956146
[5/24] Train loss=0.22840391099452972
[10/24] Train loss=0.23053154349327087
[15/24] Train loss=0.21181893348693848
[20/24] Train loss=0.18717347085475922
Test set avg_accuracy=84.06% avg_sensitivity=55.14%, avg_specificity=93.68% avg_auc=86.35%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.217542 Test loss=0.396511 Current lr=[0.000224838296036774]

[0/24] Train loss=0.19597311317920685
[5/24] Train loss=0.21995627880096436
[10/24] Train loss=0.23249037563800812
[15/24] Train loss=0.20542781054973602
[20/24] Train loss=0.18909896910190582
Test set avg_accuracy=83.57% avg_sensitivity=67.87%, avg_specificity=88.79% avg_auc=87.10%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.219839 Test loss=0.393955 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.19427163898944855
[5/24] Train loss=0.22277820110321045
[10/24] Train loss=0.23338687419891357
[15/24] Train loss=0.1970892995595932
[20/24] Train loss=0.18743275105953217
Test set avg_accuracy=84.34% avg_sensitivity=64.84%, avg_specificity=90.82% avg_auc=87.36%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.217099 Test loss=0.388993 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.1934249997138977
[5/24] Train loss=0.215835839509964
[10/24] Train loss=0.22280170023441315
[15/24] Train loss=0.19170737266540527
[20/24] Train loss=0.1760626882314682
Test set avg_accuracy=84.17% avg_sensitivity=61.71%, avg_specificity=91.64% avg_auc=86.43%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.209383 Test loss=0.387580 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1805931031703949
[5/24] Train loss=0.2129233479499817
[10/24] Train loss=0.2328203022480011
[15/24] Train loss=0.194673091173172
[20/24] Train loss=0.18848997354507446
Test set avg_accuracy=84.17% avg_sensitivity=63.69%, avg_specificity=90.98% avg_auc=86.21%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.209970 Test loss=0.394121 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.19376523792743683
[5/24] Train loss=0.20810168981552124
[10/24] Train loss=0.21553431451320648
[15/24] Train loss=0.20418913662433624
[20/24] Train loss=0.1825794279575348
Test set avg_accuracy=82.94% avg_sensitivity=59.47%, avg_specificity=90.75% avg_auc=85.24%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.211303 Test loss=0.409722 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.1798899620771408
[5/24] Train loss=0.213216170668602
[10/24] Train loss=0.22078868746757507
[15/24] Train loss=0.20466439425945282
[20/24] Train loss=0.17585770785808563
Test set avg_accuracy=83.26% avg_sensitivity=57.17%, avg_specificity=91.93% avg_auc=84.51%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.205615 Test loss=0.411718 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.18494921922683716
[5/24] Train loss=0.21099472045898438
[10/24] Train loss=0.22679726779460907
[15/24] Train loss=0.18822143971920013
[20/24] Train loss=0.18097926676273346
Test set avg_accuracy=83.32% avg_sensitivity=56.03%, avg_specificity=92.40% avg_auc=84.14%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.204151 Test loss=0.413181 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.17881277203559875
[5/24] Train loss=0.23062491416931152
[10/24] Train loss=0.22783567011356354
[15/24] Train loss=0.19002333283424377
[20/24] Train loss=0.18086160719394684
Test set avg_accuracy=83.54% avg_sensitivity=60.46%, avg_specificity=91.22% avg_auc=85.22%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.207417 Test loss=0.397926 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1871144324541092
[5/24] Train loss=0.2173299938440323
[10/24] Train loss=0.21634763479232788
[15/24] Train loss=0.18686150014400482
[20/24] Train loss=0.17996516823768616
Test set avg_accuracy=83.57% avg_sensitivity=65.21%, avg_specificity=89.68% avg_auc=86.09%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.202171 Test loss=0.399349 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.17804738879203796
[5/24] Train loss=0.20086681842803955
[10/24] Train loss=0.21293409168720245
[15/24] Train loss=0.18553775548934937
[20/24] Train loss=0.17373095452785492
Test set avg_accuracy=83.39% avg_sensitivity=64.27%, avg_specificity=89.74% avg_auc=85.90%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.201737 Test loss=0.403816 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.17965973913669586
[5/24] Train loss=0.20391590893268585
[10/24] Train loss=0.21893736720085144
[15/24] Train loss=0.18698205053806305
[20/24] Train loss=0.1726965457201004
Test set avg_accuracy=83.96% avg_sensitivity=63.22%, avg_specificity=90.86% avg_auc=85.73%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.198256 Test loss=0.395085 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.17955687642097473
[5/24] Train loss=0.1957874745130539
[10/24] Train loss=0.21305984258651733
[15/24] Train loss=0.18537020683288574
[20/24] Train loss=0.1713690161705017
Test set avg_accuracy=84.06% avg_sensitivity=62.75%, avg_specificity=91.15% avg_auc=85.56%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.197895 Test loss=0.401902 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.17252393066883087
[5/24] Train loss=0.19080546498298645
[10/24] Train loss=0.20770686864852905
[15/24] Train loss=0.18212847411632538
[20/24] Train loss=0.16593343019485474
Test set avg_accuracy=83.55% avg_sensitivity=62.49%, avg_specificity=90.56% avg_auc=85.54%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.193286 Test loss=0.396287 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.19230298697948456
[5/24] Train loss=0.19067293405532837
[10/24] Train loss=0.20359495282173157
[15/24] Train loss=0.18039655685424805
[20/24] Train loss=0.16373421251773834
Test set avg_accuracy=83.83% avg_sensitivity=62.13%, avg_specificity=91.05% avg_auc=85.65%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.191712 Test loss=0.398811 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.17241545021533966
[5/24] Train loss=0.19168995320796967
[10/24] Train loss=0.19386553764343262
[15/24] Train loss=0.1818303018808365
[20/24] Train loss=0.16388188302516937
Test set avg_accuracy=83.66% avg_sensitivity=59.62%, avg_specificity=91.65% avg_auc=85.21%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.190395 Test loss=0.402511 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.1689908504486084
[5/24] Train loss=0.1957959085702896
[10/24] Train loss=0.20034460723400116
[15/24] Train loss=0.17583097517490387
[20/24] Train loss=0.16492456197738647
Test set avg_accuracy=83.45% avg_sensitivity=65.05%, avg_specificity=89.57% avg_auc=86.39%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.189495 Test loss=0.399832 Current lr=[0.000156543481933168]

[0/24] Train loss=0.16508492827415466
[5/24] Train loss=0.19008249044418335
[10/24] Train loss=0.1952909678220749
[15/24] Train loss=0.17379145324230194
[20/24] Train loss=0.16514413058757782
Test set avg_accuracy=83.18% avg_sensitivity=60.98%, avg_specificity=90.56% avg_auc=84.84%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.185886 Test loss=0.413198 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.16764245927333832
[5/24] Train loss=0.18520992994308472
[10/24] Train loss=0.1948011815547943
[15/24] Train loss=0.16435350477695465
[20/24] Train loss=0.17398729920387268
Test set avg_accuracy=83.03% avg_sensitivity=62.60%, avg_specificity=89.83% avg_auc=84.09%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.184098 Test loss=0.422514 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.166090726852417
[5/24] Train loss=0.18807940185070038
[10/24] Train loss=0.19037117063999176
[15/24] Train loss=0.16890808939933777
[20/24] Train loss=0.15849992632865906
Test set avg_accuracy=83.55% avg_sensitivity=68.44%, avg_specificity=88.58% avg_auc=86.29%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.183615 Test loss=0.412118 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.16106882691383362
[5/24] Train loss=0.17715975642204285
[10/24] Train loss=0.19069145619869232
[15/24] Train loss=0.16482092440128326
[20/24] Train loss=0.16634026169776917
Test set avg_accuracy=82.68% avg_sensitivity=63.54%, avg_specificity=89.05% avg_auc=85.70%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.180414 Test loss=0.413309 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.16498273611068726
[5/24] Train loss=0.18208974599838257
[10/24] Train loss=0.18865230679512024
[15/24] Train loss=0.16432717442512512
[20/24] Train loss=0.15534071624279022
Test set avg_accuracy=82.97% avg_sensitivity=65.26%, avg_specificity=88.86% avg_auc=85.47%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.177671 Test loss=0.416464 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16150818765163422
[5/24] Train loss=0.17742355167865753
[10/24] Train loss=0.19748008251190186
[15/24] Train loss=0.17068660259246826
[20/24] Train loss=0.1627865582704544
Test set avg_accuracy=83.01% avg_sensitivity=63.64%, avg_specificity=89.45% avg_auc=85.21%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.177732 Test loss=0.411511 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15983766317367554
[5/24] Train loss=0.179479718208313
[10/24] Train loss=0.18573834002017975
[15/24] Train loss=0.16052068769931793
[20/24] Train loss=0.15055803954601288
Test set avg_accuracy=82.46% avg_sensitivity=67.19%, avg_specificity=87.54% avg_auc=86.01%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.176365 Test loss=0.419093 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1602807343006134
[5/24] Train loss=0.17673616111278534
[10/24] Train loss=0.18588803708553314
[15/24] Train loss=0.16702859103679657
[20/24] Train loss=0.15790130198001862
Test set avg_accuracy=82.85% avg_sensitivity=68.86%, avg_specificity=87.51% avg_auc=85.94%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.173848 Test loss=0.415491 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15471802651882172
[5/24] Train loss=0.17347948253154755
[10/24] Train loss=0.1830095499753952
[15/24] Train loss=0.16468630731105804
[20/24] Train loss=0.15304642915725708
Test set avg_accuracy=82.75% avg_sensitivity=62.55%, avg_specificity=89.47% avg_auc=85.72%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.172441 Test loss=0.410366 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.15626759827136993
[5/24] Train loss=0.1665591150522232
[10/24] Train loss=0.17843705415725708
[15/24] Train loss=0.16315272450447083
[20/24] Train loss=0.1482124775648117
Test set avg_accuracy=83.39% avg_sensitivity=67.14%, avg_specificity=88.79% avg_auc=86.03%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.167294 Test loss=0.410445 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15197262167930603
[5/24] Train loss=0.17267145216464996
[10/24] Train loss=0.18307670950889587
[15/24] Train loss=0.1619511991739273
[20/24] Train loss=0.14729849994182587
Test set avg_accuracy=83.74% avg_sensitivity=68.08%, avg_specificity=88.95% avg_auc=86.22%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.168998 Test loss=0.404038 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.153776153922081
[5/24] Train loss=0.17757348716259003
[10/24] Train loss=0.18604160845279694
[15/24] Train loss=0.1607428342103958
[20/24] Train loss=0.15031452476978302
Test set avg_accuracy=83.42% avg_sensitivity=65.78%, avg_specificity=89.29% avg_auc=86.33%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.168812 Test loss=0.408921 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.14748351275920868
[5/24] Train loss=0.1659691035747528
[10/24] Train loss=0.17980635166168213
[15/24] Train loss=0.16498246788978577
[20/24] Train loss=0.1484902799129486
Test set avg_accuracy=83.05% avg_sensitivity=67.50%, avg_specificity=88.22% avg_auc=86.23%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.166693 Test loss=0.417722 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.15182830393314362
[5/24] Train loss=0.16842392086982727
[10/24] Train loss=0.1849166303873062
[15/24] Train loss=0.15962852537631989
[20/24] Train loss=0.15730464458465576
Test set avg_accuracy=83.74% avg_sensitivity=64.42%, avg_specificity=90.16% avg_auc=86.03%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.168160 Test loss=0.409705 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14798811078071594
[5/24] Train loss=0.17447301745414734
[10/24] Train loss=0.1826704740524292
[15/24] Train loss=0.151720330119133
[20/24] Train loss=0.14868739247322083
Test set avg_accuracy=83.40% avg_sensitivity=64.84%, avg_specificity=89.57% avg_auc=85.88%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.164321 Test loss=0.415540 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.15421432256698608
[5/24] Train loss=0.17192484438419342
[10/24] Train loss=0.17763157188892365
[15/24] Train loss=0.15820707380771637
[20/24] Train loss=0.14171810448169708
Test set avg_accuracy=83.35% avg_sensitivity=64.84%, avg_specificity=89.50% avg_auc=86.03%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.163933 Test loss=0.413683 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14701329171657562
[5/24] Train loss=0.16931118071079254
[10/24] Train loss=0.1765432059764862
[15/24] Train loss=0.1567104160785675
[20/24] Train loss=0.14532610774040222
Test set avg_accuracy=83.63% avg_sensitivity=67.29%, avg_specificity=89.07% avg_auc=86.67%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.162286 Test loss=0.406651 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14510437846183777
[5/24] Train loss=0.17040924727916718
[10/24] Train loss=0.17322732508182526
[15/24] Train loss=0.1488661915063858
[20/24] Train loss=0.1466575264930725
Test set avg_accuracy=83.10% avg_sensitivity=63.54%, avg_specificity=89.61% avg_auc=86.38%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.161489 Test loss=0.404574 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14511951804161072
[5/24] Train loss=0.17067046463489532
[10/24] Train loss=0.1804446280002594
[15/24] Train loss=0.15240249037742615
[20/24] Train loss=0.13987649977207184
Test set avg_accuracy=83.22% avg_sensitivity=63.85%, avg_specificity=89.66% avg_auc=86.22%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.161222 Test loss=0.403022 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14561618864536285
[5/24] Train loss=0.16603460907936096
[10/24] Train loss=0.17756177484989166
[15/24] Train loss=0.14884743094444275
[20/24] Train loss=0.1404207944869995
Test set avg_accuracy=82.73% avg_sensitivity=62.70%, avg_specificity=89.40% avg_auc=85.45%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.158668 Test loss=0.416724 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14175987243652344
[5/24] Train loss=0.16232825815677643
[10/24] Train loss=0.16987325251102448
[15/24] Train loss=0.14902636408805847
[20/24] Train loss=0.14125220477581024
Test set avg_accuracy=82.80% avg_sensitivity=65.62%, avg_specificity=88.51% avg_auc=85.32%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.156976 Test loss=0.421914 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1391751766204834
[5/24] Train loss=0.16541142761707306
[10/24] Train loss=0.16879720985889435
[15/24] Train loss=0.14905135333538055
[20/24] Train loss=0.14201217889785767
Test set avg_accuracy=82.76% avg_sensitivity=68.70%, avg_specificity=87.44% avg_auc=86.54%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.157662 Test loss=0.415291 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14069341123104095
[5/24] Train loss=0.16249600052833557
[10/24] Train loss=0.16669054329395294
[15/24] Train loss=0.14253702759742737
[20/24] Train loss=0.14193719625473022
Test set avg_accuracy=82.50% avg_sensitivity=70.53%, avg_specificity=86.48% avg_auc=86.36%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.155654 Test loss=0.423317 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.15000100433826447
[5/24] Train loss=0.161487877368927
[10/24] Train loss=0.16716067492961884
[15/24] Train loss=0.1440640538930893
[20/24] Train loss=0.13936440646648407
Test set avg_accuracy=82.86% avg_sensitivity=68.81%, avg_specificity=87.54% avg_auc=86.27%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.154936 Test loss=0.417802 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13667914271354675
[5/24] Train loss=0.1562846153974533
[10/24] Train loss=0.15981970727443695
[15/24] Train loss=0.14156101644039154
[20/24] Train loss=0.13533765077590942
Test set avg_accuracy=83.54% avg_sensitivity=66.93%, avg_specificity=89.07% avg_auc=85.83%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.151880 Test loss=0.413486 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1339704394340515
[5/24] Train loss=0.1586955487728119
[10/24] Train loss=0.16490228474140167
[15/24] Train loss=0.14003534615039825
[20/24] Train loss=0.13581496477127075
Test set avg_accuracy=82.70% avg_sensitivity=65.62%, avg_specificity=88.37% avg_auc=85.85%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.150900 Test loss=0.415482 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13812492787837982
[5/24] Train loss=0.15272055566310883
[10/24] Train loss=0.16072513163089752
[15/24] Train loss=0.14261385798454285
[20/24] Train loss=0.13660192489624023
Test set avg_accuracy=82.98% avg_sensitivity=65.88%, avg_specificity=88.67% avg_auc=86.08%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.150074 Test loss=0.410730 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13633915781974792
[5/24] Train loss=0.15384796261787415
[10/24] Train loss=0.15946759283542633
[15/24] Train loss=0.14476443827152252
[20/24] Train loss=0.13221637904644012
Test set avg_accuracy=83.35% avg_sensitivity=65.52%, avg_specificity=89.28% avg_auc=85.63%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.148543 Test loss=0.416721 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13310113549232483
[5/24] Train loss=0.15330547094345093
[10/24] Train loss=0.15976282954216003
[15/24] Train loss=0.13703668117523193
[20/24] Train loss=0.13126210868358612
Test set avg_accuracy=83.36% avg_sensitivity=65.26%, avg_specificity=89.38% avg_auc=85.72%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.147602 Test loss=0.412332 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13514487445354462
[5/24] Train loss=0.15412946045398712
[10/24] Train loss=0.16261635720729828
[15/24] Train loss=0.13916638493537903
[20/24] Train loss=0.13241195678710938
Test set avg_accuracy=82.98% avg_sensitivity=65.88%, avg_specificity=88.67% avg_auc=85.98%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.148352 Test loss=0.411776 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13351821899414062
[5/24] Train loss=0.15317478775978088
[10/24] Train loss=0.15871360898017883
[15/24] Train loss=0.135792538523674
[20/24] Train loss=0.13303418457508087
Test set avg_accuracy=83.09% avg_sensitivity=65.94%, avg_specificity=88.79% avg_auc=85.62%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.147179 Test loss=0.414719 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1343313753604889
[5/24] Train loss=0.15489013493061066
[10/24] Train loss=0.16123232245445251
[15/24] Train loss=0.13807757198810577
[20/24] Train loss=0.13151419162750244
Test set avg_accuracy=83.01% avg_sensitivity=66.15%, avg_specificity=88.62% avg_auc=86.05%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.146973 Test loss=0.412725 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13197460770606995
[5/24] Train loss=0.1526186764240265
[10/24] Train loss=0.15901029109954834
[15/24] Train loss=0.13457199931144714
[20/24] Train loss=0.13192711770534515
Test set avg_accuracy=82.93% avg_sensitivity=66.20%, avg_specificity=88.50% avg_auc=85.83%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.145829 Test loss=0.417894 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13511298596858978
[5/24] Train loss=0.15076325833797455
[10/24] Train loss=0.15603168308734894
[15/24] Train loss=0.13364437222480774
[20/24] Train loss=0.1297338306903839
Test set avg_accuracy=83.11% avg_sensitivity=65.47%, avg_specificity=88.98% avg_auc=85.84%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.144784 Test loss=0.415635 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12833057343959808
[5/24] Train loss=0.14784809947013855
[10/24] Train loss=0.1573258638381958
[15/24] Train loss=0.13436344265937805
[20/24] Train loss=0.1298004686832428
Test set avg_accuracy=83.16% avg_sensitivity=65.31%, avg_specificity=89.10% avg_auc=85.90%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.144231 Test loss=0.414764 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12636256217956543
[5/24] Train loss=0.15022942423820496
[10/24] Train loss=0.15809565782546997
[15/24] Train loss=0.13387544453144073
[20/24] Train loss=0.13022249937057495
Test set avg_accuracy=83.15% avg_sensitivity=65.73%, avg_specificity=88.95% avg_auc=85.67%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.143306 Test loss=0.415169 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12770935893058777
[5/24] Train loss=0.14837123453617096
[10/24] Train loss=0.15264937281608582
[15/24] Train loss=0.13279801607131958
[20/24] Train loss=0.12965261936187744
Test set avg_accuracy=83.20% avg_sensitivity=65.05%, avg_specificity=89.24% avg_auc=86.08%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.142263 Test loss=0.411081 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12827716767787933
[5/24] Train loss=0.1477191001176834
[10/24] Train loss=0.1519637554883957
[15/24] Train loss=0.13383980095386505
[20/24] Train loss=0.1265946626663208
Test set avg_accuracy=83.14% avg_sensitivity=64.74%, avg_specificity=89.26% avg_auc=85.79%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.142058 Test loss=0.413537 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12854312360286713
[5/24] Train loss=0.1494140326976776
[10/24] Train loss=0.15485717356204987
[15/24] Train loss=0.13502797484397888
[20/24] Train loss=0.13152895867824554
Test set avg_accuracy=82.98% avg_sensitivity=64.89%, avg_specificity=89.00% avg_auc=85.73%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.142492 Test loss=0.415566 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12929630279541016
[5/24] Train loss=0.14782460033893585
[10/24] Train loss=0.1525244414806366
[15/24] Train loss=0.13262125849723816
[20/24] Train loss=0.12892833352088928
Test set avg_accuracy=83.14% avg_sensitivity=63.38%, avg_specificity=89.71% avg_auc=85.73%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.141731 Test loss=0.413554 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1279952973127365
[5/24] Train loss=0.14662110805511475
[10/24] Train loss=0.153489887714386
[15/24] Train loss=0.13332270085811615
[20/24] Train loss=0.12804734706878662
Test set avg_accuracy=82.84% avg_sensitivity=65.10%, avg_specificity=88.74% avg_auc=85.80%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.141637 Test loss=0.414132 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12722660601139069
[5/24] Train loss=0.14524313807487488
[10/24] Train loss=0.15124186873435974
[15/24] Train loss=0.133362278342247
[20/24] Train loss=0.1273430734872818
Test set avg_accuracy=83.05% avg_sensitivity=64.89%, avg_specificity=89.09% avg_auc=85.77%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.140533 Test loss=0.414915 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12759967148303986
[5/24] Train loss=0.14561322331428528
[10/24] Train loss=0.1552201807498932
[15/24] Train loss=0.13221322000026703
[20/24] Train loss=0.12719304859638214
Test set avg_accuracy=82.99% avg_sensitivity=64.42%, avg_specificity=89.17% avg_auc=85.86%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.141364 Test loss=0.414081 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12714174389839172
[5/24] Train loss=0.14510127902030945
[10/24] Train loss=0.15427915751934052
[15/24] Train loss=0.13196319341659546
[20/24] Train loss=0.12975822389125824
Test set avg_accuracy=82.92% avg_sensitivity=64.27%, avg_specificity=89.12% avg_auc=85.64%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.141430 Test loss=0.416580 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12823176383972168
[5/24] Train loss=0.1431436985731125
[10/24] Train loss=0.15292702615261078
[15/24] Train loss=0.13240237534046173
[20/24] Train loss=0.127999946475029
Test set avg_accuracy=82.92% avg_sensitivity=64.58%, avg_specificity=89.02% avg_auc=85.68%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.140438 Test loss=0.416457 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12341756373643875
[5/24] Train loss=0.14768238365650177
[10/24] Train loss=0.152643084526062
[15/24] Train loss=0.1323116570711136
[20/24] Train loss=0.12760193645954132
Test set avg_accuracy=82.90% avg_sensitivity=64.37%, avg_specificity=89.07% avg_auc=85.68%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.140540 Test loss=0.416252 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12547646462917328
[5/24] Train loss=0.14507199823856354
[10/24] Train loss=0.14963923394680023
[15/24] Train loss=0.13227689266204834
[20/24] Train loss=0.1264668107032776
Test set avg_accuracy=82.93% avg_sensitivity=64.63%, avg_specificity=89.02% avg_auc=85.66%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.140346 Test loss=0.416311 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12584859132766724
[5/24] Train loss=0.14495006203651428
[10/24] Train loss=0.1544916182756424
[15/24] Train loss=0.13201941549777985
[20/24] Train loss=0.1268661469221115
Test set avg_accuracy=82.86% avg_sensitivity=64.37%, avg_specificity=89.02% avg_auc=85.67%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.140421 Test loss=0.416887 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1267816573381424
[5/24] Train loss=0.14518415927886963
[10/24] Train loss=0.14795784652233124
[15/24] Train loss=0.13199001550674438
[20/24] Train loss=0.12835562229156494
Test set avg_accuracy=82.93% avg_sensitivity=64.68%, avg_specificity=89.00% avg_auc=85.69%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.140374 Test loss=0.416785 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12868747115135193
[5/24] Train loss=0.14436176419258118
[10/24] Train loss=0.15285752713680267
[15/24] Train loss=0.13272908329963684
[20/24] Train loss=0.12592291831970215
Test set avg_accuracy=82.89% avg_sensitivity=64.42%, avg_specificity=89.03% avg_auc=85.70%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.139580 Test loss=0.416368 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12450260668992996
[5/24] Train loss=0.14791876077651978
[10/24] Train loss=0.1504008173942566
[15/24] Train loss=0.1333826333284378
[20/24] Train loss=0.12436878681182861
Test set avg_accuracy=82.92% avg_sensitivity=64.27%, avg_specificity=89.12% avg_auc=85.69%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.140052 Test loss=0.416428 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12541541457176208
[5/24] Train loss=0.1433853805065155
[10/24] Train loss=0.1502089649438858
[15/24] Train loss=0.13497820496559143
[20/24] Train loss=0.12401788681745529
Test set avg_accuracy=82.94% avg_sensitivity=64.42%, avg_specificity=89.10% avg_auc=85.72%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.139923 Test loss=0.416530 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12652282416820526
[5/24] Train loss=0.14449314773082733
[10/24] Train loss=0.15156462788581848
[15/24] Train loss=0.13044174015522003
[20/24] Train loss=0.12886671721935272
Test set avg_accuracy=82.98% avg_sensitivity=64.48%, avg_specificity=89.14% avg_auc=85.72%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.139794 Test loss=0.416152 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12474362552165985
[5/24] Train loss=0.14504952728748322
[10/24] Train loss=0.15017570555210114
[15/24] Train loss=0.130595400929451
[20/24] Train loss=0.1265331655740738
Test set avg_accuracy=82.96% avg_sensitivity=64.37%, avg_specificity=89.14% avg_auc=85.69%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.139795 Test loss=0.416557 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=84.26% sen=68.70%, spe=89.43%, auc=89.48%!
Fold[2] Avg_overlap=0.65%(±0.25339279060974357)
[0/24] Train loss=0.7495751976966858
[5/24] Train loss=0.74076247215271
[10/24] Train loss=0.73824542760849
[15/24] Train loss=0.7271170616149902
[20/24] Train loss=0.7308048605918884
Test set avg_accuracy=51.47% avg_sensitivity=49.91%, avg_specificity=52.06% avg_auc=51.84%
Best model saved!! Metric=-120.72097610637698!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.742322 Test loss=0.701208 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7274131178855896
[5/24] Train loss=0.7231557369232178
[10/24] Train loss=0.7211269736289978
[15/24] Train loss=0.7207648158073425
[20/24] Train loss=0.7134543657302856
Test set avg_accuracy=57.96% avg_sensitivity=40.85%, avg_specificity=64.43% avg_auc=54.47%
Best model saved!! Metric=-108.28311807694544!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.722118 Test loss=0.663665 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7067340016365051
[5/24] Train loss=0.706062376499176
[10/24] Train loss=0.7002189755439758
[15/24] Train loss=0.7046357989311218
[20/24] Train loss=0.6835035681724548
Test set avg_accuracy=62.25% avg_sensitivity=34.93%, avg_specificity=72.60% avg_auc=57.64%
Best model saved!! Metric=-98.57221055675859!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.703282 Test loss=0.637622 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.688099205493927
[5/24] Train loss=0.6957204341888428
[10/24] Train loss=0.6863773465156555
[15/24] Train loss=0.6924629807472229
[20/24] Train loss=0.6659121513366699
Test set avg_accuracy=69.41% avg_sensitivity=30.76%, avg_specificity=84.06% avg_auc=61.05%
Best model saved!! Metric=-80.72400364650251!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.685789 Test loss=0.617409 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.671718180179596
[5/24] Train loss=0.6693509817123413
[10/24] Train loss=0.6711432933807373
[15/24] Train loss=0.6690096855163574
[20/24] Train loss=0.6554933190345764
Test set avg_accuracy=71.41% avg_sensitivity=30.66%, avg_specificity=86.84% avg_auc=64.86%
Best model saved!! Metric=-72.22861262731118!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.665532 Test loss=0.595435 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6382788419723511
[5/24] Train loss=0.6482303142547607
[10/24] Train loss=0.6469061374664307
[15/24] Train loss=0.6460248827934265
[20/24] Train loss=0.6261461973190308
Test set avg_accuracy=73.15% avg_sensitivity=34.45%, avg_specificity=87.81% avg_auc=68.97%
Best model saved!! Metric=-61.61422078366388!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.641526 Test loss=0.572074 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6200553178787231
[5/24] Train loss=0.619695246219635
[10/24] Train loss=0.6161941885948181
[15/24] Train loss=0.6181640028953552
[20/24] Train loss=0.6052988171577454
Test set avg_accuracy=73.79% avg_sensitivity=38.77%, avg_specificity=87.06% avg_auc=72.53%
Best model saved!! Metric=-53.85586164509005!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.615268 Test loss=0.548433 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5896741151809692
[5/24] Train loss=0.59591144323349
[10/24] Train loss=0.5874428749084473
[15/24] Train loss=0.5940484404563904
[20/24] Train loss=0.5730129480361938
Test set avg_accuracy=75.00% avg_sensitivity=45.21%, avg_specificity=86.28% avg_auc=75.35%
Best model saved!! Metric=-44.149718788023165!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.587508 Test loss=0.527350 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5597943663597107
[5/24] Train loss=0.5663530826568604
[10/24] Train loss=0.560426652431488
[15/24] Train loss=0.566288948059082
[20/24] Train loss=0.546307384967804
Test set avg_accuracy=75.86% avg_sensitivity=48.44%, avg_specificity=86.25% avg_auc=77.37%
Best model saved!! Metric=-38.0885773854093!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.560914 Test loss=0.507882 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5332841277122498
[5/24] Train loss=0.5381468534469604
[10/24] Train loss=0.5383429527282715
[15/24] Train loss=0.550693929195404
[20/24] Train loss=0.5183549523353577
Test set avg_accuracy=76.43% avg_sensitivity=48.91%, avg_specificity=86.86% avg_auc=78.82%
Best model saved!! Metric=-34.97724401449598!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.538705 Test loss=0.492431 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5107037425041199
[5/24] Train loss=0.5206365585327148
[10/24] Train loss=0.531051754951477
[15/24] Train loss=0.5248365998268127
[20/24] Train loss=0.492746502161026
Test set avg_accuracy=77.20% avg_sensitivity=50.47%, avg_specificity=87.32% avg_auc=80.16%
Best model saved!! Metric=-30.840125145888457!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.516682 Test loss=0.480643 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.48872679471969604
[5/24] Train loss=0.4956223964691162
[10/24] Train loss=0.5060857534408569
[15/24] Train loss=0.5121043920516968
[20/24] Train loss=0.47662514448165894
Test set avg_accuracy=77.51% avg_sensitivity=50.24%, avg_specificity=87.85% avg_auc=80.90%
Best model saved!! Metric=-29.50077599633135!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.497464 Test loss=0.469669 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.46895506978034973
[5/24] Train loss=0.4787420630455017
[10/24] Train loss=0.4960724115371704
[15/24] Train loss=0.4965430200099945
[20/24] Train loss=0.4584049582481384
Test set avg_accuracy=77.77% avg_sensitivity=49.81%, avg_specificity=88.37% avg_auc=81.73%
Best model saved!! Metric=-28.320851471895843!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.480737 Test loss=0.460937 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.44953370094299316
[5/24] Train loss=0.4671548306941986
[10/24] Train loss=0.48384663462638855
[15/24] Train loss=0.4813993573188782
[20/24] Train loss=0.4381607174873352
Test set avg_accuracy=77.99% avg_sensitivity=49.38%, avg_specificity=88.83% avg_auc=82.40%
Best model saved!! Metric=-27.392110917420396!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.464896 Test loss=0.451741 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4346737265586853
[5/24] Train loss=0.4473998546600342
[10/24] Train loss=0.4720170497894287
[15/24] Train loss=0.47096991539001465
[20/24] Train loss=0.42674681544303894
Test set avg_accuracy=78.35% avg_sensitivity=49.72%, avg_specificity=89.19% avg_auc=83.37%
Best model saved!! Metric=-25.37239131309544!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.451246 Test loss=0.441809 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.41853252053260803
[5/24] Train loss=0.4362409710884094
[10/24] Train loss=0.4590092599391937
[15/24] Train loss=0.4590018391609192
[20/24] Train loss=0.4125078022480011
Test set avg_accuracy=78.57% avg_sensitivity=48.10%, avg_specificity=90.11% avg_auc=83.80%
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.438074 Test loss=0.437258 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4119548201560974
[5/24] Train loss=0.42829301953315735
[10/24] Train loss=0.45289918780326843
[15/24] Train loss=0.44967469573020935
[20/24] Train loss=0.399992436170578
Test set avg_accuracy=78.89% avg_sensitivity=47.73%, avg_specificity=90.70% avg_auc=84.31%
Best model saved!! Metric=-24.373330857838347!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.427878 Test loss=0.432223 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.39651262760162354
[5/24] Train loss=0.42179736495018005
[10/24] Train loss=0.4369350075721741
[15/24] Train loss=0.44011837244033813
[20/24] Train loss=0.3918917179107666
Test set avg_accuracy=80.30% avg_sensitivity=55.97%, avg_specificity=89.52% avg_auc=85.38%
Best model saved!! Metric=-14.834421979452955!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.418507 Test loss=0.417240 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3870830833911896
[5/24] Train loss=0.40098872780799866
[10/24] Train loss=0.43263259530067444
[15/24] Train loss=0.4348861873149872
[20/24] Train loss=0.3874935209751129
Test set avg_accuracy=80.56% avg_sensitivity=54.31%, avg_specificity=90.50% avg_auc=85.46%
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.409174 Test loss=0.415996 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3774380683898926
[5/24] Train loss=0.39721131324768066
[10/24] Train loss=0.4267290234565735
[15/24] Train loss=0.42009711265563965
[20/24] Train loss=0.37662026286125183
Test set avg_accuracy=81.00% avg_sensitivity=60.09%, avg_specificity=88.92% avg_auc=86.55%
Best model saved!! Metric=-9.424812512053961!!
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.398436 Test loss=0.402339 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.365741103887558
[5/24] Train loss=0.3914029002189636
[10/24] Train loss=0.4197608530521393
[15/24] Train loss=0.41615474224090576
[20/24] Train loss=0.36707863211631775
Test set avg_accuracy=80.96% avg_sensitivity=65.88%, avg_specificity=86.68% avg_auc=86.13%
Best model saved!! Metric=-6.346965706107241!!
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.392596 Test loss=0.410353 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3641579747200012
[5/24] Train loss=0.384414404630661
[10/24] Train loss=0.40737205743789673
[15/24] Train loss=0.41134148836135864
[20/24] Train loss=0.35794928669929504
Test set avg_accuracy=81.22% avg_sensitivity=68.34%, avg_specificity=86.10% avg_auc=86.87%
Best model saved!! Metric=-3.461416091266969!!
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.386208 Test loss=0.402758 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3570185601711273
[5/24] Train loss=0.37875959277153015
[10/24] Train loss=0.3983914852142334
[15/24] Train loss=0.39297041296958923
[20/24] Train loss=0.35460537672042847
Test set avg_accuracy=82.11% avg_sensitivity=66.35%, avg_specificity=88.08% avg_auc=87.34%
Best model saved!! Metric=-2.1211464971878797!!
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.378469 Test loss=0.392011 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.345160573720932
[5/24] Train loss=0.3722016513347626
[10/24] Train loss=0.40455490350723267
[15/24] Train loss=0.38572224974632263
[20/24] Train loss=0.3389338552951813
Test set avg_accuracy=82.50% avg_sensitivity=66.26%, avg_specificity=88.65% avg_auc=87.91%
Best model saved!! Metric=-0.6836088728547338!!
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.366691 Test loss=0.385348 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.33683016896247864
[5/24] Train loss=0.35823854804039
[10/24] Train loss=0.38797634840011597
[15/24] Train loss=0.38230520486831665
[20/24] Train loss=0.3332388699054718
Test set avg_accuracy=83.24% avg_sensitivity=66.35%, avg_specificity=89.64% avg_auc=88.59%
Best model saved!! Metric=1.8194676143566966!!
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.359847 Test loss=0.373557 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.32821524143218994
[5/24] Train loss=0.3537150025367737
[10/24] Train loss=0.38662174344062805
[15/24] Train loss=0.3756870925426483
[20/24] Train loss=0.32083266973495483
Test set avg_accuracy=83.09% avg_sensitivity=58.67%, avg_specificity=92.33% avg_auc=88.68%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.352802 Test loss=0.374754 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.32629895210266113
[5/24] Train loss=0.3423599600791931
[10/24] Train loss=0.38648664951324463
[15/24] Train loss=0.37271806597709656
[20/24] Train loss=0.31329333782196045
Test set avg_accuracy=83.54% avg_sensitivity=66.11%, avg_specificity=90.14% avg_auc=89.05%
Best model saved!! Metric=2.850063886029048!!
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.349672 Test loss=0.367495 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3182116448879242
[5/24] Train loss=0.3400253355503082
[10/24] Train loss=0.3817722499370575
[15/24] Train loss=0.36910706758499146
[20/24] Train loss=0.31009700894355774
Test set avg_accuracy=83.93% avg_sensitivity=61.75%, avg_specificity=92.33% avg_auc=89.90%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.343861 Test loss=0.357261 Current lr=[0.000210185142098938]

[0/24] Train loss=0.31432458758354187
[5/24] Train loss=0.3504405617713928
[10/24] Train loss=0.3777572214603424
[15/24] Train loss=0.3545829951763153
[20/24] Train loss=0.3062388598918915
Test set avg_accuracy=84.28% avg_sensitivity=59.19%, avg_specificity=93.79% avg_auc=90.40%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.339789 Test loss=0.352113 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3051615357398987
[5/24] Train loss=0.3348436653614044
[10/24] Train loss=0.37233611941337585
[15/24] Train loss=0.3583033084869385
[20/24] Train loss=0.2984551191329956
Test set avg_accuracy=83.91% avg_sensitivity=56.02%, avg_specificity=94.47% avg_auc=90.40%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.332421 Test loss=0.358785 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.31591323018074036
[5/24] Train loss=0.3263002038002014
[10/24] Train loss=0.37992310523986816
[15/24] Train loss=0.35528552532196045
[20/24] Train loss=0.2959384024143219
Test set avg_accuracy=85.10% avg_sensitivity=60.43%, avg_specificity=94.45% avg_auc=90.75%
Best model saved!! Metric=4.730792888726285!!
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.331862 Test loss=0.344452 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3000214397907257
[5/24] Train loss=0.3446408212184906
[10/24] Train loss=0.3717060983181
[15/24] Train loss=0.3590031564235687
[20/24] Train loss=0.29057735204696655
Test set avg_accuracy=85.56% avg_sensitivity=64.83%, avg_specificity=93.41% avg_auc=90.91%
Best model saved!! Metric=8.718387073644067!!
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.328007 Test loss=0.337992 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3013451397418976
[5/24] Train loss=0.3277260661125183
[10/24] Train loss=0.37612754106521606
[15/24] Train loss=0.3532775342464447
[20/24] Train loss=0.2850549817085266
Test set avg_accuracy=84.49% avg_sensitivity=55.59%, avg_specificity=95.44% avg_auc=90.96%
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.322094 Test loss=0.349388 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2899548411369324
[5/24] Train loss=0.3243779242038727
[10/24] Train loss=0.35204342007637024
[15/24] Train loss=0.3487693965435028
[20/24] Train loss=0.280719131231308
Test set avg_accuracy=85.08% avg_sensitivity=62.65%, avg_specificity=93.57% avg_auc=90.59%
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.318443 Test loss=0.342393 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3034133315086365
[5/24] Train loss=0.33067768812179565
[10/24] Train loss=0.36508113145828247
[15/24] Train loss=0.3579593300819397
[20/24] Train loss=0.279461145401001
Test set avg_accuracy=84.24% avg_sensitivity=57.25%, avg_specificity=94.47% avg_auc=89.48%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.318437 Test loss=0.362688 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2905817925930023
[5/24] Train loss=0.3287678062915802
[10/24] Train loss=0.341238796710968
[15/24] Train loss=0.33590248227119446
[20/24] Train loss=0.28450366854667664
Test set avg_accuracy=84.22% avg_sensitivity=53.08%, avg_specificity=96.01% avg_auc=90.09%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.314243 Test loss=0.362067 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2916730046272278
[5/24] Train loss=0.32867947220802307
[10/24] Train loss=0.35024455189704895
[15/24] Train loss=0.33101168274879456
[20/24] Train loss=0.26546889543533325
Test set avg_accuracy=82.72% avg_sensitivity=45.26%, avg_specificity=96.91% avg_auc=88.98%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.311823 Test loss=0.395455 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.29196181893348694
[5/24] Train loss=0.31183063983917236
[10/24] Train loss=0.34093913435935974
[15/24] Train loss=0.3442261517047882
[20/24] Train loss=0.2719131112098694
Test set avg_accuracy=85.25% avg_sensitivity=57.77%, avg_specificity=95.66% avg_auc=91.32%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.308519 Test loss=0.339368 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.27977514266967773
[5/24] Train loss=0.3186846673488617
[10/24] Train loss=0.3505161702632904
[15/24] Train loss=0.32897984981536865
[20/24] Train loss=0.27018046379089355
Test set avg_accuracy=84.61% avg_sensitivity=56.21%, avg_specificity=95.37% avg_auc=90.21%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.305899 Test loss=0.357454 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2842666804790497
[5/24] Train loss=0.3097270429134369
[10/24] Train loss=0.33650022745132446
[15/24] Train loss=0.3234751224517822
[20/24] Train loss=0.2618197202682495
Test set avg_accuracy=84.06% avg_sensitivity=52.46%, avg_specificity=96.03% avg_auc=90.62%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.301732 Test loss=0.357187 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.28108280897140503
[5/24] Train loss=0.3047221302986145
[10/24] Train loss=0.34724316000938416
[15/24] Train loss=0.32294076681137085
[20/24] Train loss=0.2634519338607788
Test set avg_accuracy=83.32% avg_sensitivity=51.33%, avg_specificity=95.44% avg_auc=89.60%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.301303 Test loss=0.371405 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.29107123613357544
[5/24] Train loss=0.30827295780181885
[10/24] Train loss=0.3317033350467682
[15/24] Train loss=0.32287275791168213
[20/24] Train loss=0.2728741765022278
Test set avg_accuracy=83.24% avg_sensitivity=48.53%, avg_specificity=96.39% avg_auc=88.35%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.298611 Test loss=0.389754 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2715902030467987
[5/24] Train loss=0.31037694215774536
[10/24] Train loss=0.3450160622596741
[15/24] Train loss=0.3283695578575134
[20/24] Train loss=0.2582850456237793
Test set avg_accuracy=82.07% avg_sensitivity=42.84%, avg_specificity=96.93% avg_auc=88.30%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.298256 Test loss=0.408587 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.28015467524528503
[5/24] Train loss=0.30374476313591003
[10/24] Train loss=0.33269110321998596
[15/24] Train loss=0.32156094908714294
[20/24] Train loss=0.2631344497203827
Test set avg_accuracy=84.47% avg_sensitivity=52.99%, avg_specificity=96.39% avg_auc=90.23%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.294952 Test loss=0.363252 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2703689634799957
[5/24] Train loss=0.303587943315506
[10/24] Train loss=0.32846981287002563
[15/24] Train loss=0.3207720220088959
[20/24] Train loss=0.26266977190971375
Test set avg_accuracy=85.43% avg_sensitivity=58.10%, avg_specificity=95.78% avg_auc=91.69%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.292742 Test loss=0.334661 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.26076698303222656
[5/24] Train loss=0.2968079447746277
[10/24] Train loss=0.32669660449028015
[15/24] Train loss=0.3205510079860687
[20/24] Train loss=0.256169855594635
Test set avg_accuracy=84.09% avg_sensitivity=50.47%, avg_specificity=96.82% avg_auc=90.96%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.286084 Test loss=0.358281 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2678212523460388
[5/24] Train loss=0.29773128032684326
[10/24] Train loss=0.3172585666179657
[15/24] Train loss=0.3001912534236908
[20/24] Train loss=0.25604620575904846
Test set avg_accuracy=84.35% avg_sensitivity=51.00%, avg_specificity=96.98% avg_auc=91.01%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.287240 Test loss=0.360311 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2729209065437317
[5/24] Train loss=0.285456120967865
[10/24] Train loss=0.33028459548950195
[15/24] Train loss=0.3117614686489105
[20/24] Train loss=0.24803581833839417
Test set avg_accuracy=85.40% avg_sensitivity=58.77%, avg_specificity=95.49% avg_auc=91.47%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.284624 Test loss=0.334257 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.25922855734825134
[5/24] Train loss=0.29026180505752563
[10/24] Train loss=0.318623811006546
[15/24] Train loss=0.31152641773223877
[20/24] Train loss=0.24534928798675537
Test set avg_accuracy=84.82% avg_sensitivity=56.87%, avg_specificity=95.40% avg_auc=91.00%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.283319 Test loss=0.346860 Current lr=[0.000298904600941902]

[0/24] Train loss=0.26686981320381165
[5/24] Train loss=0.2855110764503479
[10/24] Train loss=0.3109331727027893
[15/24] Train loss=0.3031300902366638
[20/24] Train loss=0.24540475010871887
Test set avg_accuracy=85.29% avg_sensitivity=61.09%, avg_specificity=94.45% avg_auc=91.21%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.279065 Test loss=0.333729 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.24873846769332886
[5/24] Train loss=0.27092280983924866
[10/24] Train loss=0.3192204236984253
[15/24] Train loss=0.30961111187934875
[20/24] Train loss=0.24146872758865356
Test set avg_accuracy=85.43% avg_sensitivity=58.86%, avg_specificity=95.49% avg_auc=90.95%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.278137 Test loss=0.342009 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2597014605998993
[5/24] Train loss=0.2846843898296356
[10/24] Train loss=0.30524390935897827
[15/24] Train loss=0.31254246830940247
[20/24] Train loss=0.2451484650373459
Test set avg_accuracy=85.55% avg_sensitivity=58.72%, avg_specificity=95.71% avg_auc=91.84%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.278621 Test loss=0.327506 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.24780844151973724
[5/24] Train loss=0.2660679519176483
[10/24] Train loss=0.31182214617729187
[15/24] Train loss=0.3083050549030304
[20/24] Train loss=0.23617182672023773
Test set avg_accuracy=86.02% avg_sensitivity=65.78%, avg_specificity=93.68% avg_auc=91.55%
Best model saved!! Metric=11.026133223642233!!
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.274489 Test loss=0.326328 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2511371970176697
[5/24] Train loss=0.27476876974105835
[10/24] Train loss=0.31321588158607483
[15/24] Train loss=0.3088517487049103
[20/24] Train loss=0.24304521083831787
Test set avg_accuracy=85.87% avg_sensitivity=64.27%, avg_specificity=94.06% avg_auc=92.28%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.275544 Test loss=0.316162 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.25370144844055176
[5/24] Train loss=0.27000969648361206
[10/24] Train loss=0.29904302954673767
[15/24] Train loss=0.29976770281791687
[20/24] Train loss=0.23561908304691315
Test set avg_accuracy=86.03% avg_sensitivity=65.55%, avg_specificity=93.79% avg_auc=91.82%
Best model saved!! Metric=11.178747512096493!!
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.271825 Test loss=0.322853 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.24477620422840118
[5/24] Train loss=0.2755091190338135
[10/24] Train loss=0.30321556329727173
[15/24] Train loss=0.3116097152233124
[20/24] Train loss=0.24132037162780762
Test set avg_accuracy=85.74% avg_sensitivity=70.00%, avg_specificity=91.71% avg_auc=91.47%
Best model saved!! Metric=12.922197199898747!!
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.270681 Test loss=0.326499 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.24146118760108948
[5/24] Train loss=0.2589700520038605
[10/24] Train loss=0.2959248125553131
[15/24] Train loss=0.29737588763237
[20/24] Train loss=0.23066148161888123
Test set avg_accuracy=86.48% avg_sensitivity=69.57%, avg_specificity=92.89% avg_auc=92.41%
Best model saved!! Metric=15.36133093353017!!
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.267484 Test loss=0.309507 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.23832917213439941
[5/24] Train loss=0.255180686712265
[10/24] Train loss=0.2947658598423004
[15/24] Train loss=0.29769864678382874
[20/24] Train loss=0.23539318144321442
Test set avg_accuracy=86.26% avg_sensitivity=71.14%, avg_specificity=91.99% avg_auc=91.95%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.263853 Test loss=0.319093 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2437192052602768
[5/24] Train loss=0.25707846879959106
[10/24] Train loss=0.2931104302406311
[15/24] Train loss=0.28589415550231934
[20/24] Train loss=0.23699989914894104
Test set avg_accuracy=86.08% avg_sensitivity=73.22%, avg_specificity=90.95% avg_auc=91.80%
Best model saved!! Metric=16.05277388830511!!
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.263661 Test loss=0.321272 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.24084597826004028
[5/24] Train loss=0.25645941495895386
[10/24] Train loss=0.29935145378112793
[15/24] Train loss=0.2906014919281006
[20/24] Train loss=0.23304764926433563
Test set avg_accuracy=84.69% avg_sensitivity=57.68%, avg_specificity=94.92% avg_auc=90.95%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.263371 Test loss=0.346614 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2419222742319107
[5/24] Train loss=0.25081226229667664
[10/24] Train loss=0.3056091368198395
[15/24] Train loss=0.2811566889286041
[20/24] Train loss=0.23475991189479828
Test set avg_accuracy=85.59% avg_sensitivity=74.27%, avg_specificity=89.87% avg_auc=91.45%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.259516 Test loss=0.334264 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.23713946342468262
[5/24] Train loss=0.25698962807655334
[10/24] Train loss=0.2803473174571991
[15/24] Train loss=0.27441197633743286
[20/24] Train loss=0.22661148011684418
Test set avg_accuracy=85.18% avg_sensitivity=68.25%, avg_specificity=91.60% avg_auc=89.42%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.253828 Test loss=0.352510 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.23411279916763306
[5/24] Train loss=0.2656233310699463
[10/24] Train loss=0.29530513286590576
[15/24] Train loss=0.28230413794517517
[20/24] Train loss=0.22207783162593842
Test set avg_accuracy=85.26% avg_sensitivity=73.60%, avg_specificity=89.68% avg_auc=91.69%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.255672 Test loss=0.331321 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.23497116565704346
[5/24] Train loss=0.2506905496120453
[10/24] Train loss=0.2815193831920624
[15/24] Train loss=0.26869910955429077
[20/24] Train loss=0.231654092669487
Test set avg_accuracy=85.70% avg_sensitivity=69.95%, avg_specificity=91.67% avg_auc=91.63%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.252067 Test loss=0.323852 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2416781485080719
[5/24] Train loss=0.24503524601459503
[10/24] Train loss=0.2788238227367401
[15/24] Train loss=0.2802545428276062
[20/24] Train loss=0.22586150467395782
Test set avg_accuracy=84.75% avg_sensitivity=72.70%, avg_specificity=89.32% avg_auc=91.09%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.251487 Test loss=0.341853 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.23473785817623138
[5/24] Train loss=0.2549044191837311
[10/24] Train loss=0.27110210061073303
[15/24] Train loss=0.2768596112728119
[20/24] Train loss=0.22817158699035645
Test set avg_accuracy=84.74% avg_sensitivity=71.52%, avg_specificity=89.75% avg_auc=90.33%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.249218 Test loss=0.350479 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.23596350848674774
[5/24] Train loss=0.2353145182132721
[10/24] Train loss=0.2718196511268616
[15/24] Train loss=0.276528000831604
[20/24] Train loss=0.2343091070652008
Test set avg_accuracy=85.68% avg_sensitivity=71.04%, avg_specificity=91.22% avg_auc=91.44%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.249283 Test loss=0.329853 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.22594532370567322
[5/24] Train loss=0.2458871454000473
[10/24] Train loss=0.26087427139282227
[15/24] Train loss=0.2858275771141052
[20/24] Train loss=0.2252548635005951
Test set avg_accuracy=85.22% avg_sensitivity=65.02%, avg_specificity=92.87% avg_auc=90.10%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.244916 Test loss=0.343661 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.22371061146259308
[5/24] Train loss=0.23362594842910767
[10/24] Train loss=0.2633815109729767
[15/24] Train loss=0.2665620744228363
[20/24] Train loss=0.21422886848449707
Test set avg_accuracy=84.86% avg_sensitivity=73.79%, avg_specificity=89.05% avg_auc=91.49%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.242515 Test loss=0.334556 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.22773708403110504
[5/24] Train loss=0.22685198485851288
[10/24] Train loss=0.2648138105869293
[15/24] Train loss=0.2629093825817108
[20/24] Train loss=0.21387110650539398
Test set avg_accuracy=84.74% avg_sensitivity=79.91%, avg_specificity=86.57% avg_auc=91.56%
Best model saved!! Metric=16.7806334750029!!
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.237364 Test loss=0.350665 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.2178589403629303
[5/24] Train loss=0.23109129071235657
[10/24] Train loss=0.27550065517425537
[15/24] Train loss=0.26977866888046265
[20/24] Train loss=0.22120679914951324
Test set avg_accuracy=84.73% avg_sensitivity=76.35%, avg_specificity=87.90% avg_auc=91.61%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.238946 Test loss=0.338787 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.21671722829341888
[5/24] Train loss=0.22417359054088593
[10/24] Train loss=0.2589187026023865
[15/24] Train loss=0.2612670361995697
[20/24] Train loss=0.22441697120666504
Test set avg_accuracy=85.09% avg_sensitivity=72.99%, avg_specificity=89.68% avg_auc=91.60%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.235947 Test loss=0.333080 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2116301953792572
[5/24] Train loss=0.21991100907325745
[10/24] Train loss=0.2601796090602875
[15/24] Train loss=0.2613280117511749
[20/24] Train loss=0.22298108041286469
Test set avg_accuracy=84.17% avg_sensitivity=77.54%, avg_specificity=86.68% avg_auc=91.65%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.235404 Test loss=0.345049 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.21910013258457184
[5/24] Train loss=0.22131507098674774
[10/24] Train loss=0.27097010612487793
[15/24] Train loss=0.26888880133628845
[20/24] Train loss=0.22539134323596954
Test set avg_accuracy=83.22% avg_sensitivity=80.05%, avg_specificity=84.42% avg_auc=90.65%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.234493 Test loss=0.374186 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.21517986059188843
[5/24] Train loss=0.2396530658006668
[10/24] Train loss=0.2582477033138275
[15/24] Train loss=0.2636618912220001
[20/24] Train loss=0.2285773754119873
Test set avg_accuracy=84.87% avg_sensitivity=72.65%, avg_specificity=89.50% avg_auc=91.32%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.234464 Test loss=0.337672 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.21492013335227966
[5/24] Train loss=0.2184482365846634
[10/24] Train loss=0.2546423077583313
[15/24] Train loss=0.24226266145706177
[20/24] Train loss=0.21973608434200287
Test set avg_accuracy=83.80% avg_sensitivity=78.77%, avg_specificity=85.71% avg_auc=89.90%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.227263 Test loss=0.379975 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.21912357211112976
[5/24] Train loss=0.219909206032753
[10/24] Train loss=0.2450735867023468
[15/24] Train loss=0.24496197700500488
[20/24] Train loss=0.21129336953163147
Test set avg_accuracy=85.12% avg_sensitivity=75.59%, avg_specificity=88.73% avg_auc=90.89%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.225588 Test loss=0.348325 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.21730655431747437
[5/24] Train loss=0.21359972655773163
[10/24] Train loss=0.2578582465648651
[15/24] Train loss=0.2523537874221802
[20/24] Train loss=0.21871767938137054
Test set avg_accuracy=85.85% avg_sensitivity=71.14%, avg_specificity=91.42% avg_auc=90.59%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.226534 Test loss=0.339691 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2077108472585678
[5/24] Train loss=0.21132473647594452
[10/24] Train loss=0.26364201307296753
[15/24] Train loss=0.24096538126468658
[20/24] Train loss=0.21450695395469666
Test set avg_accuracy=84.97% avg_sensitivity=71.94%, avg_specificity=89.91% avg_auc=90.67%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.225511 Test loss=0.348442 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.22067315876483917
[5/24] Train loss=0.21230050921440125
[10/24] Train loss=0.2540570795536041
[15/24] Train loss=0.24704156816005707
[20/24] Train loss=0.204232320189476
Test set avg_accuracy=85.38% avg_sensitivity=75.64%, avg_specificity=89.07% avg_auc=91.42%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.222030 Test loss=0.341283 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2039804607629776
[5/24] Train loss=0.20172040164470673
[10/24] Train loss=0.2480013370513916
[15/24] Train loss=0.23510733246803284
[20/24] Train loss=0.20641762018203735
Test set avg_accuracy=84.28% avg_sensitivity=76.87%, avg_specificity=87.09% avg_auc=90.79%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.218184 Test loss=0.357096 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.19779734313488007
[5/24] Train loss=0.19836531579494476
[10/24] Train loss=0.2477824091911316
[15/24] Train loss=0.24486412107944489
[20/24] Train loss=0.20713435113430023
Test set avg_accuracy=84.49% avg_sensitivity=74.17%, avg_specificity=88.40% avg_auc=90.77%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.217605 Test loss=0.350611 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.19527316093444824
[5/24] Train loss=0.20309819281101227
[10/24] Train loss=0.25349387526512146
[15/24] Train loss=0.23973259329795837
[20/24] Train loss=0.21084024012088776
Test set avg_accuracy=84.77% avg_sensitivity=73.79%, avg_specificity=88.92% avg_auc=90.74%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.217146 Test loss=0.350084 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1953486204147339
[5/24] Train loss=0.2023497223854065
[10/24] Train loss=0.24709850549697876
[15/24] Train loss=0.2330944538116455
[20/24] Train loss=0.20790807902812958
Test set avg_accuracy=85.89% avg_sensitivity=73.13%, avg_specificity=90.72% avg_auc=91.17%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.215665 Test loss=0.340108 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.1964191198348999
[5/24] Train loss=0.21093951165676117
[10/24] Train loss=0.23599396646022797
[15/24] Train loss=0.23150840401649475
[20/24] Train loss=0.1968594640493393
Test set avg_accuracy=84.99% avg_sensitivity=64.93%, avg_specificity=92.59% avg_auc=89.70%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.210673 Test loss=0.356581 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.19774438440799713
[5/24] Train loss=0.21157678961753845
[10/24] Train loss=0.23443205654621124
[15/24] Train loss=0.23405581712722778
[20/24] Train loss=0.20876656472682953
Test set avg_accuracy=85.56% avg_sensitivity=70.47%, avg_specificity=91.27% avg_auc=90.54%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.209847 Test loss=0.348687 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1946759968996048
[5/24] Train loss=0.19258327782154083
[10/24] Train loss=0.23114092648029327
[15/24] Train loss=0.22338727116584778
[20/24] Train loss=0.18858706951141357
Test set avg_accuracy=85.23% avg_sensitivity=69.29%, avg_specificity=91.27% avg_auc=90.30%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.202898 Test loss=0.351803 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1907825618982315
[5/24] Train loss=0.18702483177185059
[10/24] Train loss=0.22602613270282745
[15/24] Train loss=0.22595378756523132
[20/24] Train loss=0.19548706710338593
Test set avg_accuracy=84.86% avg_sensitivity=68.15%, avg_specificity=91.18% avg_auc=89.91%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.201025 Test loss=0.353702 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1930244266986847
[5/24] Train loss=0.17538456618785858
[10/24] Train loss=0.2302841991186142
[15/24] Train loss=0.2187357097864151
[20/24] Train loss=0.1999916434288025
Test set avg_accuracy=85.38% avg_sensitivity=70.90%, avg_specificity=90.86% avg_auc=89.85%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.198450 Test loss=0.354937 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.19042129814624786
[5/24] Train loss=0.1792009472846985
[10/24] Train loss=0.22125256061553955
[15/24] Train loss=0.22170424461364746
[20/24] Train loss=0.19341816008090973
Test set avg_accuracy=84.48% avg_sensitivity=58.20%, avg_specificity=94.43% avg_auc=88.34%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.198218 Test loss=0.383276 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1939588040113449
[5/24] Train loss=0.19245897233486176
[10/24] Train loss=0.22030892968177795
[15/24] Train loss=0.2193135768175125
[20/24] Train loss=0.19440454244613647
Test set avg_accuracy=84.90% avg_sensitivity=60.09%, avg_specificity=94.29% avg_auc=88.77%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.200346 Test loss=0.373163 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.19930274784564972
[5/24] Train loss=0.18414007127285004
[10/24] Train loss=0.22477500140666962
[15/24] Train loss=0.21936821937561035
[20/24] Train loss=0.19624857604503632
Test set avg_accuracy=80.29% avg_sensitivity=35.50%, avg_specificity=97.25% avg_auc=85.54%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.199514 Test loss=0.494095 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.19874709844589233
[5/24] Train loss=0.1960199773311615
[10/24] Train loss=0.2146449238061905
[15/24] Train loss=0.22400768101215363
[20/24] Train loss=0.19304460287094116
Test set avg_accuracy=84.10% avg_sensitivity=52.23%, avg_specificity=96.18% avg_auc=87.74%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.196807 Test loss=0.401702 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.198850616812706
[5/24] Train loss=0.19125540554523468
[10/24] Train loss=0.2150680124759674
[15/24] Train loss=0.2329494059085846
[20/24] Train loss=0.200503870844841
Test set avg_accuracy=84.60% avg_sensitivity=60.33%, avg_specificity=93.79% avg_auc=87.96%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.198586 Test loss=0.383992 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.18745596706867218
[5/24] Train loss=0.18221716582775116
[10/24] Train loss=0.2114749699831009
[15/24] Train loss=0.21550141274929047
[20/24] Train loss=0.1986464411020279
Test set avg_accuracy=84.64% avg_sensitivity=60.28%, avg_specificity=93.86% avg_auc=88.61%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.191164 Test loss=0.382079 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.1777983456850052
[5/24] Train loss=0.17671865224838257
[10/24] Train loss=0.2171238362789154
[15/24] Train loss=0.2104860097169876
[20/24] Train loss=0.1829744130373001
Test set avg_accuracy=84.86% avg_sensitivity=60.76%, avg_specificity=93.99% avg_auc=88.66%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.188962 Test loss=0.384414 Current lr=[0.000156543481933168]

[0/24] Train loss=0.1764293760061264
[5/24] Train loss=0.1761811226606369
[10/24] Train loss=0.2099335938692093
[15/24] Train loss=0.21019630134105682
[20/24] Train loss=0.18029610812664032
Test set avg_accuracy=84.93% avg_sensitivity=65.26%, avg_specificity=92.39% avg_auc=89.18%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.185835 Test loss=0.368623 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1829257309436798
[5/24] Train loss=0.17261388897895813
[10/24] Train loss=0.21677781641483307
[15/24] Train loss=0.20816358923912048
[20/24] Train loss=0.1799497902393341
Test set avg_accuracy=84.92% avg_sensitivity=66.64%, avg_specificity=91.85% avg_auc=88.71%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.185976 Test loss=0.371596 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.17719769477844238
[5/24] Train loss=0.16012059152126312
[10/24] Train loss=0.20612618327140808
[15/24] Train loss=0.19257314503192902
[20/24] Train loss=0.17509251832962036
Test set avg_accuracy=84.77% avg_sensitivity=64.50%, avg_specificity=92.44% avg_auc=88.23%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.179747 Test loss=0.377405 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.17134037613868713
[5/24] Train loss=0.16133169829845428
[10/24] Train loss=0.20082905888557434
[15/24] Train loss=0.19119244813919067
[20/24] Train loss=0.1807464212179184
Test set avg_accuracy=84.86% avg_sensitivity=70.38%, avg_specificity=90.34% avg_auc=89.35%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.175885 Test loss=0.361077 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.16551245748996735
[5/24] Train loss=0.15953797101974487
[10/24] Train loss=0.20789779722690582
[15/24] Train loss=0.1904849410057068
[20/24] Train loss=0.17516860365867615
Test set avg_accuracy=84.95% avg_sensitivity=65.69%, avg_specificity=92.24% avg_auc=88.21%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.173776 Test loss=0.374719 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16876518726348877
[5/24] Train loss=0.15537098050117493
[10/24] Train loss=0.2003798633813858
[15/24] Train loss=0.19401657581329346
[20/24] Train loss=0.1674933135509491
Test set avg_accuracy=85.04% avg_sensitivity=67.82%, avg_specificity=91.56% avg_auc=88.06%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.172254 Test loss=0.375207 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.16426217555999756
[5/24] Train loss=0.1525581181049347
[10/24] Train loss=0.1934012770652771
[15/24] Train loss=0.1853579878807068
[20/24] Train loss=0.17173485457897186
Test set avg_accuracy=84.45% avg_sensitivity=67.01%, avg_specificity=91.06% avg_auc=88.05%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.169669 Test loss=0.382831 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.16190578043460846
[5/24] Train loss=0.15485922992229462
[10/24] Train loss=0.1945757269859314
[15/24] Train loss=0.18942618370056152
[20/24] Train loss=0.17338769137859344
Test set avg_accuracy=85.18% avg_sensitivity=68.29%, avg_specificity=91.58% avg_auc=89.59%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.169505 Test loss=0.360205 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.1671099215745926
[5/24] Train loss=0.1571827381849289
[10/24] Train loss=0.18707798421382904
[15/24] Train loss=0.18879354000091553
[20/24] Train loss=0.16537117958068848
Test set avg_accuracy=84.08% avg_sensitivity=69.81%, avg_specificity=89.48% avg_auc=88.60%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.169742 Test loss=0.381864 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.16528931260108948
[5/24] Train loss=0.1547175794839859
[10/24] Train loss=0.19407328963279724
[15/24] Train loss=0.19109459221363068
[20/24] Train loss=0.16781769692897797
Test set avg_accuracy=84.26% avg_sensitivity=64.41%, avg_specificity=91.78% avg_auc=87.90%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.169733 Test loss=0.388423 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16503684222698212
[5/24] Train loss=0.1561754047870636
[10/24] Train loss=0.18648898601531982
[15/24] Train loss=0.18127046525478363
[20/24] Train loss=0.1707771122455597
Test set avg_accuracy=84.04% avg_sensitivity=67.25%, avg_specificity=90.39% avg_auc=88.14%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.169973 Test loss=0.383323 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.16435080766677856
[5/24] Train loss=0.158291757106781
[10/24] Train loss=0.18681751191616058
[15/24] Train loss=0.18156425654888153
[20/24] Train loss=0.1687331646680832
Test set avg_accuracy=83.80% avg_sensitivity=71.00%, avg_specificity=88.65% avg_auc=89.64%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.168727 Test loss=0.370688 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1599043607711792
[5/24] Train loss=0.16117830574512482
[10/24] Train loss=0.1974668651819229
[15/24] Train loss=0.18205422163009644
[20/24] Train loss=0.1672888696193695
Test set avg_accuracy=83.91% avg_sensitivity=66.26%, avg_specificity=90.59% avg_auc=89.19%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.168582 Test loss=0.383108 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.15514488518238068
[5/24] Train loss=0.1599046289920807
[10/24] Train loss=0.18569688498973846
[15/24] Train loss=0.18011027574539185
[20/24] Train loss=0.1602906733751297
Test set avg_accuracy=84.22% avg_sensitivity=69.15%, avg_specificity=89.93% avg_auc=88.94%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.166314 Test loss=0.378249 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.16111476719379425
[5/24] Train loss=0.15429821610450745
[10/24] Train loss=0.18602414429187775
[15/24] Train loss=0.1776544153690338
[20/24] Train loss=0.16844530403614044
Test set avg_accuracy=85.20% avg_sensitivity=72.51%, avg_specificity=90.00% avg_auc=90.36%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.164800 Test loss=0.357905 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.15515725314617157
[5/24] Train loss=0.1503020077943802
[10/24] Train loss=0.18810492753982544
[15/24] Train loss=0.17581376433372498
[20/24] Train loss=0.16384121775627136
Test set avg_accuracy=84.69% avg_sensitivity=73.13%, avg_specificity=89.07% avg_auc=89.91%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.163546 Test loss=0.366406 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1579018384218216
[5/24] Train loss=0.15713171660900116
[10/24] Train loss=0.19082026183605194
[15/24] Train loss=0.1782584935426712
[20/24] Train loss=0.16633443534374237
Test set avg_accuracy=84.62% avg_sensitivity=72.23%, avg_specificity=89.32% avg_auc=90.20%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.162379 Test loss=0.360626 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1550290435552597
[5/24] Train loss=0.14762967824935913
[10/24] Train loss=0.18790550529956818
[15/24] Train loss=0.17592687904834747
[20/24] Train loss=0.16141623258590698
Test set avg_accuracy=84.75% avg_sensitivity=72.37%, avg_specificity=89.44% avg_auc=90.03%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.161091 Test loss=0.361476 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1541481912136078
[5/24] Train loss=0.1478123813867569
[10/24] Train loss=0.18382559716701508
[15/24] Train loss=0.17374196648597717
[20/24] Train loss=0.16615286469459534
Test set avg_accuracy=84.21% avg_sensitivity=70.38%, avg_specificity=89.44% avg_auc=89.42%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.159049 Test loss=0.371741 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15431532263755798
[5/24] Train loss=0.14370490610599518
[10/24] Train loss=0.17686408758163452
[15/24] Train loss=0.17492160201072693
[20/24] Train loss=0.15997618436813354
Test set avg_accuracy=84.51% avg_sensitivity=69.10%, avg_specificity=90.34% avg_auc=89.17%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.157154 Test loss=0.374171 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14991134405136108
[5/24] Train loss=0.1459975391626358
[10/24] Train loss=0.17641949653625488
[15/24] Train loss=0.17066240310668945
[20/24] Train loss=0.15751150250434875
Test set avg_accuracy=83.92% avg_sensitivity=70.90%, avg_specificity=88.85% avg_auc=89.47%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.155370 Test loss=0.376955 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1523216962814331
[5/24] Train loss=0.14187583327293396
[10/24] Train loss=0.1767178773880005
[15/24] Train loss=0.16986069083213806
[20/24] Train loss=0.15788759291172028
Test set avg_accuracy=84.34% avg_sensitivity=69.48%, avg_specificity=89.96% avg_auc=89.12%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.154681 Test loss=0.376590 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14689399302005768
[5/24] Train loss=0.14220677316188812
[10/24] Train loss=0.17426469922065735
[15/24] Train loss=0.17007215321063995
[20/24] Train loss=0.15304887294769287
Test set avg_accuracy=84.17% avg_sensitivity=68.53%, avg_specificity=90.09% avg_auc=89.17%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.153680 Test loss=0.373900 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1486128866672516
[5/24] Train loss=0.13947390019893646
[10/24] Train loss=0.17642542719841003
[15/24] Train loss=0.16520194709300995
[20/24] Train loss=0.1544492542743683
Test set avg_accuracy=84.34% avg_sensitivity=70.24%, avg_specificity=89.68% avg_auc=89.30%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.152314 Test loss=0.372924 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14264337718486786
[5/24] Train loss=0.14430390298366547
[10/24] Train loss=0.16675104200839996
[15/24] Train loss=0.16759569942951202
[20/24] Train loss=0.15474960207939148
Test set avg_accuracy=84.18% avg_sensitivity=72.46%, avg_specificity=88.62% avg_auc=89.87%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.150236 Test loss=0.367943 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.14336545765399933
[5/24] Train loss=0.13815593719482422
[10/24] Train loss=0.1686658263206482
[15/24] Train loss=0.1637953668832779
[20/24] Train loss=0.15228991210460663
Test set avg_accuracy=84.57% avg_sensitivity=71.14%, avg_specificity=89.66% avg_auc=89.57%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.149082 Test loss=0.367265 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1410682499408722
[5/24] Train loss=0.1345655620098114
[10/24] Train loss=0.16990622878074646
[15/24] Train loss=0.16045695543289185
[20/24] Train loss=0.14976364374160767
Test set avg_accuracy=84.54% avg_sensitivity=70.85%, avg_specificity=89.73% avg_auc=89.71%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.147951 Test loss=0.367878 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.14385975897312164
[5/24] Train loss=0.14096716046333313
[10/24] Train loss=0.16606685519218445
[15/24] Train loss=0.1605297476053238
[20/24] Train loss=0.15291637182235718
Test set avg_accuracy=84.26% avg_sensitivity=70.19%, avg_specificity=89.59% avg_auc=89.18%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.147089 Test loss=0.377133 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.14567480981349945
[5/24] Train loss=0.1357700079679489
[10/24] Train loss=0.16362862288951874
[15/24] Train loss=0.15788444876670837
[20/24] Train loss=0.15155074000358582
Test set avg_accuracy=84.08% avg_sensitivity=68.96%, avg_specificity=89.80% avg_auc=89.07%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.145817 Test loss=0.378352 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.14121313393115997
[5/24] Train loss=0.13471215963363647
[10/24] Train loss=0.16669979691505432
[15/24] Train loss=0.16354329884052277
[20/24] Train loss=0.148564413189888
Test set avg_accuracy=84.48% avg_sensitivity=69.91%, avg_specificity=90.00% avg_auc=89.31%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.146718 Test loss=0.372524 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1408698856830597
[5/24] Train loss=0.1341538280248642
[10/24] Train loss=0.1638767272233963
[15/24] Train loss=0.16111886501312256
[20/24] Train loss=0.1468288004398346
Test set avg_accuracy=84.21% avg_sensitivity=68.72%, avg_specificity=90.07% avg_auc=89.03%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.145800 Test loss=0.376941 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1401117742061615
[5/24] Train loss=0.13401716947555542
[10/24] Train loss=0.16785107553005219
[15/24] Train loss=0.15820500254631042
[20/24] Train loss=0.1456225961446762
Test set avg_accuracy=84.36% avg_sensitivity=70.28%, avg_specificity=89.69% avg_auc=89.41%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.144831 Test loss=0.371286 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1402682363986969
[5/24] Train loss=0.1360781043767929
[10/24] Train loss=0.16562971472740173
[15/24] Train loss=0.15889877080917358
[20/24] Train loss=0.14534790813922882
Test set avg_accuracy=84.15% avg_sensitivity=69.15%, avg_specificity=89.84% avg_auc=88.86%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.144512 Test loss=0.380115 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13928917050361633
[5/24] Train loss=0.13353689014911652
[10/24] Train loss=0.16339051723480225
[15/24] Train loss=0.15686312317848206
[20/24] Train loss=0.15067115426063538
Test set avg_accuracy=84.18% avg_sensitivity=70.95%, avg_specificity=89.19% avg_auc=89.20%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.144808 Test loss=0.376536 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1375560313463211
[5/24] Train loss=0.13086283206939697
[10/24] Train loss=0.16705575585365295
[15/24] Train loss=0.1560259312391281
[20/24] Train loss=0.1487710177898407
Test set avg_accuracy=84.15% avg_sensitivity=71.04%, avg_specificity=89.12% avg_auc=89.16%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.143294 Test loss=0.375907 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1418691873550415
[5/24] Train loss=0.1330767273902893
[10/24] Train loss=0.16076840460300446
[15/24] Train loss=0.15929178893566132
[20/24] Train loss=0.14722654223442078
Test set avg_accuracy=84.09% avg_sensitivity=71.71%, avg_specificity=88.78% avg_auc=89.28%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.142796 Test loss=0.376814 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13726158440113068
[5/24] Train loss=0.1326645016670227
[10/24] Train loss=0.16183285415172577
[15/24] Train loss=0.15512141585350037
[20/24] Train loss=0.14857254922389984
Test set avg_accuracy=83.82% avg_sensitivity=69.91%, avg_specificity=89.08% avg_auc=89.07%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.141822 Test loss=0.378355 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13894835114479065
[5/24] Train loss=0.13140738010406494
[10/24] Train loss=0.15953077375888824
[15/24] Train loss=0.15684014558792114
[20/24] Train loss=0.14656490087509155
Test set avg_accuracy=84.17% avg_sensitivity=71.00%, avg_specificity=89.16% avg_auc=89.23%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.141504 Test loss=0.374463 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13328921794891357
[5/24] Train loss=0.12985748052597046
[10/24] Train loss=0.1602715700864792
[15/24] Train loss=0.15363329648971558
[20/24] Train loss=0.1456129103899002
Test set avg_accuracy=84.14% avg_sensitivity=70.24%, avg_specificity=89.41% avg_auc=88.99%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.140583 Test loss=0.377240 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13741908967494965
[5/24] Train loss=0.13260383903980255
[10/24] Train loss=0.15474288165569305
[15/24] Train loss=0.15188230574131012
[20/24] Train loss=0.14427383244037628
Test set avg_accuracy=83.89% avg_sensitivity=70.09%, avg_specificity=89.12% avg_auc=88.96%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.140468 Test loss=0.378570 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.13343171775341034
[5/24] Train loss=0.12932758033275604
[10/24] Train loss=0.16153961420059204
[15/24] Train loss=0.15364329516887665
[20/24] Train loss=0.1447228044271469
Test set avg_accuracy=84.22% avg_sensitivity=70.95%, avg_specificity=89.25% avg_auc=89.20%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.140132 Test loss=0.377149 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1373768299818039
[5/24] Train loss=0.13228730857372284
[10/24] Train loss=0.15862825512886047
[15/24] Train loss=0.15542978048324585
[20/24] Train loss=0.1437711864709854
Test set avg_accuracy=84.23% avg_sensitivity=70.76%, avg_specificity=89.34% avg_auc=88.89%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.140147 Test loss=0.379285 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1329544484615326
[5/24] Train loss=0.12968900799751282
[10/24] Train loss=0.15914294123649597
[15/24] Train loss=0.14985033869743347
[20/24] Train loss=0.1441204696893692
Test set avg_accuracy=84.19% avg_sensitivity=71.09%, avg_specificity=89.16% avg_auc=88.91%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.140177 Test loss=0.380304 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13330960273742676
[5/24] Train loss=0.13228976726531982
[10/24] Train loss=0.1581367701292038
[15/24] Train loss=0.15165135264396667
[20/24] Train loss=0.14522461593151093
Test set avg_accuracy=84.14% avg_sensitivity=70.66%, avg_specificity=89.25% avg_auc=88.95%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.139434 Test loss=0.379585 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13280324637889862
[5/24] Train loss=0.13105009496212006
[10/24] Train loss=0.15720243752002716
[15/24] Train loss=0.15698501467704773
[20/24] Train loss=0.14565695822238922
Test set avg_accuracy=84.36% avg_sensitivity=72.09%, avg_specificity=89.01% avg_auc=89.11%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.140231 Test loss=0.378460 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.13252437114715576
[5/24] Train loss=0.12841124832630157
[10/24] Train loss=0.15671847760677338
[15/24] Train loss=0.1540023237466812
[20/24] Train loss=0.14250577986240387
Test set avg_accuracy=84.32% avg_sensitivity=71.56%, avg_specificity=89.16% avg_auc=89.04%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.139135 Test loss=0.378989 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13408610224723816
[5/24] Train loss=0.12981455028057098
[10/24] Train loss=0.1596386730670929
[15/24] Train loss=0.15179583430290222
[20/24] Train loss=0.14434628188610077
Test set avg_accuracy=84.18% avg_sensitivity=70.71%, avg_specificity=89.28% avg_auc=88.91%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.139558 Test loss=0.379820 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13309434056282043
[5/24] Train loss=0.1278318613767624
[10/24] Train loss=0.15705935657024384
[15/24] Train loss=0.15412184596061707
[20/24] Train loss=0.1448216736316681
Test set avg_accuracy=84.30% avg_sensitivity=70.85%, avg_specificity=89.39% avg_auc=88.90%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.139244 Test loss=0.380065 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13119269907474518
[5/24] Train loss=0.12930959463119507
[10/24] Train loss=0.15663234889507294
[15/24] Train loss=0.14886285364627838
[20/24] Train loss=0.1409275084733963
Test set avg_accuracy=84.17% avg_sensitivity=70.85%, avg_specificity=89.21% avg_auc=88.90%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.138832 Test loss=0.380160 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13289789855480194
[5/24] Train loss=0.13115154206752777
[10/24] Train loss=0.15673601627349854
[15/24] Train loss=0.15139158070087433
[20/24] Train loss=0.14736682176589966
Test set avg_accuracy=84.09% avg_sensitivity=70.71%, avg_specificity=89.16% avg_auc=88.94%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.139861 Test loss=0.380389 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.13200341165065765
[5/24] Train loss=0.1302681416273117
[10/24] Train loss=0.15591208636760712
[15/24] Train loss=0.15391124784946442
[20/24] Train loss=0.14593468606472015
Test set avg_accuracy=84.19% avg_sensitivity=70.90%, avg_specificity=89.23% avg_auc=88.97%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.139736 Test loss=0.380097 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1327156126499176
[5/24] Train loss=0.1318446397781372
[10/24] Train loss=0.15642352402210236
[15/24] Train loss=0.1518469601869583
[20/24] Train loss=0.14102596044540405
Test set avg_accuracy=84.15% avg_sensitivity=70.62%, avg_specificity=89.28% avg_auc=88.97%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.138949 Test loss=0.380157 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13282984495162964
[5/24] Train loss=0.13040278851985931
[10/24] Train loss=0.15678200125694275
[15/24] Train loss=0.1537875384092331
[20/24] Train loss=0.14567068219184875
Test set avg_accuracy=84.14% avg_sensitivity=70.47%, avg_specificity=89.32% avg_auc=88.93%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.139337 Test loss=0.380438 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.13368038833141327
[5/24] Train loss=0.13035020232200623
[10/24] Train loss=0.15887367725372314
[15/24] Train loss=0.15395648777484894
[20/24] Train loss=0.1435622125864029
Test set avg_accuracy=84.18% avg_sensitivity=70.76%, avg_specificity=89.26% avg_auc=88.97%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.139034 Test loss=0.380016 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=84.74% sen=79.91%, spe=86.57%, auc=91.56%!
Fold[3] Avg_overlap=0.64%(±0.24321703588791158)
[0/24] Train loss=0.7373724579811096
[5/24] Train loss=0.7224909663200378
[10/24] Train loss=0.7201792597770691
[15/24] Train loss=0.7168640494346619
[20/24] Train loss=0.7118132710456848
Test set avg_accuracy=61.28% avg_sensitivity=37.88%, avg_specificity=69.52% avg_auc=55.11%
Best model saved!! Metric=-102.2150736666686!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.719932 Test loss=0.658365 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7058022022247314
[5/24] Train loss=0.7038445472717285
[10/24] Train loss=0.701217532157898
[15/24] Train loss=0.6947989463806152
[20/24] Train loss=0.6940001249313354
Test set avg_accuracy=67.38% avg_sensitivity=28.89%, avg_specificity=80.95% avg_auc=59.31%
Best model saved!! Metric=-89.4773341127299!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.697457 Test loss=0.619845 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6816383600234985
[5/24] Train loss=0.6825441122055054
[10/24] Train loss=0.6902905106544495
[15/24] Train loss=0.6711604595184326
[20/24] Train loss=0.667296826839447
Test set avg_accuracy=67.55% avg_sensitivity=32.23%, avg_specificity=80.00% avg_auc=62.40%
Best model saved!! Metric=-83.81759227964376!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.677603 Test loss=0.606786 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6653343439102173
[5/24] Train loss=0.6696866154670715
[10/24] Train loss=0.6646806001663208
[15/24] Train loss=0.663104772567749
[20/24] Train loss=0.6541306972503662
Test set avg_accuracy=70.29% avg_sensitivity=33.93%, avg_specificity=83.10% avg_auc=65.83%
Best model saved!! Metric=-72.8540601554413!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.660461 Test loss=0.593836 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6394369006156921
[5/24] Train loss=0.6367695331573486
[10/24] Train loss=0.6538995504379272
[15/24] Train loss=0.637479841709137
[20/24] Train loss=0.6316822171211243
Test set avg_accuracy=71.08% avg_sensitivity=38.08%, avg_specificity=82.71% avg_auc=68.48%
Best model saved!! Metric=-65.6477109802259!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.638517 Test loss=0.578933 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6272367238998413
[5/24] Train loss=0.625298261642456
[10/24] Train loss=0.6339607834815979
[15/24] Train loss=0.6230544447898865
[20/24] Train loss=0.6118044853210449
Test set avg_accuracy=72.03% avg_sensitivity=41.03%, avg_specificity=82.95% avg_auc=70.74%
Best model saved!! Metric=-59.244123406799!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.618978 Test loss=0.562735 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5943771600723267
[5/24] Train loss=0.6000880002975464
[10/24] Train loss=0.6099990010261536
[15/24] Train loss=0.5932557582855225
[20/24] Train loss=0.5900360345840454
Test set avg_accuracy=74.49% avg_sensitivity=42.38%, avg_specificity=85.81% avg_auc=73.00%
Best model saved!! Metric=-50.32140535139961!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.594595 Test loss=0.541158 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5678207874298096
[5/24] Train loss=0.5799304246902466
[10/24] Train loss=0.5921304225921631
[15/24] Train loss=0.5723239183425903
[20/24] Train loss=0.56321120262146
Test set avg_accuracy=75.39% avg_sensitivity=45.98%, avg_specificity=85.75% avg_auc=75.78%
Best model saved!! Metric=-43.09367519890565!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.571045 Test loss=0.518270 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5392355918884277
[5/24] Train loss=0.5489110350608826
[10/24] Train loss=0.5648267269134521
[15/24] Train loss=0.550828218460083
[20/24] Train loss=0.5347275137901306
Test set avg_accuracy=76.04% avg_sensitivity=48.23%, avg_specificity=85.84% avg_auc=77.42%
Best model saved!! Metric=-38.46576125346376!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.547727 Test loss=0.500188 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5182771682739258
[5/24] Train loss=0.5251632332801819
[10/24] Train loss=0.5428646802902222
[15/24] Train loss=0.5268770456314087
[20/24] Train loss=0.5163309574127197
Test set avg_accuracy=76.84% avg_sensitivity=48.98%, avg_specificity=86.65% avg_auc=79.14%
Best model saved!! Metric=-34.395491511678344!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.525733 Test loss=0.483873 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4900628328323364
[5/24] Train loss=0.5021663308143616
[10/24] Train loss=0.5312498211860657
[15/24] Train loss=0.513332724571228
[20/24] Train loss=0.49260395765304565
Test set avg_accuracy=77.59% avg_sensitivity=50.47%, avg_specificity=87.15% avg_auc=80.65%
Best model saved!! Metric=-30.13865751644451!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.506411 Test loss=0.465491 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4760926067829132
[5/24] Train loss=0.48635995388031006
[10/24] Train loss=0.5131442546844482
[15/24] Train loss=0.49673908948898315
[20/24] Train loss=0.47442877292633057
Test set avg_accuracy=78.79% avg_sensitivity=51.47%, avg_specificity=88.41% avg_auc=82.14%
Best model saved!! Metric=-25.179876960539154!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.488418 Test loss=0.450044 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.4580431878566742
[5/24] Train loss=0.4666324853897095
[10/24] Train loss=0.5040181279182434
[15/24] Train loss=0.48039141297340393
[20/24] Train loss=0.4611775279045105
Test set avg_accuracy=79.19% avg_sensitivity=52.02%, avg_specificity=88.77% avg_auc=83.32%
Best model saved!! Metric=-22.70119891272669!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.472401 Test loss=0.435406 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4455871880054474
[5/24] Train loss=0.4511929154396057
[10/24] Train loss=0.4846607446670532
[15/24] Train loss=0.47280943393707275
[20/24] Train loss=0.44373565912246704
Test set avg_accuracy=79.95% avg_sensitivity=54.12%, avg_specificity=89.05% avg_auc=84.49%
Best model saved!! Metric=-18.391833514590658!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.458796 Test loss=0.422747 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.42920270562171936
[5/24] Train loss=0.4357052147388458
[10/24] Train loss=0.4704829454421997
[15/24] Train loss=0.4594860076904297
[20/24] Train loss=0.4283626675605774
Test set avg_accuracy=80.60% avg_sensitivity=56.32%, avg_specificity=89.15% avg_auc=85.44%
Best model saved!! Metric=-14.490532842895774!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.445699 Test loss=0.411770 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4215168356895447
[5/24] Train loss=0.4205712080001831
[10/24] Train loss=0.46427562832832336
[15/24] Train loss=0.4458375573158264
[20/24] Train loss=0.4180665612220764
Test set avg_accuracy=80.73% avg_sensitivity=56.47%, avg_specificity=89.28% avg_auc=85.95%
Best model saved!! Metric=-13.573853860400312!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.433062 Test loss=0.403580 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.41095468401908875
[5/24] Train loss=0.4146871268749237
[10/24] Train loss=0.4508514106273651
[15/24] Train loss=0.4327157735824585
[20/24] Train loss=0.4142690896987915
Test set avg_accuracy=81.22% avg_sensitivity=59.77%, avg_specificity=88.78% avg_auc=86.54%
Best model saved!! Metric=-9.685975324595553!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.422612 Test loss=0.396776 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.39246976375579834
[5/24] Train loss=0.40441304445266724
[10/24] Train loss=0.4368072748184204
[15/24] Train loss=0.4327719509601593
[20/24] Train loss=0.4042547941207886
Test set avg_accuracy=81.54% avg_sensitivity=58.22%, avg_specificity=89.75% avg_auc=86.89%
Best model saved!! Metric=-9.605050855724201!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.413593 Test loss=0.390536 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.38498976826667786
[5/24] Train loss=0.39173778891563416
[10/24] Train loss=0.4276511073112488
[15/24] Train loss=0.4253378212451935
[20/24] Train loss=0.39432719349861145
Test set avg_accuracy=81.94% avg_sensitivity=62.27%, avg_specificity=88.87% avg_auc=87.51%
Best model saved!! Metric=-5.406516060814241!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.404471 Test loss=0.384230 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.38023367524147034
[5/24] Train loss=0.38617777824401855
[10/24] Train loss=0.41727906465530396
[15/24] Train loss=0.41213664412498474
[20/24] Train loss=0.38817477226257324
Test set avg_accuracy=82.32% avg_sensitivity=63.72%, avg_specificity=88.87% avg_auc=88.04%
Best model saved!! Metric=-3.0543885025593482!!
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.397040 Test loss=0.375851 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.37281882762908936
[5/24] Train loss=0.37792783975601196
[10/24] Train loss=0.4060998857021332
[15/24] Train loss=0.4072069525718689
[20/24] Train loss=0.38516765832901
Test set avg_accuracy=82.63% avg_sensitivity=64.77%, avg_specificity=88.92% avg_auc=88.43%
Best model saved!! Metric=-1.2495109019601074!!
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.390254 Test loss=0.371170 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.36545681953430176
[5/24] Train loss=0.3643939197063446
[10/24] Train loss=0.40391772985458374
[15/24] Train loss=0.3908425271511078
[20/24] Train loss=0.368733286857605
Test set avg_accuracy=82.62% avg_sensitivity=67.27%, avg_specificity=88.03% avg_auc=88.65%
Best model saved!! Metric=0.5554578436096591!!
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.380115 Test loss=0.369561 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3567579388618469
[5/24] Train loss=0.3612956404685974
[10/24] Train loss=0.3961162269115448
[15/24] Train loss=0.387212336063385
[20/24] Train loss=0.36656713485717773
Test set avg_accuracy=83.01% avg_sensitivity=65.77%, avg_specificity=89.08% avg_auc=89.01%
Best model saved!! Metric=0.8629495555257591!!
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.371908 Test loss=0.363604 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3480284810066223
[5/24] Train loss=0.3507636487483978
[10/24] Train loss=0.3855260908603668
[15/24] Train loss=0.36924663186073303
[20/24] Train loss=0.3487662672996521
Test set avg_accuracy=83.83% avg_sensitivity=65.62%, avg_specificity=90.24% avg_auc=89.18%
Best model saved!! Metric=2.8668268147907696!!
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.362538 Test loss=0.357793 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.33416205644607544
[5/24] Train loss=0.345564603805542
[10/24] Train loss=0.38567814230918884
[15/24] Train loss=0.36576271057128906
[20/24] Train loss=0.3449176847934723
Test set avg_accuracy=83.75% avg_sensitivity=65.57%, avg_specificity=90.16% avg_auc=89.29%
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.356250 Test loss=0.356561 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3278063237667084
[5/24] Train loss=0.33343273401260376
[10/24] Train loss=0.37728407979011536
[15/24] Train loss=0.37175893783569336
[20/24] Train loss=0.332996129989624
Test set avg_accuracy=84.39% avg_sensitivity=63.02%, avg_specificity=91.92% avg_auc=89.41%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.348644 Test loss=0.353748 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.33454594016075134
[5/24] Train loss=0.33777034282684326
[10/24] Train loss=0.3759792447090149
[15/24] Train loss=0.3631347417831421
[20/24] Train loss=0.3296739161014557
Test set avg_accuracy=84.96% avg_sensitivity=62.47%, avg_specificity=92.89% avg_auc=89.93%
Best model saved!! Metric=4.247670784176698!!
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.345804 Test loss=0.345793 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.31958040595054626
[5/24] Train loss=0.31964895129203796
[10/24] Train loss=0.36893796920776367
[15/24] Train loss=0.36063358187675476
[20/24] Train loss=0.31899312138557434
Test set avg_accuracy=84.87% avg_sensitivity=67.87%, avg_specificity=90.86% avg_auc=90.02%
Best model saved!! Metric=7.620288754801592!!
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.338735 Test loss=0.343446 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3114563226699829
[5/24] Train loss=0.3236178457736969
[10/24] Train loss=0.3713839054107666
[15/24] Train loss=0.35197317600250244
[20/24] Train loss=0.31000494956970215
Test set avg_accuracy=85.47% avg_sensitivity=63.72%, avg_specificity=93.13% avg_auc=90.73%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.332826 Test loss=0.333415 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3047512471675873
[5/24] Train loss=0.3185531795024872
[10/24] Train loss=0.3602465093135834
[15/24] Train loss=0.35876476764678955
[20/24] Train loss=0.30262577533721924
Test set avg_accuracy=84.02% avg_sensitivity=55.77%, avg_specificity=93.98% avg_auc=90.13%
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.329939 Test loss=0.347652 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3074755072593689
[5/24] Train loss=0.31168144941329956
[10/24] Train loss=0.37306728959083557
[15/24] Train loss=0.34997275471687317
[20/24] Train loss=0.30189552903175354
Test set avg_accuracy=85.52% avg_sensitivity=69.87%, avg_specificity=91.04% avg_auc=90.91%
Best model saved!! Metric=11.334422928745155!!
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.325954 Test loss=0.331039 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.30224236845970154
[5/24] Train loss=0.3061116635799408
[10/24] Train loss=0.3534175753593445
[15/24] Train loss=0.33447712659835815
[20/24] Train loss=0.2994123101234436
Test set avg_accuracy=85.83% avg_sensitivity=65.72%, avg_specificity=92.92% avg_auc=91.05%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.320652 Test loss=0.327780 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.29898592829704285
[5/24] Train loss=0.2990419268608093
[10/24] Train loss=0.35019463300704956
[15/24] Train loss=0.3345631957054138
[20/24] Train loss=0.2870675325393677
Test set avg_accuracy=85.22% avg_sensitivity=57.62%, avg_specificity=94.95% avg_auc=90.71%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.315061 Test loss=0.341010 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.28867557644844055
[5/24] Train loss=0.3042266368865967
[10/24] Train loss=0.34295493364334106
[15/24] Train loss=0.33972030878067017
[20/24] Train loss=0.29419493675231934
Test set avg_accuracy=86.09% avg_sensitivity=61.87%, avg_specificity=94.63% avg_auc=91.32%
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.311957 Test loss=0.325176 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2901756763458252
[5/24] Train loss=0.3139207363128662
[10/24] Train loss=0.34796470403671265
[15/24] Train loss=0.3416190445423126
[20/24] Train loss=0.29240527749061584
Test set avg_accuracy=85.66% avg_sensitivity=63.67%, avg_specificity=93.41% avg_auc=91.49%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.312553 Test loss=0.320687 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2929820716381073
[5/24] Train loss=0.30053815245628357
[10/24] Train loss=0.34033113718032837
[15/24] Train loss=0.33809345960617065
[20/24] Train loss=0.2867162823677063
Test set avg_accuracy=85.52% avg_sensitivity=63.37%, avg_specificity=93.33% avg_auc=91.48%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.307062 Test loss=0.321995 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.28132593631744385
[5/24] Train loss=0.2997954189777374
[10/24] Train loss=0.3308565318584442
[15/24] Train loss=0.32806992530822754
[20/24] Train loss=0.29335862398147583
Test set avg_accuracy=86.16% avg_sensitivity=64.87%, avg_specificity=93.66% avg_auc=91.64%
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.303796 Test loss=0.318698 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.27224528789520264
[5/24] Train loss=0.2927767038345337
[10/24] Train loss=0.3218863308429718
[15/24] Train loss=0.3327847421169281
[20/24] Train loss=0.28400105237960815
Test set avg_accuracy=86.00% avg_sensitivity=70.01%, avg_specificity=91.64% avg_auc=91.68%
Best model saved!! Metric=13.336577257599643!!
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.299710 Test loss=0.317952 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2731310725212097
[5/24] Train loss=0.2914537489414215
[10/24] Train loss=0.33984655141830444
[15/24] Train loss=0.3324975073337555
[20/24] Train loss=0.2706526517868042
Test set avg_accuracy=86.13% avg_sensitivity=65.32%, avg_specificity=93.47% avg_auc=91.34%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.297475 Test loss=0.321563 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.27515220642089844
[5/24] Train loss=0.28699055314064026
[10/24] Train loss=0.3321951627731323
[15/24] Train loss=0.3266032636165619
[20/24] Train loss=0.2660506069660187
Test set avg_accuracy=85.72% avg_sensitivity=65.62%, avg_specificity=92.80% avg_auc=90.49%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.297385 Test loss=0.330762 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.27322280406951904
[5/24] Train loss=0.2833448350429535
[10/24] Train loss=0.3372383117675781
[15/24] Train loss=0.31960329413414
[20/24] Train loss=0.2807580828666687
Test set avg_accuracy=84.65% avg_sensitivity=74.66%, avg_specificity=88.17% avg_auc=90.78%
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.296716 Test loss=0.342235 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2796134650707245
[5/24] Train loss=0.28742602467536926
[10/24] Train loss=0.3275793790817261
[15/24] Train loss=0.31826478242874146
[20/24] Train loss=0.2655046880245209
Test set avg_accuracy=85.03% avg_sensitivity=55.72%, avg_specificity=95.35% avg_auc=90.75%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.293294 Test loss=0.336623 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2756032347679138
[5/24] Train loss=0.2818911075592041
[10/24] Train loss=0.3370020091533661
[15/24] Train loss=0.31668105721473694
[20/24] Train loss=0.26055970788002014
Test set avg_accuracy=86.17% avg_sensitivity=64.07%, avg_specificity=93.96% avg_auc=91.28%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.292326 Test loss=0.320501 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2619539797306061
[5/24] Train loss=0.28344327211380005
[10/24] Train loss=0.3165474534034729
[15/24] Train loss=0.31162530183792114
[20/24] Train loss=0.2671290338039398
Test set avg_accuracy=86.24% avg_sensitivity=68.12%, avg_specificity=92.62% avg_auc=91.36%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.288622 Test loss=0.319955 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2782217264175415
[5/24] Train loss=0.2880159020423889
[10/24] Train loss=0.3154747784137726
[15/24] Train loss=0.31319791078567505
[20/24] Train loss=0.25994396209716797
Test set avg_accuracy=85.34% avg_sensitivity=55.92%, avg_specificity=95.70% avg_auc=90.66%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.288439 Test loss=0.341669 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2609163522720337
[5/24] Train loss=0.27858081459999084
[10/24] Train loss=0.30883046984672546
[15/24] Train loss=0.3054370582103729
[20/24] Train loss=0.26792681217193604
Test set avg_accuracy=85.48% avg_sensitivity=68.52%, avg_specificity=91.46% avg_auc=90.42%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.283841 Test loss=0.338162 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2699430286884308
[5/24] Train loss=0.2716492712497711
[10/24] Train loss=0.30521246790885925
[15/24] Train loss=0.31756502389907837
[20/24] Train loss=0.261435866355896
Test set avg_accuracy=86.26% avg_sensitivity=63.97%, avg_specificity=94.12% avg_auc=91.44%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.283449 Test loss=0.319771 Current lr=[0.000299720220882401]

[0/24] Train loss=0.267260879278183
[5/24] Train loss=0.2721256911754608
[10/24] Train loss=0.3195163309574127
[15/24] Train loss=0.30684322118759155
[20/24] Train loss=0.2595282793045044
Test set avg_accuracy=86.26% avg_sensitivity=64.47%, avg_specificity=93.94% avg_auc=91.56%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.280217 Test loss=0.315225 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2636443078517914
[5/24] Train loss=0.26911455392837524
[10/24] Train loss=0.3030957281589508
[15/24] Train loss=0.2952306866645813
[20/24] Train loss=0.24238590896129608
Test set avg_accuracy=86.17% avg_sensitivity=68.62%, avg_specificity=92.36% avg_auc=91.56%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.274490 Test loss=0.319339 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2646835744380951
[5/24] Train loss=0.2809745967388153
[10/24] Train loss=0.3208872675895691
[15/24] Train loss=0.2981773018836975
[20/24] Train loss=0.2578411102294922
Test set avg_accuracy=86.43% avg_sensitivity=69.92%, avg_specificity=92.25% avg_auc=92.09%
Best model saved!! Metric=14.691928884507817!!
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.282382 Test loss=0.309183 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2592790126800537
[5/24] Train loss=0.2733372449874878
[10/24] Train loss=0.3088485598564148
[15/24] Train loss=0.3107641637325287
[20/24] Train loss=0.25207284092903137
Test set avg_accuracy=85.89% avg_sensitivity=67.97%, avg_specificity=92.20% avg_auc=90.92%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.276586 Test loss=0.327112 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2521861493587494
[5/24] Train loss=0.2655535936355591
[10/24] Train loss=0.2856508791446686
[15/24] Train loss=0.29418402910232544
[20/24] Train loss=0.25695091485977173
Test set avg_accuracy=85.96% avg_sensitivity=68.92%, avg_specificity=91.97% avg_auc=90.75%
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.272583 Test loss=0.332226 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.26431694626808167
[5/24] Train loss=0.2770357131958008
[10/24] Train loss=0.2874954044818878
[15/24] Train loss=0.2969356179237366
[20/24] Train loss=0.25580859184265137
Test set avg_accuracy=86.30% avg_sensitivity=68.47%, avg_specificity=92.59% avg_auc=91.12%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.270170 Test loss=0.323162 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2524257302284241
[5/24] Train loss=0.2649013102054596
[10/24] Train loss=0.287364661693573
[15/24] Train loss=0.29366323351860046
[20/24] Train loss=0.24625010788440704
Test set avg_accuracy=85.91% avg_sensitivity=59.27%, avg_specificity=95.30% avg_auc=90.95%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.266352 Test loss=0.333081 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.24389100074768066
[5/24] Train loss=0.2623022198677063
[10/24] Train loss=0.28645220398902893
[15/24] Train loss=0.2986849546432495
[20/24] Train loss=0.2557229995727539
Test set avg_accuracy=85.49% avg_sensitivity=57.72%, avg_specificity=95.28% avg_auc=90.14%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.267495 Test loss=0.343004 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2701185643672943
[5/24] Train loss=0.2693707048892975
[10/24] Train loss=0.29478952288627625
[15/24] Train loss=0.2826068103313446
[20/24] Train loss=0.24604631960391998
Test set avg_accuracy=82.66% avg_sensitivity=41.18%, avg_specificity=97.27% avg_auc=87.88%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.266651 Test loss=0.405535 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.25906485319137573
[5/24] Train loss=0.2528134286403656
[10/24] Train loss=0.2836163640022278
[15/24] Train loss=0.2819161117076874
[20/24] Train loss=0.2409418523311615
Test set avg_accuracy=83.82% avg_sensitivity=46.68%, avg_specificity=96.90% avg_auc=88.96%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.265660 Test loss=0.375065 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2514919936656952
[5/24] Train loss=0.2682882249355316
[10/24] Train loss=0.2833496928215027
[15/24] Train loss=0.27218031883239746
[20/24] Train loss=0.23736640810966492
Test set avg_accuracy=85.42% avg_sensitivity=61.22%, avg_specificity=93.94% avg_auc=89.11%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.262602 Test loss=0.348702 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.244657963514328
[5/24] Train loss=0.25259849429130554
[10/24] Train loss=0.300345778465271
[15/24] Train loss=0.2815779447555542
[20/24] Train loss=0.24835537374019623
Test set avg_accuracy=86.48% avg_sensitivity=67.02%, avg_specificity=93.34% avg_auc=91.02%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.260268 Test loss=0.323219 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2429942786693573
[5/24] Train loss=0.25890493392944336
[10/24] Train loss=0.2891561686992645
[15/24] Train loss=0.28544872999191284
[20/24] Train loss=0.24009932577610016
Test set avg_accuracy=85.21% avg_sensitivity=60.32%, avg_specificity=93.98% avg_auc=89.61%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.259523 Test loss=0.343292 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2443046122789383
[5/24] Train loss=0.24916794896125793
[10/24] Train loss=0.2695900797843933
[15/24] Train loss=0.28675737977027893
[20/24] Train loss=0.24829837679862976
Test set avg_accuracy=85.31% avg_sensitivity=67.32%, avg_specificity=91.65% avg_auc=90.28%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.255549 Test loss=0.337765 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.22866031527519226
[5/24] Train loss=0.2377014011144638
[10/24] Train loss=0.27786344289779663
[15/24] Train loss=0.2856881618499756
[20/24] Train loss=0.23977243900299072
Test set avg_accuracy=83.02% avg_sensitivity=48.53%, avg_specificity=95.18% avg_auc=86.93%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.254782 Test loss=0.400112 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2607995271682739
[5/24] Train loss=0.24427898228168488
[10/24] Train loss=0.27827462553977966
[15/24] Train loss=0.2808220684528351
[20/24] Train loss=0.23790891468524933
Test set avg_accuracy=84.08% avg_sensitivity=51.22%, avg_specificity=95.65% avg_auc=88.50%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.253872 Test loss=0.378809 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.24407914280891418
[5/24] Train loss=0.2464081197977066
[10/24] Train loss=0.26961058378219604
[15/24] Train loss=0.297516405582428
[20/24] Train loss=0.2543255090713501
Test set avg_accuracy=84.95% avg_sensitivity=63.57%, avg_specificity=92.48% avg_auc=89.57%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.254710 Test loss=0.347017 Current lr=[0.000276307469034998]

[0/24] Train loss=0.22090783715248108
[5/24] Train loss=0.24340617656707764
[10/24] Train loss=0.2762138545513153
[15/24] Train loss=0.2734535336494446
[20/24] Train loss=0.22646449506282806
Test set avg_accuracy=86.34% avg_sensitivity=67.12%, avg_specificity=93.11% avg_auc=90.55%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.252375 Test loss=0.332739 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.23085294663906097
[5/24] Train loss=0.24862024188041687
[10/24] Train loss=0.2748256325721741
[15/24] Train loss=0.27199646830558777
[20/24] Train loss=0.24210940301418304
Test set avg_accuracy=86.09% avg_sensitivity=71.26%, avg_specificity=91.32% avg_auc=91.01%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.249391 Test loss=0.327096 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2317553609609604
[5/24] Train loss=0.24205675721168518
[10/24] Train loss=0.2668866515159607
[15/24] Train loss=0.27658864855766296
[20/24] Train loss=0.22922873497009277
Test set avg_accuracy=85.74% avg_sensitivity=67.47%, avg_specificity=92.18% avg_auc=89.87%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.243774 Test loss=0.345092 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.23150143027305603
[5/24] Train loss=0.23180629312992096
[10/24] Train loss=0.26849600672721863
[15/24] Train loss=0.26829952001571655
[20/24] Train loss=0.23924244940280914
Test set avg_accuracy=85.61% avg_sensitivity=71.76%, avg_specificity=90.49% avg_auc=90.81%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.244058 Test loss=0.332189 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.22126027941703796
[5/24] Train loss=0.24199305474758148
[10/24] Train loss=0.2595946490764618
[15/24] Train loss=0.27469614148139954
[20/24] Train loss=0.23980987071990967
Test set avg_accuracy=85.47% avg_sensitivity=63.87%, avg_specificity=93.08% avg_auc=89.40%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.244418 Test loss=0.348177 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2321392446756363
[5/24] Train loss=0.23751267790794373
[10/24] Train loss=0.26270270347595215
[15/24] Train loss=0.27046266198158264
[20/24] Train loss=0.2425229847431183
Test set avg_accuracy=85.72% avg_sensitivity=75.21%, avg_specificity=89.42% avg_auc=90.82%
Best model saved!! Metric=15.163083396423602!!
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.241328 Test loss=0.337658 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.2142295241355896
[5/24] Train loss=0.21875
[10/24] Train loss=0.25155577063560486
[15/24] Train loss=0.2664310932159424
[20/24] Train loss=0.2534926235675812
Test set avg_accuracy=85.46% avg_sensitivity=71.46%, avg_specificity=90.39% avg_auc=90.48%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.237434 Test loss=0.335679 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.2204638421535492
[5/24] Train loss=0.2198861688375473
[10/24] Train loss=0.26558738946914673
[15/24] Train loss=0.2658969461917877
[20/24] Train loss=0.2393302470445633
Test set avg_accuracy=85.36% avg_sensitivity=72.71%, avg_specificity=89.82% avg_auc=90.75%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.237754 Test loss=0.335731 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2141491025686264
[5/24] Train loss=0.21728147566318512
[10/24] Train loss=0.24969080090522766
[15/24] Train loss=0.26535746455192566
[20/24] Train loss=0.23382079601287842
Test set avg_accuracy=85.38% avg_sensitivity=70.06%, avg_specificity=90.77% avg_auc=90.20%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.236254 Test loss=0.342044 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.22402344644069672
[5/24] Train loss=0.22152173519134521
[10/24] Train loss=0.25889840722084045
[15/24] Train loss=0.266835480928421
[20/24] Train loss=0.24516326189041138
Test set avg_accuracy=85.07% avg_sensitivity=69.47%, avg_specificity=90.56% avg_auc=89.39%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.234453 Test loss=0.350689 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.20985832810401917
[5/24] Train loss=0.22337695956230164
[10/24] Train loss=0.2531939744949341
[15/24] Train loss=0.2645237147808075
[20/24] Train loss=0.23158879578113556
Test set avg_accuracy=85.39% avg_sensitivity=73.91%, avg_specificity=89.43% avg_auc=90.91%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.233957 Test loss=0.336927 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.20119839906692505
[5/24] Train loss=0.2124810814857483
[10/24] Train loss=0.26021191477775574
[15/24] Train loss=0.2515658736228943
[20/24] Train loss=0.2191312611103058
Test set avg_accuracy=85.44% avg_sensitivity=70.01%, avg_specificity=90.88% avg_auc=91.04%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.229659 Test loss=0.330961 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.20907671749591827
[5/24] Train loss=0.20484720170497894
[10/24] Train loss=0.2603094279766083
[15/24] Train loss=0.26721954345703125
[20/24] Train loss=0.2564023435115814
Test set avg_accuracy=84.82% avg_sensitivity=69.97%, avg_specificity=90.05% avg_auc=90.20%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.231760 Test loss=0.352838 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.21355214715003967
[5/24] Train loss=0.23244276642799377
[10/24] Train loss=0.2554812729358673
[15/24] Train loss=0.26398277282714844
[20/24] Train loss=0.2395942211151123
Test set avg_accuracy=84.58% avg_sensitivity=64.17%, avg_specificity=91.78% avg_auc=88.50%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.233490 Test loss=0.373795 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.20988813042640686
[5/24] Train loss=0.22154147922992706
[10/24] Train loss=0.24427922070026398
[15/24] Train loss=0.2560778856277466
[20/24] Train loss=0.23665864765644073
Test set avg_accuracy=84.95% avg_sensitivity=71.66%, avg_specificity=89.63% avg_auc=89.80%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.233626 Test loss=0.353429 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.20016556978225708
[5/24] Train loss=0.20719990134239197
[10/24] Train loss=0.2437070906162262
[15/24] Train loss=0.24877962470054626
[20/24] Train loss=0.23327860236167908
Test set avg_accuracy=84.95% avg_sensitivity=65.67%, avg_specificity=91.74% avg_auc=89.71%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.223612 Test loss=0.349685 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2026893049478531
[5/24] Train loss=0.215593159198761
[10/24] Train loss=0.2444685995578766
[15/24] Train loss=0.2518458962440491
[20/24] Train loss=0.23413902521133423
Test set avg_accuracy=85.40% avg_sensitivity=69.17%, avg_specificity=91.13% avg_auc=90.20%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.224341 Test loss=0.344780 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.1972438246011734
[5/24] Train loss=0.20078158378601074
[10/24] Train loss=0.24105031788349152
[15/24] Train loss=0.24977627396583557
[20/24] Train loss=0.2154776006937027
Test set avg_accuracy=85.61% avg_sensitivity=67.72%, avg_specificity=91.92% avg_auc=89.73%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.219505 Test loss=0.349647 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2034541219472885
[5/24] Train loss=0.19902876019477844
[10/24] Train loss=0.23989391326904297
[15/24] Train loss=0.24024461209774017
[20/24] Train loss=0.23527206480503082
Test set avg_accuracy=84.43% avg_sensitivity=65.97%, avg_specificity=90.93% avg_auc=89.26%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.219125 Test loss=0.365556 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.20815037190914154
[5/24] Train loss=0.20470915734767914
[10/24] Train loss=0.24356386065483093
[15/24] Train loss=0.24061360955238342
[20/24] Train loss=0.22942830622196198
Test set avg_accuracy=84.54% avg_sensitivity=67.77%, avg_specificity=90.46% avg_auc=90.02%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.219588 Test loss=0.356400 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.20136234164237976
[5/24] Train loss=0.202332004904747
[10/24] Train loss=0.23979882895946503
[15/24] Train loss=0.23048458993434906
[20/24] Train loss=0.217363178730011
Test set avg_accuracy=85.33% avg_sensitivity=64.32%, avg_specificity=92.73% avg_auc=88.77%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.217403 Test loss=0.358984 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.206537663936615
[5/24] Train loss=0.1925066113471985
[10/24] Train loss=0.2377348691225052
[15/24] Train loss=0.2290109395980835
[20/24] Train loss=0.2150292843580246
Test set avg_accuracy=85.44% avg_sensitivity=69.07%, avg_specificity=91.21% avg_auc=89.69%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.211898 Test loss=0.348284 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.19863270223140717
[5/24] Train loss=0.18461522459983826
[10/24] Train loss=0.2304229587316513
[15/24] Train loss=0.24554872512817383
[20/24] Train loss=0.21930576860904694
Test set avg_accuracy=84.53% avg_sensitivity=60.67%, avg_specificity=92.94% avg_auc=88.15%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.211104 Test loss=0.367744 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.19296346604824066
[5/24] Train loss=0.18177127838134766
[10/24] Train loss=0.22769857943058014
[15/24] Train loss=0.23314978182315826
[20/24] Train loss=0.20955996215343475
Test set avg_accuracy=84.67% avg_sensitivity=72.31%, avg_specificity=89.03% avg_auc=89.57%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.206988 Test loss=0.362121 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.19158516824245453
[5/24] Train loss=0.18191981315612793
[10/24] Train loss=0.2258969098329544
[15/24] Train loss=0.24251483380794525
[20/24] Train loss=0.2142687886953354
Test set avg_accuracy=84.78% avg_sensitivity=61.62%, avg_specificity=92.94% avg_auc=88.43%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.207165 Test loss=0.361256 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.18937763571739197
[5/24] Train loss=0.1828758269548416
[10/24] Train loss=0.22486715018749237
[15/24] Train loss=0.22620217502117157
[20/24] Train loss=0.22479751706123352
Test set avg_accuracy=84.43% avg_sensitivity=72.41%, avg_specificity=88.66% avg_auc=89.61%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.204711 Test loss=0.366792 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.18378020823001862
[5/24] Train loss=0.1865905225276947
[10/24] Train loss=0.21774174273014069
[15/24] Train loss=0.22467051446437836
[20/24] Train loss=0.20770128071308136
Test set avg_accuracy=84.99% avg_sensitivity=64.07%, avg_specificity=92.36% avg_auc=89.14%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.202384 Test loss=0.356024 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.18785738945007324
[5/24] Train loss=0.18138498067855835
[10/24] Train loss=0.2274980992078781
[15/24] Train loss=0.21211233735084534
[20/24] Train loss=0.2118428498506546
Test set avg_accuracy=85.22% avg_sensitivity=68.77%, avg_specificity=91.02% avg_auc=89.91%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.202055 Test loss=0.350408 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.18608704209327698
[5/24] Train loss=0.18397322297096252
[10/24] Train loss=0.22609148919582367
[15/24] Train loss=0.22243928909301758
[20/24] Train loss=0.20428656041622162
Test set avg_accuracy=84.04% avg_sensitivity=64.27%, avg_specificity=91.00% avg_auc=88.40%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.200014 Test loss=0.370815 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.18297848105430603
[5/24] Train loss=0.18411913514137268
[10/24] Train loss=0.21697789430618286
[15/24] Train loss=0.21450236439704895
[20/24] Train loss=0.20951581001281738
Test set avg_accuracy=84.67% avg_sensitivity=62.42%, avg_specificity=92.52% avg_auc=89.08%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.200182 Test loss=0.360009 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1847427785396576
[5/24] Train loss=0.1779414564371109
[10/24] Train loss=0.21060363948345184
[15/24] Train loss=0.21607434749603271
[20/24] Train loss=0.2035316526889801
Test set avg_accuracy=84.43% avg_sensitivity=58.57%, avg_specificity=93.54% avg_auc=87.47%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.194109 Test loss=0.380391 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.1832524687051773
[5/24] Train loss=0.16673029959201813
[10/24] Train loss=0.21228349208831787
[15/24] Train loss=0.2156960666179657
[20/24] Train loss=0.20279227197170258
Test set avg_accuracy=84.10% avg_sensitivity=62.37%, avg_specificity=91.76% avg_auc=87.42%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.193909 Test loss=0.384832 Current lr=[0.000156543481933168]

[0/24] Train loss=0.18570013344287872
[5/24] Train loss=0.17246036231517792
[10/24] Train loss=0.21239937841892242
[15/24] Train loss=0.21642763912677765
[20/24] Train loss=0.20766526460647583
Test set avg_accuracy=85.12% avg_sensitivity=65.32%, avg_specificity=92.09% avg_auc=88.75%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.194102 Test loss=0.360034 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.18121233582496643
[5/24] Train loss=0.17660927772521973
[10/24] Train loss=0.20534838736057281
[15/24] Train loss=0.20088131725788116
[20/24] Train loss=0.20171305537223816
Test set avg_accuracy=85.07% avg_sensitivity=68.72%, avg_specificity=90.83% avg_auc=89.98%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.188934 Test loss=0.350473 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.1835799515247345
[5/24] Train loss=0.16885130107402802
[10/24] Train loss=0.2138802856206894
[15/24] Train loss=0.2169986218214035
[20/24] Train loss=0.2007346898317337
Test set avg_accuracy=84.60% avg_sensitivity=62.92%, avg_specificity=92.23% avg_auc=88.66%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.191255 Test loss=0.369588 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.17662586271762848
[5/24] Train loss=0.1672596037387848
[10/24] Train loss=0.20678219199180603
[15/24] Train loss=0.2064538598060608
[20/24] Train loss=0.20211942493915558
Test set avg_accuracy=84.88% avg_sensitivity=70.71%, avg_specificity=89.87% avg_auc=89.84%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.189548 Test loss=0.354867 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.17820192873477936
[5/24] Train loss=0.16835680603981018
[10/24] Train loss=0.19936716556549072
[15/24] Train loss=0.20196008682250977
[20/24] Train loss=0.19676123559474945
Test set avg_accuracy=84.62% avg_sensitivity=63.32%, avg_specificity=92.13% avg_auc=88.46%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.187898 Test loss=0.367164 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1801111251115799
[5/24] Train loss=0.1627931296825409
[10/24] Train loss=0.2021065652370453
[15/24] Train loss=0.2081022709608078
[20/24] Train loss=0.1928735226392746
Test set avg_accuracy=85.14% avg_sensitivity=70.61%, avg_specificity=90.26% avg_auc=90.14%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.183837 Test loss=0.349194 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.17504063248634338
[5/24] Train loss=0.1636224091053009
[10/24] Train loss=0.19335375726222992
[15/24] Train loss=0.19147644937038422
[20/24] Train loss=0.18799489736557007
Test set avg_accuracy=84.66% avg_sensitivity=68.27%, avg_specificity=90.44% avg_auc=88.96%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.182407 Test loss=0.368604 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.17433205246925354
[5/24] Train loss=0.16111095249652863
[10/24] Train loss=0.20299142599105835
[15/24] Train loss=0.20321519672870636
[20/24] Train loss=0.18905925750732422
Test set avg_accuracy=84.77% avg_sensitivity=73.01%, avg_specificity=88.91% avg_auc=90.17%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.182960 Test loss=0.358992 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.1722639799118042
[5/24] Train loss=0.15506456792354584
[10/24] Train loss=0.19764122366905212
[15/24] Train loss=0.19594818353652954
[20/24] Train loss=0.18698495626449585
Test set avg_accuracy=84.65% avg_sensitivity=70.81%, avg_specificity=89.52% avg_auc=89.63%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.181648 Test loss=0.355884 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.17101013660430908
[5/24] Train loss=0.16153855621814728
[10/24] Train loss=0.19917333126068115
[15/24] Train loss=0.2016376554965973
[20/24] Train loss=0.17976617813110352
Test set avg_accuracy=84.26% avg_sensitivity=71.71%, avg_specificity=88.68% avg_auc=89.10%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.180734 Test loss=0.371260 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16813011467456818
[5/24] Train loss=0.16607314348220825
[10/24] Train loss=0.19640010595321655
[15/24] Train loss=0.1939154863357544
[20/24] Train loss=0.18208622932434082
Test set avg_accuracy=84.66% avg_sensitivity=74.01%, avg_specificity=88.41% avg_auc=89.55%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.178865 Test loss=0.366117 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.16850176453590393
[5/24] Train loss=0.1551460325717926
[10/24] Train loss=0.1856866180896759
[15/24] Train loss=0.18964900076389313
[20/24] Train loss=0.1804737001657486
Test set avg_accuracy=84.56% avg_sensitivity=74.81%, avg_specificity=87.99% avg_auc=89.69%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.173216 Test loss=0.363793 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.16141396760940552
[5/24] Train loss=0.16951951384544373
[10/24] Train loss=0.18684180080890656
[15/24] Train loss=0.1818171888589859
[20/24] Train loss=0.17790678143501282
Test set avg_accuracy=84.32% avg_sensitivity=74.21%, avg_specificity=87.89% avg_auc=90.01%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.171850 Test loss=0.364920 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.16535457968711853
[5/24] Train loss=0.15794408321380615
[10/24] Train loss=0.187367245554924
[15/24] Train loss=0.18615281581878662
[20/24] Train loss=0.18301405012607574
Test set avg_accuracy=84.06% avg_sensitivity=73.76%, avg_specificity=87.69% avg_auc=89.46%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.170925 Test loss=0.373574 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.16312241554260254
[5/24] Train loss=0.162503182888031
[10/24] Train loss=0.1899229884147644
[15/24] Train loss=0.184373676776886
[20/24] Train loss=0.17627911269664764
Test set avg_accuracy=84.05% avg_sensitivity=70.71%, avg_specificity=88.75% avg_auc=88.68%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.172124 Test loss=0.377350 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.17087800800800323
[5/24] Train loss=0.15570800006389618
[10/24] Train loss=0.1915218085050583
[15/24] Train loss=0.19031064212322235
[20/24] Train loss=0.1757349669933319
Test set avg_accuracy=84.70% avg_sensitivity=70.86%, avg_specificity=89.58% avg_auc=89.38%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.172096 Test loss=0.361663 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.16776761412620544
[5/24] Train loss=0.15347078442573547
[10/24] Train loss=0.18458767235279083
[15/24] Train loss=0.1872553825378418
[20/24] Train loss=0.17376771569252014
Test set avg_accuracy=84.23% avg_sensitivity=73.26%, avg_specificity=88.10% avg_auc=89.15%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.168328 Test loss=0.378031 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.16078242659568787
[5/24] Train loss=0.1498745083808899
[10/24] Train loss=0.18302254378795624
[15/24] Train loss=0.18296177685260773
[20/24] Train loss=0.1729952096939087
Test set avg_accuracy=84.00% avg_sensitivity=73.16%, avg_specificity=87.81% avg_auc=89.04%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.165446 Test loss=0.376940 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.15890903770923615
[5/24] Train loss=0.14510303735733032
[10/24] Train loss=0.17648732662200928
[15/24] Train loss=0.17852675914764404
[20/24] Train loss=0.17530377209186554
Test set avg_accuracy=84.23% avg_sensitivity=72.31%, avg_specificity=88.43% avg_auc=89.04%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.163902 Test loss=0.370281 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.16181105375289917
[5/24] Train loss=0.14184895157814026
[10/24] Train loss=0.17464084923267365
[15/24] Train loss=0.17424555122852325
[20/24] Train loss=0.1708276867866516
Test set avg_accuracy=84.39% avg_sensitivity=69.17%, avg_specificity=89.75% avg_auc=88.50%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.161317 Test loss=0.373092 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1586487591266632
[5/24] Train loss=0.14230020344257355
[10/24] Train loss=0.17554332315921783
[15/24] Train loss=0.17453856766223907
[20/24] Train loss=0.16622532904148102
Test set avg_accuracy=84.18% avg_sensitivity=72.16%, avg_specificity=88.41% avg_auc=88.44%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.159785 Test loss=0.380113 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.15474966168403625
[5/24] Train loss=0.13975723087787628
[10/24] Train loss=0.17401209473609924
[15/24] Train loss=0.1754775196313858
[20/24] Train loss=0.1713738888502121
Test set avg_accuracy=84.10% avg_sensitivity=72.11%, avg_specificity=88.33% avg_auc=89.18%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.159715 Test loss=0.370828 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1562974900007248
[5/24] Train loss=0.14072701334953308
[10/24] Train loss=0.17481037974357605
[15/24] Train loss=0.17707164585590363
[20/24] Train loss=0.16356748342514038
Test set avg_accuracy=84.30% avg_sensitivity=70.66%, avg_specificity=89.10% avg_auc=89.13%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.159173 Test loss=0.368850 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14736264944076538
[5/24] Train loss=0.14284710586071014
[10/24] Train loss=0.17199042439460754
[15/24] Train loss=0.17291703820228577
[20/24] Train loss=0.16642844676971436
Test set avg_accuracy=84.27% avg_sensitivity=72.96%, avg_specificity=88.25% avg_auc=89.52%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.157095 Test loss=0.365998 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.15749159455299377
[5/24] Train loss=0.14093510806560516
[10/24] Train loss=0.1716405302286148
[15/24] Train loss=0.1745026409626007
[20/24] Train loss=0.16424070298671722
Test set avg_accuracy=84.36% avg_sensitivity=73.31%, avg_specificity=88.25% avg_auc=89.70%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.157316 Test loss=0.369154 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.15190687775611877
[5/24] Train loss=0.13994713127613068
[10/24] Train loss=0.17147713899612427
[15/24] Train loss=0.17123429477214813
[20/24] Train loss=0.16337165236473083
Test set avg_accuracy=84.39% avg_sensitivity=72.26%, avg_specificity=88.66% avg_auc=89.41%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.156769 Test loss=0.366367 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.148969829082489
[5/24] Train loss=0.13647258281707764
[10/24] Train loss=0.16376522183418274
[15/24] Train loss=0.16504959762096405
[20/24] Train loss=0.1602981984615326
Test set avg_accuracy=84.28% avg_sensitivity=72.21%, avg_specificity=88.54% avg_auc=89.36%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.153643 Test loss=0.367909 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.14833983778953552
[5/24] Train loss=0.1370641440153122
[10/24] Train loss=0.1638304740190506
[15/24] Train loss=0.16522587835788727
[20/24] Train loss=0.16215801239013672
Test set avg_accuracy=84.19% avg_sensitivity=72.41%, avg_specificity=88.34% avg_auc=89.39%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.152805 Test loss=0.371073 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.15057030320167542
[5/24] Train loss=0.13699106872081757
[10/24] Train loss=0.1639273464679718
[15/24] Train loss=0.16699498891830444
[20/24] Train loss=0.16050581634044647
Test set avg_accuracy=84.44% avg_sensitivity=72.01%, avg_specificity=88.82% avg_auc=89.32%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.152684 Test loss=0.369194 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1468650996685028
[5/24] Train loss=0.13596463203430176
[10/24] Train loss=0.16618122160434723
[15/24] Train loss=0.16733036935329437
[20/24] Train loss=0.16134829819202423
Test set avg_accuracy=84.39% avg_sensitivity=70.81%, avg_specificity=89.17% avg_auc=89.03%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.151774 Test loss=0.369201 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.14586316049098969
[5/24] Train loss=0.13569483160972595
[10/24] Train loss=0.1648183912038803
[15/24] Train loss=0.1602371633052826
[20/24] Train loss=0.15733842551708221
Test set avg_accuracy=84.06% avg_sensitivity=72.56%, avg_specificity=88.11% avg_auc=89.11%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.150403 Test loss=0.374691 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.14530447125434875
[5/24] Train loss=0.1336418241262436
[10/24] Train loss=0.16342011094093323
[15/24] Train loss=0.16444611549377441
[20/24] Train loss=0.1560790091753006
Test set avg_accuracy=84.47% avg_sensitivity=70.91%, avg_specificity=89.24% avg_auc=89.06%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.149707 Test loss=0.368981 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.14426864683628082
[5/24] Train loss=0.13568423688411713
[10/24] Train loss=0.15819783508777618
[15/24] Train loss=0.16517700254917145
[20/24] Train loss=0.15613286197185516
Test set avg_accuracy=84.30% avg_sensitivity=72.41%, avg_specificity=88.48% avg_auc=89.32%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.149421 Test loss=0.371023 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1435340940952301
[5/24] Train loss=0.13356712460517883
[10/24] Train loss=0.16279879212379456
[15/24] Train loss=0.1621178537607193
[20/24] Train loss=0.1600533276796341
Test set avg_accuracy=84.44% avg_sensitivity=69.02%, avg_specificity=89.87% avg_auc=88.64%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.149394 Test loss=0.371878 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.14554765820503235
[5/24] Train loss=0.13500988483428955
[10/24] Train loss=0.16185306012630463
[15/24] Train loss=0.16166247427463531
[20/24] Train loss=0.1578255444765091
Test set avg_accuracy=84.53% avg_sensitivity=71.81%, avg_specificity=89.01% avg_auc=88.92%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.148867 Test loss=0.374343 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.14411625266075134
[5/24] Train loss=0.1320750117301941
[10/24] Train loss=0.15877889096736908
[15/24] Train loss=0.16067077219486237
[20/24] Train loss=0.15611356496810913
Test set avg_accuracy=84.19% avg_sensitivity=72.26%, avg_specificity=88.40% avg_auc=88.98%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.147967 Test loss=0.374196 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.14251936972141266
[5/24] Train loss=0.13337133824825287
[10/24] Train loss=0.16338816285133362
[15/24] Train loss=0.15977410972118378
[20/24] Train loss=0.15596193075180054
Test set avg_accuracy=84.28% avg_sensitivity=70.61%, avg_specificity=89.10% avg_auc=88.87%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.147011 Test loss=0.371803 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1431480348110199
[5/24] Train loss=0.13284294307231903
[10/24] Train loss=0.1573847532272339
[15/24] Train loss=0.16177740693092346
[20/24] Train loss=0.1560005247592926
Test set avg_accuracy=84.18% avg_sensitivity=71.41%, avg_specificity=88.68% avg_auc=88.95%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.147280 Test loss=0.374792 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1454717218875885
[5/24] Train loss=0.13142089545726776
[10/24] Train loss=0.16039057075977325
[15/24] Train loss=0.16041788458824158
[20/24] Train loss=0.15607134997844696
Test set avg_accuracy=84.43% avg_sensitivity=71.36%, avg_specificity=89.03% avg_auc=88.96%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.146464 Test loss=0.372227 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1397145837545395
[5/24] Train loss=0.13339681923389435
[10/24] Train loss=0.15767602622509003
[15/24] Train loss=0.15897470712661743
[20/24] Train loss=0.1548709273338318
Test set avg_accuracy=84.34% avg_sensitivity=72.26%, avg_specificity=88.59% avg_auc=88.90%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.146039 Test loss=0.375111 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1407538652420044
[5/24] Train loss=0.1315644085407257
[10/24] Train loss=0.15599265694618225
[15/24] Train loss=0.16072331368923187
[20/24] Train loss=0.15416187047958374
Test set avg_accuracy=84.21% avg_sensitivity=70.96%, avg_specificity=88.87% avg_auc=88.82%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.145606 Test loss=0.375152 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1405879110097885
[5/24] Train loss=0.13317738473415375
[10/24] Train loss=0.15630003809928894
[15/24] Train loss=0.158258318901062
[20/24] Train loss=0.15455147624015808
Test set avg_accuracy=84.14% avg_sensitivity=71.21%, avg_specificity=88.70% avg_auc=88.84%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.144955 Test loss=0.375298 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.14071913063526154
[5/24] Train loss=0.127735897898674
[10/24] Train loss=0.15711113810539246
[15/24] Train loss=0.15796922147274017
[20/24] Train loss=0.1573866307735443
Test set avg_accuracy=84.13% avg_sensitivity=71.11%, avg_specificity=88.71% avg_auc=88.87%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.145047 Test loss=0.375613 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.14109386503696442
[5/24] Train loss=0.12828408181667328
[10/24] Train loss=0.1570342481136322
[15/24] Train loss=0.15547549724578857
[20/24] Train loss=0.15644468367099762
Test set avg_accuracy=84.17% avg_sensitivity=70.86%, avg_specificity=88.85% avg_auc=88.85%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.144792 Test loss=0.373634 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.14124879240989685
[5/24] Train loss=0.12857253849506378
[10/24] Train loss=0.15708854794502258
[15/24] Train loss=0.15815167129039764
[20/24] Train loss=0.15379910171031952
Test set avg_accuracy=84.24% avg_sensitivity=71.56%, avg_specificity=88.71% avg_auc=88.96%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.145039 Test loss=0.373974 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.14024542272090912
[5/24] Train loss=0.12974807620048523
[10/24] Train loss=0.15579566359519958
[15/24] Train loss=0.1601090282201767
[20/24] Train loss=0.1518324911594391
Test set avg_accuracy=84.05% avg_sensitivity=71.01%, avg_specificity=88.64% avg_auc=88.87%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.144829 Test loss=0.375576 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.14208897948265076
[5/24] Train loss=0.1308736503124237
[10/24] Train loss=0.1550193876028061
[15/24] Train loss=0.15759585797786713
[20/24] Train loss=0.15323354303836823
Test set avg_accuracy=84.21% avg_sensitivity=71.16%, avg_specificity=88.80% avg_auc=88.80%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.144141 Test loss=0.374779 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13925109803676605
[5/24] Train loss=0.12910932302474976
[10/24] Train loss=0.15782096982002258
[15/24] Train loss=0.1560370773077011
[20/24] Train loss=0.15082527697086334
Test set avg_accuracy=84.19% avg_sensitivity=71.26%, avg_specificity=88.75% avg_auc=88.78%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.144086 Test loss=0.376088 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1387210339307785
[5/24] Train loss=0.1295134723186493
[10/24] Train loss=0.15477856993675232
[15/24] Train loss=0.1585930436849594
[20/24] Train loss=0.1514316201210022
Test set avg_accuracy=84.06% avg_sensitivity=71.21%, avg_specificity=88.59% avg_auc=88.85%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.144072 Test loss=0.375915 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.14156609773635864
[5/24] Train loss=0.13117313385009766
[10/24] Train loss=0.1548016220331192
[15/24] Train loss=0.15827934443950653
[20/24] Train loss=0.15399697422981262
Test set avg_accuracy=84.11% avg_sensitivity=71.26%, avg_specificity=88.64% avg_auc=88.85%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.143857 Test loss=0.375208 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.14153802394866943
[5/24] Train loss=0.1299755871295929
[10/24] Train loss=0.1581697165966034
[15/24] Train loss=0.15590128302574158
[20/24] Train loss=0.15477900207042694
Test set avg_accuracy=84.15% avg_sensitivity=71.16%, avg_specificity=88.73% avg_auc=88.86%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.144564 Test loss=0.375332 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.14006726443767548
[5/24] Train loss=0.12819647789001465
[10/24] Train loss=0.15562011301517487
[15/24] Train loss=0.15811298787593842
[20/24] Train loss=0.1502642035484314
Test set avg_accuracy=84.15% avg_sensitivity=71.06%, avg_specificity=88.77% avg_auc=88.82%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.143546 Test loss=0.376134 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13752204179763794
[5/24] Train loss=0.1278521716594696
[10/24] Train loss=0.15601719915866852
[15/24] Train loss=0.15416695177555084
[20/24] Train loss=0.15477873384952545
Test set avg_accuracy=84.18% avg_sensitivity=71.36%, avg_specificity=88.70% avg_auc=88.88%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.143631 Test loss=0.375270 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.14216545224189758
[5/24] Train loss=0.13067471981048584
[10/24] Train loss=0.15308788418769836
[15/24] Train loss=0.15512844920158386
[20/24] Train loss=0.15152299404144287
Test set avg_accuracy=84.10% avg_sensitivity=71.16%, avg_specificity=88.66% avg_auc=88.83%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.144005 Test loss=0.376055 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=85.72% sen=75.21%, spe=89.42%, auc=90.82%!
Fold[4] Avg_overlap=0.67%(±0.24980811659592642)
[0/24] Train loss=0.7337499260902405
[5/24] Train loss=0.7164454460144043
[10/24] Train loss=0.7183316946029663
[15/24] Train loss=0.7068429589271545
[20/24] Train loss=0.7067380547523499
Test set avg_accuracy=62.45% avg_sensitivity=41.99%, avg_specificity=69.43% avg_auc=56.05%
Best model saved!! Metric=-96.08651769358428!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.711826 Test loss=0.674373 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7033040523529053
[5/24] Train loss=0.7035164833068848
[10/24] Train loss=0.6938571929931641
[15/24] Train loss=0.6793980002403259
[20/24] Train loss=0.6928845047950745
Test set avg_accuracy=65.14% avg_sensitivity=41.53%, avg_specificity=73.20% avg_auc=60.56%
Best model saved!! Metric=-85.57661237586535!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.692481 Test loss=0.647408 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6889382004737854
[5/24] Train loss=0.6766468286514282
[10/24] Train loss=0.6758947372436523
[15/24] Train loss=0.6623573899269104
[20/24] Train loss=0.6664365530014038
Test set avg_accuracy=69.80% avg_sensitivity=39.07%, avg_specificity=80.29% avg_auc=64.76%
Best model saved!! Metric=-72.08568670413416!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.673992 Test loss=0.620389 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6635515093803406
[5/24] Train loss=0.6572590470314026
[10/24] Train loss=0.6646609306335449
[15/24] Train loss=0.6472431421279907
[20/24] Train loss=0.6492162346839905
Test set avg_accuracy=74.78% avg_sensitivity=41.17%, avg_specificity=86.24% avg_auc=69.72%
Best model saved!! Metric=-54.095608592147045!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.655204 Test loss=0.592427 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6487314105033875
[5/24] Train loss=0.638923704624176
[10/24] Train loss=0.6363046169281006
[15/24] Train loss=0.6229987144470215
[20/24] Train loss=0.6259632706642151
Test set avg_accuracy=76.90% avg_sensitivity=47.36%, avg_specificity=86.97% avg_auc=72.79%
Best model saved!! Metric=-41.970442041938306!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.633229 Test loss=0.569679 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6166081428527832
[5/24] Train loss=0.6128016710281372
[10/24] Train loss=0.6187453269958496
[15/24] Train loss=0.5981152057647705
[20/24] Train loss=0.6005788445472717
Test set avg_accuracy=77.32% avg_sensitivity=50.59%, avg_specificity=86.43% avg_auc=75.95%
Best model saved!! Metric=-35.7102673240548!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.610522 Test loss=0.539219 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5889715552330017
[5/24] Train loss=0.5886146426200867
[10/24] Train loss=0.5895832777023315
[15/24] Train loss=0.5705922842025757
[20/24] Train loss=0.5795181393623352
Test set avg_accuracy=78.02% avg_sensitivity=54.12%, avg_specificity=86.17% avg_auc=78.37%
Best model saved!! Metric=-29.313350437525607!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.585214 Test loss=0.515957 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5643087029457092
[5/24] Train loss=0.5629976987838745
[10/24] Train loss=0.5649290084838867
[15/24] Train loss=0.5457064509391785
[20/24] Train loss=0.5465710163116455
Test set avg_accuracy=78.75% avg_sensitivity=57.25%, avg_specificity=86.08% avg_auc=80.42%
Best model saved!! Metric=-23.503919259039307!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.560031 Test loss=0.490269 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5420921444892883
[5/24] Train loss=0.5440123677253723
[10/24] Train loss=0.5433040857315063
[15/24] Train loss=0.5211681127548218
[20/24] Train loss=0.5260488986968994
Test set avg_accuracy=79.69% avg_sensitivity=58.63%, avg_specificity=86.87% avg_auc=81.97%
Best model saved!! Metric=-18.845764025178397!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.537462 Test loss=0.467904 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5170037746429443
[5/24] Train loss=0.5288406610488892
[10/24] Train loss=0.5263084769248962
[15/24] Train loss=0.4970131814479828
[20/24] Train loss=0.502483069896698
Test set avg_accuracy=80.17% avg_sensitivity=59.45%, avg_specificity=87.24% avg_auc=82.90%
Best model saved!! Metric=-16.247331795709542!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.516277 Test loss=0.453336 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.49782392382621765
[5/24] Train loss=0.5090699195861816
[10/24] Train loss=0.5074279308319092
[15/24] Train loss=0.4866787791252136
[20/24] Train loss=0.4827536642551422
Test set avg_accuracy=81.09% avg_sensitivity=59.40%, avg_specificity=88.49% avg_auc=84.09%
Best model saved!! Metric=-12.923960772742113!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.498821 Test loss=0.435012 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4807756245136261
[5/24] Train loss=0.49184539914131165
[10/24] Train loss=0.49439695477485657
[15/24] Train loss=0.4669542610645294
[20/24] Train loss=0.4707736372947693
Test set avg_accuracy=81.32% avg_sensitivity=59.24%, avg_specificity=88.84% avg_auc=84.95%
Best model saved!! Metric=-11.65307353758297!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.482593 Test loss=0.422908 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.46765851974487305
[5/24] Train loss=0.47745242714881897
[10/24] Train loss=0.4833166003227234
[15/24] Train loss=0.46052879095077515
[20/24] Train loss=0.45180755853652954
Test set avg_accuracy=81.65% avg_sensitivity=56.02%, avg_specificity=90.40% avg_auc=85.69%
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.467836 Test loss=0.411031 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.44777485728263855
[5/24] Train loss=0.4602344036102295
[10/24] Train loss=0.4665552079677582
[15/24] Train loss=0.44602155685424805
[20/24] Train loss=0.4385635554790497
Test set avg_accuracy=81.77% avg_sensitivity=55.04%, avg_specificity=90.89% avg_auc=86.65%
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.452905 Test loss=0.398086 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4305337071418762
[5/24] Train loss=0.45265066623687744
[10/24] Train loss=0.4617672264575958
[15/24] Train loss=0.42745259404182434
[20/24] Train loss=0.4283214509487152
Test set avg_accuracy=82.40% avg_sensitivity=57.45%, avg_specificity=90.90% avg_auc=87.71%
Best model saved!! Metric=-7.54242375790033!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.441796 Test loss=0.384147 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4223659336566925
[5/24] Train loss=0.445466548204422
[10/24] Train loss=0.44565901160240173
[15/24] Train loss=0.41495341062545776
[20/24] Train loss=0.412697434425354
Test set avg_accuracy=83.01% avg_sensitivity=56.63%, avg_specificity=92.00% avg_auc=88.20%
Best model saved!! Metric=-6.1589845664912275!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.429180 Test loss=0.376168 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.412845641374588
[5/24] Train loss=0.43157699704170227
[10/24] Train loss=0.43518126010894775
[15/24] Train loss=0.4068351984024048
[20/24] Train loss=0.4005507230758667
Test set avg_accuracy=83.48% avg_sensitivity=61.29%, avg_specificity=91.04% avg_auc=88.82%
Best model saved!! Metric=-1.374062958712777!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.419146 Test loss=0.367309 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.40199053287506104
[5/24] Train loss=0.41846024990081787
[10/24] Train loss=0.4275706708431244
[15/24] Train loss=0.3951479196548462
[20/24] Train loss=0.39435911178588867
Test set avg_accuracy=84.04% avg_sensitivity=59.91%, avg_specificity=92.26% avg_auc=89.30%
Best model saved!! Metric=-0.494519917477966!!
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.409655 Test loss=0.360200 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.39154431223869324
[5/24] Train loss=0.41109374165534973
[10/24] Train loss=0.41854891180992126
[15/24] Train loss=0.3876960575580597
[20/24] Train loss=0.38660287857055664
Test set avg_accuracy=84.36% avg_sensitivity=68.97%, avg_specificity=89.61% avg_auc=89.86%
Best model saved!! Metric=6.801293985102447!!
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.400331 Test loss=0.354596 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3816263973712921
[5/24] Train loss=0.4137115776538849
[10/24] Train loss=0.41004514694213867
[15/24] Train loss=0.3792322278022766
[20/24] Train loss=0.37542659044265747
Test set avg_accuracy=84.64% avg_sensitivity=69.74%, avg_specificity=89.72% avg_auc=90.26%
Best model saved!! Metric=8.347611692232974!!
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.393659 Test loss=0.347626 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.37788844108581543
[5/24] Train loss=0.3962293863296509
[10/24] Train loss=0.4035804867744446
[15/24] Train loss=0.36917296051979065
[20/24] Train loss=0.36644473671913147
Test set avg_accuracy=84.24% avg_sensitivity=71.33%, avg_specificity=88.65% avg_auc=90.19%
Best model saved!! Metric=8.40677891528938!!
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.385370 Test loss=0.350010 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3639920651912689
[5/24] Train loss=0.38651469349861145
[10/24] Train loss=0.40371277928352356
[15/24] Train loss=0.3653140068054199
[20/24] Train loss=0.3549763560295105
Test set avg_accuracy=83.97% avg_sensitivity=73.17%, avg_specificity=87.65% avg_auc=90.27%
Best model saved!! Metric=9.070382842200502!!
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.377221 Test loss=0.349159 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3632136285305023
[5/24] Train loss=0.37953174114227295
[10/24] Train loss=0.38504859805107117
[15/24] Train loss=0.3547646701335907
[20/24] Train loss=0.34849390387535095
Test set avg_accuracy=84.57% avg_sensitivity=68.25%, avg_specificity=90.13% avg_auc=90.45%
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.369727 Test loss=0.338498 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3487835228443146
[5/24] Train loss=0.3720903992652893
[10/24] Train loss=0.3892802894115448
[15/24] Train loss=0.3461126685142517
[20/24] Train loss=0.34160831570625305
Test set avg_accuracy=84.78% avg_sensitivity=71.12%, avg_specificity=89.44% avg_auc=90.78%
Best model saved!! Metric=10.11159847249256!!
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.360524 Test loss=0.337321 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3447057604789734
[5/24] Train loss=0.3700912594795227
[10/24] Train loss=0.3881969749927521
[15/24] Train loss=0.3359597325325012
[20/24] Train loss=0.34030261635780334
Test set avg_accuracy=85.27% avg_sensitivity=67.95%, avg_specificity=91.18% avg_auc=90.78%
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.356854 Test loss=0.332291 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3405715823173523
[5/24] Train loss=0.36528193950653076
[10/24] Train loss=0.38108590245246887
[15/24] Train loss=0.3309292197227478
[20/24] Train loss=0.3338567018508911
Test set avg_accuracy=84.56% avg_sensitivity=65.64%, avg_specificity=91.01% avg_auc=90.37%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.351652 Test loss=0.338089 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.33754733204841614
[5/24] Train loss=0.35880738496780396
[10/24] Train loss=0.38626202940940857
[15/24] Train loss=0.32653674483299255
[20/24] Train loss=0.3334004580974579
Test set avg_accuracy=85.31% avg_sensitivity=66.56%, avg_specificity=91.71% avg_auc=91.27%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.346873 Test loss=0.324311 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3304307162761688
[5/24] Train loss=0.3521599769592285
[10/24] Train loss=0.3776533901691437
[15/24] Train loss=0.3236216604709625
[20/24] Train loss=0.3299158811569214
Test set avg_accuracy=85.34% avg_sensitivity=66.72%, avg_specificity=91.69% avg_auc=91.05%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.340678 Test loss=0.326649 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3302112817764282
[5/24] Train loss=0.3597995638847351
[10/24] Train loss=0.3750600516796112
[15/24] Train loss=0.32570821046829224
[20/24] Train loss=0.31959423422813416
Test set avg_accuracy=84.87% avg_sensitivity=58.78%, avg_specificity=93.77% avg_auc=90.58%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.340317 Test loss=0.335682 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.32149770855903625
[5/24] Train loss=0.35677945613861084
[10/24] Train loss=0.36980491876602173
[15/24] Train loss=0.3143182396888733
[20/24] Train loss=0.3206438720226288
Test set avg_accuracy=83.67% avg_sensitivity=45.98%, avg_specificity=96.53% avg_auc=90.03%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.332830 Test loss=0.358494 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3205491006374359
[5/24] Train loss=0.355059951543808
[10/24] Train loss=0.36117643117904663
[15/24] Train loss=0.30912676453590393
[20/24] Train loss=0.3126358389854431
Test set avg_accuracy=85.03% avg_sensitivity=56.12%, avg_specificity=94.88% avg_auc=90.25%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.328227 Test loss=0.342365 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3236396610736847
[5/24] Train loss=0.3424629271030426
[10/24] Train loss=0.36636635661125183
[15/24] Train loss=0.30545490980148315
[20/24] Train loss=0.3030279874801636
Test set avg_accuracy=83.35% avg_sensitivity=40.45%, avg_specificity=97.97% avg_auc=90.06%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.324456 Test loss=0.372644 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3259676694869995
[5/24] Train loss=0.34751445055007935
[10/24] Train loss=0.3658645451068878
[15/24] Train loss=0.2971019446849823
[20/24] Train loss=0.29720041155815125
Test set avg_accuracy=83.75% avg_sensitivity=45.83%, avg_specificity=96.68% avg_auc=89.69%
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.322529 Test loss=0.365777 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.31510627269744873
[5/24] Train loss=0.34455859661102295
[10/24] Train loss=0.36470627784729004
[15/24] Train loss=0.30108287930488586
[20/24] Train loss=0.29230934381484985
Test set avg_accuracy=84.35% avg_sensitivity=47.47%, avg_specificity=96.93% avg_auc=90.38%
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.319977 Test loss=0.349117 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.30439838767051697
[5/24] Train loss=0.35232892632484436
[10/24] Train loss=0.35644635558128357
[15/24] Train loss=0.29263463616371155
[20/24] Train loss=0.29226750135421753
Test set avg_accuracy=85.23% avg_sensitivity=57.25%, avg_specificity=94.78% avg_auc=90.81%
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.315552 Test loss=0.331917 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3080431818962097
[5/24] Train loss=0.3417641818523407
[10/24] Train loss=0.3634895980358124
[15/24] Train loss=0.2936047613620758
[20/24] Train loss=0.30195143818855286
Test set avg_accuracy=84.78% avg_sensitivity=53.35%, avg_specificity=95.50% avg_auc=89.77%
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.313951 Test loss=0.346461 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.30549630522727966
[5/24] Train loss=0.3497045636177063
[10/24] Train loss=0.3588445484638214
[15/24] Train loss=0.2917300760746002
[20/24] Train loss=0.28692755103111267
Test set avg_accuracy=85.13% avg_sensitivity=50.28%, avg_specificity=97.01% avg_auc=90.43%
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.311337 Test loss=0.343837 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.29446980357170105
[5/24] Train loss=0.3181041181087494
[10/24] Train loss=0.35166803002357483
[15/24] Train loss=0.3011893332004547
[20/24] Train loss=0.28004834055900574
Test set avg_accuracy=85.55% avg_sensitivity=55.76%, avg_specificity=95.70% avg_auc=91.78%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.305245 Test loss=0.321942 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.30057114362716675
[5/24] Train loss=0.31733641028404236
[10/24] Train loss=0.3558318316936493
[15/24] Train loss=0.28215497732162476
[20/24] Train loss=0.28386014699935913
Test set avg_accuracy=86.93% avg_sensitivity=66.05%, avg_specificity=94.05% avg_auc=92.52%
Best model saved!! Metric=13.54910775194098!!
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.303138 Test loss=0.304956 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2871551215648651
[5/24] Train loss=0.32858017086982727
[10/24] Train loss=0.34639567136764526
[15/24] Train loss=0.2874701917171478
[20/24] Train loss=0.2776036858558655
Test set avg_accuracy=86.42% avg_sensitivity=66.87%, avg_specificity=93.09% avg_auc=92.33%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.302593 Test loss=0.302502 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.29071131348609924
[5/24] Train loss=0.3207276165485382
[10/24] Train loss=0.3515097200870514
[15/24] Train loss=0.27907371520996094
[20/24] Train loss=0.2779122292995453
Test set avg_accuracy=85.55% avg_sensitivity=70.35%, avg_specificity=90.73% avg_auc=91.32%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.298506 Test loss=0.325888 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.28778988122940063
[5/24] Train loss=0.31147468090057373
[10/24] Train loss=0.34955137968063354
[15/24] Train loss=0.2739880383014679
[20/24] Train loss=0.26967906951904297
Test set avg_accuracy=85.94% avg_sensitivity=71.79%, avg_specificity=90.76% avg_auc=92.53%
Best model saved!! Metric=15.016548579276702!!
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.296584 Test loss=0.303800 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2869361937046051
[5/24] Train loss=0.3179073631763458
[10/24] Train loss=0.34111839532852173
[15/24] Train loss=0.2760879695415497
[20/24] Train loss=0.26641952991485596
Test set avg_accuracy=86.08% avg_sensitivity=63.90%, avg_specificity=93.64% avg_auc=92.03%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.296621 Test loss=0.309743 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2757595181465149
[5/24] Train loss=0.3259177803993225
[10/24] Train loss=0.3392960727214813
[15/24] Train loss=0.2823794186115265
[20/24] Train loss=0.26902103424072266
Test set avg_accuracy=86.55% avg_sensitivity=69.53%, avg_specificity=92.35% avg_auc=92.47%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.292268 Test loss=0.301659 Current lr=[0.00029967723776099]

[0/24] Train loss=0.27352556586265564
[5/24] Train loss=0.3269006907939911
[10/24] Train loss=0.3481447100639343
[15/24] Train loss=0.26862674951553345
[20/24] Train loss=0.2628721296787262
Test set avg_accuracy=86.22% avg_sensitivity=66.77%, avg_specificity=92.86% avg_auc=92.27%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.292115 Test loss=0.305772 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2809237837791443
[5/24] Train loss=0.30880191922187805
[10/24] Train loss=0.3332998752593994
[15/24] Train loss=0.2636941373348236
[20/24] Train loss=0.2671942412853241
Test set avg_accuracy=85.86% avg_sensitivity=70.40%, avg_specificity=91.13% avg_auc=91.95%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.288227 Test loss=0.313800 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2757164239883423
[5/24] Train loss=0.29347357153892517
[10/24] Train loss=0.3238805830478668
[15/24] Train loss=0.2790634334087372
[20/24] Train loss=0.2623741328716278
Test set avg_accuracy=86.13% avg_sensitivity=67.03%, avg_specificity=92.65% avg_auc=91.90%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.285305 Test loss=0.309152 Current lr=[0.000299720220882401]

[0/24] Train loss=0.27238184213638306
[5/24] Train loss=0.30602192878723145
[10/24] Train loss=0.3361009359359741
[15/24] Train loss=0.27624639868736267
[20/24] Train loss=0.2604620158672333
Test set avg_accuracy=85.77% avg_sensitivity=56.12%, avg_specificity=95.88% avg_auc=92.25%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.281018 Test loss=0.315639 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2728371024131775
[5/24] Train loss=0.2855367064476013
[10/24] Train loss=0.324688196182251
[15/24] Train loss=0.27109014987945557
[20/24] Train loss=0.2505963146686554
Test set avg_accuracy=86.21% avg_sensitivity=68.77%, avg_specificity=92.16% avg_auc=92.39%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.281017 Test loss=0.304455 Current lr=[0.000298904600941902]

[0/24] Train loss=0.27180537581443787
[5/24] Train loss=0.2931317090988159
[10/24] Train loss=0.3182060122489929
[15/24] Train loss=0.2549227774143219
[20/24] Train loss=0.25690481066703796
Test set avg_accuracy=86.85% avg_sensitivity=67.74%, avg_specificity=93.36% avg_auc=92.41%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.278844 Test loss=0.300883 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2633368670940399
[5/24] Train loss=0.3012121021747589
[10/24] Train loss=0.3224360942840576
[15/24] Train loss=0.2703372836112976
[20/24] Train loss=0.25332605838775635
Test set avg_accuracy=86.82% avg_sensitivity=66.00%, avg_specificity=93.92% avg_auc=92.15%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.277763 Test loss=0.304037 Current lr=[0.000297555943323901]

[0/24] Train loss=0.270602822303772
[5/24] Train loss=0.3013310134410858
[10/24] Train loss=0.3180984854698181
[15/24] Train loss=0.2618579864501953
[20/24] Train loss=0.257159948348999
Test set avg_accuracy=86.71% avg_sensitivity=66.46%, avg_specificity=93.61% avg_auc=92.26%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.276810 Test loss=0.308438 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.27190518379211426
[5/24] Train loss=0.293720543384552
[10/24] Train loss=0.3182445764541626
[15/24] Train loss=0.2435818463563919
[20/24] Train loss=0.2681368887424469
Test set avg_accuracy=86.46% avg_sensitivity=62.62%, avg_specificity=94.59% avg_auc=92.00%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.274923 Test loss=0.310999 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.27158087491989136
[5/24] Train loss=0.28702136874198914
[10/24] Train loss=0.3153093457221985
[15/24] Train loss=0.24977001547813416
[20/24] Train loss=0.2577698826789856
Test set avg_accuracy=85.53% avg_sensitivity=58.63%, avg_specificity=94.71% avg_auc=91.29%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.273144 Test loss=0.323216 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2527487576007843
[5/24] Train loss=0.2821269631385803
[10/24] Train loss=0.32143837213516235
[15/24] Train loss=0.2635093927383423
[20/24] Train loss=0.25462430715560913
Test set avg_accuracy=86.50% avg_sensitivity=76.29%, avg_specificity=89.98% avg_auc=92.50%
Best model saved!! Metric=19.266674510856475!!
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.270775 Test loss=0.309512 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.25899410247802734
[5/24] Train loss=0.2842801511287689
[10/24] Train loss=0.311873197555542
[15/24] Train loss=0.2619384825229645
[20/24] Train loss=0.2497667372226715
Test set avg_accuracy=86.09% avg_sensitivity=68.05%, avg_specificity=92.25% avg_auc=92.21%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.269604 Test loss=0.306160 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.262487530708313
[5/24] Train loss=0.2800329327583313
[10/24] Train loss=0.3027776777744293
[15/24] Train loss=0.2461870163679123
[20/24] Train loss=0.2582516074180603
Test set avg_accuracy=86.51% avg_sensitivity=72.15%, avg_specificity=91.41% avg_auc=91.83%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.268574 Test loss=0.312419 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2622269093990326
[5/24] Train loss=0.28098031878471375
[10/24] Train loss=0.301381379365921
[15/24] Train loss=0.24353358149528503
[20/24] Train loss=0.2444264441728592
Test set avg_accuracy=86.73% avg_sensitivity=73.53%, avg_specificity=91.23% avg_auc=92.24%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.265516 Test loss=0.308187 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.26096653938293457
[5/24] Train loss=0.27775487303733826
[10/24] Train loss=0.29671767354011536
[15/24] Train loss=0.24825958907604218
[20/24] Train loss=0.25674933195114136
Test set avg_accuracy=87.07% avg_sensitivity=67.03%, avg_specificity=93.91% avg_auc=91.79%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.260891 Test loss=0.309078 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.24291034042835236
[5/24] Train loss=0.27676188945770264
[10/24] Train loss=0.29622265696525574
[15/24] Train loss=0.24695619940757751
[20/24] Train loss=0.24552996456623077
Test set avg_accuracy=86.54% avg_sensitivity=68.71%, avg_specificity=92.61% avg_auc=92.16%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.261310 Test loss=0.305844 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.24925826489925385
[5/24] Train loss=0.2867124676704407
[10/24] Train loss=0.292977899312973
[15/24] Train loss=0.2308901846408844
[20/24] Train loss=0.2451997846364975
Test set avg_accuracy=86.80% avg_sensitivity=72.30%, avg_specificity=91.74% avg_auc=91.80%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.260794 Test loss=0.310873 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2482042759656906
[5/24] Train loss=0.27337291836738586
[10/24] Train loss=0.28375402092933655
[15/24] Train loss=0.22761037945747375
[20/24] Train loss=0.2370200902223587
Test set avg_accuracy=87.73% avg_sensitivity=70.87%, avg_specificity=93.49% avg_auc=92.04%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.252868 Test loss=0.303641 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.24583368003368378
[5/24] Train loss=0.2539694607257843
[10/24] Train loss=0.278851181268692
[15/24] Train loss=0.22692859172821045
[20/24] Train loss=0.24466675519943237
Test set avg_accuracy=86.39% avg_sensitivity=65.08%, avg_specificity=93.66% avg_auc=90.58%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.253192 Test loss=0.321898 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.25813886523246765
[5/24] Train loss=0.2721084654331207
[10/24] Train loss=0.29496464133262634
[15/24] Train loss=0.23948320746421814
[20/24] Train loss=0.2428002953529358
Test set avg_accuracy=85.72% avg_sensitivity=58.01%, avg_specificity=95.16% avg_auc=89.42%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.256043 Test loss=0.340222 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2584681212902069
[5/24] Train loss=0.2696128487586975
[10/24] Train loss=0.28467923402786255
[15/24] Train loss=0.2234649807214737
[20/24] Train loss=0.22276103496551514
Test set avg_accuracy=86.85% avg_sensitivity=69.02%, avg_specificity=92.93% avg_auc=91.86%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.251098 Test loss=0.302565 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.24411070346832275
[5/24] Train loss=0.2638230323791504
[10/24] Train loss=0.2791740596294403
[15/24] Train loss=0.2290213704109192
[20/24] Train loss=0.23402635753154755
Test set avg_accuracy=87.43% avg_sensitivity=74.14%, avg_specificity=91.97% avg_auc=92.55%
Best model saved!! Metric=20.09532619656369!!
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.250844 Test loss=0.299865 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.24921418726444244
[5/24] Train loss=0.2634521424770355
[10/24] Train loss=0.2873428463935852
[15/24] Train loss=0.23158331215381622
[20/24] Train loss=0.23704349994659424
Test set avg_accuracy=86.48% avg_sensitivity=76.09%, avg_specificity=90.03% avg_auc=92.04%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.249381 Test loss=0.319401 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.25571680068969727
[5/24] Train loss=0.25135934352874756
[10/24] Train loss=0.2854675352573395
[15/24] Train loss=0.22485104203224182
[20/24] Train loss=0.23103150725364685
Test set avg_accuracy=86.37% avg_sensitivity=71.12%, avg_specificity=91.57% avg_auc=91.81%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.247783 Test loss=0.311758 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.24168811738491058
[5/24] Train loss=0.259041428565979
[10/24] Train loss=0.2733153700828552
[15/24] Train loss=0.2252786010503769
[20/24] Train loss=0.22618438303470612
Test set avg_accuracy=84.64% avg_sensitivity=80.44%, avg_specificity=86.07% avg_auc=92.54%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.246107 Test loss=0.331724 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2342778742313385
[5/24] Train loss=0.246787428855896
[10/24] Train loss=0.26863399147987366
[15/24] Train loss=0.21719887852668762
[20/24] Train loss=0.23096491396427155
Test set avg_accuracy=87.21% avg_sensitivity=76.96%, avg_specificity=90.71% avg_auc=93.14%
Best model saved!! Metric=22.027558436343398!!
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.244541 Test loss=0.292179 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.22753341495990753
[5/24] Train loss=0.25695887207984924
[10/24] Train loss=0.26811283826828003
[15/24] Train loss=0.22609302401542664
[20/24] Train loss=0.2329723834991455
Test set avg_accuracy=86.15% avg_sensitivity=79.06%, avg_specificity=88.56% avg_auc=92.90%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.240673 Test loss=0.307211 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.2251356840133667
[5/24] Train loss=0.24891886115074158
[10/24] Train loss=0.261316180229187
[15/24] Train loss=0.21838615834712982
[20/24] Train loss=0.22786138951778412
Test set avg_accuracy=86.86% avg_sensitivity=74.81%, avg_specificity=90.97% avg_auc=92.97%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.237204 Test loss=0.297949 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.24247124791145325
[5/24] Train loss=0.2511225640773773
[10/24] Train loss=0.25914302468299866
[15/24] Train loss=0.2219143956899643
[20/24] Train loss=0.22040215134620667
Test set avg_accuracy=86.85% avg_sensitivity=76.40%, avg_specificity=90.41% avg_auc=92.74%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.236710 Test loss=0.303995 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.21823537349700928
[5/24] Train loss=0.2329152226448059
[10/24] Train loss=0.2739450931549072
[15/24] Train loss=0.2322489470243454
[20/24] Train loss=0.22931358218193054
Test set avg_accuracy=86.86% avg_sensitivity=70.51%, avg_specificity=92.44% avg_auc=92.12%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.237124 Test loss=0.305926 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.22404929995536804
[5/24] Train loss=0.23824404180049896
[10/24] Train loss=0.2805476784706116
[15/24] Train loss=0.22278288006782532
[20/24] Train loss=0.22664830088615417
Test set avg_accuracy=87.20% avg_sensitivity=71.94%, avg_specificity=92.40% avg_auc=92.62%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.235873 Test loss=0.299971 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.22713741660118103
[5/24] Train loss=0.2321733981370926
[10/24] Train loss=0.2669074535369873
[15/24] Train loss=0.21302208304405212
[20/24] Train loss=0.21617864072322845
Test set avg_accuracy=86.82% avg_sensitivity=74.60%, avg_specificity=90.99% avg_auc=92.13%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.233746 Test loss=0.309300 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.22304826974868774
[5/24] Train loss=0.23254726827144623
[10/24] Train loss=0.2696954309940338
[15/24] Train loss=0.20575623214244843
[20/24] Train loss=0.21745552122592926
Test set avg_accuracy=86.25% avg_sensitivity=80.03%, avg_specificity=88.37% avg_auc=92.76%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.229549 Test loss=0.313870 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.21886666119098663
[5/24] Train loss=0.22085797786712646
[10/24] Train loss=0.26361364126205444
[15/24] Train loss=0.19773562252521515
[20/24] Train loss=0.21664251387119293
Test set avg_accuracy=85.90% avg_sensitivity=75.01%, avg_specificity=89.61% avg_auc=91.69%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.223174 Test loss=0.322519 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.22649884223937988
[5/24] Train loss=0.22131991386413574
[10/24] Train loss=0.2523711621761322
[15/24] Train loss=0.2037007063627243
[20/24] Train loss=0.21285194158554077
Test set avg_accuracy=86.34% avg_sensitivity=72.61%, avg_specificity=91.02% avg_auc=92.34%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.222937 Test loss=0.307541 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.21356381475925446
[5/24] Train loss=0.2165837585926056
[10/24] Train loss=0.2512841820716858
[15/24] Train loss=0.21200960874557495
[20/24] Train loss=0.21719223260879517
Test set avg_accuracy=86.25% avg_sensitivity=68.05%, avg_specificity=92.46% avg_auc=90.71%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.222666 Test loss=0.320898 Current lr=[0.000224838296036774]

[0/24] Train loss=0.21361181139945984
[5/24] Train loss=0.22363540530204773
[10/24] Train loss=0.25754886865615845
[15/24] Train loss=0.20069576799869537
[20/24] Train loss=0.21149086952209473
Test set avg_accuracy=85.95% avg_sensitivity=76.70%, avg_specificity=89.10% avg_auc=91.51%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.222779 Test loss=0.325480 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.208243265748024
[5/24] Train loss=0.21659553050994873
[10/24] Train loss=0.24806702136993408
[15/24] Train loss=0.20005017518997192
[20/24] Train loss=0.20567049086093903
Test set avg_accuracy=85.81% avg_sensitivity=74.45%, avg_specificity=89.68% avg_auc=91.27%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.217854 Test loss=0.323508 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2164975106716156
[5/24] Train loss=0.22572830319404602
[10/24] Train loss=0.23981712758541107
[15/24] Train loss=0.1937578171491623
[20/24] Train loss=0.20947346091270447
Test set avg_accuracy=86.39% avg_sensitivity=75.63%, avg_specificity=90.06% avg_auc=92.06%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.218814 Test loss=0.315613 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2062680572271347
[5/24] Train loss=0.21371226012706757
[10/24] Train loss=0.24538347125053406
[15/24] Train loss=0.19942550361156464
[20/24] Train loss=0.20447053015232086
Test set avg_accuracy=85.62% avg_sensitivity=71.79%, avg_specificity=90.34% avg_auc=90.70%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.215131 Test loss=0.334806 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.20082522928714752
[5/24] Train loss=0.21537911891937256
[10/24] Train loss=0.23677919805049896
[15/24] Train loss=0.1989412158727646
[20/24] Train loss=0.19896948337554932
Test set avg_accuracy=85.86% avg_sensitivity=77.47%, avg_specificity=88.72% avg_auc=91.41%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.215216 Test loss=0.330465 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2021833211183548
[5/24] Train loss=0.21510322391986847
[10/24] Train loss=0.2359262853860855
[15/24] Train loss=0.1881672888994217
[20/24] Train loss=0.20072583854198456
Test set avg_accuracy=85.07% avg_sensitivity=71.84%, avg_specificity=89.58% avg_auc=89.97%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.210663 Test loss=0.342573 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.19312484562397003
[5/24] Train loss=0.19812241196632385
[10/24] Train loss=0.22879968583583832
[15/24] Train loss=0.19302159547805786
[20/24] Train loss=0.20927971601486206
Test set avg_accuracy=85.53% avg_sensitivity=66.82%, avg_specificity=91.92% avg_auc=89.57%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.207909 Test loss=0.341523 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.20756322145462036
[5/24] Train loss=0.2102302461862564
[10/24] Train loss=0.22882752120494843
[15/24] Train loss=0.18497858941555023
[20/24] Train loss=0.20311063528060913
Test set avg_accuracy=86.05% avg_sensitivity=73.02%, avg_specificity=90.50% avg_auc=91.30%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.204853 Test loss=0.322675 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.19720841944217682
[5/24] Train loss=0.18410280346870422
[10/24] Train loss=0.2386145144701004
[15/24] Train loss=0.18887390196323395
[20/24] Train loss=0.19751553237438202
Test set avg_accuracy=84.88% avg_sensitivity=76.34%, avg_specificity=87.79% avg_auc=91.65%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.205304 Test loss=0.331488 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.20247682929039001
[5/24] Train loss=0.2023317664861679
[10/24] Train loss=0.23569877445697784
[15/24] Train loss=0.18802084028720856
[20/24] Train loss=0.20061026513576508
Test set avg_accuracy=85.14% avg_sensitivity=75.42%, avg_specificity=88.46% avg_auc=91.22%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.202822 Test loss=0.338032 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.20576857030391693
[5/24] Train loss=0.1870589405298233
[10/24] Train loss=0.2209453135728836
[15/24] Train loss=0.18678046762943268
[20/24] Train loss=0.20007523894309998
Test set avg_accuracy=85.70% avg_sensitivity=74.81%, avg_specificity=89.42% avg_auc=91.72%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.202072 Test loss=0.329357 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.20578128099441528
[5/24] Train loss=0.197132870554924
[10/24] Train loss=0.2321196049451828
[15/24] Train loss=0.18690136075019836
[20/24] Train loss=0.19756893813610077
Test set avg_accuracy=85.92% avg_sensitivity=69.84%, avg_specificity=91.41% avg_auc=90.75%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.203934 Test loss=0.325220 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.208853617310524
[5/24] Train loss=0.20437148213386536
[10/24] Train loss=0.2294740378856659
[15/24] Train loss=0.19415143132209778
[20/24] Train loss=0.19839496910572052
Test set avg_accuracy=85.82% avg_sensitivity=70.56%, avg_specificity=91.02% avg_auc=91.33%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.203433 Test loss=0.325060 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2058640420436859
[5/24] Train loss=0.18993301689624786
[10/24] Train loss=0.23160652816295624
[15/24] Train loss=0.19445767998695374
[20/24] Train loss=0.1947934478521347
Test set avg_accuracy=84.39% avg_sensitivity=64.16%, avg_specificity=91.29% avg_auc=89.58%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.202794 Test loss=0.352815 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.20021995902061462
[5/24] Train loss=0.18744204938411713
[10/24] Train loss=0.22179310023784637
[15/24] Train loss=0.19803427159786224
[20/24] Train loss=0.19306732714176178
Test set avg_accuracy=84.66% avg_sensitivity=60.98%, avg_specificity=92.74% avg_auc=88.65%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.199107 Test loss=0.364941 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.20729345083236694
[5/24] Train loss=0.214261993765831
[10/24] Train loss=0.22396226227283478
[15/24] Train loss=0.19168758392333984
[20/24] Train loss=0.1951225996017456
Test set avg_accuracy=83.91% avg_sensitivity=51.97%, avg_specificity=94.80% avg_auc=85.74%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.204995 Test loss=0.399959 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2009456753730774
[5/24] Train loss=0.1886911243200302
[10/24] Train loss=0.21800264716148376
[15/24] Train loss=0.1866382360458374
[20/24] Train loss=0.1934591382741928
Test set avg_accuracy=85.83% avg_sensitivity=68.46%, avg_specificity=91.76% avg_auc=90.83%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.199639 Test loss=0.328893 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.19324088096618652
[5/24] Train loss=0.19638921320438385
[10/24] Train loss=0.21802175045013428
[15/24] Train loss=0.18985603749752045
[20/24] Train loss=0.1938432902097702
Test set avg_accuracy=84.66% avg_sensitivity=63.44%, avg_specificity=91.90% avg_auc=88.15%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.195914 Test loss=0.365769 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.20007675886154175
[5/24] Train loss=0.18507561087608337
[10/24] Train loss=0.2208615243434906
[15/24] Train loss=0.19386950135231018
[20/24] Train loss=0.1859179586172104
Test set avg_accuracy=84.35% avg_sensitivity=64.82%, avg_specificity=91.01% avg_auc=88.51%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.194345 Test loss=0.363975 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.18915440142154694
[5/24] Train loss=0.1862524449825287
[10/24] Train loss=0.21440908312797546
[15/24] Train loss=0.1846667230129242
[20/24] Train loss=0.18832960724830627
Test set avg_accuracy=83.29% avg_sensitivity=56.07%, avg_specificity=92.58% avg_auc=86.60%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.193239 Test loss=0.393616 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1943603903055191
[5/24] Train loss=0.18529346585273743
[10/24] Train loss=0.2168385237455368
[15/24] Train loss=0.17849290370941162
[20/24] Train loss=0.19033074378967285
Test set avg_accuracy=85.51% avg_sensitivity=66.82%, avg_specificity=91.88% avg_auc=89.43%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.189974 Test loss=0.344700 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1865546703338623
[5/24] Train loss=0.18162816762924194
[10/24] Train loss=0.21388976275920868
[15/24] Train loss=0.17701010406017303
[20/24] Train loss=0.1798369288444519
Test set avg_accuracy=85.61% avg_sensitivity=63.03%, avg_specificity=93.31% avg_auc=88.63%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.186385 Test loss=0.355611 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.19347186386585236
[5/24] Train loss=0.17796370387077332
[10/24] Train loss=0.20344921946525574
[15/24] Train loss=0.1704373061656952
[20/24] Train loss=0.1805928349494934
Test set avg_accuracy=86.12% avg_sensitivity=69.53%, avg_specificity=91.78% avg_auc=90.31%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.183970 Test loss=0.332041 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.18539541959762573
[5/24] Train loss=0.17698781192302704
[10/24] Train loss=0.20674550533294678
[15/24] Train loss=0.17267610132694244
[20/24] Train loss=0.17860634624958038
Test set avg_accuracy=85.22% avg_sensitivity=68.00%, avg_specificity=91.09% avg_auc=89.48%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.182721 Test loss=0.346589 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.17881101369857788
[5/24] Train loss=0.17450135946273804
[10/24] Train loss=0.20140884816646576
[15/24] Train loss=0.16157697141170502
[20/24] Train loss=0.177561417222023
Test set avg_accuracy=85.55% avg_sensitivity=68.71%, avg_specificity=91.29% avg_auc=89.80%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.177454 Test loss=0.338738 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1788322478532791
[5/24] Train loss=0.1700558215379715
[10/24] Train loss=0.2017897218465805
[15/24] Train loss=0.16703014075756073
[20/24] Train loss=0.17396987974643707
Test set avg_accuracy=85.12% avg_sensitivity=68.61%, avg_specificity=90.75% avg_auc=89.98%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.176781 Test loss=0.340410 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.18421371281147003
[5/24] Train loss=0.1705920249223709
[10/24] Train loss=0.20397742092609406
[15/24] Train loss=0.16464945673942566
[20/24] Train loss=0.18020404875278473
Test set avg_accuracy=86.25% avg_sensitivity=73.73%, avg_specificity=90.52% avg_auc=91.78%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.177787 Test loss=0.321077 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.17904937267303467
[5/24] Train loss=0.17062947154045105
[10/24] Train loss=0.19803054630756378
[15/24] Train loss=0.16959264874458313
[20/24] Train loss=0.17042997479438782
Test set avg_accuracy=86.60% avg_sensitivity=71.63%, avg_specificity=91.71% avg_auc=90.72%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.175276 Test loss=0.325128 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.17502543330192566
[5/24] Train loss=0.16739143431186676
[10/24] Train loss=0.19266997277736664
[15/24] Train loss=0.15675781667232513
[20/24] Train loss=0.17180748283863068
Test set avg_accuracy=85.62% avg_sensitivity=72.71%, avg_specificity=90.03% avg_auc=91.31%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.171128 Test loss=0.327242 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1750214397907257
[5/24] Train loss=0.17124681174755096
[10/24] Train loss=0.18646514415740967
[15/24] Train loss=0.16258424520492554
[20/24] Train loss=0.1800435483455658
Test set avg_accuracy=85.59% avg_sensitivity=73.89%, avg_specificity=89.58% avg_auc=90.84%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.169655 Test loss=0.331546 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.17224140465259552
[5/24] Train loss=0.1665222942829132
[10/24] Train loss=0.1835757941007614
[15/24] Train loss=0.15769438445568085
[20/24] Train loss=0.16295072436332703
Test set avg_accuracy=85.87% avg_sensitivity=68.41%, avg_specificity=91.83% avg_auc=90.19%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.167778 Test loss=0.339246 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.17468027770519257
[5/24] Train loss=0.1646079421043396
[10/24] Train loss=0.18909995257854462
[15/24] Train loss=0.1569993793964386
[20/24] Train loss=0.16580991446971893
Test set avg_accuracy=85.96% avg_sensitivity=70.15%, avg_specificity=91.36% avg_auc=90.52%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.167822 Test loss=0.332343 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1664731204509735
[5/24] Train loss=0.15787950158119202
[10/24] Train loss=0.19501471519470215
[15/24] Train loss=0.15280482172966003
[20/24] Train loss=0.16367579996585846
Test set avg_accuracy=86.08% avg_sensitivity=70.66%, avg_specificity=91.34% avg_auc=90.30%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.164262 Test loss=0.336508 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1729792058467865
[5/24] Train loss=0.15916341543197632
[10/24] Train loss=0.18762429058551788
[15/24] Train loss=0.14940819144248962
[20/24] Train loss=0.16003088653087616
Test set avg_accuracy=85.57% avg_sensitivity=68.51%, avg_specificity=91.39% avg_auc=90.69%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.163053 Test loss=0.335630 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.16565051674842834
[5/24] Train loss=0.1559155285358429
[10/24] Train loss=0.18300674855709076
[15/24] Train loss=0.15592347085475922
[20/24] Train loss=0.16256830096244812
Test set avg_accuracy=85.18% avg_sensitivity=68.97%, avg_specificity=90.71% avg_auc=90.75%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.162058 Test loss=0.336024 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1668122410774231
[5/24] Train loss=0.1556435078382492
[10/24] Train loss=0.1790425330400467
[15/24] Train loss=0.1501549482345581
[20/24] Train loss=0.1630723774433136
Test set avg_accuracy=85.72% avg_sensitivity=67.33%, avg_specificity=91.99% avg_auc=90.33%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.160451 Test loss=0.335781 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1647832989692688
[5/24] Train loss=0.15475788712501526
[10/24] Train loss=0.17790833115577698
[15/24] Train loss=0.14883458614349365
[20/24] Train loss=0.16410930454730988
Test set avg_accuracy=85.82% avg_sensitivity=70.61%, avg_specificity=91.01% avg_auc=91.04%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.159528 Test loss=0.329641 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.16900289058685303
[5/24] Train loss=0.1509747952222824
[10/24] Train loss=0.18069100379943848
[15/24] Train loss=0.14876259863376617
[20/24] Train loss=0.15760979056358337
Test set avg_accuracy=86.02% avg_sensitivity=72.76%, avg_specificity=90.54% avg_auc=91.67%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.157517 Test loss=0.322326 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.16040967404842377
[5/24] Train loss=0.1472407728433609
[10/24] Train loss=0.17476524412631989
[15/24] Train loss=0.1421474665403366
[20/24] Train loss=0.15983107686042786
Test set avg_accuracy=85.70% avg_sensitivity=73.32%, avg_specificity=89.92% avg_auc=91.13%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.155253 Test loss=0.330557 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1598528027534485
[5/24] Train loss=0.14725522696971893
[10/24] Train loss=0.17732521891593933
[15/24] Train loss=0.14208638668060303
[20/24] Train loss=0.1588752120733261
Test set avg_accuracy=85.90% avg_sensitivity=70.71%, avg_specificity=91.08% avg_auc=90.89%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.154201 Test loss=0.328485 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1594546139240265
[5/24] Train loss=0.14824989438056946
[10/24] Train loss=0.17912223935127258
[15/24] Train loss=0.1451662927865982
[20/24] Train loss=0.15520812571048737
Test set avg_accuracy=85.53% avg_sensitivity=69.48%, avg_specificity=91.01% avg_auc=90.68%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.154112 Test loss=0.335356 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.15901388227939606
[5/24] Train loss=0.14511562883853912
[10/24] Train loss=0.16841784119606018
[15/24] Train loss=0.14135122299194336
[20/24] Train loss=0.1564285308122635
Test set avg_accuracy=85.44% avg_sensitivity=71.84%, avg_specificity=90.08% avg_auc=90.96%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.153447 Test loss=0.333502 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.15858279168605804
[5/24] Train loss=0.14602918922901154
[10/24] Train loss=0.170181006193161
[15/24] Train loss=0.14092357456684113
[20/24] Train loss=0.15468479692935944
Test set avg_accuracy=85.66% avg_sensitivity=68.87%, avg_specificity=91.39% avg_auc=90.14%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.152248 Test loss=0.339408 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.15912094712257385
[5/24] Train loss=0.14483144879341125
[10/24] Train loss=0.17417441308498383
[15/24] Train loss=0.14585676789283752
[20/24] Train loss=0.1547517478466034
Test set avg_accuracy=85.89% avg_sensitivity=71.68%, avg_specificity=90.73% avg_auc=90.65%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.151556 Test loss=0.334106 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1556359976530075
[5/24] Train loss=0.15125319361686707
[10/24] Train loss=0.16773301362991333
[15/24] Train loss=0.14136706292629242
[20/24] Train loss=0.15561656653881073
Test set avg_accuracy=85.70% avg_sensitivity=71.33%, avg_specificity=90.61% avg_auc=90.35%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.151944 Test loss=0.338970 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1610375940799713
[5/24] Train loss=0.14723841845989227
[10/24] Train loss=0.1688314825296402
[15/24] Train loss=0.1418631672859192
[20/24] Train loss=0.15305465459823608
Test set avg_accuracy=85.85% avg_sensitivity=71.22%, avg_specificity=90.83% avg_auc=90.64%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.150961 Test loss=0.333472 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.15742576122283936
[5/24] Train loss=0.14543786644935608
[10/24] Train loss=0.16980542242527008
[15/24] Train loss=0.1411372870206833
[20/24] Train loss=0.15999628603458405
Test set avg_accuracy=85.64% avg_sensitivity=69.48%, avg_specificity=91.15% avg_auc=90.52%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.151190 Test loss=0.336422 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.15549317002296448
[5/24] Train loss=0.1442500799894333
[10/24] Train loss=0.16845184564590454
[15/24] Train loss=0.1346738040447235
[20/24] Train loss=0.15664489567279816
Test set avg_accuracy=85.85% avg_sensitivity=71.07%, avg_specificity=90.89% avg_auc=90.73%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.149832 Test loss=0.334662 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.15578845143318176
[5/24] Train loss=0.1400725096464157
[10/24] Train loss=0.16893960535526276
[15/24] Train loss=0.1360948085784912
[20/24] Train loss=0.1527356505393982
Test set avg_accuracy=85.59% avg_sensitivity=69.07%, avg_specificity=91.22% avg_auc=90.44%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.148757 Test loss=0.337814 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.15140566229820251
[5/24] Train loss=0.14468513429164886
[10/24] Train loss=0.1644546389579773
[15/24] Train loss=0.1347123235464096
[20/24] Train loss=0.15183375775814056
Test set avg_accuracy=85.81% avg_sensitivity=70.40%, avg_specificity=91.06% avg_auc=90.64%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.147582 Test loss=0.334736 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.15176020562648773
[5/24] Train loss=0.14366891980171204
[10/24] Train loss=0.1671963781118393
[15/24] Train loss=0.13483305275440216
[20/24] Train loss=0.15138159692287445
Test set avg_accuracy=85.57% avg_sensitivity=71.89%, avg_specificity=90.24% avg_auc=90.92%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.146840 Test loss=0.334670 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.15147247910499573
[5/24] Train loss=0.140049010515213
[10/24] Train loss=0.16428546607494354
[15/24] Train loss=0.1346202939748764
[20/24] Train loss=0.14928382635116577
Test set avg_accuracy=85.99% avg_sensitivity=70.81%, avg_specificity=91.16% avg_auc=90.26%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.145773 Test loss=0.337352 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.15257109701633453
[5/24] Train loss=0.14330355823040009
[10/24] Train loss=0.1617487668991089
[15/24] Train loss=0.13382835686206818
[20/24] Train loss=0.1490604728460312
Test set avg_accuracy=85.86% avg_sensitivity=71.63%, avg_specificity=90.71% avg_auc=90.71%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.145747 Test loss=0.334531 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.14867983758449554
[5/24] Train loss=0.14207568764686584
[10/24] Train loss=0.16719304025173187
[15/24] Train loss=0.13228684663772583
[20/24] Train loss=0.14943662285804749
Test set avg_accuracy=85.92% avg_sensitivity=71.22%, avg_specificity=90.94% avg_auc=90.50%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.145652 Test loss=0.334984 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.15502215921878815
[5/24] Train loss=0.1418469250202179
[10/24] Train loss=0.16265004873275757
[15/24] Train loss=0.13275480270385742
[20/24] Train loss=0.14916884899139404
Test set avg_accuracy=85.53% avg_sensitivity=71.33%, avg_specificity=90.38% avg_auc=90.58%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.145274 Test loss=0.335070 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.15436705946922302
[5/24] Train loss=0.14170296490192413
[10/24] Train loss=0.1678476780653
[15/24] Train loss=0.13451360166072845
[20/24] Train loss=0.1473834365606308
Test set avg_accuracy=85.79% avg_sensitivity=69.89%, avg_specificity=91.22% avg_auc=90.39%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.145223 Test loss=0.336518 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1503036916255951
[5/24] Train loss=0.14266762137413025
[10/24] Train loss=0.16041648387908936
[15/24] Train loss=0.1337662637233734
[20/24] Train loss=0.14914092421531677
Test set avg_accuracy=85.77% avg_sensitivity=71.02%, avg_specificity=90.80% avg_auc=90.36%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.144281 Test loss=0.338234 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.14908307790756226
[5/24] Train loss=0.14000976085662842
[10/24] Train loss=0.16541843116283417
[15/24] Train loss=0.13488732278347015
[20/24] Train loss=0.1476246863603592
Test set avg_accuracy=85.62% avg_sensitivity=70.35%, avg_specificity=90.83% avg_auc=90.37%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.143661 Test loss=0.338016 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.14938701689243317
[5/24] Train loss=0.14030678570270538
[10/24] Train loss=0.15854226052761078
[15/24] Train loss=0.1312398910522461
[20/24] Train loss=0.14537853002548218
Test set avg_accuracy=85.68% avg_sensitivity=71.48%, avg_specificity=90.52% avg_auc=90.61%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.143942 Test loss=0.335803 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.15051056444644928
[5/24] Train loss=0.1377485990524292
[10/24] Train loss=0.16327033936977386
[15/24] Train loss=0.13372528553009033
[20/24] Train loss=0.1461580991744995
Test set avg_accuracy=85.70% avg_sensitivity=70.71%, avg_specificity=90.82% avg_auc=90.46%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.144066 Test loss=0.335827 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.14915594458580017
[5/24] Train loss=0.13926061987876892
[10/24] Train loss=0.1607794612646103
[15/24] Train loss=0.13306352496147156
[20/24] Train loss=0.14848385751247406
Test set avg_accuracy=85.73% avg_sensitivity=70.46%, avg_specificity=90.94% avg_auc=90.40%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.143769 Test loss=0.337434 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.14768117666244507
[5/24] Train loss=0.13738438487052917
[10/24] Train loss=0.16107772290706635
[15/24] Train loss=0.13277895748615265
[20/24] Train loss=0.14709047973155975
Test set avg_accuracy=85.69% avg_sensitivity=71.22%, avg_specificity=90.62% avg_auc=90.60%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.143227 Test loss=0.336217 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1506487876176834
[5/24] Train loss=0.13894622027873993
[10/24] Train loss=0.16071529686450958
[15/24] Train loss=0.13293705880641937
[20/24] Train loss=0.15054447948932648
Test set avg_accuracy=85.81% avg_sensitivity=70.92%, avg_specificity=90.89% avg_auc=90.62%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.143312 Test loss=0.335222 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.15145449340343475
[5/24] Train loss=0.13941332697868347
[10/24] Train loss=0.15962384641170502
[15/24] Train loss=0.1337839961051941
[20/24] Train loss=0.14594587683677673
Test set avg_accuracy=85.78% avg_sensitivity=70.92%, avg_specificity=90.85% avg_auc=90.57%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.143244 Test loss=0.335659 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.14957915246486664
[5/24] Train loss=0.1351204514503479
[10/24] Train loss=0.15871164202690125
[15/24] Train loss=0.1329347938299179
[20/24] Train loss=0.14721199870109558
Test set avg_accuracy=85.64% avg_sensitivity=70.25%, avg_specificity=90.89% avg_auc=90.48%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.142606 Test loss=0.336685 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.14889991283416748
[5/24] Train loss=0.13449929654598236
[10/24] Train loss=0.15872208774089813
[15/24] Train loss=0.13223357498645782
[20/24] Train loss=0.14665190875530243
Test set avg_accuracy=85.70% avg_sensitivity=70.71%, avg_specificity=90.82% avg_auc=90.46%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.142894 Test loss=0.337253 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.14625990390777588
[5/24] Train loss=0.13810260593891144
[10/24] Train loss=0.1619456708431244
[15/24] Train loss=0.13368143141269684
[20/24] Train loss=0.14620178937911987
Test set avg_accuracy=85.69% avg_sensitivity=70.76%, avg_specificity=90.78% avg_auc=90.48%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.142790 Test loss=0.337036 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.14904829859733582
[5/24] Train loss=0.13769613206386566
[10/24] Train loss=0.16059033572673798
[15/24] Train loss=0.13003051280975342
[20/24] Train loss=0.1462268978357315
Test set avg_accuracy=85.72% avg_sensitivity=70.61%, avg_specificity=90.87% avg_auc=90.50%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.143199 Test loss=0.336720 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.14906905591487885
[5/24] Train loss=0.13710066676139832
[10/24] Train loss=0.15782544016838074
[15/24] Train loss=0.1300899237394333
[20/24] Train loss=0.14728006720542908
Test set avg_accuracy=85.73% avg_sensitivity=70.87%, avg_specificity=90.80% avg_auc=90.50%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.143413 Test loss=0.336990 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.14846859872341156
[5/24] Train loss=0.1376311182975769
[10/24] Train loss=0.15872302651405334
[15/24] Train loss=0.13181793689727783
[20/24] Train loss=0.14688782393932343
Test set avg_accuracy=85.82% avg_sensitivity=70.87%, avg_specificity=90.92% avg_auc=90.46%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.143081 Test loss=0.337415 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=87.21% sen=76.96%, spe=90.71%, auc=93.14%!
Fold[5] Avg_overlap=0.67%(±0.24441722769772156)
[0/24] Train loss=0.773705780506134
[5/24] Train loss=0.7754092812538147
[10/24] Train loss=0.763454794883728
[15/24] Train loss=0.7593124508857727
[20/24] Train loss=0.7536868453025818
Test set avg_accuracy=54.30% avg_sensitivity=47.36%, avg_specificity=56.88% avg_auc=53.12%
Best model saved!! Metric=-114.34287984957037!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.762784 Test loss=0.714945 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7529451251029968
[5/24] Train loss=0.7459182143211365
[10/24] Train loss=0.7479612827301025
[15/24] Train loss=0.7427242398262024
[20/24] Train loss=0.7380458116531372
Test set avg_accuracy=59.87% avg_sensitivity=43.09%, avg_specificity=66.12% avg_auc=55.83%
Best model saved!! Metric=-101.09533543261867!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.743520 Test loss=0.681363 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7351661920547485
[5/24] Train loss=0.7329893708229065
[10/24] Train loss=0.7334529161453247
[15/24] Train loss=0.7207549810409546
[20/24] Train loss=0.718757152557373
Test set avg_accuracy=63.67% avg_sensitivity=41.17%, avg_specificity=72.05% avg_auc=57.71%
Best model saved!! Metric=-91.39834790393878!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.727115 Test loss=0.669245 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.7232345938682556
[5/24] Train loss=0.7072493433952332
[10/24] Train loss=0.7177849411964417
[15/24] Train loss=0.7151809930801392
[20/24] Train loss=0.7010235786437988
Test set avg_accuracy=65.44% avg_sensitivity=41.22%, avg_specificity=74.46% avg_auc=60.10%
Best model saved!! Metric=-84.77464718795348!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.713810 Test loss=0.653397 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6983898282051086
[5/24] Train loss=0.701758623123169
[10/24] Train loss=0.6970009207725525
[15/24] Train loss=0.6873470544815063
[20/24] Train loss=0.6794521808624268
Test set avg_accuracy=67.80% avg_sensitivity=40.93%, avg_specificity=77.81% avg_auc=63.07%
Best model saved!! Metric=-76.39752695506273!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.692027 Test loss=0.631553 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.676368236541748
[5/24] Train loss=0.6684971451759338
[10/24] Train loss=0.6758837699890137
[15/24] Train loss=0.6557510495185852
[20/24] Train loss=0.6484741568565369
Test set avg_accuracy=70.25% avg_sensitivity=42.56%, avg_specificity=80.56% avg_auc=67.03%
Best model saved!! Metric=-65.60715049740193!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.670328 Test loss=0.603616 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6511282920837402
[5/24] Train loss=0.6392697691917419
[10/24] Train loss=0.6464368104934692
[15/24] Train loss=0.6309072375297546
[20/24] Train loss=0.6277034878730774
Test set avg_accuracy=72.38% avg_sensitivity=46.26%, avg_specificity=82.11% avg_auc=70.81%
Best model saved!! Metric=-54.437252455911754!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.642954 Test loss=0.574306 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6238586902618408
[5/24] Train loss=0.6141979694366455
[10/24] Train loss=0.6204361319541931
[15/24] Train loss=0.6046712398529053
[20/24] Train loss=0.5895947813987732
Test set avg_accuracy=75.09% avg_sensitivity=48.56%, avg_specificity=84.97% avg_auc=73.51%
Best model saved!! Metric=-43.87161358901249!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.613262 Test loss=0.548363 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5875461101531982
[5/24] Train loss=0.5857228636741638
[10/24] Train loss=0.5904424786567688
[15/24] Train loss=0.5800337195396423
[20/24] Train loss=0.5625929236412048
Test set avg_accuracy=76.35% avg_sensitivity=52.35%, avg_specificity=85.29% avg_auc=76.43%
Best model saved!! Metric=-35.57352589272934!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.586009 Test loss=0.521933 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5604660511016846
[5/24] Train loss=0.5568706393241882
[10/24] Train loss=0.5633839964866638
[15/24] Train loss=0.5499834418296814
[20/24] Train loss=0.5316975712776184
Test set avg_accuracy=77.27% avg_sensitivity=54.61%, avg_specificity=85.70% avg_auc=78.29%
Best model saved!! Metric=-30.138039908715996!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.559054 Test loss=0.506345 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5284103155136108
[5/24] Train loss=0.5342655181884766
[10/24] Train loss=0.5423580408096313
[15/24] Train loss=0.5381463766098022
[20/24] Train loss=0.5079278945922852
Test set avg_accuracy=77.68% avg_sensitivity=54.75%, avg_specificity=86.22% avg_auc=79.20%
Best model saved!! Metric=-28.148225469922536!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.536371 Test loss=0.492391 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5049636363983154
[5/24] Train loss=0.5079464912414551
[10/24] Train loss=0.5163050889968872
[15/24] Train loss=0.5166041254997253
[20/24] Train loss=0.4848000407218933
Test set avg_accuracy=78.42% avg_sensitivity=56.14%, avg_specificity=86.72% avg_auc=80.71%
Best model saved!! Metric=-24.002360884974273!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.514373 Test loss=0.473489 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.48548591136932373
[5/24] Train loss=0.48996034264564514
[10/24] Train loss=0.5016458630561829
[15/24] Train loss=0.5015106201171875
[20/24] Train loss=0.47582951188087463
Test set avg_accuracy=79.05% avg_sensitivity=55.95%, avg_specificity=87.65% avg_auc=81.68%
Best model saved!! Metric=-21.667950783983578!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.496764 Test loss=0.459506 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.4638994336128235
[5/24] Train loss=0.4707790017127991
[10/24] Train loss=0.4848285913467407
[15/24] Train loss=0.48779529333114624
[20/24] Train loss=0.45305582880973816
Test set avg_accuracy=79.61% avg_sensitivity=55.52%, avg_specificity=88.58% avg_auc=82.25%
Best model saved!! Metric=-20.0456100866879!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.479454 Test loss=0.449889 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4499526023864746
[5/24] Train loss=0.46520891785621643
[10/24] Train loss=0.4704737663269043
[15/24] Train loss=0.4718724191188812
[20/24] Train loss=0.43586644530296326
Test set avg_accuracy=80.27% avg_sensitivity=55.52%, avg_specificity=89.49% avg_auc=83.79%
Best model saved!! Metric=-16.926789149416436!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.464613 Test loss=0.433509 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.43827134370803833
[5/24] Train loss=0.4468652904033661
[10/24] Train loss=0.4514014720916748
[15/24] Train loss=0.45948582887649536
[20/24] Train loss=0.4249914288520813
Test set avg_accuracy=80.51% avg_sensitivity=55.28%, avg_specificity=89.90% avg_auc=84.52%
Best model saved!! Metric=-15.785576388965126!!
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.450132 Test loss=0.423288 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4216836392879486
[5/24] Train loss=0.4343738853931427
[10/24] Train loss=0.4443736672401428
[15/24] Train loss=0.44703981280326843
[20/24] Train loss=0.4116167426109314
Test set avg_accuracy=81.26% avg_sensitivity=57.49%, avg_specificity=90.12% avg_auc=85.77%
Best model saved!! Metric=-11.36244958082321!!
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.438618 Test loss=0.408837 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.41099879145622253
[5/24] Train loss=0.4231751263141632
[10/24] Train loss=0.430672287940979
[15/24] Train loss=0.433203786611557
[20/24] Train loss=0.4040083885192871
Test set avg_accuracy=81.85% avg_sensitivity=57.20%, avg_specificity=91.03% avg_auc=86.58%
Best model saved!! Metric=-9.344197012066935!!
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.427373 Test loss=0.399683 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.39653927087783813
[5/24] Train loss=0.4141429364681244
[10/24] Train loss=0.4236742854118347
[15/24] Train loss=0.4181118905544281
[20/24] Train loss=0.3915315270423889
Test set avg_accuracy=82.57% avg_sensitivity=59.55%, avg_specificity=91.14% avg_auc=87.65%
Best model saved!! Metric=-5.09531889395106!!
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.415989 Test loss=0.386960 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.38466671109199524
[5/24] Train loss=0.40720248222351074
[10/24] Train loss=0.40683671832084656
[15/24] Train loss=0.405275821685791
[20/24] Train loss=0.38558727502822876
Test set avg_accuracy=83.18% avg_sensitivity=63.87%, avg_specificity=90.37% avg_auc=88.58%
Best model saved!! Metric=-0.002589150028114773!!
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.406313 Test loss=0.376496 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.37676331400871277
[5/24] Train loss=0.40019774436950684
[10/24] Train loss=0.3978891670703888
[15/24] Train loss=0.4026782214641571
[20/24] Train loss=0.3713560402393341
Test set avg_accuracy=83.83% avg_sensitivity=64.49%, avg_specificity=91.03% avg_auc=89.00%
Best model saved!! Metric=2.3527648922180475!!
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.398027 Test loss=0.369275 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.36769425868988037
[5/24] Train loss=0.3876294791698456
[10/24] Train loss=0.38210612535476685
[15/24] Train loss=0.3855089247226715
[20/24] Train loss=0.35885339975357056
Test set avg_accuracy=83.85% avg_sensitivity=70.63%, avg_specificity=88.78% avg_auc=89.60%
Best model saved!! Metric=6.860967692625707!!
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.388602 Test loss=0.364755 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3618612587451935
[5/24] Train loss=0.3764842450618744
[10/24] Train loss=0.3837975263595581
[15/24] Train loss=0.37821319699287415
[20/24] Train loss=0.3565921187400818
Test set avg_accuracy=84.93% avg_sensitivity=68.38%, avg_specificity=91.10% avg_auc=90.16%
Best model saved!! Metric=8.575071020161317!!
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.381478 Test loss=0.352949 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.35305050015449524
[5/24] Train loss=0.3674758970737457
[10/24] Train loss=0.37681177258491516
[15/24] Train loss=0.3665858507156372
[20/24] Train loss=0.3494791090488434
Test set avg_accuracy=84.38% avg_sensitivity=73.03%, avg_specificity=88.60% avg_auc=90.04%
Best model saved!! Metric=10.042131993101734!!
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.371967 Test loss=0.355244 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.35023581981658936
[5/24] Train loss=0.357474148273468
[10/24] Train loss=0.37210720777511597
[15/24] Train loss=0.3595334589481354
[20/24] Train loss=0.3399205505847931
Test set avg_accuracy=85.21% avg_sensitivity=66.03%, avg_specificity=92.35% avg_auc=90.95%
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.363845 Test loss=0.337681 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3369830548763275
[5/24] Train loss=0.355356901884079
[10/24] Train loss=0.3686964213848114
[15/24] Train loss=0.3512187600135803
[20/24] Train loss=0.32396769523620605
Test set avg_accuracy=85.09% avg_sensitivity=64.30%, avg_specificity=92.83% avg_auc=90.39%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.356619 Test loss=0.344443 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3380213975906372
[5/24] Train loss=0.3517135679721832
[10/24] Train loss=0.35665884613990784
[15/24] Train loss=0.34642133116722107
[20/24] Train loss=0.32096609473228455
Test set avg_accuracy=85.25% avg_sensitivity=60.22%, avg_specificity=94.57% avg_auc=90.80%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.349020 Test loss=0.340933 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.32437562942504883
[5/24] Train loss=0.34748199582099915
[10/24] Train loss=0.3537504971027374
[15/24] Train loss=0.3289187550544739
[20/24] Train loss=0.3244389295578003
Test set avg_accuracy=85.05% avg_sensitivity=58.11%, avg_specificity=95.09% avg_auc=90.85%
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.345772 Test loss=0.342534 Current lr=[0.000210185142098938]

[0/24] Train loss=0.31550437211990356
[5/24] Train loss=0.3377166986465454
[10/24] Train loss=0.35992106795310974
[15/24] Train loss=0.3317364454269409
[20/24] Train loss=0.3107137978076935
Test set avg_accuracy=84.88% avg_sensitivity=57.20%, avg_specificity=95.19% avg_auc=91.04%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.341702 Test loss=0.341568 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.31627967953681946
[5/24] Train loss=0.3327731192111969
[10/24] Train loss=0.3535109758377075
[15/24] Train loss=0.320129930973053
[20/24] Train loss=0.3010631799697876
Test set avg_accuracy=85.49% avg_sensitivity=61.47%, avg_specificity=94.44% avg_auc=91.42%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.334225 Test loss=0.331502 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3040005564689636
[5/24] Train loss=0.3301481008529663
[10/24] Train loss=0.350130558013916
[15/24] Train loss=0.3113081753253937
[20/24] Train loss=0.2972358167171478
Test set avg_accuracy=84.84% avg_sensitivity=61.04%, avg_specificity=93.71% avg_auc=90.41%
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.328879 Test loss=0.343713 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2987368702888489
[5/24] Train loss=0.3210962116718292
[10/24] Train loss=0.34355634450912476
[15/24] Train loss=0.3100917339324951
[20/24] Train loss=0.28849953413009644
Test set avg_accuracy=84.06% avg_sensitivity=50.67%, avg_specificity=96.50% avg_auc=90.54%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.322232 Test loss=0.361274 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.29179349541664124
[5/24] Train loss=0.3178695738315582
[10/24] Train loss=0.34426072239875793
[15/24] Train loss=0.3046046197414398
[20/24] Train loss=0.2953226566314697
Test set avg_accuracy=86.12% avg_sensitivity=62.48%, avg_specificity=94.92% avg_auc=91.81%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.320460 Test loss=0.324048 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2937318682670593
[5/24] Train loss=0.32572290301322937
[10/24] Train loss=0.33392810821533203
[15/24] Train loss=0.3056603968143463
[20/24] Train loss=0.2869983911514282
Test set avg_accuracy=85.29% avg_sensitivity=62.24%, avg_specificity=93.87% avg_auc=90.60%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.316670 Test loss=0.336717 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.29446932673454285
[5/24] Train loss=0.31835615634918213
[10/24] Train loss=0.33791452646255493
[15/24] Train loss=0.297354131937027
[20/24] Train loss=0.28820866346359253
Test set avg_accuracy=85.46% avg_sensitivity=59.60%, avg_specificity=95.09% avg_auc=91.47%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.314481 Test loss=0.332587 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.28031039237976074
[5/24] Train loss=0.3167233169078827
[10/24] Train loss=0.32454001903533936
[15/24] Train loss=0.29323458671569824
[20/24] Train loss=0.27759239077568054
Test set avg_accuracy=85.81% avg_sensitivity=61.80%, avg_specificity=94.75% avg_auc=91.06%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.310063 Test loss=0.332470 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2875201404094696
[5/24] Train loss=0.29949885606765747
[10/24] Train loss=0.3278590738773346
[15/24] Train loss=0.2903134226799011
[20/24] Train loss=0.27058061957359314
Test set avg_accuracy=84.86% avg_sensitivity=53.55%, avg_specificity=96.52% avg_auc=90.21%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.307307 Test loss=0.356789 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.28288403153419495
[5/24] Train loss=0.3108291029930115
[10/24] Train loss=0.3216985762119293
[15/24] Train loss=0.2821043133735657
[20/24] Train loss=0.27211666107177734
Test set avg_accuracy=87.23% avg_sensitivity=71.07%, avg_specificity=93.25% avg_auc=92.46%
Best model saved!! Metric=17.998344064566936!!
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.306924 Test loss=0.305699 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2785746157169342
[5/24] Train loss=0.3067246973514557
[10/24] Train loss=0.3180254101753235
[15/24] Train loss=0.28380388021469116
[20/24] Train loss=0.28248029947280884
Test set avg_accuracy=86.45% avg_sensitivity=69.58%, avg_specificity=92.73% avg_auc=92.04%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.305287 Test loss=0.313221 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2733399271965027
[5/24] Train loss=0.3060262203216553
[10/24] Train loss=0.3153882622718811
[15/24] Train loss=0.28933030366897583
[20/24] Train loss=0.2639802098274231
Test set avg_accuracy=86.86% avg_sensitivity=67.27%, avg_specificity=94.16% avg_auc=92.18%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.301899 Test loss=0.312421 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.28404751420021057
[5/24] Train loss=0.3052119016647339
[10/24] Train loss=0.3133416771888733
[15/24] Train loss=0.27870163321495056
[20/24] Train loss=0.2661742866039276
Test set avg_accuracy=86.58% avg_sensitivity=69.05%, avg_specificity=93.10% avg_auc=91.48%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.294925 Test loss=0.320656 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2794649302959442
[5/24] Train loss=0.3056645691394806
[10/24] Train loss=0.3086027503013611
[15/24] Train loss=0.2827664613723755
[20/24] Train loss=0.2543930113315582
Test set avg_accuracy=86.48% avg_sensitivity=63.44%, avg_specificity=95.07% avg_auc=91.65%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.293108 Test loss=0.321142 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.29015591740608215
[5/24] Train loss=0.30021438002586365
[10/24] Train loss=0.3026338815689087
[15/24] Train loss=0.2736193537712097
[20/24] Train loss=0.2618609666824341
Test set avg_accuracy=85.72% avg_sensitivity=60.17%, avg_specificity=95.23% avg_auc=90.77%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.291583 Test loss=0.337034 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2698180079460144
[5/24] Train loss=0.2893927991390228
[10/24] Train loss=0.3124609887599945
[15/24] Train loss=0.27405983209609985
[20/24] Train loss=0.2603400647640228
Test set avg_accuracy=86.25% avg_sensitivity=61.85%, avg_specificity=95.34% avg_auc=90.81%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.287251 Test loss=0.333221 Current lr=[0.00029967723776099]

[0/24] Train loss=0.26644501090049744
[5/24] Train loss=0.2864067256450653
[10/24] Train loss=0.294878214597702
[15/24] Train loss=0.2760135531425476
[20/24] Train loss=0.25750336050987244
Test set avg_accuracy=86.13% avg_sensitivity=64.97%, avg_specificity=94.01% avg_auc=90.84%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.286011 Test loss=0.329865 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.26557984948158264
[5/24] Train loss=0.2855958044528961
[10/24] Train loss=0.29729729890823364
[15/24] Train loss=0.27260005474090576
[20/24] Train loss=0.25685039162635803
Test set avg_accuracy=86.90% avg_sensitivity=66.75%, avg_specificity=94.41% avg_auc=91.19%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.286931 Test loss=0.321738 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.24978099763393402
[5/24] Train loss=0.29141613841056824
[10/24] Train loss=0.302700012922287
[15/24] Train loss=0.2693258225917816
[20/24] Train loss=0.26543617248535156
Test set avg_accuracy=84.28% avg_sensitivity=52.02%, avg_specificity=96.30% avg_auc=90.86%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.283812 Test loss=0.351581 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2646791636943817
[5/24] Train loss=0.2808963656425476
[10/24] Train loss=0.30666834115982056
[15/24] Train loss=0.2717142105102539
[20/24] Train loss=0.25119122862815857
Test set avg_accuracy=87.42% avg_sensitivity=69.15%, avg_specificity=94.23% avg_auc=92.24%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.282187 Test loss=0.306595 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2689060866832733
[5/24] Train loss=0.2787226438522339
[10/24] Train loss=0.3002137839794159
[15/24] Train loss=0.2534557282924652
[20/24] Train loss=0.25315138697624207
Test set avg_accuracy=87.55% avg_sensitivity=72.94%, avg_specificity=92.99% avg_auc=92.41%
Best model saved!! Metric=19.898161694762322!!
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.279935 Test loss=0.303456 Current lr=[0.000298904600941902]

[0/24] Train loss=0.25526389479637146
[5/24] Train loss=0.2684612274169922
[10/24] Train loss=0.28660520911216736
[15/24] Train loss=0.27023231983184814
[20/24] Train loss=0.2533520758152008
Test set avg_accuracy=87.24% avg_sensitivity=73.85%, avg_specificity=92.23% avg_auc=91.79%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.277533 Test loss=0.312888 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2581290900707245
[5/24] Train loss=0.27642685174942017
[10/24] Train loss=0.29617759585380554
[15/24] Train loss=0.260337769985199
[20/24] Train loss=0.2599233388900757
Test set avg_accuracy=86.59% avg_sensitivity=70.97%, avg_specificity=92.41% avg_auc=91.13%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.273457 Test loss=0.325959 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2516869604587555
[5/24] Train loss=0.2709668278694153
[10/24] Train loss=0.30412259697914124
[15/24] Train loss=0.25779032707214355
[20/24] Train loss=0.24958638846874237
Test set avg_accuracy=85.87% avg_sensitivity=59.84%, avg_specificity=95.57% avg_auc=91.45%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.274700 Test loss=0.333225 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2587927281856537
[5/24] Train loss=0.27553170919418335
[10/24] Train loss=0.28767693042755127
[15/24] Train loss=0.2579561471939087
[20/24] Train loss=0.24527519941329956
Test set avg_accuracy=86.34% avg_sensitivity=63.68%, avg_specificity=94.78% avg_auc=91.05%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.271205 Test loss=0.330363 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.24622683227062225
[5/24] Train loss=0.2606790065765381
[10/24] Train loss=0.298791766166687
[15/24] Train loss=0.2548462748527527
[20/24] Train loss=0.2368040680885315
Test set avg_accuracy=87.16% avg_sensitivity=65.40%, avg_specificity=95.26% avg_auc=91.71%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.271161 Test loss=0.319136 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.25102561712265015
[5/24] Train loss=0.26634374260902405
[10/24] Train loss=0.2745565176010132
[15/24] Train loss=0.24715502560138702
[20/24] Train loss=0.23330266773700714
Test set avg_accuracy=87.04% avg_sensitivity=69.96%, avg_specificity=93.41% avg_auc=91.68%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.266397 Test loss=0.314392 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2433299571275711
[5/24] Train loss=0.2657718062400818
[10/24] Train loss=0.26773643493652344
[15/24] Train loss=0.25179657340049744
[20/24] Train loss=0.2356041520833969
Test set avg_accuracy=86.71% avg_sensitivity=71.21%, avg_specificity=92.48% avg_auc=91.42%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.261680 Test loss=0.318751 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.23866569995880127
[5/24] Train loss=0.25500237941741943
[10/24] Train loss=0.2791582942008972
[15/24] Train loss=0.2547913193702698
[20/24] Train loss=0.23342064023017883
Test set avg_accuracy=86.94% avg_sensitivity=75.96%, avg_specificity=91.03% avg_auc=92.22%
Best model saved!! Metric=20.149014356149422!!
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.264238 Test loss=0.312458 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.23912546038627625
[5/24] Train loss=0.2560838758945465
[10/24] Train loss=0.27165862917900085
[15/24] Train loss=0.2546246349811554
[20/24] Train loss=0.23802921175956726
Test set avg_accuracy=86.93% avg_sensitivity=77.78%, avg_specificity=90.33% avg_auc=91.80%
Best model saved!! Metric=20.83945390512919!!
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.258843 Test loss=0.320364 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.24742379784584045
[5/24] Train loss=0.2645629346370697
[10/24] Train loss=0.2706417143344879
[15/24] Train loss=0.24647492170333862
[20/24] Train loss=0.23265527188777924
Test set avg_accuracy=86.32% avg_sensitivity=65.16%, avg_specificity=94.19% avg_auc=91.02%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.257035 Test loss=0.325601 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.26113617420196533
[5/24] Train loss=0.26445621252059937
[10/24] Train loss=0.2784282863140106
[15/24] Train loss=0.2519376873970032
[20/24] Train loss=0.23464298248291016
Test set avg_accuracy=87.71% avg_sensitivity=73.90%, avg_specificity=92.85% avg_auc=91.98%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.261233 Test loss=0.308593 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.23460371792316437
[5/24] Train loss=0.2625364065170288
[10/24] Train loss=0.2666514217853546
[15/24] Train loss=0.23789247870445251
[20/24] Train loss=0.2395106703042984
Test set avg_accuracy=86.21% avg_sensitivity=65.02%, avg_specificity=94.10% avg_auc=89.83%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.254891 Test loss=0.338509 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.23969444632530212
[5/24] Train loss=0.2478383183479309
[10/24] Train loss=0.2700463831424713
[15/24] Train loss=0.24266724288463593
[20/24] Train loss=0.22671492397785187
Test set avg_accuracy=86.26% avg_sensitivity=63.77%, avg_specificity=94.64% avg_auc=90.35%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.252089 Test loss=0.335719 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.23110449314117432
[5/24] Train loss=0.2628929913043976
[10/24] Train loss=0.2611589729785919
[15/24] Train loss=0.23505756258964539
[20/24] Train loss=0.21730144321918488
Test set avg_accuracy=87.04% avg_sensitivity=69.39%, avg_specificity=93.62% avg_auc=91.31%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.249810 Test loss=0.318566 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.23786695301532745
[5/24] Train loss=0.25176435708999634
[10/24] Train loss=0.25887995958328247
[15/24] Train loss=0.2392168939113617
[20/24] Train loss=0.23520979285240173
Test set avg_accuracy=86.26% avg_sensitivity=64.01%, avg_specificity=94.55% avg_auc=91.31%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.247594 Test loss=0.327242 Current lr=[0.000276307469034998]

[0/24] Train loss=0.23085343837738037
[5/24] Train loss=0.255707323551178
[10/24] Train loss=0.2451937347650528
[15/24] Train loss=0.22888147830963135
[20/24] Train loss=0.21660524606704712
Test set avg_accuracy=86.25% avg_sensitivity=68.71%, avg_specificity=92.78% avg_auc=90.45%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.242305 Test loss=0.333400 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.2368796020746231
[5/24] Train loss=0.2438799887895584
[10/24] Train loss=0.2583043575286865
[15/24] Train loss=0.23662424087524414
[20/24] Train loss=0.2154320478439331
Test set avg_accuracy=87.03% avg_sensitivity=71.02%, avg_specificity=92.99% avg_auc=90.06%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.243036 Test loss=0.336422 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.22618146240711212
[5/24] Train loss=0.24386584758758545
[10/24] Train loss=0.2481779158115387
[15/24] Train loss=0.2329336553812027
[20/24] Train loss=0.23608466982841492
Test set avg_accuracy=86.42% avg_sensitivity=74.52%, avg_specificity=90.85% avg_auc=90.82%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.242892 Test loss=0.333958 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2225652039051056
[5/24] Train loss=0.2435607761144638
[10/24] Train loss=0.260066956281662
[15/24] Train loss=0.2252991646528244
[20/24] Train loss=0.21685458719730377
Test set avg_accuracy=86.52% avg_sensitivity=71.31%, avg_specificity=92.19% avg_auc=90.38%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.240992 Test loss=0.335052 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.229146808385849
[5/24] Train loss=0.24498285353183746
[10/24] Train loss=0.25262945890426636
[15/24] Train loss=0.22966109216213226
[20/24] Train loss=0.22539269924163818
Test set avg_accuracy=86.69% avg_sensitivity=74.86%, avg_specificity=91.10% avg_auc=91.13%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.239360 Test loss=0.325769 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.21783249080181122
[5/24] Train loss=0.24205900728702545
[10/24] Train loss=0.24542786180973053
[15/24] Train loss=0.23415476083755493
[20/24] Train loss=0.21338890492916107
Test set avg_accuracy=87.14% avg_sensitivity=74.81%, avg_specificity=91.73% avg_auc=90.93%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.238677 Test loss=0.325610 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.21898093819618225
[5/24] Train loss=0.240105539560318
[10/24] Train loss=0.245032399892807
[15/24] Train loss=0.23923663794994354
[20/24] Train loss=0.22283685207366943
Test set avg_accuracy=85.83% avg_sensitivity=78.02%, avg_specificity=88.74% avg_auc=90.70%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.236512 Test loss=0.343211 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.21965599060058594
[5/24] Train loss=0.2325061410665512
[10/24] Train loss=0.23944395780563354
[15/24] Train loss=0.22289934754371643
[20/24] Train loss=0.2195487767457962
Test set avg_accuracy=84.88% avg_sensitivity=77.11%, avg_specificity=87.78% avg_auc=90.13%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.234283 Test loss=0.358799 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.22189316153526306
[5/24] Train loss=0.2339559644460678
[10/24] Train loss=0.2560071349143982
[15/24] Train loss=0.23143461346626282
[20/24] Train loss=0.21606776118278503
Test set avg_accuracy=86.73% avg_sensitivity=73.08%, avg_specificity=91.82% avg_auc=90.87%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.234271 Test loss=0.326247 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.21346738934516907
[5/24] Train loss=0.2264852672815323
[10/24] Train loss=0.22707054018974304
[15/24] Train loss=0.21286801993846893
[20/24] Train loss=0.21057170629501343
Test set avg_accuracy=86.00% avg_sensitivity=70.39%, avg_specificity=91.82% avg_auc=89.99%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.227519 Test loss=0.337032 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.2080499827861786
[5/24] Train loss=0.22528035938739777
[10/24] Train loss=0.23472024500370026
[15/24] Train loss=0.22984462976455688
[20/24] Train loss=0.2073548436164856
Test set avg_accuracy=86.78% avg_sensitivity=75.05%, avg_specificity=91.15% avg_auc=91.23%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.228166 Test loss=0.326875 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2094707190990448
[5/24] Train loss=0.23395858705043793
[10/24] Train loss=0.22840476036071777
[15/24] Train loss=0.2166939526796341
[20/24] Train loss=0.2163439393043518
Test set avg_accuracy=86.33% avg_sensitivity=76.63%, avg_specificity=89.94% avg_auc=91.03%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.224452 Test loss=0.332478 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.216558039188385
[5/24] Train loss=0.21644215285778046
[10/24] Train loss=0.23606425523757935
[15/24] Train loss=0.21155883371829987
[20/24] Train loss=0.20526184141635895
Test set avg_accuracy=86.84% avg_sensitivity=71.31%, avg_specificity=92.62% avg_auc=90.91%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.218819 Test loss=0.325274 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.20379140973091125
[5/24] Train loss=0.2123514860868454
[10/24] Train loss=0.21583956480026245
[15/24] Train loss=0.21064984798431396
[20/24] Train loss=0.20490466058254242
Test set avg_accuracy=86.50% avg_sensitivity=72.26%, avg_specificity=91.80% avg_auc=90.49%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.213457 Test loss=0.332370 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.20825637876987457
[5/24] Train loss=0.20994746685028076
[10/24] Train loss=0.22047023475170135
[15/24] Train loss=0.21303847432136536
[20/24] Train loss=0.18835145235061646
Test set avg_accuracy=86.80% avg_sensitivity=71.64%, avg_specificity=92.44% avg_auc=90.62%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.214359 Test loss=0.330499 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.20785905420780182
[5/24] Train loss=0.20879273116588593
[10/24] Train loss=0.2296961545944214
[15/24] Train loss=0.201369047164917
[20/24] Train loss=0.2042578160762787
Test set avg_accuracy=86.24% avg_sensitivity=69.15%, avg_specificity=92.60% avg_auc=90.13%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.212406 Test loss=0.338581 Current lr=[0.000224838296036774]

[0/24] Train loss=0.19574294984340668
[5/24] Train loss=0.20779284834861755
[10/24] Train loss=0.20368649065494537
[15/24] Train loss=0.20018282532691956
[20/24] Train loss=0.19501978158950806
Test set avg_accuracy=86.86% avg_sensitivity=76.25%, avg_specificity=90.81% avg_auc=90.97%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.207254 Test loss=0.330667 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.1924968659877777
[5/24] Train loss=0.20458824932575226
[10/24] Train loss=0.2200823575258255
[15/24] Train loss=0.19909417629241943
[20/24] Train loss=0.18917755782604218
Test set avg_accuracy=85.39% avg_sensitivity=66.65%, avg_specificity=92.37% avg_auc=88.22%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.207788 Test loss=0.361625 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.21059787273406982
[5/24] Train loss=0.21810674667358398
[10/24] Train loss=0.2088325321674347
[15/24] Train loss=0.19955329596996307
[20/24] Train loss=0.19616468250751495
Test set avg_accuracy=85.64% avg_sensitivity=69.43%, avg_specificity=91.67% avg_auc=89.81%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.208996 Test loss=0.346102 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.20577146112918854
[5/24] Train loss=0.20368777215480804
[10/24] Train loss=0.22132836282253265
[15/24] Train loss=0.1990433782339096
[20/24] Train loss=0.1951206624507904
Test set avg_accuracy=86.71% avg_sensitivity=72.65%, avg_specificity=91.94% avg_auc=90.03%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.205546 Test loss=0.335032 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.20138058066368103
[5/24] Train loss=0.20582729578018188
[10/24] Train loss=0.20640671253204346
[15/24] Train loss=0.19972442090511322
[20/24] Train loss=0.18854819238185883
Test set avg_accuracy=83.46% avg_sensitivity=52.64%, avg_specificity=94.94% avg_auc=86.40%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.202021 Test loss=0.407741 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.19749169051647186
[5/24] Train loss=0.2008415162563324
[10/24] Train loss=0.1985395848751068
[15/24] Train loss=0.2048949897289276
[20/24] Train loss=0.19390368461608887
Test set avg_accuracy=83.28% avg_sensitivity=52.93%, avg_specificity=94.59% avg_auc=85.85%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.203085 Test loss=0.416547 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1843658834695816
[5/24] Train loss=0.19424976408481598
[10/24] Train loss=0.20681755244731903
[15/24] Train loss=0.18983767926692963
[20/24] Train loss=0.18490074574947357
Test set avg_accuracy=82.70% avg_sensitivity=47.50%, avg_specificity=95.80% avg_auc=86.32%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.201369 Test loss=0.425041 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.19610416889190674
[5/24] Train loss=0.19851234555244446
[10/24] Train loss=0.2004508078098297
[15/24] Train loss=0.1880684494972229
[20/24] Train loss=0.17824497818946838
Test set avg_accuracy=83.54% avg_sensitivity=51.82%, avg_specificity=95.35% avg_auc=86.88%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.198125 Test loss=0.419800 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1886812448501587
[5/24] Train loss=0.18737660348415375
[10/24] Train loss=0.19943317770957947
[15/24] Train loss=0.19300739467144012
[20/24] Train loss=0.18718178570270538
Test set avg_accuracy=83.58% avg_sensitivity=54.08%, avg_specificity=94.57% avg_auc=86.47%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.197423 Test loss=0.406494 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.1979990154504776
[5/24] Train loss=0.18830156326293945
[10/24] Train loss=0.19479507207870483
[15/24] Train loss=0.19229406118392944
[20/24] Train loss=0.19299593567848206
Test set avg_accuracy=83.78% avg_sensitivity=56.00%, avg_specificity=94.12% avg_auc=86.24%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.199319 Test loss=0.402934 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1850655972957611
[5/24] Train loss=0.2001209706068039
[10/24] Train loss=0.19234496355056763
[15/24] Train loss=0.19072787463665009
[20/24] Train loss=0.17477363348007202
Test set avg_accuracy=82.32% avg_sensitivity=48.46%, avg_specificity=94.92% avg_auc=85.73%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.192671 Test loss=0.450278 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.19198906421661377
[5/24] Train loss=0.19571354985237122
[10/24] Train loss=0.19029544293880463
[15/24] Train loss=0.19150617718696594
[20/24] Train loss=0.18227672576904297
Test set avg_accuracy=83.16% avg_sensitivity=52.64%, avg_specificity=94.53% avg_auc=85.94%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.193743 Test loss=0.416955 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.18758220970630646
[5/24] Train loss=0.1880849301815033
[10/24] Train loss=0.19232036173343658
[15/24] Train loss=0.1843002736568451
[20/24] Train loss=0.18507198989391327
Test set avg_accuracy=84.31% avg_sensitivity=62.04%, avg_specificity=92.60% avg_auc=87.71%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.187788 Test loss=0.377847 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.18140177428722382
[5/24] Train loss=0.18532973527908325
[10/24] Train loss=0.1819218546152115
[15/24] Train loss=0.17729607224464417
[20/24] Train loss=0.17638932168483734
Test set avg_accuracy=86.05% avg_sensitivity=72.55%, avg_specificity=91.08% avg_auc=88.85%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.186035 Test loss=0.354601 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.17804165184497833
[5/24] Train loss=0.179569810628891
[10/24] Train loss=0.1942862868309021
[15/24] Train loss=0.17638006806373596
[20/24] Train loss=0.17547929286956787
Test set avg_accuracy=85.91% avg_sensitivity=69.00%, avg_specificity=92.21% avg_auc=88.84%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.184479 Test loss=0.358206 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.17964379489421844
[5/24] Train loss=0.18186908960342407
[10/24] Train loss=0.18424785137176514
[15/24] Train loss=0.17488659918308258
[20/24] Train loss=0.17486374080181122
Test set avg_accuracy=85.55% avg_sensitivity=68.81%, avg_specificity=91.78% avg_auc=89.15%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.182342 Test loss=0.358869 Current lr=[0.000156543481933168]

[0/24] Train loss=0.1749344915151596
[5/24] Train loss=0.17226529121398926
[10/24] Train loss=0.18541935086250305
[15/24] Train loss=0.1749371737241745
[20/24] Train loss=0.17493776977062225
Test set avg_accuracy=85.73% avg_sensitivity=66.07%, avg_specificity=93.05% avg_auc=89.50%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.179169 Test loss=0.348480 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.17656384408473969
[5/24] Train loss=0.1751663237810135
[10/24] Train loss=0.1791544109582901
[15/24] Train loss=0.17186887562274933
[20/24] Train loss=0.1702796220779419
Test set avg_accuracy=85.39% avg_sensitivity=67.90%, avg_specificity=91.90% avg_auc=89.14%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.177284 Test loss=0.358209 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.17538847029209137
[5/24] Train loss=0.17412252724170685
[10/24] Train loss=0.19196094572544098
[15/24] Train loss=0.16104811429977417
[20/24] Train loss=0.17070749402046204
Test set avg_accuracy=86.02% avg_sensitivity=70.49%, avg_specificity=91.80% avg_auc=89.92%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.175736 Test loss=0.342503 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.164296492934227
[5/24] Train loss=0.16943375766277313
[10/24] Train loss=0.17871195077896118
[15/24] Train loss=0.1739553064107895
[20/24] Train loss=0.16809703409671783
Test set avg_accuracy=85.16% avg_sensitivity=66.17%, avg_specificity=92.23% avg_auc=88.98%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.174372 Test loss=0.360063 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1702394187450409
[5/24] Train loss=0.16946497559547424
[10/24] Train loss=0.16890379786491394
[15/24] Train loss=0.1632186323404312
[20/24] Train loss=0.1680537313222885
Test set avg_accuracy=86.73% avg_sensitivity=69.96%, avg_specificity=92.98% avg_auc=90.04%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.172763 Test loss=0.335583 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16578276455402374
[5/24] Train loss=0.17354826629161835
[10/24] Train loss=0.17081725597381592
[15/24] Train loss=0.15674088895320892
[20/24] Train loss=0.16543787717819214
Test set avg_accuracy=85.85% avg_sensitivity=74.90%, avg_specificity=89.92% avg_auc=89.48%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.171169 Test loss=0.354834 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1681060492992401
[5/24] Train loss=0.16321271657943726
[10/24] Train loss=0.17149969935417175
[15/24] Train loss=0.15841220319271088
[20/24] Train loss=0.1643579751253128
Test set avg_accuracy=86.04% avg_sensitivity=72.74%, avg_specificity=90.99% avg_auc=89.35%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.170503 Test loss=0.356063 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.16224230825901031
[5/24] Train loss=0.16722522675991058
[10/24] Train loss=0.1673278510570526
[15/24] Train loss=0.16392667591571808
[20/24] Train loss=0.1652250736951828
Test set avg_accuracy=86.05% avg_sensitivity=72.41%, avg_specificity=91.14% avg_auc=90.43%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.170664 Test loss=0.342895 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.16820168495178223
[5/24] Train loss=0.15802006423473358
[10/24] Train loss=0.17799219489097595
[15/24] Train loss=0.1575596034526825
[20/24] Train loss=0.16623111069202423
Test set avg_accuracy=85.43% avg_sensitivity=73.99%, avg_specificity=89.69% avg_auc=90.62%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.168483 Test loss=0.348701 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.16358187794685364
[5/24] Train loss=0.16473472118377686
[10/24] Train loss=0.1616961658000946
[15/24] Train loss=0.153718963265419
[20/24] Train loss=0.16211900115013123
Test set avg_accuracy=86.35% avg_sensitivity=76.25%, avg_specificity=90.12% avg_auc=90.91%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.167641 Test loss=0.337957 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16279925405979156
[5/24] Train loss=0.164707213640213
[10/24] Train loss=0.16871120035648346
[15/24] Train loss=0.1573246866464615
[20/24] Train loss=0.1620636135339737
Test set avg_accuracy=86.42% avg_sensitivity=72.36%, avg_specificity=91.65% avg_auc=90.43%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.166109 Test loss=0.343851 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15977713465690613
[5/24] Train loss=0.16468799114227295
[10/24] Train loss=0.1635446697473526
[15/24] Train loss=0.15588785707950592
[20/24] Train loss=0.15449123084545135
Test set avg_accuracy=85.56% avg_sensitivity=73.66%, avg_specificity=89.99% avg_auc=90.40%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.163238 Test loss=0.350422 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15891209244728088
[5/24] Train loss=0.1568564772605896
[10/24] Train loss=0.15905635058879852
[15/24] Train loss=0.1540229618549347
[20/24] Train loss=0.15640556812286377
Test set avg_accuracy=85.95% avg_sensitivity=74.90%, avg_specificity=90.06% avg_auc=90.29%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.161239 Test loss=0.347215 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.15067324042320251
[5/24] Train loss=0.16344891488552094
[10/24] Train loss=0.1629747450351715
[15/24] Train loss=0.15141703188419342
[20/24] Train loss=0.16189587116241455
Test set avg_accuracy=85.96% avg_sensitivity=71.55%, avg_specificity=91.33% avg_auc=89.40%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.161009 Test loss=0.355847 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15210266411304474
[5/24] Train loss=0.16177524626255035
[10/24] Train loss=0.16457584500312805
[15/24] Train loss=0.1476937085390091
[20/24] Train loss=0.15188764035701752
Test set avg_accuracy=84.80% avg_sensitivity=66.89%, avg_specificity=91.48% avg_auc=88.88%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.159691 Test loss=0.370596 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.15851141512393951
[5/24] Train loss=0.14726947247982025
[10/24] Train loss=0.16348126530647278
[15/24] Train loss=0.15190701186656952
[20/24] Train loss=0.15669633448123932
Test set avg_accuracy=84.60% avg_sensitivity=63.34%, avg_specificity=92.51% avg_auc=88.28%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.159329 Test loss=0.376156 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14907507598400116
[5/24] Train loss=0.15189725160598755
[10/24] Train loss=0.15700852870941162
[15/24] Train loss=0.1573651134967804
[20/24] Train loss=0.15500898659229279
Test set avg_accuracy=85.49% avg_sensitivity=68.62%, avg_specificity=91.78% avg_auc=89.20%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.158269 Test loss=0.357559 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14597642421722412
[5/24] Train loss=0.15527646243572235
[10/24] Train loss=0.16236381232738495
[15/24] Train loss=0.1512802243232727
[20/24] Train loss=0.15107415616512299
Test set avg_accuracy=85.13% avg_sensitivity=66.65%, avg_specificity=92.01% avg_auc=88.94%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.156578 Test loss=0.357716 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1511576771736145
[5/24] Train loss=0.14858442544937134
[10/24] Train loss=0.16013087332248688
[15/24] Train loss=0.14772407710552216
[20/24] Train loss=0.14825767278671265
Test set avg_accuracy=85.86% avg_sensitivity=67.42%, avg_specificity=92.73% avg_auc=89.06%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.154719 Test loss=0.356074 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14835374057292938
[5/24] Train loss=0.147047221660614
[10/24] Train loss=0.15757355093955994
[15/24] Train loss=0.1447760909795761
[20/24] Train loss=0.15246745944023132
Test set avg_accuracy=85.07% avg_sensitivity=70.01%, avg_specificity=90.67% avg_auc=89.11%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.153123 Test loss=0.359552 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14498157799243927
[5/24] Train loss=0.14472179114818573
[10/24] Train loss=0.1565004140138626
[15/24] Train loss=0.14540360867977142
[20/24] Train loss=0.14926637709140778
Test set avg_accuracy=85.08% avg_sensitivity=66.51%, avg_specificity=91.99% avg_auc=88.91%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.152475 Test loss=0.363711 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.15586058795452118
[5/24] Train loss=0.14658071100711823
[10/24] Train loss=0.15487205982208252
[15/24] Train loss=0.14433366060256958
[20/24] Train loss=0.14463934302330017
Test set avg_accuracy=85.17% avg_sensitivity=68.09%, avg_specificity=91.53% avg_auc=88.29%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.151699 Test loss=0.367756 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14646543562412262
[5/24] Train loss=0.14594940841197968
[10/24] Train loss=0.15170744061470032
[15/24] Train loss=0.1421123892068863
[20/24] Train loss=0.14475730061531067
Test set avg_accuracy=85.69% avg_sensitivity=69.39%, avg_specificity=91.76% avg_auc=88.81%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.149739 Test loss=0.359619 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1433524638414383
[5/24] Train loss=0.14037775993347168
[10/24] Train loss=0.1518540233373642
[15/24] Train loss=0.14022177457809448
[20/24] Train loss=0.14676512777805328
Test set avg_accuracy=85.74% avg_sensitivity=70.01%, avg_specificity=91.60% avg_auc=88.90%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.147791 Test loss=0.358285 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14150077104568481
[5/24] Train loss=0.14369523525238037
[10/24] Train loss=0.14597851037979126
[15/24] Train loss=0.13661614060401917
[20/24] Train loss=0.14292874932289124
Test set avg_accuracy=85.53% avg_sensitivity=70.39%, avg_specificity=91.17% avg_auc=88.81%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.146685 Test loss=0.362014 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1418156623840332
[5/24] Train loss=0.14043287932872772
[10/24] Train loss=0.1466592699289322
[15/24] Train loss=0.13855920732021332
[20/24] Train loss=0.14166811108589172
Test set avg_accuracy=85.35% avg_sensitivity=70.49%, avg_specificity=90.89% avg_auc=88.58%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.146311 Test loss=0.363807 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14109835028648376
[5/24] Train loss=0.1407875120639801
[10/24] Train loss=0.14703911542892456
[15/24] Train loss=0.136470228433609
[20/24] Train loss=0.14151261746883392
Test set avg_accuracy=85.18% avg_sensitivity=69.67%, avg_specificity=90.96% avg_auc=88.67%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.145170 Test loss=0.367626 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13702204823493958
[5/24] Train loss=0.13869427144527435
[10/24] Train loss=0.14383679628372192
[15/24] Train loss=0.13604949414730072
[20/24] Train loss=0.14229217171669006
Test set avg_accuracy=85.91% avg_sensitivity=71.11%, avg_specificity=91.42% avg_auc=88.80%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.143920 Test loss=0.360056 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1375446319580078
[5/24] Train loss=0.1404346227645874
[10/24] Train loss=0.14155665040016174
[15/24] Train loss=0.13807368278503418
[20/24] Train loss=0.13798809051513672
Test set avg_accuracy=85.70% avg_sensitivity=69.53%, avg_specificity=91.73% avg_auc=88.62%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.143909 Test loss=0.363126 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13583382964134216
[5/24] Train loss=0.13619175553321838
[10/24] Train loss=0.1421925276517868
[15/24] Train loss=0.1375335156917572
[20/24] Train loss=0.1423744261264801
Test set avg_accuracy=85.69% avg_sensitivity=71.40%, avg_specificity=91.01% avg_auc=88.79%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.143705 Test loss=0.361890 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13689981400966644
[5/24] Train loss=0.14169007539749146
[10/24] Train loss=0.14106576144695282
[15/24] Train loss=0.13360656797885895
[20/24] Train loss=0.14055150747299194
Test set avg_accuracy=85.59% avg_sensitivity=69.48%, avg_specificity=91.58% avg_auc=89.01%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.142297 Test loss=0.360528 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.14030012488365173
[5/24] Train loss=0.1370120644569397
[10/24] Train loss=0.1429457813501358
[15/24] Train loss=0.13125211000442505
[20/24] Train loss=0.13836751878261566
Test set avg_accuracy=85.18% avg_sensitivity=69.10%, avg_specificity=91.17% avg_auc=88.96%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.142227 Test loss=0.362440 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1381915807723999
[5/24] Train loss=0.1359081268310547
[10/24] Train loss=0.14325746893882751
[15/24] Train loss=0.1334051638841629
[20/24] Train loss=0.13458941876888275
Test set avg_accuracy=85.87% avg_sensitivity=70.20%, avg_specificity=91.71% avg_auc=89.11%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.140732 Test loss=0.358562 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13334564864635468
[5/24] Train loss=0.13755297660827637
[10/24] Train loss=0.14142510294914246
[15/24] Train loss=0.13093726336956024
[20/24] Train loss=0.13453230261802673
Test set avg_accuracy=85.73% avg_sensitivity=70.92%, avg_specificity=91.24% avg_auc=89.04%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.140185 Test loss=0.356283 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13350459933280945
[5/24] Train loss=0.13637670874595642
[10/24] Train loss=0.14054922759532928
[15/24] Train loss=0.13281157612800598
[20/24] Train loss=0.13444313406944275
Test set avg_accuracy=85.62% avg_sensitivity=70.01%, avg_specificity=91.44% avg_auc=89.01%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.139284 Test loss=0.359862 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13287024199962616
[5/24] Train loss=0.1348337084054947
[10/24] Train loss=0.13720785081386566
[15/24] Train loss=0.13104841113090515
[20/24] Train loss=0.13564378023147583
Test set avg_accuracy=85.73% avg_sensitivity=71.31%, avg_specificity=91.10% avg_auc=88.96%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.138763 Test loss=0.358994 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13109835982322693
[5/24] Train loss=0.1334034651517868
[10/24] Train loss=0.1392468810081482
[15/24] Train loss=0.12895932793617249
[20/24] Train loss=0.13388805091381073
Test set avg_accuracy=85.64% avg_sensitivity=70.06%, avg_specificity=91.44% avg_auc=88.93%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.138256 Test loss=0.359283 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1326972097158432
[5/24] Train loss=0.1341334879398346
[10/24] Train loss=0.13755157589912415
[15/24] Train loss=0.1310066431760788
[20/24] Train loss=0.1354828178882599
Test set avg_accuracy=85.87% avg_sensitivity=71.31%, avg_specificity=91.30% avg_auc=88.92%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.137884 Test loss=0.359391 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13370728492736816
[5/24] Train loss=0.13380520045757294
[10/24] Train loss=0.13590136170387268
[15/24] Train loss=0.1316365897655487
[20/24] Train loss=0.1357763707637787
Test set avg_accuracy=85.81% avg_sensitivity=71.16%, avg_specificity=91.26% avg_auc=88.98%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.137301 Test loss=0.358759 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1307479590177536
[5/24] Train loss=0.13475167751312256
[10/24] Train loss=0.1379506140947342
[15/24] Train loss=0.13371464610099792
[20/24] Train loss=0.13403956592082977
Test set avg_accuracy=85.85% avg_sensitivity=71.26%, avg_specificity=91.28% avg_auc=88.99%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.137890 Test loss=0.359066 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1287468671798706
[5/24] Train loss=0.13656479120254517
[10/24] Train loss=0.13598763942718506
[15/24] Train loss=0.13088113069534302
[20/24] Train loss=0.13283401727676392
Test set avg_accuracy=85.61% avg_sensitivity=70.54%, avg_specificity=91.23% avg_auc=88.90%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.137700 Test loss=0.360777 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13112041354179382
[5/24] Train loss=0.13490909337997437
[10/24] Train loss=0.13661491870880127
[15/24] Train loss=0.13001446425914764
[20/24] Train loss=0.13252702355384827
Test set avg_accuracy=85.68% avg_sensitivity=70.73%, avg_specificity=91.24% avg_auc=89.04%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.137015 Test loss=0.358422 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.13182029128074646
[5/24] Train loss=0.13388344645500183
[10/24] Train loss=0.13494247198104858
[15/24] Train loss=0.130377858877182
[20/24] Train loss=0.1338566541671753
Test set avg_accuracy=85.70% avg_sensitivity=70.63%, avg_specificity=91.32% avg_auc=88.97%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.136867 Test loss=0.359874 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12754926085472107
[5/24] Train loss=0.13295398652553558
[10/24] Train loss=0.13483422994613647
[15/24] Train loss=0.12765292823314667
[20/24] Train loss=0.13431872427463531
Test set avg_accuracy=85.62% avg_sensitivity=70.59%, avg_specificity=91.23% avg_auc=88.92%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.136241 Test loss=0.360665 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12764012813568115
[5/24] Train loss=0.1346874237060547
[10/24] Train loss=0.13689477741718292
[15/24] Train loss=0.1280604600906372
[20/24] Train loss=0.13442794978618622
Test set avg_accuracy=85.76% avg_sensitivity=70.97%, avg_specificity=91.26% avg_auc=88.93%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.136669 Test loss=0.360245 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.13214409351348877
[5/24] Train loss=0.13264350593090057
[10/24] Train loss=0.13769656419754028
[15/24] Train loss=0.12641796469688416
[20/24] Train loss=0.13515087962150574
Test set avg_accuracy=85.72% avg_sensitivity=70.83%, avg_specificity=91.26% avg_auc=89.02%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.136400 Test loss=0.359104 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13021662831306458
[5/24] Train loss=0.13165193796157837
[10/24] Train loss=0.13403987884521484
[15/24] Train loss=0.1308886706829071
[20/24] Train loss=0.13352197408676147
Test set avg_accuracy=85.68% avg_sensitivity=70.54%, avg_specificity=91.32% avg_auc=88.97%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.135841 Test loss=0.360052 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1305571049451828
[5/24] Train loss=0.13188260793685913
[10/24] Train loss=0.13673368096351624
[15/24] Train loss=0.12848810851573944
[20/24] Train loss=0.13102202117443085
Test set avg_accuracy=85.57% avg_sensitivity=70.35%, avg_specificity=91.24% avg_auc=89.00%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.136036 Test loss=0.359885 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12783442437648773
[5/24] Train loss=0.13098643720149994
[10/24] Train loss=0.13408932089805603
[15/24] Train loss=0.13003189861774445
[20/24] Train loss=0.13433852791786194
Test set avg_accuracy=85.66% avg_sensitivity=70.83%, avg_specificity=91.19% avg_auc=89.01%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.136417 Test loss=0.359905 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12955258786678314
[5/24] Train loss=0.13193154335021973
[10/24] Train loss=0.13619321584701538
[15/24] Train loss=0.12741152942180634
[20/24] Train loss=0.13469108939170837
Test set avg_accuracy=85.69% avg_sensitivity=71.02%, avg_specificity=91.15% avg_auc=88.98%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.135836 Test loss=0.360141 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.13011199235916138
[5/24] Train loss=0.13378173112869263
[10/24] Train loss=0.13490967452526093
[15/24] Train loss=0.12673905491828918
[20/24] Train loss=0.13191555440425873
Test set avg_accuracy=85.69% avg_sensitivity=70.83%, avg_specificity=91.23% avg_auc=88.98%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.136020 Test loss=0.360101 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12728050351142883
[5/24] Train loss=0.13149841129779816
[10/24] Train loss=0.13396911323070526
[15/24] Train loss=0.12801945209503174
[20/24] Train loss=0.13215866684913635
Test set avg_accuracy=85.77% avg_sensitivity=71.21%, avg_specificity=91.19% avg_auc=89.01%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.135830 Test loss=0.359678 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.13055311143398285
[5/24] Train loss=0.1310962736606598
[10/24] Train loss=0.1361801028251648
[15/24] Train loss=0.1272997409105301
[20/24] Train loss=0.13013440370559692
Test set avg_accuracy=85.66% avg_sensitivity=70.73%, avg_specificity=91.23% avg_auc=88.99%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.136028 Test loss=0.359997 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12951183319091797
[5/24] Train loss=0.13207899034023285
[10/24] Train loss=0.13677512109279633
[15/24] Train loss=0.12774784862995148
[20/24] Train loss=0.13269349932670593
Test set avg_accuracy=85.66% avg_sensitivity=70.59%, avg_specificity=91.28% avg_auc=88.99%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.135793 Test loss=0.360028 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=86.93% sen=77.78%, spe=90.33%, auc=91.80%!
Fold[6] Avg_overlap=0.68%(±0.2409919960955412)
[0/24] Train loss=0.7478451728820801
[5/24] Train loss=0.741858959197998
[10/24] Train loss=0.7460169196128845
[15/24] Train loss=0.74136883020401
[20/24] Train loss=0.7325274348258972
Test set avg_accuracy=57.19% avg_sensitivity=39.23%, avg_specificity=64.04% avg_auc=51.80%
Best model saved!! Metric=-113.74927569129204!!
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.741195 Test loss=0.698029 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7348910570144653
[5/24] Train loss=0.7299022078514099
[10/24] Train loss=0.7306891679763794
[15/24] Train loss=0.7234187126159668
[20/24] Train loss=0.7097964882850647
Test set avg_accuracy=60.26% avg_sensitivity=35.97%, avg_specificity=69.53% avg_auc=53.74%
Best model saved!! Metric=-106.49534305085162!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.725587 Test loss=0.672906 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7201221585273743
[5/24] Train loss=0.7173689603805542
[10/24] Train loss=0.7175547480583191
[15/24] Train loss=0.7051398158073425
[20/24] Train loss=0.7017455697059631
Test set avg_accuracy=62.76% avg_sensitivity=34.09%, avg_specificity=73.70% avg_auc=56.50%
Best model saved!! Metric=-98.94818657358182!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.709484 Test loss=0.654939 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.7020193934440613
[5/24] Train loss=0.7001672387123108
[10/24] Train loss=0.7035235166549683
[15/24] Train loss=0.6892122030258179
[20/24] Train loss=0.6766687035560608
Test set avg_accuracy=65.72% avg_sensitivity=32.48%, avg_specificity=78.40% avg_auc=59.04%
Best model saved!! Metric=-90.35900955052671!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.693644 Test loss=0.638410 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.681301474571228
[5/24] Train loss=0.6744120121002197
[10/24] Train loss=0.6755352020263672
[15/24] Train loss=0.6707766652107239
[20/24] Train loss=0.6534498929977417
Test set avg_accuracy=69.88% avg_sensitivity=33.00%, avg_specificity=83.95% avg_auc=61.64%
Best model saved!! Metric=-77.51968315778412!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.672348 Test loss=0.623760 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6614839434623718
[5/24] Train loss=0.6562973260879517
[10/24] Train loss=0.6592478156089783
[15/24] Train loss=0.6437758207321167
[20/24] Train loss=0.6265436410903931
Test set avg_accuracy=72.71% avg_sensitivity=34.32%, avg_specificity=87.35% avg_auc=64.71%
Best model saved!! Metric=-66.90026752366857!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.650684 Test loss=0.602853 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6381098628044128
[5/24] Train loss=0.6319553852081299
[10/24] Train loss=0.6327683925628662
[15/24] Train loss=0.6234205961227417
[20/24] Train loss=0.6054083704948425
Test set avg_accuracy=73.97% avg_sensitivity=37.25%, avg_specificity=87.98% avg_auc=69.00%
Best model saved!! Metric=-57.79871902444705!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.625590 Test loss=0.574551 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5983713269233704
[5/24] Train loss=0.6127727031707764
[10/24] Train loss=0.6054615378379822
[15/24] Train loss=0.5884308815002441
[20/24] Train loss=0.5678315758705139
Test set avg_accuracy=74.74% avg_sensitivity=39.32%, avg_specificity=88.25% avg_auc=73.44%
Best model saved!! Metric=-50.24209187527918!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.596946 Test loss=0.542648 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5669733881950378
[5/24] Train loss=0.5792962312698364
[10/24] Train loss=0.5747888088226318
[15/24] Train loss=0.5635913014411926
[20/24] Train loss=0.5392372608184814
Test set avg_accuracy=75.95% avg_sensitivity=44.32%, avg_specificity=88.02% avg_auc=77.12%
Best model saved!! Metric=-40.586336414183116!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.567390 Test loss=0.511610 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5407244563102722
[5/24] Train loss=0.5456292629241943
[10/24] Train loss=0.5447075963020325
[15/24] Train loss=0.5367324948310852
[20/24] Train loss=0.5143889784812927
Test set avg_accuracy=76.88% avg_sensitivity=46.72%, avg_specificity=88.38% avg_auc=78.98%
Best model saved!! Metric=-35.038570926902274!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.541457 Test loss=0.493100 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5166899561882019
[5/24] Train loss=0.5218830108642578
[10/24] Train loss=0.5236152410507202
[15/24] Train loss=0.5169200897216797
[20/24] Train loss=0.4947022497653961
Test set avg_accuracy=77.75% avg_sensitivity=48.70%, avg_specificity=88.83% avg_auc=80.99%
Best model saved!! Metric=-29.732225415353895!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.519351 Test loss=0.472827 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4907910227775574
[5/24] Train loss=0.5000834465026855
[10/24] Train loss=0.505211353302002
[15/24] Train loss=0.4895307421684265
[20/24] Train loss=0.4728567898273468
Test set avg_accuracy=78.55% avg_sensitivity=50.59%, avg_specificity=89.22% avg_auc=82.34%
Best model saved!! Metric=-25.287611802014077!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.498589 Test loss=0.457198 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.47032031416893005
[5/24] Train loss=0.4808923304080963
[10/24] Train loss=0.48889780044555664
[15/24] Train loss=0.4780886471271515
[20/24] Train loss=0.4529880881309509
Test set avg_accuracy=78.88% avg_sensitivity=50.97%, avg_specificity=89.53% avg_auc=83.35%
Best model saved!! Metric=-23.26829388100805!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.481242 Test loss=0.444499 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.46035799384117126
[5/24] Train loss=0.46077388525009155
[10/24] Train loss=0.46791234612464905
[15/24] Train loss=0.4662057161331177
[20/24] Train loss=0.4400777518749237
Test set avg_accuracy=79.67% avg_sensitivity=52.95%, avg_specificity=89.87% avg_auc=84.63%
Best model saved!! Metric=-18.878742927572667!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.465852 Test loss=0.430360 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.44379112124443054
[5/24] Train loss=0.446294903755188
[10/24] Train loss=0.45574596524238586
[15/24] Train loss=0.45392903685569763
[20/24] Train loss=0.42868801951408386
Test set avg_accuracy=79.56% avg_sensitivity=50.83%, avg_specificity=90.52% avg_auc=85.13%
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.452226 Test loss=0.425122 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.43189388513565063
[5/24] Train loss=0.4332011938095093
[10/24] Train loss=0.44694894552230835
[15/24] Train loss=0.4414137899875641
[20/24] Train loss=0.4161568582057953
Test set avg_accuracy=79.92% avg_sensitivity=51.16%, avg_specificity=90.90% avg_auc=86.07%
Best model saved!! Metric=-17.95104893567474!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.440148 Test loss=0.414636 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.42202627658843994
[5/24] Train loss=0.41890856623649597
[10/24] Train loss=0.4340359568595886
[15/24] Train loss=0.42483261227607727
[20/24] Train loss=0.40058207511901855
Test set avg_accuracy=80.79% avg_sensitivity=55.30%, avg_specificity=90.52% avg_auc=87.14%
Best model saved!! Metric=-12.240399637028801!!
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.427952 Test loss=0.400247 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.40900886058807373
[5/24] Train loss=0.4105668067932129
[10/24] Train loss=0.42336541414260864
[15/24] Train loss=0.4183701276779175
[20/24] Train loss=0.3915114104747772
Test set avg_accuracy=81.30% avg_sensitivity=54.17%, avg_specificity=91.65% avg_auc=87.36%
Best model saved!! Metric=-11.507302485365713!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.418774 Test loss=0.395782 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.39570561051368713
[5/24] Train loss=0.3986221253871918
[10/24] Train loss=0.41366660594940186
[15/24] Train loss=0.4035748243331909
[20/24] Train loss=0.38481268286705017
Test set avg_accuracy=82.46% avg_sensitivity=58.23%, avg_specificity=91.71% avg_auc=88.49%
Best model saved!! Metric=-5.11072116922054!!
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.408915 Test loss=0.382185 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3939647972583771
[5/24] Train loss=0.38968005776405334
[10/24] Train loss=0.40559256076812744
[15/24] Train loss=0.39576441049575806
[20/24] Train loss=0.37495651841163635
Test set avg_accuracy=83.10% avg_sensitivity=59.22%, avg_specificity=92.21% avg_auc=88.91%
Best model saved!! Metric=-2.5611924014996177!!
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.400397 Test loss=0.376060 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.38190722465515137
[5/24] Train loss=0.380342960357666
[10/24] Train loss=0.3957643210887909
[15/24] Train loss=0.3937494456768036
[20/24] Train loss=0.3640761375427246
Test set avg_accuracy=84.28% avg_sensitivity=62.71%, avg_specificity=92.52% avg_auc=89.57%
Best model saved!! Metric=3.0732714323466865!!
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.393194 Test loss=0.364883 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.36900264024734497
[5/24] Train loss=0.37129151821136475
[10/24] Train loss=0.39001551270484924
[15/24] Train loss=0.376956969499588
[20/24] Train loss=0.35900089144706726
Test set avg_accuracy=84.58% avg_sensitivity=66.20%, avg_specificity=91.60% avg_auc=90.14%
Best model saved!! Metric=6.52033657802599!!
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.385294 Test loss=0.356756 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.365211546421051
[5/24] Train loss=0.36550313234329224
[10/24] Train loss=0.39568835496902466
[15/24] Train loss=0.3716762065887451
[20/24] Train loss=0.3557755947113037
Test set avg_accuracy=84.41% avg_sensitivity=64.92%, avg_specificity=91.85% avg_auc=89.77%
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.377995 Test loss=0.359610 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.35743531584739685
[5/24] Train loss=0.3527219295501709
[10/24] Train loss=0.38201668858528137
[15/24] Train loss=0.36125674843788147
[20/24] Train loss=0.34316352009773254
Test set avg_accuracy=84.91% avg_sensitivity=64.97%, avg_specificity=92.52% avg_auc=90.52%
Best model saved!! Metric=6.9123423575950795!!
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.369933 Test loss=0.348307 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.34676146507263184
[5/24] Train loss=0.35032904148101807
[10/24] Train loss=0.36870211362838745
[15/24] Train loss=0.3597281873226166
[20/24] Train loss=0.3326987028121948
Test set avg_accuracy=85.08% avg_sensitivity=64.40%, avg_specificity=92.97% avg_auc=90.63%
Best model saved!! Metric=7.077898379542859!!
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.364528 Test loss=0.347278 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.354768842458725
[5/24] Train loss=0.34774160385131836
[10/24] Train loss=0.37394842505455017
[15/24] Train loss=0.34359943866729736
[20/24] Train loss=0.33354562520980835
Test set avg_accuracy=84.67% avg_sensitivity=56.72%, avg_specificity=95.34% avg_auc=90.74%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.358235 Test loss=0.353310 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.33797818422317505
[5/24] Train loss=0.34158018231391907
[10/24] Train loss=0.36191326379776
[15/24] Train loss=0.3414401412010193
[20/24] Train loss=0.32215264439582825
Test set avg_accuracy=85.14% avg_sensitivity=60.07%, avg_specificity=94.71% avg_auc=91.50%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.350958 Test loss=0.338322 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3378329873085022
[5/24] Train loss=0.33469289541244507
[10/24] Train loss=0.36754345893859863
[15/24] Train loss=0.3303218483924866
[20/24] Train loss=0.316818505525589
Test set avg_accuracy=84.91% avg_sensitivity=58.65%, avg_specificity=94.93% avg_auc=91.04%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.347493 Test loss=0.346083 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3298138380050659
[5/24] Train loss=0.3324299156665802
[10/24] Train loss=0.3591160178184509
[15/24] Train loss=0.3274027109146118
[20/24] Train loss=0.3111100494861603
Test set avg_accuracy=84.65% avg_sensitivity=56.86%, avg_specificity=95.25% avg_auc=90.56%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.340657 Test loss=0.352110 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3190911114215851
[5/24] Train loss=0.3279059827327728
[10/24] Train loss=0.35482892394065857
[15/24] Train loss=0.32608938217163086
[20/24] Train loss=0.3114683926105499
Test set avg_accuracy=85.51% avg_sensitivity=58.79%, avg_specificity=95.70% avg_auc=92.41%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.337058 Test loss=0.328377 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.311027467250824
[5/24] Train loss=0.32314059138298035
[10/24] Train loss=0.3439894914627075
[15/24] Train loss=0.32029107213020325
[20/24] Train loss=0.2990601062774658
Test set avg_accuracy=85.66% avg_sensitivity=63.27%, avg_specificity=94.21% avg_auc=92.38%
Best model saved!! Metric=9.518824400521254!!
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.329825 Test loss=0.322696 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3098544180393219
[5/24] Train loss=0.30906015634536743
[10/24] Train loss=0.34713873267173767
[15/24] Train loss=0.31093695759773254
[20/24] Train loss=0.2979423701763153
Test set avg_accuracy=85.31% avg_sensitivity=60.49%, avg_specificity=94.78% avg_auc=91.60%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.325907 Test loss=0.333578 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3058464229106903
[5/24] Train loss=0.31253141164779663
[10/24] Train loss=0.3414643704891205
[15/24] Train loss=0.29889699816703796
[20/24] Train loss=0.29355618357658386
Test set avg_accuracy=86.17% avg_sensitivity=60.54%, avg_specificity=95.95% avg_auc=92.58%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.322056 Test loss=0.318622 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3055249750614166
[5/24] Train loss=0.31410983204841614
[10/24] Train loss=0.3261183500289917
[15/24] Train loss=0.30039864778518677
[20/24] Train loss=0.285817414522171
Test set avg_accuracy=86.56% avg_sensitivity=68.36%, avg_specificity=93.51% avg_auc=91.95%
Best model saved!! Metric=14.379464457990764!!
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.316178 Test loss=0.321706 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.30758240818977356
[5/24] Train loss=0.3051016628742218
[10/24] Train loss=0.33651798963546753
[15/24] Train loss=0.29722705483436584
[20/24] Train loss=0.2834082543849945
Test set avg_accuracy=85.48% avg_sensitivity=57.00%, avg_specificity=96.35% avg_auc=92.14%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.313837 Test loss=0.332998 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3030499517917633
[5/24] Train loss=0.3082638084888458
[10/24] Train loss=0.3298770785331726
[15/24] Train loss=0.2993161082267761
[20/24] Train loss=0.28382328152656555
Test set avg_accuracy=86.16% avg_sensitivity=64.92%, avg_specificity=94.26% avg_auc=92.38%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.312949 Test loss=0.316515 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2904466688632965
[5/24] Train loss=0.2958087623119354
[10/24] Train loss=0.32168444991111755
[15/24] Train loss=0.2980458438396454
[20/24] Train loss=0.2783240079879761
Test set avg_accuracy=85.91% avg_sensitivity=60.96%, avg_specificity=95.43% avg_auc=92.35%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.310774 Test loss=0.320668 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2971216142177582
[5/24] Train loss=0.29390692710876465
[10/24] Train loss=0.32656362652778625
[15/24] Train loss=0.2843816876411438
[20/24] Train loss=0.2745899558067322
Test set avg_accuracy=86.61% avg_sensitivity=64.31%, avg_specificity=95.13% avg_auc=92.98%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.304556 Test loss=0.306883 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.28759488463401794
[5/24] Train loss=0.286700576543808
[10/24] Train loss=0.32466205954551697
[15/24] Train loss=0.28956010937690735
[20/24] Train loss=0.2743465006351471
Test set avg_accuracy=86.88% avg_sensitivity=66.95%, avg_specificity=94.48% avg_auc=92.59%
Best model saved!! Metric=14.891478665829723!!
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.301754 Test loss=0.307813 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2844308912754059
[5/24] Train loss=0.29624202847480774
[10/24] Train loss=0.3242095410823822
[15/24] Train loss=0.2772216200828552
[20/24] Train loss=0.26370471715927124
Test set avg_accuracy=86.77% avg_sensitivity=63.32%, avg_specificity=95.72% avg_auc=92.69%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.297235 Test loss=0.310697 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.28287288546562195
[5/24] Train loss=0.28436800837516785
[10/24] Train loss=0.31222784519195557
[15/24] Train loss=0.26632481813430786
[20/24] Train loss=0.26619285345077515
Test set avg_accuracy=86.93% avg_sensitivity=63.65%, avg_specificity=95.81% avg_auc=93.05%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.296392 Test loss=0.303998 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.28952479362487793
[5/24] Train loss=0.28481626510620117
[10/24] Train loss=0.3006771206855774
[15/24] Train loss=0.2709209620952606
[20/24] Train loss=0.26384326815605164
Test set avg_accuracy=85.43% avg_sensitivity=58.13%, avg_specificity=95.84% avg_auc=91.60%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.291194 Test loss=0.334586 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.28334271907806396
[5/24] Train loss=0.2757914066314697
[10/24] Train loss=0.2997148633003235
[15/24] Train loss=0.28201764822006226
[20/24] Train loss=0.25719714164733887
Test set avg_accuracy=86.04% avg_sensitivity=62.00%, avg_specificity=95.21% avg_auc=92.70%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.290252 Test loss=0.316085 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.26937136054039
[5/24] Train loss=0.27614137530326843
[10/24] Train loss=0.29591065645217896
[15/24] Train loss=0.2724965512752533
[20/24] Train loss=0.2628254294395447
Test set avg_accuracy=86.02% avg_sensitivity=60.30%, avg_specificity=95.83% avg_auc=92.56%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.286727 Test loss=0.316409 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2644317150115967
[5/24] Train loss=0.2637512981891632
[10/24] Train loss=0.3209015727043152
[15/24] Train loss=0.27823615074157715
[20/24] Train loss=0.2676198482513428
Test set avg_accuracy=85.69% avg_sensitivity=59.74%, avg_specificity=95.59% avg_auc=91.83%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.289211 Test loss=0.334632 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2736002802848816
[5/24] Train loss=0.2651520371437073
[10/24] Train loss=0.3105982542037964
[15/24] Train loss=0.2665330767631531
[20/24] Train loss=0.26092585921287537
Test set avg_accuracy=86.04% avg_sensitivity=58.18%, avg_specificity=96.67% avg_auc=92.54%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.283522 Test loss=0.323495 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2676366865634918
[5/24] Train loss=0.2699615955352783
[10/24] Train loss=0.300962895154953
[15/24] Train loss=0.2664715349674225
[20/24] Train loss=0.2503654658794403
Test set avg_accuracy=84.52% avg_sensitivity=50.83%, avg_specificity=97.37% avg_auc=91.09%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.280277 Test loss=0.360619 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2810455858707428
[5/24] Train loss=0.27078768610954285
[10/24] Train loss=0.2856229245662689
[15/24] Train loss=0.2688148617744446
[20/24] Train loss=0.25548866391181946
Test set avg_accuracy=85.89% avg_sensitivity=57.85%, avg_specificity=96.58% avg_auc=92.00%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.278952 Test loss=0.330427 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.26964864134788513
[5/24] Train loss=0.2692853510379791
[10/24] Train loss=0.2982078790664673
[15/24] Train loss=0.25752168893814087
[20/24] Train loss=0.2414284199476242
Test set avg_accuracy=85.07% avg_sensitivity=55.54%, avg_specificity=96.33% avg_auc=90.84%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.276781 Test loss=0.344133 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2757170498371124
[5/24] Train loss=0.26492559909820557
[10/24] Train loss=0.26896244287490845
[15/24] Train loss=0.2585109770298004
[20/24] Train loss=0.2501441538333893
Test set avg_accuracy=85.49% avg_sensitivity=58.27%, avg_specificity=95.88% avg_auc=91.69%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.272938 Test loss=0.333816 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2606852948665619
[5/24] Train loss=0.26169246435165405
[10/24] Train loss=0.28013941645622253
[15/24] Train loss=0.24732428789138794
[20/24] Train loss=0.24552741646766663
Test set avg_accuracy=84.97% avg_sensitivity=53.47%, avg_specificity=97.00% avg_auc=91.14%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.269556 Test loss=0.347828 Current lr=[0.000297555943323901]

[0/24] Train loss=0.27043256163597107
[5/24] Train loss=0.2723095715045929
[10/24] Train loss=0.2914654314517975
[15/24] Train loss=0.25714603066444397
[20/24] Train loss=0.24041123688220978
Test set avg_accuracy=84.36% avg_sensitivity=53.65%, avg_specificity=96.08% avg_auc=90.05%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.272162 Test loss=0.365151 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.25423142313957214
[5/24] Train loss=0.2630700469017029
[10/24] Train loss=0.27717843651771545
[15/24] Train loss=0.24415259063243866
[20/24] Train loss=0.2464657872915268
Test set avg_accuracy=85.10% avg_sensitivity=55.16%, avg_specificity=96.53% avg_auc=91.18%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.268414 Test loss=0.351271 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2575112581253052
[5/24] Train loss=0.2639012038707733
[10/24] Train loss=0.2657836377620697
[15/24] Train loss=0.2462729513645172
[20/24] Train loss=0.2427234798669815
Test set avg_accuracy=85.35% avg_sensitivity=56.81%, avg_specificity=96.24% avg_auc=90.11%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.263639 Test loss=0.351854 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.2575252652168274
[5/24] Train loss=0.26449131965637207
[10/24] Train loss=0.2840730845928192
[15/24] Train loss=0.24747630953788757
[20/24] Train loss=0.23529531061649323
Test set avg_accuracy=85.14% avg_sensitivity=54.03%, avg_specificity=97.01% avg_auc=90.74%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.265906 Test loss=0.351765 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.25042763352394104
[5/24] Train loss=0.25959500670433044
[10/24] Train loss=0.29306143522262573
[15/24] Train loss=0.2564648985862732
[20/24] Train loss=0.24248062074184418
Test set avg_accuracy=86.12% avg_sensitivity=64.50%, avg_specificity=94.37% avg_auc=91.84%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.262374 Test loss=0.321327 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.2481771856546402
[5/24] Train loss=0.25222498178482056
[10/24] Train loss=0.2636173963546753
[15/24] Train loss=0.23775538802146912
[20/24] Train loss=0.23986896872520447
Test set avg_accuracy=84.11% avg_sensitivity=64.64%, avg_specificity=91.55% avg_auc=88.00%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.259998 Test loss=0.370722 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.24381756782531738
[5/24] Train loss=0.2551543712615967
[10/24] Train loss=0.27515116333961487
[15/24] Train loss=0.23428097367286682
[20/24] Train loss=0.22645017504692078
Test set avg_accuracy=86.99% avg_sensitivity=69.92%, avg_specificity=93.51% avg_auc=92.79%
Best model saved!! Metric=17.206570791694375!!
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.254690 Test loss=0.307653 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2320912480354309
[5/24] Train loss=0.23186452686786652
[10/24] Train loss=0.26991021633148193
[15/24] Train loss=0.23346377909183502
[20/24] Train loss=0.23699016869068146
Test set avg_accuracy=86.50% avg_sensitivity=69.54%, avg_specificity=92.97% avg_auc=92.46%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.251725 Test loss=0.308940 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.23636405169963837
[5/24] Train loss=0.2414109706878662
[10/24] Train loss=0.25608450174331665
[15/24] Train loss=0.2377791851758957
[20/24] Train loss=0.23012889921665192
Test set avg_accuracy=85.68% avg_sensitivity=68.32%, avg_specificity=92.30% avg_auc=90.14%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.251402 Test loss=0.341842 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.23444685339927673
[5/24] Train loss=0.2328084409236908
[10/24] Train loss=0.2658829689025879
[15/24] Train loss=0.22674301266670227
[20/24] Train loss=0.2407878339290619
Test set avg_accuracy=85.01% avg_sensitivity=56.58%, avg_specificity=95.86% avg_auc=89.90%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.252186 Test loss=0.353875 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.23996029794216156
[5/24] Train loss=0.24128791689872742
[10/24] Train loss=0.24967749416828156
[15/24] Train loss=0.23476096987724304
[20/24] Train loss=0.23209096491336823
Test set avg_accuracy=85.91% avg_sensitivity=67.14%, avg_specificity=93.07% avg_auc=92.38%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.252881 Test loss=0.315014 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.23678433895111084
[5/24] Train loss=0.2407316118478775
[10/24] Train loss=0.26651349663734436
[15/24] Train loss=0.2323753535747528
[20/24] Train loss=0.22202174365520477
Test set avg_accuracy=86.51% avg_sensitivity=67.23%, avg_specificity=93.87% avg_auc=92.64%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.251601 Test loss=0.307026 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.23223258554935455
[5/24] Train loss=0.22793707251548767
[10/24] Train loss=0.2571614384651184
[15/24] Train loss=0.2291303128004074
[20/24] Train loss=0.2347094565629959
Test set avg_accuracy=85.91% avg_sensitivity=69.97%, avg_specificity=91.99% avg_auc=91.40%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.246513 Test loss=0.328564 Current lr=[0.000276307469034998]

[0/24] Train loss=0.22663044929504395
[5/24] Train loss=0.24139100313186646
[10/24] Train loss=0.25493955612182617
[15/24] Train loss=0.217891126871109
[20/24] Train loss=0.22918514907360077
Test set avg_accuracy=86.72% avg_sensitivity=69.83%, avg_specificity=93.16% avg_auc=92.28%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.244497 Test loss=0.310844 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.2154170572757721
[5/24] Train loss=0.22935466468334198
[10/24] Train loss=0.2606160640716553
[15/24] Train loss=0.2250194102525711
[20/24] Train loss=0.22093096375465393
Test set avg_accuracy=86.48% avg_sensitivity=74.54%, avg_specificity=91.04% avg_auc=91.95%
Best model saved!! Metric=18.017859826394897!!
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.241728 Test loss=0.321970 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2268306314945221
[5/24] Train loss=0.23788711428642273
[10/24] Train loss=0.24842044711112976
[15/24] Train loss=0.22038401663303375
[20/24] Train loss=0.22268083691596985
Test set avg_accuracy=86.22% avg_sensitivity=74.21%, avg_specificity=90.81% avg_auc=92.13%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.237612 Test loss=0.318571 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2107875794172287
[5/24] Train loss=0.2205626517534256
[10/24] Train loss=0.25490501523017883
[15/24] Train loss=0.2231263816356659
[20/24] Train loss=0.21688273549079895
Test set avg_accuracy=86.50% avg_sensitivity=72.61%, avg_specificity=91.80% avg_auc=92.41%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.237427 Test loss=0.312406 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2219538539648056
[5/24] Train loss=0.2229178249835968
[10/24] Train loss=0.2485620677471161
[15/24] Train loss=0.221892312169075
[20/24] Train loss=0.22372132539749146
Test set avg_accuracy=85.59% avg_sensitivity=70.67%, avg_specificity=91.28% avg_auc=91.00%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.234808 Test loss=0.335244 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2165762037038803
[5/24] Train loss=0.22753599286079407
[10/24] Train loss=0.25894594192504883
[15/24] Train loss=0.2220337986946106
[20/24] Train loss=0.22195276618003845
Test set avg_accuracy=85.26% avg_sensitivity=62.75%, avg_specificity=93.85% avg_auc=89.59%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.233076 Test loss=0.349029 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.2142971158027649
[5/24] Train loss=0.21760526299476624
[10/24] Train loss=0.22924518585205078
[15/24] Train loss=0.21436962485313416
[20/24] Train loss=0.2123628705739975
Test set avg_accuracy=85.99% avg_sensitivity=68.22%, avg_specificity=92.77% avg_auc=90.98%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.228017 Test loss=0.332281 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.21815058588981628
[5/24] Train loss=0.2300722897052765
[10/24] Train loss=0.2312614619731903
[15/24] Train loss=0.21440324187278748
[20/24] Train loss=0.22049780189990997
Test set avg_accuracy=84.96% avg_sensitivity=60.73%, avg_specificity=94.21% avg_auc=89.74%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.229294 Test loss=0.352919 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.21216335892677307
[5/24] Train loss=0.20381489396095276
[10/24] Train loss=0.22488757967948914
[15/24] Train loss=0.21633893251419067
[20/24] Train loss=0.2138911634683609
Test set avg_accuracy=86.13% avg_sensitivity=70.86%, avg_specificity=91.96% avg_auc=91.52%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.224982 Test loss=0.327387 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.21298114955425262
[5/24] Train loss=0.2003657966852188
[10/24] Train loss=0.2542814314365387
[15/24] Train loss=0.2107679843902588
[20/24] Train loss=0.22568203508853912
Test set avg_accuracy=84.99% avg_sensitivity=76.52%, avg_specificity=88.22% avg_auc=90.47%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.225782 Test loss=0.355193 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.21311484277248383
[5/24] Train loss=0.19179998338222504
[10/24] Train loss=0.22550491988658905
[15/24] Train loss=0.20952719449996948
[20/24] Train loss=0.2174788862466812
Test set avg_accuracy=85.56% avg_sensitivity=73.64%, avg_specificity=90.11% avg_auc=91.46%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.221995 Test loss=0.331366 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1988663524389267
[5/24] Train loss=0.20815908908843994
[10/24] Train loss=0.2286011427640915
[15/24] Train loss=0.21394257247447968
[20/24] Train loss=0.21765272319316864
Test set avg_accuracy=84.96% avg_sensitivity=75.48%, avg_specificity=88.58% avg_auc=90.78%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.222498 Test loss=0.350010 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.21043387055397034
[5/24] Train loss=0.20997430384159088
[10/24] Train loss=0.23142480850219727
[15/24] Train loss=0.19388361275196075
[20/24] Train loss=0.2179124653339386
Test set avg_accuracy=86.08% avg_sensitivity=67.94%, avg_specificity=93.00% avg_auc=90.60%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.218305 Test loss=0.340899 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.20998097956180573
[5/24] Train loss=0.20848649740219116
[10/24] Train loss=0.2327083796262741
[15/24] Train loss=0.19646896421909332
[20/24] Train loss=0.21290656924247742
Test set avg_accuracy=85.42% avg_sensitivity=63.18%, avg_specificity=93.90% avg_auc=90.26%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.213228 Test loss=0.349116 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2017970234155655
[5/24] Train loss=0.2157728374004364
[10/24] Train loss=0.22349484264850616
[15/24] Train loss=0.19929012656211853
[20/24] Train loss=0.21392691135406494
Test set avg_accuracy=86.08% avg_sensitivity=71.48%, avg_specificity=91.65% avg_auc=91.65%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.215157 Test loss=0.322632 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.21665111184120178
[5/24] Train loss=0.20527289807796478
[10/24] Train loss=0.22631296515464783
[15/24] Train loss=0.20338349044322968
[20/24] Train loss=0.2106945961713791
Test set avg_accuracy=84.90% avg_sensitivity=65.72%, avg_specificity=92.21% avg_auc=89.91%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.215598 Test loss=0.356731 Current lr=[0.000224838296036774]

[0/24] Train loss=0.20825420320034027
[5/24] Train loss=0.19468438625335693
[10/24] Train loss=0.21220248937606812
[15/24] Train loss=0.2040712833404541
[20/24] Train loss=0.2121484875679016
Test set avg_accuracy=85.74% avg_sensitivity=69.17%, avg_specificity=92.07% avg_auc=90.98%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.212595 Test loss=0.334902 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.20298294723033905
[5/24] Train loss=0.2041846364736557
[10/24] Train loss=0.21973536908626556
[15/24] Train loss=0.20264436304569244
[20/24] Train loss=0.20713384449481964
Test set avg_accuracy=84.84% avg_sensitivity=62.19%, avg_specificity=93.49% avg_auc=88.50%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.209592 Test loss=0.369663 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.20489728450775146
[5/24] Train loss=0.20553570985794067
[10/24] Train loss=0.2211911678314209
[15/24] Train loss=0.21038180589675903
[20/24] Train loss=0.2077585905790329
Test set avg_accuracy=85.18% avg_sensitivity=67.04%, avg_specificity=92.10% avg_auc=90.64%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.210198 Test loss=0.342251 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2022399753332138
[5/24] Train loss=0.19615955650806427
[10/24] Train loss=0.20396141707897186
[15/24] Train loss=0.20427636802196503
[20/24] Train loss=0.20041237771511078
Test set avg_accuracy=84.48% avg_sensitivity=58.89%, avg_specificity=94.24% avg_auc=86.39%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.205866 Test loss=0.397614 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.21418645977973938
[5/24] Train loss=0.20473408699035645
[10/24] Train loss=0.21296007931232452
[15/24] Train loss=0.19777852296829224
[20/24] Train loss=0.1960616409778595
Test set avg_accuracy=84.61% avg_sensitivity=59.64%, avg_specificity=94.14% avg_auc=88.65%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.206256 Test loss=0.377679 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.20350638031959534
[5/24] Train loss=0.20700646936893463
[10/24] Train loss=0.21175885200500488
[15/24] Train loss=0.20949797332286835
[20/24] Train loss=0.19187650084495544
Test set avg_accuracy=85.42% avg_sensitivity=62.61%, avg_specificity=94.12% avg_auc=89.08%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.204778 Test loss=0.360389 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.20201194286346436
[5/24] Train loss=0.1920982301235199
[10/24] Train loss=0.20031265914440155
[15/24] Train loss=0.207681342959404
[20/24] Train loss=0.20668290555477142
Test set avg_accuracy=84.56% avg_sensitivity=61.39%, avg_specificity=93.40% avg_auc=87.93%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.206038 Test loss=0.378891 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.20601293444633484
[5/24] Train loss=0.20219048857688904
[10/24] Train loss=0.2059856504201889
[15/24] Train loss=0.19325925409793854
[20/24] Train loss=0.20915329456329346
Test set avg_accuracy=84.05% avg_sensitivity=56.01%, avg_specificity=94.75% avg_auc=87.16%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.207621 Test loss=0.399508 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.19110818207263947
[5/24] Train loss=0.183723583817482
[10/24] Train loss=0.2148667424917221
[15/24] Train loss=0.18305467069149017
[20/24] Train loss=0.19793829321861267
Test set avg_accuracy=85.44% avg_sensitivity=66.01%, avg_specificity=92.86% avg_auc=89.69%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.200500 Test loss=0.354126 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.18765956163406372
[5/24] Train loss=0.18783581256866455
[10/24] Train loss=0.20012710988521576
[15/24] Train loss=0.1831924170255661
[20/24] Train loss=0.20228224992752075
Test set avg_accuracy=85.38% avg_sensitivity=65.82%, avg_specificity=92.84% avg_auc=89.97%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.197334 Test loss=0.357248 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1862560212612152
[5/24] Train loss=0.1770823895931244
[10/24] Train loss=0.19824595749378204
[15/24] Train loss=0.1808042675256729
[20/24] Train loss=0.19205687940120697
Test set avg_accuracy=84.06% avg_sensitivity=60.77%, avg_specificity=92.95% avg_auc=86.39%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.191529 Test loss=0.394649 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.19026178121566772
[5/24] Train loss=0.1804826557636261
[10/24] Train loss=0.19411377608776093
[15/24] Train loss=0.18016301095485687
[20/24] Train loss=0.19164331257343292
Test set avg_accuracy=85.53% avg_sensitivity=65.96%, avg_specificity=93.00% avg_auc=89.34%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.191216 Test loss=0.355007 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.18366846442222595
[5/24] Train loss=0.16768485307693481
[10/24] Train loss=0.18855127692222595
[15/24] Train loss=0.17399242520332336
[20/24] Train loss=0.1817394345998764
Test set avg_accuracy=83.36% avg_sensitivity=63.04%, avg_specificity=91.11% avg_auc=86.43%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.185599 Test loss=0.398257 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.18063446879386902
[5/24] Train loss=0.17086438834667206
[10/24] Train loss=0.18897153437137604
[15/24] Train loss=0.17320634424686432
[20/24] Train loss=0.18514195084571838
Test set avg_accuracy=85.12% avg_sensitivity=65.96%, avg_specificity=92.43% avg_auc=89.45%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.184117 Test loss=0.349622 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.180917426943779
[5/24] Train loss=0.17166605591773987
[10/24] Train loss=0.18917055428028107
[15/24] Train loss=0.17585498094558716
[20/24] Train loss=0.1812441647052765
Test set avg_accuracy=84.87% avg_sensitivity=62.61%, avg_specificity=93.36% avg_auc=88.24%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.181840 Test loss=0.371130 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.1811949759721756
[5/24] Train loss=0.1690511405467987
[10/24] Train loss=0.18570613861083984
[15/24] Train loss=0.17077051103115082
[20/24] Train loss=0.17858700454235077
Test set avg_accuracy=85.14% avg_sensitivity=61.48%, avg_specificity=94.17% avg_auc=88.81%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.180424 Test loss=0.363178 Current lr=[0.000156543481933168]

[0/24] Train loss=0.16830547153949738
[5/24] Train loss=0.18206490576267242
[10/24] Train loss=0.17795886099338531
[15/24] Train loss=0.17156913876533508
[20/24] Train loss=0.17887204885482788
Test set avg_accuracy=85.55% avg_sensitivity=66.05%, avg_specificity=92.98% avg_auc=89.65%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.179311 Test loss=0.350372 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1754639744758606
[5/24] Train loss=0.16444465517997742
[10/24] Train loss=0.18626627326011658
[15/24] Train loss=0.1681283861398697
[20/24] Train loss=0.17737160623073578
Test set avg_accuracy=86.16% avg_sensitivity=69.31%, avg_specificity=92.59% avg_auc=91.11%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.178516 Test loss=0.331460 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.17229138314723969
[5/24] Train loss=0.16499505937099457
[10/24] Train loss=0.175176739692688
[15/24] Train loss=0.16653616726398468
[20/24] Train loss=0.17191915214061737
Test set avg_accuracy=85.83% avg_sensitivity=70.77%, avg_specificity=91.58% avg_auc=91.95%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.174772 Test loss=0.324509 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.16718824207782745
[5/24] Train loss=0.16072919964790344
[10/24] Train loss=0.17475281655788422
[15/24] Train loss=0.1618186980485916
[20/24] Train loss=0.1768709272146225
Test set avg_accuracy=85.18% avg_sensitivity=72.37%, avg_specificity=90.07% avg_auc=90.92%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.172107 Test loss=0.343168 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.16681061685085297
[5/24] Train loss=0.15679673850536346
[10/24] Train loss=0.16899099946022034
[15/24] Train loss=0.16164548695087433
[20/24] Train loss=0.1697283536195755
Test set avg_accuracy=86.33% avg_sensitivity=72.61%, avg_specificity=91.56% avg_auc=92.09%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.169314 Test loss=0.324313 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16425558924674988
[5/24] Train loss=0.15931758284568787
[10/24] Train loss=0.17348307371139526
[15/24] Train loss=0.15591022372245789
[20/24] Train loss=0.16759304702281952
Test set avg_accuracy=85.62% avg_sensitivity=70.86%, avg_specificity=91.26% avg_auc=91.23%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.168224 Test loss=0.338619 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15859957039356232
[5/24] Train loss=0.15550166368484497
[10/24] Train loss=0.16240297257900238
[15/24] Train loss=0.158441424369812
[20/24] Train loss=0.16315175592899323
Test set avg_accuracy=85.90% avg_sensitivity=71.05%, avg_specificity=91.56% avg_auc=91.30%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.165241 Test loss=0.337542 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1602736860513687
[5/24] Train loss=0.1522771567106247
[10/24] Train loss=0.1648583561182022
[15/24] Train loss=0.16092215478420258
[20/24] Train loss=0.1679336428642273
Test set avg_accuracy=85.55% avg_sensitivity=70.63%, avg_specificity=91.24% avg_auc=91.31%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.164997 Test loss=0.335905 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.16195286810398102
[5/24] Train loss=0.14987227320671082
[10/24] Train loss=0.15821069478988647
[15/24] Train loss=0.1566590964794159
[20/24] Train loss=0.16257962584495544
Test set avg_accuracy=85.64% avg_sensitivity=70.49%, avg_specificity=91.42% avg_auc=90.96%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.163320 Test loss=0.344707 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.15349003672599792
[5/24] Train loss=0.15526162087917328
[10/24] Train loss=0.16234828531742096
[15/24] Train loss=0.15458516776561737
[20/24] Train loss=0.161504864692688
Test set avg_accuracy=85.00% avg_sensitivity=68.22%, avg_specificity=91.40% avg_auc=90.63%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.162612 Test loss=0.353011 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16386598348617554
[5/24] Train loss=0.14527636766433716
[10/24] Train loss=0.15937942266464233
[15/24] Train loss=0.149623304605484
[20/24] Train loss=0.1614319235086441
Test set avg_accuracy=84.91% avg_sensitivity=69.59%, avg_specificity=90.75% avg_auc=90.48%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.159698 Test loss=0.352100 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15808309614658356
[5/24] Train loss=0.1486918181180954
[10/24] Train loss=0.1622411459684372
[15/24] Train loss=0.15015088021755219
[20/24] Train loss=0.15836821496486664
Test set avg_accuracy=85.20% avg_sensitivity=67.75%, avg_specificity=91.85% avg_auc=90.43%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.158573 Test loss=0.355846 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1534148007631302
[5/24] Train loss=0.14420416951179504
[10/24] Train loss=0.15815839171409607
[15/24] Train loss=0.1495107114315033
[20/24] Train loss=0.16216227412223816
Test set avg_accuracy=85.65% avg_sensitivity=70.49%, avg_specificity=91.44% avg_auc=90.66%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.156810 Test loss=0.347042 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.15363551676273346
[5/24] Train loss=0.14248648285865784
[10/24] Train loss=0.16130025684833527
[15/24] Train loss=0.15205006301403046
[20/24] Train loss=0.1589469313621521
Test set avg_accuracy=84.95% avg_sensitivity=65.58%, avg_specificity=92.34% avg_auc=89.87%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.155414 Test loss=0.356719 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15314051508903503
[5/24] Train loss=0.14322085678577423
[10/24] Train loss=0.15734504163265228
[15/24] Train loss=0.15023592114448547
[20/24] Train loss=0.15920080244541168
Test set avg_accuracy=85.03% avg_sensitivity=64.40%, avg_specificity=92.89% avg_auc=90.18%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.154756 Test loss=0.359175 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.148685023188591
[5/24] Train loss=0.14404261112213135
[10/24] Train loss=0.1533290594816208
[15/24] Train loss=0.1507561057806015
[20/24] Train loss=0.15852446854114532
Test set avg_accuracy=85.66% avg_sensitivity=67.94%, avg_specificity=92.43% avg_auc=90.56%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.153217 Test loss=0.347499 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14942970871925354
[5/24] Train loss=0.14208658039569855
[10/24] Train loss=0.15469036996364594
[15/24] Train loss=0.14910663664340973
[20/24] Train loss=0.1535043865442276
Test set avg_accuracy=85.18% avg_sensitivity=67.33%, avg_specificity=91.99% avg_auc=89.96%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.150636 Test loss=0.353601 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14845073223114014
[5/24] Train loss=0.13656724989414215
[10/24] Train loss=0.1466490477323532
[15/24] Train loss=0.14788618683815002
[20/24] Train loss=0.15693747997283936
Test set avg_accuracy=85.12% avg_sensitivity=69.17%, avg_specificity=91.20% avg_auc=89.97%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.148951 Test loss=0.357988 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14376391470432281
[5/24] Train loss=0.13858532905578613
[10/24] Train loss=0.14861595630645752
[15/24] Train loss=0.1479518711566925
[20/24] Train loss=0.151952862739563
Test set avg_accuracy=85.18% avg_sensitivity=66.20%, avg_specificity=92.43% avg_auc=90.35%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.148475 Test loss=0.356788 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14399278163909912
[5/24] Train loss=0.1360199898481369
[10/24] Train loss=0.1432194858789444
[15/24] Train loss=0.14076992869377136
[20/24] Train loss=0.1505158245563507
Test set avg_accuracy=85.42% avg_sensitivity=67.52%, avg_specificity=92.25% avg_auc=90.14%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.146195 Test loss=0.353514 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14359726011753082
[5/24] Train loss=0.1327715367078781
[10/24] Train loss=0.14267495274543762
[15/24] Train loss=0.14101143181324005
[20/24] Train loss=0.14952561259269714
Test set avg_accuracy=85.09% avg_sensitivity=67.61%, avg_specificity=91.76% avg_auc=90.60%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.145559 Test loss=0.351631 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.14001989364624023
[5/24] Train loss=0.13600783050060272
[10/24] Train loss=0.139341801404953
[15/24] Train loss=0.14074653387069702
[20/24] Train loss=0.14916931092739105
Test set avg_accuracy=85.69% avg_sensitivity=67.33%, avg_specificity=92.70% avg_auc=90.50%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.144583 Test loss=0.348708 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13971614837646484
[5/24] Train loss=0.13229545950889587
[10/24] Train loss=0.14121173322200775
[15/24] Train loss=0.14138923585414886
[20/24] Train loss=0.1440417468547821
Test set avg_accuracy=85.14% avg_sensitivity=65.49%, avg_specificity=92.64% avg_auc=90.38%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.142881 Test loss=0.354895 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14187778532505035
[5/24] Train loss=0.13121961057186127
[10/24] Train loss=0.14359691739082336
[15/24] Train loss=0.13565273582935333
[20/24] Train loss=0.14827461540699005
Test set avg_accuracy=85.20% avg_sensitivity=66.15%, avg_specificity=92.46% avg_auc=90.11%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.142175 Test loss=0.355050 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1379525512456894
[5/24] Train loss=0.12940411269664764
[10/24] Train loss=0.14152950048446655
[15/24] Train loss=0.1391143649816513
[20/24] Train loss=0.14411117136478424
Test set avg_accuracy=85.31% avg_sensitivity=67.89%, avg_specificity=91.96% avg_auc=90.42%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.141387 Test loss=0.350269 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.141837015748024
[5/24] Train loss=0.12960654497146606
[10/24] Train loss=0.1420910358428955
[15/24] Train loss=0.13686269521713257
[20/24] Train loss=0.1439858227968216
Test set avg_accuracy=85.46% avg_sensitivity=68.46%, avg_specificity=91.94% avg_auc=90.58%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.141505 Test loss=0.350987 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13934406638145447
[5/24] Train loss=0.1304587572813034
[10/24] Train loss=0.14004525542259216
[15/24] Train loss=0.13536439836025238
[20/24] Train loss=0.14645226299762726
Test set avg_accuracy=85.25% avg_sensitivity=66.62%, avg_specificity=92.35% avg_auc=90.34%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.140598 Test loss=0.355587 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1396942436695099
[5/24] Train loss=0.12836730480194092
[10/24] Train loss=0.13781967759132385
[15/24] Train loss=0.1353943794965744
[20/24] Train loss=0.14344340562820435
Test set avg_accuracy=85.30% avg_sensitivity=68.22%, avg_specificity=91.82% avg_auc=90.19%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.139433 Test loss=0.353227 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1355900764465332
[5/24] Train loss=0.12525904178619385
[10/24] Train loss=0.13817954063415527
[15/24] Train loss=0.13660362362861633
[20/24] Train loss=0.14132153987884521
Test set avg_accuracy=85.35% avg_sensitivity=67.80%, avg_specificity=92.05% avg_auc=90.01%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.138058 Test loss=0.358072 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13739082217216492
[5/24] Train loss=0.12426803261041641
[10/24] Train loss=0.13729973137378693
[15/24] Train loss=0.13630568981170654
[20/24] Train loss=0.14110445976257324
Test set avg_accuracy=85.36% avg_sensitivity=67.94%, avg_specificity=92.01% avg_auc=90.17%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.137846 Test loss=0.356379 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13640674948692322
[5/24] Train loss=0.12555409967899323
[10/24] Train loss=0.13908545672893524
[15/24] Train loss=0.1349157840013504
[20/24] Train loss=0.13948529958724976
Test set avg_accuracy=85.29% avg_sensitivity=67.85%, avg_specificity=91.94% avg_auc=90.16%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.137747 Test loss=0.358482 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13380011916160583
[5/24] Train loss=0.12361124902963638
[10/24] Train loss=0.13611187040805817
[15/24] Train loss=0.1318519413471222
[20/24] Train loss=0.1387302726507187
Test set avg_accuracy=85.31% avg_sensitivity=69.59%, avg_specificity=91.31% avg_auc=90.34%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.136675 Test loss=0.355748 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13560736179351807
[5/24] Train loss=0.12523572146892548
[10/24] Train loss=0.13476581871509552
[15/24] Train loss=0.1345459371805191
[20/24] Train loss=0.13854175806045532
Test set avg_accuracy=84.96% avg_sensitivity=66.81%, avg_specificity=91.89% avg_auc=90.15%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.136919 Test loss=0.357582 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13192439079284668
[5/24] Train loss=0.1256980299949646
[10/24] Train loss=0.13318991661071777
[15/24] Train loss=0.1315462589263916
[20/24] Train loss=0.1400594562292099
Test set avg_accuracy=85.42% avg_sensitivity=68.03%, avg_specificity=92.05% avg_auc=90.24%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.135625 Test loss=0.353596 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1304445117712021
[5/24] Train loss=0.1264844685792923
[10/24] Train loss=0.13431285321712494
[15/24] Train loss=0.13180047273635864
[20/24] Train loss=0.1369394063949585
Test set avg_accuracy=85.42% avg_sensitivity=68.22%, avg_specificity=91.98% avg_auc=90.19%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.135302 Test loss=0.354103 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1354736089706421
[5/24] Train loss=0.1236724779009819
[10/24] Train loss=0.13328705728054047
[15/24] Train loss=0.13276788592338562
[20/24] Train loss=0.1361674964427948
Test set avg_accuracy=85.20% avg_sensitivity=67.56%, avg_specificity=91.92% avg_auc=90.18%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.134974 Test loss=0.355273 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13215942680835724
[5/24] Train loss=0.12261892110109329
[10/24] Train loss=0.13224676251411438
[15/24] Train loss=0.13232453167438507
[20/24] Train loss=0.13625578582286835
Test set avg_accuracy=85.20% avg_sensitivity=67.75%, avg_specificity=91.85% avg_auc=90.12%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.134783 Test loss=0.356227 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13181990385055542
[5/24] Train loss=0.12332695722579956
[10/24] Train loss=0.13210034370422363
[15/24] Train loss=0.13192850351333618
[20/24] Train loss=0.1364409476518631
Test set avg_accuracy=85.35% avg_sensitivity=67.28%, avg_specificity=92.25% avg_auc=90.35%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.134041 Test loss=0.355268 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12954039871692657
[5/24] Train loss=0.12064637988805771
[10/24] Train loss=0.132734477519989
[15/24] Train loss=0.13123072683811188
[20/24] Train loss=0.13467803597450256
Test set avg_accuracy=85.53% avg_sensitivity=67.99%, avg_specificity=92.23% avg_auc=90.16%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.132911 Test loss=0.356044 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13081635534763336
[5/24] Train loss=0.1210663840174675
[10/24] Train loss=0.13055014610290527
[15/24] Train loss=0.12758773565292358
[20/24] Train loss=0.13493411242961884
Test set avg_accuracy=85.40% avg_sensitivity=67.75%, avg_specificity=92.14% avg_auc=90.28%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.132272 Test loss=0.354200 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.13015399873256683
[5/24] Train loss=0.11878503859043121
[10/24] Train loss=0.13214685022830963
[15/24] Train loss=0.12881965935230255
[20/24] Train loss=0.13458757102489471
Test set avg_accuracy=85.34% avg_sensitivity=67.89%, avg_specificity=91.99% avg_auc=90.20%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.132014 Test loss=0.355366 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13168402016162872
[5/24] Train loss=0.12192361801862717
[10/24] Train loss=0.13167628645896912
[15/24] Train loss=0.13158540427684784
[20/24] Train loss=0.13592495024204254
Test set avg_accuracy=85.20% avg_sensitivity=66.95%, avg_specificity=92.16% avg_auc=90.27%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.132491 Test loss=0.355136 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.13279873132705688
[5/24] Train loss=0.1222541406750679
[10/24] Train loss=0.13005119562149048
[15/24] Train loss=0.12886059284210205
[20/24] Train loss=0.13676868379116058
Test set avg_accuracy=85.31% avg_sensitivity=68.03%, avg_specificity=91.91% avg_auc=90.30%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.132492 Test loss=0.353913 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12942257523536682
[5/24] Train loss=0.11917132884263992
[10/24] Train loss=0.13129308819770813
[15/24] Train loss=0.12987107038497925
[20/24] Train loss=0.13717631995677948
Test set avg_accuracy=85.30% avg_sensitivity=67.37%, avg_specificity=92.14% avg_auc=90.30%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.131709 Test loss=0.354648 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13010060787200928
[5/24] Train loss=0.12231753021478653
[10/24] Train loss=0.13331744074821472
[15/24] Train loss=0.13052313029766083
[20/24] Train loss=0.13346335291862488
Test set avg_accuracy=85.30% avg_sensitivity=67.89%, avg_specificity=91.94% avg_auc=90.42%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.132247 Test loss=0.352386 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.13005679845809937
[5/24] Train loss=0.12050686776638031
[10/24] Train loss=0.13039103150367737
[15/24] Train loss=0.12895621359348297
[20/24] Train loss=0.13274139165878296
Test set avg_accuracy=85.33% avg_sensitivity=67.85%, avg_specificity=91.99% avg_auc=90.26%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.131538 Test loss=0.355138 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1312548816204071
[5/24] Train loss=0.12110550701618195
[10/24] Train loss=0.1320503205060959
[15/24] Train loss=0.1265316903591156
[20/24] Train loss=0.13483186066150665
Test set avg_accuracy=85.21% avg_sensitivity=67.66%, avg_specificity=91.91% avg_auc=90.21%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.131639 Test loss=0.355976 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13254302740097046
[5/24] Train loss=0.12044026702642441
[10/24] Train loss=0.12984612584114075
[15/24] Train loss=0.12623336911201477
[20/24] Train loss=0.13542889058589935
Test set avg_accuracy=85.27% avg_sensitivity=67.66%, avg_specificity=91.99% avg_auc=90.24%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.131101 Test loss=0.355429 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12964269518852234
[5/24] Train loss=0.12266336381435394
[10/24] Train loss=0.1290324330329895
[15/24] Train loss=0.13019385933876038
[20/24] Train loss=0.13568656146526337
Test set avg_accuracy=85.31% avg_sensitivity=67.70%, avg_specificity=92.03% avg_auc=90.28%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.131606 Test loss=0.354816 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12930597364902496
[5/24] Train loss=0.12155230343341827
[10/24] Train loss=0.12970523536205292
[15/24] Train loss=0.13105864822864532
[20/24] Train loss=0.13397645950317383
Test set avg_accuracy=85.34% avg_sensitivity=67.80%, avg_specificity=92.03% avg_auc=90.33%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.131509 Test loss=0.354176 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12968066334724426
[5/24] Train loss=0.11963445693254471
[10/24] Train loss=0.13000085949897766
[15/24] Train loss=0.128941610455513
[20/24] Train loss=0.1345861256122589
Test set avg_accuracy=85.26% avg_sensitivity=67.61%, avg_specificity=91.99% avg_auc=90.29%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.131375 Test loss=0.355092 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12959539890289307
[5/24] Train loss=0.12278876453638077
[10/24] Train loss=0.12814638018608093
[15/24] Train loss=0.12767212092876434
[20/24] Train loss=0.13458803296089172
Test set avg_accuracy=85.25% avg_sensitivity=67.56%, avg_specificity=91.99% avg_auc=90.32%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.131630 Test loss=0.354489 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12851083278656006
[5/24] Train loss=0.12058943510055542
[10/24] Train loss=0.13109822571277618
[15/24] Train loss=0.12779851257801056
[20/24] Train loss=0.13328319787979126
Test set avg_accuracy=85.31% avg_sensitivity=67.70%, avg_specificity=92.03% avg_auc=90.29%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.131040 Test loss=0.355062 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1290220469236374
[5/24] Train loss=0.11947678029537201
[10/24] Train loss=0.1293879598379135
[15/24] Train loss=0.12871986627578735
[20/24] Train loss=0.13529177010059357
Test set avg_accuracy=85.22% avg_sensitivity=67.52%, avg_specificity=91.98% avg_auc=90.32%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.131325 Test loss=0.354692 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=86.48% sen=74.54%, spe=91.04%, auc=91.95%!
Fold[7] Avg_overlap=0.69%(±0.23044725857332446)
[0/24] Train loss=0.7300876975059509
[5/24] Train loss=0.724815309047699
[10/24] Train loss=0.7257164120674133
[15/24] Train loss=0.7259534597396851
[20/24] Train loss=0.7141069769859314
Test set avg_accuracy=54.74% avg_sensitivity=40.34%, avg_specificity=59.58% avg_auc=50.55%
Best model saved!! Metric=-120.7964492768457!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.725519 Test loss=0.681396 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7079925537109375
[5/24] Train loss=0.7167341709136963
[10/24] Train loss=0.7095708847045898
[15/24] Train loss=0.6968120336532593
[20/24] Train loss=0.6969163417816162
Test set avg_accuracy=61.74% avg_sensitivity=32.31%, avg_specificity=71.63% avg_auc=53.38%
Best model saved!! Metric=-106.93110567490149!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.707503 Test loss=0.654926 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6889084577560425
[5/24] Train loss=0.692265510559082
[10/24] Train loss=0.6989525556564331
[15/24] Train loss=0.6893478631973267
[20/24] Train loss=0.676556408405304
Test set avg_accuracy=67.86% avg_sensitivity=31.38%, avg_specificity=80.12% avg_auc=56.63%
Best model saved!! Metric=-90.00605744367704!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.691027 Test loss=0.641166 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6723549962043762
[5/24] Train loss=0.6703974008560181
[10/24] Train loss=0.6793232560157776
[15/24] Train loss=0.6673071980476379
[20/24] Train loss=0.6527068018913269
Test set avg_accuracy=69.34% avg_sensitivity=32.83%, avg_specificity=81.60% avg_auc=59.93%
Best model saved!! Metric=-82.3093124022864!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.671493 Test loss=0.624136 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6519091725349426
[5/24] Train loss=0.647912859916687
[10/24] Train loss=0.6631336212158203
[15/24] Train loss=0.659745454788208
[20/24] Train loss=0.6303391456604004
Test set avg_accuracy=71.85% avg_sensitivity=35.58%, avg_specificity=84.03% avg_auc=63.97%
Best model saved!! Metric=-70.57304521417306!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.651971 Test loss=0.600470 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6279889941215515
[5/24] Train loss=0.6262222528457642
[10/24] Train loss=0.639548122882843
[15/24] Train loss=0.6236125230789185
[20/24] Train loss=0.6159347891807556
Test set avg_accuracy=73.06% avg_sensitivity=41.22%, avg_specificity=83.75% avg_auc=68.31%
Best model saved!! Metric=-59.656175473148366!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.629344 Test loss=0.576418 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6009071469306946
[5/24] Train loss=0.602121889591217
[10/24] Train loss=0.6203209757804871
[15/24] Train loss=0.6022707223892212
[20/24] Train loss=0.5822718739509583
Test set avg_accuracy=75.59% avg_sensitivity=46.25%, avg_specificity=85.44% avg_auc=72.47%
Best model saved!! Metric=-46.25612415051198!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.602248 Test loss=0.548220 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5756657123565674
[5/24] Train loss=0.5723013877868652
[10/24] Train loss=0.5849941372871399
[15/24] Train loss=0.5706653594970703
[20/24] Train loss=0.5561166405677795
Test set avg_accuracy=76.20% avg_sensitivity=48.16%, avg_specificity=85.61% avg_auc=75.35%
Best model saved!! Metric=-40.67717214034806!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.575145 Test loss=0.518992 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5423183441162109
[5/24] Train loss=0.5452388525009155
[10/24] Train loss=0.5583022236824036
[15/24] Train loss=0.5467090010643005
[20/24] Train loss=0.5324668884277344
Test set avg_accuracy=76.82% avg_sensitivity=52.30%, avg_specificity=85.06% avg_auc=77.66%
Best model saved!! Metric=-34.15712039019118!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.549950 Test loss=0.502181 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5153137445449829
[5/24] Train loss=0.5206048488616943
[10/24] Train loss=0.5406559109687805
[15/24] Train loss=0.5210181474685669
[20/24] Train loss=0.5090559124946594
Test set avg_accuracy=77.34% avg_sensitivity=51.58%, avg_specificity=86.00% avg_auc=78.80%
Best model saved!! Metric=-32.281078725307324!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.526426 Test loss=0.478406 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4940480887889862
[5/24] Train loss=0.5001363754272461
[10/24] Train loss=0.521579921245575
[15/24] Train loss=0.5047718286514282
[20/24] Train loss=0.48309656977653503
Test set avg_accuracy=77.73% avg_sensitivity=53.96%, avg_specificity=85.72% avg_auc=79.91%
Best model saved!! Metric=-28.67209742007909!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.507767 Test loss=0.468823 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4737389385700226
[5/24] Train loss=0.47497105598449707
[10/24] Train loss=0.5007855296134949
[15/24] Train loss=0.47960105538368225
[20/24] Train loss=0.46474072337150574
Test set avg_accuracy=78.12% avg_sensitivity=54.27%, avg_specificity=86.14% avg_auc=80.76%
Best model saved!! Metric=-26.70492102109671!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.488258 Test loss=0.456240 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.45822200179100037
[5/24] Train loss=0.4666893184185028
[10/24] Train loss=0.48639991879463196
[15/24] Train loss=0.4728664755821228
[20/24] Train loss=0.44915881752967834
Test set avg_accuracy=78.58% avg_sensitivity=54.27%, avg_specificity=86.75% avg_auc=81.72%
Best model saved!! Metric=-24.683711211994662!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.473614 Test loss=0.444725 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.44169217348098755
[5/24] Train loss=0.4491518437862396
[10/24] Train loss=0.473004549741745
[15/24] Train loss=0.45457449555397034
[20/24] Train loss=0.4354415237903595
Test set avg_accuracy=79.32% avg_sensitivity=54.74%, avg_specificity=87.58% avg_auc=82.42%
Best model saved!! Metric=-21.943022452819932!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.459723 Test loss=0.434967 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4311530888080597
[5/24] Train loss=0.42921507358551025
[10/24] Train loss=0.4629071056842804
[15/24] Train loss=0.4450116753578186
[20/24] Train loss=0.4206865429878235
Test set avg_accuracy=79.71% avg_sensitivity=52.82%, avg_specificity=88.75% avg_auc=83.29%
Best model saved!! Metric=-21.429898495714035!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.447347 Test loss=0.424350 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4160228371620178
[5/24] Train loss=0.421631783246994
[10/24] Train loss=0.44886186718940735
[15/24] Train loss=0.43813350796699524
[20/24] Train loss=0.40697768330574036
Test set avg_accuracy=80.16% avg_sensitivity=50.85%, avg_specificity=90.00% avg_auc=83.76%
Best model saved!! Metric=-21.230890933433237!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.436072 Test loss=0.416867 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4070413112640381
[5/24] Train loss=0.4126775860786438
[10/24] Train loss=0.4370516538619995
[15/24] Train loss=0.4211036264896393
[20/24] Train loss=0.3908836245536804
Test set avg_accuracy=80.78% avg_sensitivity=53.96%, avg_specificity=89.79% avg_auc=84.42%
Best model saved!! Metric=-17.048574906391742!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.425736 Test loss=0.409609 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3972100019454956
[5/24] Train loss=0.40151897072792053
[10/24] Train loss=0.4233798384666443
[15/24] Train loss=0.4177245795726776
[20/24] Train loss=0.383867084980011
Test set avg_accuracy=81.25% avg_sensitivity=52.98%, avg_specificity=90.75% avg_auc=85.39%
Best model saved!! Metric=-15.637171155067229!!
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.416992 Test loss=0.398676 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3851616382598877
[5/24] Train loss=0.3919140100479126
[10/24] Train loss=0.41410404443740845
[15/24] Train loss=0.4162829518318176
[20/24] Train loss=0.3740088939666748
Test set avg_accuracy=81.50% avg_sensitivity=55.15%, avg_specificity=90.35% avg_auc=85.91%
Best model saved!! Metric=-13.093922009168075!!
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.408864 Test loss=0.392458 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.38120004534721375
[5/24] Train loss=0.3818831741809845
[10/24] Train loss=0.40610820055007935
[15/24] Train loss=0.4057144522666931
[20/24] Train loss=0.3643476963043213
Test set avg_accuracy=82.58% avg_sensitivity=62.56%, avg_specificity=89.30% avg_auc=87.07%
Best model saved!! Metric=-4.494707876886061!!
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.399730 Test loss=0.380458 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.36999252438545227
[5/24] Train loss=0.3759867250919342
[10/24] Train loss=0.3978925943374634
[15/24] Train loss=0.39421382546424866
[20/24] Train loss=0.3538443446159363
Test set avg_accuracy=82.80% avg_sensitivity=60.44%, avg_specificity=90.31% avg_auc=87.66%
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.392741 Test loss=0.371576 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.36379027366638184
[5/24] Train loss=0.37199169397354126
[10/24] Train loss=0.39097633957862854
[15/24] Train loss=0.38437801599502563
[20/24] Train loss=0.3458619713783264
Test set avg_accuracy=83.52% avg_sensitivity=60.54%, avg_specificity=91.23% avg_auc=88.07%
Best model saved!! Metric=-2.643176850482817!!
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.384943 Test loss=0.364973 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.35710370540618896
[5/24] Train loss=0.3568630814552307
[10/24] Train loss=0.38618573546409607
[15/24] Train loss=0.37780237197875977
[20/24] Train loss=0.3432636559009552
Test set avg_accuracy=82.50% avg_sensitivity=65.10%, avg_specificity=88.35% avg_auc=87.52%
Best model saved!! Metric=-2.533732838413158!!
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.377907 Test loss=0.376262 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3539961576461792
[5/24] Train loss=0.3479764461517334
[10/24] Train loss=0.3777390718460083
[15/24] Train loss=0.37336307764053345
[20/24] Train loss=0.3310230076313019
Test set avg_accuracy=82.47% avg_sensitivity=61.42%, avg_specificity=89.55% avg_auc=87.12%
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.371685 Test loss=0.376894 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.34724491834640503
[5/24] Train loss=0.33844485878944397
[10/24] Train loss=0.3627393841743469
[15/24] Train loss=0.3660995066165924
[20/24] Train loss=0.3247983455657959
Test set avg_accuracy=82.92% avg_sensitivity=63.59%, avg_specificity=89.41% avg_auc=87.47%
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.363094 Test loss=0.372622 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.34829288721084595
[5/24] Train loss=0.3347078859806061
[10/24] Train loss=0.35639554262161255
[15/24] Train loss=0.3535265326499939
[20/24] Train loss=0.3088729977607727
Test set avg_accuracy=84.69% avg_sensitivity=63.23%, avg_specificity=91.89% avg_auc=88.71%
Best model saved!! Metric=2.520372472180995!!
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.357229 Test loss=0.352270 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3356020748615265
[5/24] Train loss=0.32732921838760376
[10/24] Train loss=0.36430883407592773
[15/24] Train loss=0.3521355986595154
[20/24] Train loss=0.30646151304244995
Test set avg_accuracy=85.16% avg_sensitivity=59.87%, avg_specificity=93.65% avg_auc=89.37%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.353171 Test loss=0.343557 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.33059483766555786
[5/24] Train loss=0.33227235078811646
[10/24] Train loss=0.35651546716690063
[15/24] Train loss=0.34371355175971985
[20/24] Train loss=0.29556524753570557
Test set avg_accuracy=84.62% avg_sensitivity=50.23%, avg_specificity=96.17% avg_auc=89.64%
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.345938 Test loss=0.352081 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3190291225910187
[5/24] Train loss=0.3280267119407654
[10/24] Train loss=0.35468611121177673
[15/24] Train loss=0.3307857811450958
[20/24] Train loss=0.2958315908908844
Test set avg_accuracy=85.61% avg_sensitivity=58.31%, avg_specificity=94.78% avg_auc=89.90%
Best model saved!! Metric=2.6100499364553613!!
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.341941 Test loss=0.337950 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.32074981927871704
[5/24] Train loss=0.32701659202575684
[10/24] Train loss=0.34907111525535583
[15/24] Train loss=0.33122900128364563
[20/24] Train loss=0.2878902852535248
Test set avg_accuracy=82.80% avg_sensitivity=37.03%, avg_specificity=98.17% avg_auc=89.37%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.333822 Test loss=0.389204 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3180195689201355
[5/24] Train loss=0.318643718957901
[10/24] Train loss=0.343456506729126
[15/24] Train loss=0.3363860547542572
[20/24] Train loss=0.27464354038238525
Test set avg_accuracy=83.85% avg_sensitivity=43.92%, avg_specificity=97.27% avg_auc=89.04%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.329519 Test loss=0.372291 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3201826810836792
[5/24] Train loss=0.3151189088821411
[10/24] Train loss=0.33426162600517273
[15/24] Train loss=0.32748281955718994
[20/24] Train loss=0.28583648800849915
Test set avg_accuracy=84.18% avg_sensitivity=43.24%, avg_specificity=97.93% avg_auc=89.58%
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.327060 Test loss=0.374192 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3063587248325348
[5/24] Train loss=0.30666008591651917
[10/24] Train loss=0.3504660725593567
[15/24] Train loss=0.33934563398361206
[20/24] Train loss=0.26855531334877014
Test set avg_accuracy=85.81% avg_sensitivity=62.25%, avg_specificity=93.72% avg_auc=90.38%
Best model saved!! Metric=6.151532382567169!!
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.323617 Test loss=0.327974 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.30610352754592896
[5/24] Train loss=0.29959627985954285
[10/24] Train loss=0.3285515606403351
[15/24] Train loss=0.330881267786026
[20/24] Train loss=0.2632785737514496
Test set avg_accuracy=83.52% avg_sensitivity=41.48%, avg_specificity=97.63% avg_auc=88.93%
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.317390 Test loss=0.382494 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3105182349681854
[5/24] Train loss=0.30578991770744324
[10/24] Train loss=0.3421178460121155
[15/24] Train loss=0.3270476162433624
[20/24] Train loss=0.2636638879776001
Test set avg_accuracy=86.42% avg_sensitivity=59.04%, avg_specificity=95.62% avg_auc=90.72%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.316435 Test loss=0.324227 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3016945421695709
[5/24] Train loss=0.30562645196914673
[10/24] Train loss=0.3250381648540497
[15/24] Train loss=0.32739853858947754
[20/24] Train loss=0.26198434829711914
Test set avg_accuracy=82.99% avg_sensitivity=37.03%, avg_specificity=98.43% avg_auc=89.32%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.313422 Test loss=0.391201 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.30792030692100525
[5/24] Train loss=0.3070089519023895
[10/24] Train loss=0.31613168120384216
[15/24] Train loss=0.32300660014152527
[20/24] Train loss=0.2548029124736786
Test set avg_accuracy=84.88% avg_sensitivity=46.71%, avg_specificity=97.70% avg_auc=89.97%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.312956 Test loss=0.354854 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.29429882764816284
[5/24] Train loss=0.2940160930156708
[10/24] Train loss=0.321304589509964
[15/24] Train loss=0.3180263042449951
[20/24] Train loss=0.25706470012664795
Test set avg_accuracy=86.82% avg_sensitivity=62.51%, avg_specificity=94.99% avg_auc=90.99%
Best model saved!! Metric=9.306808535731996!!
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.306250 Test loss=0.317148 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2918279469013214
[5/24] Train loss=0.2889847159385681
[10/24] Train loss=0.30796992778778076
[15/24] Train loss=0.3129856586456299
[20/24] Train loss=0.2455328404903412
Test set avg_accuracy=86.30% avg_sensitivity=55.00%, avg_specificity=96.82% avg_auc=90.49%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.302088 Test loss=0.331310 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2870104908943176
[5/24] Train loss=0.290688157081604
[10/24] Train loss=0.30363377928733826
[15/24] Train loss=0.31193941831588745
[20/24] Train loss=0.25388529896736145
Test set avg_accuracy=86.58% avg_sensitivity=59.81%, avg_specificity=95.56% avg_auc=90.80%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.302230 Test loss=0.319142 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.28338390588760376
[5/24] Train loss=0.28186163306236267
[10/24] Train loss=0.3020956814289093
[15/24] Train loss=0.31125494837760925
[20/24] Train loss=0.23510481417179108
Test set avg_accuracy=86.68% avg_sensitivity=55.26%, avg_specificity=97.23% avg_auc=90.85%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.295875 Test loss=0.328259 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2824835777282715
[5/24] Train loss=0.2911640405654907
[10/24] Train loss=0.31007400155067444
[15/24] Train loss=0.30879947543144226
[20/24] Train loss=0.240611732006073
Test set avg_accuracy=87.23% avg_sensitivity=68.41%, avg_specificity=93.55% avg_auc=92.18%
Best model saved!! Metric=15.358940823692905!!
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.296524 Test loss=0.297314 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2776702046394348
[5/24] Train loss=0.2897961437702179
[10/24] Train loss=0.31302058696746826
[15/24] Train loss=0.3056197762489319
[20/24] Train loss=0.23958922922611237
Test set avg_accuracy=87.19% avg_sensitivity=61.37%, avg_specificity=95.86% avg_auc=91.14%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.293563 Test loss=0.315046 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.27374884486198425
[5/24] Train loss=0.2818506956100464
[10/24] Train loss=0.3026141822338104
[15/24] Train loss=0.30209586024284363
[20/24] Train loss=0.2418598234653473
Test set avg_accuracy=87.42% avg_sensitivity=67.94%, avg_specificity=93.96% avg_auc=91.24%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.290743 Test loss=0.308538 Current lr=[0.00029967723776099]

[0/24] Train loss=0.27341899275779724
[5/24] Train loss=0.27199307084083557
[10/24] Train loss=0.30719199776649475
[15/24] Train loss=0.295746386051178
[20/24] Train loss=0.23677092790603638
Test set avg_accuracy=87.15% avg_sensitivity=60.44%, avg_specificity=96.12% avg_auc=91.39%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.288110 Test loss=0.314228 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.26924219727516174
[5/24] Train loss=0.26914840936660767
[10/24] Train loss=0.3042031228542328
[15/24] Train loss=0.29674315452575684
[20/24] Train loss=0.23249442875385284
Test set avg_accuracy=86.93% avg_sensitivity=61.68%, avg_specificity=95.41% avg_auc=91.60%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.286978 Test loss=0.309796 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.272127240896225
[5/24] Train loss=0.2712499797344208
[10/24] Train loss=0.2912091314792633
[15/24] Train loss=0.3008812665939331
[20/24] Train loss=0.2396916151046753
Test set avg_accuracy=86.09% avg_sensitivity=55.57%, avg_specificity=96.35% avg_auc=91.29%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.285769 Test loss=0.322454 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2720397412776947
[5/24] Train loss=0.26887208223342896
[10/24] Train loss=0.29083865880966187
[15/24] Train loss=0.2836263179779053
[20/24] Train loss=0.23720042407512665
Test set avg_accuracy=86.63% avg_sensitivity=65.56%, avg_specificity=93.70% avg_auc=91.45%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.280948 Test loss=0.308626 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.27154892683029175
[5/24] Train loss=0.26563701033592224
[10/24] Train loss=0.2845821976661682
[15/24] Train loss=0.28384655714035034
[20/24] Train loss=0.23768359422683716
Test set avg_accuracy=86.97% avg_sensitivity=64.99%, avg_specificity=94.35% avg_auc=90.54%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.279495 Test loss=0.319587 Current lr=[0.000298904600941902]

[0/24] Train loss=0.26257628202438354
[5/24] Train loss=0.25683829188346863
[10/24] Train loss=0.2959679365158081
[15/24] Train loss=0.295030802488327
[20/24] Train loss=0.2252466380596161
Test set avg_accuracy=86.65% avg_sensitivity=58.83%, avg_specificity=96.00% avg_auc=91.29%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.276133 Test loss=0.316010 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.26432451605796814
[5/24] Train loss=0.2521020472049713
[10/24] Train loss=0.28561434149742126
[15/24] Train loss=0.29980719089508057
[20/24] Train loss=0.22641657292842865
Test set avg_accuracy=86.42% avg_sensitivity=58.67%, avg_specificity=95.74% avg_auc=90.04%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.275004 Test loss=0.330858 Current lr=[0.000297555943323901]

[0/24] Train loss=0.25221213698387146
[5/24] Train loss=0.264601469039917
[10/24] Train loss=0.2752646207809448
[15/24] Train loss=0.28211918473243713
[20/24] Train loss=0.2202335149049759
Test set avg_accuracy=86.72% avg_sensitivity=65.20%, avg_specificity=93.95% avg_auc=90.45%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.275351 Test loss=0.322572 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.25218454003334045
[5/24] Train loss=0.25949573516845703
[10/24] Train loss=0.27813977003097534
[15/24] Train loss=0.28699037432670593
[20/24] Train loss=0.22729337215423584
Test set avg_accuracy=87.40% avg_sensitivity=64.89%, avg_specificity=94.96% avg_auc=91.52%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.271970 Test loss=0.306626 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2504587173461914
[5/24] Train loss=0.24892252683639526
[10/24] Train loss=0.27363625168800354
[15/24] Train loss=0.2769347131252289
[20/24] Train loss=0.2336587756872177
Test set avg_accuracy=83.80% avg_sensitivity=43.24%, avg_specificity=97.43% avg_auc=88.86%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.269983 Test loss=0.386196 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.25503379106521606
[5/24] Train loss=0.26070892810821533
[10/24] Train loss=0.2751380503177643
[15/24] Train loss=0.28794610500335693
[20/24] Train loss=0.22719994187355042
Test set avg_accuracy=86.69% avg_sensitivity=61.57%, avg_specificity=95.13% avg_auc=91.21%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.269239 Test loss=0.312895 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2474203258752823
[5/24] Train loss=0.24904437363147736
[10/24] Train loss=0.26422446966171265
[15/24] Train loss=0.2718946039676666
[20/24] Train loss=0.22327351570129395
Test set avg_accuracy=87.54% avg_sensitivity=68.46%, avg_specificity=93.95% avg_auc=91.71%
Best model saved!! Metric=15.661306892760905!!
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.261501 Test loss=0.302008 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.2498667687177658
[5/24] Train loss=0.2535373568534851
[10/24] Train loss=0.27683815360069275
[15/24] Train loss=0.26511454582214355
[20/24] Train loss=0.21588462591171265
Test set avg_accuracy=86.00% avg_sensitivity=55.15%, avg_specificity=96.36% avg_auc=90.58%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.262889 Test loss=0.335439 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2533026933670044
[5/24] Train loss=0.24685609340667725
[10/24] Train loss=0.2711479365825653
[15/24] Train loss=0.2696171700954437
[20/24] Train loss=0.22116811573505402
Test set avg_accuracy=86.35% avg_sensitivity=56.55%, avg_specificity=96.36% avg_auc=90.39%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.260483 Test loss=0.334906 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.26049286127090454
[5/24] Train loss=0.24608798325061798
[10/24] Train loss=0.2765567898750305
[15/24] Train loss=0.2809395492076874
[20/24] Train loss=0.2214125096797943
Test set avg_accuracy=87.33% avg_sensitivity=68.36%, avg_specificity=93.70% avg_auc=91.34%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.263079 Test loss=0.308169 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.24240034818649292
[5/24] Train loss=0.24198998510837555
[10/24] Train loss=0.27930963039398193
[15/24] Train loss=0.27394208312034607
[20/24] Train loss=0.2161429226398468
Test set avg_accuracy=86.18% avg_sensitivity=60.12%, avg_specificity=94.94% avg_auc=90.90%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.258367 Test loss=0.321203 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.23820309340953827
[5/24] Train loss=0.24767091870307922
[10/24] Train loss=0.26404428482055664
[15/24] Train loss=0.27174925804138184
[20/24] Train loss=0.20835961401462555
Test set avg_accuracy=86.64% avg_sensitivity=59.66%, avg_specificity=95.70% avg_auc=89.93%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.255004 Test loss=0.335371 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.23829273879528046
[5/24] Train loss=0.23972691595554352
[10/24] Train loss=0.2593339681625366
[15/24] Train loss=0.27513957023620605
[20/24] Train loss=0.22323885560035706
Test set avg_accuracy=82.63% avg_sensitivity=36.82%, avg_specificity=98.02% avg_auc=89.19%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.254136 Test loss=0.409885 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2487005740404129
[5/24] Train loss=0.24463576078414917
[10/24] Train loss=0.25311097502708435
[15/24] Train loss=0.2782791554927826
[20/24] Train loss=0.2080281376838684
Test set avg_accuracy=86.09% avg_sensitivity=58.16%, avg_specificity=95.48% avg_auc=89.71%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.252365 Test loss=0.335357 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.22777800261974335
[5/24] Train loss=0.23439595103263855
[10/24] Train loss=0.24596728384494781
[15/24] Train loss=0.2589139938354492
[20/24] Train loss=0.203350231051445
Test set avg_accuracy=87.02% avg_sensitivity=65.82%, avg_specificity=94.14% avg_auc=90.37%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.247912 Test loss=0.320100 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2284414917230606
[5/24] Train loss=0.23138219118118286
[10/24] Train loss=0.2507099211215973
[15/24] Train loss=0.27750325202941895
[20/24] Train loss=0.21360604465007782
Test set avg_accuracy=86.47% avg_sensitivity=62.56%, avg_specificity=94.50% avg_auc=90.27%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.249159 Test loss=0.327880 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.23985739052295685
[5/24] Train loss=0.2387615293264389
[10/24] Train loss=0.2512407600879669
[15/24] Train loss=0.25641098618507385
[20/24] Train loss=0.20829437673091888
Test set avg_accuracy=85.56% avg_sensitivity=53.13%, avg_specificity=96.45% avg_auc=88.06%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.246324 Test loss=0.360801 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.22617900371551514
[5/24] Train loss=0.23002688586711884
[10/24] Train loss=0.246678426861763
[15/24] Train loss=0.26206889748573303
[20/24] Train loss=0.21696238219738007
Test set avg_accuracy=86.47% avg_sensitivity=62.82%, avg_specificity=94.42% avg_auc=87.73%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.244833 Test loss=0.343857 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.23293213546276093
[5/24] Train loss=0.22889085114002228
[10/24] Train loss=0.24792900681495667
[15/24] Train loss=0.26641377806663513
[20/24] Train loss=0.21853899955749512
Test set avg_accuracy=87.24% avg_sensitivity=67.32%, avg_specificity=93.93% avg_auc=89.54%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.243623 Test loss=0.325499 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.22944289445877075
[5/24] Train loss=0.2345496416091919
[10/24] Train loss=0.25353479385375977
[15/24] Train loss=0.2565978765487671
[20/24] Train loss=0.20518501102924347
Test set avg_accuracy=87.19% avg_sensitivity=68.98%, avg_specificity=93.30% avg_auc=91.16%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.240563 Test loss=0.314699 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2274964153766632
[5/24] Train loss=0.2408047467470169
[10/24] Train loss=0.24662064015865326
[15/24] Train loss=0.25721216201782227
[20/24] Train loss=0.20217707753181458
Test set avg_accuracy=85.90% avg_sensitivity=63.80%, avg_specificity=93.32% avg_auc=88.83%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.237494 Test loss=0.342568 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.22314557433128357
[5/24] Train loss=0.2199842929840088
[10/24] Train loss=0.24666330218315125
[15/24] Train loss=0.2561696767807007
[20/24] Train loss=0.20638251304626465
Test set avg_accuracy=85.65% avg_sensitivity=62.09%, avg_specificity=93.56% avg_auc=89.23%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.236851 Test loss=0.339370 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.22406716644763947
[5/24] Train loss=0.21568404138088226
[10/24] Train loss=0.2298024445772171
[15/24] Train loss=0.2607674300670624
[20/24] Train loss=0.2064971625804901
Test set avg_accuracy=86.71% avg_sensitivity=72.45%, avg_specificity=91.49% avg_auc=91.49%
Best model saved!! Metric=16.13614243557643!!
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.234412 Test loss=0.311098 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.21572302281856537
[5/24] Train loss=0.2094620019197464
[10/24] Train loss=0.2586621642112732
[15/24] Train loss=0.24933819472789764
[20/24] Train loss=0.20959581434726715
Test set avg_accuracy=86.61% avg_sensitivity=71.67%, avg_specificity=91.63% avg_auc=91.08%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.236802 Test loss=0.317705 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.22026391327381134
[5/24] Train loss=0.20667403936386108
[10/24] Train loss=0.2390194684267044
[15/24] Train loss=0.24922314286231995
[20/24] Train loss=0.19519832730293274
Test set avg_accuracy=87.02% avg_sensitivity=69.96%, avg_specificity=92.75% avg_auc=91.27%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.231738 Test loss=0.309970 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.21834857761859894
[5/24] Train loss=0.224134162068367
[10/24] Train loss=0.2350582778453827
[15/24] Train loss=0.25018587708473206
[20/24] Train loss=0.18742482364177704
Test set avg_accuracy=85.70% avg_sensitivity=73.64%, avg_specificity=89.75% avg_auc=90.22%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.228721 Test loss=0.340400 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.21558235585689545
[5/24] Train loss=0.20624607801437378
[10/24] Train loss=0.2369106560945511
[15/24] Train loss=0.23635481297969818
[20/24] Train loss=0.19618897140026093
Test set avg_accuracy=86.30% avg_sensitivity=76.07%, avg_specificity=89.74% avg_auc=91.45%
Best model saved!! Metric=17.567778517842484!!
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.228800 Test loss=0.322640 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.21412278711795807
[5/24] Train loss=0.20724844932556152
[10/24] Train loss=0.21666528284549713
[15/24] Train loss=0.23049797117710114
[20/24] Train loss=0.1987282782793045
Test set avg_accuracy=85.47% avg_sensitivity=73.07%, avg_specificity=89.63% avg_auc=90.11%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.223559 Test loss=0.344478 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2073092758655548
[5/24] Train loss=0.2113591581583023
[10/24] Train loss=0.22465427219867706
[15/24] Train loss=0.24468812346458435
[20/24] Train loss=0.1815738081932068
Test set avg_accuracy=86.60% avg_sensitivity=67.84%, avg_specificity=92.90% avg_auc=90.43%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.220609 Test loss=0.326258 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.21608921885490417
[5/24] Train loss=0.20833788812160492
[10/24] Train loss=0.23063349723815918
[15/24] Train loss=0.2270677387714386
[20/24] Train loss=0.183770090341568
Test set avg_accuracy=86.90% avg_sensitivity=62.51%, avg_specificity=95.09% avg_auc=90.24%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.217524 Test loss=0.325987 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2115110158920288
[5/24] Train loss=0.1930641531944275
[10/24] Train loss=0.22196757793426514
[15/24] Train loss=0.22799725830554962
[20/24] Train loss=0.1836397498846054
Test set avg_accuracy=86.25% avg_sensitivity=72.09%, avg_specificity=91.01% avg_auc=90.12%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.214640 Test loss=0.336921 Current lr=[0.000224838296036774]

[0/24] Train loss=0.21488702297210693
[5/24] Train loss=0.1961544305086136
[10/24] Train loss=0.22444579005241394
[15/24] Train loss=0.22124965488910675
[20/24] Train loss=0.1839536428451538
Test set avg_accuracy=86.73% avg_sensitivity=66.39%, avg_specificity=93.56% avg_auc=90.18%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.212157 Test loss=0.327016 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.20840713381767273
[5/24] Train loss=0.18761563301086426
[10/24] Train loss=0.21925340592861176
[15/24] Train loss=0.2213716357946396
[20/24] Train loss=0.18972140550613403
Test set avg_accuracy=85.57% avg_sensitivity=59.35%, avg_specificity=94.38% avg_auc=87.10%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.209919 Test loss=0.368873 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.21303489804267883
[5/24] Train loss=0.1923956274986267
[10/24] Train loss=0.22604265809059143
[15/24] Train loss=0.22406035661697388
[20/24] Train loss=0.1750168800354004
Test set avg_accuracy=86.04% avg_sensitivity=65.77%, avg_specificity=92.85% avg_auc=88.30%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.208794 Test loss=0.347719 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.202336385846138
[5/24] Train loss=0.18765462934970856
[10/24] Train loss=0.20852035284042358
[15/24] Train loss=0.2165842205286026
[20/24] Train loss=0.17523862421512604
Test set avg_accuracy=87.02% avg_sensitivity=71.10%, avg_specificity=92.36% avg_auc=90.28%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.206064 Test loss=0.324142 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2011944055557251
[5/24] Train loss=0.1829313486814499
[10/24] Train loss=0.21158480644226074
[15/24] Train loss=0.2086106389760971
[20/24] Train loss=0.18023735284805298
Test set avg_accuracy=86.71% avg_sensitivity=67.79%, avg_specificity=93.06% avg_auc=89.06%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.202787 Test loss=0.335255 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.1983260214328766
[5/24] Train loss=0.18881087005138397
[10/24] Train loss=0.20762225985527039
[15/24] Train loss=0.2152433693408966
[20/24] Train loss=0.18310147523880005
Test set avg_accuracy=86.00% avg_sensitivity=66.91%, avg_specificity=92.42% avg_auc=89.14%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.202368 Test loss=0.346578 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.19107776880264282
[5/24] Train loss=0.18712034821510315
[10/24] Train loss=0.20265072584152222
[15/24] Train loss=0.2122916281223297
[20/24] Train loss=0.18093542754650116
Test set avg_accuracy=86.74% avg_sensitivity=66.18%, avg_specificity=93.65% avg_auc=88.14%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.199622 Test loss=0.343843 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.19429828226566315
[5/24] Train loss=0.1955028921365738
[10/24] Train loss=0.2017989158630371
[15/24] Train loss=0.20982161164283752
[20/24] Train loss=0.1693335473537445
Test set avg_accuracy=86.37% avg_sensitivity=67.01%, avg_specificity=92.87% avg_auc=89.00%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.198121 Test loss=0.343690 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.19163349270820618
[5/24] Train loss=0.17681993544101715
[10/24] Train loss=0.2030513882637024
[15/24] Train loss=0.21257928013801575
[20/24] Train loss=0.17197442054748535
Test set avg_accuracy=85.74% avg_sensitivity=62.35%, avg_specificity=93.60% avg_auc=87.35%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.195867 Test loss=0.361383 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.191656693816185
[5/24] Train loss=0.18038907647132874
[10/24] Train loss=0.20504628121852875
[15/24] Train loss=0.19706159830093384
[20/24] Train loss=0.17455680668354034
Test set avg_accuracy=86.81% avg_sensitivity=65.41%, avg_specificity=94.00% avg_auc=89.28%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.194053 Test loss=0.338518 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1952010542154312
[5/24] Train loss=0.18011848628520966
[10/24] Train loss=0.1996607631444931
[15/24] Train loss=0.18999691307544708
[20/24] Train loss=0.17546860873699188
Test set avg_accuracy=85.48% avg_sensitivity=64.99%, avg_specificity=92.36% avg_auc=89.54%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.191683 Test loss=0.350133 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.18987536430358887
[5/24] Train loss=0.17758587002754211
[10/24] Train loss=0.19224287569522858
[15/24] Train loss=0.20485058426856995
[20/24] Train loss=0.16402186453342438
Test set avg_accuracy=85.90% avg_sensitivity=68.88%, avg_specificity=91.62% avg_auc=89.20%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.191824 Test loss=0.346837 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.18632879853248596
[5/24] Train loss=0.17684714496135712
[10/24] Train loss=0.19262172281742096
[15/24] Train loss=0.1944272816181183
[20/24] Train loss=0.1751251220703125
Test set avg_accuracy=85.99% avg_sensitivity=68.98%, avg_specificity=91.70% avg_auc=89.21%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.190016 Test loss=0.349215 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.1840999722480774
[5/24] Train loss=0.1820252239704132
[10/24] Train loss=0.19797463715076447
[15/24] Train loss=0.19440846145153046
[20/24] Train loss=0.17161913216114044
Test set avg_accuracy=86.32% avg_sensitivity=70.07%, avg_specificity=91.77% avg_auc=89.78%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.188680 Test loss=0.336450 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1945958137512207
[5/24] Train loss=0.17323367297649384
[10/24] Train loss=0.20294088125228882
[15/24] Train loss=0.19824537634849548
[20/24] Train loss=0.16451825201511383
Test set avg_accuracy=85.48% avg_sensitivity=63.75%, avg_specificity=92.78% avg_auc=88.44%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.188867 Test loss=0.352925 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.1892102062702179
[5/24] Train loss=0.16720768809318542
[10/24] Train loss=0.20259496569633484
[15/24] Train loss=0.20359764993190765
[20/24] Train loss=0.17105497419834137
Test set avg_accuracy=85.64% avg_sensitivity=72.71%, avg_specificity=89.98% avg_auc=89.64%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.185931 Test loss=0.344488 Current lr=[0.000156543481933168]

[0/24] Train loss=0.1791624277830124
[5/24] Train loss=0.17054173350334167
[10/24] Train loss=0.18775776028633118
[15/24] Train loss=0.1938171535730362
[20/24] Train loss=0.16608040034770966
Test set avg_accuracy=86.24% avg_sensitivity=70.95%, avg_specificity=91.37% avg_auc=89.78%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.183603 Test loss=0.339989 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.18429683148860931
[5/24] Train loss=0.16728071868419647
[10/24] Train loss=0.1915787160396576
[15/24] Train loss=0.19258703291416168
[20/24] Train loss=0.16040103137493134
Test set avg_accuracy=86.71% avg_sensitivity=68.88%, avg_specificity=92.69% avg_auc=89.18%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.183005 Test loss=0.341289 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.1873587965965271
[5/24] Train loss=0.16589583456516266
[10/24] Train loss=0.1872059851884842
[15/24] Train loss=0.20260655879974365
[20/24] Train loss=0.16203515231609344
Test set avg_accuracy=85.27% avg_sensitivity=71.47%, avg_specificity=89.91% avg_auc=89.61%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.184692 Test loss=0.350414 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.17644575238227844
[5/24] Train loss=0.17697790265083313
[10/24] Train loss=0.18771594762802124
[15/24] Train loss=0.19553805887699127
[20/24] Train loss=0.17149055004119873
Test set avg_accuracy=85.51% avg_sensitivity=71.72%, avg_specificity=90.14% avg_auc=89.37%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.185181 Test loss=0.353524 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.18347294628620148
[5/24] Train loss=0.1763157993555069
[10/24] Train loss=0.18294204771518707
[15/24] Train loss=0.19527274370193481
[20/24] Train loss=0.1580825299024582
Test set avg_accuracy=85.27% avg_sensitivity=63.28%, avg_specificity=92.66% avg_auc=88.32%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.185653 Test loss=0.364421 Current lr=[0.000134135431043539]

[0/24] Train loss=0.18496273458003998
[5/24] Train loss=0.17345337569713593
[10/24] Train loss=0.1873573213815689
[15/24] Train loss=0.18964461982250214
[20/24] Train loss=0.1684478223323822
Test set avg_accuracy=86.00% avg_sensitivity=64.06%, avg_specificity=93.37% avg_auc=88.94%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.183888 Test loss=0.352366 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.18663272261619568
[5/24] Train loss=0.16908986866474152
[10/24] Train loss=0.18497703969478607
[15/24] Train loss=0.1869754195213318
[20/24] Train loss=0.1637139767408371
Test set avg_accuracy=86.41% avg_sensitivity=65.61%, avg_specificity=93.39% avg_auc=89.41%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.180275 Test loss=0.343703 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.18012772500514984
[5/24] Train loss=0.18449769914150238
[10/24] Train loss=0.18805073201656342
[15/24] Train loss=0.18348555266857147
[20/24] Train loss=0.16576321423053741
Test set avg_accuracy=86.12% avg_sensitivity=71.36%, avg_specificity=91.08% avg_auc=90.13%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.180277 Test loss=0.340070 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.17259201407432556
[5/24] Train loss=0.17480343580245972
[10/24] Train loss=0.18348370492458344
[15/24] Train loss=0.17205052077770233
[20/24] Train loss=0.16453030705451965
Test set avg_accuracy=86.20% avg_sensitivity=66.08%, avg_specificity=92.96% avg_auc=88.91%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.178134 Test loss=0.348485 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.18101270496845245
[5/24] Train loss=0.17622514069080353
[10/24] Train loss=0.1920788437128067
[15/24] Train loss=0.17354826629161835
[20/24] Train loss=0.16143876314163208
Test set avg_accuracy=86.13% avg_sensitivity=66.03%, avg_specificity=92.89% avg_auc=89.18%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.177082 Test loss=0.343539 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.16878953576087952
[5/24] Train loss=0.15669642388820648
[10/24] Train loss=0.1867550164461136
[15/24] Train loss=0.1733541190624237
[20/24] Train loss=0.16106069087982178
Test set avg_accuracy=85.96% avg_sensitivity=67.17%, avg_specificity=92.28% avg_auc=88.90%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.174480 Test loss=0.346023 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.18013224005699158
[5/24] Train loss=0.16550661623477936
[10/24] Train loss=0.18414509296417236
[15/24] Train loss=0.17487993836402893
[20/24] Train loss=0.15712442994117737
Test set avg_accuracy=86.51% avg_sensitivity=63.75%, avg_specificity=94.16% avg_auc=89.94%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.174055 Test loss=0.334920 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.17582297325134277
[5/24] Train loss=0.1519443243741989
[10/24] Train loss=0.18169397115707397
[15/24] Train loss=0.1725698560476303
[20/24] Train loss=0.15475912392139435
Test set avg_accuracy=86.54% avg_sensitivity=70.64%, avg_specificity=91.88% avg_auc=90.29%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.169562 Test loss=0.333732 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.16720756888389587
[5/24] Train loss=0.15407095849514008
[10/24] Train loss=0.17656934261322021
[15/24] Train loss=0.16666942834854126
[20/24] Train loss=0.1514214128255844
Test set avg_accuracy=87.21% avg_sensitivity=70.33%, avg_specificity=92.89% avg_auc=90.47%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.165369 Test loss=0.325188 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.1599532812833786
[5/24] Train loss=0.15349772572517395
[10/24] Train loss=0.17190368473529816
[15/24] Train loss=0.1671953946352005
[20/24] Train loss=0.15016093850135803
Test set avg_accuracy=86.93% avg_sensitivity=69.19%, avg_specificity=92.89% avg_auc=90.09%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.163009 Test loss=0.330324 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.16220217943191528
[5/24] Train loss=0.15238051116466522
[10/24] Train loss=0.1758890300989151
[15/24] Train loss=0.16312628984451294
[20/24] Train loss=0.14736512303352356
Test set avg_accuracy=86.63% avg_sensitivity=68.98%, avg_specificity=92.56% avg_auc=90.03%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.163413 Test loss=0.332816 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1648685187101364
[5/24] Train loss=0.14854180812835693
[10/24] Train loss=0.17060944437980652
[15/24] Train loss=0.16208115220069885
[20/24] Train loss=0.14514529705047607
Test set avg_accuracy=86.51% avg_sensitivity=66.86%, avg_specificity=93.11% avg_auc=89.42%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.160512 Test loss=0.336788 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.16598956286907196
[5/24] Train loss=0.15092065930366516
[10/24] Train loss=0.16689229011535645
[15/24] Train loss=0.16617728769779205
[20/24] Train loss=0.14376100897789001
Test set avg_accuracy=86.04% avg_sensitivity=68.15%, avg_specificity=92.05% avg_auc=89.19%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.159119 Test loss=0.347484 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.15407222509384155
[5/24] Train loss=0.1443062722682953
[10/24] Train loss=0.16758112609386444
[15/24] Train loss=0.16093191504478455
[20/24] Train loss=0.14219240844249725
Test set avg_accuracy=85.76% avg_sensitivity=67.43%, avg_specificity=91.91% avg_auc=88.69%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.157260 Test loss=0.350607 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1586798131465912
[5/24] Train loss=0.14646585285663605
[10/24] Train loss=0.16222363710403442
[15/24] Train loss=0.15664470195770264
[20/24] Train loss=0.1416229009628296
Test set avg_accuracy=86.42% avg_sensitivity=69.45%, avg_specificity=92.12% avg_auc=89.90%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.155061 Test loss=0.337304 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.15109069645404816
[5/24] Train loss=0.1420789659023285
[10/24] Train loss=0.15788020193576813
[15/24] Train loss=0.15461567044258118
[20/24] Train loss=0.14055582880973816
Test set avg_accuracy=86.43% avg_sensitivity=69.55%, avg_specificity=92.10% avg_auc=89.87%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.152629 Test loss=0.335627 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1490987241268158
[5/24] Train loss=0.13690361380577087
[10/24] Train loss=0.15828439593315125
[15/24] Train loss=0.1512361615896225
[20/24] Train loss=0.14047829806804657
Test set avg_accuracy=86.68% avg_sensitivity=68.62%, avg_specificity=92.75% avg_auc=89.84%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.151527 Test loss=0.332257 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.15127518773078918
[5/24] Train loss=0.14341329038143158
[10/24] Train loss=0.15665370225906372
[15/24] Train loss=0.15063674747943878
[20/24] Train loss=0.14111188054084778
Test set avg_accuracy=86.34% avg_sensitivity=67.94%, avg_specificity=92.52% avg_auc=89.79%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.151160 Test loss=0.334692 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14711886644363403
[5/24] Train loss=0.13983747363090515
[10/24] Train loss=0.16070033609867096
[15/24] Train loss=0.15234573185443878
[20/24] Train loss=0.13854429125785828
Test set avg_accuracy=86.60% avg_sensitivity=70.69%, avg_specificity=91.95% avg_auc=90.27%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.150351 Test loss=0.330179 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.15172579884529114
[5/24] Train loss=0.1360158920288086
[10/24] Train loss=0.15832704305648804
[15/24] Train loss=0.14556443691253662
[20/24] Train loss=0.13719137012958527
Test set avg_accuracy=86.82% avg_sensitivity=71.05%, avg_specificity=92.12% avg_auc=90.24%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.148561 Test loss=0.330045 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1461939662694931
[5/24] Train loss=0.13438701629638672
[10/24] Train loss=0.1519186794757843
[15/24] Train loss=0.146136075258255
[20/24] Train loss=0.13421228528022766
Test set avg_accuracy=86.33% avg_sensitivity=70.12%, avg_specificity=91.77% avg_auc=89.72%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.148048 Test loss=0.337331 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14688381552696228
[5/24] Train loss=0.13705067336559296
[10/24] Train loss=0.15629927814006805
[15/24] Train loss=0.14643986523151398
[20/24] Train loss=0.13585227727890015
Test set avg_accuracy=86.39% avg_sensitivity=69.76%, avg_specificity=91.98% avg_auc=89.75%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.147432 Test loss=0.337182 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.14932237565517426
[5/24] Train loss=0.13393989205360413
[10/24] Train loss=0.1538202315568924
[15/24] Train loss=0.14917877316474915
[20/24] Train loss=0.13685807585716248
Test set avg_accuracy=86.59% avg_sensitivity=70.84%, avg_specificity=91.88% avg_auc=89.89%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.147448 Test loss=0.335992 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.14478309452533722
[5/24] Train loss=0.13588352501392365
[10/24] Train loss=0.1547655165195465
[15/24] Train loss=0.14557413756847382
[20/24] Train loss=0.13482072949409485
Test set avg_accuracy=86.56% avg_sensitivity=70.95%, avg_specificity=91.81% avg_auc=90.03%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.146926 Test loss=0.334678 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.14807574450969696
[5/24] Train loss=0.13307121396064758
[10/24] Train loss=0.15323013067245483
[15/24] Train loss=0.14669953286647797
[20/24] Train loss=0.13527485728263855
Test set avg_accuracy=86.54% avg_sensitivity=70.43%, avg_specificity=91.95% avg_auc=89.52%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.145901 Test loss=0.338982 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1438530683517456
[5/24] Train loss=0.1339106559753418
[10/24] Train loss=0.1509847342967987
[15/24] Train loss=0.14610974490642548
[20/24] Train loss=0.13354001939296722
Test set avg_accuracy=86.21% avg_sensitivity=68.00%, avg_specificity=92.33% avg_auc=89.44%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.145559 Test loss=0.344654 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.14354079961776733
[5/24] Train loss=0.1352003514766693
[10/24] Train loss=0.15493863821029663
[15/24] Train loss=0.14646683633327484
[20/24] Train loss=0.13289080560207367
Test set avg_accuracy=86.39% avg_sensitivity=71.47%, avg_specificity=91.41% avg_auc=90.08%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.144978 Test loss=0.336480 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.14393198490142822
[5/24] Train loss=0.1329929232597351
[10/24] Train loss=0.15139716863632202
[15/24] Train loss=0.14246253669261932
[20/24] Train loss=0.13203833997249603
Test set avg_accuracy=86.47% avg_sensitivity=69.50%, avg_specificity=92.17% avg_auc=89.75%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.143510 Test loss=0.337771 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.14128577709197998
[5/24] Train loss=0.13247798383235931
[10/24] Train loss=0.15050332248210907
[15/24] Train loss=0.14384369552135468
[20/24] Train loss=0.13164253532886505
Test set avg_accuracy=86.33% avg_sensitivity=69.65%, avg_specificity=91.93% avg_auc=89.64%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.143287 Test loss=0.340248 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1421610563993454
[5/24] Train loss=0.13128861784934998
[10/24] Train loss=0.14925187826156616
[15/24] Train loss=0.1403898149728775
[20/24] Train loss=0.13172824680805206
Test set avg_accuracy=86.33% avg_sensitivity=68.93%, avg_specificity=92.17% avg_auc=89.78%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.142340 Test loss=0.336860 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1377493441104889
[5/24] Train loss=0.13014808297157288
[10/24] Train loss=0.14733996987342834
[15/24] Train loss=0.14089970290660858
[20/24] Train loss=0.13083651661872864
Test set avg_accuracy=86.58% avg_sensitivity=70.95%, avg_specificity=91.82% avg_auc=89.84%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.141731 Test loss=0.336237 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.14023743569850922
[5/24] Train loss=0.13008014857769012
[10/24] Train loss=0.1456151157617569
[15/24] Train loss=0.14275160431861877
[20/24] Train loss=0.1304444968700409
Test set avg_accuracy=86.43% avg_sensitivity=70.07%, avg_specificity=91.93% avg_auc=89.69%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.141127 Test loss=0.338763 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.14116045832633972
[5/24] Train loss=0.12977129220962524
[10/24] Train loss=0.14661681652069092
[15/24] Train loss=0.14060531556606293
[20/24] Train loss=0.12807482481002808
Test set avg_accuracy=86.47% avg_sensitivity=70.07%, avg_specificity=91.98% avg_auc=89.64%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.140719 Test loss=0.339826 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13879163563251495
[5/24] Train loss=0.12875531613826752
[10/24] Train loss=0.14573723077774048
[15/24] Train loss=0.13913317024707794
[20/24] Train loss=0.12945671379566193
Test set avg_accuracy=86.38% avg_sensitivity=69.60%, avg_specificity=92.02% avg_auc=89.52%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.139934 Test loss=0.341019 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.13879001140594482
[5/24] Train loss=0.1258658468723297
[10/24] Train loss=0.14652489125728607
[15/24] Train loss=0.1404668539762497
[20/24] Train loss=0.12709860503673553
Test set avg_accuracy=86.22% avg_sensitivity=70.43%, avg_specificity=91.53% avg_auc=89.72%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.139670 Test loss=0.339205 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.13811004161834717
[5/24] Train loss=0.12774406373500824
[10/24] Train loss=0.1451461911201477
[15/24] Train loss=0.13993991911411285
[20/24] Train loss=0.1284436732530594
Test set avg_accuracy=86.45% avg_sensitivity=70.22%, avg_specificity=91.89% avg_auc=89.75%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.139717 Test loss=0.338330 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1374107450246811
[5/24] Train loss=0.12866860628128052
[10/24] Train loss=0.14787477254867554
[15/24] Train loss=0.13791829347610474
[20/24] Train loss=0.1284342259168625
Test set avg_accuracy=86.28% avg_sensitivity=69.86%, avg_specificity=91.79% avg_auc=89.54%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.139412 Test loss=0.341100 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.13784120976924896
[5/24] Train loss=0.13056597113609314
[10/24] Train loss=0.15107424557209015
[15/24] Train loss=0.14208024740219116
[20/24] Train loss=0.13033178448677063
Test set avg_accuracy=86.45% avg_sensitivity=70.53%, avg_specificity=91.79% avg_auc=89.83%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.139681 Test loss=0.337991 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13719569146633148
[5/24] Train loss=0.13017401099205017
[10/24] Train loss=0.14585533738136292
[15/24] Train loss=0.1363605558872223
[20/24] Train loss=0.1280975192785263
Test set avg_accuracy=86.41% avg_sensitivity=69.50%, avg_specificity=92.09% avg_auc=89.68%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.138594 Test loss=0.339917 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1363464742898941
[5/24] Train loss=0.127648264169693
[10/24] Train loss=0.1458093374967575
[15/24] Train loss=0.1390397548675537
[20/24] Train loss=0.12895797193050385
Test set avg_accuracy=86.37% avg_sensitivity=69.55%, avg_specificity=92.02% avg_auc=89.63%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.138622 Test loss=0.340218 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1406782865524292
[5/24] Train loss=0.12658418715000153
[10/24] Train loss=0.14655347168445587
[15/24] Train loss=0.13572058081626892
[20/24] Train loss=0.12858042120933533
Test set avg_accuracy=86.46% avg_sensitivity=70.17%, avg_specificity=91.93% avg_auc=89.78%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.138921 Test loss=0.338492 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.13611595332622528
[5/24] Train loss=0.12764662504196167
[10/24] Train loss=0.1435302495956421
[15/24] Train loss=0.13796654343605042
[20/24] Train loss=0.1285853087902069
Test set avg_accuracy=86.43% avg_sensitivity=69.91%, avg_specificity=91.98% avg_auc=89.77%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.138486 Test loss=0.338648 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.136165589094162
[5/24] Train loss=0.1257278025150299
[10/24] Train loss=0.14644083380699158
[15/24] Train loss=0.13851478695869446
[20/24] Train loss=0.12762874364852905
Test set avg_accuracy=86.47% avg_sensitivity=70.43%, avg_specificity=91.86% avg_auc=89.80%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.139202 Test loss=0.338305 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.13656511902809143
[5/24] Train loss=0.12651757895946503
[10/24] Train loss=0.14239616692066193
[15/24] Train loss=0.13783025741577148
[20/24] Train loss=0.12975656986236572
Test set avg_accuracy=86.39% avg_sensitivity=70.38%, avg_specificity=91.77% avg_auc=89.82%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.138665 Test loss=0.338413 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.13661327958106995
[5/24] Train loss=0.12686185538768768
[10/24] Train loss=0.1439010500907898
[15/24] Train loss=0.1376824975013733
[20/24] Train loss=0.1290760338306427
Test set avg_accuracy=86.42% avg_sensitivity=69.96%, avg_specificity=91.95% avg_auc=89.75%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.138443 Test loss=0.338780 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.13619153201580048
[5/24] Train loss=0.1268090158700943
[10/24] Train loss=0.14716599881649017
[15/24] Train loss=0.1384735405445099
[20/24] Train loss=0.13141784071922302
Test set avg_accuracy=86.38% avg_sensitivity=69.91%, avg_specificity=91.91% avg_auc=89.74%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.138588 Test loss=0.338703 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.13595496118068695
[5/24] Train loss=0.1257338970899582
[10/24] Train loss=0.1451554149389267
[15/24] Train loss=0.13750216364860535
[20/24] Train loss=0.12894126772880554
Test set avg_accuracy=86.45% avg_sensitivity=69.91%, avg_specificity=92.00% avg_auc=89.76%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.138447 Test loss=0.338666 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1348048597574234
[5/24] Train loss=0.1270408034324646
[10/24] Train loss=0.1438935399055481
[15/24] Train loss=0.13603611290454865
[20/24] Train loss=0.12872402369976044
Test set avg_accuracy=86.42% avg_sensitivity=69.76%, avg_specificity=92.02% avg_auc=89.73%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.137950 Test loss=0.338647 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.14040763676166534
[5/24] Train loss=0.12844420969486237
[10/24] Train loss=0.14518839120864868
[15/24] Train loss=0.13942080736160278
[20/24] Train loss=0.12648913264274597
Test set avg_accuracy=86.42% avg_sensitivity=69.96%, avg_specificity=91.95% avg_auc=89.73%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.138577 Test loss=0.338838 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=86.30% sen=76.07%, spe=89.74%, auc=91.45%!
Fold[8] Avg_overlap=0.68%(±0.24282032686073843)
[0/23] Train loss=0.7393505573272705
[5/23] Train loss=0.7337583899497986
[10/23] Train loss=0.7311254143714905
[15/23] Train loss=0.7314032912254333
[20/23] Train loss=0.724234402179718
Test set avg_accuracy=53.82% avg_sensitivity=48.52%, avg_specificity=55.50% avg_auc=53.40%
Best model saved!! Metric=-114.76218722766254!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.733784 Test loss=0.684462 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.7170023322105408
[5/23] Train loss=0.7187968492507935
[10/23] Train loss=0.7269748449325562
[15/23] Train loss=0.7122471332550049
[20/23] Train loss=0.7084441184997559
Test set avg_accuracy=64.54% avg_sensitivity=38.54%, avg_specificity=72.82% avg_auc=57.40%
Best model saved!! Metric=-92.69135495475824!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.718536 Test loss=0.657479 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.700998842716217
[5/23] Train loss=0.7074819207191467
[10/23] Train loss=0.7066547274589539
[15/23] Train loss=0.6962892413139343
[20/23] Train loss=0.6880068182945251
Test set avg_accuracy=68.68% avg_sensitivity=35.80%, avg_specificity=79.16% avg_auc=59.73%
Best model saved!! Metric=-82.63148143261068!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.702184 Test loss=0.637458 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.6949540972709656
[5/23] Train loss=0.683363139629364
[10/23] Train loss=0.6947730183601379
[15/23] Train loss=0.6788250207901001
[20/23] Train loss=0.6684528589248657
Test set avg_accuracy=70.69% avg_sensitivity=35.85%, avg_specificity=81.79% avg_auc=62.41%
Best model saved!! Metric=-75.26626939741602!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.687225 Test loss=0.623591 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.6721351146697998
[5/23] Train loss=0.6654706597328186
[10/23] Train loss=0.6748323440551758
[15/23] Train loss=0.6523336172103882
[20/23] Train loss=0.6402907967567444
Test set avg_accuracy=73.57% avg_sensitivity=35.31%, avg_specificity=85.75% avg_auc=65.46%
Best model saved!! Metric=-65.91496117142704!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.665101 Test loss=0.602520 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.6479095816612244
[5/23] Train loss=0.6451619863510132
[10/23] Train loss=0.6533975601196289
[15/23] Train loss=0.6328662037849426
[20/23] Train loss=0.6239795088768005
Test set avg_accuracy=74.57% avg_sensitivity=39.35%, avg_specificity=85.79% avg_auc=69.51%
Best model saved!! Metric=-56.78130185859468!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.644268 Test loss=0.574078 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.6184800267219543
[5/23] Train loss=0.624988317489624
[10/23] Train loss=0.6253314018249512
[15/23] Train loss=0.6011894941329956
[20/23] Train loss=0.5960418581962585
Test set avg_accuracy=75.76% avg_sensitivity=44.31%, avg_specificity=85.77% avg_auc=73.09%
Best model saved!! Metric=-47.07713668014378!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.616647 Test loss=0.542158 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.591477632522583
[5/23] Train loss=0.5990277528762817
[10/23] Train loss=0.5957047939300537
[15/23] Train loss=0.5742989182472229
[20/23] Train loss=0.5768697261810303
Test set avg_accuracy=76.33% avg_sensitivity=49.38%, avg_specificity=84.91% avg_auc=75.78%
Best model saved!! Metric=-39.60071134302371!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.590920 Test loss=0.518516 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.5592650771141052
[5/23] Train loss=0.5731037259101868
[10/23] Train loss=0.568888247013092
[15/23] Train loss=0.5490294694900513
[20/23] Train loss=0.5529122352600098
Test set avg_accuracy=77.02% avg_sensitivity=51.21%, avg_specificity=85.24% avg_auc=77.65%
Best model saved!! Metric=-34.88646178575284!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.564434 Test loss=0.497101 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.535144567489624
[5/23] Train loss=0.548316240310669
[10/23] Train loss=0.5488426685333252
[15/23] Train loss=0.5247113108634949
[20/23] Train loss=0.5272758603096008
Test set avg_accuracy=77.76% avg_sensitivity=49.76%, avg_specificity=86.68% avg_auc=78.07%
Best model saved!! Metric=-33.73410804904194!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.540969 Test loss=0.479630 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.5097870230674744
[5/23] Train loss=0.5273918509483337
[10/23] Train loss=0.5237288475036621
[15/23] Train loss=0.5131978392601013
[20/23] Train loss=0.5013689398765564
Test set avg_accuracy=78.46% avg_sensitivity=51.75%, avg_specificity=86.97% avg_auc=79.73%
Best model saved!! Metric=-29.087653918863687!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.518368 Test loss=0.467483 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.48427486419677734
[5/23] Train loss=0.5098989009857178
[10/23] Train loss=0.5026810765266418
[15/23] Train loss=0.48912882804870605
[20/23] Train loss=0.4835323989391327
Test set avg_accuracy=79.05% avg_sensitivity=51.86%, avg_specificity=87.71% avg_auc=81.14%
Best model saved!! Metric=-26.24487202429154!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.498957 Test loss=0.450103 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.4706994593143463
[5/23] Train loss=0.48848676681518555
[10/23] Train loss=0.484416127204895
[15/23] Train loss=0.47723907232284546
[20/23] Train loss=0.4715892970561981
Test set avg_accuracy=79.21% avg_sensitivity=51.37%, avg_specificity=88.07% avg_auc=81.83%
Best model saved!! Metric=-25.52581416246352!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.482788 Test loss=0.441918 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.4505610466003418
[5/23] Train loss=0.47348278760910034
[10/23] Train loss=0.4749982953071594
[15/23] Train loss=0.4560488164424896
[20/23] Train loss=0.44984349608421326
Test set avg_accuracy=79.60% avg_sensitivity=51.97%, avg_specificity=88.39% avg_auc=83.09%
Best model saved!! Metric=-22.956111620036694!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.467737 Test loss=0.428336 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.4367689788341522
[5/23] Train loss=0.46341338753700256
[10/23] Train loss=0.46244585514068604
[15/23] Train loss=0.44283321499824524
[20/23] Train loss=0.4392305016517639
Test set avg_accuracy=80.20% avg_sensitivity=52.94%, avg_specificity=88.88% avg_auc=83.86%
Best model saved!! Metric=-20.134065240245036!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.454457 Test loss=0.418353 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.4239735007286072
[5/23] Train loss=0.44568851590156555
[10/23] Train loss=0.4485395550727844
[15/23] Train loss=0.43325477838516235
[20/23] Train loss=0.42199692130088806
Test set avg_accuracy=80.57% avg_sensitivity=53.32%, avg_specificity=89.25% avg_auc=84.64%
Best model saved!! Metric=-18.220271908463758!!
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.441788 Test loss=0.409073 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.4140331447124481
[5/23] Train loss=0.43656930327415466
[10/23] Train loss=0.4406813681125641
[15/23] Train loss=0.4183918237686157
[20/23] Train loss=0.4107479453086853
Test set avg_accuracy=80.47% avg_sensitivity=54.07%, avg_specificity=88.88% avg_auc=85.60%
Best model saved!! Metric=-16.982828496812942!!
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.431793 Test loss=0.399981 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.40032830834388733
[5/23] Train loss=0.4245893061161041
[10/23] Train loss=0.4298228621482849
[15/23] Train loss=0.4089820981025696
[20/23] Train loss=0.39735355973243713
Test set avg_accuracy=80.59% avg_sensitivity=54.02%, avg_specificity=89.05% avg_auc=85.79%
Best model saved!! Metric=-16.564874017416095!!
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.420831 Test loss=0.394965 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.3912159204483032
[5/23] Train loss=0.4193122982978821
[10/23] Train loss=0.4207969903945923
[15/23] Train loss=0.398442804813385
[20/23] Train loss=0.3857952356338501
Test set avg_accuracy=80.85% avg_sensitivity=54.23%, avg_specificity=89.32% avg_auc=86.64%
Best model saved!! Metric=-14.960010721178485!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.411116 Test loss=0.386378 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.38269689679145813
[5/23] Train loss=0.40360942482948303
[10/23] Train loss=0.40444236993789673
[15/23] Train loss=0.3916598856449127
[20/23] Train loss=0.38100767135620117
Test set avg_accuracy=81.07% avg_sensitivity=55.96%, avg_specificity=89.06% avg_auc=87.12%
Best model saved!! Metric=-12.795804038981366!!
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.402229 Test loss=0.381442 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.3748771846294403
[5/23] Train loss=0.3940308690071106
[10/23] Train loss=0.40415751934051514
[15/23] Train loss=0.3793592154979706
[20/23] Train loss=0.36869102716445923
Test set avg_accuracy=81.25% avg_sensitivity=60.86%, avg_specificity=87.74% avg_auc=87.86%
Best model saved!! Metric=-8.280363360827344!!
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.394487 Test loss=0.373267 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.3631785809993744
[5/23] Train loss=0.387897789478302
[10/23] Train loss=0.3876011073589325
[15/23] Train loss=0.3676993250846863
[20/23] Train loss=0.3655985891819
Test set avg_accuracy=80.94% avg_sensitivity=62.16%, avg_specificity=86.92% avg_auc=87.87%
Best model saved!! Metric=-8.12073721990214!!
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.385186 Test loss=0.373999 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.35892781615257263
[5/23] Train loss=0.3793741464614868
[10/23] Train loss=0.38919201493263245
[15/23] Train loss=0.36659541726112366
[20/23] Train loss=0.35448288917541504
Test set avg_accuracy=81.34% avg_sensitivity=61.83%, avg_specificity=87.55% avg_auc=87.84%
Best model saved!! Metric=-7.431326200261054!!
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.381283 Test loss=0.371130 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.3514809012413025
[5/23] Train loss=0.373851478099823
[10/23] Train loss=0.37770721316337585
[15/23] Train loss=0.3640468716621399
[20/23] Train loss=0.3463672995567322
Test set avg_accuracy=82.01% avg_sensitivity=62.48%, avg_specificity=88.22% avg_auc=88.34%
Best model saved!! Metric=-4.9511027618392305!!
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.373409 Test loss=0.364677 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.34788405895233154
[5/23] Train loss=0.3657481074333191
[10/23] Train loss=0.3654384911060333
[15/23] Train loss=0.3493832051753998
[20/23] Train loss=0.33962932229042053
Test set avg_accuracy=81.45% avg_sensitivity=65.01%, avg_specificity=86.68% avg_auc=88.17%
Best model saved!! Metric=-4.695705280502764!!
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.365310 Test loss=0.371234 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.34107711911201477
[5/23] Train loss=0.3632223904132843
[10/23] Train loss=0.37287211418151855
[15/23] Train loss=0.3382950723171234
[20/23] Train loss=0.3224809169769287
Test set avg_accuracy=82.66% avg_sensitivity=68.41%, avg_specificity=87.19% avg_auc=89.18%
Best model saved!! Metric=1.4347606949087748!!
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.359354 Test loss=0.356054 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.33865147829055786
[5/23] Train loss=0.3518659770488739
[10/23] Train loss=0.36139795184135437
[15/23] Train loss=0.34216049313545227
[20/23] Train loss=0.32524314522743225
Test set avg_accuracy=82.04% avg_sensitivity=67.49%, avg_specificity=86.68% avg_auc=89.01%
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.353420 Test loss=0.359525 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.3282979428768158
[5/23] Train loss=0.3451032042503357
[10/23] Train loss=0.36462247371673584
[15/23] Train loss=0.3303186297416687
[20/23] Train loss=0.32107195258140564
Test set avg_accuracy=83.62% avg_sensitivity=64.37%, avg_specificity=89.75% avg_auc=89.31%
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.349272 Test loss=0.349568 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.32004624605178833
[5/23] Train loss=0.340880811214447
[10/23] Train loss=0.3648053705692291
[15/23] Train loss=0.32364198565483093
[20/23] Train loss=0.31625044345855713
Test set avg_accuracy=84.70% avg_sensitivity=62.43%, avg_specificity=91.79% avg_auc=89.66%
Best model saved!! Metric=2.580765618914583!!
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.341117 Test loss=0.341730 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.3198022246360779
[5/23] Train loss=0.3333921730518341
[10/23] Train loss=0.35827064514160156
[15/23] Train loss=0.3107289969921112
[20/23] Train loss=0.32125118374824524
Test set avg_accuracy=85.33% avg_sensitivity=61.13%, avg_specificity=93.03% avg_auc=90.41%
Best model saved!! Metric=3.8966625105078876!!
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.336938 Test loss=0.331652 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.3117341101169586
[5/23] Train loss=0.3350655138492584
[10/23] Train loss=0.3534926176071167
[15/23] Train loss=0.3186711370944977
[20/23] Train loss=0.31192341446876526
Test set avg_accuracy=85.49% avg_sensitivity=55.04%, avg_specificity=95.19% avg_auc=90.39%
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.333027 Test loss=0.333545 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.3168271481990814
[5/23] Train loss=0.3256055414676666
[10/23] Train loss=0.3569885790348053
[15/23] Train loss=0.306731253862381
[20/23] Train loss=0.3011239469051361
Test set avg_accuracy=83.28% avg_sensitivity=36.87%, avg_specificity=98.06% avg_auc=90.60%
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.329322 Test loss=0.371624 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.3111416697502136
[5/23] Train loss=0.3126961886882782
[10/23] Train loss=0.34212273359298706
[15/23] Train loss=0.29994818568229675
[20/23] Train loss=0.2925196588039398
Test set avg_accuracy=84.31% avg_sensitivity=45.34%, avg_specificity=96.72% avg_auc=90.66%
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.322251 Test loss=0.348989 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.3109242916107178
[5/23] Train loss=0.3159099817276001
[10/23] Train loss=0.3410343527793884
[15/23] Train loss=0.28394269943237305
[20/23] Train loss=0.29755786061286926
Test set avg_accuracy=83.97% avg_sensitivity=42.26%, avg_specificity=97.25% avg_auc=90.88%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.320448 Test loss=0.349599 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.3002857267856598
[5/23] Train loss=0.31181401014328003
[10/23] Train loss=0.342204213142395
[15/23] Train loss=0.29005447030067444
[20/23] Train loss=0.27878209948539734
Test set avg_accuracy=85.59% avg_sensitivity=55.58%, avg_specificity=95.14% avg_auc=91.26%
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.314145 Test loss=0.322265 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.2872926592826843
[5/23] Train loss=0.2959655225276947
[10/23] Train loss=0.34318771958351135
[15/23] Train loss=0.2885514795780182
[20/23] Train loss=0.2837291359901428
Test set avg_accuracy=86.09% avg_sensitivity=58.98%, avg_specificity=94.73% avg_auc=91.17%
Best model saved!! Metric=4.96589927755862!!
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.310879 Test loss=0.320244 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.2820088565349579
[5/23] Train loss=0.30311813950538635
[10/23] Train loss=0.3434499502182007
[15/23] Train loss=0.28741326928138733
[20/23] Train loss=0.29163625836372375
Test set avg_accuracy=85.61% avg_sensitivity=57.84%, avg_specificity=94.45% avg_auc=89.70%
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.308521 Test loss=0.338904 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.2989364266395569
[5/23] Train loss=0.28346556425094604
[10/23] Train loss=0.34914350509643555
[15/23] Train loss=0.29079878330230713
[20/23] Train loss=0.28358232975006104
Test set avg_accuracy=85.60% avg_sensitivity=59.73%, avg_specificity=93.84% avg_auc=90.38%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.309885 Test loss=0.328169 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.2940323054790497
[5/23] Train loss=0.2960016131401062
[10/23] Train loss=0.3378140330314636
[15/23] Train loss=0.279259592294693
[20/23] Train loss=0.27244362235069275
Test set avg_accuracy=85.82% avg_sensitivity=59.03%, avg_specificity=94.35% avg_auc=90.71%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.303989 Test loss=0.324908 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.2831956744194031
[5/23] Train loss=0.285139262676239
[10/23] Train loss=0.3336397409439087
[15/23] Train loss=0.2804900109767914
[20/23] Train loss=0.27094733715057373
Test set avg_accuracy=85.33% avg_sensitivity=54.07%, avg_specificity=95.28% avg_auc=89.97%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.300436 Test loss=0.336005 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.28286850452423096
[5/23] Train loss=0.2903209924697876
[10/23] Train loss=0.3180558681488037
[15/23] Train loss=0.2844855487346649
[20/23] Train loss=0.26713240146636963
Test set avg_accuracy=85.92% avg_sensitivity=62.10%, avg_specificity=93.51% avg_auc=90.76%
Best model saved!! Metric=6.302601166134522!!
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.297156 Test loss=0.319231 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.2813222408294678
[5/23] Train loss=0.28071296215057373
[10/23] Train loss=0.33839139342308044
[15/23] Train loss=0.27003762125968933
[20/23] Train loss=0.26907286047935486
Test set avg_accuracy=85.01% avg_sensitivity=49.22%, avg_specificity=96.41% avg_auc=90.51%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.295465 Test loss=0.337162 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.2790757715702057
[5/23] Train loss=0.2836807370185852
[10/23] Train loss=0.3274931013584137
[15/23] Train loss=0.27599024772644043
[20/23] Train loss=0.26265260577201843
Test set avg_accuracy=85.21% avg_sensitivity=50.67%, avg_specificity=96.21% avg_auc=90.26%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.294336 Test loss=0.335567 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.28393614292144775
[5/23] Train loss=0.275829553604126
[10/23] Train loss=0.32030510902404785
[15/23] Train loss=0.28294146060943604
[20/23] Train loss=0.25927993655204773
Test set avg_accuracy=86.13% avg_sensitivity=63.50%, avg_specificity=93.34% avg_auc=90.85%
Best model saved!! Metric=7.830338037059114!!
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.293527 Test loss=0.319446 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.2577458918094635
[5/23] Train loss=0.2933279275894165
[10/23] Train loss=0.3146447539329529
[15/23] Train loss=0.2748648226261139
[20/23] Train loss=0.26044660806655884
Test set avg_accuracy=86.63% avg_sensitivity=63.72%, avg_specificity=93.92% avg_auc=91.46%
Best model saved!! Metric=9.73239692027311!!
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.291554 Test loss=0.309876 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.2728129029273987
[5/23] Train loss=0.26983118057250977
[10/23] Train loss=0.3319050073623657
[15/23] Train loss=0.2755352258682251
[20/23] Train loss=0.2563830614089966
Test set avg_accuracy=85.81% avg_sensitivity=56.50%, avg_specificity=95.14% avg_auc=90.97%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.286371 Test loss=0.320991 Current lr=[0.000299926900870094]

[0/23] Train loss=0.26316308975219727
[5/23] Train loss=0.2773376703262329
[10/23] Train loss=0.315312922000885
[15/23] Train loss=0.26770302653312683
[20/23] Train loss=0.258679062128067
Test set avg_accuracy=85.96% avg_sensitivity=60.97%, avg_specificity=93.92% avg_auc=89.89%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.285530 Test loss=0.331576 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.27946361899375916
[5/23] Train loss=0.2760012149810791
[10/23] Train loss=0.3116093575954437
[15/23] Train loss=0.2582327723503113
[20/23] Train loss=0.2659187316894531
Test set avg_accuracy=85.42% avg_sensitivity=72.24%, avg_specificity=89.61% avg_auc=90.82%
Best model saved!! Metric=12.083825372403396!!
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.281492 Test loss=0.329059 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.2596394717693329
[5/23] Train loss=0.26157665252685547
[10/23] Train loss=0.29972246289253235
[15/23] Train loss=0.2565571367740631
[20/23] Train loss=0.25675076246261597
Test set avg_accuracy=85.91% avg_sensitivity=72.99%, avg_specificity=90.03% avg_auc=90.96%
Best model saved!! Metric=13.888326327271528!!
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.274000 Test loss=0.326792 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.25053590536117554
[5/23] Train loss=0.26867562532424927
[10/23] Train loss=0.31282201409339905
[15/23] Train loss=0.2599300146102905
[20/23] Train loss=0.2566370368003845
Test set avg_accuracy=84.66% avg_sensitivity=45.98%, avg_specificity=96.98% avg_auc=89.74%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.276060 Test loss=0.350350 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.2653579115867615
[5/23] Train loss=0.26284533739089966
[10/23] Train loss=0.3042486608028412
[15/23] Train loss=0.25994178652763367
[20/23] Train loss=0.2580460011959076
Test set avg_accuracy=84.08% avg_sensitivity=42.91%, avg_specificity=97.18% avg_auc=88.52%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.276324 Test loss=0.377342 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.2574414014816284
[5/23] Train loss=0.26579317450523376
[10/23] Train loss=0.3163559138774872
[15/23] Train loss=0.2603699266910553
[20/23] Train loss=0.24135981500148773
Test set avg_accuracy=85.83% avg_sensitivity=65.01%, avg_specificity=92.46% avg_auc=90.41%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.273942 Test loss=0.327453 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.2505711615085602
[5/23] Train loss=0.25701841711997986
[10/23] Train loss=0.2982136607170105
[15/23] Train loss=0.25465527176856995
[20/23] Train loss=0.2342805117368698
Test set avg_accuracy=85.87% avg_sensitivity=70.35%, avg_specificity=90.82% avg_auc=90.78%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.268834 Test loss=0.324923 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.24841701984405518
[5/23] Train loss=0.25035157799720764
[10/23] Train loss=0.29093068838119507
[15/23] Train loss=0.24596847593784332
[20/23] Train loss=0.2494710385799408
Test set avg_accuracy=85.12% avg_sensitivity=71.16%, avg_specificity=89.56% avg_auc=90.63%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.268588 Test loss=0.335533 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.256087064743042
[5/23] Train loss=0.2674400806427002
[10/23] Train loss=0.28334179520606995
[15/23] Train loss=0.2502509355545044
[20/23] Train loss=0.2346390336751938
Test set avg_accuracy=86.52% avg_sensitivity=71.00%, avg_specificity=91.47% avg_auc=91.33%
Best model saved!! Metric=14.314509073175387!!
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.264340 Test loss=0.317559 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.24042344093322754
[5/23] Train loss=0.25274303555488586
[10/23] Train loss=0.2806762158870697
[15/23] Train loss=0.24554963409900665
[20/23] Train loss=0.2350451499223709
Test set avg_accuracy=86.37% avg_sensitivity=70.24%, avg_specificity=91.50% avg_auc=90.61%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.262021 Test loss=0.324098 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.24377572536468506
[5/23] Train loss=0.2474985271692276
[10/23] Train loss=0.29325106739997864
[15/23] Train loss=0.24700093269348145
[20/23] Train loss=0.23463307321071625
Test set avg_accuracy=85.05% avg_sensitivity=75.42%, avg_specificity=88.12% avg_auc=90.51%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.259549 Test loss=0.349050 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.2504395544528961
[5/23] Train loss=0.25293317437171936
[10/23] Train loss=0.2682427167892456
[15/23] Train loss=0.24045485258102417
[20/23] Train loss=0.23219099640846252
Test set avg_accuracy=86.00% avg_sensitivity=67.92%, avg_specificity=91.76% avg_auc=90.84%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.255266 Test loss=0.323550 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.2453855574131012
[5/23] Train loss=0.24198512732982635
[10/23] Train loss=0.27809643745422363
[15/23] Train loss=0.24831950664520264
[20/23] Train loss=0.2355068027973175
Test set avg_accuracy=86.26% avg_sensitivity=72.02%, avg_specificity=90.80% avg_auc=90.91%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.256123 Test loss=0.323723 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.24596953392028809
[5/23] Train loss=0.2454407811164856
[10/23] Train loss=0.290021151304245
[15/23] Train loss=0.24171636998653412
[20/23] Train loss=0.23384492099285126
Test set avg_accuracy=86.95% avg_sensitivity=66.85%, avg_specificity=93.36% avg_auc=91.92%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.254779 Test loss=0.300364 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.231590136885643
[5/23] Train loss=0.2442527562379837
[10/23] Train loss=0.2745661735534668
[15/23] Train loss=0.23395635187625885
[20/23] Train loss=0.23251429200172424
Test set avg_accuracy=81.54% avg_sensitivity=67.17%, avg_specificity=86.11% avg_auc=85.94%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.248159 Test loss=0.406170 Current lr=[0.000283047938381597]

[0/23] Train loss=0.23464757204055786
[5/23] Train loss=0.23068304359912872
[10/23] Train loss=0.2675996422767639
[15/23] Train loss=0.22738362848758698
[20/23] Train loss=0.2268780767917633
Test set avg_accuracy=86.17% avg_sensitivity=67.39%, avg_specificity=92.15% avg_auc=91.37%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.248025 Test loss=0.311170 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.23783862590789795
[5/23] Train loss=0.23847390711307526
[10/23] Train loss=0.26979172229766846
[15/23] Train loss=0.2425113171339035
[20/23] Train loss=0.2391730546951294
Test set avg_accuracy=85.77% avg_sensitivity=72.02%, avg_specificity=90.15% avg_auc=91.24%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.249894 Test loss=0.328183 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.23099200427532196
[5/23] Train loss=0.22633996605873108
[10/23] Train loss=0.26734626293182373
[15/23] Train loss=0.21299757063388824
[20/23] Train loss=0.23734834790229797
Test set avg_accuracy=86.02% avg_sensitivity=68.30%, avg_specificity=91.66% avg_auc=91.17%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.244361 Test loss=0.321711 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.23649083077907562
[5/23] Train loss=0.2264007329940796
[10/23] Train loss=0.2829500436782837
[15/23] Train loss=0.22884735465049744
[20/23] Train loss=0.20602115988731384
Test set avg_accuracy=85.57% avg_sensitivity=66.74%, avg_specificity=91.57% avg_auc=90.16%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.242425 Test loss=0.333676 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.22854459285736084
[5/23] Train loss=0.21989531815052032
[10/23] Train loss=0.262770414352417
[15/23] Train loss=0.2200288623571396
[20/23] Train loss=0.21757732331752777
Test set avg_accuracy=86.34% avg_sensitivity=63.13%, avg_specificity=93.73% avg_auc=91.20%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.238278 Test loss=0.322900 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.22732055187225342
[5/23] Train loss=0.21429815888404846
[10/23] Train loss=0.2592843770980835
[15/23] Train loss=0.2261909395456314
[20/23] Train loss=0.22078576683998108
Test set avg_accuracy=85.29% avg_sensitivity=67.28%, avg_specificity=91.02% avg_auc=90.69%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.235483 Test loss=0.331508 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.2212403267621994
[5/23] Train loss=0.21187570691108704
[10/23] Train loss=0.2608282268047333
[15/23] Train loss=0.22202759981155396
[20/23] Train loss=0.21116963028907776
Test set avg_accuracy=85.76% avg_sensitivity=66.74%, avg_specificity=91.81% avg_auc=88.90%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.233214 Test loss=0.342158 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.2300184667110443
[5/23] Train loss=0.2245570570230484
[10/23] Train loss=0.2702106833457947
[15/23] Train loss=0.23776893317699432
[20/23] Train loss=0.19994302093982697
Test set avg_accuracy=85.60% avg_sensitivity=55.47%, avg_specificity=95.19% avg_auc=90.58%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.238240 Test loss=0.334242 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.2274278700351715
[5/23] Train loss=0.21790753304958344
[10/23] Train loss=0.2610849142074585
[15/23] Train loss=0.21755771338939667
[20/23] Train loss=0.2067514955997467
Test set avg_accuracy=85.64% avg_sensitivity=64.69%, avg_specificity=92.31% avg_auc=90.78%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.231601 Test loss=0.326500 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.21116229891777039
[5/23] Train loss=0.22286619246006012
[10/23] Train loss=0.23930761218070984
[15/23] Train loss=0.21200646460056305
[20/23] Train loss=0.21138852834701538
Test set avg_accuracy=85.23% avg_sensitivity=66.42%, avg_specificity=91.23% avg_auc=90.90%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.226649 Test loss=0.328591 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.2166995406150818
[5/23] Train loss=0.21565960347652435
[10/23] Train loss=0.2496742308139801
[15/23] Train loss=0.21352431178092957
[20/23] Train loss=0.20266230404376984
Test set avg_accuracy=85.57% avg_sensitivity=60.11%, avg_specificity=93.68% avg_auc=88.64%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.227293 Test loss=0.345644 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.2232738584280014
[5/23] Train loss=0.22218933701515198
[10/23] Train loss=0.24870969355106354
[15/23] Train loss=0.21405348181724548
[20/23] Train loss=0.19770343601703644
Test set avg_accuracy=85.08% avg_sensitivity=58.33%, avg_specificity=93.60% avg_auc=87.78%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.229277 Test loss=0.352129 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.2113485038280487
[5/23] Train loss=0.225423663854599
[10/23] Train loss=0.24108612537384033
[15/23] Train loss=0.21198098361492157
[20/23] Train loss=0.19817620515823364
Test set avg_accuracy=84.70% avg_sensitivity=62.05%, avg_specificity=91.91% avg_auc=90.15%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.222834 Test loss=0.343837 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.19832743704319
[5/23] Train loss=0.21281421184539795
[10/23] Train loss=0.2482106238603592
[15/23] Train loss=0.20095013082027435
[20/23] Train loss=0.18635113537311554
Test set avg_accuracy=85.74% avg_sensitivity=61.62%, avg_specificity=93.42% avg_auc=88.74%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.219391 Test loss=0.349040 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.21117106080055237
[5/23] Train loss=0.20190943777561188
[10/23] Train loss=0.24866855144500732
[15/23] Train loss=0.2002340406179428
[20/23] Train loss=0.1915389746427536
Test set avg_accuracy=85.62% avg_sensitivity=61.51%, avg_specificity=93.30% avg_auc=89.18%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.220350 Test loss=0.348174 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.21652249991893768
[5/23] Train loss=0.21604157984256744
[10/23] Train loss=0.243019238114357
[15/23] Train loss=0.19714832305908203
[20/23] Train loss=0.184909388422966
Test set avg_accuracy=85.23% avg_sensitivity=57.14%, avg_specificity=94.18% avg_auc=89.41%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.217096 Test loss=0.353437 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.21764105558395386
[5/23] Train loss=0.20111820101737976
[10/23] Train loss=0.2343112677335739
[15/23] Train loss=0.19964489340782166
[20/23] Train loss=0.1930098682641983
Test set avg_accuracy=85.89% avg_sensitivity=64.64%, avg_specificity=92.65% avg_auc=90.18%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.216245 Test loss=0.337236 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.1990194171667099
[5/23] Train loss=0.2029871791601181
[10/23] Train loss=0.23811501264572144
[15/23] Train loss=0.20101164281368256
[20/23] Train loss=0.19931119680404663
Test set avg_accuracy=85.64% avg_sensitivity=62.05%, avg_specificity=93.15% avg_auc=89.37%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.211471 Test loss=0.345700 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.20582690834999084
[5/23] Train loss=0.1974973827600479
[10/23] Train loss=0.22507807612419128
[15/23] Train loss=0.1968732625246048
[20/23] Train loss=0.19999299943447113
Test set avg_accuracy=85.43% avg_sensitivity=59.51%, avg_specificity=93.68% avg_auc=89.50%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.214390 Test loss=0.349050 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.20241984724998474
[5/23] Train loss=0.20142203569412231
[10/23] Train loss=0.23055399954319
[15/23] Train loss=0.1914318948984146
[20/23] Train loss=0.18022459745407104
Test set avg_accuracy=84.70% avg_sensitivity=55.53%, avg_specificity=93.99% avg_auc=86.61%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.211005 Test loss=0.390428 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.2053222805261612
[5/23] Train loss=0.19784684479236603
[10/23] Train loss=0.23362410068511963
[15/23] Train loss=0.18778468668460846
[20/23] Train loss=0.18479827046394348
Test set avg_accuracy=85.48% avg_sensitivity=66.25%, avg_specificity=91.61% avg_auc=89.58%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.207725 Test loss=0.349052 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.19371211528778076
[5/23] Train loss=0.19706273078918457
[10/23] Train loss=0.20964911580085754
[15/23] Train loss=0.19197960197925568
[20/23] Train loss=0.18774786591529846
Test set avg_accuracy=85.14% avg_sensitivity=62.48%, avg_specificity=92.36% avg_auc=87.66%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.204337 Test loss=0.361106 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.19076593220233917
[5/23] Train loss=0.19271698594093323
[10/23] Train loss=0.22301296889781952
[15/23] Train loss=0.17940020561218262
[20/23] Train loss=0.17322030663490295
Test set avg_accuracy=85.23% avg_sensitivity=62.26%, avg_specificity=92.55% avg_auc=88.49%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.202174 Test loss=0.357441 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.19048137962818146
[5/23] Train loss=0.19310902059078217
[10/23] Train loss=0.2171289175748825
[15/23] Train loss=0.19011050462722778
[20/23] Train loss=0.17121955752372742
Test set avg_accuracy=85.10% avg_sensitivity=66.74%, avg_specificity=90.95% avg_auc=89.22%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.200408 Test loss=0.356112 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.18178901076316833
[5/23] Train loss=0.18929791450500488
[10/23] Train loss=0.20944827795028687
[15/23] Train loss=0.17600056529045105
[20/23] Train loss=0.17319922149181366
Test set avg_accuracy=85.59% avg_sensitivity=58.01%, avg_specificity=94.37% avg_auc=87.68%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.198125 Test loss=0.360802 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.1944945752620697
[5/23] Train loss=0.18598300218582153
[10/23] Train loss=0.20863281190395355
[15/23] Train loss=0.17880883812904358
[20/23] Train loss=0.18225044012069702
Test set avg_accuracy=84.78% avg_sensitivity=57.25%, avg_specificity=93.55% avg_auc=86.75%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.197623 Test loss=0.378792 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.187022402882576
[5/23] Train loss=0.17763543128967285
[10/23] Train loss=0.2120046764612198
[15/23] Train loss=0.17807020246982574
[20/23] Train loss=0.17656850814819336
Test set avg_accuracy=84.23% avg_sensitivity=63.72%, avg_specificity=90.76% avg_auc=87.81%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.199702 Test loss=0.373046 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.1820225864648819
[5/23] Train loss=0.1873238980770111
[10/23] Train loss=0.20636695623397827
[15/23] Train loss=0.17943426966667175
[20/23] Train loss=0.1721266806125641
Test set avg_accuracy=83.88% avg_sensitivity=65.07%, avg_specificity=89.87% avg_auc=86.58%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.192805 Test loss=0.382320 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.17991331219673157
[5/23] Train loss=0.18656374514102936
[10/23] Train loss=0.202113077044487
[15/23] Train loss=0.1856261044740677
[20/23] Train loss=0.17236420512199402
Test set avg_accuracy=85.07% avg_sensitivity=61.83%, avg_specificity=92.46% avg_auc=89.04%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.194177 Test loss=0.358453 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.16734586656093597
[5/23] Train loss=0.18246464431285858
[10/23] Train loss=0.20213237404823303
[15/23] Train loss=0.17773090302944183
[20/23] Train loss=0.16439560055732727
Test set avg_accuracy=85.26% avg_sensitivity=65.61%, avg_specificity=91.52% avg_auc=89.98%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.187505 Test loss=0.350351 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.17188455164432526
[5/23] Train loss=0.16477051377296448
[10/23] Train loss=0.2003842443227768
[15/23] Train loss=0.16847379505634308
[20/23] Train loss=0.16233369708061218
Test set avg_accuracy=84.91% avg_sensitivity=57.30%, avg_specificity=93.70% avg_auc=86.81%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.181755 Test loss=0.369826 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.17165541648864746
[5/23] Train loss=0.1756109595298767
[10/23] Train loss=0.1980934739112854
[15/23] Train loss=0.16485042870044708
[20/23] Train loss=0.15322978794574738
Test set avg_accuracy=85.36% avg_sensitivity=68.46%, avg_specificity=90.75% avg_auc=90.01%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.180178 Test loss=0.347398 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.16255223751068115
[5/23] Train loss=0.1658729612827301
[10/23] Train loss=0.181057870388031
[15/23] Train loss=0.16893090307712555
[20/23] Train loss=0.1519049108028412
Test set avg_accuracy=84.69% avg_sensitivity=64.26%, avg_specificity=91.19% avg_auc=87.94%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.174428 Test loss=0.373660 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.1635134220123291
[5/23] Train loss=0.16155236959457397
[10/23] Train loss=0.188694566488266
[15/23] Train loss=0.16591398417949677
[20/23] Train loss=0.15544408559799194
Test set avg_accuracy=84.99% avg_sensitivity=62.64%, avg_specificity=92.10% avg_auc=88.07%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.174300 Test loss=0.364153 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.16198651492595673
[5/23] Train loss=0.16603684425354004
[10/23] Train loss=0.18618488311767578
[15/23] Train loss=0.16548249125480652
[20/23] Train loss=0.15239544212818146
Test set avg_accuracy=84.58% avg_sensitivity=65.66%, avg_specificity=90.61% avg_auc=88.41%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.173847 Test loss=0.362503 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.1615518480539322
[5/23] Train loss=0.15742391347885132
[10/23] Train loss=0.18257182836532593
[15/23] Train loss=0.16095516085624695
[20/23] Train loss=0.14909999072551727
Test set avg_accuracy=85.42% avg_sensitivity=61.56%, avg_specificity=93.01% avg_auc=87.58%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.172197 Test loss=0.362487 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.1564817577600479
[5/23] Train loss=0.1591573804616928
[10/23] Train loss=0.18005156517028809
[15/23] Train loss=0.16022807359695435
[20/23] Train loss=0.15154360234737396
Test set avg_accuracy=85.69% avg_sensitivity=60.54%, avg_specificity=93.70% avg_auc=87.96%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.169788 Test loss=0.357632 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.15632538497447968
[5/23] Train loss=0.16121944785118103
[10/23] Train loss=0.1743890345096588
[15/23] Train loss=0.15366020798683167
[20/23] Train loss=0.14906145632266998
Test set avg_accuracy=85.78% avg_sensitivity=62.64%, avg_specificity=93.15% avg_auc=88.90%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.170199 Test loss=0.355535 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.1574823409318924
[5/23] Train loss=0.15895503759384155
[10/23] Train loss=0.18358896672725677
[15/23] Train loss=0.15589185059070587
[20/23] Train loss=0.15213152766227722
Test set avg_accuracy=85.59% avg_sensitivity=64.31%, avg_specificity=92.36% avg_auc=89.29%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.169553 Test loss=0.351433 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.15841728448867798
[5/23] Train loss=0.15592607855796814
[10/23] Train loss=0.18112030625343323
[15/23] Train loss=0.1528920829296112
[20/23] Train loss=0.14915338158607483
Test set avg_accuracy=85.95% avg_sensitivity=60.65%, avg_specificity=94.01% avg_auc=88.78%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.169335 Test loss=0.355772 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.15849906206130981
[5/23] Train loss=0.16550597548484802
[10/23] Train loss=0.1782437115907669
[15/23] Train loss=0.15302875638008118
[20/23] Train loss=0.14848938584327698
Test set avg_accuracy=85.26% avg_sensitivity=63.67%, avg_specificity=92.14% avg_auc=89.70%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.167334 Test loss=0.354648 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.1614464521408081
[5/23] Train loss=0.15543264150619507
[10/23] Train loss=0.18000225722789764
[15/23] Train loss=0.16147933900356293
[20/23] Train loss=0.14410093426704407
Test set avg_accuracy=85.61% avg_sensitivity=65.44%, avg_specificity=92.03% avg_auc=89.80%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.167064 Test loss=0.349602 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.15577150881290436
[5/23] Train loss=0.15305885672569275
[10/23] Train loss=0.17113463580608368
[15/23] Train loss=0.15429888665676117
[20/23] Train loss=0.1430661976337433
Test set avg_accuracy=86.05% avg_sensitivity=65.23%, avg_specificity=92.69% avg_auc=89.67%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.165141 Test loss=0.346299 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.15591514110565186
[5/23] Train loss=0.15499606728553772
[10/23] Train loss=0.17400552332401276
[15/23] Train loss=0.1465199738740921
[20/23] Train loss=0.14520269632339478
Test set avg_accuracy=85.43% avg_sensitivity=66.52%, avg_specificity=91.45% avg_auc=89.86%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.163082 Test loss=0.346924 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.1554044783115387
[5/23] Train loss=0.14869950711727142
[10/23] Train loss=0.17107225954532623
[15/23] Train loss=0.15529729425907135
[20/23] Train loss=0.14201202988624573
Test set avg_accuracy=85.34% avg_sensitivity=65.98%, avg_specificity=91.50% avg_auc=89.39%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.162218 Test loss=0.356627 Current lr=[0.000112073915556435]

[0/23] Train loss=0.15177515149116516
[5/23] Train loss=0.15223504602909088
[10/23] Train loss=0.16996674239635468
[15/23] Train loss=0.1518787294626236
[20/23] Train loss=0.1485453099012375
Test set avg_accuracy=85.48% avg_sensitivity=62.37%, avg_specificity=92.84% avg_auc=88.88%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.161911 Test loss=0.360046 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.14673054218292236
[5/23] Train loss=0.14623405039310455
[10/23] Train loss=0.17513176798820496
[15/23] Train loss=0.14300258457660675
[20/23] Train loss=0.1426982581615448
Test set avg_accuracy=85.55% avg_sensitivity=64.69%, avg_specificity=92.19% avg_auc=88.67%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.160102 Test loss=0.358104 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.1507391333580017
[5/23] Train loss=0.14907239377498627
[10/23] Train loss=0.16989727318286896
[15/23] Train loss=0.14430199563503265
[20/23] Train loss=0.1426657885313034
Test set avg_accuracy=85.27% avg_sensitivity=59.84%, avg_specificity=93.37% avg_auc=88.15%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.159785 Test loss=0.364580 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.15063518285751343
[5/23] Train loss=0.15289586782455444
[10/23] Train loss=0.17391526699066162
[15/23] Train loss=0.15317587554454803
[20/23] Train loss=0.1389744132757187
Test set avg_accuracy=85.33% avg_sensitivity=55.63%, avg_specificity=94.78% avg_auc=86.59%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.159984 Test loss=0.377748 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.14809753000736237
[5/23] Train loss=0.14536823332309723
[10/23] Train loss=0.170878067612648
[15/23] Train loss=0.14201140403747559
[20/23] Train loss=0.1400795727968216
Test set avg_accuracy=85.16% avg_sensitivity=58.01%, avg_specificity=93.80% avg_auc=88.33%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.157327 Test loss=0.361870 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.1469619870185852
[5/23] Train loss=0.15062199532985687
[10/23] Train loss=0.17125464975833893
[15/23] Train loss=0.14339400827884674
[20/23] Train loss=0.1407555639743805
Test set avg_accuracy=85.79% avg_sensitivity=59.68%, avg_specificity=94.11% avg_auc=88.68%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.157390 Test loss=0.355069 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.14676448702812195
[5/23] Train loss=0.14079733192920685
[10/23] Train loss=0.165510892868042
[15/23] Train loss=0.1406887322664261
[20/23] Train loss=0.14048795402050018
Test set avg_accuracy=85.56% avg_sensitivity=65.01%, avg_specificity=92.10% avg_auc=88.85%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.155220 Test loss=0.361006 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.14609327912330627
[5/23] Train loss=0.14027583599090576
[10/23] Train loss=0.16952340304851532
[15/23] Train loss=0.14528337121009827
[20/23] Train loss=0.14375461637973785
Test set avg_accuracy=83.82% avg_sensitivity=64.96%, avg_specificity=89.82% avg_auc=87.04%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.155239 Test loss=0.397301 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.14978797733783722
[5/23] Train loss=0.1435261219739914
[10/23] Train loss=0.16494102776050568
[15/23] Train loss=0.1467096358537674
[20/23] Train loss=0.13794536888599396
Test set avg_accuracy=84.35% avg_sensitivity=66.04%, avg_specificity=90.18% avg_auc=88.76%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.155284 Test loss=0.373607 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.1493282914161682
[5/23] Train loss=0.14600710570812225
[10/23] Train loss=0.15785816311836243
[15/23] Train loss=0.1428501009941101
[20/23] Train loss=0.13922660052776337
Test set avg_accuracy=84.96% avg_sensitivity=65.28%, avg_specificity=91.23% avg_auc=89.04%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.151561 Test loss=0.360811 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.14271558821201324
[5/23] Train loss=0.1377546489238739
[10/23] Train loss=0.16266673803329468
[15/23] Train loss=0.1442255675792694
[20/23] Train loss=0.13460791110992432
Test set avg_accuracy=85.01% avg_sensitivity=60.92%, avg_specificity=92.69% avg_auc=88.21%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.150873 Test loss=0.363058 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.14399109780788422
[5/23] Train loss=0.13784927129745483
[10/23] Train loss=0.16503366827964783
[15/23] Train loss=0.14040866494178772
[20/23] Train loss=0.1351005584001541
Test set avg_accuracy=84.70% avg_sensitivity=66.20%, avg_specificity=90.59% avg_auc=88.60%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.150073 Test loss=0.364275 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.14432542026042938
[5/23] Train loss=0.1367274969816208
[10/23] Train loss=0.16215214133262634
[15/23] Train loss=0.13535036146640778
[20/23] Train loss=0.130824476480484
Test set avg_accuracy=84.57% avg_sensitivity=68.41%, avg_specificity=89.72% avg_auc=89.27%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.148098 Test loss=0.360836 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.13633498549461365
[5/23] Train loss=0.1342448741197586
[10/23] Train loss=0.1523798257112503
[15/23] Train loss=0.1393684446811676
[20/23] Train loss=0.12848377227783203
Test set avg_accuracy=84.86% avg_sensitivity=64.91%, avg_specificity=91.21% avg_auc=88.40%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.145986 Test loss=0.364442 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.13663193583488464
[5/23] Train loss=0.1357942521572113
[10/23] Train loss=0.15616475045681
[15/23] Train loss=0.14069123566150665
[20/23] Train loss=0.12556946277618408
Test set avg_accuracy=85.46% avg_sensitivity=64.37%, avg_specificity=92.17% avg_auc=88.86%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.145930 Test loss=0.353867 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.13698497414588928
[5/23] Train loss=0.13485105335712433
[10/23] Train loss=0.15151646733283997
[15/23] Train loss=0.13284921646118164
[20/23] Train loss=0.1285102665424347
Test set avg_accuracy=85.33% avg_sensitivity=66.31%, avg_specificity=91.38% avg_auc=88.70%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.144234 Test loss=0.357865 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.13546855747699738
[5/23] Train loss=0.13304555416107178
[10/23] Train loss=0.15106713771820068
[15/23] Train loss=0.12988217175006866
[20/23] Train loss=0.12468617409467697
Test set avg_accuracy=85.40% avg_sensitivity=67.33%, avg_specificity=91.16% avg_auc=88.94%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.142677 Test loss=0.353650 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.13401111960411072
[5/23] Train loss=0.12720216810703278
[10/23] Train loss=0.14709793031215668
[15/23] Train loss=0.12952332198619843
[20/23] Train loss=0.12371277064085007
Test set avg_accuracy=85.49% avg_sensitivity=69.11%, avg_specificity=90.71% avg_auc=89.22%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.140353 Test loss=0.354211 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.13675366342067719
[5/23] Train loss=0.12829379737377167
[10/23] Train loss=0.14863266050815582
[15/23] Train loss=0.12723134458065033
[20/23] Train loss=0.1199413612484932
Test set avg_accuracy=85.40% avg_sensitivity=65.28%, avg_specificity=91.81% avg_auc=88.73%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.139091 Test loss=0.353861 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.13237881660461426
[5/23] Train loss=0.12926703691482544
[10/23] Train loss=0.14739403128623962
[15/23] Train loss=0.12673678994178772
[20/23] Train loss=0.12261499464511871
Test set avg_accuracy=85.31% avg_sensitivity=66.63%, avg_specificity=91.26% avg_auc=89.16%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.138258 Test loss=0.349506 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.1322556585073471
[5/23] Train loss=0.12572041153907776
[10/23] Train loss=0.1471703201532364
[15/23] Train loss=0.12353985011577606
[20/23] Train loss=0.1208709180355072
Test set avg_accuracy=85.22% avg_sensitivity=67.28%, avg_specificity=90.94% avg_auc=88.89%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.137249 Test loss=0.356593 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.13122586905956268
[5/23] Train loss=0.12943418323993683
[10/23] Train loss=0.14662468433380127
[15/23] Train loss=0.12477786093950272
[20/23] Train loss=0.12187055498361588
Test set avg_accuracy=85.26% avg_sensitivity=64.91%, avg_specificity=91.74% avg_auc=88.55%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.136661 Test loss=0.355392 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.13136249780654907
[5/23] Train loss=0.12596115469932556
[10/23] Train loss=0.14307032525539398
[15/23] Train loss=0.12290642410516739
[20/23] Train loss=0.1206716001033783
Test set avg_accuracy=84.96% avg_sensitivity=67.55%, avg_specificity=90.51% avg_auc=88.78%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.136378 Test loss=0.359992 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.12972936034202576
[5/23] Train loss=0.12668806314468384
[10/23] Train loss=0.14612522721290588
[15/23] Train loss=0.12456934154033661
[20/23] Train loss=0.12181089073419571
Test set avg_accuracy=85.46% avg_sensitivity=67.33%, avg_specificity=91.23% avg_auc=88.96%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.136578 Test loss=0.355271 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.12707656621932983
[5/23] Train loss=0.12761704623699188
[10/23] Train loss=0.14364731311798096
[15/23] Train loss=0.12308768182992935
[20/23] Train loss=0.11806133389472961
Test set avg_accuracy=85.30% avg_sensitivity=65.50%, avg_specificity=91.61% avg_auc=88.56%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.135189 Test loss=0.356886 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.12788546085357666
[5/23] Train loss=0.12416910380125046
[10/23] Train loss=0.14503803849220276
[15/23] Train loss=0.1237281784415245
[20/23] Train loss=0.12072747945785522
Test set avg_accuracy=85.25% avg_sensitivity=67.92%, avg_specificity=90.76% avg_auc=88.82%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.134693 Test loss=0.356475 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.12596645951271057
[5/23] Train loss=0.1234295591711998
[10/23] Train loss=0.1386934369802475
[15/23] Train loss=0.12410571426153183
[20/23] Train loss=0.12083236873149872
Test set avg_accuracy=85.29% avg_sensitivity=66.85%, avg_specificity=91.16% avg_auc=88.61%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.134334 Test loss=0.355824 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.12792299687862396
[5/23] Train loss=0.12493401020765305
[10/23] Train loss=0.13794264197349548
[15/23] Train loss=0.12269211560487747
[20/23] Train loss=0.11845263093709946
Test set avg_accuracy=85.27% avg_sensitivity=66.79%, avg_specificity=91.16% avg_auc=88.72%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.133633 Test loss=0.356337 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.1262182742357254
[5/23] Train loss=0.12564045190811157
[10/23] Train loss=0.1394743174314499
[15/23] Train loss=0.12354791164398193
[20/23] Train loss=0.11968325078487396
Test set avg_accuracy=85.33% avg_sensitivity=66.58%, avg_specificity=91.30% avg_auc=88.88%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.133532 Test loss=0.355053 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.12523703277111053
[5/23] Train loss=0.12464961409568787
[10/23] Train loss=0.13849946856498718
[15/23] Train loss=0.12378854304552078
[20/23] Train loss=0.12015058845281601
Test set avg_accuracy=85.34% avg_sensitivity=67.01%, avg_specificity=91.18% avg_auc=88.91%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.133521 Test loss=0.355551 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.12672463059425354
[5/23] Train loss=0.12393899261951447
[10/23] Train loss=0.14257314801216125
[15/23] Train loss=0.12286829948425293
[20/23] Train loss=0.11837673932313919
Test set avg_accuracy=85.25% avg_sensitivity=66.79%, avg_specificity=91.12% avg_auc=88.66%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.133861 Test loss=0.359820 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.12882283329963684
[5/23] Train loss=0.1231430247426033
[10/23] Train loss=0.1412830352783203
[15/23] Train loss=0.12164191901683807
[20/23] Train loss=0.11738765239715576
Test set avg_accuracy=85.26% avg_sensitivity=65.61%, avg_specificity=91.52% avg_auc=88.65%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.133057 Test loss=0.358719 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.1270119547843933
[5/23] Train loss=0.12206099182367325
[10/23] Train loss=0.13899372518062592
[15/23] Train loss=0.12170963734388351
[20/23] Train loss=0.11886479705572128
Test set avg_accuracy=85.29% avg_sensitivity=65.77%, avg_specificity=91.50% avg_auc=88.68%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.132975 Test loss=0.357122 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.12670548260211945
[5/23] Train loss=0.12421292066574097
[10/23] Train loss=0.13855348527431488
[15/23] Train loss=0.12077710032463074
[20/23] Train loss=0.11848380416631699
Test set avg_accuracy=85.35% avg_sensitivity=66.63%, avg_specificity=91.31% avg_auc=88.56%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.132977 Test loss=0.358376 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.1261356920003891
[5/23] Train loss=0.12105190008878708
[10/23] Train loss=0.14089041948318481
[15/23] Train loss=0.12050006538629532
[20/23] Train loss=0.11713269352912903
Test set avg_accuracy=85.44% avg_sensitivity=66.63%, avg_specificity=91.43% avg_auc=88.58%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.132506 Test loss=0.358071 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.1259974241256714
[5/23] Train loss=0.12265551835298538
[10/23] Train loss=0.13526087999343872
[15/23] Train loss=0.12216702848672867
[20/23] Train loss=0.1195296198129654
Test set avg_accuracy=85.31% avg_sensitivity=66.90%, avg_specificity=91.18% avg_auc=88.68%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.132918 Test loss=0.357746 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.12434420734643936
[5/23] Train loss=0.12368476390838623
[10/23] Train loss=0.13612622022628784
[15/23] Train loss=0.12385726720094681
[20/23] Train loss=0.11778105795383453
Test set avg_accuracy=85.44% avg_sensitivity=67.49%, avg_specificity=91.16% avg_auc=88.69%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.132233 Test loss=0.357729 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.12549754977226257
[5/23] Train loss=0.12134881317615509
[10/23] Train loss=0.14090527594089508
[15/23] Train loss=0.12205737829208374
[20/23] Train loss=0.11787652224302292
Test set avg_accuracy=85.31% avg_sensitivity=67.06%, avg_specificity=91.12% avg_auc=88.68%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.132267 Test loss=0.357859 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.12550760805606842
[5/23] Train loss=0.12039913237094879
[10/23] Train loss=0.14375175535678864
[15/23] Train loss=0.12050359696149826
[20/23] Train loss=0.11677008122205734
Test set avg_accuracy=85.27% avg_sensitivity=66.95%, avg_specificity=91.11% avg_auc=88.68%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.132597 Test loss=0.357957 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.12561288475990295
[5/23] Train loss=0.12101135402917862
[10/23] Train loss=0.13776575028896332
[15/23] Train loss=0.1225624606013298
[20/23] Train loss=0.11899235844612122
Test set avg_accuracy=85.31% avg_sensitivity=66.74%, avg_specificity=91.23% avg_auc=88.70%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.132582 Test loss=0.357834 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.12644997239112854
[5/23] Train loss=0.12188473343849182
[10/23] Train loss=0.13906830549240112
[15/23] Train loss=0.12143782526254654
[20/23] Train loss=0.11789596080780029
Test set avg_accuracy=85.34% avg_sensitivity=66.63%, avg_specificity=91.30% avg_auc=88.69%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.132125 Test loss=0.357984 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.1264810860157013
[5/23] Train loss=0.12187141925096512
[10/23] Train loss=0.13769224286079407
[15/23] Train loss=0.12139346450567245
[20/23] Train loss=0.11626090854406357
Test set avg_accuracy=85.35% avg_sensitivity=66.74%, avg_specificity=91.28% avg_auc=88.67%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.132248 Test loss=0.358232 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.12387658655643463
[5/23] Train loss=0.12148980051279068
[10/23] Train loss=0.13569501042366028
[15/23] Train loss=0.12137942761182785
[20/23] Train loss=0.11647576093673706
Test set avg_accuracy=85.38% avg_sensitivity=66.90%, avg_specificity=91.26% avg_auc=88.69%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.132025 Test loss=0.358115 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.12451399862766266
[5/23] Train loss=0.12334813177585602
[10/23] Train loss=0.138673335313797
[15/23] Train loss=0.12126384675502777
[20/23] Train loss=0.1171717569231987
Test set avg_accuracy=85.40% avg_sensitivity=66.68%, avg_specificity=91.36% avg_auc=88.66%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.131938 Test loss=0.358062 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=86.52% sen=71.00%, spe=91.47%, auc=91.33%!
Fold[9] Avg_overlap=0.64%(±0.2585617678836121)
[0/24] Train loss=0.7402830123901367
[5/24] Train loss=0.7508142590522766
[10/24] Train loss=0.756596565246582
[15/24] Train loss=0.7426266074180603
[20/24] Train loss=0.7402546405792236
Test set avg_accuracy=52.10% avg_sensitivity=48.96%, avg_specificity=53.01% avg_auc=53.38%
Best model saved!! Metric=-118.56478097097218!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.745352 Test loss=0.697170 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7224293351173401
[5/24] Train loss=0.7275719046592712
[10/24] Train loss=0.7350168824195862
[15/24] Train loss=0.7305396199226379
[20/24] Train loss=0.7256215810775757
Test set avg_accuracy=62.03% avg_sensitivity=42.06%, avg_specificity=67.82% avg_auc=56.46%
Best model saved!! Metric=-97.62842979305225!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.728021 Test loss=0.674407 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7130648493766785
[5/24] Train loss=0.7122959494590759
[10/24] Train loss=0.7211900353431702
[15/24] Train loss=0.7088873982429504
[20/24] Train loss=0.7108057737350464
Test set avg_accuracy=65.55% avg_sensitivity=40.50%, avg_specificity=72.81% avg_auc=59.62%
Best model saved!! Metric=-87.52888854990424!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.712990 Test loss=0.654308 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6965979337692261
[5/24] Train loss=0.6928351521492004
[10/24] Train loss=0.7038727402687073
[15/24] Train loss=0.6908378601074219
[20/24] Train loss=0.6843612790107727
Test set avg_accuracy=68.87% avg_sensitivity=42.82%, avg_specificity=76.42% avg_auc=63.58%
Best model saved!! Metric=-74.3130989058983!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.693584 Test loss=0.629078 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6657461524009705
[5/24] Train loss=0.6742199063301086
[10/24] Train loss=0.681106686592102
[15/24] Train loss=0.6708033680915833
[20/24] Train loss=0.6676838397979736
Test set avg_accuracy=71.51% avg_sensitivity=43.68%, avg_specificity=79.58% avg_auc=67.26%
Best model saved!! Metric=-63.96531091804907!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.675121 Test loss=0.600713 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6521352529525757
[5/24] Train loss=0.649116575717926
[10/24] Train loss=0.6625038385391235
[15/24] Train loss=0.6450225114822388
[20/24] Train loss=0.6460786461830139
Test set avg_accuracy=74.04% avg_sensitivity=47.74%, avg_specificity=81.66% avg_auc=70.76%
Best model saved!! Metric=-51.80020949973682!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.652055 Test loss=0.572137 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6203557848930359
[5/24] Train loss=0.6273126006126404
[10/24] Train loss=0.6387805342674255
[15/24] Train loss=0.6235750913619995
[20/24] Train loss=0.6216575503349304
Test set avg_accuracy=77.20% avg_sensitivity=49.25%, avg_specificity=85.30% avg_auc=74.49%
Best model saved!! Metric=-39.763108785945576!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.626002 Test loss=0.538525 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5880656838417053
[5/24] Train loss=0.5995301604270935
[10/24] Train loss=0.6103549599647522
[15/24] Train loss=0.5877535343170166
[20/24] Train loss=0.5887501835823059
Test set avg_accuracy=79.60% avg_sensitivity=51.91%, avg_specificity=87.62% avg_auc=77.81%
Best model saved!! Metric=-29.06133119320514!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.597571 Test loss=0.504324 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5614759922027588
[5/24] Train loss=0.5739481449127197
[10/24] Train loss=0.5805714130401611
[15/24] Train loss=0.5637697577476501
[20/24] Train loss=0.5572512149810791
Test set avg_accuracy=80.94% avg_sensitivity=54.98%, avg_specificity=88.46% avg_auc=79.96%
Best model saved!! Metric=-21.65798815931801!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.570525 Test loss=0.473374 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5244098901748657
[5/24] Train loss=0.5530310869216919
[10/24] Train loss=0.5551696419715881
[15/24] Train loss=0.5430358052253723
[20/24] Train loss=0.5310364961624146
Test set avg_accuracy=81.50% avg_sensitivity=55.97%, avg_specificity=88.90% avg_auc=81.19%
Best model saved!! Metric=-18.442823133944188!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.545832 Test loss=0.453919 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.502899169921875
[5/24] Train loss=0.5242469906806946
[10/24] Train loss=0.5320753455162048
[15/24] Train loss=0.5180583000183105
[20/24] Train loss=0.5101886987686157
Test set avg_accuracy=81.72% avg_sensitivity=55.56%, avg_specificity=89.30% avg_auc=82.72%
Best model saved!! Metric=-16.695999074694313!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.522713 Test loss=0.432415 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.48088717460632324
[5/24] Train loss=0.5101335048675537
[10/24] Train loss=0.5119155049324036
[15/24] Train loss=0.5017160773277283
[20/24] Train loss=0.4985559284687042
Test set avg_accuracy=82.17% avg_sensitivity=57.07%, avg_specificity=89.45% avg_auc=83.68%
Best model saved!! Metric=-13.62073722972265!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.504099 Test loss=0.416984 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.46041199564933777
[5/24] Train loss=0.4914155602455139
[10/24] Train loss=0.49802476167678833
[15/24] Train loss=0.48617905378341675
[20/24] Train loss=0.4769696295261383
Test set avg_accuracy=82.63% avg_sensitivity=56.14%, avg_specificity=90.31% avg_auc=84.33%
Best model saved!! Metric=-12.588188133047964!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.486265 Test loss=0.403846 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.43906745314598083
[5/24] Train loss=0.47678130865097046
[10/24] Train loss=0.47542569041252136
[15/24] Train loss=0.4685612618923187
[20/24] Train loss=0.4569794535636902
Test set avg_accuracy=82.96% avg_sensitivity=55.21%, avg_specificity=91.00% avg_auc=84.80%
Best model saved!! Metric=-12.035038600584052!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.470599 Test loss=0.392763 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.4290650188922882
[5/24] Train loss=0.45539405941963196
[10/24] Train loss=0.46635422110557556
[15/24] Train loss=0.45397716760635376
[20/24] Train loss=0.447464257478714
Test set avg_accuracy=83.66% avg_sensitivity=57.47%, avg_specificity=91.25% avg_auc=86.43%
Best model saved!! Metric=-7.190637941815872!!
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.456327 Test loss=0.378212 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4153178632259369
[5/24] Train loss=0.44860517978668213
[10/24] Train loss=0.44938328862190247
[15/24] Train loss=0.44482460618019104
[20/24] Train loss=0.43669673800468445
Test set avg_accuracy=84.09% avg_sensitivity=57.36%, avg_specificity=91.84% avg_auc=86.96%
Best model saved!! Metric=-5.751536242339071!!
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.443747 Test loss=0.368288 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3958255350589752
[5/24] Train loss=0.4365852177143097
[10/24] Train loss=0.4388512670993805
[15/24] Train loss=0.43085336685180664
[20/24] Train loss=0.42606887221336365
Test set avg_accuracy=84.47% avg_sensitivity=53.65%, avg_specificity=93.40% avg_auc=87.17%
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.431251 Test loss=0.361869 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3929569125175476
[5/24] Train loss=0.43148285150527954
[10/24] Train loss=0.42719802260398865
[15/24] Train loss=0.42327558994293213
[20/24] Train loss=0.4122123122215271
Test set avg_accuracy=84.58% avg_sensitivity=57.18%, avg_specificity=92.53% avg_auc=87.88%
Best model saved!! Metric=-3.8277705683057874!!
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.422755 Test loss=0.353695 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.38339686393737793
[5/24] Train loss=0.42247921228408813
[10/24] Train loss=0.4141540825366974
[15/24] Train loss=0.4106307029724121
[20/24] Train loss=0.40249139070510864
Test set avg_accuracy=85.21% avg_sensitivity=57.42%, avg_specificity=93.27% avg_auc=88.57%
Best model saved!! Metric=-1.539205445041297!!
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.412515 Test loss=0.344218 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3747120201587677
[5/24] Train loss=0.417331725358963
[10/24] Train loss=0.4110424220561981
[15/24] Train loss=0.40757858753204346
[20/24] Train loss=0.39817696809768677
Test set avg_accuracy=85.36% avg_sensitivity=61.01%, avg_specificity=92.43% avg_auc=88.81%
Best model saved!! Metric=1.6041548882944738!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.404775 Test loss=0.341915 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3627263307571411
[5/24] Train loss=0.4047531485557556
[10/24] Train loss=0.4003184139728546
[15/24] Train loss=0.39368394017219543
[20/24] Train loss=0.3874646723270416
Test set avg_accuracy=84.04% avg_sensitivity=67.73%, avg_specificity=88.76% avg_auc=88.77%
Best model saved!! Metric=3.3004093428302212!!
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.395581 Test loss=0.351640 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.35788434743881226
[5/24] Train loss=0.3942455053329468
[10/24] Train loss=0.3925544023513794
[15/24] Train loss=0.3888372480869293
[20/24] Train loss=0.37727707624435425
Test set avg_accuracy=85.73% avg_sensitivity=62.92%, avg_specificity=92.34% avg_auc=89.61%
Best model saved!! Metric=4.602035174590107!!
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.389618 Test loss=0.331868 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.34761252999305725
[5/24] Train loss=0.3876025974750519
[10/24] Train loss=0.3849899172782898
[15/24] Train loss=0.37843263149261475
[20/24] Train loss=0.37377652525901794
Test set avg_accuracy=85.68% avg_sensitivity=64.08%, avg_specificity=91.94% avg_auc=89.68%
Best model saved!! Metric=5.377185234700747!!
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.381010 Test loss=0.328865 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3434227406978607
[5/24] Train loss=0.3790018856525421
[10/24] Train loss=0.3739687204360962
[15/24] Train loss=0.36195072531700134
[20/24] Train loss=0.35847729444503784
Test set avg_accuracy=86.32% avg_sensitivity=61.76%, avg_specificity=93.43% avg_auc=90.13%
Best model saved!! Metric=5.642286181269952!!
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.371553 Test loss=0.321099 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3342307209968567
[5/24] Train loss=0.36647939682006836
[10/24] Train loss=0.3731967806816101
[15/24] Train loss=0.36228668689727783
[20/24] Train loss=0.35418593883514404
Test set avg_accuracy=86.52% avg_sensitivity=63.15%, avg_specificity=93.30% avg_auc=90.66%
Best model saved!! Metric=7.636389405123516!!
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.365660 Test loss=0.314614 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3253101408481598
[5/24] Train loss=0.3623622953891754
[10/24] Train loss=0.36291491985321045
[15/24] Train loss=0.3531261682510376
[20/24] Train loss=0.35046127438545227
Test set avg_accuracy=86.94% avg_sensitivity=61.01%, avg_specificity=94.46% avg_auc=90.42%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.359734 Test loss=0.314914 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.32069215178489685
[5/24] Train loss=0.3542362451553345
[10/24] Train loss=0.3588124215602875
[15/24] Train loss=0.34834474325180054
[20/24] Train loss=0.3351380527019501
Test set avg_accuracy=86.72% avg_sensitivity=55.10%, avg_specificity=95.89% avg_auc=90.58%
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.353285 Test loss=0.315355 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3184259831905365
[5/24] Train loss=0.349730521440506
[10/24] Train loss=0.3624473810195923
[15/24] Train loss=0.34400466084480286
[20/24] Train loss=0.33983588218688965
Test set avg_accuracy=86.18% avg_sensitivity=47.51%, avg_specificity=97.40% avg_auc=90.61%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.347790 Test loss=0.326803 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3100159466266632
[5/24] Train loss=0.3510202467441559
[10/24] Train loss=0.351529598236084
[15/24] Train loss=0.33436280488967896
[20/24] Train loss=0.33203959465026855
Test set avg_accuracy=87.02% avg_sensitivity=52.95%, avg_specificity=96.89% avg_auc=90.46%
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.341972 Test loss=0.318213 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3053818643093109
[5/24] Train loss=0.3522648811340332
[10/24] Train loss=0.3462621867656708
[15/24] Train loss=0.32660600543022156
[20/24] Train loss=0.3193107843399048
Test set avg_accuracy=85.43% avg_sensitivity=41.43%, avg_specificity=98.19% avg_auc=88.75%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.336808 Test loss=0.354260 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3040502071380615
[5/24] Train loss=0.3495774269104004
[10/24] Train loss=0.3373797833919525
[15/24] Train loss=0.32996666431427
[20/24] Train loss=0.3227413296699524
Test set avg_accuracy=87.07% avg_sensitivity=53.36%, avg_specificity=96.84% avg_auc=90.95%
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.334674 Test loss=0.313091 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3082576096057892
[5/24] Train loss=0.34408310055732727
[10/24] Train loss=0.3355473279953003
[15/24] Train loss=0.3185700476169586
[20/24] Train loss=0.310762494802475
Test set avg_accuracy=86.16% avg_sensitivity=48.20%, avg_specificity=97.16% avg_auc=89.58%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.327110 Test loss=0.332466 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2991699278354645
[5/24] Train loss=0.33079156279563904
[10/24] Train loss=0.3387078046798706
[15/24] Train loss=0.320095956325531
[20/24] Train loss=0.30422988533973694
Test set avg_accuracy=86.03% avg_sensitivity=42.82%, avg_specificity=98.56% avg_auc=91.29%
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.327659 Test loss=0.331867 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.28982093930244446
[5/24] Train loss=0.31740278005599976
[10/24] Train loss=0.3272246718406677
[15/24] Train loss=0.32071661949157715
[20/24] Train loss=0.30632084608078003
Test set avg_accuracy=84.77% avg_sensitivity=35.05%, avg_specificity=99.18% avg_auc=89.91%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.321881 Test loss=0.368611 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.29673030972480774
[5/24] Train loss=0.3383742868900299
[10/24] Train loss=0.33160078525543213
[15/24] Train loss=0.3114526569843292
[20/24] Train loss=0.29667583107948303
Test set avg_accuracy=86.51% avg_sensitivity=47.45%, avg_specificity=97.83% avg_auc=90.20%
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.320063 Test loss=0.335208 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.28466373682022095
[5/24] Train loss=0.34044477343559265
[10/24] Train loss=0.3234369456768036
[15/24] Train loss=0.30288583040237427
[20/24] Train loss=0.2964532971382141
Test set avg_accuracy=87.76% avg_sensitivity=56.84%, avg_specificity=96.72% avg_auc=91.83%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.315657 Test loss=0.296445 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.28627875447273254
[5/24] Train loss=0.3181776702404022
[10/24] Train loss=0.3176986873149872
[15/24] Train loss=0.30315545201301575
[20/24] Train loss=0.29698464274406433
Test set avg_accuracy=87.32% avg_sensitivity=52.90%, avg_specificity=97.30% avg_auc=90.65%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.314903 Test loss=0.312086 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2893831133842468
[5/24] Train loss=0.30587583780288696
[10/24] Train loss=0.31044572591781616
[15/24] Train loss=0.30751264095306396
[20/24] Train loss=0.28576788306236267
Test set avg_accuracy=87.76% avg_sensitivity=57.76%, avg_specificity=96.46% avg_auc=91.65%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.310616 Test loss=0.295745 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.28838208317756653
[5/24] Train loss=0.3186412453651428
[10/24] Train loss=0.3097990155220032
[15/24] Train loss=0.31326720118522644
[20/24] Train loss=0.2819729745388031
Test set avg_accuracy=87.79% avg_sensitivity=61.01%, avg_specificity=95.55% avg_auc=91.93%
Best model saved!! Metric=10.27195023318663!!
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.305266 Test loss=0.288798 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2816031575202942
[5/24] Train loss=0.31783393025398254
[10/24] Train loss=0.30741164088249207
[15/24] Train loss=0.2940099835395813
[20/24] Train loss=0.2834433615207672
Test set avg_accuracy=87.47% avg_sensitivity=60.43%, avg_specificity=95.31% avg_auc=90.38%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.304527 Test loss=0.303922 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.2774655818939209
[5/24] Train loss=0.31955140829086304
[10/24] Train loss=0.3096785843372345
[15/24] Train loss=0.3117920160293579
[20/24] Train loss=0.2742815911769867
Test set avg_accuracy=87.08% avg_sensitivity=63.21%, avg_specificity=94.00% avg_auc=91.75%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.302126 Test loss=0.290598 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.28006619215011597
[5/24] Train loss=0.30793777108192444
[10/24] Train loss=0.30324217677116394
[15/24] Train loss=0.2912746071815491
[20/24] Train loss=0.2773057818412781
Test set avg_accuracy=87.76% avg_sensitivity=58.92%, avg_specificity=96.12% avg_auc=91.17%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.301984 Test loss=0.299477 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2806655466556549
[5/24] Train loss=0.30165380239486694
[10/24] Train loss=0.3009432852268219
[15/24] Train loss=0.29931604862213135
[20/24] Train loss=0.28800907731056213
Test set avg_accuracy=85.44% avg_sensitivity=39.51%, avg_specificity=98.76% avg_auc=89.49%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.296515 Test loss=0.363263 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.28477609157562256
[5/24] Train loss=0.302365243434906
[10/24] Train loss=0.30995216965675354
[15/24] Train loss=0.2911528944969177
[20/24] Train loss=0.27462291717529297
Test set avg_accuracy=88.09% avg_sensitivity=58.23%, avg_specificity=96.74% avg_auc=92.11%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.297082 Test loss=0.290050 Current lr=[0.00029967723776099]

[0/24] Train loss=0.28364431858062744
[5/24] Train loss=0.2961186170578003
[10/24] Train loss=0.3047164976596832
[15/24] Train loss=0.2897413671016693
[20/24] Train loss=0.27415329217910767
Test set avg_accuracy=86.68% avg_sensitivity=54.29%, avg_specificity=96.07% avg_auc=89.97%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.293042 Test loss=0.313761 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.276849627494812
[5/24] Train loss=0.29409894347190857
[10/24] Train loss=0.29570072889328003
[15/24] Train loss=0.291109174489975
[20/24] Train loss=0.2783374786376953
Test set avg_accuracy=88.09% avg_sensitivity=60.25%, avg_specificity=96.15% avg_auc=91.49%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.291699 Test loss=0.289934 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.27201953530311584
[5/24] Train loss=0.2944350838661194
[10/24] Train loss=0.2918555736541748
[15/24] Train loss=0.28707805275917053
[20/24] Train loss=0.27315059304237366
Test set avg_accuracy=87.47% avg_sensitivity=68.83%, avg_specificity=92.88% avg_auc=92.02%
Best model saved!! Metric=15.207292808418686!!
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.289306 Test loss=0.289915 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2621702551841736
[5/24] Train loss=0.3038991689682007
[10/24] Train loss=0.29111865162849426
[15/24] Train loss=0.2824612855911255
[20/24] Train loss=0.26071205735206604
Test set avg_accuracy=88.27% avg_sensitivity=62.28%, avg_specificity=95.80% avg_auc=92.48%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.285925 Test loss=0.279398 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.2657495439052582
[5/24] Train loss=0.29382574558258057
[10/24] Train loss=0.29487141966819763
[15/24] Train loss=0.2810651957988739
[20/24] Train loss=0.26025277376174927
Test set avg_accuracy=88.12% avg_sensitivity=62.92%, avg_specificity=95.43% avg_auc=91.78%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.284493 Test loss=0.288570 Current lr=[0.000298904600941902]

[0/24] Train loss=0.26035794615745544
[5/24] Train loss=0.2870199680328369
[10/24] Train loss=0.28501835465431213
[15/24] Train loss=0.2780390679836273
[20/24] Train loss=0.26407504081726074
Test set avg_accuracy=88.36% avg_sensitivity=63.96%, avg_specificity=95.43% avg_auc=92.53%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.281173 Test loss=0.277029 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2544668912887573
[5/24] Train loss=0.2980863153934479
[10/24] Train loss=0.27520453929901123
[15/24] Train loss=0.28052425384521484
[20/24] Train loss=0.259243369102478
Test set avg_accuracy=88.12% avg_sensitivity=61.36%, avg_specificity=95.89% avg_auc=92.04%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.276466 Test loss=0.286308 Current lr=[0.000297555943323901]

[0/24] Train loss=0.25683456659317017
[5/24] Train loss=0.28626832365989685
[10/24] Train loss=0.275115966796875
[15/24] Train loss=0.2704887390136719
[20/24] Train loss=0.24488700926303864
Test set avg_accuracy=88.11% avg_sensitivity=58.11%, avg_specificity=96.81% avg_auc=91.66%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.274438 Test loss=0.293813 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2440912276506424
[5/24] Train loss=0.2839285433292389
[10/24] Train loss=0.27399158477783203
[15/24] Train loss=0.27892524003982544
[20/24] Train loss=0.2661988139152527
Test set avg_accuracy=88.53% avg_sensitivity=71.84%, avg_specificity=93.37% avg_auc=93.10%
Best model saved!! Metric=20.832770425465114!!
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.275847 Test loss=0.274356 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.24989034235477448
[5/24] Train loss=0.2763032913208008
[10/24] Train loss=0.2801617383956909
[15/24] Train loss=0.2702619731426239
[20/24] Train loss=0.25773483514785767
Test set avg_accuracy=87.89% avg_sensitivity=54.52%, avg_specificity=97.56% avg_auc=91.13%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.272868 Test loss=0.303923 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.256239652633667
[5/24] Train loss=0.281421422958374
[10/24] Train loss=0.2863938510417938
[15/24] Train loss=0.26409414410591125
[20/24] Train loss=0.2500065267086029
Test set avg_accuracy=88.72% avg_sensitivity=62.92%, avg_specificity=96.20% avg_auc=92.61%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.273543 Test loss=0.278439 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.25073400139808655
[5/24] Train loss=0.29212382435798645
[10/24] Train loss=0.27353569865226746
[15/24] Train loss=0.2702265977859497
[20/24] Train loss=0.25713759660720825
Test set avg_accuracy=87.79% avg_sensitivity=53.65%, avg_specificity=97.68% avg_auc=91.55%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.271046 Test loss=0.307970 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.24837419390678406
[5/24] Train loss=0.27792415022850037
[10/24] Train loss=0.27882254123687744
[15/24] Train loss=0.25653883814811707
[20/24] Train loss=0.25595182180404663
Test set avg_accuracy=88.28% avg_sensitivity=62.17%, avg_specificity=95.85% avg_auc=91.70%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.267144 Test loss=0.288573 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2535170614719391
[5/24] Train loss=0.2809012234210968
[10/24] Train loss=0.27434417605400085
[15/24] Train loss=0.26324766874313354
[20/24] Train loss=0.24661804735660553
Test set avg_accuracy=88.07% avg_sensitivity=60.02%, avg_specificity=96.20% avg_auc=91.70%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.266381 Test loss=0.291526 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.25424835085868835
[5/24] Train loss=0.29159197211265564
[10/24] Train loss=0.2718770503997803
[15/24] Train loss=0.26509127020835876
[20/24] Train loss=0.24111433327198029
Test set avg_accuracy=87.37% avg_sensitivity=52.20%, avg_specificity=97.56% avg_auc=90.31%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.268898 Test loss=0.316895 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.25264957547187805
[5/24] Train loss=0.2773852050304413
[10/24] Train loss=0.2797449827194214
[15/24] Train loss=0.2544075548648834
[20/24] Train loss=0.24227605760097504
Test set avg_accuracy=87.58% avg_sensitivity=53.30%, avg_specificity=97.51% avg_auc=90.80%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.265617 Test loss=0.308595 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.25367623567581177
[5/24] Train loss=0.2674350142478943
[10/24] Train loss=0.2616051137447357
[15/24] Train loss=0.25609567761421204
[20/24] Train loss=0.25737398862838745
Test set avg_accuracy=87.10% avg_sensitivity=56.14%, avg_specificity=96.07% avg_auc=87.93%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.259415 Test loss=0.329668 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.23631025850772858
[5/24] Train loss=0.27514198422431946
[10/24] Train loss=0.24194391071796417
[15/24] Train loss=0.24946407973766327
[20/24] Train loss=0.23812898993492126
Test set avg_accuracy=87.70% avg_sensitivity=57.76%, avg_specificity=96.37% avg_auc=91.72%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.257338 Test loss=0.295299 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.23967543244361877
[5/24] Train loss=0.26431745290756226
[10/24] Train loss=0.25275740027427673
[15/24] Train loss=0.2556338310241699
[20/24] Train loss=0.25098660588264465
Test set avg_accuracy=87.34% avg_sensitivity=54.46%, avg_specificity=96.88% avg_auc=89.54%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.258394 Test loss=0.321600 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2351827174425125
[5/24] Train loss=0.26924797892570496
[10/24] Train loss=0.2615704834461212
[15/24] Train loss=0.2500019967556
[20/24] Train loss=0.23820990324020386
Test set avg_accuracy=88.62% avg_sensitivity=64.19%, avg_specificity=95.70% avg_auc=91.42%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.256604 Test loss=0.289893 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2347557544708252
[5/24] Train loss=0.27137643098831177
[10/24] Train loss=0.25242650508880615
[15/24] Train loss=0.24451108276844025
[20/24] Train loss=0.23597228527069092
Test set avg_accuracy=88.41% avg_sensitivity=63.96%, avg_specificity=95.50% avg_auc=91.54%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.252300 Test loss=0.286274 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.23550787568092346
[5/24] Train loss=0.2538566589355469
[10/24] Train loss=0.25052013993263245
[15/24] Train loss=0.2443486452102661
[20/24] Train loss=0.2388097196817398
Test set avg_accuracy=88.44% avg_sensitivity=66.74%, avg_specificity=94.73% avg_auc=91.93%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.251548 Test loss=0.282397 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.22968757152557373
[5/24] Train loss=0.24413806200027466
[10/24] Train loss=0.2589761018753052
[15/24] Train loss=0.25132179260253906
[20/24] Train loss=0.23895812034606934
Test set avg_accuracy=88.74% avg_sensitivity=66.92%, avg_specificity=95.06% avg_auc=92.98%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.248039 Test loss=0.273747 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.22095996141433716
[5/24] Train loss=0.26048213243484497
[10/24] Train loss=0.24449947476387024
[15/24] Train loss=0.23858430981636047
[20/24] Train loss=0.23522135615348816
Test set avg_accuracy=88.45% avg_sensitivity=70.63%, avg_specificity=93.62% avg_auc=92.50%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.246403 Test loss=0.277786 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.21964605152606964
[5/24] Train loss=0.23921141028404236
[10/24] Train loss=0.24727921187877655
[15/24] Train loss=0.22804130613803864
[20/24] Train loss=0.23911258578300476
Test set avg_accuracy=87.63% avg_sensitivity=71.61%, avg_specificity=92.27% avg_auc=92.20%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.246199 Test loss=0.288058 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.220360666513443
[5/24] Train loss=0.2574547827243805
[10/24] Train loss=0.24012134969234467
[15/24] Train loss=0.23593764007091522
[20/24] Train loss=0.22514769434928894
Test set avg_accuracy=88.45% avg_sensitivity=70.97%, avg_specificity=93.52% avg_auc=92.68%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.242954 Test loss=0.276700 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.22137290239334106
[5/24] Train loss=0.2394864559173584
[10/24] Train loss=0.24055145680904388
[15/24] Train loss=0.23327338695526123
[20/24] Train loss=0.23591728508472443
Test set avg_accuracy=87.49% avg_sensitivity=72.94%, avg_specificity=91.70% avg_auc=91.50%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.240759 Test loss=0.296999 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.220811128616333
[5/24] Train loss=0.24120791256427765
[10/24] Train loss=0.2589434087276459
[15/24] Train loss=0.22191122174263
[20/24] Train loss=0.23036298155784607
Test set avg_accuracy=87.88% avg_sensitivity=73.46%, avg_specificity=92.06% avg_auc=92.33%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.236493 Test loss=0.287512 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.21170981228351593
[5/24] Train loss=0.2420325130224228
[10/24] Train loss=0.2367406040430069
[15/24] Train loss=0.2298104465007782
[20/24] Train loss=0.21630534529685974
Test set avg_accuracy=87.54% avg_sensitivity=71.67%, avg_specificity=92.14% avg_auc=91.73%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.236320 Test loss=0.295216 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.23231491446495056
[5/24] Train loss=0.23575624823570251
[10/24] Train loss=0.252939373254776
[15/24] Train loss=0.22748827934265137
[20/24] Train loss=0.22795158624649048
Test set avg_accuracy=88.26% avg_sensitivity=67.50%, avg_specificity=94.27% avg_auc=91.04%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.233919 Test loss=0.293573 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.21105001866817474
[5/24] Train loss=0.22377339005470276
[10/24] Train loss=0.23050816357135773
[15/24] Train loss=0.22283723950386047
[20/24] Train loss=0.23540997505187988
Test set avg_accuracy=87.89% avg_sensitivity=71.21%, avg_specificity=92.73% avg_auc=90.80%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.230261 Test loss=0.301751 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.21850624680519104
[5/24] Train loss=0.2172446995973587
[10/24] Train loss=0.22699500620365143
[15/24] Train loss=0.2191004902124405
[20/24] Train loss=0.2087007313966751
Test set avg_accuracy=86.93% avg_sensitivity=73.52%, avg_specificity=90.81% avg_auc=91.56%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.228331 Test loss=0.303790 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.20662865042686462
[5/24] Train loss=0.22548775374889374
[10/24] Train loss=0.24012522399425507
[15/24] Train loss=0.23364025354385376
[20/24] Train loss=0.2305551916360855
Test set avg_accuracy=87.16% avg_sensitivity=71.03%, avg_specificity=91.84% avg_auc=91.25%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.234439 Test loss=0.302252 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2199593186378479
[5/24] Train loss=0.21899163722991943
[10/24] Train loss=0.2332637906074524
[15/24] Train loss=0.2212434560060501
[20/24] Train loss=0.2208995372056961
Test set avg_accuracy=88.02% avg_sensitivity=73.99%, avg_specificity=92.09% avg_auc=92.51%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.231408 Test loss=0.285852 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.21306179463863373
[5/24] Train loss=0.21982242166996002
[10/24] Train loss=0.2414691001176834
[15/24] Train loss=0.21718385815620422
[20/24] Train loss=0.22493420541286469
Test set avg_accuracy=88.18% avg_sensitivity=75.09%, avg_specificity=91.97% avg_auc=92.48%
Best model saved!! Metric=21.71719989323971!!
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.225907 Test loss=0.285981 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.22495636343955994
[5/24] Train loss=0.2302500456571579
[10/24] Train loss=0.2623473107814789
[15/24] Train loss=0.21845456957817078
[20/24] Train loss=0.22088395059108734
Test set avg_accuracy=84.41% avg_sensitivity=77.69%, avg_specificity=86.36% avg_auc=89.57%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.227825 Test loss=0.361319 Current lr=[0.000224838296036774]

[0/24] Train loss=0.21382580697536469
[5/24] Train loss=0.2245071828365326
[10/24] Train loss=0.23004908859729767
[15/24] Train loss=0.2297489494085312
[20/24] Train loss=0.2172987312078476
Test set avg_accuracy=88.02% avg_sensitivity=73.41%, avg_specificity=92.26% avg_auc=92.60%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.226741 Test loss=0.279731 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.20490364730358124
[5/24] Train loss=0.21142815053462982
[10/24] Train loss=0.22940048575401306
[15/24] Train loss=0.2183656543493271
[20/24] Train loss=0.21558406949043274
Test set avg_accuracy=87.42% avg_sensitivity=71.26%, avg_specificity=92.11% avg_auc=91.76%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.224036 Test loss=0.296449 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.21585287153720856
[5/24] Train loss=0.2115229219198227
[10/24] Train loss=0.21704229712486267
[15/24] Train loss=0.20660868287086487
[20/24] Train loss=0.21418587863445282
Test set avg_accuracy=87.86% avg_sensitivity=71.96%, avg_specificity=92.48% avg_auc=92.41%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.218773 Test loss=0.288055 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2050658017396927
[5/24] Train loss=0.20403814315795898
[10/24] Train loss=0.22222547233104706
[15/24] Train loss=0.20212143659591675
[20/24] Train loss=0.2134793996810913
Test set avg_accuracy=87.96% avg_sensitivity=66.22%, avg_specificity=94.26% avg_auc=91.38%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.217960 Test loss=0.297374 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.20859529078006744
[5/24] Train loss=0.20880793035030365
[10/24] Train loss=0.22251448035240173
[15/24] Train loss=0.20318889617919922
[20/24] Train loss=0.21128185093402863
Test set avg_accuracy=87.70% avg_sensitivity=65.53%, avg_specificity=94.12% avg_auc=91.67%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.217302 Test loss=0.298067 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2082846313714981
[5/24] Train loss=0.195702463388443
[10/24] Train loss=0.2126343697309494
[15/24] Train loss=0.19333285093307495
[20/24] Train loss=0.2054470181465149
Test set avg_accuracy=88.32% avg_sensitivity=69.99%, avg_specificity=93.63% avg_auc=91.07%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.206134 Test loss=0.292653 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1940152943134308
[5/24] Train loss=0.19640403985977173
[10/24] Train loss=0.20348483324050903
[15/24] Train loss=0.1894940733909607
[20/24] Train loss=0.20195399224758148
Test set avg_accuracy=87.38% avg_sensitivity=68.54%, avg_specificity=92.85% avg_auc=90.91%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.207386 Test loss=0.307342 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.19656166434288025
[5/24] Train loss=0.1946265548467636
[10/24] Train loss=0.21744124591350555
[15/24] Train loss=0.19906486570835114
[20/24] Train loss=0.20093956589698792
Test set avg_accuracy=86.78% avg_sensitivity=72.31%, avg_specificity=90.98% avg_auc=89.43%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.207990 Test loss=0.329882 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.20141170918941498
[5/24] Train loss=0.19604985415935516
[10/24] Train loss=0.2042723447084427
[15/24] Train loss=0.19818395376205444
[20/24] Train loss=0.20082806050777435
Test set avg_accuracy=87.49% avg_sensitivity=68.83%, avg_specificity=92.90% avg_auc=90.17%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.204762 Test loss=0.309076 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.19360995292663574
[5/24] Train loss=0.1854492574930191
[10/24] Train loss=0.20759345591068268
[15/24] Train loss=0.20619778335094452
[20/24] Train loss=0.19459760189056396
Test set avg_accuracy=88.01% avg_sensitivity=66.86%, avg_specificity=94.14% avg_auc=90.19%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.204003 Test loss=0.307481 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.19721095263957977
[5/24] Train loss=0.18130572140216827
[10/24] Train loss=0.20738504827022552
[15/24] Train loss=0.20361784100532532
[20/24] Train loss=0.19873273372650146
Test set avg_accuracy=87.79% avg_sensitivity=66.11%, avg_specificity=94.07% avg_auc=90.48%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.202849 Test loss=0.312131 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.18938077986240387
[5/24] Train loss=0.19878333806991577
[10/24] Train loss=0.20497284829616547
[15/24] Train loss=0.20339378714561462
[20/24] Train loss=0.20523127913475037
Test set avg_accuracy=86.48% avg_sensitivity=63.27%, avg_specificity=93.21% avg_auc=88.00%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.202676 Test loss=0.345132 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1962333768606186
[5/24] Train loss=0.1906910389661789
[10/24] Train loss=0.20463675260543823
[15/24] Train loss=0.1872577965259552
[20/24] Train loss=0.20019522309303284
Test set avg_accuracy=88.07% avg_sensitivity=68.77%, avg_specificity=93.67% avg_auc=90.81%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.200238 Test loss=0.305335 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.19597011804580688
[5/24] Train loss=0.19174647331237793
[10/24] Train loss=0.19965077936649323
[15/24] Train loss=0.19027739763259888
[20/24] Train loss=0.19068939983844757
Test set avg_accuracy=87.54% avg_sensitivity=63.09%, avg_specificity=94.63% avg_auc=89.52%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.198717 Test loss=0.321345 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.19890116155147552
[5/24] Train loss=0.1920795887708664
[10/24] Train loss=0.2034408301115036
[15/24] Train loss=0.1930752545595169
[20/24] Train loss=0.1987745314836502
Test set avg_accuracy=88.02% avg_sensitivity=62.75%, avg_specificity=95.35% avg_auc=89.73%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.195724 Test loss=0.315383 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.18798726797103882
[5/24] Train loss=0.18607057631015778
[10/24] Train loss=0.19129717350006104
[15/24] Train loss=0.1847730129957199
[20/24] Train loss=0.19324125349521637
Test set avg_accuracy=87.45% avg_sensitivity=63.79%, avg_specificity=94.31% avg_auc=90.70%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.195579 Test loss=0.307648 Current lr=[0.000156543481933168]

[0/24] Train loss=0.18615497648715973
[5/24] Train loss=0.1796843260526657
[10/24] Train loss=0.19097474217414856
[15/24] Train loss=0.19375427067279816
[20/24] Train loss=0.19021159410476685
Test set avg_accuracy=87.79% avg_sensitivity=65.87%, avg_specificity=94.14% avg_auc=89.95%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.195253 Test loss=0.313411 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1906237006187439
[5/24] Train loss=0.19204562902450562
[10/24] Train loss=0.18809166550636292
[15/24] Train loss=0.19373993575572968
[20/24] Train loss=0.1876276433467865
Test set avg_accuracy=87.54% avg_sensitivity=61.59%, avg_specificity=95.06% avg_auc=90.52%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.192177 Test loss=0.319768 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.1812009960412979
[5/24] Train loss=0.17726938426494598
[10/24] Train loss=0.19703811407089233
[15/24] Train loss=0.1975468397140503
[20/24] Train loss=0.1842777281999588
Test set avg_accuracy=87.64% avg_sensitivity=61.88%, avg_specificity=95.11% avg_auc=90.44%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.189571 Test loss=0.308550 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.17644177377223969
[5/24] Train loss=0.176911860704422
[10/24] Train loss=0.18406707048416138
[15/24] Train loss=0.19110919535160065
[20/24] Train loss=0.18924464285373688
Test set avg_accuracy=87.96% avg_sensitivity=64.37%, avg_specificity=94.79% avg_auc=91.36%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.189882 Test loss=0.300536 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.18890945613384247
[5/24] Train loss=0.17598848044872284
[10/24] Train loss=0.1916782408952713
[15/24] Train loss=0.17951107025146484
[20/24] Train loss=0.18530920147895813
Test set avg_accuracy=87.88% avg_sensitivity=61.47%, avg_specificity=95.53% avg_auc=90.08%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.188468 Test loss=0.312750 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1819227933883667
[5/24] Train loss=0.1798306256532669
[10/24] Train loss=0.18716590106487274
[15/24] Train loss=0.17708343267440796
[20/24] Train loss=0.18094198405742645
Test set avg_accuracy=87.93% avg_sensitivity=61.24%, avg_specificity=95.67% avg_auc=89.96%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.184769 Test loss=0.316730 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.1813252568244934
[5/24] Train loss=0.18836961686611176
[10/24] Train loss=0.18458203971385956
[15/24] Train loss=0.17721474170684814
[20/24] Train loss=0.18890053033828735
Test set avg_accuracy=87.84% avg_sensitivity=61.30%, avg_specificity=95.53% avg_auc=88.84%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.184387 Test loss=0.321584 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.17524993419647217
[5/24] Train loss=0.17821456491947174
[10/24] Train loss=0.19294987618923187
[15/24] Train loss=0.17592981457710266
[20/24] Train loss=0.17802031338214874
Test set avg_accuracy=86.74% avg_sensitivity=58.81%, avg_specificity=94.84% avg_auc=88.33%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.181751 Test loss=0.332889 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.18214736878871918
[5/24] Train loss=0.17685525119304657
[10/24] Train loss=0.18158093094825745
[15/24] Train loss=0.18099260330200195
[20/24] Train loss=0.179549902677536
Test set avg_accuracy=87.37% avg_sensitivity=65.41%, avg_specificity=93.74% avg_auc=88.23%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.179797 Test loss=0.327905 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.17586183547973633
[5/24] Train loss=0.17844785749912262
[10/24] Train loss=0.18977656960487366
[15/24] Train loss=0.17301276326179504
[20/24] Train loss=0.17462696135044098
Test set avg_accuracy=87.17% avg_sensitivity=65.70%, avg_specificity=93.40% avg_auc=89.75%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.179383 Test loss=0.314948 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.17749837040901184
[5/24] Train loss=0.17365427315235138
[10/24] Train loss=0.18650126457214355
[15/24] Train loss=0.16462558507919312
[20/24] Train loss=0.17565663158893585
Test set avg_accuracy=88.24% avg_sensitivity=65.87%, avg_specificity=94.73% avg_auc=90.43%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.178192 Test loss=0.302558 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.17593029141426086
[5/24] Train loss=0.17872241139411926
[10/24] Train loss=0.1813635677099228
[15/24] Train loss=0.17060372233390808
[20/24] Train loss=0.1806066483259201
Test set avg_accuracy=88.03% avg_sensitivity=64.72%, avg_specificity=94.79% avg_auc=89.60%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.177099 Test loss=0.317025 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.17632558941841125
[5/24] Train loss=0.17050078511238098
[10/24] Train loss=0.18299144506454468
[15/24] Train loss=0.16356195509433746
[20/24] Train loss=0.17214687168598175
Test set avg_accuracy=88.27% avg_sensitivity=67.96%, avg_specificity=94.16% avg_auc=90.64%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.174247 Test loss=0.304113 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.16973893344402313
[5/24] Train loss=0.16476838290691376
[10/24] Train loss=0.17991524934768677
[15/24] Train loss=0.16895604133605957
[20/24] Train loss=0.16693533957004547
Test set avg_accuracy=87.46% avg_sensitivity=61.07%, avg_specificity=95.11% avg_auc=88.18%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.172649 Test loss=0.333519 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.16521739959716797
[5/24] Train loss=0.16011537611484528
[10/24] Train loss=0.1715923398733139
[15/24] Train loss=0.162970170378685
[20/24] Train loss=0.16510418057441711
Test set avg_accuracy=88.02% avg_sensitivity=63.04%, avg_specificity=95.26% avg_auc=89.64%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.168175 Test loss=0.312983 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.16163712739944458
[5/24] Train loss=0.15853601694107056
[10/24] Train loss=0.16835422813892365
[15/24] Train loss=0.16187646985054016
[20/24] Train loss=0.16219562292099
Test set avg_accuracy=88.07% avg_sensitivity=66.05%, avg_specificity=94.46% avg_auc=89.79%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.165314 Test loss=0.312869 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.16089297831058502
[5/24] Train loss=0.15459544956684113
[10/24] Train loss=0.16633708775043488
[15/24] Train loss=0.16215087473392487
[20/24] Train loss=0.16475528478622437
Test set avg_accuracy=87.63% avg_sensitivity=64.43%, avg_specificity=94.36% avg_auc=88.85%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.164445 Test loss=0.319335 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.16088244318962097
[5/24] Train loss=0.1555587202310562
[10/24] Train loss=0.1636134833097458
[15/24] Train loss=0.1601841300725937
[20/24] Train loss=0.16601233184337616
Test set avg_accuracy=88.12% avg_sensitivity=67.38%, avg_specificity=94.14% avg_auc=90.92%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.162537 Test loss=0.301877 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.16070249676704407
[5/24] Train loss=0.1527194082736969
[10/24] Train loss=0.16289950907230377
[15/24] Train loss=0.1583796739578247
[20/24] Train loss=0.16616979241371155
Test set avg_accuracy=87.98% avg_sensitivity=70.16%, avg_specificity=93.15% avg_auc=91.25%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.161285 Test loss=0.301305 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.15834084153175354
[5/24] Train loss=0.14589081704616547
[10/24] Train loss=0.16534143686294556
[15/24] Train loss=0.1556195467710495
[20/24] Train loss=0.16561388969421387
Test set avg_accuracy=88.24% avg_sensitivity=69.06%, avg_specificity=93.80% avg_auc=91.12%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.159608 Test loss=0.298606 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1564716100692749
[5/24] Train loss=0.1489030122756958
[10/24] Train loss=0.16187724471092224
[15/24] Train loss=0.15540121495723724
[20/24] Train loss=0.1678469479084015
Test set avg_accuracy=88.01% avg_sensitivity=69.64%, avg_specificity=93.33% avg_auc=90.92%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.159009 Test loss=0.301890 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.15079444646835327
[5/24] Train loss=0.1480882465839386
[10/24] Train loss=0.16156361997127533
[15/24] Train loss=0.1532253921031952
[20/24] Train loss=0.1575128734111786
Test set avg_accuracy=88.01% avg_sensitivity=68.13%, avg_specificity=93.77% avg_auc=90.57%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.157046 Test loss=0.302667 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1557096391916275
[5/24] Train loss=0.14802147448062897
[10/24] Train loss=0.15963026881217957
[15/24] Train loss=0.15305745601654053
[20/24] Train loss=0.156398206949234
Test set avg_accuracy=87.96% avg_sensitivity=65.24%, avg_specificity=94.54% avg_auc=89.34%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.156400 Test loss=0.313284 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.15527118742465973
[5/24] Train loss=0.1437002718448639
[10/24] Train loss=0.15925396978855133
[15/24] Train loss=0.1505483239889145
[20/24] Train loss=0.15630313754081726
Test set avg_accuracy=88.18% avg_sensitivity=66.51%, avg_specificity=94.46% avg_auc=89.11%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.155017 Test loss=0.313863 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14917400479316711
[5/24] Train loss=0.14434932172298431
[10/24] Train loss=0.15835009515285492
[15/24] Train loss=0.14904455840587616
[20/24] Train loss=0.15597645938396454
Test set avg_accuracy=88.15% avg_sensitivity=65.76%, avg_specificity=94.64% avg_auc=89.18%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.154518 Test loss=0.312481 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1499096155166626
[5/24] Train loss=0.14469558000564575
[10/24] Train loss=0.15522481501102448
[15/24] Train loss=0.1494256556034088
[20/24] Train loss=0.15661093592643738
Test set avg_accuracy=88.12% avg_sensitivity=66.69%, avg_specificity=94.34% avg_auc=89.35%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.153725 Test loss=0.315369 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.15267738699913025
[5/24] Train loss=0.1429295837879181
[10/24] Train loss=0.15698936581611633
[15/24] Train loss=0.1498001217842102
[20/24] Train loss=0.15369324386119843
Test set avg_accuracy=88.20% avg_sensitivity=67.38%, avg_specificity=94.24% avg_auc=90.05%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.153373 Test loss=0.310941 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.15024910867214203
[5/24] Train loss=0.14421483874320984
[10/24] Train loss=0.1508849859237671
[15/24] Train loss=0.14678312838077545
[20/24] Train loss=0.15382710099220276
Test set avg_accuracy=88.12% avg_sensitivity=68.19%, avg_specificity=93.90% avg_auc=89.54%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.152048 Test loss=0.312359 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.15536420047283173
[5/24] Train loss=0.14459511637687683
[10/24] Train loss=0.15633276104927063
[15/24] Train loss=0.15317510068416595
[20/24] Train loss=0.15027208626270294
Test set avg_accuracy=88.02% avg_sensitivity=66.28%, avg_specificity=94.32% avg_auc=89.17%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.152163 Test loss=0.315991 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1500653624534607
[5/24] Train loss=0.14420920610427856
[10/24] Train loss=0.15306511521339417
[15/24] Train loss=0.14833693206310272
[20/24] Train loss=0.1520329862833023
Test set avg_accuracy=88.24% avg_sensitivity=67.21%, avg_specificity=94.34% avg_auc=89.82%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.151715 Test loss=0.310172 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.14891760051250458
[5/24] Train loss=0.14455817639827728
[10/24] Train loss=0.15062466263771057
[15/24] Train loss=0.14928799867630005
[20/24] Train loss=0.15443933010101318
Test set avg_accuracy=88.23% avg_sensitivity=67.44%, avg_specificity=94.26% avg_auc=89.13%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.151067 Test loss=0.316108 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.15055924654006958
[5/24] Train loss=0.14591066539287567
[10/24] Train loss=0.1516454517841339
[15/24] Train loss=0.14671020209789276
[20/24] Train loss=0.15208566188812256
Test set avg_accuracy=88.33% avg_sensitivity=67.21%, avg_specificity=94.46% avg_auc=89.30%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.151338 Test loss=0.316641 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.14603956043720245
[5/24] Train loss=0.1433289796113968
[10/24] Train loss=0.15331460535526276
[15/24] Train loss=0.1470259428024292
[20/24] Train loss=0.1532180905342102
Test set avg_accuracy=87.60% avg_sensitivity=67.15%, avg_specificity=93.53% avg_auc=89.26%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.150525 Test loss=0.317872 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.14712315797805786
[5/24] Train loss=0.14290256798267365
[10/24] Train loss=0.15115244686603546
[15/24] Train loss=0.14790624380111694
[20/24] Train loss=0.15317220985889435
Test set avg_accuracy=87.79% avg_sensitivity=66.86%, avg_specificity=93.85% avg_auc=89.05%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.149682 Test loss=0.318033 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1456858217716217
[5/24] Train loss=0.14044052362442017
[10/24] Train loss=0.14922554790973663
[15/24] Train loss=0.1471412479877472
[20/24] Train loss=0.150613471865654
Test set avg_accuracy=87.86% avg_sensitivity=68.13%, avg_specificity=93.58% avg_auc=88.99%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.148475 Test loss=0.321358 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.14436140656471252
[5/24] Train loss=0.13946016132831573
[10/24] Train loss=0.14613482356071472
[15/24] Train loss=0.1423051804304123
[20/24] Train loss=0.14964190125465393
Test set avg_accuracy=87.85% avg_sensitivity=66.86%, avg_specificity=93.94% avg_auc=89.20%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.147424 Test loss=0.319722 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.14576703310012817
[5/24] Train loss=0.13763374090194702
[10/24] Train loss=0.14497686922550201
[15/24] Train loss=0.1437125951051712
[20/24] Train loss=0.1505494862794876
Test set avg_accuracy=87.77% avg_sensitivity=66.86%, avg_specificity=93.84% avg_auc=88.86%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.147025 Test loss=0.321286 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.14791804552078247
[5/24] Train loss=0.14090602099895477
[10/24] Train loss=0.14498713612556458
[15/24] Train loss=0.14286740124225616
[20/24] Train loss=0.15187421441078186
Test set avg_accuracy=88.03% avg_sensitivity=67.21%, avg_specificity=94.07% avg_auc=88.64%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.147169 Test loss=0.321094 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.14390933513641357
[5/24] Train loss=0.14247450232505798
[10/24] Train loss=0.14236050844192505
[15/24] Train loss=0.1420382559299469
[20/24] Train loss=0.15104034543037415
Test set avg_accuracy=87.99% avg_sensitivity=67.38%, avg_specificity=93.97% avg_auc=88.63%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.146062 Test loss=0.321855 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.14474935829639435
[5/24] Train loss=0.1381203681230545
[10/24] Train loss=0.14440715312957764
[15/24] Train loss=0.1420198529958725
[20/24] Train loss=0.1477917581796646
Test set avg_accuracy=87.85% avg_sensitivity=67.90%, avg_specificity=93.63% avg_auc=88.94%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.146032 Test loss=0.321235 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.14265844225883484
[5/24] Train loss=0.13731135427951813
[10/24] Train loss=0.1435411274433136
[15/24] Train loss=0.14233827590942383
[20/24] Train loss=0.14901547133922577
Test set avg_accuracy=87.88% avg_sensitivity=67.61%, avg_specificity=93.75% avg_auc=89.04%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.145341 Test loss=0.318988 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.14344428479671478
[5/24] Train loss=0.14034482836723328
[10/24] Train loss=0.14416661858558655
[15/24] Train loss=0.14043176174163818
[20/24] Train loss=0.14643904566764832
Test set avg_accuracy=88.02% avg_sensitivity=67.21%, avg_specificity=94.05% avg_auc=88.66%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.144856 Test loss=0.322443 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.14568345248699188
[5/24] Train loss=0.13537439703941345
[10/24] Train loss=0.1460503339767456
[15/24] Train loss=0.14222204685211182
[20/24] Train loss=0.1455552875995636
Test set avg_accuracy=88.03% avg_sensitivity=67.32%, avg_specificity=94.04% avg_auc=88.68%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.144091 Test loss=0.322309 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.14421173930168152
[5/24] Train loss=0.1354728788137436
[10/24] Train loss=0.14211876690387726
[15/24] Train loss=0.14633110165596008
[20/24] Train loss=0.14519618451595306
Test set avg_accuracy=87.93% avg_sensitivity=68.08%, avg_specificity=93.68% avg_auc=88.86%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.144692 Test loss=0.321298 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.14334939420223236
[5/24] Train loss=0.13883522152900696
[10/24] Train loss=0.1434740424156189
[15/24] Train loss=0.14273963868618011
[20/24] Train loss=0.14864327013492584
Test set avg_accuracy=87.86% avg_sensitivity=67.50%, avg_specificity=93.77% avg_auc=88.63%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.144677 Test loss=0.322439 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.14186710119247437
[5/24] Train loss=0.13443391025066376
[10/24] Train loss=0.14184360206127167
[15/24] Train loss=0.14004355669021606
[20/24] Train loss=0.14826364815235138
Test set avg_accuracy=87.83% avg_sensitivity=67.44%, avg_specificity=93.74% avg_auc=88.69%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.144105 Test loss=0.321946 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.140891432762146
[5/24] Train loss=0.13589005172252655
[10/24] Train loss=0.14220686256885529
[15/24] Train loss=0.14107905328273773
[20/24] Train loss=0.14716781675815582
Test set avg_accuracy=87.80% avg_sensitivity=67.21%, avg_specificity=93.77% avg_auc=88.68%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.143958 Test loss=0.322286 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1443384736776352
[5/24] Train loss=0.1352638304233551
[10/24] Train loss=0.14095237851142883
[15/24] Train loss=0.14301101863384247
[20/24] Train loss=0.14674913883209229
Test set avg_accuracy=87.84% avg_sensitivity=67.38%, avg_specificity=93.77% avg_auc=88.67%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.143694 Test loss=0.322780 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.14282701909542084
[5/24] Train loss=0.14013637602329254
[10/24] Train loss=0.14582377672195435
[15/24] Train loss=0.14417646825313568
[20/24] Train loss=0.14694353938102722
Test set avg_accuracy=87.84% avg_sensitivity=67.38%, avg_specificity=93.77% avg_auc=88.61%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.144271 Test loss=0.323264 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.14151118695735931
[5/24] Train loss=0.13448043167591095
[10/24] Train loss=0.14445766806602478
[15/24] Train loss=0.14175812900066376
[20/24] Train loss=0.14396914839744568
Test set avg_accuracy=87.80% avg_sensitivity=67.32%, avg_specificity=93.74% avg_auc=88.61%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.143620 Test loss=0.323261 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.14017897844314575
[5/24] Train loss=0.1364155262708664
[10/24] Train loss=0.14256201684474945
[15/24] Train loss=0.14058327674865723
[20/24] Train loss=0.147944375872612
Test set avg_accuracy=87.77% avg_sensitivity=67.27%, avg_specificity=93.72% avg_auc=88.62%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.144096 Test loss=0.323477 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.14119994640350342
[5/24] Train loss=0.13603852689266205
[10/24] Train loss=0.14318425953388214
[15/24] Train loss=0.14085888862609863
[20/24] Train loss=0.14496365189552307
Test set avg_accuracy=87.85% avg_sensitivity=67.32%, avg_specificity=93.80% avg_auc=88.61%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.143623 Test loss=0.323507 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1408139020204544
[5/24] Train loss=0.13556331396102905
[10/24] Train loss=0.14320825040340424
[15/24] Train loss=0.14288201928138733
[20/24] Train loss=0.14676806330680847
Test set avg_accuracy=87.83% avg_sensitivity=67.50%, avg_specificity=93.72% avg_auc=88.62%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.143370 Test loss=0.323539 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1425824612379074
[5/24] Train loss=0.13396015763282776
[10/24] Train loss=0.1435336470603943
[15/24] Train loss=0.13993114233016968
[20/24] Train loss=0.14418621361255646
Test set avg_accuracy=87.81% avg_sensitivity=67.32%, avg_specificity=93.75% avg_auc=88.58%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.143433 Test loss=0.323548 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=88.18% sen=75.09%, spe=91.97%, auc=92.48%!
Fold[10] Avg_overlap=0.67%(±0.24944283786124852)
Final Avg Result: avg_acc=86.15%(±1.1931620177183209) avg_sen=75.10% (±3.2184477781186396) avg_spe=89.92% (±1.573310308901408) avg_auc=91.47% (±1.0106718701177237) avg_overlap=0.67% (±0.01615876010081849)
